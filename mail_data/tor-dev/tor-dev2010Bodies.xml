<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20100601221233</emailId><senderName>Harry Bock</senderName><senderEmail>hbock@ele.uri.edu</senderEmail><timestampReceived>2010-06-01 22:12:33-0400</timestampReceived><subject>TorBEL data formats and active testing: feedback requested</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi all,

I've been working on TorBEL (http://tor.spanning-tree.org/) for GSoC
this year, and I'm looking for feedback on my current specifications for
data export and for an active testing mechanism.  I've bounced some
ideas around some of the developers in #tor-dev but I'd like to extend
the discussion to the mailing list.

Currently, I've written a brief draft of the "generic" data format,
which describes what fields each exit router/IP entry will contain, and
a specification for the CSV export format.  I've also started a
specification on how I plan to perform basic router testing and why.  I
tried to keep them similar to the RFC-style proposals and specs Tor has.

You can find the specifications in Git at:
http://git.spanning-tree.org/index.cgi/torbel/tree/doc

Some things I need feedback on:
  - Are the fields listed for each router/IP adequate information for
consumers of exit router data?  If not, what should I add, remove, or
clarify?
  - What other data formats are useful, easily distributable, and easily
parsed, and why? Keep in mind that consumers of this data will want
frequent updates, and the data format should be as compact as possible
to conserve bandwidth.
  - What are the most interesting ports we should be looking to test?
Should we test interesting ports even if they are explicitly rejected by
the router's ExitPolicy?  We can't test all ports on all exit routers,
so we have to limit ourselves to ports consumers would be most
interested in.  The data collected in [1] and [2] are a good start, but
I feel we need more feedback on the subject.
  - Any other comments, questions, or concerns about my approach thus
far as more than welcome!

Regards,
Harry

[1] http://freehaven.net/anonbib/cache/mccoy-pet2008.pdf
[2] http://freehaven.net/anonbib/cache/wecsr10measuring-tor.pdf
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkwFhdEACgkQDiEcLVRsw1NomgCfVd9fVkYQylLwJmcIA9ArNkV/
vEsAnj0YimGKaOQRKortr6zm+XczgOXQ
=aC4M
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100102160119</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-01-02 16:01:19-0400</timestampReceived><subject>Thoughts on future upnp/nat-pmp support in Tor</subject><body>


Hi,

During our developer meeting at the 26c3, we had a brief discussion
about extending Tor to work better behind NAT devices. Specifically,
we'd like to have the ability to configure port forwards for a bridge or
a relay behind a UPnP/NAT-PMP enabled device. Vidalia already does some
legwork to configure port forwarding on devices that support UPnP;
However, some systems do not have the ability to run Vidalia.

Here are two helpful pages to define the terms used above:
http://en.wikipedia.org/wiki/NAT_Port_Mapping_Protocol
http://en.wikipedia.org/wiki/Universal_Plug_and_Play

It seems like we have at least two paths forward:

 * Make a port forwarding stand alone program
 * Include port forwarding support in Tor itself

We had discussed possibly building an external helper tool but Peter
pointed out that this won't work well for running a chrooted Tor. If we
want to chroot by default in the future, we're probably not going to be
able to rely on external binaries. This may not be the best way forward.

Roger thinks that it's probably best to fork a (UPnP/NAT-PMP) project,
include it the Tor source and include it in the main Tor binary. If a
user has the local library (and it's newer than the included code),
we'll use their local library. This is similar to what Vidalia is doing
for UPnP support. However, Vidalia is lacking NAT-PMP support and of
course Vidalia is obviously external to the Tor binary itself. I think
adding UPnP/NAT-PMP to Tor may be the best way forward with some caveats.

Adding UPnP/NAT-PMP support to Tor has some possible pitfalls and some
clear benefits.

From a security standpoint, I'm sure that whatever library we use will
introduce code that we will need to audit. If we include it in the
source to Tor, I'm hopeful that someone will audit it. I'm not sure
who's going to step up and I'm certain that it's a lot of work. I wonder
if whatever we choose will even build with our debugging flags? I guess
probably not?

From a usability standpoint, adding this functionality seems like a
fantastic opportunity. The UPnP/NAT-PMP support will hopefully make it
effortless to setup a relay or to setup a bridge.

There are a few different software packages that we can choose from.
Currently, Vidalia uses the miniupnp client library. It seems that the
miniupnp client libraries are a good choice for UPnP/NAT-PMP support:
http://miniupnp.free.fr/
http://miniupnp.free.fr/files/download.php?file=miniupnpc-1.4.tar.gz
http://miniupnp.free.fr/files/download.php?file=libnatpmp-20091219.tar.gz

Both libraries are written in ANSI C and under a BSD license. The code
offered by the miniupnp project supports both UPnP and NAT-PMP. The UPnP
client appears to have a stable release, the NAT-PMP client code doesn't
appear to have had a real release yet. It may be best to introduce two
configuration options as we add support for each protocol:

	AttemptUPnP yes|no|auto
	AttemptNAT-PMP yes|no|auto

I've created a git branch on freehaven called 'attempt-upnp-natpmp'
where I will import the above listed tar.gz files.

I think that it's probably the case that we'll need a proposal for how
Tor's behavior will change. Does anyone want to take a stab at this with
me? I'll take a first pass at this and include it in my branch tonight.

All the best from the CCCB in Berlin,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100203220003</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-02-03 22:00:03-0400</timestampReceived><subject>Idea: Using the SPDY protocol to improve Tor performance</subject><body>

Filename: xxx-using-spdy.txt
Title: Using the SPDY protocol to improve Tor performance
Author: Steven J. Murdoch
Created: 03-Feb-2010
Status: Draft
Target:

1. Overview

   The SPDY protocol [1] is an alternative method for transferring
   web content over TCP, designed to improve efficiency and
   performance. A SPDY-aware browser can already communicate with
   a SPDY-aware web server over Tor, because this only requires a TCP
   stream to be set up. However, a SPDY-aware browser cannot
   communicate with a non-SPDY-aware web server. This proposal
   outlines how Tor could support this latter case, and why it
   may be good for performance.

2. Motivation

   About 90% of Tor traffic, by connection, is HTTP [2], but
   users report subjective performance to be poor. It would
   therefore be desirable to improve this situation. SPDY was
   designed to offer better performance than HTTP, in
   high-latency and/or low-bandwidth situations, and is therefore
   an option worth examining.

   If a user wishes to access a SPDY-enabled web server over Tor,
   all they need to do is to configure their SPDY-enabled browser
   (e.g. Google Chrome) to use Tor. However, there are few
   SPDY-enabled web servers, and even if there was high demand
   from Tor users, there would be little motivation for server
   operators to upgrade, for the benefit of only a small
   proportion of their users.

   The motivation of this proposal is to allow only the user to
   install a SPDY-enabled browser, and permit web servers to
   remain unmodified. Essentially, Tor would incorporate a proxy
   on the exit node, which communicates SPDY to the web browser
   and normal HTTP to the web server. This proxy would translate
   between the two transport protocols, and possibly perform
   other optimizations.

   SPDY currently offers five optimizations:

   1) Multiplexed streams:
      An unlimited number of resources can be transferred
      concurrently, over a single TCP connection.

   2) Request prioritization:
      The client can set a priority on each resource, to assist
      the server in re-ordering responses.

   3) Compression:
      Both HTTP header and resource content can be compressed.

   4) Server push:
      The server can offer the client resources which have not
      been requested, but which the server believes will be.

   5) Server hint:
      The server can suggest that the client request further
      resources, before the main content is transferred.

   Tor currently effectively implements (1), by being able to put
   multiple streams on one circuit. SPDY however requires fewer
   round-trips to do the same. The other features are not
   implemented by Tor. Therefore it is reasonable to expect that
   a HTTP &lt;-&gt; SPDY proxy may improve Tor performance, by some
   amount.

3. Design outline

   One way to implement the SPDY proxy is for Tor exit nodes to
   advertise this capability in their descriptor. The OP would
   then preferentially select these nodes when routing streams
   destined for port 80.

   Then, rather than sending the usual RELAY_BEGIN cell, the OP
   would send a RELAY_SPDY_BEGIN cell, to indicate that the exit
   node should translate between SPDY and HTTP. The rest of the
   connection process would operate as usual.

   There would need to be some way of elegantly handling non-HTTP
   traffic which goes over port 80.

4. Implementation status

   SPDY is under active development and both the specification
   and implementations are in a state of flux. Initial
   experiments with Google Chrome in SPDY-mode and server
   libraries indicate that more work is needed before they are
   production-ready. There is no indication that browsers other
   than Google Chrome will support SPDY (and no official
   statement as to whether Google Chrome will eventually enable
   SPDY by default).
   
   Implementing a full SPDY proxy would be non-trivial. Stream
   multiplexing and compression are supported by existing
   libraries and would be fairly simple to implement. Request
   prioritization would require some form of caching on the
   proxy-side. Server push and server hint would require content
   parsing to identify resources which should be treated
   specially.

5. Security and policy implications

   A SPDY proxy would be a significant amount of code, and may
   pull in external libraries. This code will process potentially
   malicious data, both at the SPDY and HTTP sides. This proposal
   therefore increases the risk that exit nodes will be
   compromised by exploiting a bug in the proxy.

   This proposal would also be the first way in which Tor is
   modifying TCP stream data. Arguably this is still meta-data
   (HTTP headers), but there may be some concern that Tor should
   not be doing this.

   Torbutton only works with Firefox, but SPDY only works with
   Google Chrome. We should be careful not to recommend that
   users adopt a browser which harms their privacy in other ways.

6. Open questions:

  - How difficult would this be to implement?

  - How much performance improvement would it actually result in?

  - Is there some way to rapidly develop a prototype which would
    answer the previous question?

[1] SPDY: An experimental protocol for a faster web
    http://dev.chromium.org/spdy/spdy-whitepaper
[2] Shining Light in Dark Places: Understanding the Tor Network Damon McCoy,
    Kevin Bauer, Dirk Grunwald, Tadayoshi Kohno, Douglas Sicker
    http://www.cs.washington.edu/homes/yoshi/papers/Tor/PETS2008_37.pdf

-- 
http://www.cl.cam.ac.uk/users/sjm217/
</body></email><email><emailId>20100305050208</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-03-05 05:02:08-0400</timestampReceived><subject>A couple of Git ideas: new branches, easier changelogs</subject><body>

PART 1: new branches

In the wake of the embarrassingly stupid bug 1269, I talked with Roger
and some other developers for a while about how we can use git better
to make sure that bugfixes only get backported to the stable branch
when they are well and truly tested.

Right now, we've been doing this in a couple of ways, both of which
are pretty bad in practice.  Sometimes we do fixes and merge them to
the master branch first, then backport them to the 0.2.1 branch via
cherry-picking once they've been around for a while.  This approach
risks losing track of patches, though, unless we keep close watch on
what fixes have happened where.  Sometimes we merge "obvious" fixes
into the 0.2.1 branch, and regularly merge 0.2.1 into master.
Unfortunately, "obvious" fixes can be broken too easily.

So here's what I propose.  We create a new "release-0.2.1" branch
based on maint-0.2.1, and do all our releases off that branch.  We do
_all_ bugfixes of 0.2.1 bugs in the maint-0.2.1 branch, which we merge
into master regularly.  We don't merge maint-0.2.1 directly into
release-0.2.1, however: instead, we tag it whenever we do a release of
0.2.2 from the master branch.  Only once the 0.2.2 version has tested
for a while do we merge maint-0.2.1 into release-0.2.1.  This way,
bugfixes get tested for a while in the alpha before they get merged
into stable, and we don't need to worry about losing track of them.

Not everything can be tested for a long time in the alpha before a
backport.  Notable exceptions are:
   1) fixes to bugs that only exist in the stable series
   2) critical bugs that need to get fixed Right Away.

For these, we should have a separate branch or two; I'm not sure what
to call them.

I think the above plan is an improvement, but I'm sure it's not
optimal.  Keeping the bikeshed in mind, are there better ideas, or
ways to do this better?

PART 2:

Git merges have been working really nicely for us, with one exception:
our changlog file.  Nearly every merge creates a conflict in the
changelog, and more work for the merger.  Worse, if somebody starts
working on a feature that doesn't get merged until after a release
occurs, their feature's changelog entry usually tries to merge itself
into the previous version's changelog section, not into the new
changelog stuff where it belongs.

If we do more parallel branches, merging will just get nastier.

Here are some options:
   A) Do nothing.
   B) Instead of creating a changelog entry, commits that want to add
something to the changelog should add a file to a "changes" directory,
whose elements get concatenated into a changelog before a release.
[weasel suggested this one.]
   C) Commit messages should try to be written so they themselves can
be turned into changelog entries.  To generate a changelog, just run
git log previous-release..master and massage the output.
   D) Like C, except recognizing that some commits don't warrant
independent changelog entries... so we add a way to annotate commits
(e.g., with a footer line) to say "This doesn't go in the changelog!"
or "This goes in the changelog in the new features section!"  Only
unannotated commits would need to get manually triaged.  We'd want a
little script to massage the git log into a draft changelog.

B and D seem like our best options to me.  B has the advantage that
it's easier to add or massage changelog entries between adding them
and the release; D has the advantage that we can't _forget_ to add a
changelog entry for anything.

-- 
Nick
</body></email><email><emailId>20100306034117</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-03-06 03:41:17-0400</timestampReceived><subject>Re: [or-cvs] r21825: {projects} Add FascistFirewall preference</subject><body>

On Sat, Mar 06, 2010 at 02:06:00AM +0000, Jacob Appelbaum wrote:
&gt; Modified:
&gt; projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java
&gt; Log:
&gt; Add FascistFirewall preference
&gt; 
&gt; Modified: projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java
&gt; ===================================================================
&gt; --- projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java	2010-03-06 \
&gt;                 01:27:51 UTC (rev 21824)
&gt; +++ projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java	2010-03-06 \
&gt; 02:06:00 UTC (rev 21825) @@ -460,6 +460,8 @@
[snip]
&gt; +                String fascistFirewallPorts =
&gt; +                    prefs.getString(PREF_FASCIST_FIREWALL_PORTS, "80,443");

 From the Tor man page:

  FirewallPorts PORTS
         A list of ports that your firewall allows  you  to  connect  to.
         Only  used  when  FascistFirewall  is set. This option is depre-
         cated; use ReachableAddresses instead. (Default: 80, 443)

So, don't do that. :)

You should also be aware that setting FascistFirewall 1 does not set
ReachableAddresses to "80, 443". It sets ReachableORAddresses to 443,
and ReachableDirAddresses to 80. So maybe you want to skip FascistFirewall
entirely and just set ReachableAddresses or not.

--Roger


</body></email><email><emailId>20100307113053</emailId><senderName>Christian Grothoff</senderName><senderEmail>christian@grothoff.org</senderEmail><timestampReceived>2010-03-07 11:30:53-0400</timestampReceived><subject>Help needed: Autonomous NAT traversal test [Was: enabling bridges on NATed clients]</subject><body>

Dear all,

In order to more thoroughly answer sird's question (for GNUnet, possibly for 
Tor and generally for anyone interested in P2P), a group of people (including 
Andreas Mueller, Samy Kamkar, Nate Evans and myself) would like your help.  

We've written a piece of software that will test your NAT implementation to 
determine how well various NAT hole punching techniques work.  The tester (at 
least the version with the tests we're interested in right now) currently only 
runs on W32 and requires that you first install http://www.winpcap.org/.  
Then, please download, unzip and run the NAT tester from 
http://nattest.net.in.tum.de/.

At the end, the tester will launch a browser to report the results back to the 
nat tester website for evaluation.  The collected data is made public, and our 
evaluation report will also be public; finally, whatever method we end up 
implementing for GNUnet based on this will be reasonably modular so that Tor 
can choose to build on our code (if the evaluation makes it look promising 
enough). 

Thanks for your help in advance!

Best regards,

Christian

On Monday 22 February 2010 12:56:39 am sird@rckc.at wrote:
&gt; What do you guys think about using http://samy.pl/pwnat/ idea to allow
&gt; people that want to run a bridge behind a NAT? Maybe enhance the
&gt; discovery protocol to this kind of stuff.
&gt; 
&gt; I say this because I think that people in china need bridges, and this
&gt; kind of solutions may dramatically help in that, specially because now
&gt; they can't just send reset packets in the discovery part of the
&gt; protocol.
&gt; 
&gt; Anyway, it's just an idea, what do you think? is it usable?
&gt; 
&gt; Greetings!!
&gt; 
</body></email><email><emailId>20100215082919</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-02-15 08:29:19-0400</timestampReceived><subject>Bridge stability</subject><body>

Hi everybody,

we have been wondering how useful the sets of bridges are that we are giving out to \
users. Some people complained to us that the bridges we give them aren't usable even \
a few hours later. So, let's give them more bridges, right? Or are these people just \
the unlucky ones, and everybody else is happy with what they got? We don't want to \
give out too many bridges at once to make it harder for an adversary to enumerate all \
the bridges. So, what's the number of bridges we should give out?

As you may know, whenever we receive a user request asking for bridges via e-mail or \
HTTP, we reply with a subset of 3 bridges, at least 1 of them running on port 443. \
The question I'm trying to answer here is: how long will at least one of these \
bridges be around? I took a look at our archives of bridge descriptors [0] to find an \
answer to this question.

I generated a graph [1] on the fraction of random bridge subsets containing at least \
1 running bridge throughout 6, 24, 48, or 96 hours. I generated this graph by taking \
1000 samples of 3 bridges (with at least one running on port 443) and looking how \
long at least one of them kept running over said 6, 24, 48, or 96 hours. As an \
example, if the graph contains a data point at 0.9 that means that 90% of all samples \
taken at that time had at least 1 bridge running (not necessarily the same one) at \
any time for the stated number of hours after that data point.

The graph has one unusual data point on December 11 where the 96-hours line drops to \
zero; this data point is probably an artifact of the simulation and is safe to \
ignore. Other than that, all lines decline around December 21 for a few days and at a \
couple other days, too; my first impression is that the bridge authority loses its \
state on Running bridges after a reboot and identifies bridges as not running though \
in fact they are. So, it might be that bridge availability is better here than the \
analysis tells us here.

As comparison, I also made graphs for subsets of 2 and of 4 bridges [2, 3], both of \
which containing at least 1 bridge on port 443. Unsurprisingly, the availability \
declines with only 2 bridges and improves with 4 bridges. However, even though \
availability improves for 4 bridges on average, the drops around December 21 and the \
other dates still stand out. This further strengthens the assumption that it's just \
the bridge authority thinking that bridges are offline, not that bridges are really \
down.

So, are these good news? Personally, I had expected worse results. During most of the \
time, availability is surprisingly high. An 80% chance of the bridges working even \
after 96 hours seems fair. That means in 1 out of 5 cases someone needs to send a \
second e-mail or make a second website request. We might even think (or have already \
thought) about implementing a bridge update functionality where users go to the \
bridge authority and exchange their broken bridges for working ones---as long as at \
least one of their bridges still works.

I should state that there is one major inaccuracy in the analysis: Bridges that \
change their IP address are not reachable by their clients anymore. In theory, \
clients are able to download updated bridge descriptors from the bridge authority to \
learn about new IP addresses, but this functionality is not implemented yet. However, \
I cannot take changing IP addresses into account for this analysis, because I removed \
the IP addresses when sanitizing the bridge descriptors. Hah! Maybe we should just \
fix this problem by implementing the missing functionality.

Another minor issue that Roger told me is that the bridge authority assigns the \
Stable flag to almost every bridge. If there was a sane way of assigning the Stable \
flag and we gave out, say, at least 1 bridge with the Stable flag, would this improve \
availability? This is rather hard to simulate. Maybe we should fix the Stable flag \
for bridges and run this analysis a second time as soon as we have some data. So many \
things to fix...

For those who'd like to experiment with this analysis, I made a tarball available [4] \
containing the Java application that does the parsing and the R script for plotting \
the graphs. You'll need to download the December 2009 [5] and January 2010 bridge \
descriptors [6] and change randomBridges in the source code to reproduce these \
results. You'll also install ggplot2 in R using the command \
'install.packages("ggplot2")' without 's.

--Karsten

[0] http://metrics.torproject.org/data.html#bridgedesc
[1] http://freehaven.net/~karsten/volatile/bridge-stability-default.png
[2] http://freehaven.net/~karsten/volatile/bridge-stability-2-bridges.png
[3] http://freehaven.net/~karsten/volatile/bridge-stability-4-bridges.png
[4] http://freehaven.net/~karsten/volatile/bridge-stability.tar.gz
[5] http://archive.torproject.org/tor-metrics-archive/bridge-descriptors-2009-12.tar.bz2
 [6] http://archive.torproject.org/tor-metrics-archive/bridge-descriptors-2010-01.tar.bz2



</body></email><email><emailId>20100507100616</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2010-05-07 10:06:16-0400</timestampReceived><subject>Using GnuTLS rather than OpenSSL</subject><body>

Hi,

In a discussion about memory consumption (buffers) with Roger and Jake,
the question of GnuTLS as an alternative to OpenSSL came up.

One of the things mentioned was the purported lack of support for
ephemeral Diffie-Hellman in GnuTLS.  Since we have its current
maintainer (and, I think, main developer) at arm's reach here I think we
should take the opportunity of meeting with him and discuss this before
Roger leaves Stockholm.

I don't know what Tor needs so I couldn't really judge whether existing
functionality would suffice: gnutls_certificate_set_dh_params(),
gnutls_dh_get_group(), gnutls_dh_get_peers_public_bits(),
gnutls_dh_get_prime_bits(), gnutls_dh_get_pubkey(),
gnutls_dh_get_secret_bits(), gnutls_dh_set_prime_bits()
(http://www.gnu.org/software/gnutls/manual/html_node/Core-functions.html#Core-functions
).


There might be other issues of course, perhaps licensing or similar.

-- 
Linus

</body></email><email><emailId>20100602164221</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-06-02 16:42:21-0400</timestampReceived><subject>(FWD) TLS False Start</subject><body>

Forwarding for Adam.

Any nice volunteer want to play with combining this with Tor?

--Roger

----- Forwarded message from Adam Langley &lt;agl@imperialviolet.org&gt; -----

From: Adam Langley &lt;agl@imperialviolet.org&gt;
To: Roger Dingledine &lt;arma@mit.edu&gt;, Nick Mathewson &lt;nickm@freehaven.net&gt;
Subject: TLS False Start
Delivery-Date: Wed, 02 Jun 2010 10:06:51 -0400

We've just published a draft[1] about a trick that we've been using in
Chrome for a while now which reduces the latency for a full TLS
handshake from two round trips to one without any server-side
modifications. I thought it might be useful for you.

The OpenSSL patch can be found at [2].

I have another trick to reduce the round trips to zero for both full
and abbreviated handshakes, but that one is still cooking. (And
precludes the possibility of EDH, which might be important to you.)

Cheers

AGL

[1] http://www.ietf.org/internet-drafts/draft-bmoeller-tls-falsestart-00.txt
[2] http://bazaar.launchpad.net/~nagendra/openssl-patches/trunk/files

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org

----- End forwarded message -----

</body></email><email><emailId>20100604031341</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-06-04 03:13:41-0400</timestampReceived><subject>concurrent circuits for traffic fragmentation</subject><body>

Hello,

Regarding the recent publicity, I was hoping to make a few comments. I
apologize in advance if this has been discussed before.

While Tor makes no claims of protecting unencrypted traffic at and
past exit nodes, it should be possible to mitigate the threat of
sniffing to a certain degree by fragmenting traffic. What I mean by
that is that a Tor client should be able to use more than one circuit
in the network at a time. For example, if a PDF file is downloaded
through Tor, half of it could pass through one exit node, and the
other through a second.

There would be the added benefit of increasing bandwidth, since chunks
could be downloaded in parallel. I imagine the simplex method could be
used to quickly determine how many or how big of a chunk to request
through each circuit, based on the cost (delay and throughput) of
each, in order to minimize latency and maximize throughput. The
function mapping chunks to circuits would be difficult to reconstruct
by an (single) outside attacker without real time information.

I imagine the Tor client daemon itself wouldn't need to be modified.
Many Tor daemons could be made to run concurrently and independently,
with traffic delegated by some sort of metadaemon.

I will make an attempt at implementing the latter somehow... Has
anyone tried this before?

Please let me know if I need to elaborate.

-- 
Mansour Moufid
</body></email><email><emailId>20100604033806</emailId><senderName>Brian Szymanski</senderName><senderEmail>ski@indymedia.org</senderEmail><timestampReceived>2010-06-04 03:38:06-0400</timestampReceived><subject>Re: concurrent circuits for traffic fragmentation</subject><body>

On 06/03/2010 11:13 PM, Mansour Moufid wrote:
&gt; Hello,
&gt;
&gt; Regarding the recent publicity, I was hoping to make a few comments. I
&gt; apologize in advance if this has been discussed before.
&gt;
&gt; While Tor makes no claims of protecting unencrypted traffic at and
&gt; past exit nodes, it should be possible to mitigate the threat of
&gt; sniffing to a certain degree by fragmenting traffic. What I mean by
&gt; that is that a Tor client should be able to use more than one circuit
&gt; in the network at a time. For example, if a PDF file is downloaded
&gt; through Tor, half of it could pass through one exit node, and the
&gt; other through a second.
&gt;   

Interesting thought.

... But wouldn't your proposal open tor up to further timing attacks and
other sorts of analysis - in other words, it's easier to notice N new
circuits going between two nodes than it is to notice one.

... And there's no reason to expect that fragmentation is significantly
useful in terms of making endpoint connections less insecure - sniffing
the first packet of a ssh connection is more than enough. Leaking half
of a classified document is not necessarily significantly better than a
whole classified document.  Etc. Perhaps if you gave every byte in the
connection a different route, you would do ok, but performance would be
unusable, if the packets even made it through.

In short, tor does not and IMO should not try to eliminate the need for
encrypted protocols like ssh and https. This doesn't seem like a win to me.

Or am I missing something?

Cheers,
Brian Szymanski



</body></email><email><emailId>201006040338060</emailId><senderName>Brian Szymanski</senderName><senderEmail>ski@indymedia.org</senderEmail><timestampReceived>2010-06-04 03:38:06-0400</timestampReceived><subject>Re: concurrent circuits for traffic fragmentation</subject><body>

On 06/03/2010 11:13 PM, Mansour Moufid wrote:
&gt; Hello,
&gt;
&gt; Regarding the recent publicity, I was hoping to make a few comments. I
&gt; apologize in advance if this has been discussed before.
&gt;
&gt; While Tor makes no claims of protecting unencrypted traffic at and
&gt; past exit nodes, it should be possible to mitigate the threat of
&gt; sniffing to a certain degree by fragmenting traffic. What I mean by
&gt; that is that a Tor client should be able to use more than one circuit
&gt; in the network at a time. For example, if a PDF file is downloaded
&gt; through Tor, half of it could pass through one exit node, and the
&gt; other through a second.
&gt;   

Interesting thought.

... But wouldn't your proposal open tor up to further timing attacks and
other sorts of analysis - in other words, it's easier to notice N new
circuits going between two nodes than it is to notice one.

... And there's no reason to expect that fragmentation is significantly
useful in terms of making endpoint connections less insecure - sniffing
the first packet of a ssh connection is more than enough. Leaking half
of a classified document is not necessarily significantly better than a
whole classified document.  Etc. Perhaps if you gave every byte in the
connection a different route, you would do ok, but performance would be
unusable, if the packets even made it through.

In short, tor does not and IMO should not try to eliminate the need for
encrypted protocols like ssh and https. This doesn't seem like a win to me.

Or am I missing something?

Cheers,
Brian Szymanski



</body></email><email><emailId>20100610160422</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-06-10 16:04:22-0400</timestampReceived><subject>Re: [or-cvs] [PATCH] Create a sample bridge configuration torrc.</subject><body>

Three issues below, one of them security-relevant.
(quoting commit in its entirety so others have context)

On Mon, Jun 07, 2010 at 03:03:07PM +0000, nickm@torproject.org wrote:
&gt; Author: Andrew Lewman &lt;andrew@torproject.org&gt;
&gt; Date: Sun, 6 Jun 2010 19:56:16 -0400
&gt; Subject: Create a sample bridge configuration torrc.
&gt; Commit: e95c44bc5af90d982e9d95d63e78b2fde67431ed
&gt; 
&gt; ---
&gt;  src/config/torrc.bridge.in |  171 ++++++++++++++++++++++++++++++++++++++++++++
&gt;  1 files changed, 171 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/config/torrc.bridge.in
&gt; 
&gt; diff --git a/src/config/torrc.bridge.in b/src/config/torrc.bridge.in
&gt; new file mode 100644
&gt; index 0000000..6f1f68d
&gt; --- /dev/null
&gt; +++ b/src/config/torrc.bridge.in
&gt; @@ -0,0 +1,171 @@
&gt; +## Configuration file for a typical Tor user
&gt; +## Last updated 16 July 2009 for Tor 0.2.2.1-alpha.
&gt; +## (May or may not work for much older or much newer versions of Tor.)
&gt; +##
&gt; +## Lines that begin with "## " try to explain what's going on. Lines
&gt; +## that begin with just "#" are disabled commands: you can enable them
&gt; +## by removing the "#" symbol.
&gt; +##
&gt; +## See 'man tor', or https://www.torproject.org/tor-manual.html,
&gt; +## for more options you can use in this file.
&gt; +##
&gt; +## Tor will look for this file in various places based on your platform:
&gt; +## https://wiki.torproject.org/noreply/TheOnionRouter/TorFAQ#torrc
&gt; +
&gt; +
&gt; +## Replace this with "SocksPort 0" if you plan to run Tor only as a
&gt; +## relay, and not make any local application connections yourself.
&gt; +SocksPort 9050 # what port to open for local application connections
&gt; +SocksListenAddress 127.0.0.1 # accept connections only from localhost
&gt; +#SocksListenAddress 192.168.0.1:9100 # listen on this IP:port also
&gt; +
&gt; +## Entry policies to allow/deny SOCKS requests based on IP address.
&gt; +## First entry that matches wins. If no SocksPolicy is set, we accept
&gt; +## all (and only) requests from SocksListenAddress.
&gt; +#SocksPolicy accept 192.168.0.0/16
&gt; +#SocksPolicy reject *
&gt; +
&gt; +## Logs go to stdout at level "notice" unless redirected by something
&gt; +## else, like one of the below lines. You can have as many Log lines as
&gt; +## you want.
&gt; +##
&gt; +## We advise using "notice" in most cases, since anything more verbose
&gt; +## may provide sensitive information to an attacker who obtains the logs.
&gt; +##
&gt; +## Send all messages of level 'notice' or higher to @LOCALSTATEDIR@/log/tor/notices.log
&gt; +#Log notice file @LOCALSTATEDIR@/log/tor/notices.log
&gt; +## Send every possible message to @LOCALSTATEDIR@/log/tor/debug.log
&gt; +#Log debug file @LOCALSTATEDIR@/log/tor/debug.log
&gt; +## Use the system log instead of Tor's logfiles
&gt; +#Log notice syslog
&gt; +## To send all messages to stderr:
&gt; +#Log debug stderr
&gt; +
&gt; +## Uncomment this to start the process in the background... or use
&gt; +## --runasdaemon 1 on the command line. This is ignored on Windows;
&gt; +## see the FAQ entry if you want Tor to run as an NT service.
&gt; +#RunAsDaemon 1
&gt; +
&gt; +## The directory for keeping all the keys/etc. By default, we store
&gt; +## things in $HOME/.tor on Unix, and in Application Data\tor on Windows.
&gt; +#DataDirectory @LOCALSTATEDIR@/lib/tor
&gt; +
&gt; +## The port on which Tor will listen for local connections from Tor
&gt; +## controller applications, as documented in control-spec.txt.
&gt; +ControlPort 9051
&gt; +## If you enable the controlport, be sure to enable one of these
&gt; +## authentication methods, to prevent attackers from accessing it.
&gt; +#HashedControlPassword 16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C
&gt; +#CookieAuthentication 1

1) It looks like we're setting ControlPort without setting any other
control port authentication lines? That is a bad move security-wise:
any java or flash applet that runs on the same computer and can play a
cross-domain trick lets you reconfigure our Tor.

What was the rationale for including this? Did we need it to get one of
our bundles to work right?

&gt; +############### This section is just for location-hidden services ###
&gt; +
&gt; +## Once you have configured a hidden service, you can look at the
&gt; +## contents of the file ".../hidden_service/hostname" for the address
&gt; +## to tell people.
&gt; +##
&gt; +## HiddenServicePort x y:z says to redirect requests on port x to the
&gt; +## address y:z.
&gt; +
&gt; +#HiddenServiceDir @LOCALSTATEDIR@/lib/tor/hidden_service/
&gt; +#HiddenServicePort 80 127.0.0.1:80
&gt; +
&gt; +#HiddenServiceDir @LOCALSTATEDIR@/lib/tor/other_hidden_service/
&gt; +#HiddenServicePort 80 127.0.0.1:80
&gt; +#HiddenServicePort 22 127.0.0.1:22
&gt; +
&gt; +################ This section is just for relays #####################
&gt; +#
&gt; +## See https://www.torproject.org/docs/tor-doc-relay for details.
&gt; +
&gt; +## Required: what port to advertise for incoming Tor connections.
&gt; +ORPort 9001
&gt; +## If you want to listen on a port other than the one advertised
&gt; +## in ORPort (e.g. to advertise 443 but bind to 9090), uncomment the
&gt; +## line below too. You'll need to do ipchains or other port forwarding
&gt; +## yourself to make this work.
&gt; +#ORListenAddress 0.0.0.0:9090

2) Vidalia has a nice trick where your ORPort defaults to 443 on Windows
but 9001 on Unix. That way we have more of our bridges on 443, but we
don't force you to deal with binding a low-numbered port on operating
systems that care.

Speaking of which: if this bridge torrc is designed to be used with
bundles that include Vidalia, what happens when Vidalia saves a config
change? Does it clobber the torrc changes, and you silently stop being
a bridge? Or does Vidalia read in the torrc lines and synchronize its
internal config to what Tor says it wants to be?

Or said another way, should we be shipping our bridge bundles with
*Vidalia* config changes rather than torrc config changes? Among other
features it would let us get the 443/9001 defaults right.

&gt; +## A handle for your relay, so people don't have to refer to it by key.
&gt; +Nickname Unnamed
&gt; +
&gt; +## The IP address or full DNS name for your relay. Leave commented out
&gt; +## and Tor will guess.
&gt; +#Address noname.example.com
&gt; +
&gt; +## Define these to limit how much relayed traffic you will allow. Your
&gt; +## own traffic is still unthrottled. Note that RelayBandwidthRate must
&gt; +## be at least 20 KBytes.
&gt; +#RelayBandwidthRate 100 KBytes  # Throttle traffic to 100KB/s (800Kbps)
&gt; +#RelayBandwidthBurst 200 KBytes # But allow bursts up to 200KB/s (1600Kbps)
&gt; +RelayBandwidthBurst 10485760
&gt; +RelayBandwidthRate 5242880
&gt; +
&gt; +## Use these to restrict the maximum traffic per day, week, or month.
&gt; +## Note that this threshold applies to sent _and_ to received bytes,
&gt; +## not to their sum: Setting "4 GBytes" may allow up to 8 GBytes
&gt; +## total before hibernating.
&gt; +##
&gt; +## Set a maximum of 4 gigabytes each way per period.
&gt; +#AccountingMax 4 GBytes
&gt; +## Each period starts daily at midnight (AccountingMax is per day)
&gt; +#AccountingStart day 00:00
&gt; +## Each period starts on the 3rd of the month at 15:00 (AccountingMax
&gt; +## is per month)
&gt; +#AccountingStart month 3 15:00
&gt; +
&gt; +## Contact info to be published in the directory, so we can contact you
&gt; +## if your relay is misconfigured or something else goes wrong. Google
&gt; +## indexes this, so spammers might also collect it.
&gt; +#ContactInfo Random Person &lt;nobody AT example dot com&gt;
&gt; +## You might also include your PGP or GPG fingerprint if you have one:
&gt; +#ContactInfo 1234D/FFFFFFFF Random Person &lt;nobody AT example dot com&gt;
&gt; +
&gt; +## Uncomment this to mirror directory information for others. Please do
&gt; +## if you have enough bandwidth.
&gt; +DirPort 9030 # what port to advertise for directory connections
&gt; +## If you want to listen on a port other than the one advertised
&gt; +## in DirPort (e.g. to advertise 80 but bind to 9091), uncomment the line
&gt; +## below too. You'll need to do ipchains or other port forwarding yourself
&gt; +## to make this work.
&gt; +#DirListenAddress 0.0.0.0:9091
&gt; +## Uncomment to return an arbitrary blob of html on your DirPort. Now you
&gt; +## can explain what Tor is if anybody wonders why your IP address is
&gt; +## contacting them. See contrib/tor-exit-notice.html in Tor's source
&gt; +## distribution for a sample.
&gt; +#DirPortFrontPage @CONFDIR@/tor-exit-notice.html

3) Bridges don't need to set DirPort, and they probably shouldn't if they
want to remain more subtle. No real harm; but another benefit to leaving
DirPort unset is that people wrestling with their port forwarding won't
have to wrestle quite as much.

&gt; +## Uncomment this if you run more than one Tor relay, and add the identity
&gt; +## key fingerprint of each Tor relay you control, even if they're on
&gt; +## different networks. You declare it here so Tor clients can avoid
&gt; +## using more than one of your relays in a single circuit. See
&gt; +## https://wiki.torproject.org/noreply/TheOnionRouter/TorFAQ#MultipleServers
&gt; +#MyFamily $keyid,$keyid,...
&gt; +
&gt; +## A comma-separated list of exit policies. They're considered first
&gt; +## to last, and the first match wins. If you want to _replace_
&gt; +## the default exit policy, end this with either a reject *:* or an
&gt; +## accept *:*. Otherwise, you're _augmenting_ (prepending to) the
&gt; +## default exit policy. Leave commented to just use the default, which is
&gt; +## described in the man page or at
&gt; +## https://www.torproject.org/documentation.html
&gt; +##
&gt; +## Look at https://www.torproject.org/faq-abuse.html#TypicalAbuses
&gt; +## for issues you might encounter if you use the default exit policy.
&gt; +##
&gt; +## If certain IPs and ports are blocked externally, e.g. by your firewall,
&gt; +## you should update your exit policy to reflect this -- otherwise Tor
&gt; +## users will be told that those destinations are down.
&gt; +##
&gt; +#ExitPolicy accept *:6660-6667,reject *:* # allow irc ports but no more
&gt; +#ExitPolicy accept *:119 # accept nntp as well as default exit policy
&gt; +#ExitPolicy reject *:* # no exits allowed
&gt; +#
&gt; +## Bridge relays (or "bridges") are Tor relays that aren't listed in the
&gt; +## main directory. Since there is no complete public list of them, even if an
&gt; +## ISP is filtering connections to all the known Tor relays, they probably
&gt; +## won't be able to block all the bridges. Also, websites won't treat you
&gt; +## differently because they won't know you're running Tor. If you can
&gt; +## be a real relay, please do; but if not, be a bridge!
&gt; +BridgeRelay 1
&gt; +ExitPolicy reject *:*
&gt; -- 
&gt; 1.6.5
&gt; 
</body></email><email><emailId>20100414161604</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-04-14 16:16:04-0400</timestampReceived><subject>Proposal: GETINFO controller option for connection information</subject><body>

Time to take the defibrillator paddles to this proposal once again. As per
Nick's request this is a bit more focused on the motivation for getting
connection related information. The proposed use cases are just some naive
examples I've come up with. If anyone with a stronger security background
(which wouldn't take much...) has the time I'd love comments like "WTF?!?
This idiot's looking for the completely wrong things! This is obviously
worthless if he doesn't look for X."

Also, could we move forward on the other (less controversial) items? For
instance, bandwidth totals tend to be a very highly requested piece of
information and pipe's already provided a nice patch to get it (
http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html). For
reference, here's the not-so-controversial GETINFO options I proposed:

  "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
    RelayBandwidthRate if set, otherwise BandwidthRate).

  "info/relay/burst-limit" -- Effective relayed burst limit.

  "info/relay/read-total" -- Total bytes relayed (download).

  "info/relay/write-total" -- Total bytes relayed (upload).

  "info/uptime-process" -- Total uptime of the tor process (in seconds).

  "info/uptime-reset" -- Time since last reset (startup or sighup signal, in
    seconds).

  "info/descriptor-used" -- Count of file descriptors used.

  "info/descriptor-limit" -- File descriptor limit (getrlimit results).

  "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.

I'm not planning on converting the following to the customary 80-character
width until it's at least past being a first draft for a couple reasons:
  1. I find editing fixed-width documents to be a time consuming pain in the
ass.
  2. I've yet to hear why we do this. Is it just to cater to mail clients
too dumb to know how to line wrap?

that said, keeping my fingers crossed that this starts going somewhere!
-Damian

PS. For previous discussions of this proposal see:
http://marc.info/?t=126101683100002&amp;r=1&amp;w=1

----------------------------------------

Filename: xxx-connection-getinfo-option.txt
Title: GETINFO controller option for connection information
Author: Damian Johnson
Created: 14-Apr-2010
Status: Draft

Overview:

    This details an additional GETINFO option for tor controllers that would
provide information concerning a relay's current connections.

Motivation:

    All Internet facing applications (tor included) are possible vectors for
attack on the operator's system. With hundreds of connections to relatively
unknown destinations tor is already the bane of any network based IDS, and
unless tor can be proved infallible and bug free (which would be quite a
feat!) it cannot be blindly trusted.

    While it is impossible to guard against every potential future
vulnerability, controllers can attempt to mitigate this threat by both
auditing tor's behavior and providing indicator of its activity to savvy
users. Connection related information is a useful tool for both of these
purposes.

    In terms of auditing, the following are some conditions controllers can
check for with connection information:
      - Persistent unestablished circuits. For instance a circuit has an
outbound connection without a corresponding inbound counterpart. If such a
connection was active (had substantial traffic) this would be troubling
enough to alert the user.
      - Relatively asymmetric traffic on circuits. Ie, if the controller
sees 10 kb/s inbound on a circuit and 5 mb/s outbound this could be a good
indicator that someone's using tor to issue a dos, fetch data from the local
system, etc.
      - Any connections to the local network when ExitPolicyRejectPrivate is
set, indicating that tor's being used to proxy connections to the local lan.
      - Peculiar patterns of connections, for instance numerous outbound
connections to a single IP, or if 99% of all bandwidth belonging to a single
circuit.
      - Scrubbed connection data limits our ability to check for obedience
to the exit policy, but for strictly non-exit relays we can still alert the
user if any non-relay outbound connections occur.

    Of course if we're working from the assumption that tor has been
compromised, then the information provided from the control port cannot be
blindly trusted. Hence connection data should be validateable against the
system's connection querying utilities (netstat, ss, lsof, etc - which are
more likely to be under a host based IDS, if present). This requires that
the system's been completely compromised (elevated permissions) before
controllers can be tricked, rather than just tor.

    While automated detection is handy for detecting known behavior that
might indicate issues, visualization gives us the possibility of finding
much more thanks to our tinfoil hat wearing user base. A clear display of
tor's current behavior gives assurance that tor's functioning as it should,
plus a level of transparency desirable from anyone with even the slightest
bit of paranoia. Tor is a guest process in the system of relay operators and
we should not hide what it does without legitimate reason.

    Another (albeit unintended) benefit of visualizing tor's behavior is
that it becomes a helpful tool in puzzling out how tor works. For instance,
tor spawns numerous client connections at startup (even if unused as a
client). As a newcomer to tor these asymmetric (outbound only) connections
mystified me for quite a while until until Roger explained their use to me.
The proposed TYPE_FLAGS would let controllers clearly label them as being
client related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
netstat, ss, and lsof. However, fetching it via the control port provides
several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
not. The relay's flags and cached consensus can be used to take educated
guesses concerning which connections could possibly belong to client or exit
traffic, but this is both difficult and inaccurate.

      - additional information
          All connection querying commands strictly provide the ip address
and port of connections, and nothing else. However, for auditing and
visualization the far more interesting attributes are the connection's
bandwidth usage, uptime, and the circuit to which it belongs.

      - improved performance
          Querying connection data is an expensive activity, especially for
busy relays or low end processors (such as mobile devices). Tor already
internally knows its circuits and connections, allowing for vastly quicker
lookups.

      - cross platform capability
          The connection querying utilities mentioned above not only aren't
available under Windows, but differ widely among different *nix platforms.
FreeBSD in particular takes a very unique approach, dropping important
options from netstat and assigning ss to a spreadsheet application instead.
A controller interface, however, would provide a uniform means of retrieving
this information.

Security Implications:

    The original version of this proposal left the responsibility of
scrubbing connection data with client applications (vidalia, arm, etc).
However, this was deemed unacceptable by Sebastian and Nick in previous
discussions. The proposal now includes dropping the ip address/port of
client and exit connections from the controller's response. That said, I
think it's a mistake to drop those connections entirely since some of their
attributes *are* of legitimate usefulness:

    - Existence
      At the very least it'd be nice if Tor indicated their existence (ie,
I'd say "yea, an exit connection exists on this circuit but we won't tell
you where it goes."). This would be useful, for instance, if the relay
operator has misconfigured their firewall to block some of the outbound
ports permitted by their exit policy (arm would show this as RELAY -&gt; YOU -&gt;
UNESTABLISHED, and provide a warning to indicate the issue).

    - Bandwidth
      For auditing the most interesting attribute of connections, imho, is
the bandwidth. If, says 10 KB/s is coming in and 1 MB/s is going out on a
circuit that's a good indicator that something is *very* wrong (I'd start
suspecting a security issue, personally). If we rounded all bandwidth
measurements (say, to the nearest KB) would this be sufficient to prevent
entry/exits from correlating this data to attack anonymity?

    - Uptime
      If connections are being cycled abnormally quickly (say, all
connection longevity is under thirty seconds) this could indicate the ISP
(or other middlemen like the great firewall) are sending reset packets to
kill the relay's attempts to make exit connections.

Specification:

   The following addition would be made to the control-spec's GETINFO
section:

  "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the
    associated connection, formatted as:
      CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME

    none of the parameters contain whitespace, and additional results must
be
    ignored to allow for future expansion. Parameters are defined as
follows:
      CONN_ID - Unique identifier associated with this connection.
      CIRC_ID - Unique identifier for the circuit this belongs to (0 if this
        doesn't belong to any circuit). At most their may be two connections
        (one inbound, one outbound) with any given CIRC_ID except in the
case
        of exit connections.
      OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
      IP/PORT - IP address and port used by the associated connection, 0 if
        connection is used for relaying client or exit traffic.
      L_PORT - Local port used by the connection, 0 if connection is used
for
        relaying client or exit traffic.
      TYPE_FLAGS - Single character flags indicating directionality and type
        of the connection (consists of one from each category, may become
        longer for future expansion).
          Connection Directionality:
            I: inbound, i: listening (unestablished inbound),
            O: outbound, o: unestablished outbound
          Usage Type:
            C: client traffic, R: relaying traffic,
            X: control, H: hidden service, D: directory
          Destination:
            T: inter-tor connection, t: outside the tor network
        For instance, "IRt" would indicate that this was an established
        1st-hop (or bridged) relay connection.
      READ/WRITE - Total bytes read/written over the life of this
connection.
      UPTIME - Time the connection's been established in seconds.

  "conn/all" -- Newline separated listing of all current connections.

[Attachment #3 (text/html)]

Time to take the defibrillator paddles to this proposal once again. As per Nick's \
request this is a bit more focused on the motivation for getting connection related \
information. The proposed use cases are just some naive examples I've come up \
with. If anyone with a stronger security background (which wouldn't take much...) \
has the time I'd love comments like "WTF?!? This idiot's looking for the \
completely wrong things! This is obviously worthless if he doesn't look for \
X."&lt;br&gt; &lt;br&gt;Also, could we move forward on the other (less controversial) items? \
For instance, bandwidth totals tend to be a very highly requested piece of \
information and pipe's already provided a nice patch to get it (&lt;a \
href="http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html"&gt;http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html&lt;/a&gt;). \
For reference, here's the not-so-controversial GETINFO options I proposed:&lt;br&gt; \
&lt;br&gt;  "info/relay/bw-limit" -- Effective relayed bandwidth limit \
(currently&lt;br&gt;    RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt;&lt;br&gt;  \
"info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt; &lt;br&gt;  \
"info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;&lt;br&gt;  \
"info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt;&lt;br&gt;  \
"info/uptime-process" -- Total uptime of the tor process (in seconds).&lt;br&gt; \
&lt;br&gt;  "info/uptime-reset" -- Time since last reset (startup or sighup \
signal, in&lt;br&gt;    seconds).&lt;br&gt;&lt;br&gt;  "info/descriptor-used" -- Count of \
file descriptors used.&lt;br&gt;&lt;br&gt;  "info/descriptor-limit" -- File descriptor \
limit (getrlimit results).&lt;br&gt; &lt;br&gt;  "ns/authority" -- Router status info \
(v2 directory style) for all&lt;br&gt;    recognized directory authorities, joined by \
newlines.&lt;br&gt;&lt;br&gt;I'm not planning on converting the following to the customary \
80-character width until it's at least past being a first draft for a couple \
reasons:&lt;br&gt;  1. I find editing fixed-width documents to be a time consuming pain in \
the ass.&lt;br&gt;  2. I've yet to hear why we do this. Is it just to cater to mail \
clients too dumb to know how to line wrap?&lt;br&gt;&lt;br&gt;that said, keeping my fingers \
crossed that this starts going somewhere! -Damian&lt;br&gt; &lt;br&gt;PS. For previous \
discussions of this proposal see:&lt;br&gt;&lt;a \
href="http://marc.info/?t=126101683100002&amp;r=1&amp;w=1"&gt;http://marc.info/?t=126101683100002&amp;r=1&amp;w=1&lt;/a&gt;&lt;br&gt;&lt;br&gt;----------------------------------------&lt;br&gt;
 &lt;br&gt;Filename: xxx-connection-getinfo-option.txt&lt;br&gt;Title: GETINFO controller option \
for connection information&lt;br&gt;Author: Damian Johnson&lt;br&gt;Created: \
14-Apr-2010&lt;br&gt;Status: Draft&lt;br&gt;&lt;br&gt;Overview:&lt;br&gt;&lt;br&gt;    This details an additional \
GETINFO option for tor controllers that would provide information concerning a \
relay's current connections.&lt;br&gt; &lt;br&gt;Motivation:&lt;br&gt;&lt;br&gt;    All Internet facing \
applications (tor included) are possible vectors for attack on the operator's \
system. With hundreds of connections to relatively unknown destinations tor is \
already the bane of any network based IDS, and unless tor can be proved infallible \
and bug free (which would be quite a feat!) it cannot be blindly trusted.&lt;br&gt;  &lt;br&gt;   \
While it is impossible to guard against every potential future vulnerability, \
controllers can attempt to mitigate this threat by both auditing tor's behavior \
and providing indicator of its activity to savvy users. Connection related \
information is a useful tool for both of these purposes.&lt;br&gt;  &lt;br&gt;    In terms of \
auditing, the following are some conditions controllers can check for with connection \
information:&lt;br&gt;      - Persistent unestablished circuits. For instance a circuit has \
an outbound connection without a corresponding inbound counterpart. If such a \
connection was active (had substantial traffic) this would be troubling enough to \
                alert the user.&lt;br&gt;
      - Relatively asymmetric traffic on circuits. Ie, if the controller sees 10 kb/s \
inbound on a circuit and 5 mb/s outbound this could be a good indicator that \
                someone's using tor to issue a dos, fetch data from the local \
                system, etc.&lt;br&gt;
      - Any connections to the local network when ExitPolicyRejectPrivate is set, \
indicating that tor's being used to proxy connections to the local lan.&lt;br&gt;      \
- Peculiar patterns of connections, for instance numerous outbound connections to a \
                single IP, or if 99% of all bandwidth belonging to a single \
                circuit.&lt;br&gt;
      - Scrubbed connection data limits our ability to check for
obedience to the exit policy, but for strictly
non-exit relays we can still alert the user if any non-relay outbound
connections occur.&lt;br&gt;
    &lt;br&gt;    Of course if we're working from the assumption that tor has been \
compromised, then the information provided from the control port cannot be blindly \
trusted. Hence connection data should be validateable against the system's \
connection querying utilities (netstat, ss, lsof, etc - which are more likely to be \
under a host based IDS, if present). This requires that the system's been \
completely compromised (elevated permissions) before controllers can be tricked, \
rather than just tor.&lt;br&gt;  &lt;br&gt;    While automated detection is handy for detecting \
known behavior that might indicate issues, visualization gives us the possibility of \
finding much more thanks to our tinfoil hat wearing user base. A clear display of \
tor's current behavior gives assurance that tor's functioning as it should, \
plus a level of transparency desirable from anyone with even the slightest bit of \
paranoia. Tor is a guest process in the system of relay operators and we should not \
hide what it does without legitimate reason.&lt;br&gt;  &lt;br&gt;    Another (albeit unintended) \
benefit of visualizing tor's behavior is that it becomes a helpful tool in \
puzzling out how tor works. For instance, tor spawns numerous client connections at \
startup (even if unused as a client). As a newcomer to tor these asymmetric (outbound \
only) connections mystified me for quite a while until until Roger explained their \
use to me. The proposed TYPE_FLAGS would let controllers clearly label them as being \
client related, making their purpose a bit clearer.&lt;br&gt;  &lt;br&gt;    At the moment \
connection data can only be retrieved via commands like netstat, ss, and lsof. \
However, fetching it via the control port provides several advantages:&lt;br&gt;      &lt;br&gt;  \
- scrubbing for private data&lt;br&gt;  Raw connection data has no notion of what's \
sensitive and what is not. The relay's flags and cached consensus can be used to \
take educated guesses concerning which connections could possibly belong to client or \
exit traffic, but this is both difficult and inaccurate.&lt;br&gt;  &lt;br&gt;      - additional \
information&lt;br&gt;          All connection querying commands strictly provide the ip \
address and port of connections, and nothing else. However, for auditing and \
visualization the far more interesting attributes are the connection's bandwidth \
usage, uptime, and the circuit to which it belongs.&lt;br&gt;  &lt;br&gt;      - improved \
performance&lt;br&gt;          Querying connection data is an expensive activity, \
especially for busy relays or low end processors (such as mobile devices). Tor \
already internally knows its circuits and connections, allowing for vastly quicker \
lookups.&lt;br&gt;  &lt;br&gt;      - cross platform capability&lt;br&gt;          The connection \
querying utilities mentioned above not only aren't available under Windows, but \
differ widely among different *nix platforms. FreeBSD in particular takes a very \
unique approach, dropping important options from netstat and assigning ss to a \
spreadsheet application instead. A controller interface, however, would provide a \
uniform means of retrieving this information.&lt;br&gt; &lt;br&gt;Security Implications:&lt;br&gt;&lt;br&gt;  \
The original version of this proposal left the responsibility of scrubbing connection \
data with client applications (vidalia, arm, etc). However, this was deemed \
unacceptable by Sebastian and Nick in previous discussions. The proposal now includes \
dropping the ip address/port of client and exit connections from the controller's \
response. That said, I think it's a mistake to drop those connections entirely \
since some of their attributes *are* of legitimate usefulness:&lt;br&gt;  &lt;br&gt;    - \
Existence&lt;br&gt;      At the very least it'd be nice if Tor indicated their \
existence (ie, I'd say "yea, an exit connection exists on this circuit but \
we won't tell you where it goes."). This would be useful, for instance, if \
the relay operator has misconfigured their firewall to block some of the outbound \
ports permitted by their exit policy (arm would show this as RELAY -&gt; YOU -&gt; \
UNESTABLISHED, and provide a warning to indicate the issue).&lt;br&gt;  &lt;br&gt;    - \
Bandwidth&lt;br&gt;      For auditing the most interesting attribute of connections, imho, \
is the bandwidth. If, says 10 KB/s is coming in and 1 MB/s is going out on a circuit \
that's a good indicator that something is *very* wrong (I'd start suspecting \
a security issue, personally). If we rounded all bandwidth measurements (say, to the \
nearest KB) would this be sufficient to prevent entry/exits from correlating this \
data to attack anonymity?&lt;br&gt;  &lt;br&gt;    - Uptime&lt;br&gt;      If connections are being \
cycled abnormally quickly (say, all connection longevity is under thirty seconds) \
this could indicate the ISP (or other middlemen like the great firewall) are sending \
reset packets to kill the relay's attempts to make exit connections.&lt;br&gt; \
&lt;br&gt;Specification:&lt;br&gt;&lt;br&gt;   The following addition would be made to the \
control-spec's GETINFO section:&lt;br&gt;&lt;br&gt;  "conn/&lt;Circuit \
identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the&lt;br&gt;    \
associated connection, formatted as:&lt;br&gt;  CONN_ID CIRC_ID OR_ID IP PORT L_PORT \
TYPE_FLAGS READ WRITE UPTIME&lt;br&gt;&lt;br&gt;    none of the parameters contain whitespace, \
and additional results must be&lt;br&gt;    ignored to allow for future expansion. \
Parameters are defined as follows:&lt;br&gt;  CONN_ID - Unique identifier associated with \
this connection.&lt;br&gt;      CIRC_ID - Unique identifier for the circuit this belongs to \
(0 if this&lt;br&gt;        doesn't belong to any circuit). At most their may be two \
connections&lt;br&gt;  (one inbound, one outbound) with any given CIRC_ID except in the \
case&lt;br&gt;        of exit connections.&lt;br&gt;      OR_ID - Relay fingerprint, 0 if \
connection doesn't belong to a relay.&lt;br&gt;      IP/PORT - IP address and port used \
by the associated connection, 0 if&lt;br&gt;  connection is used for relaying client or \
exit traffic.&lt;br&gt;      L_PORT - Local port used by the connection, 0 if connection is \
used for&lt;br&gt;        relaying client or exit traffic.&lt;br&gt;      TYPE_FLAGS - Single \
character flags indicating directionality and type&lt;br&gt;  of the connection (consists \
of one from each category, may become&lt;br&gt;        longer for future expansion).&lt;br&gt;    \
Connection Directionality:&lt;br&gt;            I: inbound, i: listening (unestablished \
inbound),&lt;br&gt;  O: outbound, o: unestablished outbound&lt;br&gt;          Usage Type:&lt;br&gt;    \
C: client traffic, R: relaying traffic,&lt;br&gt;            X: control, H: hidden service, \
D: directory&lt;br&gt;          Destination:&lt;br&gt;            T: inter-tor connection, t: \
outside the tor network&lt;br&gt;  For instance, "IRt" would indicate that this \
was an established&lt;br&gt;        1st-hop (or bridged) relay connection.&lt;br&gt;      \
READ/WRITE - Total bytes read/written over the life of this connection.&lt;br&gt;      \
UPTIME - Time the connection's been established in seconds.&lt;br&gt; &lt;br&gt;  \
"conn/all" -- Newline separated listing of all current connections.&lt;br&gt;&lt;br&gt;



</body></email><email><emailId>20100416164023</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-04-16 16:40:23-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

Yesterday Jake met with me to discuss this proposal, making the very
good points that both:
  1. It's completely ineffectual for the auditing purposes I've
mentioned since either (a) these results can be fetched from netstat
already or (b) the information would only be provided via tor and
can't be validated.
  2. The things I'm really interested in can be fetched with much less
(and safer) information.

In particular we discussed making the proposal circuit based rather
than connection based, being something like the following:

  "circ/&lt;Circuit identity&gt;" -- Provides entry for the associated circuit,
    formatted as:
      CIRC_ID IN_TYPE OUT_TYPE READ WRITE UPTIME

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique identifier for the circuit this belongs to.
      IN_TYPE/OUT_TYPE - Single character flags indicating the purpose of the
        inbound or outbound connection. If no connection is established then
        this provides an empty string. Otherwise, it consists of one from each
        of the following categories (this may become longer in future
        expansion):
          Usage Type:
            C: client traffic, R: relaying traffic,
            X: control, H: hidden service, D: directory
          Destination:
            I: inter-tor connection, O: outside the tor network, L: localhost
        For instance, "RO" would indicate that this was an established
        1st-hop (or bridged) relay connection.
      READ/WRITE - Total bytes read/written over the life of this connection.
      UPTIME - Time the connection's been established in seconds.

  "circ/all" -- Newline separated listing of all current circuits.

This would be almost just as useful for the purposes I'm interested in
while also stripping the most sensitive data entirely (ip addresses,
ports, and connection based bandwidth breakdowns). In particularly
this information could still address the following:

- Basic Relay Usage Questions
How is the bandwidth I'm contributing broken down? Is it being evenly
distributed or is someone hogging most of it? Do these circuits belong
to the hidden service I'm running or something else? Now that I'm
using exit policy X am I desirable as an exit, or are most people just
using me as a relay?

- Debugging
Say a relay has a restrictive firewall policy for outbound
connections, with the ORPort whitelisted but doesn't realize that tor
needs random high ports. Tor would report success ("your orport is
reachable - excellent") yet the relay would be nonfunctional. This
proposed information would reveal numerous RELAY -&gt; YOU -&gt;
UNESTABLISHED circuits, giving a good indicator of what's wrong.

- Visualization
This would still yield the benefits mentioned in the last proposal of
helping to demystify behavior the operator isn't expecting (see the
client example from before).

----------------------------------------

Second, Jake made a great point that at present if a malicious party
gets ahold of the control port then the relay's quite effectively
screwed. The current capabilities of the control port are overkill for
many controllers (like arm) which are just interested in retrieving
information from tor (GETINFO options, event listening, etc). To make
the control port safer we could include a torrc option that makes the
control port read-only...

  SafeControlPort 0|1
    Restricts access of the control port to only include read-only operations.
    (Default: 0)

Making this the default would be a no-go due to vidalia (though still
a nice option to have...). If this is implemented its setting should
be part of the PROTOCOLINFO response.

----------------------------------------

Finally, the other proposed GETINFO options still seem useful (with
the possible exception of "info/uptime-reset"), and could be improved
with the addition of:

  "info/user" -- User under which the tor process is running, providing an
    empty string if none exists.

  "info/pid" -- Process id belonging to the tor process, -1 if none exists for
    the platform.

* this one is both useful and surprisingly difficult for me to
retrieve at present (arm attempts to get it from pidof, ps, and
netstat yet still fails on some systems...)

In addition Jake mentioned the possibility of making info/* options
for all limits and capabilities (though I'd hold off until we have use
cases needing them...) and the following entries for getting activity
snapshots:

  "info/relay/[read, write]/avg/[1, 5, 15]" -- Provides the average traffic
    (bytes read or written per second) over the last 1, 5, or 15 minutes.

  "info/relay/circ/avg/[1, 5, 15]" -- Provides the average number of circuits
    established in the last 1, 5, or 15 minutes.

Cheers! -Damian

On Wed, Apr 14, 2010 at 9:16 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; Time to take the defibrillator paddles to this proposal once again. As per
&gt; Nick's request this is a bit more focused on the motivation for getting
&gt; connection related information. The proposed use cases are just some naive
&gt; examples I've come up with. If anyone with a stronger security background
&gt; (which wouldn't take much...) has the time I'd love comments like "WTF?!?
&gt; This idiot's looking for the completely wrong things! This is obviously
&gt; worthless if he doesn't look for X."
&gt;
&gt; Also, could we move forward on the other (less controversial) items? For
&gt; instance, bandwidth totals tend to be a very highly requested piece of
&gt; information and pipe's already provided a nice patch to get it
&gt; (http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html). For
&gt; reference, here's the not-so-controversial GETINFO options I proposed:
&gt;
&gt;   "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt;     RelayBandwidthRate if set, otherwise BandwidthRate).
&gt;
&gt;   "info/relay/burst-limit" -- Effective relayed burst limit.
&gt;
&gt;   "info/relay/read-total" -- Total bytes relayed (download).
&gt;
&gt;   "info/relay/write-total" -- Total bytes relayed (upload).
&gt;
&gt;   "info/uptime-process" -- Total uptime of the tor process (in seconds).
&gt;
&gt;   "info/uptime-reset" -- Time since last reset (startup or sighup signal, in
&gt;     seconds).
&gt;
&gt;   "info/descriptor-used" -- Count of file descriptors used.
&gt;
&gt;   "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt;
&gt;   "ns/authority" -- Router status info (v2 directory style) for all
&gt;     recognized directory authorities, joined by newlines.
&gt;
&gt; I'm not planning on converting the following to the customary 80-character
&gt; width until it's at least past being a first draft for a couple reasons:
&gt;   1. I find editing fixed-width documents to be a time consuming pain in the
&gt; ass.
&gt;   2. I've yet to hear why we do this. Is it just to cater to mail clients
&gt; too dumb to know how to line wrap?
&gt;
&gt; that said, keeping my fingers crossed that this starts going somewhere!
&gt; -Damian
&gt;
&gt; PS. For previous discussions of this proposal see:
&gt; http://marc.info/?t=126101683100002&amp;r=1&amp;w=1
&gt;
&gt; ----------------------------------------
&gt;
&gt; Filename: xxx-connection-getinfo-option.txt
&gt; Title: GETINFO controller option for connection information
&gt; Author: Damian Johnson
&gt; Created: 14-Apr-2010
&gt; Status: Draft
&gt;
&gt; Overview:
&gt;
&gt;     This details an additional GETINFO option for tor controllers that would
&gt; provide information concerning a relay's current connections.
&gt;
&gt; Motivation:
&gt;
&gt;     All Internet facing applications (tor included) are possible vectors for
&gt; attack on the operator's system. With hundreds of connections to relatively
&gt; unknown destinations tor is already the bane of any network based IDS, and
&gt; unless tor can be proved infallible and bug free (which would be quite a
&gt; feat!) it cannot be blindly trusted.
&gt;
&gt;     While it is impossible to guard against every potential future
&gt; vulnerability, controllers can attempt to mitigate this threat by both
&gt; auditing tor's behavior and providing indicator of its activity to savvy
&gt; users. Connection related information is a useful tool for both of these
&gt; purposes.
&gt;
&gt;     In terms of auditing, the following are some conditions controllers can
&gt; check for with connection information:
&gt;       - Persistent unestablished circuits. For instance a circuit has an
&gt; outbound connection without a corresponding inbound counterpart. If such a
&gt; connection was active (had substantial traffic) this would be troubling
&gt; enough to alert the user.
&gt;       - Relatively asymmetric traffic on circuits. Ie, if the controller
&gt; sees 10 kb/s inbound on a circuit and 5 mb/s outbound this could be a good
&gt; indicator that someone's using tor to issue a dos, fetch data from the local
&gt; system, etc.
&gt;       - Any connections to the local network when ExitPolicyRejectPrivate is
&gt; set, indicating that tor's being used to proxy connections to the local lan.
&gt;       - Peculiar patterns of connections, for instance numerous outbound
&gt; connections to a single IP, or if 99% of all bandwidth belonging to a single
&gt; circuit.
&gt;       - Scrubbed connection data limits our ability to check for obedience
&gt; to the exit policy, but for strictly non-exit relays we can still alert the
&gt; user if any non-relay outbound connections occur.
&gt;
&gt;     Of course if we're working from the assumption that tor has been
&gt; compromised, then the information provided from the control port cannot be
&gt; blindly trusted. Hence connection data should be validateable against the
&gt; system's connection querying utilities (netstat, ss, lsof, etc - which are
&gt; more likely to be under a host based IDS, if present). This requires that
&gt; the system's been completely compromised (elevated permissions) before
&gt; controllers can be tricked, rather than just tor.
&gt;
&gt;     While automated detection is handy for detecting known behavior that
&gt; might indicate issues, visualization gives us the possibility of finding
&gt; much more thanks to our tinfoil hat wearing user base. A clear display of
&gt; tor's current behavior gives assurance that tor's functioning as it should,
&gt; plus a level of transparency desirable from anyone with even the slightest
&gt; bit of paranoia. Tor is a guest process in the system of relay operators and
&gt; we should not hide what it does without legitimate reason.
&gt;
&gt;     Another (albeit unintended) benefit of visualizing tor's behavior is
&gt; that it becomes a helpful tool in puzzling out how tor works. For instance,
&gt; tor spawns numerous client connections at startup (even if unused as a
&gt; client). As a newcomer to tor these asymmetric (outbound only) connections
&gt; mystified me for quite a while until until Roger explained their use to me.
&gt; The proposed TYPE_FLAGS would let controllers clearly label them as being
&gt; client related, making their purpose a bit clearer.
&gt;
&gt;     At the moment connection data can only be retrieved via commands like
&gt; netstat, ss, and lsof. However, fetching it via the control port provides
&gt; several advantages:
&gt;
&gt;       - scrubbing for private data
&gt;           Raw connection data has no notion of what's sensitive and what is
&gt; not. The relay's flags and cached consensus can be used to take educated
&gt; guesses concerning which connections could possibly belong to client or exit
&gt; traffic, but this is both difficult and inaccurate.
&gt;
&gt;       - additional information
&gt;           All connection querying commands strictly provide the ip address
&gt; and port of connections, and nothing else. However, for auditing and
&gt; visualization the far more interesting attributes are the connection's
&gt; bandwidth usage, uptime, and the circuit to which it belongs.
&gt;
&gt;       - improved performance
&gt;           Querying connection data is an expensive activity, especially for
&gt; busy relays or low end processors (such as mobile devices). Tor already
&gt; internally knows its circuits and connections, allowing for vastly quicker
&gt; lookups.
&gt;
&gt;       - cross platform capability
&gt;           The connection querying utilities mentioned above not only aren't
&gt; available under Windows, but differ widely among different *nix platforms.
&gt; FreeBSD in particular takes a very unique approach, dropping important
&gt; options from netstat and assigning ss to a spreadsheet application instead.
&gt; A controller interface, however, would provide a uniform means of retrieving
&gt; this information.
&gt;
&gt; Security Implications:
&gt;
&gt;     The original version of this proposal left the responsibility of
&gt; scrubbing connection data with client applications (vidalia, arm, etc).
&gt; However, this was deemed unacceptable by Sebastian and Nick in previous
&gt; discussions. The proposal now includes dropping the ip address/port of
&gt; client and exit connections from the controller's response. That said, I
&gt; think it's a mistake to drop those connections entirely since some of their
&gt; attributes *are* of legitimate usefulness:
&gt;
&gt;     - Existence
&gt;       At the very least it'd be nice if Tor indicated their existence (ie,
&gt; I'd say "yea, an exit connection exists on this circuit but we won't tell
&gt; you where it goes."). This would be useful, for instance, if the relay
&gt; operator has misconfigured their firewall to block some of the outbound
&gt; ports permitted by their exit policy (arm would show this as RELAY -&gt; YOU -&gt;
&gt; UNESTABLISHED, and provide a warning to indicate the issue).
&gt;
&gt;     - Bandwidth
&gt;       For auditing the most interesting attribute of connections, imho, is
&gt; the bandwidth. If, says 10 KB/s is coming in and 1 MB/s is going out on a
&gt; circuit that's a good indicator that something is *very* wrong (I'd start
&gt; suspecting a security issue, personally). If we rounded all bandwidth
&gt; measurements (say, to the nearest KB) would this be sufficient to prevent
&gt; entry/exits from correlating this data to attack anonymity?
&gt;
&gt;     - Uptime
&gt;       If connections are being cycled abnormally quickly (say, all
&gt; connection longevity is under thirty seconds) this could indicate the ISP
&gt; (or other middlemen like the great firewall) are sending reset packets to
&gt; kill the relay's attempts to make exit connections.
&gt;
&gt; Specification:
&gt;
&gt;    The following addition would be made to the control-spec's GETINFO
&gt; section:
&gt;
&gt;   "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the
&gt;     associated connection, formatted as:
&gt;       CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME
&gt;
&gt;     none of the parameters contain whitespace, and additional results must
&gt; be
&gt;     ignored to allow for future expansion. Parameters are defined as
&gt; follows:
&gt;       CONN_ID - Unique identifier associated with this connection.
&gt;       CIRC_ID - Unique identifier for the circuit this belongs to (0 if this
&gt;         doesn't belong to any circuit). At most their may be two connections
&gt;         (one inbound, one outbound) with any given CIRC_ID except in the
&gt; case
&gt;         of exit connections.
&gt;       OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
&gt;       IP/PORT - IP address and port used by the associated connection, 0 if
&gt;         connection is used for relaying client or exit traffic.
&gt;       L_PORT - Local port used by the connection, 0 if connection is used
&gt; for
&gt;         relaying client or exit traffic.
&gt;       TYPE_FLAGS - Single character flags indicating directionality and type
&gt;         of the connection (consists of one from each category, may become
&gt;         longer for future expansion).
&gt;           Connection Directionality:
&gt;             I: inbound, i: listening (unestablished inbound),
&gt;             O: outbound, o: unestablished outbound
&gt;           Usage Type:
&gt;             C: client traffic, R: relaying traffic,
&gt;             X: control, H: hidden service, D: directory
&gt;           Destination:
&gt;             T: inter-tor connection, t: outside the tor network
&gt;         For instance, "IRt" would indicate that this was an established
&gt;         1st-hop (or bridged) relay connection.
&gt;       READ/WRITE - Total bytes read/written over the life of this
&gt; connection.
&gt;       UPTIME - Time the connection's been established in seconds.
&gt;
&gt;   "conn/all" -- Newline separated listing of all current connections.
&gt;
&gt;

</body></email><email><emailId>20100601154746</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-06-01 15:47:46-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

I'll try to follow up to this whole thread and push things forward even more.

On April 14, Damian wrote:
[...]
&gt; Also, could we move forward on the other (less controversial) items? For instance, \
&gt; bandwidth totals tend to be a very highly requested piece of information and pipe's \
&gt; already provided a nice patch to get it \
&gt; (http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html). For reference, \
&gt; here's the not-so-controversial GETINFO options I proposed:

I'm fine with most of these, but the names are no good.  *Everything*
that's returned from GETINFO is "info" after all, so prefixing all of
these with "info" is redundant; they need to be put into a grouping
that actually says what they mean.

The only one I wouldn't want to add as-is the ns/authorities option,
since it says that it uses the v2 directory format.  That format is
obsolescent; we shouldn't be adding new things that use it.  A
non-deprecated format would be fine.

 [...]
&gt; I'm not planning on converting the following to the customary 80-character width \
&gt; until it's at least past being a first draft for a couple reasons:
&gt; 1. I find editing fixed-width documents to be a time consuming pain in the ass.

Maybe use a text editor that will re-wrap paragraphs for you?  There
are dozens of them.

&gt; 2. I've yet to hear why we do this. Is it just to cater to mail clients too dumb to \
&gt; know how to line wrap?

Three reasons off the top of my head.  First: That's the format that
RFCs use.  Second: we like to be able to use diff to compare different
versions of a spec, and making every paragraph a single line makes
diff's output much less useful.  Third: we like to version-control our
specs, and it's a lot easier to resolve conflicts when every paragraph
is not a single line.

There may be more benefits too.


On Fri, Apr 16, 2010 at 3:17 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; Damian Johnson wrote:
&gt; &gt; Yesterday Jake met with me to discuss this proposal, making the very
&gt; &gt; good points that both:
&gt; &gt; 1. It's completely ineffectual for the auditing purposes I've
&gt; &gt; mentioned since either (a) these results can be fetched from netstat
&gt; &gt; already or (b) the information would only be provided via tor and
&gt; &gt; can't be validated.
&gt; &gt; 2. The things I'm really interested in can be fetched with much less
&gt; &gt; (and safer) information.
&gt; 
&gt; I still think that anything that can be used to track circuits (and the
&gt; clients associated with them) is not a good idea - in Tor or using arm.
&gt; We shouldn't encourage people to log, look or otherwise track Tor.
&gt; 
&gt; &gt; 
&gt; &gt; In particular we discussed making the proposal circuit based rather
&gt; &gt; than connection based, being something like the following:
&gt; &gt; 
&gt; &gt; "circ/&lt;Circuit identity&gt;" -- Provides entry for the associated circuit,
&gt; &gt; formatted as:
&gt; &gt; CIRC_ID IN_TYPE OUT_TYPE READ WRITE UPTIME
&gt; &gt; 
&gt; &gt; none of the parameters contain whitespace, and additional results must be
&gt; &gt; ignored to allow for future expansion. Parameters are defined as follows:
&gt; &gt; CIRC_ID - Unique identifier for the circuit this belongs to.
&gt; &gt; IN_TYPE/OUT_TYPE - Single character flags indicating the purpose of the
&gt; &gt; inbound or outbound connection. If no connection is established then
&gt; &gt; this provides an empty string. Otherwise, it consists of one from each
&gt; &gt; of the following categories (this may become longer in future
&gt; &gt; expansion):
&gt; &gt; Usage Type:
&gt; &gt; C: client traffic, R: relaying traffic,
&gt; &gt; X: control, H: hidden service, D: directory
&gt; &gt; Destination:
&gt; &gt; I: inter-tor connection, O: outside the tor network, L: localhost
&gt; &gt; For instance, "RO" would indicate that this was an established
&gt; &gt; 1st-hop (or bridged) relay connection.
&gt; &gt; READ/WRITE - Total bytes read/written over the life of this connection.
&gt; &gt; UPTIME - Time the connection's been established in seconds.

This looks a lot better; I don't see a good way to cause problems with this.

&gt; &gt; "circ/all" -- Newline separated listing of all current circuits.

Do you mean their IDs, or their entries in the format specified above, or what?

 [...]
&gt; &gt; SafeControlPort 0|1
&gt; &gt; Restricts access of the control port to only include read-only operations.
&gt; &gt; (Default: 0)
&gt; &gt; 
&gt; &gt; Making this the default would be a no-go due to vidalia (though still
&gt; &gt; a nice option to have...). If this is implemented its setting should
&gt; &gt; be part of the PROTOCOLINFO response.

I agree with Jake that this probably wants to be another proposal of
its own, and get implemented independently.

&gt; &gt; Finally, the other proposed GETINFO options still seem useful (with
&gt; &gt; the possible exception of "info/uptime-reset"), and could be improved
&gt; &gt; with the addition of:
&gt; &gt; 
&gt; &gt; "info/user" -- User under which the tor process is running, providing an
&gt; &gt; empty string if none exists.
&gt; &gt; 
&gt; 
&gt; You may also want something like the following:
&gt; 
&gt; "info/uid"
&gt; "info/euid"
&gt; "info/gid"
&gt; "info/egid"

Probably a "process-owner" notion is closer to what you want here.
Also remember that it needs to work on Windows. ;)

Also see above caveat on the "info/" prefix.

&gt; &gt; "info/pid" -- Process id belonging to the tor process, -1 if none exists for
&gt; &gt; the platform.
&gt; &gt; 
&gt; &gt; * this one is both useful and surprisingly difficult for me to
&gt; &gt; retrieve at present (arm attempts to get it from pidof, ps, and
&gt; &gt; netstat yet still fails on some systems...)
&gt; 
&gt; The good news is that it's pretty easy to do in C:
&gt; 
&gt; pid_t pid;
&gt; pid = getpid(); // see also getppid();
&gt; printf("PID is: %d\n", pid);

Fine by me, modulo calling it "info".

At this point we're probably ready for another proposal revision, and
a draft patch to implement all of the above. :)

-- 
Nick


</body></email><email><emailId>20100604041031</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-06-04 04:10:31-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Nick, thanks for the feedback!

I'm fine with most of these, but the names are no good.  *Everything*
&gt; that's returned from GETINFO is "info" after all
&gt;

Heh, good point. Changed.

The only one I wouldn't want to add as-is the ns/authorities option,
&gt; since it says that it uses the v2 directory format.
&gt;

I chose the v2 directory format since that's what all the other "ns" entries
use and it seems weird to have this be a black sheep. If this is really a
problem I'm happy to change it, though conformity to the rest of the spec
struck me as being important.

Three reasons off the top of my head.  First: That's the format that
&gt; RFCs use.  Second: we like to be able to use diff to compare different
&gt; versions of a spec, and making every paragraph a single line makes
&gt; diff's output much less useful.  Third: we like to version-control our
&gt; specs, and it's a lot easier to resolve conflicts when every paragraph
&gt; is not a single line.
&gt;

I don't want to dwell on this too much since it's a pretty trivial issue,
but I disagree with points two and three. If you add or remove words, the
rewrapping throws off the diff and version control resolution for any text
following it anyway. That said, "conformity with the other specs, and since
most people here prefer it" strike me as perfectly fine reasons. ;)

Do you mean their IDs, or their entries in the format specified above, or
&gt; what?
&gt;

I was tempted to go with just the IDs, but it seems like the other "/all"
getinfo options provide all the content so going with that to try and fit
in.

Probably a "process-owner" notion is closer to what you want here.
&gt; Also remember that it needs to work on Windows. ;)
&gt;

Yup, that's why the user entry states that an empty string is provided if
none exists. I'm not yet sold on the usefulness of the uid, euid, gid, and
egid but happy to include them if others think it would be handy.

At this point we're probably ready for another proposal revision
&gt;

Your wish is my command! I've split it up into two proposals (see attached),
one concerning the circ options and the other listing the expansion of
relay/process getinfo options. Other changes include:
- added "relay/flags" and "desc/time" getinfo options
- changed the bandwidth entries to be both inbound and outbound (not sure
how it would make sense otherwise...)
- changed the circ results to have a unix timestamp for when the circuit was
created rather than the uptime (more generally useful and avoids the
question of when the results were last updated)

Cheers! -Damian

On Tue, Jun 1, 2010 at 8:47 AM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; I'll try to follow up to this whole thread and push things forward even
&gt; more.
&gt;
&gt; On April 14, Damian wrote:
&gt; [...]
&gt; &gt;Also, could we move forward on the other (less controversial) items? For
&gt; instance, bandwidth totals tend to be a very highly requested piece of
&gt; information and pipe's already provided a nice patch to get it (
&gt; http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html). For
&gt; reference, here's the not-so-controversial GETINFO options I proposed:
&gt;
&gt; I'm fine with most of these, but the names are no good.  *Everything*
&gt; that's returned from GETINFO is "info" after all, so prefixing all of
&gt; these with "info" is redundant; they need to be put into a grouping
&gt; that actually says what they mean.
&gt;
&gt; The only one I wouldn't want to add as-is the ns/authorities option,
&gt; since it says that it uses the v2 directory format.  That format is
&gt; obsolescent; we shouldn't be adding new things that use it.  A
&gt; non-deprecated format would be fine.
&gt;
&gt;  [...]
&gt; &gt;I'm not planning on converting the following to the customary 80-character
&gt; width until it's at
&gt; &gt; least past being a first draft for a couple reasons:
&gt; &gt;1. I find editing fixed-width documents to be a time consuming pain in the
&gt; ass.
&gt;
&gt; Maybe use a text editor that will re-wrap paragraphs for you?  There
&gt; are dozens of them.
&gt;
&gt; &gt; 2. I've yet to hear why we do this. Is it just to cater to mail clients
&gt; too dumb to know how to line wrap?
&gt;
&gt; Three reasons off the top of my head.  First: That's the format that
&gt; RFCs use.  Second: we like to be able to use diff to compare different
&gt; versions of a spec, and making every paragraph a single line makes
&gt; diff's output much less useful.  Third: we like to version-control our
&gt; specs, and it's a lot easier to resolve conflicts when every paragraph
&gt; is not a single line.
&gt;
&gt; There may be more benefits too.
&gt;
&gt;
&gt; On Fri, Apr 16, 2010 at 3:17 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt; wrote:
&gt; &gt; Damian Johnson wrote:
&gt; &gt;&gt; Yesterday Jake met with me to discuss this proposal, making the very
&gt; &gt;&gt; good points that both:
&gt; &gt;&gt;   1. It's completely ineffectual for the auditing purposes I've
&gt; &gt;&gt; mentioned since either (a) these results can be fetched from netstat
&gt; &gt;&gt; already or (b) the information would only be provided via tor and
&gt; &gt;&gt; can't be validated.
&gt; &gt;&gt;   2. The things I'm really interested in can be fetched with much less
&gt; &gt;&gt; (and safer) information.
&gt; &gt;
&gt; &gt; I still think that anything that can be used to track circuits (and the
&gt; &gt; clients associated with them) is not a good idea - in Tor or using arm.
&gt; &gt; We shouldn't encourage people to log, look or otherwise track Tor.
&gt; &gt;
&gt; &gt;&gt;
&gt; &gt;&gt; In particular we discussed making the proposal circuit based rather
&gt; &gt;&gt; than connection based, being something like the following:
&gt; &gt;&gt;
&gt; &gt;&gt;   "circ/&lt;Circuit identity&gt;" -- Provides entry for the associated
&gt; circuit,
&gt; &gt;&gt;     formatted as:
&gt; &gt;&gt;       CIRC_ID IN_TYPE OUT_TYPE READ WRITE UPTIME
&gt; &gt;&gt;
&gt; &gt;&gt;     none of the parameters contain whitespace, and additional results
&gt; must be
&gt; &gt;&gt;     ignored to allow for future expansion. Parameters are defined as
&gt; follows:
&gt; &gt;&gt;       CIRC_ID - Unique identifier for the circuit this belongs to.
&gt; &gt;&gt;       IN_TYPE/OUT_TYPE - Single character flags indicating the purpose
&gt; of the
&gt; &gt;&gt;         inbound or outbound connection. If no connection is established
&gt; then
&gt; &gt;&gt;         this provides an empty string. Otherwise, it consists of one
&gt; from each
&gt; &gt;&gt;         of the following categories (this may become longer in future
&gt; &gt;&gt;         expansion):
&gt; &gt;&gt;           Usage Type:
&gt; &gt;&gt;             C: client traffic, R: relaying traffic,
&gt; &gt;&gt;             X: control, H: hidden service, D: directory
&gt; &gt;&gt;           Destination:
&gt; &gt;&gt;             I: inter-tor connection, O: outside the tor network, L:
&gt; localhost
&gt; &gt;&gt;         For instance, "RO" would indicate that this was an established
&gt; &gt;&gt;         1st-hop (or bridged) relay connection.
&gt; &gt;&gt;       READ/WRITE - Total bytes read/written over the life of this
&gt; connection.
&gt; &gt;&gt;       UPTIME - Time the connection's been established in seconds.
&gt;
&gt; This looks a lot better; I don't see a good way to cause problems with
&gt; this.
&gt;
&gt; &gt;&gt;   "circ/all" -- Newline separated listing of all current circuits.
&gt;
&gt; Do you mean their IDs, or their entries in the format specified above, or
&gt; what?
&gt;
&gt;  [...]
&gt; &gt;&gt;   SafeControlPort 0|1
&gt; &gt;&gt;     Restricts access of the control port to only include read-only
&gt; operations.
&gt; &gt;&gt;     (Default: 0)
&gt; &gt;&gt;
&gt; &gt;&gt; Making this the default would be a no-go due to vidalia (though still
&gt; &gt;&gt; a nice option to have...). If this is implemented its setting should
&gt; &gt;&gt; be part of the PROTOCOLINFO response.
&gt;
&gt; I agree with Jake that this probably wants to be another proposal of
&gt; its own, and get implemented independently.
&gt;
&gt; &gt;&gt; Finally, the other proposed GETINFO options still seem useful (with
&gt; &gt;&gt; the possible exception of "info/uptime-reset"), and could be improved
&gt; &gt;&gt; with the addition of:
&gt; &gt;&gt;
&gt; &gt;&gt;   "info/user" -- User under which the tor process is running, providing
&gt; an
&gt; &gt;&gt;     empty string if none exists.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; You may also want something like the following:
&gt; &gt;
&gt; &gt; "info/uid"
&gt; &gt; "info/euid"
&gt; &gt; "info/gid"
&gt; &gt; "info/egid"
&gt;
&gt; Probably a "process-owner" notion is closer to what you want here.
&gt; Also remember that it needs to work on Windows. ;)
&gt;
&gt; Also see above caveat on the "info/" prefix.
&gt;
&gt; &gt;&gt;   "info/pid" -- Process id belonging to the tor process, -1 if none
&gt; exists for
&gt; &gt;&gt;     the platform.
&gt; &gt;&gt;
&gt; &gt;&gt; * this one is both useful and surprisingly difficult for me to
&gt; &gt;&gt; retrieve at present (arm attempts to get it from pidof, ps, and
&gt; &gt;&gt; netstat yet still fails on some systems...)
&gt; &gt;
&gt; &gt; The good news is that it's pretty easy to do in C:
&gt; &gt;
&gt; &gt;    pid_t pid;
&gt; &gt;    pid = getpid(); // see also getppid();
&gt; &gt;    printf("PID is: %d\n", pid);
&gt;
&gt; Fine by me, modulo calling it "info".
&gt;
&gt; At this point we're probably ready for another proposal revision, and
&gt; a draft patch to implement all of the above. :)
&gt;
&gt; --
&gt; Nick
&gt;

[Attachment #5 (text/html)]

Hi Nick, thanks for the feedback!&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;I'm fine with most of these, but the names are no good.  \
*Everything*&lt;br&gt;



that's returned from GETINFO is "info" after \
all&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Heh, good point. Changed.&lt;br&gt;&lt;br&gt;&lt;blockquote \
style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; \
padding-left: 1ex;" class="gmail_quote"&gt;


The only one I wouldn't want to add as-is the ns/authorities option,&lt;br&gt;
since it says that it uses the v2 directory format.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I chose the \
v2 directory format since that's what all the other "ns" entries use \
and it seems weird to have this be a black sheep. If this is really a problem I'm \
happy to change it, though conformity to the rest of the spec struck me as being \
important.&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;Three reasons off \
the top of my head.  First: That's the format that&lt;br&gt; RFCs use.  Second: we like \
to be able to use diff to compare different&lt;br&gt; versions of a spec, and making every \
paragraph a single line makes&lt;br&gt; diff's output much less useful.  Third: we like \
to version-control our&lt;br&gt; specs, and it's a lot easier to resolve conflicts when \
every paragraph&lt;br&gt; is not a single line.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I don't want to \
dwell on this too much since it's a pretty trivial issue, but I disagree with \
points two and three. If you add or remove words, the rewrapping throws off the diff \
and version control resolution for any text following it anyway. That said, \
"conformity with the other specs, and since most people here prefer it" \
strike me as perfectly fine reasons. ;)&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px \
solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;Do you mean their IDs, or their entries in the format specified \
above, or what?&lt;br&gt;&lt;/blockquote&gt; &lt;br&gt;I was tempted to go with just the IDs, but it \
seems like the other "/all" getinfo options provide all the content so \
going with that to try and fit in.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt; Probably a "process-owner" notion is closer to what \
you want here.&lt;br&gt; Also remember that it needs to work on Windows. \
;)&lt;br&gt;&lt;/blockquote&gt; &lt;br&gt;Yup, that's why the user entry states that an empty \
string is provided if none exists. I'm not yet sold on the usefulness of the uid, \
euid, gid, and egid but happy to include them if others think it would be handy.&lt;br&gt; \
&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;At this point we're probably ready \
for another proposal revision&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt; Your wish is my command! I've \
split it up into two proposals (see attached), one concerning the circ options and \
the other listing the expansion of relay/process getinfo options. Other changes \
include:&lt;br&gt;- added "relay/flags" and "desc/time" getinfo \
                options&lt;br&gt;
- changed the bandwidth entries to be both inbound and outbound (not sure how it \
would make sense otherwise...)&lt;br&gt;- changed the circ results to have a unix timestamp \
for when the circuit was created rather than the uptime (more generally useful and \
avoids the question of when the results were last updated)&lt;br&gt; &lt;br&gt;Cheers! \
-Damian&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Tue, Jun 1, 2010 at 8:47 AM, Nick \
Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:nickm@freehaven.net" \
target="_blank"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;I'll try to follow up to this \
whole thread and push things forward even more.&lt;br&gt; &lt;br&gt;
On April 14, Damian wrote:&lt;br&gt;
[...]&lt;br&gt;
&lt;div&gt;&gt;Also, could we move forward on the other (less controversial) items? For \
instance, bandwidth totals tend to be a very highly requested piece of information \
and pipe's already provided a nice patch to get it (&lt;a \
href="http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html" \
target="_blank"&gt;http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html&lt;/a&gt;). \
For reference, here's the not-so-controversial GETINFO options I proposed:&lt;br&gt;



&lt;br&gt;
&lt;/div&gt;I'm fine with most of these, but the names are no good.  *Everything*&lt;br&gt;
that's returned from GETINFO is "info" after all, so prefixing all \
of&lt;br&gt; these with "info" is redundant; they need to be put into a \
grouping&lt;br&gt; that actually says what they mean.&lt;br&gt;
&lt;br&gt;
The only one I wouldn't want to add as-is the ns/authorities option,&lt;br&gt;
since it says that it uses the v2 directory format.  That format is&lt;br&gt;
obsolescent; we shouldn't be adding new things that use it.  A&lt;br&gt;
non-deprecated format would be fine.&lt;br&gt;
&lt;br&gt;
 [...]&lt;br&gt;
&lt;div&gt;&gt;I'm not planning on converting the following to the customary \
80-character width until it's at&lt;br&gt; &gt; least past being a first draft for a \
couple reasons:&lt;br&gt; &gt;1. I find editing fixed-width documents to be a time \
consuming pain in the ass.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Maybe use a text editor that will re-wrap paragraphs for you?  There&lt;br&gt;
are dozens of them.&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt; 2. I've yet to hear why we do this. Is it just to cater to mail clients too \
dumb to know how to line wrap?&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Three reasons off the top of my head.  First: That's the format that&lt;br&gt;
RFCs use.  Second: we like to be able to use diff to compare different&lt;br&gt;
versions of a spec, and making every paragraph a single line makes&lt;br&gt;
diff's output much less useful.  Third: we like to version-control our&lt;br&gt;
specs, and it's a lot easier to resolve conflicts when every paragraph&lt;br&gt;
is not a single line.&lt;br&gt;
&lt;br&gt;
There may be more benefits too.&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;
&lt;br&gt;
On Fri, Apr 16, 2010 at 3:17 PM, Jacob Appelbaum &lt;&lt;a \
href="mailto:jacob@appelbaum.net" target="_blank"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt; &gt; Damian Johnson wrote:&lt;br&gt;
&gt;&gt; Yesterday Jake met with me to discuss this proposal, making the very&lt;br&gt;
&gt;&gt; good points that both:&lt;br&gt;
&gt;&gt;   1. It's completely ineffectual for the auditing purposes I've&lt;br&gt;
&gt;&gt; mentioned since either (a) these results can be fetched from netstat&lt;br&gt;
&gt;&gt; already or (b) the information would only be provided via tor and&lt;br&gt;
&gt;&gt; can't be validated.&lt;br&gt;
&gt;&gt;   2. The things I'm really interested in can be fetched with much \
less&lt;br&gt; &gt;&gt; (and safer) information.&lt;br&gt;
&gt;&lt;br&gt;
&gt; I still think that anything that can be used to track circuits (and the&lt;br&gt;
&gt; clients associated with them) is not a good idea - in Tor or using arm.&lt;br&gt;
&gt; We shouldn't encourage people to log, look or otherwise track Tor.&lt;br&gt;
&gt;&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; In particular we discussed making the proposal circuit based rather&lt;br&gt;
&gt;&gt; than connection based, being something like the following:&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt;   "circ/&lt;Circuit identity&gt;" -- Provides entry for the \
associated circuit,&lt;br&gt; &gt;&gt;     formatted as:&lt;br&gt;
&gt;&gt;       CIRC_ID IN_TYPE OUT_TYPE READ WRITE UPTIME&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt;     none of the parameters contain whitespace, and additional results must \
be&lt;br&gt; &gt;&gt;     ignored to allow for future expansion. Parameters are defined as \
follows:&lt;br&gt; &gt;&gt;       CIRC_ID - Unique identifier for the circuit this belongs \
to.&lt;br&gt; &gt;&gt;       IN_TYPE/OUT_TYPE - Single character flags indicating the \
purpose of the&lt;br&gt; &gt;&gt;         inbound or outbound connection. If no connection \
is established then&lt;br&gt; &gt;&gt;         this provides an empty string. Otherwise, it \
consists of one from each&lt;br&gt; &gt;&gt;         of the following categories (this may \
become longer in future&lt;br&gt; &gt;&gt;         expansion):&lt;br&gt;
&gt;&gt;           Usage Type:&lt;br&gt;
&gt;&gt;             C: client traffic, R: relaying traffic,&lt;br&gt;
&gt;&gt;             X: control, H: hidden service, D: directory&lt;br&gt;
&gt;&gt;           Destination:&lt;br&gt;
&gt;&gt;             I: inter-tor connection, O: outside the tor network, L: \
localhost&lt;br&gt; &gt;&gt;         For instance, "RO" would indicate that this \
was an established&lt;br&gt; &gt;&gt;         1st-hop (or bridged) relay connection.&lt;br&gt;
&gt;&gt;       READ/WRITE - Total bytes read/written over the life of this \
connection.&lt;br&gt; &gt;&gt;       UPTIME - Time the connection's been established in \
seconds.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;&lt;/div&gt;This looks a lot better; I don't see a good way to cause problems \
with this.&lt;br&gt; &lt;div&gt;&lt;br&gt;
&gt;&gt;   "circ/all" -- Newline separated listing of all current \
circuits.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Do you mean their IDs, or their entries in the format specified above, or \
what?&lt;br&gt; &lt;br&gt;
 [...]&lt;br&gt;
&lt;div&gt;&gt;&gt;   SafeControlPort 0|1&lt;br&gt;
&gt;&gt;     Restricts access of the control port to only include read-only \
operations.&lt;br&gt; &gt;&gt;     (Default: 0)&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Making this the default would be a no-go due to vidalia (though still&lt;br&gt;
&gt;&gt; a nice option to have...). If this is implemented its setting should&lt;br&gt;
&gt;&gt; be part of the PROTOCOLINFO response.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;I agree with Jake that this probably wants to be another proposal of&lt;br&gt;
its own, and get implemented independently.&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt;&gt; Finally, the other proposed GETINFO options still seem useful (with&lt;br&gt;
&gt;&gt; the possible exception of "info/uptime-reset"), and could be \
improved&lt;br&gt; &gt;&gt; with the addition of:&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt;   "info/user" -- User under which the tor process is running, \
providing an&lt;br&gt; &gt;&gt;     empty string if none exists.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; You may also want something like the following:&lt;br&gt;
&gt;&lt;br&gt;
&gt; "info/uid"&lt;br&gt;
&gt; "info/euid"&lt;br&gt;
&gt; "info/gid"&lt;br&gt;
&gt; "info/egid"&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Probably a "process-owner" notion is closer to what you want \
here.&lt;br&gt; Also remember that it needs to work on Windows. ;)&lt;br&gt;
&lt;br&gt;
Also see above caveat on the "info/" prefix.&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt;&gt;   "info/pid" -- Process id belonging to the tor process, -1 if \
none exists for&lt;br&gt; &gt;&gt;     the platform.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; * this one is both useful and surprisingly difficult for me to&lt;br&gt;
&gt;&gt; retrieve at present (arm attempts to get it from pidof, ps, and&lt;br&gt;
&gt;&gt; netstat yet still fails on some systems...)&lt;br&gt;
&gt;&lt;br&gt;
&gt; The good news is that it's pretty easy to do in C:&lt;br&gt;
&gt;&lt;br&gt;
&gt;    pid_t pid;&lt;br&gt;
&gt;    pid = getpid(); // see also getppid();&lt;br&gt;
&gt;    printf("PID is: %d\n", pid);&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Fine by me, modulo calling it "info".&lt;br&gt;
&lt;br&gt;
At this point we're probably ready for another proposal revision, and&lt;br&gt;
a draft patch to implement all of the above. :)&lt;br&gt;
&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--00163630fc2b03ea9f04882c8191--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "circ/&lt;Circuit identity&gt;" -- Provides entry for the associated circuit,
    formatted as:
      CIRC_ID CREATED IN_TYPE IN_READ IN_WRITE OUT_TYPE OUT_READ OUT_WRITE

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique identifier for the circuit this belongs to.
      CREATED - Unix timestamp for when the circuit was created.
      IN_TYPE/OUT_TYPE - Single character flags indicating the purpose of the
        inbound or outbound connection. If no connection is established then
        this provides an empty string. Otherwise, it consists of one from each
        of the following categories (this may become longer in future
        expansion):
          Usage Type:
            C: client traffic, R: relaying traffic,
            X: control, H: hidden service, D: directory
          Destination:
            I: inter-tor connection, O: outside the tor network, L: localhost
        For instance, "RO" would indicate that this was an established
        1st-hop (or bridged) relay connection.
      READ/WRITE - Total bytes read/written over the life of this circuit.

  "circ/all" -- Newline separated listing of all current circuits.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit (currently
    RelayBandwidthRate if set, otherwise BandwidthRate).
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Flags currently held by the relay.
    
    "desc/time" -- Unix timestamp for when the latest server descriptor was
    fetched.
    
    "process/user" -- User under which the tor process is running, providing an
    empty string if none exists.
    
    "process/pid" -- Process id belonging to the tor process, -1 if none exists
    for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup or sighup signal,
    in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.



</body></email><email><emailId>20100623172800</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-06-23 17:28:00-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Fri, Jun 4, 2010 at 12:10 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; Hi Nick, thanks for the feedback!

Hi, Damian!  We're almost there, I think, with just a few points to clarify.

On xxx-circ-getinfo-option.txt:

* The spec addition isn't clear whether we mean all circuits, OR
circuits, or what.  I believe it's "all circuits", but it should say
so.

* IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
"connection."  Do you mean circuits, or connections on the circuits?
Either way I'm confused.  For example, a control connection is never
attached to a circuit at all.

* IN_TYPE/OUT_TYPE are specified as being an empty string if there are
no connections.  That's kind of fragile for parsing, since it would
mean that users could no longer fold multiple spaces into one like
they can for all the other control protocol formats .

* There's nothing specifying that "all" is not a valid identifier, so
"circ/all" is ambiguous. To be consistent with the rest of the getinfo
formats, let's say that the GETINFO key for a single circuit is
circ/id/&lt;circid&gt;, and the GETINFO for all circuits is circ/all.

* You clarified in your email that circ/all is a list of data in the
form given by circ/&lt;ID&gt; , but you didn't make that clarification in
your spec.

* There's no way to get notifications about new OR circuits, so any
program that wants to keep track of OR circuit state will need to
repeatedly poll circ/all.  Won't that be expensive on a busy server?
You wouldn't want to do it, say, once-per-second.  For consistency
with the rest of the controller protocol, OR circuit state changes
would probably want to be some kind of event.


On  xxx-getinfo-option-expansion.txt :

* By "relay/flags", what do you mean?  The flags held by the relay in
the current consensus, or something else?

* On "desc/time", why is it important to know the latest time we
fetched a server descriptor?

* On "desc/time", 'unix timestamp' is ambiguous; do you mean 'a
decimal integer expressing the current time in seconds since the Unix
epoch' or what?  I think the only other places in the control protocol
that express dates do so in ISO8601 format (YYYY-MM-DD HH:MM:SS,
relative to UTC).

* On "process/user", the spec needs to say what you mean by the
"user".  On Unix, is it a UID or a username?  What is it on windows?
The spec needs to say.  (You can't just have the controller tell from
context; on Unix at least, every valid decimal UID is also a valid
username.  If process/user tells me '0', am I running as root, or as a
user named "0"?)

* Also on process/user: If you meant "username", then there  should
indeed be an option to get all the *id stuff discussed upthread.

* Probably the spec needs to clarify that "process/pid" is the pid of
the _main_ Tor process, but that Tor might launch other processes from
time to time and you shouldn't be surprised if it does.

* Is "process/uptime-reset" affected by the SIGNAL command from the
controller?  The spec should  say.

yrs,
-- 
Nick
</body></email><email><emailId>20100624053458</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-06-24 05:34:58-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Nick. Thanks for the comments!

* IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt; Either way I'm confused.  For example, a control connection is never
&gt; attached to a circuit at all.
&gt;

Yea, that isn't really appropriate and was making the spec messier than it
needed to be. Replaced with a single TYPE parameter to indicate the
placement in the circuit (guard/bridge, relay, exit, or one-hop in case
they're allowing them).

This was a bad attempt to shoehorn certain connection information I thought
would be interesting, such as:
- control connections
- client circuits
- directory mirroring
- hidden service hosting

so users could tell the bandwidth usage on these sorts of connections.
However, while interesting this really has nothing to do with acting as a
relay, so dropped. Oh well... maybe in another proposal some day...

Dropped the split from the bandwidth measurements too so they're simpler.
Also, do you think something like this notice...
"These represent logical circuits, not necessarily network resources (which
might be shared between circuits via connection multiplexing)."
would help, or not?

* The spec addition isn't clear whether we mean all circuits, OR
&gt; circuits, or what.  I believe it's "all circuits", but it should say
&gt; so.
&gt;

The "circ/all" entry already said "all current circuits" so I'm guessing you
meant the inclusiveness of "circ/id/*". Added 'relay' to the description,
but I'm not quite sure what sort of clarification you're looking for here.

* IN_TYPE/OUT_TYPE are specified as being an empty string if there are
&gt; no connections.  That's kind of fragile for parsing, since it would
&gt; mean that users could no longer fold multiple spaces into one like
&gt; they can for all the other control protocol formats .
&gt;

No longer relevant with the changes above.

* There's nothing specifying that "all" is not a valid identifier, so
&gt; "circ/all" is ambiguous. To be consistent with the rest of the getinfo
&gt; formats, let's say that the GETINFO key for a single circuit is
&gt; circ/id/&lt;circid&gt;, and the GETINFO for all circuits is circ/all.
&gt;

Good point! Changed. Also specified that the circuit ID is numeric.

* You clarified in your email that circ/all is a list of data in the
&gt; form given by circ/&lt;ID&gt; , but you didn't make that clarification in
&gt; your spec.
&gt;

Changed (not sure about the wording though...).

* There's no way to get notifications about new OR circuits, so any
&gt; program that wants to keep track of OR circuit state will need to
&gt; repeatedly poll circ/all.  Won't that be expensive on a busy server?
&gt; You wouldn't want to do it, say, once-per-second.  For consistency
&gt; with the rest of the controller protocol, OR circuit state changes
&gt; would probably want to be some kind of event.
&gt;

Very good idea! Added an update parameter to entries so staleness can be
tracked. Also added an event for updates to the information.

Now on to the other proposal...

* By "relay/flags", what do you mean?  The flags held by the relay in
&gt; the current consensus, or something else?
&gt;

Yup. Clarified the entry.

* On "desc/time", why is it important to know the latest time we
&gt; fetched a server descriptor?
&gt;

There's some interesting information here such as your relay's observed
bandwidth. However, there's no way of telling how stale information provided
by the "desc/id/*" is, and since most relays stop fetching descriptors after
a time it's often hideously ancient.

What I'd really like an option to manually refresh descriptors (both
individually and as a batch call), however since I was aiming to keep this
proposal limited to GETINFO options it seemed inappropriate. Do you have any
thoughts on this sort of functionality? What section of the control-spec
would it go under?

* On "desc/time", 'unix timestamp' is ambiguous; do you mean 'a
&gt; decimal integer expressing the current time in seconds since the Unix
&gt; epoch' or what?  I think the only other places in the control protocol
&gt; that express dates do so in ISO8601 format (YYYY-MM-DD HH:MM:SS,
&gt; relative to UTC).
&gt;

Ick! Why use that ISO8601 format? Seconds are much simpler and more easily
comparable.

Yes, I meant the decimal integer. Added clarification there and to the other
spec.

* On "process/user", the spec needs to say what you mean by the
&gt; "user".  On Unix, is it a UID or a username?  What is it on windows?
&gt; The spec needs to say.  (You can't just have the controller tell from
&gt; context; on Unix at least, every valid decimal UID is also a valid
&gt; username.  If process/user tells me '0', am I running as root, or as a
&gt; user named "0"?)
&gt;

Specified that it's the username. Doesn't windows xp on up have users now?
If not, it's an empty string.

* Also on process/user: If you meant "username", then there  should
&gt; indeed be an option to get all the *id stuff discussed upthread.
&gt;

I'm sure this is a dumb question but... why? I've never had use for the
numeric uid, let alone the three other varieties Jake mentioned (actually,
never heard of them before...). If you can think of use cases in which
they're useful then by all means include them. However, I don't particularly
care about that information.

... that said, I can see the appeal of including them simply for
completeness.

* Probably the spec needs to clarify that "process/pid" is the pid of
&gt; the _main_ Tor process, but that Tor might launch other processes from
&gt; time to time and you shouldn't be surprised if it does.
&gt;

Done. A pox upon the complexities of identifying the damn process...

* Is "process/uptime-reset" affected by the SIGNAL command from the
&gt; controller?  The spec should  say.
&gt;

Done.

Thanks again! -Damian

On Wed, Jun 23, 2010 at 10:28 AM, Nick Mathewson &lt;nickm@freehaven.net&gt;wrote:

&gt; On Fri, Jun 4, 2010 at 12:10 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; &gt; Hi Nick, thanks for the feedback!
&gt;
&gt; Hi, Damian!  We're almost there, I think, with just a few points to
&gt; clarify.
&gt;
&gt; On xxx-circ-getinfo-option.txt:
&gt;
&gt; * The spec addition isn't clear whether we mean all circuits, OR
&gt; circuits, or what.  I believe it's "all circuits", but it should say
&gt; so.
&gt;
&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt; Either way I'm confused.  For example, a control connection is never
&gt; attached to a circuit at all.
&gt;
&gt; * IN_TYPE/OUT_TYPE are specified as being an empty string if there are
&gt; no connections.  That's kind of fragile for parsing, since it would
&gt; mean that users could no longer fold multiple spaces into one like
&gt; they can for all the other control protocol formats .
&gt;
&gt; * There's nothing specifying that "all" is not a valid identifier, so
&gt; "circ/all" is ambiguous. To be consistent with the rest of the getinfo
&gt; formats, let's say that the GETINFO key for a single circuit is
&gt; circ/id/&lt;circid&gt;, and the GETINFO for all circuits is circ/all.
&gt;
&gt; * You clarified in your email that circ/all is a list of data in the
&gt; form given by circ/&lt;ID&gt; , but you didn't make that clarification in
&gt; your spec.
&gt;
&gt; * There's no way to get notifications about new OR circuits, so any
&gt; program that wants to keep track of OR circuit state will need to
&gt; repeatedly poll circ/all.  Won't that be expensive on a busy server?
&gt; You wouldn't want to do it, say, once-per-second.  For consistency
&gt; with the rest of the controller protocol, OR circuit state changes
&gt; would probably want to be some kind of event.
&gt;
&gt;
&gt; On  xxx-getinfo-option-expansion.txt :
&gt;
&gt; * By "relay/flags", what do you mean?  The flags held by the relay in
&gt; the current consensus, or something else?
&gt;
&gt; * On "desc/time", why is it important to know the latest time we
&gt; fetched a server descriptor?
&gt;
&gt; * On "desc/time", 'unix timestamp' is ambiguous; do you mean 'a
&gt; decimal integer expressing the current time in seconds since the Unix
&gt; epoch' or what?  I think the only other places in the control protocol
&gt; that express dates do so in ISO8601 format (YYYY-MM-DD HH:MM:SS,
&gt; relative to UTC).
&gt;
&gt; * On "process/user", the spec needs to say what you mean by the
&gt; "user".  On Unix, is it a UID or a username?  What is it on windows?
&gt; The spec needs to say.  (You can't just have the controller tell from
&gt; context; on Unix at least, every valid decimal UID is also a valid
&gt; username.  If process/user tells me '0', am I running as root, or as a
&gt; user named "0"?)
&gt;
&gt; * Also on process/user: If you meant "username", then there  should
&gt; indeed be an option to get all the *id stuff discussed upthread.
&gt;
&gt; * Probably the spec needs to clarify that "process/pid" is the pid of
&gt; the _main_ Tor process, but that Tor might launch other processes from
&gt; time to time and you shouldn't be surprised if it does.
&gt;
&gt; * Is "process/uptime-reset" affected by the SIGNAL command from the
&gt; controller?  The spec should  say.
&gt;
&gt; yrs,
&gt; --
&gt; Nick
&gt;

[Attachment #5 (text/html)]

Hi Nick. Thanks for the comments!&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;* IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound&lt;br&gt;

"connection."  Do you mean circuits, or connections on the circuits?&lt;br&gt;
Either way I'm confused.  For example, a control connection is never&lt;br&gt;
attached to a circuit at all.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Yea, that isn't really \
appropriate and was making the spec messier than it needed to be. Replaced with a \
single TYPE parameter to indicate the placement in the circuit (guard/bridge, relay, \
exit, or one-hop in case they're allowing them).&lt;br&gt; &lt;br&gt;This was a bad attempt \
to shoehorn certain connection information I thought would be interesting, such \
as:&lt;br&gt;- control connections&lt;br&gt;- client circuits&lt;br&gt;- directory mirroring&lt;br&gt;

- hidden service hosting&lt;br&gt;&lt;br&gt;so users could tell the bandwidth usage on these \
sorts of connections. However, while interesting this really has nothing to do with \
acting as a relay, so dropped. Oh well... maybe in another proposal some day...&lt;br&gt; \
&lt;br&gt;Dropped the split from the bandwidth measurements too so they're simpler. \
Also, do you think something like this notice...&lt;br&gt;"These represent logical \
circuits, not necessarily network resources (which might be shared between circuits \
via connection multiplexing)."&lt;br&gt; would help, or not?&lt;br&gt;&lt;br&gt;&lt;blockquote \
style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; \
padding-left: 1ex;" class="gmail_quote"&gt;* The spec addition isn't clear whether \
we mean all circuits, OR&lt;br&gt;

circuits, or what.  I believe it's "all circuits", but it should \
say&lt;br&gt; so.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;The "circ/all" entry already said "all \
current circuits" so I'm guessing you meant the inclusiveness of \
"circ/id/*". Added 'relay' to the description, but I'm not \
quite sure what sort of clarification you're looking for here.&lt;br&gt; \
&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
                0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;
* IN_TYPE/OUT_TYPE are specified as being an empty string if there are&lt;br&gt;
no connections.  That's kind of fragile for parsing, since it would&lt;br&gt;
mean that users could no longer fold multiple spaces into one like&lt;br&gt;
they can for all the other control protocol formats .&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;No longer \
relevant with the changes above.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
                class="gmail_quote"&gt;
* There's nothing specifying that "all" is not a valid identifier, \
so&lt;br&gt; "circ/all" is ambiguous. To be consistent with the rest of the \
getinfo&lt;br&gt; formats, let's say that the GETINFO key for a single circuit is&lt;br&gt;
circ/id/&lt;circid&gt;, and the GETINFO for all circuits is \
circ/all.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Good point! Changed. Also specified that the circuit ID \
is numeric.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
                margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;
* You clarified in your email that circ/all is a list of data in the&lt;br&gt;
form given by circ/&lt;ID&gt; , but you didn't make that clarification in&lt;br&gt;
your spec.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Changed (not sure about the wording \
though...).&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;* There's no \
way to get notifications about new OR circuits, so any&lt;br&gt;

program that wants to keep track of OR circuit state will need to&lt;br&gt;
repeatedly poll circ/all.  Won't that be expensive on a busy server?&lt;br&gt;
You wouldn't want to do it, say, once-per-second.  For consistency&lt;br&gt;
with the rest of the controller protocol, OR circuit state changes&lt;br&gt;
would probably want to be some kind of event.&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;Very good idea! Added an update parameter to entries so staleness can be tracked. \
Also added an event for updates to the information.&lt;br&gt;&lt;br&gt;Now on to the other \
proposal...&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;

* By "relay/flags", what do you mean?  The flags held by the relay in&lt;br&gt;
the current consensus, or something else?&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;Yup. Clarified the entry.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;* On "desc/time", why is it important to know the \
latest time we&lt;br&gt;

fetched a server descriptor?&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;There's some interesting information here such as your relay's observed
bandwidth. However, there's no way of telling how stale information provided by \
the "desc/id/*" is, and since most relays stop fetching descriptors after a \
time it's often hideously ancient.&lt;br&gt;&lt;br&gt;What I'd really like an option to \
manually refresh descriptors (both individually and as a batch call), however since I \
was aiming to keep this proposal limited to GETINFO options it seemed inappropriate. \
Do you have any thoughts on this sort of functionality? What section of the \
control-spec would it go under?&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
                class="gmail_quote"&gt;
* On "desc/time", 'unix timestamp' is ambiguous; do you mean \
'a&lt;br&gt; decimal integer expressing the current time in seconds since the Unix&lt;br&gt;
epoch' or what?  I think the only other places in the control protocol&lt;br&gt;
that express dates do so in ISO8601 format (YYYY-MM-DD HH:MM:SS,&lt;br&gt;
relative to UTC).&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;Ick! Why use that ISO8601 format? Seconds are much simpler and more easily \
comparable.&lt;br&gt;&lt;br&gt;Yes, I meant the decimal integer. Added clarification there and to \
the other spec.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
                margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;
* On "process/user", the spec needs to say what you mean by the&lt;br&gt;
"user".  On Unix, is it a UID or a username?  What is it on windows?&lt;br&gt;
The spec needs to say.  (You can't just have the controller tell from&lt;br&gt;
context; on Unix at least, every valid decimal UID is also a valid&lt;br&gt;
username.  If process/user tells me '0', am I running as root, or as a&lt;br&gt;
user named "0"?)&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Specified that it's the username. \
Doesn't windows xp on up have users now? If not, it's an empty \
string.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: \
                0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;
* Also on process/user: If you meant "username", then there  should&lt;br&gt;
indeed be an option to get all the *id stuff discussed \
upthread.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I'm sure this is a dumb question but... why? \
I've never had use for the numeric uid, let alone the three other varieties Jake \
mentioned (actually, never heard of them before...). If you can think of use cases in \
which they're useful then by all means include them. However, I don't \
particularly care about that information.&lt;br&gt; &lt;br&gt;... that said, I can see the appeal \
of including them simply for completeness.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px \
solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
                class="gmail_quote"&gt;
* Probably the spec needs to clarify that "process/pid" is the pid of&lt;br&gt;
the _main_ Tor process, but that Tor might launch other processes from&lt;br&gt;
time to time and you shouldn't be surprised if it does.&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;Done. A pox upon the complexities of identifying the damn \
process...&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;* Is \
"process/uptime-reset" affected by the SIGNAL command from the&lt;br&gt;

controller?  The spec should  say.&lt;br&gt;&lt;/blockquote&gt;
&lt;br&gt;Done.&lt;br&gt;&lt;br&gt;Thanks again! -Damian&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Wed, Jun \
23, 2010 at 10:28 AM, Nick Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt; \
&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;&lt;div class="im"&gt;On Fri, Jun 4, 2010 at \
12:10 AM, Damian Johnson &lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt;

&gt; Hi Nick, thanks for the feedback!&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Hi, Damian!  We're almost there, I think, with just a few points to \
clarify.&lt;br&gt; &lt;br&gt;
On xxx-circ-getinfo-option.txt:&lt;br&gt;
&lt;br&gt;
* The spec addition isn't clear whether we mean all circuits, OR&lt;br&gt;
circuits, or what.  I believe it's "all circuits", but it should \
say&lt;br&gt; so.&lt;br&gt;
&lt;br&gt;
* IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound&lt;br&gt;
"connection."  Do you mean circuits, or connections on the circuits?&lt;br&gt;
Either way I'm confused.  For example, a control connection is never&lt;br&gt;
attached to a circuit at all.&lt;br&gt;
&lt;br&gt;
* IN_TYPE/OUT_TYPE are specified as being an empty string if there are&lt;br&gt;
no connections.  That's kind of fragile for parsing, since it would&lt;br&gt;
mean that users could no longer fold multiple spaces into one like&lt;br&gt;
they can for all the other control protocol formats .&lt;br&gt;
&lt;br&gt;
* There's nothing specifying that "all" is not a valid identifier, \
so&lt;br&gt; "circ/all" is ambiguous. To be consistent with the rest of the \
getinfo&lt;br&gt; formats, let's say that the GETINFO key for a single circuit is&lt;br&gt;
circ/id/&lt;circid&gt;, and the GETINFO for all circuits is circ/all.&lt;br&gt;
&lt;br&gt;
* You clarified in your email that circ/all is a list of data in the&lt;br&gt;
form given by circ/&lt;ID&gt; , but you didn't make that clarification in&lt;br&gt;
your spec.&lt;br&gt;
&lt;br&gt;
* There's no way to get notifications about new OR circuits, so any&lt;br&gt;
program that wants to keep track of OR circuit state will need to&lt;br&gt;
repeatedly poll circ/all.  Won't that be expensive on a busy server?&lt;br&gt;
You wouldn't want to do it, say, once-per-second.  For consistency&lt;br&gt;
with the rest of the controller protocol, OR circuit state changes&lt;br&gt;
would probably want to be some kind of event.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
On  xxx-getinfo-option-expansion.txt :&lt;br&gt;
&lt;br&gt;
* By "relay/flags", what do you mean?  The flags held by the relay in&lt;br&gt;
the current consensus, or something else?&lt;br&gt;
&lt;br&gt;
* On "desc/time", why is it important to know the latest time we&lt;br&gt;
fetched a server descriptor?&lt;br&gt;
&lt;br&gt;
* On "desc/time", 'unix timestamp' is ambiguous; do you mean \
'a&lt;br&gt; decimal integer expressing the current time in seconds since the Unix&lt;br&gt;
epoch' or what?  I think the only other places in the control protocol&lt;br&gt;
that express dates do so in ISO8601 format (YYYY-MM-DD HH:MM:SS,&lt;br&gt;
relative to UTC).&lt;br&gt;
&lt;br&gt;
* On "process/user", the spec needs to say what you mean by the&lt;br&gt;
"user".  On Unix, is it a UID or a username?  What is it on windows?&lt;br&gt;
The spec needs to say.  (You can't just have the controller tell from&lt;br&gt;
context; on Unix at least, every valid decimal UID is also a valid&lt;br&gt;
username.  If process/user tells me '0', am I running as root, or as a&lt;br&gt;
user named "0"?)&lt;br&gt;
&lt;br&gt;
* Also on process/user: If you meant "username", then there  should&lt;br&gt;
indeed be an option to get all the *id stuff discussed upthread.&lt;br&gt;
&lt;br&gt;
* Probably the spec needs to clarify that "process/pid" is the pid of&lt;br&gt;
the _main_ Tor process, but that Tor might launch other processes from&lt;br&gt;
time to time and you shouldn't be surprised if it does.&lt;br&gt;
&lt;br&gt;
* Is "process/uptime-reset" affected by the SIGNAL command from the&lt;br&gt;
controller?  The spec should  say.&lt;br&gt;
&lt;br&gt;
yrs,&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--0016e68ee003d8cdb00489c00327--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "circ/id/&lt;Circuit identity&gt;" -- Provides entry for the associated relay
    circuit, formatted as:
      CIRC_ID CREATED UPDATED TYPE READ WRITE

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique numeric identifier for the circuit this belongs to.
      CREATED - Unix timestamp (as seconds since the Epoch) for when the
          circuit was created.
      UPDATED - Unix timestamp for when this information was last updated.
      TYPE - Single character flag indicating the positioning in the circuit:
          C: client facing (first hop / bridge)
          M: intermediate
          E: exiting
          B: both client facing and exiting
      READ - Total bytes transmitted toward the exit over the circuit.
      WRITE - Total bytes transmitted toward the client over the circuit.

  "circ/all" -- The 'circ/id/*' output for all current circuits, joined by
    newlines.

   The following would be included for circ info update events.

4.1.X. Relay circuit status changed

  The syntax is:
     "650" SP "RCIRC" SP CircID SP Notice [SP Created SP Updated SP Type SP
          Read SP Write] CRLF
     
     Notice =
            "NEW"    / ; first information being provided for this circuit
            "UPDATE" / ; update for a previously reported circuit
            "CLOSED"   ; notice that the circuit no longer exists
    
  Notice indicating that queryable information on a relay related circuit has
  changed. If the Notice parameter is either "NEW" or "UPDATE" then this
  provides the same fields that would be given by calling "GETINFO circ/id/"
  with the CircID.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit.
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Space separated listing of flags currently held by the
    relay as repored by the currently cached consensus.
    
    "desc/time" -- Unix timestamp (as seconds since the Epoch) for when the
    latest server descriptor was fetched.
    
    "process/user" -- Username under which the tor process is running,
    providing an empty string if none exists.
    
    "process/pid" -- Process id belonging to the main tor process, -1 if none
    exists for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup, sighup, or RELOAD
    signal, in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.



</body></email><email><emailId>20100628215907</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-06-28 21:59:07-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; Hi Nick. Thanks for the comments!
&gt;
&gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt;&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt;&gt; Either way I'm confused.  For example, a control connection is never
&gt;&gt; attached to a circuit at all.
&gt;
&gt; Yea, that isn't really appropriate and was making the spec messier than it
&gt; needed to be. Replaced with a single TYPE parameter to indicate the
&gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in case
&gt; they're allowing them).

Hm.  But we don't necessarily know this.  Our "are we client-facing"
tests are approximate, not certain, and the only way to tell whether
we're intermediate or exiting is to wait and see if we're told to
exit.  In fact, the leaky-pipe topology means that we're potentially
intermediate _and_ exiting on a single circuit.

Also, it's still a tiny bit ambiguous: some people consider a circuit
used for a rendezvous point as an exit, and some don't.

The only other change I'd suggest to xxx-circ-getinfo-option.txt is to
consider using named parameters (like "WRITE=9090") rather than
positional parameters ('The third value is the write one').  This has
turned out to make it way easier to expand events in the future.
(Consider what would happen if we wanted to add another field to
RCIRC.)

Also, maybe rename the "circ" GETINFO to "rcirc" for consistency?

On xxx-getinfo-option-expansion.txt :

&gt;&gt; * On "desc/time", why is it important to know the latest time we
&gt;&gt; fetched a server descriptor?
&gt;
&gt; There's some interesting information here such as your relay's observed
&gt; bandwidth. However, there's no way of telling how stale information provided
&gt; by the "desc/id/*" is, and since most relays stop fetching descriptors after
&gt; a time it's often hideously ancient.

There totally is a way to tell how old a descriptor is: you just look
at the "published" field on the descriptor, and that tells you when it
was first uploaded to the authorities.

If it's important to tell when you _fetched_ the descriptor (as
opposed to when it was first published), we do store that information,
but it should be made available on a per-descriptor basis, right?
That would be more useful.

&gt; What I'd really like an option to manually refresh descriptors (both
&gt; individually and as a batch call), however since I was aiming to keep this
&gt; proposal limited to GETINFO options it seemed inappropriate. Do you have any
&gt; thoughts on this sort of functionality? What section of the control-spec
&gt; would it go under?

It sounds like it should be a torrc option saying "Don't stop
refetching descriptors when there's no network activity."  Actually,
do we have one of those already?

&gt;&gt; * Also on process/user: If you meant "username", then there  should
&gt;&gt; indeed be an option to get all the *id stuff discussed upthread.
&gt;
&gt; I'm sure this is a dumb question but... why? I've never had use for the
&gt; numeric uid, let alone the three other varieties Jake mentioned (actually,
&gt; never heard of them before...). If you can think of use cases in which
&gt; they're useful then by all means include them. However, I don't particularly
&gt; care about that information.

For unixy programs, it's way easier to work with uids than with
usernames.  The other varieties are useful for telling you about Tor's
setuid/setgid state.

Other than that, looks good.
-- 
Nick

</body></email><email><emailId>20100628220813</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2010-06-28 22:08:13-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Mon, Jun 28, 2010 at 05:59:07PM -0400, Nick Mathewson wrote:
&gt; On Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; &gt; Hi Nick. Thanks for the comments!
&gt; &gt;
&gt; &gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt; &gt;&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt; &gt;&gt; Either way I'm confused.  For example, a control connection is never
&gt; &gt;&gt; attached to a circuit at all.
&gt; &gt;
&gt; &gt; Yea, that isn't really appropriate and was making the spec messier than it
&gt; &gt; needed to be. Replaced with a single TYPE parameter to indicate the
&gt; &gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in case
&gt; &gt; they're allowing them).
&gt; 
&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt; tests are approximate, not certain, and the only way to tell whether
&gt; we're intermediate or exiting is to wait and see if we're told to
&gt; exit.  In fact, the leaky-pipe topology means that we're potentially
&gt; intermediate _and_ exiting on a single circuit.

Wah. I know I'm well out of the development loop, but is leaky-pipe
topology ever currently used and if so for what?
</body></email><email><emailId>20100629150010</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-06-29 15:00:10-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


&gt;
&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt; tests are approximate, not certain, and the only way to tell whether
&gt; we're intermediate or exiting is to wait and see if we're told to
&gt; exit.
&gt;

Understood that client facing tests fail by design when dealing with
bridges. In the case of the outbound connection component it sounds like
we'll need to wait until we're either asked to extend the circuit or exit
before counting it as an 'established circuit' and reporting it.

In fact, the leaky-pipe topology means that we're potentially
&gt; intermediate _and_ exiting on a single circuit.
&gt;

(to save other readers the googling, this means that clients can exit the
circuit prematurely, such as at a middle node if the exit policy permits it)

You're right, that would mess with the classification. If/when this is
implemented I'd suggest adding anther classification for middle hops when
they're first used to exit traffic.

The goal of these type flags are to indicate to controllers which circuits
are sensitive and which are less so. In arm for instance most information
for client/exit connections are scrubbed. Indicating via a change of the
circuits status (an UPDATE event) when this begins exiting traffic seems
good enough to me.

Also, it's still a tiny bit ambiguous: some people consider a circuit
&gt; used for a rendezvous point as an exit, and some don't.
&gt;

Not following what you mean here... do you mean a hidden service rendezvous?
If so then I don't see how this is exiting. Maybe the previous type
classifications that simply said whether or not the inbound/outbound
connection lies inside the tor network was clearer...

The only other change I'd suggest to xxx-circ-getinfo-option.txt is to
&gt; consider using named parameters (like "WRITE=9090") rather than
&gt; positional parameters
&gt;

Good idea, done (though I didn't find a good example of the preferred syntax
for this).

Also, maybe rename the "circ" GETINFO to "rcirc" for consistency?
&gt;

Done (pity the CIRC event had already been used...).

There totally is a way to tell how old a descriptor is: you just look
&gt; at the "published" field on the descriptor, and that tells you when it
&gt; was first uploaded to the authorities.
&gt;

Sweet! Didn't realise this was available. Dropped from proposal.

It sounds like it should be a torrc option saying "Don't stop
&gt; refetching descriptors when there's no network activity."  Actually,
&gt; do we have one of those already?
&gt;

Yup, we have FetchUselessDescriptors. However, setting this causes an extra
load on the directory authorities, hence the desire to be able to do this a
bit more selectively (for instance just fetching our own descriptor every
hour but letting the rest go stale).

Cheers! -Damian

On Mon, Jun 28, 2010 at 2:59 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; &gt; Hi Nick. Thanks for the comments!
&gt; &gt;
&gt; &gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt; &gt;&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt; &gt;&gt; Either way I'm confused.  For example, a control connection is never
&gt; &gt;&gt; attached to a circuit at all.
&gt; &gt;
&gt; &gt; Yea, that isn't really appropriate and was making the spec messier than
&gt; it
&gt; &gt; needed to be. Replaced with a single TYPE parameter to indicate the
&gt; &gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in case
&gt; &gt; they're allowing them).
&gt;
&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt; tests are approximate, not certain, and the only way to tell whether
&gt; we're intermediate or exiting is to wait and see if we're told to
&gt; exit.  In fact, the leaky-pipe topology means that we're potentially
&gt; intermediate _and_ exiting on a single circuit.
&gt;
&gt; Also, it's still a tiny bit ambiguous: some people consider a circuit
&gt; used for a rendezvous point as an exit, and some don't.
&gt;
&gt; The only other change I'd suggest to xxx-circ-getinfo-option.txt is to
&gt; consider using named parameters (like "WRITE=9090") rather than
&gt; positional parameters ('The third value is the write one').  This has
&gt; turned out to make it way easier to expand events in the future.
&gt; (Consider what would happen if we wanted to add another field to
&gt; RCIRC.)
&gt;
&gt; Also, maybe rename the "circ" GETINFO to "rcirc" for consistency?
&gt;
&gt; On xxx-getinfo-option-expansion.txt :
&gt;
&gt; &gt;&gt; * On "desc/time", why is it important to know the latest time we
&gt; &gt;&gt; fetched a server descriptor?
&gt; &gt;
&gt; &gt; There's some interesting information here such as your relay's observed
&gt; &gt; bandwidth. However, there's no way of telling how stale information
&gt; provided
&gt; &gt; by the "desc/id/*" is, and since most relays stop fetching descriptors
&gt; after
&gt; &gt; a time it's often hideously ancient.
&gt;
&gt; There totally is a way to tell how old a descriptor is: you just look
&gt; at the "published" field on the descriptor, and that tells you when it
&gt; was first uploaded to the authorities.
&gt;
&gt; If it's important to tell when you _fetched_ the descriptor (as
&gt; opposed to when it was first published), we do store that information,
&gt; but it should be made available on a per-descriptor basis, right?
&gt; That would be more useful.
&gt;
&gt; &gt; What I'd really like an option to manually refresh descriptors (both
&gt; &gt; individually and as a batch call), however since I was aiming to keep
&gt; this
&gt; &gt; proposal limited to GETINFO options it seemed inappropriate. Do you have
&gt; any
&gt; &gt; thoughts on this sort of functionality? What section of the control-spec
&gt; &gt; would it go under?
&gt;
&gt; It sounds like it should be a torrc option saying "Don't stop
&gt; refetching descriptors when there's no network activity."  Actually,
&gt; do we have one of those already?
&gt;
&gt; &gt;&gt; * Also on process/user: If you meant "username", then there  should
&gt; &gt;&gt; indeed be an option to get all the *id stuff discussed upthread.
&gt; &gt;
&gt; &gt; I'm sure this is a dumb question but... why? I've never had use for the
&gt; &gt; numeric uid, let alone the three other varieties Jake mentioned
&gt; (actually,
&gt; &gt; never heard of them before...). If you can think of use cases in which
&gt; &gt; they're useful then by all means include them. However, I don't
&gt; particularly
&gt; &gt; care about that information.
&gt;
&gt; For unixy programs, it's way easier to work with uids than with
&gt; usernames.  The other varieties are useful for telling you about Tor's
&gt; setuid/setgid state.
&gt;
&gt; Other than that, looks good.
&gt; --
&gt; Nick
&gt;

[Attachment #5 (text/html)]

&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;Hm.  But we don't necessarily know \
this.  Our "are we client-facing"&lt;br&gt; tests are approximate, not certain, \
and the only way to tell whether&lt;br&gt; we're intermediate or exiting is to wait and \
see if we're told to&lt;br&gt; exit.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Understood that client facing \
tests fail by design when dealing with bridges. In the case of the outbound \
connection component it sounds like we'll need to wait until we're either \
asked to extend the circuit or exit before counting it as an 'established \
circuit' and reporting it.&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px solid \
rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;In fact, the leaky-pipe topology means that we're \
potentially&lt;br&gt;

intermediate _and_ exiting on a single circuit.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;(to save other \
readers the googling, this means that clients can exit the circuit prematurely, such \
as at a middle node if the exit policy permits it)&lt;br&gt; &lt;br&gt;You're right, that \
would mess with the classification. If/when this is implemented I'd suggest \
adding anther classification for middle hops when they're first used to exit \
traffic.&lt;br&gt;&lt;br&gt;The goal of these type flags are to indicate to controllers which \
circuits are sensitive and which are less so. In arm for instance most information \
for client/exit connections are scrubbed. Indicating via a change of the circuits \
status (an UPDATE event) when this begins exiting traffic seems good enough to \
me.&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt \
0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt; Also, it's still a tiny \
bit ambiguous: some people consider a circuit&lt;br&gt; used for a rendezvous point as an \
exit, and some don't.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Not following what you mean here... do \
you mean a hidden service rendezvous? If so then I don't see how this is exiting. \
Maybe the previous type classifications that simply said whether or not the \
inbound/outbound connection lies inside the tor network was clearer...&lt;br&gt; \
&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;The only other change I'd suggest \
to xxx-circ-getinfo-option.txt is to&lt;br&gt; consider using named parameters (like \
"WRITE=9090") rather than&lt;br&gt; positional \
parameters&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Good idea, done (though I didn't find a good \
example of the preferred syntax for this).&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px \
solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt; Also, maybe rename the "circ" GETINFO to \
"rcirc" for consistency?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Done (pity the CIRC event had \
already been used...).&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt; There \
totally is a way to tell how old a descriptor is: you just look&lt;br&gt; at the \
"published" field on the descriptor, and that tells you when it&lt;br&gt; was \
first uploaded to the authorities.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Sweet! Didn't realise this \
was available. Dropped from proposal.&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px \
solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt; It sounds like it should be a torrc option saying \
"Don't stop&lt;br&gt; refetching descriptors when there's no network \
activity."  Actually,&lt;br&gt; do we have one of those \
already?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Yup, we have FetchUselessDescriptors. However, setting \
this causes an extra load on the directory authorities, hence the desire to be able \
to do this a bit more selectively (for instance just fetching our own descriptor \
every hour but letting the rest go stale).&lt;br&gt; &lt;br&gt;Cheers! -Damian&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Mon, Jun 28, 2010 at 2:59 PM, Nick Mathewson &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt; &lt;div class="im"&gt;On Thu, Jun 24, \
2010 at 1:34 AM, Damian Johnson &lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; Hi Nick. \
Thanks for the comments!&lt;br&gt; &gt;&lt;br&gt;
&gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound&lt;br&gt;
&gt;&gt; "connection."  Do you mean circuits, or connections on the \
circuits?&lt;br&gt; &gt;&gt; Either way I'm confused.  For example, a control \
connection is never&lt;br&gt; &gt;&gt; attached to a circuit at all.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Yea, that isn't really appropriate and was making the spec messier than \
it&lt;br&gt; &gt; needed to be. Replaced with a single TYPE parameter to indicate the&lt;br&gt;
&gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in case&lt;br&gt;
&gt; they're allowing them).&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Hm.  But we don't necessarily know this.  Our "are we \
client-facing"&lt;br&gt; tests are approximate, not certain, and the only way to tell \
whether&lt;br&gt; we're intermediate or exiting is to wait and see if we're told \
to&lt;br&gt; exit.  In fact, the leaky-pipe topology means that we're potentially&lt;br&gt;
intermediate _and_ exiting on a single circuit.&lt;br&gt;
&lt;br&gt;
Also, it's still a tiny bit ambiguous: some people consider a circuit&lt;br&gt;
used for a rendezvous point as an exit, and some don't.&lt;br&gt;
&lt;br&gt;
The only other change I'd suggest to xxx-circ-getinfo-option.txt is to&lt;br&gt;
consider using named parameters (like "WRITE=9090") rather than&lt;br&gt;
positional parameters ('The third value is the write one').  This has&lt;br&gt;
turned out to make it way easier to expand events in the future.&lt;br&gt;
(Consider what would happen if we wanted to add another field to&lt;br&gt;
RCIRC.)&lt;br&gt;
&lt;br&gt;
Also, maybe rename the "circ" GETINFO to "rcirc" for \
consistency?&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;
On xxx-getinfo-option-expansion.txt :&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;div class="im"&gt;&gt;&gt; * On "desc/time", why is it important to \
know the latest time we&lt;br&gt; &gt;&gt; fetched a server descriptor?&lt;br&gt;
&gt;&lt;br&gt;
&gt; There's some interesting information here such as your relay's \
observed&lt;br&gt; &gt; bandwidth. However, there's no way of telling how stale \
information provided&lt;br&gt; &gt; by the "desc/id/*" is, and since most relays \
stop fetching descriptors after&lt;br&gt; &gt; a time it's often hideously ancient.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;There totally is a way to tell how old a descriptor is: you just look&lt;br&gt;
at the "published" field on the descriptor, and that tells you when it&lt;br&gt;
was first uploaded to the authorities.&lt;br&gt;
&lt;br&gt;
If it's important to tell when you _fetched_ the descriptor (as&lt;br&gt;
opposed to when it was first published), we do store that information,&lt;br&gt;
but it should be made available on a per-descriptor basis, right?&lt;br&gt;
That would be more useful.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;
&gt; What I'd really like an option to manually refresh descriptors (both&lt;br&gt;
&gt; individually and as a batch call), however since I was aiming to keep this&lt;br&gt;
&gt; proposal limited to GETINFO options it seemed inappropriate. Do you have any&lt;br&gt;
&gt; thoughts on this sort of functionality? What section of the control-spec&lt;br&gt;
&gt; would it go under?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;It sounds like it should be a torrc option saying "Don't stop&lt;br&gt;
refetching descriptors when there's no network activity."  Actually,&lt;br&gt;
do we have one of those already?&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;
&gt;&gt; * Also on process/user: If you meant "username", then there  \
should&lt;br&gt; &gt;&gt; indeed be an option to get all the *id stuff discussed \
upthread.&lt;br&gt; &gt;&lt;br&gt;
&gt; I'm sure this is a dumb question but... why? I've never had use for \
the&lt;br&gt; &gt; numeric uid, let alone the three other varieties Jake mentioned \
(actually,&lt;br&gt; &gt; never heard of them before...). If you can think of use cases in \
which&lt;br&gt; &gt; they're useful then by all means include them. However, I \
don't particularly&lt;br&gt; &gt; care about that information.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;For unixy programs, it's way easier to work with uids than with&lt;br&gt;
usernames.  The other varieties are useful for telling you about Tor's&lt;br&gt;
setuid/setgid state.&lt;br&gt;
&lt;br&gt;
Other than that, looks good.&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--0016e6470d0c65c54b048a2c7e1b--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "rcirc/id/&lt;Circuit identity&gt;" -- Provides entry for the associated relay
    circuit, formatted as:
      CIRC_ID=&lt;circuit ID&gt; CREATED=&lt;timestamp&gt; UPDATED=&lt;timestamp&gt; TYPE=&lt;flag&gt;
        READ=&lt;bytes&gt; WRITE=&lt;bytes&gt;

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique numeric identifier for the circuit this belongs to.
      CREATED - Unix timestamp (as seconds since the Epoch) for when the
          circuit was created.
      UPDATED - Unix timestamp for when this information was last updated.
      TYPE - Single character flag indicating the positioning in the circuit:
          C: client facing (first hop / bridge)
          M: intermediate
          E: exiting
          B: both client facing and exiting
      READ - Total bytes transmitted toward the exit over the circuit.
      WRITE - Total bytes transmitted toward the client over the circuit.

  "rcirc/all" -- The 'rcirc/id/*' output for all current circuits, joined by
    newlines.

   The following would be included for circ info update events.

4.1.X. Relay circuit status changed

  The syntax is:
     "650" SP "RCIRC" SP CircID SP Notice [SP Created SP Updated SP Type SP
          Read SP Write] CRLF
     
     Notice =
            "NEW"    / ; first information being provided for this circuit
            "UPDATE" / ; update for a previously reported circuit
            "CLOSED"   ; notice that the circuit no longer exists
    
  Notice indicating that queryable information on a relay related circuit has
  changed. If the Notice parameter is either "NEW" or "UPDATE" then this
  provides the same fields that would be given by calling "GETINFO rcirc/id/"
  with the CircID.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit.
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Space separated listing of flags currently held by the
    relay as repored by the currently cached consensus.
    
    "process/user" -- Username under which the tor process is running,
    providing an empty string if none exists.
    
    "process/pid" -- Process id belonging to the main tor process, -1 if none
    exists for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup, sighup, or RELOAD
    signal, in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.



</body></email><email><emailId>20100709052334</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-07-09 05:23:34-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


Made a couple small additions to the 'xxx-getinfo-option-expansion' proposal
for getting Tor's state and the keys used in the mappings. Thanks to Roger
for the suggestion (he also opened a
ticket&lt;https://trac.torproject.org/projects/tor/ticket/1680&gt;to track
this). Cheers! -Damian

On Tue, Jun 29, 2010 at 8:01 AM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Mon, Jun 28, 2010 at 6:08 PM, Paul Syverson
&gt; &lt;syverson@itd.nrl.navy.mil&gt; wrote:
&gt; &gt; On Mon, Jun 28, 2010 at 05:59:07PM -0400, Nick Mathewson wrote:
&gt; &gt;&gt; On Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;atagar1@gmail.com&gt;
&gt; wrote:
&gt; &gt;&gt; &gt; Hi Nick. Thanks for the comments!
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt; &gt;&gt; &gt;&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt; &gt;&gt; &gt;&gt; Either way I'm confused.  For example, a control connection is never
&gt; &gt;&gt; &gt;&gt; attached to a circuit at all.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; Yea, that isn't really appropriate and was making the spec messier
&gt; than it
&gt; &gt;&gt; &gt; needed to be. Replaced with a single TYPE parameter to indicate the
&gt; &gt;&gt; &gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in
&gt; case
&gt; &gt;&gt; &gt; they're allowing them).
&gt; &gt;&gt;
&gt; &gt;&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt; &gt;&gt; tests are approximate, not certain, and the only way to tell whether
&gt; &gt;&gt; we're intermediate or exiting is to wait and see if we're told to
&gt; &gt;&gt; exit.  In fact, the leaky-pipe topology means that we're potentially
&gt; &gt;&gt; intermediate _and_ exiting on a single circuit.
&gt; &gt;
&gt; &gt; Wah. I know I'm well out of the development loop, but is leaky-pipe
&gt; &gt; topology ever currently used and if so for what?
&gt;
&gt; Well, I said "potentially". ;) The servers support it, but I don't
&gt; believe we use it.  If we did, it would probably be for fetching
&gt; directory info from a guard that happens also to be a cache, or
&gt; something like that.
&gt;
&gt; --
&gt; Nick
&gt;

[Attachment #5 (text/html)]

Made a couple small additions to the 'xxx-getinfo-option-expansion' proposal \
for getting Tor's state and the keys used in the mappings. Thanks to Roger for \
the suggestion (he also &lt;a \
href="https://trac.torproject.org/projects/tor/ticket/1680"&gt;opened a ticket&lt;/a&gt; to \
track this). Cheers! -Damian&lt;br&gt; &lt;br&gt;&lt;div class="gmail_quote"&gt;On Tue, Jun 29, 2010 at \
8:01 AM, Nick Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;On Mon, Jun 28, 2010 at 6:08 PM, Paul Syverson&lt;br&gt; &lt;&lt;a \
href="mailto:syverson@itd.nrl.navy.mil"&gt;syverson@itd.nrl.navy.mil&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt; On Mon, Jun 28, 2010 at 05:59:07PM -0400, Nick Mathewson wrote:&lt;br&gt; &gt;&gt; On \
Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt;&gt; &gt; Hi \
Nick. Thanks for the comments!&lt;br&gt; &gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound&lt;br&gt;
&gt;&gt; &gt;&gt; "connection."  Do you mean circuits, or connections on \
the circuits?&lt;br&gt; &gt;&gt; &gt;&gt; Either way I'm confused.  For example, a \
control connection is never&lt;br&gt; &gt;&gt; &gt;&gt; attached to a circuit at all.&lt;br&gt;
&gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt; Yea, that isn't really appropriate and was making the spec messier \
than it&lt;br&gt; &gt;&gt; &gt; needed to be. Replaced with a single TYPE parameter to \
indicate the&lt;br&gt; &gt;&gt; &gt; placement in the circuit (guard/bridge, relay, exit, \
or one-hop in case&lt;br&gt; &gt;&gt; &gt; they're allowing them).&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Hm.  But we don't necessarily know this.  Our "are we \
client-facing"&lt;br&gt; &gt;&gt; tests are approximate, not certain, and the only way \
to tell whether&lt;br&gt; &gt;&gt; we're intermediate or exiting is to wait and see if \
we're told to&lt;br&gt; &gt;&gt; exit.  In fact, the leaky-pipe topology means that \
we're potentially&lt;br&gt; &gt;&gt; intermediate _and_ exiting on a single \
circuit.&lt;br&gt; &gt;&lt;br&gt;
&gt; Wah. I know I'm well out of the development loop, but is leaky-pipe&lt;br&gt;
&gt; topology ever currently used and if so for what?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;Well, I said "potentially". ;) The servers support it, but I \
don't&lt;br&gt; believe we use it.  If we did, it would probably be for fetching&lt;br&gt;
directory info from a guard that happens also to be a cache, or&lt;br&gt;
something like that.&lt;br&gt;
&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--e0cb4e887583bc4c31048aed9aed--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "rcirc/id/&lt;Circuit identity&gt;" -- Provides entry for the associated relay
    circuit, formatted as:
      CIRC_ID=&lt;circuit ID&gt; CREATED=&lt;timestamp&gt; UPDATED=&lt;timestamp&gt; TYPE=&lt;flag&gt;
        READ=&lt;bytes&gt; WRITE=&lt;bytes&gt;

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique numeric identifier for the circuit this belongs to.
      CREATED - Unix timestamp (as seconds since the Epoch) for when the
          circuit was created.
      UPDATED - Unix timestamp for when this information was last updated.
      TYPE - Single character flag indicating the positioning in the circuit:
          C: client facing (first hop / bridge)
          M: intermediate
          E: exiting
          B: both client facing and exiting
      READ - Total bytes transmitted toward the exit over the circuit.
      WRITE - Total bytes transmitted toward the client over the circuit.

  "rcirc/all" -- The 'rcirc/id/*' output for all current circuits, joined by
    newlines.

   The following would be included for circ info update events.

4.1.X. Relay circuit status changed

  The syntax is:
     "650" SP "RCIRC" SP CircID SP Notice [SP Created SP Updated SP Type SP
          Read SP Write] CRLF
     
     Notice =
            "NEW"    / ; first information being provided for this circuit
            "UPDATE" / ; update for a previously reported circuit
            "CLOSED"   ; notice that the circuit no longer exists
    
  Notice indicating that queryable information on a relay related circuit has
  changed. If the Notice parameter is either "NEW" or "UPDATE" then this
  provides the same fields that would be given by calling "GETINFO rcirc/id/"
  with the CircID.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit.
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Space separated listing of flags currently held by the
    relay as repored by the currently cached consensus.
    
    "process/user" -- Username under which the tor process is running,
    providing an empty string if none exists.
    
    "process/pid" -- Process id belonging to the main tor process, -1 if none
    exists for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup, sighup, or RELOAD
    signal, in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.
    
    "state/names" -- A space-separated list of all the keys supported by this
    version of Tor's state.
    
    "state/val/&lt;key&gt;" -- Provides the current state value belonging to the
    given key. If undefined, this provides the key's default value.



</body></email><email><emailId>20100710013859</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-07-10 01:38:59-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Tue, Jun 29, 2010 at 11:00 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt;&gt; tests are approximate, not certain, and the only way to tell whether
&gt;&gt; we're intermediate or exiting is to wait and see if we're told to
&gt;&gt; exit.
&gt;
&gt; Understood that client facing tests fail by design when dealing with
&gt; bridges. In the case of the outbound connection component it sounds like
&gt; we'll need to wait until we're either asked to extend the circuit or exit
&gt; before counting it as an 'established circuit' and reporting it.

Or we could drop the false notion that "middle" or "exit" or "entry"
make a partition of established relay or_circuits.   (They aren't a
partition because: first, they don't cover or_circuits.  A circuit
that has been just extended to us can't be called a middle or an exit.
 Second, they aren't exclusive: a circuit that has been extended from
us and used as an exit can be called both a middle _and_ an exit.)
See below for another possibility.

&gt;&gt; In fact, the leaky-pipe topology means that we're potentially
&gt;&gt; intermediate _and_ exiting on a single circuit.
&gt;
&gt; (to save other readers the googling, this means that clients can exit the
&gt; circuit prematurely, such as at a middle node if the exit policy permits it)
&gt;
&gt; You're right, that would mess with the classification. If/when this is
&gt; implemented I'd suggest adding anther classification for middle hops when
&gt; they're first used to exit traffic.

It *IS* implemented server-side.  The clients just don't use it.

(Since the point of this design is to safely expose accurate circuit
status info via the control port, we might as well try to expose the
possible states of current circuits, including states that don't
typically occur.  Otherwise, if some future weird client started using
them, you'd need to upgrade Tor *and* arm to get an accurate report.)

&gt; The goal of these type flags are to indicate to controllers which circuits
&gt; are sensitive and which are less so. In arm for instance most information
&gt; for client/exit connections are scrubbed. Indicating via a change of the
&gt; circuits status (an UPDATE event) when this begins exiting traffic seems
&gt; good enough to me.

Here's an alternate proposal.  The idea of type flags is good, but
instead of the ones in your proposal, let's only use circuit type
flags that have an unambiguous meaning from the point of view of Tor's
spec and implementation.

For instance,
   (E)ntry : a connection from a node that doesn't appear to be a Tor server.
   E(X)it : has been used for at least one exit stream
   (R)elay : has been extended.
   Rende(Z)vous : is being used for a rendezvous point
   (I)ntroduction : is being used for a hidden service introduction
   (N)one of the above: none of the above have happened yet.

These all have nice, clear-cut, easy-to-evaluate meanings, some of
which are mutually exclusive, and some of which aren't.

 [...]
&gt;&gt; It sounds like it should be a torrc option saying "Don't stop
&gt;&gt; refetching descriptors when there's no network activity."  Actually,
&gt;&gt; do we have one of those already?
&gt;
&gt; Yup, we have FetchUselessDescriptors. However, setting this causes an extra
&gt; load on the directory authorities, hence the desire to be able to do this a
&gt; bit more selectively (for instance just fetching our own descriptor every
&gt; hour but letting the rest go stale).

But fetching our own descriptor is kind of needless; we generated it
ourself, after all.  Is it not accessible via the control port?  We do
*have* it; it's a static variable in router.c.  What am I missing?

yrs,
-- 
Nick

</body></email><email><emailId>20100710214337</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-07-10 21:43:37-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


&gt;
&gt; Here's an alternate proposal...
&gt;

Yup, that removes a lot of ambiguity and works perfectly for this purpose so
changed. Thanks!

But fetching our own descriptor is kind of needless; we generated it
&gt; ourself, after all.  Is it not accessible via the control port?  We do
&gt; *have* it; it's a static variable in router.c.  What am I missing?
&gt;

I'm not aware of it being available via GETINFO with the exception of
running:
"desc/id/&lt;my fingerprint&gt;"
which I'm assuming means we get a stale version of our own descriptor if not
fetching new descriptors.

Regardless, lets drop any addition concerning descriptors. With the addition
of micro-descriptors any usage I have for them will soon be irrelevant.
Currently I'm just using descriptors for two purposes:

- Our own descriptor for the observed bandwidth if...
    ... our tor version is too old, lacking consensus entries with the
measured bandwidth (a more meaningful stat)
    ... or to figure out what the measured bandwidth stat represents. This
usage is just a hack and will go away with:
https://trac.torproject.org/projects/tor/ticket/1690

- Descriptors of other relays for the exit policy, platform, and tor
version. Micro descriptors are providing the first of these and the rest are
hardly worth downloading the descriptors unless specifically requested.

In other words I'll soon drop usage of descriptors except for fallback
behavior in old tor versions... for which any new GETINFO options are
useless anyways ;)

Cheers! -Damian

On Fri, Jul 9, 2010 at 6:38 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Tue, Jun 29, 2010 at 11:00 AM, Damian Johnson &lt;atagar1@gmail.com&gt;
&gt; wrote:
&gt; &gt;&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt; &gt;&gt; tests are approximate, not certain, and the only way to tell whether
&gt; &gt;&gt; we're intermediate or exiting is to wait and see if we're told to
&gt; &gt;&gt; exit.
&gt; &gt;
&gt; &gt; Understood that client facing tests fail by design when dealing with
&gt; &gt; bridges. In the case of the outbound connection component it sounds like
&gt; &gt; we'll need to wait until we're either asked to extend the circuit or exit
&gt; &gt; before counting it as an 'established circuit' and reporting it.
&gt;
&gt; Or we could drop the false notion that "middle" or "exit" or "entry"
&gt; make a partition of established relay or_circuits.   (They aren't a
&gt; partition because: first, they don't cover or_circuits.  A circuit
&gt; that has been just extended to us can't be called a middle or an exit.
&gt;  Second, they aren't exclusive: a circuit that has been extended from
&gt; us and used as an exit can be called both a middle _and_ an exit.)
&gt; See below for another possibility.
&gt;
&gt; &gt;&gt; In fact, the leaky-pipe topology means that we're potentially
&gt; &gt;&gt; intermediate _and_ exiting on a single circuit.
&gt; &gt;
&gt; &gt; (to save other readers the googling, this means that clients can exit the
&gt; &gt; circuit prematurely, such as at a middle node if the exit policy permits
&gt; it)
&gt; &gt;
&gt; &gt; You're right, that would mess with the classification. If/when this is
&gt; &gt; implemented I'd suggest adding anther classification for middle hops when
&gt; &gt; they're first used to exit traffic.
&gt;
&gt; It *IS* implemented server-side.  The clients just don't use it.
&gt;
&gt; (Since the point of this design is to safely expose accurate circuit
&gt; status info via the control port, we might as well try to expose the
&gt; possible states of current circuits, including states that don't
&gt; typically occur.  Otherwise, if some future weird client started using
&gt; them, you'd need to upgrade Tor *and* arm to get an accurate report.)
&gt;
&gt; &gt; The goal of these type flags are to indicate to controllers which
&gt; circuits
&gt; &gt; are sensitive and which are less so. In arm for instance most information
&gt; &gt; for client/exit connections are scrubbed. Indicating via a change of the
&gt; &gt; circuits status (an UPDATE event) when this begins exiting traffic seems
&gt; &gt; good enough to me.
&gt;
&gt; Here's an alternate proposal.  The idea of type flags is good, but
&gt; instead of the ones in your proposal, let's only use circuit type
&gt; flags that have an unambiguous meaning from the point of view of Tor's
&gt; spec and implementation.
&gt;
&gt; For instance,
&gt;   (E)ntry : a connection from a node that doesn't appear to be a Tor
&gt; server.
&gt;   E(X)it : has been used for at least one exit stream
&gt;   (R)elay : has been extended.
&gt;   Rende(Z)vous : is being used for a rendezvous point
&gt;   (I)ntroduction : is being used for a hidden service introduction
&gt;   (N)one of the above: none of the above have happened yet.
&gt;
&gt; These all have nice, clear-cut, easy-to-evaluate meanings, some of
&gt; which are mutually exclusive, and some of which aren't.
&gt;
&gt;  [...]
&gt; &gt;&gt; It sounds like it should be a torrc option saying "Don't stop
&gt; &gt;&gt; refetching descriptors when there's no network activity."  Actually,
&gt; &gt;&gt; do we have one of those already?
&gt; &gt;
&gt; &gt; Yup, we have FetchUselessDescriptors. However, setting this causes an
&gt; extra
&gt; &gt; load on the directory authorities, hence the desire to be able to do this
&gt; a
&gt; &gt; bit more selectively (for instance just fetching our own descriptor every
&gt; &gt; hour but letting the rest go stale).
&gt;
&gt; But fetching our own descriptor is kind of needless; we generated it
&gt; ourself, after all.  Is it not accessible via the control port?  We do
&gt; *have* it; it's a static variable in router.c.  What am I missing?
&gt;
&gt; yrs,
&gt; --
&gt; Nick
&gt;

[Attachment #5 (text/html)]

&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;Here's an alternate \
proposal...&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Yup, that removes a lot of ambiguity and works \
perfectly for this purpose so changed. Thanks!&lt;br&gt;

&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;But fetching our own descriptor is \
kind of needless; we generated it&lt;br&gt; ourself, after all.  Is it not accessible via \
                the control port?  We do&lt;br&gt;
*have* it; it's a static variable in router.c.  What am I \
missing?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;I'm not aware of it being available via GETINFO with \
the exception of running:&lt;br&gt;"desc/id/&lt;my fingerprint&gt;"&lt;br&gt;

which I'm assuming means we get a stale version of our own descriptor if not \
fetching new descriptors.&lt;br&gt;&lt;br&gt;Regardless, lets drop any addition concerning \
descriptors. With the addition of micro-descriptors any usage I have for them will \
soon be irrelevant. Currently I'm just using descriptors for two purposes:&lt;br&gt; \
&lt;br&gt;- Our own descriptor for the observed bandwidth if...&lt;br&gt;    ... our tor version \
is too old, lacking consensus entries with the measured bandwidth (a more meaningful \
stat)&lt;br&gt;    ... or to figure out what the measured bandwidth stat represents. This \
usage is just a hack and will go away with: &lt;a \
href="https://trac.torproject.org/projects/tor/ticket/1690"&gt;https://trac.torproject.org/projects/tor/ticket/1690&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;- Descriptors of other relays for the exit policy, platform, and tor version. \
Micro descriptors are providing the first of these and the rest are hardly worth \
downloading the descriptors unless specifically requested.&lt;br&gt; &lt;br&gt;In other words \
I'll soon drop usage of descriptors except for fallback behavior in old tor \
versions... for which any new GETINFO options are useless anyways ;)&lt;br&gt;&lt;br&gt;Cheers! \
-Damian&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt; On Fri, Jul 9, 2010 at 6:38 PM, Nick \
Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:nickm@freehaven.net" \
target="_blank"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote \
class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt \
0pt 0.8ex; padding-left: 1ex;"&gt;

&lt;div&gt;On Tue, Jun 29, 2010 at 11:00 AM, Damian Johnson &lt;&lt;a \
href="mailto:atagar1@gmail.com" target="_blank"&gt;atagar1@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt;&gt; Hm.  But we don't necessarily know this.  Our "are we \
client-facing"&lt;br&gt; &gt;&gt; tests are approximate, not certain, and the only way \
to tell whether&lt;br&gt; &gt;&gt; we're intermediate or exiting is to wait and see if \
we're told to&lt;br&gt; &gt;&gt; exit.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Understood that client facing tests fail by design when dealing with&lt;br&gt;
&gt; bridges. In the case of the outbound connection component it sounds like&lt;br&gt;
&gt; we'll need to wait until we're either asked to extend the circuit or \
exit&lt;br&gt; &gt; before counting it as an 'established circuit' and reporting \
it.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Or we could drop the false notion that "middle" or "exit" \
or "entry"&lt;br&gt; make a partition of established relay or_circuits.   (They \
aren't a&lt;br&gt; partition because: first, they don't cover or_circuits.  A \
circuit&lt;br&gt; that has been just extended to us can't be called a middle or an \
exit.&lt;br&gt;  Second, they aren't exclusive: a circuit that has been extended \
from&lt;br&gt; us and used as an exit can be called both a middle _and_ an exit.)&lt;br&gt;
See below for another possibility.&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt;&gt; In fact, the leaky-pipe topology means that we're potentially&lt;br&gt;
&gt;&gt; intermediate _and_ exiting on a single circuit.&lt;br&gt;
&gt;&lt;br&gt;
&gt; (to save other readers the googling, this means that clients can exit the&lt;br&gt;
&gt; circuit prematurely, such as at a middle node if the exit policy permits it)&lt;br&gt;
&gt;&lt;br&gt;
&gt; You're right, that would mess with the classification. If/when this is&lt;br&gt;
&gt; implemented I'd suggest adding anther classification for middle hops \
when&lt;br&gt; &gt; they're first used to exit traffic.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;It *IS* implemented server-side.  The clients just don't use it.&lt;br&gt;
&lt;br&gt;
(Since the point of this design is to safely expose accurate circuit&lt;br&gt;
status info via the control port, we might as well try to expose the&lt;br&gt;
possible states of current circuits, including states that don't&lt;br&gt;
typically occur.  Otherwise, if some future weird client started using&lt;br&gt;
them, you'd need to upgrade Tor *and* arm to get an accurate report.)&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt; The goal of these type flags are to indicate to controllers which circuits&lt;br&gt;
&gt; are sensitive and which are less so. In arm for instance most information&lt;br&gt;
&gt; for client/exit connections are scrubbed. Indicating via a change of the&lt;br&gt;
&gt; circuits status (an UPDATE event) when this begins exiting traffic seems&lt;br&gt;
&gt; good enough to me.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Here's an alternate proposal.  The idea of type flags is good, but&lt;br&gt;
instead of the ones in your proposal, let's only use circuit type&lt;br&gt;
flags that have an unambiguous meaning from the point of view of Tor's&lt;br&gt;
spec and implementation.&lt;br&gt;
&lt;br&gt;
For instance,&lt;br&gt;
   (E)ntry : a connection from a node that doesn't appear to be a Tor server.&lt;br&gt;
   E(X)it : has been used for at least one exit stream&lt;br&gt;
   (R)elay : has been extended.&lt;br&gt;
   Rende(Z)vous : is being used for a rendezvous point&lt;br&gt;
   (I)ntroduction : is being used for a hidden service introduction&lt;br&gt;
   (N)one of the above: none of the above have happened yet.&lt;br&gt;
&lt;br&gt;
These all have nice, clear-cut, easy-to-evaluate meanings, some of&lt;br&gt;
which are mutually exclusive, and some of which aren't.&lt;br&gt;
&lt;br&gt;
 [...]&lt;br&gt;
&lt;div&gt;&gt;&gt; It sounds like it should be a torrc option saying "Don't \
stop&lt;br&gt; &gt;&gt; refetching descriptors when there's no network activity."  \
Actually,&lt;br&gt; &gt;&gt; do we have one of those already?&lt;br&gt;
&gt;&lt;br&gt;
&gt; Yup, we have FetchUselessDescriptors. However, setting this causes an extra&lt;br&gt;
&gt; load on the directory authorities, hence the desire to be able to do this a&lt;br&gt;
&gt; bit more selectively (for instance just fetching our own descriptor every&lt;br&gt;
&gt; hour but letting the rest go stale).&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;But fetching our own descriptor is kind of needless; we generated it&lt;br&gt;
ourself, after all.  Is it not accessible via the control port?  We do&lt;br&gt;
*have* it; it's a static variable in router.c.  What am I missing?&lt;br&gt;
&lt;br&gt;
yrs,&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--e0cb4e887b1b7c5b24048b0f69a5--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "rcirc/id/&lt;Circuit identity&gt;" -- Provides entry for the associated relay
    circuit, formatted as:
      CIRC_ID=&lt;circuit ID&gt; CREATED=&lt;timestamp&gt; UPDATED=&lt;timestamp&gt; TYPE=&lt;flag&gt;
        READ=&lt;bytes&gt; WRITE=&lt;bytes&gt;

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique numeric identifier for the circuit this belongs to.
      CREATED - Unix timestamp (as seconds since the Epoch) for when the
          circuit was created.
      UPDATED - Unix timestamp for when this information was last updated.
      TYPE - Single character flags indicating attributes in the circuit:
          (E)ntry : has a connection that doesn't belong to a known Tor server,
            indicating that this is either the first hop or bridged
          E(X)it : has been used for at least one exit stream
          (R)elay : has been extended
          Rende(Z)vous : is being used for a rendezvous point
          (I)ntroduction : is being used for a hidden service introduction
          (N)one of the above: none of the above have happened yet.
      READ - Total bytes transmitted toward the exit over the circuit.
      WRITE - Total bytes transmitted toward the client over the circuit.

  "rcirc/all" -- The 'rcirc/id/*' output for all current circuits, joined by
    newlines.

   The following would be included for circ info update events.

4.1.X. Relay circuit status changed

  The syntax is:
     "650" SP "RCIRC" SP CircID SP Notice [SP Created SP Updated SP Type SP
          Read SP Write] CRLF
     
     Notice =
            "NEW"    / ; first information being provided for this circuit
            "UPDATE" / ; update for a previously reported circuit
            "CLOSED"   ; notice that the circuit no longer exists
    
  Notice indicating that queryable information on a relay related circuit has
  changed. If the Notice parameter is either "NEW" or "UPDATE" then this
  provides the same fields that would be given by calling "GETINFO rcirc/id/"
  with the CircID.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit.
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Space separated listing of flags currently held by the
    relay as repored by the currently cached consensus.
    
    "process/user" -- Username under which the tor process is running,
    providing an empty string if none exists.
    
    "process/pid" -- Process id belonging to the main tor process, -1 if none
    exists for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup, sighup, or RELOAD
    signal, in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.
    
    "state/names" -- A space-separated list of all the keys supported by this
    version of Tor's state.
    
    "state/val/&lt;key&gt;" -- Provides the current state value belonging to the
    given key. If undefined, this provides the key's default value.



</body></email><email><emailId>20100727140509</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-07-27 14:05:09-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

[Attachment #2 (multipart/alternative)]


Hi, I've made another addition to the get-info proposal for a piece of
information Sebastian pointed out at the tor dev meeting. It consists of a
GETINFO option and corresponding events for daily aggregated statistics for
the ports we're exiting to (only for exit relays). This would use the
feature we already have for the torrc option:

ExitPortStatistics
When this option is enabled, Tor writes statistics on the number of relayed
bytes and
opened stream per exit port to disk every 24 hours. Cannot be changed while
Tor is
running. (Default: 0)

Cheers! -Damian

On Sat, Jul 10, 2010 at 2:43 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Here's an alternate proposal...
&gt;&gt;
&gt;
&gt; Yup, that removes a lot of ambiguity and works perfectly for this purpose
&gt; so changed. Thanks!
&gt;
&gt;
&gt; But fetching our own descriptor is kind of needless; we generated it
&gt;&gt; ourself, after all.  Is it not accessible via the control port?  We do
&gt;&gt; *have* it; it's a static variable in router.c.  What am I missing?
&gt;&gt;
&gt;
&gt; I'm not aware of it being available via GETINFO with the exception of
&gt; running:
&gt; "desc/id/&lt;my fingerprint&gt;"
&gt; which I'm assuming means we get a stale version of our own descriptor if
&gt; not fetching new descriptors.
&gt;
&gt; Regardless, lets drop any addition concerning descriptors. With the
&gt; addition of micro-descriptors any usage I have for them will soon be
&gt; irrelevant. Currently I'm just using descriptors for two purposes:
&gt;
&gt; - Our own descriptor for the observed bandwidth if...
&gt;     ... our tor version is too old, lacking consensus entries with the
&gt; measured bandwidth (a more meaningful stat)
&gt;     ... or to figure out what the measured bandwidth stat represents. This
&gt; usage is just a hack and will go away with:
&gt; https://trac.torproject.org/projects/tor/ticket/1690
&gt;
&gt; - Descriptors of other relays for the exit policy, platform, and tor
&gt; version. Micro descriptors are providing the first of these and the rest are
&gt; hardly worth downloading the descriptors unless specifically requested.
&gt;
&gt; In other words I'll soon drop usage of descriptors except for fallback
&gt; behavior in old tor versions... for which any new GETINFO options are
&gt; useless anyways ;)
&gt;
&gt; Cheers! -Damian
&gt;
&gt;
&gt; On Fri, Jul 9, 2010 at 6:38 PM, Nick Mathewson &lt;nickm@freehaven.net&gt;wrote:
&gt;
&gt;&gt; On Tue, Jun 29, 2010 at 11:00 AM, Damian Johnson &lt;atagar1@gmail.com&gt;
&gt;&gt; wrote:
&gt;&gt; &gt;&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt;&gt; &gt;&gt; tests are approximate, not certain, and the only way to tell whether
&gt;&gt; &gt;&gt; we're intermediate or exiting is to wait and see if we're told to
&gt;&gt; &gt;&gt; exit.
&gt;&gt; &gt;
&gt;&gt; &gt; Understood that client facing tests fail by design when dealing with
&gt;&gt; &gt; bridges. In the case of the outbound connection component it sounds like
&gt;&gt; &gt; we'll need to wait until we're either asked to extend the circuit or
&gt;&gt; exit
&gt;&gt; &gt; before counting it as an 'established circuit' and reporting it.
&gt;&gt;
&gt;&gt; Or we could drop the false notion that "middle" or "exit" or "entry"
&gt;&gt; make a partition of established relay or_circuits.   (They aren't a
&gt;&gt; partition because: first, they don't cover or_circuits.  A circuit
&gt;&gt; that has been just extended to us can't be called a middle or an exit.
&gt;&gt;  Second, they aren't exclusive: a circuit that has been extended from
&gt;&gt; us and used as an exit can be called both a middle _and_ an exit.)
&gt;&gt; See below for another possibility.
&gt;&gt;
&gt;&gt; &gt;&gt; In fact, the leaky-pipe topology means that we're potentially
&gt;&gt; &gt;&gt; intermediate _and_ exiting on a single circuit.
&gt;&gt; &gt;
&gt;&gt; &gt; (to save other readers the googling, this means that clients can exit
&gt;&gt; the
&gt;&gt; &gt; circuit prematurely, such as at a middle node if the exit policy permits
&gt;&gt; it)
&gt;&gt; &gt;
&gt;&gt; &gt; You're right, that would mess with the classification. If/when this is
&gt;&gt; &gt; implemented I'd suggest adding anther classification for middle hops
&gt;&gt; when
&gt;&gt; &gt; they're first used to exit traffic.
&gt;&gt;
&gt;&gt; It *IS* implemented server-side.  The clients just don't use it.
&gt;&gt;
&gt;&gt; (Since the point of this design is to safely expose accurate circuit
&gt;&gt; status info via the control port, we might as well try to expose the
&gt;&gt; possible states of current circuits, including states that don't
&gt;&gt; typically occur.  Otherwise, if some future weird client started using
&gt;&gt; them, you'd need to upgrade Tor *and* arm to get an accurate report.)
&gt;&gt;
&gt;&gt; &gt; The goal of these type flags are to indicate to controllers which
&gt;&gt; circuits
&gt;&gt; &gt; are sensitive and which are less so. In arm for instance most
&gt;&gt; information
&gt;&gt; &gt; for client/exit connections are scrubbed. Indicating via a change of the
&gt;&gt; &gt; circuits status (an UPDATE event) when this begins exiting traffic seems
&gt;&gt; &gt; good enough to me.
&gt;&gt;
&gt;&gt; Here's an alternate proposal.  The idea of type flags is good, but
&gt;&gt; instead of the ones in your proposal, let's only use circuit type
&gt;&gt; flags that have an unambiguous meaning from the point of view of Tor's
&gt;&gt; spec and implementation.
&gt;&gt;
&gt;&gt; For instance,
&gt;&gt;   (E)ntry : a connection from a node that doesn't appear to be a Tor
&gt;&gt; server.
&gt;&gt;   E(X)it : has been used for at least one exit stream
&gt;&gt;   (R)elay : has been extended.
&gt;&gt;   Rende(Z)vous : is being used for a rendezvous point
&gt;&gt;   (I)ntroduction : is being used for a hidden service introduction
&gt;&gt;   (N)one of the above: none of the above have happened yet.
&gt;&gt;
&gt;&gt; These all have nice, clear-cut, easy-to-evaluate meanings, some of
&gt;&gt; which are mutually exclusive, and some of which aren't.
&gt;&gt;
&gt;&gt;  [...]
&gt;&gt; &gt;&gt; It sounds like it should be a torrc option saying "Don't stop
&gt;&gt; &gt;&gt; refetching descriptors when there's no network activity."  Actually,
&gt;&gt; &gt;&gt; do we have one of those already?
&gt;&gt; &gt;
&gt;&gt; &gt; Yup, we have FetchUselessDescriptors. However, setting this causes an
&gt;&gt; extra
&gt;&gt; &gt; load on the directory authorities, hence the desire to be able to do
&gt;&gt; this a
&gt;&gt; &gt; bit more selectively (for instance just fetching our own descriptor
&gt;&gt; every
&gt;&gt; &gt; hour but letting the rest go stale).
&gt;&gt;
&gt;&gt; But fetching our own descriptor is kind of needless; we generated it
&gt;&gt; ourself, after all.  Is it not accessible via the control port?  We do
&gt;&gt; *have* it; it's a static variable in router.c.  What am I missing?
&gt;&gt;
&gt;&gt; yrs,
&gt;&gt; --
&gt;&gt; Nick
&gt;&gt;
&gt;
&gt;

[Attachment #5 (text/html)]

Hi, I've made another addition to the get-info proposal for a piece of \
information Sebastian pointed out at the tor dev meeting. It consists of a GETINFO \
option and corresponding events for daily aggregated statistics for the ports \
we're exiting to (only for exit relays). This would use the feature we already \
have for the torrc option:&lt;br&gt; &lt;br&gt;ExitPortStatistics&lt;br&gt;When this option is enabled, \
Tor writes statistics on the number of relayed bytes and&lt;br&gt;opened stream per exit \
port to disk every 24 hours. Cannot be changed while Tor is&lt;br&gt;running. (Default: \
0)&lt;br&gt; &lt;br&gt;Cheers! -Damian&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Sat, Jul 10, 2010 at \
2:43 PM, Damian Johnson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt; &lt;blockquote style="border-left: \
1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;Here's an alternate proposal...&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Yup, that \
removes a lot of ambiguity and works perfectly for this purpose so changed. \
Thanks!&lt;div class="im"&gt; &lt;br&gt;

&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;But fetching our own descriptor is \
kind of needless; we generated it&lt;br&gt; ourself, after all.  Is it not accessible via \
                the control port?  We do&lt;br&gt;
*have* it; it's a static variable in router.c.  What am I \
missing?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;/div&gt;I'm not aware of it being available via \
GETINFO with the exception of running:&lt;br&gt;"desc/id/&lt;my \
fingerprint&gt;"&lt;br&gt;


which I'm assuming means we get a stale version of our own descriptor if not \
fetching new descriptors.&lt;br&gt;&lt;br&gt;Regardless, lets drop any addition concerning \
descriptors. With the addition of micro-descriptors any usage I have for them will \
soon be irrelevant. Currently I'm just using descriptors for two purposes:&lt;br&gt;

&lt;br&gt;- Our own descriptor for the observed bandwidth if...&lt;br&gt;    ... our tor version \
is too old, lacking consensus entries with the measured bandwidth (a more meaningful \
stat)&lt;br&gt;    ... or to figure out what the measured bandwidth stat represents. This \
usage is just a hack and will go away with: &lt;a \
href="https://trac.torproject.org/projects/tor/ticket/1690" \
target="_blank"&gt;https://trac.torproject.org/projects/tor/ticket/1690&lt;/a&gt;&lt;br&gt;

&lt;br&gt;- Descriptors of other relays for the exit policy, platform, and tor version. \
Micro descriptors are providing the first of these and the rest are hardly worth \
downloading the descriptors unless specifically requested.&lt;br&gt;

&lt;br&gt;In other words I'll soon drop usage of descriptors except for fallback \
behavior in old tor versions... for which any new GETINFO options are useless anyways \
;)&lt;br&gt;&lt;br&gt;Cheers! -Damian&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt; &lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt; On Fri, Jul 9, 2010 at 6:38 PM, Nick Mathewson &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:nickm@freehaven.net" \
target="_blank"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote \
class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt \
0pt 0.8ex; padding-left: 1ex;"&gt;


&lt;div&gt;On Tue, Jun 29, 2010 at 11:00 AM, Damian Johnson &lt;&lt;a \
href="mailto:atagar1@gmail.com" target="_blank"&gt;atagar1@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt;&gt; Hm.  But we don't necessarily know this.  Our "are we \
client-facing"&lt;br&gt; &gt;&gt; tests are approximate, not certain, and the only way \
to tell whether&lt;br&gt; &gt;&gt; we're intermediate or exiting is to wait and see if \
we're told to&lt;br&gt; &gt;&gt; exit.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Understood that client facing tests fail by design when dealing with&lt;br&gt;
&gt; bridges. In the case of the outbound connection component it sounds like&lt;br&gt;
&gt; we'll need to wait until we're either asked to extend the circuit or \
exit&lt;br&gt; &gt; before counting it as an 'established circuit' and reporting \
it.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Or we could drop the false notion that "middle" or "exit" \
or "entry"&lt;br&gt; make a partition of established relay or_circuits.   (They \
aren't a&lt;br&gt; partition because: first, they don't cover or_circuits.  A \
circuit&lt;br&gt; that has been just extended to us can't be called a middle or an \
exit.&lt;br&gt;  Second, they aren't exclusive: a circuit that has been extended \
from&lt;br&gt; us and used as an exit can be called both a middle _and_ an exit.)&lt;br&gt;
See below for another possibility.&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt;&gt; In fact, the leaky-pipe topology means that we're potentially&lt;br&gt;
&gt;&gt; intermediate _and_ exiting on a single circuit.&lt;br&gt;
&gt;&lt;br&gt;
&gt; (to save other readers the googling, this means that clients can exit the&lt;br&gt;
&gt; circuit prematurely, such as at a middle node if the exit policy permits it)&lt;br&gt;
&gt;&lt;br&gt;
&gt; You're right, that would mess with the classification. If/when this is&lt;br&gt;
&gt; implemented I'd suggest adding anther classification for middle hops \
when&lt;br&gt; &gt; they're first used to exit traffic.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;It *IS* implemented server-side.  The clients just don't use it.&lt;br&gt;
&lt;br&gt;
(Since the point of this design is to safely expose accurate circuit&lt;br&gt;
status info via the control port, we might as well try to expose the&lt;br&gt;
possible states of current circuits, including states that don't&lt;br&gt;
typically occur.  Otherwise, if some future weird client started using&lt;br&gt;
them, you'd need to upgrade Tor *and* arm to get an accurate report.)&lt;br&gt;
&lt;div&gt;&lt;br&gt;
&gt; The goal of these type flags are to indicate to controllers which circuits&lt;br&gt;
&gt; are sensitive and which are less so. In arm for instance most information&lt;br&gt;
&gt; for client/exit connections are scrubbed. Indicating via a change of the&lt;br&gt;
&gt; circuits status (an UPDATE event) when this begins exiting traffic seems&lt;br&gt;
&gt; good enough to me.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Here's an alternate proposal.  The idea of type flags is good, but&lt;br&gt;
instead of the ones in your proposal, let's only use circuit type&lt;br&gt;
flags that have an unambiguous meaning from the point of view of Tor's&lt;br&gt;
spec and implementation.&lt;br&gt;
&lt;br&gt;
For instance,&lt;br&gt;
   (E)ntry : a connection from a node that doesn't appear to be a Tor server.&lt;br&gt;
   E(X)it : has been used for at least one exit stream&lt;br&gt;
   (R)elay : has been extended.&lt;br&gt;
   Rende(Z)vous : is being used for a rendezvous point&lt;br&gt;
   (I)ntroduction : is being used for a hidden service introduction&lt;br&gt;
   (N)one of the above: none of the above have happened yet.&lt;br&gt;
&lt;br&gt;
These all have nice, clear-cut, easy-to-evaluate meanings, some of&lt;br&gt;
which are mutually exclusive, and some of which aren't.&lt;br&gt;
&lt;br&gt;
 [...]&lt;br&gt;
&lt;div&gt;&gt;&gt; It sounds like it should be a torrc option saying "Don't \
stop&lt;br&gt; &gt;&gt; refetching descriptors when there's no network activity."  \
Actually,&lt;br&gt; &gt;&gt; do we have one of those already?&lt;br&gt;
&gt;&lt;br&gt;
&gt; Yup, we have FetchUselessDescriptors. However, setting this causes an extra&lt;br&gt;
&gt; load on the directory authorities, hence the desire to be able to do this a&lt;br&gt;
&gt; bit more selectively (for instance just fetching our own descriptor every&lt;br&gt;
&gt; hour but letting the rest go stale).&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;But fetching our own descriptor is kind of needless; we generated it&lt;br&gt;
ourself, after all.  Is it not accessible via the control port?  We do&lt;br&gt;
*have* it; it's a static variable in router.c.  What am I missing?&lt;br&gt;
&lt;br&gt;
yrs,&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;Nick&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;

--0015174c15d438ba7b048c5efdcd--


["xxx-circ-getinfo-option.txt" (text/plain)]

Filename: xxx-circ-getinfo-option.txt
Title: GETINFO controller option for circuit information
Author: Damian Johnson
Created: 03-June-2010
Status: Draft

Overview:

    This details an additional GETINFO option that would provide information
    concerning a relay's current circuits.

Motivation:

    The original proposal was for connection related information, but Jake make
    the excellent point that any information retrieved from the control port
    is...
    
      1. completely ineffectual for auditing purposes since either (a) these
      results can be fetched from netstat already or (b) the information would
      only be provided via tor and can't be validated.
      
      2. The more useful uses for connection information can be achieved with
      much less (and safer) information.
    
    Hence the proposal is now for circuit based rather than connection based
    information. This would strip the most controversial and sensitive data
    entirely (ip addresses, ports, and connection based bandwidth breakdowns)
    while still being useful for the following purposes:

    - Basic Relay Usage Questions
    How is the bandwidth I'm contributing broken down? Is it being evenly
    distributed or is someone hogging most of it? Do these circuits belong to
    the hidden service I'm running or something else? Now that I'm using exit
    policy X am I desirable as an exit, or are most people just using me as a
    relay?

    - Debugging
    Say a relay has a restrictive firewall policy for outbound connections,
    with the ORPort whitelisted but doesn't realize that tor needs random high
    ports. Tor would report success ("your orport is reachable - excellent")
    yet the relay would be nonfunctional. This proposed information would
    reveal numerous RELAY -&gt; YOU -&gt; UNESTABLISHED circuits, giving a good
    indicator of what's wrong.

    - Visualization
    A nice benefit of visualizing tor's behavior is that it becomes a helpful
    tool in puzzling out how tor works. For instance, tor spawns numerous
    client connections at startup (even if unused as a client). As a newcomer
    to tor these asymmetric (outbound only) connections mystified me for quite
    a while until until Roger explained their use to me. The proposed
    TYPE_FLAGS would let controllers clearly label them as being client
    related, making their purpose a bit clearer.

    At the moment connection data can only be retrieved via commands like
    netstat, ss, and lsof. However, providing an alternative via the control
    port provides several advantages:

      - scrubbing for private data
          Raw connection data has no notion of what's sensitive and what is
          not. The relay's flags and cached consensus can be used to take
          educated guesses concerning which connections could possibly belong
          to client or exit traffic, but this is both difficult and inaccurate.
          Anything provided via the control port can scrubbed to make sure we
          aren't providing anything we think relay operators should not see.
     
      - additional information
          All connection querying commands strictly provide the ip address and
          port of connections, and nothing else. However, for the uses listed
          above the far more interesting attributes are the circuit's type,
          bandwidth usage and uptime.
     
      - improved performance
          Querying connection data is an expensive activity, especially for
          busy relays or low end processors (such as mobile devices). Tor
          already internally knows its circuits, allowing for vastly quicker
          lookups.
     
      - cross platform capability
          The connection querying utilities mentioned above not only aren't
          available under Windows, but differ widely among different *nix
          platforms. FreeBSD in particular takes a very unique approach,
          dropping important options from netstat and assigning ss to a
          spreadsheet application instead. A controller interface, however,
          would provide a uniform means of retrieving this information.

Security Implications:

    This is an open question. This proposal lacks the most controversial pieces
    of information (ip addresses and ports) and insight into potential threats
    this would pose would be very welcomed!

Specification:

   The following addition would be made to the control-spec's GETINFO section:

  "rcirc/id/&lt;Circuit identity&gt;" -- Provides entry for the associated relay
    circuit, formatted as:
      CIRC_ID=&lt;circuit ID&gt; CREATED=&lt;timestamp&gt; UPDATED=&lt;timestamp&gt; TYPE=&lt;flag&gt;
        READ=&lt;bytes&gt; WRITE=&lt;bytes&gt;

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CIRC_ID - Unique numeric identifier for the circuit this belongs to.
      CREATED - Unix timestamp (as seconds since the Epoch) for when the
          circuit was created.
      UPDATED - Unix timestamp for when this information was last updated.
      TYPE - Single character flags indicating attributes in the circuit:
          (E)ntry : has a connection that doesn't belong to a known Tor server,
            indicating that this is either the first hop or bridged
          E(X)it : has been used for at least one exit stream
          (R)elay : has been extended
          Rende(Z)vous : is being used for a rendezvous point
          (I)ntroduction : is being used for a hidden service introduction
          (N)one of the above: none of the above have happened yet.
      READ - Total bytes transmitted toward the exit over the circuit.
      WRITE - Total bytes transmitted toward the client over the circuit.

  "rcirc/all" -- The 'rcirc/id/*' output for all current circuits, joined by
    newlines.

   The following would be included for circ info update events.

4.1.X. Relay circuit status changed

  The syntax is:
     "650" SP "RCIRC" SP CircID SP Notice [SP Created SP Updated SP Type SP
          Read SP Write] CRLF
     
     Notice =
            "NEW"    / ; first information being provided for this circuit
            "UPDATE" / ; update for a previously reported circuit
            "CLOSED"   ; notice that the circuit no longer exists
    
  Notice indicating that queryable information on a relay related circuit has
  changed. If the Notice parameter is either "NEW" or "UPDATE" then this
  provides the same fields that would be given by calling "GETINFO rcirc/id/"
  with the CircID.


["xxx-getinfo-option-expansion.txt" (text/plain)]

Filename: xxx-getinfo-option-expansion.txt
Title: GETINFO Option Expansion
Author: Damian Johnson
Created: 02-June-2010
Status: Draft

Overview:

    Over the course of developing arm there's been numerous hacks and
    workarounds to gleam pieces of basic, desirable information about the tor
    process. As per Roger's request I've compiled a list of these pain points
    to try and improve the control protocol interface.

Motivation:

    The purpose of this proposal is to expose additional process and relay
    related information that is currently unavailable in a convenient,
    dependable, and/or platform independent way. Examples of this are...
    
      - The relay's total contributed bandwidth. This is a highly requested
        piece of information and, based on the following patch from pipe, looks
        trivial to include.
        http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html
      
      - The process ID of the tor process. There is a high degree of guess work
        in obtaining this. Arm for instance uses pidof, netstat, and ps yet
        still fails on some platforms, and Orbot recently got a ticket about
        its own attempt to fetch it with ps:
        https://trac.torproject.org/projects/tor/ticket/1388
    
    This just includes the pieces of missing information I've noticed
    (suggestions or questions of their usefulness are welcome!).

Security Implications:

    None that I'm aware of. From a security standpoint this seems decently
    innocuous.

Specification:

    The following addition would be made to the control-spec's GETINFO section:
    
    "relay/bw-limit" -- Effective relayed bandwidth limit.
    
    "relay/burst-limit" -- Effective relayed burst limit.
    
    "relay/read-total" -- Total bytes relayed (download).
    
    "relay/write-total" -- Total bytes relayed (upload).
    
    "relay/flags" -- Space separated listing of flags currently held by the
    relay as repored by the currently cached consensus.
    
    "process/user" -- Username under which the tor process is running,
    providing an empty string if none exists.
    
    "process/pid" -- Process id belonging to the main tor process, -1 if none
    exists for the platform.
    
    "process/uptime" -- Total uptime of the tor process (in seconds).
    
    "process/uptime-reset" -- Time since last reset (startup, sighup, or RELOAD
    signal, in seconds).
    
    "process/descriptors-used" -- Count of file descriptors used.
    
    "process/descriptor-limit" -- File descriptor limit (getrlimit results).
    
    "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.
    
    "state/names" -- A space-separated list of all the keys supported by this
    version of Tor's state.
    
    "state/val/&lt;key&gt;" -- Provides the current state value belonging to the
    given key. If undefined, this provides the key's default value.
    
    "status/ports-seen" -- A summary of which ports we've seen connections
    circuits connect to recently, formatted the same as the EXITS_SEEN status
    event described in Section 4.1.XX. This GETINFO option is currently
    available only for exit relays.

4.1.XX. Per-port exit stats

  The syntax is:
     "650" SP "EXITS_SEEN" SP TimeStarted SP PortSummary CRLF

  We just generated a new summary of which ports we've seen exiting circuits
  connecting to recently. The controller could display this for the user, e.g.
  in their "relay" configuration window, to give them a sense of how they're
  being used (popularity of the various ports they exit to). Currently only
  exit relays will receive this event.
  
  TimeStarted is a quoted string indicating when the reported summary
  counts from (in GMT).

  The PortSummary keyword has as its argument a comma-separated, possibly
  empty set of "port=count" pairs. For example (without linebreak),
  650-EXITS_SEEN TimeStarted="2008-12-25 23:50:43"
  PortSummary=80=16,443=8



</body></email><email><emailId>20100803172126</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-03 17:21:26-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Tue, Jul 27, 2010 at 10:05 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; Hi, I've made another addition to the get-info proposal for a piece of
&gt; information Sebastian pointed out at the tor dev meeting. It consists of a
&gt; GETINFO option and corresponding events for daily aggregated statistics for
&gt; the ports we're exiting to (only for exit relays). This would use the
&gt; feature we already have for the torrc option:

Right.  I hereby take out the golden onion of destiny and bless these
proposals as #s 172 and 173, and add them to the repository in state
"accepted".  Thanks for your patience!

-- 
Nick
</body></email><email><emailId>20100604045508</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-06-04 04:55:08-0400</timestampReceived><subject>Re: concurrent circuits for traffic fragmentation</subject><body>

On Thu, Jun 3, 2010 at 11:38 PM, Brian Szymanski &lt;ski@indymedia.org&gt; wrote:
&gt; ... But wouldn't your proposal open tor up to further timing attacks and
&gt; other sorts of analysis - in other words, it's easier to notice N new
&gt; circuits going between two nodes than it is to notice one.

It would multiply exposure to those traffic confirmation attacks, but
I'm not sure their accuracy would improve. I suppose that problem
would have to be solved first. (I have one idea regarding this that I
hope to elaborate on once I gain some understanding.)

Unless, given a minimum amount (time-wise) of traffic that must be
observed to make a decent correlation, one is careful to have chunks
of traffic not exceed that limit? Have there been studies done in that
regard?

&gt; ... And there's no reason to expect that fragmentation is significantly
&gt; useful in terms of making endpoint connections less insecure - sniffing
&gt; the first packet of a ssh connection is more than enough. Leaking half
&gt; of a classified document is not necessarily significantly better than a
&gt; whole classified document.  Etc. Perhaps if you gave every byte in the
&gt; connection a different route, you would do ok, but performance would be
&gt; unusable, if the packets even made it through.

That's true. The second half of the hypothetical PDF file wouldn't be
of much use, but the very first chunk would have a value up to that of
the whole file. Especially considering things like email data...

But there would at least be the benefit of frustrating automated
sniffing, which I imagine is what's going on in all but very targeted
attacks. It would downgrade those scenarios to requiring a minimum of
human interaction.

&gt; In short, tor does not and IMO should not try to eliminate the need for
&gt; encrypted protocols like ssh and https. This doesn't seem like a win to me.

It still wouldn't eliminate that need, but I think Tor shouldn't be
content with warning users of the risks. There has to be some way to
make obsolete sniffing on exit nodes...

&gt; Or am I missing something?

No, you're correct. ; ) But if someone can think of improvement to the
shortcomings you mentioned, I think there is potential to such an
approach.

-- 
Mansour Moufid
</body></email><email><emailId>20100215191433</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-02-15 19:14:33-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

On Mon, Feb 15, 2010 at 09:29:19AM +0100, Karsten Loesing wrote:
&gt; So, are these good news? Personally, I had expected worse
&gt;results. During most of the time, availability is surprisingly high. An
&gt;80% chance of the bridges working even after 96 hours seems fair.

Hi Karsten,

Thanks for the analysis. This result is indeed good. But:

&gt; I should state that there is one major inaccuracy in the analysis:
&gt;Bridges that change their IP address are not reachable by their
&gt;clients anymore. In theory, clients are able to download updated bridge
&gt;descriptors from the bridge authority to learn about new IP addresses,
&gt;but this functionality is not implemented yet. However, I cannot take
&gt;changing IP addresses into account for this analysis, because I removed
&gt;the IP addresses when sanitizing the bridge descriptors. Hah! Maybe we
&gt;should just fix this problem by implementing the missing functionality.

This part is worrisome. That means your analysis is assuming the bridges
always stick to the same IP address, right? It's worth trying to do
the analysis when we take into account that some bridges are on highly
dynamic IPs (e.g. daily).

What's the process by which we sanitize them? It seems that a fine
solution would be to hash the IP addresses keyed with a secret that
remains constant across the hashes. So you could tell if the IP addresses
are the same without being able to tell what they are. The main challenge
there is keeping the secret somewhere secret in between batches (and
maybe rotating the secret monthly, for some level of forward secrecy).

&gt; Another minor issue that Roger told me is that the bridge authority
&gt;assigns the Stable flag to almost every bridge. If there was a sane way
&gt;of assigning the Stable flag and we gave out, say, at least 1 bridge
&gt;with the Stable flag, would this improve availability? This is rather
&gt;hard to simulate. Maybe we should fix the Stable flag for bridges and
&gt;run this analysis a second time as soon as we have some data. So many
&gt;things to fix...

Yep. If we want to get even more ambitious, we might want to revive
Nick's proposal 146, "Add new flag to reflect long-term stability".

--Roger

</body></email><email><emailId>20100309233955</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-03-09 23:39:55-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

On Mon, Feb 15, 2010 at 09:05:54PM +0100, Karsten Loesing wrote:
&gt; &gt;&gt; However, I cannot take
&gt; &gt;&gt; changing IP addresses into account for this analysis, because I removed
&gt; &gt;&gt; the IP addresses when sanitizing the bridge descriptors.
&gt; &gt; 
&gt; &gt; What's the process by which we sanitize them? It seems that a fine
&gt; &gt; solution would be to hash the IP addresses keyed with a secret that
&gt; &gt; remains constant across the hashes. So you could tell if the IP addresses
&gt; &gt; are the same without being able to tell what they are. The main challenge
&gt; &gt; there is keeping the secret somewhere secret in between batches (and
&gt; &gt; maybe rotating the secret monthly, for some level of forward secrecy).
&gt; 
&gt; Yes, we can do something like that. I assume that it'll keep my server
&gt;busy for a day or two to parse all the descriptors once more. But I can
&gt;do that.
&gt; 
&gt; Instead of the secret input to the hash function, how about we
&gt;concatenate bridge identity and IP address as input? Note that we
&gt;don't put the bridge identity in the sanitized descriptor, but only
&gt;its hash. That way we'd avoid using a secret that we'll lose or forget
&gt;anyway and have something reproducible. To be precise, this is what I
&gt;have in mind:
&gt; 
&gt;   sanitized bridge identity = H(bridge identity)
&gt; 
&gt;   sanitized IP address = H(bridge identity + IP address)[:4]

Interesting idea. This approach clearly does leak more information:
if you learn the bridge identity at any point, you can guess-and-check
past IP addresses for the bridge.

The next question is then: so what? Is that something we want to protect?

There are two benefits to leaking this information. First, we can generate
incremental updates to the sanitized bridge descriptor database, and
they will be compatible sanitized-IP-address-wise with the existing
database. That makes updates more convenient on our side. Second, it is
possible to ask questions about where bridges have been over the space
of months, not just inside a given month. It's not clear that we plan
to ask those questions right now, though.

So the conclusion is either "A) yes, we should do it that way, the
information leak is not a big deal", or "B) let's do it the safer way for
now, to get the answers we are looking for now; and if later we decide we
want more detailed answers, we still have the original bridge descriptors,
and we can publish slightly less sanitized data at the point we decide
we should".

I'm not sure there's a clear answer, but my instinct is to go for B.

&gt; Note that only the first 4 bytes of the result are used, because the
&gt;result is written as the bridge's IP address, covering the entire range
&gt;between 0.0.0.0 and 255.255.255.255. Of course, there's a reasonable
&gt;chance for collisions for a bridge identity with two different IP
&gt;addresses.

Right -- the birthday paradox brings us to "once we've looked at 65k
addresses, we should expect a collision".

&gt; But I want the network status to contain all relevant
&gt;information rather than re-assembling network status entries and bridge
&gt;descriptors (which could contain more information in their contact
&gt;line). Are there better ways to add 20 bytes to the network status? We
&gt;might still add the full hash to the descriptor's contact line.

So far we've been trying to make sure that the sanitized descriptors
we publish still happen to conform to dir-spec.txt. At some point this
technique is going to break down. We shouldn't be too afraid to abandon
that technique when it gets too burdensome, so long as we still give
people tools that can parse whatever format we publish.

--Roger

</body></email><email><emailId>20100310142024</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-03-10 14:20:24-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

On 3/10/10 12:39 AM, Roger Dingledine wrote:
&gt; On Mon, Feb 15, 2010 at 09:05:54PM +0100, Karsten Loesing wrote:
&gt;&gt;&gt;&gt; However, I cannot take
&gt;&gt;&gt;&gt; changing IP addresses into account for this analysis, because I removed
&gt;&gt;&gt;&gt; the IP addresses when sanitizing the bridge descriptors.
&gt;&gt;&gt;
&gt;&gt;&gt; What's the process by which we sanitize them? It seems that a fine
&gt;&gt;&gt; solution would be to hash the IP addresses keyed with a secret that
&gt;&gt;&gt; remains constant across the hashes. So you could tell if the IP addresses
&gt;&gt;&gt; are the same without being able to tell what they are. The main challenge
&gt;&gt;&gt; there is keeping the secret somewhere secret in between batches (and
&gt;&gt;&gt; maybe rotating the secret monthly, for some level of forward secrecy).
&gt;&gt;
&gt;&gt; Yes, we can do something like that. I assume that it'll keep my server
&gt;&gt; busy for a day or two to parse all the descriptors once more. But I can
&gt;&gt; do that.
&gt;&gt;
&gt;&gt; Instead of the secret input to the hash function, how about we
&gt;&gt; concatenate bridge identity and IP address as input? Note that we
&gt;&gt; don't put the bridge identity in the sanitized descriptor, but only
&gt;&gt; its hash. That way we'd avoid using a secret that we'll lose or forget
&gt;&gt; anyway and have something reproducible. To be precise, this is what I
&gt;&gt; have in mind:
&gt;&gt;
&gt;&gt;   sanitized bridge identity = H(bridge identity)
&gt;&gt;
&gt;&gt;   sanitized IP address = H(bridge identity + IP address)[:4]
&gt; 
&gt; Interesting idea. This approach clearly does leak more information:
&gt; if you learn the bridge identity at any point, you can guess-and-check
&gt; past IP addresses for the bridge.
&gt; 
&gt; The next question is then: so what? Is that something we want to protect?

A fine question. I don't think this is something we want to protect. My
understanding of bridges is that they shall make it hard for an
adversary to block the entry points to the Tor network. That means we
shouldn't reveal current bridge IP addresses, nor bridge identities
which can be used to learn about current and future IP addresses.

But why should we care about past IP addresses of a bridge? What would
the adversary---who learns about a bridge identity somehow---do with
this piece of information? Tell that someone has been using Tor via this
bridge in the past when connecting to that IP address? Is this something
we want to protect? That would imply that it's considered a security
feature that bridges change their IP addresses on a regular basis. What
about bridges on static IP addresses: when an adversary learns about
such a bridge, does that mean its past users are more screwed than the
past users of a bridge on a dynamic IP address?

The question is: What are we trying to protect? I'm happy to protect
past IP addresses of a bridge if there's a reason to do so. But knowing
what is worth protecting and what is not would be helpful. After all,
not publishing any bridge descriptors would give us best protection; but
that's not what we want.

&gt; There are two benefits to leaking this information. First, we can generate
&gt; incremental updates to the sanitized bridge descriptor database, and
&gt; they will be compatible sanitized-IP-address-wise with the existing
&gt; database. That makes updates more convenient on our side.

Yes, not including a monthly changing secret in the hash function makes
the sanitized descriptors more useful for statistics.

&gt; Second, it is
&gt; possible to ask questions about where bridges have been over the space
&gt; of months, not just inside a given month. It's not clear that we plan
&gt; to ask those questions right now, though.

Unclear. I don't think we'll be asking these questions.

&gt; So the conclusion is either "A) yes, we should do it that way, the
&gt; information leak is not a big deal", or "B) let's do it the safer way for
&gt; now, to get the answers we are looking for now; and if later we decide we
&gt; want more detailed answers, we still have the original bridge descriptors,
&gt; and we can publish slightly less sanitized data at the point we decide
&gt; we should".
&gt; 
&gt; I'm not sure there's a clear answer, but my instinct is to go for B.

Okay. I went for B by taking the hash of the bridge's IP address plus a
fixed secret string that I use for all bridges. I'm still hesitant to
publish these descriptors, though. We might be giving away too much by
including the bridge's country code (which can be a country with only
very few IP addresses) plus H(IP address + secret)[:4]. Maybe we should
do H(IP address + bridge identity + secret)[:4] or something.

In any case, I'm tempted not to update all the sanitized bridge
descriptors, but only those for December 2009 and January 2010 which I'm
using in the bridge-stability analysis. (I pondered using some 2008
descriptors, but they aren't as meaningful for the current bridge
stability situation.) How about I do the H(IP address + bridge identity
+ secret)[:4] thing and make these two tarballs available?

&gt;&gt; Note that only the first 4 bytes of the result are used, because the
&gt;&gt; result is written as the bridge's IP address, covering the entire range
&gt;&gt; between 0.0.0.0 and 255.255.255.255. Of course, there's a reasonable
&gt;&gt; chance for collisions for a bridge identity with two different IP
&gt;&gt; addresses.
&gt; 
&gt; Right -- the birthday paradox brings us to "once we've looked at 65k
&gt; addresses, we should expect a collision".

Should be fine. Even if such a collision happens, it doesn't
significantly affect the analysis result.

&gt;&gt; But I want the network status to contain all relevant
&gt;&gt; information rather than re-assembling network status entries and bridge
&gt;&gt; descriptors (which could contain more information in their contact
&gt;&gt; line). Are there better ways to add 20 bytes to the network status? We
&gt;&gt; might still add the full hash to the descriptor's contact line.
&gt; 
&gt; So far we've been trying to make sure that the sanitized descriptors
&gt; we publish still happen to conform to dir-spec.txt. At some point this
&gt; technique is going to break down. We shouldn't be too afraid to abandon
&gt; that technique when it gets too burdensome, so long as we still give
&gt; people tools that can parse whatever format we publish.

True. So far it works okay. I'm trying to conform to dir-spec.txt as
long as possible. The tools I'm giving to people should already be less
complex, not more.

Thanks!
--Karsten
</body></email><email><emailId>20100310162921</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2010-03-10 16:29:21-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

On Wed, Mar 10, 2010 at 03:20:24PM +0100, Karsten Loesing wrote:
&gt; On 3/10/10 12:39 AM, Roger Dingledine wrote:
&gt; &gt; On Mon, Feb 15, 2010 at 09:05:54PM +0100, Karsten Loesing wrote:
&gt; &gt;&gt;&gt;&gt; However, I cannot take
&gt; &gt;&gt;&gt;&gt; changing IP addresses into account for this analysis, because I removed
&gt; &gt;&gt;&gt;&gt; the IP addresses when sanitizing the bridge descriptors.
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; What's the process by which we sanitize them? It seems that a fine
&gt; &gt;&gt;&gt; solution would be to hash the IP addresses keyed with a secret that
&gt; &gt;&gt;&gt; remains constant across the hashes. So you could tell if the IP addresses
&gt; &gt;&gt;&gt; are the same without being able to tell what they are. The main challenge
&gt; &gt;&gt;&gt; there is keeping the secret somewhere secret in between batches (and
&gt; &gt;&gt;&gt; maybe rotating the secret monthly, for some level of forward secrecy).
&gt; &gt;&gt;
&gt; &gt;&gt; Yes, we can do something like that. I assume that it'll keep my server
&gt; &gt;&gt; busy for a day or two to parse all the descriptors once more. But I can
&gt; &gt;&gt; do that.
&gt; &gt;&gt;
&gt; &gt;&gt; Instead of the secret input to the hash function, how about we
&gt; &gt;&gt; concatenate bridge identity and IP address as input? Note that we
&gt; &gt;&gt; don't put the bridge identity in the sanitized descriptor, but only
&gt; &gt;&gt; its hash. That way we'd avoid using a secret that we'll lose or forget
&gt; &gt;&gt; anyway and have something reproducible. To be precise, this is what I
&gt; &gt;&gt; have in mind:
&gt; &gt;&gt;
&gt; &gt;&gt;   sanitized bridge identity = H(bridge identity)
&gt; &gt;&gt;
&gt; &gt;&gt;   sanitized IP address = H(bridge identity + IP address)[:4]
&gt; &gt; 
&gt; &gt; Interesting idea. This approach clearly does leak more information:
&gt; &gt; if you learn the bridge identity at any point, you can guess-and-check
&gt; &gt; past IP addresses for the bridge.
&gt; &gt; 
&gt; &gt; The next question is then: so what? Is that something we want to protect?
&gt; 
&gt; A fine question. I don't think this is something we want to protect. My
&gt; understanding of bridges is that they shall make it hard for an
&gt; adversary to block the entry points to the Tor network. That means we
&gt; shouldn't reveal current bridge IP addresses, nor bridge identities
&gt; which can be used to learn about current and future IP addresses.
&gt; 
&gt; But why should we care about past IP addresses of a bridge? What would
&gt; the adversary---who learns about a bridge identity somehow---do with
&gt; this piece of information? Tell that someone has been using Tor via this
&gt; bridge in the past when connecting to that IP address? Is this something
&gt; we want to protect? That would imply that it's considered a security
&gt; feature that bridges change their IP addresses on a regular basis. What
&gt; about bridges on static IP addresses: when an adversary learns about
&gt; such a bridge, does that mean its past users are more screwed than the
&gt; past users of a bridge on a dynamic IP address?
&gt; 

Much of our motivation for using Tor is because you don't know what
behavior you need to protect so be cautious.  So similarly and purely
speculatively, this means that bridges which are run by people who
moslty didn't want to run public nodes but wanted to help would now
have a public permanently confirmable record connected to something in
the outside world. They weren't signing up expecting to have forward
anonymity in any robust sense (at least I hope not), but without the
record if they run a bridge (say from a static IP that they hold for
an indefinite time) and then decide not to later, unless someone
recorded that bridge usage at the time there is no public record of
their participation. So it's a commitment that is less permanent hence
less scary. If at some point in the future someone finds it useful to
go through and look for IP addresses that have run bridges for
whatever currently unimagined nefarious purpose, then it's better if
that is not available. I'm not saying this trumps using hashed salted,
etc. addresses in some publicly listed directory info for any reason,
not even to compare it to the uses mentioned below. But you asked, so
I tried to come up with an answer.

-Paul


&gt; The question is: What are we trying to protect? I'm happy to protect
&gt; past IP addresses of a bridge if there's a reason to do so. But knowing
&gt; what is worth protecting and what is not would be helpful. After all,
&gt; not publishing any bridge descriptors would give us best protection; but
&gt; that's not what we want.
&gt; 
&gt; &gt; There are two benefits to leaking this information. First, we can generate
&gt; &gt; incremental updates to the sanitized bridge descriptor database, and
&gt; &gt; they will be compatible sanitized-IP-address-wise with the existing
&gt; &gt; database. That makes updates more convenient on our side.
&gt; 
&gt; Yes, not including a monthly changing secret in the hash function makes
&gt; the sanitized descriptors more useful for statistics.
&gt; 
&gt; &gt; Second, it is
&gt; &gt; possible to ask questions about where bridges have been over the space
&gt; &gt; of months, not just inside a given month. It's not clear that we plan
&gt; &gt; to ask those questions right now, though.
&gt; 
&gt; Unclear. I don't think we'll be asking these questions.
&gt; 
&gt; &gt; So the conclusion is either "A) yes, we should do it that way, the
&gt; &gt; information leak is not a big deal", or "B) let's do it the safer way for
&gt; &gt; now, to get the answers we are looking for now; and if later we decide we
&gt; &gt; want more detailed answers, we still have the original bridge descriptors,
&gt; &gt; and we can publish slightly less sanitized data at the point we decide
&gt; &gt; we should".
&gt; &gt; 
&gt; &gt; I'm not sure there's a clear answer, but my instinct is to go for B.
&gt; 
&gt; Okay. I went for B by taking the hash of the bridge's IP address plus a
&gt; fixed secret string that I use for all bridges. I'm still hesitant to
&gt; publish these descriptors, though. We might be giving away too much by
&gt; including the bridge's country code (which can be a country with only
&gt; very few IP addresses) plus H(IP address + secret)[:4]. Maybe we should
&gt; do H(IP address + bridge identity + secret)[:4] or something.
&gt; 
&gt; In any case, I'm tempted not to update all the sanitized bridge
&gt; descriptors, but only those for December 2009 and January 2010 which I'm
&gt; using in the bridge-stability analysis. (I pondered using some 2008
&gt; descriptors, but they aren't as meaningful for the current bridge
&gt; stability situation.) How about I do the H(IP address + bridge identity
&gt; + secret)[:4] thing and make these two tarballs available?
&gt; 
&gt; &gt;&gt; Note that only the first 4 bytes of the result are used, because the
&gt; &gt;&gt; result is written as the bridge's IP address, covering the entire range
&gt; &gt;&gt; between 0.0.0.0 and 255.255.255.255. Of course, there's a reasonable
&gt; &gt;&gt; chance for collisions for a bridge identity with two different IP
&gt; &gt;&gt; addresses.
&gt; &gt; 
&gt; &gt; Right -- the birthday paradox brings us to "once we've looked at 65k
&gt; &gt; addresses, we should expect a collision".
&gt; 
&gt; Should be fine. Even if such a collision happens, it doesn't
&gt; significantly affect the analysis result.
&gt; 
&gt; &gt;&gt; But I want the network status to contain all relevant
&gt; &gt;&gt; information rather than re-assembling network status entries and bridge
&gt; &gt;&gt; descriptors (which could contain more information in their contact
&gt; &gt;&gt; line). Are there better ways to add 20 bytes to the network status? We
&gt; &gt;&gt; might still add the full hash to the descriptor's contact line.
&gt; &gt; 
&gt; &gt; So far we've been trying to make sure that the sanitized descriptors
&gt; &gt; we publish still happen to conform to dir-spec.txt. At some point this
&gt; &gt; technique is going to break down. We shouldn't be too afraid to abandon
&gt; &gt; that technique when it gets too burdensome, so long as we still give
&gt; &gt; people tools that can parse whatever format we publish.
&gt; 
&gt; True. So far it works okay. I'm trying to conform to dir-spec.txt as
&gt; long as possible. The tools I'm giving to people should already be less
&gt; complex, not more.
&gt; 
&gt; Thanks!
&gt; --Karsten

 LocalWords:  confirmible
</body></email><email><emailId>20100401120429</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-04-01 12:04:29-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

Hi everyone,

picking up a discussion from three weeks ago. For those who don't
memorize this discussion (and don't want to read up everything), the
idea was to research bridge stability by looking at sanitized bridge
descriptors and see how long bridges were available after giving them to
clients.

Answering Paul's and Christian's mails first, and showing new results below.

On 3/10/10 5:29 PM, Paul Syverson wrote:
&gt; On Wed, Mar 10, 2010 at 03:20:24PM +0100, Karsten Loesing wrote:
&gt; &gt; On 3/10/10 12:39 AM, Roger Dingledine wrote:
&gt; &gt; &gt; On Mon, Feb 15, 2010 at 09:05:54PM +0100, Karsten Loesing wrote:
&gt; &gt; &gt; &gt; &gt; &gt; However, I cannot take
&gt; &gt; &gt; &gt; &gt; &gt; changing IP addresses into account for this analysis, because I removed
&gt; &gt; &gt; &gt; &gt; &gt; the IP addresses when sanitizing the bridge descriptors.
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; What's the process by which we sanitize them? It seems that a fine
&gt; &gt; &gt; &gt; &gt; solution would be to hash the IP addresses keyed with a secret that
&gt; &gt; &gt; &gt; &gt; remains constant across the hashes. So you could tell if the IP addresses
&gt; &gt; &gt; &gt; &gt; are the same without being able to tell what they are. The main challenge
&gt; &gt; &gt; &gt; &gt; there is keeping the secret somewhere secret in between batches (and
&gt; &gt; &gt; &gt; &gt; maybe rotating the secret monthly, for some level of forward secrecy).
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Yes, we can do something like that. I assume that it'll keep my server
&gt; &gt; &gt; &gt; busy for a day or two to parse all the descriptors once more. But I can
&gt; &gt; &gt; &gt; do that.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Instead of the secret input to the hash function, how about we
&gt; &gt; &gt; &gt; concatenate bridge identity and IP address as input? Note that we
&gt; &gt; &gt; &gt; don't put the bridge identity in the sanitized descriptor, but only
&gt; &gt; &gt; &gt; its hash. That way we'd avoid using a secret that we'll lose or forget
&gt; &gt; &gt; &gt; anyway and have something reproducible. To be precise, this is what I
&gt; &gt; &gt; &gt; have in mind:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; sanitized bridge identity = H(bridge identity)
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; sanitized IP address = H(bridge identity + IP address)[:4]
&gt; &gt; &gt; 
&gt; &gt; &gt; Interesting idea. This approach clearly does leak more information:
&gt; &gt; &gt; if you learn the bridge identity at any point, you can guess-and-check
&gt; &gt; &gt; past IP addresses for the bridge.
&gt; &gt; &gt; 
&gt; &gt; &gt; The next question is then: so what? Is that something we want to protect?
&gt; &gt; 
&gt; &gt; A fine question. I don't think this is something we want to protect. My
&gt; &gt; understanding of bridges is that they shall make it hard for an
&gt; &gt; adversary to block the entry points to the Tor network. That means we
&gt; &gt; shouldn't reveal current bridge IP addresses, nor bridge identities
&gt; &gt; which can be used to learn about current and future IP addresses.
&gt; &gt; 
&gt; &gt; But why should we care about past IP addresses of a bridge? What would
&gt; &gt; the adversary---who learns about a bridge identity somehow---do with
&gt; &gt; this piece of information? Tell that someone has been using Tor via this
&gt; &gt; bridge in the past when connecting to that IP address? Is this something
&gt; &gt; we want to protect? That would imply that it's considered a security
&gt; &gt; feature that bridges change their IP addresses on a regular basis. What
&gt; &gt; about bridges on static IP addresses: when an adversary learns about
&gt; &gt; such a bridge, does that mean its past users are more screwed than the
&gt; &gt; past users of a bridge on a dynamic IP address?
&gt; &gt; 
&gt; 
&gt; Much of our motivation for using Tor is because you don't know what
&gt; behavior you need to protect so be cautious.  So similarly and purely
&gt; speculatively, this means that bridges which are run by people who
&gt; moslty didn't want to run public nodes but wanted to help would now
&gt; have a public permanently confirmable record connected to something in
&gt; the outside world. They weren't signing up expecting to have forward
&gt; anonymity in any robust sense (at least I hope not), but without the
&gt; record if they run a bridge (say from a static IP that they hold for
&gt; an indefinite time) and then decide not to later, unless someone
&gt; recorded that bridge usage at the time there is no public record of
&gt; their participation. So it's a commitment that is less permanent hence
&gt; less scary. If at some point in the future someone finds it useful to
&gt; go through and look for IP addresses that have run bridges for
&gt; whatever currently unimagined nefarious purpose, then it's better if
&gt; that is not available. I'm not saying this trumps using hashed salted,
&gt; etc. addresses in some publicly listed directory info for any reason,
&gt; not even to compare it to the uses mentioned below. But you asked, so
&gt; I tried to come up with an answer.

Okay, I agree with you in that we should keep the IP addresses private.

I have changed the sanitizing process for two months of data as written
in my earlier mail. Specifically, I'm replacing IP addresses with

  H(IP address + bridge identity + secret)[:4]

The resulting "IP address" helps us detect whether a specific bridge has
changed its IP address, but it shouldn't reveal anything else.

Is everyone happy with this approach? If yes, I'll make the tarballs
with December 2009 and January 2010 sanitized bridge descriptors
available after the weekend (April 6).

&gt; &gt; The question is: What are we trying to protect? I'm happy to protect
&gt; &gt; past IP addresses of a bridge if there's a reason to do so. But knowing
&gt; &gt; what is worth protecting and what is not would be helpful. After all,
&gt; &gt; not publishing any bridge descriptors would give us best protection; but
&gt; &gt; that's not what we want.
&gt; &gt; 
&gt; &gt; &gt; There are two benefits to leaking this information. First, we can generate
&gt; &gt; &gt; incremental updates to the sanitized bridge descriptor database, and
&gt; &gt; &gt; they will be compatible sanitized-IP-address-wise with the existing
&gt; &gt; &gt; database. That makes updates more convenient on our side.
&gt; &gt; 
&gt; &gt; Yes, not including a monthly changing secret in the hash function makes
&gt; &gt; the sanitized descriptors more useful for statistics.
&gt; &gt; 
&gt; &gt; &gt; Second, it is
&gt; &gt; &gt; possible to ask questions about where bridges have been over the space
&gt; &gt; &gt; of months, not just inside a given month. It's not clear that we plan
&gt; &gt; &gt; to ask those questions right now, though.
&gt; &gt; 
&gt; &gt; Unclear. I don't think we'll be asking these questions.
&gt; &gt; 
&gt; &gt; &gt; So the conclusion is either "A) yes, we should do it that way, the
&gt; &gt; &gt; information leak is not a big deal", or "B) let's do it the safer way for
&gt; &gt; &gt; now, to get the answers we are looking for now; and if later we decide we
&gt; &gt; &gt; want more detailed answers, we still have the original bridge descriptors,
&gt; &gt; &gt; and we can publish slightly less sanitized data at the point we decide
&gt; &gt; &gt; we should".
&gt; &gt; &gt; 
&gt; &gt; &gt; I'm not sure there's a clear answer, but my instinct is to go for B.
&gt; &gt; 
&gt; &gt; Okay. I went for B by taking the hash of the bridge's IP address plus a
&gt; &gt; fixed secret string that I use for all bridges. I'm still hesitant to
&gt; &gt; publish these descriptors, though. We might be giving away too much by
&gt; &gt; including the bridge's country code (which can be a country with only
&gt; &gt; very few IP addresses) plus H(IP address + secret)[:4]. Maybe we should
&gt; &gt; do H(IP address + bridge identity + secret)[:4] or something.
&gt; &gt; 
&gt; &gt; In any case, I'm tempted not to update all the sanitized bridge
&gt; &gt; descriptors, but only those for December 2009 and January 2010 which I'm
&gt; &gt; using in the bridge-stability analysis. (I pondered using some 2008
&gt; &gt; descriptors, but they aren't as meaningful for the current bridge
&gt; &gt; stability situation.) How about I do the H(IP address + bridge identity
&gt; &gt; + secret)[:4] thing and make these two tarballs available?
&gt; &gt; 
&gt; &gt; &gt; &gt; Note that only the first 4 bytes of the result are used, because the
&gt; &gt; &gt; &gt; result is written as the bridge's IP address, covering the entire range
&gt; &gt; &gt; &gt; between 0.0.0.0 and 255.255.255.255. Of course, there's a reasonable
&gt; &gt; &gt; &gt; chance for collisions for a bridge identity with two different IP
&gt; &gt; &gt; &gt; addresses.
&gt; &gt; &gt; 
&gt; &gt; &gt; Right -- the birthday paradox brings us to "once we've looked at 65k
&gt; &gt; &gt; addresses, we should expect a collision".
&gt; &gt; 
&gt; &gt; Should be fine. Even if such a collision happens, it doesn't
&gt; &gt; significantly affect the analysis result.
&gt; &gt; 
&gt; &gt; &gt; &gt; But I want the network status to contain all relevant
&gt; &gt; &gt; &gt; information rather than re-assembling network status entries and bridge
&gt; &gt; &gt; &gt; descriptors (which could contain more information in their contact
&gt; &gt; &gt; &gt; line). Are there better ways to add 20 bytes to the network status? We
&gt; &gt; &gt; &gt; might still add the full hash to the descriptor's contact line.
&gt; &gt; &gt; 
&gt; &gt; &gt; So far we've been trying to make sure that the sanitized descriptors
&gt; &gt; &gt; we publish still happen to conform to dir-spec.txt. At some point this
&gt; &gt; &gt; technique is going to break down. We shouldn't be too afraid to abandon
&gt; &gt; &gt; that technique when it gets too burdensome, so long as we still give
&gt; &gt; &gt; people tools that can parse whatever format we publish.
&gt; &gt; 
&gt; &gt; True. So far it works okay. I'm trying to conform to dir-spec.txt as
&gt; &gt; long as possible. The tools I'm giving to people should already be less
&gt; &gt; complex, not more.
&gt; &gt; 
&gt; &gt; Thanks!
&gt; &gt; --Karsten


On 3/10/10 7:19 PM, Christian Fromme wrote:
&gt; Hi Karsten,
&gt; 
&gt; First of all, nice analysis!
&gt; 
&gt; On Mon, Feb 15, 2010 at 9:29 AM, Karsten Loesing
&gt; &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; 
&gt; &gt; So, are these good news? Personally, I had expected worse results. During most of \
&gt; &gt; the time, availability is surprisingly high. An 80% chance of the bridges working \
&gt; &gt; even after 96 hours seems fair. That means in 1 out of 5 cases someone needs to \
&gt; &gt; send a second e-mail or make a second website request. We might even think (or \
&gt; &gt; have already thought) about implementing a bridge update functionality where \
&gt; &gt; users go to the bridge authority and exchange their broken bridges for working \
&gt; &gt; ones---as long as at least one of their bridges still works.
&gt; 
&gt; Would it be possible for someone to tell the bridge authority that a
&gt; bridge is down even though it is not? Maybe through a DoS attack? If
&gt; this is the case, maybe this thing should be handled with care or
&gt; otherwise there's a paranoid theoretical way someone could learn all
&gt; bridge addresses.
&gt; 
&gt; A way around that, if it is considered realistic enough, would be to
&gt; tag some bridges 'private' or so and not to give those out with that
&gt; update functionality.

A valid concern. I guess that only a subset of all bridges would be
distributed this way. But I don't want to enter the (interesting) field
of bridge distribution methods here.



Okay, here are the new results, this time with taking IP address changes
into account. The graph shows the fraction of random bridge subsets
(containing 3 bridges, 1 of them running on port 443) that had at least
1 bridge running continuously throughout 6/24/48/96 hours. For example,
a value of 0.9 on the y axis means that 90% of all samples taken at the
date and time on the x axis were useful for another 6/24/48/96 hours.

http://freehaven.net/~karsten/volatile/bridge-stability-ipchange-2010-04-01.png

For comparison between the analysis with and without IP address changes,
here are the two 96 hours lines for both analyses. The red line in the
following graph is equivalent to the purple line in the previous graph.

http://freehaven.net/~karsten/volatile/bridge-stability-96h-2010-04-01.png

So, yes, when we take IP address changes into account, bridge stability
is worse than we thought from the first analysis. But still, it's not as
bad as one might have imagined. Note that the reasons for the drops on
December 11, 23, and 31 are probably problems with the bridge authority,
not with all bridges (I could make the analysis more precise by looking
at self-reported bridge uptimes, if required). That means that the 4
days before those drops are probably too low in the graphs. In this
case, the 96 hours line is between 60% and 90%. Or to rephrase that, in
3 out of 4 cases, people had a working bridge 4 days after requesting
bridge addresses, and the 4th person would have to request another set
of bridges.

I'd like to hear what others say about these results. Am I missing
something? Is "3 out of 4" a horrible result?

Thanks,
--Karsten


</body></email><email><emailId>20100304025220</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-03-04 02:52:20-0400</timestampReceived><subject>Re: Control Spec Addition First Draft</subject><body>

Hey,

my comments inline below.

On Jan 24, 2010, at 1:58 AM, Damian Johnson wrote:
&gt; Hi all. This proposal doesn't seem to be going anywhere so thought I  
&gt; should give it one last nudge before moving on to more worthwhile  
&gt; work. The issue's sticking point seems to be a difference of opinion  
&gt; about what constitutes relay evilness. Nick, Jake, and Sebastian all  
&gt; believe in a hard line stance against any retrieval of connection  
&gt; information (netstat, lsof, etc). I disagree, and think this is  
&gt; harmless unless stored or communicated. Unless this can be resolved  
&gt; I think it's obvious the proposal isn't going anywhere.
&gt;
&gt; Please note that I'm discussing relay to relay connections at the  
&gt; moment. If we can't even agree on that then client and exit  
&gt; connections are a moot point (and besides, I agree they should  
&gt; definitely be hidden from relay operators - personally I think it's  
&gt; the responsibility of client applications like vidalia and arm to  
&gt; scrub this data, but that's a different discussion...).

This seems to change the original intent of the proposal, which was  
(afaiui) to get a listing of all connections from Tor. I wouldn't mind  
doing that at all. It does, however, depend on the implementation of  
proposal 163 (detecting clients), because otherwise Tor itself cannot  
reliably differentiate in all cases.

&gt; Just to be clear I agree this proposal should be killed if it poses  
&gt; a threat to Tor users. However, I don't believe it does and still  
&gt; have yet to hear an example of any sort of threat it aggravates.  
&gt; Without that I'm a bit puzzled at the source of objections. If the  
&gt; chief issue is legal or not wanting to risk the appearance of  
&gt; supporting snooping that's fine (strikes me as political posing if  
&gt; there's no actual benefits to users, but cest la vi).

If you change it to be explicit about the fact that you do not want to  
show exit/guard connections, I think this would be ok. It needs to be  
actually spelt out, though.

&gt; My bias is toward safety for relay operators and I'm glad to see  
&gt; others biased toward user privacy pushing back. Hopefully we'll be  
&gt; able to find something acceptable to all parties concerned but if  
&gt; not it won't be the end of the world. Cheers! -Damian

Just to see if others are interested in moving this along, or if  
everyone wants to kill it.

Sebastian
</body></email><email><emailId>20100305053948</emailId><senderName>Gabriel Burt</senderName><senderEmail>gabriel.burt@gmail.com</senderEmail><timestampReceived>2010-03-05 05:39:48-0400</timestampReceived><subject>Re: A couple of Git ideas: new branches, easier changelogs</subject><body>

On Thu, Mar 4, 2010 at 9:02 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; Here are some options:
&gt;   D) Like C, except recognizing that some commits don't warrant
&gt; independent changelog entries... so we add a way to annotate commits
&gt; (e.g., with a footer line) to say "This doesn't go in the changelog!"
&gt; or "This goes in the changelog in the new features section!"  Only
&gt; unannotated commits would need to get manually triaged.  We'd want a
&gt; little script to massage the git log into a draft changelog.

This option makes sense to me - though I'm not a tor hacker (yet).
Using the git commit message as the ChangeLog (and writing them to be
succinct and readable) has been wonderful in several projects on which
I work.  We tag most of our commits with [topic] at the start of the
first msg line; could maybe use that for the non-ChangeLog-worthy
commits.

Gabriel

</body></email><email><emailId>20100305201929</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-03-05 20:19:29-0400</timestampReceived><subject>Re: A couple of Git ideas: new branches, easier changelogs</subject><body>

On Fri, Mar 05, 2010 at 12:02:08AM -0500, Nick Mathewson wrote:
&gt; So here's what I propose.  We create a new "release-0.2.1" branch
&gt; based on maint-0.2.1, and do all our releases off that branch.  We do
&gt; _all_ bugfixes of 0.2.1 bugs in the maint-0.2.1 branch, which we merge
&gt; into master regularly.  We don't merge maint-0.2.1 directly into
&gt; release-0.2.1, however: instead, we tag it whenever we do a release of
&gt; 0.2.2 from the master branch.  Only once the 0.2.2 version has tested
&gt; for a while do we merge maint-0.2.1 into release-0.2.1.  This way,
&gt; bugfixes get tested for a while in the alpha before they get merged
&gt; into stable, and we don't need to worry about losing track of them.

Works for me. There will be some rough edges as we try it out. For
example, will I find it simplest to have three repositories now rather
than two, each with .git/HEAD pointing to the appropriate branch? Doesn't
sound so bad.

&gt; Not everything can be tested for a long time in the alpha before a
&gt; backport.  Notable exceptions are:
&gt;    1) fixes to bugs that only exist in the stable series
&gt;    2) critical bugs that need to get fixed Right Away.
&gt; 
&gt; For these, we should have a separate branch or two; I'm not sure what
&gt; to call them.
&gt; 
&gt; I think the above plan is an improvement, but I'm sure it's not
&gt; optimal.  Keeping the bikeshed in mind, are there better ideas, or
&gt; ways to do this better?

We had previously used a TODO.021 file to keep track of what patches were
still undergoing testing before the backport. But I guess that approach
made more sense in svn-land than in git-land.

To complicate matters a little bit, we had previously talked of having
two phases of a stable: the first phase is soon after it comes out,
where we backport lots of fixes as we discover them. The second phase
starts a few months in, where we stop backporting all fixes and become
increasingly picky about what we backport -- basically only fixing bugs
that an increasing number of people are affected by, security bugs, and
bugs where functionality used to work for that user but doesn't anymore.

In a sense this idea is orthogonal to the above question about branches.
But in another sense, if we had been sticking to this schedule, we may
not have been motivated to fix our process. :)

Being more picky about what we backport also has the advantage that when
we try to get various distros to update their out-of-date packages in
stable, there are 3 changelog entries rather than 10. The timing usually
lines up too, in that we generally only find ourselves trying to get
people to update once the stable has been stable for a long time.

Speaking of best practice, the only way that this scheme is going to work
well is if I pick up the pace on releasing developent versions. And if
I do that, it will also help resolve some of the problems that required
us to be thinking about a third branch. So, I should do that. And you all
should encourage me to. :)

Here's a scenario I expect to happen: we have 15 items in maint-0.2.1,
5 of which are in release-0.2.1. Then we realize one of the remaining 10
is more urgent than we thought, and it's time for a stable release that
includes that patch even though it hasn't been in a development release
"long enough". So we cherry-pick it from maint-0.2.1 to release-0.2.1,
examine it very carefully, and release?

But even in that scenario, I agree it's better to not have all 15 items,
9 of which are not tested well, in the branch that we try to release.

&gt;    B) Instead of creating a changelog entry, commits that want to add
&gt; something to the changelog should add a file to a "changes" directory,
&gt; whose elements get concatenated into a changelog before a release.
&gt; [weasel suggested this one.]
&gt;    C) Commit messages should try to be written so they themselves can
&gt; be turned into changelog entries.  To generate a changelog, just run
&gt; git log previous-release..master and massage the output.
&gt;    D) Like C, except recognizing that some commits don't warrant
&gt; independent changelog entries... so we add a way to annotate commits
&gt; (e.g., with a footer line) to say "This doesn't go in the changelog!"
&gt; or "This goes in the changelog in the new features section!"  Only
&gt; unannotated commits would need to get manually triaged.  We'd want a
&gt; little script to massage the git log into a draft changelog.
&gt; 
&gt; B and D seem like our best options to me.  B has the advantage that
&gt; it's easier to add or massage changelog entries between adding them
&gt; and the release; D has the advantage that we can't _forget_ to add a
&gt; changelog entry for anything.

I like B's advantage: I can incrementally prepare the changelog for
an upcoming release whenever I want to, not just at release time. And
then mere humans (aka those not using git) can see that in-progress
changelog too.

It's also my experience that people write better changelog entries when
they know they're writing a changelog entry. Writing a git commit message
is not writing a changelog entry. We could train ourselves to think of
them as the same thing, but training our developers to become different
is always harder than it sounds.

That said, we won't just be concatenating them in any case. People will
have to say what section of the changelog their text should go in, e.g.:
  o Minor bugfixes:
    - Work correctly out-of-the-box with even more vendor-patched versions
      of OpenSSL. In particular, make it so Debian and OS X don't need
      customized patches to run/build.

But that doesn't sound so bad.

Choice D would be a good choice if we were all developers, and all our
users who read the changelog were developers too. Everybody would want
to know the commit messages. I can imagine that's the case for the Linux
kernel. But that stopped being the case for Tor several years back.

--Roger

</body></email><email><emailId>20100203231303</emailId><senderName>Carsten_Krüger</senderName><senderEmail>c.krueger@gmx.org</senderEmail><timestampReceived>2010-02-03 23:13:03-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

Hello,

it's questionable is SPDY is usefull at all.

Normally only few things changes if you visit a website seconds time
(stylesheets, javascriptlib, pics, etc. are static).
They are not delivered two times via http because they are cached in
browser.
SPDY didn't support any caching so a client that visits websites more
than once has to load everything again. Very bad.

If the caching problem isn't solved SPDY via tor would be worse than
http I think.

greetings
Carsten

</body></email><email><emailId>20100204205423</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-02-04 20:54:23-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

Hi Carsten,

On Thu, Feb 04, 2010 at 12:13:03AM +0100, Carsten Krüger wrote:
&gt; it's questionable is SPDY is usefull at all.

Google's benchmarks show a ~50% speed-up, and better performance in
high-latency environments. Using it in the way I suggested is
different from Google's tests, so I am not certain how much an
improvement SPDY would give, but I would like to perform some
experiments before dismissing it.

&gt; Normally only few things changes if you visit a website seconds time
&gt; (stylesheets, javascriptlib, pics, etc. are static).
&gt; They are not delivered two times via http because they are cached in
&gt; browser.
&gt; SPDY didn't support any caching so a client that visits websites more
&gt; than once has to load everything again. Very bad.
&gt; 
&gt; If the caching problem isn't solved SPDY via tor would be worse than
&gt; http I think.

SPDY is a transport layer for HTTP, and so has no effect on caching.
All the Cache-Control parameters supported by HTTP work with SPDY.
Browsers don't need to change their caching behaviour either.

Server push does need to be handled carefully with respect to caching,
because it would be silly to push a resource to a client, when the
client has a copy. However, all the other features of SPDY should work
just as well with caching on as with it off.

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/
</body></email><email><emailId>20100204221428</emailId><senderName>Carsten_Krüger</senderName><senderEmail>c.krueger@gmx.org</senderEmail><timestampReceived>2010-02-04 22:14:28-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

Hello Steven,

&gt; Google's benchmarks show a ~50% speed-up, and better performance in

Google didn't benchmark loading the same side twice.

&gt; SPDY is a transport layer for HTTP, and so has no effect on caching.

Wrong, SPDY didn't now If-Modified-Since_Header and sends all data
everytime.

From the FAQ of SPDY:
Caching
Since we're proposing to do almost everything over an encrypted channel, we're making \
caching either difficult or impossible. We've had some discussions about having a \
non-secure, static-only content channel (where the resources are signed, or \
cryptographic hashes of the insecure content are sent over a secure link), but have \
made no headway yet...

&gt; Server push does need to be handled carefully with respect to caching,

The Server pushes everything

greetings
Carsten


</body></email><email><emailId>20100204222419</emailId><senderName>Camilo Viecco</senderName><senderEmail>cviecco@anml.iu.edu</senderEmail><timestampReceived>2010-02-04 22:24:19-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

Hello Steven

SPDY would probably achieve little improvements at all.
The primary problem with latency withing Tor is that:
1. the network keeps to much data inside it
2. Multiple streams (of different latency requirements) are
multiplexed over the same TCP connection.

Because of 2, the latency of each connection is dominated
by the internal TCP buffering of the most BW aggresive stream.
SPDY would not solve this issue.

The only mechanism to solve this is to change the
internal transport level of Tor so that the OR behave in a similar
manner to IP routers. I am aware of four approaches to solve this.

1. TCP over DTLS for Tor by Joel Reardon. This approaches
reusees the TOR protocol using UDP+TLS. There are per circuit per
hop userland TCP stacks to solve reordering/loss issues. Would
be great bu requries large amounts of memory per circuit per stack.
There is no downloadable source code (If anyone has it and is allowed
to share it, please post the link).

2.  UDP-OR by Camilo Viecco (yours truly). Uses a UDP for all connections.
A single TCP stream is build from each application at the client to
a socks server residing on the exit node. Uses minimal resources, but
exposes the clients TCP stack to the exit node as currently implemented.
Source code is available at: http://code.google.com/p/tdor/
a running testbed also exists. (Stats at:
http://nettrust1.ucs.indiana.edu/perl/tdor-status2.pl).

3. IPSEC+NAT OR by Csaba Kiraly. Uses IPSEC for encryption and
NAT to create the illusion of circuits (very nice). But uses IPSEC
(ugly, su level required) and
leaks the packet information to every node (there is no packet padding).
I do not have any links for the source code (again links would be
appreciated).

4. The neverending request for SCTP. This would require custom
encryption at the SCTP level
and would not traverse most NATs. But in theory would solve the problem.

Any of these approaches solve the problem better than SPDY, Tor problems are
network problems that require a network level solution. Transport level
solutions
cannot solve any of the issues.

I would prefer an HTTP proxy server advertised by the exit nodes than a
SPDY proxy.
(but who knows if there is enough time-space locality for the requests 
any caching to be useful).


Camilo




On 02/04/2010 03:54 PM, Steven J. Murdoch wrote:
&gt; Hi Carsten,
&gt;
&gt; On Thu, Feb 04, 2010 at 12:13:03AM +0100, Carsten Krüger wrote:
&gt;   
&gt;&gt; it's questionable is SPDY is usefull at all.
&gt;&gt;     
&gt; Google's benchmarks show a ~50% speed-up, and better performance in
&gt; high-latency environments. Using it in the way I suggested is
&gt; different from Google's tests, so I am not certain how much an
&gt; improvement SPDY would give, but I would like to perform some
&gt; experiments before dismissing it.
&gt;
&gt;   
&gt;&gt; Normally only few things changes if you visit a website seconds time
&gt;&gt; (stylesheets, javascriptlib, pics, etc. are static).
&gt;&gt; They are not delivered two times via http because they are cached in
&gt;&gt; browser.
&gt;&gt; SPDY didn't support any caching so a client that visits websites more
&gt;&gt; than once has to load everything again. Very bad.
&gt;&gt;
&gt;&gt; If the caching problem isn't solved SPDY via tor would be worse than
&gt;&gt; http I think.
&gt;&gt;     
&gt; SPDY is a transport layer for HTTP, and so has no effect on caching.
&gt; All the Cache-Control parameters supported by HTTP work with SPDY.
&gt; Browsers don't need to change their caching behaviour either.
&gt;
&gt; Server push does need to be handled carefully with respect to caching,
&gt; because it would be silly to push a resource to a client, when the
&gt; client has a copy. However, all the other features of SPDY should work
&gt; just as well with caching on as with it off.
&gt;
&gt; Steven.
&gt;
&gt;   

</body></email><email><emailId>20100205113545</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-02-05 11:35:45-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

On Thu, Feb 04, 2010 at 11:14:28PM +0100, Carsten Krüger wrote:
&gt; &gt; SPDY is a transport layer for HTTP, and so has no effect on caching.
&gt; 
&gt; Wrong, SPDY didn't now If-Modified-Since_Header and sends all data
&gt; everytime.

SPDY supports all HTTP headers. What web servers do with them varies,
but Apache with SPDY support does the same as it does with normal TCP.

&gt; From the FAQ of SPDY:
&gt; Caching
&gt; Since we're proposing to do almost everything over an encrypted channel, we're \
&gt; making caching either difficult or impossible. We've had some discussions about \
&gt; having a non-secure, static-only content channel (where the resources are signed, \
&gt; or cryptographic hashes of the insecure content are sent over a secure link), but \
&gt; have made no headway yet...

They are referring to a transparent proxy, not in-browser caching. In
any case, we wouldn't use SSL because Tor encrypts data anyway.

&gt; &gt; Server push does need to be handled carefully with respect to caching,
&gt; 
&gt; The Server pushes everything

Server push is still experimental, and not implemented as far as I
know.

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/


</body></email><email><emailId>20100205160358</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-02-05 16:03:58-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

&gt; 3. Design outline
&gt;
&gt;   One way to implement the SPDY proxy is for Tor exit nodes to
&gt;   advertise this capability in their descriptor. The OP would
&gt;   then preferentially select these nodes when routing streams
&gt;   destined for port 80.
&gt;
&gt;   Then, rather than sending the usual RELAY_BEGIN cell, the OP
&gt;   would send a RELAY_SPDY_BEGIN cell, to indicate that the exit
&gt;   node should translate between SPDY and HTTP. The rest of the
&gt;   connection process would operate as usual.
&gt;
&gt;   There would need to be some way of elegantly handling non-HTTP
&gt;   traffic which goes over port 80.

I think there's a more generic mechanism lurking in the wings here.
SPDY is only one of several possible exit-side optimizing techniques
that might exist, and it seems overkill to add a new relay cell type
for each one we want to play with.  I'd suggest that instead, the
begin cell should tell the exit what kind of traffic transformation it
ought to perform, if any.  This could either be a new field in the
standard begin cell format, or it could be a new
RELAY_BEGIN_somethingorother cell type.

(As Scott mentioned in another thread, it is indeed a pretty basic
requirement that exits should not modify the streams they relay
without being asked.  However, there's nothing that says we can't add
a facility for asking them.)

Of course, if we aren't careful, this could partition clients.  We
need to make sure that any transformations we support on a
non-experimental basis  are going to be used by a pretty large
proportion of the userbase, or else users will risk standing out.

On performance: experiment seems like our best bet for seeing whether
and to what extent this actually helps in practice.


-- 
Nick

</body></email><email><emailId>20100602214738</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2010-06-02 21:47:38-0400</timestampReceived><subject>Re: (FWD) TLS False Start</subject><body>

On Wed, Jun 2, 2010 at 12:42 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; Forwarding for Adam.
&gt;
&gt; Any nice volunteer want to play with combining this with Tor?

While I'm on the subject, I'm probably going to send the OpenSSL patch
for nextprotoneg[1] upstream tomorrow.

This allows an application level protocol to be negotiated with the
TLS handshake. For example, a server could run a standard HTTPS server
on port 443 and also have that same port serve Tor when requested.

The server may choose to advertise Tor support in its handshake (in
the clear) or it may not and the Tor client can still request the Tor
protocol. The client's request is encrypted (and padded to a constant
length).

If that's interesting, let me know.



AGL


[1] http://tools.ietf.org/html/draft-agl-tls-nextprotoneg-00

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
</body></email><email><emailId>20100603091624</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-06-03 09:16:24-0400</timestampReceived><subject>Re: Implementing proposal 147: Eliminate the need for v2 directories in generating v3 directories</subject><body>


On May 18, 2010, at 11:18 AM, Karsten Loesing wrote:
&gt; Phase 0: Set up PuppeTor test case to show that it's broken
&gt;
&gt; - Set up 3 v3 directory authorities and 1 relay. Configure the relay
&gt; with only 1 of the directory authorities. Watch how the relay is not
&gt; contained in the first consensus, but in the second.

This is working reliably now.

&gt; Phase 1: Authorities generate opinions (and ensure they can parse  
&gt; them)
&gt; when we ask them to do so
&gt;
&gt; - Write code to generate and parse v3 opinions, including unit tests.
&gt;
&gt; - Add a new URL for everyone to request the current v3 opinion of an
&gt; authority. Requesting this URL triggers the opinion-generating code.

See note on caching, if generation is expensive this is an easy dos.

&gt; - Ponder caching our own v3 opinion for up to X minutes or until we
&gt; learn about a change in descriptors.

Caching until something about a descriptor changes sounds like the
best idea to me, unless opinion generation turns to to be expensive.

&gt; There could be a phase 4 that includes caching other authorities'
&gt; opinions to overcome the situation when both uploading and requesting
&gt; between two authorities fails. It's marked as MAY in the proposal, and
&gt; I'm not sure if we really need it. We could decide this at a later  
&gt; point.

I think we don't really need to worry about this now, especially since
the vote collection is only done once per hour. Instead, phase 4 to
me means that we should get clients with the appropriate config
options (FetchDirInfoExtraEarly) set to query authorities regularly
for their opinion documents and ensure that the appropriate
events are triggered that allow services like TorBEL and friends
to have an up-to-date view of the network.
</body></email><email><emailId>20100603140629</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-06-03 14:06:29-0400</timestampReceived><subject>Re: Orbot bugs and an upcoming Market release</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Thanks for the review, Jake. I will take a look through trac and start
tackling the remaining issues.

On 5/26/10 11:36 AM, Jacob Appelbaum wrote:
&gt; Hi Nathan,
&gt; 
&gt; I think that we're pretty close to having a reasonable Orbot package for
&gt; release into the Android Market. Sebastian and I had a conversation
&gt; about outstanding bugs; we came up with pretty short list of bugs that
&gt; are important for a public release.
&gt; 
&gt; This bug is largely about cosmetic documentation. Orweb (or Fennec, etc)
&gt; will make it largely irrelevant (I've closed it):
&gt; https://trac.torproject.org/projects/tor/ticket/1280
&gt; 
&gt; This bug is insanely complicated with many interesting sub points.
&gt; Sadly, it's impossible to address the issues because they're just one
&gt; giant bug. I've closed it and I think some should open bugs for each issue:
&gt; https://trac.torproject.org/projects/tor/ticket/1284
&gt; 
&gt; This bug is probably a blocker for release. We should catch that Tor is
&gt; unhappy and abort, perhaps reverting to a good config:
&gt; https://trac.torproject.org/projects/tor/ticket/1286
&gt; 
&gt; This bug has been fixed (I've closed it):
&gt; https://trac.torproject.org/projects/tor/ticket/1336
&gt; 
&gt; All the best,
&gt; Jake
&gt; 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.8 (Darwin)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkwHtt8ACgkQSYqeNxz0/Bx6MgCeNDAOBaYW+On6mTZoyXCaXSMH
niwAmwfKuLZ3sxI6cJfQnsXRxLPcprFK
=qcFY
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100604130505</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-06-04 13:05:05-0400</timestampReceived><subject>Re: concurrent circuits for traffic fragmentation</subject><body>

On Thu, Jun 03, 2010 at 11:13:41PM -0400, mansourmoufid@gmail.com wrote 1.4K bytes in \
32 lines about: : While Tor makes no claims of protecting unencrypted traffic at and
&gt; past exit nodes, it should be possible to mitigate the threat of
&gt; sniffing to a certain degree by fragmenting traffic. What I mean by
&gt; that is that a Tor client should be able to use more than one circuit
&gt; in the network at a time. For example, if a PDF file is downloaded
&gt; through Tor, half of it could pass through one exit node, and the
&gt; other through a second.

I think the first sentence is the problem to address.  Users should
encrypt their traffic on the Internet.  This should be true regardless
of transport mechanism; Tor, smtps, imaps, pop3s, https, etc.    

We tried to discourage some non-encrypted protocols over Tor by setting
WarnPlaintextPorts to 23, 109, 110, 143 by default.  Hopefully, this has
stopped people from giving out their login credentials to anyone on the
Internet (whether tor, wifi, etc).  

I don't expect tcp to protect my traffic, therefore I don't expect Tor
to do it either.  

See
https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TorFAQ#Youshouldspliteachconnectionovermanypaths.
 for a more direct answer to your suggestion.

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject


</body></email><email><emailId>20100611211309</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-06-11 21:13:09-0400</timestampReceived><subject>Re: [or-cvs] [PATCH] Create a sample bridge configuration torrc.</subject><body>

On Thu, 10 Jun 2010 12:04:22 -0400
Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt; 1) It looks like we're setting ControlPort without setting any other
&gt; control port authentication lines? That is a bad move security-wise:
&gt; any java or flash applet that runs on the same computer and can play a
&gt; cross-domain trick lets you reconfigure our Tor.

As you've seen, this is fixed.  The control port is now commented out
altogether.  I missed a # somehow.

&gt; 2) Vidalia has a nice trick where your ORPort defaults to 443 on
&gt; Windows but 9001 on Unix. That way we have more of our bridges on
&gt; 443, but we don't force you to deal with binding a low-numbered port
&gt; on operating systems that care.
&gt; 
&gt; Speaking of which: if this bridge torrc is designed to be used with
&gt; bundles that include Vidalia, what happens when Vidalia saves a config
&gt; change? Does it clobber the torrc changes, and you silently stop being
&gt; a bridge? Or does Vidalia read in the torrc lines and synchronize its
&gt; internal config to what Tor says it wants to be?

Actually, separate the two topics.  This is a torrc for those that only
want to run Tor without anything else.  If you have vidalia, use
vidalia to configure your bridge.


&gt; 3) Bridges don't need to set DirPort, and they probably shouldn't if
&gt; they want to remain more subtle. No real harm; but another benefit to
&gt; leaving DirPort unset is that people wrestling with their port
&gt; forwarding won't have to wrestle quite as much.

If you are already reconfiguring your router/nat device for one port
forwarding, doing so for another port isn't any more difficult.
However, not running dirport is fine with me too.


-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20100629150136</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-06-29 15:01:36-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>

On Mon, Jun 28, 2010 at 6:08 PM, Paul Syverson
&lt;syverson@itd.nrl.navy.mil&gt; wrote:
&gt; On Mon, Jun 28, 2010 at 05:59:07PM -0400, Nick Mathewson wrote:
&gt;&gt; On Thu, Jun 24, 2010 at 1:34 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;&gt; &gt; Hi Nick. Thanks for the comments!
&gt;&gt; &gt;
&gt;&gt; &gt;&gt; * IN_TYPE/OUT_TYPE talk about the type of an inbound/outbound
&gt;&gt; &gt;&gt; "connection."  Do you mean circuits, or connections on the circuits?
&gt;&gt; &gt;&gt; Either way I'm confused.  For example, a control connection is never
&gt;&gt; &gt;&gt; attached to a circuit at all.
&gt;&gt; &gt;
&gt;&gt; &gt; Yea, that isn't really appropriate and was making the spec messier than it
&gt;&gt; &gt; needed to be. Replaced with a single TYPE parameter to indicate the
&gt;&gt; &gt; placement in the circuit (guard/bridge, relay, exit, or one-hop in case
&gt;&gt; &gt; they're allowing them).
&gt;&gt;
&gt;&gt; Hm.  But we don't necessarily know this.  Our "are we client-facing"
&gt;&gt; tests are approximate, not certain, and the only way to tell whether
&gt;&gt; we're intermediate or exiting is to wait and see if we're told to
&gt;&gt; exit.  In fact, the leaky-pipe topology means that we're potentially
&gt;&gt; intermediate _and_ exiting on a single circuit.
&gt;
&gt; Wah. I know I'm well out of the development loop, but is leaky-pipe
&gt; topology ever currently used and if so for what?

Well, I said "potentially". ;) The servers support it, but I don't
believe we use it.  If we did, it would probably be for fetching
directory info from a guard that happens also to be a cache, or
something like that.

-- 
Nick

</body></email><email><emailId>20100504194308</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-05-04 19:43:08-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently facing</subject><body>


Thus spake Roger Dingledine (arma@mit.edu):

&gt; My intuition is that a huge amount of it was going to openssl buffers.
&gt; When you have 20k TLS connections open, that's 37k*20k = 740 megs of
&gt; ram just sitting idle in openssl.

Out of curiosity, would this issue likely be alleviated by a switch to
UDP+DTLS, or would the same amount of OpenSSL buffering be required,
despite the fact that we'd be using significantly less sockets?

&gt; &gt; Perhaps we need to
&gt; &gt; limit the amount that we up-rate any router's bandwidth, or perhaps we
&gt; &gt; need to find a way for a router to signal that it's running into load
&gt; &gt; troubles and get downrated.
&gt; 
&gt; Mike pushed back in the tor-relays thread about my suggestion of
&gt; capping the amount of attention we give to any router. That approach
&gt; will apparently really reduce the performance gain we can get.
&gt; 
&gt; It would be great to reduce the weightings for relays that are failing --
&gt; but it's hard to remotely detect "about to fail", and "actually failed"
&gt; usually comes in the form of a down relay.

I pushed back for a couple of reasons, actually. I believe that
requiring relay operators to tweak configs to advertise their capacity
is not a scalable or ideal solution. Any nob we give them is likely to
be a hack that will require black magic and/or keen intuition to use
properly. It would be much better to find a way to measure their
capacity issues in terms of memory or fds.

For example, is it possible that we can alter the relay code to stop
accepting TLS connections when the total tor memory and fd usage
approaches some limit, ideally a limit based on ulimits, available OS
memory, and/or total physical memory?

If we can get Tor to degrade by failing connections, we can measure
this failure rate using the scanners or even a distributed approach
like EigenSpeed and calculate appropriate capacity adjustments using
it. We should be measuring reliability anyways, to protect against
attacks like the one in Borisov et al's "Denial of Service or Denial
of Security" paper.



-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100504210753</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-05-04 21:07:53-0400</timestampReceived><subject>Re: The long anticipated move from Flyspray...</subject><body>


Thus spake Erinn Clark (erinn@torproject.org):

&gt; - Beat it up a little and tell me if you find bugs!

The file attachments seem to have failed to import properly. Links
exist for my attachments from the old flyspray bugs, but the files are
404ing. 

Example bug:
https://trac.torproject.org/projects/tor/ticket/1335



-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100507132733</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-07 13:27:33-0400</timestampReceived><subject>Re: Using GnuTLS rather than OpenSSL</subject><body>

On Fri, May 07, 2010 at 12:06:16PM +0200, Linus Nordberg wrote:
&gt; In a discussion about memory consumption (buffers) with Roger and Jake,
&gt; the question of GnuTLS as an alternative to OpenSSL came up.

Check out src/common/crypto.[ch] and src/common/tortls.[ch]

Once upon a time these were good clean abstractions over openssl, meaning
they are the only files that need to change if you switch from openssl
to some other crypto lib.

I say 'once upon a time' because I just looked over them again and they
sure seem to have grown messier since they started. :(

&gt; One of the things mentioned was the purported lack of support for
&gt; ephemeral Diffie-Hellman in GnuTLS.  Since we have its current
&gt; maintainer (and, I think, main developer) at arm's reach here I think we
&gt; should take the opportunity of meeting with him and discuss this before
&gt; Roger leaves Stockholm.
&gt; 
&gt; I don't know what Tor needs so I couldn't really judge whether existing
&gt; functionality would suffice:

Sounds good. I vaguely recall that in the early 2000s it was missing
server-side EDH. That could have been the Netscape crypto lib that I'm
thinking of though. Nick did those investigations and they are likely
now lost in the depths of time (plus hopefully obsolete).

--Roger

</body></email><email><emailId>20100510141716</emailId><senderName>Christian Kujau</senderName><senderEmail>lists@nerdbynature.de</senderEmail><timestampReceived>2010-05-10 14:17:16-0400</timestampReceived><subject>Re: [or-dev] Re: Tor hardening at compile time</subject><body>

On Sat, 8 May 2010 at 16:09, Jacob Appelbaum wrote:
&gt; &gt; configure: error: C compiler cannot create executables
&gt; 
&gt; Can you try that again but this time without '--enable-linker-hardening'
&gt; in your ./configure configuring? We can't support linker hardening for
&gt; ELF and Mac OS X uses the Mach-O binary format.

Same message on Linux/powerpc32, config.log has:

configure:2930: gcc  -D_FORTIFY_SOURCE=2 -fstack-protector-all -fwrapv 
-fPIE -Wstack-protector -Wformat -Wformat-security -Wpointer-sign  
-I${top_srcdir}/src/common  -pie -z relro -z now conftest.c  &gt;&amp;5
gcc: relro: No such file or directory
gcc: now: No such file or directory
configure:2933: $? = 1

However, other posts[0] seem to suggest that it's indeed a linker issue 
and only supported with binutils &gt;= 2.20, while my Debian/stable here is 
still on 2.18.

Without --enable-linker-hardening Tor can be built:

# ./configure --prefix=/opt/tor
No RELRO   No canary found   NX enabled    No PIE      /opt/tor/bin/tor

# ./configure --prefix=/opt/tor --enable-gcc-warnings --enable-gcc-hardening
No RELRO   Canary found      NX enabled    PIE enabled   src/or/tor

Although NX is marked "enabled", my CPU does not support NX.

Thanks,
Christian.

[0] http://readlist.com/lists/gcc.gnu.org/gcc-help/3/18416.html
-- 
BOFH excuse #226:

A star wars satellite accidently blew up the WAN.
</body></email><email><emailId>20100510154432</emailId><senderName>Martin Mulazzani</senderName><senderEmail>e0225055@student.tuwien.ac.at</senderEmail><timestampReceived>2010-05-10 15:44:32-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

Zitat von Karsten Loesing &lt;karsten.loesing@gmx.net&gt;:

&gt; On 5/6/10 11:49 AM, Roger Dingledine wrote:
&gt;&gt; On Mon, May 03, 2010 at 06:40:13PM +0200, Martin Mulazzani wrote:
&gt;&gt;&gt; TorStatus is already using the Maxmind GeoLite database.
&gt;&gt;
&gt;&gt; I've been wondering for a while why
&gt;&gt; http://trunk.torstatus.kgprog.com/index.php
&gt;&gt; has so many relays listed as Namibia. They're pretty clearly not in
&gt;&gt; Namibia.
&gt;
&gt; You're right, Torstatus is wrong.
&gt;
&gt; I just resolved the IP addresses from the torstatus output at
&gt; http://trunk.torstatus.kgprog.com/query_export.php/Tor_query_EXPORT.csv
&gt; using Maxmind's free database from May 1. Below you'll find the lines
&gt; where Torstatus and Maxmind disagree.


The GeoIP.dat @ trunk.torstatus... seems to be out of date. On my 
instance  there is currently no relay in Namibia, and my GeoIP.dat is 
from May 1st. http://torstatus.kgprog.com seems to be up2date too.

TorStatus checks for updates of the GeoIP file, and should update 
automatically. Might be a file permission issue at trunk.torstatus...


&gt; Random thought: does Torstatus use "NA" as abbreviation for "not
&gt; available" when resolving IP addresses, but as "Namibia" when choosing a
&gt; flag to display?


Sounds reasonable. If GeoIP returns NA for unknown countries, TorStatus 
should use the nna.gif instead of the na.gif. We will open a ticket for 
that and check it.


&gt; Also, how recent is the GeoIP database that Torstatus, especially
&gt; trunk.torstatus.kgprog.com, uses?
&gt;
&gt; At the end of this mail, you'll also find the Java code to generate this
&gt; output. Put the geoip file from current Tor master and the .csv as
&gt; stated above in the same directory, compile, run.
&gt;
&gt; Best,
&gt; --Karsten
&gt;
&gt;
&gt; First column = Maxmind
&gt; Second column = Torstatus
&gt; Third column = nickname
&gt;
&gt; US NA 0x41414141
&gt; DE NA 0x42FF
&gt; US NA 107167
&gt; RU NA a1s2ew4wfedjhc6je8
&gt; DE NA agitator
&gt; CA NA andromeda
&gt; CA NA anona
&gt; US NA avarner
&gt; PL NA Azhar
&gt; DE NA b215c035618f047d
&gt; SK NA backslash777
&gt; CA US BarkerJrNet
&gt; SK NA BecherovHomeunix
&gt; DE NA bingsFreeNet
&gt; DE NA bmwanon
&gt; CA NA buttercup
&gt; BY NA ByHomenet
&gt; NL NA canon
&gt; US NA canoworms
&gt; NL NA carpetbagger
&gt; DE NA Cerritus
&gt; CA NA chuckthecanuck
&gt; IE NA cupboard
&gt; US NA customer679498
&gt; US NA dametenshi
&gt; DE NA DerAufbruch2
&gt; GB NA deusexmachina
&gt; GB FR devasdfasdf
&gt; DE NA Diega
&gt; US NA DigitalFreedom
&gt; DE FR Dinosaur
&gt; FR NA djiins
&gt; UA NA DLag
&gt; SE NA DVBT
&gt; GB NA DynoTor
&gt; DE FR Edmontosaurus
&gt; DE NA Enigma
&gt; GB NA F00DD00D
&gt; DE NA ferrot04st
&gt; RU NA FFA
&gt; RU FR Fisto
&gt; DE NA flunkey
&gt; DE NA Freedom
&gt; SE FR frogbeard
&gt; DE NA gartentor
&gt; US NA greyunknown
&gt; RU NA GuyRitchie
&gt; UA NA happiness
&gt; CA NA harman2
&gt; RU NA HazarD
&gt; RU NA HellyMotion
&gt; DE IL herecomesthesun
&gt; RU NA hometoorspbru
&gt; US NA hurrdurr
&gt; DE NA HWR
&gt; RU NA IDDQD
&gt; TH NA igor1977
&gt; US NA ihas5cat
&gt; NL NA ItsHiddenYa
&gt; DE IR jefOlewkia
&gt; US NA jetddna
&gt; US NA jujubee
&gt; DE NA justanothernode
&gt; DE NA kaon
&gt; US NA knegg
&gt; GB NA kuzlatko
&gt; US NA lapiste
&gt; GB NA lego
&gt; CA US Link2VoIP
&gt; DE NA LittleMao
&gt; DE NA ljsilver
&gt; US NA lot49
&gt; GB NA MaoUK2
&gt; FR NA matterhorn
&gt; DE NA megaantisanitary1
&gt; TW AU MgeniUser
&gt; DE NA MicsInTrees
&gt; DE NA Mischmaschine
&gt; DE NA mullbinde3
&gt; DE NA nerdsurf
&gt; US NA networkb289be5
&gt; DE NA netzfrei2
&gt; GB IT nixgeek
&gt; US NA nockodotnet
&gt; GB NA node13
&gt; LK NA NSTHome
&gt; US NA oldthink
&gt; IL NA OnionFox
&gt; DE GB OrionTorNode
&gt; HK NA pangu
&gt; CA US Pasquino
&gt; SE NA PPrivComSweden
&gt; GB NA PPrivComUK4
&gt; CZ NA PwNibulikvps83
&gt; DE NA qeki0i7g3kd8tynseg0
&gt; RU LU QLEnDGKmay
&gt; DE NA raf
&gt; US NA RankaLee
&gt; UA NA ReactorRelay
&gt; US NA revo
&gt; TH NA rsquarersharp
&gt; US NA SamuraiPizzaCat
&gt; DE NA SedanUK
&gt; FR NA servicePublic
&gt; CA US Shaft
&gt; MN NA Shaman0
&gt; DE NA shawnthesheep
&gt; DE NA shiven
&gt; US NA singulicity
&gt; DE NA sork
&gt; ID NA speekfree
&gt; US NA srv1esctoulous
&gt; US NA srv3
&gt; US NA srv4
&gt; US NA srv5
&gt; US NA srv6
&gt; US NA stegosaurus
&gt; DE NA Suga23
&gt; US NA SuperDave
&gt; SE NA SwedishBikiniTeam
&gt; SE NA swetzsupertor
&gt; US NA taoppv
&gt; TR GB TinyTurtle
&gt; FR NA ToileLibre
&gt; DE IR Toni
&gt; DE NA TOR2fm1
&gt; GB DK toroftheworld
&gt; DE NA torschlusspanik2
&gt; RO NA trafficlight
&gt; GB NA triczlinode
&gt; TR GB umbrella
&gt; US NA underdonk01
&gt; US NA underdonk02
&gt; US NA Unnamed
&gt; AL NA Unnamed
&gt; AT SE Unnamed
&gt; DE NA Unnamed
&gt; US NA Unnamed
&gt; IR NA Unnamed
&gt; CA NA Unnamed
&gt; DE NA Unnamed
&gt; IR NA Unnamed
&gt; KR NA Unnamed
&gt; JP AU Unnamed
&gt; JP AU Unnamed
&gt; RU NA uran
&gt; GR NA Vagabond2
&gt; GB NA vee
&gt; CA NA Waldo
&gt; DE NA wg362
&gt; US NA wingedgods
&gt; NL NA worldstr989418
&gt; NL NA worldstre0f571
&gt; US NA ydobonobody
&gt; DE NA zermanes
&gt; DE NA Zwiebelschale3
&gt;
&gt;
&gt;
&gt; import java.io.*;
&gt; import java.util.*;
&gt; public class ResolveRelayCountries {
&gt;  public static void main(String[] args) throws Exception {
&gt;    File geoipFile = new File("geoip");
&gt;    File torstatusOutput = new File("Tor_query_EXPORT.csv");
&gt;    BufferedReader br = new BufferedReader(new FileReader(geoipFile));
&gt;    String line = null;
&gt;    SortedMap&lt;Long, String&gt; geoipLines = new TreeMap&lt;Long, String&gt;();
&gt;    while ((line = br.readLine()) != null) {
&gt;      if (line.startsWith("#")) {
&gt;        continue;
&gt;      }
&gt;      geoipLines.put(Long.parseLong(line.split(",")[0]), line);
&gt;    }
&gt;    br.close();
&gt;    br = new BufferedReader(new FileReader(torstatusOutput));
&gt;    br.readLine();
&gt;    while ((line = br.readLine()) != null) {
&gt;      String nickname = line.split(",")[0];
&gt;      String reportedCountryCode = line.split(",")[1];
&gt;      String ip = line.split(",")[4];
&gt;      String[] octets = ip.split("\\.");
&gt;      long ipNum = Long.parseLong(octets[0]) * 256L * 256L * 256L
&gt;          + Long.parseLong(octets[1]) * 256L * 256L
&gt;          + Long.parseLong(octets[2]) * 256L
&gt;          + Long.parseLong(octets[3]);
&gt;      SortedMap&lt;Long, String&gt; subMap = geoipLines.headMap(ipNum + 1L);
&gt;      if (subMap.isEmpty()) {
&gt;        System.out.println("  ?? " + reportedCountryCode + " "
&gt;            + nickname);
&gt;      } else {
&gt;        long intervalStart = subMap.lastKey();
&gt;        String geoipLine = geoipLines.get(intervalStart);
&gt;        long intervalEnd = Long.parseLong(geoipLine.split(",")[1]);
&gt;        if (intervalStart &lt;= ipNum &amp;&amp; intervalEnd &gt;= ipNum) {
&gt;        String countryCode = geoipLine.split(",")[2];
&gt;          System.out.println((countryCode.equals(reportedCountryCode)
&gt;              ? "  " : "* ") + countryCode + " " + reportedCountryCode
&gt;              + " " + nickname);
&gt;        } else {
&gt;          System.out.println("  ?? " + reportedCountryCode + " "
&gt;              + nickname);
&gt;        }
&gt;      }
&gt;    }
&gt;  }
&gt; }
&gt;



</body></email><email><emailId>20100519064132</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-19 06:41:32-0400</timestampReceived><subject>Git fun, or Turning off autocommit when importing descriptors</subject><body>

Hi Kevin,

I'm moving this discussion to or-dev, as it might be of interest for the
other GSoC students, too.

On 5/18/10 6:58 PM, kevin berry wrote:
&gt; I fixed everything in the code, whitespace, javadoc, etc. I reverted my
&gt; master github branch, then created a branch called "autocommit", fixed
&gt; stuff, and then pushed the changes. So my master branch should reflect
&gt; gitweb.torproject.org/ernie.git, and I should do my development in other
&gt; branches? I think I'm finally gitting the hang of it (har har). Thanks for
&gt; the help

In your public repository (http://github.com/kjbbb/ernie) you don't need
a master branch reflecting the official repository
(git://git.torproject.org/ernie). Nobody would pull from it, and it
would be out-of-date most of the time.

You only need to push branches to your public repository that you want
others to look at. Once the changes are in the official repository, you
can delete your public branches using "git push public :somebranch" with
'public' being the name you picked for your public repository and
'somebranch' being the name of your public branch.

Here are some comments on your autocommit branch:

- When I look at the logs using "git log", I see that you didn't set
Author to your full name. You can do this by typing "git config --global
user.name "Kevin Berry"", though this won't be effective for the commits
you already made.

- I also see in "git log -p" that you changed things back and forth.
This is not so nice, because people reading the commit history will have
a hard time figuring out what changes were made. The solution to this
problem is to squash the four commits using "git rebase -i". In general,
be careful with squashing commits that you pushed and asked others to
review, because you're "changing history". But in this case it makes
sense to squash the commits and have a single commit for your change.
Here are the commands I'd use to squash your commits:

$ git rebase -i HEAD~4
Change "pick" in lines 2, 3, and 4 to "squash"
$ git add src/RelayDescriptorDatabaseImporter.java
$ git rebase --continue
Delete all but the 3rd commit message.

You should try squashing the commits in your local branch, just to see
how convenient it is when you do it right. However, in case you're
unhappy with the result, just kick out your last four commits and make a
new one:

$ git reset --soft HEAD~4
$ git commit

- "git log -p" further reveals some unnecessary whitespace in the
Javadoc lines.

Can you fix these things, push a new branch, e.g. "autocommit2" to your
public repository, and let me know it's there?

A lot of trouble for getting a patch in, agreed, but imagine we'd go
through this at the end of summer with all your changes! :)

I bet you'll also enjoy reading
https://gitweb.torproject.org//githax.git?a=blob;f=doc/Howto.txt;h=0a502904ba33ba2778670fd6b513637311e6b5c7;hb=HEAD


Thanks,
--Karsten


</body></email><email><emailId>20100519074446</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-19 07:44:46-0400</timestampReceived><subject>Re: Implementing proposal 147: Eliminate the need for v2 directories</subject><body>

On 5/18/10 3:16 PM, Roger Dingledine wrote:
&gt; On Tue, May 18, 2010 at 11:18:19AM +0200, Karsten Loesing wrote:
&gt;&gt; Sebastian and I think that we really need this proposal to be
&gt;&gt; implemented in Tor soon, because we're running out of v2 authorities.
&gt;&gt; Only 2 of them are still running: tor26 and dizum. Time to get rid of v2.
&gt;&gt;
&gt;&gt; - Set up 3 v3 directory authorities and 1 relay. Configure the relay
&gt;&gt; with only 1 of the directory authorities. Watch how the relay is not
&gt;&gt; contained in the first consensus, but in the second.
&gt; 
&gt; Make sure you use 0.2.2.12-alpha or later for these tests (and for
&gt; directory authorities in general). That's where I added:
&gt;     - Many relays have been falling out of the consensus lately because
&gt;       not enough authorities know about their descriptor for them to get
&gt;       a majority of votes. When we deprecated the v2 directory protocol,
&gt;       we got rid of the only way that v3 authorities can hear from each
&gt;       other about other descriptors. Now authorities examine every v3
&gt;       vote for new descriptors, and fetch them from that authority. Bugfix
&gt;       on 0.2.1.23.
&gt; 
&gt; In short, in the scenario you describe above, in earlier versions they
&gt; only discover new descriptors in the consensus itself, not the votes --
&gt; so since it isn't in the first, nobody else ever learns to fetch the
&gt; descriptor, so it's never in later consensuses either.

Yes, we discovered that somewhat unexpected behavior when setting up the
test case with 3 authorities and a relay knowing only 1 of them. The
authorities started exchanging votes within 1 second of time (depending
on when they enter their 1-second main loop), and if the authority the
relay knows about was first, the others learned about the relay. We
fixed our test case by delaying uploading votes on the first authority
by 5 seconds.

&gt;&gt; - Write code to process v3 opinions. This includes verifying signatures
&gt;&gt; and downloading missing descriptors from the authority that sent the
&gt;&gt; opinion.
&gt; 
&gt; git show 2e692bd8c98c841a
&gt; for how I did the earlier changes.
&gt; 
&gt; I wonder what would happen if we simply generate a vote at :45 and send
&gt; it, and then generate another vote at :50 and send that? It seems like at
&gt; the least we could reuse nearly all of the vote-generating and -parsing
&gt; code. I'll grant that we might want to declare the actual document to
&gt; be something other than a "vote", in case things can go bad when we've
&gt; received two votes from a single authority.

I'm hoping that we can re-use 99% of the vote-generating and -parsing
code. Still, adopting the features in phases might be useful.

&gt;&gt; - Add an opinion-exchanging phase preceding the vote-exchanging phase.
&gt;&gt; With default values, the voting phase is from :50 to :55, so that the
&gt;&gt; opinion phase would be :45 to :50. Add config options to adjust the
&gt;&gt; length of this new phase.
&gt; 
&gt; You'll also like the feature I added in eaf5487d9570fb that makes
&gt; the authority fetch the missing descriptor from the source of the vote
&gt; it's reading (rather than from a random authority).

Yup. Sebastian mentioned that commit and the one above.

Best,
--Karsten
</body></email><email><emailId>20100523184224</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-05-23 18:42:24-0400</timestampReceived><subject>Re: A attack aganist Tor?</subject><body>


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; Thus spake torsecurity (torbridges.security@gmail.com):
&gt; 
&gt; &gt; I use a tor bridge (freedomwithwall) connecting to Tor and it seems
&gt; &gt; doing well. But when I observe ( four) circuits  the Tor created, I
&gt; &gt; find the second and the last tor nodes do not exsit! Their nicknames
&gt; &gt; are not in the cached-descriptors or cached-descriptors.new files.
&gt; &gt; The Vidalia can not show their IPs also, just show the
&gt; &gt; freedomwithwall's IP.
&gt; &gt; 
&gt; &gt; I have never seen this happen before.
&gt; &gt; 
&gt; &gt; Is the bridge freedomwithwall a mallicious node and the middle and
&gt; &gt; exit nodes are fake?
&gt; 
&gt; Barring some serious vulnerability the likes of which we haven't yet
&gt; seen, Tor cannot extend to relays without knowing their public key,
&gt; even if you are using a malicious bridge. At best, a malicious bridge
&gt; can only prevent you from connecting to peers that it doesn't like.
&gt; 
&gt; Most likely this is a bug in Vidalia and/or a race between Tor
&gt; receiving descriptors and updating those cached files.

Right after sending this, Roger reminded me that this bug would have
allowed exactly what you described back in the 0.1.1.x days.
http://archives.seul.org/or/announce/Aug-2005/msg00002.html

So it's not outside of the realm of posibility, but probably is still
on the unlikely side. Keep an eye out, anyways.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100524093826</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2010-05-24 09:38:26-0400</timestampReceived><subject>Re: Translated manpages</subject><body>

On Mon, May 24, 2010 at 11:00 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Mon, May 24, 2010 at 10:41:17AM +0200, Runa A. Sandvik wrote:
&gt;&gt; &gt; Currently tor-manual-dev.wml should be the man page for Tor 0.2.2.x.
&gt;&gt; &gt; You can find it in the latest git head under doc/tor.1.txt, and you
&gt;&gt; &gt; can convert it to html using the combination of git and asciidoc commands
&gt;&gt; &gt; you find in tor-manual-dev.wml.
&gt;&gt; &gt;
&gt;&gt; &gt; Currently tor-manual.wml should be the man page for Tor 0.2.1.x. Since
&gt;&gt; &gt; Tor 0.2.1.x doesn't use asciidoc, you can convert doc/tor.1.in in the
&gt;&gt; &gt; maint-0.2.1 git branch using man2html (as you see in tor-manual.wml).
&gt;&gt;
&gt;&gt; I noticed that they are not actually the same, even though it may look
&gt;&gt; that way. For the translations, I will create one tor-manual.po and
&gt;&gt; one tor-manual-dev.po (in addition to po files for the remaining three
&gt;&gt; manpages).
&gt;
&gt; Our translators might like us more if we don't make them duplicate a
&gt; lot of work for these two po files, which will be mostly the same.

Yep.

&gt; I wonder if that means we should just ask them to translate the
&gt; tor-manual-dev one. Or I wonder if there's a way to take the strings
&gt; and combine them into a single po file for translation. Or to have
&gt; pootle automatically recognize when two strings in two po files got
&gt; the same translations, and fill in the other one as a hint.

I think the best option is to translate just tor-manual-dev. It would
be possible to take the strings and combine then into a single po file
for translation, but this means that I would have to combine
tor-manual and tor-manual-dev into one manpage first. It would be
great if Pootle could automatically recognize when two strings in two
po files got the same translations, but I don't think this is going to
happen soon.

&gt;&gt; &gt; A good question. I think a fine first try is to make a tor-manual.html.de
&gt;&gt; &gt; and tor-manual-dev.html.de in the website root (to go with the
&gt;&gt; &gt; .en ones), and then people who click on the 'Handbuch' links from
&gt;&gt; &gt; torproject.org/documentation.html.de will get the German version.
&gt;&gt;
&gt;&gt; I have that working already, and the only remaining questions is what
&gt;&gt; we should do with the rest of the translated manpages. I guess we
&gt;&gt; could find a way to include them on the website, in the same way we
&gt;&gt; include the manpage for Tor 0.2.2.x and 0.2.1.x.
&gt;
&gt; Right. What exactly are "the rest of the translates manpages"? Are these
&gt; all translations of the main tor man page, or are the other man pages
&gt; translated too?

I figured it would be nice to have translated versions of all the
manpages: tor, tor-gencert, tor-resolve and torify.

-- 
Runa A. Sandvik
</body></email><email><emailId>20100525011525</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-05-25 01:15:25-0400</timestampReceived><subject>Re: Integrating libnatpnp and miniupnpc into Tor</subject><body>

On Mon, May 24, 2010 at 6:04 PM, Steven J. Murdoch
&lt;tor+Steven.Murdoch@cl.cam.ac.uk&gt; wrote:
 [...]
&gt; The first is how the library will be called by Tor. One option is to
&gt; call it from the Tor main thread. This is simple, but has the
&gt; disadvantage that a bug in the library could cause Tor to crash. This
&gt; would annoy the user, but on the other hand a Tor bridge without port
&gt; forwarding being set up isn't much use.
&gt;
&gt; Another option is to fork() off a new process. This would insulate Tor
&gt; from crash bugs, but isn't as robust security-wise because the
&gt; subprocess would have read-only access to Tor's memory (unless we
&gt; fiddle with page table permissions).

Also, on Windows, you can't fork().  You can CreateProcess (which is a
little like vfork+exec), but you need an .exe to call for that.

&gt; Yet another option would be to fork() and exec(). This might be tricky
&gt; to get right because Tor would need to find where the helper program
&gt; lives. It would give some security isolation, but not much because the
&gt; subprocess would still be running under the same user ID.

I prefer this option.  Calling a helper program is a solved problem,
after all, and once they're isolated at a process level, distributors
(or others, or maybe we) could use an OS's existing capabilities
system to isolate it from the rest of Tor.  (For Linux, this would
mean somebody doing the standard selinux magic.  Elsewhere, it might
be running  suid upnp_user.)

At the vary least, running it in a separate process makes it easier to
debug. I don't like the argument that "Tor without a forwarded port
(when needed) is not so useful; therefore it's not so bad for Tor to
just crash whenever there's a crash bug in the UPnP layer."
Remember, an immediate, traceable crash is not the only kind of crash
there is.  There are also lingering crashes that show up in unrelated
parts of the codebase with no apparent relation to their actual cause,
or crashes that show up unanticipated because of shared process
resources.   Pulling these libraries into the Tor process would means
that we'd no longer be able to clearly distinguish all Tor crashes
from port-forwarder crashes, which would make debugging work more than
just a little harder.

&gt; Another choice we have is how to manage the build process. Neither
&gt; miniupnpc or libnatpmp come with binary packages for major Linux
&gt; distributions. Asking people to build these before building Tor might
&gt; be too much to ask (especially given that they don't use autoconf).
&gt; Also we might want to keep the version we use under our own control
&gt; because in the past the library has broken API compatibility and their
&gt; build scripts currently don't work on all platforms (notably the BSD
&gt; family).

I really don't like pulling things into our source-trees except as a
last resort.  Forks are a contingency plan if Tor needs something from
these libraries that we cannot convince the developers to do, but
forks are not free, easy, fun, or polite.  If we truly need to fork,
we should fork cleanly, with the goal being an eventual re-merge,
pushing as many patches as we can upstream, and we should manage the
libnatpnp and miniupnpc code in their own repositories with that goal
in mind.

Even if that re-merge never happens, we should do our forked versions
in separate repositories from Tor so that other people can use them
too.  Otherwise, Tor's version will diverge from Vidalia's, which will
diverge from every other version under the sun.

If possible, building with these libraries should be optional.  Also,
we should get these things packaged for as many OSs as we can.  If Tor
strongly recommends them, that'd probably help.

yrs,
-- 
Nick
</body></email><email><emailId>20100525060242</emailId><senderName>kevin berry</senderName><senderEmail>xckjb88@gmail.com</senderEmail><timestampReceived>2010-05-25 06:02:42-0400</timestampReceived><subject>Re: Database schema for metrics portal</subject><body>

Karsten,

This is all extremely helpful. I certainly won't be able to test with the
full amount of data, but we can get a look at the performance implications
of running queries on both normalized and unnormalized schemas.

As far as a timeline - I think 2 weeks is a fair amount of time for the
schema to be finished. Should I finish early (which has a good chance of
happening), I can begin working on having R work with the database directly,
or making/modifying a descriptor database importer for this schema. I'm
really looking to get the db stuff down for a basis from which we can build
off. We can discuss this when the time comes.

Thanks,
Kevin


On 21 May 2010 07:06, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; Hi Kevin,
&gt; 
&gt; here are some thoughts on importing relay descriptors into a database.
&gt; 
&gt; You may already have noticed that there are three documents holding
&gt; information about a relay in the Tor network: network status entry,
&gt; server descriptor, and extra-info descriptor. In the past, I have used
&gt; three tables and joined them whenever necessary. It turned out that join
&gt; operations are highly inefficient and that it doesn't even make sense to
&gt; join extra-info descriptors with network status entries and server
&gt; descriptors.
&gt; 
&gt; Here's an example. The current network status consensus has this entry
&gt; for gabelmoo:
&gt; 
&gt; r gabelmoo 8gREE9rC4C49a89HNaGbyh3pcoE gL7MFClJBGG6l3KzCXJPh5fQnl8
&gt; 2010-05-21 02:34:42 80.190.246.100 8080 8180
&gt; s Authority Fast Guard HSDir Running Stable Unnamed V2Dir Valid
&gt; v Tor 0.2.2.13-alpha
&gt; w Bandwidth=512
&gt; p reject 1-65535
&gt; 
&gt; 
&gt; The referenced server descriptor gL7MFCl... in base64 or
&gt; 80becc1429490461ba9772b309724f8797d09e5f in hex has this content:
&gt; 
&gt; router gabelmoo 80.190.246.100 8080 0 8180
&gt; platform Tor 0.2.2.13-alpha (git-a3db6300225c5f34) on Linux i686
&gt; opt protocols Link 1 2 Circuit 1
&gt; published 2010-05-21 02:34:42
&gt; opt fingerprint F204 4413 DAC2 E02E 3D6B CF47 35A1 9BCA 1DE9 7281
&gt; uptime 1154088
&gt; bandwidth 512000 1280000 1166966
&gt; opt extra-info-digest CECC7F83F5CD771BF0DF9827C08F561CE84A5DA3
&gt; opt caches-extra-info
&gt; onion-key
&gt; -----BEGIN RSA PUBLIC KEY-----
&gt; MIGJAoGBANbj/L3FZCbIKNdBKMH1tamU/r+9p+X4fI+1i9jDtHt11D4Rz+rsQ4CX
&gt; 8no0NMx2yOHpvq7Cp8scO2ZcH4UjQ/bJIumgGqjuslWMn9KtrbBKdtNzVtOMNjYY
&gt; 7zjZJ8UVmS1/hH2wl2dwZeAVbQ931u9DWX5R/u1ck28EQS8C2Z/jAgMBAAE=
&gt; -----END RSA PUBLIC KEY-----
&gt; signing-key
&gt; -----BEGIN RSA PUBLIC KEY-----
&gt; MIGJAoGBAMjPhp0QAN8WQeP8sDg+mnM7hnPExcXTOfsmt7Sl2k3fHcHeAJnYu10V
&gt; /hb6RBhubi1HRg6fYF5PwZWOppxRj90WX3n2JEcQh88+4tuQNQ2jOxXQ/hBkyf0w
&gt; klrx6Fh8ana1VX+QXInfRW5z3eaANXqvdCvDG5jfUrz6pj8WGPrxAgMBAAE=
&gt; -----END RSA PUBLIC KEY-----
&gt; opt hidden-service-dir
&gt; contact 1024D/F7C11265 Karsten Loesing &lt;karsten dot loesing AT gmx dot net&gt;
&gt; reject *:*
&gt; router-signature
&gt; -----BEGIN SIGNATURE-----
&gt; FxYg32MXPM2aOoa5q244CgSs0/EUw4nKJsxde0sD2f3zav7dXdBJBTrv0GdPETUC
&gt; iv125vk/zCNNljk2c3bbNAKVnFbBYyBXnJ7/BJL+kSAPYTpQGpIw6RXl3NtWhyZa
&gt; 08weBwj1bY+xZzYzgB7yuhPvYzH4F/Ji6qLzRsTfJp0=
&gt; -----END SIGNATURE-----
&gt; 
&gt; 
&gt; And finally, the referenced extra-info descriptor cecc7f83... is:
&gt; 
&gt; extra-info gabelmoo F2044413DAC2E02E3D6BCF4735A19BCA1DE97281
&gt; published 2010-05-21 02:34:42
&gt; write-history 2010-05-21 02:32:48 (900 s)
&gt; 
&gt; 544401408,540996608,642924544,583867392,653665280,637046784,684775424,598684672,5863 \
&gt; 47520,658676736,630778880,719997952,486724608,622078976,748093440,589464576,53946060 \
&gt; 8,801062912,825155584,805288960,791465984,678842368,636246016,630557696,679609344,66 \
&gt; 6486784,621635584,758945792,654635008,513009664,617194496,636549120,748435456,865181 \
&gt; 696,736525312,715303936,742599680,690369536,870909952,873070592,690373632,661690368, \
&gt; 703024128,689483776,837165056,626258944,741469184,897375232,802021376,669841408,7190 \
&gt; 76352,717147136,819868672,731346944,717606912,574259200,624780288,682221568,70885068 \
&gt; 8,666567680,734041088,725368832,799907840,881100800,896225280,907387904,854701056,93 \
&gt; 4236160,910132224,856087552,894130176,831595520,846332928,831883264,925052928,840542 \
&gt; 208,701243392,741879808,707265536,858382336,931992576,926849024,923104256,888730624, \
&gt; 934275072,929859584,938267648,938893312,929412096,928772096,876532736,828409856,885524480,806822912,656070656,632248320
&gt;  read-history 2010-05-21 02:32:48 (900 s)
&gt; 
&gt; 540297216,534199296,628869120,572840960,648410112,631605248,663860224,588089344,5802 \
&gt; 11712,650313728,608541696,701733888,478575616,611846144,726459392,572938240,52645478 \
&gt; 4,786325504,806251520,796734464,787733504,669499392,621448192,617405440,674842624,66 \
&gt; 0013056,599517184,743075840,644049920,506447872,603792384,622928896,742297600,860128 \
&gt; 256,712641536,694036480,735109120,682270720,852083712,859357184,683282432,656016384, \
&gt; 680463360,673383424,831110144,622981120,720413696,891073536,798917632,669814784,7051 \
&gt; 87840,709612544,818158592,729244672,703837184,564427776,625363968,682468352,69199462 \
&gt; 4,660142080,733149184,725949440,785703936,875602944,896345088,909398016,846983168,93 \
&gt; 3785600,917148672,854514688,884723712,822371328,844339200,821991424,913144832,828115 \
&gt; 968,695621632,737174528,691364864,847837184,934027264,929199104,912046080,877563904, \
&gt; 940472320,937701376,935174144,940459008,940481536,938059776,867339264,817305600,884368384,800684032,641873920,621056000
&gt;  dirreq-stats-end 2010-05-20 17:59:54 (86400 s)
&gt; dirreq-v3-ips
&gt; 
&gt; us=880,de=752,fr=320,it=224,kr=224,ru=200,gb=176,pl=128,ca=96,ng=88,nl=88,ir=80,jp=8 \
&gt; 0,pk=80,br=72,se=72,at=64,au=56,ch=56,es=56,ph=48,ua=48,mx=40,sn=40,th=40,tr=40,be=3 \
&gt; 2,fi=32,in=32,tw=32,ar=24,bg=24,cz=24,dk=24,eg=24,gh=24,gr=24,ie=24,no=24,ro=24,sg=2 \
&gt; 4,vn=24,a1=16,by=16,ci=16,co=16,dz=16,hk=16,hr=16,hu=16,id=16,il=16,kw=16,kz=16,ma=1 \
&gt; 6,my=16,nz=16,pt=16,sa=16,si=16,sk=16,ve=16,za=16,??=8,a2=8,ae=8,ao=8,aw=8,bd=8,bj=8 \
&gt; ,bn=8,bo=8,bs=8,cl=8,cr=8,cy=8,do=8,ec=8,ee=8,et=8,eu=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq= \
&gt; 8,is=8,jo=8,ke=8,kg=8,lb=8,lt=8,lu=8,lv=8,md=8,mn=8,mt=8,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,ps=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tn=8,tt=8,tz=8,uz=8,ye=8
&gt;  dirreq-v2-ips ng=8
&gt; dirreq-v3-reqs
&gt; 
&gt; us=1992,de=1296,fr=568,ru=344,kr=304,gb=280,it=256,ng=208,nl=200,se=176,pl=152,at=13 \
&gt; 6,ca=112,br=104,jp=104,ir=88,ph=88,ar=80,es=80,pk=80,ua=80,au=72,ch=72,tw=64,fi=56,b \
&gt; e=48,cz=48,th=48,tr=48,bg=40,in=40,mx=40,sn=40,dk=32,gr=32,no=32,ro=32,sg=32,eg=24,g \
&gt; h=24,hk=24,id=24,ie=24,il=24,pt=24,sk=24,vn=24,a1=16,a2=16,ae=16,by=16,ci=16,cl=16,c \
&gt; o=16,dz=16,ee=16,hr=16,hu=16,kw=16,kz=16,lb=16,lv=16,ma=16,mn=16,my=16,nz=16,ps=16,s \
&gt; a=16,si=16,tn=16,ve=16,za=16,??=8,ao=8,aw=8,bd=8,bj=8,bn=8,bo=8,bs=8,cr=8,cy=8,do=8, \
&gt; ec=8,et=8,eu=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq=8,is=8,jo=8,ke=8,kg=8,lt=8,lu=8,md=8,mt=8 \
&gt; ,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tt=8,tz=8,uz=8,ye=8
&gt;  dirreq-v2-reqs ng=8
&gt; dirreq-v3-resp
&gt; ok=8000,not-enough-sigs=0,unavailable=0,not-found=0,not-modified=0,busy=0
&gt; dirreq-v2-resp ok=8,unavailable=0,not-found=0,not-modified=0,busy=0
&gt; dirreq-v2-share 0.00%
&gt; dirreq-v3-share 0.00%
&gt; dirreq-v3-direct-dl
&gt; 
&gt; complete=3924,timeout=24,running=0,min=529,d1=49744,d2=84867,q1=103848,d3=119618,d4=165491,md=215631,d6=293536,d7=428605,q3=500448,d8=656839,d9=1507344,max=25818600
&gt;  dirreq-v2-direct-dl complete=4,timeout=0,running=0
&gt; dirreq-v3-tunneled-dl
&gt; 
&gt; complete=3968,timeout=88,running=4,min=161,d1=24326,d2=51796,q1=61586,d3=71895,d4=91512,md=121749,d6=161907,d7=231554,q3=285958,d8=343692,d9=529069,max=25762200
&gt;  dirreq-v2-tunneled-dl complete=0,timeout=0,running=0
&gt; entry-stats-end 2010-05-20 17:59:54 (86400 s)
&gt; entry-ips
&gt; 
&gt; de=1832,us=1680,kr=912,fr=680,it=672,ru=416,gb=384,pl=352,ir=336,jp=264,ng=240,ca=21 \
&gt; 6,br=208,es=168,in=152,pk=144,at=128,au=128,nl=128,ph=128,se=128,tr=128,ua=112,ch=10 \
&gt; 4,th=104,mx=96,tw=80,cz=72,ar=64,fi=64,sn=64,be=56,hu=56,ie=56,il=56,tn=56,vn=56,dk= \
&gt; 48,gh=48,gr=48,id=48,kw=48,ma=48,no=48,ro=48,sa=48,??=40,bg=40,ci=40,eg=40,hk=40,my= \
&gt; 40,pt=40,za=40,co=32,dz=32,nz=32,sg=32,a1=24,by=24,cl=24,kz=24,sk=24,ve=24,a2=16,bd= \
&gt; 16,bj=16,hr=16,jo=16,ke=16,lb=16,lt=16,lu=16,pe=16,ps=16,rs=16,sd=16,si=16,sy=16,ye= \
&gt; 16,ae=8,af=8,al=8,am=8,ao=8,aw=8,az=8,ba=8,bb=8,bh=8,bn=8,bo=8,bs=8,cm=8,cn=8,cr=8,c \
&gt; y=8,dj=8,do=8,ec=8,ee=8,eu=8,fj=8,fo=8,ge=8,gg=8,gt=8,gy=8,hn=8,ht=8,iq=8,is=8,jm=8, \
&gt; kg=8,ky=8,lk=8,lv=8,ly=8,mc=8,md=8,me=8,mg=8,mk=8,ml=8,mo=8,mr=8,mt=8,mu=8,mv=8,nc=8,ni=8,np=8,pa=8,pf=8,pr=8,py=8,qa=8,sc=8,so=8,sv=8,tg=8,tt=8,tz=8,ug=8,uy=8,uz=8
&gt;  cell-stats-end 2010-05-20 17:59:54 (86400 s)
&gt; cell-processed-cells 9890,208,69,27,16,7,5,5,4,2
&gt; cell-queued-cells 2.63,0.77,0.02,0.00,0.00,0.00,0.00,0.00,0.00,0.00
&gt; cell-time-in-queue 911,505,39,11,15,9,9,20,46,197
&gt; cell-circuits-per-decile 11482
&gt; exit-stats-end 2010-05-20 17:59:54 (86400 s)
&gt; exit-kibibytes-written other=0
&gt; exit-kibibytes-read other=0
&gt; exit-streams-opened other=0
&gt; router-signature
&gt; -----BEGIN SIGNATURE-----
&gt; N1CbWArG7rBEXa0r6dprMSh/HkdcpjtRyG0zScAJAYp76j4Nm/bIZz8UbDTwauqN
&gt; G9ysHp+qUf4IAuSDrYeLrSo5mrHuQOEDfEfA04eJ9bS2QzTFYZeO6kEFXlSprnc3
&gt; IC23R/isVEpDqM2qaWKnBIo3mT7bKram7GO1weIDfR0=
&gt; -----END SIGNATURE-----
&gt; 
&gt; 
&gt; One thing you can see here is that all fields in extra-info descriptors
&gt; have their own timestamps. None of the data in extra-info descriptors
&gt; requires knowledge of the corresponding server descriptor or network
&gt; status entry. If you want to analyze data from the extra-info
&gt; descriptors, you can import them into a table of its own.
&gt; 
&gt; So, what about joining network status entries and server descriptors?
&gt; There are statistics when it makes sense to join these documents. For
&gt; example, you might want to evaluate assigned relay flags (Stable, Guard;
&gt; contained in network status entry) and uptime (contained in server
&gt; descriptor) at the same time. In particular, it's almost never useful to
&gt; base statistics solely on server descriptors, because relays are not
&gt; even confirmed to be reachable when you only have a server descriptor.
&gt; 
&gt; How do you avoid join operations in your queries? I'd think that having
&gt; 2 import tables for network status entries and server descriptors and 1
&gt; unnormalized table containing all data for aggregation/querying might be
&gt; a good approach. You might be able to update that 1 table by using
&gt; triggers on the other 2 tables. You'll have lots of redundant data in
&gt; your database: all fields in your server descriptors can be contained in
&gt; up to 24 rows, as the maximum amount of time a server descriptor is
&gt; valid is 24 hours. But that's probably fine, as there's not so much
&gt; stuff in server descriptors that's useful for statistics anyway. And
&gt; you'll be excited how fast queries are without having to join tables. :)
&gt; 
&gt; 
&gt; Also, as discussed on #tor-dev, below are some notes on creating a
&gt; database schema for the BIRT-based metrics portal we had a couple of
&gt; months ago (and only for a very short time). I don't think you can
&gt; re-use everything as-is, but maybe you find some of the ideas useful for
&gt; your database schema.
&gt; 
&gt; Best,
&gt; --Karsten
&gt; 
&gt; 
&gt; Data table
&gt; ----------
&gt; 
&gt; The data table only includes entries from network statuses, not from
&gt; server descriptors or extra-info descriptors.
&gt; 
&gt; CREATE TABLE statusentry (
&gt; validafter TIMESTAMP WITHOUT TIME ZONE NOT NULL,
&gt; fingerprint CHARACTER(40),
&gt; hashed_fingerprint CHARACTER(40) NOT NULL,
&gt; bridge BOOLEAN NOT NULL DEFAULT false,
&gt; descriptor CHARACTER(40) NOT NULL,
&gt; authority BOOLEAN NOT NULL DEFAULT false,
&gt; badexit BOOLEAN NOT NULL DEFAULT false,
&gt; baddirectory BOOLEAN NOT NULL DEFAULT false,
&gt; exit BOOLEAN NOT NULL DEFAULT false,
&gt; fast BOOLEAN NOT NULL DEFAULT false,
&gt; guard BOOLEAN NOT NULL DEFAULT false,
&gt; hsdir BOOLEAN NOT NULL DEFAULT false,
&gt; named BOOLEAN NOT NULL DEFAULT false,
&gt; stable BOOLEAN NOT NULL DEFAULT false,
&gt; running BOOLEAN NOT NULL DEFAULT false,
&gt; unnamed BOOLEAN NOT NULL DEFAULT false,
&gt; valid BOOLEAN NOT NULL DEFAULT false,
&gt; v2dir BOOLEAN NOT NULL DEFAULT false,
&gt; v3dir BOOLEAN NOT NULL DEFAULT false,
&gt; bandwidthmeasured BIGINT CHECK (bandwidthmeasured &gt;= 0),
&gt; country CHARACTER(2),
&gt; PRIMARY KEY (validafter, hashed_fingerprint, bridge));
&gt; 
&gt; 
&gt; Network size
&gt; ------------
&gt; 
&gt; The network size is determined as the mean number of running relays or
&gt; bridges on a given day. These numbers are calculated from the network
&gt; status by counting the number of running relays or bridges over the day
&gt; and dividing them by the number of network statuses per that day:
&gt; 
&gt; CREATE VIEW network_size_v AS
&gt; SELECT DATE(validafter),
&gt; SUM(CASE WHEN bridge IS FALSE THEN 1 ELSE 0 END) /
&gt; relay_statuses_per_day.count AS avg_relays,
&gt; SUM(CASE WHEN bridge IS TRUE THEN 1 ELSE 0 END) /
&gt; bridge_statuses_per_day.count AS avg_bridges
&gt; FROM statusentry,
&gt; (SELECT COUNT(*) AS count, DATE(validafter) AS date
&gt; FROM (SELECT DISTINCT validafter FROM statusentry
&gt; WHERE bridge IS FALSE)
&gt; distinct_consensuses GROUP BY DATE(validafter))
&gt; relay_statuses_per_day,
&gt; (SELECT COUNT(*) AS count, DATE(validafter) AS date
&gt; FROM (SELECT DISTINCT validafter FROM statusentry
&gt; WHERE bridge IS TRUE)
&gt; distinct_consensuses GROUP BY DATE(validafter))
&gt; bridge_statuses_per_day
&gt; WHERE statusentry.running IS TRUE
&gt; AND DATE(validafter) = relay_statuses_per_day.date
&gt; AND DATE(validafter) = bridge_statuses_per_day.date
&gt; GROUP BY DATE(validafter), relay_statuses_per_day.count,
&gt; bridge_statuses_per_day.count
&gt; ORDER BY DATE(validafter);
&gt; 
&gt; The resulting view is 'materialized' by creating a table with the
&gt; contents of the view. Finally, the query role gets select rights for the
&gt; materialized view:
&gt; 
&gt; CREATE TABLE network_size_mv as SELECT * FROM network_size_v;
&gt; 
&gt; GRANT SELECT ON network_size_mv TO query;
&gt; 
&gt; 
&gt; Platforms and relay versions
&gt; ----------------------------
&gt; 
&gt; The reports on platforms and relay versions are based on network status
&gt; entries in combination with relay descriptors. The information whether a
&gt; relay was running and contained in a network status comes from the
&gt; statusentry relation, whereas the simplified platform string comes from
&gt; the descriptor relation. For each date, the number of running relays are
&gt; counted, grouped by platform string, and divided by the number of stored
&gt; network statuses at that day:
&gt; 
&gt; CREATE VIEW platforms_v AS
&gt; SELECT DATE(validafter) AS date, platform,
&gt; COUNT(*) / relay_statuses_per_day.count AS count
&gt; FROM (
&gt; SELECT COUNT(*) AS count, DATE(validafter) AS date
&gt; FROM (
&gt; SELECT DISTINCT validafter
&gt; FROM statusentry
&gt; WHERE bridge IS FALSE) distinct_consensuses
&gt; GROUP BY DATE(validafter)) relay_statuses_per_day
&gt; JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)
&gt; LEFT JOIN descriptor
&gt; ON statusentry.descriptor = descriptor.descriptor
&gt; WHERE running IS TRUE AND bridge IS FALSE
&gt; GROUP BY DATE(validafter), platform, relay_statuses_per_day.count,
&gt; relay_statuses_per_day.date
&gt; ORDER BY DATE(validafter), platform;
&gt; 
&gt; The mean numbers of relays per day running a certain Tor version are
&gt; determined similarly:
&gt; 
&gt; CREATE VIEW versions_v AS
&gt; SELECT DATE(validafter) AS date,
&gt; SUBSTRING(version, 1, 5) AS version,
&gt; COUNT(*) / relay_statuses_per_day.count AS count
&gt; FROM (
&gt; SELECT COUNT(*) AS count, DATE(validafter) AS date
&gt; FROM (
&gt; SELECT DISTINCT validafter
&gt; FROM statusentry
&gt; WHERE bridge IS FALSE) distinct_consensuses
&gt; GROUP BY DATE(validafter)) relay_statuses_per_day
&gt; JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)
&gt; LEFT JOIN descriptor
&gt; ON statusentry.descriptor = descriptor.descriptor
&gt; WHERE running IS TRUE AND bridge IS FALSE
&gt; GROUP BY DATE(validafter), SUBSTRING(version, 1, 5),
&gt; relay_statuses_per_day.count, relay_statuses_per_day.date
&gt; ORDER BY DATE(validafter), SUBSTRING(version, 1, 5);
&gt; 
&gt; Finally, two tables are created with the contents of these two views in
&gt; order to accelerate querying, and select rights are granted to the query
&gt; role:
&gt; 
&gt; CREATE TABLE platforms_mv as SELECT * FROM platforms_v;
&gt; 
&gt; CREATE TABLE versions_mv as SELECT * FROM versions_v;
&gt; 
&gt; GRANT SELECT ON platforms_mv TO query;
&gt; 
&gt; GRANT SELECT ON versions_mv TO query;
&gt; 
&gt; 
&gt; Bridge churn
&gt; ------------
&gt; 
&gt; Bridge churn is visualized as time plot with four lines showing how many
&gt; of the running bridges at a given time are still running 1
&gt; day/week/month later. The fewer bridges are missing after those times,
&gt; the more stable the bridge population is.
&gt; 
&gt; The necessary query table for this report is constructed in multiple
&gt; steps. To begin with, the set of bridges in network statuses is reduced
&gt; to the first network status of each day:
&gt; 
&gt; CREATE VIEW bridges_day_v AS
&gt; SELECT DATE(validafter), hashed_fingerprint
&gt; FROM statusentry
&gt; WHERE validafter IN (
&gt; SELECT MIN(validafter)
&gt; FROM statusentry
&gt; WHERE bridge IS true AND running IS true
&gt; GROUP BY DATE(validafter))
&gt; AND bridge IS true AND running IS true;
&gt; 
&gt; The resulting view is materialized, as it is used by multiple other views:
&gt; 
&gt; CREATE TABLE bridges_day_mv AS SELECT * FROM bridges_day_v;
&gt; 
&gt; In the next step, four views are created that determine how many bridges
&gt; overlap in the sets of a given date and a date 1 day/week/month in the
&gt; future from then:
&gt; 
&gt; CREATE VIEW bridges_churn_now_v AS
&gt; SELECT date, COUNT(*)
&gt; FROM bridges_day_mv
&gt; GROUP BY date;
&gt; 
&gt; CREATE VIEW bridges_churn_day_v AS
&gt; SELECT now.date, COUNT(*)
&gt; FROM bridges_day_mv now, bridges_day_mv future
&gt; WHERE now.date = DATE(future.date + interval '1 day')
&gt; AND now.hashed_fingerprint = future.hashed_fingerprint
&gt; GROUP BY now.date, future.date;
&gt; 
&gt; CREATE VIEW bridges_churn_week_v AS
&gt; SELECT now.date, COUNT(*)
&gt; FROM bridges_day_mv now, bridges_day_mv future
&gt; WHERE now.date = date(future.date + interval '1 week')
&gt; AND now.hashed_fingerprint = future.hashed_fingerprint
&gt; GROUP BY now.date, future.date;
&gt; 
&gt; CREATE VIEW bridges_churn_month_v AS
&gt; SELECT now.date, COUNT(*)
&gt; FROM bridges_day_mv now, bridges_day_mv future
&gt; WHERE now.date = date(future.date + interval '1 month')
&gt; AND now.hashed_fingerprint = future.hashed_fingerprint
&gt; GROUP BY now.date, future.date;
&gt; 
&gt; In the last step, these four views are joined into one common view:
&gt; 
&gt; CREATE VIEW bridges_churn_v AS
&gt; SELECT bridges_churn_now_v.date, bridges_churn_now_v.count AS now,
&gt; bridges_churn_day_v.count AS day,
&gt; bridges_churn_week_v.count AS week,
&gt; bridges_churn_month_v.count AS month
&gt; FROM bridges_churn_now_v
&gt; LEFT JOIN bridges_churn_day_v
&gt; ON bridges_churn_now_v.date = bridges_churn_day_v.date
&gt; LEFT JOIN bridges_churn_week_v
&gt; ON bridges_churn_day_v.date = bridges_churn_week_v.date
&gt; LEFT JOIN bridges_churn_month_v
&gt; ON bridges_churn_week_v.date = bridges_churn_month_v.date
&gt; ORDER BY bridges_churn_now_v.date;
&gt; 
&gt; In order to improve query performance, a materialized view is created
&gt; based on the last view and is given select rights to the query role:
&gt; 
&gt; CREATE TABLE bridges_churn_mv AS SELECT * FROM bridges_churn_v;
&gt; 
&gt; GRANT SELECT ON bridges_churn_mv TO query;
&gt; 
&gt; 
&gt; Bridge churn histogram
&gt; ----------------------
&gt; 
&gt; Bridge churn can be visualized as histogram with bars representing the
&gt; number of bridges that have been seen as running for a certain number of
&gt; days throughout 1 month.  The higher the bars for high numbers of days,
&gt; the more stable the bridge population is.
&gt; 
&gt; The underlying data set for this report is built from a sequence of
&gt; views, starting with a view on the bridges seen on the first days of a
&gt; month:
&gt; 
&gt; CREATE VIEW bridges_hist_first_day_v AS
&gt; SELECT DATE_TRUNC('month', validafter) AS first_day,
&gt; hashed_fingerprint
&gt; FROM statusentry
&gt; WHERE DATE(validafter) IN (
&gt; SELECT DATE(MIN(validafter))
&gt; FROM statusentry
&gt; WHERE bridge IS true AND running IS true
&gt; GROUP BY DATE_TRUNC('month', validafter))
&gt; AND bridge IS true AND running IS true
&gt; GROUP BY DATE_TRUNC('month', validafter), hashed_fingerprint;
&gt; 
&gt; In the next step, all days are selected on which these bridges have been
&gt; seen as running:
&gt; 
&gt; CREATE VIEW bridges_hist_seen_v AS
&gt; SELECT DATE(statusentry.validafter), statusentry.hashed_fingerprint
&gt; FROM statusentry, bridges_hist_first_day_v
&gt; WHERE DATE_TRUNC('month', statusentry.validafter) =
&gt; bridges_hist_first_day_v.first_day
&gt; AND statusentry.hashed_fingerprint =
&gt; bridges_hist_first_day_v.hashed_fingerprint
&gt; GROUP BY DATE(statusentry.validafter), statusentry.hashed_fingerprint;
&gt; 
&gt; For each distinct bridge in each month, the number of days that this
&gt; bridge has been seen as running are counted:
&gt; 
&gt; CREATE VIEW bridges_hist_pre_v AS
&gt; SELECT COUNT(*) AS days, DATE_TRUNC('month', date) AS month
&gt; FROM bridges_hist_seen_v
&gt; GROUP BY DATE_TRUNC('month', date), hashed_fingerprint;
&gt; 
&gt; Finally, the number of bridges for a given number of days are added up:
&gt; 
&gt; CREATE VIEW bridges_hist_v AS
&gt; SELECT COUNT(*), days, DATE(month) AS month
&gt; FROM bridges_hist_pre_v
&gt; GROUP BY month, days
&gt; ORDER BY month, days;
&gt; 
&gt; A materialized view is created and given the select rights for the query
&gt; role:
&gt; 
&gt; CREATE TABLE bridges_hist_mv AS SELECT * FROM bridges_hist_v;
&gt; 
&gt; GRANT SELECT ON bridges_hist_mv TO query;
&gt; 
&gt; 


[Attachment #3 (text/html)]

Karsten,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is all extremely helpful. I certainly won't be \
able to test with the full amount of data, but we can get a look at the performance \
implications of running queries on both normalized and unnormalized schemas. &lt;/div&gt;







&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As far as a timeline - I think 2 weeks is a fair amount of time \
for the schema to be finished. Should I finish early (which has a good chance of \
happening), I can begin working on having R work with the database directly, or \
making/modifying a descriptor database importer for this schema. I'm really \
looking to get the db stuff down for a basis from which we can build off. We can \
discuss this when the time comes. &lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;/div&gt;&lt;div&gt;Kevin&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On 21 May 2010 07:06, Karsten Loesing &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:karsten.loesing@gmx.net" \
target="_blank"&gt;karsten.loesing@gmx.net&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;







&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt;Hi Kevin,&lt;br&gt; &lt;br&gt;
here are some thoughts on importing relay descriptors into a database.&lt;br&gt;
&lt;br&gt;
You may already have noticed that there are three documents holding&lt;br&gt;
information about a relay in the Tor network: network status entry,&lt;br&gt;
server descriptor, and extra-info descriptor. In the past, I have used&lt;br&gt;
three tables and joined them whenever necessary. It turned out that join&lt;br&gt;
operations are highly inefficient and that it doesn't even make sense to&lt;br&gt;
join extra-info descriptors with network status entries and server&lt;br&gt;
descriptors.&lt;br&gt;
&lt;br&gt;
Here's an example. The current network status consensus has this entry&lt;br&gt;
for gabelmoo:&lt;br&gt;
&lt;br&gt;
r gabelmoo 8gREE9rC4C49a89HNaGbyh3pcoE gL7MFClJBGG6l3KzCXJPh5fQnl8&lt;br&gt;
2010-05-21 02:34:42 80.190.246.100 8080 8180&lt;br&gt;
s Authority Fast Guard HSDir Running Stable Unnamed V2Dir Valid&lt;br&gt;
v Tor 0.2.2.13-alpha&lt;br&gt;
w Bandwidth=512&lt;br&gt;
p reject 1-65535&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
The referenced server descriptor gL7MFCl... in base64 or&lt;br&gt;
80becc1429490461ba9772b309724f8797d09e5f in hex has this content:&lt;br&gt;
&lt;br&gt;
router gabelmoo 80.190.246.100 8080 0 8180&lt;br&gt;
platform Tor 0.2.2.13-alpha (git-a3db6300225c5f34) on Linux i686&lt;br&gt;
opt protocols Link 1 2 Circuit 1&lt;br&gt;
published 2010-05-21 02:34:42&lt;br&gt;
opt fingerprint F204 4413 DAC2 E02E 3D6B CF47 35A1 9BCA 1DE9 7281&lt;br&gt;
uptime 1154088&lt;br&gt;
bandwidth 512000 1280000 1166966&lt;br&gt;
opt extra-info-digest CECC7F83F5CD771BF0DF9827C08F561CE84A5DA3&lt;br&gt;
opt caches-extra-info&lt;br&gt;
onion-key&lt;br&gt;
-----BEGIN RSA PUBLIC KEY-----&lt;br&gt;
MIGJAoGBANbj/L3FZCbIKNdBKMH1tamU/r+9p+X4fI+1i9jDtHt11D4Rz+rsQ4CX&lt;br&gt;
8no0NMx2yOHpvq7Cp8scO2ZcH4UjQ/bJIumgGqjuslWMn9KtrbBKdtNzVtOMNjYY&lt;br&gt;
7zjZJ8UVmS1/hH2wl2dwZeAVbQ931u9DWX5R/u1ck28EQS8C2Z/jAgMBAAE=&lt;br&gt;
-----END RSA PUBLIC KEY-----&lt;br&gt;
signing-key&lt;br&gt;
-----BEGIN RSA PUBLIC KEY-----&lt;br&gt;
MIGJAoGBAMjPhp0QAN8WQeP8sDg+mnM7hnPExcXTOfsmt7Sl2k3fHcHeAJnYu10V&lt;br&gt;
/hb6RBhubi1HRg6fYF5PwZWOppxRj90WX3n2JEcQh88+4tuQNQ2jOxXQ/hBkyf0w&lt;br&gt;
klrx6Fh8ana1VX+QXInfRW5z3eaANXqvdCvDG5jfUrz6pj8WGPrxAgMBAAE=&lt;br&gt;
-----END RSA PUBLIC KEY-----&lt;br&gt;
opt hidden-service-dir&lt;br&gt;
contact 1024D/F7C11265 Karsten Loesing &lt;karsten dot loesing AT gmx dot net&gt;&lt;br&gt;
reject *:*&lt;br&gt;
router-signature&lt;br&gt;
-----BEGIN SIGNATURE-----&lt;br&gt;
FxYg32MXPM2aOoa5q244CgSs0/EUw4nKJsxde0sD2f3zav7dXdBJBTrv0GdPETUC&lt;br&gt;
iv125vk/zCNNljk2c3bbNAKVnFbBYyBXnJ7/BJL+kSAPYTpQGpIw6RXl3NtWhyZa&lt;br&gt;
08weBwj1bY+xZzYzgB7yuhPvYzH4F/Ji6qLzRsTfJp0=&lt;br&gt;
-----END SIGNATURE-----&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
And finally, the referenced extra-info descriptor cecc7f83... is:&lt;br&gt;
&lt;br&gt;
extra-info gabelmoo F2044413DAC2E02E3D6BCF4735A19BCA1DE97281&lt;br&gt;
published 2010-05-21 02:34:42&lt;br&gt;
write-history 2010-05-21 02:32:48 (900 s)&lt;br&gt;
544401408,540996608,642924544,583867392,653665280,637046784,684775424,598684672,586347 \
520,658676736,630778880,719997952,486724608,622078976,748093440,589464576,539460608,80 \
1062912,825155584,805288960,791465984,678842368,636246016,630557696,679609344,66648678 \
4,621635584,758945792,654635008,513009664,617194496,636549120,748435456,865181696,7365 \
25312,715303936,742599680,690369536,870909952,873070592,690373632,661690368,703024128, \
689483776,837165056,626258944,741469184,897375232,802021376,669841408,719076352,717147 \
136,819868672,731346944,717606912,574259200,624780288,682221568,708850688,666567680,73 \
4041088,725368832,799907840,881100800,896225280,907387904,854701056,934236160,91013222 \
4,856087552,894130176,831595520,846332928,831883264,925052928,840542208,701243392,7418 \
79808,707265536,858382336,931992576,926849024,923104256,888730624,934275072,929859584, \
938267648,938893312,929412096,928772096,876532736,828409856,885524480,806822912,656070656,632248320&lt;br&gt;









read-history 2010-05-21 02:32:48 (900 s)&lt;br&gt;
540297216,534199296,628869120,572840960,648410112,631605248,663860224,588089344,580211 \
712,650313728,608541696,701733888,478575616,611846144,726459392,572938240,526454784,78 \
6325504,806251520,796734464,787733504,669499392,621448192,617405440,674842624,66001305 \
6,599517184,743075840,644049920,506447872,603792384,622928896,742297600,860128256,7126 \
41536,694036480,735109120,682270720,852083712,859357184,683282432,656016384,680463360, \
673383424,831110144,622981120,720413696,891073536,798917632,669814784,705187840,709612 \
544,818158592,729244672,703837184,564427776,625363968,682468352,691994624,660142080,73 \
3149184,725949440,785703936,875602944,896345088,909398016,846983168,933785600,91714867 \
2,854514688,884723712,822371328,844339200,821991424,913144832,828115968,695621632,7371 \
74528,691364864,847837184,934027264,929199104,912046080,877563904,940472320,937701376, \
935174144,940459008,940481536,938059776,867339264,817305600,884368384,800684032,641873920,621056000&lt;br&gt;









dirreq-stats-end 2010-05-20 17:59:54 (86400 s)&lt;br&gt;
dirreq-v3-ips&lt;br&gt;
us=880,de=752,fr=320,it=224,kr=224,ru=200,gb=176,pl=128,ca=96,ng=88,nl=88,ir=80,jp=80, \
pk=80,br=72,se=72,at=64,au=56,ch=56,es=56,ph=48,ua=48,mx=40,sn=40,th=40,tr=40,be=32,fi \
=32,in=32,tw=32,ar=24,bg=24,cz=24,dk=24,eg=24,gh=24,gr=24,ie=24,no=24,ro=24,sg=24,vn=2 \
4,a1=16,by=16,ci=16,co=16,dz=16,hk=16,hr=16,hu=16,id=16,il=16,kw=16,kz=16,ma=16,my=16, \
nz=16,pt=16,sa=16,si=16,sk=16,ve=16,za=16,??=8,a2=8,ae=8,ao=8,aw=8,bd=8,bj=8,bn=8,bo=8 \
,bs=8,cl=8,cr=8,cy=8,do=8,ec=8,ee=8,et=8,eu=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq=8,is=8,jo=8, \
ke=8,kg=8,lb=8,lt=8,lu=8,lv=8,md=8,mn=8,mt=8,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,ps=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tn=8,tt=8,tz=8,uz=8,ye=8&lt;br&gt;









dirreq-v2-ips ng=8&lt;br&gt;
dirreq-v3-reqs&lt;br&gt;
us=1992,de=1296,fr=568,ru=344,kr=304,gb=280,it=256,ng=208,nl=200,se=176,pl=152,at=136, \
ca=112,br=104,jp=104,ir=88,ph=88,ar=80,es=80,pk=80,ua=80,au=72,ch=72,tw=64,fi=56,be=48 \
,cz=48,th=48,tr=48,bg=40,in=40,mx=40,sn=40,dk=32,gr=32,no=32,ro=32,sg=32,eg=24,gh=24,h \
k=24,id=24,ie=24,il=24,pt=24,sk=24,vn=24,a1=16,a2=16,ae=16,by=16,ci=16,cl=16,co=16,dz= \
16,ee=16,hr=16,hu=16,kw=16,kz=16,lb=16,lv=16,ma=16,mn=16,my=16,nz=16,ps=16,sa=16,si=16 \
,tn=16,ve=16,za=16,??=8,ao=8,aw=8,bd=8,bj=8,bn=8,bo=8,bs=8,cr=8,cy=8,do=8,ec=8,et=8,eu \
=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq=8,is=8,jo=8,ke=8,kg=8,lt=8,lu=8,md=8,mt=8,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tt=8,tz=8,uz=8,ye=8&lt;br&gt;









dirreq-v2-reqs ng=8&lt;br&gt;
dirreq-v3-resp&lt;br&gt;
ok=8000,not-enough-sigs=0,unavailable=0,not-found=0,not-modified=0,busy=0&lt;br&gt;
dirreq-v2-resp ok=8,unavailable=0,not-found=0,not-modified=0,busy=0&lt;br&gt;
dirreq-v2-share 0.00%&lt;br&gt;
dirreq-v3-share 0.00%&lt;br&gt;
dirreq-v3-direct-dl&lt;br&gt;
complete=3924,timeout=24,running=0,min=529,d1=49744,d2=84867,q1=103848,d3=119618,d4=16 \
5491,md=215631,d6=293536,d7=428605,q3=500448,d8=656839,d9=1507344,max=25818600&lt;br&gt; \
dirreq-v2-direct-dl complete=4,timeout=0,running=0&lt;br&gt; dirreq-v3-tunneled-dl&lt;br&gt;
complete=3968,timeout=88,running=4,min=161,d1=24326,d2=51796,q1=61586,d3=71895,d4=91512,md=121749,d6=161907,d7=231554,q3=285958,d8=343692,d9=529069,max=25762200&lt;br&gt;
 dirreq-v2-tunneled-dl complete=0,timeout=0,running=0&lt;br&gt;
entry-stats-end 2010-05-20 17:59:54 (86400 s)&lt;br&gt;
entry-ips&lt;br&gt;
de=1832,us=1680,kr=912,fr=680,it=672,ru=416,gb=384,pl=352,ir=336,jp=264,ng=240,ca=216, \
br=208,es=168,in=152,pk=144,at=128,au=128,nl=128,ph=128,se=128,tr=128,ua=112,ch=104,th \
=104,mx=96,tw=80,cz=72,ar=64,fi=64,sn=64,be=56,hu=56,ie=56,il=56,tn=56,vn=56,dk=48,gh= \
48,gr=48,id=48,kw=48,ma=48,no=48,ro=48,sa=48,??=40,bg=40,ci=40,eg=40,hk=40,my=40,pt=40 \
,za=40,co=32,dz=32,nz=32,sg=32,a1=24,by=24,cl=24,kz=24,sk=24,ve=24,a2=16,bd=16,bj=16,h \
r=16,jo=16,ke=16,lb=16,lt=16,lu=16,pe=16,ps=16,rs=16,sd=16,si=16,sy=16,ye=16,ae=8,af=8 \
,al=8,am=8,ao=8,aw=8,az=8,ba=8,bb=8,bh=8,bn=8,bo=8,bs=8,cm=8,cn=8,cr=8,cy=8,dj=8,do=8, \
ec=8,ee=8,eu=8,fj=8,fo=8,ge=8,gg=8,gt=8,gy=8,hn=8,ht=8,iq=8,is=8,jm=8,kg=8,ky=8,lk=8,l \
v=8,ly=8,mc=8,md=8,me=8,mg=8,mk=8,ml=8,mo=8,mr=8,mt=8,mu=8,mv=8,nc=8,ni=8,np=8,pa=8,pf=8,pr=8,py=8,qa=8,sc=8,so=8,sv=8,tg=8,tt=8,tz=8,ug=8,uy=8,uz=8&lt;br&gt;









cell-stats-end 2010-05-20 17:59:54 (86400 s)&lt;br&gt;
cell-processed-cells 9890,208,69,27,16,7,5,5,4,2&lt;br&gt;
cell-queued-cells 2.63,0.77,0.02,0.00,0.00,0.00,0.00,0.00,0.00,0.00&lt;br&gt;
cell-time-in-queue 911,505,39,11,15,9,9,20,46,197&lt;br&gt;
cell-circuits-per-decile 11482&lt;br&gt;
exit-stats-end 2010-05-20 17:59:54 (86400 s)&lt;br&gt;
exit-kibibytes-written other=0&lt;br&gt;
exit-kibibytes-read other=0&lt;br&gt;
exit-streams-opened other=0&lt;br&gt;
router-signature&lt;br&gt;
-----BEGIN SIGNATURE-----&lt;br&gt;
N1CbWArG7rBEXa0r6dprMSh/HkdcpjtRyG0zScAJAYp76j4Nm/bIZz8UbDTwauqN&lt;br&gt;
G9ysHp+qUf4IAuSDrYeLrSo5mrHuQOEDfEfA04eJ9bS2QzTFYZeO6kEFXlSprnc3&lt;br&gt;
IC23R/isVEpDqM2qaWKnBIo3mT7bKram7GO1weIDfR0=&lt;br&gt;
-----END SIGNATURE-----&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
One thing you can see here is that all fields in extra-info descriptors&lt;br&gt;
have their own timestamps. None of the data in extra-info descriptors&lt;br&gt;
requires knowledge of the corresponding server descriptor or network&lt;br&gt;
status entry. If you want to analyze data from the extra-info&lt;br&gt;
descriptors, you can import them into a table of its own.&lt;br&gt;
&lt;br&gt;
So, what about joining network status entries and server descriptors?&lt;br&gt;
There are statistics when it makes sense to join these documents. For&lt;br&gt;
example, you might want to evaluate assigned relay flags (Stable, Guard;&lt;br&gt;
contained in network status entry) and uptime (contained in server&lt;br&gt;
descriptor) at the same time. In particular, it's almost never useful to&lt;br&gt;
base statistics solely on server descriptors, because relays are not&lt;br&gt;
even confirmed to be reachable when you only have a server descriptor.&lt;br&gt;
&lt;br&gt;
How do you avoid join operations in your queries? I'd think that having&lt;br&gt;
2 import tables for network status entries and server descriptors and 1&lt;br&gt;
unnormalized table containing all data for aggregation/querying might be&lt;br&gt;
a good approach. You might be able to update that 1 table by using&lt;br&gt;
triggers on the other 2 tables. You'll have lots of redundant data in&lt;br&gt;
your database: all fields in your server descriptors can be contained in&lt;br&gt;
up to 24 rows, as the maximum amount of time a server descriptor is&lt;br&gt;
valid is 24 hours. But that's probably fine, as there's not so much&lt;br&gt;
stuff in server descriptors that's useful for statistics anyway. And&lt;br&gt;
you'll be excited how fast queries are without having to join tables. :)&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Also, as discussed on #tor-dev, below are some notes on creating a&lt;br&gt;
database schema for the BIRT-based metrics portal we had a couple of&lt;br&gt;
months ago (and only for a very short time). I don't think you can&lt;br&gt;
re-use everything as-is, but maybe you find some of the ideas useful for&lt;br&gt;
your database schema.&lt;br&gt;
&lt;br&gt;
Best,&lt;br&gt;
--Karsten&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Data table&lt;br&gt;
----------&lt;br&gt;
&lt;br&gt;
The data table only includes entries from network statuses, not from&lt;br&gt;
server descriptors or extra-info descriptors.&lt;br&gt;
&lt;br&gt;
  CREATE TABLE statusentry (&lt;br&gt;
    validafter TIMESTAMP WITHOUT TIME ZONE NOT NULL,&lt;br&gt;
    fingerprint CHARACTER(40),&lt;br&gt;
    hashed_fingerprint CHARACTER(40) NOT NULL,&lt;br&gt;
    bridge BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    descriptor CHARACTER(40) NOT NULL,&lt;br&gt;
    authority BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    badexit BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    baddirectory BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    exit BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    fast BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    guard BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    hsdir BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    named BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    stable BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    running BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    unnamed BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    valid BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    v2dir BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    v3dir BOOLEAN NOT NULL DEFAULT false,&lt;br&gt;
    bandwidthmeasured BIGINT CHECK (bandwidthmeasured &gt;= 0),&lt;br&gt;
    country CHARACTER(2),&lt;br&gt;
    PRIMARY KEY (validafter, hashed_fingerprint, bridge));&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Network size&lt;br&gt;
------------&lt;br&gt;
&lt;br&gt;
The network size is determined as the mean number of running relays or&lt;br&gt;
bridges on a given day. These numbers are calculated from the network&lt;br&gt;
status by counting the number of running relays or bridges over the day&lt;br&gt;
and dividing them by the number of network statuses per that day:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW network_size_v AS&lt;br&gt;
    SELECT DATE(validafter),&lt;br&gt;
      SUM(CASE WHEN bridge IS FALSE THEN 1 ELSE 0 END) /&lt;br&gt;
        relay_statuses_per_day.count AS avg_relays,&lt;br&gt;
      SUM(CASE WHEN bridge IS TRUE THEN 1 ELSE 0 END) /&lt;br&gt;
        bridge_statuses_per_day.count AS avg_bridges&lt;br&gt;
    FROM statusentry,&lt;br&gt;
      (SELECT COUNT(*) AS count, DATE(validafter) AS date&lt;br&gt;
        FROM (SELECT DISTINCT validafter FROM statusentry&lt;br&gt;
          WHERE bridge IS FALSE)&lt;br&gt;
        distinct_consensuses GROUP BY DATE(validafter))&lt;br&gt;
        relay_statuses_per_day,&lt;br&gt;
      (SELECT COUNT(*) AS count, DATE(validafter) AS date&lt;br&gt;
        FROM (SELECT DISTINCT validafter FROM statusentry&lt;br&gt;
          WHERE bridge IS TRUE)&lt;br&gt;
        distinct_consensuses GROUP BY DATE(validafter))&lt;br&gt;
        bridge_statuses_per_day&lt;br&gt;
    WHERE statusentry.running IS TRUE&lt;br&gt;
      AND DATE(validafter) = relay_statuses_per_day.date&lt;br&gt;
      AND DATE(validafter) = bridge_statuses_per_day.date&lt;br&gt;
    GROUP BY DATE(validafter), relay_statuses_per_day.count,&lt;br&gt;
      bridge_statuses_per_day.count&lt;br&gt;
    ORDER BY DATE(validafter);&lt;br&gt;
&lt;br&gt;
The resulting view is 'materialized' by creating a table with the&lt;br&gt;
contents of the view. Finally, the query role gets select rights for the&lt;br&gt;
materialized view:&lt;br&gt;
&lt;br&gt;
  CREATE TABLE network_size_mv as SELECT * FROM network_size_v;&lt;br&gt;
&lt;br&gt;
  GRANT SELECT ON network_size_mv TO query;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Platforms and relay versions&lt;br&gt;
----------------------------&lt;br&gt;
&lt;br&gt;
The reports on platforms and relay versions are based on network status&lt;br&gt;
entries in combination with relay descriptors. The information whether a&lt;br&gt;
relay was running and contained in a network status comes from the&lt;br&gt;
statusentry relation, whereas the simplified platform string comes from&lt;br&gt;
the descriptor relation. For each date, the number of running relays are&lt;br&gt;
counted, grouped by platform string, and divided by the number of stored&lt;br&gt;
network statuses at that day:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW platforms_v AS&lt;br&gt;
    SELECT DATE(validafter) AS date, platform,&lt;br&gt;
    COUNT(*) / relay_statuses_per_day.count AS count&lt;br&gt;
    FROM (&lt;br&gt;
      SELECT COUNT(*) AS count, DATE(validafter) AS date&lt;br&gt;
      FROM (&lt;br&gt;
        SELECT DISTINCT validafter&lt;br&gt;
        FROM statusentry&lt;br&gt;
        WHERE bridge IS FALSE) distinct_consensuses&lt;br&gt;
      GROUP BY DATE(validafter)) relay_statuses_per_day&lt;br&gt;
    JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)&lt;br&gt;
    LEFT JOIN descriptor&lt;br&gt;
      ON statusentry.descriptor = descriptor.descriptor&lt;br&gt;
    WHERE running IS TRUE AND bridge IS FALSE&lt;br&gt;
    GROUP BY DATE(validafter), platform, relay_statuses_per_day.count,&lt;br&gt;
      relay_statuses_per_day.date&lt;br&gt;
    ORDER BY DATE(validafter), platform;&lt;br&gt;
&lt;br&gt;
The mean numbers of relays per day running a certain Tor version are&lt;br&gt;
determined similarly:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW versions_v AS&lt;br&gt;
    SELECT DATE(validafter) AS date,&lt;br&gt;
      SUBSTRING(version, 1, 5) AS version,&lt;br&gt;
      COUNT(*) / relay_statuses_per_day.count AS count&lt;br&gt;
    FROM (&lt;br&gt;
      SELECT COUNT(*) AS count, DATE(validafter) AS date&lt;br&gt;
      FROM (&lt;br&gt;
        SELECT DISTINCT validafter&lt;br&gt;
        FROM statusentry&lt;br&gt;
        WHERE bridge IS FALSE) distinct_consensuses&lt;br&gt;
      GROUP BY DATE(validafter)) relay_statuses_per_day&lt;br&gt;
    JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)&lt;br&gt;
    LEFT JOIN descriptor&lt;br&gt;
      ON statusentry.descriptor = descriptor.descriptor&lt;br&gt;
    WHERE running IS TRUE AND bridge IS FALSE&lt;br&gt;
    GROUP BY DATE(validafter), SUBSTRING(version, 1, 5),&lt;br&gt;
      relay_statuses_per_day.count, relay_statuses_per_day.date&lt;br&gt;
    ORDER BY DATE(validafter), SUBSTRING(version, 1, 5);&lt;br&gt;
&lt;br&gt;
Finally, two tables are created with the contents of these two views in&lt;br&gt;
order to accelerate querying, and select rights are granted to the query&lt;br&gt;
role:&lt;br&gt;
&lt;br&gt;
  CREATE TABLE platforms_mv as SELECT * FROM platforms_v;&lt;br&gt;
&lt;br&gt;
  CREATE TABLE versions_mv as SELECT * FROM versions_v;&lt;br&gt;
&lt;br&gt;
  GRANT SELECT ON platforms_mv TO query;&lt;br&gt;
&lt;br&gt;
  GRANT SELECT ON versions_mv TO query;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Bridge churn&lt;br&gt;
------------&lt;br&gt;
&lt;br&gt;
Bridge churn is visualized as time plot with four lines showing how many&lt;br&gt;
of the running bridges at a given time are still running 1&lt;br&gt;
day/week/month later. The fewer bridges are missing after those times,&lt;br&gt;
the more stable the bridge population is.&lt;br&gt;
&lt;br&gt;
The necessary query table for this report is constructed in multiple&lt;br&gt;
steps. To begin with, the set of bridges in network statuses is reduced&lt;br&gt;
to the first network status of each day:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_day_v AS&lt;br&gt;
    SELECT DATE(validafter), hashed_fingerprint&lt;br&gt;
    FROM statusentry&lt;br&gt;
    WHERE validafter IN (&lt;br&gt;
      SELECT MIN(validafter)&lt;br&gt;
      FROM statusentry&lt;br&gt;
      WHERE bridge IS true AND running IS true&lt;br&gt;
      GROUP BY DATE(validafter))&lt;br&gt;
    AND bridge IS true AND running IS true;&lt;br&gt;
&lt;br&gt;
The resulting view is materialized, as it is used by multiple other views:&lt;br&gt;
&lt;br&gt;
  CREATE TABLE bridges_day_mv AS SELECT * FROM bridges_day_v;&lt;br&gt;
&lt;br&gt;
In the next step, four views are created that determine how many bridges&lt;br&gt;
overlap in the sets of a given date and a date 1 day/week/month in the&lt;br&gt;
future from then:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_churn_now_v AS&lt;br&gt;
    SELECT date, COUNT(*)&lt;br&gt;
    FROM bridges_day_mv&lt;br&gt;
    GROUP BY date;&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_churn_day_v AS&lt;br&gt;
    SELECT now.date, COUNT(*)&lt;br&gt;
    FROM bridges_day_mv now, bridges_day_mv future&lt;br&gt;
    WHERE now.date = DATE(future.date + interval '1 day')&lt;br&gt;
      AND now.hashed_fingerprint = future.hashed_fingerprint&lt;br&gt;
    GROUP BY now.date, future.date;&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_churn_week_v AS&lt;br&gt;
    SELECT now.date, COUNT(*)&lt;br&gt;
    FROM bridges_day_mv now, bridges_day_mv future&lt;br&gt;
    WHERE now.date = date(future.date + interval '1 week')&lt;br&gt;
      AND now.hashed_fingerprint = future.hashed_fingerprint&lt;br&gt;
    GROUP BY now.date, future.date;&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_churn_month_v AS&lt;br&gt;
    SELECT now.date, COUNT(*)&lt;br&gt;
    FROM bridges_day_mv now, bridges_day_mv future&lt;br&gt;
    WHERE now.date = date(future.date + interval '1 month')&lt;br&gt;
      AND now.hashed_fingerprint = future.hashed_fingerprint&lt;br&gt;
    GROUP BY now.date, future.date;&lt;br&gt;
&lt;br&gt;
In the last step, these four views are joined into one common view:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_churn_v AS&lt;br&gt;
    SELECT bridges_churn_now_v.date, bridges_churn_now_v.count AS now,&lt;br&gt;
      bridges_churn_day_v.count AS day,&lt;br&gt;
      bridges_churn_week_v.count AS week,&lt;br&gt;
      bridges_churn_month_v.count AS month&lt;br&gt;
    FROM bridges_churn_now_v&lt;br&gt;
      LEFT JOIN bridges_churn_day_v&lt;br&gt;
        ON bridges_churn_now_v.date = bridges_churn_day_v.date&lt;br&gt;
      LEFT JOIN bridges_churn_week_v&lt;br&gt;
        ON bridges_churn_day_v.date = bridges_churn_week_v.date&lt;br&gt;
      LEFT JOIN bridges_churn_month_v&lt;br&gt;
        ON bridges_churn_week_v.date = bridges_churn_month_v.date&lt;br&gt;
      ORDER BY bridges_churn_now_v.date;&lt;br&gt;
&lt;br&gt;
In order to improve query performance, a materialized view is created&lt;br&gt;
based on the last view and is given select rights to the query role:&lt;br&gt;
&lt;br&gt;
  CREATE TABLE bridges_churn_mv AS SELECT * FROM bridges_churn_v;&lt;br&gt;
&lt;br&gt;
  GRANT SELECT ON bridges_churn_mv TO query;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Bridge churn histogram&lt;br&gt;
----------------------&lt;br&gt;
&lt;br&gt;
Bridge churn can be visualized as histogram with bars representing the&lt;br&gt;
number of bridges that have been seen as running for a certain number of&lt;br&gt;
days throughout 1 month.  The higher the bars for high numbers of days,&lt;br&gt;
the more stable the bridge population is.&lt;br&gt;
&lt;br&gt;
The underlying data set for this report is built from a sequence of&lt;br&gt;
views, starting with a view on the bridges seen on the first days of a&lt;br&gt;
month:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_hist_first_day_v AS&lt;br&gt;
    SELECT DATE_TRUNC('month', validafter) AS first_day,&lt;br&gt;
      hashed_fingerprint&lt;br&gt;
    FROM statusentry&lt;br&gt;
    WHERE DATE(validafter) IN (&lt;br&gt;
      SELECT DATE(MIN(validafter))&lt;br&gt;
      FROM statusentry&lt;br&gt;
      WHERE bridge IS true AND running IS true&lt;br&gt;
      GROUP BY DATE_TRUNC('month', validafter))&lt;br&gt;
    AND bridge IS true AND running IS true&lt;br&gt;
    GROUP BY DATE_TRUNC('month', validafter), hashed_fingerprint;&lt;br&gt;
&lt;br&gt;
In the next step, all days are selected on which these bridges have been&lt;br&gt;
seen as running:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_hist_seen_v AS&lt;br&gt;
    SELECT DATE(statusentry.validafter), statusentry.hashed_fingerprint&lt;br&gt;
    FROM statusentry, bridges_hist_first_day_v&lt;br&gt;
    WHERE DATE_TRUNC('month', statusentry.validafter) =&lt;br&gt;
        bridges_hist_first_day_v.first_day&lt;br&gt;
      AND statusentry.hashed_fingerprint =&lt;br&gt;
        bridges_hist_first_day_v.hashed_fingerprint&lt;br&gt;
    GROUP BY DATE(statusentry.validafter), statusentry.hashed_fingerprint;&lt;br&gt;
&lt;br&gt;
For each distinct bridge in each month, the number of days that this&lt;br&gt;
bridge has been seen as running are counted:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_hist_pre_v AS&lt;br&gt;
    SELECT COUNT(*) AS days, DATE_TRUNC('month', date) AS month&lt;br&gt;
    FROM bridges_hist_seen_v&lt;br&gt;
    GROUP BY DATE_TRUNC('month', date), hashed_fingerprint;&lt;br&gt;
&lt;br&gt;
Finally, the number of bridges for a given number of days are added up:&lt;br&gt;
&lt;br&gt;
  CREATE VIEW bridges_hist_v AS&lt;br&gt;
    SELECT COUNT(*), days, DATE(month) AS month&lt;br&gt;
    FROM bridges_hist_pre_v&lt;br&gt;
    GROUP BY month, days&lt;br&gt;
    ORDER BY month, days;&lt;br&gt;
&lt;br&gt;
A materialized view is created and given the select rights for the query&lt;br&gt;
role:&lt;br&gt;
&lt;br&gt;
  CREATE TABLE bridges_hist_mv AS SELECT * FROM bridges_hist_v;&lt;br&gt;
&lt;br&gt;
  GRANT SELECT ON bridges_hist_mv TO query;&lt;br&gt;
&lt;br&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;



</body></email><email><emailId>20100526130648</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-05-26 13:06:48-0400</timestampReceived><subject>Re: Bridge status website</subject><body>

Hi Sebastian,

On Wed, May 26, 2010 at 2:09 PM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:

&gt;&gt; I wonder whether (b) is a good idea. Say I am Sir John McEvil and I
&gt;&gt; want to learn something about which IP address belongs to which
&gt;&gt; bridge: All I gotta do is iterate connections from some obscure
&gt;&gt; countries to certain bridges and check the stats later on.
&gt;
&gt; This isn't really an issue: If they adversary has the ability to push
&gt; traffic through a bridge, it can learn its descriptor, and thus its
&gt; fingerprint. The hashed fingerprint is used to look up the bridge on
&gt; the website.

Right. It was rather stupid thinking on my side. If someone connects
to a bridge from $country, he already knows the IP address of that
bridge. m(

&gt;&gt; I'd like to add something else instead: Giving out information about
&gt;&gt; which bridge is known to be blocked in which country maybe? I know
&gt;&gt; that feature isn't in BridgeDB yet, but it is on my TODO-list for it.
&gt;&gt; I don't see much risk in disclosing this information, but it'd bring
&gt;&gt; some sort of awareness and also offers data for researchers.
&gt;
&gt; I think this is probably hard to do reliably, as blockings are very
&gt; inhomogenous if you look at an entire country. Another point
&gt; is that seeing no Burmese users on my bridge doesn't mean the
&gt; bridge is blocked there - maybe nobody has gotten its descriptor,
&gt; or the people who have it turned off their Tor. This will be more
&gt; common as we gain more bridges.

You're right that we need much more research in this area. I didn't
mean to add this info right away but I wanted to mention it so it
isn't forgotten.

As far as I know we really don't yet know a good algorithm (other than
testing and updating by hand [which is not what I'd call good]) that
will tell us "brigde X is blocked in country Y". We surely don't want
to scan in an automated and frequent way to help them learn all
bridges. Maybe heuristics are our answer: "based on data we have,
bridge X is likely to be blocked from country Y". Maybe people should
be able to tell us if they think a bridge is blocked: By mail or web
interface, whichever they are still able to reach. The more "bridge X
is blocked in Y" information we get from users for a certain bridge,
the more likely that bridge will really be blocked. Obviously that
method is open to manipulation. Maybe there's more information we
could gather. Some trusted contact person from China tells us "bridge
X is blocked" and we can manually update information for that bridge
which gets more weight in our heuristics. Sounds clumsy though.

The thing is, we should be able to stop handing out bridges to Chinese
users that we know are blocked there.

For the most commonly use cases Iran and China, are we really seeing
blockings on ISP level? I thought it was countrywide and therefore
rather homogenous. I might be wrong.

About your question what users can do with that information, I don't
really have a certain special use case to pinpoint. I'd say its a
statistical record. Researchers might be interested. I don't consider
it dangerous to give out and I think it's good to be transparent.

Thanks,
/C
</body></email><email><emailId>20100526141645</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-26 14:16:45-0400</timestampReceived><subject>Orbot debugging</subject><body>


Hi Nathan,

I just committed a small change for Orbot that we should always keep for
public builds in the future. Jesse Burns pointed out a possible issue
that would be relevant for forensics.

We previously had debugging enabled in Orbot/AndroidManifest.xml; this
should absolutely not be enabled in the Marketplace or on any production
builds. I've committed revision 22401 to address this and to disable
debugging by default.

All the best,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100526153607</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-26 15:36:07-0400</timestampReceived><subject>Orbot bugs and an upcoming Market release</subject><body>


Hi Nathan,

I think that we're pretty close to having a reasonable Orbot package for
release into the Android Market. Sebastian and I had a conversation
about outstanding bugs; we came up with pretty short list of bugs that
are important for a public release.

This bug is largely about cosmetic documentation. Orweb (or Fennec, etc)
will make it largely irrelevant (I've closed it):
https://trac.torproject.org/projects/tor/ticket/1280

This bug is insanely complicated with many interesting sub points.
Sadly, it's impossible to address the issues because they're just one
giant bug. I've closed it and I think some should open bugs for each issu=
e:
https://trac.torproject.org/projects/tor/ticket/1284

This bug is probably a blocker for release. We should catch that Tor is
unhappy and abort, perhaps reverting to a good config:
https://trac.torproject.org/projects/tor/ticket/1286

This bug has been fixed (I've closed it):
https://trac.torproject.org/projects/tor/ticket/1336

All the best,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100507131507</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-07 13:15:07-0400</timestampReceived><subject>Tor hardening at compile time</subject><body>

[Attachment #2 (multipart/mixed)]


Hi,

I've pushed a new git branch 'compileTimeHardening' out to my git repo.
I've also attached a patch for those that are git adverse. Either way,
apply the patch to your current Tor master sources and you should be in
good shape.

You can use it like so:
=2E/autogen.sh &amp;&amp; ./configure --enable-gcc-warnings --enable-gcc-hardenin=
g
--enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make install

The end result on Debian Lenny is a slightly hardened build when checked
with checksec.sh[0].

This is weasel's build on my x86 machine:
RELRO           STACK CANARY      NX            PIE
   Partial RELRO   Canary found      NX enabled    PIE enabled

This is a build with my new options on the same machine:
RELRO           STACK CANARY      NX            PIE
Full RELRO      Canary found      NX enabled    PIE enabled

This is a build without my new options on the same machine:
RELRO           STACK CANARY      NX            PIE
No RELRO        No canary found   NX enabled    No PIE

This seems like a useful improvement for people building from source.

The gcc hardening flag works on Mac OS X. The linker hardening is
specific to the ELF binary format and does not work on Mac OS X. So on
Mac OS X, only use '--enable-gcc-hardening' and not
'--enable-linker-hardening' for your builds.

Checksec doesn't work on Mac OS X. It does appear to be possible to
check if a binary has a stack canary by doing the following (Using Mac
OS X 10.6.3 here):

	nm /bin/ls | grep "chk_guard"

You should see something like this:

	U ___stack_chk_guard

Also, you can check by looking for the following with otool on Mac OS X:

	otool -tvV /bin/ls | grep "___stack_chk_fail"

You should see something like this:

	00004bf7        calll   0x00005468      ; symbol stub for:
___stack_chk_fail

If you look at /Applications/Vidalia.app/Contents/MacOS/tor, you will
not see those protections at the moment. I think we can improve our
shipping Mac OS X binaries by enabling these protections. The PIE
protections won't really matter until Apple fixes their platform
(perhaps in 10.7?!); still it's nice to be ready and this patch provides
that too.

It appears that FORTIFY_SOURCE is on by default on Mac OS X. We don't
currently build Tor on Mac OS X with stack canaries though, so we're
improving Tor's security on Mac OS X. It may not be possible to do this
for all versions of Mac OS X - I suspect that Apple may disable some or
all protections to make a binary more compatible with different Mac OS X
versions.

It would be useful to get some extra testing on other platforms; is
anyone working with Windows building and interested in testing this? I
also left a comment in the patch for hardening flags that would be
useful with a non-gcc compiler on Windows.

There is some performance cost to running Tor with these security
enhancements. Debian already runs with most of the run time checks and
the relays on Debian appear to be just fine. The only real enhancement
for Linux systems is a startup time cost to gain protection from GOT/PLT
overwrites (if you're already using Weasel's packages).  If you're
merely building from source on any of the supported platforms, it's a
huge gain.

I think this option should be enabled by default at some point in the
future but probably not until we have a reasonably exhaustive list of
information for our major platforms. After we have a little testing from
Tor developers, I'll ask on or-talk for some testers.

It would be nice to have it merged into master as an optional option
soon though. Roger seemed to think this was a fine idea. I think it may
encourage people to try it out and to help us decide if it's worth
applying as a build default.

All the best,
Jacob

[0] http://www.trapkit.de/tools/checksec.html

["gcc-hardening-linker-hardening.patch" (text/x-patch)]

diff --git a/configure.in b/configure.in
index 10e509d..2b1210c 100644
--- a/configure.in
+++ b/configure.in
@@ -90,6 +90,26 @@ AC_ARG_ENABLE(gcc-warnings,
 AC_ARG_ENABLE(gcc-warnings-advisory,
      AS_HELP_STRING(--enable-gcc-warnings-advisory, [enable verbose warnings, excluding -Werror]))
 
+dnl Adam shostack suggests the following for Windows:
+dnl -D_FORTIFY_SOURCE=2 -fstack-protector-all
+dnl Others suggest '/gs /safeseh /nxcompat /dynamicbase' for non-gcc on Windows
+AC_ARG_ENABLE(gcc-hardening,
+     AS_HELP_STRING(--enable-gcc-hardening, enable compiler security checks),
+[if test x$enableval = xyes; then
+    CFLAGS="$CFLAGS -D_FORTIFY_SOURCE=2 -O2 -fstack-protector-all"
+    CFLAGS+=" -Wstack-protector -fwrapv -fPIE -Wformat -Wformat-security"
+    CFLAGS+=" -Wpointer-sign"
+    LDFLAGS+=" -pie"
+fi])
+
+dnl Linker hardening options
+dnl Currently these options are ELF specific - you can't use this with MacOSX
+AC_ARG_ENABLE(linker-hardening,
+        AS_HELP_STRING(--enable-linker-hardening, enable linker security fixups),
+[if test x$enableval = xyes; then
+    LDFLAGS+=" -z relro -z now"
+fi])
+
 AC_ARG_ENABLE(local-appdata,
    AS_HELP_STRING(--enable-local-appdata, default to host local application data paths on Windows))
 if test "$enable_local_appdata" = "yes"; then

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100429085827</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-04-29 08:58:27-0400</timestampReceived><subject>GeoIP database comparison</subject><body>


Hi everybody,

as you may or may not know, Tor uses a GeoIP database to resolve client
IP addresses to country codes for statistics. That's how we get the data
to plot usage-by-country graphs such as these:

  http://metrics.torproject.org/recurring-users-graphs.html

However, our GeoIP database was last updated on June 6, 2009, because a
subsequent update from our GeoIP database provider (ip-to-country) was
broken and declared most of the US IP addresses as unassigned. After
waiting for a few weeks for the database provider to fix this, we gave
up and kept on using the June 6, 2009 database.

Another issue with our current GeoIP database is that it didn't resolve
a single observed IP address to Tunisia, for example. But we know we
have users in Tunisia, so this cannot be true.

Time to look for alternatives. The alternatives I investigated are:

- Update to the most recent ip-to-country database from April 26, 2010,
available at
http://ip-to-country.webhosting.info/downloads/ip-to-country.csv.zip

- Switch to the Host IP database from April 26, 2010, available at
http://www.hostip.info/faq.html

- Switch to Maxmind's free GeoLite Country database from April 1, 2010,
available at http://www.maxmind.com/app/geolitecountry

In addition to these databases, I looked at two more sources, mostly for
comparison, not for shipping them with Tor:

- Maxmind's commercial GeoIP Country database, last updated on April 20,
2010

- Jake's blockfinder tool http://github.com/ioerror/blockfinder

In particular, I looked at IP address ranges assigned to Tunisia,
because our current database fails entirely here and because Tunisia has
a nice small number of IP ranges in all the databases that makes it easy
to handle for this comparison. I attached the analysis to this mail
(32K), so that it's in the mail archives.

The PDF has IP address ranges in its rows and country codes resolved by
the various databases in its columns. Larger IP address ranges are bold
and bigger. Here are some observations:

- Our current database (ip-to-country 6/3/09) resolves almost zero IP
addresses to Tunisia, just one /29, one /30, and one /28. No wonder
we're seeing no users from Tunisia. Let's give up on this database.

- The most recent ip-to-country database from 4/26/10 has the very same
IP address ranges for Tunisia. No need to upgrade, IMO.

- Host IP disagrees most with the other databases. Host IP has lots of
/24 ranges that it thinks are Tunisia, but which no other database
agrees with. Host IP fails to identify the two largest ranges
41.224.0.0/13 and 196.203.0.0/16 as Tunisia, as opposed to the two
Maxminds and blockfinder. I should also say that /24 is the smallest
unit that Host IP knows, which is quite imprecise. I think Host IP is
out, too.

- blockfinder knows about the largest ranges only, which are all at
least /24 in size. It agrees with both Maxmind databases in all these
ranges.

- Both Maxmind databases have quite a few smaller IP address ranges that
none or few of the other databases know. One of them is a /26, the
others are /28 or smaller.

- Commercial and free Maxmind have almost the same ranges for Tunisia.
One example for a difference is 196.203.0.0/16 which is split into 5
ranges in the commercial database covering 65470 addresses (compared to
65536 in the free database) which is an overlap of 99.899%.

From this comparison it looks like the free Maxmind database is a far
better choice than ip-to-country or Host IP.

Jake was so kind to run his fast directory mirror trusted with the free
Maxmind database for 24 hours. I compared the output of these 24 hours
with the 24 hours before and made these observations:

- With the free Maxmind database we suddenly have 320 requests from
Tunisia in 24 hours. Before that, we had constantly zero requests from
Tunisia. Yay!

- With the new database we only have 8 unresolved IP addresses. Before
that, trusted was unable to resolve 9024 requests with the ip-to-country
database, right after US with 17808 requests, DE with 11336 requests,
and KR with 9368 requests. That's a lot of unresolved IP addresses.

- Interestingly, trusted resolves 7368 requests to Nigeria with the
Maxmind database, which were only 8 with ip-to-country. I wonder if this
can be correct. Is Tor this well-known in Nigeria?

In summary, I think we should ship Maxmind's free database with Tor, if
the license permits it. I'm hoping to get much better usage statistics
results for smaller countries like Tunisia from the free Maxmind. Also,
Maxmind has more users and is therefore less likely to provide a broken
update and not noticing for weeks.

Thoughts?

Best,
--Karsten

["geoipdb-comparison-TN-2010-04-29.pdf" (application/pdf)]

</body></email><email><emailId>20100518091819</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-18 09:18:19-0400</timestampReceived><subject>Implementing proposal 147: Eliminate the need for v2 directories</subject><body>

Hi everyone,

Sebastian and I plan to implement proposal 147:


https://gitweb.torproject.org//tor.git?a=blob;f=doc/spec/proposals/147-prevoting-opinions.txt;h=3d9659c98435d22b43efa5c67b95090b9ff908e0;hb=HEAD


For those who are unable to look at documents behind three-line URLS,
the overview of this proposal says: "We propose a new v3 vote document
type to replace the role of v2 networkstatus information in generating
v3 consensuses."

Sebastian and I think that we really need this proposal to be
implemented in Tor soon, because we're running out of v2 authorities.
Only 2 of them are still running: tor26 and dizum. Time to get rid of v2.

Here are some thoughts on the implementation: We could implement this
proposal in phases with running and tested prototypes at the end of each
phase.


Phase 0: Set up PuppeTor test case to show that it's broken

- Set up 3 v3 directory authorities and 1 relay. Configure the relay
with only 1 of the directory authorities. Watch how the relay is not
contained in the first consensus, but in the second.


Phase 1: Authorities generate opinions (and ensure they can parse them)
when we ask them to do so

- Write code to generate and parse v3 opinions, including unit tests.

- Add a new URL for everyone to request the current v3 opinion of an
authority. Requesting this URL triggers the opinion-generating code.

- Ponder caching our own v3 opinion for up to X minutes or until we
learn about a change in descriptors.

- Make PuppeTor download and parse v3 opinions of all three directory
authorities and compare their contents to what we would expect the
authorities to know.

- Update dir-spec.txt to reflect what a v3 opinion is.


Phase 2: Process opinions when uploaded from another authority

- Add a new URL for authorities to post their v3 opinions.

- Write code to process v3 opinions. This includes verifying signatures
and downloading missing descriptors from the authority that sent the
opinion.

- Make PuppeTor feed the v3 opinion from the directory authority the
relay knows about into the other two directory authorities. Watch how
the relay is included in the first consensus.


Phase 3: Include opinion-exchanging phase in voting process

- Add an opinion-exchanging phase preceding the vote-exchanging phase.
With default values, the voting phase is from :50 to :55, so that the
opinion phase would be :45 to :50. Add config options to adjust the
length of this new phase.

- Update TestingTorNetwork to reduce this phase to 20 seconds.

- Update dir-spec.txt to reflect the new opinion-exchanging phase.

- At the beginning of the opinion-exchanging phase, upload our opinion
to all other authorities.

- After 50% of the opinion-exchanging phase have passed, request missing
opinions from the respective authorities.

- Run the PuppeTor test case and watch how the relay is contained in the
first consensus.

- Run the same PuppeTor test case with the directory authority that the
relay knows about, running the tor binary from the previous phase. That
directory won't upload its opinion to the other directories at :45, but
the other directories will request the opinion at :47:30. Watch how the
relay is still contained in the first consensus.



There could be a phase 4 that includes caching other authorities'
opinions to overcome the situation when both uploading and requesting
between two authorities fails. It's marked as MAY in the proposal, and
I'm not sure if we really need it. We could decide this at a later point.

Sebastian, Nick, others: Please feel free to comment on this plan.

Thanks,
--Karsten


</body></email><email><emailId>20100522074001</emailId><senderName>"torsecurity"</senderName><senderEmail>torbridges.security@gmail.com</senderEmail><timestampReceived>2010-05-22 07:40:01-0400</timestampReceived><subject>A attack aganist Tor?</subject><body>

A strange thing, everyone!

I use a tor bridge (freedomwithwall) connecting to Tor and it seems doing well. But \
when I observe ( four) circuits  the Tor created, I find the second and the last tor \
nodes do not exsit! Their nicknames  are not in the cached-descriptors or \
cached-descriptors.new files. The Vidalia can not show their IPs also, just show the \
freedomwithwall's IP.

I have never seen this happen before.

Is the bridge freedomwithwall a mallicious node and the middle and exit nodes are \
fake?


[Attachment #3 (text/html)]

&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"&gt;
&lt;HTML&gt;&lt;HEAD&gt;
&lt;META http-equiv=Content-Type content="text/html; charset=us-ascii"&gt;
&lt;STYLE&gt;BLOCKQUOTE {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; MARGIN-LEFT: 2em
}
OL {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px
}
UL {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px
}
&lt;/STYLE&gt;

&lt;META content="MSHTML 6.00.2900.5945" name=GENERATOR&gt;&lt;/HEAD&gt;
&lt;BODY style="MARGIN: 10px"&gt;&lt;FONT size=2&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;A strange thing, everyone!&lt;BR&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;I use a tor bridge (&lt;EM&gt;freedomwithwall&lt;/EM&gt;) connecting 
to Tor and it seems doing well. But when I observe ( four) 
circuits  the Tor created, I find the second and the last tor nodes do 
not exsit! Their nicknames  are not in the cached-descriptors or 
cached-descriptors.new files. The Vidalia can not show their IPs also, 
just show the &lt;EM&gt;freedomwithwall&lt;/EM&gt;'s IP.&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;&lt;/FONT&gt;&lt;/SPAN&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;I have never seen this happen 
before.&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;&lt;/FONT&gt;&lt;/SPAN&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;SPAN&gt;&lt;FONT size=5&gt;Is the bridge &lt;EM&gt;freedomwithwall&lt;/EM&gt; a mallicious node 
and the middle and exit nodes are fake?&lt;/FONT&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;FONT 
size=5&gt;&lt;/DIV&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/BODY&gt;&lt;/HTML&gt;


</body></email><email><emailId>20100523191940</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2010-05-23 19:19:40-0400</timestampReceived><subject>Translated manpages</subject><body>

Hi,

I have been working on finding a way to translate the manpages via the
translation interface. There are only two small issues left: (1)
figure out whether or not tor-manual-dev.wml and tor-manual.wml should
be based on the same manpage, and (2) what we should do with the
translated manpages.

Both tor-manual-dev.wml and tor-manual.wml generate the manpages that
are displayed on the website. These files use the same manpage to
generate the html files. That's probably not what we want. Which
manpage should tor-manual-dev.wml use, and which manpage should
tor-manual.wml use?

We have four manpages in total, but only one is displayed on the
website. We do not want to ship translated manpages, but what should
we do with translations? Should we put everything on the website?

Comments and/or questions are always appreciated.

Thanks,

-- 
Runa A. Sandvik
</body></email><email><emailId>20100524220434</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-05-24 22:04:34-0400</timestampReceived><subject>Integrating libnatpnp and miniupnpc into Tor</subject><body>

Currently Vidalia is using miniupnpc [1] to automatically configure
port forwarding on UPnP compatible routers, but this means that people
running a headless Tor instance are out of luck. This is particularly
bad because it is likely that the most reliable potential Tor
bridges/relays are headless.

So as to help support the draft proposal on automatic bridge promotion
[2] Jake and I've been working on adding UPnP and NAT-PMP support to
Tor, so as to allow Tor bridge and relay operators to automatically
configure their NAT router to port-forward. For NAT-PMP we are using
libnatpmp [2], which supports Apple hardware, and miniupnpc which
supports most of the rest.

The branch where this is work is happening is being maintained by
Jake:

 https://gitweb.torproject.org/ioerror/tor.git/shortlog/refs/heads/natpmp

Currently it is only a stand-alone utility, but eventually the plan is
to integrate it into Tor. Before we do so there are a few design
options that we should consider.

The first is how the library will be called by Tor. One option is to
call it from the Tor main thread. This is simple, but has the
disadvantage that a bug in the library could cause Tor to crash. This
would annoy the user, but on the other hand a Tor bridge without port
forwarding being set up isn't much use.

Another option is to fork() off a new process. This would insulate Tor
from crash bugs, but isn't as robust security-wise because the
subprocess would have read-only access to Tor's memory (unless we
fiddle with page table permissions).

Yet another option would be to fork() and exec(). This might be tricky
to get right because Tor would need to find where the helper program
lives. It would give some security isolation, but not much because the
subprocess would still be running under the same user ID.

Another choice we have is how to manage the build process. Neither
miniupnpc or libnatpmp come with binary packages for major Linux
distributions. Asking people to build these before building Tor might
be too much to ask (especially given that they don't use autoconf).
Also we might want to keep the version we use under our own control
because in the past the library has broken API compatibility and their
build scripts currently don't work on all platforms (notably the BSD
family).

For these reasons both Vidalia and the Transmission BitTorrent client
keep versions of the libraries in their own source tree, and update
from the upstream periodically. At least for Vidalia, the build of the
libraries is done using the same build tool (Cmake) as the rest of the
code and we could do the same with autoconf. Having to track an
external library isn't great, but it might be the best of the
available options.

Any comments?

Steven.

[1] http://miniupnp.free.fr/
[2] http://miniupnp.free.fr/libnatpmp.html
[3] https://gitweb.torproject.org/sjm217/tor.git/blob/xxx-automatic-node-promotion:/doc/spec/proposals/ideas/xxx-automatic-node-promotion.txt


-- 
http://www.cl.cam.ac.uk/users/sjm217/


</body></email><email><emailId>20100521110612</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-21 11:06:12-0400</timestampReceived><subject>Database schema for metrics portal</subject><body>

Hi Kevin,

here are some thoughts on importing relay descriptors into a database.

You may already have noticed that there are three documents holding
information about a relay in the Tor network: network status entry,
server descriptor, and extra-info descriptor. In the past, I have used
three tables and joined them whenever necessary. It turned out that join
operations are highly inefficient and that it doesn't even make sense to
join extra-info descriptors with network status entries and server
descriptors.

Here's an example. The current network status consensus has this entry
for gabelmoo:

r gabelmoo 8gREE9rC4C49a89HNaGbyh3pcoE gL7MFClJBGG6l3KzCXJPh5fQnl8
2010-05-21 02:34:42 80.190.246.100 8080 8180
s Authority Fast Guard HSDir Running Stable Unnamed V2Dir Valid
v Tor 0.2.2.13-alpha
w Bandwidth=512
p reject 1-65535


The referenced server descriptor gL7MFCl... in base64 or
80becc1429490461ba9772b309724f8797d09e5f in hex has this content:

router gabelmoo 80.190.246.100 8080 0 8180
platform Tor 0.2.2.13-alpha (git-a3db6300225c5f34) on Linux i686
opt protocols Link 1 2 Circuit 1
published 2010-05-21 02:34:42
opt fingerprint F204 4413 DAC2 E02E 3D6B CF47 35A1 9BCA 1DE9 7281
uptime 1154088
bandwidth 512000 1280000 1166966
opt extra-info-digest CECC7F83F5CD771BF0DF9827C08F561CE84A5DA3
opt caches-extra-info
onion-key
-----BEGIN RSA PUBLIC KEY-----
MIGJAoGBANbj/L3FZCbIKNdBKMH1tamU/r+9p+X4fI+1i9jDtHt11D4Rz+rsQ4CX
8no0NMx2yOHpvq7Cp8scO2ZcH4UjQ/bJIumgGqjuslWMn9KtrbBKdtNzVtOMNjYY
7zjZJ8UVmS1/hH2wl2dwZeAVbQ931u9DWX5R/u1ck28EQS8C2Z/jAgMBAAE=
-----END RSA PUBLIC KEY-----
signing-key
-----BEGIN RSA PUBLIC KEY-----
MIGJAoGBAMjPhp0QAN8WQeP8sDg+mnM7hnPExcXTOfsmt7Sl2k3fHcHeAJnYu10V
/hb6RBhubi1HRg6fYF5PwZWOppxRj90WX3n2JEcQh88+4tuQNQ2jOxXQ/hBkyf0w
klrx6Fh8ana1VX+QXInfRW5z3eaANXqvdCvDG5jfUrz6pj8WGPrxAgMBAAE=
-----END RSA PUBLIC KEY-----
opt hidden-service-dir
contact 1024D/F7C11265 Karsten Loesing &lt;karsten dot loesing AT gmx dot net&gt;
reject *:*
router-signature
-----BEGIN SIGNATURE-----
FxYg32MXPM2aOoa5q244CgSs0/EUw4nKJsxde0sD2f3zav7dXdBJBTrv0GdPETUC
iv125vk/zCNNljk2c3bbNAKVnFbBYyBXnJ7/BJL+kSAPYTpQGpIw6RXl3NtWhyZa
08weBwj1bY+xZzYzgB7yuhPvYzH4F/Ji6qLzRsTfJp0=
-----END SIGNATURE-----


And finally, the referenced extra-info descriptor cecc7f83... is:

extra-info gabelmoo F2044413DAC2E02E3D6BCF4735A19BCA1DE97281
published 2010-05-21 02:34:42
write-history 2010-05-21 02:32:48 (900 s)
544401408,540996608,642924544,583867392,653665280,637046784,684775424,598684672,586347 \
520,658676736,630778880,719997952,486724608,622078976,748093440,589464576,539460608,80 \
1062912,825155584,805288960,791465984,678842368,636246016,630557696,679609344,66648678 \
4,621635584,758945792,654635008,513009664,617194496,636549120,748435456,865181696,7365 \
25312,715303936,742599680,690369536,870909952,873070592,690373632,661690368,703024128, \
689483776,837165056,626258944,741469184,897375232,802021376,669841408,719076352,717147 \
136,819868672,731346944,717606912,574259200,624780288,682221568,708850688,666567680,73 \
4041088,725368832,799907840,881100800,896225280,907387904,854701056,934236160,91013222 \
4,856087552,894130176,831595520,846332928,831883264,925052928,840542208,701243392,7418 \
79808,707265536,858382336,931992576,926849024,923104256,888730624,934275072,929859584, \
938267648,938893312,929412096,928772096,876532736,828409856,885524480,806822912,656070656,632248320
 read-history 2010-05-21 02:32:48 (900 s)
540297216,534199296,628869120,572840960,648410112,631605248,663860224,588089344,580211 \
712,650313728,608541696,701733888,478575616,611846144,726459392,572938240,526454784,78 \
6325504,806251520,796734464,787733504,669499392,621448192,617405440,674842624,66001305 \
6,599517184,743075840,644049920,506447872,603792384,622928896,742297600,860128256,7126 \
41536,694036480,735109120,682270720,852083712,859357184,683282432,656016384,680463360, \
673383424,831110144,622981120,720413696,891073536,798917632,669814784,705187840,709612 \
544,818158592,729244672,703837184,564427776,625363968,682468352,691994624,660142080,73 \
3149184,725949440,785703936,875602944,896345088,909398016,846983168,933785600,91714867 \
2,854514688,884723712,822371328,844339200,821991424,913144832,828115968,695621632,7371 \
74528,691364864,847837184,934027264,929199104,912046080,877563904,940472320,937701376, \
935174144,940459008,940481536,938059776,867339264,817305600,884368384,800684032,641873920,621056000
 dirreq-stats-end 2010-05-20 17:59:54 (86400 s)
dirreq-v3-ips
us=880,de=752,fr=320,it=224,kr=224,ru=200,gb=176,pl=128,ca=96,ng=88,nl=88,ir=80,jp=80, \
pk=80,br=72,se=72,at=64,au=56,ch=56,es=56,ph=48,ua=48,mx=40,sn=40,th=40,tr=40,be=32,fi \
=32,in=32,tw=32,ar=24,bg=24,cz=24,dk=24,eg=24,gh=24,gr=24,ie=24,no=24,ro=24,sg=24,vn=2 \
4,a1=16,by=16,ci=16,co=16,dz=16,hk=16,hr=16,hu=16,id=16,il=16,kw=16,kz=16,ma=16,my=16, \
nz=16,pt=16,sa=16,si=16,sk=16,ve=16,za=16,??=8,a2=8,ae=8,ao=8,aw=8,bd=8,bj=8,bn=8,bo=8 \
,bs=8,cl=8,cr=8,cy=8,do=8,ec=8,ee=8,et=8,eu=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq=8,is=8,jo=8, \
ke=8,kg=8,lb=8,lt=8,lu=8,lv=8,md=8,mn=8,mt=8,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,ps=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tn=8,tt=8,tz=8,uz=8,ye=8
 dirreq-v2-ips ng=8
dirreq-v3-reqs
us=1992,de=1296,fr=568,ru=344,kr=304,gb=280,it=256,ng=208,nl=200,se=176,pl=152,at=136, \
ca=112,br=104,jp=104,ir=88,ph=88,ar=80,es=80,pk=80,ua=80,au=72,ch=72,tw=64,fi=56,be=48 \
,cz=48,th=48,tr=48,bg=40,in=40,mx=40,sn=40,dk=32,gr=32,no=32,ro=32,sg=32,eg=24,gh=24,h \
k=24,id=24,ie=24,il=24,pt=24,sk=24,vn=24,a1=16,a2=16,ae=16,by=16,ci=16,cl=16,co=16,dz= \
16,ee=16,hr=16,hu=16,kw=16,kz=16,lb=16,lv=16,ma=16,mn=16,my=16,nz=16,ps=16,sa=16,si=16 \
,tn=16,ve=16,za=16,??=8,ao=8,aw=8,bd=8,bj=8,bn=8,bo=8,bs=8,cr=8,cy=8,do=8,ec=8,et=8,eu \
=8,ge=8,gg=8,gt=8,hn=8,ht=8,iq=8,is=8,jo=8,ke=8,kg=8,lt=8,lu=8,md=8,mt=8,mu=8,nc=8,pa=8,pe=8,pf=8,pr=8,qa=8,rs=8,sc=8,sd=8,sm=8,so=8,sv=8,sy=8,tt=8,tz=8,uz=8,ye=8
 dirreq-v2-reqs ng=8
dirreq-v3-resp
ok=8000,not-enough-sigs=0,unavailable=0,not-found=0,not-modified=0,busy=0
dirreq-v2-resp ok=8,unavailable=0,not-found=0,not-modified=0,busy=0
dirreq-v2-share 0.00%
dirreq-v3-share 0.00%
dirreq-v3-direct-dl
complete=3924,timeout=24,running=0,min=529,d1=49744,d2=84867,q1=103848,d3=119618,d4=165491,md=215631,d6=293536,d7=428605,q3=500448,d8=656839,d9=1507344,max=25818600
 dirreq-v2-direct-dl complete=4,timeout=0,running=0
dirreq-v3-tunneled-dl
complete=3968,timeout=88,running=4,min=161,d1=24326,d2=51796,q1=61586,d3=71895,d4=91512,md=121749,d6=161907,d7=231554,q3=285958,d8=343692,d9=529069,max=25762200
 dirreq-v2-tunneled-dl complete=0,timeout=0,running=0
entry-stats-end 2010-05-20 17:59:54 (86400 s)
entry-ips
de=1832,us=1680,kr=912,fr=680,it=672,ru=416,gb=384,pl=352,ir=336,jp=264,ng=240,ca=216, \
br=208,es=168,in=152,pk=144,at=128,au=128,nl=128,ph=128,se=128,tr=128,ua=112,ch=104,th \
=104,mx=96,tw=80,cz=72,ar=64,fi=64,sn=64,be=56,hu=56,ie=56,il=56,tn=56,vn=56,dk=48,gh= \
48,gr=48,id=48,kw=48,ma=48,no=48,ro=48,sa=48,??=40,bg=40,ci=40,eg=40,hk=40,my=40,pt=40 \
,za=40,co=32,dz=32,nz=32,sg=32,a1=24,by=24,cl=24,kz=24,sk=24,ve=24,a2=16,bd=16,bj=16,h \
r=16,jo=16,ke=16,lb=16,lt=16,lu=16,pe=16,ps=16,rs=16,sd=16,si=16,sy=16,ye=16,ae=8,af=8 \
,al=8,am=8,ao=8,aw=8,az=8,ba=8,bb=8,bh=8,bn=8,bo=8,bs=8,cm=8,cn=8,cr=8,cy=8,dj=8,do=8, \
ec=8,ee=8,eu=8,fj=8,fo=8,ge=8,gg=8,gt=8,gy=8,hn=8,ht=8,iq=8,is=8,jm=8,kg=8,ky=8,lk=8,l \
v=8,ly=8,mc=8,md=8,me=8,mg=8,mk=8,ml=8,mo=8,mr=8,mt=8,mu=8,mv=8,nc=8,ni=8,np=8,pa=8,pf=8,pr=8,py=8,qa=8,sc=8,so=8,sv=8,tg=8,tt=8,tz=8,ug=8,uy=8,uz=8
 cell-stats-end 2010-05-20 17:59:54 (86400 s)
cell-processed-cells 9890,208,69,27,16,7,5,5,4,2
cell-queued-cells 2.63,0.77,0.02,0.00,0.00,0.00,0.00,0.00,0.00,0.00
cell-time-in-queue 911,505,39,11,15,9,9,20,46,197
cell-circuits-per-decile 11482
exit-stats-end 2010-05-20 17:59:54 (86400 s)
exit-kibibytes-written other=0
exit-kibibytes-read other=0
exit-streams-opened other=0
router-signature
-----BEGIN SIGNATURE-----
N1CbWArG7rBEXa0r6dprMSh/HkdcpjtRyG0zScAJAYp76j4Nm/bIZz8UbDTwauqN
G9ysHp+qUf4IAuSDrYeLrSo5mrHuQOEDfEfA04eJ9bS2QzTFYZeO6kEFXlSprnc3
IC23R/isVEpDqM2qaWKnBIo3mT7bKram7GO1weIDfR0=
-----END SIGNATURE-----


One thing you can see here is that all fields in extra-info descriptors
have their own timestamps. None of the data in extra-info descriptors
requires knowledge of the corresponding server descriptor or network
status entry. If you want to analyze data from the extra-info
descriptors, you can import them into a table of its own.

So, what about joining network status entries and server descriptors?
There are statistics when it makes sense to join these documents. For
example, you might want to evaluate assigned relay flags (Stable, Guard;
contained in network status entry) and uptime (contained in server
descriptor) at the same time. In particular, it's almost never useful to
base statistics solely on server descriptors, because relays are not
even confirmed to be reachable when you only have a server descriptor.

How do you avoid join operations in your queries? I'd think that having
2 import tables for network status entries and server descriptors and 1
unnormalized table containing all data for aggregation/querying might be
a good approach. You might be able to update that 1 table by using
triggers on the other 2 tables. You'll have lots of redundant data in
your database: all fields in your server descriptors can be contained in
up to 24 rows, as the maximum amount of time a server descriptor is
valid is 24 hours. But that's probably fine, as there's not so much
stuff in server descriptors that's useful for statistics anyway. And
you'll be excited how fast queries are without having to join tables. :)


Also, as discussed on #tor-dev, below are some notes on creating a
database schema for the BIRT-based metrics portal we had a couple of
months ago (and only for a very short time). I don't think you can
re-use everything as-is, but maybe you find some of the ideas useful for
your database schema.

Best,
--Karsten


Data table
----------

The data table only includes entries from network statuses, not from
server descriptors or extra-info descriptors.

  CREATE TABLE statusentry (
    validafter TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    fingerprint CHARACTER(40),
    hashed_fingerprint CHARACTER(40) NOT NULL,
    bridge BOOLEAN NOT NULL DEFAULT false,
    descriptor CHARACTER(40) NOT NULL,
    authority BOOLEAN NOT NULL DEFAULT false,
    badexit BOOLEAN NOT NULL DEFAULT false,
    baddirectory BOOLEAN NOT NULL DEFAULT false,
    exit BOOLEAN NOT NULL DEFAULT false,
    fast BOOLEAN NOT NULL DEFAULT false,
    guard BOOLEAN NOT NULL DEFAULT false,
    hsdir BOOLEAN NOT NULL DEFAULT false,
    named BOOLEAN NOT NULL DEFAULT false,
    stable BOOLEAN NOT NULL DEFAULT false,
    running BOOLEAN NOT NULL DEFAULT false,
    unnamed BOOLEAN NOT NULL DEFAULT false,
    valid BOOLEAN NOT NULL DEFAULT false,
    v2dir BOOLEAN NOT NULL DEFAULT false,
    v3dir BOOLEAN NOT NULL DEFAULT false,
    bandwidthmeasured BIGINT CHECK (bandwidthmeasured &gt;= 0),
    country CHARACTER(2),
    PRIMARY KEY (validafter, hashed_fingerprint, bridge));


Network size
------------

The network size is determined as the mean number of running relays or
bridges on a given day. These numbers are calculated from the network
status by counting the number of running relays or bridges over the day
and dividing them by the number of network statuses per that day:

  CREATE VIEW network_size_v AS
    SELECT DATE(validafter),
      SUM(CASE WHEN bridge IS FALSE THEN 1 ELSE 0 END) /
        relay_statuses_per_day.count AS avg_relays,
      SUM(CASE WHEN bridge IS TRUE THEN 1 ELSE 0 END) /
        bridge_statuses_per_day.count AS avg_bridges
    FROM statusentry,
      (SELECT COUNT(*) AS count, DATE(validafter) AS date
        FROM (SELECT DISTINCT validafter FROM statusentry
          WHERE bridge IS FALSE)
        distinct_consensuses GROUP BY DATE(validafter))
        relay_statuses_per_day,
      (SELECT COUNT(*) AS count, DATE(validafter) AS date
        FROM (SELECT DISTINCT validafter FROM statusentry
          WHERE bridge IS TRUE)
        distinct_consensuses GROUP BY DATE(validafter))
        bridge_statuses_per_day
    WHERE statusentry.running IS TRUE
      AND DATE(validafter) = relay_statuses_per_day.date
      AND DATE(validafter) = bridge_statuses_per_day.date
    GROUP BY DATE(validafter), relay_statuses_per_day.count,
      bridge_statuses_per_day.count
    ORDER BY DATE(validafter);

The resulting view is 'materialized' by creating a table with the
contents of the view. Finally, the query role gets select rights for the
materialized view:

  CREATE TABLE network_size_mv as SELECT * FROM network_size_v;

  GRANT SELECT ON network_size_mv TO query;


Platforms and relay versions
----------------------------

The reports on platforms and relay versions are based on network status
entries in combination with relay descriptors. The information whether a
relay was running and contained in a network status comes from the
statusentry relation, whereas the simplified platform string comes from
the descriptor relation. For each date, the number of running relays are
counted, grouped by platform string, and divided by the number of stored
network statuses at that day:

  CREATE VIEW platforms_v AS
    SELECT DATE(validafter) AS date, platform,
    COUNT(*) / relay_statuses_per_day.count AS count
    FROM (
      SELECT COUNT(*) AS count, DATE(validafter) AS date
      FROM (
        SELECT DISTINCT validafter
        FROM statusentry
        WHERE bridge IS FALSE) distinct_consensuses
      GROUP BY DATE(validafter)) relay_statuses_per_day
    JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)
    LEFT JOIN descriptor
      ON statusentry.descriptor = descriptor.descriptor
    WHERE running IS TRUE AND bridge IS FALSE
    GROUP BY DATE(validafter), platform, relay_statuses_per_day.count,
      relay_statuses_per_day.date
    ORDER BY DATE(validafter), platform;

The mean numbers of relays per day running a certain Tor version are
determined similarly:

  CREATE VIEW versions_v AS
    SELECT DATE(validafter) AS date,
      SUBSTRING(version, 1, 5) AS version,
      COUNT(*) / relay_statuses_per_day.count AS count
    FROM (
      SELECT COUNT(*) AS count, DATE(validafter) AS date
      FROM (
        SELECT DISTINCT validafter
        FROM statusentry
        WHERE bridge IS FALSE) distinct_consensuses
      GROUP BY DATE(validafter)) relay_statuses_per_day
    JOIN statusentry ON relay_statuses_per_day.date = DATE(validafter)
    LEFT JOIN descriptor
      ON statusentry.descriptor = descriptor.descriptor
    WHERE running IS TRUE AND bridge IS FALSE
    GROUP BY DATE(validafter), SUBSTRING(version, 1, 5),
      relay_statuses_per_day.count, relay_statuses_per_day.date
    ORDER BY DATE(validafter), SUBSTRING(version, 1, 5);

Finally, two tables are created with the contents of these two views in
order to accelerate querying, and select rights are granted to the query
role:

  CREATE TABLE platforms_mv as SELECT * FROM platforms_v;

  CREATE TABLE versions_mv as SELECT * FROM versions_v;

  GRANT SELECT ON platforms_mv TO query;

  GRANT SELECT ON versions_mv TO query;


Bridge churn
------------

Bridge churn is visualized as time plot with four lines showing how many
of the running bridges at a given time are still running 1
day/week/month later. The fewer bridges are missing after those times,
the more stable the bridge population is.

The necessary query table for this report is constructed in multiple
steps. To begin with, the set of bridges in network statuses is reduced
to the first network status of each day:

  CREATE VIEW bridges_day_v AS
    SELECT DATE(validafter), hashed_fingerprint
    FROM statusentry
    WHERE validafter IN (
      SELECT MIN(validafter)
      FROM statusentry
      WHERE bridge IS true AND running IS true
      GROUP BY DATE(validafter))
    AND bridge IS true AND running IS true;

The resulting view is materialized, as it is used by multiple other views:

  CREATE TABLE bridges_day_mv AS SELECT * FROM bridges_day_v;

In the next step, four views are created that determine how many bridges
overlap in the sets of a given date and a date 1 day/week/month in the
future from then:

  CREATE VIEW bridges_churn_now_v AS
    SELECT date, COUNT(*)
    FROM bridges_day_mv
    GROUP BY date;

  CREATE VIEW bridges_churn_day_v AS
    SELECT now.date, COUNT(*)
    FROM bridges_day_mv now, bridges_day_mv future
    WHERE now.date = DATE(future.date + interval '1 day')
      AND now.hashed_fingerprint = future.hashed_fingerprint
    GROUP BY now.date, future.date;

  CREATE VIEW bridges_churn_week_v AS
    SELECT now.date, COUNT(*)
    FROM bridges_day_mv now, bridges_day_mv future
    WHERE now.date = date(future.date + interval '1 week')
      AND now.hashed_fingerprint = future.hashed_fingerprint
    GROUP BY now.date, future.date;

  CREATE VIEW bridges_churn_month_v AS
    SELECT now.date, COUNT(*)
    FROM bridges_day_mv now, bridges_day_mv future
    WHERE now.date = date(future.date + interval '1 month')
      AND now.hashed_fingerprint = future.hashed_fingerprint
    GROUP BY now.date, future.date;

In the last step, these four views are joined into one common view:

  CREATE VIEW bridges_churn_v AS
    SELECT bridges_churn_now_v.date, bridges_churn_now_v.count AS now,
      bridges_churn_day_v.count AS day,
      bridges_churn_week_v.count AS week,
      bridges_churn_month_v.count AS month
    FROM bridges_churn_now_v
      LEFT JOIN bridges_churn_day_v
        ON bridges_churn_now_v.date = bridges_churn_day_v.date
      LEFT JOIN bridges_churn_week_v
        ON bridges_churn_day_v.date = bridges_churn_week_v.date
      LEFT JOIN bridges_churn_month_v
        ON bridges_churn_week_v.date = bridges_churn_month_v.date
      ORDER BY bridges_churn_now_v.date;

In order to improve query performance, a materialized view is created
based on the last view and is given select rights to the query role:

  CREATE TABLE bridges_churn_mv AS SELECT * FROM bridges_churn_v;

  GRANT SELECT ON bridges_churn_mv TO query;


Bridge churn histogram
----------------------

Bridge churn can be visualized as histogram with bars representing the
number of bridges that have been seen as running for a certain number of
days throughout 1 month.  The higher the bars for high numbers of days,
the more stable the bridge population is.

The underlying data set for this report is built from a sequence of
views, starting with a view on the bridges seen on the first days of a
month:

  CREATE VIEW bridges_hist_first_day_v AS
    SELECT DATE_TRUNC('month', validafter) AS first_day,
      hashed_fingerprint
    FROM statusentry
    WHERE DATE(validafter) IN (
      SELECT DATE(MIN(validafter))
      FROM statusentry
      WHERE bridge IS true AND running IS true
      GROUP BY DATE_TRUNC('month', validafter))
    AND bridge IS true AND running IS true
    GROUP BY DATE_TRUNC('month', validafter), hashed_fingerprint;

In the next step, all days are selected on which these bridges have been
seen as running:

  CREATE VIEW bridges_hist_seen_v AS
    SELECT DATE(statusentry.validafter), statusentry.hashed_fingerprint
    FROM statusentry, bridges_hist_first_day_v
    WHERE DATE_TRUNC('month', statusentry.validafter) =
        bridges_hist_first_day_v.first_day
      AND statusentry.hashed_fingerprint =
        bridges_hist_first_day_v.hashed_fingerprint
    GROUP BY DATE(statusentry.validafter), statusentry.hashed_fingerprint;

For each distinct bridge in each month, the number of days that this
bridge has been seen as running are counted:

  CREATE VIEW bridges_hist_pre_v AS
    SELECT COUNT(*) AS days, DATE_TRUNC('month', date) AS month
    FROM bridges_hist_seen_v
    GROUP BY DATE_TRUNC('month', date), hashed_fingerprint;

Finally, the number of bridges for a given number of days are added up:

  CREATE VIEW bridges_hist_v AS
    SELECT COUNT(*), days, DATE(month) AS month
    FROM bridges_hist_pre_v
    GROUP BY month, days
    ORDER BY month, days;

A materialized view is created and given the select rights for the query
role:

  CREATE TABLE bridges_hist_mv AS SELECT * FROM bridges_hist_v;

  GRANT SELECT ON bridges_hist_mv TO query;


</body></email><email><emailId>20100526110215</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-26 11:02:15-0400</timestampReceived><subject>Bridge status website</subject><body>

Hi everyone,

Roger, Sebastian, and I have been discussing a possible bridge status
website that provides information to bridge operators whether their
bridge is considered running, is being distributed to users, and sees
actual users.

The problem is that, right now, bridge operators get little feedback
about the usefulness of their bridge. This is in contrast to relay
operators who have TorStatus, cached-consensus, and the like. Some of
the bridge operators may assume their bridge is not needed and stop
running it. We need to give bridge operators better support if we want
more bridges.

Here's the idea:

Bridge operators find a non-secret identifier in their logs or Tor data
directory. This identifier is the bridge identity hash. They can enter
this identifier on a public website and learn (a) whether their bridge
is marked in the most recent bridge network status as
Running/Stable/etc., (b) how many users the bridge had from which
countries in the past 24 hours, (c) whether the bridge is given out via
https/email/etc., (d) how much bandwidth was utilized in the past 24
hours, and so on. The assumption is that all of this information is
already public or will be made public in the future. The website may
contain the most recent information plus, say, a 30-day history
displayed in graphs. Bridge operators can bookmark this website and
share it with others without revealing the IP address or raw identity of
their bridge.

Here are some questions to discuss (people here will most likely have
more questions):

- Would such a website be useful for bridge operators and lead to more
people running bridges? What information would bridge operators want to
learn about?

- Can we publish the pool assignments from BridgeDB saying which bridge
identity hashes are contained in which pool? This information would also
be useful for researchers to learn more about blockings. What risks are
there in making this information public?

In addition to the possible bridge status website as discussed here,
Sebastian is working on heartbeat log messages containing the locally
known information about usefulness of a relay or bridge. There are two
shortcomings of heartbeat messages for bridges compared to a bridge
status website, though: The heartbeat log messages cannot contain
information about assigned flags or assigned distribution pool. Further,
bridge operators would need to log into the machine running the bridge
and read log messages or use Vidalia in order to see these heartbeat
messages. This is opposed to going to a website which can be done from
anywhere. Maybe we should do both approaches.

Best,
--Karsten
</body></email><email><emailId>20100526113340</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-05-26 11:33:40-0400</timestampReceived><subject>Re: Bridge status website</subject><body>

Hi Karsten,

first of all, I really like this proposal. Giving bridge users some
information on usage to play with will likely encourage them to keep
it running.

On Wed, May 26, 2010 at 1:02 PM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:

&gt; Bridge operators find a non-secret identifier in their logs or Tor data
&gt; directory. This identifier is the bridge identity hash. They can enter
&gt; this identifier on a public website and learn (a) whether their bridge
&gt; is marked in the most recent bridge network status as
&gt; Running/Stable/etc., (b) how many users the bridge had from which
&gt; countries in the past 24 hours, (c) whether the bridge is given out via
&gt; https/email/etc., (d) how much bandwidth was utilized in the past 24
&gt; hours, and so on. The assumption is that all of this information is
&gt; already public or will be made public in the future. The website may
&gt; contain the most recent information plus, say, a 30-day history
&gt; displayed in graphs. Bridge operators can bookmark this website and
&gt; share it with others without revealing the IP address or raw identity of
&gt; their bridge.

I wonder whether (b) is a good idea. Say I am Sir John McEvil and I
want to learn something about which IP address belongs to which
bridge: All I gotta do is iterate connections from some obscure
countries to certain bridges and check the stats later on.

Similar reasoning could go for (d) but I think bandwidth usage is
harder to track.

&gt; - Can we publish the pool assignments from BridgeDB saying which bridge
&gt; identity hashes are contained in which pool? This information would also
&gt; be useful for researchers to learn more about blockings. What risks are
&gt; there in making this information public?

By intuition I don't really like disclosing pool assignments.
"Researchers" learning about blockings could also be Chinese firewall
engineers. They shouldn't be able to tell if that mail traffic they
listened in on just now that contained some IP address/port
combinations actually helped them block 5 bridges from the 'private'
pool.

I guess I'd like to keep the information we give out as small as
possible, e.g. only give out bandwidth usage (d) and network status
infos (a) from that list above.

I'd like to add something else instead: Giving out information about
which bridge is known to be blocked in which country maybe? I know
that feature isn't in BridgeDB yet, but it is on my TODO-list for it.
I don't see much risk in disclosing this information, but it'd bring
some sort of awareness and also offers data for researchers.

Thanks,
/C
</body></email><email><emailId>20100526120939</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-05-26 12:09:39-0400</timestampReceived><subject>Re: Bridge status website</subject><body>


On May 26, 2010, at 1:33 PM, Christian Fromme wrote:
&gt; I wonder whether (b) is a good idea. Say I am Sir John McEvil and I
&gt; want to learn something about which IP address belongs to which
&gt; bridge: All I gotta do is iterate connections from some obscure
&gt; countries to certain bridges and check the stats later on.

This isn't really an issue: If they adversary has the ability to push
traffic through a bridge, it can learn its descriptor, and thus its
fingerprint. The hashed fingerprint is used to look up the bridge on
the website.

This attack would be more interesting if knowing the bridge
descriptor didn't give you the ability to make the query.

&gt; I'd like to add something else instead: Giving out information about
&gt; which bridge is known to be blocked in which country maybe? I know
&gt; that feature isn't in BridgeDB yet, but it is on my TODO-list for it.
&gt; I don't see much risk in disclosing this information, but it'd bring
&gt; some sort of awareness and also offers data for researchers.

I think this is probably hard to do reliably, as blockings are very
inhomogenous if you look at an entire country. Another point
is that seeing no Burmese users on my bridge doesn't mean the
bridge is blocked there - maybe nobody has gotten its descriptor,
or the people who have it turned off their Tor. This will be more
common as we gain more bridges.

Deciding when a country has blocked a bridge is something
that will need more research, imo. Once we've come up with
a good metric or possibly even some active testing, we could
integrate that later. I generally wonder what bridge operators
want to do with that information, though. There isn't really much
they can do other than change their ip - but if the bridge is still
working for some people, changing its IP also means sadness.

&gt; Thanks,
&gt; /C

Sebastian
</body></email><email><emailId>20100524025121</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-24 02:51:21-0400</timestampReceived><subject>Re: Translated manpages</subject><body>

On Sun, May 23, 2010 at 09:19:40PM +0200, Runa A. Sandvik wrote:
&gt; I have been working on finding a way to translate the manpages via the
&gt; translation interface. There are only two small issues left: (1)
&gt; figure out whether or not tor-manual-dev.wml and tor-manual.wml should
&gt; be based on the same manpage, and (2) what we should do with the
&gt; translated manpages.
&gt; 
&gt; Both tor-manual-dev.wml and tor-manual.wml generate the manpages that
&gt; are displayed on the website. These files use the same manpage to
&gt; generate the html files. That's probably not what we want. Which
&gt; manpage should tor-manual-dev.wml use, and which manpage should
&gt; tor-manual.wml use?

Currently tor-manual-dev.wml should be the man page for Tor 0.2.2.x.
You can find it in the latest git head under doc/tor.1.txt, and you
can convert it to html using the combination of git and asciidoc commands
you find in tor-manual-dev.wml.

Currently tor-manual.wml should be the man page for Tor 0.2.1.x. Since
Tor 0.2.1.x doesn't use asciidoc, you can convert doc/tor.1.in in the
maint-0.2.1 git branch using man2html (as you see in tor-manual.wml).

&gt; We have four manpages in total, but only one is displayed on the
&gt; website.

Yep. Anybody using the other three progams (tor-resolve, tor-gencert,
and torify) is hopefully using a command line so they can just read the
man page themselves.

&gt; We do not want to ship translated manpages, but what should
&gt; we do with translations? Should we put everything on the website?

A good question. I think a fine first try is to make a tor-manual.html.de
and tor-manual-dev.html.de in the website root (to go with the
.en ones), and then people who click on the 'Handbuch' links from
torproject.org/documentation.html.de will get the German version.

&gt; Comments and/or questions are always appreciated.

Is that a good enough answer to get started?
--Roger

</body></email><email><emailId>20100524084117</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2010-05-24 08:41:17-0400</timestampReceived><subject>Re: Translated manpages</subject><body>

On Mon, May 24, 2010 at 4:51 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Sun, May 23, 2010 at 09:19:40PM +0200, Runa A. Sandvik wrote:
&gt;&gt; I have been working on finding a way to translate the manpages via the
&gt;&gt; translation interface. There are only two small issues left: (1)
&gt;&gt; figure out whether or not tor-manual-dev.wml and tor-manual.wml should
&gt;&gt; be based on the same manpage, and (2) what we should do with the
&gt;&gt; translated manpages.
&gt;&gt;
&gt;&gt; Both tor-manual-dev.wml and tor-manual.wml generate the manpages that
&gt;&gt; are displayed on the website. These files use the same manpage to
&gt;&gt; generate the html files. That's probably not what we want. Which
&gt;&gt; manpage should tor-manual-dev.wml use, and which manpage should
&gt;&gt; tor-manual.wml use?
&gt;
&gt; Currently tor-manual-dev.wml should be the man page for Tor 0.2.2.x.
&gt; You can find it in the latest git head under doc/tor.1.txt, and you
&gt; can convert it to html using the combination of git and asciidoc commands
&gt; you find in tor-manual-dev.wml.
&gt;
&gt; Currently tor-manual.wml should be the man page for Tor 0.2.1.x. Since
&gt; Tor 0.2.1.x doesn't use asciidoc, you can convert doc/tor.1.in in the
&gt; maint-0.2.1 git branch using man2html (as you see in tor-manual.wml).

I noticed that they are not actually the same, even though it may look
that way. For the translations, I will create one tor-manual.po and
one tor-manual-dev.po (in addition to po files for the remaining three
manpages).

&gt;&gt; We have four manpages in total, but only one is displayed on the
&gt;&gt; website.
&gt;
&gt; Yep. Anybody using the other three progams (tor-resolve, tor-gencert,
&gt; and torify) is hopefully using a command line so they can just read the
&gt; man page themselves.
&gt;
&gt;&gt; We do not want to ship translated manpages, but what should
&gt;&gt; we do with translations? Should we put everything on the website?
&gt;
&gt; A good question. I think a fine first try is to make a tor-manual.html.de
&gt; and tor-manual-dev.html.de in the website root (to go with the
&gt; .en ones), and then people who click on the 'Handbuch' links from
&gt; torproject.org/documentation.html.de will get the German version.

I have that working already, and the only remaining questions is what
we should do with the rest of the translated manpages. I guess we
could find a way to include them on the website, in the same way we
include the manpage for Tor 0.2.2.x and 0.2.1.x.

-- 
Runa A. Sandvik
</body></email><email><emailId>20100524090057</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-24 09:00:57-0400</timestampReceived><subject>Re: Translated manpages</subject><body>

On Mon, May 24, 2010 at 10:41:17AM +0200, Runa A. Sandvik wrote:
&gt; &gt; Currently tor-manual-dev.wml should be the man page for Tor 0.2.2.x.
&gt; &gt; You can find it in the latest git head under doc/tor.1.txt, and you
&gt; &gt; can convert it to html using the combination of git and asciidoc commands
&gt; &gt; you find in tor-manual-dev.wml.
&gt; &gt;
&gt; &gt; Currently tor-manual.wml should be the man page for Tor 0.2.1.x. Since
&gt; &gt; Tor 0.2.1.x doesn't use asciidoc, you can convert doc/tor.1.in in the
&gt; &gt; maint-0.2.1 git branch using man2html (as you see in tor-manual.wml).
&gt; 
&gt; I noticed that they are not actually the same, even though it may look
&gt; that way. For the translations, I will create one tor-manual.po and
&gt; one tor-manual-dev.po (in addition to po files for the remaining three
&gt; manpages).

Our translators might like us more if we don't make them duplicate a
lot of work for these two po files, which will be mostly the same.

I wonder if that means we should just ask them to translate the
tor-manual-dev one. Or I wonder if there's a way to take the strings
and combine them into a single po file for translation. Or to have
pootle automatically recognize when two strings in two po files got
the same translations, and fill in the other one as a hint.

&gt; &gt; A good question. I think a fine first try is to make a tor-manual.html.de
&gt; &gt; and tor-manual-dev.html.de in the website root (to go with the
&gt; &gt; .en ones), and then people who click on the 'Handbuch' links from
&gt; &gt; torproject.org/documentation.html.de will get the German version.
&gt; 
&gt; I have that working already, and the only remaining questions is what
&gt; we should do with the rest of the translated manpages. I guess we
&gt; could find a way to include them on the website, in the same way we
&gt; include the manpage for Tor 0.2.2.x and 0.2.1.x.

Right. What exactly are "the rest of the translates manpages"? Are these
all translations of the main tor man page, or are the other man pages
translated too?

--Roger

</body></email><email><emailId>20100523043954</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-05-23 04:39:54-0400</timestampReceived><subject>Re: A attack aganist Tor?</subject><body>


Thus spake torsecurity (torbridges.security@gmail.com):

&gt; I use a tor bridge (freedomwithwall) connecting to Tor and it seems
&gt; doing well. But when I observe ( four) circuits  the Tor created, I
&gt; find the second and the last tor nodes do not exsit! Their nicknames
&gt; are not in the cached-descriptors or cached-descriptors.new files.
&gt; The Vidalia can not show their IPs also, just show the
&gt; freedomwithwall's IP.
&gt; 
&gt; I have never seen this happen before.
&gt; 
&gt; Is the bridge freedomwithwall a mallicious node and the middle and
&gt; exit nodes are fake?

Barring some serious vulnerability the likes of which we haven't yet
seen, Tor cannot extend to relays without knowing their public key,
even if you are using a malicious bridge. At best, a malicious bridge
can only prevent you from connecting to peers that it doesn't like.

Most likely this is a bug in Vidalia and/or a race between Tor
receiving descriptors and updating those cached files.

You should try connecting to the Tor Control Port (port 9051 on
127.0.0.1) and issuing something like:

AUTHENTICATE "password"
GETINFO desc/name/&lt;name of relay&gt;
GETINFO ns/name/&lt;name of relay&gt;

or

GETINFO desc/id/&lt;identity hash of relay&gt;
GETINFO ns/id/&lt;identity of relay&gt;

and see what comes back.

You can also issue:
GETINFO circuit-status

to see your current circuits as Tor understands them, independent of
Vidalia.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100518131612</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-18 13:16:12-0400</timestampReceived><subject>Re: Implementing proposal 147: Eliminate the need for v2</subject><body>

On Tue, May 18, 2010 at 11:18:19AM +0200, Karsten Loesing wrote:
&gt; Sebastian and I think that we really need this proposal to be
&gt; implemented in Tor soon, because we're running out of v2 authorities.
&gt; Only 2 of them are still running: tor26 and dizum. Time to get rid of v2.
&gt; 
&gt; - Set up 3 v3 directory authorities and 1 relay. Configure the relay
&gt; with only 1 of the directory authorities. Watch how the relay is not
&gt; contained in the first consensus, but in the second.

Make sure you use 0.2.2.12-alpha or later for these tests (and for
directory authorities in general). That's where I added:
    - Many relays have been falling out of the consensus lately because
      not enough authorities know about their descriptor for them to get
      a majority of votes. When we deprecated the v2 directory protocol,
      we got rid of the only way that v3 authorities can hear from each
      other about other descriptors. Now authorities examine every v3
      vote for new descriptors, and fetch them from that authority. Bugfix
      on 0.2.1.23.

In short, in the scenario you describe above, in earlier versions they
only discover new descriptors in the consensus itself, not the votes --
so since it isn't in the first, nobody else ever learns to fetch the
descriptor, so it's never in later consensuses either.

&gt; - Write code to process v3 opinions. This includes verifying signatures
&gt; and downloading missing descriptors from the authority that sent the
&gt; opinion.

git show 2e692bd8c98c841a
for how I did the earlier changes.

I wonder what would happen if we simply generate a vote at :45 and send
it, and then generate another vote at :50 and send that? It seems like at
the least we could reuse nearly all of the vote-generating and -parsing
code. I'll grant that we might want to declare the actual document to
be something other than a "vote", in case things can go bad when we've
received two votes from a single authority.

&gt; - Add an opinion-exchanging phase preceding the vote-exchanging phase.
&gt; With default values, the voting phase is from :50 to :55, so that the
&gt; opinion phase would be :45 to :50. Add config options to adjust the
&gt; length of this new phase.

You'll also like the feature I added in eaf5487d9570fb that makes
the authority fetch the missing descriptor from the source of the vote
it's reading (rather than from a random authority).

--Roger

</body></email><email><emailId>20100429134528</emailId><senderName>Bill Weiss</senderName><senderEmail>houdini+tor@clanspum.net</senderEmail><timestampReceived>2010-04-29 13:45:28-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

I've had good luck with the MaxMind databases, both paid and free.  If the
license allows it I'm in favor of using that.

As a bonus, if you use the free DB, people who have licenses for the paid
one can drop it in and gain the additional accuracy; the file formats are
the same.

-- 
Bill Weiss
 
&gt; I need some good links about ip spoffing .
 So, you need some good herking sites so you can become a crocker?
    -- Unknown

</body></email><email><emailId>20100429145646</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-04-29 14:56:46-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

On Thu, Apr 29, 2010 at 4:58 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
 [...]
&gt; In summary, I think we should ship Maxmind's free database with Tor, if
&gt; the license permits it. I'm hoping to get much better usage statistics
&gt; results for smaller countries like Tunisia from the free Maxmind. Also,
&gt; Maxmind has more users and is therefore less likely to provide a broken
&gt; update and not noticing for weeks.

http://geolite.maxmind.com/download/geoip/database/LICENSE.txt

This license doesn't look too bad to me.  Their software (which we
wouldn't use, so it doesn't matter) is LGPL; the database appears to
be under a old-BSD-like license, with the notorious advertising
clause.  The advertising clause is annoying, but not a show-stopper,
since we aren't GPL.  (We're already stuck with an advertising clause
anyway, from OpenSSL's SSLeay license.)

One of the lawyers should double-check me here, though.

-- 
Nick
</body></email><email><emailId>20100429150226</emailId><senderName>Wendy Seltzer</senderName><senderEmail>wendy@seltzer.com</senderEmail><timestampReceived>2010-04-29 15:02:26-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

Nick Mathewson wrote:
&gt; On Thu, Apr 29, 2010 at 4:58 AM, Karsten Loesing
&gt; &lt;karsten.loesing@gmx.net&gt; wrote:
&gt;  [...]
&gt;&gt; In summary, I think we should ship Maxmind's free database with Tor, if
&gt;&gt; the license permits it. I'm hoping to get much better usage statistics
&gt;&gt; results for smaller countries like Tunisia from the free Maxmind. Also,
&gt;&gt; Maxmind has more users and is therefore less likely to provide a broken
&gt;&gt; update and not noticing for weeks.
&gt; 
&gt; http://geolite.maxmind.com/download/geoip/database/LICENSE.txt
&gt; 
&gt; This license doesn't look too bad to me.  Their software (which we
&gt; wouldn't use, so it doesn't matter) is LGPL; the database appears to
&gt; be under a old-BSD-like license, with the notorious advertising
&gt; clause.  The advertising clause is annoying, but not a show-stopper,
&gt; since we aren't GPL.  (We're already stuck with an advertising clause
&gt; anyway, from OpenSSL's SSLeay license.)
&gt; 
&gt; One of the lawyers should double-check me here, though.

Check++

Facts and collections of facts aren't copyrightable in the US. Since Tor
distributes world-wide, it doesn't hurt to put in the attribution clause.

--Wendy

-- 
Wendy Seltzer -- wendy@seltzer.org
phone: +1.914.374.0613
Fellow, Silicon Flatirons Center at University of Colorado Law School
Fellow, Berkman Center for Internet &amp; Society at Harvard University
http://cyber.law.harvard.edu/seltzer.html
http://www.chillingeffects.org/
https://www.torproject.org/
</body></email><email><emailId>20100429160803</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-04-29 16:08:03-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

On Thursday April 29 2010 04:58:27 Karsten Loesing wrote:
&gt; - Interestingly, trusted resolves 7368 requests to Nigeria with the
&gt; Maxmind database, which were only 8 with ip-to-country. I wonder if this
&gt; can be correct. Is Tor this well-known in Nigeria?

That seems high to me.  What about other countries like Iran and China?  When 
China blocked the public list of relays in September 2009, we saw jumps of 
bridge users in Australia and Japan the same day we saw the jumps from China.  
This seems like imprecise assignment to me.

Iran's connections to the outside world go through Turkey, Kuwait, and 
Azerbaijan, etc.  See, 
https://svn.torproject.org/svn/projects/presentations/images/iran-internet-
connectivity-TAE-14.gif

I wonder if we're over-counting other countries, even with the new database.  

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20100503164013</emailId><senderName>Martin Mulazzani</senderName><senderEmail>e0225055@student.tuwien.ac.at</senderEmail><timestampReceived>2010-05-03 16:40:13-0400</timestampReceived><subject>Re: Re: GeoIP database comparison</subject><body>

TorStatus is already using the Maxmind GeoLite database.

For consistency, this could be an argument to use it in Tor as well. If 
another GeoIP is chosen, TorStatus might be changed for consistency.

Greetz, Martin

Karsten Loesing wrote:
&gt; On 4/29/10 6:08 PM, Andrew Lewman wrote:
&gt;&gt; On Thursday April 29 2010 04:58:27 Karsten Loesing wrote:
&gt;&gt;&gt; - Interestingly, trusted resolves 7368 requests to Nigeria with the
&gt;&gt;&gt; Maxmind database, which were only 8 with ip-to-country. I wonder if this
&gt;&gt;&gt; can be correct. Is Tor this well-known in Nigeria?
&gt;&gt; That seems high to me.  What about other countries like Iran and 
&gt;&gt; China?  When China blocked the public list of relays in September 
&gt;&gt; 2009, we saw jumps of bridge users in Australia and Japan the same 
&gt;&gt; day we saw the jumps from China.  This seems like imprecise 
&gt;&gt; assignment to me.
&gt;
&gt; China had 3520 requests (2.37% of all requests on that day) with the
&gt; Maxmind database and 2248 (2.28%) with ip-to-country, and Iran had 2168
&gt; (1.46%) with Maxmind and 1568 (1.59%) with ip-to-country. No changes to
&gt; worry about here.
&gt;
&gt;&gt; Iran's connections to the outside world go through Turkey, Kuwait, 
&gt;&gt; and Azerbaijan, etc.  See, 
&gt;&gt; https://svn.torproject.org/svn/projects/presentations/images/iran-internet-
&gt;&gt; connectivity-TAE-14.gif
&gt;&gt;
&gt;&gt; I wonder if we're over-counting other countries, even with the new database.
&gt;
&gt; I also had a closer look at the reported numbers for Nigeria. There were
&gt; 7368 requests from Nigeria (with the Maxmind database), but these
&gt; requests came from only 328 unique IP addresses. That's a ratio of 22.5
&gt; requests per IP address, with a ratio of 1.6 on average for other
&gt; countries. I think we're seeing something unusual going on here, but
&gt; false resolution of IP addresses is probably not the problem.
&gt;
&gt; While looking at the numbers, I found more African countries in addition
&gt; to Nigeria and Tunisia that suddenly have Tor users. Here are the
&gt; request numbers for some of these countries: Nigeria 7368 (from 328
&gt; IPs), Tunisia 320, Côte d'Ivoire 272, Morocco 272, Senegal 240, South
&gt; Africa 216, Algeria 184, Ghana 104. All of these countries were reported
&gt; to have 0 requests with the old database, except for Nigeria which had
&gt; 8. There are no similar increases for countries in other continents.
&gt;
&gt; Bill's point about being able to replace the free Maxmind with the
&gt; commercial Maxmind is also a good one. I'm considering to use the
&gt; commercial database on gabelmoo to get somewhat more precise (or more
&gt; up-to-date) results. Still, these results will be comparable to what
&gt; other relays with the free database report.
&gt;
&gt; Best,
&gt; --Karsten
&gt;



</body></email><email><emailId>20100506094944</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-06 09:49:44-0400</timestampReceived><subject>Re: Re: GeoIP database comparison</subject><body>

On Mon, May 03, 2010 at 06:40:13PM +0200, Martin Mulazzani wrote:
&gt; TorStatus is already using the Maxmind GeoLite database.

I've been wondering for a while why
http://trunk.torstatus.kgprog.com/index.php
has so many relays listed as Namibia. They're pretty clearly not in
Namibia.

--Roger

</body></email><email><emailId>20100506095157</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-05-06 09:51:57-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

On Thu, Apr 29, 2010 at 10:58:27AM +0200, Karsten Loesing wrote:
&gt; In summary, I think we should ship Maxmind's free database with Tor, if
&gt; the license permits it. I'm hoping to get much better usage statistics
&gt; results for smaller countries like Tunisia from the free Maxmind. Also,
&gt; Maxmind has more users and is therefore less likely to provide a broken
&gt; update and not noticing for weeks.

Sounds great. Please add it to maint-0.2.1, and we can merge it
forward to master and include it in 0.2.2.14-alpha.

Thanks!
--Roger

</body></email><email><emailId>20100507135712</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-05-07 13:57:12-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

On 5/6/10 11:49 AM, Roger Dingledine wrote:
&gt; On Mon, May 03, 2010 at 06:40:13PM +0200, Martin Mulazzani wrote:
&gt;&gt; TorStatus is already using the Maxmind GeoLite database.
&gt; 
&gt; I've been wondering for a while why
&gt; http://trunk.torstatus.kgprog.com/index.php
&gt; has so many relays listed as Namibia. They're pretty clearly not in
&gt; Namibia.

You're right, Torstatus is wrong.

I just resolved the IP addresses from the torstatus output at
http://trunk.torstatus.kgprog.com/query_export.php/Tor_query_EXPORT.csv
using Maxmind's free database from May 1. Below you'll find the lines
where Torstatus and Maxmind disagree.

Random thought: does Torstatus use "NA" as abbreviation for "not
available" when resolving IP addresses, but as "Namibia" when choosing a
flag to display?

Also, how recent is the GeoIP database that Torstatus, especially
trunk.torstatus.kgprog.com, uses?

At the end of this mail, you'll also find the Java code to generate this
output. Put the geoip file from current Tor master and the .csv as
stated above in the same directory, compile, run.

Best,
--Karsten


First column = Maxmind
Second column = Torstatus
Third column = nickname

US NA 0x41414141
DE NA 0x42FF
US NA 107167
RU NA a1s2ew4wfedjhc6je8
DE NA agitator
CA NA andromeda
CA NA anona
US NA avarner
PL NA Azhar
DE NA b215c035618f047d
SK NA backslash777
CA US BarkerJrNet
SK NA BecherovHomeunix
DE NA bingsFreeNet
DE NA bmwanon
CA NA buttercup
BY NA ByHomenet
NL NA canon
US NA canoworms
NL NA carpetbagger
DE NA Cerritus
CA NA chuckthecanuck
IE NA cupboard
US NA customer679498
US NA dametenshi
DE NA DerAufbruch2
GB NA deusexmachina
GB FR devasdfasdf
DE NA Diega
US NA DigitalFreedom
DE FR Dinosaur
FR NA djiins
UA NA DLag
SE NA DVBT
GB NA DynoTor
DE FR Edmontosaurus
DE NA Enigma
GB NA F00DD00D
DE NA ferrot04st
RU NA FFA
RU FR Fisto
DE NA flunkey
DE NA Freedom
SE FR frogbeard
DE NA gartentor
US NA greyunknown
RU NA GuyRitchie
UA NA happiness
CA NA harman2
RU NA HazarD
RU NA HellyMotion
DE IL herecomesthesun
RU NA hometoorspbru
US NA hurrdurr
DE NA HWR
RU NA IDDQD
TH NA igor1977
US NA ihas5cat
NL NA ItsHiddenYa
DE IR jefOlewkia
US NA jetddna
US NA jujubee
DE NA justanothernode
DE NA kaon
US NA knegg
GB NA kuzlatko
US NA lapiste
GB NA lego
CA US Link2VoIP
DE NA LittleMao
DE NA ljsilver
US NA lot49
GB NA MaoUK2
FR NA matterhorn
DE NA megaantisanitary1
TW AU MgeniUser
DE NA MicsInTrees
DE NA Mischmaschine
DE NA mullbinde3
DE NA nerdsurf
US NA networkb289be5
DE NA netzfrei2
GB IT nixgeek
US NA nockodotnet
GB NA node13
LK NA NSTHome
US NA oldthink
IL NA OnionFox
DE GB OrionTorNode
HK NA pangu
CA US Pasquino
SE NA PPrivComSweden
GB NA PPrivComUK4
CZ NA PwNibulikvps83
DE NA qeki0i7g3kd8tynseg0
RU LU QLEnDGKmay
DE NA raf
US NA RankaLee
UA NA ReactorRelay
US NA revo
TH NA rsquarersharp
US NA SamuraiPizzaCat
DE NA SedanUK
FR NA servicePublic
CA US Shaft
MN NA Shaman0
DE NA shawnthesheep
DE NA shiven
US NA singulicity
DE NA sork
ID NA speekfree
US NA srv1esctoulous
US NA srv3
US NA srv4
US NA srv5
US NA srv6
US NA stegosaurus
DE NA Suga23
US NA SuperDave
SE NA SwedishBikiniTeam
SE NA swetzsupertor
US NA taoppv
TR GB TinyTurtle
FR NA ToileLibre
DE IR Toni
DE NA TOR2fm1
GB DK toroftheworld
DE NA torschlusspanik2
RO NA trafficlight
GB NA triczlinode
TR GB umbrella
US NA underdonk01
US NA underdonk02
US NA Unnamed
AL NA Unnamed
AT SE Unnamed
DE NA Unnamed
US NA Unnamed
IR NA Unnamed
CA NA Unnamed
DE NA Unnamed
IR NA Unnamed
KR NA Unnamed
JP AU Unnamed
JP AU Unnamed
RU NA uran
GR NA Vagabond2
GB NA vee
CA NA Waldo
DE NA wg362
US NA wingedgods
NL NA worldstr989418
NL NA worldstre0f571
US NA ydobonobody
DE NA zermanes
DE NA Zwiebelschale3



import java.io.*;
import java.util.*;
public class ResolveRelayCountries {
  public static void main(String[] args) throws Exception {
    File geoipFile = new File("geoip");
    File torstatusOutput = new File("Tor_query_EXPORT.csv");
    BufferedReader br = new BufferedReader(new FileReader(geoipFile));
    String line = null;
    SortedMap&lt;Long, String&gt; geoipLines = new TreeMap&lt;Long, String&gt;();
    while ((line = br.readLine()) != null) {
      if (line.startsWith("#")) {
        continue;
      }
      geoipLines.put(Long.parseLong(line.split(",")[0]), line);
    }
    br.close();
    br = new BufferedReader(new FileReader(torstatusOutput));
    br.readLine();
    while ((line = br.readLine()) != null) {
      String nickname = line.split(",")[0];
      String reportedCountryCode = line.split(",")[1];
      String ip = line.split(",")[4];
      String[] octets = ip.split("\\.");
      long ipNum = Long.parseLong(octets[0]) * 256L * 256L * 256L
          + Long.parseLong(octets[1]) * 256L * 256L
          + Long.parseLong(octets[2]) * 256L
          + Long.parseLong(octets[3]);
      SortedMap&lt;Long, String&gt; subMap = geoipLines.headMap(ipNum + 1L);
      if (subMap.isEmpty()) {
        System.out.println("  ?? " + reportedCountryCode + " "
            + nickname);
      } else {
        long intervalStart = subMap.lastKey();
        String geoipLine = geoipLines.get(intervalStart);
        long intervalEnd = Long.parseLong(geoipLine.split(",")[1]);
        if (intervalStart &lt;= ipNum &amp;&amp; intervalEnd &gt;= ipNum) {
        String countryCode = geoipLine.split(",")[2];
          System.out.println((countryCode.equals(reportedCountryCode)
              ? "  " : "* ") + countryCode + " " + reportedCountryCode
              + " " + nickname);
        } else {
          System.out.println("  ?? " + reportedCountryCode + " "
              + nickname);
        }
      }
    }
  }
}
</body></email><email><emailId>20100507150931</emailId><senderName>"stars () hispeed ! ch"</senderName><senderEmail>stars@hispeed.ch</senderEmail><timestampReceived>2010-05-07 15:09:31-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


Le Fri, 07 May 2010 15:15:07 +0200,
Jacob Appelbaum &lt;jacob@appelbaum.net&gt; a écrit :

&gt; Hi,
&gt; 
&gt; I've pushed a new git branch 'compileTimeHardening' out to my git
&gt; repo. I've also attached a patch for those that are git adverse.
&gt; Either way, apply the patch to your current Tor master sources and
&gt; you should be in good shape.
&gt; 
&gt; You can use it like so:
&gt; ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings
&gt; --enable-gcc-hardening --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make
&gt; install
&gt; 
&gt; The end result on Debian Lenny is a slightly hardened build when
&gt; checked with checksec.sh[0].
&gt; 
&gt; This is weasel's build on my x86 machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt;    Partial RELRO   Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build with my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; Full RELRO      Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build without my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; No RELRO        No canary found   NX enabled    No PIE
&gt; 
&gt; This seems like a useful improvement for people building from source.
&gt; 
&gt; The gcc hardening flag works on Mac OS X. The linker hardening is
&gt; specific to the ELF binary format and does not work on Mac OS X. So on
&gt; Mac OS X, only use '--enable-gcc-hardening' and not
&gt; '--enable-linker-hardening' for your builds.
&gt; 
&gt; Checksec doesn't work on Mac OS X. It does appear to be possible to
&gt; check if a binary has a stack canary by doing the following (Using Mac
&gt; OS X 10.6.3 here):
&gt; 
&gt; 	nm /bin/ls | grep "chk_guard"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	U ___stack_chk_guard
&gt; 
&gt; Also, you can check by looking for the following with otool on Mac OS
&gt; X:
&gt; 
&gt; 	otool -tvV /bin/ls | grep "___stack_chk_fail"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	00004bf7        calll   0x00005468      ; symbol stub for:
&gt; ___stack_chk_fail
&gt; 
&gt; If you look at /Applications/Vidalia.app/Contents/MacOS/tor, you will
&gt; not see those protections at the moment. I think we can improve our
&gt; shipping Mac OS X binaries by enabling these protections. The PIE
&gt; protections won't really matter until Apple fixes their platform
&gt; (perhaps in 10.7?!); still it's nice to be ready and this patch
&gt; provides that too.
&gt; 
&gt; It appears that FORTIFY_SOURCE is on by default on Mac OS X. We don't
&gt; currently build Tor on Mac OS X with stack canaries though, so we're
&gt; improving Tor's security on Mac OS X. It may not be possible to do
&gt; this for all versions of Mac OS X - I suspect that Apple may disable
&gt; some or all protections to make a binary more compatible with
&gt; different Mac OS X versions.
&gt; 
&gt; It would be useful to get some extra testing on other platforms; is
&gt; anyone working with Windows building and interested in testing this? I
&gt; also left a comment in the patch for hardening flags that would be
&gt; useful with a non-gcc compiler on Windows.
&gt; 
&gt; There is some performance cost to running Tor with these security
&gt; enhancements. Debian already runs with most of the run time checks and
&gt; the relays on Debian appear to be just fine. The only real enhancement
&gt; for Linux systems is a startup time cost to gain protection from
&gt; GOT/PLT overwrites (if you're already using Weasel's packages).  If
&gt; you're merely building from source on any of the supported platforms,
&gt; it's a huge gain.
&gt; 
&gt; I think this option should be enabled by default at some point in the
&gt; future but probably not until we have a reasonably exhaustive list of
&gt; information for our major platforms. After we have a little testing
&gt; from Tor developers, I'll ask on or-talk for some testers.
&gt; 
&gt; It would be nice to have it merged into master as an optional option
&gt; soon though. Roger seemed to think this was a fine idea. I think it
&gt; may encourage people to try it out and to help us decide if it's worth
&gt; applying as a build default.
&gt; 
&gt; All the best,
&gt; Jacob
&gt; 
&gt; [0] http://www.trapkit.de/tools/checksec.html

Hello Jacob,

I run linux OS but it will great to have a few infos about what are
this features, So far with my knowledge, it mean nothing...

So any details welcome :P

Best regards

SWissTorExit

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100508075938</emailId><senderName>"stars () hispeed ! ch"</senderName><senderEmail>stars@hispeed.ch</senderEmail><timestampReceived>2010-05-08 07:59:38-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


Le Fri, 07 May 2010 15:15:07 +0200,
Jacob Appelbaum &lt;jacob@appelbaum.net&gt; a écrit :

&gt; Hi,
&gt; 
&gt; I've pushed a new git branch 'compileTimeHardening' out to my git
&gt; repo. I've also attached a patch for those that are git adverse.
&gt; Either way, apply the patch to your current Tor master sources and
&gt; you should be in good shape.
&gt; 
&gt; You can use it like so:
&gt; ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings
&gt; --enable-gcc-hardening --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make
&gt; install
&gt; 
&gt; The end result on Debian Lenny is a slightly hardened build when
&gt; checked with checksec.sh[0].
&gt; 
&gt; This is weasel's build on my x86 machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt;    Partial RELRO   Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build with my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; Full RELRO      Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build without my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; No RELRO        No canary found   NX enabled    No PIE
&gt; 
&gt; This seems like a useful improvement for people building from source.
&gt; 
&gt; The gcc hardening flag works on Mac OS X. The linker hardening is
&gt; specific to the ELF binary format and does not work on Mac OS X. So on
&gt; Mac OS X, only use '--enable-gcc-hardening' and not
&gt; '--enable-linker-hardening' for your builds.
&gt; 
&gt; Checksec doesn't work on Mac OS X. It does appear to be possible to
&gt; check if a binary has a stack canary by doing the following (Using Mac
&gt; OS X 10.6.3 here):
&gt; 
&gt; 	nm /bin/ls | grep "chk_guard"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	U ___stack_chk_guard
&gt; 
&gt; Also, you can check by looking for the following with otool on Mac OS
&gt; X:
&gt; 
&gt; 	otool -tvV /bin/ls | grep "___stack_chk_fail"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	00004bf7        calll   0x00005468      ; symbol stub for:
&gt; ___stack_chk_fail
&gt; 
&gt; If you look at /Applications/Vidalia.app/Contents/MacOS/tor, you will
&gt; not see those protections at the moment. I think we can improve our
&gt; shipping Mac OS X binaries by enabling these protections. The PIE
&gt; protections won't really matter until Apple fixes their platform
&gt; (perhaps in 10.7?!); still it's nice to be ready and this patch
&gt; provides that too.
&gt; 
&gt; It appears that FORTIFY_SOURCE is on by default on Mac OS X. We don't
&gt; currently build Tor on Mac OS X with stack canaries though, so we're
&gt; improving Tor's security on Mac OS X. It may not be possible to do
&gt; this for all versions of Mac OS X - I suspect that Apple may disable
&gt; some or all protections to make a binary more compatible with
&gt; different Mac OS X versions.
&gt; 
&gt; It would be useful to get some extra testing on other platforms; is
&gt; anyone working with Windows building and interested in testing this? I
&gt; also left a comment in the patch for hardening flags that would be
&gt; useful with a non-gcc compiler on Windows.
&gt; 
&gt; There is some performance cost to running Tor with these security
&gt; enhancements. Debian already runs with most of the run time checks and
&gt; the relays on Debian appear to be just fine. The only real enhancement
&gt; for Linux systems is a startup time cost to gain protection from
&gt; GOT/PLT overwrites (if you're already using Weasel's packages).  If
&gt; you're merely building from source on any of the supported platforms,
&gt; it's a huge gain.
&gt; 
&gt; I think this option should be enabled by default at some point in the
&gt; future but probably not until we have a reasonably exhaustive list of
&gt; information for our major platforms. After we have a little testing
&gt; from Tor developers, I'll ask on or-talk for some testers.
&gt; 
&gt; It would be nice to have it merged into master as an optional option
&gt; soon though. Roger seemed to think this was a fine idea. I think it
&gt; may encourage people to try it out and to help us decide if it's worth
&gt; applying as a build default.
&gt; 
&gt; All the best,
&gt; Jacob
&gt; 
&gt; [0] http://www.trapkit.de/tools/checksec.html

Hello to everyone,

I tested it on kubuntu Lucid 10.04 LTS x86 64, i has on my machine
without options, same output as Jacob and with options, all are enabled.

For info, tested on last master git branch and last libevent2 git
master branch.

Thanks for your help and this great patch Jacob.

Best regrads

SwissTorExit

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100403182714</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-04-03 18:27:14-0400</timestampReceived><subject>Re: New changelog system (developers please read) [was Re: A</subject><body>

On Mon, Mar 08, 2010 at 11:49:06PM -0500, Nick Mathewson wrote:
&gt; So it looks like we've settled on a new way to get good ChangeLogs
&gt; written without running into merge conflicts every time we turn
&gt; around, and without requiring that everybody's commit messages be
&gt; user-facing.
&gt; 
&gt; When you do a commit that needs a ChangeLog entry, add a new file to
&gt; the "changes" toplevel subdirectory.
[snip]
&gt; When Roger goes to make a release, he will concatenate all the entries
&gt; in changes to make a draft changelog, and clear the directory.  He'll
&gt; then edit the draft changelog into a nice readable format.

We just ran into an edge case for this new design: how do we handle
changelog entries in maint-0.2.1?

According to
https://bugs.torproject.org/flyspray/index.php?do=details&amp;id=1324&amp;area=comments#4159
Nick recommends using the changes/ approach in maint-0.2.1 too, "Or else
when we merge it into master, there will be conflict fun."

But that isn't going to do what we want.

Scenario 1: I add a changes/foo file to maint-0.2.1. I add the entry
into the maint-0.2.1 ChangeLog file, and delete changes/foo. We merge
it into master. I'm going to have to manually copy entries from the
0.2.1.26 release into the appropriate 0.2.2.x-alpha release.

Scenario 2: I add a change/foo file to maint-0.2.1, then we merge it to
master. Then I delete it from maint-0.2.1 while building the 0.2.1.26
changelog, and delete it from master while building the 0.2.2.x-alpha
changelog. Then we'll have a conflict.

Scenario 3: We opt to never delete changes/foo in the maint-0.2.1 tree,
so it will survive into master, so we can fold it into the 0.2.2.x-alpha
changelog and then delete it there. But then the changes/ files just
pile up in maint-0.2.1. That's no good.

I think the best answer we can hope for is scenario 1.

But it gets worse. We need to be sure to fold every changes/foo file into
maint-0.2.1's changelog before we merge to master, or it could turn into
scenario 2. So:

Scenario 4: Always make your maint-0.2.1 commits in pairs, one to make
changes/foo and another to delete it and fold it immediately into the
ChangeLog file. It will need to be manually added to the 0.2.2.x-alpha
ChangeLog file later in any case.

Scenario 5: Just go ahead and put your changes into the ChangeLog file
directly; this changes/foo business is only for master.

Is there any benefit to Scenario 4 over Scenario 5?

--Roger

</body></email><email><emailId>20100508082444</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2010-05-08 08:24:44-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>

Content-Transfer-Encoding: quoted-printable

Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote
Fri, 07 May 2010 15:15:07 +0200:

| ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings --enable-gcc-hardening
| --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make install

I can report that this works well on NetBSD (5.0.2) @ i386 as well.
I'm using gcc 4.1.3, the one shipped with NetBSD.


| The end result on Debian Lenny is a slightly hardened build when checked
| with checksec.sh[0].
| 
| This is weasel's build on my x86 machine:
| RELRO           STACK CANARY      NX            PIE
|    Partial RELRO   Canary found      NX enabled    PIE enabled
| 
| This is a build with my new options on the same machine:
| RELRO           STACK CANARY      NX            PIE
| Full RELRO      Canary found      NX enabled    PIE enabled
| 
| This is a build without my new options on the same machine:
| RELRO           STACK CANARY      NX            PIE
| No RELRO        No canary found   NX enabled    No PIE

My observations are as follow.

- I see the GNU_RELRO header but not the BIND_NOW header.  This would
  have been displayed by checksec.sh as "Partial RELRO".
- Canary is found.
- I don't see GNU_STACK so NX is not there.
- PIE is enabled


| This seems like a useful improvement for people building from source.

Indeed.  Thanks!

I'll look into why BIND_NOW and GNU_STACK aren't present.  Do you have
any ideas?

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100508113834</emailId><senderName>"Anthony G. Basile"</senderName><senderEmail>basile@opensource.dyc.edu</senderEmail><timestampReceived>2010-05-08 11:38:34-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Jacob,

FYI, I have been compiling tor with these hardening features using the
gcc compiler that Magnus and I hacked up and are now trying to get
migrating into Gentoo.  The goodies are in Gentoo overlays.  The ebuilds
are at

http://git.overlays.gentoo.org/gitweb/?p=proj/hardened-development.git;a=summary

The patchset against gcc is at

http://git.overlays.gentoo.org/gitweb/?p=proj/hardened-gccpatchset.git;a=summary

The only difference is that I used stack-protector, whereas you're using
stack-protector-all, which is possibly better.

Anyhow, running and dissecting the resulting binaries/libraries, I have
*never* encountered any issues with gcc-4.*  The only issue was with
gcc-3.4.6 which is already reported at
https://trac.torproject.org/projects/tor/ticket/1060.  We've pretty much
abandoned hardened gcc-3.4.6 anyhow at hardened Gentoo.

So, I vote for putting the patch master, for whatever that's worth.


Anthony G. Basile, Ph.D.
Chair IT, D'Youville College
Buffalo NY 14201
(716) 829-8197




On 05/07/2010 09:15 AM, Jacob Appelbaum wrote:
&gt; Hi,
&gt; 
&gt; I've pushed a new git branch 'compileTimeHardening' out to my git repo.
&gt; I've also attached a patch for those that are git adverse. Either way,
&gt; apply the patch to your current Tor master sources and you should be in
&gt; good shape.
&gt; 
&gt; You can use it like so:
&gt; ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings --enable-gcc-hardening
&gt; --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make install
&gt; 
&gt; The end result on Debian Lenny is a slightly hardened build when checked
&gt; with checksec.sh[0].
&gt; 
&gt; This is weasel's build on my x86 machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt;    Partial RELRO   Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build with my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; Full RELRO      Canary found      NX enabled    PIE enabled
&gt; 
&gt; This is a build without my new options on the same machine:
&gt; RELRO           STACK CANARY      NX            PIE
&gt; No RELRO        No canary found   NX enabled    No PIE
&gt; 
&gt; This seems like a useful improvement for people building from source.
&gt; 
&gt; The gcc hardening flag works on Mac OS X. The linker hardening is
&gt; specific to the ELF binary format and does not work on Mac OS X. So on
&gt; Mac OS X, only use '--enable-gcc-hardening' and not
&gt; '--enable-linker-hardening' for your builds.
&gt; 
&gt; Checksec doesn't work on Mac OS X. It does appear to be possible to
&gt; check if a binary has a stack canary by doing the following (Using Mac
&gt; OS X 10.6.3 here):
&gt; 
&gt; 	nm /bin/ls | grep "chk_guard"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	U ___stack_chk_guard
&gt; 
&gt; Also, you can check by looking for the following with otool on Mac OS X:
&gt; 
&gt; 	otool -tvV /bin/ls | grep "___stack_chk_fail"
&gt; 
&gt; You should see something like this:
&gt; 
&gt; 	00004bf7        calll   0x00005468      ; symbol stub for:
&gt; ___stack_chk_fail
&gt; 
&gt; If you look at /Applications/Vidalia.app/Contents/MacOS/tor, you will
&gt; not see those protections at the moment. I think we can improve our
&gt; shipping Mac OS X binaries by enabling these protections. The PIE
&gt; protections won't really matter until Apple fixes their platform
&gt; (perhaps in 10.7?!); still it's nice to be ready and this patch provides
&gt; that too.
&gt; 
&gt; It appears that FORTIFY_SOURCE is on by default on Mac OS X. We don't
&gt; currently build Tor on Mac OS X with stack canaries though, so we're
&gt; improving Tor's security on Mac OS X. It may not be possible to do this
&gt; for all versions of Mac OS X - I suspect that Apple may disable some or
&gt; all protections to make a binary more compatible with different Mac OS X
&gt; versions.
&gt; 
&gt; It would be useful to get some extra testing on other platforms; is
&gt; anyone working with Windows building and interested in testing this? I
&gt; also left a comment in the patch for hardening flags that would be
&gt; useful with a non-gcc compiler on Windows.
&gt; 
&gt; There is some performance cost to running Tor with these security
&gt; enhancements. Debian already runs with most of the run time checks and
&gt; the relays on Debian appear to be just fine. The only real enhancement
&gt; for Linux systems is a startup time cost to gain protection from GOT/PLT
&gt; overwrites (if you're already using Weasel's packages).  If you're
&gt; merely building from source on any of the supported platforms, it's a
&gt; huge gain.
&gt; 
&gt; I think this option should be enabled by default at some point in the
&gt; future but probably not until we have a reasonably exhaustive list of
&gt; information for our major platforms. After we have a little testing from
&gt; Tor developers, I'll ask on or-talk for some testers.
&gt; 
&gt; It would be nice to have it merged into master as an optional option
&gt; soon though. Roger seemed to think this was a fine idea. I think it may
&gt; encourage people to try it out and to help us decide if it's worth
&gt; applying as a build default.
&gt; 
&gt; All the best,
&gt; Jacob
&gt; 
&gt; [0] http://www.trapkit.de/tools/checksec.html

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkvlTToACgkQl5yvQNBFVTUXcACeJuuQUyP+zDoKop2cG4XD6/On
eSQAnRuFOXGRHxA4YL3eXD83yKk4/LRH
=fv2J
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100508120258</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-05-08 12:02:58-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


On May 8, 2010, at 1:38 PM, Anthony G. Basile wrote:
&gt; So, I vote for putting the patch master, for whatever that's worth.

This has already happened, see
https://gitweb.torproject.org//tor.git?a=commit;h=8ba00e4305fe87c540c452271bc6f5c461738777
for reference.

Sebastian
</body></email><email><emailId>20100508135958</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-05-08 13:59:58-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


On Fri, May 07, 2010 at 03:15:07PM +0200, jacob@appelbaum.net wrote 6.0K bytes in 166 lines about:
: You can use it like so:
: ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings --enable-gcc-hardening
: --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make install

Here are the results from OSX 10.5 build machine:

CFLAGS="-O -g -mmacosx-version-min=10.4 -isysroot
/Developer/SDKs/MacOSX10.4u.sdk -arch i386"
LDFLAGS="-Wl,-syslibroot,/Developer/SDKs/MacOSX10.4u.sdk"
CONFDIR=/Library/Tor ./configure --prefix=/Library/Tor
--bindir=/Library/Tor --sysconfdir=/Library
--disable-dependency-tracking gcc="4.0" --enable-gcc-warnings
--enable-gcc-hardening --enable-linker-hardening

configure: error: C compiler cannot create executables

attached is the config.log

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject

["config.log.gz" (application/octet-stream)]

</body></email><email><emailId>20100508140316</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-08 14:03:16-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


Sebastian Hahn wrote:
&gt; 
&gt; On May 8, 2010, at 1:38 PM, Anthony G. Basile wrote:
&gt;&gt; So, I vote for putting the patch master, for whatever that's worth.
&gt; 
&gt; This has already happened, see
&gt; https://gitweb.torproject.org//tor.git?a=commit;h=8ba00e4305fe87c540c452271bc6f5c461738777
&gt; 
&gt; for reference.

It sounds like we're getting a nice table of places that it works as a
default. I think that once we have a reasonably large table with good
results, we should turn it on by default (as is already the case in Debian).

All the best,
Jacob


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100508140700</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-08 14:07:00-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


Anthony G. Basile wrote:
&gt; Hi Jacob,
&gt; 
&gt; FYI, I have been compiling tor with these hardening features using the
&gt; gcc compiler that Magnus and I hacked up and are now trying to get
&gt; migrating into Gentoo.  The goodies are in Gentoo overlays.  The ebuilds
&gt; are at
&gt;  

Fantastic!

Can you build with your normal options, run checksec.sh, and collect the
output? Furthermore, if you can rebuild with these options, run
checksec.sh, and send it along with the first set of data?

We'd love to hear about how it runs over days or weeks too, if you can
send that along as well.

Thanks in advance,
Jacob


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100508140955</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-05-08 14:09:55-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>


andrew@torproject.org wrote:
&gt; On Fri, May 07, 2010 at 03:15:07PM +0200, jacob@appelbaum.net wrote 6.0K bytes in 166 lines about:
&gt; : You can use it like so:
&gt; : ./autogen.sh &amp;&amp; ./configure --enable-gcc-warnings --enable-gcc-hardening
&gt; : --enable-linker-hardening &amp;&amp; make &amp;&amp; sudo make install
&gt; 
&gt; Here are the results from OSX 10.5 build machine:
&gt; 
&gt; CFLAGS="-O -g -mmacosx-version-min=10.4 -isysroot
&gt; /Developer/SDKs/MacOSX10.4u.sdk -arch i386"
&gt; LDFLAGS="-Wl,-syslibroot,/Developer/SDKs/MacOSX10.4u.sdk"
&gt; CONFDIR=/Library/Tor ./configure --prefix=/Library/Tor
&gt; --bindir=/Library/Tor --sysconfdir=/Library
&gt; --disable-dependency-tracking gcc="4.0" --enable-gcc-warnings
&gt; --enable-gcc-hardening --enable-linker-hardening
&gt; 
&gt; configure: error: C compiler cannot create executables
&gt; 
&gt; attached is the config.log
&gt; 

Hi Andrew,

Thanks for your testing.

Can you try that again but this time without '--enable-linker-hardening'
in your ./configure configuring? We can't support linker hardening for
ELF and Mac OS X uses the Mach-O binary format.

Try to do the following configure command?

CFLAGS="-O -g -mmacosx-version-min=10.4 -isysroot
/Developer/SDKs/MacOSX10.4u.sdk -arch i386"
LDFLAGS="-Wl,-syslibroot,/Developer/SDKs/MacOSX10.4u.sdk"
CONFDIR=/Library/Tor ./configure --prefix=/Library/Tor
--bindir=/Library/Tor --sysconfdir=/Library
--disable-dependency-tracking gcc="4.0" --enable-gcc-warnings
--enable-gcc-hardening

All the best,
Jacob


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100510131001</emailId><senderName>"Anthony G. Basile"</senderName><senderEmail>basile@opensource.dyc.edu</senderEmail><timestampReceived>2010-05-10 13:10:01-0400</timestampReceived><subject>Re: Tor hardening at compile time</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/08/2010 10:07 AM, Jacob Appelbaum wrote:
&gt; Anthony G. Basile wrote:
&gt;&gt; Hi Jacob,
&gt;&gt;
&gt;&gt; FYI, I have been compiling tor with these hardening features using the
&gt;&gt; gcc compiler that Magnus and I hacked up and are now trying to get
&gt;&gt; migrating into Gentoo.  The goodies are in Gentoo overlays.  The ebuilds
&gt;&gt; are at
&gt;&gt;  
&gt; 
&gt; Fantastic!
&gt; 
&gt; Can you build with your normal options, run checksec.sh, and collect the
&gt; output? Furthermore, if you can rebuild with these options, run
&gt; checksec.sh, and send it along with the first set of data?
&gt; 
&gt; We'd love to hear about how it runs over days or weeks too, if you can
&gt; send that along as well.
&gt; 
&gt; Thanks in advance,
&gt; Jacob
&gt; 


Hi Jacob,

Here's what you wanted.  All were done against master at
git://git.torproject.org/git/tor.git as of this morning.


1. Test with hardened gcc and no hardening flags added via ./configure

i686-pc-linux-gnu-4.4.3 - from hardened gentoo overlay [1]
./configure WITHOUT --enable-gcc-hardening --enable-linker-hardening

~/GIT/tor-hardened-gcc/src $ checksec.sh --file or/tor
RELRO           STACK CANARY      NX            PIE               FILE
Full RELRO      Canary found      NX enabled    PIE enabled       or/tor



2. Test with vanilla gcc and no hardening flags added via ./configure

i686-pc-linux-gnu-4.4.3-vanilla - from [1]
./configure WITHOUT --enable-gcc-hardening --enable-linker-hardening

~/GIT/tor-soft-gcc/src $ checksec.sh --file or/tor
RELRO           STACK CANARY      NX            PIE              FILE
Partial RELRO   No canary found   NX enabled    No PIE           or/tor



3. Test with vanilla gcc and hardening flags added via ./configure

i686-pc-linux-gnu-4.4.3-vanilla
./configure --enable-gcc-hardening --enable-linker-hardening

~/GIT/tor-soft-gcc-hardening/src $ checksec.sh --file or/tor
RELRO           STACK CANARY      NX            PIE              FILE
Full RELRO      Canary found      NX enabled    PIE enabled      or/tor



4. As for testing hardening with tor, *all* tor-ramdisk images [2] were
compiled/linked with the above hardening from day one.  However since
these are statically linked against uclibc, it may not be the test
you're looking for.

Currently node "rafiki" at IP 67.151.215.240 is running tor built by #3
above. I'll give you the results in a few days.

The host is a fully hardened desktop gentoo system --- see [3] for
checksec.sh on running binaries. Its also a xen virtual machine.  If you
want, I can move rafiki to a more traditional system, stock debian or
centos.  It might be a more realistic test of what you'll get in the wild.



[1] git://git.overlays.gentoo.org/proj/hardened-dev.git
[2] http://opensource.dyc.edu/tor-ramdisk
[3] http://opensource.dyc.edu/sites/default/files/tinhat-checksec.txt

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkvoBakACgkQl5yvQNBFVTVwNACeIcm632u4mGhSqhRuyljyXvvS
DX4AoJ83Vl13vfBeBG7JOXVgY4JVJ3PD
=cekq
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100406091208</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-04-06 09:12:08-0400</timestampReceived><subject>Re: Bridge stability</subject><body>


Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; Okay, here are the new results, this time with taking IP address changes
&gt; into account. The graph shows the fraction of random bridge subsets
&gt; (containing 3 bridges, 1 of them running on port 443) that had at least
&gt; 1 bridge running continuously throughout 6/24/48/96 hours. For example,
&gt; a value of 0.9 on the y axis means that 90% of all samples taken at the
&gt; date and time on the x axis were useful for another 6/24/48/96 hours.
&gt; 
&gt; http://freehaven.net/~karsten/volatile/bridge-stability-ipchange-2010-04-01.png
&gt; 
&gt; For comparison between the analysis with and without IP address changes,
&gt; here are the two 96 hours lines for both analyses. The red line in the
&gt; following graph is equivalent to the purple line in the previous graph.
&gt; 
&gt; http://freehaven.net/~karsten/volatile/bridge-stability-96h-2010-04-01.png
&gt; 
&gt; So, yes, when we take IP address changes into account, bridge stability
&gt; is worse than we thought from the first analysis. But still, it's not as
&gt; bad as one might have imagined. Note that the reasons for the drops on
&gt; December 11, 23, and 31 are probably problems with the bridge authority,
&gt; not with all bridges (I could make the analysis more precise by looking
&gt; at self-reported bridge uptimes, if required). That means that the 4
&gt; days before those drops are probably too low in the graphs. In this
&gt; case, the 96 hours line is between 60% and 90%. Or to rephrase that, in
&gt; 3 out of 4 cases, people had a working bridge 4 days after requesting
&gt; bridge addresses, and the 4th person would have to request another set
&gt; of bridges.
&gt; 
&gt; I'd like to hear what others say about these results. Am I missing
&gt; something? Is "3 out of 4" a horrible result?

I don't know. I feel like there is a significant difference between:
http://freehaven.net/~karsten/volatile/bridge-stability-4-bridges.png
and
http://freehaven.net/~karsten/volatile/bridge-stability-96h-2010-04-01.png

I am especially suspicious as to why sets of 4 bridges weren't as
dramatically affected by the bridge db failure?

The big question on my mind is does it really cost us that much in
terms of adversary effort to enumerate X% of the bridges if we hand
out one extra?

Can we run some simulations or math as to how many samples of 3, 4, or
5 bridges it would take for an adversary to get 50%, 60%, 70%, 80%,
90% blockage coverage of all of them?

If the answer is that it doesn't significantly reduce the number of
hits against https://bridges.tp.o that the adversary has to do to get
75% coverage, I think we should really consider handing out more to
get that reliability boost.


Also, reliability isn't the only issue here. We also should simulate
blocking probability too, in conjunction with reliability.

For example, what is the likelihood that all of your 3, 4 or 5 bridges
from tp.o will be blocked or down if the adversary has 75% of the
bridges blocked (or whatever the blockage rate was during the recent
bridge blocking event in march). How much does this change if we hand
out 4 or 5 bridges instead?

There may be some sweet spot in that it takes the adversary less hits
to block 75% of the network if we hand out 4 or 5 bridges, but it is
also more likely for a user to still have at least one of their
bridges not blocked and still running at this blockage rate.

The best way to answer this is probably to get an estimate on the
number of 3-bridge samples China needed to block the percentage of the
network they blocked in March, and expect that they will devote this
same effort in the future. Using this number of samples, does the
likelihood of a user being blocked go up or down if China blocks an
additional percentage of the network because we handed out an extra
bridge, but they have an extra bridge IP or two to work with.




-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100406154740</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-04-06 15:47:40-0400</timestampReceived><subject>Re: New changelog system (developers please read) [was Re: A couple</subject><body>

On Sat, Apr 3, 2010 at 2:27 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Mon, Mar 08, 2010 at 11:49:06PM -0500, Nick Mathewson wrote:
&gt;&gt; So it looks like we've settled on a new way to get good ChangeLogs
&gt;&gt; written without running into merge conflicts every time we turn
&gt;&gt; around, and without requiring that everybody's commit messages be
&gt;&gt; user-facing.
&gt;&gt;
&gt;&gt; When you do a commit that needs a ChangeLog entry, add a new file to
&gt;&gt; the "changes" toplevel subdirectory.
&gt; [snip]
&gt;&gt; When Roger goes to make a release, he will concatenate all the entries
&gt;&gt; in changes to make a draft changelog, and clear the directory.  He'll
&gt;&gt; then edit the draft changelog into a nice readable format.
&gt;
&gt; We just ran into an edge case for this new design: how do we handle
&gt; changelog entries in maint-0.2.1?
&gt;
&gt; According to
&gt; https://bugs.torproject.org/flyspray/index.php?do=details&amp;id=1324&amp;area=comments#4159
&gt; Nick recommends using the changes/ approach in maint-0.2.1 too, "Or else
&gt; when we merge it into master, there will be conflict fun."
&gt;
&gt; But that isn't going to do what we want.
&gt;
&gt; Scenario 1: I add a changes/foo file to maint-0.2.1. I add the entry
&gt; into the maint-0.2.1 ChangeLog file, and delete changes/foo. We merge
&gt; it into master. I'm going to have to manually copy entries from the
&gt; 0.2.1.26 release into the appropriate 0.2.2.x-alpha release.
&gt;
&gt; Scenario 2: I add a change/foo file to maint-0.2.1, then we merge it to
&gt; master. Then I delete it from maint-0.2.1 while building the 0.2.1.26
&gt; changelog, and delete it from master while building the 0.2.2.x-alpha
&gt; changelog. Then we'll have a conflict.

Actually, no.  Git doesn't mind if you delete the same thing (or
generally, if you make the same change) in two branches.  The merge
algorithm isn't completely broken. :)

&gt; Scenario 3: We opt to never delete changes/foo in the maint-0.2.1 tree,
&gt; so it will survive into master, so we can fold it into the 0.2.2.x-alpha
&gt; changelog and then delete it there. But then the changes/ files just
&gt; pile up in maint-0.2.1. That's no good.

Revised protocol (discussed on IRC):

Remember that we're planning to stop doing releases from maint-0.2.1
directly.  Instead, we're hoping to have a release-0.2.1 branch that
pulls from older versions of maint-0.2.1, plus from occasional hotfix
branches.  The idea was to ensure that bugfixes get tested for a good
while in master before they make it into a stable release.

Once this is done, the answer becomes clear (ish): edit changes
entries for clarity in maint-0.2.1.  Only
delete-and-merge-into-a-changelog when actually doing a release from
master or release-0.2.1.

Better?

-- 
Nick

</body></email><email><emailId>20100416191715</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-04-16 19:17:15-0400</timestampReceived><subject>Re: Proposal: GETINFO controller option for connection information</subject><body>


Damian Johnson wrote:
&gt; Yesterday Jake met with me to discuss this proposal, making the very
&gt; good points that both:
&gt;   1. It's completely ineffectual for the auditing purposes I've
&gt; mentioned since either (a) these results can be fetched from netstat
&gt; already or (b) the information would only be provided via tor and
&gt; can't be validated.
&gt;   2. The things I'm really interested in can be fetched with much less
&gt; (and safer) information.

I still think that anything that can be used to track circuits (and the
clients associated with them) is not a good idea - in Tor or using arm.
We shouldn't encourage people to log, look or otherwise track Tor.

&gt; 
&gt; In particular we discussed making the proposal circuit based rather
&gt; than connection based, being something like the following:
&gt; 
&gt;   "circ/&lt;Circuit identity&gt;" -- Provides entry for the associated circuit,
&gt;     formatted as:
&gt;       CIRC_ID IN_TYPE OUT_TYPE READ WRITE UPTIME
&gt; 
&gt;     none of the parameters contain whitespace, and additional results must be
&gt;     ignored to allow for future expansion. Parameters are defined as follows:
&gt;       CIRC_ID - Unique identifier for the circuit this belongs to.
&gt;       IN_TYPE/OUT_TYPE - Single character flags indicating the purpose of the
&gt;         inbound or outbound connection. If no connection is established then
&gt;         this provides an empty string. Otherwise, it consists of one from each
&gt;         of the following categories (this may become longer in future
&gt;         expansion):
&gt;           Usage Type:
&gt;             C: client traffic, R: relaying traffic,
&gt;             X: control, H: hidden service, D: directory
&gt;           Destination:
&gt;             I: inter-tor connection, O: outside the tor network, L: localhost
&gt;         For instance, "RO" would indicate that this was an established
&gt;         1st-hop (or bridged) relay connection.
&gt;       READ/WRITE - Total bytes read/written over the life of this connection.
&gt;       UPTIME - Time the connection's been established in seconds.
&gt; 
&gt;   "circ/all" -- Newline separated listing of all current circuits.

Both of these seem useful for an administrator that wants to see what's
happening in a very general way. I think that it shouldn't be a
(tracking/logging/etc) risk but I'd like Nick or Roger to comment here.

&gt; 
&gt; This would be almost just as useful for the purposes I'm interested in
&gt; while also stripping the most sensitive data entirely (ip addresses,
&gt; ports, and connection based bandwidth breakdowns). In particularly
&gt; this information could still address the following:
&gt; 
&gt; - Basic Relay Usage Questions
&gt; How is the bandwidth I'm contributing broken down? Is it being evenly
&gt; distributed or is someone hogging most of it? Do these circuits belong
&gt; to the hidden service I'm running or something else? Now that I'm
&gt; using exit policy X am I desirable as an exit, or are most people just
&gt; using me as a relay?
&gt; 

Agreed.

&gt; - Debugging
&gt; Say a relay has a restrictive firewall policy for outbound
&gt; connections, with the ORPort whitelisted but doesn't realize that tor
&gt; needs random high ports. Tor would report success ("your orport is
&gt; reachable - excellent") yet the relay would be nonfunctional. This
&gt; proposed information would reveal numerous RELAY -&gt; YOU -&gt;
&gt; UNESTABLISHED circuits, giving a good indicator of what's wrong.
&gt; 

I'm not sure that I follow this? You're saying that Tor can make
circuits to other Tor nodes but not arbitrary things on the internet?

&gt; - Visualization
&gt; This would still yield the benefits mentioned in the last proposal of
&gt; helping to demystify behavior the operator isn't expecting (see the
&gt; client example from before).


I agree.

&gt; 
&gt; ----------------------------------------
&gt; 
&gt; Second, Jake made a great point that at present if a malicious party
&gt; gets ahold of the control port then the relay's quite effectively
&gt; screwed. The current capabilities of the control port are overkill for
&gt; many controllers (like arm) which are just interested in retrieving
&gt; information from tor (GETINFO options, event listening, etc). To make
&gt; the control port safer we could include a torrc option that makes the
&gt; control port read-only...
&gt; 
&gt;   SafeControlPort 0|1
&gt;     Restricts access of the control port to only include read-only operations.
&gt;     (Default: 0)
&gt; 
&gt; Making this the default would be a no-go due to vidalia (though still
&gt; a nice option to have...). If this is implemented its setting should
&gt; be part of the PROTOCOLINFO response.

Ah - I'm sorry, I should have been clearer! I meant to suggest another
control port _entirely_:

SafeControlPort Port
SafeControlListenAddress IP[:PORT]
SafeHashedControlPassword

This would mean that you could expose a second control port that is
designed to give generalized, rounded, perhaps even delayed statistical
information to a visualization engine. The first I had in mind was arm
but there could be useful stuff for mrtg or another graphing program. I
don't need or want my graphing programs to have the ability to control
Tor - I just want to get some data out to help me manage my relay.

With that said - I don't think it's a good idea to focus on such a
feature at this time. Work on getting the statistics to your controller
first. When you have a good case for the features being available in a
different, more safe way, you can make it happen.

&gt; 
&gt; ----------------------------------------
&gt; 
&gt; Finally, the other proposed GETINFO options still seem useful (with
&gt; the possible exception of "info/uptime-reset"), and could be improved
&gt; with the addition of:
&gt; 
&gt;   "info/user" -- User under which the tor process is running, providing an
&gt;     empty string if none exists.
&gt; 

You may also want something like the following:

"info/uid"
"info/euid"
"info/gid"
"info/egid"

&gt;   "info/pid" -- Process id belonging to the tor process, -1 if none exists for
&gt;     the platform.
&gt; 
&gt; * this one is both useful and surprisingly difficult for me to
&gt; retrieve at present (arm attempts to get it from pidof, ps, and
&gt; netstat yet still fails on some systems...)

The good news is that it's pretty easy to do in C:

    pid_t pid;
    pid = getpid(); // see also getppid();
    printf("PID is: %d\n", pid);


&gt; 
&gt; In addition Jake mentioned the possibility of making info/* options
&gt; for all limits and capabilities (though I'd hold off until we have use
&gt; cases needing them...) and the following entries for getting activity
&gt; snapshots:
&gt; 
&gt;   "info/relay/[read, write]/avg/[1, 5, 15]" -- Provides the average traffic
&gt;     (bytes read or written per second) over the last 1, 5, or 15 minutes.
&gt; 
&gt;   "info/relay/circ/avg/[1, 5, 15]" -- Provides the average number of circuits
&gt;     established in the last 1, 5, or 15 minutes.
&gt; 

This allows you to make a nice 'uptime' visualization within an instant
of connecting to the control port.

It was good to talk with you yesterday, I think you're on the right path.

All the best,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100417211050</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-04-17 21:10:50-0400</timestampReceived><subject>Re: /src/common/compat.c:363: undefined reference to `__vcsprint</subject><body>

Confirmed by phobos when he tried to build 0.2.2.11-alpha.

Nickm, it looks like this is a bug in your 6fa8dacb97587707156507 commit
on April 2?

(It is now holding up the 0.2.2.11-alpha packages.)

--Roger

On Fri, Apr 16, 2010 at 05:42:01PM +0100, CAv wrote:
&gt; Hi Or-Dev,
&gt;
&gt; I am trying to compile tor-0.2.2.11-alpha on windows and get the  
&gt; following error:
&gt; ../common/libor.a(compat.o): In function `tor_vasprintf':
&gt; tor-0.2.2.11-alpha/src/common/compat.c:363: undefined reference to  
&gt; `__vcsprint
&gt;
&gt; I think this is a new portable method that is defined in compat.c
&gt;
&gt; Can anyone help resolve this ?
&gt;
&gt; With kind regards,
&gt; Cav

</body></email><email><emailId>20100424181742</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-04-24 18:17:42-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

Hi,

On Fri, Apr 23, 2010 at 7:48 AM, Christian Fromme &lt;kaner@strace.org&gt; wrote:
&gt; Hi,
&gt;
&gt; On Fri, Apr 23, 2010 at 12:14 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt;
&gt;&gt;&gt; we might want to see if using the new-ish standalone
&gt;&gt;&gt; Linux jemalloc helps people.   (We keep hitting fragmentation issues
&gt;&gt;&gt; with glibc malloc.)  To try it out, build the code from
&gt;&gt;&gt; http://www.canonware.com/jemalloc/ , stick the resulting .so file in
&gt;&gt;&gt; your LD_PRELOAD before you start Tor, and see if the memory usage is
&gt;&gt;&gt; much better.
&gt;&gt;
&gt;&gt; Somebody should try this and see how it goes. You might suggest it to
&gt;&gt; the folks on tor-relays -- I bet not many of them read this list.
&gt;
&gt; I ran into that OOM killer memory problem on my Linux based exit node,
&gt; too (Nick and Roger might remember the machine hanging and basically
&gt; needing a reset a few weeks back). Currently I am restarting Tor daily
&gt; via cron. So I am happy to try this jemalloc thing and report back.

Here is my follow-up mail:

I tried jemalloc. It seems to help against the excessive memory usage,
but takes CPU usage up to 99%. (Maybe the memory isn't high because
Tor isnt doing anything useful?)

Best,
/C

</body></email><email><emailId>20100427112645</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2010-04-27 11:26:45-0400</timestampReceived><subject>Re: The long anticipated move from Flyspray...</subject><body>


So, a couple of updates.

* Erinn Clark &lt;erinn@torproject.org&gt; [2010:04:22 23:06 -0700]: 
&gt; The version control support is pending. I'm going to add the git
&gt; support, but currently there doesn't appear to be a way to use remote
&gt; subversion repositories, so I've just added a link to
&gt; https://gitweb.torproject.org and https://svn.torproject.org/svn for
&gt; now.

I can't declare a firm date for when this integration will happen, but
what we're waiting on is the multi-repo support that's in the pending
Trac release (0.12):
http://trac.edgewall.org/wiki/MultipleRepositorySupport

Once that's up and running I'll add the git repos and begin working on
figuring out a way to get remote svn repos running too.

Many people have requested the ability to be subscribed to all bugs,
automatically, including all updates they receive. There is a tor-bugs@
mailing list in the works for exactly this purpose and once that's
sorted out, people should be able to subscribe to it and imbibe deeply
from the firehose, so to speak.

I think most of the initial bugs are fixed at this point. There are
still many wiki pages which need to be tamed, but if you come across
any particularly egregious ones, please let me know and I'll fix them.

And as a final plea, one cool feature that I would like to see used
frequently is tags: https://trac.torproject.org/projects/tor/tags

Tags aren't really new technology, but being able to sort by topic
rather than component is compelling, especially in the case where you
might have random volunteers (or even established ones) who check to see
if there's anything fun (and specific) to hack on. So maybe they could
sort by "easy", "openssl", "help", "c++", "needs-testers" or whatever. 

Thanks,
Erinn

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100430204416</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-04-30 20:44:16-0400</timestampReceived><subject>Re: GeoIP database comparison</subject><body>

On 4/29/10 6:08 PM, Andrew Lewman wrote:
&gt; On Thursday April 29 2010 04:58:27 Karsten Loesing wrote:
&gt;&gt; - Interestingly, trusted resolves 7368 requests to Nigeria with the
&gt;&gt; Maxmind database, which were only 8 with ip-to-country. I wonder if this
&gt;&gt; can be correct. Is Tor this well-known in Nigeria?
&gt; 
&gt; That seems high to me.  What about other countries like Iran and China?  When 
&gt; China blocked the public list of relays in September 2009, we saw jumps of 
&gt; bridge users in Australia and Japan the same day we saw the jumps from China.  
&gt; This seems like imprecise assignment to me.

China had 3520 requests (2.37% of all requests on that day) with the
Maxmind database and 2248 (2.28%) with ip-to-country, and Iran had 2168
(1.46%) with Maxmind and 1568 (1.59%) with ip-to-country. No changes to
worry about here.

&gt; Iran's connections to the outside world go through Turkey, Kuwait, and 
&gt; Azerbaijan, etc.  See, 
&gt; https://svn.torproject.org/svn/projects/presentations/images/iran-internet-
&gt; connectivity-TAE-14.gif
&gt; 
&gt; I wonder if we're over-counting other countries, even with the new database.

I also had a closer look at the reported numbers for Nigeria. There were
7368 requests from Nigeria (with the Maxmind database), but these
requests came from only 328 unique IP addresses. That's a ratio of 22.5
requests per IP address, with a ratio of 1.6 on average for other
countries. I think we're seeing something unusual going on here, but
false resolution of IP addresses is probably not the problem.

While looking at the numbers, I found more African countries in addition
to Nigeria and Tunisia that suddenly have Tor users. Here are the
request numbers for some of these countries: Nigeria 7368 (from 328
IPs), Tunisia 320, Côte d'Ivoire 272, Morocco 272, Senegal 240, South
Africa 216, Algeria 184, Ghana 104. All of these countries were reported
to have 0 requests with the old database, except for Nigeria which had
8. There are no similar increases for countries in other continents.

Bill's point about being able to replace the free Maxmind with the
commercial Maxmind is also a good one. I'm considering to use the
commercial database on gabelmoo to get somewhat more precise (or more
up-to-date) results. Still, these results will be comparable to what
other relays with the free database report.

Best,
--Karsten
</body></email><email><emailId>20100304045900</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-03-04 04:59:00-0400</timestampReceived><subject>Proposal 170: Configuration options regarding circuit building [was</subject><body>

Added as proposal 170.

On Wed, Mar 3, 2010 at 10:24 PM, Sebastian Hahn &lt;mail@sebastianhahn.net&gt; wrote:
&gt; Filename: xxx-user-path-config.txt
&gt; Title: Configuration options regarding circuit building
&gt; Author: Sebastian Hahn
&gt; Created: 01-March-2010
&gt; Status: Draft
&gt;
</body></email><email><emailId>20100305220255</emailId><senderName>Nick Mathewson</senderName><senderEmail>nick.a.mathewson@gmail.com</senderEmail><timestampReceived>2010-03-05 22:02:55-0400</timestampReceived><subject>Re: A couple of Git ideas: new branches, easier changelogs</subject><body>

On Fri, Mar 5, 2010 at 3:19 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Fri, Mar 05, 2010 at 12:02:08AM -0500, Nick Mathewson wrote:
&gt;&gt; So here's what I propose.  We create a new "release-0.2.1" branch
&gt;&gt; based on maint-0.2.1, and do all our releases off that branch.  We do
&gt;&gt; _all_ bugfixes of 0.2.1 bugs in the maint-0.2.1 branch, which we merge
&gt;&gt; into master regularly.  We don't merge maint-0.2.1 directly into
&gt;&gt; release-0.2.1, however: instead, we tag it whenever we do a release of
&gt;&gt; 0.2.2 from the master branch.  Only once the 0.2.2 version has tested
&gt;&gt; for a while do we merge maint-0.2.1 into release-0.2.1.  This way,
&gt;&gt; bugfixes get tested for a while in the alpha before they get merged
&gt;&gt; into stable, and we don't need to worry about losing track of them.
&gt;
&gt; Works for me. There will be some rough edges as we try it out. For
&gt; example, will I find it simplest to have three repositories now rather
&gt; than two, each with .git/HEAD pointing to the appropriate branch? Doesn't
&gt; sound so bad.

It's up to you how you want to do it on your own working machines.  I
generally use a separate local working repositories only to the extent
I find it necessary to avoid re-running autoconf all the time.

 [...]

I'm skipping over stuff about "backporting less".  I agree that it's
mostly orthogonal...

...except for the point that it isn't always easy to see when you
start working on a bugfix how important it's really going to wind up
being.

One way to implement it might be, at some point late in the release
cycle, to stop merging maint-0.2.1 into release-0.2.1 entirely, and
_only_ cherry-pick.  That way we still have a queue of "what are the
bugfixes on 0.2.1"; but we _would_ have a tricky time keeping track of
what was or wasn't backported.

Or if we want to be more merge-friendly, when 0.2.1.x becomes old
news, we could say "Starting now, every fix on 0.2.1.x gets its own
branch.  Merge all such branches into maint-0.2.1 and master.  Merge
them into release-0.2.1 only when it seems most sensible."

I think these approaches are worth thinking about if the maint/release
thing starts becoming nonfunctional, but perhaps a bit too complicated
to do before then.

 [...]
&gt; Here's a scenario I expect to happen: we have 15 items in maint-0.2.1,
&gt; 5 of which are in release-0.2.1. Then we realize one of the remaining 10
&gt; is more urgent than we thought, and it's time for a stable release that
&gt; includes that patch even though it hasn't been in a development release
&gt; "long enough". So we cherry-pick it from maint-0.2.1 to release-0.2.1,
&gt; examine it very carefully, and release?

I believe that's so.  It beats our current approach, which has been
"release an 0.2.1.x version from maint-0.2.1 immediately and hope that
nothing vital got broken."

&gt; But even in that scenario, I agree it's better to not have all 15 items,
&gt; 9 of which are not tested well, in the branch that we try to release.
&gt;
&gt;&gt;    B) Instead of creating a changelog entry, commits that want to add
&gt;&gt; something to the changelog should add a file to a "changes" directory,
&gt;&gt; whose elements get concatenated into a changelog before a release.
&gt;&gt; [weasel suggested this one.]
&gt;&gt;    C) Commit messages should try to be written so they themselves can
&gt;&gt; be turned into changelog entries.  To generate a changelog, just run
&gt;&gt; git log previous-release..master and massage the output.
&gt;&gt;    D) Like C, except recognizing that some commits don't warrant
&gt;&gt; independent changelog entries... so we add a way to annotate commits
&gt;&gt; (e.g., with a footer line) to say "This doesn't go in the changelog!"
&gt;&gt; or "This goes in the changelog in the new features section!"  Only
&gt;&gt; unannotated commits would need to get manually triaged.  We'd want a
&gt;&gt; little script to massage the git log into a draft changelog.
&gt;&gt;
&gt;&gt; B and D seem like our best options to me.  B has the advantage that
&gt;&gt; it's easier to add or massage changelog entries between adding them
&gt;&gt; and the release; D has the advantage that we can't _forget_ to add a
&gt;&gt; changelog entry for anything.
&gt;
&gt; I like B's advantage: I can incrementally prepare the changelog for
&gt; an upcoming release whenever I want to, not just at release time. And
&gt; then mere humans (aka those not using git) can see that in-progress
&gt; changelog too.
&gt;
&gt; It's also my experience that people write better changelog entries when
&gt; they know they're writing a changelog entry. Writing a git commit message
&gt; is not writing a changelog entry. We could train ourselves to think of
&gt; them as the same thing, but training our developers to become different
&gt; is always harder than it sounds.

Well, we'll have to train people to generate new files in 'changes'
and give them names that are nice and distinct.  (In my experience,
the same people who don't write commit messages with communicative
intent are the same ones who won't write changelog messages unless you
threaten them and call them unkind names.)  But at least with B, it's
a little easier to write the changelog messages for them without
having to amend all their commits before merging them.

yrs,
-- 
Nick

</body></email><email><emailId>20100306042436</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-03-06 04:24:36-0400</timestampReceived><subject>Re: [or-cvs] r21825: {projects} Add FascistFirewall preference	(projects/android/trunk/Orbot/src/org</subject><body>


Roger Dingledine wrote:
&gt; On Sat, Mar 06, 2010 at 02:06:00AM +0000, Jacob Appelbaum wrote:
&gt; &gt; Modified:
&gt; &gt; projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java
&gt; &gt; Log:
&gt; &gt; Add FascistFirewall preference
&gt; &gt; 
&gt; &gt; Modified: projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java
&gt; &gt; ===================================================================
&gt; &gt; --- projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java	2010-03-06 \
&gt; &gt;                 01:27:51 UTC (rev 21824)
&gt; &gt; +++ projects/android/trunk/Orbot/src/org/torproject/android/Orbot.java	2010-03-06 \
&gt; &gt; 02:06:00 UTC (rev 21825) @@ -460,6 +460,8 @@
&gt; [snip]
&gt; &gt; +                String fascistFirewallPorts =
&gt; &gt; +                    prefs.getString(PREF_FASCIST_FIREWALL_PORTS, "80,443");
&gt; 
&gt; From the Tor man page:
&gt; 
&gt; FirewallPorts PORTS
&gt; A list of ports that your firewall allows  you  to  connect  to.
&gt; Only  used  when  FascistFirewall  is set. This option is depre-
&gt; cated; use ReachableAddresses instead. (Default: 80, 443)
&gt; 
&gt; So, don't do that. :)
&gt; 
&gt; You should also be aware that setting FascistFirewall 1 does not set
&gt; ReachableAddresses to "80, 443". It sets ReachableORAddresses to 443,
&gt; and ReachableDirAddresses to 80. So maybe you want to skip FascistFirewall
&gt; entirely and just set ReachableAddresses or not.
&gt; 

Good point! I'll re-code it and commit the diff in a bit.

Best,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100306231243</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-03-06 23:12:43-0400</timestampReceived><subject>Re: Control Spec Addition First Draft</subject><body>

Thanks Sebastian! You're right - I can't think of any valid use cases
for needing the ip address/port of client and exit connections so
dropping that from the proposal.

That said, I think it's a mistake to drop those connections entirely
since some of their attributes *are* of legitimate usefulness:

- Existance
At the very least it'd be nice if Tor indicated their existence (ie,
I'd say "yea, an exit connection exists on this circuit but we won't
tell you where it goes."). This would be useful, for instance, if the
relay operator has misconfigured their firewall to block some of the
outbound ports permitted by their exit policy (arm would show this as
RELAY -&gt; YOU -&gt; UNESTABLISHED, and provide a warning to indicate the
issue).

- Bandwidth
For auditing the most interesting attribute of connections, imho, is
the bandwidth. If, says 10 KB/s is coming in and 1 MB/s is going out
on a circuit that's a good indicator that something is *very* wrong
(I'd start suspecting a security issue, personally). If we rounded all
bandwidth measurements (say, to the nearest KB) would this be
sufficient to prevent entry/exits from correlating this data to attack
anonymity?

- Uptime
If connections are being cycled abnormally quickly (say, all
connection longevity is under thirty seconds) this could indicate the
ISP (or other middlemen like the great firewall) are sending reset
packets to kill the relay's attempts to make exit connections.

I'd be willing to backpedal from requesting this information if others
think it's dangerous. However, unlike addresses / ports I think this
is useful information so I'd rather not see it stripped without
reason. Cheers! -Damian

PS. Is the BUFF field useful to anyone? I don't care about it, but
thought it might be useful for indicating some issues.

-------------------------------------------------------------------------------

  "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the
    associated connection, formatted as:
      CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME BUFF

    none of the parameters contain whitespace, and additional results must be
    ignored to allow for future expansion. Parameters are defined as follows:
      CONN_ID - Unique identifier associated with this connection.
      CIRC_ID - Unique identifier for the circuit this belongs to (0 if this
        doesn't belong to any circuit). At most their may be two connections
        (one inbound, one outbound) with any given CIRC_ID except in the case
        of exit connections.
      OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
      IP/PORT - IP address and port used by the associated connection, 0 if
        connection is used for relaying client or exit traffic.
      L_PORT - Local port used by the connection, 0 if connection is used for
        relaying client or exit traffic.
      TYPE_FLAGS - Single character flags indicating directionality and type
        of the connection (consists of one from each category, may become
        longer for future expansion).
          Connection Directionality:
            I: inbound, i: listening (unestablished inbound),
            O: outbound, o: unestablished outbound
          Usage Type:
            C: client traffic, R: relaying traffic,
            X: control, H: hidden service, D: directory
          Destination:
            T: inter-tor connection, t: outside the tor network
        For instance, "IRt" would indicate that this was an established
        1st-hop (or bridged) relay connection.
      READ/WRITE - Total bytes read/written over the life of this connection.
      UPTIME - Time the connection's been established in seconds.
      BUFF - Bytes of data buffered for this relay connection.

  "conn/all" -- Newline separated listing of all current connections.

  "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
    RelayBandwidthRate if set, otherwise BandwidthRate).

  "info/relay/burst-limit" -- Effective relayed burst limit.

  "info/relay/read-total" -- Total bytes relayed (download).

  "info/relay/write-total" -- Total bytes relayed (upload).

  "info/relay/buffer-cap" -- Maximum buffer size for relay connections.

  "info/uptime-process" -- Total uptime of the tor process (in seconds).

  "info/uptime-reset" -- Time since last reset (startup or sighup signal, in
    seconds).

  "info/descriptor-used" -- Count of file descriptors used.

  "info/descriptor-limit" -- File descriptor limit (getrlimit results).

  "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.

On Wed, Mar 3, 2010 at 6:52 PM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt; 
&gt; Hey,
&gt; 
&gt; my comments inline below.
&gt; 
&gt; On Jan 24, 2010, at 1:58 AM, Damian Johnson wrote:
&gt; &gt; 
&gt; &gt; Hi all. This proposal doesn't seem to be going anywhere so thought I should give \
&gt; &gt; it one last nudge before moving on to more worthwhile work. The issue's sticking \
&gt; &gt; point seems to be a difference of opinion about what constitutes relay evilness. \
&gt; &gt; Nick, Jake, and Sebastian all believe in a hard line stance against any retrieval \
&gt; &gt; of connection information (netstat, lsof, etc). I disagree, and think this is \
&gt; &gt; harmless unless stored or communicated. Unless this can be resolved I think it's \
&gt; &gt; obvious the proposal isn't going anywhere. 
&gt; &gt; Please note that I'm discussing relay to relay connections at the moment. If we \
&gt; &gt; can't even agree on that then client and exit connections are a moot point (and \
&gt; &gt; besides, I agree they should definitely be hidden from relay operators - \
&gt; &gt; personally I think it's the responsibility of client applications like vidalia \
&gt; &gt; and arm to scrub this data, but that's a different discussion...).
&gt; 
&gt; This seems to change the original intent of the proposal, which was (afaiui) to get \
&gt; a listing of all connections from Tor. I wouldn't mind doing that at all. It does, \
&gt; however, depend on the implementation of proposal 163 (detecting clients), because \
&gt; otherwise Tor itself cannot reliably differentiate in all cases. 
&gt; &gt; Just to be clear I agree this proposal should be killed if it poses a threat to \
&gt; &gt; Tor users. However, I don't believe it does and still have yet to hear an example \
&gt; &gt; of any sort of threat it aggravates. Without that I'm a bit puzzled at the source \
&gt; &gt; of objections. If the chief issue is legal or not wanting to risk the appearance \
&gt; &gt; of supporting snooping that's fine (strikes me as political posing if there's no \
&gt; &gt; actual benefits to users, but cest la vi).
&gt; 
&gt; If you change it to be explicit about the fact that you do not want to show \
&gt; exit/guard connections, I think this would be ok. It needs to be actually spelt \
&gt; out, though. 
&gt; &gt; My bias is toward safety for relay operators and I'm glad to see others biased \
&gt; &gt; toward user privacy pushing back. Hopefully we'll be able to find something \
&gt; &gt; acceptable to all parties concerned but if not it won't be the end of the world. \
&gt; &gt; Cheers! -Damian
&gt; 
&gt; Just to see if others are interested in moving this along, or if everyone wants to \
&gt; kill it. 
&gt; Sebastian


</body></email><email><emailId>201003071130530</emailId><senderName>Christian Grothoff</senderName><senderEmail>christian@grothoff.org</senderEmail><timestampReceived>2010-03-07 11:30:53-0400</timestampReceived><subject>Help needed: Autonomous NAT traversal test [Was: enabling bridges on NATed clients]</subject><body>

Dear all,

In order to more thoroughly answer sird's question (for GNUnet, possibly for 
Tor and generally for anyone interested in P2P), a group of people (including 
Andreas Mueller, Samy Kamkar, Nate Evans and myself) would like your help.  

We've written a piece of software that will test your NAT implementation to 
determine how well various NAT hole punching techniques work.  The tester (at 
least the version with the tests we're interested in right now) currently only 
runs on W32 and requires that you first install http://www.winpcap.org/.  
Then, please download, unzip and run the NAT tester from 
http://nattest.net.in.tum.de/.

At the end, the tester will launch a browser to report the results back to the 
nat tester website for evaluation.  The collected data is made public, and our 
evaluation report will also be public; finally, whatever method we end up 
implementing for GNUnet based on this will be reasonably modular so that Tor 
can choose to build on our code (if the evaluation makes it look promising 
enough). 

Thanks for your help in advance!

Best regards,

Christian

On Monday 22 February 2010 12:56:39 am sird@rckc.at wrote:
&gt; What do you guys think about using http://samy.pl/pwnat/ idea to allow
&gt; people that want to run a bridge behind a NAT? Maybe enhance the
&gt; discovery protocol to this kind of stuff.
&gt; 
&gt; I say this because I think that people in china need bridges, and this
&gt; kind of solutions may dramatically help in that, specially because now
&gt; they can't just send reset packets in the discovery part of the
&gt; protocol.
&gt; 
&gt; Anyway, it's just an idea, what do you think? is it usable?
&gt; 
&gt; Greetings!!
&gt; 
</body></email><email><emailId>20100416164201</emailId><senderName>CAv</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-04-16 16:42:01-0400</timestampReceived><subject>/src/common/compat.c:363: undefined reference to `__vcsprint</subject><body>

Hi Or-Dev,

I am trying to compile tor-0.2.2.11-alpha on windows and get the 
following error:
../common/libor.a(compat.o): In function `tor_vasprintf':
tor-0.2.2.11-alpha/src/common/compat.c:363: undefined reference to 
`__vcsprint

I think this is a new portable method that is defined in compat.c

Can anyone help resolve this ?

With kind regards,
Cav



Damian Johnson wrote:
&gt; Time to take the defibrillator paddles to this proposal once again. As 
&gt; per Nick's request this is a bit more focused on the motivation for 
&gt; getting connection related information. The proposed use cases are 
&gt; just some naive examples I've come up with. If anyone with a stronger 
&gt; security background (which wouldn't take much...) has the time I'd 
&gt; love comments like "WTF?!? This idiot's looking for the completely 
&gt; wrong things! This is obviously worthless if he doesn't look for X."
&gt;
&gt; Also, could we move forward on the other (less controversial) items? 
&gt; For instance, bandwidth totals tend to be a very highly requested 
&gt; piece of information and pipe's already provided a nice patch to get 
&gt; it (http://www.mail-archive.com/or-talk@freehaven.net/msg13085.html). 
&gt; For reference, here's the not-so-controversial GETINFO options I proposed:
&gt;
&gt;   "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt;     RelayBandwidthRate if set, otherwise BandwidthRate).
&gt;
&gt;   "info/relay/burst-limit" -- Effective relayed burst limit.
&gt;
&gt;   "info/relay/read-total" -- Total bytes relayed (download).
&gt;
&gt;   "info/relay/write-total" -- Total bytes relayed (upload).
&gt;
&gt;   "info/uptime-process" -- Total uptime of the tor process (in seconds).
&gt;
&gt;   "info/uptime-reset" -- Time since last reset (startup or sighup 
&gt; signal, in
&gt;     seconds).
&gt;
&gt;   "info/descriptor-used" -- Count of file descriptors used.
&gt;
&gt;   "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt;
&gt;   "ns/authority" -- Router status info (v2 directory style) for all
&gt;     recognized directory authorities, joined by newlines.
&gt;
&gt; I'm not planning on converting the following to the customary 
&gt; 80-character width until it's at least past being a first draft for a 
&gt; couple reasons:
&gt;   1. I find editing fixed-width documents to be a time consuming pain 
&gt; in the ass.
&gt;   2. I've yet to hear why we do this. Is it just to cater to mail 
&gt; clients too dumb to know how to line wrap?
&gt;
&gt; that said, keeping my fingers crossed that this starts going 
&gt; somewhere! -Damian
&gt;
&gt; PS. For previous discussions of this proposal see:
&gt; http://marc.info/?t=126101683100002&amp;r=1&amp;w=1 
&gt; &lt;http://marc.info/?t=126101683100002&amp;r=1&amp;w=1&gt;
&gt;
&gt; ----------------------------------------
&gt;
&gt; Filename: xxx-connection-getinfo-option.txt
&gt; Title: GETINFO controller option for connection information
&gt; Author: Damian Johnson
&gt; Created: 14-Apr-2010
&gt; Status: Draft
&gt;
&gt; Overview:
&gt;
&gt;     This details an additional GETINFO option for tor controllers that 
&gt; would provide information concerning a relay's current connections.
&gt;
&gt; Motivation:
&gt;
&gt;     All Internet facing applications (tor included) are possible 
&gt; vectors for attack on the operator's system. With hundreds of 
&gt; connections to relatively unknown destinations tor is already the bane 
&gt; of any network based IDS, and unless tor can be proved infallible and 
&gt; bug free (which would be quite a feat!) it cannot be blindly trusted.
&gt;    
&gt;     While it is impossible to guard against every potential future 
&gt; vulnerability, controllers can attempt to mitigate this threat by both 
&gt; auditing tor's behavior and providing indicator of its activity to 
&gt; savvy users. Connection related information is a useful tool for both 
&gt; of these purposes.
&gt;    
&gt;     In terms of auditing, the following are some conditions 
&gt; controllers can check for with connection information:
&gt;       - Persistent unestablished circuits. For instance a circuit has 
&gt; an outbound connection without a corresponding inbound counterpart. If 
&gt; such a connection was active (had substantial traffic) this would be 
&gt; troubling enough to alert the user.
&gt;       - Relatively asymmetric traffic on circuits. Ie, if the 
&gt; controller sees 10 kb/s inbound on a circuit and 5 mb/s outbound this 
&gt; could be a good indicator that someone's using tor to issue a dos, 
&gt; fetch data from the local system, etc.
&gt;       - Any connections to the local network when 
&gt; ExitPolicyRejectPrivate is set, indicating that tor's being used to 
&gt; proxy connections to the local lan.
&gt;       - Peculiar patterns of connections, for instance numerous 
&gt; outbound connections to a single IP, or if 99% of all bandwidth 
&gt; belonging to a single circuit.
&gt;       - Scrubbed connection data limits our ability to check for 
&gt; obedience to the exit policy, but for strictly non-exit relays we can 
&gt; still alert the user if any non-relay outbound connections occur.
&gt;    
&gt;     Of course if we're working from the assumption that tor has been 
&gt; compromised, then the information provided from the control port 
&gt; cannot be blindly trusted. Hence connection data should be 
&gt; validateable against the system's connection querying utilities 
&gt; (netstat, ss, lsof, etc - which are more likely to be under a host 
&gt; based IDS, if present). This requires that the system's been 
&gt; completely compromised (elevated permissions) before controllers can 
&gt; be tricked, rather than just tor.
&gt;    
&gt;     While automated detection is handy for detecting known behavior 
&gt; that might indicate issues, visualization gives us the possibility of 
&gt; finding much more thanks to our tinfoil hat wearing user base. A clear 
&gt; display of tor's current behavior gives assurance that tor's 
&gt; functioning as it should, plus a level of transparency desirable from 
&gt; anyone with even the slightest bit of paranoia. Tor is a guest process 
&gt; in the system of relay operators and we should not hide what it does 
&gt; without legitimate reason.
&gt;    
&gt;     Another (albeit unintended) benefit of visualizing tor's behavior 
&gt; is that it becomes a helpful tool in puzzling out how tor works. For 
&gt; instance, tor spawns numerous client connections at startup (even if 
&gt; unused as a client). As a newcomer to tor these asymmetric (outbound 
&gt; only) connections mystified me for quite a while until until Roger 
&gt; explained their use to me. The proposed TYPE_FLAGS would let 
&gt; controllers clearly label them as being client related, making their 
&gt; purpose a bit clearer.
&gt;    
&gt;     At the moment connection data can only be retrieved via commands 
&gt; like netstat, ss, and lsof. However, fetching it via the control port 
&gt; provides several advantages:
&gt;      
&gt;       - scrubbing for private data
&gt;           Raw connection data has no notion of what's sensitive and 
&gt; what is not. The relay's flags and cached consensus can be used to 
&gt; take educated guesses concerning which connections could possibly 
&gt; belong to client or exit traffic, but this is both difficult and 
&gt; inaccurate.
&gt;      
&gt;       - additional information
&gt;           All connection querying commands strictly provide the ip 
&gt; address and port of connections, and nothing else. However, for 
&gt; auditing and visualization the far more interesting attributes are the 
&gt; connection's bandwidth usage, uptime, and the circuit to which it belongs.
&gt;      
&gt;       - improved performance
&gt;           Querying connection data is an expensive activity, 
&gt; especially for busy relays or low end processors (such as mobile 
&gt; devices). Tor already internally knows its circuits and connections, 
&gt; allowing for vastly quicker lookups.
&gt;      
&gt;       - cross platform capability
&gt;           The connection querying utilities mentioned above not only 
&gt; aren't available under Windows, but differ widely among different *nix 
&gt; platforms. FreeBSD in particular takes a very unique approach, 
&gt; dropping important options from netstat and assigning ss to a 
&gt; spreadsheet application instead. A controller interface, however, 
&gt; would provide a uniform means of retrieving this information.
&gt;
&gt; Security Implications:
&gt;
&gt;     The original version of this proposal left the responsibility of 
&gt; scrubbing connection data with client applications (vidalia, arm, 
&gt; etc). However, this was deemed unacceptable by Sebastian and Nick in 
&gt; previous discussions. The proposal now includes dropping the ip 
&gt; address/port of client and exit connections from the controller's 
&gt; response. That said, I think it's a mistake to drop those connections 
&gt; entirely since some of their attributes *are* of legitimate usefulness:
&gt;    
&gt;     - Existence
&gt;       At the very least it'd be nice if Tor indicated their existence 
&gt; (ie, I'd say "yea, an exit connection exists on this circuit but we 
&gt; won't tell you where it goes."). This would be useful, for instance, 
&gt; if the relay operator has misconfigured their firewall to block some 
&gt; of the outbound ports permitted by their exit policy (arm would show 
&gt; this as RELAY -&gt; YOU -&gt; UNESTABLISHED, and provide a warning to 
&gt; indicate the issue).
&gt;    
&gt;     - Bandwidth
&gt;       For auditing the most interesting attribute of connections, 
&gt; imho, is the bandwidth. If, says 10 KB/s is coming in and 1 MB/s is 
&gt; going out on a circuit that's a good indicator that something is 
&gt; *very* wrong (I'd start suspecting a security issue, personally). If 
&gt; we rounded all bandwidth measurements (say, to the nearest KB) would 
&gt; this be sufficient to prevent entry/exits from correlating this data 
&gt; to attack anonymity?
&gt;    
&gt;     - Uptime
&gt;       If connections are being cycled abnormally quickly (say, all 
&gt; connection longevity is under thirty seconds) this could indicate the 
&gt; ISP (or other middlemen like the great firewall) are sending reset 
&gt; packets to kill the relay's attempts to make exit connections.
&gt;
&gt; Specification:
&gt;
&gt;    The following addition would be made to the control-spec's GETINFO 
&gt; section:
&gt;
&gt;   "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry 
&gt; for the
&gt;     associated connection, formatted as:
&gt;       CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME
&gt;
&gt;     none of the parameters contain whitespace, and additional results 
&gt; must be
&gt;     ignored to allow for future expansion. Parameters are defined as 
&gt; follows:
&gt;       CONN_ID - Unique identifier associated with this connection.
&gt;       CIRC_ID - Unique identifier for the circuit this belongs to (0 
&gt; if this
&gt;         doesn't belong to any circuit). At most their may be two 
&gt; connections
&gt;         (one inbound, one outbound) with any given CIRC_ID except in 
&gt; the case
&gt;         of exit connections.
&gt;       OR_ID - Relay fingerprint, 0 if connection doesn't belong to a 
&gt; relay.
&gt;       IP/PORT - IP address and port used by the associated connection, 
&gt; 0 if
&gt;         connection is used for relaying client or exit traffic.
&gt;       L_PORT - Local port used by the connection, 0 if connection is 
&gt; used for
&gt;         relaying client or exit traffic.
&gt;       TYPE_FLAGS - Single character flags indicating directionality 
&gt; and type
&gt;         of the connection (consists of one from each category, may become
&gt;         longer for future expansion).
&gt;           Connection Directionality:
&gt;             I: inbound, i: listening (unestablished inbound),
&gt;             O: outbound, o: unestablished outbound
&gt;           Usage Type:
&gt;             C: client traffic, R: relaying traffic,
&gt;             X: control, H: hidden service, D: directory
&gt;           Destination:
&gt;             T: inter-tor connection, t: outside the tor network
&gt;         For instance, "IRt" would indicate that this was an established
&gt;         1st-hop (or bridged) relay connection.
&gt;       READ/WRITE - Total bytes read/written over the life of this 
&gt; connection.
&gt;       UPTIME - Time the connection's been established in seconds.
&gt;
&gt;   "conn/all" -- Newline separated listing of all current connections.
&gt;
</body></email><email><emailId>20100421160424</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2010-04-21 16:04:24-0400</timestampReceived><subject>Analysis of the problems many relay operators are currently facing</subject><body>

I'll try to summarize here what I've learned in the past weeks over the
problems we are currently having with the Tor network as a whole, and  
the
issues that individual relay operators have; as well as describing the  
issues
we have identified (some of which have been adressed already). As the
information comes from #tor-dev on OFTC, bug reports and mailing  
lists, but no
overview exists, it seems worthwhile to collect what we know.

For the past months, quite a few relays have been sporadically  
dropping from
the consensus; either until they published the next descriptor again  
or for
longer periods of time. For this we have identified the following  
problems:

     Some vendors have backported openssl features to older versions,  
rendering
     those relays either completely useless as they are unable to  
establish
     connections so won't even bootstrap; or useless as relays to  
people using
     certain openssl versions. Thus, the directory authorities couldn't
     establish connections to them, meaning they marked them offline.

     We believe this is now fixed as of 0.2.2.11-alpha. A fix for the  
stable
     series of Tor has not been released yet.


     Authorities only downloaded descriptors for relays from V2  
directory
     authorities if they didn't have them available themselves. As  
only two
     V2 auths remain, one of which probably disallows most relays from
     publishing descriptors, this led to authorities knowing only  
about a part
     of the network. Some relays were thus unreachable by the majority  
of
     dir authorities, meaning they dropped out of the consensus.

     We believe this is now fixed as of 0.2.2.12-alpha. Not all  
authorities
     have upgraded yet.


     Relays (and authorities) running 0.2.2.11-alpha crash 24 hours  
after start
     if they have the statistic gathering functionality enabled.

     We believe this is now fixed as of 0.2.2.12-alpha. A workaround  
is to
     disable statistic gathering.


     Another issue exists that has not been identified yet, where a  
relay is
     only reachable from outside sporadically, even though there is no  
load.
     This issue is rare and has not been reproduced reliably.

Another class of problems exists which affects some/many relays: The  
relay
attracts a huge amount of connections, affecting stability of network  
equipment
and operating system. These problems might occur:

     The Tor process runs out of memory, because it has too many open
     connections. Tor is then killed by the OS's OOM-killer.

     Tor exhausts the ulimit -n that is affecting it, meaning random  
things
     like opening logfiles, establishing new connections or gathering  
more
     entropy fail, often creating many warnings in Tor's logfile. In  
some
     cases it appears that Tor is spinning until a file descriptor  
becomes
     available, burning all cpu.

     Tor makes a home router/DSL modem/kernel lock up, because it cannot
     handle the load. Symptoms include that internet access is  
completely
     nonfunctional even after the relay is stopped, or that it is  
extremely
     slow. These symptoms might last until the relevant piece of  
equipment is
     restarted.


     All these share the same underlying problem: Tor is getting more
     connections than it can handle. One way to help would be to make  
sure
     unused connections are closed more quickly, so that relays don't  
need
     to maintain as many active connections concurrently as they need  
to do
     now. A Tor patch that logs what state current connections have  
[0] shows
     that on some systems, around 10% of all connections were used for a
     begindir operation before, but now don't have a circuit attached  
anymore.
	Generally, the fraction of connections used exclusively for begindir
	operations appears to be high, so it might be worthwhile to close the
	circuits on them more quickly and not keep them around for possible  
later
	cannibalization.
	
	
	Another theory is that the fastest relays (by consensus weights) are  
used
	by a large proportion of users. This means that almost every Tor user  
will
	make a connection to those few relays, massively increasing the  
amount of
	connections the relay has to handle at the same time. Some evidence
	supporting this is that even after the bw authorities voted  
blutmagie's bw
	weight down a lot after the operator lowered the banwdidthrate  
considerably,
	it was still seeing many concurrent connections, while the amount of  
new
	connections/s was dropping a lot.
	
	
	As many relay operators are forced to turn off their relay because they
	don't have the resources to keep their relay up anymore, the problem  
only
	gets worse for the other operators, who need to deal with an unchanged
	number of clients.
	
	
	One last concern is that we're seeing scalability problems with our  
current
	design. Lots of chinese users are back on the network, as many relays  
have
	been unblocked by the gfw. Some relays are seeing more than 40k active
	connections, while being far away from reaching their bw limits. If  
usage
	increases to grow and a clear bug cannot be identified that causes the
	massive amount of connections and it can be determined that this is  
just
	Tor's popularity growing, alternative designs that don't require
	tcp connections might become a necessity very quickly.
	
I hope I didn't forget any problem/solution/analysis here, if so,  
please add it
so we can all track this down as quickly as possible.

Thanks
Sebastian
	
[0] http://archives.seul.org/or/relays/Apr-2010/msg00066.html
</body></email><email><emailId>20100423060640</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2010-04-23 06:06:40-0400</timestampReceived><subject>The long anticipated move from Flyspray...</subject><body>


...is finally complete: https://trac.torproject.org/

We've moved to Trac and both bugs.torproject.org and bugs.noreply.org
redirect to the above URL now. Please update the URLs in your source
code, bookmarks, etc. All of the bug numbers are the same so this should
hopefully be relatively easy. Your logins should work and you should
still be subscribed to any bugs you were subscribed to before. The wiki
has also been converted.

The version control support is pending. I'm going to add the git
support, but currently there doesn't appear to be a way to use remote
subversion repositories, so I've just added a link to
https://gitweb.torproject.org and https://svn.torproject.org/svn for
now.

I've added everyone I could remember to the trac admin group. If you are
not an admin and are a developer, please email me or ping me on IRC,
tell me your login name and I'll add you. 

Things you can and should do:

- Take a look over https://trac.torproject.org/projects/tor/report and
form new default reports. 

I made one for myself and Andrew under Tor Bundles and Installation
(https://trac.torproject.org/projects/tor/report/10) but didn't want to
presume I could do the same for everyone else. For example, bugs for Tor
Client and Tor Server might want to be in a single report, or maybe
nobody cares about Active Tickets by Milestone and it needs to
disappear. If you have admin access, you can delete/modify these.

- Beat it up a little and tell me if you find bugs!

- Feature requests. There are a number of Trac plugins we might want.

And many thanks to Peter for his sysadmin-fu and overall help. :)

Erinn

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100423093951</emailId><senderName>starslights</senderName><senderEmail>stars@hispeed.ch</senderEmail><timestampReceived>2010-04-23 09:39:51-0400</timestampReceived><subject>Re: The long anticipated move from Flyspray...</subject><body>


Hello to everyone 

Great new trac for Tor :D

I just found a bug in the new trac tracker, it t look like it use a old 
database for the accounts or something else, so in my case, when i open it , 
it send a confirmation about new mail address, by chance my old one was active 
and i was able to change it again.

Best Regards

SwissTorExit

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100421184403</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-04-21 18:44:03-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Wed, Apr 21, 2010 at 12:04 PM, Sebastian Hahn &lt;mail@sebastianhahn.net&gt; wrote:
&gt; I'll try to summarize here what I've learned in the past weeks over the
&gt; problems we are currently having with the Tor network as a whole, and the
&gt; issues that individual relay operators have; as well as describing the
&gt; issues
&gt; we have identified (some of which have been adressed already). As the
&gt; information comes from #tor-dev on OFTC, bug reports and mailing lists, but
&gt; no
&gt; overview exists, it seems worthwhile to collect what we know.

Thanks for collecting all this info, Sebastian!

 [...]
&gt;    Another issue exists that has not been identified yet, where a relay is
&gt;    only reachable from outside sporadically, even though there is no load.
&gt;    This issue is rare and has not been reproduced reliably.

I assume if they had anything in their logs, you would have said so.

&gt; Another class of problems exists which affects some/many relays: The relay
&gt; attracts a huge amount of connections, affecting stability of network
&gt; equipment
&gt; and operating system. These problems might occur:
&gt;
&gt;    The Tor process runs out of memory, because it has too many open
&gt;    connections. Tor is then killed by the OS's OOM-killer.

Where is the memory going, exactly?  Is it all in buffers, or is it
somewhere else?  Time to profile memory usage yet again.

If this is mostly Linux (and the mention of an OOM-killer suggests
that it is), we might want to see if using the new-ish standalone
Linux jemalloc helps people.   (We keep hitting fragmentation issues
with glibc malloc.)  To try it out, build the code from
http://www.canonware.com/jemalloc/ , stick the resulting .so file in
your LD_PRELOAD before you start Tor, and see if the memory usage is
much better.

&gt;    Tor exhausts the ulimit -n that is affecting it, meaning random things
&gt;    like opening logfiles, establishing new connections or gathering more
&gt;    entropy fail, often creating many warnings in Tor's logfile. In some
&gt;    cases it appears that Tor is spinning until a file descriptor becomes
&gt;    available, burning all cpu.

Some of our earlier discussion related to bug 925 is probably relevant
here.  We should solve that one so we can stop spinning when we're out
of fds.  What's more, when we run out of fds, it generally means that
the estimated number of connections we could handle was too high; if
we revise our estimate downwards, we can go back to keeping a few fds
in reserve for disk IO.

&gt;    Tor makes a home router/DSL modem/kernel lock up, because it cannot
&gt;    handle the load. Symptoms include that internet access is completely
&gt;    nonfunctional even after the relay is stopped, or that it is extremely
&gt;    slow. These symptoms might last until the relevant piece of equipment is
&gt;    restarted.

Do we know what kind of load is needed for this?  Too many
simultaneous connections, too many simultaneous incoming connections,
too much bw, or what?

&gt;    All these share the same underlying problem: Tor is getting more
&gt;    connections than it can handle. One way to help would be to make sure
&gt;    unused connections are closed more quickly, so that relays don't need
&gt;    to maintain as many active connections concurrently as they need to do
&gt;    now. A Tor patch that logs what state current connections have [0] shows
&gt;    that on some systems, around 10% of all connections were used for a
&gt;    begindir operation before, but now don't have a circuit attached anymore.

I think this number is could be a bit on the low side: the numbers I'm
seeing people report on IRC seem higher than 10%.  Also, the patch
counts the number of connections that have only a single circuit: if
this circuit is the same circuit that was used for the begindir (and I
think it typically is), then those connections too are lying unused.
 [...]
&gt;        As many relay operators are forced to turn off their relay because
&gt; they
&gt;        don't have the resources to keep their relay up anymore, the problem
&gt; only
&gt;        gets worse for the other operators, who need to deal with an
&gt; unchanged
&gt;        number of clients.

If this is what's happening, then our resource-limiting code isn't
working as well as it should be and we need to fix it.  In the past,
we've reached equilibrium in the face of large surges of clients by


&gt;        One last concern is that we're seeing scalability problems with our
&gt; current
&gt;        design. Lots of chinese users are back on the network, as many relays
&gt; have
&gt;        been unblocked by the gfw. Some relays are seeing more than 40k
&gt; active
&gt;        connections, while being far away from reaching their bw limits.

This is fishy; we should also try to rule out broken clients and/or
DOS attempts.

One more thing I saw suggested in IRC: it's possible that the new
bandwidth authority code is causing a problem here, since it uses a
node's bandwidth capacity to determine what fraction of the network's
connections it can handle.  But bandwidth isn't the only resource:
just because a router can handle twice as many bytes as it's pushing,
doesn't mean we should send it twice as many connections as it's
getting.  I'm not sure of the right lesson here.  Perhaps we need to
limit the amount that we up-rate any router's bandwidth, or perhaps we
need to find a way for a router to signal that it's running into load
troubles and get downrated.

-- 
Nick

</body></email><email><emailId>20100422221417</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-04-22 22:14:17-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Wed, Apr 21, 2010 at 02:44:03PM -0400, Nick Mathewson wrote:
&gt; &gt; Another class of problems exists which affects some/many relays: The relay
&gt; &gt; attracts a huge amount of connections, affecting stability of network
&gt; &gt; equipment
&gt; &gt; and operating system. These problems might occur:
&gt; &gt;
&gt; &gt;    The Tor process runs out of memory, because it has too many open
&gt; &gt;    connections. Tor is then killed by the OS's OOM-killer.
&gt; 
&gt; Where is the memory going, exactly?  Is it all in buffers, or is it
&gt; somewhere else?  Time to profile memory usage yet again.

My intuition is that a huge amount of it was going to openssl buffers.
When you have 20k TLS connections open, that's 37k*20k = 740 megs of
ram just sitting idle in openssl.

We got swisstorexit to run his non-exit relay under valgrind for a few
hours, and it didn't find any outright leaks.

&gt; If this is mostly Linux (and the mention of an OOM-killer suggests
&gt; that it is),

I think it's mostly Linux only because most of our fast relays are Linux.

&gt; we might want to see if using the new-ish standalone
&gt; Linux jemalloc helps people.   (We keep hitting fragmentation issues
&gt; with glibc malloc.)  To try it out, build the code from
&gt; http://www.canonware.com/jemalloc/ , stick the resulting .so file in
&gt; your LD_PRELOAD before you start Tor, and see if the memory usage is
&gt; much better.

Somebody should try this and see how it goes. You might suggest it to
the folks on tor-relays -- I bet not many of them read this list.

&gt; &gt;    Tor exhausts the ulimit -n that is affecting it, meaning random things
&gt; &gt;    like opening logfiles, establishing new connections or gathering more
&gt; &gt;    entropy fail, often creating many warnings in Tor's logfile. In some
&gt; &gt;    cases it appears that Tor is spinning until a file descriptor becomes
&gt; &gt;    available, burning all cpu.
&gt; 
&gt; Some of our earlier discussion related to bug 925 is probably relevant
&gt; here.  We should solve that one so we can stop spinning when we're out
&gt; of fds.  What's more, when we run out of fds, it generally means that
&gt; the estimated number of connections we could handle was too high; if
&gt; we revise our estimate downwards, we can go back to keeping a few fds
&gt; in reserve for disk IO.
&gt; 
&gt; &gt;    Tor makes a home router/DSL modem/kernel lock up, because it cannot
&gt; &gt;    handle the load. Symptoms include that internet access is completely
&gt; &gt;    nonfunctional even after the relay is stopped, or that it is extremely
&gt; &gt;    slow. These symptoms might last until the relevant piece of equipment is
&gt; &gt;    restarted.
&gt; 
&gt; Do we know what kind of load is needed for this?  Too many
&gt; simultaneous connections, too many simultaneous incoming connections,
&gt; too much bw, or what?

I think the main cause is typically too many open connections. There's
a state table inside the router, and once the table fills up, things
start to lose.

Too many simultaneous incoming connections could be another problem,
but I think it's rarer. It's certainly rarer to find good evidence of it.

&gt; &gt;    All these share the same underlying problem: Tor is getting more
&gt; &gt;    connections than it can handle. One way to help would be to make sure
&gt; &gt;    unused connections are closed more quickly, so that relays don't need
&gt; &gt;    to maintain as many active connections concurrently as they need to do
&gt; &gt;    now. A Tor patch that logs what state current connections have [0] shows
&gt; &gt;    that on some systems, around 10% of all connections were used for a
&gt; &gt;    begindir operation before, but now don't have a circuit attached anymore.
&gt; 
&gt; I think this number is could be a bit on the low side: the numbers I'm
&gt; seeing people report on IRC seem higher than 10%.  Also, the patch
&gt; counts the number of connections that have only a single circuit: if
&gt; this circuit is the same circuit that was used for the begindir (and I
&gt; think it typically is), then those connections too are lying unused.

I think I've solved this particular variant of the issue:
http://archives.seul.org/tor/relays/Apr-2010/msg00066.html
http://archives.seul.org/tor/relays/Apr-2010/msg00073.html
http://archives.seul.org/tor/relays/Apr-2010/msg00078.html

The next question is how much of a backport we should try to squeeze
into 0.2.1.x, on the theory that if stable Tor can't run a relay, our
network is going to continue to decay:
http://metrics.torproject.org/graphs/exit/exit-30d.png
http://metrics.torproject.org/torperf-graphs.html

Oh, and the other next question is what actual cutoff parameters to use
in the relays (and in the clients, when we get around to writing the
patch for them).

&gt;  [...]
&gt; &gt;        As many relay operators are forced to turn off their relay because
&gt; &gt; they
&gt; &gt;        don't have the resources to keep their relay up anymore, the problem
&gt; &gt; only
&gt; &gt;        gets worse for the other operators, who need to deal with an
&gt; &gt; unchanged
&gt; &gt;        number of clients.
&gt; 
&gt; If this is what's happening, then our resource-limiting code isn't
&gt; working as well as it should be and we need to fix it.  In the past,
&gt; we've reached equilibrium in the face of large surges of clients by

...by?

&gt; &gt;        One last concern is that we're seeing scalability problems with our
&gt; &gt; current
&gt; &gt;        design. Lots of chinese users are back on the network, as many relays
&gt; &gt; have
&gt; &gt;        been unblocked by the gfw. Some relays are seeing more than 40k
&gt; &gt; active
&gt; &gt;        connections, while being far away from reaching their bw limits.
&gt; 
&gt; This is fishy; we should also try to rule out broken clients and/or
&gt; DOS attempts.

I think they're real clients.

&gt; One more thing I saw suggested in IRC: it's possible that the new
&gt; bandwidth authority code is causing a problem here, since it uses a
&gt; node's bandwidth capacity to determine what fraction of the network's
&gt; connections it can handle.  But bandwidth isn't the only resource:
&gt; just because a router can handle twice as many bytes as it's pushing,
&gt; doesn't mean we should send it twice as many connections as it's
&gt; getting.  I'm not sure of the right lesson here.

Yep.

&gt;  Perhaps we need to
&gt; limit the amount that we up-rate any router's bandwidth, or perhaps we
&gt; need to find a way for a router to signal that it's running into load
&gt; troubles and get downrated.

Mike pushed back in the tor-relays thread about my suggestion of
capping the amount of attention we give to any router. That approach
will apparently really reduce the performance gain we can get.

It would be great to reduce the weightings for relays that are failing --
but it's hard to remotely detect "about to fail", and "actually failed"
usually comes in the form of a down relay.

--Roger

</body></email><email><emailId>20100422233910</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2010-04-22 23:39:10-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Thu, Apr 22, 2010 at 6:14 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; My intuition is that a huge amount of it was going to openssl buffers.
&gt; When you have 20k TLS connections open, that's 37k*20k = 740 megs of
&gt; ram just sitting idle in openssl.

For our frontend machines here where have a patch to OpenSSL which
reduces the default buffer size. I can dig it up and send it along if
it would be helpful.



AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
</body></email><email><emailId>20100422234821</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-04-22 23:48:21-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Thu, Apr 22, 2010 at 07:39:10PM -0400, Adam Langley wrote:
&gt; On Thu, Apr 22, 2010 at 6:14 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; &gt; My intuition is that a huge amount of it was going to openssl buffers.
&gt; &gt; When you have 20k TLS connections open, that's 37k*20k = 740 megs of
&gt; &gt; ram just sitting idle in openssl.
&gt; 
&gt; For our frontend machines here where have a patch to OpenSSL which
&gt; reduces the default buffer size. I can dig it up and send it along if
&gt; it would be helpful.

Hi Adam,

Actually Nick got a patch accepted to OpenSSL mainline that dynamically
reduces buffers as they're not needed. See item #2 on
https://www.torproject.org/faq.html.en#RelayMemory

The remaining challenge is that roughly nobody is running OpenSSL
1.0.0-beta5, and roughly nobody knows how to recompile their OpenSSL. :)

(Is your patch better or orthogonal to Nick's? Maybe we should get yours
in too?)

--Roger

</body></email><email><emailId>20100422235452</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2010-04-22 23:54:52-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Thu, Apr 22, 2010 at 7:48 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; Actually Nick got a patch accepted to OpenSSL mainline that dynamically
&gt; reduces buffers as they're not needed. See item #2 on
&gt; https://www.torproject.org/faq.html.en#RelayMemory
&gt;
&gt; The remaining challenge is that roughly nobody is running OpenSSL
&gt; 1.0.0-beta5, and roughly nobody knows how to recompile their OpenSSL. :)
&gt;
&gt; (Is your patch better or orthogonal to Nick's? Maybe we should get yours
&gt; in too?)

Our patch reduces the default size of the buffers, but the buffers
stick around all the time. Based on Nick's email, your patch is
probably better.

We've just bumped up to OpenSSL 1.0.0 for Android trunk, so hopefully
we can drop our local patch when 1.0.1 comes around!

Why not ship your own OpenSSL and statically link as an option? The
OpenSSL build probably is a little scary, but I'm guessing that most
of your big relays are running on Windows where a simple "./config &amp;&amp;
make" will produce .a's for you.


AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
</body></email><email><emailId>20100423003437</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-04-23 00:34:37-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

On Thu, Apr 22, 2010 at 07:54:52PM -0400, agl@imperialviolet.org wrote 1.1K bytes in 28 lines about:
: Why not ship your own OpenSSL and statically link as an option? The
: OpenSSL build probably is a little scary, but I'm guessing that most
: of your big relays are running on Windows where a simple "./config &amp;&amp;
: make" will produce .a's for you.

We do this for Windows already. The windows packages include a version
of openssl we want to rely upon.  Right now, this is 0.9.8l.  My plan is
to upgrade after 1.0.x is released to the world.

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20100423054831</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-04-23 05:48:31-0400</timestampReceived><subject>Re: Analysis of the problems many relay operators are currently</subject><body>

Hi,

On Fri, Apr 23, 2010 at 12:14 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt;&gt; we might want to see if using the new-ish standalone
&gt;&gt; Linux jemalloc helps people.   (We keep hitting fragmentation issues
&gt;&gt; with glibc malloc.)  To try it out, build the code from
&gt;&gt; http://www.canonware.com/jemalloc/ , stick the resulting .so file in
&gt;&gt; your LD_PRELOAD before you start Tor, and see if the memory usage is
&gt;&gt; much better.
&gt;
&gt; Somebody should try this and see how it goes. You might suggest it to
&gt; the folks on tor-relays -- I bet not many of them read this list.

I ran into that OOM killer memory problem on my Linux based exit node,
too (Nick and Roger might remember the machine hanging and basically
needing a reset a few weeks back). Currently I am restarting Tor daily
via cron. So I am happy to try this jemalloc thing and report back.

Best,
/C

</body></email><email><emailId>20100309044906</emailId><senderName>Nick Mathewson</senderName><senderEmail>nick.a.mathewson@gmail.com</senderEmail><timestampReceived>2010-03-09 04:49:06-0400</timestampReceived><subject>New changelog system (developers please read) [was Re: A couple of</subject><body>

So it looks like we've settled on a new way to get good ChangeLogs
written without running into merge conflicts every time we turn
around, and without requiring that everybody's commit messages be
user-facing.

When you do a commit that needs a ChangeLog entry, add a new file to
the "changes" toplevel subdirectory.  It should have the format of a
one-entry
changelog section, as in

   o Major bugfixes:
      - Fix a potential buffer overflow.  Fixes bug 9999.

If at all possible, try to create this file in the same commit where
you are making the change.  Please give it a distinctive name that no
other branch will use for the lifetime of your change.

When Roger goes to make a release, he will concatenate all the entries
in changes to make a draft changelog, and clear the directory.  He'll
then edit the draft changelog into a nice readable format.

Frequently Unasked Questions:

1) What needs a changelog entry?

A not-exhaustive list: Anything that might change user-visible
behavior. Anything that changes internals, documentation, or the build
system enough that somebody could notice.  Big or interesting code
rewrites.  Anything about which somebody might plausibly wonder "when
did that happen, and/or why did we do that" 6 months down the line.

2) What goes in a changelog entry?

First, categorize it.  Some common categories are:

    Minor bugfixes, Major bugfixes, Minor features, Major features,
Code simplifications and refactoring.

Then, say what the change does.

Finally, if it's a bugfix, then mention what bug it fixes and when the
bug was introduced.

3) What's the difference between a major bugfix and a minor bugfix, or
a major feature and a minor feature?

Use your own best judgment.

-- 
Nick
</body></email><email><emailId>20100310181903</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-03-10 18:19:03-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

Hi Karsten,

First of all, nice analysis!

On Mon, Feb 15, 2010 at 9:29 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:

&gt; So, are these good news? Personally, I had expected worse results. During most of \
&gt; the time, availability is surprisingly high. An 80% chance of the bridges working \
&gt; even after 96 hours seems fair. That means in 1 out of 5 cases someone needs to \
&gt; send a second e-mail or make a second website request. We might even think (or have \
&gt; already thought) about implementing a bridge update functionality where users go to \
&gt; the bridge authority and exchange their broken bridges for working ones---as long \
&gt; as at least one of their bridges still works.

Would it be possible for someone to tell the bridge authority that a
bridge is down even though it is not? Maybe through a DoS attack? If
this is the case, maybe this thing should be handled with care or
otherwise there's a paranoid theoretical way someone could learn all
bridge addresses.

A way around that, if it is considered realistic enough, would be to
tag some bridges 'private' or so and not to give those out with that
update functionality.

Best,
C


</body></email><email><emailId>20100304032430</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2010-03-04 03:24:30-0400</timestampReceived><subject>Proposal idea: User path configuration</subject><body>

Filename: xxx-user-path-config.txt
Title: Configuration options regarding circuit building
Author: Sebastian Hahn
Created: 01-March-2010
Status: Draft

Overview:

    This document outlines how Tor handles the user configuration  
options
    to influence the circuit building process.

Motivation:

    Tor's treatment of the configuration *Nodes options was surprising  
to many
    users, and quite a few conspiracy theories have crept up. We  
should update
    our specification and code to better describe and communicate what  
is going
    during circuit building, and how we're honoring configuration. So  
far,
    we've been tracking a bugreport about this behaviour (
    https://bugs.torproject.org/flyspray/index.php? 
do=details&amp;id=1090 ) and
    Nick replied in a thread on or-talk (
    http://archives.seul.org/or/talk/Feb-2010/msg00117.html ). This  
proposal
    tries to document our intention for those configuration options.

Design:

    Five configuration options are available to users to influence Tor's
    circuit building. EntryNodes and ExitNodes define a list of nodes  
that
    are for the Entry/Exit position in all circuits. ExcludeNodes is a  
list of
    nodes that are used for no circuit, and ExcludeExitNodes is a list  
of
    nodes that aren't used as the last hop. StrictNodes defines Tor's  
behaviour
    in case of a conflict, for example when a node that is excluded is  
the only
    available introduction point. Setting StrictNodes to 1 breaks Tor's
    functionality in that case, and it will refuse to build such a  
circuit.

    Neither Nick's email nor bug 1090 have clear suggestions how we  
should
    behave in each case, so I tried to come up with something that made
    sense to me.

Security implications:

    Deviating from normal circuit building can break one's anonymity,  
so the
    documentation of the above option should contain a warning to make  
users
    aware of the pitfalls.

Specification:

    It is proposed that the "User configuration" part of path-spec  
(section
    2.2.2) be replaced with this:

    Users can alter the default behavior for path selection with  
configuration
    options. In case of conflicts (excluding and requiring the same  
node) the
    "StrictNodes" option is used to determine behaviour. If a nodes is  
both
    excluded and required via a configuration option, the exclusion  
takes
    preference.

    - If "ExitNodes" is provided, then every request requires an exit  
node on
      the ExitNodes list. If a request is supported by no nodes on  
that list,
      and "StrictNodes" is false, then Tor treats that request as if  
ExitNodes
      were not provided.

    - "EntryNodes" behaves analogously.

    - If "ExcludeNodes" is provided, then no circuit uses any of the  
nodes
      listed. If a circuit requires an excluded node to be used, and
      "StrictNodes" is false, then Tor uses the node in that position  
while
      not using any other of the excluded nodes.

    - If "ExcludeExitNodes" is provided, then Tor will not use the nodes
      listed for the exit position in a circuit. If a circuit requires  
an
      excluded node to be used in the exit position and "StrictNodes" is
      false, then Tor builds that circuit as if ExcludeExitNodes were  
not
      provided.

    - If a user tries to connect to or resolve a hostname of the form
      &lt;target&gt;.&lt;servername&gt;.exit and the "AllowDotExit" configuration  
option
      is set to 1, the request is rewritten to a request for &lt;target&gt;,  
and the
      request is only supported by the exit whose nickname or  
fingerprint is
      &lt;servername&gt;. If "AllowDotExit" is set to 0 (default), any  
request for
      &lt;anything&gt;.exit is denied.

    - When any of the *Nodes settings are changed, all circuits are  
expired
      immediately, to prevent a situation where a previously built  
circuit
      is used even though some of its nodes are now excluded.


Compatibility:

    The old Strict*Nodes options are deprecated, and the StrictNodes  
option is
    new. Tor users may need to update their configuration file.

</body></email><email><emailId>20100327160517</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-03-27 16:05:17-0400</timestampReceived><subject>Firefox privacy and Tor Browser</subject><body>

Hello,

I just heard the news about the Tor Browser bundle for GNU/Linux. I
like the idea, and I wanted to pitch a couple thoughts to the
developers. I apologize in advance if these things have been brought
up already, or if the subject belongs on or-talk instead.

Firstly, about NoScript. You may wish to consider an extension named
RequestPolicy [1] instead. You may want to also want to consider
FlashBlock [2], since that is a popular attack vector.

Secondly, about a specific behavior in Firefox itself, which I think
Tor developers should all be aware (or reminded) of. Firefox uses
Google's Safe Browsing API [3] to check visited websites against a
Google blacklist. There have been privacy issues brought up [4]. In
short, Firefox's use of this API could lead to Google (or anyone
listening to network traffic, since it was in the clear) being able to
track users via a unique hash communicated with Google servers and
persistent across sessions (including "Private Browsing"). Bartłomiej
has written extensively on the subject [5]. His attempts to patch this
privacy leak at the time were sabotaged by Google employees [6]. This
behavior is optional now in Firefox 3, but still on by default [7].
So, Tor Browser may want to consider having this "feature" off by
default?

That's all for now.

Thanks everyone for your time and the great work on Tor!

[1] &lt;https://addons.mozilla.org/en-US/firefox/addon/9727&gt;
[2] &lt;https://addons.mozilla.org/en-US/firefox/addon/433&gt;
[3] &lt;http://code.google.com/apis/safebrowsing/&gt;
[4] &lt;http://ha.ckers.org/blog/20090824/google-safe-browsing-and-chrome-privacy-leak/&gt;
[5] &lt;http://bb.homelinux.org/en/firefox/howtobug368255.html&gt;
[6] &lt;https://bugzilla.mozilla.org/show_bug.cgi?id=368255&gt;
[7] &lt;http://bb.homelinux.org/en/firefox/googsbff3.html&gt;

-- 
Mansour Moufid

</body></email><email><emailId>20100331132601</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-03-31 13:26:01-0400</timestampReceived><subject>Proposal idea: Automatically promoting Tor clients to nodes</subject><body>

I've been working recently on a proposal to increase the number of
bridges in the Tor network. It describes how Tor clients can
automatically become bridges, if they are considered to be
sufficiently reliable and the operator consents.

Comments and suggestions would be appreciated.

The current draft is below, and the latest version can be found here:

 https://gitweb.torproject.org//sjm217/tor.git?a=blob;f=doc/spec/proposals/ideas/xxx-automatic-node-promotion.txt;hb=xxx-automatic-node-promotion


Filename: xxx-automatic-node-promotion.txt
Title: Automatically promoting Tor clients to nodes
Author: Steven Murdoch
Created: 12-Mar-2010
Status: Draft
Target:

1. Overview

   This proposal describes how Tor clients could determine when they
   have sufficient bandwidth capacity and are sufficiently reliable to
   become either bridges or Tor relays. When they meet this
   criteria, they will automatically promote themselves, based on user
   preferences. The proposal also defines the new controller messages
   and options which will control this process.

   Note that for the moment, only transitions between client and
   bridge are being considered. Transitions to public relay will
   be considered at a future date, but will use the same
   infrastructure for measuring capacity and reliability.

2. Motivation and history

   Tor has a growing user-base and one of the major impediments to the
   quality of service offered is the lack of network capacity. This is
   particularly the case for bridges, because these are gradually
   being blocked, and thus no longer of use to people within some
   countries. By automatically promoting Tor clients to bridges, and
   perhaps also to full public relays, this proposal aims to solve
   these problems.
 
   Only Tor clients which are sufficiently useful should be promoted,
   and the process of determining usefulness should be performed
   without reporting the existence of the client to the central
   authorities. The criteria used for determining usefulness will be
   in terms of bandwidth capacity and uptime, but parameters should be
   specified in the directory consensus. State stored at the client
   should be in no more detail than necessary, to prevent sensitive
   information being recorded.

3. Design

3.x Opt-in state model

   Tor can be in one of five node-promotion states:

   - off (O): Currently a client, and will stay as such
   - auto (A): Currently a client, but will consider promotion
   - bridge (B): Currently a bridge, and will stay as such
   - auto-bridge (AB): Currently a bridge, but will consider promotion
   - relay (R): Currently a public relay, and will stay as such

   The state can be fully controlled from the configuration file or
   controller, but the normal state transitions are as follows:

   Any state -&gt; off: User has opted out of node promotion
   Off -&gt; any state: Only permitted with user consent

   Auto -&gt; auto-bridge: Tor has detected that it is sufficiently
    reliable to be a *bridge*
   Auto -&gt; bridge: Tor has detected that it is sufficiently reliable
    to be a *relay*, but the user has chosen to remain a *bridge*
   Auto -&gt; relay: Tor has detected that it is sufficiently reliable
    to be *relay*, and will skip being a *bridge*
   Auto-bridge -&gt; relay: Tor has detected that it is sufficiently
    reliable to be a *relay*

   Note that this model does not support automatic demotion. If this
   is desirable, there should be some memory as to whether the
   previous state was relay, bridge, or auto-bridge. Otherwise the
   user may be prompted to become a relay, although he has opted to
   only be a bridge.

3.x User interaction policy

   There are a variety of options in how to involve the user into the
   decision as to whether and when to perform node promotion. The
   choice also may be different when Tor is running from Vidalia (and
   thus can readily prompt the user for information), and standalone
   (where Tor can only log messages, which may or may not be read).

   The option requiring minimal user interaction is to automatically
   promote nodes according to reliability, and allow the user to opt
   out, by changing settings in the configuration file or Vidalia user
   interface.

   Alternatively, if a user interface is available, Tor could prompt
   the user when it detects that a transition is available, and allow
   the user to choose which of the available options to select. If
   Vidalia is not available, it still may be possible to solicit an
   email address on install, and contact the operator to ask whether
   a transition to bridge or relay is permitted.

   Finally, Tor could by default not make any transition, and the user
   would need to opt in by stating the maximum level (bridge or
   relay) to which the node may automatically promote itself.

3.x Performance monitoring model

   To prevent a large number of clients activating as relays, but
   being too unreliable to be useful, clients should measure their
   performance. If this performance meets a parameterized acceptance
   criteria, a client should consider promotion. To measure
   reliability, this proposal adopts a simple user model:

    - A user decides to use Tor at times which follow a Poisson
      distribution
    - At each time, the user will be happy if the bridge chosen has
      adequate bandwidth and is reachable
    - If the chosen bridge is down or slow too many times, the user
      will consider Tor to be bad

   If we additionally assume that the recent history of relay
   performance matches the current performance, we can measure
   reliability by simulating this simple user.

   The following parameters are distributed to clients in the
   directory consensus:

     - min_bandwidth: Minimum self-measured bandwidth for a node to be
       considered useful, in bytes per second
     - check_period: How long, in seconds, to wait between checking
       reachability and bandwidth (on average)
     - num_samples: Number of recent samples to keep
     - num_useful: Minimum number of recent samples where the node was
       reachable and had at least min_bandwidth capacity, for a client
       to consider promoting to a bridge

   A different set of parameters may be used for considering when to
   promote a bridge to a full relay, but this will be the subject of a
   future revision of the proposal.

3.x Performance monitoring algorithm

   The simulation described above can be implemented as follows:

   Every 60 seconds:
     1. Tor generates a random floating point number x in
        the interval [0, 1).
     2. If x &gt; (1 / (check_period / 60)) GOTO end; otherwise:
     3. Tor sets the value last_check to the current_time (in seconds)
     4. Tor measures reachability
     5. If the client is reachable, Tor measures its bandwidth
     6. If the client is reachable and the bandwidth is &gt;=
        min_bandwidth, the test has succeeded, otherwise it has failed.
     7. Tor adds the test result to the end of a ring-buffer containing
        the last num_samples results: measurement_results
     8. Tor saves last_check and measurements_results to disk
     9. If the length of measurements_results == num_samples and
        the number of successes &gt;= num_useful, Tor should consider
        promotion to a bridge
   end.
 
   When Tor starts, it must fill in the samples for which it was not
   running. This can only happen once the consensus has downloaded,
   because the value of check_period is needed.
 
      1. Tor generates a random number y from the Poisson distribution [1]
         with lambda = (current_time - last_check) * (1 / check_period)
      2. Tor sets the value last_check to the current_time (in seconds)	
      3. Add y test failures to the ring buffer measurements_results
      4. Tor saves last_check and measurements_results to disk
 
   In this way, a Tor client will measure its bandwidth and
   reachability every check_period seconds, on average. Provided
   check_period is sufficiently greater than a minute (say, at least an
   hour), the times of check will follow a Poisson distribution. [2]
 
   While this does require that Tor does record the state of a client
   over time, this does not leak much information. Only a binary
   reachable/non-reachable is stored, and the timing of samples becomes
   increasingly fuzzy as the data becomes less recent.

   On IP address changes, Tor should clear the ring-buffer, because
   from the perspective of users with the old IP address, this node
   might as well be a new one with no history. This policy may change
   once we start allowing the bridge authority to hand out new IP
   addresses given the fingerprint.

3.x Bandwidth measurement

   Tor needs to measure its bandwidth to test the usefulness as a
   bridge. A non-intrusive way to do this would be to passively measure
   the peak data transfer rate since the last reachability test. Once
   this exceeds min_bandwidth, Tor can set a flag that this node
   currently has sufficient bandwidth to pass the bandwidth component
   of the upcoming performance measurement.

   For the first version we may simply skip the bandwidth test,
   because the existing reachability test sends 500 kB over several
   circuits, and checks whether the node can transfer at least 50
   kB/s.  This is probably good enough for a bridge, so this test
   might be sufficient to record a success in the ring buffer.

3.x New options

3.x New controller message

4. Migration plan

   We should start by setting a high bandwidth and uptime requirement
   in the consensus, so as to avoid overloading the bridge authority
   with too many bridges. Once we are confident our systems can scale,
   the criteria can be gradually shifted down to gain more bridges.

5. Related proposals

6. Open questions:

   - What user interaction policy should we take?

   - When (if ever) should we turn a relay into an exit relay?

   - What should the rate limits be for auto-promoted bridges/relays?
     Should we prompt the user for this?

   - Perhaps the bridge authority should tell potential bridges
     whether to enable themselves, by taking into account whether
     their IP address is blocked

   - How do we explain the possible risks of running a bridge/relay
     * Use of bandwidth/congestion
     * Publication of IP address
     * Blocking from IRC (even for non-exit relays)

   - What feedback should we give to bridge relays, to encourage then
     e.g. number of recent users (what about reserve bridges)?

   - Can clients back-off from doing these tests (yes, we should do
     this)

[1] For algorithms to generate random numbers from the Poisson
    distribution, see: \
http://en.wikipedia.org/wiki/Poisson_distribution#Generating_Poisson-distributed_random_variables
 [2] "The sample size n should be equal to or larger than 20 and the
     probability of a single success, p, should be smaller than or equal to
     .05. If n &gt;= 100, the approximation is excellent if np is also &lt;= 10."
    http://www.itl.nist.gov/div898/handbook/pmc/section3/pmc331.htm (e-Handbook of \
Statistical Methods)

-- 
http://www.cl.cam.ac.uk/users/sjm217/


</body></email><email><emailId>20100327164756</emailId><senderName>Al MailingList</senderName><senderEmail>alpal.mailinglist@gmail.com</senderEmail><timestampReceived>2010-03-27 16:47:56-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>

A couple of points

No script also blocks flash.

Google's safe browsing is just an HTTP request, so I would assume when
tor is correctly configured it would not be in the clear.

Reference 5 seems to have his tin foil hat on a little tight. I'm not
quite sure what he's saying, but the google safe browsing updates
don't send the sites you're visiting, it simple retrieves the list of
bad sites (more specifically a diff of the bad sites list since your
last update). So all they can do is track that a particular user is
updating the local black list periodically.



On Sat, Mar 27, 2010 at 4:17 PM, Mansour Moufid &lt;mansourmoufid@gmail.com&gt; wrote:
&gt; Hello,
&gt;
&gt; I just heard the news about the Tor Browser bundle for GNU/Linux. I
&gt; like the idea, and I wanted to pitch a couple thoughts to the
&gt; developers. I apologize in advance if these things have been brought
&gt; up already, or if the subject belongs on or-talk instead.
&gt;
&gt; Firstly, about NoScript. You may wish to consider an extension named
&gt; RequestPolicy [1] instead. You may want to also want to consider
&gt; FlashBlock [2], since that is a popular attack vector.
&gt;
&gt; Secondly, about a specific behavior in Firefox itself, which I think
&gt; Tor developers should all be aware (or reminded) of. Firefox uses
&gt; Google's Safe Browsing API [3] to check visited websites against a
&gt; Google blacklist. There have been privacy issues brought up [4]. In
&gt; short, Firefox's use of this API could lead to Google (or anyone
&gt; listening to network traffic, since it was in the clear) being able to
&gt; track users via a unique hash communicated with Google servers and
&gt; persistent across sessions (including "Private Browsing"). Bartłomiej
&gt; has written extensively on the subject [5]. His attempts to patch this
&gt; privacy leak at the time were sabotaged by Google employees [6]. This
&gt; behavior is optional now in Firefox 3, but still on by default [7].
&gt; So, Tor Browser may want to consider having this "feature" off by
&gt; default?
&gt;
&gt; That's all for now.
&gt;
&gt; Thanks everyone for your time and the great work on Tor!
&gt;
&gt; [1] &lt;https://addons.mozilla.org/en-US/firefox/addon/9727&gt;
&gt; [2] &lt;https://addons.mozilla.org/en-US/firefox/addon/433&gt;
&gt; [3] &lt;http://code.google.com/apis/safebrowsing/&gt;
&gt; [4] &lt;http://ha.ckers.org/blog/20090824/google-safe-browsing-and-chrome-privacy-leak/&gt;
&gt; [5] &lt;http://bb.homelinux.org/en/firefox/howtobug368255.html&gt;
&gt; [6] &lt;https://bugzilla.mozilla.org/show_bug.cgi?id=368255&gt;
&gt; [7] &lt;http://bb.homelinux.org/en/firefox/googsbff3.html&gt;
&gt;
&gt; --
&gt; Mansour Moufid
&gt;

</body></email><email><emailId>20100327195706</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-03-27 19:57:06-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>

On Sat, Mar 27, 2010 at 12:17 PM, Al MailingList
&lt;alpal.mailinglist@gmail.com&gt; wrote:
&gt; Google's safe browsing is just an HTTP request, so I would assume when
&gt; tor is correctly configured it would not be in the clear.

It would be clearly visible to Tor exit nodes, and the "signature" of
such traffic would be clear to a local observer (I elaborate further
down).

&gt; Reference 5 seems to have his tin foil hat on a little tight.

Probably a Tor user. ; )

&gt; I'm not
&gt; quite sure what he's saying, but the google safe browsing updates
&gt; don't send the sites you're visiting, it simple retrieves the list of
&gt; bad sites (more specifically a diff of the bad sites list since your
&gt; last update). So all they can do is track that a particular user is
&gt; updating the local black list periodically.

That's correct, but with each of those requests to update your
browser's blacklist, is sent uniquely identifying information
(including "machineid" and "userid"). This information does not change
over time, and cannot be prevented from being sent -- even in Private
Browsing mode -- unless you unsubscribe from this service in the
preferences. In effect, your browser is periodically phoning home to
Google with a uniquely identifying key that -- and this is the issue
that I think Tor developers should consider closely: -- does not
change across browsing sessions.

To illustrate why I think this is something that concerns Tor, allow
me to elaborate. There has been some discussion regarding identifying
Tor users based on correlating "signatures" of traffic observed
locally versus at exit nodes. Instead of watching website traffic, an
attacker could instead watch intermittent noise. Things like a
specific combination of RSS bookmark auto-updates, or... periodic
blacklist updates. The Google Safe Browsing update traffic occurs in
bursts and periodically, and will therefore have a very unique
signature. Furthermore, the uniquely identifying key sent to Google
unencrypted each time would allow an attacker to cross-reference exit
node traffic and identify a user across sessions.

It may seem far-fetched, but I don't think it's inappropriate to
consider these possibilities.

-- 
Mansour Moufid
</body></email><email><emailId>20100327202036</emailId><senderName>Al MailingList</senderName><senderEmail>alpal.mailinglist@gmail.com</senderEmail><timestampReceived>2010-03-27 20:20:36-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>

On Sat, Mar 27, 2010 at 8:09 PM, Mansour Moufid &lt;mansourmoufid@gmail.com&gt; wrote:
&gt; On Sat, Mar 27, 2010 at 12:17 PM, Al MailingList
&gt; &lt;alpal.mailinglist@gmail.com&gt; wrote:
&gt;&gt; Google's safe browsing is just an HTTP request, so I would assume when
&gt;&gt; tor is correctly configured it would not be in the clear.
&gt;
&gt; It would be clearly visible to Tor exit nodes, and the "signature" of
&gt; such traffic would be clear to a local observer (I elaborate further
&gt; down).
&gt;
&gt;&gt; Reference 5 seems to have his tin foil hat on a little tight.
&gt;
&gt; Probably a Tor user. ; )
&gt;
&gt;&gt; I'm not
&gt;&gt; quite sure what he's saying, but the google safe browsing updates
&gt;&gt; don't send the sites you're visiting, it simple retrieves the list of
&gt;&gt; bad sites (more specifically a diff of the bad sites list since your
&gt;&gt; last update). So all they can do is track that a particular user is
&gt;&gt; updating the local black list periodically.
&gt;
&gt; That's correct, but with each of those requests to update your
&gt; browser's blacklist, is sent uniquely identifying information
&gt; (including "machineid" and "userid"). This information does not change
&gt; over time, and cannot be prevented from being sent -- even in Private
&gt; Browsing mode -- unless you unsubscribe from this service in the
&gt; preferences. In effect, your browser is periodically phoning home to
&gt; Google with a uniquely identifying key that -- and this is the issue
&gt; that I think Tor developers should consider closely: -- does not
&gt; change across browsing sessions.
&gt;
&gt; To illustrate why I think this is something that concerns Tor, allow
&gt; me to elaborate. There has been some discussion regarding identifying
&gt; Tor users based on correlating "signatures" of traffic observed
&gt; locally versus at exit nodes. Instead of watching website traffic, an
&gt; attacker could instead watch intermittent noise. Things like a
&gt; specific combination of RSS bookmark auto-updates, or... periodic
&gt; blacklist updates. The Google Safe Browsing update traffic occurs in
&gt; bursts and periodically, and will therefore have a very unique
&gt; signature. Furthermore, the uniquely identifying key sent to Google
&gt; unencrypted each time would allow an attacker to cross-reference exit
&gt; node traffic and identify a user across sessions.
&gt;
&gt; It may seem far-fetched, but I don't think it's inappropriate to
&gt; consider these possibilities.
&gt;
&gt; --
&gt; Mansour Moufid
&gt;


Perhaps I was a little dismissive :) I see the issue now - you could
track a user moving between exit nodes if you saw that unique cookie,
and do some profiling.

&lt;runs for his tin hat&gt;

:D
</body></email><email><emailId>20100328012258</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-03-28 01:22:58-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>

On Sat, Mar 27, 2010 at 11:47:17AM -0430, mansourmoufid@gmail.com wrote 1.8K bytes in 40 lines about:
: Firstly, about NoScript. You may wish to consider an extension named
: RequestPolicy [1] instead. You may want to also want to consider
: FlashBlock [2], since that is a popular attack vector.

Thanks for your thoughts.  While I'm a big fan of request policy, it
'breaks' the web for 95% of the users out there.  The
slightly-above-average web user still doesn't understand the web page
they are viewing is composed of many domains all serving up different
parts.  Having watched people use request policy for the first time,
they end up temporarily enabling everything, because the defaults are
still shocking to them.

: Secondly, about a specific behavior in Firefox itself, which I think
: Tor developers should all be aware (or reminded) of. Firefox uses
: Google's Safe Browsing API [3] to check visited websites against a
: Google blacklist. There have been privacy issues brought up [4]. In
: short, Firefox's use of this API could lead to Google (or anyone
: listening to network traffic, since it was in the clear) being able to
: track users via a unique hash communicated with Google servers and
: persistent across sessions (including "Private Browsing"). Bartłomiej
: has written extensively on the subject [5]. His attempts to patch this
: privacy leak at the time were sabotaged by Google employees [6]. This
: behavior is optional now in Firefox 3, but still on by default [7].
: So, Tor Browser may want to consider having this "feature" off by
: default?

It is disabled, along with reported attack sites. It's disabled in
prefs.js.  See
https://svn.torproject.org/svn/torbrowser/trunk/build-scripts/config/prefs.js

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20100328023047</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-03-28 02:30:47-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>


Thus spake andrew@torproject.org (andrew@torproject.org):

&gt; On Sat, Mar 27, 2010 at 11:47:17AM -0430, mansourmoufid@gmail.com wrote 1.8K bytes in 40 lines about:
&gt; : Firstly, about NoScript. You may wish to consider an extension named
&gt; : RequestPolicy [1] instead. You may want to also want to consider
&gt; : FlashBlock [2], since that is a popular attack vector.
&gt; 
&gt; Thanks for your thoughts.  While I'm a big fan of request policy, it
&gt; 'breaks' the web for 95% of the users out there.  The
&gt; slightly-above-average web user still doesn't understand the web page
&gt; they are viewing is composed of many domains all serving up different
&gt; parts.  Having watched people use request policy for the first time,
&gt; they end up temporarily enabling everything, because the defaults are
&gt; still shocking to them.

Yes. See also my comments on the blog as to why I feel that NoScript
is a better solution than RequestPolicy even if usability wasn't a factor:
https://blog.torproject.org/blog/tor-browser-bundle-gnulinux#comment-4844

&gt; : Secondly, about a specific behavior in Firefox itself, which I think
&gt; : Tor developers should all be aware (or reminded) of. Firefox uses
&gt; : Google's Safe Browsing API [3] to check visited websites against a
&gt; : Google blacklist. There have been privacy issues brought up [4]. In
&gt; : short, Firefox's use of this API could lead to Google (or anyone
&gt; : listening to network traffic, since it was in the clear) being able to
&gt; : track users via a unique hash communicated with Google servers and
&gt; : persistent across sessions (including "Private Browsing"). Bart??omiej
&gt; : has written extensively on the subject [5]. His attempts to patch this
&gt; : privacy leak at the time were sabotaged by Google employees [6]. This
&gt; : behavior is optional now in Firefox 3, but still on by default [7].
&gt; : So, Tor Browser may want to consider having this "feature" off by
&gt; : default?
&gt; 
&gt; It is disabled, along with reported attack sites. It's disabled in
&gt; prefs.js.  See
&gt; https://svn.torproject.org/svn/torbrowser/trunk/build-scripts/config/prefs.js

Note that it is not disabled by the normal Torbutton shipped with the
installable bundles. This is because it is expected that the common
use case there is that the user will be toggling in and out of Tor
fairly frequently, which clears both this Google cookie and the
SafeBrowsing API's HMAC key (which is itself an additional
identifier).

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100310043223</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-03-10 04:32:23-0400</timestampReceived><subject>Re: Proposal idea: User path configuration</subject><body>

On Thu, Mar 04, 2010 at 04:24:30AM +0100, Sebastian Hahn wrote:
&gt;    Users can alter the default behavior for path selection with  
&gt; configuration
&gt;    options. In case of conflicts (excluding and requiring the same node) 
&gt; the
&gt;    "StrictNodes" option is used to determine behaviour. If a nodes is  
&gt; both
&gt;    excluded and required via a configuration option, the exclusion takes
&gt;    preference.

I think we should work out the situations where strictnodes is needed,
and the situations where we want to honor the config option even without
strictnodes 1.

For example, if you set entrynodes or exitnodes, then imo you should get
one of the nodes you specified, or fail if none work. You asked for it,
you get it. Similarly, if you set Excludenodes or excludeexitnodes, I
think that should trump any entrynodes or exitnodes you set. And if you
exclude everything that's possible, then you fail to make a circuit. It's
what you asked for. That's pretty much what I built in 0.2.2.7-alpha
(though I haven't finished the "excluding" part).

The part where StrictNodes should come up is when your Tor wants to
do something that we the Tor designers consider non-dangerous, yet you
still want to exclude the node Tor wants to use. Examples here include:

* Your Tor hidden service wants to reach a rendezvous point that a
client picked, to establish a connection to the client.
* Tor wants to publish its hidden service descriptor to the appropriate
HSDir relay, or fetch a hidden service descriptor from the appropriate
HSDir relay.
* Your Tor relay tries to publish a server descriptor to an authority
that you've excluded.

In short, I suggest that we should come up with a reasonable thing for
EntryNodes, ExitNodes, ExcludeNodes, and ExcludeExitNodes to do, such that
a reasonable user would get the behavior they would expect. And we should
have that be the default behavior (i.e. the behavior when StrictNodes is
0). And for the people who say "omg my Tor made a circuit that reached
this relay that I excluded wtf conspiracy", we let them set StrictNodes
and tell them they get to keep both pieces when their Tor behavior breaks
in some way.

There are still some controversial decisions to be made, though. For
example:

* What if Tor as a client wants to reach an introduction point for
a hidden service that the user asked to visit, but that intro point
is in excludenodes? The complex answer is to avoid the excluded intro
points unless that would exclude all of them, in which case, either fail
if StrictNodes is 1 else choose one like normal. The simpler answer
coding-wise is to ignore ExcludeNodes when choosing which intro point
to contact, and then either fail or allow it depending on the value
of StrictNodes. I'm inclined toward the simpler answer here, because I
don't think you should care whether your Tor reaches some relay at the
end of your circuit, if that's all Tor uses the circuit for.

* If you ExcludeNodes a relay but your Tor wants to ask it for directory
information, do we? I think the answer is no, a) because there's a
plausible client-enumeration attack a reasonable person could to be
trying to avoid by excluding it, and b) because the information should be
available from a different relay. And if you exclude all the authorities
and then fail to bootstrap, that's your own fault.

* How do we handle foo.exit when AllowDotExit is 1 but foo is in
ExcludeNodes or ExcludeExitNodes? The user both asked for it and asked
for not it. We could allow it if StrictNodes is 0, and refuse it if
StrictNodes is 1. I'm inclined to just refuse it in both cases, to make
the code (and spec) simpler.

* If we would _implicitly_ append the .exit because of exit enclaving,
but the exit is excluded, then we definitely shouldn't append it.

What other scenarios have I missed?

&gt;    - If "ExitNodes" is provided, then every request requires an exit  
&gt; node on

More precisely, "then every exit circuit requires"

&gt;    - When any of the *Nodes settings are changed, all circuits are  
&gt; expired
&gt;      immediately, to prevent a situation where a previously built  
&gt; circuit
&gt;      is used even though some of its nodes are now excluded.

Right, we do that as of 0.2.2.7-alpha.

&gt; Compatibility:
&gt;
&gt;    The old Strict*Nodes options are deprecated, and the StrictNodes  
&gt; option is
&gt;    new. Tor users may need to update their configuration file.

In the current (0.2.2.x) behavior, setting any Strict*Nodes is an alias
for setting StrictNodes. That way we don't break torrc files as people
upgrade. (Periodically we run into folks like the Ubuntu people who want
us to promise that if they give a newer version to their existing users,
it won't break existing config files.)

--Roger

</body></email><email><emailId>20100310093206</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2010-03-10 09:32:06-0400</timestampReceived><subject>Re: Proposal idea: User path configuration</subject><body>

Hi,

On Wed, Mar 10, 2010 at 5:32 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt; I think we should work out the situations where strictnodes is needed,
&gt; and the situations where we want to honor the config option even without
&gt; strictnodes 1.
&gt;
&gt; For example, if you set entrynodes or exitnodes, then imo you should get
&gt; one of the nodes you specified, or fail if none work. You asked for it,
&gt; you get it. Similarly, if you set Excludenodes or excludeexitnodes, I
&gt; think that should trump any entrynodes or exitnodes you set. And if you
&gt; exclude everything that's possible, then you fail to make a circuit. It's
&gt; what you asked for. That's pretty much what I built in 0.2.2.7-alpha
&gt; (though I haven't finished the "excluding" part).

This sounds like we rather want an option "RelaxStrictNodesOnConflict
1" for the user to explicitly relax the rules if he knows what he's
doing. Default should be 0. At least I find that more intuitive.

Best,
C
</body></email><email><emailId>20100310154953</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2010-03-10 15:49:53-0400</timestampReceived><subject>Re: Proposal idea: User path configuration</subject><body>

On Wed, Mar 10, 2010 at 10:32:06AM +0100, Christian Fromme wrote:
&gt; Hi,
&gt; 
&gt; On Wed, Mar 10, 2010 at 5:32 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; 
&gt; &gt; I think we should work out the situations where strictnodes is needed,
&gt; &gt; and the situations where we want to honor the config option even without
&gt; &gt; strictnodes 1.
&gt; &gt;
&gt; &gt; For example, if you set entrynodes or exitnodes, then imo you should get
&gt; &gt; one of the nodes you specified, or fail if none work. You asked for it,
&gt; &gt; you get it. Similarly, if you set Excludenodes or excludeexitnodes, I
&gt; &gt; think that should trump any entrynodes or exitnodes you set. And if you
&gt; &gt; exclude everything that's possible, then you fail to make a circuit. It's
&gt; &gt; what you asked for. That's pretty much what I built in 0.2.2.7-alpha
&gt; &gt; (though I haven't finished the "excluding" part).
&gt; 
&gt; This sounds like we rather want an option "RelaxStrictNodesOnConflict
&gt; 1" for the user to explicitly relax the rules if he knows what he's
&gt; doing. Default should be 0. At least I find that more intuitive.
&gt; 

OK too many layer for me: Do we really now have in any version of
code, spec, or proposal
excludenodes, excludeexitnodes, etc. plus strictnodes plus
relaxstricnodesonconflict as options that can take values or be set?
Woah and Whoa.

I would want the default to be to fail safe without second-guessing
the user. Some of that was reflected in what Roger said, but then he
seemed to take it back in places. By "fail safe" here I mean that if
you say don't go there, then you don't go there no matter what.
Having the default be
I-don't-want-to-do-that-but-if-I-can't-make-a-circuit-then-screw-it
seems like really bad semantics to me. It might mean less frequent
shooting oneself in the foot by semicompetents, but it probably also
means more shooting in the foot when it really matters, especially by
someone who (OK failed to RTFM, but) thinks that excludenodes means
exclude nodes, not exclude nodes unless you think it would be better
if I didn't. Something that means what it says without reading the
documentation makes more sense to me.

I know I'm jumping in without looking, so apologies if my suggestions
are obviated by something said earlier/elsewhere but what about having
just strictexcludenodes and preferredexcludenodes or some such (plus
similar for entry and exits)? Strict would trump everything.
preferredexcludenodes would try to follow preferences but would
reflect the best guess reasonable behavior set by the developers as
you have been discussing. There is then no simple excludenodes, people
need to pick one (or possibly both) and then get what they ask for.
I could suggest even more to this but I don't want to get into some
elaborate access control language. I think you were starting down
that road and this is simpler. Please feel free to show me why I'm
being an idiot.

I should admit that I'm also thinking forward to a time when trust is
part of Tor's routing so that we are in no position to claim to know
which nodes are safe for a given client. But I think the points hold
right now as well.

HTH,
Paul
</body></email><email><emailId>20100310200936</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-03-10 20:09:36-0400</timestampReceived><subject>Re: Proposal idea: User path configuration</subject><body>


On Mar 10, 2010, at 5:32 AM, Roger Dingledine wrote:

&gt; On Thu, Mar 04, 2010 at 04:24:30AM +0100, Sebastian Hahn wrote:
&gt;&gt;   Users can alter the default behavior for path selection with
&gt;&gt; configuration
&gt;&gt;   options. In case of conflicts (excluding and requiring the same  
&gt;&gt; node)
&gt;&gt; the
&gt;&gt;   "StrictNodes" option is used to determine behaviour. If a nodes is
&gt;&gt; both
&gt;&gt;   excluded and required via a configuration option, the exclusion  
&gt;&gt; takes
&gt;&gt;   preference.
&gt;
&gt; I think we should work out the situations where strictnodes is needed,
&gt; and the situations where we want to honor the config option even  
&gt; without
&gt; strictnodes 1.
&gt;
&gt; For example, if you set entrynodes or exitnodes, then imo you should  
&gt; get
&gt; one of the nodes you specified, or fail if none work. You asked for  
&gt; it,
&gt; you get it. Similarly, if you set Excludenodes or excludeexitnodes, I
&gt; think that should trump any entrynodes or exitnodes you set. And if  
&gt; you
&gt; exclude everything that's possible, then you fail to make a circuit.  
&gt; It's
&gt; what you asked for. That's pretty much what I built in 0.2.2.7-alpha
&gt; (though I haven't finished the "excluding" part).

I think there's a misunderstanding here. I think we should make it  
clear that
excluding trumps including, but it would be sad if we end up in a  
state where
people cannot say "ExcludeExitNodes xy, y, z" and still have their  
hidden
services work. This seems to be what you're trying to say below, and I  
had
tried to capture it in my spec addition. "require" above is meant to  
mean
"Tor requires this node because it is an intro point and all other  
intro points
are down", for example, not that someone used ExcludeNodes and  
EntryNodes
with overlapping nodes, for example.

So to make it clear, I want StrictNodes to only be considered at all  
when
we have a special case for a non-exit circuit.

&gt; * What if Tor as a client wants to reach an introduction point for
&gt; a hidden service that the user asked to visit, but that intro point
&gt; is in excludenodes? The complex answer is to avoid the excluded intro
&gt; points unless that would exclude all of them, in which case, either  
&gt; fail
&gt; if StrictNodes is 1 else choose one like normal. The simpler answer
&gt; coding-wise is to ignore ExcludeNodes when choosing which intro point
&gt; to contact, and then either fail or allow it depending on the value
&gt; of StrictNodes. I'm inclined toward the simpler answer here, because I
&gt; don't think you should care whether your Tor reaches some relay at the
&gt; end of your circuit, if that's all Tor uses the circuit for.

I don't think this is so controversial. We should do the complicated  
thing,
at least according to how I wanted the spec change to be interpreted.

&gt; * If you ExcludeNodes a relay but your Tor wants to ask it for  
&gt; directory
&gt; information, do we? I think the answer is no, a) because there's a
&gt; plausible client-enumeration attack a reasonable person could to be
&gt; trying to avoid by excluding it, and b) because the information  
&gt; should be
&gt; available from a different relay. And if you exclude all the  
&gt; authorities
&gt; and then fail to bootstrap, that's your own fault.

No, we don't ask that node, once again unless all nodes are excluded and
strictnodes is set.

&gt; * How do we handle foo.exit when AllowDotExit is 1 but foo is in
&gt; ExcludeNodes or ExcludeExitNodes? The user both asked for it and asked
&gt; for not it. We could allow it if StrictNodes is 0, and refuse it if
&gt; StrictNodes is 1. I'm inclined to just refuse it in both cases, to  
&gt; make
&gt; the code (and spec) simpler.

Just refuse it always.

&gt; * If we would _implicitly_ append the .exit because of exit enclaving,
&gt; but the exit is excluded, then we definitely shouldn't append it.

Right.

&gt; What other scenarios have I missed?
&gt;
&gt;&gt;   - If "ExitNodes" is provided, then every request requires an exit
&gt;&gt; node on
&gt;
&gt; More precisely, "then every exit circuit requires"
&gt;
&gt;&gt;   - When any of the *Nodes settings are changed, all circuits are
&gt;&gt; expired
&gt;&gt;     immediately, to prevent a situation where a previously built
&gt;&gt; circuit
&gt;&gt;     is used even though some of its nodes are now excluded.
&gt;
&gt; Right, we do that as of 0.2.2.7-alpha.
&gt;
&gt;&gt; Compatibility:
&gt;&gt;
&gt;&gt;   The old Strict*Nodes options are deprecated, and the StrictNodes
&gt;&gt; option is
&gt;&gt;   new. Tor users may need to update their configuration file.
&gt;
&gt; In the current (0.2.2.x) behavior, setting any Strict*Nodes is an  
&gt; alias
&gt; for setting StrictNodes. That way we don't break torrc files as people
&gt; upgrade. (Periodically we run into folks like the Ubuntu people who  
&gt; want
&gt; us to promise that if they give a newer version to their existing  
&gt; users,
&gt; it won't break existing config files.)

I guess breaking the torrc format eventually isn't so bad, but doing  
this
kind of fallback and warning about it seems ok for now?

&gt; --Roger

Thanks
Sebastian
</body></email><email><emailId>20100328025847</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-03-28 02:58:47-0400</timestampReceived><subject>Re: Firefox privacy and Tor Browser</subject><body>

On Sat, Mar 27, 2010 at 8:52 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt; Thanks for your thoughts.  While I'm a big fan of request policy, it
&gt; 'breaks' the web for 95% of the users out there.  The
&gt; slightly-above-average web user still doesn't understand the web page
&gt; they are viewing is composed of many domains all serving up different
&gt; parts.  Having watched people use request policy for the first time,
&gt; they end up temporarily enabling everything, because the defaults are
&gt; still shocking to them.

I agree. Although I use RequestPolicy myself, it does take a lot of
patience to get to the point of being usable.

&gt; It is disabled, along with reported attack sites. It's disabled in
&gt; prefs.js.  See
&gt; https://svn.torproject.org/svn/torbrowser/trunk/build-scripts/config/prefs.js

Excellent! It's very reassuring to see that Tor developers are were
already aware of these issues. Very impressive!

I look forward to testing and using Tor Browser. Thanks again.

-- 
Mansour Moufid

</body></email><email><emailId>20100329091147</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-03-29 09:11:47-0400</timestampReceived><subject>Instructions for setting up relay descriptor database</subject><body>

Hi everyone,

as you may or may not know, we're currently putting some effort on
supporting PET researchers in learning more about the Tor network. As
part of these efforts, we want to give people more data and better
analysis tools.

One tool that we think researchers might find useful is a database of
Tor relay descriptors. People can use such a database to learn more
about the available relays, their stability, churn, and whatever metrics
they are interested in. We don't have a relay descriptor database with
access for everyone, mostly because people will want to customize the
database schema to better fit their needs (and because of the possible
security nightmare). But we now have step-by-step instructions for
setting up a basic database schema and importing relay descriptors into it:


https://gitweb.torproject.org//ernie.git?a=blob_plain;f=doc/manual.pdf;hb=HEAD

(If this link doesn't survive line breaking, go to our Git website at
https://gitweb.torproject.org/ , ernie.git, go to tree, doc, and select
manual.pdf .)

The tutorial for importing relay descriptors into a database can be
found on page 2, Section 2.2. (This may change in the future with more
content being added.)

It would be grand if people here could try out these instructions and
give me some comments for improving them. What is missing in the User's
Guide?

We're planning to send out these instructions, together with a
description of the data and tools that we have, to the people who have
been writing Tor papers in the past.

Thanks!
--Karsten
</body></email><email><emailId>20100331141202</emailId><senderName>CAv</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-03-31 14:12:02-0400</timestampReceived><subject>Re: Proposal idea: Automatically promoting Tor clients to nodes</subject><body>

Hi Steven,

I think related to this, possibly, is some way of differentiating 
circuits built to route traffic as a relay / bridge and circuits built 
to route traffic as a client ?
It would be good to be able to set hibernation properties to shut the 
server down, when its reached some limit, but still have the client 
functionality of the Vidalia bundle working.

This ability could dovetail nicely with your idea of auto promotion. It 
could mean that all Tor nodes become servers up to the limits specified 
in hibernation properties (if they are fast enough nodes) - which then 
saves on too much bandwidth being used when its operating as a relay or 
bridge.

I have a Tor server machine with hibernate properties set on it - which 
I cannot use as a client when Tor has hibernated, forcing me to have 
another machine that I use as a client to the Tor network, with which I 
browse the net day to day.

Cav.

On 31/03/2010 14:26, Steven J. Murdoch wrote:
&gt; I've been working recently on a proposal to increase the number of
&gt; bridges in the Tor network. It describes how Tor clients can
&gt; automatically become bridges, if they are considered to be
&gt; sufficiently reliable and the operator consents.
&gt; 
&gt; Comments and suggestions would be appreciated.
&gt; 
&gt; The current draft is below, and the latest version can be found here:
&gt; 
&gt; https://gitweb.torproject.org//sjm217/tor.git?a=blob;f=doc/spec/proposals/ideas/xxx-automatic-node-promotion.txt;hb=xxx-automatic-node-promotion
&gt;  
&gt; Filename: xxx-automatic-node-promotion.txt
&gt; Title: Automatically promoting Tor clients to nodes
&gt; Author: Steven Murdoch
&gt; Created: 12-Mar-2010
&gt; Status: Draft
&gt; Target:
&gt; 
&gt; 1. Overview
&gt; 
&gt; This proposal describes how Tor clients could determine when they
&gt; have sufficient bandwidth capacity and are sufficiently reliable to
&gt; become either bridges or Tor relays. When they meet this
&gt; criteria, they will automatically promote themselves, based on user
&gt; preferences. The proposal also defines the new controller messages
&gt; and options which will control this process.
&gt; 
&gt; Note that for the moment, only transitions between client and
&gt; bridge are being considered. Transitions to public relay will
&gt; be considered at a future date, but will use the same
&gt; infrastructure for measuring capacity and reliability.
&gt; 
&gt; 2. Motivation and history
&gt; 
&gt; Tor has a growing user-base and one of the major impediments to the
&gt; quality of service offered is the lack of network capacity. This is
&gt; particularly the case for bridges, because these are gradually
&gt; being blocked, and thus no longer of use to people within some
&gt; countries. By automatically promoting Tor clients to bridges, and
&gt; perhaps also to full public relays, this proposal aims to solve
&gt; these problems.
&gt; 
&gt; Only Tor clients which are sufficiently useful should be promoted,
&gt; and the process of determining usefulness should be performed
&gt; without reporting the existence of the client to the central
&gt; authorities. The criteria used for determining usefulness will be
&gt; in terms of bandwidth capacity and uptime, but parameters should be
&gt; specified in the directory consensus. State stored at the client
&gt; should be in no more detail than necessary, to prevent sensitive
&gt; information being recorded.
&gt; 
&gt; 3. Design
&gt; 
&gt; 3.x Opt-in state model
&gt; 
&gt; Tor can be in one of five node-promotion states:
&gt; 
&gt; - off (O): Currently a client, and will stay as such
&gt; - auto (A): Currently a client, but will consider promotion
&gt; - bridge (B): Currently a bridge, and will stay as such
&gt; - auto-bridge (AB): Currently a bridge, but will consider promotion
&gt; - relay (R): Currently a public relay, and will stay as such
&gt; 
&gt; The state can be fully controlled from the configuration file or
&gt; controller, but the normal state transitions are as follows:
&gt; 
&gt; Any state -&gt; off: User has opted out of node promotion
&gt; Off -&gt; any state: Only permitted with user consent
&gt; 
&gt; Auto -&gt; auto-bridge: Tor has detected that it is sufficiently
&gt; reliable to be a *bridge*
&gt; Auto -&gt; bridge: Tor has detected that it is sufficiently reliable
&gt; to be a *relay*, but the user has chosen to remain a *bridge*
&gt; Auto -&gt; relay: Tor has detected that it is sufficiently reliable
&gt; to be *relay*, and will skip being a *bridge*
&gt; Auto-bridge -&gt; relay: Tor has detected that it is sufficiently
&gt; reliable to be a *relay*
&gt; 
&gt; Note that this model does not support automatic demotion. If this
&gt; is desirable, there should be some memory as to whether the
&gt; previous state was relay, bridge, or auto-bridge. Otherwise the
&gt; user may be prompted to become a relay, although he has opted to
&gt; only be a bridge.
&gt; 
&gt; 3.x User interaction policy
&gt; 
&gt; There are a variety of options in how to involve the user into the
&gt; decision as to whether and when to perform node promotion. The
&gt; choice also may be different when Tor is running from Vidalia (and
&gt; thus can readily prompt the user for information), and standalone
&gt; (where Tor can only log messages, which may or may not be read).
&gt; 
&gt; The option requiring minimal user interaction is to automatically
&gt; promote nodes according to reliability, and allow the user to opt
&gt; out, by changing settings in the configuration file or Vidalia user
&gt; interface.
&gt; 
&gt; Alternatively, if a user interface is available, Tor could prompt
&gt; the user when it detects that a transition is available, and allow
&gt; the user to choose which of the available options to select. If
&gt; Vidalia is not available, it still may be possible to solicit an
&gt; email address on install, and contact the operator to ask whether
&gt; a transition to bridge or relay is permitted.
&gt; 
&gt; Finally, Tor could by default not make any transition, and the user
&gt; would need to opt in by stating the maximum level (bridge or
&gt; relay) to which the node may automatically promote itself.
&gt; 
&gt; 3.x Performance monitoring model
&gt; 
&gt; To prevent a large number of clients activating as relays, but
&gt; being too unreliable to be useful, clients should measure their
&gt; performance. If this performance meets a parameterized acceptance
&gt; criteria, a client should consider promotion. To measure
&gt; reliability, this proposal adopts a simple user model:
&gt; 
&gt; - A user decides to use Tor at times which follow a Poisson
&gt; distribution
&gt; - At each time, the user will be happy if the bridge chosen has
&gt; adequate bandwidth and is reachable
&gt; - If the chosen bridge is down or slow too many times, the user
&gt; will consider Tor to be bad
&gt; 
&gt; If we additionally assume that the recent history of relay
&gt; performance matches the current performance, we can measure
&gt; reliability by simulating this simple user.
&gt; 
&gt; The following parameters are distributed to clients in the
&gt; directory consensus:
&gt; 
&gt; - min_bandwidth: Minimum self-measured bandwidth for a node to be
&gt; considered useful, in bytes per second
&gt; - check_period: How long, in seconds, to wait between checking
&gt; reachability and bandwidth (on average)
&gt; - num_samples: Number of recent samples to keep
&gt; - num_useful: Minimum number of recent samples where the node was
&gt; reachable and had at least min_bandwidth capacity, for a client
&gt; to consider promoting to a bridge
&gt; 
&gt; A different set of parameters may be used for considering when to
&gt; promote a bridge to a full relay, but this will be the subject of a
&gt; future revision of the proposal.
&gt; 
&gt; 3.x Performance monitoring algorithm
&gt; 
&gt; The simulation described above can be implemented as follows:
&gt; 
&gt; Every 60 seconds:
&gt; 1. Tor generates a random floating point number x in
&gt; the interval [0, 1).
&gt; 2. If x &gt; (1 / (check_period / 60)) GOTO end; otherwise:
&gt; 3. Tor sets the value last_check to the current_time (in seconds)
&gt; 4. Tor measures reachability
&gt; 5. If the client is reachable, Tor measures its bandwidth
&gt; 6. If the client is reachable and the bandwidth is &gt;=
&gt; min_bandwidth, the test has succeeded, otherwise it has failed.
&gt; 7. Tor adds the test result to the end of a ring-buffer containing
&gt; the last num_samples results: measurement_results
&gt; 8. Tor saves last_check and measurements_results to disk
&gt; 9. If the length of measurements_results == num_samples and
&gt; the number of successes &gt;= num_useful, Tor should consider
&gt; promotion to a bridge
&gt; end.
&gt; 
&gt; When Tor starts, it must fill in the samples for which it was not
&gt; running. This can only happen once the consensus has downloaded,
&gt; because the value of check_period is needed.
&gt; 
&gt; 1. Tor generates a random number y from the Poisson distribution [1]
&gt; with lambda = (current_time - last_check) * (1 / check_period)
&gt; 2. Tor sets the value last_check to the current_time (in seconds)	
&gt; 3. Add y test failures to the ring buffer measurements_results
&gt; 4. Tor saves last_check and measurements_results to disk
&gt; 
&gt; In this way, a Tor client will measure its bandwidth and
&gt; reachability every check_period seconds, on average. Provided
&gt; check_period is sufficiently greater than a minute (say, at least an
&gt; hour), the times of check will follow a Poisson distribution. [2]
&gt; 
&gt; While this does require that Tor does record the state of a client
&gt; over time, this does not leak much information. Only a binary
&gt; reachable/non-reachable is stored, and the timing of samples becomes
&gt; increasingly fuzzy as the data becomes less recent.
&gt; 
&gt; On IP address changes, Tor should clear the ring-buffer, because
&gt; from the perspective of users with the old IP address, this node
&gt; might as well be a new one with no history. This policy may change
&gt; once we start allowing the bridge authority to hand out new IP
&gt; addresses given the fingerprint.
&gt; 
&gt; 3.x Bandwidth measurement
&gt; 
&gt; Tor needs to measure its bandwidth to test the usefulness as a
&gt; bridge. A non-intrusive way to do this would be to passively measure
&gt; the peak data transfer rate since the last reachability test. Once
&gt; this exceeds min_bandwidth, Tor can set a flag that this node
&gt; currently has sufficient bandwidth to pass the bandwidth component
&gt; of the upcoming performance measurement.
&gt; 
&gt; For the first version we may simply skip the bandwidth test,
&gt; because the existing reachability test sends 500 kB over several
&gt; circuits, and checks whether the node can transfer at least 50
&gt; kB/s.  This is probably good enough for a bridge, so this test
&gt; might be sufficient to record a success in the ring buffer.
&gt; 
&gt; 3.x New options
&gt; 
&gt; 3.x New controller message
&gt; 
&gt; 4. Migration plan
&gt; 
&gt; We should start by setting a high bandwidth and uptime requirement
&gt; in the consensus, so as to avoid overloading the bridge authority
&gt; with too many bridges. Once we are confident our systems can scale,
&gt; the criteria can be gradually shifted down to gain more bridges.
&gt; 
&gt; 5. Related proposals
&gt; 
&gt; 6. Open questions:
&gt; 
&gt; - What user interaction policy should we take?
&gt; 
&gt; - When (if ever) should we turn a relay into an exit relay?
&gt; 
&gt; - What should the rate limits be for auto-promoted bridges/relays?
&gt; Should we prompt the user for this?
&gt; 
&gt; - Perhaps the bridge authority should tell potential bridges
&gt; whether to enable themselves, by taking into account whether
&gt; their IP address is blocked
&gt; 
&gt; - How do we explain the possible risks of running a bridge/relay
&gt; * Use of bandwidth/congestion
&gt; * Publication of IP address
&gt; * Blocking from IRC (even for non-exit relays)
&gt; 
&gt; - What feedback should we give to bridge relays, to encourage then
&gt; e.g. number of recent users (what about reserve bridges)?
&gt; 
&gt; - Can clients back-off from doing these tests (yes, we should do
&gt; this)
&gt; 
&gt; [1] For algorithms to generate random numbers from the Poisson
&gt; distribution, see: \
&gt; http://en.wikipedia.org/wiki/Poisson_distribution#Generating_Poisson-distributed_random_variables
&gt;  [2] "The sample size n should be equal to or larger than 20 and the
&gt; probability of a single success, p, should be smaller than or equal to
&gt; .05. If n &gt;= 100, the approximation is excellent if np is also &lt;= 10."
&gt; http://www.itl.nist.gov/div898/handbook/pmc/section3/pmc331.htm (e-Handbook of \
&gt; Statistical Methods) 
&gt; 


</body></email><email><emailId>20100205065801</emailId><senderName>Shane Pope</senderName><senderEmail>shane.m.pope@gmail.com</senderEmail><timestampReceived>2010-02-05 06:58:01-0400</timestampReceived><subject>Re: Tor Port-Scanning Resistance Specification</subject><body>

The following How-To walks through setting up the Apache module as
well as the Tor server and client.
I didn't fully step through it yet, so there may be some steps
missing. Just let me know if anyone tries it out before I get around
to it.
The source and thesis (overview) are linked in it as well.

http://dl.dropbox.com/u/37735/index.html

This is very early development, while it works I would not deploy this
except for testing purposes. (In fact it will loop infinitely if you
get too many connections.)

Sorry this has taken so long, I recently started a working,
Cheers,
Shane
</body></email><email><emailId>20100205160835</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2010-02-05 16:08:35-0400</timestampReceived><subject>Re: Idea: Using the SPDY protocol to improve Tor performance</subject><body>

On Fri, Feb 5, 2010 at 11:03 AM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; I think there's a more generic mechanism lurking in the wings here.
&gt; SPDY is only one of several possible exit-side optimizing techniques
&gt; that might exist, and it seems overkill to add a new relay cell type
&gt; for each one we want to play with.  I'd suggest that instead, the
&gt; begin cell should tell the exit what kind of traffic transformation it
&gt; ought to perform, if any.  This could either be a new field in the
&gt; standard begin cell format, or it could be a new
&gt; RELAY_BEGIN_somethingorother cell type.

One thing to keep in mind: SPDY assumes that all clients support gzip
encoding so you will probably want to munge the Accept-Encoding header
accordingly.

Also, we haven't developed any SPDY proxies yet and haven't yet added
per-stream flow control to the protocol.


If you have any SPDY questions, please feel free to ask myself (I'm on
the SPDY team here at Google) or spdy-dev.


Cheers

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org

</body></email><email><emailId>20100214013622</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-14 01:36:22-0400</timestampReceived><subject>Re: Node-Weight Balancing Corrections</subject><body>


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; Future Work:
&gt;  [Node weight balancing case updates].

In my git branch of the implementation (in
mikeperry/consensus-bw-weights3), I've included some additional but
currently unused weights for weighting directory server traffic in
future consensus methods.

There are 8 new weights for this:

  Wgb - Weight for BEGIN_DIR-supporting Guard-flagged nodes
  Wmb - Weight for BEGIN_DIR-supporting non-flagged nodes
  Web - Weight for BEGIN_DIR-supporting Exit-flagged nodes
  Wdb - Weight for BEGIN_DIR-supporting Guard+Exit-flagged nodes

  Wbg - Weight for Guard+Exit-flagged nodes for BEGIN_DIR requests
  Wbm - Weight for Guard+Exit-flagged nodes for BEGIN_DIR requests
  Wbe - Weight for Guard+Exit-flagged nodes for BEGIN_DIR requests
  Wbd - Weight for Guard+Exit-flagged nodes for BEGIN_DIR requests

The first four weights are currently set to 1.0 by the current consensus
process, and the last four are set to their Wm* equivalents (to treat
directory requests as middle traffic).

However, we can use them in the future by changing the weight
calculation into a two step process:

First, calculate G, M, E, D, and T by reducing the bandwidth of nodes
with dir_port != 0 by the average dirport traffic consumption
percentage that Karsten measures as part of his statistics gathering.
This reduction is represented in the Wgb, Wmb, Web, and Wdb weights,
and these would be set to his measured hardcoded values before the G,
M, E, D and T computation for purposes of doing this computation.

If this places us into a scarcity case that prevents network balancing
(such as Case 2a or 3a), we recompute G, M, E, D, and T without
reducing the bandwidths of dirport enabled nodes for the scarce class
by setting its corresponding weight to 0, and then adjust the above
weights accordingly to compensate for this.


For example, if Exits are scarce, and we know that dirport traffic
takes up approximately (1-Wgb) of Guard, (1-Wmb) of Middle, (1-Web) of
Exit, and (1-Wdb) of Dual dirport bandwidth on average from Karsten's
measurements, we know that the total dirport (BEGIN_DIR) traffic is
then:

   (1-Wgb)*Gb + (1-Wmb)*Mb + (1-Web)*Eb + (1-Wdb)*Db = B

Where Gb, Mb, Eb, and Db are the total bandwidth of Guard, Middle,
Exit, and Dual flagged nodes that ALSO have their dir_port != 0.

If we then set Web=0 and Wdb=0 to shift dirport traffic away from our
scarce Exit-capable nodes, we need to come up with a delta weight w to
add to the other two weights:

   (1-(Wgb+w))*Gb + (1-(Wmb+w))*Mb = B

Solving for w:

   w =  (-B + Gb + Mb - Gb*Wgb - Mb*Wmb)/(Gb + Mb)

We then update Wgb and Wmb with this w to distribute the former Exit
and Dual-flagged dirport traffic among them, and then recompute G, M,
E, D, and T, determine the new scarcity case, and then compute the 7
original weights from the previous post as normal.

We then also publish:

  Wbg = Wbm = 1.0
  Wbe = Wbd = 0 

Along with:

  Web = Wdb = 1.0
  Wgb = Wgb_measured + w
  Wmb = Wmb_measured + w

Clients will then properly avoid the scarce Exit class for their
dirport node selection, and properly redistribute their requests
accordingly, with no additional change in client logic beyond what is
already in my branch.

Because of the complexity of this change, and because we do not yet
have statistics for the bandwidth consumption of dirport traffic in a
balanced network condition, we are not going to compute these weights
this way yet until the network rebalances and stabilizes again.

In the meantime, it is likely that the bandwidth scanners will correct
for any misbalancing caused by treating these requests as middle
traffic, but using this method prevents us from having more control
over our specific scarcity case.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100214022536</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-02-14 02:25:36-0400</timestampReceived><subject>Hardware Crypto acceleration?</subject><body>


Hi,

I've been playing around with a VPN1401 PCI card[0]. This card ships
with the the Hi/Fn 7955 chipset (or is it properly called a hifn 7955?).

I want to use it to offload AES and SHA computation. Additionally, I
want it to seed my software random number generator. I specifically want
to ensure that Tor doesn't drain the entropy pool on my machine.

I have Tor configured as a normal client and I have added one line to my
torrc file:
HardwareAccel 1

I don't have any dynamic engines enabled (AccelName is unset). I'm not
sure what dynamic engines I might need. I think there are patches to
make this possible [1] but I've not used them.

When I start Tor with debug level logging, I see the relevant following
events:
Feb 13 18:04:04.681 [info] crypto_global_init(): Initializing OpenSSL
engine support.
Feb 13 18:04:04.681 [info] Using default implementation for RSA
Feb 13 18:04:04.681 [info] Using default implementation for DH
Feb 13 18:04:04.681 [info] Using default implementation for RAND
Feb 13 18:04:04.681 [info] Using default implementation for SHA1
Feb 13 18:04:04.681 [info] Using default implementation for 3DES
Feb 13 18:04:04.681 [info] Using default implementation for AES
Feb 13 18:04:04.681 [info] crypto_seed_rng(): Seeding RNG from
"/dev/urandom"

I'm running a Debian Lenny (current Stable) machine for my tests. It
appears to work out of the box for some software (eg: kernel CryptoAPI)
but I don't think it's working for Tor. I had to install the 'rng-utils'
package to feed the hardware RNG into my entropy pool. It appears to be
seeding my random number generator and so half of my requirements are
resolved.

Any idea on how to get OpenSSL to use this hardware for AES and SHA
acceleration?

Here are the relevant lines in my dmesg log from the kernel module loading:
[   19.819528] hifn795x: assuming 66MHz clock speed, override with
hifn_pll_ref=ext&lt;frequency&gt;
[   20.032612] hifn0: AES 128 ECB test has been successfully passed.
[   20.036288] Driver for HIFN 795x crypto accelerator chip has been
successfully registered.

Here are the relevant modules:
$ lsmod|grep hifn
hifn_795x              23812  0
rng_core                8968  2 hifn_795x
des_generic            21376  1 hifn_795x
crypto_blkcipher       21636  6 ecb,hifn_795x,cbc,dm_crypt

Here's what /proc/crypto reports:
~$ cat /proc/crypto
name         : ecb(arc4)
driver       : ecb(arc4-generic)
module       : ecb
priority     : 0
refcnt       : 3
type         : blkcipher
blocksize    : 1
min keysize  : 1
max keysize  : 256
ivsize       : 0
geniv        : &lt;default&gt;

name         : arc4
driver       : arc4-generic
module       : arc4
priority     : 0
refcnt       : 3
type         : cipher
blocksize    : 1
min keysize  : 1
max keysize  : 256

name         : ofb(aes)
driver       : hifn-aes
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 16
min keysize  : 16
max keysize  : 32
ivsize       : 0
geniv        : &lt;default&gt;

name         : cfb(aes)
driver       : hifn-aes
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 16
min keysize  : 16
max keysize  : 32
ivsize       : 0
geniv        : &lt;default&gt;

name         : cbc(aes)
driver       : hifn-aes
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 16
min keysize  : 16
max keysize  : 32
ivsize       : 0
geniv        : &lt;default&gt;

name         : ecb(aes)
driver       : hifn-aes
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 16
min keysize  : 16
max keysize  : 32
ivsize       : 0
geniv        : &lt;default&gt;

name         : ecb(des)
driver       : hifn-des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 8
max keysize  : 8
ivsize       : 0
geniv        : &lt;default&gt;

name         : cbc(des)
driver       : hifn-des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 8
max keysize  : 8
ivsize       : 0
geniv        : &lt;default&gt;

name         : ofb(des)
driver       : hifn-des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 8
max keysize  : 8
ivsize       : 0
geniv        : &lt;default&gt;

name         : cfb(des)
driver       : hifn-des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 8
max keysize  : 8
ivsize       : 0
geniv        : &lt;default&gt;

name         : ecb(des3_ede)
driver       : hifn-3des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 24
max keysize  : 24
ivsize       : 0
geniv        : &lt;default&gt;

name         : cbc(des3_ede)
driver       : hifn-3des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 24
max keysize  : 24
ivsize       : 0
geniv        : &lt;default&gt;

name         : ofb(des3_ede)
driver       : hifn-3des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 24
max keysize  : 24
ivsize       : 0
geniv        : &lt;default&gt;

name         : cfb(des3_ede)
driver       : hifn-3des
module       : hifn_795x
priority     : 300
refcnt       : 1
type         : ablkcipher
async        : yes
blocksize    : 8
min keysize  : 24
max keysize  : 24
ivsize       : 0
geniv        : &lt;default&gt;

name         : des3_ede
driver       : des3_ede-generic
module       : des_generic
priority     : 0
refcnt       : 1
type         : cipher
blocksize    : 8
min keysize  : 24
max keysize  : 24

name         : des
driver       : des-generic
module       : des_generic
priority     : 0
refcnt       : 1
type         : cipher
blocksize    : 8
min keysize  : 8
max keysize  : 8

name         : sha256
driver       : sha256-generic
module       : sha256_generic
priority     : 0
refcnt       : 1
type         : digest
blocksize    : 64
digestsize   : 32

name         : sha224
driver       : sha224-generic
module       : sha256_generic
priority     : 0
refcnt       : 1
type         : digest
blocksize    : 64
digestsize   : 28

name         : cbc(aes)
driver       : cbc(aes-asm)
module       : cbc
priority     : 200
refcnt       : 2
type         : blkcipher
blocksize    : 16
min keysize  : 16
max keysize  : 32
ivsize       : 16
geniv        : &lt;default&gt;

name         : aes
driver       : aes-asm
module       : aes_x86_64
priority     : 200
refcnt       : 3
type         : cipher
blocksize    : 16
min keysize  : 16
max keysize  : 32

name         : aes
driver       : aes-generic
module       : aes_generic
priority     : 100
refcnt       : 1
type         : cipher
blocksize    : 16
min keysize  : 16
max keysize  : 32

name         : md5
driver       : md5-generic
module       : kernel
priority     : 0
refcnt       : 1
type         : digest
blocksize    : 64
digestsize   : 16

It seems clear that some of the kernel CryptoAPI is now backed by the
hardware. It seems less clear on how to get userspace programs like Tor
to use the hardware.

Thoughts?

Best,
Jacob

[0] http://www.soekris.com/vpn1401.htm
[1] http://www.logix.cz/michal/devel/cryptodev/


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100215200554</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-02-15 20:05:54-0400</timestampReceived><subject>Re: Bridge stability</subject><body>

Hey Roger,

On Feb 15, 2010, at 8:14 PM, Roger Dingledine wrote:
&gt; On Mon, Feb 15, 2010 at 09:29:19AM +0100, Karsten Loesing wrote:
&gt; &gt; I should state that there is one major inaccuracy in the analysis:
&gt; &gt; Bridges that change their IP address are not reachable by their
&gt; &gt; clients anymore. In theory, clients are able to download updated bridge
&gt; &gt; descriptors from the bridge authority to learn about new IP addresses,
&gt; &gt; but this functionality is not implemented yet. However, I cannot take
&gt; &gt; changing IP addresses into account for this analysis, because I removed
&gt; &gt; the IP addresses when sanitizing the bridge descriptors. Hah! Maybe we
&gt; &gt; should just fix this problem by implementing the missing functionality.
&gt; 
&gt; This part is worrisome. That means your analysis is assuming the bridges
&gt; always stick to the same IP address, right? It's worth trying to do
&gt; the analysis when we take into account that some bridges are on highly
&gt; dynamic IPs (e.g. daily).
&gt; 
&gt; What's the process by which we sanitize them? It seems that a fine
&gt; solution would be to hash the IP addresses keyed with a secret that
&gt; remains constant across the hashes. So you could tell if the IP addresses
&gt; are the same without being able to tell what they are. The main challenge
&gt; there is keeping the secret somewhere secret in between batches (and
&gt; maybe rotating the secret monthly, for some level of forward secrecy).

Yes, we can do something like that. I assume that it'll keep my server busy for a day \
or two to parse all the descriptors once more. But I can do that.

Instead of the secret input to the hash function, how about we concatenate bridge \
identity and IP address as input? Note that we don't put the bridge identity in the \
sanitized descriptor, but only its hash. That way we'd avoid using a secret that \
we'll lose or forget anyway and have something reproducible. To be precise, this is \
what I have in mind:

  sanitized bridge identity = H(bridge identity)

  sanitized IP address = H(bridge identity + IP address)[:4]

Note that only the first 4 bytes of the result are used, because the result is \
written as the bridge's IP address, covering the entire range between 0.0.0.0 and \
255.255.255.255. Of course, there's a reasonable chance for collisions for a bridge \
identity with two different IP addresses. But I want the network status to contain \
all relevant information rather than re-assembling network status entries and bridge \
descriptors (which could contain more information in their contact line). Are there \
better ways to add 20 bytes to the network status? We might still add the full hash \
to the descriptor's contact line.

Thanks,
--Karsten


</body></email><email><emailId>20100217145007</emailId><senderName>"Wesley W. Terpstra"</senderName><senderEmail>wesley@terpstra.ca</senderEmail><timestampReceived>2010-02-17 14:50:07-0400</timestampReceived><subject>torify and dns via nsswitch - PATCH</subject><body>


I'm not certain who maintains the torify tsocks wrapper, so apologies
if this is misdirected.

The use of torify with programs like wget is quite nice. However, it
leaks dns requests. One approach I hacked together is to create an
nsswitch.conf compatible module that performs DNS lookups using Tor
whenever an environment variable TOR_NSS is set. This way the torify
wrapper just sets the TOR_NSS and tsocks environement variables and
things work (TM).

I understand that tsocks can redirect dns requests to tcp and then
redirect these out to Tor. This approach suffers from a few problems
AFAICS:
1. You need a list of DNS servers that support open recursive requests
OR you need to perform the entire lookup starting from route servers
over Tor (ie: very slow)
2. Tor doesn't see the DNS lookup and so gives warnings about dns leakage
3. Tor doesn't see the DNS lookup so the caching + new identity stuff
doesn't work
4. It's inappropriate to do this for any application other that Tor,
and so isn't included in the default debian build of tsocks.

Using my nsswitch module it is as though every time gethostbyname is
run, tor-resolve gets called. This means:
1. DNS exits from a Tor node which can use it's local DNS -&gt; faster
2. Tor has full control over the DNS cache / etc

There is a downside: installing the module into nsswitch.conf means
that every program that uses gethostbyname will need to load
libtor_nss.so.2 (though they won't use it). However, they already need
to load 4+ such libraries on a typical debian system and
libtor_nss.so.2 is especially small.

How it works: nsswitch.conf describes what steps to take when
resolving a host name. By putting a Tor specific module before dns, we
can capture any calls to gethostbyname that would otherwise leak. The
module provides gethostbyname by using the SOCKS5 RESOLVE capability
of the Tor daemon.

Issues: I didn't implement reverse DNS,  but this would be easy to add.

I hereby place this code in the public domain. If it's useful to the
Tor project, do with it whatever you like. I'm open to suggestions
about ways to improve it.

["nss-tor-0.1.tar.gz" (application/x-gzip)]

</body></email><email><emailId>20100221051408</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-02-21 05:14:08-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>

On Sat, Feb 20, 2010 at 6:27 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; Ok, consensus-bw-weights4 should have fixes for these, with the
&gt; exception of the XXX in find_start_of_next_routerstatus() that you
&gt; mention. That XXX actually is for the old code, which seemed to
&gt; preserve the \n for some reason there.
&gt;
&gt; Nick, do you think you could have a look at that function, and see
&gt; what should be done there? It looks like it was possibly a bug or just
&gt; bad behavior to me.

I think it's a bug, but a harmless one.  If we fix it, we need to make
sure that everything that calls find_start_of_next_routerstatus()
works fine if it gets the actual start of the routerstatus, not one
character before.  This means at least that we'd need to test parsing
consensuses and v2 networkstatus documents.

Or for stability we could convert the XXX into an explanatory comment,
but leave it alone otherwise.

&gt; In general, I'd also like someone to verify that adding the new
&gt; 'directory-footer' line and 'bandwidth-weights' line to the consensus
&gt; won't break existing clients. It looks to me like the parsing code is
&gt; written to handle the addition of arbitrary new lines in the
&gt; consensus, but I'd like some confirmation of that. For example, is it
&gt; possible that the last routerstatus document in the consensus might
&gt; get silently rejected due to the parser finding the extra lines there?
&gt; routerstatus_parse_entry_from_string() looks like it might be OK with
&gt; that to me, but I'm not familiar with all of the bits of the parsing
&gt; code.

According to the spec:

 When interpreting a Document, software MUST ignore any KeywordLine that
 starts with a keyword it doesn't recognize; future implementations MUST NOT
 require current clients to understand any KeywordLine not currently
 described.

All the parsing code goes through get_next_token(), which translates
unrecognized keywords into K_OPT, which is ignored everywhere.
Specifically, nothing in routerstatus_parse_entry_from_string does
anything to reject routerstatuses with extraneous entries.

--
Nick
</body></email><email><emailId>20100221235639</emailId><senderName>"sird () rckc ! at"</senderName><senderEmail>sird@rckc.at</senderEmail><timestampReceived>2010-02-21 23:56:39-0400</timestampReceived><subject>enabling bridges on NATed clients</subject><body>

What do you guys think about using http://samy.pl/pwnat/ idea to allow
people that want to run a bridge behind a NAT? Maybe enhance the
discovery protocol to this kind of stuff.

I say this because I think that people in china need bridges, and this
kind of solutions may dramatically help in that, specially because now
they can't just send reset packets in the discovery part of the
protocol.

Anyway, it's just an idea, what do you think? is it usable?

Greetings!!

</body></email><email><emailId>20100222105647</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-02-22 10:56:47-0400</timestampReceived><subject>Re: TOR -Token Bucket implementation</subject><body>

On Mon, Feb 22, 2010 at 01:29:39AM -0800, rkapoor@ucsd.edu wrote:
&gt;  I am new to the TOR community. While reading through the tor performance
&gt; issues, I found out that TOR uses token bucket implementation for rate
&gt; limiting.
&gt; 
&gt; I am planning to implement Hierarchical token bucket as part of my class
&gt; project
&gt; in TOR.
&gt; 
&gt; Seeking feedback/opinions from tor community regarding the same.

What did you have in mind? Note that we have a global token bucket
for reads, another for writes, plus read/write buckets for "relayed"
traffic, and then yet another set of read/write buckets for each TLS
connection. So in a sense there is some hierarchy already.

--Roger

</body></email><email><emailId>20100222172535</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-02-22 17:25:35-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

On Mon, Feb 22, 2010 at 1:26 AM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
 [...]
&gt; Just wanted to let you know that this will change how we need to deal
&gt; with weighting begindir requests. Right now the check done by clients
&gt; is to verify dir_port != 0. This means that if we want clients to be
&gt; able to easily adapt to new directory request weights yet still handle
&gt; reweighting properly when everyone is a dir mirror, we need to signal
&gt; this by specifying some magic dirport number in the consensus.  That,
&gt; or we need a different, yet backwards compatible flag in the check.
&gt; V2Dir seems the wrong one, but it is all we have now.
&gt;
&gt; http://archives.seul.org/or/dev/Jan-2010/msg00019.html
&gt;
&gt; Thoughts?

We should (AFTER writing a proposal!) have clients accept a DirCache
flag in consensus "s" lines, and treat having the dircache flag set as
if the server had a nonzero dirport.

We don't need to actually generate the DirCache flag in a big hurry,
though, so long as clients start accepting it now.

-- 
Nick

</body></email><email><emailId>20100223210226</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-02-23 21:02:26-0400</timestampReceived><subject>Re: [PATCH] contrib/tor-exit-notice.html url fix</subject><body>


On Feb 23, 2010, at 7:11 AM, Christian Kujau wrote:
&gt; After playing around with a newer version of "tidy" and a lot of editing,
&gt; the document appears to be valid now. As the patch is rather big now (due
&gt; to line breaks, the content did not change), I've attached the .html as 
&gt; well.
&gt; 
&gt; Thanks,
&gt; Christian.

Great, I've put your patch up for review and merge by Nick or Roger. See the
first two commits on
http://gitweb.torproject.org//sebastian/tor.git?a=shortlog;h=refs/heads/exitnotice
to check it out.

Thanks for fixing the xhtml issues so quickly, I tested it on a relay and it works
nicely. Also, the filesize isn't inflated by much, so really good job

Sebastian



</body></email><email><emailId>20100102190844</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-01-02 19:08:44-0400</timestampReceived><subject>Re: Thoughts on future upnp/nat-pmp support in Tor</subject><body>

On Sat, Jan 02, 2010 at 05:01:19PM +0100, Jacob Appelbaum wrote:
&gt; Roger thinks that it's probably best to fork a (UPnP/NAT-PMP) project,
&gt; include it the Tor source and include it in the main Tor binary. If a
&gt; user has the local library (and it's newer than the included code),
&gt; we'll use their local library. This is similar to what Vidalia is doing
&gt; for UPnP support. However, Vidalia is lacking NAT-PMP support and of
&gt; course Vidalia is obviously external to the Tor binary itself. I think
&gt; adding UPnP/NAT-PMP to Tor may be the best way forward with some caveats.

Actually, Roger thinks we'll be sad long-term if we ship with a copy of
the library but elect to use the local one "sometimes". We should either
link in the local library package, and package the software for all our
target platforms, or include a copy of the source ourselves and always
use that. Not both.

A combination will mean all the sadness of maintaining our own version
*plus* all the sadness of whatever versions are on our target platforms
already.

--Roger

</body></email><email><emailId>20100110230039</emailId><senderName>Lee Fisher</senderName><senderEmail>blibbet@gmail.com</senderEmail><timestampReceived>2010-01-10 23:00:39-0400</timestampReceived><subject>Re: GIT repository down?</subject><body>

http://archives.seul.org/or/talk/Jan-2010/msg00046.html

</body></email><email><emailId>20100119211834</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-01-19 21:18:34-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

On Tue, Jan 19, 2010 at 01:48:50PM -0500, Lexi Pimenidis wrote:
&gt; Just a minor thought: could an adversary learn some significant from the
&gt; atime/mtime/ctime of the file you store the information in? If so, it could
&gt; be nice to have that obscured, too :-)

This is the state file, so we store other things in it, including a
header like:

# Tor state file last generated on 2010-01-19 16:07:20 local time
# Other times below are in GMT

The state file gets written pretty frequently, especially for clients
now that mikeperry's new "circuitbuildtime" counting is in place.

So file properties shouldn't give much away about the timing of guard
selection -- but that's because mtime instead gives away roughly when
you last ran Tor (!).

I'm not sure it's worth going down the rabbit-hole to fix the "when did
you last run Tor" leak though.

--Roger

</body></email><email><emailId>20100124005845</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-01-24 00:58:45-0400</timestampReceived><subject>Re: Control Spec Addition First Draft</subject><body>

Hi all. This proposal doesn't seem to be going anywhere so thought I should
give it one last nudge before moving on to more worthwhile work. The issue's
sticking point seems to be a difference of opinion about what constitutes
relay evilness. Nick, Jake, and Sebastian all believe in a hard line stance
against any retrieval of connection information (netstat, lsof, etc). I
disagree, and think this is harmless unless stored or communicated. Unless
this can be resolved I think it's obvious the proposal isn't going anywhere.

Please note that I'm discussing relay to relay connections at the moment. If
we can't even agree on that then client and exit connections are a moot
point (and besides, I agree they should definitely be hidden from relay
operators - personally I think it's the responsibility of client
applications like vidalia and arm to scrub this data, but that's a different
discussion...).

Just to be clear I agree this proposal should be killed if it poses a threat
to Tor users. However, I don't believe it does and still have yet to hear an
example of any sort of threat it aggravates. Without that I'm a bit puzzled
at the source of objections. If the chief issue is legal or not wanting to
risk the appearance of supporting snooping that's fine (strikes me as
political posing if there's no actual benefits to users, but cest la vi).

Contrary to Nick's impression of my last response I'm not a Scooby-Doo
villain laughing maniacally as I scheme against Tor's users. I think
transient connection data is good for auditing and transparency, but welcome
correction if it's dangerous (before including it in arm I'd tried to ask
about risks and objections at Toorcamp but no one seemed interested...). As
for this proposal, I think it has some tasty benefits that could help arm
quite a bit including:
- better performance
- added information, juiciest from an auditing perspective being bandwidth
measurements and association of connections to circuits
- the ability to discern client and exit connections so they can be scrubbed
(I've tried correlating against consensus data to do this, but that was
pretty inaccurate)

My bias is toward safety for relay operators and I'm glad to see others
biased toward user privacy pushing back. Hopefully we'll be able to find
something acceptable to all parties concerned but if not it won't be the end
of the world. Cheers! -Damian

On Sun, Dec 20, 2009 at 2:24 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Hi Sebastian, thanks for the feedback!
&gt;
&gt;
&gt; As always, I'm very uncomfortable with giving away users'/destinations' ip
&gt;&gt; addresses or ports. I do realize that the same information can be obtained
&gt;&gt; from netstat and friends, but I still think we should actively discourage
&gt;&gt; the use and acquisition of this data. I realize that this is against the
&gt;&gt; intentions of this proposal, but I hope that it is still useful even without
&gt;&gt; client/destination identifying information.
&gt;&gt;
&gt;
&gt; Disagree for the following reasons:
&gt; - As mentioned on IRC: all Internet facing applications (browsers, email
&gt; clients, tor) are attack vectors for my system. Tor's developers are good,
&gt; but I'm not so sure that they're infallible (sorry Nick) and hence the
&gt; process can't be blindly trusted - that's why I think transparency is the
&gt; best way to go. With hundreds of connections to relatively unknown
&gt; destinations tor is already the bane of network based IDS so it would be
&gt; nice if we could provide some accounting to system administrators that tor
&gt; is behaving as it should. For instance say the tor process claims a big
&gt; outbound connection taking 90% of your bandwidth that can't be accounted for
&gt; as belonging to a circuit. If you aren't using it as a client that would
&gt; be... bad.
&gt;
&gt; - I agree that for correlation attacks this data is of concern in the event
&gt; that numerous relays store or share this information. However, for an
&gt; individual relay operator having this data shouldn't pose *any* threat to
&gt; tor users (if it does... we have an issue). From what I can tell this
&gt; proposal doesn't do anything that makes correlation attacks more dangerous
&gt; since netstat running in a cron job is all they need (assuming they own a
&gt; big chunk of the relays).
&gt;
&gt; - Tor was designed with a certain level of distrust of relays. Beyond that
&gt; the best we can do is discourage them from risky behaviour (ie, running
&gt; outdated versions, looking at exit traffic, sharing connection data, etc).
&gt; By including connection types controllers will have the opportunity to tell
&gt; relay operators "Oi! Please don't look at these exit connections unless you
&gt; have a damn good reason.". As it stands I don't have a way of telling them
&gt; apart, and hence can't even hide them by default.
&gt;
&gt; - As you mentioned we can't (and imho shouldn't) prevent relay operators
&gt; from seeing the connections made to/from their own system. This proposal
&gt; doesn't seem to exasperate any privacy issues while providing some nice
&gt; benefits (performance and some handy bits of extra data that'll make
&gt; security anomalies far easier to detect).
&gt;
&gt;
&gt; This is, I think, a misunderstanding of what a connection is. More below.
&gt;&gt;
&gt;
&gt; No, the hidden service question isn't. I'm assuming that when hosting
&gt; hidden services there's some connections dedicated to providing that
&gt; service. If so, a TYPE_FLAG should probably be included since they don't
&gt; really belong to any of the other groups. Changed proposal to include one
&gt; till someone tells me this is wrong.
&gt;
&gt; Here, the connection identity needs to either include the CIRC_ID, or this
&gt;&gt; is ambigious...
&gt;&gt;
&gt;
&gt; Thanks for the catch! Made the following three corrections:
&gt;
&gt; - Changed signature to "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" to
&gt; avoid ambiguity. I'm assuming that in general people will use the "conn/all"
&gt; to discover the circuit/connection ids (actually, can't think of a use for
&gt; getting a single connection - just including it to conform with other
&gt; control-spec GETINFO options).
&gt;
&gt; - Noted that more than two connections could have the same circuit ID in
&gt; the case of exit connections.
&gt;
&gt; - Including a L_PORT (local port) parameter - wasn't mentioned but
&gt; definitely an oversight.
&gt;
&gt;
&gt; These flags seem to be mostly redundant. Again, they don't necessarily work
&gt;&gt; because a connection can be used for many things. As for the Ee flag, I
&gt;&gt; don't really see the purpose, we certainly shouldn't look at exit traffic
&gt;&gt; going through the connection to decide if it is encrypted or not.
&gt;
&gt;
&gt; Yea, I wasn't sure if they should be like argument flags (given a default
&gt; if excluded) or always explicitly stated. Opted for the later since in
&gt; general explicit is better than implicit, and this way implementers (like
&gt; TorCtl) won't need to hard code any defaults. Both minor points and glad to
&gt; discuss more if people disagree.
&gt;
&gt; Yes, if this was only associated with a connection it wouldn't work, but
&gt; circuit/connection combinations should be unique so issue fixed there.
&gt;
&gt; As for the Ee flag I'm suspecting that it would have use for client
&gt; connections since any unencrypted traffic there is sniffable. This isn't
&gt; important to the use cases I care about so we can drop it if others think
&gt; it's a bad idea.
&gt;
&gt; Here's the revised proposal:
&gt;
&gt;
&gt; -------------------------------------------------------------------------------
&gt;
&gt;   "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the
&gt;     associated connection, formatted as:
&gt;       CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME
&gt; BUFF
&gt;
&gt;
&gt;     none of the parameters contain whitespace, and additional results must
&gt; be
&gt;     ignored to allow for future expansion. Parameters are defined as
&gt; follows:
&gt;       CONN_ID - Unique identifier associated with this connection.
&gt;       CIRC_ID - Unique identifier for the circuit this belongs to (0 if
&gt; this
&gt;         doesn't belong to any circuit). At most their may be two
&gt; connections
&gt;         (one inbound, one outbound) with any given CIRC_ID except in the
&gt; case
&gt;         of exit connections.
&gt;
&gt;       OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
&gt;       IP/PORT - IP address and port used by the associated connection.
&gt;       L_PORT - Local port used by the connection.
&gt;
&gt;       TYPE_FLAGS - Single character flags indicating directionality and
&gt; type
&gt;         of the connection (consists of one from each category, may become
&gt;         longer for future expansion).
&gt;           I: inbound, i: listening (unestablished inbound),
&gt;             O: outbound, o: unestablished outbound
&gt;           C: client related, R: relay related, X: control, H: hidden
&gt; service,
&gt;
&gt;             D: directory
&gt;           T: inter-tor connection, t: outside the tor network
&gt;           E: encrypted traffic, e: unencrypted traffic
&gt;         For instance, "IRtE" would indicate that this was an established
&gt;         1st-hop (or bridged) relay connection.
&gt;       READ/WRITE - Total bytes read/written over the life of this
&gt; connection.
&gt;       UPTIME - Time the connection's been established in seconds.
&gt;       BUFF - Bytes of data buffered for this relay connection.
&gt;
&gt;   "conn/all" -- Newline separated listing of all current connections.
&gt;
&gt;   "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt;     RelayBandwidthRate if set, otherwise BandwidthRate).
&gt;
&gt;   "info/relay/burst-limit" -- Effective relayed burst limit.
&gt;
&gt;   "info/relay/read-total" -- Total bytes relayed (download).
&gt;
&gt;   "info/relay/write-total" -- Total bytes relayed (upload).
&gt;
&gt;   "info/relay/buffer-cap" -- Maximum buffer size for relay connections.
&gt;
&gt;   "info/uptime-process" -- Total uptime of the tor process (in seconds).
&gt;
&gt;   "info/uptime-reset" -- Time since last reset (startup or sighup signal,
&gt; in
&gt;     seconds).
&gt;
&gt;   "info/descriptor-used" -- Count of file descriptors used.
&gt;
&gt;   "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt;
&gt;   "ns/authority" -- Router status info (v2 directory style) for all
&gt;     recognized directory authorities, joined by newlines.
&gt;
&gt;
&gt; -------------------------------------------------------------------------------
&gt;
&gt; Cheers! -Damian
&gt;
&gt;
&gt; On Sat, Dec 19, 2009 at 11:43 PM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;
&gt;&gt; Hi Damian,
&gt;&gt;
&gt;&gt; please find my comments inline below.
&gt;&gt;
&gt;&gt; On Dec 17, 2009, at 3:24 AM, Damian Johnson wrote:
&gt;&gt;
&gt;&gt; [snip]
&gt;&gt; &gt;  - Anything dangerous? Doubt it, but the bandwidth measurements should
&gt;&gt; probably
&gt;&gt; &gt;  either be rounded or provided occasionally (say, every second) to
&gt;&gt; address
&gt;&gt; &gt;  correlation attacks. I'm sure Sebastian will enthusiastically sink some
&gt;&gt; &gt;  paranoia into this later. ;)
&gt;&gt;
&gt;&gt; As always, I'm very uncomfortable with giving away users'/destinations' ip
&gt;&gt; addresses or ports. I do realize that the same information can be obtained
&gt;&gt; from netstat and friends, but I still think we should actively discourage
&gt;&gt; the use and acquisition of this data. I realize that this is against the
&gt;&gt; intentions of this proposal, but I hope that it is still useful even without
&gt;&gt; client/destination identifying information.
&gt;&gt;
&gt;&gt; &gt; - When hosting hidden services I'd imagine some connections are
&gt;&gt; dedicated to
&gt;&gt; &gt;  them. If so, lets add a flag to indicate them.
&gt;&gt;
&gt;&gt; This is, I think, a misunderstanding of what a connection is. More below.
&gt;&gt;
&gt;&gt; [snip]
&gt;&gt; &gt;    "conn/&lt;Connection identity&gt;" -- Provides entry for the associated
&gt;&gt; &gt;      connection, formatted as:
&gt;&gt; &gt;        CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF
&gt;&gt; &gt;
&gt;&gt; &gt;      none of the parameters contain whitespace, and additional results
&gt;&gt; must be
&gt;&gt; &gt;      ignored to allow for future expansion. Parameters are defined as
&gt;&gt; follows:
&gt;&gt; &gt;        CONN_ID - Unique identifier associated with this connection.
&gt;&gt; &gt;        CIRC_ID - Unique identifier for the circuit this belongs to (0 if
&gt;&gt; this
&gt;&gt; &gt;          doesn't belong to any circuit). At most their may be two
&gt;&gt; connections
&gt;&gt; &gt;          (one inbound, one outbound) with any given CIRC_ID.
&gt;&gt;
&gt;&gt; Here, the connection identity needs to either include the CIRC_ID, or this
&gt;&gt; is ambigious. Tor mutliplexes many circuits over the same connection, so
&gt;&gt; there is no way to infer the circuit id from a connection id. Also, for exit
&gt;&gt; connections, there may be more than two connections with the same circuit
&gt;&gt; id. What this means: We either want a seperate query to learn about
&gt;&gt; circuits, or we want the conn_id to list all the circuits that it has
&gt;&gt; attached, or we want to only allow queries of this kind when circ id and
&gt;&gt; conn id are both known to the controller
&gt;&gt;
&gt;&gt; &gt;        OR_ID - Relay fingerprint, 0 if connection doesn't belong to a
&gt;&gt; relay.
&gt;&gt; &gt;        IP/PORT - IP address and port used by the associated connection.
&gt;&gt; &gt;        TYPE_FLAGS - Single character flags indicating directionality and
&gt;&gt; type
&gt;&gt; &gt;          of the connection (consists of one from each category, may
&gt;&gt; become
&gt;&gt; &gt;          longer for future expansion).
&gt;&gt; &gt;            I: inbound, i: listening (unestablished inbound),
&gt;&gt; &gt;              O: outbound, o: unestablished outbound
&gt;&gt; &gt;            C: client related, R: relay related, X: control, D: directory
&gt;&gt; &gt;            T: inter-tor connection, t: outside the tor network
&gt;&gt; &gt;            E: encrypted traffic, e: unencrypted traffic
&gt;&gt; &gt;          For instance, "IRtE" would indicate that this was an
&gt;&gt; established
&gt;&gt; &gt;          1st-hop (or bridged) relay connection.
&gt;&gt;
&gt;&gt; These flags seem to be mostly redundant. Again, they don't necessarily
&gt;&gt; work because a connection can be used for many things. As for the Ee flag, I
&gt;&gt; don't really see the purpose, we certainly shouldn't look at exit traffic
&gt;&gt; going through the connection to decide if it is encrypted or not.
&gt;&gt;
&gt;&gt; &gt;        READ/WRITE - Total bytes read/written over the life of this
&gt;&gt; connection.
&gt;&gt; &gt;        UPTIME - Time the connection's been established in seconds.
&gt;&gt; &gt;        BUFF - Bytes of data buffered for this relay connection.
&gt;&gt; &gt;
&gt;&gt; &gt;    "conn/all" -- Newline separated listing of all current connections.
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt;&gt; &gt;      RelayBandwidthRate if set, otherwise BandwidthRate).
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/relay/burst-limit" -- Effective relayed burst limit.
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/relay/read-total" -- Total bytes relayed (download).
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/relay/write-total" -- Total bytes relayed (upload).
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/relay/buffer-cap" -- Maximum buffer size for relay connections.
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/uptime-process" -- Total uptime of the tor process (in
&gt;&gt; seconds).
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/uptime-reset" -- Time since last reset (startup or sighup
&gt;&gt; signal, in
&gt;&gt; &gt;      seconds).
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/descriptor-used" -- Count of file descriptors used.
&gt;&gt; &gt;
&gt;&gt; &gt;    "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt;&gt; &gt;
&gt;&gt; &gt;    "ns/authority" -- Router status info (v2 directory style) for all
&gt;&gt; &gt;      recognized directory authorities, joined by newlines.
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt; These all sound sane.
&gt;&gt;
&gt;&gt;
&gt;&gt; Sebastian
&gt;
&gt;
&gt;

[Attachment #3 (text/html)]

Hi all. This proposal doesn't seem to be going anywhere so thought I should give \
it one last nudge before moving on to more worthwhile work. The issue's sticking \
point seems to be a difference of opinion about what constitutes relay evilness. \
Nick, Jake, and Sebastian all believe in a hard line stance against any retrieval of \
connection information (netstat, lsof, etc). I disagree, and think this is harmless \
unless stored or communicated. Unless this can be resolved I think it's obvious \
the proposal isn't going anywhere.&lt;br&gt; &lt;br&gt;Please note that I'm discussing \
relay to relay connections at the moment. If we can't even agree on that then \
client and exit connections are a moot point (and besides, I agree they should \
definitely be hidden from relay operators - personally I think it's the \
responsibility of client applications like vidalia and arm to scrub this data, but \
that's a different discussion...).&lt;br&gt; &lt;br&gt;Just to be clear I agree this proposal \
should be killed if it poses a threat to Tor users. However, I don't believe it \
does and still have yet to hear an example of any sort of threat it aggravates. \
Without that I'm a bit puzzled at the source of objections. If the chief issue is \
legal or not wanting to risk the appearance of supporting snooping that's fine \
(strikes me as political posing if there's no actual benefits to users, but cest \
la vi).&lt;br&gt; &lt;br&gt;Contrary to Nick's impression of my last response I'm not a \
Scooby-Doo villain laughing maniacally as I scheme against Tor's users. I think \
transient connection data is good for auditing and transparency, but welcome \
correction if it's dangerous (before including it in arm I'd tried to ask \
about risks and objections at Toorcamp but no one seemed interested...). As for this \
proposal, I think it has some tasty benefits that could help arm quite a bit \
                including:&lt;br&gt;
- better performance&lt;br&gt;- added information, juiciest from an auditing perspective \
being bandwidth measurements and association of connections to circuits&lt;br&gt;- the \
ability to discern client and exit connections so they can be scrubbed (I've \
tried correlating against consensus data to do this, but that was pretty \
inaccurate)&lt;br&gt; &lt;br&gt;My bias is toward safety for relay operators and I'm glad to \
see others biased toward user privacy pushing back. Hopefully we'll be able to \
find something acceptable to all parties concerned but if not it won't be the end \
of the world. Cheers! -Damian&lt;br&gt; &lt;br&gt;&lt;div class="gmail_quote"&gt;On Sun, Dec 20, 2009 \
at 2:24 PM, Damian Johnson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt; Hi Sebastian, thanks for the \
feedback!&lt;div class="im"&gt;&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, \
204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;As \
always, I'm very uncomfortable with giving away users'/destinations' ip \
addresses or ports. I do realize that the same information can be obtained from \
netstat and friends, but I still think we should actively discourage the use and \
acquisition of this data. I realize that this is against the intentions of this \
proposal, but I hope that it is still useful even without client/destination \
identifying information.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;/div&gt;Disagree for the following \
reasons:&lt;br&gt;- As mentioned on IRC: all Internet facing applications (browsers, email \
clients, tor) are attack vectors for my system. Tor's developers are good, but \
I'm not so sure that they're infallible (sorry Nick) and hence the process \
can't be blindly trusted - that's why I think transparency is the best way to \
go. With hundreds of connections to relatively unknown destinations tor is already \
the bane of network based IDS so it would be nice if we could provide some accounting \
to system administrators that tor is behaving as it should. For instance say the tor \
process claims a big outbound connection taking 90% of your bandwidth that can't \
be accounted for as belonging to a circuit. If you aren't using it as a client \
that would be... bad.&lt;br&gt;

&lt;br&gt;- I agree that for correlation attacks this data is of concern in the event that \
numerous relays store or share this information. However, for an individual relay \
operator having this data shouldn't pose *any* threat to tor users (if it does... \
we have an issue). From what I can tell this proposal doesn't do anything that \
makes correlation attacks more dangerous since netstat running in a cron job is all \
they need (assuming they own a big chunk of the relays).&lt;br&gt;

&lt;br&gt;- Tor was designed with a certain level of distrust of relays. Beyond that the \
best we can do is discourage them from risky behaviour (ie, running outdated \
versions, looking at exit traffic, sharing connection data, etc). By including \
connection types controllers will have the opportunity to tell relay operators \
"Oi! Please don't look at these exit connections unless you have a damn good \
reason.". As it stands I don't have a way of telling them apart, and hence \
can't even hide them by default.&lt;br&gt;

&lt;br&gt;- As you mentioned we can't (and imho shouldn't) prevent relay operators \
from seeing the connections made to/from their own system. This proposal doesn't \
seem to exasperate any privacy issues while providing some nice benefits (performance \
and some handy bits of extra data that'll make security anomalies far easier to \
detect).&lt;div class="im"&gt; &lt;br&gt;
&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;This is, I think, a misunderstanding \
of what a connection is. More below.&lt;br&gt;&lt;/blockquote&gt;

&lt;br&gt;&lt;/div&gt;No, the hidden service question isn't. I'm assuming that when \
hosting hidden services there's some connections dedicated to providing that \
service. If so, a TYPE_FLAG should probably be included since they don't really \
belong to any of the other groups. Changed proposal to include one till someone tells \
me this is wrong.&lt;br&gt;

&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;Here, the connection identity needs to \
either include the CIRC_ID, or this is ambigious...&lt;br&gt;

&lt;/blockquote&gt;&lt;br&gt;Thanks for the catch! Made the following three corrections:&lt;br&gt;&lt;br&gt;- \
Changed signature to "conn/&lt;Circuit identity&gt;/&lt;Connection \
identity&gt;" to avoid ambiguity. I'm assuming that in general people will \
use the "conn/all" to discover the circuit/connection ids (actually, \
can't think of a use for getting a single connection - just including it to \
conform with other control-spec GETINFO options).&lt;br&gt;

&lt;br&gt;- Noted that more than two connections could have the same circuit ID in the case \
of exit connections.&lt;br&gt;&lt;br&gt;- Including a L_PORT (local port) parameter - wasn't \
mentioned but definitely an oversight.&lt;div class="im"&gt; &lt;br&gt;&lt;br&gt;&lt;blockquote \
style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; \
padding-left: 1ex;" class="gmail_quote"&gt; These flags seem to be mostly redundant. \
Again, they don't necessarily work because a connection can be used for many \
things. As for the Ee flag, I don't really see the purpose, we certainly \
shouldn't look at exit traffic going through the connection to decide if it is \
encrypted or not.&lt;/blockquote&gt;&lt;br&gt;&lt;/div&gt;Yea, I wasn't sure if they should be like \
argument flags (given a default if excluded) or always explicitly stated. Opted for \
the later since in general explicit is better than implicit, and this way \
implementers (like TorCtl) won't need to hard code any defaults. Both minor \
points and glad to discuss more if people disagree.&lt;br&gt;

&lt;br&gt;Yes, if this was only associated with a connection it wouldn't work, but \
circuit/connection combinations should be unique so issue fixed there.&lt;br&gt;&lt;br&gt;As for \
the Ee flag I'm suspecting that it would have use for client connections since \
any unencrypted traffic there is sniffable. This isn't important to the use cases \
I care about so we can drop it if others think it's a bad idea.&lt;br&gt;

&lt;br&gt;Here's the revised \
proposal:&lt;br&gt;&lt;br&gt;-------------------------------------------------------------------------------&lt;br&gt;&lt;br&gt; \
"conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides \
entry for the&lt;br&gt;

    associated connection, formatted as:&lt;br&gt;      CONN_ID CIRC_ID OR_ID IP PORT \
L_PORT TYPE_FLAGS READ WRITE UPTIME BUFF&lt;div class="im"&gt;&lt;br&gt;&lt;br&gt;    none of the \
parameters contain whitespace, and additional results must be&lt;br&gt;  ignored to allow \
for future expansion. Parameters are defined as follows:&lt;br&gt;  CONN_ID - Unique \
identifier associated with this connection.&lt;br&gt;      CIRC_ID - Unique identifier for \
the circuit this belongs to (0 if this&lt;br&gt;        doesn't belong to any circuit). \
At most their may be two connections&lt;br&gt; &lt;/div&gt;
        (one inbound, one outbound) with any given CIRC_ID except in the case&lt;br&gt;     \
of exit connections.&lt;div class="im"&gt;&lt;br&gt;      OR_ID - Relay fingerprint, 0 if \
connection doesn't belong to a relay.&lt;br&gt;      IP/PORT - IP address and port used \
by the associated connection.&lt;br&gt; &lt;/div&gt;
      L_PORT - Local port used by the connection.&lt;div class="im"&gt;&lt;br&gt;      TYPE_FLAGS \
- Single character flags indicating directionality and type&lt;br&gt;        of the \
connection (consists of one from each category, may become&lt;br&gt;  longer for future \
expansion).&lt;br&gt;  I: inbound, i: listening (unestablished inbound),&lt;br&gt;            O: \
outbound, o: unestablished outbound&lt;br&gt;&lt;/div&gt;          C: client related, R: relay \
related, X: control, H: hidden service,&lt;div class="im"&gt;&lt;br&gt;  D: directory&lt;br&gt;
          T: inter-tor connection, t: outside the tor network&lt;br&gt;          E: \
encrypted traffic, e: unencrypted traffic&lt;br&gt;        For instance, "IRtE" \
would indicate that this was an established&lt;br&gt;        1st-hop (or bridged) relay \
connection.&lt;br&gt; &lt;/div&gt;&lt;div class="im"&gt;
      READ/WRITE - Total bytes read/written over the life of this connection.&lt;br&gt;     \
UPTIME - Time the connection's been established in seconds.&lt;br&gt;      BUFF - Bytes \
of data buffered for this relay connection.&lt;br&gt; &lt;br&gt;
  "conn/all" -- Newline separated listing of all current \
connections.&lt;br&gt;&lt;br&gt;  "info/relay/bw-limit" -- Effective relayed bandwidth \
limit (currently&lt;br&gt;    RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt;

&lt;br&gt;  "info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt;&lt;br&gt;  \
"info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;&lt;br&gt;  \
"info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt;

&lt;br&gt;  "info/relay/buffer-cap" -- Maximum buffer size for relay \
connections.&lt;br&gt;&lt;br&gt;  "info/uptime-process" -- Total uptime of the tor \
process (in seconds).&lt;br&gt;&lt;br&gt;  "info/uptime-reset" -- Time since last reset \
(startup or sighup signal, in&lt;br&gt;

    seconds).&lt;br&gt;&lt;br&gt;  "info/descriptor-used" -- Count of file descriptors \
used.&lt;br&gt;&lt;br&gt;  "info/descriptor-limit" -- File descriptor limit (getrlimit \
results).&lt;br&gt;&lt;br&gt;  "ns/authority" -- Router status info (v2 directory \
style) for all&lt;br&gt;

    recognized directory authorities, joined by \
newlines.&lt;br&gt;&lt;br&gt;&lt;/div&gt;-------------------------------------------------------------------------------&lt;br&gt;&lt;br&gt;Cheers! \
-Damian&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt; On Sat, Dec \
19, 2009 at 11:43 PM, Sebastian Hahn &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:hahn.seb@web.de" target="_blank"&gt;hahn.seb@web.de&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, \
204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;Hi Damian,&lt;br&gt; &lt;br&gt;
please find my comments inline below.&lt;br&gt;
&lt;br&gt;
On Dec 17, 2009, at 3:24 AM, Damian Johnson wrote:&lt;br&gt;
&lt;br&gt;
[snip]&lt;br&gt;
&lt;div&gt;&gt;  - Anything dangerous? Doubt it, but the bandwidth measurements should \
probably&lt;br&gt; &gt;  either be rounded or provided occasionally (say, every second) to \
address&lt;br&gt; &gt;  correlation attacks. I'm sure Sebastian will enthusiastically \
sink some&lt;br&gt; &gt;  paranoia into this later. ;)&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;As always, I'm very uncomfortable with giving away \
users'/destinations' ip addresses or ports. I do realize that the same \
information can be obtained from netstat and friends, but I still think we should \
actively discourage the use and acquisition of this data. I realize that this is \
against the intentions of this proposal, but I hope that it is still useful even \
without client/destination identifying information.&lt;br&gt;


&lt;div&gt;&lt;br&gt;
&gt; - When hosting hidden services I'd imagine some connections are dedicated \
to&lt;br&gt; &gt;  them. If so, lets add a flag to indicate them.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;This is, I think, a misunderstanding of what a connection is. More below.&lt;br&gt;
&lt;br&gt;
[snip]&lt;br&gt;
&lt;div&gt;&gt;    "conn/&lt;Connection identity&gt;" -- Provides entry for the \
associated&lt;br&gt; &gt;      connection, formatted as:&lt;br&gt;
&gt;        CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF&lt;br&gt;
&gt;&lt;br&gt;
&gt;      none of the parameters contain whitespace, and additional results must \
be&lt;br&gt; &gt;      ignored to allow for future expansion. Parameters are defined as \
follows:&lt;br&gt; &gt;        CONN_ID - Unique identifier associated with this \
connection.&lt;br&gt; &gt;        CIRC_ID - Unique identifier for the circuit this belongs \
to (0 if this&lt;br&gt; &gt;          doesn't belong to any circuit). At most their may \
be two connections&lt;br&gt; &gt;          (one inbound, one outbound) with any given \
CIRC_ID.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Here, the connection identity needs to either include the CIRC_ID, or this is \
ambigious. Tor mutliplexes many circuits over the same connection, so there is no way \
to infer the circuit id from a connection id. Also, for exit connections, there may \
be more than two connections with the same circuit id. What this means: We either \
want a seperate query to learn about circuits, or we want the conn_id to list all the \
circuits that it has attached, or we want to only allow queries of this kind when \
circ id and conn id are both known to the controller&lt;br&gt;


&lt;div&gt;&lt;br&gt;
&gt;        OR_ID - Relay fingerprint, 0 if connection doesn't belong to a \
relay.&lt;br&gt; &gt;        IP/PORT - IP address and port used by the associated \
connection.&lt;br&gt; &gt;        TYPE_FLAGS - Single character flags indicating \
directionality and type&lt;br&gt; &gt;          of the connection (consists of one from \
each category, may become&lt;br&gt; &gt;          longer for future expansion).&lt;br&gt;
&gt;            I: inbound, i: listening (unestablished inbound),&lt;br&gt;
&gt;              O: outbound, o: unestablished outbound&lt;br&gt;
&gt;            C: client related, R: relay related, X: control, D: directory&lt;br&gt;
&gt;            T: inter-tor connection, t: outside the tor network&lt;br&gt;
&gt;            E: encrypted traffic, e: unencrypted traffic&lt;br&gt;
&gt;          For instance, "IRtE" would indicate that this was an \
established&lt;br&gt; &gt;          1st-hop (or bridged) relay connection.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;These flags seem to be mostly redundant. Again, they don't necessarily work \
because a connection can be used for many things. As for the Ee flag, I don't \
really see the purpose, we certainly shouldn't look at exit traffic going through \
the connection to decide if it is encrypted or not.&lt;br&gt;


&lt;div&gt;&lt;br&gt;
&gt;        READ/WRITE - Total bytes read/written over the life of this \
connection.&lt;br&gt; &gt;        UPTIME - Time the connection's been established in \
seconds.&lt;br&gt; &gt;        BUFF - Bytes of data buffered for this relay connection.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "conn/all" -- Newline separated listing of all current \
connections.&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/relay/bw-limit" -- Effective relayed bandwidth limit \
(currently&lt;br&gt; &gt;      RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/buffer-cap" -- Maximum buffer size for relay \
connections.&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/uptime-process" -- Total uptime of the tor process (in \
seconds).&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/uptime-reset" -- Time since last reset (startup or sighup \
signal, in&lt;br&gt; &gt;      seconds).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/descriptor-used" -- Count of file descriptors used.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/descriptor-limit" -- File descriptor limit (getrlimit \
results).&lt;br&gt; &gt;&lt;br&gt;
&gt;    "ns/authority" -- Router status info (v2 directory style) for \
all&lt;br&gt; &gt;      recognized directory authorities, joined by newlines.&lt;br&gt;
&gt;&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;These all sound sane.&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;
&lt;br&gt;
Sebastian&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20100128222724</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-01-28 22:27:24-0400</timestampReceived><subject>Re: Proposal 169: Eliminate TLS renegotiation for the Tor connection</subject><body>

On Thu, Jan 28, 2010 at 10:21 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; Nick Mathewson wrote:

&gt; [...]
&gt;
&gt;&gt;              * If the CERT cell is a good cert signing the public
&gt;&gt;                key in the x.509 certificate we got during the TLS
&gt;&gt;                handshake, we connected to the server with that
&gt;&gt;                identity key.  Otherwise close the connection.
&gt;
&gt;
&gt; I think this needs to be re-written to be clearer.
&gt;

I've rewritten it to:

   * If the CERT cell contains a valid self-identity cert, and the identity
     key in the cert can be used to check the signature on the x.509
     certificate we got during the TLS handshake, then we know we
     connected to the server with that identity.  If any of these checks
     fail, or the identity key was not what we expected, then we close the
     connection.


&gt;&gt;              * Once the NETINFO cell arrives, continue as before.
&gt;&gt;
&gt;
&gt; [...]
&gt;
&gt;&gt; 6. Open questions:
&gt;&gt;
&gt;&gt;   - Should we use X.509 certificates instead of the certificate-ish
&gt;&gt;     things we describe here?  They are more standard, but more ugly.
&gt;
&gt; Do we get anything out of custom-ish things? It seems kludgy to make
&gt; stuff up on the fly but perhaps it's somehow simpler for our use?

We get the benefit of not importing the whole X.509 mess by reference.
 Right now we already require its use since we're using TLS, but we've
had the good fortune not to need to actually do anything with X.509
inside Tor per se once we've got a secure connection established.

&gt;&gt;
&gt;&gt;   - May we cache which certificates we've already verified?  It
&gt;&gt;     might leak in timing whether we've connected with a given server
&gt;&gt;     before, and how recently.
&gt;
&gt;  It seems like timing information would be leaked. We should avoid that
&gt; if possible.

I wonder if it's ever safe to cache a cert verification result, even
for a little while.  If we can wind up doing less RSA, it would be
worthwhile.


&gt;&gt;
&gt;&gt;   - Is there a better secret than the master secret to use in the
&gt;&gt;     AUTHENTICATE cell?  Say, a portable one?  Can we get at it for
&gt;&gt;     other libraries besides OpenSSL?
&gt;&gt;
&gt;
&gt; I'm not sure. It seems OK. What worries you about it?

First off, if we leak the master_secret somehow, then an observer
might be able to decrypt the TLS stream.  Second, I've only confirmed
that we can grab it out of the guts of the OpenSSL SSL struct; I have
no idea whether people writing Tor clients in Java or Python would be
able to get it without hacking their own SSL libraries.

&gt;&gt;   - Can we give some way for clients to signal "I want to use the
&gt;&gt;     V3 protocol if possible, but I can't renegotiate, so don't give
&gt;&gt;     me the V2"?  Clients currently have a fair idea of server
&gt;&gt;     versions, so they could potentially do the V3+ handshake with
&gt;&gt;     servers that support it, and fall back to V1 otherwise.
&gt;&gt;
&gt;
&gt; Does this open us up to downgrade attacks? Downgrade attacks here seem
&gt; like they might range in seriousness from simply potentially detecting
&gt; Tor users or perhaps doing something actually nasty...

The regular downgrade prevention in TLS should make sure that the
handshake that each party thought they sent matches the handshake the
other one received, and close the connection if a MITM tries any
tomfoolery.

-- 
Nick

</body></email><email><emailId>20100214045302</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-14 04:53:02-0400</timestampReceived><subject>(Desperate) Plea for multi-person code review</subject><body>


My past few posts to this list have been about developing new formulas
for load balancing Tor requests. I've since implemented these formulas
in my git branch mikeperry/consensus-bw-weights3. You can get it with:

 git clone git://git.torproject.org/git/tor.git tor.git
 cd tor.git
 git remote add mikeperry git://git.torproject.org/mikeperry/tor
 git fetch mikeperry
 git branch --track mp-consensus-bw-weights3 mikeperry/consensus-bw-weights3
 git checkout mp-consensus-bw-weights3

X11 users can see the change sets easily with 'gitk'.

The consensus weight calculation changes exist in
networkstatus_compute_bw_weights_v9() in dirvote.c, but what really
needs lots of eyeballs is smartlist_choose_by_bandwidth_weights() and
all the codepaths that lead to it in routerlist.c (and also those
elsewhere that don't, but should!). Basically anywhere we choose to
use a node somehow, we need to ensure we are properly weighting node
probability selection for it.

The reason why it is more important to review the client code than the
formulas right now is because every time we make an error client-side,
we need to wait almost an entire year after the fix before enough
clients upgrade and we begin to see the results of the fix on network
load. (Yes. It takes up to a year for everyone to upgrade.. We really
need an autoupdater.)

Weight calculation updates and bugfixes now will at least take place
as soon as 4 out of 7 directory authorities do a 'git pull', but
client errors with using weights can mean years of further bad Tor
performance.

Our track record with these codepaths hasn't exactly been great
either: So far we've made at least 3-4 critical errors in the
implementation of node selection, leading to uniform guard selection
in two separate instances, due to two different bugs! One of them is
ruining Tor performance as we speak, and things won't improve until
most of the clients upgrade to the not-yet-released 0.2.1.23.

I'm going to try to budget some time for statistical verification of
these codepaths later on, but that won't be foolproof either. If you
can read C code and have a few moments to spare, please do have a look
at my git branch and check it for logic, branching, arithmetic, and
transcription errors in at least the client node selection, if not
also the weight calculations themselves.


--=20
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100222092939</emailId><senderName></senderName><senderEmail>rkapoor</senderEmail><timestampReceived>2010-02-22 09:29:39-0400</timestampReceived><subject>TOR -Token Bucket implementation</subject><body>

Hi,

 I am new to the TOR community. While reading through the tor performance
issues, I found out that TOR uses token bucket implementation for rate
limiting.

I am planning to implement Hierarchical token bucket as part of my class
project
in TOR.

Seeking feedback/opinions from tor community regarding the same.



Thanks,
Rishi



</body></email><email><emailId>20100215020948</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-15 02:09:48-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; My past few posts to this list have been about developing new formulas
&gt; for load balancing Tor requests. I've since implemented these formulas
&gt; in my git branch mikeperry/consensus-bw-weights3. You can get it with:
&gt; 
&gt;  git clone git://git.torproject.org/git/tor.git tor.git
&gt;  cd tor.git
&gt;  git remote add mikeperry git://git.torproject.org/mikeperry/tor
&gt;  git fetch mikeperry
&gt;  git branch --track mp-consensus-bw-weights3 mikeperry/consensus-bw-weights3
&gt;  git checkout mp-consensus-bw-weights3
&gt; 
&gt; X11 users can see the change sets easily with 'gitk'.

Sebastian requested that I should utilize git to engage in some
revisionist history and make my branch look a little less
schizophrenic.

I've now rebased, split, and squashed all the commits into 8
logically distinct patches in mikeperry/consensus-bw-weights4.
Should be easier to review for those who prefer to look at things
one commit at a time.


  "This is what I find most encouraging about the writing trades: They
  allow mediocre people who are patient and industrious to revise
  their stupidity, to edit themselves into something like intelligence,
  they also allow lunatics to seem saner than sane."
           -- Kurt Vonnegut


Who knew that would soon apply to software development too?


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100221033015</emailId><senderName>Christian Kujau</senderName><senderEmail>lists@nerdbynature.de</senderEmail><timestampReceived>2010-02-21 03:30:15-0400</timestampReceived><subject>[PATCH] contrib/tor-exit-notice.html url fix</subject><body>

Hi,

just a minor URL fix to the contrib/tor-exit-notice.html document. Also 
adding a DOCTYPE to make it valid XHTML.

Apart from these nitpicks, the latest -git checkouts are running great on 
Linux/powerpc!

Thanks,
Christian.

diff --git a/tor-exit-notice.orig.html b/tor-exit-notice.html
index 4ab028f..dbbf031 100644
--- a/tor-exit-notice.orig.html
+++ b/tor-exit-notice.html
@@ -1,4 +1,7 @@
-&lt;html&gt;
+&lt;?xml version="1.0"?&gt;
+&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
+    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
+&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
 &lt;head&gt;
 &lt;title&gt;This is a Tor Exit Router&lt;/title&gt;
 
@@ -26,7 +29,7 @@ They are marked with FIXME.
 &lt;p&gt;Most likely you are accessing this website because you had some issue with
 the traffic coming from this IP. This router is part of the &lt;a
 href="https://www.torproject.org/"&gt;Tor Anonymity Network&lt;/a&gt;, which is
-dedicated to &lt;a href="https://www.torproject.org/30seconds.html.en"&gt;providing
+dedicated to &lt;a href="https://www.torproject.org/overview.html"&gt;providing
 privacy&lt;/a&gt; to people who need it most: average computer users. This
 router IP should be generating no other traffic, unless it has been
 compromised.
@@ -37,11 +40,11 @@ compromised.
 &lt;!-- FIXME: you should probably grab your own copy of how_tor_works_thumb.png
 and serve it locally --&gt;
 &lt;center&gt;&lt;a href="https://www.torproject.org/overview.html"&gt;
-&lt;img src="https://www.torproject.org/images/how_tor_works_thumb.png"&gt;&lt;/a&gt;&lt;/center&gt;
+&lt;img src="https://www.torproject.org/images/how_tor_works_thumb.png" alt="How Tor works"/&gt;&lt;/a&gt;&lt;/center&gt;
 
 &lt;p&gt;
 
-Tor sees use by &lt;a href="https://www.torproject.org/torusers.html.en"&gt;many
+Tor sees use by &lt;a href="https://www.torproject.org/torusers.html"&gt;many
 important segments of the population&lt;/a&gt;, including whistle blowers,
 journalists, Chinese dissidents skirting the Great Firewall and oppressive
 censorship, abuse victims, stalker targets, the US military, and law
@@ -127,7 +130,7 @@ already blocked.
 
 &lt;p&gt;You also have the option of blocking this IP address and others on
 the Tor network if you so desire. The Tor project provides a &lt;a
-href="https://tor-svn.freehaven.net/svn/tor/trunk/contrib/exitlist"&gt;python script&lt;/a&gt; to
+href="https://check.torproject.org/cgi-bin/TorBulkExitList.py"&gt;python script&lt;/a&gt; to
 extract all IP addresses of Tor exit nodes, and an official &lt;a
 href="https://www.torproject.org/tordnsel/"&gt;DNSRBL&lt;/a&gt; is also available to
 determine if a given IP address is actually a Tor exit server. Please
-- 
BOFH excuse #328:

Fiber optics caused gas main leak
</body></email><email><emailId>20100222142442</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-02-22 14:24:42-0400</timestampReceived><subject>Re: [PATCH] contrib/tor-exit-notice.html url fix</subject><body>

Hi Christian,

thanks for your patch. Comments below:

On Feb 21, 2010, at 4:30 AM, Christian Kujau wrote:
&gt; Hi,
&gt; 
&gt; just a minor URL fix to the contrib/tor-exit-notice.html document. Also 
&gt; adding a DOCTYPE to make it valid XHTML.

Simply adding the doctype won't make something valid xhtml. The file is
far from being valid, so we should fix that first before declaring our
compliance.

&gt; Apart from these nitpicks, the latest -git checkouts are running great on 
&gt; Linux/powerpc!

Great to hear, thanks!

&gt; Thanks,
&gt; Christian.
&gt; 
&gt; diff --git a/tor-exit-notice.orig.html b/tor-exit-notice.html
&gt; index 4ab028f..dbbf031 100644
&gt; --- a/tor-exit-notice.orig.html
&gt; +++ b/tor-exit-notice.html
&gt; @@ -1,4 +1,7 @@
&gt; -&lt;html&gt;
&gt; +&lt;?xml version="1.0"?&gt;
&gt; +&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
&gt; +    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
&gt; +&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&gt; &lt;head&gt;
&gt; &lt;title&gt;This is a Tor Exit Router&lt;/title&gt;
&gt; 

dropping this hunk, see comment above

&gt; [snip]
&gt; &lt;p&gt;You also have the option of blocking this IP address and others on
&gt; the Tor network if you so desire. The Tor project provides a &lt;a
&gt; -href="https://tor-svn.freehaven.net/svn/tor/trunk/contrib/exitlist"&gt;python script&lt;/a&gt; to
&gt; +href="https://check.torproject.org/cgi-bin/TorBulkExitList.py"&gt;python script&lt;/a&gt; to
&gt; extract all IP addresses of Tor exit nodes, and an official &lt;a
&gt; href="https://www.torproject.org/tordnsel/"&gt;DNSRBL&lt;/a&gt; is also available to
&gt; determine if a given IP address is actually a Tor exit server. Please

I added some more words here to hopefully make it clear what we mean.

Generally, please feel free to send git format-patch formatted patches, if you want
(or I'm happy to make commits from diffs, if that is what you prefer).

Please let me know if this patch works for you, and whether you want a different
kind of credit.

http://gitweb.torproject.org//sebastian/tor.git?a=commitdiff;h=29fd31cf6b85dc54b4623c460c6aaeadb21281f1

If you want to submit a patch to make the exit notice file actually xhtml compliant,
that'd be neat, too. We've been going with the "fewer bytes" maxime here so far,
though.

Sincere thanks for your efforts!

Sebastian
</body></email><email><emailId>20100223061114</emailId><senderName>Christian Kujau</senderName><senderEmail>lists@nerdbynature.de</senderEmail><timestampReceived>2010-02-23 06:11:14-0400</timestampReceived><subject>Re: [PATCH] contrib/tor-exit-notice.html url fix</subject><body>

On Mon, 22 Feb 2010 at 15:24, Sebastian Hahn wrote:
&gt; Simply adding the doctype won't make something valid xhtml. The file is
&gt; far from being valid, so we should fix that first before declaring our
&gt; compliance.

Yes, I should've clarified: after fixing the URL I used tidy[0] and it 
spotted only two warnings:

# tidy -e contrib/tor-exit-notice.html 
line 1 column 1 - Warning: missing &lt;!DOCTYPE&gt; declaration
line 40 column 1 - Warning: &lt;img&gt; lacks "alt" attribute

After fixing these two, I assumed the document was now valid, but your 
comment made me double check with the "official" validator[1] - and it
failed miserably :-\

After playing around with a newer version of "tidy" and a lot of editing,
the document appears to be valid now. As the patch is rather big now (due
to line breaks, the content did not change), I've attached the .html as 
well.

Thanks,
Christian.

[0] http://tidy.sourceforge.net/
[1] http://validator.w3.org/

Signed-off-by: Christian Kujau &lt;lists@nerdbynature.de&gt;

 tor-exit-notice.html |   67 +++++++++++++++++++++++++--------------------------
 1 file changed, 34 insertions(+), 33 deletions(-)

diff --git a/tor-exit-notice.html.orig b/tor-exit-notice.html
index 4ab028f..68218a5 100644
--- a/tor-exit-notice.html.orig
+++ b/tor-exit-notice.html
@@ -1,5 +1,9 @@
-&lt;html&gt;
+&lt;?xml version="1.0"?&gt;
+&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
+    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
+&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
 &lt;head&gt;
+&lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt;
 &lt;title&gt;This is a Tor Exit Router&lt;/title&gt;
 
 &lt;!--
@@ -19,29 +23,29 @@ They are marked with FIXME.
 --&gt;
 
 &lt;/head&gt;
-&lt;body bgcolor=white text=black&gt;
+&lt;body&gt;
 
-&lt;center&gt;&lt;h1&gt;This is a Tor Exit Router&lt;/h1&gt;&lt;/center&gt;
+&lt;p style="text-align:center; font-size:xx-large; font-weight:bold"&gt;This is a Tor \
Exit Router&lt;/p&gt;  
-&lt;p&gt;Most likely you are accessing this website because you had some issue with
+&lt;p&gt;
 the traffic coming from this IP. This router is part of the &lt;a
 href="https://www.torproject.org/"&gt;Tor Anonymity Network&lt;/a&gt;, which is
-dedicated to &lt;a href="https://www.torproject.org/30seconds.html.en"&gt;providing
+dedicated to &lt;a href="https://www.torproject.org/overview.html"&gt;providing
 privacy&lt;/a&gt; to people who need it most: average computer users. This
 router IP should be generating no other traffic, unless it has been
-compromised.
-
-&lt;p&gt;
+compromised.&lt;/p&gt;
 
 
 &lt;!-- FIXME: you should probably grab your own copy of how_tor_works_thumb.png
-and serve it locally --&gt;
-&lt;center&gt;&lt;a href="https://www.torproject.org/overview.html"&gt;
-&lt;img src="https://www.torproject.org/images/how_tor_works_thumb.png"&gt;&lt;/a&gt;&lt;/center&gt;
+     and serve it locally --&gt;
 
-&lt;p&gt;
+&lt;p style="text-align:center"&gt;
+&lt;a href="https://www.torproject.org/overview.html"&gt;
+&lt;img src="https://www.torproject.org/images/how_tor_works_thumb.png" alt="How Tor \
works" style="border-style:none"/&gt; +&lt;/a&gt;&lt;/p&gt;
 
-Tor sees use by &lt;a href="https://www.torproject.org/torusers.html.en"&gt;many
+&lt;p&gt;
+Tor sees use by &lt;a href="https://www.torproject.org/torusers.html"&gt;many
 important segments of the population&lt;/a&gt;, including whistle blowers,
 journalists, Chinese dissidents skirting the Great Firewall and oppressive
 censorship, abuse victims, stalker targets, the US military, and law
@@ -59,44 +63,41 @@ powerful networks&lt;/a&gt; than Tor on a daily basis. Thus, in the \
mind of this  operator, the social need for easily accessible censorship-resistant \
private,  anonymous communication trumps the risk of unskilled bad actors, who are
 almost always more easily uncovered by traditional police work than by
-extensive monitoring and surveillance anyway.
+extensive monitoring and surveillance anyway.&lt;/p&gt;
 
 &lt;p&gt;
-
 In terms of applicable law, the best way to understand Tor is to consider it a
 network of routers operating as common carriers, much like the Internet
 backbone. However, unlike the Internet backbone routers, Tor routers
 explicitly do not contain identifiable routing information about the source of
 a packet, and no single Tor node can determine both the origin and destination
-of a given transmission.
+of a given transmission.&lt;/p&gt;
 
 &lt;p&gt;
-
 As such, there is little the operator of this router can do to help you track
 the connection further. This router maintains no logs of any of the Tor
 traffic, so there is little that can be done to trace either legitimate or
 illegitimate traffic (or to filter one from the other).  Attempts to
-seize this router will accomplish nothing.
-&lt;p&gt;
+seize this router will accomplish nothing.&lt;/p&gt;
 
-&lt;!--- FIXME: US-Only section. Remove if you are a non-US operator --&gt;
+&lt;!-- FIXME: US-Only section. Remove if you are a non-US operator --&gt;
 
+&lt;p&gt;
 Furthermore, this machine also serves as a carrier of email, which means that
 its contents are further protected under the ECPA. &lt;a
 href="http://www4.law.cornell.edu/uscode/html/uscode18/usc_sec_18_00002707----000-.html"&gt;18
  USC 2707&lt;/a&gt; explicitly allows for civil remedies ($1000/account
-&lt;i&gt;&lt;b&gt;&lt;u&gt;plus&lt;/u&gt;&lt;/b&gt;&lt;/i&gt;  legal fees)
+&lt;i&gt;&lt;b&gt;plus&lt;/b&gt;&lt;/i&gt;  legal fees)
 in the event of a seizure executed without good faith or probable cause (it
 should be clear at this point that traffic with an originating IP address of
 FIXME_DNS_NAME should not constitute probable cause to seize the
 machine). Similar considerations exist for 1st amendment content on this
-machine.
-
-&lt;p&gt;
+machine.&lt;/p&gt;
 
 &lt;!-- FIXME: May or may not be US-only. Some non-US tor nodes have in
-fact reported DMCA harassment... --&gt;
+     fact reported DMCA harassment... --&gt;
 
+&lt;p&gt;
 If you are a representative of a company who feels that this router is being
 used to violate the DMCA, please be aware that this machine does not host or
 contain any illegal content. Also be aware that network infrastructure
@@ -106,35 +107,35 @@ \
href="http://www4.law.cornell.edu/uscode/html/uscode17/usc_sec_17_00000512----00  \
"safe harbor" provisions&lt;/a&gt;. In other words, you will have just as much luck  \
sending a takedown notice to the Internet backbone providers. Please consult  &lt;a \
                href="https://www.torproject.org/eff/tor-dmca-response.html"&gt;EFF's \
                prepared
-response&lt;/a&gt; for more information on this matter.
+response&lt;/a&gt; for more information on this matter.&lt;/p&gt;
 
-&lt;p&gt;For more information, please consult the following documentation:
+&lt;p&gt;For more information, please consult the following documentation:&lt;/p&gt;
 
 &lt;ol&gt;
 &lt;li&gt;&lt;a href="https://www.torproject.org/overview.html"&gt;Tor Overview&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://www.torproject.org/faq-abuse.html"&gt;Tor Abuse FAQ&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://www.torproject.org/eff/tor-legal-faq.html"&gt;Tor Legal \
FAQ&lt;/a&gt;&lt;/li&gt;  &lt;/ol&gt;
-&lt;p&gt;
 
+&lt;p&gt;
 That being said, if you still have a complaint about the router,  you may
 email the &lt;a href="mailto:FIXME_YOUR_EMAIL_ADDRESS"&gt;maintainer&lt;/a&gt;. If
 complaints are related to a particular service that is being abused, I will
 consider removing that service from my exit policy, which would prevent my
 router from allowing that traffic to exit through it. I can only do this on an
 IP+destination port basis, however. Common P2P ports are
-already blocked.
+already blocked.&lt;/p&gt;
 
-&lt;p&gt;You also have the option of blocking this IP address and others on
+&lt;p&gt;
+You also have the option of blocking this IP address and others on
 the Tor network if you so desire. The Tor project provides a &lt;a
-href="https://tor-svn.freehaven.net/svn/tor/trunk/contrib/exitlist"&gt;python \
script&lt;/a&gt; to +href="https://check.torproject.org/cgi-bin/TorBulkExitList.py"&gt;python \
script&lt;/a&gt; to  extract all IP addresses of Tor exit nodes, and an official &lt;a
 href="https://www.torproject.org/tordnsel/"&gt;DNSRBL&lt;/a&gt; is also available to
 determine if a given IP address is actually a Tor exit server. Please
 be considerate
 when using these options. It would be unfortunate to deny all Tor users access
-to your site indefinitely simply because of a few bad apples.
+to your site indefinitely simply because of a few bad apples.&lt;/p&gt;
 
 &lt;/body&gt;
 &lt;/html&gt;
-
-- 
BOFH excuse #445:

Browser's cookie is corrupted -- someone's been nibbling on it.


["tor-exit-notice.html;" (TEXT/HTML)]

&lt;?xml version="1.0"?&gt;
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8" /&gt;
&lt;title&gt;This is a Tor Exit Router&lt;/title&gt;

&lt;!--

This notice is intended to be placed on a virtual host for a domain that
your Tor exit node IP reverse resolves to so that people who may be about
to file an abuse complaint would check it first before bothering you or
your ISP. Ex:
http://tor-exit.yourdomain.org or http://tor-readme.yourdomain.org.

This type of setup has proven very effective at reducing abuse complaints
for exit node operators.

There are a few places in this document that you may want to customize.
They are marked with FIXME.

--&gt;

&lt;/head&gt;
&lt;body&gt;

&lt;p style="text-align:center; font-size:xx-large; font-weight:bold"&gt;This is a Tor Exit \
Router&lt;/p&gt;

&lt;p&gt;
the traffic coming from this IP. This router is part of the &lt;a
href="https://www.torproject.org/"&gt;Tor Anonymity Network&lt;/a&gt;, which is
dedicated to &lt;a href="https://www.torproject.org/overview.html"&gt;providing
privacy&lt;/a&gt; to people who need it most: average computer users. This
router IP should be generating no other traffic, unless it has been
compromised.&lt;/p&gt;


&lt;!-- FIXME: you should probably grab your own copy of how_tor_works_thumb.png
     and serve it locally --&gt;

&lt;p style="text-align:center"&gt;
&lt;a href="https://www.torproject.org/overview.html"&gt;
&lt;img src="https://www.torproject.org/images/how_tor_works_thumb.png" alt="How Tor \
works" style="border-style:none"/&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;
Tor sees use by &lt;a href="https://www.torproject.org/torusers.html"&gt;many
important segments of the population&lt;/a&gt;, including whistle blowers,
journalists, Chinese dissidents skirting the Great Firewall and oppressive
censorship, abuse victims, stalker targets, the US military, and law
enforcement, just to name a few.  While Tor is not designed for malicious
computer users, it is true that they can use the network for malicious ends.
In reality however, the actual amount of &lt;a
href="https://www.torproject.org/faq-abuse.html"&gt;abuse&lt;/a&gt; is quite low. This
is largely because criminals and hackers have significantly better access to
privacy and anonymity than do the regular users whom they prey upon. Criminals
can and do &lt;a
href="http://voices.washingtonpost.com/securityfix/2008/08/web_fraud_20_tools.html"&gt;build,
 sell, and trade&lt;/a&gt; far larger and &lt;a
href="http://voices.washingtonpost.com/securityfix/2008/08/web_fraud_20_distributing_your.html"&gt;more
 powerful networks&lt;/a&gt; than Tor on a daily basis. Thus, in the mind of this
operator, the social need for easily accessible censorship-resistant private,
anonymous communication trumps the risk of unskilled bad actors, who are
almost always more easily uncovered by traditional police work than by
extensive monitoring and surveillance anyway.&lt;/p&gt;

&lt;p&gt;
In terms of applicable law, the best way to understand Tor is to consider it a
network of routers operating as common carriers, much like the Internet
backbone. However, unlike the Internet backbone routers, Tor routers
explicitly do not contain identifiable routing information about the source of
a packet, and no single Tor node can determine both the origin and destination
of a given transmission.&lt;/p&gt;

&lt;p&gt;
As such, there is little the operator of this router can do to help you track
the connection further. This router maintains no logs of any of the Tor
traffic, so there is little that can be done to trace either legitimate or
illegitimate traffic (or to filter one from the other).  Attempts to
seize this router will accomplish nothing.&lt;/p&gt;

&lt;!-- FIXME: US-Only section. Remove if you are a non-US operator --&gt;

&lt;p&gt;
Furthermore, this machine also serves as a carrier of email, which means that
its contents are further protected under the ECPA. &lt;a
href="http://www4.law.cornell.edu/uscode/html/uscode18/usc_sec_18_00002707----000-.html"&gt;18
 USC 2707&lt;/a&gt; explicitly allows for civil remedies ($1000/account
&lt;i&gt;&lt;b&gt;plus&lt;/b&gt;&lt;/i&gt;  legal fees)
in the event of a seizure executed without good faith or probable cause (it
should be clear at this point that traffic with an originating IP address of
FIXME_DNS_NAME should not constitute probable cause to seize the
machine). Similar considerations exist for 1st amendment content on this
machine.&lt;/p&gt;

&lt;!-- FIXME: May or may not be US-only. Some non-US tor nodes have in
     fact reported DMCA harassment... --&gt;

&lt;p&gt;
If you are a representative of a company who feels that this router is being
used to violate the DMCA, please be aware that this machine does not host or
contain any illegal content. Also be aware that network infrastructure
maintainers are not liable for the type of content that passes over their
equipment, in accordance with &lt;a
href="http://www4.law.cornell.edu/uscode/html/uscode17/usc_sec_17_00000512----000-.html"&gt;DMCA
 "safe harbor" provisions&lt;/a&gt;. In other words, you will have just as much luck
sending a takedown notice to the Internet backbone providers. Please consult
&lt;a href="https://www.torproject.org/eff/tor-dmca-response.html"&gt;EFF's prepared
response&lt;/a&gt; for more information on this matter.&lt;/p&gt;

&lt;p&gt;For more information, please consult the following documentation:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.torproject.org/overview.html"&gt;Tor Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.torproject.org/faq-abuse.html"&gt;Tor Abuse FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.torproject.org/eff/tor-legal-faq.html"&gt;Tor Legal \
FAQ&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt;

&lt;p&gt;
That being said, if you still have a complaint about the router,  you may
email the &lt;a href="mailto:FIXME_YOUR_EMAIL_ADDRESS"&gt;maintainer&lt;/a&gt;. If
complaints are related to a particular service that is being abused, I will
consider removing that service from my exit policy, which would prevent my
router from allowing that traffic to exit through it. I can only do this on an
IP+destination port basis, however. Common P2P ports are
already blocked.&lt;/p&gt;

&lt;p&gt;
You also have the option of blocking this IP address and others on
the Tor network if you so desire. The Tor project provides a &lt;a
href="https://check.torproject.org/cgi-bin/TorBulkExitList.py"&gt;python script&lt;/a&gt; to
extract all IP addresses of Tor exit nodes, and an official &lt;a
href="https://www.torproject.org/tordnsel/"&gt;DNSRBL&lt;/a&gt; is also available to
determine if a given IP address is actually a Tor exit server. Please
be considerate
when using these options. It would be unfortunate to deny all Tor users access
to your site indefinitely simply because of a few bad apples.&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100222043415</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-02-22 04:34:15-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

On Sun, Dec 13, 2009 at 08:23:14PM -0500, Roger Dingledine wrote:
&gt; +  if (r || router_get_consensus_status_by_id(id_digest)) {
&gt; +    /* It's in the consensus, or we have a descriptor for it meaning it
&gt; +     * was probably in a recent consensus. It's a recognized relay:
&gt; +     * give it full bandwidth. */
&gt; +    conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst = (int)options-&gt;BandwidthBurst;
&gt; +  } else { /* Not a recognized relay. Squeeze it down based on the
&gt; +            * suggested bandwidth parameters in the consensus. */
[snip]
&gt; As you can see, I'm making it configurable inside the consensus, so we
&gt; can experiment with it rather than rolling it out and then changing our
&gt; minds later. I don't have a good sense of whether it will be a good move,
&gt; but the only way I can imagine to find out is to try it.

I put that feature into Tor 0.2.2.7-alpha. Now there's a followup feature
I want to put into 0.2.2.10-alpha:

diff --git a/src/or/connection_edge.c b/src/or/connection_edge.c
index 8e2fcf9..ea871a5 100644
--- a/src/or/connection_edge.c
+++ b/src/or/connection_edge.c
@@ -2505,16 +2505,25 @@ connection_exit_begin_conn(cell_t *cell, circuit_t *circ)
       tor_free(address);
       return 0;
     }
-    if (or_circ &amp;&amp; or_circ-&gt;is_first_hop &amp;&amp;
-        !get_options()-&gt;AllowSingleHopExits) {
+    if (or_circ &amp;&amp; or_circ-&gt;p_conn &amp;&amp; !get_options()-&gt;AllowSingleHopExits &amp;&amp;
+        (or_circ-&gt;is_first_hop ||
+         (!connection_or_digest_is_known_relay(
+                                       or_circ-&gt;p_conn-&gt;identity_digest) &amp;&amp;
+          networkstatus_get_param(NULL, "refuseunknownexits", 1)))) {
       /* Don't let clients use us as a single-hop proxy, unless the user
        * has explicitly allowed that in the config.  It attracts attackers
        * and users who'd be better off with, well, single-hop proxies.
        */
       log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,
-             "Attempt to open a stream on first hop of circuit. Closing.");
+             "Attempt by %s to open a stream %s. Closing.",
+             safe_str(or_circ-&gt;p_conn-&gt;_base.address),
+             or_circ-&gt;is_first_hop ? "on first hop of circuit" :
+                                     "from unknown relay");
       relay_send_end_cell_from_edge(rh.stream_id, circ,
-                                    END_STREAM_REASON_TORPROTOCOL, NULL);
+                                    or_circ-&gt;is_first_hop ?
+                                      END_STREAM_REASON_TORPROTOCOL :
+                                      END_STREAM_REASON_MISC,
+                                    NULL);
       tor_free(address);
       return 0;
     }
diff --git a/src/or/connection_or.c b/src/or/connection_or.c
index 1aa0bb3..213ade1 100644
--- a/src/or/connection_or.c
+++ b/src/or/connection_or.c
@@ -322,7 +322,7 @@ connection_or_finished_connecting(or_connection_t *or_conn)
 
 /** Return 1 if identity digest &lt;b&gt;id_digest&lt;/b&gt; is known to be a
  * currently or recently running relay. Otherwise return 0. */
-static int
+int
 connection_or_digest_is_known_relay(const char *id_digest)
 {
   if (router_get_consensus_status_by_id(id_digest))
diff --git a/src/or/or.h b/src/or/or.h
index 434de78..dcf2f3d 100644
--- a/src/or/or.h
+++ b/src/or/or.h
@@ -3528,6 +3528,7 @@ int connection_or_process_inbuf(or_connection_t *conn);
 int connection_or_flushed_some(or_connection_t *conn);
 int connection_or_finished_flushing(or_connection_t *conn);
 int connection_or_finished_connecting(or_connection_t *conn);
+int connection_or_digest_is_known_relay(const char *id_digest);
 
 void connection_or_connect_failed(or_connection_t *conn,
                                   int reason, const char *msg);



You'll notice that I'm again using the consensus to provide a potential
kill switch for this feature -- first, in case it goes horribly wrong,
and second, so that in the distant future when the network topology
is different, we can turn it off smoothly. I decided to make it on by
default rather than off by default (meaning that we don't put anything
in the consensus until we want to turn it off) on the theory that it
will probably work ok, and we will probably not want to turn it off for
quite a while.

The only other question here is how to fail the stream -- that is, what
reason to send back. We still send back END_STREAM_REASON_TORPROTOCOL in
the case of or_circ-&gt;is_first_hop, since that's clearly against what's
written in tor-spec.txt.

Should we reject people not listed in the consensus with
TORPROTOCOL too? The chance of false positives is higher. Check out
edge_reason_is_retriable() in relay.c:

/** Return 1 if reason is something that you should retry if you
 * get the end cell before you've connected; else return 0. */
static int
edge_reason_is_retriable(int reason)
{
  return reason == END_STREAM_REASON_HIBERNATING ||
         reason == END_STREAM_REASON_RESOURCELIMIT ||
         reason == END_STREAM_REASON_EXITPOLICY ||
         reason == END_STREAM_REASON_RESOLVEFAILED ||
         reason == END_STREAM_REASON_MISC;
}

If we want the client to retry the stream somewhere else (to handle false
positives more smoothly), we want to use one of these. RESOURCELIMIT,
EXITPOLICY, and MISC are plausible choices. If we choose EXITPOLICY or
RESOURCELIMIT (but not MISC), we'll call
            policies_set_router_exitpolicy_to_reject_all(exitrouter);
which on first glance seems like a good idea -- it means we will avoid
that router in the future on the theory that one broken attempt is an
indication of future results. (Its exit policy will get reset the next
time a descriptor is parsed for it.) But on further thought, if the
false positives here are randomly distributed, we don't actually want
to avoid that router for a whole day. The ...reject_all() idea was
introduced back in directory v1, when you got a new descriptor for the
relay every hour. With the new microdescriptor plan, you might not
refresh the relay's exit policy for a week.

So I went with MISC.

How's my logic? If you like it, I'll try to summarize it in a comment
when I put the patch in.

--Roger

</body></email><email><emailId>20100222062614</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-22 06:26:14-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>


Thus spake Roger Dingledine (arma@mit.edu):

&gt; On Sun, Dec 13, 2009 at 08:23:14PM -0500, Roger Dingledine wrote:
&gt; &gt; I've been pondering other performance improvements. One of them is to
&gt; &gt; rate-limit client connections as they enter the network. Rate limiting
&gt; &gt; in the Tor client itself would work better, but it's not a very stable
&gt; &gt; equilibrium -- it encourages people to switch to security disasters
&gt; &gt; like tortunnel.
&gt; 
&gt; I talked to Nick about this idea, and he:
&gt; 1) Reminded me about proposal 163. Go read that thread. The main
&gt; difference is that I proposed a "or has a descriptor in its cache"
&gt; check too.
&gt; 2) Demanded that I break out the "is a client" to its own function. Ok.
&gt; 3) Thought it was a fine experiment to do.
&gt; 
&gt; Here's the newer patch:
&gt; 
&gt; http://archives.seul.org/or/cvs/Dec-2009/msg00390.html
&gt; 
&gt; &gt; My main concern here is that I wonder if we are being thorough enough at
&gt; &gt; detecting "is a relay". It checks the consensus and the descriptor cache
&gt; &gt; currently. So if the authorities think you're not Running, they won't put
&gt; &gt; you in the consensus, and no relays will hear about you. If you go up and
&gt; &gt; down, relays that serve dirport info will have your descriptor cached,
&gt; &gt; so they'll recognize you so long as you were around in the past day or so.
&gt; &gt; 
&gt; &gt; Relays that don't serve dirport info will stop fetching descriptors,
&gt; &gt; but they'll continue to fetch the consensus. So they'll still mostly work.
&gt; 
&gt; Soon I would like to make all relays above e.g. 50KB/s cache and serve
&gt; directory info. Having a separate open DirPort is becoming an obsolete
&gt; notion these days anyway now that most Tors use begindir requests over
&gt; the ORPort. Once we do that, these relays will be better at identifying
&gt; who else is a relay. I'd also like to make all relays regardless of their
&gt; dirport status answer begindir requests for their own descriptor. That bug
&gt; is currently preventing people (for example, me while testing censorship
&gt; stuff in Hong Kong) from using relays with no dirport set as bridges.

Just wanted to let you know that this will change how we need to deal
with weighting begindir requests. Right now the check done by clients
is to verify dir_port != 0. This means that if we want clients to be
able to easily adapt to new directory request weights yet still handle
reweighting properly when everyone is a dir mirror, we need to signal
this by specifying some magic dirport number in the consensus.  That,
or we need a different, yet backwards compatible flag in the check.
V2Dir seems the wrong one, but it is all we have now.

http://archives.seul.org/or/dev/Jan-2010/msg00019.html

Thoughts?

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100222064835</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-22 06:48:35-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>


Thus spake Roger Dingledine (arma@mit.edu):

&gt; Hi folks (Nick in particular),
&gt; 
&gt; I've been pondering other performance improvements. One of them is to
&gt; rate-limit client connections as they enter the network. Rate limiting
&gt; in the Tor client itself would work better, but it's not a very stable
&gt; equilibrium -- it encourages people to switch to security disasters
&gt; like tortunnel.
&gt;
&gt; It would impact Mike's bwauthority tests. We'd want to make an exception
&gt; for those Tors. I think we'd leave the torperf deployments alone, since
&gt; after all their goal is to measure "realistic" client performance.

Has code been checked in to handle this case? Otherwise any
experiments you run will be tainted by the bias of the bandwidth
authorites effiectively being disabled, for better or worse.

Also, my opinion is that eventually this value should be set by the
bandwidth authorites. They already measure a network-wide average
stream capacity. It seems to me that this should be the value we cap
long term client streams at, if it turns out that this experiment
improves overall performance. 

It does feel like a hack to compensate for poor flow control to me,
though.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100110224557</emailId><senderName>Michael Reed</senderName><senderEmail>reed@inet.org</senderEmail><timestampReceived>2010-01-10 22:45:57-0400</timestampReceived><subject>GIT repository down?</subject><body>

Things don't seem happy at the moment...

reed@banana-jr:~/$ git clone git://git.torproject.org/git/tor
Initialized empty Git repository in /home/reed/tor/.git/
git.torproject.org[0: 128.31.0.47]: errno=Connection refused
fatal: unable to connect a socket (Connection refused)

</body></email><email><emailId>20100222172344</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-02-22 17:23:44-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

On Sun, Feb 21, 2010 at 11:34 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Sun, Dec 13, 2009 at 08:23:14PM -0500, Roger Dingledine wrote:
&gt;&gt; +  if (r || router_get_consensus_status_by_id(id_digest)) {
&gt;&gt; +    /* It's in the consensus, or we have a descriptor for it meaning it
&gt;&gt; +     * was probably in a recent consensus. It's a recognized relay:
&gt;&gt; +     * give it full bandwidth. */
&gt;&gt; +    conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
&gt;&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst = (int)options-&gt;BandwidthBurst;
&gt;&gt; +  } else { /* Not a recognized relay. Squeeze it down based on the
&gt;&gt; +            * suggested bandwidth parameters in the consensus. */
&gt; [snip]
&gt;&gt; As you can see, I'm making it configurable inside the consensus, so we
&gt;&gt; can experiment with it rather than rolling it out and then changing our
&gt;&gt; minds later. I don't have a good sense of whether it will be a good move,
&gt;&gt; but the only way I can imagine to find out is to try it.
&gt;
&gt; I put that feature into Tor 0.2.2.7-alpha. Now there's a followup feature
&gt; I want to put into 0.2.2.10-alpha:
&gt;
 [...]

The patch looks not implausbile.  Before we merge it and turn it on,
would it be possible to run it on an actual exit node for a day or two
to see how much traffic it actually blocks in practice?

[...]
&gt; The only other question here is how to fail the stream -- that is, what
&gt; reason to send back. We still send back END_STREAM_REASON_TORPROTOCOL in
&gt; the case of or_circ-&gt;is_first_hop, since that's clearly against what's
&gt; written in tor-spec.txt.
&gt;
&gt; Should we reject people not listed in the consensus with
&gt; TORPROTOCOL too? The chance of false positives is higher. Check out
&gt; edge_reason_is_retriable() in relay.c:
&gt;
&gt; /** Return 1 if reason is something that you should retry if you
&gt;  * get the end cell before you've connected; else return 0. */
&gt; static int
&gt; edge_reason_is_retriable(int reason)
&gt; {
&gt;  return reason == END_STREAM_REASON_HIBERNATING ||
&gt;         reason == END_STREAM_REASON_RESOURCELIMIT ||
&gt;         reason == END_STREAM_REASON_EXITPOLICY ||
&gt;         reason == END_STREAM_REASON_RESOLVEFAILED ||
&gt;         reason == END_STREAM_REASON_MISC;
&gt; }
&gt;
&gt; If we want the client to retry the stream somewhere else (to handle false
&gt; positives more smoothly), we want to use one of these. RESOURCELIMIT,
&gt; EXITPOLICY, and MISC are plausible choices. If we choose EXITPOLICY or
&gt; RESOURCELIMIT (but not MISC), we'll call
&gt;            policies_set_router_exitpolicy_to_reject_all(exitrouter);
&gt; which on first glance seems like a good idea -- it means we will avoid
&gt; that router in the future on the theory that one broken attempt is an
&gt; indication of future results. (Its exit policy will get reset the next
&gt; time a descriptor is parsed for it.) But on further thought, if the
&gt; false positives here are randomly distributed, we don't actually want
&gt; to avoid that router for a whole day. The ...reject_all() idea was
&gt; introduced back in directory v1, when you got a new descriptor for the
&gt; relay every hour. With the new microdescriptor plan, you might not
&gt; refresh the relay's exit policy for a week.
&gt;
&gt; So I went with MISC.
&gt;
&gt; How's my logic? If you like it, I'll try to summarize it in a comment
&gt; when I put the patch in.

Your logic seems fine, but it shows a weakness in our protocol: If I
were redesigning this from scratch, I'd want a new "you don't look
like an OR to me!" reason, but we can't introduce new reasons if we
want them to be treated as retriable things by existing clients.

Somebody should write a proposal to carve off unallocated section of
the various end-reason spaces for retriable errors and non-retriable
errors, so that future extensions here can be smarter.

-- 
Nick

</body></email><email><emailId>20100215122544</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-02-15 12:25:44-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>

On Feb 15, 2010, at 3:09 AM, Mike Perry wrote:

&gt; Thus spake Mike Perry (mikeperry@fscked.org):
&gt; 
&gt; &gt; My past few posts to this list have been about developing new formulas
&gt; &gt; for load balancing Tor requests. I've since implemented these formulas
&gt; &gt; in my git branch mikeperry/consensus-bw-weights3. You can get it with:
&gt; &gt; 
&gt; &gt; git clone git://git.torproject.org/git/tor.git tor.git
&gt; &gt; cd tor.git
&gt; &gt; git remote add mikeperry git://git.torproject.org/mikeperry/tor
&gt; &gt; git fetch mikeperry
&gt; &gt; git branch --track mp-consensus-bw-weights3 mikeperry/consensus-bw-weights3
&gt; &gt; git checkout mp-consensus-bw-weights3
&gt; &gt; 
&gt; &gt; X11 users can see the change sets easily with 'gitk'.
&gt; 
&gt; Sebastian requested that I should utilize git to engage in some
&gt; revisionist history and make my branch look a little less
&gt; schizophrenic.
&gt; 
&gt; I've now rebased, split, and squashed all the commits into 8
&gt; logically distinct patches in mikeperry/consensus-bw-weights4.
&gt; Should be easier to review for those who prefer to look at things
&gt; one commit at a time.

I had a quick look at your branch to find similar mistakes as I would make them. I \
should say that I didn't check any of your calculations which are quite hard to get \
started with. So, don't consider this a real code review.

Your last commit breaks test_dir.c which is probably okay, because that commit will \
go away anyway.

I found a comment 'XXX: Should this be+1 for the \n?'. Do you want to make sure \
you're doing the right thing and take this comment out?

In smartlist_choose_by_bandwidth_weights() (and maybe some other places), you might \
write 'weight = is_dir ? Wbd*Wd : Wd;' instead of using if-else. Makes your code \
shorter and easier to read, IMO.

There are some, IMO, unnecessary newlines before closing }'s. I extended the \
check-spaces script as pasted below. I figured it's probably easier for you to put it \
in rather than pulling these few lines from my branch and doing the git black magic \
to remove your last commit before applying mine.

diff --git a/contrib/checkSpace.pl b/contrib/checkSpace.pl
index db061a0..074fb6d 100755
--- a/contrib/checkSpace.pl
+++ b/contrib/checkSpace.pl
@@ -33,6 +33,10 @@ for $fn (@ARGV) {
             print " #else#if:$fn:$.\n";
        }
        $lastline = $_;
+        ## Warn about unnecessary empty lines.
+        if ($lastnil &amp;&amp; /^\s*}\n/) {
+            print "  UnnecNL:$fn:$.\n";
+        }
         ## Warn about multiple empty lines.
         if ($lastnil &amp;&amp; /^$/) {
             print " DoubleNL:$fn:$.\n";

Would it make sense to update the list of consensus methods in dir-spec.txt, section \
3.4.1? It seems that nobody did that for the past few methods, though.

Sometimes you're writing 'if () foo;' in one line which is, IMO, not-so-good coding \
style. I don't know how to tell Perl to detect that, though.

In networkstatus_verify_bw_weights, you have lines like 'if (fabs(Wem - Wee) &gt; 1) {'. \
You are comparing double to int here, which is probably okay, but somewhat bad style, \
IMO. More importantly, if Wem and Wee differ by exactly 1, your condition doesn't \
detect that difference; did you mean '&gt; 0.00001' or something?


These are just minor issues, as you can see. I think the most promising approaches to \
find more bugs would be: 1) write some tests, 2) run the code in a private Tor \
network, 3) ask more people to review your code, and/or 4) just put it in 0.2.2.x and \
hope to find the bugs before 0.2.2.x becomes the new stable. 1) and 2) are probably \
rather painful. If you want to do 2) and need support, please let me know.

--Karsten


</body></email><email><emailId>20100215172206</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-02-15 17:22:06-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>

On Sun, Feb 14, 2010 at 9:09 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt; I've now rebased, split, and squashed all the commits into 8
&gt; logically distinct patches in mikeperry/consensus-bw-weights4.
&gt; Should be easier to review for those who prefer to look at things
&gt; one commit at a time.
&gt;

Ouch.  This is great for people who want to read your patch series de
novo, and it's good for clarity once we merge it into Tor's main
history, but it makes stuff harder for people who've been reviewing
the old patch series unless you say something like, "BTW, commit X in
consensus-bw-weights4 corresponds to exactly the same changes as you
had looked at up until now in consesus-bw-weights3, just cleaned up a
little."

thanks,
-- 
Nick
</body></email><email><emailId>20100215203649</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-15 20:36:49-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>


Thus spake Nick Mathewson (nickm@freehaven.net):

&gt; On Sun, Feb 14, 2010 at 9:09 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; 
&gt; &gt; I've now rebased, split, and squashed all the commits into 8
&gt; &gt; logically distinct patches in mikeperry/consensus-bw-weights4.
&gt; &gt; Should be easier to review for those who prefer to look at things
&gt; &gt; one commit at a time.
&gt; &gt;
&gt; 
&gt; Ouch.  This is great for people who want to read your patch series de
&gt; novo, and it's good for clarity once we merge it into Tor's main
&gt; history, but it makes stuff harder for people who've been reviewing
&gt; the old patch series unless you say something like, "BTW, commit X in
&gt; consensus-bw-weights4 corresponds to exactly the same changes as you
&gt; had looked at up until now in consesus-bw-weights3, just cleaned up a
&gt; little."

Ah yes, the branches should be equivalent and have and empty diff
between them after you rebase both to the latest origin/master (unless
I forgot a push?), but I had commited one or two changes to
consensus-bw-weights3 since you reviewed it. You can do a git fetch of
course to see the new diffs in consesus-bw-weights3. Not sure where
you left off, but the new commits are just the fixes for your code
review and the additional fix to always weight by bandwidth, as I
mentioned on or-talk.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100215212513</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-15 21:25:13-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>


Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; These are just minor issues, as you can see.

I think they are good suggestions. I'll be fixing them soon.

&gt; I think the most promising approaches to find more bugs would be: 1)
&gt; write some tests, 2) run the code in a private Tor network, 3) ask
&gt; more people to review your code, and/or 4) just put it in 0.2.2.x
&gt; and hope to find the bugs before 0.2.2.x becomes the new stable. 1)
&gt; and 2) are probably rather painful. If you want to do 2) and need
&gt; support, please let me know.

Yeah, I am inclined to try to avoid #2 if possible, as I'm not sure
how much that actually buys us for the time investment. So long as
existing clients can properly handle the new consensus documents
without dying, I think it is better if I can devote my time to testing
how our current authority platforms fare in actually computing integer
arithmetic the same, and in writing statistical tests using my
'EXTENDCIRCUIT 0\n' control port patch in my other branch to ensure
that the weights are being used by clients as we expect for the
current network.

I have a feeling that setting up a test tor network large and diverse
enough to perform these tests in a worthwhile fashion will consume
about another week of development time at least, possibly for the both
of us, and if we're not careful about how we do it, it won't tell us
anything new anyways. But maybe I'm just impatient :)

Right now my directory authority is producing votes with the new code,
and it is producing fake consensus v9 documents for purposes of
running the verification code in that branch against them. So far the
consensus is parseable, and the weights being generated do satisfy the
balancing equations from the other thread.

--=20
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100119052934</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-01-19 05:29:34-0400</timestampReceived><subject>Guard selection time and expiry</subject><body>

Hi folks,

Sebastian pointed out that our current guard expiration algorithm has
a bad failure mode.

The current algorithm is that when we pick a guard, we write down into
the state file what month we picked it in. So whether we pick it on Jan
1 or Jan 31, we write down "2010-01-01 00:00:00". We want to expire our
guards after a while though, a) because we may have chosen the guards
based on network weightings from the past, and the network might look
quite different now, and b) because if clients don't give up old guards,
then guards that have been around for a while will just accrue more and
more clients. The current algorithm is to check if
  entry-&gt;chosen_on_date + 3600*24*35 &lt; this_month
That is, Jan 1 + 35 days &lt; start of the current month. So guards that
we picked in January, no matter when in January, will expire the first
time we run our Tor client in March.

So we get two nice privacy properties here. First, somebody examining
your state file on disk only learns to the month granularity about when
you picked that guard. Second, since you're abandoning your guards at a
time not very correlated to when you picked them, nobody watching your
network activity can learn exactly when you picked your guards.

(Side note: the first privacy property isn't as strong as it appears. If
the date is Jan 2, and we see that you have a guard timestamped at
"beginning of January", we are not thrown off very far.)

But the real problem is that half the guards are turning over on the first
of each month. If we're trying to balance the network with Mikeperry's
feedback-based load balancing tricks, then all the users descend on the
guards that happen to be labelled then as "not loaded enough". Whichever
guards were prominent on that particular day get hammered for the next
two months.

The answer is to spread out the rotation event, ideally without
compromising much on the privacy properties, and without deviating too
much from the timing distribution we have now. So:

Option 1: The current algorithm I described above. Minimum time to keep
a guard is 1 month, maximum time is 2 months, expected time according to
the math is 1.5 months, expected time for active Tor clients is more like
2 months (since they'll probably run toward the beginning of each month).

Option 2: Rather than writing "2010-01-01 00:00:00", pick a random time
in January. Then expire the guard 45 days after this random time. Minimum
time to keep a guard is 0.5 months (on Jan 31 I randomly choose to record
Jan 1, and then I discard it on Feb 15), maximum time is 2.5 months (on
Jan 1 I write down Jan 31, and discard it on Mar 15), expected time is
1.5 months.

Option 3: When recording the selection time for the guard, pick a random
timestamp from two weeks in the past to two weeks in the future. Then
discard the guard 45 days after the timestamp. Minimum time is 1 month,
maximum time 2 months, expected time 1.5 months.

Option 2 has the disadvantage of a wider time distribution (if that's
a disadvantage). Other than that, it seems to share exactly whatever
privacy properties we get from Option 1.

Option 3 matches the distribution time, but it has a potential privacy
problem: if I pick three guards at once, somebody examining my state
file can bound the true timeframe. That makes me nervous because it
sounds like one of those messy anonymity issues that gets messier the
more you look at it.

So I'm going to go with option 2. Unless anybody else has clever ideas?

--Roger

</body></email><email><emailId>20100128050407</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-01-28 05:04:07-0400</timestampReceived><subject>Proposal 169: Eliminate TLS renegotiation for the Tor connection</subject><body>

Filename: 169-eliminating-renegotiation.txt
Title: Eliminate TLS renegotiation for the Tor connection handshake
Author: Nick Mathewson
Created: 27-Jan-2010
Status: Draft
Target: 0.2.2

1. Overview

   I propose a backward-compatible change to the Tor connection
   establishment protocol to avoid the use of TLS renegotiation.

   Rather than doing a TLS renegotiation to exchange certificates
   and authenticate the original handshake, this proposal takes an
   approach similar to Steven Murdoch's proposal 124, and uses Tor
   cells to finish authenticating the parties' identities once the
   initial TLS handshake is finished.

   Terminological note: I use "client" below to mean the Tor
   instance (a client or a relay) that initiates a TLS connection,
   and "server" to mean the Tor instance (a relay) that accepts it.

2. Motivation and history

   In the original Tor TLS connection handshake protocol ("V1", or
   "two-cert"), parties that wanted to authenticate provided a
   two-cert chain of X.509 certificates during the handshake setup
   phase.  Every party that wanted to authenticate sent these
   certificates.

   In the current Tor TLS connection handshake protocol ("V2", or
   "renegotiating"), the parties begin with a single certificate
   sent from the server (responder) to the client (initiator), and
   then renegotiated to a two-certs-from-each-authenticating party.
   We made this change to make Tor's handshake look like a browser
   speaking SSL to a webserver.  (See proposal 130, and
   tor-spec.txt.)  To tell whether to use the V1 or V2 handshake,
   servers look at the list of ciphers sent by the client.  (This is
   ugly, but there's not much else in the ClientHello that they can
   look at.) If the list contains any cipher not used by the V1
   protocol, the server sends back a single cert and expects a
   renegotiation.  If the client gets back a single cert, then it
   withholds its own certificates until the TLS renegotiation phase.

   In other words, initiator behavior now looks like this:

      - Begin TLS negotiation with V2 cipher list; wait for
        certificate(s).
      - If we get a certificate chain:
         - Then we are using the V1 handshake.  Send our own
           certificate chain as part of this initial TLS handshake
           if we want to authenticate; otherwise, send no
           certificates.  When the handshake completes, check
           certificates.  We are now mutually authenticated.

        Otherwise, if we get just a single certificate:
         - Then we are using the V2 handshake.  Do not send any
           certificates during this handshake.
         - When the handshake is done, immediately start a TLS
           renegotiation.  During the renegotiation, expect
           a certificate chain from the server; send a certificate
           chain of our own if we want to authenticate ourselves.
         - After the renegotiation, check the certificates. Then
           send (and expect) a VERSIONS cell from the other side to
           establish the link protocol version.

   And V2 responder behavior now looks like this:

      - When we get a TLS ClientHello request, look at the cipher
        list.
      - If the cipher list contains only the V1 ciphersuites:
         - Then we're doing a V1 handshake.  Send a certificate
           chain.  Expect a possible client certificate chain in
           response.
        Otherwise, if we get other ciphersuites:
         - We're using the V2 handshake.  Send back a single
           certificate and let the handshake complete.
         - Do not accept any data until the client has renegotiated.
         - When the client is renegotiating, send a certificate
           chain, and expect (possibly multiple certificates in
           reply).
         - Check the certificates when the renegotiation is done.
           Then exchange VERSIONS cells.

   Late in 2009, researchers found a flaw in most application's use
   of TLS renegotiation: Although TLS renegotiation does not
   reauthenticate any information exchanged before the renegotiation
   takes place, many applications were treating it as though it did,
   and assuming that data sent _before_ the renegotiation was
   authenticated with the credentials negotiated _during_ the
   renegotiation.  This problem was exacerbated by the fact that
   most TLS libraries don't actually give you an obvious good way to
   tell where the renegotiation occurred relative to the datastream.
   Tor wasn't directly affected by this vulnerability, but its
   aftermath hurts us in a few ways:

      1) OpenSSL has disabled renegotiation by default, and created
         a "yes we know what we're doing" option we need to set to
         turn it back on.  (Two options, actually: one for openssl
         0.9.8l and one for 0.9.8m and later.)

      2) Some vendors have removed all renegotiation support from
         their versions of OpenSSL entirely, forcing us to tell
         users to either replace their versions of OpenSSL or to
         link Tor against a hand-built one.

      3) Because of 1 and 2, I'd expect TLS renegotiation to become
         rarer and rarer in the wild, making our own use stand out
         more.

3. Design

3.1. The view in the large

   Taking a cue from Steven Murdoch's proposal 124, I propose that
   we move the work currently done by the TLS renegotiation step
   (that is, authenticating the parties to one another) and do it
   with Tor cells instead of with TLS.

   Using _yet another_ variant response from the responder (server),
   we allow the client to learn that doesn't need to rehandshake,
   and it can use a cell-based authentication system.  Once the
   TLS handshake is done, the client and server exchange VERSIONS
   cells to determine what link protocol version (including
   handshake version).  If they're using the handshake version
   specified here, the client and server arrive at link protocol
   version 3 (or higher), and use cells to exchange further
   authentication information.

3.2. New TLS handshake variant

   We already used the list of ciphers from the clienthello to
   indicate whether the client can speak the V2 ("renegotiating")
   handshake or later, so we can't encode more information there.

   We can, however, change the DN in the certificate passed by the
   server to back the client.  Currently, all V2 certificates are
   generated with CN values ending with ".net".  I propose that we
   have the ".net" commonName ending reserved to indicate the V2
   protocol, and use commonName values ending with ".com" to
   indicate the V3 ("minimal") handshake described herein.

   Now, once the initial TLS handshake is done, the client can look
   at the server's certificate(s).  If there is a certificate chain,
   the handshake is V1.  If there is a single certificate whose
   subject commonName ends in ".net", the handshake is V2 and the
   client should try to renegotiate as it would currently.
   Otherwise, the client should assume that the handshake is V3+.
   [Servers should _only_ send ".com" addesses, to allow room for
   more signaling in the future.]

3.3. Authenticating inside Tor

   Once the TLS handshake is finished, if the client renegotiates,
   then the server should go on as it does currently.

   If the client implements this proposal, however, and the server
   has shown it can understand the V3+ handshake protocol, the
   client immediately sends a VERSIONS cell to the server
   and waits to receive a VERSIONS cell in return.  We negotiate
   the Tor link protocol version _before_ we proceed with the
   negotiation, in case we need to change the authentication
   protocol in the future.

   Once either party has seen the VERSIONS cell from the other, it
   knows which version they will pick (that is, the highest version
   shared by both parties' VERSIONS cells).  All Tor instances using
   the handshake protocol described in 3.2 MUST support at least
   link protocol version 3 as described here.

   On learning the link protocol, the server then sends the client a
   CERT cell and a NETINFO cell.  If the client wants to
   authenticate to the server, it sends a CERT cell, an AUTHENTICATE
   cell, and a NETINFO cell, or it may simply send a NETINFO cell if
   it does not want to authenticate.

   The CERT cell describes the keys that a Tor instance is claiming
   to have.  It is a variable-length cell.  Its payload format is:

        N: Number of certs in cell            [1 octet]
        N times:
           CLEN                               [2 octets]
           Certificate                        [CLEN octets]

   Any extra octets at the end of a CERT cell MUST be ignored.

   Each certificate has the form:

        CertType                              [1 octet]
        CertPurpose                           [1 octet]
        PublicKeyLen                          [2 octets]
        PublicKey                             [PublicKeyLen octets]
        NotBefore                             [4 octets]
        NotAfter                              [4 octets]
        SignerID                              [HASH256_LEN octets]
        SignatureLen                          [2 octets]
        Signature                             [SignatureLen octets]

   where CertType is 1 (meaning "RSA/SHA256")
         CertPurpose is 1 (meaning "link certificate")
         PublicKey is the DER encoding of the ASN.1 representation
            of the RSA key of the subject of this certificate,
         NotBefore is a time in HOURS since January 1, 1970, 00:00
            UTC before which this certificate should not be
            considered valid.
         NotAfter is a time in HOURS since January 1, 1970, 00:00
            UTC after which this certificate should not be
            considered valid.
         SignerID is the SHA-256 digest of the public key signing
            this certificate
         and Signature is the signature of the all other fields in
            this certificate, using SHA256 as described in proposal
            158.

   While authenticating, a server need send only a self-signed
   certificate for its identity key.  (Its TLS certificate already
   contains its link key signed by its identity key.)  A client that
   wants to authenticate MUST send two certificates: one containing
   a public link key signed by its identity key, and one self-signed
   cert for its identity.

   Tor instances MUST ignore any certificate with an unrecognized
   CertType or CertPurpose.

   The AUTHENTICATE cell proves to the server that the client with
   whom it completed the initial TLS handshake is the one possessing
   the link public key in its certificate.  It is a variable-length
   cell.  Its contents are:

        SignatureType                         [2 octets]
        SignatureLen                          [2 octets]
        Signature                             [SignatureLen octets]

   where SignatureType is 1 (meaning "RSA-SHA256") and Signature is
   an RSA-SHA256 signature of the HMAC-SHA256, using the TLS master
   secret key as its key, of the following elements:

     - The SignatureType field (0x00 0x01)
     - The NUL terminated ASCII string: "Tor certificate verification"
     - client_random, as sent in the Client Hello
     - server_random, as sent in the Server Hello

   Once the above handshake is complete, the client knows (from the
   initial TLS handshake) that it has a secure connection to an
   entity that controls a given link public key, and knows (from the
   CERT cell) that the link public key is a valid public key for a
   given Tor identity.

   If the client authenticates, the server learns from the CERT cell
   that a given Tor identity has a given current public link key.
   From the AUTHENTICATE cell, it knows that an entity with that
   link key knows the master secret for the TLS connection, and
   hence must be the party with whom it's talking, if TLS works.

3.4. Security checks

   If the TLS handshake indicates a V2 or V3+ connection, the server
   MUST reject any connection from the client that does not begin
   with either a renegotiation attempt or a VERSIONS cell containing
   at least link protocol version "3".  If the TLS handshake
   indicates a V3+ connection, the client MUST reject any connection
   where the server sends anything before the client has sent a
   VERSIONS cell, and any connection where the VERSIONS cell does
   not contain at least link protocol version "3".

   If link protocol version 3 is chosen:

     Clients and servers MUST check that all digests and signatures
     on the certificates in CERT cells they are given are as
     described above.

     After the VERSIONS cell, clients and servers MUST close the
     connection if anything besides a CERT or AUTH cell is sent
     before the

     CERT or AUTHENTICATE cells anywhere after the first NETINFO
     cell must be rejected.

   ... [write more here.  What else?] ...

3.5. Summary

   We now revisit the protocol outlines from section 2 to incorporate
   our changes.  New or modified steps are marked with a *.

   The new initiator behavior now looks like this:

      - Begin TLS negotiation with V2 cipher list; wait for
        certificate(s).
      - If we get a certificate chain:
         - Then we are using the V1 handshake.  Send our own
           certificate chain as part of this initial TLS handshake
           if we want to authenticate; otherwise, send no
           certificates.  When the handshake completes, check
           certificates.  We are now mutually authenticated.
        Otherwise, if we get just a single certificate:
         - Then we are using the V2 or the V3+ handshake.  Do not
           send any certificates during this handshake.
         * When the handshake is done, look at the server's
           certificate's subject commonName.
           * If it ends with ".net", we're doing a V2 handshake:
             - Immediately start a TLS renegotiation.  During the
               renegotiation, expect a certificate chain from the
               server; send a certificate chain of our own if we
               want to authenticate ourselves.
             - After the renegotiation, check the certificates. Then
               send (and expect) a VERSIONS cell from the other side
               to establish the link protocol version.
           * If it ends with anything else, assume a V3 or later
             handshake:
             * Send a VERSIONS cell, and wait for a VERSIONS cell
               from the server.
             * If we are authenticating, send CERT and AUTHENTICATE
               cells.
             * Send a NETINFO cell.  Wait for a CERT and a NETINFO
               cell from the server.
             * If the CERT cell is a good cert signing the public
               key in the x.509 certificate we got during the TLS
               handshake, we connected to the server with that
               identity key.  Otherwise close the connection.
             * Once the NETINFO cell arrives, continue as before.

   And V3+ responder behavior now looks like this:

      - When we get a TLS ClientHello request, look at the cipher
        list.

      - If the cipher list contains only the V1 ciphersuites:
         - Then we're doing a V1 handshake.  Send a certificate
           chain.  Expect a possible client certificate chain in
           response.
        Otherwise, if we get other ciphersuites:
         - We're using the V2 handshake.  Send back a single
           certificate whose subject commonName ends with ".com",
           and let the handshake complete.
         * If the client does anything besides renegotiate or send a
           VERSIONS cell, drop the connection.
         - If the client renegotiates immediately, it's a V2
           connection:
           - When the client is renegotiating, send a certificate
             chain, and expect (possibly multiple certificates in
             reply).
           - Check the certificates when the renegotiation is done.
             Then exchange VERSIONS cells.
         * Otherwise we got a VERSIONS cell and it's a V3 handshake.
           * Send a VERSIONS cell, a CERT cell, an AUTHENTICATE
             cell, and a NETINFO cell.
           * Wait for the client to send cells in reply.  If the
             client sends a CERT and an AUTHENTICATE and a NETINFO,
             use them to authenticate the client.  If the client
             sends a NETINFO, it is unauthenticated.  If it sends
             anything else before its NETINFO, it's rejected.

4. Numbers to assign

   We need a version number for this link protocol.  I've been
   calling it "3".

   We need to reserve command numbers for CERT and AUTH cells.  I
   suggest that in link protocol 3 and higher, we reserve command
   numbers 128..240 for variable-length cells.  (241-256 we can hold
   for future extensions.

5. Efficiency

   This protocol add a round-trip step when the client sends a
   VERSIONS cell to the server, and waits for the {VERSIONS, CERT,
   NETINFO} response in turn.  (The server then waits for the
   client's {NETINFO} or {CERT, AUTHENTICATE, NETINFO} reply,
   but it would have already been waiting for the client's NETINFO,
   so that's not an additional wait.)

   This is actually fewer round-trip steps than required before for
   TLS renegotiation, so that's a win.

6. Open questions:

  - Should we use X.509 certificates instead of the certificate-ish
    things we describe here?  They are more standard, but more ugly.

  - May we cache which certificates we've already verified?  It
    might leak in timing whether we've connected with a given server
    before, and how recently.

  - Is there a better secret than the master secret to use in the
    AUTHENTICATE cell?  Say, a portable one?  Can we get at it for
    other libraries besides OpenSSL?

  - Does using the client_random and server_random data in the
    AUTHENTICATE message actually help us?  How hard is it to pull
    them out of the OpenSSL data structure?

  - Can we give some way for clients to signal "I want to use the
    V3 protocol if possible, but I can't renegotiate, so don't give
    me the V2"?  Clients currently have a fair idea of server
    versions, so they could potentially do the V3+ handshake with
    servers that support it, and fall back to V1 otherwise.

  - What should servers that don't have TLS renegotiation do?  For
    now, I think they should just get it.  Eventually we can
    deprecate the V2 handshake as we did with the V1 handshake.
</body></email><email><emailId>20100128152130</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-01-28 15:21:30-0400</timestampReceived><subject>Re: Proposal 169: Eliminate TLS renegotiation for the Tor connection</subject><body>


Nick Mathewson wrote:
&gt; Filename: 169-eliminating-renegotiation.txt
&gt; Title: Eliminate TLS renegotiation for the Tor connection handshake
&gt; Author: Nick Mathewson
&gt; Created: 27-Jan-2010
&gt; Status: Draft
&gt; Target: 0.2.2
&gt; 

[...]

&gt;    The new initiator behavior now looks like this:
&gt; 

[...]

&gt;              * If the CERT cell is a good cert signing the public
&gt;                key in the x.509 certificate we got during the TLS
&gt;                handshake, we connected to the server with that
&gt;                identity key.  Otherwise close the connection.


I think this needs to be re-written to be clearer.

&gt;              * Once the NETINFO cell arrives, continue as before.
&gt; 

[...]

&gt; 6. Open questions:
&gt; 
&gt;   - Should we use X.509 certificates instead of the certificate-ish
&gt;     things we describe here?  They are more standard, but more ugly.

Do we get anything out of custom-ish things? It seems kludgy to make
stuff up on the fly but perhaps it's somehow simpler for our use?

&gt; 
&gt;   - May we cache which certificates we've already verified?  It
&gt;     might leak in timing whether we've connected with a given server
&gt;     before, and how recently.

It seems like timing information would be leaked. We should avoid that
if possible.

&gt; 
&gt;   - Is there a better secret than the master secret to use in the
&gt;     AUTHENTICATE cell?  Say, a portable one?  Can we get at it for
&gt;     other libraries besides OpenSSL?
&gt; 

I'm not sure. It seems OK. What worries you about it?


&gt;   - Can we give some way for clients to signal "I want to use the
&gt;     V3 protocol if possible, but I can't renegotiate, so don't give
&gt;     me the V2"?  Clients currently have a fair idea of server
&gt;     versions, so they could potentially do the V3+ handshake with
&gt;     servers that support it, and fall back to V1 otherwise.
&gt; 

Does this open us up to downgrade attacks? Downgrade attacks here seem
like they might range in seriousness from simply potentially detecting
Tor users or perhaps doing something actually nasty...

&gt;   - What should servers that don't have TLS renegotiation do?  For
&gt;     now, I think they should just get it.  Eventually we can
&gt;     deprecate the V2 handshake as we did with the V1 handshake.
&gt; 

Seems reasonable.

Best,
Jake


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100119055858</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-01-19 05:58:58-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

On Tue, Jan 19, 2010 at 12:29:34AM -0500, Roger Dingledine wrote:
&gt; Option 2: Rather than writing "2010-01-01 00:00:00", pick a random time
&gt; in January. Then expire the guard 45 days after this random time. Minimum
&gt; time to keep a guard is 0.5 months (on Jan 31 I randomly choose to record
&gt; Jan 1, and then I discard it on Feb 15), maximum time is 2.5 months (on
&gt; Jan 1 I write down Jan 31, and discard it on Mar 15), expected time is
&gt; 1.5 months.
[snip]
&gt; So I'm going to go with option 2. Unless anybody else has clever ideas?

The code in either case is really easy. Here's a patch on master:
(I realize that not all months have 30 days, but I think the assumption
doesn't hurt anything here. Also, I realize there's another place where
we pick a chosen_on_date, but I think that's an edge case that can
be ignored. And thirdly, I think this patch could go into maint-0.2.1
safely; in any case, the right time for it to go in is alongside the
patch to bug 1217.)

diff --git a/src/or/circuitbuild.c b/src/or/circuitbuild.c
index 7eafeb3..d27a47d 100644
--- a/src/or/circuitbuild.c
+++ b/src/or/circuitbuild.c
@@ -3022,7 +3022,10 @@ add_an_entry_guard(routerinfo_t *chosen, int reset_status
   log_info(LD_CIRC, "Chose '%s' as new entry guard.", router-&gt;nickname);
   strlcpy(entry-&gt;nickname, router-&gt;nickname, sizeof(entry-&gt;nickname));
   memcpy(entry-&gt;identity, router-&gt;cache_info.identity_digest, DIGEST_LEN);
-  entry-&gt;chosen_on_date = start_of_month(time(NULL));
+  /* Choose expiry time smudged over this month. For details, see
+   * http://archives.seul.org/or/dev/Jan-2010/msg00004.html */
+  entry-&gt;chosen_on_date = start_of_month(time(NULL)) +
+                          crypto_rand_int(3600*24*30);
   entry-&gt;chosen_by_version = tor_strdup(VERSION);
   if (chosen) /* prepend */
     smartlist_insert(entry_guards, 0, entry);
@@ -3074,7 +3077,7 @@ static int
 remove_obsolete_entry_guards(void)
 {
   int changed = 0, i;
-  time_t this_month = start_of_month(time(NULL));
+  time_t now = time(NULL);

   for (i = 0; i &lt; smartlist_len(entry_guards); ++i) {
     entry_guard_t *entry = smartlist_get(entry_guards, i);
@@ -3094,9 +3097,8 @@ remove_obsolete_entry_guards(void)
                 !tor_version_as_new_as(ver, "0.2.0.6-alpha"))) {
       msg = "was selected without regard for guard bandwidth";
       version_is_bad = 1;
-    } else if (entry-&gt;chosen_on_date + 3600*24*35 &lt; this_month) {
-      /* It's been more than a month, and probably more like two since
-       * chosen_on_date is clipped to the beginning of its month. */
+    } else if (entry-&gt;chosen_on_date + 3600*24*45 &lt; now) {
+      /* It's been 1.5 months since the date listed in our state file. */
       msg = "was selected several months ago";
       date_is_bad = 1;
     }
</body></email><email><emailId>20100121001733</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-01-21 00:17:33-0400</timestampReceived><subject>Node-Weight Balancing Corrections</subject><body>


For purposes of load balancing, exit and guard node node bandwidths
are weighted by fractional values when they are probabilistically
selected for circuit positions other than their primary purpose. This
done is to govern scarcity and properly distribute load amongst the
node classes.

The exit weight and guard weight are both currently computed from the
formulas in: http://archives.seul.org/or/dev/Jul-2007/msg00056.html
and http://archives.seul.org/or/dev/Jul-2007/msg00021.html.

We unfortunately made two oversights in the derivation of these
formulas. Firstly, exit-only nodes cannot be placed in the Entry
position, and Guard-only nodes cannot be placed in the Exit position.
Secondly, Guard+Exit flagged nodes are not properly used in many cases
of scarcity.

These oversights are evident in measurement results and in review of
the source code. 

While looking over data for Bug 1217
(https://bugs.torproject.org/flyspray/index.php?do=details&amp;id=1217), I
discovered that nodes that were flagged for both Guard and Exit seemed
to be being rated as significantly less loaded by the bandwidth
authorities than either Guards or Exits alone. I also noticed that
Guard, Middle, and Exit capacity measurements were vastly different on
average. These measurements were observed using the consensus
statistic gathering script in TorFlow:
https://svn.torproject.org/svn/torflow/trunk/NetworkScanners/statsplitter.py

The source code actually has three implementations of the above
formulas: one for guards, one for exits, and one for guard+exits
(which is simply a multiplication of the exit and guard result).

After spot-checking the source against different edge cases, it
quickly became apparent that for the case when either or both Guards
or Exits were scarce, we were not properly weighting Guard+Exit nodes
in smartlist_choose_by_bandwidth(). This can be seen by considering
what happens when exit_weight=0 and/or guard_weight=0 in that
function:

 if (is_exit &amp;&amp; is_guard)
   bw = ((uint64_t)(bandwidths[i] * exit_weight * guard_weight));

Because of the multiplication, the result is that when both guards and
exits are scarce, Exit+Guard nodes cannot be used for either the Exit
or the Guard position. Additionally, they are not considered at their
full bandwidth weight for the exit position if exits but not guards
are scarce. Similarly, they are not properly weighted for the guard
position if guards but not exits are scarce. This is obviously wrong.


To derive the correct formulas for weighting Guard, Exit, and
Guard+Exit nodes, we actually need to consider four separate cases of
Exit and Guard capacity:

1. Neither are scarce
2. Both Guard and Exit are scarce
3. One of Guard or Exit is scarce


Case 1: Neither are scarce

This is the most general case, and also the most common for the
current Tor network.

Let G be the total Guard-only capacity.
Let M be the total capacity of all Middle-only nodes.
Let E be the total Exit-only capacity.
Let D be the total Exit+Guard capacity (Dual-flagged nodes)
Let T be the total network capacity.

Note that M, E, G, and D are disjoint, and thus:
 T = G + M + E + D

If neither Guards nor Exits are scarce, we know that E &gt; T/3 and 
G &gt; T/3. Therefore the remainder of the bandwidth for middle nodes
must be M+D &lt; T/3. In this case, it is relatively easy to see that the
Guard+Exit bandwidth could be devoted exclusively to the middle
position.

However, this will reduce entropy in the network, and exclude some
potentially scarce, stable Exit+Guard nodes from ever being used as
Exits. Let's instead divide the Exit+Guard bandwidth equally between
the Guard, Middle, and Exit positions in this case.

In order to do this, we want to define a set of constraints such that
the amount of bandwidth from Guard (G), Middle (M), Exit (E), and
Guard+Exit (D) nodes devoted to the entry, middle, and exit positions
are equal.

Let Wgd be the weight for choosing a Guard+Exit for the guard position.
Let Wmd be the weight for choosing a Guard+Exit for the middle position.
Let Wed be the weight for choosing a Guard+Exit for the exit position.

Let Wme be the weight for choosing an Exit for the middle position.
Let Wmg be the weight for choosing a Guard for the middle position.

Let Wgg be the weight for choosing a Guard for the guard position.
Let Wee be the weight for choosing an Exit for the exit position.

The allocation equality condition is then:

  Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G   (guard bw = middle bw)
  Wgg*G + Wgd*D = Wee*E + Wed*D               (guard bw = exit bw)

We also want to constrain the Guard+Exit weights to divide the
bandwidth equally between the entry, middle, and exit positions:

  Wed*D + Wmd*D + Wgd*D = D               (aka: Wed + Wmd + Wdg = 1)
  Wed = Wmd = Wgd = 1/3

Also, since the amount of Guard and Exit bandwidth placed on the
middle node is also removed from the entry and exit positions:

  Wmg*G + Wgg*G = G                       (aka: Wgg = 1-Wmg)
  Wme*E + Wee*E = E                       (aka: Wee = 1-Wme)

We can then simplify down to 2 equations with 2 unknowns:

  1. (1-Wme)*E + D/3 = (1-Wmg)*G + D/3
  2. (1-Wmg)*G + D/3 = M + D/3 + Wme*E + Wmg*G

Solving these two equations gives:

  Wmg = (2G - E - M)/3G
  Wme = (2E - M - G)/3E

Here is a Mathematica line to verify this from the general formula:
Reduce[{Wgg*G + Wgd*D == M + Wmd*D + Wme*E + Wmg*G,
        Wgg*G + Wgd*D == Wee*E + Wed*D,
        Wed*D + Wmd*D + Wgd*D == D,
        Wed == Wmd, Wmd == Wgd, Wgd == 1/3,
        Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
        {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]


Case 2: Both Guards and Exits are scarce

If both exits and guards are scarce, we need to determine weightings
to distribute the Exit+Guard bandwidth evenly between the guard and
exit positions, and ignore the middle position. First, we should
consider some subcases.

Let R denote the more scarce class (Rare) between Guard vs Exit.
Let S denote the less scarce class.

Subcase a: R+D &lt;= S

For this case, we should simply devote all of D to the more scarce
condition. This is because we don't have enough Exit+Guard bandwidth
to make the more-scarce position have as much capacity as the
less-scarce one.

Subcase b: R+D &gt; S

For this case, we should divide D to make the two scarce classes
equal.

Using Case 1's General Form:

  Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
  Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
  Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
  Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
  Wee = 1-Wme                                  (Wme*E + Wee*E = E)

We want guard bandwidth to equal exit bandwidth, and also:
   Wgg = Wee = 1 and Wme = Wmg = Wmd = 0.

Therefore, we know we want the following two equations to hold:
   1.   G +     Wgd*D = E + Wed*D     (guard bw = exit bw)
   2.   Wed*D + Wgd*D = D             (properly divide D)

Solving for Wed by adding 1+2:
    2*Wed*D + E + Wgd*D = G + Wgd*D + D
    2*Wed*D = G + D - E
    Wed = (G+D-E)/2D
    Wed = (G-E)/2D + 1/2

Solving for Wgd by rewriting 2 as Wgd=1-Wed:
    Wgd = 1-(G+D-E)/2D
    Wgd = (E+D-G)/2D
    Wgd = (E-G)/2D + 1/2

Here is a Mathematica line to verify this:
Reduce[{G + Wgd*D == E + Wed*D,
        Wed*D + Wgd*D == D},
       {Wed, Wgd}]


Case 3: One of Exit or Guard is scarce

If only one of exits or guards are scarce, we want to proceed
similarly as Case 2.

Let S be the scarce class.

This has two subcases:

Subcase a: S+D &lt; T/3

In this case, we can simply treat D as the scarce class, and attempt
to balance the load between the non-scarce class and the middle nodes.
For simplification's sake, lets say S=G.

Using Case 1's General Form:

  Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
  Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
  Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
  Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
  Wee = 1-Wme                                  (Wme*E + Wee*E = E)

We then want Wgg = Wgd = 1 and Wmd = Wed = Wmg = 0.

We're now left with:

  G + D &lt; M + Wme*E                            (guard bw &lt; middle bw)
  G + D &lt; Wee*E                                (guard bw &lt; exit bw)
  M + Wme = Wee*E                              (middle bw = exit bw)
  Wee = 1-Wme                                  (Wme*E + Wee*E = E)

Which is only two equations with two unknowns.

Solving for Wme:

  M + Wme = (1-Wme)*E
  M + Wme = E - Wme*E
  Wme + Wme*E = E - M
  (1+E)*Wme = E-M
  Wme = (E-M)/(1+E)

  Wee = (1+E)/(1+E) - (E-M)/(1+E)
  Wee = (1+M)/(1+E)
  
Here is a Mathematica line to verify this:
Reduce[{M + Wme == Wee*E, Wee == 1-Wme}, {Wme, Wee}]

Subcase b: S+D &gt;= T/3

In this case, the formerly scarce class is no longer scarce, and now
we have a condition that is similar to Case 1 with the exception that
we want to change the D weighting from 1/3 for position S to whatever
quantity brings it up to T/3. For simplification's sake, lets say S=G:

  G+Wgd*D = T/3                                (guard bw = T/3)
  Wgd = (T/3-G)/D

Using Case 1's General Form:

  Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
  Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
  Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
  Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
  Wee = 1-Wme                                  (Wme*E + Wee*E = E)

We then want Wgg = 1 and Wmg = 0.

We can then evenly divide D between middle and exit positions:

  Wed = Wmd

We're now left with:

  G + Wgd*D = M + Wed*D + Wme*E
  G + Wgd*D = (1-Wme)*E + Wed*D
  2*Wed*D + Wgd*D = D
  Wgd = (T/3-G)/D

This gives:
 
  Wed = 1/2 - (T/3-G)/2D
  Wme = (E-M)/2E

Here is a Mathematica line to verify this:
Reduce[{G + Wgd*D == M + Wed*D + Wme*E,
        G + Wgd*D == (1-Wme)*E + Wed*D,
        2*Wed*D + Wgd*D == D,
        Wgd == (T/3-G)/D,
        T == G + M + E + D},
        {Wed, Wme, Wgd}]

 
Implementation Notes:

The current smartlist_choose_by_bandwidth() calculates Guard, Exit,
and Total bandwidth based on the smartlist passed in, which has
already been restricted to viable nodes. We'll need to refactor this
function to receive G, E, M, D and T as parameters independent of the
current node selection list, which is a local position property
independent from the global capacity and balance of the network.

Furthermore, even these weights are approximate, because in actual
operation not all Exit nodes are equal. In fact, some nodes lack an
Exit flag, but still contribute Exit bandwidth for certain ports. We
could envision dividing the classes such that E and D are counted only
for the current exit port instead of purely based on flag, but this is
not always known at time of circuit construction.

The implementation should verify that the total weighted bandwidth
available to each position is properly balanced according to the
current scarcity case of the network. This will be difficult to do in
a unit test, but there should be debug ifdefs on non-release Tors to
check these conditions on the current consensus during selection.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100121022351</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-01-21 02:23:51-0400</timestampReceived><subject>Re: Node-Weight Balancing Corrections</subject><body>

On Wed, Jan 20, 2010 at 7:17 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; For purposes of load balancing, exit and guard node node bandwidths
&gt; are weighted by fractional values when they are probabilistically
&gt; selected for circuit positions other than their primary purpose. This
&gt; done is to govern scarcity and properly distribute load amongst the
&gt; node classes.
 [...]
&gt; The current smartlist_choose_by_bandwidth() calculates Guard, Exit,
&gt; and Total bandwidth based on the smartlist passed in, which has
&gt; already been restricted to viable nodes. We'll need to refactor this
&gt; function to receive G, E, M, D and T as parameters independent of the
&gt; current node selection list, which is a local position property
&gt; independent from the global capacity and balance of the network.
&gt;
&gt; Furthermore, even these weights are approximate, because in actual
&gt; operation not all Exit nodes are equal. In fact, some nodes lack an
&gt; Exit flag, but still contribute Exit bandwidth for certain ports. We
&gt; could envision dividing the classes such that E and D are counted only
&gt; for the current exit port instead of purely based on flag, but this is
&gt; not always known at time of circuit construction.
&gt;
&gt; The implementation should verify that the total weighted bandwidth
&gt; available to each position is properly balanced according to the
&gt; current scarcity case of the network. This will be difficult to do in
&gt; a unit test, but there should be debug ifdefs on non-release Tors to
&gt; check these conditions on the current consensus during selection.

Nice. Your reasoning seems correct, though I haven't doublechecked your math.

For implementation, I'm wondering if we can't push the complexity to
the authority side and have clients look at a parameter or set of
per-router values derived by the authorities, so that if we want to
change the weighting algorithm even more in the  future we can.

For unit testing, it probably makes sense to split the function into
two parts, one of which calculates node weights, and one of which
picks nodes by weight?  This should be good enough to confirm that our
code really does as specified.  To confirm that the spec is correct,
I'd think it would be smarter to write a simulation script to see how
the specified load balancing works in practice.

Also, once we've finalized the formulas here, they should all go into
path-spec.txt .

peace,
-- 
Nick
</body></email><email><emailId>20100128023024</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-01-28 02:30:24-0400</timestampReceived><subject>Re: Node-Weight Balancing Corrections</subject><body>


Since no one is likely to review this math except for me, I decided to
write mathematica commands to verify all the cases directly from the
General Form in Case 1. While doing this and writing the
implementation, I noticed one error, and a few edge cases. They are
documented below.

Thus spake Mike Perry (mikeperry@fscked.org):

&gt; Case 2: Both Guards and Exits are scarce
&gt; 
&gt; If both exits and guards are scarce, we need to determine weightings
&gt; to distribute the Exit+Guard bandwidth evenly between the guard and
&gt; exit positions, and ignore the middle position. First, we should
&gt; consider some subcases.
&gt; 
&gt; Let R denote the more scarce class (Rare) between Guard vs Exit.
&gt; Let S denote the less scarce class.
&gt; 
&gt; Subcase a: R+D &lt;= S
&gt; 
&gt; For this case, we should simply devote all of D to the more scarce
&gt; condition. This is because we don't have enough Exit+Guard bandwidth
&gt; to make the more-scarce position have as much capacity as the
&gt; less-scarce one.

For reference, this is: Wgg = Wee = 1; Wmg = Wme = Wmd = 0;

And then, if R=E: Wed = 1; Wgd = 0;
or if R=G: Wed = 0; Wgd = 1;

&gt; Subcase b: R+D &gt; S
&gt; 
&gt; For this case, we should divide D to make the two scarce classes
&gt; equal.
&gt; 
&gt; Using Case 1's General Form:
&gt; 
&gt;   Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
&gt;   Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
&gt;   Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
&gt;   Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
&gt;   Wee = 1-Wme                                  (Wme*E + Wee*E = E)
&gt; 
&gt; We want guard bandwidth to equal exit bandwidth, and also:
&gt;    Wgg = Wee = 1 and Wme = Wmg = Wmd = 0.
&gt; 
&gt; Therefore, we know we want the following two equations to hold:
&gt;    1.   G +     Wgd*D = E + Wed*D     (guard bw = exit bw)
&gt;    2.   Wed*D + Wgd*D = D             (properly divide D)
&gt; 
&gt; Solving for Wed by adding 1+2:
&gt;     2*Wed*D + E + Wgd*D = G + Wgd*D + D
&gt;     2*Wed*D = G + D - E
&gt;     Wed = (G+D-E)/2D
&gt;     Wed = (G-E)/2D + 1/2
&gt; 
&gt; Solving for Wgd by rewriting 2 as Wgd=1-Wed:
&gt;     Wgd = 1-(G+D-E)/2D
&gt;     Wgd = (E+D-G)/2D
&gt;     Wgd = (E-G)/2D + 1/2
&gt; 
&gt; Here is a Mathematica line to verify this:
&gt; Reduce[{G + Wgd*D == E + Wed*D,
&gt;         Wed*D + Wgd*D == D},
&gt;        {Wed, Wgd}]

Here's a mathematica line to verify it from the General Form:
Reduce[{Wgg*G + Wgd*D == Wee*E + Wed*D,
        Wed*D + Wmd*D + Wgd*D == D,
        Wgg == Wee, Wee == 1,
        Wme == Wmd, Wmd == Wmg, Wme == 0,
        Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
        {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]

The result is the same, but since nobody will likely review this math
except me, its nice to have a full verification handy.

&gt; Case 3: One of Exit or Guard is scarce
&gt; 
&gt; If only one of exits or guards are scarce, we want to proceed
&gt; similarly as Case 2.
&gt; 
&gt; Let S be the scarce class.
&gt; 
&gt; This has two subcases:
&gt; 
&gt; Subcase a: S+D &lt; T/3
&gt; 
&gt; In this case, we can simply treat D as the scarce class, and attempt
&gt; to balance the load between the non-scarce class and the middle nodes.
&gt; For simplification's sake, lets say S=G.
&gt; 
&gt; Using Case 1's General Form:
&gt; 
&gt;   Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
&gt;   Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
&gt;   Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
&gt;   Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
&gt;   Wee = 1-Wme                                  (Wme*E + Wee*E = E)
&gt; 
&gt; We then want Wgg = Wgd = 1 and Wmd = Wed = Wmg = 0.
&gt; 
&gt; We're now left with:
&gt; 
&gt;   G + D &lt; M + Wme*E                            (guard bw &lt; middle bw)
&gt;   G + D &lt; Wee*E                                (guard bw &lt; exit bw)
&gt;   M + Wme = Wee*E                              (middle bw = exit bw)
&gt;   Wee = 1-Wme                                  (Wme*E + Wee*E = E)
&gt; 
&gt; Which is only two equations with two unknowns.
&gt; 
&gt; Solving for Wme:
&gt; 
&gt;   M + Wme = (1-Wme)*E
&gt;   M + Wme = E - Wme*E   (Typo! Missed an E!)
&gt;   Wme + Wme*E = E - M
&gt;   (1+E)*Wme = E-M
&gt;   Wme = (E-M)/(1+E)
&gt; 
&gt;   Wee = (1+E)/(1+E) - (E-M)/(1+E)
&gt;   Wee = (1+M)/(1+E)
&gt;   
&gt; Here is a Mathematica line to verify this:
&gt; Reduce[{M + Wme == Wee*E, Wee == 1-Wme}, {Wme, Wee}]

This was actually incorrect due to a typo in the second line. When I
wrote the mathematica reduce command to verify the entire derivation, I
got a different result. Here is that command:
Reduce[{M + Wmd*D + Wme*E + Wmg*G == Wee*E + Wed*D,
        Wed*D + Wmd*D + Wgd*D == D,
        Wgg == Wgd, Wgd == 1,
        Wmd == Wed, Wmd == Wmg, Wmg == 0,
        Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
        {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]

Solving for Wme and Wee:

  M + Wme = (1-Wme)*E
  M + Wme*E = E - Wme*E   (Typo in original formula. Missed an E)
  2*Wme*E = E - M
  (2*E)*Wme = E-M
  Wme = (E-M)/(2E)
  Wee = 1-Wme
  
&gt; Subcase b: S+D &gt;= T/3
&gt; 
&gt; In this case, the formerly scarce class is no longer scarce, and now
&gt; we have a condition that is similar to Case 1 with the exception that
&gt; we want to change the D weighting from 1/3 for position S to whatever
&gt; quantity brings it up to T/3. For simplification's sake, lets say S=G:
&gt; 
&gt;   G+Wgd*D = T/3                                (guard bw = T/3)
&gt;   Wgd = (T/3-G)/D
&gt; 
&gt; Using Case 1's General Form:
&gt; 
&gt;   Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
&gt;   Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
&gt;   Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
&gt;   Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
&gt;   Wee = 1-Wme                                  (Wme*E + Wee*E = E)
&gt; 
&gt; We then want Wgg = 1 and Wmg = 0.
&gt; 
&gt; We can then evenly divide D between middle and exit positions:
&gt; 
&gt;   Wed = Wmd
&gt; 
&gt; We're now left with:
&gt; 
&gt;   G + Wgd*D = M + Wed*D + Wme*E
&gt;   G + Wgd*D = (1-Wme)*E + Wed*D
&gt;   2*Wed*D + Wgd*D = D
&gt;   Wgd = (T/3-G)/D
&gt; 
&gt; This gives:
&gt;  
&gt;   Wed = 1/2 - (T/3-G)/2D
&gt;   Wme = (E-M)/2E
&gt; 
&gt; Here is a Mathematica line to verify this:
&gt; Reduce[{G + Wgd*D == M + Wed*D + Wme*E,
&gt;         G + Wgd*D == (1-Wme)*E + Wed*D,
&gt;         2*Wed*D + Wgd*D == D,
&gt;         Wgd == (T/3-G)/D,
&gt;         T == G + M + E + D},
&gt;         {Wed, Wme, Wgd}]

Reduce[{Wgg*G + Wgd*D == M + Wmd*D + Wme*E + Wmg*G,
        Wgg*G + Wgd*D == Wee*E + Wed*D,
        Wed*D + Wmd*D + Wgd*D == D,
        Wgg == 1, Wmg == 0, Wed == Wmd,
        Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
        {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]

Result is the same.
 
&gt; Implementation Notes:

When D is 0, the denominator of some of those equations is zero. In
those cases, simply setting the Wxd weights to zero is acceptable,
since there is no D bandwidth to distribute. 

There are also edge cases when E &lt; M or G &lt; M in Case 3a and 3b, which
leads to a negative result. In those cases, setting Wme or Wmg to 0 is
fine, because we do not want to devote any bandwidth to an already
large middle position capacity.



-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100119162525</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2010-01-19 16:25:25-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

Hi Roger et al.,

On Tue, Jan 19, 2010 at 12:29:34AM -0500, Roger Dingledine wrote:
&gt; 
&gt; Option 2: Rather than writing "2010-01-01 00:00:00", pick a random time
&gt; in January. Then expire the guard 45 days after this random time. Minimum
&gt; time to keep a guard is 0.5 months (on Jan 31 I randomly choose to record
&gt; Jan 1, and then I discard it on Feb 15), maximum time is 2.5 months (on
&gt; Jan 1 I write down Jan 31, and discard it on Mar 15), expected time is
&gt; 1.5 months.
&gt; 
&gt; Option 3: When recording the selection time for the guard, pick a random
&gt; timestamp from two weeks in the past to two weeks in the future. Then
&gt; discard the guard 45 days after the timestamp. Minimum time is 1 month,
&gt; maximum time 2 months, expected time 1.5 months.
&gt; 
&gt; Option 2 has the disadvantage of a wider time distribution (if that's
&gt; a disadvantage). Other than that, it seems to share exactly whatever
&gt; privacy properties we get from Option 1.
&gt; 
&gt; Option 3 matches the distribution time, but it has a potential privacy
&gt; problem: if I pick three guards at once, somebody examining my state
&gt; file can bound the true timeframe. That makes me nervous because it
&gt; sounds like one of those messy anonymity issues that gets messier the
&gt; more you look at it.
&gt; 
&gt; So I'm going to go with option 2. Unless anybody else has clever ideas?
&gt; 

Ideas, probably not clever. I'm confused by the potential problem you
cite for option 3. In option 2, somebody examining your state file
will know that these three guards were chosen during January.  If the
file is examined on January 2, for example, the attacker will know
exactly what day the nodes were picked. And he can also bound the true
timeframe for any date in January later than the actual date.  By
contrast, in option 3, the best he can do is know that the nodes were
chosen not more than two weeks in the past. So with option 2 he could
potentially know more. He also knows what time of the month these
attacks are most effective.

Why not combine the two options?
Pick a random timestamp during the last four weeks and an expiry 45
days in the future of the timestamp. (Or if you don't like the resulting
expected expiry time or range, make it 60 days or some other time
after the timestamp.) Note that if your timestamps just happen to all
be recent, he will know that, but with option 2 there are times when
this is guaranteed to work rather than just occasional luck. If you
want to make even this less likely you could add a check that at least
one timestamp must be more than some amount old and then throw out the
the third chosen guard's timestamp if none are old enough and pick
again. Don't know if that seems to complex, and this is after reading
your message and responding immediately. Might be problems if I
thought about it more.

HTH,
Paul
</body></email><email><emailId>20100119165159</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2010-01-19 16:51:59-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>


On Jan 19, 2010, at 5:25 PM, Paul Syverson wrote:

&gt; Hi Roger et al.,
&gt;
&gt; On Tue, Jan 19, 2010 at 12:29:34AM -0500, Roger Dingledine wrote:
&gt;&gt;
&gt;&gt; Option 2: Rather than writing "2010-01-01 00:00:00", pick a random  
&gt;&gt; time
&gt;&gt; in January. Then expire the guard 45 days after this random time.  
&gt;&gt; Minimum
&gt;&gt; time to keep a guard is 0.5 months (on Jan 31 I randomly choose to  
&gt;&gt; record
&gt;&gt; Jan 1, and then I discard it on Feb 15), maximum time is 2.5 months  
&gt;&gt; (on
&gt;&gt; Jan 1 I write down Jan 31, and discard it on Mar 15), expected time  
&gt;&gt; is
&gt;&gt; 1.5 months.
&gt;&gt;
&gt;&gt; Option 3: When recording the selection time for the guard, pick a  
&gt;&gt; random
&gt;&gt; timestamp from two weeks in the past to two weeks in the future. Then
&gt;&gt; discard the guard 45 days after the timestamp. Minimum time is 1  
&gt;&gt; month,
&gt;&gt; maximum time 2 months, expected time 1.5 months.
&gt;&gt;
&gt;&gt; Option 2 has the disadvantage of a wider time distribution (if that's
&gt;&gt; a disadvantage). Other than that, it seems to share exactly whatever
&gt;&gt; privacy properties we get from Option 1.
&gt;&gt;
&gt;&gt; Option 3 matches the distribution time, but it has a potential  
&gt;&gt; privacy
&gt;&gt; problem: if I pick three guards at once, somebody examining my state
&gt;&gt; file can bound the true timeframe. That makes me nervous because it
&gt;&gt; sounds like one of those messy anonymity issues that gets messier the
&gt;&gt; more you look at it.
&gt;&gt;
&gt;&gt; So I'm going to go with option 2. Unless anybody else has clever  
&gt;&gt; ideas?
&gt;&gt;
&gt;
&gt; Ideas, probably not clever. I'm confused by the potential problem you
&gt; cite for option 3. In option 2, somebody examining your state file
&gt; will know that these three guards were chosen during January.  If the
&gt; file is examined on January 2, for example, the attacker will know
&gt; exactly what day the nodes were picked. And he can also bound the true
&gt; timeframe for any date in January later than the actual date.  By
&gt; contrast, in option 3, the best he can do is know that the nodes were
&gt; chosen not more than two weeks in the past. So with option 2 he could
&gt; potentially know more. He also knows what time of the month these
&gt; attacks are most effective.

I think the idea is like this: Today is January 14, and you choose  
according to method 3. You pick Jan 2, Jan 6 and Jan 27. The attacker  
now knows that you picked guards in a timeframe between Jan 13-15,  
because otherwise you couldn't have picked those three dates.

&gt; Why not combine the two options?
&gt; Pick a random timestamp during the last four weeks and an expiry 45
&gt; days in the future of the timestamp. (Or if you don't like the  
&gt; resulting
&gt; expected expiry time or range, make it 60 days or some other time
&gt; after the timestamp.) Note that if your timestamps just happen to all
&gt; be recent, he will know that, but with option 2 there are times when
&gt; this is guaranteed to work rather than just occasional luck. If you
&gt; want to make even this less likely you could add a check that at least
&gt; one timestamp must be more than some amount old and then throw out the
&gt; the third chosen guard's timestamp if none are old enough and pick
&gt; again. Don't know if that seems to complex, and this is after reading
&gt; your message and responding immediately. Might be problems if I
&gt; thought about it more.

This scheme shares a similar problem: Today is Jan 28, and you pick  
Jan 4, Jan 12 and Jan 26. The attacker now knows that the timeframe is  
Jan 26 to Feb 1.

I wonder how much this actually matters, though. Both of Roger's  
schemes pick dates that might be in the future (up to two weeks for  
scheme 3, up to one month for scheme 2), so if an adversary gets a  
hold of your state file, the dates are obviously false. After two and  
a half months (or less time), though, our guard selection changes, so  
it seems that with a good probability, the adversary will learn  
something valuable from our state file regardless.

Am I missing something?

Sebastian
</body></email><email><emailId>20100119174635</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2010-01-19 17:46:35-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

On Tue, Jan 19, 2010 at 05:51:59PM +0100, Sebastian Hahn wrote:
&gt;
&gt; On Jan 19, 2010, at 5:25 PM, Paul Syverson wrote:
&gt;
&gt;&gt; Hi Roger et al.,
&gt;&gt;
&gt;&gt; On Tue, Jan 19, 2010 at 12:29:34AM -0500, Roger Dingledine wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Option 2: Rather than writing "2010-01-01 00:00:00", pick a random time
&gt;&gt;&gt; in January. Then expire the guard 45 days after this random time. Minimum
&gt;&gt;&gt; time to keep a guard is 0.5 months (on Jan 31 I randomly choose to record
&gt;&gt;&gt; Jan 1, and then I discard it on Feb 15), maximum time is 2.5 months (on
&gt;&gt;&gt; Jan 1 I write down Jan 31, and discard it on Mar 15), expected time is
&gt;&gt;&gt; 1.5 months.
&gt;&gt;&gt;
&gt;&gt;&gt; Option 3: When recording the selection time for the guard, pick a random
&gt;&gt;&gt; timestamp from two weeks in the past to two weeks in the future. Then
&gt;&gt;&gt; discard the guard 45 days after the timestamp. Minimum time is 1 month,
&gt;&gt;&gt; maximum time 2 months, expected time 1.5 months.
&gt;&gt;&gt;
&gt;&gt;&gt; Option 2 has the disadvantage of a wider time distribution (if that's
&gt;&gt;&gt; a disadvantage). Other than that, it seems to share exactly whatever
&gt;&gt;&gt; privacy properties we get from Option 1.
&gt;&gt;&gt;
&gt;&gt;&gt; Option 3 matches the distribution time, but it has a potential privacy
&gt;&gt;&gt; problem: if I pick three guards at once, somebody examining my state
&gt;&gt;&gt; file can bound the true timeframe. That makes me nervous because it
&gt;&gt;&gt; sounds like one of those messy anonymity issues that gets messier the
&gt;&gt;&gt; more you look at it.
&gt;&gt;&gt;
&gt;&gt;&gt; So I'm going to go with option 2. Unless anybody else has clever ideas?
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Ideas, probably not clever. I'm confused by the potential problem you
&gt;&gt; cite for option 3. In option 2, somebody examining your state file
&gt;&gt; will know that these three guards were chosen during January.  If the
&gt;&gt; file is examined on January 2, for example, the attacker will know
&gt;&gt; exactly what day the nodes were picked. And he can also bound the true
&gt;&gt; timeframe for any date in January later than the actual date.  By
&gt;&gt; contrast, in option 3, the best he can do is know that the nodes were
&gt;&gt; chosen not more than two weeks in the past. So with option 2 he could
&gt;&gt; potentially know more. He also knows what time of the month these
&gt;&gt; attacks are most effective.
&gt;
&gt; I think the idea is like this: Today is January 14, and you choose 
&gt; according to method 3. You pick Jan 2, Jan 6 and Jan 27. The attacker now 
&gt; knows that you picked guards in a timeframe between Jan 13-15, because 
&gt; otherwise you couldn't have picked those three dates.

Umm. If the adversary can know that you just picked three guards
today, he doesn't need to do this analysis to learn that you picked
three guards sometime in a three day window. He knows what day today
is.  So that threat is moot. (I actually was thinking similarly at
first till this occurred to me, so don't feel bad. If I'm overlooking
something else, please don't make me feel bad ;&gt;)

&gt;
&gt;&gt; Why not combine the two options?
&gt;&gt; Pick a random timestamp during the last four weeks and an expiry 45
&gt;&gt; days in the future of the timestamp. (Or if you don't like the resulting
&gt;&gt; expected expiry time or range, make it 60 days or some other time
&gt;&gt; after the timestamp.) Note that if your timestamps just happen to all
&gt;&gt; be recent, he will know that, but with option 2 there are times when
&gt;&gt; this is guaranteed to work rather than just occasional luck. If you
&gt;&gt; want to make even this less likely you could add a check that at least
&gt;&gt; one timestamp must be more than some amount old and then throw out the
&gt;&gt; the third chosen guard's timestamp if none are old enough and pick
&gt;&gt; again. Don't know if that seems to complex, and this is after reading
&gt;&gt; your message and responding immediately. Might be problems if I
&gt;&gt; thought about it more.
&gt;
&gt; This scheme shares a similar problem: Today is Jan 28, and you pick Jan 4, 
&gt; Jan 12 and Jan 26. The attacker now knows that the timeframe is Jan 26 to 
&gt; Feb 1.
&gt;

Again, if he knows when you picked them, he knows when you picked them;
he doesn't need to do any analysis to infer less than he already knows.


&gt; I wonder how much this actually matters, though. Both of Roger's schemes 
&gt; pick dates that might be in the future (up to two weeks for scheme 3, up to 
&gt; one month for scheme 2), so if an adversary gets a hold of your state file, 
&gt; the dates are obviously false. 

That's why my proposal avoids any false dates. The only way he gets
lucky is if you randomly just picked three timestamps that were close
to the current date and then he got your state file shortly thereafter.
If you want to prevent even that, just add a check when you are choosing
timestamps: if all are more recent than say 10 days, pick again.
Or do the check on the other two timestamps first and then force the pick
to be in the 10 to 30 day range. I'm not the coder and don't know the
advantages of one vs. the other in code simplicity vs. overhead, etc.

&gt; After two and a half months (or less time), 
&gt; though, our guard selection changes, so it seems that with a good 
&gt; probability, the adversary will learn something valuable from our state 
&gt; file regardless.

I assume they are (ir)regularly rotating. What is it that he is
supposed to learn of value from this (other than your guards themselves
of course)?

aloha,
Paul
</body></email><email><emailId>20100119184850</emailId><senderName>Lexi Pimenidis</senderName><senderEmail>lexi.pimenidis@gmail.com</senderEmail><timestampReceived>2010-01-19 18:48:50-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

On Tue, Jan 19, 2010 at 06:58:58AM CET, Roger Dingledine wrote:

Hej,

&gt; &gt; So I'm going to go with option 2. Unless anybody else has clever ideas?

Just a minor thought: could an adversary learn some significant from the
atime/mtime/ctime of the file you store the information in? If so, it could
be nice to have that obscured, too :-)

Cheers, Lexi

-- 
Jc. Eqsu Vuiqlujud, uJqw OipR, Dvuyrqcldmc. 73, 50672 Ftqel
NO Ftqel RCP 58720, Oqdyrnqgmdgkqrcklo: Iuyrnqe Iqcmqld
| Rnpq lkl, nyr! Vruetdtvruq, Zkcudmqcqu klj Iqjuaul,
| Klj equjqc nkyr Mrqtetouq!  Jkcyrnkd dmkjuqcm, ium rquddqi Pqikqrl.
| Jn dmqr uyr lkl, uyr nciqc Mtc!  Klj pul dt feko ned huq akwtc;

----- End forwarded message -----
</body></email><email><emailId>20100119211338</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-01-19 21:13:38-0400</timestampReceived><subject>Re: Guard selection time and expiry</subject><body>

On Tue, Jan 19, 2010 at 11:25:25AM -0500, Paul Syverson wrote:
&gt; Pick a random timestamp during the last four weeks and an expiry [...]
&gt; 60 days [...] after the timestamp.)

I like this one. I'm going to go with it. As a bonus, it means we can
cut more code.

Thanks,
--Roger

diff --git a/src/or/circuitbuild.c b/src/or/circuitbuild.c
index 7eafeb3..458df02 100644
--- a/src/or/circuitbuild.c
+++ b/src/or/circuitbuild.c
@@ -78,7 +78,6 @@ static int count_acceptable_routers(smartlist_t *routers);
 static int onion_append_hop(crypt_path_t **head_ptr, extend_info_t *choice);
 
 static void entry_guards_changed(void);
-static time_t start_of_month(time_t when);
 
 /** Make a note that we're running unit tests (rather than running Tor
  * itself), so we avoid clobbering our state file. */
@@ -3022,7 +3021,9 @@ add_an_entry_guard(routerinfo_t *chosen, int reset_status)
   log_info(LD_CIRC, "Chose '%s' as new entry guard.", router-&gt;nickname);
   strlcpy(entry-&gt;nickname, router-&gt;nickname, sizeof(entry-&gt;nickname));
   memcpy(entry-&gt;identity, router-&gt;cache_info.identity_digest, DIGEST_LEN);
-  entry-&gt;chosen_on_date = start_of_month(time(NULL));
+  /* Choose expiry time smudged over the past month. For details, see
+   * http://archives.seul.org/or/dev/Jan-2010/msg00004.html */
+  entry-&gt;chosen_on_date = time(NULL) - crypto_rand_int(3600*24*30);
   entry-&gt;chosen_by_version = tor_strdup(VERSION);
   if (chosen) /* prepend */
     smartlist_insert(entry_guards, 0, entry);
@@ -3074,7 +3075,7 @@ static int
 remove_obsolete_entry_guards(void)
 {
   int changed = 0, i;
-  time_t this_month = start_of_month(time(NULL));
+  time_t now = time(NULL);
 
   for (i = 0; i &lt; smartlist_len(entry_guards); ++i) {
     entry_guard_t *entry = smartlist_get(entry_guards, i);
@@ -3094,9 +3095,8 @@ remove_obsolete_entry_guards(void)
                 !tor_version_as_new_as(ver, "0.2.0.6-alpha"))) {
       msg = "was selected without regard for guard bandwidth";
       version_is_bad = 1;
-    } else if (entry-&gt;chosen_on_date + 3600*24*35 &lt; this_month) {
-      /* It's been more than a month, and probably more like two since
-       * chosen_on_date is clipped to the beginning of its month. */
+    } else if (entry-&gt;chosen_on_date + 3600*24*60 &lt; now) {
+      /* It's been 2 months since the date listed in our state file. */
       msg = "was selected several months ago";
       date_is_bad = 1;
     }
@@ -3594,19 +3594,6 @@ choose_random_entry(cpath_build_state_t *state)
   return r;
 }
 
-/** Helper: Return the start of the month containing &lt;b&gt;time&lt;/b&gt;. */
-static time_t
-start_of_month(time_t now)
-{
-  struct tm tm;
-  tor_gmtime_r(&amp;now, &amp;tm);
-  tm.tm_sec = 0;
-  tm.tm_min = 0;
-  tm.tm_hour = 0;
-  tm.tm_mday = 1;
-  return tor_timegm(&amp;tm);
-}
-
 /** Parse &lt;b&gt;state&lt;/b&gt; and learn about the entry guards it describes.
  * If &lt;b&gt;set&lt;/b&gt; is true, and there are no errors, replace the global
  * entry_list with what we find.
@@ -3715,7 +3702,7 @@ entry_guards_parse_state(or_state_t *state, int set, char 
      } else {
        if (state_version) {
          e-&gt;chosen_by_version = tor_strdup(state_version);
-         e-&gt;chosen_on_date = start_of_month(time(NULL));
+         e-&gt;chosen_on_date = time(NULL) - crypto_rand_int(3600*24*30);
        }
      }
    });
</body></email><email><emailId>20100220232744</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-02-20 23:27:44-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>


Ok, consensus-bw-weights4 should have fixes for these, with the
exception of the XXX in find_start_of_next_routerstatus() that you
mention. That XXX actually is for the old code, which seemed to
preserve the \n for some reason there.

Nick, do you think you could have a look at that function, and see
what should be done there? It looks like it was possibly a bug or just
bad behavior to me.

In general, I'd also like someone to verify that adding the new
'directory-footer' line and 'bandwidth-weights' line to the consensus
won't break existing clients. It looks to me like the parsing code is
written to handle the addition of arbitrary new lines in the
consensus, but I'd like some confirmation of that. For example, is it
possible that the last routerstatus document in the consensus might
get silently rejected due to the parser finding the extra lines there?
routerstatus_parse_entry_from_string() looks like it might be OK with
that to me, but I'm not familiar with all of the bits of the parsing
code.

Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; I had a quick look at your branch to find similar mistakes as I
&gt; would make them. I should say that I didn't check any of your
&gt; calculations which are quite hard to get started with. So, don't
&gt; consider this a real code review.
&gt; 
&gt; Your last commit breaks test_dir.c which is probably okay, because
&gt; that commit will go away anyway.
&gt; 
&gt; I found a comment 'XXX: Should this be+1 for the \n?'. Do you want
&gt; to make sure you're doing the right thing and take this comment out?
&gt; 
&gt; In smartlist_choose_by_bandwidth_weights() (and maybe some other
&gt; places), you might write 'weight = is_dir ? Wbd*Wd : Wd;' instead of
&gt; using if-else. Makes your code shorter and easier to read, IMO.
&gt; 
&gt; There are some, IMO, unnecessary newlines before closing }'s. I
&gt; extended the check-spaces script as pasted below. I figured it's
&gt; probably easier for you to put it in rather than pulling these few
&gt; lines from my branch and doing the git black magic to remove your
&gt; last commit before applying mine.
&gt; 
&gt; diff --git a/contrib/checkSpace.pl b/contrib/checkSpace.pl index
&gt; db061a0..074fb6d 100755 --- a/contrib/checkSpace.pl +++
&gt; b/contrib/checkSpace.pl @@ -33,6 +33,10 @@ for $fn (@ARGV) { print "
&gt; #else#if:$fn:$.\n"; } $lastline = $_; +        ## Warn about
&gt; unnecessary empty lines.  +        if ($lastnil &amp;&amp; /^\s*}\n/) { +
&gt; print "  UnnecNL:$fn:$.\n"; +        } ## Warn about multiple empty
&gt; lines.  if ($lastnil &amp;&amp; /^$/) { print " DoubleNL:$fn:$.\n";
&gt; 
&gt; Would it make sense to update the list of consensus methods in
&gt; dir-spec.txt, section 3.4.1? It seems that nobody did that for the
&gt; past few methods, though.
&gt; 
&gt; Sometimes you're writing 'if () foo;' in one line which is, IMO,
&gt; not-so-good coding style. I don't know how to tell Perl to detect
&gt; that, though.
&gt; 
&gt; In networkstatus_verify_bw_weights, you have lines like 'if
&gt; (fabs(Wem - Wee) &gt; 1) {'. You are comparing double to int here,
&gt; which is probably okay, but somewhat bad style, IMO. More
&gt; importantly, if Wem and Wee differ by exactly 1, your condition
&gt; doesn't detect that difference; did you mean '&gt; 0.00001' or
&gt; something?
&gt; 
&gt; 
&gt; These are just minor issues, as you can see. I think the most
&gt; promising approaches to find more bugs would be: 1) write some
&gt; tests, 2) run the code in a private Tor network, 3) ask more people
&gt; to review your code, and/or 4) just put it in 0.2.2.x and hope to
&gt; find the bugs before 0.2.2.x becomes the new stable. 1) and 2) are
&gt; probably rather painful. If you want to do 2) and need support,
&gt; please let me know.
&gt; 
&gt; --Karsten

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100221051145</emailId><senderName>Nick Mathewson</senderName><senderEmail>nick.a.mathewson@gmail.com</senderEmail><timestampReceived>2010-02-21 05:11:45-0400</timestampReceived><subject>Re: (Desperate) Plea for multi-person code review</subject><body>

On Sat, Feb 20, 2010 at 6:27 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; Ok, consensus-bw-weights4 should have fixes for these, with the
&gt; exception of the XXX in find_start_of_next_routerstatus() that you
&gt; mention. That XXX actually is for the old code, which seemed to
&gt; preserve the \n for some reason there.
&gt;
&gt; Nick, do you think you could have a look at that function, and see
&gt; what should be done there? It looks like it was possibly a bug or just
&gt; bad behavior to me.

I think it's a bug, but a harmless one.  If we fix it, we need to make
sure that everything that calls find_start_of_next_routerstatus()
works fine if it gets the actual start of the routerstatus, not one
character before.  This means at least that we'd need to test parsing
consensuses and v2 networkstatus documents.

Or for stability we could convert the XXX into an explanatory comment,
but leave it alone otherwise.

&gt; In general, I'd also like someone to verify that adding the new
&gt; 'directory-footer' line and 'bandwidth-weights' line to the consensus
&gt; won't break existing clients. It looks to me like the parsing code is
&gt; written to handle the addition of arbitrary new lines in the
&gt; consensus, but I'd like some confirmation of that. For example, is it
&gt; possible that the last routerstatus document in the consensus might
&gt; get silently rejected due to the parser finding the extra lines there?
&gt; routerstatus_parse_entry_from_string() looks like it might be OK with
&gt; that to me, but I'm not familiar with all of the bits of the parsing
&gt; code.

According to the spec:

  When interpreting a Document, software MUST ignore any KeywordLine that
  starts with a keyword it doesn't recognize; future implementations MUST NOT
  require current clients to understand any KeywordLine not currently
  described.

All the parsing code goes through get_next_token(), which translates
unrecognized keywords into K_OPT, which is ignored everywhere.
Specifically, nothing in routerstatus_parse_entry_from_string does
anything to reject routerstatuses with extraneous entries.

-- 
Nick
</body></email><email><emailId>20100130023958</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-01-30 02:39:58-0400</timestampReceived><subject>Re: Node-Weight Balancing Corrections</subject><body>


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; &gt; Case 2: Both Guards and Exits are scarce
&gt; &gt; 
&gt; &gt; If both exits and guards are scarce, we need to determine weightings
&gt; &gt; to distribute the Exit+Guard bandwidth evenly between the guard and
&gt; &gt; exit positions, and ignore the middle position. First, we should
&gt; &gt; consider some subcases.
&gt; &gt; 
&gt; &gt; Let R denote the more scarce class (Rare) between Guard vs Exit.
&gt; &gt; Let S denote the less scarce class.
&gt; &gt; 
&gt; &gt; Subcase b: R+D &gt; S
&gt; &gt; 
&gt; &gt; For this case, we should divide D to make the two scarce classes
&gt; &gt; equal.
&gt; &gt; 
&gt; &gt; Using Case 1's General Form:
&gt; &gt; 
&gt; &gt;   Wgg*G + Wgd*D = M + Wmd*D + Wme*E + Wmg*G    (guard bw = middle bw)
&gt; &gt;   Wgg*G + Wgd*D = Wee*E + Wed*D                (guard bw = exit bw)
&gt; &gt;   Wed + Wmd + Wgd = 1                          (Wed*D+Wmd*D+Wgd*D = D)
&gt; &gt;   Wgg = 1-Wmg                                  (Wmg*G + Wgg*G = G)
&gt; &gt;   Wee = 1-Wme                                  (Wme*E + Wee*E = E)
&gt; &gt; 
&gt; &gt; We want guard bandwidth to equal exit bandwidth, and also:
&gt; &gt;    Wgg = Wee = 1 and Wme = Wmg = Wmd = 0.
&gt; &gt; 
&gt; &gt; Therefore, we know we want the following two equations to hold:
&gt; &gt;    1.   G +     Wgd*D = E + Wed*D     (guard bw = exit bw)
&gt; &gt;    2.   Wed*D + Wgd*D = D             (properly divide D)
&gt; &gt; 
&gt; &gt; Solving for Wed by adding 1+2:
&gt; &gt;     2*Wed*D + E + Wgd*D = G + Wgd*D + D
&gt; &gt;     2*Wed*D = G + D - E
&gt; &gt;     Wed = (G+D-E)/2D
&gt; &gt;     Wed = (G-E)/2D + 1/2
&gt; &gt; 
&gt; &gt; Solving for Wgd by rewriting 2 as Wgd=1-Wed:
&gt; &gt;     Wgd = 1-(G+D-E)/2D
&gt; &gt;     Wgd = (E+D-G)/2D
&gt; &gt;     Wgd = (E-G)/2D + 1/2
&gt; &gt; 
&gt; &gt; Here is a Mathematica line to verify this:
&gt; &gt; Reduce[{G + Wgd*D == E + Wed*D,
&gt; &gt;         Wed*D + Wgd*D == D},
&gt; &gt;        {Wed, Wgd}]
&gt; 
&gt; Here's a mathematica line to verify it from the General Form:
&gt; Reduce[{Wgg*G + Wgd*D == Wee*E + Wed*D,
&gt;         Wed*D + Wmd*D + Wgd*D == D,
&gt;         Wgg == Wee, Wee == 1,
&gt;         Wme == Wmd, Wmd == Wmg, Wme == 0,
&gt;         Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
&gt;         {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]

While running the new consensus weight code on the current Tor
network, I've discovered that there is a subcase that Case 2b above
does not handle optimally. It turns out that if both G and E are
scarce, there still can be enough D bandwidth such that the above
result actually creates a scarcity in the middle position.

I am handling this subcase in the code by computing the above weightings
for Wgd and Wed, and then seeing if G+Wgd*D &gt; M &amp;&amp; E+Wed*D &gt; M.

When this happens, we know that G+Wgd*D and E+Wed*D both exceed T/3
(because G+Wgd*D+E+Wed*D+M = T and G+Wgd*D = E+Wed*D).
 
Therefore, we can fix the Guard and Exit flagged nodes in their
position, because they are scarce (Wgg = Wee = 1 and Wmg = Wme = 0),
and add a new constraint similar to Case 3b:

 G+Wgd*D = T/3
 Wgd = (T/3-G)/D

In fact, since we know that there is sufficient bandwidth to balance
the network, we can cut right to the chase and say:

 M+Wmd*D = T/3
 Wmd = (T/3-M)/D

 E+Wed*D = T/3
 Wed = (T/3-E)/D

This can be verified in mathematica from the general form in case 1:
Reduce[{Wgg*G + Wgd*D == M + Wmd*D + Wme*E + Wmg*G,
        Wgg*G + Wgd*D == Wee*E + Wed*D,
        Wed*D + Wmd*D + Wgd*D == D,
        Wgg == 1, Wmg == 0, Wee == 1, Wme == 0,
        Wmg*G + Wgg*G == G, Wme*E + Wee*E == E},
        {Wgg, Wgd, Wmd, Wme, Wmg, Wee, Wed}]


Future work:

It has also occurred to me that while the above cases for balancing
the network attempt to conserve entropy in an ad-hoc fashion, there
are likely also entropy-maximizing constraints that would strike a
balance somehow between fixing Guard and Exit flagged nodes in their
place and allowing them to also be middle nodes in exchange for the
Guard+Exit nodes that could be either Guard or Exit.

For example, right now, in case 2b, Guard nodes will only be in the
Guard position, and Exit nodes will only be in the Exit position. The
other cases (except for case 1) have similar constraints on fixing one
of either the Guard or the Exit hop. This is less than ideal from an
entropy standpoint, but I'm not sure exactly how to frame
entropy-maximizing constraints into the general formula.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100703110853</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-03 11:08:53-0400</timestampReceived><subject>Building Tor tor-0.2.2.13-alpha on windows</subject><body>

Dear Tor Team,

The build on Windows reports a make file that has incorrect options.
Is anyone aware of this ?

"""make: *** No targets specified and no makefile found.  Stop."""

Thanks in advance.

Cav Edwards
</body></email><email><emailId>20100804181939</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-04 18:19:39-0400</timestampReceived><subject>Second Tor online "developer party" on Monday from 18:00 to 20:00 UTC</subject><body>

Hi, folks!  This email is a heads-up about our next online
nonstructured mass developer meeting, still called a "developer party"
on the superstitious belief that if we act like it's supposed to be
fun, it will be.   The last one was fun, after all.

(I'm announcing this one on or-dev, since that's where people
suggested that I announce it after I announced the last one on another
list.  If you don't think these messages should be on or-dev, please
email me personally [not the list] to say so.)

It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
channel on irc.oftc.net.  That's 14:00 to 16:00 eastern, and 11:00 to
13:00 pacific, if I can still do math with my current jetlag.

General notes:
* If you're not free to make it, or if you're not free to make it for
the whole time, don't worry.  There will be more of these at other
times ranging from "too late in Europe" to "too early in California".
* If you're not an actual developer on Tor, you're welcome to come and
hang out, but this is mainly a time for developers to chat and plot
and generally confab.
* We're probably not going to be "partying" for every minute of all 2
hours; think of this as a salon where people wander in and out and
take breaks to go into a corner and eat cheese or debug trac or
whatever.
* The format will probably change in the future as we get some
experience with it and learn more about what does (and doesn't) work
for us.  If having 2 open hours is too much, let's do less.
* I'm going to try to "host" this developer party.  Since you can't
serve food over IRC, and there's no need to vacuum the floor before
the party starts, I'm not quite sure what my responsibility will be
other than being around the whole time and trying to make sure the
conversation stays interesting.  I'll play it by ear.

peace,
-- 
Nick
</body></email><email><emailId>20100804160342</emailId><senderName>Peter Palfrader</senderName><senderEmail>peter@palfrader.org</senderEmail><timestampReceived>2010-08-04 16:03:42-0400</timestampReceived><subject>thandy repository mirrorability</subject><body>

Hey,

I've been wondering about mirrorability for when we start using thandy
for real.  That is, what happens when a user accesses a mirror that is
in the process of updating its files.


Let me describe first how Debian does things, so we have a nice example
of the problem:

In your normal Debian archive tree we have normal files (.deb and
.tar.gz and all that);  in Debian they all live below pool/.

We have a list of various subsets of them with their corresponding
digests in files called Sources and Packages (one per
arch/suite/component but that's not really that important).  And we have
a list of all those metafiles with their hashes in a file called
Release, and the pgp signature of that file is next to it and named
Release.pgp.  All these files live under dist/.

When a user wants to update their system or install a new package they
first run 'apt-get update' which fetches all the metadata files
(Packages, Release, Release.pgp) and later they run apt-get install or
upgrade (or ..) which gets the .deb.

This is all fine and no problem if the archive is static almost all of
the time.  Of course it isn't and that introduces two problems when
updating and especially when mirroring the archive:

- The Sources/Packages file might refer to files that are not yet or
  no longer on the server.
- The various checksums might be out of sync
  + the .pgp file might not go with the Release file a client downloaded
  + the Release file might reference a Packages/Sources file with a
    different hash.
  + Packages/Sources files referencing files with their wrong digest
    does not happen in debian because files below pool/ never change -
    they get added and removed but they don't ever get modified once
    there.

Debian mirroring solves the problem partially by doing the mirroring
process in two stages (and nothing accesses the master repository, so
everything a user sees always is a mirror).

The first stage just fetches new files below pool/.[1]  It does not
ever delete anything.

The second stage then updates the rest of the archive bug using rsync's
--delay-updates option which means rsync first gets a new version of all
the files that changed (or are new), stores them under some temporary
name and once it has all data locally it walks over the tree and renames
stuff into place.  We kinda pretend that this rename step is atomic.
The second stage also runs with --delete and --delete-after, removing
all the files that are no longer on the master at the end of the run.

In addition to this two stage mirroring process the master archive does
not remove files immediately after they stop being referenced but waits
for a couple of days before they get deleted.

In theory that's quite simple but it does have its pitfalls.  For one
everybody who wants to mirror the archive has to run your own special
mirroring script (and people don't really like doing that).
Secondly, it becomes really painful when you have a rotation like
security.debian.org that is many machines but should present the same
view of data to users regardless of which individual machine they get
their data form.  I.e. you have to do some form of synchronized staged
mirroring.



So, from a quick look at thandy and without knowing much about it, it
appears as if thandy will suffer from much of the same problems.  The
timestamp.txt file looks like one that's particular problematic.  Is
this correct or is there some clever scheme that avoids the desync
problems while a mirror update is in progress?

Should we worry about this and try to see if we can come up with some
clever schemes that mitigate or avoid the issue?

Cheers,
weasel

1. Not exactly true, but close enough for this discussion.
-- 
                           |  .''`.  ** Debian GNU/Linux **
      Peter Palfrader      | : :' :      The  universal
 http://www.palfrader.org/ | `. `'      Operating System
                           |   `-    http://www.debian.org/
</body></email><email><emailId>20100914220456</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-09-14 22:04:56-0400</timestampReceived><subject>Re: [or-cvs] r23192: {projects} resync  (projects/articles)</subject><body>


On Tue, 14 Sep 2010 21:31:57 +0000 (UTC)
Roger Dingledine &lt;arma@torproject.org&gt; wrote:

&gt; Author: arma
&gt; Date: 2010-09-14 21:31:57 +0000 (Tue, 14 Sep 2010)
&gt; New Revision: 23192
&gt; 
&gt; Modified:
&gt;    projects/articles/circumvention-features.html
&gt; Log:
&gt; resync
&gt; 
&gt; 
&gt; Modified: projects/articles/circumvention-features.html
&gt; ===================================================================
&gt; --- projects/articles/circumvention-features.html	2010-09-14 21:27:58 UTC (rev 23191)
&gt; +++ projects/articles/circumvention-features.html	2010-09-14 21:31:57 UTC (rev 23192)

&gt; @@ -144,7 +144,7 @@
&gt;  the future.
&gt;  &lt;/p&gt;
&gt;  
&gt; -&lt;h3&gt;4. Open design&lt;/h3&gt;
&gt; +&lt;h3&gt;Has an open design&lt;/h3&gt;
&gt;  
&gt;  &lt;p&gt;
&gt;  The first step to transparency and reusability of the tool's software and
&gt; @@ -195,7 +195,7 @@
&gt;  forward too slowly.
&gt;  &lt;/p&gt;
&gt;  
&gt; -&lt;h3&gt;5. Decentralized architecture&lt;/h3&gt;
&gt; +&lt;h3&gt;Has a decentralized architecture&lt;/h3&gt;
&gt;  
&gt;  &lt;p&gt;
&gt;  Another feature to look for in a circumvention tool is whether its network

You lost the section numbers.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101008003821</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-08 00:38:21-0400</timestampReceived><subject>Re: [or-cvs] r23443: {website} remove the glossary. fix up the rtfm</subject><body>


On Thu,  7 Oct 2010 16:09:58 +0000 (UTC)
Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; Author: phobos
&gt; Date: 2010-10-07 16:09:57 +0000 (Thu, 07 Oct 2010)
&gt; New Revision: 23443
&gt; 
&gt; Removed:
&gt; website/branches/web20/docs/en/glossary.wml
&gt; Modified:
&gt; website/branches/web20/docs/en/sidenav.wmi
&gt; website/branches/web20/download/en/download.wml
&gt; website/branches/web20/include/foot.wmi
&gt; website/branches/web20/include/info.wmi
&gt; Log:
&gt; remove the glossary. fix up the rtfm link on the download page.

&gt; Modified: website/branches/web20/download/en/download.wml
&gt; ===================================================================
&gt; --- website/branches/web20/download/en/download.wml	2010-10-07 15:52:43 UTC (rev \
&gt;                 23442)
&gt; +++ website/branches/web20/download/en/download.wml	2010-10-07 16:09:57 UTC (rev \
&gt; 23443)

&gt; @@ -257,14 +256,8 @@
&gt; &lt;div class="img-shadow"&gt;
&gt; 	&lt;div class="sidenav-sub"&gt;
&gt; 	&lt;h2&gt;Having Trouble?&lt;/h2&gt;
&gt; -          	&lt;ul&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;What are the differences between \
&gt;                 stable and unstable downloads?&lt;/a&gt;&lt;/li&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;Why is the TorBrowser Bundle only \
&gt;                 available for Windows?&lt;/a&gt;&lt;/li&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;What is the Expert Developer \
&gt;                 Package?&lt;/a&gt;&lt;/li&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;What are the differences between \
&gt;                 stable and unstable downloads?&lt;/a&gt;&lt;/li&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;Why is the TorBrowser Bundle only \
&gt;                 available for Windows?&lt;/a&gt;&lt;/li&gt;
&gt; -            	&lt;li class="dropdown"&gt;&lt;a href="#"&gt;What is the Expert Developer \
&gt;                 Package?&lt;/a&gt;&lt;/li&gt;
&gt; -            &lt;/ul&gt;
&gt; +            &lt;ul&gt;
&gt; +              &lt;li class="dropdown"&gt;&lt;a href="&lt;page docs/documentation&gt;"&gt;Read the \
&gt; fine manuals&lt;/a&gt;&lt;/li&gt; &lt;/div&gt;
&gt; 	&lt;/div&gt;
&gt; &lt;!-- END SIDENAV --&gt;

You dropped the "&lt;/ul&gt;" tag, and I don't see it reappearing in the
later commit messages.


Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101101192703</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-11-01 19:27:03-0400</timestampReceived><subject>Bug in parsing Address line in torrc</subject><body>

Nick et al.,

Mashael and I uncovered a little bug in the torrc parsing code in
src/or/config.c.  If Address is set to a dotted quad, tor_inet_aton
returns 1, and stores the address in in.s_addr, but that field is then
never copied out to the addr variable.  Here's a patch.

--- config.c.stock	2010-11-01 19:20:34.000000000 +0000
+++ config.c	2010-11-01 19:20:59.000000000 +0000
@@ -2413,6 +2413,8 @@
         }
       }
     }
+  } else {
+    addr = ntohl(in.s_addr);
   }
 
   addr_string = tor_dup_ip(addr);


This is against 0.2.3.0-alpha-dev.

Thanks,

   - Ian
</body></email><email><emailId>20101202131855</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-12-02 13:18:55-0400</timestampReceived><subject>Missing certificates</subject><body>

Every time I launch 0.2.3, I see these messages:

Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
with signing key F7C7B9191C74C0BA07363C84D37BBAD3A8A6C6D8: launching
request.
Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
with signing key 604834622B54F2D9BA39B34AC53924546733AA60: launching
request.

Whose certificates are these, and why are we continually missing them?

Thanks,

   - Ian
</body></email><email><emailId>20101215043138</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-12-15 04:31:38-0400</timestampReceived><subject>Some draft notes on migrating Tor's ciphersuites</subject><body>

Here's something I've worked up, with fixes from Robert Ransom.  It's
currently in doc/spec/proposals/ideas/xxx-crypto-migration.txt.  Once
it's more discussed and worked out, it should turn into a real
proposal, but I'd like to kick the ball off here.

Robert has also written up a couple of documents I'll be forwarding in
my next email.

=====
Title: Initial thoughts on migrating Tor to new cryptography
Author: Nick Mathewson
Created: 12 December 2010

1. Introduction

  Tor currently uses AES-128, RSA-1024, and SHA1.  Even though these
  ciphers were a decent choice back in 2003, and even though attacking
  these algorithms is by no means the best way for a well-funded
  adversary to attack users (correlation attacks are still cheaper, even
  with pessimistic assumptions about the security of each cipher), we
  will want to move to better algorithms in the future.  Indeed, if
  migrating to a new ciphersuite were simple, we would probably have
  already moved to RSA-1024/AES-128/SHA256 or something like that.

  So it's a good idea to start figuring out how we can move to better
  ciphers.  Unfortunately, this is a bit nontrivial, so before we start
  doing the design work here, we should start by examining the issues
  involved.  Robert Ransom and I both decided to spend this weekend
  writing up documents of this type so that we can see how much two
  people working independently agree on.  I know more Tor than Robert;
  Robert knows far more cryptography than I do.  With luck we'll
  complement each other's work nicely.

  A note on scope: This document WILL NOT attempt to pick a new cipher
  or set of ciphers.  Instead, it's about how to migrate to new ciphers
  in general.  Any algorithms mentioned other than those we use today
  are just for illustration.

  Also, I don't much consider the importance of updating each particular
  usage; only the methods that you'd use to do it.

  Also, this isn't a complete proposal.

2. General principles and tricks

  Before I get started, let's talk about some general design issues.

2.1. Many algorithms or few?

  Protocols like TLS and OpenPGP allow a wide choice of cryptographic
  algorithms; so long as the sender and receiver (or the responder and
  initiator) have at least one mutually acceptable algorithm, they can
  converge upon it and send each other messages.

  This isn't the best choice for anonymity designs.  If two clients
  support a different set of algorithms, then an attacker can tell them
  apart.  A protocol with N ciphersuites would in principle split
  clients into 2**N-1 sets.  (In practice, nearly all users will use the
  default, and most users who choose _not_ to use the default will do so
  without considering the loss of anonymity.  See "Anonymity Loves
  Company: Usability and the Network Effect".)

  On the other hand, building only one ciphersuite into Tor has a flaw
  of its own: it has proven difficult to migrate to another one.  So
  perhaps instead of specifying only a single new ciphersuite, we should
  specify more than one, with plans to switch over (based on a flag in
  the consensus or some other secure signal) once the first choice of
  algorithms start looking iffy.  This switch-based approach would seem
  especially easy for parameterizable stuff like key sizes.

2.2. Waiting for old clients and servers to upgrade

  The easiest way to implement a shift in algorithms would be to declare
  a "flag day": once we have the new versions of the protocols
  implemented, pick a day by which everybody must upgrade to the new
  software.  Before this day, the software would have the old behavior;
  after this way, it would use the improved behavior.

  Tor tries to avoid flag days whenever possible; they have well-known
  issues.  First, since a number of our users don't automatically
  update, it can take a while for people to upgrade to new versions of
  our software.  Second and more worryingly, it's hard to get adequate
  testing for new behavior that is off-by-default.  Flag days in other
  systems have been known to leave whole networks more or less
  inoperable for months; we should not trust in our skill to avoid
  similar problems.

  So if we're avoiding flag days, what can we do?

  * We can add _support_ for new behavior early, and have clients use it
    where it's available.  (Clients know the advertised versions of the
    Tor servers they use-- but see 2.3 below for a danger here, and 2.4
    for a bigger danger.)

  * We can remove misfeatures that _prevent_ deployment of new
    behavior.  For instance, if a certain key length has an arbitrary
    1024-bit limit, we can remove that arbitrary limitation.

  * Once an optional new behavior is ubiquitous enough, the authorities
    can stop accepting descriptors from servers that do not have it
    until they upgrade.

  It is far easier to remove arbitrary limitations than to make other
  changes; such changes are generally safe to back-port to older stable
  release series.  But in general, it's much better to avoid any plans
  that require waiting for any version of Tor to no longer be in common
  use: a stable release can take on the order of 2.5 years to start
  dropping off the radar.  Thandy might fix that, but even if a perfect
  Thandy release comes out tomorrow, we'll still have lots of older
  clients and relays not using it.

  We'll have to approach the migration problem on a case-by-case basis
  as we consider the algorithms used by Tor and how to change them.

2.3. Early adopters and other partitioning dangers

  It's pretty much unavoidable that clients running software that speak
  the new version of any protocol will be distinguishable from those
  that cannot speak the new version.  This is inevitable, though we
  could try to minimize the number of such partitioning sets by having
  features turned on in the same release rather than one-at-a-time.

  Another option here is to have new protocols controlled by a
  configuration tri-state with values "on", "off", and "auto".  The
  "auto" value means to look at the consensus to decide wither to use
  the feature; the other two values are self-explanatory.  We'd ship
  clients with the feature set to "auto" by default, with people only
  using "on" for testing.

  If we're worried about early client-side implementations of a protocol
  turning out to be broken, we can have the consensus value say _which_
  versions should turn on the protocol.

2.4. Avoid whole-circuit switches

  One risky kind of protocol migration is a feature that gets used only
  when all the routers in a circuit support it.  If such a feature is
  implemented by few relays, then each relay learns a lot about the rest
  of the path by seeing it used.  On the other hand, if the feature is
  implemented by most relays, then a relay learns a lot about the rest of
  the path when the feature is *not* used.

  It's okay to have a feature that can be only used if two consecutive
  routers in the patch support it: each router knows the ones adjacent
  to it, after all, so knowing what version of Tor they're running is no
  big deal.

2.5. The Second System Effect rears its ugly head

  Any attempt at improving Tor's crypto is likely to involve changes
  throughout the Tor protocol.  We should be aware of the risks of
  falling into what Fred Brooks called the "Second System Effect": when
  redesigning a fielded system, it's always tempting to try to shovel in
  every possible change that one ever wanted to make to it.

  This is a fine time to make parts of our protocol that weren't
  previously versionable into ones that are easier to upgrade in the
  future.  This probably _isn't_ time to redesign every aspect of the
  Tor protocol that anybody finds problematic.

2.6. Low-hanging fruit and well-lit areas

  Not all parts of Tor are tightly covered.  If it's possible to upgrade
  different parts of the system at different rates from one another, we
  should consider doing the stuff we can do easier, earlier.

  But remember the story of the policeman who finds a drunk under a
  streetlamp, staring at the ground?  The cop asks, "What are you
  doing?"  The drunk says, "I'm looking for my keys!"  "Oh, did you drop
  them around here?" says the policeman.  "No," says the drunk, "But the
  light is so much better here!"

  Or less proverbially: Simply because a change is easiest, does not
  mean it is the best use of our time.  We should avoid getting bogged
  down solving the _easy_ aspects of our system unless they happen also
  to be _important_.

2.7. Nice safe boring codes

  Let's avoid, to the extent that we can:
    - being the primary user of any cryptographic construction or
      protocol.
    - anything that hasn't gotten much attention in the literature.
    - anything we would have to implement from scratch
    - anything without a nice BSD-licensed C implementation

  Sometimes we'll have the choice of a more efficient algorithm or a
  more boring &amp; well-analyzed one.  We should not even consider trading
  conservative design for efficiency unless we are firmly in the
  critical path.

2.8. Key restrictions

  Our spec says that RSA exponents should be 65537, but our code never
  checks for that.  If we want to bolster resistance against collision
  attacks, we could check this requirement.  To the best of my
  knowledge, nothing violates it except for tools like "shallot" that
  generate cute memorable .onion names.  If we want to be nice to
  shallot users, we could check the requirement for everything *except*
  hidden service identity keys.

3. Aspects of Tor's cryptography, and thoughts on how to upgrade them all

3.1. Link cryptography

  Tor uses TLS for its link cryptography; it is easy to add more
  ciphersuites to the acceptable list, or increase the length of
  link-crypto public keys, or increase the length of the DH parameter,
  or sign the X509 certificates with any digest algorithm that OpenSSL
  clients will support.  Current Tor versions do not check any of these
  against expected values.

  The identity key used to sign the second certificate in the current
  handshake protocol, however, is harder to change, since it needs to
  match up with what we see in the router descriptor for the router
  we're connecting to.  See notes on router identity below.  So long as
  the certificate chain is ultimately authenticated by a RSA-1024 key,
  it's not clear whether making the link RSA key longer on its own
  really improves matters or not.

  Recall also that for anti-fingerprinting reasons, we're thinking of
  revising the protocol handshake sometime in the 0.2.3.x timeframe.
  If we do that, that might be a good time to make sure that we aren't
  limited by the old identity key size.

3.2. Circuit-extend crypto

  Currently, our code requires RSA onion keys to be 1024 bits long.
  Additionally, current nodes will not deliver an EXTEND cell unless it
  is the right length.

  For this, we might add a second, longer onion-key to router
  descriptors, and a second CREATE2 cell to open new circuits
  using this key type.  It should contain not only the onionskin, but
  also information on onionskin version and ciphersuite.  Onionskins
  generated for CREATE2 cells should use a larger DH group as well, and
  keys should be derived from DH results using a better digest algorithm.

  We should remove the length limit on EXTEND cells, backported to all
  supported stable versions; call these "EXTEND2" cells.  Call these
  "lightly patched".  Clients could use the new EXTEND2/CREATE2 format
  whenever using a lightly patched or new server to extend to a new
  server, and the old EXTEND/CREATE format otherwise.

  The new onion skin format should try to avoid the design oddities of
  our old one.  Instead of its current iffy hybrid encryption scheme, it
  should probably do something more like a BEAR/LIONESS operation with a
  fixed key on the g^x value, followed by a public key encryption on the
  start of the encrypted data.  (Robert reminded me about this
  construction.)

  The current EXTEND cell format ends with a router identity
  fingerprint, which is used by the extended-from router to authenticate
  the extended-to router when it connects.  Changes to this will
  interact with changes to how long an identity key can be and to the
  link protocol; see notes on the link protocol above and about router
  identity below.

3.2.1. Circuit-extend crypto: fast case

  When we do unauthenticated circuit extends with CREATE/CREATED_FAST,
  the two input values are combined with SHA1.  I believe that's okay;
  using any entropy here at all is overkill.

3.3. Relay crypto

  Upon receiving relay cells, a router transforms the payload portion of
  the cell with the appropriate key appropriate key, sees if it
  recognizes the cell (the recognized field is zero, the digest field is
  correct, the cell is outbound), and passes them on if not.  It is
  possible for each hop in the circuit to handle the relay crypto
  differently; nobody but the client and the hop in question need to
  coordinate their operations.

  It's not clear, though, whether updating the relay crypto algorithms
  would help anything, unless we changed the whole relay cell processing
  format too.  The stream cipher is good enough, and the use of 4 bytes
  of digest does not have enough bits to provide cryptographic strength,
  no matter what cipher we use.

  This is the likeliest area for the second-system effect to strike;
  there are lots of opportunities to try to be more clever than we are
  now.

3.4. Router identity

  This is one of the hardest things to change.  Right now, routers are
  identified by a "fingerprint" equal to the SHA1 hash of their 1024-bit
  identity key as given in their router descriptor.  No existing Tor
  will accept any other size of identity key, or any other hash
  algorithm.  The identity key itself is used:
    - To sign the router descriptors
    - To sign link-key certificates
    - To determine the least significant bits of circuit IDs used on a
      Tor instance's links (see tor-spec  §5.1)

  The fingerprint is used:
    - To identify a router identity key in EXTEND cells
    - To identify a router identity key in bridge lines
    - Throughout the controller interface
    - To fetch bridge descriptors for a bridge
    - To identify a particular router throughout the codebase
    - In the .exit notation.
    - By the controller to identify nodes
    - To identify servers in the logs
    - Probably other places too

  To begin to allow other key types, key lengths, and hash functions, we
  would either need to wait till all current Tors are obsolete, or allow
  routers to have more than one identity for a while.

  To allow routers to have more than one identity, we need to
  cross-certify identity keys.  We can do this trivially, in theory, by
  listing both keys in the router descriptor and having both identities
  sign the descriptor.  In practice, we will need to analyze this pretty
  carefully to avoid attacks where one key is completely fake aimed to
  trick old clients somehow.

  Upgrading the hash algorithm once would be easy: just say that all
  new-type keys get hashed using the new hash algorithm.  Remaining
  future-proof could be tricky.

  This is one of the hardest areas to update; "SHA1 of identity key" is
  assumed in so many places throughout Tor that we'll probably need a
  lot of design work to work with something else.

3.5. Directory objects

  Fortunately, the problem is not so bad for consensuses themselves,
  because:
    - Authority identity keys are allowed to be RSA keys of any length;
      in practice I think they are all 3072 bits.
    - Authority signing keys are also allowed to be of any length.
      AFAIK the code works with longer signing keys just fine.
    - Currently, votes are hashed with both sha1 and sha256; adding
      more hash algorithms isn't so hard.
    - Microdescriptor consensuses are all signed using sha256.  While
      regular consensuses are signed using sha1, exploitable collisions
      are hard to come up with, since once you had a collision, you
      would need to get a majority of other authorities to agree to
      generate it.

  Router descriptors are currently identified by SHA1 digests of their
  identity keys and descriptor digests in regular consensuses, and by
  SHA1 digests of identity keys and SHA256 digests of microdescriptors
  in microdesc consensuses.  The consensus-flavors design allows us to
  generate new flavors of consensus that identity routers by new hashes
  of their identity keys.  Alternatively, existing consensuses could be
  expanded to contain more hashes, though that would have some space
  concerns.

  Router descriptors themselves are signed using RSA-1024 identity keys
  and SHA1.  For information on updating identity keys, see above.

  Router descriptors and extra-info documents cross-certify one another
  using SHA1.

  Microdescriptors are currently specified to contain exactly one
  onion key, of length 1024 bits.

3.6. The directory protocol

  Most objects are indexed by SHA1 hash of an identity key or a
  descriptor object.  Adding more hash types wouldn't be a huge problem
  at the directory cache level.

3.7. The hidden service protocol

  Hidden services self-identify by a 1024-bit RSA key.  Other key
  lengths are not supported.  This key is turned into an 80 bit half
  SHA-1 hash for hidden service names.

  The most simple change here would be to set an interface for putting
  the whole ugly SHA1 hash in the hidden service name.  Remember that
  this needs to coexist with the authentication system which also uses
  .onion hostnames; that hostnames top out around 255 characters and and
  their components top out at 63.

  Currently, ESTABLISH_INTRO cells take a key length parameter, so in
  theory they allow longer keys.  The rest of the protocol assumes that
  this will be hashed into a 20-byte SHA1 identifier.  Changing that
  would require changes at the introduction point as well as the hidden
  service.

  The parsing code for hidden service descriptors currently enforce a
  1024-bit identity key, though this does not seem to be described in
  the specification.  Changing that would be at least as hard as doing
  it for regular identity keys.

  Fortunately, hidden services are nearly completely orthogonal to
  everything else.

</body></email><email><emailId>20101217220255</emailId><senderName>Weidong Shao</senderName><senderEmail>weidongshao@gmail.com</senderEmail><timestampReceived>2010-12-17 22:02:55-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

Is there any writeup on the current status of Tor crypto?  doc or issue
list.

Thanks,
Weidong

On Tue, Dec 14, 2010 at 8:31 PM, Nick Mathewson &lt;nickm@torproject.org&gt;wrote:

&gt; Here's something I've worked up, with fixes from Robert Ransom.  It's
&gt; currently in doc/spec/proposals/ideas/xxx-crypto-migration.txt.  Once
&gt; it's more discussed and worked out, it should turn into a real
&gt; proposal, but I'd like to kick the ball off here.
&gt;
&gt; Robert has also written up a couple of documents I'll be forwarding in
&gt; my next email.
&gt;
&gt; =====
&gt; Title: Initial thoughts on migrating Tor to new cryptography
&gt; Author: Nick Mathewson
&gt; Created: 12 December 2010
&gt;
&gt; 1. Introduction
&gt;
&gt;  Tor currently uses AES-128, RSA-1024, and SHA1.  Even though these
&gt;  ciphers were a decent choice back in 2003, and even though attacking
&gt;  these algorithms is by no means the best way for a well-funded
&gt;  adversary to attack users (correlation attacks are still cheaper, even
&gt;  with pessimistic assumptions about the security of each cipher), we
&gt;  will want to move to better algorithms in the future.  Indeed, if
&gt;  migrating to a new ciphersuite were simple, we would probably have
&gt;  already moved to RSA-1024/AES-128/SHA256 or something like that.
&gt;
&gt;  So it's a good idea to start figuring out how we can move to better
&gt;  ciphers.  Unfortunately, this is a bit nontrivial, so before we start
&gt;  doing the design work here, we should start by examining the issues
&gt;  involved.  Robert Ransom and I both decided to spend this weekend
&gt;  writing up documents of this type so that we can see how much two
&gt;  people working independently agree on.  I know more Tor than Robert;
&gt;  Robert knows far more cryptography than I do.  With luck we'll
&gt;  complement each other's work nicely.
&gt;
&gt;  A note on scope: This document WILL NOT attempt to pick a new cipher
&gt;  or set of ciphers.  Instead, it's about how to migrate to new ciphers
&gt;  in general.  Any algorithms mentioned other than those we use today
&gt;  are just for illustration.
&gt;
&gt;  Also, I don't much consider the importance of updating each particular
&gt;  usage; only the methods that you'd use to do it.
&gt;
&gt;  Also, this isn't a complete proposal.
&gt;
&gt; 2. General principles and tricks
&gt;
&gt;  Before I get started, let's talk about some general design issues.
&gt;
&gt; 2.1. Many algorithms or few?
&gt;
&gt;  Protocols like TLS and OpenPGP allow a wide choice of cryptographic
&gt;  algorithms; so long as the sender and receiver (or the responder and
&gt;  initiator) have at least one mutually acceptable algorithm, they can
&gt;  converge upon it and send each other messages.
&gt;
&gt;  This isn't the best choice for anonymity designs.  If two clients
&gt;  support a different set of algorithms, then an attacker can tell them
&gt;  apart.  A protocol with N ciphersuites would in principle split
&gt;  clients into 2**N-1 sets.  (In practice, nearly all users will use the
&gt;  default, and most users who choose _not_ to use the default will do so
&gt;  without considering the loss of anonymity.  See "Anonymity Loves
&gt;  Company: Usability and the Network Effect".)
&gt;
&gt;  On the other hand, building only one ciphersuite into Tor has a flaw
&gt;  of its own: it has proven difficult to migrate to another one.  So
&gt;  perhaps instead of specifying only a single new ciphersuite, we should
&gt;  specify more than one, with plans to switch over (based on a flag in
&gt;  the consensus or some other secure signal) once the first choice of
&gt;  algorithms start looking iffy.  This switch-based approach would seem
&gt;  especially easy for parameterizable stuff like key sizes.
&gt;
&gt; 2.2. Waiting for old clients and servers to upgrade
&gt;
&gt;  The easiest way to implement a shift in algorithms would be to declare
&gt;  a "flag day": once we have the new versions of the protocols
&gt;  implemented, pick a day by which everybody must upgrade to the new
&gt;  software.  Before this day, the software would have the old behavior;
&gt;  after this way, it would use the improved behavior.
&gt;
&gt;  Tor tries to avoid flag days whenever possible; they have well-known
&gt;  issues.  First, since a number of our users don't automatically
&gt;  update, it can take a while for people to upgrade to new versions of
&gt;  our software.  Second and more worryingly, it's hard to get adequate
&gt;  testing for new behavior that is off-by-default.  Flag days in other
&gt;  systems have been known to leave whole networks more or less
&gt;  inoperable for months; we should not trust in our skill to avoid
&gt;  similar problems.
&gt;
&gt;  So if we're avoiding flag days, what can we do?
&gt;
&gt;  * We can add _support_ for new behavior early, and have clients use it
&gt;    where it's available.  (Clients know the advertised versions of the
&gt;    Tor servers they use-- but see 2.3 below for a danger here, and 2.4
&gt;    for a bigger danger.)
&gt;
&gt;  * We can remove misfeatures that _prevent_ deployment of new
&gt;    behavior.  For instance, if a certain key length has an arbitrary
&gt;    1024-bit limit, we can remove that arbitrary limitation.
&gt;
&gt;  * Once an optional new behavior is ubiquitous enough, the authorities
&gt;    can stop accepting descriptors from servers that do not have it
&gt;    until they upgrade.
&gt;
&gt;  It is far easier to remove arbitrary limitations than to make other
&gt;  changes; such changes are generally safe to back-port to older stable
&gt;  release series.  But in general, it's much better to avoid any plans
&gt;  that require waiting for any version of Tor to no longer be in common
&gt;  use: a stable release can take on the order of 2.5 years to start
&gt;  dropping off the radar.  Thandy might fix that, but even if a perfect
&gt;  Thandy release comes out tomorrow, we'll still have lots of older
&gt;  clients and relays not using it.
&gt;
&gt;  We'll have to approach the migration problem on a case-by-case basis
&gt;  as we consider the algorithms used by Tor and how to change them.
&gt;
&gt; 2.3. Early adopters and other partitioning dangers
&gt;
&gt;  It's pretty much unavoidable that clients running software that speak
&gt;  the new version of any protocol will be distinguishable from those
&gt;  that cannot speak the new version.  This is inevitable, though we
&gt;  could try to minimize the number of such partitioning sets by having
&gt;  features turned on in the same release rather than one-at-a-time.
&gt;
&gt;  Another option here is to have new protocols controlled by a
&gt;  configuration tri-state with values "on", "off", and "auto".  The
&gt;  "auto" value means to look at the consensus to decide wither to use
&gt;  the feature; the other two values are self-explanatory.  We'd ship
&gt;  clients with the feature set to "auto" by default, with people only
&gt;  using "on" for testing.
&gt;
&gt;  If we're worried about early client-side implementations of a protocol
&gt;  turning out to be broken, we can have the consensus value say _which_
&gt;  versions should turn on the protocol.
&gt;
&gt; 2.4. Avoid whole-circuit switches
&gt;
&gt;  One risky kind of protocol migration is a feature that gets used only
&gt;  when all the routers in a circuit support it.  If such a feature is
&gt;  implemented by few relays, then each relay learns a lot about the rest
&gt;  of the path by seeing it used.  On the other hand, if the feature is
&gt;  implemented by most relays, then a relay learns a lot about the rest of
&gt;  the path when the feature is *not* used.
&gt;
&gt;  It's okay to have a feature that can be only used if two consecutive
&gt;  routers in the patch support it: each router knows the ones adjacent
&gt;  to it, after all, so knowing what version of Tor they're running is no
&gt;  big deal.
&gt;
&gt; 2.5. The Second System Effect rears its ugly head
&gt;
&gt;  Any attempt at improving Tor's crypto is likely to involve changes
&gt;  throughout the Tor protocol.  We should be aware of the risks of
&gt;  falling into what Fred Brooks called the "Second System Effect": when
&gt;  redesigning a fielded system, it's always tempting to try to shovel in
&gt;  every possible change that one ever wanted to make to it.
&gt;
&gt;  This is a fine time to make parts of our protocol that weren't
&gt;  previously versionable into ones that are easier to upgrade in the
&gt;  future.  This probably _isn't_ time to redesign every aspect of the
&gt;  Tor protocol that anybody finds problematic.
&gt;
&gt; 2.6. Low-hanging fruit and well-lit areas
&gt;
&gt;  Not all parts of Tor are tightly covered.  If it's possible to upgrade
&gt;  different parts of the system at different rates from one another, we
&gt;  should consider doing the stuff we can do easier, earlier.
&gt;
&gt;  But remember the story of the policeman who finds a drunk under a
&gt;  streetlamp, staring at the ground?  The cop asks, "What are you
&gt;  doing?"  The drunk says, "I'm looking for my keys!"  "Oh, did you drop
&gt;  them around here?" says the policeman.  "No," says the drunk, "But the
&gt;  light is so much better here!"
&gt;
&gt;  Or less proverbially: Simply because a change is easiest, does not
&gt;  mean it is the best use of our time.  We should avoid getting bogged
&gt;  down solving the _easy_ aspects of our system unless they happen also
&gt;  to be _important_.
&gt;
&gt; 2.7. Nice safe boring codes
&gt;
&gt;  Let's avoid, to the extent that we can:
&gt;    - being the primary user of any cryptographic construction or
&gt;      protocol.
&gt;    - anything that hasn't gotten much attention in the literature.
&gt;    - anything we would have to implement from scratch
&gt;    - anything without a nice BSD-licensed C implementation
&gt;
&gt;  Sometimes we'll have the choice of a more efficient algorithm or a
&gt;  more boring &amp; well-analyzed one.  We should not even consider trading
&gt;  conservative design for efficiency unless we are firmly in the
&gt;  critical path.
&gt;
&gt; 2.8. Key restrictions
&gt;
&gt;  Our spec says that RSA exponents should be 65537, but our code never
&gt;  checks for that.  If we want to bolster resistance against collision
&gt;  attacks, we could check this requirement.  To the best of my
&gt;  knowledge, nothing violates it except for tools like "shallot" that
&gt;  generate cute memorable .onion names.  If we want to be nice to
&gt;  shallot users, we could check the requirement for everything *except*
&gt;  hidden service identity keys.
&gt;
&gt; 3. Aspects of Tor's cryptography, and thoughts on how to upgrade them all
&gt;
&gt; 3.1. Link cryptography
&gt;
&gt;  Tor uses TLS for its link cryptography; it is easy to add more
&gt;  ciphersuites to the acceptable list, or increase the length of
&gt;  link-crypto public keys, or increase the length of the DH parameter,
&gt;  or sign the X509 certificates with any digest algorithm that OpenSSL
&gt;  clients will support.  Current Tor versions do not check any of these
&gt;  against expected values.
&gt;
&gt;  The identity key used to sign the second certificate in the current
&gt;  handshake protocol, however, is harder to change, since it needs to
&gt;  match up with what we see in the router descriptor for the router
&gt;  we're connecting to.  See notes on router identity below.  So long as
&gt;  the certificate chain is ultimately authenticated by a RSA-1024 key,
&gt;  it's not clear whether making the link RSA key longer on its own
&gt;  really improves matters or not.
&gt;
&gt;  Recall also that for anti-fingerprinting reasons, we're thinking of
&gt;  revising the protocol handshake sometime in the 0.2.3.x timeframe.
&gt;  If we do that, that might be a good time to make sure that we aren't
&gt;  limited by the old identity key size.
&gt;
&gt; 3.2. Circuit-extend crypto
&gt;
&gt;  Currently, our code requires RSA onion keys to be 1024 bits long.
&gt;  Additionally, current nodes will not deliver an EXTEND cell unless it
&gt;  is the right length.
&gt;
&gt;  For this, we might add a second, longer onion-key to router
&gt;  descriptors, and a second CREATE2 cell to open new circuits
&gt;  using this key type.  It should contain not only the onionskin, but
&gt;  also information on onionskin version and ciphersuite.  Onionskins
&gt;  generated for CREATE2 cells should use a larger DH group as well, and
&gt;  keys should be derived from DH results using a better digest algorithm.
&gt;
&gt;  We should remove the length limit on EXTEND cells, backported to all
&gt;  supported stable versions; call these "EXTEND2" cells.  Call these
&gt;  "lightly patched".  Clients could use the new EXTEND2/CREATE2 format
&gt;  whenever using a lightly patched or new server to extend to a new
&gt;  server, and the old EXTEND/CREATE format otherwise.
&gt;
&gt;  The new onion skin format should try to avoid the design oddities of
&gt;  our old one.  Instead of its current iffy hybrid encryption scheme, it
&gt;  should probably do something more like a BEAR/LIONESS operation with a
&gt;  fixed key on the g^x value, followed by a public key encryption on the
&gt;  start of the encrypted data.  (Robert reminded me about this
&gt;  construction.)
&gt;
&gt;  The current EXTEND cell format ends with a router identity
&gt;  fingerprint, which is used by the extended-from router to authenticate
&gt;  the extended-to router when it connects.  Changes to this will
&gt;  interact with changes to how long an identity key can be and to the
&gt;  link protocol; see notes on the link protocol above and about router
&gt;  identity below.
&gt;
&gt; 3.2.1. Circuit-extend crypto: fast case
&gt;
&gt;  When we do unauthenticated circuit extends with CREATE/CREATED_FAST,
&gt;  the two input values are combined with SHA1.  I believe that's okay;
&gt;  using any entropy here at all is overkill.
&gt;
&gt; 3.3. Relay crypto
&gt;
&gt;  Upon receiving relay cells, a router transforms the payload portion of
&gt;  the cell with the appropriate key appropriate key, sees if it
&gt;  recognizes the cell (the recognized field is zero, the digest field is
&gt;  correct, the cell is outbound), and passes them on if not.  It is
&gt;  possible for each hop in the circuit to handle the relay crypto
&gt;  differently; nobody but the client and the hop in question need to
&gt;  coordinate their operations.
&gt;
&gt;  It's not clear, though, whether updating the relay crypto algorithms
&gt;  would help anything, unless we changed the whole relay cell processing
&gt;  format too.  The stream cipher is good enough, and the use of 4 bytes
&gt;  of digest does not have enough bits to provide cryptographic strength,
&gt;  no matter what cipher we use.
&gt;
&gt;  This is the likeliest area for the second-system effect to strike;
&gt;  there are lots of opportunities to try to be more clever than we are
&gt;  now.
&gt;
&gt; 3.4. Router identity
&gt;
&gt;  This is one of the hardest things to change.  Right now, routers are
&gt;  identified by a "fingerprint" equal to the SHA1 hash of their 1024-bit
&gt;  identity key as given in their router descriptor.  No existing Tor
&gt;  will accept any other size of identity key, or any other hash
&gt;  algorithm.  The identity key itself is used:
&gt;    - To sign the router descriptors
&gt;    - To sign link-key certificates
&gt;    - To determine the least significant bits of circuit IDs used on a
&gt;      Tor instance's links (see tor-spec  §5.1)
&gt;
&gt;  The fingerprint is used:
&gt;    - To identify a router identity key in EXTEND cells
&gt;    - To identify a router identity key in bridge lines
&gt;    - Throughout the controller interface
&gt;    - To fetch bridge descriptors for a bridge
&gt;    - To identify a particular router throughout the codebase
&gt;    - In the .exit notation.
&gt;    - By the controller to identify nodes
&gt;    - To identify servers in the logs
&gt;    - Probably other places too
&gt;
&gt;  To begin to allow other key types, key lengths, and hash functions, we
&gt;  would either need to wait till all current Tors are obsolete, or allow
&gt;  routers to have more than one identity for a while.
&gt;
&gt;  To allow routers to have more than one identity, we need to
&gt;  cross-certify identity keys.  We can do this trivially, in theory, by
&gt;  listing both keys in the router descriptor and having both identities
&gt;  sign the descriptor.  In practice, we will need to analyze this pretty
&gt;  carefully to avoid attacks where one key is completely fake aimed to
&gt;  trick old clients somehow.
&gt;
&gt;  Upgrading the hash algorithm once would be easy: just say that all
&gt;  new-type keys get hashed using the new hash algorithm.  Remaining
&gt;  future-proof could be tricky.
&gt;
&gt;  This is one of the hardest areas to update; "SHA1 of identity key" is
&gt;  assumed in so many places throughout Tor that we'll probably need a
&gt;  lot of design work to work with something else.
&gt;
&gt; 3.5. Directory objects
&gt;
&gt;  Fortunately, the problem is not so bad for consensuses themselves,
&gt;  because:
&gt;    - Authority identity keys are allowed to be RSA keys of any length;
&gt;      in practice I think they are all 3072 bits.
&gt;    - Authority signing keys are also allowed to be of any length.
&gt;      AFAIK the code works with longer signing keys just fine.
&gt;    - Currently, votes are hashed with both sha1 and sha256; adding
&gt;      more hash algorithms isn't so hard.
&gt;    - Microdescriptor consensuses are all signed using sha256.  While
&gt;      regular consensuses are signed using sha1, exploitable collisions
&gt;      are hard to come up with, since once you had a collision, you
&gt;      would need to get a majority of other authorities to agree to
&gt;      generate it.
&gt;
&gt;  Router descriptors are currently identified by SHA1 digests of their
&gt;  identity keys and descriptor digests in regular consensuses, and by
&gt;  SHA1 digests of identity keys and SHA256 digests of microdescriptors
&gt;  in microdesc consensuses.  The consensus-flavors design allows us to
&gt;  generate new flavors of consensus that identity routers by new hashes
&gt;  of their identity keys.  Alternatively, existing consensuses could be
&gt;  expanded to contain more hashes, though that would have some space
&gt;  concerns.
&gt;
&gt;  Router descriptors themselves are signed using RSA-1024 identity keys
&gt;  and SHA1.  For information on updating identity keys, see above.
&gt;
&gt;  Router descriptors and extra-info documents cross-certify one another
&gt;  using SHA1.
&gt;
&gt;  Microdescriptors are currently specified to contain exactly one
&gt;  onion key, of length 1024 bits.
&gt;
&gt; 3.6. The directory protocol
&gt;
&gt;  Most objects are indexed by SHA1 hash of an identity key or a
&gt;  descriptor object.  Adding more hash types wouldn't be a huge problem
&gt;  at the directory cache level.
&gt;
&gt; 3.7. The hidden service protocol
&gt;
&gt;  Hidden services self-identify by a 1024-bit RSA key.  Other key
&gt;  lengths are not supported.  This key is turned into an 80 bit half
&gt;  SHA-1 hash for hidden service names.
&gt;
&gt;  The most simple change here would be to set an interface for putting
&gt;  the whole ugly SHA1 hash in the hidden service name.  Remember that
&gt;  this needs to coexist with the authentication system which also uses
&gt;  .onion hostnames; that hostnames top out around 255 characters and and
&gt;  their components top out at 63.
&gt;
&gt;  Currently, ESTABLISH_INTRO cells take a key length parameter, so in
&gt;  theory they allow longer keys.  The rest of the protocol assumes that
&gt;  this will be hashed into a 20-byte SHA1 identifier.  Changing that
&gt;  would require changes at the introduction point as well as the hidden
&gt;  service.
&gt;
&gt;  The parsing code for hidden service descriptors currently enforce a
&gt;  1024-bit identity key, though this does not seem to be described in
&gt;  the specification.  Changing that would be at least as hard as doing
&gt;  it for regular identity keys.
&gt;
&gt;  Fortunately, hidden services are nearly completely orthogonal to
&gt;  everything else.
&gt;

[Attachment #3 (text/html)]

Is there any writeup on the current status of Tor crypto?  doc or issue list. \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;/div&gt;&lt;div&gt;Weidong &lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On \
Tue, Dec 14, 2010 at 8:31 PM, Nick Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@torproject.org" \
target="_blank"&gt;nickm@torproject.org&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt;Here's something I've worked up, with fixes from \
Robert Ransom.  It's&lt;br&gt; currently in \
doc/spec/proposals/ideas/xxx-crypto-migration.txt.  Once&lt;br&gt; it's more discussed \
and worked out, it should turn into a real&lt;br&gt; proposal, but I'd like to kick the \
ball off here.&lt;br&gt; &lt;br&gt;
Robert has also written up a couple of documents I'll be forwarding in&lt;br&gt;
my next email.&lt;br&gt;
&lt;br&gt;
=====&lt;br&gt;
Title: Initial thoughts on migrating Tor to new cryptography&lt;br&gt;
Author: Nick Mathewson&lt;br&gt;
Created: 12 December 2010&lt;br&gt;
&lt;br&gt;
1. Introduction&lt;br&gt;
&lt;br&gt;
  Tor currently uses AES-128, RSA-1024, and SHA1.  Even though these&lt;br&gt;
  ciphers were a decent choice back in 2003, and even though attacking&lt;br&gt;
  these algorithms is by no means the best way for a well-funded&lt;br&gt;
  adversary to attack users (correlation attacks are still cheaper, even&lt;br&gt;
  with pessimistic assumptions about the security of each cipher), we&lt;br&gt;
  will want to move to better algorithms in the future.  Indeed, if&lt;br&gt;
  migrating to a new ciphersuite were simple, we would probably have&lt;br&gt;
  already moved to RSA-1024/AES-128/SHA256 or something like that.&lt;br&gt;
&lt;br&gt;
  So it's a good idea to start figuring out how we can move to better&lt;br&gt;
  ciphers.  Unfortunately, this is a bit nontrivial, so before we start&lt;br&gt;
  doing the design work here, we should start by examining the issues&lt;br&gt;
  involved.  Robert Ransom and I both decided to spend this weekend&lt;br&gt;
  writing up documents of this type so that we can see how much two&lt;br&gt;
  people working independently agree on.  I know more Tor than Robert;&lt;br&gt;
  Robert knows far more cryptography than I do.  With luck we'll&lt;br&gt;
  complement each other's work nicely.&lt;br&gt;
&lt;br&gt;
  A note on scope: This document WILL NOT attempt to pick a new cipher&lt;br&gt;
  or set of ciphers.  Instead, it's about how to migrate to new ciphers&lt;br&gt;
  in general.  Any algorithms mentioned other than those we use today&lt;br&gt;
  are just for illustration.&lt;br&gt;
&lt;br&gt;
  Also, I don't much consider the importance of updating each particular&lt;br&gt;
  usage; only the methods that you'd use to do it.&lt;br&gt;
&lt;br&gt;
  Also, this isn't a complete proposal.&lt;br&gt;
&lt;br&gt;
2. General principles and tricks&lt;br&gt;
&lt;br&gt;
  Before I get started, let's talk about some general design issues.&lt;br&gt;
&lt;br&gt;
2.1. Many algorithms or few?&lt;br&gt;
&lt;br&gt;
  Protocols like TLS and OpenPGP allow a wide choice of cryptographic&lt;br&gt;
  algorithms; so long as the sender and receiver (or the responder and&lt;br&gt;
  initiator) have at least one mutually acceptable algorithm, they can&lt;br&gt;
  converge upon it and send each other messages.&lt;br&gt;
&lt;br&gt;
  This isn't the best choice for anonymity designs.  If two clients&lt;br&gt;
  support a different set of algorithms, then an attacker can tell them&lt;br&gt;
  apart.  A protocol with N ciphersuites would in principle split&lt;br&gt;
  clients into 2**N-1 sets.  (In practice, nearly all users will use the&lt;br&gt;
  default, and most users who choose _not_ to use the default will do so&lt;br&gt;
  without considering the loss of anonymity.  See "Anonymity Loves&lt;br&gt;
  Company: Usability and the Network Effect".)&lt;br&gt;
&lt;br&gt;
  On the other hand, building only one ciphersuite into Tor has a flaw&lt;br&gt;
  of its own: it has proven difficult to migrate to another one.  So&lt;br&gt;
  perhaps instead of specifying only a single new ciphersuite, we should&lt;br&gt;
  specify more than one, with plans to switch over (based on a flag in&lt;br&gt;
  the consensus or some other secure signal) once the first choice of&lt;br&gt;
  algorithms start looking iffy.  This switch-based approach would seem&lt;br&gt;
  especially easy for parameterizable stuff like key sizes.&lt;br&gt;
&lt;br&gt;
2.2. Waiting for old clients and servers to upgrade&lt;br&gt;
&lt;br&gt;
  The easiest way to implement a shift in algorithms would be to declare&lt;br&gt;
  a "flag day": once we have the new versions of the protocols&lt;br&gt;
  implemented, pick a day by which everybody must upgrade to the new&lt;br&gt;
  software.  Before this day, the software would have the old behavior;&lt;br&gt;
  after this way, it would use the improved behavior.&lt;br&gt;
&lt;br&gt;
  Tor tries to avoid flag days whenever possible; they have well-known&lt;br&gt;
  issues.  First, since a number of our users don't automatically&lt;br&gt;
  update, it can take a while for people to upgrade to new versions of&lt;br&gt;
  our software.  Second and more worryingly, it's hard to get adequate&lt;br&gt;
  testing for new behavior that is off-by-default.  Flag days in other&lt;br&gt;
  systems have been known to leave whole networks more or less&lt;br&gt;
  inoperable for months; we should not trust in our skill to avoid&lt;br&gt;
  similar problems.&lt;br&gt;
&lt;br&gt;
  So if we're avoiding flag days, what can we do?&lt;br&gt;
&lt;br&gt;
  * We can add _support_ for new behavior early, and have clients use it&lt;br&gt;
    where it's available.  (Clients know the advertised versions of the&lt;br&gt;
    Tor servers they use-- but see 2.3 below for a danger here, and 2.4&lt;br&gt;
    for a bigger danger.)&lt;br&gt;
&lt;br&gt;
  * We can remove misfeatures that _prevent_ deployment of new&lt;br&gt;
    behavior.  For instance, if a certain key length has an arbitrary&lt;br&gt;
    1024-bit limit, we can remove that arbitrary limitation.&lt;br&gt;
&lt;br&gt;
  * Once an optional new behavior is ubiquitous enough, the authorities&lt;br&gt;
    can stop accepting descriptors from servers that do not have it&lt;br&gt;
    until they upgrade.&lt;br&gt;
&lt;br&gt;
  It is far easier to remove arbitrary limitations than to make other&lt;br&gt;
  changes; such changes are generally safe to back-port to older stable&lt;br&gt;
  release series.  But in general, it's much better to avoid any plans&lt;br&gt;
  that require waiting for any version of Tor to no longer be in common&lt;br&gt;
  use: a stable release can take on the order of 2.5 years to start&lt;br&gt;
  dropping off the radar.  Thandy might fix that, but even if a perfect&lt;br&gt;
  Thandy release comes out tomorrow, we'll still have lots of older&lt;br&gt;
  clients and relays not using it.&lt;br&gt;
&lt;br&gt;
  We'll have to approach the migration problem on a case-by-case basis&lt;br&gt;
  as we consider the algorithms used by Tor and how to change them.&lt;br&gt;
&lt;br&gt;
2.3. Early adopters and other partitioning dangers&lt;br&gt;
&lt;br&gt;
  It's pretty much unavoidable that clients running software that speak&lt;br&gt;
  the new version of any protocol will be distinguishable from those&lt;br&gt;
  that cannot speak the new version.  This is inevitable, though we&lt;br&gt;
  could try to minimize the number of such partitioning sets by having&lt;br&gt;
  features turned on in the same release rather than one-at-a-time.&lt;br&gt;
&lt;br&gt;
  Another option here is to have new protocols controlled by a&lt;br&gt;
  configuration tri-state with values "on", "off", and \
"auto".  The&lt;br&gt;  "auto" value means to look at the consensus to \
decide wither to use&lt;br&gt;  the feature; the other two values are self-explanatory.  \
We'd ship&lt;br&gt;  clients with the feature set to "auto" by default, with \
people only&lt;br&gt;  using "on" for testing.&lt;br&gt;
&lt;br&gt;
  If we're worried about early client-side implementations of a protocol&lt;br&gt;
  turning out to be broken, we can have the consensus value say _which_&lt;br&gt;
  versions should turn on the protocol.&lt;br&gt;
&lt;br&gt;
2.4. Avoid whole-circuit switches&lt;br&gt;
&lt;br&gt;
  One risky kind of protocol migration is a feature that gets used only&lt;br&gt;
  when all the routers in a circuit support it.  If such a feature is&lt;br&gt;
  implemented by few relays, then each relay learns a lot about the rest&lt;br&gt;
  of the path by seeing it used.  On the other hand, if the feature is&lt;br&gt;
  implemented by most relays, then a relay learns a lot about the rest of&lt;br&gt;
  the path when the feature is *not* used.&lt;br&gt;
&lt;br&gt;
  It's okay to have a feature that can be only used if two consecutive&lt;br&gt;
  routers in the patch support it: each router knows the ones adjacent&lt;br&gt;
  to it, after all, so knowing what version of Tor they're running is no&lt;br&gt;
  big deal.&lt;br&gt;
&lt;br&gt;
2.5. The Second System Effect rears its ugly head&lt;br&gt;
&lt;br&gt;
  Any attempt at improving Tor's crypto is likely to involve changes&lt;br&gt;
  throughout the Tor protocol.  We should be aware of the risks of&lt;br&gt;
  falling into what Fred Brooks called the "Second System Effect": when&lt;br&gt;
  redesigning a fielded system, it's always tempting to try to shovel in&lt;br&gt;
  every possible change that one ever wanted to make to it.&lt;br&gt;
&lt;br&gt;
  This is a fine time to make parts of our protocol that weren't&lt;br&gt;
  previously versionable into ones that are easier to upgrade in the&lt;br&gt;
  future.  This probably _isn't_ time to redesign every aspect of the&lt;br&gt;
  Tor protocol that anybody finds problematic.&lt;br&gt;
&lt;br&gt;
2.6. Low-hanging fruit and well-lit areas&lt;br&gt;
&lt;br&gt;
  Not all parts of Tor are tightly covered.  If it's possible to upgrade&lt;br&gt;
  different parts of the system at different rates from one another, we&lt;br&gt;
  should consider doing the stuff we can do easier, earlier.&lt;br&gt;
&lt;br&gt;
  But remember the story of the policeman who finds a drunk under a&lt;br&gt;
  streetlamp, staring at the ground?  The cop asks, "What are you&lt;br&gt;
  doing?"  The drunk says, "I'm looking for my keys!"  "Oh, \
did you drop&lt;br&gt;  them around here?" says the policeman.  "No," says \
the drunk, "But the&lt;br&gt;  light is so much better here!"&lt;br&gt;
&lt;br&gt;
  Or less proverbially: Simply because a change is easiest, does not&lt;br&gt;
  mean it is the best use of our time.  We should avoid getting bogged&lt;br&gt;
  down solving the _easy_ aspects of our system unless they happen also&lt;br&gt;
  to be _important_.&lt;br&gt;
&lt;br&gt;
2.7. Nice safe boring codes&lt;br&gt;
&lt;br&gt;
  Let's avoid, to the extent that we can:&lt;br&gt;
    - being the primary user of any cryptographic construction or&lt;br&gt;
      protocol.&lt;br&gt;
    - anything that hasn't gotten much attention in the literature.&lt;br&gt;
    - anything we would have to implement from scratch&lt;br&gt;
    - anything without a nice BSD-licensed C implementation&lt;br&gt;
&lt;br&gt;
  Sometimes we'll have the choice of a more efficient algorithm or a&lt;br&gt;
  more boring &amp; well-analyzed one.  We should not even consider trading&lt;br&gt;
  conservative design for efficiency unless we are firmly in the&lt;br&gt;
  critical path.&lt;br&gt;
&lt;br&gt;
2.8. Key restrictions&lt;br&gt;
&lt;br&gt;
  Our spec says that RSA exponents should be 65537, but our code never&lt;br&gt;
  checks for that.  If we want to bolster resistance against collision&lt;br&gt;
  attacks, we could check this requirement.  To the best of my&lt;br&gt;
  knowledge, nothing violates it except for tools like "shallot" that&lt;br&gt;
  generate cute memorable .onion names.  If we want to be nice to&lt;br&gt;
  shallot users, we could check the requirement for everything *except*&lt;br&gt;
  hidden service identity keys.&lt;br&gt;
&lt;br&gt;
3. Aspects of Tor's cryptography, and thoughts on how to upgrade them all&lt;br&gt;
&lt;br&gt;
3.1. Link cryptography&lt;br&gt;
&lt;br&gt;
  Tor uses TLS for its link cryptography; it is easy to add more&lt;br&gt;
  ciphersuites to the acceptable list, or increase the length of&lt;br&gt;
  link-crypto public keys, or increase the length of the DH parameter,&lt;br&gt;
  or sign the X509 certificates with any digest algorithm that OpenSSL&lt;br&gt;
  clients will support.  Current Tor versions do not check any of these&lt;br&gt;
  against expected values.&lt;br&gt;
&lt;br&gt;
  The identity key used to sign the second certificate in the current&lt;br&gt;
  handshake protocol, however, is harder to change, since it needs to&lt;br&gt;
  match up with what we see in the router descriptor for the router&lt;br&gt;
  we're connecting to.  See notes on router identity below.  So long as&lt;br&gt;
  the certificate chain is ultimately authenticated by a RSA-1024 key,&lt;br&gt;
  it's not clear whether making the link RSA key longer on its own&lt;br&gt;
  really improves matters or not.&lt;br&gt;
&lt;br&gt;
  Recall also that for anti-fingerprinting reasons, we're thinking of&lt;br&gt;
  revising the protocol handshake sometime in the 0.2.3.x timeframe.&lt;br&gt;
  If we do that, that might be a good time to make sure that we aren't&lt;br&gt;
  limited by the old identity key size.&lt;br&gt;
&lt;br&gt;
3.2. Circuit-extend crypto&lt;br&gt;
&lt;br&gt;
  Currently, our code requires RSA onion keys to be 1024 bits long.&lt;br&gt;
  Additionally, current nodes will not deliver an EXTEND cell unless it&lt;br&gt;
  is the right length.&lt;br&gt;
&lt;br&gt;
  For this, we might add a second, longer onion-key to router&lt;br&gt;
  descriptors, and a second CREATE2 cell to open new circuits&lt;br&gt;
  using this key type.  It should contain not only the onionskin, but&lt;br&gt;
  also information on onionskin version and ciphersuite.  Onionskins&lt;br&gt;
  generated for CREATE2 cells should use a larger DH group as well, and&lt;br&gt;
  keys should be derived from DH results using a better digest algorithm.&lt;br&gt;
&lt;br&gt;
  We should remove the length limit on EXTEND cells, backported to all&lt;br&gt;
  supported stable versions; call these "EXTEND2" cells.  Call these&lt;br&gt;
  "lightly patched".  Clients could use the new EXTEND2/CREATE2 format&lt;br&gt;
  whenever using a lightly patched or new server to extend to a new&lt;br&gt;
  server, and the old EXTEND/CREATE format otherwise.&lt;br&gt;
&lt;br&gt;
  The new onion skin format should try to avoid the design oddities of&lt;br&gt;
  our old one.  Instead of its current iffy hybrid encryption scheme, it&lt;br&gt;
  should probably do something more like a BEAR/LIONESS operation with a&lt;br&gt;
  fixed key on the g^x value, followed by a public key encryption on the&lt;br&gt;
  start of the encrypted data.  (Robert reminded me about this&lt;br&gt;
  construction.)&lt;br&gt;
&lt;br&gt;
  The current EXTEND cell format ends with a router identity&lt;br&gt;
  fingerprint, which is used by the extended-from router to authenticate&lt;br&gt;
  the extended-to router when it connects.  Changes to this will&lt;br&gt;
  interact with changes to how long an identity key can be and to the&lt;br&gt;
  link protocol; see notes on the link protocol above and about router&lt;br&gt;
  identity below.&lt;br&gt;
&lt;br&gt;
3.2.1. Circuit-extend crypto: fast case&lt;br&gt;
&lt;br&gt;
  When we do unauthenticated circuit extends with CREATE/CREATED_FAST,&lt;br&gt;
  the two input values are combined with SHA1.  I believe that's okay;&lt;br&gt;
  using any entropy here at all is overkill.&lt;br&gt;
&lt;br&gt;
3.3. Relay crypto&lt;br&gt;
&lt;br&gt;
  Upon receiving relay cells, a router transforms the payload portion of&lt;br&gt;
  the cell with the appropriate key appropriate key, sees if it&lt;br&gt;
  recognizes the cell (the recognized field is zero, the digest field is&lt;br&gt;
  correct, the cell is outbound), and passes them on if not.  It is&lt;br&gt;
  possible for each hop in the circuit to handle the relay crypto&lt;br&gt;
  differently; nobody but the client and the hop in question need to&lt;br&gt;
  coordinate their operations.&lt;br&gt;
&lt;br&gt;
  It's not clear, though, whether updating the relay crypto algorithms&lt;br&gt;
  would help anything, unless we changed the whole relay cell processing&lt;br&gt;
  format too.  The stream cipher is good enough, and the use of 4 bytes&lt;br&gt;
  of digest does not have enough bits to provide cryptographic strength,&lt;br&gt;
  no matter what cipher we use.&lt;br&gt;
&lt;br&gt;
  This is the likeliest area for the second-system effect to strike;&lt;br&gt;
  there are lots of opportunities to try to be more clever than we are&lt;br&gt;
  now.&lt;br&gt;
&lt;br&gt;
3.4. Router identity&lt;br&gt;
&lt;br&gt;
  This is one of the hardest things to change.  Right now, routers are&lt;br&gt;
  identified by a "fingerprint" equal to the SHA1 hash of their \
1024-bit&lt;br&gt;  identity key as given in their router descriptor.  No existing Tor&lt;br&gt;
  will accept any other size of identity key, or any other hash&lt;br&gt;
  algorithm.  The identity key itself is used:&lt;br&gt;
    - To sign the router descriptors&lt;br&gt;
    - To sign link-key certificates&lt;br&gt;
    - To determine the least significant bits of circuit IDs used on a&lt;br&gt;
      Tor instance's links (see tor-spec  §5.1)&lt;br&gt;
&lt;br&gt;
  The fingerprint is used:&lt;br&gt;
    - To identify a router identity key in EXTEND cells&lt;br&gt;
    - To identify a router identity key in bridge lines&lt;br&gt;
    - Throughout the controller interface&lt;br&gt;
    - To fetch bridge descriptors for a bridge&lt;br&gt;
    - To identify a particular router throughout the codebase&lt;br&gt;
    - In the .exit notation.&lt;br&gt;
    - By the controller to identify nodes&lt;br&gt;
    - To identify servers in the logs&lt;br&gt;
    - Probably other places too&lt;br&gt;
&lt;br&gt;
  To begin to allow other key types, key lengths, and hash functions, we&lt;br&gt;
  would either need to wait till all current Tors are obsolete, or allow&lt;br&gt;
  routers to have more than one identity for a while.&lt;br&gt;
&lt;br&gt;
  To allow routers to have more than one identity, we need to&lt;br&gt;
  cross-certify identity keys.  We can do this trivially, in theory, by&lt;br&gt;
  listing both keys in the router descriptor and having both identities&lt;br&gt;
  sign the descriptor.  In practice, we will need to analyze this pretty&lt;br&gt;
  carefully to avoid attacks where one key is completely fake aimed to&lt;br&gt;
  trick old clients somehow.&lt;br&gt;
&lt;br&gt;
  Upgrading the hash algorithm once would be easy: just say that all&lt;br&gt;
  new-type keys get hashed using the new hash algorithm.  Remaining&lt;br&gt;
  future-proof could be tricky.&lt;br&gt;
&lt;br&gt;
  This is one of the hardest areas to update; "SHA1 of identity key" is&lt;br&gt;
  assumed in so many places throughout Tor that we'll probably need a&lt;br&gt;
  lot of design work to work with something else.&lt;br&gt;
&lt;br&gt;
3.5. Directory objects&lt;br&gt;
&lt;br&gt;
  Fortunately, the problem is not so bad for consensuses themselves,&lt;br&gt;
  because:&lt;br&gt;
    - Authority identity keys are allowed to be RSA keys of any length;&lt;br&gt;
      in practice I think they are all 3072 bits.&lt;br&gt;
    - Authority signing keys are also allowed to be of any length.&lt;br&gt;
      AFAIK the code works with longer signing keys just fine.&lt;br&gt;
    - Currently, votes are hashed with both sha1 and sha256; adding&lt;br&gt;
      more hash algorithms isn't so hard.&lt;br&gt;
    - Microdescriptor consensuses are all signed using sha256.  While&lt;br&gt;
      regular consensuses are signed using sha1, exploitable collisions&lt;br&gt;
      are hard to come up with, since once you had a collision, you&lt;br&gt;
      would need to get a majority of other authorities to agree to&lt;br&gt;
      generate it.&lt;br&gt;
&lt;br&gt;
  Router descriptors are currently identified by SHA1 digests of their&lt;br&gt;
  identity keys and descriptor digests in regular consensuses, and by&lt;br&gt;
  SHA1 digests of identity keys and SHA256 digests of microdescriptors&lt;br&gt;
  in microdesc consensuses.  The consensus-flavors design allows us to&lt;br&gt;
  generate new flavors of consensus that identity routers by new hashes&lt;br&gt;
  of their identity keys.  Alternatively, existing consensuses could be&lt;br&gt;
  expanded to contain more hashes, though that would have some space&lt;br&gt;
  concerns.&lt;br&gt;
&lt;br&gt;
  Router descriptors themselves are signed using RSA-1024 identity keys&lt;br&gt;
  and SHA1.  For information on updating identity keys, see above.&lt;br&gt;
&lt;br&gt;
  Router descriptors and extra-info documents cross-certify one another&lt;br&gt;
  using SHA1.&lt;br&gt;
&lt;br&gt;
  Microdescriptors are currently specified to contain exactly one&lt;br&gt;
  onion key, of length 1024 bits.&lt;br&gt;
&lt;br&gt;
3.6. The directory protocol&lt;br&gt;
&lt;br&gt;
  Most objects are indexed by SHA1 hash of an identity key or a&lt;br&gt;
  descriptor object.  Adding more hash types wouldn't be a huge problem&lt;br&gt;
  at the directory cache level.&lt;br&gt;
&lt;br&gt;
3.7. The hidden service protocol&lt;br&gt;
&lt;br&gt;
  Hidden services self-identify by a 1024-bit RSA key.  Other key&lt;br&gt;
  lengths are not supported.  This key is turned into an 80 bit half&lt;br&gt;
  SHA-1 hash for hidden service names.&lt;br&gt;
&lt;br&gt;
  The most simple change here would be to set an interface for putting&lt;br&gt;
  the whole ugly SHA1 hash in the hidden service name.  Remember that&lt;br&gt;
  this needs to coexist with the authentication system which also uses&lt;br&gt;
  .onion hostnames; that hostnames top out around 255 characters and and&lt;br&gt;
  their components top out at 63.&lt;br&gt;
&lt;br&gt;
  Currently, ESTABLISH_INTRO cells take a key length parameter, so in&lt;br&gt;
  theory they allow longer keys.  The rest of the protocol assumes that&lt;br&gt;
  this will be hashed into a 20-byte SHA1 identifier.  Changing that&lt;br&gt;
  would require changes at the introduction point as well as the hidden&lt;br&gt;
  service.&lt;br&gt;
&lt;br&gt;
  The parsing code for hidden service descriptors currently enforce a&lt;br&gt;
  1024-bit identity key, though this does not seem to be described in&lt;br&gt;
  the specification.  Changing that would be at least as hard as doing&lt;br&gt;
  it for regular identity keys.&lt;br&gt;
&lt;br&gt;
  Fortunately, hidden services are nearly completely orthogonal to&lt;br&gt;
  everything else.&lt;br&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;



</body></email><email><emailId>20101217222035</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-12-17 22:20:35-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>


On Fri, 17 Dec 2010 14:02:55 -0800
Weidong Shao &lt;weidongshao@gmail.com&gt; wrote:

&gt; Is there any writeup on the current status of Tor crypto?  doc or issue
&gt; list.

See &lt;https://gitweb.torproject.org/tor.git/tree/HEAD:/doc/spec&gt;.

Circuit and link cryptography are described in tor-spec.txt .
dir-spec.txt describes cryptography used to authenticate Tor's
directory, and rend-spec.txt describes cryptography used to
authenticate hidden services (and their clients, when required by a
hidden service) and secure the connection between the client and
hidden service.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101218032714</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2010-12-18 03:27:14-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

Just throwing in my two cents here.

If there is talk about going back to the design board, and while you're
about crypto, I was wondering if this would be a good time to also think
about a UDP transport vs TCP.

Just wondering,

Kyle

On Tue, Dec 14, 2010 at 8:31 PM, Nick Mathewson &lt;nickm@torproject.org&gt;wrote:

&gt; Here's something I've worked up, with fixes from Robert Ransom.  It's
&gt; currently in doc/spec/proposals/ideas/xxx-crypto-migration.txt.  Once
&gt; it's more discussed and worked out, it should turn into a real
&gt; proposal, but I'd like to kick the ball off here.
&gt;
&gt; Robert has also written up a couple of documents I'll be forwarding in
&gt; my next email.
&gt;
&gt; =====
&gt; Title: Initial thoughts on migrating Tor to new cryptography
&gt; Author: Nick Mathewson
&gt; Created: 12 December 2010
&gt;
&gt; 1. Introduction
&gt;
&gt;  Tor currently uses AES-128, RSA-1024, and SHA1.  Even though these
&gt;  ciphers were a decent choice back in 2003, and even though attacking
&gt;  these algorithms is by no means the best way for a well-funded
&gt;  adversary to attack users (correlation attacks are still cheaper, even
&gt;  with pessimistic assumptions about the security of each cipher), we
&gt;  will want to move to better algorithms in the future.  Indeed, if
&gt;  migrating to a new ciphersuite were simple, we would probably have
&gt;  already moved to RSA-1024/AES-128/SHA256 or something like that.
&gt;
&gt;  So it's a good idea to start figuring out how we can move to better
&gt;  ciphers.  Unfortunately, this is a bit nontrivial, so before we start
&gt;  doing the design work here, we should start by examining the issues
&gt;  involved.  Robert Ransom and I both decided to spend this weekend
&gt;  writing up documents of this type so that we can see how much two
&gt;  people working independently agree on.  I know more Tor than Robert;
&gt;  Robert knows far more cryptography than I do.  With luck we'll
&gt;  complement each other's work nicely.
&gt;
&gt;  A note on scope: This document WILL NOT attempt to pick a new cipher
&gt;  or set of ciphers.  Instead, it's about how to migrate to new ciphers
&gt;  in general.  Any algorithms mentioned other than those we use today
&gt;  are just for illustration.
&gt;
&gt;  Also, I don't much consider the importance of updating each particular
&gt;  usage; only the methods that you'd use to do it.
&gt;
&gt;  Also, this isn't a complete proposal.
&gt;
&gt; 2. General principles and tricks
&gt;
&gt;  Before I get started, let's talk about some general design issues.
&gt;
&gt; 2.1. Many algorithms or few?
&gt;
&gt;  Protocols like TLS and OpenPGP allow a wide choice of cryptographic
&gt;  algorithms; so long as the sender and receiver (or the responder and
&gt;  initiator) have at least one mutually acceptable algorithm, they can
&gt;  converge upon it and send each other messages.
&gt;
&gt;  This isn't the best choice for anonymity designs.  If two clients
&gt;  support a different set of algorithms, then an attacker can tell them
&gt;  apart.  A protocol with N ciphersuites would in principle split
&gt;  clients into 2**N-1 sets.  (In practice, nearly all users will use the
&gt;  default, and most users who choose _not_ to use the default will do so
&gt;  without considering the loss of anonymity.  See "Anonymity Loves
&gt;  Company: Usability and the Network Effect".)
&gt;
&gt;  On the other hand, building only one ciphersuite into Tor has a flaw
&gt;  of its own: it has proven difficult to migrate to another one.  So
&gt;  perhaps instead of specifying only a single new ciphersuite, we should
&gt;  specify more than one, with plans to switch over (based on a flag in
&gt;  the consensus or some other secure signal) once the first choice of
&gt;  algorithms start looking iffy.  This switch-based approach would seem
&gt;  especially easy for parameterizable stuff like key sizes.
&gt;
&gt; 2.2. Waiting for old clients and servers to upgrade
&gt;
&gt;  The easiest way to implement a shift in algorithms would be to declare
&gt;  a "flag day": once we have the new versions of the protocols
&gt;  implemented, pick a day by which everybody must upgrade to the new
&gt;  software.  Before this day, the software would have the old behavior;
&gt;  after this way, it would use the improved behavior.
&gt;
&gt;  Tor tries to avoid flag days whenever possible; they have well-known
&gt;  issues.  First, since a number of our users don't automatically
&gt;  update, it can take a while for people to upgrade to new versions of
&gt;  our software.  Second and more worryingly, it's hard to get adequate
&gt;  testing for new behavior that is off-by-default.  Flag days in other
&gt;  systems have been known to leave whole networks more or less
&gt;  inoperable for months; we should not trust in our skill to avoid
&gt;  similar problems.
&gt;
&gt;  So if we're avoiding flag days, what can we do?
&gt;
&gt;  * We can add _support_ for new behavior early, and have clients use it
&gt;    where it's available.  (Clients know the advertised versions of the
&gt;    Tor servers they use-- but see 2.3 below for a danger here, and 2.4
&gt;    for a bigger danger.)
&gt;
&gt;  * We can remove misfeatures that _prevent_ deployment of new
&gt;    behavior.  For instance, if a certain key length has an arbitrary
&gt;    1024-bit limit, we can remove that arbitrary limitation.
&gt;
&gt;  * Once an optional new behavior is ubiquitous enough, the authorities
&gt;    can stop accepting descriptors from servers that do not have it
&gt;    until they upgrade.
&gt;
&gt;  It is far easier to remove arbitrary limitations than to make other
&gt;  changes; such changes are generally safe to back-port to older stable
&gt;  release series.  But in general, it's much better to avoid any plans
&gt;  that require waiting for any version of Tor to no longer be in common
&gt;  use: a stable release can take on the order of 2.5 years to start
&gt;  dropping off the radar.  Thandy might fix that, but even if a perfect
&gt;  Thandy release comes out tomorrow, we'll still have lots of older
&gt;  clients and relays not using it.
&gt;
&gt;  We'll have to approach the migration problem on a case-by-case basis
&gt;  as we consider the algorithms used by Tor and how to change them.
&gt;
&gt; 2.3. Early adopters and other partitioning dangers
&gt;
&gt;  It's pretty much unavoidable that clients running software that speak
&gt;  the new version of any protocol will be distinguishable from those
&gt;  that cannot speak the new version.  This is inevitable, though we
&gt;  could try to minimize the number of such partitioning sets by having
&gt;  features turned on in the same release rather than one-at-a-time.
&gt;
&gt;  Another option here is to have new protocols controlled by a
&gt;  configuration tri-state with values "on", "off", and "auto".  The
&gt;  "auto" value means to look at the consensus to decide wither to use
&gt;  the feature; the other two values are self-explanatory.  We'd ship
&gt;  clients with the feature set to "auto" by default, with people only
&gt;  using "on" for testing.
&gt;
&gt;  If we're worried about early client-side implementations of a protocol
&gt;  turning out to be broken, we can have the consensus value say _which_
&gt;  versions should turn on the protocol.
&gt;
&gt; 2.4. Avoid whole-circuit switches
&gt;
&gt;  One risky kind of protocol migration is a feature that gets used only
&gt;  when all the routers in a circuit support it.  If such a feature is
&gt;  implemented by few relays, then each relay learns a lot about the rest
&gt;  of the path by seeing it used.  On the other hand, if the feature is
&gt;  implemented by most relays, then a relay learns a lot about the rest of
&gt;  the path when the feature is *not* used.
&gt;
&gt;  It's okay to have a feature that can be only used if two consecutive
&gt;  routers in the patch support it: each router knows the ones adjacent
&gt;  to it, after all, so knowing what version of Tor they're running is no
&gt;  big deal.
&gt;
&gt; 2.5. The Second System Effect rears its ugly head
&gt;
&gt;  Any attempt at improving Tor's crypto is likely to involve changes
&gt;  throughout the Tor protocol.  We should be aware of the risks of
&gt;  falling into what Fred Brooks called the "Second System Effect": when
&gt;  redesigning a fielded system, it's always tempting to try to shovel in
&gt;  every possible change that one ever wanted to make to it.
&gt;
&gt;  This is a fine time to make parts of our protocol that weren't
&gt;  previously versionable into ones that are easier to upgrade in the
&gt;  future.  This probably _isn't_ time to redesign every aspect of the
&gt;  Tor protocol that anybody finds problematic.
&gt;
&gt; 2.6. Low-hanging fruit and well-lit areas
&gt;
&gt;  Not all parts of Tor are tightly covered.  If it's possible to upgrade
&gt;  different parts of the system at different rates from one another, we
&gt;  should consider doing the stuff we can do easier, earlier.
&gt;
&gt;  But remember the story of the policeman who finds a drunk under a
&gt;  streetlamp, staring at the ground?  The cop asks, "What are you
&gt;  doing?"  The drunk says, "I'm looking for my keys!"  "Oh, did you drop
&gt;  them around here?" says the policeman.  "No," says the drunk, "But the
&gt;  light is so much better here!"
&gt;
&gt;  Or less proverbially: Simply because a change is easiest, does not
&gt;  mean it is the best use of our time.  We should avoid getting bogged
&gt;  down solving the _easy_ aspects of our system unless they happen also
&gt;  to be _important_.
&gt;
&gt; 2.7. Nice safe boring codes
&gt;
&gt;  Let's avoid, to the extent that we can:
&gt;    - being the primary user of any cryptographic construction or
&gt;      protocol.
&gt;    - anything that hasn't gotten much attention in the literature.
&gt;    - anything we would have to implement from scratch
&gt;    - anything without a nice BSD-licensed C implementation
&gt;
&gt;  Sometimes we'll have the choice of a more efficient algorithm or a
&gt;  more boring &amp; well-analyzed one.  We should not even consider trading
&gt;  conservative design for efficiency unless we are firmly in the
&gt;  critical path.
&gt;
&gt; 2.8. Key restrictions
&gt;
&gt;  Our spec says that RSA exponents should be 65537, but our code never
&gt;  checks for that.  If we want to bolster resistance against collision
&gt;  attacks, we could check this requirement.  To the best of my
&gt;  knowledge, nothing violates it except for tools like "shallot" that
&gt;  generate cute memorable .onion names.  If we want to be nice to
&gt;  shallot users, we could check the requirement for everything *except*
&gt;  hidden service identity keys.
&gt;
&gt; 3. Aspects of Tor's cryptography, and thoughts on how to upgrade them all
&gt;
&gt; 3.1. Link cryptography
&gt;
&gt;  Tor uses TLS for its link cryptography; it is easy to add more
&gt;  ciphersuites to the acceptable list, or increase the length of
&gt;  link-crypto public keys, or increase the length of the DH parameter,
&gt;  or sign the X509 certificates with any digest algorithm that OpenSSL
&gt;  clients will support.  Current Tor versions do not check any of these
&gt;  against expected values.
&gt;
&gt;  The identity key used to sign the second certificate in the current
&gt;  handshake protocol, however, is harder to change, since it needs to
&gt;  match up with what we see in the router descriptor for the router
&gt;  we're connecting to.  See notes on router identity below.  So long as
&gt;  the certificate chain is ultimately authenticated by a RSA-1024 key,
&gt;  it's not clear whether making the link RSA key longer on its own
&gt;  really improves matters or not.
&gt;
&gt;  Recall also that for anti-fingerprinting reasons, we're thinking of
&gt;  revising the protocol handshake sometime in the 0.2.3.x timeframe.
&gt;  If we do that, that might be a good time to make sure that we aren't
&gt;  limited by the old identity key size.
&gt;
&gt; 3.2. Circuit-extend crypto
&gt;
&gt;  Currently, our code requires RSA onion keys to be 1024 bits long.
&gt;  Additionally, current nodes will not deliver an EXTEND cell unless it
&gt;  is the right length.
&gt;
&gt;  For this, we might add a second, longer onion-key to router
&gt;  descriptors, and a second CREATE2 cell to open new circuits
&gt;  using this key type.  It should contain not only the onionskin, but
&gt;  also information on onionskin version and ciphersuite.  Onionskins
&gt;  generated for CREATE2 cells should use a larger DH group as well, and
&gt;  keys should be derived from DH results using a better digest algorithm.
&gt;
&gt;  We should remove the length limit on EXTEND cells, backported to all
&gt;  supported stable versions; call these "EXTEND2" cells.  Call these
&gt;  "lightly patched".  Clients could use the new EXTEND2/CREATE2 format
&gt;  whenever using a lightly patched or new server to extend to a new
&gt;  server, and the old EXTEND/CREATE format otherwise.
&gt;
&gt;  The new onion skin format should try to avoid the design oddities of
&gt;  our old one.  Instead of its current iffy hybrid encryption scheme, it
&gt;  should probably do something more like a BEAR/LIONESS operation with a
&gt;  fixed key on the g^x value, followed by a public key encryption on the
&gt;  start of the encrypted data.  (Robert reminded me about this
&gt;  construction.)
&gt;
&gt;  The current EXTEND cell format ends with a router identity
&gt;  fingerprint, which is used by the extended-from router to authenticate
&gt;  the extended-to router when it connects.  Changes to this will
&gt;  interact with changes to how long an identity key can be and to the
&gt;  link protocol; see notes on the link protocol above and about router
&gt;  identity below.
&gt;
&gt; 3.2.1. Circuit-extend crypto: fast case
&gt;
&gt;  When we do unauthenticated circuit extends with CREATE/CREATED_FAST,
&gt;  the two input values are combined with SHA1.  I believe that's okay;
&gt;  using any entropy here at all is overkill.
&gt;
&gt; 3.3. Relay crypto
&gt;
&gt;  Upon receiving relay cells, a router transforms the payload portion of
&gt;  the cell with the appropriate key appropriate key, sees if it
&gt;  recognizes the cell (the recognized field is zero, the digest field is
&gt;  correct, the cell is outbound), and passes them on if not.  It is
&gt;  possible for each hop in the circuit to handle the relay crypto
&gt;  differently; nobody but the client and the hop in question need to
&gt;  coordinate their operations.
&gt;
&gt;  It's not clear, though, whether updating the relay crypto algorithms
&gt;  would help anything, unless we changed the whole relay cell processing
&gt;  format too.  The stream cipher is good enough, and the use of 4 bytes
&gt;  of digest does not have enough bits to provide cryptographic strength,
&gt;  no matter what cipher we use.
&gt;
&gt;  This is the likeliest area for the second-system effect to strike;
&gt;  there are lots of opportunities to try to be more clever than we are
&gt;  now.
&gt;
&gt; 3.4. Router identity
&gt;
&gt;  This is one of the hardest things to change.  Right now, routers are
&gt;  identified by a "fingerprint" equal to the SHA1 hash of their 1024-bit
&gt;  identity key as given in their router descriptor.  No existing Tor
&gt;  will accept any other size of identity key, or any other hash
&gt;  algorithm.  The identity key itself is used:
&gt;    - To sign the router descriptors
&gt;    - To sign link-key certificates
&gt;    - To determine the least significant bits of circuit IDs used on a
&gt;      Tor instance's links (see tor-spec  §5.1)
&gt;
&gt;  The fingerprint is used:
&gt;    - To identify a router identity key in EXTEND cells
&gt;    - To identify a router identity key in bridge lines
&gt;    - Throughout the controller interface
&gt;    - To fetch bridge descriptors for a bridge
&gt;    - To identify a particular router throughout the codebase
&gt;    - In the .exit notation.
&gt;    - By the controller to identify nodes
&gt;    - To identify servers in the logs
&gt;    - Probably other places too
&gt;
&gt;  To begin to allow other key types, key lengths, and hash functions, we
&gt;  would either need to wait till all current Tors are obsolete, or allow
&gt;  routers to have more than one identity for a while.
&gt;
&gt;  To allow routers to have more than one identity, we need to
&gt;  cross-certify identity keys.  We can do this trivially, in theory, by
&gt;  listing both keys in the router descriptor and having both identities
&gt;  sign the descriptor.  In practice, we will need to analyze this pretty
&gt;  carefully to avoid attacks where one key is completely fake aimed to
&gt;  trick old clients somehow.
&gt;
&gt;  Upgrading the hash algorithm once would be easy: just say that all
&gt;  new-type keys get hashed using the new hash algorithm.  Remaining
&gt;  future-proof could be tricky.
&gt;
&gt;  This is one of the hardest areas to update; "SHA1 of identity key" is
&gt;  assumed in so many places throughout Tor that we'll probably need a
&gt;  lot of design work to work with something else.
&gt;
&gt; 3.5. Directory objects
&gt;
&gt;  Fortunately, the problem is not so bad for consensuses themselves,
&gt;  because:
&gt;    - Authority identity keys are allowed to be RSA keys of any length;
&gt;      in practice I think they are all 3072 bits.
&gt;    - Authority signing keys are also allowed to be of any length.
&gt;      AFAIK the code works with longer signing keys just fine.
&gt;    - Currently, votes are hashed with both sha1 and sha256; adding
&gt;      more hash algorithms isn't so hard.
&gt;    - Microdescriptor consensuses are all signed using sha256.  While
&gt;      regular consensuses are signed using sha1, exploitable collisions
&gt;      are hard to come up with, since once you had a collision, you
&gt;      would need to get a majority of other authorities to agree to
&gt;      generate it.
&gt;
&gt;  Router descriptors are currently identified by SHA1 digests of their
&gt;  identity keys and descriptor digests in regular consensuses, and by
&gt;  SHA1 digests of identity keys and SHA256 digests of microdescriptors
&gt;  in microdesc consensuses.  The consensus-flavors design allows us to
&gt;  generate new flavors of consensus that identity routers by new hashes
&gt;  of their identity keys.  Alternatively, existing consensuses could be
&gt;  expanded to contain more hashes, though that would have some space
&gt;  concerns.
&gt;
&gt;  Router descriptors themselves are signed using RSA-1024 identity keys
&gt;  and SHA1.  For information on updating identity keys, see above.
&gt;
&gt;  Router descriptors and extra-info documents cross-certify one another
&gt;  using SHA1.
&gt;
&gt;  Microdescriptors are currently specified to contain exactly one
&gt;  onion key, of length 1024 bits.
&gt;
&gt; 3.6. The directory protocol
&gt;
&gt;  Most objects are indexed by SHA1 hash of an identity key or a
&gt;  descriptor object.  Adding more hash types wouldn't be a huge problem
&gt;  at the directory cache level.
&gt;
&gt; 3.7. The hidden service protocol
&gt;
&gt;  Hidden services self-identify by a 1024-bit RSA key.  Other key
&gt;  lengths are not supported.  This key is turned into an 80 bit half
&gt;  SHA-1 hash for hidden service names.
&gt;
&gt;  The most simple change here would be to set an interface for putting
&gt;  the whole ugly SHA1 hash in the hidden service name.  Remember that
&gt;  this needs to coexist with the authentication system which also uses
&gt;  .onion hostnames; that hostnames top out around 255 characters and and
&gt;  their components top out at 63.
&gt;
&gt;  Currently, ESTABLISH_INTRO cells take a key length parameter, so in
&gt;  theory they allow longer keys.  The rest of the protocol assumes that
&gt;  this will be hashed into a 20-byte SHA1 identifier.  Changing that
&gt;  would require changes at the introduction point as well as the hidden
&gt;  service.
&gt;
&gt;  The parsing code for hidden service descriptors currently enforce a
&gt;  1024-bit identity key, though this does not seem to be described in
&gt;  the specification.  Changing that would be at least as hard as doing
&gt;  it for regular identity keys.
&gt;
&gt;  Fortunately, hidden services are nearly completely orthogonal to
&gt;  everything else.
&gt;

[Attachment #3 (text/html)]

Just throwing in my two cents here.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If there is talk about going \
back to the design board, and while you're about crypto, I was wondering if this \
would be a good time to also think about a UDP transport vs TCP.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Just wondering,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Kyle&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Tue, Dec 14, 2010 at 8:31 PM, Nick Mathewson &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:nickm@torproject.org"&gt;nickm@torproject.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt;Here's something I've worked up, with fixes \
from Robert Ransom.  It's&lt;br&gt; currently in \
doc/spec/proposals/ideas/xxx-crypto-migration.txt.  Once&lt;br&gt; it's more discussed \
and worked out, it should turn into a real&lt;br&gt; proposal, but I'd like to kick the \
ball off here.&lt;br&gt; &lt;br&gt;
Robert has also written up a couple of documents I'll be forwarding in&lt;br&gt;
my next email.&lt;br&gt;
&lt;br&gt;
=====&lt;br&gt;
Title: Initial thoughts on migrating Tor to new cryptography&lt;br&gt;
Author: Nick Mathewson&lt;br&gt;
Created: 12 December 2010&lt;br&gt;
&lt;br&gt;
1. Introduction&lt;br&gt;
&lt;br&gt;
  Tor currently uses AES-128, RSA-1024, and SHA1.  Even though these&lt;br&gt;
  ciphers were a decent choice back in 2003, and even though attacking&lt;br&gt;
  these algorithms is by no means the best way for a well-funded&lt;br&gt;
  adversary to attack users (correlation attacks are still cheaper, even&lt;br&gt;
  with pessimistic assumptions about the security of each cipher), we&lt;br&gt;
  will want to move to better algorithms in the future.  Indeed, if&lt;br&gt;
  migrating to a new ciphersuite were simple, we would probably have&lt;br&gt;
  already moved to RSA-1024/AES-128/SHA256 or something like that.&lt;br&gt;
&lt;br&gt;
  So it's a good idea to start figuring out how we can move to better&lt;br&gt;
  ciphers.  Unfortunately, this is a bit nontrivial, so before we start&lt;br&gt;
  doing the design work here, we should start by examining the issues&lt;br&gt;
  involved.  Robert Ransom and I both decided to spend this weekend&lt;br&gt;
  writing up documents of this type so that we can see how much two&lt;br&gt;
  people working independently agree on.  I know more Tor than Robert;&lt;br&gt;
  Robert knows far more cryptography than I do.  With luck we'll&lt;br&gt;
  complement each other's work nicely.&lt;br&gt;
&lt;br&gt;
  A note on scope: This document WILL NOT attempt to pick a new cipher&lt;br&gt;
  or set of ciphers.  Instead, it's about how to migrate to new ciphers&lt;br&gt;
  in general.  Any algorithms mentioned other than those we use today&lt;br&gt;
  are just for illustration.&lt;br&gt;
&lt;br&gt;
  Also, I don't much consider the importance of updating each particular&lt;br&gt;
  usage; only the methods that you'd use to do it.&lt;br&gt;
&lt;br&gt;
  Also, this isn't a complete proposal.&lt;br&gt;
&lt;br&gt;
2. General principles and tricks&lt;br&gt;
&lt;br&gt;
  Before I get started, let's talk about some general design issues.&lt;br&gt;
&lt;br&gt;
2.1. Many algorithms or few?&lt;br&gt;
&lt;br&gt;
  Protocols like TLS and OpenPGP allow a wide choice of cryptographic&lt;br&gt;
  algorithms; so long as the sender and receiver (or the responder and&lt;br&gt;
  initiator) have at least one mutually acceptable algorithm, they can&lt;br&gt;
  converge upon it and send each other messages.&lt;br&gt;
&lt;br&gt;
  This isn't the best choice for anonymity designs.  If two clients&lt;br&gt;
  support a different set of algorithms, then an attacker can tell them&lt;br&gt;
  apart.  A protocol with N ciphersuites would in principle split&lt;br&gt;
  clients into 2**N-1 sets.  (In practice, nearly all users will use the&lt;br&gt;
  default, and most users who choose _not_ to use the default will do so&lt;br&gt;
  without considering the loss of anonymity.  See "Anonymity Loves&lt;br&gt;
  Company: Usability and the Network Effect".)&lt;br&gt;
&lt;br&gt;
  On the other hand, building only one ciphersuite into Tor has a flaw&lt;br&gt;
  of its own: it has proven difficult to migrate to another one.  So&lt;br&gt;
  perhaps instead of specifying only a single new ciphersuite, we should&lt;br&gt;
  specify more than one, with plans to switch over (based on a flag in&lt;br&gt;
  the consensus or some other secure signal) once the first choice of&lt;br&gt;
  algorithms start looking iffy.  This switch-based approach would seem&lt;br&gt;
  especially easy for parameterizable stuff like key sizes.&lt;br&gt;
&lt;br&gt;
2.2. Waiting for old clients and servers to upgrade&lt;br&gt;
&lt;br&gt;
  The easiest way to implement a shift in algorithms would be to declare&lt;br&gt;
  a "flag day": once we have the new versions of the protocols&lt;br&gt;
  implemented, pick a day by which everybody must upgrade to the new&lt;br&gt;
  software.  Before this day, the software would have the old behavior;&lt;br&gt;
  after this way, it would use the improved behavior.&lt;br&gt;
&lt;br&gt;
  Tor tries to avoid flag days whenever possible; they have well-known&lt;br&gt;
  issues.  First, since a number of our users don't automatically&lt;br&gt;
  update, it can take a while for people to upgrade to new versions of&lt;br&gt;
  our software.  Second and more worryingly, it's hard to get adequate&lt;br&gt;
  testing for new behavior that is off-by-default.  Flag days in other&lt;br&gt;
  systems have been known to leave whole networks more or less&lt;br&gt;
  inoperable for months; we should not trust in our skill to avoid&lt;br&gt;
  similar problems.&lt;br&gt;
&lt;br&gt;
  So if we're avoiding flag days, what can we do?&lt;br&gt;
&lt;br&gt;
  * We can add _support_ for new behavior early, and have clients use it&lt;br&gt;
    where it's available.  (Clients know the advertised versions of the&lt;br&gt;
    Tor servers they use-- but see 2.3 below for a danger here, and 2.4&lt;br&gt;
    for a bigger danger.)&lt;br&gt;
&lt;br&gt;
  * We can remove misfeatures that _prevent_ deployment of new&lt;br&gt;
    behavior.  For instance, if a certain key length has an arbitrary&lt;br&gt;
    1024-bit limit, we can remove that arbitrary limitation.&lt;br&gt;
&lt;br&gt;
  * Once an optional new behavior is ubiquitous enough, the authorities&lt;br&gt;
    can stop accepting descriptors from servers that do not have it&lt;br&gt;
    until they upgrade.&lt;br&gt;
&lt;br&gt;
  It is far easier to remove arbitrary limitations than to make other&lt;br&gt;
  changes; such changes are generally safe to back-port to older stable&lt;br&gt;
  release series.  But in general, it's much better to avoid any plans&lt;br&gt;
  that require waiting for any version of Tor to no longer be in common&lt;br&gt;
  use: a stable release can take on the order of 2.5 years to start&lt;br&gt;
  dropping off the radar.  Thandy might fix that, but even if a perfect&lt;br&gt;
  Thandy release comes out tomorrow, we'll still have lots of older&lt;br&gt;
  clients and relays not using it.&lt;br&gt;
&lt;br&gt;
  We'll have to approach the migration problem on a case-by-case basis&lt;br&gt;
  as we consider the algorithms used by Tor and how to change them.&lt;br&gt;
&lt;br&gt;
2.3. Early adopters and other partitioning dangers&lt;br&gt;
&lt;br&gt;
  It's pretty much unavoidable that clients running software that speak&lt;br&gt;
  the new version of any protocol will be distinguishable from those&lt;br&gt;
  that cannot speak the new version.  This is inevitable, though we&lt;br&gt;
  could try to minimize the number of such partitioning sets by having&lt;br&gt;
  features turned on in the same release rather than one-at-a-time.&lt;br&gt;
&lt;br&gt;
  Another option here is to have new protocols controlled by a&lt;br&gt;
  configuration tri-state with values "on", "off", and \
"auto".  The&lt;br&gt;  "auto" value means to look at the consensus to \
decide wither to use&lt;br&gt;  the feature; the other two values are self-explanatory.  \
We'd ship&lt;br&gt;  clients with the feature set to "auto" by default, with \
people only&lt;br&gt;  using "on" for testing.&lt;br&gt;
&lt;br&gt;
  If we're worried about early client-side implementations of a protocol&lt;br&gt;
  turning out to be broken, we can have the consensus value say _which_&lt;br&gt;
  versions should turn on the protocol.&lt;br&gt;
&lt;br&gt;
2.4. Avoid whole-circuit switches&lt;br&gt;
&lt;br&gt;
  One risky kind of protocol migration is a feature that gets used only&lt;br&gt;
  when all the routers in a circuit support it.  If such a feature is&lt;br&gt;
  implemented by few relays, then each relay learns a lot about the rest&lt;br&gt;
  of the path by seeing it used.  On the other hand, if the feature is&lt;br&gt;
  implemented by most relays, then a relay learns a lot about the rest of&lt;br&gt;
  the path when the feature is *not* used.&lt;br&gt;
&lt;br&gt;
  It's okay to have a feature that can be only used if two consecutive&lt;br&gt;
  routers in the patch support it: each router knows the ones adjacent&lt;br&gt;
  to it, after all, so knowing what version of Tor they're running is no&lt;br&gt;
  big deal.&lt;br&gt;
&lt;br&gt;
2.5. The Second System Effect rears its ugly head&lt;br&gt;
&lt;br&gt;
  Any attempt at improving Tor's crypto is likely to involve changes&lt;br&gt;
  throughout the Tor protocol.  We should be aware of the risks of&lt;br&gt;
  falling into what Fred Brooks called the "Second System Effect": when&lt;br&gt;
  redesigning a fielded system, it's always tempting to try to shovel in&lt;br&gt;
  every possible change that one ever wanted to make to it.&lt;br&gt;
&lt;br&gt;
  This is a fine time to make parts of our protocol that weren't&lt;br&gt;
  previously versionable into ones that are easier to upgrade in the&lt;br&gt;
  future.  This probably _isn't_ time to redesign every aspect of the&lt;br&gt;
  Tor protocol that anybody finds problematic.&lt;br&gt;
&lt;br&gt;
2.6. Low-hanging fruit and well-lit areas&lt;br&gt;
&lt;br&gt;
  Not all parts of Tor are tightly covered.  If it's possible to upgrade&lt;br&gt;
  different parts of the system at different rates from one another, we&lt;br&gt;
  should consider doing the stuff we can do easier, earlier.&lt;br&gt;
&lt;br&gt;
  But remember the story of the policeman who finds a drunk under a&lt;br&gt;
  streetlamp, staring at the ground?  The cop asks, "What are you&lt;br&gt;
  doing?"  The drunk says, "I'm looking for my keys!"  "Oh, \
did you drop&lt;br&gt;  them around here?" says the policeman.  "No," says \
the drunk, "But the&lt;br&gt;  light is so much better here!"&lt;br&gt;
&lt;br&gt;
  Or less proverbially: Simply because a change is easiest, does not&lt;br&gt;
  mean it is the best use of our time.  We should avoid getting bogged&lt;br&gt;
  down solving the _easy_ aspects of our system unless they happen also&lt;br&gt;
  to be _important_.&lt;br&gt;
&lt;br&gt;
2.7. Nice safe boring codes&lt;br&gt;
&lt;br&gt;
  Let's avoid, to the extent that we can:&lt;br&gt;
    - being the primary user of any cryptographic construction or&lt;br&gt;
      protocol.&lt;br&gt;
    - anything that hasn't gotten much attention in the literature.&lt;br&gt;
    - anything we would have to implement from scratch&lt;br&gt;
    - anything without a nice BSD-licensed C implementation&lt;br&gt;
&lt;br&gt;
  Sometimes we'll have the choice of a more efficient algorithm or a&lt;br&gt;
  more boring &amp; well-analyzed one.  We should not even consider trading&lt;br&gt;
  conservative design for efficiency unless we are firmly in the&lt;br&gt;
  critical path.&lt;br&gt;
&lt;br&gt;
2.8. Key restrictions&lt;br&gt;
&lt;br&gt;
  Our spec says that RSA exponents should be 65537, but our code never&lt;br&gt;
  checks for that.  If we want to bolster resistance against collision&lt;br&gt;
  attacks, we could check this requirement.  To the best of my&lt;br&gt;
  knowledge, nothing violates it except for tools like "shallot" that&lt;br&gt;
  generate cute memorable .onion names.  If we want to be nice to&lt;br&gt;
  shallot users, we could check the requirement for everything *except*&lt;br&gt;
  hidden service identity keys.&lt;br&gt;
&lt;br&gt;
3. Aspects of Tor's cryptography, and thoughts on how to upgrade them all&lt;br&gt;
&lt;br&gt;
3.1. Link cryptography&lt;br&gt;
&lt;br&gt;
  Tor uses TLS for its link cryptography; it is easy to add more&lt;br&gt;
  ciphersuites to the acceptable list, or increase the length of&lt;br&gt;
  link-crypto public keys, or increase the length of the DH parameter,&lt;br&gt;
  or sign the X509 certificates with any digest algorithm that OpenSSL&lt;br&gt;
  clients will support.  Current Tor versions do not check any of these&lt;br&gt;
  against expected values.&lt;br&gt;
&lt;br&gt;
  The identity key used to sign the second certificate in the current&lt;br&gt;
  handshake protocol, however, is harder to change, since it needs to&lt;br&gt;
  match up with what we see in the router descriptor for the router&lt;br&gt;
  we're connecting to.  See notes on router identity below.  So long as&lt;br&gt;
  the certificate chain is ultimately authenticated by a RSA-1024 key,&lt;br&gt;
  it's not clear whether making the link RSA key longer on its own&lt;br&gt;
  really improves matters or not.&lt;br&gt;
&lt;br&gt;
  Recall also that for anti-fingerprinting reasons, we're thinking of&lt;br&gt;
  revising the protocol handshake sometime in the 0.2.3.x timeframe.&lt;br&gt;
  If we do that, that might be a good time to make sure that we aren't&lt;br&gt;
  limited by the old identity key size.&lt;br&gt;
&lt;br&gt;
3.2. Circuit-extend crypto&lt;br&gt;
&lt;br&gt;
  Currently, our code requires RSA onion keys to be 1024 bits long.&lt;br&gt;
  Additionally, current nodes will not deliver an EXTEND cell unless it&lt;br&gt;
  is the right length.&lt;br&gt;
&lt;br&gt;
  For this, we might add a second, longer onion-key to router&lt;br&gt;
  descriptors, and a second CREATE2 cell to open new circuits&lt;br&gt;
  using this key type.  It should contain not only the onionskin, but&lt;br&gt;
  also information on onionskin version and ciphersuite.  Onionskins&lt;br&gt;
  generated for CREATE2 cells should use a larger DH group as well, and&lt;br&gt;
  keys should be derived from DH results using a better digest algorithm.&lt;br&gt;
&lt;br&gt;
  We should remove the length limit on EXTEND cells, backported to all&lt;br&gt;
  supported stable versions; call these "EXTEND2" cells.  Call these&lt;br&gt;
  "lightly patched".  Clients could use the new EXTEND2/CREATE2 format&lt;br&gt;
  whenever using a lightly patched or new server to extend to a new&lt;br&gt;
  server, and the old EXTEND/CREATE format otherwise.&lt;br&gt;
&lt;br&gt;
  The new onion skin format should try to avoid the design oddities of&lt;br&gt;
  our old one.  Instead of its current iffy hybrid encryption scheme, it&lt;br&gt;
  should probably do something more like a BEAR/LIONESS operation with a&lt;br&gt;
  fixed key on the g^x value, followed by a public key encryption on the&lt;br&gt;
  start of the encrypted data.  (Robert reminded me about this&lt;br&gt;
  construction.)&lt;br&gt;
&lt;br&gt;
  The current EXTEND cell format ends with a router identity&lt;br&gt;
  fingerprint, which is used by the extended-from router to authenticate&lt;br&gt;
  the extended-to router when it connects.  Changes to this will&lt;br&gt;
  interact with changes to how long an identity key can be and to the&lt;br&gt;
  link protocol; see notes on the link protocol above and about router&lt;br&gt;
  identity below.&lt;br&gt;
&lt;br&gt;
3.2.1. Circuit-extend crypto: fast case&lt;br&gt;
&lt;br&gt;
  When we do unauthenticated circuit extends with CREATE/CREATED_FAST,&lt;br&gt;
  the two input values are combined with SHA1.  I believe that's okay;&lt;br&gt;
  using any entropy here at all is overkill.&lt;br&gt;
&lt;br&gt;
3.3. Relay crypto&lt;br&gt;
&lt;br&gt;
  Upon receiving relay cells, a router transforms the payload portion of&lt;br&gt;
  the cell with the appropriate key appropriate key, sees if it&lt;br&gt;
  recognizes the cell (the recognized field is zero, the digest field is&lt;br&gt;
  correct, the cell is outbound), and passes them on if not.  It is&lt;br&gt;
  possible for each hop in the circuit to handle the relay crypto&lt;br&gt;
  differently; nobody but the client and the hop in question need to&lt;br&gt;
  coordinate their operations.&lt;br&gt;
&lt;br&gt;
  It's not clear, though, whether updating the relay crypto algorithms&lt;br&gt;
  would help anything, unless we changed the whole relay cell processing&lt;br&gt;
  format too.  The stream cipher is good enough, and the use of 4 bytes&lt;br&gt;
  of digest does not have enough bits to provide cryptographic strength,&lt;br&gt;
  no matter what cipher we use.&lt;br&gt;
&lt;br&gt;
  This is the likeliest area for the second-system effect to strike;&lt;br&gt;
  there are lots of opportunities to try to be more clever than we are&lt;br&gt;
  now.&lt;br&gt;
&lt;br&gt;
3.4. Router identity&lt;br&gt;
&lt;br&gt;
  This is one of the hardest things to change.  Right now, routers are&lt;br&gt;
  identified by a "fingerprint" equal to the SHA1 hash of their \
1024-bit&lt;br&gt;  identity key as given in their router descriptor.  No existing Tor&lt;br&gt;
  will accept any other size of identity key, or any other hash&lt;br&gt;
  algorithm.  The identity key itself is used:&lt;br&gt;
    - To sign the router descriptors&lt;br&gt;
    - To sign link-key certificates&lt;br&gt;
    - To determine the least significant bits of circuit IDs used on a&lt;br&gt;
      Tor instance's links (see tor-spec  §5.1)&lt;br&gt;
&lt;br&gt;
  The fingerprint is used:&lt;br&gt;
    - To identify a router identity key in EXTEND cells&lt;br&gt;
    - To identify a router identity key in bridge lines&lt;br&gt;
    - Throughout the controller interface&lt;br&gt;
    - To fetch bridge descriptors for a bridge&lt;br&gt;
    - To identify a particular router throughout the codebase&lt;br&gt;
    - In the .exit notation.&lt;br&gt;
    - By the controller to identify nodes&lt;br&gt;
    - To identify servers in the logs&lt;br&gt;
    - Probably other places too&lt;br&gt;
&lt;br&gt;
  To begin to allow other key types, key lengths, and hash functions, we&lt;br&gt;
  would either need to wait till all current Tors are obsolete, or allow&lt;br&gt;
  routers to have more than one identity for a while.&lt;br&gt;
&lt;br&gt;
  To allow routers to have more than one identity, we need to&lt;br&gt;
  cross-certify identity keys.  We can do this trivially, in theory, by&lt;br&gt;
  listing both keys in the router descriptor and having both identities&lt;br&gt;
  sign the descriptor.  In practice, we will need to analyze this pretty&lt;br&gt;
  carefully to avoid attacks where one key is completely fake aimed to&lt;br&gt;
  trick old clients somehow.&lt;br&gt;
&lt;br&gt;
  Upgrading the hash algorithm once would be easy: just say that all&lt;br&gt;
  new-type keys get hashed using the new hash algorithm.  Remaining&lt;br&gt;
  future-proof could be tricky.&lt;br&gt;
&lt;br&gt;
  This is one of the hardest areas to update; "SHA1 of identity key" is&lt;br&gt;
  assumed in so many places throughout Tor that we'll probably need a&lt;br&gt;
  lot of design work to work with something else.&lt;br&gt;
&lt;br&gt;
3.5. Directory objects&lt;br&gt;
&lt;br&gt;
  Fortunately, the problem is not so bad for consensuses themselves,&lt;br&gt;
  because:&lt;br&gt;
    - Authority identity keys are allowed to be RSA keys of any length;&lt;br&gt;
      in practice I think they are all 3072 bits.&lt;br&gt;
    - Authority signing keys are also allowed to be of any length.&lt;br&gt;
      AFAIK the code works with longer signing keys just fine.&lt;br&gt;
    - Currently, votes are hashed with both sha1 and sha256; adding&lt;br&gt;
      more hash algorithms isn't so hard.&lt;br&gt;
    - Microdescriptor consensuses are all signed using sha256.  While&lt;br&gt;
      regular consensuses are signed using sha1, exploitable collisions&lt;br&gt;
      are hard to come up with, since once you had a collision, you&lt;br&gt;
      would need to get a majority of other authorities to agree to&lt;br&gt;
      generate it.&lt;br&gt;
&lt;br&gt;
  Router descriptors are currently identified by SHA1 digests of their&lt;br&gt;
  identity keys and descriptor digests in regular consensuses, and by&lt;br&gt;
  SHA1 digests of identity keys and SHA256 digests of microdescriptors&lt;br&gt;
  in microdesc consensuses.  The consensus-flavors design allows us to&lt;br&gt;
  generate new flavors of consensus that identity routers by new hashes&lt;br&gt;
  of their identity keys.  Alternatively, existing consensuses could be&lt;br&gt;
  expanded to contain more hashes, though that would have some space&lt;br&gt;
  concerns.&lt;br&gt;
&lt;br&gt;
  Router descriptors themselves are signed using RSA-1024 identity keys&lt;br&gt;
  and SHA1.  For information on updating identity keys, see above.&lt;br&gt;
&lt;br&gt;
  Router descriptors and extra-info documents cross-certify one another&lt;br&gt;
  using SHA1.&lt;br&gt;
&lt;br&gt;
  Microdescriptors are currently specified to contain exactly one&lt;br&gt;
  onion key, of length 1024 bits.&lt;br&gt;
&lt;br&gt;
3.6. The directory protocol&lt;br&gt;
&lt;br&gt;
  Most objects are indexed by SHA1 hash of an identity key or a&lt;br&gt;
  descriptor object.  Adding more hash types wouldn't be a huge problem&lt;br&gt;
  at the directory cache level.&lt;br&gt;
&lt;br&gt;
3.7. The hidden service protocol&lt;br&gt;
&lt;br&gt;
  Hidden services self-identify by a 1024-bit RSA key.  Other key&lt;br&gt;
  lengths are not supported.  This key is turned into an 80 bit half&lt;br&gt;
  SHA-1 hash for hidden service names.&lt;br&gt;
&lt;br&gt;
  The most simple change here would be to set an interface for putting&lt;br&gt;
  the whole ugly SHA1 hash in the hidden service name.  Remember that&lt;br&gt;
  this needs to coexist with the authentication system which also uses&lt;br&gt;
  .onion hostnames; that hostnames top out around 255 characters and and&lt;br&gt;
  their components top out at 63.&lt;br&gt;
&lt;br&gt;
  Currently, ESTABLISH_INTRO cells take a key length parameter, so in&lt;br&gt;
  theory they allow longer keys.  The rest of the protocol assumes that&lt;br&gt;
  this will be hashed into a 20-byte SHA1 identifier.  Changing that&lt;br&gt;
  would require changes at the introduction point as well as the hidden&lt;br&gt;
  service.&lt;br&gt;
&lt;br&gt;
  The parsing code for hidden service descriptors currently enforce a&lt;br&gt;
  1024-bit identity key, though this does not seem to be described in&lt;br&gt;
  the specification.  Changing that would be at least as hard as doing&lt;br&gt;
  it for regular identity keys.&lt;br&gt;
&lt;br&gt;
  Fortunately, hidden services are nearly completely orthogonal to&lt;br&gt;
  everything else.&lt;br&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;



</body></email><email><emailId>20101218053013</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-12-18 05:30:13-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

On Fri, Dec 17, 2010 at 10:27 PM, Kyle Williams
&lt;kyle.kwilliams@gmail.com&gt; wrote:
&gt; Just throwing in my two cents here.
&gt; If there is talk about going back to the design board, and while you're
&gt; about crypto, I was wondering if this would be a good time to also think
&gt; about a UDP transport vs TCP.

I've got no objection, and it's not unreasonable to do any crypto
redesign with an eye to how improved protocols would play out for UDP
transports.  But they're fairly big problems, and I don't want to
force us to solve both at once, or come up with one master plan for
everything.  (See section 2.6 above. ;) )

(As an aside, I don't personally see this as a "going back to the
design board" for Tor as a whole so much as "figuring out how to
upgrade part of the original Tor design that we hadn't really put much
thought into making upgradeable when we designed it." )

yrs,
-- 
Nick
</body></email><email><emailId>20101218140104</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2010-12-18 14:01:04-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

One thing that I would like to point out is that .onion addresses will
always contain a public key, and we want to keep them short. This
means ECC (un)fortunately, but apparently DJB has an unencumbered
implementation.
The other thing I would like to note is that when we extend a relay,
we are going to reveal something about the client if we use a protocol
version number that is externally visible to the passing relay. I
don't really see a way around this given that the next relay needs to
know in what format the remainder of the data is in the packet

So I think we also have 2 separate problems here. Problem 1 is this
upgrade, and Problem 2 is future-proofing. Unfortunately they feed
into each other.

What we could do is (depending on how tor responds to unused commands)
is defined EXT_CREAT as packet number 10 which has the format
CircID 2 bytes
10       1 byte
SUITE  1 byte, 0 for this revision.
PAYLOAD  fills remainder of packet.

When a client receives indication that its EXT_CREAT was not
recognized it falls back on CREATE. ORs send back a packet that
indicates if they do not recognize the SUITE and the client falls back
to an earlier revision.
It is important that all clients support only 2 methods to avoid
massive fracturing of the anonymous set. ORs probably also should also
do this.
Anyway, that is my 2 cents.
Sincerely,
Watson Ladd
</body></email><email><emailId>20101218224803</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-12-18 22:48:03-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>


On Sat, 18 Dec 2010 09:01:04 -0500
Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:

&gt; One thing that I would like to point out is that .onion addresses will
&gt; always contain a public key, and we want to keep them short. This
&gt; means ECC (un)fortunately, but apparently DJB has an unencumbered
&gt; implementation.

A .onion address currently contains an 80-bit hash of a public key, not
a public key itself.  We will probably add an address format containing
a longer hash of a public key long before we add an address format
containing one coordinate of an elliptic curve public key itself.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101218230700</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2010-12-18 23:07:00-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

On Fri, Dec 17, 2010 at 9:30 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Fri, Dec 17, 2010 at 10:27 PM, Kyle Williams
&gt; &lt;kyle.kwilliams@gmail.com&gt; wrote:
&gt; &gt; Just throwing in my two cents here.
&gt; &gt; If there is talk about going back to the design board, and while you're
&gt; &gt; about crypto, I was wondering if this would be a good time to also think
&gt; &gt; about a UDP transport vs TCP.
&gt;
&gt; (As an aside, I don't personally see this as a "going back to the
&gt; design board" for Tor as a whole so much as "figuring out how to
&gt; upgrade part of the original Tor design that we hadn't really put much
&gt; thought into making upgradeable when we designed it." )
&gt;
&gt; Much better wording. ;)

[Attachment #3 (text/html)]

&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Fri, Dec 17, 2010 at 9:30 PM, Nick Mathewson \
&lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Fri, Dec 17, 2010 at 10:27 PM, Kyle \
Williams&lt;br&gt; &lt;&lt;a href="mailto:kyle.kwilliams@gmail.com"&gt;kyle.kwilliams@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt; &gt; Just throwing in my two cents here.&lt;br&gt;
&gt; If there is talk about going back to the design board, and while you're&lt;br&gt;
&gt; about crypto, I was wondering if this would be a good time to also think&lt;br&gt;
&gt; about a UDP transport vs TCP.&lt;br&gt;&lt;br&gt;&lt;/div&gt;
(As an aside, I don't personally see this as a "going back to the&lt;br&gt;
design board" for Tor as a whole so much as "figuring out how to&lt;br&gt;
upgrade part of the original Tor design that we hadn't really put much&lt;br&gt;
thought into making upgradeable when we designed it." \
)&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;Much better wording. ;)&lt;div&gt;&lt;br&gt;&lt;/div&gt;



</body></email><email><emailId>20101219033417</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-12-19 03:34:17-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

On Sat, Dec 18, 2010 at 9:01 AM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
 [...]
&gt; When a client receives indication that its EXT_CREAT was not
&gt; recognized it falls back on CREATE. ORs send back a packet that
&gt; indicates if they do not recognize the SUITE and the client falls back
&gt; to an earlier revision.

Actually, the fallback mechanism probably isn't even needed: remember,
the client has a descriptor for the servers that it wants to extend
from and to, so it knows which keys and ciphersuites the target server
supports, and which extend protocols the origin server supports.

You're right that it's important to limit partitioning opportunities
in any protocol revision; I tried to go over that in section 2, but we
shouldn't assume that I've said the last word on this.  We should
continue to look for ways to revise and improve whatever we come up
with to get the partitioning and other undesirable things down to a
minimum.

-- 
Nick
</body></email><email><emailId>20101219134613</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2010-12-19 13:46:13-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

On Sat, Dec 18, 2010 at 10:34 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; On Sat, Dec 18, 2010 at 9:01 AM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt;  [...]
&gt;&gt; When a client receives indication that its EXT_CREAT was not
&gt;&gt; recognized it falls back on CREATE. ORs send back a packet that
&gt;&gt; indicates if they do not recognize the SUITE and the client falls back
&gt;&gt; to an earlier revision.
&gt;
&gt; Actually, the fallback mechanism probably isn't even needed: remember,
&gt; the client has a descriptor for the servers that it wants to extend
&gt; from and to, so it knows which keys and ciphersuites the target server
&gt; supports, and which extend protocols the origin server supports.

Looking at the documentation I see the directory is extensible whereas
what is on the wire is less likely to be.

&gt;
&gt; You're right that it's important to limit partitioning opportunities
&gt; in any protocol revision; I tried to go over that in section 2, but we
&gt; shouldn't assume that I've said the last word on this.  We should
&gt; continue to look for ways to revise and improve whatever we come up
&gt; with to get the partitioning and other undesirable things down to a
&gt; minimum.
One way is to be very conservative in suite choices so we don't have
to change them that often. I'm going to also go out on a limb and say
that we also want a crypto API like NaCL that lets us just say
enciphered=encrypt(key, unenciphered) and doesn't force us to worry
about padding or modes because this is a much simpler abstraction
layer and so offers less opportunity for mistakes that could threaten
security. I'll put together a demo program sometime to demonstrate
this.
&gt;
&gt; --
&gt; Nick
&gt;



-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin

</body></email><email><emailId>20101202132954</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-12-02 13:29:54-0400</timestampReceived><subject>Re: Missing certificates</subject><body>

On Thu, Dec 02, 2010 at 08:18:55AM -0500, Ian Goldberg wrote:
&gt; Every time I launch 0.2.3, I see these messages:

To be clear, this is an OR, not an OP.

&gt; Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
&gt; with signing key F7C7B9191C74C0BA07363C84D37BBAD3A8A6C6D8: launching
&gt; request.
&gt; Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
&gt; with signing key 604834622B54F2D9BA39B34AC53924546733AA60: launching
&gt; request.
&gt; 
&gt; Whose certificates are these, and why are we continually missing them?

   - Ian
</body></email><email><emailId>20100804190604</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-08-04 19:06:04-0400</timestampReceived><subject>Re: Second Tor online "developer party" on Monday from 18:00 to 20:00</subject><body>

Hi Nick,

Sorry if I am asking the obvious. I cant see a reference in the email to 
the IRC channel.
I'd like to join you guys.

With kind regards,
Cav Edwards



Nick Mathewson wrote:
&gt; Hi, folks!  This email is a heads-up about our next online
&gt; nonstructured mass developer meeting, still called a "developer party"
&gt; on the superstitious belief that if we act like it's supposed to be
&gt; fun, it will be.   The last one was fun, after all.
&gt;
&gt; (I'm announcing this one on or-dev, since that's where people
&gt; suggested that I announce it after I announced the last one on another
&gt; list.  If you don't think these messages should be on or-dev, please
&gt; email me personally [not the list] to say so.)
&gt;
&gt; It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
&gt; channel on irc.oftc.net.  That's 14:00 to 16:00 eastern, and 11:00 to
&gt; 13:00 pacific, if I can still do math with my current jetlag.
&gt;
&gt; General notes:
&gt; * If you're not free to make it, or if you're not free to make it for
&gt; the whole time, don't worry.  There will be more of these at other
&gt; times ranging from "too late in Europe" to "too early in California".
&gt; * If you're not an actual developer on Tor, you're welcome to come and
&gt; hang out, but this is mainly a time for developers to chat and plot
&gt; and generally confab.
&gt; * We're probably not going to be "partying" for every minute of all 2
&gt; hours; think of this as a salon where people wander in and out and
&gt; take breaks to go into a corner and eat cheese or debug trac or
&gt; whatever.
&gt; * The format will probably change in the future as we get some
&gt; experience with it and learn more about what does (and doesn't) work
&gt; for us.  If having 2 open hours is too much, let's do less.
&gt; * I'm going to try to "host" this developer party.  Since you can't
&gt; serve food over IRC, and there's no need to vacuum the floor before
&gt; the party starts, I'm not quite sure what my responsibility will be
&gt; other than being around the whole time and trying to make sure the
&gt; conversation stays interesting.  I'll play it by ear.
&gt;
&gt; peace,
&gt;   
</body></email><email><emailId>20100703112528</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-07-03 11:25:28-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

On Sat, Jul 03, 2010 at 12:08:53PM +0100, cav@gotadsl.co.uk wrote 0.2K bytes in 10 lines about:
&gt; The build on Windows reports a make file that has incorrect options.
&gt; Is anyone aware of this ?
&gt;
&gt; """make: *** No targets specified and no makefile found.  Stop."""

How are you trying to build it?  Obviously I was able to build a binary
and package so I know it works.

Here's how I build:
https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
Skype:  lewmanator
</body></email><email><emailId>20100703113105</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-03 11:31:05-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

Sorry All,

False alarm. I seem to have an over-zealous virus checker.

With kind regards,
Cav Edwards



Cav wrote:
&gt; Dear Tor Team,
&gt;
&gt; The build on Windows reports a make file that has incorrect options.
&gt; Is anyone aware of this ?
&gt;
&gt; """make: *** No targets specified and no makefile found.  Stop."""
&gt;
&gt; Thanks in advance.
&gt;
&gt; Cav Edwards
&gt; ------------------------------------------------------------------------
&gt;
&gt;
&gt; No virus found in this incoming message.
&gt; Checked by AVG - www.avg.com 
&gt; Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Sorry All,&lt;br&gt;
&lt;br&gt;
False alarm. I seem to have an over-zealous virus checker.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Cav wrote:
&lt;blockquote cite="mid:4C2F1A45.8010707@gotadsl.co.uk" type="cite"&gt;Dear
Tor Team,
  &lt;br&gt;
  &lt;br&gt;
The build on Windows reports a make file that has incorrect options.
  &lt;br&gt;
Is anyone aware of this ?
  &lt;br&gt;
  &lt;br&gt;
"""make: *** No targets specified and no makefile found.  Stop."""
  &lt;br&gt;
  &lt;br&gt;
Thanks in advance.
  &lt;br&gt;
  &lt;br&gt;
Cav Edwards
  &lt;br&gt;
  &lt;pre wrap=""&gt;
&lt;hr size="4" width="90%"&gt;

No virus found in this incoming message.
Checked by AVG - &lt;a class="moz-txt-link-abbreviated" href="http://www.avg.com"&gt;www.avg.com&lt;/a&gt; 
Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00

  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20100703121616</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-03 12:16:16-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

Thank you Andrew,

My MinGW environment is broken at the moment, so thats the reason this end.
I will pay attention to how you build.

Thanks again !!!

With kind regards,
Cav Edwards



andrew@torproject.org wrote:
&gt; On Sat, Jul 03, 2010 at 12:08:53PM +0100, cav@gotadsl.co.uk wrote 0.2K bytes in 10 lines about:
&gt;   
&gt;&gt; The build on Windows reports a make file that has incorrect options.
&gt;&gt; Is anyone aware of this ?
&gt;&gt;
&gt;&gt; """make: *** No targets specified and no makefile found.  Stop."""
&gt;&gt;     
&gt;
&gt; How are you trying to build it?  Obviously I was able to build a binary
&gt; and package so I know it works.
&gt;
&gt; Here's how I build:
&gt; https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt
&gt;
&gt;   
&gt; ------------------------------------------------------------------------
&gt;
&gt;
&gt; No virus found in this incoming message.
&gt; Checked by AVG - www.avg.com 
&gt; Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Thank you Andrew,&lt;br&gt;
&lt;br&gt;
My MinGW environment is broken at the moment, so thats the reason this
end.&lt;br&gt;
I will pay attention to how you build.&lt;br&gt;
&lt;br&gt;
Thanks again !!!&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;a class="moz-txt-link-abbreviated" \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt; wrote: &lt;blockquote \
cite="mid:20100703112527.GA752@interloper.org" type="cite"&gt;  &lt;pre wrap=""&gt;On Sat, Jul \
03, 2010 at 12:08:53PM +0100, &lt;a class="moz-txt-link-abbreviated" \
href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt; wrote 0.2K bytes in 10 lines \
about:  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;The build on Windows reports a make file that has incorrect options.
Is anyone aware of this ?

"""make: *** No targets specified and no makefile found.  Stop."""
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
How are you trying to build it?  Obviously I was able to build a binary
and package so I know it works.

Here's how I build:
&lt;a class="moz-txt-link-freetext" \
href="https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt"&gt;https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt&lt;/a&gt;


  &lt;/pre&gt;
  &lt;pre wrap=""&gt;
&lt;hr size="4" width="90%"&gt;

No virus found in this incoming message.
Checked by AVG - &lt;a class="moz-txt-link-abbreviated" \
                href="http://www.avg.com"&gt;www.avg.com&lt;/a&gt; 
Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00

  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100703204236</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-03 20:42:36-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

Hi Folks,

Andrew: Thank you so much for your article. Its much more succinct than 
the one I had.

Is there a way around the problem below ?
"""
                LIBDEPS=" $LIBRARIES -lwsock32 -lgdi32" \
                link_app.${shlib_target}
make[2]: Entering directory `/d/workspace++/openssl-0.9.8l/apps'
( :; LIBDEPS="${LIBDEPS:--L.. -lssl  -L.. -lcrypto -lwsock32 -lgdi32}"; 
LDCMD="$
{LDCMD:-gcc}"; LDFLAGS="${LDFLAGS:--DOPENSSL_THREADS  -DDSO_WIN32 
-mno-cygwin -D
L_ENDIAN -fomit-frame-pointer -O3 -march=i486 -Wall -D_WIN32_WINNT=0x333 
-DOPENS
SL_BN_ASM_PART_WORDS -DOPENSSL_IA32_SSE2 -DSHA1_ASM -DMD5_ASM 
-DRMD160_ASM -DAES
_ASM}"; LIBPATH=`for x in $LIBDEPS; do if echo $x | grep '^ *-L' &gt; 
/dev/null 2&gt;&amp;
1; then echo $x | sed -e 's/^ *-L//'; fi; done | uniq`; LIBPATH=`echo 
$LIBPATH |
 sed -e 's/ /:/g'`; LD_LIBRARY_PATH=$LIBPATH:$LD_LIBRARY_PATH ${LDCMD} 
${LDFLAGS
} -o ${APPNAME:=openssl.exe} openssl.o verify.o asn1pars.o req.o dgst.o 
dh.o dhp
aram.o enc.o passwd.o gendh.o errstr.o ca.o pkcs7.o crl2p7.o crl.o rsa.o 
rsautl.
o dsa.o dsaparam.o ec.o ecparam.o x509.o genrsa.o gendsa.o s_server.o 
s_client.o
 speed.o s_time.o apps.o s_cb.o s_socket.o app_rand.o version.o 
sess_id.o cipher
s.o nseq.o pkcs12.o pkcs8.o spkac.o smime.o rand.o engine.o ocsp.o 
prime.o cms.o
 ${LIBDEPS} )
../libcrypto.a(eng_all.o):eng_all.c:(.text+0xe): undefined reference to 
`ENGINE_
load_4758cca'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x13): undefined reference to 
`ENGINE
_load_aep'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x18): undefined reference to 
`ENGINE
_load_atalla'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x1d): undefined reference to 
`ENGINE
_load_cswift'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x22): undefined reference to 
`ENGINE
_load_chil'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x27): undefined reference to 
`ENGINE
_load_nuron'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x2c): undefined reference to 
`ENGINE
_load_sureware'
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x34): undefined reference to 
`ENGINE
_load_ubsec'
make[2]: *** [link_app.] Error 1
make[2]: Leaving directory `/d/workspace++/openssl-0.9.8l/apps'
make[1]: *** [openssl.exe] Error 2
make[1]: Leaving directory `/d/workspace++/openssl-0.9.8l/apps'
make: *** [build_apps] Error 1
"""

With kind regards,
Cav Edwards



Cav wrote:
&gt; Thank you Andrew,
&gt;
&gt; My MinGW environment is broken at the moment, so thats the reason this 
&gt; end.
&gt; I will pay attention to how you build.
&gt;
&gt; Thanks again !!!
&gt;
&gt; With kind regards,
&gt; Cav Edwards
&gt;
&gt;
&gt;
&gt; andrew@torproject.org wrote:
&gt;&gt; On Sat, Jul 03, 2010 at 12:08:53PM +0100, cav@gotadsl.co.uk wrote 0.2K bytes in 10 lines about:
&gt;&gt;   
&gt;&gt;&gt; The build on Windows reports a make file that has incorrect options.
&gt;&gt;&gt; Is anyone aware of this ?
&gt;&gt;&gt;
&gt;&gt;&gt; """make: *** No targets specified and no makefile found.  Stop."""
&gt;&gt;&gt;     
&gt;&gt;
&gt;&gt; How are you trying to build it?  Obviously I was able to build a binary
&gt;&gt; and package so I know it works.
&gt;&gt;
&gt;&gt; Here's how I build:
&gt;&gt; https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt
&gt;&gt;
&gt;&gt;   
&gt;&gt; ------------------------------------------------------------------------
&gt;&gt;
&gt;&gt;
&gt;&gt; No virus found in this incoming message.
&gt;&gt; Checked by AVG - www.avg.com 
&gt;&gt; Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00
&gt;&gt;
&gt;&gt;   
&gt; ------------------------------------------------------------------------
&gt;
&gt;
&gt; No virus found in this incoming message.
&gt; Checked by AVG - www.avg.com 
&gt; Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi Folks,&lt;br&gt;
&lt;br&gt;
Andrew: Thank you so much for your article. Its much more succinct than
the one I had.&lt;br&gt;
&lt;br&gt;
Is there a way around the problem below ?&lt;br&gt;
"""&lt;br&gt;
                \
LIBDEPS=" $LIBRARIES -lwsock32 -lgdi32" \&lt;br&gt; \
                \
link_app.${shlib_target}&lt;br&gt; make[2]: Entering directory \
`/d/workspace++/openssl-0.9.8l/apps'&lt;br&gt; ( :; LIBDEPS="${LIBDEPS:--L.. -lssl  \
-L.. -lcrypto -lwsock32 -lgdi32}"; LDCMD="$&lt;br&gt;
{LDCMD:-gcc}"; LDFLAGS="${LDFLAGS:--DOPENSSL_THREADS  -DDSO_WIN32
-mno-cygwin -D&lt;br&gt;
L_ENDIAN -fomit-frame-pointer -O3 -march=i486 -Wall
-D_WIN32_WINNT=0x333 -DOPENS&lt;br&gt;
SL_BN_ASM_PART_WORDS -DOPENSSL_IA32_SSE2 -DSHA1_ASM -DMD5_ASM
-DRMD160_ASM -DAES&lt;br&gt;
_ASM}"; LIBPATH=`for x in $LIBDEPS; do if echo $x | grep '^ *-L' &gt;
/dev/null 2&gt;&amp;&lt;br&gt;
1; then echo $x | sed -e 's/^ *-L//'; fi; done | uniq`; LIBPATH=`echo
$LIBPATH |&lt;br&gt;
 sed -e 's/ /:/g'`; LD_LIBRARY_PATH=$LIBPATH:$LD_LIBRARY_PATH ${LDCMD}
${LDFLAGS&lt;br&gt;
} -o ${APPNAME:=openssl.exe} openssl.o verify.o asn1pars.o req.o dgst.o
dh.o dhp&lt;br&gt;
aram.o enc.o passwd.o gendh.o errstr.o ca.o pkcs7.o crl2p7.o crl.o
rsa.o rsautl.&lt;br&gt;
o dsa.o dsaparam.o ec.o ecparam.o x509.o genrsa.o gendsa.o s_server.o
s_client.o&lt;br&gt;
 speed.o s_time.o apps.o s_cb.o s_socket.o app_rand.o version.o
sess_id.o cipher&lt;br&gt;
s.o nseq.o pkcs12.o pkcs8.o spkac.o smime.o rand.o engine.o ocsp.o
prime.o cms.o&lt;br&gt;
 ${LIBDEPS} )&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0xe): undefined reference to
`ENGINE_&lt;br&gt;
load_4758cca'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x13): undefined reference
to `ENGINE&lt;br&gt;
_load_aep'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x18): undefined reference
to `ENGINE&lt;br&gt;
_load_atalla'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x1d): undefined reference
to `ENGINE&lt;br&gt;
_load_cswift'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x22): undefined reference
to `ENGINE&lt;br&gt;
_load_chil'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x27): undefined reference
to `ENGINE&lt;br&gt;
_load_nuron'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x2c): undefined reference
to `ENGINE&lt;br&gt;
_load_sureware'&lt;br&gt;
../libcrypto.a(eng_all.o):eng_all.c:(.text+0x34): undefined reference
to `ENGINE&lt;br&gt;
_load_ubsec'&lt;br&gt;
make[2]: *** [link_app.] Error 1&lt;br&gt;
make[2]: Leaving directory `/d/workspace++/openssl-0.9.8l/apps'&lt;br&gt;
make[1]: *** [openssl.exe] Error 2&lt;br&gt;
make[1]: Leaving directory `/d/workspace++/openssl-0.9.8l/apps'&lt;br&gt;
make: *** [build_apps] Error 1&lt;br&gt;
"""&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Cav wrote:
&lt;blockquote cite="mid:4C2F2A10.3040001@gotadsl.co.uk" type="cite"&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
Thank you Andrew,&lt;br&gt;
  &lt;br&gt;
My MinGW environment is broken at the moment, so thats the reason this
end.&lt;br&gt;
I will pay attention to how you build.&lt;br&gt;
  &lt;br&gt;
Thanks again !!!&lt;br&gt;
  &lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
  &lt;br&gt;
Cav Edwards&lt;br&gt;
  &lt;br&gt;
  &lt;/div&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a moz-do-not-send="true" class="moz-txt-link-abbreviated"
 href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt; wrote:
  &lt;blockquote cite="mid:20100703112527.GA752@interloper.org" type="cite"&gt;
    &lt;pre wrap=""&gt;On Sat, Jul 03, 2010 at 12:08:53PM +0100, &lt;a
 moz-do-not-send="true" class="moz-txt-link-abbreviated"
 href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt; wrote 0.2K bytes in 10 lines \
about:  &lt;/pre&gt;
    &lt;blockquote type="cite"&gt;
      &lt;pre wrap=""&gt;The build on Windows reports a make file that has incorrect \
options. Is anyone aware of this ?

"""make: *** No targets specified and no makefile found.  Stop."""
    &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;pre wrap=""&gt;&lt;!----&gt;
How are you trying to build it?  Obviously I was able to build a binary
and package so I know it works.

Here's how I build:
&lt;a moz-do-not-send="true" class="moz-txt-link-freetext"
 href="https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt"&gt;https://svn.torproject.org/svn/tor/trunk/doc/tor-win32-mingw-creation.txt&lt;/a&gt;


  &lt;/pre&gt;
    &lt;pre wrap=""&gt;&lt;hr size="4" width="90%"&gt;

No virus found in this incoming message.
Checked by AVG - &lt;a moz-do-not-send="true"
 class="moz-txt-link-abbreviated" href="http://www.avg.com"&gt;www.avg.com&lt;/a&gt; 
Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00

  &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;
&lt;hr size="4" width="90%"&gt;

No virus found in this incoming message.
Checked by AVG - &lt;a class="moz-txt-link-abbreviated" \
                href="http://www.avg.com"&gt;www.avg.com&lt;/a&gt; 
Version: 9.0.830 / Virus Database: 271.1.1/2977 - Release Date: 07/02/10 07:35:00

  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100704223816</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-07-04 22:38:16-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

On Sat, Jul 3, 2010 at 1:42 PM, Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt;...
&gt; Is there a way around the problem below ?

try adding 'no-hw' to your OpenSSL Configure options when building openssl libs.
</body></email><email><emailId>20101202133852</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-12-02 13:38:52-0400</timestampReceived><subject>Re: Missing certificates</subject><body>

On 12/2/10 2:18 PM, Ian Goldberg wrote:
&gt; Every time I launch 0.2.3, I see these messages:
&gt; 
&gt; Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
&gt; with signing key F7C7B9191C74C0BA07363C84D37BBAD3A8A6C6D8: launching
&gt; request.
&gt; Dec 02 08:13:06.000 [notice] We're missing a certificate from authority
&gt; with signing key 604834622B54F2D9BA39B34AC53924546733AA60: launching
&gt; request.
&gt; 
&gt; Whose certificates are these, and why are we continually missing them?

That are the legacy certificates of moria1 and gabelmoo. In theory, they
shouldn't expire before 2011-04-16 and 2012-05-03, respectively. Hmm.

Karsten
</body></email><email><emailId>20101202225246</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-12-02 22:52:46-0400</timestampReceived><subject>Re: Single-hop (or unknown relay) attempts in 0.2.3</subject><body>

On Thu, Dec 2, 2010 at 5:11 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; ...
&gt; every 3-6 hours, I see a group of entries like this in my log:
&gt;
&gt; Dec 02 05:08:17.000 [notice] Attempt by [scrubbed] to open a stream from
&gt; unknown relay. Closing.
&gt; ...
&gt; Any idea what this might be?

i can only speculate; however, back when looking into
https://trac.torproject.org/projects/tor/ticket/1160 someone was using
single hops for malicious exit node checking, other periodic requests.

$0.02
</body></email><email><emailId>20101204063922</emailId><senderName>Csaba Kiraly</senderName><senderEmail>kiraly@disi.unitn.it</senderEmail><timestampReceived>2010-12-04 06:39:22-0400</timestampReceived><subject>Re: IP datagram size for TLS connection to relay</subject><body>

TCP (and thus TLS) in general is a stream protocol. The fact that Tor or someone else \
writes to it in units of 512 does not guarantee anything about how the stream is \
segmented into IP packets. It usually gets fragmented the same (or multiples of it), \
since data is flushed fast, but you can easily get other sizes when your send rate is \
higher or some if TCP's widows gets clogged.

Csaba

On 12/03/2010 11:37 PM, Xinwen Fu wrote:
&gt; This phenomenon was explored: http://www.cs.uml.edu/~xinwenfu/paper/CCS09_Fu.pdf \
&gt; &lt;http://www.cs.uml.edu/%7Exinwenfu/paper/CCS09_Fu.pdf&gt;. 
&gt; Equal-sized cells at the application layer does not mean equal-sized packets at the \
&gt; IP layer. 
&gt; Xinwen Fu
&gt; 
&gt; On Fri, Dec 3, 2010 at 12:18 PM, Nick Mathewson &lt;nickm@freehaven.net \
&gt; &lt;mailto:nickm@freehaven.net&gt;&gt; wrote: 
&gt; On Fri, Dec 3, 2010 at 6:25 AM, Weidong Shao &lt;weidongshao@gmail.com \
&gt; &lt;mailto:weidongshao@gmail.com&gt;&gt; wrote:
&gt; &gt; Hi
&gt; &gt; I did a packet capture and found that the IP datagram size for TLS between
&gt; &gt; my browser and the first relay has different sizes, some of which are 638,
&gt; &gt; which corresponds to  the fixed TOR cell size of 512. But I also see sizes
&gt; &gt; of 1500, and other values.
&gt; &gt; Does it mean that there are IP packets other than the 512-byte tor cell in
&gt; &gt; the same TLS connection?
&gt; 
&gt; It's just as likely that the packets aren't always getting sent in
&gt; multiples of one cell.  The current code puts cells in a buffer as
&gt; it's about to send them, and lets the buffers and ratelimiting
&gt; backends decide how much to send at a time.
&gt; 
&gt; 


[Attachment #3 (text/html)]

&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta content="text/html; charset=ISO-8859-1"
      http-equiv="Content-Type"&gt;
  &lt;/head&gt;
  &lt;body bgcolor="#ffffff" text="#000000"&gt;
    TCP (and thus TLS) in general is a stream protocol. The fact that
    Tor or someone else writes to it in units of 512 does not guarantee
    anything about how the stream is segmented into IP packets. It
    usually gets fragmented the same (or multiples of it), since data is
    flushed fast, but you can easily get other sizes when your send rate
    is higher or some if TCP's widows gets clogged.&lt;br&gt;
    &lt;br&gt;
    Csaba&lt;br&gt;
    &lt;br&gt;
    On 12/03/2010 11:37 PM, Xinwen Fu wrote:
    &lt;blockquote
      cite="mid:AANLkTi=ye562vrkJMbpwWPoECGBvwqA8_NPsy02Gv4y8@mail.gmail.com"
      type="cite"&gt;This phenomenon was explored: &lt;a
        moz-do-not-send="true"
        href="http://www.cs.uml.edu/%7Exinwenfu/paper/CCS09_Fu.pdf"&gt;http://www.cs.uml.edu/~xinwenfu/paper/CCS09_Fu.pdf&lt;/a&gt;.&lt;br&gt;
  &lt;br&gt;
      Equal-sized cells at the application layer does not mean
      equal-sized packets at the IP layer. &lt;br&gt;
      &lt;br&gt;
      Xinwen Fu&lt;br&gt;
      &lt;br&gt;
      &lt;div class="gmail_quote"&gt;On Fri, Dec 3, 2010 at 12:18 PM, Nick
        Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a moz-do-not-send="true"
            href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt;
        wrote:&lt;br&gt;
        &lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt
          0.8ex; border-left: 1px solid rgb(204, 204, 204);
          padding-left: 1ex;"&gt;
          &lt;div&gt;
            &lt;div class="h5"&gt;On Fri, Dec 3, 2010 at 6:25 AM, Weidong Shao
              &lt;&lt;a moz-do-not-send="true"
                href="mailto:weidongshao@gmail.com"&gt;weidongshao@gmail.com&lt;/a&gt;&gt;
              wrote:&lt;br&gt;
              &gt; Hi&lt;br&gt;
              &gt; I did a packet capture and found that the IP datagram
              size for TLS between&lt;br&gt;
              &gt; my browser and the first relay has different sizes,
              some of which are 638,&lt;br&gt;
              &gt; which corresponds to  the fixed TOR cell size of 512.
              But I also see sizes&lt;br&gt;
              &gt; of 1500, and other values.&lt;br&gt;
              &gt; Does it mean that there are IP packets other than the
              512-byte tor cell in&lt;br&gt;
              &gt; the same TLS connection?&lt;br&gt;
              &lt;br&gt;
            &lt;/div&gt;
          &lt;/div&gt;
          It's just as likely that the packets aren't always getting
          sent in&lt;br&gt;
          multiples of one cell.  The current code puts cells in a
          buffer as&lt;br&gt;
          it's about to send them, and lets the buffers and ratelimiting&lt;br&gt;
          backends decide how much to send at a time.&lt;br&gt;
        &lt;/blockquote&gt;
      &lt;/div&gt;
      &lt;br&gt;
    &lt;/blockquote&gt;
    &lt;br&gt;
  &lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20101215065041</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2010-12-15 06:50:41-0400</timestampReceived><subject>Re: Proposal 171 (revised): Separate streams across circuits by connection metadata</subject><body>

On Dec 14, 2010, at 8:59 PM, Nick Mathewson wrote:

&gt; I thought these interfaces were only for passing credentials over unix
&gt; sockets. What's the API to get a copy of one of these structures given
&gt; only a socket without the other guy passing you a credential?

Oh, yeah; nevermind. If your peer doesn't pass it to you, I don't think there's a way to get it.
</body></email><email><emailId>20101218062349</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-12-18 06:23:49-0400</timestampReceived><subject>Re: Draft document and notes from rransom: requirements for circuit crypto</subject><body>

On Tue, Dec 14, 2010 at 11:35 PM, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:

I'm going to try to kick off discussion here in hopes of moving the
design effort forward.  I don't have the crypto chops of Robert, so
I'm hoping that people with more experience in formal cryptography can
have a look here too.

&gt; ===
&gt; Title: Requirements for Tor's circuit cryptography

This document might morph into a larger "requirements for Tor's
cryptography" document, or one of a set of such documents.  Unless I'm
forgetting something, the other areas of cryptography Tor has are:

  * link cryptography
  * directory authentication
  * hidden-service protocol
  * hidden-service directory protocol

&gt; Author: Robert Ransom
&gt; Created: 12 December 2010
&gt;
&gt; Overview
&gt;
&gt;  This draft is intended to specify the meaning of 'secure' for a Tor
&gt;  circuit protocol, hopefully in enough detail that
&gt;  mathematically-inclined cryptographers can use this definition to
&gt;  prove that a Tor circuit protocol (or component thereof) is secure
&gt;  under reasonably well-accepted assumptions.
&gt;
&gt;  Tor's current circuit protocol consists of the CREATE, CREATED, RELAY,
&gt;  DESTROY, CREATE_FAST, CREATED_FAST, and RELAY_EARLY cells (including
&gt;  all subtypes of RELAY and RELAY_EARLY cells).

So as written, this would make the circuit protocol consist of all
hidden service cells too, since they are also RELAY_* cells.  Can we
exclude them from consideration here?  The rendezvous protocol is
pretty complicated, and almost wholly orthogonal from the rest of the
circuit protocol.

(At first I wanted to say that the circuit protocol should consist
only of the crypto done to transmit relay cells, and not their
contents, but saying that would exclude the contents of  RELAY EXTEND
cells, which would be silly.)

&gt;    Tor currently has two
&gt;  circuit-extension handshake protocols: one consists of the CREATE and
&gt;  CREATED cells; the other, used only over the TLS connection to the
&gt;  first node in a circuit, consists of the CREATE_FAST and CREATED_FAST
&gt;  cells.
&gt;
&gt; Requirements


&gt;  1. Every circuit-extension handshake protocol must provide forward
&gt;  secrecy -- the protocol must allow both the client and the relay to
&gt;  destroy, immediately after a circuit is closed, enough key material
&gt;  that no attacker who can eavesdrop on all handshake and circuit cells
&gt;  and who can seize and inspect the client and relay after the circuit
&gt;  is closed will be able to decrypt any non-handshake data sent along
&gt;  the circuit.
&gt;
&gt;  In particular, the protocol must not require that a key which can be
&gt;  used to decrypt non-handshake data be stored for a predetermined
&gt;  period of time, as such a key must be written to persistent storage.

It would also be nice if we could do better here: if for example we
could re-key an existing circuit and drop the old keys so that the
nodes long-lived circuit didn't need to keep the key material needed
to decrypt all the stuff they had already received.

&gt;  2. Every circuit-extension handshake protocol must specify what key
&gt;  material must be used only once in order to allow unlinkability of
&gt;  circuit-extension handshakes.
&gt;
&gt;  3. Every circuit-extension handshake protocol must authenticate the relay
&gt;  to the client -- an attacker who can eavesdrop on all handshake and
&gt;  circuit cells and who can participate in handshakes with the client
&gt;  must not be able to determine a symmetric session key that a circuit
&gt;  will use without either knowing a secret key corresponding to a
&gt;  handshake-authentication public key published by the relay or breaking
&gt;  a cryptosystem for which the relay published a
&gt;  handshake-authentication public key.
&gt;
&gt;  4. Every circuit-extension handshake protocol must ensure that neither
&gt;  the client nor the relay can cause the handshake to result in a
&gt;  predetermined symmetric session key.

I think you want something a little stronger here; by the literal
reading of 4, it's okay if the relay can force _one of two_ keys, but
of course that's not okay.

Also, what is the problem if the *client* can force a particular
session key?  If the client is hostile to her own anonymity, then the
system is not expected to work.

&gt;  5. Every circuit-extension handshake protocol should ensure that an
&gt;  attacker who can predict the relay's ephemeral secret input to the
&gt;  handshake and can eavesdrop on all handshake and circuit cells, but
&gt;  does not know a secret key corresponding to the
&gt;  handshake-authentication public key used in the handshake, cannot
&gt;  break the handshake-authentication public key's cryptosystem, and
&gt;  cannot predict the client's ephemeral secret input to the handshake,
&gt;  cannot predict the symmetric session keys used for the resulting
&gt;  circuit.
&gt;
&gt;  6. The circuit protocol must specify an end-to-end flow-control
&gt;  mechanism, and must allow for the addition of new mechanisms.
&gt;
&gt;  7. The circuit protocol should specify the statistics to be exchanged
&gt;  between circuit endpoints in order to support end-to-end flow control,
&gt;  and should specify how such statistics can be verified.
&gt;
&gt;
&gt;  8. The circuit protocol should allow an endpoint to verify that the other
&gt;  endpoint is participating in an end-to-end flow-control protocol
&gt;  honestly.

I note that this doesn't actually say much about the content of RELAY
cells themselves.  IMO, that's a little cart-before-the-horseish,
since the whole point of establishing circuits is to use them to send
RELAY cells back and forth.   I don't have a complete list, but here's
a sketch:

 * The point of the circuit crypto protocol is to transmit data
between the client and the nodes in the circuit so they can handle it
appropriately.  This data is sent in RELAY cells.  Each RELAY cell
originated by the client goes to exactly one node on the circuit; each
RELAY cell originated by a node on the circuit goes to the client.

 * Relay cells should get encrypted with one layer of cryptography per
node in the circuit.  We want a property here something like, "A cell
sent by the client cannot be read by anybody but the relay it is
intended for; a cell sent by the relay cannot be read by anybody but
the client."

There's probably more to say here, though we could probably also just
incorporate the appropriate part of the design paper by reference and
say "it works like that".  We might also want to mention some
properties that you get for free from the rest of the Tor design,
including:

 * Link crypto exists.
 * Clients know circuit-establishment public keys (a.k.a onion keys)
for all relays they want to use.

Also, here are a few more nice-to-have properties that might be worth
considering if they can be done without too much trouble.    I realize
that all of these probably fall under the heading of "Second System"
desiderata, but I feel unable to keep myself from writing them down
*somewhere*.

  * It would be nice to make it a little harder for end-to-end bitwise
tagging attacks to work.  This isn't a huge priority, though, since
these are already outside our threat model (as noted in the Tor design
paper), and there are plenty of other and less detectable ways to do
active and passive end-to-end correlation.

  * Some work in resisting traffic analysis relies on an ability for
_all_ nodes in the circuit to introduce long-range padding in both
directions.  In our current protocol, only the client can add outbound
padding, while each node can only add inbound padding.  I'm not
putting a high priority on this one personally, since it's only a
building block for future work and not actually applicable to anything
solid today.

  * There shouldn't be any high-multiplier DoS attacks against the
protocol.  In particular, maybe an attacker shouldn't be able to force
a node to do an expensive secret-key operation just by sending some
undecodable junk data.  Proof-of-work might be one way to do this.

  * The protocol should not be very hard to implement; hard things are
error-prone.  In particular, it shouldn't require any particular
cryptographic algorithm not commonly available in Free/Open Source
crypto libraries.



&gt; ===========
&gt; NOTES:
&gt;
&gt;
&gt;
&gt;
&gt; All circuit handshake protocols must provide forward security.  This
&gt; requires that the client send a public key for some asymmetric
&gt; protocol that can provide secrecy (RSA, ElGamal, DH, McEliece,
&gt; Ajtai-Dwork, Lyubashevsky-Palacio-Segev, etc.) to each node in each
&gt; circuit.
&gt;
&gt; The public keys and public parameters used in different handshakes
&gt; must be unlinkable.  This will restrict different cryptosystems in
&gt; different ways:
&gt;
&gt; * An RSA or LPS key must be used only once, and then the entire secret
&gt;  key must be destroyed.
&gt;
&gt; * An ElGamal or DH key must be used only once, and then the secret
&gt;  exponent must be destroyed.  In addition, if the client generated
&gt;  the public parameters used by the key, the public parameters must
&gt;  also be destroyed.  (Public parameters published by a third party
&gt;  may be used multiple times.)

To be clear, the above applies only to keys used for forward-secrecy,
right?  IOW, our current CREATE/CREATED format uses a long-term RSA
public key for authentication and encryption of the DH handshake, and
a short-term DH handshake to generate the actual key material used for
encrypting cells.

&gt; special wants to make it impossible for a node in the hidserv
&gt; directory DHT to determine the address a hidserv descriptor describes
&gt; unless it already knows the address.  The problem here is that the
&gt; following are absolutely required:
&gt;
&gt; * Each client must be able to compute, from the hidserv's address and
&gt;  a public nonce, the DHT retrieval key needed to retrieve the
&gt;  hidserv's descriptor and any decryption key needed to use the
&gt;  descriptor.
&gt;
&gt; * Each hidserv must give each DHT node responsible for its retrieval
&gt;  key the DHT retrieval key and a descriptor, and must prove to the
&gt;  DHT node that it knows a secret key which ‘owns’ a hidserv address
&gt;  which currently ‘owns’ the retrieval key.
&gt;
&gt; The proof of knowledge of a hidserv secret key is needed not to keep
&gt; jerks from crapflooding a DHT node (they can still do that by
&gt; generating lots of hidserv secret keys), but to prevent a censor from
&gt; overwriting someone else's hidserv descriptor and thereby blocking
&gt; access to the hidserv.

I want to call all of this hidden service stuff orthogonal for now,
but we should come up for it when we're writing requirements and
nice-to-haves for

&gt; Other questions:
&gt;
&gt; * What types of attackers should Tor's crypto protect against?
&gt;
&gt; * What types of attacks should Tor's crypto protect against?

My rule of thumb is: attacking the crypto should never be the easiest
way to attack Tor users for any attacker.  So for attackers and
attacks that Tor currently defeats, has a reasonable prospect of
evolving to defeat, or aspires to defeat (see the paper and other work
on the threat model), the cryptography should be hard enough to attack
that they cannot link or trace users.  Even for attackers we currently
*don't* know how to defeat with today's low-latency anonymity net
designs (e.g., those who can do end-to-end correlation attacks against
users), the cryptography should be strong enough that attacking it is
far more expensive than all their current plausible attacks.

(My rationale here is that today's cryptography research can give far
more impressive results than today's anonymity research, so we might
as well get them.)

&gt; * How do we transition relay identity key cryptosystems, now and in
&gt;  the future?
&gt;
&gt; * How do we transition directory identity key cryptosystems, now and
&gt;  in the future?

My other proposal draft starts to answer these, I hope.  Comments
welcome and invited!

peace,
-- 
Nick

</body></email><email><emailId>20101224194919</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-12-24 19:49:19-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

&gt; Stable download URLs would indeed be useful.

I'll put this and all new releases in a static subdirectory, so here's
the current one:
http://www.atagar.com/arm/resources/static/arm-1.4.0-2.tar.bz2

My plan was to do the next release in a month or so (finishing the
proc enhancement and including a few other bits from the todo) but if
you'd like a release sooner to have a release version with your bsd
compatibility fixes then let me know. Of course, if using one of the
bsdTest tarballs is sufficient then I can just copy one into the
static directory to make sure it doesn't get deleted.

&gt; I would expect messing with LANG or other localization-related
&gt; variables in the arm shell script or in arm itself to be without
&gt; consequences for the user's terminal once arm is stopped.

Patches welcome on this one. I'm not sure of the exact fix you have in
mind nor do I have a repro use case, so if you're sure this can be
done safely then I'd be happy to include it.

&gt; Nope, but I'm also under the impression that they don't
&gt; really matter and that the load is mainly caused by the
&gt; algorithms used in arm itself.

Kinda yes, kinda no. More no I think. I've changed the arm cpu usage
to instead be samplings of '(os.times() results + system call
runtimes) / sampling time'. I'm not sure if this is a more or less
arbitrary measure of the actual cpu time, but this at least takes the
system calls into account which I'm finding to be useful.

The bad news is that the system calls component was just as large as
the arm cpu usage (about 1.2% on arm, 1.0% on netstat/ps calls). This
isn't surprising and matches reports from some users that on devices
with low resources (mobile, old computers, etc) that arm has trouble
running with the connection resolution.

The good news is that the proc enhancements mentioned earlier
practically eliminates the need for system calls (yay!). I'm
suspecting that there will be some low hanging fruit for the baseline
python cpu usage too when refactoring the controller too.

&gt; So far it happened maybe four or five times on both FreeBSD and
&gt; Debian GNU/Linux combined, always when not interacting with arm.
&gt; I haven't found a way to reproduce it, yet.

When you have log file results for a few freezes I'd love to know what
they end with (any commonalities, for instance if there's a specific
system call giving it trouble).

Family is arriving now, so off to visit. Happy holidays! -Damian
</body></email><email><emailId>20101231211722</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-12-31 21:17:22-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>


On Sun, 19 Dec 2010 08:46:13 -0500
Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:

&gt; On Sat, Dec 18, 2010 at 10:34 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; &gt; You're right that it's important to limit partitioning opportunities
&gt; &gt; in any protocol revision; I tried to go over that in section 2, but we
&gt; &gt; shouldn't assume that I've said the last word on this.   We should
&gt; &gt; continue to look for ways to revise and improve whatever we come up
&gt; &gt; with to get the partitioning and other undesirable things down to a
&gt; &gt; minimum.

My current plan to minimize partitioning of the client anonymity set is:

* The directory authorities should specify lists of cryptographic
  primitives (identity key signature systems, circuit-extension
  handshakes, circuit ciphersuites, etc.) that relays are permitted to
  support in the consensus.

* The directory authorities should specify lists of cryptographic
  primitives that clients should consider using in the consensus.

* Each relay should specify lists of cryptographic primitives that it
  is willing to use in its descriptor, ordered by the relay's
  preference (e.g. the relay puts its favorite primitive in a list
  first).

* A client should select the first cryptographic primitive in a relay's
  list that (a) the consensus recommends that clients use, and (b) the
  client supports.

* The Tor developers should not introduce new cryptographic primitives
  between two stable releases in the same branch.

The Tor client will need to support torrc options that override the
lists of recommended cryptographic primitives in the consensus in order
to allow testing of not-yet-recommended primitives on the public Tor
network, but the manual page will need to warn explicitly that setting
those options will harm a Tor user's anonymity.

This plan relies on the directory authorities not recommending a new
cryptographic primitive until a large fraction of Tor clients support
it.


&gt; One way is to be very conservative in suite choices so we don't have
&gt; to change them that often. I'm going to also go out on a limb and say
&gt; that we also want a crypto API like NaCL that lets us just say
&gt; enciphered=encrypt(key, unenciphered) and doesn't force us to worry
&gt; about padding or modes because this is a much simpler abstraction
&gt; layer and so offers less opportunity for mistakes that could threaten
&gt; security.

I think that if we follow the plan above, we don't need to limit the
number of cryptographic primitives of each type in order to preserve
the client anonymity set.  It's more important to have at least two
cryptographic primitives of each type implemented, even if we expect
that few relays will prefer one of them, in order to ensure that we get
the APIs for each primitive right.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101202131128</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-12-02 13:11:28-0400</timestampReceived><subject>Single-hop (or unknown relay) attempts in 0.2.3</subject><body>

While tracking down #2205, I bumped up the severity level of

log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,
             "Attempt by %s to open a stream %s. Closing.",
             safe_str(or_circ-&gt;p_conn-&gt;_base.address),
             or_circ-&gt;is_first_hop ? "on first hop of circuit" :
                                     "from unknown relay");

in connection_edge.c to LOG_NOTICE.  I've applied the patch
https://trac.torproject.org/projects/tor/attachment/ticket/2205/idea_raw_for_2205.diff
but every 3-6 hours, I see a group of entries like this in my log:

Dec 02 05:08:17.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:18.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:18.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:18.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:19.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:19.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:20.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:21.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:21.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:22.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.
Dec 02 05:08:22.000 [notice] Attempt by [scrubbed] to open a stream from
unknown relay. Closing.

Any idea what this might be?

   - Ian
</body></email><email><emailId>20101203112555</emailId><senderName>Weidong Shao</senderName><senderEmail>weidongshao@gmail.com</senderEmail><timestampReceived>2010-12-03 11:25:55-0400</timestampReceived><subject>IP datagram size for TLS connection to relay</subject><body>

Hi

I did a packet capture and found that the IP datagram size for TLS between
my browser and the first relay has different sizes, some of which are 638,
which corresponds to  the fixed TOR cell size of 512. But I also see sizes
of 1500, and other values.

Does it mean that there are IP packets other than the 512-byte tor cell in
the same TLS connection?

Thanks
Weidong

[Attachment #3 (text/html)]

Hi&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I did a packet capture and found that the IP datagram=
 size for TLS between my browser and the first relay has different sizes, s=
ome of which are 638, which corresponds to=A0=A0the fixed TOR cell size of =
512. But I also see sizes of 1500, and other values.=A0&lt;/div&gt;
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Does it mean that there are IP packets other than the 5=
12-byte tor cell in the same TLS connection?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thank=
s&lt;/div&gt;&lt;div&gt;Weidong&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;


</body></email><email><emailId>20101203171818</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-12-03 17:18:18-0400</timestampReceived><subject>Re: IP datagram size for TLS connection to relay</subject><body>

On Fri, Dec 3, 2010 at 6:25 AM, Weidong Shao &lt;weidongshao@gmail.com&gt; wrote:
&gt; Hi
&gt; I did a packet capture and found that the IP datagram size for TLS between
&gt; my browser and the first relay has different sizes, some of which are 638,
&gt; which corresponds to  the fixed TOR cell size of 512. But I also see sizes
&gt; of 1500, and other values.
&gt; Does it mean that there are IP packets other than the 512-byte tor cell in
&gt; the same TLS connection?

It's just as likely that the packets aren't always getting sent in
multiples of one cell.  The current code puts cells in a buffer as
it's about to send them, and lets the buffers and ratelimiting
backends decide how much to send at a time.

</body></email><email><emailId>20101203223706</emailId><senderName>Xinwen Fu</senderName><senderEmail>xinwenfu@gmail.com</senderEmail><timestampReceived>2010-12-03 22:37:06-0400</timestampReceived><subject>Re: IP datagram size for TLS connection to relay</subject><body>

This phenomenon was explored:
http://www.cs.uml.edu/~xinwenfu/paper/CCS09_Fu.pdf.

Equal-sized cells at the application layer does not mean equal-sized packets
at the IP layer.

Xinwen Fu

On Fri, Dec 3, 2010 at 12:18 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Fri, Dec 3, 2010 at 6:25 AM, Weidong Shao &lt;weidongshao@gmail.com&gt;
&gt; wrote:
&gt; &gt; Hi
&gt; &gt; I did a packet capture and found that the IP datagram size for TLS
&gt; between
&gt; &gt; my browser and the first relay has different sizes, some of which are
&gt; 638,
&gt; &gt; which corresponds to  the fixed TOR cell size of 512. But I also see
&gt; sizes
&gt; &gt; of 1500, and other values.
&gt; &gt; Does it mean that there are IP packets other than the 512-byte tor cell
&gt; in
&gt; &gt; the same TLS connection?
&gt;
&gt; It's just as likely that the packets aren't always getting sent in
&gt; multiples of one cell.  The current code puts cells in a buffer as
&gt; it's about to send them, and lets the buffers and ratelimiting
&gt; backends decide how much to send at a time.
&gt;

[Attachment #3 (text/html)]

This phenomenon was explored: &lt;a \
href="http://www.cs.uml.edu/~xinwenfu/paper/CCS09_Fu.pdf"&gt;http://www.cs.uml.edu/~xinwenfu/paper/CCS09_Fu.pdf&lt;/a&gt;.&lt;br&gt;&lt;br&gt;Equal-sized \
cells at the application layer does not mean equal-sized packets at the IP layer. \
&lt;br&gt; &lt;br&gt;Xinwen Fu&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Fri, Dec 3, 2010 at 12:18 PM, \
Nick Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@freehaven.net"&gt;nickm@freehaven.net&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;On Fri, Dec 3, 2010 at 6:25 AM, Weidong Shao &lt;&lt;a \
href="mailto:weidongshao@gmail.com"&gt;weidongshao@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; \
Hi&lt;br&gt; &gt; I did a packet capture and found that the IP datagram size for TLS \
between&lt;br&gt; &gt; my browser and the first relay has different sizes, some of which \
are 638,&lt;br&gt; &gt; which corresponds to  the fixed TOR cell size of 512. But I also \
see sizes&lt;br&gt; &gt; of 1500, and other values.&lt;br&gt;
&gt; Does it mean that there are IP packets other than the 512-byte tor cell in&lt;br&gt;
&gt; the same TLS connection?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;It's just as likely that the packets aren't always getting sent \
in&lt;br&gt; multiples of one cell.  The current code puts cells in a buffer as&lt;br&gt;
it's about to send them, and lets the buffers and ratelimiting&lt;br&gt;
backends decide how much to send at a time.&lt;br&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20101207160205</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-12-07 16:02:05-0400</timestampReceived><subject>Proposal 171 (revised): Separate streams across circuits by</subject><body>

Hi, all.  I'm trying to get the proposal-171 discussion settled down a
bit more, so I revised the proposal to try to say more like what I
think it should say.  Here goes:


Filename: 171-separate-streams.txt
Title: Separate streams across circuits by connection metadata
Author: Robert Hogan, Jacob Appelbaum, Damon McCoy, Nick Mathewson
Created: 21-Oct-2008
Modified: 7-Dec-2010
Status: Open

Summary:

  We propose a new set of options to isolate unrelated streams from one
  another, putting them on separate circuits so that semantically
  unrelated traffic is not inadvertently made linkable.

Motivation:

  Currently, Tor attaches regular streams (that is, ones not carrying
  rendezvous or directory traffic) to circuits based only on whether Tor
  circuit's current exit node supports the destination, and whether the
  circuit has been dirty (that is, in use) for too long.

  This means that traffic that would otherwise be unrelated sometimes
  gets sent over the same circuit, allowing the exit node to link such
  streams with certainty, and allowing other parties to link such
  streams probabilistically.

  Older versions of onion routing tried to address this problem by
  sending every stream over a separate circuit; performance issues made
  this unfeasible. Moreover, in the presence of a localized adversary,
  separating streams by circuits increases the odds that, for any given
  linked set of streams, at least one will go over a compromised
  circuit.

  Therefore we ought to look for ways to allow streams that ought to be
  linked to travel over a single circuit, while keeping streams that
  ought not be linked isolated to separate circuits.

Discussion:

  Let's call a series of inherently-linked streams (like a set of
  streams downloading objects from the same webpage, or a browsing
  session where the user requests several related webpages) a "Session".

  "Sessions" are a necessarily a fuzzy concept.  While users typically
  consider some activities as wholly unrelated to each other ("My IM
  session has nothing to do with my web browsing!"), the boundaries
  between activities are sometimes hard to determine.  If I'm reading
  lolcats in one browser tab and reading about treatments for an
  embarrassing disease in another, those are probably separate sessions.
  If I search for a forum, log in, read it for a while, and post a few
  messages on unrelated topics, that's probably all the same session.

  So with the proviso that no automated process can identify sessions
  100% accurately, let's see which options we have available.

  Generally, all the streams on a session come from a single
  application.  Unfortunately, isolating streams by application
  automatically isn't feasible, given the lack of any nice
  cross-platform way to tell which local process originated a given
  connection.  (Yes, lsof works.  But a quick review of the lsof code
  should be sufficient to scare you away from thinking there is a
  portable option, much less a portable O(1) option.)  So instead, we'll
  have to use some other aspect of a Tor request as a proxy for the
  application.

  Generally, traffic from separate applications is not in the same
  session.

  With some applications (IRC, for example), each stream is a session.

  Some applications (most notably web browsing) can't be meaningfully
  split into sessions without inspecting the traffic itself and
  maintaining a lot of state.

  How well do ports correspond to sessions?  Early versions of this
  proposal focused on using destination ports as a proxy for
  application, since a connection to port 22 for SSH is probably not in
  the same session as one to port 80. This only works with some
  applications better than others, though: while SSH users typically
  know when they're on port 22 and when they aren't, a web browser can
  be coaxed (though img urls or any number of releated tricks) into
  connecting to any port at all.  Moreover, when Tor gets a DNS lookup
  request, it doesn't know in advance which port the resulting address
  will be used to connect to.

  So in summary, each kind of traffic wants to follow different rules,
  and assuming the existence of a web browser and a hostile web page or
  exit node, we can't tell one kind of traffic from another by simply
  looking at the destination:port of the traffic.

  Fortunately, we're not doomed.

Design:

  When a stream arrives at Tor, we have the following data to examine:
    1) The destination address
    2) The destination port (unless this a DNS lookup)
    3) The protocol used by the application to send the stream to Tor:
       SOCKS4, SOCKS4A, SOCKS5, or whatever local "transparent proxy"
       mechanism the kernel gives us.
    4) The port used by the application to send the stream to Tor --
       that is, the SOCKSListenAddress or TransListenAddress that the
       application used, if we have more than one.
    5) The SOCKS username and password, if any.
    6) The source address and port for the application.

  We propose to use 3, 4, and 5 as a backchannel for applications to
  tell Tor about different sessions.  Rather than running only one
  SOCKSPort, a Tor user who would prefer better session isolation should
  run multiple SOCKSPorts/TransPorts, and configure different
  applications to use separate ports. Applications that support SOCKS
  authentication can further be separated on a single port by their
  choice of username/password.  Streams sent to separate ports or using
  different authentication information should never be sent over the
  same circuit.  We allow each port to have its own settings for
  isolation based on destination port, destination address, or both.

  Handling DNS can be a challenge.  We can get hostnames by one of three
  means:

    A) A SOCKS4a request, or a SOCKS5 request with a hostname.  This
       case is handled trivially using the rules above.
    B) A RESOLVE request on a SOCKSPort.  This case is handled using the
       rules above, except that port isolation can't work to isolate
       RESOLVE requests into a proper session, since we don't know which
       port will eventually be used when we connect to the returned
       address.
    C) A request on a DNSPort.  We have no way of knowing which
       address/port will be used to connect to the requested address.

  When B or C is required but problematic, we could favor the use of
  AutomapHostsOnResolve.

Interface:

  We propose that {SOCKS,Natd,Trans,DNS}ListenAddr be deprecated in
  favor of an expanded {SOCKS,Natd,Trans,DNS}Port syntax:

  ClientPortLine = OptionName SP (Addr ":")? Port (SP Options?)
  OptionName = "SOCKSPort" / "NatdPort" / "TransPort" / "DNSPort"
  Addr = An IPv4 address / an IPv6 address surrounded by brackets.
         If optional, we default to 127.0.0.1
  Port = An integer from 1 through 65535 inclusive
  Options = Option
  Options = Options SP Option
  Option = IsolateOption / GroupOption
  GroupOption = "SessionGroup=" UINT
  IsolateOption =  OptNo ("IsolateDestPort" / "IsolateDestAddr" /
         "IsolateSOCKSUser"/ "IsolateClientProtocol" /
         "IsolateClientAddr") OptPlural
  OptNo = "No" ?
  OptPlural = "s" ?
  SP = " "
  UINT = An unsigned integer

  All options are case-insensitive.

  The "IsolateSOCKSUser" and "IsolateClientAddr" options are on by
  default; "NoIsolateSOCKSUser" and "NoIsolateClientAddr" respectively
  turn them off.  The IsolateDestPort and IsolateDestAddr and
  IsolateClientProtocol options are off by default.  NoIsolateDestPort and
  NoIsolateDestAddr and NoIsolateClientProtocol have no effect.

  Given a set of ClientPortLines, streams must NOT be placed on the same
  circuit if ANY of the following hold:

    * They were sent to two different client ports, unless the two
      client ports both specify a "SessionGroup" option with the same
      integer value.
    * At least one was sent to a client port with the IsolateDestPort
      active, and they have different destination ports.
    * At least one was sent to a client port with IsolateDestAddr
      active, and they have different destination addresses.
    * At least one was sent to a client port with IsolateClientProtocol
      active, and they use different protocols (where SOCKS4, SOCKS4a,
      SOCKS5, TransPort, NatdPort, and DNS are the protocols in question)
    * At least one was sent to a client port with IsolateSOCKSUser
      active, and they have different SOCKS username/password values
      configurations.  (For the purposes of this option, the
      username/password pair of ""/"" is distinct from SOCKS without
      authentication, and both are distinct from any non-SOCKS client's
      non-authentication.)
    * At least one was sent to a client port with IsolateClientAddr
      active, and they came from different client addresses.  (For the
      purpose of this option, any local interface counts as the same
      address.  So if the host is configured with addresses 10.0.0.1,
      192.0.32.10, and 127.0.0.1, then traffic from those addresses can
      leave on the same circuit, but traffic to from 10.0.0.2 (for
      example) could not share a circuit with any of them.)

  These rules apply regardless of whether the streams are active at the
  same time.  In other words, if the rules say that streams A and B must
  not be on the same circuit, and stream A is attached to circuit X,
  then stream B must never be attached to stream X, even if stream A is
  closed first.

Alternative Interface:

  We're cramming a lot onto one line in the design above.  Perhaps
  instead it would be a better idea to have grouped lines of the form:

    StreamGroup 1
    SOCKSPort 9050
    TransPort 9051
    IsolateDestPort 1
    IsolateClientProtocol 0
    EndStreamGroup

    StreamGroup 2
    SOCKSPort 9052
    DNSPort 9053
    IsolateDestAddr 1
    EndStreamGroup

  This would be equivalent to:
   SOCKSPort 9050 SessionGroup=1 IsolateDestPort NoIsolateClientProtocol
   TransPort 9051 SessionGroup=1 IsolateDestPort NoIsolateClientProtocol
   SOCKSPort 9052 SessionGroup=2 IsolateDestAddr
   DNSPort   9053 SessionGroup=2 IsolateDestAddr

  But it would let us extend range of allowed options later without
  having client port lines group without bound.  For example, we might
  give different circuit building parameters to different session
  groups.

Example of use:

  Suppose that we want to use a web browser, an IRC client, and a SSH
  client all at the same time.  Let's assume that we want web traffic to
  be isolated from all other traffic, even if the browser makes
  connections to ports usually used for IRC or SSH.  Let's also assume
  that IRC and SSH are both used for relatively long-lived connections,
  and we want to keep all IRC/SSH sessions separate from one another.

  In this case, we could say:

    SOCKSPort 9050
    SOCKSPort 9051 IsolateDestAddr IsolateDestPort

  We would then configure our browser to use 9050 and our IRC/SSH
  clients to use 9051.

Advanced example of use, #2:

  Suppose that we have a bunch of applications, and we launch them all
  using torsocks, and we want to keep each applications isolated from
  one another.  We just create a shell script, "torlaunch":
    #!/bin/bash
    export TORSOCKS_USERNAME="$1"
    exec torsocks $@
  And we configure our SOCKSPort with IsolateSOCKSUser.

  Or if we're on Linux and we want to isolate by application invocation,
  we would change the TORSOCKS_USERNAME line to:

    export TORSOCKS_USERNAME="`cat /proc/sys/kernel/random/uuid`"

Advanced example of use, #2:

  Now suppose that we want to achieve the benefits of the first example
  of use, but we are stuck using transparent proxies.  Let's suppose
  this is Linux.

    TransPort 9090
    TransPort 9091 IsolateDestAddr IsolateDestPort
    DNSPort 5353
    AutomapHostsOnResolve 1

  Here we use the iptables --cmd-owner filter to distinguish which
  command is originating the packets, directing traffic from our irc
  client and our SSH client to port 9091, and directing other traffic to
  9090.  Using AutomapHostsOnResolve will confuse ssh in its default
  configuration; we'll need to find a way around that.

Security Risks:

  Disabling IsolateClientAddr is a pretty bad idea.

  Setting up a set of applications to use this system effectively is a
  big problem.  It's likely that lots of people who try to do this will
  mess it up.  We should try to see which setups are sensible, and see
  if we can provide good feedback to explain which streams are isolated
  how.

Performance Risks:

  This proposal will result in clients building many more circuits than
  they do today.  To avoid accidentally hammering the network, we should
  have in-process limits on the maximum circuit creation rate and the
  total maximum client circuits.

Specification:

  The Tor client circuit selection process is not entirely specified.
  Any client circuit specification must take these changes into account.

Implementation notes:

  The more obvious ways to implement the "find a good circuit to attach
  to" part of this proposal involve doing an O(n_circuits) operation
  every time we have a stream to attach.  We already do such an
  operation, so it's not as if we need to hunt for fancy ways to make it
  O(1).  What will be harder is implementing the "launch circuits as
  needed" part of the proposal.  Still, it should come down to "a simple
  matter of programming."

  The SOCKS4 spec has the client provide authentication info when it
  connects; accepting such info is no problem.  But the SOCKS5 spec has
  the client send a list of known auth methods, then has the server send
  back the authentication method it chooses.  We'll need to update the
  SOCKS5 implementation so it can accept user/password authentication if
  it's offered.

  If we use the second syntax for describing these options, we'll want
  to add a new "section-based" entry type for the configuration parser.
  Not a huge deal; we already have kludged up something similar for
  hidden service configurations.

  Opening circuits for predicted ports has the potential to get a little
  more complicated; we can probably get away with the existing
  algorithm, though, to see where its weak points are and look for
  better ones.

  Perhaps we can get our next-gen HTTP proxy to communicate browser tab
  or session into to tor via authentication, or have torbutton do it
  directly.  More design is needed here, though.

Alternative designs:

  The implementation of this option may want to consider cases where the
  same exit node is shared by two or more circuits and
  IsolateStreamsByPort is in force.  Since one possible use of the option
  is to reduce the opportunity of Exit Nodes to attack traffic from the
  same source on multiple ports, the implementation may need to ensure
  that circuits reserved for the exclusive use of given ports do not
  share the same exit node.  On the other hand, if our goal is only that
  streams should be unlinkable, deliberately shunting them to different
  exit nodes is unnecessary and slightly counterproductive.

  Earlier versions of this design included a mechanism to isolate
  _particular_ destination ports and addresses, so that traffic sent to,
  say, port 22 would never share a port with any traffic *not* sent to
  port 22.  You can achieve this here by having all applications that
  send traffic to one of these ports use a separate SOCKSPort, and
  then setting IsolateDestPorts on that SOCKSPort.

Lingering questions:

  I suspect there are issues remaining with DNS and TransPort users, and
  that my "just use AutomapHostsOnResolve" suggestion may be
  insufficient.
</body></email><email><emailId>20101215043503</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-12-15 04:35:03-0400</timestampReceived><subject>Draft document and notes from rransom: requirements for circuit crypto</subject><body>

Here's a slightly reformatted version of Robert Ransom's current notes
on circuit crypto requirements.  If I understand his goals here, he
wants to work out a set of requirements for any revised circuit crypto
protocol s.t. it can be called "secure" for Tor's purposes.  With
permission, I'm posting it here and putting it in
doc/spec/proposals/ideas/xxx-crypto-requirements.txt.

I'm also attaching, but not putting in the repo, some additional notes
that Robert's been keeping as he worked along with these.  I don't
know that they belong in the tor repo yet, but they've got some neat
thoughts that could be well integrated into some of the other
documents.

===
Title: Requirements for Tor's circuit cryptography
Author: Robert Ransom
Created: 12 December 2010

Overview

  This draft is intended to specify the meaning of 'secure' for a Tor
  circuit protocol, hopefully in enough detail that
  mathematically-inclined cryptographers can use this definition to
  prove that a Tor circuit protocol (or component thereof) is secure
  under reasonably well-accepted assumptions.

  Tor's current circuit protocol consists of the CREATE, CREATED, RELAY,
  DESTROY, CREATE_FAST, CREATED_FAST, and RELAY_EARLY cells (including
  all subtypes of RELAY and RELAY_EARLY cells).  Tor currently has two
  circuit-extension handshake protocols: one consists of the CREATE and
  CREATED cells; the other, used only over the TLS connection to the
  first node in a circuit, consists of the CREATE_FAST and CREATED_FAST
  cells.

Requirements

  1. Every circuit-extension handshake protocol must provide forward
  secrecy -- the protocol must allow both the client and the relay to
  destroy, immediately after a circuit is closed, enough key material
  that no attacker who can eavesdrop on all handshake and circuit cells
  and who can seize and inspect the client and relay after the circuit
  is closed will be able to decrypt any non-handshake data sent along
  the circuit.

  In particular, the protocol must not require that a key which can be
  used to decrypt non-handshake data be stored for a predetermined
  period of time, as such a key must be written to persistent storage.

  2. Every circuit-extension handshake protocol must specify what key
  material must be used only once in order to allow unlinkability of
  circuit-extension handshakes.

  3. Every circuit-extension handshake protocol must authenticate the relay
  to the client -- an attacker who can eavesdrop on all handshake and
  circuit cells and who can participate in handshakes with the client
  must not be able to determine a symmetric session key that a circuit
  will use without either knowing a secret key corresponding to a
  handshake-authentication public key published by the relay or breaking
  a cryptosystem for which the relay published a
  handshake-authentication public key.

  4. Every circuit-extension handshake protocol must ensure that neither
  the client nor the relay can cause the handshake to result in a
  predetermined symmetric session key.

  5. Every circuit-extension handshake protocol should ensure that an
  attacker who can predict the relay's ephemeral secret input to the
  handshake and can eavesdrop on all handshake and circuit cells, but
  does not know a secret key corresponding to the
  handshake-authentication public key used in the handshake, cannot
  break the handshake-authentication public key's cryptosystem, and
  cannot predict the client's ephemeral secret input to the handshake,
  cannot predict the symmetric session keys used for the resulting
  circuit.

  6. The circuit protocol must specify an end-to-end flow-control
  mechanism, and must allow for the addition of new mechanisms.

  7. The circuit protocol should specify the statistics to be exchanged
  between circuit endpoints in order to support end-to-end flow control,
  and should specify how such statistics can be verified.


  8. The circuit protocol should allow an endpoint to verify that the other
  endpoint is participating in an end-to-end flow-control protocol
  honestly.
===========
NOTES:




All circuit handshake protocols must provide forward security.  This
requires that the client send a public key for some asymmetric
protocol that can provide secrecy (RSA, ElGamal, DH, McEliece,
Ajtai-Dwork, Lyubashevsky-Palacio-Segev, etc.) to each node in each
circuit.

The public keys and public parameters used in different handshakes
must be unlinkable.  This will restrict different cryptosystems in
different ways:

* An RSA or LPS key must be used only once, and then the entire secret
  key must be destroyed.

* An ElGamal or DH key must be used only once, and then the secret
  exponent must be destroyed.  In addition, if the client generated
  the public parameters used by the key, the public parameters must
  also be destroyed.  (Public parameters published by a third party
  may be used multiple times.)



special wants to make it impossible for a node in the hidserv
directory DHT to determine the address a hidserv descriptor describes
unless it already knows the address.  The problem here is that the
following are absolutely required:

* Each client must be able to compute, from the hidserv's address and
  a public nonce, the DHT retrieval key needed to retrieve the
  hidserv's descriptor and any decryption key needed to use the
  descriptor.

* Each hidserv must give each DHT node responsible for its retrieval
  key the DHT retrieval key and a descriptor, and must prove to the
  DHT node that it knows a secret key which ‘owns’ a hidserv address
  which currently ‘owns’ the retrieval key.

The proof of knowledge of a hidserv secret key is needed not to keep
jerks from crapflooding a DHT node (they can still do that by
generating lots of hidserv secret keys), but to prevent a censor from
overwriting someone else's hidserv descriptor and thereby blocking
access to the hidserv.



Other questions:

* What types of attackers should Tor's crypto protect against?

* What types of attacks should Tor's crypto protect against?

* How do we transition relay identity key cryptosystems, now and in
  the future?

* How do we transition directory identity key cryptosystems, now and
  in the future?

</body></email><email><emailId>20101102124316</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-02 12:43:16-0400</timestampReceived><subject>Tor on 64bit Windows (XP)</subject><body>

Hi or-dev,

Someone asked me about Tor on 64bit Windows XP.
Does anyone have any thoughts on Tor running under XP @ 64bit ?
I don't know if its just an issue of compiling it ?

Im sure 32bit Tor can run under 64bit Windows 7 (well, im kinda sure(ish) )

I found this link to 64bit compatible software, offering Tor for download...
http://www.x64bitdownload.com/downloads/t-64-bit-tor-for-windows-download-cwevqwmj.html
But the list of OS'es at that site does not explicitly name 64bit 
Windows XP, mentioning only 64bit Windows 7.

It could be a case of suggesting a move to Windows 7 ?

I cant experiment as I'm on a 32bit OS.

Thanks in advance...
-- 

</body></email><email><emailId>20101108151530</emailId><senderName>Hans Schnehl</senderName><senderEmail>torvallenator@gmail.com</senderEmail><timestampReceived>2010-11-08 15:15:30-0400</timestampReceived><subject>Recommended combinations tor/ssl/libevent</subject><body>


Hi all,

see exempt from coredump of a v0.2.2.12-alpha-dev, which was happily 
running until 5 days ago.
Which versions of libevent, openssh , tor itself are known to be co-working
nicely nowadays ?

Regards 

Hans

----------------------------------

       
ico# gdb tor_git/src/or/tor   tor.core 
GNU gdb 6.1.1 [FreeBSD]
Copyright 2004 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for details.
This GDB was configured as "amd64-marcel-freebsd"...
Core was generated by `tor'.
Program terminated with signal 11, Segmentation fault.
Reading symbols from /lib/libm.so.5...done.
Loaded symbols for /lib/libm.so.5
Reading symbols from /lib/libthr.so.3...done.
Loaded symbols for /lib/libthr.so.3
Reading symbols from /lib/libc.so.7...done.
Loaded symbols for /lib/libc.so.7
Reading symbols from /libexec/ld-elf.so.1...done.
Loaded symbols for /libexec/ld-elf.so.1
#0  0x00000000004d8610 in tls1_mac ()
[New Thread 804a2f940 (LWP 100125)]
[New Thread 800e041c0 (LWP 100117)]
(gdb) bt full
#0  0x00000000004d8610 in tls1_mac ()
No symbol table info available.
#1  0x00000000004f7a94 in do_ssl3_write ()
No symbol table info available.
#2  0x00000000004f7b86 in ssl3_dispatch_alert ()
No symbol table info available.
#3  0x00000000004f8519 in ssl3_read_bytes ()
No symbol table info available.
#4  0x00000000004f5562 in ssl3_read_internal ()
No symbol table info available.
#5  0x00000000004b579d in tor_tls_read (tls=0x80337b460, cp=Variable "cp" is not available.
) at tortls.c:1084
        r = Variable "r" is not available.
(gdb) frame 5
#5  0x00000000004b579d in tor_tls_read (tls=0x80337b460, cp=Variable "cp" is not available.
) at tortls.c:1084
1084      r = SSL_read(tls-&gt;ssl, cp, (int)len);
(gdb) l
1079      int r, err;
1080      tor_assert(tls);
1081      tor_assert(tls-&gt;ssl);
1082      tor_assert(tls-&gt;state == TOR_TLS_ST_OPEN);
1083      tor_assert(len&lt;INT_MAX);
1084      r = SSL_read(tls-&gt;ssl, cp, (int)len);
1085      if (r &gt; 0) {
1086    #ifdef V2_HANDSHAKE_SERVER
1087        if (tls-&gt;got_renegotiate) {
1088          /* Renegotiation happened! */
(gdb) p r
Variable "r" is not available.
(gdb) 


-----------------------------------
</body></email><email><emailId>20101108212139</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-08 21:21:39-0400</timestampReceived><subject>Re: Recommended combinations tor/ssl/libevent</subject><body>

On Mon, Nov 8, 2010 at 10:15 AM, Hans Schnehl &lt;torvallenator@gmail.com&gt; wrote:
&gt;
&gt; Hi all,
&gt;
&gt; see exempt from coredump of a v0.2.2.12-alpha-dev, which was happily
&gt; running until 5 days ago.
&gt; Which versions of libevent, openssh , tor itself are known to be co-working
&gt; nicely nowadays ?

I'd guess that your problem there is the Tor version: The latest
0.2.2.x alpha code, or the latest maint-0.2.2 git head, should be much
better than anything from back in April.  If you're going to use alpha
releases, you should probably try to keep up-to-date: knowing that
there was a bug in 0.2.2.12-alpha at this point doesn't really help us
much unless we know whether it is also a bug in the latest 0.2.2.x.
This goes doubly for "-dev" versions (versions based on the state of
the Git repository between releases): if you want to checkpoint the
state of Tor development then ignore it for half a year, I'd strondly
suggest checkpointing at an actually released version that works for
you.

For Libevent, I personally recommend the latest 2.0.x, or at least
1.4.12-stable or later.  1.3e should work in a pinch too, if you
really must.

Tor doesn't use openssh; it uses openssl.  Most vendor versions should
work assuming they claim to be 0.9.7x or later.  If you can't use your
vendor's shipped version, I personally recommend the latest 0.9.8x
release or the latest 1.0.0x release.

(These are my recommended versions, not an exhaustive list of
known-to-work versions.  To the best of my knowledge, nobody has
compiled such a list.)

-- 
Nick
</body></email><email><emailId>20101102125622</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-02 12:56:22-0400</timestampReceived><subject>Re: Tor on 64bit Windows (XP)</subject><body>


On Tue, 02 Nov 2010 12:43:16 +0000
Cav &lt;cav@gotadsl.co.uk&gt; wrote:

&gt; Someone asked me about Tor on 64bit Windows XP.
&gt; Does anyone have any thoughts on Tor running under XP @ 64bit ?
&gt; I don't know if its just an issue of compiling it ?
&gt; 
&gt; Im sure 32bit Tor can run under 64bit Windows 7 (well, im kinda sure(ish) )

It works for me.

Compiling Tor as a 64-bit program should make the cryptographic
operations a bit faster, but it's not necessary in order to run Tor on
64-bit Windows.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101102125859</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-02 12:58:59-0400</timestampReceived><subject>Re: Tor on 64bit Windows (XP)</subject><body>

Thanks Robert for getting back so quick !

When you say 64bit Windows, are you including XP 64bit ?

TIA...


Robert Ransom wrote:
&gt; On Tue, 02 Nov 2010 12:43:16 +0000
&gt; Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt;
&gt;   
&gt;&gt; Someone asked me about Tor on 64bit Windows XP.
&gt;&gt; Does anyone have any thoughts on Tor running under XP @ 64bit ?
&gt;&gt; I don't know if its just an issue of compiling it ?
&gt;&gt;
&gt;&gt; Im sure 32bit Tor can run under 64bit Windows 7 (well, im kinda sure(ish) )
&gt;&gt;     
&gt;
&gt; It works for me.
&gt;
&gt; Compiling Tor as a 64-bit program should make the cryptographic
&gt; operations a bit faster, but it's not necessary in order to run Tor on
&gt; 64-bit Windows.
&gt;
&gt;
&gt; Robert Ransom
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Thanks Robert for getting back so quick !&lt;br&gt;
&lt;br&gt;
When you say 64bit Windows, are you including XP 64bit ?&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
TIA...&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Robert Ransom wrote:
&lt;blockquote cite="mid:20101102055622.3dd93a1a@gmail.com" type="cite"&gt;
  &lt;pre wrap=""&gt;On Tue, 02 Nov 2010 12:43:16 +0000
Cav &lt;a class="moz-txt-link-rfc2396E" href="mailto:cav@gotadsl.co.uk"&gt;&lt;cav@gotadsl.co.uk&gt;&lt;/a&gt; wrote:

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;Someone asked me about Tor on 64bit Windows XP.
Does anyone have any thoughts on Tor running under XP @ 64bit ?
I don't know if its just an issue of compiling it ?

Im sure 32bit Tor can run under 64bit Windows 7 (well, im kinda sure(ish) )
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
It works for me.

Compiling Tor as a 64-bit program should make the cryptographic
operations a bit faster, but it's not necessary in order to run Tor on
64-bit Windows.


Robert Ransom
  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20101102131633</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-02 13:16:33-0400</timestampReceived><subject>Re: Tor on 64bit Windows (XP)</subject><body>


On Tue, 02 Nov 2010 12:58:59 +0000
Cav &lt;cav@gotadsl.co.uk&gt; wrote:

&gt; When you say 64bit Windows, are you including XP 64bit ?

I have never used 64-bit Windows XP, but as I understand it, 32-bit
programs can run on 64-bit Windows XP, and Tor is a particularly
well-behaved 32-bit program.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101218144609</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2010-12-18 14:46:09-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

[Attachment #2 (multipart/mixed)]


Damian Johnson &lt;atagar1@gmail.com&gt; wrote on or-talk@:

&gt; Hi, I've uploaded a new tarball to:
&gt; http://www.atagar.com/transfer/tmp/arm_bsdTest3.tar.bz2
&gt; http://www.atagar.com/transfer/tmp/arm_bsdTest3.tar.bz2.asc

Seems to work great on my FreeBSD system, but when trying it
on one of my Tor relays (currently running Debian GNU/Linux)
I had to unset LANG to get the connection resolver working:

su -m debian-tor -c 'LANG=; /root/arm.git/arm -i 127.0.0.1:9051 -e 1'

Probably arm itself should do that.

Although there weren't that many connections:
"(171 inbound, 93 outbound, 1 control)"
I had to disable the connection panel anyway, as arm kept
hogging the CPU.

&gt; Besides a modified version of Febian's patch to autodetect FreeBSD
&gt; jails it most notably includes...
&gt; 
&gt; - A replacement for the connection test function (which was a pita in
&gt; my humble opinion). The new script [1] provides the resolver runtimes,
&gt; a check if all the resolvers match, and a better method of dumping the
&gt; connection results. If you modify the bsd resolvers then this should
&gt; provide a nice sanity check that it's working as expected.

I haven't looked into using it yet, but it sounds great.

&gt; - I forgot to account for the dns resolution exits do on behalf of the
&gt; clients. The resolvers need to include UDP connections so, on *nix,
&gt; they're now:
&gt; - netstat -np | grep "ESTABLISHED &lt;pid&gt;/&lt;process&gt;"
&gt; - sockstat | egrep "&lt;process&gt;\s*&lt;pid&gt;.*ESTABLISHED"
&gt; - lsof -nPi | egrep "^&lt;process&gt;\s*&lt;pid&gt;.*((UDP.*)|(\(ESTABLISHED\)))"
&gt; - ss -nptu | grep "ESTAB.*\"&lt;process&gt;\",&lt;pid&gt;"
&gt; 
&gt; I'm guessing, for the FreeBSD resolvers, that sockstats already works
&gt; and procstat just needs the 'grep TCP' to be removed (or maybe
&gt; replaced with 'egrep "(TCP|UDP)"'). Is that right?

I think you are.

&gt; &gt; The connection doesn't leave the system because its a socks
&gt; &gt; connection with both the source and the destination address
&gt; &gt; located on the same system.
&gt; 
&gt; Hm. Sounds like basic client connections (ie, things like firefox
&gt; connecting to tor via the SocksPort). However, I tried running TBB and
&gt; arm didn't list any of those connections. This is what I'd expect
&gt; since the connection resolution is only fetching tor connections. Am I
&gt; missing something here?

No, you're right, those socks connections are client connections.

&gt; Regardless, I made a couple changes to address issues that have been
&gt; brought up (socks connections and listing external addresses for
&gt; private ip range connections - see lines 332-334 and 363-364 in
&gt; src/interface/connPanel.py [2]). But without a working repro case I
&gt; can't promises that this'll do the trick.

Those socks connections now show up properly as client connections, thanks.

&gt; &gt; With ^ added to the pattern it seems to work
&gt; 
&gt; Great, it's happy with that on Linux as well so I'm now using:
&gt; lsof -nPi | egrep "^&lt;process&gt;\s*&lt;pid&gt;.*((UDP.*)|(\(ESTABLISHED\)))"
&gt; 
&gt; and including it among FreeBSD resolvers as the last fallback.

With the '\s' that's still not going to work. Even on the
Debian GNU/Linux system the egrep doesn't understand the "\s".

After fixing that and switching the resolver to lsof, I get the
following exception (may be a bit messed up as I had to scrape
it out of the connection panel):

File "/usr/lib/python2.5/threading.py", line 486, in __bootstrap_inner
self.run()
File "/root/arm.git/src/util/connections.py", line 339, in run
connResults = getConnections(resolver, self.processName, self.processPid)             \
File "/root/arm.git/src/util/connections.py", line 151, in getConnections) local, \
                foreign = comp[8].split("-&gt;")
IndexError: list index out of range

At least for the lsof 4.78 I'm using, the 8 needs to be a 7.

I attached a couple of patches for the problems I noticed, and an
improperly tested hack to show the external address between the
local and the foreign one, if the local and the external one differ.

Fabian


[Attachment #5 (text/x-patch)]

From fac5423e4ef6ecee0c85e38dc95b47931aa9c96a Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Tue, 14 Dec 2010 23:24:01 +0100
Subject: [PATCH 1/8] Fix spelling in a comment

---
 src/test.py |    2 +-
 1 files changed, 1 insertions(+), 1 deletions(-)

diff --git a/src/test.py b/src/test.py
index 94b1126..aad901c 100644
--- a/src/test.py
+++ b/src/test.py
@@ -98,7 +98,7 @@ while True:
   elif userInput == "3":
     uiTools.demoGlyphs()
     
-    # Switching to a curses context and back repetedy seems to screw up the
+    # Switching to a curses context and back repeatedly seems to screw up the
     # terminal. Just to be safe this ends the process after the demo.
     break
   else:
-- 
1.7.3.3


[Attachment #6 (text/x-patch)]

From 0b342d330b3430f7351e2b7b23ef2f6ac72a2204 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Wed, 15 Dec 2010 21:34:44 +0100
Subject: [PATCH 2/8] Factor ipAddressIsPrivate() out of reset()

---
 src/interface/connPanel.py |   12 ++++++++----
 1 files changed, 8 insertions(+), 4 deletions(-)

diff --git a/src/interface/connPanel.py b/src/interface/connPanel.py
index e9abe00..81f3f76 100644
--- a/src/interface/connPanel.py
+++ b/src/interface/connPanel.py
@@ -105,6 +105,13 @@ def getSortType(sortLabel):
     if sortLabel == label: return type
   raise ValueError(sortLabel)
 
+def ipAddressIsPrivate(Ip):
+  # TODO: range should restrict to the following address ranges:
+  #   10.*, 172.16.* - 172.31.*, 192.168.*
+  # being lazy right now - fix the 172.* range when rewriting
+  isPrivateIp = Ip.startswith("10.") or Ip.startswith("192.168.") or Ip.startswith("172.")
+  return isPrivateIp
+
 class ConnPanel(TorCtl.PostEventListener, panel.Panel):
   """
   Lists tor related connection data.
@@ -357,10 +364,7 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
         
         # replace nat address with external version if available and the
         # external address isn't a private IP
-        # TODO: range should restrict to the following address ranges:
-        #   10.*, 172.16.* - 172.31.*, 192.168.*
-        # being lazy right now - fix the 172.* range when rewriting
-        isPrivateIp = fIp.startswith("10.") or fIp.startswith("192.168.") or fIp.startswith("172.")
+        isPrivateIp = ipAddressIsPrivate(fIp)
         if self.address and type != "control" and not isPrivateIp: lIp = self.address
         
         try:
-- 
1.7.3.3


[Attachment #7 (text/x-patch)]

From b3a491898b677c58dc24f2fbdef18da1de0ce222 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Fri, 17 Dec 2010 00:09:06 +0100
Subject: [PATCH 3/8] Treat addresses starting with '127.' as private, too.

---
 src/interface/connPanel.py |    4 ++--
 1 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/src/interface/connPanel.py b/src/interface/connPanel.py
index 81f3f76..1703077 100644
--- a/src/interface/connPanel.py
+++ b/src/interface/connPanel.py
@@ -107,9 +107,9 @@ def getSortType(sortLabel):
 
 def ipAddressIsPrivate(Ip):
   # TODO: range should restrict to the following address ranges:
-  #   10.*, 172.16.* - 172.31.*, 192.168.*
+  #   10.*, 172.16.* - 172.31.*, 192.168.*, 127.*
   # being lazy right now - fix the 172.* range when rewriting
-  isPrivateIp = Ip.startswith("10.") or Ip.startswith("192.168.") or \
Ip.startswith("172.") +  isPrivateIp = Ip.startswith("10.") or \
Ip.startswith("192.168.") or Ip.startswith("172.") or Ip.startswith("127.")  return \
isPrivateIp  
 class ConnPanel(TorCtl.PostEventListener, panel.Panel):
-- 
1.7.3.3


[Attachment #8 (text/x-patch)]

From e0e1f903272558610f509407c953b6d92265ccac Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Wed, 15 Dec 2010 22:20:02 +0100
Subject: [PATCH 4/8] Don't add the country code to private addresses. XXX: the \
duplicated code could be factored out.

---
 src/interface/connPanel.py |   21 +++++++++++++++++----
 1 files changed, 17 insertions(+), 4 deletions(-)

diff --git a/src/interface/connPanel.py b/src/interface/connPanel.py
index 1703077..78a8bab 100644
--- a/src/interface/connPanel.py
+++ b/src/interface/connPanel.py
@@ -550,7 +550,9 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
             if self.listingType == LIST_IP:
               # base data requires 73 characters
               src = "%s:%s" % (entry[CONN_L_IP], entry[CONN_L_PORT])
-              dst = "%s:%s %s" % (entry[CONN_F_IP], entry[CONN_F_PORT], "" if type \
== "control" else "(%s)" % entry[CONN_COUNTRY]) +              dst = "%s:%s" % \
(entry[CONN_F_IP], entry[CONN_F_PORT]) +              if not \
ipAddressIsPrivate(entry[CONN_F_IP]): +                dst += " (%s)" % \
entry[CONN_COUNTRY]  
               if isPrivate: dst = "&lt;scrubbed&gt;"
               
@@ -583,7 +585,11 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
                 foreignHostnameSpace -= 22
                 
                 if isPrivate: ipEntry = "&lt;scrubbed&gt;"
-                else: ipEntry = "%s %s" % (entry[CONN_F_IP], "" if type == "control" \
else "(%s)" % entry[CONN_COUNTRY]) +                else:
+                  ipEntry = "%s:%s" % (entry[CONN_F_IP], entry[CONN_F_PORT])
+                  if ipAddressIsPrivate(entry[CONN_F_IP]):
+                    ipEntry += " (%s)" % entry[CONN_COUNTRY]
+
                 etc += "%-20s  " % ipEntry
               
               if width &gt; 134 + xOffset:
@@ -631,7 +637,10 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
               if width &gt; 125 + xOffset:
                 # shows ip/port/locale (column width: 28 characters)
                 if isPrivate: ipEntry = "&lt;scrubbed&gt;"
-                else: ipEntry = "%s:%s %s" % (entry[CONN_F_IP], entry[CONN_F_PORT], \
"" if type == "control" else "(%s)" % entry[CONN_COUNTRY]) +                else:
+                  ipEntry = "%s:%s" % (entry[CONN_F_IP], entry[CONN_F_PORT])
+                  if ipAddressIsPrivate(entry[CONN_F_IP]):
+                    ipEntry += " (%s)" % entry[CONN_COUNTRY]
                 etc += "%-26s  " % ipEntry
             else:
               # base data uses whatever extra room's available (using minimun of 50 \
characters) @@ -653,7 +662,11 @@ class ConnPanel(TorCtl.PostEventListener, \
panel.Panel):  foreignNicknameSpace -= 28
                 
                 if isPrivate: ipEntry = "&lt;scrubbed&gt;"
-                else: ipEntry = "%s:%s %s" % (entry[CONN_F_IP], entry[CONN_F_PORT], \
"" if type == "control" else "(%s)" % entry[CONN_COUNTRY]) +                else:
+                  ipEntry = "%s:%s" % (entry[CONN_F_IP], entry[CONN_F_PORT])
+                  if ipAddressIsPrivate(entry[CONN_F_IP]):
+                    ipEntry += " (%s)" % entry[CONN_COUNTRY]
+
                 etc += "%-26s  " % ipEntry
               
               dst = ("%%-%is" % foreignNicknameSpace) % dst
-- 
1.7.3.3


[Attachment #9 (text/x-patch)]

From 7633ef1e9eb166c0c1c8517aa95802eeac6a4b8e Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Fri, 17 Dec 2010 19:03:56 +0100
Subject: [PATCH 5/8] If the fIp is private, don't bother trying to get a countryCode

---
 src/interface/connPanel.py |   20 ++++++++++++--------
 1 files changed, 12 insertions(+), 8 deletions(-)

diff --git a/src/interface/connPanel.py b/src/interface/connPanel.py
index 78a8bab..5e1b0d5 100644
--- a/src/interface/connPanel.py
+++ b/src/interface/connPanel.py
@@ -367,14 +367,18 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
         isPrivateIp = ipAddressIsPrivate(fIp)
         if self.address and type != "control" and not isPrivateIp: lIp = self.address
         
-        try:
-          countryCodeQuery = "ip-to-country/%s" % fIp
-          countryCode = self.conn.get_info(countryCodeQuery)[countryCodeQuery]
-        except (socket.error, TorCtl.ErrorReply, TorCtl.TorCtlClosed):
-          countryCode = "??"
-          if not self.providedGeoipWarning:
-            log.log(log.WARN, "Tor geoip database is unavailable.")
-            self.providedGeoipWarning = True
+        if ipAddressIsPrivate(fIp):
+          # Should not be shown
+          countryCode = "???"
+        else:
+          try:
+            countryCodeQuery = "ip-to-country/%s" % fIp
+            countryCode = self.conn.get_info(countryCodeQuery)[countryCodeQuery]
+          except (socket.error, TorCtl.ErrorReply, TorCtl.TorCtlClosed):
+            countryCode = "??"
+            if not self.providedGeoipWarning:
+              log.log(log.WARN, "Tor geoip database is unavailable.")
+              self.providedGeoipWarning = True
         
         if (fIp, fPort) in connTimes: connTime = connTimes[(fIp, fPort)]
         else: connTime = time.time()
-- 
1.7.3.3


[Attachment #10 (text/x-patch)]

From 7e2ca00f19505859ec02fbfbff9f4edfb14bd00d Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Sat, 18 Dec 2010 14:45:09 +0100
Subject: [PATCH 6/8] Replace the '\s' in RUN_LSOF with ' ' to get it working.

---
 src/util/connections.py |    2 +-
 1 files changed, 1 insertions(+), 1 deletions(-)

diff --git a/src/util/connections.py b/src/util/connections.py
index abec3f6..d154288 100644
--- a/src/util/connections.py
+++ b/src/util/connections.py
@@ -60,7 +60,7 @@ RUN_SS = "ss -nptu | grep \"ESTAB.*\\\"%s\\\",%s\""
 # oddly, using the -p flag via:
 # lsof      lsof -nPi -p &lt;pid&gt; | grep "^&lt;process&gt;.*(ESTABLISHED)"
 # is much slower (11-28% in tests I ran)
-RUN_LSOF = "lsof -nPi | egrep \"^%s\\s*%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
+RUN_LSOF = "lsof -nPi | egrep \"^%s *%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
 
 # output:
 # atagar  tor  3475  tcp4  127.0.0.1:9051  127.0.0.1:38942  ESTABLISHED
-- 
1.7.3.3


[Attachment #11 (text/x-patch)]

From e420434b29a64887a396e016921d8408cbbc80f6 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Sat, 18 Dec 2010 15:09:06 +0100
Subject: [PATCH 7/8] Fix splitting of the CMD_LSOF results

---
 src/util/connections.py |    2 +-
 1 files changed, 1 insertions(+), 1 deletions(-)

diff --git a/src/util/connections.py b/src/util/connections.py
index d154288..9ca32be 100644
--- a/src/util/connections.py
+++ b/src/util/connections.py
@@ -148,7 +148,7 @@ def getConnections(resolutionCmd, processName, processPid = ""):
       localIp, localPort = comp[4].split(":")
       foreignIp, foreignPort = comp[5].split(":")
     elif resolutionCmd == CMD_LSOF:
-      local, foreign = comp[8].split("-&gt;")
+      local, foreign = comp[7].split("-&gt;")
       localIp, localPort = local.split(":")
       foreignIp, foreignPort = foreign.split(":")
     elif resolutionCmd == CMD_SOCKSTAT:
-- 
1.7.3.3


[Attachment #12 (text/x-patch)]

From 91e0bb1208a010e9ab1fd73aec456b48ce321b48 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Sat, 11 Dec 2010 17:56:21 +0100
Subject: [PATCH 8/8] Hack to show the nat address behind the local address instead of \
showing it instead of the local address.

---
 src/interface/connPanel.py |   20 +++++++++++++++-----
 1 files changed, 15 insertions(+), 5 deletions(-)

diff --git a/src/interface/connPanel.py b/src/interface/connPanel.py
index 5e1b0d5..aef5c75 100644
--- a/src/interface/connPanel.py
+++ b/src/interface/connPanel.py
@@ -362,11 +362,6 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
             connectionCountTmp[1] += 1
             if SCRUB_PRIVATE_DATA and fIp not in self.fingerprintMappings.keys(): \
isPrivate = isExitAllowed(fIp, fPort, self.exitPolicy, self.exitRejectPrivate)  
-        # replace nat address with external version if available and the
-        # external address isn't a private IP
-        isPrivateIp = ipAddressIsPrivate(fIp)
-        if self.address and type != "control" and not isPrivateIp: lIp = \
                self.address
-        
         if ipAddressIsPrivate(fIp):
           # Should not be shown
           countryCode = "???"
@@ -558,6 +553,17 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
               if not ipAddressIsPrivate(entry[CONN_F_IP]):
                 dst += " (%s)" % entry[CONN_COUNTRY]
               
+              # Hack to include the external address if it differs from the local \
one +              if entry[CONN_L_IP] != self.address:
+                if not ipAddressIsPrivate(entry[CONN_F_IP]):
+                  if type == "inbound":
+                    # XXX: untested
+                    src = self.address + "  &lt;--  " + src
+                  else:
+                    src += "  --&gt;  " + self.address
+                else:
+                  src   += "       " + " " * (len(self.address) + 1)
+
               if isPrivate: dst = "&lt;scrubbed&gt;"
               
               src, dst = "%-21s" % src, "%-26s" % dst
@@ -691,6 +697,10 @@ class ConnPanel(TorCtl.PostEventListener, panel.Panel):
               else:
                 ipStart = etc.find("256")
                 if ipStart &gt; -1: etc = etc[:ipStart] + ("%%-%is" % \
len(etc[ipStart:])) % "UNKNOWN" +
+            if entry[CONN_L_IP] != self.address:
+              # Make room for the previously added external address
+              etc = etc.strip()
             
             padding = width - (len(src) + len(dst) + len(etc) + 27) - xOffset # \
                padding needed to fill full line
             lineEntry = "&lt;%s&gt;%s  --&gt;  %s  %s%s%5s (&lt;b&gt;%s&lt;/b&gt;)%s&lt;/%s&gt;" % (color, src, \
                dst, etc, " " * padding, timeLabel, type.upper(), " " * (9 - \
                len(type)), color)
-- 
1.7.3.3


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101219044420</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-12-19 04:44:20-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

Fantastic! Thank you Fabian. I've applied everything except the
myInternal -&gt; myExternal address change (see below).

http://www.atagar.com/transfer/tmp/arm_bsdTest4.tar.bz2
http://www.atagar.com/transfer/tmp/arm_bsdTest4.tar.bz2.asc

&gt; I had to disable the connection panel anyway, as arm kept hogging the CPU

This is a problem. Arm defaults to making a connection resolution
every five seconds, and falls back to do them more infrequently if
they take longer than 50ms. This should mean that the backoff is
triggered if at least 1% of the total CPU time is spent on connection
resolutions (handled in lines 344-355 of connections.py [1]). However,
it sounds like that isn't functioning as intended. :(

For Linux I'm about to borrow a trick from psutil [2] and read the
/proc contents instead of performing ps and netstat lookups. Hopefully
this will help.

Could you please run the test.py script to check the relative runtimes
for the resolvers? Netstat and sockstat seem to perform the best on
Linux systems, but if this isn't always the case then I should have
arm check which is the fastest when picking the default resolver.

Also, did the log message saying "Arm's cpu usage is high (averaging
X%). You could lower it by dropping the connection data (running as
"arm -b")." show up? My system doesn't experience this issue so I
haven't confirmed if the warning's working or not.

&gt; I had to unset LANG to get the connection resolver working... Probably arm itself \
&gt; should do that.

This is the first I've heard of this. Do you have any idea what the
language has to do with connection resolution or arm? I'm weary of
messing with the environment variables since they're highly system
dependent and tend to have unintended side effects...

&gt; Even on the Debian GNU/Linux system the egrep doesn't understand the "\s".

Weird, on Ubuntu it's happy with both (I'd expect Ubuntu and Debian to
be alike in this way). Thanks for the fix! I applied it to sockstat
resolutions too.

&gt; At least for the lsof 4.78 I'm using, the 8 needs to be a 7.

Hm, sounds like your lsof version is missing one of the columns.
Here's what some of my results look like:

tor       28246 atagar   12u  IPv4 181244      0t0  UDP
192.168.0.3:56143-&gt;192.168.0.1:53
tor       28246 atagar   16u  IPv4 181278      0t0  TCP
192.168.0.3:47057-&gt;&lt;scrubbed&gt;:443 (ESTABLISHED)

I've changed it to strip the "(ESTABLISHED)" part and use the last
column so it should be happy with both of our versions.

&gt; ... and an improperly tested hack to show the external address between the local \
&gt; and the foreign one, if the local and the external one differ.

I tried applying this one (with a few fixes) but the connection panel
isn't great code to hack up. This introduces issues with column
alignment, confusing controller entries like:
127.0.0.1:9051  --&gt;  89.188.20.246  --&gt;  127.0.0.1:55224
and probably a few other headaches for edge cases like small screen resolutions.

The problem isn't really the change, but rather that this part of the
arm codebase kinda sucks. I'm not sure if you noticed, but the
connection panel and controller differ from all the rest of the
components. The reason is that arm's been going through a rewrite and
these are the last bits of the old codebase left.

I like this change, and the connection panel is the next part due for
a rewrite, so while I'm revising it I'll be sure to include this.

Many thanks for the patches! -Damian

[1] https://svn.torproject.org/svn/arm/trunk/src/util/connections.py
[2] https://code.google.com/p/psutil/


</body></email><email><emailId>20101219114117</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2010-12-19 11:41:17-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>


Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; &gt; I had to disable the connection panel anyway, as arm kept hogging the CPU
&gt; 
&gt; This is a problem. Arm defaults to making a connection resolution
&gt; every five seconds, and falls back to do them more infrequently if
&gt; they take longer than 50ms. This should mean that the backoff is
&gt; triggered if at least 1% of the total CPU time is spent on connection
&gt; resolutions (handled in lines 344-355 of connections.py [1]). However,
&gt; it sounds like that isn't functioning as intended. :(

I mainly see the problem when scrolling through the connection results:

arm - h942175 (Linux 2.6.26-2-686)         Tor 0.2.2.19-alpha (recommended)
Piper - 81.169.155.246:9001, Dir Port: 9030, Control Port (open): 9051
cpu: 10.3% tor, 92.2% arm  mem: 82 MB (16.4%)  pid: 1774   uptime: 1-18:57:16

I get the impression that the back-off mechanism doesn't apply in
that situation? Otherwise arm tends to stay below 30% cpu usage,
occasionally dropping below 5%.

Another problem I noticed that may or may not be connection related
is that arm occasionally stops working and neither updates the screen
nor reacts to keyboard input.

I previously thought it was caused by a problem with the ssh connection,
but after killing the python process and resetting the terminal the
connection is usable again. Unfortunately I'm not familiar enough
with python to debug this. When the problem happens, python doesn't
seem to use any cpu:

Cpu(s): 11.3%us,  2.0%sy,  0.0%ni, 85.7%id,  0.0%wa,  0.0%hi,  1.0%si,  0.0%st
Mem:    516292k total,   261100k used,   255192k free,    32176k buffers
Swap:  2104504k total,        0k used,  2104504k free,   126948k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 1774 debian-t  20   0 98.2m  84m  19m S 18.3 16.8 276:02.67 tor
 8317 debian-t  20   0  3772 1084  880 S  0.0  0.2   0:00.00 su
 8318 debian-t  20   0  4356 1400  992 S  0.0  0.3   0:00.00 bash
 8319 debian-t  20   0 55296  11m 2724 S  0.0  2.3   2:11.43 python

&gt; Could you please run the test.py script to check the relative runtimes
&gt; for the resolvers? Netstat and sockstat seem to perform the best on
&gt; Linux systems, but if this isn't always the case then I should have
&gt; arm check which is the fastest when picking the default resolver.

h942175:~/arm.git# su -m debian-tor -c 'LANG=; python /root/arm.git/src/test.py'
Arm Test Options:
  1. Resolver Performance Test
  2. Resolver Dump
  3. Glyph Demo
  q. Quit

Selection: 1

----------------------------------------

netstat     478 results     0.0587 seconds
sockstat    478 results     0.2310 seconds
lsof        478 results     0.1100 seconds
Traceback (most recent call last):
  File "/root/arm.git/src/test.py", line 42, in &lt;module&gt;
    connectionResults = connections.getConnections(resolver, "tor", conn.getMyPid())
  File "/root/arm.git/src/util/connections.py", line 135, in getConnections
    results = sysTools.call(cmd)
  File "/root/arm.git/src/util/sysTools.py", line 194, in call
    else: raise errorExc
IOError: 'ss' is unavailable

I didn't find a package for ss, yet.

&gt; Also, did the log message saying "Arm's cpu usage is high (averaging
&gt; X%). You could lower it by dropping the connection data (running as
&gt; "arm -b")." show up?

Yes.

12:40:37 [ARM_WARN] Arm's cpu usage is high (averaging 40.643%). You could lower it \
by dropping the connection data (running as "arm -b").

&gt; &gt; I had to unset LANG to get the connection resolver working... Probably arm itself \
&gt; &gt; should do that.
&gt; 
&gt; This is the first I've heard of this. Do you have any idea what the
&gt; language has to do with connection resolution or arm? I'm weary of
&gt; messing with the environment variables since they're highly system
&gt; dependent and tend to have unintended side effects...

If the output of the resolver utility is (partly) localized
the grep for "ESTABLISHED" no longer matches. However I also
just noticed that only netstat seems to be affected (at least
on the Debian GNU/Linux 5.0 system I'm using).

I think when I first ran into the problem I hadn't installed
sockstat yet and the lsof resolution failed because of the
column mismatch.

&gt; &gt; At least for the lsof 4.78 I'm using, the 8 needs to be a 7.
&gt; 
&gt; Hm, sounds like your lsof version is missing one of the columns.
&gt; Here's what some of my results look like:
&gt; 
&gt; tor       28246 atagar   12u  IPv4 181244      0t0  UDP
&gt; 192.168.0.3:56143-&gt;192.168.0.1:53
&gt; tor       28246 atagar   16u  IPv4 181278      0t0  TCP
&gt; 192.168.0.3:47057-&gt;&lt;scrubbed&gt;:443 (ESTABLISHED)

Yes, I don't get the "0t0" column:

tor     1774 debian-tor  625u  IPv4 395678       TCP \
81.169.155.246:47851-&gt;&lt;scrubbed&gt;:9001 (ESTABLISHED)

&gt; I've changed it to strip the "(ESTABLISHED)" part and use the last
&gt; column so it should be happy with both of our versions.

It works, thanks.

&gt; &gt; ... and an improperly tested hack to show the external address between the local \
&gt; &gt; and the foreign one, if the local and the external one differ.
&gt; 
&gt; I tried applying this one (with a few fixes) but the connection panel
&gt; isn't great code to hack up. This introduces issues with column
&gt; alignment, confusing controller entries like:
&gt; 127.0.0.1:9051  --&gt;  89.188.20.246  --&gt;  127.0.0.1:55224
&gt; and probably a few other headaches for edge cases like small screen resolutions.

Hmm, I thought the confusing controller case should be handled
with the ipAddressIsPrivate() patch (it works for me), but I
agree that there are a bunch of other problems with the patch.

&gt; The problem isn't really the change, but rather that this part of the
&gt; arm codebase kinda sucks. I'm not sure if you noticed, but the
&gt; connection panel and controller differ from all the rest of the
&gt; components. The reason is that arm's been going through a rewrite and
&gt; these are the last bits of the old codebase left.
&gt; 
&gt; I like this change, and the connection panel is the next part due for
&gt; a rewrite, so while I'm revising it I'll be sure to include this.

Great, thanks.

Fabian


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101109165506</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-09 16:55:06-0400</timestampReceived><subject>Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

Hi Or-Dev,

I have stumbled across this torrent client. My first thoughts, upon 
seeing Onion Routing in the description, was wondering if this is using 
the Tor network.
I have included a link and some details about this torrent client below.

In which case, does this then mean its likely to clobber the Tor network 
with p2p traffic ? - this bodes ill for Tor servers ?
Does anyone have any thoughts ?

 From the main page...
"""
*Anomos* is a pseudonymous, encrypted multi-peer-to-peer file 
distribution protocol. It is based on the peer/tracker concept of 
BitTorrent in combination with an onion routing anonymization layer, 
with the added benefit of end-to-end encryption. By combining these 
technologies, we have created a platform where by no party outside of 
the trusted tracker will have any information about who a peer is or 
what they are downloading.
"""

Anomos, psp client home page...
http://anomos.info/wp/

Tor is explicitly mentioned in this comments blog...
http://anomos.info/wp/2008/06/02/what-is-anomos/

-- 

With kind regards,


[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi Or-Dev,&lt;br&gt;
&lt;br&gt;
I have stumbled across this torrent client. My first thoughts, upon
seeing Onion Routing in the description, was wondering if this is using
the Tor network.&lt;br&gt;
I have included a link and some details about this torrent client below.&lt;br&gt;
&lt;br&gt;
In which case, does this then mean its likely to clobber the Tor
network with p2p traffic ? - this bodes ill for Tor servers ?&lt;br&gt;
Does anyone have any thoughts ?&lt;br&gt;
&lt;br&gt;
From the main page...&lt;br&gt;
"""&lt;br&gt;
&lt;strong&gt;Anomos&lt;/strong&gt; is a pseudonymous, encrypted multi-peer-to-peer
file distribution protocol. It is based on the peer/tracker concept of
BitTorrent in combination with an onion routing anonymization layer,
with the added benefit of end-to-end encryption. By combining these
technologies, we have created a platform where by no party outside of
the trusted tracker will have any information about who a peer is or
what they are downloading.&lt;br&gt;
"""&lt;br&gt;
&lt;br&gt;
Anomos, psp client home page...&lt;br&gt;
&lt;a class="moz-txt-link-freetext" \
href="http://anomos.info/wp/"&gt;http://anomos.info/wp/&lt;/a&gt;&lt;br&gt; &lt;br&gt;
Tor is explicitly mentioned in this comments blog...&lt;br&gt;
&lt;a class="moz-txt-link-freetext" \
href="http://anomos.info/wp/2008/06/02/what-is-anomos/"&gt;http://anomos.info/wp/2008/06/02/what-is-anomos/&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;
&lt;div class="moz-signature"&gt;-- &lt;br&gt;
&lt;br&gt;
With kind regards,
&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20101117230211</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-11-17 23:02:11-0400</timestampReceived><subject>P2P over Tor [was: Anomos - anonBT]</subject><body>

&gt; "
&gt; It's my understanding that BitTorrent is less of a bandwidth hog as it
&gt; is a connections/circuits hog. These are expensive to create and you
&gt; can't balance your BitTorrenting by hosting a high-bandwidth node
&gt; because to have 0 net effect on the network, you'd have to host a
&gt; circuit's worth of nodes for every circuit you're using for BitTorrent
&gt; connections.
&gt; "
&gt;
&gt; Bandwidth is surely finite but I'd bet safe to calculate. I would think
&gt; it easy to reach zero net, starting at minimally six times your use.
&gt;
&gt; Circuits are a separate issue. AFAIK, they are just consumers of state
&gt; on the nodes... CPU, RAM, TCP, etc. I can see where adding a node
&gt; [any node] in at 6x [or any x] would help distribute that load as well.
&gt;
&gt; Other than between the tracker, BT spawns a bunch of bandwith filled
&gt; pipes, up to some number of peers limit in the app. What is, if any, the
&gt; relationship between IPv4 TCP flows and Tor circuit usage? That could
&gt; help calculate the replacement value for non-bandwidth node resources.
&gt;
&gt;&gt; Am I wrong, Tor Old Ones?
&gt;
&gt; I sure haven't got that far in reading to guess yet, so yeah, if someone
&gt; has a hunch, that would be interesting. Maybe 6 nodes that add up to
&gt; 6x bandwidth or something.
&gt;
&gt; Not sure about anyone else, but I do think that with the way things
&gt; are going on the internet, more people will be looking to anonymous
&gt; systems in general to supplant it for their 'filesharing' and other
&gt; interests. That accumulation might be unstoppable.  So hopefully
&gt; those sorts of uses are being thought after and researched/planned/coded
&gt; for.


Thought about the non-bandwidth parts of the load some more...

There doesn't seem to be a need to quantify it with a numerical
estimate of what amount of resource giveback would yield a zero sum
impact for those parts.

Say you're using 'filesharing' in the form of BitTorrent. Your
single PC, when operating as a non-exit relay [1], can surely handle
many times the trivial sum of all the various non-bandwidth resources
described above that you would use along the way. Think of simulating
a TorNet by running all the needed directories, nodes and operations
bound to IP aliases on one PC. Conservatively say [3] you will have
up to 100 P2P circuits at 6 hops each... Any PC should be able to
handle that entire load with lots of headroom.

So long as users are covering their bandwidth with giveback [1], I
think it's safe to assume the rest of their overhead is also covered
by the addition of that node to the network.

I no longer think the standard reply/FAQ regarding such uses of
Tor, excepting [2], should be an unqualified: Tor can't handle it,
so don't.

The answer should be that... so long as such giveback [1] is:
- understood by users to be a necessary 'techical' condition to
 support their use of Tor for bulk transfer.
- indeed provided back to the network as a 'moral' condition by
 those same users.

... they should then feel free to use Tor for whatever they want.
BitTorrent, P2P, FTP, streaming media, chat, etc. And OnionCat is
the shim that will allow the apps to communicate seamlessly.

Though not as simple a response, and requiring donation by the user,
it seems to be the more reasoned one.

Further thoughts welcomed.


[1] It's already established that in order for your use of Tor
bandwidth to be zero sum (in the Hidden Service &lt;--&gt; Hidden Service
case) you need to give back at least 6x your use. So you will already
be running said relay (for the purpose of bandwidth giveback).

[2] Isn't there a proposal out there to better handle magnitudes
more users [and avoid shutdown points] by getting rid of the
directories and self-hosting the TorNet into a DHT or something?

[3] As the average bandwidth that most users [dsl, cable] will be
able to give back is small, transfers will be slow anyways. Which
may limit adoption [P2P peer counts]. Regardless, the limiting
factor is really only bandwidth because (dice up the giveback/6 you
can legitimately use... amongst P2P peer circuits however you want,
ie): dsl/cable = 1 x 256Kb/6 = 10 x 25.6Kb/6 = 100 x 2.56Kb/6
</body></email><email><emailId>20101117234914</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-11-17 23:49:14-0400</timestampReceived><subject>Re: Scalability and fairness [was: P2P over Tor [was: Anomos - anonBT]]</subject><body>

On Wed, Nov 17, 2010 at 3:02 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:
&gt; ...
&gt; So long as users are covering their bandwidth with giveback [1], I
&gt; think it's safe to assume the rest of their overhead is also covered
&gt; by the addition of that node to the network.

there's always a catch. ;)


&gt; ...
&gt; [1] It's already established that in order for your use of Tor
&gt; bandwidth to be zero sum (in the Hidden Service &lt;--&gt; Hidden Service
&gt; case) you need to give back at least 6x your use. So you will already
&gt; be running said relay (for the purpose of bandwidth giveback).
&gt;
&gt; [2] Isn't there a proposal out there to better handle magnitudes
&gt; more users [and avoid shutdown points] by getting rid of the
&gt; directories and self-hosting the TorNet into a DHT or something?

Tor would become something else, perhaps UDP Tor.

there has been more written on that subject than i can do justice
here.  i'm fond of DTLS signalling for encapsulated IPsec telescopes
with SFQ and DLP transport for multi-homed SCTP endpoints, but that is
just one of many possibilities.

a grand unified datagram Tor spec has yet to be written...
</body></email><email><emailId>20101119033655</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-19 03:36:55-0400</timestampReceived><subject>Vidalia Command Line Arguments... ?</subject><body>

Hi or-dev,

Forgive me my ignorance. I can't find a command-line reference for Vidalia.
I am only aware of the -data option, are there more ?

Thanks in advance...
-- 

With kind regards,
Cav Edwards

</body></email><email><emailId>20101122133315</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-11-22 13:33:15-0400</timestampReceived><subject>Stream starvation in Tor (with patch)</subject><body>

or-dev folks,

A number of groups (the UW people, the UCSD people, Roger(?) and
possibly others) have noticed that when many active streams (more than
about 4) are opened on a single circuit, 3 or 4 of them get service and
the rest starve until those are finished.  Note that, for example, most
web browsers will open multiple streams at once to fetch parts of web
pages.

Here's a plot of 9 active streams on one circuit:

https://thunk.cs.uwaterloo.ca/mashael/broken.png

(This graph was from measurements on a private Tor network on
PlanetLab.  This was from 0.2.3.0-alpha-dev, but the same behaviour was
observed previously on 0.2.2.*.)

Here's Mashael's writeup about the problem.

Our network consists of five nodes. An authoritative directory, a client
(also running as Onion Proxy), 3 Tor Onion Routers and a server.  We
refer to the three onion routers as Entry, Middle and Exit. Our client
constructs a circuit through the network, where the first hop is Entry,
the second is Middle and the third is Exit. The constructed circuit is
used to create multiple streams to the server. Each stream basically
carries a request from the client to the server, which replies with
10,000 cells. We repeated this experiment for 2, 5, 9 and 13 streams.
The common result is that the last three client streams created "almost"
starved the other earlier streams until they fully completed
transferring their 10,000 cells.


This problem only occurs when we have a bottleneck OR in the path. We
continue to see the problem as long as the bandwidth offered by the
bottleneck router is less than approximately 80% of the bandwidth that
is offered by the other routers in the circuit. For example, if the
bandwidthrate of Entry and Exit is 630 KB/s and 720 KB/s, respectively,
the problem is still visible even when the bandwidthrate of Middle is up
to 550 KB/s.  We verified that by setting the bandwidthrate command for
the Middle to a minimum value (20 KB/s) and then gradually increasing it
until the starvation of streams disappears from the resulting graphs at
approximately 600 KB/s.


The reason the "streams problem" occurs is due to the complicated
interaction between Tor's congestion control and libevent. At some point
during the experiment, the circuit window is exhausted, which blocks all
edge streams. When a circuit level sendme is received at Exit, it
resumes edge reading by looping over linked list of edge streams, and
calling connection_start_reading() to inform libevent to resume reading.
When the streams are activated again, Tor gets the chance to service the
first three streams activated before the circuit window is exhausted
again, which causes all streams to be blocked again.  As an experiment,
we reversed the order in which the streams are activated, and indeed the
first three streams, rather than the last three, got service, while the
others starved.

Our solution is to change the order in which streams are activated. We
choose a random edge connection from the linked list, and then we
activate streams starting from that chosen stream. When we reach the end
of the list, then we continue from the head of the list until our chosen
stream (treating the linked list as a circular linked list).  It would
probably be better to actually remember which streams have received
service recently, but this way is simple and effective.

Here's the graph again, with the patched Exit:

https://thunk.cs.uwaterloo.ca/mashael/fixed.png

The patch is attached.

   - Ian and Mashael

["mashael_stream_fix.diff" (text/x-diff)]

--- src/or/relay.c.orig	2010-11-19 11:00:22.140368267 -0500
+++ src/or/relay.c	2010-11-19 14:58:24.432368619 -0500
@@ -1507,6 +1507,8 @@
   int packaged_this_round;
   int cells_on_queue;
   int cells_per_conn;
+  int num_streams = 0;
+  edge_connection_t *chosen_stream = NULL;
 
   /* How many cells do we have space for?  It will be the minimum of
    * the number needed to exhaust the package window, and the minimum
@@ -1524,7 +1526,38 @@
   /* Count how many non-marked streams there are that have anything on
    * their inbuf, and enable reading on all of the connections. */
   n_streams = 0;
-  for (conn=first_conn; conn; conn=conn-&gt;next_stream) {
+  /* This used to start listening on the streams in the order they
+   * appeared in the linked list.  That leads to starvation in the
+   * event that, for example, our circuit window is almost full, and
+   * there are lots of streams.  Then the first few streams will have
+   * data read from them, and then the window will close again.  When
+   * it reopens, we would enable reading from the beginning of the list
+   * again.  Instead, we just pick a random stream on the list, and
+   * enable reading for streams starting at that point (and wrapping
+   * around as if the list were circular).  It would probably be better
+   * to actually remember which streams we've serviced in the past, but
+   * this is simple and effective. */
+
+  /* Select a stream uniformly at random from the linked list.  We
+   * don't need cryptographic randomness here. */
+  for(conn = first_conn; conn; conn = conn-&gt;next_stream) {
+    num_streams++;
+    if((random() % num_streams)==0) chosen_stream = conn;
+  }
+  /* Activate reading starting from the chosen stream */
+  for (conn=chosen_stream; conn; conn = conn-&gt;next_stream) {
+    /* Start reading for the streams starting from here */
+    if (conn-&gt;_base.marked_for_close || conn-&gt;package_window &lt;= 0)
+      continue;
+    if (!layer_hint || conn-&gt;cpath_layer == layer_hint) {
+      connection_start_reading(TO_CONN(conn));    
+
+      if (connection_get_inbuf_len(TO_CONN(conn)) &gt; 0)
+        ++n_streams;
+    }
+  }
+  /* Go back and do the ones we skipped, circular-style */
+  for(conn = first_conn; conn != chosen_stream; conn = conn-&gt;next_stream) {
     if (conn-&gt;_base.marked_for_close || conn-&gt;package_window &lt;= 0)
       continue;
     if (!layer_hint || conn-&gt;cpath_layer == layer_hint) {


</body></email><email><emailId>20101124220304</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-11-24 22:03:04-0400</timestampReceived><subject>0.2.3.0 as an exit: identity_digest not set</subject><body>

Here's another bug report.  [No patch this time, I'm afraid. :-( ]

When we try to use 0.2.3.0 as an exit, circuit construction succeeds,
but stream creation fails almost all the time.  The failure is in
connection_edge.c, here:

    if (or_circ &amp;&amp; or_circ-&gt;p_conn &amp;&amp; !options-&gt;AllowSingleHopExits &amp;&amp;
        (or_circ-&gt;is_first_hop ||
         (!connection_or_digest_is_known_relay(
                                       or_circ-&gt;p_conn-&gt;identity_digest) &amp;&amp;
          should_refuse_unknown_exits(options)))) {

Almost always (on both a PlanetLab test network and the live Tor
network), or_circ-&gt;p_conn-&gt;identity_digest is just a bunch of NULs,
so connection_or_digest_is_known_relay naturally returns false.
Weirdly, I've seen it *not* fail once or twice, but I can't replicate
the non-failure.

Commenting out the body of the if makes the problem go away, but of
course it removes the single-hop protection.

Any ideas?

Thanks,

   - Ian
</body></email><email><emailId>20101126151820</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-11-26 15:18:20-0400</timestampReceived><subject>Android: Tor shared library vs exec binary?</subject><body>


Any thoughts on running Tor as a shared library within Orbot/Android
versus the way we do it now (command line start/stop with control port)?


-------- Original Message --------
Subject: 	Re: Tor as a native JNI library
Date: 	Fri, 26 Nov 2010 15:58:46 +0100
From: 	Kristoffer Warming &lt;heavyhenning@gmail.com&gt;
To: 	Nathan Freitas &lt;nathan@freitas.net&gt;



In fact i meant to say that i've implemented it as a Android JNI
library, built with the NDK.
So far there's only a JNI API for starting and stopping tor, but i guess
one could replace the control port with a JNI solution?
The libtor.so file as i've called it is 1,2 megs, i wonder if thats of
any relevance.
I don't know if the JNI approach will make things easier, but i've often
encountered bugs with Orbot, where it seems it has lost touch with the
tor binary, so it thinks tor is not running, even though it is. This
would be easier to control with a JNI-tor running on a controllable
thread i guess.

/gr0gmint

2010/11/26 Nathan Freitas &lt;nathan@freitas.net &lt;mailto:nathan@freitas.net&gt;&gt;

    Thanks for letting me know. Is this for Java 1.6 on the desktop/server?

    Have you looked at the Android NDK at all? It is basically JNI for
    Android, though a bit more limited I believe. This is the route we would
    use for incorporating your work into Orbot.

    Have you talked with any of the other core tor-dev folks about running
    Tor as a shared library, vs. interacting with it via the control port. I
    wonder if there are any increased security risks with the library
    approach.

    +nathan (n8fr8)

    On 11/25/2010 03:45 PM, Kristoffer Warming wrote:
    &gt; Hi Nathan,
    &gt; I spoke to 'helix' on IRC, and he told me to contact you about this.
    &gt; I've implemented Tor as a JNI shared library, and i wonder if it could
    &gt; be of any interest to the Orbot project?
    &gt;
    &gt; Regards,
    &gt; Kristoffer (gr0gmint)


</body></email><email><emailId>20101129150408</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-29 15:04:08-0400</timestampReceived><subject>Re: Android: Tor shared library vs exec binary?</subject><body>

On Fri, Nov 26, 2010 at 10:18 AM, Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt;
&gt; Any thoughts on running Tor as a shared library within Orbot/Android
&gt; versus the way we do it now (command line start/stop with control port)?

So, first off, the obligatory disclaimers apply: It's free software,
not a dictatorship, so please don't feel bound by my opinions. :)

That said, I don't generally think embedding Tor as a shared library
is the best choice, for a few reasons.  Here's a _nonexhaustive__
list:

* Tor has absolutely zero promised-stable or supported internal APIs.
There is no function that we guarantee will exist in the next version.
 The only interfaces to Tor that we try to keep stable between one
interface and the next are the external ones, such as the command
line, the torrc format, the control protocol, and so on.

* Almost none of the functions that you'd want to call in Tor are
documented as safe to call from another thread.  So if you want to do
most of what Tor controllers let you do, and you try to do it via
function calls, you either need to hack up the Tor main loop to make
it stop periodically so as to run nonblockingly, or you need to add
locking to some admittedly complicated data structures, or you need to
accept that sometimes you'll get weird crashes and other misbehavior.

* Using process isolation to isolate Tor from its controllers makes it
easier to tell Tor bugs from controller bugs.  If they're both running
in the same process space, and you have a problem with mysterious
crashes, it's hard to tell whether the problem is in Tor, the
controller, or in the interaction between the two.

* Using process isolation to isolate Tor from its controllers can also
make it easier to secure each of the two domains properly against bugs
in the other, especially if you're using OS or VM sandboxing features.

So in summary, the only interface that you've got a prayer of running
safely via a JNI call without significant architectural changes is
tor_main(int argc, char **argv). All this really gets you is that it
makes it slightly easier for you to tell if Tor has exited normally
via returning from tor_main... but it means that any Tor crashes,
exits(), and assertion failures will crash your controller rather than
just crashing Tor.  That doesn't seem like a great trade to me.

If there's a problem with thinking that Tor is running when it isn't,
it's probably better to try to debug those (maybe by probing for
process status more often or something) that than to change your
architecture to one with new and more exciting issues.

just my thoughts; feel free to do differently.

peace,
-- 
Nick Mathewson
</body></email><email><emailId>20101124221451</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-24 22:14:51-0400</timestampReceived><subject>Re: 0.2.3.0 as an exit: identity_digest not set</subject><body>

On Wed, Nov 24, 2010 at 5:03 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; Here's another bug report.  [No patch this time, I'm afraid. :-( ]
&gt;
&gt; When we try to use 0.2.3.0 as an exit, circuit construction succeeds,
&gt; but stream creation fails almost all the time.  The failure is in
&gt; connection_edge.c, here:
&gt;

This looks like it is possibly part of the explanation for
https://trac.torproject.org/projects/tor/ticket/2205 .

-- 
Nick

</body></email><email><emailId>201011172349140</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-11-17 23:49:14-0400</timestampReceived><subject>Re: Scalability and fairness [was: P2P over Tor [was: Anomos - anonBT]]</subject><body>

On Wed, Nov 17, 2010 at 3:02 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:
&gt; ...
&gt; So long as users are covering their bandwidth with giveback [1], I
&gt; think it's safe to assume the rest of their overhead is also covered
&gt; by the addition of that node to the network.

there's always a catch. ;)


&gt; ...
&gt; [1] It's already established that in order for your use of Tor
&gt; bandwidth to be zero sum (in the Hidden Service &lt;--&gt; Hidden Service
&gt; case) you need to give back at least 6x your use. So you will already
&gt; be running said relay (for the purpose of bandwidth giveback).
&gt;
&gt; [2] Isn't there a proposal out there to better handle magnitudes
&gt; more users [and avoid shutdown points] by getting rid of the
&gt; directories and self-hosting the TorNet into a DHT or something?

Tor would become something else, perhaps UDP Tor.

there has been more written on that subject than i can do justice
here.  i'm fond of DTLS signalling for encapsulated IPsec telescopes
with SFQ and DLP transport for multi-homed SCTP endpoints, but that is
just one of many possibilities.

a grand unified datagram Tor spec has yet to be written...
</body></email><email><emailId>20101109173217</emailId><senderName>John Brooks</senderName><senderEmail>special@dereferenced.net</senderEmail><timestampReceived>2010-11-09 17:32:17-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

On Tue, Nov 9, 2010 at 9:55 AM, Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt; 
&gt; Hi Or-Dev,
&gt; 
&gt; I have stumbled across this torrent client. My first thoughts, upon seeing Onion \
&gt; Routing in the description, was wondering if this is using the Tor network. I have \
&gt; included a link and some details about this torrent client below. 

http://anomos.info/trac/wiki/FrequentlyAskedQuestions

Is Anomos BitTorrent over Tor?

"No. Tor is designed to protect against traffic-analysis attacks
against anonymity by routing traffic through its fixed network. It is
used primarily for web-surfing, although it can be used for other
services, such as BitTorrent. However, this is damaging to the Tor
network, which has a limited capacity, and the network operators often
take deliberate steps to prevent BitTorrent traffic on their network."

That said, it's an interesting project. Thanks for the link.

&gt; 
&gt; --
&gt; 
&gt; With kind regards,
&gt; 

- John Brooks


</body></email><email><emailId>20101109192130</emailId><senderName>"John M. Schanck"</senderName><senderEmail>jms07@hampshire.edu</senderEmail><timestampReceived>2010-11-09 19:21:30-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
&gt; Hi Or-Dev,
&gt; 
&gt; I have stumbled across this torrent client. My first thoughts, upon
&gt; seeing Onion Routing in the description, was wondering if this is
&gt; using the Tor network.
&gt; I have included a link and some details about this torrent client below.
&gt; 
&gt; In which case, does this then mean its likely to clobber the Tor
&gt; network with p2p traffic ? - this bodes ill for Tor servers ?
&gt; Does anyone have any thoughts ?
&gt; [snip]

Hi Cav,

I'm an Anomos developer so hopefully I can answer your questions :).
Anomos does not rely on the Tor network in any way. The blog does
suggest that clients could use Tor to make their announce requests, but
that functionality isn't built into Anomos directly. Even if users chose
to announce over Tor, it would amount, at most, to a few small HTTPS
requests per client per hour. The file transfers themselves are done
entirely peer-to-peer, with clients connected to the same tracker
serving as relays for each other. So, Anomos certainly wouldn't clobber
the Tor network, and ideally it would alleviate some of the load on Tor
by drawing BitTorrent users off of it.

-John
</body></email><email><emailId>20101109194322</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-09 19:43:22-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

Hi John,

Thanks very much for responding.

It does sound like a great project !
Wishing you every success with it.

With kind regards,



John M. Schanck wrote:
&gt; On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
&gt;   
&gt;&gt; Hi Or-Dev,
&gt;&gt;
&gt;&gt; I have stumbled across this torrent client. My first thoughts, upon
&gt;&gt; seeing Onion Routing in the description, was wondering if this is
&gt;&gt; using the Tor network.
&gt;&gt; I have included a link and some details about this torrent client below.
&gt;&gt;
&gt;&gt; In which case, does this then mean its likely to clobber the Tor
&gt;&gt; network with p2p traffic ? - this bodes ill for Tor servers ?
&gt;&gt; Does anyone have any thoughts ?
&gt;&gt; [snip]
&gt;&gt;     
&gt;
&gt; Hi Cav,
&gt;
&gt; I'm an Anomos developer so hopefully I can answer your questions :).
&gt; Anomos does not rely on the Tor network in any way. The blog does
&gt; suggest that clients could use Tor to make their announce requests, but
&gt; that functionality isn't built into Anomos directly. Even if users chose
&gt; to announce over Tor, it would amount, at most, to a few small HTTPS
&gt; requests per client per hour. The file transfers themselves are done
&gt; entirely peer-to-peer, with clients connected to the same tracker
&gt; serving as relays for each other. So, Anomos certainly wouldn't clobber
&gt; the Tor network, and ideally it would alleviate some of the load on Tor
&gt; by drawing BitTorrent users off of it.
&gt;
&gt; -John
&gt;
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi John,&lt;br&gt;
&lt;br&gt;
Thanks very much for responding.&lt;br&gt;
&lt;br&gt;
It does sound like a great project !&lt;br&gt;
Wishing you every success with it.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
John M. Schanck wrote:
&lt;blockquote cite="mid:20101109192130.GH5238@john-laptop" type="cite"&gt;
  &lt;pre wrap=""&gt;On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;Hi Or-Dev,

I have stumbled across this torrent client. My first thoughts, upon
seeing Onion Routing in the description, was wondering if this is
using the Tor network.
I have included a link and some details about this torrent client below.

In which case, does this then mean its likely to clobber the Tor
network with p2p traffic ? - this bodes ill for Tor servers ?
Does anyone have any thoughts ?
[snip]
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
Hi Cav,

I'm an Anomos developer so hopefully I can answer your questions :).
Anomos does not rely on the Tor network in any way. The blog does
suggest that clients could use Tor to make their announce requests, but
that functionality isn't built into Anomos directly. Even if users chose
to announce over Tor, it would amount, at most, to a few small HTTPS
requests per client per hour. The file transfers themselves are done
entirely peer-to-peer, with clients connected to the same tracker
serving as relays for each other. So, Anomos certainly wouldn't clobber
the Tor network, and ideally it would alleviate some of the load on Tor
by drawing BitTorrent users off of it.

-John


  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20101109215538</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2010-11-09 21:55:38-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

On Tue, Nov 9, 2010 at 11:21 AM, John M. Schanck &lt;jms07@hampshire.edu&gt;wrote:

&gt; On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
&gt; &gt; Hi Or-Dev,
&gt; &gt;
&gt; &gt; I have stumbled across this torrent client. My first thoughts, upon
&gt; &gt; seeing Onion Routing in the description, was wondering if this is
&gt; &gt; using the Tor network.
&gt; &gt; I have included a link and some details about this torrent client below.
&gt; &gt;
&gt; &gt; In which case, does this then mean its likely to clobber the Tor
&gt; &gt; network with p2p traffic ? - this bodes ill for Tor servers ?
&gt; &gt; Does anyone have any thoughts ?
&gt; &gt; [snip]
&gt;
&gt; Hi Cav,
&gt;
&gt; I'm an Anomos developer so hopefully I can answer your questions :).
&gt; Anomos does not rely on the Tor network in any way. The blog does
&gt; suggest that clients could use Tor to make their announce requests, but
&gt; that functionality isn't built into Anomos directly.


It is important to note that the many torrent clients report their real IP
address to the tracker through the announcement of the torrent.  This is so
other torrent clients can send request to the client that issued the
announce to the tracker.  Anyone who has run an exit node and observed
torrent exit traffic.  Bottom line, it's not anonymous if the client reports
to the tracker correctly.


&gt; Even if users chose
&gt; to announce over Tor, it would amount, at most, to a few small HTTPS
&gt; requests per client per hour. The file transfers themselves are done
&gt; entirely peer-to-peer, with clients connected to the same tracker
&gt; serving as relays for each other. So, Anomos certainly wouldn't clobber
&gt; the Tor network, and ideally it would alleviate some of the load on Tor
&gt; by drawing BitTorrent users off of it.
&gt;
&gt; -John
&gt;

[Attachment #3 (text/html)]

&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Tue, Nov 9, 2010 at 11:21 AM, John M. Schanck \
&lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:jms07@hampshire.edu"&gt;jms07@hampshire.edu&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Tue, Nov 09, 2010 at 04:55:06PM \
+0000, Cav wrote:&lt;br&gt; &gt; Hi Or-Dev,&lt;br&gt;
&gt;&lt;br&gt;
&gt; I have stumbled across this torrent client. My first thoughts, upon&lt;br&gt;
&gt; seeing Onion Routing in the description, was wondering if this is&lt;br&gt;
&gt; using the Tor network.&lt;br&gt;
&gt; I have included a link and some details about this torrent client below.&lt;br&gt;
&gt;&lt;br&gt;
&gt; In which case, does this then mean its likely to clobber the Tor&lt;br&gt;
&gt; network with p2p traffic ? - this bodes ill for Tor servers ?&lt;br&gt;
&gt; Does anyone have any thoughts ?&lt;br&gt;
&lt;/div&gt;&gt; [snip]&lt;br&gt;
&lt;br&gt;
Hi Cav,&lt;br&gt;
&lt;br&gt;
I'm an Anomos developer so hopefully I can answer your questions :).&lt;br&gt;
Anomos does not rely on the Tor network in any way. The blog does&lt;br&gt;
suggest that clients could use Tor to make their announce requests, but&lt;br&gt;
that functionality isn't built into Anomos \
directly.&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It is important to note that the many \
torrent clients report their real IP address to the tracker through the announcement \
of the torrent.  This is so other torrent clients can send request to the client that \
issued the announce to the tracker.  Anyone who has run an exit node and observed \
torrent exit traffic.  Bottom line, it's not anonymous if the client reports to \
the tracker correctly.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; Even if users \
chose&lt;br&gt; to announce over Tor, it would amount, at most, to a few small HTTPS&lt;br&gt;
requests per client per hour. The file transfers themselves are done&lt;br&gt;
entirely peer-to-peer, with clients connected to the same tracker&lt;br&gt;
serving as relays for each other. So, Anomos certainly wouldn't clobber&lt;br&gt;
the Tor network, and ideally it would alleviate some of the load on Tor&lt;br&gt;
by drawing BitTorrent users off of it.&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;
-John&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20101110070325</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-11-10 07:03:25-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

"we have created a platform where by no party outside of the trusted
tracker will have any information about who a peer is or what they are
downloading"

There are many issues with this. Just an FYI re Anomos.

On 11/9/10, Kyle Williams &lt;kyle.kwilliams@gmail.com&gt; wrote:
&gt; On Tue, Nov 9, 2010 at 11:21 AM, John M. Schanck &lt;jms07@hampshire.edu&gt;wrote:
&gt;
&gt;&gt; On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
&gt;&gt; &gt; Hi Or-Dev,
&gt;&gt; &gt;
&gt;&gt; &gt; I have stumbled across this torrent client. My first thoughts, upon
&gt;&gt; &gt; seeing Onion Routing in the description, was wondering if this is
&gt;&gt; &gt; using the Tor network.
&gt;&gt; &gt; I have included a link and some details about this torrent client below.
&gt;&gt; &gt;
&gt;&gt; &gt; In which case, does this then mean its likely to clobber the Tor
&gt;&gt; &gt; network with p2p traffic ? - this bodes ill for Tor servers ?
&gt;&gt; &gt; Does anyone have any thoughts ?
&gt;&gt; &gt; [snip]
&gt;&gt;
&gt;&gt; Hi Cav,
&gt;&gt;
&gt;&gt; I'm an Anomos developer so hopefully I can answer your questions :).
&gt;&gt; Anomos does not rely on the Tor network in any way. The blog does
&gt;&gt; suggest that clients could use Tor to make their announce requests, but
&gt;&gt; that functionality isn't built into Anomos directly.
&gt;
&gt;
&gt; It is important to note that the many torrent clients report their real IP
&gt; address to the tracker through the announcement of the torrent.  This is so
&gt; other torrent clients can send request to the client that issued the
&gt; announce to the tracker.  Anyone who has run an exit node and observed
&gt; torrent exit traffic.  Bottom line, it's not anonymous if the client reports
&gt; to the tracker correctly.
&gt;
&gt;
&gt;&gt; Even if users chose
&gt;&gt; to announce over Tor, it would amount, at most, to a few small HTTPS
&gt;&gt; requests per client per hour. The file transfers themselves are done
&gt;&gt; entirely peer-to-peer, with clients connected to the same tracker
&gt;&gt; serving as relays for each other. So, Anomos certainly wouldn't clobber
&gt;&gt; the Tor network, and ideally it would alleviate some of the load on Tor
&gt;&gt; by drawing BitTorrent users off of it.
&gt;&gt;
&gt;&gt; -John
&gt;&gt;
&gt;
</body></email><email><emailId>20101110123326</emailId><senderName>"Anthony G. Basile"</senderName><senderEmail>basile@opensource.dyc.edu</senderEmail><timestampReceived>2010-11-10 12:33:26-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

On 11/10/2010 02:03 AM, grarpamp wrote:
&gt; "we have created a platform where by no party outside of the trusted
&gt; tracker will have any information about who a peer is or what they are
&gt; downloading"
&gt; 
&gt; There are many issues with this. Just an FYI re Anomos.
&gt; 
&gt; On 11/9/10, Kyle Williams &lt;kyle.kwilliams@gmail.com&gt; wrote:
&gt;&gt; On Tue, Nov 9, 2010 at 11:21 AM, John M. Schanck &lt;jms07@hampshire.edu&gt;wrote:
&gt;&gt;
&gt;&gt;&gt; On Tue, Nov 09, 2010 at 04:55:06PM +0000, Cav wrote:
&gt;&gt;&gt;&gt; Hi Or-Dev,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I have stumbled across this torrent client. My first thoughts, upon
&gt;&gt;&gt;&gt; seeing Onion Routing in the description, was wondering if this is
&gt;&gt;&gt;&gt; using the Tor network.
&gt;&gt;&gt;&gt; I have included a link and some details about this torrent client below.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; In which case, does this then mean its likely to clobber the Tor
&gt;&gt;&gt;&gt; network with p2p traffic ? - this bodes ill for Tor servers ?
&gt;&gt;&gt;&gt; Does anyone have any thoughts ?
&gt;&gt;&gt;&gt; [snip]
&gt;&gt;&gt;
&gt;&gt;&gt; Hi Cav,
&gt;&gt;&gt;
&gt;&gt;&gt; I'm an Anomos developer so hopefully I can answer your questions :).
&gt;&gt;&gt; Anomos does not rely on the Tor network in any way. The blog does
&gt;&gt;&gt; suggest that clients could use Tor to make their announce requests, but
&gt;&gt;&gt; that functionality isn't built into Anomos directly.
&gt;&gt;
&gt;&gt;
&gt;&gt; It is important to note that the many torrent clients report their real IP
&gt;&gt; address to the tracker through the announcement of the torrent.  This is so
&gt;&gt; other torrent clients can send request to the client that issued the
&gt;&gt; announce to the tracker.  Anyone who has run an exit node and observed
&gt;&gt; torrent exit traffic.  Bottom line, it's not anonymous if the client reports
&gt;&gt; to the tracker correctly.
&gt;&gt;
&gt;&gt;
&gt;&gt;&gt; Even if users chose
&gt;&gt;&gt; to announce over Tor, it would amount, at most, to a few small HTTPS
&gt;&gt;&gt; requests per client per hour. The file transfers themselves are done
&gt;&gt;&gt; entirely peer-to-peer, with clients connected to the same tracker
&gt;&gt;&gt; serving as relays for each other. So, Anomos certainly wouldn't clobber
&gt;&gt;&gt; the Tor network, and ideally it would alleviate some of the load on Tor
&gt;&gt;&gt; by drawing BitTorrent users off of it.
&gt;&gt;&gt;
&gt;&gt;&gt; -John
&gt;&gt;&gt;
&gt;&gt;

If the torrent client is on a box behind a NAT on a private IP address,
and it is firewalled in such a way that only tor traffic can exit the
box, there is no way the torrent client can possible obtain the external IP.

Nonetheless, there are other reasons why one should not use bittorrent
over tor, not the least of which is that it is a bandwidth hog.

-- 
Anthony G. Basile, Ph. D.
Chair of Information Technology
D'Youville College
Buffalo, NY 14201
(716) 829-8197
</body></email><email><emailId>20101113084125</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-11-13 08:41:25-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

&gt; Nonetheless, there are other reasons why one should not use bittorrent
&gt; over tor, not the least of which is that it is a bandwidth hog.

Why do we keep saying don't use it? That's almost an invitation
to break the rules. Look at the lists of services out there. Bandwidth
usage is always going up.

So why not instead say, sure, use Tor for whatever you want PROVIDED
you also help maintain equilibrium by donating some resources. Which
in the case of Tor would be at least six times your own bandwidth use.

A steep price for sure. But an accurate minumum to maintain state.

What parts of Tor aren't able to scale to more users?
</body></email><email><emailId>20101114210327</emailId><senderName>Ted Smith</senderName><senderEmail>teddks@gmail.com</senderEmail><timestampReceived>2010-11-14 21:03:27-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

On Sat, 2010-11-13 at 03:41 -0500, grarpamp wrote:
&gt; &gt; Nonetheless, there are other reasons why one should not use bittorrent
&gt; &gt; over tor, not the least of which is that it is a bandwidth hog.
&gt; 
&gt; Why do we keep saying don't use it? That's almost an invitation
&gt; to break the rules. Look at the lists of services out there. Bandwidth
&gt; usage is always going up.
&gt; 
&gt; So why not instead say, sure, use Tor for whatever you want PROVIDED
&gt; you also help maintain equilibrium by donating some resources. Which
&gt; in the case of Tor would be at least six times your own bandwidth use.
&gt; 
&gt; A steep price for sure. But an accurate minumum to maintain state.
&gt; 
&gt; What parts of Tor aren't able to scale to more users?

It's my understanding that BitTorrent is less of a bandwidth hog as it
is a connections/circuits hog. These are expensive to create and you
can't balance your BitTorrenting by hosting a high-bandwidth node
because to have 0 net effect on the network, you'd have to host a
circuit's worth of nodes for every circuit you're using for BitTorrent
connections.

Am I wrong, Tor Old Ones?

</body></email><email><emailId>20101219190257</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-12-19 19:02:57-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

&gt; I mainly see the problem when scrolling through the connection results:

Ahhh, gotcha. The problem here isn't really the connection resolution
then, but rather the sucky panel implementation. The old code had a
habit of doing lengthy operations in the draw loop rather than using
cached results, so most likely the high cpu usage is from sort
operations being triggered each time it scrolls. Making the
sortConnections function (line 835) a no-op (just return right away)
might address this.

That said, here's a couple of observations about the arm cpu field:
- Scrolling through the connections is the worst, but the newer panels
exhibit cpu spikes too. On my system scrolling the log goes to 7% and
scrolling the config listing goes to around 35%. I'll look into this
some, but I'm suspecting that it may be unavoidable since moving the
cursor requires a panel refresh so scrolling a dozen times a second is
always gonna require a dozen refreshes. The only thing to rate limit
scrolling is the redraw, so holding down the scroll key in essence
creates an open loop where arm is scrolling and redrawing as fast as
it can (maybe I should try to coalesce those events...).

In essence this means that the performance improvements that I've been
making in those panels makes it so users can scroll faster, but
doesn't really improve the cpu usage when users hold the arrow keys
down. Not quite what I'd intended. :P

- I'm using the os.times() function to get the arm cpu usage which is
*supposed* to include child processes. However, it doesn't seem to be
including the ps and netstat lookups since disabling them or making
them occur more frequently doesn't have an effect on this value. Pity,
that was the main point in including this stat...

Per chance do you have any ideas for how to include the system calls
in this figure?

&gt; I get the impression that the back-off mechanism doesn't apply in
&gt; that situation?

Backoff only applies if the connection results are taking too long.
The netstat runtime was 0.0587 seconds so backoff was probably being
triggered a little bit, but wouldn't help with the cpu usage being
wasted on the sorting.

&gt; Another problem I noticed that may or may not be connection related
&gt; is that arm occasionally stops working and neither updates the screen
&gt; nor reacts to keyboard input.

Uggg, that's annoying. The low cpu usage means that it's probably not
falling into any sort of busy wait situation. How frequently does it
occur? Does it always happen when on a particular part of the
interface? Does this arise when interacting with arm, or does it occur
on its own (ie, not in response to user input)? A repro case would be
very helpful...

For debugging you can run arm at its debug runlevel (arm -e 1) with
the "features.logFile" set to collect arm's events and see if it's
continuing to do anything while it seems frozen. Also, to double check
that ssh isn't the issue you could run arm in a detached screen
session, then reattach with another ssh connection when it seems
frozen to see if they get the same results.

&gt; Arm Test Options: ...

Great! Did you run the test multiple times? It might have been biased
due to cached results (favoring netstat since it had been running in
arm). However, besides lsof outperforming sockstat that was more or
less what I'd expected. Thanks!

I should have the testing utility fetch twice to account for this...

&gt; If the output of the resolver utility is (partly) localized
&gt; the grep for "ESTABLISHED" no longer matches.

Ack! Would you suggest modifying LANG, letting it fall back to another
resolver, or something else? The resolver fallback in this case isn't
ideal since (a) netstat tends to outperform the others and (b) since
the netstat command is available but failing it'll make three attempts
before going to the fallback (so fifteen seconds before the
resolutions appear).

If you have an idea for how to modify the LANG env variable safely
(ie, without unintended consequences on other platforms nor leaving
the user's terminal in a bad state, even when arm crashes) then I'd be
happy to apply a patch. I don't trust that I have a deep enough
understanding of this to do the above properly. :(

That said, if this is a Linux-only issue then it might be moot if the
connection resolution via /proc contents works.

&gt; It works, thanks.

Hazaa!

&gt; Hmm, I thought the confusing controller case should be handled
&gt; with the ipAddressIsPrivate() patch

Oops. You're right, that shouldn't be happening. That was probably due
to something I did while messing with the patch.

Out of curiosity, what is going to be involved with the bsd port? When
arm makes a new release what is the process for getting the port
upgraded? Emailing you? Filing a ticket?

Also, if this is going to require a permanent tarball link (like
Gentoo) then please let me know and I'll add it to the site.

Cheers! -Damian
</body></email><email><emailId>20101220113511</emailId><senderName>Hans Schnehl</senderName><senderEmail>torvallenator@gmail.com</senderEmail><timestampReceived>2010-12-20 11:35:11-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

Hi,

lsof may spit out a lot of (un)predictable warnings, unwanted and not
relevant to arm.  
Adding the -w option (no warnings) stops that.
Patch attached.


&gt; From 7e2ca00f19505859ec02fbfbff9f4edfb14bd00d Mon Sep 17 00:00:00 2001
&gt; From: Fabian Keil &lt;fk@fabiankeil.de&gt;
&gt; Date: Sat, 18 Dec 2010 14:45:09 +0100
&gt; Subject: [PATCH 6/8] Replace the '\s' in RUN_LSOF with ' ' to get it working.
&gt; 
&gt; ---
&gt;  src/util/connections.py |    2 +-
&gt;  1 files changed, 1 insertions(+), 1 deletions(-)
&gt; 
&gt; diff --git a/src/util/connections.py b/src/util/connections.py
&gt; index abec3f6..d154288 100644
&gt; --- a/src/util/connections.py
&gt; +++ b/src/util/connections.py
&gt; @@ -60,7 +60,7 @@ RUN_SS = "ss -nptu | grep \"ESTAB.*\\\"%s\\\",%s\""
&gt;  # oddly, using the -p flag via:
&gt;  # lsof      lsof -nPi -p &lt;pid&gt; | grep "^&lt;process&gt;.*(ESTABLISHED)"
&gt;  # is much slower (11-28% in tests I ran)
&gt; -RUN_LSOF = "lsof -nPi | egrep \"^%s\\s*%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
&gt; +RUN_LSOF = "lsof -nPi | egrep \"^%s *%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
&gt;  
&gt;  # output:
&gt;  # atagar  tor  3475  tcp4  127.0.0.1:9051  127.0.0.1:38942  ESTABLISHED
&gt; -- 
&gt; 1.7.3.3
&gt; 

["lsof_add_option_w.patch" (text/x-diff)]

Index: trunk/src/util/connections.py
===================================================================
--- trunk/src/util/connections.py	(revision 23956)
+++ trunk/src/util/connections.py	(working copy)
@@ -60,7 +60,7 @@
 # oddly, using the -p flag via:
 # lsof      lsof -nPi -p &lt;pid&gt; | grep "^&lt;process&gt;.*(ESTABLISHED)"
 # is much slower (11-28% in tests I ran)
-RUN_LSOF = "lsof -nPi | egrep \"^%s *%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
+RUN_LSOF = "lsof -wnPi | egrep \"^%s *%s.*((UDP.*)|(\\(ESTABLISHED\\)))\""
 
 # output:
 # atagar  tor  3475  tcp4  127.0.0.1:9051  127.0.0.1:38942  ESTABLISHED


</body></email><email><emailId>20101223063826</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-12-23 06:38:26-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

&gt; For Linux I'm about to borrow a trick from psutil and read the
&gt; /proc contents instead of performing ps and netstat lookups. Hopefully
&gt; this will help.

Hi Febian. Great news, querying the proc contents works insanely well
(about 90% better):

proc          0.0031 seconds
netstat       0.0328 seconds
sockstat      0.0282 seconds
lsof          0.0537 seconds
ss            0.1127 seconds

I've also added (and tested) utilities that can be used as
replacements for ps queries, though arm isn't configured to use them
just yet. Tarballs with this improvement are available at:

http://www.atagar.com/transfer/tmp/arm_bsdTest5.tar.bz2
http://www.atagar.com/transfer/tmp/arm_bsdTest5.tar.bz2.asc

The only bad news is that this is a highly system dependent
enhancement, so this only works on Linux. Porting this to bsd or osx
would be difficult, if it's possible at all. Here's the util that's
providing the lookups:
https://svn.torproject.org/svn/arm/trunk/src/util/procTools.py

Cheers! -Damian

PS. I'm gonna need to send a thank-you note to the psutil developers.
Viva la foss libraries!
</body></email><email><emailId>20101223085715</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-12-23 08:57:15-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>

On Wed, Dec 22, 2010 at 10:38 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; ... querying the proc contents works insanely well
&gt; (about 90% better):
&gt; ...
&gt; The only bad news is that this is a highly system dependent
&gt; enhancement, so this only works on Linux. Porting this to bsd or osx
&gt; would be difficult, if it's possible at all.

not sure about the Python bindings off hand; general approach for
other systems if /proc (not just /proc/stat) insufficient consists of
one or more:

direct kernel data structure interpretation - also fast, but also very
arch. specific. you could perhaps use lsof or top or other interface
to cross-platform vars of this sort where /dev/kmem or /dev/mem is
present.

kernel audit or profiling facilities like performance counters,
kprobes, security hooks, other common facilities.

this will cover all common platforms but is more time consuming and
maintenance intensive than would be ideal...

good luck,
</body></email><email><emailId>20101224152400</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2010-12-24 15:24:00-0400</timestampReceived><subject>Re: Arm Release 1.4.0</subject><body>


Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; - I'm using the os.times() function to get the arm cpu usage which is
&gt; *supposed* to include child processes. However, it doesn't seem to be
&gt; including the ps and netstat lookups since disabling them or making
&gt; them occur more frequently doesn't have an effect on this value. Pity,
&gt; that was the main point in including this stat...
&gt; 
&gt; Per chance do you have any ideas for how to include the system calls
&gt; in this figure?

Nope, but I'm also under the impression that they don't
really matter and that the load is mainly caused by the
algorithms used in arm itself.

&gt; &gt; I get the impression that the back-off mechanism doesn't apply in
&gt; &gt; that situation?
&gt; 
&gt; Backoff only applies if the connection results are taking too long.
&gt; The netstat runtime was 0.0587 seconds so backoff was probably being
&gt; triggered a little bit, but wouldn't help with the cpu usage being
&gt; wasted on the sorting.

Right.
 
&gt; &gt; Another problem I noticed that may or may not be connection related
&gt; &gt; is that arm occasionally stops working and neither updates the screen
&gt; &gt; nor reacts to keyboard input.
&gt; 
&gt; Uggg, that's annoying. The low cpu usage means that it's probably not
&gt; falling into any sort of busy wait situation. How frequently does it
&gt; occur? Does it always happen when on a particular part of the
&gt; interface? Does this arise when interacting with arm, or does it occur
&gt; on its own (ie, not in response to user input)? A repro case would be
&gt; very helpful...

So far it happened maybe four or five times on both FreeBSD and
Debian GNU/Linux combined, always when not interacting with arm.
I haven't found a way to reproduce it, yet.

&gt; For debugging you can run arm at its debug runlevel (arm -e 1) with
&gt; the "features.logFile" set to collect arm's events and see if it's
&gt; continuing to do anything while it seems frozen.

Ok, I'm already running with "-e 1" anyway.

&gt;                                                  Also, to double check
&gt; that ssh isn't the issue you could run arm in a detached screen
&gt; session, then reattach with another ssh connection when it seems
&gt; frozen to see if they get the same results.

Good idea. I'm not using ssh when running arm on FreeBSD,
though, so I expect that this isn't it.

&gt; &gt; Arm Test Options: ...
&gt; 
&gt; Great! Did you run the test multiple times? It might have been biased
&gt; due to cached results (favoring netstat since it had been running in
&gt; arm). However, besides lsof outperforming sockstat that was more or
&gt; less what I'd expected. Thanks!
&gt; 
&gt; I should have the testing utility fetch twice to account for this...

I ran the test multiple times and the results looked comparable
to me, but I didn't confirm it with ministat.
 
&gt; &gt; If the output of the resolver utility is (partly) localized
&gt; &gt; the grep for "ESTABLISHED" no longer matches.
&gt; 
&gt; Ack! Would you suggest modifying LANG, letting it fall back to another
&gt; resolver, or something else? The resolver fallback in this case isn't
&gt; ideal since (a) netstat tends to outperform the others and (b) since
&gt; the netstat command is available but failing it'll make three attempts
&gt; before going to the fallback (so fifteen seconds before the
&gt; resolutions appear).
&gt; 
&gt; If you have an idea for how to modify the LANG env variable safely
&gt; (ie, without unintended consequences on other platforms nor leaving
&gt; the user's terminal in a bad state, even when arm crashes) then I'd be
&gt; happy to apply a patch. I don't trust that I have a deep enough
&gt; understanding of this to do the above properly. :(

I would expect messing with LANG or other localization-related
variables in the arm shell script or in arm itself to be without
consequences for the user's terminal once arm is stopped.

&gt; That said, if this is a Linux-only issue then it might be moot if the
&gt; connection resolution via /proc contents works.

I don't actually think the problem is limited to GNU/Linux.

I run FreeBSD without localization support compiled-in, otherwise I'd
probably could get the same problem there (assuming the utilities in
question actually support localization).

&gt; &gt; Hmm, I thought the confusing controller case should be handled
&gt; &gt; with the ipAddressIsPrivate() patch
&gt; 
&gt; Oops. You're right, that shouldn't be happening. That was probably due
&gt; to something I did while messing with the patch.
&gt; 
&gt; Out of curiosity, what is going to be involved with the bsd port? When
&gt; arm makes a new release what is the process for getting the port
&gt; upgraded? Emailing you? Filing a ticket?

Announcing it in a place I now about should do.

For example I usually update the Vidalia port after a new
release has been mentioned on tor-cvs@ and the source tarball
is actually fetchable.

&gt; Also, if this is going to require a permanent tarball link (like
&gt; Gentoo) then please let me know and I'll add it to the site.

Stable download URLs would indeed be useful.

Fabian

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101214223558</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-12-14 22:35:58-0400</timestampReceived><subject>Re: Proposal 171 (revised): Separate streams across circuits by connection metadata</subject><body>

A lot to digest!


On Tuesday 07 December 2010 16:02:05 you wrote:
&gt; 
&gt;   Generally, all the streams on a session come from a single
&gt;   application.  Unfortunately, isolating streams by application
&gt;   automatically isn't feasible, given the lack of any nice
&gt;   cross-platform way to tell which local process originated a given
&gt;   connection.  (Yes, lsof works.  But a quick review of the lsof code
&gt;   should be sufficient to scare you away from thinking there is a
&gt;   portable option, much less a portable O(1) option.)  So instead, we'll
&gt;   have to use some other aspect of a Tor request as a proxy for the
&gt;   application.

It's hard to credit there isn't a good interface for this. The closest 
Linux gets is taskstats - see http://linux.derkeiler.com/Mailing-
Lists/Kernel/2010-06/msg01125.html, but the requirement here (which is 
shared by programs like wireshark and nearly every network management 
application) is to match inode to pid reliably. 

Interestingly, Unix sockets allow you to collect the gid and uid of the 
process on the other side of the socket. Not the pid unfortunately.

&gt; 
&gt; Design:
&gt; 
&gt;   When a stream arrives at Tor, we have the following data to examine:
&gt;     1) The destination address
&gt;     2) The destination port (unless this a DNS lookup)
&gt;     3) The protocol used by the application to send the stream to Tor:
&gt;        SOCKS4, SOCKS4A, SOCKS5, or whatever local "transparent proxy"
&gt;        mechanism the kernel gives us.
&gt;     4) The port used by the application to send the stream to Tor --
&gt;        that is, the SOCKSListenAddress or TransListenAddress that the
&gt;        application used, if we have more than one.
&gt;     5) The SOCKS username and password, if any.
&gt;     6) The source address and port for the application.
&gt; 

Why not the source address too? Robert Ransom made the point in a previous 
thread that Tor could be serving a local network.

&gt; The "IsolateSOCKSUser" and "IsolateClientAddr" options are on by
&gt;  default; "NoIsolateSOCKSUser" and "NoIsolateClientAddr" respectively
&gt;  turn them off.  The IsolateDestPort and IsolateDestAddr and
&gt;  IsolateClientProtocol options are off by default.  NoIsolateDestPort and
&gt;  NoIsolateDestAddr and NoIsolateClientProtocol have no effect.

Why is IsolateClientProtocol off by default? Seems like a cheap, 
opportunistic way of distinguishing client applications.

&gt; 
&gt;   Handling DNS can be a challenge.  We can get hostnames by one of three
&gt;   means:
&gt; 
&gt;     A) A SOCKS4a request, or a SOCKS5 request with a hostname.  This
&gt;        case is handled trivially using the rules above.
&gt;     B) A RESOLVE request on a SOCKSPort.  This case is handled using the
&gt;        rules above, except that port isolation can't work to isolate
&gt;        RESOLVE requests into a proper session, since we don't know which
&gt;        port will eventually be used when we connect to the returned
&gt;        address.
&gt;     C) A request on a DNSPort.  We have no way of knowing which
&gt;        address/port will be used to connect to the requested address.
&gt; 
&gt;   When B or C is required but problematic, we could favor the use of
&gt;   AutomapHostsOnResolve.
&gt; 

I'm not clear when it will be problematic. Can you clarify?

</body></email><email><emailId>20101214232320</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2010-12-14 23:23:20-0400</timestampReceived><subject>Re: Proposal 171 (revised): Separate streams across circuits by connection</subject><body>

On 12/14/2010 02:35 PM, Robert Hogan wrote:

&gt; Interestingly, Unix sockets allow you to collect the gid and uid of the 
&gt; process on the other side of the socket. Not the pid unfortunately.

Not so: my FreeBSD sys/socket.h has:

/*
 * Credentials structure, used to verify the identity of a peer
 * process that has sent us a message. This is allocated by the
 * peer process but filled in by the kernel. This prevents the
 * peer from lying about its identity. (Note that cmcred_groups[0]
 * is the effective GID.)
 */
struct cmsgcred {
        pid_t   cmcred_pid;             /* PID of sending process */
        uid_t   cmcred_uid;             /* real UID of sending process */
        uid_t   cmcred_euid;            /* effective UID of sending
process */
        gid_t   cmcred_gid;             /* real GID of sending process */
        short   cmcred_ngroups;         /* number or groups */
        gid_t   cmcred_groups[CMGROUP_MAX];     /* groups */
};

Linux has:

#ifdef __USE_GNU
/* User visible structure for SCM_CREDENTIALS message */
struct ucred
{
  pid_t pid;                  /* PID of sending process.  */
  uid_t uid;                  /* UID of sending process.  */
  gid_t gid;                  /* GID of sending process.  */
};
#endif

It'd be nice to have a portability layer around this stuff, of course.
Note also that Android's Binder system supports this too, with an API
you might like better.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation
</body></email><email><emailId>20101215045515</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-12-15 04:55:15-0400</timestampReceived><subject>Re: Proposal 171 (revised): Separate streams across circuits by</subject><body>

On Tue, Dec 14, 2010 at 5:35 PM, Robert Hogan &lt;robert@roberthogan.net&gt; wrote:
&gt; A lot to digest!
&gt;
&gt;
&gt; On Tuesday 07 December 2010 16:02:05 you wrote:
&gt;&gt;
&gt;&gt;   Generally, all the streams on a session come from a single
&gt;&gt;   application.  Unfortunately, isolating streams by application
&gt;&gt;   automatically isn't feasible, given the lack of any nice
&gt;&gt;   cross-platform way to tell which local process originated a given
&gt;&gt;   connection.  (Yes, lsof works.  But a quick review of the lsof code
&gt;&gt;   should be sufficient to scare you away from thinking there is a
&gt;&gt;   portable option, much less a portable O(1) option.)  So instead, we'll
&gt;&gt;   have to use some other aspect of a Tor request as a proxy for the
&gt;&gt;   application.
&gt;
&gt; It's hard to credit there isn't a good interface for this. The closest
&gt; Linux gets is taskstats - see http://linux.derkeiler.com/Mailing-
&gt; Lists/Kernel/2010-06/msg01125.html, but the requirement here (which is
&gt; shared by programs like wireshark and nearly every network management
&gt; application) is to match inode to pid reliably.
&gt;
&gt; Interestingly, Unix sockets allow you to collect the gid and uid of the
&gt; process on the other side of the socket. Not the pid unfortunately.

Yeah.  If there's a good interface here, I would love to see it, but
afaict there isn't one. I spent a while grepping through the kernel
source and didn't see an easy way to get this stuff.  If somebody can
point to some working code, that would be neat.

&gt;&gt; Design:
&gt;&gt;
&gt;&gt;   When a stream arrives at Tor, we have the following data to examine:
&gt;&gt;     1) The destination address
&gt;&gt;     2) The destination port (unless this a DNS lookup)
&gt;&gt;     3) The protocol used by the application to send the stream to Tor:
&gt;&gt;        SOCKS4, SOCKS4A, SOCKS5, or whatever local "transparent proxy"
&gt;&gt;        mechanism the kernel gives us.
&gt;&gt;     4) The port used by the application to send the stream to Tor --
&gt;&gt;        that is, the SOCKSListenAddress or TransListenAddress that the
&gt;&gt;        application used, if we have more than one.
&gt;&gt;     5) The SOCKS username and password, if any.
&gt;&gt;     6) The source address and port for the application.
&gt;&gt;
&gt;
&gt; Why not the source address too? Robert Ransom made the point in a previous
&gt; thread that Tor could be serving a local network.

I don't understand the question.  My option 6 above includes the
source address; that's what the option "IsolateClientAddr" is meant to
do.

Oh!  Was it confusing when I wrote, "We propose to use options 3, 4,
and 5 as a backchannel for the application to tell Tor about different
sessions"?  I didn't mean that Tor should not look at 1, 2, and 6:
what I mean is that 3..5 are more or less arbitrary choices under the
application's control, whereas 1, 2,and 6 are generally not something
that the application gets to pick.  So I considered 3,4,5 to be a
"backchannel" and 1,2,6 to be the actual routing information.

IOW, I agree that isolating by client address is valuable.  In fact, I
think it's crucial.  That's why the Security Risks section says
"Disabling IsolateClientAddr is a pretty bad idea".

&gt;&gt; The "IsolateSOCKSUser" and "IsolateClientAddr" options are on by
&gt;&gt;  default; "NoIsolateSOCKSUser" and "NoIsolateClientAddr" respectively
&gt;&gt;  turn them off.  The IsolateDestPort and IsolateDestAddr and
&gt;&gt;  IsolateClientProtocol options are off by default.  NoIsolateDestPort and
&gt;&gt;  NoIsolateDestAddr and NoIsolateClientProtocol have no effect.
&gt;
&gt; Why is IsolateClientProtocol off by default? Seems like a cheap,
&gt; opportunistic way of distinguishing client applications.

No objection there.

&gt;&gt;   Handling DNS can be a challenge.  We can get hostnames by one of three
&gt;&gt;   means:
&gt;&gt;
&gt;&gt;     A) A SOCKS4a request, or a SOCKS5 request with a hostname.  This
&gt;&gt;        case is handled trivially using the rules above.
&gt;&gt;     B) A RESOLVE request on a SOCKSPort.  This case is handled using the
&gt;&gt;        rules above, except that port isolation can't work to isolate
&gt;&gt;        RESOLVE requests into a proper session, since we don't know which
&gt;&gt;        port will eventually be used when we connect to the returned
&gt;&gt;        address.
&gt;&gt;     C) A request on a DNSPort.  We have no way of knowing which
&gt;&gt;        address/port will be used to connect to the requested address.
&gt;&gt;
&gt;&gt;   When B or C is required but problematic, we could favor the use of
&gt;&gt;   AutomapHostsOnResolve.
&gt;&gt;
&gt;
&gt; I'm not clear when it will be problematic. Can you clarify?

Well, suppose that we're configured to isolate requests by destination
port.  When you get a new request to resolve (say) example.com via a
DNSPort request or via a SOCKS resolve request, what circuit should
you put it on?  To make this concrete, suppose that IsolateDestPort is
set, and that the user makes DNS requests for www.example.com and
gopher.example.com, then connects to the IP for www.example.com on
port 80 and to the IP for gopher.example.com on port 70.

We *could* call both of these DNS requests "port 53"; if you did this,
then the exit node for the port-53 circuit will get a complete list of
all the hosts you were connecting to, which would partially defeat the
purpose of session isolation.  Instead, we'd want to have the DNS
request go out on the circuit that will eventually connect to the
resolved address -- we'd like to have the www.example.com DNS request
made on the port-80 circuit, and the gopher.example.com  DNS request
made on the port-70 circuit.  Doing it like this would confine the
information about our DNS requests to the circuits handling the
applications that use them.

But of course the problem is that when we see only a RESOLVE request
or a DNS request, we do not actually know what port or ports will
actually be used when we connect to the resulting address.  Hence my
suggestion to use AutomapHostsOnResolve with IsolateHostsByPort: it
postpones the real lookup until we're actually connecting to the
target host, and we know what port it's using.

(Not sure if that makes sense; if not, just say so: I am pretty sleepy atm)

-- 
Nick

</body></email><email><emailId>20101215045930</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-12-15 04:59:30-0400</timestampReceived><subject>Re: Proposal 171 (revised): Separate streams across circuits by</subject><body>

On Tue, Dec 14, 2010 at 6:23 PM, Chris Palmer &lt;chris@eff.org&gt; wrote:
&gt; On 12/14/2010 02:35 PM, Robert Hogan wrote:
&gt;
&gt;&gt; Interestingly, Unix sockets allow you to collect the gid and uid of the
&gt;&gt; process on the other side of the socket. Not the pid unfortunately.
&gt;
&gt; Not so: my FreeBSD sys/socket.h has:

I thought these interfaces were only for passing credentials over unix
sockets. What's the API to get a copy of one of these structures given
only a socket without the other guy passing you a credential?

(Either way, it's a bit academic if it only works on unix sockets; I'm
not aware of any applications that support socks over non-TCP sockets)

yrs,
-- 
Nick
</body></email><email><emailId>20101101195257</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-01 19:52:57-0400</timestampReceived><subject>Re: Bug in parsing Address line in torrc</subject><body>

On Mon, Nov 1, 2010 at 3:27 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; Nick et al.,
&gt;
&gt; Mashael and I uncovered a little bug in the torrc parsing code in
&gt; src/or/config.c.  If Address is set to a dotted quad, tor_inet_aton
&gt; returns 1, and stores the address in in.s_addr, but that field is then
&gt; never copied out to the addr variable.  Here's a patch.

Applied; thanks!

</body></email><email><emailId>20101102131918</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-02 13:19:18-0400</timestampReceived><subject>Re: Tor on 64bit Windows (XP)</subject><body>

Many many thanks Robert !




Robert Ransom wrote:
&gt; On Tue, 02 Nov 2010 12:58:59 +0000
&gt; Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt;
&gt;   
&gt;&gt; When you say 64bit Windows, are you including XP 64bit ?
&gt;&gt;     
&gt;
&gt; I have never used 64-bit Windows XP, but as I understand it, 32-bit
&gt; programs can run on 64-bit Windows XP, and Tor is a particularly
&gt; well-behaved 32-bit program.
&gt;
&gt;
&gt; Robert Ransom
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Many many thanks Robert !&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Robert Ransom wrote:
&lt;blockquote cite="mid:20101102061633.3b504c67@gmail.com" type="cite"&gt;
  &lt;pre wrap=""&gt;On Tue, 02 Nov 2010 12:58:59 +0000
Cav &lt;a class="moz-txt-link-rfc2396E" href="mailto:cav@gotadsl.co.uk"&gt;&lt;cav@gotadsl.co.uk&gt;&lt;/a&gt; wrote:

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;When you say 64bit Windows, are you including XP 64bit ?
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
I have never used 64-bit Windows XP, but as I understand it, 32-bit
programs can run on 64-bit Windows XP, and Tor is a particularly
well-behaved 32-bit program.


Robert Ransom
  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20101105002911</emailId><senderName>"Anthony G. Basile"</senderName><senderEmail>basile@opensource.dyc.edu</senderEmail><timestampReceived>2010-11-05 00:29:11-0400</timestampReceived><subject>tor-ramdisk on git</subject><body>

Hi everyone,

I've had lots of requests to add ssh support to tor-ramdisk [1] because
ftp is insecure.  I originally used dropbear, but after discussion with
Jacob, I switched to openssh.

I'm not providing images yet, but I've got the build scripts up on a git
repo [2].  They're meant to be run on a x86 uclibc system, but might
build on glibc and/or x86_64.  When I produce the images for
distribution, they are built with hardened gentoo, both toolchain and
kernel [3].  This give userland pie, ssp, _FORTIFY_SOURCE=2 and the
kernel GRSEC/PaX.

Feel free to grab the stuff and contribute.  I'll throw a GPL-2 in there.


Refs.

[1] http://opensource.dyc.edu/tor-ramdisk
[2] git://opensource.dyc.edu/tor-ramdisk
[3] http://www.gentoo.org/proj/en/hardened/

-- 
Anthony G. Basile, Ph. D.
Chair of Information Technology
D'Youville College
Buffalo, NY 14201
(716) 829-8197
</body></email><email><emailId>20101107001640</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-07 00:16:40-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master] user-contributed rule for</subject><body>


On Sat,  6 Nov 2010 23:54:59 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Sat, 6 Nov 2010 16:54:33 -0700
&gt; Subject: user-contributed rule for Springpadit.com
&gt; Commit: f7b5d70c4630c4af505d03c9f9cadefe18dee253
&gt; 
&gt; ---
&gt;  pending-rules/Springpad.xml |    6 ++++++
&gt;  1 files changed, 6 insertions(+), 0 deletions(-)
&gt;  create mode 100644 pending-rules/Springpad.xml
&gt; 
&gt; diff --git a/pending-rules/Springpad.xml b/pending-rules/Springpad.xml
&gt; new file mode 100644
&gt; index 0000000..33da7b9
&gt; --- /dev/null
&gt; +++ b/pending-rules/Springpad.xml
&gt; @@ -0,0 +1,6 @@
&gt; +&lt;ruleset name="Springpad"&gt;
&gt; +  &lt;target host="springpad.com" /&gt;
&gt; +  &lt;target host="www.springpad.com" /&gt;

The ‘target' elements do not match the ‘rule' element:

&gt; +  &lt;rule from="^http://(www\.)?springpadit\.com/" to="https://springpadit.com/"/&gt;
&gt; +&lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101108222115</emailId><senderName>Hans Schnehl</senderName><senderEmail>torvallenator@gmail.com</senderEmail><timestampReceived>2010-11-08 22:21:15-0400</timestampReceived><subject>Re: Recommended combinations tor/ssl/libevent</subject><body>

On Mon, Nov 08, 2010 at 04:21:39PM -0500, Nick Mathewson wrote:
&gt; On Mon, Nov 8, 2010 at 10:15 AM, Hans Schnehl &lt;torvallenator@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; Hi all,
&gt; &gt;
&gt; &gt; see exempt from coredump of a v0.2.2.12-alpha-dev, which was happily
&gt; &gt; running until 5 days ago.
&gt; &gt; Which versions of libevent, openssh , tor itself are known to be co-working
&gt; &gt; nicely nowadays ?
&gt; 
&gt; I'd guess that your problem there is the Tor version: The latest
&gt; 0.2.2.x alpha code, or the latest maint-0.2.2 git head, should be much
&gt; better than anything from back in April.  If you're going to use alpha
&gt; releases, you should probably try to keep up-to-date: knowing that
&gt; there was a bug in 0.2.2.12-alpha at this point doesn't really help us
&gt; much unless we know whether it is also a bug in the latest 0.2.2.x.
&gt; This goes doubly for "-dev" versions (versions based on the state of
&gt; the Git repository between releases): if you want to checkpoint the
&gt; state of Tor development then ignore it for half a year, I'd strondly
&gt; suggest checkpointing at an actually released version that works for
&gt; you.

In this case that particular version was running exceptionally
well since April. Emphasizing 'was'. 

&gt; 
&gt; For Libevent, I personally recommend the latest 2.0.x, or at least
&gt; 1.4.12-stable or later.  1.3e should work in a pinch too, if you
&gt; really must.
&gt;
&gt; Tor doesn't use openssh; it uses openssl.  Most vendor versions should
&gt; work assuming they claim to be 0.9.7x or later.  If you can't use your
&gt; vendor's shipped version, I personally recommend the latest 0.9.8x
&gt; release or the latest 1.0.0x release.
&gt;
maybe shifting openssh to openssl will have magnificent effects 
in my case;)

&gt; (These are my recommended versions, not an exhaustive list of
&gt; known-to-work versions.  To the best of my knowledge, nobody has
&gt; compiled such a list.)
&gt;

Thanks for the recommendations.

Hans


</body></email><email><emailId>20101110190307</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-11-10 19:03:07-0400</timestampReceived><subject>Seeking Slightly Paranoid Android Developers for Hire and Internships</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


(Full post is here:
https://guardianproject.info/2010/11/10/seeking-slightly-paranoid-android-developers-for-hire-and-internships/)


The Guardian Project is kicking off a three month project focused on
finishing up our secure chat app, codenamed Gibber but also known as
?OtRChat?. We are looking for developers of all levels to join us in
this work. We have already implemented the primary  ?Off the Record?
messaging functionality, and achieved interoperability with desktop
clients such as Pidgin and AdiumX. From here, there is work to be done
on implementing some unique features, cleaning up the user experience,
and ensuring that the implementation is as secure as possible, providing
all the necessary features for verifying and managing secure identities
and sessions.

We have a few contract positions available, but are also looking for
interns and students interested in getting real-world production
development under their belt. All in all, you should be keenly
interested in work that strives to find the right balance of usability
and security on mobile devices.

If you are interested, please get in touch with us, and we will go from
there. We are looking for individuals or small teams. For the paid
positions, we would expect you have at least one Android app released in
public on the Android Market, and would prefer you have experience with
open-source projects, as well. There is much more work to do beyond this
specific app, but this is a good place to start. Work can be done
anywhere, anytime, assuming your are familiar with the tools and culture
of open-source+agile development.

Contact us securely here: https://guardianproject.info/contact/
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkza7GsACgkQhemw+yiNNc4dwgCgnoBFnP/BY6MZ1gng0DKe4HiK
omwAnjvlpZDQ1Cd0c6zC73uOZmn3/yOp
=9hDx
-----END PGP SIGNATURE-----


</body></email><email><emailId>20101111025840</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-11 02:58:40-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master] Experimentally securecookie</subject><body>


On Thu, 11 Nov 2010 01:28:25 +0000 (UTC)
pde@torproject.org wrote:

&gt; Author: Peter Eckersley &lt;pde@eff.org&gt;
&gt; Date: Wed, 10 Nov 2010 17:26:35 -0800
&gt; Subject: Experimentally securecookie Bit.ly; fix Facebook
&gt; Commit: a7436a55fc2818ebe6ac096a8ee4d0ca7157468f
&gt; 
&gt; ---
&gt;  src/chrome/content/code/HTTPS.js      |    2 +-
&gt;  src/chrome/content/rules/Bitly.xml    |    5 +++++
&gt;  src/chrome/content/rules/Facebook.xml |    8 ++++----
&gt;  3 files changed, 10 insertions(+), 5 deletions(-)
&gt; 
&gt; diff --git a/src/chrome/content/code/HTTPS.js b/src/chrome/content/code/HTTPS.js
&gt; index 3ac96f5..a8d4bb9 100644
&gt; --- a/src/chrome/content/code/HTTPS.js
&gt; +++ b/src/chrome/content/code/HTTPS.js
&gt; @@ -163,7 +163,7 @@ const HTTPS = {
&gt;        try {
&gt;          var cookies = req.getResponseHeader("Set-Cookie");
&gt;        } catch(mayHappen) {
&gt; -        this.log(DBUG,"Exception huntting Set-Cookie in headers: " + mayHappen);
&gt; +        this.log(VERB,"Exception huntting Set-Cookie in headers: " + mayHappen);

s/huntting/hunting/

&gt;          return;
&gt;        }
&gt;        if (!cookies) return;
&gt; diff --git a/src/chrome/content/rules/Bitly.xml b/src/chrome/content/rules/Bitly.xml
&gt; index 71a415d..8ec0072 100644
&gt; --- a/src/chrome/content/rules/Bitly.xml
&gt; +++ b/src/chrome/content/rules/Bitly.xml
&gt; @@ -6,7 +6,12 @@
&gt;    &lt;target host="j.mp" /&gt;
&gt;    &lt;target host="www.j.mp" /&gt;
&gt;  
&gt; +  &lt;securecookie host="*.\.bit\.ly$" name=".*"&gt;

s/\*\./.*/


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101112052541</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-12 05:25:41-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or</subject><body>

On Sun, Sep 26, 2010 at 9:34 AM, Robert Hogan &lt;robert@roberthogan.net&gt; wrote:
&gt; On Wednesday 25 August 2010 22:12:28 Robert Hogan wrote:
&gt;&gt;
&gt;&gt; - We can achieve some/a lot of the benefits sought by the proposal if we
&gt;&gt; isolate streams based on the information provided by the socks request
&gt;&gt; itself. The things people have suggested are:
&gt;&gt;   1 Socks authentication info (username/pass)
&gt;&gt;   2 Socks listener address/port
&gt;&gt;   3 Socks protocol
&gt;&gt;   4 Socks client IP
&gt;&gt;   5 Info in /proc/pid/cmdline garnered from the client's port number
&gt;
&gt; So after more discussion this list now looks like:
&gt;
&gt;   1 Socks authentication info (username/pass)
&gt;   2 Socks listener address/port
&gt;   3 Socks protocol
&gt;   4 Socks client IP
&gt;   5 Destination Port (if it is in the LongLivedPort list)
&gt;
&gt; And the consensus is it should be on by default.
&gt;
&gt; Adding number 5 to the list would allow users to isolate streams by port 80
&gt; if they chose to designate it a LongLivedPort. I'm not sure if that means
&gt; we should leave it out of the list, if we should defend against 'invalid'
&gt; LongLivedPorts, or if it's something we are happy to allow.
&gt;
&gt; I think the list above allows stream isolation on requests over TransPort
&gt; and NATDPort - at least to the extent that it will isolate streams on the
&gt; basis of 2, 4 and 5 (if applicable).

Trying to push this forward...  The next step here is a revised
proposal.   I will lobby intransigently for holding out for an
IsolatePorts option distinct from LongLivedPorts: overloading
"long-lived" to "isolated" leads to nonsense like people deciding to
put port 80 into LongLivedPorts, which is exactly what you don't want
to use LongLivedPorts for.

</body></email><email><emailId>20101112221555</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-12 22:15:55-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 2/2] securecookie: Dropbox,</subject><body>


On Fri, 12 Nov 2010 18:38:09 +0000 (UTC)
pde@torproject.org wrote:

&gt; Author: Peter Eckersley &lt;pde@eff.org&gt;
&gt; Date: Fri, 12 Nov 2010 10:24:51 -0800
&gt; Subject: securecookie: Dropbox, Evernote, Github
&gt; Commit: 4d87e583e18b42373343e6b19820710fd1a4a088
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/Dropbox.xml  |    2 ++
&gt;  src/chrome/content/rules/Evernote.xml |    2 ++
&gt;  src/chrome/content/rules/Facebook.xml |    2 +-
&gt;  src/chrome/content/rules/Github.xml   |    2 ++
&gt;  4 files changed, 7 insertions(+), 1 deletions(-)
&gt; 
&gt; diff --git a/src/chrome/content/rules/Dropbox.xml b/src/chrome/content/rules/Dropbox.xml
&gt; index 7df8033..712ad26 100644
&gt; --- a/src/chrome/content/rules/Dropbox.xml
&gt; +++ b/src/chrome/content/rules/Dropbox.xml
&gt; @@ -2,6 +2,8 @@
&gt;    &lt;target host="www.dropbox.com" /&gt;
&gt;    &lt;target host="dropbox.com" /&gt;
&gt;  
&gt; +  &lt;securecookie host="^(.*\.)?dropbox.com$" name=".*" /&gt;

The hostname has an unescaped dot.  The Evernote and Github
securecookie rules have the same problem.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101113080106</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-13 08:01:06-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master] Added Google Finance to</subject><body>


On Sat, 13 Nov 2010 07:56:57 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Gilad Shaham &lt;gilad@voxisoft.com&gt;
&gt; Date: Sat, 13 Nov 2010 05:44:52 +0200
&gt; Subject: Added Google Finance to Google Services rule
&gt; Commit: 10d7ae6817cc1d58a5e86c39c2ee0f4ae4924886
&gt; 
&gt; ---
&gt; src/chrome/content/rules/GoogleServices.xml |    4 ++++
&gt; 1 files changed, 4 insertions(+), 0 deletions(-)
&gt; 
&gt; diff --git a/src/chrome/content/rules/GoogleServices.xml \
&gt; b/src/chrome/content/rules/GoogleServices.xml index 6c6fde3..5d5ae48 100644
&gt; --- a/src/chrome/content/rules/GoogleServices.xml
&gt; +++ b/src/chrome/content/rules/GoogleServices.xml
&gt; @@ -60,4 +60,8 @@
&gt; 
&gt; &lt;rule from="^http://www\.google\.com/cse/intl/([^/:@][^/:@])/images/google_custom_search_watermark\.gif$" \
&gt; to="https://www.google.com/cse/intl/$1/images/google_custom_search_watermark.gif" \
&gt; /&gt; 
&gt; +  &lt;rule from="^http://(www\.)?google\.com/finance" 
&gt; +          to="https://www.google.com/finance"/&gt;
&gt; +  &lt;rule from="^http://(www\.)?google\.co.uk/finance" 

This rule has an unescaped dot.

&gt; +          to="https://www.google.co.uk/finance"/&gt;
&gt; &lt;/ruleset&gt;


Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101115094258</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-11-15 09:42:58-0400</timestampReceived><subject>Re: Anomos - anonymous bit torrent - using Onion Routing...</subject><body>

"
It's my understanding that BitTorrent is less of a bandwidth hog as it
is a connections/circuits hog. These are expensive to create and you
can't balance your BitTorrenting by hosting a high-bandwidth node
because to have 0 net effect on the network, you'd have to host a
circuit's worth of nodes for every circuit you're using for BitTorrent
connections.
"

Bandwidth is surely finite but I'd bet safe to calculate. I would think
it easy to reach zero net, starting at minimally six times your use.

Circuits are a separate issue. AFAIK, they are just consumers of state
on the nodes... CPU, RAM, TCP, etc. I can see where adding a node
[any node] in at 6x [or any x] would help distribute that load as well.

Other than between the tracker, BT spawns a bunch of bandwith filled
pipes, up to some number of peers limit in the app. What is, if any, the
relationship between IPv4 TCP flows and Tor circuit usage? That could
help calculate the replacement value for non-bandwidth node resources.

&gt; Am I wrong, Tor Old Ones?

I sure haven't got that far in reading to guess yet, so yeah, if someone
has a hunch, that would be interesting. Maybe 6 nodes that add up to
6x bandwidth or something.

Not sure about anyone else, but I do think that with the way things
are going on the internet, more people will be looking to anonymous
systems in general to supplant it for their 'filesharing' and other
interests. That accumulation might be unstoppable.  So hopefully
those sorts of uses are being thought after and researched/planned/coded for.
</body></email><email><emailId>20101116021343</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-16 02:13:43-0400</timestampReceived><subject>Re: [or-cvs] [tor/master] changes entry for nopublish removal in</subject><body>


On Mon, 15 Nov 2010 19:25:55 +0000 (UTC)
nickm@torproject.org wrote:

&gt; Author: Nick Mathewson &lt;nickm@torproject.org&gt;
&gt; Date: Mon, 15 Nov 2010 14:29:53 -0500
&gt; Subject: changes entry for nopublish removal in 5040c855d
&gt; Commit: 29c468146d86f7360c5764cdb4efd86943a8e2ca
&gt; 
&gt; ---
&gt;  changes/nonopublish |    3 +++
&gt;  1 files changed, 3 insertions(+), 0 deletions(-)
&gt;  create mode 100644 changes/nonopublish
&gt; 
&gt; diff --git a/changes/nonopublish b/changes/nonopublish
&gt; new file mode 100644
&gt; index 0000000..6285611
&gt; --- /dev/null
&gt; +++ b/changes/nonopublish
&gt; @@ -0,0 +1,3 @@
&gt; +  o Removed features
&gt; +    - Removed the obsolete "NoPublished" option; it has been flagged

s/NoPublished/NoPublish/

&gt; +      as obsolete and has produced a warning since 0.1.1.18-rc.


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101117234855</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-11-17 23:48:55-0400</timestampReceived><subject>Re: P2P over Tor [was: Anomos - anonBT]</subject><body>

"""

[3] As the average bandwidth that most users [dsl, cable] will be
able to give back is small, transfers will be slow anyways. Which
may limit adoption [P2P peer counts]. Regardless, the limiting
factor is really only bandwidth because (dice up the giveback/6 you
can legitimately use... amongst P2P peer circuits however you want,
ie): dsl/cable = 1 x 256Kb/6 = 10 x 25.6Kb/6 = 100 x 2.56Kb/6

"""

This is the point I was thinking about with respect to exit relays.
It has been noted that 2GB per day is the load that an exit relay ought 
to handling, to be of use the Tor network.
Most users don't have that kind of bandwidth, but the wider Tor network 
would benefit from more bandwidth in general.
So I assumed, possibly falsely, that some bandwidth given back to the 
network is better than none.

In the case with Torrents, all members of the swarm are usually 
supplying the data they have downloaded back to the network.

This leaves me wondering if these kinds of p2p principles can be brought 
to bear on the Tor network too, with users offering what they can, when 
they can, back to the Tor network.

As I noted, the 2GB per day load is beyond most home users, but 
thousands of users giving a little bit back could help ?

Are there any thoughts on this ?

Regards.

grarpamp wrote:
&gt;&gt; "
&gt;&gt; It's my understanding that BitTorrent is less of a bandwidth hog as it
&gt;&gt; is a connections/circuits hog. These are expensive to create and you
&gt;&gt; can't balance your BitTorrenting by hosting a high-bandwidth node
&gt;&gt; because to have 0 net effect on the network, you'd have to host a
&gt;&gt; circuit's worth of nodes for every circuit you're using for BitTorrent
&gt;&gt; connections.
&gt;&gt; "
&gt;&gt;
&gt;&gt; Bandwidth is surely finite but I'd bet safe to calculate. I would think
&gt;&gt; it easy to reach zero net, starting at minimally six times your use.
&gt;&gt;
&gt;&gt; Circuits are a separate issue. AFAIK, they are just consumers of state
&gt;&gt; on the nodes... CPU, RAM, TCP, etc. I can see where adding a node
&gt;&gt; [any node] in at 6x [or any x] would help distribute that load as well.
&gt;&gt;
&gt;&gt; Other than between the tracker, BT spawns a bunch of bandwith filled
&gt;&gt; pipes, up to some number of peers limit in the app. What is, if any, the
&gt;&gt; relationship between IPv4 TCP flows and Tor circuit usage? That could
&gt;&gt; help calculate the replacement value for non-bandwidth node resources.
&gt;&gt;
&gt;&gt;     
&gt;&gt;&gt; Am I wrong, Tor Old Ones?
&gt;&gt;&gt;       
&gt;&gt; I sure haven't got that far in reading to guess yet, so yeah, if someone
&gt;&gt; has a hunch, that would be interesting. Maybe 6 nodes that add up to
&gt;&gt; 6x bandwidth or something.
&gt;&gt;
&gt;&gt; Not sure about anyone else, but I do think that with the way things
&gt;&gt; are going on the internet, more people will be looking to anonymous
&gt;&gt; systems in general to supplant it for their 'filesharing' and other
&gt;&gt; interests. That accumulation might be unstoppable.  So hopefully
&gt;&gt; those sorts of uses are being thought after and researched/planned/coded
&gt;&gt; for.
&gt;&gt;     
&gt;
&gt;
&gt; Thought about the non-bandwidth parts of the load some more...
&gt;
&gt; There doesn't seem to be a need to quantify it with a numerical
&gt; estimate of what amount of resource giveback would yield a zero sum
&gt; impact for those parts.
&gt;
&gt; Say you're using 'filesharing' in the form of BitTorrent. Your
&gt; single PC, when operating as a non-exit relay [1], can surely handle
&gt; many times the trivial sum of all the various non-bandwidth resources
&gt; described above that you would use along the way. Think of simulating
&gt; a TorNet by running all the needed directories, nodes and operations
&gt; bound to IP aliases on one PC. Conservatively say [3] you will have
&gt; up to 100 P2P circuits at 6 hops each... Any PC should be able to
&gt; handle that entire load with lots of headroom.
&gt;
&gt; So long as users are covering their bandwidth with giveback [1], I
&gt; think it's safe to assume the rest of their overhead is also covered
&gt; by the addition of that node to the network.
&gt;
&gt; I no longer think the standard reply/FAQ regarding such uses of
&gt; Tor, excepting [2], should be an unqualified: Tor can't handle it,
&gt; so don't.
&gt;
&gt; The answer should be that... so long as such giveback [1] is:
&gt; - understood by users to be a necessary 'techical' condition to
&gt;  support their use of Tor for bulk transfer.
&gt; - indeed provided back to the network as a 'moral' condition by
&gt;  those same users.
&gt;
&gt; ... they should then feel free to use Tor for whatever they want.
&gt; BitTorrent, P2P, FTP, streaming media, chat, etc. And OnionCat is
&gt; the shim that will allow the apps to communicate seamlessly.
&gt;
&gt; Though not as simple a response, and requiring donation by the user,
&gt; it seems to be the more reasoned one.
&gt;
&gt; Further thoughts welcomed.
&gt;
&gt;
&gt; [1] It's already established that in order for your use of Tor
&gt; bandwidth to be zero sum (in the Hidden Service &lt;--&gt; Hidden Service
&gt; case) you need to give back at least 6x your use. So you will already
&gt; be running said relay (for the purpose of bandwidth giveback).
&gt;
&gt; [2] Isn't there a proposal out there to better handle magnitudes
&gt; more users [and avoid shutdown points] by getting rid of the
&gt; directories and self-hosting the TorNet into a DHT or something?
&gt;
&gt; [3] As the average bandwidth that most users [dsl, cable] will be
&gt; able to give back is small, transfers will be slow anyways. Which
&gt; may limit adoption [P2P peer counts]. Regardless, the limiting
&gt; factor is really only bandwidth because (dice up the giveback/6 you
&gt; can legitimately use... amongst P2P peer circuits however you want,
&gt; ie): dsl/cable = 1 x 256Kb/6 = 10 x 25.6Kb/6 = 100 x 2.56Kb/6
&gt;
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
"""&lt;br&gt;
&lt;pre wrap=""&gt;[3] As the average bandwidth that most users [dsl, cable] will be
able to give back is small, transfers will be slow anyways. Which
may limit adoption [P2P peer counts]. Regardless, the limiting
factor is really only bandwidth because (dice up the giveback/6 you
can legitimately use... amongst P2P peer circuits however you want,
ie): dsl/cable = 1 x 256Kb/6 = 10 x 25.6Kb/6 = 100 x 2.56Kb/6
&lt;/pre&gt;
"""&lt;br&gt;
&lt;br&gt;
This is the point I was thinking about with respect to exit relays.&lt;br&gt;
It has been noted that 2GB per day is the load that an exit relay ought
to handling, to be of use the Tor network.&lt;br&gt;
Most users don't have that kind of bandwidth, but the wider Tor network
would benefit from more bandwidth in general.&lt;br&gt;
So I assumed, possibly falsely, that some bandwidth given back to the
network is better than none.&lt;br&gt;
&lt;br&gt;
In the case with Torrents, all members of the swarm are usually
supplying the data they have downloaded back to the network.&lt;br&gt;
&lt;br&gt;
This leaves me wondering if these kinds of p2p principles can be
brought to bear on the Tor network too, with users offering what they
can, when they can, back to the Tor network.&lt;br&gt;
&lt;br&gt;
As I noted, the 2GB per day load is beyond most home users, but
thousands of users giving a little bit back could help ?&lt;br&gt;
&lt;br&gt;
Are there any thoughts on this ?&lt;br&gt;
&lt;br&gt;
Regards.&lt;br&gt;
&lt;br&gt;
grarpamp wrote:
&lt;blockquote
 cite="mid:AANLkTin=ZJ146fYL4nqG1ds97djisiK_td3YwQLFx4SK@mail.gmail.com"
 type="cite"&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;"
It's my understanding that BitTorrent is less of a bandwidth hog as it
is a connections/circuits hog. These are expensive to create and you
can't balance your BitTorrenting by hosting a high-bandwidth node
because to have 0 net effect on the network, you'd have to host a
circuit's worth of nodes for every circuit you're using for BitTorrent
connections.
"

Bandwidth is surely finite but I'd bet safe to calculate. I would think
it easy to reach zero net, starting at minimally six times your use.

Circuits are a separate issue. AFAIK, they are just consumers of state
on the nodes... CPU, RAM, TCP, etc. I can see where adding a node
[any node] in at 6x [or any x] would help distribute that load as well.

Other than between the tracker, BT spawns a bunch of bandwith filled
pipes, up to some number of peers limit in the app. What is, if any, the
relationship between IPv4 TCP flows and Tor circuit usage? That could
help calculate the replacement value for non-bandwidth node resources.

    &lt;/pre&gt;
    &lt;blockquote type="cite"&gt;
      &lt;pre wrap=""&gt;Am I wrong, Tor Old Ones?
      &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;pre wrap=""&gt;I sure haven't got that far in reading to guess yet, so yeah, if someone
has a hunch, that would be interesting. Maybe 6 nodes that add up to
6x bandwidth or something.

Not sure about anyone else, but I do think that with the way things
are going on the internet, more people will be looking to anonymous
systems in general to supplant it for their 'filesharing' and other
interests. That accumulation might be unstoppable.  So hopefully
those sorts of uses are being thought after and researched/planned/coded
for.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;

Thought about the non-bandwidth parts of the load some more...

There doesn't seem to be a need to quantify it with a numerical
estimate of what amount of resource giveback would yield a zero sum
impact for those parts.

Say you're using 'filesharing' in the form of BitTorrent. Your
single PC, when operating as a non-exit relay [1], can surely handle
many times the trivial sum of all the various non-bandwidth resources
described above that you would use along the way. Think of simulating
a TorNet by running all the needed directories, nodes and operations
bound to IP aliases on one PC. Conservatively say [3] you will have
up to 100 P2P circuits at 6 hops each... Any PC should be able to
handle that entire load with lots of headroom.

So long as users are covering their bandwidth with giveback [1], I
think it's safe to assume the rest of their overhead is also covered
by the addition of that node to the network.

I no longer think the standard reply/FAQ regarding such uses of
Tor, excepting [2], should be an unqualified: Tor can't handle it,
so don't.

The answer should be that... so long as such giveback [1] is:
- understood by users to be a necessary 'techical' condition to
 support their use of Tor for bulk transfer.
- indeed provided back to the network as a 'moral' condition by
 those same users.

... they should then feel free to use Tor for whatever they want.
BitTorrent, P2P, FTP, streaming media, chat, etc. And OnionCat is
the shim that will allow the apps to communicate seamlessly.

Though not as simple a response, and requiring donation by the user,
it seems to be the more reasoned one.

Further thoughts welcomed.


[1] It's already established that in order for your use of Tor
bandwidth to be zero sum (in the Hidden Service &lt;--&gt; Hidden Service
case) you need to give back at least 6x your use. So you will already
be running said relay (for the purpose of bandwidth giveback).

[2] Isn't there a proposal out there to better handle magnitudes
more users [and avoid shutdown points] by getting rid of the
directories and self-hosting the TorNet into a DHT or something?

[3] As the average bandwidth that most users [dsl, cable] will be
able to give back is small, transfers will be slow anyways. Which
may limit adoption [P2P peer counts]. Regardless, the limiting
factor is really only bandwidth because (dice up the giveback/6 you
can legitimately use... amongst P2P peer circuits however you want,
ie): dsl/cable = 1 x 256Kb/6 = 10 x 25.6Kb/6 = 100 x 2.56Kb/6


  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20101118010358</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-11-18 01:03:58-0400</timestampReceived><subject>Re: Scalability and fairness [was: P2P over Tor [was: Anomos - anonBT]]</subject><body>

&gt;&gt; So long as users are covering their bandwidth with giveback [1], I
...
&gt;&gt; - indeed provided back to the network as a 'moral' condition by
&gt;&gt; those same users.
...
&gt;&gt; case) you need to give back at least 6x your use. So you will already

&gt; there's always a catch. ;)

Heh, yeah, no one ever suggested this would happen, as the leecher
mindset abounds :) It just seemed useful to actually ask for, examine
and collate the parameters under which it *could* happen successfully.
And the areas where Tor, or any other anonymous system, is permanently
incapable as a limitation of architecture. Or where the system
actually could be enhanced to better support what some users are
already going to use it for regardless of disencouragement.

It should be noted that one reason people ask about using anon
systems for such traffic is because they feel risk when doing so
in the clear. Either as consumer, distributor or participant. Being
anonymous may actually be the key they need that allows them to run
the seed/server/distributor side without fear. In other words...
I'd bet it's called 'filesharing' because most people actually *do*
want to give back and share, albeit safely.

Is anonymity the missing link to the global filesharing utopia
invisioned be all the various sharing systems? Who knows. We'll
find out.

&gt;&gt; [2] Isn't there a proposal out there to better handle magnitudes
&gt;&gt; more users [and avoid shutdown points] by getting rid of the
&gt;&gt; directories and self-hosting the TorNet into a DHT or something?
&gt;
&gt; Tor would become something else, perhaps UDP Tor.
&gt;
&gt; there has been more written on that subject than i can do justice

Wish the mbox or maildir archives were available/mirrored for easy
search, reading, reference and reply using native mail clients :)
</body></email><email><emailId>20101119034426</emailId><senderName>Tomás_Touceda</senderName><senderEmail>chiiph@gentoo.org</senderEmail><timestampReceived>2010-11-19 03:44:26-0400</timestampReceived><subject>Re: Vidalia Command Line Arguments... ?</subject><body>

2010/11/19 Cav &lt;cav@gotadsl.co.uk&gt;:
&gt; Hi or-dev,
&gt;
&gt; Forgive me my ignorance. I can't find a command-line reference for Vidalia.
&gt; I am only aware of the -data option, are there more ?

Try vidalia --help

Cheers,
Tomas
</body></email><email><emailId>20101120100747</emailId><senderName>Christian Kujau</senderName><senderEmail>lists@nerdbynature.de</senderEmail><timestampReceived>2010-11-20 10:07:47-0400</timestampReceived><subject>=?UTF-8?Q?format_=E2=80=98%lu=E2=80=99_expects_type_=E2=80=98long_unsigned_int=E2=80=99=2C_but_argum</subject><body>

Hi,

while compiling the today's git tree (e361de80bb), I get the following 
error when compiling (gcc 4.3.2, powerpc32):

----------------------------------------------------
control.c: In function ‘control_event_signal':
control.c:3621: error: format ‘%lu' expects type ‘long unsigned int', but \
argument 5 has type ‘uintptr_t' make[3]: *** [control.o] Error 1
make[3]: Leaving directory `/usr/local/src/tor-git/src/or'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/usr/local/src/tor-git/src'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/usr/local/src/tor-git'
make: *** [all] Error 2
----------------------------------------------------

Reverting 7441999738e7c1b0ea94a39dd6e1f8a48043ff7d ("Add a SIGNAL event 
for control connections") seems to help. Also, changing %lu to %u in 
src/or/control.c helps too, but I don't know if this is the right thing to 
do - at all. Please check.

Thanks,
Christian.

diff --git a/src/or/control.c b/src/or/control.c
index 5037529..307f0a2 100644
--- a/src/or/control.c
+++ b/src/or/control.c
@@ -3618,7 +3618,7 @@ control_event_signal(uintptr_t signal)
       signal_string = "CLEARDNSCACHE";
       break;
     default:
-      log_warn(LD_BUG, "Unrecognized signal %lu in control_event_signal",
+      log_warn(LD_BUG, "Unrecognized signal %u in control_event_signal",
                signal);
       return -1;
   }
-- 
BOFH excuse #412:

Radial Telemetry Infiltration


</body></email><email><emailId>20101120102305</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-20 10:23:05-0400</timestampReceived><subject>=?windows-1252?Q?Re=3A_format_=91=25lu=92_expects_type_=91long_unsigned_i?=</subject><body>

On Sat, Nov 20, 2010 at 5:07 AM, Christian Kujau &lt;lists@nerdbynature.de&gt; wrote:
&gt; Hi,
&gt; 
&gt; while compiling the today's git tree (e361de80bb), I get the following
&gt; error when compiling (gcc 4.3.2, powerpc32):
&gt; 
&gt; ----------------------------------------------------
&gt; control.c: In function ‘control_event_signal’:
&gt; control.c:3621: error: format ‘%lu’ expects type ‘long unsigned int’, but argument \
&gt; 5 has type ‘uintptr_t’ make[3]: *** [control.o] Error 1
&gt; make[3]: Leaving directory `/usr/local/src/tor-git/src/or'
&gt; make[2]: *** [all-recursive] Error 1
&gt; make[2]: Leaving directory `/usr/local/src/tor-git/src'
&gt; make[1]: *** [all-recursive] Error 1
&gt; make[1]: Leaving directory `/usr/local/src/tor-git'
&gt; make: *** [all] Error 2
&gt; ----------------------------------------------------
&gt; 
&gt; Reverting 7441999738e7c1b0ea94a39dd6e1f8a48043ff7d ("Add a SIGNAL event
&gt; for control connections") seems to help. Also, changing %lu to %u in
&gt; src/or/control.c helps too, but I don't know if this is the right thing to
&gt; do - at all. Please check.

Thanks, and thanks for the excellent bug report.  This should be fixed now.

The problem was that the new code to report SIGNAL events to the
controller used %u to format a uintptr_t for display to the logs in
the case where the signal number was unknown.  Neither %u now %lu is
quite right for uintptr_t, since that type will be the same slze as
unsigned int on  some architectures, but the same size as unsigned
long on others.  Since the log message is triggered only on a bug, it
should be good enough to display the wider type unconditionally: hence
see 9cbe64db45de6d6f5.

Thanks again,
-- 
Nick


</body></email><email><emailId>20101120111927</emailId><senderName>Christian Kujau</senderName><senderEmail>lists@nerdbynature.de</senderEmail><timestampReceived>2010-11-20 11:19:27-0400</timestampReceived><subject>=?UTF-8?Q?Re=3A_=5Bor-dev=5D_Re=3A_format_=E2=80=98%lu=E2=80=99_expects_type_=E2=80=98long_unsigned_</subject><body>

On Sat, 20 Nov 2010 at 05:23, Nick Mathewson wrote:
&gt; long on others.  Since the log message is triggered only on a bug, it
&gt; should be good enough to display the wider type unconditionally: hence
&gt; see 9cbe64db45de6d6f5.

It builds! :-)

Thanks for the quick fix and the explanation! 

Christian.
-- 
BOFH excuse #384:

it's an ID-10-T error
</body></email><email><emailId>20101121200902</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-21 20:09:02-0400</timestampReceived><subject>Next developer party Tuesday, Nov 23 at 1pm EST (18:00 UTC)</subject><body>

Hello everyone,

I'm declaring the next developer party at 23 Nov at 1pm EST (I believe
that's 18:00 UTC).  It will last for 2 hours of official partytime,
though please feel free to linger after. It will be in #tor-dev on
irc.oftc.net. The agenda is still simple: let's figure out what we're
all working on 'til the end of the year, and see how we can help each
other out.  Let's not get bogged down in just one or two individual
projects; I'll moderate as needed.

Standard party notes:

* This is called a "party" because calling our IRC meetings "parties"
has produced better outcomes in the past than calling them "meetings".
* If you're not free to make it, or if you're not free to make it for
the whole time, don't worry.  There will be more of these at other
times ranging from "too late in Europe" to "too early in California".
* If you're not an actual developer on Tor, you're welcome to come and
hang out, but this is mainly a time for developers to chat and plot
and generally confab.
* We're probably not going to be "partying" for every minute of all 2
hours; think of this as a salon where people wander in and out and
take breaks to go into a corner and eat cheese or debug trac or
whatever.
* The format will probably change in the future as we get some
experience with it and learn more about what does (and doesn't) work
for us.  If having 2 open hours is too much, let's do less.
* I'm going to try to "host" this developer party.  Since you can't
serve food over IRC, and there's no need to vacuum the floor before
the party starts, I'm not quite sure what my responsibility will be
other than being around the whole time and trying to make sure the
conversation stays interesting.  I'll play it by ear.

yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20101122154953</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-22 15:49:53-0400</timestampReceived><subject>Re: Stream starvation in Tor (with patch)</subject><body>

On Mon, Nov 22, 2010 at 8:33 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
[...]
&gt; The patch is attached.

Looks good to me, &amp; thanks for the hard work. I think it should go
into 0.2.2.x, with a possible backport to 0.2.1.x as a followup to
#1653.

I've added a ticket for this as
https://trac.torproject.org/projects/tor/ticket/2210#comment:3  .
Without a trac ticket, we tend to lose track of patches.  I've posted
a quick code review there too.

peace,
-- 
Nick
</body></email><email><emailId>20101123050636</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-11-23 05:06:36-0400</timestampReceived><subject>Thoughts on</subject><body>

My initial impressions are effectively summarized as "wow, this is long
and complex!  Does it really need to be so?"

One thought is how thandy/secure updater affects this plan. I see we'll
still need to handle alpha vs. stable in some way, but the rest seems to
be easier to maintain.

From a past packing perspective, having anything more than 2 branches
to maintain and build was suboptimal.  If package building is automated,
it may still be suboptimal, but less of a nuisance because packages
magically appears hours after one starts the build farm building
packages.

I've always viewed -alpha and -stable as feature dependent.  -alpha
gets new features, -stable is frozen in time with respect to features
and only gets bugfixes.  In both branches, bugfixes are prominent
throughout their lifetimes.  Therefore, I propose a simple set of 2
branches, -alpha and -stable. -alpha continues to get new features and
bugfixes as we create them.  -stable continues to only receive
bugfixes on its existing features.  

When we're happy with the set of features in -alpha, or something
else is driving the creation of new and crazy features, we do a
feature freeze.  Only bugfixes to existing features are included
during this phase.  When an -alpha switches to -stable, the former
-stable is now obsolete and at end of life. The desire for a new -alpha
may force the switch to -stable.   I think having more than 2 branches
creates much more work for us.

The previous two paragraphs are perhaps a loose interpretation of what
we have done in the recent past.

As for operating system support, I'm fine with supporting whatever the
current OS manufacturer (for loose meanings of organization that
creates the releases) supports.  I'd caution this with finding out what
our users actually need.  There are a many places in the world where
they use operating systems from more than 10 years ago.  If we truly
want to help people, both -alpha and -stable branches should have wide
and a variety of OS functionality.

As of last winter when I did some testing, Tor (the binary itself) runs
under Win98 through Windows 7, OS X 10.3 through 10.6, and Fedora 10
through current.  

As for packages, I suggest we support the current release of an OS plus
two previous versions.  We could rely upon the OS versions of
libraries rather than bundle our own.  In an optimal world, we ship our
own libraries for Tor rather than relying upon various vendors to keep
up to date.  This lets us control features and some part of an operating
environment for tor.  I'm primarily thinking of zlib, openssl, and
libevent 1 or 2 for inclusion here.  My idea of an optimal world may
need thandy implemented to make it a reality.  

I think trying to keep lists of OSes and their various libraries is
going to create work for little gain.  If the OS does not have our
minimum requirements, such as openssl 0.9.8, libevent 1.4, etc ,then we
cannot run on that OS.  Users can build their own tor from source, if
so desired.

My goals here are to keep things simple.  I worry that a complex set of
rules for releases will bog us down and not force us to make decisions
to keep tor progressing along as it has for the past few years.

-- 
Andrew
pgp 0x31B0974B

</body></email><email><emailId>20101123060047</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-11-23 06:00:47-0400</timestampReceived><subject>Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

On Tue, Nov 23, 2010 at 12:06 AM, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
[...]

I should probably add this as a motivations section to the
SupportPolicy draft document.  Without an overview of how our lack of
clarity here has been hurting us, it's not obvious why we need more.

So here are some problems we've had, and how they have caused trouble.

First off, we have had little clarity about which releases are
"supported" with which kind of bug fixes at what time.  This creates
some problems, such as:
   * Users get told about end-of-life only after the fact.
   * People often decide whether to backport or not backport bugfixes
on a case-by-case basis with no real criteria to work from.
   * Because there are no criteria as to which bugfixes get
backported, and no clarity as to which releases we backport bugfixes
to, when we _have_ decided we should put out an update for a
not-latest release, we have sometimes found that we just can't do so,
because we would have to review the entire set of patches that went
into the more recent release, looking for ones to backport.
   * Questions of, "Must the network support routers of version X?
clients of version Y?" have been answered by "are there any left?"
rather than "is that still supported?"

Second, we haven't had much clarify about which operating systems we
support, with what effort.  From time to time, we break win98; from
time to time, somebody tells us and I spend a day or two figuring out
how to make it work again.  Vidalia's recent miniupnp stuff, I hear,
has problems on win2k.  Our explicitly stated policy wrt win98 has
been in the past, "If anybody notices we broke it, we might fix it".
I am pretty sure we broke win95 osr2 or whatever it was called without
meaning to at some point; it would have been nice to have done it on
purpose.

Knowing which operating systems and which versions of them we support
would help us get out of supporting ancient versions of our
dependencies.  We still have backward compatibility code for Libevent
1.0 and until recently we were maintaining backward compatibility code
for openssl 0.9.6.  Knowing what OSs we support can let us know what
we require.

So there are 4 questions we need to answer, from just a Tor
development POV, ignoring all bundling issues for now:
  * Which Tor versions do we support?
  * To what degree to we support them?
  * What operating systems do we try to run on, and how hard do we try?
  * Which library versions do we try to tolerate?

Here are some user goals:
  * Users should be able to answer the above questions clearly.
  * Users should always have a genuinely stable release to run that
works fine on the network.
  * Given that transitions between release series can be more
destabilizing than transitions within a release series, conservative
users should have a reasonably broad window in which to see if a new
stable series is stable enough for them before they upgrade.
   * Given that some operating systems that run a lot of relays
(notably the free linuxes) don't do major-release upgrades during
their series, we should

Here are some developer goals:
  * Developers should know what compatibility features are necessary,
and what compatibility features are a waste of time.
  * Developers who find a longstanding bug (say, "bugfix on
0.0.9pre8") should know which version to write their patch against.

Having written this up, I think I can come up with a simpler policy
that's still accurate and workable.  I'll revise and see if it makes
more sense.

yrs,
-- 
Nick
</body></email><email><emailId>20101124084127</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-11-24 08:41:27-0400</timestampReceived><subject>Privacy-preserving Ways to Estimate the Number of Tor Users</subject><body>

Hello everyone,

Sebastian and I just finished our tech report on "Privacy-preserving
Ways to Estimate the Number of Tor Users" which is available here:

  https://metrics.torproject.org/papers.html

  https://metrics.torproject.org/papers/countingusers-2010-11-24.pdf

From the Introduction:

"The Tor network allows hundreds of thousands of users every day to stay
anonymous online and enables another tens of thousands of people in
oppressed countries to circumvent local censorship. At least, these are
the orders of magnitude of Tor usage that we assume at the time of
writing this report. Estimating the number of users in an anonymity
network is a hard problem. On the one hand, it's important to learn
something about the users of a network to improve its service. But on
the other hand, the users of an anonymity network have a high demand for
privacy, which prohibits collecting sensitive information that is
necessary to obtain exact usage statistics. In this report we describe
our approaches to collect aggregated usage data and derive user number
estimates from them."

The new user number estimate described in Section 4 is available here:

  https://metrics.torproject.org/users.html

As always, feedback is highly appreciated!

Best,
Karsten
</body></email><email><emailId>20101125212203</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-11-25 21:22:03-0400</timestampReceived><subject>Re: [or-cvs] [metrics-utils/master 2/4] Match full Torbutton user</subject><body>


On Thu, 25 Nov 2010 18:47:07 +0000 (UTC)
karsten@torproject.org wrote:

&gt; Author: Karsten Loesing &lt;karsten.loesing@gmx.net&gt;
&gt; Date: Thu, 25 Nov 2010 19:42:49 +0100
&gt; Subject: Match full Torbutton user agents.
&gt; Commit: 157c0dfe0722113bef50cea73be74600bde9414e
&gt; 
&gt; ---
&gt; visitor/visitor.py |   16 ++++++++--------
&gt; 1 files changed, 8 insertions(+), 8 deletions(-)
&gt; 
&gt; diff --git a/visitor/visitor.py b/visitor/visitor.py
&gt; index 06288b1..466bd52 100644
&gt; --- a/visitor/visitor.py
&gt; +++ b/visitor/visitor.py
&gt; @@ -16,18 +16,18 @@ from cStringIO import StringIO
&gt; # regexes used in the script
&gt; IP_RE = re.compile(r'(\d+\.){3}\d+')
&gt; APACHE_DATETIME = re.compile(r'\[(\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2}) \
&gt;                 ([+-]\d{4})\]')
&gt; -TOR_USERAGENTS = [('torbutton1_2_0', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; Windows NT 5\.1; ' +TOR_USERAGENTS = [('torbutton1_2_0', \
&gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; ' r'[a-z]{2}-[A-Z]{2}; \
&gt;                 rv\:1\.8\.1\.16\) '
&gt; -                                                r'Gecko/20080702 \
&gt;                 Firefox/2\.0\.0\.16')),
&gt; -                  ('torbutton1_2_0rc1', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; Windows NT 5\.1; ' +                                                \
&gt; r'Gecko/20080702 Firefox/2\.0\.0\.16"$')), +                  ('torbutton1_2_0rc1', \
&gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; ' r'en-US; \
&gt;                 rv\:1\.8\.1\.14\) '
&gt; -                                                   r'Gecko/20080404 \
&gt;                 Firefox/2\.0\.0\.14')),
&gt; -                  ('torbutton1_2_1', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; Windows NT 5\.1; ' +                                                   \
&gt; r'Gecko/20080404 Firefox/2\.0\.0\.14"$')), +                  ('torbutton1_2_1', \
&gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; ' r'en-US; \
&gt;                 rv\:1\.9\.0\.7\) '
&gt; -                                                r'Gecko/2009021910 \
&gt;                 Firefox/3\.0\.7')),
&gt; -                  ('torbutton1_2_5', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; Windows NT 6\.1; ' +                                                \
&gt; r'Gecko/2009021910 Firefox/3\.0\.7"$')), +                  ('torbutton1_2_5', \
&gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 6\.1; ' r'[a-z]{2}-[A-Z]{2}; \
&gt;                 rv:1\.9\.2\.3\) '
&gt; -                                                r'Gecko/20100401 \
&gt; Firefox/3\.6\.3')) +                                                \
&gt; r'Gecko/20100401 Firefox/3\.6\.3"$')) ]
&gt; 
&gt; 

This list is not complete -- TAILS 0.5, and presumably other
installations of Torbutton 1.2.5, produce the following User-Agent
string:

Mozilla/5.0 (Windows; U; Windows NT 6.1; chrome://global/locale/intl.properties; \
rv:1.9.2.3) Gecko/20100401 Firefox/3.6.3

See &lt;https://amnesia.boum.org/security/Iceweasel_exposes_a_rare_User-Agent/&gt;.

(Nobody should still be using TAILS 0.5, due to this and other security
issues, but your script is intended to be useful for analyzing older
logs as well as new ones.)


Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101124090402</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-11-24 09:04:02-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Hi Florian,

On 11/18/10 8:07 PM, Florian Tschorsch wrote:
&gt; it is been a while since we discussed this topic here: 
&gt; As Björn already pointed out in an earlier message, we are interested in the \
&gt; fraction of bidirectional traffic in tor.  \
&gt; (http://archives.seul.org/or/dev/Aug-2010/msg00038.html) 
&gt; Therefore we developed a metric with Karsten that tries to capture the necessary \
&gt; information.  He implemented this metric into Tor (thanks for that): \
&gt; https://gitweb.torproject.org/karsten/tor.git/shortlog/refs/heads/bidistats2 
&gt; After checking the code, we can confirm that it looks very good and matches exactly \
&gt; our intentions.

Great! Thanks for the review, Florian!

&gt; In order to get wide range results, we would prefer to merge the code into the main \
&gt; Tor distribution.  However should this constitute any trouble, we would be \
&gt; satisfied with an implementation on only a few selected running relays too. 

Nick, do you think we can merge the bidistats2 branch into master? If
so, I'll make sure it merges cleanly (which it may not right now).

Thanks,
Karsten


</body></email><email><emailId>20101124225018</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-11-24 22:50:18-0400</timestampReceived><subject>Re: 0.2.3.0 as an exit: identity_digest not set</subject><body>

On Wed, Nov 24, 2010 at 05:14:51PM -0500, Nick Mathewson wrote:
&gt; On Wed, Nov 24, 2010 at 5:03 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt; Here's another bug report.  [No patch this time, I'm afraid. :-( ]
&gt; &gt;
&gt; &gt; When we try to use 0.2.3.0 as an exit, circuit construction succeeds,
&gt; &gt; but stream creation fails almost all the time.  The failure is in
&gt; &gt; connection_edge.c, here:
&gt; &gt;
&gt; 
&gt; This looks like it is possibly part of the explanation for
&gt; https://trac.torproject.org/projects/tor/ticket/2205 .

Indeed it does.

BTW, Mashael gets the credit for tracking this down this far.  ;-)

   - Ian
</body></email><email><emailId>20101130040137</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-11-30 04:01:37-0400</timestampReceived><subject>Re: Android: Tor shared library vs exec binary?</subject><body>

On Fri, Nov 26, 2010 at 10:18 AM, Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt; Any thoughts on running Tor as a shared library within Orbot/Android
&gt; versus the way we do it now (command line start/stop with control port)?
...

On Mon, Nov 29, 2010 at 7:04 AM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; ... That said, I don't generally think embedding Tor as a shared library
&gt; is the best choice, for a few reasons...
&gt; * Using process isolation to isolate Tor from its controllers makes it
&gt; easier to tell Tor bugs from controller bugs....
&gt; * Using process isolation to isolate Tor from its controllers can also
&gt; make it easier to secure each of the two domains properly against bugs
&gt; in the other, especially if you're using OS or VM sandboxing features.

Tor must be its own process for these and other reasons. Yet it is
still preferable to have Orbot/Android app communicate / dependent on
just a slim shared library rather than cumbersome command line
start/stop method.

this implies use of android.app Service for Tor implemented as dynamic
DSO via NDK JNI for ideal integration. The NDK portion is really just
Tor invoked as main() per Nick's suggestion. a configuration like this
using both DSO and Service plays better with Task Killers as well,
among other benefits.

the Tor app Service could use a Message Queue or other available
communicate mechanism to map a subset of Control Port commands to a
queue and Java language client that the Controller utilizes when
needed and GUI active to display and configure the running Tor
instance / Service.

although this too is just suggestion to be taken with grains of salt. :)

best regards,
</body></email><email><emailId>20101130125144</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-11-30 12:51:44-0400</timestampReceived><subject>Re: [or-cvs] [metrics-utils/master 2/4] Match full Torbutton user</subject><body>

On 11/25/10 10:22 PM, Robert Ransom wrote:
&gt; On Thu, 25 Nov 2010 18:47:07 +0000 (UTC)
&gt; karsten@torproject.org wrote:
&gt; 
&gt; &gt; Author: Karsten Loesing &lt;karsten.loesing@gmx.net&gt;
&gt; &gt; Date: Thu, 25 Nov 2010 19:42:49 +0100
&gt; &gt; Subject: Match full Torbutton user agents.
&gt; &gt; Commit: 157c0dfe0722113bef50cea73be74600bde9414e
&gt; &gt; 
&gt; &gt; ---
&gt; &gt; visitor/visitor.py |   16 ++++++++--------
&gt; &gt; 1 files changed, 8 insertions(+), 8 deletions(-)
&gt; &gt; 
&gt; &gt; diff --git a/visitor/visitor.py b/visitor/visitor.py
&gt; &gt; index 06288b1..466bd52 100644
&gt; &gt; --- a/visitor/visitor.py
&gt; &gt; +++ b/visitor/visitor.py
&gt; &gt; @@ -16,18 +16,18 @@ from cStringIO import StringIO
&gt; &gt; # regexes used in the script
&gt; &gt; IP_RE = re.compile(r'(\d+\.){3}\d+')
&gt; &gt; APACHE_DATETIME = re.compile(r'\[(\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2}) \
&gt; &gt;                 ([+-]\d{4})\]')
&gt; &gt; -TOR_USERAGENTS = [('torbutton1_2_0', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; &gt; Windows NT 5\.1; ' +TOR_USERAGENTS = [('torbutton1_2_0', \
&gt; &gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; ' r'[a-z]{2}-[A-Z]{2}; \
&gt; &gt;                 rv\:1\.8\.1\.16\) '
&gt; &gt; -                                                r'Gecko/20080702 \
&gt; &gt;                 Firefox/2\.0\.0\.16')),
&gt; &gt; -                  ('torbutton1_2_0rc1', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; &gt; Windows NT 5\.1; ' +                                                \
&gt; &gt; r'Gecko/20080702 Firefox/2\.0\.0\.16"$')), +                  \
&gt; &gt; ('torbutton1_2_0rc1', re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; \
&gt; &gt; ' r'en-US; rv\:1\.8\.1\.14\) '
&gt; &gt; -                                                   r'Gecko/20080404 \
&gt; &gt;                 Firefox/2\.0\.0\.14')),
&gt; &gt; -                  ('torbutton1_2_1', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; &gt; Windows NT 5\.1; ' +                                                   \
&gt; &gt; r'Gecko/20080404 Firefox/2\.0\.0\.14"$')), +                  ('torbutton1_2_1', \
&gt; &gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 5\.1; ' r'en-US; \
&gt; &gt;                 rv\:1\.9\.0\.7\) '
&gt; &gt; -                                                r'Gecko/2009021910 \
&gt; &gt;                 Firefox/3\.0\.7')),
&gt; &gt; -                  ('torbutton1_2_5', re.compile(r'Mozilla/5\.0 \(Windows; U; \
&gt; &gt; Windows NT 6\.1; ' +                                                \
&gt; &gt; r'Gecko/2009021910 Firefox/3\.0\.7"$')), +                  ('torbutton1_2_5', \
&gt; &gt; re.compile(r'^"Mozilla/5\.0 \(Windows; U; Windows NT 6\.1; ' r'[a-z]{2}-[A-Z]{2}; \
&gt; &gt;                 rv:1\.9\.2\.3\) '
&gt; &gt; -                                                r'Gecko/20100401 \
&gt; &gt; Firefox/3\.6\.3')) +                                                \
&gt; &gt; r'Gecko/20100401 Firefox/3\.6\.3"$')) ]
&gt; &gt; 
&gt; &gt; 
&gt; 
&gt; This list is not complete -- TAILS 0.5, and presumably other
&gt; installations of Torbutton 1.2.5, produce the following User-Agent
&gt; string:
&gt; 
&gt; Mozilla/5.0 (Windows; U; Windows NT 6.1; chrome://global/locale/intl.properties; \
&gt; rv:1.9.2.3) Gecko/20100401 Firefox/3.6.3 
&gt; See &lt;https://amnesia.boum.org/security/Iceweasel_exposes_a_rare_User-Agent/&gt;.
&gt; 
&gt; (Nobody should still be using TAILS 0.5, due to this and other security
&gt; issues, but your script is intended to be useful for analyzing older
&gt; logs as well as new ones.)

I just added this user-agent string:

  https://gitweb.torproject.org/metrics-utils.git/commitdiff/e3e9ec8

Thanks!
Karsten


</body></email><email><emailId>20101005165732</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2010-10-05 16:57:32-0400</timestampReceived><subject>Developer party on Thursday Oct 14th from 18:00 to 20:00 UTC</subject><body>


Hello everyone,

I'm actually declaring two developer parties: a big one and a small one.

The big one is Thursday Oct 14th from 18:00 to 20:00 UTC. That's 11am
for west coast US folks and 2pm for east coasters. It will be in
#tor-dev on irc.oftc.net. The agenda is pretty simple and
straightforward: let's figure out what we're all working on 'til the end
of the year, and see how we can help each other out.

The small one is taking place this Thursday, Oct 7th, from 16:00 to
18:00 UTC also in #tor-dev on irc.oftc.net. This one is focused on
Thandy development that needs to be done over the course of the next six
months. I expect most of the discussion to be between me, Nick, and
Sebastian, but everyone is welcome to join.

Quoting Nick's previous email about developer parties, for people new to
the concept:

On Wed, Aug 04, 2010 at 02:19:39PM -0400, Nick Mathewson wrote:
&gt; Hi, folks!  This email is a heads-up about our next online  =20
&gt; nonstructured mass developer meeting, still called a "developer party"
&gt; on the superstitious belief that if we act like it's supposed to be
&gt; fun, it will be.   The last one was fun, after all.
&gt;
&gt; (I'm announcing this one on or-dev, since that's where people
&gt; suggested that I announce it after I announced the last one on another
&gt; list.  If you don't think these messages should be on or-dev, please
&gt; email me personally [not the list] to say so.)
&gt;
&gt; It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
&gt; channel on irc.oftc.net.  That's 14:00 to 16:00 eastern, and 11:00 to
&gt; 13:00 pacific, if I can still do math with my current jetlag.
&gt;
&gt; General notes:
&gt; * If you're not free to make it, or if you're not free to make it for
&gt; the whole time, don't worry.  There will be more of these at other
&gt; times ranging from "too late in Europe" to "too early in California".
&gt; * If you're not an actual developer on Tor, you're welcome to come and
&gt; hang out, but this is mainly a time for developers to chat and plot
&gt; and generally confab.
&gt; * We're probably not going to be "partying" for every minute of all 2
&gt; hours; think of this as a salon where people wander in and out and
&gt; take breaks to go into a corner and eat cheese or debug trac or
&gt; whatever.
&gt; * The format will probably change in the future as we get some
&gt; experience with it and learn more about what does (and doesn't) work
&gt; for us.  If having 2 open hours is too much, let's do less.
&gt; * I'm going to try to "host" this developer party.  Since you can't
&gt; serve food over IRC, and there's no need to vacuum the floor before
&gt; the party starts, I'm not quite sure what my responsibility will be
&gt; other than being around the whole time and trying to make sure the
&gt; conversation stays interesting.  I'll play it by ear.



["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101008003901</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2010-10-08 00:39:01-0400</timestampReceived><subject>Re: [or-cvs] r23443: {website} remove the glossary. fix up the</subject><body>

On Thu, Oct 07, 2010 at 05:38:21PM -0700, rransom.8774@gmail.com wrote 2.6K bytes in 75 lines about:
: You dropped the "&lt;/ul&gt;" tag, and I don't see it reappearing in the
: later commit messages.

Indeed, fixed. Thanks!

-- 
Andrew
pgp 0x31B0974B
</body></email><email><emailId>20101010034017</emailId><senderName>"LU Tb"</senderName><senderEmail>lutianbo@software.ict.ac.cn</senderEmail><timestampReceived>2010-10-10 03:40:17-0400</timestampReceived><subject>report on supply chain security</subject><body>

[Attachment #2 (text/plain)]

Hi, everyone,

Recently, IATAC released a report on supply chain security. However, only people in \
.gov or .mil can download it. Maybe someone can download it, especially those in USA. \
Can you help me? Thank you very much.

Best regards

Lu

The information on the report as follows:

 Risk Management for the Off-the-Shelf (OTS) Information Communications Technology \
(ICT) Supply Chain 

http://iac.dtic.mil/iatac/reports.jsp


[Attachment #3 (text/html)]

&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"&gt;
&lt;HTML&gt;&lt;HEAD&gt;
&lt;META content="text/html; charset=gb2312" http-equiv=Content-Type&gt;
&lt;META name=GENERATOR content="MSHTML 8.00.6001.18939"&gt;
&lt;STYLE&gt;&lt;/STYLE&gt;
&lt;/HEAD&gt;
&lt;BODY bgColor=#ffffff&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;Hi, everyone,&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;Recently, IATAC released a report on supply chain security. 
However, only people in .gov or .mil can download it. Maybe someone can download 
it, especially those in USA. Can you help me? Thank you very much.&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;Best regards&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;Lu&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;The information on the report as follows:&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt; &lt;A href=""&gt;Risk Management for the Off-the-Shelf (OTS) Information 
Communications Technology (ICT) Supply Chain &lt;/A&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;/FONT&gt; &lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT size=2&gt;&lt;A 
href=""&gt;http://iac.dtic.mil/iatac/reports.jsp&lt;/A&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;/BODY&gt;&lt;/HTML&gt;


</body></email><email><emailId>20101010071018</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-10 07:10:18-0400</timestampReceived><subject>Web site patch</subject><body>

[Attachment #2 (multipart/mixed)]


The attached patch contains numerous minor cleanups for the web site.


Robert Ransom

[Attachment #5 (text/x-patch)]

Index: en/index.wml
===================================================================
--- en/index.wml	(revision 23568)
+++ en/index.wml	(working copy)
@@ -101,7 +101,7 @@
               &lt;a href="&lt;page about/torusers&gt;#executives"&gt;&lt;img \
src="$(IMGROOT)/consumers.jpg" alt="Businesses"&gt;  Businesses&lt;/a&gt;
             &lt;/h3&gt;
-            &lt;p&gt;Businesses use Tor to research competition and keep strategies \
confidential, facilitating internal accountability.&lt;/p&gt; +            &lt;p&gt;Businesses \
use Tor to research competition, keep business strategies confidential, and \
facilitate internal accountability.&lt;/p&gt;  &lt;/div&gt;
           &lt;div class="user"&gt;
             &lt;h3&gt;
@@ -115,14 +115,14 @@
               &lt;a href="&lt;page about/torusers&gt;#journalist"&gt;&lt;img \
src="$(IMGROOT)/media.jpg" alt="Journalists and the Media"&gt;  Media&lt;/a&gt;
             &lt;/h3&gt;
-            &lt;p&gt;Journalists and the Media use Tor to protect their research and \
sources online.&lt;/p&gt; +            &lt;p&gt;Journalists and the media use Tor to protect \
their research and sources online.&lt;/p&gt;  &lt;/div&gt;
           &lt;div class="user"&gt;
             &lt;h3&gt;
               &lt;a href="&lt;page about/torusers&gt;#military"&gt;&lt;img \
src="$(IMGROOT)/military.jpg" alt="Military and Law Enforcement"&gt;  Military &amp; Law \
Enforcement&lt;/a&gt;  &lt;/h3&gt;
-            &lt;p&gt;Militaries and Law Enforcement use Tor to protect their \
communications, investigations, and intelligence gathering online.&lt;/p&gt; +            \
&lt;p&gt;Militaries and law enforcement use Tor to protect their communications, \
investigations, and intelligence gathering online.&lt;/p&gt;  &lt;/div&gt;
         &lt;/div&gt;
         &lt;div id="home-announcements" class="clearfix"&gt;
Index: about/en/torusers.wml
===================================================================
--- about/en/torusers.wml	(revision 23568)
+++ about/en/torusers.wml	(working copy)
@@ -18,7 +18,7 @@
     Tor was originally designed, implemented, and deployed as a
     third-generation &lt;a href="http://www.onion-router.net/"&gt;onion routing
     project of the Naval Research Laboratory&lt;/a&gt;.  It was originally
-    developed with the U.S. Navy in mind, for the primary purpose of
+    developed with the U.S. Navy in mind, primarily for the purpose of
     protecting government communications.  Today, it is used every day
     for a wide variety of purposes by the military, journalists, law
     enforcement officers, activists, and many others. Here are some of
@@ -31,15 +31,15 @@
     &lt;hr&gt;
     &lt;ul&gt;
     &lt;li&gt;&lt;strong&gt;They protect their privacy from unscrupulous marketers and identity \
                thieves.&lt;/strong&gt;
-    Internet Service Providers (ISPs) &lt;a \
href="http://seekingalpha.com/article/29449-compete-ceo-isps-sell-clickstreams-for-5-a-month"&gt;
                
-    sell your Internet browsing records&lt;/a&gt; to marketers or anyone else
+    Internet Service Providers (ISPs) &lt;a \
href="http://seekingalpha.com/article/29449-compete-ceo-isps-sell-clickstreams-for-5-a-month"&gt;sell
 +    your Internet browsing records&lt;/a&gt; to marketers and anyone else
     willing to pay for it. ISPs typically say that
     they anonymize the data by not providing personally identifiable information, \
                but
     &lt;a href="http://www.wired.com/politics/security/news/2006/08/71579?currentPage=all"&gt;this
                
     has proven incorrect&lt;/a&gt;.  A full record of every site you visit, the text of \
every search you perform, and potentially  userid and even password information can \
still be part of this data.  In addition to your ISP, the websites (&lt;a \
href="http://www.google.com/privacy_faq.html"&gt;and search engines&lt;/a&gt;) you visit have \
their own logs, containing the same or more information.  &lt;/li&gt;
-    &lt;li&gt;&lt;strong&gt; They protect their communications from irresponsible \
corporations.&lt;/strong&gt; +    &lt;li&gt;&lt;strong&gt;They protect their communications from \
                irresponsible corporations.&lt;/strong&gt;
     All over the Internet, Tor is being recommended to people newly concerned about \
                their privacy in the face of increasing breaches and betrayals of
     private data. From &lt;a href="http://www.securityfocus.com/news/11048"&gt;lost backup \
                tapes&lt;/a&gt;, to
     &lt;a href="http://www.nytimes.com/2006/08/09/technology/09aol.html?ex=1312776000&amp;en=f6f61949c6da4d38&amp;ei=5090"&gt;giving \
away the data to researchers&lt;/a&gt;, @@ -47,7 +47,7 @@
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;They protect their children online.&lt;/strong&gt;
     You've told your kids they shouldn't share personally identifying information \
                online, but they may be sharing their location simply
-    by not concealing their IP address. Increasingly, IP addresses can be &lt;a \
href="http://whatismyipaddress.com/"&gt;literally mapped to a city or even street \
location&lt;/a&gt;, and can &lt;a href="http://whatsmyip.org/more/"&gt;reveal other \
information&lt;/a&gt; about how you are connecting to the Internet. +    by not concealing \
their IP address. Increasingly, IP addresses can literally be &lt;a \
href="http://whatismyipaddress.com/"&gt;mapped to a city or even street location&lt;/a&gt;, \
and can &lt;a href="http://whatsmyip.org/more/"&gt;reveal other information&lt;/a&gt; about how \
                you are connecting to the Internet.
     In the United States, the government is pushing to make this mapping \
increasingly precise.  &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;They research sensitive topics.&lt;/strong&gt;
@@ -64,7 +64,7 @@
     &lt;ul&gt;
     
     &lt;li&gt;
-    &lt;strong&gt;Field Agents:&lt;/strong&gt;
+    &lt;strong&gt;Field agents:&lt;/strong&gt;
     It is not difficult for insurgents to monitor Internet traffic and
     discover all the hotels and other locations from which people are
     connecting to known military servers.
@@ -74,20 +74,20 @@
     &lt;/li&gt;
     
     &lt;li&gt;&lt;strong&gt;Hidden services:&lt;/strong&gt;
-    When the Internet was designed by DARPA, its primary purpose was to be able to \
                facilitate distributed, robust communications in case of
-    local strikes.  However, some functions must be centralized, such as command and \
                control sites.  It's the nature of the Internet protocols to
-    reveal the geographic location of any server that is reachable online.  Tor's \
hidden services capacity allows military command and +    When the Internet was \
designed by DARPA, its primary purpose was to facilitate distributed, robust \
communications in case of +    local strikes.  However, some functions must be \
centralized, such as command and control sites.  By their nature, Internet protocols \
+    reveal the geographic location of any server that is reachable online.  Tor's &lt;a \
href="&lt;page docs/hidden-services&gt;"&gt;hidden service capability&lt;/a&gt; allows military \
command and  control to be physically secure from discovery and takedown.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Intelligence gathering:&lt;/strong&gt;
     Military personnel need to use electronic resources run and monitored by \
                insurgents. They do not want the webserver logs on an insurgent \
                website
-    to record a military address, thereby revealing the surveillance.
+    to record a military address, thereby revealing that the site is under \
surveillance.  &lt;/li&gt;
     &lt;/ul&gt;
     
     &lt;a name="journalist"&gt;&lt;/a&gt;
     &lt;img src="$(IMGROOT)/media.jpg" alt="Journalists and the Media"&gt;
-    &lt;h2&gt;&lt;a class="anchor" href="#journalist"&gt;Journalists and their audience use \
Tor&lt;/a&gt;&lt;/h2&gt; +    &lt;h2&gt;&lt;a class="anchor" href="#journalist"&gt;Journalists and their \
audiences use Tor&lt;/a&gt;&lt;/h2&gt;  &lt;hr&gt;
     &lt;ul&gt;
     &lt;li&gt;&lt;strong&gt;&lt;a href="http://www.rsf.org/"&gt;Reporters without Borders&lt;/a&gt;&lt;/strong&gt;
@@ -96,8 +96,8 @@
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;The US &lt;a href="http://www.ibb.gov/"&gt;International Broadcasting \
                Bureau&lt;/a&gt;&lt;/strong&gt;
     (Voice of America/Radio Free Europe/Radio Free Asia) supports Tor development to \
                help Internet users in countries without
-    safe access to free media.  Tor preserves the ability of persons behind national \
                firewalls or under
-    the surveillance of repressive regimes to obtain a global perspective on \
controversial topics including democracy, +    safe access to free media.  Tor \
preserves the ability of persons behind national firewalls, or under +    the \
surveillance of repressive regimes, to obtain a global perspective on controversial \
topics including democracy,  economics and religion.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Citizen journalists in China&lt;/strong&gt; use Tor to write about
@@ -124,14 +124,14 @@
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Sting operations:&lt;/strong&gt;
     Similarly, anonymity allows law officers to engage in online
-    “undercover ” operations.  Regardless of how good an
-    undercover officer's “street cred” may be, if the
-    communications include IP ranges from police addresses, the cover is blown.
+    “undercover” operations.  Regardless of how good an
+    undercover officer's “street cred” may be, if his
+    communications come from IP addresses allocated to the police, his cover is \
blown.  &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Truly anonymous tip lines:&lt;/strong&gt;
     While online anonymous tip lines are popular, without anonymity
     software, they are far less useful.  Sophisticated sources understand that
-    although a name or email address is not attached to information, server
+    although a name or e-mail address is not attached to information, server
     logs can identify them very quickly.  As a result, tip line web sites that
     do not encourage anonymity are limiting the sources of their tips.
     &lt;/li&gt;
@@ -145,7 +145,7 @@
     &lt;li&gt;&lt;strong&gt;Human rights activists use Tor to anonymously report abuses from
     danger zones.&lt;/strong&gt;  Internationally, labor rights workers use Tor and other
     forms of online and offline anonymity to organize workers in accordance
-    with the Universal Declaration of Human Rights. Even though they are within
+    with the Universal Declaration of Human Rights. Even though their actions are \
within  the law, it does not mean they are safe. Tor provides the ability to
     avoid persecution while still raising a voice.
     &lt;/li&gt;
@@ -155,16 +155,16 @@
     change rely on Tor for basic privacy during legitimate activities.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;&lt;a href="http://hrw.org/doc/?t=internet"&gt;Human Rights \
                Watch&lt;/a&gt;&lt;/strong&gt;
-    recommends Tor in their report, “
-    &lt;a href="http://www.hrw.org/reports/2006/china0806/"&gt;Race to the Bottom: \
Corporate +    recommends Tor in their report,
+    “&lt;a href="http://www.hrw.org/reports/2006/china0806/"&gt;Race to the Bottom: \
Corporate  Complicity in Chinese Internet Censorship&lt;/a&gt;.” The study
     co-author interviewed Roger Dingledine, Tor project leader,
-    on Tor use.  They cover Tor in the section on how to breach the &lt;a
+    regarding Tor use.  They cover Tor in the section on how to breach the &lt;a
     href="http://www.hrw.org/reports/2006/china0806/3.htm#_Toc142395820"&gt;“Great
                
-    Firewall of China,”&lt;/a&gt; and recommend that human rights workers throughout
-    the globe use Tor for “secure browsing and communications.”
+    Firewall of China”&lt;/a&gt;, and recommend that human rights workers throughout
+    the globe use Tor for “secure browsing and communications”.
     &lt;/li&gt;
-    &lt;li&gt; Tor has consulted with and volunteered help to &lt;strong&gt;Amnesty \
International's +    &lt;li&gt;Tor has consulted with and volunteered help to \
                &lt;strong&gt;Amnesty International's
     recent &lt;a href="http://irrepressible.info/"&gt;corporate responsibility \
                campaign&lt;/a&gt;&lt;/strong&gt;.
     See also their &lt;a \
href="http://irrepressible.info/static/pdf/FOE-in-china-2006-lores.pdf"&gt;full  \
report&lt;/a&gt; on China Internet issues. @@ -172,7 +172,7 @@
     &lt;li&gt;&lt;a href="http://www.globalvoicesonline.org"&gt;Global Voices&lt;/a&gt;
     recommends Tor, especially for &lt;strong&gt;anonymous blogging&lt;/strong&gt;,
     throughout their &lt;a \
                href="http://advocacy.globalvoicesonline.org/projects/guide/"&gt;
-    web site.&lt;/a&gt;
+    web site&lt;/a&gt;.
     &lt;/li&gt;
     &lt;li&gt;In the US, the Supreme Court recently stripped legal protections from
     government whistleblowers.  But whistleblowers working for governmental
@@ -181,8 +181,8 @@
     &lt;/li&gt;
     &lt;li&gt;A contact of ours who works with a public health nonprofit in
     Africa reports that his nonprofit &lt;strong&gt;must budget 10% to cover various sorts \
                of corruption&lt;/strong&gt;,
-    mostly bribes and such.  When that percentage rises steeply, not only can they \
                not afford the money, but they can
-    not afford to complain — this is the point at which open objection can
+    mostly bribes and such.  When that percentage rises steeply, not only are they \
unable to afford the money, but they +    cannot afford to complain — this is \
the point at which open objection can  become dangerous.  So his nonprofit has been \
                working to
     &lt;strong&gt;use Tor to safely whistleblow on government corruption&lt;/strong&gt; in order \
to continue their work.  &lt;/li&gt;
@@ -191,17 +191,17 @@
     local residents to &lt;strong&gt;urge reform in the company&lt;/strong&gt; that dominated \
                the town's
     economic and government affairs. She is fully cognizant that the kind of
     organizing she was doing &lt;strong&gt;could lead to harm or “fatal
-    accidents.”&lt;/strong&gt;
+    accidents”&lt;/strong&gt;.
     &lt;/li&gt;
     &lt;li&gt;In east Asia, some labor organizers use anonymity to &lt;strong&gt;reveal \
                information
-    regarding sweatshops&lt;/strong&gt; that produce goods for western countries and to
+    regarding sweatshops&lt;/strong&gt; that produce goods for western countries, and to
     organize local labor.
     &lt;/li&gt;
     &lt;li&gt;
     Tor can help activists avoid government or corporate censorship that hinders \
                organization.
-    In one such case, a
-    &lt;a href="http://www.cbc.ca/canada/story/2005/07/24/telus-sites050724.html"&gt;Canadian \
                ISP blocked access to a union website used by their own employees&lt;/a&gt;
-    to help organize a strike.
+    In one such case,
+    &lt;a href="http://www.cbc.ca/canada/story/2005/07/24/telus-sites050724.html"&gt;a \
Canadian ISP blocked access to a union website&lt;/a&gt; +    used by its own employees to \
help organize a strike.  &lt;/li&gt;
     &lt;/ul&gt;
     
@@ -228,7 +228,7 @@
     safer civic engagement&lt;/strong&gt;.  Although it's often said that the poor do not \
                use
     online access for civic engagement, failing to act in their self-interests,
     it is our hypothesis (based on personal conversations and anecdotal
-    information) that it is precisely the “permanent record ”
+    information) that it is precisely the “permanent record”
     left online that keeps many of the poor from speaking out on the Internet.
     We hope to show people how to engage more safely online, and then at
     the end of the year, evaluate how online and offline civic engagement has
@@ -246,23 +246,23 @@
     of information on Internet attacks.  Such a repository requires members
     to report breaches to a central group, who correlates attacks to detect
     coordinated patterns and send out alerts.  But if a specific bank in St. Louis \
                is breached, they don't want an attacker watching the incoming
-    traffic to such a repository to be able to track where information is
-    coming from.  Even though every packet were encrypted, the IP
+    traffic to such a repository to where the report is
+    sent from.  Even if every packet were encrypted, the IP
     address would betray the location of a compromised system.  Tor allows
-    such repositories of sensitive information to resist compromises.
+    such repositories of sensitive information to resist eavesdropping.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Seeing your competition as your market does:&lt;/strong&gt;
-    If you try to check out a competitor's pricing, you may find no
+    If you try to check out your competitor's pricing, you may find no
     information or misleading information on their web site.  This is because
     their web server may be keyed to detect connections from competitors,
-    and block or spread disinformation to your staff.  Tor allows a business
-    to view their sector as the general public would view it.
+    and block your staff or spread disinformation to them.  Tor allows a business
+    to view its sector as the general public would view it.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Keeping strategies confidential:&lt;/strong&gt;
     An investment bank, for example, might not want industry snoopers to be
     able to track what web sites their analysts are watching.  The strategic
-    importance of traffic patterns, and the vulnerability of the surveillance
-    of such data, is starting to be more widely recognized in several areas
+    importance of traffic patterns, and the vulnerability of such data
+    to surveillance, is starting to be more widely recognized in several areas
     of the business world.
     &lt;/li&gt;
     &lt;li&gt;&lt;strong&gt;Accountability:&lt;/strong&gt;
@@ -290,11 +290,11 @@
     &lt;h2&gt;&lt;a class="anchor" href="#itprofessionals"&gt;IT Professionals use Tor&lt;/a&gt;&lt;/h2&gt;
     &lt;hr&gt;
     &lt;ul&gt;
-    &lt;li&gt;To verify IP based firewall rules: A firewall may have some policies that \
only allow certain IP addresses or ranges. Tor can be used to verify those \
                configurations by using an IP number outside of the company's alloted \
                IP block.&lt;/li&gt;
-    &lt;li&gt;To bypass their own security systems for sensitive professional activities: \
For instance, a company may have a strict policy regarding the material employees can \
view on the internet. A log review reveals a possible violation. Tor can be used to \
verify the information without an exception being put into corporate security \
systems.&lt;/li&gt; +    &lt;li&gt;To verify IP-address-based firewall rules: A firewall may have \
some policies that only allow certain IP addresses or ranges to access a site. Tor \
can be used to verify those configurations by using an IP number outside the \
company's alloted IP block.&lt;/li&gt; +    &lt;li&gt;To bypass their own security systems for \
sensitive professional activities: For instance, a company may have a strict policy \
regarding the material employees can view on the internet. When a log review reveals \
a possible violation, Tor can be used to verify the information without putting an \
exception into corporate security systems.&lt;/li&gt;  &lt;li&gt;To connect back to deployed \
services: A network engineer can use Tor to remotely connect back to services, \
without the need for an external machine and user account, as part of operational \
                testing.&lt;/li&gt;
-    &lt;li&gt;To access internet resources: Acceptable use policy for IT Staff and normal \
employees is usually different. Tor can allow unfettered access to the internet while \
                leaving standard security policies in place.&lt;/li&gt;
-    &lt;li&gt;To work around ISP network outages: Sometimes when an ISP is having routing \
or DNS problems, Tor can make internet resources available, when the actual ISP is \
malfunctioning. This can be invaluable is crisis situations. &lt;/li&gt; +    &lt;li&gt;To access \
Internet resources: Acceptable use policy for IT Staff and normal employees is \
usually different. Tor can allow unfettered access to the Internet while leaving \
standard security policies in place.&lt;/li&gt; +    &lt;li&gt;To work around ISP network \
outages: Sometimes when an ISP is having routing or DNS problems, Tor can make \
Internet resources available, when the actual ISP is malfunctioning. This can be \
invaluable is crisis situations.&lt;/li&gt;  &lt;/ul&gt;
     
     &lt;p&gt;
@@ -310,15 +310,15 @@
     &lt;p&gt; Like any technology, from pencils to cellphones, anonymity can be used for \
                both good and bad.  You have probably seen some of the vigorous
     debate (&lt;a href="http://www.wired.com/politics/security/commentary/securitymatters/2006/01/70000"&gt;pro&lt;/a&gt;,
  &lt;a href="http://www.edge.org/q2006/q06_4.html#kelly"&gt;con&lt;/a&gt;, and &lt;a
-    href="http://web.mit.edu/gtmarx/www/anon.html"&gt;academic&lt;/a&gt;) over anonymity. The \
                Tor project is based on the belief that anonymity is not
-    just a good idea some of the time — it is a requirement for a free and \
functioning society.  The &lt;a href="http://www.eff.org/issues/anonymity"&gt;EFF maintains \
a good overview&lt;/a&gt; of how anonymity was crucial to the founding of the United \
States.  Anonymity is recognized by US courts as a fundamental and important right. \
In fact, governments mandate anonymity in many cases themselves: +    \
href="http://web.mit.edu/gtmarx/www/anon.html"&gt;academic&lt;/a&gt;) over anonymity. The Tor \
Project is based on the belief that anonymity is not +    just a good idea some of \
the time — it is a requirement for a free and functioning society.  The EFF \
maintains &lt;a href="http://www.eff.org/issues/anonymity"&gt;a good overview of how \
anonymity was crucial to the founding of the United States&lt;/a&gt;.  Anonymity is \
recognized by US courts as a fundamental and important right. In fact, governments \
                mandate anonymity in many cases themselves:
     &lt;a href="https://www.crimeline.co.za/default.asp"&gt;police tip lines&lt;/a&gt;,
     &lt;a href="http://www.texasbar.com/Content/ContentGroups/Public_Information1/Legal_Resources_Consumer_Information/Family_Law1/Adoption_Options.htm#sect2"&gt;adoption \
                services&lt;/a&gt;,
     &lt;a href="http://writ.news.findlaw.com/aronson/20020827.html"&gt;police officer \
                identities&lt;/a&gt;,
     and so forth. It would be impossible to rehash the entire anonymity debate here \
                — it is too large an issue with too many nuances, and there
     are plenty of other places where this information can be found. We do have a &lt;a \
                href="&lt;page docs/faq-abuse&gt;"&gt;Tor abuse&lt;/a&gt; page describing some of
     the possible abuse cases for Tor, but suffice it to say that if you want to \
                abuse the system, you'll either find it mostly closed for your
-    purposes (e.g. the majority of Tor relays do not support SMTP in order to \
prevent anonymous email spamming), or if you're one of the +    purposes (e.g., the \
majority of Tor relays do not support SMTP, in order to prevent anonymous e-mail \
                spamming), or if you're one of the
     &lt;a href="http://www.schneier.com/blog/archives/2005/12/computer_crime_1.html"&gt;Four \
                Horsemen of the Information Apocalypse&lt;/a&gt;,
     you have better options than Tor. While not dismissing the potential abuses of \
                Tor,
     this page shows a few of the many important ways anonymity is used online \
today.&lt;/p&gt;


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101010071315</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-10 07:13:15-0400</timestampReceived><subject>Re: [or-cvs] r23534: {website} i doubt andreas wanted us to say</subject><body>


On Sun, 10 Oct 2010 00:41:55 +0000 (UTC)
Roger Dingledine &lt;arma@torproject.org&gt; wrote:

&gt; Author: arma
&gt; Date: 2010-10-10 00:41:55 +0000 (Sun, 10 Oct 2010)
&gt; New Revision: 23534
&gt; 
&gt; Modified:
&gt; website/trunk/donate/en/donate.wml
&gt; Log:
&gt; i doubt andreas wanted us to say "SEPA[0]" on the website
&gt; 
&gt; 
&gt; Modified: website/trunk/donate/en/donate.wml
&gt; ===================================================================
&gt; --- website/trunk/donate/en/donate.wml	2010-10-10 00:26:26 UTC (rev 23533)
&gt; +++ website/trunk/donate/en/donate.wml	2010-10-10 00:41:55 UTC (rev 23534)
&gt; @@ -180,7 +180,7 @@
&gt; BLZ: 52040021&lt;/p&gt;
&gt; &lt;p&gt;&lt;em&gt;For European bank transfers, we have an arrangement with &lt;a \
&gt; href="http://ccc.de"&gt;CCC in Germany&lt;/a&gt; to provide tax-deductible donations for \
&gt; Europeans:&lt;/em&gt;&lt;/p&gt; &lt;ul&gt;
&gt; -          &lt;li&gt;Residents from any of the 31 SEPA[0] member states can wire up to \
&gt; 50.000 Euro at the cost of a domestic transaction (ie, usually free if submitted \
&gt; electronically).&lt;/li&gt; +          &lt;li&gt;Residents from any of the 31 &lt;a \
&gt; href="http://en.wikipedia.org/wiki/Single_Euro_Payments_Area"&gt;SEPA&lt;/a&gt; member \
&gt; states can wire up to 50.000 Euro at the cost of a domestic transaction (ie, \
&gt; usually free if submitted electronically).&lt;/li&gt;

s/ie/i.e./


Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101018024622</emailId><senderName>Justin Samuel</senderName><senderEmail>js@justinsamuel.com</senderEmail><timestampReceived>2010-10-18 02:46:22-0400</timestampReceived><subject>RFC/proposal for Thandy changes</subject><body>

Hi all,

Here's my first pass at proposed Thandy changes as discussed on irc a couple
of weeks ago.

Justin

0. Proposed Thandy Changes
==========================

This is a set of proposals that includes a section of simple changes that can
be considered on their own (Section 1) as well as a more fundamental Thandy
restructuring proposal (Section 2).

This isn't meant to be at the level of detail needed for a spec and subsequent
implementation. This is to get feedback and promote discussion. It's not an
official proposal at this point but more of a request for comment.

A few relevant documents for reference:

 * Thandy spec:
   https://gitweb.torproject.org/thandy.git/blob_plain/HEAD:/specs/thandy-spec.txt
 * TUF spec: https://www.updateframework.com/browser/specs/tuf-spec.txt
 * High-level differences between Thandy and TUF:
   https://www.updateframework.com/wiki/ThandyDifferences
 * Paper on TUF: http://www.freehaven.net/~arma/tuf-ccs2010.pdf

1. Individual Thandy Changes
============================

These are changes that could be made to Thandy without major overhaul and can
be considered separately of the restructuring proposal (Section 2).

1.1. Multiple File Hashes
-------------------------

Make all file hashes be a set of (algorithm, digest) pairs rather than a
single digest of a predefined algorithm. Thus, instead of describing a file's
hash in metadata with:

  "hash" : 349dceb3de2db82e363c3d73063f031c56c5aac5

It would be described as:

  "hash" : ["sha1" : 349dceb3de2db82e363c3d73063f031c56c5aac5,
            "sha256" : 95eaa1682a99fba24b26c94499b545...747d7759ba845c8b5c]

Note that it could still be allowed to list only one digest. This just allows
the ability to use multiple hashes. It's up to the client implementation to
determine which are checked.

1.2. Refer to Keys by Their ID when Delegating
----------------------------------------------

In the Thandy key list file (the "root metadata"), the full keys are listed
each time they are referenced. This may decrease the human readability of the
key list.

An alternative approach is to use a separate section in the file that defines
the keys that will be used in the rest of this metadata file, list them with
their ID (a hash of the canonical format of the key), and then refer to them
later by this ID. This is similar to how signatures are already done in
Thandy: the ID of the key is listed along with the signature.

An implementation of this needs to check for ID collisions when reading keys
from metadata. It's fine to see the same key specified with the same ID, but a
different key with the same ID as one that has been seen indicates something
wrong. (Note that the implementation would always check that the specified IDs
are correct for the corresponding key, even without collisions.)

1.3. Indicate Signature Thresholds
----------------------------------

The current Thandy spec isn't clear about how multiple keys are specified for
a role. There also doesn't appear to be a way to specify a threshold that is
less than the total number of keys. The method of specifying multiple keys
should be made clear and the ability to indicate the number of signatures of
those keys that are required should be added. (There's an example of how this
can be specified in metadata in Section 2.2.)

1.4. Add a 'Release' Role
-------------------------

Thandy currently lists the hashes of all other metadata in the timestamp file.
There are certain attacks that could be mitigated if the Timestamp role signed
a separate Release role's metadata that listed the hashes of all other
metadata files. The idea here is that an attacker who compromises only the
Timestamp role cannot present clients with a mix-and-match of signed metadata
files that were available from the repository at different times. The
separation helps because the Timestamp role has a higher likelihood of key
compromise because the keys are used in an automated fashion, whereas the
Release role would not be used in an automated fashion.

Though the idea of a metadata mix-and-match attack is in general something
worth keeping in mind, it may be the case that Thandy isn't at much risk
because bundles serve a similar role of grouping together package versions in
a way that attackers can't cause the clients to use an unintended combination
of package versions. The risk to Thandy depends on whether packagers ever
replace a package version rather than increment it (they aren't supposed to
ever replace a version) and whether Thandy bundles always specify exact
package versions rather than minimum/maximum package versions or package
version ranges.

2. Thandy Restructuring Proposal
================================

Primary goal: Keep Thandy's concepts of bundles and packages but overlay them
on top of the generic 'targets' approach of TUF.

Note: This proposal is not advocating using/maintaining/relying on TUF as a
separate project. That depends on factors such as the future of TUF according
to the current TUF maintainers, whether Python is an appropriate choice for
Windows clients, etc.

2.1 Approach
------------

Two separate layers:

  1. An authentication layer that downloads and authenticates opaque 'target'
     files according to metadata it understands that lists hashes and sizes of
     the target files. This layer doesn't understand what bundles and packages
     are.

  2. A decision/installation layer that uses the authentication layer to
     download bundle/package info and associated files. This layer doesn't
     know the details of the authentication mechanisms or roles; it gets
     files from the authentication layer that the authentication layer has
     already authenticated.

     * Note that the update decision and installation code are probably
       separate, but for the sake of this proposal all that matters is that
       the Thandy authentication layer is logically separate from the rest of
       Thandy.

For the authentication layer, we start with the following roles (the same as
TUF uses):

  * Root
    o Root of trust for the entire PKI. Indicates through signed
      metadata which keys are trusted for the Release, Targets, Timestamp, and
      Mirror roles.

  * Timestamp
    o Signs a frequently regenerated timestamp file with a short
      expiration indicating the most recent release metadata.

  * Release
    o Signs the release metadata which lists the hashes and sizes of all
      other metadata files (other than the timestamp file). Note that
      bundleinfo and pkginfo are not considered metadata at the authentication
      layer.

  * Targets
    o Signs a metadata file that lists the hashes and sizes of target
      files: the files that the decision layer ultimately wants to obtain.
    o Can delegate to sub-roles the responsibility for providing target
      files from specific paths on the repository (e.g. Role A is trusted to
      provide files from the /targets/role_a/ directory).

  * Mirror
    o Signs a metadata file that lists the locations and details of
      repository mirrors.

From here we use delegation by the Targets role to create the roles for
bundlers and packagers. The top-level Targets role delegates a separate role
for each bundle and each package.

The targets role hierarchy looks like this (with many more bundle and package
roles):

Root
`-- Targets
    |-- bundles/tor-browser-stable
    |-- bundles/tor-browser-beta
    `-- pkgs/openssl

Each bundle version and package version that bundlers and packagers released
has a separate bundleinfo and pkginfo file, respectively. These bundleinfo and
pkginfo files are opaque to the authentication layer: it considers them target
files like any other. However, the decision layer understands the contents of
these files and uses them to make subsequent download and installation
decisions (with the downloads always being done through the authentication
layer).

2.2. Repository Structure
-------------------------

Top-level metadata files are:

/meta/root.txt
/meta/release.txt
/meta/timestamp.txt
/meta/targets.txt
/meta/mirrors.txt

The /meta/targets.txt file would include a delegations section such as:

delegations : {
    keys : {
        'ABC...' : { details },
        '123...' : { details },
        ...
      },
    roles : {
        'bundles/tor-browser-stable' : {
            keys : ['ABC...', '123...'],
            threshold : 2,
            paths : ['bundles/tor-browser-stable/**'],
          },
        'pkgs/openssl' : {
            keys : ['DEF...', '456...'],
            threshold : 2,
            paths : ['pkgs/openssl/**'],
          },
        ...
      }
  }

The above would mean that the top-level Targets role had delegated a role
whose full name would be targets/bundles/tor-browser-stable (as it is
delegated by the targets role, the prepended targets/ is implicit in the
delegated role's name). This role for the tor-browser-stable bundle would be
trusted for the specified paths relative to the repository's targets/
directory. Thus, a specific version's bundleinfo file created by the bundler
could be placed on the repository at, for example:

  /targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.bundleinfo

(Note that this bundle role is trusted for all targets files matching the path
'bundles/tor-browser-stable/**' under the repository's targets/ directory, as
specified when this role was created through the above delegation.)

The bundle maintainer would sign a metadata file listing the hash and size of
this bundleinfo. This metadata would be placed on the repository at:

  /meta/targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.txt

(Note that the basename of these files isn't crucial to this aspect of the
design. They don't need to repeat the path info, though that's probably
helpful for humans.)

More generally, the metadata location is:

  /meta/ROLE_NAME/[ANY_PATH/]ANY_NAME.txt

Packages are similar to bundles with the difference that there are one or more
target files in addition to the pkginfo file. A package maintainer may supply
the following files to be placed on the repository:

  /targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.pkginfo
  /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll
  /targets/pkgs/openssl/win32/0.9.8m/ssleay32.dll

The hashes and sizes of these files are listed in metadata signed by the
targets/pkgs/openssl role (that is, the openssl package maintainer's role).
This metadata would be placed on the repository at:

  /meta/targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.txt

2.3. Update Procedure
---------------------

The update procedure is:

  * The decision layer uses the authentication layer to retrieve a list of
    all available bundleinfo files.
    o Implementation: the decision layer asks the authentication layer
      for a list of all available metadata file paths/names. The
      authentication layer obtains this information from the release metadata.
  * Looking at the paths/names of available bundleinfo files, the decision
    layer identifies whether there is a newer version of a bundle it is
    interested in.
    o Implementation: the bundle names, OS, arch, and bundle version are
      all contained in paths of the available bundle metadata files.
  * The decision layer notices a bundle version in the list that it wants
    and uses the authentication layer to retrieve the bundleinfo file for that
    version.
  * The decision layer reads the contents of the bundleinfo file which
    indicate the necessary package versions and any other info the decision
    layer needs.
  * The decision layer uses the authentication layer to retrieve the pkginfo
    files for each of the package versions that it wants.
  * The decision layer understands the contents of the pkginfo files. These
    files indicate the individual files that are part of this version of the
    package.
  * The decision layer uses the authentication layer to retrieve the
    individual files (e.g. /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll)
    that are needed.
  * The decision layer hands off the relevant installation instructions
    (from the bundleinfo and pkginfo files) and individual package files to
    the code that performs the installation/upgrade.

2.4.bundleinfo and pkginfo
--------------------------

As the contents of the bundleinfo and pkginfo are opaque to the authentication
layer, essentially there are two completely separate sets of metadata in this
design. It would make sense to have them use the same format (e.g. Canonical
JSON) and be parsed/generated by the same code.

The bundleinfo and pkginfo files would contain largely the same information as
these files do in the current Thandy spec (though they wouldn't be directly
signed but rather would be described in signed authentication-layer metadata).

There are a few reasons it is good to have the bundleinfo/pkginfo be opaque to
the authentication layer. One reason is that changes to bundleinfo/pkginfo
fields can be tested independently of the authentication layer. Also,
non-backwards-compatible changes could be made by introducing a new file name
such as bundleinfo.v2 which would be effectively invisible to legacy clients.

2.5. Differences with TUF
-------------------------

The authentication layer's metadata and roles are very similar to the current
TUF specification. However, there are a few differences.

TUF currently does not allow a single role to directly delegate multiple roles
deep. In TUF, one would need the following role structure:

Root
`-- Targets
    |-- bundles
    |   `-- tor-browser-stable
    `-- pkgs
        `-- openssl

That is, the Targets role would have to first delegate a bundles role which
then delegates a tor-browser-stable role.

Relatedly, TUF gives each delegated role the ability to sign a single metadata
file whose name is exactly the role's name. This may be non-ideal for Thandy
because bundlers and packagers would need to keep a continuously growing
metadata file that lists all of the versions that they want to be available to
clients or, alternatively, delegate subroles for each version in order to use
separate metadata files for each. (Note that this is talking about the
authentication layer's metadata, not bundleinfo and pkginfo files.)

In contrast, with this proposal, a bundler/packager would sign a metadata file
that lists only the new target files they are adding to the repository.---This
isn't a case where there's one correct way to do things, but my understanding
is that Thandy would like old versions to remain available within their
expiration times and would like bundlers/packagers to not have to deal with
issues such as accidentally removing an old version they didn't mean to remove
when generating and signing metadata to make a new version available.

[end of proposal]
</body></email><email><emailId>20101020033423</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-10-20 03:34:23-0400</timestampReceived><subject>Re: hidden service</subject><body>

On Tue, Oct 19, 2010 at 08:25:26PM -0700, Robert Ransom wrote:
&gt; &gt; I think the problem is in the directory server's configuration, how can I set up \
&gt; &gt; it to support the hidden service? Is there any example?
&gt; 
&gt; I think the option you need to set for current Tor versions is
&gt; ???HidServDirectoryV2???.  Add ???HidServDirectoryV2 1??? to at least one
&gt; relay's torrc.

HidServDirectoryV2 has defaulted to 1 since Tor 0.2.1.6-alpha. So setting
that line should have no effect.

&gt; You may also want to add ???MinUptimeHidServDirectoryV2 0
&gt; seconds??? to the directory authority's torrc.

This one should work well though.

But if you're running Tor 0.2.1.x, you'll still get complaints when
it tries to find an original (centralized) hidden service authority in
parallel, and finds that your dirserver lines don't list any. I think
the best fix there is to move to Tor 0.2.2.x.

Thanks!
--Roger


</body></email><email><emailId>20101026212055</emailId><senderName>Dan Levin</senderName><senderEmail>dlevin@net.t-labs.tu-berlin.de</senderEmail><timestampReceived>2010-10-26 21:20:55-0400</timestampReceived><subject>Announcing the Release of a Userspace TCP Stack</subject><body>

At Mike Perry's request, I'd like to announce the recent availability of a tunable, \
BSD-licensed Userspace TCP Stack. I'll just post my original email exchange from \
yesterday below, which includes all the details:

------------------------ 8&lt;  ------------------------

Hi Mike,
I hope my TCP code may prove useful. Our code comes out of a research
project for enabling legacy TCP-speaking end-hosts to interface with
new, clean slate wireless mesh transport protocols. Our sources can be
obtained as part of the TCPSpeaker Element of the Click Modular Router
project:

git clone git://bowl.net.t-labs.tu-berlin.de/click.git
git checkout tcpspeaker

All TCP-specific code is contained in the two files:
elements/local/tcpspeaker.cc
elements/local/tcpspeaker.hh

To build the code as a click element (which I'm not certain may be
your desired use case)
./configure --disable-linuxmodule --enable-userlevel --enable-local&amp;&amp;
make

To get a high-level overview of our design, which may assist in your
retooling it to your needs, here's a video from the SyClick workshop
which gives a nice explanation:
http://www.syclick.ua.ac.be/content/multiflowdispatcher-and-tcpspeaker-video

A 3-page abstract:
http://www.net.t-labs.tu-berlin.de/papers/LSMS-TCDSSS-10a.pdf
A (slightly longer) Thesis:
http://www.net.t-labs.tu-berlin.de/~dlevin/mthesis/main.pdf

This thesis contains a lot (possibly too much) documentation on the
TCPSpeaker Click Element. The implementation section may give some
useful insights. At the end in the Appendix, there are some tables
documenting the TCPSpeaker element handlers. Finally, if anyone wishes
to try running this within click, there are some example click
configurations given in the click repository under
conf/tcpspeaker-{avila,avila-baseline}.click

------------------------ 8&lt;  ------------------------

I'm happy to provide whatever further information or assistance I can, if our code \
                appears useful to anyone.
-Dan


</body></email><email><emailId>20101027010013</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-10-27 01:00:13-0400</timestampReceived><subject>Re: Torperf</subject><body>


Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; &gt; On Oct 15, 2010, at 4:13 AM, Mike Perry wrote:
&gt; &gt;&gt; I would love to have all of these datastream available for comparison
&gt; &gt;&gt; when various events and perf tweaks change the network. In fact, I
&gt; &gt;&gt; would love it if we could have the following 5 torperf runs logging
&gt; &gt;&gt; continuously and all overlayed on the main Torperf metrics graph:
&gt; &gt;&gt;
&gt; &gt;&gt; 1. Fastest 3 guards by network status
&gt; &gt;&gt; 2. Fastest 3 guards by ratio of ns_bw/desc_bw
&gt; &gt;&gt; 3. EntryGuards=0 (default current torperf)
&gt; &gt;&gt; 4. Slowest 3 guards by network status
&gt; &gt;&gt; 5. Slowest 3 guards by ratio of ns_bw/desc_bw
&gt; 
&gt; Okay, I think we can continue running the 3 or 5 Torperf runs with
&gt; modified guard node selection algorithms in the future if we think the
&gt; data is useful. However, note that
&gt; 
&gt; a) the 3 Torperf runs for #1919 run on some machine which is, AFAIK, not
&gt; one of our VMs and which may or may not host the 3 or even 5 Torperf
&gt; runs in the future,
&gt; 
&gt; b) I have no idea how to add 2 more Torperf runs with the guard
&gt; selection algorithms you stated, and

I can update the #1919 script to handle runs #2 and #5. I've added it
to my TODO list.

&gt; &gt; The problem wasn't that the script was taking a lot of RAM, but rather
&gt; &gt; that each torperf instance comes with its own tor instance. Spinning
&gt; &gt; up another 9 clients caused the memory issues.
&gt; 
&gt; I think we can ask for more memory for the VM running this.

Ok, let's do that and put them all there.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20101027064449</emailId><senderName>Erik de Castro Lopo</senderName><senderEmail>mle+tools@mega-nerd.com</senderEmail><timestampReceived>2010-10-27 06:44:49-0400</timestampReceived><subject>Re: polipo-tor debian package</subject><body>

travis+ml-tor-dev@subspacefield.org wrote:

&gt; I put this together (attached).
&gt; 
&gt; Would people care to look at it and tell me if you think it's right?

If you want people to look at the packaging, you should provide
the Debian .dsc file, the original tarball and a diff.gz file
(assuming this packaging of some upstream source).

If yuo really want someone to look at the Debian packaging, you would
be better off emailing the debian-mentors mail list.

&gt; Config file is direct from your page.
&gt; 
&gt; I can tar up the source (including debian dir) if you want.

You should be using something like debuild to build a debian package
and that will provide the three files I was asking about.

Building Debian packages is very well documented on debian.org.

&gt; My emails do not have attachments;

This email did have an attachment.

Erik
-- 
----------------------------------------------------------------------
Erik de Castro Lopo
http://www.mega-nerd.com/
</body></email><email><emailId>20101029093315</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-29 09:33:15-0400</timestampReceived><subject>Re: [or-cvs] [tor/master 4/6] Remove "is this too slow?" XXXX</subject><body>


On Fri, 15 Oct 2010 16:07:33 +0000 (UTC)
nickm@torproject.org wrote:

&gt; Author: Nick Mathewson &lt;nickm@torproject.org&gt;
&gt; Date: Fri, 15 Oct 2010 11:21:33 -0400
&gt; Subject: Remove "is this too slow?" XXXX comments for code not appearing in profiles
&gt; Commit: 247ce5876a56cdbbd6a7b3f501476ff10f4bce5e
&gt; 
&gt; ---
&gt;  src/or/circuitbuild.c  |    2 --
&gt;  src/or/networkstatus.c |    3 +--
&gt;  src/or/policies.c      |    2 +-
&gt;  src/or/routerlist.c    |    7 -------
&gt;  4 files changed, 2 insertions(+), 12 deletions(-)
&gt; 
&gt; diff --git a/src/or/circuitbuild.c b/src/or/circuitbuild.c
&gt; index a4cdf81..9c7262a 100644
&gt; --- a/src/or/circuitbuild.c
&gt; +++ b/src/or/circuitbuild.c
&gt; @@ -3032,8 +3032,6 @@ choose_good_entry_server(uint8_t purpose, cpath_build_state_t *state)
&gt;      nodelist_add_node_family(excluded, node);
&gt;    }
&gt;    if (firewall_is_fascist_or()) {
&gt; -    /*XXXX This could slow things down a lot; use a smarter implementation */
&gt; -    /* exclude all ORs that listen on the wrong port, if anybody notices. */

The second comment line here should not have been removed.

&gt;      smartlist_t *nodes = nodelist_get_list();
&gt;      SMARTLIST_FOREACH(nodes, const node_t *,node, {
&gt;        if (!fascist_firewall_allows_node(node))


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101029140044</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2010-10-29 14:00:44-0400</timestampReceived><subject>Re: Descriptor fingerprint format</subject><body>

On 2010-10-29 02:23, grarpamp wrote:
&gt; Descriptor fingerprints look like this:
&gt; opt fingerprint 0001 AC1F 9AE6 9A00 3C5E 6F02 73CB D69E C6E7 6926
&gt; ...
&gt; opt fingerprint FFEB 470C F379 9E9C 5956 8521 8627 9ED5 55AB 1340
&gt; 
&gt; It's an extra routine to remove or add the spaces for scripting, with
&gt; the control port, etc. And who really uses them in a human fashion
&gt; with spaces anyways, this isn't a keysigning party :)
&gt; 
&gt; It also uses about 9 spaces x ~3300+ descriptors ~= 30,000 bytes
&gt; of traffic for one client to pull the entire relay list. Multiply that
&gt; by number of clients[?] x the frequency[?] ~= bandwidth wasted.
&gt; 
&gt; Maybe another ~10,000+ bytes x clients x freq could be saved by not
&gt; publishing the junk after the first left bracket '[' in the windows
&gt; platform lines.
&gt; 
&gt; Any ideas on removing these two someday?

Why not just run a compression algorithm over them, or even better, just
do everything in binary format?

Greets,
 Jeroen
</body></email><email><emailId>20101029153821</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-10-29 15:38:21-0400</timestampReceived><subject>Re: Tor - Black Belt Edition for Windows - Tor Client + Tor	Server(with</subject><body>

Hi Roger,

Thanks for getting back to me so quickly. I have read your email and 
admit to being a little naive. For one I did not realise Tor is pushing 
/ pulling 600mb per second !
I note your raised points about branding, and that I could be implying 
its an official version, which I should not be doing in any case.

The reason for the 2 stacks is to enable hibernation of one without 
affecting client behaviour, as you identified. It will be great when we 
can both hibernate and still maintain client connectivity.

Based on your comments and those of Robert Ransom, I think its best to 
cease work on this version and not distribute it. As you mentioned 2 
stacks will result in double the descriptor traffic - which is not a 
good idea. I was aiming this at home users who may have a small amount 
of bandwidth to spare, but as you again mentioned, it appears this may 
not help all that much, given the volumes in the network now.

Thanks for the comments and input. I am relieved I sought some feedback 
before taking things any further.

With kind regards,
Cav Edwards



Roger Dingledine wrote:
&gt; On Thu, Oct 28, 2010 at 06:44:31AM +0100, Cav wrote:
&gt;   
&gt;&gt; We are just completing the 2010-11 release of Tor - Black Belt Edition.-  
&gt;&gt; running on Windows.
&gt;&gt;     
&gt;
&gt; Ah ha -- I remember seeing the "black belt edition" thing on a torrent
&gt; somewhere, and wondered who was doing it. Now we know -- great.
&gt;
&gt;   
&gt;&gt; This version, with some tweaking, actually includes 2 vidalia+tor  
&gt;&gt; stacks, running side by side.
&gt;&gt;
&gt;&gt; One as a server, providing 15MB of bandwidth per day.
&gt;&gt; The other as an unrestricted client.
&gt;&gt;
&gt;&gt; The use of the server, and its auto-starting, on Windows user-login is  
&gt;&gt; controlled through the Start menu and install-time options. This is to  
&gt;&gt; ensure that no user is 'forced' to run an exit relay without their  
&gt;&gt; knowledge.
&gt;&gt;
&gt;&gt; I am hoping for a wide exposure of this software version.
&gt;&gt; Just 1000 users of this version would be capable of adding 15GB !!! of  
&gt;&gt; Server bandwidth PER DAY to the Tor network, with each user providing  
&gt;&gt; their small amount. Surely this will help the Tor network immensely.
&gt;&gt;     
&gt;
&gt; Four thoughts at first:
&gt;
&gt; A) Why separate Tors and Vidalias? Tor is designed to be able to operate
&gt; as both a client and a relay at the same time. This is important because
&gt; every operating Tor fetches directory information over the course of
&gt; the day, and with hundreds of thousands of users, it adds up. Two Tors
&gt; means twice as much directory fetching load.
&gt;
&gt; I guess one answer is that if you're using Tor's hibernation feature,
&gt; then the client functionality shuts off as well when Tor hibernates. I
&gt; just opened a trac entry to remind us about that:
&gt; https://trac.torproject.org/projects/tor/ticket/2129
&gt;
&gt; B) 15MB per day is really not very much. First, notice that the Tor
&gt; network as a whole averages 600MB/s of traffic.
&gt; http://metrics.torproject.org/network.html#bandwidth
&gt; That's 52 TB a day. To double the capacity of the network, at 15MB per
&gt; relay, you'd need to get 3.5 million people running it. But it's actually
&gt; worse than that -- each Tor relay generates a server descriptor that
&gt; clients need to get in order to use it. So figuring a very conservative
&gt; 100000 Tor clients running right now, and a conservative 500 bytes that
&gt; each user needs to fetch each day, that's 50MB that's going to be spent
&gt; just distributing the server descriptor to all the clients. So you really
&gt; want to be offering a few gigabytes per day before the numbers start to
&gt; become workable.
&gt;
&gt; C) Many users are behind a nat that doesn't allow inbound connections.
&gt; Vidalia supports upnp, but I'm not sure how many users have routers that
&gt; support it. I wonder what approaches we can use to increase the chances
&gt; that users actually make sure their Tor relay is reachable.
&gt;
&gt; D) The name "Tor black belt edition" sure implies that you're providing
&gt; an official Tor bundle. I wonder if there's a good name that doesn't
&gt; confuse users about who is making the package? See also
&gt; https://www.torproject.org/docs/trademark-faq.html.en
&gt;
&gt; --Roger
&gt;
&gt;
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi Roger,&lt;br&gt;
&lt;br&gt;
Thanks for getting back to me so quickly. I have read your email and
admit to being a little naive. For one I did not realise Tor is pushing
/ pulling 600mb per second !&lt;br&gt;
I note your raised points about branding, and that I could be implying
its an official version, which I should not be doing in any case.&lt;br&gt;
&lt;br&gt;
The reason for the 2 stacks is to enable hibernation of one without
affecting client behaviour, as you identified. It will be great when we
can both hibernate and still maintain client connectivity.&lt;br&gt;
&lt;br&gt;
Based on your comments and those of Robert Ransom, I think its best to
cease work on this version and not distribute it. As you mentioned 2
stacks will result in double the descriptor traffic - which is not a
good idea. I was aiming this at home users who may have a small amount
of bandwidth to spare, but as you again mentioned, it appears this may
not help all that much, given the volumes in the network now.&lt;br&gt;
&lt;br&gt;
Thanks for the comments and input. I am relieved I sought some feedback
before taking things any further.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Roger Dingledine wrote:
&lt;blockquote cite="mid:20101028082852.GZ3145@moria.seul.org" type="cite"&gt;
  &lt;pre wrap=""&gt;On Thu, Oct 28, 2010 at 06:44:31AM +0100, Cav wrote:
  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;We are just completing the 2010-11 release of Tor - Black Belt \
Edition.-   running on Windows.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
Ah ha -- I remember seeing the "black belt edition" thing on a torrent
somewhere, and wondered who was doing it. Now we know -- great.

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;This version, with some tweaking, actually includes 2 vidalia+tor  
stacks, running side by side.

One as a server, providing 15MB of bandwidth per day.
The other as an unrestricted client.

The use of the server, and its auto-starting, on Windows user-login is  
controlled through the Start menu and install-time options. This is to  
ensure that no user is 'forced' to run an exit relay without their  
knowledge.

I am hoping for a wide exposure of this software version.
Just 1000 users of this version would be capable of adding 15GB !!! of  
Server bandwidth PER DAY to the Tor network, with each user providing  
their small amount. Surely this will help the Tor network immensely.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
Four thoughts at first:

A) Why separate Tors and Vidalias? Tor is designed to be able to operate
as both a client and a relay at the same time. This is important because
every operating Tor fetches directory information over the course of
the day, and with hundreds of thousands of users, it adds up. Two Tors
means twice as much directory fetching load.

I guess one answer is that if you're using Tor's hibernation feature,
then the client functionality shuts off as well when Tor hibernates. I
just opened a trac entry to remind us about that:
&lt;a class="moz-txt-link-freetext"
 href="https://trac.torproject.org/projects/tor/ticket/2129"&gt;https://trac.torproject.org/projects/tor/ticket/2129&lt;/a&gt;


B) 15MB per day is really not very much. First, notice that the Tor
network as a whole averages 600MB/s of traffic.
&lt;a class="moz-txt-link-freetext"
 href="http://metrics.torproject.org/network.html#bandwidth"&gt;http://metrics.torproject.org/network.html#bandwidth&lt;/a&gt;
 That's 52 TB a day. To double the capacity of the network, at 15MB per
relay, you'd need to get 3.5 million people running it. But it's actually
worse than that -- each Tor relay generates a server descriptor that
clients need to get in order to use it. So figuring a very conservative
100000 Tor clients running right now, and a conservative 500 bytes that
each user needs to fetch each day, that's 50MB that's going to be spent
just distributing the server descriptor to all the clients. So you really
want to be offering a few gigabytes per day before the numbers start to
become workable.

C) Many users are behind a nat that doesn't allow inbound connections.
Vidalia supports upnp, but I'm not sure how many users have routers that
support it. I wonder what approaches we can use to increase the chances
that users actually make sure their Tor relay is reachable.

D) The name "Tor black belt edition" sure implies that you're providing
an official Tor bundle. I wonder if there's a good name that doesn't
confuse users about who is making the package? See also
&lt;a class="moz-txt-link-freetext"
 href="https://www.torproject.org/docs/trademark-faq.html.en"&gt;https://www.torproject.org/docs/trademark-faq.html.en&lt;/a&gt;


--Roger



  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20101031053731</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 05:37:31-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 225/291] user-contributed</subject><body>


On Sat, 30 Oct 2010 00:32:43 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Sun, 17 Oct 2010 12:28:58 -0700
&gt; Subject: user-contributed rule for ISIS.poly.edu
&gt; Commit: 05e8a87bf573e0daa021833f4310389c717b77be
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/ISIS.xml |    3 +++
&gt;  1 files changed, 3 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/chrome/content/rules/ISIS.xml
&gt; 
&gt; diff --git a/src/chrome/content/rules/ISIS.xml b/src/chrome/content/rules/ISIS.xml
&gt; new file mode 100644
&gt; index 0000000..520eb09
&gt; --- /dev/null
&gt; +++ b/src/chrome/content/rules/ISIS.xml
&gt; @@ -0,0 +1,3 @@
&gt; +&lt;ruleset name="ISIS"&gt;
&gt; +  &lt;rule from="^http://isis.poly.edu/" to="https://isis.poly.edu/"/&gt;
&gt; +&lt;/ruleset&gt;

The ‘from' attribute value has unescaped "." characters.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101031054743</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 05:47:43-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 006/291] updates to T-Mobile</subject><body>


On Sat, 30 Oct 2010 00:32:33 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Fri, 8 Oct 2010 16:37:02 -0700
&gt; Subject: updates to T-Mobile rule for T-Mobile UK
&gt; Commit: 40cef8d99ccc2ab57cb4eb8b9bb74ee0b348fd7d
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/T-Mobile.xml |    1 +
&gt;  1 files changed, 1 insertions(+), 0 deletions(-)
&gt; 
&gt; diff --git a/src/chrome/content/rules/T-Mobile.xml b/src/chrome/content/rules/T-Mobile.xml
&gt; index ae206a4..6b4f477 100644
&gt; --- a/src/chrome/content/rules/T-Mobile.xml
&gt; +++ b/src/chrome/content/rules/T-Mobile.xml
&gt; @@ -6,4 +6,5 @@
&gt;    &lt;rule from="^http://(www\.)?t-mobile\.com/" to="https://www.t-mobile.com/"/&gt;
&gt;    &lt;rule from="^http://(www\.)?tmobile\.com/" to="https://www.tmobile.com/"/&gt;
&gt;    &lt;rule from="^http://my\.t-?mobile\.com/" to="http://my.t-mobile.com/"/&gt;

This should say " to="https://my.t-mobile.com/" ".

&gt; +  &lt;rule from="^http://(www\.)?t-mobile\.co\.uk/" to="https://www.t-mobile.co.uk/" /&gt;
&gt;  &lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101020021853</emailId><senderName>"torsecurity"</senderName><senderEmail>torbridges.security@gmail.com</senderEmail><timestampReceived>2010-10-20 02:18:53-0400</timestampReceived><subject>hidden service</subject><body>

hello, I want to set up a hidden server in my private network. I have successfully \
build a private tor network, including one directory server and 4 OR nodes, but when \
I add hidden service in one of the OR node, it has an error, the log is:

[warn] Publishing server descriptor to directory authorities of type 'Hidden \
service', but no authorities of that type listed!

I think the problem is in the directory server's configuration, how can I set up it \
to support the hidden service? Is there any example?


2010-10-20



Gaofeng He


[Attachment #3 (text/html)]

&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"&gt;
&lt;HTML&gt;&lt;HEAD&gt;
&lt;META content="text/html; charset=us-ascii" http-equiv=Content-Type&gt;
&lt;STYLE&gt;BLOCKQUOTE {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; MARGIN-LEFT: 2em
}
OL {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px
}
UL {
	MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px
}
&lt;/STYLE&gt;

&lt;META name=GENERATOR content="MSHTML 8.00.6001.18939"&gt;&lt;/HEAD&gt;
&lt;BODY style="MARGIN: 10px"&gt;&lt;FONT size=2 face=Verdana&gt;
&lt;DIV&gt;
&lt;DIV&gt;&lt;FONT size=2 face=Verdana&gt;hello, I want to set up a hidden server in my 
private network. I have successfully build a private tor network, 
including one directory server and 4 OR nodes, but when I add hidden 
service in one of the OR node, it has an error, the log is:&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;
&lt;DIV&gt;[warn] Publishing server descriptor to directory authorities of type 
'Hidden service', but no authorities of that type listed!&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;
&lt;DIV&gt;I think the problem is in the directory server's configuration, how can I 
set up it to support the hidden service? Is there any example?&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;
&lt;DIV align=left&gt;2010-10-20&lt;/DIV&gt;
&lt;HR style="WIDTH: 122px; HEIGHT: 2px" align=left SIZE=2&gt;

&lt;DIV&gt;&lt;SPAN&gt;
&lt;DIV&gt;
&lt;DIV&gt;Gaofeng He&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;&lt;/DIV&gt;&lt;/SPAN&gt;&lt;/DIV&gt;&lt;/FONT&gt;&lt;/BODY&gt;&lt;/HTML&gt;


</body></email><email><emailId>20101020032526</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-20 03:25:26-0400</timestampReceived><subject>Re: hidden service</subject><body>


On Wed, 20 Oct 2010 10:18:53 +0800
"torsecurity" &lt;torbridges.security@gmail.com&gt; wrote:

&gt; hello, I want to set up a hidden server in my private network. I have successfully \
&gt; build a private tor network, including one directory server and 4 OR nodes, but \
&gt; when I add hidden service in one of the OR node, it has an error, the log is: 
&gt; [warn] Publishing server descriptor to directory authorities of type 'Hidden \
&gt; service', but no authorities of that type listed! 
&gt; I think the problem is in the directory server's configuration, how can I set up it \
&gt; to support the hidden service? Is there any example?

I think the option you need to set for current Tor versions is
‘HidServDirectoryV2'.  Add "HidServDirectoryV2 1" to at least one
relay's torrc.  You may also want to add "MinUptimeHidServDirectoryV2 0
seconds" to the directory authority's torrc.


Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101013065158</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-10-13 06:51:58-0400</timestampReceived><subject>Torperf</subject><body>

Hi Sebastian, hi Roger,

Sebastian reminded me yesterday that we should talk about Torperf at
some point. You're right. There are a lot of open questions. Here are
some of them:

- What shall we do with the Torperf run on ferrinii that fetches a 50
KiB file every minute and notes the path? I think Sebastian wanted this
run to validate whether our assumption about Tor doing path selection is
correct. Do you still want to do this? Shall I keep it running?

- Do we want to keep the #1919 Torperf runs running or migrate them to
some other VM (that has enough memory)? What do we expect to learn from
keeping them running or migrating them that we didn't learn from the
first week or two? Instead of keeping them running we could also make a
PDF report and put it on metrics.tpo/papers.html.

- Shall we "upgrade" the Torperfs on moria/torperf.tpo/siv to write
their path to disk? Sebastian, did you finish the script to combine
.data and .extradata files? And can you push your .extradata code to the
main repository? While upgrading the Torperf scripts, should we also
upgrade the Tor clients? Last time I checked, siv was running
0.2.1.24-dev, torperf was running 0.2.2.10-alpha-dev, and moria was
running 0.2.2.8-alpha-dev.

- What graphs do we want to put on the metrics website? Right now we
have the daily median and interquartile range by file size and data
source on metrics.tpo/performance.html. We could have a similar graph
for all data sources, a graph with all individual data points instead of
aggregates, the ECDFs for all sources and file sizes, and a graph on the
number or fraction of failed/timed out runs. These new graphs would
require us to add the raw Torperf measurements to the database and write
procedures to make materialized views out of them. While doing so we
should also add the path to the database schema. Anything we want to
evaluate based on the path once it's in the database?

Best,
--Karsten
</body></email><email><emailId>20101013152510</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2010-10-13 15:25:10-0400</timestampReceived><subject>Re: Torperf</subject><body>

On Oct 13, 2010, at 8:51 AM, Karsten Loesing wrote:
&gt; Hi Sebastian, hi Roger,

Ahoy

&gt; - What shall we do with the Torperf run on ferrinii that fetches a 50
&gt; KiB file every minute and notes the path? I think Sebastian wanted  
&gt; this
&gt; run to validate whether our assumption about Tor doing path  
&gt; selection is
&gt; correct. Do you still want to do this? Shall I keep it running?

I thought we would want to run all our torperfs this way, because it  
would
collect just the data and when we need it we can look at it. Is there an
indication that this would be unwise?

&gt; - Shall we "upgrade" the Torperfs on moria/torperf.tpo/siv to write
&gt; their path to disk? Sebastian, did you finish the script to combine
&gt; .data and .extradata files? And can you push your .extradata code to  
&gt; the
&gt; main repository? While upgrading the Torperf scripts, should we also
&gt; upgrade the Tor clients? Last time I checked, siv was running
&gt; 0.2.1.24-dev, torperf was running 0.2.2.10-alpha-dev, and moria was
&gt; running 0.2.2.8-alpha-dev.

I did finish the script, it is in my bug1918 branch currently. I had  
hoped
for some review before pushing my code to the main review, but if
that's unlikely to happen I'll merge.

I hope to have answered all questions that I can usefully answer here :)

All the best
Sebastian
</body></email><email><emailId>20101021211901</emailId><senderName></senderName><senderEmail>travis+ml-tor-dev</senderEmail><timestampReceived>2010-10-21 21:19:01-0400</timestampReceived><subject>polipo-tor debian package</subject><body>

[Attachment #2 (multipart/mixed)]


Hey all,

I put this together (attached).

Would people care to look at it and tell me if you think it's right?

Config file is direct from your page.

I can tar up the source (including debian dir) if you want.

Seems to work as designed for me; aptitude install it and it's
running, no config needed, and install torbutton, restart firefox,
click to enable, and you're done.
-- 
Good code works on most inputs; correct code works on all inputs.
My emails do not have attachments; it's a digital signature that your mail
program doesn't understand. | http://www.subspacefield.org/~travis/ 
If you are a spammer, please email john@subspacefield.org to get blacklisted.

["polipo-tor_1.1-1ubuntu1_all.deb" (application/x-debian-package)]
[Attachment #6 (application/pgp-signature)]

</body></email><email><emailId>20101029002317</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-10-29 00:23:17-0400</timestampReceived><subject>Descriptor fingerprint format</subject><body>

Descriptor fingerprints look like this:
opt fingerprint 0001 AC1F 9AE6 9A00 3C5E 6F02 73CB D69E C6E7 6926
...
opt fingerprint FFEB 470C F379 9E9C 5956 8521 8627 9ED5 55AB 1340

It's an extra routine to remove or add the spaces for scripting, with
the control port, etc. And who really uses them in a human fashion
with spaces anyways, this isn't a keysigning party :)

It also uses about 9 spaces x ~3300+ descriptors ~= 30,000 bytes
of traffic for one client to pull the entire relay list. Multiply that
by number of clients[?] x the frequency[?] ~= bandwidth wasted.

Maybe another ~10,000+ bytes x clients x freq could be saved by not
publishing the junk after the first left bracket '[' in the windows
platform lines.

Any ideas on removing these two someday?
</body></email><email><emailId>20101028054431</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-10-28 05:44:31-0400</timestampReceived><subject>Tor - Black Belt Edition for Windows - Tor Client + Tor Server(with</subject><body>

We are just completing the 2010-11 release of Tor - Black Belt Edition.- 
running on Windows.

This version, with some tweaking, actually includes 2 vidalia+tor 
stacks, running side by side.

One as a server, providing 15MB of bandwidth per day.
The other as an unrestricted client.

The use of the server, and its auto-starting, on Windows user-login is 
controlled through the Start menu and install-time options. This is to 
ensure that no user is 'forced' to run an exit relay without their 
knowledge.

I am hoping for a wide exposure of this software version.
Just 1000 users of this version would be capable of adding 15GB !!! of 
Server bandwidth PER DAY to the Tor network, with each user providing 
their small amount. Surely this will help the Tor network immensely.

All source code changes to the stock 0.2.2.17-alpha are included, when 
installed, in a 'src' folder, should anyone want to inspect what has 
been changed.

Is there anyway this software stack can get a wide exposure ?

I can post links when the software has been sufficiently tested and is 
released, probably as a Torrent, for download.
-- 

With kind regards,
Cav Edwards

</body></email><email><emailId>20101028082852</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-10-28 08:28:52-0400</timestampReceived><subject>Re: Tor - Black Belt Edition for Windows - Tor Client + Tor</subject><body>

On Thu, Oct 28, 2010 at 06:44:31AM +0100, Cav wrote:
&gt; We are just completing the 2010-11 release of Tor - Black Belt Edition.-  
&gt; running on Windows.

Ah ha -- I remember seeing the "black belt edition" thing on a torrent
somewhere, and wondered who was doing it. Now we know -- great.

&gt; This version, with some tweaking, actually includes 2 vidalia+tor  
&gt; stacks, running side by side.
&gt;
&gt; One as a server, providing 15MB of bandwidth per day.
&gt; The other as an unrestricted client.
&gt;
&gt; The use of the server, and its auto-starting, on Windows user-login is  
&gt; controlled through the Start menu and install-time options. This is to  
&gt; ensure that no user is 'forced' to run an exit relay without their  
&gt; knowledge.
&gt;
&gt; I am hoping for a wide exposure of this software version.
&gt; Just 1000 users of this version would be capable of adding 15GB !!! of  
&gt; Server bandwidth PER DAY to the Tor network, with each user providing  
&gt; their small amount. Surely this will help the Tor network immensely.

Four thoughts at first:

A) Why separate Tors and Vidalias? Tor is designed to be able to operate
as both a client and a relay at the same time. This is important because
every operating Tor fetches directory information over the course of
the day, and with hundreds of thousands of users, it adds up. Two Tors
means twice as much directory fetching load.

I guess one answer is that if you're using Tor's hibernation feature,
then the client functionality shuts off as well when Tor hibernates. I
just opened a trac entry to remind us about that:
https://trac.torproject.org/projects/tor/ticket/2129

B) 15MB per day is really not very much. First, notice that the Tor
network as a whole averages 600MB/s of traffic.
http://metrics.torproject.org/network.html#bandwidth
That's 52 TB a day. To double the capacity of the network, at 15MB per
relay, you'd need to get 3.5 million people running it. But it's actually
worse than that -- each Tor relay generates a server descriptor that
clients need to get in order to use it. So figuring a very conservative
100000 Tor clients running right now, and a conservative 500 bytes that
each user needs to fetch each day, that's 50MB that's going to be spent
just distributing the server descriptor to all the clients. So you really
want to be offering a few gigabytes per day before the numbers start to
become workable.

C) Many users are behind a nat that doesn't allow inbound connections.
Vidalia supports upnp, but I'm not sure how many users have routers that
support it. I wonder what approaches we can use to increase the chances
that users actually make sure their Tor relay is reachable.

D) The name "Tor black belt edition" sure implies that you're providing
an official Tor bundle. I wonder if there's a good name that doesn't
confuse users about who is making the package? See also
https://www.torproject.org/docs/trademark-faq.html.en

--Roger

</body></email><email><emailId>20101028092436</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-28 09:24:36-0400</timestampReceived><subject>Re: Tor - Black Belt Edition for Windows - Tor Client + Tor</subject><body>


On Thu, 28 Oct 2010 06:44:31 +0100
Cav &lt;cav@gotadsl.co.uk&gt; wrote:

&gt; All source code changes to the stock 0.2.2.17-alpha are included, when 
&gt; installed, in a 'src' folder, should anyone want to inspect what has 
&gt; been changed.

Please document your changes and send them to the Tor developers as
patches, instead of mashing them into a modified source tree and
distributing them only within a big binary package.  If your changes are
useful, they can be added to the official Tor codebase; if they are
harmful, whether to users or to the Tor network, the Tor developers can
explain why.

&gt; Is there anyway this software stack can get a wide exposure ?

There are many ways that your software can get ‘wide exposure'.  One
way is to distribute it to users with a gaping security flaw, and wait
for someone else to rip it to shreds.  All of us would prefer to avoid
that kind of exposure.

&gt; I can post links when the software has been sufficiently tested and is 
&gt; released, probably as a Torrent, for download.

The Tor Project makes its source code available for public review and
testing *before* it distributes packages to users.  If you want other
people to trust your Tor derivative, whatever you call it, you should
do the same.

There are many public Git hosting sites where you can post the Git
repositories containing your modified Tor and your build scripts.  I use
repo.or.cz (to post your Tor sources there, start by going to
http://repo.or.cz/tor.git/ and clicking the ‘fork' link), but you may
prefer another site.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101028103618</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-28 10:36:18-0400</timestampReceived><subject>Re: Tor - Black Belt Edition for Windows - Tor Client + Tor</subject><body>


On Thu, 28 Oct 2010 02:24:36 -0700
Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:

&gt; There are many public Git hosting sites where you can post the Git
&gt; repositories containing your modified Tor and your build scripts.  I use
&gt; repo.or.cz (to post your Tor sources there, start by going to
&gt; http://repo.or.cz/tor.git/ and clicking the ‘fork' link), but you may
&gt; prefer another site.

Oops -- that URL should be http://repo.or.cz/w/tor.git/ .


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101029052528</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-29 05:25:28-0400</timestampReceived><subject>Re: Descriptor fingerprint format</subject><body>


On Thu, 28 Oct 2010 20:23:17 -0400
grarpamp &lt;grarpamp@gmail.com&gt; wrote:

&gt; Descriptor fingerprints look like this:
&gt; opt fingerprint 0001 AC1F 9AE6 9A00 3C5E 6F02 73CB D69E C6E7 6926
&gt; ...
&gt; opt fingerprint FFEB 470C F379 9E9C 5956 8521 8627 9ED5 55AB 1340
&gt; 
&gt; It's an extra routine to remove or add the spaces for scripting, with
&gt; the control port, etc. And who really uses them in a human fashion
&gt; with spaces anyways, this isn't a keysigning party :)
&gt; 
&gt; It also uses about 9 spaces x ~3300+ descriptors ~= 30,000 bytes
&gt; of traffic for one client to pull the entire relay list. Multiply that
&gt; by number of clients[?] x the frequency[?] ~= bandwidth wasted.
&gt; 
&gt; Maybe another ~10,000+ bytes x clients x freq could be saved by not
&gt; publishing the junk after the first left bracket '[' in the windows
&gt; platform lines.
&gt; 
&gt; Any ideas on removing these two someday?

Very unlikely, unless someone hands it to us before Tor's cryptographic
algorithms need to change.  The descriptors and consensuses are
compressed, so it's less than 9 bytes per fingerprint, and the format
that Tor relays emit can't change unless all Tor clients can read the
new format.  (A change in cryptographic algorithms would probably lead
to a break in backwards compatibility sometime later.)

There are also bigger wins -- base32 or base64 fingerprints, for
example.  (Base32 would be better for router fingerprints, because that
can be cut and pasted into the .exit notation to select an exit node.
Base64 can't be used in .exit because DNS does not preserve letter
case.)

If you really want this to happen, write a proposal, and start writing
a patch to the parsing code.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101029052927</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-10-29 05:29:27-0400</timestampReceived><subject>Re: Descriptor fingerprint format</subject><body>

On Thu, Oct 28, 2010 at 8:23 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:
 [...]
&gt; Any ideas on removing these two someday?

Have a look at proposal 158?

-- 
Nick
</body></email><email><emailId>201010291400440</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2010-10-29 14:00:44-0400</timestampReceived><subject>Re: Descriptor fingerprint format</subject><body>

On 2010-10-29 02:23, grarpamp wrote:
&gt; Descriptor fingerprints look like this:
&gt; opt fingerprint 0001 AC1F 9AE6 9A00 3C5E 6F02 73CB D69E C6E7 6926
&gt; ...
&gt; opt fingerprint FFEB 470C F379 9E9C 5956 8521 8627 9ED5 55AB 1340
&gt; 
&gt; It's an extra routine to remove or add the spaces for scripting, with
&gt; the control port, etc. And who really uses them in a human fashion
&gt; with spaces anyways, this isn't a keysigning party :)
&gt; 
&gt; It also uses about 9 spaces x ~3300+ descriptors ~= 30,000 bytes
&gt; of traffic for one client to pull the entire relay list. Multiply that
&gt; by number of clients[?] x the frequency[?] ~= bandwidth wasted.
&gt; 
&gt; Maybe another ~10,000+ bytes x clients x freq could be saved by not
&gt; publishing the junk after the first left bracket '[' in the windows
&gt; platform lines.
&gt; 
&gt; Any ideas on removing these two someday?

Why not just run a compression algorithm over them, or even better, just
do everything in binary format?

Greets,
 Jeroen
</body></email><email><emailId>20101015021328</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-10-15 02:13:28-0400</timestampReceived><subject>Re: Torperf</subject><body>


Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; - Do we want to keep the #1919 Torperf runs running or migrate them to
&gt; some other VM (that has enough memory)? What do we expect to learn from
&gt; keeping them running or migrating them that we didn't learn from the
&gt; first week or two? Instead of keeping them running we could also make a
&gt; PDF report and put it on metrics.tpo/papers.html.

I think this is very important to keep running, and that we should
think about adding new runs for based on the ratios of measured
consensus bandwidth to published descriptor bandwidth. Guards with
high ratios for this value have been observed by the bandwidth
authorities as having lots of slack capacity, where as Guards with
low ratios would be overloaded.

I would love to have all of these datastream available for comparison
when various events and perf tweaks change the network. In fact, I
would love it if we could have the following 5 torperf runs logging
continuously and all overlayed on the main Torperf metrics graph:

1. Fastest 3 guards by network status
2. Fastest 3 guards by ratio of ns_bw/desc_bw
3. EntryGuards=0 (default current torperf)
4. Slowest 3 guards by network status
5. Slowest 3 guards by ratio of ns_bw/desc_bw

Is it hard to keep all of these running and logging for some reason?
Does the 1919 script take up a lot of RAM?

I can make these and any other changes to the 1919 script to help this
along.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20101017051159</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-10-17 05:11:59-0400</timestampReceived><subject>Re: Torperf</subject><body>

Somewhat related, came up in chat as a possible todo...
Is anyone collecting stats regarding hidden service to hidden service
performance?

On 10/14/10, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; Thus spake Karsten Loesing (karsten.loesing@gmx.net):
&gt;
&gt;&gt; - Do we want to keep the #1919 Torperf runs running or migrate them to
&gt;&gt; some other VM (that has enough memory)? What do we expect to learn from
&gt;&gt; keeping them running or migrating them that we didn't learn from the
&gt;&gt; first week or two? Instead of keeping them running we could also make a
&gt;&gt; PDF report and put it on metrics.tpo/papers.html.
&gt;
&gt; I think this is very important to keep running, and that we should
&gt; think about adding new runs for based on the ratios of measured
&gt; consensus bandwidth to published descriptor bandwidth. Guards with
&gt; high ratios for this value have been observed by the bandwidth
&gt; authorities as having lots of slack capacity, where as Guards with
&gt; low ratios would be overloaded.
&gt;
&gt; I would love to have all of these datastream available for comparison
&gt; when various events and perf tweaks change the network. In fact, I
&gt; would love it if we could have the following 5 torperf runs logging
&gt; continuously and all overlayed on the main Torperf metrics graph:
&gt;
&gt; 1. Fastest 3 guards by network status
&gt; 2. Fastest 3 guards by ratio of ns_bw/desc_bw
&gt; 3. EntryGuards=0 (default current torperf)
&gt; 4. Slowest 3 guards by network status
&gt; 5. Slowest 3 guards by ratio of ns_bw/desc_bw
&gt;
&gt; Is it hard to keep all of these running and logging for some reason?
&gt; Does the 1919 script take up a lot of RAM?
&gt;
&gt; I can make these and any other changes to the 1919 script to help this
&gt; along.
&gt;
&gt; --
&gt; Mike Perry
&gt; Mad Computer Scientist
&gt; fscked.org evil labs
&gt;
</body></email><email><emailId>20101017101906</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2010-10-17 10:19:06-0400</timestampReceived><subject>Re: Torperf</subject><body>


On Oct 15, 2010, at 4:13 AM, Mike Perry wrote:
&gt; I would love to have all of these datastream available for comparison
&gt; when various events and perf tweaks change the network. In fact, I
&gt; would love it if we could have the following 5 torperf runs logging
&gt; continuously and all overlayed on the main Torperf metrics graph:
&gt;
&gt; 1. Fastest 3 guards by network status
&gt; 2. Fastest 3 guards by ratio of ns_bw/desc_bw
&gt; 3. EntryGuards=0 (default current torperf)
&gt; 4. Slowest 3 guards by network status
&gt; 5. Slowest 3 guards by ratio of ns_bw/desc_bw
&gt;
&gt; Is it hard to keep all of these running and logging for some reason?
&gt; Does the 1919 script take up a lot of RAM?

The problem wasn't that the script was taking a lot of RAM, but rather
that each torperf instance comes with its own tor instance. Spinning
up another 9 clients caused the memory issues.

&gt; I can make these and any other changes to the 1919 script to help this
&gt; along.

So far it appears the script is doing fine.

Sebastian
</body></email><email><emailId>20101025081135</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-10-25 08:11:35-0400</timestampReceived><subject>Re: Torperf</subject><body>

On 10/13/10 5:25 PM, Sebastian Hahn wrote:

Ooops, sorry for the delay. I spent the past 1.5 weeks in JSP Hell TM!
Catching up with email today...

&gt; On Oct 13, 2010, at 8:51 AM, Karsten Loesing wrote:
&gt;&gt; - What shall we do with the Torperf run on ferrinii that fetches a 50
&gt;&gt; KiB file every minute and notes the path? I think Sebastian wanted this
&gt;&gt; run to validate whether our assumption about Tor doing path selection is
&gt;&gt; correct. Do you still want to do this? Shall I keep it running?
&gt; 
&gt; I thought we would want to run all our torperfs this way, because it would
&gt; collect just the data and when we need it we can look at it. Is there an
&gt; indication that this would be unwise?

Right, we can change the 3x3 Torperfs we're running to write their paths
to disk. But in the question above I was referring to the (fourth)
Torperf run on torperf.tpo that requests a 50 KiB file every minute. You
asked me to set that one up a few weeks ago. Shall I keep it running?
And if so, what are we doing with the data?

&gt;&gt; - Shall we "upgrade" the Torperfs on moria/torperf.tpo/siv to write
&gt;&gt; their path to disk? Sebastian, did you finish the script to combine
&gt;&gt; .data and .extradata files? And can you push your .extradata code to the
&gt;&gt; main repository? While upgrading the Torperf scripts, should we also
&gt;&gt; upgrade the Tor clients? Last time I checked, siv was running
&gt;&gt; 0.2.1.24-dev, torperf was running 0.2.2.10-alpha-dev, and moria was
&gt;&gt; running 0.2.2.8-alpha-dev.
&gt; 
&gt; I did finish the script, it is in my bug1918 branch currently. I had hoped
&gt; for some review before pushing my code to the main review, but if
&gt; that's unlikely to happen I'll merge.

I'm going to do the upgrade today and will let you know if something breaks.

Thanks,
--Karsten
</body></email><email><emailId>20101025081753</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-10-25 08:17:53-0400</timestampReceived><subject>Re: Torperf</subject><body>

On 10/17/10 7:11 AM, grarpamp wrote:
&gt; Somewhat related, came up in chat as a possible todo...
&gt; Is anyone collecting stats regarding hidden service to hidden service
&gt; performance?

  https://trac.torproject.org/projects/tor/ticket/1944

No progress here, though. Any volunteers? :)

Best,
--Karsten
</body></email><email><emailId>20101025084713</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-10-25 08:47:13-0400</timestampReceived><subject>Re: Torperf</subject><body>

On 10/17/10 12:19 PM, Sebastian Hahn wrote:
&gt; On Oct 15, 2010, at 4:13 AM, Mike Perry wrote:
&gt;&gt; Thus spake Karsten Loesing (karsten.loesing@gmx.net):
&gt;&gt;
&gt;&gt;&gt; - Do we want to keep the #1919 Torperf runs running or migrate them
&gt;&gt;&gt; to some other VM (that has enough memory)? What do we expect to
&gt;&gt;&gt; learn from keeping them running or migrating them that we didn't
&gt;&gt;&gt; learn from the first week or two? Instead of keeping them running
&gt;&gt;&gt; we could also make a PDF report and put it on
&gt;&gt;&gt; metrics.tpo/papers.html.
&gt;&gt;
&gt;&gt; I think this is very important to keep running, and that we should
&gt;&gt; think about adding new runs for based on the ratios of measured
&gt;&gt; consensus bandwidth to published descriptor bandwidth. Guards with
&gt;&gt; high ratios for this value have been observed by the bandwidth
&gt;&gt; authorities as having lots of slack capacity, where as Guards with
&gt;&gt; low ratios would be overloaded.
&gt;&gt;
&gt;&gt; I would love to have all of these datastream available for comparison
&gt;&gt; when various events and perf tweaks change the network. In fact, I
&gt;&gt; would love it if we could have the following 5 torperf runs logging
&gt;&gt; continuously and all overlayed on the main Torperf metrics graph:
&gt;&gt;
&gt;&gt; 1. Fastest 3 guards by network status
&gt;&gt; 2. Fastest 3 guards by ratio of ns_bw/desc_bw
&gt;&gt; 3. EntryGuards=0 (default current torperf)
&gt;&gt; 4. Slowest 3 guards by network status
&gt;&gt; 5. Slowest 3 guards by ratio of ns_bw/desc_bw

Okay, I think we can continue running the 3 or 5 Torperf runs with
modified guard node selection algorithms in the future if we think the
data is useful. However, note that

a) the 3 Torperf runs for #1919 run on some machine which is, AFAIK, not
one of our VMs and which may or may not host the 3 or even 5 Torperf
runs in the future,

b) I have no idea how to add 2 more Torperf runs with the guard
selection algorithms you stated, and

c) we're not using the output data for anything yet.

Mike and Sebastian, any ideas about a) and b)?

I think I can help with c) once I have the data.

&gt;&gt; Is it hard to keep all of these running and logging for some reason?
&gt;&gt; Does the 1919 script take up a lot of RAM?
&gt; 
&gt; The problem wasn't that the script was taking a lot of RAM, but rather
&gt; that each torperf instance comes with its own tor instance. Spinning
&gt; up another 9 clients caused the memory issues.

I think we can ask for more memory for the VM running this.

&gt;&gt; I can make these and any other changes to the 1919 script to help this
&gt;&gt; along.
&gt; 
&gt; So far it appears the script is doing fine.

Does that apply to the additional 2 Torperf runs, too?

Best,
--Karsten
</body></email><email><emailId>20101031055536</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 05:55:36-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 013/291] user-contributed</subject><body>


On Sat, 30 Oct 2010 00:32:34 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Fri, 8 Oct 2010 16:40:00 -0700
&gt; Subject: user-contributed rule for Airtricity
&gt; Commit: c9867f329e286ff2b51a8eac9596f8bf1e0954f8
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/Airtricity.xml |    4 ++++
&gt;  1 files changed, 4 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/chrome/content/rules/Airtricity.xml
&gt; 
&gt; diff --git a/src/chrome/content/rules/Airtricity.xml b/src/chrome/content/rules/Airtricity.xml
&gt; new file mode 100644
&gt; index 0000000..9f20f31
&gt; --- /dev/null
&gt; +++ b/src/chrome/content/rules/Airtricity.xml
&gt; @@ -0,0 +1,4 @@
&gt; +&lt;ruleset name="Airtricity"&gt;
&gt; +  &lt;rule from="^http://airtricity\.com/" to="https://www.airtricity.com/"/&gt;
&gt; +  &lt;rule from="^http://([^/:@]*)\airtricity\.com/" to="https://$1.airtricity.com/"/&gt;

This rule is missing "." before "airtricity" in ‘from' value.

&gt; +&lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101031064738</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 06:47:38-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 030/291] user-contributed</subject><body>


On Sat, 30 Oct 2010 00:32:35 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Fri, 8 Oct 2010 16:50:14 -0700
&gt; Subject: user-contributed rule for Bloglines.com
&gt; Commit: a0c02962fb381a5eec5e1ab2ea7b354ba6403c80
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/Bloglines.xml |    3 +++
&gt;  1 files changed, 3 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/chrome/content/rules/Bloglines.xml
&gt; 
&gt; diff --git a/src/chrome/content/rules/Bloglines.xml b/src/chrome/content/rules/Bloglines.xml
&gt; new file mode 100644
&gt; index 0000000..3fafdbe
&gt; --- /dev/null
&gt; +++ b/src/chrome/content/rules/Bloglines.xml
&gt; @@ -0,0 +1,3 @@
&gt; +&lt;ruleset name="Bloglines"&gt;
&gt; +  &lt;rule from="^http://(www\.)?bloglines\.com/" to="https://bloglines.com"/&gt;

The ‘to' attribute needs a trailing slash, too.

&gt; +&lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101031065119</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 06:51:19-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 033/291] user-contributed</subject><body>


On Sat, 30 Oct 2010 00:32:35 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Fri, 8 Oct 2010 16:50:53 -0700
&gt; Subject: user-contributed rule for Chaos Computer Club
&gt; Commit: 57ff4ae9ee379a2502a7c0fc7f19dcb17c07a08a
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/CCC.xml |    7 +++++++
&gt;  1 files changed, 7 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/chrome/content/rules/CCC.xml
&gt; 
&gt; diff --git a/src/chrome/content/rules/CCC.xml b/src/chrome/content/rules/CCC.xml
&gt; new file mode 100644
&gt; index 0000000..68598fe
&gt; --- /dev/null
&gt; +++ b/src/chrome/content/rules/CCC.xml
&gt; @@ -0,0 +1,7 @@
&gt; +&lt;ruleset name="ccc.de"&gt;
&gt; +  &lt;exclusion pattern="^http://dasalte\.ccc\.de/"/&gt;&lt;!-- revoked cert --&gt;
&gt; +  &lt;exclusion pattern="^http://chaosradio\.ccc\.de/"/&gt;&lt;!-- invalid cert --&gt;
&gt; +  &lt;exclusion pattern="^http://blog.chaosradio\.ccc\.de/"/&gt;&lt;!-- invalid cert --&gt;

This pattern has an unescaped dot.

&gt; +  &lt;rule from="^http://ccc\.de/" to="https://www.ccc.de/"/&gt;
&gt; +  &lt;rule from="^http://([^/:@]*)\.ccc\.de/" to="https://$1.ccc.de/"/&gt;
&gt; +&lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20101031065506</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-10-31 06:55:06-0400</timestampReceived><subject>Re: [or-cvs] [https-everywhere/master 038/291] user-contributed</subject><body>


On Sat, 30 Oct 2010 00:32:35 +0000 (UTC)
schoen@torproject.org wrote:

&gt; Author: Seth Schoen &lt;schoen@eff.org&gt;
&gt; Date: Fri, 8 Oct 2010 16:52:57 -0700
&gt; Subject: user-contributed rule for DVDFab
&gt; Commit: 73ea064a7042ad4d13bb87d439b32a8a8704eaa8
&gt; 
&gt; ---
&gt;  src/chrome/content/rules/DVDFab.xml |    3 +++
&gt;  1 files changed, 3 insertions(+), 0 deletions(-)
&gt;  create mode 100644 src/chrome/content/rules/DVDFab.xml
&gt; 
&gt; diff --git a/src/chrome/content/rules/DVDFab.xml b/src/chrome/content/rules/DVDFab.xml
&gt; new file mode 100644
&gt; index 0000000..3365fbc
&gt; --- /dev/null
&gt; +++ b/src/chrome/content/rules/DVDFab.xml
&gt; @@ -0,0 +1,3 @@
&gt; +&lt;ruleset name="DVDFab"&gt;
&gt; +  &lt;rule from="^https?://(www\.)?dvdfab\.(com|net)/" to="https://www.dvdfab.$3/"/&gt;

Remove the "s?", replace "$3" with "$2", and remove the CRs from the
line endings so this will look nicer in Gitweb.

&gt; +&lt;/ruleset&gt;


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100914220519</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-09-14 22:05:19-0400</timestampReceived><subject>Re: [or-cvs] r23192: {projects} resync  (projects/articles)</subject><body>

On Tue, Sep 14, 2010 at 03:04:56PM -0700, Robert Ransom wrote:
&gt; &gt; -&lt;h3&gt;4. Open design&lt;/h3&gt;
&gt; &gt; +&lt;h3&gt;Has an open design&lt;/h3&gt;
&gt; &gt;  
&gt; &gt; -&lt;h3&gt;5. Decentralized architecture&lt;/h3&gt;
&gt; &gt; +&lt;h3&gt;Has a decentralized architecture&lt;/h3&gt;
&gt; &gt;  
&gt; You lost the section numbers.

Whoops! So I did. Fixed. Thanks.

--Roger

</body></email><email><emailId>20100915013019</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-09-15 01:30:19-0400</timestampReceived><subject>Google Chrome Incognito Mode and Tor</subject><body>


(I'm cross-posting to or-dev and or-talk. Please remove one of the Cc's
as appropriate, depending upon the nature of your reply.)

For the past couple months, I've been doing a lot of work reviewing
and summarizing the major issues remaining before we can safely write
a Tor Incognito Mode extension for Google Chrome. I've been using
this ticket group on trac to track my progress:
https://trac.torproject.org/projects/tor/ticket/1770

I've also written a prototype Chrome extension that is functionally
incomplete and unsafe to use, but could use some review by any
Javascript ninjas out there:
https://trac.torproject.org/projects/tor/ticket/1816

The work has also been summarized in this blog post:
https://blog.torproject.org/blog/google-chrome-incognito-mode-tor-and-fingerprinting

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100917042603</emailId><senderName>Xinwen Fu</senderName><senderEmail>xinwenfu@gmail.com</senderEmail><timestampReceived>2010-09-17 04:26:03-0400</timestampReceived><subject>Re: Boston Tor Hackers: Join us Sunday September 19th</subject><body>

I will be there.

Cheers,

Xinwen Fu

On Thu, Sep 16, 2010 at 8:17 PM, Andrew Lewman &lt;andrew@torproject.org&gt;wrote:

&gt; Boston Tor Hackers: Join us Sunday September 19th
&gt;
&gt; We're holding a Tor hackfest this Sunday, the 19th. Tor's Chief
&gt; Architect, Nick Mathewson, will be explaining Tor's goals and what the
&gt; project has been up to lately, and then we'll pick a few day-sized
&gt; projects to work on together with his help.
&gt;
&gt; We'll be meeting at 2pm in the new Media Lab building (E14), room 240,
&gt; thanks to the Center for Future Civic Media at MIT. Since the building
&gt; is closed on Sundays, please e-mail chris-torfest@printf.net before
&gt; Sunday to get a phone number to use to be let in. We're hoping to
&gt; provide pizza and drinks, and we'll finish up and move to Grendel's Den
&gt; around 9pm.
&gt;
&gt; Map: http://whereis.mit.edu/?go=E14
&gt;
&gt; Please attend if you have some programming experience and are
&gt; interested in Tor, or are willing to be persuaded to entertain an
&gt; interest. :) Tor's a small project (in terms of number of developers)
&gt; that could really use your help.
&gt;
&gt; Please RSVP if you can make it. Hope to see you on Sunday!
&gt;
&gt; --
&gt; Andrew Lewman
&gt; The Tor Project
&gt; pgp 0x31B0974B
&gt; +1-781-352-0568
&gt;
&gt; Website: https://www.torproject.org/
&gt; Blog: https://blog.torproject.org/
&gt; Identi.ca: torproject
&gt; skype:  lewmanator
&gt;

[Attachment #3 (text/html)]

I will be there.&lt;br&gt;&lt;br&gt;Cheers,&lt;br&gt;&lt;br&gt;Xinwen Fu&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On \
Thu, Sep 16, 2010 at 8:17 PM, Andrew Lewman &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt; \
&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px \
solid rgb(204, 204, 204); padding-left: 1ex;"&gt;Boston Tor Hackers: Join us Sunday \
September 19th&lt;br&gt; &lt;br&gt;
We're holding a Tor hackfest this Sunday, the 19th. Tor's Chief&lt;br&gt;
Architect, Nick Mathewson, will be explaining Tor's goals and what the&lt;br&gt;
project has been up to lately, and then we'll pick a few day-sized&lt;br&gt;
projects to work on together with his help.&lt;br&gt;
&lt;br&gt;
We'll be meeting at 2pm in the new Media Lab building (E14), room 240,&lt;br&gt;
thanks to the Center for Future Civic Media at MIT. Since the building&lt;br&gt;
is closed on Sundays, please e-mail &lt;a \
href="mailto:chris-torfest@printf.net"&gt;chris-torfest@printf.net&lt;/a&gt; before&lt;br&gt; Sunday \
to get a phone number to use to be let in. We're hoping to&lt;br&gt; provide pizza and \
drinks, and we'll finish up and move to Grendel's Den&lt;br&gt; around 9pm.&lt;br&gt;
&lt;br&gt;
Map: &lt;a href="http://whereis.mit.edu/?go=E14" \
target="_blank"&gt;http://whereis.mit.edu/?go=E14&lt;/a&gt;&lt;br&gt; &lt;br&gt;
Please attend if you have some programming experience and are&lt;br&gt;
interested in Tor, or are willing to be persuaded to entertain an&lt;br&gt;
interest. :) Tor's a small project (in terms of number of developers)&lt;br&gt;
that could really use your help.&lt;br&gt;
&lt;br&gt;
Please RSVP if you can make it. Hope to see you on Sunday!&lt;br&gt;
&lt;br&gt;
--&lt;br&gt;
Andrew Lewman&lt;br&gt;
The Tor Project&lt;br&gt;
pgp 0x31B0974B&lt;br&gt;
+1-781-352-0568&lt;br&gt;
&lt;br&gt;
Website: &lt;a href="https://www.torproject.org/" \
                target="_blank"&gt;https://www.torproject.org/&lt;/a&gt;&lt;br&gt;
Blog: &lt;a href="https://blog.torproject.org/" \
                target="_blank"&gt;https://blog.torproject.org/&lt;/a&gt;&lt;br&gt;
Identi.ca: torproject&lt;br&gt;
skype:  lewmanator&lt;br&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20100919065420</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-09-19 06:54:20-0400</timestampReceived><subject>Re: [or-cvs] r23240: {website} move mwenge to the core people page</subject><body>

On Sat, Sep 18, 2010 at 11:50:55PM -0700, Robert Ransom wrote:
&gt; &gt; +href="http://code.google.com/p/torora/"&gt;privacy-oriented Aurora fork&lt;/a&gt;,
&gt; 
&gt; s/Aurora/Arora/

What a silly name for a browser. :)

Fixed. Thanks,
--Roger

</body></email><email><emailId>20100920174120</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2010-09-20 17:41:20-0400</timestampReceived><subject>Re: Tor multithreaded crypto</subject><body>

Following the "Release early, release often" principle, I'm posting
today's revision of the multithreaded crypto changes.

This time I've spent some time fixing the code and I've even
semi-tested the queues.  
By semi-tested I mean that I made a small program with the queue code
but with the normal pthread_* functions and not the Tor wrappers and
with char* values getting passed around instead of circuits and
cell_directions etc.
I guess that's not considered commercial-quality QA, but at least it's
something!

Code is obviously still immature and nothing much changed but I think
that this time it may handle some lightweight code review.

Now, two questions:

a) Like I said in #tor-dev, the packed relay cell throughout idea was
nice, but I've ended up adjusting _many_ functions to support this
change [1]. We need to find out if:
* I'm doing it right and it indeed needs so many changes.
   * If I'm right, if it's worth doing all those changes.
   
b) Nick, can you expand a bit on how and where should the interaction
between Libevent and the main thread should happen? Basically, when
the 'unhandled' cell queue gets filled how should Libevent notify the
main thread? And where in the main thread should we be waiting for
Libevent wakeups?

Now:
In http://people.cs.unipi.gr/asn/tor you will find:
- multicrypto.c
  This is the file where the work queues and the relay_crypto_worker
  code is held. This will - most probably - get split later, but I
  guess it's readable enough for now.
- experimentality.c
  This is the file where relay_crypt() and
  handle_encrypted_relay_cell() are held. These will most probably go
  to relay.c or to somewhere meaningful, but they are still in an
  awful state because of the transition to packed_cell_t so I have
  temporarily moved them to this file.
- packedchanges.diff
  All the ugly adjustments I've done to support packed_cell_t in
  various relay-related (and not) functions.
  Careful it's a bit bloated file.
  
Comments are more than welcome, of course, although do remember that
it's far from done and it's still more of a blueprint than the actual
implementation. 

Thank you :)
</body></email><email><emailId>20100921040623</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-09-21 04:06:23-0400</timestampReceived><subject>Research problem: adaptive throttling of Tor clients by entry</subject><body>

Looking for a paper topic (or a thesis topic)? Here's a Tor research area
that needs more attention. The short version is: if we prevent the really
loud users from using too much of the Tor network, how much can it help?

We've instrumented Tor's entry relays so they can rate-limit connections
from users, and we've instrumented the directory authorities so they can
change the rate-limiting parameters globally across the network. Which
parameter values improve performance for the Tor network as a whole? How
should relays adapt their rate-limiting parameters based on their capacity
and based on the network load they see, and what rate-limiting algorithms
will work best?

We'd love to work with you to help answer these questions.

Read more here:
https://blog.torproject.org/blog/research-problem-adaptive-throttling-tor-clients-entry-guards

--Roger

</body></email><email><emailId>20100921144446</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-09-21 14:44:46-0400</timestampReceived><subject>Re: [or-cvs] r23274: {website} add metrics, link to media.tpo,</subject><body>

On Tue, 21 Sep 2010 07:31:50 -0700
Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:

&gt; &gt;  with Polipo, your browser, or some other application, please don't
&gt; &gt; put it in our bugtracker.) The
&gt; 
&gt; Polipo bugs do belong in the Tor Project's bug tracker now.

Possibly.  It seems polipo has stagnated because the volunteer
maintainer has no time for it anymore.  Juliusz may take it back, but
nothing is certain at this point.  

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B
+1-781-352-0568

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
Skype: lewmanator
</body></email><email><emailId>20100924191643</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-09-24 19:16:43-0400</timestampReceived><subject>ATTN: The maint-0.2.2 branch has branched; master is now 0.2.3.x-alpha</subject><body>

Hi, all!

I've just created a new "maint-0.2.2" branch[*] in the official Git
repository for work on Tor 0.2.2.x.  This may be overly optimistic of
me, but I think Tor 0.2.2.x is almost ready for rc status.[**]  Just a
couple more bugfixes!  (To see all bugs marked for 0.2.2.x on the
tracker, go to https://trac.torproject.org/projects/tor/milestone/Tor:%200.2.2.x-final
and click on "Active Tickets".  Some are rc-blockers, but most
aren't.)

For more info on how we use git branches, see "How we use git
branches" in doc/HACKING.  The upshot is that bugfix branches should
be done on maint-0.2.2 (or maint-0.2.1 if they're serious and old
enough), and new-feature branches should be done on master.  Don't
worry if you have a branch that you started on the old master: It will
merge cleanly onto maint-0.2.2, since it started before the
branch.[***]

[*] (There's also a release-0.2.2 branch. Almost nobody but Roger
should care about that one.  If you're curious about what it's for,
have a look at that section of doc/HACKING I mentioned.)
[**] Also, there are some deliverables we need to merge into an alpha
rsn in order to be contract-compliant, from what I understand.
[***] And if you screw up and base a bugfix branch on the new master,
don't worry.  Make a backup copy of the branch, then rebase it with
"git rebase --onto origin/maint-0.2.2 master", subject to the usual
rebasing caveats.

peace,
-- 
Nick
</body></email><email><emailId>20100926133427</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-09-26 13:34:27-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>

On Wednesday 25 August 2010 22:12:28 Robert Hogan wrote:
&gt; 
&gt; - We can achieve some/a lot of the benefits sought by the proposal if we
&gt; isolate streams based on the information provided by the socks request
&gt; itself. The things people have suggested are:
&gt;   1 Socks authentication info (username/pass)
&gt;   2 Socks listener address/port
&gt;   3 Socks protocol
&gt;   4 Socks client IP
&gt;   5 Info in /proc/pid/cmdline garnered from the client's port number

So after more discussion this list now looks like:

   1 Socks authentication info (username/pass)
   2 Socks listener address/port
   3 Socks protocol
   4 Socks client IP
   5 Destination Port (if it is in the LongLivedPort list)

And the consensus is it should be on by default.

Adding number 5 to the list would allow users to isolate streams by port 80 
if they chose to designate it a LongLivedPort. I'm not sure if that means 
we should leave it out of the list, if we should defend against 'invalid' 
LongLivedPorts, or if it's something we are happy to allow.

I think the list above allows stream isolation on requests over TransPort 
and NATDPort - at least to the extent that it will isolate streams on the 
basis of 2, 4 and 5 (if applicable). 
</body></email><email><emailId>20100927083609</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-09-27 08:36:09-0400</timestampReceived><subject>Re: Correctness proof for new bandwidth-weights (bug 1952)</subject><body>


Thus spake Mike Perry (mikeperry@fscked.org):
 
&gt; Case 2b:
&gt; 
&gt;   Wgg = Wee = weight_scale
&gt;   Wed = (weight_scale*(D - 2*E + G + M))/(3*D)
&gt;   Wmd = (weight_Scale*(D - 2*M + G + E))/(3*D)
&gt;   Wme = Wmg = 0
&gt;   Wgd = weight_scale - Wed - Wmd
&gt;
&gt; Wmd &gt;= 0:
&gt;   D+G+E-2*M &gt;= 0
    D+G+E-2*M+M &gt;= M
    D+G+E+M &gt;= 3*M
&gt;   T/3 &gt;= M
&gt; 
&gt;   If your eyes haven't glazed over yet, you'll notice that this last
&gt;   condition can actually be true. If we don't hand out enough Guard

*sigh*... And, of course by "true" here, I actually meant "false", in
that there can be mathematical situations where M &gt; T/3 and this
weight could thus take on a negative number. The rest of this
paragraph was correct, I just said "true" when I meant "false".

&gt;   flags, there may be too many middle nodes. In this case, the code just
&gt;   warns and suggests that the WFU parameters be lowered.

The code also sets this weight to 0 in this case, and adjusts Wgd
appropriately.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100917001746</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-09-17 00:17:46-0400</timestampReceived><subject>Boston Tor Hackers: Join us Sunday September 19th</subject><body>

Boston Tor Hackers: Join us Sunday September 19th

We're holding a Tor hackfest this Sunday, the 19th. Tor's Chief
Architect, Nick Mathewson, will be explaining Tor's goals and what the
project has been up to lately, and then we'll pick a few day-sized
projects to work on together with his help.

We'll be meeting at 2pm in the new Media Lab building (E14), room 240,
thanks to the Center for Future Civic Media at MIT. Since the building
is closed on Sundays, please e-mail chris-torfest@printf.net before
Sunday to get a phone number to use to be let in. We're hoping to
provide pizza and drinks, and we'll finish up and move to Grendel's Den
around 9pm.

Map: http://whereis.mit.edu/?go=E14

Please attend if you have some programming experience and are
interested in Tor, or are willing to be persuaded to entertain an
interest. :) Tor's a small project (in terms of number of developers)
that could really use your help.

Please RSVP if you can make it. Hope to see you on Sunday!

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B
+1-781-352-0568

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
skype:  lewmanator
</body></email><email><emailId>20100919065055</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-09-19 06:50:55-0400</timestampReceived><subject>Re: [or-cvs] r23240: {website} move mwenge to the core people page</subject><body>


On Sat, 18 Sep 2010 23:17:20 +0000 (UTC)
Roger Dingledine &lt;arma@torproject.org&gt; wrote:

&gt; Modified: website/trunk/en/people.wml
&gt; ===================================================================
&gt; --- website/trunk/en/people.wml	2010-09-18 23:11:33 UTC (rev 23239)
&gt; +++ website/trunk/en/people.wml	2010-09-18 23:17:20 UTC (rev 23240)
&gt; @@ -82,11 +82,17 @@

&gt; +&lt;dt&gt;Robert Hogan&lt;/dt&gt;&lt;dd&gt;Developer for the &lt;a
&gt; +href="http://tork.sf.net/"&gt;TorK&lt;/a&gt; Tor controller, a &lt;a
&gt; +href="http://code.google.com/p/torora/"&gt;privacy-oriented Aurora fork&lt;/a&gt;,

s/Aurora/Arora/


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100903194510</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2010-09-03 19:45:10-0400</timestampReceived><subject>Re: Tor multithreaded crypto</subject><body>

[Replying to or-dev with permission.  George is talking about the
draft ideas for multithreading and crypto as discussed on the wiki at
https://trac.torproject.org/projects/tor/wiki/projects/Tor/MultithreadedCrypto
.  Please read that before commenting, if you can.]

On Thu, Sep 2, 2010 at 3:12 PM, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt; Greetings Nick,
&gt;
&gt; I have some questions on the multithreading implementation.
&gt;
&gt; First of all, is it possible to use the cpuworker (obviously, with
&gt; alterations to fill our needs) infrastructure for this?
&gt; If we rename cpuworker_main() to cpuworker_onionskin() and generalize
&gt; a bit the whole thing, we could add a
&gt; assign_relay_crypt_to_cpuworker() which would get called from
&gt; circuit_package_relay_cell() and relay_crypt() and manage the whole
&gt; multithreaded AES crypt deal.

There are a few problems with the way cpuworkers handle communication
now that might make them a poor fit for AES crypto.  I'm not sure
whether the best move is to make them a better fit, or to just build
something else that fits to begin with.

The issues with using cpuworkers for AES crypto are:
  1) cpuworkers assume that they can run in a multiprocess or
multithreaded mode.  Our AES stuff really wants to happen in-process.
  2) Currently, all work is passed to cpuworkers over one half of a
socketpair, and their answers are passed back over the other half.
This is okay for public-key data structures, where the expense of the
crypto outweighs the cost of passing the data around, but for
stream-cipher stuff, we don't want to copy our data more than
necessary -- and copying it to and from kernel-space *twice* for every
crypto operation seems like it would probably hurt a lot.
  3) Cpuworkers have no notion of work priority.
  4) Cpuworkers are balanced by the main thread/process, which only
hands work to non-busy cpuworkers, and queues it otherwise.  This
isn't really an efficient way to assign work to workers.
  5) Even if we relax issue 1 above (so that we don't have to pass
data to cpuworkers over socketpairs) so we can relax assumption 2, we
still have cpuworkers using socketpairs as their
notification/synchronization mechanism.  That's not good either; we
can probably do an order of magnitude faster at least if we build
something using real thread synchronization primitives.

(At this point, somebody will point out that inter-process shared
memory exists.  Yes indeed it does.  Let's not got there. ;) )

&gt; We need to create, like you said, two per-circuit cell queue
&gt; structures, let's call them unencrypted_cell_queue_{in,out} for now
&gt; which will mimic cell_queue_t, and possibly a
&gt; circuit_relay_crypt_queue_t structure à la mimic onion_queue_t that
&gt; will hold all circuits that contain unencrypted cells.
&gt;
&gt;&gt; We will want some kind of a work-queue implementation for passing info
&gt;&gt; to the worker threads.
&gt;
&gt; What info should be passed to the worker threads? My naive mind says
&gt; that we need to basically pass the arguments of
&gt; relay_crypt_one_payload() which are:
&gt; "crypto_cipher_env_t *cipher, char *in, int encrypt_mode"
&gt; can't these be passed through pthread_create() in the same way that
&gt; spawn_func() and tor_pthread_helper_fn() are currently doing it?

No, you wouldn't want to do it like that: pthread_create() is called
only once per thread, and we sure don't want to create one thread per
cell, or even one thread per circuit.  We want to get closer to O(1)
cell per CPU.  Instead, you want to put this (or something like it,
maybe at a higher level) on a work queue, then have the threads pull
off pieces of work one at a time.

For instance, you could stick individual cells on a work queue, but
then you'd have to be careful about making sure they wound up
in-order.  Alternatively, you could stick "circuits in need of getting
some cells en/decrypted" on the work queue, and have the worker
threads just encrypt cells from them in-order.  Or maybe there's some
appropriate level in between.

&gt;&gt; We need to keep multiple workers from messing with the same circuit at once.
&gt;
&gt; Indeed, and as you may have noticed, I'm just stating obvious points
&gt; in my mail without touching the hot topics, like points were locking
&gt; should be implemented.
&gt; I haven't delved enough into concurrent programming to be able to talk
&gt; about this yet, but I guess/hope I'll clear the matter up soon :)

The way to avoid craziness here is probably to work out the smallest
amount of info that worker threads really need to touch, and lock that
alone.

&gt;&gt; We don't necessarily want to crypt all circuits' cells with the same
&gt;&gt; priority. Rather, we will probably want to use similar calculations to
&gt;&gt; those used by the circuit priority logic, maybe.
&gt;
&gt; I guess this is a matter of implementing some sort of scheduling (like
&gt; the circuit priority logic you mentioned) in our
&gt; process_pending_relay_crypto_task() function; no?

Well, "maybe".  It could be that we'll be better off just using
round-robin here, or partitioning circuits into two or three groups,
or something.  The overhead of the pqueue code that we use for circuit
priorities is definitely a win when it comes to dividing up or-conn
bandwidth (which is comparatively expensive), but it might not be such
a huge win for dividing up CPU.

&gt;&gt; We should design our data structures carefully and avoid like the
&gt;&gt; plague anything that will force us to iterate over all circuits, or
&gt;&gt; over all connections. That's really slow.
&gt;
&gt; I know I'm thinking freakingly short scale at the moment, but I don't
&gt; see this happening in our utopian implementation.
&gt;
&gt;&gt; Alerting the main thread is a little nontrivial with pre-2.0 Libevent,
&gt;&gt; but we can always fake it with a socketpair.
&gt;
&gt; You mean alerting circuit_package_relay_cell() or relay_crypt() that
&gt; their cells got encrypted? How is this usually done?

Well, you'd have another queue of work that needs to get done in the
main thread; have the workers add to it; have them alert the main
thread by waking it up whenever the queue's state goes from "empty" to
"nonempty".  The trick here is that the normal way of doing this
(using condition variables to build a work queue) doesn't work so well
since the main thread is using a select/poll/kqueue/epoll/whatever
event wakeup mechanism.  So we'll have to fake it, either with
Libevent's normal wakeup mechanisms (if we have Libevent 2.0), or via
a socketpair (if we don't).

Anyways, I hope this helps.  I'll try to come up with more
implementation detail, and answers to some of the coding questions for
this some time today or over the weekend.

peace,
-- 
Nick

</body></email><email><emailId>20100915172925</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2010-09-15 17:29:25-0400</timestampReceived><subject>Re: Tor multithreaded crypto</subject><body>

Hey,

I won't be playing with this for the next few days because of exams
and whatnot so I felt like throwing some minor progress I've done in
here.

Like I said in #tor-dev, treat it as pseudocode. Nothing is set in
stone and I'm just organizing everything in code to better understand
Nick's design. 

Behold! You can find a git diff here:
http://people.cs.unipi.gr/asn/multicrypto.patch

Like I said (and you will notice it right away, really) it's just
blueprints in code.
If any poor soul actually wants to open the file and look what's
inside, comments are more than welcome!

Thank you.
</body></email><email><emailId>20100921143150</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-09-21 14:31:50-0400</timestampReceived><subject>Re: [or-cvs] r23274: {website} add metrics, link to media.tpo,</subject><body>


On Tue, 21 Sep 2010 14:22:09 +0000 (UTC)
Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; Author: phobos
&gt; Date: 2010-09-21 14:22:09 +0000 (Tue, 21 Sep 2010)
&gt; New Revision: 23274
&gt; 
&gt; Modified:
&gt;    website/trunk/en/documentation.wml
&gt; Log:
&gt; add metrics, link to media.tpo, update some links to docs.
&gt; 
&gt; 
&gt; Modified: website/trunk/en/documentation.wml
&gt; ===================================================================
&gt; --- website/trunk/en/documentation.wml	2010-09-21 07:31:50 UTC (rev 23273)
&gt; +++ website/trunk/en/documentation.wml	2010-09-21 14:22:09 UTC (rev 23274)
&gt; @@ -66,7 +66,7 @@
&gt;  href="&lt;wiki&gt;TorFAQ#MyTorkeepscrashing."&gt;how
&gt;  to report a Tor bug&lt;/a&gt; first and then tell us as much information
&gt;  about it as you can in
&gt; -&lt;a href="https://bugs.torproject.org/tor"&gt;our bugtracker&lt;/a&gt;.
&gt; +&lt;a href="&lt;wiki&gt;"&gt;our bugtracker&lt;/a&gt;.
&gt;  (If your bug is
&gt;  with Polipo, your browser, or some other application, please don't put
&gt;  it in our bugtracker.) The

Polipo bugs do belong in the Tor Project's bug tracker now.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100723150309</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-07-23 15:03:09-0400</timestampReceived><subject>Proposal: Separate streams across circuits by destination port or</subject><body>


Hello,

Nick blessed me as a co-proposal editor last night at PETS2010; I've
given the following proposal an initial number of 171.

The proposal in question will be updated in my git repository until it
is accepted into master:
https://gitweb.torproject.org/ioerror/tor.git/blob/refs/heads/isolated-st=
reams:/doc/spec/proposals/171-separate-streams-by-port-or-host.txt

Here's the proposal in question:

Filename: 171-separate-streams-by-port-or-host.txt
Title: Separate streams across circuits by destination port or
destination host
Author: Robert Hogan, Jacob Appelbaum, Damon McCoy
Created: 21-Oct-2008
Modified: 22-Jul-2010
Status: Draft

Motivation:

Streams are currently attached to circuits without regard to their
content, destination host, or destination port. We propose two options,
IsolateStreamsByPort and IsolateStreamsByHost to change the default
behavior.

The contents of some streams will always have revealing plain text
information; these streams should be treated differently than other
streams that may or may not have unencrypted PII content. DNS, with the
exception of DNSCurve, is always unencrypted. It is reasonable to assume
that other protocols may exist that have a similar issue and may cause
user concern. It is also the case that we must balance network load
issues and stream privacy. The Tor network will not currently scale to
one circuit per connection nor should it anytime soon.

Circuits are currently created with a few constraints and are rotated
within a reasonable time window. This allows a rogue exit nodes to
correlate all streams on a given circuit.

Design:

We propose two options for isolation of streams that lessen the
observability and linkability of the Tor client's traffic.

IsolateStreamsByPort will take a list of ports or optionally the keyword
'All' in place of a port list. The use of the keyword 'All' will ensure
that all connections attached to streams will be isolated to separate
circuits by port number.

IsolateStreamsByHost will take a boolean value. When enabled, all
connections, regardless of port number will be isolated with separate
circuits per host. If this option is enabled, we should ensure that the
client has a reasonable number of pre-built circuits to ensure perceived
performance. This should also intentionally limit the total number of
circuits a client will build to ten circuits to prevent abuse and load
on the network. This is a trade-off of performance for anonymity. Tor
will issue a warning if a client encounters this
limit.

Security implications:

It is believed that the proposed changes will improve the anonymity for
end user stream privacy.  The end user will no longer link all of their
traffic at a single exit node during a given time window.

Specification:

The Tor client circuit selection process is not entirely specified. Any
client circuit specification must take these changes into account.

Compatibility:

The proposed changes should not create any compatibility issues. New Tor
clients will be able to take advantage of this without any modification
to the network.

Implementation:

It is further proposed that IsolateStreamsByPort will be enabled by
default for port 22, 53, and port 80.

It is further proposed that IsolateStreamsByHost will be disabled by
default.

Implementation notes:

The implementation of this option may want to consider cases where the
same exit node is shared by two or more circuits and
IsolateStreamsByPort is in force. Since the purpose of the option is to
reduce the opportunity of Exit Nodes to attack traffic from the same
source on multiple ports, the implementation may need to ensure that
circuits reserved for the exclusive use of given ports do not share the
same exit node.

Performance and scalability notes:

It is further proposed that IsolateStreamsByPort will be enabled by
default for all ports after a reasonable assessment is performed.
Specifically, we should determine the impact this option has on Tor
clients and the Tor network.


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100723183711</emailId><senderName>starslights</senderName><senderEmail>stars@hispeed.ch</senderEmail><timestampReceived>2010-07-23 18:37:11-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>


Le vendredi 23 juillet 2010 17.03:09, vous avez écrit :
&gt; Hello,
&gt; 
&gt; Nick blessed me as a co-proposal editor last night at PETS2010; I've
&gt; given the following proposal an initial number of 171.
&gt; 
&gt; The proposal in question will be updated in my git repository until it
&gt; is accepted into master:
&gt; https://gitweb.torproject.org/ioerror/tor.git/blob/refs/heads/isolated-stre
&gt; ams:/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; 
&gt; Here's the proposal in question:
&gt; 
&gt; Filename: 171-separate-streams-by-port-or-host.txt
&gt; Title: Separate streams across circuits by destination port or
&gt; destination host
&gt; Author: Robert Hogan, Jacob Appelbaum, Damon McCoy
&gt; Created: 21-Oct-2008
&gt; Modified: 22-Jul-2010
&gt; Status: Draft
&gt; 
&gt; Motivation:
&gt; 
&gt; Streams are currently attached to circuits without regard to their
&gt; content, destination host, or destination port. We propose two options,
&gt; IsolateStreamsByPort and IsolateStreamsByHost to change the default
&gt; behavior.
&gt; 
&gt; The contents of some streams will always have revealing plain text
&gt; information; these streams should be treated differently than other
&gt; streams that may or may not have unencrypted PII content. DNS, with the
&gt; exception of DNSCurve, is always unencrypted. It is reasonable to assume
&gt; that other protocols may exist that have a similar issue and may cause
&gt; user concern. It is also the case that we must balance network load
&gt; issues and stream privacy. The Tor network will not currently scale to
&gt; one circuit per connection nor should it anytime soon.
&gt; 
&gt; Circuits are currently created with a few constraints and are rotated
&gt; within a reasonable time window. This allows a rogue exit nodes to
&gt; correlate all streams on a given circuit.
&gt; 
&gt; Design:
&gt; 
&gt; We propose two options for isolation of streams that lessen the
&gt; observability and linkability of the Tor client's traffic.
&gt; 
&gt; IsolateStreamsByPort will take a list of ports or optionally the keyword
&gt; 'All' in place of a port list. The use of the keyword 'All' will ensure
&gt; that all connections attached to streams will be isolated to separate
&gt; circuits by port number.
&gt; 
&gt; IsolateStreamsByHost will take a boolean value. When enabled, all
&gt; connections, regardless of port number will be isolated with separate
&gt; circuits per host. If this option is enabled, we should ensure that the
&gt; client has a reasonable number of pre-built circuits to ensure perceived
&gt; performance. This should also intentionally limit the total number of
&gt; circuits a client will build to ten circuits to prevent abuse and load
&gt; on the network. This is a trade-off of performance for anonymity. Tor
&gt; will issue a warning if a client encounters this
&gt; limit.
&gt; 
&gt; Security implications:
&gt; 
&gt; It is believed that the proposed changes will improve the anonymity for
&gt; end user stream privacy.  The end user will no longer link all of their
&gt; traffic at a single exit node during a given time window.
&gt; 
&gt; Specification:
&gt; 
&gt; The Tor client circuit selection process is not entirely specified. Any
&gt; client circuit specification must take these changes into account.
&gt; 
&gt; Compatibility:
&gt; 
&gt; The proposed changes should not create any compatibility issues. New Tor
&gt; clients will be able to take advantage of this without any modification
&gt; to the network.
&gt; 
&gt; Implementation:
&gt; 
&gt; It is further proposed that IsolateStreamsByPort will be enabled by
&gt; default for port 22, 53, and port 80.
&gt; 
&gt; It is further proposed that IsolateStreamsByHost will be disabled by
&gt; default.
&gt; 
&gt; Implementation notes:
&gt; 
&gt; The implementation of this option may want to consider cases where the
&gt; same exit node is shared by two or more circuits and
&gt; IsolateStreamsByPort is in force. Since the purpose of the option is to
&gt; reduce the opportunity of Exit Nodes to attack traffic from the same
&gt; source on multiple ports, the implementation may need to ensure that
&gt; circuits reserved for the exclusive use of given ports do not share the
&gt; same exit node.
&gt; 
&gt; Performance and scalability notes:
&gt; 
&gt; It is further proposed that IsolateStreamsByPort will be enabled by
&gt; default for all ports after a reasonable assessment is performed.
&gt; Specifically, we should determine the impact this option has on Tor
&gt; clients and the Tor network.

Hi  Jacob,

Thanks very much to sahre with us, it look a good idea for me, some site still 
resitant against ssl and little help for security will welcome....

I will give a try.

I will give my feedback, best regrads

SwissTorExit

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100927055309</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-09-27 05:53:09-0400</timestampReceived><subject>Correctness proof for new bandwidth-weights (bug 1952)</subject><body>


Recently, Tor 0.2.2.x-alpha has suffered from a serious bug that
caused the directory authorities to produce incorrect
bandwidth-weights for use by 0.2.2.x clients.

The process used is described in 3.4.3 of dir-spec.txt
https://gitweb.torproject.org/tor.git/blob_plain/HEAD:/doc/spec/dir-spec.txt

To achieve balance, we start with 5 equations for 7 unknowns, and then
we add 2 extra equations depending upon the amount of capacity in the
network, as described by the cases in 3.4.3.

The problem is that the extra constraints added for case 1, case 2b,
and case 3b can lead to solutions outside of the range of
0..weight_scale in some cases. These solutions are invalid for use as
selection weights.

Because these invalid solution situations have begun to appear on the
current network, I've spent the past few days redoing these cases to
solve this bug: https://trac.torproject.org/projects/tor/ticket/1952

The new extra constraints are:

Case 1: Wmg == Wmd, Wed == 1/3.
Case 2b:
  Wgg == 1, Wee == 1
Case 3b:
  If G&lt;E: Wgg = 1, Wmd == Wed
  If E&lt;G: Wee == 1, Wmd == Wgd

To prove they are correct, we simply consider the cases where each
weight might exceed weight_scale, and where each might fall below 0.


For Case 1, the solution to the 7 equations is:
  Wgd = weight_scale/3
  Wed = weight_scale/3
  Wmd = weight_scale/3
  Wee = (weight_scale*(E+G+M))/(3*E)
  Wme = weight_scale - Wee
  Wmg = (weight_scale*(2*G-E-M))/(3*G)
  Wgg = weight_scale - Wmg

Now, let's examine those weights that can either exceed weight_scale,
or fall below 0. We derive conditions for valid solution ranges, and
then compare these conditions to the case requirements:

Wee &lt;= weight_scale:
  E+G+M &lt;= 3*E               # From (weight_scale*(E+G+M))/(3*E)
  E+G+M+D &lt;= 3*E+D
  T &lt;= 3*E+D                 # From T=G+M+E+D
  (T-D)/3 &lt;= E

  Since Case 1 is only in effect while E &gt;= T/3, this constraint is
  clearly always true.
  
Wme &gt;= 0:
  2*E-G-M &gt;= 0              # From Wme's denominator
  2*E+D+E &gt; = G+M+E+D
  3*E+D &gt;= T
  E &gt;= (T-D)/3
  
  This is true because of the conditions for Case 1: E &gt;= T/3 &amp;&amp; G &gt;= T/3.
 
Wmg &lt;= weight_scale:
  2*G-E-M &lt;= 3*G
  0 &lt;= G+E+M
  D &lt;= G+E+M+D
  D &lt;= T

Wmg &gt;= 0:
  2*G-E-M &gt;= 0
  2*G+D+G &gt;= E+M+D+G
  3*G+D &gt;= T
  G &gt;= (T-D)/3 

  This is true because of the conditions for Case 1: E &gt;= T/3 &amp;&amp; G &gt;= T/3.


Case 2b:

  Wgg = Wee = weight_scale
  Wed = (weight_scale*(D - 2*E + G + M))/(3*D)
  Wmd = (weight_Scale*(D - 2*M + G + E))/(3*D)
  Wme = Wmg = 0
  Wgd = weight_scale - Wed - Wmd

In this case, we need to check the following:

Wed &gt;= 0:
  D+G+M-2*E &gt;= 0
  D+G+M+E &gt;= 3*E
  T/3 &gt;= E

  This is one of the conditions for Case 2b.

Wgd &gt;= 0:
  Wed + Wmd &lt;= 1
  2*D-2*E-2*M+2*G+M+E &lt;= 3*D
  2*G-M-E-D &lt;= 0
  3*G &lt;= M+E+D+G
  G &lt;= T/3

  This is one of the conditions for Case 2b.

Wmd &gt;= 0:
  D+G+E-2*M &gt; 0
  T/3 &gt;= M

  If your eyes haven't glazed over yet, you'll notice that this last
  condition can actually be true. If we don't hand out enough Guard
  flags, there may be too many middle nodes. In this case, the code just
  warns and suggests that the WFU parameters be lowered.


Case 3b:

For case 3b, there are two subcases, but they are the same formula
set, just with E and G reversed. Thus, we only need to prove one of
them. For simplicity, let's do the E scarce case, as that is the only
one of the two we have ever seen:

  Wee = weight_scale;
  Wed = (weight_scale*(D - 2*E + G + M))/(3*D);
  Wme = 0;
  Wgg = (weight_scale*(G+M))/(2*G);
  Wmg = weight_scale - Wgg;
  Wmd = (weight_scale - Wed)/2;


Wed &gt;= 0:
  D - 2*E + G + M &gt;= 0
  D + E + G + M &gt;= 3E
  T/3 &gt;= E

  This is one of the conditions for Case 3b.

Wed &lt;= weight_scale:
  D - 2*E + G + M &lt;= 3*D
  G + M &lt;= 2*D + 2*E
  G + E + M + D &lt;= 3*D + 3*E
  T/3 &lt;= D+E

  This is also one of the conditions for Case 3b, when E is scarce.

Wgg &lt;= weight_scale:
  G+M &lt;= 2*G
  M &lt;= G

  Since G &gt;= T/3, and E+D &gt;= T/3, we know that M &lt;= T/3. So M &lt;= G.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100723190912</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2010-07-23 19:09:12-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>


[Attachment #2 (multipart/mixed)]
[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100723211833</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-07-23 21:18:33-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or</subject><body>

On Fri, Jul 23, 2010 at 3:09 PM, Linus Nordberg &lt;linus@nordberg.se&gt; wrote:
&gt; 2. &gt;IsolateStreamsByPort will take a list of ports or optionally the
&gt;   &gt;keyword 'All' in place of a port list. The use of the keyword 'All'
&gt;   &gt;will ensure that all connections attached to streams will be
&gt;   &gt;isolated to separate circuits by port number.
&gt;
&gt;   Just to make it clear, would a packet sent to hostA:port1 end up
&gt;   on the same circuit as one sent to hostB:port1?

If I understand correctly, the answer is yes if IsolateStreamsByHost
is set to 'False' (the proposed default).

&gt; 3. If 2 says yes, would this turn into a no if IsolateStreamsByHost was
&gt;   enabled?

Correct. The two options are independent, so if IsolateStreamsByHost
is set to 'True', then it is always true that circuit(hostA:portx) !=
circuit(hostB:porty), regardless of ports x and y (even if x == y).

Now my understanding is that if IsolateStreamsByPort is set to 'All'
and IsolateStreamsByHost is set to 'True', then circuit(h_1, p_1) !=
... != circuit(h_m, p_n) is always true for all permutations of hosts
h in {h_1, ..., h_m} and ports p in {p_1, ..., p_n}.

As the proposal mentions, the number of circuits can grow quickly in
that case (imagine the overhead from Bittorrent), so limiting the
ports list to 22, 80 and such is a good idea, but you might also
consider just turning off IsolateStreamsByHost entirely if certain
limits are reached.

This is an excellent proposal. :)

-- 
Mansour Moufid

</body></email><email><emailId>20100808001038</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-08 00:10:38-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or</subject><body>

On Fri, Jul 23, 2010 at 11:03 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; Hello,
&gt; 
&gt; Nick blessed me as a co-proposal editor last night at PETS2010; I've
&gt; given the following proposal an initial number of 171.
&gt; 
&gt; The proposal in question will be updated in my git repository until it
&gt; is accepted into master:
&gt; https://gitweb.torproject.org/ioerror/tor.git/blob/refs/heads/isolated-streams:/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt;  
&gt; Here's the proposal in question:
&gt; 
&gt; Filename: 171-separate-streams-by-port-or-host.txt
&gt; Title: Separate streams across circuits by destination port or
&gt; destination host
&gt; Author: Robert Hogan, Jacob Appelbaum, Damon McCoy
&gt; Created: 21-Oct-2008
&gt; Modified: 22-Jul-2010
&gt; Status: Draft
&gt; 

Hi, Jacob, and sorry about the delay in getting to this.  I think I've
figured out a way to enhance this proposal and make it even more
secure.

Preliminary notes:

A. You should consistently say "streams" or "application connections"
not "connections".  In Tor specification vocab, we tried to reserve
"connection" for an arbitrary TCP connection (including OR
connections) and "stream" for the kind of connection-like thing that
gets relayed end-to-end.

B. There's an attack we talked about at PETS where a hostile web page
possibly in collusion with an exit node contains image links for
images at (say) "evil.example.com:53" and "evil.example.com:31337",
and thereby (if they're lucky) correlate port-80 circuits with port-53
and port-31337 circuits.  This isn't a total showstopper, but it needs
to be analyzed.

C. This part needs clarification IMO:

&gt; Implementation notes:
&gt; 
&gt; The implementation of this option may want to consider cases where the
&gt; same exit node is shared by two or more circuits and
&gt; IsolateStreamsByPort is in force. Since the purpose of the option is to
&gt; reduce the opportunity of Exit Nodes to attack traffic from the same
&gt; source on multiple ports, the implementation may need to ensure that
&gt; circuits reserved for the exclusive use of given ports do not share the
&gt; same exit node.

There is too much "we may want to X" here for now.  We should figure
out the answer to whether isolated circuits should force distinct exit
nodes or not, and either say "do it" or "don't do it".  If we can't
answer this in the spec, it's pretty hopeless to ask users or
implementors to decide it for us in the future.

D. Allow me to propose a third way to isolate streams that will enable
even smarter application-level isolation without requiring any code
changes to most applications:

** IsolateBySOCKSUser -- If this boolean option is true, then Tor will
look at the username field of the SOCKS protocol, and make sure that
any two streams that were created with different SOCKS usernames will
be sent over different circuits.  The empty username will be treated
as its own username different from all other usernames.

Assuming an application with complete socks support (or an application
using a proxy with complete socks support, etc), the application can
use this to isolate all of its connections regardless of port.  If you
want to isolate your IM connections from your firefox connections from
your ttdnsd connections, all you need to do is tell each application a
different socks username in its configuration.  You could have two
connections to the same host on the same port always use different
circuits simply by setting up a socat connection for each one that
always used .

An application (or application plugin) that was aware of this feature
could even use it to signal which streams are inherently linkable, and
which streams should remain unlinkable.

This feature would incidentally make the attack in B unfeasible.

One thing I'm not sure of: should it look at socks user only, or
should it look at user+password combination?

yrs,
-- 
Nick


</body></email><email><emailId>20100808112306</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-08-08 11:23:06-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>

On Sunday 08 August 2010 01:10:38 Nick Mathewson wrote:
&gt; 
&gt; ** IsolateBySOCKSUser -- If this boolean option is true, then Tor will
&gt; look at the username field of the SOCKS protocol, and make sure that
&gt; any two streams that were created with different SOCKS usernames will
&gt; be sent over different circuits.  The empty username will be treated
&gt; as its own username different from all other usernames.
&gt; 

Given that the problem is how to use separate circuits per application this 
sounds much closer to the real solution than separating by service port.

Maybe there are other things Tor could do with the SOCKS connection if 
username information is not present:

- Do not share SOCKS4/4a/5 on the same circuit.
- On *nix use the source port to look up the connection's application name 
  in  /proc/pid/cmdline and, if cmdline is readable, treat that as a SOCKS
  username when choosing circuits.

</body></email><email><emailId>20100808183911</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-08 18:39:11-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port</subject><body>


On Sun, 8 Aug 2010 12:23:06 +0100
Robert Hogan &lt;robert@roberthogan.net&gt; wrote:

&gt; Maybe there are other things Tor could do with the SOCKS connection if 
&gt; username information is not present:
&gt; 
&gt; - Do not share SOCKS4/4a/5 on the same circuit.
&gt; - On *nix use the source port to look up the connection's application name 
&gt;   in  /proc/pid/cmdline and, if cmdline is readable, treat that as a SOCKS
&gt;   username when choosing circuits.

- Do not share circuits across multiple client IP addresses (when
  SocksPort is exposed to a local network).
- Do not share circuits across clients connecting to different SOCKS
  ports (when the SocksListenAddress is used to specify multiple SOCKS
  listeners).


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100808213017</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2010-08-08 21:30:17-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or</subject><body>

On Sat, Aug 7, 2010 at 8:10 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; B. There's an attack we talked about at PETS where a hostile web page
&gt; possibly in collusion with an exit node contains image links for
&gt; images at (say) "evil.example.com:53" and "evil.example.com:31337",
&gt; and thereby (if they're lucky) correlate port-80 circuits with port-53
&gt; and port-31337 circuits.  This isn't a total showstopper, but it needs
&gt; to be analyzed.

Whatever information is gained from such an attack would be no more
than what can be known currently, except that separate circuits would
mean the attacker has to then control many more exit nodes to get the
same information. So in the worst case scenario the user isn't any
more exposed than they already are. This assumes circuits do not share
exit nodes...

&gt; C. This part needs clarification IMO:
&gt;
&gt;&gt; Implementation notes:
&gt;&gt;
&gt;&gt; The implementation of this option may want to consider cases where the
&gt;&gt; same exit node is shared by two or more circuits and
&gt;&gt; IsolateStreamsByPort is in force. Since the purpose of the option is to
&gt;&gt; reduce the opportunity of Exit Nodes to attack traffic from the same
&gt;&gt; source on multiple ports, the implementation may need to ensure that
&gt;&gt; circuits reserved for the exclusive use of given ports do not share the
&gt;&gt; same exit node.
&gt;
&gt; There is too much "we may want to X" here for now.  We should figure
&gt; out the answer to whether isolated circuits should force distinct exit
&gt; nodes or not, and either say "do it" or "don't do it".  If we can't
&gt; answer this in the spec, it's pretty hopeless to ask users or
&gt; implementors to decide it for us in the future.

I think no two circuits should use the same exit node, because doing
otherwise would defeat the purpose of the proposal.

&gt; D. Allow me to propose a third way to isolate streams that will enable
&gt; even smarter application-level isolation without requiring any code
&gt; changes to most applications:
&gt;
&gt; ** IsolateBySOCKSUser -- If this boolean option is true, then Tor will
&gt; look at the username field of the SOCKS protocol, and make sure that
&gt; any two streams that were created with different SOCKS usernames will
&gt; be sent over different circuits.  The empty username will be treated
&gt; as its own username different from all other usernames.
&gt;
&gt; Assuming an application with complete socks support (or an application
&gt; using a proxy with complete socks support, etc), the application can
&gt; use this to isolate all of its connections regardless of port.  If you
&gt; want to isolate your IM connections from your firefox connections from
&gt; your ttdnsd connections, all you need to do is tell each application a
&gt; different socks username in its configuration.  You could have two
&gt; connections to the same host on the same port always use different
&gt; circuits simply by setting up a socat connection for each one that
&gt; always used .
&gt;
&gt; An application (or application plugin) that was aware of this feature
&gt; could even use it to signal which streams are inherently linkable, and
&gt; which streams should remain unlinkable.
&gt;
&gt; This feature would incidentally make the attack in B unfeasible.
&gt;
&gt; One thing I'm not sure of: should it look at socks user only, or
&gt; should it look at user+password combination?

Why not take this idea further: "IsolateStreamsBySOCKSFields" -- a
list of one or more keywords {"username", "password", "destination
address", "port number"}. Their values in the actual SOCKS fields
would be hashed together, along with a nonce, and each unique outcome
assigned to a circuit (not necessarily one-to-one). The nonce could be
changed every, say, 10 minutes.

That way, application that are SOCKS unaware would all be assigned the
same "default" circuit (similar to the current behaviour). If
'username' is in the list, then applications that want separate
circuits from other applications could set the username field. If
'password' is also in the list, applications that want multiple unique
circuits could set both the username and password fields, e.g. your
browser uses one password for DNS, another for 80, yet another for
443.

If only 'destination address' or 'port number' (or both) are listed,
then this emulates the behaviour of IsolateStreamsBy{Host,Port}.

Users that didn't want to support any of this could just leave
IsolateStreamsBySOCKSFields empty (in which case only the nonce
matters).

Seems like a compromise. :)

-- 
Mansour Moufid

</body></email><email><emailId>20100825211228</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-08-25 21:12:28-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>

So this is my take on the thread so far:

- We've zoned in on the fact that this proposal is really about isolating 
applications on circuits rather than ports on circuits.

- Isolating by destination address is likely to increase the number of 
circuits the client builds by some scary quantity.

- There is a potential attack if we isolate by port number alone. A 
malicious website could server resources over a variety of port numbers, 
learn our exit nodes for each, and then presumably correlate our activity 
on port 443/80 with our activity on any services we use that it happens to 
provide on any of the other ports.

- We can achieve some/a lot of the benefits sought by the proposal if we 
isolate streams based on the information provided by the socks request 
itself. The things people have suggested are:
  1 Socks authentication info (username/pass)
  2 Socks listener address/port
  3 Socks protocol
  4 Socks client IP
  5 Info in /proc/pid/cmdline garnered from the client's port number

My own view is that 1 to 4 above could be used to determine the choice of 
circuit even in the absence of an IsolateStreamsBy* option. 5 is ugly and 
generally won't work if running as a 'tor' user so can be discarded.

I think the only argument for making item 1 optional would be so that 
people know about it. Maybe it can be an option and on by default. 

Thoughts?


On Friday 23 July 2010 16:03:09 Jacob Appelbaum wrote:
&gt; Hello,
&gt; 
&gt; Nick blessed me as a co-proposal editor last night at PETS2010; I've
&gt; given the following proposal an initial number of 171.
&gt; 
&gt; The proposal in question will be updated in my git repository until it
&gt; is accepted into master:
&gt; https://gitweb.torproject.org/ioerror/tor.git/blob/refs/heads/isolated-s
&gt; treams:/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; 
&gt; Here's the proposal in question:
&gt; 
&gt; Filename: 171-separate-streams-by-port-or-host.txt
&gt; Title: Separate streams across circuits by destination port or
&gt; destination host
&gt; Author: Robert Hogan, Jacob Appelbaum, Damon McCoy
&gt; Created: 21-Oct-2008
&gt; Modified: 22-Jul-2010
&gt; Status: Draft
&gt; 
&gt; Motivation:
&gt; 
&gt; Streams are currently attached to circuits without regard to their
&gt; content, destination host, or destination port. We propose two options,
&gt; IsolateStreamsByPort and IsolateStreamsByHost to change the default
&gt; behavior.
&gt; 
&gt; The contents of some streams will always have revealing plain text
&gt; information; these streams should be treated differently than other
&gt; streams that may or may not have unencrypted PII content. DNS, with the
&gt; exception of DNSCurve, is always unencrypted. It is reasonable to assume
&gt; that other protocols may exist that have a similar issue and may cause
&gt; user concern. It is also the case that we must balance network load
&gt; issues and stream privacy. The Tor network will not currently scale to
&gt; one circuit per connection nor should it anytime soon.
&gt; 
&gt; Circuits are currently created with a few constraints and are rotated
&gt; within a reasonable time window. This allows a rogue exit nodes to
&gt; correlate all streams on a given circuit.
&gt; 
&gt; Design:
&gt; 
&gt; We propose two options for isolation of streams that lessen the
&gt; observability and linkability of the Tor client's traffic.
&gt; 
&gt; IsolateStreamsByPort will take a list of ports or optionally the keyword
&gt; 'All' in place of a port list. The use of the keyword 'All' will ensure
&gt; that all connections attached to streams will be isolated to separate
&gt; circuits by port number.
&gt; 
&gt; IsolateStreamsByHost will take a boolean value. When enabled, all
&gt; connections, regardless of port number will be isolated with separate
&gt; circuits per host. If this option is enabled, we should ensure that the
&gt; client has a reasonable number of pre-built circuits to ensure perceived
&gt; performance. This should also intentionally limit the total number of
&gt; circuits a client will build to ten circuits to prevent abuse and load
&gt; on the network. This is a trade-off of performance for anonymity. Tor
&gt; will issue a warning if a client encounters this
&gt; limit.
&gt; 
&gt; Security implications:
&gt; 
&gt; It is believed that the proposed changes will improve the anonymity for
&gt; end user stream privacy.  The end user will no longer link all of their
&gt; traffic at a single exit node during a given time window.
&gt; 
&gt; Specification:
&gt; 
&gt; The Tor client circuit selection process is not entirely specified. Any
&gt; client circuit specification must take these changes into account.
&gt; 
&gt; Compatibility:
&gt; 
&gt; The proposed changes should not create any compatibility issues. New Tor
&gt; clients will be able to take advantage of this without any modification
&gt; to the network.
&gt; 
&gt; Implementation:
&gt; 
&gt; It is further proposed that IsolateStreamsByPort will be enabled by
&gt; default for port 22, 53, and port 80.
&gt; 
&gt; It is further proposed that IsolateStreamsByHost will be disabled by
&gt; default.
&gt; 
&gt; Implementation notes:
&gt; 
&gt; The implementation of this option may want to consider cases where the
&gt; same exit node is shared by two or more circuits and
&gt; IsolateStreamsByPort is in force. Since the purpose of the option is to
&gt; reduce the opportunity of Exit Nodes to attack traffic from the same
&gt; source on multiple ports, the implementation may need to ensure that
&gt; circuits reserved for the exclusive use of given ports do not share the
&gt; same exit node.
&gt; 
&gt; Performance and scalability notes:
&gt; 
&gt; It is further proposed that IsolateStreamsByPort will be enabled by
&gt; default for all ports after a reasonable assessment is performed.
&gt; Specifically, we should determine the impact this option has on Tor
&gt; clients and the Tor network.
</body></email><email><emailId>20100826184432</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-26 18:44:32-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or</subject><body>

On Wed, Aug 25, 2010 at 5:12 PM, Robert Hogan &lt;robert@roberthogan.net&gt; wrote:
&gt; So this is my take on the thread so far:
&gt;
&gt; - We've zoned in on the fact that this proposal is really about isolating
&gt; applications on circuits rather than ports on circuits.
&gt;
&gt; - Isolating by destination address is likely to increase the number of
&gt; circuits the client builds by some scary quantity.
&gt;
&gt; - There is a potential attack if we isolate by port number alone. A
&gt; malicious website could server resources over a variety of port numbers,
&gt; learn our exit nodes for each, and then presumably correlate our activity
&gt; on port 443/80 with our activity on any services we use that it happens to
&gt; provide on any of the other ports.
&gt;
&gt; - We can achieve some/a lot of the benefits sought by the proposal if we
&gt; isolate streams based on the information provided by the socks request
&gt; itself. The things people have suggested are:
&gt;  1 Socks authentication info (username/pass)
&gt;  2 Socks listener address/port
&gt;  3 Socks protocol
&gt;  4 Socks client IP
&gt;  5 Info in /proc/pid/cmdline garnered from the client's port number
&gt;
&gt; My own view is that 1 to 4 above could be used to determine the choice of
&gt; circuit even in the absence of an IsolateStreamsBy* option. 5 is ugly and
&gt; generally won't work if running as a 'tor' user so can be discarded.

I tend to agree wrt 1..4.

5 is not only ugly but also hard and unportable.  I spent a lovely
evening a couple of weeks back reading the sources to "lsof" to see
how they answer the "what process is using this socket" question, and
the games that lsof needs to play are fiddly, platform-specific, and
sometimes grossly inefficient.  My hat is off to the lsof authors and
maintainers, but we do not want to try to do what they do.

&gt; I think the only argument for making item 1 optional would be so that
&gt; people know about it. Maybe it can be an option and on by default.

Personally, I think it's fine to have all of 1..4 on-by-default and
maybe even "always on".  I am having a hard time thinking of a use
case where somebody is using socks username/password or multiple socks
listeners or multiple socks protocols or connecting from multiple
client IPs and where they would _want_ the streams from these
different socks usage profiles coalesced into different circuits
together.

-- 
Nick

</body></email><email><emailId>20100831003306</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-08-31 00:33:06-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port</subject><body>

On 08/07/2010 05:10 PM, Nick Mathewson wrote:
&gt; On Fri, Jul 23, 2010 at 11:03 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; &gt; Hello,
&gt; &gt; 
&gt; &gt; Nick blessed me as a co-proposal editor last night at PETS2010; I've
&gt; &gt; given the following proposal an initial number of 171.
&gt; &gt; 
&gt; &gt; The proposal in question will be updated in my git repository until it
&gt; &gt; is accepted into master:
&gt; &gt; https://gitweb.torproject.org/ioerror/tor.git/blob/refs/heads/isolated-streams:/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; &gt;  
&gt; &gt; Here's the proposal in question:
&gt; &gt; 
&gt; &gt; Filename: 171-separate-streams-by-port-or-host.txt
&gt; &gt; Title: Separate streams across circuits by destination port or
&gt; &gt; destination host
&gt; &gt; Author: Robert Hogan, Jacob Appelbaum, Damon McCoy
&gt; &gt; Created: 21-Oct-2008
&gt; &gt; Modified: 22-Jul-2010
&gt; &gt; Status: Draft
&gt; &gt; 
&gt; 
&gt; Hi, Jacob, and sorry about the delay in getting to this.  I think I've
&gt; figured out a way to enhance this proposal and make it even more
&gt; secure.
&gt; 
&gt; Preliminary notes:
&gt; 
&gt; A. You should consistently say "streams" or "application connections"
&gt; not "connections".  In Tor specification vocab, we tried to reserve
&gt; "connection" for an arbitrary TCP connection (including OR
&gt; connections) and "stream" for the kind of connection-like thing that
&gt; gets relayed end-to-end.
&gt; 

Good point, I've updated the proposal to fix the terminology.

&gt; B. There's an attack we talked about at PETS where a hostile web page
&gt; possibly in collusion with an exit node contains image links for
&gt; images at (say) "evil.example.com:53" and "evil.example.com:31337",
&gt; and thereby (if they're lucky) correlate port-80 circuits with port-53
&gt; and port-31337 circuits.  This isn't a total showstopper, but it needs
&gt; to be analyzed.

I agree. I've added this to the proposal - nearly word for word.

&gt; 
&gt; C. This part needs clarification IMO:
&gt; 
&gt; &gt; Implementation notes:
&gt; &gt; 
&gt; &gt; The implementation of this option may want to consider cases where the
&gt; &gt; same exit node is shared by two or more circuits and
&gt; &gt; IsolateStreamsByPort is in force. Since the purpose of the option is to
&gt; &gt; reduce the opportunity of Exit Nodes to attack traffic from the same
&gt; &gt; source on multiple ports, the implementation may need to ensure that
&gt; &gt; circuits reserved for the exclusive use of given ports do not share the
&gt; &gt; same exit node.
&gt; 
&gt; There is too much "we may want to X" here for now.  We should figure
&gt; out the answer to whether isolated circuits should force distinct exit
&gt; nodes or not, and either say "do it" or "don't do it".  If we can't
&gt; answer this in the spec, it's pretty hopeless to ask users or
&gt; implementors to decide it for us in the future.

I agree. I say that we "do it" but I'm not sure how to reword this -
thoughts?

&gt; 
&gt; D. Allow me to propose a third way to isolate streams that will enable
&gt; even smarter application-level isolation without requiring any code
&gt; changes to most applications:
&gt; 
&gt; ** IsolateBySOCKSUser -- If this boolean option is true, then Tor will
&gt; look at the username field of the SOCKS protocol, and make sure that
&gt; any two streams that were created with different SOCKS usernames will
&gt; be sent over different circuits.  The empty username will be treated
&gt; as its own username different from all other usernames.
&gt; 
&gt; Assuming an application with complete socks support (or an application
&gt; using a proxy with complete socks support, etc), the application can
&gt; use this to isolate all of its connections regardless of port.  If you
&gt; want to isolate your IM connections from your firefox connections from
&gt; your ttdnsd connections, all you need to do is tell each application a
&gt; different socks username in its configuration.  You could have two
&gt; connections to the same host on the same port always use different
&gt; circuits simply by setting up a socat connection for each one that
&gt; always used .
&gt; 
&gt; An application (or application plugin) that was aware of this feature
&gt; could even use it to signal which streams are inherently linkable, and
&gt; which streams should remain unlinkable.
&gt; 

That's a great idea. I've added it to the proposal.

&gt; This feature would incidentally make the attack in B unfeasible.
&gt; 
&gt; One thing I'm not sure of: should it look at socks user only, or
&gt; should it look at user+password combination?

I think that probably use both but fail closed; specifically, it seems
to be a good idea to not allow a local application to try to discover
circuits created by another application. I worry that a local
application may try to connect to say, an upstream webserver with local
username 'pidgin' and no password. What happens? I think without a
proper password, we should allow them through but not link the circuits...

Thoughts?

All the best,
Jacob


</body></email><email><emailId>20100805144057</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-08-05 14:40:57-0400</timestampReceived><subject>Encryption over Hidden Services</subject><body>


Is transport or message layer encryption redundant between a tor client
and a hidden service?

We are working on a simple "p2p" messaging service between Android
devices running Tor, with each running a hidden service to accept
messages. I am trying to figure out if we need to OTR or SSL on top of
this for any reason.

I am just trying to understand how far we should rely on encryption with
the Tor stack for this type of thing, vs. adding in our own bits (err,
bytes).

+n


</body></email><email><emailId>20100802143101</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-08-02 14:31:01-0400</timestampReceived><subject>Proposal: Optimistic Data for Tor: Server Side</subject><body>

(My first Tor proposal; hopefully it's in a sensible form...)

Here's the server side of the proposal I promised in my rump session
talk at PETS.  The server side seems harmless, and getting it deployed
to a bunch of nodes before the client side gets out there seems like a
good idea in any event.

The client side yields both the performance improvements, as well as
potential client fingerprinting issues.  That side will have to be
carefully considered.

Discuss.  ;-)

   - Ian

["xxx-optimistic-data-server.txt" (text/plain)]

Filename: xxx-optimistic-data-server.txt
Title: Optimistic Data for Tor: Server Side
Author: Ian Goldberg
Created: 2-Aug-2010
Status: Open

Overview:

When a SOCKS client opens a TCP connection through Tor (for an HTTP
request, for example), the query latency is about 1.5x higher than it
needs to be.  Simply, the problem is that the sequence of data flows
is this:

1. The SOCKS client opens a TCP connection to the OP
2. The SOCKS client sends a SOCKS CONNECT command
3. The OP sends a BEGIN cell to the Exit
4. The Exit opens a TCP connection to the Server
5. The Exit returns a CONNECTED cell to the OP
6. The OP returns a SOCKS CONNECTED notification to the SOCKS client
7. The SOCKS client sends some data (the GET request, for example)
8. The OP sends a DATA cell to the Exit
9. The Exit sends the GET to the server
10. The Server returns the HTTP result to the Exit
11. The Exit sends the DATA cells to the OP
12. The OP returns the HTTP result to the SOCKS client

Note that the Exit node knows that the connection to the Server was
successful at the end of step 4, but is unable to send the HTTP query to
the server until step 9.

This proposal (as well as its upcoming sibling concerning the client
side) aims to reduce the latency by allowing:
1. SOCKS clients to optimistically send data before they are notified
    that the SOCKS connection has completed successfully
2. OPs to optimistically send DATA cells on streams in the CONNECT_WAIT
    state
3. Exit nodes to accept and queue DATA cells while in the
    EXIT_CONN_STATE_CONNECTING state

This particular proposal deals with #3.

In this way, the flow would be as follows:

1. The SOCKS client opens a TCP connection to the OP
2. The SOCKS client sends a SOCKS CONNECT command, followed immediately
    by data (such as the GET request)
3. The OP sends a BEGIN cell to the Exit, followed immediately by DATA
    cells
4. The Exit opens a TCP connection to the Server
5. The Exit returns a CONNECTED cell to the OP, and sends the queued GET
    request to the Server
6. The OP returns a SOCKS CONNECTED notification to the SOCKS client,
    and the Server returns the HTTP result to the Exit
7. The Exit sends the DATA cells to the OP
8. The OP returns the HTTP result to the SOCKS client

Motivation:

This change will save one OP&lt;-&gt;Exit round trip (down to one from two).
There are still two SOCKS Client&lt;-&gt;OP round trips (negligible time) and
two Exit&lt;-&gt;Server round trips.  Depending on the ratio of the
Exit&lt;-&gt;Server (Internet) RTT to the OP&lt;-&gt;Exit (Tor) RTT, this will
decrease the latency by 25 to 50 percent.  Experiments validate these
predictions. [Goldberg, PETS 2010 rump session; see
https://thunk.cs.uwaterloo.ca/optimistic-data-pets2010-rump.pdf ]

Design:

The current code actually correctly handles queued data at the Exit; if
there is queued data in a EXIT_CONN_STATE_CONNECTING stream, that data
will be immediately sent when the connection succeeds.  If the
connection fails, the data will be correctly ignored and freed.  The
problem with the current server code is that the server currently
drops DATA cells on streams in the EXIT_CONN_STATE_CONNECTING state.
Also, if you try to queue data in the EXIT_CONN_STATE_RESOLVING state,
bad things happen because streams in that state don't yet have
conn-&gt;write_event set, and so some existing sanity checks (any stream
with queued data is at least potentially writable) are no longer sound.

The solution is to simply not drop received DATA cells while in the
EXIT_CONN_STATE_CONNECTING state.  Also do not send SENDME cells in this
state, so that the OP cannot send more than one window's worth of data
to be queued at the Exit.  Finally, patch the sanity checks so that
streams in the EXIT_CONN_STATE_RESOLVING state that have buffered data
can pass.

If no clients ever send such optimistic data, the new code will never be
executed, and the behaviour of Tor will not change.  When clients begin
to send optimistic data, the performance of those clients' streams will
improve.

After discussion with nickm, it seems best to just have the server
version number be the indicator of whether a particular Exit supports
optimistic data.  (If a client sends optimistic data to an Exit which
does not support it, the data will be dropped, and the client's request
will fail to complete.)  What do version numbers for hypothetical future
protocol-compatible implementations look like, though?

Security implications:

Servers (for sure the Exit, and possibly others, by watching the
pattern of packets) will be able to tell that a particular client
is using optimistic data.  This will be discussed more in the sibling
proposal.

On the Exit side, servers will be queueing a little bit extra data, but
no more than one window.  Clients today can cause Exits to queue that
much data anyway, simply by establishing a Tor connection to a slow
machine, and sending one window of data.

Specification:

tor-spec section 6.2 currently says:

    The OP waits for a RELAY_CONNECTED cell before sending any data.
    Once a connection has been established, the OP and exit node
    package stream data in RELAY_DATA cells, and upon receiving such
    cells, echo their contents to the corresponding TCP stream.
    RELAY_DATA cells sent to unrecognized streams are dropped.

It is not clear exactly what an "unrecognized" stream is, but this last
sentence would be changed to say that RELAY_DATA cells received on a
stream that has processed a RELAY_BEGIN cell and has not yet issued a
RELAY_END or a RELAY_CONNECTED cell are queued; that queue is processed
immediately after a RELAY_CONNECTED cell is issued for the stream, or
freed after a RELAY_END cell is issued for the stream.

The earlier part of this section will be addressed in the sibling
proposal.

Compatibility:

There are compatibility issues, as mentioned above.  OPs MUST NOT send
optimistic data to Exit nodes whose version numbers predate (something).
OPs MAY send optimistic data to Exit nodes whose version numbers match
or follow that value.  (But see the question about independent server
reimplementations, above.)

Implementation:

Here is a simple patch.  It seems to work with both regular streams and
hidden services, but there may be other corner cases I'm not aware of.
(Do streams used for directory fetches, hidden services, etc. take a
different code path?)

diff --git a/src/or/connection.c b/src/or/connection.c
index 7b1493b..f80cd6e 100644
--- a/src/or/connection.c
+++ b/src/or/connection.c
@@ -2845,7 +2845,13 @@ _connection_write_to_buf_impl(const char *string, size_t len,
     return;
   }
 
-  connection_start_writing(conn);
+  /* If we receive optimistic data in the EXIT_CONN_STATE_RESOLVING
+   * state, we don't want to try to write it right away, since
+   * conn-&gt;write_event won't be set yet.  Otherwise, write data from
+   * this conn as the socket is available. */
+  if (conn-&gt;state != EXIT_CONN_STATE_RESOLVING) {
+      connection_start_writing(conn);
+  }
   if (zlib) {
     conn-&gt;outbuf_flushlen += buf_datalen(conn-&gt;outbuf) - old_datalen;
   } else {
@@ -3382,7 +3388,11 @@ assert_connection_ok(connection_t *conn, time_t now)
     tor_assert(conn-&gt;s &lt; 0);
 
   if (conn-&gt;outbuf_flushlen &gt; 0) {
-    tor_assert(connection_is_writing(conn) || conn-&gt;write_blocked_on_bw ||
+    /* With optimistic data, we may have queued data in
+     * EXIT_CONN_STATE_RESOLVING while the conn is not yet marked to writing.
+     * */
+    tor_assert(conn-&gt;state == EXIT_CONN_STATE_RESOLVING ||
+	    connection_is_writing(conn) || conn-&gt;write_blocked_on_bw ||
             (CONN_IS_EDGE(conn) &amp;&amp; TO_EDGE_CONN(conn)-&gt;edge_blocked_on_circ));
   }
 
diff --git a/src/or/relay.c b/src/or/relay.c
index fab2d88..e45ff70 100644
--- a/src/or/relay.c
+++ b/src/or/relay.c
@@ -1019,6 +1019,9 @@ connection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,
   relay_header_t rh;
   unsigned domain = layer_hint?LD_APP:LD_EXIT;
   int reason;
+  int optimistic_data = 0;  /* Set to 1 if we receive data on a stream
+			       that's in the EXIT_CONN_STATE_RESOLVING
+			       or EXIT_CONN_STATE_CONNECTING states.*/
 
   tor_assert(cell);
   tor_assert(circ);
@@ -1038,9 +1041,20 @@ connection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,
   /* either conn is NULL, in which case we've got a control cell, or else
    * conn points to the recognized stream. */
 
-  if (conn &amp;&amp; !connection_state_is_open(TO_CONN(conn)))
-    return connection_edge_process_relay_cell_not_open(
-             &amp;rh, cell, circ, conn, layer_hint);
+  if (conn &amp;&amp; !connection_state_is_open(TO_CONN(conn))) {
+    if ((conn-&gt;_base.state == EXIT_CONN_STATE_CONNECTING ||
+	    conn-&gt;_base.state == EXIT_CONN_STATE_RESOLVING) &amp;&amp;
+	rh.command == RELAY_COMMAND_DATA) {
+	/* We're going to allow DATA cells to be delivered to an exit
+	 * node in state EXIT_CONN_STATE_CONNECTING or
+	 * EXIT_CONN_STATE_RESOLVING.  This speeds up HTTP, for example. */
+	log_warn(domain, "Optimistic data received.");
+	optimistic_data = 1;
+    } else {
+	return connection_edge_process_relay_cell_not_open(
+		 &amp;rh, cell, circ, conn, layer_hint);
+    }
+  }
 
   switch (rh.command) {
     case RELAY_COMMAND_DROP:
@@ -1090,7 +1104,9 @@ connection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,
       log_debug(domain,"circ deliver_window now %d.", layer_hint ?
                 layer_hint-&gt;deliver_window : circ-&gt;deliver_window);
 
-      circuit_consider_sending_sendme(circ, layer_hint);
+      if (!optimistic_data) {
+	  circuit_consider_sending_sendme(circ, layer_hint);
+      }
 
       if (!conn) {
         log_info(domain,"data cell dropped, unknown stream (streamid %d).",
@@ -1107,7 +1123,9 @@ connection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,
       stats_n_data_bytes_received += rh.length;
       connection_write_to_buf(cell-&gt;payload + RELAY_HEADER_SIZE,
                               rh.length, TO_CONN(conn));
-      connection_edge_consider_sending_sendme(conn);
+      if (!optimistic_data) {
+	  connection_edge_consider_sending_sendme(conn);
+      }
       return 0;
     case RELAY_COMMAND_END:
       reason = rh.length &gt; 0 ?

Performance and scalability notes:

There may be more RAM used at Exit nodes, as mentioned above, but it is
transient.


</body></email><email><emailId>20100810215328</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-08-10 21:53:28-0400</timestampReceived><subject>Re: [or-cvs] [tor/master 3/3] Move exit-stats code to the end of</subject><body>

On Fri, Aug 06, 2010 at 02:45:57PM +0000, nickm@torproject.org wrote:
&gt; Author: Karsten Loesing &lt;karsten.loesing@gmx.net&gt;
&gt; Date: Wed, 4 Aug 2010 07:32:10 +0200
&gt; Subject: Move exit-stats code to the end of rephist.c.
&gt; Commit: 83626ec91c4d0de610f59bc43a1e5d0dd4103d87
[snip]
&gt; -/** Free all storage held by the OR/link history caches, by the
&gt; - * bandwidth history arrays, or by the port history. */
&gt;  void
&gt; -rep_hist_free_all(void)
[snip]
&gt; +/** Stop collecting exit port stats in a way that we can re-start doing
&gt; + * so in rep_hist_exit_stats_init(). */
&gt; +void
&gt; +rep_hist_exit_stats_term(void)
&gt; +{
&gt; +  start_of_exit_stats_interval = 0;
&gt;    tor_free(exit_bytes_read);
&gt;    tor_free(exit_bytes_written);
&gt;    tor_free(exit_streams);
&gt; -  built_last_stability_doc_at = 0;
&gt; -  predicted_ports_free();
&gt; +}
&gt; +
[snip]
&gt; +/** Free all storage held by the OR/link history caches, by the
&gt; + * bandwidth history arrays, by the port history, or by statistics . */
&gt; +void
&gt; +rep_hist_free_all(void)
&gt; +{
&gt; +  digestmap_free(history_map, free_or_history);
&gt; +  tor_free(read_array);
&gt; +  tor_free(write_array);
&gt; +  tor_free(last_stability_doc);
&gt; +  tor_free(exit_bytes_read);
&gt; +  tor_free(exit_bytes_written);
&gt; +  tor_free(exit_streams);
&gt; +  built_last_stability_doc_at = 0;
&gt; +  predicted_ports_free();
&gt; +}

Hi Karsten,

It would be good in the future to do this sort of change as two commits --
one that moves the huge chunks of code from one file to another, and a
second that actually modifies what the code is. Otherwise when reviewing,
we have to memorize all the removed lines and recognize them when they
reappear, so we can learn what actually changed.

--Roger

</body></email><email><emailId>20100812182837</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-08-12 18:28:37-0400</timestampReceived><subject>Bandwidth Measurement for Tor Server Nodes</subject><body>

Dear Group,

I have noticed that if I set a bandwidth restraint for my server, it 
hibernates when the amount of data 'downloaded' rather than 'sent' 
reaches the specified limit within the accounting period.
Thinking about it... does it make more sense for the limit to be applied 
to the amount of 'sent' data as opposed to 'received' ?
-- 

With kind regards,
Cav Edwards

</body></email><email><emailId>20100712111747</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-07-12 11:17:47-0400</timestampReceived><subject>New passive performance metrics in Tor</subject><body>


Hi everyone,

I'm planning to add new passive performance metrics to Tor so that we
can better understand why it's slow and how we can improve it. Here is a
list of performance metrics we already have and a few ideas for new
metrics. If anyone has an idea what other metrics might be missing or
how we can improve the existing/planned metrics, please let us know!


Performance metrics we already have:

- write-history and read-history: Total written and read bytes

- dirreq-v[23]-{direct,tunneled}-dl: Network status download times

- cell-processed-cells: Number of processed cells per circuit

- cell-queued-cells: Mean number of cells contained in circuit queues

- cell-time-in-queue: Mean time cells spend in circuit queues

- cell-circuits-per-decile: Number of active circuits per day

- exit-kibibytes-{written,read} and exit-streams-opened: Written and
read bytes and opened streams exiting the Tor network

Just in case you just learned that we have these kinds of data and want
to look at them more closely, you'll find the daily updated July 2010
extra-info descriptors containing these metrics here:

  http://metrics.torproject.org/data/extra-infos-2010-07.tar.bz2

If you happen to find out something useful, please let us know, too! :)



New performance metrics:

1. Written and read bytes spent on answering directory requests

Mike wants to know for his bandwidth weights how many bytes we're
writing and reading for directory requests as compared to all bytes. We
could add two new lines in the style of write-history and read-history
that declare how many bytes were spent on directory requests, including
both direct connections to the Dir port and tunneled requests via
BEGIN_DIR cells:

    "dirreq-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
        [At most once]
    "dirreq-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
        [At most once]

        Declare how much bandwidth the OR has spent on answering
        directory requests.  Usage is divided into intervals of NSEC
        seconds.  The YYYY-MM-DD HH:MM:SS field defines the end of the
        most recent interval.  The numbers are the number of bytes used
        in the most recent intervals, ordered from oldest to newest.

Here are some example numbers from my test relay, together with the
write-history and read-history lines for comparison:

write-history 2010-07-10 19:53:30 (900 s) 126585824,118608860,
160984887,215227933,279503671,292334518,247741024,219398726,402868466,
171578104,134845462,103864240,339932861,197773378,313857195,172963329,
155526629,252937014,244187702,197075966,152386190,175927358,163121741,
178683670,257434914,113004935,113712270,105843282,163919436,209717008,
145912027,185671909,214901809,120711828,177862476,215853506,151845080,
246348316,249139845,159824705,189301611,149167678,174661744,148893984,
166705025,96488337,113451396,125986495,83252142,111691155,89342727,
181081343,247091129,222168462,127634564,151465333,284533765,235486901,
288744935,243722540,187109053,140379274,107682143,155506145,215314138,
165721878,172790983,194321640,263295290,196657740,206465896,181921549,
157166653,216171620,273935225,341610717,254576134,287283026,345218991,
218867344,221304725,159918366,219410175,317998413,267456903,370347960,
360990463,227152997,210737304,328228011,284975201,195563699,169440384,
225952664,167331447,206871134
read-history 2010-07-10 19:53:30 (900 s) 111893867,101529861,143895849,
194786027,259952571,273497972,232257574,199549600,385105937,153788132,
117426290,84115625,322626270,179367559,293464555,155173008,140076076,
237776118,225444069,180710872,138166684,160516398,148001360,161921342,
243594475,100661995,102812182,90311549,151614536,197647669,135284514,
170708653,202502593,108863871,165358926,203496697,142017462,230877056,
235022066,146810734,176047157,135151618,161136000,134416764,154471070,
84377707,100789666,112208099,72023045,97726026,75320408,161555620,
229979123,205614801,111857592,133387588,265711511,216666832,270679486,
226124920,171931895,123012431,88188621,135887568,197036553,148318468,
155601095,174911703,241373709,176322860,188172703,161709145,139134142,
196972335,254543821,319215780,235328518,268214943,325796822,197507205,
201169007,143374694,201244669,296243416,246725945,353965769,337025998,
200899391,189473401,309588351,266155617,173460369,152280169,206597244,
147200841,184052057
dirreq-write-history 2010-07-10 19:53:30 (900 s) 646347,560172,696779,
830638,619676,602628,361450,740160,524300,568569,731671,854635,605561,
564858,678157,532414,719312,494666,1301201,944818,527056,202686,1013200,
553622,402782,416251,531494,366742,429971,664552,321484,617111,291196,
397877,657988,323410,261872,698337,656536,958921,315250,222864,296399,
657562,291304,532770,325678,409172,606387,573317,753559,764482,400565,
464494,567049,451342,127342,492985,315013,887299,688030,589603,389064,
223902,329524,807354,1215069,423756,697600,907185,723453,689116,538715,
511851,558052,620773,354970,586254,421827,822856,786349,609691,638619,
651930,653235,393705,627669,635353,554215,234620,725708,575857,538672,
335683,846807,454024
dirreq-read-history 2010-07-10 19:53:30 (900 s) 492788,18459,30148,
37121,533625,23774,163742,33518,553467,165008,31612,40248,530115,158371,
27364,35238,539279,23376,166453,14047,525003,13245,163134,29956,615381,
19639,11663,23016,600257,27761,14674,17969,495159,144806,13802,22840,
490508,149164,19911,31915,597266,12861,20509,17639,493599,139914,14597,
20603,494243,158505,34142,41609,508383,32690,160229,33347,508837,16767,
151166,34133,556447,164360,27186,16380,13605,694385,39106,30262,41665,
675799,32311,14205,28536,670198,37591,32236,23552,644491,29737,39118,
21215,670186,17262,27210,34859,654266,25168,34874,29585,648736,13492,
30356,19431,518298,173052,32005

I'm wondering if we're really spending these few bytes on answering
directory requests. But even if these numbers are wrong, one gets the
idea what this metric is about.



2. Bidirectional use of connections

Björn Scheuermann and Florian Tschorsch of Uni Düsseldorf want to know
what fraction of connections are used bidirectionally. They suggested to
count read and written bytes per connection in 10-second intervals and
classify connections as "below threshold", "mostly reading", "mostly
writing", and "both reading and writing":

    "conn-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
        [At most once]

        YYYY-MM-DD HH:MM:SS defines the end of the included connection
        statistics measurement interval of length NSEC seconds (86400
        seconds by default).

        A "conn-stats-end" line, as well as any other "conn-*" line,
        is first added after the relay has been running for at least 24
        hours.

    "conn-bidirectional" BELOW,READ,WRITE,BOTH NL
        [At most once]

        Number of connections, split into 10-second intervals, that are
        used uni-directionally or bi-directionally.  Every 10 seconds,
        we determine for every connection whether we read and wrote less
        than a threshold of 20 KiB (BELOW), read 10 times more than we
        wrote (READ), wrote 10 times more than we read (WRITE), or read
        and wrote more than the threshold, but not 10 times more in
        either direction (BOTH).  After classifying a connection, read
        and write counters are reset for the next 10-second interval.

I performed an early analysis based on the findings on my test relay.
Attached to this mail you'll find a histogram and a scatterplot that we
used to determine the threshold of 20 KiB (or 2 KiB/s) and the factor 10
as parameters.

Here are the results of my test relay:

conn-stats-end 2010-07-10 19:53:38 (84600 s)
conn-bidirectional 315227,55437,66653,97878

These numbers imply that 97878 of 55437+66653+97878, or 44.5% of all
connections are used bidirectionally.

An open question is whether we should distinguish between connections to
other relays and to clients. I wonder if there's an easy way to tell the
two connection types apart.


Comments? Thoughts?

Thanks,
--Karsten

["scatterplot.png" (image/png)]
["histogram.png" (image/png)]

</body></email><email><emailId>20100826113114</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-26 11:31:14-0400</timestampReceived><subject>Safely collecting data to estimate the number of Tor users</subject><body>

Hi everyone,

in the past year or so, we put some efforts on finding out how many
people use the Tor network every day. We expect that there are 500,000
daily users, but we have no good data to support this expectation. We'd
like to be more certain about the user count in order to understand the
Tor network better and hopefully improve it.

We have started writing down the current state of counting users in a
privacy-preserving way. Note that this is just a draft that is going to
change over time:


https://gitweb.torproject.org/karsten/metrics.git/blob_plain/refs/heads/counting-users:/report/counting-users/countingusers.pdf


One of the more promising approaches to count Tor users is to count
unique client IP addresses on a fast directory mirror (see Section 3.2
"Count unique IP addresses of connecting clients..."). We make use of
the fact that clients send out 20 to 80 directory requests per day and
very likely contact every fast directory mirror at least once. This is
going to change with the directory guard design, though. We'll need to
come up with a way to combine the findings of multiple directory guards.

So, here's my plan for researching this more: I'd like to run an
experiment with multiple fast directory mirrors run by the same operator
on the same host (like Jake's trusted and Pandora*, Olaf's blutmagie*,
Moritz's torserversNet*, etc.). I'm going to write a patch for Tor to
accept some key string in its torrc and extend SafeLogging to accept the
value 'encrypt'. Tor will then pass all client IP addresses through a
keyed hash function using the provided key string and write the result
to its logs. I'm also going to implement #1668 to make log granularity
configurable. The operators configure the same key string for all their
relays and run them with the new SafeLogging option and logging
granularity of 15 minutes for, say, a week. Operators then delete the
key string and only keep the logs. The operators do not give out these
logs to me or anyone else. I'm going to write Python scripts to analyze
the logs and publish them for the operators and others to review. The
operators will run these scripts and publish the results.

I hope to learn more about the overlap of unique IP address sets seen by
fast directory mirrors and also about client uptime sessions. I'd like
to try out different schemes to safely combine unique IP address sets to
come up with a better user count.

Before writing code, what questions or concerns are there about this
experiment? Are there better ways to achieve what I'm trying to achieve?

Thanks,
--Karsten


</body></email><email><emailId>20100826155001</emailId><senderName>"stars () hispeed ! ch"</senderName><senderEmail>stars@hispeed.ch</senderEmail><timestampReceived>2010-08-26 15:50:01-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Le Thu, 26 Aug 2010 13:31:14 +0200,
Karsten Loesing &lt;karsten.loesing@gmx.net&gt; a écrit :

&gt; Hi everyone,
&gt; 
&gt; in the past year or so, we put some efforts on finding out how many
&gt; people use the Tor network every day. We expect that there are 500,000
&gt; daily users, but we have no good data to support this expectation.
&gt; We'd like to be more certain about the user count in order to
&gt; understand the Tor network better and hopefully improve it.
&gt; 
&gt; We have started writing down the current state of counting users in a
&gt; privacy-preserving way. Note that this is just a draft that is going
&gt; to change over time:
&gt; 
&gt; 
&gt; https://gitweb.torproject.org/karsten/metrics.git/blob_plain/refs/heads/counting-users:/report/counting-users/countingusers.pdf
&gt;  
&gt; One of the more promising approaches to count Tor users is to count
&gt; unique client IP addresses on a fast directory mirror (see Section 3.2
&gt; "Count unique IP addresses of connecting clients..."). We make use of
&gt; the fact that clients send out 20 to 80 directory requests per day and
&gt; very likely contact every fast directory mirror at least once. This is
&gt; going to change with the directory guard design, though. We'll need to
&gt; come up with a way to combine the findings of multiple directory
&gt; guards.
&gt; 
&gt; So, here's my plan for researching this more: I'd like to run an
&gt; experiment with multiple fast directory mirrors run by the same
&gt; operator on the same host (like Jake's trusted and Pandora*, Olaf's
&gt; blutmagie*, Moritz's torserversNet*, etc.). I'm going to write a
&gt; patch for Tor to accept some key string in its torrc and extend
&gt; SafeLogging to accept the value 'encrypt'. Tor will then pass all
&gt; client IP addresses through a keyed hash function using the provided
&gt; key string and write the result to its logs. I'm also going to
&gt; implement #1668 to make log granularity configurable. The operators
&gt; configure the same key string for all their relays and run them with
&gt; the new SafeLogging option and logging granularity of 15 minutes for,
&gt; say, a week. Operators then delete the key string and only keep the
&gt; logs. The operators do not give out these logs to me or anyone else.
&gt; I'm going to write Python scripts to analyze the logs and publish
&gt; them for the operators and others to review. The operators will run
&gt; these scripts and publish the results.
&gt; 
&gt; I hope to learn more about the overlap of unique IP address sets seen
&gt; by fast directory mirrors and also about client uptime sessions. I'd
&gt; like to try out different schemes to safely combine unique IP address
&gt; sets to come up with a better user count.
&gt; 
&gt; Before writing code, what questions or concerns are there about this
&gt; experiment? Are there better ways to achieve what I'm trying to
&gt; achieve?
&gt; 
&gt; Thanks,
&gt; --Karsten

Hi Karsten,

It seem a great idea for me and hope that it can be used as Non-Exit
Relay with High bandwitch and all flag assigned ( i mean stable. named,
HS, Guard, fast, Dir)

If yes, i will with pleasure contribute to help like always.

Best Regards

SwissTorExit


</body></email><email><emailId>20100826191757</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-26 19:17:57-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi SwissTorExit!

On 8/26/10 5:50 PM, stars@hispeed.ch wrote:
&gt; It seem a great idea for me and hope that it can be used as Non-Exit
&gt; Relay with High bandwitch and all flag assigned ( i mean stable. named,
&gt; HS, Guard, fast, Dir)
&gt; 
&gt; If yes, i will with pleasure contribute to help like always.

Thanks for the offer. Yes, non-exit relays with high bandwidth are what
we need. But for this experiment I'm looking for a set of really fast
relays that answers a large fraction of, say, 10 % of all directory
requests in the network. I think there are only three relay families
matching that requirement (but I didn't look very closely). Once we have
found a way to safely combine findings from multiple directories, I'll
let you know and ask you to help out.

Thanks!
--Karsten
</body></email><email><emailId>20100827070745</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-27 07:07:45-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi Karsten,

&gt; So, here's my plan for researching this more: I'd like to run an
&gt; experiment with multiple fast directory mirrors run by the same operator
&gt; on the same host (like Jake's trusted and Pandora*, Olaf's blutmagie*,
&gt; Moritz's torserversNet*, etc.). I'm going to write a patch for Tor to
&gt; accept some key string in its torrc and extend SafeLogging to accept the
&gt; value 'encrypt'. Tor will then pass all client IP addresses through a
&gt; keyed hash function using the provided key string and write the result
&gt; to its logs. I'm also going to implement #1668 to make log granularity
&gt; configurable. The operators configure the same key string for all their
&gt; relays and run them with the new SafeLogging option and logging
&gt; granularity of 15 minutes for, say, a week. Operators then delete the
&gt; key string and only keep the logs. The operators do not give out these
&gt; logs to me or anyone else. I'm going to write Python scripts to analyze
&gt; the logs and publish them for the operators and others to review. The
&gt; operators will run these scripts and publish the results.
&gt; 
&gt; I hope to learn more about the overlap of unique IP address sets seen by
&gt; fast directory mirrors and also about client uptime sessions. I'd like
&gt; to try out different schemes to safely combine unique IP address sets to
&gt; come up with a better user count.
&gt; 
&gt; Before writing code, what questions or concerns are there about this
&gt; experiment? Are there better ways to achieve what I'm trying to achieve?

I think an interesting alternative option could be to use a so-called FM
sketch for counting distinct IP addresses at the relays. FM sketches are
bitfield-based data structures that can be used to estimate the number
of distinct elements in a multiset, based on a specific kind of hash
function. Originally, they have been proposed by Flajolet and Martin (F
and M...) in the 1980s (Flajolet, Martin: Probabilistic Counting
Algorithms for Data Base Applications, Journal of Computer and System
Sciences, vol 31(2),
http://algo.inria.fr/flajolet/Publications/FlMa85.pdf ).

Basically, FM sketches work as follows: you start with an empty (i.e.,
all-zero) bit field. For each element (i.e., IP address) that you see,
you calculate a hash function which maps the element to one position in
that bit field. The hash function is a specifically "crafted" one which
is not uniformly distributed, that is, not every bit is "hit" with the
same probability. Whenever some bit in the bit field is hit by hashing
an IP address, you set the respective bit to one, regardless of whether
it was zero or whether it was one already. The bit fields that are used
are actually quite small (at most a few thousand bits), and the hash
value distribution is highly non-uniform, so that typically many IP
addresses map to the same bit. You can then extract an estimate for the
number of *distinct* IP addresses that you have "seen" and hashed into
the bit field by analyzing the pattern of bits that emerged in the bit
field in a specific way. I am happy to provide more detailed
explanations and more references if you want.

FM sketches have (at least) three very intriguing properties for the
application that you outline:

1) Since many IP addresses map to the same bit, you cannot reverse the
operation, i.e., at least to me it seems that it would be no problem at
all to exchange the generated bit fields between operators (or between
operators and you), even if the used hash function, keys, etc. are
known.

2) You can easily combine FM sketches from multiple sources if they use
the same hash function. To this end, you simply calculate the bit-wise
OR or the respective bit fields. What you will get is the very same bit
field that would have emerged if all IP addresses from all relays were
hashed to the same bit field. If the same IP address occurred at
different relays, the respective bit will be set in both bit fields, so
that the address will be counted only once (FM sketches are "duplicate
insensitive"), i.e., you can really obtain the overall number of
distinct IP addresses without exchanging and merging any lists, just
based on the bit fields. (I personally think this is *really*
cool. :-) )

3) You can trade off bit field size versus accuracy: larger bit fields
give more accurate estimates. In your context this means that you can
basically trade off anonymization of IP addresses (smaller bit fields =&gt;
more IP addresses are mapped to the same bit) versus accuracy. The
tradeoff is very favorable, though: a few hundred to a few thousand bits
can already give you an accuracy to within a few percent estimation
error.

I have already used FM sketches and variants thereof in several
different projects and contexts, and my feeling is that they are a
perfect match for your problem. I'm happy to help if needed.


Cheers

BjÃ¶rn



-- 
Jun.-Prof. Dr. BjÃ¶rn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
UniversitÃ¤tsstr. 1, D-40225 DÃ¼sseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20100827082409</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-27 08:24:09-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>


On Fri, 27 Aug 2010 09:07:45 +0200
Björn Scheuermann &lt;scheuermann@cs.uni-duesseldorf.de&gt; wrote:

&gt; FM sketches have (at least) three very intriguing properties for the
&gt; application that you outline:
&gt; 
&gt; 1) Since many IP addresses map to the same bit, you cannot reverse the
&gt; operation, i.e., at least to me it seems that it would be no problem at
&gt; all to exchange the generated bit fields between operators (or between
&gt; operators and you), even if the used hash function, keys, etc. are
&gt; known.

FM sketches were not designed to destroy information about which
elements were hashed into it, and they cannot be relied on to destroy
sensitive information in this application.

If an adversary knows that only one IP address with a certain hash
value could possibly be using Tor, the adversary can use an operator's
FM sketch to determine whether or not that IP address accessed the
operator's directory mirror in the FM sketch's time period.  The
tin-foil-hat crowd and their parodists will also point out that the
adversary may design the hash function to single out certain users.
(Are you enjoying that CIA time-share, Dr. Loesing?)


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100827111208</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-27 11:12:08-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi,

&gt; If an adversary knows that only one IP address with a certain hash
&gt; value could possibly be using Tor, the adversary can use an operator's
&gt; FM sketch to determine whether or not that IP address accessed the
&gt; operator's directory mirror in the FM sketch's time period. The
&gt; tin-foil-hat crowd and their parodists will also point out that the
&gt; adversary may design the hash function to single out certain users.
&gt; (Are you enjoying that CIA time-share, Dr. Loesing?)

you certainly have a point there. Philosophizing about whether this is
practically doable and relevant (esp. if you use a cryptographic hash as
a basis) is probably futile.

Yet, I almost expected that you guys would come up with this argument,
so I have a fallback at hand. ;-) It appears to me that the problem can
be overcome relatively easily if you do the following: instead of
initializing the FM sketch to all-zero, you set each individual bit to
one with a certain, fixed probability. For instance, you could
initialize the bit field such that each bit is zero with 95%
probability, and one with 5% probability. You do that independently and
randomly at each relay, and never communicate the generated initial bit
pattern to anyone.

The additional one bits avoid the problem that you can know for sure
from a 1-bit in the sketch that there was "at least one" IP address
which has been mapped to that particular bit. In fact, for those bits
that are hit by only very few IP addresses, if the respective bit is 1
in the sketch, then the probability that it has been set to one by the
above stated random initialization is much higher than the probability
that the respective IP address really contacted the relay.

When an estimate for the total number is extracted from such a sketch,
the additional 1-bits add a certain distortion to the estimated value.
However, the resulting bias is relatively easy to eliminate if the
probability with which bits have been initialized to one is known (also
for combined bit fields from multiple relays, as long as neither the
number of relays nor the fraction of "artificial" 1-bits becomes too
large).

Better?


Cheers

BjÃ¶rn


-- 
Jun.-Prof. Dr. BjÃ¶rn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
UniversitÃ¤tsstr. 1, D-40225 DÃ¼sseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20100828092100</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2010-08-28 09:21:00-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi Karsten,

[Following up from our IRC conversation]

On Thu, Aug 26, 2010 at 01:31:14PM +0200, Karsten Loesing wrote:
&gt; So, here's my plan for researching this more: I'd like to run an
&gt; experiment with multiple fast directory mirrors run by the same operator
&gt; on the same host (like Jake's trusted and Pandora*, Olaf's blutmagie*,
&gt; Moritz's torserversNet*, etc.). I'm going to write a patch for Tor to
&gt; accept some key string in its torrc and extend SafeLogging to accept the
&gt; value 'encrypt'. Tor will then pass all client IP addresses through a
&gt; keyed hash function using the provided key string and write the result
&gt; to its logs. I'm also going to implement #1668 to make log granularity
&gt; configurable. The operators configure the same key string for all their
&gt; relays and run them with the new SafeLogging option and logging
&gt; granularity of 15 minutes for, say, a week. Operators then delete the
&gt; key string and only keep the logs. The operators do not give out these
&gt; logs to me or anyone else. I'm going to write Python scripts to analyze
&gt; the logs and publish them for the operators and others to review. The
&gt; operators will run these scripts and publish the results.

That sounds fine, but as I am sure you are aware, since there are only
2^32 IP addresses, given the key string, it will be possible to
reverse the keyed hash. This key string will be on hard disks, so I'd
therefore suggest adding an additional level of security.

On an offline analysis machine you could generate a public keypair.
Give the public half to the server operators.

On the directory mirrors, Tor then generates a symmetric key which
it keeps in RAM. Tor logs the symmetric key encrypted under the public
key. Then the hash would be encrypted under this symmetric key. Each
time Tor restarts it generates a new key.

On the offline analysis machine, decrypt the records from all the
directory mirrors, and encrypt them under a single new key. Discard
all the keys and only export the encrypted logs.

Another thing to do is to shrink the hash size. If we assume that
there are going to be, say, no more than 1 million distinct IP
addresses, we could use a 40 bit hash with only a small number of
collisions (due to the Birthday Paradox). However, someone who tries
to reverse the full 32 bit IPv4 space will get many collisions.

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/
</body></email><email><emailId>20100829111735</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-29 11:17:35-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi,

Steven J. Murdoch wrote:
&gt; Another thing to do is to shrink the hash size. If we assume that
&gt; there are going to be, say, no more than 1 million distinct IP
&gt; addresses, we could use a 40 bit hash with only a small number of
&gt; collisions (due to the Birthday Paradox). However, someone who tries
&gt; to reverse the full 32 bit IPv4 space will get many collisions.

with a 40 bit hash, the vast majority of 2^32 IP addresses will not
collide with any other IP address, despite the birthday paradox. So this
would not really be a significant additional level of protection. It
would make a difference only for the small fraction of the IP addresses
that actually do collide.

However, you don't need that many bits anyway, as collisions are not a
big issue when your goal is to only count how many different addresses
you have seen. If you proceed as you suggested, you can, as detailed
below, do well with a 21-bit hash. With additional tweaks, you can
further reduce that to 12-bit hash values.

If n distinct IP addresses have occurred and you use m-bit hash values,
any given one of the 2^m possible hash values will have been recorded at
least once with probability

  1 - (1 - 1/(2^m))^n

You would thus expect that

  2^m * ( 1 - (1 - 1/(2^m))^n )

different hash values have been recorded. This can be approximated (by
a Poisson approximation) by

  2^m * ( 1 - e^(-n/(2^m)) )

If, after a measurement period, you have seen Z different hash values in
your logs, you can invert that formula:

      Z = 2^m * ( 1 - e^(-n/(2^m)) )
 &lt;=&gt;  e^(-n/(2^m)) = 1 - Z / (2^m)
 &lt;=&gt;  -n/(2^m) = ln(1 - Z / (2^m))
 &lt;=&gt;  n = - 2^m * ln(1 - Z / (2^m))

By using the above formula (known as "hit counting"), you can obtain a
very good estimate for the number n of different IP addresses with much
smaller hashes than 40 bits.

In general, this approach works well as long as less than half of the
possible hash values have occurred. To be on the safe side, I'd reduce
that further to, say, one third. If you assume that there are no more
than one million distinct IP addresses, a 21-bit hash should be
perfectly fine to get a very good idea of the number of Tor users. Use
22 or 23 bits to reduce the estimation error further if you want.

That, though, is still suboptimal. If you use a non-uniform hash, you
can do even better. If you replace the uniform hash function by a
specific non-uniform one (yes, along the lines of FM sketches again),
you could get estimates for the number of distinct IP addresses with a
standard error of 0.05 by using only 4096 different hash values for the
IP addresses, i.e., with a non-uniform 12-bit hash function. Such a hash
function is very easy to construct starting from any arbitrary uniform
"standard" hash. I'm happy to provide more details (and code) if you
want.


Best regards

BjÃ¶rn



</body></email><email><emailId>20100829153707</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-29 15:37:07-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>


On Sun, 29 Aug 2010 13:17:35 +0200
Björn Scheuermann &lt;scheuermann@cs.uni-duesseldorf.de&gt; wrote:

&gt; Steven J. Murdoch wrote:
&gt; &gt; Another thing to do is to shrink the hash size. If we assume that
&gt; &gt; there are going to be, say, no more than 1 million distinct IP
&gt; &gt; addresses, we could use a 40 bit hash with only a small number of
&gt; &gt; collisions (due to the Birthday Paradox). However, someone who tries
&gt; &gt; to reverse the full 32 bit IPv4 space will get many collisions.
&gt; 
&gt; with a 40 bit hash, the vast majority of 2^32 IP addresses will not
&gt; collide with any other IP address, despite the birthday paradox. So this
&gt; would not really be a significant additional level of protection. It
&gt; would make a difference only for the small fraction of the IP addresses
&gt; that actually do collide.
&gt; 
&gt; However, you don't need that many bits anyway, as collisions are not a
&gt; big issue when your goal is to only count how many different addresses
&gt; you have seen. If you proceed as you suggested, you can, as detailed
&gt; below, do well with a 21-bit hash. With additional tweaks, you can
&gt; further reduce that to 12-bit hash values.

And then it's more efficient to use FM sketches rather than a list of
hash values.  The *only* problem I had with your first message in this
thread was your suggestion that the FM sketches could be exchanged
between the operators; the FM sketches may still be quite sensitive
(only $AGENCY knows exactly how sensitive they are; we really can't
tell).

Other than the fact that the FM sketches must remain secret, your
approach is also safer than Dr. Murdoch's idea.


There is a slight improvement, though:

* Each instrumented Tor instance should generate an FM sketch in memory
  as it is contacted by directory clients.  This loses most of the
  sensitive information instantly.

* Every N minutes, the Tor instance should encrypt its current FM
  sketch with Dr. Loesing's public key for this purpose, base64-encode
  it, and write it to the log on a single line.  As long as the
  encryption algorithm is randomized, this packages up the rest of the
  sensitive information so only one trusted person can recover it.  The
  Tor instance then erases its FM sketch and starts accumulating a new
  one.

* The Tor operators use one or more invocations of grep to extract
  *only* the encrypted FM sketches from the log.  Sort the resulting
  list, and delete the original log files.  This loses any potentially
  sensitive timing information, so that Dr. Loesing can't recover it.
  Each operator should then merge the encrypted-sketch lists produced
  by all of his/her/its Tor relays into one sorted list before sending
  it in for analysis.

* Dr. Loesing decrypts all of the FM sketches, ORs them together, and
  publishes only the resulting count.  Then he erases the decrypted FM
  sketches and sets his private key on fire.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100829170613</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-29 17:06:13-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi,

On So, 2010-08-29 at 08:37 -0700, Robert Ransom wrote:
&gt; And then it's more efficient to use FM sketches rather than a list of
&gt; hash values.  The *only* problem I had with your first message in this
&gt; thread was your suggestion that the FM sketches could be exchanged
&gt; between the operators; the FM sketches may still be quite sensitive
&gt; (only $AGENCY knows exactly how sensitive they are; we really can't
&gt; tell).

granted.

&gt; Other than the fact that the FM sketches must remain secret, your
&gt; approach is also safer than Dr. Murdoch's idea.
&gt; 
&gt; There is a slight improvement, though:
&gt; 
&gt; * Each instrumented Tor instance should generate an FM sketch in memory
&gt;   as it is contacted by directory clients.  This loses most of the
&gt;   sensitive information instantly.
&gt; 
&gt; * Every N minutes, the Tor instance should encrypt its current FM
&gt;   sketch with Dr. Loesing's public key for this purpose, base64-encode
&gt;   it, and write it to the log on a single line.  As long as the
&gt;   encryption algorithm is randomized, this packages up the rest of the
&gt;   sensitive information so only one trusted person can recover it.  The
&gt;   Tor instance then erases its FM sketch and starts accumulating a new
&gt;   one.
&gt; 
&gt; * The Tor operators use one or more invocations of grep to extract
&gt;   *only* the encrypted FM sketches from the log.  Sort the resulting
&gt;   list, and delete the original log files.  This loses any potentially
&gt;   sensitive timing information, so that Dr. Loesing can't recover it.
&gt;   Each operator should then merge the encrypted-sketch lists produced
&gt;   by all of his/her/its Tor relays into one sorted list before sending
&gt;   it in for analysis.
&gt; 
&gt; * Dr. Loesing decrypts all of the FM sketches, ORs them together, and
&gt;   publishes only the resulting count.  Then he erases the decrypted FM
&gt;   sketches and sets his private key on fire.

Wait a minute, I'm losing track. If I got Karsten's and Stephen's
discussion right, they did not intend to exchange anything between
operators. Karsten wrote that "the operators do not give out these
logs to me or anyone else. I'm going to write Python scripts to analyze
the logs and publish them for the operators and others to review. The
operators will run these scripts and publish the results."

There are two options, which we should clearly keep apart. Option #1 is
to provide a tool chain to the directory mirror operators to collect and
evaluate how many distinct IP addresses contacted their mirrors, and
only their mirrors (i.e., a group of mirrors that is under the same
administrative control). An operator would then only publish the final
result, i.e., the number of distinct IP addresses for his group of
mirrors during some time period. The tool chain should of course still
keep as little sensitive information as possible. It could be
implemented in several different ways, including what Stephen suggested
and including a solution based on FM sketches.

The drawback of option #1 is that it can only provide information on the
number of users of each individual operator, not a total estimate for
the whole Tor network. The benefit is that - whatever the tool chain
looks like in detail - no potentially sensitive data needs to be
exchanged between different operators or between operators and Karsten
Loesing. As far as I got it, this option that Karsten and Stephen are
referring to.

Option #2 is to find some kind of mechanism that allows to merge
information from multiple operators, ideally without revealing sensitive
information to anyone. This would provide "better" information, as it
gives an estimate for the number of distinct users of the Tor network in
total. In his first mail, Karsten was asking for ideas how this could
possibly be achieved. This is what *I* was referring to in my first two
mails, and apparently this is also what you have in mind.

Variant #2a would be to craft a data structure in such a way that we can
be absolutely sure that it is no longer sensitive. In that case, the
operators could publish the data structure. I admit that this is most
likely impossible (even though I believe that sketches with additional
"noise" bits, as suggested in my second mail, come at least pretty
close).

Variant #2b is to craft the data structure in such a way that we are
*reasonably* sure that the data are no longer sensitive. In that case,
the data structures should be encrypted by the operators so that only
Karsten Loesing can decrypt them, and all traces of them should be
eliminated once Karsten has finished the merging and evaluation process,
just as you suggest.

Out of the variants discussed so far, sketches reveal the least
information; it seems that we agree on that. Adding random noise would
be a measure to provide additional protection in all scenarios, unless
the number of sketches to be ORed becomes too large.

There is one potential issue/limitation, though, in what you suggest. If
sketches are collected over N-minute intervals, and are conveyed to
Karsten without any indication of timing and order, then all Karsten can
do is to calculate the total number of distinct user IPs over the whole
period during which all these sketches have been generated. If this is
what is desired, it will be important a) that all operators collect
information during the same time interval, and only during that time
interval, and b) that this time interval is not too long, otherwise we
will end up with the number of distinct IP addresses during a whole week
or so, which might not be very helpful (due to dynamic IPs etc.).
Furthermore, if all sketches from this time period are combined by
Karsten anyway, then we might consider to let each operator OR all his
sketches locally and to send only the result to Karsten, so as to reveal
even less information to him.


Best regards

BjÃ¶rn



</body></email><email><emailId>20100829170821</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-29 17:08:21-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi,

&gt; Wait a minute, I'm losing track. If I got Karsten's and Stephen's
&gt; discussion right, they did not intend to exchange anything between
&gt; operators.

sorry, small correction to avoid further confusion. What I meant was
"...between operators *and*Karsten*".


Cheers

BjÃ¶rn



</body></email><email><emailId>20100829173018</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-29 17:30:18-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>


On Sun, 29 Aug 2010 19:06:13 +0200
Björn Scheuermann &lt;scheuermann@cs.uni-duesseldorf.de&gt; wrote:

&gt; Variant #2a would be to craft a data structure in such a way that we can
&gt; be absolutely sure that it is no longer sensitive. In that case, the
&gt; operators could publish the data structure. I admit that this is most
&gt; likely impossible (even though I believe that sketches with additional
&gt; "noise" bits, as suggested in my second mail, come at least pretty
&gt; close).
&gt; 
&gt; Variant #2b is to craft the data structure in such a way that we are
&gt; *reasonably* sure that the data are no longer sensitive. In that case,
&gt; the data structures should be encrypted by the operators so that only
&gt; Karsten Loesing can decrypt them, and all traces of them should be
&gt; eliminated once Karsten has finished the merging and evaluation process,
&gt; just as you suggest.

I'm writing up a cryptosystem that will help with this right now; it
allows untrusted parties to merge encrypted Bloom-filter-like objects,
but one trusted party will be required to decrypt the merged encrypted
blob and compute the estimated number of distinct IP addresses.  The
kind of homomorphic encryption we need is feasible, with about 160
ciphertext bits per plaintext-Bloom-filter bit.


&gt; There is one potential issue/limitation, though, in what you suggest. If
&gt; sketches are collected over N-minute intervals, and are conveyed to
&gt; Karsten without any indication of timing and order, then all Karsten can
&gt; do is to calculate the total number of distinct user IPs over the whole
&gt; period during which all these sketches have been generated. If this is
&gt; what is desired, it will be important a) that all operators collect
&gt; information during the same time interval, and only during that time
&gt; interval, and b) that this time interval is not too long, otherwise we
&gt; will end up with the number of distinct IP addresses during a whole week
&gt; or so, which might not be very helpful (due to dynamic IPs etc.).
&gt; Furthermore, if all sketches from this time period are combined by
&gt; Karsten anyway, then we might consider to let each operator OR all his
&gt; sketches locally and to send only the result to Karsten, so as to reveal
&gt; even less information to him.

You're right about the limitation; with my approach in the message
you're replying to, it would be best to include a sanitized time in the
encrypted blob.  With what I'm working on, we're stuck with (a) in your
paragraph here (but *everyone* can participate in collecting data).


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100829175118</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-29 17:51:18-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi,

On So, 2010-08-29 at 10:30 -0700, Robert Ransom wrote:
&gt; I'm writing up a cryptosystem that will help with this right now; it
&gt; allows untrusted parties to merge encrypted Bloom-filter-like objects,
&gt; but one trusted party will be required to decrypt the merged encrypted
&gt; blob and compute the estimated number of distinct IP addresses.  The
&gt; kind of homomorphic encryption we need is feasible, with about 160
&gt; ciphertext bits per plaintext-Bloom-filter bit.

that sounds cool, I'd love to read more about that (I see potential
applications for something like that in other projects I'm working on,
too). You don't happen to have a paper on that?

&gt; &gt; There is one potential issue/limitation, though, in what you suggest. If
&gt; &gt; sketches are collected over N-minute intervals, and are conveyed to
&gt; &gt; Karsten without any indication of timing and order, then all Karsten can
&gt; &gt; do is to calculate the total number of distinct user IPs over the whole
&gt; &gt; period during which all these sketches have been generated. If this is
&gt; &gt; what is desired, it will be important a) that all operators collect
&gt; &gt; information during the same time interval, and only during that time
&gt; &gt; interval, and b) that this time interval is not too long, otherwise we
&gt; &gt; will end up with the number of distinct IP addresses during a whole week
&gt; &gt; or so, which might not be very helpful (due to dynamic IPs etc.).
&gt; &gt; Furthermore, if all sketches from this time period are combined by
&gt; &gt; Karsten anyway, then we might consider to let each operator OR all his
&gt; &gt; sketches locally and to send only the result to Karsten, so as to reveal
&gt; &gt; even less information to him.
&gt; 
&gt; You're right about the limitation; with my approach in the message
&gt; you're replying to, it would be best to include a sanitized time in the
&gt; encrypted blob.  With what I'm working on, we're stuck with (a) in your
&gt; paragraph here (but *everyone* can participate in collecting data).

If properly co-ordinated, this seems feasible. It's just something
Karsten should probably keep an eye on, if this is the direction he
chooses.


Best regards

BjÃ¶rn


-- 
Jun.-Prof. Dr. BjÃ¶rn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
UniversitÃ¤tsstr. 1, D-40225 DÃ¼sseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20100830090907</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-30 09:09:07-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>

Hi Björn, Robert, Steven,

woah, quite some discussion on the topic. That's great! Sorry for the
delay, but, as you all know, weekends are CIA time... ;)

So, I think my original posting lead to some confusion about what I'm
trying to achieve. Björn did a great job summarizing this in his 29 Aug
2010 19:06:13 +0200 email. Let me make another attempt to describe my
intentions and sort in your thoughts:

There are three things that I'm interested in:

1) I want to analyze 'anonymized' directory requests on a couple of
directory mirrors run by the same operator (who doesn't share any data
but the results with me or anyone else) for a limited time to

2) learn more about merging unique IP address sets from many directory
mirrors run by different operators on a regular basis and

3) learn more about client uptime to better translate network status
requests to an overall client number, also on a regular basis.

In my initial posting I was mostly referring to 1) and only briefly
mentioned 2) and 3). Most of your discussion so far was about 2). In
particular, the following ideas were discussed (greatly simplified):

a) Björn introduced the idea of using FM sketches, possibly initialized
with some false 1 bits, to solve problem 2) above. AFAIU, the FM sketch
idea is comparable to my Bloom filter idea (4.2 in countingusers.pdf as
linked from my initial posting), despite using a 'specifically crafted
hash function'. I discussed my Bloom filter idea with Steven in July in
Berlin and he was also concerned that publishing Bloom filters could
leak sensitive information. I'd very much like to work on this idea more
to evaluate the risks when choosing a rather small filter size. The goal
should be to find out if we can make all directory mirrors publish their
filters to the directory authorities where everyone can download them or
not.

b) Robert is working on merging encrypted Bloom-filter-like objects. I'm
interested in this idea, too, even though it implies we fail in a), that
is, we're unable to make the Bloom filters safe enough to publish
without encryption. I'm mostly concerned about having a single trusted
party and would rather distribute trust among, say, the majority of the
currently eight directory authority operators. Still, having a solution
that doesn't require additional encryption would be best.

c) Steven proposes to i) encrypt logs to a public key (or rather to a
symmetric session key which is encrypted to a public key) and ii) to
reduce IP address hashes in those logs to 40 bits. That means he's
referring to problem 1) above. I think that i) is a good approach to
move sensitive logs from an Internet host to a more secure place to run
the evaluation on. I could imagine implementing this to be a general Tor
feature, so that people who need verbose logs for debugging can encrypt
them on their server and evaluate them on a safe machine. I'm slightly
concerned that this could encourage people to log more than they need. I
also like idea ii), because we really don't need 160 bit hashes in the
logs, but should be fine with 40 bits.

So, here's what I'd like to do next:

I) Research the FM-or-Bloom-filter idea analytically, gladly accepting
Björn's offer to help,

II) implement log sanitizing and encryption to keep as little sensitive
information in logs as possible,

III) design and have someone run an experiment to evaluate how well the
filter idea works in practice, and

IV) design and run an experiment to learn about client sessions.

Thanks for your input so far! More comments/corrections are highly
appreciated!

--Karsten
</body></email><email><emailId>20100816004143</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-16 00:41:43-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

On Mon, Jul 12, 2010 at 7:17 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
 [...]
&gt; 2. Bidirectional use of connections
&gt;
&gt; Björn Scheuermann and Florian Tschorsch of Uni Düsseldorf want to know
&gt; what fraction of connections are used bidirectionally. They suggested to
&gt; count read and written bytes per connection in 10-second intervals and
&gt; classify connections as "below threshold", "mostly reading", "mostly
&gt; writing", and "both reading and writing":

Replying here rather than on
https://trac.torproject.org/projects/tor/ticket/1819 , since this is
where the discussion of the "bidirectional connection counting"
feature started.  I'm hoping that Björn and Florien (or somebody who
knows their work) will point me at some kind of writeup to explain the
motivation here.  Why is the fraction of "bidirectional" connections
important?  What does knowing it get us?

many thanks,
-- 
Nick

</body></email><email><emailId>20100816180913</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-08-16 18:09:13-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

On Monday 12 July 2010 12:17:47 Karsten Loesing wrote:
&gt; Hi everyone,
&gt; 
&gt; I'm planning to add new passive performance metrics to Tor so that we
&gt; can better understand why it's slow and how we can improve it. Here is a
&gt; list of performance metrics we already have and a few ideas for new
&gt; metrics. If anyone has an idea what other metrics might be missing or
&gt; how we can improve the existing/planned metrics, please let us know!
&gt; 
Hi Karsten,

Hope I'm not too late.  This is connected to:

https://trac.torproject.org/projects/tor/ticket/1826

It would be useful to know how many cells relays are sending to streams 
after they have received a RELAY_END on the stream from the client.

On a poor-performing circuit terminating at a fast exit, a RELAY_END on a 
stream can result in up to 1000 queued cells getting flushed to a client 
that doesn't want them anymore. This wastage of bandwidth can't be remedied 
without just tearing down the circuit or resetting it in some way.

This metric would tell us how much of this wasted bandwidth there is on the 
network and whether it merits action.

I can implement for your review if you are amenable to the idea.

Thanks,
Robert
</body></email><email><emailId>20100817115235</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-17 11:52:35-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Hi Robert,

On 8/16/10 8:09 PM, Robert Hogan wrote:
&gt; On Monday 12 July 2010 12:17:47 Karsten Loesing wrote:
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; I'm planning to add new passive performance metrics to Tor so that we
&gt;&gt; can better understand why it's slow and how we can improve it. Here is a
&gt;&gt; list of performance metrics we already have and a few ideas for new
&gt;&gt; metrics. If anyone has an idea what other metrics might be missing or
&gt;&gt; how we can improve the existing/planned metrics, please let us know!
&gt;&gt;
&gt; Hi Karsten,
&gt; 
&gt; Hope I'm not too late.

Never too late. :)

&gt; This is connected to:
&gt; 
&gt; https://trac.torproject.org/projects/tor/ticket/1826
&gt; 
&gt; It would be useful to know how many cells relays are sending to streams 
&gt; after they have received a RELAY_END on the stream from the client.
&gt; 
&gt; On a poor-performing circuit terminating at a fast exit, a RELAY_END on a 
&gt; stream can result in up to 1000 queued cells getting flushed to a client 
&gt; that doesn't want them anymore. This wastage of bandwidth can't be remedied 
&gt; without just tearing down the circuit or resetting it in some way.
&gt; 
&gt; This metric would tell us how much of this wasted bandwidth there is on the 
&gt; network and whether it merits action.
&gt; 
&gt; I can implement for your review if you are amenable to the idea.

Where would this code be running? Only on the exit node?

What would we count? All cells sent to clients vs. cells sent or flushed
after seeing a RELAY_END for the contained stream ID?

Have you identified the places in the code where we learn about given
cells? I can write the code that keeps cell counters, manages
measurement periods, and formats results to be written to the logs or to
extra-info descriptors.

As for getting this stats code merged: We could write the code and ask
some friendly exit node operators to run our modified Tor version. If
the results turn out to be useful and we decide we want these stats from
most or all exit nodes, we can merge the code into master. I think Nick
wouldn't want to merge this into 0.2.2.x anymore, so that would be on a
0.2.3.x timeframe. But maybe we're already happy with the results from a
few exit nodes that we decide that merging isn't necessary.

I like the idea. Unless someone jumps up and says it's a really bad
idea, let's do it.

Best,
--Karsten
</body></email><email><emailId>20100817184349</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-08-17 18:43:49-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

On Tuesday 17 August 2010 12:52:35 Karsten Loesing wrote:
&gt; Hi Robert,
&gt; 
&gt; On 8/16/10 8:09 PM, Robert Hogan wrote:
&gt; &gt; On Monday 12 July 2010 12:17:47 Karsten Loesing wrote:
&gt; &gt;&gt; Hi everyone,
&gt; &gt;&gt; 
&gt; &gt;&gt; I'm planning to add new passive performance metrics to Tor so that we
&gt; &gt;&gt; can better understand why it's slow and how we can improve it. Here
&gt; &gt;&gt; is a list of performance metrics we already have and a few ideas for
&gt; &gt;&gt; new metrics. If anyone has an idea what other metrics might be
&gt; &gt;&gt; missing or how we can improve the existing/planned metrics, please
&gt; &gt;&gt; let us know!
&gt; &gt; 
&gt; &gt; Hi Karsten,
&gt; &gt; 
&gt; &gt; Hope I'm not too late.
&gt; 
&gt; Never too late. :)
&gt; 
&gt; &gt; This is connected to:
&gt; &gt; 
&gt; &gt; https://trac.torproject.org/projects/tor/ticket/1826
&gt; &gt; 
&gt; &gt; It would be useful to know how many cells relays are sending to
&gt; &gt; streams after they have received a RELAY_END on the stream from the
&gt; &gt; client.
&gt; &gt; 
&gt; &gt; On a poor-performing circuit terminating at a fast exit, a RELAY_END
&gt; &gt; on a stream can result in up to 1000 queued cells getting flushed to
&gt; &gt; a client that doesn't want them anymore. This wastage of bandwidth
&gt; &gt; can't be remedied without just tearing down the circuit or resetting
&gt; &gt; it in some way.
&gt; &gt; 
&gt; &gt; This metric would tell us how much of this wasted bandwidth there is
&gt; &gt; on the network and whether it merits action.
&gt; &gt; 
&gt; &gt; I can implement for your review if you are amenable to the idea.
&gt; 
&gt; Where would this code be running? Only on the exit node?
&gt; 
Yes - only on the exit node.

&gt; What would we count? All cells sent to clients vs. cells sent or flushed
&gt; after seeing a RELAY_END for the contained stream ID?

Just the latter I think - the absolute number is just as meaningful as 
comparing it to the total number of cells sent.
&gt; 
&gt; Have you identified the places in the code where we learn about given
&gt; cells? 

I *think* it just requires taking the value in the package_window for the 
stream when the RELAY_END is received and adding that to the counter.

&gt; I can write the code that keeps cell counters, manages
&gt; measurement periods, and formats results to be written to the logs or to
&gt; extra-info descriptors.
&gt; 
&gt; As for getting this stats code merged: We could write the code and ask
&gt; some friendly exit node operators to run our modified Tor version. If
&gt; the results turn out to be useful and we decide we want these stats from
&gt; most or all exit nodes, we can merge the code into master. I think Nick
&gt; wouldn't want to merge this into 0.2.2.x anymore, so that would be on a
&gt; 0.2.3.x timeframe. But maybe we're already happy with the results from a
&gt; few exit nodes that we decide that merging isn't necessary.
&gt; 
&gt; I like the idea. Unless someone jumps up and says it's a really bad
&gt; idea, let's do it.
&gt; 
&gt; Best,
&gt; --Karsten
</body></email><email><emailId>20100819080856</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-19 08:08:56-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

On 8/17/10 8:43 PM, Robert Hogan wrote:
&gt; On Tuesday 17 August 2010 12:52:35 Karsten Loesing wrote:
&gt;&gt; Hi Robert,
&gt;&gt;
&gt;&gt; On 8/16/10 8:09 PM, Robert Hogan wrote:
&gt;&gt;&gt; On Monday 12 July 2010 12:17:47 Karsten Loesing wrote:
&gt;&gt;&gt;&gt; Hi everyone,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I'm planning to add new passive performance metrics to Tor so that we
&gt;&gt;&gt;&gt; can better understand why it's slow and how we can improve it. Here
&gt;&gt;&gt;&gt; is a list of performance metrics we already have and a few ideas for
&gt;&gt;&gt;&gt; new metrics. If anyone has an idea what other metrics might be
&gt;&gt;&gt;&gt; missing or how we can improve the existing/planned metrics, please
&gt;&gt;&gt;&gt; let us know!
&gt;&gt;&gt;
&gt;&gt;&gt; Hi Karsten,
&gt;&gt;&gt;
&gt;&gt;&gt; Hope I'm not too late.
&gt;&gt;
&gt;&gt; Never too late. :)
&gt;&gt;
&gt;&gt;&gt; This is connected to:
&gt;&gt;&gt;
&gt;&gt;&gt; https://trac.torproject.org/projects/tor/ticket/1826
&gt;&gt;&gt;
&gt;&gt;&gt; It would be useful to know how many cells relays are sending to
&gt;&gt;&gt; streams after they have received a RELAY_END on the stream from the
&gt;&gt;&gt; client.
&gt;&gt;&gt;
&gt;&gt;&gt; On a poor-performing circuit terminating at a fast exit, a RELAY_END
&gt;&gt;&gt; on a stream can result in up to 1000 queued cells getting flushed to
&gt;&gt;&gt; a client that doesn't want them anymore. This wastage of bandwidth
&gt;&gt;&gt; can't be remedied without just tearing down the circuit or resetting
&gt;&gt;&gt; it in some way.
&gt;&gt;&gt;
&gt;&gt;&gt; This metric would tell us how much of this wasted bandwidth there is
&gt;&gt;&gt; on the network and whether it merits action.
&gt;&gt;&gt;
&gt;&gt;&gt; I can implement for your review if you are amenable to the idea.
&gt;&gt;
&gt;&gt; Where would this code be running? Only on the exit node?
&gt;&gt;
&gt; Yes - only on the exit node.

Okay.

&gt;&gt; What would we count? All cells sent to clients vs. cells sent or flushed
&gt;&gt; after seeing a RELAY_END for the contained stream ID?
&gt; 
&gt; Just the latter I think - the absolute number is just as meaningful as 
&gt; comparing it to the total number of cells sent.

Okay.

&gt;&gt; Have you identified the places in the code where we learn about given
&gt;&gt; cells? 
&gt; 
&gt; I *think* it just requires taking the value in the package_window for the 
&gt; stream when the RELAY_END is received and adding that to the counter.

Do you have a patch that prints out a log message whenever we would add
cells or bytes to a counter?

And do you have an exit node to test the new stats code?

--Karsten

&gt;&gt; I can write the code that keeps cell counters, manages
&gt;&gt; measurement periods, and formats results to be written to the logs or to
&gt;&gt; extra-info descriptors.
&gt;&gt;
&gt;&gt; As for getting this stats code merged: We could write the code and ask
&gt;&gt; some friendly exit node operators to run our modified Tor version. If
&gt;&gt; the results turn out to be useful and we decide we want these stats from
&gt;&gt; most or all exit nodes, we can merge the code into master. I think Nick
&gt;&gt; wouldn't want to merge this into 0.2.2.x anymore, so that would be on a
&gt;&gt; 0.2.3.x timeframe. But maybe we're already happy with the results from a
&gt;&gt; few exit nodes that we decide that merging isn't necessary.
&gt;&gt;
&gt;&gt; I like the idea. Unless someone jumps up and says it's a really bad
&gt;&gt; idea, let's do it.
&gt;&gt;
&gt;&gt; Best,
&gt;&gt; --Karsten
</body></email><email><emailId>20100819093132</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-19 09:31:32-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Dear Nick,

Nick Mathewson wrote:
&gt; Replying here rather than on
&gt; https://trac.torproject.org/projects/tor/ticket/1819 , since this is
&gt; where the discussion of the "bidirectional connection counting"
&gt; feature started.  I'm hoping that BjÃ¶rn and Florien (or somebody who
&gt; knows their work) will point me at some kind of writeup to explain the
&gt; motivation here.  Why is the fraction of "bidirectional" connections
&gt; important?  What does knowing it get us?

sorry for the long delay - I have been out of office for the last few
days.

The background behind this metric is the following: Tor (just like many
other overlay networks) uses many TCP connections over the same physical
link - all incoming/outgoing TCP connections of an OR will typically
share the same physical Internet connection. We found that in such cases
the individual TCP interactions can interact, with potentially severe
performance impact. The short version of the story is as follows:

The outgoing queue of the network interface is shared between all TCP
connections that traverse the respective link. This queue contains both
data segments for outgoing traffic and ACKs for incoming TCP segments.
If there is significant outgoing data traffic, the outgoing ACKs can be
delayed significantly, which impacts TCP's self-clocking and can
severely deteriorate the performance for incoming traffic (simply
because it takes a long time until the ACKs finally make it to the front
of the queue and are transmitted). This causes unnecessary TCP timeouts
and slow starts.

These effects can be avoided with simple traffic shaping mechanisms that
prioritize TCP ACKs in the outgoing interface queue. However, this works
only if the TCP connection transfers data in one direction (i.e., only
incoming traffic or only outgoing traffic, but not both at the same
time). If TCP connections are used bidirectionally, ACKs for incoming
traffic are piggybacked on outgoing data segments and therefore cannot
be prioritized that easily. A possible remedy is to "split up"
bidirectionally used TCP connections into one connection per direction
of communication, so as to avoid ACK piggybacking.

We believe that the described effects could be a significant source of
performance problems in Tor. This is the reason why we are interested in
the "bidirectional traffic on TCP connections" metric, in order to get a
feeling how common bidirectional use of TCP connections in Tor "in the
wild" is.

A more in-depth discussion, including experimental results etc., has
recently been accepted as a paper to this year's IEEE LCN conference
(Marks, Tschorsch, Scheuermann: "Unleashing Tor, BitTorrent &amp; Co.: How
to Relieve TCP Deficiencies in Overlays"). An extended version of this
paper (even more results...) is available as a technical report here: 

http://www.cn.uni-duesseldorf.de/publications/library/Marks2010b.pdf


If you have further questions, please do not hesitate to ask. 


Cheers

BjÃ¶rn (+ Florian)


-- 
Jun.-Prof. Dr. BjÃ¶rn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
UniversitÃ¤tsstr. 1, D-40225 DÃ¼sseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20100819135852</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-19 13:58:52-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

2010/8/19 Björn Scheuermann &lt;scheuermann@cs.uni-duesseldorf.de&gt;:
 [...]
&gt; A more in-depth discussion, including experimental results etc., has
&gt; recently been accepted as a paper to this year's IEEE LCN conference
&gt; (Marks, Tschorsch, Scheuermann: "Unleashing Tor, BitTorrent &amp; Co.: How
&gt; to Relieve TCP Deficiencies in Overlays"). An extended version of this
&gt; paper (even more results...) is available as a technical report here:
&gt;
&gt; http://www.cn.uni-duesseldorf.de/publications/library/Marks2010b.pdf
&gt;
&gt;
&gt; If you have further questions, please do not hesitate to ask.

Thanks, Björn!  That was quite interesting.

It's not urgent, but when you can, could you please have a look at the
measurements implemented in
https://trac.torproject.org/projects/tor/ticket/1819 and confirm
(there or here is fine) whether the way Karsten's code is measuring
"bidirectionality"  is indeed the way that would be helpful in your
work?

yrs,
-- 
Nick

</body></email><email><emailId>20100819140544</emailId><senderName>Björn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-08-19 14:05:44-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Dear Nick,

&gt; Thanks, BjÃ¶rn!  That was quite interesting.
&gt; 
&gt; It's not urgent, but when you can, could you please have a look at the
&gt; measurements implemented in
&gt; https://trac.torproject.org/projects/tor/ticket/1819 and confirm
&gt; (there or here is fine) whether the way Karsten's code is measuring
&gt; "bidirectionality"  is indeed the way that would be helpful in your
&gt; work?

in fact, Florian and me discussed that with Karsten before (not on this
list, though) - the implemented metric resulted from this discussion. I
am therefore quite confident that this is actually what we need.

Nevertheless we will take a look ASAP.


Cheers

BjÃ¶rn


-- 
Jun.-Prof. Dr. BjÃ¶rn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
UniversitÃ¤tsstr. 1, D-40225 DÃ¼sseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20100822193432</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-08-22 19:34:32-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

On Thursday 19 August 2010 09:08:56 Karsten Loesing wrote:
&gt; 
&gt; Do you have a patch that prints out a log message whenever we would add
&gt; cells or bytes to a counter?
&gt; 

Yes - see:

https://trac.torproject.org/projects/tor/ticket/1826

and

https://gitweb.torproject.org/hoganrobert/tor.git/shortlog/refs/heads/bug1826-
metrics

I'm hoping you can fill in the &lt;insert metric here&gt; bit!

&gt; And do you have an exit node to test the new stats code?
&gt; 

I can run a restrictive exit to test that the code works properly. I don't 
have an exit node that can return useful data.
</body></email><email><emailId>20101118190759</emailId><senderName>Florian Tschorsch</senderName><senderEmail>tschorsch@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2010-11-18 19:07:59-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Hi Everyone, 

it is been a while since we discussed this topic here: 
As Björn already pointed out in an earlier message, we are interested in the fraction \
of bidirectional traffic in tor.  \
(http://archives.seul.org/or/dev/Aug-2010/msg00038.html)

Therefore we developed a metric with Karsten that tries to capture the necessary \
information.  He implemented this metric into Tor (thanks for that): \
https://gitweb.torproject.org/karsten/tor.git/shortlog/refs/heads/bidistats2

After checking the code, we can confirm that it looks very good and matches exactly \
our intentions.   

In order to get wide range results, we would prefer to merge the code into the main \
Tor distribution.  However should this constitute any trouble, we would be satisfied \
with an implementation on only a few selected running relays too. 


If you have further questions, please do not hesitate to ask. 

Cheers, 

Florian and Björn. 



&gt; &gt; Thanks, Björn!  That was quite interesting.
&gt; &gt; 
&gt; &gt; It's not urgent, but when you can, could you please have a look at the
&gt; &gt; measurements implemented in
&gt; &gt; https://trac.torproject.org/projects/tor/ticket/1819 and confirm
&gt; &gt; (there or here is fine) whether the way Karsten's code is measuring
&gt; &gt; "bidirectionality"  is indeed the way that would be helpful in your
&gt; &gt; work?
&gt; 
&gt; in fact, Florian and me discussed that with Karsten before (not on this
&gt; list, though) - the implemented metric resulted from this discussion. I
&gt; am therefore quite confident that this is actually what we need.
&gt; 
&gt; Nevertheless we will take a look ASAP.



-- 
Florian Tschorsch
Mobile and Decentralized Networks
Heinrich-Heine-University
Universitätsstr. 1, D-40225 Düsseldorf

Building 25.12, Room 02.43
Phone +49 211 81 11635
Fax +49 211 81 11638

tschorsch@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


[Attachment #3 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
-webkit-line-break: after-white-space; "&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;Hi \
Everyone, &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;it is been a while since we discussed this \
topic here: &lt;/div&gt;&lt;div&gt;As Björn already pointed out in an earlier message, we \
are interested in the fraction of bidirectional traffic in tor. &lt;/div&gt;&lt;div&gt;(&lt;a \
href="http://archives.seul.org/or/dev/Aug-2010/msg00038.html"&gt;http://archives.seul.org/or/dev/Aug-2010/msg00038.html&lt;/a&gt;)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Therefore \
we developed a metric with Karsten that tries to capture the necessary \
information. &lt;/div&gt;&lt;/div&gt;&lt;div&gt;He implemented this metric into Tor (thanks for \
that): &lt;a href="https://gitweb.torproject.org/karsten/tor.git/shortlog/refs/heads \
/bidistats2"&gt;https://gitweb.torproject.org/karsten/tor.git/shortlog/refs/heads/bidistats2&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;After \
checking the code, we can confirm that it looks very good and matches exactly \
our intentions.   &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In order to get wide range \
results, we would prefer to merge the code into the main Tor \
distribution. &lt;/div&gt;&lt;div&gt;However should this constitute any trouble, we would be \
satisfied with an implementation on only a few selected running relays \
too. &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If you have further questions, \
please do not hesitate to \
ask. &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cheers, &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Florian \
and Björn. &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;blockquote \
type="cite"&gt;&lt;div&gt;&lt;blockquote type="cite"&gt;Thanks, Björn!  That was quite \
interesting.&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote \
type="cite"&gt;It's not urgent, but when you can, could you please have a look at \
the&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;measurements implemented \
in&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/1819"&gt;https://trac.torproject.org/projects/tor/ticket/1819&lt;/a&gt; \
and confirm&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;(there or here is fine) whether \
the way Karsten's code is measuring&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote \
type="cite"&gt;"bidirectionality"  is indeed the way that would be helpful in \
your&lt;br&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;work?&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;in fact, \
Florian and me discussed that with Karsten before (not on this&lt;br&gt;list, though) - the \
implemented metric resulted from this discussion. I&lt;br&gt;am therefore quite confident \
that this is actually what we need.&lt;br&gt;&lt;br&gt;Nevertheless we will take a look \
ASAP.&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div&gt; &lt;div style="word-wrap: \
break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; "&gt;&lt;span \
class="Apple-style-span" style="border-collapse: separate; color: rgb(0, 0, 0); \
font-family: Helvetica; font-style: normal; font-variant: normal; font-weight: \
normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; \
text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; \
-webkit-border-horizontal-spacing: 0px; -webkit-border-vertical-spacing: 0px; \
-webkit-text-decorations-in-effect: none; -webkit-text-size-adjust: auto; \
-webkit-text-stroke-width: 0px; font-size: medium; "&gt;&lt;div style="word-wrap: \
break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; \
"&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;-- &lt;/div&gt;&lt;div&gt;Florian \
Tschorsch&lt;/div&gt;&lt;div&gt;Mobile and Decentralized \
Networks&lt;/div&gt;&lt;div&gt;Heinrich-Heine-University&lt;/div&gt;&lt;div&gt;Universitätsstr. 1, D-40225 \
Düsseldorf&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Building 25.12, Room 02.43&lt;/div&gt;&lt;div&gt;Phone +49 \
211 81 11635&lt;/div&gt;&lt;div&gt;Fax +49 211 81 11638&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="mailto:tschorsch@cs.uni-duesseldorf.de"&gt;tschorsch@cs.uni-duesseldorf.de&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="http://www.cn.uni-duesseldorf.de"&gt;http://www.cn.uni-duesseldorf.de&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;&lt;br \
class="Apple-interchange-newline"&gt;&lt;/div&gt;&lt;br class="Apple-interchange-newline"&gt; \
&lt;/div&gt;&lt;br&gt;&lt;/body&gt;&lt;/html&gt;



</body></email><email><emailId>20100812190428</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2010-08-12 19:04:28-0400</timestampReceived><subject>Re: Bandwidth Measurement for Tor Server Nodes</subject><body>

It hibernates when *either* the read or write total reaches your limit for
the accounting period. This is documented in the man page under
AccountingMax:
http://www.torproject.org/tor-manual.html.en

Usually these values are decently symmetric. Cheers! -Damian

On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;cav@gotadsl.co.uk&gt; wrote:

&gt; Dear Group,
&gt;
&gt; I have noticed that if I set a bandwidth restraint for my server, it
&gt; hibernates when the amount of data 'downloaded' rather than 'sent' reaches
&gt; the specified limit within the accounting period.
&gt; Thinking about it... does it make more sense for the limit to be applied to
&gt; the amount of 'sent' data as opposed to 'received' ?
&gt; --
&gt;
&gt; With kind regards,
&gt; Cav Edwards
&gt;
&gt;

[Attachment #3 (text/html)]

It hibernates when &lt;b&gt;either&lt;/b&gt; the read or write total reaches your limit for the \
accounting period. This is documented in the man page under AccountingMax:&lt;br&gt;&lt;a \
href="http://www.torproject.org/tor-manual.html.en"&gt;http://www.torproject.org/tor-manual.html.en&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;Usually these values are decently symmetric. Cheers! -Damian&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt; \
&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: 1px \
solid rgb(204, 204, 204); padding-left: 1ex;"&gt;Dear Group,&lt;br&gt; &lt;br&gt;
I have noticed that if I set a bandwidth restraint for my server, it hibernates when \
the amount of data 'downloaded' rather than 'sent' reaches the \
specified limit within the accounting period.&lt;br&gt; Thinking about it... does it make \
more sense for the limit to be applied to the amount of 'sent' data as \
                opposed to 'received' ?&lt;br&gt;&lt;font color="#888888"&gt;
-- &lt;br&gt;
&lt;br&gt;
With kind regards,&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20100812191514</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-08-12 19:15:14-0400</timestampReceived><subject>Re: Bandwidth Measurement for Tor Server Nodes</subject><body>

Thanks for the heads up.

With kind regards,
Cav Edwards



Damian Johnson wrote:
&gt; It hibernates when *either* the read or write total reaches your limit 
&gt; for the accounting period. This is documented in the man page under 
&gt; AccountingMax:
&gt; http://www.torproject.org/tor-manual.html.en
&gt;
&gt; Usually these values are decently symmetric. Cheers! -Damian
&gt;
&gt; On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;cav@gotadsl.co.uk 
&gt; &lt;mailto:cav@gotadsl.co.uk&gt;&gt; wrote:
&gt;
&gt;     Dear Group,
&gt;
&gt;     I have noticed that if I set a bandwidth restraint for my server,
&gt;     it hibernates when the amount of data 'downloaded' rather than
&gt;     'sent' reaches the specified limit within the accounting period.
&gt;     Thinking about it... does it make more sense for the limit to be
&gt;     applied to the amount of 'sent' data as opposed to 'received' ?
&gt;     -- 
&gt;
&gt;     With kind regards,
&gt;     Cav Edwards
&gt;
&gt;

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Thanks for the heads up.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Damian Johnson wrote:
&lt;blockquote
 cite="mid:AANLkTi=-_AutETg2gBSF4a8BAJ=spewaPPnk2-iC1_jw@mail.gmail.com"
 type="cite"&gt;It hibernates when &lt;b&gt;either&lt;/b&gt; the read or write total
reaches your limit for the accounting period. This is documented in the
man page under AccountingMax:&lt;br&gt;
  &lt;a moz-do-not-send="true"
 href="http://www.torproject.org/tor-manual.html.en"&gt;http://www.torproject.org/tor-manual.html.en&lt;/a&gt;&lt;br&gt;
  &lt;br&gt;
Usually these values are decently symmetric. Cheers! -Damian&lt;br&gt;
  &lt;br&gt;
  &lt;div class="gmail_quote"&gt;On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;span
 dir="ltr"&gt;&lt;&lt;a moz-do-not-send="true" href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt;&gt;&lt;/span&gt;
wrote:&lt;br&gt;
  &lt;blockquote class="gmail_quote"
 style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;Dear
Group,&lt;br&gt;
    &lt;br&gt;
I have noticed that if I set a bandwidth restraint for my server, it
hibernates when the amount of data 'downloaded' rather than 'sent'
reaches the specified limit within the accounting period.&lt;br&gt;
Thinking about it... does it make more sense for the limit to be
applied to the amount of 'sent' data as opposed to 'received' ?&lt;br&gt;
    &lt;font color="#888888"&gt;-- &lt;br&gt;
    &lt;br&gt;
With kind regards,&lt;br&gt;
Cav Edwards&lt;br&gt;
    &lt;br&gt;
    &lt;/font&gt;&lt;/blockquote&gt;
  &lt;/div&gt;
  &lt;br&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20100803182735</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-03 18:27:35-0400</timestampReceived><subject>Re: Proposal: Optimistic Data for Tor: Server Side</subject><body>

On Mon, Aug 2, 2010 at 10:31 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; (My first Tor proposal; hopefully it's in a sensible form...)
&gt;
&gt; Here's the server side of the proposal I promised in my rump session
&gt; talk at PETS.  The server side seems harmless, and getting it deployed
&gt; to a bunch of nodes before the client side gets out there seems like a
&gt; good idea in any event.
&gt;
&gt; The client side yields both the performance improvements, as well as
&gt; potential client fingerprinting issues.  That side will have to be
&gt; carefully considered.
&gt;
&gt; Discuss.  ;-)

Thanks, Ian!  I've added it as proposal 174.

The proposal looks good to me.  I'll try to answer some of the points
that it was confused on:

&gt; What do version numbers for hypothetical future protocol-compatible implementations look like, though?

They look like Tor version numbers, for whatever Tor version merges
the patch that implements this, and later.

&gt; It is not clear exactly what an "unrecognized" stream is

An "unrecognized" stream is one for which we haven't yet received a
BEGIN cell.  We'll also need to modify the spec to say that older
versions of Tor didn't handle RELAY_DATA cells the same way that newer
ones did.

We should consider the patch independently from the proposal.  The
proposal itself looks fine.  Generally, we try discussing patches on
the tracker at trac.torproject.org.  We're in a loose feature-freeze
right now in a hurried attempt to release an 0.2.2.x rc, but a later
version of the patch in this proposal has a good shot IMO for 0.2.3.x.
 Do you want to make the tracker entry for the patch, or should I? :)

yrs,
-- 
Nick Mathewson

</body></email><email><emailId>20100803195245</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2010-08-03 19:52:45-0400</timestampReceived><subject>Re: Proposal: Optimistic Data for Tor: Server Side</subject><body>

On Tue, Aug 03, 2010 at 02:27:35PM -0400, Nick Mathewson wrote:
&gt; On Mon, Aug 2, 2010 at 10:31 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt; (My first Tor proposal; hopefully it's in a sensible form...)
&gt; &gt; 
&gt; &gt; Here's the server side of the proposal I promised in my rump session
&gt; &gt; talk at PETS.  The server side seems harmless, and getting it deployed
&gt; &gt; to a bunch of nodes before the client side gets out there seems like a
&gt; &gt; good idea in any event.
&gt; &gt; 
&gt; &gt; The client side yields both the performance improvements, as well as
&gt; &gt; potential client fingerprinting issues.  That side will have to be
&gt; &gt; carefully considered.
&gt; &gt; 
&gt; &gt; Discuss.  ;-)
&gt; 
&gt; Thanks, Ian!  I've added it as proposal 174.
&gt; 
&gt; The proposal looks good to me.  I'll try to answer some of the points
&gt; that it was confused on:
&gt; 
&gt; &gt; What do version numbers for hypothetical future protocol-compatible \
&gt; &gt; implementations look like, though?
&gt; 
&gt; They look like Tor version numbers, for whatever Tor version merges
&gt; the patch that implements this, and later.

No, I mean that if someone writes a totally different implementation of
the Tor server (say in some other language like Java or Haskell), how
will the client be able to tell whether that implementation supports
this feature?

&gt; &gt; It is not clear exactly what an "unrecognized" stream is
&gt; 
&gt; An "unrecognized" stream is one for which we haven't yet received a
&gt; BEGIN cell.  We'll also need to modify the spec to say that older
&gt; versions of Tor didn't handle RELAY_DATA cells the same way that newer
&gt; ones did.
&gt; 
&gt; We should consider the patch independently from the proposal.  The
&gt; proposal itself looks fine.  Generally, we try discussing patches on
&gt; the tracker at trac.torproject.org.  We're in a loose feature-freeze
&gt; right now in a hurried attempt to release an 0.2.2.x rc, but a later
&gt; version of the patch in this proposal has a good shot IMO for 0.2.3.x.
&gt; Do you want to make the tracker entry for the patch, or should I? :)

Please go ahead.

Thanks,

   - Ian


</body></email><email><emailId>20100806195608</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-06 19:56:08-0400</timestampReceived><subject>Re: Proposal: Optimistic Data for Tor: Server Side</subject><body>

On Tue, Aug 3, 2010 at 3:52 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
 [...]
&gt;&gt; They look like Tor version numbers, for whatever Tor version merges
&gt;&gt; the patch that implements this, and later.
&gt;
&gt; No, I mean that if someone writes a totally different implementation of
&gt; the Tor server (say in some other language like Java or Haskell), how
&gt; will the client be able to tell whether that implementation supports
&gt; this feature?

We have no really good solution for this in general. It would be neat
to work one out, but that's probably a separate proposal. :)

&gt;&gt;  Do you want to make the tracker entry for the patch, or should I? :)
&gt;
&gt; Please go ahead.

Okay; it's live at
https://trac.torproject.org/projects/tor/ticket/1795 .  You should
probably subscribe to that tracker entry to see any updates or
discussions about the patch.

-- 
Nick

</body></email><email><emailId>20100807001345</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-07 00:13:45-0400</timestampReceived><subject>Re: Proposal: Optimistic Data for Tor: Server Side</subject><body>


On Fri, 6 Aug 2010 15:56:08 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Tue, Aug 3, 2010 at 3:52 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;  [...]
&gt; &gt;&gt; They look like Tor version numbers, for whatever Tor version merges
&gt; &gt;&gt; the patch that implements this, and later.
&gt; &gt;
&gt; &gt; No, I mean that if someone writes a totally different implementation of
&gt; &gt; the Tor server (say in some other language like Java or Haskell), how
&gt; &gt; will the client be able to tell whether that implementation supports
&gt; &gt; this feature?
&gt;=20
&gt; We have no really good solution for this in general. It would be neat
&gt; to work one out, but that's probably a separate proposal. :)

Add a relay descriptor line:

bugfixes trac1795,fs12345,bz9876


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100806100712</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-08-06 10:07:12-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>


Thus spake Nathan Freitas (nathan@freitas.net):

&gt; Is transport or message layer encryption redundant between a tor client
&gt; and a hidden service?

The short answer is yes, we believe it is redundant and unnecessary.

The long answer is "My god man, hidden services? Nobody touches that
code. Who knows what lurks in the deep..."

In particular, the Tor Hidden Service protocol for some reason
discounts the threat of hash collisions, opting for 80bit hashes for
"usability" reasons in onion urls. These urls are the only real means
a user has of authenticating their destination.

In an ideal world, users are perfectly capable of memorizing every
character of the 80bit base64 key hash in the .onion url.

In the real world, it is disturbingly practical to compute .onion urls
that have a significantly large number of characters in common with an
arbitrary target url, in arbitrary positions of the url.

There was a program called 'shallot' which optimized hidden service
key generation to accomplish exactly this using THC's Fuzzy
Fingerprint technique. It seems to exist only in rumor and legend
these days, but if you would like an arbitrary snapshot of the code
that calls itself 0.0.1, I can post it somewhere.

It was originally created for the sake of creating vanity .onion urls.
However, the author optimized it far enough so that the hash could
have something like 8 characters in common with a target .onion url,
in either the prefix, or the suffix, or both, with just a few
machine-days of computation. Their implementation also only created
"strong" RSA keys for the resulting .onion urls. If they allowed weak
key generation for their targets, much more optimization was possible
(and if your goal is to deceive a user into visiting or chatting with
your spoofed hidden service, why not use weak keys?).

So, while in theory, hidden services are probably just barely beyond
the horizon of the cryptographically insecure, in practice they are a
usability nightmare to use for things like chat, where humans need to
establish visual continuity for the endpoint they are communicating
with.

Sadly, this issue may just be the tip of the iceberg in the hidden
service design, and there may be other edge cases that could be a huge
problem for uses like chat. Denial of service conditions are
particularly susceptible to gaming for chat, and the hidden service
code may have quite a few of those. "Oh, I'm sorry, my .onion is down
because of reason X. It will never come back. This my new .onion. I
made them as similar looking as possible for security reasons. Trust
me."

In an ideal world, we'd have a distributed dictionary that safely maps
full-strength hidden service key hashes to unique, human readable
names, a-la .i2p eepsites to avoid lookalikes and gaming.

In the real world, secure distributed dictionaries for this may not
exist, and/or may have subtle vulnerabilities of their own. They probably
do exist for our centralized directory model, but we haven't really
devoted enough thought into the hidden service design to really bother
with them. Perhaps you could build one as part of your chat protocol.


All that said, hidden services do have one signifcant advantage over
regular Tor usage that is probably worth mentioning: Hidden services
overall are generally more secure than using Tor to contact an
arbitrary Internet endpoint using an arbitrary application.

This is due to the likelyhood of user error in the form of using
insecure, non-torrified applications. Given the choice between an
insecure app that has every feature that they want, and an secure app
that is missing a feature or two, the average user will choose the
insecure app *every* time, and recommend it eagerly to their friends.
Hidden services at least have the advantage that they tend to be
harder to connect to in a fashion that is insecure. Either they work,
or they don't. Especially if you trust the hidden service you are
attempting to connect to.

&gt; We are working on a simple "p2p" messaging service between Android
&gt; devices running Tor, with each running a hidden service to accept
&gt; messages. I am trying to figure out if we need to OTR or SSL on top of
&gt; this for any reason.

Have you seen torchat? https://code.google.com/p/torchat/

I've not used it, but perhaps it could be worth looking at, at least.

&gt; I am just trying to understand how far we should rely on encryption with
&gt; the Tor stack for this type of thing, vs. adding in our own bits (err,
&gt; bytes).

Probably your primary threat at this point is user error, more so than
interception or the direct subversion of the hidden service protocol,
which most likely is end-to-end secure...

If your secondary crypto system could somehow improve upon the utterly
broken usability model of hidden services, then it would be a good
idea to add it. Most likely though, a secondary system would just add
confusion, and therefore insecurity. Ultimately it depends on the
userbase and the UI design.

--=20
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100806130012</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-06 13:00:12-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>


On Fri, 6 Aug 2010 03:07:12 -0700
Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt; In the real world, it is disturbingly practical to compute .onion urls
&gt; that have a significantly large number of characters in common with an
&gt; arbitrary target url, in arbitrary positions of the url.
&gt; 
&gt; There was a program called 'shallot' which optimized hidden service
&gt; key generation to accomplish exactly this using THC's Fuzzy
&gt; Fingerprint technique. It seems to exist only in rumor and legend
&gt; these days, but if you would like an arbitrary snapshot of the code
&gt; that calls itself 0.0.1, I can post it somewhere.

http://taswebqlseworuhc.onion/

&gt; It was originally created for the sake of creating vanity .onion urls.
&gt; However, the author optimized it far enough so that the hash could
&gt; have something like 8 characters in common with a target .onion url,
&gt; in either the prefix, or the suffix, or both, with just a few
&gt; machine-days of computation. Their implementation also only created
&gt; "strong" RSA keys for the resulting .onion urls. If they allowed weak
&gt; key generation for their targets, much more optimization was possible
&gt; (and if your goal is to deceive a user into visiting or chatting with
&gt; your spoofed hidden service, why not use weak keys?).

From the README file for version 0.0.3:

| On my 1.5GHz x86-machine, I get about 500k hashes/sec.
| +---------------------------------------------+
| | chars | ~number of tries | ~time @ 500 KH/s |
  [snip]
| |     6 |      32^6  =  1g |           30 min |
| |     7 |      32^7  = 32g |            1 day |
| |     8 |      32^8  =  1t |          25 days |
| |     9 |      32^9  = 32t |        2.5 years |

Also, it can search for keys whose hashes match an arbitrary regular
expression, not just keys whose hashes have specified characters at the
beginning and end.

Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100806134408</emailId><senderName>Marcus Griep</senderName><senderEmail>tormaster@xpdm.us</senderEmail><timestampReceived>2010-08-06 13:44:08-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On Fri, Aug 6, 2010 at 09:00, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt;
&gt; On Fri, 6 Aug 2010 03:07:12 -0700
&gt; Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt;
&gt; &gt; In the real world, it is disturbingly practical to compute .onion urls
&gt; &gt; that have a significantly large number of characters in common with an
&gt; &gt; arbitrary target url, in arbitrary positions of the url.
&gt; &gt;
&gt; &gt; There was a program called 'shallot' which optimized hidden service
&gt; &gt; key generation to accomplish exactly this using THC's Fuzzy
&gt; &gt; Fingerprint technique. It seems to exist only in rumor and legend
&gt; &gt; these days, but if you would like an arbitrary snapshot of the code
&gt; &gt; that calls itself 0.0.1, I can post it somewhere.
&gt;
&gt; http://taswebqlseworuhc.onion/

I haven't worked on it in a while, but I wrote a Mono implementation
of a vanity onion generator as well You can find it here:
http://github.com/neoeinstein/purpleonion

The main relevant portion is under src/Por.OnionGenerator.

&gt;
&gt; &gt; It was originally created for the sake of creating vanity .onion urls.
&gt; &gt; ...
&gt; &gt; (and if your goal is to deceive a user into visiting or chatting with
&gt; &gt; your spoofed hidden service, why not use weak keys?).
&gt;
&gt; Also, it can search for keys whose hashes match an arbitrary regular
&gt; expression, not just keys whose hashes have specified characters at the
&gt; beginning and end.
&gt;

PurpleOnion (Por) was intended to be a full Mono implementation of
Tor, but I didn't get that far. The PurpleOnion vanity generator also
uses an arbitrary regular expression for doing its matching and uses
multi-threading. It currently just uses the Mono framework's
implementation to generate the key pairs, but could probably be
optimized by writing it's own generating functions, including using
Mono.SIMD or CUDA in some form.

I may have to pull this back out of the mothballs to continue
hammering at it and run some more tests.
- --
Marcus Griep
������
������������ ����.���� �, 3 �
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.14 (MingW32)

iQIcBAEBAgAGBQJMXA//AAoJEBLJ7QUyTAFmV1IP/2MC2q65VezVnebL7Jw1PeTY
S96K2rbi/NmjQrxIf6daLiAyoLQBYVb6PoLGTi85At90oKsCRuczx7SX3ulJa6Rp
TvJdDhn8HeQGNGd4QA61zJPshBbw9+aZ89qdEbqYkbxwtSBZb2Q6IXNQcTxV0OeI
LhR4fOWJxaMC8XAUqPaVWLSQM2TIlW1NrHTt/G5dZ2A0OuPu0m+NsbVHvUjmRi3l
v7LhyK7Yz57wdCmgUeSK0KK1vwQ9CdfAVrXo43I+84QX2xWGDgq2zBl2vn/6q7NI
53kyd4kZiXa8X1Tfp1oNdvKBnO3GEkmP0sUPUAuztcIlCr1Up55y8Q16sPejdo2V
3nkhX7JcYXx2Z6QqZEUhP45wWOsYxPB5CFb1fzg8OQD8KMaAKEUqkOtQIWubaHyN
vDvqu/BcJz1znidpVHYQTyWDGdfOE6+h5PBiBIt5rIji+6CjDECvv2JJlmnlbVay
neHCI0OJvyrIMEzXP6uUWQWEGYrSIbJQsdsT2nHh2ZYYWKG6gbZb/GaaMCcuwpnH
2OBB6EBF1KWMMa2I8+kfL+rINphwDYOFuwzvlJoV8BY+wvDuo2Es8v2L/yPNeF2M
/gN+Iq6lwSED1jqLC1rspq1gTIIdhC5tmx89LSyoXrTge2bZP/Z5pi+05k1n56Rc
dL65DbGZPDc4YPBy/gkz
=P1gQ
-----END PGP SIGNATURE-----

</body></email><email><emailId>20100806163544</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-08-06 16:35:44-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>

Thanks for the reply, Mike. More below...

On 8/06/2010 06:07 AM, Mike Perry wrote:
&gt;&gt; Is transport or message layer encryption redundant between a tor client
&gt;&gt; and a hidden service?
&gt; The short answer is yes, we believe it is redundant and unnecessary.

Yay!

&gt; The long answer is "My god man, hidden services? Nobody touches that
&gt; code. Who knows what lurks in the deep..."

Boo! Well, considering the power that hidden services brings to mobile
devices, I think it may well be worth getting someone to return to the
deep.

Here's a quick rundown of why I want to use them on Android:

- As a mobile device is always switching between carrier networks, wifi,
moving around the world, it is obviously constantly changing its IP
address. Having an onion address be a consistent way of addressig a
device is a very useful tool.

- Currently, to get "push" updates, a mobile device has to either poll,
keep a socket open, or receive some sort of SMS or other network native
push. With a hidden service, we can hold a server socket open on the
device, and let Tor handle the inbound traffic.

- Tor has proven insanely more resilient than traditional VPNs when it
comes to switching between 3G, 2G, wifi and no network at all. I have
been very impressed in field testing. The fact that hidden service based
solutions would seamlessly become available on to of this reliability is
another good reason to use them on mobiles.

- I/we/us mobile developers would prefer to spend our time focusing on
the specific usability and user experience issues unique to these
devices, and not reinventing, rolling our own secure messaging
protocols. For us to be able to rely on Tor for this is a great benefit,
but obviously we'd want to make sure we weren't worshipping false gods.

&gt; "usability" reasons in onion urls. These urls are the only real means
&gt; a user has of authenticating their destination.

Right.

&gt; In an ideal world, users are perfectly capable of memorizing every
&gt; character of the 80bit base64 key hash in the .onion url.

What if used QRCodes or some other digital format to exchange the full
key hash, so that we don't have to shorten, vanitize or otherwise weaken
them?

&gt; In the real world, it is disturbingly practical to compute .onion urls
&gt; that have a significantly large number of characters in common with an
&gt; arbitrary target url, in arbitrary positions of the url.

We would never do this... our focus is not on the hidden service web so
to speak, and more on the hidden service as infrastructure for
messaging. This removes a ton of issues around friendly URL schemes.

&gt; So, while in theory, hidden services are probably just barely beyond
&gt; the horizon of the cryptographically insecure, in practice they are a
&gt; usability nightmare to use for things like chat, where humans need to
&gt; establish visual continuity for the endpoint they are communicating
&gt; with.
&gt; Sadly, this issue may just be the tip of the iceberg in the hidden
&gt; service design, and there may be other edge cases that could be a huge
&gt; problem for uses like chat. Denial of service conditions are
&gt; particularly susceptible to gaming for chat, and the hidden service

I need to think about this more... in terms of availability of services,
this is definitely an increased case with a mobile device to goes up and
down quite a bit. However, our perspective on that was to use that feature

As for the visual continuity and social engineering impersonation
aspects, this has been a huge problem with services like Skype, and they
use human readable, friendly names.

The other approach, used by Drop.io, is to create temporary hash-based
URL "rooms" or "drops", that are an anonymous place to temporarily
connect, share files, talk, etc, and then move on. Less permanent, more
transient, and more difficult perhaps to impersonate, since no one is
claiming a permanent .onion. Every chat, every session a new hostname
and port would be used for the hidden service.

We just need to figure out how to bootstrap the discovery bit..

&gt; In the real world, secure distributed dictionaries for this may not
&gt; exist, and/or may have subtle vulnerabilities of their own. They probably
&gt; do exist for our centralized directory model, but we haven't really
&gt; devoted enough thought into the hidden service design to really bother
&gt; with them. Perhaps you could build one as part of your chat protocol.

Would love to, with some help. We have initially been thinking about a
centralized directory server, a basic DNS type service, mapping
nicknames to .onions. This would be optional.

&gt; All that said, hidden services do have one signifcant advantage over
&gt; regular Tor usage that is probably worth mentioning: Hidden services
&gt; overall are generally more secure than using Tor to contact an
&gt; arbitrary Internet endpoint using an arbitrary application.

YES! That is what I am most excited about, especially paired with the
P2P nature of what we are designing. No XMPP/Jabber hosted Gmail chat
service to worry about, no exit nodes... just two Tor client talking to
eachother in the most direct manner possible.


&gt; Have you seen torchat? https://code.google.com/p/torchat/

Yup we are checking it out. It is an interesting start, and we are
trying to decide if we want to be interoperable with it or not.
Currently, we have a small embedded HTTP server that runs in the app and
were planning on basically using more of a text message style
connectionless model of interaction. We would also be able to support
file transfer.

&gt; Probably your primary threat at this point is user error, more so than
&gt; interception or the direct subversion of the hidden service protocol,
&gt; which most likely is end-to-end secure...

Right, and that is where we want to focus our energy, while also
encouraging Tor core to continue work on improving hidden services for
applications just like these.

&gt; If your secondary crypto system could somehow improve upon the utterly
&gt; broken usability model of hidden services, then it would be a good
&gt; idea to add it. Most likely though, a secondary system would just add
&gt; confusion, and therefore insecurity. Ultimately it depends on the
&gt; userbase and the UI design.

We have already implemented the chat OTR protocol using the OTR4Java
library, and it seems to work well enough. My experience has been that
users can be trained to press the "encrypt chat" button, but they very
rarely bother to verify their key fingerprints via a separate channel.

Thanks again for the reply. A lot to think about here. I will share a
larger design document for comment next week, and perhaps a prototype.

+n



</body></email><email><emailId>20100806182117</emailId><senderName>John Brooks</senderName><senderEmail>special@dereferenced.net</senderEmail><timestampReceived>2010-08-06 18:21:17-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>

On Fri, Aug 6, 2010 at 10:35 AM, Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt; &gt; Have you seen torchat? https://code.google.com/p/torchat/
&gt;
&gt; Yup we are checking it out. It is an interesting start, and we are
&gt; trying to decide if we want to be interoperable with it or not.
&gt; Currently, we have a small embedded HTTP server that runs in the app and
&gt; were planning on basically using more of a text message style
&gt; connectionless model of interaction. We would also be able to support
&gt; file transfer.

I can't let this pass by without mentioning a project of my own that
I've been sitting on for awhile. I wrote Torsion, which is a hidden
service-based instant messaging system similar to TorChat, but much
more elaborate, maintained, and less buggy/insecure. It's currently in
a pre-beta state pending a few usability touches, but it's very solid.

You can take a look at http://github.com/special/torsion - with your
focus on mobile and Java, it's obviously a different goal, but there
might be some useful pieces in there. Torsion's protocol is much more
complex, though, so it would be difficult to have any sort of
compatibility. I do not use any encryption or authentication on top of
hidden services, other than leveraging the hidden service keys to
prove identity during contact requests. I'd be happy to talk more
about it; feel free to ask.

If anyone is more generally interested, it's absolutely possible to
build and use right now. I'll be making proper releases and a real
announcement when I've got things polished to my satisfaction.

&gt; +n

 - John Brooks
</body></email><email><emailId>20100806182815</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-08-06 18:28:15-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>

On Fri, Aug 6, 2010 at 6:00 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; ...
&gt; | On my 1.5GHz x86-machine, I get about 500k hashes/sec.
&gt; | +---------------------------------------------+
&gt; | | chars | ~number of tries | ~time @ 500 KH/s |
&gt;  [snip]
&gt; | |     6 |      32^6  =  1g |           30 min |
&gt; | |     7 |      32^7  = 32g |            1 day |
&gt; | |     8 |      32^8  =  1t |          25 days |
&gt; | |     9 |      32^9  = 32t |        2.5 years |

to throw in my $0.02, this is quite low for any kind of on-demand
computing resource within the same league of difficulty. at $200 you
can get grid/cloud compute time on the order of 200B hashes/hour (160
cores, 160 G memory) for 3-4 hours. and getting cheaper every day...

best regards,

</body></email><email><emailId>20100806232841</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-06 23:28:41-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>


On Fri, 6 Aug 2010 11:28:15 -0700
coderman &lt;coderman@gmail.com&gt; wrote:

&gt; On Fri, Aug 6, 2010 at 6:00 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; &gt; ...
&gt; &gt; | On my 1.5GHz x86-machine, I get about 500k hashes/sec.
&gt; &gt; | +---------------------------------------------+
&gt; &gt; | | chars | ~number of tries | ~time @ 500 KH/s |
&gt; &gt;   [snip]
&gt; &gt; | |       6 |         32^6   =   1g |                30 min |
&gt; &gt; | |       7 |         32^7   = 32g |                  1 day |
&gt; &gt; | |       8 |         32^8   =   1t |               25 days |
&gt; &gt; | |       9 |         32^9   = 32t |            2.5 years |
&gt; 
&gt; to throw in my $0.02, this is quite low for any kind of on-demand
&gt; computing resource within the same league of difficulty. at $200 you
&gt; can get grid/cloud compute time on the order of 200B hashes/hour (160
&gt; cores, 160 G memory) for 3-4 hours. and getting cheaper every day...

Good point.  Also, the README lists a few optimizations that would make
it go even faster (most notably, converting the user-provided regex for
the base32-encoded hash to something that the binary hash can be
efficiently compared to).

Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100917175352</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-09-17 17:53:52-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port or destination host</subject><body>

On Tuesday 31 August 2010 01:42:51 Jacob Appelbaum wrote:
&gt; On 08/25/2010 02:12 PM, Robert Hogan wrote:
&gt; &gt; So this is my take on the thread so far:
&gt; &gt; 
&gt; &gt; - We've zoned in on the fact that this proposal is really about
&gt; &gt; isolating applications on circuits rather than ports on circuits.
&gt; 
&gt; I think so too.
&gt; 
&gt; &gt; - Isolating by destination address is likely to increase the number of
&gt; &gt; circuits the client builds by some scary quantity.
&gt; 
&gt; I'm not sure that I'm entirely on board with that - I think for
&gt; webbrowsing this is true but for ssh or other traffic, I'm not sure. I
&gt; actually want five circuits when I start my Tor - one for IRC, one for
&gt; ssh, one for ttdnsd, one for email stuff, another for jabber and so on.
&gt; In most cases, I require a different circuit for each because I don't
&gt; want to link _any_ of that data.
&gt; 

I wonder would adapting LongLivedPorts to enforce circuit isolation achieve 
this requirement without the risk of inducing exponential circuit creation. 
Since applications that use LongLivedPorts by definition require long-
running connections and create new connections relatively infrequently it 
seems like a good fit. 

Changing LongLivedPorts this way would all the problem-cases I can remember 
that gave rise to this proposal, most of which involved mixing chat/ssh/irc 
with browsing and the like.



</body></email><email><emailId>20100801200802</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-01 20:08:02-0400</timestampReceived><subject>Re: [or-cvs] r22762: {website} get some work done on the new</subject><body>


On Sun,  1 Aug 2010 17:37:01 +0000 (UTC)
Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; Modified: website/branches/web20/about/en/corepeople.wml
&gt; ===================================================================
&gt; --- website/branches/web20/about/en/corepeople.wml	2010-08-01 14:44:18 UTC (rev \
&gt;                 22761)
&gt; +++ website/branches/web20/about/en/corepeople.wml	2010-08-01 17:37:01 UTC (rev \
&gt; 22762)

&gt; +        &lt;td&gt;
&gt; +          &lt;div class="name"&gt;Sebastian Hahn&lt;/div&gt;
&gt; +          &lt;div class="caps"&gt;Developer&lt;/div&gt;
&gt; +          &lt;p&gt;Worked during the 2008 Google Summer of Code on a networking \
&gt; application to automatically carry out tests for Tor and during the 2009 Google \
&gt; Summer of Code on expanding our secure updater to include BitTorrent support. \
&gt; Generally manages out git repository, reviews code patches, and generally helps out \
&gt; a lot.&lt;/p&gt; +        &lt;/td&gt;

s/manages out/manages our/

Robert Ransom


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100804191107</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2010-08-04 19:11:07-0400</timestampReceived><subject>Re: Second Tor online "developer party" on Monday from 18:00 to 20:00</subject><body>

On Wed, Aug 4, 2010 at 3:06 PM, Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt; Hi Nick,
&gt;
&gt; Sorry if I am asking the obvious. I cant see a reference in the email to the
&gt; IRC channel.
&gt; I'd like to join you guys.

See below:

&gt; Nick Mathewson wrote:
&gt;&gt; It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
&gt;&gt; channel on irc.oftc.net.
</body></email><email><emailId>20100805011621</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2010-08-05 01:16:21-0400</timestampReceived><subject>Re: thandy repository mirrorability</subject><body>

On Wed, Aug 4, 2010 at 9:03 AM, Peter Palfrader &lt;peter@palfrader.org&gt; wrote:
&gt; ...
&gt; I've been wondering about mirrorability for when we start using thandy
&gt; for real.  That is, what happens when a user accesses a mirror that is
&gt; in the process of updating its files.
&gt; ...
&gt; So, from a quick look at thandy and without knowing much about it, it
&gt; appears as if thandy will suffer from much of the same problems.  The
&gt; timestamp.txt file looks like one that's particular problematic.  Is
&gt; this correct or is there some clever scheme that avoids the desync
&gt; problems while a mirror update is in progress?

yes, this will have a similar issue. caveat being that at least one
repository has all the files needed, so the client will retry / resume
until success. (not always using a mirror like Debian)

this introduces other issues as one pet peeve of mine during the "use
Thandy as network installer" experiment was that an on-demand network
install would delay a while on failed attempts, while you really want
it to try again quick or bail out.


&gt; Should we worry about this and try to see if we can come up with some
&gt; clever schemes that mitigate or avoid the issue?

i am inclined to say ignore this unless it becomes a problem for these reasons:

- most Thandy clients will be doing background updates, and won't care
if they have to cycle to the next mirror because the current file is
incomplete or missing.

- the HTTP 1.1 resume capability in Thandy means even a partial file
can be useful, so avoiding these is not necessary and may actually be
counter-productive.

note that my understanding of Thandy is rusty, and out of date.
hopefully Nick or others will correct my misstatements :)

</body></email><email><emailId>20100806235958</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-06 23:59:58-0400</timestampReceived><subject>Re: Encryption over Hidden Services</subject><body>


On Fri, 06 Aug 2010 12:35:44 -0400
Nathan Freitas &lt;nathan@freitas.net&gt; wrote:

&gt; - Currently, to get "push" updates, a mobile device has to either poll,
&gt; keep a socket open, or receive some sort of SMS or other network native
&gt; push. With a hidden service, we can hold a server socket open on the
&gt; device, and let Tor handle the inbound traffic.

That sounds like a bad idea.  If you use only one hidden service per
device, an attacker can easily direct a ‘special' update to a specific
user.  If you use two or more hidden services per device and dedicate
one of them to receiving updates, it's still possible for a well-funded
attacker to correlate a device's hidden services (their descriptors
will always be published at about the same time), and you're putting
more load on the hidden-service directories for a lousy reason.

What's wrong with ‘pull' updates, anyway?  Everyone else uses them.

&gt; &gt; In the real world, it is disturbingly practical to compute .onion urls
&gt; &gt; that have a significantly large number of characters in common with an
&gt; &gt; arbitrary target url, in arbitrary positions of the url.
&gt; 
&gt; We would never do this... our focus is not on the hidden service web so
&gt; to speak, and more on the hidden service as infrastructure for
&gt; messaging. This removes a ton of issues around friendly URL schemes.

It doesn't matter whether you would do that -- an attacker can generate
keys whose hashes match 7 characters at the beginning and 2 at the end
of your hidden service name (and as coderman pointed out, this will
take any competent TLA very little time), and your users will not check
the rest of the hash.  DO NOT rely on your users comparing a key
fingerprint with any care at all.

&gt; &gt; In the real world, secure distributed dictionaries for this may not
&gt; &gt; exist, and/or may have subtle vulnerabilities of their own. They probably
&gt; &gt; do exist for our centralized directory model, but we haven't really
&gt; &gt; devoted enough thought into the hidden service design to really bother
&gt; &gt; with them. Perhaps you could build one as part of your chat protocol.
&gt; 
&gt; Would love to, with some help. We have initially been thinking about a
&gt; centralized directory server, a basic DNS type service, mapping
&gt; nicknames to .onions. This would be optional.

Yes, centralize it!  That way, the ‘very polite man from Italy named
Guido' that Mr. Dingledine keeps mentioning in the Tor videos can
arrange a spoofed directory entry with only one, er, visit.

Why not require your users to exchange their contact addresses in
advance using ordinary Internet mail messages or attachments?  That
makes spoofing a name-hash association at least slightly harder, and
also increases the difficulty of spamming your entire userbase.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100807001703</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-07 00:17:03-0400</timestampReceived><subject>Re: Proposal: Optimistic Data for Tor: Server Side</subject><body>


On Fri, 6 Aug 2010 17:13:45 -0700
Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:

&gt; On Fri, 6 Aug 2010 15:56:08 -0400
&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt; &gt; On Tue, Aug 3, 2010 at 3:52 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt;  [...]
&gt; &gt; &gt;&gt; They look like Tor version numbers, for whatever Tor version merges
&gt; &gt; &gt;&gt; the patch that implements this, and later.
&gt; &gt; &gt;
&gt; &gt; &gt; No, I mean that if someone writes a totally different implementation of
&gt; &gt; &gt; the Tor server (say in some other language like Java or Haskell), how
&gt; &gt; &gt; will the client be able to tell whether that implementation supports
&gt; &gt; &gt; this feature?
&gt; &gt; 
&gt; &gt; We have no really good solution for this in general. It would be neat
&gt; &gt; to work one out, but that's probably a separate proposal. :)
&gt; 
&gt; Add a relay descriptor line:
&gt; 
&gt; bugfixes trac1795,fs12345,bz9876

On second thought, a ‘proposals' line would be more appropriate.
(Other implementations would have their own bugs and bug trackers.)

Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100811062543</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-11 06:25:43-0400</timestampReceived><subject>Re: [or-cvs] [tor/master 3/3] Move exit-stats code to the end of</subject><body>

On 8/10/10 11:53 PM, Roger Dingledine wrote:
&gt; It would be good in the future to do this sort of change as two commits --
&gt; one that moves the huge chunks of code from one file to another, and a
&gt; second that actually modifies what the code is. Otherwise when reviewing,
&gt; we have to memorize all the removed lines and recognize them when they
&gt; reappear, so we can learn what actually changed.

This patch basically moves code from the middle of rephist.c to its end
and only changes two comments. Maybe the latter confused patch and made
the diff look funny. But there are no code changes here.

--Karsten
</body></email><email><emailId>20100814143953</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2010-08-14 14:39:53-0400</timestampReceived><subject>The state of website translations</subject><body>

Hi everyone,

This email is long overdue, but the goal is that you will get a better
look at how website translations make it from the translation portal
and on to the website. This email will also explain why some of the
translated pages show outdated information.

When someone translates a file for the website on
https://translation.torproject.org/, that file is stored as .po.
Before the translation can make it on to the website, the file has to
be converted to .wml. However, the translated .po will only be
converted if 80% or more has been translated. If the translation
cannot be converted, the file that is used as fallback when building
the website is the version that was last successfully converted to
.wml and added to the repository.

At the moment, we have 584 .wml files in the repository that make up
the website, including the original English pages. If we were to
remove the translated .wml files from the repository, and only convert
them before building and pushing the website, we would have 334 .wml
files (again, also including the original English pages).

The plan is that we will, starting when the new website is released
(hopefully in not too long), not keep translated .wml files in the
repository and only convert them before building the website. This may
give us less translated files than we have right now, but at least the
pages will be more up to date. If anyone wants to start doing this
today with the current website, let me know.

Thanks,

-- 
Runa A. Sandvik
</body></email><email><emailId>20100816183711</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-08-16 18:37:11-0400</timestampReceived><subject>Re: Bandwidth Measurement for Tor Server Nodes - hibernating the</subject><body>

Hi or-dev,

I have just spent a little time thinking about this and tinkering here.
I may not have been too clear before.

I ideally want to have my Tor installation acting as a server and a 
client at the same time.
Failing that 2 machines are required, one as a server and one being used 
as a client, which I think is not ideal.
If I could find a way to have it run as a server - a fast one - but with 
limited bandwidth allocated, and then a client at the same time, I would 
be happy.
Right now I have 384mb Recv and 78mb served, so the 2 numbers are not 
necessarily symmetric.

At present with Tor, as you say, EITHER Recv OR Sent is used in 
bandwidth limiting, with connections being blown away when the node 
moves to hibernate state.

Ideally I would like only 'server'' connections blown away, but the 
ability to act as a client intact so I can continue browsing with the 
same node.
In this endeavour I have been playing with the code and so far I have 
half the story covered, with only Sent bytes operating in the hibernate 
code.
What I need now is to switch off the blowing away of 'Client mode' based 
connection, and still enabling them be created. Though I am not sure if 
that's possible ?

Of course, according to how the originators of Tor intended, I could be 
barking up the wrong tree ?

With kind regards,
Cav Edwards



Damian Johnson wrote:
&gt; It hibernates when *either* the read or write total reaches your limit 
&gt; for the accounting period. This is documented in the man page under 
&gt; AccountingMax:
&gt; http://www.torproject.org/tor-manual.html.en
&gt;
&gt; Usually these values are decently symmetric. Cheers! -Damian
&gt;
&gt; On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;cav@gotadsl.co.uk 
&gt; &lt;mailto:cav@gotadsl.co.uk&gt;&gt; wrote:
&gt;
&gt;     Dear Group,
&gt;
&gt;     I have noticed that if I set a bandwidth restraint for my server,
&gt;     it hibernates when the amount of data 'downloaded' rather than
&gt;     'sent' reaches the specified limit within the accounting period.
&gt;     Thinking about it... does it make more sense for the limit to be
&gt;     applied to the amount of 'sent' data as opposed to 'received' ?
&gt;     -- 
&gt;
&gt;     With kind regards,
&gt;     Cav Edwards
&gt;
&gt;

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi or-dev,&lt;br&gt;
&lt;br&gt;
I have just spent a little time thinking about this and tinkering here.&lt;br&gt;
I may not have been too clear before.&lt;br&gt;
&lt;br&gt;
I ideally want to have my Tor installation acting as a server and a
client at the same time.&lt;br&gt;
Failing that 2 machines are required, one as a server and one being
used as a client, which I think is not ideal.&lt;br&gt;
If I could find a way to have it run as a server - a fast one - but
with limited bandwidth allocated, and then a client at the same time, I
would be happy.&lt;br&gt;
Right now I have 384mb Recv and 78mb served, so the 2 numbers are not
necessarily symmetric.&lt;br&gt;
&lt;br&gt;
At present with Tor, as you say, EITHER Recv OR Sent is used in
bandwidth limiting, with connections being blown away when the node
moves to hibernate state.&lt;br&gt;
&lt;br&gt;
Ideally I would like only 'server'' connections blown away, but the
ability to act as a client intact so I can continue browsing with the
same node.&lt;br&gt;
In this endeavour I have been playing with the code and so far I have
half the story covered, with only Sent bytes operating in the hibernate
code.&lt;br&gt;
What I need now is to switch off the blowing away of 'Client mode'
based connection, and still enabling them be created. Though I am not
sure if that's possible ?&lt;br&gt;
&lt;br&gt;
Of course, according to how the originators of Tor intended, I could be
barking up the wrong tree ?&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Damian Johnson wrote:
&lt;blockquote
 cite="mid:AANLkTi=-_AutETg2gBSF4a8BAJ=spewaPPnk2-iC1_jw@mail.gmail.com"
 type="cite"&gt;It hibernates when &lt;b&gt;either&lt;/b&gt; the read or write total
reaches your limit for the accounting period. This is documented in the
man page under AccountingMax:&lt;br&gt;
  &lt;a moz-do-not-send="true"
 href="http://www.torproject.org/tor-manual.html.en"&gt;http://www.torproject.org/tor-manual.html.en&lt;/a&gt;&lt;br&gt;
  &lt;br&gt;
Usually these values are decently symmetric. Cheers! -Damian&lt;br&gt;
  &lt;br&gt;
  &lt;div class="gmail_quote"&gt;On Thu, Aug 12, 2010 at 11:28 AM, Cav &lt;span
 dir="ltr"&gt;&lt;&lt;a moz-do-not-send="true" href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt;&gt;&lt;/span&gt;
wrote:&lt;br&gt;
  &lt;blockquote class="gmail_quote"
 style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;Dear
Group,&lt;br&gt;
    &lt;br&gt;
I have noticed that if I set a bandwidth restraint for my server, it
hibernates when the amount of data 'downloaded' rather than 'sent'
reaches the specified limit within the accounting period.&lt;br&gt;
Thinking about it... does it make more sense for the limit to be
applied to the amount of 'sent' data as opposed to 'received' ?&lt;br&gt;
    &lt;font color="#888888"&gt;-- &lt;br&gt;
    &lt;br&gt;
With kind regards,&lt;br&gt;
Cav Edwards&lt;br&gt;
    &lt;br&gt;
    &lt;/font&gt;&lt;/blockquote&gt;
  &lt;/div&gt;
  &lt;br&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


</body></email><email><emailId>20100822045330</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2010-08-22 04:53:30-0400</timestampReceived><subject>Re: Encryption over Hidden Services [messaging]</subject><body>

Lot of interesting replies here.

One area where additional end to end encryption between things
running over hidden services is useful is when you terminate the
hidden service on one machine/dmz and forward the traffic
somewhere else. You may indeed want to encrypt that. A couple
of the current hidden services hint at forwarding on such terminations
in their docs. Same goes for encrypting the user path to the Tor client.

Further, Tor itself both can and may have inputs from adversaries.
As may also OpenSSL, upon which Tor relies for crypto.

In any case, having another end to end wrapper... such as the common
case of HTPS... is a good thing, even if it is OpenSSL. And a blanket 'no,
Tor already has end2end crypto' is a case unspecific answer.

If you suspect OpenSSL, there's always NSS, GnuTLS, Secure Channel,
JSSE, PolarSSL, etc. As well as OTR, Zfone and so on.


Also, OnionCat may compliment some of the ideas in this thread.
It would be nice if all the anon systems could interop well... between
their own private /48's worth of IPV6 space. Though it's still only 80 bits.

You also need to be concerned with source address authentication in
these apps... if you plan on using Tor PKI to derive that part of things.


Torsion and the use of Tor for [telephony based] IM in general seems
comparable to the delay in SMS, which users already accept.
</body></email><email><emailId>20100823200432</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2010-08-23 20:04:32-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Hi Robert,

On 8/22/10 9:34 PM, Robert Hogan wrote:
&gt; On Thursday 19 August 2010 09:08:56 Karsten Loesing wrote:
&gt;&gt;
&gt;&gt; Do you have a patch that prints out a log message whenever we would add
&gt;&gt; cells or bytes to a counter?
&gt;&gt;
&gt; 
&gt; Yes - see:
&gt; 
&gt; https://trac.torproject.org/projects/tor/ticket/1826
&gt; 
&gt; and
&gt; 
&gt; https://gitweb.torproject.org/hoganrobert/tor.git/shortlog/refs/heads/bug1826-
&gt; metrics
&gt; 
&gt; I'm hoping you can fill in the &lt;insert metric here&gt; bit!

Can you look at branch bug1826-metrics in my public repository,
particularly at log_unwanted_bytes() where I call the counting function?
Does that look correct to you?

&gt;&gt; And do you have an exit node to test the new stats code?
&gt;&gt;
&gt; 
&gt; I can run a restrictive exit to test that the code works properly. I don't 
&gt; have an exit node that can return useful data.

Great! I didn't test my code yet other than running the unit tests. Can
you run this code (if it looks good to you) on your relay for at least
24 hours? It should write a file stats/unwanted-bytes-stats to its data
directory. If it does, we can try to find someone with the default exit
policy to run this code.

Best,
--Karsten
</body></email><email><emailId>20100830100434</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2010-08-30 10:04:34-0400</timestampReceived><subject>Third Tor online "developer party" on Tuesday from 19:00 to 21:00</subject><body>

I hereby schedule a developer party for this coming Tuesday, 3pm to 5pm
Eastern time, noon to 2pm Pacific time, I think that makes it 19:00 to
21:00 GMT. The location is the #tor-dev channel on irc.oftc.net.

For this particular party, I will define "fun" to be "opening and
refining trac entries".

(Doesn't that sound like fun? Isn't overloading the definition of common
words fun?)

Part of the goal is to flesh out your entries under
https://trac.torproject.org/projects/tor/wiki/sponsors/SponsorD/September2010
and
https://trac.torproject.org/projects/tor/wiki/sponsors/SponsorD/March2011
with brainstorming actual steps that need to get done to make progress
on each item, figure out if there are orphan projects where everybody is
thinking that somebody else will move it forward, and generally help sort
out the "how do we get there from here" questions that people might have.

For those new to this developer party concept, I've quoted Nick's earlier
summary below.

--Roger

On Wed, Aug 04, 2010 at 02:19:39PM -0400, Nick Mathewson wrote:
&gt; Hi, folks!  This email is a heads-up about our next online
&gt; nonstructured mass developer meeting, still called a "developer party"
&gt; on the superstitious belief that if we act like it's supposed to be
&gt; fun, it will be.   The last one was fun, after all.
&gt; 
&gt; (I'm announcing this one on or-dev, since that's where people
&gt; suggested that I announce it after I announced the last one on another
&gt; list.  If you don't think these messages should be on or-dev, please
&gt; email me personally [not the list] to say so.)
&gt; 
&gt; It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
&gt; channel on irc.oftc.net.  That's 14:00 to 16:00 eastern, and 11:00 to
&gt; 13:00 pacific, if I can still do math with my current jetlag.
&gt; 
&gt; General notes:
&gt; * If you're not free to make it, or if you're not free to make it for
&gt; the whole time, don't worry.  There will be more of these at other
&gt; times ranging from "too late in Europe" to "too early in California".
&gt; * If you're not an actual developer on Tor, you're welcome to come and
&gt; hang out, but this is mainly a time for developers to chat and plot
&gt; and generally confab.
&gt; * We're probably not going to be "partying" for every minute of all 2
&gt; hours; think of this as a salon where people wander in and out and
&gt; take breaks to go into a corner and eat cheese or debug trac or
&gt; whatever.
&gt; * The format will probably change in the future as we get some
&gt; experience with it and learn more about what does (and doesn't) work
&gt; for us.  If having 2 open hours is too much, let's do less.
&gt; * I'm going to try to "host" this developer party.  Since you can't
&gt; serve food over IRC, and there's no need to vacuum the floor before
&gt; the party starts, I'm not quite sure what my responsibility will be
&gt; other than being around the whole time and trying to make sure the
&gt; conversation stays interesting.  I'll play it by ear.
&gt; 
&gt; peace,
&gt; -- 
&gt; Nick
&gt; 
</body></email><email><emailId>20100830103630</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2010-08-30 10:36:30-0400</timestampReceived><subject>Re: Safely collecting data to estimate the number of Tor users</subject><body>


On Mon, 30 Aug 2010 11:09:07 +0200
Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; c) Steven proposes to i) encrypt logs to a public key (or rather to a
&gt; symmetric session key which is encrypted to a public key) and ii) to
&gt; reduce IP address hashes in those logs to 40 bits. That means he's
&gt; referring to problem 1) above. I think that i) is a good approach to
&gt; move sensitive logs from an Internet host to a more secure place to run
&gt; the evaluation on. I could imagine implementing this to be a general Tor
&gt; feature, so that people who need verbose logs for debugging can encrypt
&gt; them on their server and evaluate them on a safe machine.

Log encryption doesn't need to be a new feature in Tor. Tell Tor to log
to a file that just happens to be a Unix FIFO, and have an encryption
tool designed for the task read from the pipe and write to a real file.

&gt;                                                           I'm slightly
&gt; concerned that this could encourage people to log more than they need.

Using a pipe and a separate encryption tool has the advantage of being
rather more difficult (and annoying) to set up than adding one new line
to torrc.  You can also glue on a chain of external log-sanitizing
filters (invocations of grep/sed, perhaps?) before the log is encrypted
that way.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20100831004251</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-08-31 00:42:51-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port</subject><body>

On 08/25/2010 02:12 PM, Robert Hogan wrote:
&gt; So this is my take on the thread so far:
&gt; 
&gt; - We've zoned in on the fact that this proposal is really about isolating 
&gt; applications on circuits rather than ports on circuits.
&gt; 

I think so too.

&gt; - Isolating by destination address is likely to increase the number of 
&gt; circuits the client builds by some scary quantity.

I'm not sure that I'm entirely on board with that - I think for
webbrowsing this is true but for ssh or other traffic, I'm not sure. I
actually want five circuits when I start my Tor - one for IRC, one for
ssh, one for ttdnsd, one for email stuff, another for jabber and so on.
In most cases, I require a different circuit for each because I don't
want to link _any_ of that data.

I'm going to use Tor like this because otherwise, I can't use the
Internet anonymously. It seems likely that this is a common use case for
a number of people. When we throw browsing into the mix, I'm not sure of
the best way to handle the circuit building.

Perhaps we should write a test to actually gather usage data? It would
allow us to know where we might build a new circuit and count the total
used in say, a day?

&gt; 
&gt; - There is a potential attack if we isolate by port number alone. A 
&gt; malicious website could server resources over a variety of port numbers, 
&gt; learn our exit nodes for each, and then presumably correlate our activity 
&gt; on port 443/80 with our activity on any services we use that it happens to 
&gt; provide on any of the other ports.
&gt; 

This is a problem but it is only a problem with a single protocol and I
think at best, it takes a user right back to the point where we've
started. For all other protocols, we've improved the security of the users.

&gt; - We can achieve some/a lot of the benefits sought by the proposal if we 
&gt; isolate streams based on the information provided by the socks request 
&gt; itself. The things people have suggested are:
&gt;   1 Socks authentication info (username/pass)
&gt;   2 Socks listener address/port
&gt;   3 Socks protocol
&gt;   4 Socks client IP
&gt;   5 Info in /proc/pid/cmdline garnered from the client's port number
&gt; 

I think 1-4 are solid. It also seems reasonable to look at the user
making the call if possible but as Nick pointed out, it seems hairy.

I'd also add the TransPort and the NATD port to the list - it may be
that a user is transparently routed or NAT'ed into Tor. We should
account for them as well.

&gt; My own view is that 1 to 4 above could be used to determine the choice of 
&gt; circuit even in the absence of an IsolateStreamsBy* option. 5 is ugly and 
&gt; generally won't work if running as a 'tor' user so can be discarded.
&gt; 

I think it's probably true but I wonder about this on Windows or other
platforms?

&gt; I think the only argument for making item 1 optional would be so that 
&gt; people know about it. Maybe it can be an option and on by default. 

I think it should be on by default and I'm fine with it being always on.

All the best,
Jacob
</body></email><email><emailId>20100705103317</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-05 10:33:17-0400</timestampReceived><subject>Re: Building Tor tor-0.2.2.13-alpha on windows</subject><body>

Thank you coderman.
I have reverted to the l release of OpenSSL and am now building ok.

With kind regards,
Cav Edwards



coderman wrote:
&gt; On Sat, Jul 3, 2010 at 1:42 PM, Cav &lt;cav@gotadsl.co.uk&gt; wrote:
&gt;   
&gt;&gt; ...
&gt;&gt; Is there a way around the problem below ?
&gt;&gt;     
&gt;
&gt; try adding 'no-hw' to your OpenSSL Configure options when building openssl libs.
&gt;   
&gt; ------------------------------------------------------------------------
&gt;
&gt;
&gt; No virus found in this incoming message.
&gt; Checked by AVG - www.avg.com 
&gt; Version: 9.0.830 / Virus Database: 271.1.1/2982 - Release Date: 07/04/10 19:35:00
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Thank you coderman.&lt;br&gt;
I have reverted to the l release of OpenSSL and am now building ok.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
coderman wrote:
&lt;blockquote
 cite="mid:AANLkTik91hPC9TvsactlYWNQ_DICdw36vM-HJEMl-NSc@mail.gmail.com"
 type="cite"&gt;
  &lt;pre wrap=""&gt;On Sat, Jul 3, 2010 at 1:42 PM, Cav &lt;a class="moz-txt-link-rfc2396E" \
href="mailto:cav@gotadsl.co.uk"&gt;&lt;cav@gotadsl.co.uk&gt;&lt;/a&gt; wrote:  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;...
Is there a way around the problem below ?
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
try adding 'no-hw' to your OpenSSL Configure options when building openssl libs.
  &lt;/pre&gt;
  &lt;pre wrap=""&gt;
&lt;hr size="4" width="90%"&gt;

No virus found in this incoming message.
Checked by AVG - &lt;a class="moz-txt-link-abbreviated" \
                href="http://www.avg.com"&gt;www.avg.com&lt;/a&gt; 
Version: 9.0.830 / Virus Database: 271.1.1/2982 - Release Date: 07/04/10 19:35:00

  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100707201910</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2010-07-07 20:19:10-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 07/07/2010 07:44 PM, Robert Hogan wrote:
&gt; I've pushed this to a new branch 'iphone' in the torsocks git repo so we 
&gt; can work on it together.
Thanks!

&gt; If you keep your branch on a repo in git hub I should be able to pull from 
&gt; it and keep it in line with any changes I make.
Hm, time I look for a manual on how to use git

&gt; Haven't looked at the patch yet, but it certainly applied cleanly!
eheh, at least! I'm using that patch myself to provide a deb for
torsocks over at slackware.it :)

- -- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkw04T4ACgkQTYvJ9gtgvF+kegCgySefxHZ0WGlCw4BwS6qaJM99
ztIAmwRa4pX0ryrD43grKusty1VQ9ELt
=TnOO
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100710022200</emailId><senderName>"torbridges.security"</senderName><senderEmail>torbridges.security@gmail.com</senderEmail><timestampReceived>2010-07-10 02:22:00-0400</timestampReceived><subject>tor cell size</subject><body>

Hello,everyone.

Can anyone explain to me why the tor cell size is 512 (498 +3) bytes? Is it special?
Thanks a lot!

2010-07-10 



torbridges.security 

[Attachment #3 (text/html)]

&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"&gt;
&lt;HTML&gt;&lt;HEAD&gt;
&lt;META content="text/html; charset=us-ascii" http-equiv=Content-Type&gt;
&lt;META name=GENERATOR content="MSHTML 8.00.7600.16588"&gt;&lt;LINK rel=stylesheet 
href="BLOCKQUOTE{margin-Top: 0px; margin-Bottom: 0px; margin-Left: 2em}"&gt;&lt;/HEAD&gt;
&lt;BODY style="MARGIN: 10px; FONT-FAMILY: verdana; FONT-SIZE: 10pt"&gt;
&lt;DIV&gt;&lt;FONT size=2 face=Verdana&gt;Hello,everyone.&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt; &lt;/DIV&gt;
&lt;DIV style="TEXT-INDENT: 2em"&gt;Can anyone explain to me why the tor 
cell size is 512 (498 +3) bytes? Is it special?&lt;/DIV&gt;
&lt;DIV style="TEXT-INDENT: 2em"&gt;Thanks a lot!&lt;/DIV&gt;
&lt;DIV style="TEXT-INDENT: 2em"&gt; &lt;/DIV&gt;
&lt;DIV align=left&gt;&lt;FONT size=2 face=Verdana&gt;2010-07-10 &lt;/FONT&gt;&lt;/DIV&gt;&lt;FONT size=2 
face=Verdana&gt;
&lt;HR style="WIDTH: 122px; HEIGHT: 2px" align=left SIZE=2&gt;

&lt;DIV&gt;&lt;FONT size=2 face=Verdana&gt;&lt;SPAN&gt;torbridges.security&lt;/SPAN&gt; 
&lt;/FONT&gt;&lt;/DIV&gt;&lt;/FONT&gt;&lt;/BODY&gt;&lt;/HTML&gt;


</body></email><email><emailId>20100712113744</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-12 11:37:44-0400</timestampReceived><subject>Re: New passive performance metrics in Tor</subject><body>

Hi There,

Does anyone know why there are very large values appearing in the state 
file ?

With kind regards,
Cav Edwards



Karsten Loesing wrote:
&gt; Hi everyone,
&gt;
&gt; I'm planning to add new passive performance metrics to Tor so that we
&gt; can better understand why it's slow and how we can improve it. Here is a
&gt; list of performance metrics we already have and a few ideas for new
&gt; metrics. If anyone has an idea what other metrics might be missing or
&gt; how we can improve the existing/planned metrics, please let us know!
&gt;
&gt;
&gt; Performance metrics we already have:
&gt;
&gt; - write-history and read-history: Total written and read bytes
&gt;
&gt; - dirreq-v[23]-{direct,tunneled}-dl: Network status download times
&gt;
&gt; - cell-processed-cells: Number of processed cells per circuit
&gt;
&gt; - cell-queued-cells: Mean number of cells contained in circuit queues
&gt;
&gt; - cell-time-in-queue: Mean time cells spend in circuit queues
&gt;
&gt; - cell-circuits-per-decile: Number of active circuits per day
&gt;
&gt; - exit-kibibytes-{written,read} and exit-streams-opened: Written and
&gt; read bytes and opened streams exiting the Tor network
&gt;
&gt; Just in case you just learned that we have these kinds of data and want
&gt; to look at them more closely, you'll find the daily updated July 2010
&gt; extra-info descriptors containing these metrics here:
&gt;
&gt;   http://metrics.torproject.org/data/extra-infos-2010-07.tar.bz2
&gt;
&gt; If you happen to find out something useful, please let us know, too! :)
&gt;
&gt;
&gt;
&gt; New performance metrics:
&gt;
&gt; 1. Written and read bytes spent on answering directory requests
&gt;
&gt; Mike wants to know for his bandwidth weights how many bytes we're
&gt; writing and reading for directory requests as compared to all bytes. We
&gt; could add two new lines in the style of write-history and read-history
&gt; that declare how many bytes were spent on directory requests, including
&gt; both direct connections to the Dir port and tunneled requests via
&gt; BEGIN_DIR cells:
&gt;
&gt;     "dirreq-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
&gt;         [At most once]
&gt;     "dirreq-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
&gt;         [At most once]
&gt;
&gt;         Declare how much bandwidth the OR has spent on answering
&gt;         directory requests.  Usage is divided into intervals of NSEC
&gt;         seconds.  The YYYY-MM-DD HH:MM:SS field defines the end of the
&gt;         most recent interval.  The numbers are the number of bytes used
&gt;         in the most recent intervals, ordered from oldest to newest.
&gt;
&gt; Here are some example numbers from my test relay, together with the
&gt; write-history and read-history lines for comparison:
&gt;
&gt; write-history 2010-07-10 19:53:30 (900 s) 126585824,118608860,
&gt; 160984887,215227933,279503671,292334518,247741024,219398726,402868466,
&gt; 171578104,134845462,103864240,339932861,197773378,313857195,172963329,
&gt; 155526629,252937014,244187702,197075966,152386190,175927358,163121741,
&gt; 178683670,257434914,113004935,113712270,105843282,163919436,209717008,
&gt; 145912027,185671909,214901809,120711828,177862476,215853506,151845080,
&gt; 246348316,249139845,159824705,189301611,149167678,174661744,148893984,
&gt; 166705025,96488337,113451396,125986495,83252142,111691155,89342727,
&gt; 181081343,247091129,222168462,127634564,151465333,284533765,235486901,
&gt; 288744935,243722540,187109053,140379274,107682143,155506145,215314138,
&gt; 165721878,172790983,194321640,263295290,196657740,206465896,181921549,
&gt; 157166653,216171620,273935225,341610717,254576134,287283026,345218991,
&gt; 218867344,221304725,159918366,219410175,317998413,267456903,370347960,
&gt; 360990463,227152997,210737304,328228011,284975201,195563699,169440384,
&gt; 225952664,167331447,206871134
&gt; read-history 2010-07-10 19:53:30 (900 s) 111893867,101529861,143895849,
&gt; 194786027,259952571,273497972,232257574,199549600,385105937,153788132,
&gt; 117426290,84115625,322626270,179367559,293464555,155173008,140076076,
&gt; 237776118,225444069,180710872,138166684,160516398,148001360,161921342,
&gt; 243594475,100661995,102812182,90311549,151614536,197647669,135284514,
&gt; 170708653,202502593,108863871,165358926,203496697,142017462,230877056,
&gt; 235022066,146810734,176047157,135151618,161136000,134416764,154471070,
&gt; 84377707,100789666,112208099,72023045,97726026,75320408,161555620,
&gt; 229979123,205614801,111857592,133387588,265711511,216666832,270679486,
&gt; 226124920,171931895,123012431,88188621,135887568,197036553,148318468,
&gt; 155601095,174911703,241373709,176322860,188172703,161709145,139134142,
&gt; 196972335,254543821,319215780,235328518,268214943,325796822,197507205,
&gt; 201169007,143374694,201244669,296243416,246725945,353965769,337025998,
&gt; 200899391,189473401,309588351,266155617,173460369,152280169,206597244,
&gt; 147200841,184052057
&gt; dirreq-write-history 2010-07-10 19:53:30 (900 s) 646347,560172,696779,
&gt; 830638,619676,602628,361450,740160,524300,568569,731671,854635,605561,
&gt; 564858,678157,532414,719312,494666,1301201,944818,527056,202686,1013200,
&gt; 553622,402782,416251,531494,366742,429971,664552,321484,617111,291196,
&gt; 397877,657988,323410,261872,698337,656536,958921,315250,222864,296399,
&gt; 657562,291304,532770,325678,409172,606387,573317,753559,764482,400565,
&gt; 464494,567049,451342,127342,492985,315013,887299,688030,589603,389064,
&gt; 223902,329524,807354,1215069,423756,697600,907185,723453,689116,538715,
&gt; 511851,558052,620773,354970,586254,421827,822856,786349,609691,638619,
&gt; 651930,653235,393705,627669,635353,554215,234620,725708,575857,538672,
&gt; 335683,846807,454024
&gt; dirreq-read-history 2010-07-10 19:53:30 (900 s) 492788,18459,30148,
&gt; 37121,533625,23774,163742,33518,553467,165008,31612,40248,530115,158371,
&gt; 27364,35238,539279,23376,166453,14047,525003,13245,163134,29956,615381,
&gt; 19639,11663,23016,600257,27761,14674,17969,495159,144806,13802,22840,
&gt; 490508,149164,19911,31915,597266,12861,20509,17639,493599,139914,14597,
&gt; 20603,494243,158505,34142,41609,508383,32690,160229,33347,508837,16767,
&gt; 151166,34133,556447,164360,27186,16380,13605,694385,39106,30262,41665,
&gt; 675799,32311,14205,28536,670198,37591,32236,23552,644491,29737,39118,
&gt; 21215,670186,17262,27210,34859,654266,25168,34874,29585,648736,13492,
&gt; 30356,19431,518298,173052,32005
&gt;
&gt; I'm wondering if we're really spending these few bytes on answering
&gt; directory requests. But even if these numbers are wrong, one gets the
&gt; idea what this metric is about.
&gt;
&gt;
&gt;
&gt; 2. Bidirectional use of connections
&gt;
&gt; Björn Scheuermann and Florian Tschorsch of Uni Düsseldorf want to know
&gt; what fraction of connections are used bidirectionally. They suggested to
&gt; count read and written bytes per connection in 10-second intervals and
&gt; classify connections as "below threshold", "mostly reading", "mostly
&gt; writing", and "both reading and writing":
&gt;
&gt;     "conn-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
&gt;         [At most once]
&gt;
&gt;         YYYY-MM-DD HH:MM:SS defines the end of the included connection
&gt;         statistics measurement interval of length NSEC seconds (86400
&gt;         seconds by default).
&gt;
&gt;         A "conn-stats-end" line, as well as any other "conn-*" line,
&gt;         is first added after the relay has been running for at least 24
&gt;         hours.
&gt;
&gt;     "conn-bidirectional" BELOW,READ,WRITE,BOTH NL
&gt;         [At most once]
&gt;
&gt;         Number of connections, split into 10-second intervals, that are
&gt;         used uni-directionally or bi-directionally.  Every 10 seconds,
&gt;         we determine for every connection whether we read and wrote less
&gt;         than a threshold of 20 KiB (BELOW), read 10 times more than we
&gt;         wrote (READ), wrote 10 times more than we read (WRITE), or read
&gt;         and wrote more than the threshold, but not 10 times more in
&gt;         either direction (BOTH).  After classifying a connection, read
&gt;         and write counters are reset for the next 10-second interval.
&gt;
&gt; I performed an early analysis based on the findings on my test relay.
&gt; Attached to this mail you'll find a histogram and a scatterplot that we
&gt; used to determine the threshold of 20 KiB (or 2 KiB/s) and the factor 10
&gt; as parameters.
&gt;
&gt; Here are the results of my test relay:
&gt;
&gt; conn-stats-end 2010-07-10 19:53:38 (84600 s)
&gt; conn-bidirectional 315227,55437,66653,97878
&gt;
&gt; These numbers imply that 97878 of 55437+66653+97878, or 44.5% of all
&gt; connections are used bidirectionally.
&gt;
&gt; An open question is whether we should distinguish between connections to
&gt; other relays and to clients. I wonder if there's an easy way to tell the
&gt; two connection types apart.
&gt;
&gt;
&gt; Comments? Thoughts?
&gt;
&gt; Thanks,
&gt; --Karsten
&gt;   
&gt;
&gt; ------------------------------------------------------------------------
&gt;
&gt;
&gt; ------------------------------------------------------------------------
&gt;

[Attachment #3 (multipart/related)]

[Attachment #5 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=UTF-8" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi There,&lt;br&gt;
&lt;br&gt;
Does anyone know why there are very large values appearing in the state
file ?&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Karsten Loesing wrote:
&lt;blockquote cite="mid:4C3AF9DB.8010702@gmx.net" type="cite"&gt;
  &lt;pre wrap=""&gt;Hi everyone,

I'm planning to add new passive performance metrics to Tor so that we
can better understand why it's slow and how we can improve it. Here is a
list of performance metrics we already have and a few ideas for new
metrics. If anyone has an idea what other metrics might be missing or
how we can improve the existing/planned metrics, please let us know!


Performance metrics we already have:

- write-history and read-history: Total written and read bytes

- dirreq-v[23]-{direct,tunneled}-dl: Network status download times

- cell-processed-cells: Number of processed cells per circuit

- cell-queued-cells: Mean number of cells contained in circuit queues

- cell-time-in-queue: Mean time cells spend in circuit queues

- cell-circuits-per-decile: Number of active circuits per day

- exit-kibibytes-{written,read} and exit-streams-opened: Written and
read bytes and opened streams exiting the Tor network

Just in case you just learned that we have these kinds of data and want
to look at them more closely, you'll find the daily updated July 2010
extra-info descriptors containing these metrics here:

  &lt;a class="moz-txt-link-freetext" \
href="http://metrics.torproject.org/data/extra-infos-2010-07.tar.bz2"&gt;http://metrics.torproject.org/data/extra-infos-2010-07.tar.bz2&lt;/a&gt;


If you happen to find out something useful, please let us know, too! :)



New performance metrics:

1. Written and read bytes spent on answering directory requests

Mike wants to know for his bandwidth weights how many bytes we're
writing and reading for directory requests as compared to all bytes. We
could add two new lines in the style of write-history and read-history
that declare how many bytes were spent on directory requests, including
both direct connections to the Dir port and tunneled requests via
BEGIN_DIR cells:

    "dirreq-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
        [At most once]
    "dirreq-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM... NL
        [At most once]

        Declare how much bandwidth the OR has spent on answering
        directory requests.  Usage is divided into intervals of NSEC
        seconds.  The YYYY-MM-DD HH:MM:SS field defines the end of the
        most recent interval.  The numbers are the number of bytes used
        in the most recent intervals, ordered from oldest to newest.

Here are some example numbers from my test relay, together with the
write-history and read-history lines for comparison:

write-history 2010-07-10 19:53:30 (900 s) 126585824,118608860,
160984887,215227933,279503671,292334518,247741024,219398726,402868466,
171578104,134845462,103864240,339932861,197773378,313857195,172963329,
155526629,252937014,244187702,197075966,152386190,175927358,163121741,
178683670,257434914,113004935,113712270,105843282,163919436,209717008,
145912027,185671909,214901809,120711828,177862476,215853506,151845080,
246348316,249139845,159824705,189301611,149167678,174661744,148893984,
166705025,96488337,113451396,125986495,83252142,111691155,89342727,
181081343,247091129,222168462,127634564,151465333,284533765,235486901,
288744935,243722540,187109053,140379274,107682143,155506145,215314138,
165721878,172790983,194321640,263295290,196657740,206465896,181921549,
157166653,216171620,273935225,341610717,254576134,287283026,345218991,
218867344,221304725,159918366,219410175,317998413,267456903,370347960,
360990463,227152997,210737304,328228011,284975201,195563699,169440384,
225952664,167331447,206871134
read-history 2010-07-10 19:53:30 (900 s) 111893867,101529861,143895849,
194786027,259952571,273497972,232257574,199549600,385105937,153788132,
117426290,84115625,322626270,179367559,293464555,155173008,140076076,
237776118,225444069,180710872,138166684,160516398,148001360,161921342,
243594475,100661995,102812182,90311549,151614536,197647669,135284514,
170708653,202502593,108863871,165358926,203496697,142017462,230877056,
235022066,146810734,176047157,135151618,161136000,134416764,154471070,
84377707,100789666,112208099,72023045,97726026,75320408,161555620,
229979123,205614801,111857592,133387588,265711511,216666832,270679486,
226124920,171931895,123012431,88188621,135887568,197036553,148318468,
155601095,174911703,241373709,176322860,188172703,161709145,139134142,
196972335,254543821,319215780,235328518,268214943,325796822,197507205,
201169007,143374694,201244669,296243416,246725945,353965769,337025998,
200899391,189473401,309588351,266155617,173460369,152280169,206597244,
147200841,184052057
dirreq-write-history 2010-07-10 19:53:30 (900 s) 646347,560172,696779,
830638,619676,602628,361450,740160,524300,568569,731671,854635,605561,
564858,678157,532414,719312,494666,1301201,944818,527056,202686,1013200,
553622,402782,416251,531494,366742,429971,664552,321484,617111,291196,
397877,657988,323410,261872,698337,656536,958921,315250,222864,296399,
657562,291304,532770,325678,409172,606387,573317,753559,764482,400565,
464494,567049,451342,127342,492985,315013,887299,688030,589603,389064,
223902,329524,807354,1215069,423756,697600,907185,723453,689116,538715,
511851,558052,620773,354970,586254,421827,822856,786349,609691,638619,
651930,653235,393705,627669,635353,554215,234620,725708,575857,538672,
335683,846807,454024
dirreq-read-history 2010-07-10 19:53:30 (900 s) 492788,18459,30148,
37121,533625,23774,163742,33518,553467,165008,31612,40248,530115,158371,
27364,35238,539279,23376,166453,14047,525003,13245,163134,29956,615381,
19639,11663,23016,600257,27761,14674,17969,495159,144806,13802,22840,
490508,149164,19911,31915,597266,12861,20509,17639,493599,139914,14597,
20603,494243,158505,34142,41609,508383,32690,160229,33347,508837,16767,
151166,34133,556447,164360,27186,16380,13605,694385,39106,30262,41665,
675799,32311,14205,28536,670198,37591,32236,23552,644491,29737,39118,
21215,670186,17262,27210,34859,654266,25168,34874,29585,648736,13492,
30356,19431,518298,173052,32005

I'm wondering if we're really spending these few bytes on answering
directory requests. But even if these numbers are wrong, one gets the
idea what this metric is about.



2. Bidirectional use of connections

Björn Scheuermann and Florian Tschorsch of Uni Düsseldorf want to know
what fraction of connections are used bidirectionally. They suggested to
count read and written bytes per connection in 10-second intervals and
classify connections as "below threshold", "mostly reading", "mostly
writing", and "both reading and writing":

    "conn-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
        [At most once]

        YYYY-MM-DD HH:MM:SS defines the end of the included connection
        statistics measurement interval of length NSEC seconds (86400
        seconds by default).

        A "conn-stats-end" line, as well as any other "conn-*" line,
        is first added after the relay has been running for at least 24
        hours.

    "conn-bidirectional" BELOW,READ,WRITE,BOTH NL
        [At most once]

        Number of connections, split into 10-second intervals, that are
        used uni-directionally or bi-directionally.  Every 10 seconds,
        we determine for every connection whether we read and wrote less
        than a threshold of 20 KiB (BELOW), read 10 times more than we
        wrote (READ), wrote 10 times more than we read (WRITE), or read
        and wrote more than the threshold, but not 10 times more in
        either direction (BOTH).  After classifying a connection, read
        and write counters are reset for the next 10-second interval.

I performed an early analysis based on the findings on my test relay.
Attached to this mail you'll find a histogram and a scatterplot that we
used to determine the threshold of 20 KiB (or 2 KiB/s) and the factor 10
as parameters.

Here are the results of my test relay:

conn-stats-end 2010-07-10 19:53:38 (84600 s)
conn-bidirectional 315227,55437,66653,97878

These numbers imply that 97878 of 55437+66653+97878, or 44.5% of all
connections are used bidirectionally.

An open question is whether we should distinguish between connections to
other relays and to clients. I wonder if there's an easy way to tell the
two connection types apart.


Comments? Thoughts?

Thanks,
--Karsten
  &lt;/pre&gt;
  &lt;br&gt;
  &lt;hr size="4" width="90%"&gt;&lt;br&gt;
  &lt;center&gt;&lt;img src="cid:part1.09060701.06090602@gotadsl.co.uk"&gt;&lt;/center&gt;
  &lt;p&gt;&lt;br&gt;
  &lt;/p&gt;
  &lt;hr size="4" width="90%"&gt;&lt;br&gt;
  &lt;center&gt;&lt;img src="cid:part2.07040206.01000603@gotadsl.co.uk"&gt;&lt;/center&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


[Attachment #6 (image/png)]
[Attachment #7 (image/png)]

</body></email><email><emailId>20100713150441</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2010-07-13 15:04:41-0400</timestampReceived><subject>Re:</subject><body>

On Tue, 13 Jul 2010 07:03:53 -0700 (PDT)
davide89v@riseup.net wrote:

&gt; hi i'm a tor user, it is possible to configure pidgin portable with
&gt; the off the record plugin alredy installed?

Yes, we already do this as part of the Tor Browser IM Bundle, see
https://www.torproject.org/torbrowser/details.html.en#contents

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B
+1-781-352-0568

Website: https://www.torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
Skype: lewmanator
</body></email><email><emailId>20100720201040</emailId><senderName>Florian Tschorsch</senderName><senderEmail>florian.tschorsch@uni-duesseldorf.de</senderEmail><timestampReceived>2010-07-20 20:10:40-0400</timestampReceived><subject>Queuing process in ORs</subject><body>




Hi Everyone, 

I'm trying to understand the exact queuing process in ORs. 
As far as I know and verified in the source code it goes like this: 


TCP IN --&gt; ROUND ROBIN/ LEAKY BUCKET --&gt; CONN INBUF --&gt; CIRC QUEUES* --&gt; CONN OUTBUF \
--&gt; ROUND ROBIN/ LEAKY BUCKET --&gt; TCP OUT

ORs read data from a TCP connection to the connection's inbuf (read_to_buf_tls).
The amount of the allowed readable data is calculated by a round robin scheduler \
(depending on the bucket mechanism).

"Reading to" the inbuf (connection_handle_read_impl) triggers a bunch of procedures \
and ultimately pushes cells (after crypting) to the appropriate circuit queue.  After \
appending cells, Tor tries to pop cells and flushes them \
(connection_or_flush_from_first_active_curcuit) into the respective connection's \
outbuf. 

*And here comes my vagueness: I know circuits, multiplexed over one connection, are \
ordered in a circular linked list.  My assumption is that the scheduling on circuit \
level is realized by passing through the linked list of circuits and giving each of \
them the chance to forward cells.  I also could identify a callback method for the \
above mentioned procedure (connection_or_flushed_some), that tries to forward even \
more data.  But how do these mechanisms intertwine into circuit level scheduling? And \
is the circuit level scheduling influenced by the round robin scheduling?    

As soon as data is then available in a connection's outbuf Tor tries to flush some \
data over the TCP socket.  This also happens with an intermediate round robin \
scheduler (analogous to inbuf). 


It would be kind if someone could help me understanding this issue or at least \
confirm/disprove my findings.  I believe this would help other developers too and \
provide a better overall knowledge of Tor's source code. 

Thanks in advance.

Florian


</body></email><email><emailId>20100725195626</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2010-07-25 19:56:26-0400</timestampReceived><subject>Re: Proposal: Separate streams across circuits by destination port</subject><body>

On 07/23/2010 09:09 PM, Linus Nordberg wrote:
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote
&gt; Fri, 23 Jul 2010 17:03:09 +0200:
&gt; 
&gt; &gt; Filename: 171-separate-streams-by-port-or-host.txt
&gt; 
&gt; 1. Is 'connections' a well established term here?  I'm thinking TCP
&gt; connection but that clearly doesn't make sense in a UDP context, such
&gt; as DNS.  One could use 'packet' in one way or another instead, I
&gt; guess.

I think so. There is only TCP with Tor; I don't think it makes much
sense to discuss packets.

&gt; 
&gt; 2. &gt;IsolateStreamsByPort will take a list of ports or optionally the
&gt; &gt; keyword 'All' in place of a port list. The use of the keyword 'All'
&gt; &gt; will ensure that all connections attached to streams will be
&gt; &gt; isolated to separate circuits by port number.
&gt; 
&gt; Just to make it clear, would a packet sent to hostA:port1 end up
&gt; on the same circuit as one sent to hostB:port1?
&gt; 

Yes.

&gt; 3. If 2 says yes, would this turn into a no if IsolateStreamsByHost was
&gt; enabled?
&gt; 

Yes.


&gt; 4. 
&gt; 
&gt; 
&gt; 

Thanks for the patch!

&gt; Remote: origin http://git.torproject.org/ioerror/tor.git
&gt; Local:  isolated-streams /u/src/tor.ioerror/
&gt; Head:   b32947a tpyo correction
&gt; 
&gt; Changes:
&gt; 	Modified doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; diff --git a/doc/spec/proposals/171-separate-streams-by-port-or-host.txt \
&gt; b/doc/spec/proposals/171-separate-streams-by-port-or-host.txt index \
&gt;                 3f745dc..3bd0532 100644
&gt; --- a/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; +++ b/doc/spec/proposals/171-separate-streams-by-port-or-host.txt
&gt; @@ -20,7 +20,7 @@ we must balance network load issues and stream privacy. The Tor \
&gt; network will not currently scale to one circuit per connection nor should it \
&gt; anytime soon. 
&gt; Circuits are currently created with a few constraints and are rotated within
&gt; -a reasonable time window. This allows a rogue exit nodes to correlate all
&gt; +a reasonable time window. This allows a rogue exit node to correlate all
&gt; streams on a given circuit.
&gt; 
&gt; Design:
&gt; @@ -36,7 +36,7 @@ number.
&gt; IsolateStreamsByHost will take a boolean value. When enabled, all connections,
&gt; regardless of port number will be isolated with separate circuits per host. If
&gt; this option is enabled, we should ensure that the client has a reasonable
&gt; -number of pre-built circuits to ensure percieved performance. This should also
&gt; +number of pre-built circuits to ensure perceived performance. This should also
&gt; intentionally limit the total number of circuits a client will build to ten
&gt; circuits to prevent abuse and load on the network. This is a tradeoff of
&gt; performance for anonymity. Tor will issue a warning if a client encounters this
&gt; @@ -45,7 +45,7 @@ limit.
&gt; Security implications:
&gt; 
&gt; It is believed that the proposed changes will improve the anonymity for end
&gt; -user stream privacy.  The end user will no longer link all of their traffic at
&gt; +user stream privacy.  The end user will no longer link all of its traffic at
&gt; a single exit node during a given time window.
&gt; 
&gt; Specification:
&gt; 

All the best,
Jake


</body></email><email><emailId>20100726223322</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-26 22:33:22-0400</timestampReceived><subject>Re: CircuitBuildTimeout Management and the Pareto Distribution</subject><body>

Thanks Mike !

With kind regards,
Cav Edwards



Mike Perry wrote:
&gt; Thus spake Cav (cav@gotadsl.co.uk):
&gt;
&gt;   
&gt;&gt; Hi Mike,
&gt;&gt;
&gt;&gt; Thanks for a quick reply. Maybe its my warped mind that had me consider 
&gt;&gt; that the management of timeouts (sliding the timeout up and down - as it 
&gt;&gt; appears in the logs) would affect the distribution of timeouts and 
&gt;&gt; therefore the pareto distribution around them.
&gt;&gt;
&gt;&gt; I will admit to experimenting with smaller values of 
&gt;&gt; CBT_DEFAULT_QUANTILE_CUTOFF. These lead to 'peaks' in the timeout 
&gt;&gt; distribution. The smaller the value, the tighter these 'peaks' seem to be.
&gt;&gt;     
&gt;
&gt; This should not be the case in 0.2.2.14 and above. Changing the
&gt; QUANTILE_CUTOFF default should now only govern which circuits you
&gt; actually use. Circuits should continue to build until
&gt; CBT_DEFAULT_CLOSE_QUANTILE, so the distribution of recorded buildtimes
&gt; will be much more insenitive to changes in the timeout value.
&gt;
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Thanks Mike !&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Mike Perry wrote:
&lt;blockquote cite="mid:20100726200406.GB16798@fscked.org" type="cite"&gt;
  &lt;pre wrap=""&gt;Thus spake Cav (&lt;a class="moz-txt-link-abbreviated" \
href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt;):

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;Hi Mike,

Thanks for a quick reply. Maybe its my warped mind that had me consider 
that the management of timeouts (sliding the timeout up and down - as it 
appears in the logs) would affect the distribution of timeouts and 
therefore the pareto distribution around them.

I will admit to experimenting with smaller values of 
CBT_DEFAULT_QUANTILE_CUTOFF. These lead to 'peaks' in the timeout 
distribution. The smaller the value, the tighter these 'peaks' seem to be.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
This should not be the case in 0.2.2.14 and above. Changing the
QUANTILE_CUTOFF default should now only govern which circuits you
actually use. Circuits should continue to build until
CBT_DEFAULT_CLOSE_QUANTILE, so the distribution of recorded buildtimes
will be much more insenitive to changes in the timeout value.


  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100707095642</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2010-07-07 09:56:42-0400</timestampReceived><subject>Torsocks patch for iDevices</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi all,
my name is Marco, I'm currently keeping a working port of Tor for the
(jailbroken) iPhone/iPod Touch/iPad platforms.
Attached here there's a patch for torsocks to build it with the iPhone
Open Toolchain. The patch is very dirty so I'm looking for suggestions
to clean it before (I hope!) an eventual inclusion.
Basically, the iPhone OS is a stripped down version of OS X. The first
step needed, is to identify that we're running a cross or native build
for such platform: I'm using
__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ which is not very elegant
but, at least, it's the only define I've found with an "IPHONE" string
in it.
This platform defines both __APPLE__ and __darwin__, unfortunately we
can't use _NONSTD_SOURCE, so I skip the define as if we're running on 64bit.
Last, the core libraries are much simpler: the UNIX2003, NOCANCEL and
DARWIN_EXTSN variants do not exist, so I skipped involved code blocks.
In doing this I used the "#if (defined(__APPLE__) ||
defined(__darwin__)) &amp;&amp;
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)" switch, if
someone could refresh me operators precedence I could remove a couple of
brackets :-P

Ciao!
Marco

- -- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkw0T1kACgkQTYvJ9gtgvF9ViwCgw7IQZSyPoiR7WdQGjvvJp6xR
UU8An0tGOtGwhWibfva0bCQDrJy4Uf9h
=CCwZ
-----END PGP SIGNATURE-----

["tsocks.iphone.diff" (text/plain)]

diff -Naur torsocks-201006201219.orig/src/tsocks.c torsocks-201006201219/src/tsocks.c
--- torsocks-201006201219.orig/src/tsocks.c	2010-07-06 10:37:06.000000000 +0200
+++ torsocks-201006201219/src/tsocks.c	2010-07-07 10:43:40.770849533 +0200
@@ -60,7 +60,8 @@
      is always on (the _DARWIN_FEATURE_UNIX_CONFORMANCE macro will also be defined \
to the SUS conformance  level).  Defining _NONSTD_SOURCE will cause a compilation \
                error.
 */
-#if !defined(__LP64__)
+/*Don't set _NONSTD_SOURCE when building for iPhoneOS*/
+#if !defined(__LP64__) &amp;&amp; !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
 #define _NONSTD_SOURCE 1
 #endif
 #include &lt;sys/socket.h&gt;
@@ -117,7 +118,7 @@
 static struct hostent *(*realgetipnodebyname)(GETIPNODEBYNAME_SIGNATURE);
 static ssize_t (*realsendto)(SENDTO_SIGNATURE);
 static ssize_t (*realsendmsg)(SENDMSG_SIGNATURE);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  static ssize_t \
(*realsendto_unix2003)(SENDTO_SIGNATURE);  static ssize_t \
(*realsendto_nocancel)(SENDTO_SIGNATURE);  static ssize_t \
(*realsendmsg_unix2003)(SENDMSG_SIGNATURE); @@ -129,7 +130,7 @@
 static int (*realpoll)(POLL_SIGNATURE);
 int (*realclose)(CLOSE_SIGNATURE);
 static int (*realgetpeername)(GETPEERNAME_SIGNATURE);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  static int \
(*realconnect_unix2003)(CONNECT_SIGNATURE);  static int \
(*realconnect_nocancel)(CONNECT_SIGNATURE);  static int \
(*realselect_darwinextsn)(SELECT_SIGNATURE); @@ -156,7 +157,7 @@
 int poll(POLL_SIGNATURE);
 int close(CLOSE_SIGNATURE);
 int getpeername(GETPEERNAME_SIGNATURE);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  int \
connect_unix2003(CONNECT_SIGNATURE) __asm("_connect$UNIX2003");  int \
connect_nocancel(CONNECT_SIGNATURE) __asm("_connect$NOCANCEL$UNIX2003");  int \
select_darwinextsn(SELECT_SIGNATURE) __asm("_select$DARWIN_EXTSN"); @@ -184,7 +185,7 \
@@  struct hostent *getipnodebyname(GETIPNODEBYNAME_SIGNATURE);
 ssize_t sendto(SENDTO_SIGNATURE);
 ssize_t sendmsg(SENDMSG_SIGNATURE);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  ssize_t \
sendto_unix2003(SENDTO_SIGNATURE) __asm("_sendto$UNIX2003");  ssize_t \
sendto_nocancel(SENDTO_SIGNATURE) __asm("_sendto$NOCANCEL$UNIX2003");  ssize_t \
sendmsg_unix2003(SENDMSG_SIGNATURE) __asm("_sendmsg$UNIX2003"); @@ -269,7 +270,7 @@
 #ifndef USE_OLD_DLSYM
     if ((realconnect = dlsym(RTLD_NEXT, "connect")) == NULL)
       LOAD_ERROR("connect", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realconnect_unix2003 = dlsym(RTLD_NEXT, "connect$UNIX2003")) == NULL)
       LOAD_ERROR("connect$UNIX2003", MSGERR);
     if ((realconnect_nocancel = dlsym(RTLD_NEXT, "connect$NOCANCEL$UNIX2003")) == \
NULL) @@ -278,7 +279,7 @@
 
     if ((realselect = dlsym(RTLD_NEXT, "select")) == NULL)
       LOAD_ERROR("select", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realselect_darwinextsn = dlsym(RTLD_NEXT, "select$DARWIN_EXTSN")) == NULL)
       LOAD_ERROR("select$DARWIN_EXTSN", MSGERR);
     if ((realselect_darwinextsn_nocancel = dlsym(RTLD_NEXT, \
"select$DARWIN_EXTSN$NOCANCEL")) == NULL) @@ -291,7 +292,7 @@
 
     if ((realpoll = dlsym(RTLD_NEXT, "poll")) == NULL)
       LOAD_ERROR("poll", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  if ((realpoll_unix2003 = \
dlsym(RTLD_NEXT, "poll$UNIX2003")) == NULL)  LOAD_ERROR("poll$UNIX2003", MSGERR);
     if ((realpoll_nocancel = dlsym(RTLD_NEXT, "poll$NOCANCEL$UNIX2003")) == NULL)
@@ -300,7 +301,7 @@
 
     if ((realclose = dlsym(RTLD_NEXT, "close")) == NULL)
       LOAD_ERROR("close", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realclose_unix2003 = dlsym(RTLD_NEXT, "close$UNIX2003")) == NULL)
       LOAD_ERROR("close$UNIX2003", MSGERR);
     if ((realclose_nocancel = dlsym(RTLD_NEXT, "close$NOCANCEL$UNIX2003")) == NULL)
@@ -309,7 +310,7 @@
 
     if ((realgetpeername = dlsym(RTLD_NEXT, "getpeername")) == NULL)
       LOAD_ERROR("getpeername", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realgetpeername_unix2003 = dlsym(RTLD_NEXT, "getpeername$UNIX2003")) == \
NULL)  LOAD_ERROR("getpeername$UNIX2003", MSGERR);
 #endif
@@ -340,7 +341,7 @@
 
     if ((realsendto = dlsym(RTLD_NEXT, "sendto")) == NULL)
       LOAD_ERROR("sendto", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realsendto_unix2003 = dlsym(RTLD_NEXT, "sendto$UNIX2003")) == NULL)
       LOAD_ERROR("sendto$UNIX2003", MSGERR);
     if ((realsendto_nocancel = dlsym(RTLD_NEXT, "sendto$NOCANCEL$UNIX2003")) == \
NULL) @@ -349,7 +350,7 @@
 
     if ((realsendmsg = dlsym(RTLD_NEXT, "sendmsg")) == NULL)
       LOAD_ERROR("sendmsg", MSGERR);
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
                !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)
     if ((realsendmsg_unix2003 = dlsym(RTLD_NEXT, "sendmsg$UNIX2003")) == NULL)
       LOAD_ERROR("sendmsg$UNIX2003", MSGERR);
     if ((realsendmsg_nocancel = dlsym(RTLD_NEXT, "sendmsg$NOCANCEL$UNIX2003")) == \
NULL) @@ -453,7 +454,7 @@
     return tsocks_connect_guts(__fd, __addr, __len, real ## funcname); \
   }
 PATCH_CONNECT(connect, "connect")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  \
PATCH_CONNECT(connect_unix2003, "conncect$UNIX2003")  PATCH_CONNECT(connect_nocancel, \
"conncect$NOCANCEL$UNIX2003")  #endif
@@ -468,7 +469,7 @@
     return tsocks_close_guts(fd, real ## funcname); \
   }
 PATCH_CLOSE(close, "close")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  PATCH_CLOSE(close_unix2003, \
"close$UNIX2003")  PATCH_CLOSE(close_nocancel, "close$NOCANCEL$UNIX2003")
 #endif
@@ -483,7 +484,7 @@
     return tsocks_select_guts(n, readfds, writefds, exceptfds, timeout, real ## \
funcname); \  }
 PATCH_SELECT(select, "select")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  \
PATCH_SELECT(select_darwinextsn, "select$DARWIN_EXTSN")  \
PATCH_SELECT(select_darwinextsn_nocancel, "select$DARWIN_EXTSN$NOCANCEL")  \
PATCH_SELECT(select_unix2003, "select$UNIX2003") @@ -500,7 +501,7 @@
     return tsocks_poll_guts(ufds, nfds, timeout, real ## funcname); \
   }
 PATCH_POLL(poll, "poll")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  PATCH_POLL(poll_unix2003, \
"poll$UNIX2003")  PATCH_POLL(poll_nocancel, "poll$NOCANCEL$UNIX2003")
 #endif
@@ -515,7 +516,7 @@
     return tsocks_getpeername_guts(__fd, __name, __namelen, real ## funcname); \
   }
 PATCH_GETPEERNAME(getpeername, "getpeername")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  \
PATCH_GETPEERNAME(getpeername_unix2003, "getpeername$UNIX2003")  #endif
 
@@ -529,7 +530,7 @@
     return tsocks_sendto_guts(s, buf, len, flags, to, tolen, real ## funcname); \
   }
 PATCH_SENDTO(sendto, "sendto")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  \
PATCH_SENDTO(sendto_unix2003, "sendto$UNIX2003")  PATCH_SENDTO(sendto_nocancel, \
"sendto$NOCANCEL$UNIX2003")  #endif
@@ -544,7 +545,7 @@
     return tsocks_sendmsg_guts(s, msg, flags, real ## funcname); \
   }
 PATCH_SENDMSG(sendmsg, "sendmsg")
-#if defined(__APPLE__) || defined(__darwin__)
+#if (defined(__APPLE__) || defined(__darwin__)) &amp;&amp; \
!defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)  \
PATCH_SENDMSG(sendmsg_unix2003, "sendmsg$UNIX2003")  PATCH_SENDMSG(sendmsg_nocancel, \
"sendmsg$NOCANCEL$UNIX2003")  #endif


["tsocks.iphone.diff.sig" (application/octet-stream)]

</body></email><email><emailId>20100707134611</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-07-07 13:46:11-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

Marco,

Exciting work on this. I am your alter-ego on the Android port of Tor.

I am curious what about Tor requires the device to be jailbroken? Does
the new psuedo-multitasking/threading/app'ing change any of that?

In addition, have you thought about doing a combined Tor+Webkit browser
app all-in-one such that the Tor proxy doesn't have to run in the
background perse?

Best,
  Nathan

On 7/7/10 5:56 AM, Marco Bonetti wrote:
&gt; Hi all,
&gt; my name is Marco, I'm currently keeping a working port of Tor for the
&gt; (jailbroken) iPhone/iPod Touch/iPad platforms.
&gt; Attached here there's a patch for torsocks to build it with the iPhone
&gt; Open Toolchain. The patch is very dirty so I'm looking for suggestions
&gt; to clean it before (I hope!) an eventual inclusion.
&gt; Basically, the iPhone OS is a stripped down version of OS X. The first
&gt; step needed, is to identify that we're running a cross or native build
&gt; for such platform: I'm using
&gt; __ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ which is not very elegant
&gt; but, at least, it's the only define I've found with an "IPHONE" string
&gt; in it.
&gt; This platform defines both __APPLE__ and __darwin__, unfortunately we
&gt; can't use _NONSTD_SOURCE, so I skip the define as if we're running on 64bit.
&gt; Last, the core libraries are much simpler: the UNIX2003, NOCANCEL and
&gt; DARWIN_EXTSN variants do not exist, so I skipped involved code blocks.
&gt; In doing this I used the "#if (defined(__APPLE__) ||
&gt; defined(__darwin__)) &amp;&amp;
&gt; !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)" switch, if
&gt; someone could refresh me operators precedence I could remove a couple of
&gt; brackets :-P
&gt; 
&gt; Ciao!
&gt; Marco
&gt; 
&gt; --
&gt; Marco Bonetti
&gt; Tor research and other stuff: http://sid77.slackware.it/
&gt; Slackintosh Linux Project Developer: http://workaround.ch/
&gt; Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/
&gt; 
&gt; My GnuPG key id: 0x0B60BC5F
</body></email><email><emailId>201007071346110</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2010-07-07 13:46:11-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

Marco,

Exciting work on this. I am your alter-ego on the Android port of Tor.

I am curious what about Tor requires the device to be jailbroken? Does
the new psuedo-multitasking/threading/app'ing change any of that?

In addition, have you thought about doing a combined Tor+Webkit browser
app all-in-one such that the Tor proxy doesn't have to run in the
background perse?

Best,
  Nathan

On 7/7/10 5:56 AM, Marco Bonetti wrote:
&gt; Hi all,
&gt; my name is Marco, I'm currently keeping a working port of Tor for the
&gt; (jailbroken) iPhone/iPod Touch/iPad platforms.
&gt; Attached here there's a patch for torsocks to build it with the iPhone
&gt; Open Toolchain. The patch is very dirty so I'm looking for suggestions
&gt; to clean it before (I hope!) an eventual inclusion.
&gt; Basically, the iPhone OS is a stripped down version of OS X. The first
&gt; step needed, is to identify that we're running a cross or native build
&gt; for such platform: I'm using
&gt; __ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ which is not very elegant
&gt; but, at least, it's the only define I've found with an "IPHONE" string
&gt; in it.
&gt; This platform defines both __APPLE__ and __darwin__, unfortunately we
&gt; can't use _NONSTD_SOURCE, so I skip the define as if we're running on 64bit.
&gt; Last, the core libraries are much simpler: the UNIX2003, NOCANCEL and
&gt; DARWIN_EXTSN variants do not exist, so I skipped involved code blocks.
&gt; In doing this I used the "#if (defined(__APPLE__) ||
&gt; defined(__darwin__)) &amp;&amp;
&gt; !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)" switch, if
&gt; someone could refresh me operators precedence I could remove a couple of
&gt; brackets :-P
&gt; 
&gt; Ciao!
&gt; Marco
&gt; 
&gt; --
&gt; Marco Bonetti
&gt; Tor research and other stuff: http://sid77.slackware.it/
&gt; Slackintosh Linux Project Developer: http://workaround.ch/
&gt; Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/
&gt; 
&gt; My GnuPG key id: 0x0B60BC5F
</body></email><email><emailId>20100707135848</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2010-07-07 13:58:48-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 07/07/2010 03:46 PM, Nathan Freitas wrote:
&gt; Exciting work on this.
Thanks!

&gt; I am your alter-ego on the Android port of Tor.
Cool :)

&gt; I am curious what about Tor requires the device to be jailbroken? Does
&gt; the new psuedo-multitasking/threading/app'ing change any of that?
Naaah, "just" freedom of use: I do not own an Intel Mac and I'm doing
all my porting using the open toolchain on Slackware, that's all.
This does not mean it's easier than using the official SDK but running
on jailbroken devices will give you more freedom in what you're allowed
to do on those machine (real background processes, no need to send the
traffic updates to apple servers and so on...).

&gt; In addition, have you thought about doing a combined Tor+Webkit browser
&gt; app all-in-one such that the Tor proxy doesn't have to run in the
&gt; background perse?
It would be wonderful and it will also be eligible for inclusion in the
AppStore but, well, it's a bit over my experience: I really enjoy
porting stuff over to different architectures and operating systems but
I'm not for pure development.

- -- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkw0iBgACgkQTYvJ9gtgvF8ougCfZyRCM4sAjpFgUmTk9CfDYJmy
BakAn1NYXW2ZZm81G4fhf+8z0ZRpCky4
=OaFZ
-----END PGP SIGNATURE-----
</body></email><email><emailId>20100724155931</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-24 15:59:31-0400</timestampReceived><subject>CircuitBuildTimeout Management and the Pareto Distribution</subject><body>

I was wondering if the new CircuitBuildTimeout management code in the 
0.2.2.14 release renders the pareto distribution code redundant in a sense ?
It seems there is now, in that new code, a distorting effect on the 
normal distribution of circuits that are built ?
-- 

With kind regards,
Cav Edwards

</body></email><email><emailId>20100724174358</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-07-24 17:43:58-0400</timestampReceived><subject>Re: CircuitBuildTimeout Management and the Pareto Distribution</subject><body>


Thus spake Cav (cav@gotadsl.co.uk):

&gt; I was wondering if the new CircuitBuildTimeout management code in the 
&gt; 0.2.2.14 release renders the pareto distribution code redundant in a sense ?
&gt; It seems there is now, in that new code, a distorting effect on the 
&gt; normal distribution of circuits that are built ?

I'm not 100% sure what you mean here. We are still using the pareto
distribution. In fact, we're using it more correctly than before, in
that instead of generating "synthetic" values for circuits that time
out, we allow circuits to continue to build until the 95th percentile
on the pareto curve (but do not use them). Circuits that take an
amount of time to build that is beyond the 95th percentile on the
curve get counted as "censored" values for a "right-censored" Pareto
estimator. 

This is documented in greater detail in path-spec.txt section 2.4.

The end result is that we expect to allow the fastest 80% of circuits
to be used for tor traffic. In practice we actually get pretty darn
close to this for my experimental setup and on the real network.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100724203653</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2010-07-24 20:36:53-0400</timestampReceived><subject>Re: CircuitBuildTimeout Management and the Pareto Distribution</subject><body>

Hi Mike,

Thanks for a quick reply. Maybe its my warped mind that had me consider 
that the management of timeouts (sliding the timeout up and down - as it 
appears in the logs) would affect the distribution of timeouts and 
therefore the pareto distribution around them.

I will admit to experimenting with smaller values of 
CBT_DEFAULT_QUANTILE_CUTOFF. These lead to 'peaks' in the timeout 
distribution. The smaller the value, the tighter these 'peaks' seem to be.

I assumed from this that as the timeout is moved up and time from the 
management code, that these islands of circuit build timeouts would 
appear around the current timeout values.

I admit this could be conjecture and speculation, apart from the build 
timeouts I see in the state file.

With kind regards,
Cav Edwards



Mike Perry wrote:
&gt; Thus spake Cav (cav@gotadsl.co.uk):
&gt;
&gt;   
&gt;&gt; I was wondering if the new CircuitBuildTimeout management code in the 
&gt;&gt; 0.2.2.14 release renders the pareto distribution code redundant in a sense ?
&gt;&gt; It seems there is now, in that new code, a distorting effect on the 
&gt;&gt; normal distribution of circuits that are built ?
&gt;&gt;     
&gt;
&gt; I'm not 100% sure what you mean here. We are still using the pareto
&gt; distribution. In fact, we're using it more correctly than before, in
&gt; that instead of generating "synthetic" values for circuits that time
&gt; out, we allow circuits to continue to build until the 95th percentile
&gt; on the pareto curve (but do not use them). Circuits that take an
&gt; amount of time to build that is beyond the 95th percentile on the
&gt; curve get counted as "censored" values for a "right-censored" Pareto
&gt; estimator. 
&gt;
&gt; This is documented in greater detail in path-spec.txt section 2.4.
&gt;
&gt; The end result is that we expect to allow the fastest 80% of circuits
&gt; to be used for tor traffic. In practice we actually get pretty darn
&gt; close to this for my experimental setup and on the real network.
&gt;
&gt;   

[Attachment #3 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
Hi Mike,&lt;br&gt;
&lt;br&gt;
Thanks for a quick reply. Maybe its my warped mind that had me consider
that the management of timeouts (sliding the timeout up and down - as
it appears in the logs) would affect the distribution of timeouts and
therefore the pareto distribution around them.&lt;br&gt;
&lt;br&gt;
I will admit to experimenting with smaller values of
CBT_DEFAULT_QUANTILE_CUTOFF. These lead to 'peaks' in the timeout
distribution. The smaller the value, the tighter these 'peaks' seem to
be.&lt;br&gt;
&lt;br&gt;
I assumed from this that as the timeout is moved up and time from the
management code, that these islands of circuit build timeouts would
appear around the current timeout values.&lt;br&gt;
&lt;br&gt;
I admit this could be conjecture and speculation, apart from the build
timeouts I see in the state file.&lt;br&gt;
&lt;div class="moz-signature"&gt;&lt;br&gt;
With kind regards,
&lt;br&gt;
Cav Edwards&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
Mike Perry wrote:
&lt;blockquote cite="mid:20100724174358.GA16798@fscked.org" type="cite"&gt;
  &lt;pre wrap=""&gt;Thus spake Cav (&lt;a class="moz-txt-link-abbreviated" \
href="mailto:cav@gotadsl.co.uk"&gt;cav@gotadsl.co.uk&lt;/a&gt;):

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;I was wondering if the new CircuitBuildTimeout management code in \
the  0.2.2.14 release renders the pareto distribution code redundant in a sense ?
It seems there is now, in that new code, a distorting effect on the 
normal distribution of circuits that are built ?
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
I'm not 100% sure what you mean here. We are still using the pareto
distribution. In fact, we're using it more correctly than before, in
that instead of generating "synthetic" values for circuits that time
out, we allow circuits to continue to build until the 95th percentile
on the pareto curve (but do not use them). Circuits that take an
amount of time to build that is beyond the 95th percentile on the
curve get counted as "censored" values for a "right-censored" Pareto
estimator. 

This is documented in greater detail in path-spec.txt section 2.4.

The end result is that we expect to allow the fastest 80% of circuits
to be used for tor traffic. In practice we actually get pretty darn
close to this for my experimental setup and on the real network.

  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;



</body></email><email><emailId>20100726200406</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2010-07-26 20:04:06-0400</timestampReceived><subject>Re: CircuitBuildTimeout Management and the Pareto Distribution</subject><body>


Thus spake Cav (cav@gotadsl.co.uk):

&gt; Hi Mike,
&gt; 
&gt; Thanks for a quick reply. Maybe its my warped mind that had me consider 
&gt; that the management of timeouts (sliding the timeout up and down - as it 
&gt; appears in the logs) would affect the distribution of timeouts and 
&gt; therefore the pareto distribution around them.
&gt; 
&gt; I will admit to experimenting with smaller values of 
&gt; CBT_DEFAULT_QUANTILE_CUTOFF. These lead to 'peaks' in the timeout 
&gt; distribution. The smaller the value, the tighter these 'peaks' seem to be.

This should not be the case in 0.2.2.14 and above. Changing the
QUANTILE_CUTOFF default should now only govern which circuits you
actually use. Circuits should continue to build until
CBT_DEFAULT_CLOSE_QUANTILE, so the distribution of recorded buildtimes
will be much more insenitive to changes in the timeout value.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20100707174444</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-07-07 17:44:44-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

Hi Marco,

I've pushed this to a new branch 'iphone' in the torsocks git repo so we 
can work on it together.

If you keep your branch on a repo in git hub I should be able to pull from 
it and keep it in line with any changes I make.

Haven't looked at the patch yet, but it certainly applied cleanly!

On Wednesday 07 July 2010 10:56:42 Marco Bonetti wrote:
&gt; Hi all,
&gt; my name is Marco, I'm currently keeping a working port of Tor for the
&gt; (jailbroken) iPhone/iPod Touch/iPad platforms.
&gt; Attached here there's a patch for torsocks to build it with the iPhone
&gt; Open Toolchain. The patch is very dirty so I'm looking for suggestions
&gt; to clean it before (I hope!) an eventual inclusion.
&gt; Basically, the iPhone OS is a stripped down version of OS X. The first
&gt; step needed, is to identify that we're running a cross or native build
&gt; for such platform: I'm using
&gt; __ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ which is not very elegant
&gt; but, at least, it's the only define I've found with an "IPHONE" string
&gt; in it.
&gt; This platform defines both __APPLE__ and __darwin__, unfortunately we
&gt; can't use _NONSTD_SOURCE, so I skip the define as if we're running on
&gt; 64bit. Last, the core libraries are much simpler: the UNIX2003,
&gt; NOCANCEL and DARWIN_EXTSN variants do not exist, so I skipped involved
&gt; code blocks. In doing this I used the "#if (defined(__APPLE__) ||
&gt; defined(__darwin__)) &amp;&amp;
&gt; !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)" switch, if
&gt; someone could refresh me operators precedence I could remove a couple of
&gt; brackets :-P
&gt; 
&gt; Ciao!
&gt; Marco
</body></email><email><emailId>201007071744440</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2010-07-07 17:44:44-0400</timestampReceived><subject>Re: Torsocks patch for iDevices</subject><body>

Hi Marco,

I've pushed this to a new branch 'iphone' in the torsocks git repo so we 
can work on it together.

If you keep your branch on a repo in git hub I should be able to pull from 
it and keep it in line with any changes I make.

Haven't looked at the patch yet, but it certainly applied cleanly!

On Wednesday 07 July 2010 10:56:42 Marco Bonetti wrote:
&gt; Hi all,
&gt; my name is Marco, I'm currently keeping a working port of Tor for the
&gt; (jailbroken) iPhone/iPod Touch/iPad platforms.
&gt; Attached here there's a patch for torsocks to build it with the iPhone
&gt; Open Toolchain. The patch is very dirty so I'm looking for suggestions
&gt; to clean it before (I hope!) an eventual inclusion.
&gt; Basically, the iPhone OS is a stripped down version of OS X. The first
&gt; step needed, is to identify that we're running a cross or native build
&gt; for such platform: I'm using
&gt; __ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__ which is not very elegant
&gt; but, at least, it's the only define I've found with an "IPHONE" string
&gt; in it.
&gt; This platform defines both __APPLE__ and __darwin__, unfortunately we
&gt; can't use _NONSTD_SOURCE, so I skip the define as if we're running on
&gt; 64bit. Last, the core libraries are much simpler: the UNIX2003,
&gt; NOCANCEL and DARWIN_EXTSN variants do not exist, so I skipped involved
&gt; code blocks. In doing this I used the "#if (defined(__APPLE__) ||
&gt; defined(__darwin__)) &amp;&amp;
&gt; !defined(__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__)" switch, if
&gt; someone could refresh me operators precedence I could remove a couple of
&gt; brackets :-P
&gt; 
&gt; Ciao!
&gt; Marco
</body></email></emails>