<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20201116212456</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-11-16 21:24:56-0400</timestampReceived><subject>Re: [tor-dev] tor relay process health data for operators (controlport)</subject><body>

I've put this thread into a new ticket:

"provide relay health prometheus metrics via MetricsPort/MetricsSocket"
https://gitlab.torproject.org/tpo/core/tor/-/issues/40194

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200614181913</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-06-14 18:19:13-0400</timestampReceived><subject>Re: [tor-dev] DNS-over-HTTPS (DOH) in Firefox/Torbrowser</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Georg Koppen:
&gt; nusenu:
&gt;&gt; Hi,
&gt;&gt;
&gt;&gt; since Mozilla did tests [0] on DOH [1] in Firefox I was wondering
&gt;&gt; if Torbrowser developers have put any thought into that as well?
&gt; 
&gt; Actually, the study did not get done yet. The start date is scheduled
&gt; for June 4th, see: https://bugzilla.mozilla.org/show_bug.cgi?id=1446404
&gt; 
&gt; We'll look at the code in the coming weeks when doing our audit for
&gt; ESR60 and we'll follow the Mozilla experiment closely. Right now we
&gt; don't have plans to enable DOH in Tor Browser 8.

Since we are discussing this topic in the "Support for full DNS resolution and DNSSEC validation"
thread, I wanted ask whether there have been any updates on this topic since and how 
you think about making use of DoH in Tor Browser?

I'd be interested to write a design document, but if you see a blocker
then we probably shouldn't be putting any resources into it.
 
kind regards,
nusenu

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200701232914</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-07-01 23:29:14-0400</timestampReceived><subject>Re: [tor-dev] DNS-over-HTTPS (DOH) in Firefox/Torbrowser</subject><body>

On Sun, Jun 14, 2020 at 08:19:13PM +0200, nusenu wrote:
&gt; Georg Koppen:
&gt; &gt; nusenu:
&gt; &gt;&gt; Hi,
&gt; &gt;&gt;
&gt; &gt;&gt; since Mozilla did tests [0] on DOH [1] in Firefox I was wondering
&gt; &gt;&gt; if Torbrowser developers have put any thought into that as well?
&gt; &gt; 
&gt; &gt; Actually, the study did not get done yet. The start date is scheduled
&gt; &gt; for June 4th, see: https://bugzilla.mozilla.org/show_bug.cgi?id=1446404
&gt; &gt; 
&gt; &gt; We'll look at the code in the coming weeks when doing our audit for
&gt; &gt; ESR60 and we'll follow the Mozilla experiment closely. Right now we
&gt; &gt; don't have plans to enable DOH in Tor Browser 8.
&gt; 
&gt; Since we are discussing this topic in the "Support for full DNS resolution and DNSSEC validation"
&gt; thread, I wanted ask whether there have been any updates on this topic since and how 
&gt; you think about making use of DoH in Tor Browser?

Sorry for the delay. The short answer is "we aren't planning on making
any use of DoH in Tor Browser".

&gt; 
&gt; I'd be interested to write a design document, but if you see a blocker
&gt; then we probably shouldn't be putting any resources into it.

The (slightly) longer answer is that, at face value, there are many
seemingly obvious disadvantages to Tor Browser using DoH for DNS
resolution and there aren't many advantages. I didn't follow the DNSSEC
thread, but I just skimmed it, so I apologize if I reiterate some
already mentioned points.

Using DoH has the same disadvantages as the tor client sending its own
DNSSEC query (instead of letting the exit relay perform the resolution).
I see Roger mentioned the concern about additional latency and
round-trips, so I won't restate that.

Your comment about achieving hostname-confidentiality is interesting,
but (as with most arguments about ESNI+DoH) this assumes/requires
multi-tenant service providers (and centralization, in general). We can
get a similar outcome by including a list of providers that support
domain fronting and Tor Browser doing some intelligent substitution in
the TLS handshake. This would be very hacky, though.

The main concern I have is that DoH is not fit for Tor's purposes.
Instead of trying to re-use a new level of abstraction, we can get a lot
of the same benefits by improve the adoption and usability of onion
services.

With all of this being said, I am curious to see measurement results
that compare connection times where a) the exit relay handles the DNS
resolution, and b) where Tor Browser uses a DoH server and then requests
a connection to a raw IP address.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200307223600</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-03-07 22:36:00-0400</timestampReceived><subject>Re: [tor-dev] Lets give every circuit its own exit IP?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Would it help to write a short proposal to move this forward?

Would there be someone to actually implement it?

According to nickm:
"This wouldn't be too hard, actually." [1]

As more platforms (i.e. youtube) are more strictly blocking IPs with bad
reputation this would be a crucial feature to make the internet more accessible
to Tor users.

thanks,
nusenu

[1] https://trac.torproject.org/projects/tor/ticket/3847#comment:6

 

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200307231157</emailId><senderName>Mirimir</senderName><senderEmail>mirimir@riseup.net</senderEmail><timestampReceived>2020-03-07 23:11:57-0400</timestampReceived><subject>Re: [tor-dev] Lets give every circuit its own exit IP?</subject><body>

On 03/07/2020 03:36 PM, nusenu wrote:
&gt; Would it help to write a short proposal to move this forward?
&gt; 
&gt; Would there be someone to actually implement it?
&gt; 
&gt; According to nickm:
&gt; "This wouldn't be too hard, actually." [1]
&gt; 
&gt; As more platforms (i.e. youtube) are more strictly blocking IPs with bad
&gt; reputation this would be a crucial feature to make the internet more accessible
&gt; to Tor users.
&gt; 
&gt; thanks,
&gt; nusenu
&gt; 
&gt; [1] https://trac.torproject.org/projects/tor/ticket/3847#comment:6

While I have no skills to implement this, it is a damn good idea!

Would these be IPv6 addresses?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200307231500</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-03-07 23:15:00-0400</timestampReceived><subject>Re: [tor-dev] Lets give every circuit its own exit IP?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; While I have no skills to implement this, it is a damn good idea!
&gt; 
&gt; Would these be IPv6 addresses?

As the ticket says, the idea is to support it for IPv4 and IPv6.

In practice big blocks of IPv4 are likely to expensive for most operators
but IPv6 addresses basically don't cost anything.

https://trac.torproject.org/projects/tor/ticket/26646

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200307232120</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2020-03-07 23:21:20-0400</timestampReceived><subject>Re: [tor-dev] Lets give every circuit its own exit IP?</subject><body>

signal NEWNYM exit bucketing - Make circuit isolation isolate exits?
https://trac.torproject.org/projects/tor/ticket/6256
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200318143544</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-18 14:35:44-0400</timestampReceived><subject>Re: [tor-dev] Lets give every circuit its own exit IP?</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

&gt; On 8 Mar 2020, at 08:36, nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt; 
&gt; Would it help to write a short proposal to move this forward?

Yes, proposals help us know what to implement, when we have time.

The proposal can be short, but it needs to describe the feature in
enough detail, that a developer could implement it:
https://gitweb.torproject.org/torspec.git/tree/proposals/001-process.txt#n39

&gt; Would there be someone to actually implement it?

If there's a good proposal, some volunteer or staff member may decide
to implement it, when they have time.

We can also include proposals in grant applications. (It's much harder
to include an idea in a grant application, we don't have enough details.)

Perhaps it might fit into some of our existing anti-censorship grants.
But that's something for the anti-censorship team to decide.
Again, a proposal makes that decision much easier.

&gt; According to nickm:
&gt; "This wouldn't be too hard, actually." [1]
&gt; 
&gt; As more platforms (i.e. youtube) are more strictly blocking IPs with bad
&gt; reputation this would be a crucial feature to make the internet more accessible
&gt; to Tor users.

Yes, I agree.

Unfortunately, there are lots of really useful and important things
we can do. And never enough people to do them.

But a proposal is a good step forward.

&gt; [1] https://trac.torproject.org/projects/tor/ticket/3847#comment:6

T



["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl5yMcAACgkQEP6qDnB1
ZyoNtw//cXNaTDzpOjXNsBADuD8cWN0tqCQ/rwmDKqxAyIduXmqT1Hlfi59bPkeP
Pzt8F8eOD7FqS0PGH0JI/tOXQoSe/VX3IPfLQg8iIbUaVgHRz/5VvJjl0tb9NP6x
N1E1Ldzd1sgc4qhk7jM2KXcA6nfZi+7CpYQFD5RW+RuzemofwYguQhNyERokf5L0
aZ8AyuG0wCmIYDdsslycK84h6yLw/orb+ys/AHayhXE1vbeqQzsSNB2SqLSFcIQG
TlDCCZlK7ScsunZliEjfZmHTvgtumYDz1RtztoVuZAwo4KwiHV4lCqWOfuRpJzWu
rOGjJa0jEJLkV5jiCCmLNx2iCZHUa+xYU9J7oXNA3bfnydiLFAP4ts0RJPx+maL3
kQeNWbOaSInHtUpdMpZwxfBjhv9+zsOzSbo6q2+31iCd+8ikjQn3w5y+ZV+ekcoP
eaA7OoPqIv4/Adew+LNtGKTbAczqjMzIUa3aC6Fad5IookO5ir5D7bV5rLf+gXVP
At3VyDBXgi/36v/FjTIpLEB4Z0W4Nrq69Gs46WoTHl+Rbjs+gVVwd/EUowYbPF5g
njeLWvZ3KTD2zensqJ/rKG7OQ4ISxOTgxLIKUX/RggKOFpwejz89yEQrp0wDF8QY
Yq7IQwMzPIngy+DOvjFGeh3c6hQFb7hLAvToyebcoY3mjs9b8KM=
=K3hg
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200109132514</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-01-09 13:25:14-0400</timestampReceived><subject>[tor-dev] Changes to accessing and using MaxMind's databases</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi!

When trying to update tor's geoip databases the other day I found that
MaxMind's GeoLite2 database is not available for download anymore. The
reason is:

https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-=
using-geolite2-databases/

We do not have a MaxMind account (yet). As of now, we cannot update
tor's geoip files nor the files used by Onionoo.

Should we try to get somebody who knows more about licenses and legal
stuff to review their GeoLite2 EULA and tell us if it's okay for us to
sign up for a MaxMind account? A possible downside would be that whoever
wants to verify that we didn't mess with their database when converting
it to our format would have to sign up for an account, too.

An alternative is to find another, truly open data source than MaxMind
databases (#25542, #26585). However, this could eat up more time than we
currently have available, and we should have something ready in a few
weeks from now. I'm not sure how we would squeeze this into the metrics
team schedule, so we might need help with this.

Thoughts on the two alternatives? What else did I miss?

All the best,
Karsten


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200129140349</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-01-29 14:03:49-0400</timestampReceived><subject>[tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

Here is an initial draft of Proposal 312: Automatic Relay IPv6 Addresses.

This proposal includes:
 * relay auto IPv6 addresses, and
 * relay auto IPv6 ORPorts.

This is the second of 3 proposals:
* Proposal 311: Relay IPv6 Reachability
* Proposal 312: Automatic Relay IPv6 Addresses
* Proposal 313: Relay IPv6 Statistics
(I haven't written the final one yet.)

I also want to make some minor changes to Proposal 306, so that bridge
IPv6 behaviour stays in sync with client IPv6 behaviour. (See section
7 of this proposal for details.)

There is still one TODO item in the proposal, about Tor's current
behaviour. If you know the answer, please let me know.

The full text is included below, and it is also available as a GitHub
pull request:
https://github.com/torproject/torspec/pull/105

The related tickets are #33073 (proposal) and #5940 (implementation):
https://trac.torproject.org/projects/tor/ticket/33073
https://trac.torproject.org/projects/tor/ticket/5940

Please feel free to reply on this list, or via GitHub pull request
comments.

Filename: 312-relay-auto-ipv6-addr.txt
Title: Tor Relays Automatically Find Their IPv6 Address
Author: teor
Created: 28-January-2020
Status: Draft
Ticket: #33073

0. Abstract

   We propose that Tor relays (and bridges) should automatically find their
   IPv6 address, and use it to publish an IPv6 ORPort. For some relays to find
   their IPv6 address, they may need to fetch some directory documents from
   directory authorities over IPv6. (For anonymity reasons, bridges are unable
   to fetch directory documents over IPv6, until clients start to do so.)

1. Introduction

   Tor relays (and bridges) currently find their IPv4 address, and use it as
   their ORPort and DirPort address when publishing their descriptor. But
   relays and bridges do not automatically find their IPv6 address.

   However, relay operators can manually configure an ORPort with an IPv6
   address, and that ORPort is published in their descriptor in an "or-address"
   line (see [Tor Directory Protocol]).

   Many relay operators don't know their relay's IPv4 or IPv6 addresses. So
   they rely on Tor's IPv4 auto-detection, and don't configure an IPv6
   address. When operators do configure an IPv6 address, it's easy for them to
   make mistakes. IPv6 ORPort issues are a significant source of relay
   operator support requests.

   Implementing IPv6 address auto-detection, and IPv6 ORPort reachability
   checks (see [Proposal 311: Relay IPv6 Reachability]) will increase the
   number of working IPv6-capable relays in the tor network.

2. Scope

   This proposal modifies Tor's behaviour as follows:

   Relays, bridges, and directory authorities:
     * automatically find their IPv6 address, and
     * for consistency between IPv4 and IPv6 detection:
       * start using IPv4 ORPort and DirPort for IPv4 address detection, and
       * re-order IPv4 address detection methods.

   Relays and directory authorities (but not bridges):
     * fetch some directory documents over IPv6.
   For anonymity reasons, bridges are unable to fetch directory documents over
   IPv6, until clients start to do so. (See
   [Proposal 306: Client Auto IPv6 Connections].)

   This proposal makes a small, optional change to existing client behaviour:
     * clients also check IPv6 addresses when rotating TLS keys for new
       networks.
   In addition to the changes to IPv4 address resolution, most of which won't
   affect clients. (Because they do not set Address, ORPort, or DirPort.)

   Throughout this proposal, "relays" includes directory authorities, except
   where they are specifically excluded. "relays" does not include bridges,
   except where they are specifically included. (The first mention of "relays"
   in each section should specifically exclude or include these other roles.)

   When this proposal describes Tor's current behaviour, it covers all
   supported Tor versions (0.3.5.7 to 0.4.2.5), as of January 2020, except
   where another version is specifically mentioned.

3. Finding Relay IPv6 Addresses

   We propose that tor relays (and bridges) automatically find their IPv6
   address, and use it to publish an IPv6 ORPort.

   For some relays to find their IPv6 address, they may need to fetch some
   directory documents from directory authorities over IPv6. (For anonymity
   reasons, bridges are unable to fetch directory documents over IPv6, until
   clients start to do so.)

3.1. Current Relay IPv4 Address Implementation

   Currently, all relays (and bridges) must have an IPv4 address. IPv6
   addresses are optional for relays.

   Tor currently tries to find relay IPv4 addresses in this order:
     1. the Address torrc option
     2. the address of the hostname (resolved using DNS, if needed)
     3. a local interface address
        (by making a self-connected socket, if needed)
     4. an address reported by a directory server (using X-Your-Address-Is)

   When using the Address option, or the hostname, tor supports:
     * an IPv4 address literal, or
     * resolving an IPv4 address from a hostname.

   If tor is running on the public network, and an address isn't globally
   routable, tor ignores it. (If it was explicitly set in Address, tor logs an
   error.)

   If there are multiple valid addresses, tor chooses:
     * the first address returned by the resolver,
     * the first address returned by the local interface API, or
     * the latest address returned by a directory server.

3.2. Finding Relay IPv6 Addresses

   We propose that relays (and bridges) try to find their IPv6 address. For
   consistency, we also propose to change the address resolution order for
   IPv4 addresses.

   We use the following general principles to choose the order of IP address
   methods:
     * Explicit is better than Implicit,
     * Local Information is better than a Remote Dependency,
     * Trusted is better than Untrusted, and
     * Reliable is better than Unreliable.
   Within these constraints, we try to find the simplest working design.

   Therefore, we propose that tor tries to find relay IPv4 and IPv6 addresses
   in this order:
     1. the Address torrc option
     2. the advertised ORPort address
     3. the advertised DirPort address (IPv4 only; relays, not bridges)
     4. a local interface address
        (by making a self-connected socket, if needed)
     5. the address of the host's own hostname (resolved using DNS, if needed)
     6. an address reported by a directory server (using X-Your-Address-Is)

   (Each of these address resolution steps is described in more detail, in its
   own subsection.)

   While making these changes, we want to preserve tor's existing behaviour:
     * resolve Address using the local resolver, if needed,
     * ignore private addresses on public tor networks, and
     * when there are multiple valid addresses, choose the first or latest
       address, as appropriate.

3.2.1. Make the Address torrc Option Support IPv6

   First, we propose that relays (and bridges) use the Address torrc option
   to find their IPv4 and IPv6 addresses.

   There are two cases we need to cover:

     1. Explicit IP addresses:
        * allow the option to be specified up to two times,
        * use the IPv4 address for IPv4,
        * use the IPv6 address for IPv6.
        Configuring two addresses in the same address family is a config error.

     2. Hostnames / DNS names:
        * allow the option to be specified up to two times,
        * look up the configured name,
        * use the first IPv4 and IPv6 address returned by the resolver, and
        Resolving multiple addresses in the same address family is not a
        runtime error, but only the first address from each family will be
        used.

   These lookups should ignore private addresses on public tor networks. If
   multiple IPv4 or IPv6 addresses are returned, the first public address from
   each family should be used.

   We should also support the following combinations:
     A. IPv4 Address / hostname (for IPv6 only),
     B. IPv6 Address / hostname (for IPv4 only),
     C. IPv4 Address only / try to guess IPv6, then check its reachability
        (see section 4.3.1 in [Proposal 311: Relay IPv6 Reachability]), and
     D. IPv6 Address only / guess IPv4, then its reachability must succeed.
   There are also similar configurations where a hostname is configured, but it
   only provides IPv4 or IPv6 addresses.

   Combination C is the most common legacy configuration. We want to
   support the following outcomes for legacy configurations:
     * automatic upgrades to guessed and reachable IPv6 addresses,
     * continuing to operate on IPv4 when the IPv6 address can't be guessed,
       and
     * continuing to operate on IPv4 when the IPv6 address has been guessed,
       but it is unreachable.

   At this time, we do not propose guessing multiple IPv4 or IPv6 addresses
   and testing their reachability (see section 3.4.2).

   It is an error to configure an Address option with a private IPv4 or IPv6
   address, or with a hostname that does not resolve to any publicly routable
   IPv4 or IPv6 addresses.

   If the Address option is not configured for IPv4 or IPv6, or the hostname
   lookups do not provide both IPv4 and IPv6 addresses, address resolution
   should go to the next step.

3.2.2. Use the Advertised ORPort IPv4 and IPv6 Addresses

   Next, we propose that relays (and bridges) use the first advertised ORPort
   IPv4 and IPv6 addresses, as configured in their torrc.

   The ORPort address may be a hostname. If it is, tor should try to use it to
   resolve an IPv4 and IPv6 address, and open ORPorts on the first available
   IPv4 and IPv6 address. Tor should respect the IPv4Only and IPv6Only port
   flags, if specified. (Tor currently resolves IPv4 addresses in ORPort
   lines. It may not look for an IPv6 address.)

   Relays (and bridges) currently use the first advertised ORPort IPv6 address
   as their IPv6 address. We propose to use the first advertised IPv4 ORPort
   address in a similar way, for consistency.

   Therefore, this change may affect existing relay IPv4 addressses. We expect
   that a small number of relays may change IPv4 address, from a guessed IPv4
   address, to their first advertised IPv4 ORPort address.

   In rare cases, relays may have been using non-advertised ORPorts for their
   addresses. This change may also change their addresses.

   We propose ignoring private configured ORPort addresses on public tor
   networks. (Binding to private ORPort addresses is supported, even on public
   tor networks, for relays that use NAT to reach the Internet.) If an ORPort
   address is private, address resolution should go to the next step.

3.2.3. Use the Advertised DirPort IPv4 Address

   Next, we propose that relays use the first advertised DirPort IPv4 address,
   as configured in their torrc.

   The following DirPort configurations can not be used for address
   resolution, because they are not supported:
     * bridge DirPorts, and
     * advertised IPv6 DirPorts.

   The DirPort address may be a hostname. If it is, tor should try to use it to
   resolve an IPv4 address, and open a DirPort on the first available IPv4
   address. Tor should only look for IPv6 addresses if the IPv6Only port flag
   is specified. (Since advertised IPv6 DirPorts are not supported, a
   working configuration may also require the NoAdvertise flag.)

   Relays currently use the first advertised ORPort IPv6 address as their IPv6
   address. We propose to use the first advertised IPv4 DirPort address in a
   similar way, for consistency.

   Therefore, this change may affect existing relay IPv4 addressses. We expect
   that a very small number of relays may change IPv4 address, from a guessed
   IPv4 address, to their first advertised IPv4 DirPort address. (But we expect
   that most relays that change will be using their ORPort address.)

   We propose ignoring private configured DirPort addresses on public relays.
   (Binding to private DirPort addresses is supported, for networks that use
   NAT.) If a DirPort address is private, address resolution should go to the
   next step.

3.2.4. Use Local Interface IPv6 Address

   Next, we propose that relays (and bridges) use publicly routable addresses
   from the OS interface addresses or routing table, as their IPv4 and IPv6
   addresses.

   Tor has local interface address resolution functions, which support most
   major OSes. Tor uses these functions to guess its IPv4 address. We propose
   using them to also guess tor's IPv6 address.

   We also propose modifying the address resolution order, so interface
   addresses are used before the local hostname. This decision is based
   on our principles: interface addresses are local, trusted, and reliable;
   hostname lookups may be remote, untrusted, and unreliable.

   Some developer documentation also recommends using interface addresses,
   rather than resolving the host's own hostname. For example, on recent
   versions of macOS, the man pages tell developers to use interface addresses
   (getifaddrs) rather than look up the host's own hostname (gethostname and
   getaddrinfo). Unfortunately, these man pages don't seem to be available
   online, except for short quotes (see [getaddrinfo man page] for the
   relevant quote).

   If the local interface addresses are unavailable, tor opens a self-connected
   UDP socket to a publicly routable address, but doesn't actually send any
   packets. Instead, it uses the socket APIs to discover the interface address
   for the socket.

   Tor already ignores private IPv4 interface addresses on public relays.
   (Binding to private DirPort addresses is supported, for networks that use
   NAT.) We propose to also ignore private IPv6 interface addresses. If all
   IPv4 or IPv6 interface addresses are private, address resolution should go
   to the next step.

3.2.5. Use Own Hostname IPv6 Addresses

   Next, we propose that relays (and bridges) get their local hostname, look
   up its addresses, and use them as its IPv4 and IPv6 addresses.

   We propose to use the same underlying lookup functions to look up the IPv4
   and IPv6 addresses for:
     * the Address torrc option (see section 3.2.1), and
     * the local hostname.
   However, OS APIs typically only return a single hostname.

   Even though the hostname lookup may use remote DNS, we propose to use it on
   directory authorities, to maintain compatibility with current
   configurations. Even if it is remote, we expect the configured DNS to be
   somewhat trusted by the operator.

   The hostname lookup should ignore private addresses on public relays. If
   multiple IPv4 or IPv6 addresses are returned, the first public address from
   each family should be used. If all IPv4 or IPv6 hostname addresses are
   private, address resolution should go to the next step.

3.2.6. Use Directory Header IPv6 Addresses

   Finally, we propose that relays get their IPv4 and IPv6 addresses from the
   X-Your-Address-Is HTTP header in tor directory documents. To support this
   change, we propose that relays start fetching directory documents over IPv4
   and IPv6.

   We propose that bridges continue to only fetch directory documents over
   IPv4, because they try to imitate clients. (Most clients only fetch
   directory documents over IPv4, a few clients are configured to only fetch
   over IPv6.) When client behaviour changes to use both IPv4 and IPv6 for
   directory fetches, bridge behaviour can also change to match. (See
   section 3.4.1 and [Proposal 306: Client Auto IPv6 Connections].)

   We propose that directory authorities should ignore addresses in directory
   headers. Allowing other authorities (or relays?) to change a directory
   authority's published IP address may lead to security issues. Instead,
   if interface and hostname lookups fail, tor should stop address resolution,
   and return a permanent error. (And issue a log to the operator, see below.)

   We propose to use a simple load balancing scheme for IPv4 and IPv6
   directory requests:
     * choose between IPv4 and IPv6 directory requests at random.

   We do not expect this change to have any load-balancing impact on the public
   tor network, because the number of relays is much smaller than the number
   of clients. However, the 6 directory authorities with IPv6 enabled may see
   slightly more directory load, particularly over IPv6.

   To support this change, tor should also change how it handles IPv6
   directory failures on relays:
     * avoid recording IPv6 directory failures as remote relay failures,
       because they may actually be due to a lack of IPv6 connectivity on the
       local relay, and
     * issue IPv6 directory failure logs at notice level, and rate-limit them
       to one per hour.

   If a relay is:
     * explicitly configured with an IPv6 address, or
     * a publicly routable, reachable IPv6 address is discovered in an
       earlier step,
   tor should start issuing IPv6 directory failure logs at warning level.

   (Alternately, tor could stop doing IPv6 directory requests entirely. But we
   prefer designs where all relays behave in a similar way, regardless of their
   internal state.)

   For some more complex directory load-balancing schemes, see section 3.5.2.

   Tor already ignores private IPv4 addresses in directory headers. We propose
   to also ignore private IPv6 addresses in directory headers. If all IPv4 and
   IPv6 addresses in directory headers are private, address resolution should
   pause, and return a temporary error.

   Whenever address resolution fails, tor should warn the operator to set the
   Address torrc option for IPv4 and IPv6. (If IPv4 is available, and only
   IPv6 is missing, the log should be at notice level.)

   Address resolution should continue the next time tor receives a directory
   header containing a public IPv4 or IPv6 address.

3.2.7. Disabling IPv6 Address Resolution

   Relays that have a reachable IPv6 address, but that address is unsuitable
   for the relay, need to be able to disable IPv6 address resolution.

   Based on [Proposal 311: Relay IPv6 Reachability], and this proposal, those
   relays would:
     * discover their IPv6 address,
     * open an IPv6 ORPort,
     * find it reachable,
     * publish a descriptor containing that IPv6 ORPort,
     * have the directory authorities find it reachable,
     * have it published in the consensus, and
     * have it used by clients.

   Currently, relays are required to have an IPv4 address. So if the guessed
   IPv4 address is unsuitable, operators can set the Address option to a
   suitable IPv4 address. But IPv6 addresses are optional, so relay operators
   may need to disable IPv6 entirely.

   We propose a new torrc-only option, AddressDisableIPv6. This option is set
   to 0 by default. If the option is set to 1, tor disables IPv6 address
   resolution, IPv6 ORPorts, IPv6 reachability checks, and publishing an IPv6
   ORPort in its descriptor.

3.2.8. Automatically Enabling an IPv6 ORPort

   We propose that relays that discover their IPv6 address, should open an
   ORPort on that address, and test its reachability (see
   [Proposal 311: Relay IPv6 Reachability], particularly section 4.3.1).

   The ORPort should be opened on the port configured in the relay's ORPort
   torrc option. Relay operators can use the IPv4Only and IPv6Only options
   to configure different ports for IPv4 and IPv6.

   If both reachability checks succeed, relays should publish their IPv4 and
   IPv6 ORPorts in their descriptor.

   If only the IPv4 ORPort check succeeds, and the IPv6 address was guessed
   (rather than being explicitly configured), then relays should publish their
   IPv4 ORPort in their descriptor.

3.3. Consequential Tor Client Changes

   We do not propose any required client address resolution changes at this
   time.

   However, clients will use the updated address resolution functions to detect
   when they are on a new connection, and therefore need to rotate their TLS
   keys.

   This minor client change allows us to avoid keeping an outdated version of
   the address resolution functions, which is only for client use.

   Clients should skip address resolution steps that don't apply to them, such
   as:
     * the ORPort option,
     * the DirPort option, and
     * the Address option, if it becomes a relay module option.

3.4. Alternative Address Resolution Designs

   We briefly mention some potential address resolution designs, and the
   reasons that they were not used in this proposal.

   (Some designs may be proposed for future Tor versions, but are not necessary
   at this time.)

3.4.1. Future Bridge IPv6 Address Resolution Behaviour

   When clients automatically fetch directory documents via relay IPv4 and
   IPv6 ORPorts by default, bridges should also adopt this dual-stack
   behaviour. (For example, see [Proposal 306: Client Auto IPv6 Connections].)

   When bridges fetch directory documents via IPv6, they will be able to find
   their IPv6 address using directory headers (see 3.2.6).

3.4.2. Guessing Muliple IPv4 or IPv6 Addresses

   We avoid designs which guess (or configure) multiple IPv4 or IPv6
   addresses, test them all for reachability, and choose one that works.

   Using multiple addresses is rare, and the code to handle it is complex. It
   also requires careful design to avoid:
     * conflicts between multiple relays on the same address
       (tor allows up to 2 relays per IPv4 address)
         * flapping / race conditions / address switching
         * rare

3.4.3. Rejected Address Resolution Designs

   We reject designs that try all the different address resolution methods,
   score addresses, and then choose the address with the highest score.

   These designs are a generalisation of designs that try different methods in
   a set order (like this proposal). They are more complex than required.
   Complex designs can confuse operators, particularly when they fail.

   Operators should not need complex address resolution in tor: most relay
   addresses are fixed, or change occasionally. And most relays can reliably
   discover their address using directory headers, if all other methods fail.

   If complex address resolution is required, it can be configured using a
   dynamic DNS name in the Address torrc option, or via the control port.

   We also avoid designs that use any addresses other than the first
   (or latest) valid IPv4 and IPv6 address. These designs are more complex, and
   they don't have clear benefits:
     * sort addresses numerically (avoid address flipping)
     * sort addresses by length, then numerically
       (also minimise consensus size)
     * store a list of previous addresses in the state file, and use the most
       recently used address that's currently available.
   Operators who want to avoid address flipping should set the Address option
   in the torrc. Operators who want to minimise the size of the consensus
   should use all-zero IPv6 host identifiers.

3.5. Optional Efficiency and Reliability Changes

   We propose some optional changes for efficiency and reliability, and
   describe their impact.

   Some of these changes may be more appropriate in future releases, or
   along with other proposed features.

3.5.1. Only Use Authenticated Directory Header IPv4 and IPv6 Addresses

   We propose this optional change, to improve relay address accuracy and
   reliability.

   Relays should only use:
     * authenticated directory fetches,
     * to directory authorities,
   to discover their own IPv4 and IPv6 addresses. (Both changes are optional,
   and they can be made separately.)

   Tor supports authenticated, encrypted directory fetches using BEGINDIR over
   ORPorts (see the [Tor Specification] for details).

   Relays currently fetch unencrypted directory documents over DirPorts. The
   directory document itself is signed, but the HTTP headers are not
   authenticated. (Clients and bridges only fetch directory documents using
   authenticated directory fetches.)

   Using authenticated directory headers for relay addresses:
     * avoids caches (or other machines) mangling X-Your-Address-Is headers in
       transit, and
     * avoids attacks where directories are deliberately given an incorrect IP
       address.

   To make this change, we need to modify two different parts of tor:
     * when making directory requests, relays should fetch some directory
       documents using BEGINDIR over ORPorts, and
     * when using the X-Your-Address-Is HTTP header to guess their own IPv4 or
       IPv6 addresses, relays ignore directory documents that were not fetched
       using BEGINDIR over ORPorts.

   Optionally, relays should also ignore addresses from other relays:
     * when using the X-Your-Address-Is HTTP header to guess their own IPv4 or
       IPv6 addresses, relays ignore directory documents that were not fetched
       from directory authorities.

   Ideally, we would like all relays to do all their directory fetches:
     * using BEGINDIR over ORPorts, and
     * to directory authorities.
   However, this change may be unsustainable during high network load
   (see [Ticket 33018: Dir auths using an unsustainable 400+ mbit/s]).

   Therefore, we propose a simple load-balancing scheme between address
   resolution and non-address resolution requests:
     * when relays do not know their own IP addresses, they should make as many
       address resolution directory fetches as is sustainable, and
     * when relays know their own IP addresses, they should make an occasional
       address resolution directory fetch, to learn if their address has
       changed.

   We use the load-balancing criteria in the next section, to select the ratio
   between:
     * ORPort connections to directory authorities, and
     * DirPort connections to directory mirrors.

3.5.1.1. General Load Balancing Criteria

   We propose the following criteria for choosing load-balancing ratios:

   The selected ratios should be chosen based on the following factors:
     * the current number of directory fetches that a relay makes:
       * when bootstrapping with an empty cache directory, and
       * in a steady state (per hour, or per new consensus),
       (these numbers aren't currently collected by tor, so we may need to
       write some extra code to include them in the heartbeat logs),
     * relays need to discover their IPv4 and IPv6 addresses to bootstrap,
     * it only takes one successful directory fetch from one authority for a
       relay to discover its IP address,
     * BEGINDIR over ORPort requires and TLS connection, and some additional
       tor cryptography, so it is more expensive for authorities than a
       DirPort fetch (and it can not be cached by a HTTP cache),
     * minimising wasted CPU (and bandwidth) on IPv4-only relays, and
     * other potential changes to relay directory fetches (see
       [Ticket 33018: Dir auths using an unsustainable 400+ mbit/s])

   The selected ratios should allow almost all relays to update both their IPv4
   and IPv6 addresses:
     * at least twice when they bootstrap (to allow for fetch failures), and
     * at least once per directory fetch (or per hour).

   In this proposal, relays choose between IPv4 and IPv6 directory fetches
   at random (see section 3.2.6 for more detail). See the next section for
   an alternative load-balancing scheme.

3.5.2. Load Balancing Between IPv4 and IPv6 Directories

   We propose this optional change, to improve the load-balancing between IPv4
   and IPv6 directories, when used by relays to find their IPv4 and IPv6
   addresses (see section 3.2.6).

   This change may only be necessary if the following changes result in poor
   load-balancing, or other relay issues:
     * randomly selecting IPv4 or IPv6 directories (see section 3.2.6), or
     * only using directory headers for addresses when they come from directory
       authorities, via an authenticated connection (see section 3.5.1).

   We propose a new torrc option and consensus parameter:
   MaxNumIPv4DirectoryAttempts. This option limits the number of IPv4 directory
   requests, before the relay makes an IPv6 directory request. It should only
   apply to attempts that are expected to provide a usable IPv4 or IPv6
   address in their directory header. (Based on sections 3.2.6 and 3.5.1.)

   The design is similar to MaxNumIPv4BootstrapAttempts in
   [Proposal 306: Client Auto IPv6 Connections].

   Here is a quick sketch of the design:
    * when MaxNumIPv4DirectoryAttempts is reached, select an IPv6-capable
      directory, and make an IPv6 connection attempt,
    * use a directory authority, or an ORPort, if required (see section 3.5.1),
    * use a default value between 2 and 4:
      * the ideal value for load-balancing is &gt;= 2
        (because 6/9 directory authorities are already on IPv6)
      * the ideal value for minimising failures is ~4
        (because relays won't waste too much CPU or bandwidth)
    * choose the default value based on the load-balancing criteria in section
      3.5.1.1.

   Alternately, we could wait until
   [Proposal 306: Client Auto IPv6 Connections] is implemented, and use the
   directory fetch design from that proposal.

3.5.3. Detailed Address Resolution Logs

   We propose this optional change, to help diagnose relay address resolution
   issues.

   Relays (and bridges) should  log the address chosen using each address
   resolution method, when:
     * address resolution succeeds,
     * address resolution fails,
     * reachability checks fail, or
     * publishing the descriptor fails.
   These logs should be rate-limited separately for successes and failures.

   The logs should tell operators to set the Address torrc option for IPv4 and
   IPv6 (if available).

3.5.4. Add IPv6 Support to is_local_addr()

   We propose this optional change, to improve the accuracy of IPv6 address
   detection from directory documents.

   Directory servers use is_local_addr() to detect if the requesting tor
   instance is on the same local network. If it is, the directory server does
   not include the X-Your-Address-Is HTTP header in directory documents.

   Currently, is_local_addr() checks for:
     * an internal IPv4 or IPv6 address, or
     * the same IPv4 /24 as the directory server.

   We propose also checking for:
     * the same IPv6 /48 as the directory server.

   We choose /48 because it is typically the smallest network in the global
   IPv6 routing tables, and it was previously the recommended per-customer
   network block. (See [RFC 6177: IPv6 End Site Address Assignment].)

   Tor currently uses:
     * IPv4 /8 and IPv6 /16 for port summaries,
     * IPv4 /16 and IPv6 /32 for path selection (avoiding relays in the same
       network block).

3.5.5. Add IPv6 Support to AuthDirMaxServersPerAddr

   We propose this optional change, to improve the health of the network, by
   rejecting too many relays on the same IPv6 address.

   Modify get_possible_sybil_list() so it takes an address family argument,
   and returns a list of IPv4 or IPv6 sybils.

   Use the modified get_possible_sybil_list() to exclude relays from the
   authority's vote, if there are more than AuthDirMaxServersPerAddr on the
   same IPv4 or IPv6 address.

   Since these relay exclusions happen at voting time, they do not require a
   new consensus method.

3.5.6. Use a Local Interface Address on the Default Route

   We propose this optional change, to improve the accuracy of local interface
   IPv4 and IPv6 address detection (see section 3.2.4).

   Rewrite the get_interface_address*() functions to choose an interface
   address on the default route, or to sort default route addresses first in
   the list of addresses. (If the platform API allows us to find the default
   route.)

   For more information, see [Ticket 12377: Prefer default route when checking
   local interface addresses].

   This change may not be necessary, because the directory header IP address
   method will find the IP address of the default route, in most cases
   (see section 3.2.6).

3.5.7. Add IPv6 Support Using gethostbyname2()

   We propose these optional changes, to add IPv6 support to hostname
   resolution on older OSes. These changes affect:
     * the Address torrc option, when it is a hostname (see section 3.2.1),
       and
     * automatic hostname resolution (see section 3.2.5).

   Use gethostbyname2() to add IPv6 support to hostname resolution on older
   OSes, which don't support getaddrinfo().

   But this change may be unnecessary, because:
     * Linux has used getaddrinfo() by default since glibc 2.20 (2014)
     * macOS has recommended getaddrinfo() since before 2006
     * since macOS adopts BSD changes, most BSDs would have switched to
       getaddrinfo() in a similar timeframe
     * Windows has supported getaddrinfo() since Windows Vista; tor's minimum
       supported Windows version is Vista.
   See [Tor Supported Platforms] for more details.

   When looking up hostnames using gethostbyname() or gethostbyname2(), if the
   first address is a private address, we may want to look at the entire list
   of addresses. Some struct hostent versions (example: current macOS) also
   have a h_addr_list rather than h_addr. (They define h_addr as
   h_addr_list[0], for backwards compatibility.)

   However, having private and public addresses resolving from the same
   hostname is a rare configuration, so we may not need to make this change.
   (On OSes that support getaddrinfo(), tor searches the list of addresses for
   a publicly routable address.)

   As an alternative, if we believe that all supported OSes have getaddrinfo(),
   we could simply remove the gethostbyname() code, rather than trying to
   modify it to work with IPv6.

   Most relays can reliably discover their address using directory headers,
   if all other methods fail. Or operators can set the Address torrc option to
   an IPv4 or IPv6 literal.

3.5.8. Change Relay OutboundBindAddress Defaults

   We propose this optional change, to improve the reliability of
   IP address-based filters in tor.

   For example, the tor network treats relay IP addresses differently when:
     * resisting denial of service, and
     * selecting canonical, long-term connections.
   (See [Ticket 33018: Dir auths using an unsustainable 400+ mbit/s] for the
   initial motivation for this change: resisting significant bandwidth load
   on directory authorities.)

   Now that tor knows its own addresses, we propose that relays (and bridges)
   set their IPv4 and IPv6 OutboundBindAddress to these discovered addresses,
   by default. If binding fails, tor should fall back to an unbound socket.

   Operators would still be able to set a custom IPv4 and IPv6
   OutboundBindAddress, if needed.

   Currently, tor doesn't bind to a specific address, unless
   OutboundBindAddress is configured. So on relays with multiple IP addresses,
   the outbound address comes from the chosen route (usually the default
   route).

4. Directory Protocol Specification Changes

   We propose explicitly supporting IPv6 X-Your-Address-Is HTTP headers in the
   tor directory protocol.

   We propose the following changes to the [Tor Directory Protocol]
   specification, in section 6.1:

  Servers MAY include an X-Your-Address-Is: header, whose value is the
  apparent IPv4 or IPv6 address of the client connecting to them. IPv6
  addresses SHOULD/MAY (TODO) be formatted enclosed in square brackets.

  TODO: require brackets? What does Tor currently do?

  For directory connections tunneled over a BEGIN_DIR stream, servers SHOULD
  report the IP from which the circuit carrying the BEGIN_DIR stream reached
  them.

  Servers SHOULD disable caching of multiple network statuses or multiple
  server descriptors.  Servers MAY enable caching of single descriptors,
  single network statuses, the list of all server descriptors, a v1
  directory, or a v1 running routers document, with appropriate expiry times
  (around 30 minutes). Servers SHOULD disable caching of X-Your-Address-Is
  headers.

5. Test Plan

   We provide a quick summary of our testing plans.

5.1. Test Find Relay IPv6 Addresses

   We propose to test these changes using chutney networks. However, chutney
   creates a limited number of configurations, so we also need to test these
   changes with relay operators on the public network.

   Therefore, we propose to test these changes on the public network with a
   small number of relays and bridges.

   Once these changes are merged, volunteer relay and bridge operators will be
   able to test them by:
     * compiling from source,
     * running nightly builds, or
     * running alpha releases.

5.2. Test Existing Features

   We will modify and test these existing features:
     * Find Relay IPv4 Addresses

   We do not plan on modifying these existing features:
     * relay address retries
     * existing warning logs
   But we will test that they continue to function correctly, and fix any bugs
   triggered by the modifications in this proposal.

6. Ongoing Monitoring

   To monitor the impact of these changes, relays should collect basic IPv4
   and IPv6 connection and bandwidth statistics (see [Proposal 313: Relay IPv6
   Statistics]).

   We may also collect separate statistics on connections from:
     * clients (and bridges, because they act like clients), and
     * other relays (and authorities, because they act like relays).

   Some of these statistics may be included in tor's heartbeat logs, making
   them accessible to relay operators.

   We do not propose to collect additional statistics on:
     * bridges,
     * address resolution,
     * circuit counts, or
     * failure rates.
   Collecting statistics like these could impact user privacy, or relay
   security.

7. Changes to Other Proposals

   [Proposal 306: Client Auto IPv6 Connections] needs to be modified to keep
   bridge IPv6 behaviour in sync with client IPv6 behaviour. (See section
   3.2.6.)

References:

[getaddrinfo man page]: See the quoted section in \
https://stackoverflow.com/a/42351676

[Proposal 306: Client Auto IPv6 Connections]: One possible design for automatic \
client IPv4 and IPv6 connections is at \
https://gitweb.torproject.org/torspec.git/tree/proposals/306-ipv6-happy-eyeballs.txt \
(TODO: modify to include bridge changes with client changes)

[Proposal 311: Relay IPv6 Reachability]: \
https://gitweb.torproject.org/torspec.git/tree/proposals/311-relay-ipv6-reachability.txt


[Proposal 313: Relay IPv6 Statistics]: \
https://gitweb.torproject.org/torspec.git/tree/proposals/313-relay-ipv6-stats.txt \
(TODO)

[RFC 6177: IPv6 End Site Address Assignment]: \
https://tools.ietf.org/html/rfc6177#page-7

[Ticket 12377: Prefer default route when checking local interface addresses]: \
https://trac.torproject.org/projects/tor/ticket/12377

[Ticket 33018: Dir auths using an unsustainable 400+ mbit/s]: \
https://trac.torproject.org/projects/tor/ticket/33018

[Tor Directory Protocol]: (version 3) \
https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt

[Tor Specification]: https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt

[Tor Supported Platforms]: \
https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/SupportedPlatforms#OSSupportlevels


(End)


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl4xkMUACgkQEP6qDnB1
Zyqlyg/9FAxdF4dPMfFjA5PlAxaJy7VLXywU5Vsawtbf+K3swIn8pVTzu1D9Q3yI
cH2jbDgWKolAeelllreBxVoDFc+VKO0YlRceqA68XMmDOTZShmIimXgtMZRA00ki
s6H7spRqCbvMjYgjcl8PlcNADEMQ3y8ILAVyqTT7VfUCrWYWpBsrna37GKVkF+/c
QgAknhhWEiNg059/gfDan0woEXRBQHcX9lpwPsTKjfeAUE7MlKc5Zs0+cLIN7FOg
Q2sehBAZzsLcgF2INsQo7WF4FbIF55bYIrXTZyUotIwkQ+gqM3OuRYpaYhEmfZhY
b3RaEAvUzUjf3IEa2Dsd6I0f/+CPimJK9F4Rt/c0oUOMXBxGIbikDXPduaea+jO/
wgB7YmbgiVj/yEyyaaQIaNzYTTrKL9YyC1FYh0SmCRI21hQCYtRdqPHiALTawtXF
s5UNiVTxj71cjLde49KSiNAbGxRlofyq2mSAIbtPbQH8SAFQCR83TdbK2VTCJQ7l
8h+45rotHZCtdJoOT0Nao34L3czbixRBxQitmcMsQ69H+HyhOukIqyIKLwejRx8M
XlFdHZOKpAZWT/I2DHa+pT/RNAtHpEpnX5EIc0m2lyEl8nuL6JphZqhnqcZZ7RsP
nltoBzq50O9TE/QuqqqDLi3i5jnySWtpIF4nA/21aF8trxks38U=
=uvT9
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200302053221</emailId><senderName>Aman Rastogi</senderName><senderEmail>arastogi2810@gmail.com</senderEmail><timestampReceived>2020-03-02 05:32:21-0400</timestampReceived><subject>[tor-dev] Regarding GSoC 2020</subject><body>

[Attachment #2 (multipart/alternative)]


Respected Developers,
   I am Aman, GSoC 2020 aspirant, and i would like to work for Torr. I am
interested in "Privacy Friendly Web" and "OONI Explorer Advanced Search".

   Can I get some guidance, please?

   Thanking you, and sorry for such an informal mail.

-- 
Aman

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Respected Developers,&lt;div&gt;&lt;div&gt;     I am Aman, GSoC 2020 aspirant, and \
i would like to work for Torr. I am interested  in "Privacy Friendly Web" \
and "OONI Explorer Advanced Search".&lt;/div&gt;&lt;div&gt;     &lt;/div&gt;&lt;div&gt;     Can I \
get some guidance, please?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;     Thanking you, and sorry for \
such an  informal  mail.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;-- &lt;br&gt;&lt;div dir="ltr" \
class="gmail_signature" \
data-smartmail="gmail_signature"&gt;Aman&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200402155459</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-04-02 15:54:59-0400</timestampReceived><subject>[tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hello list,

hope everyone is safe and doing well!

I present you an initial draft of a proposal on PoW-based defences for
onion services under DoS.

The proposal is not finished yet and it needs tuning and fixing. There
are many places marked with XXX and TODO around the proposal that should
be addressed.

The important part is that looking at the numbers it does seem like this
proposal can work as a concept and serve its intended purpose. The most
handwavey parts of the proposal right now are [INTRO_QUEUE] and
[POW_SECURITY] and if this thing fails in the end, it's probably gonna
be something that slipped over there. Hence, we should polish these
sections before we proceed with any sort of engineering here.

In any case, I decided to send it to the list even in premature form, so
that it can serve as a stable point of reference in subsequent
discussions. It can also be found in my git repo:
    https://github.com/asn-d6/torspec/tree/pow-over-intro

Cheers and stay safe!

---

Filename: xxx-pow-over-intro-v1
Title: A First Take at PoW Over Introduction Circuits
Author: George Kadianakis
Created: 2 April 2020
Status: Draft

0. Abstract

  This proposal aims to thwart introduction flooding DoS attacks by introducing
  a dynamic Proof-Of-Work protocol that occurs over introduction circuits.

1. Motivation

  So far our attempts at limiting the impact of introduction flooding DoS
  attacks on onion services has been focused on horizontal scaling with
  Onionbalance, optimizing the CPU usage of Tor and applying congestion control
  using rate limiting. While these measures move the goalpost forward, a core
  problem with onion service DoS is that building rendezvous circuits is a
  costly procedure both for the service and for the network. If we ever hope to
  have truly reachable global onion services, we need to make it harder for
  attackers to overload the service with introduction requests.

  This proposal achieves this by allowing onion services to specify an optional
  dynamic proof-of-work scheme that its clients need to participate in if they
  want to get served.

  With the right parameters, this proof-of-work scheme acts as a gatekeeper to
  block amplification attacks by attackers while letting legitimate clients
  through.

1.1. Threat model [THREAT_MODEL]

1.1.1. Attacker profiles [ATTACKER_MODEL]

  This proposal is written to thwart specific attackers. A simple PoW proposal
  cannot defend against all and every DoS attack on the Internet, but there are
  adverary models we can defend against.

  Let's start with some adversary profiles:

  "The script-kiddie"

    The script-kiddie has a single computer and pushes it to its
    limits. Perhaps it also has a VPS and a pwned server. We are talking about
    an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
    consider the total cost for this attacker to be zero $.

  "The small botnet"

    The small botnet is a bunch of computers lined up to do an introduction
    flooding attack. Assuming 500 medium-range computers, we are talking about
    an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
    the upfront cost for this attacker to be about $400.

  "The large botnet"

    The large botnet is a serious operation with many thousands of computers
    organized to do this attack. Assuming 100k medium-range computers, we are
    talking about an attacker with total access to 200 Thz of CPU and 200 TB of
    RAM. The upfront cost for this attacker is about $36k.

  We hope that this proposal can help us defend against the script-kiddie
  attacker and small botnets. To defend against a large botnet we would need
  more tools in our disposal (see [FUTURE_WORK]).

  {XXX: Do the above make sense? What other attackers do we care about? What
        other metrics do we care about? Network speed? I got the botnet costs
        from here [REF_BOTNET] Back up our claims of defence.}

1.1.2. User profiles [USER_MODEL]

  We have attackers and we have users. Here are a few user profiles:

  "The standard web user"

    This is a standard laptop/desktop user who is trying to browse the
    web. They don't know how these defences work and they don't care to
    configure or tweak them. They are gonna use the default values and if the
    site doesn't load, they are gonna close their browser and be sad at Tor.
    They run a 2Ghz computer with 4GB of RAM.

  "The motivated user"

    This is a user that really wants to reach their destination. They don't
    care about the journey; they just want to get there. They know what's going
    on; they are willing to tweak the default values and make their computer do
    expensive multi-minute PoW computations to get where they want to be.

  "The mobile user"

    This is a motivated user on a mobile phone. Even tho they want to read the
    news article, they don't have much leeway on stressing their machine to do
    more computation.

  We hope that this proposal will allow the motivated user to always connect
  where they want to connect to, and also give more chances to the other user
  groups to reach the destination.

1.1.3. The DoS Catch-22 [CATCH22]

  This proposal is not perfect and it does not cover all the use cases. Still,
  we think that by covering some use cases and giving reachability to the
  people who really need it, we will severely demotivate the attackers from
  continuing the DoS attacks and hence stop the DoS threat all
  together. Furthermore, by increasing the cost to launch a DoS attack, a big
  class of DoS attackers will disappear from the map, since the expected ROI
  will decrease.

2. System Overview

2.1. Tor protocol overview

                                          +----------------------------------+
                                          |                                  |
   +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
   |Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
   +-------+         +-----------+        |Verifier|           |             |
                                          +--------+           |             |
                                          |                    |             |
                                          |                    |             |
                                          |         +----------v---------+   |
                                          |         |Intro Priority Queue|   |
                                          +---------+--------------------+---+
                                                           |  |  |
                                                Rendezvous |  |  |
                                                  circuits |  |  |
                                                           v  v  v



  The proof-of-work scheme specified in this proposal takes place during the
  introduction phase of the onion service protocol. It's an optional mechanism
  that only occurs if the service requires it. It can be enabled and disabled
  either through its torrc or through the control port.

  In summary, the following steps are taken for the protocol to complete:

  1) Service encodes PoW parameters in descriptor [DESC_POW]
  2) Client fetches descriptor and computes PoW [CLIENT_POW]
  3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
  4) Service verifies PoW and queues introduction based on PoW effort \
[SERVICE_VERIFY]

2.2. Proof-of-work overview

2.2.1. Primitives

  For our proof-of-work scheme we want to minimize the spread of resources
  between a motivated attacker and legitimate clients. This means that we are
  looking to minimize any benefits that GPUs or ACICs can offer to an attacker.

  For this reason we chose argon2 [REF_ARGON2] as the hash function for our
  proof-of-work scheme since it's well audited and GPU-resistant and to some
  extend ASIC-resistant as well.

  As a password hash function, argon2 by default outputs 32 bytes of hash, and
  takes as primary input a message and a nonce/salt. For the purposes of this
  specification we will define an argon2() function as:
     uint8_t hash_output[32] = argon2(uint8_t *message, uint8_t *nonce)'.

  See section [ARGON_PARAMS] for more information on the secondary inputs of
  argon2.

2.2.2. Dynamic PoW

  DoS is a dynamic problem where the attacker's capabilities constantly change,
  and hence we want our proof-of-work system to be dynamic and not stuck with a
  static difficulty setting. Hence, instead of forcing clients to go below a
  static target like in Bitcoin to be successful, we ask clients to "bid" using
  their PoW effort. Effectively, a client gets higher priority the higher
  effort they put into their proof-of-work. This is similar to how
  proof-of-stake works but instead of staking coins, you stake work.

  The benefit here is that legitimate clients who really care about getting
  access can spend a big amount of effort into their PoW computation, which
  should guarantee access to the service given reasonable adversary models. See
  [POW_SECURITY] for more details about these guarantees and tradeoffs.

3. Protocol specification

3.1. Service encodes PoW parameters in descriptor [DESC_POW]

  This whole protocol starts with the service encoding the PoW parameters in
  the 'encrypted' (inner) part of the v3 descriptor. As follows:

       "pow-params" SP type SP seed-b64 SP expiration-time NL

        [At most once]

        type: The type of PoW system used. We call the one specified here "v1"

        seed-b64: A random seed that should be used as the input to the PoW
                  hash function. Should be 32 random bytes encoded in base64
                  without trailing padding.

        expiration-time: A timestamp after which the above seed expires and is
                         no longer valid as the input for PoW. It's needed so
                         that the size of our replay cache does not grow
                         infinitely. It should be set to an hour in the future
                         (+- some randomness).  {TODO: PARAM_TUNING}

       {XXX: Expiration time makes us even more susceptible to clock skews, but
             it's needed so that our replay cache refreshes. How to fix this?
             See [CLIENT_BEHAVIOR] for more details.}

3.2. Client fetches descriptor and computes PoW [CLIENT_POW]

  If a client receives a descriptor with "pow-params", it should assume that
  the service is expecting a PoW input as part of the introduction protocol.

  In such cases, the client should have been configured with a specific PoW
  'target' (which is a 32-byte integer similar to the 'target' of Bitcoin
  [REF_TARGET]). See [POW_SECURITY] for more information of how such a target
  should be set. For the purposes of this section, we will assume that the
  target has been set automatically by Tor, or the user configured it manually.

  Now the client parses the descriptor and extracts the PoW parameters. It
  makes sure that the expiration-time has not expired and if it has, it needs
  to fetch a new descriptor.

  To complete the PoW the client follows the following logic:

      a) Client generates 'nonce' as 32 random bytes.
      b) Client derives 'seed' by decoding 'seed-b64'.
      c) Client computes hash_output = argon2(seed, nonce)
      d) Client interprets hash_output as a 32-byte big-endian integer.
      e) Client checks if int(hash_output) &lt;= target.
        e1) If yes, success! The client uses 'hash_output' as the hash and
            'nonce' and 'seed' as its inputs.
        e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
            increments it by one, and goes back to step (c).

  At the end of the above procedure, the client should have a triplet
  (hash_output, seed, nonce) that can be used as the answer to the PoW
  puzzle. How quickly this happens depends solely on the 'target' parameter.

3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]

  Now that the client has an answer to the puzzle it's time to encode it into
  an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
  portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
  [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
  INTRODUCE1 cell only gets read by the onion service and is ignored by the
  introduction point.

  We propose a new EXT_FIELD_TYPE value:

     [01] -- PROOF_OF_WORK

   The EXT_FIELD content format is:

      POW_VERSION    [1 byte]
      POW_SEED       [32 bytes]
      POW_NONCE      [32 bytes]
      POW_OUTPUT     [32 bytes]

   where:

    POW_VERSION is 1 for the protocol specified in this proposal
    POW_SEED is 'seed' from the section above
    POW_NONCE is 'nonce' from the section above
    POW_OUTPUT is 'hash_output' from the section above

   {XXX: do we need POW_VERSION? Perhaps we can use EXT_FIELD_TYPE as version}
   {XXX: do we need to encode the SEED? Perhaps we can ommit it since the
   service already knows it. But what happens in cases of desynch, if client
   has diff seed from service?}
   {XXX: Do we need to include the output? Probably not. The service has to
   compute it anyway during verification. What's the use?}

   This will increase the INTRODUCE1 payload size by 99 bytes since the
   extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
   present and currently set to 0 and the EXT_FIELD is 97 bytes. According to
   ticket #33650, INTRODUCE1 cells currently have more than 200 bytes available.

3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]

   When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
   should check its configuration on whether proof-of-work is required to
   complete the introduction. If it's not required, the extension SHOULD BE
   ignored. If it is required, the service follows the procedure detailed in
   this section.

3.4.1. PoW verification

   To verify the client's proof-of-work the service extracts (hash_output,
   seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:

   1) Make sure that the client's seed is identical to the active seed.
   2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
   3) Verify that 'hash_output =?= argon2(seed, nonce)

   If any of these steps fail the service MUST ignore this introduction request
   and abort the protocol.

   If all the steps passed, then the circuit is added to the introduction queue
   as detailed in section [INTRO_QUEUE].

3.4.1.1. Replay protection [REPLAY_PROTECTION]

  The service MUST NOT accept introduction requests with the same (seed, nonce)
  tuple. For this reason a replay protection mechanism must be employed.

  The simplest way is to use a simple hash table to check whether a (seed,
  nonce) tuple has been used before for the actiev duration of a
  seed. Depending on how long a seed stays active this might be a viable
  solution with reasonable memory/time overhead.

  If there is a worry that we might get too many introductions during the
  lifetime of a seed, we can use a Bloom filter as our replay cache
  mechanism. The probabilistic nature of Bloom filters means that sometimes we
  will flag some connections as replays even if they are not; with this false
  positive probability increasing as the number of entries increase. However,
  with the right parameter tuning this probability should be negligible and
  well handled by clients. {TODO: PARAM_TUNING}

3.4.2. The Introduction Queue  [INTRO_QUEUE]

3.4.2.1. Adding introductions to the introduction queue

  When PoW is enabled and a verified introduction comes through, the service
  instead of jumping straight into rendezvous, queues it and prioritizes it
  based on how much effort was devoted by the client to PoW. This means that
  introduction requests with high effort should be prioritized over those with
  low effort.

  To do so, the service maintains an "introduction priority queue" data
  structure. Each element in that priority queue is an introduction request,
  and its priority is the effort put into its PoW:

  When a verified introduction comes through, the service interprets the PoW
  hash as a 32-byte big-endian integer 'hash_int' and based on that integer it
  inserts it into the right position of the priority_queue: The smallest
  'hash_int' goes forward in the queue. If two elements have the same value,
  the older one has priority over the newer one.
  {XXX: Is this operation with 32-bytes integers expensive? How to make cheaper?}

  {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
   effort what attacks can happen in various scenarios? Do we want to order on
   time+effort?  Which scenarios and attackers should we examine here?}

  {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can we
   use WRED usefully?}

3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]

  The service should handle introductions by pulling from the introduction
  queue.

  Similar to how our cell scheduler works, the onion service subsystem will
  poll the priority queue every 100ms tick and process the first 20 cells from
  the priority queue (if they exist). The service will perform the rendezvous
  and the rest of the onion service protocol as normal.

  With this tempo, we can process 200 introduction cells per second.
  {XXX: Is this good?}

  {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
  per 100ms is probably unmaintainable, since each cell is quite expensive:
  doing so involving path selection, crypto and making circuits. We will need
  to profile this procedure and see how we can do this scheduling better.}

  {XXX: This might be a nice place to promote multithreading. Queues and pools
  are nice objects to do multithreading since you can have multiple threads
  pull from the queue, or leave stuff on the queue. Not sure if this should be
  in the proposal tho.}

4. Attacker strategies [ATTACK_META]

  Now that we defined our protocol we need to start tweaking the various
  knobs. But before we can do that, we first need to understand a few
  high-level attacker strategies to see what we are fighting against.

4.1.1. Total overwhelm strat

  Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
  effective strategy for the attacker is to totally overwhelm the queue
  processing by sending more high-effort introductions than the onion service
  can handle at any given tick.

  To do so, the attacker would have to send at least 20 high-effort
  introduction cells every 100ms, where high-effort is a PoW which is above the
  estimated level of "the motivated user" (see [USER_MODEL]).

  An easier attack for the adversary, is the same strategy but with
  introduction cells that are all above the comfortable level of "the standard
  user" (see [USER_MODEL]). This would block out all standard users and only
  allow motivated users to pass.

  {XXX: What other attack strategies we should care about?}

5. Parameter tuning [POW_SECURITY]

  There are various parameters in this system that need to be tuned.

  We will first start by tuning the default difficulty of our PoW
  system. That's gonna define an expected time for attackers and clients to
  succeed.

  We are then gonna tune the parameters of the argon2 hash function. That will
  define the resources that an attacker needs to spend to overwhelm the onion
  service, the resources that the service needs to spend to verify introduction
  requests, and the resources that legitimate clients need to spend to get to
  the onon service.

5.1. PoW Difficulty settings

  The difficulty setting of our PoW basically dictates how difficult it should
  be to get a success in our PoW system. In classic PoW systems, "success" is
  defined as getting a hash output below the "target". However, since our
  system is dynamic, we define "success" as an abstract high-effort computation.

  Even tho our system is dynamic, we still need default difficulty settings
  that will define the metagame. The client and attacker can still aim higher
  or lower, but for UX purposes and for analysis purposes we do need to define
  some difficulties.

  We hence created the table (see [REF_TABLE]) below which shows how much time
  a legitimate client with a single machine should expect to burn before they
  get a single success. The x-axis is how many successes we want the attacker
  to be able to do per second: the more successes we allow the adversary, the
  more they can overwhelm our introduction queue. The y-axis is how many
  machines the adversary has in her disposal, ranging from just 5 to 1000.

       ===============================================================
       |    Expected Time (in seconds) Per Success For One Machine   |
 ===========================================================================
 |                                                                          |
 |   Attacker Succeses        1       5       10      20      30      50    |
 |       per second                                                         |
 |                                                                          |
 |            5               5       1       0       0       0       0     |
 |            50              50      10      5       2       1       1     |
 |            100             100     20      10      5       3       2     |
 | Attacker   200             200     40      20      10      6       4     |
 |  Boxes     300             300     60      30      15      10      6     |
 |            400             400     80      40      20      13      8     |
 |            500             500     100     50      25      16      10    |
 |            1000            1000    200     100     50      33      20    |
 |                                                                          |
 ============================================================================

  Here is how you can read the table above:

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
    success per second, then a legitimate client with a single box should be
    expected to spend 1000 seconds getting a single success.

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 200 seconds getting a single success.

  - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 100 seconds getting a single success.

  - If an adversary has access to 50 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 10 seconds getting a single success.

  - If an adversary has access to 5 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 1 seconds getting a single success.

  With the above table we can create some profiles for default values of our
  PoW difficulty. So for example, we can use the last case as the default
  parameter for Tor Browser, and then create three more profiles for more
  expensive cases, scaling up to the first case which could be hardest since
  the client is expected to spend 15 minutes for a single introduction.

  {TODO: PARAM_TUNING You can see that this section is completely CPU/memory
  agnostic, and it does not take into account potential optimizations that can
  come from GPU/ASICs. This is intentional so that we don't put more variables
  into this equation right now, but as this proposal moves forward we will need
  to put more concrete values here.}

5.2. Argon2 parameters [ARGON_PARAMS]

  We now need to define the secondary argon2 parameters as defined in
  [REF_ARGON2]. This includes the number of lanes 'h', the memory size 'm', the
  number of iterations 't'. Section 9 of [REF_ARGON2] recommends an approach of
  how to tune these parameters.

  To tune these parameters we are looking to *minimize* the verification speed
  of an onion service, while *maximizing* the sparse resources spent by an
  adversary trying to overwhelm the service using [ATTACK_META].

  When it comes to verification speed, to verify a single introduction cell the
  service needs to do a single argon2 call: so the service will need to do
  hundreds of those per second as INTRODUCE2 cells arrive. The service will
  have to do this verification step even for very cheap zero-effort PoW
  received, so this has to be a cheap procedure so that it doesn't become a DoS
  vector of each own. Hence each individual argon2 call must be cheap enough to
  be able to be done comfortably and plentifuly by an onion service with a
  single host (or horizontally scaled with Onionbalance).

  At the same time, the adversary will have to do thousands of these calls if
  she wants to make high-effort PoW, so it's this assymetry that we are looking
  to exploit here. Right now, the most expensive resource for adversaries is
  the RAM size, and that's why we chose argon2 which is memory-hard.

  To minmax this game we will need

  {TODO: PARAM_TUNING: I've had a hard time minmaxing this game for
  argon2. Even argon2 invocations with a small memory parameter will take
  multiple milliseconds to run on my machine, and the parameters recommended in
  section 8 of the paper all take many hundreds of milliseconds. This is just
  not practical for our use case, since we want to process hundreds of such PoW
  per second... I also did not manage to find a benchmark of argon2 calls for
  different CPU/GPU/FPGA configurations.}

5. Client behavior [CLIENT_BEHAVIOR]

  This proposal introduces a bunch of new ways where a legitimate client can
  fail to reach the onion service.

  Furthermore, there is currently no end-to-end way for the onion service to
  inform the client that the introduction failed. The INTRO_ACK cell is not
  end-to-end (it's from the introduction point to the client) and hence it does
  not allow the service to inform the client that the rendezvous is never gonna
  occur.

  Let's examine a few such cases:

5.1. Timeout issues

  Alice can fail to reach the onion service if her introduction request falls
  off the priority queue, or if the priority queue is so big that the
  connection times out.

  Is building a new introduction circuit sufficient here? Or do we need to
  build an end-to-end mechanism over the introduction circuit to inform
  her? {XXX}

  How should timeout values change here since the priority queue will cause
  bigger delays than usual to rendezvous? Can there be some feedback mechanism
  to inform the client of its queue position or ETA?

5.2. Seed expiration issues

  As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
  cause issues with clock skewed clients. Furthermore, even not clock skewed
  clients can encounter TOCTOU-style race conditions here.

  How should this be handled? Should we have multiple active seeds at the same
  time similar to how we have overlapping descriptors and time periods in v3?
  This would solve the problem but it grows the complexity of the system
  substantially. {XXX}

5.3. Other descriptor issues

  Another race condition here is if the service enables PoW, while a client has
  a cached descriptor. How will the client notice that PoW is needed? Does it
  need to fetch a new descriptor? Should there be another feedback mechanism?
  {XXX}

5. Discussion

5.1. UX

  This proposal has user facing UX consequences. Here are a few UX approaches
  with increasing engineering difficulty:

  a) Tor Browser needs a "range field" which the user can use to specify how
     much effort they want to spend in PoW if this ever occurs while they are
     browsing. The ranges could be from "Easy" to "Difficult", or we could try
     to estimate time using an average computer. This setting is in the Tor
     Browser settings and users need to find it.

  b) We start with a default effort setting, and then we use the new onion
     errors (see #19251) to estimate when an onion service connection has
     failed because of DoS, and only then we present the user a "range field"
     which they can set dynamically. Detecting when an onion service connection
     has failed because of DoS can be hard because of the lack of feedback (see
     [CLIENT_BEHAVIOR])

  c) We start with a default effort setting, and if things fail we
     automatically try to figure out an effort setting that will work for the
     user by doing some trial-and-error connections with different effort
     values. Until the connection succeeds we present a "Service is
     overwhelmed, please wait" message to the user.

  For this proposal to work initially we need at least (a), and then we can
  start thinking of how far we want to take it.

5.2. Future directions [FUTURE_WORK]

  This is just the beginning in DoS defences for Tor and there are various
  future avenues that we can investigate. Here is a brief summary of these:

  "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
         schemes like MTP-argon2 or Itsuku to make it even harder for
         adversaries to create successful PoWs. Unfortunately these schemes
         have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
         See #31223 for more details.

  "Third-party anonymous credentials" -- We can use anonymous credentials and a
         third-party token issuance server on the clearnet to issue tokens
         based on PoW or CAPTCHA and then use those tokens to get access to the
         service. See [REF_CREDS] for more details.

  "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
         where we present a hard puzzle to the user when connecting to the
         onion service, and if they solve it we then give the user a bunch of
         anonymous tokens that can be used in the future. This can all happen
         between the client and the service without a need for a third party.

  All of the above approaches are much more complicated than this proposal, and
  hence we want to start easy before we get into more serious projects.

5.3. Environment

  We love the environment! We are concerned of how PoW schemes can waste energy
  by doing useless hash iterations. Here is a few reasons we still decided to
  pursue a PoW approach here:

  "We are not making things worse" -- DoS attacks are already happening and
      attackers are already burning energy to carry them out both on the
      attacker side, on the service side and on the network side. We think that
      asking legitimate clients to carry out PoW computations is not gonna
      affect the equation too much, since an attacker right now can very
      quickly cause the same damage that hundreds of legitimate clients do a
      whole day.

  "We hope to make things better" -- The hope is that proposals like this will
      make the DoS actors go away and hence the PoW system will not be used. As
      long as DoS is happening there will be a waste of energy, but if we
      manage to demotivate them with technical means, the network as a whole
      will less wasteful. Also see [CATCH22] for a similar argument.

6. References

  [REF_ARGON2]: https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf
  https://password-hashing.net/#argon2
  [REF_TABLE]: The table is based on the script below plus some manual editing for \
                readability:
               https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
  [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
  [REF_TARGET]: https://en.bitcoin.it/wiki/Target
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200505170536</emailId><senderName>Eli Vakrat</senderName><senderEmail>eli@vakrat.com</senderEmail><timestampReceived>2020-05-05 17:05:36-0400</timestampReceived><subject>[tor-dev] Example of how a stream of RELAY_DATA cells would work?</subject><body>

[Attachment #2 (multipart/alternative)]


Hi again everyone! It's Eli ...

So thanks to Teor and Nick's help, my python client (tor OP) is finally
able to successfully establish a three-hop circuit with any TOR relays in
the whole public network!

Now It's on to the Data Cells...
As of writing this, I can send and receive the proper RELAY_BEGIN and
RELAY_CONNECTED to and from my exit node, but I'm not quite sure what to do
next...

Do I just start sending RELAY_DATA cells (where the "data" of the cell is
literally the encoded HTTP requests)?

I've tried connecting to 'www.facebook.com:443'  with the RELAY_BEGIN cells
as a test (I do get a Relay Connected Cell so at least I know that part
works).

After getting back the RELAY_CONNECTED cell, I send a RELAY_DATA cell with
the data of the cell being the following 'utf-8' encoded string:

* #######this is how i wrote the literal in python#### *
*'GET / HTTP/1.1\r\nHost: www.facebook.com
&lt;http://www.facebook.com&gt;\r\nUser-Agent:
python-requests/2.23.0\r\nAccept-Encoding: gzip, deflate\r\nAccept:
*/*\r\nConnection: keep-alive\r\n\r\n\r\n'.encode() *

What I get back is a short couple of bytes:


*\x15\x03\x03\x00\x02\x022*

I had no idea what this meant but after digging around a bit I found that
this seems to be some part of the TLS handshake that is used in HTTPS.

So now two questions arise:

1. Is this a good TLS response? What does it mean exactly?

2. Generally speaking, is this how the RELAY_DATA cells are supposed to be
sent and received?
Just to clarify it would be great if I could get an exact example of how
the stream of data should look. For example, if someone could maybe break
down the steps of how a basic HTTP GET request would work through a TOR
circuit (starting from sending a RELAY_BEGIN cell) that would help me
tremendously.

Thanks again to everyone who've helped me so far, and thanks in advance to
anyone with an answer to any of my questions!

Regards,
Eli

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi again everyone! It's Eli ...&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So thanks to \
Teor and Nick's help, my python client (tor OP) is finally able to  successfully  \
establish a three-hop circuit with any TOR relays in the whole public network!  \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Now It's on to the Data Cells...&lt;/div&gt;&lt;div&gt;As of \
writing this, I can send and receive the proper RELAY_BEGIN and RELAY_CONNECTED to \
and from my exit node, but I'm not quite sure what to do \
next...&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Do I just start sending RELAY_DATA cells (where the \
"data" of the cell is literally the encoded HTTP \
requests)?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I've tried connecting to '&lt;a \
href="http://www.facebook.com:443"&gt;www.facebook.com:443&lt;/a&gt;'   with the \
RELAY_BEGIN cells as a test (I do get a Relay Connected Cell so at least I know that \
part works).&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;After getting back the RELAY_CONNECTED cell, I \
send a RELAY_DATA cell with the data of the cell being the following 'utf-8' \
encoded string:&lt;/div&gt;&lt;div&gt;&lt;b&gt;  #######this is how i wrote the literal in python####  \
&lt;br&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;'GET / HTTP/1.1\r\nHost: &lt;a \
href="http://www.facebook.com"&gt;www.facebook.com&lt;/a&gt;\r\nUser-Agent: \
python-requests/2.23.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: \
*/*\r\nConnection: keep-alive\r\n\r\n\r\n'.encode() \
&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What I get back is a short couple of \
bytes:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;\x15\x03\x03\x00\x02\x022&lt;br&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I \
had no idea what this meant but after digging around a bit I found that this seems to \
be some part of the TLS handshake  that is used in HTTPS.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So \
now two questions arise:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. Is this a good TLS response? \
What does it mean exactly?  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;2. Generally speaking, is this \
how the RELAY_DATA cells are supposed to be sent and received?  &lt;/div&gt;&lt;div&gt;Just to \
clarify it would be great if I could get an exact example of how the stream of data \
should look. For example, if someone could maybe break down the steps of how a basic \
HTTP GET request would work through a TOR circuit (starting  from sending a \
RELAY_BEGIN cell) that would help me tremendously.    \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks again to everyone who've helped me so far, and \
thanks in advance to anyone with an answer to any of my \
questions!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Eli    \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200520154551</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@torproject.org</senderEmail><timestampReceived>2020-05-20 15:45:51-0400</timestampReceived><subject>[tor-dev] Moving key material out of the main tor process</subject><body>

Hi,

tl;dr How to move key material out of tor?

## The idea of a vault component

ahf and others in the network team have been discussing the
possibility of a "vault" component in tor, for moving private keys out
of the tor process. Separating secret key material from the code
handling data from the network seems valuable and providing a
component making different implementations "pluggable" would allow for
anyone to use their favourite technology without touching the tor
code base. Examples are local trusted execution environments like Intel
SGX and Arm TrustZone and various HSM's and security keys/tokens.

One way of implementing this would be to define a protocol, for a
vault component to talk to a daemon running on the same host as tor,
over some IPC mechanism. This protocol would allow tor to request a
signature over a hash, or a document, in a certain key. Whether the
daemon has access to the key material or has to forward the request to
a separate device or hardware component is irrelevant to the protocol
and the vault component.

Even if the design focuses on signatures it should probably take
encryption and decryption into account, to be added later.


## The vault as a possible match for TorHSM

Such a vault component would fit well with a project where Peter Stuge
and myself are building an HSM for Tor directory authority signing
keys [0] based on the CrypTech design [1].

[0] https://trac.cryptech.is/wiki/ExternalProjectsTorHSM
[1] https://cryptech.is/

One of the options for tor to delegate the signing of votes and
consensuses to such a device would be to use a vault component as
described above. We would then have a signing daemon responsible for
the USB communication with the TorHSM device. Another option would be
to build support directly into tor for communicating with the device,
through a library capable of a USB vendor specific protocol defined by
TorHSM.

There are pros and cons with both options. I'd like to hear what the
Tor developers community think would be best.


## Asynchronous signing API

Vault or not, tor needs to change the way signing is done to be able
to move key material out of the main process. First, external devices
may need more time to perform a signature operation than what tor can
accept to spend blocking in its main thread. Second, an external
device might disappear or malfunction, requiring the possibility for
an operation to time out.

This can be implemented either with callbacks or with a state machine
with more well defined state transitions. Maybe there are more
options that I didn't think of.


## Protocol choice

If we decide to go for the vault component with a separate daemon we
should consider using the ssh-agent protocol for tor to talk to the
daemon. Apart from being already defined there are multiple well
tested implementations of this protocol. It also has a couple of
features we might want, such as forgetting a certain key and
locking/unlocking of the vault. Finally, it's extensible and should
accommodate potential additions we might want to make later.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200807161751</emailId><senderName>Ladar Levison</senderName><senderEmail>ladar@lavabit.com</senderEmail><timestampReceived>2020-08-07 16:17:51-0400</timestampReceived><subject>[tor-dev] CentOS 8 TOR Repo</subject><body>

[Attachment #2 (multipart/alternative)]


It appears that installing TOR via the CentOS 8 DNF repo isn't working.
The pre-flight configuration check fails because the repo package was
built using zstd 1.4.4, and CentOS 8 is currently providing zstd 1.4.2.

For any that cares to try, the repo is at:
https://rpm.torproject.org/centos/8/

L~


[Attachment #5 (text/html)]

&lt;html&gt;
  &lt;head&gt;

    &lt;meta http-equiv="content-type" content="text/html; charset=UTF-8"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;&lt;font face="Helvetica, Arial, sans-serif"&gt;It appears that
        installing TOR via the CentOS 8 DNF repo isn't working. The
        pre-flight configuration check fails because the repo package
        was built using zstd 1.4.4, and CentOS 8 is currently providing
        zstd 1.4.2.&lt;/font&gt;&lt;/p&gt;
    &lt;p&gt;&lt;font face="Helvetica, Arial, sans-serif"&gt;For any that cares to
        try, the repo is at: &lt;a class="moz-txt-link-freetext" \
href="https://rpm.torproject.org/centos/8/"&gt;https://rpm.torproject.org/centos/8/&lt;/a&gt;&lt;br&gt;
  &lt;/font&gt;&lt;/p&gt;
    &lt;p&gt;&lt;font face="Helvetica, Arial, sans-serif"&gt;L~&lt;/font&gt;&lt;br&gt;
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200904122633</emailId><senderName>Matt Traudt</senderName><senderEmail>pastly@torproject.org</senderEmail><timestampReceived>2020-09-04 12:26:33-0400</timestampReceived><subject>[tor-dev] Update to Proposal 316: FlashFlow</subject><body>

Hi all

I polished up the FlashFlow proposal based on the feedback provided by
Teor, Nick, and Mike. I converted it to markdown, and pasted the new
text at the bottom of this email. The updated proposal is also in my
fork of torspec is on gitlab [0]; the branch with the changes is
"flashflow-revision".

I'd like to address Nick's concerns [1] again [2].

1. Measurers get to consume lots of bandwidth at relays. Malicious
measurers could do bad things. More generally, these measurements may
induce traffic patterns that assist traffic analysis.

Measurers are trusted entities. In practice we expect each bwauth
wanting to run FlashFlow to run a deployment entirely on their own
despite FF's design allowing people they trust to run the measurers. I
do not think measurers themselves being malicious is a major concern.

Relays target some ratio of background/measurement traffic during a
measurement. If the amount of traffic they normally see is less than the
amount of background traffic allowed by this ratio during a measurement,
then there should be no observable impact on the background traffic
during the measurement. To illustrate: assume the ratio is 25%. A relay
that is only forwarding traffic at 10% of its capacity will not have to
throttle traffic during the measurement.

But what about relays that *do* handle more traffic than the ratio allows?

First an easy mitigation (not solution): The ratio can be raised, thus
reducing the number of relays with normal background traffic levels
exceeding it. We suggest a ratio of 25% (maximum inflation factor of
1.33); it could be raised to, say, 50% (2.0) or even 75% (4.0) if we're
okay with an adversary doubling or quadrupling its weight (how? [fn1]).
I assume this is not okay.

Another easy mitigation: relay capacities don't change very often, so
don't measure every relay every day like we suggest. Measure new relays
ASAP, but for relays with an existing measurement, only measure them
once a week. Just like that, the adversary has to wait much longer for
the FF-induced pattern.

Another idea: first group the relays (say, randomly by hashing their
keys into k bins, with maybe k=10). If the entire network could be
measured in t time (we showed howe 5h6h might currently suffice), then
we could have each group of relays simultaneously start restricting
background traffic at a different p=t/k period of time (for k=10 and t=6
hours, we would have p=36 minutes). All relays in a group would be
measured during their period. This would reduce performance overall but
would limit the adversary to learning from the FF attack only the group
that a measured relay is in.

Finally we note that the measurement schedule is random and known only
to the bwauths/coordinators. Unless the adversary has infiltrated a FF
deployment or bwauth, attacks involving the adversary referencing a
known schedule should not be possible.

The adversary could maintain connections through all relays and monitor
each for a drop in performance indicating it's under measurement;
however, they have the burden of performing this monitoring, making it
more costly and similar to just performing the attack (introducing
spikes/patterns/congestion) itself. Moreover, if the adversary were able
to monitor performance of all relays over time in this way, then he
could just use natural variations in performance (due to varying client
load) to perform the correlation attack anyway:

    "Stealthy Traffic Analysis of Low-Latency Anonymous Communication
    Using Throughput Fingerprinting"
    Prateek Mittal et al.
    ACM CCS 2011
    https://dl.acm.org/doi/pdf/10.1145/2046707.2046732



2. MEAS_BG cells leak way too much info

These cells go to the FF coordinators, operated by the bwauths. Coords
don't use these cells beyond calculating the capacities of relays. An
adversary looking at v3bw files or votes does not learn anything about
the amount of background traffic that went through a relay during its
measurement.



3. Do cell crypto, use circuits

As mentioned in [2], the implementation is starting out doing cell
crypto on all cells at the measurer. The proposal has been updated to
clarify that circuits are used and the measurement traffic (MEAS_ECHO
cells) are RELAY cells.



4. Use a pseudorandom stream function to generate cells

Good idea that we will investigate and talk about more. Again, we're
worried about the measurer's CPU ending up being a bottleneck before its
network, which happened to us in prototyping: the measurer was at 100%
CPU while a relay on the same type of machine was not yet



5. IPs for measurer identification

(copy/paste from previous response to Nick)

It's the short term deployment that we propose use IP addresses for
identification. At this point there's 1 FlashFlow deployment being
operated by us and measuring relays that have opted in to running our
patches (realistically: just us, but hopefully some adventurous
operators too). In the medium/long term coords/measurers will use proper
TLS identities that will be checked by the relays.

Maybe that's still unacceptable, but I just wanted to make that clear.


[0]: https://gitlab.torproject.org/pastly/torspec
[1]: https://lists.torproject.org/pipermail/tor-dev/2020-June/014341.html
[2]: https://lists.torproject.org/pipermail/tor-dev/2020-June/014342.html

[fn1]: The relay allocates all its bandwidth to measurement traffic
(leaving none for background traffic), yet claim lots of background
traffic. The relay will be trusted to be telling the truth up to the
ratio. A 1 Gbit/s relay that sustains 1 Gbit/s of measurement traffic
can claim up to: 333 Mbit/s of client traffic (r=25%), 1 Gbit/s (r=50%),
3 Gbit/s (r=75%). In general, the inflation factor is calculated 1/(1-r).




----------------------------------------




```
Filename: 316-flashflow.txt
Title: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)
Author: Matthew Traudt, Aaron Johnson, Rob Jansen, Mike Perry
Created: 23 April 2020
Status: Draft
```

# 1. Introduction

FlashFlow is a new distributed bandwidth measurement system for Tor that
consists of a single authority node ("coordinator") instructing one or
more measurement nodes ("measurers") when and how to measure Tor relays.
A measurement consists of the following steps:

1. The measurement nodes demonstrate to the target relay permission to
   perform measurements.
2. The measurement nodes open many TCP connections to the target relay
   and create a one-hop circuit to the target relay on each one.
3. For 30 seconds the measurement nodes send measurement cells to the
   target relay and verify that the cells echoed back match the ones
   sent. During this time the relay caps the amount of background
   traffic it transfers. Background and measurement traffic are
   handled separately at the relay. Measurement traffic counts towards
   all the standard existing relay statistics.
4. For every second during the measurement, the measurement nodes
   report to the authority node how much traffic was echoed back. The
   target relay also reports the amount of per-second background
   (non-measurement) traffic.
5. The authority node sums the per-second reported throughputs into 30
   sums (one for each second) and calculates the median. This is the
   estimated capacity of the relay.

FlashFlow performs a measurement of every relay according to a schedule
described later in this document. Periodically it produces relay
capacity estimates in the form of a v3bw file, which is suitable for
direct consumption by a Tor directory authority. Alternatively an
existing load balancing system such as Simple Bandwidth Scanner could be
modified to use FlashFlow's v3bw file as input.

It is envisioned that each directory authority that wants to use
FlashFlow will run their own FlashFlow deployment consisting of a
coordinator that they run and one or more measurers that they trust
(e.g. because they run them themselves), similar to how each runs their
own Torflow/sbws. Section 5 of this proposal describes long term plans
involving multiple FlashFlow deployments. *FlashFlow coordinators do not
need
to communicate with each other*.

FlashFlow is more performant than Torflow: FlashFlow takes 5 hours to
measure the entire existing Tor network from scratch (with 3 Gbit/s
measurer capacity) while Torflow takes 2 days; FlashFlow measures relays
it hasn't seen recently as soon as it learns about them (i.e. every new
consensus) while Torflow can take a day or more; and FlashFlow
accurately measures new high-capacity relays the first time and every
time while Torflow takes days/weeks to assign them their full fair share
of bandwidth (especially for non-exits). FlashFlow is more secure than
Torflow: FlashFlow allows a relay to inflate its measured capacity by up
to 1.33x (configured by a parameter) while Torflow allows weight
inflation by a factor of 89x [0] or even 177x [1].

After an overview in section 2 of the planned deployment stages, section
3, 4, and 5 discuss the short, medium, and long term deployment plans in
more detail.

# 2. Deployment Stages

FlashFlow's deployment shall be broken up into three stages.

In the short term we will implement a working FlashFlow measurement
system. This requires code changes in little-t tor and an external
FlashFlow codebase. The majority of the implementation work will be
done in the short term, and the product is a complete FlashFlow
measurement system. Remaining pieces (e.g. better authentication) are
added later for enhanced security and network performance.

In the medium term we will begin collecting data with a FlashFlow
deployment. The intermediate results and v3bw files produced will be
made available (semi?) publicly for study.

In the long term experiments will be performed to study ways of using FF
v3bw files to improve load balancing. Two examples: (1) using FF v3bw
files instead of sbws's (and eventually phasing out torflow/sbws), and
(2) continuing to run sbws but use FF's results as a better estimate of
relay capacity than observed bandwidth. Authentication and other
FlashFlow features necessary to make it completely ready for full
production deployment will be worked on during this long term phase.

# 3. FlashFlow measurement system: Short term

The core measurement mechanics will be implemented in little-t tor, but
a separate codebase for the FlashFlow side of the measurement system
will also be created. This section is divided into three parts: first a
discussion of changes/additions that logically reside entirely within
tor (essentially: relay-side modifications), second a discussion of the
separate FlashFlow code that also requires some amount of tor changes
(essentially: measurer-side and coordinator-side modifications), and
third a security discussion.

## 3.1 Little-T Tor Components

The primary additions/changes that entirely reside within tor on the
relay side:

- New torrc options/consensus parameters.
- New cell commands.
- Pre-measurement handshaking (with a simplified authentication
  scheme).
- Measurement mode, during which the relay will echo traffic with
  measurers, set a cap on the amount of background traffic it
  transfers, and report the amount of transferred background traffic.

### 3.1.1 Parameters

FlashFlow will require some consensus parameters/torrc options. Each has
some default value if nothing is specified; the consensus parameter
overrides this default value; the torrc option overrides both.

FFMeasurementsAllowed: A global toggle on whether or not to allow
measurements. Even if all other settings would allow a measurement, if
this is turned off, then no measurement is allowed. Possible values: 0,
1. Default: 0 (disallowed).

FFAllowedCoordinators: The list of coordinator TLS certificate
fingerprints that are allowed to start measurements. Relays check their
torrc when they receive a connection from a FlashFlow coordinator to see
if it's on the list. If they have no list, they check the consensus
parameter. If nether exist, then no FlashFlow deployment is allowed to
measure this relay. Default: empty list.

FFMeasurementPeriod: A relay should expect on average, to be measured by
each FlashFlow deployment once each measurement period. A relay will not
allow itself to be measured more than twice by a FlashFlow deployment in
any time window of this length. Relays should not change this option
unless they really know what they're doing. Changing it at the relay
will not change how often FlashFlow will attempt to measure the relay.
Possible values are in the range [1 hour, 1 month] inclusive. Default: 1
day.

FFBackgroundTrafficPercent: The maximum amount of regular
non-measurement traffic a relay should handle while being measured, as a
percent of total traffic (measurement + non-measurement). This
parameter is a trade off between having to limit background traffic and
limiting how much a relay can inflate its result by handling no
background traffic but reporting that it has done so. Possible values
are in the range [0, 99] inclusive. Default: 25 (a maximum inflation
factor of 1.33).

FFMaxMeasurementDuration: The maximum amount of time, in seconds, that
is allowed to pass from the moment the relay is notified that a
measurement will begin soon and the end of the measurement. If this
amount of time passes, the relay shall close all measurement connections
and exit its measurement mode. Note this duration includes handshake
time, thus it necessarily is larger than the expected actual measurement
duration. Possible values are in the range [10, 120] inclusive.
Default: 45.

### 3.1.2 New Cell Types

FlashFlow will introduce a new cell command MEASUREMENT.

The payload of each MEASUREMENT cell consists of:

```
Measure command [1 byte]
Data            [varied]
```

The measure commands are:

```
0 -- MEAS_PARAMS    [forward]
1 -- MEAS_PARAMS_OK [backward]
2 -- MEAS_BG        [backward]
3 -- MEAS_ERR       [forward and backward]
```

Forward cells are sent from the measurer/coordinator to the relay.
Backward cells are sent from the relay to the measurer/coordinator.

MEAS_PARAMS and MEAS_PARAMS_OK are used during the pre-measurement stage
to tell the target what to expect and for the relay to positively
acknowledge the message.
The target send a MEAS_BG cell once per second to report
the amount of background traffic it is handling. MEAS_ERR cells are used
to signal to the other party that there has been some sort of problem
and that the measurement should be aborted. These measure commands are
described in more detail in the next section.

FlashFlow also introduces a new relay command, MEAS_ECHO. Relay celsl with
this relay command are the measurement traffic. The measurer generates and
encrypts them, sends them to the target, the target decrypts them, then it
sends them back. A variation where the measurer skips encryption of
MEAS_ECHO
cells in most cases is described in Appendix A, and was found to be
necessary
in paper prototypes to save CPU load at the measurer.

MEASUREMENT cells, on the other hand, are not encrypted (beyond the regular
TLS on the connection).

### 3.1.3 Pre-Measurement Handshaking/Starting a Measurement

The coordinator establishes a one-hop circuit with the target relay and
sends
it a MEAS_PARAMS cell. If the target is unwilling to be measured at this
time
or if the coordinator didn't use a TLS certificate that the target
trusts, it
responds with an error cell and closes the connection. Otherwise it checks
that the parameters of the measurement are acceptable (e.g. the version is
acceptable, the duration isn't too long, etc.). If the target is happy, it
sends a MEAS_PARAMS_OK, otherwise it sends a MEAS_ERR and closes the
connection.

Upon learning the IP addresses of the measurers from the coordinator in
the MEAS_PARAMS cell, the target whitelists their IPs in its DoS
detection subsystem until the measurement ends (successfully or
otherwise), at which point the whitelist is cleared.

Upon receiving a MEAS_PARAMS_OK from the target, the coordinator will
instruct
the measurers to open their circuits (one circuit per connection) with the
target. If the coordinator or any measurer receives a MEAS_ERR, it
reports the
error to the coordinator and considers the measurement a failure. It is
also a
failure if any measurer is unable to open at least half of its circuits with
the target.

The payload of MEAS_PARAMS cells [XXX more may need to be added]:

```
- meas_duration [2 bytes] [1, 600]
- num_measurers [1 byte] [1, 10]
- measurer_info [num_measurers times]
```

meas_duration is the duration, in seconds, that the actual measurement will
last.  num_measurers is how many link_specifier structs follow containing
information on the measurers that the relay should expect.  Future
versions of
FlashFlow and MEAS_PARAMS will use TLS certificates instead of IP addresses.
[XXX probably need diff layout to allow upgrade to TLS certs instead of
link_specifier structs. probably using ext-type-length-value like teor
suggests]
[XXX want to specify number of conns to expect from each measurer here?]

MEAS_PARAMS_OK has no payload: it's just padding bytes to make the cell
PAYLOAD_LEN (509) bytes long.

The payload of MEAS_ECHO cells:

```
- arbitrary bytes [PAYLOAD_LEN bytes]
```

The payload of MEAS_BG cells [XXX more for extra info? like CPU usage]:

```
- second        [2 byte] [1, 600]
- sent_bg_bytes [4 bytes] [0, 2^32-1]
- recv_bg_bytes [4 bytes] [0, 2^32-1]
```

second is the number of seconds since the measurement began. MEAS_BG
cells are sent once per second from the relay to the FlashFlow
coordinator. The first cell will have this set to 1, and each
subsequent cell will increment it by one. sent_bg_bytes is the number of
background traffic bytes sent in the last second (since the last MEAS_BG
cell). recv_bg_bytes is the same but for received bytes.

The payload of MEAS_ERR cells [XXX need field for more info]:

```
- err_code [1 byte] [0, 255]
```

The error code is one of:

```
[... XXX TODO ...]
255 -- OTHER
```

### 3.1.4 Measurement Mode

The relay considers the measurement to have started the moment it
receives the first MEAS_ECHO cell from any measurer. At this point, the
relay

- Starts a repeating 1s timer on which it will report the amount of
  background traffic to the coordinator over the coordinator's
  connection.
- Enters "measurement mode" and limits the amount of background
  traffic it handles according to the torrc option/consensus
  parameter.

The relay decrypts and echos back all MEAS_ECHO cells it receives on
measurement connections until it has reported its amount of background
traffic the same number of times as there are seconds in the measurement
(e.g. 30 per-second reports for a 30 second measurement). After sending
the last MEAS_BG cell, the relay drops all buffered MEAS_ECHO cells,
closes all measurement connections, and exits measurement mode.

During the measurement the relay targets a ratio of background traffic
to measurement traffic as specified by a consensus parameter/torrc
option. For a given ratio r, if the relay has handled x cells of
measurement traffic recently, Tor then limits itself to y = xr/(1-r)
cells of non-measurement traffic this scheduling round.
If x is very small, the relay will perform the calculation s.t. x is the
number of cells required to produce 10 Mbit/s of measurement traffic, thus
ensuring some minimum amount of background traffic is allowed.

[XXX teor suggests in [4] that the number 10 Mbit/s could be derived more
intelligently. E.g. based on AuthDirFastGuarantee or
AuthDirGuardBWGuarantee]

## 3.2 FlashFlow Components

The FF coordinator and measurer code will reside in a FlashFlow
repository separate from little-t tor.

There are three notable parameters for which a FF deployment must choose
values. They are:

- The number of sockets, s, the measurers should open, in aggregate,
  with the target relay. We suggest s=160 based on the FF paper.
- The bandwidth multiplier, m. Given an existing capacity estimate for
  a relay, z, the coordinator will instruct the measurers to, in
  aggregate, send m*z Mbit/s to the target relay. We recommend m=2.25.
- The measurement duration, d. Based on the FF paper, we recommend
  d=30 seconds.

The rest of this section first discusses notable functions of the
FlashFlow coordinator, then goes on to discuss FF measurer code that
will require supporting tor code.

### 3.2.1 FlashFlow Coordinator

The coordinator is responsible for scheduling measurements, aggregating
results, and producing v3bw files. It needs continuous access to new
consensus files, which it can obtain by running an accompanying Tor
process in client mode.

The coordinator has the following functions, which will be described in
this section:

- result aggregation.
- schedule measurements.
- v3bw file generation.

#### 3.2.1.1 Aggregating Results

Every second during a measurement, the measurers send the amount of
verified measurement traffic they have received back from the relay.
Additionally, the relay sends a MEAS_BG cell each second to the
coordinator with amount of non-measurement background traffic it is
sending and receiving.

For each second's reports, the coordinator sums the measurer's reports.
The coordinator takes the minimum of the relay's reported sent and
received background traffic. If, when compared to the measurer's reports
for this second, the relay's claimed background traffic is more than
what's allowed by the background/measurement traffic ratio, then the
coordinator further clamps the relay's report down. The coordinator adds
this final adjusted amount of background traffic to the sum of the
measurer's reports.

Once the coordinator has done the above for each second in the
measurement (e.g. 30 times for a 30 second measurement), the coordinator
takes the median of the 30 per-second throughputs and records it as the
estimated capacity of the target relay.

#### 3.2.1.2 Measurement Schedule

The short term implementation of measurement scheduling will be simpler
than the long term one due to (1) there only being one FlashFlow
deployment, and (2) there being very few relays that support being
measured by FlashFlow. In fact the FF coordinator will maintain a list
of the relays that have updated to support being measured and have opted
in to being measured, and it will only measure them.

The coordinator divides time into a series of 24 hour periods, commonly
referred to as days. Each period has measurement slots that are longer
than a measurement lasts (30s), say 60s, to account for pre- and
post-measurement work. Thus with 60s slots there's 1,440 slots in a
day.

At the start of each day the coordinator considers the list of relays
that have opted in to being measured. From this list of relays, it
repeatedly takes the relay with the largest existing capacity estimate.
It selects a random slot. If the slot has existing relays assigned to
it, the coordinator makes sure there is enough additional measurer
capacity to handle this relay. If so, it assigns this relay to this
slot. If not, it keeps picking new random slots until one has sufficient
additional measurer capacity.

Relays without existing capacity estimates are assumed to have the 75th
percentile capacity of the current network.

If a relay is not online when it's scheduled to be measured, it doesn't
get measured that day.

##### 3.2.1.2.1 Example

Assume the FF deployment has 1 Gbit/s of measurer capacity. Assume the
chosen multiplier m=2. Assume there are only 5 slots in a measurement
period.

Consider a set of relays with the following existing capacity estimates
and that have opted in to being measured by FlashFlow.

- 500 Mbit/s
- 300 Mbit/s
- 250 Mbit/s
- 200 Mbit/s
- 100 Mbit/s
-  50 Mbit/s

The coordinator takes the largest relay, 500 Mbit/s, and picks a random
slot for it. It picks slot 3. The coordinator takes the next largest,
300, and randomly picks slot 2. The slots are now:

```
   0   |   1   |   2   |   3   |   4
-------|-------|-------|-------|-------
       |       |  300  |  500  |
       |       |       |       |
```

The coordinator takes the next largest, 250, and randomly picks slot 2.
Slot 2 already has 600 Mbit/s of measurer capacity reserved (300*m);
given just 1000 Mbit/s of total measurer capacity, there is just 400
Mbit/s of spare capacity while this relay requires 500 Mbit/s. There is
not enough room in slot 2 for this relay. The coordinator picks a new
random slot, 0.

```
   0   |   1   |   2   |   3   |   4
-------|-------|-------|-------|-------
  250  |       |  300  |  500  |
       |       |       |       |
```

The next largest is 200 and the coordinator randomly picks slot 2 again
(wow!). As there is just enough spare capacity, the coordinator assigns
this relay to slot 2.

```
   0   |   1   |   2   |   3   |   4
-------|-------|-------|-------|-------
  250  |       |  300  |  500  |
       |       |  200  |       |
```

The coordinator randomly picks slot 4 for the last remaining relays, in
that order.

```
   0   |   1   |   2   |   3   |   4
-------|-------|-------|-------|-------
  250  |       |  300  |  500  |  100
       |       |  200  |       |   50
```

#### 3.2.1.3 Generating V3BW files

Every hour the FF coordinator produces a v3bw file in which it stores
the latest capacity estimate for every relay it has measured in the last
week. The coordinator will create this file on the host's local file
system. Previously-generated v3bw files will not be deleted by the
coordinator. A symbolic link at a static path will always point to the
latest v3bw file.

```
$ ls -l
v3bw -&gt; v3bw.2020-03-01-05-00-00
v3bw.2020-03-01-00-00-00
v3bw.2020-03-01-01-00-00
v3bw.2020-03-01-02-00-00
v3bw.2020-03-01-03-00-00
v3bw.2020-03-01-04-00-00
v3bw.2020-03-01-05-00-00
```

[XXX Either FF should auto-delete old ones, logrotate config should be
provided, a script provided, or something to help bwauths not accidentally
fill up their disk]

[XXX What's the approxmiate disk usage for, say, a few years of these?]

### 3.2.2 FlashFlow Measurer

The measurers take commands from the coordinator, connect to target
relays with many sockets, send them traffic, and verify the received
traffic is the same as what was sent.

Notable new things that internal tor code will need to do on the
measurer (client) side:

1. Open many TLS+TCP connections to the same relay on purpose.

#### 3.2.2.1 Open many connections

FlashFlow prototypes needed to "hack in" a flag in the
open-a-connection-with-this-relay function call chain that indicated
whether or not we wanted to force a new connection to be created. Most
of Tor doesn't care if it reuses an existing connection, but FF does
want to create many different connections. The cleanest way to
accomplish this will be investigated.

On the relay side, these measurer connections do not count towards DoS
detection algorithms.

## 3.3 Security

In this section we discuss the security of various aspects of FlashFlow
and the tor changes it requires.

### 3.3.1 Weight Inflation

Target relays are an active part of the measurement process; they know
they are getting measured. While a relay cannot fake the measurement
traffic, it can trivially stop transferring client background traffic
for the duration of the measurement yet claim it carried some. More
generally, there is no verification of the claimed amount of background
traffic during the measurement. The relay can claim whatever it wants,
but it will not be trusted above the ratio the FlashFlow deployment is
configured to know. This places an easy to understand, firm, and (if set
as we suggest) low cap on how much a relay can inflate its measured
capacity.

Consider a background/measurement ratio of 1/4, or 25%. Assume the relay
in question has a hard limit on capacity (e.g. from its NIC) of 100
Mbit/s. The relay is supposed to use up to 25% of its capacity for
background traffic and the remaining 75%+ capacity for measurement
traffic. Instead the relay ceases carrying background traffic, uses all
100 Mbit/s of capacity to handle measurement traffic, and reports ~33
Mbit/s of background traffic (33/133 = ~25%). FlashFlow would trust this
and consider the relay capable of 133 Mbit/s. (If the relay were to
report more than ~33 Mbit/s, FlashFlow limits it to just ~33 Mbit/s.)
With r=25%, FlashFlow only allows 1.33x weight inflation.

Prior work shows that Torflow allows weight inflation by a factor of 89x
[0] or even 177x [1].

The ratio chosen is a trade-off between impact on background traffic and
security: r=50% allows a relay to double its weight but won't impact
client traffic for relays with steady state throughput below 50%, while
r=10% allows a very low inflation factor but will cause throttling of
client traffic at far more relays. We suggest r=25% (and thus
1/(1-0.25)=1.33x inflation) for a reasonable trade-off between
performance and security.

It may be possible to catch relays performing this attack, especially if
they literally drop all background traffic during the measurement: have
the measurer (or some party on its behalf) create a regular stream
through the relay and measure the throughput on the stream
before/during/after the measurement. This can be explored longer term.

### 3.3.2 Incomplete Authentication

The short term FlashFlow implementation has the relay set two torrc
options if they would like to allow themselves to be measured: a flag
allowing measurement, and the list of coordinator TLS certificate that
are allowed to start a measurement.

The relay drops MEAS_PARAMS cells from coordinators it does not trust,
and immediately closes the connection after that. A FF coordinator
cannot convince a relay to enter measurement mode unless the relay
trusts its TLS certificate.

A trusted coordinator specifies in the MEAS_PARAMS cell the IP addresses
of the measurers the relay shall expect to connect to it shortly. The
target adds the measurer IP addresses to a whitelist in the DoS
connection limit system, exempting them from any configured connection
limit. If a measurer is behind a NAT, an adversary behind the same NAT
can DoS the relay's available sockets until the end of the measurement.
The adversary could also pretend to be the measurer. Such an adversary
could induce measurement failures and inaccuracies. (Note: the whitelist
is cleared after the measurement is over.)

# 4. FlashFlow measurement system: Medium term

The medium term deployment stage begins after FlashFlow has been
implemented and relays are starting to update to a version of Tor that
supports it.

New link- and relay-subprotocol versions will be used by the relay to
indicate
FF support. E.g. at the time of writing, the next relay subprotocol
version is
4 [3].

We plan to host a FlashFlow deployment consisting of a FF coordinator
and a single FF measurer on a single 1 Gbit/s machine. Data produced by
this deployment will be made available (semi?) publicly, including both
v3bw files and intermediate results.

Any development changes needed during this time would go through
separate proposals.

# 5. FlashFlow measurement system: Long term

In the long term, finishing-touch development work will be done,
including adding better authentication and measurement scheduling, and
experiments will be run to determine the best way to integrate FlashFlow
into the Tor ecosystem.

Any development changes needed during this time would go through
separate proposals.

## 5.1 Authentication to Target Relay

Short term deployment already had FlashFlow coordinators using TLS
certificates when connecting to relays, but in the long term, directory
authorities will vote on the consensus parameter for which coordinators
should be allowed to perform measurements. The voting is done in the
same way they currently vote on recommended tor versions.

FlashFlow measurers will be updated to use TLS certificates when
connecting to relays too. FlashFlow coordinators will update the
contents of MEAS_PARAMS cells to contain measurer TLS certificates
instead of IP addresses, and relays will update to expect this change.

## 5.2 Measurement Scheduling

Short term deployment only has one FF deployment running. Long term this
may no longer be the case because, for example, more than one directory
authority decides to adopt it and they each want to run their own
deployment. FF deployments will need to coordinate between themselves
to not measure the same relay at the same time, and to handle new relays
as they join during the middle of a measurement period (during the day).

The measurement scheduling process shall be non-interactive. All the inputs
(e.g. the shared random value, the identities of the coords, the relays
currently in the network) are publicly known to (at least) the bwauths, thus
each individual bwauth can calculate same multi-coord measurement schedule.

The following is quoted from Section 4.3 of the FlashFlow paper.

    To measure all relays in the network, the BWAuths periodically
    determine the measurement schedule. The schedule determines when and
    by whom a relay should be measured. We assume that the BWAuths have
    sufficiently synchronized clocks to facilitate coordinating their
    schedules. A measurement schedule is created for each measurement
    period, the length p of which determines how often a relay is
    measured. We use a measurement period of p = 24 hours.

    To help avoid active denial-of-service attacks on targeted relays,
    the measurement schedule is randomized and known only to the
    BWAuths. Before the next measurement period starts, the BWAuths
    collectively generate a random seed (e.g. using Tor's
    secure-randomness protocol). Each BWAuth can then locally determine
    the shared schedule using pseudorandom bits extracted from that
    seed. The algorithm to create the schedule considers each
    measurement period to be divided into a sequence of t-second
    measurement slots. For each old relay, slots for each BWAuth to
    measure it are selected uniformly at random without replacement
    from all slots in the period that have sufficient unallocated
    measurement capacity to accommodate the measurement. When a new
    relay appears, it is measured separately by each BWAuth in the first
    slots with sufficient unallocated capacity. Note that this design
    ensures that old relays will continue to be measured, with new
    relays given secondary priority in the order they arrive.

[XXX Teor leaves good ideas in his tor-dev@ post [5],
including a good plain language description of what the FF paper quotes
says,
and a recommendation on which consensus to use when making a new schedule]

A problem arises when two relays are hosted on the same machine but measured
at different times: they both will be measured to have the full capacity of
their host. At the very least, the scheduling algo should schedule
relays with
the same IP to be measured at the same time. Perhaps better is measuring all
relays in the same MyFamily, same ipv4/24, and/or same ipv6/48 at the same
time. What specifically to do here is left for medium/long term work.

## 5.3 Experiments

   [XXX todo]

## 5.4 Other Changes/Investigations/Ideas

- How can FlashFlow data be used in a way that doesn't lead to poor load
  balancing given the following items that lead to non-uniform client
  behavior:
    - Guards that high-traffic HSs choose (for 3 months at a time)
    - Guard vs middle flag allocation issues
    - New Guard nodes (Guardfraction)
    - Exit policies other than default/all
    - Directory activity
    - Total onion service activity
    - Super long-lived circuits
- Add a cell that the target relay sends to the coordinator indicating
  its CPU and memory usage, whether it has a shortage of sockets, how
  much bandwidth load it has been experiencing lately, etc. Use this
  information to lower a relays weight, never increase.
- If FlashFlow and sbws work together (as opposed to FlashFlow replacing
  sbws), consider logic for how much sbws can increase/decrease FF
  results
- Coordination of multiple FlashFlow deployments: scheduling of
  measurements, seeding schedule with shared random value.
- Other background/measurement traffic ratios. Dynamic? (known slow
  relay =&gt; more allowed bg traffic?)
- Catching relays inflating their measured capacity by dropping
  background traffic.
- What to do about co-located relays. Can they be detected reliably?
  Should we just add a torrc option a la MyFamily for co-located relays?
- What is the explanation for dennis.jackson's scary graphs in this [2]
  ticket?  Was it because of the speed test? Why? Will FlashFlow produce
  the same behavior?

# Citations

[0] F. Thill. Hidden Service Tracking Detection and Bandwidth Cheating
    in Tor Anonymity Network. Master's thesis, Univ. Luxembourg, 2014.

https://www.cryptolux.org/images/b/bc/Tor_Issues_Thesis_Thill_Fabrice.pdf
[1] A. Johnson, R. Jansen, N. Hopper, A. Segal, and P. Syverson.
    PeerFlow: Secure Load Balancing in Tor. Proceedings on Privacy
    Enhancing Technologies (PoPETs), 2017(2), April 2017.
    https://ohmygodel.com/publications/peerflow-popets2017.pdf
[2] Mike Perry: Graph onionperf and consensus information from Rob's
    experiments
    https://trac.torproject.org/projects/tor/ticket/33076
[3] tor-spec.txt Section 9.3 "Relay" Subprotocol versioning
    https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2132
[4] Teor's second respose to FlashFlow proposal
    https://lists.torproject.org/pipermail/tor-dev/2020-April/014251.html
[5] Teor's first respose to FlashFlow proposal
    https://lists.torproject.org/pipermail/tor-dev/2020-April/014246.html

# Appendix A: Save CPU at measurer by not encrypting all MEAS_ECHO cells

## Verify echo cells

A parameter will exist to tell the measurers with what frequency they
shall verify that cells echoed back to them match what was sent. This
parameter does not need to exist outside of the FF deployment (e.g. it
doesn't need to be a consensus parameter).

The parameter instructs the measurers to check 1 out of every N cells.

The measurer keeps a count of how many measurement cells it has sent. It
also logically splits its output stream of cells into buckets of size N.
At the start of each bucket (when num_sent % N == 0), the measurer
chooses a random index in the bucket. Upon sending the cell at that
index (num_sent % N == chosen_index), the measurer records the cell.

The measurer also counts cells that it receives. When it receives a cell
at an index that was recorded, it verifies that the received cell
matches the recorded sent cell. If they match, no special action is
taken. If they don't match, the measurer indicates failure to the
coordinator and target relay and closes all connections, ending the
measurement.

### Example

Consider bucket_size is 1000. For the moment ignore cell encryption.

We start at idx=0 and pick an idx in [0, 1000) to record, say 640. At
idx=640 we record the cell. At idx=1000 we choose a new idx in [1000,
2000) to record, say 1236. At idx=1236 we record the cell. At idx=2000
we choose a new idx in [2000, 3000). Etc.

There's 2000+ cells in flight and the measurer has recorded two items:

```
- (640, contents_of_cellA)
- (1236, contents_of_cellB)
```

Consider the receive side now. It counts the cells it receives. At
receive idx=640, it checks the received cell matches the saved cell from
before. At receive idx=1236, it again checks the received cell matches.
Etc.

### Motivation

A malicious relay may want to skip decryption of measurement cells to
save CPU cycles and obtain a higher capacity estimate. More generally,
it could generate fake measurement cells locally, ignore the measurement
traffic it is receiving, and flood the measurer with more traffic that
it (the measurer) is even sending.

The security of echo cell verification is discussed in section 3.3.1.

### Security

A smaller bucket size means more cells are checked and FF is more likely
to detect a malicious target. It also means more bookkeeping overhead
(CPU/RAM).

An adversary that knows bucket_size and cheats on one item out of every
bucket_size items will have a 1/bucket_size chance of getting caught in
the first bucket. This is the worst case adversary. While cheating on
just a single item per bucket yields very little advantage, cheating on
more items per bucket increases the likelihood the adversary gets
caught. Thus only the worst case is considered here.

In general, the odds the adversary can successfully cheat in a single
bucket are

```
(bucket_size-1)/bucket_size
```

Thus the odds the adversary can cheat in X consecutive buckets are

```
[(bucket_size-1)/bucket_size]^X
```

In our case, X will be highly varied: Slow relays won't see very many
buckets, but fast relays will. The damage to the network a very slow
relay can do by faking being only slightly faster is limited.
Nonetheless, for now we motivate the selection of bucket_size with a
slow relay:

- Assume a very slow relay of 1 Mbit/s capacity that will cheat 1 cell
  in each bucket. Assume a 30 second measurement.
- The relay will handle 1*30 = 30 Mbit of traffic during the
  measurement, or 3.75 MB, or 3.75 million bytes.
- Cells are 514 bytes. Approximately (e.g. ignoring TLS) 7300 cells
  will be sent/recv over the course of the measurement.
- A bucket_size of 50 results in about 146 buckets over the course of
  the 30s measurement.
- Therefore, the odds of the adversary cheating successfully as
  (49/50)^(146), or about 5.2%.

This sounds high, but a relay capable of double the bandwidth (2 Mbit/s)
will have (49/50)^(2*146) or 0.2% odds of success, which is quite low.

Wanting a &lt;1% chance that a 10 Mbit/s relay can successfully cheat
results in a bucket size of approximately 125:

- 10*30 = 300 Mbit of traffic during 30s measurement. 37.5 million
  bytes.
- 37,500,000 bytes / 514 bytes/cell = ~73,000 cells
- bucket_size of 125 cells means 73,000 / 125 = 584 buckets
- (124/125)^(584) = 0.918% chance of successfully cheating

Slower relays can cheat more easily but the amount of extra weight they
can obtain is insignificant in absolute terms. Faster relays are
essentially unable to cheat.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20201017234329</emailId><senderName></senderName><senderEmail>"jansen, robert g civ usn nrl (5543) washington dc (usa)" &lt;rob.g.jansen</senderEmail><timestampReceived>2020-10-17 23:43:29-0400</timestampReceived><subject>[tor-dev] Statistical inference in live network perf experiments</subject><body>

Hello Mike and David!

I see that we are in the process of testing some changes to KIST parameters, and have \
more upcoming perf experiments planned. It will be great to gather additional \
information to help us better understand how to improve Tor performance :)

My main concern about running experiments on the live network is the lack of control \
[0] across the uncountable number of confounding variables present across the \
network.

Because of the lack of control, I strongly advise that statistical inference \
techniques are applied when conducting the experiments and analyzing the results. \
Ideally you will estimate and quantify sources of systematic error. Repeated trials \
and A/B testing (when that makes sense) will help increase our confidence in your \
results.

We have some recent work on these topics (in submission). DM if you are interested in \
a copy of the paper.

Peace, love, and positivity,
Rob

[0] https://en.wikipedia.org/wiki/Scientific_control
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201112191944</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2020-11-12 19:19:44-0400</timestampReceived><subject>[tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/alternative)]


Hi there,

So I have a new email encryption system which requires that the user has
the specific key file generated for a message rather than the password,
specifically this software generates a unique key file for a specific
message every time a message is created. The user then enters the date and
time the message was created. Without the original key file the message
can't be opened;

https://www.youtube.com/watch?v=R0W7OVdNrOA

Here is a video showing the software. I've built it for Windows and Mac OS.
I was wondering if this could be implemented in tor. I think it would be an
interesting idea for a tor based email system to make the messages
unrecoverable after use.

OS: Windows, Mac OS

What do you think?


--Keifer

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi there,  &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So I have a new email encryption system \
which requires that the user has the specific  key file generated for a message \
rather than the password, specifically this software generates a unique key file for \
a specific message every time a message  is created. The user then enters the date \
and time the message was created. Without the original key file the message can't \
be opened;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://www.youtube.com/watch?v=R0W7OVdNrOA"&gt;https://www.youtube.com/watch?v=R0W7OVdNrOA&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here \
is a video showing the software. I've built it for Windows and Mac OS. I was \
wondering if this  could be implemented in tor. I think it would be an interesting \
idea for a tor based email system to make the messages unrecoverable after \
use.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;OS: Windows, Mac OS&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What do \
you think?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br clear="all"&gt;&lt;div&gt;&lt;div dir="ltr" \
class="gmail_signature" data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201112212657</emailId><senderName>Santiago Torres-Arias</senderName><senderEmail>santiago@archlinux.org</senderEmail><timestampReceived>2020-11-12 21:26:57-0400</timestampReceived><subject>Re: [tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer Bly wrote:
&gt; Hi there,

Hello,

&gt; So I have a new email encryption system which requires that the user has
&gt; the specific key file generated for a message rather than the password,
&gt; specifically this software generates a unique key file for a specific
&gt; message every time a message is created. The user then enters the date and
&gt; time the message was created. Without the original key file the message
&gt; can't be opened;
&gt;
&gt; https://www.youtube.com/watch?v=R0W7OVdNrOA
&gt;
&gt; Here is a video showing the software. I've built it for Windows and Mac OS.
&gt; I was wondering if this could be implemented in tor. I think it would be an
&gt; interesting idea for a tor based email system to make the messages
&gt; unrecoverable after use.

I'm not a tor-dev, so I can't comment on the interest, but it appears to
me that the value added of this idea (basically, using time to seed a
PRF/KDF) is very little. All in all, using time to seed keys is not the
best idea. It also seems to be on top of PGP, so I'm pretty convinced
this doesn't provide perfect forward-secrecy unless you're layering any
sort of session key ratcheting mechanism yourself.

I think the goal is laudable, but I suggest getting a little bit more
involved in cryptography engineering communities to see learn, develop
and eventually help change the status quo.

Cheers!
-S

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201113011938</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2020-11-13 01:19:38-0400</timestampReceived><subject>Re: [tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/alternative)]


Well, the mechanism is that it overwrites the key ever time, so each
message has its own unique key, also the receiver needs to verify the key
file with the built in tool to be able to use it. So an attacker does not
know this the only way to get this information is from the person that
created the message as the need when the OS originally generated the
message, not when it was uploaded as an attachment somewhere. That's what I
was thinking. I will look into the communities suggested, thanks very much.
--Keifer


On Thu, Nov 12, 2020 at 1:27 PM Santiago Torres-Arias &lt;
santiago@archlinux.org&gt; wrote:

&gt; On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer Bly wrote:
&gt; &gt; Hi there,
&gt;
&gt; Hello,
&gt;
&gt; &gt; So I have a new email encryption system which requires that the user has
&gt; &gt; the specific key file generated for a message rather than the password,
&gt; &gt; specifically this software generates a unique key file for a specific
&gt; &gt; message every time a message is created. The user then enters the date
&gt; and
&gt; &gt; time the message was created. Without the original key file the message
&gt; &gt; can't be opened;
&gt; &gt;
&gt; &gt; https://www.youtube.com/watch?v=R0W7OVdNrOA
&gt; &gt;
&gt; &gt; Here is a video showing the software. I've built it for Windows and Mac
&gt; OS.
&gt; &gt; I was wondering if this could be implemented in tor. I think it would be
&gt; an
&gt; &gt; interesting idea for a tor based email system to make the messages
&gt; &gt; unrecoverable after use.
&gt;
&gt; I'm not a tor-dev, so I can't comment on the interest, but it appears to
&gt; me that the value added of this idea (basically, using time to seed a
&gt; PRF/KDF) is very little. All in all, using time to seed keys is not the
&gt; best idea. It also seems to be on top of PGP, so I'm pretty convinced
&gt; this doesn't provide perfect forward-secrecy unless you're layering any
&gt; sort of session key ratcheting mechanism yourself.
&gt;
&gt; I think the goal is laudable, but I suggest getting a little bit more
&gt; involved in cryptography engineering communities to see learn, develop
&gt; and eventually help change the status quo.
&gt;
&gt; Cheers!
&gt; -S
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Well, the mechanism  is that it  overwrites the key ever time, so each \
message has its own unique key, also the receiver  needs to verify the key file with \
the built in tool to be able to use it. So an attacker does not know this the only \
way to get this information is from the person that created the message as the need \
when the OS originally generated the message, not when it was uploaded as an \
attachment somewhere. That's what I was thinking. I will look into the \
communities suggested, thanks very much. --Keifer  &lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Thu, Nov 12, 2020 at 1:27 PM \
Santiago Torres-Arias &lt;&lt;a href="mailto:santiago@archlinux.org" \
target="_blank"&gt;santiago@archlinux.org&lt;/a&gt;&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer \
Bly wrote:&lt;br&gt; &gt; Hi there,&lt;br&gt;
&lt;br&gt;
Hello,&lt;br&gt;
&lt;br&gt;
&gt; So I have a new email encryption system which requires that the user has&lt;br&gt;
&gt; the specific key file generated for a message rather than the password,&lt;br&gt;
&gt; specifically this software generates a unique key file for a specific&lt;br&gt;
&gt; message every time a message is created. The user then enters the date and&lt;br&gt;
&gt; time the message was created. Without the original key file the message&lt;br&gt;
&gt; can't be opened;&lt;br&gt;
&gt;&lt;br&gt;
&gt; &lt;a href="https://www.youtube.com/watch?v=R0W7OVdNrOA" rel="noreferrer" \
target="_blank"&gt;https://www.youtube.com/watch?v=R0W7OVdNrOA&lt;/a&gt;&lt;br&gt; &gt;&lt;br&gt;
&gt; Here is a video showing the software. I've built it for Windows and Mac \
OS.&lt;br&gt; &gt; I was wondering if this could be implemented in tor. I think it would be \
an&lt;br&gt; &gt; interesting idea for a tor based email system to make the messages&lt;br&gt;
&gt; unrecoverable after use.&lt;br&gt;
&lt;br&gt;
I'm not a tor-dev, so I can't comment on the interest, but it appears to&lt;br&gt;
me that the value added of this idea (basically, using time to seed a&lt;br&gt;
PRF/KDF) is very little. All in all, using time to seed keys is not the&lt;br&gt;
best idea. It also seems to be on top of PGP, so I'm pretty convinced&lt;br&gt;
this doesn't provide perfect forward-secrecy unless you're layering any&lt;br&gt;
sort of session key ratcheting mechanism yourself.&lt;br&gt;
&lt;br&gt;
I think the goal is laudable, but I suggest getting a little bit more&lt;br&gt;
involved in cryptography engineering communities to see learn, develop&lt;br&gt;
and eventually help change the status quo.&lt;br&gt;
&lt;br&gt;
Cheers!&lt;br&gt;
-S&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201203021850</emailId><senderName>Dmitry Khutornoy</senderName><senderEmail>khutord435@gmail.com</senderEmail><timestampReceived>2020-12-03 02:18:50-0400</timestampReceived><subject>Re: [tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/alternative)]


Hey, I left some comments on the video, I am not a Tor developer but I
think I made some valid points, please respond to them

Thanks and Regards

On Wed, Dec 2, 2020 at 4:10 PM Wisdom With Rahul &lt;rahulbhatia172@gmail.com&gt;
wrote:

&gt; This idea is interesting but who owns all the keys?
&gt;
&gt; Thanks and regards!
&gt;
&gt;
&gt;
&gt;
&gt; On Fri 13 Nov, 2020, 6:49 AM Keifer Bly, &lt;keifer.bly@gmail.com&gt; wrote:
&gt;
&gt;&gt; Well, the mechanism is that it overwrites the key ever time, so each
&gt;&gt; message has its own unique key, also the receiver needs to verify the key
&gt;&gt; file with the built in tool to be able to use it. So an attacker does not
&gt;&gt; know this the only way to get this information is from the person that
&gt;&gt; created the message as the need when the OS originally generated the
&gt;&gt; message, not when it was uploaded as an attachment somewhere. That's what I
&gt;&gt; was thinking. I will look into the communities suggested, thanks very much.
&gt;&gt; --Keifer
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Nov 12, 2020 at 1:27 PM Santiago Torres-Arias &lt;
&gt;&gt; santiago@archlinux.org&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer Bly wrote:
&gt;&gt;&gt; &gt; Hi there,
&gt;&gt;&gt;
&gt;&gt;&gt; Hello,
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; So I have a new email encryption system which requires that the user
&gt;&gt;&gt; has
&gt;&gt;&gt; &gt; the specific key file generated for a message rather than the password,
&gt;&gt;&gt; &gt; specifically this software generates a unique key file for a specific
&gt;&gt;&gt; &gt; message every time a message is created. The user then enters the date
&gt;&gt;&gt; and
&gt;&gt;&gt; &gt; time the message was created. Without the original key file the message
&gt;&gt;&gt; &gt; can't be opened;
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; https://www.youtube.com/watch?v=R0W7OVdNrOA
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; Here is a video showing the software. I've built it for Windows and
&gt;&gt;&gt; Mac OS.
&gt;&gt;&gt; &gt; I was wondering if this could be implemented in tor. I think it would
&gt;&gt;&gt; be an
&gt;&gt;&gt; &gt; interesting idea for a tor based email system to make the messages
&gt;&gt;&gt; &gt; unrecoverable after use.
&gt;&gt;&gt;
&gt;&gt;&gt; I'm not a tor-dev, so I can't comment on the interest, but it appears to
&gt;&gt;&gt; me that the value added of this idea (basically, using time to seed a
&gt;&gt;&gt; PRF/KDF) is very little. All in all, using time to seed keys is not the
&gt;&gt;&gt; best idea. It also seems to be on top of PGP, so I'm pretty convinced
&gt;&gt;&gt; this doesn't provide perfect forward-secrecy unless you're layering any
&gt;&gt;&gt; sort of session key ratcheting mechanism yourself.
&gt;&gt;&gt;
&gt;&gt;&gt; I think the goal is laudable, but I suggest getting a little bit more
&gt;&gt;&gt; involved in cryptography engineering communities to see learn, develop
&gt;&gt;&gt; and eventually help change the status quo.
&gt;&gt;&gt;
&gt;&gt;&gt; Cheers!
&gt;&gt;&gt; -S
&gt;&gt;&gt; _______________________________________________
&gt;&gt;&gt; tor-dev mailing list
&gt;&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;&gt;
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hey, I left some comments on the video, I am not a Tor developer but I \
think I made some valid points, please respond to them&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks and \
Regards&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On \
Wed, Dec 2, 2020 at 4:10 PM Wisdom With Rahul &lt;&lt;a \
href="mailto:rahulbhatia172@gmail.com"&gt;rahulbhatia172@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="auto"&gt;This \
idea is interesting but who owns all the keys?&lt;br&gt;&lt;br&gt;&lt;div&gt;Thanks and \
regards!&lt;br&gt;&lt;br&gt;&lt;br&gt;       &lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Fri 13 Nov, 2020, 6:49 AM Keifer Bly, &lt;&lt;a \
href="mailto:keifer.bly@gmail.com" target="_blank"&gt;keifer.bly@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="ltr"&gt;Well, \
the mechanism  is that it  overwrites the key ever time, so each message has its own \
unique key, also the receiver  needs to verify the key file with the built in tool to \
be able to use it. So an attacker does not know this the only way to get this \
information is from the person that created the message as the need when the OS \
originally generated the message, not when it was uploaded as an attachment \
somewhere. That's what I was thinking. I will look into the communities \
suggested, thanks very much. --Keifer  &lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Thu, Nov 12, 2020 at 1:27 PM \
Santiago Torres-Arias &lt;&lt;a href="mailto:santiago@archlinux.org" rel="noreferrer" \
target="_blank"&gt;santiago@archlinux.org&lt;/a&gt;&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer \
Bly wrote:&lt;br&gt; &gt; Hi there,&lt;br&gt;
&lt;br&gt;
Hello,&lt;br&gt;
&lt;br&gt;
&gt; So I have a new email encryption system which requires that the user has&lt;br&gt;
&gt; the specific key file generated for a message rather than the password,&lt;br&gt;
&gt; specifically this software generates a unique key file for a specific&lt;br&gt;
&gt; message every time a message is created. The user then enters the date and&lt;br&gt;
&gt; time the message was created. Without the original key file the message&lt;br&gt;
&gt; can't be opened;&lt;br&gt;
&gt;&lt;br&gt;
&gt; &lt;a href="https://www.youtube.com/watch?v=R0W7OVdNrOA" rel="noreferrer \
noreferrer" target="_blank"&gt;https://www.youtube.com/watch?v=R0W7OVdNrOA&lt;/a&gt;&lt;br&gt; \
&gt;&lt;br&gt; &gt; Here is a video showing the software. I've built it for Windows and \
Mac OS.&lt;br&gt; &gt; I was wondering if this could be implemented in tor. I think it \
would be an&lt;br&gt; &gt; interesting idea for a tor based email system to make the \
messages&lt;br&gt; &gt; unrecoverable after use.&lt;br&gt;
&lt;br&gt;
I'm not a tor-dev, so I can't comment on the interest, but it appears to&lt;br&gt;
me that the value added of this idea (basically, using time to seed a&lt;br&gt;
PRF/KDF) is very little. All in all, using time to seed keys is not the&lt;br&gt;
best idea. It also seems to be on top of PGP, so I'm pretty convinced&lt;br&gt;
this doesn't provide perfect forward-secrecy unless you're layering any&lt;br&gt;
sort of session key ratcheting mechanism yourself.&lt;br&gt;
&lt;br&gt;
I think the goal is laudable, but I suggest getting a little bit more&lt;br&gt;
involved in cryptography engineering communities to see learn, develop&lt;br&gt;
and eventually help change the status quo.&lt;br&gt;
&lt;br&gt;
Cheers!&lt;br&gt;
-S&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" rel="noreferrer" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" rel="noreferrer" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201008183435</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-10-08 18:34:35-0400</timestampReceived><subject>Re: [tor-dev] Update to Proposal 316: FlashFlow</subject><body>

Hi!  We had a meeting about FlashFlow today, including several of the
authors.  Here are the notes we wound up with for ideas and next
straps.

Easy changes:
    * Just use a PRNG; assume we can make them arbitrarily fast.
(example candidates: chacha8, shake128.)
    * Use relay identities as the identifiers for measurers, so that
we won't need a novel authentication scheme.
    * We can't call the list of measurer IDs a "network parameter",
since technically speaking network parameters have to be integers.  It
will have to be a different part of the consensus header.
    * Make sure that all of the declared ranges for network parameters
are as wide as they could possibly be; making these parameters take a
wider range is hard to change later.

Trickier but straightforward:
    * Describe how to avoid collisions with multiple coordinators
       - idea: exactly how it's specified in the paper ;) but a
simplier idea ...
       - idea: coord 1 measurers on day 1, c2 on d2, ... etc. for all
coords, then repeat
    * Describe how to aggregate all background measurements over the
full 30 seconds, and how to use that data.  (This may lower accuracy a
little, but makes some kinds of the analysis harder.) Idea: relay
reports *once* at end of measurement the total amount of bg traffic
and the coord simply divides that by the length of the measurement to
have a per-second average.
    * Mention whether relays should reserve sockets in case they get measured

More thinking may be needed:
    *  Summarize ideas for how multiple coordinators don't have to
share full schedules with one another. Possibly divide up the network
by days? [e.g., Coordinator 1 measures nodes in set X on Monday]
    * Would it work if we declare a maximum measurement fraction (eg
75% of bandwidth) but measurers only use that fraction in a few
measurements once in a while, and mostly they do less (eg 10% of
bandwidth).
    * Discuss migration: how do we use this data when not all relays
support being measured in this way?


In terms of implementation:
- identify the python parts that are different to sbws, create sbws
subpackages "ff measurer" and "ff coordinator" and add a config option
to run in 1 mode or other, to do not have yet another code base to
maintain

In terms of deployment:
- we currently don't have any automatic way to ensure net is still
"working properly", only some mostly-manual ways and some one-time
experiments. This has caused some relay operators to do not be happy
and some quite time to figure out the problem and solve it

In terms of coordination:
We're deploying sbws only 1 dirauth at a time and trying to ensure net
is still "working properly".
If we deploy ff, before we have deployed sbws in all bwauths and
ensure net is still "working properly", will be hard to see what is an
sbws bug or ff one or both


FlashFlow, the python code for coordinator, measurer, etc.
https://gitlab.torproject.org/pastly/flashflow

The rendered documentation for/from the above https://flashflow.pastly.xyz/

Tor repo with branch https://gitlab.torproject.org/pastly/tor/-/tree/ff-v2

The ticket with the concerning graphs attributable to "Rob's speedtest thing"
https://trac.torproject.org/projects/tor/ticket/33076
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200807174602</emailId><senderName>Kushal Das</senderName><senderEmail>mail@kushaldas.in</senderEmail><timestampReceived>2020-08-07 17:46:02-0400</timestampReceived><subject>Re: [tor-dev] CentOS 8 TOR Repo</subject><body>

On 07/08/20, Ladar Levison wrote:
&gt; It appears that installing TOR via the CentOS 8 DNF repo isn't working.
&gt; The pre-flight configuration check fails because the repo package was
&gt; built using zstd 1.4.4, and CentOS 8 is currently providing zstd 1.4.2.
&gt; 

Thank you for the report.

&gt; For any that cares to try, the repo is at:
&gt; https://rpm.torproject.org/centos/8/
&gt; 

Our rpm repo for CentOS/RHEL requires EPEL repository enabled. It is the
step 1 in our documentation [0].

You can see the upstream build of the zstd package at [1].


[0] https://support.torproject.org/rpm/
[1] https://koji.fedoraproject.org/koji/buildinfo?buildID=1429450

Kushal
-- 
Public Interest Technologist, Freedom of the Press Foundation
CPython Core Developer
Director, Python Software Foundation
https://kushaldas.in
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200602102858</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@torproject.org</senderEmail><timestampReceived>2020-06-02 10:28:58-0400</timestampReceived><subject>Re: [tor-dev] Moving key material out of the main tor process</subject><body>

David Goulet &lt;dgoulet@torproject.org&gt; wrote
Fri, 29 May 2020 09:41:51 -0400:

&gt; &gt; ## The idea of a vault component
&gt; &gt; 
&gt; &gt; ahf and others in the network team have been discussing the
&gt; &gt; possibility of a "vault" component in tor, for moving private keys out
&gt; &gt; of the tor process. Separating secret key material from the code
&gt; &gt; handling data from the network seems valuable and providing a
&gt; &gt; component making different implementations "pluggable" would allow for
&gt; &gt; anyone to use their favourite technology without touching the tor
&gt; &gt; code base. Examples are local trusted execution environments like Intel
&gt; &gt; SGX and Arm TrustZone and various HSM's and security keys/tokens.
&gt; &gt; 
&gt; &gt; One way of implementing this would be to define a protocol, for a
&gt; &gt; vault component to talk to a daemon running on the same host as tor,
&gt; &gt; over some IPC mechanism. This protocol would allow tor to request a
&gt; &gt; signature over a hash, or a document, in a certain key. Whether the
&gt; &gt; daemon has access to the key material or has to forward the request to
&gt; &gt; a separate device or hardware component is irrelevant to the protocol
&gt; &gt; and the vault component.
&gt; &gt; 
&gt; &gt; Even if the design focuses on signatures it should probably take
&gt; &gt; encryption and decryption into account, to be added later.
&gt; 
&gt; Love it.

Glad to hear that there's support for the vault idea. Let's see if
TorHSM should use such a vault or not.


&gt; &gt; ## The vault as a possible match for TorHSM
&gt; &gt; 
&gt; &gt; Such a vault component would fit well with a project where Peter Stuge
&gt; &gt; and myself are building an HSM for Tor directory authority signing
&gt; &gt; keys [0] based on the CrypTech design [1].
&gt; &gt; 
&gt; &gt; [0] https://trac.cryptech.is/wiki/ExternalProjectsTorHSM&gt; [1] \
&gt; &gt; https://cryptech.is/&gt;  One of the options for tor to delegate the signing of \
&gt; &gt; votes and consensuses to such a device would be to use a vault component as
&gt; &gt; described above. We would then have a signing daemon responsible for
&gt; &gt; the USB communication with the TorHSM device. Another option would be
&gt; &gt; to build support directly into tor for communicating with the device,
&gt; &gt; through a library capable of a USB vendor specific protocol defined by
&gt; &gt; TorHSM.
&gt; &gt; 
&gt; &gt; There are pros and cons with both options. I'd like to hear what the
&gt; &gt; Tor developers community think would be best.

Do you have an opinion on the choice between a separate daemon and a
lib/torhsm?

The daemon way is the more generic and PT-like pluggable idea that also
involves quite some more work. I would probably need some help with
that.

The library option would be specific to this particular HSM and probably
not very reusable. I'd sort this out myself, given that an "asynchronous
signing API" (as discussed below) is in place.


&gt; &gt; ## Asynchronous signing API
&gt; &gt; 
&gt; &gt; Vault or not, tor needs to change the way signing is done to be able
&gt; &gt; to move key material out of the main process. First, external devices
&gt; &gt; may need more time to perform a signature operation than what tor can
&gt; &gt; accept to spend blocking in its main thread. Second, an external
&gt; &gt; device might disappear or malfunction, requiring the possibility for
&gt; &gt; an operation to time out.
&gt; &gt; 
&gt; &gt; This can be implemented either with callbacks or with a state machine
&gt; &gt; with more well defined state transitions. Maybe there are more
&gt; &gt; options that I didn't think of.
&gt; 
&gt; Right, I don't think this is any show stopper here. Signing with the long term
&gt; key material is not something that don't happens "often" and so adding delays
&gt; to it is probably negligible in the grand scheme of things.

As long as the time consumed waiting for signing operations to finish is
counted in seconds and not minutes this should indeed be negligible for
consensus periods of one hour, as in the public Tor network.

Two things to consider are test networks, which have substantially lower
consensus periods, and the rumour about a feature called variable
consensus periods.

I think that test networks could be dealt with by warning, or even
refusing to start, when a dirauth configured with a period shorter than
N minutes is also configured for having keys in an HSM.

The variable consensus period thing is something I heard about for the
first time at the Stockholm meeting last year. I'm still not certain
that it exists. Does anybody have a pointer?


&gt; &gt; ## Protocol choice
&gt; &gt; 
&gt; &gt; If we decide to go for the vault component with a separate daemon we
&gt; &gt; should consider using the ssh-agent protocol for tor to talk to the
&gt; &gt; daemon. Apart from being already defined there are multiple well
&gt; &gt; tested implementations of this protocol. It also has a couple of
&gt; &gt; features we might want, such as forgetting a certain key and
&gt; &gt; locking/unlocking of the vault. Finally, it's extensible and should
&gt; &gt; accommodate potential additions we might want to make later.
&gt; 
&gt; That is a _great_ idea in my opinion. It is robust, maintained by serious
&gt; people/project and did through the test of time!
&gt; 
&gt; I'm very excited about this "proposal" especially for relays and dirauth.

Happy to hear that! What do you think would be a good next step? A
decision about state machine vs. callbacks might be a good start. How
would this be made? I'm happy to take a stab at implementing either,
preferable with someone in the network team at my side.


&gt; However, I do wonder about onion services here because one difference here is
&gt; that for v3 onion service offline key to work, the operator needs to derive a
&gt; series of keys (blinded keys) from the master key which implies secret key
&gt; material access so maybe something we could discuss with HSM token designer
&gt; that is this concept of "key derivation" from the secret material. And who
&gt; knows, maybe they have?

Looking at the most famous API for talking to HSM's, PKCS#11, there's
indeed the concept of "key derivation", for example through the
C_DeriveKey[0] function. What the chances are that any HSM is doing
exactly what's laid out in rend-spec-v3.txt A.2 [1] I don't know yet.

[0] http://docs.oasis-open.org/pkcs11/pkcs11-base/v2.40/errata01/os/pkcs11-base-v2.40-errata01-os-complete.html#_Toc441755812
 [1] https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n2267
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200602155107</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-06-02 15:51:07-0400</timestampReceived><subject>Re: [tor-dev] Moving key material out of the main tor process</subject><body>

On Wed, May 20, 2020 at 11:46 AM Linus Nordberg &lt;linus@torproject.org&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; tl;dr How to move key material out of tor?
&gt;
&gt; ## The idea of a vault component
&gt;
&gt; ahf and others in the network team have been discussing the
&gt; possibility of a "vault" component in tor, for moving private keys out
&gt; of the tor process. Separating secret key material from the code
&gt; handling data from the network seems valuable and providing a
&gt; component making different implementations "pluggable" would allow for
&gt; anyone to use their favourite technology without touching the tor
&gt; code base. Examples are local trusted execution environments like Intel
&gt; SGX and Arm TrustZone and various HSM's and security keys/tokens.
&gt;
&gt; One way of implementing this would be to define a protocol, for a
&gt; vault component to talk to a daemon running on the same host as tor,
&gt; over some IPC mechanism. This protocol would allow tor to request a
&gt; signature over a hash, or a document, in a certain key. Whether the
&gt; daemon has access to the key material or has to forward the request to
&gt; a separate device or hardware component is irrelevant to the protocol
&gt; and the vault component.
&gt;
&gt; Even if the design focuses on signatures it should probably take
&gt; encryption and decryption into account, to be added later.


Hi!

I'm also +1 on this idea, and I think you're correct to hint that the
"vault" or "separate daemon" part doesn't have to be a tor-specific
tool.  Moving responsibilities out of the core Tor process should help
us make it harder for keys to leak.

One issue with the ssh-agent protocol as I see it is that it isn't
originally designed for decryption or for high-volume usage.  If we
want to support those in the future, we'll need to make sure that we
have an extension path for them in whatever vault tool we're using.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200402193012</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-04-02 19:30:12-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]


On 02 Apr (18:54:59), George Kadianakis wrote:
&gt; Hello list,
&gt; 
&gt; hope everyone is safe and doing well!
&gt; 
&gt; I present you an initial draft of a proposal on PoW-based defences for
&gt; onion services under DoS.
&gt; 
&gt; The proposal is not finished yet and it needs tuning and fixing. There
&gt; are many places marked with XXX and TODO around the proposal that should
&gt; be addressed.
&gt; 
&gt; The important part is that looking at the numbers it does seem like this
&gt; proposal can work as a concept and serve its intended purpose. The most
&gt; handwavey parts of the proposal right now are [INTRO_QUEUE] and
&gt; [POW_SECURITY] and if this thing fails in the end, it's probably gonna
&gt; be something that slipped over there. Hence, we should polish these
&gt; sections before we proceed with any sort of engineering here.
&gt; 
&gt; In any case, I decided to send it to the list even in premature form, so
&gt; that it can serve as a stable point of reference in subsequent
&gt; discussions. It can also be found in my git repo:
&gt; https://github.com/asn-d6/torspec/tree/pow-over-intro
&gt; 
&gt; Cheers and stay safe!
&gt; 
&gt; ---
&gt; 
&gt; Filename: xxx-pow-over-intro-v1
&gt; Title: A First Take at PoW Over Introduction Circuits
&gt; Author: George Kadianakis
&gt; Created: 2 April 2020
&gt; Status: Draft
&gt; 
&gt; 0. Abstract
&gt; 
&gt; This proposal aims to thwart introduction flooding DoS attacks by introducing
&gt; a dynamic Proof-Of-Work protocol that occurs over introduction circuits.
&gt; 
&gt; 1. Motivation
&gt; 
&gt; So far our attempts at limiting the impact of introduction flooding DoS
&gt; attacks on onion services has been focused on horizontal scaling with
&gt; Onionbalance, optimizing the CPU usage of Tor and applying congestion control
&gt; using rate limiting. While these measures move the goalpost forward, a core
&gt; problem with onion service DoS is that building rendezvous circuits is a
&gt; costly procedure both for the service and for the network. If we ever hope to
&gt; have truly reachable global onion services, we need to make it harder for
&gt; attackers to overload the service with introduction requests.
&gt; 
&gt; This proposal achieves this by allowing onion services to specify an optional
&gt; dynamic proof-of-work scheme that its clients need to participate in if they
&gt; want to get served.
&gt; 
&gt; With the right parameters, this proof-of-work scheme acts as a gatekeeper to
&gt; block amplification attacks by attackers while letting legitimate clients
&gt; through.
&gt; 
&gt; 1.1. Threat model [THREAT_MODEL]
&gt; 
&gt; 1.1.1. Attacker profiles [ATTACKER_MODEL]
&gt; 
&gt; This proposal is written to thwart specific attackers. A simple PoW proposal
&gt; cannot defend against all and every DoS attack on the Internet, but there are
&gt; adverary models we can defend against.
&gt; 
&gt; Let's start with some adversary profiles:
&gt; 
&gt; "The script-kiddie"
&gt; 
&gt; The script-kiddie has a single computer and pushes it to its
&gt; limits. Perhaps it also has a VPS and a pwned server. We are talking about
&gt; an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
&gt; consider the total cost for this attacker to be zero $.
&gt; 
&gt; "The small botnet"
&gt; 
&gt; The small botnet is a bunch of computers lined up to do an introduction
&gt; flooding attack. Assuming 500 medium-range computers, we are talking about
&gt; an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
&gt; the upfront cost for this attacker to be about $400.
&gt; 
&gt; "The large botnet"
&gt; 
&gt; The large botnet is a serious operation with many thousands of computers
&gt; organized to do this attack. Assuming 100k medium-range computers, we are
&gt; talking about an attacker with total access to 200 Thz of CPU and 200 TB of
&gt; RAM. The upfront cost for this attacker is about $36k.
&gt; 
&gt; We hope that this proposal can help us defend against the script-kiddie
&gt; attacker and small botnets. To defend against a large botnet we would need
&gt; more tools in our disposal (see [FUTURE_WORK]).
&gt; 
&gt; {XXX: Do the above make sense? What other attackers do we care about? What
&gt; other metrics do we care about? Network speed? I got the botnet costs
&gt; from here [REF_BOTNET] Back up our claims of defence.}
&gt; 
&gt; 1.1.2. User profiles [USER_MODEL]
&gt; 
&gt; We have attackers and we have users. Here are a few user profiles:
&gt; 
&gt; "The standard web user"
&gt; 
&gt; This is a standard laptop/desktop user who is trying to browse the
&gt; web. They don't know how these defences work and they don't care to
&gt; configure or tweak them. They are gonna use the default values and if the
&gt; site doesn't load, they are gonna close their browser and be sad at Tor.
&gt; They run a 2Ghz computer with 4GB of RAM.
&gt; 
&gt; "The motivated user"
&gt; 
&gt; This is a user that really wants to reach their destination. They don't
&gt; care about the journey; they just want to get there. They know what's going
&gt; on; they are willing to tweak the default values and make their computer do
&gt; expensive multi-minute PoW computations to get where they want to be.
&gt; 
&gt; "The mobile user"
&gt; 
&gt; This is a motivated user on a mobile phone. Even tho they want to read the
&gt; news article, they don't have much leeway on stressing their machine to do
&gt; more computation.
&gt; 
&gt; We hope that this proposal will allow the motivated user to always connect
&gt; where they want to connect to, and also give more chances to the other user
&gt; groups to reach the destination.
&gt; 
&gt; 1.1.3. The DoS Catch-22 [CATCH22]
&gt; 
&gt; This proposal is not perfect and it does not cover all the use cases. Still,
&gt; we think that by covering some use cases and giving reachability to the
&gt; people who really need it, we will severely demotivate the attackers from
&gt; continuing the DoS attacks and hence stop the DoS threat all
&gt; together. Furthermore, by increasing the cost to launch a DoS attack, a big
&gt; class of DoS attackers will disappear from the map, since the expected ROI
&gt; will decrease.
&gt; 
&gt; 2. System Overview
&gt; 
&gt; 2.1. Tor protocol overview
&gt; 
&gt; +----------------------------------+
&gt; &gt; &gt; 
&gt; +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
&gt; &gt; Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
&gt; +-------+         +-----------+        |Verifier|           |             |
&gt; +--------+           |             |
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; 
&gt; &gt; +----------v---------+   |
&gt; &gt; &gt; Intro Priority Queue|   |
&gt; +---------+--------------------+---+
&gt; &gt; &gt; &gt; 
&gt; Rendezvous |  |  |
&gt; circuits |  |  |
&gt; v  v  v
&gt; 
&gt; 
&gt; 
&gt; The proof-of-work scheme specified in this proposal takes place during the
&gt; introduction phase of the onion service protocol. It's an optional mechanism
&gt; that only occurs if the service requires it. It can be enabled and disabled
&gt; either through its torrc or through the control port.
&gt; 
&gt; In summary, the following steps are taken for the protocol to complete:
&gt; 
&gt; 1) Service encodes PoW parameters in descriptor [DESC_POW]
&gt; 2) Client fetches descriptor and computes PoW [CLIENT_POW]
&gt; 3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
&gt; 4) Service verifies PoW and queues introduction based on PoW effort \
&gt; [SERVICE_VERIFY] 
&gt; 2.2. Proof-of-work overview
&gt; 
&gt; 2.2.1. Primitives
&gt; 
&gt; For our proof-of-work scheme we want to minimize the spread of resources
&gt; between a motivated attacker and legitimate clients. This means that we are
&gt; looking to minimize any benefits that GPUs or ACICs can offer to an attacker.
&gt; 
&gt; For this reason we chose argon2 [REF_ARGON2] as the hash function for our
&gt; proof-of-work scheme since it's well audited and GPU-resistant and to some
&gt; extend ASIC-resistant as well.
&gt; 
&gt; As a password hash function, argon2 by default outputs 32 bytes of hash, and
&gt; takes as primary input a message and a nonce/salt. For the purposes of this
&gt; specification we will define an argon2() function as:
&gt; uint8_t hash_output[32] = argon2(uint8_t *message, uint8_t *nonce)'.
&gt; 
&gt; See section [ARGON_PARAMS] for more information on the secondary inputs of
&gt; argon2.
&gt; 
&gt; 2.2.2. Dynamic PoW
&gt; 
&gt; DoS is a dynamic problem where the attacker's capabilities constantly change,
&gt; and hence we want our proof-of-work system to be dynamic and not stuck with a
&gt; static difficulty setting. Hence, instead of forcing clients to go below a
&gt; static target like in Bitcoin to be successful, we ask clients to "bid" using
&gt; their PoW effort. Effectively, a client gets higher priority the higher
&gt; effort they put into their proof-of-work. This is similar to how
&gt; proof-of-stake works but instead of staking coins, you stake work.

So this means that desktop users will be prioritized over mobile users
basically unless I make my phone use X% of battery?

&gt; 
&gt; The benefit here is that legitimate clients who really care about getting
&gt; access can spend a big amount of effort into their PoW computation, which
&gt; should guarantee access to the service given reasonable adversary models. See
&gt; [POW_SECURITY] for more details about these guarantees and tradeoffs.
&gt; 
&gt; 3. Protocol specification
&gt; 
&gt; 3.1. Service encodes PoW parameters in descriptor [DESC_POW]
&gt; 
&gt; This whole protocol starts with the service encoding the PoW parameters in
&gt; the 'encrypted' (inner) part of the v3 descriptor. As follows:
&gt; 
&gt; "pow-params" SP type SP seed-b64 SP expiration-time NL
&gt; 
&gt; [At most once]
&gt; 
&gt; type: The type of PoW system used. We call the one specified here "v1"
&gt; 
&gt; seed-b64: A random seed that should be used as the input to the PoW
&gt; hash function. Should be 32 random bytes encoded in base64
&gt; without trailing padding.
&gt; 
&gt; expiration-time: A timestamp after which the above seed expires and is
&gt; no longer valid as the input for PoW. It's needed so
&gt; that the size of our replay cache does not grow
&gt; infinitely. It should be set to an hour in the future
&gt; (+- some randomness).  {TODO: PARAM_TUNING}

Format is?

&gt; 
&gt; {XXX: Expiration time makes us even more susceptible to clock skews, but
&gt; it's needed so that our replay cache refreshes. How to fix this?
&gt; See [CLIENT_BEHAVIOR] for more details.}

Would probably allow some room like +/- 1 or 2 hours ... something like that
unless this would fill our replay cache?

&gt; 
&gt; 3.2. Client fetches descriptor and computes PoW [CLIENT_POW]
&gt; 
&gt; If a client receives a descriptor with "pow-params", it should assume that
&gt; the service is expecting a PoW input as part of the introduction protocol.

What happens with clients _without_ PoW support? They basically won't be able
to connect I suppose? Or be put in the prio queue at the service at the very
hand with work done = 0 ?

&gt; 
&gt; In such cases, the client should have been configured with a specific PoW
&gt; 'target' (which is a 32-byte integer similar to the 'target' of Bitcoin
&gt; [REF_TARGET]). See [POW_SECURITY] for more information of how such a target
&gt; should be set. For the purposes of this section, we will assume that the
&gt; target has been set automatically by Tor, or the user configured it manually.
&gt; 
&gt; Now the client parses the descriptor and extracts the PoW parameters. It
&gt; makes sure that the expiration-time has not expired and if it has, it needs
&gt; to fetch a new descriptor.
&gt; 
&gt; To complete the PoW the client follows the following logic:
&gt; 
&gt; a) Client generates 'nonce' as 32 random bytes.
&gt; b) Client derives 'seed' by decoding 'seed-b64'.
&gt; c) Client computes hash_output = argon2(seed, nonce)
&gt; d) Client interprets hash_output as a 32-byte big-endian integer.
&gt; e) Client checks if int(hash_output) &lt;= target.
&gt; e1) If yes, success! The client uses 'hash_output' as the hash and
&gt; 'nonce' and 'seed' as its inputs.
&gt; e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
&gt; increments it by one, and goes back to step (c).
&gt; 
&gt; At the end of the above procedure, the client should have a triplet
&gt; (hash_output, seed, nonce) that can be used as the answer to the PoW
&gt; puzzle. How quickly this happens depends solely on the 'target' parameter.
&gt; 
&gt; 3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]
&gt; 
&gt; Now that the client has an answer to the puzzle it's time to encode it into
&gt; an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
&gt; portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
&gt; [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
&gt; INTRODUCE1 cell only gets read by the onion service and is ignored by the
&gt; introduction point.
&gt; 
&gt; We propose a new EXT_FIELD_TYPE value:
&gt; 
&gt; [01] -- PROOF_OF_WORK
&gt; 
&gt; The EXT_FIELD content format is:
&gt; 
&gt; POW_VERSION    [1 byte]
&gt; POW_SEED       [32 bytes]
&gt; POW_NONCE      [32 bytes]
&gt; POW_OUTPUT     [32 bytes]
&gt; 
&gt; where:
&gt; 
&gt; POW_VERSION is 1 for the protocol specified in this proposal
&gt; POW_SEED is 'seed' from the section above
&gt; POW_NONCE is 'nonce' from the section above
&gt; POW_OUTPUT is 'hash_output' from the section above
&gt; 
&gt; {XXX: do we need POW_VERSION? Perhaps we can use EXT_FIELD_TYPE as version}

I would still keep it for the cost of 1 byte. Reason is that I think
EXT_FIELD_TYPE should denote a "type of extension" and in this case anything
related to PoW is 0x01. Then what comes next, depends on the POW_VERSION.

&gt; {XXX: do we need to encode the SEED? Perhaps we can ommit it since the
&gt; service already knows it. But what happens in cases of desynch, if client
&gt; has diff seed from service?}

Service has no way of notifying back the client that the PoW validation
failed... so the service should just use the seed it has meaning not needed?

&gt; {XXX: Do we need to include the output? Probably not. The service has to
&gt; compute it anyway during verification. What's the use?}

Same reason I would say. The only thing I could see that both the POW_SEED and
POW_OUTPUT would be "useful" is if they could avoid the service doing
validation by just comparing if these params?

&gt; 
&gt; This will increase the INTRODUCE1 payload size by 99 bytes since the
&gt; extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
&gt; present and currently set to 0 and the EXT_FIELD is 97 bytes. According to
&gt; ticket #33650, INTRODUCE1 cells currently have more than 200 bytes available.
&gt; 
&gt; 3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]
&gt; 
&gt; When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
&gt; should check its configuration on whether proof-of-work is required to
&gt; complete the introduction. If it's not required, the extension SHOULD BE
&gt; ignored. If it is required, the service follows the procedure detailed in
&gt; this section.
&gt; 
&gt; 3.4.1. PoW verification
&gt; 
&gt; To verify the client's proof-of-work the service extracts (hash_output,
&gt; seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:
&gt; 
&gt; 1) Make sure that the client's seed is identical to the active seed.
&gt; 2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
&gt; 3) Verify that 'hash_output =?= argon2(seed, nonce)

So wait, the service also has to do the PoW for each client by computing the
Argon2 hash for each cell? Or am I mis-understanding?

&gt; 
&gt; If any of these steps fail the service MUST ignore this introduction request
&gt; and abort the protocol.
&gt; 
&gt; If all the steps passed, then the circuit is added to the introduction queue
&gt; as detailed in section [INTRO_QUEUE].
&gt; 
&gt; 3.4.1.1. Replay protection [REPLAY_PROTECTION]
&gt; 
&gt; The service MUST NOT accept introduction requests with the same (seed, nonce)
&gt; tuple. For this reason a replay protection mechanism must be employed.
&gt; 
&gt; The simplest way is to use a simple hash table to check whether a (seed,
&gt; nonce) tuple has been used before for the actiev duration of a
&gt; seed. Depending on how long a seed stays active this might be a viable
&gt; solution with reasonable memory/time overhead.
&gt; 
&gt; If there is a worry that we might get too many introductions during the
&gt; lifetime of a seed, we can use a Bloom filter as our replay cache
&gt; mechanism. The probabilistic nature of Bloom filters means that sometimes we
&gt; will flag some connections as replays even if they are not; with this false
&gt; positive probability increasing as the number of entries increase. However,
&gt; with the right parameter tuning this probability should be negligible and
&gt; well handled by clients. {TODO: PARAM_TUNING}
&gt; 
&gt; 3.4.2. The Introduction Queue  [INTRO_QUEUE]
&gt; 
&gt; 3.4.2.1. Adding introductions to the introduction queue
&gt; 
&gt; When PoW is enabled and a verified introduction comes through, the service
&gt; instead of jumping straight into rendezvous, queues it and prioritizes it
&gt; based on how much effort was devoted by the client to PoW. This means that
&gt; introduction requests with high effort should be prioritized over those with
&gt; low effort.
&gt; 
&gt; To do so, the service maintains an "introduction priority queue" data
&gt; structure. Each element in that priority queue is an introduction request,
&gt; and its priority is the effort put into its PoW:
&gt; 
&gt; When a verified introduction comes through, the service interprets the PoW
&gt; hash as a 32-byte big-endian integer 'hash_int' and based on that integer it
&gt; inserts it into the right position of the priority_queue: The smallest
&gt; 'hash_int' goes forward in the queue. If two elements have the same value,
&gt; the older one has priority over the newer one.
&gt; {XXX: Is this operation with 32-bytes integers expensive? How to make cheaper?}
&gt; 
&gt; {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
&gt; effort what attacks can happen in various scenarios? Do we want to order on
&gt; time+effort?  Which scenarios and attackers should we examine here?}
&gt; 
&gt; {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can we
&gt; use WRED usefully?}

I think you'll be bound by the amount of data a connection inbuf can take
which has an upper bound of 32 cells each read event.

Then tor will have to empty at once the inbuf, queue all INTRODUCE2 cells (at
most 32) in that priority queue and once done, we would process it until we
return to handling the connection inbuf.

In other words, the queue size, with tor's architecture, is bound to the
number of cells upper bound you can get when doing a recv() pass which is 32
cells.

Nevertheless, that limit is weirdly hardcoded in tor so you should definitely
think of a way to upper bound the queue and just drop the rest. A good
starting point would be that 32 cells number?

&gt; 
&gt; 3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]
&gt; 
&gt; The service should handle introductions by pulling from the introduction
&gt; queue.
&gt; 
&gt; Similar to how our cell scheduler works, the onion service subsystem will
&gt; poll the priority queue every 100ms tick and process the first 20 cells from
&gt; the priority queue (if they exist). The service will perform the rendezvous
&gt; and the rest of the onion service protocol as normal.
&gt; 
&gt; With this tempo, we can process 200 introduction cells per second.

As I described above, I think we might want to do something like that for
simplicity at first which is "empty inbuf by priority queuing all INTRODUCE2"
and once done, process them.

Thus, it won't be like the cell scheduler that accumulates until a certain
tick (10msec) and then process it all.

&gt; {XXX: Is this good?}
&gt; 
&gt; {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
&gt; per 100ms is probably unmaintainable, since each cell is quite expensive:
&gt; doing so involving path selection, crypto and making circuits. We will need
&gt; to profile this procedure and see how we can do this scheduling better.}

With the above, we should be within the same performance as we have right now
since we just deferring the processing of INTRODUCE2 cell after the inbuf is
emptied.

&gt; 
&gt; {XXX: This might be a nice place to promote multithreading. Queues and pools
&gt; are nice objects to do multithreading since you can have multiple threads
&gt; pull from the queue, or leave stuff on the queue. Not sure if this should be
&gt; in the proposal tho.}

I would _love_ to but could be too early for that if we consider that we are
still unsure that this defense will be useful or not (according to Mike as a
discussion on IRC).

&gt; 
&gt; 4. Attacker strategies [ATTACK_META]
&gt; 
&gt; Now that we defined our protocol we need to start tweaking the various
&gt; knobs. But before we can do that, we first need to understand a few
&gt; high-level attacker strategies to see what we are fighting against.
&gt; 
&gt; 4.1.1. Total overwhelm strat
&gt; 
&gt; Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
&gt; effective strategy for the attacker is to totally overwhelm the queue
&gt; processing by sending more high-effort introductions than the onion service
&gt; can handle at any given tick.
&gt; 
&gt; To do so, the attacker would have to send at least 20 high-effort
&gt; introduction cells every 100ms, where high-effort is a PoW which is above the
&gt; estimated level of "the motivated user" (see [USER_MODEL]).
&gt; 
&gt; An easier attack for the adversary, is the same strategy but with
&gt; introduction cells that are all above the comfortable level of "the standard
&gt; user" (see [USER_MODEL]). This would block out all standard users and only
&gt; allow motivated users to pass.
&gt; 
&gt; {XXX: What other attack strategies we should care about?}
&gt; 
&gt; 5. Parameter tuning [POW_SECURITY]
&gt; 
&gt; There are various parameters in this system that need to be tuned.
&gt; 
&gt; We will first start by tuning the default difficulty of our PoW
&gt; system. That's gonna define an expected time for attackers and clients to
&gt; succeed.
&gt; 
&gt; We are then gonna tune the parameters of the argon2 hash function. That will
&gt; define the resources that an attacker needs to spend to overwhelm the onion
&gt; service, the resources that the service needs to spend to verify introduction
&gt; requests, and the resources that legitimate clients need to spend to get to
&gt; the onon service.
&gt; 
&gt; 5.1. PoW Difficulty settings
&gt; 
&gt; The difficulty setting of our PoW basically dictates how difficult it should
&gt; be to get a success in our PoW system. In classic PoW systems, "success" is
&gt; defined as getting a hash output below the "target". However, since our
&gt; system is dynamic, we define "success" as an abstract high-effort computation.
&gt; 
&gt; Even tho our system is dynamic, we still need default difficulty settings
&gt; that will define the metagame. The client and attacker can still aim higher
&gt; or lower, but for UX purposes and for analysis purposes we do need to define
&gt; some difficulties.
&gt; 
&gt; We hence created the table (see [REF_TABLE]) below which shows how much time
&gt; a legitimate client with a single machine should expect to burn before they
&gt; get a single success. The x-axis is how many successes we want the attacker
&gt; to be able to do per second: the more successes we allow the adversary, the
&gt; more they can overwhelm our introduction queue. The y-axis is how many
&gt; machines the adversary has in her disposal, ranging from just 5 to 1000.
&gt; 
&gt; ===============================================================
&gt; &gt; Expected Time (in seconds) Per Success For One Machine   |
&gt; ===========================================================================
&gt; &gt; &gt; 
&gt; &gt; Attacker Succeses        1       5       10      20      30      50    |
&gt; &gt; per second                                                         |
&gt; &gt; &gt; 
&gt; &gt; 5               5       1       0       0       0       0     |
&gt; &gt; 50              50      10      5       2       1       1     |
&gt; &gt; 100             100     20      10      5       3       2     |
&gt; &gt; Attacker   200             200     40      20      10      6       4     |
&gt; &gt; Boxes     300             300     60      30      15      10      6     |
&gt; &gt; 400             400     80      40      20      13      8     |
&gt; &gt; 500             500     100     50      25      16      10    |
&gt; &gt; 1000            1000    200     100     50      33      20    |
&gt; &gt; &gt; 
&gt; ============================================================================
&gt; 
&gt; Here is how you can read the table above:
&gt; 
&gt; - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
&gt; success per second, then a legitimate client with a single box should be
&gt; expected to spend 1000 seconds getting a single success.
&gt; 
&gt; - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 200 seconds getting a single success.
&gt; 
&gt; - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 100 seconds getting a single success.
&gt; 
&gt; - If an adversary has access to 50 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 10 seconds getting a single success.
&gt; 
&gt; - If an adversary has access to 5 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 1 seconds getting a single success.
&gt; 
&gt; With the above table we can create some profiles for default values of our
&gt; PoW difficulty. So for example, we can use the last case as the default
&gt; parameter for Tor Browser, and then create three more profiles for more
&gt; expensive cases, scaling up to the first case which could be hardest since
&gt; the client is expected to spend 15 minutes for a single introduction.
&gt; 
&gt; {TODO: PARAM_TUNING You can see that this section is completely CPU/memory
&gt; agnostic, and it does not take into account potential optimizations that can
&gt; come from GPU/ASICs. This is intentional so that we don't put more variables
&gt; into this equation right now, but as this proposal moves forward we will need
&gt; to put more concrete values here.}
&gt; 
&gt; 5.2. Argon2 parameters [ARGON_PARAMS]
&gt; 
&gt; We now need to define the secondary argon2 parameters as defined in
&gt; [REF_ARGON2]. This includes the number of lanes 'h', the memory size 'm', the
&gt; number of iterations 't'. Section 9 of [REF_ARGON2] recommends an approach of
&gt; how to tune these parameters.
&gt; 
&gt; To tune these parameters we are looking to *minimize* the verification speed
&gt; of an onion service, while *maximizing* the sparse resources spent by an
&gt; adversary trying to overwhelm the service using [ATTACK_META].
&gt; 
&gt; When it comes to verification speed, to verify a single introduction cell the
&gt; service needs to do a single argon2 call: so the service will need to do
&gt; hundreds of those per second as INTRODUCE2 cells arrive. The service will
&gt; have to do this verification step even for very cheap zero-effort PoW
&gt; received, so this has to be a cheap procedure so that it doesn't become a DoS
&gt; vector of each own. Hence each individual argon2 call must be cheap enough to
&gt; be able to be done comfortably and plentifuly by an onion service with a
&gt; single host (or horizontally scaled with Onionbalance).
&gt; 
&gt; At the same time, the adversary will have to do thousands of these calls if
&gt; she wants to make high-effort PoW, so it's this assymetry that we are looking
&gt; to exploit here. Right now, the most expensive resource for adversaries is
&gt; the RAM size, and that's why we chose argon2 which is memory-hard.
&gt; 
&gt; To minmax this game we will need
&gt; 
&gt; {TODO: PARAM_TUNING: I've had a hard time minmaxing this game for
&gt; argon2. Even argon2 invocations with a small memory parameter will take
&gt; multiple milliseconds to run on my machine, and the parameters recommended in
&gt; section 8 of the paper all take many hundreds of milliseconds. This is just
&gt; not practical for our use case, since we want to process hundreds of such PoW
&gt; per second... I also did not manage to find a benchmark of argon2 calls for
&gt; different CPU/GPU/FPGA configurations.}
&gt; 
&gt; 5. Client behavior [CLIENT_BEHAVIOR]
&gt; 
&gt; This proposal introduces a bunch of new ways where a legitimate client can
&gt; fail to reach the onion service.
&gt; 
&gt; Furthermore, there is currently no end-to-end way for the onion service to
&gt; inform the client that the introduction failed. The INTRO_ACK cell is not
&gt; end-to-end (it's from the introduction point to the client) and hence it does
&gt; not allow the service to inform the client that the rendezvous is never gonna
&gt; occur.
&gt; 
&gt; Let's examine a few such cases:
&gt; 
&gt; 5.1. Timeout issues
&gt; 
&gt; Alice can fail to reach the onion service if her introduction request falls
&gt; off the priority queue, or if the priority queue is so big that the
&gt; connection times out.
&gt; 
&gt; Is building a new introduction circuit sufficient here? Or do we need to
&gt; build an end-to-end mechanism over the introduction circuit to inform
&gt; her? {XXX}
&gt; 
&gt; How should timeout values change here since the priority queue will cause
&gt; bigger delays than usual to rendezvous? Can there be some feedback mechanism
&gt; to inform the client of its queue position or ETA?

I don't see this proposal adding new delays for the rendezvous circuit because
as of now, if you as a client get in the queue the 32th, you will be handled
by the service after 32 cells but if you get in the priority queue the 32th,
same situation.

Only way to inform the client I see would be a ACK from service to IP.

&gt; 
&gt; 5.2. Seed expiration issues
&gt; 
&gt; As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
&gt; cause issues with clock skewed clients. Furthermore, even not clock skewed
&gt; clients can encounter TOCTOU-style race conditions here.
&gt; 
&gt; How should this be handled? Should we have multiple active seeds at the same
&gt; time similar to how we have overlapping descriptors and time periods in v3?
&gt; This would solve the problem but it grows the complexity of the system
&gt; substantially. {XXX}
&gt; 
&gt; 5.3. Other descriptor issues
&gt; 
&gt; Another race condition here is if the service enables PoW, while a client has
&gt; a cached descriptor. How will the client notice that PoW is needed? Does it
&gt; need to fetch a new descriptor? Should there be another feedback mechanism?
&gt; {XXX}

I assume current behavior would kick in that is failing to introduce, ditch
descriptor, refetch and succeed.

Without a feedback from the service, not much we can do there :S.

&gt; 
&gt; 5. Discussion
&gt; 
&gt; 5.1. UX
&gt; 
&gt; This proposal has user facing UX consequences. Here are a few UX approaches
&gt; with increasing engineering difficulty:
&gt; 
&gt; a) Tor Browser needs a "range field" which the user can use to specify how
&gt; much effort they want to spend in PoW if this ever occurs while they are
&gt; browsing. The ranges could be from "Easy" to "Difficult", or we could try
&gt; to estimate time using an average computer. This setting is in the Tor
&gt; Browser settings and users need to find it.
&gt; 
&gt; b) We start with a default effort setting, and then we use the new onion
&gt; errors (see #19251) to estimate when an onion service connection has
&gt; failed because of DoS, and only then we present the user a "range field"
&gt; which they can set dynamically. Detecting when an onion service connection
&gt; has failed because of DoS can be hard because of the lack of feedback (see
&gt; [CLIENT_BEHAVIOR])
&gt; 
&gt; c) We start with a default effort setting, and if things fail we
&gt; automatically try to figure out an effort setting that will work for the
&gt; user by doing some trial-and-error connections with different effort
&gt; values. Until the connection succeeds we present a "Service is
&gt; overwhelmed, please wait" message to the user.
&gt; 
&gt; For this proposal to work initially we need at least (a), and then we can
&gt; start thinking of how far we want to take it.

This is not a simple concept for non technical users. A default value will be
used 99.9% of the time so I would strongly consider making it hard on
ourselves to find a good value instead of the other way. And possibly never
exposing that "range of effort" to the user, could be done all under the hood.

&gt; 
&gt; 5.2. Future directions [FUTURE_WORK]
&gt; 
&gt; This is just the beginning in DoS defences for Tor and there are various
&gt; future avenues that we can investigate. Here is a brief summary of these:
&gt; 
&gt; "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
&gt; schemes like MTP-argon2 or Itsuku to make it even harder for
&gt; adversaries to create successful PoWs. Unfortunately these schemes
&gt; have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
&gt; See #31223 for more details.
&gt; 
&gt; "Third-party anonymous credentials" -- We can use anonymous credentials and a
&gt; third-party token issuance server on the clearnet to issue tokens
&gt; based on PoW or CAPTCHA and then use those tokens to get access to the
&gt; service. See [REF_CREDS] for more details.
&gt; 
&gt; "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
&gt; where we present a hard puzzle to the user when connecting to the
&gt; onion service, and if they solve it we then give the user a bunch of
&gt; anonymous tokens that can be used in the future. This can all happen
&gt; between the client and the service without a need for a third party.
&gt; 
&gt; All of the above approaches are much more complicated than this proposal, and
&gt; hence we want to start easy before we get into more serious projects.
&gt; 
&gt; 5.3. Environment
&gt; 
&gt; We love the environment! We are concerned of how PoW schemes can waste energy
&gt; by doing useless hash iterations. Here is a few reasons we still decided to
&gt; pursue a PoW approach here:
&gt; 
&gt; "We are not making things worse" -- DoS attacks are already happening and
&gt; attackers are already burning energy to carry them out both on the
&gt; attacker side, on the service side and on the network side. We think that
&gt; asking legitimate clients to carry out PoW computations is not gonna
&gt; affect the equation too much, since an attacker right now can very
&gt; quickly cause the same damage that hundreds of legitimate clients do a
&gt; whole day.
&gt; 
&gt; "We hope to make things better" -- The hope is that proposals like this will
&gt; make the DoS actors go away and hence the PoW system will not be used. As
&gt; long as DoS is happening there will be a waste of energy, but if we
&gt; manage to demotivate them with technical means, the network as a whole
&gt; will less wasteful. Also see [CATCH22] for a similar argument.
&gt; 
&gt; 6. References
&gt; 
&gt; [REF_ARGON2]: https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf
&gt;  https://password-hashing.net/#argon2
&gt; [REF_TABLE]: The table is based on the script below plus some manual editing for \
&gt; readability: https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
&gt; [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
&gt;  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
&gt; [REF_TARGET]: https://en.bitcoin.it/wiki/Target

Good stuff asn!!!

Cheers!
David

-- 
7LuDL5uwrIIBSORTZgBkxR0ZGg82VNEKb+JshW/Q9ig=


["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200403013033</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-04-03 01:30:33-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Phew! This is loooonnnng but excellent! Comments in-line!

On 4/2/20 10:54 AM, George Kadianakis wrote:i
&gt; Hello list,
&gt; 
&gt; hope everyone is safe and doing well!
&gt; 
&gt; I present you an initial draft of a proposal on PoW-based defences for
&gt; onion services under DoS.
&gt; 
&gt; The proposal is not finished yet and it needs tuning and fixing. There
&gt; are many places marked with XXX and TODO around the proposal that should
&gt; be addressed.
&gt; 
&gt; The important part is that looking at the numbers it does seem like this
&gt; proposal can work as a concept and serve its intended purpose. The most
&gt; handwavey parts of the proposal right now are [INTRO_QUEUE] and
&gt; [POW_SECURITY] and if this thing fails in the end, it's probably gonna
&gt; be something that slipped over there. Hence, we should polish these
&gt; sections before we proceed with any sort of engineering here.
&gt; 
&gt; In any case, I decided to send it to the list even in premature form, so
&gt; that it can serve as a stable point of reference in subsequent
&gt; discussions. It can also be found in my git repo:
&gt; https://github.com/asn-d6/torspec/tree/pow-over-intro
&gt; 
&gt; Cheers and stay safe!
&gt; 
&gt; ---
&gt; 
&gt; Filename: xxx-pow-over-intro-v1
&gt; Title: A First Take at PoW Over Introduction Circuits
&gt; Author: George Kadianakis
&gt; Created: 2 April 2020
&gt; Status: Draft
&gt; 
&gt; 0. Abstract
&gt; 
&gt; This proposal aims to thwart introduction flooding DoS attacks by introducing
&gt; a dynamic Proof-Of-Work protocol that occurs over introduction circuits.
&gt; 
&gt; 1. Motivation
&gt; 
&gt; So far our attempts at limiting the impact of introduction flooding DoS
&gt; attacks on onion services has been focused on horizontal scaling with
&gt; Onionbalance, optimizing the CPU usage of Tor and applying congestion control
&gt; using rate limiting. While these measures move the goalpost forward, a core
&gt; problem with onion service DoS is that building rendezvous circuits is a
&gt; costly procedure both for the service and for the network. If we ever hope to
&gt; have truly reachable global onion services, we need to make it harder for
&gt; attackers to overload the service with introduction requests.
&gt; 
&gt; This proposal achieves this by allowing onion services to specify an optional
&gt; dynamic proof-of-work scheme that its clients need to participate in if they
&gt; want to get served.
&gt; 
&gt; With the right parameters, this proof-of-work scheme acts as a gatekeeper to
&gt; block amplification attacks by attackers while letting legitimate clients
&gt; through.
&gt; 
&gt; 1.1. Threat model [THREAT_MODEL]
&gt; 
&gt; 1.1.1. Attacker profiles [ATTACKER_MODEL]
&gt; 
&gt; This proposal is written to thwart specific attackers. A simple PoW proposal
&gt; cannot defend against all and every DoS attack on the Internet, but there are
&gt; adverary models we can defend against.
&gt; 
&gt; Let's start with some adversary profiles:
&gt; 
&gt; "The script-kiddie"
&gt; 
&gt; The script-kiddie has a single computer and pushes it to its
&gt; limits. Perhaps it also has a VPS and a pwned server. We are talking about
&gt; an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
&gt; consider the total cost for this attacker to be zero $.
&gt; 
&gt; "The small botnet"
&gt; 
&gt; The small botnet is a bunch of computers lined up to do an introduction
&gt; flooding attack. Assuming 500 medium-range computers, we are talking about
&gt; an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
&gt; the upfront cost for this attacker to be about $400.
&gt; 
&gt; "The large botnet"
&gt; 
&gt; The large botnet is a serious operation with many thousands of computers
&gt; organized to do this attack. Assuming 100k medium-range computers, we are
&gt; talking about an attacker with total access to 200 Thz of CPU and 200 TB of
&gt; RAM. The upfront cost for this attacker is about $36k.
&gt; 
&gt; 1.1.2. User profiles [USER_MODEL]
&gt; 
&gt; We have attackers and we have users. Here are a few user profiles:
&gt; 
&gt; "The standard web user"
&gt; 
&gt; This is a standard laptop/desktop user who is trying to browse the
&gt; web. They don't know how these defences work and they don't care to
&gt; configure or tweak them. They are gonna use the default values and if the
&gt; site doesn't load, they are gonna close their browser and be sad at Tor.
&gt; They run a 2Ghz computer with 4GB of RAM.
&gt; 
&gt; "The motivated user"
&gt; 
&gt; This is a user that really wants to reach their destination. They don't
&gt; care about the journey; they just want to get there. They know what's going
&gt; on; they are willing to tweak the default values and make their computer do
&gt; expensive multi-minute PoW computations to get where they want to be.
&gt; 
&gt; "The mobile user"
&gt; 
&gt; This is a motivated user on a mobile phone. Even tho they want to read the
&gt; news article, they don't have much leeway on stressing their machine to do
&gt; more computation.
&gt; 
&gt; We hope that this proposal will allow the motivated user to always connect
&gt; where they want to connect to, and also give more chances to the other user
&gt; groups to reach the destination.
&gt; 
&gt; 1.1.3. The DoS Catch-22 [CATCH22]
&gt; 
&gt; This proposal is not perfect and it does not cover all the use cases. Still,
&gt; we think that by covering some use cases and giving reachability to the
&gt; people who really need it, we will severely demotivate the attackers from
&gt; continuing the DoS attacks and hence stop the DoS threat all
&gt; together. Furthermore, by increasing the cost to launch a DoS attack, a big
&gt; class of DoS attackers will disappear from the map, since the expected ROI
&gt; will decrease.
&gt; 
&gt; 2. System Overview
&gt; 
&gt; 2.1. Tor protocol overview
&gt; 
&gt; +----------------------------------+
&gt; &gt; &gt; 
&gt; +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
&gt; &gt; Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
&gt; +-------+         +-----------+        |Verifier|           |             |
&gt; +--------+           |             |
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; 
&gt; &gt; +----------v---------+   |
&gt; &gt; &gt; Intro Priority Queue|   |
&gt; +---------+--------------------+---+
&gt; &gt; &gt; &gt; 
&gt; Rendezvous |  |  |
&gt; circuits |  |  |
&gt; v  v  v
&gt; 
&gt; 
&gt; 
&gt; The proof-of-work scheme specified in this proposal takes place during the
&gt; introduction phase of the onion service protocol. It's an optional mechanism
&gt; that only occurs if the service requires it. It can be enabled and disabled
&gt; either through its torrc or through the control port.
&gt; 
&gt; In summary, the following steps are taken for the protocol to complete:
&gt; 
&gt; 1) Service encodes PoW parameters in descriptor [DESC_POW]
&gt; 2) Client fetches descriptor and computes PoW [CLIENT_POW]
&gt; 3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
&gt; 4) Service verifies PoW and queues introduction based on PoW effort \
&gt; [SERVICE_VERIFY] 
&gt; 2.2. Proof-of-work overview
&gt; 
&gt; 2.2.1. Primitives
&gt; 
&gt; For our proof-of-work scheme we want to minimize the spread of resources
&gt; between a motivated attacker and legitimate clients. This means that we are
&gt; looking to minimize any benefits that GPUs or ACICs can offer to an attacker.
&gt; 
&gt; For this reason we chose argon2 [REF_ARGON2] as the hash function for our
&gt; proof-of-work scheme since it's well audited and GPU-resistant and to some
&gt; extend ASIC-resistant as well.

FWIW, I think we should also consider
https://github.com/tevador/RandomX, which is based on argon2 plus some
additional sauce, and comes as a library with C exports, pretty much
tuned for our usecase.

The downside is that it is C++ itself, but if we use it as an optional
external build dep (only Tor Browser and onion services need this
thing.. relays do not), that should be fine.

&gt; As a password hash function, argon2 by default outputs 32 bytes of hash, and
&gt; takes as primary input a message and a nonce/salt. For the purposes of this
&gt; specification we will define an argon2() function as:
&gt; uint8_t hash_output[32] = argon2(uint8_t *message, uint8_t *nonce)'.
&gt; 
&gt; See section [ARGON_PARAMS] for more information on the secondary inputs of
&gt; argon2.
&gt; 
&gt; 2.2.2. Dynamic PoW
&gt; 
&gt; DoS is a dynamic problem where the attacker's capabilities constantly change,
&gt; and hence we want our proof-of-work system to be dynamic and not stuck with a
&gt; static difficulty setting. Hence, instead of forcing clients to go below a
&gt; static target like in Bitcoin to be successful, we ask clients to "bid" using
&gt; their PoW effort. Effectively, a client gets higher priority the higher
&gt; effort they put into their proof-of-work. This is similar to how
&gt; proof-of-stake works but instead of staking coins, you stake work.
&gt; 
&gt; The benefit here is that legitimate clients who really care about getting
&gt; access can spend a big amount of effort into their PoW computation, which
&gt; should guarantee access to the service given reasonable adversary models. See
&gt; [POW_SECURITY] for more details about these guarantees and tradeoffs.
&gt; 
&gt; 3. Protocol specification
&gt; 
&gt; 3.1. Service encodes PoW parameters in descriptor [DESC_POW]
&gt; 
&gt; This whole protocol starts with the service encoding the PoW parameters in
&gt; the 'encrypted' (inner) part of the v3 descriptor. As follows:
&gt; 
&gt; "pow-params" SP type SP seed-b64 SP expiration-time NL
&gt; 
&gt; [At most once]
&gt; 
&gt; type: The type of PoW system used. We call the one specified here "v1"
&gt; 
&gt; seed-b64: A random seed that should be used as the input to the PoW
&gt; hash function. Should be 32 random bytes encoded in base64
&gt; without trailing padding.
&gt; 
&gt; expiration-time: A timestamp after which the above seed expires and is
&gt; no longer valid as the input for PoW. It's needed so
&gt; that the size of our replay cache does not grow
&gt; infinitely. It should be set to an hour in the future
&gt; (+- some randomness).  {TODO: PARAM_TUNING}
&gt; 
&gt; {XXX: Expiration time makes us even more susceptible to clock skews, but
&gt; it's needed so that our replay cache refreshes. How to fix this?
&gt; See [CLIENT_BEHAVIOR] for more details.}

We should also include the lowest difficulty successfully serviced from
the queue recently (last N seconds of time), in this field, as a hint of
the difficulty level that clients should shoot for, as a minimum.

This will save them from waiting for quite so many timeouts, and from
doing too much needless work.

&gt; 3.2. Client fetches descriptor and computes PoW [CLIENT_POW]
&gt; 
&gt; If a client receives a descriptor with "pow-params", it should assume that
&gt; the service is expecting a PoW input as part of the introduction protocol.
&gt; 
&gt; In such cases, the client should have been configured with a specific PoW
&gt; 'target' (which is a 32-byte integer similar to the 'target' of Bitcoin
&gt; [REF_TARGET]). See [POW_SECURITY] for more information of how such a target
&gt; should be set. For the purposes of this section, we will assume that the
&gt; target has been set automatically by Tor, or the user configured it manually.
&gt; 
&gt; Now the client parses the descriptor and extracts the PoW parameters. It
&gt; makes sure that the expiration-time has not expired and if it has, it needs
&gt; to fetch a new descriptor.
&gt; 
&gt; To complete the PoW the client follows the following logic:
&gt; 
&gt; a) Client generates 'nonce' as 32 random bytes.
&gt; b) Client derives 'seed' by decoding 'seed-b64'.
&gt; c) Client computes hash_output = argon2(seed, nonce)
&gt; d) Client interprets hash_output as a 32-byte big-endian integer.
&gt; e) Client checks if int(hash_output) &lt;= target.
&gt; e1) If yes, success! The client uses 'hash_output' as the hash and
&gt; 'nonce' and 'seed' as its inputs.
&gt; e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
&gt; increments it by one, and goes back to step (c).
&gt; 
&gt; At the end of the above procedure, the client should have a triplet
&gt; (hash_output, seed, nonce) that can be used as the answer to the PoW
&gt; puzzle. How quickly this happens depends solely on the 'target' parameter.

Nice. Clarification (as per dgoule's verification question):

The hard part here is finding the nonce that matches the target.
Verification (running the hash once) should be easy.

RandomX does require (relatively) a lot of setup for the VM, etc, so we
will need to be careful about preserving the right pieces of setup
there. But, if we do that right, we're fine.

&gt; 3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]
&gt; 
&gt; Now that the client has an answer to the puzzle it's time to encode it into
&gt; an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
&gt; portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
&gt; [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
&gt; INTRODUCE1 cell only gets read by the onion service and is ignored by the
&gt; introduction point.
&gt; 
&gt; We propose a new EXT_FIELD_TYPE value:
&gt; 
&gt; [01] -- PROOF_OF_WORK
&gt; 
&gt; The EXT_FIELD content format is:
&gt; 
&gt; POW_VERSION    [1 byte]
&gt; POW_SEED       [32 bytes]
&gt; POW_NONCE      [32 bytes]
&gt; POW_OUTPUT     [32 bytes]
&gt; 
&gt; where:
&gt; 
&gt; POW_VERSION is 1 for the protocol specified in this proposal
&gt; POW_SEED is 'seed' from the section above
&gt; POW_NONCE is 'nonce' from the section above
&gt; POW_OUTPUT is 'hash_output' from the section above
&gt; 
&gt; {XXX: do we need POW_VERSION? Perhaps we can use EXT_FIELD_TYPE as version}
&gt; {XXX: do we need to encode the SEED? Perhaps we can ommit it since the
&gt; service already knows it. But what happens in cases of desynch, if client
&gt; has diff seed from service?}
&gt; {XXX: Do we need to include the output? Probably not. The service has to
&gt; compute it anyway during verification. What's the use?}
&gt; 
&gt; This will increase the INTRODUCE1 payload size by 99 bytes since the
&gt; extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
&gt; present and currently set to 0 and the EXT_FIELD is 97 bytes. According to
&gt; ticket #33650, INTRODUCE1 cells currently have more than 200 bytes available.
&gt; 
&gt; 3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]
&gt; 
&gt; When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
&gt; should check its configuration on whether proof-of-work is required to
&gt; complete the introduction. If it's not required, the extension SHOULD BE
&gt; ignored. If it is required, the service follows the procedure detailed in
&gt; this section.
&gt; 
&gt; 3.4.1. PoW verification
&gt; 
&gt; To verify the client's proof-of-work the service extracts (hash_output,
&gt; seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:
&gt; 
&gt; 1) Make sure that the client's seed is identical to the active seed.
&gt; 2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
&gt; 3) Verify that 'hash_output =?= argon2(seed, nonce)
&gt; 
&gt; If any of these steps fail the service MUST ignore this introduction request
&gt; and abort the protocol.
&gt; 
&gt; If all the steps passed, then the circuit is added to the introduction queue
&gt; as detailed in section [INTRO_QUEUE].
&gt; 
&gt; 3.4.1.1. Replay protection [REPLAY_PROTECTION]
&gt; 
&gt; The service MUST NOT accept introduction requests with the same (seed, nonce)
&gt; tuple. For this reason a replay protection mechanism must be employed.
&gt; 
&gt; The simplest way is to use a simple hash table to check whether a (seed,
&gt; nonce) tuple has been used before for the actiev duration of a
&gt; seed. Depending on how long a seed stays active this might be a viable
&gt; solution with reasonable memory/time overhead.
&gt; 
&gt; If there is a worry that we might get too many introductions during the
&gt; lifetime of a seed, we can use a Bloom filter as our replay cache
&gt; mechanism. The probabilistic nature of Bloom filters means that sometimes we
&gt; will flag some connections as replays even if they are not; with this false
&gt; positive probability increasing as the number of entries increase. However,
&gt; with the right parameter tuning this probability should be negligible and
&gt; well handled by clients. {TODO: PARAM_TUNING}
&gt; 
&gt; 3.4.2. The Introduction Queue  [INTRO_QUEUE]
&gt; 
&gt; 3.4.2.1. Adding introductions to the introduction queue
&gt; 
&gt; When PoW is enabled and a verified introduction comes through, the service
&gt; instead of jumping straight into rendezvous, queues it and prioritizes it
&gt; based on how much effort was devoted by the client to PoW. This means that
&gt; introduction requests with high effort should be prioritized over those with
&gt; low effort.
&gt; 
&gt; To do so, the service maintains an "introduction priority queue" data
&gt; structure. Each element in that priority queue is an introduction request,
&gt; and its priority is the effort put into its PoW:
&gt; 
&gt; When a verified introduction comes through, the service interprets the PoW
&gt; hash as a 32-byte big-endian integer 'hash_int' and based on that integer it
&gt; inserts it into the right position of the priority_queue: The smallest
&gt; 'hash_int' goes forward in the queue. If two elements have the same value,
&gt; the older one has priority over the newer one.
&gt; {XXX: Is this operation with 32-bytes integers expensive? How to make cheaper?}
&gt; 
&gt; {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
&gt; effort what attacks can happen in various scenarios? Do we want to order on
&gt; time+effort?  Which scenarios and attackers should we examine here?}
&gt; 
&gt; {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can we
&gt; use WRED usefully?}

We should record the lowest difficulty level that was successfully
serviced from the priority queue, and post it in the descriptor.

{TODO: PARAM_TUNING: Is lowest enough? Do we want to timebound that? How
does it combine with options above? }

&gt; 3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]
&gt; 
&gt; The service should handle introductions by pulling from the introduction
&gt; queue.
&gt; 
&gt; Similar to how our cell scheduler works, the onion service subsystem will
&gt; poll the priority queue every 100ms tick and process the first 20 cells from
&gt; the priority queue (if they exist). The service will perform the rendezvous
&gt; and the rest of the onion service protocol as normal.
&gt; 
&gt; With this tempo, we can process 200 introduction cells per second.
&gt; {XXX: Is this good?}
&gt; 
&gt; {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
&gt; per 100ms is probably unmaintainable, since each cell is quite expensive:
&gt; doing so involving path selection, crypto and making circuits. We will need
&gt; to profile this procedure and see how we can do this scheduling better.}
&gt; 
&gt; {XXX: This might be a nice place to promote multithreading. Queues and pools
&gt; are nice objects to do multithreading since you can have multiple threads
&gt; pull from the queue, or leave stuff on the queue. Not sure if this should be
&gt; in the proposal tho.}

I think we should only do multi-threading in v1 if it still fits in a
single Tor release cycle. Otherwise slide it to a v1.5 or v2.

Onionbalance is a backstop option instead of multithreading.. The
traffic analysis characteristics are not as good for this case, so if it
helps in practice, we should be sure to do multithreading ASAP (but
still maybe not v1? It really depends on how deep a rabbit-hole it is
for this case).

&gt; 4. Attacker strategies [ATTACK_META]
&gt; 
&gt; Now that we defined our protocol we need to start tweaking the various
&gt; knobs. But before we can do that, we first need to understand a few
&gt; high-level attacker strategies to see what we are fighting against.
&gt; 
&gt; 4.1.1. Total overwhelm strat
&gt; 
&gt; Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
&gt; effective strategy for the attacker is to totally overwhelm the queue
&gt; processing by sending more high-effort introductions than the onion service
&gt; can handle at any given tick.
&gt; 
&gt; To do so, the attacker would have to send at least 20 high-effort
&gt; introduction cells every 100ms, where high-effort is a PoW which is above the
&gt; estimated level of "the motivated user" (see [USER_MODEL]).

If the queue generates a libevent callback event when it has N entries,
is this better? (Is such a callback hard to create?)

&gt; An easier attack for the adversary, is the same strategy but with
&gt; introduction cells that are all above the comfortable level of "the standard
&gt; user" (see [USER_MODEL]). This would block out all standard users and only
&gt; allow motivated users to pass.
&gt; 
&gt; {XXX: What other attack strategies we should care about?}
&gt; 
&gt; 5. Parameter tuning [POW_SECURITY]
&gt; 
&gt; There are various parameters in this system that need to be tuned.
&gt; 
&gt; We will first start by tuning the default difficulty of our PoW
&gt; system. That's gonna define an expected time for attackers and clients to
&gt; succeed.
&gt; 
&gt; We are then gonna tune the parameters of the argon2 hash function. That will
&gt; define the resources that an attacker needs to spend to overwhelm the onion
&gt; service, the resources that the service needs to spend to verify introduction
&gt; requests, and the resources that legitimate clients need to spend to get to
&gt; the onon service.
&gt; 
&gt; 5.1. PoW Difficulty settings
&gt; 
&gt; The difficulty setting of our PoW basically dictates how difficult it should
&gt; be to get a success in our PoW system. In classic PoW systems, "success" is
&gt; defined as getting a hash output below the "target". However, since our
&gt; system is dynamic, we define "success" as an abstract high-effort computation.
&gt; 
&gt; Even tho our system is dynamic, we still need default difficulty settings
&gt; that will define the metagame. The client and attacker can still aim higher
&gt; or lower, but for UX purposes and for analysis purposes we do need to define
&gt; some difficulties.
&gt; 
&gt; We hence created the table (see [REF_TABLE]) below which shows how much time
&gt; a legitimate client with a single machine should expect to burn before they
&gt; get a single success. The x-axis is how many successes we want the attacker
&gt; to be able to do per second: the more successes we allow the adversary, the
&gt; more they can overwhelm our introduction queue. The y-axis is how many
&gt; machines the adversary has in her disposal, ranging from just 5 to 1000.
&gt; 
&gt; ===============================================================
&gt; &gt; Expected Time (in seconds) Per Success For One Machine   |
&gt; ===========================================================================
&gt; &gt; &gt; 
&gt; &gt; Attacker Succeses        1       5       10      20      30      50    |
&gt; &gt; per second                                                         |
&gt; &gt; &gt; 
&gt; &gt; 5               5       1       0       0       0       0     |
&gt; &gt; 50              50      10      5       2       1       1     |
&gt; &gt; 100             100     20      10      5       3       2     |
&gt; &gt; Attacker   200             200     40      20      10      6       4     |
&gt; &gt; Boxes     300             300     60      30      15      10      6     |
&gt; &gt; 400             400     80      40      20      13      8     |
&gt; &gt; 500             500     100     50      25      16      10    |
&gt; &gt; 1000            1000    200     100     50      33      20    |
&gt; &gt; &gt; 
&gt; ============================================================================
&gt; 
&gt; Here is how you can read the table above:
&gt; 
&gt; - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
&gt; success per second, then a legitimate client with a single box should be
&gt; expected to spend 1000 seconds getting a single success.
&gt; 
&gt; - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 200 seconds getting a single success.
&gt; 
&gt; - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 100 seconds getting a single success.
&gt; 
&gt; - If an adversary has access to 50 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 10 seconds getting a single success.
&gt; 
&gt; - If an adversary has access to 5 boxes, and we want to limit her to 5
&gt; successes per second, then a legitimate client with a single box should be
&gt; expected to spend 1 seconds getting a single success.
&gt; 
&gt; With the above table we can create some profiles for default values of our
&gt; PoW difficulty. So for example, we can use the last case as the default
&gt; parameter for Tor Browser, and then create three more profiles for more
&gt; expensive cases, scaling up to the first case which could be hardest since
&gt; the client is expected to spend 15 minutes for a single introduction.
&gt; 
&gt; {TODO: PARAM_TUNING You can see that this section is completely CPU/memory
&gt; agnostic, and it does not take into account potential optimizations that can
&gt; come from GPU/ASICs. This is intentional so that we don't put more variables
&gt; into this equation right now, but as this proposal moves forward we will need
&gt; to put more concrete values here.}

This is excellent analysis!

Do we know how many "successes per second" (ie: INTRO2+rend
response+nginx) a typically spec'ed HS can serve? That would be a useful
stat for comparison. Is 50/second unreasonable to expect to survive, on
the typical service side?

Related: At what point do people need onionbalance, typically? And how
far does that get you, in req/sec handling on a single machine? On
multiple machines?

&gt; 5.2. Argon2 parameters [ARGON_PARAMS]
&gt; 
&gt; We now need to define the secondary argon2 parameters as defined in
&gt; [REF_ARGON2]. This includes the number of lanes 'h', the memory size 'm', the
&gt; number of iterations 't'. Section 9 of [REF_ARGON2] recommends an approach of
&gt; how to tune these parameters.
&gt; 
&gt; To tune these parameters we are looking to *minimize* the verification speed
&gt; of an onion service, while *maximizing* the sparse resources spent by an
&gt; adversary trying to overwhelm the service using [ATTACK_META].
&gt; 
&gt; When it comes to verification speed, to verify a single introduction cell the
&gt; service needs to do a single argon2 call: so the service will need to do
&gt; hundreds of those per second as INTRODUCE2 cells arrive. The service will
&gt; have to do this verification step even for very cheap zero-effort PoW
&gt; received, so this has to be a cheap procedure so that it doesn't become a DoS
&gt; vector of each own. Hence each individual argon2 call must be cheap enough to
&gt; be able to be done comfortably and plentifuly by an onion service with a
&gt; single host (or horizontally scaled with Onionbalance).
&gt; 
&gt; At the same time, the adversary will have to do thousands of these calls if
&gt; she wants to make high-effort PoW, so it's this assymetry that we are looking
&gt; to exploit here. Right now, the most expensive resource for adversaries is
&gt; the RAM size, and that's why we chose argon2 which is memory-hard.
&gt; 
&gt; To minmax this game we will need
&gt; 
&gt; {TODO: PARAM_TUNING: I've had a hard time minmaxing this game for
&gt; argon2. Even argon2 invocations with a small memory parameter will take
&gt; multiple milliseconds to run on my machine, and the parameters recommended in
&gt; section 8 of the paper all take many hundreds of milliseconds. This is just
&gt; not practical for our use case, since we want to process hundreds of such PoW
&gt; per second... I also did not manage to find a benchmark of argon2 calls for
&gt; different CPU/GPU/FPGA configurations.}

TODO: We should write something similar for RandomX.

&gt; 5. Client behavior [CLIENT_BEHAVIOR]
&gt; 
&gt; This proposal introduces a bunch of new ways where a legitimate client can
&gt; fail to reach the onion service.
&gt; 
&gt; Furthermore, there is currently no end-to-end way for the onion service to
&gt; inform the client that the introduction failed. The INTRO_ACK cell is not
&gt; end-to-end (it's from the introduction point to the client) and hence it does
&gt; not allow the service to inform the client that the rendezvous is never gonna
&gt; occur.
&gt; 
&gt; Let's examine a few such cases:
&gt; 
&gt; 5.1. Timeout issues
&gt; 
&gt; Alice can fail to reach the onion service if her introduction request falls
&gt; off the priority queue, or if the priority queue is so big that the
&gt; connection times out.
&gt; 
&gt; Is building a new introduction circuit sufficient here? Or do we need to
&gt; build an end-to-end mechanism over the introduction circuit to inform
&gt; her? {XXX}
&gt; 
&gt; How should timeout values change here since the priority queue will cause
&gt; bigger delays than usual to rendezvous? Can there be some feedback mechanism
&gt; to inform the client of its queue position or ETA?

Clients could estimate this time based on the published descriptor
difficulty (ie: lowest-needed-to-service), and how long such a
difficulty takes on their platform. They could record their own history
for stats and UX reporting.

&gt; 5.2. Seed expiration issues
&gt; 
&gt; As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
&gt; cause issues with clock skewed clients. Furthermore, even not clock skewed
&gt; clients can encounter TOCTOU-style race conditions here.
&gt; 
&gt; How should this be handled? Should we have multiple active seeds at the same
&gt; time similar to how we have overlapping descriptors and time periods in v3?
&gt; This would solve the problem but it grows the complexity of the system
&gt; substantially. {XXX}
&gt; 
&gt; 5.3. Other descriptor issues
&gt; 
&gt; Another race condition here is if the service enables PoW, while a client has
&gt; a cached descriptor. How will the client notice that PoW is needed? Does it
&gt; need to fetch a new descriptor? Should there be another feedback mechanism?
&gt; {XXX}
&gt; 
&gt; 5. Discussion
&gt; 
&gt; 5.1. UX
&gt; 
&gt; This proposal has user facing UX consequences. Here are a few UX approaches
&gt; with increasing engineering difficulty:
&gt; 
&gt; a) Tor Browser needs a "range field" which the user can use to specify how
&gt; much effort they want to spend in PoW if this ever occurs while they are
&gt; browsing. The ranges could be from "Easy" to "Difficult", or we could try
&gt; to estimate time using an average computer. This setting is in the Tor
&gt; Browser settings and users need to find it.

If clients can estimate based on the difficulty, this could be a notice
instead of a config option: "This site will take about X seconds to
access, as it is under attack. Please be patient, or give up." There is
no need to config anything. You decide to give up on a site-by-site and
visit-by-visit basis, depending on how important that site is to you at
that time.

&gt; b) We start with a default effort setting, and then we use the new onion
&gt; errors (see #19251) to estimate when an onion service connection has
&gt; failed because of DoS, and only then we present the user a "range field"
&gt; which they can set dynamically. Detecting when an onion service connection
&gt; has failed because of DoS can be hard because of the lack of feedback (see
&gt; [CLIENT_BEHAVIOR])
&gt; 
&gt; c) We start with a default effort setting, and if things fail we
&gt; automatically try to figure out an effort setting that will work for the
&gt; user by doing some trial-and-error connections with different effort
&gt; values. Until the connection succeeds we present a "Service is
&gt; overwhelmed, please wait" message to the user.
&gt; 
&gt; For this proposal to work initially we need at least (a), and then we can
&gt; start thinking of how far we want to take it.
&gt; 
&gt; 5.2. Future directions [FUTURE_WORK]
&gt; 
&gt; This is just the beginning in DoS defences for Tor and there are various
&gt; future avenues that we can investigate. Here is a brief summary of these:
&gt; 
&gt; "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
&gt; schemes like MTP-argon2 or Itsuku to make it even harder for
&gt; adversaries to create successful PoWs. Unfortunately these schemes
&gt; have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
&gt; See #31223 for more details.
&gt; 
&gt; "Third-party anonymous credentials" -- We can use anonymous credentials and a
&gt; third-party token issuance server on the clearnet to issue tokens
&gt; based on PoW or CAPTCHA and then use those tokens to get access to the
&gt; service. See [REF_CREDS] for more details.
&gt; 
&gt; "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
&gt; where we present a hard puzzle to the user when connecting to the
&gt; onion service, and if they solve it we then give the user a bunch of
&gt; anonymous tokens that can be used in the future. This can all happen
&gt; between the client and the service without a need for a third party.
&gt; 
&gt; All of the above approaches are much more complicated than this proposal, and
&gt; hence we want to start easy before we get into more serious projects.
&gt; 
&gt; 5.3. Environment
&gt; 
&gt; We love the environment! We are concerned of how PoW schemes can waste energy
&gt; by doing useless hash iterations. Here is a few reasons we still decided to
&gt; pursue a PoW approach here:
&gt; 
&gt; "We are not making things worse" -- DoS attacks are already happening and
&gt; attackers are already burning energy to carry them out both on the
&gt; attacker side, on the service side and on the network side. We think that
&gt; asking legitimate clients to carry out PoW computations is not gonna
&gt; affect the equation too much, since an attacker right now can very
&gt; quickly cause the same damage that hundreds of legitimate clients do a
&gt; whole day.
&gt; 
&gt; "We hope to make things better" -- The hope is that proposals like this will
&gt; make the DoS actors go away and hence the PoW system will not be used. As
&gt; long as DoS is happening there will be a waste of energy, but if we
&gt; manage to demotivate them with technical means, the network as a whole
&gt; will less wasteful. Also see [CATCH22] for a similar argument.
&gt; 
&gt; 6. References
&gt; 
&gt; [REF_ARGON2]: https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf
&gt;  https://password-hashing.net/#argon2
&gt; [REF_TABLE]: The table is based on the script below plus some manual editing for \
&gt; readability: https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
&gt; [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
&gt;  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
&gt; [REF_TARGET]: https://en.bitcoin.it/wiki/Target
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 

-- 
Mike Perry


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200406220812</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-04-06 22:08:12-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Trimming to stuff that I just want to reply to; I otherwise agree.

Note: in a couple places I replied directly to asn's OP, because I
noticed some more questions that I could answer.

On 4/2/20 2:30 PM, David Goulet wrote:
&gt;
&gt; On 02 Apr (18:54:59), George Kadianakis wrote:
&gt;&gt; 2.2.2. Dynamic PoW
&gt;&gt;
&gt;&gt;   DoS is a dynamic problem where the attacker's capabilities constantly change,
&gt;&gt;   and hence we want our proof-of-work system to be dynamic and not stuck with a
&gt;&gt;   static difficulty setting. Hence, instead of forcing clients to go below a
&gt;&gt;   static target like in Bitcoin to be successful, we ask clients to "bid" using
&gt;&gt;   their PoW effort. Effectively, a client gets higher priority the higher
&gt;&gt;   effort they put into their proof-of-work. This is similar to how
&gt;&gt;   proof-of-stake works but instead of staking coins, you stake work.
&gt; 
&gt; So this means that desktop users will be prioritized over mobile users
&gt; basically unless I make my phone use X% of battery?

Yes. We should be clear that this is not meant to be on all the time,
and that yes, it is likely to sacrifice access by mobile users,
depending on the current attack volume/difficulty level.

The Tor Browser Android UI could inform users the service is under
attack and direct them try on their desktop instead.

&gt;&gt;   If a client receives a descriptor with "pow-params", it should assume that
&gt;&gt;   the service is expecting a PoW input as part of the introduction protocol.
&gt; 
&gt; What happens with clients _without_ PoW support? They basically won't be able
&gt; to connect I suppose? Or be put in the prio queue at the service at the very
&gt; hand with work done = 0 ?

The work_done=0 will be better. Fake work with actual work_done=0 is
just as easy to create as omitting work, for an attacker.

&gt;&gt; 3.4.1. PoW verification
&gt;&gt;
&gt;&gt;    To verify the client's proof-of-work the service extracts (hash_output,
&gt;&gt;    seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:
&gt;&gt;
&gt;&gt;    1) Make sure that the client's seed is identical to the active seed.
&gt;&gt;    2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
&gt;&gt;    3) Verify that 'hash_output =?= argon2(seed, nonce)
&gt; 
&gt; So wait, the service also has to do the PoW for each client by computing the
&gt; Argon2 hash for each cell? Or am I mis-understanding?

Yes, but the service side only has to run the hash once, which should be
fast.

The client/attacker is hashing many times, to search for a nonce that
will satisfy the target hash value comparison.

But oops! We forgot to list that directly above, which might have caused
the confusion:

0) Check that hash_output &lt;= target_level

&gt;&gt; 3.4.2. The Introduction Queue  [INTRO_QUEUE]
&gt;&gt;
&gt;&gt; 3.4.2.1. Adding introductions to the introduction queue
&gt;&gt;
&gt;&gt;   When PoW is enabled and a verified introduction comes through, the service
&gt;&gt;   instead of jumping straight into rendezvous, queues it and prioritizes it
&gt;&gt;   based on how much effort was devoted by the client to PoW. This means that
&gt;&gt;   introduction requests with high effort should be prioritized over those with
&gt;&gt;   low effort.
&gt;&gt;
&gt;&gt;   To do so, the service maintains an "introduction priority queue" data
&gt;&gt;   structure. Each element in that priority queue is an introduction request,
&gt;&gt;   and its priority is the effort put into its PoW:
&gt;&gt;
&gt;&gt;   When a verified introduction comes through, the service interprets the PoW
&gt;&gt;   hash as a 32-byte big-endian integer 'hash_int' and based on that integer it
&gt;&gt;   inserts it into the right position of the priority_queue: The smallest
&gt;&gt;   'hash_int' goes forward in the queue. If two elements have the same value,
&gt;&gt;   the older one has priority over the newer one.
&gt;&gt;   {XXX: Is this operation with 32-bytes integers expensive? How to make cheaper?}

One option: either subtract or and-off the target, so we're comparing
difficulty relative to the target - ie a much smaller integer space.

In blockchain world, typically the difficulty target is expressed as a
bitmask anyway, probably for reasons like this.

&gt;&gt;   {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
&gt;&gt;    effort what attacks can happen in various scenarios? Do we want to order on
&gt;&gt;    time+effort?  Which scenarios and attackers should we examine here?}
&gt;&gt;
&gt;&gt;   {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can we
&gt;&gt;    use WRED usefully?}
&gt; 
&gt; I think you'll be bound by the amount of data a connection inbuf can take
&gt; which has an upper bound of 32 cells each read event.
&gt; 
&gt; Then tor will have to empty at once the inbuf, queue all INTRODUCE2 cells (at
&gt; most 32) in that priority queue and once done, we would process it until we
&gt; return to handling the connection inbuf.
&gt; 
&gt; In other words, the queue size, with tor's architecture, is bound to the
&gt; number of cells upper bound you can get when doing a recv() pass which is 32
&gt; cells.
&gt; 
&gt; Nevertheless, that limit is weirdly hardcoded in tor so you should definitely
&gt; think of a way to upper bound the queue and just drop the rest. A good
&gt; starting point would be that 32 cells number?

dgoulet and I think the following will work better than always doing 32
cells at a time. Basically, the idea is to split our INTRO2 handling
into "top-half" and "bottom-half" handlers.

Top-half handling:
 1) read 32 cells off inbuf as usual
 2) do AES relay cell decryption as usual
 3) Parse relay headers, handle all cells as usual, except:
    a) in hs_service_receive_introduce2(), add to pqueue
       and return without further processing of those
 4) Return to rest of mainloop


Then, separately, also in mainloop, do the bottom half. (TODO: What
group priority?)

Bottom-half handling:
  I) pop a single intro2 off of pqueue (ie: max difficulty in queue)
 II) Compare this difficulty to desc difficulty. If lower, lower
     desc difficulty
III) Parse it and launch RP circuit (as per current bottom half of
     hs_service_receive_introduce2())
 IV) trim pqueue elements, if queue "too big" (TODO: how to trim?)
  V) Compare trim point difficulty to descriptor difficulty, if trim
     point was higher than descriptor value, raise desc difficulty
 VI) return to libevent/mainloop again


The astute reader will note that even without PoW, the above can provide
almost the exact same functionality as the naive rate limiting currently
done at intropoints - just cut the queue arbitrarily. Basically PoW and
the pqueue just gives us a smarter way to decide who to reply to.

However, it still has the following potential issues:
  A) AES will bottleneck us at ~100Mbit-300Mbit at #2 in top-half above
  B) Extra mainloop() iterations for INTRO2s may be expensive (or not?)


For A, onionbalance will still help by adding new back-end instances
providing intropoints via separate back-end Tor daemons, either on the
same box or different boxes.

But it will only help up to a point. A HSDesc maxes out at 30k, so at
some point we'll run out of space to list more intropoints in a single
descriptor. At that point, we can still list different intropoints at
each HSDir position, but after that, we are screwed.

We can alternatively avoid the AES bottleneck by moving this whole
system to the intropoint tor relay. Basically, we split
hs_intro_received_introduce1() into a top and bottom half in almost
exactly the same way we split hs_service_receive_introduce2(), and we
use the unencrypted extension field instead of the encrypted one.

This is a very straight-forward v1.5 change, but it requires intropoints
on the network to upgrade for it to work.

&gt;&gt; 3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]
&gt;&gt;
&gt;&gt;   The service should handle introductions by pulling from the introduction
&gt;&gt;   queue.
&gt;&gt;
&gt;&gt;   Similar to how our cell scheduler works, the onion service subsystem will
&gt;&gt;   poll the priority queue every 100ms tick and process the first 20 cells from
&gt;&gt;   the priority queue (if they exist). The service will perform the rendezvous
&gt;&gt;   and the rest of the onion service protocol as normal.
&gt;&gt;
&gt;&gt;   With this tempo, we can process 200 introduction cells per second.
&gt; 
&gt; As I described above, I think we might want to do something like that for
&gt; simplicity at first which is "empty inbuf by priority queuing all INTRODUCE2"
&gt; and once done, process them.
&gt; 
&gt; Thus, it won't be like the cell scheduler that accumulates until a certain
&gt; tick (10msec) and then process it all.
&gt; 
&gt;&gt;   {XXX: Is this good?}
&gt;&gt;
&gt;&gt;   {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
&gt;&gt;   per 100ms is probably unmaintainable, since each cell is quite expensive:
&gt;&gt;   doing so involving path selection, crypto and making circuits. We will need
&gt;&gt;   to profile this procedure and see how we can do this scheduling better.}
&gt; 
&gt; With the above, we should be within the same performance as we have right now
&gt; since we just deferring the processing of INTRODUCE2 cell after the inbuf is
&gt; emptied.
&gt; 
&gt;&gt;
&gt;&gt;   {XXX: This might be a nice place to promote multithreading. Queues and pools
&gt;&gt;   are nice objects to do multithreading since you can have multiple threads
&gt;&gt;   pull from the queue, or leave stuff on the queue. Not sure if this should be
&gt;&gt;   in the proposal tho.}
&gt; 
&gt; I would _love_ to but could be too early for that if we consider that we are
&gt; still unsure that this defense will be useful or not (according to Mike as a
&gt; discussion on IRC).

As described above, multithreading still provides a multiplier in the
AES bottleneck case, even over onionbalance.

But, there may be more bottlenecks than just AES crypto, so this is a
further argument for not jumping the gun just yet, and trying v1 first
(or even a simple prototype without pow, that just cuts the queue
arbitrarily), and getting some more profiling data.


Next steps (not necessarily in order):

a) pqueue plan review + more detailed description
b) Figure out pqueue trim mechanism - can we do better than O(n)?
c) test using randomx as a hash function in various ways, esp wrt
   key usage, cache setup, and VM infos
d) test pqueue refactoring, maybe without pow involved yet
e) specify a v1.5 that works at intropoint (to avoid AES bottleneck)
f) Merge this thread back into a single proposal document
g) other stuff we forgot, XXX's, TODOs, etc.


-- 
Mike Perry




["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201122011945</emailId><senderName>Ian Laurie</senderName><senderEmail>ilaurie@bigpond.net.au</senderEmail><timestampReceived>2020-11-22 01:19:45-0400</timestampReceived><subject>[tor-dev] Tor Browser 10.0.5 not functional on Fedora Rawhide</subject><body>

Regular Firefox became briefly non-functional on Fedora Rawhide due to 
the following (now resolved) bug:

https://bugzilla.redhat.com/show_bug.cgi?id=1891234

The issue was that all tabs immediately crashed making the browser 
unusable.  I believe Tor is now suffering from the same issue.

-- 
Ian Laurie

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200407142055</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-04-07 14:20:55-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]


On 06 Apr (17:08:12), Mike Perry wrote:

[snip]

&gt; &gt; I think you'll be bound by the amount of data a connection inbuf can take
&gt; &gt; which has an upper bound of 32 cells each read event.
&gt; &gt; 
&gt; &gt; Then tor will have to empty at once the inbuf, queue all INTRODUCE2 cells (at
&gt; &gt; most 32) in that priority queue and once done, we would process it until we
&gt; &gt; return to handling the connection inbuf.
&gt; &gt; 
&gt; &gt; In other words, the queue size, with tor's architecture, is bound to the
&gt; &gt; number of cells upper bound you can get when doing a recv() pass which is 32
&gt; &gt; cells.
&gt; &gt; 
&gt; &gt; Nevertheless, that limit is weirdly hardcoded in tor so you should definitely
&gt; &gt; think of a way to upper bound the queue and just drop the rest. A good
&gt; &gt; starting point would be that 32 cells number?
&gt; 
&gt; dgoulet and I think the following will work better than always doing 32
&gt; cells at a time. Basically, the idea is to split our INTRO2 handling
&gt; into "top-half" and "bottom-half" handlers.
&gt; 
&gt; Top-half handling:
&gt;  1) read 32 cells off inbuf as usual
&gt;  2) do AES relay cell decryption as usual
&gt;  3) Parse relay headers, handle all cells as usual, except:
&gt;     a) in hs_service_receive_introduce2(), add to pqueue
&gt;        and return without further processing of those
&gt;  4) Return to rest of mainloop

Agree with the above. It is trivial to do this today so very low engineering
cost.

&gt; 
&gt; Then, separately, also in mainloop, do the bottom half. (TODO: What
&gt; group priority?)
&gt; 
&gt; Bottom-half handling:
&gt;   I) pop a single intro2 off of pqueue (ie: max difficulty in queue)
&gt;  II) Compare this difficulty to desc difficulty. If lower, lower
&gt;      desc difficulty
&gt; III) Parse it and launch RP circuit (as per current bottom half of
&gt;      hs_service_receive_introduce2())
&gt;  IV) trim pqueue elements, if queue "too big" (TODO: how to trim?)
&gt;   V) Compare trim point difficulty to descriptor difficulty, if trim
&gt;      point was higher than descriptor value, raise desc difficulty
&gt;  VI) return to libevent/mainloop again

I would maybe try to convince you that we could dequeue more than 1 cell here
because this behavior is changing quite a bit the current state of HS.

Right now, we would get 32 cells out of the inbuf and one at a time, process
it then go back to mainloop.

This new algorithm means that we would process 1 single cell at each mainloop
event instead of 32. This is quite a decrease. Ok, it is not that exact ration
because maybe dequeue the inbuf without processing the decrypted INTRO2 is
fast but it is still a full mainloop run per cell is clearly slower than right
now.

We need some sort of performance measurements here to make an informed
decision but my guts feeling tells me that we might want to don't know process
5 or 10 cells instead of 1 per mainloop round.

We _should_ run timing measurement here to see how much delaying INTRO2
processing to another mainloop event affects the overall rate of introduction.

But let say a full mainloop run takes 100msec, we will process 50
introductions per second... that looks quite low? But could be already what we
do now, unknown.

&gt; 
&gt; 
&gt; The astute reader will note that even without PoW, the above can provide
&gt; almost the exact same functionality as the naive rate limiting currently
&gt; done at intropoints - just cut the queue arbitrarily. Basically PoW and
&gt; the pqueue just gives us a smarter way to decide who to reply to.
&gt; 
&gt; However, it still has the following potential issues:
&gt;   A) AES will bottleneck us at ~100Mbit-300Mbit at #2 in top-half above
&gt;   B) Extra mainloop() iterations for INTRO2s may be expensive (or not?)

Possibly, from the above, some analysis should happen. I can easily do that
once we get the tracing API upstream.

&gt; 
&gt; For A, onionbalance will still help by adding new back-end instances
&gt; providing intropoints via separate back-end Tor daemons, either on the
&gt; same box or different boxes.
&gt; 
&gt; But it will only help up to a point. A HSDesc maxes out at 30k, so at
&gt; some point we'll run out of space to list more intropoints in a single
&gt; descriptor. At that point, we can still list different intropoints at
&gt; each HSDir position, but after that, we are screwed.

Small correctino. HSDesc max at 50k for v3 and 20k for v2. But lets just
consider v3 for the forseable future :D.

[snip]

&gt; &gt; I would _love_ to but could be too early for that if we consider that we are
&gt; &gt; still unsure that this defense will be useful or not (according to Mike as a
&gt; &gt; discussion on IRC).
&gt; 
&gt; As described above, multithreading still provides a multiplier in the
&gt; AES bottleneck case, even over onionbalance.
&gt; 
&gt; But, there may be more bottlenecks than just AES crypto, so this is a
&gt; further argument for not jumping the gun just yet, and trying v1 first
&gt; (or even a simple prototype without pow, that just cuts the queue
&gt; arbitrarily), and getting some more profiling data.

As an initial step, I agree. Onionbalance provides an easy way for service to
outsource client introduction to more CPUs.

But, in my opinion, onionbalance is a power user solution and thus usually a
small percentage of our .onion users that can take advantage of it. As .onion
move more and more in the mobile sphere and client to client applications
(onionshare, ricochet), it ain't much of an option :S.

Without using more CPUs in Tor, I have a _hard_ time seeing tor scale over
time especially for services. As long as we keep that in mind with our
designs, I'm good :).

&gt; 
&gt; Next steps (not necessarily in order):
&gt; 
&gt; a) pqueue plan review + more detailed description
&gt; b) Figure out pqueue trim mechanism - can we do better than O(n)?

Initially, we could simply go with an upper limit and just drop cells as you
queue them if you are above limit? As in drop back() if you reach the limit
everytime you queue?

Else, we can get into more complicated schemes with queueing rate versus
processing rate and come down with a golden number to strike a memory and CPU
balance...?

&gt; c) test using randomx as a hash function in various ways, esp wrt
&gt;    key usage, cache setup, and VM infos
&gt; d) test pqueue refactoring, maybe without pow involved yet
&gt; e) specify a v1.5 that works at intropoint (to avoid AES bottleneck)
&gt; f) Merge this thread back into a single proposal document

We could put the engineering details could be in an Annexe of the proposal if
we don't want to loose track of it and not dispersed on a mailing list :)?

I'm happy to help with this, let me know.

&gt; g) other stuff we forgot, XXX's, TODOs, etc.

Cheers!
David

-- 
6Kt/Zhrgtx/7LnJzUvEZzDZSIq5yophZyqpI6PgAsv4=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200508195310</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-05-08 19:53:10-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi all,

I was asked by George to submit my comments about the proposal and to suggest
suitable RandomX parameters for this PoW scheme.

&gt; For our dynamic PoW system to work, we will need to be able to compare PoW
&gt;  tokens with each other. To do so we define a function:
&gt;         unsigned effort(uint8_t *token)
&gt;  which takes as its argument a hash output token, and returns the number of
&gt;  leading zero bits on it.

This definition makes the effort exponential, i.e. the computational resources
required to reach one notch higher effort increase by a factor of 2 each time.

I suggest to use linear effort defined as the quotient of dividing a bitstring
of 1s by the hash value:

== Example A:

  effort(00000001100010101101) = 11111111111111111111 / 00000001100010101101

or in decimal:

  effort(6317) = 1048575 / 6317 = 165.

This definition of effort has the advantage of directly expressing the expected
number of hashes that the client had to calculate to reach the effort.

With the exponential definition, we could have an equivalent linear effort of
either 128 (7 leading zeroes) or 256 (8 leading zeroes), while the linear
definition provides smoother classification of PoW results.



&gt;   The EXT_FIELD content format is:
&gt;
&gt;      POW_VERSION    [1 byte]
&gt;      POW_NONCE      [32 bytes]
&gt;

I suggest to use a 16-byte nonce value, which is more than sufficient given the
target security level and has the benefit of reducing the replay cache size to
half.

Since we expect the seed to be valid for around 3 hours (as proposed), then even
if the service receives 1 million proofs per second and each proof has an effort
of 1 million, then the number of submitted nonces from clients will only reach
about 10^10. With a 108-bit solution space (subtracting 20 bits as the search
space per client), the probability that two clients accidentally submit the same
nonce is roughly 10^-13 (see [REF_BIRTHDAY]).

Additionally, I suggest to add the client's effort for convenience:

   The updated EXT_FIELD content format would be:

      POW_VERSION    [1 byte]
      POW_EFFORT     [4 bytes]
      POW_NONCE      [16 bytes]

Including the effort has 2 benefits:

    1. In case the Intro Priority Queue is full, the service doesn't need to
       waste time verifying PoW solutions that have effort lower than the last
       element in the queue. While an attacker can always lie about the actual
       effort of their nonce value, I think this field can still save some CPU
       cycles when the service is under heavy load.

    2. The service can conveniently verify the reported effort with
       the following inequality:

           POW_EFFORT * pow_function(POW_NONCE, SEED) &lt;= MAX_RESULT

       where MAX_RESULT is the highest possible output from the pow_function.
       In the case of Example A, that would be:

           165 * 6317 = 1042305 &lt;= 1048576



&gt;  Similar to how our cell scheduler works, the onion service subsystem will
&gt;  poll the priority queue every 100ms tick and process the first 20 cells from
&gt;  the priority queue (if they exist). The service will perform the rendezvous
&gt;  and the rest of the onion service protocol as normal.

I suggest to use a different selection method rather than always taking
the first 20 requests.

Selecting cells from the front of the queue actually minimizes the effort that
an attacker needs to expend to completely block access to the service.
The attacker can always submit the minimum effort required to occupy the first
20 slots in each 100 ms window. This can be done by submitting just 200 requests
per second and observing how many circuits are successfully open and adjusting
the effort until no other request can go through. This is the "Total overwhelm
strategy" described in   5.1.1.

See the following examples to show how selecting the first N cells from
the queue is unfair. I will use N = 4 for clarity. E denotes some value of
effort.

== Example B:

               ATTACKER                       LEGITIMATE CLIENTS
     ___________      _________         ____________       ______________
    /                          \       /                                 \

+--------+--------+--------+--------+----+----+----+----+----+----+----+----+
|   2E   |   2E   |   2E   |   2E   |  E |  E |  E |  E |  E |  E |  E |  E |
+--------+--------+--------+--------+----+----+----+----+----+----+----+----+

    ^        ^        ^        ^
 selected selected selected selected

Here both the attacker and the legitimate clients have expended a combined
effort of 8E. All of the attacker's cells get selected, while none of the other
clients get through.

Instead, I suggest to use Stochastic universal sampling [REF_SUS], where
the probability that a cell gets selected is proportional to its effort.

== Example C:

Here the total effort in the queue is 16E, so we first select a random value in
the interval [0, 4E) and then select 4 evenly spaced cells:

               ATTACKER                       LEGITIMATE CLIENTS
     ___________      _________         ____________       ______________
    /                          \       /                                 \

+--------+--------+--------+--------+----+----+----+----+----+----+----+----+
|   2E   |   2E   |   2E   |   2E   |  E |  E |  E |  E |  E |  E |  E |  E |
+--------+--------+--------+--------+----+----+----+----+----+----+----+----+

      ^                  ^                  ^                  ^
  selected            selected           selected           selected

In this case, 2 cells are selected from each group, which is fairer considering
that each group expended the same effort.

== Example D:

Now if the attacker wanted to block access to all legitimate clients, they would
need to at least quadruple their total PoW effort (and there would still be
a chance that a legitimate client gets selected from the end of the queue):

                             ATTACKER                        LEGITIMATE CLIENTS
  __________________________          ______________________   ______________
 /                                                          \ /              \

+--------------+--------------+---------------+--------------+-+-+-+-+-+-+-+-+
|       8E     |       8E     |       8E     |       8E      |E|E|E|E|E|E|E|E|
+--------------+--------------+--------------+---------------+-+-+-+-+-+-+-+-+

   ^                  ^                  ^                  ^
selected            selected           selected          selected

Note: With linear effort, the original selection method becomes even worse
because the attacker can occupy the front of the queue with an effort of just
E+1 per cell rather than 2E.

In some cases, Stochastic universal sampling can select a single element
multiple times, which is not a problem for genetic algorithms, but we want to
avoid it. I suggest to restart the selection algorithm from the beginning of
the next cell in those cases and shorten the sampling interval according to
the remaining portion of the queue. See the following example.

== Example E:

+---------------+-------------+--------------+------------+-+-+-+-+-+-+-+-+-+-+
|              16E            |       8E     |     6E     |E|E|E|E|E|E|E|E|E|E|
+---------------+-------------+--------------+------------+-+-+-+-+-+-+-+-+-+-+

      ^                                  ^              ^              ^
  selected                            selected       selected       selected



&gt;  In particular, the service starts with a default suggested-effort value of 15.
&gt;
&gt;  Everytime the service handles an introduction request from the priority queue
&gt;  in [HANDLE_QUEUE], the service compares the request's effort to the current
&gt;  suggested-effort value. If the new request's effort is lower than the
&gt;  suggested-effort, set the suggested-effort equal to the effort of the new
&gt;  request.
&gt;
&gt;  Everytime the service trims the priority queue in [HANDLE_QUEUE], the service
&gt;  compares the request at the trim point against the current suggested-effort
&gt;  value. If the trimmed request's effort is higher than the suggested-effort,
&gt;  set the suggested-effort equal to the effort of the new request.

I think the default suggested-effort is a bit too high. Assuming each attempt
takes around 1 ms to calculate, the client would need, on average,
2^15 ms = 33 seconds to find a solution using 1 CPU core. I suggest to specify
a minimum effort instead. Requests with effort &lt; MIN_EFFORT and requests without
the PROOF_OF_WORK extension would be treated as having effort = 1 for
the purposes of the sampling algorithm.

Secondly, the proposed method of calculating the suggested-effort is susceptible
to gaming by attackers. Since the service can only update the value in
the directory once every 'hs-pow-desc-upload-rate-limit' seconds, they could
stop the attack for a little while just before the directory gets updated, which
would cause the suggested-effort value to be too low despite an ongoing attack.

I suggest to take the median effort of the selected cells during each 100 ms
window. For the examples above that would be:

  Example C: 1.5E
  Example D: 8E
  Example E: 7E

Then I would take the median of these values over the directory update period.

&gt;
&gt; 5. Attacker strategies
&gt;

Additional attacks:

5.1.2 PoW Spam Attack

The attacker may try to spam many requests with random values of POW_NONCE,
requiring the service to waste cycles verifying the invalid proofs. No such
request would make it into the Intro Queue, but it may still be a viable DoS
strategy depending on proof verification time and the number of intro requests
that can be practically delivered through the network.

5.1.3 Precomputed PoW attack

The attacker may precompute many valid PoW nonces and submit them all at once
before the current seed expires, overwhelming the service temporarily even
using a single computer.


&gt; 4.2. Seed expiration issues
&gt;
&gt;  As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
&gt;  cause issues with clock skewed clients. Furthermore, even not clock skewed
&gt;  clients can encounter TOCTOU-style race conditions here.
&gt;
&gt;  The client descriptor refetch logic of [CLIENT_TIMEOUT] should take care of
&gt;  such seed-expiration issues, since the client will refetch the descriptor.
&gt;

I suggest to use 2 concurrent seeds, i.e. to accept PoW both from the current
and the last seed epoch. We use this approach in Monero. It would however
require adding the seed value into the proof of work extension field and also
double the memory requirements for verification with RandomX.

&gt;   The proposal suggests argon2, and Mike has been looking at Randomx. However,
&gt;   after further consideration and speaking with some people (props to Alex
&gt;   Biryukov), it seems like those two functions are not well fitted for this
&gt;   purpose, since they are memory-hard both for the client and the service. And
&gt;   since we are trying to minimize the verification overhead, so that the
&gt;   service can do hundreds of verifications per second, they don't seem like
&gt;   good fits.

Asymmetric function like Equihash, Cuckoo cycle [REF_CUCKOO] and MTP have the
advantage of being very fast to verify, but they run much faster on GPUs and
specialized hardware, so I don't think they are particularly suitable for this
purpose.

When we designed RandomX to be used as the PoW algorithm by Monero, we selected
the parameters very conservatively to maximize the ASIC resistance of
the algorithm. That's because it is very difficult to change the PoW algorithm
once it's deployed.

TOR is not limited by this, so we can be much more aggressive when configuring
RandomX. I suggest to use a configuration that gives the fastest possible
verification time without completely breaking the algorithm.

In particular, the following parameters should be set differently from Monero:

    RANDOMX_ARGON_SALT = "RandomX-TOR-v1"

The unique RandomX salt means we do not need to use a separate salt as PoW input
as specified in   3.2.

    RANDOMX_ARGON_ITERATIONS = 1
    RANDOMX_CACHE_ACCESSES = 4
    RANDOMX_DATASET_BASE_SIZE = 1073741824
    RANDOMX_DATASET_EXTRA_SIZE = 16777216

These 4 changes reduce the RandomX Dataset size to ~1 GiB, which allows
the number of iteration to be reduced from 8 to 4. The combined effect of this
is that Dataset initialization becomes 4 times faster, which is needed due to
more frequent updates of the seed (Monero updates once per ~3 days).

    RANDOMX_PROGRAM_COUNT = 2
    RANDOMX_SCRATCHPAD_L3 = 1048576

Additionally, reducing the number of programs from 8 to 2 makes the hash
calculation about 4 times faster, while still providing resistance against
program filtering strategies (see [REF_RANDOMX_PROGRAMS]). Since there are
4 times fewer writes, we also have to reduce the scratchpad size. I suggest to
use a 1 MiB scratchpad size as a compromise between scratchpad write density and
memory hardness. Most x86 CPUs will perform roughly the same with a 512 KiB and
1024 KiB scratchpad, while the larger size provides higher resistance against
specialized hardware, at the cost of possible time-memory tradeoffs (see
[REF_RANDOMX_TMTO] for details).

Lastly, we reduce the output of RandomX to just 8 bytes:

    RANDOMX_HASH_SIZE = 8

64-bit preimage security is more than sufficient for proof-of-work and it allows
the result to be treated as a little-endian encoded unsigned integer for easy
effort calculation.

RandomX would be used as follows:

The service will select a 32-byte POW_SEED and initialize the cache and
the dataset:

    randomx_init_cache(myCache, POW_SEED, 32);
    randomx_init_dataset(myDataset, myCache, 0, randomx_dataset_item_count());

    randomx_vm *myMachine = randomx_create_vm(flags, NULL, myDataset);

Then in order to validate a PoW token, we could use something like this:

    int validateProof(uint32_t pow_effort, void* pow_nonce) {

        uint64_t result;

        randomx_calculate_hash(myMachine, pow_nonce, 16, &amp;result);

        if (mulh(pow_effort, result) == 0) {
            return 1;
        }

        return 0;
    }

I suggest to set MIN_EFFORT = 10000, which takes about 1 second on my laptop.
Requests with pow_effort &lt; MIN_EFFORT would not be validated.

I have collected some performance figures for the fast mode with the above
RandomX configuration (~1 GiB of memory is required):

H/s = hashes per second

== CPUs:

  Intel Core i3-3220
    - 1 thread           700 H/s
    - 3 threads         1400 H/s

  Intel Xeon (dual core VPS, Sandy Bridge, unknown model)
    - 1 thread          2000 H/s
    - 2 threads         4000 H/s

  Intel Core i5-2500K (stock)
    - 1 thread          2200 H/s
    - 4 threads         8200 H/s

  Intel Core i7-8550U (laptop)
    - 1 thread          2700 H/s
    - 8 threads        10000 H/s

  Intel Core i7-9850H (laptop)
    - 1 thread          3100 H/s
    - 12 threads       16000 H/s

  AMD Ryzen 1700  @ 3300MHz
    - 1 thread          2300 H/s
    - 16 threads       23800 H/s

  AMD Ryzen 3700X @ 3300MHz
    - 1 thread          2500 H/s
    - 16 threads       27500 H/s

  AMD Epyc 7702P
    - 1 thread          2100 H/s
    - 128 threads     139000 H/s

== GPUs:

  NVIDIA GeForce GTX 1660 Ti (credits to SChernykh, see [REF_RANDOMX_CUDA])
    - 3072 intensity    2600 H/s


According to the above results, the time to verify a single hash is around
400-500 s. A mid-range GPU has a similar performance as a single CPU core.
Most CPUs made since 2011 have similar per-core performance except of low-end
CPUs without hardware AES support.

References:

  [REF_BIRTHDAY]: https://en.wikipedia.org/wiki/Birthday_attack#Mathematics

  [REF_SUS]: https://en.wikipedia.org/wiki/Stochastic_universal_sampling

  [REF_CUCKOO]: https://github.com/tromp/cuckoo

  [REF_RANDOMX_PROGRAMS]:
https://github.com/tevador/RandomX/blob/master/doc/design.md#12-the-easy-program-problem

  [REF_RANDOMX_TMTO]: https://github.com/tevador/RandomX/issues/65

  [REF_RANDOMX_CUDA]: https://github.com/SChernykh/RandomX_CUDA
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200509193852</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-05-09 19:38:52-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

On 08 May, 21:53, tevador &lt;tevador@gmail.com&gt; wrote:
&gt; In particular, the following parameters should be set differently from
&gt; Monero:
&gt;
&gt;     RANDOMX_ARGON_SALT = "RandomX-TOR-v1"
&gt;
&gt; The unique RandomX salt means we do not need to use a separate salt as PoW
&gt; input as specified in   3.2.
&gt;
&gt;     RANDOMX_ARGON_ITERATIONS = 1
&gt;     RANDOMX_CACHE_ACCESSES = 4
&gt;     RANDOMX_DATASET_BASE_SIZE = 1073741824
&gt;     RANDOMX_DATASET_EXTRA_SIZE = 16777216
&gt;
&gt; These 4 changes reduce the RandomX Dataset size to ~1 GiB, which allows
&gt; the number of iteration to be reduced from 8 to 4. The combined effect of
&gt; this is that Dataset initialization becomes 4 times faster, which is needed
&gt; due to more frequent updates of the seed (Monero updates once per ~3 days).
&gt;
&gt;     RANDOMX_PROGRAM_COUNT = 2
&gt;     RANDOMX_SCRATCHPAD_L3 = 1048576
&gt;
&gt; Additionally, reducing the number of programs from 8 to 2 makes the hash
&gt; calculation about 4 times faster, while still providing resistance against
&gt; program filtering strategies (see [REF_RANDOMX_PROGRAMS]). Since there are
&gt; 4 times fewer writes, we also have to reduce the scratchpad size. I suggest
&gt; to use a 1 MiB scratchpad size as a compromise between scratchpad write
&gt; density and memory hardness. Most x86 CPUs will perform roughly the same
&gt; with a 512 KiB and 1024 KiB scratchpad, while the larger size provides
&gt; higher resistance against specialized hardware, at the cost of possible
&gt; time-memory tradeoffs (see [REF_RANDOMX_TMTO] for details).
&gt;
&gt; Lastly, we reduce the output of RandomX to just 8 bytes:
&gt;
&gt;    RANDOMX_HASH_SIZE = 8
&gt;
&gt; 64-bit preimage security is more than sufficient for proof-of-work and it
&gt; allows the result to be treated as a little-endian encoded unsigned integer
&gt; for easy effort calculation.

I have implemented this in the tor-pow branch of the RandomX repository:

    https://github.com/tevador/RandomX/tree/tor-pow

Namely I have changed the API to return the hash value as an uint64_t and
made corresponding changes in the benchmark.

Benchmark example:

    ./randomx-benchmark --mine \
                        --avx2 \
                        --jit  \
                        --largePages \
                        --nonces 10000 \
                        --seed 1234 \
                        --init 1 \
                        --threads 1 \
                        --batch
    RandomX-TOR-v1 benchmark
     - Argon2 implementation: AVX2
     - full memory mode (1040 MiB)
     - JIT compiled mode
     - hardware AES mode
     - large pages mode
     - batch mode
    Initializing (1 thread) ...
    Memory initialized in 5.32855 s
    Initializing 1 virtual machine(s) ...
    Running benchmark (10000 nonces) ...
    Performance: 2535.43 hashes per second
    Best result:
      Nonce: 8bc3ded34d2dcdeed9000000f95cd20c
      Result: d947ceff08750300
      Effort: 18956
      Valid: 1

At the end, it prints out the nonce that gives the highest effort value and
validates it.

For the actual implementation in TOR, the RandomX validator should run in
a separate thread that doesn't do anything else apart from validation and
moving valid requests into the Intro Queue. This way we can reach the maximum
performance of ~2000 processed requests per second.

Finally, here are some disadvantages of RandomX-TOR:

 1) Fast verification requires ~1 GiB of memory. If we decide to use two
    overlapping seed epochs, each service will need to allocate &gt;2 GiB of RAM
    just to verify the PoW. Alternatively, it is possible to use the slow
    mode, which requires only 256 MiB per seed, but runs 4x slower.
 2) The fast mode needs about 5 seconds to initialize every time the
seed is      changed (can be reduced to under 1 second using multiple
threads). The
    slow mode needs about 0.1 seconds to initialize.
 3) RandomX includes a JIT compiler for maximum performance. The iOS operating
    system doesn't support JIT compilation, so RandomX runs about 10x slower
    there.
 4) The JIT compiler in RandomX is currently implemented only for
x86-64 and      ARM64 CPU architectures. Other architectures will run
very slowly
    (especially 32-bit systems). However, the two supported architectures
    cover the vast majority of devices, so this should not be an issue.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200510043617</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-10 04:36:17-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi tevador,

&gt; On 9 May 2020, at 06:43, tevador &lt;tevador@gmail.com&gt; wrote:
&gt;&gt; For our dynamic PoW system to work, we will need to be able to compare PoW
&gt;&gt; tokens with each other. To do so we define a function:
&gt;&gt;        unsigned effort(uint8_t *token)
&gt;&gt; which takes as its argument a hash output token, and returns the number of
&gt;&gt; leading zero bits on it.
&gt; 
&gt; This definition makes the effort exponential, i.e. the computational resources
&gt; required to reach one notch higher effort increase by a factor of 2 each time.
&gt; 
&gt; I suggest to use linear effort defined as the quotient of dividing a bitstring
&gt; of 1s by the hash value:
&gt; 
&gt; == Example A:
&gt; 
&gt;  effort(00000001100010101101) = 11111111111111111111 / 00000001100010101101
&gt; 
&gt; or in decimal:
&gt; 
&gt;  effort(6317) = 1048575 / 6317 = 165.
&gt; 
&gt; This definition of effort has the advantage of directly expressing the expected
&gt; number of hashes that the client had to calculate to reach the effort.
&gt; 
&gt; With the exponential definition, we could have an equivalent linear effort of
&gt; either 128 (7 leading zeroes) or 256 (8 leading zeroes), while the linear
&gt; definition provides smoother classification of PoW results.

There are two possible issues with this design:

Division is expensive on some platforms, including ARM-based devices.
But there might be a way to calculate an approximate value without division.
(For example, bit shifts, or multiplying by an inverse.) Or we could calculate
the maximum value once, and then re-use it.

Is it still possible to express the full range of difficulties? Is that expression
reasonably compact?

Some advantages of this exponential distribution are:
* spurious results can be filtered using a single instruction (a bit mask),
* the expected effort is quick and easy to calculate,
* the effort can be expressed in a compact way.

Maybe we don't need some of these properties, and a linear design would
be fine.

But if we do, we could change the exponent to the square or cube root of
two. There would be a smoother distribution, but a wider range, and the
checks would still be reasonably fast.

T


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200510125159</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-05-10 12:51:59-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi teor,

On Sun, May 10, 2020 at 6:36 AM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; There are two possible issues with this design:
&gt;
&gt; Division is expensive on some platforms, including ARM-based devices.
&gt; But there might be a way to calculate an approximate value without division.
&gt; (For example, bit shifts, or multiplying by an inverse.) Or we could
&gt; calculate the maximum value once, and then re-use it.
&gt;
&gt; Is it still possible to express the full range of difficulties? Is that
&gt; expression reasonably compact?
&gt;
&gt; Some advantages of this exponential distribution are:
&gt; * spurious results can be filtered using a single instruction (a bit mask),
&gt; * the expected effort is quick and easy to calculate,
&gt; * the effort can be expressed in a compact way.
&gt;
&gt; Maybe we don't need some of these properties, and a linear design would
&gt; be fine.
&gt;
&gt; But if we do, we could change the exponent to the square or cube root of
&gt; two. There would be a smoother distribution, but a wider range, and the
&gt; checks would still be reasonably fast.
&gt;
&gt; T
&gt;

You only need 1 or 2 divisions per introduction request, so it doesn't matter
even if division is expensive, because it will take a minuscule amount of time
compared to the actual hashing effort.

There are 2 scenarios:

1) User wants to wait for X seconds and then submit the best result they could
   find.

2) User wants to wait as long as it takes to submit a result with an effort
   of at least E.

In case 1), the client will simply take the smallest result R found during the
X seconds and calculate ACTUAL_EFFORT = MAX_RESULT / R at the end.

In case 2), the client will calculate TARGET = MAX_RESULT / E at the beginning
and keep hashing until they find a result R &lt;= TARGET. Then they can calculate
ACTUAL_EFFORT = MAX_RESULT / R at the end, which implies ACTUAL_EFFORT &gt;= E.

Case 1) takes 1 division instruction, case 2) takes 2 division instructions.
When hashing, the client can filter results with a single instruction
(comparison).

Examples:

1) After X seconds, the client finds results 660445, 6317, 599102 ... 111847.
   The smallest result is 6317, so:

      ACTUAL_EFFORT = 1048575 / 6317 = 165

2) The client wants to find a result with an effort of at least E = 165, so
   they calculate TARGET = 1048575 / 165 = 6355. Then they can keep hashing
   until they find R &lt;= 6355, e.g. 6317. The actual effort is calculated
   as above.

So the only advantage of the exponential notation is:

&gt;
&gt; * the effort can be expressed in a compact way.
&gt;

This can save a few characters in the HS descriptor, at the cost of a coarse
effort classification, e.g. clients who spent 60 seconds hashing will be, on
average, classified the same as those who spent 100 seconds.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200513210040</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-05-13 21:00:40-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi tevador,

On 5/8/20 2:53 PM, tevador wrote:
&gt; Including the effort has 2 benefits:
&gt; 
&gt;     1. In case the Intro Priority Queue is full, the service doesn't need to
&gt;        waste time verifying PoW solutions that have effort lower than the last
&gt;        element in the queue. While an attacker can always lie about the actual
&gt;        effort of their nonce value, I think this field can still save some CPU
&gt;        cycles when the service is under heavy load.
&gt; 
&gt;     2. The service can conveniently verify the reported effort with
&gt;        the following inequality:
&gt; 
&gt;            POW_EFFORT * pow_function(POW_NONCE, SEED) &lt;= MAX_RESULT
&gt; 
&gt;        where MAX_RESULT is the highest possible output from the pow_function.
&gt;        In the case of Example A, that would be:
&gt; 
&gt;            165 * 6317 = 1042305 &lt;= 1048576
&gt; 
&gt; 
&gt; 
&gt;&gt;  Similar to how our cell scheduler works, the onion service subsystem will
&gt;&gt;  poll the priority queue every 100ms tick and process the first 20 cells from
&gt;&gt;  the priority queue (if they exist). The service will perform the rendezvous
&gt;&gt;  and the rest of the onion service protocol as normal.
&gt; 
&gt; I suggest to use a different selection method rather than always taking
&gt; the first 20 requests.
&gt; 
&gt; Selecting cells from the front of the queue actually minimizes the effort that
&gt; an attacker needs to expend to completely block access to the service.
&gt; The attacker can always submit the minimum effort required to occupy the first
&gt; 20 slots in each 100 ms window. This can be done by submitting just 200 requests
&gt; per second and observing how many circuits are successfully open and adjusting
&gt; the effort until no other request can go through. This is the "Total overwhelm
&gt; strategy" described in   5.1.1.

Hrm, you seem to have read the original proposal and missed some of the
follow-on threads.

We moved away from a 100ms tick-based system into a top-half and
bottom-half handler design, which updates the difficulty target as well.
I tried to describe this in the top-half and bottom-half handler steps
in my reply:
https://lists.torproject.org/pipermail/tor-dev/2020-April/014219.html

In short, we let the queue grow at a faster rate than we serve, and we
trim it occasionally. Those steps set the descriptor difficulty a
property of based on what the service can actually serve from the queue
and based on the queue trim point. We allow clients to pick a higher
difficulty arbitrarily to jump to the head of the queue, if they notice
they are still not getting service based on the descriptor difficulty.

This also eliminates the need for a "default" difficulty.

So in order for the attacker to "total overwhelm" that system, don't
they have to submit not just 200 requests per second, but *continuously*
send requests with higher difficulty than anyone else in the queue, in
order to fully deny service?

Are there other reasons to do stochastic sampling over a priority queue,
given this top-half and bottom-half design?

-- 
Mike Perry


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200513224829</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-05-13 22:48:29-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi Mike,

My apologies. I thought this later email from 14th April had the
latest version of the proposal:
https://lists.torproject.org/pipermail/tor-dev/2020-April/014225.html

&gt; In short, we let the queue grow at a faster rate than we serve, and we
&gt; trim it occasionally.

What is the benefit of this approach rather than discarding low
priority requests right away in the top-half handler?

Note that a priority queue is typically implemented as a heap, which
does not support efficient trimming.

&gt; However, it still has the following potential issues:
&gt;  A) AES will bottleneck us at ~100Mbit-300Mbit at #2 in top-half above
&gt;  B) Extra mainloop() iterations for INTRO2s may be expensive (or not?)

I don't think AES is the main concern here. Each introduction request
is 512 bytes (AFAIK), so with a PoW verification performance of 2000
requests per second, the top-half handler will bottleneck at ~1 MB/s.

&gt; Are there other reasons to do stochastic sampling over a priority queue,
&gt; given this top-half and bottom-half design?

After thinking about it more, I would recommend starting with a simple
priority queue as proposed. More complex solutions can be implemented
later if field testing finds issues.

T.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200606122910</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-06-06 12:29:10-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

I've been working on a custom PoW algorithm specifically for this
proposal. It is 10x faster to verify than RandomX-Tor and doesn't
require any memory for verification.

Full write-up is here: https://github.com/tevador/equix/blob/master/devlog.md

Especially the comparison table in the Appendix may be of interest to
this discussion.

T.

On Sat, May 9, 2020 at 9:38 PM tevador &lt;tevador@gmail.com&gt; wrote:
&gt; I have implemented this in the tor-pow branch of the RandomX repository:
&gt;
&gt;     https://github.com/tevador/RandomX/tree/tor-pow
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200606133620</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-06-06 13:36:20-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

On Mon, May 18, 2020 at 1:01 PM &lt;yoehoduv@protonmail.com&gt; wrote:
&gt;
&gt; When a cell with a small effort in the queue has any chance of getting
&gt; selected, the optimal strategy for a legitimate client would be to
&gt; compute nonces and send as many nonces as possible until it causes
&gt; congestion on his network.  Instead when only the cell with the highest
&gt; effort is processed, sending more than one nonces per connection does no
&gt; good for a client.  We want each legitimate client to send only one
&gt; nonce per connection.
&gt;

Sending many requests is not the optimal strategy. One high-effort
request would have exactly the same chance of being selected as many
low-effort requests with the same total effort. The difference is that
with many requests, the client wouldn't know which rendezvous would be
selected, so he'd have to waste resources on opening many circuits.

Anyways, I suggest using a priority queue first and see how it works
in practice. To allow efficient insertion and trimming, the queue can
be implemented as a red-black tree.

&gt; As of trimming the priority queue, we don't have to use a heap.  We can
&gt; compress the effort into maybe 7 bits, and then store the requests in
&gt; 128 arrays.  Then trimming it is freeing an array.  The compression can
&gt; be something like floating point.
&gt;
&gt;    ~clz(POW_NONCE) &lt;&lt; 1 | (POW_NONCE &gt;&gt; (127 - clz(POW_NONCE))) &amp; 1
&gt;
&gt; That is, take the number of leading zeros and by one bit on the right of
&gt; the leftmost 1 bit, then complement the first part to preserve order.
&gt; We can expect the number of leading zeros to be less than 64, so this
&gt; will take 7 bits.  A decrement of this value means about 1.3 - 1.5 times
&gt; more work, which should be finely enough grained.

What you are describing is called a hashtable. The question is: what
happens when one of the arrays gets filled up? You would have to
discard all additional requests coming into that bucket. With your
construction, it's very likely that most requests would end up in just
a few buckets and the rest would remain empty (e.g. all buckets for
more than 40 leading zeroes).

T.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200607064234</emailId><senderName></senderName><senderEmail>yoehoduv</senderEmail><timestampReceived>2020-06-07 06:42:34-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

&gt; Sending many requests is not the optimal strategy. One high-effort
&gt; request would have exactly the same chance of being selected as many
&gt; low-effort requests with the same total effort. The difference is that
&gt; with many requests, the client wouldn't know which rendezvous would be
&gt; selected, so he'd have to waste resources on opening many circuits.

Is solving for a high-effort solution different from solving for a
lower-effort solution?  If not, many lower-effort solutions will be
found while working for a high-effort solution.  Then nothing stops a
client from making requests with those lower-effort solutions as well.
I can expect to find 2 solutions of effort E/2 for every solution of
effort E.  If I make 3 requests with those solutions, my chance of
succeeding doubles, at the cost of 3 times the server's verification
effort.

One way is to include the target effort in requests, and include both
the server-provided nonce and the target effort as the x in Hx.  Then
only check that the real effort comes out no less than the target
effort, but use the target effort for everything else.

&gt; Anyways, I suggest using a priority queue first and see how it works
&gt; in practice. To allow efficient insertion and trimming, the queue can
&gt; be implemented as a red-black tree.
&gt;
&gt; &gt; As of trimming the priority queue, we don't have to use a heap. We can
&gt; &gt; compress the effort into maybe 7 bits, and then store the requests in
&gt; &gt; 128 arrays. Then trimming it is freeing an array. The compression can
&gt; &gt; be something like floating point.
&gt; &gt; ~clz(POW_NONCE) &lt;&lt; 1 | (POW_NONCE &gt;&gt; (127 - clz(POW_NONCE))) &amp; 1
&gt; &gt; That is, take the number of leading zeros and by one bit on the right of
&gt; &gt; the leftmost 1 bit, then complement the first part to preserve order.
&gt; &gt; We can expect the number of leading zeros to be less than 64, so this
&gt; &gt; will take 7 bits. A decrement of this value means about 1.3 - 1.5 times
&gt; &gt; more work, which should be finely enough grained.
&gt;
&gt; What you are describing is called a hashtable. The question is: what
&gt; happens when one of the arrays gets filled up? You would have to
&gt; discard all additional requests coming into that bucket. With your
&gt; construction, it's very likely that most requests would end up in just
&gt; a few buckets and the rest would remain empty (e.g. all buckets for
&gt; more than 40 leading zeroes).

I was thinking of dynamically sized arrays.  Anyway, my point was we
don't need to compare 128-bit solutions.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200607094645</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-06-07 09:46:45-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

On Sun, Jun 7, 2020 at 8:42 AM &lt;yoehoduv@protonmail.com&gt; wrote:
&gt;
&gt; One way is to include the target effort in requests, and include both
&gt; the server-provided nonce and the target effort as the x in Hx.  Then
&gt; only check that the real effort comes out no less than the target
&gt; effort, but use the target effort for everything else.
&gt;

That's a very good idea. It would also prevent "lucky" high-effort
solutions (unless the client wants to play the lottery).

With the Equi-X puzzle, it would work like this:

C   ... server challenge (32 bytes)
N   ... client nonce (16 bytes)
E   ... client target effort (4 bytes, little endian)
S   ... Equi-X solution (16 bytes)
R   ... hash result (4 bytes, little endian)
||  ... concatenation operator

The client's algorithm:
Input: C
1) Select N, E
2) Calculate S = equix_solve(C || N || E)
3) Calculate R = blake2b(C || N || E || S)
4) if R * E &gt; UINT32_MAX, go back to step 1)
5) Submit C, N, E, S (68 bytes total)

The server's algorithm:
Input: C, N, E, S
1) Check that C is a valid challenge (there may be multiple challenges
active at a time).
2) Check that E is above the minimum effort
3) Check that N hasn't been used before with C
4) Check equix_verify(C || N || E, S) == EQUIX_OK
5) Calculate R = blake2b(C || N || E || S)
6) Check R * E &lt;= UINT32_MAX
7) Put the request in the queue with weight E

Optionally, C could be omitted from the extension field if there is
only one global challenge. That would reduce the payload size to 36
bytes.

Note: 32-bit effort should be enough for more than a week of solving
with an 8-core CPU.

T.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200608010921</emailId><senderName></senderName><senderEmail>yoehoduv</senderEmail><timestampReceived>2020-06-08 01:09:21-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

&gt; The client's algorithm:
&gt; Input: C
&gt;
&gt; 1.  Select N, E
&gt;
&gt; 2.  Calculate S = equix_solve(C || N || E)
&gt;
&gt; 3.  Calculate R = blake2b(C || N || E || S)
&gt;
&gt; 4.  if R * E &gt; UINT32_MAX, go back to step 1)
&gt;
&gt; 5.  Submit C, N, E, S (68 bytes total)

It looks like all the 40320 permutations of the 16-bit words in S are
equix solutions.  Are steps 3 to 5 supposed to be repeated for all the
permutations?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200608065106</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-06-08 06:51:06-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

On Mon, Jun 8, 2020 at 3:09 AM &lt;yoehoduv@protonmail.com&gt; wrote:
&gt;
&gt; It looks like all the 40320 permutations of the 16-bit words in S are
&gt; equix solutions.  Are steps 3 to 5 supposed to be repeated for all the
&gt; permutations?
&gt;

Each unique S provides only one attempt. The indices in S must be
ordered in a certain way, otherwise the solution is invalid.
See: https://github.com/tevador/equix/blob/master/src/equix.c#L14-L23
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200610120508</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-06-10 12:05:08-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hello,

after reading all the excellent feedback on this thread, I did another
revision on this proposal:
  https://github.com/asn-d6/torspec/tree/pow-over-intro
I'm inlining the full proposal in the end of this email.

Here is a changelog:
- Improve attack vector section
- Shrink nonce size on cells to 16 bytes
- Change effort definition to linear

Here is a few things I did not do and might need some help with:

- I did not decide on the PoW function. I think to do this we miss the
  scheduler number crunching from dgoulet, and also I need to understand the
  possible options a bit more. I removed most references to argon2 and replaced
  them with XXX_POW.

  Tevador, thanks a lot for your tailored work on equix. This is fantastic.  I
  have a question that I don't see addressed in your very well written
  README. In your initial email, we discuss how Equihash does not have good GPU
  resistance:
  https://lists.torproject.org/pipermail/tor-dev/2020-May/014268.html

  Since equix is using Equihash isn't this gonna be a problem here too? I'm not
  too worried about ASIC resistance since I doubt someone is gonna build ASICs
  for this problem just yet, but script kiddies with their CS:GO graphics cards
  attacking equix is something I'm concerned about. I bet you have thought of
  this, so I'm wondering what's your take here.

  Right now I think the possible options are equix or the reduced Randomx
  (again thanks tevador) or yespower. In theory we could do all three of them
  and just support different versions; but that means more engineering.

  In any case, we are also waiting for some Tor-specific numbers from dgoulet,
  so we need those before we proceed here.

- In their initial mail, tevador points out an attack where the adversary games
  the effort estimation logic, by pausing an attack a minute before descriptor
  upload, so that the final descriptor has a very small target effort. They
  suggest using the median effort over a long period of time to fix this. Mike,
  can you check that out and see how we can adapt our logic to fix this?

- In tevador's initial mail, they point how the cell should include POW_EFFORT
  and that we should specify a "minimum effort" value instead of just inserting
  any effort in the pqueue. I can understand how this can have benefits (like
  the June discussion between tevador and yoehoduv) but I'm also concerned that
  this can make us more vulnerable to [ATTACK_BOTTOM_HALF] types of attacks, by
  completely dropping introduction requests instead of queueing them for an
  abstract future. I wouldn't be surprised if my concerns are invalid and
  harmful here. Does anyone have intuition?

- tevador suggests we use two seeds, and always accept introductions with the
  previous seed. I agree this is a good idea, and it's not as complex as I
  originally thought (I have trauma from the v3 design where we try to support
  multiple time periods at the same time). However, because this doubles the
  vefication time, I decided to wait for dgoulet's scheduler numbers and until
  the PoW function is finalized to understand if we can afford the verification
  overhead.

- Solar Designer suggested we do Ethash's anti-DDoS trick to avoid instances of
  [ATTACK_TOP_HALF]. This involves wrapping the final PoW token in a fast hash
  with a really low difficulty, and having the verifier check that fast hash
  POW first. This means that a target trying to flood us with invalid PoW would
  need to do some work for every PoW instead of it being free. This is a
  decision we should take at the end after we do some number crunching and see
  where we are at in terms of verification time and attack models.

Thanks a lot! :)

---

Filename: xxx-pow-over-intro-v1
Title: A First Take at PoW Over Introduction Circuits
Author: George Kadianakis, Mike Perry, David Goulet
Created: 2 April 2020
Status: Draft

0. Abstract

  This proposal aims to thwart introduction flooding DoS attacks by introducing
  a dynamic Proof-Of-Work protocol that occurs over introduction circuits.

1. Motivation

  So far our attempts at limiting the impact of introduction flooding DoS
  attacks on onion services has been focused on horizontal scaling with
  Onionbalance, optimizing the CPU usage of Tor and applying congestion control
  using rate limiting. While these measures move the goalpost forward, a core
  problem with onion service DoS is that building rendezvous circuits is a
  costly procedure both for the service and for the network. For more
  information on the limitations of rate-limiting when defending against DDoS,
  see [REF_TLS_1].

  If we ever hope to have truly reachable global onion services, we need to
  make it harder for attackers to overload the service with introduction
  requests. This proposal achieves this by allowing onion services to specify
  an optional dynamic proof-of-work scheme that its clients need to participate
  in if they want to get served.

  With the right parameters, this proof-of-work scheme acts as a gatekeeper to
  block amplification attacks by attackers while letting legitimate clients
  through.

1.1. Related work

  For a similar concept, see the three internet drafts that have been proposed
  for defending against TLS-based DDoS attacks using client puzzles [REF_TLS].

1.2. Threat model [THREAT_MODEL]

1.2.1. Attacker profiles [ATTACKER_MODEL]

  This proposal is written to thwart specific attackers. A simple PoW proposal
  cannot defend against all and every DoS attack on the Internet, but there are
  adverary models we can defend against.

  Let's start with some adversary profiles:

  "The script-kiddie"

    The script-kiddie has a single computer and pushes it to its
    limits. Perhaps it also has a VPS and a pwned server. We are talking about
    an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
    consider the total cost for this attacker to be zero $.

  "The small botnet"

    The small botnet is a bunch of computers lined up to do an introduction
    flooding attack. Assuming 500 medium-range computers, we are talking about
    an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
    the upfront cost for this attacker to be about $400.

  "The large botnet"

    The large botnet is a serious operation with many thousands of computers
    organized to do this attack. Assuming 100k medium-range computers, we are
    talking about an attacker with total access to 200 Thz of CPU and 200 TB of
    RAM. The upfront cost for this attacker is about $36k.

  We hope that this proposal can help us defend against the script-kiddie
  attacker and small botnets. To defend against a large botnet we would need
  more tools in our disposal (see [FUTURE_DESIGNS]).

  {XXX: Do the above make sense? What other attackers do we care about? What
        other metrics do we care about? Network speed? I got the botnet costs
        from here [REF_BOTNET] Back up our claims of defence.}

1.2.2. User profiles [USER_MODEL]

  We have attackers and we have users. Here are a few user profiles:

  "The standard web user"

    This is a standard laptop/desktop user who is trying to browse the
    web. They don't know how these defences work and they don't care to
    configure or tweak them. They are gonna use the default values and if the
    site doesn't load, they are gonna close their browser and be sad at Tor.
    They run a 2Ghz computer with 4GB of RAM.

  "The motivated user"

    This is a user that really wants to reach their destination. They don't
    care about the journey; they just want to get there. They know what's going
    on; they are willing to tweak the default values and make their computer do
    expensive multi-minute PoW computations to get where they want to be.

  "The mobile user"

    This is a motivated user on a mobile phone. Even tho they want to read the
    news article, they don't have much leeway on stressing their machine to do
    more computation.

  We hope that this proposal will allow the motivated user to always connect
  where they want to connect to, and also give more chances to the other user
  groups to reach the destination.

1.2.3. The DoS Catch-22 [CATCH22]

  This proposal is not perfect and it does not cover all the use cases. Still,
  we think that by covering some use cases and giving reachability to the
  people who really need it, we will severely demotivate the attackers from
  continuing the DoS attacks and hence stop the DoS threat all
  together. Furthermore, by increasing the cost to launch a DoS attack, a big
  class of DoS attackers will disappear from the map, since the expected ROI
  will decrease.

2. System Overview

2.1. Tor protocol overview

                                          +----------------------------------+
                                          |                                  |
   +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
   |Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
   +-------+         +-----------+        |Verifier|           |             |
                                          +--------+           |             |
                                          |                    |             |
                                          |                    |             |
                                          |         +----------v---------+   |
                                          |         |Intro Priority Queue|   |
                                          +---------+--------------------+---+
                                                           |  |  |
                                                Rendezvous |  |  |
                                                  circuits |  |  |
                                                           v  v  v



  The proof-of-work scheme specified in this proposal takes place during the
  introduction phase of the onion service protocol.

  The system described in this proposal is not meant to be on all the time, and
  should only be enabled by services when under duress. The percentage of
  clients receiving puzzles can also be configured based on the load of the
  service.

  In summary, the following steps are taken for the protocol to complete:

  1) Service encodes PoW parameters in descriptor [DESC_POW]
  2) Client fetches descriptor and computes PoW [CLIENT_POW]
  3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
  4) Service verifies PoW and queues introduction based on PoW effort \
[SERVICE_VERIFY]

2.2. Proof-of-work overview

2.2.1. Primitives

  For our proof-of-work scheme we want to minimize the spread of resources
  between a motivated attacker and legitimate clients. This means that we are
  looking to minimize any benefits that GPUs or ACICs can offer to an attacker.

  For this reason we chose XXX_POW

2.2.2. Dynamic PoW

  DoS is a dynamic problem where the attacker's capabilities constantly change,
  and hence we want our proof-of-work system to be dynamic and not stuck with a
  static difficulty setting. Hence, instead of forcing clients to go below a
  static target like in Bitcoin to be successful, we ask clients to "bid" using
  their PoW effort. Effectively, a client gets higher priority the higher
  effort they put into their proof-of-work. This is similar to how
  proof-of-stake works but instead of staking coins, you stake work.

  The benefit here is that legitimate clients who really care about getting
  access can spend a big amount of effort into their PoW computation, which
  should guarantee access to the service given reasonable adversary models. See
  [PARAM_TUNING] for more details about these guarantees and tradeoffs.

  As a way to improve reachability and UX, the service tries to estimate the
  effort needed for clients to get access at any given time and places it in
  the descriptor. See [EFFORT_ESTIMATION] for more details.

2.2.3. PoW effort

  For our dynamic PoW system to work, we will need to be able to compare PoW
  tokens with each other. To do so we define a function:
         unsigned effort(uint8_t *token)
  which takes as its argument a hash output token, interprets it as a
  bitstring, and returns the quotient of dividing a bitstring of 1s by it.

  So for example:
         effort(00000001100010101101) = 11111111111111111111 / 00000001100010101101
  or the same in decimal:
         effort(6317) = 1048575 / 6317 = 165.

  This definition of effort has the advantage of directly expressing the
  expected number of hashes that the client had to calculate to reach the
  effort. This is in contrast to the (cheaper) exponential effort definition of
  taking the number of leading zero bits.

3. Protocol specification

3.1. Service encodes PoW parameters in descriptor [DESC_POW]

  This whole protocol starts with the service encoding the PoW parameters in
  the 'encrypted' (inner) part of the v3 descriptor. As follows:

       "pow-params" SP type SP seed-b64 SP expiration-time NL

        [At most once]

        type: The type of PoW system used. We call the one specified here "v1"

        seed-b64: A random seed that should be used as the input to the PoW
                  hash function. Should be 32 random bytes encoded in base64
                  without trailing padding.

        suggested-effort: An unsigned integer specifying an effort value that
                  clients should aim for when contacting the service. See
                  [EFFORT_ESTIMATION] for more details here.

        expiration-time: A timestamp in "YYYY-MM-DD SP HH:MM:SS" format after
                         which the above seed expires and is no longer valid as
                         the input for PoW. It's needed so that the size of our
                         replay cache does not grow infinitely. It should be
                         set to three hours in the future (+- some randomness).
                         {TODO: PARAM_TUNING}

       {XXX: Expiration time makes us even more susceptible to clock skews, but
             it's needed so that our replay cache refreshes. How to fix this?
             See [CLIENT_BEHAVIOR] for more details.}

3.2. Client fetches descriptor and computes PoW [CLIENT_POW]

  If a client receives a descriptor with "pow-params", it should assume that
  the service is expecting a PoW input as part of the introduction protocol.

  The client parses the descriptor and extracts the PoW parameters. It makes
  sure that the &lt;expiration-time&gt; has not expired and if it has, it needs to
  fetch a new descriptor.

  The client should then extract the &lt;suggested-effort&gt; field to configure its
  PoW 'target' (see [REF_TARGET]). The client SHOULD NOT accept 'target' values
  that will cause an infinite PoW computation. {XXX: How to enforce this?}

  To complete the PoW the client follows the following logic:

      a) Client generates 'nonce' as 16 random bytes.
      b) Client derives 'seed' by decoding 'seed-b64'.
      c) Client derives 'labeled_seed = seed + "TorV1PoW"'
      d) Client computes hash_output = XXX_POW(labeled_seed, nonce)
      e) Client checks if effort(hash_output) &gt;= target.
        e1) If yes, success! The client uses 'hash_output' as the puzzle
            solution and 'nonce' and 'seed' as its inputs.
        e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
            increments it by one, and goes back to step (d).

  At the end of the above procedure, the client should have a triplet
  (hash_output, seed, nonce) that can be used as the answer to the PoW
  puzzle. How quickly this happens depends solely on the 'target' parameter.

3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]

  Now that the client has an answer to the puzzle it's time to encode it into
  an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
  portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
  [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
  INTRODUCE1 cell only gets read by the onion service and is ignored by the
  introduction point.

  We propose a new EXT_FIELD_TYPE value:

     [01] -- PROOF_OF_WORK

   The EXT_FIELD content format is:

      POW_VERSION    [1 byte]
      POW_NONCE      [16 bytes]

   where:

    POW_VERSION is 1 for the protocol specified in this proposal
    POW_NONCE is 'nonce' from the section above

   This will increase the INTRODUCE1 payload size by 19 bytes since the
   extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
   present and currently set to 0 and the EXT_FIELD is 17 bytes. According to
   ticket #33650, INTRODUCE1 cells currently have more than 200 bytes
   available.

3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]

   When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
   should check its configuration on whether proof-of-work is required to
   complete the introduction. If it's not required, the extension SHOULD BE
   ignored. If it is required, the service follows the procedure detailed in
   this section.

   If the service requires the PROOF_OF_WORK extension but received an
   INTRODUCE1 cell without any embedded proof-of-work, the service SHOULD
   consider this cell as a zero-effort introduction for the purposes of the
   priority queue (see section [INTRO_QUEUE]).

3.4.1. PoW verification [POW_VERIFY]

   To verify the client's proof-of-work the service extracts (hash_output,
   seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:

   1) Make sure that the client's seed is identical to the active seed.
   2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
   3) Verify that 'hash_output =?= XXX_POW(seed, nonce)

   If any of these steps fail the service MUST ignore this introduction request
   and abort the protocol.

   In this proposal we call the above steps the "top half" of introduction
   handling. If all the steps of the "top half" have passed, then the circuit
   is added to the introduction queue as detailed in section [INTRO_QUEUE].

3.4.1.1. Replay protection [REPLAY_PROTECTION]

  The service MUST NOT accept introduction requests with the same (seed, nonce)
  tuple. For this reason a replay protection mechanism must be employed.

  The simplest way is to use a simple hash table to check whether a (seed,
  nonce) tuple has been used before for the actiev duration of a
  seed. Depending on how long a seed stays active this might be a viable
  solution with reasonable memory/time overhead.

  If there is a worry that we might get too many introductions during the
  lifetime of a seed, we can use a Bloom filter as our replay cache
  mechanism. The probabilistic nature of Bloom filters means that sometimes we
  will flag some connections as replays even if they are not; with this false
  positive probability increasing as the number of entries increase. However,
  with the right parameter tuning this probability should be negligible and
  well handled by clients. {TODO: PARAM_TUNING}

3.4.2. The Introduction Queue  [INTRO_QUEUE]

3.4.2.1. Adding introductions to the introduction queue [ADD_QUEUE]

  When PoW is enabled and a verified introduction comes through, the service
  instead of jumping straight into rendezvous, queues it and prioritizes it
  based on how much effort was devoted by the client to PoW. This means that
  introduction requests with high effort should be prioritized over those with
  low effort.

  To do so, the service maintains an "introduction priority queue" data
  structure. Each element in that priority queue is an introduction request,
  and its priority is the effort put into its PoW:

  When a verified introduction comes through, the service uses the effort()
  function with hash_output as its input, and uses the output to place requests
  into the right position of the priority_queue: The bigger the effort, the
  more priority it gets in the queue. If two elements have the same effort, the
  older one has priority over the newer one.

  {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
   effort what attacks can happen in various scenarios? Do we want to order on
   time+effort?  Which scenarios and attackers should we examine here?}

3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]

  The service should handle introductions by pulling from the introduction
  queue. We call this part of introduction handling the "bottom half" because
  most of the computation happens in this stage.

  Similar to how our cell scheduler works, the onion service subsystem will
  poll the priority queue every 100ms tick and process the first 20 cells from
  the priority queue (if they exist). The service will perform the rendezvous
  and the rest of the onion service protocol as normal.

  With this tempo, we can process 200 introduction cells per second.
  {XXX: Is this good?}

  After the introduction request is handled from the queue, the service trims
  the priority queue if the queue is too big.
  {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can
  we use WRED usefully?}

  {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
  per 100ms is probably unmaintainable, since each cell is quite expensive:
  doing so involving path selection, crypto and making circuits. We will need
  to profile this procedure and see how we can do this scheduling better.}

3.4.3. PoW effort estimation [EFFORT_ESTIMATION]

  During its operation the service continuously keeps track of the received PoW
  cell efforts to inform its clients of the effort they should put in their
  introduction to get service. The service informs the clients by using the
  &lt;suggested-effort&gt; field in the descriptor.

  In particular, the service starts with a default suggested-effort value of 5000.

  Everytime the service handles an introduction request from the priority queue
  in [HANDLE_QUEUE], the service compares the request's effort to the current
  suggested-effort value. If the new request's effort is lower than the
  suggested-effort, set the suggested-effort equal to the effort of the new
  request.

  {XXX tevador attack: see their email
     https://lists.torproject.org/pipermail/tor-dev/2020-May/014268.html
   where it says "Secondly, the proposed method of calculating..."
   They suggest using the median here and their "pause-before-desc-publish"
   attack seems legit.}

  Everytime the service trims the priority queue in [HANDLE_QUEUE], the service
  compares the request at the trim point against the current suggested-effort
  value. If the trimmed request's effort is higher than the suggested-effort,
  set the suggested-effort equal to the effort of the new request.

  The above two operations are meant to balance the suggested effort based on
  the requests currently waiting in the priority queue. If the priority queue
  is filled with high-effort requests, make the suggested effort higher. And
  when all the high-effort requests get handled and the priority queue is back
  to normal operation, relax the suggested effort to lower levels.

  The suggested-effort is not a hard limit to the efforts that are accepted by
  the service, and it's only meant to serve as a guideline for clients to
  reduce the number of unsuccessful requests that get to the service. The
  service still adds requests with lower effort than suggested-effort to the
  priority queue in [ADD_QUEUE].

  {XXX: What attacks are possible here?}

3.4.3.1. Updating descriptor with new suggested effort

  When a service changes its suggested-effort value, it SHOULD upload a new
  descriptor with the new value.

  The service should avoid uploading descriptors too often to avoid overwheming
  the HSDirs. The service SHOULD NOT upload descriptors more often than
  'hs-pow-desc-upload-rate-limit' seconds (which is controlled through a
  consensus parameter and has a default value of 300 seconds).

  {XXX: Is this too often? Or too rare? Perhaps we can set different limits
  for when the difficulty goes up and different for when it goes down. It's
  more important to update the descriptor when the difficulty goes up.}

  {XXX: What attacks are possible here? Can the attacker intentionally hit this
  rate-limit and then influence the suggested effort so that clients do not
  learn about the new effort?}

4. Client behavior [CLIENT_BEHAVIOR]

  This proposal introduces a bunch of new ways where a legitimate client can
  fail to reach the onion service.

  Furthermore, there is currently no end-to-end way for the onion service to
  inform the client that the introduction failed. The INTRO_ACK cell is not
  end-to-end (it's from the introduction point to the client) and hence it does
  not allow the service to inform the client that the rendezvous is never gonna
  occur.

  For this reason we need to define some client behaviors to work around these
  issues.

4.1. Clients handling timeouts [CLIENT_TIMEOUT]

  Alice can fail to reach the onion service if her introduction request gets
  trimmed off the priority queue in [HANDLE_QUEUE], or if the service does not
  get through its priority queue in time and the connection times out.

  {XXX: How should timeout values change here since the priority queue will
  cause bigger delays than usual to rendezvous?}

  This section presents a heuristic method for the client getting service even
  in such scenarios.

  If the rendezvous request times out, the client SHOULD fetch a new descriptor
  for the service to make sure that it's using the right suggested-effort for
  the PoW and the right PoW seed. The client SHOULD NOT fetch service
  descriptors more often than every 'hs-pow-desc-fetch-rate-limit' seconds
  (which is controlled through a consensus parameter and has a default value of
  600 seconds).

  {XXX: Is this too rare? Too often?}

  When the client fetches a new descriptor, it should try connecting to the
  service with the new suggested-effort and PoW seed. If that doesn't work, it
  should double the effort and retry. The client should keep on
  doubling-and-retrying until it manages to get service, or its able to fetch a
  new descriptor again.

  {XXX: This means that the client will keep on spinning and
  doubling-and-retrying for a service under this situation. There will never be
  a "Client connection timed out" page for the user. Is this good? Is this bad?
  Should we stop doubling-and-retrying after some iterations? Or should we
  throw a custom error page to the user, and ask the user to stop spinning
  whenever they want?}

4.2. Seed expiration issues

  As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
  cause issues with clock skewed clients. Furthermore, even not clock skewed
  clients can encounter TOCTOU-style race conditions here.

  The client descriptor refetch logic of [CLIENT_TIMEOUT] should take care of
  such seed-expiration issues, since the client will refetch the descriptor.

  {XXX: Is this sufficient? Should we have multiple active seeds at the same
  time similar to how we have overlapping descriptors and time periods in v3?
  This would solve the problem but it grows the complexity of the system
  substantially.}

4.3. Other descriptor issues

  Another race condition here is if the service enables PoW, while a client has
  a cached descriptor. How will the client notice that PoW is needed? Does it
  need to fetch a new descriptor? Should there be another feedback mechanism?
  {XXX}

5. Attacker strategies [ATTACK_META]

  Now that we defined our protocol we need to start tweaking the various
  knobs. But before we can do that, we first need to understand a few
  high-level attacker strategies to see what we are fighting against.

5.1.1. Overwhelm PoW verification (aka "Overwhelm top half") [ATTACK_TOP_HALF]

  A basic attack here is the adversary spamming with bogus INTRO cells so that
  the service does not have computing capacity to even verify the
  proof-of-work. This adversary tries to overwhelm the procedure in the
  [POW_VERIFY] section.

  That's why we need the PoW algorithm to have extremely cheap verification
  time so that this attack is not possible.

5.1.2. Overwhelm rendezvous capacity (aka "Overwhelm bottom half") \
[ATTACK_BOTTOM_HALF]

  Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
  effective strategy for the attacker is to totally overwhelm the queue
  processing by sending more high-effort introductions than the onion service
  can handle at any given tick. This adversary tries to overwhelm the procedure
  in the [HANDLE_QUEUE] section.

  To do so, the attacker would have to send at least 20 high-effort
  introduction cells every 100ms, where high-effort is a PoW which is above the
  estimated level of "the motivated user" (see [USER_MODEL]).

  An easier attack for the adversary, is the same strategy but with
  introduction cells that are all above the comfortable level of "the standard
  user" (see [USER_MODEL]). This would block out all standard users and only
  allow motivated users to pass.

5.1.3. Precomputed PoW attack

  The attacker may precompute many valid PoW nonces and submit them all at once
  before the current seed expires, overwhelming the service temporarily even
  using a single computer. An attacker with this attack might be aiming to DoS
  the service for a limited amount of time, or confuse the difficulty
  estimation algorithm.

6. Parameter tuning [PARAM_TUNING]

  There are various parameters in this system that need to be tuned.

  We will first start by tuning the default difficulty of our PoW
  system. That's gonna define an expected time for attackers and clients to
  succeed.

  We are then gonna tune the parameters of our proof-of-work function. That will
  define the resources that an attacker needs to spend to overwhelm the onion
  service, the resources that the service needs to spend to verify introduction
  requests, and the resources that legitimate clients need to spend to get to
  the onon service.

6.1. PoW Difficulty settings

  The difficulty setting of our PoW basically dictates how difficult it should
  be to get a success in our PoW system. In classic PoW systems, "success" is
  defined as getting a hash output below the "target". However, since our
  system is dynamic, we define "success" as an abstract high-effort computation.

  Even tho our system is dynamic, we still need default difficulty settings
  that will define the metagame. The client and attacker can still aim higher
  or lower, but for UX purposes and for analysis purposes we do need to define
  some difficulties.

  We hence created the table (see [REF_TABLE]) below which shows how much time
  a legitimate client with a single machine should expect to burn before they
  get a single success. The x-axis is how many successes we want the attacker
  to be able to do per second: the more successes we allow the adversary, the
  more they can overwhelm our introduction queue. The y-axis is how many
  machines the adversary has in her disposal, ranging from just 5 to 1000.

       ===============================================================
       |    Expected Time (in seconds) Per Success For One Machine   |
 ===========================================================================
 |                                                                          |
 |   Attacker Succeses        1       5       10      20      30      50    |
 |       per second                                                         |
 |                                                                          |
 |            5               5       1       0       0       0       0     |
 |            50              50      10      5       2       1       1     |
 |            100             100     20      10      5       3       2     |
 | Attacker   200             200     40      20      10      6       4     |
 |  Boxes     300             300     60      30      15      10      6     |
 |            400             400     80      40      20      13      8     |
 |            500             500     100     50      25      16      10    |
 |            1000            1000    200     100     50      33      20    |
 |                                                                          |
 ============================================================================

  Here is how you can read the table above:

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
    success per second, then a legitimate client with a single box should be
    expected to spend 1000 seconds getting a single success.

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 200 seconds getting a single success.

  - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 100 seconds getting a single success.

  - If an adversary has access to 50 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 10 seconds getting a single success.

  - If an adversary has access to 5 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 1 seconds getting a single success.

  With the above table we can create some profiles for default values of our
  PoW difficulty. So for example, we can use the last case as the default
  parameter for Tor Browser, and then create three more profiles for more
  expensive cases, scaling up to the first case which could be hardest since
  the client is expected to spend 15 minutes for a single introduction.

  {TODO: PARAM_TUNING You can see that this section is completely CPU/memory
  agnostic, and it does not take into account potential optimizations that can
  come from GPU/ASICs. This is intentional so that we don't put more variables
  into this equation right now, but as this proposal moves forward we will need
  to put more concrete values here.}

6.2. XXX_POW parameters [ARGON_PARAMS]

  XXX_POW

  We now need to define the secondary argon2 parameters as defined in
  [REF_ARGON2]. This includes the number of lanes 'h', the memory size 'm', the
  number of iterations 't'. Section 9 of [REF_ARGON2] recommends an approach of
  how to tune these parameters.

  To tune these parameters we are looking to *minimize* the verification speed
  of an onion service, while *maximizing* the sparse resources spent by an
  adversary trying to overwhelm the service using [ATTACK_META].

  When it comes to verification speed, to verify a single introduction cell the
  service needs to do a single argon2 call: so the service will need to do
  hundreds of those per second as INTRODUCE2 cells arrive. The service will
  have to do this verification step even for very cheap zero-effort PoW
  received, so this has to be a cheap procedure so that it doesn't become a DoS
  vector of each own. Hence each individual argon2 call must be cheap enough to
  be able to be done comfortably and plentifuly by an onion service with a
  single host (or horizontally scaled with Onionbalance).

  At the same time, the adversary will have to do thousands of these calls if
  she wants to make high-effort PoW, so it's this assymetry that we are looking
  to exploit here. Right now, the most expensive resource for adversaries is
  the RAM size, and that's why we chose argon2 which is memory-hard.

  To minmax this game we will need

  {TODO: PARAM_TUNING: I've had a hard time minmaxing this game for
  argon2. Even argon2 invocations with a small memory parameter will take
  multiple milliseconds to run on my machine, and the parameters recommended in
  section 8 of the paper all take many hundreds of milliseconds. This is just
  not practical for our use case, since we want to process hundreds of such PoW
  per second... I also did not manage to find a benchmark of argon2 calls for
  different CPU/GPU/FPGA configurations.}

7. Discussion

7.1. UX

  This proposal has user facing UX consequences.

  Here is some UX improvements that don't need user-input:

  - Primarily, there should be a way for Tor Browser to display to users that
    additional time (and resources) will be needed to access a service that is
    under attack. Depending on the design of the system, it might even be
    possible to estimate how much time it will take.

  And here are a few UX approaches that will need user-input and have an
  increasing engineering difficulty. Ideally this proposal will not need
  user-input and the default behavior should work for almost all cases.

  a) Tor Browser needs a "range field" which the user can use to specify how
     much effort they want to spend in PoW if this ever occurs while they are
     browsing. The ranges could be from "Easy" to "Difficult", or we could try
     to estimate time using an average computer. This setting is in the Tor
     Browser settings and users need to find it.

  b) We start with a default effort setting, and then we use the new onion
     errors (see #19251) to estimate when an onion service connection has
     failed because of DoS, and only then we present the user a "range field"
     which they can set dynamically. Detecting when an onion service connection
     has failed because of DoS can be hard because of the lack of feedback (see
     [CLIENT_BEHAVIOR])

  c) We start with a default effort setting, and if things fail we
     automatically try to figure out an effort setting that will work for the
     user by doing some trial-and-error connections with different effort
     values. Until the connection succeeds we present a "Service is
     overwhelmed, please wait" message to the user.

7.2. Future work [FUTURE_WORK]

7.2.1. Incremental improvements to this proposal

  There are various improvements that can be done in this proposal, and while
  we are trying to keep this v1 version simple, we need to keep the design
  extensible so that we build more features into it. In particular:

  - End-to-end introduction ACKs

    This proposal suffers from various UX issues because there is no end-to-end
    mechanism for an onion service to inform the client about its introduction
    request. If we had end-to-end introduction ACKs many of the problems from
    [CLIENT_BEHAVIOR] would be aleviated. The problem here is that end-to-end
    ACKs require modifications on the introduction point code and a network
    update which is a lengthy process.

  - Multithreading scheduler

    Our scheduler is pretty limited by the fact that Tor has a single-threaded
    design. If we improve our multithreading support we could handle a much
    greater amount of introduction requests per second.

7.2.2. Future designs [FUTURE_DESIGNS]

  This is just the beginning in DoS defences for Tor and there are various
  futured designs and schemes that we can investigate. Here is a brief summary
  of these:

  "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
         schemes like MTP-argon2 or Itsuku to make it even harder for
         adversaries to create successful PoWs. Unfortunately these schemes
         have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
         See #31223 for more details.

  "Third-party anonymous credentials" -- We can use anonymous credentials and a
         third-party token issuance server on the clearnet to issue tokens
         based on PoW or CAPTCHA and then use those tokens to get access to the
         service. See [REF_CREDS] for more details.

  "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
         where we present a hard puzzle to the user when connecting to the
         onion service, and if they solve it we then give the user a bunch of
         anonymous tokens that can be used in the future. This can all happen
         between the client and the service without a need for a third party.

  All of the above approaches are much more complicated than this proposal, and
  hence we want to start easy before we get into more serious projects.

7.3. Environment

  We love the environment! We are concerned of how PoW schemes can waste energy
  by doing useless hash iterations. Here is a few reasons we still decided to
  pursue a PoW approach here:

  "We are not making things worse" -- DoS attacks are already happening and
      attackers are already burning energy to carry them out both on the
      attacker side, on the service side and on the network side. We think that
      asking legitimate clients to carry out PoW computations is not gonna
      affect the equation too much, since an attacker right now can very
      quickly cause the same damage that hundreds of legitimate clients do a
      whole day.

  "We hope to make things better" -- The hope is that proposals like this will
      make the DoS actors go away and hence the PoW system will not be used. As
      long as DoS is happening there will be a waste of energy, but if we
      manage to demotivate them with technical means, the network as a whole
      will less wasteful. Also see [CATCH22] for a similar argument.

8. Acknowledgements

  Thanks a lot to tevador for the various improvements to the proposal and for
  helping us understand and tweak the RandomX scheme.

  Thanks to Solar Designer for the help in understanding the current PoW
  landscape, the various approaches we could take, and teaching us a few neat
  tricks.

9. References

  [REF_ARGON2]: https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf
  https://password-hashing.net/#argon2
  [REF_TABLE]: The table is based on the script below plus some manual editing for \
                readability:
               https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
  [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
  [REF_TARGET]: https://en.bitcoin.it/wiki/Target
  [REF_TLS]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt
             https://tools.ietf.org/id/draft-nir-tls-puzzles-00.html
             https://tools.ietf.org/html/draft-ietf-ipsecme-ddos-protection-10
  [REF_TLS_1]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200610153042</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-06-10 15:30:42-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi George,

Thanks for the update.

On Wed, Jun 10, 2020 at 2:05 PM George Kadianakis &lt;desnacked@riseup.net&gt; wrote:
&gt;
&gt;   Tevador, thanks a lot for your tailored work on equix. This is fantastic.
&gt;   I have a question that I don't see addressed in your very well written
&gt;   README. In your initial email, we discuss how Equihash does not have good
&gt;   GPU resistance:
&gt;   https://lists.torproject.org/pipermail/tor-dev/2020-May/014268.html
&gt;
&gt;   Since equix is using Equihash isn't this gonna be a problem here too?
&gt;   I'm not too worried about ASIC resistance since I doubt someone is gonna
&gt;   build ASICs for this problem just yet, but script kiddies with their CS:GO
&gt;   graphics cards attacking equix is something I'm concerned about. I bet you
&gt;   have thought of this, so I'm wondering what's your take here.
&gt;

Equihash runs much faster on GPUs only if the memory requirements
exceed the size of the CPU cache. This is the case for most Equihash
variants that are in use by cryptocurrencies (e.g. 200,9 and 144,5),
but doesn't apply to Equi-X, which uses only 2 MB.

The GPU resistance of Equi-X is based on 2 facts:
1) Each solution attempt uses a different hash function. GPUs cannot
compile new kernels fast enough (it would require &gt;1000 kernels per
second), so they have to run in emulator mode, which is much slower.
GPUs are also impacted by thread divergence.
2) The entire sorting phase fits into CPU cache, so CPUs can benefit
from memory bandwidth comparable to GPUs (~500 GB/s).

&gt; In tevador's initial mail, they point how the cell should include
&gt; POW_EFFORT and that we should specify a "minimum effort" value instead
&gt; of just inserting any effort in the pqueue. I can understand how this can
&gt; have benefits (like  the June discussion between tevador and yoehoduv) but
&gt; I'm also concerned that this can make us more vulnerable to
&gt; [ATTACK_BOTTOM_HALF] types of attacks, by completely dropping introduction
&gt; requests instead of queueing them for an abstract future. I wouldn't be
&gt; surprised if my concerns are invalid and harmful here. Does anyone have
&gt; intuition?
&gt;

I don't see any downsides to including the PoW effort in the cell and
specifying the minimum effort. The minimum effort is needed to reduce
the verification overhead and to ensure that the queue doesn't grow
indefinitely. If the effort of the introduction request is lower than
the minimum, the service can simply treat it like a request without
any PoW (and saving a verification call). The exact outcome would
depend on the circumstances, normally the request would go to the back
of the queue.

I suggest a minimum effort equivalent to ~1 second of CPU time and
adjust it upward if the queue is full. This is more efficient than
trimming.

The size of the queue should be enough to handle short attack bursts
without dropping any requests. I'd say that a reasonable maximum queue
size is {bottom half throughput} * {number of seconds the client will
wait before retrying}. There is no point in queueing up more requests
than this because the client will have already given up on the request
by the earliest time it could be serviced.

&gt; - tevador suggests we use two seeds, and always accept introductions with
&gt; the previous seed. I agree this is a good idea, and it's not as complex as
&gt; I originally thought (I have trauma from the v3 design where we try to
&gt; support multiple time periods at the same time). However, because this
&gt; doubles the vefication time, I decided to wait for dgoulet's scheduler
&gt; numbers and until the PoW function is finalized to understand if we can
&gt; afford the verification overhead.
&gt;

There is no verification overhead if the seed is included in the
request. If additional 32 bytes are too much, the request can include
e.g. the first 4 bytes of the seed. This is enough for the service to
select the correct seed from the two active ones. The chance that two
subsequent seeds have the same first 32 bits is negligible (and can be
even avoided completely).

&gt; - Solar Designer suggested we do Ethash's anti-DDoS trick to avoid instances
&gt; of [ATTACK_TOP_HALF]. This involves wrapping the final PoW token in a fast
&gt; hash with a really low difficulty, and having the verifier check that fast
&gt; hash POW first. This means that a target trying to flood us with invalid PoW
&gt; would need to do some work for every PoW instead of it being free. This is a
&gt; decision we should take at the end after we do some number crunching and see
&gt; where we are at in terms of verification time and attack models.
&gt;

This trick is mostly relevant to slow-to-verify algorithms, but can be
also applied to Equi-X by reordering the server algorithm steps:

Input: C, N, E, S
1) Check that C is a valid seed (there may be multiple seeds active at a time).
2) Check that E is above the minimum effort
3) Check that N hasn't been used before with C
4) Calculate R = blake2b(C || N || E || S)
5) Check R * E &lt;= UINT32_MAX
6) Check equix_verify(C || N || E, S) == EQUIX_OK
7) Put the request in the queue with weight E

Simple spam attacks will fail at step 5, avoiding the call to equix_verify.

However, I would not overly rely on this feature because even a single
GPU can provide enough fast hashes (5-10 GH/s) for [ATTACK_TOP_HALF]
on schemes like Yespower, Argon2 or RandomX. It works for Ethash
because the required effort is determined by the computing power of
the entire Ethereum network, so the attacker would need to compute
billions of fast hashes even to pass the first check.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200701030834</emailId><senderName></senderName><senderEmail>johnymnx</senderEmail><timestampReceived>2020-07-01 03:08:34-0400</timestampReceived><subject>[tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hello, list !
Some ideas about this proposal, it's a little bit surface ideas, cause 
I'm not currently digging deep into the internals of Tor-core.

There's user division on different classes there ("The standard web 
user",   "The motivated user",   "The mobile user").
I would add "Registered user", user registered within the service. Thus 
service keeps fast-access DB(Redis) with some unique-id of registered 
user, which is given to registered user. When user wants to connect to 
HS, he puts this Unique-ID via TBB (similar to stealth auth introduced 
recently)

About "The mobile user", mobile user can be offered two options:
1. Go to Desktop
2. Compute series of reCAPTCHA
3. If mobile user is "The registered user", enter unique-id saved in 
some encrypted vault on the phone

Registered and unregistered class of users introduces another issue
When HS starts its operation and no registered users exist, and DDoS 
starts with initial HS availability to the World, unregistered/guest 
users will have no chance to register on HS. Thus, hybrid solution is 
required, as described in 5.2 (5.2. Future directions [FUTURE_WORK]) 
"PoW + "Third-party anonymous credentials"
HS must have Third-Party Human Puzzle service behind Anit-DDOS operator 
(Cloudflare, e.t.c.), where unregistered users could solve some AI-proof 
puzzles and get access-token to connect to HS

In the long run, when user base of HS is saturated, and number of user 
registrations decays, PoW for unregistered users can be significantly 
increased, thus protecting HS from huge DDoS attacks, cause it's usually 
when HS is popular and has big and saturated user base, it becomes 
target for huge DDoS attacks.

Verification of PoW
I didn't dig deep to HS implementation, but it seems reasonable if 
decision about PoW verification is made on the closest node to 
client(ClosestNode).

1. HS sends encrypted PoW task to client
2. Client computes PoW
3. Client sends PoW to ClosestNode
4. ClosestNode verifies PoW (verification of PoW is always much faster, 
than Proof)
5. Verification succeeded - approve connection to HS
6. Verification failed - disconnect this client

&gt; Finally, our proposal has a big benefit over the blockchain use cases: 
&gt; it's
&gt; much more agile. We can deploy changes to the PoW algorithm without 
&gt; having
&gt; to hard-fork, and we can do this even through the consensus for maximum
&gt; agility. This means that we should try to use this agility to our 
&gt; advantage.

Change of PoW algorithms can be made in form of some PoW CAP(capability) 
flag, so some version of client supports PoW_CAP1, PoW_CAP2, PoW_CAP3 
and HS supports PoW_CAP1, PoW_CAP1, thus they both can only interact 
with intersection of their PoW_CAP# sets. Similar to OpenVPN 
crypto-capabilities exchange between client and server



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200701140202</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-07-01 14:02:02-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hi all,

On Mon, Jun 22, 2020 at 4:52 PM George Kadianakis &lt;desnacked@riseup.net&gt; wrote:
&gt; Also, tevador let me know if you'd like me to add you as a co-author on the
&gt; proposal based on all your great feedback so far.

Thanks for the update. Yes, you can add me as a co-author.

&gt; During our performance measurements in [TOR_MEASUREMENTS] we learned that
&gt; the "top half" takes about 0.26 msecs in average, without doing any sort
&gt; of PoW verification.

Interesting. This confirms the need for fast PoW verification. Equi-X
takes about 0.05 ms to verify, so the top-half throughput should still
be over 3000 requests per second.

&gt; Our scheduler is pretty limited by the fact that Tor has a single-threaded
&gt; design.

If both the top- and bottom- halves are processed by the same thread,
this opens up the possibility for a "hybrid" attack. Given the
performance figures for the bottom half (0.31 ms/req.) and the top
half (5.5 ms/req.), the attacker can optimally deny service by
submitting 91 high-effort requests and 1520 invalid requests per
second. This will completely saturate the main loop because:

0.31*(1520+91) ~ 0.5 sec.
5.5*91         ~ 0.5 sec.

This attack only has half the bandwidth requirement of
[ATTACK_TOP_HALF] and half the compute requirement of
[ATTACK_BOTTOM_HALF].

Alternatively, the attacker can adjust the ratio between invalid and
high-effort requests depending on their bandwidth and compute
capabilities.

&gt; {TODO: BLOCKER: What's the max size of the queue? Do we trim it, or do
&gt; we just stop adding new requests when it reaches max size? Can we use WRED?
&gt; Trimming is currently used EFFORT_ESTIMATION, so if we don't do it we need
&gt; to find a different way to estimate effort. See tevador's [REF_TEVADOR_2]
&gt; email.}

The simplest approach is to have a "soft" maximum size of the queue.
All requests with valid PoW can be added to the queue, but once per
second, the queue is trimmed to the "soft" max size by removing
timed-out and low-effort requests. I used this approach in my
simulations (see below).

&gt; The EXT_FIELD content format is:
&gt;     POW_VERSION    [1 byte]
&gt;     POW_NONCE      [16 bytes]
&gt;     POW_SEED       [4 bytes]

If we want to use Equi-X, you also need to add the solution (16 bytes)
and I also recommend adding the client's target effort.

    POW_VERSION    [1 byte]
    POW_NONCE      [16 bytes]
    POW_EFFORT     [4 bytes]
    POW_SEED       [4 bytes]
    POW_SOLUTION   [16 bytes]

43 bytes total including the extension type and length.

The client's algorithm in section 3.2 should be modified to:

  a) Client selects a target effort E.
  b) Client generates a random 16-byte nonce N.
  c) Client derives seed C by decoding 'seed-b64'.
  d) Client calculates S = equix_solve(C || N || E)
  e) Client calculates R = blake2b(C || N || E || S)
  f) Client checks if R * E &lt;= UINT32_MAX.
    f1) If yes, success! The client can submit N, E, the first 4 bytes of C
        and S.
    f2) If no, fail! The client interprets N as a 16-byte little-endian
        integer, increments it by 1 and goes back to step d).

We could also add the server algorithm in 3.4:

  a) Find a valid seed C that starts with POW_SEED. Fail if no such seed
     exists.
  b) Fail if E = POW_EFFORT is lower than the minimum effort.
  c) Fail if N = POW_NONCE is present in the replay cache.
  d) Calculate R = blake2b(C || N || E || S)
  e) Fail if R * E &gt; UINT32_MAX
  f) Fail if equix_verify(C || N || E, S) != EQUIX_OK
  g) Put the request in the queue with a priority of E

&gt; 3.4.3. PoW effort estimation [EFFORT_ESTIMATION]
&gt; {XXX: BLOCKER: Figure out of this system makes sense}

I wrote a simple simulation in Python to test different ways of
adjusting the suggested effort. The results are here:
https://github.com/tevador/scratchpad/blob/master/tor-pow/effort_sim.md

In summary, I suggest to use MIN_EFFORT = 1000 and the following
algorithm to calculate the suggested effort:

1. Sum the effort of all valid requests that have been received since the
   last HS descriptor update. This includes all handled requests, trimmed
   requests and requests still in the queue.
2. Divide the sum by the max. number of requests that the service could have
   handled during that time (SVC_BOTTOM_CAPACITY * HS_UPDATE_PERIOD).
3. Suggested effort = max(MIN_EFFORT, result)

This algorithm can both increase and reduce the suggested effort.

My simulations also show that bottom-half attacks are not feasible
(even "The large botnet" cannot completely deny access to the
service). I think further research and testing should focus on
top-half attacks (or hybrid attacks).

&gt; {XXX: Does this mean that this system can auto-enable and auto-disable the
&gt; DoS subsystem with reasonable accuracy?}

I tried to make the effort estimation algorithm disable PoW
automatically (by setting suggested effort to 0), but it led to
oscillating behavior in the case of a sustained attack (i.e. once the
suggested effort is set to 0, clients cannot connect anymore because
the attacker can easily saturate the service). Having an acceptably
low minimum effort could work better. MIN_EFFORT = 1000 as I suggested
will take around 1 second on a quad core CPU. Mobile clients can
simply ignore the suggested effort and always try to connect without
PoW.

The algorithm can be easily modified to auto-enable PoW in case of an
attack (but will not auto-disable it). This can be done by keeping
suggested effort zero as long as no requests have been trimmed from
the queue. The PoW subsystem could be disabled manually by the HS
operator if needed.

&gt; {XXX: BLOCKER: How should timeout values change here since the priority
&gt; queue will cause bigger delays than usual to rendezvous?}

I think the timeout should stay the same. Attackers don't care about
timeouts and longer timeout values would increase users'
time-to-connect when the service is under attack and the suggested
effort hasn't been updated yet.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200922121030</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-09-22 12:10:30-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

George Kadianakis &lt;desnacked@riseup.net&gt; writes:

&gt; tevador &lt;tevador@gmail.com&gt; writes:
&gt;
&gt;&gt; Hi all,
&gt;&gt;

Hello,

I have pushed another update to the PoW proposal here:
  https://github.com/asn-d6/torspec/tree/pow-over-intro
I also (finally) merged it upstream to torspec as proposal #327:
  https://github.com/torproject/torspec/blob/master/proposals/327-pow-over-intro.txt

The most important improvements are:
- Add tevador as an author.
- Update PoW algorithms based on tevador's Equix feedback.
- Update effort estimation algorithm based on tevador's simulation.
- Include hybrid attack section.
- Remove a bunch of blocker tags.

Two things I'd like to work more on:

- I'd like people to take tevador's Equix PoW function and run it on
  their boxes and post back benchmarks of how it performed. Particularly
  so if you have a GPU-enabled box, so that we can get some benchmarks
  from GPUs as well. That will help us tune the proposal even more.

  For my laptop (with an Intel CPU i7-8550U CPU @ 1.80GHz) I got pretty
  accurate benchmarks (compared to https://github.com/tevador/equix#performance):
  $ ./equix-bench 
     Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 1) ...
     1.910000 solutions/nonce
     283.829505 solutions/sec. (1 thread)
     22810.327943 verifications/sec. (1 thread)
  $ ./equix-bench --threads 16
     Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 16) ...
     1.910000 solutions/nonce
     2296.585708 solutions/sec. (16 threads)
     20223.196324 verifications/sec. (1 thread)

  See how to do this here: https://github.com/tevador/equix#build

- I'd like to improve the effort estimation algorithm by dynamically adjusting
  SVC_BOTTOM_CAPACITY instead of having it as a static value. Otherwise, I
  would like to reduce the currently suggested SVC_BOTTOM_CAPACITY because I
  feel that 180 is too big. I would like to put it to 100 which is much more
  conservative.  I tried to do so while updating tevador's simulation
  accordingly, but I found out that the simulation code does not do the graphs
  itself, so I didn't make much progress here.

  tevador do you have the graphing code somewhere so that I can run the
  experiments again and see how the graphs are influenced?

Apart from that, I think the proposal is really solid. I have hence merged it
as proposal #327 to torspec and further revisions can be done on top of that
from now on.

Thanks for all the work here and I'm looking forward to further feedback!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200924165429</emailId><senderName>Jim Newsome</senderName><senderEmail>jnewsome@torproject.org</senderEmail><timestampReceived>2020-09-24 16:54:29-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>


On 9/22/20 07:10, George Kadianakis wrote:
&gt; George Kadianakis &lt;desnacked@riseup.net&gt; writes:
&gt;
&gt;&gt; tevador &lt;tevador@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt;&gt; Hi all,
&gt;&gt;&gt;
&gt; Hello,
&gt;
&gt; I have pushed another update to the PoW proposal here:
&gt;   https://github.com/asn-d6/torspec/tree/pow-over-intro
&gt; I also (finally) merged it upstream to torspec as proposal #327:
&gt;   https://github.com/torproject/torspec/blob/master/proposals/327-pow-over-intro.txt
&gt;
&gt; The most important improvements are:
&gt; - Add tevador as an author.
&gt; - Update PoW algorithms based on tevador's Equix feedback.
&gt; - Update effort estimation algorithm based on tevador's simulation.
&gt; - Include hybrid attack section.
&gt; - Remove a bunch of blocker tags.
&gt;
&gt; Two things I'd like to work more on:
&gt;
&gt; - I'd like people to take tevador's Equix PoW function and run it on
&gt;   their boxes and post back benchmarks of how it performed.

I shared some results privately with George and he suggested including
the list. Results below.

&gt; Particularly
&gt;   so if you have a GPU-enabled box, so that we can get some benchmarks
&gt;   from GPUs as well. That will help us tune the proposal even more.

For anyone else following along or also contributing benchmarks, George
clarified for me that the equix benchmark isn't capable of utilizing the
GPU.

My results:

First results are on my w530, i7, 4 core (hyperthreaded to 8) laptop
(with moderate activity in the background).

I stumbled across some weird artifacts when using more threads than
processors: the benchmark reports solutions/sec continuing to increase
linearly with #threads. The wall-clock time for the benchmark itself
(measured with `time`) show the expected trend though of linear scaling
only up to 4 (the number of physical cores), a little bump at 8 (using
the hyperthreaded virtual cores), and no improvement past that.

Further below are results on my pinephone.
   
$ time ./equix-bench --threads 1
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 1) ...
    1.910000 solutions/nonce
    227.714446 solutions/sec. (1 thread)
    20301.439170 verifications/sec. (1 thread)

    real    0m4.242s
    user    0m4.230s
    sys    0m0.012s

$ time ./equix-bench --threads 2
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 2) ... 
    1.910000 solutions/nonce
    450.100153 solutions/sec. (2 threads)
    17925.519934 verifications/sec. (1 thread)

    real    0m2.184s
    user    0m4.294s
    sys    0m0.004s

$ time ./equix-bench --threads 4
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 4) ... 
    1.910000 solutions/nonce
    876.343564 solutions/sec. (4 threads)
    18863.079719 verifications/sec. (1 thread)

    real    0m1.154s
    user    0m4.400s
    sys    0m0.012s

$ time ./equix-bench --threads 8
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 8) ... 
    1.910000 solutions/nonce
    1089.198671 solutions/sec. (8 threads)
    17808.857809 verifications/sec. (1 thread)

    real    0m0.981s
    user    0m7.019s
    sys    0m0.052s

$ time ./equix-bench --threads 16
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 16) ... 
    1.910000 solutions/nonce
    2183.232035 solutions/sec. (16 threads)
    18936.014118 verifications/sec. (1 thread)

    real    0m1.025s
    user    0m7.021s
    sys    0m0.032s

$ time ./equix-bench --threads 32
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 32) ... 
    1.910000 solutions/nonce
    4397.259598 solutions/sec. (32 threads)
    17754.229411 verifications/sec. (1 thread)

    real    0m1.026s
    user    0m6.961s
    sys    0m0.049s

$ cat /proc/cpuinfo
    &lt;snip&gt;
    processor    : 7
    vendor_id    : GenuineIntel
    cpu family    : 6
    model        : 58
    model name    : Intel(R) Core(TM) i7-3740QM CPU @ 2.70GHz
    stepping    : 9
    microcode    : 0x21
    cpu MHz        : 1856.366
    cache size    : 6144 KB
    physical id    : 0
    siblings    : 8
    core id        : 3
    cpu cores    : 4
    apicid        : 7
    initial apicid    : 7
    fpu        : yes
    fpu_exception    : yes
    cpuid level    : 13
    wp        : yes
    flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge
mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe
syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl
xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor
ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic
popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault
epb pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid
fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1d
    bugs        : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass
l1tf mds swapgs itlb_multihit srbds
    bogomips    : 5387.48
    clflush size    : 64
    cache_alignment    : 64
    address sizes    : 36 bits physical, 48 bits virtual
    power management:

Similar behavior on the (4-core aarch64) pinephone:
   
$ time ./equix-bench --threads 1
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 1) ... 
    1.910000 solutions/nonce
    23.920219 solutions/sec. (1 thread)
    4477.199102 verifications/sec. (1 thread)

    real    0m 40.35s
    user    0m 40.12s
    sys    0m 0.01s

$ time ./equix-bench --threads 2
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 2) ... 
    1.910000 solutions/nonce
    47.683428 solutions/sec. (2 threads)
    4384.937853 verifications/sec. (1 thread)

    real    0m 20.45s
    user    0m 40.20s
    sys    0m 0.06s


$ time ./equix-bench --threads 4
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 4) ... 
    1.910000 solutions/nonce
    94.149494 solutions/sec. (4 threads)
    4359.695415 verifications/sec. (1 thread)
    real    0m 10.47s
    user    0m 40.71s
    sys    0m 0.08s

$ time ./equix-bench --threads 8
    Solving nonces 0-499 (interpret: 0, hugepages: 0, threads: 8) ... 
    1.910000 solutions/nonce
    188.808873 solutions/sec. (8 threads)
    4348.479398 verifications/sec. (1 thread)

    real    0m 10.50s
    user    0m 40.61s
    sys    0m 0.07s


$ cat /proc/cpuinfo
    &lt;snip&gt;
    processor    : 3
    BogoMIPS    : 48.00
    Features    : fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid
    CPU implementer    : 0x41
    CPU architecture: 8
    CPU variant    : 0x0
    CPU part    : 0xd03
    CPU revision    : 4




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200129160620</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-01-29 16:06:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi teor,

Thanks for this epic work, some lecture for me to deeply go over this
weekend.

By briefly reviewing I've noticed something important is missing that
should be a part of this proposal.

I am not sure under which section it should go under. I guess `3.2.2.
Use the Advertised ORPort IPv4 and IPv6 Addresses`, or maybe it's
important enough that we should make its own section.

In IPv6, besides publicly routable and non-publicly routable addresses
(fe80:// etc.) which are documented in the proposal, we have temporary
IPv6 addresses coming from Privacy extensions or RFC4941 IPv6 addresses.

https://tools.ietf.org/rfc/rfc4941.txt

These addresses are publicly routable, they can appear as reachable from
the directory authorities or from directory data fetches, but they have
limited lifetime and change over time. I am not sure if one  such
address becomes deprecated if already in use (say by Tor), as the RFC
states MAY _if not in use by applications  or upper layers_:

   "As an optional optimization, an implementation MAY remove a
   deprecated temporary address that is not in use by applications or
   upper layers as detailed in Section 6."

But since this is implementation dependent, we cannot be sure about the
behavior across different platforms that relays might run on.

It is up to the operating system if such addresses are used or not. In
Debian they are disabled by default net.ipv6.conf.eth0.use_tempaddr=0
(unless some desktop packages that use network manager with different
settings change it). In Windows (at least Windows 10) apparently they
are enabled by default.

The question is, do we want such addresses in relay descriptors? I think
such addresses will behave similar to dynamic IPv4 addresses, or even
worse since these ones really change when they want, not just when we
disconnect and reconnect the network interface. So maybe Tor should
detect such behavior and log an error or something?

Actually I'll setup a vm this weekend and give it a native, static /64
IPv6 prefix, enable privacy extension to use temporary addresses and
spin up a Tor process on it. Then disconnect the internet a couple of
times and see how it behaves, how often it changes.

What do you think?

teor wrote:
&gt; Hi,
&gt; 
&gt; Here is an initial draft of Proposal 312: Automatic Relay IPv6 Addresses.
&gt; 
&gt; This proposal includes:
&gt;  * relay auto IPv6 addresses, and
&gt;  * relay auto IPv6 ORPorts.
&gt; 
&gt; This is the second of 3 proposals:
&gt; * Proposal 311: Relay IPv6 Reachability
&gt; * Proposal 312: Automatic Relay IPv6 Addresses
&gt; * Proposal 313: Relay IPv6 Statistics
&gt; (I haven't written the final one yet.)
&gt; 
&gt; I also want to make some minor changes to Proposal 306, so that bridge
&gt; IPv6 behaviour stays in sync with client IPv6 behaviour. (See section
&gt; 7 of this proposal for details.)
&gt; 


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200129161955</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-01-29 16:19:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi again,

Apologies, a quick follow-up:

There is another RFC (older), that is in use by Debian apparently:
RFC3041. https://tools.ietf.org/rfc/rfc3041.txt

From:
https://manpages.debian.org/buster/iproute2/ip-address.8.en.html
see `mngtmpaddr`

RFC4941 is newer and with some improvements, however it does not mention
its purpose is to update / deprecate RFC3041. Actually it mentions the
differences / improvements.

Anyway, the point still fully stands, I just thought both RFCs should be
mentioned. Bottom line still is temporary (expiring) but otherwise
public and reachable IPv6 addresses in relay descriptor.


s7r wrote:
&gt; Hi teor,
&gt; 
&gt; Thanks for this epic work, some lecture for me to deeply go over this
&gt; weekend.
&gt; 
&gt; By briefly reviewing I've noticed something important is missing that
&gt; should be a part of this proposal.
&gt; 
&gt; I am not sure under which section it should go under. I guess `3.2.2.
&gt; Use the Advertised ORPort IPv4 and IPv6 Addresses`, or maybe it's
&gt; important enough that we should make its own section.
&gt; 
&gt; In IPv6, besides publicly routable and non-publicly routable addresses
&gt; (fe80:// etc.) which are documented in the proposal, we have temporary
&gt; IPv6 addresses coming from Privacy extensions or RFC4941 IPv6 addresses.
&gt; 
&gt; https://tools.ietf.org/rfc/rfc4941.txt
&gt; 
&gt; These addresses are publicly routable, they can appear as reachable from
&gt; the directory authorities or from directory data fetches, but they have
&gt; limited lifetime and change over time. I am not sure if one  such
&gt; address becomes deprecated if already in use (say by Tor), as the RFC
&gt; states MAY _if not in use by applications  or upper layers_:
&gt; 
&gt;    "As an optional optimization, an implementation MAY remove a
&gt;    deprecated temporary address that is not in use by applications or
&gt;    upper layers as detailed in Section 6."
&gt; 
&gt; But since this is implementation dependent, we cannot be sure about the
&gt; behavior across different platforms that relays might run on.
&gt; 
&gt; It is up to the operating system if such addresses are used or not. In
&gt; Debian they are disabled by default net.ipv6.conf.eth0.use_tempaddr=0
&gt; (unless some desktop packages that use network manager with different
&gt; settings change it). In Windows (at least Windows 10) apparently they
&gt; are enabled by default.
&gt; 
&gt; The question is, do we want such addresses in relay descriptors? I think
&gt; such addresses will behave similar to dynamic IPv4 addresses, or even
&gt; worse since these ones really change when they want, not just when we
&gt; disconnect and reconnect the network interface. So maybe Tor should
&gt; detect such behavior and log an error or something?
&gt; 
&gt; Actually I'll setup a vm this weekend and give it a native, static /64
&gt; IPv6 prefix, enable privacy extension to use temporary addresses and
&gt; spin up a Tor process on it. Then disconnect the internet a couple of
&gt; times and see how it behaves, how often it changes.
&gt; 
&gt; What do you think?
&gt; 


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200203091430</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-03 09:14:30-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]


Hi s7r,

Thanks for bringing up IPv6 address privacy extensions.

&gt; On 30 Jan 2020, at 02:19, s7r &lt;s7r@sky-ip.org&gt; wrote:
&gt; 
&gt; There is another RFC (older), that is in use by Debian apparently:
&gt; RFC3041. https://tools.ietf.org/rfc/rfc3041.txt
&gt; 
&gt; From:
&gt; https://manpages.debian.org/buster/iproute2/ip-address.8.en.html
&gt; see `mngtmpaddr`
&gt; 
&gt; RFC4941 is newer and with some improvements, however it does not mention
&gt; its purpose is to update / deprecate RFC3041. Actually it mentions the
&gt; differences / improvements.
&gt; 
&gt; Anyway, the point still fully stands, I just thought both RFCs should be
&gt; mentioned. Bottom line still is temporary (expiring) but otherwise
&gt; public and reachable IPv6 addresses in relay descriptor.
&gt; 
&gt; s7r wrote:
&gt;&gt; 
&gt;&gt; 
&gt;&gt; By briefly reviewing I've noticed something important is missing that
&gt;&gt; should be a part of this proposal.
&gt;&gt; 
&gt;&gt; I am not sure under which section it should go under. I guess `3.2.2.
&gt;&gt; Use the Advertised ORPort IPv4 and IPv6 Addresses`, or maybe it's
&gt;&gt; important enough that we should make its own section.
&gt;&gt; 
&gt;&gt; In IPv6, besides publicly routable and non-publicly routable addresses
&gt;&gt; (fe80:// etc.) which are documented in the proposal, we have temporary
&gt;&gt; IPv6 addresses coming from Privacy extensions or RFC4941 IPv6 addresses.
&gt;&gt; 
&gt;&gt; https://tools.ietf.org/rfc/rfc4941.txt
&gt;&gt; 
&gt;&gt; These addresses are publicly routable, they can appear as reachable from
&gt;&gt; the directory authorities or from directory data fetches, but they have
&gt;&gt; limited lifetime and change over time. I am not sure if one  such
&gt;&gt; address becomes deprecated if already in use (say by Tor), as the RFC
&gt;&gt; states MAY _if not in use by applications  or upper layers_:
&gt;&gt; 
&gt;&gt;   "As an optional optimization, an implementation MAY remove a
&gt;&gt;   deprecated temporary address that is not in use by applications or
&gt;&gt;   upper layers as detailed in Section 6."
&gt;&gt; 
&gt;&gt; But since this is implementation dependent, we cannot be sure about the
&gt;&gt; behavior across different platforms that relays might run on.
&gt;&gt; 
&gt;&gt; It is up to the operating system if such addresses are used or not. In
&gt;&gt; Debian they are disabled by default net.ipv6.conf.eth0.use_tempaddr=0
&gt;&gt; (unless some desktop packages that use network manager with different
&gt;&gt; settings change it). In Windows (at least Windows 10) apparently they
&gt;&gt; are enabled by default.
&gt;&gt; 
&gt;&gt; The question is, do we want such addresses in relay descriptors? I think
&gt;&gt; such addresses will behave similar to dynamic IPv4 addresses, or even
&gt;&gt; worse since these ones really change when they want, not just when we
&gt;&gt; disconnect and reconnect the network interface. So maybe Tor should
&gt;&gt; detect such behavior and log an error or something?
&gt;&gt; 
&gt;&gt; Actually I'll setup a vm this weekend and give it a native, static /64
&gt;&gt; IPv6 prefix, enable privacy extension to use temporary addresses and
&gt;&gt; spin up a Tor process on it. Then disconnect the internet a couple of
&gt;&gt; times and see how it behaves, how often it changes.
&gt;&gt; 
&gt;&gt; What do you think?

I read RFCs 4941 and 3041, looked at the tor directory spec, and did some
analysis:
* tor clients get new relay addresses within 4.5 hours
* IPv6 privacy extensions rotate addresses every day (by default)
* IPv6 privacy extensions remove old addresses after a week (by default)

(And applications have to opt-in to IPv6 privacy extensions addresses,
by default, according to the RFC.)

Therefore, I don't think tor relays or clients will be affected by relays
using IPv6 privacy extensions.

See my detailed analysis here:
https://github.com/torproject/torspec/pull/105/files#diff-28c992d72bedaa9378a4f3627afb8694R816

(I still have to revise proposal 312 based on Nick's review, I hope to do
that today or tomorrow.)

T

["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl435HYACgkQEP6qDnB1
Zyo9yQ//TA/SnQOxu8DYkVa1aH1gKO0FhOVsA2WPGDyZbQgqKiBdh373DHrat9UX
HtQos+INnb1zp93iVZ0g3gbDuSzDLx6UZmtWi8CU4mEHhM7rIMcx+izQYgxez+9s
VbRL/Y/4ACOgEnZUPasihyLTcc3yDl76jJQR5cHauMqMx3xG8ZHNU9t5X9gX4Anz
KuMvaMvG+xJmLXmP3WWF70nxuUH2D+1euMGfzY+odUD4pnoGVCFvpvLzplIDw84M
5GObzPVWyUCnYQvOziQrklfTaElscCE8kxo4HVxHJ4BnLAo8g4q0ub69NHa2ftw7
sdjZ7VuVGiRBAYcJtvrXkqAbyPxPp32gzt0Tz3MuPUtf+dAUGnYvtEaI95eN9Yc8
YAxQyFi0tEBolC2q5J4uSf4Af7z/ts+eMlDUfbc0oGM8ptgusKKB0+tbKaLxYqXD
gUBVK+fiRIqWNkxKueVBEbuSyIT9VUuRNskFc3CKRxiN/xRixxuxAXszD9zuI0tA
ppnU/K4Xn+JsvJKOZLvt5VyXqCqe3L8+iel34b3Q1l+uC4ZgqwiCpu6kUcZ+De0n
zXoin9DVYP8lOO9L7WTSOTs82RUdvrkCJJt5inGuSvejkPNL1HN3fydveIv2WRj6
sLXzW6sl2yOOJwBAuRvwVLp0d8N/90z+2dYmvrQt/ht1Zn+sOAE=
=aEcu
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200203211748</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-02-03 21:17:48-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi teor,

teor wrote:
&gt; Hi s7r,
&gt; 
&gt; Thanks for bringing up IPv6 address privacy extensions.
&gt; 
&gt;&gt; On 30 Jan 2020, at 02:19, s7r &lt;s7r@sky-ip.org&gt; wrote:
&gt;&gt;
&gt; 
&gt; I read RFCs 4941 and 3041, looked at the tor directory spec, and did some
&gt; analysis:
&gt; * tor clients get new relay addresses within 4.5 hours
&gt; * IPv6 privacy extensions rotate addresses every day (by default)
&gt; * IPv6 privacy extensions remove old addresses after a week (by default)
&gt; 
&gt; (And applications have to opt-in to IPv6 privacy extensions addresses,
&gt; by default, according to the RFC.)
&gt; 
&gt; Therefore, I don't think tor relays or clients will be affected by relays
&gt; using IPv6 privacy extensions.
&gt; 
&gt; See my detailed analysis here:
&gt; https://github.com/torproject/torspec/pull/105/files#diff-28c992d72bedaa9378a4f3627afb8694R816
&gt; 
&gt; (I still have to revise proposal 312 based on Nick's review, I hope to do
&gt; that today or tomorrow.)
&gt; 
&gt; T

Thanks for looking into it!

I agree with your analysis fully. However, I just think it would be
better if we mention in proposal 312 explicitly that Tor should try hard
to get an IPv6 address that has the desired state, and use that. It is
true that this is different on each operating system, but the operating
systems we most care about should be pretty trivial to patch for this
change.

IPv6 addresses have multiple states. We simply request for one that has
state `public` and not `temporary`.
(https://tools.ietf.org/html/rfc3484).

In the current form of this proposal, it looks kind of optional ("We
propose this optional change, to improve..."). I propose removing the
line which contains "this optional change" and changing the following:

In practice, each operating system has a different way of detecting IPv6
address privacy extensions. And some operating systems may not tell
applications if a particular address is using privacy extensions. So
implementing this change may be difficult.

to

In practice, each operating system has a different way of indicating if
an IPv6 address comes from a privacy extension or not. Usually the
operating system also returns the state of each available address:
"public" - the ones that does not change, and which Tor should use
"temporary" - the ones that come from privacy extensions
Tor should always ask for and use a "public" IPv6 addresses to build
relay descriptor.

Might not be the most explicit wording, but feel free to rephrase, we
just need to make it clear that we will try as hard as possible to NOT
use a temporary IPv6 address, and might only use one in small isolated
cases where operating systems do not report to Tor properly the states
of the available IPv6 addresses.

This shouldn't be too hard - apache and most properly coded server apps
do not bind to temporary IPv6 addresses. Also, all the IPv6 related RFCs
make it mandatory for server type applications (like Tor in relay mode)
to request `public` IPv6 addresses, not `temporary` ones.

sbws of course should account relays per IPv6 prefix, and not per
address. Usually we should be able to determine if an address is in the
same /64 IPv6 subnet and not reset the bandwidth measurement because
most probably it is the same relay. A /64 is standard, however there are
ISPs that do now follow the standard in assigning /64 to end users and
sometimes assign /112 or strange things like that. So this can become
complicated again. Which is why it is more simple to always ask for a
`public` IPv6 address and ignore `temporary` ones. I think it's simpler
and more efficient than changing sbws.


##### NOT DIRECTLY RELATED TO PROPOSAL 312 SECTION #####
These privacy extensions IPv6 addresses might be good for outgoing IPv6
exit connections, like changing per circuit or per destination to get
rid of captchas and blacklists, but this is something different.

Our internal DoS defense subsystem should also treat prefixes instead of
addresses, because right now with a client with a /64 public IPv6 prefix
assigned to it I could hammer via IPv6 guards without triggering the DoS
defense. This is is something different as well.

From my point of view all these should go under the same big `Tor-IPv6`
project, and get funded as well. So, there's quite some work ahead ;)
##### END OF NOT DIRECTLY RELATED TO PROPOSAL 312 SECTION #####

-s7r


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200204004324</emailId><senderName>Mirimir</senderName><senderEmail>mirimir@riseup.net</senderEmail><timestampReceived>2020-02-04 00:43:24-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

On 02/03/2020 02:17 PM, s7r wrote:

&lt;SNIP&gt;

&gt; In the current form of this proposal, it looks kind of optional ("We
&gt; propose this optional change, to improve..."). I propose removing the
&gt; line which contains "this optional change" and changing the following:
&gt; 
&gt; In practice, each operating system has a different way of detecting IPv6
&gt; address privacy extensions. And some operating systems may not tell
&gt; applications if a particular address is using privacy extensions. So
&gt; implementing this change may be difficult.
&gt; 
&gt; to
&gt; 
&gt; In practice, each operating system has a different way of indicating if
&gt; an IPv6 address comes from a privacy extension or not. Usually the
&gt; operating system also returns the state of each available address:
&gt; "public" - the ones that does not change, and which Tor should use
&gt; "temporary" - the ones that come from privacy extensions
&gt; Tor should always ask for and use a "public" IPv6 addresses to build
&gt; relay descriptor.

What's the downside of using "temporary" IPv6 addresses from privacy
extensions?

I mean, isn't better privacy a good thing?

&lt;SNIP&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200204221355</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-02-04 22:13:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


 Mirimir wrote:
&gt; On 02/03/2020 02:17 PM, s7r wrote:
&gt; 
&gt; &lt;SNIP&gt;
&gt; 
&gt;&gt; In the current form of this proposal, it looks kind of optional ("We
&gt;&gt; propose this optional change, to improve..."). I propose removing the
&gt;&gt; line which contains "this optional change" and changing the following:
&gt;&gt;
&gt;&gt; In practice, each operating system has a different way of detecting IPv6
&gt;&gt; address privacy extensions. And some operating systems may not tell
&gt;&gt; applications if a particular address is using privacy extensions. So
&gt;&gt; implementing this change may be difficult.
&gt;&gt;
&gt;&gt; to
&gt;&gt;
&gt;&gt; In practice, each operating system has a different way of indicating if
&gt;&gt; an IPv6 address comes from a privacy extension or not. Usually the
&gt;&gt; operating system also returns the state of each available address:
&gt;&gt; "public" - the ones that does not change, and which Tor should use
&gt;&gt; "temporary" - the ones that come from privacy extensions
&gt;&gt; Tor should always ask for and use a "public" IPv6 addresses to build
&gt;&gt; relay descriptor.
&gt; 
&gt; What's the downside of using "temporary" IPv6 addresses from privacy
&gt; extensions?
&gt; 
&gt; I mean, isn't better privacy a good thing?
&gt; 
&gt; &lt;SNIP&gt;

Not really.
These privacy extensions IPv6 addresses might be good for outbound bind
exit addresses (for Exit relays), and maybe (not sure) for regular
clients that could connect to their entry guards or bridges using a
temporary IPv6 address.

We only refer in this proposal to Tor in _relay mode_. When in relay
mode, it is desirable to bind to a static IPv6 address that does not
change, so bandwidth authorities can measure its bandwidth and directory
authorities and maintain its history, uptime statistics and flags as
well as not upload descriptors too often that will make them unusuable
for clients that have an older consensus which is still valid, and so on.

Usually it is not desirable for a 'server' of any kind (Tor relay
included of course) to have an expiring / temporary / dynamic IP
address. It is the other way around actually.

So, we don't plan to throw poison on privacy extensions IPv6 addresses,
might actually use them for the purposes explained at the beginning of
this email, but in this particular case of Proposal 312 when we are
discussing automatic address discovery for *relays* they are bad for us
- we wouldn't want to code Tor to discovery and gladly use a temporary
IPv6 address that was designed to *not* be used in server mode.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200205014655</emailId><senderName>Mirimir</senderName><senderEmail>mirimir@riseup.net</senderEmail><timestampReceived>2020-02-05 01:46:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

On 02/04/2020 03:13 PM, s7r wrote:

&lt;SNIP&gt;

&gt; These privacy extensions IPv6 addresses might be good for outbound bind
&gt; exit addresses (for Exit relays), and maybe (not sure) for regular
&gt; clients that could connect to their entry guards or bridges using a
&gt; temporary IPv6 address.

Thanks. Those are the two situations I had in mind.

&gt; We only refer in this proposal to Tor in _relay mode_.

That wasn't clear to me, and that's arguably my fault.

&lt;SNIP&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200205025646</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-05 02:56:46-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]


Hi Nick,

Thanks so much for your review!

I've made most of the changes you've suggested, you can see the latest
version of the proposal here:
https://github.com/torproject/torspec/pull/105/files

I've also made changes in response to s7r's feedback about IPv6 privacy
extensions. Since sending the draft, I've also noticed some missing
information, and some things that could be explained better.

I'm trying to keep a clear distinction in this proposal, to keep the
sponsor 55 scope manageable. So I am keeping different sections for:
  * required changes: changes that we must make to achieve the objectives
                      of sponsor 55
  * optional changes: good ideas that we can implement if we have time left
                      in sponsor 55, or in future IPv6 work

There's some flexibility, particularly if we decide that an optional
change is the fastest way to get something implemented.

I'll send another full text to the list when all the reviews are done.

I've also responded to your comments below individually:

&gt; On 31 Jan 2020, at 08:08, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; On Wed, Jan 29, 2020 at 9:04 AM teor &lt;teor@riseup.net&gt; wrote:
&gt; 
&gt; Hello again!  This looks like another fine proposal.  I'm leaving
&gt; comments inline, and clipping sections that I'm not commenting on.
&gt; 
&gt;&gt; Filename: 312-relay-auto-ipv6-addr.txt
&gt;&gt; Title: Tor Relays Automatically Find Their IPv6 Address
&gt;&gt; Author: teor
&gt;&gt; Created: 28-January-2020
&gt;&gt; Status: Draft
&gt;&gt; Ticket: #33073
&gt;&gt; 
&gt;&gt; 0. Abstract
&gt;&gt; 
&gt;&gt;   We propose that Tor relays (and bridges) should automatically find their
&gt;&gt;   IPv6 address, and use it to publish an IPv6 ORPort. For some relays to find
&gt;&gt;   their IPv6 address, they may need to fetch some directory documents from
&gt;&gt;   directory authorities over IPv6. (For anonymity reasons, bridges are unable
&gt;&gt;   to fetch directory documents over IPv6, until clients start to do so.)
&gt;&gt; 
&gt;&gt; 1. Introduction
&gt;&gt; 
&gt;&gt;   Tor relays (and bridges) currently find their IPv4 address, and use it as
&gt;&gt;   their ORPort and DirPort address when publishing their descriptor. But
&gt;&gt;   relays and bridges do not automatically find their IPv6 address.
&gt; 
&gt; At the beginning of this document, we should be a bit more clear about
&gt; which address specifically we're trying to find.  If we wanted _some_
&gt; address, or if NAT and firewalls didn't exist, we could just open a
&gt; socket, call getsockname(), and be done with it.  What we are looking
&gt; for specifically is an address that we can advertise to the rest of
&gt; the world in our server descriptor.  [I know you know this, but we
&gt; should say so.]

Thanks, that's a great reminder. I've explained how we use the detected
IP addresses, and what kind of addresses we are looking for.

I've left a detailed description of how we ignore private addresses, and
use other methods, to later in the proposal.

Please see this commit:
https://github.com/torproject/torspec/pull/105/commits/dff29ec0424a31147c040a8d8b6724df4d2dfc25

&gt; [...]
&gt;&gt; 3. Finding Relay IPv6 Addresses
&gt;&gt; 
&gt;&gt;   We propose that tor relays (and bridges) automatically find their IPv6
&gt;&gt;   address, and use it to publish an IPv6 ORPort.
&gt;&gt; 
&gt;&gt;   For some relays to find their IPv6 address, they may need to fetch some
&gt;&gt;   directory documents from directory authorities over IPv6. (For anonymity
&gt;&gt;   reasons, bridges are unable to fetch directory documents over IPv6, until
&gt;&gt;   clients start to do so.)
&gt;&gt; 
&gt;&gt; 3.1. Current Relay IPv4 Address Implementation
&gt;&gt; 
&gt;&gt;   Currently, all relays (and bridges) must have an IPv4 address. IPv6
&gt;&gt;   addresses are optional for relays.
&gt;&gt; 
&gt;&gt;   Tor currently tries to find relay IPv4 addresses in this order:
&gt;&gt;     1. the Address torrc option
&gt;&gt;     2. the address of the hostname (resolved using DNS, if needed)
&gt;&gt;     3. a local interface address
&gt;&gt;        (by making a self-connected socket, if needed)
&gt;&gt;     4. an address reported by a directory server (using X-Your-Address-Is)
&gt; 
&gt; Any server, or only an authority?  Over any connection, or only an
&gt; authenticated one?

Thanks for picking up on this inconsistency.

In the current implementation, when a tor relay doesn't know its address, it
tried to fetch from directory authorities. But it will believe an addresses from
any directory server.

Relays try to use DirPorts, even if they don't know their own IP address. But if
they select a directory mirror that only has an ORPort, they will use its ORPort.

I've fixed this particular inconsistency in this commit:
https://github.com/torproject/torspec/pull/105/commits/dff29ec0424a31147c040a8d8b6724df4d2dfc25

Ideally, relays should use authenticated directory authorities to discover their
addresses. But it's not a simple change, because it affects directory authority
load balancing.

So I've put it in the "optional changes" section of the proposal. If we have time,
we should make these changes, with high priority.

For more details, see sections 3.5.1, 3.5.2, and 3.5.3 in:
https://github.com/torproject/torspec/pull/105/files

&gt; [...]
&gt;&gt; 3.2. Finding Relay IPv6 Addresses
&gt;&gt; 
&gt;&gt;   We propose that relays (and bridges) try to find their IPv6 address. For
&gt;&gt;   consistency, we also propose to change the address resolution order for
&gt;&gt;   IPv4 addresses.
&gt;&gt; 
&gt;&gt;   We use the following general principles to choose the order of IP address
&gt;&gt;   methods:
&gt;&gt;     * Explicit is better than Implicit,
&gt;&gt;     * Local Information is better than a Remote Dependency,
&gt;&gt;     * Trusted is better than Untrusted, and
&gt;&gt;     * Reliable is better than Unreliable.
&gt;&gt;   Within these constraints, we try to find the simplest working design.
&gt; 
&gt; We should make sure to be clear about the impact of using an untrusted
&gt; source.  Anybody who can fool a relay about its IP can effectively
&gt; MITM that relay's incoming connections (traffic patterns only), so
&gt; using a non-trusted source can be risky for anonymity.

I've explained the attack here:
https://github.com/torproject/torspec/pull/105/commits/0908365d52a022580dfcc236b0a73605886a38a1

And some potential mitigations in sections 3.5.1, 3.5.2, and 3.5.3 in:
https://github.com/torproject/torspec/pull/105/files

&gt; [...]
&gt;&gt;   (Each of these address resolution steps is described in more detail, in its
&gt;&gt;   own subsection.)
&gt;&gt; 
&gt;&gt;   While making these changes, we want to preserve tor's existing behaviour:
&gt;&gt;     * resolve Address using the local resolver, if needed,
&gt;&gt;     * ignore private addresses on public tor networks, and
&gt;&gt;     * when there are multiple valid addresses, choose the first or latest
&gt;&gt;       address, as appropriate.
&gt; 
&gt; Instead of "first or latest" I suggest "first-listed or most recently
&gt; received" here, to help non-native speakers.

I expanded the explanation so it says *when* we use each address selection
heuristic. And I made sure that the heuristics are not described as (exclusive)
alternatives.

Some methods may actually deliver a list of addresses, *and* that list may change
over time (DNS, local interfaces). So tor may need to use both heuristics for a
single method.

See commit:
https://github.com/torproject/torspec/pull/105/commits/13961201d21dd5592cc95d38b35870f696a4e38b

&gt;&gt; 3.2.1. Make the Address torrc Option Support IPv6
&gt; [...]
&gt;&gt;   It is an error to configure an Address option with a private IPv4 or IPv6
&gt;&gt;   address, or with a hostname that does not resolve to any publicly routable
&gt;&gt;   IPv4 or IPv6 addresses.
&gt; 
&gt; We should say "on a public network" here -- private addresses are fine
&gt; on private networks.

Thanks, I made a similar change in:
https://github.com/torproject/torspec/pull/105/commits/f74bc06210cf7c0ffc83a302d21422457038b34b

&gt; Also, this seems to mean that if the relay's DNS resolver goes down,
&gt; the relay should give an error and exit, even if it was already
&gt; running.  That seems undesired.

I changed it to "tor should warn" in:
https://github.com/torproject/torspec/pull/105/commits/f74bc06210cf7c0ffc83a302d21422457038b34b

&gt; [...]
&gt;&gt; 3.2.2. Use the Advertised ORPort IPv4 and IPv6 Addresses
&gt;&gt; 
&gt;&gt;   Next, we propose that relays (and bridges) use the first advertised ORPort
&gt;&gt;   IPv4 and IPv6 addresses, as configured in their torrc.
&gt;&gt; 
&gt;&gt;   The ORPort address may be a hostname. If it is, tor should try to use it to
&gt;&gt;   resolve an IPv4 and IPv6 address, and open ORPorts on the first available
&gt;&gt;   IPv4 and IPv6 address. Tor should respect the IPv4Only and IPv6Only port
&gt;&gt;   flags, if specified. (Tor currently resolves IPv4 addresses in ORPort
&gt;&gt;   lines. It may not look for an IPv6 address.)
&gt;&gt; 
&gt;&gt;   Relays (and bridges) currently use the first advertised ORPort IPv6 address
&gt;&gt;   as their IPv6 address. We propose to use the first advertised IPv4 ORPort
&gt;&gt;   address in a similar way, for consistency.
&gt;&gt; 
&gt;&gt;   Therefore, this change may affect existing relay IPv4 addressses. We expect
&gt;&gt;   that a small number of relays may change IPv4 address, from a guessed IPv4
&gt;&gt;   address, to their first advertised IPv4 ORPort address.
&gt;&gt; 
&gt;&gt;   In rare cases, relays may have been using non-advertised ORPorts for their
&gt;&gt;   addresses. This change may also change their addresses.
&gt;&gt; 
&gt;&gt;   We propose ignoring private configured ORPort addresses on public tor
&gt;&gt;   networks. (Binding to private ORPort addresses is supported, even on public
&gt;&gt;   tor networks, for relays that use NAT to reach the Internet.) If an ORPort
&gt;&gt;   address is private, address resolution should go to the next step.
&gt;&gt; 
&gt;&gt; 3.2.3. Use the Advertised DirPort IPv4 Address
&gt;&gt; 
&gt;&gt;   Next, we propose that relays use the first advertised DirPort IPv4 address,
&gt;&gt;   as configured in their torrc.
&gt; 
&gt; I think that we could omit this method; it seems unlikely to me that
&gt; anybody is going to configure an advertised DirPort address but not an
&gt; advertised ORPort address.   In the long run, I think we want DirPorts
&gt; to disappear entirely as part of our official protocol.

I agree that:

ORPort 8888
DirPort 1.1.1.1:9999

is probably a rare configuration.

I originally added this method, because of a bug with DirPort addresses:
https://trac.torproject.org/projects/tor/ticket/10519

But I don't think the DirPort method would actually fix that bug. So I've
removed the DirPort method entirely:
https://github.com/torproject/torspec/pull/105/commits/d8c7254aece841453f3073f5d3b7870d2cd2c70d

&gt;&gt; 3.2.4. Use Local Interface IPv6 Address
&gt;&gt; 
&gt;&gt;   Next, we propose that relays (and bridges) use publicly routable addresses
&gt;&gt;   from the OS interface addresses or routing table, as their IPv4 and IPv6
&gt;&gt;   addresses.
&gt;&gt; 
&gt;&gt;   Tor has local interface address resolution functions, which support most
&gt;&gt;   major OSes. Tor uses these functions to guess its IPv4 address. We propose
&gt;&gt;   using them to also guess tor's IPv6 address.
&gt;&gt; 
&gt;&gt;   We also propose modifying the address resolution order, so interface
&gt;&gt;   addresses are used before the local hostname. This decision is based
&gt;&gt;   on our principles: interface addresses are local, trusted, and reliable;
&gt;&gt;   hostname lookups may be remote, untrusted, and unreliable.
&gt;&gt; 
&gt;&gt;   Some developer documentation also recommends using interface addresses,
&gt;&gt;   rather than resolving the host's own hostname. For example, on recent
&gt;&gt;   versions of macOS, the man pages tell developers to use interface addresses
&gt;&gt;   (getifaddrs) rather than look up the host's own hostname (gethostname and
&gt;&gt;   getaddrinfo). Unfortunately, these man pages don't seem to be available
&gt;&gt;   online, except for short quotes (see [getaddrinfo man page] for the
&gt;&gt;   relevant quote).
&gt;&gt; 
&gt;&gt;   If the local interface addresses are unavailable, tor opens a self-connected
&gt;&gt;   UDP socket to a publicly routable address, but doesn't actually send any
&gt;&gt;   packets. Instead, it uses the socket APIs to discover the interface address
&gt;&gt;   for the socket.
&gt; 
&gt; I don't understand in which sense this socket is  "self-connected" --
&gt; maybe "unused" or something?

Thanks, I've made this change in:
https://github.com/torproject/torspec/pull/105/commits/01099076c47449a1237e51f2030d071d79b87034

&gt; Also I'd suggest that Tor should use an
&gt; authority's IP address for this purpose.  Currently, we use 18.0.0.1,
&gt; which tends to confuse people who are looking at their firewall's
&gt; warnings.

Or for IPv6, we use [2002::].

I've described this optional change in a new section:
https://github.com/torproject/torspec/pull/105/commits/c60e1173e68fa2768dc3f2e343d17a3d751da732

&gt;&gt;   Tor already ignores private IPv4 interface addresses on public relays.
&gt;&gt;   (Binding to private DirPort addresses is supported, for networks that use
&gt;&gt;   NAT.) We propose to also ignore private IPv6 interface addresses. If all
&gt;&gt;   IPv4 or IPv6 interface addresses are private, address resolution should go
&gt;&gt;   to the next step.
&gt;&gt; 
&gt;&gt; 3.2.5. Use Own Hostname IPv6 Addresses
&gt;&gt; 
&gt;&gt;   Next, we propose that relays (and bridges) get their local hostname, look
&gt;&gt;   up its addresses, and use them as its IPv4 and IPv6 addresses.
&gt;&gt; 
&gt;&gt;   We propose to use the same underlying lookup functions to look up the IPv4
&gt;&gt;   and IPv6 addresses for:
&gt;&gt;     * the Address torrc option (see section 3.2.1), and
&gt;&gt;     * the local hostname.
&gt;&gt;   However, OS APIs typically only return a single hostname.
&gt;&gt; 
&gt;&gt;   Even though the hostname lookup may use remote DNS, we propose to use it on
&gt;&gt;   directory authorities, to maintain compatibility with current
&gt;&gt;   configurations. Even if it is remote, we expect the configured DNS to be
&gt;&gt;   somewhat trusted by the operator.
&gt; 
&gt; Do you mean to say "directory authorities" here? I don't understand that part.

I agree it's unclear.

I've changed the proposal to require explicitly configured addresses on
directory authorities, in:
https://github.com/torproject/torspec/pull/105/commits/3264015ec8bb61604fbdf1e61053bfc56990696d

&gt; [...]
&gt;&gt; 3.2.6. Use Directory Header IPv6 Addresses
&gt;&gt; 
&gt;&gt;   Finally, we propose that relays get their IPv4 and IPv6 addresses from the
&gt;&gt;   X-Your-Address-Is HTTP header in tor directory documents. To support this
&gt;&gt;   change, we propose that relays start fetching directory documents over IPv4
&gt;&gt;   and IPv6.
&gt; 
&gt; Can we specify use of NETINFO cells additionally or instead?  Unlike
&gt; DirPort connections, ORPort connections are authenticated, so we know
&gt; who is telling us what our address is.

I've added an optional section for NETINFO cells:
https://github.com/torproject/torspec/pull/105/commits/6815f8ddb8ff0de7395e343821b6c74b570862ef

&gt;&gt;   We propose that bridges continue to only fetch directory documents over
&gt;&gt;   IPv4, because they try to imitate clients. (Most clients only fetch
&gt;&gt;   directory documents over IPv4, a few clients are configured to only fetch
&gt;&gt;   over IPv6.) When client behaviour changes to use both IPv4 and IPv6 for
&gt;&gt;   directory fetches, bridge behaviour can also change to match. (See
&gt;&gt;   section 3.4.1 and [Proposal 306: Client Auto IPv6 Connections].)
&gt;&gt; 
&gt;&gt;   We propose that directory authorities should ignore addresses in directory
&gt;&gt;   headers. Allowing other authorities (or relays?) to change a directory
&gt;&gt;   authority's published IP address may lead to security issues. Instead,
&gt;&gt;   if interface and hostname lookups fail, tor should stop address resolution,
&gt;&gt;   and return a permanent error. (And issue a log to the operator, see below.)
&gt; 
&gt; I suggest that we simplify the whole directory authority logic and say
&gt; that authorities must have configured Address lines, or nothing.

That's a breaking change for most directory authority operators, including
all operators whose authorities have IPv6 ORPorts.

I've tweaked this change slightly, so that directory authorities:
* only use IPv4 and IPv6 address literals
* use the addresses configured in Address, then ORPort, then stop

This design has the following benefits:
* support current configs that set ORPort [IPv6]:Port
* only use explicitly configured addresses
* no DNS, or any other dynamic lookups, even for Address or ORPort,
  (authorities currently use DNS to lookup hostnames in Address lines)
* no implicit addresses, even using local information, like interface
  addresses (it's not necessary)

It's only a breaking change when necessary for security: that is, when
authorities are depending on hostnames, or other implicit address
detection.

Here's the detailed design:
https://github.com/torproject/torspec/pull/105/commits/3264015ec8bb61604fbdf1e61053bfc56990696d

&gt; [...]
&gt;&gt; 3.3. Consequential Tor Client Changes
&gt;&gt; 
&gt;&gt;   We do not propose any required client address resolution changes at this
&gt;&gt;   time.
&gt;&gt; 
&gt;&gt;   However, clients will use the updated address resolution functions to detect
&gt;&gt;   when they are on a new connection, and therefore need to rotate their TLS
&gt;&gt;   keys.
&gt; 
&gt; Do clients have meaningful TLS keys any more, now that they have
&gt; dropped client support for the v1 link protocol?
&gt; 
&gt; (This is just a side question -- clients should still have a working
&gt; ip_address_changed() function.)

I'm really not sure. I'm working off the functions and comments, which are all
still in the current codebase.

I think it's out of scope for this proposal, but maybe worth opening a ticket.

Is there a specific change you'd like to this proposal?

Deleting ", and therefore need to rotate their TLS keys." ?

&gt; [...]
&gt;&gt; 3.5. Optional Efficiency and Reliability Changes
&gt;&gt; 
&gt;&gt;   We propose some optional changes for efficiency and reliability, and
&gt;&gt;   describe their impact.
&gt;&gt; 
&gt;&gt;   Some of these changes may be more appropriate in future releases, or
&gt;&gt;   along with other proposed features.
&gt;&gt; 
&gt;&gt; 3.5.1. Only Use Authenticated Directory Header IPv4 and IPv6 Addresses
&gt;&gt; 
&gt;&gt;   We propose this optional change, to improve relay address accuracy and
&gt;&gt;   reliability.
&gt; 
&gt; I am +1 here, with a proviso that we should be able to use NETINFO cells.

That's an optional change, in:
https://github.com/torproject/torspec/pull/105/commits/6815f8ddb8ff0de7395e343821b6c74b570862ef

&gt; [...]
&gt;&gt; 3.5.5. Add IPv6 Support to AuthDirMaxServersPerAddr
&gt;&gt; 
&gt;&gt;   We propose this optional change, to improve the health of the network, by
&gt;&gt;   rejecting too many relays on the same IPv6 address.
&gt;&gt; 
&gt;&gt;   Modify get_possible_sybil_list() so it takes an address family argument,
&gt;&gt;   and returns a list of IPv4 or IPv6 sybils.
&gt;&gt; 
&gt;&gt;   Use the modified get_possible_sybil_list() to exclude relays from the
&gt;&gt;   authority's vote, if there are more than AuthDirMaxServersPerAddr on the
&gt;&gt;   same IPv4 or IPv6 address.
&gt;&gt; 
&gt;&gt;   Since these relay exclusions happen at voting time, they do not require a
&gt;&gt;   new consensus method.
&gt; 
&gt; Since it's trivial for one host to have a staggering number of IPv6
&gt; addresses, should this specify a /80 or /96 or something as being
&gt; sybil-like?

You're thinking way too small :-)

The typical host allocation is /64, and the smallest provider site allocation
is also usually /64.

Therefore, I think we should add a new AuthDirMaxServersPerIPv6Site option,
and analyse the current network to choose its default value:
https://github.com/torproject/torspec/pull/105/commits/31206b9fc4d114586fc556fb33ab7a8d71314666

(Personally, I've run 6 relays on one IPv6 address.)

&gt; [...]
&gt;&gt; 3.5.7. Add IPv6 Support Using gethostbyname2()
&gt; 
&gt; I agree that this change should be unnecessary; I'd suggest that we
&gt; not do it and just require getaddrinfo() for meaningful IPv6
&gt; resolution.
&gt; 
&gt; Alternatively, we could use libevent's DNS.

I agree that this change may be unnecessary. It's already in the list of
optional changes in the proposal.

I've added libevent as our preferred DNS API, if we discover that a large
number of systems don't support IPv6 DNS, because they're using
gethostbyname():

https://github.com/torproject/torspec/pull/105/commits/ab5a618b8246c9cc8e8d14b75e9ba95a5ece2c70

&gt;&gt; 3.5.8. Change Relay OutboundBindAddress Defaults
&gt;&gt; 
&gt;&gt;   We propose this optional change, to improve the reliability of
&gt;&gt;   IP address-based filters in tor.
&gt;&gt; 
&gt;&gt;   For example, the tor network treats relay IP addresses differently when:
&gt;&gt;     * resisting denial of service, and
&gt;&gt;     * selecting canonical, long-term connections.
&gt;&gt;   (See [Ticket 33018: Dir auths using an unsustainable 400+ mbit/s] for the
&gt;&gt;   initial motivation for this change: resisting significant bandwidth load
&gt;&gt;   on directory authorities.)
&gt;&gt; 
&gt;&gt;   Now that tor knows its own addresses, we propose that relays (and bridges)
&gt;&gt;   set their IPv4 and IPv6 OutboundBindAddress to these discovered addresses,
&gt;&gt;   by default. If binding fails, tor should fall back to an unbound socket.
&gt; 
&gt; I think this change might be unnecessary, but it shouldn't hurt.  I'd
&gt; suggest not prioritizing it very high.

I agree it's low-priority right now.

But if directory authorities start blocking all non-relay addresses to reduce
load, then we may have to make this change.

For the latest progress on the current authority load issue, see:
https://trac.torproject.org/projects/tor/ticket/33018#comment:16

&gt; [...]
&gt; 
&gt; In general, this plan above looks solid.
&gt; 
&gt; I have a suggestion before we get into the implementation, though: I
&gt; think we should, for each check, make sure that we write down _when_
&gt; it happens, what makes it happen, and where we store the result.  That
&gt; is, some of these checks are things we need to launch (like looking up
&gt; our own hostname), whereas others will happen passively pretty often
&gt; (like connecting to a directory authority).  Of the ones that we need
&gt; to launch, some will happen only when other methods have failed,
&gt; whereas some will happen on startup.  Some are things that can time
&gt; out, whereas others aren't.  Writing this all down will make sure that
&gt; we aren't making our state machine more complex than it needs to be.
&gt; 
&gt; IMO, we should record the status of all possible IP lookup methods,
&gt; with "not yet tried" being a possible status: it will help us keep our
&gt; implementation and our logging simple -- or at least, as simple as
&gt; can be.

The current state machine is implicit, but it seems to be fit for
purpose. So I didn't propose any modifications to it, because we're
trying to keep the Sponsor 55 work as small as possible.

For similar reasons, I didn't analyse or describe the current or
proposed state machines.

But it was a useful exercise, so I added it to the proposal:
https://github.com/torproject/torspec/pull/105/commits/094ef8553bb402faf44acf39a01961220e391831

Thanks again for the review!

T



["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl46Lu4ACgkQEP6qDnB1
Zyq5oRAAn+CnEgq2W64citgxc1yjh/HB691UYpoFZulwL8D5ZfagO7KUN30KJ1x5
FAoQ3auqnJaIpgle/GW2YPPmJ4i4q89K/SoHsPzrsKRS9zjovOrl8ZsX5GqEBCw1
/q1JmuT4y5WuvaYZ31qD09alQbt3amhRQE6/kfne4HxQO7wD8wPDwNeKduchft5V
s8CpgOD8QvDJWjsjRJmBfrj2LcaDSAQNO9xiQCMqIEGrjLlLpnXl0QWQP+hQiwGA
Tkeado8V39gI7benoryGMI6aGyf2Jw5wJDf5Kfg8ye91zoFidfAwbYyyHDPapqzO
0bPj0AdLfHkiBvlvk6VE9sLcn2qxEiZD2CefCNpqxw+RSFRwqQ8SmqlsWO/9dYMb
CdWvRMQl6DnFeWi1EPwaSEEsaVL5wNNKqM3TyEJ77lVlGj1S4qkT7Zg2uZfy0mbB
xXpyS+awBcGsnHLrx8Y0mSk320qa5K6Y9yhGzYdRj7vURC2GDHBwtpd5YvZYPY5t
lrRC2dncx+J4RPHtf/b3gAdNKe37mDi5aA2Hi00XL0NhzZH6Ki+zI8hqqHMit70F
LJ74Tqbi+3zFqf6YP8RAdkh64RK8cGgK4imrpK9qT9CFi4K7qmPNZJKcH6YXKjRt
1+IJ/558PAFT6sC325LKgUWKAGEzKG1xCvQwb/y2rOxTlJfgGaM=
=xDEQ
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201113051053</emailId><senderName>Wisdom With Rahul</senderName><senderEmail>rahulbhatia172@gmail.com</senderEmail><timestampReceived>2020-11-13 05:10:53-0400</timestampReceived><subject>Re: [tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/alternative)]


This idea is interesting but who owns all the keys?

Thanks and regards!




On Fri 13 Nov, 2020, 6:49 AM Keifer Bly, &lt;keifer.bly@gmail.com&gt; wrote:

&gt; Well, the mechanism is that it overwrites the key ever time, so each
&gt; message has its own unique key, also the receiver needs to verify the key
&gt; file with the built in tool to be able to use it. So an attacker does not
&gt; know this the only way to get this information is from the person that
&gt; created the message as the need when the OS originally generated the
&gt; message, not when it was uploaded as an attachment somewhere. That's what I
&gt; was thinking. I will look into the communities suggested, thanks very much.
&gt; --Keifer
&gt;
&gt;
&gt; On Thu, Nov 12, 2020 at 1:27 PM Santiago Torres-Arias &lt;
&gt; santiago@archlinux.org&gt; wrote:
&gt;
&gt;&gt; On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer Bly wrote:
&gt;&gt; &gt; Hi there,
&gt;&gt;
&gt;&gt; Hello,
&gt;&gt;
&gt;&gt; &gt; So I have a new email encryption system which requires that the user has
&gt;&gt; &gt; the specific key file generated for a message rather than the password,
&gt;&gt; &gt; specifically this software generates a unique key file for a specific
&gt;&gt; &gt; message every time a message is created. The user then enters the date
&gt;&gt; and
&gt;&gt; &gt; time the message was created. Without the original key file the message
&gt;&gt; &gt; can't be opened;
&gt;&gt; &gt;
&gt;&gt; &gt; https://www.youtube.com/watch?v=R0W7OVdNrOA
&gt;&gt; &gt;
&gt;&gt; &gt; Here is a video showing the software. I've built it for Windows and Mac
&gt;&gt; OS.
&gt;&gt; &gt; I was wondering if this could be implemented in tor. I think it would
&gt;&gt; be an
&gt;&gt; &gt; interesting idea for a tor based email system to make the messages
&gt;&gt; &gt; unrecoverable after use.
&gt;&gt;
&gt;&gt; I'm not a tor-dev, so I can't comment on the interest, but it appears to
&gt;&gt; me that the value added of this idea (basically, using time to seed a
&gt;&gt; PRF/KDF) is very little. All in all, using time to seed keys is not the
&gt;&gt; best idea. It also seems to be on top of PGP, so I'm pretty convinced
&gt;&gt; this doesn't provide perfect forward-secrecy unless you're layering any
&gt;&gt; sort of session key ratcheting mechanism yourself.
&gt;&gt;
&gt;&gt; I think the goal is laudable, but I suggest getting a little bit more
&gt;&gt; involved in cryptography engineering communities to see learn, develop
&gt;&gt; and eventually help change the status quo.
&gt;&gt;
&gt;&gt; Cheers!
&gt;&gt; -S
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="auto"&gt;This idea is interesting but who owns all the keys?&lt;br&gt;&lt;br&gt;&lt;div \
data-smartmail="gmail_signature"&gt;Thanks and regards!&lt;br&gt;&lt;br&gt;&lt;br&gt;       \
&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Fri 13 \
Nov, 2020, 6:49 AM Keifer Bly, &lt;&lt;a \
href="mailto:keifer.bly@gmail.com"&gt;keifer.bly@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex"&gt;&lt;div dir="ltr"&gt;Well, the mechanism  \
is that it  overwrites the key ever time, so each message has its own unique key, \
also the receiver  needs to verify the key file with the built in tool to be able to \
use it. So an attacker does not know this the only way to get this information is \
from the person that created the message as the need when the OS originally generated \
the message, not when it was uploaded as an attachment somewhere. That's what I \
was thinking. I will look into the communities suggested, thanks very much. --Keifer  \
&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Thu, \
Nov 12, 2020 at 1:27 PM Santiago Torres-Arias &lt;&lt;a \
href="mailto:santiago@archlinux.org" target="_blank" \
rel="noreferrer"&gt;santiago@archlinux.org&lt;/a&gt;&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer \
Bly wrote:&lt;br&gt; &gt; Hi there,&lt;br&gt;
&lt;br&gt;
Hello,&lt;br&gt;
&lt;br&gt;
&gt; So I have a new email encryption system which requires that the user has&lt;br&gt;
&gt; the specific key file generated for a message rather than the password,&lt;br&gt;
&gt; specifically this software generates a unique key file for a specific&lt;br&gt;
&gt; message every time a message is created. The user then enters the date and&lt;br&gt;
&gt; time the message was created. Without the original key file the message&lt;br&gt;
&gt; can't be opened;&lt;br&gt;
&gt;&lt;br&gt;
&gt; &lt;a href="https://www.youtube.com/watch?v=R0W7OVdNrOA" rel="noreferrer \
noreferrer" target="_blank"&gt;https://www.youtube.com/watch?v=R0W7OVdNrOA&lt;/a&gt;&lt;br&gt; \
&gt;&lt;br&gt; &gt; Here is a video showing the software. I've built it for Windows and \
Mac OS.&lt;br&gt; &gt; I was wondering if this could be implemented in tor. I think it \
would be an&lt;br&gt; &gt; interesting idea for a tor based email system to make the \
messages&lt;br&gt; &gt; unrecoverable after use.&lt;br&gt;
&lt;br&gt;
I'm not a tor-dev, so I can't comment on the interest, but it appears to&lt;br&gt;
me that the value added of this idea (basically, using time to seed a&lt;br&gt;
PRF/KDF) is very little. All in all, using time to seed keys is not the&lt;br&gt;
best idea. It also seems to be on top of PGP, so I'm pretty convinced&lt;br&gt;
this doesn't provide perfect forward-secrecy unless you're layering any&lt;br&gt;
sort of session key ratcheting mechanism yourself.&lt;br&gt;
&lt;br&gt;
I think the goal is laudable, but I suggest getting a little bit more&lt;br&gt;
involved in cryptography engineering communities to see learn, develop&lt;br&gt;
and eventually help change the status quo.&lt;br&gt;
&lt;br&gt;
Cheers!&lt;br&gt;
-S&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" target="_blank" \
rel="noreferrer"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" target="_blank" \
rel="noreferrer"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201124074259</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2020-11-24 07:42:59-0400</timestampReceived><subject>Re: [tor-dev] Tor Browser 10.0.5 not functional on Fedora Rawhide</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Ian Laurie:
&gt; Regular Firefox became briefly non-functional on Fedora Rawhide due to
&gt; the following (now resolved) bug:
&gt; 
&gt; https://bugzilla.redhat.com/show_bug.cgi?id=1891234
&gt; 
&gt; The issue was that all tabs immediately crashed making the browser
&gt; unusable.   I believe Tor is now suffering from the same issue.
&gt; 

This is a known bug in Firefox's current ESR which Tor Browser is based
on. We have a ticket[1] for it in our bug tracker, too.

That said, we plan to pick the Firefox fix up with the next release.
That one is currently planned for 12/15[2].

Georg

[1]
https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/40226
[2]
https://gitlab.torproject.org/tpo/applications/tor-browser/-/wikis/Release-Schedule


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201124094440</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-11-24 09:44:40-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

On 2020-11-23 16:49, George Kadianakis wrote:
&gt; Karsten Loesing &lt;karsten@torproject.org&gt; writes:
&gt; 
&gt; &gt; On 2020-11-03 17:16, Karsten Loesing wrote:
&gt; &gt; &gt; On 2020-11-03 15:01, George Kadianakis wrote:
&gt; &gt; &gt; &gt; Hello Karsten,
&gt; &gt; &gt; 
&gt; &gt; &gt; Hi George!
&gt; &gt; 
&gt; &gt; Hi again!
&gt; &gt; 
&gt; &gt; &gt; &gt; hope you are doing well!
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; I've been working on the S61 performance experiments [0] and I would \
&gt; &gt; &gt; &gt; appreciate some help with onionperf.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; I have done various onionperf measurements using something the following \
&gt; &gt; &gt; &gt; command: $ onionperf measure -i --tgen ~/tgen/build/src/tgen --tor \
&gt; &gt; &gt; &gt; ~/onionperf/tor/src/app/tor --drop-guards 10 
&gt; &gt; &gt; &gt; I put each of the measurements on a different directory and now I want
&gt; &gt; &gt; &gt; to analyze them and derive the CDF-TTFB graphs etc. I attempted doing
&gt; &gt; &gt; &gt; that using the following calls:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; $ onionperf analyze --tgen ./tgen-client/onionperf.tgen.log --torctl \
&gt; &gt; &gt; &gt; ./tor-client/onionperf.torctl.log $ onionperf visualize --data \
&gt; &gt; &gt; &gt; onionperf.analysis.json.xz "test" 
&gt; &gt; &gt; &gt; Unfortunately, the 'visualize' call can fail for the attached \
&gt; &gt; &gt; &gt; 'onionperf-mbps.json.xz': 
&gt; &gt; &gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; &gt; &gt; 2020-11-03 15:51:31 1604411491.540736 [onionperf] [INFO] loading analysis \
&gt; &gt; &gt; &gt; results from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz \
&gt; &gt; &gt; &gt; 2020-11-03 15:51:31 1604411491.577864 [onionperf] [INFO] done! 2020-11-03 \
&gt; &gt; &gt; &gt; 15:51:31 1604411491.586845 [onionperf] [INFO] NumExpr defaulting to 8 \
&gt; &gt; &gt; &gt;                 threads.
&gt; &gt; &gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; &gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt; &gt; &gt;                 singular transformations; automatically expanding.
&gt; &gt; &gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; &gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt; &gt; &gt; singular transformations; automatically expanding. Traceback (most recent \
&gt; &gt; &gt; &gt; call last): File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; &gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; &gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, \
&gt; &gt; &gt; &gt; in run_script exec(script_code, namespace, namespace)
&gt; &gt; &gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; &gt; line 382, in main File \
&gt; &gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; &gt; line 522, in visualize File \
&gt; &gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; &gt; line 48, in plot_all File \
&gt; &gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; &gt; line 205, in __plot_throughput_ecdf File \
&gt; &gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; &gt; line 235, in __draw_ecdf File \
&gt; &gt; &gt; &gt; "/usr/lib/python3/dist-packages/pandas/core/frame.py", line 5000, in dropna \
&gt; &gt; &gt; &gt;                 raise KeyError(list(np.compress(check, subset)))
&gt; &gt; &gt; &gt; KeyError: ['mbps']
&gt; &gt; &gt; 
&gt; &gt; &gt; Indeed, that's a bug in the visualize mode.
&gt; &gt; &gt; 
&gt; &gt; &gt; However, before it fails it writes a .csv file that tells us why: none
&gt; &gt; &gt; of the measurements are successful! I'm seeing lots of TOR/CANT_ATTACH
&gt; &gt; &gt; errors in that file. There's something wrong in your measurement setup.
&gt; &gt; &gt; If you fix that, you'll be able to visualize the results.
&gt; &gt; 
&gt; &gt; Did you figure out what went wrong? Do you need help figuring that out?
&gt; &gt; 
&gt; &gt; &gt; (We should still fix the bug and produce a nicer error message.)
&gt; &gt; 
&gt; &gt; I'm going to file an issue and start working on a possible fix tomorrow.
&gt; &gt; 
&gt; &gt; All the best,
&gt; &gt; Karsten
&gt; &gt; 
&gt; 
&gt; Hey hey Karsten,

Hello!

&gt; yes there was an issue with the port forwarding (or the incoming IP
&gt; addr) and tgen could not do its thing, and I didn't realize because
&gt; there were not any errors exposed to this effect.

Understood. I'm not sure how to make it easier to spot configuration
errors like this in the future. In fact, we had a very similar problem
with one of the long-running instances, op-hk5, and it took us two weeks
to figure that out. I just opened a issue to discuss possible fixes:

https://gitlab.torproject.org/tpo/metrics/onionperf/-/issues/40011

I also opened an issue to avoid the tracebacks you ran into in the future:

https://gitlab.torproject.org/tpo/metrics/onionperf/-/issues/40012

&gt; In any case, I fixed this and then onionperf worked just fine. For
&gt; example see here https://gitlab.torproject.org/tpo/core/tor/-/issues/40157#note_2714605
&gt;  
&gt; So no worries about this, it's all good on this front.
&gt; 
&gt; Also onionperf has been perfoming just fine in general for the purposes
&gt; of #40157 so far.

Awesome! Please let me know if there's anything else causing trouble. Or
just open an issue.

&gt; Cheers!
&gt; (and welcome back (?))

Yes, I'm back!

Cheers!
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201127144636</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-11-27 14:46:36-0400</timestampReceived><subject>Re: [tor-dev] Resolving TXT records</subject><body>

Jorropo:
&gt; Is this expected or I am doing something wrong?

Have a look at the documentation of DNSPort:
https://2019.www.torproject.org/docs/tor-manual.html.en#DNSPort

Tor's DNSPort is rather limited, 
if you need more I recommend to 
use an encrypted DNS protocol like DNS-over-TLS or DNS-over-HTTPS
and route that over Tor, but be aware that your DNS resolution requests
are linkable if you do not establish a new stream and connection for each resolution attempt.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201008185041</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-10-08 18:50:41-0400</timestampReceived><subject>Re: [tor-dev] Update to Proposal 316: FlashFlow</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Sorry I had other things to juggle after the meeting. Did not have time
to update pad. Adding some additional things we touched on below.

On 10/8/20 1:34 PM, Nick Mathewson wrote:
&gt; 
&gt; Hi!  We had a meeting about FlashFlow today, including several of the
&gt; authors.  Here are the notes we wound up with for ideas and next
&gt; straps.
&gt; 
&gt; Easy changes:
&gt;     * Just use a PRNG; assume we can make them arbitrarily fast.
&gt; (example candidates: chacha8, shake128.)
&gt;     * Use relay identities as the identifiers for measurers, so that
&gt; we won't need a novel authentication scheme.
&gt;     * We can't call the list of measurer IDs a "network parameter",
&gt; since technically speaking network parameters have to be integers.  It
&gt; will have to be a different part of the consensus header.
&gt;     * Make sure that all of the declared ranges for network parameters
&gt; are as wide as they could possibly be; making these parameters take a
&gt; wider range is hard to change later.
&gt; 
&gt; Trickier but straightforward:
&gt;     * Describe how to avoid collisions with multiple coordinators
&gt;        - idea: exactly how it's specified in the paper ;) but a
&gt; simplier idea ...
&gt;        - idea: coord 1 measurers on day 1, c2 on d2, ... etc. for all
&gt; coords, then repeat
&gt;     * Describe how to aggregate all background measurements over the
&gt; full 30 seconds, and how to use that data.  (This may lower accuracy a
&gt; little, but makes some kinds of the analysis harder.) Idea: relay
&gt; reports *once* at end of measurement the total amount of bg traffic
&gt; and the coord simply divides that by the length of the measurement to
&gt; have a per-second average.
&gt;     * Mention whether relays should reserve sockets in case they get measured
&gt; 
&gt; More thinking may be needed:
&gt;     *  Summarize ideas for how multiple coordinators don't have to
&gt; share full schedules with one another. Possibly divide up the network
&gt; by days? [e.g., Coordinator 1 measures nodes in set X on Monday]
&gt;     * Would it work if we declare a maximum measurement fraction (eg
&gt; 75% of bandwidth) but measurers only use that fraction in a few
&gt; measurements once in a while, and mostly they do less (eg 10% of
&gt; bandwidth).
      * Find ways we may use sbws and/or network utilization to devcide
        on a safe flashflow measurement level that does not introduce
        traffic analysis side channels.
&gt;     * Discuss migration: how do we use this data when not all relays
&gt; support being measured in this way?

&gt; 
&gt; 
&gt; In terms of implementation:
&gt; - identify the python parts that are different to sbws, create sbws
&gt; subpackages "ff measurer" and "ff coordinator" and add a config option
&gt; to run in 1 mode or other, to do not have yet another code base to
&gt; maintain
&gt; 
&gt; In terms of deployment:
&gt; - we currently don't have any automatic way to ensure net is still
&gt; "working properly", only some mostly-manual ways and some one-time
&gt; experiments. This has caused some relay operators to do not be happy
&gt; and some quite time to figure out the problem and solve it
&gt; 
&gt; In terms of coordination:
&gt; We're deploying sbws only 1 dirauth at a time and trying to ensure net
&gt; is still "working properly".
&gt; If we deploy ff, before we have deployed sbws in all bwauths and
&gt; ensure net is still "working properly", will be hard to see what is an
&gt; sbws bug or ff one or both

In particular here, I want to run some additional live experiments to
ensure that long tail perf is improved:

https://gitlab.torproject.org/tpo/metrics/analysis/-/issues/33076#note_2569011
   aka
   https://trac.torproject.org/projects/tor/ticket/33076#comment:23

I do not yet have confidence that these issues are solved simply because
they did not appear in Shadow. Shadow does not simulate multi-instance
relays, CPU bound relays, or structural load imbalances in the network.

For this reason I think we should look for deployment strategies that
enable us to test a combination of Rob's experiment, Flashflow, and
sbws, in live testing (even if only for week-long periods of test).

This way we can confirm these bugs and develop fixes for these issues
before we wait for the whole network to upgrade to Flashflow, only to
realize it still has problems that make its tail worse than sbws.

&gt; FlashFlow, the python code for coordinator, measurer, etc.
&gt; https://gitlab.torproject.org/pastly/flashflow
&gt; 
&gt; The rendered documentation for/from the above https://flashflow.pastly.xyz/
&gt; 
&gt; Tor repo with branch https://gitlab.torproject.org/pastly/tor/-/tree/ff-v2
&gt; 
&gt; The ticket with the concerning graphs attributable to "Rob's speedtest thing"
&gt; https://trac.torproject.org/projects/tor/ticket/33076


-- 
Mike Perry


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201017234243</emailId><senderName></senderName><senderEmail>"jansen, robert g civ usn nrl (5543) washington dc (usa)" &lt;rob.g.jansen</senderEmail><timestampReceived>2020-10-17 23:42:43-0400</timestampReceived><subject>[tor-dev] Improving Tor network models [was: Update to Proposal 316: FlashFlow]</subject><body>

&gt; 
&gt; On Oct 8, 2020, at 2:50 PM, Mike Perry &lt;mikeperry@torproject.org&gt; wrote:
&gt; 
&gt; I do not yet have confidence that these issues are solved simply because
&gt; they did not appear in Shadow. Shadow does not simulate multi-instance
&gt; relays, CPU bound relays, or structural load imbalances in the network.

Hi Mike and others!

I'd like to better understand your criticisms here so that we can work to make Shadow \
more useful (work that fits squarely under sponsor 38).

&gt; multi-instance relays

Nothing prevents Shadow from running multiple tor relay processes on the same virtual \
host. We could add this to the Tor models that are created by our model generation \
tool[0].

One issue is that we don't have ground truth about:
- which relays are co-resident with one another; and
- the capacity of the machine hosting the co-resident relays.

A short term fix could be that we look at relays in the same family, and randomly \
choose some of them to run on the same machine (setting the capacity of the machine \
as the sum of max observed bandwidth of the co-resident relays). A longer term \
solution would be to add a new parameter similar to MyFamily and ask operators to \
identify which relays are co-resident, or add to tor a self-measurement of \
co-residency - and that would provide the ground truth we would need for accurate \
modeling.

Thoughts? Any other ideas?

&gt; CPU-bound relays

There are two issues here:
- we need to improve/rewrite our virtual CPU module in Shadow that accounts for CPU \
                load; and
- we need ground truth about the number of CPUs and CPU speeds for each relay.

The first one is relatively straightforward to resolve, the second one again requires \
some form of self-reporting or automated self-measurement in tor.

&gt; structural load imbalances

Could you please explain this one in a couple more sentences?

By 'structural' I think you might mean imbalances across relay positions (i.e., more \
guard bandwidth and less exit bandwidth). If so, then Shadow does already properly \
account for this by statically assigning flags using the TestingDirAuthVoteExit and \
TestingDirAuthVoteGuard torrc options.

Here are some bonus ones for you:

&gt; capacity of relays

We currently use the maximum observed bandwidth that we've seen for a relay and set \
that value as the network link capacity of the (virtual) host machine that runs reach \
relay. Again, we don't have any ground truth of how much capacity is available to \
each relay, though maybe someday FlashFlow will collect it for us.

&gt; diversity of Tor versions

We should make sure our modeling tool includes relays across different versions of \
Tor, since not all relays in the public network run the same version. This one is \
pretty simple to fix (it just requires us to build Tor plugins multiple different Tor \
source versions) but research that is testing how a new idea performs across the \
network by modifying Tor source will obviously need to use their custom research \
version of Tor.

Peace, love, and positivity,
Rob

[0] https://github.com/shadow/tornetgen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201018202340</emailId><senderName></senderName><senderEmail>"jansen, robert g civ usn nrl (5543) washington dc (usa)" &lt;rob.g.jansen</senderEmail><timestampReceived>2020-10-18 20:23:40-0400</timestampReceived><subject>Re: [tor-dev] Statistical inference in live network perf experiments</subject><body>

Hi Mike,

So I just read your mail in the "Initial ideas from the culture/VPN thread" where you \
state:

&gt; The core problem: People who do not have time to monitor the full workflow of other \
&gt; groups and get properly involved in them should not randomly interject to demand \
&gt; things that are already documented in tickets, public list posts, proposals, wiki \
&gt; pages, meetings, and irc discussion.

I feel like I have done exactly that in my previous mail below, and I sincerely \
apologize. I agree with you, random interjections from the uninformed likely cause \
more harm than good, so I should just stay out of it.

We _are_ working on the topic of statistical inference, but I'm sure you already have \
a solid plan, so please just ignore my noise.

Again, I am truly sorry, and I'll try not to make this mistake again.

Peace, love, and positivity,
Rob

&gt; On Oct 17, 2020, at 7:43 PM, Jansen, Robert G CIV USN NRL (5543) Washington DC \
&gt; (USA) &lt;rob.g.jansen@nrl.navy.mil&gt; wrote: 
&gt; Hello Mike and David!
&gt; 
&gt; I see that we are in the process of testing some changes to KIST parameters, and \
&gt; have more upcoming perf experiments planned. It will be great to gather additional \
&gt; information to help us better understand how to improve Tor performance :) 
&gt; My main concern about running experiments on the live network is the lack of \
&gt; control [0] across the uncountable number of confounding variables present across \
&gt; the network. 
&gt; Because of the lack of control, I strongly advise that statistical inference \
&gt; techniques are applied when conducting the experiments and analyzing the results. \
&gt; Ideally you will estimate and quantify sources of systematic error. Repeated trials \
&gt; and A/B testing (when that makes sense) will help increase our confidence in your \
&gt; results. 
&gt; We have some recent work on these topics (in submission). DM if you are interested \
&gt; in a copy of the paper. 
&gt; Peace, love, and positivity,
&gt; Rob
&gt; 
&gt; [0] https://en.wikipedia.org/wiki/Scientific_control

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200907114909</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2020-09-07 11:49:09-0400</timestampReceived><subject>Re: [tor-dev] CAPTCHA Monitoring Project Final Report</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Gaba:
&gt; El 8/31/20 a las 9:22 AM, Barkin Simsek escribi:
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; The end of the Google Summer of Code period has arrived, and you can
&gt;&gt; find my GSoC final report for the CAPTCHA Monitoring project here [1].
&gt;&gt; This was my first time working with an active open source community
&gt;&gt; and I enjoyed it a lot! The feedback you have provided made the
&gt;&gt; experience worthwhile and exciting. I couldn't finish implementing all
&gt;&gt; of the features I planned, so I will be around and I plan to stay
&gt;&gt; active. I want to thank my mentors GeKo &amp; arma and everyone who helped
&gt;&gt; me with the project!
&gt;&gt;
&gt;&gt; Best,
&gt;&gt; Barkin
&gt; 
&gt; 
&gt; Thanks so much for the great work you did!

Indeed, I'd like to second that. It's been a pleasure working with you
during the GSoC time and I hope you stick around. :)

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200917163748</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-09-17 16:37:48-0400</timestampReceived><subject>Re: [tor-dev] Update to Proposal 316: FlashFlow</subject><body>

On Fri, Sep 4, 2020 at 8:26 AM Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt;
&gt; Hi all
&gt;
&gt; I polished up the FlashFlow proposal based on the feedback provided by
&gt; Teor, Nick, and Mike. I converted it to markdown, and pasted the new
&gt; text at the bottom of this email. The updated proposal is also in my
&gt; fork of torspec is on gitlab [0]; the branch with the changes is
&gt; "flashflow-revision".

Merged to torspec.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200917203611</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-09-17 20:36:11-0400</timestampReceived><subject>Re: [tor-dev] proposal for "tor-relay" well-known URI</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Nick Mathewson:
&gt; This is now proposal 326.

Thanks!

Please let me know if you have any comments on this proposal:
https://github.com/torproject/torspec/blob/master/proposals/326-tor-relay=
-well-known-uri-rfc8615.md

Nathaniel Wesley Filardo (Microsoft Research) left a comment on the githu=
b merge request [1].

The goal is to move the IANA registration [2] for "tor-relay" forward aft=
er the prop 326 reached the "accepted" status [3]
so I'm curious to learn about any showstopper for the accepted status. Th=
is proposal is probably a bit different than
others since it does not require any implementation in tor's code.

kind regards,
nusenu

[1] https://github.com/torproject/torspec/pull/129#issuecomment-681194660=

[2] https://github.com/protocol-registries/well-known-uris/issues/8
[3] https://github.com/torproject/torspec/blob/master/proposals/001-proce=
ss.txt


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200917212554</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-09-17 21:25:54-0400</timestampReceived><subject>Re: [tor-dev] new home for trac/CoreTorReleases?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Nick Mathewson:
&gt;&gt; in the past
&gt;&gt; https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/CoreTorReleases
&gt;&gt;
&gt;&gt; used to be the canonical place for tor EoL information.
&gt;&gt; Since Trac is no longer used: Is there a new home for this kind of information?
&gt; 
&gt; https://gitlab.torproject.org/tpo/core/team/-/wikis/NetworkTeam/CoreTorReleases
&gt; is the new place.

thanks!


&gt; Thanks, this is quite helpful!  Is it okay if I add links to these
&gt; from the wiki page?

sure.
 



["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200925111508</emailId><senderName>tevador</senderName><senderEmail>tevador@gmail.com</senderEmail><timestampReceived>2020-09-25 11:15:08-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

On Tue, Sep 22, 2020 at 2:10 PM George Kadianakis &lt;desnacked@riseup.net&gt; wrote:
&gt;
&gt; if you have a GPU-enabled box, so that we can get some benchmarks
&gt; from GPUs as well
&gt;

Someone would have to write a GPU benchmark for that. My code is CPU-only.

&gt;
&gt;   tevador do you have the graphing code somewhere so that I can run the
&gt;   experiments again and see how the graphs are influenced?
&gt;

I've uploaded the gnuplot script I used to generate the graphs here:
https://github.com/tevador/scratchpad/blob/master/tor-pow/effort_sim.plt

You will need to modify the script with your path to the simulation output file.

On Thu, Sep 24, 2020 at 6:54 PM Jim Newsome &lt;jnewsome@torproject.org&gt; wrote:
&gt;
&gt; I stumbled across some weird artifacts when using more threads than
&gt; processors: the benchmark reports solutions/sec continuing to increase
&gt; linearly with #threads. The wall-clock time for the benchmark itself
&gt; (measured with `time`) show the expected trend though of linear scaling
&gt; only up to 4 (the number of physical cores), a little bump at 8 (using
&gt; the hyperthreaded virtual cores), and no improvement past that.
&gt;

Good catch. There was a bug in the time measurement code in the
benchmark. Should be fixed now in the master branch.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200930182328</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2020-09-30 18:23:28-0400</timestampReceived><subject>Re: [tor-dev] When are you going to update the package?</subject><body>

On Tue, Sep 29, 2020 at 09:08:18PM -0700, xpathcss@secmail.pro wrote:
&gt; 
&gt; Package: tor
&gt; Version: 0.4.2.7-1~d10.buster+1
&gt; 
&gt; 
&gt; deb.torproject.org/torproject.org/dists/buster/main/binary-amd64/Packages
&gt; 
&gt; Package: tor
&gt; Version: 0.4.4.5-1~d10.buster+1
&gt; 
&gt; &gt; deb https://deb.torproject.org/torproject.org buster main
&gt; 
&gt; Have you abandoned "armhf"?

Yes, correct. See
https://lists.torproject.org/pipermail/tor-talk/2020-May/045582.html
https://lists.torproject.org/pipermail/tor-talk/2020-May/045583.html

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200806193549</emailId><senderName>"procmem () riseup ! net"</senderName><senderEmail>procmem@riseup.net</senderEmail><timestampReceived>2020-08-06 19:35:49-0400</timestampReceived><subject>[tor-dev] Connection padding set to 1 vs auto</subject><body>

Hi. I was wondering if setting the connection padding setting in torrc

to 1 instead of auto has any benefit in protecting against a passive
adversary outside the Tor network.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201103140133</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-11-03 14:01:33-0400</timestampReceived><subject>[tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

Hello Karsten,

hope you are doing well!

I've been working on the S61 performance experiments [0] and I would appreciate
some help with onionperf.

I have done various onionperf measurements using something the following command:
  $ onionperf measure -i --tgen ~/tgen/build/src/tgen --tor \
~/onionperf/tor/src/app/tor --drop-guards 10

I put each of the measurements on a different directory and now I want
to analyze them and derive the CDF-TTFB graphs etc. I attempted doing
that using the following calls:

 $ onionperf analyze --tgen ./tgen-client/onionperf.tgen.log --torctl \
./tor-client/onionperf.torctl.log  $ onionperf visualize --data \
onionperf.analysis.json.xz "test"

Unfortunately, the 'visualize' call can fail for the attached \
'onionperf-mbps.json.xz':

  $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
  2020-11-03 15:51:31 1604411491.540736 [onionperf] [INFO] loading analysis results \
from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz  2020-11-03 15:51:31 \
1604411491.577864 [onionperf] [INFO] done!  2020-11-03 15:51:31 1604411491.586845 \
[onionperf] [INFO] NumExpr defaulting to 8 threads.  \
/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
UserWarning: Attempting to set identical left == right == -1e-06 results in singular \
transformations; automatically expanding.  \
/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
UserWarning: Attempting to set identical left == right == -1e-06 results in singular \
transformations; automatically expanding.  Traceback (most recent call last):
    File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
      __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
    File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
run_script  self.require(requires)[0].run_script(script_name, ns)
    File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
run_script  exec(script_code, namespace, namespace)
    File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 622, in &lt;module&gt;  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 382, in main  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 522, in visualize  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 48, in plot_all  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 205, in __plot_throughput_ecdf  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 235, in __draw_ecdf  File "/usr/lib/python3/dist-packages/pandas/core/frame.py", \
line 5000, in dropna  raise KeyError(list(np.compress(check, subset)))
  KeyError: ['mbps']

Then for another onionperf run (attached as 'onionperf-44028.json.xz') it gave me a \
different error:

  $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
  2020-11-03 15:50:03 1604411403.946028 [onionperf] [INFO] loading analysis results \
from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz  2020-11-03 15:50:03 \
1604411403.976088 [onionperf] [INFO] done!  Traceback (most recent call last):
    File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
      __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
    File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
run_script  self.require(requires)[0].run_script(script_name, ns)
    File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
run_script  exec(script_code, namespace, namespace)
    File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 622, in &lt;module&gt;  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 382, in main  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 522, in visualize  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 38, in plot_all  File \
"/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 129, in __extract_data_frame  KeyError: '44028'

Because of the two errors above I'm unable to proceed with producing any
results.  Any idea what I might be doing wrong? Is there any other data
you might need to help me with this?

Thanks a lot!

[0]: https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceExperiments
  https://gitlab.torproject.org/tpo/core/tor/-/issues/40157


["onionperf-mbps.json.xz" (application/x-xz)]
["onionperf-44028.json.xz" (application/x-xz)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201126153640</emailId><senderName>Jorropo</senderName><senderEmail>jorropo.pgm@gmail.com</senderEmail><timestampReceived>2020-11-26 15:36:40-0400</timestampReceived><subject>[tor-dev] Resolving TXT records</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

I'm trying to port go-libp2p &lt;https://libp2p.io/&gt; on tor.
The problem is with the dnslink features. Basically libp2p addresses are
not always friendly to use so libp2p allows to store them in dns TXT
records.

But when I try to resolve a TXT record over Tor this errors :

tor --DNSPort 127.53.53.53 &amp;
host -v -t any jorropo.net
Trying "jorropo.net"
;; Connection to 127.53.53.53#53(127.53.53.53) for jorropo.net failed:
connection refused.
# I'm pretty confident the dns option of Tor is working because I can
resolve A records.

Is this expected or I am doing something wrong?

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;&lt;div&gt;Hi,&lt;br&gt;&lt;br&gt;&lt;/div&gt;I'm trying to port &lt;a \
href="https://libp2p.io/"&gt;go-libp2p&lt;/a&gt; on tor.&lt;br&gt;&lt;/div&gt;&lt;div&gt;The problem is with the \
dnslink features. Basically libp2p addresses are not always friendly to use so libp2p \
allows to store them in dns TXT records.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;But when I try to \
resolve a TXT record over Tor this errors :&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;tor \
--DNSPort 127.53.53.53 &amp;&lt;br&gt;&lt;/div&gt;&lt;div&gt;host -v -t any &lt;a \
href="http://jorropo.net"&gt;jorropo.net&lt;/a&gt;&lt;br&gt;Trying "&lt;a \
href="http://jorropo.net"&gt;jorropo.net&lt;/a&gt;"&lt;br&gt;;; Connection to \
127.53.53.53#53(127.53.53.53) for &lt;a href="http://jorropo.net"&gt;jorropo.net&lt;/a&gt; \
failed: connection refused.&lt;br&gt;&lt;/div&gt;&lt;div&gt;# I'm pretty confident the dns option \
of Tor is working because I can resolve A records.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is \
this expected or I am doing something wrong?&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201103161606</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-11-03 16:16:06-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

On 2020-11-03 15:01, George Kadianakis wrote:
&gt; Hello Karsten,

Hi George!

&gt; hope you are doing well!
&gt; 
&gt; I've been working on the S61 performance experiments [0] and I would appreciate
&gt; some help with onionperf.
&gt; 
&gt; I have done various onionperf measurements using something the following command:
&gt; $ onionperf measure -i --tgen ~/tgen/build/src/tgen --tor \
&gt; ~/onionperf/tor/src/app/tor --drop-guards 10 
&gt; I put each of the measurements on a different directory and now I want
&gt; to analyze them and derive the CDF-TTFB graphs etc. I attempted doing
&gt; that using the following calls:
&gt; 
&gt; $ onionperf analyze --tgen ./tgen-client/onionperf.tgen.log --torctl \
&gt; ./tor-client/onionperf.torctl.log $ onionperf visualize --data \
&gt; onionperf.analysis.json.xz "test" 
&gt; Unfortunately, the 'visualize' call can fail for the attached \
&gt; 'onionperf-mbps.json.xz': 
&gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; 2020-11-03 15:51:31 1604411491.540736 [onionperf] [INFO] loading analysis results \
&gt; from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 15:51:31 \
&gt; 1604411491.577864 [onionperf] [INFO] done! 2020-11-03 15:51:31 1604411491.586845 \
&gt;                 [onionperf] [INFO] NumExpr defaulting to 8 threads.
&gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt;                 singular transformations; automatically expanding.
&gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; singular transformations; automatically expanding. Traceback (most recent call \
&gt; last): File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; run_script exec(script_code, namespace, namespace)
&gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 622, in &lt;module&gt; File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 382, in main File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 522, in visualize File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; line 48, in plot_all File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; line 205, in __plot_throughput_ecdf File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; line 235, in __draw_ecdf File \
&gt; "/usr/lib/python3/dist-packages/pandas/core/frame.py", line 5000, in dropna raise \
&gt;                 KeyError(list(np.compress(check, subset)))
&gt; KeyError: ['mbps']

Indeed, that's a bug in the visualize mode.

However, before it fails it writes a .csv file that tells us why: none
of the measurements are successful! I'm seeing lots of TOR/CANT_ATTACH
errors in that file. There's something wrong in your measurement setup.
If you fix that, you'll be able to visualize the results.

(We should still fix the bug and produce a nicer error message.)

&gt; Then for another onionperf run (attached as 'onionperf-44028.json.xz') it gave me a \
&gt; different error: 
&gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; 2020-11-03 15:50:03 1604411403.946028 [onionperf] [INFO] loading analysis results \
&gt; from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 15:50:03 \
&gt; 1604411403.976088 [onionperf] [INFO] done! Traceback (most recent call last):
&gt; File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; run_script exec(script_code, namespace, namespace)
&gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 622, in &lt;module&gt; File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 382, in main File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 522, in visualize File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; line 38, in plot_all File \
&gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt;                 line 129, in __extract_data_frame
&gt; KeyError: '44028'
&gt; 
&gt; Because of the two errors above I'm unable to proceed with producing any
&gt; results.  Any idea what I might be doing wrong? Is there any other data
&gt; you might need to help me with this?

In this case it's failing even before writing a CSV file. Still, when
looking at the .xz file I'm seeing only errors, too, so it's a related
issue here.

&gt; Thanks a lot!
&gt; 
&gt; [0]: https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceExperiments
&gt;  https://gitlab.torproject.org/tpo/core/tor/-/issues/40157

Hope this helps!

All the best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200917204952</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-09-17 20:49:52-0400</timestampReceived><subject>[tor-dev] new home for trac/CoreTorReleases?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

in the past 
https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/CoreTorReleases

used to be the canonical place for tor EoL information. 
Since Trac is no longer used: Is there a new home for this kind of information?

@Nick:
In the past, before rejecting eol versions you asked about 
the current state on the tor network, the following new table
will now provide you with a list of operators (more precisely ContactInfos)
by clicking on the CW column you can get it sorted by consensus weight
to find the biggest affected operators running eol releases:

https://nusenu.github.io/OrNetStats/#tor-version-distribution-relays
https://nusenu.github.io/OrNetStats/#end-of-life-relays-share


kind regards,
nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200930040818</emailId><senderName></senderName><senderEmail>xpathcss</senderEmail><timestampReceived>2020-09-30 04:08:18-0400</timestampReceived><subject>[tor-dev] When are you going to update the package?</subject><body>

deb.torproject.org/torproject.org/dists/buster/main/binary-armhf/Packages

Package: tor
Version: 0.4.2.7-1~d10.buster+1


deb.torproject.org/torproject.org/dists/buster/main/binary-amd64/Packages

Package: tor
Version: 0.4.4.5-1~d10.buster+1

&gt; deb https://deb.torproject.org/torproject.org buster main

Have you abandoned "armhf"?



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200917212142</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-09-17 21:21:42-0400</timestampReceived><subject>Re: [tor-dev] new home for trac/CoreTorReleases?</subject><body>

On Thu, Sep 17, 2020 at 4:50 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; in the past
&gt; https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/CoreTorReleases
&gt;
&gt; used to be the canonical place for tor EoL information.
&gt; Since Trac is no longer used: Is there a new home for this kind of information?

https://gitlab.torproject.org/tpo/core/team/-/wikis/NetworkTeam/CoreTorReleases
is the new place.

&gt; @Nick:
&gt; In the past, before rejecting eol versions you asked about
&gt; the current state on the tor network, the following new table
&gt; will now provide you with a list of operators (more precisely ContactInfos)
&gt; by clicking on the CW column you can get it sorted by consensus weight
&gt; to find the biggest affected operators running eol releases:
&gt;
&gt; https://nusenu.github.io/OrNetStats/#tor-version-distribution-relays
&gt; https://nusenu.github.io/OrNetStats/#end-of-life-relays-share

Thanks, this is quite helpful!  Is it okay if I add links to these
from the wiki page?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201123152554</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-11-23 15:25:54-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

On 2020-11-03 17:16, Karsten Loesing wrote:
&gt; On 2020-11-03 15:01, George Kadianakis wrote:
&gt; &gt; Hello Karsten,
&gt; 
&gt; Hi George!

Hi again!

&gt; &gt; hope you are doing well!
&gt; &gt; 
&gt; &gt; I've been working on the S61 performance experiments [0] and I would appreciate
&gt; &gt; some help with onionperf.
&gt; &gt; 
&gt; &gt; I have done various onionperf measurements using something the following command:
&gt; &gt; $ onionperf measure -i --tgen ~/tgen/build/src/tgen --tor \
&gt; &gt; ~/onionperf/tor/src/app/tor --drop-guards 10 
&gt; &gt; I put each of the measurements on a different directory and now I want
&gt; &gt; to analyze them and derive the CDF-TTFB graphs etc. I attempted doing
&gt; &gt; that using the following calls:
&gt; &gt; 
&gt; &gt; $ onionperf analyze --tgen ./tgen-client/onionperf.tgen.log --torctl \
&gt; &gt; ./tor-client/onionperf.torctl.log $ onionperf visualize --data \
&gt; &gt; onionperf.analysis.json.xz "test" 
&gt; &gt; Unfortunately, the 'visualize' call can fail for the attached \
&gt; &gt; 'onionperf-mbps.json.xz': 
&gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; 2020-11-03 15:51:31 1604411491.540736 [onionperf] [INFO] loading analysis results \
&gt; &gt; from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 15:51:31 \
&gt; &gt; 1604411491.577864 [onionperf] [INFO] done! 2020-11-03 15:51:31 1604411491.586845 \
&gt; &gt;                 [onionperf] [INFO] NumExpr defaulting to 8 threads.
&gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt;                 singular transformations; automatically expanding.
&gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt; singular transformations; automatically expanding. Traceback (most recent call \
&gt; &gt; last): File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; &gt; run_script exec(script_code, namespace, namespace)
&gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 382, in main File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 522, in visualize File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; line 48, in plot_all File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; line 205, in __plot_throughput_ecdf File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; line 235, in __draw_ecdf File \
&gt; &gt; "/usr/lib/python3/dist-packages/pandas/core/frame.py", line 5000, in dropna raise \
&gt; &gt;                 KeyError(list(np.compress(check, subset)))
&gt; &gt; KeyError: ['mbps']
&gt; 
&gt; Indeed, that's a bug in the visualize mode.
&gt; 
&gt; However, before it fails it writes a .csv file that tells us why: none
&gt; of the measurements are successful! I'm seeing lots of TOR/CANT_ATTACH
&gt; errors in that file. There's something wrong in your measurement setup.
&gt; If you fix that, you'll be able to visualize the results.

Did you figure out what went wrong? Do you need help figuring that out?

&gt; (We should still fix the bug and produce a nicer error message.)

I'm going to file an issue and start working on a possible fix tomorrow.

All the best,
Karsten


&gt; 
&gt; &gt; Then for another onionperf run (attached as 'onionperf-44028.json.xz') it gave me \
&gt; &gt; a different error: 
&gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; 2020-11-03 15:50:03 1604411403.946028 [onionperf] [INFO] loading analysis results \
&gt; &gt; from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 15:50:03 \
&gt; &gt; 1604411403.976088 [onionperf] [INFO] done! Traceback (most recent call last):
&gt; &gt; File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; &gt; run_script exec(script_code, namespace, namespace)
&gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 382, in main File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 522, in visualize File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; line 38, in plot_all File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt;                 line 129, in __extract_data_frame
&gt; &gt; KeyError: '44028'
&gt; &gt; 
&gt; &gt; Because of the two errors above I'm unable to proceed with producing any
&gt; &gt; results.  Any idea what I might be doing wrong? Is there any other data
&gt; &gt; you might need to help me with this?
&gt; 
&gt; In this case it's failing even before writing a CSV file. Still, when
&gt; looking at the .xz file I'm seeing only errors, too, so it's a related
&gt; issue here.
&gt; 
&gt; &gt; Thanks a lot!
&gt; &gt; 
&gt; &gt; [0]: https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceExperiments
&gt; &gt;  https://gitlab.torproject.org/tpo/core/tor/-/issues/40157
&gt; 
&gt; Hope this helps!
&gt; 
&gt; All the best,
&gt; Karsten
&gt; 

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201123154901</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-11-23 15:49:01-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

Karsten Loesing &lt;karsten@torproject.org&gt; writes:

&gt; On 2020-11-03 17:16, Karsten Loesing wrote:
&gt; &gt; On 2020-11-03 15:01, George Kadianakis wrote:
&gt; &gt; &gt; Hello Karsten,
&gt; &gt; 
&gt; &gt; Hi George!
&gt; 
&gt; Hi again!
&gt; 
&gt; &gt; &gt; hope you are doing well!
&gt; &gt; &gt; 
&gt; &gt; &gt; I've been working on the S61 performance experiments [0] and I would appreciate
&gt; &gt; &gt; some help with onionperf.
&gt; &gt; &gt; 
&gt; &gt; &gt; I have done various onionperf measurements using something the following \
&gt; &gt; &gt; command: $ onionperf measure -i --tgen ~/tgen/build/src/tgen --tor \
&gt; &gt; &gt; ~/onionperf/tor/src/app/tor --drop-guards 10 
&gt; &gt; &gt; I put each of the measurements on a different directory and now I want
&gt; &gt; &gt; to analyze them and derive the CDF-TTFB graphs etc. I attempted doing
&gt; &gt; &gt; that using the following calls:
&gt; &gt; &gt; 
&gt; &gt; &gt; $ onionperf analyze --tgen ./tgen-client/onionperf.tgen.log --torctl \
&gt; &gt; &gt; ./tor-client/onionperf.torctl.log $ onionperf visualize --data \
&gt; &gt; &gt; onionperf.analysis.json.xz "test" 
&gt; &gt; &gt; Unfortunately, the 'visualize' call can fail for the attached \
&gt; &gt; &gt; 'onionperf-mbps.json.xz': 
&gt; &gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; &gt; 2020-11-03 15:51:31 1604411491.540736 [onionperf] [INFO] loading analysis \
&gt; &gt; &gt; results from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 \
&gt; &gt; &gt; 15:51:31 1604411491.577864 [onionperf] [INFO] done! 2020-11-03 15:51:31 \
&gt; &gt; &gt;                 1604411491.586845 [onionperf] [INFO] NumExpr defaulting to 8 \
&gt; &gt; &gt;                 threads.
&gt; &gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt; &gt;                 singular transformations; automatically expanding.
&gt; &gt; &gt; /user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py:251: \
&gt; &gt; &gt; UserWarning: Attempting to set identical left == right == -1e-06 results in \
&gt; &gt; &gt; singular transformations; automatically expanding. Traceback (most recent call \
&gt; &gt; &gt; last): File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; &gt; &gt; run_script exec(script_code, namespace, namespace)
&gt; &gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 382, in main File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 522, in visualize File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; line 48, in plot_all File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; line 205, in __plot_throughput_ecdf File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; line 235, in __draw_ecdf File \
&gt; &gt; &gt; "/usr/lib/python3/dist-packages/pandas/core/frame.py", line 5000, in dropna \
&gt; &gt; &gt;                 raise KeyError(list(np.compress(check, subset)))
&gt; &gt; &gt; KeyError: ['mbps']
&gt; &gt; 
&gt; &gt; Indeed, that's a bug in the visualize mode.
&gt; &gt; 
&gt; &gt; However, before it fails it writes a .csv file that tells us why: none
&gt; &gt; of the measurements are successful! I'm seeing lots of TOR/CANT_ATTACH
&gt; &gt; errors in that file. There's something wrong in your measurement setup.
&gt; &gt; If you fix that, you'll be able to visualize the results.
&gt; 
&gt; Did you figure out what went wrong? Do you need help figuring that out?
&gt; 
&gt; &gt; (We should still fix the bug and produce a nicer error message.)
&gt; 
&gt; I'm going to file an issue and start working on a possible fix tomorrow.
&gt; 
&gt; All the best,
&gt; Karsten
&gt; 

Hey hey Karsten,

yes there was an issue with the port forwarding (or the incoming IP
addr) and tgen could not do its thing, and I didn't realize because
there were not any errors exposed to this effect.

In any case, I fixed this and then onionperf worked just fine. For
example see here https://gitlab.torproject.org/tpo/core/tor/-/issues/40157#note_2714605


So no worries about this, it's all good on this front.

Also onionperf has been perfoming just fine in general for the purposes
of #40157 so far.

Cheers!
(and welcome back (?))

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201202192311</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-12-02 19:23:11-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>


Karsten Loesing &lt;karsten@torproject.org&gt; writes:

&gt; On 2020-11-03 15:01, George Kadianakis wrote:
&gt; &gt; Hello Karsten,
&gt; 
&gt; Hi George!
&gt; 
&gt; &gt; hope you are doing well!
&gt; &gt; 
&gt; &gt; I've been working on the S61 performance experiments [0] and I would appreciate
&gt; &gt; some help with onionperf.
&gt; &gt; 
&gt; &lt;snip&gt;
&gt; 
&gt; &gt; Then for another onionperf run (attached as 'onionperf-44028.json.xz') it gave me \
&gt; &gt; a different error: 
&gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; 2020-11-03 15:50:03 1604411403.946028 [onionperf] [INFO] loading analysis results \
&gt; &gt; from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 15:50:03 \
&gt; &gt; 1604411403.976088 [onionperf] [INFO] done! Traceback (most recent call last):
&gt; &gt; File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; &gt; run_script exec(script_code, namespace, namespace)
&gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 382, in main File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; line 522, in visualize File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; line 38, in plot_all File \
&gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt;                 line 129, in __extract_data_frame
&gt; &gt; KeyError: '44028'
&gt; &gt; 
&gt; &gt; Because of the two errors above I'm unable to proceed with producing any
&gt; &gt; results.  Any idea what I might be doing wrong? Is there any other data
&gt; &gt; you might need to help me with this?
&gt; 
&gt; In this case it's failing even before writing a CSV file. Still, when
&gt; looking at the .xz file I'm seeing only errors, too, so it's a related
&gt; issue here.
&gt; 

Hello again Karsten,

your help was valuable last time and I managed to overcome those issues.

I've been doing more experiments recently (see
https://gitlab.torproject.org/tpo/core/tor/-/issues/40157#note_2716591)
and while the data collection is still ongoing, I decided to do some
visualizations to make sure that I'm not collecting useless data all
this time.

So I took collected onionperf data but when I tried to visualize them I
got a similar error like the one from my previous email:

"""
$ onionperf visualize  --data onionperf.analysis.json.xz "bla" 
2020-12-02 21:19:04 1606936744.475013 [onionperf] [INFO] loading analysis results \
from /home/user/tmp/onionperf/onionperf-data-2558933-close/onionperf.analysis.json.xz \
2020-12-02 21:19:05 1606936745.245664 [onionperf] [INFO] done! Traceback (most recent \
call last):  File "/home/user/.local/bin/onionperf", line 4, in &lt;module&gt;
    __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
run_script  self.require(requires)[0].run_script(script_name, ns)
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
run_script  exec(script_code, namespace, namespace)
  File "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 622, in &lt;module&gt;  File \
"/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 382, in main  File \
"/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
line 522, in visualize  File \
"/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
line 38, in plot_all  File \
"/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
                line 129, in __extract_data_frame
KeyError: '36178'
"""

However this time the onionperf.analysis.json.xz file looks more
reasonable. I'm attaching it to this email just in case you have the
time to check it out and tell me what might be going wrong.

FWIW, the data was collected in a manner similar to this:
      $ onionperf measure -i --tgen ./tgen --tor ./tor --torclient-conf-file ./torrc \
--tgen-connect-ip 1.2.3.4 --tgen-listen-port 443 --tgen-connect-port 443 \
--tgen-pause-initial 20 --tgen-pause-between 2 --tgen-transfer-size '50 KiB'

Thanks a lot!


["onionperf.analysis.json.xz" (application/x-xz)]

</body></email><email><emailId>20201207075658</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-12-07 07:56:58-0400</timestampReceived><subject>Re: [tor-dev] Trouble with onionperf visualize and S61 performance experiments</subject><body>

On 2020-12-02 20:23, George Kadianakis wrote:
&gt; Karsten Loesing &lt;karsten@torproject.org&gt; writes:
&gt; 
&gt; &gt; On 2020-11-03 15:01, George Kadianakis wrote:
&gt; &gt; &gt; Hello Karsten,
&gt; &gt; 
&gt; &gt; Hi George!
&gt; &gt; 
&gt; &gt; &gt; hope you are doing well!
&gt; &gt; &gt; 
&gt; &gt; &gt; I've been working on the S61 performance experiments [0] and I would appreciate
&gt; &gt; &gt; some help with onionperf.
&gt; &gt; &gt; 
&gt; &gt; &lt;snip&gt;
&gt; &gt; 
&gt; &gt; &gt; Then for another onionperf run (attached as 'onionperf-44028.json.xz') it gave \
&gt; &gt; &gt; me a different error: 
&gt; &gt; &gt; $ onionperf visualize --data onionperf.analysis.json.xz "Test Measurements"
&gt; &gt; &gt; 2020-11-03 15:50:03 1604411403.946028 [onionperf] [INFO] loading analysis \
&gt; &gt; &gt; results from /user/tmp/onionperf/analysis/onionperf.analysis.json.xz 2020-11-03 \
&gt; &gt; &gt; 15:50:03 1604411403.976088 [onionperf] [INFO] done! Traceback (most recent call \
&gt; &gt; &gt; last): File "/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; &gt; &gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; &gt; &gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; &gt; &gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; &gt; &gt; run_script exec(script_code, namespace, namespace)
&gt; &gt; &gt; File "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 622, in &lt;module&gt; File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 382, in main File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; &gt; &gt; line 522, in visualize File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt; line 38, in plot_all File \
&gt; &gt; &gt; "/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; &gt; &gt;                 line 129, in __extract_data_frame
&gt; &gt; &gt; KeyError: '44028'
&gt; &gt; &gt; 
&gt; &gt; &gt; Because of the two errors above I'm unable to proceed with producing any
&gt; &gt; &gt; results.  Any idea what I might be doing wrong? Is there any other data
&gt; &gt; &gt; you might need to help me with this?
&gt; &gt; 
&gt; &gt; In this case it's failing even before writing a CSV file. Still, when
&gt; &gt; looking at the .xz file I'm seeing only errors, too, so it's a related
&gt; &gt; issue here.
&gt; &gt; 
&gt; 
&gt; Hello again Karsten,

Hi George!

&gt; your help was valuable last time and I managed to overcome those issues.
&gt; 
&gt; I've been doing more experiments recently (see
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/40157#note_2716591)
&gt; and while the data collection is still ongoing, I decided to do some
&gt; visualizations to make sure that I'm not collecting useless data all
&gt; this time.
&gt; 
&gt; So I took collected onionperf data but when I tried to visualize them I
&gt; got a similar error like the one from my previous email:
&gt; 
&gt; """
&gt; $ onionperf visualize  --data onionperf.analysis.json.xz "bla" 
&gt; 2020-12-02 21:19:04 1606936744.475013 [onionperf] [INFO] loading analysis results \
&gt; from /home/user/tmp/onionperf/onionperf-data-2558933-close/onionperf.analysis.json.xz
&gt;  2020-12-02 21:19:05 1606936745.245664 [onionperf] [INFO] done!
&gt; Traceback (most recent call last):
&gt; File "/home/user/.local/bin/onionperf", line 4, in &lt;module&gt;
&gt; __import__('pkg_resources').run_script('OnionPerf==0.8', 'onionperf')
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 650, in \
&gt; run_script self.require(requires)[0].run_script(script_name, ns)
&gt; File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 1453, in \
&gt; run_script exec(script_code, namespace, namespace)
&gt; File "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 622, in &lt;module&gt; File \
&gt; "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 382, in main File \
&gt; "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/EGG-INFO/scripts/onionperf", \
&gt; line 522, in visualize File \
&gt; "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt; line 38, in plot_all File \
&gt; "/home/user/.local/lib/python3.8/site-packages/OnionPerf-0.8-py3.8.egg/onionperf/visualization.py", \
&gt;                 line 129, in __extract_data_frame
&gt; KeyError: '36178'
&gt; """
&gt; 
&gt; However this time the onionperf.analysis.json.xz file looks more
&gt; reasonable. I'm attaching it to this email just in case you have the
&gt; time to check it out and tell me what might be going wrong.

This is related to the issues you saw before. Please try out the patch
that I wrote for #40012 last week for the visualization part (no need to
re-do the measurements):

$ git remote add karsten https://gitlab.torproject.org/karsten/onionperf.git

$ git fetch karsten

$ git checkout -b task-40012 karsten/task-40012

If you want, please comment on the ticket whether this worked for you!

All the best,
Karsten


&gt; 
&gt; FWIW, the data was collected in a manner similar to this:
&gt; $ onionperf measure -i --tgen ./tgen --tor ./tor --torclient-conf-file ./torrc \
&gt; --tgen-connect-ip 1.2.3.4 --tgen-listen-port 443 --tgen-connect-port 443 \
&gt; --tgen-pause-initial 20 --tgen-pause-between 2 --tgen-transfer-size '50 KiB' 
&gt; Thanks a lot!
&gt; 

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200801100944</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-01 10:09:44-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


nusenu:
&gt; &gt; The only question that came up was: Will there be two types of relay fingerprints
&gt; &gt; in the future (Ed25519)?
&gt; 
&gt; I assume the correct proposal for the Ed25519 keys is this:
&gt; https://gitweb.torproject.org/torspec.git/tree/proposals/220-ecc-id-keys.txt
&gt; 
&gt; I'm wondering what kind of format is used for a relay's Ed25519 ID in tor?
&gt; 
&gt; The spec says base64:
&gt; 
&gt; &gt; When an ed25519 signature is present, there MAY be a "master-key-ed25519"
&gt; &gt; element containing the base64 encoded ed25519 master key as a single
&gt; &gt; argument.  If it is present, it MUST match the identity key in
&gt; &gt; the certificate.
&gt; 
&gt; examples:
&gt; grep master-key-ed 2020-07-28-19-05-00-server-descriptors |head -2
&gt; 
&gt; master-key-ed25519 clT/2GWmTY/qU5TBGaudAIjOUUxUdKhMY/Q5riK6G2E
&gt; master-key-ed25519 qDI9PbwtiKzpR9phLnWI99uimdwNW8+l9c7hDoWV9dQ
&gt; 
&gt; Is this the canonical format you use when referring to a relay's Ed25519 identity?

I looked at what stem does in this area [1].
It uses the more accurate name "ed25519_master_key" instead of Ed25519 ID
and contains the above mentioned base64 encoded Ed25519 public master key 
so I assume this is the canonical format since I didn't see any other representation.

&gt; What command does a relay operator need to run to find out
&gt; his relay's Ed25519 ID on the command line?

base64 encoding (parts of) the ed25519_master_id_public_key
file, provides the same output as in master-key-ed25519 descriptor lines
but I didn't find a spec for that key file to confirm the try and error approach
or a tor command to simply output the ed25519_master_key public key in base64 format.

kind regards,
nusenu

[1] https://stem.torproject.org/api/descriptor/server_descriptor.html#stem.descriptor.server_descriptor.RelayDescriptor
 https://gitweb.torproject.org/torspec.git/tree/cert-spec.txt

These are the file paths I would suggest for the well-known registry:
.well-known/tor-relay/rsa-fingerprints
.well-known/tor-relay/ed25519-pubkeys



-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200801134750</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-01 13:47:50-0400</timestampReceived><subject>Re: [tor-dev] IANA well-known URI suffix registration for tor-relay-fingerprints file</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


I've put together the text, if you have any
comments please let me know. I'm planning to submit it
soon-ish.

https://nusenu.github.io/tor-relay-well-known-uri-spec/

I'll also send it to the tor-relays mailing list.

kind regards,
nusenu

--=20
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200806145606</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-08-06 14:56:06-0400</timestampReceived><subject>[tor-dev] CAPTCHA Monitoring Project's Dashboard</subject><body>

Hi everyone,

I created a wiki page [1] for "describing" the graphs that will be
used to visualize the CAPTCHA Monitor dataset [2]. There are already a
few graphs on the dashboard [3] and they will be replaced with the new
ones described on the wiki page.

I'm interested in hearing your feedback on the graph descriptions [1]
and suggestions for adding new graphs. I want to understand if the
graphs I proposed make sense and useful for anyone. The descriptions
have a similar style to the one used in the metrics website's
"Reproducible Metrics" page [4].

Thank you in advance!

Best,
Barkin (woswos)

[1] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/Dashboard-Graphs
[2] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home
[3] https://dashboard.captcha.wtf
[4] https://metrics.torproject.org/reproducible-metrics.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200811073430</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2020-08-11 07:34:30-0400</timestampReceived><subject>Re: [tor-dev] CAPTCHA Monitoring Project's Dashboard</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Barkin Simsek:
&gt; Hi everyone,
&gt; 
&gt; I created a wiki page [1] for "describing" the graphs that will be
&gt; used to visualize the CAPTCHA Monitor dataset [2]. There are already a
&gt; few graphs on the dashboard [3] and they will be replaced with the new
&gt; ones described on the wiki page.

Thanks for that wiki page. That's been really helpful. One thing I kept
wondering while reading through the different graph descriptions with
the default graph style in mind: You said:

"X-axis: The dates of the last 30*24 consensuses (last 30 days), each
tick representing a single consensus"

While the graphs you describe read:

3. Merge the graphs created for each consensus

So, what's the tick shown per day then? One consensus somehow picked or
data for all consensuses for that day? Or...?

&gt; I'm interested in hearing your feedback on the graph descriptions [1]
&gt; and suggestions for adding new graphs. I want to understand if the
&gt; graphs I proposed make sense and useful for anyone. The descriptions
&gt; have a similar style to the one used in the metrics website's
&gt; "Reproducible Metrics" page [4].

How do you plan to show those graphs on the dashboard? Are they all
shown in some order? Grouped by sections (maybe along those on the
wiki)? Grouped by "importance"? I suspect there is a tension between
just showing them all and the most usefulness of the dashboard and it
might be worth spending some though on that (if you did not have
already). Or maybe there are even guidelines in the literature somewhere
I am not aware of.

Somewhat related to that, I think we can try reducing the number of
graphs, at least those which are greatly related. E.g. I was at first
confused seeing "Weighted CAPTCHA rate by exit relay age" and "Weighted
CAPTCHA rate by exit relay location" twice until I realized the
different sections they showed up. One thing that could be useful here
is having a switch/buttons next to the graph giving the user the option
to see "by exit relay age" for all CAPTCHAs, or for Cloudflare ones, or
for Akamai ones or for... depending on the switch/button the users
clicked on. The graph would update accordingly once clicked, showing the
user choice. The default could be for all CAPTCHAs or essentially
whatever we think is more important for us. That way you have related
things grouped together AND you have less graphs shown per default on
the dashboard, too, which might help not getting confused.

Georg

&gt; Thank you in advance!
&gt; 
&gt; Best,
&gt; Barkin (woswos)
&gt; 
&gt; [1] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/Dashboard-Graphs
&gt; [2] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home
&gt; [3] https://dashboard.captcha.wtf
&gt; [4] https://metrics.torproject.org/reproducible-metrics.html
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 



["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200729051509</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-07-29 05:15:09-0400</timestampReceived><subject>[tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

Hello everyone,

Onion service version two (v2) key pairs were used for more purposes
than simply facilitating the establishment of rendezvous circuits, in
particular third-party applications used this key in numerous ways.
Similarly, version three (v3) onion service keys are being re-used in
similar (and new) ways. However, the (re)use of v3 long-term keys is not
obviously safe in all situations. How should (and should not) these
keys be used, such that the security of the onion service is preserved?

I'll briefly summarize v3 keys (for those who don't want to read through
the spec), and then I'll sketch two alternative use cases along with a
straw man proposal. The long-term v3 identity keys are ed25519 keys (see
[0] for a nice write up of ed25519, in general). The generated key
material is serialized externally (outside of tor) in two (similar)
formats: written on-disk [2] and from the control port [3].

The secret (private) key is the (64-byte) SHA-512 digest of a 32-byte
seed value. The 64-byte digest is the "expanded form". The seed is
thrown away. The public key is obtained by taking the first 32 bytes of
that SHA-512 hash, clamping some of the bits, and performing a scalar
multiplication with the (fixed) base point. This key is the onion
service long-term identity key.

Creating and verifying a signature using the above keys (respectively)
follow standard EdDSA. However, (at this time) Tor does not use these
keys directly for signing messages. All messages are signed using an
ephemeral ed25519 key, and that ephemeral key is certified by a blinded
ed25519 key derived from the long-term key pair. The blinded keys are
computed using a specified blinding scheme [4]. All messages signed
using the ephemeral key are prefixed with a context-specific string. In
summary, long-term keys are used for deriving a short-term blinded key,
and that short-term blinded key is used for certifying an ephemeral
signing key.

For computing the blinded key, the first 32 bytes of the long-term
secret key (LH) are multiplied with a blinding factor (h*a mod l), see
the specification for the value of **h** [4]. This becomes LH'
(LH-prime). The second 32 bytes of the secret key (RH) are concatenated
with a string prefix and then the SHA3-256 digest is computed of the
concatenated string. The first 32 bytes of the resulting digest become
RH' (RH-prime). LH' and RH' are used as regular ed25519 secret keys for
signing and verifying messages following EdDSA.

Tor's EdDSA signature is "R|S", R concatenated with S (the message is
not included in the signature).

The safest usage of the long-term keys for alternative purposes I see
appears to be by deriving a (fixed/deterministic) blinded key pair using
the same scheme that Tor uses, and signing/verification simply follow
the same process as Tor, except the derived keys need not rotate
periodically (is this true?). The derived key should be used for
certifying a freshly generated ed25519 key, which is used in the
application protocol. For example, if I want to use a key for code
signing such that it is bound to my onion service key, then I could
derive a certifying key by following Tor's derivation scheme, by
substituting:

  BLIND_STRING = "Derive temporary signing key" | INT_1(0)
  N = "key-blind" | INT_8(period-number) | INT_8(period_length)

with

  BLIND_STRING = "Derive code signing key" | INT_1(0)
  N = "code-sigining-key-blind" | "v0" | "YYYY-MM-DD" |  INT_8(validity_period)

for computing the blinding factor. Where "v0" is a version tag.
YYYY-MM-DD is an arbitrary date, but it can be used for rotating signing
keys in the future. INT_8(validity_period) may be used for specifying
the number of days after YYYY-MM-DD at which time previously unverified
signatures using this key should be considered invalid (where INT_8(0)
could indicate "never expire").

And substituting

  RH_BLIND_STRING = "Derive temporary signing key hash input"

with

  RH_BLIND_STRING = "Derive code signing key hash input"

for computing RH'.

A signature must include "v0" and the values used in "YYYY-MM-DD" and
INT_8(validity_period), such that the client can derive the correct
blinded public key for verification when starting from the long-term
identity key. The signature should be over a certification of an
independently generated ed25519 key pair. This new key pair (along with
the certification) can be used for providing message integrity within
the application's protocol. If, instead, the derived key is used
directly for signing, and the application needs the keys online for
signing messages, then this risks the security of the long-term key, as
well. The blinding scheme allows for (partially) recovering the
long-term secret key from the derived secret key.

Another example use case comes from Jeremy Rand where the onion service
key is used in a root CA certificate, and a leaf certificate (signed by
the CA cert) is used by the application.

Following from the previous example, (most likely) the CA certificate
should not be signed directly using the onion service's long-term secret
key. However, a derived key could be used in the CA certificate and the
leaf cert could contain an ephemeral key (in exactly the same way that
tor certifies ephemeral keys using the derived blinded signing key).
This idea appears to be a concrete design of how the above (abstract)
key certification could be implemented, and it could be a format that
tor natively supports.

The above process seems like a lot to ask from application developers.
Can we make it easier for them?

Open questions:

 1) Going back to the long-term secret key, can LH and RH be used
    directly in EdDSA without reducing the security and unlinkability of
    the blinded keys?

 2) Should other use cases of the long-term keys only derive distinct
    (blinded) keys, instead of using the long-term keys directly?

 3) If other use cases should only use derived keys, then is there an
    alternative derivation scheme for when unlinkability between derived
    keys is not needed (without reducing the security properties of the
    onion service blinded keys), and is allowing linkability
    useful/worthwhile?

 4) Is the above example derivation scheme safe if different
    applications tweak the above prefix strings in similar ways?

 5) Should Tor simply derive one blinded key that can be used by all
    alternative applications? Is that safe?

I'd like to thank Nick Mathewson and David Goulet for their comments on
an earlier version of this mail.

Thanks,
Matt


[0] https://blog.mozilla.org/warner/2011/11/29/ed25519-keys/
[1] https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n2267
[2] A tagged value: "== ed25519v1-secret: type0 =="\0\0\0 | (64-byte
SHA-512 hash of the seed)
[3] https://gitweb.torproject.org/torspec.git/tree/control-spec.txt#n1746
[4] https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n2267
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200810221311</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-10 22:13:11-0400</timestampReceived><subject>[tor-dev] Can "ExcludeNodes" be used multiple times in torrc?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

it is not clear to me whether ExcludeNodes and other similar options (ExcludeExitNodes)
can be used multiple times in a torrc file.

Are all of the lines merged like multiple "MyFamily" lines or
how does it behave?

thanks,
nusenu



-- 
https://mastodon.social/@nusenu




["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200814101750</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-14 10:17:50-0400</timestampReceived><subject>[tor-dev] proposal for "tor-relay" well-known URI</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

I'm submitting this as a proposal according to:
https://github.com/torproject/torspec/blob/master/proposals/001-process.t=
xt

I made a PR request for you:
https://github.com/torproject/torspec/pull/129/files

kind regards,
nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200917185918</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-09-17 18:59:18-0400</timestampReceived><subject>Re: [tor-dev] proposal for "tor-relay" well-known URI</subject><body>

On Mon, Aug 17, 2020 at 11:19 AM David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt;
&gt; On 14 Aug (12:17:50), nusenu wrote:
&gt; &gt; Hi,
&gt; &gt;
&gt; &gt; I'm submitting this as a proposal according to:
&gt; &gt; https://github.com/torproject/torspec/blob/master/proposals/001-process.txt
&gt; &gt;
&gt; &gt; I made a PR request for you:
&gt; &gt; https://github.com/torproject/torspec/pull/129/files
&gt;
&gt; Thanks nusenu!
&gt;
&gt; FYI, the merge request to tor-spec.git is here:
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/3
&gt;
&gt; Cheers!
&gt; David
&gt;

This is now proposal 326.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200811211554</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-08-11 21:15:54-0400</timestampReceived><subject>Re: [tor-dev] Can "ExcludeNodes" be used multiple times in torrc?</subject><body>

On Mon, Aug 10, 2020 at 6:13 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; it is not clear to me whether ExcludeNodes and other similar options (ExcludeExitNodes)
&gt; can be used multiple times in a torrc file.
&gt;
&gt; Are all of the lines merged like multiple "MyFamily" lines or
&gt; how does it behave?

No, only one is recognized.

If you try to start tor with ExcludeNodes set twice, it should say
something like:

Aug 11 17:14:36.928 [warn] Option 'ExcludeNodes' used more than once;
all but the last value will be ignored.

I'd welcome patches to clarify this in the documentation, or to allow
this option to repeat.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200820183009</emailId><senderName>Philipp Winter</senderName><senderEmail>phw@nymity.ch</senderEmail><timestampReceived>2020-08-20 18:30:09-0400</timestampReceived><subject>[tor-dev] Store Salmon-related information in Tor Browser?</subject><body>

(Sending this email again because I failed to copy tor-dev@.)

On Mon, Aug 17, 2020 at 12:16:08PM -0700, Philipp Winter wrote:
&gt; Hi Matt,
&gt; 
&gt; We recently started experimenting with the Salmon social bridge
&gt; distributor:
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/31873
&gt; 
&gt; We are now exploring the possibility of storing some Salmon-related data
&gt; on a user's computer and are wondering what our options are.  The data
&gt; we're talking about is a lightweight, signed, and encrypted blurb that
&gt; contains a user's social graph, proxies, and registration ID.
&gt; 
&gt; One option to store this data is Tor's data directory but that doesn't
&gt; seem ideal because Salmon isn't a PT and technically has nothing to do
&gt; with Tor.  Is Tor Browser an option here?  Or does the "disk avoidance"
&gt; design goal mean that we don't get to store anything at all?  A last
&gt; resort option would be to simply hand the blurb to the user and ask them
&gt; to store it somewhere but we would like to find a more usable way to
&gt; handle this.
&gt; 
&gt; Thanks,
&gt; Philipp
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200811213353</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-11 21:33:53-0400</timestampReceived><subject>Re: [tor-dev] Can "ExcludeNodes" be used multiple times in torrc?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Nick Mathewson:
&gt; On Mon, Aug 10, 2020 at 6:13 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;&gt;
&gt;&gt; Hi,
&gt;&gt;
&gt;&gt; it is not clear to me whether ExcludeNodes and other similar options (ExcludeExitNodes)
&gt;&gt; can be used multiple times in a torrc file.
&gt;&gt;
&gt;&gt; Are all of the lines merged like multiple "MyFamily" lines or
&gt;&gt; how does it behave?
&gt; 
&gt; No, only one is recognized.

thanks for your reply.

Is there any way to comment fingerprints in ExcludeNodes?

Since everything after "#" is ignored I guess something like this is
not possible since everything after the first fingerprint is a comment?

ExcludeNodes  \
  fingerprint1 # comment \
  fingerprint2 # comment \
  fingerprint3 # comment





-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200811235806</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-08-11 23:58:06-0400</timestampReceived><subject>Re: [tor-dev] Can "ExcludeNodes" be used multiple times in torrc?</subject><body>

Hi nusenu, tor's manual says [1]...

"To split one configuration entry into multiple lines, use a single
backslash character (\) before the end of the line. Comments can be
used in such multiline entries, but they must start at the beginning
of a line."

I just double checked and it works...

========================================
torrc
========================================

ControlPort 9051

ExcludeNodes \
  # nickname: moria1
  9695DFC35FFEB861329B9F1AB04C46397020CE31, \
  # nickname: tor26
  847B1F850344D7876491A54892F904934E4EB85D

========================================

% cat demo.py
from stem.control import Controller

with Controller.from_port() as controller:
  controller.authenticate()
  print(controller.get_conf('ExcludeNodes'))

% python demo.py
9695DFC35FFEB861329B9F1AB04C46397020CE31,847B1F850344D7876491A54892F904934E4EB85D

========================================

[1] https://2019.www.torproject.org/docs/tor-manual.html.en#_the_configuration_file_format
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200831162201</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-08-31 16:22:01-0400</timestampReceived><subject>[tor-dev] CAPTCHA Monitoring Project Final Report</subject><body>

Hi everyone,

The end of the Google Summer of Code period has arrived, and you can
find my GSoC final report for the CAPTCHA Monitoring project here [1].
This was my first time working with an active open source community
and I enjoyed it a lot! The feedback you have provided made the
experience worthwhile and exciting. I couldn't finish implementing all
of the features I planned, so I will be around and I plan to stay
active. I want to thank my mentors GeKo &amp; arma and everyone who helped
me with the project!

Best,
Barkin

[1] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2020
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200730014938</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-07-30 01:49:38-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

On 2020/07/29 05:15, Matthew Finkel wrote:
&gt;
&gt; [ ... snip ... ]
&gt; =

&gt; A signature must include "v0" and the values used in "YYYY-MM-DD" and
&gt; INT_8(validity_period), such that the client can derive the correct
&gt; blinded public key for verification when starting from the long-term
&gt; identity key. The signature should be over a certification of an
&gt; independently generated ed25519 key pair. This new key pair (along with
&gt; the certification) can be used for providing message integrity within
&gt; the application's protocol. If, instead, the derived key is used
&gt; directly for signing, and the application needs the keys online for
&gt; signing messages, then this risks the security of the long-term key, as
&gt; well. The blinding scheme allows for (partially) recovering the
&gt; long-term secret key from the derived secret key.

This is super useful, Matt! Thanks for writing all of this down.

&gt; Another example use case comes from Jeremy Rand where the onion service
&gt; key is used in a root CA certificate, and a leaf certificate (signed by
&gt; the CA cert) is used by the application.

This idea stemmed from a conversation between David, George, and me a
little while after the Stockholm meeting last summer. The implementation
of the tool for generating the various x509 files (the x509 CA and the
signed x509 certificates) is available from

    https://gitlab.torproject.org/ahf/onion-x509

For people who are unaware of what this tool is doing, I can flesh it
out here:

Tor uses an ed25519 secret key format that is incompatible with the
ed25519 secret key encoding found in x509, and we cannot just convert
the .onion identity ed25519 key to a PEM file and make, for example, a
web server use it directly. This also seems to be what Matt is
recommending against. As seen in Matt's [0], the signatures and public
keys are all using the same encoding, however.

In ordinary TLS, where the server sends the certificate chain, we don't
keep ANY of our CA's secret keys online (since we hopefully don't have
access to them under normal circumstances). Thus, we only need the
secret and public key of our leaf certificate to be available for our
TLS service to do signatures as part of the TLS protocol. We can
therefore generate an "Onion CA" from Tor's .onion identity secret key,
but never have to move any secret key with it into our TLS service
deployments.

Once we have generated this "Onion CA", which is identified by the onion
identity public key, we use the onion-x509 tool to issue leaf
certificates that are signed by the "Onion CA." By configuring our TLS
service to use the Onion CA and our ed25519 leaf key pair, and its x509
certificate (signed by the Onion CA), the client will be able to verify
if the certificate is "valid" just based on the Onion address itself.

I think the stateless nature of this system is pretty cool.  I don't
believe that moving to blinded keys blocks anything for it to work,
which means I think Jeremy and I should probably coordinate to do that
instead of the direct use of the onion identity key pair as the tool
does today.

Of course, the modifications to the browser are the terrifying part of
all of this as such changes touch some scary code paths in how TLS
certificates are validated. Still, if this can work, it would make x509
certificates very easily accessible for Onion service operators.

If Jeremy gets the demo to work in Tor Browser and it all looks
promising, we should also spend a bit of time rewriting the Go tool to C
and bundle it with the Tor codebase.

&gt; Following from the previous example, (most likely) the CA certificate
&gt; should not be signed directly using the onion service's long-term secret
&gt; key. However, a derived key could be used in the CA certificate and the
&gt; leaf cert could contain an ephemeral key (in exactly the same way that
&gt; tor certifies ephemeral keys using the derived blinded signing key).
&gt; This idea appears to be a concrete design of how the above (abstract)
&gt; key certification could be implemented, and it could be a format that
&gt; tor natively supports.

From what I can tell, it should be possible for us to update the
onion-x509 tool to use the blinded key instead.

Exciting stuff!

All the best,
Alex.

-- =

Alexander F=E6r=F8y
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200730101833</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-07-30 10:18:33-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

Matthew Finkel &lt;sysrqb@torproject.org&gt; writes:

&gt; Hello everyone,
&gt;

Hello hello!

These are all good questions and they become more and more important as
the onionspace grows and more use cases appear.

&gt; &lt;snip&gt;
&gt;
&gt; For computing the blinded key, the first 32 bytes of the long-term
&gt; secret key (LH) are multiplied with a blinding factor (h*a mod l), see
&gt; the specification for the value of **h** [4]. This becomes LH'
&gt; (LH-prime). The second 32 bytes of the secret key (RH) are concatenated
&gt; with a string prefix and then the SHA3-256 digest is computed of the
&gt; concatenated string. The first 32 bytes of the resulting digest become
&gt; RH' (RH-prime). LH' and RH' are used as regular ed25519 secret keys for
&gt; signing and verifying messages following EdDSA.
&gt;

Hmm, not sure about this last sentence. Are you implying that LH' and RH' are
two different secret keys? Because I don't think that's the case. LH' and RH'
are components of the final public/private keypair.

&gt; Tor's EdDSA signature is "R|S", R concatenated with S (the message is
&gt; not included in the signature).
&gt;
&gt;
&gt; The above process seems like a lot to ask from application developers.
&gt; Can we make it easier for them?
&gt;

Yes I totally agree that this procedure is too much to ask from application
developers.

&gt; Open questions:
&gt;
&gt;  1) Going back to the long-term secret key, can LH and RH be used
&gt;     directly in EdDSA without reducing the security and unlinkability of
&gt;     the blinded keys?
&gt;

In which way would we use LH and RH directly in EdDSA?

&gt;  2) Should other use cases of the long-term keys only derive distinct
&gt;     (blinded) keys, instead of using the long-term keys directly?
&gt;

I think that's the most important question. That is, what can we safely do with
the long-term keys (given that they are also used for this key blinding procedure)?

My intuition is that it's safe to use the long-term keys to sign other things
directly, because the blinding factor of the key blinding procedure does not
contain any attacker-controlled input. However, this is just an intuition from
a non-cryptographer and hence we need a proper security proof, especially given
the various complexities of the whole system
(e.g. clamping: https://lists.torproject.org/pipermail/tor-dev/2017-April/012204.html),
and especially if we want to do more complicated things than just signing (like
use those keys for x25519 or something).

In some way I think that exploring this problem is the first step before
deciding to use derived keys, since as you said having to use derived keys will
complicate things a lot for application developers.

&gt;  3) If other use cases should only use derived keys, then is there an
&gt;     alternative derivation scheme for when unlinkability between derived
&gt;     keys is not needed (without reducing the security properties of the
&gt;     onion service blinded keys), and is allowing linkability
&gt;     useful/worthwhile?
&gt;

Hm, if linkability between derived keys is _desired_, then perhaps you could
generate subsequent derived keys by iterating on top of previous derived keys,
instead of iterating on top of the long-term key like HSv3 does. This way you
can prove relations between derived public keys without leaking the long-term
key.

In any case, IANAC so a security proof is what we need here.

&gt;
&gt;  4) Is the above example derivation scheme safe if different
&gt;     applications tweak the above prefix strings in similar ways?
&gt;

Again my intuition says that it should be OK, since tweaking the BLIND_STRING
tweaks the blind factor 'h':
                  h = H(BLIND_STRING | A | s | B | N)

And because the blind factor is the output of a hash function, tweaking the
BLIND_STRING is not any different from using a blind factor with a different
time period value:
                  N = "key-blind" | INT_8(period-number) | INT_8(period_length)

In any case, IANAC so a security proof is what we need here.

&gt;  5) Should Tor simply derive one blinded key that can be used by all
&gt;     alternative applications? Is that safe?
&gt;

If we assume that derived keys are as safe as long-term keys, then that should
be fine, as it is safe for many applications to use the same long-term ed25519
key, assuming that they don't do anything silly with it (like converting
between ed25519 and x25519 and exposing a DH oracle that might generate valid
signatures for the attacker).

In any case, IANAC so a security proof is what we need here.

---

Hope that was useful. It's as far as I can get here without spending days on it
and without going into dangerous waters.

I've seen more and more interest about hierarchical key derivation
lately, and it seems like our design is one of the popular ones (and
probably the oldest), but there are more these days:
    https://mailarchive.ietf.org/arch/msg/cfrg/qDJKIMRctVvYuZBYBcACLLeS7hM/
    https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44
    https://github.com/satoshilabs/slips/blob/master/slip-0010.md

In general, I'd be interested in participating in a standarization and security
analysis process where we clarify what application-developers can and cannot do
with our scheme.

Cheers! :)



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200810130032</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-08-10 13:00:32-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

On Wed, Jul 29, 2020 at 1:15 AM Matthew Finkel &lt;sysrqb@torproject.org&gt; wrote:
&gt;
&gt; Hello everyone,

Hi, Matt!

There's a part of this that I'm still trying to figure out:

&gt; The safest usage of the long-term keys for alternative purposes I see
&gt; appears to be by deriving a (fixed/deterministic) blinded key pair using
&gt; the same scheme that Tor uses, and signing/verification simply follow
&gt; the same process as Tor, except the derived keys need not rotate
&gt; periodically (is this true?). The derived key should be used for
&gt; certifying a freshly generated ed25519 key, which is used in the
&gt; application protocol. For example, if I want to use a key for code
&gt; signing such that it is bound to my onion service key, then I could
&gt; derive a certifying key by following Tor's derivation scheme, by
&gt; substituting:
&gt;
&gt;   BLIND_STRING = "Derive temporary signing key" | INT_1(0)
&gt;   N = "key-blind" | INT_8(period-number) | INT_8(period_length)
&gt;
&gt; with
&gt;
&gt;   BLIND_STRING = "Derive code signing key" | INT_1(0)
&gt;   N = "code-sigining-key-blind" | "v0" | "YYYY-MM-DD" |  INT_8(validity_period)

In the case of v3 onion services, 'period-number' comes from the
current time, and 'period-length' comes from the consensus, so it's
easy for the client to know what parameters to use when deriving the
key.

But how is the party that relies on the derived key supposed to know
what values were used for "YYYY-MM-DD" and "validity period" in this
case?  It seems like those two values would need to be shipped along
with the key, which could make for logistical issues.

I guess in the case of an X.509 certificate, we could use the
validAfter  and validUntil fields to set the  parameters -- though
it's a little weird to have to look at _just_ those fields to see what
the signing key is supposed to be.

Maybe, for an X.509 cert, we could have

  N = "x509 onion key derivation" | H(unsigned-certificate)

where `unsigned-certificate` is a DER-encoded TBSCertificate (the part
of the certificate that's signed).  That way, we get a separate
blinded key for each certificate.

 [...]
&gt; The above process seems like a lot to ask from application developers.
&gt; Can we make it easier for them?
&gt;
&gt; Open questions:
&gt;
&gt;  1) Going back to the long-term secret key, can LH and RH be used
&gt;     directly in EdDSA without reducing the security and unlinkability of
&gt;     the blinded keys?

From a practical point of view: Forcing the signer to keep LH and RH
online reduces the security of the protocol IMO; the current protocol
is designed so that the onion service doesn't need to keep its
long-term identity key online.

Also note that if we care about keeping the primary identity key
offline, LH' and RH' shouldn't be used directly!  Although it is not
possible to derive a long-term public key from a blinded public key,
it IS possible to derive a long-term _private_ key from a blined
private key.  That's why in the v3 onion service system, blinded
private keys aren't kept for any longer than needed in order to
certify a short-term randomly generated signing key.

&gt;  2) Should other use cases of the long-term keys only derive distinct
&gt;     (blinded) keys, instead of using the long-term keys directly?

IMO yes.

&gt;  3) If other use cases should only use derived keys, then is there an
&gt;     alternative derivation scheme for when unlinkability between derived
&gt;     keys is not needed (without reducing the security properties of the
&gt;     onion service blinded keys), and is allowing linkability
&gt;     useful/worthwhile?
&gt;
&gt;  4) Is the above example derivation scheme safe if different
&gt;     applications tweak the above prefix strings in similar ways?
&gt;
&gt;  5) Should Tor simply derive one blinded key that can be used by all
&gt;     alternative applications? Is that safe?

Yes, but only if that key will never ever need to rotate.

Here's a suggestion -- what if we come up with a single profile for
this kind of key derivation, to be used in X.509.  Along with it, we
could have a nice small library that can generate and verify the
"root" certificates (the ones signed by a blinded key).

What important parts of the application space would be left unaddressed by that?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200810130919</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-08-10 13:09:19-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

but it's trivial to verify the certificate if you know what the

On Mon, Aug 10, 2020 at 9:00 AM Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt; On Wed, Jul 29, 2020 at 1:15 AM Matthew Finkel &lt;sysrqb@torproject.org&gt; wrote:
&gt; &gt;
&gt; &gt; Hello everyone,
&gt;
&gt; Hi, Matt!
&gt;
&gt; There's a part of this that I'm still trying to figure out:
&gt;
&gt; &gt; The safest usage of the long-term keys for alternative purposes I see
&gt; &gt; appears to be by deriving a (fixed/deterministic) blinded key pair using
&gt; &gt; the same scheme that Tor uses, and signing/verification simply follow
&gt; &gt; the same process as Tor, except the derived keys need not rotate
&gt; &gt; periodically (is this true?). The derived key should be used for
&gt; &gt; certifying a freshly generated ed25519 key, which is used in the
&gt; &gt; application protocol. For example, if I want to use a key for code
&gt; &gt; signing such that it is bound to my onion service key, then I could
&gt; &gt; derive a certifying key by following Tor's derivation scheme, by
&gt; &gt; substituting:
&gt; &gt;
&gt; &gt;   BLIND_STRING = "Derive temporary signing key" | INT_1(0)
&gt; &gt;   N = "key-blind" | INT_8(period-number) | INT_8(period_length)
&gt; &gt;
&gt; &gt; with
&gt; &gt;
&gt; &gt;   BLIND_STRING = "Derive code signing key" | INT_1(0)
&gt; &gt;   N = "code-sigining-key-blind" | "v0" | "YYYY-MM-DD" |  INT_8(validity_period)
&gt;
&gt; In the case of v3 onion services, 'period-number' comes from the
&gt; current time, and 'period-length' comes from the consensus, so it's
&gt; easy for the client to know what parameters to use when deriving the
&gt; key.
&gt;
&gt; But how is the party that relies on the derived key supposed to know
&gt; what values were used for "YYYY-MM-DD" and "validity period" in this
&gt; case?  It seems like those two values would need to be shipped along
&gt; with the key, which could make for logistical issues.
&gt;
&gt; I guess in the case of an X.509 certificate, we could use the
&gt; validAfter  and validUntil fields to set the  parameters -- though
&gt; it's a little weird to have to look at _just_ those fields to see what
&gt; the signing key is supposed to be.
&gt;
&gt; Maybe, for an X.509 cert, we could have
&gt;
&gt;   N = "x509 onion key derivation" | H(unsigned-certificate)
&gt;
&gt; where `unsigned-certificate` is a DER-encoded TBSCertificate (the part
&gt; of the certificate that's signed).  That way, we get a separate
&gt; blinded key for each certificate.
&gt;
&gt;  [...]
&gt; &gt; The above process seems like a lot to ask from application developers.
&gt; &gt; Can we make it easier for them?
&gt; &gt;
&gt; &gt; Open questions:
&gt; &gt;
&gt; &gt;  1) Going back to the long-term secret key, can LH and RH be used
&gt; &gt;     directly in EdDSA without reducing the security and unlinkability of
&gt; &gt;     the blinded keys?
&gt;
&gt; From a practical point of view: Forcing the signer to keep LH and RH
&gt; online reduces the security of the protocol IMO; the current protocol
&gt; is designed so that the onion service doesn't need to keep its
&gt; long-term identity key online.
&gt;
&gt; Also note that if we care about keeping the primary identity key
&gt; offline, LH' and RH' shouldn't be used directly!  Although it is not
&gt; possible to derive a long-term public key from a blinded public key,
&gt; it IS possible to derive a long-term _private_ key from a blined
&gt; private key.  That's why in the v3 onion service system, blinded
&gt; private keys aren't kept for any longer than needed in order to
&gt; certify a short-term randomly generated signing key.
&gt;
&gt; &gt;  2) Should other use cases of the long-term keys only derive distinct
&gt; &gt;     (blinded) keys, instead of using the long-term keys directly?
&gt;
&gt; IMO yes.
&gt;
&gt; &gt;  3) If other use cases should only use derived keys, then is there an
&gt; &gt;     alternative derivation scheme for when unlinkability between derived
&gt; &gt;     keys is not needed (without reducing the security properties of the
&gt; &gt;     onion service blinded keys), and is allowing linkability
&gt; &gt;     useful/worthwhile?
&gt; &gt;
&gt; &gt;  4) Is the above example derivation scheme safe if different
&gt; &gt;     applications tweak the above prefix strings in similar ways?
&gt; &gt;
&gt; &gt;  5) Should Tor simply derive one blinded key that can be used by all
&gt; &gt;     alternative applications? Is that safe?
&gt;
&gt; Yes, but only if that key will never ever need to rotate.
&gt;
&gt; Here's a suggestion -- what if we come up with a single profile for
&gt; this kind of key derivation, to be used in X.509.  Along with it, we
&gt; could have a nice small library that can generate and verify the
&gt; "root" certificates (the ones signed by a blinded key).
&gt;
&gt; What important parts of the application space would be left unaddressed by that?

Like, here's the API I'm envisioning, in pseudocode.

On the service side, you would have a function that takes the primary
keypair for an onion service, and an unsigned X.509 certificate, and
produces a signed certificate:

  X509Cert create_cert(PrimaryKeypair, UnsignedCertificate);

then later on, an application that knows the public key for an onion
service could check one of these certificates by getting the public
key as follows:

  PublicKey get_public_key_to_check_cert(X509Cert, PrimaryPublicKey pub);

and then the application would just call the regular X509 verification
functions.

.....

Of course, maybe we'd want to stick the blinded signing key in the
certificate, so that you could verify the certificate without knowing
its identity key?  If so we'd need a different API to create the cert,
but we could still make it work.


-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200808073644</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-08 07:36:44-0400</timestampReceived><subject>Re: [tor-dev] IANA well-known URI suffix registration "tor-relay"</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


submitted as:
https://github.com/protocol-registries/well-known-uris/issues/8


@nickm and Mike: Mark would like to hear your opinion on it.
https://github.com/protocol-registries/well-known-uris/issues/8#issuecomment-670269951


-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200809111100</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-09 11:11:00-0400</timestampReceived><subject>Re: [tor-dev] IANA well-known URI suffix registration "tor-relay"</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


nusenu:
&gt; submitted as:
&gt; https://github.com/protocol-registries/well-known-uris/issues/8
&gt; 
&gt; 
&gt; @nickm and Mike: Mark would like to hear your opinion on it.
&gt; https://github.com/protocol-registries/well-known-uris/issues/8#issuecomment-670269951


here is the background story about this 

https://medium.com/@nusenu/how-malicious-tor-relays-are-exploiting-users-in-2020-part-i-1097575c0cac
(specifically section "Better visualizations")

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200810133406</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-08-10 13:34:06-0400</timestampReceived><subject>Re: [tor-dev] IANA well-known URI suffix registration "tor-relay"</subject><body>

On Sat, Aug 8, 2020 at 3:37 AM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt;
&gt;
&gt; submitted as:
&gt; https://github.com/protocol-registries/well-known-uris/issues/8
&gt;
&gt;
&gt; @nickm and Mike: Mark would like to hear your opinion on it.
&gt; https://github.com/protocol-registries/well-known-uris/issues/8#issuecomment-670269951

I think as a general idea this is fine.  I could probably tweak the
format a bit, but there probably isn't a strong need.

One thing I'd want to know about though, is current uptake and trends
in uptake.  How many relays are currently using this schema?

I'm happy to say "yes, this is a good thing for family operators to
do" if that will help, but I'd rather that we only standardize
something if it's on track to get used.

peace,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200801134134</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-08-01 13:41:34-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

On Sat, Aug 1, 2020 at 6:10 AM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; nusenu:
&gt; &gt;&gt; The only question that came up was: Will there be two types of relay fingerprints
&gt; &gt;&gt; in the future (Ed25519)?
&gt; &gt;
&gt; &gt; I assume the correct proposal for the Ed25519 keys is this:
&gt; &gt; https://gitweb.torproject.org/torspec.git/tree/proposals/220-ecc-id-keys.txt
&gt; &gt;
&gt; &gt; I'm wondering what kind of format is used for a relay's Ed25519 ID in tor?
&gt; &gt;
&gt; &gt; The spec says base64:
&gt; &gt;
&gt; &gt;&gt;    When an ed25519 signature is present, there MAY be a "master-key-ed25519"
&gt; &gt;&gt;    element containing the base64 encoded ed25519 master key as a single
&gt; &gt;&gt;    argument.  If it is present, it MUST match the identity key in
&gt; &gt;&gt;    the certificate.
&gt; &gt;
&gt; &gt; examples:
&gt; &gt; grep master-key-ed 2020-07-28-19-05-00-server-descriptors |head -2
&gt; &gt;
&gt; &gt; master-key-ed25519 clT/2GWmTY/qU5TBGaudAIjOUUxUdKhMY/Q5riK6G2E
&gt; &gt; master-key-ed25519 qDI9PbwtiKzpR9phLnWI99uimdwNW8+l9c7hDoWV9dQ
&gt; &gt;
&gt; &gt; Is this the canonical format you use when referring to a relay's Ed25519 identity?
&gt;
&gt; I looked at what stem does in this area [1].
&gt; It uses the more accurate name "ed25519_master_key" instead of Ed25519 ID
&gt; and contains the above mentioned base64 encoded Ed25519 public master key
&gt; so I assume this is the canonical format since I didn't see any other representation.

I'd like to use "ed25519 identity" or even just "identity" here going
forward.  While it might make sense to use other names when describing
it in relation to other keys, when talking about the relay, it is an
identity key.

The base64-encoded form is the best one we have; whenever we output a
key, we use that format.

&gt; &gt; What command does a relay operator need to run to find out
&gt; &gt; his relay's Ed25519 ID on the command line?
&gt;
&gt; base64 encoding (parts of) the ed25519_master_id_public_key
&gt; file, provides the same output as in master-key-ed25519 descriptor lines
&gt; but I didn't find a spec for that key file to confirm the try and error approach
&gt; or a tor command to simply output the ed25519_master_key public key in base64 format.

I'd like to add such a command, as well as support for using ed25519
keys in more places in the UI and the control API.  I'm not going to
have time for a while, though, but if anybody would be interested in
hacking this together, I can point to some of the places in the code
you'd need to change.

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200801140023</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-01 14:00:23-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt;&gt; base64 encoding (parts of) the ed25519_master_id_public_key
&gt;&gt; file, provides the same output as in master-key-ed25519 descriptor lines
&gt;&gt; but I didn't find a spec for that key file to confirm the try and error approach
&gt;&gt; or a tor command to simply output the ed25519_master_key public key in base64 format.

I was wondering why the base64 string is 43 characters long for a 32byte Ed25519 key.
32*8/6=42


&gt; I'd like to add such a command

great, thanks!

&gt; as well as support for using ed25519
&gt; keys in more places in the UI and the control API.

maybe add a file similar to the datadir/fingerprint file
containing the base64 representation of the Ed25519 public key?
maybe datadir/ed25519_identity ?


-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200801220448</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-08-01 22:04:48-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt; I was wondering why the base64 string is 43 characters long for a 32byte Ed25519 key.
&gt; 32*8/6=42

That is because tor drops trailing '=' from base64 encoded values
within descriptors. Some fields indicate this within the spec, others
don't.

https://gitweb.torproject.org/stem.git/tree/stem/util/str_tools.py#n98

&gt; I'd like to use "ed25519 identity" or even just "identity" here going
&gt; forward.

Gotcha. The name of 'identity' makes me wonder how this relates to
relay fingerprints, which are the canonical identifier we use.

Regardless, the more we can standardize the terminology we use the
less confusing these fields will be.

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200801223055</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2020-08-01 22:30:55-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

Hi Damian,

&gt; On 2. Aug 2020, at 00:04, Damian Johnson &lt;atagar@torproject.org&gt; wrote:
&gt;
&gt;&gt; I'd like to use "ed25519 identity" or even just "identity" here going
&gt;&gt; forward.
&gt;
&gt; Gotcha. The name of 'identity' makes me wonder how this relates to
&gt; relay fingerprints, which are the canonical identifier we use.
&gt;
&gt; Regardless, the more we can standardize the terminology we use the
&gt; less confusing these fields will be.

The way I understand it is this: Relay fingerprints are based on the
RSA key, which will go away eventually. The canonical identifier will
be the identity. We should start that transition

Cheers
Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200801232527</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-08-01 23:25:27-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt; The way I understand it is this: Relay fingerprints are based on the
&gt; RSA key, which will go away eventually. The canonical identifier will
&gt; be the identity. We should start that transition

Thanks Sebastian. In that case we should put more thought into this
because fingerprints are foundational to our control and directory
specifications. Commands, events, descriptors... really everything
reference relays by fingerprint (or optionally sometimes nickname).
Migrating to a new identifier is no small task.

First, I'd advise that we call these 'v2 fingerprints' so it's clear
that we intend to substitute these anywhere traditional fingerprints
are used.

Second, I would advise against truncated base64 identifiers.
Fingerprints are 40 character hex. master-key-ed25519's base64 value
can include slashes (such as
"yp0fwtp4aa/VMyZJGz8vN7Km3zYet1YBZwqZEk1CwHI") which will be
problematic for DirPort urls, GETINFO commands, etc.

The simplest solution would be to simply hexify these values. This
will raise our fingerprint length from 40 to 64 characters which will
slightly impact DirPorts [1], but otherwise I don't anticipate a
problem with such a replacement.

============================================================

import base64


def hexify_id(ed25519_identifier):
  binary_id = base64.b64decode(ed25519_identifier +
((len(ed25519_identifier) % 4) * '='))
  return bytes.hex(binary_id).upper()


identifier = 'yp0fwtp4aa/VMyZJGz8vN7Km3zYet1YBZwqZEk1CwHI'
print('the hex id of "%s" is "%s"' % (identifier, hexify_id(identifier)))

============================================================

% python3.7 demo.py
the hex id of "yp0fwtp4aa/VMyZJGz8vN7Km3zYet1YBZwqZEk1CwHI" is
"CA9D1FC2DA7869AFD53326491B3F2F37B2A6DF361EB75601670A99124D42C072"

============================================================

Cheers! -Damian

[1] At most 96 server or extrainfo descriptors can be downloaded from
DirPorts via their fingerprint due to a limitation on the url length
by squid proxies...

https://gitweb.torproject.org/stem.git/commit/?id=871a957f

Maybe this is no longer relevant? If it is then raising the
fingerprint length from 40 to 64 will reduce this maximum to 60 (which
seems fine to me).
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200802004552</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-02 00:45:52-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; First, I'd advise that we call these 'v2 fingerprints' so it's clear
&gt; that we intend to substitute these anywhere traditional fingerprints
&gt; are used.

Isn't using "fingerprint" not a bit misleading since it is not the output of
a hash function but the ed25519 master public key itself?

&gt; Second, I would advise against truncated base64 identifiers.
&gt; Fingerprints are 40 character hex. master-key-ed25519's base64 value
&gt; can include slashes (such as
&gt; "yp0fwtp4aa/VMyZJGz8vN7Km3zYet1YBZwqZEk1CwHI") which will be
&gt; problematic for DirPort urls, GETINFO commands, etc.
&gt; 
&gt; The simplest solution would be to simply hexify these values. This
&gt; will raise our fingerprint length from 40 to 64 characters

to avoid increasing the length to 64 characters, how about using urlsafe base64
that does not make use of the "/" character?
https://tools.ietf.org/html/rfc4648#section-5
https://docs.python.org/3/library/base64.html#base64.urlsafe_b64encode



-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200802030848</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-08-02 03:08:48-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt; Isn't using "fingerprint" not a bit misleading since it is not the output of
&gt; a hash function but the ed25519 master public key itself?

Hi nusenu, that's fair. We've begun to conflate a couple concepts here...

* Relay operators, controllers, DirPorts, etc all require a canonical
relay identifier. They don't care how it's derived as long as it's
unique to the relay.

* Relays publish a public ed25519 key. This is an implementation
detail that isn't of interest to the above populations.

I'd advise against attempting to rename "fingerprint". That hasn't
gone well for hidden services [1]. But with that aside, relay
identifiers and the representation of ed25519 public keys don't
necessarily need to be one and the same.

[1] https://trac.torproject.org/projects/tor/ticket/25918
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200802095752</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-02 09:57:52-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Damian Johnson:
&gt;&gt; Isn't using "fingerprint" not a bit misleading since it is not the output of
&gt;&gt; a hash function but the ed25519 master public key itself?
&gt; 
&gt; Hi nusenu, that's fair. We've begun to conflate a couple concepts here...
&gt; 
&gt; * Relay operators, controllers, DirPorts, etc all require a canonical
&gt; relay identifier. They don't care how it's derived as long as it's
&gt; unique to the relay.
&gt; 
&gt; * Relays publish a public ed25519 key. This is an implementation
&gt; detail that isn't of interest to the above populations.
&gt; 
&gt; I'd advise against attempting to rename "fingerprint". That hasn't
&gt; gone well for hidden services [1]. But with that aside, relay
&gt; identifiers and the representation of ed25519 public keys don't
&gt; necessarily need to be one and the same.

I'll wait until you (Tor developers) decided on the final naming and format
and added a reference 

https://github.com/nusenu/tor-relay-well-known-uri-spec/commit/949980e72132ba20ca9f687ed8d0e8b43a333834

thanks,
nusenu

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200804224037</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-04 22:40:37-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


nusenu:
&gt; I'll wait until you (Tor developers) decided on the final naming and format

Is there any interest to move this topic forward to come to some decision 
in the near future? (before the end of the month) 

Here is a short summary of what opinions I observed for this topic (naming and format
for Ed25519 identities) so far:

Naming proposals for relay Ed25519 identities:
------------------------------------

'v2 fingerprints' (Damian)

"ed25519 identity" or even just "identity" (nickm)


Output format the Ed25519 relay IDs:
------------------------------------

base64 - 43 characters long (nickm)
  this is problematic due to the "/" sign (Damian)
hex - 64 characters long (Damian)
  "/" is problematic for DirPort urls, GETINFO commands, etc (Damian)
    isn't there urlencoding for URLs? (nusenu)
base64urlsafe - 43 characters long (nusenu)

I hope we can agree to use the same format in all places.

How does the decision process looks like in general in the Tor Project?


-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200804231158</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-08-04 23:11:58-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt; I hope we can agree to use the same format in all places.

Thanks nusenu, that's a great summary. Honestly I doubt that
deprecating RSA keys is on anyone's visible horizon, and by extension
RSA-based fingerprints will remain our canonical identifiers for the
foreseeable future.

That leaves our present default position as "ed25519 public identity
keys are a base64 encoded descriptor field that has no relationship to
fingerprints, but might become the basis for them in the future".

That said, I'm happy to discuss this topic further if Nick or the
Network team would like to do so.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200804232524</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-04 23:25:24-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Damian Johnson:
&gt;&gt; I hope we can agree to use the same format in all places.
&gt; 
&gt; Thanks nusenu, that's a great summary. Honestly I doubt that
&gt; deprecating RSA keys is on anyone's visible horizon, and by extension
&gt; RSA-based fingerprints will remain our canonical identifiers for the
&gt; foreseeable future.

That is fine. To clarify: I'm _not_ aiming to speed the transition
to a RSA1024 free tor world up (that is not my goal here).
I'd just like to see a decision on the naming and format that will be used from the point
the decision has been made - so I can point to it and use it in
the well-known URI submission.
If it is clear to you that we will not see a decision on the naming and format
in Aug 2020. That is also valuable information for me.



-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200807200651</emailId><senderName>Ladar Levison</senderName><senderEmail>ladar@lavabit.com</senderEmail><timestampReceived>2020-08-07 20:06:51-0400</timestampReceived><subject>Re: [tor-dev] CentOS 8 TOR Repo</subject><body>

[Attachment #2 (multipart/alternative)]


On 8/7/20 12:34 PM, Kushal Das wrote:
&gt; Our rpm repo for CentOS/RHEL requires EPEL repository enabled. It is th=
e
&gt; step 1 in our documentation [0].


After running into the issue I've already reported, I checked, and at
least for the moment, the EPEL version matches the package in the TOR
repo. So I switched back to using the EPEL version.


[Attachment #5 (text/html)]

&lt;html&gt;
  &lt;head&gt;
    &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;&lt;br&gt;
    &lt;/p&gt;
    &lt;div class="moz-cite-prefix"&gt;On 8/7/20 12:34 PM, Kushal Das wrote:&lt;br&gt;
    &lt;/div&gt;
    &lt;blockquote type="cite"
      cite="mid:20200807173402.zhcyz7f25z7v23tv@justhome"&gt;
      &lt;pre class="moz-quote-pre" wrap=""&gt;Our rpm repo for CentOS/RHEL requires EPEL \
repository enabled. It is the step 1 in our documentation [0].&lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;&lt;font face="Helvetica, Arial, sans-serif"&gt;After running into the
        issue I've already reported, I checked, and at least for the
        moment, the EPEL version matches the package in the TOR repo. So
        I switched back to using the EPEL version. &lt;br&gt;
      &lt;/font&gt;&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200810140119</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-08-10 14:01:19-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

On Tue, Aug 4, 2020 at 6:41 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; nusenu:
&gt; &gt; I'll wait until you (Tor developers) decided on the final naming and format
&gt;
&gt; Is there any interest to move this topic forward to come to some decision
&gt; in the near future? (before the end of the month)

I don't think that'd be too hard.

&gt; Here is a short summary of what opinions I observed for this topic (naming and format
&gt; for Ed25519 identities) so far:
&gt;
&gt; Naming proposals for relay Ed25519 identities:
&gt; ------------------------------------
&gt;
&gt; 'v2 fingerprints' (Damian)
&gt;
&gt; "ed25519 identity" or even just "identity" (nickm)
&gt;
&gt;
&gt; Output format the Ed25519 relay IDs:
&gt; ------------------------------------
&gt;
&gt; base64 - 43 characters long (nickm)
&gt;   this is problematic due to the "/" sign (Damian)
&gt; hex - 64 characters long (Damian)
&gt;   "/" is problematic for DirPort urls, GETINFO commands, etc (Damian)
&gt;     isn't there urlencoding for URLs? (nusenu)
&gt; base64urlsafe - 43 characters long (nusenu)
&gt;
&gt; I hope we can agree to use the same format in all places.
&gt;
&gt; How does the decision process looks like in general in the Tor Project?

I think right now Tor uses unpadded base64 in most internal formats,
but it doesn't actually use those in the user interface anywhere, so
we could just use base64urlsafe (per rfc4648 section 5) for the user
interface.

I would be fine with standardizing that for our API, but I'd want to
write a proposal for it first.  It wouldn't have to be long.  We'd
want to describe other places where we currently use regular base64
for 256-bit keys, and say whether we should/shouldn't accept and emit
url-safe identifiers there instead.

We should specify that there are no spaces, that the padding "="
characters are removed, and that even though the format as given can
handle 43*6==258 bits, the last two bits must be set to 0, since these
are only 256-bit identifiers.

We should also _probably_ specify some canonical encoding for a pair of keys.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200810182824</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-10 18:28:24-0400</timestampReceived><subject>Re: [tor-dev] IANA well-known URI suffix registration "tor-relay"</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Nick Mathewson:
&gt; I think as a general idea this is fine. 

thanks!

&gt; I could probably tweak the
&gt; format a bit, but there probably isn't a strong need.

how would you like to tweak it? 
I tried to keep it as simple as possible for relay operators
to keep adoption trivial.

&gt; One thing I'd want to know about though, is current uptake and trends
&gt; in uptake.  How many relays are currently using this schema?
&gt; 
&gt; I'm happy to say "yes, this is a good thing for family operators to
&gt; do" if that will help, but I'd rather that we only standardize
&gt; something if it's on track to get used.

The ContactInfo spec is used currently by 100 relays (&gt;12% exit probability).
The amount of relays using it increased from 44 to 100 after version 1
of the spec got released on 2020-07-21. The well-known URI will
be part of version 2.

regards,
nusenu

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200811204024</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-08-11 20:40:24-0400</timestampReceived><subject>Re: [tor-dev] CAPTCHA Monitoring Project's Dashboard</subject><body>

I messed up with replying to my own thread since I was receiving
emails in a digest. I'm sorry for creating a duplicate thread.
This email intends to reply to Georg's reply from the original thread.

&gt; Thanks for that wiki page. That's been really helpful. One thing I kept
&gt; wondering while reading through the different graph descriptions with
&gt; the default graph style in mind:
[..snip..]
&gt; So, what's the tick shown per day then? One consensus somehow picked or
&gt; data for all consensuses for that day? Or...?

I initially wanted to have per-day data points on the graphs, but
later I realized that it complicates the calculations a lot (and
increases the probability of making a mistake) since some relays show
up &amp; disappear (and their exit probabilities change) throughout the
day. So, I decided to calculate the CAPTCHA rates per each hourly
consensus to simplify calculations. There will be 24 data points
(representing each consensus) per day and 30 days of history in a
single graph. In total, there will be 24*30=720 data points in a
single graph. Since having 720 labels similar to "2020-07-18 14:00" in
the x-axis would be too cluttered, I decided to put ticks for each
whole day and label them only rather than labeling every single data
point. I hope this explanation makes it more clear. I will update the
wiki and example graph on the wiki to reflect what I just explained.

&gt; How do you plan to show those graphs on the dashboard? Are they all
&gt; shown in some order? Grouped by sections (maybe along those on the
&gt; wiki)? Grouped by "importance"?

I plan to have separate pages for each section mentioned in the wiki.
In addition to that, I plan to have a "highlights" page to show a
quick summary of all graphs. People visiting the dashboard will first
see the highlights and later check more detailed graphs if they are
interested in seeing them. I agree that there is a lot of information
for a visitor to digest, and making this process as effortless as
possible is one of my top priorities.

&gt; Somewhat related to that, I think we can try reducing the number of
&gt; graphs, at least those which are greatly related.
[..snip..]
&gt; One thing that could be useful here
&gt; is having a switch/buttons next to the graph giving the user the option
&gt; to see "by exit relay age" for all CAPTCHAs, or for Cloudflare ones, or
&gt; for Akamai ones or for... depending on the switch/button the users
&gt; clicked on. The graph would update accordingly once clicked, showing the
&gt; user choice. The default could be for all CAPTCHAs or essentially
&gt; whatever we think is more important for us. That way you have related
&gt; things grouped together AND you have less graphs shown per default on
&gt; the dashboard, too, which might help not getting confused.

A few other people suggested using this approach as well, and I like
it! I will place buttons to achieve what you have suggested. On top of
this, there will be checkboxes next to graphs for users to make
decisions on what to include in the graphs, and the graphs will be
updated accordingly. The default values will be configured in a way to
reflect what we care about most. For example, both "Tor Browser" and
"Firefox over Tor" measurements could be used to calculate the CAPTCHA
rates, but only "Tor Browser" checkbox will be checked by default, and
the user will have the ability to include "Firefox over Tor" and
others into calculations.

This gives the user the ability to compare different options easily.
That said, I wonder if having too many options is another problem for
users. It might lead to confusion, and determining the right balance
is still an open issue.

Thank you for your feedback!

Best,
Barkin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200812201800</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-08-12 20:18:00-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

On Mon, Aug 10, 2020 at 09:00:32AM -0400, Nick Mathewson wrote:
&gt; On Wed, Jul 29, 2020 at 1:15 AM Matthew Finkel &lt;sysrqb@torproject.org&gt; wrote:
&gt; &gt;
&gt; &gt; Hello everyone,
&gt; 
&gt; Hi, Matt!
&gt; 
&gt; There's a part of this that I'm still trying to figure out:
&gt; 
&gt; &gt; The safest usage of the long-term keys for alternative purposes I see
&gt; &gt; appears to be by deriving a (fixed/deterministic) blinded key pair using
&gt; &gt; the same scheme that Tor uses, and signing/verification simply follow
&gt; &gt; the same process as Tor, except the derived keys need not rotate
&gt; &gt; periodically (is this true?). The derived key should be used for
&gt; &gt; certifying a freshly generated ed25519 key, which is used in the
&gt; &gt; application protocol. For example, if I want to use a key for code
&gt; &gt; signing such that it is bound to my onion service key, then I could
&gt; &gt; derive a certifying key by following Tor's derivation scheme, by
&gt; &gt; substituting:
&gt; &gt;
&gt; &gt;   BLIND_STRING = "Derive temporary signing key" | INT_1(0)
&gt; &gt;   N = "key-blind" | INT_8(period-number) | INT_8(period_length)
&gt; &gt;
&gt; &gt; with
&gt; &gt;
&gt; &gt;   BLIND_STRING = "Derive code signing key" | INT_1(0)
&gt; &gt;   N = "code-sigining-key-blind" | "v0" | "YYYY-MM-DD" |  INT_8(validity_period)
&gt; 
&gt; In the case of v3 onion services, 'period-number' comes from the
&gt; current time, and 'period-length' comes from the consensus, so it's
&gt; easy for the client to know what parameters to use when deriving the
&gt; key.
&gt; 
&gt; But how is the party that relies on the derived key supposed to know
&gt; what values were used for "YYYY-MM-DD" and "validity period" in this
&gt; case?  It seems like those two values would need to be shipped along
&gt; with the key, which could make for logistical issues.

I was imagining "just serialize it in the public key". The public key
would grow by a few more characters, but not too much. In this case,
we'd probably want a defined (extensible) structure for the public key
rather than each application defining their own arbitrary format, but I
didn't get that far in thinking about it.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200814091458</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-08-14 09:14:58-0400</timestampReceived><subject>Re: [tor-dev] Can "ExcludeNodes" be used multiple times in torrc?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Damian Johnson:
&gt; Hi nusenu, tor's manual says [1]...
&gt; 
&gt; "To split one configuration entry into multiple lines, use a single
&gt; backslash character (\) before the end of the line. Comments can be
&gt; used in such multiline entries, but they must start at the beginning
&gt; of a line."

Thank you Damian!
Reading the above I didn't expect that you can create
a multiline entry without "\" before the end of the line.

Now I'll play around to see how this works if a single 
multiline entry is split across multiple included files.

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200814175753</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2020-08-14 17:57:53-0400</timestampReceived><subject>[tor-dev] (FWD) [network-team] Hand-off notes for Nick's vacation</subject><body>

Forwarding with permission from Nick, since he sent it to only a sekrit
list, and it should go to a public list.

Onward and upward,
--Roger

----- Forwarded message from Nick Mathewson &lt;nickm@torproject.org&gt; -----

Date: Fri, 14 Aug 2020 13:52:02 -0400
From: Nick Mathewson &lt;nickm@torproject.org&gt;
To: network-team &lt;network-team@lists.torproject.org&gt;
Subject: [network-team] Hand-off notes for Nick's vacation

Hi!

You can also read this at
https://gitlab.torproject.org/nickm/notes/-/wikis/Vacation2020 -- it
is a list of stuff I thought might be helpful or important to think
about while I'm away.

This is me signing off for the next while.  As documented in the
calendar, I'll be back on 14 September.  If you need to contact me in
the meanwhile, please use Signal or personal email.  I'll be routing
all mailing lists to a "Post-Vacation" folder.

I'm going to use this email to checkpoint a few things before I go
off, so it'll be easier to pick them up.  I've asked George to help me
write it.

I've sorted this list in order of decreasing priority.

# 0.4.4

We are planning to release a stable 0.4.4 release on 15 September.
That's the day after I get back.  I just put out an 0.4.4.4-rc release
on 13 August.

There are still some 044-must/044-should issues that

I think we have several possible choices here:

  * If there are no further risky changes in 0.4.4 between now and 15
September, we can just release 0.4.4 stable on that date.
  * If we want to do futher risky changes between now and 15
September, it would probably be okay to plan for another release
candidate on 1 September. That would let me put out a stable when I
get back.
  * If you don't do a release candidate between now and when I get
back, but there _are_ risky changes, then we should put out a release
candidate when I'm back, and we can plan to put out the stable 2-3
weeks after that.

I have updated the ReleasingTor.md documentation in the master branch
to reflect current practice.

There is a ticket at
https://gitlab.torproject.org/tpo/core/team/-/issues/11 to track
things we need to do for the release.  Please make sure that the
"must" and "should" tickets get triaged and handled (or not handled)
as appropriate.

# Caitlin's internship

Caitlin has been working on
https://gitlab.torproject.org/tpo/core/tor/-/issues/40066 ??? there is a
patch with a merge request. Please make sure to give them all the help
they need, and answer their questions promptly and usefully: if I
understand correctly, their internship ends at the end of month.

# Sponsor 55

Sponsor 55 will come to an end over the weekend.  For a list of what
we've done, have a look at
https://gitlab.torproject.org/tpo/core/team/-/wikis/NetworkTeam/Sponsor55Report
.  I sent a copy of this pad to gaba and david under the heading
"sponsor 55 - what was worked on (so we can start having stuff
together for the report)".

There are remaining tickets labeled with "sponsor 55".  I believe that
none of them are must-do items for the sponsor.  But some of them are
things we need to do before we can release 0.4.5, and some of them are
things that we should do while the code is still fresh in our heads.
I will try to sort these out as much as I can before I go, but there
may be remaining tickets for you to sort.

https://gitlab.torproject.org/tpo/core/team/-/issues/12 is the
tracking ticket for removing the S55 label from the remaining tickets.

# Gitlab best practices

IMPORTANT: Make sure you are seeing new tickets in tpo/core/tor that
do not mention you specifically.  This may not be the default.  You
can do this either by looking at the complete list of tickets every
day or two, then skipping to the end... or by updating the settings in
"User settings &gt; notifications" at
https://gitlab.torproject.org/profile/notifications .

When somebody submits a patch but not a merge request, please ask them
to do a merge request if they can, and open one for them if they
can't.

If a volunteer has been sitting on a needs_revision patch for a long
time, consider asking them for permission to take it over and fix it
up.

# 0.4.5 best practices

Please remember how to handle tickets that are possibly backportable.

When making a Merge Request:

  1. Make the branch against the target maint-0.x.y branch.
  2. Make your merge request against the target maint-0.x.y branch.
  3. Note that the MR is backportable in your MR message.

When merging, if it is even _possible_ we want to backport more:

  1. Give the MR the "Backport" label.
  2. Un-assign yourself from the MR: you don't need to review it any more.
  3. Put the MR into the latest milestone to which it has not been backported.

# Tickets and MRs assigned to Nick

There are a bunch of tickets still assigned to me.  Please feel to
take any of them over that you want.  I'm going to go through them and
unasssign any that I think should be handled before I'm back, with
notes.

If you review an MR that I wrote and it needs changes, please consider
making those changes yourself or getting somebody else to do so, if
you feel that you can.  I won't mind, and it's probably better if this
code doesn't rot for a whole month.

# CI

We now have CI running on gitlab, with debian-stable.  It covers (I
believe) hardened builds, gcc, clang, stem, chutney, distcheck, and
documentation.  It's implemented in .gitlab.yml and in scripts/ci/ .
Feel free to hack on it, but make sure to make any changes to
maint-0.3.5 and merge them forward from there: it was really
unpleasant to have our appveyor and travis files diverge among
versions.

There are more changes to make, and please feel free to move ahead
with this stuff: I've tried to update stuff on trac as we go.

https://gitlab.torproject.org/tpo/core/tor/-/issues/40048 is the
ticket for moving to gitlab CI.

Also please remember that super-slow CI is not our friend. You can
make hardened builds run much faster by merging tpo/core/tor#40088,
once you trust it. :)

# 0.4.5 planning

Please feel free to make progress on planning and coding stuff for
045, but keep im mind that technical debt and leftovers from 044 would
also be very smart things to work on.

The ticket where our discussions have been happening is:
https://gitlab.torproject.org/tpo/core/team/-/issues/7

# TROVE-2020-005

We have an open low-severity issue tracked as tpo/core/tor#40080
(private) and tpo/core/tor#40086 (public).  More thought there would
always be valuable.  If it is indeed low-severity, the it's okay to
merge it in 044 if you like it and are confident in it. But please be
careful: the code is subtle.

# Tor ticket triage

I closed our original ticket triage activity, and opened a new one:
https://gitlab.torproject.org/tpo/core/team/-/issues/10

Feel free to do as much or as little here as you think good, and/or to
come up with different ideas.

# Blog post comments

We're supposed to moderate comments on all our blog posts, and I just
put out a release (0.4.4.4-rc) on 13 August.  Please keep an eye on
the comments there and approve the ones that are on-topic.

# Defer till later: rename 'master', autostyle the code.

We're planning to rename "master" to "main", and to get clang-format
running happily on our code.  Both of these are deferred till I get
back in September.

----- End forwarded message -----

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200817151913</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-08-17 15:19:13-0400</timestampReceived><subject>Re: [tor-dev] proposal for "tor-relay" well-known URI</subject><body>

[Attachment #2 (multipart/signed)]


On 14 Aug (12:17:50), nusenu wrote:
&gt; Hi,
&gt; 
&gt; I'm submitting this as a proposal according to:
&gt; https://github.com/torproject/torspec/blob/master/proposals/001-process.txt
&gt; 
&gt; I made a PR request for you:
&gt; https://github.com/torproject/torspec/pull/129/files

Thanks nusenu!

FYI, the merge request to tor-spec.git is here:
https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/3

Cheers!
David

-- 
9EcBLQe/UEFMDMsq6J3D9gjc6jA4j/h0yj8TyjEx6t4=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200820193006</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-08-20 19:30:06-0400</timestampReceived><subject>Re: [tor-dev] Store Salmon-related information in Tor Browser?</subject><body>

On Thu, Aug 20, 2020 at 11:30:09AM -0700, Philipp Winter wrote:
&gt; We recently started experimenting with the Salmon social bridge
&gt; distributor:
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/31873
&gt; 
&gt; We are now exploring the possibility of storing some Salmon-related data
&gt; on a user's computer and are wondering what our options are.  The data
&gt; we're talking about is a lightweight, signed, and encrypted blurb that
&gt; contains a user's social graph, proxies, and registration ID.
&gt; 
&gt; One option to store this data is Tor's data directory but that doesn't
&gt; seem ideal because Salmon isn't a PT and technically has nothing to do
&gt; with Tor.  Is Tor Browser an option here?  Or does the "disk avoidance"
&gt; design goal mean that we don't get to store anything at all?  A last
&gt; resort option would be to simply hand the blurb to the user and ask them
&gt; to store it somewhere but we would like to find a more usable way to
&gt; handle this.

This is a really good question. Tor Browser's "Disk Avoidance" goal is
"prevent all disk records of browser activity" [0]. However, this is
only the default operating mode. A user should be given the option of
recording certain browser activity on disk (such as saving bookmarks).

In the case of Salmon, writing a person's social graph and ID on disk
(encrypted or plaintext) is a requirement of a user participating in the
Salmon distributor, yes? While Salmon is not the only distributor, I
think writing it within Tor Browser's directory is an appropriate place
as long as the user is given sufficient information about the data
contained in the file and they consent to storing it (participating).

Overall, putting the burden on the user for saving the file somewhere
else seems really bad for usability (and, therefore, security and
privacy). I can imagine saving the file externally being an option, but
I don't think it should be the default.

Hopefully this helps, but please let me know if I can clarify anything
more.

- Matt

[0] https://2019.www.torproject.org/projects/torbrowser/design/#disk-avoidance
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200826142013</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-08-26 14:20:13-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

tevador &lt;tevador@gmail.com&gt; writes:

&gt; Hi all,
&gt;

Hello tevador,

thanks so much for your work here and for the great simulation. Also for
the hybrid attack which was definitely missing from the puzzle.

I've been working on a further revision of the proposal based on your
comments. I have just one small question I would like your feedback on.

&gt;&gt; 3.4.3. PoW effort estimation [EFFORT_ESTIMATION]
&gt;&gt; {XXX: BLOCKER: Figure out of this system makes sense}
&gt;
&gt; I wrote a simple simulation in Python to test different ways of
&gt; adjusting the suggested effort. The results are here:
&gt; https://github.com/tevador/scratchpad/blob/master/tor-pow/effort_sim.md
&gt;
&gt; In summary, I suggest to use MIN_EFFORT = 1000 and the following
&gt; algorithm to calculate the suggested effort:
&gt;
&gt; 1. Sum the effort of all valid requests that have been received since the
&gt;    last HS descriptor update. This includes all handled requests, trimmed
&gt;    requests and requests still in the queue.
&gt; 2. Divide the sum by the max. number of requests that the service could have
&gt;    handled during that time (SVC_BOTTOM_CAPACITY * HS_UPDATE_PERIOD).
&gt; 3. Suggested effort = max(MIN_EFFORT, result)
&gt;
&gt; This algorithm can both increase and reduce the suggested effort.
&gt;

I like the above logic but I'm wondering of how we can get the real
SVC_BOTTOM_CAPACITY for every scenario. In particular, the
SVC_BOTTOM_CAPACITY=180 value from 6.2.2 might have been true for
David's testing but it will not be true for every computer and every
network.

I wonder if we can adapt the above effort estimation algorithm to use an
initial SVC_BOTTOM_CAPACITY magic value for the first run (let's say
180), but then derive the real SVC_BOTTOM_CAPACITY of the host in
runtime and use that for subsequent runs of the algorithm.

Do you think this is possible?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200831164250</emailId><senderName>Gaba</senderName><senderEmail>gaba@torproject.org</senderEmail><timestampReceived>2020-08-31 16:42:50-0400</timestampReceived><subject>Re: [tor-dev] CAPTCHA Monitoring Project Final Report</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


El 8/31/20 a las 9:22 AM, Barkin Simsek escribi:
&gt; Hi everyone,
&gt; 
&gt; The end of the Google Summer of Code period has arrived, and you can
&gt; find my GSoC final report for the CAPTCHA Monitoring project here [1].
&gt; This was my first time working with an active open source community
&gt; and I enjoyed it a lot! The feedback you have provided made the
&gt; experience worthwhile and exciting. I couldn't finish implementing all
&gt; of the features I planned, so I will be around and I plan to stay
&gt; active. I want to thank my mentors GeKo &amp; arma and everyone who helped
&gt; me with the project!
&gt; 
&gt; Best,
&gt; Barkin


Thanks so much for the great work you did!


&gt; 
&gt; [1] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2020
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 

-- 
she/her are my pronouns
GPG Fingerprint EE3F DF5C AD91 643C 21BE  8370 180D B06C 59CA BD19


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200831222438</emailId><senderName>Jim Newsome</senderName><senderEmail>jnewsome@torproject.org</senderEmail><timestampReceived>2020-08-31 22:24:38-0400</timestampReceived><subject>Re: [tor-dev] Using linux perf tool to look at sleep times</subject><body>

cc tor-dev for real this time :)

On 8/31/20 17:23, Jim Newsome wrote:
&gt; Hi David, (cc tor-dev in case others are interested or know anything
&gt; about it)
&gt;
&gt; I'm told you're the local expert on the linux perf tool :). I'm using it
&gt; to profile sleep times in Shadow, using the instructions here:
&gt; https://perf.wiki.kernel.org/index.php/Tutorial#Profiling_sleep_times
&gt;
&gt; perf unfortunately splits the data both by what the scheduler is
&gt; switching from (which I want) and what it's switching to (which I
&gt; don't). e.g. I have two separate lines:
&gt;
&gt; +   13.46%    13.46%  prev_comm=shadow prev_pid=24996 prev_prio=120
&gt; prev_state=S ==&gt; next_comm=swapper/3 next_pid=0 next_prio=120
&gt; +   11.57%    11.57%  prev_comm=shadow prev_pid=24996 prev_prio=120
&gt; prev_state=S ==&gt; next_comm=swapper/2 next_pid=0 next_prio=120
&gt;
&gt; I'd rather these were merged into a single "prev_comm=shadow
&gt; prev_pid=24996 prev_prio=120 prev_state=S" bucket.
&gt;
&gt; Any ideas?
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200701004835</emailId><senderName>Daniel Pinto</senderName><senderEmail>danielpinto52@gmail.com</senderEmail><timestampReceived>2020-07-01 00:48:35-0400</timestampReceived><subject>[tor-dev] Docker containers to run tor with multiple glibc versions</subject><body>

Hello,

I've been investigating some bugs related to the seccomp sandbox. While
doing this, I've developed some docker containers that can run tor with
different versions of glibc. As this might be useful for future
problems, I wanted to share them.

You can find the containers in my github repository:
https://github.com/Jigsaw52/docker-containers-glibc-tor

I've created containers for the currently supported versions of Ubuntu
and Debian. Each container builds the glibc versions with which I was
able to start the tor built on that container. They also download and
build tor from the current master branch and create a test torrc which
enables Sandbox and %includes folders and files in the home folder of
user user. There is also a container for alpine to test tor with musl libc.

To run a program with a specific version of glibc, use the command:
run_with_glibc &lt;GLIBC_VERSION&gt; &lt;PROGRAM_PATH&gt; [&lt;ARGS&gt;]

You can see which glibc versions are installed in /opt/ or in the
dockerfile. On the root user home folder, you will find a script
install_glibc.sh that will download and build the glibc versions passed
as arguments. The script supports glibc 2.13 and above. If you need to
build versions of glibc before 2.13, the following page will be helpful:
https://www.lordaro.co.uk/posts/2018-08-26-compiling-glibc.htm

Even though we can build glibc 2.13, even the oldest containers (Debian
8 and Ubuntu 14.04) are only able to run tor with starting with glibc
2.17. This is because the tor binary built in the container (using the
container system glibc) requires symbols for glibc 2.17. According to
this page
(https://gist.github.com/wagenet/35adca1a032cec2999d47b6c40aa45b1) this
provides coverage for the glibc versions present in the supported
versions of the top 10 Linux distros, except for CentOS 6.10 which EOLs
in November. Two containers (Ubuntu 14.04 and 18.04 or Debian 8 and
Debian 10) are enough to cover the glibc versions from 2.17 to 2.31.

Best regards,
-- 
Daniel Pinto
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200701144153</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-07-01 14:41:53-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]


On 22 Jun (17:52:44), George Kadianakis wrote:
&gt; Hello there,
&gt; 
&gt; here is another round of PoW revisions:
&gt;      https://github.com/asn-d6/torspec/tree/pow-over-intro
&gt; I'm inlining the full proposal in the end of this email.
&gt; 
&gt; Here is a changelog:
&gt; - Actually used tevador's EquiX scheme as our PoW scheme for now. This is still
&gt;   tentative, but I needed some ingredients to cook with so I went for it.
&gt; - Fold in David's performance measurements and use them to get some
&gt;   guesstimates on the default PoW difficulty etc.
&gt; - Enable overlapping seed system.
&gt; - Enrich the attack section of the proposal some more.
&gt; - Attempt to fix an effort estimation attack pointed by tevador.
&gt; - Added a bunch of "BLOCKER" tags around the proposal for things that we need
&gt;   to figure out or at least have some good intuition if we want to have
&gt;   guarantees that the proposal can work before we start implementing.
&gt; 
&gt; Here is what needs to happen next:
&gt; 
&gt; - David's performance measurements have been really useful, but they open a
&gt;   bunch of questions on auxiliary overheads. We are now performing more
&gt;   experiments to confirm the performance numbers we got and make sure we are
&gt;   not overshooting. I noted these issues down as BLOCKER in the proposal.
&gt;   While doing so we also found a pretty serious bug with our scheduler that we
&gt;   trying to fix:
&gt;      https://gitlab.torproject.org/tpo/core/tor/-/issues/40006

[snip]

(For the record)

Ok now that this bug has been fixed here are the new numbers. The time per
INTRO2 cell, on average, is the same as in the proposal.

Big difference is that Tor is not handling on average ~15 cells per mainloop
round during heavy DDoS. It is 15 and not 32 (theoretical limit) because the
service also handles a lot of DESTROY cells due to the rendezvous circuit
failing but also due to some seconds where no cells are processed because tor
is busy doing other things.

We've also confirmed that the theoretical value of 180 requests per second in
the proposal actually is valid. During high DDoS time, we've observed on
average 165 cells per second (by removing few outliers since tor has other
events that prevents cell processing for 1-3 seconds sometimes.

We've observed rate of 185cells/second so the 180 numbers holds here imo.

Cheers!
David

-- 
aivM0ymbv1PERLUJ1ZMsGtCDACQ3MpuWDLc0zbwJjqQ=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200702213149</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-07-02 21:31:49-0400</timestampReceived><subject>[tor-dev] Proposal: RTT-based Congestion Control for Tor</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


https://github.com/mikeperry-tor/torspec/blob/rtt-congestion-control/proposals/324-rtt-congestion-control.txt
 https://github.com/torproject/torspec/pull/125


================================

Filename: 324-rtt-congestion-control.txt
Title: RTT-based Congestion Control for Tor
Author: Mike Perry
Created: 02 July 2020
Status: Open


0. Motivation [MOTIVATION]

This proposal specifies how to incrementally deploy RTT-based congestion
control and improved queue management in Tor. It is written to allow us
to first deploy the system only at Exit relays, and then incrementally
improve the system by upgrading intermediate relays.

Lack of congestion control is the reason why Tor has an inherent speed
limit of about 500KB/sec for downloads and uploads via Exits, and even
slower for onion services. Because our stream SENDME windows are fixed
at 500 cells per stream, and only ~500 bytes can be sent in one cell,
the max speed of a single Tor stream is 500*500/circuit_latency. This
works out to about 500KB/sec max sustained throughput for a single
download, even if circuit latency is as low as 500ms.

Because onion services paths are more than twice the length of Exit
paths (and thus more than twice the circuit latency), onion service
throughput will always have less than half the throughput of Exit
throughput, until we deploy proper congestion control with dynamic
windows.

Proper congestion control will remove this speed limit for both Exits
and onion services, as well as reduce memory requirements for fast Tor
relays, by reducing queue lengths.

The high-level plan is to use Round Trip Time (RTT) as a primary
congestion signal, and compare the performance of two different
congestion window update algorithms that both use RTT as a congestion
signal.

The combination of RTT-based congestion signaling, a congestion window
update algorithm, and Circuit-EWMA will get us the most if not all of
the benefits we seek, and only requires clients and Exits to upgrade to
use it. Once this is deployed, circuit bandwidth caps will no longer be
capped at ~500kb/sec by the fixed window sizes of SENDME; queue latency
will fall significantly; memory requirements at relays should plummet;
and transient bottlenecks in the network should dissipate.

Extended background information on the choices made in this proposal can
be found at:
  https://lists.torproject.org/pipermail/tor-dev/2020-June/014343.html
  https://lists.torproject.org/pipermail/tor-dev/2020-January/014140.html

An exhaustive list of citations for further reading is in Section
[CITATIONS].


1. Overview [OVERVIEW]

This proposal has five main sections, after this overview. These
sections are referenced [IN_ALL_CAPS] rather than by number, for easy
searching.

Section [CONGESTION_SIGNALS] specifies how to use Tor's SENDME flow
control cells to measure circuit RTT, for use as an implicit congestion
signal. It also specifies an explicit congestion signal, which can be
used as a future optimization once all relays upgrade.

Section [CONTROL_ALGORITHMS] specifies two candidate congestion window
upgrade mechanisms, which will be compared for performance in simulation
in Shadow, as well as evaluated on the live network, and tuned via
consensus parameters listed in [CONSENSUS_PARAMETERS].

Section [FLOW_CONTROL] specifies how to handle back-pressure when one of
the endpoints stops reading data, but data is still arriving. In
particular, it specifies what to do with streams that are not being read
by an application, but still have data arriving on them.

Section [SYSTEM_INTERACTIONS] describes how congestion control will
interact with onion services, circuit padding, and conflux-style traffic
splitting.

Section [EVALUATION] describes how we will evaluate and tune our
options for control algorithms and their parameters.

Section [PROTOCOL_SPEC] describes the specific cell formats and
descriptor changes needed by this proposal.

Section [SECURITY_ANALYSIS] provides information about the DoS and
traffic analysis properties of congestion control.


2. Congestion Signals [CONGESTION_SIGNALS]

In order to detect congestion at relays on a circuit, Tor will use
circuit Round Trip Time (RTT) measurement. This signal will be used in
slightly different ways in our various [CONTROL_ALGORITHMS], which will
be compared against each other for optimum performance in Shadow and on
the live network.

To facilitate this, we will also change SENDME accounting logic
slightly. These changes only require clients, exits, and dirauths to
update.

As a future optimization, we also specify an explicit congestion signal.
This signal *will* require all relays on a circuit to upgrade to support
it, but it will reduce congestion by making the first congestion event
on a circuit much faster to detect.

2.1 RTT measurement

Recall that Tor clients, exits, and onion services send
RELAY_COMMAND_SENDME relay cells every CIRCWINDOW_INCREMENT (100) cells
of received RELAY_COMMAND_DATA.

This allows those endpoints to measure the current circuit RTT, by
measuring the amount of time between sending of every 100th data cell
and the arrival of the SENDME command that the other endpoint
immediately sends to ack that 100th cell.

Circuits will record the current RTT measurement as a field in their
circuit_t data structure. They will also record the minimum and maximum
RTT seen so far.

Algorithms that make use of this RTT measurement for congestion
window update are specified in [CONTROL_ALGORITHMS].

2.2. SENDME behavior changes

We will make four major changes to SENDME behavior to aid in computing
and using RTT as a congestion signal.

First, we will need to establish a ProtoVer of "CCtrl=1" to signal
support by Exits for the new SENDME format and congestion control
algorithm mechanisms.  We will need a similar announcement in the onion
service descriptors of services that support congestion control.

Second, we will turn CIRCWINDOW_INCREMENT into a consensus parameter
'circwindow_inc', instead of using a hardcoded value of 100 cells. It is
likely that more frequent SENDME cells will provide quicker reaction to
congestion, since the RTT will be measured more often. If
experimentation in Shadow shows that more frequent SENDMEs reduce
congestion and improve performance but add significant overhead, we can
reduce SENDME overhead by allowing SENDME cells to carry stream data, as
well.

  TODO: If two endpoints view different consensus parameters for
        'circwindow_inc', we will have complications measuring RTT,
        as well as complications for authenticated SENDME hash
        accounting. We need a way for endpoints to negotiate SENDME
        pacing with eachother, perhaps during circuit setup. This will
        require changes to the Onionskin/CREATE cell format (and
        RELAY_COMMAND_EXTEND), as mentioned in Section [PROTOCOL_SPEC].

Second, all end-to-end relay cells except RELAY_COMMAND_DROP and
RELAY_COMMAND_INTRODUCE1 will count towards SENDME cell counts. The
details behind how these cells are handled is addressed in section
[SYSTEM_INTERACTIONS].

   TODO: List any other exceptions. There probably are some more.

Third, authenticated SENDMEs can remain as-is in terms of protocol
behavior, but will require some implementation updates to account for
variable window sizes and variable SENDME pacing. In particular, the
sendme_last_digests list for auth sendmes needs updated checks for
larger windows and CIRCWINDOW_INCREMENT changes. Other functions to
examine include:
     - circuit_sendme_cell_is_next()
     - sendme_record_cell_digest_on_circ()
     - sendme_record_received_cell_digest()
     - sendme_record_sending_cell_digest()
     - send_randomness_after_n_cells

Fourth, stream level SENDMEs will be eliminated. Details on handling
streams and backpressure is covered in [FLOW_CONTROL].

2.3. Backward ECN signaling [BACKWARD_ECN]

As an optimization after the RTT deployment, we will deploy an explicit
congestion control signal by allowing relays to modify the
cell_t.command field when they detect congestion, on circuits for which
all relays have support for this signal (as mediated by Tor protocol
version handshake via the client). This is taken from the Options
mail[1], section BACKWARD_ECN_TOR.

To detect congestion in order to deliver this signal, we will deploy a
simplified version of the already-simple CoDel algorithm on each
outbound TLS connection at relays.
   https://queue.acm.org/detail.cfm?id=2209336
   https://tools.ietf.org/html/rfc8289

Each cell will get a timestamp upon arrival at a relay that will allow
us to measure how long it spends in queues, all the way to hitting a TLS
outbuf.

The duration of total circuitmux queue time for each cell will be
compared a consensus parameter 'min_queue_target', which is set to 5% of
min network RTT. (This mirrors the CoDel parameter of the same name).

As soon as a cell of a circuit spends more than this time in queues, a
per-circuit flag 'ecn_exit_slow_start' will be set to 1. As soon as a
cell is available in the opposite direction on that circuit, the relay
will flip the cell_t.command of from CELL_COMMAND_RELAY to
CELL_COMMAND_RELAY_CONGESTION. (We must wait for a cell in the opposite
direction because that is the sender that caused the congestion).

This enhancement will allow endpoints to very quickly exit from
[CONTROL_ALGORITHM] "slow start" phase (during which, the congestion
window increases exponentially). The ability to more quickly exit the
exponential slow start phase during congestion will help reduce queue
sizes at relays.

To avoid side channels, this cell must only be flipped on
CELL_COMMAND_RELAY, and not CELL_COMMAND_RELAY_EARLY. Additionally, all
relays MUST enforce that only *one* such cell command is flipped, per
direction, per circuit. Any additional CELL_COMMAND_RELAY_CONGESTION
cells seen by any relay or client MUST cause those circuit participants
to immediately close the circuit.

As a further optimization, if no relay cells are pending in the opposite
direction as congestion is happening, we can send a zero-filled cell
instead. In the forward direction of the circuit, we can send this cell
without any crypto layers, so long as further relays enforce that the
contents are zero-filled, to avoid side channels.


3. Congestion Window Update Algorithms [CONTROL_ALGORITHMS]

We specify two candidate window update algorithms. The specification
describes the update algorithms for the slow start phase and the
steady state phase separately, with some explanation. Then the
combined algorithm is given.

Note that these algorithms differ slightly from the background tor-dev
mails[1,2], due to corrections and improvements. Hence they have been
given different names than in those two mails.

These algorithms will be evaluated by running Shadow simulations, to
help determine parameter ranges, but experimentation on the live network
will be required to determine which of these algorithms performs best
when in competition with our current SENDME behavior, as used by real
network traffic. This experimentation and tuning is detailed in section
[EVALUATION].

All of these algorithms have rules to update 'cwnd' - the current
congestion window. In the C Tor reference implementation, 'cwnd' is
called the circuit 'package_window'. C Tor also maintains a
'deliver_window', which it uses to track how many cells it has received,
in order to send the appropriate number of SENDME acks.

  TODO: This 'deliver_window' count can be updated by the other
        endpoint using the congestion control rules to watch for
        cheating. Alternatively, it can be simplified just to count
        the number of cells we get until we send a SENDME.

Implementation of different algorithms should be very simple - each
algorithm should have a different set of package_window update functions
depending on the selected algorithm, as specified by consensus parameter
'cc_alg'.

For C Tor's current flow control, these functions are defined in sendme.c,
and are called by relay.c:
  - sendme_note_circuit_data_packaged()
  - sendme_circuit_data_received()
  - sendme_circuit_consider_sending()
  - sendme_process_circuit_level()

Despite the complexity of the following algorithms in their TCP
implementations, their Tor equivalents are extremely simple, each being
just a handful of lines of C. This simplicity is possible because Tor
does not have to deal with out-of-order delivery, packet drops,
duplicate packets, and other network issues at the circuit layer, due to
the fact that Tor circuits already have reliability and in-order
delivery at that layer.

We are also removing the aspects of TCP that cause the congestion
algorithm to reset into slow start after being idle for too long, or
after too many congestion signals. These are deliberate choices that
simplify the algorithms and also should provide better performance for
Tor workloads.

  TODO: We may want to experiment with adding revert-to-slow-start back
        in, but slow start is very expensive in a lot of ways, so let's
        see if we can avoid falling back into it, if at all possible.

3.1. Tor Westwood: TCP Westwood using RTT signaling [TOR_WESTWOOD]
   http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-westwood

http://nrlweb.cs.ucla.edu/nrlweb/publication/download/99/2001-mobicom-0.pdf
   http://cpham.perso.univ-pau.fr/TCP/ccr_v31.pdf
   https://c3lab.poliba.it/images/d/d7/Westwood_linux.pdf

Recall that TCP Westwood is basically TCP Reno, but it uses RTT to help
estimate the bandwidth-delay-product (BDP) of the link, and use that for
"Fast recovery" after a congestion signal arrives.

We will also be using the RTT congestion signal as per BOOTLEG_RTT_TOR
here, from the Options mail[1] and Defenestrator paper[3]. Recall that
BOOTLEG_RTT_TOR emits a congestion signal when the current RTT falls
below some fractional threshold ('rtt_thresh') fraction between RTT_min
and RTT_max:

   RTT_current &lt; (1rtt_thresh)*RTT_min + rtt_thresh*RTT_max

We can also optionally use the ECN signal described in [BACKWARD_ECN]
above, to exit Slow Start.

Tor Westwood will require each circuit endpoint to maintain a
Bandwidth-Delay-Product (BDP) and Bandwidth Estimate (BWE) variable.

The bandwidth estimate is the current congestion window size divided by
the RTT estimate:

   BWE = cwnd / RTT_current

The BDP estimate is computed by multiplying the Bandwidth estimate by
the circuit latency:

   BDP = BWE * RTT_min

  TODO: Different papers on TCP Westwood and TCP Vegas recommend
        different methods for calculating BWE. See citations for
        details, but common options are 'packets_in_flight/RTT_current'
        or 'circwindow_inc*sendme_arrival_rate'. They also recommend
        averaging and filtering of the BWE, due to ack compression in
        inbound queues. We will need to experiment to determine how to
        best compute the BWE for Tor circuits.

3.1.1. Tor Westwood: Slow Start

Prior to the first congestion signal, Tor Westwood will update its
congestion window exponentially, as per Slow Start.

Recall that this first congestion signal can be either BOOTLEG_RTT_TOR's
RTT threshold signal, or BACKWARD_ECN's cell command signal.

For simplicity, we will just write the BOOTLEG_RTT_TOR check, which
compares the current RTT measurement to the observed min and max RTT,
using the consensus parameter 'rtt_thresh'.

This section of the update algorithm is:

   cwnd = cwnd + circwindow_inc           # For acked cells

   # BOOTLEG_RTT_TOR threshold check:
   if RTT_current &lt; (1rtt_thresh)*RTT_min + rtt_thresh*RTT_max:
      cwnd = cwnd + circwindow_inc        # Exponential window growth
    else:
      BDP = BWE*RTT_min
      cwnd = max(cwnd * cwnd_recovery_m, BDP)
      in_slow_start = 0

Increasing the congestion window by 100 *more* cells every SENDME allows
the sender to send 100 *more* cells every 100 cells. Thus, this is an
exponential function that causes cwnd to double every cwnd cells.

Once a congestion signal is experienced, Slow Start is exited, and the
Additive-Increase-Multiplicative-Decrease (AIMD) steady-state phase
begins.

3.1.2. Tor Westwood: Steady State AIMD

After slow start exits, in steady-state, after every SENDME response
without a congestion signal, the window is updated as:

   cwnd = cwnd + circwindow_inc           # For acked cells
   cwnd = cwnd + circwindow_inc/cwnd      # Linear window growth

This comes out to increasing cwnd by 1, every time cwnd cells are
successfully sent without a congestion signal occurring. Thus this is
additive linear growth, not exponential growth.

If there is a congestion signal, cwnd is updated as:

   cwnd = cwnd + circwindow_inc             # For acked cells
   cwnd = max(cwnd * cwnd_recovery_m, BDP)  # For window shrink

This is called "Fast Recovery". If you dig into the citations, actual
TCP Westwood has some additional details for responding to multiple
packet losses that in some cases can fall back into slow-start, as well
as some smoothing of the BDP to make up for dropped acks. Tor does not
need either of these aspects of complexity.

3.1.3. Tor Westwood: Complete SENDME Update Algorithm

Here is the complete congestion window algorithm for Tor Westwood, using
only RTT signaling.

This will run each time we get a SENDME (aka
sendme_process_circuit_level()):

   in_slow_start = 1                            # Per-circuit indicator

   Every received SENDME ack, do:
     cwnd = cwnd + circwindow_inc               # Update acked cells

     # BOOTLEG_RTT_TOR threshold; can also be BACKWARD_ECN check:
     if RTT_current &lt; (1rtt_thresh)*RTT_min + rtt_thresh*RTT_max:
       if in_slow_start:
         cwnd = cwnd + circwindow_inc           # Exponential growth
       else:
         cwnd = cwnd + circwindow_inc/cwnd      # Linear growth
     else:
       BDP = BWE*RTT_min
       cwnd = max(cwnd * cwnd_recovery_m, BDP)  # Window shrink
       in_slow_start = 0

3.2. Tor Vegas: TCP Vegas with Aggressive Slow Start [TOR_VEGAS]
   http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-vegas
   http://pages.cs.wisc.edu/~akella/CS740/F08/740-Papers/BOP94.pdf
   ftp://ftp.cs.princeton.edu/techreports/2000/628.pdf

TCP Vegas control algorithm makes use of two RTT measurements:
RTT_current and RTT_min. Like TCP Westwood, it also maintains a
bandwidth estimate and a BDP estimate, but those can be simplified away
with algebra.

The bandwidth estimate is the current congestion window size divided by
the RTT estimate:

   BWE = cwnd/RTT_current

The extra queue use along a path can thus be estimated by first
estimating the path's bandwidth-delay product:

   BDP = BWE*RTT_min

TCP Vegas then estimates the queue use caused by congestion as:

   queue_use = cwnd - BDP
             = cwnd - cwnd*RTT_min/RTT_current
             = cwnd * (1 - RTT_min/RTT_current)

So only RTT_min and RTT_current need to be recorded to provide this
queue_use estimate.

  TODO: This simplification might not hold for some versions of BWE
        and BDP estimation. See also the [TOR_WESTWOOD] section's TODO
        and paper citations for both TCP Westwood and TCP Vegas.

3.2.1. Tor Vegas Slow Start

During slow start, we will increase our window exponentially, so long as
this queue_use estimate is below the 'vegas_gamma' consensus parameter.

We also re-use the Tor Westwood backoff, upon exit from Slow Start.

Note though that the exit from Slow Start for here does *not* use the
BOOTLEG_RTT_TOR style RTT threshold, and instead relies on the
queue_use calculation directly.

Tor Vegas slow start can also be exited due to [BACKWARD_ECN] cell
signal, which is omitted for brevity and clarity.

   cwnd = cwnd + circwindow_inc                   # Ack cells

   if queue_use &lt; vegas_gamma:                    # Vegas RTT check
     cwnd = cwnd + circwindow_inc                 # Exponential growth
   else:
     cwnd = max(cwnd * cwnd_recovery_m, BDP)      # Westwood backoff
     in_slow_start = 0

3.2.2. Tor Vegas: Steady State Queue Tracking

Recall that TCP Vegas does not use AIMD in the steady state. Because
TCP Vegas is actually trying to directly control the queue use
on the path, its updates are additive and subtractive only.

If queue_use drops below a threshold alpha (typically 2-3 packets for
TCP Vegas, but perhaps double or triple that for our smaller cells),
then the congestion window is increased. If queue_use exceeds a
threshold beta (typically 4-6 packets, but again we should probably
double or triple this), then the congestion window is decreased.

   cwnd = cwnd + circwindow_inc                 # Ack cells

   if queue_use &lt; vegas_alpha:
     cwnd = cwnd + circwindow_inc/cwnd          # linear growth
   elif queue_use &gt; vegas_beta:
     cwnd = cwnd - circwindow_inc/cwnd          # linear backoff

  TODO: Why not reduce the window by the number of packets that
        queue_use is over or under the target value by, rather than
        just 1 cell per cwnd? Need to ask some TCP folks, or experiment.

3.2.3. Tor Vegas: Complete SENDME Update Algorithm

   in_slow_start = 1                             # Per-circuit indicator

   Every received SENDME ack:
     cwnd = cwnd + circwindow_inc                # Update acked cells

     queue_use = cwnd * (1 - RTT_min/RTT_current)

     if in_slow_start:
       if queue_use &lt; vegas_gamma:
         cwnd = cwnd + circwindow_inc            # Exponential growth
       else:
         cwnd = max(cwnd * cwnd_recovery_m, BDP) # Westwood backoff
         in_slow_start = 0
     else:
       if queue_use &lt; vegas_alpha:
         cwnd = cwnd + circwindow_inc/cwnd       # linear growth
       elif queue_use &gt; vegas_beta:
         cwnd = cwnd - circwindow_inc/cwnd       # linear backoff


4. Flow Control [FLOW_CONTROL]

Flow control provides what is known as "pushback" -- the property that
if one endpoint stops reading data, the other endpoint stops sending
data. This prevents data from accumulating at points in the network, if
it is not being read fast enough by an application.

Because Tor must multiplex many streams onto one circuit, and each
stream is mapped to another TCP socket, Tor's current pushback is rather
complicated and under-specified. In C Tor, it is implemented in the
following functions:
   - circuit_consider_stop_edge_reading()
   - connection_edge_package_raw_inbuf()
   - circuit_resume_edge_reading()

Tor currently maintains separate windows for each stream on a circuit,
to provide individual stream flow control. Circuit windows are SENDME
acked as soon as a relay data cell is decrypted and recognized. Stream
windows are only SENDME acked if the data can be delivered to an active
edge connection. This allows the circuit to continue to operate if an
endpoint refuses to read data off of one of the streams on the circuit.

Because Tor streams can connect to many different applications and
endpoints per circuit, it is important to preserve the property that if
only one endpoint edge connection is inactive, it does not stall the
whole circuit, in case one of those endpoints is malfunctioning or
malicious.

However, window-based stream flow control also imposes a speed limit on
individual streams. If the stream window size is below the circuit
congestion window size, then it becomes the speed limit of a download,
as we saw in the [MOTIVATION] section of this proposal.

So for performance, it is optimal that each stream window is the same
size as the circuit's congestion window. However, large stream windows
are a vector for OOM attacks, because malicious clients can force Exits
to buffer a full stream window for each stream while connecting to a
malicious site and uploading data that the site does not read from its
socket. This attack is significantly easier to perform at the stream
level than on the circuit level, because of the multiplier effects of
only needing to establish a single fast circuit to perform the attack on
a very large number of streams.

This catch22 means that if we use windows for stream flow control, we
either have to commit to allocating a full congestion window worth
memory for each stream, or impose a speed limit on our streams.

Hence, we will discard stream windows entirely, and instead use a
simpler buffer-based design that uses XON/XOFF as a backstop. This will
allow us to make full use of the circuit congestion window for every
stream in combination, while still avoiding buffer buildup inside the
network.

4.1. Stream Flow Control Without Windows [WINDOWLESS_FLOW]

Each endpoint (client, Exit, or onion service) should send circuit-level
SENDME acks for all circuit cells as soon as they are decrypted and
recognized, but *before* delivery to their edge connections. If the edge
connection is blocked because an application is not reading, data will
build up in a queue at that endpoint.

Three consensus parameters will govern the max length of this queue:
xoff_client, xoff_exit, and xoff_mobile. These will be used for Tor
clients, exits, and mobile devices, respectively. These cuttofs will be
a percentage of current 'cwnd' rather than number of cells. Something
like 5% of 'cwnd' should be plenty, since these edge connections should
normally drain *much* faster than Tor itself.

If the length of an application stream queue exceeds the size provided
in the appropriate consensus parameter, a RELAY_COMMAND_STREAM_XOFF will
be sent, which instructs the other endpoint to stop sending from that
edge connection. This XOFF cell can optionally contain any available
stream data, as well.

As soon as the queue begins to drain, a RELAY_COMMAND_STREAM_XON will
sent, which allows the other end to resume reading on that edge
connection. Because application streams should drain quickly once they
are active, we will send the XON command as soon as they start draining.
If the queues fill again, another XOFF will be sent. If this results in
excessive XOFF/XON flapping and chatter, we will also use consensus
parameters xon_client, xon_exit, and xon_mobile to optionally specify
when to send an XON. These parameters will be defined in terms of cells
below the xoff_* levels, rather than percentage. The XON cells can also
contain stream data, if any is available.

Tor's OOM killer will be invoked to close any streams whose application
buffer grows too large, due to memory shortage, or malicious endpoints.

Note that no stream buffer should ever grow larger than the xoff level
plus 'cwnd', unless an endpoint is ignoring XOFF. So,
'xoff_{client,exit,mobile} + cwnd' should be the hard-close stream
cutoff, regardless of OOM killer status.


5. System Interactions [SYSTEM_INTERACTIONS]

Tor's circuit-level SENDME system currently has special cases in the
following situations: Intropoints, HSDirs, onion services, and circuit
padding. Additionally, proper congestion control will allow us to very
easily implement conflux (circuit traffic splitting).

This section details those special cases and interactions of congestion
control with other components of Tor.

5.1. HSDirs

Because HSDirs use the tunneled dirconn mechanism and thus also use
RELAY_COMMAND_DATA, they are already subject to Tor's flow control.

We may want to make sure our initial circuit window for HSDir circuits
is set custom for those circuit types, so a SENDME is not required to
fetch long descriptors. This will ensure HSDir descriptors can be
fetched in one RTT.

5.2. Introduction Points

Introduction Points are not currently subject to any flow control.

Because Intropoints accept INTRODUCE1 cells from many client circuits
and then relay them down a single circuit to the service as INTRODUCE2
cells, we cannot provide end-to-end congestion control all the way from
client to service for these cells.

We can run congestion control from the service to the Intropoint,
however, and if that congestion window reaches zero (because the service
is overwhelmed), then we start sending NACKS back to the clients (or
begin requiring proof-of-work), rather than just let clients wait for
timeout.

5.3. Rendezvous Points

Rendezvous points are already subject to end-to-end SENDME control,
because all relay cells are sent end-to-end via the rendezvous circuit
splice in circuit_receive_relay_cell().

This means that rendezvous circuits will use end-to-end congestion
control, as soon as individual onion clients and onion services upgrade
to support it. There is no need for intermediate relays to upgrade at
all.

5.4. Circuit Padding

Recall that circuit padding is negotiated between a client and a middle
relay, with one or more state machines running on circuits at the middle
relay that decide when to add padding.

https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md


This means that the middle relay can send padding traffic towards the
client that contributes to congestion, and the client may also send
padding towards the middle relay, that also creates congestion.

For low-traffic padding machines, such as the currently deployed circuit
setup obfuscation, this padding is inconsequential.

However, higher traffic circuit padding machines that are designed to
defend against website traffic fingerprinting will need additional care
to avoid inducing additional congestion, especially after the client or
the exit experiences a congestion signal.

The current overhead percentage rate limiting features of the circuit
padding system should handle this in some cases, but in other cases, an
XON/XOFF circuit padding flow control command may be required, so that
clients may signal to the machine that congestion is occurring.

5.5. Conflux

Conflux (aka multi-circuit traffic splitting) becomes significantly
easier to implement once we have congestion control. However, much like
congestion control, it will require experimentation to tune properly.

Recall that Conflux uses a 256-bit UUID to bind two circuits together at
the Exit or onion service. The original Conflux paper specified an
equation based on RTT to choose which circuit to send cells on.
  https://www.cypherpunks.ca/~iang/pubs/conflux-pets.pdf

However, with congestion control, we will already know which circuit has
the larger congestion window, and thus has the most available cells in
its current congestion window. This will also be the faster circuit.
Thus, the decision of which circuit to send a cell on only requires
comparing congestion windows (and choosing the circuit with more packets
remaining in its window).

Conflux will require sequence numbers on data cells, to ensure that the
two circuits' data is properly re-assembled. The resulting out-of-order
buffer can potentially be as large as an entire congestion window, if
the circuits are very desynced (or one of them closes). It will be very
expensive for Exits to maintain this much memory, and exposes them to
OOM attacks.

This is not as much of a concern in the client download direction, since
clients will typically only have a small number of these out-of-order
buffers to keep around. But for the upload direction, Exits will need
to send some form of early XOFF on the faster circuit if this
out-of-order buffer begins to grow too large, since simply halting the
delivery of SENDMEs will still allow a full congestion window full of
data to arrive. This will also require tuning and experimentation, and
optimum results will vary between simulator and live network.

  TODO: Can we use explicit SENDME sequence number acking to make a
       connection-resumption conflux, to recover from circuit collapse
       or client migration? I am having trouble coming up with a design
       that does not require Exits to maintain a full congestion
       window full of data as a retransmit buffer in the event of
       circuit close. Such reconnect activity might require assistance
       from Guard relays so that they can help clients discover which
       cells were sent vs lost.


6. Performance Evaluation [EVALUATION]

Congestion control for Tor will be easy to implement, but difficult to
tune to ensure optimal behavior.

6.1. Congestion Signal Experiments

Our first experiments will be to conduct client-side experiments to
determine how stable the RTT measurements of circuits are across the
live Tor network, to determine if we need more frequent SENDMEs, and/or
need to use any RTT smoothing or averaging.

Once we have a reliable way to measure RTT, we will need to test the
reliability and accuracy of the Bandwidth Estimation (BWE) and
Bandwidth-Delay-Product (BDP) measurements that are required for
[TOR_WESTWOOD] and [TOR_VEGAS]. These experiments can be conducted in
Shadow, with precise network topologies for which actual bandwidth and
latency (and thus BWE and BDP) are known parameters.  We should use the
most accurate form of these estimators from Shadow experimentation to
run some client tests with custom Exits on the live network, to check
for high variability in these estimates, discrepancy with client
application throughput and application latency, and other surprises.

Care will need to be taken to increase or alter Tor's circwindow during
these experiments in Shadow and on the custom Exits, so that the default
of 1000 does not impose an artificial ceiling on circuit bandwidth.

6.2. Congestion Algorithm Experiments

In order to evaluate performance of congestion control algorithms, we
will need to implement [TOR_WESTWOOD], [TOR_VEGAS], and also variants of
those without the Westwood BDP fast recovery backoff. We will need to
simulate their use in the Shadow Tor network simulator.

Simulation runs will need to evaluate performance on networks that use
only one algorithm, as well as on networks that run a combinations of
algorithms - particularly each type of congestion control in combination
with Tor's current flow control. If Tor's current flow control is too
aggressive, we can experiment with kneecapping these legacy flow control
Tor clients by setting a low 'circwindow' consensus parameter for them.

Because custom congestion control can be deployed by any Exit or onion
service that desires better service, we will need to be particularly
careful about how congestion control algorithms interact with rogue
implementations that more aggressively increase their window sizes.
During these adversarial-style experiments, we must verify that cheaters
do not get better service, and that Tor's circuit OOM killer properly
closes circuits that seriously abuse the congestion control algorithm,
as per [SECURITY_ANALYSIS].

Finally, we should determine if the [BACKWARD_ECN] cell_t.command
congestion signal is enough of an optimization to be worth the
complexity, especially if it is only used once, to exit slow start. This
can be determined in Shadow.

6.3. Flow Control Algorithm Experiments

We will need to tune the xoff_* consensus parameters to minimize the
amount of edge connection buffering as well as XON/XOFF chatter for
Exits. This can be done in simulation, but will require fine-tuning on
the live network.

Relays will need to report these statistics in extra-info descriptor,
to help with monitoring the live network conditions.

6.4. Performance Metrics [EVALUATION_METRICS]

Because congestion control will affect so many aspects of performance,
from throughput to RTT, to load balancing, queue length, overload, and
other failure conditions, the full set of performance metrics will be
required:

https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceMetrics

We will also need to monitor network health for relay queue lengths,
relay overload, and other signs of network stress (and particularly the
alleviation of network stress).

6.5. Consensus Parameter Tuning [CONSENSUS_PARAMETERS]

During Shadow simulation, we will determine reasonable default
parameters for our consensus parameters for each algorithm. We will then
re-run these tuning experiments on the live Tor network, as described
in:

https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceExperiments


The following list is the complete set of network consensus parameters
referenced in this proposal, sorted roughly in order of importance (most
important to tune first):

  cc_alg:
    - Description:
          Specifies which congestion control algorithm clients should
          use, as an integer.
    - Range: [0,2]  (0=fixed, 1=Westwood, 2=Vegas)
    - Default: 2

  cwnd_recovery_m:
    - Description: Specifies how much to reduce the congestion
                   window after a congestion signal, as a fraction of
                   100.
    - Range: [0, 100]
    - Default: 70

  circwindow:
    - Description: Initial congestion window for legacy Tor clients
    - Range: [1, 1000]
    - Default: 1000 (reduced if legacy Tor clients compete unfairly)

  circwindow_cc:
    - Description: Initial congestion window for new congestion
                   control Tor clients.
    - Range: [1, 1000]
    - Default: 10-100

  rtt_thresh:
    - Description:
              Specifies the cutoff for BOOTLEG_RTT_TOR to deliver
              congestion signal, as fixed point representation
              divided by 1000.
    - Range: [1, 1000]
    - Default: 230

  vegas_alpha
  vegas_beta
  vegas_gamma
    - Description: These parameters govern the number of cells
                   that [TOR_VEGAS] can detect in queue before reacting.
    - Range: [1, 1000]
    - Defaults: 6,12,12

  circwindow_inc:
    - Description: Specifies how many cells a SENDME acks
    - Range: [1, 5000]
    - Default: 100

  min_queue_target:
    - Description: How long in milliseconds can a cell spend in
      a relay's queues before we declare its circuit congested?
    - Range: [1, 10000]
    - Default: 10

  xoff_client
  xoff_mobile
  xoff_exit
    - Description: Specifies the stream queue size as a percentage of
                   'cwnd' at an endpoint before an XOFF is sent.
    - Range: [1, 100]
    - Default: 5

  xon_client
  xon_mobile
  xon_exit
    - Description: Specifies the how many cells below xoff_* before
                   an XON is sent from an endpoint.
    - Range: [1, 10000000]
    - Default: 10000


7. Protocol format specifications [PROTOCOL_SPEC]

   TODO: This section needs details once we close out other TODOs above.

7.1. Circuit window handshake format

   TODO: We need to specify a way to communicate the currently seen
         circwindow_inc consensus parameter to the other endpoint,
         due to consensus sync delay. Probably during the CREATE
         onionskin (and RELAY_COMMAND_EXTEND).
   TODO: We probably want stricter rules on the range of values
         for the per-circuit negotiation - something like
         it has to be between [circwindow_inc/2, 2*circwindow_inc].
         That way, we can limit weird per-circuit values, but still
         allow us to change the consensus value in increments.

7.2. XON/XOFF relay cell formats

   TODO: We need to specify XON/XOFF for flow control. This should be
         simple.
   TODO: We should also allow it to carry stream data.

7.3. Onion Service formats

   TODO: We need to specify how to signal support for congestion control
         in an onion service, to both the intropoint and to clients.

7.4. Protocol Version format

   TODO: We need to pick a protover to signal Exit and Intropoint
         congestion control support.

7.5. SENDME relay cell format

   TODO: We need to specify how to add stream data to a SENDME as an
         optimization.

7.6. BACKWARD_ECN signal format

   TODO: We need to specify exactly which byte to flip in cells
         to signal congestion on a circuit.

   TODO: Black magic will allow us to send zero-filled BACKWARD_ECN
         cells in the *wrong* direction in a circuit, towards the Exit -
         ie with no crypto layers at all. If we enforce strict format
         and zero-filling of these cells at intermediate relays, we can
         avoid side channels there, too. (Such a hack allows us to
         send BACKWARD_ECN without any wait, if there are no relay cells
         that are available heading in the backward direction, towards
         the endpoint that caused congestion).

7.7. Extrainfo descriptor formats

   TODO: We will want to gather information on circuitmux and other
         relay queues, as well as XON/XOFF rates, and edge connection
         queue lengths at exits.


8. Security Analysis [SECURITY_ANALYSIS]

The security risks of congestion control come in three forms: DoS
attacks, fairness abuse, and side channel risk.

8.1. DoS Attacks (aka Adversarial Buffer Bloat)

The most serious risk of eliminating our current window cap is that
endpoints can abuse this situation to create huge queues and thus DoS
Tor relays.

This form of attack was already studied against the Tor network in the
Sniper attack:
  https://www.freehaven.net/anonbib/cache/sniper14.pdf

We had two fixes for this. First, we implemented a circuit-level OOM
killer that closed circuits whose queues became too big, before the
relay OOMed and crashed.

Second, we implemented authenticated SENDMEs, so clients could not
artificially increase their window sizes with honest exits:

https://gitweb.torproject.org/torspec.git/tree/proposals/289-authenticated-sendmes.txt


We can continue this kind of enforcement by having Exit relays ensure
that clients are not transmitting SENDMEs too often, and do not appear
to be inflating their send windows beyond what the Exit expects by
calculating a similar receive window.

Unfortunately, authenticated SENDMEs do *not* prevent the same attack
from being done by rogue exits, or rogue onion services. For that, we
rely solely on the circuit OOM killer. During our experimentation, we
must ensure that the circuit OOM killer works properly to close circuits
in these scenarios.

But in any case, it is important to note that we are not any worse off
with congestion control than we were before, with respect to these kinds
of DoS attacks. In fact, the deployment of congestion control by honest
clients should reduce queue use and overall memory use in relays,
allowing them to be more resilient to OOM attacks than before.

8.2. Congestion Control Fairness Abuse (aka Cheating)

On the Internet, significant research and engineering effort has been
devoted to ensuring that congestion control algorithms are "fair" in
that each connection receives equal throughput. This fairness is
provided both via the congestion control algorithm, as well as via queue
management algorithms at Internet routers.

One of the most unfortunate early results was that TCP Vegas, despite
being near-optimal at minimizing queue lengths at routers, was easily
out-performed by more aggressive algorithms that tolerated larger queue
delay (such as TCP Reno).

Note that because the most common direction of traffic for Tor is from
Exit to client, unless Exits are malicious, we do not need to worry
about rogue algorithms as much, but we should still examine them in our
experiments because of the possibility of malicious Exits, as well as
malicious onion services.

Queue management can help further mitigate this risk, too. When RTT is
used as a congestion signal, our current Circuit-EWMA queue management
algorithm is likely sufficient for this. Because Circuit-EWMA will add
additional delay to loud circuits, "cheaters" who use alternate
congestion control algorithms to inflate their congestion windows should
end up with more RTT congestion signals than those who do not, and the
Circuit-EWMA scheduler will also relay fewer of their cells per time
interval.

In this sense, we do not need to worry about fairness and cheating as a
security property, but a lack of fairness in the congestion control
algorithm *will* increase memory use in relays to queue these
unfair/loud circuits, perhaps enough to trigger the OOM killer. So we
should still be mindful of these properties in selecting our congestion
control algorithm, to minimize relay memory use, if nothing else.

These two properties (honest Exits and Circuit-EWMA) may even be enough
to make it possible to use [TOR_VEGAS] even in the presence of other
algorithms, which would be a huge win in terms of memory savings as well
as vastly reduced queue delay. We must verify this experimentally,
though.

8.3. Side Channel Risks

Vastly reduced queue delay and predictable amounts of congestion on the
Tor network may make certain forms of traffic analysis easier.
Additionally, the ability to measure RTT and have it be stable due to
minimal network congestion may make geographical inference attacks
easier:
  https://www.freehaven.net/anonbib/cache/ccs07-latency-leak.pdf
  https://www.robgjansen.com/publications/howlow-pets2013.pdf

It is an open question as to if these risks are serious enough to
warrant eliminating the ability to measure RTT at the protocol level and
abandoning it as a congestion signal, in favor of other approaches
(which have their own side channel risks). It will be difficult to
comprehensively eliminate RTT measurements, too.

On the plus side, Conflux traffic splitting (which is made easy once
congestion control is implemented) does show promise as providing
defense against traffic analysis:

https://www.comsys.rwth-aachen.de/fileadmin/papers/2019/2019-delacadena-splitting-defense.pdf


There is also literature on shaping circuit bandwidth to create a side
channel. This can be done regardless of the use of congestion control,
and is not an argument against using congestion control. In fact, the
Backlit defense may be an argument in favor of endpoints monitoring
circuit bandwidth and latency more closely, as a defense:
  https://www.freehaven.net/anonbib/cache/ndss09-rainbow.pdf
  https://www.freehaven.net/anonbib/cache/ndss11-swirl.pdf
  https://www.freehaven.net/anonbib/cache/acsac11-backlit.pdf

Finally, recall that we are considering BACKWARD_ECN to use a
circuit-level cell_t.command to signal congestion. This allows all
relays in the path to signal congestion in under RTT/2 in either
direction, and it can be flipped on existing relay cells already in
transit, without introducing any overhead.  However, because
cell_t.command is visible and malleable to all relays, it can also be
used as a side channel. So we must limit its use to a couple of cells
per circuit, at most.

https://blog.torproject.org/tor-security-advisory-relay-early-traffic-confirmation-attack



9. [CITATIONS]

1. Options for Congestion Control in Tor-Like Networks.
   https://lists.torproject.org/pipermail/tor-dev/2020-January/014140.html

2. Towards Congestion Control Deployment in Tor-like Networks.
   https://lists.torproject.org/pipermail/tor-dev/2020-June/014343.html

3. DefenestraTor: Throwing out Windows in Tor.
   https://www.cypherpunks.ca/~iang/pubs/defenestrator.pdf

4. TCP Westwood: Bandwidth Estimation for Enhanced Transport over
Wireless Links

http://nrlweb.cs.ucla.edu/nrlweb/publication/download/99/2001-mobicom-0.pdf

5. Performance Evaluation and Comparison of Westwood+, New Reno, and
Vegas TCP Congestion Control
   http://cpham.perso.univ-pau.fr/TCP/ccr_v31.pdf

6. Linux 2.4 Implementation of Westwood+ TCP with rate-halving
   https://c3lab.poliba.it/images/d/d7/Westwood_linux.pdf

7. TCP Westwood
   http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-westwood

8. TCP Vegas: New Techniques for Congestion Detection and Avoidance
   http://pages.cs.wisc.edu/~akella/CS740/F08/740-Papers/BOP94.pdf

9. Understanding TCP Vegas: A Duality Model
   ftp://ftp.cs.princeton.edu/techreports/2000/628.pdf

10. TCP Vegas
    http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-vegas

11. Controlling Queue Delay
    https://queue.acm.org/detail.cfm?id=2209336

12. Controlled Delay Active Queue Management
    https://tools.ietf.org/html/rfc8289

13. How Much Anonymity does Network Latency Leak?
    https://www.freehaven.net/anonbib/cache/ccs07-latency-leak.pdf

14. How Low Can You Go: Balancing Performance with Anonymity in Tor
    https://www.robgjansen.com/publications/howlow-pets2013.pdf

15. POSTER: Traffic Splitting to Counter Website Fingerprinting

https://www.comsys.rwth-aachen.de/fileadmin/papers/2019/2019-delacadena-splitting-defense.pdf


16. RAINBOW: A Robust And Invisible Non-Blind Watermark for Network Flows
    https://www.freehaven.net/anonbib/cache/ndss09-rainbow.pdf

17. SWIRL: A Scalable Watermark to Detect Correlated Network Flows
    https://www.freehaven.net/anonbib/cache/ndss11-swirl.pdf

18. Exposing Invisible Timing-based Traffic Watermarks with BACKLIT
    https://www.freehaven.net/anonbib/cache/acsac11-backlit.pdf

19. The Sniper Attack: Anonymously Deanonymizing and Disabling the Tor
Network
    https://www.freehaven.net/anonbib/cache/sniper14.pdf

20. Authenticating sendme cells to mitigate bandwidth attacks

https://gitweb.torproject.org/torspec.git/tree/proposals/289-authenticated-sendmes.txt


21. Tor security advisory: "relay early" traffic confirmation attack

https://blog.torproject.org/tor-security-advisory-relay-early-traffic-confirmation-attack


22. The Path Less Travelled: Overcoming Tor's Bottlenecks with Traffic
Splitting
    https://www.cypherpunks.ca/~iang/pubs/conflux-pets.pdf

23. Circuit Padding Developer Documentation

https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md


24. Plans for Tor Live Network Performance Experiments

https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceExperiments


25. Tor Performance Metrics for Live Network Tuning

https://trac.torproject.org/projects/tor/wiki/org/roadmaps/CoreTor/PerformanceMetrics


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200709083936</emailId><senderName>Hans-Christoph Steiner</senderName><senderEmail>hans@guardianproject.info</senderEmail><timestampReceived>2020-07-09 08:39:36-0400</timestampReceived><subject>Re: [tor-dev] Gitlab CI runners available for experimentation on gitlab.torproject.org</subject><body>


Happy to help!  I'm a big fan of gitlab-ci since it is a collection of
standard tools like Docker, YAML, bash, etc. It takes a bit more to
learn than Travis-CI, but it pays off by being more flexible and a
simpler setup.  E.g. it is easy to start with a plain, base Debian
image, only install the requirements, and run tests from there.  No
intermediate layer. And using YAML templates, it is possible to reuse
chunks of code. In the go setup I'm using right now for snowflake, I
have a template for the install and test run.  Then its trivial to
add/change the base image between Debian-derivs of various releases.

I should also add: these are actually F-Droid runners, not Guardian
Project.  F-Droid a bare metal server (16-core/32-thread, 142GB RAM, 3TB
disk) that could be allocated to only gitlab runners that can be shared
with Tor Project cost-free.  We just need someone to admin it.  We have
an almost complete setup with ansible.  @uniqx and I would happily help
someone finish that setup if there was someone to make sure it stays
updated and running.  (I'm personally already admining more servers than
I should be).

Also, these runners have KVM and privileged mode enabled, so you can run
any KVM VM in the gitlab-ci jobs.  Docker too.

.hc

Alexander Fry:
&gt; Hello folks!
&gt; 
&gt; Hans from The Guardian Project added his CI runners to our Gitlab
&gt; instance. It looks like some pretty fast machines that allows each team
&gt; to experiment with Gitlab CI on our Gitlab instance.
&gt; 
&gt; Hans says that the runners have no uptime promises or anything like
&gt; that, so if they are down they are down :-)
&gt; 
&gt; Here's some documentation for getting started:
&gt; https://docs.gitlab.com/ee/ci/
&gt; 
&gt; Thanks to Hans for this!
&gt; 
&gt; All the best,
&gt; Alex.
&gt; 

-- 
PGP fingerprint: EE66 20C7 136B 0D2C 456C  0A4D E9E2 8DEA 00AA 5556
https://pgp.mit.edu/pks/lookup?op=vindex&amp;search=0xE9E28DEA00AA5556
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200709143105</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-07-09 14:31:05-0400</timestampReceived><subject>[tor-dev] Gitolite to Gitlab Sync Change</subject><body>

Hello folks!

In an attempt to solve Gitlab#41[1] the hooks that is executed when you
push to git.torproject.org to synchronize to Gitlab was modified to
avoid pruning references in Gitlab that was missing in the Gitolite
repository.

This /should/ have the following implications:

- We no longer delete the "refs/merge-requests/*" namespace each time
  someone pushes to your repository on git.torproject.org. This should
  allow people to use the `git mr` alias that can be found online which
  should make local code-reviews easier and also allow you to handle
  manual CLI merging more easily.

- We no longer delete branches automatically on Gitlab: if a branch is
  deleted on git.torproject.org. This have to be deleted manually now on
  Gitlab.

Please report any issues you that you might discover on the ticket.

Thanks to Hiro for getting this running!

All the best,
Alex.

[1]: https://gitlab.torproject.org/tpo/tpa/gitlab/-/issues/41

-- =

Alexander F=E6r=F8y
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200710000646</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-07-10 00:06:46-0400</timestampReceived><subject>[tor-dev] CAPTCHA Monitoring Project Updates &amp; Findings</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

I made progress on the Cloudflare CAPTCHA Monitoring project since my last
email, and I wanted to share some of the updates &amp; findings. This year Tor
Project is participating in GSoC under the DIAL umbrella, and I have
already been posting updates to the DIAL blog [1] weekly. I started
mirroring these updates [2] to my project's wiki page, and I will be
posting more frequent updates here.

a) Updates:
Firstly, I moved the wiki page that explains the project, the code base,
and the issue tracker to Tor Project's GitLab. They are all in the same
GitLab project. You can find detailed information about the project on the
wiki page [3] and leave comments &amp; suggestions within that repository by
creating issues.

Secondly, I got a fully functioning system up and running. The system
fetches various URLs with Tor Browser &amp; Firefox over Tor and checks for
CAPTCHAs. The system also checks if any third-party code was injected by
comparing the hash of the received page with an expected hash value. It
repeats these experiments using different exit relays and records results.
You can view the results on the dashboard [4] I created. I'm looking for
more URLs to track for CAPTCHAs. Feel free to share the websites you
frequently visit and get CAPTCHAs, so that I can track these websites with
this tool as well. I want to experiment with all types of CAPTCHAs, and
these URLs don't have to be fronted by Cloudflare.

b) Findings:
So far, I have observed that using the Tor Browser Bundle out of the box
without changing its configurations doesn't lead to a high CAPTCHA rate on
Cloudflare fronted websites (assuming the website owners don't explicitly
block exit relays [5]). That said, modifying the user-agent or any other
modifications that deviate your browser's fingerprint from a typical Tor
Browser user, significantly increases the chance of getting CAPTCHAs. For
example, using the regular Firefox over Tor resulted in getting CAPTCHAs in
~90% of the measurements. I believe Cloudflare is very aggressive against
the "Firefox over Tor" users because many people, unfortunately, use
Chromium/Firefox + Selenium + Tor to scrape web pages and bypass IP-based
rate limits. That's why I'm interested in hearing about your specific
browser/Tor configurations to test them with the CAPTCHA Monitor. Not
everyone is affected in the same way because of these differences in the
way we use Tor, but we can understand which differences affect the CAPTCHA
rate more than others by experimenting.

Additionally, I observed that the TLS fingerprint has a significant role in
whether someone gets a CAPTCHA or not. As a part of the project, I decided
to capture the HTTP headers during measurements to understand how they
affect the CAPTCHA rates. Initially, I was using a Python library called
seleniumwire to capture the HTTP headers by intercepting the traffic
between the Tor Browser and Tor. By doing this, I got a very high CAPTCHA
rate, like 98% of the time. seleniumwire forwards the traffic
transparently, but it has a different TLS fingerprint than Tor Browser. I
figured out that the difference in the TLS fingerprints was triggering the
MITM detection on the Cloudflare side, thus, resulting in very high CAPTCHA
rates.

Interestingly, I tried using the exact same Tor Browser &amp; seleniumwire
setup, but without Tor and, practically, I didn't get any CAPTCHAs. I
believe the MITM detection is more aggressive if the traffic is coming
through an exit relay. So, I stopped using seleniumwire to capture headers
because it didn't reflect what a real human Tor Browser user is usually
experiencing. Please feel free to use the sample code [6] that I used to
combine seleniumwire and Tor, if you are interested in doing further
experimenting on this.

c) Next:
I will work on collecting more metrics by testing more configurations and
websites. I will create a "Relay Search" section on the dashboard, where
CAPTCHA statistics for the relays (exit relays for now) will be available.
I will also work on using the collected data to predict the probability of
getting CAPTCHAs with a given exit relay and configuration/setup.

Best,
Barkin

[1]
https://hub.osc.dial.community/t/tor-project-cloudflare-captcha-monitoring/1558
[2] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/Updates
[3] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home
[4] https://dashboard.captcha.wtf/
[5] Cloudflare has a setting to block all traffic originating from the Tor
network, but that setting is not "turned on" by default
[6] https://gist.github.com/woswos/38b921f0b82de009c12c6494db3f50c5

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi everyone,&lt;br&gt;&lt;br&gt;I made progress on the Cloudflare CAPTCHA \
Monitoring project since my last email, and I wanted to share some of the updates \
&amp; findings. This year Tor Project is participating in GSoC under the DIAL \
umbrella, and I have already been posting updates to the DIAL blog [1] weekly. I \
started mirroring these updates [2] to my project's wiki page, and I will be \
posting more frequent updates here.&lt;br&gt;&lt;br&gt;a) Updates:&lt;br&gt;Firstly, I moved the wiki \
page that explains the project, the code base, and the issue tracker to Tor \
Project's GitLab. They are all in the same GitLab project. You can find detailed \
information about the project on the wiki page [3] and leave comments &amp; \
suggestions within that repository by creating issues.&lt;br&gt;&lt;br&gt;Secondly, I got a fully \
functioning system up and running. The system fetches various URLs with Tor Browser \
&amp; Firefox over Tor and checks for CAPTCHAs. The system also checks if any \
third-party code was injected by comparing the hash of the received page with an \
expected hash value. It repeats these experiments using different exit relays and \
records results. You can view the results on the dashboard [4] I created. I'm \
looking for more URLs to track for CAPTCHAs. Feel free to share the websites you \
frequently visit and get CAPTCHAs, so that I can track these websites with this tool \
as well. I want to experiment with all types of CAPTCHAs, and these URLs don't \
have to be fronted by Cloudflare.&lt;br&gt;&lt;br&gt;b) Findings:&lt;br&gt;So far, I have observed that \
using the Tor Browser Bundle out of the box without changing its configurations \
doesn't lead to a high CAPTCHA rate on Cloudflare fronted websites (assuming the \
website owners don't explicitly block exit relays [5]). That said, modifying the \
user-agent or any other modifications that deviate your browser's fingerprint \
from a typical Tor Browser user, significantly increases the chance of getting \
CAPTCHAs. For example, using the regular Firefox over Tor resulted in getting \
CAPTCHAs in ~90% of the measurements. I believe Cloudflare is very aggressive against \
the "Firefox over Tor" users because many people, unfortunately, use \
Chromium/Firefox + Selenium + Tor to scrape web pages and bypass IP-based rate \
limits. That's why I'm interested in hearing about your specific browser/Tor \
configurations to test them with the CAPTCHA Monitor. Not everyone is affected in the \
same way because of these differences in the way we use Tor, but we can understand \
which differences affect the CAPTCHA rate more than others by \
experimenting.&lt;br&gt;&lt;br&gt;Additionally, I observed that the TLS fingerprint has a \
significant role in whether someone gets a CAPTCHA or not. As a part of the project, \
I decided to capture the HTTP headers during measurements to understand how they \
affect the CAPTCHA rates. Initially, I was using a Python library called seleniumwire \
to capture the HTTP headers by intercepting the traffic between the Tor Browser and \
Tor. By doing this, I got a very high CAPTCHA rate, like 98% of the time. \
seleniumwire forwards the traffic transparently, but it has a different TLS \
fingerprint than Tor Browser. I figured out that the difference in the TLS \
fingerprints was triggering the MITM detection on the Cloudflare side, thus, \
resulting in very high CAPTCHA rates.&lt;br&gt;&lt;br&gt;Interestingly, I tried using the exact \
same Tor Browser &amp; seleniumwire setup, but without Tor and, practically, I \
didn't get any CAPTCHAs. I believe the MITM detection is more aggressive if the \
traffic is coming through an exit relay. So, I stopped using seleniumwire to capture \
headers because it didn't reflect what a real human Tor Browser user is usually \
experiencing. Please feel free to use the sample code [6] that I used to combine \
seleniumwire and Tor, if you are interested in doing further experimenting on \
this.&lt;br&gt;&lt;br&gt;c) Next:&lt;br&gt;I will work on collecting more metrics by testing more \
configurations and websites. I will create a "Relay Search" section on the \
dashboard, where CAPTCHA statistics for the relays (exit relays for now) will be \
available. I will also work on using the collected data to predict the probability of \
getting CAPTCHAs with a given exit relay and \
configuration/setup.&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Best,&lt;br&gt;Barkin&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;[1] \
&lt;a href="https://hub.osc.dial.community/t/tor-project-cloudflare-captcha-monitoring/15 \
58"&gt;https://hub.osc.dial.community/t/tor-project-cloudflare-captcha-monitoring/1558&lt;/a&gt;&lt;br&gt;[2] \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/Updates"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/Updates&lt;/a&gt;&lt;br&gt;[3] \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home&lt;/a&gt;&lt;br&gt;[4] \
&lt;a href="https://dashboard.captcha.wtf/"&gt;https://dashboard.captcha.wtf/&lt;/a&gt;&lt;br&gt;[5] \
Cloudflare has a setting to block all traffic originating from the Tor network, but \
that setting is not "turned on" by default&lt;br&gt;[6] &lt;a \
href="https://gist.github.com/woswos/38b921f0b82de009c12c6494db3f50c5"&gt;https://gist.github.com/woswos/38b921f0b82de009c12c6494db3f50c5&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200710191609</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-07-10 19:16:09-0400</timestampReceived><subject>Re: [tor-dev] Proposal 325: Packed relay cells: saving space on small commands</subject><body>

On Fri, Jul 10, 2020 at 2:07 PM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt;
&gt; On Fri, Jul 10, 2020 at 01:52:00PM -0400, Nick Mathewson wrote:
&gt; &gt; After receiving a packed relay cell, the relay know that the client
&gt;
&gt; typo: "know" -&gt; "knows"

thanks!

&gt; &gt;     struct relay_header {
&gt; &gt;        u1 stream_id_included; // Is the stream_id included?
&gt; &gt;        u6 relay_command; // as before
&gt; &gt;        u9 relay_data_len; // as before
&gt; &gt;        u8 optional_stream_id[]; // 0 bytes or two bytes.
&gt; &gt;     }
&gt; &gt;
&gt; &gt; Alternatively, you can view the first three fields as a 16-bit
&gt; &gt; value, computed as:
&gt; &gt;
&gt; &gt;     (stream_id_included&lt;&lt;15) | (relay_command &lt;&lt; 9) | (relay_data_len).
&gt;
&gt; Where everything is big-endian, both at the byte and bit level?  (Is
&gt; that specified at some higher level in the specs?  I forget.)

Early in the spec, we say that we always use network byte order. I
don't think we ever actually spec a bit order.

&gt; &gt; If the optional_stream_id field is not present, then the default
&gt; &gt; value for the stream_id is computed as follows.  We use stream_id 0
&gt; &gt; for any command that doesn't take a stream ID.  For commands that
&gt; &gt; _do_ take a steam_id, we use whichever nonzero stream_id appeared
&gt; &gt; last in this cell.
&gt;
&gt; Do you mean "last in this cell" as in "the one closest to the end of the
&gt; cell" or as in "the one that appeared closest to, but before, this relay
&gt; command header"?

Ah; the latter. Maybe "most recently" would be more clear?

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200720232821</emailId><senderName>Andrew Clausen</senderName><senderEmail>andrew.p.clausen@gmail.com</senderEmail><timestampReceived>2020-07-20 23:28:21-0400</timestampReceived><subject>Re: [tor-dev] Distributing Tor developer keys via Fedora packages</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Matt,

On Mon, 20 Jul 2020 at 22:37, Matthew Finkel &lt;sysrqb@torproject.org&gt; wrote:

&gt; &gt; I propose distributing the Tor developer keys inside the Fedora package
&gt; &gt; distribution-gpg-keys.[1]  This would give most Linux users a trustworthy
&gt; &gt; chain of signatures from their own distributor (e.g. CentOS or Fedora) to
&gt; &gt; Tor project downloads.
&gt;
&gt; (most? :) )
&gt;

I suspect so.  I haven't checked if Debian/Ubuntu have keyrings for
Fedora.  (Vice versa is certainly true.)


&gt; &gt; I am happy to take care of this, although I am also happy if somebody who
&gt; &gt; is more involved with Tor than me takes this on.  I wrote a shell script
&gt; &gt; (attached) to acquire and organise the keys based on
&gt; &gt; https://2019.www.torproject.org/include/keys.txt.  My script would
&gt; install
&gt; &gt; the following keys under /usr/share/distribution-gpg-keys/tor:
&gt;
&gt; Unfortuntately that file is very old and incorrect now.
&gt;

That is unfortunate.  Is there any sensible way that users can currently
verify signatures of their downloads?  (Can I mimic that?)


&gt; &gt; The most obvious question is: how do I know that I am distributing
&gt; &gt; unadulterated keys?  I think the answer is that I don't!  But any attack
&gt; &gt; would have to affect a large group of people, and would be detected
&gt; quickly
&gt; &gt; as long as many people are looking at the distribution-gpg-keys package.
&gt; &gt; If this solution is unsatisfactory, then perhaps someone who is more
&gt; &gt; involved with the Tor developers -- and hence able to directly check the
&gt; &gt; keys -- ought to take this on.
&gt;
&gt; Yeah, if a package like this exists and it has tor's name attached to
&gt; it, then we should have a high degree of confidence that the package
&gt; contains the correct keys.
&gt;

I'm not sure I understood what you mean.  Are you worried about an attack?
Or just miscommunication?

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;Hi Matt,&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Mon, 20 Jul 2020 at 22:37, Matthew Finkel &lt;&lt;a \
href="mailto:sysrqb@torproject.org"&gt;sysrqb@torproject.org&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&gt; I propose \
distributing the Tor developer keys inside the Fedora package&lt;br&gt; &gt; \
distribution-gpg-keys.[1]   This would give most Linux users a trustworthy&lt;br&gt; &gt; \
chain of signatures from their own distributor (e.g. CentOS or Fedora) to&lt;br&gt; &gt; \
Tor project downloads.&lt;br&gt; &lt;br&gt;
(most? :) )&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I suspect so.   I haven't checked \
if Debian/Ubuntu have keyrings for Fedora.   (Vice versa is certainly \
true.)&lt;br&gt;&lt;/div&gt;&lt;div&gt;  &lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px \
0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt; &gt; I am \
happy to take care of this, although I am also happy if somebody who&lt;br&gt; &gt; is more \
involved with Tor than me takes this on.   I wrote a shell script&lt;br&gt; &gt; (attached) \
to acquire and organise the keys based on&lt;br&gt; &gt; &lt;a \
href="https://2019.www.torproject.org/include/keys.txt" rel="noreferrer" \
target="_blank"&gt;https://2019.www.torproject.org/include/keys.txt&lt;/a&gt;.   My script \
would install&lt;br&gt; &gt; the following keys under \
/usr/share/distribution-gpg-keys/tor:&lt;br&gt; &lt;br&gt;
Unfortuntately that file is very old and incorrect \
now.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That is unfortunate.   Is there any sensible \
way that users can currently verify signatures of their downloads?   (Can I mimic \
that?)&lt;br&gt;&lt;/div&gt;&lt;div&gt;  &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px \
0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&gt; The most \
obvious question is: how do I know that I am distributing&lt;br&gt; &gt; unadulterated \
keys?   I think the answer is that I don't!   But any attack&lt;br&gt; &gt; would have \
to affect a large group of people, and would be detected quickly&lt;br&gt; &gt; as long as \
many people are looking at the distribution-gpg-keys package.&lt;br&gt; &gt; If this \
solution is unsatisfactory, then perhaps someone who is more&lt;br&gt; &gt; involved with \
the Tor developers -- and hence able to directly check the&lt;br&gt; &gt; keys -- ought to \
take this on.&lt;br&gt; &lt;br&gt;
Yeah, if a package like this exists and it has tor's name attached to&lt;br&gt;
it, then we should have a high degree of confidence that the package&lt;br&gt;
contains the correct keys.&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div \
class="gmail_quote"&gt;&lt;br&gt;&lt;/div&gt;&lt;div class="gmail_quote"&gt;I'm not sure I understood \
what you mean.   Are you worried about an attack?   Or just \
miscommunication?&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200725111443</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-07-25 11:14:43-0400</timestampReceived><subject>[tor-dev] CAPTCHA Monitoring Project Updates #3</subject><body>

Hi everyone,

I have a few more updates since my last email (you might want to check
the project's wiki page [0] first if you didn't see my previous
emails):

-- I have the onion service [1] of the dashboard [2] up and running.
-- I was using an SQLite database and migrated it to PostgreSQL. This
migration was needed to scale up the whole system. At the moment,
there are 50000+ measurements in the database, and access time was
very long with SQLite.
-- Now there is a properly documented API [3] available for everyone's
use. You can perform queries through the API if you prefer to access
the raw data, instead of the visualizations on the dashboard.
-- The Dockerfile [4] is updated and working again.
-- I decided to give priority to the API and Dockerfile for the
"reproducibility" of the results and graphs in the dashboard. Before
the API, the graphs were using hardcoded SQL queries, which required
people to dig in the source code to find out possible mistakes. It was
also impossible for people to execute these SQL queries and see the
results themselves. API allows me to put a link to the exact API calls
to anything I place on the dashboard so that people can double-check
with the raw data if they want.
-- I'm working on adding Brave Browser's "Private Window with Tor" to
the CAPTCHA Monitor. I'm very close to finishing it and should be
ready at the end of this weekend. I expect to see a high amount of
CAPTCHA since it is using Tor without Tor Browser's user-agent (and
thus fingerprint).
-- I discussed a possible integration with the metrics website on the
metrics team meeting. I initially thought about placing CAPTCHA rate
graphs under each relay in the "Relay Search" section. If you have any
suggestions, you are welcomed to mention them in ticket
tpo/metrics/website/40002 [5].
-- Finally, you can take a look at my blog posts on DIAL's blog [6] to
see more detailed explanations, but I already summarized the blog
posts in this email.

Best,
Barkin (woswos)

[0] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/home
[1] http://captchaufjq5m2i73up537pldaxnbp6rzcbdrzc7y5rlwtx3mwigznad.onion/
[2] https://dashboard.captcha.wtf/
[3] https://api.captcha.wtf/
[4] https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/tree/master/docker
[5] https://gitlab.torproject.org/tpo/metrics/website/-/issues/40002
[6] https://hub.osc.dial.community/t/tor-project-cloudflare-captcha-monitoring/1558
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200726162151</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-07-26 16:21:51-0400</timestampReceived><subject>[tor-dev] IANA well-known URI suffix registration for tor-relay-fingerprints file</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

to reduce the risk of certain kinds of attacks 
I'm aiming to submit a short spec (like [1])

in accordance with RFC8615
https://tools.ietf.org/html/rfc8615#section-3.1

for the registration of of a suffix for the verifyurl
from
https://github.com/nusenu/ContactInfo-Information-Sharing-Specification#verifyurl

The name I have in mind is:

tor-relay-fingerprints

The file contains comments (lines starting with #)
and relay fingerprints.

https://www.iana.org/assignments/well-known-uris/well-known-uris.xhtml


Let me know if you have any feedback on this and whether you have any opinion
on whether you (The Torproject) wants to be the change controller.

The only question that came up was: Will there be two types of relay fingerprints
in the future (Ed25519)?

thanks,
nusenu


-- 
https://mastodon.social/@nusenu


[1] https://keybase.io/docs/keybase_well_known


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200730140652</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-07-30 14:06:52-0400</timestampReceived><subject>Re: [tor-dev] Safe Alternative Uses of Onion Service Keys</subject><body>

On Thu, Jul 30, 2020 at 01:18:33PM +0300, George Kadianakis wrote:
&gt; Matthew Finkel &lt;sysrqb@torproject.org&gt; writes:
&gt; 
&gt; &gt; Hello everyone,
&gt; &gt;
&gt; 
&gt; Hello hello!
&gt; 
&gt; These are all good questions and they become more and more important as
&gt; the onionspace grows and more use cases appear.
&gt; 
&gt; &gt; &lt;snip&gt;
&gt; &gt;
&gt; &gt; For computing the blinded key, the first 32 bytes of the long-term
&gt; &gt; secret key (LH) are multiplied with a blinding factor (h*a mod l), see
&gt; &gt; the specification for the value of **h** [4]. This becomes LH'
&gt; &gt; (LH-prime). The second 32 bytes of the secret key (RH) are concatenated
&gt; &gt; with a string prefix and then the SHA3-256 digest is computed of the
&gt; &gt; concatenated string. The first 32 bytes of the resulting digest become
&gt; &gt; RH' (RH-prime). LH' and RH' are used as regular ed25519 secret keys for
&gt; &gt; signing and verifying messages following EdDSA.
&gt; &gt;
&gt; 
&gt; Hmm, not sure about this last sentence. Are you implying that LH' and RH' are
&gt; two different secret keys? Because I don't think that's the case. LH' and RH'
&gt; are components of the final public/private keypair.
&gt; 

Yes, but no, your description of them as "components of" the keypair
seems more correct than mine. My goal was simply to imply that both LH'
and RH' are secret values and they are used as secret inputs into the
signing procedure, and I wanted to make it clear that the blinding
procedure begins with a valid ed25519 secret key and derives a valid
ed25519 secret key in the same format as the original (specifically a LH
value and a RH value).

Hopefully this clarification doesn't make it more confusing/wrong.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200731213220</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-07-31 21:32:20-0400</timestampReceived><subject>[tor-dev] How do Ed25519 relay IDs look like?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; The only question that came up was: Will there be two types of relay fingerprints
&gt; in the future (Ed25519)?

I assume the correct proposal for the Ed25519 keys is this:
https://gitweb.torproject.org/torspec.git/tree/proposals/220-ecc-id-keys.txt

I'm wondering what kind of format is used for a relay's Ed25519 ID in tor?

The spec says base64:

&gt; When an ed25519 signature is present, there MAY be a "master-key-ed25519"
&gt; element containing the base64 encoded ed25519 master key as a single
&gt; argument.  If it is present, it MUST match the identity key in
&gt; the certificate.

examples:
grep master-key-ed 2020-07-28-19-05-00-server-descriptors |head -2

master-key-ed25519 clT/2GWmTY/qU5TBGaudAIjOUUxUdKhMY/Q5riK6G2E
master-key-ed25519 qDI9PbwtiKzpR9phLnWI99uimdwNW8+l9c7hDoWV9dQ

Is this the canonical format you use when referring to a relay's Ed25519 identity?

(So it is not a hash of the key but the entire public Ed25519 master key of the relay \
since Ed25519 keys are so short.)

What command does a relay operator need to run to find out
his relay's Ed25519 ID on the command line?

Here is the example for the RSA1024 SHA1 fingerprint:
openssl rsa -in keys/secret_id_key -outform DER -RSAPublicKey_out 2&gt; /dev/null| \
openssl sha1 -r|cut -d" " -f1|sed -e 's/ /,/g'

also:
Are there any plans to include the Ed25519 IDs in onionoo/Relay Search?
What format would you most likely use there?

thanks,
nusenu


These are the filenames I would suggest for the well-known registry:
tor-relay-rsa-fingerprints
tor-relay-ed25519-pubkeys



-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200602201251</emailId><senderName>Matt Traudt</senderName><senderEmail>pastly@torproject.org</senderEmail><timestampReceived>2020-06-02 20:12:51-0400</timestampReceived><subject>Re: [tor-dev] Proposal 316: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>



On 6/2/20 3:01 PM, Nick Mathewson wrote:
&gt; On Thu, Apr 23, 2020 at 2:48 PM Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt;&gt;
&gt; 
&gt; Hi!  I've got some comments on the FlashFlow proposal; I'll start with
&gt; the ones that I think are most important, so that we can try to get
&gt; them out of the way.
&gt; 
&gt; First off, I'm concerned about the approach where measurers get to
&gt; consume a certain amount of bandwidth, with only a set fraction left
&gt; to devote to the background traffic.  It seems like a hostile set of
&gt; measurers could use this authority to introduce traffic patterns on
&gt; the network to assist in traffic analysis.  In general, having regular
&gt; scheduled and visible changes in relay capacity seem to me like they'd
&gt; help out traffic analysis a good deal.
&gt; 
&gt; Second, the "MSM_BG" information type also seems like a serious
&gt; traffic analysis risk.  It is, literally, telling the measurers a
&gt; report of how much traffic was sent each second on other connections.
&gt; Previously we decided that a much coarser summary than this was too
&gt; much information to publish in bandwidth-history lines, and I'm
&gt; worried not to see any analysis here.
&gt; 
&gt; {In both of the above cases we might say, "well, an attacker could do
&gt; that anyway!"  But to get the traffic information, an attacker would
&gt; need to compromise the upstream connection, and to introduce traffic
&gt; spikes the attacker would need to risk detection.  This proposal as
&gt; written would make both of these traffic analysis opportunities an
&gt; expected part of the infrastructure, which seems not-so-good to me.}
&gt; 

Not just anyone can be a measurer. A bandwidth authority runs a
coordinator and chooses to trust some small number of measurers. In
practice, knowing the humans behind the dirauths today, I'd expect each
would only trust measurers they run themself.

&gt; Third, I don't understand why we're using cell crypto here but we
&gt; aren't using RELAY cells or (apparently?) circuits.  Since TLS is
&gt; already in play, we'll already be measuring the relays' encryption
&gt; performance.  But if we do decide that cell crypto is needed, then
&gt; it's way easier to get that crypto happening if there are circuits
&gt; involved.  I think there's been some discussion of that on IRC; I'd
&gt; suggest that we try to make that work if we can.
&gt; 

Yes the outcome of some IRC discussion with asn is that we should start
with MSM_ECHO cells being RELAY cells until we discover that is
untenable. The proposal will be updated to state this as well as clarify
that we'll be building circuits on which to send measurement traffic.

&gt; Fourth, this approach to authenticating echo cell contents seems
&gt; needlessly complicated.  Instead of using random contents and
&gt; remembering a fraction of cells, it would make more sense for
&gt; measurers to use a keyed pseudorandom stream function to generate the
&gt; cells, and to verify the contents of all the cells as they come back
&gt; in.  (AES128-CTR and ChaCha8 and SHAKE128 all have nice properties
&gt; here.)
&gt; 

The motivation here is to do everything possible to prevent measurers
from being a bottleneck before the relay, which was a problem for us in
prototyping. This final transition-able FlashFlow is starting out with
verifying all cells the normal way so we can see if this can of worms is
even necessary. I'm not optimistic.

&gt; Fifth, using IP addresses for identification is NOT something we do on
&gt; the production network.  I think we should authenticate measurers by
&gt; identity key, not by IPv4 address (as is happening here, unless I
&gt; misunderstand.)
&gt; 

It's the short term deployment that we propose use IP addresses for
identification. At this point there's 1 FlashFlow deployment being
operated by us and measuring relays that have opted in to running our
patches (realistically: just us, but hopefully some adventurous
operators too). In the medium/long term coords/measurers will use proper
TLS identities that will be checked by the relays.

Maybe that's still unacceptable, but I just wanted to make that clear.

Matt
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200602215236</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-06-02 21:52:36-0400</timestampReceived><subject>[tor-dev] Towards Congestion Control Deployment in Tor-like Networks</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


This novelette-length mail is meant to provide the background
information necessary to understand choices in congestion control
deployment for Tor. Much of this background information won't be
included in my planned Tor Proposal, which will hopefully be much
shorter, but the choices made there will be informed by this material.

This material has been enhanced through review and conversations with
Toke Hiland-Jrgensen, g burdell, Rob Jansen, and George Kadianakis.
Immense credit goes to Toke in particular, for detailed and thoughtful
review, and input on queue management.

Like my last mail on this topic, this mail comes with a playlist. Fair
warning: it is not exactly easy listening. Still, hopefully it gives you
strength and inspiration in these trying times:

https://people.torproject.org/~mikeperry/borders/everybody-loves-them/TakeAKneeAndMeditateInThePaint.txt


Section -I: Recap [RECAP]

  https://wizardzines.com/zines/networking

I strongly believe that congestion control will provide the single
largest performance win for the Tor network. Specifically, it will
considerably improve both latency and throughput metrics in the best,
average, and worst case. In addition to performance, congestion control
will also provide the second-largest scalability win on our research
horizon (behind Walking Onions), by making the queue length memory
requirements of Tor relays independent of the number of circuits carried
on that relay.

I also believe we can achieve the vast majority of the benefits by
deploying an RTT-based system that only clients and Exits need to
support, specifically BOOTLEG_RTT_TOR. After this, we might consider
more advanced options based on ECN, but their benefits are far less
clear, and fraught with peril.

This mail assumes that you have read "Options for Congestion Control in
Tor-like Networks":
  https://lists.torproject.org/pipermail/tor-dev/2020-January/014140.html

Even if you have already read the Options mail, I recommend reviewing
the the SENDME section and the sections marked with TCP_HISTORY,
BOOTLEG_RTT_TOR, BACKWARD_ECN_TOR, and perhaps also FORWARD_ECN_TOR, as
understanding this mail requires an understanding of those sections. The
summary of the other sections from the Options mail is basically this:
adding ECN signals to Tor seems straight-forward, but is actually very
tricky.


Section @: Introduction and summary [INTRO_SUMMARY]

Deep understanding of the congestion control problem space is essential
because shitty congestion control will not be a huge win, and will
reduce the benefit of other performance improvements. Worse still, it
may introduce side channels and other anonymity attacks.

In particular, our level of congestion latency (and associated relay
queue lengths) will be very sensitive to congestion signal response
time, to our congestion window update rules, and also to our choice of
queue management algorithm (ie: which circuits send cells and/or
congestion signals).

Our average circuit bandwidth on the network will similarly be very
sensitive to the ability of the congestion window to quickly update and
converge on the available Bandwidth-Delay Product (BDP) of its path.

In other words, we need to make good design choices in the following
three different areas:
    I. Which congestion signal to use [CONGESTION_SIGNALS]
   II. How to update congestion window [CONTROL_ALGORITHMS]
  III. What circuits to send the signal on [QUEUE_MANAGEMENT]

The next three sections of this mail correspond to those three areas.

As before, I have tagged the specific sub-sections that will be used in
the Tor Proposal with [PROPOSAL_CANDIDATE]. I have also given tags to
section in this document. References to things in this document are
enclosed in brackets.  References to the Options mail are simply all
caps, without brackets.

The high-level plan is that we use RTT as a primary congestion signal,
as per BOOTLEG_RTT_TOR from the Options mail, and try it out with a few
different congestion algorithms, such as [TCP_VEGAS_TOR] and
[TCP_WESTWOOD_TOR].

It turns out that when RTT is used as a congestion signal, our current
Circuit-EWMA is sufficient to serve as [QUEUE_MANAGEMENT]. It also turns
out that Circuit-EWMA actually should protect us from fairness issues in
the control algorithms, and from cheaters who try to run different
congestion control algorithms. Circuit-EWMA will also deliver RTT
congestion signals more heavily to bulk circuits (because it prioritizes
their cells below light circuits), causing them to back off in favor of
lighter traffic, even as we relay fewer of their cells. Thanks goes to
Toke Hiland-Jrgensen for pointing this out.

The combination of RTT-based congestion signaling, a decent but simple
control algorithm, and Circuit-EWMA will get us the most if not all of
the benefits we seek, and only requires clients and Exits to upgrade to
use it. Once it is deployed, circuit bandwidth caps will no longer be
capped at ~500kb/sec by the fixed window sizes of SENDME; queue latency
will fall significantly; memory requirements at relays should plummet;
and bottlenecks in the network should dissipate.

However, we can still improve upon this further, after this initial
deployment. Because the "slow start" phase of TCP can take a long time,
we will also want to play around with various initial window sizes,
window growth rate parameters, and experiment with using a single
BACKWARD_ECN_TOR cell_t.command ECN-style signal. This signal will be
sent on circuits as determined by [CODEL_TOR]. An instance of
[CODEL_TOR] can be added to each TLS connection, after Circuit-EWMA is
applied.

While BACKWARD_ECN_TOR is complex and slow to roll out (all relays must
support this new cell_t.command), this optimization will likely be worth
it because BACKWARD_ECN_TOR can send a signal on a circuit to stop the
exponential growth of slow start in *less than* RTT/2 time, which is
significantly faster than implicitly measuring an RTT-based signal
(which takes RTT plus some measurement lag to act upon). This faster
signal means faster termination of slow start, which means less buffer
bloat.

For stream flow control, on the client side, we should just ack all
streams cells with a circuit-level SENDME even though they were not
delivered to their blocked stream. The local Tor client should keep
queuing them until the application reads them. Thus, a blocked client
application stream will not block other streams, but will cause Tor
client stream-level queues to build up. For exit-side streams, we should
*not* send SENDMEs until the cell has been sent on its exiting upstream
connection. This allows TCP pushback on one stream to block the entire
circuit, but this is desirable to avoid queuing, and it will only happen
in the upload direction.


Section I: Selecting Congestion Signals [CONGESTION_SIGNALS]

The "Options for Congestion Control in Tor-like Networks" mail probably
should have been titled "Options for Congestion Signals in Tor-like
Networks", as its primary focus was on the ways Tor endpoints can
receive a signal about the congestion status of a circuit on bottleneck
relays. In that post, I postponed discussion of queue management, and
deliberately under-specified how to react to a congestion signal (going
no further than saying "use SlowStart and AIMD").

I chose that scoping because the most difficult barrier we have faced in
the past decade of work on this topic is the side channels enabled by a
congestion signal (and information leaks in general).

However, I should have made our constraints more explicit. Our choice of
acceptable congestion signal mechanism is restricted by these design
constraints: 1. No side channels between Guard and Exit, or between
circuits 2. Incremental upgrade path 3. Fast response time 4. Cheater
prevention

These design constraints restrict our choice of congestion signal, but
they are not our only design constraints in this problem space. When we
get to the later sections on window control update algorithm, and queue
management algorithm, I will explicitly enumerate additional design
constraints there.  Hopefully this will provide more clarity than the
uncategorized list of "causes of death" in the Options post.

For your convenience, here's the summary table of all the options for
congestion signal again:

______________________________________________________________________
|        MIX           | CHEATING  | RESPONSE|     SIDE   |  UPGRADE |
|       TRACK          | DETECTION |   TIME  |   CHANNELS |   PATH?  |
|~~~~~~~~~~~~~~~~~~~~~~|~~~~~~~~~~~|~~~~~~~~~|~~~~~~~~~~~~|~~~~~~~~~~|
|BOOTLEG_RTT_TOR       | Exit RTT  |100c+RTT |     RTT    |   Exits  |
|FORWARD_ECN_TOR       | Circ OOM  |   RTT   |    None?   | Full Net |
|FORWARD_ECN_RTT_TOR   | Exit RTT  |   RTT   |     RTT    |Exits;Full|
|BACKWARD_ECN_TOR      |Middles;OOM|  RTT/2  | Guard-&gt;Exit| Full Net |
|BACKWARD_ECN_RTT_TOR  |Middles;RTT|RTT/2;RTT| Guard-&gt;Exit|Exits;Full|
|BACKWARD_ECN_TRAP_TOR |  Middles  |  RTT/2  |Guard&lt;-&gt;Exit| Full Net |
|EDGE_FORWARD_ECN_TOR  |Middles;OOM| 2*RTT/3 |    None?   | Full Net |
|START_BACKWARD_ECN_TOR|Middles;OOM|RTT/2;RTT|  Low/None? | Full Net |
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

My short-term favorite is BOOTLEG_RTT_TOR, because it only requires
Exit relay support to use.

Recall that BOOTLEG_RTT_TOR defines an RTT latency threshold as its
congestion signal, and was first described in section 4.1 of the N23
Defenestrator paper.  Even though the N23 paper didn't bother to name
this system, RTT use as a congestion signal in this way also resembles
TCP Vegas, as we shall see.
  https://www.cypherpunks.ca/~iang/pubs/defenestrator.pdf

Note that because Circuit-EWMA will add additional delay to loud
circuits, "cheaters" who use alternate congestion control algorithms
should end up with more delay than those who do not. This means that if
we use RTT as a congestion signal, Circuit-EWMA should provide *more*
RTT congestion signal to cheaters, and cheaters would only be punishing
themselves with more Circuit-EWMA delay. So cheater resilience for an
RTT signal is actually more well handled that I previously thought.
Again, thanks goes to Toke Hiland-Jrgensen for pointing this out.

For completeness, we will still explore some examples of alternate
"cheating" control algorithms in Section II, though.

Unfortunately, RTT is itself a side channel, as per:
  https://www.freehaven.net/anonbib/cache/ccs07-latency-leak.pdf
  https://www.robgjansen.com/publications/howlow-pets2013.pdf

There is also literature on shaping circuit bandwidth to create a side
channel. This can be done regardless of the use of congestion control,
and is not an argument against using congestion control. In fact, the
Backlit defense may be an argument in favor of endpoints monitoring
circuit bandwidth and latency more closely, as a defense:
  https://www.freehaven.net/anonbib/cache/ndss09-rainbow.pdf
  https://www.freehaven.net/anonbib/cache/ndss11-swirl.pdf
  https://www.freehaven.net/anonbib/cache/acsac11-backlit.pdf

Recall that BACKWARD_ECN_TOR used circuit-level cell_t.command to signal
congestion. This allows all relays in the path to signal congestion in
under RTT/2 in either direction, and it can be flipped on existing relay
cells already in transit, without introducing any overhead. However,
because cell_t.command is visible and malleable to all relays, it can
also be used as a side channel. So we must limit its use to a couple of
cells per circuit, at most.

Recall that FORWARD_ECN_TOR adds encrypted end-to-end relay cells that
explicitly signal congestion to either the client or the Exit, but
requires the client to mediate and echo this cell to protect against
side channels. Because congestion signals must be relayed off the
client, it still takes the Exit a full RTT to learn about congestion at
earlier nodes in the circuit.  Additionally, because this cell itself
must travel the full path in each direction, it is further delayed by
congestion on the path, and it also adds yet more congestion to
congested paths. Congestion in Exit to client direction is the most
common, as this is the download direction. It will be particularly
expensive and slow to bounce the congestion signal off the client to the
Exit.

For this reason, I think all forms of FORWARD_ECN_TOR are not likely to
be as efficient as RTT signaling, despite the FORWARD_ECN_RTT_TOR
variant initially being flagged as a PROPOSAL_CANDIDATE in the Options
mail. However, we should still keep it in mind, since RTT may turn out
to be an unreliable signal by itself.

Therefore, since RTT is already measurable with our current SENDME flow
control, I propose that we use it via BOOTLEG_RTT_TOR (or TCP Vegas),
and then add START_BACKWARD_ECN_TOR only exactly once (to exit slow
start). If RTT proves unreliable, then we can experiment with the more
heavyweight FORWARD_ECN_TOR full-cell signal.

As we shall see in the following control algorithm section, RTT-based
systems like TCP Vegas largely avoid the need to send any congestion
signal (drop or ECN). In other words: if we can rely on RTT, we should
not need any explicit signals at all (though they would improve
responsiveness).


Section II: Congestion Window Control Algorithms [CONTROL_ALGORITHMS]

Recall that the congestion window is the number of packets TCP will
allow to be sent on a connection without any acknowledgment. The
congestion window is meant to match the bandwidth-delay product of the
connection as close as possible. The bandwidth-delay product can be
thought of as the total amount of data that can be in-transit on a link
at one time without using any queue memory (bytes per second of
bandwidth multiplied by seconds of transit time delay = total bytes in
transit on the wire at one time).

On the Internet, if the congestion window exceeds the bandwidth-delay
product of a transmission path, then packets must build up in router
queues, and eventually get dropped.  If the congestion window is below
the bandwidth-delay product of the path, then all routers on the path
spend time unused and idle, and thus utilization suffers, even if users
are trying to use full bandwidth.

TCP variants basically compete on their ability to collectively track
the bandwidth-delay product of a path under a wider of a variety of
network conditions and other competing traffic.

In the interest of brevity, my "Options for Congestion Control in
Tor-like Networks" mail suggested that we update the congestion window
according to Slow Start with AIMD, in response to a congestion signal
(or lack thereof).

However, that is not the only option, and if we retain the ability to
measure RTT, it may not even be the most efficient one. So to help us
make this decision, I did a review of historical TCP and TCP-like
systems in the research literature, and will present the highlights
here.

But first, let's define the control requirements that we want to satisfy:
  1. Full bandwidth utilization of slowest TLS link in every circuit
  2. Queue length minimization at the relay sending on this TLS link
  3. Fairness between circuits (esp partially overlapping ones)
  4. Rapid convergence to full circuit capacity

These requirements mirror the requirements used in TCP evaluation. TCP
implementations compete over metrics in each of these areas, and
algorithm design is far more art than formally proved optimal or even
correct.

That does not mean that formalism is impossible, however. For a great
formal breakdown of this design space without all of TCP's baggage, see
Section 3 of the XCP paper. Note that we can't use XCP as-is because its
congestion signal fields provide way too much information for use in
potential side-channels, but it is worth a read because it clarifies the
control theory behind congestion control:
  http://conferences.sigcomm.org/sigcomm/2002/papers/xcp.pdf

In terms of how this design space is approached in TCP: utilization and
queue minimization are typically handled simultaneously - sometimes
explicitly and sometimes implicitly. Similarly, fairness is sometimes
explicitly designed for, but more often fairness is an emergent property
that is analyzed when competing against a benchmark (historically: TCP
Reno). Fairness abuse is also an area where cheating can occur that
enables cheaters to get more than their fair share of bandwidth, and
such cheating can be very hard to detect and prevent on the Internet.

Interestingly, many of the design goals of TCP are *also* improved via
queue management algorithms at routers (Section III of this mail). In
fact, our Circuit-EWMA circuit scheduler will effectively hand out RTT
congestion signals (delay) to loud circuits before quiet ones, and will
*also* enforce fairness and impede cheating, by delaying a cheater's
cells even more.

In this sense, we do not need to worry quite so much about fairness and
cheating as security properties, but a lack of fairness at the TCP
algorithm will *still* increase memory use in relays to queue these
unfair/loud circuits. So we should still be mindful of these properties
in selecting our congestion algorithm, to minimize relay memory use, if
nothing else.

For a good summary of several TCP congestion control algorithms, see:
  http://intronetworks.cs.luc.edu/1/html/reno.html ("Slow Start+AIMD")
  http://intronetworks.cs.luc.edu/1/html/newtcps.html (modern TCPs)

As you can see, the TCP design space is huge.

A good way to break down the TCP space is to separate the drop-based
algorithms from the delay-based algorithms. TCP drop-based algorithms
require either packet drops or ECN packet marking to signal congestion.
Delay based algorithms infer congestion from RTT measurements only.

But as we shall see, this distinction is artificial for us.
BOOTLEG_RTT_TOR effectively converts delay *into* an explicit congestion
signal, as far as congestion window control algorithms are concerned.
Similarly, either of our ECN signals can be used in place of the drop
signal in the algorithms below.

I'm going to review four options that strike me as most relevant to our
needs.  Two are drop-based: TCP Reno, and TCP CUBIC. Two are
delay-based: TCP Vegas, TCP Westwood.

It should be noted that there are also hybrid algorithms that use
drops/ECN in addition to delay as congestion signals, but since we are
focusing on primarily using RTT only as our signal, I won't be covering
them. For a good overview of those options, see:
  https://arxiv.org/pdf/1903.03852.pdf

Toke Hiland-Jrgensen suggested that we also investigate BBR, which is
a hybrid algorithm currently being evaluated by DropBox and Google.
However, BBR involves packet send time scheduling, which will require
replacement of Circuit-EWMA and other extensive changes. Furthermore,
BBR is still under active development, experimentation, and tuning. In
fact, while v2 has been tested by Dropbox, no IETF draft specification
exists yet. Still, for completeness:
  https://tools.ietf.org/html/draft-cardwell-iccrg-bbr-congestion-control-00
  https://queue.acm.org/detail.cfm?id=3022184
  https://datatracker.ietf.org/doc/slides-106-iccrg-update-on-bbrv2/

https://dropbox.tech/infrastructure/evaluating-bbrv2-on-the-dropbox-edge-network

I am also going to simplify and omit treatment of packet loss and
duplicate acks, since we will not be dropping any packets. Additionally,
I have normalized all formulas below to be in terms of Tor cells, rather
than bytes.

The hope is that these simplifications help us get to the essence of
what these algorithms would look like when deployed on Tor, without
getting distracted by irrelevant drop and ack synchronization management
details from TCP/IP.

However, as we move closer to specifying an actual design proposal, we
should double-check my simplifications below, for the algorithm(s) that
we actually specify.


Section II.A: TCP Reno [TCP_RENO_TOR]

  https://tools.ietf.org/html/rfc5681
  http://intronetworks.cs.luc.edu/1/html/reno.html

Until recently, TCP Reno was the most popular TCP on the Internet, and
it is still used as a fairness benchmark. While we won't be using it
directly, it is thus important to understand.

Like all TCPs, TCP Reno satisfies its utilization and queue minimization
design goals by trying to make its congestion window closely match the
bandwidth-delay product of the link. More importantly, when multiple TCP
connections are present competing for the bandwidth of a link, TCP Reno
fairly distributes the bandwidth-delay product of the link equally among
all competing TCP Reno connections.
  http://pbg.cs.illinois.edu/courses/cs598fa09/slides/05-Ashish.pdf
  https://www.cse.wustl.edu/~jain/papers/ftp/cong_av.pdf

TCP Reno probes the bandwidth-delay product by increasing its congestion
window until it overflows the the queue capacity of the slowest router
on a path, causing a packet drop or ECN signal, upon which TCP Reno
reduces its congestion window.

The initial phase of TCP Reno is called "Slow Start". For our purposes,
Slow Start in TCP Reno means that every SENDME ack, the congestion
window cwnd becomes:

   cwnd = cwnd + SENDME_RATE   (recall Tor's SENDME_RATE is 100 cells)

Because increasing the congestion window by 100 every SENDME allows the
sender to send 100 *more* 512 byte cells every 100 cells, this is an
exponential function that causes cwnd to double every cwnd cells. TCP
Reno keeps on doubling until it experiences a congestion signal.

Once a congestion signal is experienced, Slow Start is exited, and the
Additive-Increase-Multiplicative-Decrease (AIMD) steady-state phase
begins.  AIMD algorithms can be generalized with two parameters: the add
quantity, and the multiply quantity. This is written as AIMD(a,m). TCP
Reno uses AIMD(1, 0.5).  It should be noted that most later TCP's
include an AIMD component of some kind, but tend to use 0.7 for m
instead of 0.5. This allows them to recover faster from congestion.

After slow start exits, in steady-state, after every ack (SENDME)
response without a congestion signal, the window is updated as:

   cwnd = cwnd + SENDME_RATE/cwnd

This comes out to increasing cwnd by 1, every time cwnd cells are
successfully sent without a congestion signal occurring. Thus this is
additive linear growth, not exponential growth.

If there was a congestion signal, cwnd is updated as:

   cwnd  = cwnd * m   (m=0.5 or 0.7)

This is called "Fast Recovery". If you dig into the RFCs, actual TCP
Reno has some additional details for responding to multiple packet
losses that in some cases can fall back into slow-start. However, for
our purposes, the congestion window should only be updated once per cwnd
cells, in either the congestion case, or the non-congestion case.

TCP Reno (and all TCPs) also revert to slow start when the connection
has been idle, in case bottleneck capacity has changed in this time. We
may or may not want to do this, as slow start has a dramatic impact on
page load times.

TCP Reno is still used as the benchmark to determine fairness. If an
algorithm is "TCP Friendly", this basically means that when competing
with TCP Reno to use spare path capacity, it does not get its ass
kicked, and it does not kick Reno's ass. Several algorithms contain
hacks or special cases to preserve this property. If this fairness
property holds, a bunch of math can prove convergence rates,
utilization, congestion window sizes, and even queue sizes.  Modern
queue management also relies on this math to auto-tune queue parameters,
as we will see in Section III.
  http://pbg.cs.illinois.edu/courses/cs598fa09/slides/05-Ashish.pdf
  https://www.icir.org/tfrc/aimd.pdf


Section II.B: TCP Cubic [TCP_CUBIC_TOR]

  http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-cubic
  https://pandorafms.com/blog/tcp-congestion-control/
  https://tools.ietf.org/html/rfc8312

TCP Reno unfortunately does not perform optimally for networks where the
natural packet loss rate starts to become frequent, which happens for
both high bandwidth and high latency networks. This shortcoming has lead
to a huge explosion of competition among replacements and improvements
for this use case, and TCP Cubic has won out (for now).

TCP Cubic basically takes TCP Reno and tweaks the additive portion of
AIMD behavior to be a cubic function (y=x^3) instead of linearly
additive. The cubic function was chosen because it is concave, then
flat, and then convex.  The concave piece allows for quickly recovering
after congestion (or non-congestion-related packet loss), and the convex
piece allows for gently probing for fresh spare link capacity.

Because of adoption by both the Linux kernel and the Windows kernel as
the default TCP, TCP Cubic is now the most popular TCP on the Internet.

Unfortunately, TCP Cubic is complicated. It has multiple magic numbers,
and is defined piece wise depending on how its congestion window would
compare to the equivalent TCP Reno window (to ensure the "TCP Friendly"
property -- without this hack, TCP Cubic is "too polite" and TCP Reno
eats its lunch). It additionally has time-based components that must be
clocked relative to current measured RTT (though it does not use RTT as
a congestion signal).

The cubic congestion window is defined as:

   W_max = previous window size before last congestion signal
   W_cubic(t) = C*(t-K)^3 + W_max

With magic number constants:
   C = 0.4
   beta_cubic = 0.7
   K = cubic_root(W_max*(1-beta_cubic)/C)

To maintain competitiveness with TCP Reno, Cubic keeps a running
estimate of an equivalent TCP Reno's window size, using the AIMD math
cited for Reno above:

    W_est(t) = W_max*beta_cubic +
                   [3*(1-beta_cubic)/(1+beta_cubic)] * (t/RTT)

    if W_est(t) &gt; W_cubic(t):
        cwnd = W_est(t)
    else:
        cwnd = cwnd + (W_cubic(t+RTT) - cwnd)/cwnd

Upon congestion signal, Cubic uses its beta_cubic parameter (0.7), and
thus does not back off quite as far as Reno:

    W_max = cwnd
    cwnd = cwnd * beta_cubic

It is pretty easy to convince yourself that Cubic will do as least as
well as TCP Reno (thanks to the AIMD Reno window comparison hack), but
it is very hard to conceptualize the above and convince yourself that it
is the best we could possibly do for our use case. Especially since Tor
is *not* affected by an increasing inherent drop rate as bandwidth
increases, unlike the Internet.

For these reasons, the complexity of TCP Cubic does not strike me as
worthwhile, as compared to other, simpler candidates.


Section II.C: TCP Vegas and [TCP_VEGAS_TOR] [PROPOSAL_CANDIDATE]

  http://pages.cs.wisc.edu/~akella/CS740/F08/740-Papers/BOP94.pdf
  ftp://ftp.cs.princeton.edu/techreports/2000/628.pdf (lol ftp, sorry)

Similar to BOOTLEG_RTT_TOR from my Options mail, TCP Vegas was designed
to make use of RTT and bandwidth estimation to avoid queue congestion,
and thus avoid any dropped packets or ECN signals. However, TCP Vegas
actually directly estimates queue length of the bottleneck router, and
aims to minimize the packets in that queue.

To accomplish this, TCP Vegas maintains two RTT measurements:
RTT_current and RTT_min. It also maintains a bandwidth estimate.

The bandwidth estimate is the current congestion window size divided by
the RTT estimate:

   BWE = cwnd/RTT_current

(Note: In later TCP Vegas relatives like TCP Westwood, this bandwidth
estimate was improved to use an explicit count of the unacked packets in
transit, instead of cwnd).

Recall that in order to utilize the full capacity of the link, all TCPs
attempt to maintain its congestion window as close to the
bandwidth-delay product (ie: the "memory capacity") of the transmission
path as possible.

The extra queue use along a path can thus be estimated by first
estimating the path's bandwidth-delay product:

   BDP = BWE*RTT_min

TCP Vegas then estimates the queue use caused by congestion as:

   queue_use = cwnd - BDP
             = cwnd - cwnd*RTT_min/RTT_current
             = cwnd * (1 - RTT_min/RTT_current)

If queue_use drops below a threshold alpha (typically 2-3 packets for
TCP, but perhaps double or triple that for our smaller cells), then the
congestion window is increased. If queue_use exceeds a threshold beta
(typically 4-6 packets, but again we should probably double or triple
this), then the congestion window is decreased. This update happens only
once per cwnd packets:

   if queue_use &lt; alpha:
     cwnd = cwnd + 1
   elif queue_use &gt; beta:
     cwnd = cwnd - 1

As a backstop, TCP Vegas still will half its congestion window in the
event that a congestion signal (packet drop or ECN) still occurs.
However, such packet drops should not actually even happen, unless Vegas
is fighting with a less fair control algorithm that is causing drops
instead of backing off based on queue delay.

Vegas also uses this queue_use estimate to govern its initial slow start
behavior. During slow start, the Vegas congestion window grows
exponentially, but only half as fast as Reno (to avoid excessive
congestion). For us, this means that cwnd is updated every SENDME ack
by:

   if queue_use &lt; gamma:
     cwnd = cwnd + SENDME_RATE/2

This exponential increase continues until the queue_use estimate exceeds
"gamma" (which is determined experimentally and sadly not listed in the
TCP Vegas paper). If I had to guess, gamma is probably close to beta
(4-6 packets).

Because Vegas tries much harder to avoid congestion than TCP Reno, Vegas
is vulnerable to cheating through fairness abuse. When TCP Vegas
competes against a TCP Reno-style TCP that responds only to packet drops
(or ECN signals in our case) and ignores RTT, TCP Vegas detects
congestion earlier than TCP Reno would, and ends up yielding bandwidth
to TCP Reno. This means that Vegas does *not* have the "TCP Friendly"
property that modern AQM algorithms depend on for their
parameterization.

Note that we should expect the same thing to happen if TCP Vegas
competed with BOOTLEG_RTT_TOR algorithm run by cheaters. However, since
RTT is being used as the congestion signal in both cases, Circuit-EWMA
should still balance this out, but we should experiment with this to
confirm. There may still be additional queuing memory costs in the
presence of cheaters, compared to either pure [TCP_VEGAS_TOR] or pure
BOOTLEG_RTT_TOR. Even so: this form of cheating is also pretty easy for
honest Exit nodes to detect, and cheating clients only get benefit in
the upload direction, even if they did cheat.

To see this a bit more concretely, if we sub in TCP Reno in
BOOTLEG_RTT_TOR, during slow start we have:

    T=(1a)*rtt_min+a*rtt_max

    If rtt &lt; T:
      cwnd = cwnd + SENDME
    else:
      exit slow start

And then for steady state:

    If rtt &lt; T:
      cwnd = cwnd + SENDME_RATE/cwnd
    else:
      cwnd = cwnd * 0.5

The 'a' parameter from BOOTLEG_RTT_TOR is operating similarly to the
queue_len criterion of [TCP_VEGAS_TOR], but the window update rules are
[TCP_RENO_TOR], which are more aggressive than TCP Vegas.

So effectively, this is still [TCP_VEGAS_TOR] with a different target
condition for queue_len. This means we could expect BOOTLEG_RTT_TOR to
drive the congestion to some higher rate of queue use than
[TCP_VEGAS_TOR], and senders who use it may out-compete Vegas much like
TCP Reno out-competes Vegas, until Circuit-EWMA starts punishing them
(at the expense of more queue memory waste).

This also shows us a crucial testing consideration: [TCP_VEGAS_TOR] may
not compete well with our current SENDME congestion control, since it's
ability to set queue_target may cause it to de-prioritize itself below
competing SENDME flows. BOOTLEG_RTT_TOR, on the other hand, will allow
us to set its 'a' parameter at whatever point makes it competitive with
SENDME. For this reason, BOOTLEG_RTT_TOR may yield better performance
characteristics until all clients upgrade.


Section II.D: TCP Westwood [TCP_WESTWOOD_TOR] [PROPOSAL_CANDIDATE]

  https://tools.ietf.org/html/rfc8290#section-4.1
  http://intronetworks.cs.luc.edu/1/html/newtcps.html#tcp-westwood

TCP Westwood is essentially TCP Reno, but if the current BDP estimate is
greater than half the current congestion window, TCP Westwood uses that
instead of halving the congestion window, during a congestion signal.

In other words, upon a congestion signal, TCP Westood does:

   cwnd = max(cwnd * 0.5, BDP_estimate)

This has the effect of recovering from congestion events much quicker
than TCP Reno, and thus utilizing more of the path capacity.

Westwood+ also has some improvements on TCP Vegas's BDP_estimate in
order to smooth it in the presence of delayed and/or dropped acks:

    BWE_k = a*BWE_k-1 + (1a)*BWM_k

We may not need this smoothing as much, because we do not have any
dropped acks, and dropped acks were far more damaging to TCP Vegas than
slightly delayed acks.


Section III: Queue Management Algorithms [QUEUE_MANAGEMENT]

On the Internet, Queue Management Algorithms are used by routers to
decide how long their queues should be, which packets they should drop
and when, and which connections to send ECN signals on and when. Queue
management is almost as large of a research area as congestion control.

Thanks to bittorrent and video streaming, queue management also grew to
consider fairness or QoS between flows. This is done by separating
queues or imposing a scheduling algorithm on packet ordering. For an
excellent overview of fairness vs queue management, see RFC 7806:
   https://tools.ietf.org/html/rfc7806

Since Tor relays cannot drop packets, our design goals are slightly
different than Internet queue management. We care about the following
design goals:
  1. Prioritize well-behaved/light circuits over loud/heavy ones
  2. Decide when to send ECN signals
  3  Decide which circuits to send ECN signals on
  4. Detect which circuits are queuing too much (or otherwise cheating)

Recall that Tor has already deployed Circuit-EWMA in order to meet goal
#1.  Circuit-EWMA tries to give priority to less loud circuits in the
circuit scheduler, so that interactive applications experience less
latency than bulk transfers.
  https://www.cypherpunks.ca/~iang/pubs/ewma-ccs.pdf

Circuit-EWMA can be viewed as a fairness algorithm as per RFC 7806
Section 2, since it schedules flows independently with the target
fairness property of prioritizing quiet circuits cells over loud ones.
When Circuit-EWMA is used in combination with RTT as a congestion
signal, it is effectively *also* a marking algorithm. This is because it
*also* distributes RTT congestion signals more frequently to loud
circuit:
  https://tools.ietf.org/html/rfc7806#section-2
  https://tools.ietf.org/html/rfc7806#section-3

Recall that Tor also had to deploy KIST, to move queues from the Linux
kernel into Tor, for Circuit-EWMA to properly prioritize them. See
Section 4 and 5 of the full-length KIST paper for details on this
interaction, and see page 5 for a good graphical depiction of all the
queuing points in Tor and the Kernel:
  https://matt.traudt.xyz/static/papers/kist-tops2018.pdf

It is likely the case that Circuit-EWMA and KIST are all we need if we
only use RTT signaling. But if we add in ECN, at minimum we will need to
update Circuit-EWMA to inform us which circuit(s) to send ECN signals
on. In fact, thanks to RFC7806's distinction between fairness and
management, modern Internet queue management algorithms compose well
with Circuit-EWMA, allowing us to still use Circuit-EWMA for the
fairness portion, but use an existing Internet algorithm for the ECN
marking. So it is useful to review Internet history here, as well as
current state-of-the-art.

On the Internet, queue management algorithms arose fairly early for one
primary reason: early routers performed what is called "tail dropping".
Tail dropping means that routers allowed their queues to get full, and
then started dropping all packets that arrived while queue remained
full. This has all kinds of negative consequences, but the easiest to
intuitively understand is that if you wait until your queue is full
before you start dropping packets, and then drop all of the packets that
arrive from then on, competing TCP connections will all back off at the
same time, leading to lulls in network utilization.

The key innovation to address tail dropping was to randomly drop (or ECN
mark) packets early, before the queue was full, with a per-packet drop
probability.  This probability was computed based on many factors of the
link, and sometimes based on individual TCP connection tracking.

Until very recently, both queue management and fair queuing algorithms
tended to have many knobs that must be tuned for specific kinds of links
and load levels. The Internet seems to be converging on three main
contenders for "knobless" queue management: PIE, ARED, and CoDel. Here's
some recent review material:

http://content.ikr.uni-stuttgart.de/Content/Publications/Archive/Wa_EUNICE_14_40255.pdf
  https://datatracker.ietf.org/meeting/88/materials/slides-88-iccrg-4/

However, be aware that these knobless systems make assumptions about the
congestion control algorithms and the latency of the connections that
may not apply to us. The assumptions are most clearly specified in
Section 3.2 of the CoDel RFC, and are closely related to the "TCP
Fairness vs TCP Reno" assumption from our congestion control review:
  https://tools.ietf.org/html/rfc8289#section-3.2

Ok, so let's review the top "knobless" contenders.


Section III.A: PIE and ARED [ARED_PIE_TOR]

  https://tools.ietf.org/html/rfc8033
  http://www.icir.org/floyd/papers/adaptiveRed.pdf

As a quick summary, both PIE and ARED manage their queues by dropping
packets probabalistically. In both systems, the per-packet drop
probability is updated in proportion to average queue transit time --
longer queues mean the drop probability is increased.

Both systems decide to drop individual packets from the queue in using
this probability. This has the effect that louder flows (with more
packets) are also more likely to experience drops (or ECN congestion
marking). But otherwise they have no explicit notion of fairness.

This makes them marking algorithms as per RFC7806's classification. If
explicit QoS or fairness is desired, they have to be deployed in
combination with a fairness algorithm to prioritize between separate
queues, again as per RFC 7806 Section 3.3:
  https://tools.ietf.org/html/rfc7806#section-3.3

Recall that Tor has multiple levels of queues: Circuit, TLS connections,
and kernel buffers, as per Figure 1 on page 5 in the KIST paper:
  https://matt.traudt.xyz/static/papers/kist-tops2018.pdf

Even if we keep Circuit-EWMA for scheduling (and thus fairness), we can
still add in PIE or ARED per each TLS connection. If the average total
queue length for all circuits on a TLS connection grows beyond the
marking threshold for PIE/ARED, we could then begin sending congestion
signals on circuits, as they send cells, as per the cell drop
probability of these algorithms.

However, because we only want to send one BACKWARD_ECN_TOR signal per
circuit, we will have to save these signals for circuits that have not
yet gotten one.  It is an open question how we should manage the mark
probability if we have to pass over a circuit because we already sent a
backward ECN signal on it.


Section III.B: CoDel and FQ_CoDel [CODEL_TOR] [PROPOSAL_CANDIDATE]

  https://queue.acm.org/detail.cfm?id=2209336
  https://tools.ietf.org/html/rfc8289
  https://tools.ietf.org/html/rfc8290

CoDel is a relatively recent algorithm that is gaining traction because
of its simple elegance. Like PIE and ARED, CoDel itself is a marking
algorithm, and can be combined with any fairness/QoS algorithm. It also
comes with its own fairness algorithm, called FQ_CoDel.
  https://tools.ietf.org/html/rfc7806#section-3.2

Despite being touted as parameterless, CoDel does have two parameters:
  inspection_interval &lt;- set above max RTT (but not too high)
  min_queue_target &lt;- set to 5% of min RTT

CoDel tags packets with timestamps as soon as they enter the queue.
Every inspection_interval, it examines the queue to see if any packets
have waited longer than target_delay. If they have, it begins dropping
packets (sending ECN signals in our case).

Because CoDel is accurately tracking the time *each* packet spends in
the queue, it is able to differentiate between "good" queues (not
congested), vs "bad" queues (congested), on a packet-by-packet basis.
This good vs bad distinction is determined by comparing the packet
transit time to min_queue_target. If a packet exceeds this transit time,
then the queue is bad, and the packet must be dropped or ECN marked.

It is this per-packet distinction that significantly separates CoDel
from PIE and ARED, which both use average queue times. This was the
source of some controversy, as per-packet timestamping was initially
argued to be too expensive. But on modern commodity hardware, this
per-packet timestamping is actually incredibly efficient. It also allows
CoDel to converge on the min_queue_target very rapidly, with high link
utilization.

However, it would seem that because we can't drop packets, sojourn times
will *not* decrease down to min_queue_target immediately upon congestion
for Tor.  We will have to wait for the actual backoff signal to
propagate (1 RTT) before the queue size changes due to backoff.
According to Toke Hiland-Jrgensen (one of the FQ_CoDel spec authors),
this should not be that significant, but it should be tested.

FQ_CoDel extends CoDel to provide fairness in a very similar way as
Circuit-EWMA does, by separating out TCP connections into "generated a
queue recently" and "did not generate a queue recently". This allows
packets from flows that are not causing congestion to be sent more
quickly than flows that are. This also has the side effect that when
connections build long FQ queues, their packets spend more time in
queues, and have an increased probability of being ECN marked or
dropped.
  https://ieeexplore.ieee.org/document/8469111

Like CoDel, FQ_CoDel relies on the assumption that it can drop a lot of
packets at once to correct queue sizes instantly:
  https://tools.ietf.org/html/rfc8290#section-4.1

This makes me think we should not rush to replace Circuit-EWMA with
FQ_CoDel, but we may get benefit from doing CoDel on a per-TLS
connection basis, just as is described for PIE and ARED above. In this
case, it is more clear which circuits to ECN mark. Whenever a cell has a
Circuit-EWMA circuitmux queue transit time longer than the target queue
time threshold (min_queue_target), that circuit gets an ECN mark. If it
has already been ECN marked, no biggie.  In other words: The decision to
ECN mark circuits is completely dependent only on how long their cells
traverse our queues, and does not require any capacity estimates or
other measurements. Very clean.

So if we decide we want to try ECN, I think Circuit-EWMA with CoDel is a
smart first choice. We would then use CoDel to deliver exactly one
BACKWARD_ECN_TOR signal when it detects a circuit's queues are too long.
This RTT/2 signal should cause the circuit to exit slow start more
quickly than RTT measurement by endpoints will.


Section IV: Next Steps [NEXT_STEPS]

After this extended review, I am convinced that an RTT-based approach
can provide a comprehensive solution to all of our design requirements,
and can be enhanced based on experimentation and further additions. Such
an approach also only requires clients and Exits (or just clients and
onion services) to upgrade to initially deploy.

However, we can still improve on this with a few enhancements. In
particular, we can compare [TCP_VEGAS_TOR] to [TCP_WESTWOOD_TOR] to
BOOTLEG_RTT_TOR, and see how they perform in competition with each
other, and in competition with Tor's currently fixed-size SENDME
windows. We can also implement CoDel in circuitmux to track transit
times and determine which circuits to send a single BACKWARD_ECN_TOR
signal, to exit slow start on circuits more quickly, and we can play
around with higher initial window sizes. We can do this experimentation
first in Shadow, and also on the live network via consensus parameters.

The immediate next steps here are to create a proper Tor Proposal from
the sections tagged [PROPOSAL_CANDIDATE] above.



-- 
Mike Perry


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200603125353</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@torproject.org</senderEmail><timestampReceived>2020-06-03 12:53:53-0400</timestampReceived><subject>Re: [tor-dev] Moving key material out of the main tor process</subject><body>

Nick Mathewson &lt;nickm@freehaven.net&gt; wrote
Tue, 2 Jun 2020 11:51:07 -0400:

&gt; One issue with the ssh-agent protocol as I see it is that it isn't
&gt; originally designed for decryption or for high-volume usage.  If we
&gt; want to support those in the future, we'll need to make sure that we
&gt; have an extension path for them in whatever vault tool we're using.

Good point. The extension mechanism defined for the protocol (see
[draft-miller-ssh-agent-04] section 4.7) could be used for finding out
if and how other types of operations are supported by the "vault" or
"crypto daemon". This sounds like an invitation to complicate things
though, like defining an extension function returning a new endpoint for
a separate, more powerful, protocol. But maybe we should be able to
constrain ourselves.

An alternative to using the ssh-agent protocol extension would be to
have the internal key data type in tor include a protocol and an
endpoint and let the user set things up through torrc (default
"call_openssl://path/to/privkey"). This would allow for expressing that
your signing keys have moved from "ssh-agent://path/to/ssh-agent.socket"
to "new-and-shiny://path/to/powerful-crypto-daemon.socket".

And even if I don't like it much, there's always the option of defining
something new, encompassing all our needs from start. To be weighed
against the upside of being able to use already well established
software for our specific needs of signing. One could argue that the
minimal implementation of such a protocol, only for signing, could
forward requests to a running instance of ssh-agent but the number of
moving parts just went up. Simple is better here IMO.

[draft-miller-ssh-agent-04] https://www.ietf.org/id/draft-miller-ssh-agent-04.txt
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200603150356</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-06-03 15:03:56-0400</timestampReceived><subject>[tor-dev] Proposal 323: Specification for Walking Onions</subject><body>

```
Filename: 323-walking-onions-full.md
Title: Specification for Walking Onions
Author: Nick Mathewson
Created: 3 June 2020
Status: Draft
```


&lt;!-- Section 1 --&gt; &lt;a id='S1'&gt;&lt;/a&gt;

# Introduction: A Specification for Walking Onions

In Proposal 300, I introduced Walking Onions, a design for scaling
Tor and simplifying clients, by removing the requirement that every
client know about every relay on the network.

This proposal will elaborate on the original Walking Onions idea,
and should provide enough detail to allow multiple compatible
implementations. In this introduction, I'll start by summarizing the
key ideas of Walking Onions, and then outline how the rest of this
proposal will be structured.

&lt;!-- Section 1.1 --&gt; &lt;a id='S1.1'&gt;&lt;/a&gt;

## Remind me about Walking Onions again?

With Tor's current design, every client downloads and refreshes a
set of directory documents that describe the directory authorities'
views about every single relay on the Tor network.  This requirement
makes directory bandwidth usage grow quadratically, since the
directory size grows linearly with the number of relays, and it is
downloaded a number of times that grows linearly with the number of
clients.  Additionally, low-bandwidth clients and bootstrapping
clients spend a disproportionate amount of their bandwidth loading
directory information.

With these drawbacks, why does Tor still require clients to
download a directory?  It does so in order to prevent attacks that
would be possible if clients let somebody else choose their
paths through the network, or if each client chose its paths from a
different subset of relays.

Walking Onions is a design that resists these attacks without
requiring clients ever to have a complete view of the network.

You can think of the Walking Onions design like this: Imagine that with
the current Tor design, the client covers a wall with little pieces
of paper, each representing a relay, and then throws a dart at the wall
to pick a relay.  Low-bandwidth relays get small pieces of paper;
high-bandwidth relays get large pieces of paper.  With the Walking
Onions design, however, the client throws its dart at a _blank
wall_, notes the position of the dart, and asks for the relay whose
paper _would be_ at that position on a "standard wall".  These
"standard walls" are mapped out by directory authorities in advance,
and are authenticated in such a way that the client can receive a
proof of a relay's position on the wall without actually having to
know the whole wall.

Because the client itself picks the position on the wall, and
because the authorities must vote together to build a set of
"standard walls", nobody else controls the client's path through the
network, and all clients can choose their paths in the same way.
But since clients only probe one position on the wall at a time,
they don't need to download a complete directory.

(Note that there has to be more than one wall at a time: the client
throws darts at one wall to pick guards, another wall to pick
middle relays, and so on.)

In Walking Onions, we call a collection of standard walls an
"ENDIVE" (Efficient Network Directory with Individually Verifiable
Entries).  We call each of the individual walls a "routing index",
and we call each of the little pieces of paper describing a relay and
its position within the routing index a "SNIP" (Separable Network
Index Proof).

For more details about the key ideas behind Walking Onions, see
proposal 300.  For more detailed analysis and discussion, see
"Walking Onions: Scaling Anonymity Networks while Protecting Users"
by Komlo, Mathewson, and Goldberg.

&lt;!-- Section 1.2 --&gt; &lt;a id='S1.2'&gt;&lt;/a&gt;

## The rest of this document

This proposal is unusually long, since Walking Onions touches on many
aspects of Tor's functionality.  It requires changes to voting,
directory formats, directory operations, circuit building, path
selection, client operations, and more.  These changes are described in the
sections listed below.

Here in section 1, we briefly reintroduce Walking Onions, and talk
about the rest of this proposal.

Section 2 will describe the formats for ENDIVEs, SNIPs, and related
documents.

Section 3 will describe new behavior for directory authorities as
they vote on and produce ENDIVEs.

Section 4 describes how relays fetch and reconstruct ENDIVEs from
the directory authorities.

Section 5 has the necessary changes to Tor's circuit extension
protocol so that clients can extend to relays by index position.

Section 6 describes new behaviors for clients as they use Walking
Onions, to retain existing Tor functionality for circuit construction.

Section 7 explains how to implement onion services using Walking
Onions.

Section 8 describes small alterations in client and relay behavior
to strengthen clients against some kinds of attacks based on relays
picking among multiple ENDIVEs, while still making the voting
system robust against transient authority failures.

Section 9 closes with a discussion of how to migrate from the
existing Tor design to the new system proposed here.

&lt;!-- Section 1.2.1 --&gt; &lt;a id='S1.2.1'&gt;&lt;/a&gt;

### Appendices

Additionally, this proposal has several appendices:

Appendix A defines commonly used terms.

Appendix B provides definitions for CDDL grammar productions that
are used elsewhere in the documents.

Appendix C lists the new elements in the protocol that will require
assigned values.

Appendix D lists new network parameters that authorities must vote
on.

Appendix E gives a sorting algorithm for a subset of the CBOR object
representation.

Appendix F gives an example set of possible "voting rules" that
authorities could use to produce an ENDIVE.

Appendix G lists the different routing indices that will be required
in a Walking Onions deployment.

Appendix H discusses partitioning TCP ports into a small number of
subsets, so that relays' exit policies can be represented only as
the group of ports that they support.

Appendix Z closes with acknowledgments.

&lt;!-- Section 1.2.2 --&gt; &lt;a id='S1.2.2'&gt;&lt;/a&gt;

### Related proposals

The following proposals are not part of the Walking Onions proposal,
but they were written at the same time, and are either helpful or
necessary for its implementation.

318-limit-protovers.md restricts the allowed version numbers for
each subprotocol to the range 0..63.

319-wide-everything.md gives a general mechanism for splitting relay
commands across more than one cell.

320-tap-out-again.md attempts to remove the need for TAP keys in
the HSv2 protocol.

321-happy-families.md lets families be represented with a single
identifier, rather than a long list of keys

322-dirport-linkspec.md allows a directory port to be represented
with a link specifier.

&lt;!-- Section 2 --&gt; &lt;a id='S2'&gt;&lt;/a&gt;

# Document Formats: ENDIVEs and SNIPs

Here we specify a pair of related document formats that we will
use for specifying SNIPs and ENDIVEs.

Recall from proposal 300 that a SNIP is a set of information about
a single relay, plus proof from the directory authorities that the
given relay occupies a given range in a certain routing index.
For example, we can imagine that a SNIP might say:

* Relay X has the following IP, port, and onion key.
* In the routing index Y, it occupies index positions 0x20002
  through 0x23000.
* This SNIP is valid on 2020-12-09 00:00:00, for one hour.
* Here is a signature of all the above text, using a threshold
  signature algorithm.

You can think of a SNIP as a signed combination of a routerstatus and
a microdescriptor... together with a little bit of the randomized
routing table from Tor's current path selection code, all wrapped
in a signature.

Every relay keeps a set of SNIPs, and serves them to clients when
the client is extending by a routing index position.

An ENDIVE is a complete set of SNIPs.  Relays download ENDIVEs, or
diffs between ENDIVEs, once every voting period.  We'll accept some
complexity in order to make these diffs small, even though some of the
information in them (particularly SNIP signatures and index
ranges) will tend to change with every period.

&lt;!-- Section 2.1 --&gt; &lt;a id='S2.1'&gt;&lt;/a&gt;

## Preliminaries and scope

&lt;!-- Section 2.1.1 --&gt; &lt;a id='S2.1.1'&gt;&lt;/a&gt;

### Goals for our formats

We want SNIPs to be small, since they need to be sent on the wire
one at a time, and won't get much benefit from compression.  (To
avoid a side-channel, we want CREATED cells to all be the same
size, which means we need to pad up to the largest size possible
for a SNIP.)

We want to place as few requirements on clients as possible, and we
want to preserve forward compatibility.

We want ENDIVEs to be compressible, and small. We want successive
ENDIVEs to be textually similar, so that we can use diffs to
transmit only the parts that change.

We should preserve our policy of requiring only loose time
synchronization between clients and relays, and allow even looser
synchronization when possible.  Where possible, we'll make the
permitted skew explicit in the protocol: for example, rather than
saying "you can accept a document 10 minutes before it is valid", we
will just make the validity interval start 10 minutes earlier.

&lt;!-- Section 2.1.2 --&gt; &lt;a id='S2.1.2'&gt;&lt;/a&gt;

### Notes on Metaformat

In the format descriptions below, we will describe a set of
documents in the CBOR metaformat, as specified in RFC 7049.  If
you're not familiar with CBOR, you can think of it as a simple
binary version of JSON, optimized first for simplicity of
implementation and second for space.

I've chosen CBOR because it's schema-free (you can parse it
without knowing what it is), terse, dumpable as text, extensible,
standardized, and very easy to parse and encode.

We will choose to represent many size-critical types as maps whose
keys are short integers: this is slightly shorter in its encoding
than string-based dictionaries.  In some cases, we make types even
shorter by using arrays rather than maps, but only when we are
confident we will not have to make changes to the number of elements
in the future.

We'll use CDDL (defined in RFC 8610) to describe the data in a way
that can be validated -- and hopefully, in a way that will make it
comprehensible. (The state of CDDL tooling is a bit lacking at the
moment, so my CDDL validation will likely be imperfect.)

We make the following restrictions to CBOR documents that Tor
implementations will _generate_:

   * No floating-point values are permitted.

   * No tags are allowed unless otherwise specified.

   * All items must follow the rules of RFC 7049 section 3.9 for
     canonical encoding, unless otherwise specified.

Implementations SHOULD accept and parse documents that are not
generated according to these rules, for future extensibility.
However, implementations SHOULD reject documents that are not
"well-formed" and "valid" by the definitions of RFC 7049.

&lt;!-- Section 2.1.3 --&gt; &lt;a id='S2.1.3'&gt;&lt;/a&gt;

### Design overview: signing documents

We try to use a single document-signing approach here, using a hash
function parameterized to accommodate lifespan information and an
optional nonce.

All the signed CBOR data used in this format is represented as a
binary string, so that CBOR-processing tools are less likely to
re-encode or transform it.   We denote this below with the CDDL syntax
`bstr .cbor Object`, which means "a binary string that must hold a valid
encoding of a CBOR object whose type is `Object`".

&lt;!-- Section 2.1.4 --&gt; &lt;a id='S2.1.4'&gt;&lt;/a&gt;

### Design overview: SNIP Authentication

I'm going to specify a flexible authentication format for SNIPs that
can handle threshold signatures, multisignatures, and Merkle trees.
This will give us flexibility in our choice of authentication
mechanism over time.

  * If we use Merkle trees, we can make ENDIVE diffs much much smaller,
    and save a bunch of authority CPU -- at the expense of requiring
    slightly larger SNIPs.

  * If Merkle tree root signatures are in SNIPs, SNIPs get a
    bit larger, but they can be used by clients that do not have the
    latest signed Merkle tree root.

  * If we use threshold signatures, we need to depend on
    not-yet-quite-standardized algorithms.  If we use multisignatures,
    then either SNIPs get bigger, or we need to put the signed Merkle
    tree roots into a consensus document.

Of course, flexibility in signature formats is risky, since the more
code paths there are, the more opportunities there are for nasty bugs.
With this in mind, I'm structuring our authentication so that there
should (to the extent possible) be only a single validation path for
different uses.

With this in mind, our format is structured so that "not using a
Merkle tree" is considered, from the client's point of view, the same as
"using a Merkle of depth 1".

The authentication on a single snip is structured, in the abstract, as:
   - ITEM: The item to be authenticated.
   - PATH: A string of N bits, representing a path through a Merkle tree from
     its root, where 0 indicates a left branch and 1 indicates a right
     branch.  (Note that in a left-leaning tree, the 0th leaf will have
     path 000..0, the 1st leaf will have path 000..1, and so on.)
   - BRANCH: A list of N digests, representing the digests for the
     branches in the Merkle tree that we are _not_ taking.
   - SIG: A generalized signature (either a threshold signature or a
     multisignature) of a top-level digest.
   - NONCE: an optional nonce for use with the hash functions.

Note that PATH here is a bitstring, not an integer! "0001" and "01" are
different paths, and "" is a valid path, indicating the root of the tree.

We assume two hash functions here: `H_leaf()` to be used with leaf
items, and `H_node()` to be used with intermediate nodes.  These functions
are parameterized with a path through the tree, with
the lifespan of the object to be signed, and with a nonce.

To validate the authentication on a SNIP, the client proceeds as follows:

    Algorithm: Validating SNIP authentication

    Let N = the length of PATH, in bits.

    Let H = H_leaf(PATH, LIFESPAN, NONCE, ITEM).

    While N &gt; 0:
       Remove the last bit of PATH; call it P.
       Remove the last digest of BRANCH; call it B.

       If P is zero:
           Let H = H_node(PATH, LIFESPAN, NONCE, H, B)
       else:
           Let H = H_node(PATH, LIFESPAN, NONCE, B, H)

       Let N = N - 1

    Check wither SIG is a correct (multi)signature over H with the
    correct key(s).

Parameterization on this structure is up to the authorities.  If N is
zero, then we are not using a Merkle tree.  The generalize signature
SIG can either be given as part of the SNIP, or as part of a consensus
document.  I expect that in practice, we will converge on a single set of
parameters here quickly (I'm favoring BLS signatures and a Merkle
tree), but using this format will give clients the flexibility to handle
other variations in the future.

For our definition of `H_leaf()` and `H_node()`, see "Digests and
parameters" below.

&lt;!-- Section 2.1.5 --&gt; &lt;a id='S2.1.5'&gt;&lt;/a&gt;

### Design overview: timestamps and validity.

For future-proofing, SNIPs and ENDIVEs have separate time ranges
indicating when they are valid.  Unlike with current designs, these
validity ranges should take clock skew into account, and should not
require clients or relays to deliberately add extra tolerance to their
processing.  (For example, instead of saying that a document is "fresh"
for three hours and then telling clients to accept documents for 24
hours before they are valid and 24 hours after they are expired, we will
simply make the documents valid for 51 hours.)

We give each lifespan as a (PUBLISHED, PRE, POST) triple, such that
objects are valid from (PUBLISHED - PRE) through (PUBLISHED + POST).
(The "PUBLISHED" time is provided so that we can more reliably tell
which of two objects is more recent.)

Later (see section 08), we'll explain measures to ensure that
hostile relays do not take advantage of multiple overlapping SNIP
lifetimes to attack clients.

&lt;!-- Section 2.1.6 --&gt; &lt;a id='S2.1.6'&gt;&lt;/a&gt;

### Design overview: how the formats work together

Authorities, as part of their current voting process, will produce an
ENDIVE.

Relays will download this ENDIVE (either directly or as a diff),
validate it, and extract SNIPs from it.  Extracting these SNIPs may be
trivial (if they are signed individually), or more complex (if they are
signed via a Merkle tree, and the Merkle tree needs to be
reconstructed).  This complexity is acceptable only to the extent that
it reduces compressed diff size.

Once the SNIPs are reconstructed, relays will hold them and serve them
to clients.

&lt;!-- Section 2.1.7 --&gt; &lt;a id='S2.1.7'&gt;&lt;/a&gt;

### What isn't in this section

This section doesn't tell you what the different routing indices
are or mean.  For now, we can imagine there being one routing index for
guards, one for middles, and one for exits, and one for each hidden
service directory ring. (See section 06 for more on regular indices,
and section 07 for more on onion services.)

This section doesn't give an algorithm for computing ENDIVEs from
votes, and doesn't give an algorithm for extracting SNIPs from an ENDIVE.
Those come later. (See sections 03 and 04 respectively.)

&lt;!-- Section 2.2 --&gt; &lt;a id='S2.2'&gt;&lt;/a&gt;

## SNIPs

Each SNIP has three pieces: the part of the SNIP that describes the
router, the part of that describes the SNIP's place within an ENDIVE, and
the part that authenticates the whole SNIP.

Why two _separate_ authenticated pieces?  Because one (the router
description) is taken verbatim from the ENDIVE, and the other
(the location within the ENDIVE) is computed from the ENDIVE by the
relays. Separating them like this helps ensure that the part
generated by the relay and the part generated by the authorities
can't interfere with each other.

    ; A SNIP, as it is sent from the relay to the client.  Note that
    ; this is represented as a three-element array.
    SNIP = [
        ; First comes the signature.  This is computed over
        ; the concatenation of the two bstr objects below.
        auth: SNIPSignature,

        ; Next comes the location of the SNIP within the ENDIVE.
        index: bstr .cbor SNIPLocation,

        ; Finally comes the information about the router.
        router: bstr .cbor SNIPRouterData,
    ]

(Computing the signature over a concatenation of objects is safe, since
the objects' content is self-describing CBOR, and isn't vulnerable to
framing issues.)

&lt;!-- Section 2.2.1 --&gt; &lt;a id='S2.2.1'&gt;&lt;/a&gt;

### SNIPRouterData: information about a single router.

Here we talk about the type that tells a client about a single
router.  For cases where we are just storing information about a
router (for example, when using it as a guard), we can remember
this part, and discard the other pieces.

The only required parts here are those that identify the router
and tell the client how to build a circuit through it.  The others
are all optional.  In practice, I expect they will be encoded in most
cases, but clients MUST behave properly if they are absent.

More than one SNIPRouterData may exist in the same ENDIVE for a
single router.  For example, there might be a longer version to
represent a router to be used as a guard, and another to represent
the same router when used as a hidden service directory.  (This is
not possible in the voting mechanism that I'm working on, but relays
and clients MUST NOT treat this as an error.)

This representation is based on the routerstats and
microdescriptor entries of today, but tries to omit a number of
obsolete fields, including RSA identity fingerprint, TAP key,
published time, etc.

    ; A SNIPRouterData is a map from integer keys to values for
    ; those keys.
    SNIPRouterData = {
        ; identity key.
        ? 0 =&gt; Ed25519PublicKey,

        ; ntor onion key.
        ? 1 =&gt; Curve25519PublicKey,

        ; list of link specifiers other than the identity key.
        ; If a client wants to extend to the same router later on,
        ; they SHOULD include all of these link specifiers verbatim,
        ; whether they recognize them or not.
        ? 2 =&gt; [ LinkSpecifier ],

        ; The software that this relay says it is running.
        ? 3 =&gt; SoftwareDescription,

        ; protovers.
        ? 4 =&gt; ProtoVersions,

        ; Family.  See below for notes on dual encoding.
        ? 5 =&gt; [ * FamilyId ],

        ; Country Code
        ? 6 =&gt; Country,

        ; Exit policies describing supported port _classes_.  Absent exit
        ; policies are treated as "deny all".
        ? 7 =&gt; ExitPolicy,

        ; NOTE: Properly speaking, there should be a CDDL 'cut'
        ; here, to indicate that the rules below should only match
        ; if one if the previous rules hasn't matched.
        ; Unfortunately, my CDDL tool doesn't seem to support cuts.

        ; For future tor extensions.
        * int =&gt; any,

        ; For unofficial and experimental extensions.
        * tstr =&gt; any,
    }

    ; For future-proofing, we are allowing multiple ways to encode
    ; families.  One is as a list of other relays that are in your
    ; family.  One is as a list of authority-generated family
    ; identifiers. And one is as a master key for a family (as in
    ; Tor proposal 242).
    ;
    ; A client should consider two routers to be in the same
    ; family if they have at least one FamilyId in common.
    ; Authorities will canonicalize these lists.
    FamilyId = bstr

    ; A country.  These should ordinarily be 2-character strings,
    ; but I don't want to enforce that.
    Country = tstr;

    ; SoftwareDescription replaces our old "version".
    SoftwareDescription = [
      software: tstr,
      version: tstr,
      extra: tstr
    ]

    ; Protocol versions: after a bit of experimentation, I think
    ; the most reasonable representation to use is a map from protocol
    ; ID to a bitmask of the supported versions.
    ProtoVersions = { ProtoId =&gt; ProtoBitmask }

    ; Integer protocols are reserved for future version of Tor. tstr ids
    ; are reserved for experimental and non-tor extensions.
    ProtoId = ProtoIdEnum / int / tstr

    ProtoIdEnum = &amp;(
      Link     : 0,
      LinkAuth : 1,
      Relay    : 2,
      DirCache : 3,
      HSDir    : 4,
      HSIntro  : 5,
      HSRend   : 6,
      Desc     : 7,
      MicroDesc: 8,
      Cons     : 9,
      Padding  : 10,
      FlowCtrl : 11,
    )
    ; This type is limited to 64 bits, and that's fine.  If we ever
    ; need a protocol version higher than 63, we should allocate a
    ; new protoid.
    ProtoBitmask = uint

    ; An exit policy may exist in up to two variants.  When port classes
    ; have not changed in a while, only one policy is needed.  If port
    ; classes have changed recently, however, then SNIPs need to include
    ; each relay's position according to both the older and the newer policy
    ; until older network parameter documents become invalid.
    ExitPolicy = SinglePolicy / [ SinglePolicy, SinglePolicy ]

    ; Each single exit policy is a tagged bit array, whose bits
    ; correspond to the members of the list of port classes in the
    ; network parameter document with a corresponding tag.
    SinglePolicy = [
         ; Identifies which group of port classes we're talking about
         tag: unsigned,
         ; Bit-array of which port classes this relay supports.
         policy: bstr
    ]

&lt;!-- Section 2.2.2 --&gt; &lt;a id='S2.2.2'&gt;&lt;/a&gt;

### SNIPLocation: Locating a SNIP within a routing index.

The SNIPLocation type can encode where a SNIP is located with
respect to one or more routing indices.  Note that a SNIPLocation
does not need to be exhaustive: If a given IndexId is not listed for
a given relay in one SNIP, it might exist in another SNIP. Clients
should not infer that the absence of an IndexId in one SNIPLocation
for a relay means that no SNIPLocation with that IndexId exists for
the relay.

    ; SNIPLocation: we're using a map here because it's natural
    ; to look up indices in maps.
    SNIPLocation = {
        ; The keys of this mapping represent the routing indices in
        ; which a SNIP appears.  The values represent the index ranges
        ; that it occupies in those indices.
        * IndexId =&gt; IndexRange / ExtensionIndex,
    }

    ; We'll define the different index ranges as we go on with
    ; these specifications.
    ;
    ; IndexId values over 65535 are reserved for extensions and
    ; experimentation.
    IndexId = uint32

    ; An index range extends from a minimum to a maximum value.
    ; These ranges are _inclusive_ on both sides.  If 'hi' is less
    ; than 'lo', then this index "wraps around" the end of the ring.
    ; A "nil" value indicates an empty range, which would not
    ; ordinarily be included.
    IndexRange = [ lo: IndexPos,
                   hi: IndexPos ] / nil

    ; An ExtensionIndex is reserved for future use; current clients
    ; will not understand it and current ENDIVEs will not contain it.
    ExtensionIndex = any

    ; For most routing indices, the ranges are encoded as 4-byte integers.
    ; But for hsdir rings, they are binary strings.  (Clients and
    ; relays SHOULD NOT require this.)
    IndexPos = uint / bstr

A bit more on IndexRanges: Every IndexRange actually describes a set of
_prefixes_ for possible index positions.  For example, the IndexRange
`[ h'AB12', h'AB24' ]` includes all the binary strings that start with (hex)
`AB12`, `AB13`, and so on, up through all strings that start with `AB24`.
Alternatively, you can think of a `bstr`-based IndexRange *(lo, hi)* as
covering *lo*`00000...` through *hi*`ff...`.

IndexRanges based on the uint type work the same, except that they always
specify the first 32 bits of a prefix.

&lt;!-- Section 2.2.3 --&gt; &lt;a id='S2.2.3'&gt;&lt;/a&gt;

### SNIPSignature: How to prove a SNIP is in the ENDIVE.

Here we describe the types for implementing SNIP signatures, to be
validated as described in "Design overview: Authentication" above.

    ; Most elements in a SNIPSignature are positional and fixed
    SNIPSignature = [
        ; The actual signature or signatures.  If this is a single signature,
        ; it's probably a threshold signature.  Otherwise, it's probably
        ; a list containing one signature from each directory authority.
        SingleSig / MultiSig,

        ; algorithm to use for the path through the merkle tree.
        d_alg: DigestAlgorithm,
        ; Path through merkle tree, possibly empty.
        merkle_path: MerklePath,

        ; Lifespan information.  This is included as part of the input
        ; to the hash algorithm for the signature.
        LifespanInfo,

        ; optional nonce for hash algorithm.
        ? nonce: bstr,

        ; extensions for later use. These are not signed.
        ? extensions: { * any =&gt; any },
    ]

    ; We use this group to indicate when an object originated, and when
    ; it should be accepted.
    ;
    ; When we are using it as an input to a hash algorithm for computing
    ; signatures, we encode it as an 8-byte number for "published",
    ; followed by two 4-byte numbers for pre-valid and post-valid.
    LifespanInfo = (
        ; Official publication time in seconds since the epoch.  These
        ; MUST be monotonically increasing over time for a given set of
        ; authorities on all SNIPs or ENDIVEs that they generate: a
        ; document with a greater `published` time is always more recent
        ; than one with an earlier `published` time.
        ;
        ; Seeing a publication time "in the future" on a correctly
        ; authenticated document is a reliable sign that your
        ; clock is set too far in the past.
        published: uint,

        ; Value to subtract from "published" in order to find the first second
        ; at which this object should be accepted.
        pre-valid: uint32,

        ; Value to add to "published" in order to find the last
        ; second at which this object should be accepted.  The
        ; lifetime of an object is therefore equal to "(post-valid +
        ; pre-valid)".
        post-valid: uint32,
    )

    ; A Lifespan is just the fields of LifespanInfo, encoded as a list.
    Lifespan = [ LifespanInfo ]

    ; One signature on a SNIP or ENDIVE.  If the signature is a threshold
    ; signature, or a reference to a signature in another
    ; document, there will probably be just one of these per SNIP.  But if
    ; we're sticking a full multisignature in the document, this
    ; is just one of the signatures on it.
    SingleSig = [
       s_alg: SigningAlgorithm,
       ; One of signature and sig_reference must be present.
       ?signature: bstr,
       ; sig_reference is an identifier for a signature that appears
       ; elsewhere, and can be fetched on request.  It should only be
       ; used with signature types too large to attach to SNIPs on their
       ; own.
       ?sig_reference: bstr,
       ; A prefix of the key or the key's digest, depending on the
       ; algorithm.
       ?keyid: bstr,
    ]

    MultiSig = [ + SingleSig ]

    ; A Merkle path is represented as a sequence of bits to
    ; indicate whether we're going left or right, and a list of
    ; hashes for the parts of the tree that we aren't including.
    ;
    ; (It's safe to use a uint for the number of bits, since it will
    ; never overflow 64 bits -- that would mean a Merkle tree with
    ; too many leaves to actually calculate on.)
    MerklePath = [ uint, *bstr ]

&lt;!-- Section 2.3 --&gt; &lt;a id='S2.3'&gt;&lt;/a&gt;

## ENDIVEs: sending a bunch of SNIPs efficiently.

ENDIVEs are delivered by the authorities in a compressed format, optimized
for diffs.

Note that if we are using Merkle trees for SNIP authentication, ENDIVEs do
not include the trees at all, since those can be inferred from the leaves of
the tree.  Similarly, the ENDIVEs do not include raw routing indices, but
instead include a set of bandwidths that can be combined into the routing
indices -- these bandwidths change less frequently, and therefore are more
diff-friendly.

Note also that this format has more "wasted bytes" than SNIPs
do. Unlike SNIPs, ENDIVEs are large enough to benefit from
compression with with gzip, lzma2, or so on.

This section does not fully specify how to construct SNIPs from an ENDIVE;
for the full algorithm, see section 04.

    ; ENDIVEs are also sent as CBOR.
    ENDIVE = [
        ; Signature for the ENDIVE, using a simpler format than for
        ; a SNIP.  Since ENDIVEs are more like a consensus, we don't need
        ; to use threshold signatures or Merkle paths here.
        sig: ENDIVESignature,

        ; Contents, as a binary string.
        body: encoded-cbor .cbor ENDIVEContent,
    ]

    ; The set of signatures across an ENDIVE.
    ;
    ; This type doubles as the "detached signature" document used when
    ; collecting signatures for a consensus.
    ENDIVESignature = {
        ; The actual signatures on the endive. A multisignature is the
        ; likeliest format here.
        endive_sig: [ + SingleSig ],

        ; Lifespan information.  As with SNIPs, this is included as part
        ; of the input to the hash algorithm for the signature.
        ; Note that the lifespan of an ENDIVE is likely to be a subset
        ; of the lifespan of its SNIPs.
        endive_lifespan: Lifespan,

        ; Signatures across SNIPs, at some level of the Merkle tree.  Note
        ; that these signatures are not themselves signed -- having them
        ; signed would take another step in the voting algorithm.
        snip_sigs: DetachedSNIPSignatures,

        ; Signatures across the ParamDoc pieces.  Note that as with the
        ; DetachedSNIPSignatures, these signatures are not themselves signed.
        param_doc: ParamDocSignature,

        ; extensions for later use. These are not signed.
        * tstr =&gt; any,
    }

    ; A list of single signatures or a list of multisignatures. This
    ; list must have 2^signature-depth elements.
    DetachedSNIPSignatures =
          [ *SingleSig ] / [ *MultiSig ]

    ENDIVEContent = {

        ; Describes how to interpret the signatures over the SNIPs in this
        ; ENDIVE. See section 04 for the full algorithm.
        sig_params: {
            ; When should we say that the signatures are valid?
            lifespan: Lifespan,
            ; Nonce to be used with the signing algorithm for the signatures.
            ? signature-nonce: bstr,

            ; At what depth of a Merkle tree do the signatures apply?
            ; (If this value is 0, then only the root of the tree is signed.
            ; If this value is &gt;= ceil(log2(n_leaves)), then every leaf is
            ; signed.).
            signature-depth: uint,

            ; What digest algorithm is used for calculating the signatures?
            signature-digest-alg: DigestAlgorithm,

            ; reserved for future extensions.
            * tstr =&gt; any,
        },

        ; Documents for clients/relays to learn about current network
        ; parameters.
        client-param-doc: encoded-cbor .cbor ClientParamDoc,
        relay-param-doc: encoded-cbor .cbor RelayParamDoc,

        ; Definitions for index group.  Each "index group" is all
        ; applied to the same SNIPs.  (If there is one index group,
        ; then every relay is in at most one SNIP, and likely has several
        ; indices.  If there are multiple index groups, then relays
        ; can appear in more than one SNIP.)
        indexgroups: [ *IndexGroup ],

        ; Information on particular relays.
        ;
        ; (The total number of SNIPs identified by an ENDIVE is at most
        ; len(indexgroups) * len(relays).)
        relays: [ * ENDIVERouterData ],

        ; for future exensions
        * tstr =&gt; any,
    }

    ; An "index group" lists a bunch of routing indices that apply to the same
    ; SNIPs.  There may be multiple index groups when a relay needs to appear
    ; in different SNIPs with routing indices for some reason.
    IndexGroup = {
        ; A list of all the indices that are built for this index group.
        ; An IndexId may appear in at most one group per ENDIVE.
        indices: [ + IndexId ],
        ; A list of keys to delete from SNIPs to build this index group.
        omit_from_snips: [ *(int/tstr) ],
        ; A list of keys to forward from SNIPs to the next relay in an EXTEND
        ; cell.  This can help the next relay know which keys to use in its
        ; handshake.
        forward_with_extend: [ *(int/tstr) ],

        ; A number of "gaps" to place in the Merkle tree after the SNIPs
        ; in this group.  This can be used together with signature-depth
        ; to give different index-groups independent signatures.
        ? n_padding_entries: uint,

        ; A detailed description of how to build the index.
        + IndexId =&gt; IndexSpec,

        ; For experimental and extension use.
        * tstr =&gt; any,
    }

    ; Enumeration to identify how to generate an index.
    Indextype_Raw = 0
    Indextype_Weighted = 1
    Indextype_RSAId = 2
    Indextype_Ed25519Id = 3
    Indextype_RawNumeric = 4

    ; An indexspec may be given as a raw set of index ranges.  This is a
    ; fallback for cases where we simply can't construct an index any other
    ; way.
    IndexSpec_Raw = {
        type: Indextype_Raw,
        ; This index is constructed by taking relays by their position in the
        ; list from the list of ENDIVERouterData, and placing them at a given
        ; location in the routing index.  Each index range extends up to
        ; right before the next index position.
        index_ranges: [ * [ uint, IndexPos ] ],
    }

    ; An indexspec given as a list of numeric spans on the index.
    IndexSpec_RawNumeric = {
        type: Indextype_RawNumeric,
        first_index_pos: uint,
        ; This index is constructed by taking relays by index from the list
        ; of ENDIVERouterData, and giving them a certain amount of "weight"
        ; in the index.
        index_ranges: [ * [ idx: uint, span: uint ] ],
    }

    ; This index is computed from the weighted bandwidths of all the SNIPs.
    ;
    ; Note that when a single bandwidth changes, it can change _all_ of
    ; the indices in a bandwidth-weighted index, even if no other
    ; bandwidth changes.  That's why we only pack the bandwidths
    ; here, and scale them as part of the reconstruction algorithm.
    IndexSpec_Weighted = {
        type: Indextype_Weighted,
        ; This index is constructed by assigning a weight to each relay,
        ; and then normalizing those weights. See algorithm below in section
        ; 04.
        ; Limiting bandwidth weights to uint32 makes reconstruction algorithms
        ; much easier.
        index_weights: [ * uint32 ],
    }

    ; This index is computed from the RSA identity key digests of all of the
    ; SNIPs. It is used in the HSv2 directory ring.
    IndexSpec_RSAId = {
        type: Indextype_RSAId,
        ; How many bytes of RSA identity data go into each indexpos entry?
        n_bytes: uint,
        ; Bitmap of which routers should be included.
        members: bstr,
    }

    ; This index is computed from the Ed25519 identity keys of all of the
    ; SNIPs.  It is used in the HSv3 directory ring.
    IndexSpec_Ed25519Id = {
        type: Indextype_Ed25519Id,
        ; How many bytes of digest go into each indexpos entry?
        n_bytes: uint,
        ; What digest do we use for building this ring?
        d_alg: DigestAlgorithm,
        ; What bytes do we give to the hash before the ed25519?
        prefix: bstr,
        ; What bytes do we give to the hash after the ed25519?
        suffix: bstr,
        ; Bitmap of which routers should be included.
        members: bstr,
    }

    IndexSpec = IndexSpec_Raw /
                IndexSpec_RawNumeric /
                IndexSpec_Weighted /
                IndexSpec_RSAId /
                IndexSpec_Ed25519Id

    ; Information about a single router in an ENDIVE.
    ENDIVERouterData = {
        ; The authority-generated SNIPRouterData for this router.
        1 =&gt; encoded-cbor .cbor SNIPRouterData,
        ; The RSA identity, or a prefix of it, to use for HSv2 indices.
        ? 2 =&gt; RSAIdentityFingerprint,

        * int =&gt; any,
        * tstr =&gt; any,
    }

    ; encoded-cbor is defined in the CDDL postlude as a bstr that is
    ; tagged as holding verbatim CBOR:
    ;
    ;    encoded-cbor = #6.24(bstr)
    ;
    ; Using a tag like this helps tools that validate the string as
    ; valid CBOR; using a bstr helps indicate that the signed data
    ; should not be interpreted until after the signature is checked.
    ; It also helps diff tools know that they should look inside these
    ; objects.

&lt;!-- Section 2.4 --&gt; &lt;a id='S2.4'&gt;&lt;/a&gt;

## Network parameter documents

Network parameter documents ("ParamDocs" for short) take the place of the
current consensus and certificates as a small document that clients and
relays need to download periodically and keep up-to-date.  They are generated
as part of the voting process, and contain fields like network parameters,
recommended versions, authority certificates, and so on.

    ; A "parameter document" is like a tiny consensus that relays and clients
    ; can use to get network parameters.
    ParamDoc = [
       sig: ParamDocSignature,
       ; Client-relevant portion of the parameter document. Everybody fetches
       ; this.
       cbody: encoded-cbor .cbor ClientParamDoc,
       ; Relay-relevant portion of the parameter document. Only relays need to
       ; fetch this; the document can be validated without it.
       ? sbody: encoded-cbor .cbor RelayParamDoc,
    ]
    ParamDocSignature = [
       ; Multisignature or threshold signature of the concatenation
       ; of the two digests below.
       SingleSig / MultiSig,

       ; Lifespan information.  As with SNIPs, this is included as part
       ; of the input to the hash algorithm for the signature.
       ; Note that the lifespan of a parameter document is likely to be
       ; very long.
       LifespanInfo,

       ; how are c_digest and s_digest computed?
       d_alg: DigestAlgorithm,
       ; Digest over the cbody field
       c_digest: bstr,
       ; Digest over the sbody field
       s_digest: bstr,
    ]

    ClientParamDoc = {
       params: NetParams,
       ; List of certificates for all the voters.  These
       ; authenticate the keys used to sign SNIPs and ENDIVEs and votes,
       ; using the authorities' longest-term identity keys.
       voters: [ + bstr .cbor VoterCert ],

       ; A division of exit ports into "classes" of ports.
       port-classes: PortClasses,

       ; As in client-versions from dir-spec.txt
       ? recommend-versions: [ * tstr ],
       ; As in recommended-client-protocols in dir-spec.txt
       ? recommend-protos: ProtoVersions,
       ; As in required-client-protocols in dir-spec.txt
       ? require-protos: ProtoVersions,

       ; For future extensions.
       * tstr =&gt; any,
    }

    RelayParamDoc = {
       params: NetParams,

       ; As in server-versions from dir-spec.txt
       ? recommend-versions: [ * tstr ],
       ; As in recommended-relay-protocols in dir-spec.txt
       ? recommend-protos: ProtoVersions,
       ; As in required-relay-protocols in dir-spec.txt
       ? require-versions: ProtoVersions,

       * tstr =&gt; any,
    }

    ; A NetParams encodes information about the Tor network that
    ; clients and relays need in order to participate in it.  The
    ; current list of parameters is described in the "params" field
    ; as specified in dir-spec.txt.
    ;
    ; Note that there are separate client and relay NetParams now.
    ; Relays are expected to first check for a defintion in the
    ; RelayParamDoc, and then in the ClientParamDoc.
    NetParams = { *tstr =&gt; int }

    PortClasses = {
        ; identifies which port class grouping this is. Used to migrate
        ; from one group of port classes to another.
        tag: uint,
        ; list of the port classes.
        classes: { * IndexId =&gt; PortList },
    }
    PortList = [ *PortOrRange ]
     ; Either a single port or a low-high pair
    PortOrRange = Port / [ Port, Port ]
    Port = 1...65535

&lt;!-- Section 2.5 --&gt; &lt;a id='S2.5'&gt;&lt;/a&gt;

## Certificates

Voting certificates are used to bind authorities' long-term
identities to shorter-term signing keys.  These have a similar
purpose to the authority certs made for the existing voting
algorithm, but support more key types.

    ; A 'voter certificate' is a statement by an authority binding keys to
    ; each other.
    VoterCert = [

       ; One or more signatures over `content` using the provided lifetime.
       ; Each signature should be treated independently.
       [ + SingleSig ],
       ; A lifetime value, used (as usual ) as an input to the
       ; signature algorithm.
       LifespanInfo,
       ; The keys and other data to be certified.
       content: encoded-cbor .cbor CertContent,
    ]

    ; The contents of the certificate that get signed.
    CertContent = {
       ; What kind of a certificate is this?
       type: CertType,
       ; A list of keys that are being certified in this document
       keys: [ + CertifiedKey ],
       ; A list of other keys that you might need to know about, which
       ; are NOT certififed in this document.
       ? extra: [ + CertifiedKey ],
       * tstr =&gt; any,
    }

    CertifiedKey = {
       ; What is the intended usage of this key?
       usage: KeyUsage,
       ; What cryptographic algorithm is this key used for?
       alg: PKAlgorithm,
       ; The actual key being certified.
       data: bstr,
       ; A human readable string.
       ? remarks: tstr,
       * tstr =&gt; any,
    }

&lt;!-- Section 2.6 --&gt; &lt;a id='S2.6'&gt;&lt;/a&gt;

## ENDIVE diffs

Here is a binary format to be used with ENDIVEs, ParamDocs, and any
other similar binary formats.  Authorities and directory caches need to
be able to generate it; clients and non-cache relays only need to be
able to parse and apply it.

    ; Binary diff specification.
    BinaryDiff = {
        ; This is version 1.
        v: 1,
        ; Optionally, a diff can say what different digests
        ; of the document should be before and after it is applied.
        ; If there is more than one entry, parties MAY check one or
        ; all of them.
        ? digest: { * DigestAlgorithm =&gt;
                         [ pre: Digest,
                           post: Digest ]},

        ; Optionally, a diff can give some information to identify
        ; which document it applies to, and what document you get
        ; from applying it.  These might be a tuple of a document type
        ; and a publication type.
        ? ident: [ pre: any, post: any ],

        ; list of commands to apply in order to the original document in
        ; order to get the transformed document
        cmds: [ *DiffCommand ],

        ; for future extension.
        * tstr =&gt; any,
    }

    ; There are currently only two diff commands.
    ; One is to copy some bytes from the original.
    CopyDiffCommand = [
        OrigBytesCmdId,
        ; Range of bytes to copy from the original document.
        ; Ranges include their starting byte.  The "offset" is relative to
        ; the end of the _last_ range that was copied.
        offset: int,
        length: uint,
    ]

    ; The other diff comment is to insert some bytes from the diff.
    InsertDiffCommand = [
        InsertBytesCmdId,
        data: bstr,
    ]

    DiffCommand = CopyDiffCommand / InsertDiffCommand

    OrigBytesCmdId = 0
    InsertBytesCmdId = 1

Applying a binary diff is simple:

    Algorithm: applying a binary diff.

    (Given an input bytestring INP and a diff D, produces an output OUT.)

    Initialize OUT to an empty bytestring.

    Set OFFSET to 0.

    For each command C in D.commands, in order:

        If C begins with OrigBytesCmdId:
            Increase "OFFSET" by C.offset
            If OFFSET..OFFSET+C.length is not a valid range in
               INP, abort.
            Append INP[OFFSET .. OFFSET+C.length] to OUT.
            Increase "OFFSET" by C.length

        else: # C begins with InsertBytesCmdId:
            Append C.data to OUT.

Generating a binary diff can be trickier, and is not specified here.
There are several generic algorithms out there for making binary diffs
between arbitrary byte sequences. Since these are complex, I recommend a
chunk-based CBOR-aware algorithm, using each CBOR item in a similar way
to the way in which our current line-oriented code uses lines.  When
encountering a bstr tagged with "encoded-cbor", the diff algorithm
should look inside it to find more cbor chunks. (See
example-code/cbor_diff.py for an example of doing this with Python's
difflib.)

The diff format above should work equally well no matter what
diff algorithm is used, so we have room to move to other algorithms
in the future if needed.

To indicate support for the above diff format in directory requests,
implementations should use an `X-Support-Diff-Formats` header.  The
above format is designated "cbor-bindiff"; our existing format is
called "ed".

&lt;!-- Section 2.7 --&gt; &lt;a id='S2.7'&gt;&lt;/a&gt;

## Digests and parameters

Here we give definitions for `H_leaf()` and `H_node()`, based on an
underlying digest function H() with a preferred input block size of B.
(B should be chosen as the natural input size of the hash function, to
aid in precomputation.)

We also define `H_sign()`, to be used outside of SNIP authentication
where we aren't using a Merkle tree at all.

PATH must be no more than 64 bits long.  NONCE must be no more than B-33
bytes long.

     H_sign(LIFESPAN, NONCE, ITEM) =
        H( PREFIX(OTHER_C, LIFESPAN, NONCE) || ITEM)

     H_leaf(PATH, LIFESPAN, NONCE, ITEM) =
        H( PREFIX(LEAF_C, LIFESPAN, NONCE) ||
           U64(PATH) ||
           U64(bits(path)) ||
           ITEM )

     H_node(PATH, LIFESPAN, NONCE, ITEM) =
        H( PREFIX(NODE_C, LIFESPAN, NONCE) ||
           U64(PATH) ||
           U64(bits(PATH)) ||
           ITEM )

     PREFIX(leafcode, lifespan, nonce) =
          U64(leafcode) ||
          U64(lifespan.published) ||
          U32(lifespan.pre-valid) ||
          U32(lifespan.post-valid) ||
          U8(len(nonce)) ||
          nonce ||
          Z(B - 33 - len(nonce))

     LEAF_C = 0x8BFF0F687F4DC6A1 ^ NETCONST
     NODE_C = 0xA6F7933D3E6B60DB ^ NETCONST
     OTHER_C = 0x7365706172617465 ^ NETCONST

     # For the live Tor network only.
     NETCONST = 0x0746f72202020202
     # For testing networks, by default.
     NETCONST = 0x74657374696e6720

     U64(n) -- N encoded as a big-endian 64-bit number.
     Z(n) -- N bytes with value zero.
     len(b) -- the number of bytes in a byte-string b.
     bits(b) -- the number of bits in a bit-string b.


&lt;!-- Section 3 --&gt; &lt;a id='S3'&gt;&lt;/a&gt;

# Directory authority operations

For Walking Onions to work, authorities must begin to generate
ENDIVEs as a new kind of "consensus document".  Since this format is
incompatible with the previous consensus document formats, and is
CBOR-based, a text-based voting protocol is no longer appropriate
for generating it.

We cannot immediately abandon the text-based consensus and
microdescriptor formats, but instead will need to keep
generating them for legacy relays and clients.  Ideally, process
that produces the ENDIVE should also produce a legacy consensus,
to limit the amount of divergence in their contents.

Further, it would be good for the purposes of this proposal if we
can "inherit" as much as possible of our existing voting mechanism
for legacy purposes.

This section of the proposal will try to solve these goals by defining a
new binary-based voting format, a new set of voting rules for it, and a
series of migration steps.

&lt;!-- Section 3.1 --&gt; &lt;a id='S3.1'&gt;&lt;/a&gt;

## Overview

Except as described below, we retain from Tor's existing voting
mechanism all notions of how votes are transferred and processed.
Other changes are likely desirable, but they are out of scope for
this proposal.

Notably, we are not changing how the voting schedule works.  Nor are
we changing the property that all authorities must agree on the list
of authorities; the property that a consensus is computed as a
deterministic function of a set of votes; or the property that if
authorities believe in different sets of votes, they will not reach
the same consensus.

The principal changes in the voting that are relevant for legacy
consensus computation are:

  * The uploading process for votes now supports negotiation, so
    that the receiving authority can tell the uploading authority
    what kind of formats, diffs, and compression it supports.

  * We specify a CBOR-based binary format for votes, with a simple
    embedding method for the legacy text format.  This embedding is
    meant for transitional use only; once all authorities support
    the binary format, the transitional format and its support
    structures can be abandoned.

  * To reduce complexity, the new vote format also includes
    _verbatim_ microdescriptors, whereas previously microdescriptors
    would have been referenced by hash.  (The use of diffs and
    compression should make the bandwidth impact of this addition
    negligible.)

For computing ENDIVEs, the principal changes in voting are:

  * The consensus outputs for most voteable objects are specified in a
    way that does not require the authorities to understand their
    semantics when computing a consensus.  This should make it
    easier to change fields without requiring new consensus methods.

&lt;!-- Section 3.2 --&gt; &lt;a id='S3.2'&gt;&lt;/a&gt;

## Negotiating vote uploads

Authorities supporting Walking Onions are required to support a new
resource "/tor/auth-vote-opts".  This resource is a text document
containing a list of HTTP-style headers. Recognized headers are
described below; unrecognized headers MUST be ignored.

The *Accept-Encoding* header follows the same format as the HTTP
header of the same name; it indicates a list of Content-Encodings
that the authority will accept for uploads.  All authorities SHOULD
support the gzip and identity encodings.  The identity encoding is
mandatory.  (Default: "identity")

The *Accept-Vote-Diffs-From* header is a list of digests of previous
votes held by this authority; any new uploaded votes that are given
as diffs from one of these old votes SHOULD be accepted.  The format
is a space-separated list of "digestname:Hexdigest".  (Default: "".)

The *Accept-Vote-Formats* header is a space-separated list of the
vote formats that this router accepts. The recognized vote formats
are "legacy-3" (Tor's current vote format) and "endive-1" (the vote
format described here). Unrecognized vote formats MUST be ignored.
(Default: "legacy-3".)

If requesting "/tor/auth-vote-opts" gives an error, or if one or
more headers are missing, the default values SHOULD be used.  These
documents (or their absence) MAY be cached for up to 2 voting
periods.)

Authorities supporting Walking Onions SHOULD also support the
"Connection: keep-alive" and "Keep-Alive" HTTP headers, to avoid
needless reconnections in response to these requests.
Implementors SHOULD be aware of potential denial-of-service
attacks based on open HTTP connections, and mitigate them as
appropriate.

&gt; Note: I thought about using OPTIONS here, but OPTIONS isn't quite
&gt; right for this, since Accept-Vote-Diffs-From does not fit with its
&gt; semantics.

&gt; Note: It might be desirable to support this negotiation for legacy
&gt; votes as well, even before walking onions is implemented.  Doing so
&gt; would allow us to reduce authority bandwidth a little, and possibly
&gt; include microdescriptors in votes for more convenient processing.

&lt;!-- Section 3.3 --&gt; &lt;a id='S3.3'&gt;&lt;/a&gt;

## A generalized algorithm for voting

Unlike with previous versions of our voting specification, here I'm
going to try to describe pieces the voting algorithm in terms of
simpler voting operations.  Each voting operation will be named and
possibly parameterized, and data will frequently self-describe what
voting operation is to be used on it.

Voting operations may operate over different CBOR types, and are
themselves specified as CBOR objects.

A voting operation takes place over a given "voteable field".  Each
authority that specifies a value for a voteable field MUST specify
which voting operation to use for that field.  Specifying a voteable
field without a voting operation MUST be taken as specifying the
voting operation "None" -- that is, voting against a consensus.

On the other hand, an authority MAY specify a voting operation for
a field without casting any vote for it.  This means that the
authority has an opinion on how to reach a consensus about the
field, without having any preferred value for the field itself.

&lt;!-- Section 3.3.1 --&gt; &lt;a id='S3.3.1'&gt;&lt;/a&gt;

### Constants used with voting operations

Many voting operations may be parameterized by an unsigned integer.
In some cases the integers are constant, but in others, they depend
on the number of authorities, the number of votes cast, or the
number of votes cast for a particular field.

When we encode these values, we encode them as short strings
rather than as integers.

&gt; I had thought of using negative integers here to encode these
&gt; special constants, but that seems too error-prone.

The following constants are defined:

`N_AUTH` -- the total number of authorities, including those whose
votes are absent.

`N_PRESENT` -- the total number of authorities whose votes are
present for this vote.

`N_FIELD` -- the total number of authorities whose votes for a given
field are present.

Necessarily, `N_FIELD` &lt;= `N_PRESENT` &lt;= `N_AUTH` -- you can't vote
on a field unless you've cast a vote, and you can't cast a vote
unless you're an authority.

In the definitions below, `//` denotes the truncating integer division
operation, as implemented with `/` in C.

`QUORUM_AUTH` -- The lowest integer that is greater than half of
`N_AUTH`.  Equivalent to `N_AUTH // 2 + 1`.

`QUORUM_PRESENT` -- The lowest integer that is greater than half of
`N_PRESENT`.  Equivalent to `N_PRESENT // 2 + 1`.

`QUORUM_FIELD` -- The lowest integer that is greater than half of
`N_FIELD`.  Equivalent to `N_FIELD // 2 + 1`.

We define `SUPERQUORUM_`..., variants of these fields as well, based
on the lowest integer that is greater than 2/3 majority of the
underlying field.  `SUPERQUORUM_x` is thus equivalent to
`(N_x * 2) // 3 + 1`.

    ; We need to encode these arguments; we do so as short strings.
    IntOpArgument = uint / "auth" / "present" / "field" /
         "qauth" / "qpresent" / "qfield" /
         "sqauth" / "sqpresent" / "sqfield"

No IntOpArgument may be greater than AUTH.  If an IntOpArgument is
given as an integer, and that integer is greater than AUTH, then it
is treated as if it were AUTH.

&gt; This rule lets us say things like "at least 3 authorities must
&gt; vote on x...if there are 3 authorities."

&lt;!-- Section 3.3.2 --&gt; &lt;a id='S3.3.2'&gt;&lt;/a&gt;

### Producing consensus on a field

Each voting operation will either produce a CBOR output, or produce
no consensus.  Unless otherwise stated, all CBOR outputs are to be
given in canonical form.

Below we specify a number of operations, and the parameters that
they take.  We begin with operations that apply to "simple" values
(integers and binary strings), then show how to compose them to
larger values.

All of the descriptions below show how to apply a _single_ voting
operation to a set of votes.  We will later describe how to behave when
the authorities do not agree on which voting operation to use, in our
discussion of the StructJoinOp operation.

Note that while some voting operations take other operations as
parameters, we are _not_ supporting full recursion here: there is a
strict hierarchy of operations, and more complex operations can only
have simpler operations in their parameters.

All voting operations follow this metaformat:

    ; All a generic voting operation has to do is say what kind it is.
    GenericVotingOp = {
        op: tstr,
        * tstr =&gt; any,
    }

Note that some voting operations require a sort or comparison
operation over CBOR values.  This operation is defined later in
appendix E; it works only on homogeneous inputs.

&lt;!-- Section 3.3.3 --&gt; &lt;a id='S3.3.3'&gt;&lt;/a&gt;

### Generic voting operations

&lt;!-- Section 3.3.3.1 --&gt; &lt;a id='S3.3.3.1'&gt;&lt;/a&gt;

#### None

This voting operation takes no parameters, and always produces "no
consensus".  It is encoded as:

    ; "Don't produce a consensus".
    NoneOp = { op: "None" }

When encountering an unrecognized or nonconforming voting operation,
_or one which is not recognized by the consensus-method in use_, the
authorities proceed as if the operation had been "None".

&lt;!-- Section 3.3.4 --&gt; &lt;a id='S3.3.4'&gt;&lt;/a&gt;

### Voting operations for simple values

We define a "simple value" according to these cddl rules:

    ; Simple values are primitive types, and tuples of primitive types.
    SimpleVal = BasicVal / SimpleTupleVal
    BasicVal = bool / int / bstr / tstr
    SimpleTupleVal = [ *BasicVal ]

We also need the ability to encode the types for these values:

    ; Encoding a simple type.
    SimpleType = BasicType / SimpleTupleType
    BasicType = "bool" /  "uint" / "sint" / "bstr" / "tstr"
    SimpleTupleType = [ "tuple", *BasicType ]

In other words, a SimpleVal is either an non-compound base value, or is
a tuple of such values.

    ; We encode these operations as:
    SimpleOp = MedianOp / ModeOp / ThresholdOp /
        BitThresholdOp / CborSimpleOp / NoneOp

We define each of these operations in the sections below.

&lt;!-- Section 3.3.4.1 --&gt; &lt;a id='S3.3.4.1'&gt;&lt;/a&gt;

#### Median

_Parameters_: `MIN_VOTES` (an integer), `BREAK_EVEN_LOW` (a boolean),
`TYPE` (a SimpleType)

    ; Encoding:
    MedianOp = { op: "Median",
                 ? min_vote: IntOpArgument,  ; Default is 1.
                 ? even_low: bool,           ; Default is true.
                 type: SimpleType  }

Discard all votes that are not of the specified `TYPE`. If there are
fewer than `MIN_VOTES` votes remaining, return "no consensus".

Put the votes in ascending sorted order. If the number of votes N
is odd, take the center vote (the one at position (N+1)/2).  If N is
even, take the lower of the two center votes (the one at position
N/2) if `BREAK_EVEN_LOW` is true. Otherwise, take the higher of the
two center votes (the one at position N/2 + 1).

For example, the Median(, even_low: True, type: "uint") of the votes
["String", 2, 111, 6] is 6. The Median(, even_low: True, type: "uint")
of the votes ["String", 77, 9, 22, "String", 3] is 9.

&lt;!-- Section 3.3.4.2 --&gt; &lt;a id='S3.3.4.2'&gt;&lt;/a&gt;

#### Mode

_Parameters_: `MIN_COUNT` (an integer), `BREAK_TIES_LOW` (a boolean),
`TYPE` (a SimpleType)

    ; Encoding:
    ModeOp = { op: "Mode",
               ? min_count: IntOpArgument,   ; Default 1.
               ? tie_low: bool,              ; Default true.
               type: SimpleType
    }

Discard all votes that are not of the specified `TYPE`.  Of the
remaining votes, look for the value that has received the most
votes.  If no value has received at least `MIN_COUNT` votes, then
return "no consensus".

If there is a single value that has received the most votes, return
it. Break ties in favor of lower values if `BREAK_TIES_LOW` is true,
and in favor of higher values if `BREAK_TIES_LOW` is false.
(Perform comparisons in canonical cbor order.)

&lt;!-- Section 3.3.4.3 --&gt; &lt;a id='S3.3.4.3'&gt;&lt;/a&gt;

#### Threshold

_Parameters_: `MIN_COUNT` (an integer), `BREAK_MULTI_LOW` (a boolean),
`TYPE` (a SimpleType)

    ; Encoding
    ThresholdOp = { op: "Threshold",
                    min_count: IntOpArgument,  ; No default.
                    ? multi_low: bool,          ; Default true.
                    type: SimpleType
    }

Discard all votes that are not of the specified `TYPE`.  Sort in
canonical cbor order.  If `BREAK_MULTI_LOW` is false, reverse the
order of the list.

Return the first element that received at least `MIN_COUNT` votes.
If no value has received at least `MIN_COUNT` votes, then return
"no consensus".

&lt;!-- Section 3.3.4.4 --&gt; &lt;a id='S3.3.4.4'&gt;&lt;/a&gt;

#### BitThreshold

Parameters: `MIN_COUNT` (an integer &gt;= 1)

    ; Encoding
    BitThresholdOp = { op: "BitThreshold",
                       min_count: IntOpArgument, ; No default.
    }

These are usually not needed, but are quite useful for
building some ProtoVer operations.

Discard all votes that are not of type uint or bstr; construe bstr
inputs as having type "biguint".

The output is a uint or biguint in which the b'th bit is set iff the
b'th bit is set in at least `MIN_COUNT` of the votes.

&lt;!-- Section 3.3.5 --&gt; &lt;a id='S3.3.5'&gt;&lt;/a&gt;

### Voting operations for lists

These operations work on lists of SimpleVal:

    ; List type definitions
    ListVal = [ * SimpleVal ]

    ListType = [ "list",
                 [ *SimpleType ] / nil ]

They are encoded as:

    ; Only one list operation exists right now.
    ListOp = SetJoinOp

&lt;!-- Section 3.3.5.1 --&gt; &lt;a id='S3.3.5.1'&gt;&lt;/a&gt;

#### SetJoin

Parameters: `MIN_COUNT` (an integer &gt;= 1).
Optional parameters: `TYPE` (a SimpleType.)

    ; Encoding:
    SetJoinOp = {
       op: "SetJoin",
       min_count: IntOpArgument,
       ? type: SimpleType
    }

Discard all votes that are not lists.  From each vote,
discard all members that are not of type 'TYPE'.

For the consensus, construct a new list containing exactly those
elements that appears in at least `MIN_COUNT` votes.

(Note that the input votes may contain duplicate elements.  These
must be treated as if there were no duplicates: the vote
[1, 1, 1, 1] is the same as the vote [1]. Implementations may want
to preprocess votes by discarding all but one instance of each
member.)

&lt;!-- Section 3.3.6 --&gt; &lt;a id='S3.3.6'&gt;&lt;/a&gt;

### Voting operations for maps

Map voting operations work over maps from key types to other non-map
types.

    ; Map type definitions.
    MapVal = { * SimpleVal =&gt; ItemVal }
    ItemVal = ListVal / SimpleVal

    MapType = [ "map", [ *SimpleType ] / nil, [ *ItemType ] / nil ]
    ItemType = ListType / SimpleType

They are encoded as:

    ; MapOp encodings
    MapOp = MapJoinOp / StructJoinOp

&lt;!-- Section 3.3.6.1 --&gt; &lt;a id='S3.3.6.1'&gt;&lt;/a&gt;

#### MapJoin

The MapJoin operation combines homogeneous maps (that is, maps from
a single key type to a single value type.)

Parameters:
   `KEY_MIN_COUNT` (an integer &gt;= 1)
   `KEY_TYPE` (a SimpleType type)
   `ITEM_OP` (A non-MapJoin voting operation)

Encoding:

    ; MapJoin operation encoding
    MapJoinOp = {
       op: "MapJoin"
       ? key_min_count: IntOpArgument, ; Default 1.
       key_type: SimpleType,
       item_op: ListOp / SimpleOp
    }

First, discard all votes that are not maps.  Then consider the set
of keys from each vote as if they were a list, and apply
`SetJoin[KEY_MIN_COUNT,KEY_TYPE]` to those lists.  The resulting list
is a set of keys to consider including in the output map.

&gt; We have a separate `key_min_count` field, even if `item_op` has
&gt; its own `min_count` field, because some min_count values (like
&gt; `qfield`) depend on the overall number of votes for the field.
&gt; Having `key_min_count` lets us specify rules like "the FOO of all
&gt; votes on this field, if there are at least 2 such votes."

For each key in the output list, run the sub-voting operation
`ItemOperation` on the values it received in the votes.  Discard all
keys for which the outcome was "no consensus".

The final vote result is a map from the remaining keys to the values
produced by the voting operation.

&lt;!-- Section 3.3.6.2 --&gt; &lt;a id='S3.3.6.2'&gt;&lt;/a&gt;

#### StructJoin

A StructJoinOp operation describes a way to vote on maps that encode a
structure-like object.

Parameters:
    `KEY_RULES` (a map from int or string to StructItemOp)
    `UNKNOWN_RULE` (An operation to apply to unrecognized keys.)

    ; Encoding
    StructItemOp = ListOp / SimpleOp / MapJoinOp / DerivedItemOp /
        CborDerivedItemOp

    VoteableStructKey = int / tstr

    StructJoinOp = {
        op: "StructJoin",
        key_rules: {
            * VoteableStructKey =&gt; StructItemOp,
        }
        ? unknown_rule: StructItemOp
    }

To apply a StructJoinOp to a set of votes, first discard every vote that is
not a map.  Then consider the set of keys from all the votes as a single
list, with duplicates removed.  Also remove all entries that are not integers
or strings from the list of keys.

For each key, then look for that key in the `KEY_RULES` map.  If there is an
entry, then apply the StructItemOp for that entry to the values for that key
in every vote.  Otherwise, apply the `UNKNOWN_RULE` operation to the values
for that key in every vote.  Otherwise, there is no consensus for the values
of this key.  If there _is_ a consensus for the values, then the key should
map to that consensus in the result.

This operation always reaches a consensus, even if it is an empty map.

&lt;!-- Section 3.3.6.3 --&gt; &lt;a id='S3.3.6.3'&gt;&lt;/a&gt;

#### CborData

A CborData operation wraps another operation, and tells the authorities
that after the operation is completed, its result should be decoded as a
CBOR bytestring and interpolated directly into the document.

Parameters: `ITEM_OP` (Any SingleOp that can take a bstr input.)

     ; Encoding
     CborSimpleOp = {
         op: "CborSimple",
         item-op: MedianOp / ModeOp / ThresholdOp / NoneOp
     }
     CborDerivedItemOp = {
         op: "CborDerived",
         item-op: DerivedItemOp,
     }

To apply either of these operations to a set of votes, first apply
`ITEM_OP` to those votes.  After that's done, check whether the
consensus from that operation is a bstr that encodes a single item of
"well-formed" "valid" cbor.  If it is not, this operation gives no
consensus.  Otherwise, the consensus value for this operation is the
decoding of that bstr value.

&lt;!-- Section 3.3.6.4 --&gt; &lt;a id='S3.3.6.4'&gt;&lt;/a&gt;

#### DerivedFromField

This operation can only occur within a StructJoinOp operation (or a
semantically similar SectionRules). It indicates that one field
should have been derived from another.  It can be used, for example,
to say that a relay's version is "derived from" a relay's descriptor
digest.

Unlike other operations, this one depends on the entire consensus (as
computed so far), and on the entirety of the set of votes.

&gt; This operation might be a mistake, but we need it to continue lots of
&gt; our current behavior.

Parameters:
    `FIELDS` (one or more other locations in the vote)
    `RULE` (the rule used to combine values)

Encoding
    ; This item is "derived from" some other field.
    DerivedItemOp = {
        op: "DerivedFrom",
        fields: [ +SourceField ],
        rule: SimpleOp
    }

    ; A field in the vote.
    SourceField = [ FieldSource, VoteableStructKey ]

    ; A location in the vote.  Each location here can only
    ; be referenced from later locations, or from itself.
    FieldSource = "M" ; Meta.
               / "CP" ; ClientParam.
               / "SP" ; ServerParam.
               / "RM" ; Relay-meta
               / "RS" ; Relay-SNIP
               / "RL" ; Relay-legacy

To compute a consensus with this operation, first locate each field described
in the SourceField entry in each VoteDocument (if present), and in the
consensus computed so far.  If there is no such field in the
consensus or if it has not been computed yet, then
this operation produces "no consensus".  Otherwise, discard the VoteDocuments
that do not have the same value for the field as the consensus, and their
corresponding votes for this field.  Do this for every listed field.

At this point, we have a set of votes for this field's value that all come
from VoteDocuments that describe the same value for the source field(s).  Apply
the `RULE` operation to those votes in order to give the result for this
voting operation.

The DerivedFromField members in a SectionRules or a StructJoinOp
should be computed _after_ the other members, so that they can refer
to those members themselves.

&lt;!-- Section 3.3.7 --&gt; &lt;a id='S3.3.7'&gt;&lt;/a&gt;

### Voting on document sections

Voting on a section of the document is similar to the StructJoin
operation, with some exceptions.  When we vote on a section of the
document, we do *not* apply a single voting rule immediately.
Instead, we first "_merge_" a set of SectionRules together, and then
apply the merged rule to the votes.  This is the only place where we
merge rules like this.

A SectionRules is _not_ a voting operation, so its format is not
tagged with an "op":

    ; Format for section rules.
    SectionRules = {
      * VoteableStructKey =&gt; SectionItemOp,
      ? nil =&gt; SectionItemOp
    }
    SectionItemOp = StructJoinOp / StructItemOp

To merge a set of SectionRules together, proceed as follows. For each
key, consider whether at least QUORUM_AUTH authorities have voted the
same StructItemOp for that key.  If so, that StructItemOp is the
resulting operation for this key.  Otherwise, there is no entry for this key.

Do the same for the "nil" StructItemOp; use the result as the
`UNKNOWN_RULE`.

Note that this merging operation is *not* recursive.

&lt;!-- Section 3.4 --&gt; &lt;a id='S3.4'&gt;&lt;/a&gt;

## A CBOR-based metaformat for votes.

A vote is a signed document containing a number of sections; each
section corresponds roughly to a section of another document, a
description of how the vote is to be conducted, or both.

    ; VoteDocument is a top-level signed vote.
    VoteDocument = [
        ; Each signature may be produced by a different key, if they
        ; are all held by the same authority.
        sig: [ + SingleSig ],
        lifetime: Lifespan,
        digest-alg: DigestAlgorithm,
        body: bstr .cbor VoteContent
    ]

    VoteContent = {
        ; List of supported consensus methods.
        consensus-methods: [ + uint ],

        ; Text-based legacy vote to be used if the negotiated
        ; consensus method is too old.  It should itself be signed.
        ; It's encoded as a series of text chunks, to help with
        ; cbor-based binary diffs.
        ? legacy-vote: [ * tstr ],

        ; How should the votes within the individual sections be
        ; computed?
        voting-rules: VotingRules,

        ; Information that the authority wants to share about this
        ; vote, which is not itself voted upon.
        notes: NoteSection,

        ; Meta-information that the authorities vote on, which does
        ; not actually appear in the ENDIVE or consensus directory.
        meta: MetaSection .within VoteableSection,

        ; Fields that appear in the client network parameter document.
        client-params: ParamSection .within VoteableSection,
        ; Fields that appear in the server network parameter document.
        server-params: ParamSection .within VoteableSection,

        ; Information about each relay.
        relays: RelaySection,

        ; Information about indices.
        indices: IndexSection,

        * tstr =&gt; any
    }

    ; Self-description of a voter.
    VoterSection = {
        ; human-memorable name
        name: tstr,

        ; List of link specifiers to use when uploading to this
        ; authority. (See proposal for dirport link specifier)
        ? ul: [ *LinkSpecifier ],

        ; List of link specifiers to use when downloading from this authority.
        ? dl: [ *LinkSpecifier ],

        ; contact information for this authority.
        ? contact: tstr,

        ; legacy certificate in format given by dir-spec.txt.
        ? legacy-cert: tstr,

        ; for extensions
        * tstr =&gt; any,
    }

    ; An indexsection says how we think routing indices should be built.
    IndexSection = {
        * IndexId =&gt; bstr .cbor [ IndexGroupId, GenericIndexRule ],
    }
    IndexGroupId = uint
    ; A mechanism for building a single routing index.  Actual values need to
    ; be within RecognizedIndexRule or the authority can't complete the
    ; consensus.
    GenericIndexRule = {
        type: tstr,
        * tstr =&gt; any
    }
    RecognizedIndexRule = EdIndex / RSAIndex / BWIndex / WeightedIndex
    ; The values in an RSAIndex are derived from digests of Ed25519 keys.
    EdIndex = {
        type: "ed-id",
        alg: DigestAlgorithm,
        prefix: bstr,
        suffix: bstr
    }
    ; The values in an RSAIndex are derived from RSA keys.
    RSAIndex = {
        type: "rsa-id"
    }
    ; A BWIndex is built by taking some uint-valued field referred to by
    ; SourceField from all the relays that have all of required_flags set.
    BWIndex = {
        type: "bw",
        bwfield: SourceField,
        require_flags: FlagSet,
    }
    ; A flag can be prefixed with "!" to indicate negation.  A flag
    ; with a name like P@X indicates support for port class 'X' in its
    ; exit policy.
    ;
    ; FUTURE WORK: perhaps we should add more structure here and it
    ; should be a matching pattern?
    FlagSet = [ *tstr ]
    ; A WeightedIndex applies a set of weights to a BWIndex based on which
    ; flags the various routers have.  Relays that match a set of flags have
    ; their weights multiplied by the corresponding WeightVal.
    WeightedIndex = {
        type: "weighted",
        source: BwIndex,
        weight: { * FlagSet =&gt; WeightVal }
    }
    ; A WeightVal is either an integer to multiply bandwidths by, or a
    ; string from the Wgg, Weg, Wbm, ... set as documented in dir-spec.txt,
    ; or a reference to an earlier field.
    WeightVal = uint / tstr / SourceField
    VoteableValue =  MapVal / ListVal / SimpleVal

    ; A "VoteableSection" is something that we apply part of the
    ; voting rules to.  When we apply voting rules to these sections,
    ; we do so without regards to their semantics.  When we are done,
    ; we use these consensus values to make the final consensus.
    VoteableSection = {
       VoteableStructKey =&gt; VoteableValue,
    }

    ; A NoteSection is used to convey information about the voter and
    ; its vote that is not actually voted on.
    NoteSection = {
       ; Information about the voter itself
       voter: VoterSection,
       ; Information that the voter used when assigning flags.
       ? flag-thresholds: { tstr =&gt; any },
       ; Headers from the bandwidth file to be reported as part of
       ; the vote.
       ? bw-file-headers: {tstr =&gt; any },
       ? shared-rand-commit: SRCommit,
       * VoteableStructKey =&gt; VoteableValue,
    }

    ; Shared random commitment; fields are as for the current
    ; shared-random-commit fields.
    SRCommit = {
       ver: uint,
       alg: DigestAlgorithm,
       ident: bstr,
       commit: bstr,
       ? reveal: bstr
    }

    ; the meta-section is voted on, but does not appear in the ENDIVE.
    MetaSection = {
       ; Seconds to allocate for voting and distributing signatures
       ; Analagous to the "voting-delay" field in the legacy algorithm.
       voting-delay: [ vote_seconds: uint, dist_seconds: uint ],
       ; Proposed time till next vote.
       voting-interval: uint,
       ; proposed lifetime for the SNIPs and ENDIVEs
       snip-lifetime: Lifespan,
       ; proposed lifetime for client params document
       c-param-lifetime: Lifespan,
       ; proposed lifetime for server params document
       s-param-lifetime: Lifespan,
       ; signature depth for ENDIVE
       signature-depth: uint,
       ; digest algorithm to use with ENDIVE.
       signature-digest-alg: DigestAlgorithm,
       ; Current and previous shared-random values
       ? cur-shared-rand: [ reveals: uint, rand: bstr ],
       ? prev-shared-rand: [ reveals: uint, rand: bstr ],
       ; extensions.
       * VoteableStructKey =&gt; VoteableValue,
    };

    ; A ParamSection will be made into a ParamDoc after voting;
    ; the fields are analogous.
    ParamSection = {
       ? certs: [ 1*2 bstr .cbor VoterCert ],
       ? recommend-versions: [ * tstr ],
       ? require-protos: ProtoVersions,
       ? recommend-protos: ProtoVersions,
       ? params: NetParams,
       * VoteableStructKey =&gt; VoteableValue,
    }
    RelaySection = {
       ; Mapping from relay identity key (or digest) to relay information.
       * bstr =&gt; RelayInfo,
    }

    ; A RelayInfo is a vote about a single relay.
    RelayInfo = {
       meta: RelayMetaInfo .within VoteableSection,
       snip: RelaySNIPInfo .within VoteableSection,
       legacy: RelayLegacyInfo .within VoteableSection,
    }

    ; Information about a relay that doesn't go into a SNIP.
    RelayMetaInfo = {
        ; Tuple of published-time and descriptor digest.
        ? desc: [ uint , bstr ],
        ; What flags are assigned to this relay?  We use a
        ; string-&gt;value encoding here so that only the authorities
        ; who have an opinion on the status of a flag for a relay need
        ; to vote yes or no on it.
        ? flags: { *tstr=&gt;bool },
        ; The relay's self-declared bandwidth.
        ? bw: uint,
        ; The relay's measured bandwidth.
        ? mbw: uint,
        ; The fingerprint of the relay's RSA identity key.
        ? rsa-id: RSAIdentityFingerprint
    }
    ; SNIP information can just be voted on directly; the formats
    ; are the same.
    RelaySNIPInfo = SNIPRouterData

    ; Legacy information is used to build legacy consensuses, but
    ; not actually required by walking onions clients.
    RelayLegacyInfo = {
       ; Mapping from consensus version to microdescriptor digests
       ; and microdescriptors.
       ? mds: [ *Microdesc ],
    }

    ; Microdescriptor votes now include the digest AND the
    ; microdescriptor-- see note.
    Microdesc = [
       low: uint,
       high: uint,
       digest: bstr .size 32,
       ; This is encoded in this way so that cbor-based diff tools
       ; can see inside it.  Because of compression and diffs,
       ; including microdesc text verbatim should be comparatively cheap.
       content: encoded-cbor .cbor [ *tstr ],
    ]

    ; ==========

    ; The VotingRules field explains how to vote on the members of
    ; each section
    VotingRules = {
        meta: SectionRules,
        params: SectionRules,
        relay: RelayRules,
        indices: SectionRules,
    }

    ; The RelayRules object explains the rules that apply to each
    ; part of a RelayInfo.  A key will appear in the consensus if it
    ; has been listed by at least key_min_count authorities.
    RelayRules = {
        key_min_count: IntOpArgument,
        meta: SectionRules,
        snip: SectionRules,
        legacy: SectionRules,
    }

&lt;!-- Section 3.5 --&gt; &lt;a id='S3.5'&gt;&lt;/a&gt;

## Computing a consensus.

To compute a consensus, the authorities first verify that all the votes are
timely and correctly signed by real authorities.  This includes
validating all invariants stated here, and all internal documents.

If they have two votes from an authority, authorities SHOULD issue a
warning, and they should take the one that is published more
recently.

&gt; TODO: Teor suggests that maybe we shouldn't warn about two votes
&gt; from an authority for the same period, and we could instead have a
&gt; more resilient process here, where authorities can update their
&gt; votes at various times over the voting period, up to some point.
&gt;
&gt; I'm not sure whether this helps reliability more or less than it risks it,
&gt; but it worth investigating.

Next, the authorities determine the consensus method as they do today,
using the field "consensus-method".  This can also be expressed as
the voting operation `Threshold[SUPERQUORUM_PRESENT, false, uint]`.

If there is no consensus for the consensus-method, then voting stops
without having produced a consensus.

Note that in contrast with its behavior in the current voting algorithm, the
consensus method does not determine the way to vote on every
individual field: that aspect of voting is controlled by the
voting-rules.  Instead, the consensus-method changes other aspects
of this voting, such as:

    * Adding, removing, or changing the semantics of voting
      operations.
    * Changing the set of documents to which voting operations apply.
    * Otherwise changing the rules that are set out in this
      document.

Once a consensus-method is decided, the next step is to compute the
consensus for other sections in this order: `meta`, `client-params`,
`server-params`, and `indices`.  The consensus for each is calculated
according to the operations given in the corresponding section of
VotingRules.

Next the authorities compute a consensus on the `relays` section,
which is done slightly differently, according to the rules of
RelayRules element of VotingRules.

Finally, the authorities transform the resulting sections into an
ENDIVE and a legacy consensus, as in "Computing an ENDIVE" and
"Computing a legacy consensus" below.

To vote on a single VotingSection, find the corresponding
SectionRules objects in the VotingRules of this votes, and apply it
as described above in "Voting on document sections".

&lt;!-- Section 3.6 --&gt; &lt;a id='S3.6'&gt;&lt;/a&gt;

## If an older consensus method is negotiated (Transitional)

The `legacy-vote` field in the vote document contains an older (v3,
text-style) consensus vote, and is used when an older consensus
method is negotiated.  The legacy-vote is encoded by splitting it
into pieces, to help with CBOR diff calculation.  Authorities MAY split at
line boundaries, space boundaries, or anywhere that will help with
diffs.   To reconstruct the legacy vote, concatenate the members of
`legacy-vote` in order.  The resulting string MUST validate
according to the rules of the legacy voting algorithm.

If a legacy vote is present, then authorities SHOULD include the
same view of the network in the legacy vote as they included in their
real vote.

If a legacy vote is present, then authorities MUST
give the same list of consensus-methods and the same voting
schedule in both votes.  Authorities MUST reject noncompliant votes.

&lt;!-- Section 3.7 --&gt; &lt;a id='S3.7'&gt;&lt;/a&gt;

## Computing an ENDIVE.

If a consensus-method is negotiated that is high enough to support
ENDIVEs, then the authorities proceed as follows to transform the consensus
sectoins above into an ENDIVE.

The ParamSections from the consensus are used verbatim as the bodies of the
`client-params` and `relay-params` fields.

The fields that appear in each RelaySNIPInfo determine what goes
into the SNIPRouterData for each relay. To build the relay section,
first decide which relays appear according to the `key_min_count`
field in the RelayRules.  Then collate relays across all the votes
by their keys, and see which ones are listed.  For each key that
appears in at least `key_min_count` votes, apply the RelayRules to
each section of the RelayInfos for that key.

The sig_params section is derived from fields in the meta section.
Fields with identical names are simply copied; Lifespan values are
copied to the corresponding documents (snip-lifetime as the lifespan
for SNIPs and ENDIVEs, and c and s-param-lifetime as the lifespan
for ParamDocs).

To compute the signature nonce, use the signature digest algorithm
to compute the digest of each input vote body, sort those digests
lexicographically, and concatenate and hash those digests again.

Routing indices are built according to named IndexRules, and grouped
according to fields in the meta section.  See "Constructing Indices" below.

&gt; (At this point extra fields may be copied from the Meta section of
&gt; each RelayInfo into the ENDIVERouterData depending on the meta
&gt; document; we do not, however, currently specify any case where this
&gt; is done.)

&lt;!-- Section 3.7.1 --&gt; &lt;a id='S3.7.1'&gt;&lt;/a&gt;

### Constructing indices

After having built the list of relays, the authorities construct and
encode the indices that appear in the ENDIVEs.  The voted-upon
GenericIndexRule values in the IndexSection of the consensus say how
to build the indices in the ENDIVE, as follows.

An `EdIndex` is built using the IndexType_Ed25519Id value, with the
provided prefix and suffix values.  Authorities don't need to expand
this index in the ENDIVE, since the relays can compute it
deterministically.

An `RSAIndex` is built using the IndexType_RSAId type.  Authorities
don't need to expand this index in the ENDIVE, since the relays can
compute it deterministically.

A `BwIndex` is built using the IndexType_Weighted type. Each relay has a
weight equal to some specified bandwidth field in its consensus
RelayInfo.  If a relay is missing any of the `required_flags` in
its meta section, or if it does not have the specified bandwidth
field, that relay's weight becomes 0.

A `WeightedIndex` is built by computing a BwIndex, and then
transforming each relay in the list according to the flags that it
has set.  Relays that match any set of flags in the WeightedIndex
rule get their bandwidths multiplied by _all_ WeightVals that
apply.  Some WeightVals are computed according to special rules,
such as "Wgg", "Weg", and so on.  These are taken from the current
dir-spec.txt.

For both BwIndex and WeightedIndex values, authorities MUST scale
the computed outputs so that no value is greater than UINT32_MAX;
they MUST do by shifting all values right by lowest number of bits
that achieves this.

&gt; We could specify a more precise algorithm, but this is simpler.

Indices with the same IndexGroupId are placed in the same index
group; index groups are ordered numerically.

&lt;!-- Section 3.8 --&gt; &lt;a id='S3.8'&gt;&lt;/a&gt;

## Computing a legacy consensus.

When using a consensus method that supports Walking Onions, the
legacy consensus is computed from the same data as the ENDIVE.
Because the legacy consensus format will be frozen once Walking
Onions is finalized, we specify this transformation directly, rather
than in a more extensible way.

The published time and descriptor digest are used directly.
Microdescriptor negotiation proceeds as before.  Bandwidths,
measured bandwidths, descriptor digests, published times, flags, and
rsa-id values are taken from the RelayMetaInfo section.  Addresses,
protovers, versions, and so on are taken from the RelaySNIPInfo. Header
fields are all taken from the corresponding header fields in the
MetaSection or the ClientParamsSection. All parameters are copied
into the net-params field.

&lt;!-- Section 3.9 --&gt; &lt;a id='S3.9'&gt;&lt;/a&gt;

## Managing indices over time.

&gt; The present voting mechanism does not do a great job of handling
&gt; the authorities

The semantic meaning of most IndexId values, as understood by
clients should remain unchanging; if a client uses index 6 for
middle nodes, 6 should _always_ mean "middle nodes".

If an IndexId is going to change its meaning over time, it should
_not_ be hardcoded by clients; it should instead be listed in the
NetParams document, as the exit indices are in the `port-classes`
field. (See also section 6 and appendix AH.)  If such a field needs
to change, it also needs a migration method that allows clients with
older and newer parameters documents to exist at the same time.

&lt;!-- Section 4 --&gt; &lt;a id='S4'&gt;&lt;/a&gt;

# Relay operations: Receiving and expanding ENDIVEs

Previously, we introduced a format for ENDIVEs to be transmitted
from authorities to relays.  To save on bandwidth, the relays
download diffs rather than entire ENDIVEs.  The ENDIVE format makes
several choices in order to make these diffs small: the Merkle tree
is omitted, and routing indices are not included directly.

To address those issues, this document describes the steps that a
relay needs to perform, upon receiving an ENDIVE document, to derive
all the SNIPs for that ENDIVE.

Here are the steps to be followed.  We'll describe them in order,
though in practice they could be pipelined somewhat.  We'll expand
further on each step later on.

  1. Compute routing indices positions.

  2. Compute truncated SNIPRouterData variations.

  3. Build signed SNIP data.

  4. Compute Merkle tree.

  5. Build authenticated SNIPs.

Below we'll specify specific algorithms for these steps.  Note that
relays do not need to follow the steps of these algorithms exactly,
but they MUST produce the same outputs as if they had followed them.

&lt;!-- Section 4.1 --&gt; &lt;a id='S4.1'&gt;&lt;/a&gt;

## Computing index positions.

For every IndexId in every Index Group, the relay will compute the
full routing index.  Every routing index is a mapping from
index position ranges (represented as 2-tuples) to relays, where the
relays are represented as ENDIVERouterData members of the ENDIVE.  The
routing index must map every possible value of the index to exactly one
relay.

An IndexSpec field describes how the index is to be constructed.  There
are four types of IndexSpec: Raw, Raw Spans, Weighted, RSAId, and
Ed25519Id.  We'll describe how to build the indices for each.

Every index may either have an integer key, or a binary-string
key. We define the "successor" of an integer index as the succeeding
integer.  We define the "successor" of a binary string as the next
binary string of the same length in lexicographical (memcmp) order.  We
define "predecessor" as the inverse of "successor".  Both these
operations "wrap around" the index.

The algorithms here describe a set of invariants that are
"verified".  Relays SHOULD check each of these invariants;
authorities MUST NOT generate any ENDIVEs that violate them.  If a
relay encounters an ENDIVE that cannot be verified, then the ENDIVE
cannot be expanded.

&gt; NOTE: conceivably should there be some way to define an index as a
&gt; subset of another index, with elements weighted in different ways?  In
&gt; other words, "Index a is index b, except multiply these relays by 0 and
&gt; these relays by 1.2".  We can keep this idea sitting around in case there
&gt; turns out to be a use for it.

&lt;!-- Section 4.1.1 --&gt; &lt;a id='S4.1.1'&gt;&lt;/a&gt;

### Raw indices

When the IndexType is Indextype_Raw, then its members are listed
directly in the IndexSpec.

    Algorithm: Expanding a "Raw" indexspec.

    Let result_idx = {} (an empty mapping).

    Let previous_pos = indexspec.first_index

    For each element [i, pos2] of indexspec.index_ranges:

        Verify that i is a valid index into the list of ENDIVERouterData.

        Set pos1 = the successor of previous_pos.

        Verify that pos1 and pos2 have the same type.

        Append the mapping (pos1, pos2) =&gt; i to result_idx

        Set previous_pos to pos2.

    Verify that previous_pos = the predecessor of indexspec.first_index.

    Return result_idx.

&lt;!-- Section 4.1.2 --&gt; &lt;a id='S4.1.2'&gt;&lt;/a&gt;

### Raw numeric indices

If the IndexType is Indextype_RawNumeric, it is described by a set of
spans on a 32-bit index range.

    Algorithm: Expanding a RawNumeric index.

    Let prev_pos = 0

    For each element [i, span] of indexspec.index_ranges:

        Verify that i is a valid index into the list of ENDIVERouterData.

        Verify that prev_pos &lt;= UINT32_MAX - span.

        Let pos2 = prev_pos + span.

        Append the mapping (pos1, pos2) =&gt; i to result_idx.

        Let prev_pos = successor(pos2)

    Verify that prev_pos = UINT32_MAX.

    Return result_idx.

&lt;!-- Section 4.1.3 --&gt; &lt;a id='S4.1.3'&gt;&lt;/a&gt;

### Weighted indices

If the IndexSpec type is Indextype_Weighted, then the index is
described by assigning a probability weight to each of a number of relays.
From these, we compute a series of 32-bit index positions.

This algorithm uses 64-bit math, and 64-by-32-bit integer division.

It requires that the sum of weights is no more than UINT32_MAX.

    Algorithm: Expanding a "Weighted" indexspec.

    Let total_weight = SUM(indexspec.index_weights)

    Verify total_weight &lt;= UINT32_MAX.

    Let total_so_far = 0.

    Let result_idx = {} (an empty mapping).

    Define POS(b) = FLOOR( (b &lt;&lt; 32) / total_weight).

    For 0 &lt;= i &lt; LEN(indexspec.indexweights):

       Let w = indexspec.indexweights[i].

       Let lo = POS(total_so_far).

       Let total_so_far = total_so_far + w.

       Let hi = POS(total_so_far) - 1.

       Append (lo, hi) =&gt; i to result_idx.

    Verify that total_so_far = total_weight.

    Verify that the last value of "hi" was UINT32_MAX.

    Return result_idx.

This algorithm is a bit finicky in its use of division, but it
results in a mapping onto 32 bit integers that completely covers the
space of available indices.

&lt;!-- Section 4.1.4 --&gt; &lt;a id='S4.1.4'&gt;&lt;/a&gt;

### RSAId indices

If the IndexSpec type is Indextype_RSAId then the index is a set of
binary strings describing the routers' legacy RSA identities, for
use in the HSv2 hash ring.

These identities are truncated to a fixed length.  Though the SNIP
format allows _variable_-length binary prefixes, we do not use this
feature.

    Algorithm: Expanding an "RSAId" indexspec.

    Let R = [ ] (an empty list).

    Take the value n_bytes from the IndexSpec.

    For 0 &lt;= b_idx &lt; MIN( LEN(indexspec.members) * 8,
                          LEN(list of ENDIVERouterData) ):

       Let b = the b_idx'th bit of indexspec.members.

       If b is 1:
           Let m = the b_idx'th member of the ENDIVERouterData list.

           Verify that m has its RSAIdentityFingerprint set.

           Let pos = m.RSAIdentityFingerprint, truncated to n_bytes.

           Add (pos, b_idx) to the list R.

    Return INDEX_FROM_RING_KEYS(R).

    Sub-Algorithm: INDEX_FROM_RING_KEYS(R)

    First, sort R according to its 'pos' field.

    For each member (pos, idx) of the list R:

        If this is the first member of the list R:
            Let key_low = pos for the last member of R.
        else:
            Let key_low = pos for the previous member of R.

        Let key_high = predecessor(pos)

        Add (key_low, key_high) =&gt; idx to result_idx.

    Return result_idx.

&lt;!-- Section 4.1.5 --&gt; &lt;a id='S4.1.5'&gt;&lt;/a&gt;

### Ed25519 indices

If the IndexSpec type is Indextype_Ed25519, then the index is a set of
binary strings describing the routers' positions in a hash ring,
derived from their Ed25519 identity keys.

This algorithm is a generalization of the one used for hsv3 rings,
to be used to compute the hsv3 ring and other possible future
derivatives.

    Algorithm: Expanding an "Ed25519Id" indexspec.

    Let R = [ ] (an empty list).

    Take the values prefix, suffix, and n_bytes from the IndexSpec.

    Let H() be the digest algorithm specified by d_alg from the
    IndexSpec.

    For 0 &lt;= b_idx &lt; MIN( LEN(indexspec.members) * 8,
                          LEN(list of ENDIVERouterData) ):

       Let b = the b_idx'th bit of indexspec.members.

       If b is 1:
           Let m = the b_idx'th member of the ENDIVERouterData list.

           Let key = m's ed25519 identity key, as a 32-byte value.

           Compute pos = H(prefix || key || suffix)

           Truncate pos to n_bytes.

           Add (pos, b_idx) to the list R.

    Return INDEX_FROM_RING_KEYS(R).

&lt;!-- Section 4.1.6 --&gt; &lt;a id='S4.1.6'&gt;&lt;/a&gt;

### Building a SNIPLocation

After computing all the indices in an IndexGroup, relays combine
them into a series of SNIPLocation objects. Each SNIPLocation
MUST contain all the IndexId =&gt; IndexRange entries that point to a
given ENDIVERouterData, for the IndexIds listed in an IndexGroup.

    Algorithm: Build a list of SNIPLocation objects from a set of
routing indices.

    Initialize R as [ { } ] * LEN(relays)   (A list of empty maps)

    For each IndexId "ID" in the IndexGroup:

       Let router_idx be the index map calculated for ID.
       (This is what we computed previously.)

       For each entry ( (LO, HI) =&gt; idx) in router_idx:

          Let R[idx][ID] = (LO, HI).

SNIPLocation objects are thus organized in the order in which they will
appear in the Merkle tree: that is, sorted by the position of their
corresponding ENDIVERouterData.

Because SNIPLocation objects are signed, they must be encoded as "canonical"
cbor, according to section 3.9 of RFC 7049.

If R[idx] is {} (the empty map) for any given idx, then no SNIP will be
generated for the SNIPRouterData at that routing index for this index group.

&lt;!-- Section 4.2 --&gt; &lt;a id='S4.2'&gt;&lt;/a&gt;

## Computing truncated SNIPRouterData.

An index group can include an `omit_from_snips` field to indicate that
certain fields from a SNIPRouterData should not be included in the
SNIPs for that index group.

Since a SNIPRouterData needs to be signed, this process has to be
deterministic.  Thus, the truncated SNIPRouterData should be computed by
removing the keys and values for EXACTLY the keys listed and no more.  The
remaining keys MUST be left in the same order that they appeared in the
original SNIPRouterData, and they MUST NOT be re-encoded.

(Two keys are "the same" if and only if they are integers encoding the same
value, or text strings with the same UT-8 content.)

There is no need to compute a SNIPRouterData when no SNIP is going to be
generated for a given router.

&lt;!-- Section 4.3 --&gt; &lt;a id='S4.3'&gt;&lt;/a&gt;

## Building the Merkle tree.

After computing a list of (SNIPLocation, SNIPRouterData) for every entry
in an index group, the relay needs to expand a Merkle tree to
authenticate every SNIP.

There are two steps here: First the relay generates the leaves, and then
it generates the intermediate hashes.

To generate the list of leaves for an index group, the relay first
removes all entries from the (SNIPLocation, SNIPRouterData) list that
have an empty index map.  The relay then puts `n_padding_entries` "nil"
entries at the end of the list.

To generate the list of leaves for the whole Merkle tree, the relay
concatenates these index group lists in the order in which they appear
in the ENDIVE, and pads the resulting list with "nil" entries until the
length of the list is a power of two: 2^`tree-depth` for some integer
`tree-depth`.  Let LEAF(IDX) denote the entry at position IDX in this
list, where IDX is a D-bit bitstring.  LEAF(IDX) is either a byte string
or nil.

The relay then recursively computes the hashes in the Merkle tree as
follows.  (Recall that `H_node()` and `H_leaf()` are hashes taking
a bit-string PATH, a LIFESPAN and NONCE from the signature information,
and a variable-length string ITEM.)

    Recursive defintion: HM(PATH)

    Given PATH a bitstring of length no more than tree-depth.

    Define S:
        S(nil) = an all-0 string of the same length as the hash output.
        S(x) = x, for all other x.

    If LEN(PATH) = tree-depth:   (Leaf case.)
       If LEAF(PATH) = nil:
         HM(PATH) = nil.
       Else:
         HM(PATH) = H_node(PATH, LIFESPAN, NONCE, LEAF(PATH)).

    Else:
       Let LEFT = HM(PATH || 0)
       Let RIGHT = HM(PATH || 1)
       If LEFT = nil and RIGHT = nil:
           HM(PATH) = nil
       else:
           HM(PATH) = H_node(PATH, LIFESPAN, NONCE, S(LEFT) || S(RIGHT))

Note that entries aren't computed for "nil" leaves, or any node all of
whose children are "nil".  The "nil" entries only exist to place all
leaves at a constant depth, and to enable spacing out different sections
of the tree.

If `signature-depth` for the ENDIVE is N, the relay does not need to
compute any Merkle tree entries for PATHs of length shorter than N bits.

&lt;!-- Section 4.4 --&gt; &lt;a id='S4.4'&gt;&lt;/a&gt;

## Assembling the SNIPs

Finally, the relay has computed a list of encoded (SNIPLocation,
RouterData) values, and a Merkle tree to authenticate them.  At this
point, the relay builds them into SNIPs, using the `sig_params` and
`signatures` from the ENDIVE.

    Algorithm: Building a SNIPSignature for a SNIP.

    Given a non-nil (SNIPLocation, RouterData) at leaf position PATH.

    Let SIG_IDX = PATH, truncated to signature-depth bits.
    Consider SIG_IDX as an integer.

    Let Sig = signatures[SIG_IDX] -- either the SingleSig or the MultiSig
    for this snip.

    Let HashPath = []   (an empty list).
    For bitlen = signature-depth+1 ... tree-depth-1:
        Let X = PATH, truncated to bitlen bits.
        Invert the final bit of PATH.
        Append HM(PATH) to HashPath.

    The SnipSignature's signature values is Sig, and its merkle_path is
    HashPath.

&lt;!-- Section 4.5 --&gt; &lt;a id='S4.5'&gt;&lt;/a&gt;

## Implementation considerations

A relay only needs to hold one set of SNIPs at a time: once one
ENDIVE's SNIPs have been extracted, then the SNIPs from the previous
ENDIVE can be discarded.

To save memory, a relay MAY store SNIPs to disk, and mmap them as
needed.

&lt;!-- Section 5 --&gt; &lt;a id='S5'&gt;&lt;/a&gt;

# Extending circuits with Walking Onions

When a client wants to extend a circuit, there are several
possibilities.  It might need to extend to an unknown relay with
specific properties.  It might need to extend to a particular relay
from which it has received a SNIP before.  In both cases, there are
changes to be made in the circuit extension process.

Further, there are changes we need to make for the handshake between
the extending relay and the target relay.  The target relay is no
longer told by the client which of its onion keys it should use... so
the extending relay needs to tell the target relay which keys are in
the SNIP that the client is using.

&lt;!-- Section 5.1 --&gt; &lt;a id='S5.1'&gt;&lt;/a&gt;

## Modifying the EXTEND/CREATE handshake

First, we will require that proposal 249 (or some similar proposal
for wide CREATE and EXTEND cells) is in place, so that we can have
EXTEND cells larger than can fit in a single cell.  (See
319-wide-everything.md for an example proposal to supersede 249.)

We add new fields to the CREATE2 cell so that relays can send each
other more information without interfering with the client's part of
the handshake.

The CREATE2, CREATED2, and EXTENDED2 cells change as follows:

      struct create2_body {
         // old fields
         u16 htype; // client handshake type
         u16 hlen; // client handshake length
         u8 hdata[hlen]; // client handshake data.

         // new fields
         u8 n_extensions;
         struct extension extension[n_extensions];
      }

      struct created2_body {
         // old fields
         u16 hlen;
         u8 hdata[hlen];

         // new fields
         u8 n_extensions;
         struct extension extension[n_extensions];
      }

      struct truncated_body {
         // old fields
         u8 errcode;

         // new fields
         u8 n_extensions;
         struct extension extension[n_extensions];
      }

      // EXTENDED2 cells can now use the same new fields as in the
      // created2 cell.

      struct extension {
         u16 type;
         u16 len;
         u8 body[len];
      }

These extensions are defined by this proposal:

  [01] -- `Partial_SNIPRouterData` -- Sent from an extending relay
          to a target relay. This extension holds one or more fields
          from the SNIPRouterData that the extending relay is using,
          so that the target relay knows (for example) what keys to
          use.  (These fields are determined by the
          "forward_with_extend" field in the ENDIVE.)

  [02] -- Full_SNIP -- an entire SNIP that was used in an attempt to
          extend the circuit.  This must match the client's provided
          index position.

  [03] -- Extra_SNIP -- an entire SNIP that was not used to extend
          the circuit, but which the client requested anyway.  This
          can be sent back from the extending relay when the client
          specifies multiple index positions, or uses a nonzero "nth" value
          in their `snip_index_pos` link specifier.

  [04] -- SNIP_Request -- a 32-bit index position, or a single zero
          byte, sent away from the client.  If the byte is 0, the
          originator does not want a SNIP.  Otherwise, the
          originator does want a SNIP containing the router and the
          specified index.  Other values are unspecified.

By default, EXTENDED2 cells are sent with a SNIP iff the EXTENDED2
cell used a `snip_index_pos` link specifier, and CREATED2 cells are
not sent with a SNIP.

&lt;!-- Section 5.1.1 --&gt; &lt;a id='S5.1.1'&gt;&lt;/a&gt;

### New link specifiers

We add a new link specifier type for a router index, using the
following coding for its contents:

    /* Using trunnel syntax here. */
    struct snip_index_pos {
        u32 index_id; // which index is it?
        u8 nth; // how many SNIPs should be skipped/included?
        u8 index_pos[]; // extends to the end of the link specifier.
    }

The `index_pos` field can be longer or shorter than the actual width of
the router index.  If it is too long, it is truncated.  If it is too
short, it is extended with zero-valued bytes.

Any number of these link specifiers may appear in an EXTEND cell.
If there is more then one, then they should appear in order of
client preference; the extending relay may extend to any of the
listed routers.

This link specifier SHOULD NOT be used along with IPv4, IPv6, RSA
ID, or Ed25519 ID link specifiers.  Relays receiving such a link
specifier along with a `snip_index_pos` link specifier SHOULD reject
the entire EXTEND request.

If `nth` is nonzero, then link specifier means "the n'th SNIP after
the one defined by the SNIP index position."  A relay MAY reject
this request if `nth` is greater than 4.  If the relay does not
reject this request, then it MUST include all snips between
`index_pos` and the one that was actually used in an Extra_Snip
extension.  (Otherwise, the client would not be able to verify that
it had gotten the correct SNIP.)

&gt; I've avoided use of CBOR for these types, under the assumption that we'd
&gt; like to use CBOR for directory stuff, but no more.  We already have
&gt; trunnel-like objects for this purpose.

&lt;!-- Section 5.2 --&gt; &lt;a id='S5.2'&gt;&lt;/a&gt;

## Modified ntor handshake

We adapt the ntor handshake from tor-spec.txt for this use, with the
following main changes.

  * The NODEID and KEYID fields are omitted from the input.
    Instead, these fields _may_ appear in a PartialSNIPData extension.

  * The NODEID and KEYID fields appear in the reply.

  * The NODEID field is extended to 32 bytes, and now holds the
    relay's ed25519 identity.

So the client's message is now:

   CLIENT_PK [32 bytes]

And the relay's reply is now:

   NODEID    [32 bytes]
   KEYID     [32 bytes]
   SERVER_PK [32 bytes]
   AUTH      [32 bytes]

otherwise, all fields are computed as described in tor-spec.

When this handshake is in use, the hash function is SHA3-256 and keys
are derived using SHAKE-256, as in rend-spec-v3.txt.

&gt; Future work: We may wish to update this choice of functions
&gt; between now and the implementation date, since SHA3 is a bit
&gt; pricey.  Perhaps one of the BLAKEs would be a better choice.  If
&gt; so, we should use it more generally.  On the other hand, the
&gt; presence of public-key operations in the handshake _probably_
&gt; outweighs the use of SHA3.

We will have to give this version of the handshake a new handshake
type.

&lt;!-- Section 5.3 --&gt; &lt;a id='S5.3'&gt;&lt;/a&gt;

## New relay behavior on EXTEND and CREATE failure.

If an EXTEND2 cell based on an routing index fails, the relay should
not close the circuit, but should instead send back a TRUNCATED cell
containing the SNIP in an extension.

If a CREATE2 cell fails and a SNIP was requested, then instead of
sending a DESTROY cell, the relay SHOULD respond with a CREATED2
cell containing 0 bytes of handshake data, and the SNIP in an
extension.  Clients MAY re-extend or close the circuit, but should
not leave it dangling.

&lt;!-- Section 5.4 --&gt; &lt;a id='S5.4'&gt;&lt;/a&gt;

## NIL handshake type

We introduce a new handshake type, "NIL".  The NIL handshake always
fails.  A client's part of the NIL handshake is an empty bytestring;
there is no server response that indicates success.

The NIL handshake can used by the client when it wants to fetch a
SNIP without creating a circuit.

Upon receiving a request to extend with the NIL circuit type, a
relay SHOULD NOT actually open any connection or send any data to
the target relay.  Instead, it should respond with a TRUNCATED cell
with the SNIP(s) that the client requested in one or more Extra_SNIP
extensions.

&lt;!-- Section 5.5 --&gt; &lt;a id='S5.5'&gt;&lt;/a&gt;

## Padding handshake cells to a uniform size

To avoid leaking information, all CREATE/CREATED/EXTEND/EXTENDED
cells SHOULD be padded to the same sizes.  In all cases, the amount
of padding is controlled by a set of network parameters:
"create-pad-len", "created-pad-len", "extend-pad-len" and
"extended-pad-len".  These parameters determine the minimum length
that the cell body or relay cell bodies should be.

If a cell would be sent whose body is less than the corresponding
parameter value, then the sender SHOULD pad the body by adding
zero-valued bytes to the cell body.  As usual, receivers MUST ignore
extra bytes at the end of cells.

&gt; ALTERNATIVE: We could specify a more complicated padding
&gt; mechanism, eg. 32 bytes of zeros then random bytes.


&lt;!-- Section 6 --&gt; &lt;a id='S6'&gt;&lt;/a&gt;

# Client behavior with walking onions

Today's Tor clients have several behaviors that become somewhat
more difficult to implement with Walking Onions.  Some of these
behaviors are essential and achievable.  Others can be achieved with
some effort, and still others appear to be incompatible with the
Walking Onions design.

&lt;!-- Section 6.1 --&gt; &lt;a id='S6.1'&gt;&lt;/a&gt;

## Bootstrapping and guard selection

When a client first starts running, it has no guards on the Tor
network, and therefore can't start building circuits immediately.
To produce a list of possible guards, the client begins connecting
to one or more fallback directories on their ORPorts, and building
circuits through them.  These are 3-hop circuits.  The first hop of
each circuit is the fallback directory; the second and third hops
are chosen from the Middle routing index.  At the third hop, the
client then sends an informational request for a guard's SNIP.  This
informational request is an EXTEND2 cell with handshake type NIL,
using a random spot on the Guard routing index.

Each such request yields a single SNIP that the client will store.
These SNIPs, in the order in which they were _requested_, will form the
client's list of "Sampled" guards as described in guard-spec.txt.

Clients SHOULD ensure that their sampled guards are not
linkable to one another.  In particular, clients SHOULD NOT add more
than one guard retrieved from the same third hop on the same
circuit. (If it did, that third hop would realize that some client using
guard A was also using guard B.)

&gt; Future work: Is this threat real?  It seems to me that knowing one or two
&gt; guards at a time in this way is not a big deal, though knowing the whole
&gt; set would sure be bad.  However, we shouldn't optimize this kind of
&gt; defense away until we know that it's actually needless.

If a client's network connection or choice of entry nodes is heavily
restricted, the client MAY request more than one guard at a time, but if
it does so, it SHOULD discard all but one guard retrieved from each set.

After choosing guards, clients will continue to use them even after
their SNIPs expire.  On the first circuit through each guard after
opening a channel, clients should ask that guard for a fresh SNIP for
itself, to ensure that the guard is still listed in the consensus, and
to keep the client's information up-to-date.

&lt;!-- Section 6.2 --&gt; &lt;a id='S6.2'&gt;&lt;/a&gt;

## Using bridges

As now, clients are configured to use a bridge by using an address and a
public key for the bridge.  Bridges behave like guards, except that they
are not listed in any directory or ENDIVE, and so cannot prove
membership when the client connects to them.

On the first circuit through each channel to a bridge, the client
asks that bridge for a SNIP listing itself in the `Self` routing
index.  The bridge responds with a self-created unsigned SNIP:

     ; This is only valid when received on an authenticated connection
     ; to a bridge.
     UnsignedSNIP = [
        ; There is no signature on this SNIP.
        auth : nil,

        ; Next comes the location of the SNIP within the ENDIVE.  This
        ; SNIPLocation will list only the Self index.
        index : bstr .cbor SNIPLocation,

        ; Finally comes the information about the router.
        router : bstr .cbor SNIPRouterData,
     ]

*Security note*: Clients MUST take care to keep UnsignedSNIPs separated
from signed ones. These are not part of any ENDIVE, and so should not be
used for any purpose other than connecting through the bridge that the
client has received them from.  They should be kept associated with that
bridge, and not used for any other, even if they contain other link
specifiers or keys.  The client MAY use link specifiers from the
UnsignedSNIP on future attempts to connect to the bridge.

&lt;!-- Section 6.3 --&gt; &lt;a id='S6.3'&gt;&lt;/a&gt;

## Finding relays by exit policy

To find a relay by exit policy, clients might choose the exit
routing index corresponding to the exit port they want to use.  This
has negative privacy implications, however, since the middle node
discovers what kind of exit traffic the client wants to use.
Instead, we support two other options.

First, clients may build anonymous three-hop circuits and then use those
circuits to request the SNIPs that they will use for their exits.  This
may, however, be inefficient.

Second, clients may build anonymous three-hop circuits and then use a
BEGIN cell to try to open the connection when they want.  When they do
so, they may include a new flag in the begin cell, "DVS" to enable
Delegated Verifiable Selection.  As described in the Walking Onions
paper, DVS allows a relay that doesn't support the requested port to
instead send the client the SNIP of a relay that does.  (In the paper,
the relay uses a digest of previous messages to decide which routing
index to use. Instead, we have the client send an index field.)

This requires changes to the BEGIN and END cell formats.  After the
"flags" field in BEGIN cells, we add an extension mechanism:

    struct begin_cell {
        nulterm addr_port;
        u32 flags;
        u8 n_extensions;
        struct extension exts[n_extensions];
    }

We allow the `snip_index_pos` link specifier type to appear as a begin
extension.

END cells will need to have a new format that supports including policy and
SNIP information.  This format is enabled whenever a new `EXTENDED_END_CELL`
flag appears in the begin cell.

    struct end_cell {
        u8 tag IN [ 0xff ]; // indicate that this isn't an old-style end cell.
        u8 reason;
        u8 n_extensions;
        struct extension exts[n_extensions];
    }

We define three END cell extensions.  Two types are for addresses, that
indicate what address was resolved and the associated TTL:

    struct end_ext_ipv4 {
        u32 addr;
        u32 ttl;
    }
    struct end_ext_ipv6 {
        u8 addr[16];
        u32 ttl;
    }

One new END cell extension is used for delegated verifiable selection:

    struct end_ext_alt_snip {
        u16 index_id;
        u8 snip[..];
    }

This design may require END cells to become wider; see
319-wide-everything.md for an example proposal to
supersede proposal 249 and allow more wide cell types.

&lt;!-- Section 6.4 --&gt; &lt;a id='S6.4'&gt;&lt;/a&gt;

## Universal path restrictions

There are some restrictions on Tor paths that all clients should obey,
unless they are configured not to do so.  Some of these restrictions
(like "start paths with a Guard node" or "don't use an Exit as a middle
when Exit bandwidth is scarce") are captured by the index system. Some
other restrictions are not.  Here we describe how to implement those.

The general approach taken here is "build and discard".  Since most
possible paths will not violate these universal restrictions, we
accept that a fraction of the paths built will not be usable.
Clients tear them down a short time after they are built.

Clients SHOULD discard a circuit if, after it has been built, they
find that it contains the same relay twice, or it contains more than
one relay from the same family or from the same subnet.

Clients MAY remember the SNIPs they have received, and use those
SNIPs to avoid index ranges that they would automatically reject.
Clients SHOULD NOT store any SNIP for longer than it is maximally
recent.

&gt; NOTE: We should continue to monitor the fraction of paths that are
&gt; rejected in this way.  If it grows too high, we either need to amend
&gt; the path selection rules, or change authorities to e.g. forbid more
&gt; than a certain fraction of relay weight in the same family or subnet.

&gt; FUTURE WORK: It might be a good idea, if these restrictions truly are
&gt; 'universal', for relays to have a way to say "You wouldn't want that
&gt; SNIP; I am giving you the next one in sequence" and send back both
&gt; SNIPs.  This would need some signaling in the EXTEND/EXTENDED cells.

&lt;!-- Section 6.5 --&gt; &lt;a id='S6.5'&gt;&lt;/a&gt;

## Client-configured path restrictions

Sometimes users configure their clients with path restrictions beyond
those that are in ordinary use.  For example, a user might want to enter
only from US relays, but never exit from US.  Or they might be
configured with a short list of vanguards to use in their second
position.

&lt;!-- Section 6.5.1 --&gt; &lt;a id='S6.5.1'&gt;&lt;/a&gt;

### Handling "light" restrictions

If a restriction only excludes a small number of relays, then clients
can continue to use the "build and discard" methodology described above.

&lt;!-- Section 6.5.2 --&gt; &lt;a id='S6.5.2'&gt;&lt;/a&gt;

### Handling some "heavy" restrictions

Some restrictions can exclude most relays, and still be reasonably easy
to implement if they only _include_ a small fraction of relays.  For
example, if the user has a EntryNodes restriction that contains only a
small group of relays by exact IP address, the client can connect or
extend to one of those addresses specifically.

If we decide IP ranges are important, that IP addresses without
ports are important, or that key specifications are important, we
can add routing indices that list relays by IP, by RSAId, or by
Ed25519 Id.  Clients could then use those indices to remotely
retrieve SNIPs, and then use those SNIPs to connect to their
selected relays.

&gt; Future work: we need to decide how many of the above functions to actually
&gt; support.

&lt;!-- Section 6.5.3 --&gt; &lt;a id='S6.5.3'&gt;&lt;/a&gt;

### Recognizing too-heavy restrictions

The above approaches do not handle all possible sets of restrictions. In
particular, they do a bad job for restrictions that ban a large fraction
of paths in a way that is not encodeable in the routing index system.

If there is substantial demand for such a path restriction, implementors
and authority operators should figure out how to implement it in the
index system if possible.

Implementations SHOULD track what fraction of otherwise valid circuits
they are closing because of the user's configuration.  If this fraction
is above a certain threshold, they SHOULD issue a warning; if it is
above some other threshold, they SHOULD refuse to build circuits
entirely.

&gt; Future work: determine which fraction appears in practice, and use that to
&gt; set the appropriate thresholds above.

&lt;!-- Section 7 --&gt; &lt;a id='S7'&gt;&lt;/a&gt;

# Using and providing onion services with Walking Onions

Both live versions of the onion service design rely on a ring of
hidden service directories for use in uploading and downloading
hidden service descriptors.  With Walking Onions, we can use routing
indices based on Ed25519 or RSA identity keys to retrieve this data.

(The RSA identity ring is unchanging, whereas the Ed25519 ring
changes daily based on the shared random value: for this reason, we
have to compute two simultaneous indices for Ed25519 rings: one for
the earlier date that is potentially valid, and one for the later
date that is potentially valid. We call these `hsv3-early` and
`hsv3-late`.)

Beyond the use of these indices, however, there are other steps that
clients and services need to take in order to maintain their privacy.

&lt;!-- Section 7.1 --&gt; &lt;a id='S7.1'&gt;&lt;/a&gt;

## Finding HSDirs

When a client or service wants to contact an HSDir, it SHOULD do so
anonymously, by building a three-hop anonymous circuit, and then
extending it a further hop using the snip_span link specifier to
upload to any of the first 3 replicas on the ring.  Clients SHOULD
choose an 'nth' at random; services SHOULD upload to each replica.

Using a full 80-bit or 256-bit index position in the link specifier
would leak the chosen service to somebody other than the directory.
Instead, the client or service SHOULD truncate the identifier to a
number of bytes equal to the network parameter `hsv2-index-bytes` or
`hsv3-index-bytes` respectively.  (See Appendix C.)

&lt;!-- Section 7.2 --&gt; &lt;a id='S7.2'&gt;&lt;/a&gt;

## SNIPs for introduction points

When services select an introduction point, they should include the
SNIP for the introduction point in their hidden service directory
entry, along with the introduction-point fields.  The format for
this entry is:

    "snip" NL snip NL
      [at most once per introduction points]

Clients SHOULD begin treating the link specifier and onion-key
fields of each introduction point as optional when the "snip" field
is present, and when the `hsv3-tolerate-no-legacy` network parameter
is set to 1. If either of these fields _is_ present, and the SNIP is
too, then these fields MUST match those listed in the SNIPs.
Clients SHOULD reject descriptors with mismatched fields, and alert
the user that the service may be trying a partitioning attack.
The "legacy-key" and "legacy-key-cert" fields, if present, should be
checked similarly.

&gt; Using the SNIPs in these ways allows services to prove that their
&gt; introduction points have actually been listed in the consensus
&gt; recently.  It also lets clients use introduction point features
&gt; that the relay might not understand.

Services should include these fields based on a set of network
parameters: `hsv3-intro-snip` and `hsv3-intro-legacy-fields`.
(See appendix C.)

Clients should use these fields only when Walking Onions support is
enabled; see section 09.

&lt;!-- Section 7.3 --&gt; &lt;a id='S7.3'&gt;&lt;/a&gt;

## SNIPs for rendezvous points

When a client chooses a rendezvous point for a v3 onion service, it
similarly has the opportunity to include the SNIP of its rendezvous
point in the encrypted part of its INTRODUCE cell.  (This may cause
INTRODUCE cells to become fragmented; see proposal about fragmenting
relay cells.)

&gt; Using the SNIPs in these ways allows services to prove that their
&gt; introduction points have actually been listed in the consensus
&gt; recently.  It also lets services use introduction point features
&gt; that the relay might not understand.

To include the SNIP, the client places it in an extension in the
INTRODUCE cell.  The onion key can now be omitted[*], along with
the link specifiers.

&gt; [*] Technically, we use a zero-length onion key, with a new type
&gt; "implicit in SNIP".

To know whether the service can recognize this kind of cell, the
client should look for the presence of a "snips-allowed 1" field in
the encrypted part of the hidden service descriptor.

In order to prevent partitioning, services SHOULD NOT advertise
"snips-allowed 1" unless the network parameter
"hsv3-rend-service-snip" is set to 1.  Clients SHOULD NOT use this
field unless "hsv3-rend-client-snip" is set to 1.

&lt;!-- Section 7.4 --&gt; &lt;a id='S7.4'&gt;&lt;/a&gt;

## TAP keys and where to find them

If v2 hidden services are still supported when Walking Onions arrives
on the network, we have two choices:  We could migrate them to use
ntor keys instead of TAP, or we could provide a way for TAP keys to
be advertised with Walking Onions.

The first option would appear to be far simpler. See
proposal draft 320-tap-out-again.md.

The latter option would require us to put RSA-1024 keys in SNIPs, or
put a digest of them in SNIPs and give some way to retrieve them
independently.

(Of course, it's possible that we will have v2 onion services
deprecated by the time Walking Onions is implemented.  If so, that
will simplify matters a great deal too.)


&lt;!-- Section 8 --&gt; &lt;a id='S8'&gt;&lt;/a&gt;

# Tracking Relay honesty

Our design introduces an opportunity for dishonest relay behavior:
since multiple ENDIVEs are valid at the same time, a malicious relay
might choose any of several possible SNIPs in response to a client's
routing index value.

Here we discuss several ways to mitigate this kind of attack.

&lt;!-- Section 8.1 --&gt; &lt;a id='S8.1'&gt;&lt;/a&gt;

## Defense: index stability

First, the voting process should be designed such that relays do not
needlessly move around the routing index.  For example, it would
_not_ be appropriate to add an index type whose value is computed by
first putting the relays into a pseudorandom order.  Instead, index
voting should be deterministic and tend to give similar outputs for
similar inputs.

This proposal tries to achieve this property in its index voting
algorithms.  We should measure the degree to which we succeed over
time, by looking at all of the ENDIVEs that are valid at any
particular time, and sampling several points for each index to see
how many distinct relays are listed at each point, across all valid
ENDIVEs.

We do not need this stability property for routing indices whose
purpose is nonrandomized relay selection, such as those indices used
for onion service directories.

&lt;!-- Section 8.2 --&gt; &lt;a id='S8.2'&gt;&lt;/a&gt;

## Defense: enforced monotonicity

Once an honest relay has received an ENDIVE, it has no reason to
keep any previous ENDIVEs or serve SNIPs from them.  Because of
this, relay implementations SHOULD ensure that no data is served
from a new ENDIVE until all the data from an old ENDIVE is
thoroughly discarded.

Clients and relays can use this monotonicity property to keep relays
honest: once a relay has served a SNIP with some timestamp `T`, that
relay should never serve any other SNIP with a timestamp earlier than
`T`.  Clients SHOULD track the most recent SNIP timestamp that they
have received from each of their guards, and MAY track the most
recent SNIP timestamps that they have received from other relays as
well.

&lt;!-- Section 8.3 --&gt; &lt;a id='S8.3'&gt;&lt;/a&gt;

## Defense: limiting ENDIVE variance within the network.

The primary motivation for allowing long (de facto) lifespans on
today's consensus documents is to keep the network from grinding to
a halt if the authorities fail to reach consensus for a few hours.
But in practice, _if_ there is a consensus, then relays should have
it within an hour or two, so they should not be falling a full day out
of date.

Therefore we can potentially add a client behavior that, within N
minutes after the client has seen any SNIP with timestamp `T`,
the client should not accept any SNIP with timestamp earlier than
`T - Delta`.

Values for N and Delta are controlled by network parameters
(`enforce-endive-dl-delay-after` and `allow-endive-dl-delay`
respectively in appendix C).  N should be about as long as we expect
it to take for a single ENDIVE to propagate to all the relays on the
network; Delta should be about as long as we would like relays to go
between updating ENDIVEs under ideal circumstances.

&lt;!-- Section 9 --&gt; &lt;a id='S9'&gt;&lt;/a&gt;

# Migrating to Walking Onions

This proposal is a major change in the Tor network that will
eventually require the participation of all relays [*], and will make
clients who support it distinguishable from clients that don't.

&gt; [*] Technically, the last relay in the path doesn't need support.

To keep the compatibility issues under control, here is the order in which it
should be deployed on the network.

1. First, authorities should add support for voting on ENDIVEs.

2. Relays may immediately begin trying to download and reconstruct
   ENDIVEs. (Relay versions are public, so they leak nothing by
   doing this.)

3. Once a sufficient number of authorities are voting on ENDIVEs and
   unlikely to downgrade, relays should begin serving parameter documents
   and responding to walking-onion EXTEND and CREATE cells.  (Again,
   relay versions are public, so this doesn't leak.)

4. In parallel with relay support, Tor should also add client
   support for Walking Onions.  This should be disabled by default,
   however, since it will only be usable with the subset of relays
   that support Walking Onions, and since it would make clients
   distinguishable.

5. Once enough of the relays (possibly, all) support Walking Onions,
   the client support can be turned on.  They will not be able to
   use old relays that do not support Walking Onions.

6. Eventually, relays that do not support Walking Onions should not
   be listed in the consensus.

Client support for Walking Onions should be enabled or disabled, at
first, with a configuration option.  Once it seems stable, the
option should have an "auto" setting that looks at a network
parameter. This parameter should NOT be a simple "on" or "off",
however: it should be the minimum client version whose support for
Walking Onions is believed to be correct.

&lt;!-- Section 9.1 --&gt; &lt;a id='S9.1'&gt;&lt;/a&gt;

## Future work: migrating away from sedentary onions

Once all clients are using Walking Onions, we can take a pass
through the Tor specifications and source code to remove
no-longer-needed code.

Clients should be the first to lose support for old directories,
since nobody but the clients depends on the clients having them.
Only after obsolete clients represent a very small fraction of the
network should relay or authority support be disabled.

Some fields in router descriptors become obsolete with Walking
Onions, and possibly router descriptors themselves should be
replaced with cbor objects of some kind.  This can only happen,
however, after no descriptor users remain.

&lt;!-- Section A --&gt; &lt;a id='SA'&gt;&lt;/a&gt;

# Appendices

&lt;!-- Section A.1 --&gt; &lt;a id='SA.1'&gt;&lt;/a&gt;

## Appendix A: Glossary

I'm going to put a glossary here so I can try to use these terms
consistently.

*SNIP* -- A "Separable Network Index Proof".  Each SNIP contains the
information necessary to use a single Tor relay, and associates the relay
with one or more index ranges. SNIPs are authenticated by the directory
authorities.

*ENDIVE* -- An "Efficient Network Directory with Individually Verifiable
Entries".  An ENDIVE is a collection of SNIPS downloaded by relays,
authenticated by the directory authorities.

*Routing index* -- A routing index is a map from binary strings to relays,
with some given property.  Each relay that is in the routing index is
associated with a single *index range*.

*Index range* -- A range of positions withing a routing index.  Each range
 contains many positions.

*Index position* -- A single value within a routing index.  Every position in
 a routing index corresponds to a single relay.

*ParamDoc* -- A network parameters document, describing settings for the
 whole network.  Clients download this infrequently.

*Index group* -- A collection of routing indices that are encoded in the same
 SNIPs.

&lt;!-- Section A.2 --&gt; &lt;a id='SA.2'&gt;&lt;/a&gt;

## Appendix B: More cddl definions

    ; These definitions are used throughout the rest of the
    ; proposal

    ; Ed25519 keys are 32 bytes, and that isn't changing.
    Ed25519PublicKey = bstr .size 32

    ; Curve25519 keys are 32 bytes, and that isn't changing.
    Curve25519PublicKey = bstr .size 32

    ; 20 bytes or fewer: legacy RSA SHA1 identity fingerprint.
    RSAIdentityFingerprint = bstr

    ; A 4-byte integer -- or to be cddl-pedantic, one that is
    ; between 0 and UINT32_MAX.
    uint32 = uint .size 4

    ; Enumeration to define integer equivalents for all the digest algorithms
    ; that Tor uses anywhere.  Note that some of these are not used in
    ; this spec, but are included so that we can use this production
    ; whenever we need to refer to a hash function.
    DigestAlgorithm = &amp;(
        NoDigest: 0,
        SHA1    : 1,     ; deprecated.
        SHA2-256: 2,
        SHA2-512: 3,
        SHA3-256: 4,
        SHA3-512: 5,
        Kangaroo12-256: 6,
        Kangaroo12-512: 7,
    )

    ; A digest is represented as a binary blob.
    Digest = bstr

    ; Enumeration for different signing algorithms.
    SigningAlgorithm = &amp;(
       RSA-OAEP-SHA1  : 1,     ; deprecated.
       RSA-OAEP-SHA256: 2,     ; deprecated.
       Ed25519        : 3,
       Ed448          : 4,
       BLS            : 5,     ; Not yet standardized.
    )

    PKAlgorithm = &amp;(
       SigningAlgorithm,

       Curve25519: 100,
       Curve448  : 101
    )

    KeyUsage = &amp;(
       ; A master unchangeable identity key for this authority.  May be
       ; any signing key type.  Distinct from the authority's identity as a
       ; relay.
       AuthorityIdentity: 0x10,
       ; A medium-term key used for signing SNIPs, votes, and ENDIVEs.
       SNIPSigning: 0x11,

       ; These are designed not to collide with the "list of certificate
       ; types" or "list of key types" in cert-spec.txt
    )

    CertType = &amp;(
       VotingCert: 0x12,
       ; These are designed not to collide with the "list of certificate
       ; types" in cert-spec.txt.
    )

    LinkSpecifier = bstr

&lt;!-- Section A.3 --&gt; &lt;a id='SA.3'&gt;&lt;/a&gt;

## Appendix C: new numbers to assign.

Relay commands:

* We need a new relay command for "FRAGMENT" per proposal 319.

CREATE handshake types:

* We need a type for the NIL handshake.

* We need a handshake type for the new ntor handshake variant.

Link specifiers:

* We need a link specifier for extend-by-index.

* We need a link specifier for dirport URL.

Certificate Types and Key Types:

* We need to add the new entries from CertType and KeyUsage to
  cert-spec.txt, and possibly merge the two lists.

Begin cells:

* We need a flag for Delegated Verifiable Selection.

* We need an extension type for extra data, and a value for indices.

End cells:

* We need an extension type for extra data, a value for indices, a
  value for IPv4 addresses, and a value for IPv6 addresses.

Extensions for decrypted INTRODUCE2 cells:

* A SNIP for the rendezvous point.

Onion key types for decrypted INTRODUCE2 cells:

* An "onion key" to indicate that the onion key for the rendezvous point is
  implicit in the SNIP.

New URLs:

* A URL for fetching ENDIVEs.

* A URL for fetching client / relay parameter documents

* A URL for fetching detached SNIP signatures.

Protocol versions:

(In theory we could omit many new protovers here, since being listed
in an ENDIVE implies support for the new protocol variants.  We're
going to use new protovers anyway, however, since doing so keeps our
numbering consistent.)

We need new versions for these subprotocols:

* _Relay_ to denote support for new handshake elements.

* _DirCache_ to denote support for ENDIVEs, paramdocs, binary diffs, etc.

* _Cons_ to denote support for ENDIVEs


&lt;!-- Section A.4 --&gt; &lt;a id='SA.4'&gt;&lt;/a&gt;

## Appendix D: New network parameters.

We introduce these network parameters:

From section 5:

* `create-pad-len` -- Clients SHOULD pad their CREATE cell bodies
  to this size.

* `created-pad-len` -- Relays SHOULD pad their CREATED cell bodies to this
  size.

* `extend-pad-len` -- Clients SHOULD pad their EXTEND cell bodies to this
  size.

* `extended-pad-len` -- Relays SHOULD pad their EXTENDED cell bodies to this
size.

From section 7:

* `hsv2-index-bytes` -- how many bytes to use when sending an hsv2 index
  position to look up a hidden service directory.  Min: 1,
  Max: 40. Default: 4.

* `hsv3-index-bytes` -- how many bytes to use when sending an hsv3 index
  position to look up a hidden service directory.  Min: 1,
  Max: 128. Default: 4.

* `hsv3-intro-legacy-fields` -- include legacy fields in service descriptors.
  Min: 0. Max: 1. Default: 1.

* `hsv3-intro-snip` -- include intro point SNIPs in service descriptors.
  Min: 0. Max: 1. Default: 0.

* `hsv3-rend-service-snip` -- Should services advertise and accept rendezvous
  point SNIPs in INTRODUCE2 cells?    Min: 0. Max: 1. Default: 0.

* `hsv3-rend-client-snip` -- Should clients place rendezvous point SNIPS in
  INTRODUCE2 cells when the service supports it?
  Min: 0. Max: 1. Default: 0.

* `hsv3-tolerate-no-legacy` -- Should clients tolerate v3 service descriptors
  that don't have legacy fields? Min: 0. Max: 1. Default: 0.

From section 8:

* `enforce-endive-dl-delay-after` -- How many seconds after receiving a
  SNIP with some timestamp T does a client wait for rejecting older SNIPs?
  Equivalent to "N" in "limiting ENDIVE variance within the network."
  Min: 0. Max: INT32_MAX. Default: 3600 (1 hour).

* `allow-endive-dl-delay` -- Once a client has received an SNIP with
  timestamp T, it will not accept any SNIP with timestamp earlier than
  "allow-endive-dl-delay" seconds before T.
  Equivalent to "Delta" in "limiting ENDIVE variance within the network."
  Min: 0. Max: 2592000 (30 days). Default: 10800 (3 hours).

&lt;!-- Section A.5 --&gt; &lt;a id='SA.5'&gt;&lt;/a&gt;

## Appendix E: Semantic sorting for CBOR values.

Some voting operations assume a partial ordering on CBOR values.  We define
such an ordering as follows:

  * bstr and tstr items are sorted lexicographically, as if they were
    compared with a version of strcmp() that accepts internal NULs.
  * uint and int items are are sorted by integer values.
  * arrays are sorted lexicographically by elements.
  * Tagged items are sorted as if they were not tagged.
  * Maps do not have any sorting order.
  * False precedes true.
  * Otherwise, the ordering between two items is not defined.

More specifically:

     Algorithm: compare two cbor items A and B.

     Returns LT, EQ, GT, or NIL.

     While A is tagged, remove the tag from A.
     While B is tagged, remove the tag from B.

     If A is any integer type, and B is any integer type:
          return A cmp B

     If the type of A is not the same as the type of B:
          return NIL.

     If A and B are both booleans:
          return int(A) cmp int(B), where int(false)=0 and int(B)=1.

     If A and B are both tstr or both bstr:
          while len(A)&gt;0 and len(B)&gt;0:
             if A[0] != B[0]:
                  return A[0] cmp B[0]
             Discard A[0] and B[0]
          If len(A) == len(B) == 0:
             return EQ.
          else if len(A) == 0:
             return LT.  (B is longer)
          else:
             return GT.  (A is longer)

     If A and B are both arrays:
          while len(A)&gt;0 and len(B)&gt;0:
             Run this algorithm recursively on A[0] and B[0].
             If the result is not EQ:
                 Return that result.
             Discard A[0] and B[0]
          If len(A) == len(B) == 0:
             return EQ.
          else if len(A) == 0:
             return LT.  (B is longer)
          else:
             return GT.  (A is longer)

    Otherwise, A and B are a type for which we do not define an ordering,
    so return NIL.

&lt;!-- Section A.6 --&gt; &lt;a id='SA.6'&gt;&lt;/a&gt;

## Appendix F: Example voting rules

Here we give a set of voting rules for the fields described in our initial
VoteDocuments.

    {
      meta: {
         voting-delay: { op: "Mode", tie_low:false,
                           type:["tuple","uint","uint"] },
         voting-interval: { op: "Median", type:"uint" },
         snip-lifespan: {op: "Mode", type:["tuple","uint","uint","uint"] },
         c-param-lifetime: {op: "Mode", type:["tuple","uint","uint","uint"] },
         s-param-lifetime: {op: "Mode", type:["tuple","uint","uint","uint"] },
         cur-shared-rand: {op: "Mode", min_count: "qfield",
                             type:["tuple","uint","bstr"]},
         prev-shared-rand: {op: "Mode", min_count: "qfield",
                             type:["tuple","uint","bstr"]},
      client-params: {
         recommend-versions: {op:"SetJoin", min_count:"qfield",type:"tstr"},
         require-protos: {op:"BitThreshold", min_count:"sqauth"},
         recommend-protos: {op:"BitThreshold", min_count:"qauth"},
         params: {op:"MapJoin",key_min_count:"qauth",
                     keytype:"tstr",
                     item_op:{op:"Median",min_vote:"qauth",type:"uint"},
                     },
         certs: {op:"SetJoin",min_count:1, type: 'bstr'},
      },
      ; Use same value for server-params.
      relay: {
         meta: {
            desc: {op:"Mode", min_count:"qauth",tie_low:false,
                   type:["uint","bstr"] },
            flags: {op:"MapJoin", key_type:"tstr",
                    item_op:{op:"Mode",type:"bool"}},
            bw: {op:"Median", type:"uint" },
            mbw :{op:"Median", type:"uint" },
            rsa-id: {op:"Mode", type:"bstr"},
        },
        snip: {
           ; ed25519 key is handled as any other value.
           0: { op:"DerivedFrom", fields:[["RM","desc"]],
                 rule:{op:"Mode",type="bstr"} },

           ; ntor onion key.
           1: { op:"DerivedFrom", fields:[["RM","desc"]],
                 rule:{op:"Mode",type="bstr"} },

           ; link specifiers.
           2: { op: "CborDerived",
                 item-op: { op:"DerivedFrom", fields:[["RM","desc"]],
                            rule:{op:"Mode",type="bstr" } } },

           ; software description.
           3: { op:"DerivedFrom", fields:[["RM","desc"]],
                 rule:{op:"Mode",type=["tuple", "tstr", "tstr"] } },

           ; protovers.
           4: { op: "CborDerived",
                 item-op: { op:"DerivedFrom", fields:[["RM","desc"]],
                          rule:{op:"Mode",type="bstr" } } },

           ; families.
           5: { op:"SetJoin", min_count:"qfield", type:"bstr" },

           ; countrycode
           6: { op:"Mode", type="tstr" } ,

           ; 7: exitpolicy.
           7: { op: "CborDerived",
                 item-op: { op: "DerivedFrom",
fields:[["RM","desc"],["CP","port-classes"]],
                          rule:{op:"Mode",type="bstr" } } },
        },
        legacy: {
          "sha1-desc": { op:"DerivedFrom",
                          fields:[["RM","desc"]],
                          rule:{op:"Mode",type="bstr"} },
          "mds": { op:"DerivedFrom",
                    fields:[["RM":"desc"]],
                    rule: { op:"ThresholdOp", min_count: "qauth",
                             multi_low:false,
                             type:["tuple", "uint", "uint",
                                   "bstr", "bstr" ] }},
        }
      }
      indices: {
         ; See appendix G.
      }
    }

&lt;!-- Section A.7 --&gt; &lt;a id='SA.7'&gt;&lt;/a&gt;

## Appendix G: A list of routing indices

Middle -- general purpose index for use when picking middle hops in
circuits.  Bandwidth-weighted for use as middle relays.  May exclude
guards and/or exits depending on overall balance of resources on the
network.

Formula:
      type: 'weighted',
      source: {
          type:'bw', require_flags: ['Valid'], 'bwfield' : ["RM", "mbw"]
      },
      weight: {
          [ "!Exit", "!Guard" ] =&gt; "Wmm",
          [ "Exit", "Guard" ] =&gt; "Wbm",
          [ "Exit", "!Guard" ] =&gt; "Wem",
          [ "!Exit", "Guard" ] =&gt; "Wgm",
      }

Guard -- index for choosing guard relays. This index is not used
directly when extending, but instead only for _picking_ guard relays
that the client will later connect to directly.  Bandwidth-weighted
for use as guard relays. May exclude guard+exit relays depending on
resource balance.

      type: 'weighted',
      source: {
           type:'bw',
           require_flags: ['Valid', "Guard"],
           bwfield : ["RM", "mbw"]
      },
      weight: {
          [ "Exit", ] =&gt; "Weg",
      }

HSDirV2 -- index for finding spots on the hsv2 directory ring.

Formula:
      type: 'rsa-id',

HSDirV3-early -- index for finding spots on the hsv3 directory ring
for the earlier of the two "active" days. (The active days are
today, and whichever other day is closest to the time at which the
ENDIVE becomes active.)

Formula:
      type: 'ed-id'
      alg: SHA3-256,
      prefix: b"node-idx",
      suffix: (depends on shared-random and time period)

HSDirV3-late -- index for finding spots on the hsv3 directory ring
for the later of the two "active" days.

Formula: as HSDirV3-early, but with a different suffix.

Self -- A virtual index that never appears in an ENDIVE.  SNIPs with
this index are unsigned, and occupy the entire index range.  This
index is used with bridges to represent each bridge's uniqueness.

Formula: none.

Exit0..ExitNNN -- Exits that can connect to all ports within a given
PortClass 0 through NNN.

Formula:

      type: 'weighted',
      source: {
           type:'bw',
           ; The second flag here depends on which portclass this is.
           require_flags: [ 'Valid', "P@3" ],
           bwfield : ["RM", "mbw"]
       },
      weight: {
          [ "Guard", ] =&gt; "Wge",
      }

&lt;!-- Section A.8 --&gt; &lt;a id='SA.8'&gt;&lt;/a&gt;

## Appendix H: Choosing good clusters of exit policies

With Walking Onions, we cannot easily support all the port
combinations [*] that we currently allow in the "policy summaries"
that we support in microdescriptors.

&gt; [*] How many "short policy summaries" are there? The number would be
&gt; 2^65535, except for the fact today's Tor doesn't permit exit policies to
&gt; get maximally long.

In the Walking Onions whitepaper
(https://crysp.uwaterloo.ca/software/walkingonions/) we noted in
section 6 that we can group exit policies by class, and get down to
around 220 "classes" of port, such that each class was either
completely supported or completely unsupported by every relay.  But
that number is still impractically large: if we need ~11 bytes to
represent a SNIP index range, we would need an extra 2320 bytes per
SNIP, which seems like more overhead than we really want.

We can reduce the number of port classes further, at the cost of
some fidelity.  For example, suppose that the set {https,http} is
supported by relays {A,B,C,D}, and that the set {ssh,irc} is
supported by relays {B,C,D,E}.  We could combine them into a new
port class {https,http,ssh,irc}, supported by relays {B,C,D} -- at
the expense of no longer being able to say that relay A supported
{https,http}, or that relay E supported {ssh,irc}.

This loss would not necessarily be permanent: the operator of relay
A might be willing to add support for {ssh,irc}, and the operator of
relay E might be willing to add support for {https,http}, in order
to become useful as an exit again.

(We might also choose to add a configuration option for relays to
take their exit policies directly from the port classes in the
consensus.)

How might we select our port classes?  Three general categories of
approach seem possible: top-down, bottom-up, and hybrid.

In a top-down approach, we would collaborate with authority and exit
operators to identify _a priori_ reasonable classes of ports, such
as "Web", "Chat", "Miscellaneous internet", "SMTP", and "Everything
else".  Authorities would then base exit indices on these classes.

In a bottom-up approach, we would find an algorithm to run on the
current exit policies in order to find the "best" set of port
classes to capture the policies as they stand with minimal loss.
(Quantifying this loss is nontrivial: do we weight by bandwidth? Do
we weight every port equally, or do we call some more "important"
than others?)

&gt; See exit-analysis for an example tool that runs a greedy algorithm
&gt; to find a "good" partition using an unweighted,
&gt; all-ports-are-equal cost function.  See the files
&gt; "greedy-set-cov-{4,8,16}" for examples of port classes produced
&gt; by this algorithm.

In a hybrid approach, we'd use top-down and bottom-up techniques
together. For example, we could start with an automated bottom-up
approach, and then evaluate it based feedback from operators.  Or we
could start with a handcrafted top-down approach, and then use
bottom-up cost metrics to look for ways to split or combine those
port classes in order to represent existing policies with better
fidelity.


&lt;!-- Section A.9 --&gt; &lt;a id='SA.9'&gt;&lt;/a&gt;

## Appendix I: Non-clique topologies with Walking Onions

For future work, we can expand the Walking Onions design to
accommodate network topologies where relays are divided into groups,
and not every group connects to every other.  To do so requires
additional design work, but here I'll provide what I hope will be a
workable sketch.

First, each SNIP needs to contain an ID saying which relay group it
belongs to, and an ID saying which relay group(s) may serve it.

When downloading an ENDIVE, each relay should report its own
identity, and receive an ENDIVE for that identity's group.  It
should contain both the identities of relays in the group, and the
SNIPs that should be served for different indices by members of that
group.

The easy part would be to add an optional group identity field to
SNIPs, defaulting to 0, indicating that the relay belongs to that
group, and an optional served-by field to each SNIP, indicating
groups that may serve the SNIP.  You'd only accept SNIPs if they
were served by a relay in a group that was allowed to serve them.

Would guards work?  Sure: we'd need to have guard SNIPS served by
middle relays.

For hsdirs, we'd need to have either multiple shards of the hsdir
ring (which seems like a bad idea?) or have all middle nodes able to
reach the hsdir ring.

Things would get tricky with making onion services work: if you need
to use an introduction point or a rendezvous point in group X, then
you need to get there from a relay that allows connections to group
X.  Does this imply indices meaning "Can reach group X" or
"two-degrees of group X"?

The question becomes: "how much work on alternative topologies does
it make sense to deploy in advance?"  It seems like there are
unknowns affecting both client and relay operations here, which
suggests that advance deployment for either case is premature: we
can't necessarily make either clients or relays "do the right thing"
in advance given what we now know of the right thing.

&lt;!-- Section A.10 --&gt; &lt;a id='SA.10'&gt;&lt;/a&gt;

## Appendix Z: acknowledgments

Thanks to Peter Palfrader for his original design in proposal 141,
and to the designers of PIR-Tor, both of which inspired aspects of
this Walking Onions design.

Thanks to Chelsea Komlo, Sajin Sasy, and Ian Goldberg for feedback on
an earlier version of this design.

Thanks to David Goulet, Teor, and George Kadianakis for commentary on
earlier versions of proposal 300.

Thanks to Chelsea Komlo and Ian Goldberg for their help fleshing out
so many ideas related to Walking Onions in their work on the design
paper.

Thanks to Teor for improvements to diff format, ideas about grouping
exit ports, and numerous ideas about getting topology and
distribution right.

These specifications were supported by a grant from the Zcash
Foundation.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200707211356</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-07-07 21:13:56-0400</timestampReceived><subject>[tor-dev] Gitlab CI runners available for experimentation on gitlab.torproject.org</subject><body>

Hello folks!

Hans from The Guardian Project added his CI runners to our Gitlab
instance. It looks like some pretty fast machines that allows each team
to experiment with Gitlab CI on our Gitlab instance.

Hans says that the runners have no uptime promises or anything like
that, so if they are down they are down :-)

Here's some documentation for getting started:
https://docs.gitlab.com/ee/ci/

Thanks to Hans for this!

All the best,
Alex.

-- =

Alexander F=E6r=F8y
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200603213419</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-06-03 21:34:19-0400</timestampReceived><subject>Re: [tor-dev] onionbalance useful on same server / for high-spec non-location hidden servers?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Patrick Schleizer wrote:
&gt; Would it be useful to run multiple Tor instances and onionbalance on the
&gt; very same server? Or does that totally defeat the purpose of onionbalance?
&gt; 
&gt; In my case, it's not a location hidden service. Just an alternative way
&gt; to connect to a server which is available over clearnet anyhow.
&gt; 
&gt; I guess the presumption of onionbalance is that a location hidden server
&gt; shouldn't produce too much Tor traffic as that would be suspicious?
&gt; 
&gt; Is a single Tor client a bottleneck? I.e. are multiple Tor clients more
&gt; performant than only one Tor client? Does onionbalance "only" work
&gt; around limitations of individual servers in CPU / IO / bandwidth?
&gt; 
&gt; In other words, assume CPU / IO / bandwidth is "unlimited" on one
&gt; server. (And ignore failover.) Does it make sense to run multiple Tor
&gt; instances and onionbalance or would a single Tor instance without
&gt; onionbalance be sufficient?
&gt; 
&gt; Cheers,
&gt; Patrick

Hi Patrick,

If we don't think about the anonymity penalties (being exposed to more
Guards, more Tor traffic being observable on the network, etc.), the
biggest advantage you get by doing this is CPU related.

Because Tor is not multi-threaded, at least in my use cases, the
bottleneck was always the CPU (one core of the CPU actually better
said). If you have a single core with much Ghz, Tor will do better and
better, but this is rarely the case, most of us have less GHz spread on
more CPU cores. Because my bandwidth was always high speed, I always hit
the CPU bottleneck before saturating the bandwidth on any server.

If you run multiple Tor processes on a server, you spread the load on
multiple CPU cores, thus pushing this CPU bottleneck to higher limit. If
bandwidth is "unlimited", this should be a win.

I think this also increases the chances to also lift the next bandwidth
bottleneck, since you won't be capped at the Guard speed of one Tor
process (maybe that particular Guard is more busy or has lower speed, etc.).

Onionbalance is a must if you want all the Tor processes to respond to
the same .onion 'front' address. If you don't care to have different /
multiple hostnames, you don't need onionbalance.

Also, if anonymity is not a problem, and you know you raised your CPU
bottleneck by running multiple Tor processes, you can tune all of them
to saturate the CPU power by raising MaxClientCircuitsPending slightly
and set NumEntryGuards to a higher value like 4 or 6 and also
NumPrimaryGuards to 10x$NumEntryGuards in all the torrc's of the
processes you will run. This lifts the next bottleneck you face after
CPU: bandwidth.

However, the best way (and also most friendly for the network), if you
run a high traffic .onion where location anonymity is not a problem, is
to run a bridge Tor process that listens on localhost and uses
PublishServerDescriptor 0 in torrc, so it's not public and it's only
used by you. Then you set your Tor onion service instance to use that
bridge only. You are gonna need a bridge instance for each onion service
instance because of the CPU bottleneck will move from the onion service
instances to the bridge instance.



["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200710175200</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-07-10 17:52:00-0400</timestampReceived><subject>[tor-dev] Proposal 325: Packed relay cells: saving space on small commands</subject><body>

```
Filename: 325-packed-relay-cells.md
Title: Packed relay cells: saving space on small commands
Author: Nick Mathewson
Created: 10 July 2020
Status: Draft
```

# Introduction

In proposal 319 I suggested a way to fragment long commands across
multiple RELAY cells.  In this proposal, I suggest a new format for
RELAY cells that can be used to pack multiple relay commands into a
single cell.

Why would we want to do this?  As we move towards improved
congestion-control and flow-control algorithms, we might not want to
use an entire 498-byte relay payload just to send a one-byte
flow-control message.

We already have some cases where we'd benefit from this feature.
For example, when we send SENDME messages, END cells, or BEGIN_DIR
cells, most of the cell body is wasted with padding.

As a side benefit, packing cells in this way may make the job of the
traffic analyst a little more tricky, as cell contents become less
predictable.

# The basic design

Let's use the term "Relay Message" to mean the kind of thing that a
relay cell used to hold.  Thus, this proposal is about packing
multiple "Relay Messages" in to a cell.

I'll use "Packed relay cell" to mean a relay cell in this new
format, that supports multiple messages.

I'll use "client" to mean the initiator of a circuit, and "relay" to
refer to the parties through who a circuit is created.  Note that
each "relay" (as used here) may be the "client" on circuits of its own.

When a relay supports relay message packing, it advertises the fact
using a new Relay protocol version.  Clients must opt-in to using
this protocol version (see XXX below) before they can send any
packed relay cells, and before the relay will send them any packed
relay cells.

When packed cells are in use, multiple cell messages can be
concatenated in a single relay cell.

Only some relay commands are supported for relay cell packing,
listed here:
      - SENDME
      - DROP
      - DATA
      - BEGIN
      - BEGIN_DIR
      - END
      - CONNECTED
      - PADDING_NEGOTIATE
      - PADDING_NEGOTIATED

If any relay message with a relay command _not_ listed above appears
in a packed relay cell with another relay message, then the
receiving party MUST tear down the circuit.

(Note that relay cell fragments (proposal 319) are not supported for
packing.)

The command byte "0" is now used to explicitly indicate "end of
cell".  If the byte "0" appears after a relay message, the rest of
the cell MUST be ignored.

When generating RELAY cells, implementations SHOULD (as they do
today) fill in the unused bytes with four 0-valued bytes, followed by
a sequence of random bytes up to the end of the cell.  If there are
fewer than 4 unused bytes at the end of the cell, those unused bytes
should all be filled with 0-valued bytes.

# Negotiation and migration

After receiving a packed relay cell, the relay know that the client
supports this proposal: Relays SHOULD send packed relay
cells on any circuit on which they have received a packed relay
cell.  Relays MUST NOT send packed relay cells otherwise.

Clients, in turn, MAY send packed relay cells to any relay whose
"Relay" subprotocol version indicates that it supports this
protocol.  To avoid fingerprinting, this client behavior should
controlled with a tristate (1/0/auto) torrc configuration value,
with the default set to use a consensus parameter.

The parameter is:

    "relay-cell-packing"

    Boolean: if 1, clients should send packed relay cells.
    (Min: 0, Max 1, Default: 0)

To handle migration, first the parameter should be set to 0 and the
configuration setting should be "auto".  To test the feature, individual
clients can set the tristate to "1".

Once enough clients have support for the parameter, the parameter
can be set to 1.


# A new relay message format

(This section is optional and should be considered separately; we
may decide it is too complex.)

Currently, every relay message uses 5 bytes of header to hold a
relay command, a length field, and a stream ID.  This is wasteful:
the stream ID is often redundant, and the top 7 bits of the length
field are always zero.

I propose a new relay message format, described here (with `ux`
denoting an x-bit bitfield).  This format is 2 bytes or 4 bytes,
depending on its first bit.

    struct relay_header {
       u1 stream_id_included; // Is the stream_id included?
       u6 relay_command; // as before
       u9 relay_data_len; // as before
       u8 optional_stream_id[]; // 0 bytes or two bytes.
    }

Alternatively, you can view the first three fields as a 16-bit
value, computed as:

    (stream_id_included&lt;&lt;15) | (relay_command &lt;&lt; 9) | (relay_data_len).

If the optional_stream_id field is not present, then the default
value for the stream_id is computed as follows.  We use stream_id 0
for any command that doesn't take a stream ID.  For commands that
_do_ take a steam_id, we use whichever nonzero stream_id appeared
last in this cell.

This format limits the space of possible relay commands.  That's
probably okay: after 20 years of Tor development, we have defined 25
relay command values.  But in case 2^6==64 commands will not be
enough, we reserve command values 48 through 63 for future formats
that need more command bits.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200717135608</emailId><senderName>Andrew Clausen</senderName><senderEmail>andrew.p.clausen@gmail.com</senderEmail><timestampReceived>2020-07-17 13:56:08-0400</timestampReceived><subject>[tor-dev] Distributing Tor developer keys via Fedora packages</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

I propose distributing the Tor developer keys inside the Fedora package
distribution-gpg-keys.[1]  This would give most Linux users a trustworthy
chain of signatures from their own distributor (e.g. CentOS or Fedora) to
Tor project downloads.

I am happy to take care of this, although I am also happy if somebody who
is more involved with Tor than me takes this on.  I wrote a shell script
(attached) to acquire and organise the keys based on
https://2019.www.torproject.org/include/keys.txt.  My script would install
the following keys under /usr/share/distribution-gpg-keys/tor:

Arm_releases/Damian_Johnson.gpg
Tails_live_system_releases/The_Tails_team.gpg
TorBirdy_releases/Sukhbir_Singh.gpg
Tor_Browser_releases/Arthur_Edelstein.gpg
Tor_Browser_releases/Georg_Koppen.gpg
Tor_Browser_releases/Mike_Perry.gpg
Tor_Browser_releases/Nicolas_Vigier.gpg
Tor_Browser_releases/The_Tor_Browser_Developers.gpg
Tor_source_tarballs/Nick_Mathewson.gpg
Tor_source_tarballs/Roger_Dingledine.gpg
Torsocks_releases/David_Goulet.gpg
deb.torproject.org_repositories_and_archives/Tor_Project_Archive.gpg
older_Tor_tarballs/Nick_Mathewson.gpg
other/Peter_Palfrader.gpg

Unless someone else volunteers (please do!), I will set up a weekly job to
run the script and alert me to any changes.

Can anyone see any potential problems with this plan?

The most obvious question is: how do I know that I am distributing
unadulterated keys?  I think the answer is that I don't!  But any attack
would have to affect a large group of people, and would be detected quickly
as long as many people are looking at the distribution-gpg-keys package.
If this solution is unsatisfactory, then perhaps someone who is more
involved with the Tor developers -- and hence able to directly check the
keys -- ought to take this on.

[1] See https://github.com/xsuchy/distribution-gpg-keys and
https://rpmfind.net/linux/RPM/fedora/updates/32/x86_64/Packages/d/distribution-gpg-keys-1.39-1.fc32.noarch.html



[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;Hi everyone,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I propose distributing the \
Tor developer keys inside the Fedora package distribution-gpg-keys.[1]   This would \
give most Linux users a trustworthy chain of signatures from their own distributor \
(e.g. CentOS or Fedora) to Tor project downloads.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am \
happy to take care of this, although I am also happy if somebody who is more involved \
with Tor than me takes this on.   I wrote a shell script (attached) to acquire and \
organise the keys based on &lt;a \
href="https://2019.www.torproject.org/include/keys.txt"&gt;https://2019.www.torproject.org/include/keys.txt&lt;/a&gt;. \
My script would install the following keys under \
/usr/share/distribution-gpg-keys/tor:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Arm_releases/Damian_Joh \
nson.gpg&lt;br&gt;Tails_live_system_releases/The_Tails_team.gpg&lt;br&gt;TorBirdy_releases/Sukhbir \
_Singh.gpg&lt;br&gt;Tor_Browser_releases/Arthur_Edelstein.gpg&lt;br&gt;Tor_Browser_releases/Georg_ \
Koppen.gpg&lt;br&gt;Tor_Browser_releases/Mike_Perry.gpg&lt;br&gt;Tor_Browser_releases/Nicolas_Vigi \
er.gpg&lt;br&gt;Tor_Browser_releases/The_Tor_Browser_Developers.gpg&lt;br&gt;Tor_source_tarballs/N \
ick_Mathewson.gpg&lt;br&gt;Tor_source_tarballs/Roger_Dingledine.gpg&lt;br&gt;Torsocks_releases/Dav \
id_Goulet.gpg&lt;br&gt;deb.torproject.org_repositories_and_archives/Tor_Project_Archive.gpg&lt; \
br&gt;older_Tor_tarballs/Nick_Mathewson.gpg&lt;br&gt;other/Peter_Palfrader.gpg&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Unless \
someone else volunteers (please do!), I will set up a weekly job to run the script \
and alert me to any changes.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Can anyone see any \
potential problems with this plan?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The most obvious question \
is: how do I know that I am distributing unadulterated keys?   I think the answer is \
that I don't!   But any attack would have to affect a large group of people, and \
would be detected quickly as long as many people are looking at the \
distribution-gpg-keys package.   If this solution is unsatisfactory, then perhaps \
someone who is more involved with the Tor developers -- and hence able to directly \
check the keys -- ought to take this on.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;[1] See &lt;a \
href="https://github.com/xsuchy/distribution-gpg-keys"&gt;https://github.com/xsuchy/distribution-gpg-keys&lt;/a&gt; \
and &lt;a href="https://rpmfind.net/linux/RPM/fedora/updates/32/x86_64/Packages/d/distrib \
ution-gpg-keys-1.39-1.fc32.noarch.html"&gt;https://rpmfind.net/linux/RPM/fedora/updates/3 \
2/x86_64/Packages/d/distribution-gpg-keys-1.39-1.fc32.noarch.html&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;


["fetch" (application/octet-stream)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200720213704</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2020-07-20 21:37:04-0400</timestampReceived><subject>Re: [tor-dev] Distributing Tor developer keys via Fedora packages</subject><body>

On Fri, Jul 17, 2020 at 02:56:08PM +0100, Andrew Clausen wrote:
&gt; Hi everyone,
&gt; 

Hi,

Thanks for your interest in this.

&gt; I propose distributing the Tor developer keys inside the Fedora package
&gt; distribution-gpg-keys.[1]  This would give most Linux users a trustworthy
&gt; chain of signatures from their own distributor (e.g. CentOS or Fedora) to
&gt; Tor project downloads.

(most? :) )

&gt; 
&gt; I am happy to take care of this, although I am also happy if somebody who
&gt; is more involved with Tor than me takes this on.  I wrote a shell script
&gt; (attached) to acquire and organise the keys based on
&gt; https://2019.www.torproject.org/include/keys.txt.  My script would install
&gt; the following keys under /usr/share/distribution-gpg-keys/tor:

Unfortuntately that file is very old and incorrect now.

&gt; 
&gt; Arm_releases/Damian_Johnson.gpg
&gt; Tails_live_system_releases/The_Tails_team.gpg
&gt; TorBirdy_releases/Sukhbir_Singh.gpg
&gt; Tor_Browser_releases/Arthur_Edelstein.gpg
&gt; Tor_Browser_releases/Georg_Koppen.gpg
&gt; Tor_Browser_releases/Mike_Perry.gpg
&gt; Tor_Browser_releases/Nicolas_Vigier.gpg
&gt; Tor_Browser_releases/The_Tor_Browser_Developers.gpg
&gt; Tor_source_tarballs/Nick_Mathewson.gpg
&gt; Tor_source_tarballs/Roger_Dingledine.gpg
&gt; Torsocks_releases/David_Goulet.gpg
&gt; deb.torproject.org_repositories_and_archives/Tor_Project_Archive.gpg
&gt; older_Tor_tarballs/Nick_Mathewson.gpg
&gt; other/Peter_Palfrader.gpg
&gt; 
&gt; Unless someone else volunteers (please do!), I will set up a weekly job to
&gt; run the script and alert me to any changes.
&gt; 
&gt; Can anyone see any potential problems with this plan?
&gt; 

While this is a nice idea, creating a package like this would take more
time than we currently have to spare right now. But, with that being
said, we could probably automatically generate the package in a CI/CD
pipeline when the right people become less overwhelmed. Luckily, project
signing keys don't change very often (on the order of years), so if
there is a desire for a package like this, then it would likely only be
updated a couple times per year. I don't know who would upload it for
distribution, though.

&gt; The most obvious question is: how do I know that I am distributing
&gt; unadulterated keys?  I think the answer is that I don't!  But any attack
&gt; would have to affect a large group of people, and would be detected quickly
&gt; as long as many people are looking at the distribution-gpg-keys package.
&gt; If this solution is unsatisfactory, then perhaps someone who is more
&gt; involved with the Tor developers -- and hence able to directly check the
&gt; keys -- ought to take this on.

Yeah, if a package like this exists and it has tor's name attached to
it, then we should have a high degree of confidence that the package
contains the correct keys.

Thanks,
Matt
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200710180708</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2020-07-10 18:07:08-0400</timestampReceived><subject>Re: [tor-dev] Proposal 325: Packed relay cells: saving space on small commands</subject><body>

On Fri, Jul 10, 2020 at 01:52:00PM -0400, Nick Mathewson wrote:
&gt; After receiving a packed relay cell, the relay know that the client

typo: "know" -&gt; "knows"

&gt;     struct relay_header {
&gt;        u1 stream_id_included; // Is the stream_id included?
&gt;        u6 relay_command; // as before
&gt;        u9 relay_data_len; // as before
&gt;        u8 optional_stream_id[]; // 0 bytes or two bytes.
&gt;     }
&gt; 
&gt; Alternatively, you can view the first three fields as a 16-bit
&gt; value, computed as:
&gt; 
&gt;     (stream_id_included&lt;&lt;15) | (relay_command &lt;&lt; 9) | (relay_data_len).

Where everything is big-endian, both at the byte and bit level?  (Is
that specified at some higher level in the specs?  I forget.)

&gt; If the optional_stream_id field is not present, then the default
&gt; value for the stream_id is computed as follows.  We use stream_id 0
&gt; for any command that doesn't take a stream ID.  For commands that
&gt; _do_ take a steam_id, we use whichever nonzero stream_id appeared
&gt; last in this cell.

Do you mean "last in this cell" as in "the one closest to the end of the
cell" or as in "the one that appeared closest to, but before, this relay
command header"?
-- 
Ian Goldberg
Canada Research Chair in Privacy Enhancing Technologies
Professor, Cheriton School of Computer Science
University of Waterloo
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200607223922</emailId><senderName>Rusty Bird</senderName><senderEmail>rustybird@net-c.com</senderEmail><timestampReceived>2020-06-07 22:39:22-0400</timestampReceived><subject>Re: [tor-dev] onion_client_auth_add Flags=Permanent fails with 553 Unable to store creds for</subject><body>

[Attachment #2 (multipart/signed)]


Hi Patrick,

&gt; 553 Unable to store creds for

Did you set ClientOnionAuthDir in torrc (to a directory with "private
enough" permissions)?

Rusty

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200610201054</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-06-10 20:10:54-0400</timestampReceived><subject>[tor-dev] Walking onions specifications: Project wrap-up</subject><body>

On a grant from the zcash foundation, I've been working on a
full specification for the Walking Onions design.  This is the last update
for the spec project.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html

Week 5:
   Voting (part 2)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014218.html

Week 6:
   Editing, voting rules, and client behavior (part 1)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014222.html

Week 7:
   Exit policies: How do they work?

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014232.html

Week 8:
   Onion services, relay honesty, migration and families

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014255.html

Week 9:
   (There was no week 9)

Week 10:
   Pushing towards completion

   https://lists.torproject.org/pipermail/tor-dev/2020-May/014281.html

== Since the last update

The last couple weeks of the walking onions project were mostly the
"fiddly bits" left over from previous work.  I had to edit for
consistency and clarity, move text around, add specifications for
missing details, and so on.  There were parts of the voting design
that didn't actually work as written, and needed to get tweaked
around.

Index voting was tricky for a few reasons: notably, index weights
are a complex function of bandwidths, which themselves are voted on.
I had hoped that we could move the algorithms we use for weighting
out of the consensus algorithm and into the authorities, but for
now, I think we're stuck with having them as yet another thing
authorities need to implement identically.  At least the new consensus
system itself is extensible, so we have a clear path forward to a
better consensus approach for indices (if we ever figure one out).

I also needed to figure out handling for VoterCerts: I had done the
first version of the spec for how they should appear in parameters
documents before I actually figured out how voting would work, and
the two approaches weren't compatible.  This took some revision, but
I think it should work out now.

Similarly, I had known that we'd need to use the "detached
signatures" mechanism from the existing consensus protocol, but the
Walking Onions spec didn't actually allow for this.  Fortunately,
this was an easy chance to make.

And overall, I went through a pretty large number of places in the
document where there were "XXXX" comments indicating things I had to
come back to later.

With that, the first version Walking Onions proposal was ready to go
out as [PROP323].  You can see a rendered version of it over at
[PROP323-RENDERED], though there will be a better URL for that in
the future.

I also put out the remaining side related proposals ([PROP321] for
families, and [PROP322] for link specifiers for directory ports).

== Project recap

When I first described Walking Onions [PROP300], I had only the
general outlines of a design for a more efficient Tor network: a
couple of tricks to allow clients to continue building secure paths
through the network without having to know a list of relays on the
network.  But I had known there would be remaining problems to
solve, and listed them in that proposal.

Thanks to this grant, I've been able to flesh out Walking Onions to
a specified design that I think we could actually build.  In doing
so, I ran into the typical specification curse, where each change
led to a need for other changes.  Notably:

  * The need for a new kind of directory-like structure led to the
    need for a more flexible and parsable metadocument format, and a
    more generic voting algorithm for authorities.

  * When designing the new meta-format, I found a better approach
    for handling expiration and clock synchronization between
    clients and relays that should allow us to be a little more lax
    with skew, while better resisting attacks based on serving
    obsolete information.

  * The search for a reasonable solution to exit policies led to
    a hybrid extraction/designed approach for clustering exit ports
    by their correlatedness, then designing exit policies around
    semantic similarity in port types.

  * When enumerating the various ways that clients need to be able
    to request SNIPs and circuits, I found a need for a span-based
    SNIP query request, which I hadn't previously known that we'd
    need.  This simplifies some of our logic.

  * (and more; please see previous updates.)

The resulting documents (proposals 318 through 323) are not final: I
believe that as we continue to discuss them, and eventually implement
them, we'll find further opportunities for improvement--and for fixing
things that I missed when I was designing and writing all of this.  But
I think we've got a much firmer grasp of this project now.

I think there are parts that we could in principle start building
now: the preliminary proposals 318 (limiting protocol versions), 319
(cell fragmentation) and 321 (improved family handling) are high on
my list for now, if we get time.

And now the design iteration begins!






[PROP300] https://gitweb.torproject.org/torspec.git/plain/proposals/300-walking-onions.txt

[PROP321] https://gitweb.torproject.org/torspec.git/plain/proposals/321-happy-families.md

[PROP322] https://gitweb.torproject.org/torspec.git/plain/proposals/322-dirport-linkspec.md

[PROP323] https://gitweb.torproject.org/torspec.git/plain/proposals/323-walking-onions-full.md

[PROP323-RENDERED] https://people.torproject.org/~nickm/volatile/rendered.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200614181649</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-06-14 18:16:49-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Christian Hofer:
&gt; On Tue, 2020-06-09 at 23:54 +0200, nusenu wrote:
&gt; &gt; &gt; However, thinking about it, DNSSEC might be useful for caching DNS
&gt; &gt; &gt; records on the client side.
&gt; &gt; 
&gt; &gt; caching has privacy implications and is therefore a risk.
&gt; &gt; 
&gt; 
&gt; So you are saying that caching is not an option in any case, right? Can
&gt; I kindly ask you to elaborate on this? You don't have to write a long
&gt; answer. A link pointing me to the answer would be more than enough. I
&gt; just want to understand the reason behind this.

You can use cache but it must address the linkability risk by scoping the cache \
usage. With DoH the browser has access to TTL values from DNS records, so caching is
somewhat easier for the browser as it used to be.

keywords and pointers:
unlinkability 
first party isolation
https://www.torproject.org/projects/torbrowser/design/


&gt; &gt; but finding resolvers is probably one of the smaller issues when
&gt; &gt; compared to getting
&gt; &gt; everything implemented in firefox/tor browser. Current versions do
&gt; &gt; not even allow 
&gt; &gt; to set more than one resolver URL.
&gt; &gt; 
&gt; 
&gt; I see. Are there any tickets or design proposals I can contribute to?

I haven't put my ideas into a specification yet, but it looks like there is a good \
reason to write a spec now.

A next step - before anything else - could be to ask Tor Browser people if there are \
any DoH plans yet, I did so back in 2018 and will follow up on that right after this \
email.

&gt; Since you have no comments on my suggestion for an alternative
&gt; approach, I assume that it is not worth to compare it to DoH, right? 

to quote my vision:
&gt; My vision for DNS privacy in Tor Browser: 
&gt; Be able to visit a HTTPS website without the exit relay learning what domain it was \
&gt;  (encrypted DNS + encrypted SNI)

This vision somewhat implies the use of DoH, since Firefox requires DoH for ESNI \
(unless one wants to implement that in an additional Firefox patch). 
A second good reason for DoH over some other option: DoH is a specified protocol with \
public implementations and public services/service providers. This helps with \
resolver diversity, availability  and gives us more options when choosing resolvers.

kind regards,
nusenu

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200615174639</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-06-15 17:46:39-0400</timestampReceived><subject>Re: [tor-dev] #32888 IPv6 and 'Address' option</subject><body>

On Sun, Jun 14, 2020 at 6:42 AM c &lt;c@chroniko.jp&gt; wrote:
&gt;
&gt; Trac &lt;https://trac.torproject.org/projects/tor/ticket/32888&gt; describes
&gt; that "we should also log [for] IPv4 and IPv6: the Address torrc option"
&gt; and as tor(1) states, 'Address' takes only an IPv4 address and port.
&gt;
&gt; So what is suggested here? Make 'Address' support IPv6 to be consistent
&gt; with other options ('ORPort', 'SocksPort', 'TransPort', 'DNSPort', and
&gt; the like all support multiple declarations per torrc, both IPv4 and
&gt; IPv6)? If we will have IPv6-only relays in the future, this option
&gt; would make quite a bit of sense.

I think what you're looking for here is section 3.2.1 of proposal 312,
which covers how Tor should determine its IPv6 addresses.  The plan
described there is to allow Address to appear up to twice.

Link:

https://gitweb.torproject.org/torspec.git/tree/proposals/312-relay-auto-ipv6-addr.txt#n245

&gt; Since I'm on the topic of #32888, I went ahead and pushed the IPv6
&gt; logging portion to &lt;https://github.com/torproject/tor/pull/1932&gt; and
&gt; have tested with 'ORPort [::1]:9001' and it seems to log successfully.
&gt; Not a big change, so I expect it to be an easy merge.

Sounds good!  I'll take a look at it soon.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200616152448</emailId><senderName>meskio</senderName><senderEmail>meskio@sindominio.net</senderEmail><timestampReceived>2020-06-16 15:24:48-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/signed)]


Quoting Alec Muffett (2020-06-16 14:10:24)
&gt;    On Tue, 16 Jun 2020 at 12:15, meskio &lt;[1]meskio@sindominio.net&gt; wrote:
&gt; 
&gt;      I'm wondering if it will make sense to use Onion-Location in V2 onion
&gt;      services
&gt;      to advertise the V3 onion. So existing known V2 services can use it to
&gt;      upgrade
&gt;      their users to V3.
&gt; 
&gt;      AFAIK right now tor-browser ignores the Onion-Location header if is
&gt;      already
&gt;      coming from an onion service. Will it make sense to stop ignoring it at
&gt;      least
&gt;      for V2 onion services?
&gt; 
&gt;    Or the site could just issue a Location header and/or explicit redirect to
&gt;    the v3 service?
&gt;    After all, if the v2 site is compromised to the point where that's a
&gt;    problem, then there are larger issues / "game over", etc.

True, I agree I don't see much value added to do the Onion-Location instead of 
just doing a redirect. I guess this is a better way of upgrading users.

-- 
meskio | https://meskio.net/
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
 My contact info: https://meskio.net/crypto.txt
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Nos vamos a Croatan.
["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAABCAAdFiEEs7M6f/ZpXzXMAQR+Urj1rJei2oYFAl7o5DwACgkQUrj1rJei
2oYayw/+J0MVECZyOkRnoWGBCRiJCkZSBsxfEW5YNhlGV+i19WdEno85abcDZP2H
A+8rfcx0eodN/cAGmQr+WmPLHqK37rcaL+93BF8EPD+sWRUTxq9h1CpVYWR9hS7N
725u4sTYW3JczEfBCAwVArAt1jZ/MW0mEbTMlizBP00Tsc4+Ic1E0TkmDvNMBZXW
7qr3eu7F6VUdNjnCAgYCMWq/qlShnrDYCfCr8P38WyYM2lZLnVn+AMY8ZBg7nJDq
k/NhtPr+mOcelTOCaKtJEicduR9XW+OT9xT9hr7wiPhZklzSBPIq5INhwOry6Y23
+fLJf/esOk5phE4wt0CF0ZJ26FQQkzc/elo2Z5UoMg+j6zUpupl6XJ9qczbYZxDv
knY5KslXLniy79YYVe46QyyFTDenV6sqTt2qdICOl6eukY8Nb3eIXVbs9YO8O6rW
u6OSdkJ/iZQSaIH3UtGTo4HITYy9ngj9p+mxfxFnP0H+1M1x7XGFx33cpkUkNmeM
4Lvi1rV0Pwob2DspU5G1SaA/lN7f+VQLKJUxslhW9rQ78iGrBmOpjjd9wYy6mFqt
OEdqu1gtSB7kMmB5lQXslIUvoW7Ap7w0TwxFUNrACVIR4fyrcMwsPVbDW75zwMOS
xsUsiWl26774tk3jzFmJmidVjPJN8GFEbw3pb/AWqy3Z6t8JhfA=
=d102
-----END PGP SIGNATURE-----


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200617101601</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-06-17 10:16:01-0400</timestampReceived><subject>Re: [tor-dev] Onion Client Auth on v3 descriptor via Control port</subject><body>

Miguel Jacq &lt;mig@mig5.net&gt; writes:

&gt; Hi George,
&gt; 
&gt; On Wed, Jun 17, 2020 at 12:37:18PM +0300, George Kadianakis wrote:
&gt; &gt; 
&gt; &gt; Hmm, this is a bit embarassing for both of us, but if I'm not mistaken
&gt; &gt; ONION_CLIENT_AUTH_ADD only controls the client-side of client auth
&gt; &gt; credentials. This is not obvious at all by the command name, and it only
&gt; &gt; becomes a bit clearer by reading the control-spec.txt...
&gt; &gt; 
&gt; &gt; We added that control port command so that the browser could present a
&gt; &gt; UX for client authorization.
&gt; 
&gt; Ahahahah. Riiight, thanks for that clarification. This whole time I indeed thought \
&gt; this was a novel way for adding Client Auth for v3 onions via the control port. 
&gt; I had been reading the rend-spec-v3 \
&gt; https://github.com/torproject/torspec/blob/master/rend-spec-v3.txt  
&gt; G.2.1 'Service side' says '[XXX figure out control port command format]' and I \
&gt; figured it just hadn't been updated to reflect the new command. I hadn't even \
&gt; thought to read the control spec.. 
&gt; &gt; 
&gt; &gt; AFAIK there is no control port command for adding service-side client
&gt; &gt; auth credentials. You will need to do this using the filesystem by using
&gt; &gt; the '&lt;HiddenServiceDir&gt;/authorized_clients/' directory as displayed by
&gt; &gt; the "CLIENT AUTHORIZATION" section of the manual... Or you will need to
&gt; &gt; implement the control port commands in tor :/
&gt; &gt; 
&gt; &gt; Sorry for the sad news here....... :/
&gt; 
&gt; Okay, thanks for all the clarification. Indeed, OnionShare uses purely ephemeral \
&gt; onions, so the standard filesystem method won't work (unless we switch to that). 

Right.... Seems like v2 supports adding client auth credentials through
the control port using the ADD_ONION command, but that's not the case
for v3...

Just a simple matter of programming as always ;)

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200618125249</emailId><senderName>Krona Emmanuel</senderName><senderEmail>kronaemmanuel@gmail.com</senderEmail><timestampReceived>2020-06-18 12:52:49-0400</timestampReceived><subject>[tor-dev] GSOC: Social Media Sharing for OONI</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

I'm Krona Emmanuel, working on implementing better Social Media Sharing
within OONI Explorer [1]. OONI Explorer allows users to view measurements
and visualizations of network interference around the world. This project
is aimed at improving OONI Explorer in the following areas:

1. SEO
2. Social media link sharing.
3. Sharing charts

So far, I have been working on making prototypes for charts and social
media link sharing. I recently finished a PR which improved the meta tags
of measurement pages to better indicate the results of the measurement [3].

You can see more details about the project on the GSOC project page [2]. I
would be very happy to get any suggestions etc about the project. I'll also
send in more updates about the project as I implement features.

Regards,
Krona Emmanuel


1. https://explorer.ooni.org/
2. https://summerofcode.withgoogle.com/projects/#4714428131442688
3. https://github.com/ooni/explorer/pull/470

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;&lt;div&gt;Hi,&lt;br&gt;&lt;br&gt;&lt;/div&gt;I'm Krona Emmanuel, working on \
implementing better Social Media Sharing within OONI Explorer [1]. OONI Explorer \
allows users to view measurements and visualizations of network interference around \
the world. This project is aimed at improving OONI Explorer in the following \
areas:&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. SEO&lt;br&gt;&lt;/div&gt;&lt;div&gt;2. Social media link \
sharing.&lt;/div&gt;&lt;div&gt;3. Sharing charts&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So far, I have been \
working on making prototypes for charts and social media link sharing. I recently \
finished a PR which improved the meta tags of measurement pages to better indicate \
the results of the measurement [3].&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You can see more \
details about the project on the GSOC project page [2]. I would be very happy to get \
any suggestions etc about the project. I'll also send in more updates about the \
project as I implement features.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;br&gt;&lt;/div&gt;&lt;div&gt;Krona \
Emmanuel&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;br&gt;1. &lt;a href="https://explorer.ooni.org/" \
target="_blank"&gt;https://explorer.ooni.org/&lt;/a&gt;&lt;/div&gt;&lt;div&gt;2. &lt;a \
href="https://summerofcode.withgoogle.com/projects/#4714428131442688"&gt;https://summerofcode.withgoogle.com/projects/#4714428131442688&lt;/a&gt;&lt;/div&gt;&lt;div&gt;3. \
&lt;a href="https://github.com/ooni/explorer/pull/470"&gt;https://github.com/ooni/explorer/pull/470&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200603092422</emailId><senderName>Patrick Schleizer</senderName><senderEmail>patrick-mailinglists@whonix.org</senderEmail><timestampReceived>2020-06-03 09:24:22-0400</timestampReceived><subject>[tor-dev] onionbalance useful on same server / for high-spec non-location hidden servers?</subject><body>

Would it be useful to run multiple Tor instances and onionbalance on the
very same server? Or does that totally defeat the purpose of onionbalance?

In my case, it's not a location hidden service. Just an alternative way
to connect to a server which is available over clearnet anyhow.

I guess the presumption of onionbalance is that a location hidden server
shouldn't produce too much Tor traffic as that would be suspicious?

Is a single Tor client a bottleneck? I.e. are multiple Tor clients more
performant than only one Tor client? Does onionbalance "only" work
around limitations of individual servers in CPU / IO / bandwidth?

In other words, assume CPU / IO / bandwidth is "unlimited" on one
server. (And ignore failover.) Does it make sense to run multiple Tor
instances and onionbalance or would a single Tor instance without
onionbalance be sufficient?

Cheers,
Patrick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200605162347</emailId><senderName>Patrick Schleizer</senderName><senderEmail>patrick-mailinglists@whonix.org</senderEmail><timestampReceived>2020-06-05 16:23:47-0400</timestampReceived><subject>[tor-dev] onion_client_auth_add Flags=Permanent fails with 553 Unable to store creds for</subject><body>

Hi!

sudo -u debian-tor socat - UNIX-CONNECT:/var/run/tor/control
AUTHENTICATE "test"
250 OK

onion_client_auth_add
m5bmcnsk64naezc26scz2xb3l3n2nd5xobsljljrpvf77tclmykn7wid
x25519:uBKh6DGrkcFxB1adYuyKQltUDDUT9IZrOsne3nfHbHI=

252 Registered client and decrypted desc

onion_client_auth_add
m5bmcnsk64naezc26scz2xb3l3n2nd5xobsljljrpvf77tclmykn7wid
x25519:uBKh6DGrkcFxB1adYuyKQltUDDUT9IZrOsne3nfHbHI= Flags=Permanent

553 Unable to store creds for
"m5bmcnsk64naezc26scz2xb3l3n2nd5xobsljljrpvf77tclmykn7wid"

tor --version
Tor version 0.4.3.5.

Should be implemented according to:

https://trac.torproject.org/projects/tor/ticket/32562

Cheers,
Patrick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200614104113</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-06-14 10:41:13-0400</timestampReceived><subject>[tor-dev] #32888 IPv6 and 'Address' option</subject><body>

Trac &lt;https://trac.torproject.org/projects/tor/ticket/32888&gt; describes
that "we should also log [for] IPv4 and IPv6: the Address torrc option"
and as tor(1) states, 'Address' takes only an IPv4 address and port.

So what is suggested here? Make 'Address' support IPv6 to be consistent
with other options ('ORPort', 'SocksPort', 'TransPort', 'DNSPort', and
the like all support multiple declarations per torrc, both IPv4 and
IPv6)? If we will have IPv6-only relays in the future, this option
would make quite a bit of sense.

Since I'm on the topic of #32888, I went ahead and pushed the IPv6
logging portion to &lt;https://github.com/torproject/tor/pull/1932&gt; and
have tested with 'ORPort [::1]:9001' and it seems to log successfully.
Not a big change, so I expect it to be an easy merge.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200615163417</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-06-15 16:34:17-0400</timestampReceived><subject>[tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/signed)]


Greetings everyone!

I will try to make this quick. Deprecation of v2 has already been discussed on
this list [0] and so this is not about re-creating this discussion but rather
giving you the Tor Project timeline for v2 deprecation.

To very quickly summarize why we are deprecating, in one word: Safety. Onion
service v2 uses RSA1024 and 80 bit SHA1 (truncated) addresses [1]. It also
still uses the TAP [2] handshake which has been entirely removed from Tor for
many years now _except_ v2 services. Its simplistic directory system exposes
it to a variety of enumeration and location-prediction attacks that give HSDir
relays too much power to enumerate or even block v2 services. Finally, v2
services are not being developed nor maintained anymore. Only the most severe
security issues are being addressed.

That being said, the deprecation timeline is now quite simple because v3 has
reached a good maturity level:

  * v3 has been the default since Tor 0.3.5.1-alpha.
  * v3 is feature parity with v2.
  * v3 now has Onion Balance support [3]
  * Entire network supports v3 since the End-of-Life of 0.2.9.x series earlier
    this year.

The deprecation to obsolescence timeline:

  1) September 15th, 2020
     0.4.4.x: Tor will start warning onion service operators and clients that
              v2 is deprecated and will be obsolete in version 0.4.6

  2) July 15th, 2021
     0.4.6.x: Tor will no longer support v2 and will be removed from the code
              base.

  3) October 15th, 2021
     We will release new stable versions for all supported series that will
     disable v2.

This effectively means that from _today_ (June 11th 2020), the Internet has
around 15 months to migrate from v2 to v3 once and for all.

We plan to publish a blog post in the coming days/weeks about this
deprecation, in order to inform as many users as possible. It will include the
reasons why, how to migrate and the timeline.

We'll probably run into some difficulties here; no matter how prepared we
think we are, we find that there are always more surprises. Nonetheless, we'll
do our best to fix problems as they come up, and try to make this process as
smooth as possible.

Good Luck!
The tor maintainers.

[0] https://lists.torproject.org/pipermail/tor-dev/2018-April/013097.html
[1] https://shattered.io/
[2] https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1084
[3] https://blog.torproject.org/cooking-onions-reclaiming-onionbalance

-- 
262Gy/4o+HGG/7ELoDp1drRojN33l7AZaBoRHN6mjXY=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200617071436</emailId><senderName>Miguel Jacq</senderName><senderEmail>mig@mig5.net</senderEmail><timestampReceived>2020-06-17 07:14:36-0400</timestampReceived><subject>[tor-dev] Onion Client Auth on v3 descriptor via Control port</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

I'm one of the OnionShare developers, looking at what can be done to support Client \
Auth with v3 onions.

OnionShare depends on Stem for all its interaction setting up ephemeral onions, so we \
need Stem to support that fierst.

So I have been working on adding support for ONION_CLIENT_AUTH_ADD to Stem. I \
actually have it working as far as getting a 250 OK back from the controller! Nice.

But I'm puzzled, because despite successfully adding the client auth, I can access my \
onion service *without* auth in Tor Browser.


Here is a link to a PoC script. Note that it doesn't do the ONION_CLIENT_AUTH_ADD via \
Stem here yet. I have that working locally, but this issue isn't with my Stem \
implementation I don't think...

https://gist.github.com/mig5/2e95a3fbe157e1f78764f7a718bf93b9

Here's the output if I run the script with python3 create-v3-service-and-keys.py

user@onionshare:~$ python3 create-v3-service-and-keys.py
http service: http://127.0.0.1:8080/

starting onion service with: key_type='NEW', key_content='ED25519-V3'
http://4sa6jhqf2atg7edi2nzqun4o5kyughmwvjyrb7sfxe7d6ypqyh7f6nqd.onion/

private base64: wkiyM1bQN2dI43PvobZnbD87cNBl/KFyrc8baZzJOv0=
public base32:  WJJTONEA5SRZKVHHAYY2EHIF5LNF3526RCLYSC7ZZRCPVPIFA6PA====
private base32: YJELEM2W2A3WOSHDOPX2DNTHNQ7TW4GQMX6KC4VNZ4NWTHGJHL6Q====


Now, if in another terminal I telnet to the control port and manually add the onion \
auth, I get a 250, I can view the auth etc:

user@onionshare:~/git/stem$ sudo -u debian-tor telnet 127.0.0.1 9051
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
Authenticate ""
250 OK
ONION_CLIENT_AUTH_ADD 4sa6jhqf2atg7edi2nzqun4o5kyughmwvjyrb7sfxe7d6ypqyh7f6nqd \
x25519:wkiyM1bQN2dI43PvobZnbD87cNBl/KFyrc8baZzJOv0= 250 OK
ONION_CLIENT_AUTH_VIEW 4sa6jhqf2atg7edi2nzqun4o5kyughmwvjyrb7sfxe7d6ypqyh7f6nqd
250-ONION_CLIENT_AUTH_VIEW 4sa6jhqf2atg7edi2nzqun4o5kyughmwvjyrb7sfxe7d6ypqyh7f6nqd
250-CLIENT 4sa6jhqf2atg7edi2nzqun4o5kyughmwvjyrb7sfxe7d6ypqyh7f6nqd \
x25519:wkiyM1bQN2dI43PvobZnbD87cNBl/KFyrc8baZzJOv0= 250 OK


So that all looks good. But what is weird, is if I go to \
http://gmdo3idszymnvfbuf2fm6miepearldgwbo7qfc4lsrw2kact2ka77kqd.onion/ , I see my \
'hello world', I never had to add any client auth to Tor Browser.

What am I doing wrong? How do I make the onion auth actually be 'required' since I \
succeeded at adding it? I was under the impression that as soon as I ran \
ONION_CLIENT_AUTH_ADD and got a success, from that point on, client auth would be \
*needed*.

Maybe it's a problem with how I'm generating the keys? I had a bit of trouble \
figuring out how to send the base64 encoded private key. Even so, it accepts the \
private key, and yet it allows access without auth, which surprised me...

It's probably really obvious but I've been working on this a while so I'm tired :) \
Time to embarass myself on a public mailing list..

Thanks in advance!

Mig


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200615125251</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-06-15 12:52:51-0400</timestampReceived><subject>[tor-dev] Reproducing #33598 "chutney does not fail on some SOCKS errors"</subject><body>

I asked on ticket https://bugs.torproject.org/33598 how to reliably
reproduce SOCKS errors so that it would be easier to determine when the
underlying issue is properly fixed, rather than running into the
possibility of race conditions (as the current workaround depends on
"waiting long enough" for connections to succeed most of the time).

In #tor-dev I believe it was arma who pointed me toward the right
direction, but that still leaves me with unresolved questions. It was
suggested that I can attempt SOCKS connections to an invalid host/port
versus a valid one, in order to have a reliable failure case for
testing. But in the context of Chutney I believe we only want to
attempt local connections, correct? So either attempting connection to
127.0.0.0/8 on a known-closed port, or perhaps more simply 0.0.0.0 on
any port, would be a reliable case to use, correct?

Also from my comment on #33598:

&gt; Assuming workaround is at Traffic.py:441? I see the timeout was
&gt; adjusted in 95ce144c which has more changes than just that line.

and

&gt; will decreasing the timeout back to 0.2 be enough to encourage
&gt; failure?

Last question: I looked for a bit, but where is Chutney actually
initiating SOCKS connections to Tor during tests? I still find it hard
to follow especially when I am going in blind for much of this.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200619134854</emailId><senderName>The Paranoia Project</senderName><senderEmail>info@paranoia.tools</senderEmail><timestampReceived>2020-06-19 13:48:54-0400</timestampReceived><subject>[tor-dev] Implementing an embeddable C++ Tor client, advice requested</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Hello everyone, I'm a long time user of Tor, first time poster here.

Over the last few months, I have been working on a light weight C++ client only \
implementation of the Tor protocol, intended to be used as an embedded library in \
other applications. It is now at the stage where it can complete bootstrapping, build \
circuits, as well as connect to services / host hidden services (v3). I have been \
building this primarily off the spec documents (which have generally been extremely \
helpful), and well as the assistance of stepping through the official Tor \
implementation when needed for troubleshooting and to confirm specifics. Before I \
release this to the wider world, I'd like to confirm a few points that may not be \
explicitly stated in the specs.

1. In general, what are the things to look out for when implementing the Tor protocol \
beyond "making it work" and validating all data (signatures, timestamps, etc)? One \
thing I'm concerned about is the risk of fingerprinting where the spec does not \
completely specify behaviour, e.g. the order in which link specifiers are passed in \
an extend cell, exact criteria for when circuits are explicitly destroyed etc. (I'm \
very excited to see the proposals around CBOR on this point which would help greatly \
with knowing that a canonical data representation was used).

2. When it comes to bootstrapping, the official implementation appears to favour \
accessing directories via plaintext HTTP rather than connecting on the OR port and \
using create fast / begin dir. What is the motivation for using the plaintext option \
(and for that matter, having a plaintext http service open at all)?. While the OR \
will learn just as much about the client regardless, it seems like the default \
plaintext access to directory information unnecessarily gives away details of how \
clients engage with the Tor network to third parties.

3. When using bridges and in particular pluggable transports, how is the client \
intended to safely bootstrap in the cold start case where it does not know up front \
which bridge/relay it will be connected to (e.g. when using Snowflake)? The RSA \
identity can be accepted in blind faith based on the Tor handshake, and it's then \
possible to get the full details with create fast / begin dir, but how does a client \
know that it has been connected to a bridge that is "blessed" by the Tor network \
rather than a MITM actor?

4. Finally, if anyone reading has been involved with or close to the development of \
other unofficial Tor implementations, what are the lessons learned on this front? I'm \
aware of among others Orchid (updated last in 2016), node-Tor (does not implement \
ECC) and torpy (does not implement hidden services v3). What makes these fail / \
stall?

Many thanks,
P


[Attachment #5 (text/html)]

&lt;div&gt;Hello everyone, I'm a long time user of Tor, first time poster \
here.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Over the last few months, I have been working on a \
light weight C++ client only implementation of the Tor protocol, intended to be used \
as an embedded library in other applications. It is now at the stage where it can \
complete bootstrapping, build circuits, as well as connect to services / host hidden \
services (v3). I have been building this primarily off the spec documents (which have \
generally been extremely helpful), and well as the assistance of stepping through the \
official Tor implementation when needed for troubleshooting and to confirm specifics. \
Before I release this to the wider world, I'd like to confirm a few points that may \
not be explicitly stated in the specs.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. In general, \
what are the things to look out for when implementing the Tor protocol beyond "making \
it work" and validating all data (signatures, timestamps, etc)? One thing I'm \
concerned about is the risk of fingerprinting where the spec does not completely \
specify behaviour, e.g. the order in which link specifiers are passed in an extend \
cell, exact criteria for when circuits are explicitly destroyed etc. (I'm very \
excited to see the proposals around CBOR on this point which would help greatly with \
knowing that a canonical data representation was \
used).&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;2. When it comes to bootstrapping, the official \
implementation appears to favour accessing directories via plaintext HTTP rather than \
connecting on the OR port and using create fast / begin dir. What is the motivation \
for using the plaintext option (and for that matter, having a plaintext http service \
open at all)?. While the OR will learn just as much about the client regardless, it \
seems like the default plaintext access to directory information unnecessarily gives \
away details of how clients engage with the Tor network to third \
parties.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;3. When using bridges and in particular \
pluggable transports, how is the client intended to safely bootstrap in the cold \
start case where it does not know up front which bridge/relay it will be connected to \
(e.g. when using Snowflake)? The RSA identity can be accepted in blind faith based on \
the Tor handshake, and it's then possible to get the full details with create fast / \
begin dir, but how does a client know that it has been connected to a bridge that is \
"blessed" by the Tor network rather than a MITM \
actor?&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;4. Finally, if anyone reading has been involved \
with or close to the development of other unofficial Tor implementations, what are \
the lessons learned on this front? I'm aware of among others Orchid (updated last in \
2016), node-Tor (does not implement ECC) and torpy (does not implement hidden \
services v3). What makes these fail / stall?&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Many \
thanks,&lt;br&gt;&lt;/div&gt;&lt;div&gt;P&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200623183421</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-06-23 18:34:21-0400</timestampReceived><subject>Re: [tor-dev] Implementing an embeddable C++ Tor client, advice requested</subject><body>

On Fri, Jun 19, 2020 at 3:59 PM The Paranoia Project
&lt;info@paranoia.tools&gt; wrote:
&gt; 
&gt; Hello everyone, I'm a long time user of Tor, first time poster here.
&gt; 
&gt; Over the last few months, I have been working on a light weight C++ client only \
&gt; implementation of the Tor protocol, intended to be used as an embedded library in \
&gt; other applications. It is now at the stage where it can complete bootstrapping, \
&gt; build circuits, as well as connect to services / host hidden services (v3). I have \
&gt; been building this primarily off the spec documents (which have generally been \
&gt; extremely helpful), and well as the assistance of stepping through the official Tor \
&gt; implementation when needed for troubleshooting and to confirm specifics. Before I \
&gt; release this to the wider world, I'd like to confirm a few points that may not be \
&gt; explicitly stated in the specs.

Hello, P!  It'll be neat to have a look at this when it comes out;
building a Tor implementation is a lot of work.

&gt; 1. In general, what are the things to look out for when implementing the Tor \
&gt; protocol beyond "making it work" and validating all data (signatures, timestamps, \
&gt; etc)? One thing I'm concerned about is the risk of fingerprinting where the spec \
&gt; does not completely specify behaviour, e.g. the order in which link specifiers are \
&gt; passed in an extend cell, exact criteria for when circuits are explicitly destroyed \
&gt; etc. (I'm very excited to see the proposals around CBOR on this point which would \
&gt; help greatly with knowing that a canonical data representation was used).

There are a lot of these, I'm afraid, and they're not all perfectly
documented.  Some of the trickier ones are about "being kind to the
network" -- not making too many circuits, not over-using resources
when idle, and so on.  These are under-documented, but I believe Roger
has talked a few times about starting a document to collect these.
Roger, do you remember if this ever went anywhere, and produced a
draft or something?

For your first few versions, I'd suggest that your best bet is to
label your software loudly as experimental and alpha, since there will
almost certainly be ways to distinguish your software and surprising
bugs. Trying to be completely indistinguishable is probably
impossible, due to timing issues at least -- about the best you can do
is try to avoid easy ways to passively distinguish your software.

In general, I wouldn't mind taking patches to enhance the specs by
describing a preferred behavior whenever there is more than on
possible behavior.

&gt; 2. When it comes to bootstrapping, the official implementation appears to favour \
&gt; accessing directories via plaintext HTTP rather than connecting on the OR port and \
&gt; using create fast / begin dir. What is the motivation for using the plaintext \
&gt; option (and for that matter, having a plaintext http service open at all)?. While \
&gt; the OR will learn just as much about the client regardless, it seems like the \
&gt; default plaintext access to directory information unnecessarily gives away details \
&gt; of how clients engage with the Tor network to third parties.

That isn't right.  It's preferred for clients to download directory
material over the ORPort via begindir.  Plaintext DirPorts are
supposed to be used by relays and authorities only.

What part of the spec or the implementation says that the plaintext
dirport should be preferred?  I'd like to correct that.

&gt; 3. When using bridges and in particular pluggable transports, how is the client \
&gt; intended to safely bootstrap in the cold start case where it does not know up front \
&gt; which bridge/relay it will be connected to (e.g. when using Snowflake)? The RSA \
&gt; identity can be accepted in blind faith based on the Tor handshake, and it's then \
&gt; possible to get the full details with create fast / begin dir, but how does a \
&gt; client know that it has been connected to a bridge that is "blessed" by the Tor \
&gt; network rather than a MITM actor?

Bridge addresses and identities need to be discovered out-of-band, by
some means like bridgedb.torproject.org, personal communication, or
bundling with software.  The provenance of this information is the
only way to tell whether you're getting a likely-to-be-good bridge or
likely-to-be-run-by-your-enemy bridge.

&gt; 4. Finally, if anyone reading has been involved with or close to the development of \
&gt; other unofficial Tor implementations, what are the lessons learned on this front? \
&gt; I'm aware of among others Orchid (updated last in 2016), node-Tor (does not \
&gt; implement ECC) and torpy (does not implement hidden services v3). What makes these \
&gt; fail / stall?

I'll let developers answer here -- part of the issue is that it can be
hard to maintain feature parity over time.

For a longer list of implementations, see
https://gitlab.torproject.org/legacy/trac/-/wikis/doc/ListOfTorImplementations
[warning -- wiki migration in progress].

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200615180637</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-06-15 18:06:37-0400</timestampReceived><subject>Re: [tor-dev] Reproducing #33598 "chutney does not fail on some SOCKS errors"</subject><body>

On Mon, Jun 15, 2020 at 8:53 AM c &lt;c@chroniko.jp&gt; wrote:
&gt;
&gt; I asked on ticket https://bugs.torproject.org/33598 how to reliably
&gt; reproduce SOCKS errors so that it would be easier to determine when the
&gt; underlying issue is properly fixed, rather than running into the
&gt; possibility of race conditions (as the current workaround depends on
&gt; "waiting long enough" for connections to succeed most of the time).
&gt;
&gt; In #tor-dev I believe it was arma who pointed me toward the right
&gt; direction, but that still leaves me with unresolved questions. It was
&gt; suggested that I can attempt SOCKS connections to an invalid host/port
&gt; versus a valid one, in order to have a reliable failure case for
&gt; testing. But in the context of Chutney I believe we only want to
&gt; attempt local connections, correct? So either attempting connection to
&gt; 127.0.0.0/8 on a known-closed port, or perhaps more simply 0.0.0.0 on
&gt; any port, would be a reliable case to use, correct?

This seems plausible, though 0.0.0.0:x will just be the local computer as well.

Maybe you could try routing to a known-unassigned address, or one that
Tor simply won't support, like the one from RFC 6666?  For IPv4 I
think maybe a multicast or known-unassigned prefix might have similar
results.

&gt; Also from my comment on #33598:
&gt;
&gt; &gt; Assuming workaround is at Traffic.py:441? I see the timeout was
&gt; &gt; adjusted in 95ce144c which has more changes than just that line.

Hm, that might be where the "5.0" is coming from, yeah.

&gt; and
&gt;
&gt; &gt; will decreasing the timeout back to 0.2 be enough to encourage
&gt; &gt; failure?

So the way that timeout works, I think, is that it controls how long
asyncore will go without any events before it exits.  The while loop
around asyncore.loop() is what makes it retry over and over.

I think the problem here might be that the while loop keeps going
until the time reaches "end", or until "self.tests.all_done()".  This
might mean that we need to adjust the socks handling code instead, so
it detects socks refusals and treats them as the test being "done",
but failed.

In theory, the code handles this in Source.collect_incoming_data(),
where it looks for a socks response, and compares it to an expected
value.  But I guess chutney is restarting the connection again, or not
treating this as a test failure?

&gt; Last question: I looked for a bit, but where is Chutney actually
&gt; initiating SOCKS connections to Tor during tests? I still find it hard
&gt; to follow especially when I am going in blind for much of this.

It's in Traffic.py, Source.handle_connect(), in this line:

            self.push(socks_cmd(self.server))

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200617093718</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-06-17 09:37:18-0400</timestampReceived><subject>Re: [tor-dev] Onion Client Auth on v3 descriptor via Control port</subject><body>

Miguel Jacq &lt;mig@mig5.net&gt; writes:

&gt; Hi,
&gt; 
&gt; I'm one of the OnionShare developers, looking at what can be done to support Client \
&gt; Auth with v3 onions. 
&gt; OnionShare depends on Stem for all its interaction setting up ephemeral onions, so \
&gt; we need Stem to support that fierst. 
&gt; So I have been working on adding support for ONION_CLIENT_AUTH_ADD to Stem. I \
&gt; actually have it working as far as getting a 250 OK back from the controller! Nice. \
&gt;  But I'm puzzled, because despite successfully adding the client auth, I can access \
&gt; my onion service *without* auth in Tor Browser. 
&gt; &lt;snip&gt;
&gt; 
&gt; So that all looks good. But what is weird, is if I go to \
&gt; http://gmdo3idszymnvfbuf2fm6miepearldgwbo7qfc4lsrw2kact2ka77kqd.onion/ , I see my \
&gt; 'hello world', I never had to add any client auth to Tor Browser. 
&gt; What am I doing wrong? How do I make the onion auth actually be 'required' since I \
&gt; succeeded at adding it? I was under the impression that as soon as I ran \
&gt; ONION_CLIENT_AUTH_ADD and got a success, from that point on, client auth would be \
&gt; *needed*. 
&gt; Maybe it's a problem with how I'm generating the keys? I had a bit of trouble \
&gt; figuring out how to send the base64 encoded private key. Even so, it accepts the \
&gt; private key, and yet it allows access without auth, which surprised me... 
&gt; It's probably really obvious but I've been working on this a while so I'm tired :) \
&gt; Time to embarass myself on a public mailing list.. 
&gt; Thanks in advance!
&gt; 

Hmm, this is a bit embarassing for both of us, but if I'm not mistaken
ONION_CLIENT_AUTH_ADD only controls the client-side of client auth
credentials. This is not obvious at all by the command name, and it only
becomes a bit clearer by reading the control-spec.txt...

We added that control port command so that the browser could present a
UX for client authorization.

AFAIK there is no control port command for adding service-side client
auth credentials. You will need to do this using the filesystem by using
the '&lt;HiddenServiceDir&gt;/authorized_clients/' directory as displayed by
the "CLIENT AUTHORIZATION" section of the manual... Or you will need to
implement the control port commands in tor :/

Sorry for the sad news here....... :/

PS: All this confusion stems from the name of this feature being "client
    authorization". The fact that the name includes the string "client"
    makes it confusing to specify whether functionality is client-side
    or service-side... We should rename that feature, but making it
    simply "authorization" is weird because then people are gonna wonder
    whether onion services offer no authentication by default. Perhaps
    we need to find a cooler name for this feature...
    
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200617095319</emailId><senderName>Miguel Jacq</senderName><senderEmail>mig@mig5.net</senderEmail><timestampReceived>2020-06-17 09:53:19-0400</timestampReceived><subject>Re: [tor-dev] Onion Client Auth on v3 descriptor via Control port</subject><body>

[Attachment #2 (multipart/signed)]


Hi George,

On Wed, Jun 17, 2020 at 12:37:18PM +0300, George Kadianakis wrote:
&gt; 
&gt; Hmm, this is a bit embarassing for both of us, but if I'm not mistaken
&gt; ONION_CLIENT_AUTH_ADD only controls the client-side of client auth
&gt; credentials. This is not obvious at all by the command name, and it only
&gt; becomes a bit clearer by reading the control-spec.txt...
&gt; 
&gt; We added that control port command so that the browser could present a
&gt; UX for client authorization.

Ahahahah. Riiight, thanks for that clarification. This whole time I indeed thought \
this was a novel way for adding Client Auth for v3 onions via the control port.

I had been reading the rend-spec-v3 \
https://github.com/torproject/torspec/blob/master/rend-spec-v3.txt 

G.2.1 'Service side' says '[XXX figure out control port command format]' and I \
figured it just hadn't been updated to reflect the new command. I hadn't even thought \
to read the control spec..

&gt; 
&gt; AFAIK there is no control port command for adding service-side client
&gt; auth credentials. You will need to do this using the filesystem by using
&gt; the '&lt;HiddenServiceDir&gt;/authorized_clients/' directory as displayed by
&gt; the "CLIENT AUTHORIZATION" section of the manual... Or you will need to
&gt; implement the control port commands in tor :/
&gt; 
&gt; Sorry for the sad news here....... :/

Okay, thanks for all the clarification. Indeed, OnionShare uses purely ephemeral \
onions, so the standard filesystem method won't work (unless we switch to that).

A shame it can't be as easy as the basic_auth method for v2 onions! But it's not the \
same auth, so I understand :)

&gt; PS: All this confusion stems from the name of this feature being "client
&gt; authorization". The fact that the name includes the string "client"
&gt; makes it confusing to specify whether functionality is client-side
&gt; or service-side... We should rename that feature, but making it
&gt; simply "authorization" is weird because then people are gonna wonder
&gt; whether onion services offer no authentication by default. Perhaps
&gt; we need to find a cooler name for this feature...
&gt; 

OnionShare called v2 client auth 'Stealth Mode'. But that was really just because it \
was understood that v2 descriptors were discoverable.

On the other hand, OnionShare now uses HTTP basic auth for both v2 and v3 onions, so \
it's not all bad.

Cheers,
Mig


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200615181325</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-06-15 18:13:25-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/signed)]


On 15 Jun (12:34:17), David Goulet wrote:
&gt; This effectively means that from _today_ (June 11th 2020), the Internet has
&gt; around 15 months to migrate from v2 to v3 once and for all.

Typo: June 11th 2020 --&gt; June 15th 2020 :)

David

-- 
262Gy/4o+HGG/7ELoDp1drRojN33l7AZaBoRHN6mjXY=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200616083102</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2020-06-16 08:31:02-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

On Mon, Jun 15, 2020 at 12:34:17PM -0400, David Goulet wrote:
&gt;   1) September 15th, 2020
&gt;      0.4.4.x: Tor will start warning onion service operators and clients that
&gt;               v2 is deprecated and will be obsolete in version 0.4.6

Thanks David. "Late 2020" is also a good timeframe for Tor Browser to
learn how to warn users when they visit a v2 onion service.

That is, we can't just change the underlying Tor proxy program to write
warnings in a log file. We need to improve the user flow for popular
Tor-using apps, starting with Tor Browser and maybe continuing to other
common Tor-using apps we appreciate such as Brave.

I recognize that the Tor Browser dev team has their hands full with
keeping up with Mozilla's changes while trying to improve things for
mobile while having not enough funded developers for those tasks. All
the more reason to highlight this need early, and to do as much of the
supporting design/planning/strategy work as we can in other teams like
the UX team.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200616091546</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2020-06-16 09:15:46-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Roger Dingledine:
&gt; On Mon, Jun 15, 2020 at 12:34:17PM -0400, David Goulet wrote:
&gt;&gt;   1) September 15th, 2020
&gt;&gt;      0.4.4.x: Tor will start warning onion service operators and clients that
&gt;&gt;               v2 is deprecated and will be obsolete in version 0.4.6
&gt; 
&gt; Thanks David. "Late 2020" is also a good timeframe for Tor Browser to
&gt; learn how to warn users when they visit a v2 onion service.
&gt; 
&gt; That is, we can't just change the underlying Tor proxy program to write
&gt; warnings in a log file. We need to improve the user flow for popular
&gt; Tor-using apps, starting with Tor Browser and maybe continuing to other
&gt; common Tor-using apps we appreciate such as Brave.
&gt; 
&gt; I recognize that the Tor Browser dev team has their hands full with
&gt; keeping up with Mozilla's changes while trying to improve things for
&gt; mobile while having not enough funded developers for those tasks. All
&gt; the more reason to highlight this need early, and to do as much of the
&gt; supporting design/planning/strategy work as we can in other teams like
&gt; the UX team.

I just Created

https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/40001

(via email, yes, you don't need to click around anymore in a GUI to do
this kind of thing ;)).

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200616111512</emailId><senderName>meskio</senderName><senderEmail>meskio@sindominio.net</senderEmail><timestampReceived>2020-06-16 11:15:12-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/signed)]


Quoting Georg Koppen (2020-06-16 11:15:46)
&gt; Roger Dingledine:
&gt; &gt; On Mon, Jun 15, 2020 at 12:34:17PM -0400, David Goulet wrote:
&gt; &gt;&gt;   1) September 15th, 2020
&gt; &gt;&gt;      0.4.4.x: Tor will start warning onion service operators and clients that
&gt; &gt;&gt;               v2 is deprecated and will be obsolete in version 0.4.6
&gt; &gt; 
&gt; &gt; Thanks David. "Late 2020" is also a good timeframe for Tor Browser to
&gt; &gt; learn how to warn users when they visit a v2 onion service.
&gt; &gt; 
&gt; &gt; That is, we can't just change the underlying Tor proxy program to write
&gt; &gt; warnings in a log file. We need to improve the user flow for popular
&gt; &gt; Tor-using apps, starting with Tor Browser and maybe continuing to other
&gt; &gt; common Tor-using apps we appreciate such as Brave.
&gt; &gt; 
&gt; &gt; I recognize that the Tor Browser dev team has their hands full with
&gt; &gt; keeping up with Mozilla's changes while trying to improve things for
&gt; &gt; mobile while having not enough funded developers for those tasks. All
&gt; &gt; the more reason to highlight this need early, and to do as much of the
&gt; &gt; supporting design/planning/strategy work as we can in other teams like
&gt; &gt; the UX team.
&gt; 
&gt; I just Created
&gt; 
&gt; https://gitlab.torproject.org/tpo/applications/tor-browser/-/issues/40001
&gt; 
&gt; (via email, yes, you don't need to click around anymore in a GUI to do
&gt; this kind of thing ;)).

I'm wondering if it will make sense to use Onion-Location in V2 onion services 
to advertise the V3 onion. So existing known V2 services can use it to upgrade 
their users to V3. 

AFAIK right now tor-browser ignores the Onion-Location header if is already 
coming from an onion service. Will it make sense to stop ignoring it at least 
for V2 onion services?

-- 
meskio | https://meskio.net/
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
 My contact info: https://meskio.net/crypto.txt
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Nos vamos a Croatan.
["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAABCAAdFiEEs7M6f/ZpXzXMAQR+Urj1rJei2oYFAl7oqbUACgkQUrj1rJei
2oZjPw//RPmeGiX5fHd6ZdMsq0HjI5VcEM6at4c2txyhVOWhwNYLIpMJbx8GvWF2
uSuQ7+z0ofLsk/grCaamWRFr10xb0yxu2gzDVmTeMZ8rTPHV7E5C/KTNvjcgFlYl
jvyzg9r9rOAehJjs+EUtp3otmSDYdfWc8AHU3kokG7Rcr//zefxPDHxdGqNHqjEB
TtVZ467O5mmPE+4JwYj6YBnakIy1DUQv3M3AAQbFd5q01uhP8V78BHQ93jEEoJs7
5RPNqe+ONqgdraaQFkXRpqaFIoboFD1EFuU1yj7chsaFRddQVFK3mn5zjXdi7KkM
8i15WCylxYPHM5BCreEi2e6w82lrdvoiMZwNfPZDryXdvTtB9m+1Jc2U5xQdLcEj
E0H6mZGUNYbMa4vlL5k70a6FtA7imMAZqB2YW21MEiWfN6LyAToVEqgl6zej+3Gr
AD/BInKNPFsK66aBzJXagprk13/mPh/heFJtNwkScGqSVqZQ6T4mXhVmi4uCzdxz
/qcHr6r+2ksFCfOVgel46WwHJdWW5fFQX3tzb7g8OsVUMqoIhQNuT59HyVvktwhb
KaU+/tRavEl50TQO9RqUgw6MtQQtOx4ebyONOXAojuDIucGLCsZ31brrZvlukcpJ
VudDAtfDIBzMaJa7lMFmcOTjuymOQxIHNm8F7Vhmd3RUOJh1QbQ=
=A6FB
-----END PGP SIGNATURE-----


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200616121024</emailId><senderName>Alec Muffett</senderName><senderEmail>alec.muffett@gmail.com</senderEmail><timestampReceived>2020-06-16 12:10:24-0400</timestampReceived><subject>Re: [tor-dev] Onion Service v2 Deprecation Timeline</subject><body>

[Attachment #2 (multipart/alternative)]


On Tue, 16 Jun 2020 at 12:15, meskio &lt;meskio@sindominio.net&gt; wrote:

&gt; I'm wondering if it will make sense to use Onion-Location in V2 onion
&gt; services
&gt; to advertise the V3 onion. So existing known V2 services can use it to
&gt; upgrade
&gt; their users to V3.
&gt;
&gt; AFAIK right now tor-browser ignores the Onion-Location header if is
&gt; already
&gt; coming from an onion service. Will it make sense to stop ignoring it at
&gt; least
&gt; for V2 onion services?
&gt;

Or the site could just issue a Location header and/or explicit redirect to
the v3 service?

After all, if the v2 site is compromised to the point where that's a
problem, then there are larger issues / "game over", etc.

    -a
-- 
http://dropsafe.crypticide.com/aboutalecm

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Tue, 16 Jun 2020 at 12:15, meskio &lt;&lt;a \
href="mailto:meskio@sindominio.net"&gt;meskio@sindominio.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex"&gt;I'm \
wondering if it will make sense to use Onion-Location in V2 onion services &lt;br&gt; to \
advertise the V3 onion. So existing known V2 services can use it to upgrade &lt;br&gt; \
their users to V3. &lt;br&gt; &lt;br&gt;
AFAIK right now tor-browser ignores the Onion-Location header if is already &lt;br&gt;
coming from an onion service. Will it make sense to stop ignoring it at least &lt;br&gt;
for V2 onion services?&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Or the site could just \
issue a Location header and/or explicit redirect to the v3 \
service?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;After all, if the v2 site is compromised to the \
point where that's a problem, then there are larger issues / "game \
over", etc.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;      -a&lt;/div&gt;&lt;/div&gt;-- &lt;br&gt;&lt;div dir="ltr" \
class="gmail_signature"&gt;&lt;a href="http://dropsafe.crypticide.com/aboutalecm" \
target="_blank"&gt;http://dropsafe.crypticide.com/aboutalecm&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200618213249</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-06-18 21:32:49-0400</timestampReceived><subject>Re: [tor-dev] Reproducing #33598 "chutney does not fail on some SOCKS errors"</subject><body>

On Mon, 15 Jun 2020 14:06:37 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; This seems plausible, though 0.0.0.0:x will just be the local computer as well.
&gt; 
&gt; Maybe you could try routing to a known-unassigned address, or one that
&gt; Tor simply won't support, like the one from RFC 6666? 

From my understanding 0.0.0.0/32 is a special address that is not
supposed to be routable. But `ping 0.0.0.0` does seem to redirect it to
127.0.0.1 for whatever reason; it might be some odd Linux-specific
behaviour. I'll check for other known-unroutable addresses and try one
of them.

&gt; [...]
&gt; 
&gt; It's in Traffic.py, Source.handle_connect(), in this line:

Thanks, I'll take a look at it.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200622145244</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-06-22 14:52:44-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

Hello there,

here is another round of PoW revisions:
     https://github.com/asn-d6/torspec/tree/pow-over-intro
I'm inlining the full proposal in the end of this email.

Here is a changelog:
- Actually used tevador's EquiX scheme as our PoW scheme for now. This is still
  tentative, but I needed some ingredients to cook with so I went for it.
- Fold in David's performance measurements and use them to get some
  guesstimates on the default PoW difficulty etc.
- Enable overlapping seed system.
- Enrich the attack section of the proposal some more.
- Attempt to fix an effort estimation attack pointed by tevador.
- Added a bunch of "BLOCKER" tags around the proposal for things that we need
  to figure out or at least have some good intuition if we want to have
  guarantees that the proposal can work before we start implementing.

Here is what needs to happen next:

- David's performance measurements have been really useful, but they open a
  bunch of questions on auxiliary overheads. We are now performing more
  experiments to confirm the performance numbers we got and make sure we are
  not overshooting. I noted these issues down as BLOCKER in the proposal.
  While doing so we also found a pretty serious bug with our scheduler that we
  trying to fix:
     https://gitlab.torproject.org/tpo/core/tor/-/issues/40006
- Did not have time to think about the priority queue's max size. I added a
  BLOCKER about this in the [HANDLE_QUEUE] section.
- Did not have time to think about a minimum effort feature on the queue. I
  guess this also depends on the scheduler.
- Need to think more about the effort estimation logic and make sure that it
  can't backfire big time.
- Need to kill all the XXXs, TODOs and BLOCKERs.

Also, tevador let me know if you'd like me to add you as a co-author on the
proposal based on all your great feedback so far.

This is looking more and more plausible but let's wait for more data before we
seal the deal.

Thanks for all the feedback and looking forward to more!

---

Filename: xxx-pow-over-intro-v1
Title: A First Take at PoW Over Introduction Circuits
Author: George Kadianakis, Mike Perry, David Goulet
Created: 2 April 2020
Status: Draft

0. Abstract

  This proposal aims to thwart introduction flooding DoS attacks by introducing
  a dynamic Proof-Of-Work protocol that occurs over introduction circuits.

1. Motivation

  So far our attempts at limiting the impact of introduction flooding DoS
  attacks on onion services has been focused on horizontal scaling with
  Onionbalance, optimizing the CPU usage of Tor and applying congestion control
  using rate limiting. While these measures move the goalpost forward, a core
  problem with onion service DoS is that building rendezvous circuits is a
  costly procedure both for the service and for the network. For more
  information on the limitations of rate-limiting when defending against DDoS,
  see [REF_TLS_1].

  If we ever hope to have truly reachable global onion services, we need to
  make it harder for attackers to overload the service with introduction
  requests. This proposal achieves this by allowing onion services to specify
  an optional dynamic proof-of-work scheme that its clients need to participate
  in if they want to get served.

  With the right parameters, this proof-of-work scheme acts as a gatekeeper to
  block amplification attacks by attackers while letting legitimate clients
  through.

1.1. Related work

  For a similar concept, see the three internet drafts that have been proposed
  for defending against TLS-based DDoS attacks using client puzzles [REF_TLS].

1.2. Threat model [THREAT_MODEL]

1.2.1. Attacker profiles [ATTACKER_MODEL]

  This proposal is written to thwart specific attackers. A simple PoW proposal
  cannot defend against all and every DoS attack on the Internet, but there are
  adverary models we can defend against.

  Let's start with some adversary profiles:

  "The script-kiddie"

    The script-kiddie has a single computer and pushes it to its
    limits. Perhaps it also has a VPS and a pwned server. We are talking about
    an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
    consider the total cost for this attacker to be zero $.

  "The small botnet"

    The small botnet is a bunch of computers lined up to do an introduction
    flooding attack. Assuming 500 medium-range computers, we are talking about
    an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
    the upfront cost for this attacker to be about $400.

  "The large botnet"

    The large botnet is a serious operation with many thousands of computers
    organized to do this attack. Assuming 100k medium-range computers, we are
    talking about an attacker with total access to 200 Thz of CPU and 200 TB of
    RAM. The upfront cost for this attacker is about $36k.

  We hope that this proposal can help us defend against the script-kiddie
  attacker and small botnets. To defend against a large botnet we would need
  more tools in our disposal (see [FUTURE_DESIGNS]).

1.2.2. User profiles [USER_MODEL]

  We have attackers and we have users. Here are a few user profiles:

  "The standard web user"

    This is a standard laptop/desktop user who is trying to browse the
    web. They don't know how these defences work and they don't care to
    configure or tweak them. They are gonna use the default values and if the
    site doesn't load, they are gonna close their browser and be sad at Tor.
    They run a 2Ghz computer with 4GB of RAM.

  "The motivated user"

    This is a user that really wants to reach their destination. They don't
    care about the journey; they just want to get there. They know what's going
    on; they are willing to tweak the default values and make their computer do
    expensive multi-minute PoW computations to get where they want to be.

  "The mobile user"

    This is a motivated user on a mobile phone. Even tho they want to read the
    news article, they don't have much leeway on stressing their machine to do
    more computation.

  We hope that this proposal will allow the motivated user to always connect
  where they want to connect to, and also give more chances to the other user
  groups to reach the destination.

1.2.3. The DoS Catch-22 [CATCH22]

  This proposal is not perfect and it does not cover all the use cases. Still,
  we think that by covering some use cases and giving reachability to the
  people who really need it, we will severely demotivate the attackers from
  continuing the DoS attacks and hence stop the DoS threat all
  together. Furthermore, by increasing the cost to launch a DoS attack, a big
  class of DoS attackers will disappear from the map, since the expected ROI
  will decrease.

2. System Overview

2.1. Tor protocol overview

                                          +----------------------------------+
                                          |                                  |
   +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
   |Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
   +-------+         +-----------+        |Verifier|           |             |
                                          +--------+           |             |
                                          |                    |             |
                                          |                    |             |
                                          |         +----------v---------+   |
                                          |         |Intro Priority Queue|   |
                                          +---------+--------------------+---+
                                                           |  |  |
                                                Rendezvous |  |  |
                                                  circuits |  |  |
                                                           v  v  v



  The proof-of-work scheme specified in this proposal takes place during the
  introduction phase of the onion service protocol.

  The system described in this proposal is not meant to be on all the time, and
  should only be enabled by services when under duress. The percentage of
  clients receiving puzzles can also be configured based on the load of the
  service.

  In summary, the following steps are taken for the protocol to complete:

  1) Service encodes PoW parameters in descriptor [DESC_POW]
  2) Client fetches descriptor and computes PoW [CLIENT_POW]
  3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
  4) Service verifies PoW and queues introduction based on PoW effort \
[SERVICE_VERIFY]

2.2. Proof-of-work overview

2.2.1. Primitives

  For our proof-of-work function we will use the 'equix' scheme by tevador
  [REF_EQUIX].  Equix is an assymetric PoW function based on Equihash&lt;60,3&gt;. It
  features lightning fast verification speed, and also aims to minimize the
  assymetry between CPU and GPU. Furthermore, it's designed for this particular
  use-case and hence cryptocurrency miners are not incentivized to make
  optimized ASICs for it.

  {TODO: define verification/proof interface.}

  We tune equix in section [EQUIX_TUNING].

2.2.2. Dynamic PoW

  DoS is a dynamic problem where the attacker's capabilities constantly change,
  and hence we want our proof-of-work system to be dynamic and not stuck with a
  static difficulty setting. Hence, instead of forcing clients to go below a
  static target like in Bitcoin to be successful, we ask clients to "bid" using
  their PoW effort. Effectively, a client gets higher priority the higher
  effort they put into their proof-of-work. This is similar to how
  proof-of-stake works but instead of staking coins, you stake work.

  The benefit here is that legitimate clients who really care about getting
  access can spend a big amount of effort into their PoW computation, which
  should guarantee access to the service given reasonable adversary models. See
  [PARAM_TUNING] for more details about these guarantees and tradeoffs.

  As a way to improve reachability and UX, the service tries to estimate the
  effort needed for clients to get access at any given time and places it in
  the descriptor. See [EFFORT_ESTIMATION] for more details.

2.2.3. PoW effort

  For our dynamic PoW system to work, we will need to be able to compare PoW
  tokens with each other. To do so we define a function:
         unsigned effort(uint8_t *token)
  which takes as its argument a hash output token, interprets it as a
  bitstring, and returns the quotient of dividing a bitstring of 1s by it.

  So for example:
         effort(00000001100010101101) = 11111111111111111111 / 00000001100010101101
  or the same in decimal:
         effort(6317) = 1048575 / 6317 = 165.

  This definition of effort has the advantage of directly expressing the
  expected number of hashes that the client had to calculate to reach the
  effort. This is in contrast to the (cheaper) exponential effort definition of
  taking the number of leading zero bits.

3. Protocol specification

3.1. Service encodes PoW parameters in descriptor [DESC_POW]

  This whole protocol starts with the service encoding the PoW parameters in
  the 'encrypted' (inner) part of the v3 descriptor. As follows:

       "pow-params" SP type SP seed-b64 SP expiration-time NL

        [At most once]

        type: The type of PoW system used. We call the one specified here "v1"

        seed-b64: A random seed that should be used as the input to the PoW
                  hash function. Should be 32 random bytes encoded in base64
                  without trailing padding.

        suggested-effort: An unsigned integer specifying an effort value that
                  clients should aim for when contacting the service. See
                  [EFFORT_ESTIMATION] for more details here.

        expiration-time: A timestamp in "YYYY-MM-DD SP HH:MM:SS" format after
                         which the above seed expires and is no longer valid as
                         the input for PoW. It's needed so that the size of our
                         replay cache does not grow infinitely. It should be
                         set to RAND_TIME(now+7200, 900) seconds.

   The service should refresh its seed when expiration-time passes. The service
   SHOULD keep its previous seed in memory and accept PoWs using it to avoid
   race-conditions with clients that have an old seed. The service SHOULD avoid
   generating two consequent seeds that have a common 4 bytes prefix. See
   [INTRO1_POW] for more info.

   By RAND_TIME(ts, interval) we mean a time between ts-interval and ts, chosen
   uniformly at random.

3.2. Client fetches descriptor and computes PoW [CLIENT_POW]

  If a client receives a descriptor with "pow-params", it should assume that
  the service is expecting a PoW input as part of the introduction protocol.

  The client parses the descriptor and extracts the PoW parameters. It makes
  sure that the &lt;expiration-time&gt; has not expired and if it has, it needs to
  fetch a new descriptor.

  The client should then extract the &lt;suggested-effort&gt; field to configure its
  PoW 'target' (see [REF_TARGET]). The client SHOULD NOT accept 'target' values
  that will cause an infinite PoW computation. {XXX: How to enforce this?}

  To complete the PoW the client follows the following logic:

      a) Client generates 'nonce' as 16 random bytes.
      b) Client derives 'seed' by decoding 'seed-b64'.
      c) Client derives 'labeled_seed = seed + "TorV1PoW"'
      d) Client computes hash_output = XXX_POW(labeled_seed, nonce)
      e) Client checks if effort(hash_output) &gt;= target.
        e1) If yes, success! The client uses 'hash_output' as the puzzle
            solution and 'nonce' and 'seed' as its inputs.
        e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
            increments it by one, and goes back to step (d).

  At the end of the above procedure, the client should have a triplet
  (hash_output, seed, nonce) that can be used as the answer to the PoW
  puzzle. How quickly this happens depends solely on the 'target' parameter.

3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]

  Now that the client has an answer to the puzzle it's time to encode it into
  an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
  portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
  [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
  INTRODUCE1 cell only gets read by the onion service and is ignored by the
  introduction point.

  We propose a new EXT_FIELD_TYPE value:

     [01] -- PROOF_OF_WORK

   The EXT_FIELD content format is:

      POW_VERSION    [1 byte]
      POW_NONCE      [16 bytes]
      POW_SEED       [4 bytes]

   where:

    POW_VERSION is 1 for the protocol specified in this proposal
    POW_NONCE is 'nonce' from the section above
    POW_SEED is the first 4 bytes of the seed used

   This will increase the INTRODUCE1 payload size by 23 bytes since the
   extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
   present and currently set to 0 and the EXT_FIELD is 21 bytes. According to
   ticket #33650, INTRODUCE1 cells currently have more than 200 bytes
   available.

3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]

   When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
   should check its configuration on whether proof-of-work is required to
   complete the introduction. If it's not required, the extension SHOULD BE
   ignored. If it is required, the service follows the procedure detailed in
   this section.

   If the service requires the PROOF_OF_WORK extension but received an
   INTRODUCE1 cell without any embedded proof-of-work, the service SHOULD
   consider this cell as a zero-effort introduction for the purposes of the
   priority queue (see section [INTRO_QUEUE]).

3.4.1. PoW verification [POW_VERIFY]

   To verify the client's proof-of-work the service extracts (hash_output,
   seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:

   1) Use POW_SEED to figure out whether client is using current or previous seed.
   2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
   3) Verify that 'hash_output =?= XXX_POW(seed, nonce)

   If any of these steps fail the service MUST ignore this introduction request
   and abort the protocol.

   In this proposal we call the above steps the "top half" of introduction
   handling. If all the steps of the "top half" have passed, then the circuit
   is added to the introduction queue as detailed in section [INTRO_QUEUE].

3.4.1.1. Replay protection [REPLAY_PROTECTION]

  The service MUST NOT accept introduction requests with the same (seed, nonce)
  tuple. For this reason a replay protection mechanism must be employed.

  The simplest way is to use a simple hash table to check whether a (seed,
  nonce) tuple has been used before for the actiev duration of a
  seed. Depending on how long a seed stays active this might be a viable
  solution with reasonable memory/time overhead.

  If there is a worry that we might get too many introductions during the
  lifetime of a seed, we can use a Bloom filter as our replay cache
  mechanism. The probabilistic nature of Bloom filters means that sometimes we
  will flag some connections as replays even if they are not; with this false
  positive probability increasing as the number of entries increase. However,
  with the right parameter tuning this probability should be negligible and
  well handled by clients. {TODO: Figure bloom filter}

3.4.2. The Introduction Queue  [INTRO_QUEUE]

3.4.2.1. Adding introductions to the introduction queue [ADD_QUEUE]

  When PoW is enabled and a verified introduction comes through, the service
  instead of jumping straight into rendezvous, queues it and prioritizes it
  based on how much effort was devoted by the client to PoW. This means that
  introduction requests with high effort should be prioritized over those with
  low effort.

  To do so, the service maintains an "introduction priority queue" data
  structure. Each element in that priority queue is an introduction request,
  and its priority is the effort put into its PoW:

  When a verified introduction comes through, the service uses the effort()
  function with hash_output as its input, and uses the output to place requests
  into the right position of the priority_queue: The bigger the effort, the
  more priority it gets in the queue. If two elements have the same effort, the
  older one has priority over the newer one.

3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]

  The service should handle introductions by pulling from the introduction
  queue. We call this part of introduction handling the "bottom half" because
  most of the computation happens in this stage. For a description of how we
  expect such a system to work in Tor, see [TOR_SCHEDULER] section.

  {TODO: BLOCKER: What's the max size of the queue? Do we trim it, or do
  we just stop adding new requests when it reaches max size? Can we use WRED?
  Trimming is currently used EFFORT_ESTIMATION, so if we don't do it we need to
  find a different way to estimate effort. See tevador's [REF_TEVADOR_2] email.}

3.4.3. PoW effort estimation [EFFORT_ESTIMATION]

  The service starts with a default suggested-effort value of 5000 (see
  [EQUIX_DIFFICULTY] section for more info).

  Then during its operation the service continuously keeps track of the
  received PoW cell efforts to inform its clients of the effort they should put
  in their introduction to get service. The service informs the clients by
  using the &lt;suggested-effort&gt; field in the descriptor.

  Everytime the service handles an introduction request from the priority queue
  in [HANDLE_QUEUE], the service adds the request's effort to a sorted
  'handled-requests-efforts' list. Everytime the service trims its priority
  queue it adds the median of the trimmed requests' to a sorted
  'trimmed-requests-median-efforts' list.

  Then every 'hs-pow-desc-upload-rate-limit' seconds (which is controlled
  through a consensus parameter and has a default value of 300 seconds) and
  while the DoS feature is enabled, the service updates its &lt;suggested-effort&gt;
  value as follows:
  - If the service's current &lt;suggested-effort&gt; value is lower than the
    median of the 'trimmed-requests-median-efforts' list, then set
    &lt;suggested-effort&gt; to that median (i.e. increase suggested-effort).
  - *Else* if the service's current &lt;suggested-effort&gt; value is higher than the
    median of the 'handled-requests-efforts' list, then set &lt;suggested-effort&gt;
    to that median (i.e. lower suggested-effort).
  - Either way, clear 'handled-requests-efforts' and
    'trimmed-requests-median-efforts'.

  The above two operations are meant to balance the suggested effort based on
  the requests residing in the priority queue. If the priority queue is filled
  with high-effort requests, make the suggested effort higher. And when all the
  high-effort requests get handled and the priority queue is back to normal
  operation, relax the suggested effort to lower levels.

  Given the way the algorithm works above, priority is given to the operation
  that increases the suggested-effort. Also the values are taken as medians
  over a period of time to avoid [ATTACK_EFFORT] attacks where the attacker
  changes her behavior right before the descriptor upload to influence the
  &lt;suggested-effort&gt;.

  {XXX: BLOCKER: Figure out of this system makes sense}

  The suggested-effort is not a hard limit to the efforts that are accepted by
  the service, and it's only meant to serve as a guideline for clients to
  reduce the number of unsuccessful requests that get to the service. The
  service still adds requests with lower effort than suggested-effort to the
  priority queue in [ADD_QUEUE].

  {XXX: Another approach would be to use the maximum value instead of the
  median here. This would give a more surefire effort estimation, but it could
  also cause attacks where an adversary spends 1 hour to make a single
  introduction with a huge PoW and then denies access to all clients for 5
  minutes.}

  {XXX: Does this mean that this system can auto-enable and auto-disable the
  DoS subsystem with reasonable accuracy?}

3.4.3.1. Updating descriptor with new suggested effort

  Every 'hs-pow-desc-upload-rate-limit' seconds the service should upload a new
  descriptor with a new suggested-effort value.

  The service should avoid uploading descriptors too often to avoid overwheming
  the HSDirs. The service SHOULD NOT upload descriptors more often than
  'hs-pow-desc-upload-rate-limit'. The service SHOULD NOT upload a new
  descriptor if the suggested-effort value changes by less than 15%.

  {XXX: Is this too often? Perhaps we can set different limits for when the
  difficulty goes up and different for when it goes down. It's more important
  to update the descriptor when the difficulty goes up.}

  {XXX: What attacks are possible here? Can the attacker intentionally hit this
  rate-limit and then influence the suggested effort so that clients do not
  learn about the new effort?}

4. Client behavior [CLIENT_BEHAVIOR]

  This proposal introduces a bunch of new ways where a legitimate client can
  fail to reach the onion service.

  Furthermore, there is currently no end-to-end way for the onion service to
  inform the client that the introduction failed. The INTRO_ACK cell is not
  end-to-end (it's from the introduction point to the client) and hence it does
  not allow the service to inform the client that the rendezvous is never gonna
  occur.

  For this reason we need to define some client behaviors to work around these
  issues.

4.1. Clients handling timeouts [CLIENT_TIMEOUT]

  Alice can fail to reach the onion service if her introduction request gets
  trimmed off the priority queue in [HANDLE_QUEUE], or if the service does not
  get through its priority queue in time and the connection times out.

  {XXX: BLOCKER: How should timeout values change here since the priority queue will
  cause bigger delays than usual to rendezvous?}

  This section presents a heuristic method for the client getting service even
  in such scenarios.

  If the rendezvous request times out, the client SHOULD fetch a new descriptor
  for the service to make sure that it's using the right suggested-effort for
  the PoW and the right PoW seed. The client SHOULD NOT fetch service
  descriptors more often than every 'hs-pow-desc-fetch-rate-limit' seconds
  (which is controlled through a consensus parameter and has a default value of
  600 seconds).

  {XXX: Is this too rare? Too often?}

  When the client fetches a new descriptor, it should try connecting to the
  service with the new suggested-effort and PoW seed. If that doesn't work, it
  should double the effort and retry. The client should keep on
  doubling-and-retrying until it manages to get service, or its able to fetch a
  new descriptor again.

  {XXX: This means that the client will keep on spinning and
  doubling-and-retrying for a service under this situation. There will never be
  a "Client connection timed out" page for the user. Is this good? Is this bad?
  Should we stop doubling-and-retrying after some iterations? Or should we
  throw a custom error page to the user, and ask the user to stop spinning
  whenever they want?}

4.3. Other descriptor issues

  Another race condition here is if the service enables PoW, while a client has
  a cached descriptor. How will the client notice that PoW is needed? Does it
  need to fetch a new descriptor? Should there be another feedback mechanism?

5. Attacker strategies [ATTACK_META]

  Now that we defined our protocol we need to start tweaking the various
  knobs. But before we can do that, we first need to understand a few
  high-level attacker strategies to see what we are fighting against.

5.1.1. Overwhelm PoW verification (aka "Overwhelm top half") [ATTACK_TOP_HALF]

  A basic attack here is the adversary spamming with bogus INTRO cells so that
  the service does not have computing capacity to even verify the
  proof-of-work. This adversary tries to overwhelm the procedure in the
  [POW_VERIFY] section.

  That's why we need the PoW algorithm to have a cheap verification time so
  that this attack is not possible: we tune this PoW parameter in section
  [POW_TUNING_VERIFICATION].

5.1.2. Overwhelm rendezvous capacity (aka "Overwhelm bottom half") \
[ATTACK_BOTTOM_HALF]

  Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
  effective strategy for the attacker is to totally overwhelm the queue
  processing by sending more high-effort introductions than the onion service
  can handle at any given tick. This adversary tries to overwhelm the procedure
  in the [HANDLE_QUEUE] section.

  To do so, the attacker would have to send at least 20 high-effort
  introduction cells every 100ms, where high-effort is a PoW which is above the
  estimated level of "the motivated user" (see [USER_MODEL]).

  An easier attack for the adversary, is the same strategy but with
  introduction cells that are all above the comfortable level of "the standard
  user" (see [USER_MODEL]). This would block out all standard users and only
  allow motivated users to pass.

5.1.3. Gaming the effort estimation logic [ATTACK_EFFORT]

  Another way to beat this system is for the attacker to game the effort
  estimation logic (see [EFFORT_ESTIMATION]). Essentialy, there are two attacks
  that we are trying to avoid:

  - Attacker sets descriptor suggested-effort to a very high value effectively
    making it impossible for most clients to produce a PoW token in a
    reasonable timeframe.
  - Attacker sets descriptor suggested-effort to a very small value so that
    most clients aim for a small value while the attacker comfortably launches
    an [ATTACK_BOTTOM_HALF] using medium effort PoW (see [REF_TEVADOR_1])

5.1.4. Precomputed PoW attack

  The attacker may precompute many valid PoW nonces and submit them all at once
  before the current seed expires, overwhelming the service temporarily even
  using a single computer. The current scheme gives the attackers 4 hours to
  launch this attack since each seed lasts 2 hours and the service caches two
  seeds.

  An attacker with this attack might be aiming to DoS the service for a limited
  amount of time, or to cause an [ATTACK_EFFORT] attack.

6. Parameter tuning [POW_TUNING]

  There are various parameters in this PoW system that need to be tuned:

  We first start by tuning the time it takes to verify a PoW token. We do this
  first because it's fundamental to the performance of onion services and can
  turn into a DoS vector of its own. We will do this tuning in a way that's
  agnostic to the chosen PoW function.

  We will then move towards analyzing the default difficulty setting for our
  PoW system. That defines the expected time for clients to succeed in our
  system, and the expected time for attackers to overwhelm our system. Same as
  above we will do this in a way that's agnostic to the chosen PoW function.

  Finally, using those two pieces we will tune our PoW function and pick the
  right default difficulty setting. At the end of this section we will know the
  resources that an attacker needs to overwhelm the onion service, the
  resources that the service needs to verify introduction requests, and the
  resources that legitimate clients need to get to the onion service.

6.1. PoW verification [POW_TUNING_VERIFICATION]

  Verifying a PoW token is the first thing that a service does when it receives
  an INTRODUCE2 cell and it's detailed in section [POW_VERIFY]. This
  verification happens during the "top half" part of the process. Every
  milisecond spent verifying PoW adds overhead to the already existing "top
  half" part of handling an introduction cell. Hence we should be careful to
  add minimal overhead here so that we don't enable attacks like [ATTACK_TOP_HALF].

  During our performance measurements in [TOR_MEASUREMENTS] we learned that the
  "top half" takes about 0.26 msecs in average, without doing any sort of PoW
  verification. Using that value we compute the following table, that describes
  the number of cells we can queue per second (aka times we can perform the
  "top half" process) for different values of PoW verification time:

      +---------------------+-----------------------+--------------+
      |PoW Verification Time| Total "top half" time | Cells Queued |
      |                     |                       |  per second  |
      |---------------------|-----------------------|--------------|
      |    0     msec       |    0.26      msec     |    3846      |
      |    1     msec       |    1.26      msec     |    793       |
      |    2     msec       |    2.26      msec     |    442       |
      |    3     msec       |    3.26      msec     |    306       |
      |    4     msec       |    4.26      msec     |    234       |
      |    5     msec       |    5.26      msec     |    190       |
      |    6     msec       |    6.26      msec     |    159       |
      |    7     msec       |    7.26      msec     |    137       |
      |    8     msec       |    8.26      msec     |    121       |
      |    9     msec       |    9.26      msec     |    107       |
      |    10    msec       |    10.26     msec     |    97        |
      +---------------------+-----------------------+--------------+

  Here is how you can read the table above:

  - For a PoW function with a 1ms verification time, an attacker needs to send
    793 dummy introduction cells per second to succeed in a [ATTACK_TOP_HALF] attack.

  - For a PoW function with a 2ms verification time, an attacker needs to send
    442 dummy introduction cells per second to succeed in a [ATTACK_TOP_HALF] attack.

  - For a PoW function with a 10ms verification time, an attacker needs to send
    97 dummy introduction cells per second to succeed in a [ATTACK_TOP_HALF] attack.

  Whether an attacker can succeed at that depends on the attacker's resources,
  but also on the network's capacity.
  {TODO: BLOCKER: Need to investigate this and see if it's possible}

  Our purpose here is to have the smallest PoW verification overhead possible
  that also allows us to achieve all our other goals.

  [Note that the table above is simply the result of a naive multiplication and
  does not take into account all the auxiliary overheads that happen every
  second like the time to invoke the mainloop, the bottom-half processes, or
  pretty much anything other than the "top-half" processing.

  During our measurements the time to handle INTRODUCE2 cells dominates any
  other action time: There might be events that require a long processing time,
  but these are pretty infrequent (like uploading a new HS descriptor) and
  hence over a long time they smooth out. Hence extrapolating the total cells
  queued per second based on a single "top half" time seems like good enough to
  get some initial intuition. That said, the values of "Cells queued per
  second" from the table above, are likely much smaller than displayed above
  because of all the auxiliary overheads.]

  {TODO: BLOCKER: Figure out auxiliary overheads in real scenario}

6.2. PoW difficulty analysis [POW_DIFFICULTY_ANALYSIS]

  The difficulty setting of our PoW basically dictates how difficult it should
  be to get a success in our PoW system. An attacker who can get many successes
  per second can pull a successfull [ATTACK_BOTTOM_HALF] attack against our
  system.

  In classic PoW systems, "success" is defined as getting a hash output below
  the "target". However, since our system is dynamic, we define "success" as an
  abstract high-effort computation.

  Our system is dynamic but we still need a default difficulty settings that
  will define the metagame and be used for bootstrapping the system. The client
  and attacker can still aim higher or lower but for UX purposes and for
  analysis purposes we do need to define a default difficulty.

6.2.1. Analysis based on adversary power

  In this section we will try to do an analysis of PoW difficulty without using
  any sort of Tor-related or PoW-related benchmark numbers.

  We created the table (see [REF_TABLE]) below which shows how much time a
  legitimate client with a single machine should expect to burn before they get
  a single success. The x-axis is how many successes we want the attacker to be
  able to do per second: the more successes we allow the adversary, the more
  they can overwhelm our introduction queue. The y-axis is how many machines
  the adversary has in her disposal, ranging from just 5 to 1000.

       ===============================================================
       |    Expected Time (in seconds) Per Success For One Machine   |
 ===========================================================================
 |                                                                          |
 |   Attacker Succeses        1       5       10      20      30      50    |
 |       per second                                                         |
 |                                                                          |
 |            5               5       1       0       0       0       0     |
 |            50              50      10      5       2       1       1     |
 |            100             100     20      10      5       3       2     |
 | Attacker   200             200     40      20      10      6       4     |
 |  Boxes     300             300     60      30      15      10      6     |
 |            400             400     80      40      20      13      8     |
 |            500             500     100     50      25      16      10    |
 |            1000            1000    200     100     50      33      20    |
 |                                                                          |
 ============================================================================

  Here is how you can read the table above:

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
    success per second, then a legitimate client with a single box should be
    expected to spend 1000 seconds getting a single success.

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 200 seconds getting a single success.

  - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 100 seconds getting a single success.

  - If an adversary has access to 50 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 10 seconds getting a single success.

  - If an adversary has access to 5 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 1 seconds getting a single success.

  With the above table we can create some profiles for default values of our
  PoW difficulty. So for example, we can use the last case as the default
  parameter for Tor Browser, and then create three more profiles for more
  expensive cases, scaling up to the first case which could be hardest since
  the client is expected to spend 15 minutes for a single introduction.

6.2.2. Analysis based on Tor's performance [POW_DIFFICULTY_TOR]

  To go deeper here, we can use the performance measurements from
  [TOR_MEASUREMENTS] to get a more specific intuition on the default
  difficulty. In particular, we learned that completely handling an
  introduction cell takes 5.55 msecs in average. Using that value, we can
  compute the following table, that describes the number of introduction cells
  we can handle per second for different values of PoW verification:

      +---------------------+-----------------------+--------------+
      |PoW Verification Time| Total time to handle  | Cells handled|
      |                     |   introduction cell   |  per second  |
      |---------------------|-----------------------|--------------|
      |    0      msec      |    5.55        msec   |    180.18    |
      |    1      msec      |    6.55        msec   |    152.67    |
      |    2      msec      |    7.55        msec   |    132.45    |
      |    3      msec      |    8.55        msec   |    116.96    |
      |    4      msec      |    9.55        mesc   |    104.71    |
      |    5      msec      |    10.55       msec   |    94.79     |
      |    6      msec      |    11.55       msec   |    86.58     |
      |    7      msec      |    12.55       msec   |    79.68     |
      |    8      msec      |    13.55       msec   |    73.80     |
      |    9      msec      |    14.55       msec   |    68.73     |
      |    10     msec      |    15.55       msec   |    64.31     |
      +---------------------+-----------------------+--------------+

  Here is how you can read the table above:

  - For a PoW function with a 1ms verification time, an attacker needs to send
    152 high-effort introduction cells per second to succeed in a
    [ATTACK_BOTTOM_HALF] attack.

  - For a PoW function with a 10ms verification time, an attacker needs to send
    64 high-effort introduction cells per second to succeed in a
    [ATTACK_BOTTOM_HALF] attack.

  We can use this table to specify a default difficulty that won't allow our
  target adversary to succeed in an [ATTACK_BOTTOM_HALF] attack.

  Of course, when it comes to this table, the same disclaimer as in section
  [POW_TUNING_VERIFICATION] is valid. That is, the above table is just a
  theoretical extrapolation and we expect the real values to be much lower
  since they depend on auxiliary processing overheads, and on the network's
  capacity.
  {TODO: BLOCKER: Figure out auxiliary overheads here too}

6.3. Tuning equix difficulty [EQUIX_DIFFICULTY]

  The above two sections were not depending on a particular PoW scheme. They
  gave us an intuition on the values we are aiming for in terms of verification
  speed and PoW difficulty. Now we need to make things concrete:

  As described in section [EFFORT_ESTIMATION] we start the service with a
  default suggested-effort value of 5000. Given the benchmarks of EquiX
  [REF_EQUIX] this should take about 2 to 3 seconds on a modern CPU.

  With this default difficulty setting and given the table in
  [POW_DIFFICULTY_ANALYSIS] this means that an attacker with 50 boxes will be
  able to get about 20 successful PoWs per second, and an attacker with 100
  boxes about 40 successful PoWs per second.

  Then using the table in [POW_DIFFICULTY_TOR] we can see that the number of
  attacker's successes is not enough to overwhelm the service through an
  [ATTACK_BOTTOM_HALF] attack. That is, an attacker would need to do about 152
  introductions per second to overwhelm the service, whereas they can only do
  40 with 100 boxes.

  {TODO: BLOCKER: Still, the [POW_DIFFICULTY_TOR] disclaimer about auxiliary overhead \
is  too true and we need to figure it out. For now this section remains just to
  show the methodology and not to be hard on the numbers}

7. Discussion

7.1. UX

  This proposal has user facing UX consequences.

  Here is some UX improvements that don't need user-input:

  - Primarily, there should be a way for Tor Browser to display to users that
    additional time (and resources) will be needed to access a service that is
    under attack. Depending on the design of the system, it might even be
    possible to estimate how much time it will take.

  And here are a few UX approaches that will need user-input and have an
  increasing engineering difficulty. Ideally this proposal will not need
  user-input and the default behavior should work for almost all cases.

  a) Tor Browser needs a "range field" which the user can use to specify how
     much effort they want to spend in PoW if this ever occurs while they are
     browsing. The ranges could be from "Easy" to "Difficult", or we could try
     to estimate time using an average computer. This setting is in the Tor
     Browser settings and users need to find it.

  b) We start with a default effort setting, and then we use the new onion
     errors (see #19251) to estimate when an onion service connection has
     failed because of DoS, and only then we present the user a "range field"
     which they can set dynamically. Detecting when an onion service connection
     has failed because of DoS can be hard because of the lack of feedback (see
     [CLIENT_BEHAVIOR])

  c) We start with a default effort setting, and if things fail we
     automatically try to figure out an effort setting that will work for the
     user by doing some trial-and-error connections with different effort
     values. Until the connection succeeds we present a "Service is
     overwhelmed, please wait" message to the user.

7.2. Future work [FUTURE_WORK]

7.2.1. Incremental improvements to this proposal

  There are various improvements that can be done in this proposal, and while
  we are trying to keep this v1 version simple, we need to keep the design
  extensible so that we build more features into it. In particular:

  - End-to-end introduction ACKs

    This proposal suffers from various UX issues because there is no end-to-end
    mechanism for an onion service to inform the client about its introduction
    request. If we had end-to-end introduction ACKs many of the problems from
    [CLIENT_BEHAVIOR] would be aleviated. The problem here is that end-to-end
    ACKs require modifications on the introduction point code and a network
    update which is a lengthy process.

  - Multithreading scheduler

    Our scheduler is pretty limited by the fact that Tor has a single-threaded
    design. If we improve our multithreading support we could handle a much
    greater amount of introduction requests per second.

7.2.2. Future designs [FUTURE_DESIGNS]

  This is just the beginning in DoS defences for Tor and there are various
  futured designs and schemes that we can investigate. Here is a brief summary
  of these:

  "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
         schemes like MTP-argon2 or Itsuku to make it even harder for
         adversaries to create successful PoWs. Unfortunately these schemes
         have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
         See #31223 for more details.

  "Third-party anonymous credentials" -- We can use anonymous credentials and a
         third-party token issuance server on the clearnet to issue tokens
         based on PoW or CAPTCHA and then use those tokens to get access to the
         service. See [REF_CREDS] for more details.

  "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
         where we present a hard puzzle to the user when connecting to the
         onion service, and if they solve it we then give the user a bunch of
         anonymous tokens that can be used in the future. This can all happen
         between the client and the service without a need for a third party.

  All of the above approaches are much more complicated than this proposal, and
  hence we want to start easy before we get into more serious projects.

7.3. Environment

  We love the environment! We are concerned of how PoW schemes can waste energy
  by doing useless hash iterations. Here is a few reasons we still decided to
  pursue a PoW approach here:

  "We are not making things worse" -- DoS attacks are already happening and
      attackers are already burning energy to carry them out both on the
      attacker side, on the service side and on the network side. We think that
      asking legitimate clients to carry out PoW computations is not gonna
      affect the equation too much, since an attacker right now can very
      quickly cause the same damage that hundreds of legitimate clients do a
      whole day.

  "We hope to make things better" -- The hope is that proposals like this will
      make the DoS actors go away and hence the PoW system will not be used. As
      long as DoS is happening there will be a waste of energy, but if we
      manage to demotivate them with technical means, the network as a whole
      will less wasteful. Also see [CATCH22] for a similar argument.

8. Acknowledgements

  Thanks a lot to tevador for the various improvements to the proposal and for
  helping us understand and tweak the RandomX scheme.

  Thanks to Solar Designer for the help in understanding the current PoW
  landscape, the various approaches we could take, and teaching us a few neat
  tricks.

Appendix A.  Little-t tor introduction scheduler

  This section describes how we will implement this proposal in the "tor"
  software (little-t tor).

  The following should be read as if tor is an onion service and thus the end
  point of all inbound data.

A.1. The Main Loop [MAIN_LOOP]

  Tor uses libevent for its mainloop. For network I/O operations, a mainloop
  event is used to inform tor if it can read on a certain socket, or a
  connection object in tor.

  From there, this event will empty the connection input buffer (inbuf) by
  extracting and processing a cell at a time. The mainloop is single threaded
  and thus each cell is handled sequentially.

  Processing an INTRODUCE2 cell at the onion service means a series of
  operations (in order):

    1) Unpack cell from inbuf to local buffer.

    2) Decrypt cell (AES operations).

    3) Parse cell header and process it depending on its RELAY_COMMAND.

    4) INTRODUCE2 cell handling which means building a rendezvous circuit:
        i)  Path selection
        ii) Launch circuit to first hop.

    5) Return to mainloop event which essentially means back to step (1).

  Tor will read at most 32 cells out of the inbuf per mainloop round.

A.2. Requirements for PoW

  With this proposal, in order to prioritize cells by the amount of PoW work
  it has done, cells can _not_ be processed sequentially as described above.

  Thus, we need a way to queue a certain number of cells, prioritize them and
  then process some cell(s) from the top of the queue (that is, the cells that
  have done the most PoW effort).

  We thus require a new cell processing flow that is _not_ compatible with
  current tor design. The elements are:

    - Validate PoW and place cells in a priority queue of INTRODUCE2 cells (as
      described in section [INTRO_QUEUE]).

    - Defer "bottom half" INTRO2 cell processing for after cells have been
      queued into the priority queue.

A.3. Proposed scheduler [TOR_SCHEDULER]

  The intuitive way to address the A.2 requirements would be to do this
  simple and naive approach:

    1) Mainloop: Empty inbuf INTRODUCE2 cells into priority queue

    2) Process all cells in pqueue

    3) Goto (1)

  However, we are worried that handling all those cells before returning to the
  mainloop opens possibilities of attack by an adversary since the priority
  queue is not gonna be kept up to date while we process all those cells. This
  means that we might spend lots of time dealing with introductions that don't
  deserve it. See [BOTTOM_HALF_SCHEDULER] for more details.

  We thus propose to split the INTRODUCE2 handling into two different steps:
  "top half" and "bottom half" process, as also mentioned in [POW_VERIFY]
  section above.

A.3.1. Top half and bottom half scheduler

  The top half process is responsible for queuing introductions into the
  priority queue as follows:

    a) Unpack cell from inbuf to local buffer.

    b) Decrypt cell (AES operations).

    c) Parse INTRODUCE2 cell header and validate PoW.

    d) Return to mainloop event which essentially means step (1).

  The top-half basically does all operations of section [MAIN_LOOP] except from (4).

  An then, the bottom-half process is responsible for handling introductions
  and doing rendezvous. To achieve this we introduce a new mainloop event to
  process the priority queue _after_ the top-half event has completed. This new
  event would do these operations sequentially:

    a) Pop INTRODUCE2 cell from priority queue.

    b) Parse and process INTRODUCE2 cell.

    c) End event and yield back to mainloop.

A.3.2. Scheduling the bottom half process [BOTTOM_HALF_SCHEDULER]

  The question now becomes: when should the "bottom half" event get triggered
  from the mainloop?

  We propose that this event is scheduled in when the network I/O event
  queues at least 1 cell into the priority queue. Then, as long as it has a
  cell in the queue, it would re-schedule itself for immediate execution
  meaning at the next mainloop round, it would execute again.

  The idea is to try to empty the queue as fast as it can in order to provide a
  fast response time to an introduction request but always leave a chance for
  more cells to appear between cell processing by yielding back to the
  mainloop. With this we are aiming to always have the most up-to-date version
  of the priority queue when we are completing introductions: this way we are
  prioritizing clients that spent a lot of time and effort completing their PoW.

  If the size of the queue drops to 0, it stops scheduling itself in order to
  not create a busy loop. The network I/O event will re-schedule it in time.

  Notice that the proposed solution will make the service handle 1 single
  introduction request at every main loop event. However, when we do
  performance measurements we might learn that it's preferable to bump the
  number of cells in the future from 1 to N where N &lt;= 32.

A.4 Performance measurements

  This section will detail the performance measurements we've done on tor.git
  for handling an INTRODUCE2 cell and then a discussion on how much more CPU
  time we can add (for PoW validation) before it badly degrades our
  performance.

A.4.1 Tor measurements [TOR_MEASUREMENTS]

  In this section we will derive measurement numbers for the "top half" and
  "bottom half" parts of handling an introduction cell.

  These measurements have been done on tor.git at commit
  80031db32abebaf4d0a91c01db258fcdbd54a471.

  We've measured several set of actions of the INTRODUCE2 cell handling process
  on Intel(R) Xeon(R) CPU E5-2650 v4. Our service was accessed by an array of
  clients that sent introduction requests for a period of 60 seconds.

  1. Full Mainloop Event

     We start by measuring the full time it takes for a mainloop event to
     process an inbuf containing INTRODUCE2 cells. The mainloop event processed
     2.42 cells per invocation on average during our measurements.

     Total measurements: 3279

       Min: 0.30 msec - 1st Q.: 5.47 msec - Median: 5.91 msec
       Mean: 13.43 msec - 3rd Q.: 16.20 msec - Max: 257.95 msec

  2. INTRODUCE2 cell processing (bottom-half)

     We also measured how much time the "bottom half" part of the process
     takes. That's the heavy part of processing an introduction request as seen
     in step (4) of the [MAIN_LOOP] section:

     Total measurements: 7931

       Min: 0.28 msec - 1st Q.: 5.06 msec - Median: 5.33 msec
       Mean: 5.29 msec - 3rd Q.: 5.57 msec - Max: 14.64 msec

  3. Connection data read (top half)

     Now that we have the above pieces, we can use them to measure just the
     "top half" part of the procedure. That's when bytes are taken from the
     connection inbound buffer and parsed into an INTRODUCE2 cell where basic
     validation is done.

     There is an average of 2.42 INTRODUCE2 cells per mainloop event and so we
     divide that by the full mainloop event mean time to get the time for one
     cell. From that we substract the "bottom half" mean time to get how much
     the "top half" takes:

        =&gt; 13.43 / (7931 / 3279) = 5.55
        =&gt; 5.55 - 5.29 = 0.26

        Mean: 0.26 msec

  To summarize, during our measurements the average number of INTRODUCE2 cells
  a mainloop event processed is ~2.42 cells (7931 cells for 3279 mainloop
  invocations).

  This means that, taking the mean of mainloop event times, it takes ~5.55msec
  (13.43/2.42) to completely process an INTRODUCE2 cell. Then if we look deeper
  we see that the "top half" of INTRODUCE2 cell processing takes 0.26 msec in
  average, whereas the "bottom half" takes around 5.33 msec.

  The heavyness of the "bottom half" is to be expected since that's where 95%
  of the total work takes place: in particular the rendezvous path selection
  and circuit launch.

  {TODO: BLOCKER: While gathering these measurements we found an issue with our
  scheduler which was limiting the amount of cells we were reading per mainloop
  invocation. We are currently analyzing it and will do another confirmation
  round after we fix it: https://gitlab.torproject.org/tpo/core/tor/-/issues/40006}

A.2. References

    [REF_EQUIX]: https://github.com/tevador/equix
                 https://github.com/tevador/equix/blob/master/devlog.md
    [REF_TABLE]: The table is based on the script below plus some manual editing for \
                readability:
                 https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
    [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
    [REF_TARGET]: https://en.bitcoin.it/wiki/Target
    [REF_TLS]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt
               https://tools.ietf.org/id/draft-nir-tls-puzzles-00.html
               https://tools.ietf.org/html/draft-ietf-ipsecme-ddos-protection-10
    [REF_TLS_1]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt
  [REF_TEVADOR_1]: https://lists.torproject.org/pipermail/tor-dev/2020-May/014268.html
  [REF_TEVADOR_2]: https://lists.torproject.org/pipermail/tor-dev/2020-June/014358.html


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200626080736</emailId><senderName>The Paranoia Project</senderName><senderEmail>info@paranoia.tools</senderEmail><timestampReceived>2020-06-26 08:07:36-0400</timestampReceived><subject>Re: [tor-dev] Implementing an embeddable C++ Tor client, advice requested</subject><body>

On Tuesday, June 23, 2020 7:34 PM, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:

&gt; On Fri, Jun 19, 2020 at 3:59 PM The Paranoia Project
&gt; info@paranoia.tools wrote:
&gt; 
&gt; &gt; Hello everyone, I'm a long time user of Tor, first time poster here.
&gt; &gt; Over the last few months, I have been working on a light weight C++ client only \
&gt; &gt; implementation of the Tor protocol, intended to be used as an embedded library in \
&gt; &gt; other applications. It is now at the stage where it can complete bootstrapping, \
&gt; &gt; build circuits, as well as connect to services / host hidden services (v3). I \
&gt; &gt; have been building this primarily off the spec documents (which have generally \
&gt; &gt; been extremely helpful), and well as the assistance of stepping through the \
&gt; &gt; official Tor implementation when needed for troubleshooting and to confirm \
&gt; &gt; specifics. Before I release this to the wider world, I'd like to confirm a few \
&gt; &gt; points that may not be explicitly stated in the specs.
&gt; 
&gt; Hello, P! It'll be neat to have a look at this when it comes out;
&gt; building a Tor implementation is a lot of work.

Many thanks for your reply! The intent is to release this as open
source once reasonably stable, and I would be very happy to get more
eyes on it when it is ready.

I started out thinking I was making good progress with the core binary
protocol and crypto primitives, but quickly found out that there are
many layers to doing this well, the directory protocol formats was a
whole thing in itself, not to mention path selection, DHT for hidden
services, etc. As it stands, I have around 20k LOC of C++ and an
implementation that functionally performs the basics up to using
hidden services (as a client, or hosting one) but I'm sure there's a
lot more to come to make it stable and network friendly as you mention
below.

&gt; &gt; 1.  In general, what are the things to look out for when implementing the Tor \
&gt; &gt; protocol beyond "making it work" and validating all data (signatures, timestamps, \
&gt; &gt; etc)? One thing I'm concerned about is the risk of fingerprinting where the spec \
&gt; &gt; does not completely specify behaviour, e.g. the order in which link specifiers \
&gt; &gt; are passed in an extend cell, exact criteria for when circuits are explicitly \
&gt; &gt; destroyed etc. (I'm very excited to see the proposals around CBOR on this point \
&gt; &gt; which would help greatly with knowing that a canonical data representation was \
&gt; &gt; used).
&gt; 
&gt; There are a lot of these, I'm afraid, and they're not all perfectly
&gt; documented. Some of the trickier ones are about "being kind to the
&gt; network" -- not making too many circuits, not over-using resources
&gt; when idle, and so on. These are under-documented, but I believe Roger
&gt; has talked a few times about starting a document to collect these.
&gt; Roger, do you remember if this ever went anywhere, and produced a
&gt; draft or something?
&gt; 
&gt; For your first few versions, I'd suggest that your best bet is to
&gt; label your software loudly as experimental and alpha, since there will
&gt; almost certainly be ways to distinguish your software and surprising
&gt; bugs. Trying to be completely indistinguishable is probably
&gt; impossible, due to timing issues at least -- about the best you can do
&gt; is try to avoid easy ways to passively distinguish your software.

This all makes sense, and there are a lot of active behaviour parts
that I definitely do not yet have implemented in an identical way
(e.g. around padding). I've tried to mimic what the official client
sends on the wire where possible, but some other cases I've found
would include specific format of HTTP requests including headers used,
ordering of header, etc (for anonymous HsDir access), base64 encoding
in the directory formats that is sometimes explicitly specified as
being without trailing padding =s, canonical ordering of link
specifiers, and ordering of entries in directory documents. In
rend-spec-v3, there is an order in which directory keys are described
but I do not think it's explicitly stated that it should be the order
in which the keys are given.

If there are any more examples that comes to mind where fingerprinting
of data contracts would be possible, I'd appreciate any pointers.

&gt; In general, I wouldn't mind taking patches to enhance the specs by
&gt; describing a preferred behavior whenever there is more than on
&gt; possible behavior.
&gt; 
&gt; &gt; 2.  When it comes to bootstrapping, the official implementation appears to favour \
&gt; &gt; accessing directories via plaintext HTTP rather than connecting on the OR port \
&gt; &gt; and using create fast / begin dir. What is the motivation for using the plaintext \
&gt; &gt; option (and for that matter, having a plaintext http service open at all)?. While \
&gt; &gt; the OR will learn just as much about the client regardless, it seems like the \
&gt; &gt; default plaintext access to directory information unnecessarily gives away \
&gt; &gt; details of how clients engage with the Tor network to third parties.
&gt; 
&gt; That isn't right. It's preferred for clients to download directory
&gt; material over the ORPort via begindir. Plaintext DirPorts are
&gt; supposed to be used by relays and authorities only.
&gt; 
&gt; What part of the spec or the implementation says that the plaintext
&gt; dirport should be preferred? I'd like to correct that.

I may have misinterpreted the spec here. Dir-spec 5.1 states that
"The client does not build circuits until it has a live network-status
consensus document, and it has descriptors for a significant
proportion of the routers that it believes are running (this is
configurable using torrc options and consensus parameters).".

I took this to mean that _all_ bootstrapping would be done over
HTTP until the point of having "enough" descriptors, but I assume now
that this is meant to describe only "real" anonymous circuits?

In my current implementation, I do use begindir, and currently always
using create fast (as this is required in the cold start case). Is
there a meaningful preference here between using create/create fast
for the non anonymous circuits used for directory info? What is the
official client doing?

&gt; &gt; 3.  When using bridges and in particular pluggable transports, how is the client \
&gt; &gt; intended to safely bootstrap in the cold start case where it does not know up \
&gt; &gt; front which bridge/relay it will be connected to (e.g. when using Snowflake)? The \
&gt; &gt; RSA identity can be accepted in blind faith based on the Tor handshake, and it's \
&gt; &gt; then possible to get the full details with create fast / begin dir, but how does \
&gt; &gt; a client know that it has been connected to a bridge that is "blessed" by the Tor \
&gt; &gt; network rather than a MITM actor?
&gt; 
&gt; Bridge addresses and identities need to be discovered out-of-band, by
&gt; some means like bridgedb.torproject.org, personal communication, or
&gt; bundling with software. The provenance of this information is the
&gt; only way to tell whether you're getting a likely-to-be-good bridge or
&gt; likely-to-be-run-by-your-enemy bridge.

For normal bridges I understand this point, though I am not clear on
how it is intended to work with pluggable transports like Meek or
Snowflake. Unless I've missed it, I've not seen any secure identity
being specified when choosing a Meek or Snowflake setup, so how does
the OP know who it is (or should be) connected to on the first hop?

&gt; &gt; 4.  Finally, if anyone reading has been involved with or close to the development \
&gt; &gt; of other unofficial Tor implementations, what are the lessons learned on this \
&gt; &gt; front? I'm aware of among others Orchid (updated last in 2016), node-Tor (does \
&gt; &gt; not implement ECC) and torpy (does not implement hidden services v3). What makes \
&gt; &gt; these fail / stall?
&gt; 
&gt; I'll let developers answer here -- part of the issue is that it can be
&gt; hard to maintain feature parity over time.
&gt; 
&gt; For a longer list of implementations, see
&gt; https://gitlab.torproject.org/legacy/trac/-/wikis/doc/ListOfTorImplementations
&gt; [warning -- wiki migration in progress].

Thank you for that, I hadn't seen this specific list before!

Many thanks,
P



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200501060855</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-01 06:08:55-0400</timestampReceived><subject>[tor-dev] Proposal Idea: IPv6-Only Exit Relays</subject><body>

[Attachment #2 (multipart/alternative)]


Hi all,

The network team is making it easier to set up a dual-stack Tor relay.

We're currently working on:
* IPv6 reachability self-tests
* IPv6 address auto-detection
* IPv6 relay statistics

We're also thinking about the next IPv6 project. One possibility is
adding IPv6-only exits to the Tor network.

We'd need to solve two technical problems:
1. stop requiring IPv4 in the consensus and circuit code
2. avoiding delays when using an IPv6-only exit for an IPv4-only site

And one deployment problem:
3. Get more dual-stack middle relays (50% - 75%)

Here's a quick sketch of a solution to the IPv4-only site issue:

Clients open two exit streams for every site. One of those streams
must use an exit with IPv4 support. The client uses whichever
stream succeeds first.

Just like the "happy eyeballs" protocol, there is a delay between
launching the two streams:
https://www.rfc-editor.org/rfc/rfc8305.txt

Here are some benefits of a universal change:
* code and protocol consistency
* makes traffic analysis harder
* also helps with other exit failures, for a better user experience

Here are some drawbacks:
* extra load

We can change the delay to manage the tradeoff between load,
user experience, and traffic analysis resistance. Making the delay
longer reduces the load, but makes the user experience worse.

Traffic analysis resistance is a bit more complex. Consistency
across different clients is important, but we also don't want to
create obvious traffic patterns. So there are also some benefits
to randomisation.

If I get time, I'd like to turn these ideas into a proposal.

T

-- 
teor
----------------------------------------------------------------------


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;Hi all,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The network team is \
making it easier to set up a dual-stack Tor relay.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We're \
currently working on:&lt;/div&gt;&lt;div&gt;* IPv6 reachability self-tests&lt;/div&gt;&lt;div&gt;* IPv6 \
address auto-detection&lt;/div&gt;&lt;div&gt;* IPv6 relay \
statistics&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We're also thinking about the next IPv6 project. \
One possibility is&lt;/div&gt;&lt;div&gt;adding IPv6-only exits to the Tor \
network.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We'd need to solve two technical \
problems:&lt;/div&gt;&lt;div&gt;1. stop requiring IPv4 in the consensus and circuit \
code&lt;/div&gt;&lt;div&gt;2. avoiding delays when using an IPv6-only exit for an IPv4-only \
site&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;And one deployment problem:&lt;/div&gt;&lt;div&gt;3. Get more \
dual-stack middle relays (50% - 75%)&lt;/div&gt;&lt;div&gt;&lt;br&gt;Here's a quick sketch of a \
solution to the IPv4-only site issue:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Clients open two exit \
streams for every site. One of those streams&lt;/div&gt;&lt;div&gt;must use an exit with IPv4 \
support. The client uses whichever&lt;/div&gt;&lt;div&gt;stream succeeds \
first.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Just like the "happy eyeballs" protocol, there is a \
delay between&lt;/div&gt;&lt;div&gt;launching the two streams:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://www.rfc-editor.org/rfc/rfc8305.txt"&gt;https://www.rfc-editor.org/rfc/rfc8305.txt&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here \
are some benefits of a universal change:&lt;/div&gt;&lt;div&gt;* code and protocol \
consistency&lt;/div&gt;&lt;div&gt;* makes traffic analysis harder&lt;/div&gt;&lt;div&gt;* also helps with \
other exit failures, for a better user experience&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here are \
some drawbacks:&lt;/div&gt;&lt;div&gt;* extra load&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We can change the \
delay to manage the tradeoff between load,&lt;/div&gt;&lt;div&gt;user experience, and traffic \
analysis resistance. Making the delay&lt;/div&gt;&lt;div&gt;longer reduces the load, but makes \
the user experience worse.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Traffic analysis resistance is a \
bit more complex. Consistency&lt;/div&gt;&lt;div&gt;across different clients is important, but we \
also don't want to&lt;/div&gt;&lt;div&gt;create obvious traffic patterns. So there are also some \
benefits&lt;/div&gt;&lt;div&gt;to randomisation.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If I get time, I'd like \
to turn these ideas into a proposal.&lt;br&gt;&lt;br&gt;&lt;div dir="ltr"&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;T&lt;/span&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;--&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;teor&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, \
0);"&gt;----------------------------------------------------------------------&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, \
0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200504161356</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2020-05-04 16:13:56-0400</timestampReceived><subject>[tor-dev] Fwd: Orbot 16.2.0 RC-1 (tor-0.4.2.7)</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Now with integrated MOTE bridge request support, just like on Onion
Browser iOS, courtesy of Benjamin Erhart (aka tla).



-------- Forwarded Message --------
Subject: 	Orbot 16.2.0 RC-1 (tor-0.4.2.7)
Date: 	Mon, 4 May 2020 12:03:13 -0400
From: 	Nathan of Guardian &lt;nathan@guardianproject.info&gt;
Organization: 	Guardian Project
To: 	Guardian Dev &lt;guardian-dev@lists.mayfirst.org&gt;




Orbot 16.2.0 RC-1 (tor-0.4.2.7)

Tag: https://gitweb.torproject.org/orbot.git/tag/?h=16.2.0-RC-1-tor-0.4.2.7

APKs:

-
https://github.com/guardianproject/orbot/releases/tag/16.2.0-RC-1-tor-0.4.2.7

- Universal:
https://guardianproject.info/releases/Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-universal-release.apk
 (.asc)

- ARM64:
https://guardianproject.info/releases/Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-arm64-v8a-release.apk
 (.asc)

- F-Droid soon...


Thanks to the fantastic contributions by @bitmold @tladesignz and
@Hashik-Donthineni

Highlights

       Resolved many issues related to startup of Tor and Obfs4/Meek
bridges on Android Q/10
       VPN fixes resolved through unifying 2 background services
(TorVPNService, TorService) into one (OrbotService)
       Update tor to 0.4.2.7 and obfs4proxy to 0.0.12 latest
       Brand new "beta" integrated bridge fetch feature through Tor's MOTE
service (just like in Tor Browser)
       Brand new custom bridge configuration, setup UI
       Zulu language random switch bug FINALLY fixed.... now the language
you choose remains! (sorry, Zulu!)
       and much more...

/** 16.2.0-RC-1-tor-0.4.2.7 / 4 May 2020 / 0a3a4f7 **/

0a3a4f7 (HEAD -&gt; master) update version code to 16202001
a631077 (HEAD -&gt; master, origin/master, origin/HEAD) Merge branch
'tladesignz-master'
875f18a (tladesignz-master) Merge branch 'master' of
https://github.com/tladesignz/orbot into tladesignz-master
85e027c update version code
cabf328 don't start tun2socks/VPN if it is already running
718bb42 Issue #324: Implemented CustomBridgesActivity analogous to Onion
Browser iOS.
12a3f4a (tag: 16.2.0-BETA-4-tor-0.4.2.7) remove TorVpnService from
manifest to address #327 crash
22d7ef8 (tag: 16.2.0-BETA-3-tor-0.4.2.7) update to 16201003
22bd248 update binary install scripts, to fix pdnsd install - now pdnsd
is packaged as libpdsnd.so to work on newer platforms
e93c8bc (tag: 16.2.0-BETA-2-tor-0.4.2.7) update version code to 16201002
d0fec8e update tor and obfs4proxy binary libs to address #326 hopefully
3ac5a70 Issue #309: Activate newly required bridges, fixed accidental
reset through Tor status notification.
e1425d3 Issue #309: Also disable CAPTCHA solution EditText, as long as
there's no CAPTCHA to solve and while letting it check.
ff7cbcf Issue #309: Error alert button should say "OK" instead of
"Cancel", since there's nothing to cancel, really, just to acknowledge
the error.
54f5f31 Issue #309: Hide refresh option menu item instead of disable,
because Android doesn't visualize that adequately. Additionally: Fix
issue where you couldn't refresh after a network error.
3bfaa8a Issue #309: Fixed potential crash, when activity went away.
c41d453 (public/master) fix unneeded includes
4f4300a (tag: 16.2.0-BETA-1A-tor-0.4.2.7, tag:
16.2.0-BETA-1-tor-0.4.2.7, ghdev/master) update version to 16201001
7d7b2e9 remove app updater code to address concerns in #323
ec47151 major VPN refactor with Android Q updates for #263 #261 #151
#316 and #303 - integrate TorVPNService directly into OrbotService, so
just one service now - removed VPNEnableActivity, and just have
VPN activated by service now - changes address start on boot with VPN
enable - also improvements to managing PDNSD daemon
d64b4d0 (tag: 16.1.5-BETA-2-tor-0.4.2.7) update version code to 16150001
d5bc374 update to SDK 29
919c211 improve pdnsd pid checking
e78c27b remove unneeded commands in tor config and startup
5cd6cc8 update tor to 0.4.2.7
785fa8f Merge branch 'master' of github.com:guardianproject/orbot
93a0786 Merge pull request #322 from bitmold/AboutDialogCrashFix
b24750e Fixes #321 IlleglaStateException on about dialog
2e6c9b1 (tag: 16.1.5-BETA-1-tor-0.4.2.5-rc) small tweaks to request
bridge strings
3c80df0 Merge branch 'bitmold-compile_erorr+refactor'
08de553 (bitmold-compile_erorr+refactor) Merge branch
'compile_erorr+refactor' of https://github.com/bitmold/orbot into
bitmold-compile_erorr+refactor
df847ff Merge branch 'tladesignz-master'
b2646a3 update AndroidPT to latest 1.0.8 with fixes for obfs4 and meek
on Android 10
feedb3b fix string variable values
155980f Change from using String resources for a bundle key in Onboarding
ec0ad26 Fixes compile error on master branch right now
f2c8473 Merge branch 'master' of https://github.com/tladesignz/orbot
into tladesignz-master
732c153 Merge branch 'master' of https://github.com/guardianproject/orbot
09ded59 (githubgp/master) Merge pull request #311 from
bitmold/email_bridges_fix
b1049ca Merge branch 'master' of https://github.com/guardianproject/orbot
b9804c1 Merge pull request #305 from
Hashik-Donthineni/AppIntroOrientationFix
410ae03 tweaks to app data storage and control port interaction - in
some cases, Orbot connection to local control port can hang. Make
changes to address that.
19d5054 Color indeterminate ProgressBar.
1749167 Fixed behaviour on device turn.
f94931e Don't allow refresh button to trigger while request ongoing.
7a9b9d1 Adapted to naming convention of project.
964c311 Fixed MoatActivity startup when Tor is not running. Reset old
bridge configuration, when not completed.
5c99859 Finish BridgeWizardActivity on successful MOAT.
a34ee22 Improved UI: show progress spinner, start request on keyboard enter.
a46e463 Updated Gradle to latest version.
c026e20 Check OrbotService status, start Tor, if down, switch to Meek,
when started, fetch CAPTCHA, as soon as done with that. Proxy Volley
correctly. Improved option menu handling. Not working, yet: Tor
doesn't come up. Why?
e7cfe46 Added first stab at a MoatActivity. Doesn't change bridges
automatically, yet. Also, Volley needs to be proxied.
469d4cf Fixed most warnings and errors in OrbotMainActivity.
3eb76e6 Updated Gradle.
4283221 Updated BUILD info.
446dfa6 Fixes bugs in #289 pertaining to parsing bridges
8627989 Merge pull request #310 from bitmold/zulu_context_menu
29541f3 Fixes #300 Where Locale is set to Zulu when settings are opened
bfbb85b Changed variable names for better understanding
a09b4eb Fixed Unused Imports
f4580cf Added comments for better understanding
6c09f67 Extracted String Resources
ee3e054 Fixed blank screen when orintation changed in AppIntro
8a3727a Merge pull request #301 from PLNech/patch-1
0dcba0d fix FAQ URL in README
73b0b0d handle NPE since node is not yet set
Assets 6
Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-arm64-v8a-release.apk
11.2 MB
Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-arm64-v8a-release.apk.asc
833 Bytes
Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-universal-release.apk
32.2 MB
Orbot-16.2.0-RC-1-tor-0.4.2.7-1-geed732a3-fullperm-universal-release.apk.asc
833 Bytes
Source code (zip)
Source code (tar.gz)


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200504180231</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-04 18:02:31-0400</timestampReceived><subject>[tor-dev] (No walking onions update for last week)</subject><body>

Hi all!  Sending a short note that I won't be doing a walking onions
update from the past week -- my time went to follow-on tasks for
personnel transitions, and I didn't make much progress to speak of on
the walking onions specs.  I hope to get more done this week, and send
an update then.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200507073934</emailId><senderName>Lennart Oldenburg</senderName><senderEmail>lennart.oldenburg@esat.kuleuven.be</senderEmail><timestampReceived>2020-05-07 07:39:34-0400</timestampReceived><subject>Re: [tor-dev] Does a design document for the DoS subsystem exist?</subject><body>

Hello David, hello all!

&gt; Sorry for the late reply, as you may have seen, things got a bit
&gt; intense in Tor in the last 2 weeks.

We heard, very sorry about the ramifications that this pandemic caused
for the Tor project!

Thanks for the detailed response, it clarifies a lot of the questions we
had about the Guard DoS subsystem.

Kind regards
Lennart

On 29/04/2020 14.02, David Goulet wrote:
&gt; On 15 Apr (00:25:11), Lennart Oldenburg wrote:
&gt;&gt; Hello George, hello all,
&gt; 
&gt; Hi Lennart,
&gt; 
&gt; Sorry for the late reply, as you may have seen, things got a bit intense in
&gt; Tor in the last 2 weeks.
&gt; 
&gt;&gt; Thank you very much for the provided pointers. Great to hear progress is
&gt;&gt; being made on the Onion Services DoS matter. Two follow-up questions:
&gt;&gt;
&gt;&gt; 1) Will the DoS subsystem overhaul also affect guard-centric DoS
&gt;&gt; countermeasures? Or will it exclusively focus on DoS protection specific
&gt;&gt; to Onion Services? If guard-centric countermeasures are also being
&gt;&gt; updated, is there a document to see what is about to change?
&gt; 
&gt; The HS DoS defenses are independent from the relay DoS subsystem.
&gt; 
&gt;&gt; 2) The linked bug ticket [1] under your first bullet point does not
&gt;&gt; mention the origin of the concrete threshold values
&gt;&gt; (DoSCircuitCreationRate, etc.). Could you share any insight on how these
&gt;&gt; DoS threshold values are determined? Are they inferred from experiments?
&gt; 
&gt; Correct that we don't have a clear document explaining how we got there. But
&gt; if we dig, there are emails on a mailing list and possibly a ticket with
&gt; discussions about the choice of these parameters. But I do also unfortunately
&gt; recall some of it was only discussed and decided on IRC...
&gt; 
&gt; As far as I can recall, we've decided these values based on the "common use
&gt; case" and observation at Guard relays _not_ under attack versus one under
&gt; attack at the time.
&gt; 
&gt; One of the main reason for the picked values was the "Coffee Shop Effect" or
&gt; the "Airport Effect" that is in a regular normal use case, how many clients
&gt; would connect to Tor from the same IP address? We thought that 100-150 people
&gt; would be reasonable (from an airport or coffee shop) so we doubled that.
&gt; Putting all this together, with these two parameters, you get your 300 value:
&gt; 
&gt;     DoSCircuitCreationRate * DoSConnectionMaxConcurrentCount
&gt; 
&gt; So for a single client IP address, we allow 3 concurrent connections
&gt; (DoSCircuitCreationMinConnections) until we activate defenses for that IP. And
&gt; then, you are allowed 3 * 100 circuits per second until we start denying you
&gt; circuit creation. And a burst of 90 (DoSCircuitCreationBurst) is allowed per
&gt; second up to 300 maximum).
&gt; 
&gt; And why 3 concurrent connections until we activate defenses? At the time, we
&gt; imagined that someone could have 1 Tor Browser and a standalone tor daemon for
&gt; the rest (onion share, torsocks, etc...). Above that, it would not be the
&gt; "usual" use case and thus we activate defenses. But then even if you are 10 on
&gt; the same IP, 300 circuit/sec is massive for clients... so there was still a
&gt; good margin from what the attack was doing.
&gt; 
&gt; And also, all these parameters can be controlled within the consensus so if
&gt; any of them would have been too much or too lax, we could have reacted. It
&gt; turned out in the end that they were very efficient at stopping the DDoS we
&gt; had at the time. Who knows what the next big DDoS will bring and we might need
&gt; to tweak those values as we monitor the attack.
&gt; 
&gt; All in all, I do agree with you that we should have a clear nice document in
&gt; our spec repository at least to describe the what/how these values came about.
&gt; Time is such a scarse resources these days :(.
&gt; 
&gt; Cheers!
&gt; David
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200507170806</emailId><senderName>Hashik Donthineni</senderName><senderEmail>hashikdonthineni@gmail.com</senderEmail><timestampReceived>2020-05-07 17:08:06-0400</timestampReceived><subject>[tor-dev] My Introduction_GSoC Student</subject><body>

[Attachment #2 (multipart/alternative)]


Hello everyone!

My name is Hashik Donthineni (IRC: HashikD), I am a GSoC 2020 student. I
will be working on* Snowflake Proxy on the Android *project with the help
of my mentors Cecylia (Cohosh), Phillipp (phw).

I am really excited to join the Tor team!
Thank you all for giving me this exciting opportunity!

Regards,
D. Hashik

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello everyone!&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My name is Hashik Donthineni (IRC: \
HashikD), I am a GSoC 2020 student. I will be working on&lt;b&gt; Snowflake Proxy on the \
Android &lt;/b&gt;project with the help of my mentors Cecylia (Cohosh), Phillipp \
(phw).&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am really excited to join the Tor team!  \
&lt;/div&gt;&lt;div&gt;Thank you all for giving me this exciting \
opportunity!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;D. Hashik&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200509231627</emailId><senderName>Beecher Bruno</senderName><senderEmail>beecherbruno1@gmail.com</senderEmail><timestampReceived>2020-05-09 23:16:27-0400</timestampReceived><subject>[tor-dev] Tor Network Expansion Question/Suggestion</subject><body>

[Attachment #2 (multipart/alternative)]


Hello All,

I don't know much in the ways of how the actual coding works, but I'm very
familiar with computers. I'm a student in Network Systems Engineering
Technology in the USA. After being introduced to Tor several years ago, I
loved it. I recently had a potentially good idea in making the Tor network
more resilient against tracking/surveillance attempts.

My basic understanding is that information from one computer gets
transmitted to a node, bounced around between different nodes, and then
spit out somewhere else. Or, at least, that's what it would look like from
the outside, making it extremely difficult to pin down the actual origin
computer. (Please do forgive me if this is an inaccurate representation).

But what about expanding the network significantly, without truly widening
the load on all the nodes?

My idea was essentially this: an app for mobile devices and/or computers
that would ask for consent from the user. Upon consent, that device could
essentially fake its identity, so that everyone outside the network thought
it was a node? Data that's actually sent between nodes could just put in a
random "fake" node at the beginning and end of a packet so, as far as
anyone else knows, that data went through an extra two nodes?

Just in case that's not clear, imagine a Tor node receives packet A in
Washington DC. On its complicated, 3 node journey to the end node in
Hongkong, random devices that have been consented to be "fake nodes" will
have added themselves in. Theoretically, by the time it arrives in
Hongkong, this 5 node journey (DC Hongkong and the 3 in between) will look
on the outside to be a 6 or 7 node journey.

I'm not sure if this is possible, but if it is, I think it could help
protect people's privacy even more.

I do apologize for emailing this list, I couldn't exactly find an "Contact
Us" page, probably for good reason.

Have a great day!

Stay safe out there.

Beecher

[Attachment #5 (text/html)]

&lt;div dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;Hello \
All,&lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;I \
don't know much in the ways of how the actual coding  works, but I'm very familiar \
with computers. I'm a student in Network Systems Engineering Technology in the USA. \
After being introduced to Tor several years ago, I loved it. I recently had a \
potentially good idea in making the Tor network more resilient against \
tracking/surveillance attempts.  &lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;My \
basic understanding is that information from one computer gets transmitted to a node, \
bounced around between different nodes, and then spit out somewhere else. Or, at \
least, that's what it would look like from the outside, making it extremely difficult \
to pin down the actual origin computer. (Please do forgive me if this is an \
inaccurate representation).  &lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;But \
what about expanding the network significantly, without truly widening the load on \
all the nodes?  &lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;My \
idea was essentially this: an app for mobile devices and/or computers that would ask \
for consent from the user. Upon consent, that device could essentially fake its \
identity, so that everyone outside the network thought it was a node? Data that's \
actually sent between nodes could just put in a random "fake" node at the beginning \
and end of a packet so, as far as anyone else knows, that data went through an extra \
two nodes?  &lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;Just \
in case that's not clear, imagine a Tor node receives packet A in Washington DC. On \
its complicated, 3 node journey to the end node in Hongkong, random devices that have \
been consented to be "fake nodes" will have added themselves in. Theoretically, by \
the time it arrives in Hongkong, this 5 node journey (DC Hongkong and the 3 in \
between) will look on the outside to be a 6 or 7 node journey.&lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;I'm \
not sure if this is possible, but if it is, I think it could help protect people's \
privacy even more.&lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;I \
do apologize for emailing this list, I couldn't exactly find an "Contact Us" page, \
probably for good reason.&lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;Have \
a great day!&lt;/div&gt;&lt;div dir="auto" \
style="word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;Stay \
safe out there.&lt;/div&gt;&lt;div dir="auto" \
style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto" style="font-size:1rem;word-spacing:1px;border-color:rgb(49,49,49);color:rgb(49,49,49)"&gt;Beecher&lt;/div&gt;



[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200510015737</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2020-05-10 01:57:37-0400</timestampReceived><subject>Re: [tor-dev] Example of how a stream of RELAY_DATA cells would work?</subject><body>

On Tue, May 05, 2020 at 08:05:36PM +0300, Eli Vakrat wrote:
&gt; As of writing this, I can send and receive the proper RELAY_BEGIN and
&gt; RELAY_CONNECTED to and from my exit node, but I'm not quite sure what to do
&gt; next...

Great. Now you have a socket open, and you talk to the remote server
(e.g. webserver) over it. That is, you can pretend that you just opened
that socket directly to the remote server. You put bytes into your RELAY
DATA cells, and those bytes get sent to the remote server.

&gt; Do I just start sending RELAY_DATA cells (where the "data" of the cell is
&gt; literally the encoded HTTP requests)?

Yes, almost. You make the data be whatever you want the other side to
get. But now you need to understand what protocols the webserver thinks
you'll speak, as you see below:

&gt; I've tried connecting to 'www.facebook.com:443'  with the RELAY_BEGIN cells
&gt; as a test (I do get a Relay Connected Cell so at least I know that part
&gt; works).

www.facebook.com:443, also known as https://www.facebook.com/, will
expect you to speak TLS to it. If you send it plaintext http requests,
it will give you a tls error in response.

&gt; After getting back the RELAY_CONNECTED cell, I send a RELAY_DATA cell with
&gt; the data of the cell being the following 'utf-8' encoded string:
&gt; 
&gt; * #######this is how i wrote the literal in python#### *
&gt; *'GET / HTTP/1.1\r\nHost: www.facebook.com
&gt; &lt;http://www.facebook.com&gt;\r\nUser-Agent:
&gt; python-requests/2.23.0\r\nAccept-Encoding: gzip, deflate\r\nAccept:
&gt; */*\r\nConnection: keep-alive\r\n\r\n\r\n'.encode() *

Yeah, you are trying to send http, when instead you should be
starting your tls handshake.

&gt; What I get back is a short couple of bytes:
&gt; 
&gt; 
&gt; *\x15\x03\x03\x00\x02\x022*
&gt; 
&gt; I had no idea what this meant but after digging around a bit I found that
&gt; this seems to be some part of the TLS handshake that is used in HTTPS.

That makes sense.

&gt; So now two questions arise:
&gt; 
&gt; 1. Is this a good TLS response? What does it mean exactly?

I haven't checked, but I assume it means "error, that thing you sent me
was not the proper beginning of a tls handshake."

&gt; 2. Generally speaking, is this how the RELAY_DATA cells are supposed to be
&gt; sent and received?

Yes.

You might try sending your http text to www.facebook.com:80, which
expects http without any tls.

At this point it sounds like your Tor is working, and your new question
is "what's the right way to interact with a webserver?"

Hope this helps,
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200511204654</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-11 20:46:54-0400</timestampReceived><subject>[tor-dev] Proposal 318: Limit protover values to 0-63</subject><body>

```
Filename: 318-limit-protovers.md
Title: Limit protover values to 0-63.
Author: Nick Mathewson
Created: 11 May 2020
Status: Open
```

# Limit protover values to 0-63.

I propose that we no longer accept protover values higher than 63,
so that they can all fit nicely into 64-bit fields.

(This proposal is part of the Walking Onions spec project.)

## Motivation

Doing this will simplify our implementations and our protocols.
Right now, an efficient protover implementation needs to use ranges
to represent possible protocol versions, and needs workarounds to
prevent an attacker from constructing a protover line that would
consume too much memory.  With Walking Onions, we need lists of
protocol versions to be represented in an extremely compact format,
which also would benefit from a limited set of possible versions.

I believe that we will lose nothing by making this
change. Currently, after nearly two decades of Tor development
and 3.5 years of experiences with protovers in production, we have
no protocol version high than 5.

Even if we did someday need to implement higher protocol
versions, we could simply add a new subprotocol name instead.  For
example, instead of "HSIntro=64", we could say "HSIntro2=1".

## Migration

Immediately, authorities should begin rejecting relays with protocol
versions above 63.  (There are no such relays in the consensus right
now.)

Once this change is deployed to a majority of authorities, we can
remove support in other Tor environments for protocol versions
above 63.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515035806</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-15 03:58:06-0400</timestampReceived><subject>[tor-dev] Deprecating Tor Protocol Versions</subject><body>

[Attachment #2 (multipart/signed)]


Hi all,

Nick and I were talking about how we remove legacy features in tor,
and their corresponding subprotocol versions.

Here is a list of the current subprotocol versions:
https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2049

Here's a recent protocol version proposal, which deals with
recommending and requiring new features:
https://gitweb.torproject.org/torspec.git/tree/proposals/303-protover-removal-policy.txt

But we don't have a similar proposal for removing support for older
protocol versions from the tor codebase.

For an example of what that proposal could look like, see our proposal
for deprecating consensus methods:
https://gitweb.torproject.org/torspec.git/tree/proposals/290-deprecate-consensus-methods.txt

Here's the original conversation Nick and I had:
https://github.com/torproject/tor/pull/1874#discussion_r423713579

But after reading our consensus methods deprecation proposal, I've
changed my mind. I think that we should check for "protocol N, and
any later version" by default.

That's what we do for consensus methods, and it seems to work well.
We can drop the earliest consensus methods, and recent tor versions
just keep working.

If we need an incompatible change, we can make it another protocol
version, and recommend then require support for it.

So here's an edited version of my notes on that ticket:

There are a few instances of "&gt;=" and "=" confusion in protocol
versions. We should try to fix them all.

It only matters when we remove protocol versions. We haven't
really specified, tested, or exercised this functionality in
practice. And so our reviewers lack experience. (And when we did
discover a need for it with NSS and LinkAuth, it was more complicated
than we expected.)

I'd like to see a proposal that tells us how to check future protocol
versions as they are added. Along with a migration plan for disabling
protocol versions.

So let's also open a ticket to check for "any future version".
We should replace all "=" checks with "&gt;=". Let's make sure we check
all the places where we use protocol versions, even if they don't
have a summary flag.

Overall, I think it would be helpful if future protocol versions were
orthogonal. Or if they depend on earlier features, that dependency
should be clearly documented. (For example, Relay=3 IPv6 extends
depends on Relay=2 EXTEND2 cells. So if we were checking EXTEND2 cell
support, it would be Relay=2 or Relay=3.)

T

--
teor
----------------------------------------------------------------------


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6+E04ACgkQEP6qDnB1
ZyrU+BAAqHjv56hmxVUnFRd+6vH8EwjMHTFWt85akRjR/WkW3OiDwiEzb//Wio4+
7w5F1xV1cKffmKbgyZSrDdMPJ6UkcIGltpWhj/s0pQMkdwWdKfcoZEiL79SwvbEo
NELB+W44StqW9WUW4NN0zUah89oLamY8TRZWLMBjKh/U8wkhNdj67bE36xgHcPEh
W1raxzLjkDI7aE5qo1ed2gT4XimRF7uBoJBgKxIK3zThNAg7yjd3a4COgjxhXAKB
UF9iHtL2st1M9XKQM2nJSObLy64jkQ7qbWLE03d9roTctibNI3IVsKW1v99XLLdt
49V9Fo/oczGpnA6xJKjz7B4jjk+xVmS//516j/IHx7PJZQuzdw123ap5kafEp1qa
cVu1pR1RAFjh9JmU8AFuBvrqiOQsrSAJz1LiwxJiVd8I+yqw9RZ2fbIBEcE8K03J
d6KLdcUdDGf2e9AmGXLYXzLj81UtvkuJRZopHjcyxIHdPWaNHDNCzaz6M2RL8fvx
tycbK80B7wcbQv6vVrQM7dCZBolc0gLDlVTwKcmB9UiYcM8lG1dghjZVTtzs07h1
RIKqXwlZYUt0uSxlMlb8P5JOekupRnBo7vYSzpstRHt7MzjMOSkaHGSlOUmwGgLn
XMhEo9w1RkUvgxOEYZcmQOgfTAmnaPkYwyVIBWpvo35BhjBBMlQ=
=rUhH
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515105346</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-15 10:53:46-0400</timestampReceived><subject>Re: [tor-dev] Deprecating Tor Protocol Versions</subject><body>

[Attachment #2 (multipart/signed)]


On 15 May (13:58:06), teor wrote:
&gt; Hi all,
&gt; 
&gt; Nick and I were talking about how we remove legacy features in tor,
&gt; and their corresponding subprotocol versions.
&gt; 
&gt; Here is a list of the current subprotocol versions:
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2049
&gt; 
&gt; Here's a recent protocol version proposal, which deals with
&gt; recommending and requiring new features:
&gt; https://gitweb.torproject.org/torspec.git/tree/proposals/303-protover-removal-policy.txt
&gt; 
&gt; But we don't have a similar proposal for removing support for older
&gt; protocol versions from the tor codebase.
&gt; 
&gt; For an example of what that proposal could look like, see our proposal
&gt; for deprecating consensus methods:
&gt; https://gitweb.torproject.org/torspec.git/tree/proposals/290-deprecate-consensus-methods.txt
&gt; 
&gt; Here's the original conversation Nick and I had:
&gt; https://github.com/torproject/tor/pull/1874#discussion_r423713579
&gt; 
&gt; But after reading our consensus methods deprecation proposal, I've
&gt; changed my mind. I think that we should check for "protocol N, and
&gt; any later version" by default.

I agree that this is the right approach imo as well.

&gt; 
&gt; That's what we do for consensus methods, and it seems to work well.
&gt; We can drop the earliest consensus methods, and recent tor versions
&gt; just keep working.
&gt; 
&gt; If we need an incompatible change, we can make it another protocol
&gt; version, and recommend then require support for it.
&gt; 
&gt; So here's an edited version of my notes on that ticket:
&gt; 
&gt; There are a few instances of "&gt;=" and "=" confusion in protocol
&gt; versions. We should try to fix them all.
&gt; 
&gt; It only matters when we remove protocol versions. We haven't
&gt; really specified, tested, or exercised this functionality in
&gt; practice. And so our reviewers lack experience. (And when we did
&gt; discover a need for it with NSS and LinkAuth, it was more complicated
&gt; than we expected.)
&gt; 
&gt; I'd like to see a proposal that tells us how to check future protocol
&gt; versions as they are added. Along with a migration plan for disabling
&gt; protocol versions.
&gt; 
&gt; So let's also open a ticket to check for "any future version".
&gt; We should replace all "=" checks with "&gt;=". Let's make sure we check
&gt; all the places where we use protocol versions, even if they don't
&gt; have a summary flag.
&gt; 
&gt; Overall, I think it would be helpful if future protocol versions were
&gt; orthogonal. Or if they depend on earlier features, that dependency
&gt; should be clearly documented. (For example, Relay=3 IPv6 extends
&gt; depends on Relay=2 EXTEND2 cells. So if we were checking EXTEND2 cell
&gt; support, it would be Relay=2 or Relay=3.)

At the moment, they do depend between each other last time I had that
discussion with Nick. As in the later in your example.

Which means that supporting protocol version with a "&gt;=" is consistent with
our "non-written expectations" that we have now.

So if I understand correctly, we'll need to add a new protocol version let say
N+1 in order to deprecate anything &lt;= N ?

As an example, Relay=4 could mean "deprecate Relay=2 and use only Relay=3"

I'm +1 on this if iiuc.

Cheers!
David

-- 
dApigzB8NtOQEAlKqhqbshxjxOMakjiX9LGU9wvhFqs=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200416033519</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-04-16 03:35:19-0400</timestampReceived><subject>[tor-dev] Chutney code refactoring</subject><body>

I was going to mention this on my pull request
&lt;https://github.com/torproject/chutney/pull/67&gt; but I figured it would
be much more fitting to have a more-general thread here. In the PR I
mentioned how I believe that, if it quacks like a dict, it should be
implemented as a dict. That way we (hopefully) run into fewer gotchas
down the line, trying to reinvent the dict ourselves, and we have
clearer self-docuemtnation ("oh, this class inherits dict, now I know
kind of what to expect out of it").

I'm still trying to reason through chutney's code for how exactly
inheritance works and how this inheritance can be expressed more
clearly, for example it looks like the `Node` class is for a type of
relay (authority, client, bridge, et cetera) and its `getN` method is
to generate a number of those nodes. That is poorly documented and I
only figured this out by seeing how `Node.getN` was being called in the
tests themselves. To me, it makes more sense not to "overload" what a
`Node` is; if we are using an object as a factory to create more
`Node`s, then we should make that evident. The factory can then make
identical nodes with similar properties, rather than one parent `Node`
spawning children that refer back to their parent.

For me this issue is mostly "it feels like a lot of mental overhead,
and I'm sure it can be done better than it already is." But of course
it's difficult to fix something without first understanding how it
should behave. (Perhaps a test suite for the test suite? ;) But since
we're dealing with a lot of inheritance in chutney, and since this
inheritance is (in my opinion) expressed poorly, it can be quick to
find oneself caught in a web of code with no clear way out.

Here is what I have been considering lately, with the code overall. I
hope that laying it out in points will help both myself and others try
to divy up what could be improved about the code, work on it piecewise,
and make sure nothing is reimplemented incorrectly. I know I'm new to
the code and thus have not looked into it thoroughly enough to
understand everything about it, but again, something in the back of my
head is telling me that if it's this difficult to understand now, then
it can stand to be changed. So please take my criticism lightly and
only where it applies. I could be wrong about some things as well. But,
as a testing suite, this is the place we absolutely need to be sure we
get right, because with a hard-to-reason testing suite, we open
ourselves up to bugs within the tests themselves.

- Documentation especially for methods that the tests are supposed to
  call. In `Node` class, there is a comment "Users are expected to call
  these" with `__init__` and three other functions declared. `__init__`
  is fairly self-explanatory but the other three could stand to have
  the same docstrings that we are giving other functions. I think this
  should be my first task, before trying to mess with anything that
  moves. That way, we have a clearer overview of the testsuite's API,
  and then we can work the implementation around that.
- Once it's clear to all of us (meaning, not only the core Chutney
  devs, but also outsiders such as myself) what the current interface
  does, we can see the strengths of that interface, maybe some design
  flaws if we deem any to exist, and some improvements we can make with
  the interface. What I mean is: here is the place to make any
  necessary adjustments to the API before we dive into implementation.
- Now we visit the implementation. By this point I (and other non-core
  developers) should have a better understanding on what the tests
  *should* be doing, that we can then proceed to verify the correctness
  of the tests' implementations themselves. Here's where I would like
  to revisit cleaning up the code so that we make use of functions to
  abstract and "atomize" certain aspects of the code (like the
  currently-unused function isBoostrapped), where we should introduce
  more self-documenting names (as suggested, replace getAttribute names
  with isAttribute names for when we want to return bool values), et
  cetera.

I'm outlining what *I* think the approach should be, and in hopes that
everything else will line up and make more sense for us all. I do want
to make sure I know what the code should be doing, because while I
could inspect the code line by line and go through the logic branches
myself, I'm going to be perfectly honest and say it gives me a
headache :) I think it's much easier to reason about with
compartmentalised, self-documenting (and docstringed) components, than
to try to step through the code as it runs and take it in as one giant
piece.

Because, we're testing a complex piece of software (Tor). Tor itself
can do a lot of things that can throw us off especially if we're less
familiar with its implementation, yet. And that throws off our
understanding of how Chutney is supposed to work, as well. A lot of the
tests currently seem to be very conditional -- they pass or fail with
little rhyme or reason, which is of course the best type of issues to
debug :P -- so I don't see the test results helping me as well as
refactoring the testsuite first.

Again, let me know if I have anything wrong, made any unjust
assumptions, showed my ignorance, et cetera. I'm going into this boldly
and I hope that's the right call.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200423184814</emailId><senderName>Matt Traudt</senderName><senderEmail>pastly@torproject.org</senderEmail><timestampReceived>2020-04-23 18:48:14-0400</timestampReceived><subject>[tor-dev] Proposal XXX: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

Filename: xxx-flashflow.txt
Title: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)
Author: Matthew Traudt, Aaron Johnson, Rob Jansen, Mike Perry
Created: 23 April 2020
Status: Draft

1. Introduction

FlashFlow is a new distributed bandwidth measurement system for Tor that
consists of a single authority node ("coordinator") instructing one or
more measurement nodes ("measurers") when and how to measure Tor relays.
A measurement consists of the following steps:

  1. The measurement nodes demonstrate to the target relay permission to
     perform measurements.
  2. The measurement nodes open many TCP connections to the target relay
     and create a one-hop circuit to the target relay on each one.
  3. For 30 seconds the measurement nodes send measurement cells to the
     target relay and verify that the cells echoed back match the ones
     sent. During this time the relay caps the amount of background
     traffic it transfers. Background and measurement traffic are
     handled separately at the relay. Measurement traffic counts towards
     all the standard existing relay statistics.
  4. For every second during the measurement, the measurement nodes
     report to the authority node how much traffic was echoed back. The
     target relay also reports the amount of per-second background
     (non-measurement) traffic.
  5. The authority node sums the per-second reported throughputs into 30
     sums (one for each second) and calculates the median. This is the
     estimated capacity of the relay.

FlashFlow performs a measurement of every relay according to a schedule
described later in this document. Periodically it produces relay
capacity estimates in the form of a v3bw file, which is suitable for
direct consumption by a Tor directory authority. Alternatively an
existing load balancing system such as Simple Bandwidth Scanner could be
modified to use FlashFlow's v3bw file as input.

It is envisioned that each directory authority that wants to use
FlashFlow will run their own FlashFlow deployment consisting of a
coordinator that they run and one or more measurers that they trust
(e.g. because they run them themselves), similar to how each runs their
own Torflow/sbws. Section 5.2 of this proposal describes long term plans
involving multiple FlashFlow deployments.

FlashFlow is more performant than Torflow: FlashFlow takes 5 hours to
measure the entire existing Tor network from scratch (with 3 Gbit/s
measurer capacity) while Torflow takes 2 days; FlashFlow measures relays
it hasn't seen recently as soon as it learns about them (i.e. every new
consensus) while Torflow can take a day or more; and FlashFlow
accurately measures new high-capacity relays the first time and every
time while Torflow takes days/weeks to assign them their full fair share
of bandwidth (especially for non-exits). FlashFlow is more secure than
Torflow: FlashFlow allows a relay to inflate its measured capacity by up
to 1.33x (configured by a parameter) while Torflow allows weight
inflation by a factor of 89x [0] or even 177x [1].

After an overview in section 2 of the planned deployment stages, section
3, 4, and 5 discuss the short, medium, and long term deployment plans in
more detail.

2. Deployment Stages

FlashFlow's deployment shall be broken up into three stages.

In the short term we will implement a working FlashFlow measurement
system. This requires code changes in little-t tor and an external
FlashFlow codebase. The majority of the implementation work will be
done in the short term, and the product is a complete FlashFlow
measurement system. Remaining pieces (e.g. better authentication) are
added later for enhanced security and network performance.

In the medium term we will begin collecting data with a FlashFlow
deployment. The intermediate results and v3bw files produced will be
made available (semi?) publicly for study.

In the long term experiments will be performed to study ways of using FF
v3bw files to improve load balancing. Two examples: (1) using FF v3bw
files instead of sbws's (and eventually phasing out torflow/sbws), and
(2) continuing to run sbws but use FF's results as a better estimate of
relay capacity than observed bandwidth. Authentication and other
FlashFlow features necessary to make it completely ready for full
production deployment will be worked on during this long term phase.

3. FlashFlow measurement system: Short term

The core measurement mechanics will be implemented in little-t tor, but
a separate codebase for the FlashFlow side of the measurement system
will also be created. This section is divided into three parts: first a
discussion of changes/additions that logically reside entirely within
tor (essentially: relay-side modifications), second a discussion of the
separate FlashFlow code that also requires some amount of tor changes
(essentially: measurer-side and coordinator-side modifications), and
third a security discussion.

3.1 Little-T Tor Components

The primary additions/changes that entirely reside within tor on the
relay side:

  - New torrc options/consensus parameters.
  - New cell commands.
  - Pre-measurement handshaking (with a simplified authentication
    scheme).
  - Measurement mode, during which the relay will echo traffic with
    measurers, set a cap on the amount of background traffic it
    transfers, and report the amount of transferred background traffic.

3.1.1 Parameters

FlashFlow will require some consensus parameters/torrc options. Each has
some default value if nothing is specified; the consensus parameter
overrides this default value; the torrc option overrides both.

FFMeasurementsAllowed: A global toggle on whether or not to allow
measurements. Even if all other settings would allow a measurement, if
this is turned off, then no measurement is allowed. Possible values: 0,
1. Default: 0 (disallowed).

FFAllowedCoordinators: The list of coordinator TLS certificate
fingerprints that are allowed to start measurements. Relays check their
torrc when they receive a connection from a FlashFlow coordinator to see
if it's on the list. If they have no list, they check the consensus
parameter. If nether exist, then no FlashFlow deployment is allowed to
measure this relay. Default: empty list.

FFMeasurementPeriod: A relay should expect on average, to be measured by
each FlashFlow deployment once each measurement period. A relay will not
allow itself to be measured more than twice by a FlashFlow deployment in
any time window of this length. Relays should not change this option
unless they really know what they're doing. Changing it at the relay
will not change how often FlashFlow will attempt to measure the relay.
Possible values are in the range [1 hour, 1 month] inclusive. Default: 1
day.

FFBackgroundTrafficPercent: The maximum amount of regular
non-measurement traffic a relay should handle while being measured, as a
percent of total traffic (measurement + non-measurement). This
parameter is a trade off between having to limit background traffic and
limiting how much a relay can inflate its result by handling no
background traffic but reporting that it has done so. Possible values
are in the range [0, 99] inclusive. Default: 25 (a maximum inflation
factor of 1.33).

FFMaxMeasurementDuration: The maximum amount of time, in seconds, that
is allowed to pass from the moment the relay is notified that a
measurement will begin soon and the end of the measurement. If this
amount of time passes, the relay shall close all measurement connections
and exit its measurement mode. Note this duration includes handshake
time, thus it necessarily is larger than the expected actual measurement
duration. Possible values are in the range [10, 120] inclusive.
Default: 45.

3.1.2 New Cell Types

FlashFlow will introduce a new cell command MEASURE.

The payload of each MEASURE cell consists of:

  Measure command [1 byte]
  Length          [2 bytes]
  Data            [Length-3 bytes]

The measure commands are:

  0 -- MSM_PARAMS    [forward]
  1 -- MSM_PARAMS_OK [backward]
  2 -- MSM_ECHO      [forward and backward]
  3 -- MSM_BG        [backward]
  4 -- MSM_ERR       [forward and backward]

Forward cells are sent from the measurer/coordinator to the relay.
Backward cells are sent from the relay to the measurer/coordinator.

MSM_PARAMS and MSM_PARAMS_OK are used during the pre-measurement stage
to tell the target what to expect and for the relay to positively
acknowledge the message. MSM_ECHO cells are the measurement traffic;
the measurer generates them, sends them to the target, and the target
echos them back. The target send a MSM_BG cell once per second to report
the amount of background traffic it is handling. MSM_ERR cells are used
to signal to the other party that there has been some sort of problem
and that the measurement should be aborted. These measure commands are
described in more detail in the next section.

The only cell that sometimes undergoes cell encryption is MSM_ECHO; no
other cell ever gets cell encrypted. (All cells are transmitted on a
regular TLS-wrapped OR connection; that encryption still exists.)

The relay "decrypts" MSM_ECHO cells before sending them back to the
measurer; this mirrors the way relays decrypt/encrypt RELAY_DATA cells
in order to induce realistic cryptographic CPU load. The measurer
usually skips encrypting MSM_ECHO cells to reduce its own CPU load;
however, to verify the relay is actually correctly decrypting all cells,
the measurer will choose random outgoing cells, encrypt them, remember
the ciphertext, and verify the corresponding incoming cell matches.

3.1.3 Pre-Measurement Handshaking/Starting a Measurement

The coordinator connects to the target relay and sends it a MSM_PARAMS
cell. If the target is unwilling to be measured at this time or if the
coordinator didn't use a TLS certificate that the target trusts, it
responds with an error cell and closes the connection. Otherwise it
checks that the parameters of the measurement are acceptable (e.g. the
version is acceptable, the duration isn't too long, etc.). If the
target is happy, it sends a MSM_PARAMS_OK, otherwise it sends a MSM_ERR
and closes the connection.

Upon learning the IP addresses of the measurers from the coordinator in
the MSM_PARAMS cell, the target whitelists their IPs in its DoS
detection subsystem until the measurement ends (successfully or
otherwise), at which point the whitelist is cleared.

Upon receiving a MSM_PARAMS_OK from the target, the coordinator will
instruct the measurers to open their TCP connections with the target. If
the coordinator or any measurer receives a MSM_ERR, it reports the error
to the coordinator and considers the measurement a failure. It is also a
failure if any measurer is unable to open at least half of its TCP
connections with the target.

The payload of MSM_PARAMS cells [XXX more may need to be added]:

  - version       [1 byte]
  - msm_duration  [1 byte]
  - num_measurers [1 byte]
  - measurer_info [num_measurers times]
    - ipv4_addr   [4 bytes]
    - num_conns   [2 bytes]

version dictates how this MSM_PARAMS cell shall be parsed. msm_duration
is the duration, in seconds, that the actual measurement will last.
num_measurers is how many measurer_info structs follow. For each
measurer, the ipv4_addr it will use when connecting to the target is
provided, as is num_conns, the number of TCP connections that measurer
will open with the target. Future versions of FlashFlow and MSM_PARAMS
will use TLS certificates instead of IP addresses.

MSM_PARAMS_OK has no payload: it's just padding bytes to make the cell
514 bytes long.

The payload of MSM_ECHO cells:

  - arbitrary bytes [max to fill up 514 byte cell]

The payload of MSM_BG cells:

  - second        [1 byte]
  - sent_bg_bytes [4 bytes]
  - recv_bg_bytes [4 bytes]

second is the number of seconds since the measurement began. MSM_BG
cells are sent once per second from the relay to the FlashFlow
coordinator. The first cell will have this set to 1, and each
subsequent cell will increment it by one. sent_bg_bytes is the number of
background traffic bytes sent in the last second (since the last MSM_BG
cell). recv_bg_bytes is the same but for received bytes.

The payload of MSM_ERR cells:

  - err_code [1 byte]
  - err_str  [possibly zero-len null-terminated string]

The error code is one of:

  [... XXX TODO ...]
  255 -- OTHER

The error string is optional in all cases. It isn't present if the first
byte of err_str is null, otherwise it is present. It ends at the first
null byte or the end of the cell, whichever comes first.

3.1.4 Measurement Mode

The relay considers the measurement to have started the moment it
receives the first MSM_ECHO cell from any measurer. At this point, the
relay

  - Starts a repeating 1s timer on which it will report the amount of
    background traffic to the coordinator over the coordinator's
    connection.
  - Enters "measurement mode" and limits the amount of background
    traffic it handles according to the torrc option/consensus
    parameter.

The relay decrypts and echos back all MSM_ECHO cells it receives on
measurement connections until it has reported its amount of background
traffic the same number of times as there are seconds in the measurement
(e.g. 30 per-second reports for a 30 second measurement). After sending
the last MSM_BG cell, the relay drops all buffered MSM_ECHO cells,
closes all measurement connections, and exits measurement mode.

During the measurement the relay targets a ratio of background traffic
to measurement traffic as specified by a consensus parameter/torrc
option. For a given ratio r, if the relay has handled x cells of
measurement traffic recently, Tor then limits itself to y = xr/(1-r)
cells of non-measurement traffic this scheduling round. The target will
enforce that a minimum of 10 Mbit/s of measurement traffic is recorded
since the last background traffic scheduling round to ensure it always
allows some minimum amount of background traffic.

3.2 FlashFlow Components

The FF coordinator and measurer code will reside in a FlashFlow
repository separate from little-t tor.

There are three notable parameters for which a FF deployment must choose
values. They are:

  - The number of sockets, s, the measurers should open, in aggregate,
    with the target relay. We suggest s=160 based on the FF paper.
  - The bandwidth multiplier, m. Given an existing capacity estimate for
    a relay, z, the coordinator will instruct the measurers to, in
    aggregate, send m*z Mbit/s to the target relay. We recommend m=2.25.
  - The measurement duration, d. Based on the FF paper, we recommend
    d=30 seconds.

The rest of this section first discusses notable functions of the
FlashFlow coordinator, then goes on to discuss FF measurer code that
will require supporting tor code.

3.2.1 FlashFlow Coordinator

The coordinator is responsible for scheduling measurements, aggregating
results, and producing v3bw files. It needs continuous access to new
consensus files, which it can obtain by running an accompanying Tor
process in client mode.

The coordinator has the following functions, which will be described in
this section:

  - result aggregation.
  - schedule measurements.
  - v3bw file generation.

3.2.1.1 Aggregating Results

Every second during a measurement, the measurers send the amount of
verified measurement traffic they have received back from the relay.
Additionally, the relay sends a MSM_BG cell each second to the
coordinator with amount of non-measurement background traffic it is
sending and receiving.

For each second's reports, the coordinator sums the measurer's reports.
The coordinator takes the minimum of the relay's reported sent and
received background traffic. If, when compared to the measurer's reports
for this second, the relay's claimed background traffic is more than
what's allowed by the background/measurement traffic ratio, then the
coordinator further clamps the relay's report down. The coordinator adds
this final adjusted amount of background traffic to the sum of the
measurer's reports.

Once the coordinator has done the above for each second in the
measurement (e.g. 30 times for a 30 second measurement), the coordinator
takes the median of the 30 per-second throughputs and records it as the
estimated capacity of the target relay.

3.2.1.2 Measurement Schedule

The short term implementation of measurement scheduling will be simpler
than the long term one due to (1) there only being one FlashFlow
deployment, and (2) there being very few relays that support being
measured by FlashFlow. In fact the FF coordinator will maintain a list
of the relays that have updated to support being measured and have opted
in to being measured, and it will only measure them.

The coordinator divides time into a series of 24 hour periods, commonly
referred to as days. Each period has measurement slots that are longer
than a measurement lasts (30s), say 60s, to account for pre- and
post-measurement work. Thus with 60s slots there's 1,440 slots in a
day.

At the start of each day the coordinator considers the list of relays
that have opted in to being measured. From this list of relays, it
repeatedly takes the relay with the largest existing capacity estimate.
It selects a random slot. If the slot has existing relays assigned to
it, the coordinator makes sure there is enough additional measurer
capacity to handle this relay. If so, it assigns this relay to this
slot. If not, it keeps picking new random slots until one has sufficient
additional measurer capacity.

Relays without existing capacity estimates are assumed to have the 75th
percentile capacity of the current network.

If a relay is not online when it's scheduled to be measured, it doesn't
get measured that day.

3.2.1.2.1 Example

Assume the FF deployment has 1 Gbit/s of measurer capacity. Assume the
chosen multiplier m=2. Assume there are only 5 slots in a measurement
period.

Consider a set of relays with the following existing capacity estimates
and that have opted in to being measured by FlashFlow.

  - 500 Mbit/s
  - 300 Mbit/s
  - 250 Mbit/s
  - 200 Mbit/s
  - 100 Mbit/s
  -  50 Mbit/s

The coordinator takes the largest relay, 500 Mbit/s, and picks a random
slot for it. It picks slot 3. The coordinator takes the next largest,
300, and randomly picks slot 2. The slots are now:

     0   |   1   |   2   |   3   |   4
  -------|-------|-------|-------|-------
         |       |  300  |  500  |
         |       |       |       |

The coordinator takes the next largest, 250, and randomly picks slot 2.
Slot 2 already has 600 Mbit/s of measurer capacity reserved (300*m);
given just 1000 Mbit/s of total measurer capacity, there is just 400
Mbit/s of spare capacity while this relay requires 500 Mbit/s. There is
not enough room in slot 2 for this relay. The coordinator picks a new
random slot, 0.

     0   |   1   |   2   |   3   |   4
  -------|-------|-------|-------|-------
    250  |       |  300  |  500  |
         |       |       |       |

The next largest is 200 and the coordinator randomly picks slot 2 again
(wow!). As there is just enough spare capacity, the coordinator assigns
this relay to slot 2.

     0   |   1   |   2   |   3   |   4
  -------|-------|-------|-------|-------
    250  |       |  300  |  500  |
         |       |  200  |       |

The coordinator randomly picks slot 4 for the last remaining relays, in
that order.

     0   |   1   |   2   |   3   |   4
  -------|-------|-------|-------|-------
    250  |       |  300  |  500  |  100
         |       |  200  |       |   50

3.2.1.3 Generating V3BW files

Every hour the FF coordinator produces a v3bw file in which it stores
the latest capacity estimate for every relay it has measured in the last
week. The coordinator will create this file on the host's local file
system. Previously-generated v3bw files will not be deleted by the
coordinator. A symbolic link at a static path will always point to the
latest v3bw file.

    $ ls -l
    v3bw -&gt; v3bw.2020-03-01-05-00-00
    v3bw.2020-03-01-00-00-00
    v3bw.2020-03-01-01-00-00
    v3bw.2020-03-01-02-00-00
    v3bw.2020-03-01-03-00-00
    v3bw.2020-03-01-04-00-00
    v3bw.2020-03-01-05-00-00

3.2.2 FlashFlow Measurer

The measurers take commands from the coordinator, connect to target
relays with many sockets, send them traffic, and verify the received
traffic is the same as what was sent. Measurers need access to a lot of
internal tor functionality. One strategy is to house as much logic as
possible inside an compile-time-optional control port module that calls
into other parts of tor. Alternatively FlashFlow could link against tor
and call internal tor functions directly.

[XXX for now I'll assume that an optional little-t tor control port
module housing a lot of this code is the best idea.]

Notable new things that internal tor code will need to do on the
measurer (client) side:

  1. Open many TLS+TCP connections to the same relay on purpose.
  2. Verify echo cells.

3.2.2.1 Open many connections

FlashFlow prototypes needed to "hack in" a flag in the
open-a-connection-with-this-relay function call chain that indicated
whether or not we wanted to force a new connection to be created. Most
of Tor doesn't care if it reuses an existing connection, but FF does
want to create many different connections. The cleanest way to
accomplish this will be investigated.

On the relay side, these measurer connections do not count towards DoS
detection algorithms.

3.2.2.2 Verify echo cells

A parameter will exist to tell the measurers with what frequency they
shall verify that cells echoed back to them match what was sent. This
parameter does not need to exist outside of the FF deployment (e.g. it
doesn't need to be a consensus parameter).

The parameter instructs the measurers to check 1 out of every N cells.

The measurer keeps a count of how many measurement cells it has sent. It
also logically splits its output stream of cells into buckets of size N.
At the start of each bucket (when num_sent % N == 0), the measurer
chooses a random index in the bucket. Upon sending the cell at that
index (num_sent % N == chosen_index), the measurer records the cell.

The measurer also counts cells that it receives. When it receives a cell
at an index that was recorded, it verifies that the received cell
matches the recorded sent cell. If they match, no special action is
taken. If they don't match, the measurer indicates failure to the
coordinator and target relay and closes all connections, ending the
measurement.

3.2.2.2.1 Example

Consider bucket_size is 1000. For the moment ignore cell encryption.

We start at idx=0 and pick an idx in [0, 1000) to record, say 640. At
idx=640 we record the cell. At idx=1000 we choose a new idx in [1000,
2000) to record, say 1236. At idx=1236 we record the cell. At idx=2000
we choose a new idx in [2000, 3000). Etc.

There's 2000+ cells in flight and the measurer has recorded two items:

  - (640, contents_of_cellA)
  - (1236, contents_of_cellB)

Consider the receive side now. It counts the cells it receives. At
receive idx=640, it checks the received cell matches the saved cell from
before. At receive idx=1236, it again checks the received cell matches.
Etc.

3.2.2.2.2 Motivation

A malicious relay may want to skip decryption of measurement cells to
save CPU cycles and obtain a higher capacity estimate. More generally,
it could generate fake measurement cells locally, ignore the measurement
traffic it is receiving, and flood the measurer with more traffic that
it (the measurer) is even sending.

The security of echo cell verification is discussed in section 3.3.1.

3.3 Security

In this section we discuss the security of various aspects of FlashFlow
and the tor changes it requires.

3.3.1 Echo Cell Verification: Bucket Size

A smaller bucket size means more cells are checked and FF is more likely
to detect a malicious target. It also means more bookkeeping overhead
(CPU/RAM).

An adversary that knows bucket_size and cheats on one item out of every
bucket_size items will have a 1/bucket_size chance of getting caught in
the first bucket. This is the worst case adversary. While cheating on
just a single item per bucket yields very little advantage, cheating on
more items per bucket increases the likelihood the adversary gets
caught. Thus only the worst case is considered here.

In general, the odds the adversary can successfully cheat in a single
bucket are

    (bucket_size-1)/bucket_size

Thus the odds the adversary can cheat in X consecutive buckets are

    [(bucket_size-1)/bucket_size]^X

In our case, X will be highly varied: Slow relays won't see very many
buckets, but fast relays will. The damage to the network a very slow
relay can do by faking being only slightly faster is limited.
Nonetheless, for now we motivate the selection of bucket_size with a
slow relay:

  - Assume a very slow relay of 1 Mbit/s capacity that will cheat 1 cell
    in each bucket. Assume a 30 second measurement.
  - The relay will handle 1*30 = 30 Mbit of traffic during the
    measurement, or 3.75 MB, or 3.75 million bytes.
  - Cells are 514 bytes. Approximately (e.g. ignoring TLS) 7300 cells
    will be sent/recv over the course of the measurement.
  - A bucket_size of 50 results in about 146 buckets over the course of
    the 30s measurement.
  - Therefore, the odds of the adversary cheating successfully as
    (49/50)^(146), or about 5.2%.

This sounds high, but a relay capable of double the bandwidth (2 Mbit/s)
will have (49/50)^(2*146) or 0.2% odds of success, which is quite low.

Wanting a &lt;1% chance that a 10 Mbit/s relay can successfully cheat
results in a bucket size of approximately 125:

  - 10*30 = 300 Mbit of traffic during 30s measurement. 37.5 million
    bytes.
  - 37,500,000 bytes / 514 bytes/cell = ~73,000 cells
  - bucket_size of 125 cells means 73,000 / 125 = 584 buckets
  - (124/125)^(584) = 0.918% chance of successfully cheating

Slower relays can cheat more easily but the amount of extra weight they
can obtain is insignificant in absolute terms. Faster relays are
essentially unable to cheat.

3.3.2 Weight Inflation

Target relays are an active part of the measurement process; they know
they are getting measured. While a relay cannot fake the measurement
traffic, it can trivially stop transferring client background traffic
for the duration of the measurement yet claim it carried some. More
generally, there is no verification of the claimed amount of background
traffic during the measurement. The relay can claim whatever it wants,
but it will not be trusted above the ratio the FlashFlow deployment is
configured to know. This places an easy to understand, firm, and (if set
as we suggest) low cap on how much a relay can inflate its measured
capacity.

Consider a background/measurement ratio of 1/4, or 25%. Assume the relay
in question has a hard limit on capacity (e.g. from its NIC) of 100
Mbit/s. The relay is supposed to use up to 25% of its capacity for
background traffic and the remaining 75%+ capacity for measurement
traffic. Instead the relay ceases carrying background traffic, uses all
100 Mbit/s of capacity to handle measurement traffic, and reports ~33
Mbit/s of background traffic (33/133 = ~25%). FlashFlow would trust this
and consider the relay capable of 133 Mbit/s. (If the relay were to
report more than ~33 Mbit/s, FlashFlow limits it to just ~33 Mbit/s.)
With r=25%, FlashFlow only allows 1.33x weight inflation.

Prior work shows that Torflow allows weight inflation by a factor of 89x
[0] or even 177x [1].

The ratio chosen is a trade-off between impact on background traffic and
security: r=50% allows a relay to double its weight but won't impact
client traffic for relays with steady state throughput below 50%, while
r=10% allows a very low inflation factor but will cause throttling of
client traffic at far more relays. We suggest r=25% (and thus
1/(1-0.25)=1.33x inflation) for a reasonable trade-off between
performance and security.

It may be possible to catch relays performing this attack, especially if
they literally drop all background traffic during the measurement: have
the measurer (or some party on its behalf) create a regular stream
through the relay and measure the throughput on the stream
before/during/after the measurement. This can be explored longer term.

3.3.3 Incomplete Authentication

The short term FlashFlow implementation has the relay set two torrc
options if they would like to allow themselves to be measured: a flag
allowing measurement, and the list of coordinator TLS certificate that
are allowed to start a measurement.

The relay drops MSM_PARAMS cells from coordinators it does not trust,
and immediately closes the connection after that. A FF coordinator
cannot convince a relay to enter measurement mode unless the relay
trusts its TLS certificate.

A trusted coordinator specifies in the MSM_PARAMS cell the IP addresses
of the measurers the relay shall expect to connect to it shortly. The
target adds the measurer IP addresses to a whitelist in the DoS
connection limit system, exempting them from any configured connection
limit. If a measurer is behind a NAT, an adversary behind the same NAT
can DoS the relay's available sockets until the end of the measurement.
The adversary could also pretend to be the measurer. Such an adversary
could induce measurement failures and inaccuracies. (Note: the whitelist
is cleared after the measurement is over.)

4. FlashFlow measurement system: Medium term

The medium term deployment stage begins after FlashFlow has been
implemented and relays are starting to update to a version of Tor that
supports it.

We plan to host a FlashFlow deployment consisting of a FF coordinator
and a single FF measurer on a single 1 Gbit/s machine. Data produced by
this deployment will be made available (semi?) publicly, including both
v3bw files and intermediate results.

Any development changes needed during this time would go through
separate proposals.

5. FlashFlow measurement system: Long term

In the long term, finishing-touch development work will be done,
including adding better authentication and measurement scheduling, and
experiments will be run to determine the best way to integrate FlashFlow
into the Tor ecosystem.

Any development changes needed during this time would go through
separate proposals.

5.1 Authentication to Target Relay

Short term deployment already had FlashFlow coordinators using TLS
certificates when connecting to relays, but in the long term, directory
authorities will vote on the consensus parameter for which coordinators
should be allowed to perform measurements. The voting is done in the
same way they currently vote on recommended tor versions.

FlashFlow measurers will be updated to use TLS certificates when
connecting to relays too. FlashFlow coordinators will update the
contents of MSM_PARAMS cells to contain measurer TLS certificates
instead of IP addresses, and relays will update to expect this change.

5.2 Measurement Scheduling

Short term deployment only has one FF deployment running. Long term this
may no longer be the case because, for example, more than one directory
authority decides to adopt it and they each want to run their own
deployment. FF deployments will need to coordinate between themselves
to not measure the same relay at the same time, and to handle new relays
as they join during the middle of a measurement period (during the day).

The following is quoted from Section 4.3 of the FlashFlow paper.

    To measure all relays in the network, the BWAuths periodically
    determine the measurement schedule. The schedule determines when and
    by whom a relay should be measured. We assume that the BWAuths have
    sufficiently synchronized clocks to facilitate coordinating their
    schedules. A measurement schedule is created for each measurement
    period, the length p of which determines how often a relay is
    measured. We use a measurement period of p = 24 hours.

    To help avoid active denial-of-service attacks on targeted relays,
    the measurement schedule is randomized and known only to the
    BWAuths. Before the next measurement period starts, the BWAuths
    collectively generate a random seed (e.g. using Tor's
    secure-randomness protocol). Each BWAuth can then locally determine
    the shared schedule using pseudorandom bits extracted from that
    seed. The algorithm to create the schedule considers each
    measurement period to be divided into a sequence of t-second
    measurement slots. For each old relay, slots for each BWAuth to
    measure it are selected uniformly at random without replacement
    from all slots in the period that have sufficient unallocated
    measurement capacity to accommodate the measurement. When a new
    relay appears, it is measured separately by each BWAuth in the first
    slots with sufficient unallocated capacity. Note that this design
    ensures that old relays will continue to be measured, with new
    relays given secondary priority in the order they arrive.

5.3 Experiments

   [XXX todo]

5.4 Other Changes/Investigations/Ideas

- How can FlashFlow data be used in a way that doesn't lead to poor load
  balancing given the following items that lead to non-uniform client
  behavior:
    - Guards that high-traffic HSs choose (for 3 months at a time)
    - Guard vs middle flag allocation issues
    - New Guard nodes (Guardfraction)
    - Exit policies other than default/all
    - Directory activity
    - Total onion service activity
    - Super long-lived circuits
- Add a cell that the target relay sends to the coordinator indicating
  its CPU and memory usage, whether it has a shortage of sockets, how
  much bandwidth load it has been experiencing lately, etc. Use this
  information to lower a relays weight, never increase.
- If FlashFlow and sbws work together (as opposed to FlashFlow replacing
  sbws), consider logic for how much sbws can increase/decrease FF
  results
- Coordination of multiple FlashFlow deployments: scheduling of
  measurements, seeding schedule with shared random value.
- Other background/measurement traffic ratios. Dynamic? (known slow
  relay =&gt; more allowed bg traffic?)
- Catching relays inflating their measured capacity by dropping
  background traffic.
- What to do about co-located relays. Can they be detected reliably?
  Should we just add a torrc option a la MyFamily for co-located relays?
- What is the explanation for dennis.jackson's scary graphs in this [2]
  ticket?  Was it because of the speed test? Why? Will FlashFlow produce
  the same behavior?

6. Citations

[0] F. Thill. Hidden Service Tracking Detection and Bandwidth Cheating
    in Tor Anonymity Network. Master's thesis, Univ. Luxembourg, 2014.
[1] A. Johnson, R. Jansen, N. Hopper, A. Segal, and P. Syverson.
    PeerFlow: Secure Load Balancing in Tor. Proceedings on Privacy
    Enhancing Technologies (PoPETs), 2017(2), April 2017.
[2] Mike Perry: Graph onionperf and consensus information from Rob's
    experiments https://trac.torproject.org/projects/tor/ticket/33076

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200423191255</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-04-23 19:12:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal XXX: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

Added as proposal 316.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200516060507</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-05-16 06:05:07-0400</timestampReceived><subject>Re: [tor-dev] Proposal XXX: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

On 4/23/20 1:48 PM, Matt Traudt wrote:

&gt; 5.4 Other Changes/Investigations/Ideas
&gt;
&gt; - How can FlashFlow data be used in a way that doesn't lead to poor
&gt;   load balancing given the following items that lead to non-uniform
&gt;   client behavior:
&gt;     - Guards that high-traffic HSs choose (for 3 months at a time)
&gt;     - Guard vs middle flag allocation issues
&gt;     - New Guard nodes (Guardfraction)
&gt;     - Exit policies other than default/all
&gt;     - Directory activity
&gt;     - Total onion service activity
&gt;     - Super long-lived circuits
&gt; - What is the explanation for dennis.jackson's scary graphs in this [2]
&gt;   ticket?  Was it because of the speed test? Why? Will FlashFlow produce
&gt;   the same behavior?

It will also be wise to provide a way for relays to signify that they
are on the same machine. I bet concurrent machine deployments are one of
the top contributors to the long tail of bad perf we saw caused by the
Flashflow experiment[2]. If flashflow measures each such relay as having
the full link capacity instead of a shared fraction, this is obviously
going to result in overload on those relays, leading to a long tail of
bad perf when they are chosen and are also overloaded. It is unlikely
that we can deploy a FlashFlow that has this long tail perf problem
without fixing this and related balancing issues (though hopefully most
will be smoothed over by sbws).

This is a little tricky, because we might not want rogue relays joining
each others "machines" (similar to the Family problem), but for testing
something as simple as how MyFamily works would be great. Ideally,
though, relays would ask or detect that they are concurrently running in
nearby IP space and either warn the operator to set the flag, or set it
automatically.

We actually have this work included in a future performance funding
proposal, but the timeline on that getting approved (or even rejected)
is so far out that we should figure out a way to do this before that,
especially if Flashflow development is going to begin soon.

&gt; [2] Mike Perry: Graph onionperf and consensus information from Rob's
&gt;     experiments https://trac.torproject.org/projects/tor/ticket/33076


-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200416161218</emailId><senderName>meejah</senderName><senderEmail>meejah@meejah.ca</senderEmail><timestampReceived>2020-04-16 16:12:18-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>


Context: I've done a lot of Python development and once upon a time
delved into Chutney a little bit. In general I agree that there are some
confusing things including inheritance. So, I think giving it some love
through refactoring would make it more approachable.

As to the specific DictWrapper issue, I also found this confusing. It's
kind of tied into a custom templating system too. I would question
whether this is a good idea; there are many templating systems already
for Python -- what does Chutney's add that these don't already have?

While re-factoring I would try to reduce the amount of inheritence where
the user has to understand it to make progress. For example, any API
where a user is expected to override a class and re-write some methods.

I'd have to delve back into Chutney to give more specific suggestions,
but wanted to chime in and say that I also found it confusing and hard
to read Python :)

-- 
meejah
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200416215003</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-04-16 21:50:03-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Thu, 16 Apr 2020 20:12:18 +0400
meejah &lt;meejah@meejah.ca&gt; wrote:

&gt; As to the specific DictWrapper issue, I also found this confusing. It's
&gt; kind of tied into a custom templating system too. I would question
&gt; whether this is a good idea; there are many templating systems already
&gt; for Python -- what does Chutney's add that these don't already have?

That's why I want to understand what Chutney is trying to do exactly so
maybe I could find some pre-made wheels (no pun intended toward the
package format) in Python's ecosystem that will fit the vehicle, rather
than reinventing it. That is, of course, if such wheels make sense for
Chutney to use. One thing I love about Python is its mature ecosystem.

&gt; While re-factoring I would try to reduce the amount of inheritence where
&gt; the user has to understand it to make progress. For example, any API
&gt; where a user is expected to override a class and re-write some methods.

Agreed, I will keep this in mind.

&gt; I'd have to delve back into Chutney to give more specific suggestions,
&gt; but wanted to chime in and say that I also found it confusing and hard
&gt; to read Python :)

So far your suggestions have been helpful, so thank you.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200417220142</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-04-17 22:01:42-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Wed, Apr 15, 2020 at 11:45 PM c &lt;c@chroniko.jp&gt; wrote:

Skipping over some design stuff that seems reasonable.

 [...]
&gt; Here is what I have been considering lately, with the code overall. I
&gt; hope that laying it out in points will help both myself and others try
&gt; to divy up what could be improved about the code, work on it piecewise,
&gt; and make sure nothing is reimplemented incorrectly. I know I'm new to
&gt; the code and thus have not looked into it thoroughly enough to
&gt; understand everything about it, but again, something in the back of my
&gt; head is telling me that if it's this difficult to understand now, then
&gt; it can stand to be changed. So please take my criticism lightly and
&gt; only where it applies. I could be wrong about some things as well. But,
&gt; as a testing suite, this is the place we absolutely need to be sure we
&gt; get right, because with a hard-to-reason testing suite, we open
&gt; ourselves up to bugs within the tests themselves.

Agreed totally.

&gt; - Documentation especially for methods that the tests are supposed to
&gt;   call. In `Node` class, there is a comment "Users are expected to call
&gt;   these" with `__init__` and three other functions declared. `__init__`
&gt;   is fairly self-explanatory but the other three could stand to have
&gt;   the same docstrings that we are giving other functions. I think this
&gt;   should be my first task, before trying to mess with anything that
&gt;   moves. That way, we have a clearer overview of the testsuite's API,
&gt;   and then we can work the implementation around that.

This seems plausible, though I would caution that we shouldn't expect
to find a great separation between the external and internal parts of
chutney right now.  It's been built up piece by piece over time
without a wholly consistent vision, so it probably doesn't have the
best isolation between its layers.

This documentation project would also IMO benefit from a high-level or
module-level overviews on what things exactly chutney does.  Some of
its tasks are well-documented, but others are less so.

If you want to work on this it would be helpful to maybe start by
listing (here or elsewhere) some places where you *don't* feel like
you could (or would want to) write documentation: those would be a
good target for devs who _have_ worked on Chutney before.

&gt; - Once it's clear to all of us (meaning, not only the core Chutney
&gt;   devs, but also outsiders such as myself) what the current interface
&gt;   does, we can see the strengths of that interface, maybe some design
&gt;   flaws if we deem any to exist, and some improvements we can make with
&gt;   the interface. What I mean is: here is the place to make any
&gt;   necessary adjustments to the API before we dive into implementation.

+1.  Though I think this is likely to be an ongoing change that we see
over time, since

&gt; - Now we visit the implementation. By this point I (and other non-core
&gt;   developers) should have a better understanding on what the tests
&gt;   *should* be doing, that we can then proceed to verify the correctness
&gt;   of the tests' implementations themselves. Here's where I would like
&gt;   to revisit cleaning up the code so that we make use of functions to
&gt;   abstract and "atomize" certain aspects of the code (like the
&gt;   currently-unused function isBoostrapped), where we should introduce
&gt;   more self-documenting names (as suggested, replace getAttribute names
&gt;   with isAttribute names for when we want to return bool values), et
&gt;   cetera.

Yes.  I think there are other steps that could help at this stage too,
including:
  * More tests for the various parts of chutney, and refactoring to
make them more testable.
  * Making chutney comply with one or more of the python style
checking tools that are out there.

&gt; I'm outlining what *I* think the approach should be, and in hopes that
&gt; everything else will line up and make more sense for us all. I do want
&gt; to make sure I know what the code should be doing, because while I
&gt; could inspect the code line by line and go through the logic branches
&gt; myself, I'm going to be perfectly honest and say it gives me a
&gt; headache :) I think it's much easier to reason about with
&gt; compartmentalised, self-documenting (and docstringed) components, than
&gt; to try to step through the code as it runs and take it in as one giant
&gt; piece.
&gt;
&gt; Because, we're testing a complex piece of software (Tor). Tor itself
&gt; can do a lot of things that can throw us off especially if we're less
&gt; familiar with its implementation, yet. And that throws off our
&gt; understanding of how Chutney is supposed to work, as well. A lot of the
&gt; tests currently seem to be very conditional -- they pass or fail with
&gt; little rhyme or reason, which is of course the best type of issues to
&gt; debug :P -- so I don't see the test results helping me as well as
&gt; refactoring the testsuite first.

This is an good vision for how Chutney should go; I really support this idea.

&gt; Again, let me know if I have anything wrong, made any unjust
&gt; assumptions, showed my ignorance, et cetera. I'm going into this boldly
&gt; and I hope that's the right call.
&gt;
&gt; Caitlin
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200418020333</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-04-18 02:03:33-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Fri, 17 Apr 2020 18:01:42 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; If you want to work on this it would be helpful to maybe start by
&gt; listing (here or elsewhere) some places where you *don't* feel like
&gt; you could (or would want to) write documentation: those would be a
&gt; good target for devs who _have_ worked on Chutney before.

Sounds good, I will work on this.

&gt; Though I think this is likely to be an ongoing change that we see
&gt; over time, since

Was this sentence supposed to be longer?

&gt;   * More tests for the various parts of chutney, and refactoring to
&gt; make them more testable.

Internal unit testing seems like a good idea, yes.

&gt;   * Making chutney comply with one or more of the python style
&gt; checking tools that are out there.

I can look into this; personally I have no experience with Python
style-checking or linting tools, but now's a good time as ever for me
to learn what is available and how it would work for Chutney.

&gt; This is an good vision for how Chutney should go; I really support
&gt; this idea.

Glad you are on board :)

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200418022127</emailId><senderName>meejah</senderName><senderEmail>meejah@meejah.ca</senderEmail><timestampReceived>2020-04-18 02:21:27-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

c &lt;c@chroniko.jp&gt; writes:

&gt; I can look into this; personally I have no experience with Python
&gt; style-checking or linting tools, but now's a good time as ever for me
&gt; to learn what is available and how it would work for Chutney.

For style-enforcement, things seem to be converging around "black" in
the Python community (I personally haven't used it).

For linting it's flake8 (and also pylint or pyflakes). They all seem to
come down to "how many warnings do you want to turn off". I have
most-often used flake8 which is a fine choice.

Find me as "meejah" on #tor-dev if you want more random opinions from
Python-land :)

-- 
meejah
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200511204724</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-11 20:47:24-0400</timestampReceived><subject>[tor-dev] Proposal 319: RELAY_FRAGMENT cells</subject><body>

```
Filename: 319-wide-everything.md
Title: RELAY_FRAGMENT cells
Author: Nick Mathewson
Created: 11 May 2020
Status: Open
```

(This proposal is part of the Walking Onions spec project.)

# Introduction

Proposal 249 described a system for `CREATE` cells to become wider, in order to
accommodate hybrid crypto.  And in order to send those cell bodies across
circuits, it described a way to split `CREATE` cells into multiple `EXTEND`
cells.

But there are other cell types that can need to be wider too. For
example, `INTRODUCE` and `RENDEZVOUS` cells also contain key material
used for a handshake: if handshakes need to grow larger, then so do
these cells.

This proposal describes an encoding for arbitrary "wide" relay cells,
that can be used to send a wide variant of anything.

To be clear, although this proposal describes a way that all relay
cells can become "wide", I do not propose that wide cells should
actually be _allowed_ for all relay cell types.

# Proposal

We add a new relay cell type: `RELAY_FRAGMENT`.  This cell type contains part
of another relay cell.  A `RELAY_FRAGEMENT` cell can either introduce a new
fragmented cell, or can continue one that is already in progress.

The format of a RELAY_FRAGMENT body is one of the following:

    // First body in a series
    struct fragment_begin {
       // What relay_command is in use for the underlying cell?
       u8 relay_command;
       // What will the total length of the cell be once it is reassembled?
       u16 total_len;
       // Bytes for the cell body
       u8 body[];
    }

    // all other cells.
    struct fragment_continued {
       // More bytes for the cell body.
       u8 body[];
    }

To send a fragmented cell, first a party sends a RELAY_FRAGMENT cell
containing a "fragment_begin" payload.  This payload describes the total
length of the cell, the relay command

Fragmented cells other than the last one in sequence MUST be sent full of
as much data as possible.  Parties SHOULD close a circuit if they receive a
non-full fragmented cell that is not the last fragment in a sequence.

Fragmented cells MUST NOT be interleaved with other relay cells on a circuit,
other than cells used for flow control. (Currently, this is only SENDME
cells.)  If any party receives any cell on a circuit, other than a flow
control cell or a RELAY_FRAGEMENT cell, before the fragmented cell is
complete, than it SHOULD close the circuit.

Parties MUST NOT send extra data in fragmented cells beyond the amount given
in the first 'total_len' field.

Not every relay command may be sent in a fragmented cell.  In this proposal,
we allow the following cell types to be fragmented: EXTEND2, EXTENDED2,
INTRODUCE1, INTRODUCE2, RENDEZVOUS.  Any party receiving a command that they
believe should not be fragmented should close the circuit.

Not all lengths up to 65535 are valid lengths for a fragmented cell.  Any
length under 499 bytes SHOULD cause the circuit to close, since that could
fit into a non-fragmented RELAY cell.  Parties SHOULD enforce maximum lengths
for cell types that they understand.

All `RELAY_FRAGMENT` cells for the fragmented cell must have the
same Stream ID.  (For those cells allowed above, the Stream ID is
always zero.)  Implementations SHOULD close a circuit if they
receive fragments with mismatched Stream ID.

# Onion service concerns.

We allocate a new extension for use in the ESTABLISH_INTRO by onion services,
to indicate that they can receive a wide INTRODUCE2 cell.  This extension
contains:

        struct wide_intro2_ok {
          u16 max_len;
        }

We allocate a new extension for use in the `ESTABLISH_RENDEZVOUS`
cell, to indicate acceptance of wide `RENDEZVOUS2` cells.  This
extension contains:

        struct wide_rend2_ok {
          u16 max_len;
        }

(Note that `ESTABLISH_RENDEZVOUS` cells do not currently have a an
extension mechanism.  They should be extended to use the same
extension format as `ESTABLISH_INTRO` cells, with extensions placed
after the rendezvous cookie.)

# Handling RELAY_EARLY

The first fragment of each EXTEND cell should be tagged with `RELAY_EARLY`.
The remaining fragments should not.  Relays should accept `EXTEND` cells if and
only if their _first_ fragment is tagged with `RELAY_EARLY`.

&gt; Rationale: We could allow any fragment to be tagged, but that would give
&gt; hostile guards an opportunity to move RELAY_EARLY tags around and build a
&gt; covert channel.  But if we later move to a relay encryption method that
&gt; lets us authenticate RELAY_EARLY, we could then require only that _any_
&gt; fragment has RELAY_EARLY set.

# Compatibility

This proposal will require the allocation of a new 'Relay' protocol version,
to indicate understanding of the RELAY_FRAGMENTED command.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200524225458</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2020-05-24 22:54:58-0400</timestampReceived><subject>[tor-dev] So Windows is Adding a Package Manager.....</subject><body>

[Attachment #2 (unknown)]

&lt;html xmlns:o="urn:schemas-microsoft-com:office:office" \
xmlns:w="urn:schemas-microsoft-com:office:word" \
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" \
xmlns="http://www.w3.org/TR/REC-html40"&gt;&lt;head&gt;&lt;meta http-equiv=Content-Type \
content="text/html; charset=utf-8"&gt;&lt;meta name=Generator content="Microsoft Word 15 \
(filtered medium)"&gt;&lt;style&gt;&lt;!-- /* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
MsoChpDefault
	{mso-style-type:export-only;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
--&gt;&lt;/style&gt;&lt;/head&gt;&lt;body lang=EN-US link=blue vlink="#954F72"&gt;&lt;div \
class=WordSection1&gt;&lt;p class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;Hi \
all,&lt;/p&gt;&lt;p class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;So based on this \
article here,&lt;/p&gt;&lt;p class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;&lt;a \
href="https://docs.microsoft.com/en-us/windows/package-manager/"&gt;https://docs.microsoft.com/en-us/windows/package-manager/&lt;/a&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p \
class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;Windows is getting a package \
manager in the near future,   including winget, a Linux like tool that can install \
and manage packages. With this in might   it be possible to add tor as a manageable \
package for Windows (for auto upgrades, install via this method, etc.)?   \
&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p \
class=MsoNormal&gt;Thx.&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p \
class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=MsoNormal&gt;Sent from &lt;a \
href="https://go.microsoft.com/fwlink/?LinkId=550986"&gt;Mail&lt;/a&gt; for Windows 10&lt;/p&gt;&lt;p \
class=MsoNormal&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div \
id="DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2"&gt; &lt;br /&gt;&lt;br /&gt;
&lt;hr style='border:none; color:#909090; background-color:#B0B0B0; height: 1px; width: \
99%;' /&gt; &lt;table style='border-collapse:collapse;border:none;'&gt;
	&lt;tr&gt;
		&lt;td style='border:none;padding:0px 15px 0px 8px'&gt;
			&lt;a href="https://www.avast.com/antivirus"&gt;
				&lt;img border=0 src="https://static.avast.com/emails/avast-mail-stamp.png" \
alt="Avast logo" /&gt;  &lt;/a&gt;
		&lt;/td&gt;
		&lt;td&gt;
			&lt;p style='color:#3d4d5a; font-family:"Calibri","Verdana","Arial","Helvetica"; \
font-size:12pt;'&gt;  This email has been checked for viruses by Avast antivirus \
software.  &lt;br&gt;&lt;a href="https://www.avast.com/antivirus"&gt;www.avast.com&lt;/a&gt;
			&lt;/p&gt;
		&lt;/td&gt;
	&lt;/tr&gt;
&lt;/table&gt;
&lt;br /&gt;
&lt;a href="#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2" width="1" height="1"&gt; \
&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200426173756</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-04-26 17:37:56-0400</timestampReceived><subject>[tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hi there,

I have a proposal regarding DNS name resolution.

Ticket: https://trac.torproject.org/projects/tor/ticket/34004
Proposal: 
https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
Implementation: https://github.com/torproject/tor/pull/1869

All functioniality is behind the DNSResolver feature flag, so don't
forget to activate it before you start testing.

Please let me know what you think.

BR
Christian


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200511204753</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-11 20:47:53-0400</timestampReceived><subject>[tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

```
Filename: 320-tap-out-again.md
Title: Removing TAP usage from v2 onion services
Author: Nick Mathewson
Created: 11 May 2020
Status: Open
```

(This proposal is part of the Walking Onions spec project.  It updates
proposal 245.)

# Removing TAP from v2 onion services

As we implement walking onions, we're faced with a problem: what to do
with TAP keys?  They are bulky and insecure, and not used for anything
besides v2 onion services.  Keeping them in SNIPs would consume
bandwidth, and keeping them indirectly would consume complexity.  It
would be nicer to remove TAP keys entirely.

But although v2 onion services are obsolescent and their
cryptographic parameters are disturbing, we do not want to drop
support for them as part of the Walking Onions migration.  If we did
so, then we would force some users to choose between Walking Onions
and v2 onion services, which we do not want to do.

Instead, we describe here a phased plan to replace TAP in v2 onion
services with ntor.  This change improves the forward secrecy of
_some_ of the session keys used with v2 onion services, but does not
improve their authentication, which is strongly tied to truncated
SHA1 hashes of RSA1024 keys.

Implementing this change is more complex than similar changes
elsewhere in the Tor protocol, since we do not want clients or
services to leak whether they have support for this proposal, until
support is widespread enough that revealing it is no longer a
privacy risk.

## Ntor keys, link specifiers, and SNIPs in v2 descriptors.

We define these entries that may appear in v2 onion service
descriptors, once per introduction point.

    "identity-ed25519"
    "ntor-onion-key"

       [at most once each per intro point.]

       These values are in the same format as and follow the same
       rules as their equivalents in router descriptors.

    "link-specifiers"

       [at most once per introduction point]

       This value is the same as the link specifiers in a v3 onion
       service descriptor, and follows the same rules.

Services should not include any of these fields unless a new network
parameter, "hsv2-intro-updated" is set to 1. Clients should not parse
these fields or use them unless "hsv2-use-intro-updated" is set to 1.

We define a new field that can be used for hsv2 descriptors with
walking onions:

    "snip"
        [at most once]

        This value is the same as the snip field introduced to a v3
        onion service descriptor by proposal (XXX) and follows the
        same rules.

Services should not include this field unless a new network parameter,
"hsv2-intro-snip" is set to 1. Clients should not parse this field or use it
unless the parameter "hsv2-use-intro-snip" is set to 1.

Additionally, relays SHOULD omit the following legacy intro point
parameters when a new network parameter, "hsv2-intro-legacy" is set
to 0: "ip-address", "onion-port", and "onion-key". Clients should
treat them as optional when "hsv2-tolerate-no-legacy" is set to 1.

## INTRODUCE cells, RENDEZVOUS cells, and ntor.

We allow clients to specify the rendezvous point's ntor key in the
INTRODUCE2 cell instead of the TAP key.  To do this, the client
simply sets KLEN to 32, and includes the ntor key for the relay.

Clients should only use ntor keys in this way if the network parameter
"hsv2-client-rend-ntor" is set to 1, and if the entry "allow-rend-ntor"
is present in the onion service descriptor.

Services should only advertise "allow-rend-ntor" in this way if the
network parameter "hsv2-service-rend-ntor" is set to 1.

## Migration steps

First, we implement all of the above, but set it to be disabled by
default.  We use torrc fields to selectively enable them for testing
purposes, to make sure they work.

Once all non-LTS versions of Tor without support for this proposal are
obsolete, we can safely enable "hsv2-client-rend-ntor",
"hsv2-service-rend-ntor", "hsv2-intro-updated", and
"hsv2-use-intro-updated".

Once all non-LTS versions of Tor without support for walking onions
are obsolete, we can safely enable "hsv2-intro-snip",
"hsv2-use-intro-snip", and "hsv2-tolerate-no-legacy".

Once all non-LTS versions of Tor without support for _both_ of the
above implementations are finally obsolete, we can finally set
"hsv2-intro-legacy" to 0.

## Future work

There is a final TAP-like protocol used for v2 hidden services: the
client uses RSA1024 and DH1024 to send information about the
rendezvous point and to start negotiating the session key to be used
for end-to-end encryption.

In theory we could get a benefit to forward secrecy by using ntor
instead of TAP here, but we would get not corresponding benefit for
authentication, since authentication is still ultimately tied to
HSv2's scary RSA1024-plus-truncated-SHA1 combination.

Given that, it might be just as good to allow the client to insert
a curve25519 key in place of their DH1024 key, and use that for the
DH handshake instead.  That would be a separate proposal, though:
this proposal is enough to allow all relays to drop TAP support.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200511215831</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2020-05-11 21:58:31-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

On Mon, May 11, 2020 at 04:47:53PM -0400, Nick Mathewson wrote:
&gt; ## INTRODUCE cells, RENDEZVOUS cells, and ntor.
&gt; 
&gt; We allow clients to specify the rendezvous point's ntor key in the
&gt; INTRODUCE2 cell instead of the TAP key.  To do this, the client
&gt; simply sets KLEN to 32, and includes the ntor key for the relay.
&gt; 
&gt; Clients should only use ntor keys in this way if the network parameter
&gt; "hsv2-client-rend-ntor" is set to 1, and if the entry "allow-rend-ntor"
&gt; is present in the onion service descriptor.
&gt; 
&gt; Services should only advertise "allow-rend-ntor" in this way if the
&gt; network parameter "hsv2-service-rend-ntor" is set to 1.

It should be stronger, right? A service that does not advertise
allow-rend-ntor (because hsv2-service-rend-tor is unset) MUST reject an
ntor key, even if the service actually does support it?  Otherwise a
client could simply try it even if support is not advertised?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200511231358</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-05-11 23:13:58-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

On Mon, May 11, 2020 at 5:58 PM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt;
&gt; On Mon, May 11, 2020 at 04:47:53PM -0400, Nick Mathewson wrote:
&gt; &gt; ## INTRODUCE cells, RENDEZVOUS cells, and ntor.
&gt; &gt;
&gt; &gt; We allow clients to specify the rendezvous point's ntor key in the
&gt; &gt; INTRODUCE2 cell instead of the TAP key.  To do this, the client
&gt; &gt; simply sets KLEN to 32, and includes the ntor key for the relay.
&gt; &gt;
&gt; &gt; Clients should only use ntor keys in this way if the network parameter
&gt; &gt; "hsv2-client-rend-ntor" is set to 1, and if the entry "allow-rend-ntor"
&gt; &gt; is present in the onion service descriptor.
&gt; &gt;
&gt; &gt; Services should only advertise "allow-rend-ntor" in this way if the
&gt; &gt; network parameter "hsv2-service-rend-ntor" is set to 1.
&gt;
&gt; It should be stronger, right? A service that does not advertise
&gt; allow-rend-ntor (because hsv2-service-rend-tor is unset) MUST reject an
&gt; ntor key, even if the service actually does support it?  Otherwise a
&gt; client could simply try it even if support is not advertised?

Ah yes, you're right.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200512005212</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-12 00:52:12-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

Hi Nick,

&gt; On 12 May 2020, at 06:48, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; ## Migration steps
&gt; 
&gt; First, we implement all of the above, but set it to be disabled by
&gt; default.  We use torrc fields to selectively enable them for testing
&gt; purposes, to make sure they work.

Can you expand on the testing plan here?

One of the risks with multi-year migration projects is that unrelated
changes break the migration, and we don't notice.

For example, you might need to create a chutney network for each
stage, and run them on every pull request and merge. In our current
CI, that's 30-60 seconds of extra time per network, or 2-4 extra
minutes of CI time.

If you need to test different combinations of features for each stage,
let's try to do that in the same networks. Otherwise, the testing matrix
expands out very quickly.

T
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200513140904</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-13 14:09:04-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

[Attachment #2 (multipart/signed)]


On 11 May (16:47:53), Nick Mathewson wrote:

Hello!

&gt; ```
&gt; Filename: 320-tap-out-again.md
&gt; Title: Removing TAP usage from v2 onion services
&gt; Author: Nick Mathewson
&gt; Created: 11 May 2020
&gt; Status: Open
&gt; ```
&gt; 
&gt; (This proposal is part of the Walking Onions spec project.  It updates
&gt; proposal 245.)
&gt; 
&gt; # Removing TAP from v2 onion services
&gt; 
&gt; As we implement walking onions, we're faced with a problem: what to do
&gt; with TAP keys?  They are bulky and insecure, and not used for anything
&gt; besides v2 onion services.  Keeping them in SNIPs would consume
&gt; bandwidth, and keeping them indirectly would consume complexity.  It
&gt; would be nicer to remove TAP keys entirely.
&gt; 
&gt; But although v2 onion services are obsolescent and their
&gt; cryptographic parameters are disturbing, we do not want to drop
&gt; support for them as part of the Walking Onions migration.  If we did
&gt; so, then we would force some users to choose between Walking Onions
&gt; and v2 onion services, which we do not want to do.

I haven't read the entire proposal so I won't comment on its technical aspect.
I was reading and got here and that made me very uncertain about the whole
proposal itself.

I will propose that we revisit the overall idea of changing v2 here.

I personally think this is the wrong approach. Onion services v2 should be
deprecated as in removed from the network instead of being offered as a choice
to the users.

We haven't properly done a deprecation path yet for v2 primarly due to our
lack of time to do so. But at this point in time, where the network is 100%
composed of relays supporting v3 now (which took 3+ years to get there), it is
time for v2 to not be presented as a choice anymore.

It is a codebase that is barely maintained, no new features are being added to
it and thus moving it to ntor means another at least 3 years of network
migration. This would mean a major new feature in that deprecated code base...

So thus, I personally will argue that moving v2 to ntor is really not the
right thing to do. Onion service v2 are, at this point in time, _dangerous_
choice for the users.

Cheers!
David

-- 
A6ufpccBUu9sxu+cw0b1qX9hKnkXjLXyU5P1hxeBhsk=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200513144642</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-13 14:46:42-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

Hi Nick,

&gt; On 14 May 2020, at 00:09, David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt; 
&gt; On 11 May (16:47:53), Nick Mathewson wrote:
&gt; 
&gt;&gt; ```
&gt;&gt; Filename: 320-tap-out-again.md
&gt;&gt; Title: Removing TAP usage from v2 onion services
&gt;&gt; Author: Nick Mathewson
&gt;&gt; Created: 11 May 2020
&gt;&gt; Status: Open
&gt;&gt; ```
&gt;&gt; 
&gt;&gt; (This proposal is part of the Walking Onions spec project.  It updates
&gt;&gt; proposal 245.)
&gt;&gt; 
&gt;&gt; # Removing TAP from v2 onion services
&gt;&gt; 
&gt;&gt; As we implement walking onions, we're faced with a problem: what to do
&gt;&gt; with TAP keys?  They are bulky and insecure, and not used for anything
&gt;&gt; besides v2 onion services.  Keeping them in SNIPs would consume
&gt;&gt; bandwidth, and keeping them indirectly would consume complexity.  It
&gt;&gt; would be nicer to remove TAP keys entirely.
&gt;&gt; 
&gt;&gt; But although v2 onion services are obsolescent and their
&gt;&gt; cryptographic parameters are disturbing, we do not want to drop
&gt;&gt; support for them as part of the Walking Onions migration.  If we did
&gt;&gt; so, then we would force some users to choose between Walking Onions
&gt;&gt; and v2 onion services, which we do not want to do.
&gt; 
&gt; I haven't read the entire proposal so I won't comment on its technical aspect.
&gt; I was reading and got here and that made me very uncertain about the whole
&gt; proposal itself.
&gt; 
&gt; I will propose that we revisit the overall idea of changing v2 here.
&gt; 
&gt; I personally think this is the wrong approach. Onion services v2 should be
&gt; deprecated as in removed from the network instead of being offered as a choice
&gt; to the users.
&gt; 
&gt; We haven't properly done a deprecation path yet for v2 primarly due to our
&gt; lack of time to do so. But at this point in time, where the network is 100%
&gt; composed of relays supporting v3 now (which took 3+ years to get there), it is
&gt; time for v2 to not be presented as a choice anymore.
&gt; 
&gt; It is a codebase that is barely maintained, no new features are being added to
&gt; it and thus moving it to ntor means another at least 3 years of network
&gt; migration. This would mean a major new feature in that deprecated code base...
&gt; 
&gt; So thus, I personally will argue that moving v2 to ntor is really not the
&gt; right thing to do. Onion service v2 are, at this point in time, _dangerous_
&gt; choice for the users.

I agree that we shouldn't support old features forever. And it seems unwise
to spend development effort just to migrate away from TAP, when we could
instead spend that time migrating away from TAP and v2 onion services.
(And reducing our dependency on SHA1 and RSA keys.)

Strategically, it also seems unwise to carry v2 onion services, TAP
handshakes, RSA relay keys and signatures, and SHA1 into walking onions.

But it's hard to make these kinds of decisions without approximate
timeframes.

How long would it take to migrate away from v2 onion services?

How long would it take to introduce walking onions?

If we decide to modify v2 onion services, how long would that migration
take? And what's the final plan to end the modified v2 onion services?

T



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200513153640</emailId><senderName>Paul Syverson</senderName><senderEmail>paul.syverson@nrl.navy.mil</senderEmail><timestampReceived>2020-05-13 15:36:40-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

On Thu, May 14, 2020 at 12:46:42AM +1000, teor wrote:
&gt; Hi Nick,
&gt; 
&gt; &gt; On 14 May 2020, at 00:09, David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt; &gt; 
&gt; &gt; On 11 May (16:47:53), Nick Mathewson wrote:
&gt; &gt; 
&gt; &gt;&gt; ```
&gt; &gt;&gt; Filename: 320-tap-out-again.md
&gt; &gt;&gt; Title: Removing TAP usage from v2 onion services
&gt; &gt;&gt; Author: Nick Mathewson
&gt; &gt;&gt; Created: 11 May 2020
&gt; &gt;&gt; Status: Open
&gt; &gt;&gt; ```
&gt; &gt;&gt; 
&gt; &gt;&gt; (This proposal is part of the Walking Onions spec project.  It updates
&gt; &gt;&gt; proposal 245.)
&gt; &gt;&gt; 
&gt; &gt;&gt; # Removing TAP from v2 onion services
&gt; &gt;&gt; 
&gt; &gt;&gt; As we implement walking onions, we're faced with a problem: what to do
&gt; &gt;&gt; with TAP keys?  They are bulky and insecure, and not used for anything
&gt; &gt;&gt; besides v2 onion services.  Keeping them in SNIPs would consume
&gt; &gt;&gt; bandwidth, and keeping them indirectly would consume complexity.  It
&gt; &gt;&gt; would be nicer to remove TAP keys entirely.
&gt; &gt;&gt; 
&gt; &gt;&gt; But although v2 onion services are obsolescent and their
&gt; &gt;&gt; cryptographic parameters are disturbing, we do not want to drop
&gt; &gt;&gt; support for them as part of the Walking Onions migration.  If we did
&gt; &gt;&gt; so, then we would force some users to choose between Walking Onions
&gt; &gt;&gt; and v2 onion services, which we do not want to do.
&gt; &gt; 
&gt; &gt; I haven't read the entire proposal so I won't comment on its technical aspect.
&gt; &gt; I was reading and got here and that made me very uncertain about the whole
&gt; &gt; proposal itself.
&gt; &gt; 
&gt; &gt; I will propose that we revisit the overall idea of changing v2 here.
&gt; &gt; 
&gt; &gt; I personally think this is the wrong approach. Onion services v2 should be
&gt; &gt; deprecated as in removed from the network instead of being offered as a choice
&gt; &gt; to the users.
&gt; &gt; 
&gt; &gt; We haven't properly done a deprecation path yet for v2 primarly due to our
&gt; &gt; lack of time to do so. But at this point in time, where the network is 100%
&gt; &gt; composed of relays supporting v3 now (which took 3+ years to get there), it is
&gt; &gt; time for v2 to not be presented as a choice anymore.
&gt; &gt; 
&gt; &gt; It is a codebase that is barely maintained, no new features are being added to
&gt; &gt; it and thus moving it to ntor means another at least 3 years of network
&gt; &gt; migration. This would mean a major new feature in that deprecated code base...
&gt; &gt; 
&gt; &gt; So thus, I personally will argue that moving v2 to ntor is really not the
&gt; &gt; right thing to do. Onion service v2 are, at this point in time, _dangerous_
&gt; &gt; choice for the users.
&gt; 
&gt; I agree that we shouldn't support old features forever. And it seems unwise
&gt; to spend development effort just to migrate away from TAP, when we could
&gt; instead spend that time migrating away from TAP and v2 onion services.
&gt; (And reducing our dependency on SHA1 and RSA keys.)
&gt; 
&gt; Strategically, it also seems unwise to carry v2 onion services, TAP
&gt; handshakes, RSA relay keys and signatures, and SHA1 into walking onions.
&gt; 
&gt; But it's hard to make these kinds of decisions without approximate
&gt; timeframes.
&gt; 
&gt; How long would it take to migrate away from v2 onion services?
&gt; 
&gt; How long would it take to introduce walking onions?
&gt; 
&gt; If we decide to modify v2 onion services, how long would that migration
&gt; take? And what's the final plan to end the modified v2 onion services?
&gt; 

I completely agree about not maintaining things forever and that there
are security reasons for abandoning v2 (much) sooner than later, but
as always I don't think we can just blanketly state what is a
dangerous choice for users without specifying a usage and adversary
context. I'm not trying to open a discussion of how dangerous this is
or getting people to give that specification, only cautioning against
such unqualified statements.

Another element in this decision making is whether to take into
account and engage with the userbase for v2 onion services. The most
salient case is probably facebook, but there may be others with a
significant amount vested in specific v2 addresses. We could just make
decisions about a timeline and inform them, or we could engage with at
least some of the more popular or larger v2 onion services to see if
they have reasons e.g. why officially announcing EOL in e.g. 3 months
is fine, but 2 months would make for craziness for them.

Si Vales, Valeo,
Paul
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200513182940</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-05-13 18:29:40-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


 Nick Mathewson wrote:
&gt; ```
&gt; Filename: 320-tap-out-again.md
&gt; Title: Removing TAP usage from v2 onion services
&gt; Author: Nick Mathewson
&gt; Created: 11 May 2020
&gt; Status: Open
&gt; ```
&gt; 
&gt; (This proposal is part of the Walking Onions spec project.  It updates
&gt; proposal 245.)
&gt; 
&gt; # Removing TAP from v2 onion services
&gt; 
&gt; As we implement walking onions, we're faced with a problem: what to do
&gt; with TAP keys?  They are bulky and insecure, and not used for anything
&gt; besides v2 onion services.  Keeping them in SNIPs would consume
&gt; bandwidth, and keeping them indirectly would consume complexity.  It
&gt; would be nicer to remove TAP keys entirely.
&gt; 
&gt; But although v2 onion services are obsolescent and their
&gt; cryptographic parameters are disturbing, we do not want to drop
&gt; support for them as part of the Walking Onions migration.  If we did
&gt; so, then we would force some users to choose between Walking Onions
&gt; and v2 onion services, which we do not want to do.
&gt; 

I also think this might not be worth it. The engineering time-cost far
exceeds the gains and it also decreases the security of users with yet
another penalty on Tor network performance and code-base maintenance. It
just extends the time of inevitable: dropping v2 onions entirely, so I
agree with Teor, David and Paul.

I won't also repeat the obvious about RSA1024 and SHA1, these two just
don't mix up well with Tor and the attention it gets, the userbase it
has and the amount of motivated, well funded attackers particularly
targeting onion services.

What I can say and could make a penny here is that I really keep an eye
on onion services usage in external, unrelated projects, and keep
contact with people in those communities. To be frank, I think that at
present time most of v2 onion traffic is from bitcoin full nodes in
Tor-land, facebook and people using onioncat for UDP in Tor or other
tunneling related stuff.

They do so not because they want or like, but simply because v3 onion
addresses are much larger and need some code change. However, work is
undergo. IIRC onioncat was already patched to support v3 at some level.
Bitcoin is changing their p2p protocol to support larger address space.

Other v2 onion traffic might be our own apt repositories channels and
other tp.o services, as well as some Debian derivatives offering updates
over Tor -- these all know about v3 onion services and want to move to
v3 -- they were just waiting for OnionBalance v3 which I heavily tested
and it was improved (asn's credit - I only did the testing and bug
hunting): at this moment there is a tagged 0.2.0 release which is rock
solid and can safely be used in PROD mode.

Of course there is probably an unknown number of websites that still use
v2, but I am pretty sure they will switch to v3 sooner rather than
later. After all, it's trivial to switch for most users (those that
don't have dependencies on tools that do not support such large
addresses - I'm not aware of any others than what I've mentioned).

All in all I can only see advantages in adding enhancements and
improvements to v3 onion services and setting a reasonable and smooth
deprecation plan for v2 services. The crypto used in v2 is already under
recommendations - while of course it doesn't technically mean that if
Tor supports them it also endorses them, some users might still not get
it and don't upgrade to v3 unless they really need to (on the logic as
long as it works, leave it on). Forcing the upgrade for users own
protection + a lot of benefits on Tor network and code side mentioned by
teor does not seam like a wrong approach at all to me.

Thanks.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200519173517</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-05-19 17:35:17-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

On Mon, May 11, 2020 at 8:52 PM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; &gt; On 12 May 2020, at 06:48, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; &gt;
&gt; &gt; ## Migration steps
&gt; &gt;
&gt; &gt; First, we implement all of the above, but set it to be disabled by
&gt; &gt; default.  We use torrc fields to selectively enable them for testing
&gt; &gt; purposes, to make sure they work.
&gt;
&gt; Can you expand on the testing plan here?
&gt;
&gt; One of the risks with multi-year migration projects is that unrelated
&gt; changes break the migration, and we don't notice.
&gt;
&gt; For example, you might need to create a chutney network for each
&gt; stage, and run them on every pull request and merge. In our current
&gt; CI, that's 30-60 seconds of extra time per network, or 2-4 extra
&gt; minutes of CI time.
&gt;
&gt; If you need to test different combinations of features for each stage,
&gt; let's try to do that in the same networks. Otherwise, the testing matrix
&gt; expands out very quickly.

I agree here think that the right approach here is to test for the
various ways that we expect the network to exist at a time.  The
trickiest stage of the migration will be the one where some services
support ntor keys and some don't, some clients do and some don't.  If
we add a chutney network for that case specifically and make sure that
all clients can reach all services, we should be fine here.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200519175537</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-19 17:55:37-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

On Wed, May 13, 2020 at 10:09 AM David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt;
&gt; On 11 May (16:47:53), Nick Mathewson wrote:
&gt;
&gt; Hello!
&gt;
&gt; &gt; ```
&gt; &gt; Filename: 320-tap-out-again.md
&gt; &gt; Title: Removing TAP usage from v2 onion services
&gt; &gt; Author: Nick Mathewson
&gt; &gt; Created: 11 May 2020
&gt; &gt; Status: Open
&gt; &gt; ```
&gt; &gt;
&gt; &gt; (This proposal is part of the Walking Onions spec project.  It updates
&gt; &gt; proposal 245.)
&gt; &gt;
&gt; &gt; # Removing TAP from v2 onion services
&gt; &gt;
&gt; &gt; As we implement walking onions, we're faced with a problem: what to do
&gt; &gt; with TAP keys?  They are bulky and insecure, and not used for anything
&gt; &gt; besides v2 onion services.  Keeping them in SNIPs would consume
&gt; &gt; bandwidth, and keeping them indirectly would consume complexity.  It
&gt; &gt; would be nicer to remove TAP keys entirely.
&gt; &gt;
&gt; &gt; But although v2 onion services are obsolescent and their
&gt; &gt; cryptographic parameters are disturbing, we do not want to drop
&gt; &gt; support for them as part of the Walking Onions migration.  If we did
&gt; &gt; so, then we would force some users to choose between Walking Onions
&gt; &gt; and v2 onion services, which we do not want to do.
&gt;
&gt; I haven't read the entire proposal so I won't comment on its technical aspect.
&gt; I was reading and got here and that made me very uncertain about the whole
&gt; proposal itself.
&gt;
&gt; I will propose that we revisit the overall idea of changing v2 here.
&gt;
&gt; I personally think this is the wrong approach. Onion services v2 should be
&gt; deprecated as in removed from the network instead of being offered as a choice
&gt; to the users.
&gt;
&gt; We haven't properly done a deprecation path yet for v2 primarly due to our
&gt; lack of time to do so. But at this point in time, where the network is 100%
&gt; composed of relays supporting v3 now (which took 3+ years to get there), it is
&gt; time for v2 to not be presented as a choice anymore.
&gt;
&gt; It is a codebase that is barely maintained, no new features are being added to
&gt; it and thus moving it to ntor means another at least 3 years of network
&gt; migration. This would mean a major new feature in that deprecated code base...
&gt;
&gt; So thus, I personally will argue that moving v2 to ntor is really not the
&gt; right thing to do. Onion service v2 are, at this point in time, _dangerous_
&gt; choice for the users.

Hi, David!  I'm sympathetic to this point of view: I certainly don't
like carrying around old code either.

If we do decide to finally deprecate v2 onion services, that would be
a significant maintenance burden reduced for us, but we'd have to
handle the transition carefully.  Unlike all the other migrations
we've done, there isn't a drop-in path to get the same functionality
or keep the same identities with v3 onion services.  (And the problem
is that there _can't_ be: the identities are strongly tied to
80-bit-truncated-SHA1 and RSA-1024, and the lack of key blinding makes
them enumerable.)


The main reason I wrote this proposal is this: Any deprecation will
probably cause a few users to stick with the old versions of the code
for as long as they still work on the network, even if those versions
become unsupported and insecure.  (After all, people who listen to our
advice about what is secure and what isn't have already stopped using
v2 onion services.) .

Is it time to start this deprecation?  If so we need to start working
on a timeline, and I agree with Teor that we'd need to figure out how
that timeline would work with any walking onions timeline.

One possible role for this proposal is to be kept in reserve, in case
somebody feels so strongly that they want v2 services to work that
they want to maintain them themselves, or pay for somebody else to do
it.  If so, we can indicate this proposal as "the right way to keep v2
services working without TAP", make it clear that we don't plan to
implement it, and move along.


There are other ways to keep TAP working with walking onions, but they
seem kludgey too, and would also require implementation changes for v2
onion services.

What do others think?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200519213628</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2020-05-19 21:36:28-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

Hi there,

&gt; On 19. May 2020, at 19:55, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; If we do decide to finally deprecate v2 onion services, that would be
&gt; a significant maintenance burden reduced for us, but we'd have to
&gt; handle the transition carefully.  Unlike all the other migrations
&gt; we've done, there isn't a drop-in path to get the same functionality
&gt; or keep the same identities with v3 onion services.  (And the problem
&gt; is that there _can't_ be: the identities are strongly tied to
&gt; 80-bit-truncated-SHA1 and RSA-1024, and the lack of key blinding makes
&gt; them enumerable.)

I would be exstatic about not having V2 onions around anymore. This
would reduce a huge attack vector that incentivizes people to set up
malicious relays, which causes huge amounts of time lost, the relays
shouldn't have this opportunity to harvest onions, etc.

&gt; The main reason I wrote this proposal is this: Any deprecation will
&gt; probably cause a few users to stick with the old versions of the code
&gt; for as long as they still work on the network, even if those versions
&gt; become unsupported and insecure.  (After all, people who listen to our
&gt; advice about what is secure and what isn't have already stopped using
&gt; v2 onion services.) .

I kind of don't buy the statement in the parentheses, we don't seem
to discourage v2 strongly at all afaict. Or is there a warning when
you use it or connect to it, for example?

A question, is the HSDir flag for both v2 and v3 onions? If not we
could just take that away to break v2 at some point.

&gt; Is it time to start this deprecation?  If so we need to start working
&gt; on a timeline, and I agree with Teor that we'd need to figure out how
&gt; that timeline would work with any walking onions timeline.

I think it should have been started a while ago :)

&gt; What do others think?

Cheers
Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200426225624</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-04-26 22:56:24-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hi Christian,

thanks for your efforts to improve DNS resolution in the tor context.

A few general questions:
- What is the underlying threat model and what threats you are trying to address in
your proposal?
- What use case are you aiming for? Do you propose to make use of this DNS resolution \
                in Tor Browser by default?
- if so: 
  - Do you do connection re-use to route multiple DNS queries over a single \
                connection? (related: RFC 7766)
  - How does your proposal (or the user of your proposal - Tor Browser) ensure stream \
                isolation for DNS queries to avoid profiling based on DNS queries?
  - How do you aim to solve the problems of resolver selection and centralization?
if not:
  - why not just run existing resolver software (i.e. stubby) over tor?

- How does your design compare to running existing DNS privacy protocols over tor \
                that do not require any changes to tor?
  - DoT non-opportunistic mode+DNSSEC validation or 
  - DoH+DNSSEC validation

I would also be interesting to see how your design compares to a design like this 
(aiming for Tor Browser integration and enabled by default, without tor changes):
DoH (RFC 8484) enabled in Tor Browser, the vanilla DoH implementation in Firefox \
slightly changed so it is stream isolation aware (domains are resolved via the same \
stream that is used to fetch the HTTP content in all cases where the exit policy \
allows for that). Resolver selection: pre-configured list in Tor Browser
(no implementation or proposal exists at this point)

&gt; Filename: 317-secure-dns-name-resolution.txt
&gt; Title: Improve security aspects of DNS name resolution
&gt; Author: Christian Hofer
&gt; Created: 21-Mar-2020
&gt; Status: Open
&gt; 
&gt; Overview:
&gt; 
&gt; This document proposes a solution for handling DNS name resolution within
&gt; Tor in a secure manner. In order to achieve this the responsibility for
&gt; name resolution is moved from the exit relays to the clients. Therefore a
&gt; security aware DNS resolver is required that is able to operate using Tor.


&gt; DNSResolverNameservers: A list of comma separated nameservers, can be an
&gt; IPv4, an IPv6, or an onion address. Should allow means to configure the
&gt; port and supported zones.

How is end-to-end encryption / query confidentiality ensured in the case this
configuration parameter contains IPv4/IPv6 addresses?

 
&gt; DNSResolverHiddenServiceZones: A list of comma separated hidden service
&gt; zones.

What are "hidden service zones"? what is the impact of listing them in this config \
parameter and how is it related to RFC 7686?

&gt; DNSResolverTrustAnchors: A list of comma separated trust anchors in DS
&gt; record format. https://www.iana.org/dnssec/files

Does your design support RFC 5011?

&gt; DNSResolverMaxCacheEntries: Specifies the maximum number of cache
&gt; entries.


Where is the cache located? Is it written to disk?
Is the cache stream isolation aware or do you aim to reuse the cache across multiple \
streams? (which results in correlation issues across streams)

&gt; Performance and scalability:
&gt; 
&gt; Since there are no direct changes to the protocol and this is an alternative
&gt; approach for an already existing requirement, there are no performance
&gt; issues expected. Additionally, the encoding and decoding of DNS message
&gt; handling as well as the verification takes place on the client side.

A few remarks regarding performance (DNS resolution response time and subsequent \
                content fetches i.e. HTTPS):
- this design increases the network path when the configured resolver is not the exit \
                relay
- a design that will not use the exit for resolution will likely have a performance \
impact on domains that do geoIP based optimizations to allow i.e. HTTP fetches from \
locations near the exit relay


kind regards,
nusenu


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200427124106</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-04-27 12:41:06-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Sun, Apr 26, 2020 at 4:32 PM Christian Hofer &lt;chrisss404@gmail.com&gt; wrote:
&gt;
&gt; Hi there,
&gt;
&gt; I have a proposal regarding DNS name resolution.
&gt;
&gt; Ticket: https://trac.torproject.org/projects/tor/ticket/34004
&gt; Proposal:
&gt; https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
&gt; Implementation: https://github.com/torproject/tor/pull/1869
&gt;
&gt; All functioniality is behind the DNSResolver feature flag, so don't
&gt; forget to activate it before you start testing.
&gt;
&gt; Please let me know what you think.

Added to the torspec repository as proposal 317.  This is cool stuff!
I'm behind in proposal review but I'll try to catch up soon.  It's
good to see other people with good questions too, here and on the
ticket.

peace,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200514195654</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-14 19:56:54-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]


On 26 Apr (19:37:56), Christian Hofer wrote:
&gt; Hi there,

Greetings Christian!

&gt; 
&gt; I have a proposal regarding DNS name resolution.
&gt; 
&gt; Ticket: https://trac.torproject.org/projects/tor/ticket/34004
&gt; Proposal: 
&gt; https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
&gt; Implementation: https://github.com/torproject/tor/pull/1869

First, this is quite impressive piece of work. I was _NOT_ expecting a 27k
line diff ;).

So the proposal looks very good. I like the idea very much. I honestly thought
that you were about to propose a way for Tor to talk to an *external* DNS
resolver client application (third part) but I see that client DNSSEC is
basically implemented in tor with your patch which is... interesting?

Before we go further, can you walk me through the reasons (if you had thought
of it of course) why you didn't use something like libunbound?

There are side effects of adding DNSSEC client support (with our own
implementation) that we, people maintaining tor, have to become DNSSEC expert
in some ways just to be able to understand what is happening in that code, fix
issues but also possibly implement new features if any. That is where a third
part library like unbound becomes very nice because they are the experts at
providing such features.

Of course, everytime we have to link to an external library we do it carefully
and with considerations because of the "yet another attack" vector problem.
But adding that much code to support a well known feature like DNSSEC also has
huge implications for tor maintainability and security.

Finally, something I noticed and made me itch a bit. You hardcoded a lot of
.onions where one appears to be Cloudflare (?) resolver. What are the other
addresses? I worry here because default options are always the one used the
most so I'm concerned here about shipping hardcoded addresses _within_ our C
code.

Thanks!
David

-- 
dApigzB8NtOQEAlKqhqbshxjxOMakjiX9LGU9wvhFqs=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515152944</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-05-15 15:29:44-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hello Christian,

On 2020/04/26 19:37, Christian Hofer wrote:
&gt; I have a proposal regarding DNS name resolution.
&gt; 
&gt; Ticket: https://trac.torproject.org/projects/tor/ticket/34004
&gt; Proposal: 
&gt; https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
&gt; Implementation: https://github.com/torproject/tor/pull/1869
&gt; 
&gt; All functioniality is behind the DNSResolver feature flag, so don't
&gt; forget to activate it before you start testing.
&gt; 
&gt; Please let me know what you think.

Thanks for doing this work. I think our DNS subsystem has been lacking
behind for a while. This work is exciting.

Generally, after having done one pass over your code, I think the source
code is good quality, especially if this is your first contribution to
Tor! However, I think this is going to be a bit problematic for us to
import.

It will be hard, if not impossible, for Tor's Network Team to adopt 27k
LOC's in one pull-request. We will have to have multiple people going
over each line repeatedly and try to build up some confidence in this
code. If we are to go down this path, with having a complete DNS
subsystem in Tor, we need to add some capacity from our side to take
this in and maintain it. I think that with the recent layoffs in Tor, it
will be hard to achieve in a time-frame that is fair towards you.

One of the goals with our specification process is to have a set of
documents, which allows other people to understand how Tor is working to
the point where they should be able to implement Tor from scratch if
they found that useful. This isn't always possible today, but this is a
goal we should have in mind. Your proposal is mostly a specification of
the *implementation* of the DNS resolver patches and doesn't contain any
information on any changes to the network layer of Tor. Instead, those
seem to be referenced as the various DNS related RFCs from the IETF.
Configuration options of the Tor binary is largely an implementation
detail.

I wonder if it would make more sense to have an onion-aware
DNSSEC-enabled resolver *outside* of the Tor binary and have a way for
Tor to query an external tool for DNS lookups. Such tool should be
allowed to use Tor itself for transport of the actual queries. One of
the best parts of Tor (in my opinion) is the Pluggable Transport
subsystem. This subsystem allows external developers, researchers, and
hackers to build new technology that benefits users in censored areas
*without* having to alter a single line of C code in tor.git.

Let's say we had a "Pluggable DNS" layer in Tor. Users would be able to
configure their Tor process to *never* use the built-in DNS subsystem in
Tor, but instead outsource it to an external process that Tor spawns on
startup. This process could use .onion's to reach a
DNS-over-(TLS|HTTPS|TCP) server as onions themselves aren't looked up
via DNS.

A "Pluggable DNS" subsystem would be much less code, I believe, and it
wouldn't require us to have a DNS+DNSSEC implementation in the heart of
Tor to maintain in the future. Such a system would be similar to the
proposed design for Name =&gt; Onion lookups defined in proposal #279 by
asn, yawning, and dgoulet.

Lastly, I assume it's just for testing purpose, but I don't think we
could ship with CloudFlare's DNS-over-Onion services as the default
servers for a feature like this without having a discussion in the
community about it first :-)

All the best,
Alex.

-- 
Alexander Fry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515153923</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-15 15:39:23-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Thu, 2020-05-14 at 15:56 -0400, David Goulet wrote:
&gt; On 26 Apr (19:37:56), Christian Hofer wrote:
&gt; &gt; Hi there,
&gt; 
&gt; Greetings Christian!
&gt; 

Hi David!

&gt; &gt; I have a proposal regarding DNS name resolution.
&gt; &gt; 
&gt; &gt; Ticket: https://trac.torproject.org/projects/tor/ticket/34004
&gt; &gt; Proposal: 
&gt; &gt; https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
&gt; &gt; Implementation: https://github.com/torproject/tor/pull/1869
&gt; 
&gt; First, this is quite impressive piece of work. I was _NOT_ expecting
&gt; a 27k
&gt; line diff ;).
&gt; 

Yeah this might look scary at first, but if you take a closer look it
is not that bad.

More than half of the lines account for tests: 15,437

3,584 test_crypto_dnssec.c
1,456 test_crypto_dnssec_openssl.c
  726 test_dns_message.c
5,105 test_dns_resolver.c
1,389 test_dns_string.c
3,177 test_dns_wireformat.c

Another big part accounts for containers and translators: 6,531

They don't contain much logic and their main purpose is to translate
DNS message &lt;-&gt; wireformat and DNS message &lt;-&gt; string. So this area
shouldn't change very often, except you want to add support for new DNS
types or the specification for an existing DNS type changes, which
shouldn't actually happen.

1,150 dns_message.c
  173 dns_message.h
  457 dns_message_st.h
  199 dns_types.h 
1,564 dns_string.c
   80 dns_string.h
2,586 dns_wireformat.c
  322 dns_wireformat.h

The most interesting part accounts (only) for 4,970 lines (2,066
relevant lines). It contains all the DNS resolution and DNSSEC
validation logic. 

* The dns_lookup_st contains state related types that lives in AP
connections (entry_connection_t).
* The dns_resolver is responsible for sending and receiving DNS
messages, validating DNS messages using crypto_dnssec, and caching DNS
messages.
* The crypto_dnssec contains all required DNSSEC algorithms.

lines / relevant / coverage / filename 

   57 /        0 /    100.0 / dns_lookup_st.h
2,564 /    1,197 /    98.75 / dns_resolver.c
  179 /        0 /    100.0 / dns_resolver.h 
1,478 /      684 /    98.83 / crypto_dnssec.c
  495 /      185 /    99.46 / crypto_dnssec_openssl.c
  197 /        0 /    100.0 / crypto_dnssec.h

These numbers were taken from the coveralls report: 
https://coveralls.io/builds/30352518

&gt; So the proposal looks very good. I like the idea very much. I
&gt; honestly thought
&gt; that you were about to propose a way for Tor to talk to an *external*
&gt; DNS
&gt; resolver client application (third part) but I see that client DNSSEC
&gt; is
&gt; basically implemented in tor with your patch which is... interesting?
&gt; 
&gt; Before we go further, can you walk me through the reasons (if you had
&gt; thought
&gt; of it of course) why you didn't use something like libunbound?
&gt; 

I might be wrong, please correct me if so. The scenario I was aiming
for is when the target address that is received within the socks
handshake in connection_ap_handshake_process_socks is a hostname. As
far as I understand it, in this case the name resolution is done at the
exit relay that is also responsible for retrieving the contents from
the target. This means that the user has to trust the exit relay in
terms of name resolution? However, I am not sure if this is a valid use
case or if you can cover this using libunbound. So please let me know.

Using the DNS resolver would resolve the hostname upfront in a separate
connection that is not related to the connection that is responsible
for retrieving the contents from the target. Additionally, the user has
control over the nameserver that should be used for name resolution and
is also able to verify the response using DNSSEC. So this should
reduces the number of entities that must be trusted.

&gt; There are side effects of adding DNSSEC client support (with our own
&gt; implementation) that we, people maintaining tor, have to become
&gt; DNSSEC expert
&gt; in some ways just to be able to understand what is happening in that
&gt; code, fix
&gt; issues but also possibly implement new features if any. That is where
&gt; a third
&gt; part library like unbound becomes very nice because they are the
&gt; experts at
&gt; providing such features.
&gt; 

I can understand this.

&gt; Of course, everytime we have to link to an external library we do it
&gt; carefully
&gt; and with considerations because of the "yet another attack" vector
&gt; problem.
&gt; But adding that much code to support a well known feature like DNSSEC
&gt; also has
&gt; huge implications for tor maintainability and security.
&gt; 
&gt; Finally, something I noticed and made me itch a bit. You hardcoded a
&gt; lot of
&gt; .onions where one appears to be Cloudflare (?) resolver. What are the
&gt; other
&gt; addresses? I worry here because default options are always the one
&gt; used the
&gt; most so I'm concerned here about shipping hardcoded addresses
&gt; _within_ our C
&gt; code.
&gt; 

Regarding the the default configuration. There is a configuration
called DNSResolver which defaults to off. As long as this flag is
turned off nothing changes related to DNS resolution.
Yes, the first onion is the Cloudflare resolver. The other onion
addresses are DNS resolvers (PowerDNS Recursor) behind hidden services
which I used and am still using for testing. They can be easily changed
/ removed (?) since it is only a configuration and as mentioned if you
want to activate this feature you have to enable the DNSResolver flag
first.

Final remarks. When I started, I didn't expect it to get this big, and
frankly, if I had known before, I might not have even started. However,
I learned a lot about DNS, DNSSEC, SOCKS, and Tor. So even if you
decide not to merge it, it was not a waste :-)

In the end you have to decide if you want to add this and I can
understand if you don't want to maintain DNS related code. At least it
would be interesting how the different solutions compare regarding
performance, security, and maintainability. What do you think?


&gt; Thanks!
&gt; David

BR
Christian

&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515155300</emailId><senderName>Jeremy Rand</senderName><senderEmail>jeremyrand@airmail.cc</senderEmail><timestampReceived>2020-05-15 15:53:00-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Alexander Fry:
&gt; I wonder if it would make more sense to have an onion-aware
&gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a way for
&gt; Tor to query an external tool for DNS lookups. Such tool should be
&gt; allowed to use Tor itself for transport of the actual queries. One of
&gt; the best parts of Tor (in my opinion) is the Pluggable Transport
&gt; subsystem. This subsystem allows external developers, researchers, and
&gt; hackers to build new technology that benefits users in censored areas
&gt; *without* having to alter a single line of C code in tor.git.
&gt; 
&gt; Let's say we had a "Pluggable DNS" layer in Tor. Users would be able to
&gt; configure their Tor process to *never* use the built-in DNS subsystem in
&gt; Tor, but instead outsource it to an external process that Tor spawns on
&gt; startup. This process could use .onion's to reach a
&gt; DNS-over-(TLS|HTTPS|TCP) server as onions themselves aren't looked up
&gt; via DNS.
&gt; 
&gt; A "Pluggable DNS" subsystem would be much less code, I believe, and it
&gt; wouldn't require us to have a DNS+DNSSEC implementation in the heart of
&gt; Tor to maintain in the future. Such a system would be similar to the
&gt; proposed design for Name =&gt; Onion lookups defined in proposal #279 by
&gt; asn, yawning, and dgoulet.

Hi Alex,

FYI I already wrote a Prop279 provider that looks up the names via DNS
(it's aptly named "dns-prop279"); it does pretty much exactly what you
describe.  It doesn't handle DNSSEC validation itself (it assumes that
you've specified a DNS server that you trust -- most likely one running
on localhost).  Stream isolation can be handled via an EDNS0 field (and
I'm guessing it would not be difficult to patch an existing DNS server
to respect that EDNS0 field).  I wouldn't be surprised if it's easy to
make dns-prop279 do DNSSEC validation itself (and not use a
localhost-based DNS server) if that's desired -- the library it uses
(miekg/dns) does claim to support DNSSEC validation, though I've never
tried testing that feature.

I originally wrote dns-prop279 for Namecoin purposes, but I see no
reason it couldn't be used to achieve DNSSEC support in Tor.  If there's
interest in pursuing this, let me know, I'm happy to contribute.

Code is at https://github.com/namecoin/dns-prop279

Cheers,
-- 
-Jeremy Rand
Lead Application Engineer at Namecoin
Mobile email: jeremyrandmobile@airmail.cc
Mobile OpenPGP: 2158 0643 C13B B40F B0FD 5854 B007 A32D AB44 3D9C
Send non-security-critical things to my Mobile with OpenPGP.
Please don't send me unencrypted messages.
My business email jeremy@veclabs.net is having technical issues at the
moment.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515162158</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-15 16:21:58-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Fri, 2020-05-15 at 15:29 +0000, Alexander Fry wrote:
&gt; Hello Christian,
&gt; 

Hi Alex!

&gt; On 2020/04/26 19:37, Christian Hofer wrote:
&gt; &gt; I have a proposal regarding DNS name resolution.
&gt; &gt; 
&gt; &gt; Ticket: https://trac.torproject.org/projects/tor/ticket/34004
&gt; &gt; Proposal: 
&gt; &gt; https://trac.torproject.org/projects/tor/attachment/ticket/34004/317-secure-dns-name-resolution.txt
&gt; &gt; Implementation: https://github.com/torproject/tor/pull/1869
&gt; &gt; 
&gt; &gt; All functioniality is behind the DNSResolver feature flag, so don't
&gt; &gt; forget to activate it before you start testing.
&gt; &gt; 
&gt; &gt; Please let me know what you think.
&gt; 
&gt; Thanks for doing this work. I think our DNS subsystem has been
&gt; lacking
&gt; behind for a while. This work is exciting.
&gt; 
&gt; Generally, after having done one pass over your code, I think the
&gt; source
&gt; code is good quality, especially if this is your first contribution
&gt; to
&gt; Tor! However, I think this is going to be a bit problematic for us to
&gt; import.
&gt; 
&gt; It will be hard, if not impossible, for Tor's Network Team to adopt
&gt; 27k
&gt; LOC's in one pull-request. We will have to have multiple people going
&gt; over each line repeatedly and try to build up some confidence in this
&gt; code. If we are to go down this path, with having a complete DNS
&gt; subsystem in Tor, we need to add some capacity from our side to take
&gt; this in and maintain it. I think that with the recent layoffs in Tor,
&gt; it
&gt; will be hard to achieve in a time-frame that is fair towards you.
&gt; 

There are not many changes to the existing code, but most of the code
is new. How could I prepare the changes to simplify the review? Since
most parts depend on other parts within this change, I don't think it
would be a good approach to split them up in multiple PRs?

&gt; One of the goals with our specification process is to have a set of
&gt; documents, which allows other people to understand how Tor is working
&gt; to
&gt; the point where they should be able to implement Tor from scratch if
&gt; they found that useful. This isn't always possible today, but this is
&gt; a
&gt; goal we should have in mind. Your proposal is mostly a specification
&gt; of
&gt; the *implementation* of the DNS resolver patches and doesn't contain
&gt; any
&gt; information on any changes to the network layer of Tor. Instead,
&gt; those
&gt; seem to be referenced as the various DNS related RFCs from the IETF.
&gt; Configuration options of the Tor binary is largely an implementation
&gt; detail.
&gt; 

There is only one entry and one exit point, apart from this there are
no further changes to the network layer if you consider these
changes even as a change to the network layer. See the sections
"SocksPort related changes" and "DNSPort related changes" in the
proposal. The DNS resolver implementation should of course comply to
the DNS RFCs.
I would like to try to improve the specification. So, you suggest to
remove the section about configuration options and add more details
about network layer changes?

&gt; I wonder if it would make more sense to have an onion-aware
&gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a way
&gt; for
&gt; Tor to query an external tool for DNS lookups. Such tool should be
&gt; allowed to use Tor itself for transport of the actual queries. One of
&gt; the best parts of Tor (in my opinion) is the Pluggable Transport
&gt; subsystem. This subsystem allows external developers, researchers,
&gt; and
&gt; hackers to build new technology that benefits users in censored areas
&gt; *without* having to alter a single line of C code in tor.git.
&gt; 
&gt; Let's say we had a "Pluggable DNS" layer in Tor. Users would be able
&gt; to
&gt; configure their Tor process to *never* use the built-in DNS subsystem
&gt; in
&gt; Tor, but instead outsource it to an external process that Tor spawns
&gt; on
&gt; startup. This process could use .onion's to reach a
&gt; DNS-over-(TLS|HTTPS|TCP) server as onions themselves aren't looked up
&gt; via DNS.
&gt; 

Sounds great. Let's start?

&gt; A "Pluggable DNS" subsystem would be much less code, I believe, and
&gt; it
&gt; wouldn't require us to have a DNS+DNSSEC implementation in the heart
&gt; of
&gt; Tor to maintain in the future. Such a system would be similar to the
&gt; proposed design for Name =&gt; Onion lookups defined in proposal #279 by
&gt; asn, yawning, and dgoulet.
&gt; 
&gt; Lastly, I assume it's just for testing purpose, but I don't think we
&gt; could ship with CloudFlare's DNS-over-Onion services as the default
&gt; servers for a feature like this without having a discussion in the
&gt; community about it first :-)
&gt; 

You are right. There is even the DNSResolver flag that defaults to off,
which completely disables this feature.

&gt; All the best,
&gt; Alex.
&gt; 

BR
Christian

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515162420</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-05-15 16:24:20-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hey Jeremy,

On 2020/05/15 15:53, Jeremy Rand wrote:
&gt; FYI I already wrote a Prop279 provider that looks up the names via DNS
&gt; (it's aptly named "dns-prop279"); it does pretty much exactly what you
&gt; describe.  It doesn't handle DNSSEC validation itself (it assumes that
&gt; you've specified a DNS server that you trust -- most likely one running
&gt; on localhost).  Stream isolation can be handled via an EDNS0 field (and
&gt; I'm guessing it would not be difficult to patch an existing DNS server
&gt; to respect that EDNS0 field).  I wouldn't be surprised if it's easy to
&gt; make dns-prop279 do DNSSEC validation itself (and not use a
&gt; localhost-based DNS server) if that's desired -- the library it uses
&gt; (miekg/dns) does claim to support DNSSEC validation, though I've never
&gt; tried testing that feature.

Very interesting.

I think proposal #279 only tries to solve the subset of name look ups,
which is about looking up onions from a human name. The work in this
thread is to replace all name lookups *except* for Onions. It could very
well be that it would be easier to extend proposal #279 by having it
handle all lookups and not just for .onion's, but I think my intuition
says that it should be two different systems as onion lookups is still a
much more open question whereas Tor will need to support ordinary DNS
for many years into the future.

If `OnionNamePlugin` allowed you to specify `.*` for "everything" as the
TLD specifier, then it might be possible to implement such system using
proposal #279 :-)

All the best,
Alex.

-- 
Alexander Fry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515163600</emailId><senderName>Jeremy Rand</senderName><senderEmail>jeremyrand@airmail.cc</senderEmail><timestampReceived>2020-05-15 16:36:00-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Alexander Fry:
&gt; Hey Jeremy,
&gt; 
&gt; On 2020/05/15 15:53, Jeremy Rand wrote:
&gt;&gt; FYI I already wrote a Prop279 provider that looks up the names via DNS
&gt;&gt; (it's aptly named "dns-prop279"); it does pretty much exactly what you
&gt;&gt; describe.  It doesn't handle DNSSEC validation itself (it assumes that
&gt;&gt; you've specified a DNS server that you trust -- most likely one running
&gt;&gt; on localhost).  Stream isolation can be handled via an EDNS0 field (and
&gt;&gt; I'm guessing it would not be difficult to patch an existing DNS server
&gt;&gt; to respect that EDNS0 field).  I wouldn't be surprised if it's easy to
&gt;&gt; make dns-prop279 do DNSSEC validation itself (and not use a
&gt;&gt; localhost-based DNS server) if that's desired -- the library it uses
&gt;&gt; (miekg/dns) does claim to support DNSSEC validation, though I've never
&gt;&gt; tried testing that feature.
&gt; 
&gt; Very interesting.
&gt; 
&gt; I think proposal #279 only tries to solve the subset of name look ups,
&gt; which is about looking up onions from a human name. The work in this
&gt; thread is to replace all name lookups *except* for Onions. It could very
&gt; well be that it would be easier to extend proposal #279 by having it
&gt; handle all lookups and not just for .onion's, but I think my intuition
&gt; says that it should be two different systems as onion lookups is still a
&gt; much more open question whereas Tor will need to support ordinary DNS
&gt; for many years into the future.
&gt; 
&gt; If `OnionNamePlugin` allowed you to specify `.*` for "everything" as the
&gt; TLD specifier, then it might be possible to implement such system using
&gt; proposal #279 :-)

Hi Alex,

The Prop279 spec text is ambiguous about whether the target is required
to be a .onion domain, but the implementations (TorNS and StemNS) do not
have that restriction.  TorNS and StemNS allow a Prop279 plugin to
advertise acceptance of any domain suffix (haven't explicitly tried the
root zone as an suffix, but if that doesn't work, it's a bug that should
be easy to fix) and can resolve them to any result (e.g. an IP address,
a .onion domain, or another DNS name a la CNAME).

Cheers,
-- 
-Jeremy Rand
Lead Application Engineer at Namecoin
Mobile email: jeremyrandmobile@airmail.cc
Mobile OpenPGP: 2158 0643 C13B B40F B0FD 5854 B007 A32D AB44 3D9C
Send non-security-critical things to my Mobile with OpenPGP.
Please don't send me unencrypted messages.
My business email jeremy@veclabs.net is having technical issues at the
moment.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515165329</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2020-05-15 16:53:29-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hey,

On 2020/05/15 16:36, Jeremy Rand wrote:
&gt; The Prop279 spec text is ambiguous about whether the target is required
&gt; to be a .onion domain, but the implementations (TorNS and StemNS) do not
&gt; have that restriction.  TorNS and StemNS allow a Prop279 plugin to
&gt; advertise acceptance of any domain suffix (haven't explicitly tried the
&gt; root zone as an suffix, but if that doesn't work, it's a bug that should
&gt; be easy to fix) and can resolve them to any result (e.g. an IP address,
&gt; a .onion domain, or another DNS name a la CNAME).

In proposal #279 the subprocess passes the `RESOLVED` message to Tor
once it is has completed a name look up. The `RESOLVED` message is
defined as follows:

    ``When the name plugin completes the name resolution, it prints the
    following line in its stdout:

        RESOLVED &lt;QUERY_ID&gt; &lt;STATUS_CODE&gt; &lt;RESULT&gt;

    where QUERY_ID is the corresponding query ID and STATUS_CODE is an integer
    status code. RESULT is the resolution result (an onion address) or an error
    message if the resolution was not succesful.''

Here the `&lt;RESULT&gt;` must be an onion address. We would have to change
that, such that an IP address can be returned as well :-)

All the best,
Alex.

-- 
Alexander Fry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515172200</emailId><senderName>Jeremy Rand</senderName><senderEmail>jeremyrand@airmail.cc</senderEmail><timestampReceived>2020-05-15 17:22:00-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Alexander Fry:
&gt; Hey,
&gt; 
&gt; On 2020/05/15 16:36, Jeremy Rand wrote:
&gt;&gt; The Prop279 spec text is ambiguous about whether the target is required
&gt;&gt; to be a .onion domain, but the implementations (TorNS and StemNS) do not
&gt;&gt; have that restriction.  TorNS and StemNS allow a Prop279 plugin to
&gt;&gt; advertise acceptance of any domain suffix (haven't explicitly tried the
&gt;&gt; root zone as an suffix, but if that doesn't work, it's a bug that should
&gt;&gt; be easy to fix) and can resolve them to any result (e.g. an IP address,
&gt;&gt; a .onion domain, or another DNS name a la CNAME).
&gt; 
&gt; In proposal #279 the subprocess passes the `RESOLVED` message to Tor
&gt; once it is has completed a name look up. The `RESOLVED` message is
&gt; defined as follows:
&gt; 
&gt;     ``When the name plugin completes the name resolution, it prints the
&gt;     following line in its stdout:
&gt; 
&gt;         RESOLVED &lt;QUERY_ID&gt; &lt;STATUS_CODE&gt; &lt;RESULT&gt;
&gt; 
&gt;     where QUERY_ID is the corresponding query ID and STATUS_CODE is an integer
&gt;     status code. RESULT is the resolution result (an onion address) or an error
&gt;     message if the resolution was not succesful.''
&gt; 
&gt; Here the `&lt;RESULT&gt;` must be an onion address. We would have to change
&gt; that, such that an IP address can be returned as well :-)

Hi Alex,

The ambiguity I was referring to is that while the section you quote
does require that the result be a .onion domain, below it is this note:

&gt; Tor MUST validate that the resolution result is a valid .onion name.
&gt; XXX should we also accept IPs and regular domain results???

Prop279 is clearly labeled as a draft, so this makes it appear that no
decision was reached on whether the result should be required to be a
.onion domain.

My opinion is that accepting non-.onion addresses as results is
desirable (both because it's useful for the Namecoin use case and
because it's useful for the DNSSEC use case that we're discussing).

Cheers,
-- 
-Jeremy Rand
Lead Application Engineer at Namecoin
Mobile email: jeremyrandmobile@airmail.cc
Mobile OpenPGP: 2158 0643 C13B B40F B0FD 5854 B007 A32D AB44 3D9C
Send non-security-critical things to my Mobile with OpenPGP.
Please don't send me unencrypted messages.
My business email jeremy@veclabs.net is having technical issues at the
moment.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515183047</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2020-05-15 18:30:47-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Fri, May 15, 2020 at 05:39:23PM +0200, Christian Hofer wrote:
&gt; Final remarks. When I started, I didn't expect it to get this big, and
&gt; frankly, if I had known before, I might not have even started. However,
&gt; I learned a lot about DNS, DNSSEC, SOCKS, and Tor. So even if you
&gt; decide not to merge it, it was not a waste :-)

Hi Christian!

Given the above learning, let me ask you a related question. Or maybe
rather, a question about an alternative design.

As I understand it, the design in your patch is basically to let the
Tor client talk via Tor to an authenticated dns server that the client
chooses, and do the DNS interaction to satisfy itself that the DNS answer
is correct.

And because the DNS server is a different destination than the original
stream destination, this requires another round-trip through Tor, for
doing the resolve?

And maybe it's way worse than that, because to do DNSSEC properly, you
need to go up the chain, with a new round-trip over Tor for each link
in the chain?

Whereas in the current Tor design, we have no extra round-trips for the
DNS component, because the client sends the hostname in the BEGIN cell,
and the exit relay resolves it and connects, and then sends the IP
address back in the CONNECTED cell in case the client wanted to know it.

To me, extra round-trips over the Tor network in the critical path of
"user clicks and waits for the website to load" are really bad, and
need a really good argument for being there. Given that DNS is only one
piece of the connection -- after all, the exit relay can still route you
somewhere else -- it's hard to see how this case brings enough benefit
to justify the extra round trip(s).

Ok, with that as a preface, here is an alternative design: the Tor
client sends the hostname to the exit relay, along with a request for
dnssec proofs. The exit relay uses its own dnssec server to convince
itself that its answer is right. Then it returns the IP address in
the CONNECTED cell as it does now, and also it returns a set of dnssec
answers that the client can use to reconstruct the dnssec interaction
and convince itself of the result too.

This design adds no extra round trips (yay), but it requires a notion of
"dnssec chain stapling" that I think doesn't entirely exist yet. Alex
points me to a long-expired IETF draft from agl on the topic:
https://tools.ietf.org/html/draft-agl-dane-serializechain-01
and I don't know if there is newer progress.

I would also worry about the overall size of the stapled answers -- if we
add another 50KBytes to every stream interaction in Tor, that's probably
not worth it. Whereas adding another 1KByte could be a great tradeoff.

Yet another twist here is that it's hard for the client to cache answers,
or to cache intermediate certs in the chain, because changing behavior
based on cached answers can reveal the client's past browsing history.

Do these goals make sense? :)

Thanks!
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515233718</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-15 23:37:18-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Alexander Fry:
&gt; I wonder if it would make more sense to have an onion-aware
&gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a way for
&gt; Tor to query an external tool for DNS lookups. 

I'm also in favor of this approach,
and you can do this today with no code changes to tor at all.

CF demonstrated it even before DoH/RFC8484 was finalized:
https://blog.cloudflare.com/welcome-hidden-resolver/


&gt; Such tool should be
&gt; allowed to use Tor itself for transport of the actual queries. One of
&gt; the best parts of Tor (in my opinion) is the Pluggable Transport
&gt; subsystem. This subsystem allows external developers, researchers, and
&gt; hackers to build new technology that benefits users in censored areas
&gt; *without* having to alter a single line of C code in tor.git.
&gt; 
&gt; Let's say we had a "Pluggable DNS" layer in Tor. Users would be able to
&gt; configure their Tor process to *never* use the built-in DNS subsystem in
&gt; Tor, but instead outsource it to an external process that Tor spawns on
&gt; startup. This process could use .onion's to reach a
&gt; DNS-over-(TLS|HTTPS|TCP) server as onions themselves aren't looked up
&gt; via DNS.

+ 1 for DoT and DoH over tor, especially due to the DoH implementation that is
available in firefox (it would still require work on stream isolation and caching
risks to ensure the usual first party isolation).
In terms of achieving a big improvement on tor browser users in the context of DNS
this would be the most effective path to spend coding resources on in my opinion.






["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515233729</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-15 23:37:29-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; To me, extra round-trips over the Tor network in the critical path of
&gt; "user clicks and waits for the website to load" are really bad, and
&gt; need a really good argument for being there. Given that DNS is only one
&gt; piece of the connection -- after all, the exit relay can still route you
&gt; somewhere else -- it's hard to see how this case brings enough benefit
&gt; to justify the extra round trip(s).
&gt; 
&gt; Ok, with that as a preface, here is an alternative design: the Tor
&gt; client sends the hostname to the exit relay, along with a request for
&gt; dnssec proofs. The exit relay uses its own dnssec server to convince
&gt; itself that its answer is right. Then it returns the IP address in
&gt; the CONNECTED cell as it does now, and also it returns a set of dnssec
&gt; answers that the client can use to reconstruct the dnssec interaction
&gt; and convince itself of the result too.
&gt; 
&gt; This design adds no extra round trips (yay), but it requires a notion of
&gt; "dnssec chain stapling" that I think doesn't entirely exist yet. Alex
&gt; points me to a long-expired IETF draft from agl on the topic:
&gt; https://tools.ietf.org/html/draft-agl-dane-serializechain-01
&gt; and I don't know if there is newer progress.

also expired but newer
https://datatracker.ietf.org/doc/draft-ietf-tls-dnssec-chain-extension/
 
&gt; I would also worry about the overall size of the stapled answers -- if we
&gt; add another 50KBytes to every stream interaction in Tor, that's probably
&gt; not worth it. Whereas adding another 1KByte could be a great tradeoff.
&gt; 
&gt; Yet another twist here is that it's hard for the client to cache answers,
&gt; or to cache intermediate certs in the chain, because changing behavior
&gt; based on cached answers can reveal the client's past browsing history.

I share your concerns on performance (additional round trips) and caching and I find it also important
to note that in the context of tor browser (probably the main use case of tor)
encrypted DNS (confidentiality) is more relevant than DNSSEC (integrity), 
especially as soon as ESNI becomes reality. 
https://datatracker.ietf.org/doc/draft-ietf-tls-esni/
That will allow for using tor exits without disclosing the visited domain to the exit relay
and no more issues with exits with broken DNS.
DNSSEC would still be valuable for TLS verification but DANE for https does not appear to be a thing.




["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515233740</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-15 23:37:40-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; I can not really say anything about how this design compares to other
&gt; approaches, since I don't know how I can setup meaningful test
&gt; scenarios to compare them. 

Do we really need test setups to discuss protocol designs 
and compare protocols with a common threat model if specs for the
protocols are available? 

&gt; However, I would appreciate if you could
&gt; share how to setup such test environments. 

take your preferred DoT client implementation that supports the strict profile (RFC8310)
or your preferred DoH implementation and route it over tor to your resolver of choice.



["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515233750</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-15 23:37:50-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; Before we go further, can you walk me through the reasons (if you had thought
&gt; of it of course) why you didn't use something like libunbound?
&gt; 
&gt; There are side effects of adding DNSSEC client support (with our own
&gt; implementation) that we, people maintaining tor, have to become DNSSEC expert
&gt; in some ways just to be able to understand what is happening in that code, fix
&gt; issues but also possibly implement new features if any. That is where a third
&gt; part library like unbound becomes very nice because they are the experts at
&gt; providing such features.
&gt; 
&gt; Of course, everytime we have to link to an external library we do it carefully
&gt; and with considerations because of the "yet another attack" vector problem.
&gt; But adding that much code to support a well known feature like DNSSEC also has
&gt; huge implications for tor maintainability and security.
&gt; 
&gt; Finally, something I noticed and made me itch a bit. You hardcoded a lot of
&gt; .onions where one appears to be Cloudflare (?) resolver. What are the other
&gt; addresses? I worry here because default options are always the one used the
&gt; most so I'm concerned here about shipping hardcoded addresses _within_ our C
&gt; code.

+1 for "don't roll your own DNS(SEC) implementation". There are people that do \
DNS(SEC) for years,  should the torproject really implement and maintain its own \
custom DNS stub resolver and DNSSEC validator?

Also consider that DNS is moving towards DNS encryption protocols (DoT and DoH) and \
firefox has DoH support that could be made stream isolation aware. 
Using open protocols will increase the availability of multiple public resolvers \
speaking that protocol.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200516094147</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-16 09:41:47-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Fri, 2020-05-15 at 14:30 -0400, Roger Dingledine wrote:
&gt; On Fri, May 15, 2020 at 05:39:23PM +0200, Christian Hofer wrote:
&gt; &gt; Final remarks. When I started, I didn't expect it to get this big,
&gt; &gt; and
&gt; &gt; frankly, if I had known before, I might not have even started.
&gt; &gt; However,
&gt; &gt; I learned a lot about DNS, DNSSEC, SOCKS, and Tor. So even if you
&gt; &gt; decide not to merge it, it was not a waste :-)
&gt; 
&gt; Hi Christian!
&gt; 

Hi Roger!

&gt; Given the above learning, let me ask you a related question. Or maybe
&gt; rather, a question about an alternative design.
&gt; 
&gt; As I understand it, the design in your patch is basically to let the
&gt; Tor client talk via Tor to an authenticated dns server that the
&gt; client
&gt; chooses, and do the DNS interaction to satisfy itself that the DNS
&gt; answer
&gt; is correct.
&gt; 

Yes. Exactly.

&gt; And because the DNS server is a different destination than the
&gt; original
&gt; stream destination, this requires another round-trip through Tor, for
&gt; doing the resolve?
&gt; 
&gt; And maybe it's way worse than that, because to do DNSSEC properly,
&gt; you
&gt; need to go up the chain, with a new round-trip over Tor for each link
&gt; in the chain?
&gt; 

Yes, that is a big concern. However, that is the trade-off you have to
consider (performance vs security).

&gt; Whereas in the current Tor design, we have no extra round-trips for
&gt; the
&gt; DNS component, because the client sends the hostname in the BEGIN
&gt; cell,
&gt; and the exit relay resolves it and connects, and then sends the IP
&gt; address back in the CONNECTED cell in case the client wanted to know
&gt; it.
&gt; 
&gt; To me, extra round-trips over the Tor network in the critical path of
&gt; "user clicks and waits for the website to load" are really bad, and
&gt; need a really good argument for being there. Given that DNS is only
&gt; one
&gt; piece of the connection -- after all, the exit relay can still route
&gt; you
&gt; somewhere else -- it's hard to see how this case brings enough
&gt; benefit
&gt; to justify the extra round trip(s).
&gt; 

I understand.

&gt; Ok, with that as a preface, here is an alternative design: the Tor
&gt; client sends the hostname to the exit relay, along with a request for
&gt; dnssec proofs. The exit relay uses its own dnssec server to convince
&gt; itself that its answer is right. Then it returns the IP address in
&gt; the CONNECTED cell as it does now, and also it returns a set of
&gt; dnssec
&gt; answers that the client can use to reconstruct the dnssec interaction
&gt; and convince itself of the result too.
&gt; 
&gt; This design adds no extra round trips (yay), but it requires a notion
&gt; of
&gt; "dnssec chain stapling" that I think doesn't entirely exist yet. Alex
&gt; points me to a long-expired IETF draft from agl on the topic:
&gt; https://tools.ietf.org/html/draft-agl-dane-serializechain-01
&gt; and I don't know if there is newer progress.
&gt; 

Sounds very interesting. This would definitely save a lot of time
(round trips).

&gt; I would also worry about the overall size of the stapled answers --
&gt; if we
&gt; add another 50KBytes to every stream interaction in Tor, that's
&gt; probably
&gt; not worth it. Whereas adding another 1KByte could be a great
&gt; tradeoff.
&gt; 
&gt; Yet another twist here is that it's hard for the client to cache
&gt; answers,
&gt; or to cache intermediate certs in the chain, because changing
&gt; behavior
&gt; based on cached answers can reveal the client's past browsing
&gt; history.
&gt; 

For my proposal this is true. For your proposal if you get all DNS
messages required for performing chain validation in one big batch you
don't have to cache intermediates but only the resulting DNS record and
caching would be feasible.

&gt; Do these goals make sense? :)
&gt; 

Yes, I think this would be a big improvement. Let me know if you plan
to start working on a design / implementation to get this done.

&gt; Thanks!
&gt; --Roger
&gt; 

BR
Christian

&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200524161704</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-24 16:17:04-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Sat, 2020-05-16 at 01:37 +0200, nusenu wrote:
&gt; &gt; Before we go further, can you walk me through the reasons (if you
&gt; &gt; had thought
&gt; &gt; of it of course) why you didn't use something like libunbound?
&gt; &gt; 
&gt; &gt; There are side effects of adding DNSSEC client support (with our
&gt; &gt; own
&gt; &gt; implementation) that we, people maintaining tor, have to become
&gt; &gt; DNSSEC expert
&gt; &gt; in some ways just to be able to understand what is happening in
&gt; &gt; that code, fix
&gt; &gt; issues but also possibly implement new features if any. That is
&gt; &gt; where a third
&gt; &gt; part library like unbound becomes very nice because they are the
&gt; &gt; experts at
&gt; &gt; providing such features.
&gt; &gt; 
&gt; &gt; Of course, everytime we have to link to an external library we do
&gt; &gt; it carefully
&gt; &gt; and with considerations because of the "yet another attack" vector
&gt; &gt; problem.
&gt; &gt; But adding that much code to support a well known feature like
&gt; &gt; DNSSEC also has
&gt; &gt; huge implications for tor maintainability and security.
&gt; &gt; 
&gt; &gt; Finally, something I noticed and made me itch a bit. You hardcoded
&gt; &gt; a lot of
&gt; &gt; .onions where one appears to be Cloudflare (?) resolver. What are
&gt; &gt; the other
&gt; &gt; addresses? I worry here because default options are always the one
&gt; &gt; used the
&gt; &gt; most so I'm concerned here about shipping hardcoded addresses
&gt; &gt; _within_ our C
&gt; &gt; code.
&gt; 
&gt; +1 for "don't roll your own DNS(SEC) implementation". There are
&gt; people that do DNS(SEC) for years, 
&gt; should the torproject really implement and maintain its own custom
&gt; DNS stub resolver and DNSSEC validator?
&gt; 

Yep. I agree in general. I think this is a hard decision someone has to
take.

&gt; Also consider that DNS is moving towards DNS encryption protocols
&gt; (DoT and DoH) and firefox
&gt; has DoH support that could be made stream isolation aware. 
&gt; Using open protocols will increase the availability of multiple
&gt; public resolvers speaking that protocol.
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200524161718</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-24 16:17:18-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Sat, 2020-05-16 at 01:37 +0200, nusenu wrote:
&gt; &gt; I can not really say anything about how this design compares to
&gt; &gt; other
&gt; &gt; approaches, since I don't know how I can setup meaningful test
&gt; &gt; scenarios to compare them. 
&gt; 
&gt; Do we really need test setups to discuss protocol designs 
&gt; and compare protocols with a common threat model if specs for the
&gt; protocols are available? 
&gt; 

I think it depends on the context. However, if you want to neglect the
context you can just compare plain DNS employing DNSSEC (authenticity
and integrity) to DoH / DoT (confidentiality). There are quite a few
comparisons out there, e.g.: [1]. 

[1] 
https://blog.circuitsofimagination.com/2018/11/08/dns-o-t-dnssec-dns-o-h.html

&gt; &gt; However, I would appreciate if you could
&gt; &gt; share how to setup such test environments. 
&gt; 
&gt; take your preferred DoT client implementation that supports the
&gt; strict profile (RFC8310)
&gt; or your preferred DoH implementation and route it over tor to your
&gt; resolver of choice.
&gt; 

If you put it like this, then the proposed design would save the
required TLS / HTTPS handshake you have in DoT / DoH and would add
authenticity and integrity verification of DNS responses. However, the
confidentiality you get with DoH / DoT (at the exit realy, which may
not even be necessary?) would be missing.

&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200524161724</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-24 16:17:24-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Sat, 2020-05-16 at 01:37 +0200, nusenu wrote:
&gt; Alexander Fry:
&gt; &gt; I wonder if it would make more sense to have an onion-aware
&gt; &gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a way
&gt; &gt; for
&gt; &gt; Tor to query an external tool for DNS lookups. 
&gt; 
&gt; I'm also in favor of this approach,
&gt; and you can do this today with no code changes to tor at all.
&gt; 
&gt; CF demonstrated it even before DoH/RFC8484 was finalized:
&gt; https://blog.cloudflare.com/welcome-hidden-resolver/
&gt; 

Do you have DNSSEC validation in this approach? Looking at [1] it seems
that it is only a proxy forwarding requests. I can not see any
verification of answers. What you achieve here is that you no longer
have to trust the exit relays, but now you have to trust CF. I don't
think this such a big improvement.

If you want to add DNSSEC validation to this setup using unbound or
something else you have the issue with additional round-trips as
pointed out by Roger. And you have no means to reduce them in this
scenario.

[1] https://github.com/cloudflare/cloudflared

&gt; 
&gt; &gt; Such tool should be
&gt; &gt; allowed to use Tor itself for transport of the actual queries. One
&gt; &gt; of
&gt; &gt; the best parts of Tor (in my opinion) is the Pluggable Transport
&gt; &gt; subsystem. This subsystem allows external developers, researchers,
&gt; &gt; and
&gt; &gt; hackers to build new technology that benefits users in censored
&gt; &gt; areas
&gt; &gt; *without* having to alter a single line of C code in tor.git.
&gt; &gt; 
&gt; &gt; Let's say we had a "Pluggable DNS" layer in Tor. Users would be
&gt; &gt; able to
&gt; &gt; configure their Tor process to *never* use the built-in DNS
&gt; &gt; subsystem in
&gt; &gt; Tor, but instead outsource it to an external process that Tor
&gt; &gt; spawns on
&gt; &gt; startup. This process could use .onion's to reach a
&gt; &gt; DNS-over-(TLS|HTTPS|TCP) server as onions themselves aren't looked
&gt; &gt; up
&gt; &gt; via DNS.
&gt; 
&gt; + 1 for DoT and DoH over tor, especially due to the DoH
&gt; implementation that is
&gt; available in firefox (it would still require work on stream isolation
&gt; and caching
&gt; risks to ensure the usual first party isolation).
&gt; In terms of achieving a big improvement on tor browser users in the
&gt; context of DNS
&gt; this would be the most effective path to spend coding resources on in
&gt; my opinion.
&gt; 
&gt; 

It seems that Firefox's DoH implementation does not employ DNSSEC
validation, see [2]. They trust CF doing it for them. Be careful here.

Furthermore, there are privacy concerns about additional metadata
regarding the use of DoH (agent headers, language settings, and
cookies) see [3]. To be fair I have to admit that I have not looked
into this myself.

[2] 
https://support.mozilla.org/en-US/kb/dns-over-https-doh-faqs#w_do-you-validate-dnssec
[3] 
https://nlnog.net/static/nlnogday2019/5_NLNOG_day_2019_Bert_Hubert_DNS_TLS_Privacy.pdf


&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200524161728</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-24 16:17:28-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Fri, 2020-05-15 at 14:30 -0400, Roger Dingledine wrote:
&gt; On Fri, May 15, 2020 at 05:39:23PM +0200, Christian Hofer wrote:
&gt; &gt; Final remarks. When I started, I didn't expect it to get this big,
&gt; &gt; and
&gt; &gt; frankly, if I had known before, I might not have even started.
&gt; &gt; However,
&gt; &gt; I learned a lot about DNS, DNSSEC, SOCKS, and Tor. So even if you
&gt; &gt; decide not to merge it, it was not a waste :-)
&gt; 
&gt; Hi Christian!
&gt; 
&gt; Given the above learning, let me ask you a related question. Or maybe
&gt; rather, a question about an alternative design.
&gt; 
&gt; As I understand it, the design in your patch is basically to let the
&gt; Tor client talk via Tor to an authenticated dns server that the
&gt; client
&gt; chooses, and do the DNS interaction to satisfy itself that the DNS
&gt; answer
&gt; is correct.
&gt; 
&gt; And because the DNS server is a different destination than the
&gt; original
&gt; stream destination, this requires another round-trip through Tor, for
&gt; doing the resolve?
&gt; 
&gt; And maybe it's way worse than that, because to do DNSSEC properly,
&gt; you
&gt; need to go up the chain, with a new round-trip over Tor for each link
&gt; in the chain?
&gt; 
&gt; Whereas in the current Tor design, we have no extra round-trips for
&gt; the
&gt; DNS component, because the client sends the hostname in the BEGIN
&gt; cell,
&gt; and the exit relay resolves it and connects, and then sends the IP
&gt; address back in the CONNECTED cell in case the client wanted to know
&gt; it.
&gt; 
&gt; To me, extra round-trips over the Tor network in the critical path of
&gt; "user clicks and waits for the website to load" are really bad, and
&gt; need a really good argument for being there. Given that DNS is only
&gt; one
&gt; piece of the connection -- after all, the exit relay can still route
&gt; you
&gt; somewhere else -- it's hard to see how this case brings enough
&gt; benefit
&gt; to justify the extra round trip(s).
&gt; 
&gt; Ok, with that as a preface, here is an alternative design: the Tor
&gt; client sends the hostname to the exit relay, along with a request for
&gt; dnssec proofs. The exit relay uses its own dnssec server to convince
&gt; itself that its answer is right. Then it returns the IP address in
&gt; the CONNECTED cell as it does now, and also it returns a set of
&gt; dnssec
&gt; answers that the client can use to reconstruct the dnssec interaction
&gt; and convince itself of the result too.
&gt; 
&gt; This design adds no extra round trips (yay), but it requires a notion
&gt; of
&gt; "dnssec chain stapling" that I think doesn't entirely exist yet. Alex
&gt; points me to a long-expired IETF draft from agl on the topic:
&gt; https://tools.ietf.org/html/draft-agl-dane-serializechain-01
&gt; and I don't know if there is newer progress.
&gt; 
&gt; I would also worry about the overall size of the stapled answers --
&gt; if we
&gt; add another 50KBytes to every stream interaction in Tor, that's
&gt; probably
&gt; not worth it. Whereas adding another 1KByte could be a great
&gt; tradeoff.
&gt; 

A follow-up to answer sizes. Here is a list of domain lookups with
sizes in wireformat (A record including the chain up to the root zone).
See attachments for more details on the contents.

aus5.mozilla.org           / 12 RRs / 8968 bytes / 8.8 KB / signed   /
2 CNAMEs / 3 TLDs
example.com                /  6 RRs / 4241 bytes / 4.1 KB / signed   /
0 CNAMEs / 1 TLD
www.dnssec-ok.acei.ca      / 11 RRs / 8405 bytes / 8.2 KB / signed   /
1 CNAME  / 2 TLDs
www.dnssec-invalid.acei.ca / 11 RRs / 8495 bytes / 8.3 KB / signed   /
1 CNAME  / 2 TLDs
www.torproject.org         /  6 RRs / 4401 bytes / 4.3 KB / signed   /
0 CNAMEs / 1 TLD
duckduckgo.com             /  5 RRs / 3053 bytes / 3.0 KB / unsigned /
0 CNAMEs / 1 TLD
cdnjs.cloudflare.com       /  6 RRs / 2955 bytes / 2.9 KB / signed   /
0 CNAMEs / 1 TLD
matt.traudt.xyz            / 14 RRs / 9011 bytes / 8.8 KB / signed   /
2 CNAMEs / 3 TLDs
www.norid.no               /  6 RRs / 4042 bytes / 3.9 KB / signed   /
1 CNAME  / 1 TLD
www.wikipedia.org          /  6 RRs / 4212 bytes / 4.1 KB / unsigned /
1 CNAME  / 1 TLD
enabled.dnssec.hkirc.hk    / 10 RRs / 7542 bytes / 7.4 KB / signed   /
0 CNAMEs / 1 TLD

&gt; Yet another twist here is that it's hard for the client to cache
&gt; answers,
&gt; or to cache intermediate certs in the chain, because changing
&gt; behavior
&gt; based on cached answers can reveal the client's past browsing
&gt; history.
&gt; 
&gt; Do these goals make sense? :)
&gt; 
&gt; Thanks!
&gt; --Roger
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

["aus5.mozilla.org.txt" (aus5.mozilla.org.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 7, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
aus5.mozilla.org. 	IN	A

ANSWER SECTION:
aus5.mozilla.org. 	12	IN	CNAME	balrog-aus5.r53-2.services.mozilla.com.
aus5.mozilla.org. 	12	IN	RRSIG	CNAME 7 3 60 1590287117 1590549917 27767 mozilla.org. \
FzPDo3az6+1kgoPst46NM1toZSO5/vNrGnm1jv9JVCwIlW8mcobUvgixvkujjtbyRIhfLqZ/5UtlVipclaOPJO \
6HSeciTp2JgHyAIcM4VyebF0IVLFonHU41ShJBsqLE/ZXgZkD3JYvbG/bjwkYxVsTsxoBkLMSYBnGV9J4/dC8=
 balrog-aus5.r53-2.services.mozilla.com. \
776	IN	CNAME	balrog-cloudfront.prod.mozaws.net. balrog-cloudfront.prod.mozaws.net. \
59	IN	A	13.224.95.71 balrog-cloudfront.prod.mozaws.net. 	59	IN	A	13.224.95.129
balrog-cloudfront.prod.mozaws.net. 	59	IN	A	13.224.95.15
balrog-cloudfront.prod.mozaws.net. 	59	IN	A	13.224.95.39

ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	58252	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	58252	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	58252	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DS

ANSWER SECTION:
org.       	82119	IN	DS	17883 7 1 38C5CF93B369C7557E0515FAAA57060F1BFB12C1
org.       	82119	IN	DS	17883 7 2 \
D889CAD790F01979E860D6627B58F85AB554E0E491FE06515F35548D1EB4E6EE org.       \
82119	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
q98M9S0lf8aORT+4+97k2VUWhy37NT9UOVvY9OhQuz3DDlC4iMVO4NiylR/q7P1aMme/WiuEN/654kqhRbdfvX \
HNgQBoEWHWcbfiVg1qot5NsYQyGZ7euA6VWNABTiwCnfNhwf5t/Pw4lWxvWfrpakoFPmfMqyHFxdISmqZ+j4lW \
eGCmdocqupbvum55Pe/nh//YhYh71xikIYGqTH13Yva12k/zFYWKWwACaNPkLLuQNZisj9Xp2Gtnpyz60S0Ajr \
Adh2XlQoLpAfQrZjfdyLxeUZ9YOvLUPWlTHbboiEeFhw+UswIPe2mGJipS8577zlfkT/CkE94oTIuSNMZg0g==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DNSKEY

ANSWER SECTION:
org.       	802	IN	DNSKEY	256 3 7 \
AwEAAdmwceOWXmoXZj0PLI0LWOWz47/nqFoSesfbthZe0hmVsiHt9ywWE/4sHe6XGjlqwEzzH165ara2hKnbl8 \
FoaLf9+YV0RlmUojZlOM0WAqL8dtMj9cz663+HHrI0f1oJ6dWweED4XRBJ55j4Tks7yZTNdgCDJj09K3vercPicxN/
 org.       	802	IN	DNSKEY	256 3 7 \
AwEAAeDsADaJg3/dnppzytgK+V0cnEE89Uhn4X5CihDr1g4Xe/CawmO3vSLURrMr9n7XbBUf7Fu26z8TyHcMrB \
IwwigQz891VPQNZc5spPOsQcz43KGQVmbl0agf2TJFZihBGsuG895Q9kzJ1ls7TRpTXQYtzrdkJUxy+3xQzbNrYsIX
 org.       	802	IN	DNSKEY	257 3 7 \
AwEAAcMnWBKLuvG/LwnPVykcmpvnntwxfshHlHRhlY0F3oz8AMcuF8gw9McCw+BoC2YxWaiTpNPuxjSNhUlBtc \
Jmcdkz3/r7PIn0oDf14ept1Y9pdPh8SbIBIWx50ZPfVRlj8oQXv2Y6yKiQik7bi3MT37zMRU2kw2oy3cgrsGAz \
GN4s/C6SFYon5N1Q2O4hGDbeOq538kATOy0GFELjuauV9guX/431msYu4Rgb5lLuQ3Mx5FSIxXpI/RaAn2mhM4 \
nEZ/5IeRPKZVGydcuLBS8GZlxW4qbb8MgRZ8bwMg0pqWRHmhirGmJIt3UuzvN1pSFBfX7ysI9PPhSnwXCNDXk0kk0=
 org.       	802	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 27074 org. \
oHbegLUfWC6zJEMAtwP5upbHR6/nuY7GJKNbVsU67smder8Pfnl01ybM8rGuw3FHZmnBbRXOIcbHrjj1oJk7pp \
r+7d2v78CGE7OxcYl1GOwPEe8tg4529k84vhxlb+tHXKrAVMmYi/0MQYr9ZzJ/o0NLsbMwtYCKiMtPCmk2nV8=
 org.       	802	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 17883 org. \
B9XZ9LyfU2Ua56OSjNEWt6V4itluZdt/v9dY1TBTZRkRS4MSTYBowHW9QsLdiS3MUOK0B0fQZftWftV8AV3XPQ \
NF+R4RebqwiX/W7kYpn4L+6zDgaYOD8GkiJmyomFXqO4cf6fsYVgAU+0XluCwIwHjarIQA6yRZRhTIN9mT4AlR \
0vwo5csAA6rhRrzeA20Z70OQoQnDF2crT/3q29Ki0yXLIODN9kcjJOB881XxdD9jtSB6L3aUNSjAiKG9NO5qUc \
4cBuErEqlqsURZqXBggeLE/S/hxp/voSvRp/vKEgzQ+A7nF6d4P9G9bcjjITmeqih2/DE6NqP/hXaotv1I3Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
mozilla.org. 	IN	DS

ANSWER SECTION:
mozilla.org. 	21399	IN	DS	44421 7 1 E5052BDB5E59FB7D1FF4F56E99ECA86D29EB9834
mozilla.org. 	21399	IN	RRSIG	DS 7 2 86400 1589984588 1591802588 27074 org. \
TYXpas8xFmB+nv8mbEEYUlX+nBo4HVGPCG9BcGzSLkK2KgIsstXV8jxVREcFA1RWWC95cnnc3v8XWUCkMgIzvJ \
P4CiicVh2gPaDJT+PPbp2XpWCLvTvX+jgF0eQytqNTeuZi4R1KKm8Wvklrc4iUQIidUL/7OwVOyISA1M50e7I=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
mozilla.org. 	IN	DNSKEY

ANSWER SECTION:
mozilla.org. 	7177	IN	DNSKEY	256 3 7 \
AwEAAb5M3O40Pgt0Mb8iRdFW2jfUUoy5zXhQ+GWTJA3lSrH1AC4F2KmIEhxFV3E7dxM8MleUp/LJwj2516+Inc \
GOE64op48GTI7fgFWFMvhORI6X+rMryku6NVKrvoOKAKiQFuSDCrQ+S26qI6td+Kv7pGVuutQuOCJSYdK3lOMpygTR
 mozilla.org. 	7177	IN	DNSKEY	257 3 7 \
Av//szWRDSGz3g4JkiuQqws79YZ6nwxk0f9PF9MCQSYrRGd0f4VuuoufaKdeFvdeY4x9tGmh7FQ51Qi6EEr9LL \
y2Q8qTtEuN2fJ4PnWBNRfKwhWbSNQWvq1jwhsXlsAelLz7tO5kptI7TO16p2ncpnhJqfzT5mWJ4nK76YPZlu+M \
ZlIYJOMv/OQWD2nVmsjXeO0dnsrL8MyC5wdyPy2gbksWBscsbwN234APEYO48B6sovy2fuTVWnj7LDsEh3Nzrh \
jGYlhWmtvrXg3mlFelz/MZXrK6uAlp6206Hc669ylfhIcD9d7w0rc9Ms1DFCh5wzVRbnJJF51mW2nCmh5C8E7xSw==
 mozilla.org. 	7177	IN	DNSKEY	257 3 7 \
Av//qpFLcHzrAyY8QUvs71dy1DDDUB2+8x36MDPAerY4fgV9P2Xp8xenRYj8TeMiNLe82+1Uy77C6xTyNLRX61 \
AHRUeRZ5oeI5oyjQ7756q3NGBYC79o4ySY4KnMly3aKdIirApJ+TWu1RIII2r6A/e7yLYI/MJ2hIf91+nEEJJD \
FyuAY6l2P52yffvmPqBnCQ2JslYewxh2Xd8H1ci/F95+RdZ7Q0EOhiWLEDDs+Ox6xIec3oZK/iTuJ8O2MONtpX \
8fNd8mi/AKKi4CL0qI1khy9rYuIWOAu8ku7kOXMAedJd34jHvOesUqGLv7/fbU90rU3ZBEWkm3aQDYouN7SGIe9w==
 mozilla.org. 	7177	IN	DNSKEY	256 3 7 \
AwEAAbwmdUqkBoc9oJXvdkGVeQrm44IFZhd/sFEDO40UrXC+9Bqnk5OtYt2UgVwHLbpwJFWxNo2/bGj25PT8pR \
E00P5gKd8wifxVvJikikMQW41Nkw6OPcUi18Nh9gUxrLp0WTkqItYnOgSVGh62RvaeFaDIw2AT6gydcSJ5K3jnWKDr
 mozilla.org. 	7177	IN	RRSIG	DNSKEY 7 2 7200 1590287117 1590549917 44421 mozilla.org. \
jC5TeCaSRUhLhMuq1Ucyou+y6g4H0OEIJzRQ4sMAxCdEZJIFhnqgi1HjcZLnvqAhn0JnzzYPlXyuF7gV4OXR+i \
B1+aEW0N22HRyE8/KWTkhF+aS+jXU+4IAnEvhOknDI2x0GSrVchyRsnCDN9zSkjMLpBadTxSj/ncolLO220uok \
iXkkk2driicdWDi719IrwE8HKEYmCP9UQPsPI/ioZnGo0o8rAbhbNOHOQXqs22SFUyuMS8z9ChdQEQxMUlQk0lMJuwTcOTRDPqLggQcRIKaoBbWOzFesQ9EJzp8PFInTSYDm8EH8jTsIIr906qY8AW/bljb



==    7 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	73810	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
73810	IN	RRSIG	DS 8 1 86400 1590249600 1591376400 48903 . \
kV1mV0TZBQcFYl3az5abu6sNWeWOLvnu4977Pjkiqty3hQ5AW7xSOlLHuWwkSuPXK7kTwD/GSfP5tv2pRIlESY \
MPtvnlqtAGgUlFPYsGc3Nu5OoPBQ37M9ZgkAiWjvrjyzIbQ0I5Imc8mUtNJpVeXg5IRs9SPrcj9hcHPMjkIXfj \
wtNk4LZcDxUzVdZQF86fBj3VKC+GOjPf1ODyOr1r4iDzPdYqRBbx1Zs61IbJLiVJcgIlxPPQc/M0a6ofS8kLXP \
tXUXLUAprE8UO8v+YVw7tB6Ot6SIvP4SG3gVeKIzMi7OvS8WOkxU3Da3ZnzUV68ms66yRfSJ9xx8CKTxIJ1Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    8 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	21011	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	21011	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	21011	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    9 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
mozilla.com. 	IN	DS

AUTHORITY SECTION:
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	20989	IN	NSEC3	1 1 0  \
CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM \
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	20989	IN	RRSIG	NSEC3 8 2 86400 1590118683 \
1590727683 39844 com. \
NArL30b9Vy8GobUMocYC399NaMB4oqLbana/HTaTIz4lKkLRtFM6iuBewn3CXtCuBCZ3VfV6q0K4jvi2+su+bt \
kuGZo+Ds+9ktZo2snOzdiuqFOdalMkzpNbVUyEuiJDsFRYPpueKaWNLPv1ceo+/C20hzxUUJ0UDBCLo/RX85dLAiVl1OA8O2FPidsDyXnoCxT1vJaySfDnNkLUCqDohA==
 com.       	289	IN	SOA	a.gtld-servers.net. nstld.verisign-grs.com. 1590326678 1800 \
900 604800 86400 com.       	289	IN	RRSIG	SOA 8 1 900 1590322478 1590931478 39844 \
com. kzPrRjw7twUf7sbHlYwF5Aoh6dOW39C4RkROjsTHW7tUd3rvQ2GCv+JA8ioxiR4NDTdM5YGHAqCP8ni8n \
ADdc5MESC9TPdRbrh7qiV4ZXk6MkAAMy23NecrKpIRw/Npwh4QDKvold//9auhbFaedP7lfvQrES7AvFe3rpxWNbrGjecKWiagA/PpjZIQV5FlESmZ0MQ46qvWhJMvQeFNRhA==
 683UB7KMRII4TIJF1FR6ODCM6UI21S10.com. 	20989	IN	NSEC3	1 1 0  \
683UIUFE9VPMDULSDLOKT5U4SSCRE1R9 NS DS RRSIG 683UB7KMRII4TIJF1FR6ODCM6UI21S10.com. \
20989	IN	RRSIG	NSEC3 8 2 86400 1590038753 1590647753 39844 com. \
j1g++JsjLT8mOfK5P1w0zJ3I8s9DCeg5awnoTw4pV+t2r9EJFR6Ha8YDaKvL4Nnz/ZrtS+zPkevM92vIGAl2Km \
vMDRtRx6mBhBWIktYmcvtsHno1GmQPAYSIJtYJyr/9WRz/D1sz6AU/bTTCW8D9J/++KsAR2D6F2tP/OQNTM2fR7VJ/GE/e70TBJl3d0COhdcI9/Obh/q6KChfqankTTQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   10 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
net.       	IN	DS

ANSWER SECTION:
net.       	81525	IN	DS	35886 8 2 \
7862B27F5F516EBE19680444D4CE5E762981931842C465F00236401D8BD973EE net.       \
81525	IN	RRSIG	DS 8 1 86400 1590206400 1591333200 48903 . \
Km6+SzeT53UEB2866H8zFqn2DFcsTaOh1mgK0tKNeV0Wc11EkrYBrH+vyME+D2r9eIXO8IQEJWYl7XrFOhTG0a \
l1U7PI644mruVtHQE+rbF46hKopYRDZKIWSHQNT3uOtBuEmH6tC+PLbqiovMhwVizrPsMkcWIOLlaI8ASs4UIl \
FuF3ZEZEdJKU5r9NmUXULUHRo0Iv4dKRysb5LRmXNZHDPmjRp/d7+IPUy+bfWAbaS5PdqwrCS2W0u/jDkljh1o \
xKcozL0MBRCHASflnDQckOaOOnGUpcc90fEb2Ce4Qh0snqtQAlUyHWKItefroyGJrbq46lMwHIg5y8yFMeng==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   11 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
net.       	IN	DNSKEY

ANSWER SECTION:
net.       	16372	IN	DNSKEY	257 3 8 \
AQOYBnzqWXIEj6mlgXg4LWC0HP2n8eK8XqgHlmJ/69iuIHsa1TrHDG6TcOra/pyeGKwH0nKZhTmXSuUFGh9BCN \
iwVDuyyb6OBGy2Nte9Kr8NwWg4q+zhSoOf4D+gC9dEzg0yFdwT0DKEvmNPt0K4jbQDS4Yimb+uPKuF6yieWWrP \
YYCrv8C9KC8JMze2uT6NuWBfsl2fDUoV4l65qMww06D7n+p7RbdwWkAZ0fA63mXVXBZF6kpDtsYD7SUB9jhhfL \
QE/r85bvg3FaSs5Wi2BaqN06SzGWI1DHu7axthIOeHwg00zxlhTpoYCH0ldoQz+S65zWYi/fRJiyLSBb6JZOvn
 net.       	16372	IN	DNSKEY	256 3 8 \
AQPlC0AS+lRQ2S97U6GcXyItQZSEC9CJ1XIPOah6RkU8CtoSwvapf/M6T/qZvJhcqnLAwujEiIOMWTwwSQ8XDU \
Dn8fiw4upqe5wg/favLI2Uc3ElQcD7qoqufLnmspGP5urK9JTqGkW9PFfMd/iPCfLLnpjiZEv7qBYhR0QxjYRyyNIZ/wpGjdNs1rKmiZxHqp4hT6oEVlL2rLbjpzeZwRRf
 net.       	16372	IN	RRSIG	DNSKEY 8 1 86400 1589473410 1590769710 35886 net. \
Q64lprln18kf1DuOagLzYo90C1RZhOm6fq63tC/M89NeOAjeoDeebMYw2lCbRhIlKn564oPqX9DnbXXqsMzzvf \
nmyxnGcba1i2bRcfrqo30lYpzjfCo/LWjmSqNa3IM5wKydACyNqNXGbsjFkl7GHn8AOeUPSSB3+Pjl9HbXtRL9 \
Gg3prYft1jL+JkCSAOWND5iSnP8/ZwpnxEqE0rvnEooGFtaSg8HbBYHNksHkdAFes+LKfLNOyEVQLaWYORnARY \
bT0qrLD1y7awgzjlEbjOfOanWFRkn2lM+OTmFehdXEVhMznphp76waPo9tJmTGLgtoifd7MlCX5AsrS5Z7bA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   12 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
mozaws.net. 	IN	DS

AUTHORITY SECTION:
A1RT98BS5QGC9NFI51S9HCI47ULJG6JH.net. 	21574	IN	NSEC3	1 1 0  \
A1RUUFFJKCT2Q54P78F8EJGJ8JBK7I8B NS SOA RRSIG DNSKEY NSEC3PARAM \
A1RT98BS5QGC9NFI51S9HCI47ULJG6JH.net. 	21574	IN	RRSIG	NSEC3 8 2 86400 1590126447 \
1590735447 36059 net. \
pL1LEmGqiiGjGFVgwF06OLjRpF0l11m0BWonFoeJbs6RN1HHUpoO3JIGUk30OOA6LSUd1xRjhAgkbXBriAjWza \
Ye59fsAFXDyxHBRh85kCAkfITBZBz2rRRCLf3ACaJlRjE9+5aj4pN+KpCY1aLfrEQLh+jToOVVfk+jNsMQunr71vz9D0mpnoYLF+Ae9Hqc6nXyXYxk787QcRRGKkh55A==
 net.       	874	IN	SOA	a.gtld-servers.net. nstld.verisign-grs.com. 1590327527 1800 \
900 604800 86400 net.       	874	IN	RRSIG	SOA 8 1 900 1590323327 1590932327 36059 \
net. yo/ESrPjx6pNTbZhiJmECG03tO4PhitI2ZYlExE0pniZZiZN4/tHPGTD0rtLu+onjVumUSZzEKOc+NSFC \
LDSZaktk1mlzIcrn5t9xQp/p2+nZpgNr6dorzaysE/IIAsHr6zmGLffM0hJBT7ZfSdREFpv7UPSeCy3q6dhxvMjO8VA4QC5BfV1wS5UwetWnrG+qXn3hBMEmuzSGHkrzFHGZQ==
 1851PEECE9C1RIG309ODPB7H9ER81N6M.net. 	21574	IN	NSEC3	1 1 0  \
1857F0TG4DQQRG4EK3C9TRH2HJK20FUE NS DS RRSIG 1851PEECE9C1RIG309ODPB7H9ER81N6M.net. \
21574	IN	RRSIG	NSEC3 8 2 86400 1590212056 1590821056 36059 net. \
E9AeXUsehBI1rtQwCAyA0EPq96wM37T5CiU5E7pIC7Om6rxeYvN6grKwHfoHGSMAlJy5OTFXdKvrmta/Zac+zj \
tU807F/0BuvETTPtT/3xwDmHEBarEdQWwx4/nO7/miyK7Ygki2rBbBaz8xvIAQZvlfhFpVYxuEEVBl7QpgZIYLMJ4jSIqTNvCQxuI0w8FBswcQUOHnjMvolsnrwSEVFA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


aus5.mozilla.org. has: 8968 bytes


["cdnjs.cloudflare.com.txt" (cdnjs.cloudflare.com.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
cdnjs.cloudflare.com. 	IN	A

ANSWER SECTION:
cdnjs.cloudflare.com. 	160	IN	RRSIG	A 13 3 300 1590238350 1590418350 34505 \
cloudflare.com. 5UA+kQi26bzB35ZpRkSEO7ilcL7DqvJ7jEpqfu4hnvNx5guq6Em1iSrlJkOTnE24w12IBe03uM3ti6QmW4+N1w==
 cdnjs.cloudflare.com. 	160	IN	A	104.16.133.229
cdnjs.cloudflare.com. 	160	IN	A	104.16.132.229

ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	8082	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	8082	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	8082	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	73352	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
73352	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
uqEjk6O3Ar61SqlGxHZlx6T0AlSP/jGwXDX9Q8gaiyeKaDcf7U7OZH5e2eIMztZw4b/ctH3nbZBvvpeVV9bow8 \
4ubmHeXjO8KbiiSgbc1+Xrz4sbpZaYzs7NpG9A852kU2f8J5JKwfe3wmZ7MfbInjMKlKRmn74HPZTO12FZqZVI \
rxXX6og4FG8FnO9eSiIf7m1gtutTqrQPD1azXz96VEY+v+kl/AVyhQ+tkP1B4rplqDq2gf1qizgggJz0m3pVzd \
tB41uNdwK25j+BzhiVt+tRGau1s0e+x2au26MhG0WeseuKn9Mt2CWyxE9/mCgWjFEQmadPWz5/EyzBWhhlcw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	808	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	808	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	808	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
cloudflare.com. 	IN	DS

ANSWER SECTION:
cloudflare.com. 	76787	IN	DS	2371 13 2 \
32996839A6D808AFE3EB4A795A0E6A7A39A76FC52FF228B22B76F6D63826F2B9 cloudflare.com. \
76787	IN	RRSIG	DS 8 2 86400 1590030822 1590639822 39844 com. \
B+R/hZxaeFFebs72M0CkdBJfIwyhLzM+VgH2nLyMLy7xXVBzlC/ZQOpAQF+GcHgKXxp224SfDyY/Z8cPPZtGAF \
OE9G+1IiVNy9eQV+qpANcf4zaPAOgMDU0HGFTAD2YWPmuodo7VINVTrszhguJANSK7AD7oGCBWKS/CZQvwzn5c2Us/rHC+dte364ejoVoBUPrTv9tMAEHQ4LprMd+fNg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
cloudflare.com. 	IN	DNSKEY

ANSWER SECTION:
cloudflare.com. 	2960	IN	DNSKEY	256 3 13 \
oJMRESz5E4gYzS/q6XDrvU1qMPYIjCWzJaOau8XNEZeqCYKD5ar0IRd8KqXXFJkqmVfRvMGPmM1x8fGAa2XhSA==
 cloudflare.com. 	2960	IN	DNSKEY	257 3 13 \
mdsswUyr3DPW132mOi8V9xESWE8jTo0dxCjjnopKl+GqJxpVXckHAeF+KkxLbxILfDLUT0rAK9iUzy1L53eKGQ==
 cloudflare.com. 	2960	IN	RRSIG	DNSKEY 13 2 3600 1587712462 1592896462 2371 \
cloudflare.com. M4Gm5gntEncnqRht2ALaUd8tu/NHqIWTCIlu/anbncHYYE3qJx00sVTFdkuxpaRRQRRI7HXd/dJjxZi/2FWLJg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


cdnjs.cloudflare.com. has: 2955 bytes


["duckduckgo.com.txt" (duckduckgo.com.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56761
flags: qr rd ra cd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
duckduckgo.com. 	IN	A

ANSWER SECTION:
duckduckgo.com. 	185	IN	A	184.72.104.138

ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56761
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	37986	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	37986	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	37986	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56761
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	36010	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
36010	IN	RRSIG	DS 8 1 86400 1590206400 1591333200 48903 . \
sM9w5bxXzXYLvjkjjlBQ6D6KE1R69DPjnP4gnfywkB9IXJpy0DVx4qDZr0ac1MQzvLal3RXSar+QFDJT9jx3Qo \
078zH18n+jozkfvptgpCd5mcxD4zRD+7U7AnbdxUHJJl1rx84mRJ8D71yWSl2FbK7szksZafM918ztLZwiyRd3 \
BKG6jLPVbAoKbPVfFxp4KPM1COL/v3gHr+MTqk0JTR1KalSn+SEi7198gwnpSKtqRDj/s8clL9w1mRgaYIL3H3 \
znCk5+RJTx/lJADfqA0QUt4bCufXAf4dxelNtgFy+g8+MWanFJSdGjk3W+NLv54h6D6oDy2xvjbf3mnNp5mw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56761
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	18365	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	18365	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	18365	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56761
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
duckduckgo.com. 	IN	DS

AUTHORITY SECTION:
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	21139	IN	NSEC3	1 1 0  \
CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM \
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	21139	IN	RRSIG	NSEC3 8 2 86400 1590118683 \
1590727683 39844 com. \
NArL30b9Vy8GobUMocYC399NaMB4oqLbana/HTaTIz4lKkLRtFM6iuBewn3CXtCuBCZ3VfV6q0K4jvi2+su+bt \
kuGZo+Ds+9ktZo2snOzdiuqFOdalMkzpNbVUyEuiJDsFRYPpueKaWNLPv1ceo+/C20hzxUUJ0UDBCLo/RX85dLAiVl1OA8O2FPidsDyXnoCxT1vJaySfDnNkLUCqDohA==
 com.       	439	IN	SOA	a.gtld-servers.net. nstld.verisign-grs.com. 1590314297 1800 \
900 604800 86400 com.       	439	IN	RRSIG	SOA 8 1 900 1590310097 1590919097 39844 \
com. CvDVJLaC9rWBEpzw1ZFCswGg8IYfSIRrImkCahS2jTfrkSPxavdLgnLEy5d3TBR3wkM3dE89ODBe/Tszp \
bO9OFxIZC9mUqcf7B6uL0aaDIVFtffru7fzS53ueyhZy8IuZyhYS5q7khd9kqoreAfPgrkzSYA1JZSpoJ/PgnI50uWuptErgvjpva5XWNn8h/9DqFtcB94jWFODrPEe813+kQ==
 BN1FJS0UO0RMBT477B345GNU6A9CFODA.com. 	21139	IN	NSEC3	1 1 0  \
BN1G255EFBBQHJ10333PK7TVU3NBC6RJ NS DS RRSIG BN1FJS0UO0RMBT477B345GNU6A9CFODA.com. \
21139	IN	RRSIG	NSEC3 8 2 86400 1590209780 1590818780 39844 com. \
n8XCvGqwx7Nnm+Fmrtpq4eUlIOj+BZPcNvfRN7M48Xyclts9N5gggjGOhxNQtgwE0/0YN/wfxRwgsoRfBvI1UH \
4UNI8pXEZWxHORnVHgPSJ5+St3bgbce0iHmsnnMCMeVjdoBs+GTqePDVdahlkSUONeXZdxZjsURHjCBkFgyyIL+DU8b+O7XPdcuLrW/8F0OEFI4FBLUHRm5W5cLx0FHA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


duckduckgo.com. has: 3053 bytes


["enabled.dnssec.hkirc.hk.txt" (enabled.dnssec.hkirc.hk.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
enabled.dnssec.hkirc.hk. 	IN	A

ANSWER SECTION:
enabled.dnssec.hkirc.hk. 	3600	IN	A	203.119.87.71
enabled.dnssec.hkirc.hk. 	3600	IN	A	203.119.2.71
enabled.dnssec.hkirc.hk. 	3600	IN	RRSIG	A 8 4 3600 1590256851 1592852451 2790 \
enabled.dnssec.hkirc.hk. \
CYa73R/g6y5cah4kntbtZDJtDQvCQWfTHydZWR1TZpLcUgBhCPAxPkpLFzgisuOgqMLerqvhvT/eD3ONHG8zp9 \
5Ph6Dh81Q02+gGkTwSUfUnsmruJhyC7wEJleCUGa3ICXru6sT/VUfCIeqxAOxlVcqpBDQOUU7QqAhuk3YAifk=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	7514	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	7514	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	7514	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
hk.        	IN	DS

ANSWER SECTION:
hk.        	86396	IN	DS	36746 8 1 3F84E13235BA03D337B1D95D1F2A9549DBD91636
hk.        	86396	IN	DS	36746 8 2 \
2AA25EDBEA1519DE7E1E264165BBC72627868F1A2B19DC7DE5417ADD9B56E02E hk.        \
86396	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
p4rO+BCAgBsHXO6KyMD+tqyjsNVSRA2E4lxtroB/qhAOICED/1NhqVdjhLOFdA3foYCjviXgJWWqwz16NlVMNz \
/o00Wx0QauyMIgrhhWNo2ScGgGBCZEHatYfSz0CU9OmKb66xniD2CzKzXBPzDtUfa+zIlKQcV41Ti9dKrtXzIP \
4GKBvshK6z+HGWNnnrIMB864+K1eQcuH5cDORF6iN2rCHEM/24UC4GT2q4EFVQVyORUFnrCZT1mbmXZ3t/E5av \
7CVP86yUXjJIFItNCZJ1qRUK49aGj1pW+9ifEJKhZIEZgTgd2gYYvw1Jk0N3QG2Rv5daeNHmzLKguO5Ht2UA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
hk.        	IN	DNSKEY

ANSWER SECTION:
hk.        	86397	IN	DNSKEY	256 3 8 \
AwEAAaduHfdJYOO8OEnNvV3U2udBnsUKFWYrczyLtJIZ8tQeP6LXkavUA5rjT3V+r9HN0pgavJ8FTBCnZb9Dvf \
z7xthysYZ1MCBCKnEXcKVAhQ0+tLtU1MvIZeWvt9px2myINBcyTI5nEFahtzIYIGuO4dMis6S/f9rEZkQA5LWNxrwH
 hk.        	86397	IN	DNSKEY	256 3 8 \
AwEAAfXHvUmhEVhBUP5UOmW0zXPsnJq/eVnhw2v1ioAOqTRzWpQQW2KqiLSBtqZMIGslQMIksFTiYlGvo5oDJo \
ZFds42I8M+rRd5e/ondMAbTewzLz+VvFuabmPvosyP3jaY8QNgHNzktVdJ2rRLVk7EaDp1sNyEdG3ZYdFiWEZEk2sv
 hk.        	86397	IN	DNSKEY	257 3 8 \
AwEAAbbMFi3Z7lDrMN7sefXgvAvAjPP0rmWzL1Q1ca3ZCdMVZHz0QKUN6act55yr20t8F9Qzf0jgbmx5ScO3Fi \
spivujdyutUXJzyym7rbwMQOZsHoEQeAEOjN5+OYPS1YbZ5RRshGkXHkbTV+aBAfv0J1KLmyM+J1sdSomB2FFx \
hYrPrY4Z4WhbdCgAwdxNP2YF4uQvIhV0+f5mMi5MQK90pCfm10JJum7Q1mMNUrTimbhiyAcjcn2GMcNZjv3co+ \
1zM8NVYSZ37mpKN1lLdYv2mDNiXIGpbgcea+L/5ngZLNIhAnw580RyW0JKtU5KlsuJFkkzP5hshHvnhZRnTWG6fsc=
 hk.        	86397	IN	DNSKEY	257 3 8 \
AwEAAaB0ebOjKppb+vcU4196Mr2vtFQNHZydF6Y8csbwceMDnoV7v6wTqO8ofpFms2cyoYRD8Z31GdJCI1m41U \
6kQb6bKwyyyMa+BOKGPi1ef8x6l209esJFpbEcAIOWM5XVNDeEpu+x9KkFEz2tIY2vyajEfZwFUWh6/3wlE2JU \
ck5DO97LiDGWAjnQKZVD0VaGhw4yCaZy1BYV+beaYBhmd+HDYOaKtFzp1fDnDtorI8pJEdSuHrMGShFtdQXyi2 \
gw+flKFfEdy+8RSv/TMT0c9TFL69+15eShukEbqvzz68Gyt5I9dUwTdZcKBTIBJqigIb4Putc7tkbeDvX4ZvACyvs=
 hk.        	86397	IN	RRSIG	DNSKEY 8 1 86400 1590264871 1592860471 36746 hk. \
Y6K+7+mP6I49TQCEVztGaDuhEg5txjZAeORb7FiqXQP1XL05rETwCv6+LqihUIGcvQO38DfNJTAv9HG6Q2jDcq \
mtN+8AgSrvuGDBfiWds0ytSgccXsyzjlNcnPqqgCcMcKR0CAcXB8yJQYCwDEPEAZqCQw2WDuU+Jx68WL/y0/RH \
nGc2Krkvr+uPUX2xyocHP/HZX5QG3vqTEJ0C7fRmHdQywLdUkclna1j+NsJjRPqffcX1ZEHdk7Z59zKX+aQK4H \
sqwN3N7PDxKcqVMQDcrWCi5+YQ9bqzvTdYFYlNCk2bKJYsZSJz4ioLwWheZkRkoWXs5BnkFzi2wQHGOuFxOg


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
hkirc.hk.  	IN	DS

ANSWER SECTION:
hkirc.hk.  	28796	IN	DS	36209 8 1 9BE96C02158B3FB40A896A48E4BE6447F6104B49
hkirc.hk.  	28796	IN	DS	36209 8 2 \
8F1F2CC25DF23AB6575B824BDC6811410A8BFDCFA35ED590688119514FFE71C6 hkirc.hk.  \
28796	IN	RRSIG	DS 8 2 28800 1590264871 1592860471 21360 hk. \
I3+xjxvR4zkBquLMwpf+gtW0VbjdiGg5lqe662z+mP/8LVtEbHU4CtJ9JQk3MiLkg+qiDXEr/n8ffulaAdCQ+Q \
3yBj+r2EvcqjUzdp9nY05n2QiGsNkVm+zbEljvnZ7Yv93JJZNzdyWUb++uvKRdHM895jZp9ClGiOtJswb1l1Y=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
hkirc.hk.  	IN	DNSKEY

ANSWER SECTION:
hkirc.hk.  	86396	IN	DNSKEY	257 3 8 \
AwEAAYgqoNVg6Mfhxn+C2SUn3GBEJOKPhC4M+5vrjCQ4wWG2MRN5yEUM/g1Q473zF3VrEx60O3ichbsQaCrCyo \
Lc8FOuRqqCbLb4qs1rvFM4CLG/VPCHps2LRtFwdp6SMLuM9WvK+Lk9qZ+JZ3sCSN6UYqL09AfRWUQs16gDW2hy \
g3vGg8ROTGWjsO5Qr3IIbWWWll1GNtSqEnX3MzI2pQvPPj7nN9ltFQo5UzbP+FEbbbUUp5zdYANndk/udDba8u \
pFiLvaTmgytFxtTZBv6c77P40br42LyfUrg8AcfzI4EY9t0VxWpCUV4OEow/84ao4NOk1EVHvkI+ZgEUmWskgJh7s=
 hkirc.hk.  	86396	IN	DNSKEY	256 3 8 \
AwEAAbVsWFd5drQUPd91dl0COX2KxXo2IRRjW9+HBN3CcLb1Ua1yLuRycOM+zehnOA1qQVCmP58QOu1QuyI5kz \
JH/4TOvIWbx45L1pfgl2YuUJZzOmj9X0lOeKICYRy90kV38Rsmov7pElOwXQwNFlC4vWK7s1MbtpvemDiSJCtknF2l
 hkirc.hk.  	86396	IN	DNSKEY	257 3 8 \
AwEAAa1MnHimBavCH281M52iAMr3RWKd2InUmw/7Y1XEyHN1f7tyqN/K8a+juk8IBjDVQATe8BMKh3OK+pw/8o \
kwkU0kNCKWTC3G6nHGa8fv+R9QRjlzJAyj68QMpuK38fPHX8k/YJppCHIIQRACM+ABNd5pCFUGMVPmDiKRaUe+ \
c3VPcFPXfv8RRZOqmE5ro4AY18AGzHUuMRGSSmLKZMuKUEcRpeD3geOMDS1fFbYZQ/0VdKNe7ae+d4/UZxu/ja \
HEu6Foy1QUPOymvL45ztVuIuMEdHvtD6OIAsjh3TPNv9NCsM5hYhdCdZgyUj1G07/Yq+kRMjMsVEJE9jEb40OiMnM=
 hkirc.hk.  	86396	IN	DNSKEY	256 3 8 \
AwEAAdEaiV+jCAU08qjER7ejvu/6rUK/fq3yIku/JRJ8dXhmQBgYDL7ImUv9ljK9e7gylGP0WadZnQVYz6mzDo \
F6I+ZbrPpNQomzUmgDOgZTPufDEeNDnQHJl/JHGQEmQhXgc/HXTVBU2xEEUOQuZuumPWZiHoJDmP/8zzMMjXdViae1
 hkirc.hk.  	86396	IN	RRSIG	DNSKEY 8 2 86400 1590256851 1592852451 36209 hkirc.hk. \
YNteQ0K23WZbdRNGZ9FGDK/WIZAp4+W+0tbERgXtjStu+86Sv2jo2KSClfN/EK8lbWELwpb0a4PR2e/r2hR873 \
jblBtMarWJIKInnyRUPs9fYIRDItXDrUqL4s8cWX1CLFWsLl36rfwtjUTYKZoEQRhoZWyJ0XV0oSMAM2WN0xcl \
e1ky/tufFHj5Cvw+CropAyq/Tsq9Qm/6nCxx5++pGEnMKrl6uXnIfXKSz01s4gSxp5bJcjnGOeJ9qpT3wWGM8VeewLQql07z0eKpdvdfGtbSB9DePXN5Det5uH/xGRZEMt/DRwkZpnKp5oXrPvO3zdfkDj2AJiPMgZaa



==    7 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec.hkirc.hk. 	IN	DS

ANSWER SECTION:
dnssec.hkirc.hk. 	3596	IN	DS	47995 8 2 \
485B16FD37F4F3D3EEBC75FCD0A69E84F3291B9CB0C40F96394ED946A10A3147 dnssec.hkirc.hk. \
3596	IN	RRSIG	DS 8 3 3600 1590256851 1592852451 65388 hkirc.hk. \
JXvIr6o2ep6RCYfK9lJNSZGaQDTM6wJd8VDKPkrU5rKV04mz9SZ2o2aHIpkc6DgGDeK+61A57zvWs/Z/2c3SuJ \
yXvaVAOJQaY6c6lLmaJPtYEiSWUzEku/+eIreviHctDOd6S3zKxmtKpZjJG3/u4nqbSRem7AAE2OkCT0FamhI=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    8 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec.hkirc.hk. 	IN	DNSKEY

ANSWER SECTION:
dnssec.hkirc.hk. 	86396	IN	DNSKEY	257 3 8 \
AwEAAcA81YRxlUqMw9QypL4E9v0d2nqoSOM7Mi2iKIQuqfdy5aj4of5knWGpPoEMmL2h1uIeuSjBwiI9DjQZzf \
5I7KQigukisD8ERlZQ4umsb/2j18q9FF8zvEEtBFWoe0L3V/s8U5Q2djDdhEFmEguSB9a81P6+Wk8mvsGm2pMS \
nBy6LBejcTf6Pcu0JyYn4H7lXHKFGr/CZ48O4E3wl13bPGm/ZScVYU2uO2ZFScNRCbAsfBsLJj9B9wsokKo7Zf \
2BtKNBPUz9MEQcbkCD8XjAsGgQFrKEHe+xN78mgwn3tGkvouBBHifZmehzAheA+T5tqZ+K/S0mTbUcpYdVbOfpXKU=
 dnssec.hkirc.hk. 	86396	IN	DNSKEY	256 3 8 \
AwEAAb4iUxNdR/UWLf214gxkI+2ePJJowMg8u8ouq9H2fgtaQO1fXhFdi3m22XmW7yqxvLtZPTtzgfH7M8QHyw \
EPJzAlnlt9UPR+qii1DSvu6TUUiLMJ4BaPjLfNBYPHld3i6RZf8yyYyWlVAvf3jnG7A0Rs/kEemXjx9WGNCuIB1nQz
 dnssec.hkirc.hk. 	86396	IN	DNSKEY	257 3 8 \
AwEAAX/uKicISwQkfbVAJbYmUl8ajydANNG9Yfgu3/axMNE/fTz4tQYPyu8LGFuHzJ4DXNYRNZxGjCV2VaYwif \
DWm+Hq18l3eJFzFH51zxWyUwKKsUfvg1bipKRsOMp1j9GAjxrwKK9nA0egD5qvBNO3+PjyfGklviDg28Bn5oKY \
o6qO9DC5jnLb49HRnrIkvOS3vUwyaC0X6gWPB/1Y/UnDaIIqRXmzQJrKfVnwoIJVuEzebGzUuu5YZFvUbwO0q6 \
zsebqI7puLhFgFZRgb3QhneGpmlbjqQ+HlFQbH9a1u+8DRoc2JJSAaKEL119TqXu0xHTG5Oyc5aBEtoot/n6vpL70=
 dnssec.hkirc.hk. 	86396	IN	DNSKEY	256 3 8 \
AwEAAesS2YK/mGoeuuZ1F9BQ35H7AmBwa3+cyYRuAhbRSKAbaij4aO1kFb/5hqeyAtIRU3IlCyu7y4L5oVDmiJ \
6mfxxTIq/JX613MN21JiTwvsI5AUrmRoVl7ANHnVmldKvtKxJLRWDfDv+3FROkt0YouxKdFIAU/BSOZbnjxEILiwSJ
 dnssec.hkirc.hk. 	86396	IN	RRSIG	DNSKEY 8 3 86400 1590256851 1592852451 47995 \
dnssec.hkirc.hk. L99xgEyweIegaOkyV3APWeBaYkcPz9L+ObDfKVbxL6NxcCIR8XTHwVcxviDV/qVHZ3mKZ \
KtRKgjFDOcI1Z+Z2wCVluTVt02qwa0uWl17INDlNAAMuoIzzRDLQg2gx/NTQ2PqWLKlIzdMMrsab7MkaFmTXx7 \
VqPKCGXgIpCu7Bu8TN5NPnO0eeG2J49uISwaEzCXDrUDeKF6/LOLkNAAtHecu5BP6WLmIqH4/D17ShuLffN9ANfeNipaJ3KypOc3lniATY/sKy/Mv35EYqRqW0oZWS0s4bpbMEXtrl



==    9 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
enabled.dnssec.hkirc.hk. 	IN	DS

ANSWER SECTION:
enabled.dnssec.hkirc.hk. 	3596	IN	DS	27725 8 2 \
D2F213FEA0FC1740A1AAF2AF8A93422B00B22ED51A43BF76575D52113278566E \
enabled.dnssec.hkirc.hk. 	3596	IN	RRSIG	DS 8 4 3600 1590256851 1592852451 13929 \
dnssec.hkirc.hk. PsdxxvAlstsf516YhGA4901GzOj3jxaf+VcMxi6Vpcnr+2T14icv546cnT5deMMzM2+Az \
AIV2vYKzFh0Fh+3Wz1RSHn3FQU04lzI4qo9+8IDo7r4A7zJO4xzNgufPDXGv7dc4u3IO1yCrkfr/CiK2jrCk+twIMkT0VzLmPkoaVc=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   10 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64032
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
enabled.dnssec.hkirc.hk. 	IN	DNSKEY

ANSWER SECTION:
enabled.dnssec.hkirc.hk. 	86396	IN	DNSKEY	256 3 8 \
AwEAAb7S4D7f2VNCFYxUqrhkryrcxN0t7DDzdTrZCVzTP1yUeGAZZ+xQt0ZUwFl1ipcQZF3SGfEs4QDAICqn14 \
xB3/p6TgFuQHeU43sXFs5Ix7YIrq+NylRRF/mYDtz4CK8Yqz02xLO0++wcE9qzQnAG32T89giYAZ4fs4IH9e1b4STd
 enabled.dnssec.hkirc.hk. 	86396	IN	DNSKEY	257 3 8 \
AwEAAbW2C3XzOjVfz87K73Wm1S6GnueHdVgH5nD/ghpH44m/Rg9H5oQzomfR+mLZWK+KAxqJPU9Xef+NdI0E0y \
oPl37VUBlSlzcsryrPewC9HAmgoOYH3fFLpYRCPJO/kSXuuaNe+l18Qw8+gJN77C7G5ILVDUEBjuJ74/WYILsS \
ieoy+fTidAps1msSdVExUpTl3+UQO9Xu1r/K5L6kGDFA/4cTDA0G8I1/HgeH5n4e/NJ7uqd8DgK9BnKLzxkfJh \
DklCCrfeuWzwcJJcyBHebRGErzeVB3QTZQkHWSK9GJR9Y42+MTDfYfDM6fGhm6G20HlRdhhlUfFJjPDAqz3G5Wwpc=
 enabled.dnssec.hkirc.hk. 	86396	IN	DNSKEY	256 3 8 \
AwEAAcEs5IjFc4fFzKw+Yr9k+TEbNN2VJYVBtD03GUITDF/YiK+d6eHZgDnfGbkQNs6PseZw7lI08XnuTwmOBl \
+51R3wPMWjKgEp57W1jRcWLuhL0kntkn4+fIsi5J21hGxl5ITATwLCfLxP3ehKGMzWGDDdsj62+PHXDUm3hGZCiXqz
 enabled.dnssec.hkirc.hk. 	86396	IN	DNSKEY	257 3 8 \
AwEAAbabw+RMcNLdsRM+Ps9A67VIth/eeKlBJfV6t9m8mUt0aVsk6yDbuL0e+O+btPr+96VxXuGQH5/i4ypne1 \
rUMGgiFahmVuYjHQLMZV8XU+w0NIa82B7pv0jKmgMaShrQFYgka1RJZSiHJneFR498E4Z0Xr3yfb2v3wtqgtC7 \
uD8/XXH2dX+RN0ggBiOgxcxLQHJ5gFCsFUNY4uVGtC5Ndq3LJ7ckICCMD8OEdrXFJMy6Ni3OkzezuMFd/JTjZK \
e2fcVV7Jmkhrerm58dwTS8ApbF7ju/Zf3g8Z6HYrJEAyB0t/tydCgdpZLgtLpr7yMyW/QnrkwCHKqZIQVPE16RxIE=
 enabled.dnssec.hkirc.hk. 	86396	IN	RRSIG	DNSKEY 8 4 86400 1590256851 1592852451 \
27725 enabled.dnssec.hkirc.hk. \
MDNCFpMcoeKmDfd1T3hccKIJtgEU69RobHRX3uiaUU0vSjYAYJD+h1x4+jf1XSpc5gyMhVpgXvKMFrUW0pzv5Q \
V2XHvgXxFmzaoNrW+Ene3SEYeYxyukf00yySRlctNOoJbnL1IUCjtSDEkbbzJdHelDwrt0LE4zHOyTmne22n7+PzWQMpBXEJYsUyyzBlePJhrlyor624JoOIVb11WiXTxYwrr9EL6AJpU93EA45Mlaz



enabled.dnssec.hkirc.hk. has: 7542 bytes


["example.com.txt" (example.com.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
example.com. 	IN	A

ANSWER SECTION:
example.com. 	21021	IN	A	93.184.216.34
example.com. 	21021	IN	RRSIG	A 8 2 86400 1589301185 1591125158 21738 example.com. \
yKNWyFOxkCla6EzUCpF/9iOQK2FE/YpsnO3qNW4eL+5+VLCUjlyRWniuT2Nx7/1pKTdJxjIeIBdiKl33A66+gH \
sRs/1V+N+GUBy12l+oh9zncSRzTy2V++6eU8hoHlEhKhPfKF55PfTAFuIeYM89x38e/jGYsDHWtz+wRzPxcEA=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	85752	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	85752	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	85752	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	85388	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
85388	IN	RRSIG	DS 8 1 86400 1590206400 1591333200 48903 . \
sM9w5bxXzXYLvjkjjlBQ6D6KE1R69DPjnP4gnfywkB9IXJpy0DVx4qDZr0ac1MQzvLal3RXSar+QFDJT9jx3Qo \
078zH18n+jozkfvptgpCd5mcxD4zRD+7U7AnbdxUHJJl1rx84mRJ8D71yWSl2FbK7szksZafM918ztLZwiyRd3 \
BKG6jLPVbAoKbPVfFxp4KPM1COL/v3gHr+MTqk0JTR1KalSn+SEi7198gwnpSKtqRDj/s8clL9w1mRgaYIL3H3 \
znCk5+RJTx/lJADfqA0QUt4bCufXAf4dxelNtgFy+g8+MWanFJSdGjk3W+NLv54h6D6oDy2xvjbf3mnNp5mw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	17849	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	17849	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	17849	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra cd; QUERY: 1, ANSWER: 7, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
example.com. 	IN	DS

ANSWER SECTION:
example.com. 	21599	IN	DS	31589 8 1 3490A6806D47F17A34C29E2CE80E8A999FFBE4BE
example.com. 	21599	IN	DS	31589 8 2 \
CDE0D742D6998AA554A92D890F8184C698CFAC8A26FA59875A990C03E576343C example.com. \
21599	IN	DS	43547 8 1 B6225AB2CC613E0DCA7962BDC2342EA4F1B56083 example.com. \
21599	IN	DS	43547 8 2 \
615A64233543F66F44D68933625B17497C89A70E858ED76A2145997EDF96A918 example.com. \
21599	IN	DS	31406 8 1 189968811E6EBA862DD6C209F75623D8D9ED9142 example.com. \
21599	IN	DS	31406 8 2 \
F78CF3344F72137235098ECBBD08947C2C9001C7F6A085A17F518B5D8F6B916D example.com. \
21599	IN	RRSIG	DS 8 2 86400 1590030776 1590639776 39844 com. \
BIW7xFG5fa2AZ4aTDnGoJnmpWS6w9niunTfvOXoeyEAqREeWtqZdbMijgsHtfOh7uc32N/XPV0Lc5IvYsRr+Bc \
0Ru1X9PZRpDyN7iU//LKUs/q5WL56LTNFhPmuGauu0E7ou+pO6WGgw3v35QunPzUubVbLG0LYzuPFsNNpEk6uJpb/flT2/ODVk0hqhZFp5SPELtCY0TwRD2RqBSbanZQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32945
flags: qr rd ra cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
example.com. 	IN	DNSKEY

ANSWER SECTION:
example.com. 	3412	IN	DNSKEY	256 3 8 \
AwEAAdTxhSwz3/lGdlPuQdw+WzsBPmt99VBxvkpfbST65UlCgWOW+5fnGbxfFSrscnQixl6ApgVBYE1Z9KuBRf \
5y9OD69arf3EYLoE3tYvFreCbcl7sFfWhhZUkBLE028i4pzFhdStQO+yY8xzE3zg1NE86wQUT0LChhMudSpXAmf6DJ
 example.com. 	3412	IN	DNSKEY	257 3 8 \
AwEAAZ0aqu1rJ6orJynrRfNpPmayJZoAx9Ic2/Rl9VQWLMHyjxxem3VUSoNUIFXERQbj0A9Ogp0zDM9YIccKLR \
d6LmWiDCt7UJQxVdD+heb5Ec4qlqGmyX9MDabkvX2NvMwsUecbYBq8oXeTT9LRmCUt9KUt/WOi6DKECxoG/bWT \
ykrXyBR8elD+SQY43OAVjlWrVltHxgp4/rhBCvRbmdflunaPIgu27eE2U4myDSLT8a4A0rB5uHG4PkOa9dIRs9 \
y00M2mWf4lyPee7vi5few2dbayHXmieGcaAHrx76NGAABeY393xjlmDNcUkF1gpNWUla4fWZbbaYQzA93mLdrng+M=
 example.com. 	3412	IN	DNSKEY	257 3 8 \
AwEAAbOFAxl+Lkt0UMglZizKEC1AxUu8zlj65KYatR5wBWMrh18TYzK/ig6Y1t5YTWCO68bynorpNu9fqNFALX \
7bVl9/gybA0v0EhF+dgXmoUfRX7ksMGgBvtfa2/Y9a3klXNLqkTszIQ4PEMVCjtryl19Be9/PkFeC9ITjgMRQs \
QhmB39eyMYnal+f3bUxKk4fq7cuEU0dbRpue4H/N6jPucXWOwiMAkTJhghqgy+o9FfIp+tR/emKao94/wpVXDc \
Pf5B18j7xz2SvTTxiuqCzCMtsxnikZHcoh1j4g+Y1B8zIMIvrEM+pZGhh/Yuf4RwCBgaYCi9hpiMWVvS4WBzx0/lU=
 example.com. 	3412	IN	RRSIG	DNSKEY 8 2 3600 1589200385 1591057258 31406 example.com. \
e/68/Lr3OM4Jz0EOn4fvRVp1fqc+PEYWni0ihk38LHHgUG9ifxC8c487EBeo1V/phcEC5/oPZ2BByux6iCQHKS \
+Y5jaQEdPaV4fq6GVX7bQAgSjbQLKdv3DvMiY1P2xBweqZUvmp4GcskrmgQk2VZcD2VLT+lPyCPwHJ8UCTlrqu \
8KwBc2opjuBaECgRkaTOZ3AIRxVLHPZjShycpyHk/ovI3BRD0POLirK0jrTdOA0ZjZw85WNqdx4R/171ivEpHz \
X0uRR8SFomSEWhbw6cWlo3lwlnwOe9l+lnfll6t6jIatHeBPtFbeKMfiZTxUzaNO6MXO7mMvC6x4UUPPmirg==
 example.com. 	3412	IN	RRSIG	DNSKEY 8 2 3600 1589200385 1591057258 45620 example.com. \
NW1hAzKjVTacM63zce/tKcOTdfEJR2e3DxlJLNN4MPUkrsKkqrGc+d7t5DZYurG6JoeqtsElBdaUbOVrVJCkl0QF8wLqTXJiBUDhGIQtu469f7u3By



example.com. has: 4241 bytes


["matt.traudt.xyz.txt" (matt.traudt.xyz.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
matt.traudt.xyz. 	IN	A

ANSWER SECTION:
matt.traudt.xyz. 	1799	IN	CNAME	home.system33.pw.
home.system33.pw. 	1799	IN	CNAME	p0f389034.probes.atlas.ripe.net.
p0f389034.probes.atlas.ripe.net. 	900	IN	A	100.36.56.172
p0f389034.probes.atlas.ripe.net. 	900	IN	RRSIG	A 8 5 900 1590078047 1591293047 45309 \
probes.atlas.ripe.net. \
ZyKI8Myhg5NmQsNFMCi3PRZgIq5dvtPsBBipTDCdZRyFowCbfINgd3/oWegKy2AjrY4aMn9LRYW6renvIHEEEX \
5hPqQAcV18xIuRkH2Ik3CNL46Hz6guDwrjnts4nH1k5N5uALdar23VpgYYVaDiZqF36ggY+RLT7BOu3KUVxoE=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	5274	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	5274	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	5274	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
net.       	IN	DS

ANSWER SECTION:
net.       	74448	IN	DS	35886 8 2 \
7862B27F5F516EBE19680444D4CE5E762981931842C465F00236401D8BD973EE net.       \
74448	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
q48AgBhW2g3eVSXFqIjCjQQ74vl+BcI2NwipVoaN4YveWzmriCRpCXwnhmlDk/9OqeEbAqoUP0xQO445eS+FpZ \
7qsZmjndiAZ3jTmW8bGdPUuXmd9EssC56L1qV4o+2yOSvpbPW+sTO8AMnifq1mbceuU5/gAvWCawA3JNRyYkOt \
jPfj6JURX+OROm9sj7MVUCoK6nIhxlmrcllEQTohpEH1c284avRWm0jATK/NK6wAiEMq3+Hf98hY4S5guuMFYF \
mdQe3ACeryatIA4mrXxt7IZEKYLdNLrnd0yC4qkePztqEEEsbfIbs01CaaJNZcsAM5MhF0A/JPnUtRIsyYfw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
net.       	IN	DNSKEY

ANSWER SECTION:
net.       	8340	IN	DNSKEY	256 3 8 \
AQPlC0AS+lRQ2S97U6GcXyItQZSEC9CJ1XIPOah6RkU8CtoSwvapf/M6T/qZvJhcqnLAwujEiIOMWTwwSQ8XDU \
Dn8fiw4upqe5wg/favLI2Uc3ElQcD7qoqufLnmspGP5urK9JTqGkW9PFfMd/iPCfLLnpjiZEv7qBYhR0QxjYRyyNIZ/wpGjdNs1rKmiZxHqp4hT6oEVlL2rLbjpzeZwRRf
 net.       	8340	IN	DNSKEY	257 3 8 \
AQOYBnzqWXIEj6mlgXg4LWC0HP2n8eK8XqgHlmJ/69iuIHsa1TrHDG6TcOra/pyeGKwH0nKZhTmXSuUFGh9BCN \
iwVDuyyb6OBGy2Nte9Kr8NwWg4q+zhSoOf4D+gC9dEzg0yFdwT0DKEvmNPt0K4jbQDS4Yimb+uPKuF6yieWWrP \
YYCrv8C9KC8JMze2uT6NuWBfsl2fDUoV4l65qMww06D7n+p7RbdwWkAZ0fA63mXVXBZF6kpDtsYD7SUB9jhhfL \
QE/r85bvg3FaSs5Wi2BaqN06SzGWI1DHu7axthIOeHwg00zxlhTpoYCH0ldoQz+S65zWYi/fRJiyLSBb6JZOvn
 net.       	8340	IN	RRSIG	DNSKEY 8 1 86400 1589473410 1590769710 35886 net. \
Q64lprln18kf1DuOagLzYo90C1RZhOm6fq63tC/M89NeOAjeoDeebMYw2lCbRhIlKn564oPqX9DnbXXqsMzzvf \
nmyxnGcba1i2bRcfrqo30lYpzjfCo/LWjmSqNa3IM5wKydACyNqNXGbsjFkl7GHn8AOeUPSSB3+Pjl9HbXtRL9 \
Gg3prYft1jL+JkCSAOWND5iSnP8/ZwpnxEqE0rvnEooGFtaSg8HbBYHNksHkdAFes+LKfLNOyEVQLaWYORnARY \
bT0qrLD1y7awgzjlEbjOfOanWFRkn2lM+OTmFehdXEVhMznphp76waPo9tJmTGLgtoifd7MlCX5AsrS5Z7bA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ripe.net.  	IN	DS

ANSWER SECTION:
ripe.net.  	77710	IN	DS	51356 8 2 \
9E5A6D4D413DC6D27E8D412E737DD87FE6ECFDA7C4A14927A145DFDD05FC0A65 ripe.net.  \
77710	IN	RRSIG	DS 8 2 86400 1590126303 1590735303 36059 net. \
D6k11+0DK7fwxNxIt74TCywxNwmF7oG5u1V7AhN1k8qZ1dDfYDUsCPZyRgG5r2zatJ8COv/oLvSmU3+ObgPI6I \
anb+8Npeh137n6wlJbVHB91Y1RRNtftbTi5RiBse8/BLyuzbnbA0KZAglR/1z65GbOaYbQFj4NGfWSP8MfjvSD86CfhhEvoAyulEJ36lNbnyxaQqdsuMOuQT22Qk+jaw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ripe.net.  	IN	DNSKEY

ANSWER SECTION:
ripe.net.  	71	IN	DNSKEY	256 3 8 \
AwEAAcMbmiRnycdRf5qVlM8efJaBvldhjx7JhDL2SF/DDVxtCPjHQGSWDa5Bo/c0pgGCddYIbf9DCisq1VJ1k1 \
TdV6Xr3PvsM7scyAW8q99TklBxghZ5pLHREVoxAxu13F+9Aibq0LNl0rWCsXjimKTjKuL/+RGLO3k72HqwRBw6Rwpx
 ripe.net.  	71	IN	DNSKEY	257 3 8 \
AwEAAb5IhmWq0JOokzX8AWFWqOxf/xVbIfvhjKBGneZRA3Pp/1vUp3bTQt3PRaagV2zIHUtU07+9JrccaBcNXa \
RJebQtrnryqyeeZdt/tLndquXLkUcnaV6VRS5USCY5iHkVefbYlHeoshhpg9SujJ132JXKO6MQ7+eqis9XYB9/ \
6rXNUoDKg5SlwHv6Yxys+03wf5DaFiEXnLek3fgdwd1fxsrw0IxImbxXp9qwHzv9Fszj1ZYk0LPUg77QKJrTe6 \
MCq0gzi/PUBTwoRd3VxH6Ge9pvxIUJxg87WFPZuYbLFFXk5s1Vjjmmy3Ca3Ou6TKbi2wTm+t6MnIk68KEJHxwbp7k=
 ripe.net.  	71	IN	RRSIG	DNSKEY 8 2 3600 1590081652 1591296652 51356 ripe.net. \
idie1SghrQMPDRxOtrp1A45reUCJPt3nAfdKU6mSuv6WVUrmTDqMcx4DXfOaF5qP5PgBPWQ5vQo8uUB8TJCJRk \
qgGmtJ/OQE/qtKI/o2OMPnRZwVdCyxV5PiQ+qSxkiWUWQJ+BOoc8HFZxwF9p6MrUtcAmoMaE7hUuljD4i06lYZ \
wtoVomYWE2ytbVnwSuofkr35t+e/pZY7zUedPxGzvfIzHibLBjOlMC5zPUUShJ5tzXts/exFlTtdQaAt3KigZN \
XkRqVFNPra94F5mUozG5yiydbUYT3L0txcMJ24hgnXbblpz+eaERePbOYrqqRQ651+Ozsf/tnhxTiivYUqBQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    7 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
probes.atlas.ripe.net. 	IN	DS

ANSWER SECTION:
probes.atlas.ripe.net. 	86400	IN	DS	28486 8 2 \
D63357B122C8BC216ACBBF99DAEB65B73DB47FC2B2BD422A82DCCAEE74DCDCA8 \
probes.atlas.ripe.net. 	86400	IN	RRSIG	DS 8 4 86400 1590078052 1591293052 17508 \
ripe.net. BWCFJv1yaiIj7ew3UZDhJ+PmTVhCRVsyV/uAH1AOLgQsdPBWmDxPIC3kdHKrTWvy7q45PHxd91Z3 \
KpBwoGoACt1e3c7obaGCip05l2rYfm8W1o5AZgCXCwN2WTepN9Io3XFxGDqQ3K8+BjNAP3ihi3jh6+tdJMQ+1eqM65GFL5w=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    8 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
probes.atlas.ripe.net. 	IN	DNSKEY

ANSWER SECTION:
probes.atlas.ripe.net. 	3600	IN	DNSKEY	257 3 8 \
AwEAAdiht1rYzyIV7rVSD/ACGNiGXHiu2tQRBfgigyBSJM0llq7dS+kkyPl2Y2XNfXUfG3PbtSF85DysWIOIwY \
vVE22mNZV7JQJavO6QKg7BHtWZYHNn0xTP+vJ995nZTYG7qigj4TF8ta3Bj4BfdWY+QR15OXSumb+pfQ/p4Gwz \
PufE8TbvnN17HRffcAxy7G18fLU89V0BMqU/XR4RdFU9xrLahz389gYF7wI97ybUnmBc2rEPVVfty8AemfXu67 \
/DezdIUAE3y3TO2jTfxq6PHsGnupv61orNnSWaAghpIBUp4UHorS8sr9ZQyKR/ujgRQBv7Ee844GvXXWBlrE3784E=
 probes.atlas.ripe.net. 	3600	IN	DNSKEY	256 3 8 \
AwEAAZ+9lm1lZIRoPY+5imP2BnK88FH1lYiZIporngA7702udTdLi/SFYWouI9eSKZdHe1W/ZZYisqlE+6+V4D \
O6Wl2wUmIZb3KPrbXyJodP/FnGwhOrkrtMC2HM1hjXElRxJC44e5xMgp0Mrj9nf9RsdLPYRB6N5if52e/4+EjHPkbT
 probes.atlas.ripe.net. 	3600	IN	RRSIG	DNSKEY 8 4 3600 1590081647 1591296647 28486 \
probes.atlas.ripe.net. \
0nVBGBrb40Ki6Nuh+Ft6rxLxoydE2cycKKGdLD7hOoTUIVnG7SJlcmtJ8aerqxKUBvNUuJfh9pNjD9JbThREHQ \
HFaDvrcsivkKCEXwPcx+Bkf+E6Dk48HphT3+LUc1/L2MT7bUBZ5BMNR2iYUiWIcKgjsd+cD2YmKGEwlshwKU0v \
6SbBzSDk/U7qVZFM16egfo9MHtzAEFufVCbYrJPFC3Ffr5tvf9SVSmB/eIz0UevvFY2heTF21kVBx2vZIsE4ct \
OtSbVikbQCGKRkema4RbsX8cDebubTrscF74bx/7y93r2Y/jyZowj0JUmXw/sbWO/cNjFLR9l8gyquEPUbiA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    9 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
xyz.       	IN	DS

ANSWER SECTION:
xyz.       	74096	IN	DS	3599 8 1 3FA3B264F45DB5F38BEDEAF1A88B76AA318C2C7F
xyz.       	74096	IN	DS	3599 8 2 \
B9733869BC84C86BB59D102BA5DA6B27B2088552332A39DCD54BC4E8D66B0499 xyz.       \
74096	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
pmzouszNXlgF28NaWaMshuBbzTIVvwx7jDVoUz4j4Q02T/gZ4wEehC7j8tIE0SUAj2q1te7fxiqporlAIA7xQB \
ru+mtqgs+51fNlyDh0/T29kjjCWNhJv05VvpC0oyv/qpBtnUPVVLYyronagGw0YjZii6aFmoy6dUSoZtKTxH1L \
lqLtz0w54UWwGgiJswxy0lD5zVxWrSqRJSB87JG38xnBfiUiYtmqRd4vj3Fz458YLe3szBien4hEARvrS53h5Q \
5LJNwGtnxGMhKLCuah+6/Pq2iEwOY40/axu3deXcjg8spETakjQs7LGLuHOq5jaYWkikTju0rpQGmoAm/vQg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   10 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
xyz.       	IN	DNSKEY

ANSWER SECTION:
xyz.       	1300	IN	DNSKEY	256 3 8 \
AwEAAcFQcBshfBkV4Fo7iCeKmhM23w+eX9ty9e+wZXDzl5CfBrUj3mjiLUcoYNRAUiRnOV7GhjUWV751KoXwfm \
zB9CT5nC52raqCtjL/BsmPAse4RmDliJKLjHTcfJHLoOTo6a4XTt3NunFIuA64DATMUcOo2knVJgBn7kWiMhdh+oNt
 xyz.       	1300	IN	DNSKEY	257 3 8 \
AwEAAbYRTzkgLg4oxcFb/+oFQMvluEut45siTtLiNL7t5Fim/ZnYhkxal6TiCUywnfgiycJyneNmtC/3eoTcz5 \
dlrlRB5dwDehcqiZoFiqjaXGHcykHGFBDynD0/sRcEAQL+bLMv2qA+o2L7pDPHbCGJVXlUq57oTWfS4esbGDIa \
+1Bs8gDVMGUZcbRmeeKkc/MH2Oq1ApE5EKjH0ZRvYWS6afsWyvlXD2NXDthS5LltVKqqjhi6dy2O02stOt41z1 \
qwfRlU89b3HXfDghlJ/L33DE+OcTyK0yRJ+ay4WpBgQJL8GDFKz1hnR2lOjYXLttJD7aHfcYyVO6zYsx2aeHI0OYM=
 xyz.       	1300	IN	DNSKEY	256 3 8 \
AwEAAc+yMD9rUVId9Yuyxw636XdQrsgP6HcBk+FD69ITzV/JLrFYGU2EiBfUTjUZC3dDOtipGrIFymkyzhcPcb \
mg2CBrPtNa1EqNSn15bQKqo6mDTfnME4PpoQ2q2M82lk0vArxO3+FYJo+TJWqboNhtR1MIm9fvPfDYCsNwCWfrwsJl
 xyz.       	1300	IN	RRSIG	DNSKEY 8 1 3600 1588549613 1591134081 3599 xyz. \
iZhPTCrsn6wwN2LvNkSFfpDmWJmiP0ha02RdlOTneT/7q0PCo8RGJHrLcoPQVvGqodqQU4kGyNJ00ZFVcoG4fk \
8sjUwVdh6V+cTGbqOI0Avg/XYpuJ+HCEEYi7n8tAiLvKcvQos3XhetXoAYXCD80JEOALtkGn6gBtCmXO6NFjmE \
oBkB/56FZvyczt3f6mld5uerKNsPHuGMID1S+zPDLwC82HQMBZosLa8hhbdoiyTXEFuuhRIRXIrf6I1S6vARo5 \
GGkVAegu5j+FZy0QQ5gSud7VQhEJ1uwXfA3BohJ4FC36MNlqKuon3izJR4DX8jAoFq6RweYhq+kRWaCQv4AQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   11 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
traudt.xyz. 	IN	DS

AUTHORITY SECTION:
xyz.       	3600	IN	SOA	ns0.centralnic.net. hostmaster.centralnic.net. -1294423112 \
900 1800 6048000 3600 xyz.       	3600	IN	RRSIG	SOA 8 1 3600 1590321048 1592936988 \
25080 xyz. rsdziCo2mfIMK+6PVMoir0GsOo/wfDaCTgzwLm1KrmSPkRTSFu5XCLe9Q4znAMNU6dJ41vasvAr \
2Bsv6K2fX1t5h6ulbNd0gyRas7YkmtGK33w+L3UkgC7iSjqYBo5gUHgRJYJjRcFNJ8Rr71FEpe3UExI0c6dKndNKEihvgtQU=
 1h97h2oec2juov8dlbbjj6i7ik26bm8d.xyz. 	3600	IN	NSEC3	1 1 1  \
1H9SP7N22537R92KKG4DNO5R90TMHMCQ NS SOA RRSIG DNSKEY NSEC3PARAM \
1h97h2oec2juov8dlbbjj6i7ik26bm8d.xyz. 	3600	IN	RRSIG	NSEC3 8 2 3600 1589808943 \
1592376628 25080 xyz. \
joPtjBfChdBuXX0w8kumBtKsYCC3MVNjyLx1MXPSBBJBbk2NliL6O3+QzAMYLNDk9c97Oy2DxlLWi9HMhW7cbY \
7BxtfWkpzWvvEVrrTRw6D4iK/EybWwCnS+qGsYjohHRAEJrlZIHsxhpb1GIoHCHVvVxKdgcYSy7VrLcs/MIQk=
 vim8qo3rsjndcngh7s6ja0n4vrdu78cd.xyz. 	3600	IN	NSEC3	1 1 1  \
VIPUERNRGKH3G6REJ37L566OT8SIHT1K NS DS RRSIG vim8qo3rsjndcngh7s6ja0n4vrdu78cd.xyz. \
3600	IN	RRSIG	NSEC3 8 2 3600 1589942592 1592577233 25080 xyz. \
kePtQYGKWuwYD6rCgNGbflMd9SpbSosRkAGlKtW8NmR/0S9pMN38mW6iSqu/P4gBZ2Z2ktcOZS5rYu5hd/J9vL \
LNnrAGvwE3NCuEXKKs4uevxnhZDP/BrRkP1KQZdfjW4W8DGwRAcZgUGhkbKWlkIJsPqbFMxl4HUfKPm1YJwqk=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   12 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
pw.        	IN	DS

ANSWER SECTION:
pw.        	80631	IN	DS	26645 7 1 58EE332D303E2A64B7449C43AB770DAA1CA74C40
pw.        	80631	IN	DS	26645 7 2 \
7EF397EDF4D7CA228C0F5111F5E1696CDBF279C0B6AFA48FC7E71A12E07E5880 pw.        \
80631	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
gq1fCxOa9/FdPGFLXvKtICgeIBe9cJGohzzMHdUKAJD4Mmm9VnipU4T90/RBfYdf1XDobZ4bSV74smAxh4OHTs \
fNZKmzjfT6f+7Qw0rZD0y1SN0TsCk6CPdxXh9066WzNrfZIRAIibyR3m1+OwvP77Cu8o15xrJ/Tf8BFjin/nbU \
wi5d3GR+N1w6ti/yztiBay7y86DYkaPLAN6nU4gdCTSDIgbW4DwHTp80mwh4wphM6R/UXd17cnPulagqDL84/S \
ILH/dX7UyrF3brVjm/QXWH8JNWStj/BkEKOxVPDcDWHEBITcXgHPeqncanEKd67MGlYUwjrcn2q6kweA0UWQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   13 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
pw.        	IN	DNSKEY

ANSWER SECTION:
pw.        	2392	IN	DNSKEY	256 3 7 \
AwEAAYsskko6PQH0En1soZmAvDRm3yGeA70a98n06eNn7XD2B2b2h/D5iJF6C+gEmtAeoC1NznEtG0i3U3Bfm1 \
hQYKb/zbBbLBY6KyGKMflzue33IsxXhFxMhM8cc7uAviyszjAszAbF7eoTKT29eIZBaWvaN9Ck18629i55y7xmaaCT
 pw.        	2392	IN	DNSKEY	256 3 7 \
AwEAAcV2Mm50D3AT30ajrXa7pbDg6xlnTwD754wFalHnal7gpdi+vh2ov7GGe8ft15AmWHbDRz3MNUfvc/k6Nf \
ydSIxQhCwooNv7PL9fdM+eoKicKG4U/VaF271unTsI6nVZC/F7XhxTLtu9UIlfrDARas63qZtkiugiBCW5M1QtSuH9
 pw.        	2392	IN	DNSKEY	257 3 7 \
BQEAAAABs98NLxDqJKJ/pdRfNcBSC3eetcuNII+nkbniYVYRrM2OWVfBV+WpHBhzgr0bqe8xE+Wg/aInWs4o+z \
mJCKzqGFwLo8k9bhQWYlACrzfj50oQ/FvRgTmUigGNW+nE1nRUXb7kr/YXPTG6pNf3smCUDvBDzM7CV62IPsCf \
Atf/DQvi2+nQJYYODQG8yav8bvE38RrkjbmojGdkxcAZMYTJqvgNC4MAIunj0s51VTIIVn3Pj5POnV0XNXSzSu \
l4nvnFXH6Y4BrIvn7HyfCKyU7WqExtRZmCbC+/mi3W1L8hRN/4uFyMac4VN5BfajD7GyDGUIdR854a5LQzXFl1XnMxLQ==
 pw.        	2392	IN	RRSIG	DNSKEY 7 1 3600 1588466768 1591098184 26645 pw. \
IKKK64nP9MUr9P/0T+d3l1jf7A7dbh6WLXuiNEIEP4Js6GfYp24SP4yjOuk6JQxrdK+QH+g7cHcJmW8fvCGyzp \
wT3MwvYQYK2WHuJbnviEtZrcuE+kUuv7h73G02bAlXcphk15EZoFm3k/rtX0PJxkkIwjOSyLVFVqg28iiFwjuR \
e7lGIOcdjhxmHYpJF4Wlgi3GW8iZ+962byID8Hiwl47rKNaQz+aVVFEfTlUFI4oaSdh5ZxkpOeAoDnqQ+4Ui8A \
qEWbGzZV1iCKlwXmZy+RuxlZli+hvigCtKRLhXReDt5ZGxjbyXoPD+BFIE3eLJsm5bCU5rh5P8vat3XHorfQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   14 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
system33.pw. 	IN	DS

AUTHORITY SECTION:
pw.        	3600	IN	SOA	ns0.centralnic.net. hostmaster.centralnic.net. -1294415353 \
900 1800 6048000 3600 pw.        	3600	IN	RRSIG	SOA 7 1 3600 1590321264 1592936423 \
362 pw. AeCz27hvHy9lBAqbGpU2Vh+yjv5FqkUYi9RjiFBtxVtqpN4hQKD2oSx8o7vcip015wx0vioZ37t+y9 \
RU/KRG/0O07XJ/rL4FGLUpY3ELL4yTq7jsSGPbLYsOFfhMEFH7UoG5c5iYiHx+CY99cAye1LvZOUmERmzsuWmB9/8+oSI=
 5njihdv29htfqesp4s66h5ia7mau40g2.pw. 	3600	IN	NSEC3	1 1 1  \
5NKAI1879KPE8PQ8975I42IIPTGCTSSE NS SOA RRSIG DNSKEY NSEC3PARAM \
5njihdv29htfqesp4s66h5ia7mau40g2.pw. 	3600	IN	RRSIG	NSEC3 7 2 3600 1589910792 \
1592528711 362 pw. ZEu8bkz7QEbY8huZmylf2Tqvm53egYHFtGHKYw5/Fq/T3rO38pfQNhjZfZ/ujyPWVYv \
TKsSoltGI/hcyhVLPbVyrN4Y4oFcLm9yPOdAg3pbm7a+72oiMgrm9WsPX0MPbMXPYzzig4s77Hz5I1ZSgGF6LsxiUPDRapj+ml++uA94=
 oj01ns7fcmobmrplhlu3talptlo14meu.pw. 	3600	IN	NSEC3	1 1 1  \
OJ0E0U2C6NPIQG80NS0C8EUBHPP4P157 TXT RRSIG oj01ns7fcmobmrplhlu3talptlo14meu.pw. \
3600	IN	RRSIG	NSEC3 7 2 3600 1589654485 1592240455 362 pw. \
HTO4QorqPvHsS0uFwPreogtCIZWjfaF2tcuBWw6/FM7lMHpomqLfa/PG850nP1u3I9y/IsWNhrtF/g8tdotUYe \
wTXRNpSCLWJGtCSkK81Ny+W8DfjSFIpE0PMsK5WH57TON8LmxqUwVzgwER4NMj7K6atRq7a0tjl0lkgmapcWc=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


matt.traudt.xyz. has: 9011 bytes


["www.dnssec-invalid.acei.ca.txt" (www.dnssec-invalid.acei.ca.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 2, ADDITIONAL: 1

QUESTION SECTION:
www.dnssec-invalid.acei.ca. 	IN	A

ANSWER SECTION:
www.dnssec-invalid.acei.ca. \
30	IN	CNAME	cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
60	IN	A	52.60.179.126 \
cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
60	IN	A	15.222.131.125 www.dnssec-invalid.acei.ca. 	30	IN	RRSIG	CNAME 7 3 30 \
1588482456 1591077439 63407 dnssec-invalid.acei.ca. \
A7zCbvemHT5MxMLEd+FVdCyzXkjbJgLXNpfhIZMNUMa9+qFtF0d6uaPVzS5Vnu+69JlC1e8ejPtgFyqb/i4Y0V \
D1Y+SlNDQAY8NHvFaHbQfcc+h+8er9sg4ZY58dVvvXuD6nAFlxCv89t8H2SwEy2xcT7Ek8pbvrX9EbIaXwSMBQ \
6t0e13YyEX6USxRHprzkuY4ZiZxqBaEWP3yGSKjF6xskkmTLAAVcNQTQW10OhXd1Wxnr+/sS6qr4nO9ecJxylD \
6r8A2Er4tuLvlP6OhC89A2FhWql+19VWPnMIX3QtcXwIkLPnGlUtvYMZe8/mU4N3SXZX0nQSmpJZssvLYbow==


AUTHORITY SECTION:
*.dnssec-invalid.acei.ca. 	300	IN	NSEC	dnssec-invalid.acei.ca. CNAME RRSIG NSEC
*.dnssec-invalid.acei.ca. 	300	IN	RRSIG	NSEC 7 3 300 1588482456 1591077439 63407 \
dnssec-invalid.acei.ca. \
ivQVdByFiS33elIjt3kVvE66ctS9MbYuYbjDnCMMzSrjCyOt/NHexr8paGVEqe52dJX1H4+f1DLeHNtI62CU+7 \
UewHkI1QQ1bWH7rR2be3Zf2Q3JDDu45Eok1zXSv2nGk8ksbkCvEF+Np6/eXa7LDbFfgbF2an9RysiVsPRsi5fO \
YeWAFTN3A5pAH2b8afgQ44HgJMa39werhYdbTwvZiUneD1XiZQFnoYGq7JUxfYJge60xTXRbb1iPAPudgJ0hiV \
cczrUni1jP3LSZTLuTfRKaSAgm6VC42h3ZrFdpJZeL15JAtR7LLFbym+s/4hhh1NyEPxOoNIIumX2FBRXbaQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	8589	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	8589	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	8589	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ca.        	IN	DS

ANSWER SECTION:
ca.        	86399	IN	DS	2134 8 2 \
4B8475C0C0FE2AFDFEE1A71A237C91059098D12FC18265B290EDB238A5F63582 ca.        \
86399	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
MbkxSn6qiyTMGVKlBV8cBDXRW7O60pdnwpDPQxQGzlsy4hacfgFHUdgJ0KKYoxUBZzMrMTKOMF+Ym9DTnkLx3g \
2715m2UD15GFDlZFAmNr6OC4GEs0Xg6zm9oARfshUOykhwmIkOHnXhHfScq4sJd1AEmSBzD8B3B3jOsJItFMVw \
xQ4Kau0aG79slNafzyGTYkf51RZgPAxma9IbBn+e/CnLL8MF390W5qITV1oD42EwLQUbWNPM3rXcXYP43kVH1o \
U9P/zwkZzhx9dz0/TX7k31x2dXalf+2Dbwkrr/B05HCtjrqYDsroyxgmmUIssFUcHvANYHkdLmKoqfYsZuYg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ca.        	IN	DNSKEY

ANSWER SECTION:
ca.        	3599	IN	DNSKEY	257 3 8 \
AwEAAbCgygRHgULoUtVno8pEVz1XMjnTjTFVvZYphDUcgIy4SofQQlss6rG9MURtgzULLnJHaaoAcnT6MJXjhf \
g4HeBkV2JlvTkHRnBQbRkCqxx9lpOU0BsnfEkoIpUGVm18LHdLmEoSFSNlXHNfW3/uayHXM3yKXTqyvIgEvMHs \
V3qLxLIxZj7UrAqsZi4pJFOwEz+QzydWt/QZvc5iXcDZDlYjfBDHT+UiU3NR4A7XLNUCH434rjRhUe9oFQFaWa \
cbWwtt3aimY+mD08fM2IgxprP1eECDu/dSaVkI37DLVbJawWdqpsDobACVl7jbKwxIqmkseLxmrxjOtUvAEcvIqe0=
 ca.        	3599	IN	DNSKEY	256 3 8 \
AwEAAdv1tDhjeFHA6WYgNcxHxFLQAegMnIfy4Wo715kdVp2A6E+l/YvxvDq6Bdt8QBqwT0LyQiESwedlM/XN9q \
GgIWdJGWPzkmFs+qpiHgUGM/vEScUHj5GT4URssB1Vef7HO9Fz4Dysqa7rzVSmbQWpUDacTqd7rppBgZkYU7ltQlPx
 ca.        	3599	IN	RRSIG	DNSKEY 8 1 3600 1590080953 1590672086 2134 ca. \
ZUPshg5ydlgmpUmnkXECsa5y3lgycF+sEvkfRAzxYzGlP6yf6WbAZHCshcTORvX4NErEQR3jUKsY+l4HO20WgG \
r57FkBt2wHlAumttTaeY3l1viJIdnRhUG+KpZJ4sbPZ6Mp7zk+HJoD1Wfmcv2VkFOyzpYVTzjV3QPyC5RAfOBM \
txdHhv2NPaT3PK//gWEcUbMRxr/HRo1WL/HD04lJo4nFTXXHUQmHiNiS31juTlE0J1wbMhzVjkaybcZTK/beiD \
1mfBuXjHU6o9QJL4ZAxOUaLWEdsfsynlsMOHHiUUHTox/tRGUXRU7SMnV2dF7fO51BxD03X5C8/ktOw3ip1w==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
acei.ca.   	IN	DS

ANSWER SECTION:
acei.ca.   	86399	IN	DS	40897 5 1 044E3A2621B65330976A4113F3C77220F42D21A0
acei.ca.   	86399	IN	RRSIG	DS 8 2 86400 1590212353 1590837152 35433 ca. \
rSHOnT5C9xtIkQyACz4+pgYAOGJQNQ9aKReqndCEL1X78HDgflNMzZcjy1okok1fyfO7KeTh0radkpkeOpuJaO \
1iFgx/BQaTcwldCTYYDyv90+WVHRKSxVlIA7teQiqs7h2Nv9GFsAXgO4rNVy3zgG2qw1tWHirG1CrP6pOyScI=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
acei.ca.   	IN	DNSKEY

ANSWER SECTION:
acei.ca.   	86399	IN	DNSKEY	256 3 5 \
AwEAAeSlFnjKtzwUmNB2lqw6Gx4YqllpS5b/y3WoSdxIiEd6Z7roh3SCAgEQ4vecmEy/kT6xDlBi0sYJCjl2Si \
mFBZH3qMcpO8Sa9jn0lqrHWjdvENwAR43CAYf6jme/s7sGoTlOi2B4BCpqk6+4xQyervWZoXI9quJC+EUFdMBPbtEX
 acei.ca.   	86399	IN	DNSKEY	257 3 5 \
AwEAAfXHHIEIPyiIJqTviIsLLNKmqot1lPFMkjRdclSW5QpPbcpGJl7iTsDTlfzIp11wAjP7ch5LL5ZNuz+yoi \
7nQnsoFDrpgB9gpU7NgU85nU9ETdtcV0vrbW2HKIPB1Ly3Zfawrl1Sy69vM93vKwDwBNJQd9TzncB5+TcTawYs \
TazfmQlg9hnkOKBf1kEg8BIriZCNwRj8rnG27+RpJVIdt5xL95ByWpjILqMB7zQf1sPWgPwkTE8T64S84pXuVX \
FC0QzE2Uun3mStZSUqHeUILrMoYz/gp/M9wYKidsl7fWSogEj/jU3AjhqJmOLrb/PP6jo/UartM145bkPZVwXVBh0=
 acei.ca.   	86399	IN	RRSIG	DNSKEY 5 2 86400 1589685203 1592278222 40578 acei.ca. \
EPr1RBYJNYnVgKm5w6NZGd1eW3u3d860dBYaeCbExSl97yNpvLii03n4nlw/aDvFxPyIQIjrJzKyXgnrSHYW8x \
B5ZABb3y2xKEb50qB28u/4VZPtcgMcQh+FJABX9VTXANRvSrYov0lWTg4fCYwYpdfwHM4OT5VqzL0LBDFwcaM=
 acei.ca.   	86399	IN	RRSIG	DNSKEY 5 2 86400 1589685203 1592278222 40897 acei.ca. \
3ILu9AVLuWgoxBGy2mjXVBur/ALFFYBA5hx7xC66baFXq0MQaSNdD86F1DgZ65kZrplKrdchEImXwF5XuT49Ds \
SI3/Ej5wRXrgT2Gqq1IrCgrGH7t3yIVL9iHMugUBBWtWV9iWnL2lOQiOGYnIapm0lZbbOVqA+U4Fttw+2uVMMr \
u74RXysFCVYieHWK5O6uhHGeistKBXtuTeXP14Z4BU8tBl3EKDKUhuR9vljAjfRlXXulotTYw3/7X+oxnqkGfo \
PRmGV5Eif9wsP7rbwmshHODDHVf/DcAcE+hdEYrypNqW+hbPcJYasTf5zipZL4rYYURhBsfKaZtxsyznW07g==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    7 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec-invalid.acei.ca. 	IN	DS

ANSWER SECTION:
dnssec-invalid.acei.ca. 	86399	IN	DS	55341 7 1 \
CBA26CFA50ACBAE0D527AA9AC2102412FD35E901 dnssec-invalid.acei.ca. 	86399	IN	RRSIG	DS 5 \
3 86400 1589681234 1592276151 40578 acei.ca. \
jToef4cSg0E64eF4orXCXH68tzd9aljYMVcTmsdBTF0RHEUjtyfuTmt1saPCYDAiR5wDldP74+NQcyA7WSo7GP \
1DpnbEsyGj1NTs5CINHf3/xW9IrgVWTnj7PtgiMKnggTaHYlTBSeF69nQ6vzG84eX9LS2GDOqCwNJTtFz/o6c=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    8 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec-invalid.acei.ca. 	IN	DNSKEY

ANSWER SECTION:
dnssec-invalid.acei.ca. 	3599	IN	DNSKEY	257 3 7 
dnssec-invalid.acei.ca. 	3599	IN	DNSKEY	256 3 7 \
AwEAAaTlSOKqIxC7Raj5K1eFVVq32VRmop8BMgjjd1KuF4aTodl0laEooKgvpPs8E2UDHkODwr1Ko3jJ8DuqA3 \
YBvtJ6FOh7mSXCmARd4vAyMpQlDTzdmHqqHC+9iVew2aZHk7J9NziCKOv8PCIQ34Me5mMX80oKoolfqgN/AMXj \
Is8h7YfOCgvcQ9QHxmH4MhXioaWAGmgSc9krQdqbp51NsKyUlgHu9fLkpB2uipNt57H3erjGsqnxgBDprK9ixF \
KHNiA/AF2WmsoCGE5XJalKMfjjGZ+s+O7QIcxEnPW+qTF7Lm5D3VJDaXLowWX4Yv4V4HfzjXaG1YvsaauNk3OGpBE=
 dnssec-invalid.acei.ca. 	3599	IN	RRSIG	DNSKEY 7 3 3600 1588475940 1591071108 26190 \
dnssec-invalid.acei.ca.  dnssec-invalid.acei.ca. 	3599	IN	RRSIG	DNSKEY 7 3 3600 \
1588475940 1591071108 63407 dnssec-invalid.acei.ca. \
M+H4I6XmSfQqnDlta1gF4mi2lNHTAxHYzkcfQKJuUrBt9XWG3jxWK9uPCNygqwBToO/ig6hiDi/cowys0hF9h3 \
wdZ2wiXCmZ+TmmsSp/1XzRIDGxDvCpenxV542/uBTue3NVRHk1rbDp1ge9ohz/LDa5tRNO6CS1cbAVNurOUW/B \
qu0Kxo/CY+Useo0FRldqKMZFWMQr8p6YAEPsrpuEqVBWVhHaS+xSLKWkqOMViCVC9vmIzbE90EtSABBF/Ugxb2 \
HXxQadYbenp7U0O2KtlwcRiMGMDUP2oCdcH5jPcY4tJ5lFWBiXiO7oiOfcKPMBCvFmsIEpi5GWS65Yx5SBqg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    9 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	84855	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
84855	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
uqEjk6O3Ar61SqlGxHZlx6T0AlSP/jGwXDX9Q8gaiyeKaDcf7U7OZH5e2eIMztZw4b/ctH3nbZBvvpeVV9bow8 \
4ubmHeXjO8KbiiSgbc1+Xrz4sbpZaYzs7NpG9A852kU2f8J5JKwfe3wmZ7MfbInjMKlKRmn74HPZTO12FZqZVI \
rxXX6og4FG8FnO9eSiIf7m1gtutTqrQPD1azXz96VEY+v+kl/AVyhQ+tkP1B4rplqDq2gf1qizgggJz0m3pVzd \
tB41uNdwK25j+BzhiVt+tRGau1s0e+x2au26MhG0WeseuKn9Mt2CWyxE9/mCgWjFEQmadPWz5/EyzBWhhlcw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   10 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	84855	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	84855	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	84855	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   11 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
elasticbeanstalk.com. 	IN	DS

AUTHORITY SECTION:
com.       	896	IN	SOA	a.gtld-servers.net. nstld.verisign-grs.com. 1590329293 1800 \
900 604800 86400 CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	896	IN	NSEC3	1 1 0  \
CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM \
8FL8ACCB7QGAJ6Q4Q4HHDH1G2C1FEQ6G.com. 	896	IN	NSEC3	1 1 0  \
8FLAB747GTO10MQV1MGB252GK63UAF3S NS DS RRSIG com.       	896	IN	RRSIG	SOA 8 1 900 \
1590325093 1590934093 39844 com. \
rjlgVW1rC2GknsFWz+hCzmzT3T/iZvdCmbYMaxTjH4B4NZL/WsqTuwNNxy0A+72rXFzl8Ay7VoBt9OqYsq5oz5 \
gErLlyoRCQeM6aYeE3FizB6dpCJvLnc9OT+IwPq0oc5NDoxra1cOIT/N6EkEpgZYwoI+GOPX7IWPdf/of3K60soqWRbRutJvYCoIWyNLlrd3GEZX0i3sBmzttwGfKwtA==
 CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	896	IN	RRSIG	NSEC3 8 2 86400 1590118683 \
1590727683 39844 com. \
NArL30b9Vy8GobUMocYC399NaMB4oqLbana/HTaTIz4lKkLRtFM6iuBewn3CXtCuBCZ3VfV6q0K4jvi2+su+bt \
kuGZo+Ds+9ktZo2snOzdiuqFOdalMkzpNbVUyEuiJDsFRYPpueKaWNLPv1ceo+/C20hzxUUJ0UDBCLo/RX85dLAiVl1OA8O2FPidsDyXnoCxT1vJaySfDnNkLUCqDohA==
 8FL8ACCB7QGAJ6Q4Q4HHDH1G2C1FEQ6G.com. 	896	IN	RRSIG	NSEC3 8 2 86400 1590290526 \
1590899526 39844 com. \
UOSpB/Py6JyjNpl9jHLxp5wskEQqo91g5eVPqqnIzSObTEIFf213/noUU6kisdeKeXNMnobs96+QymKTLPqM9g \
yL3NnrS6tsTr0kQAPU4orEZI48JdtR8xfTZl5KhS3MOoVGuKi8B3PwXk4rfl9mhiF4tO80e4PtBwR5oAVT9uYaC68mpwQPhiH6pu5RVCLzt3t7NtuZ5vOffS3S/uUzQg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


www.dnssec-invalid.acei.ca. has: 8495 bytes


["www.dnssec-ok.acei.ca.txt" (www.dnssec-ok.acei.ca.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 2, ADDITIONAL: 1

QUESTION SECTION:
www.dnssec-ok.acei.ca. 	IN	A

ANSWER SECTION:
www.dnssec-ok.acei.ca. \
29	IN	CNAME	cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
www.dnssec-ok.acei.ca. 	29	IN	RRSIG	CNAME 7 3 30 1588480796 1591074160 58628 \
dnssec-ok.acei.ca. I4qJTF8YcO5a3NAjGsTzXxW1haj4lpq/GH3vXIzjJcgkZB7PQVW3KOk32ziVfrN7hsC \
8+rvCIJZUXUzKmmQ4g7mzDH3KkcQvDQd6QMwKmskreaCot09VBJhW4vDDa1GPCmjspNQnn+7wCgbumaigc74xy \
3JTaTqJ76iSVfjNPx9xz6j/uR9kaGOIvoxl5CRkJzjWgJTT/vjiT3e17m9+6WyV2Ic7HSkeSGdk8ClGp1OfElY \
+S232XZ1klbbel8Vyq7qCvl1PaPj+Uu3AzLPhc602MtZ1sx1SM3/n3eo3VNgOPcP/UFIkejItq7CDHyeLVdAthLHQYySYx4E4FF42ag==
 cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
59	IN	A	52.60.179.126 \
cira-ipt-env-prd-v2.23rarjsxpq.ca-central-1.elasticbeanstalk.com. \
59	IN	A	15.222.131.125

AUTHORITY SECTION:
*.dnssec-ok.acei.ca. 	299	IN	NSEC	dnssec-ok.acei.ca. CNAME RRSIG NSEC
*.dnssec-ok.acei.ca. 	299	IN	RRSIG	NSEC 7 3 300 1588480796 1591074160 58628 \
dnssec-ok.acei.ca. Rk/AcKVT8EKMLsXpt7t/aEdq0I0hXBmS/SMNXPKZtbhfS7Rs8VoxMD9u3WkGAl7U+PF \
3gyAewb35xGXh/PWJF95HXJ5+BO3CVLRikGUmSxqRqULrs02w2vfOUxfEXrJvTiaCSvCKbYNM/UsN0AKh4t54K \
7luIX/Z0o5uS/4XQ14qb1Z/97ufbDNM5bK8pt+y+FpvRwHn7LUjXHzJzMz0wDxA+b1ZDvHJaVZIlZzw3IAstkz \
fYFQSrsiD2a/cxWiDJGdcBlfEYEV52Y+Clx6cj5irtKmnSYEHrTxeiJIik/OnGJeLLGRIXugdDQxPHnGjFOShf1XzXlYu2jnfaFvuzw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	72177	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	72177	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	72177	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ca.        	IN	DS

ANSWER SECTION:
ca.        	86399	IN	DS	2134 8 2 \
4B8475C0C0FE2AFDFEE1A71A237C91059098D12FC18265B290EDB238A5F63582 ca.        \
86399	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
MbkxSn6qiyTMGVKlBV8cBDXRW7O60pdnwpDPQxQGzlsy4hacfgFHUdgJ0KKYoxUBZzMrMTKOMF+Ym9DTnkLx3g \
2715m2UD15GFDlZFAmNr6OC4GEs0Xg6zm9oARfshUOykhwmIkOHnXhHfScq4sJd1AEmSBzD8B3B3jOsJItFMVw \
xQ4Kau0aG79slNafzyGTYkf51RZgPAxma9IbBn+e/CnLL8MF390W5qITV1oD42EwLQUbWNPM3rXcXYP43kVH1o \
U9P/zwkZzhx9dz0/TX7k31x2dXalf+2Dbwkrr/B05HCtjrqYDsroyxgmmUIssFUcHvANYHkdLmKoqfYsZuYg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
ca.        	IN	DNSKEY

ANSWER SECTION:
ca.        	3562	IN	DNSKEY	256 3 8 \
AwEAAdv1tDhjeFHA6WYgNcxHxFLQAegMnIfy4Wo715kdVp2A6E+l/YvxvDq6Bdt8QBqwT0LyQiESwedlM/XN9q \
GgIWdJGWPzkmFs+qpiHgUGM/vEScUHj5GT4URssB1Vef7HO9Fz4Dysqa7rzVSmbQWpUDacTqd7rppBgZkYU7ltQlPx
 ca.        	3562	IN	DNSKEY	257 3 8 \
AwEAAbCgygRHgULoUtVno8pEVz1XMjnTjTFVvZYphDUcgIy4SofQQlss6rG9MURtgzULLnJHaaoAcnT6MJXjhf \
g4HeBkV2JlvTkHRnBQbRkCqxx9lpOU0BsnfEkoIpUGVm18LHdLmEoSFSNlXHNfW3/uayHXM3yKXTqyvIgEvMHs \
V3qLxLIxZj7UrAqsZi4pJFOwEz+QzydWt/QZvc5iXcDZDlYjfBDHT+UiU3NR4A7XLNUCH434rjRhUe9oFQFaWa \
cbWwtt3aimY+mD08fM2IgxprP1eECDu/dSaVkI37DLVbJawWdqpsDobACVl7jbKwxIqmkseLxmrxjOtUvAEcvIqe0=
 ca.        	3562	IN	RRSIG	DNSKEY 8 1 3600 1589992762 1590622287 2134 ca. \
rk1ZgX0DPgCGPpHjUIyqB4mRJMHD+ET+X+gU7oEDpF1kZ6WMOkFaDnasw/FsW/DkwpOFpADB7rigSnkbT/3bUo \
O6o8H2KKuxeiYUlwoEfEetKIETIwrTxbpYhI0cwueiOWlIotfq8zU1lvn6gSP2wAT3HbF8OTvtRIVs7WQ9FsOb \
nw0Q4TgoWQojDi02Mcjabh7LMViKZ2EXMbJhSTMc+iFaDpjQEsRb1ckX/BPNBgTIUlOLclEaTGUUmzn/YRUrVi \
fxtQk0ny6ot+JYEQaG8dvTaQARoe5jwtz5esm3MLm591eqh6fviLLRwC8ZWg53bM2kRVFk0dwRnrGgENd0pA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
acei.ca.   	IN	DS

ANSWER SECTION:
acei.ca.   	21599	IN	DS	40897 5 1 044E3A2621B65330976A4113F3C77220F42D21A0
acei.ca.   	21599	IN	RRSIG	DS 8 2 86400 1590239372 1590863675 35433 ca. \
vyC7NxkjWpGxjwrsIFUG9O4lQo4ZQf0Uf/eqPb4Ki7Ro9tm2DSeeXjswTer8ZpoyBbKpW3IvMLLaDl43zQl0k7 \
xGDaoDQGfyaX1QWqY7HteNtBNdrMdDoeT5ChxllRu4nMZ/uSoIQ2HbODfqxCb61YKzwTHO/K5gTRPtn5K4mP4=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
acei.ca.   	IN	DNSKEY

ANSWER SECTION:
acei.ca.   	21599	IN	DNSKEY	256 3 5 \
AwEAAeSlFnjKtzwUmNB2lqw6Gx4YqllpS5b/y3WoSdxIiEd6Z7roh3SCAgEQ4vecmEy/kT6xDlBi0sYJCjl2Si \
mFBZH3qMcpO8Sa9jn0lqrHWjdvENwAR43CAYf6jme/s7sGoTlOi2B4BCpqk6+4xQyervWZoXI9quJC+EUFdMBPbtEX
 acei.ca.   	21599	IN	DNSKEY	257 3 5 \
AwEAAfXHHIEIPyiIJqTviIsLLNKmqot1lPFMkjRdclSW5QpPbcpGJl7iTsDTlfzIp11wAjP7ch5LL5ZNuz+yoi \
7nQnsoFDrpgB9gpU7NgU85nU9ETdtcV0vrbW2HKIPB1Ly3Zfawrl1Sy69vM93vKwDwBNJQd9TzncB5+TcTawYs \
TazfmQlg9hnkOKBf1kEg8BIriZCNwRj8rnG27+RpJVIdt5xL95ByWpjILqMB7zQf1sPWgPwkTE8T64S84pXuVX \
FC0QzE2Uun3mStZSUqHeUILrMoYz/gp/M9wYKidsl7fWSogEj/jU3AjhqJmOLrb/PP6jo/UartM145bkPZVwXVBh0=
 acei.ca.   	21599	IN	RRSIG	DNSKEY 5 2 86400 1589685203 1592278222 40578 acei.ca. \
EPr1RBYJNYnVgKm5w6NZGd1eW3u3d860dBYaeCbExSl97yNpvLii03n4nlw/aDvFxPyIQIjrJzKyXgnrSHYW8x \
B5ZABb3y2xKEb50qB28u/4VZPtcgMcQh+FJABX9VTXANRvSrYov0lWTg4fCYwYpdfwHM4OT5VqzL0LBDFwcaM=
 acei.ca.   	21599	IN	RRSIG	DNSKEY 5 2 86400 1589685203 1592278222 40897 acei.ca. \
3ILu9AVLuWgoxBGy2mjXVBur/ALFFYBA5hx7xC66baFXq0MQaSNdD86F1DgZ65kZrplKrdchEImXwF5XuT49Ds \
SI3/Ej5wRXrgT2Gqq1IrCgrGH7t3yIVL9iHMugUBBWtWV9iWnL2lOQiOGYnIapm0lZbbOVqA+U4Fttw+2uVMMr \
u74RXysFCVYieHWK5O6uhHGeistKBXtuTeXP14Z4BU8tBl3EKDKUhuR9vljAjfRlXXulotTYw3/7X+oxnqkGfo \
PRmGV5Eif9wsP7rbwmshHODDHVf/DcAcE+hdEYrypNqW+hbPcJYasTf5zipZL4rYYURhBsfKaZtxsyznW07g==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    7 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec-ok.acei.ca. 	IN	DS

ANSWER SECTION:
dnssec-ok.acei.ca. 	21599	IN	DS	55341 7 1 CBA26CFA50ACBAE0D527AA9AC2102412FD35E901
dnssec-ok.acei.ca. 	21599	IN	RRSIG	DS 5 3 86400 1589688108 1592280360 40578 acei.ca. \
aXulEnlXmI2gp92ISjDEjIDP7ulJXER8H0+KPzLvLJMwKVbjaPqi1ZifCyWeman9lE95n4ETnR2SL+wP2/cdU0 \
TDyC8lZbjV4qZ07dgxa5xpVdKvr8lhacmOjcfT4rc6SVH1STttTKlF6uHwm0uWYQwk7mRTUqtZ+BPmo2iaCw4=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    8 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
dnssec-ok.acei.ca. 	IN	DNSKEY

ANSWER SECTION:
dnssec-ok.acei.ca. 	3599	IN	DNSKEY	256 3 7 \
AwEAAZZyCNN1zOT+2h6VCti+svTIZuwJgE655iwtxfj4aZQsCEXoBDBJ7ROHG72aty8Dk1N2JPRUIzV5GkOdr+ \
ZUVzOQwBvuCHTYvr11fNH5fiTmQZsZiMAK7ukjtWcaIZh0FHSV7RN2miCMSvCXmujMUE3Z5ksvtZoUhlyUqdXL \
YZVsog6QyHdfI//79acLo8hT2zPm33W0PAw7O7wpglXqQIxAWDmVTTZgSaXAC5HxO6cZVmIRSAQNp5cGKWekgq \
18Y9Tyci2+rwj7zQ69NOVqqAtuKuGzrKGds41nW+QzuP2AeXhnHdmFtZUHR0U948AGEct9cEw7fEmDfy9iQglipHk=
 dnssec-ok.acei.ca. 	3599	IN	DNSKEY	257 3 7 
dnssec-ok.acei.ca. 	3599	IN	RRSIG	DNSKEY 7 3 3600 1588468175 1591062839 55341 \
dnssec-ok.acei.ca.  dnssec-ok.acei.ca. 	3599	IN	RRSIG	DNSKEY 7 3 3600 1588468175 \
1591062839 58628 dnssec-ok.acei.ca. \
hTFLN9K/J0jq3Et9I1cV6zs6bsUxrc6WZhxMm7aaAIo2BBWIAFlvltekp3K/dMQu/f71DHI3TNasTlMbhuYgBo \
Ddw/w/30jsZkbrJKZgA1rCCVQv5nuwQcXZaBWkKCFCs5i1cS3JXU/KtgCdSZN2g3WdKs1T33Aces/hXJ/pUCKS \
Y7Rn4aGcZe9hxnPU6vgSZjB2t/KPBeHKfvgLxbiARz9jE5U57KvUafCB92pxrOPVhNNMABG3Rnt9xfeFBKtGm6 \
gzeA/AbQkla7+q/FJeEVf1vi8hUl04HSyGHoUNTYBhE08dM0eLA33S4b5uq3YrigEKDzye35SaqcI5F75eCQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    9 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DS

ANSWER SECTION:
com.       	64329	IN	DS	30909 8 2 \
E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CFC41A5766 com.       \
64329	IN	RRSIG	DS 8 1 86400 1590206400 1591333200 48903 . \
sM9w5bxXzXYLvjkjjlBQ6D6KE1R69DPjnP4gnfywkB9IXJpy0DVx4qDZr0ac1MQzvLal3RXSar+QFDJT9jx3Qo \
078zH18n+jozkfvptgpCd5mcxD4zRD+7U7AnbdxUHJJl1rx84mRJ8D71yWSl2FbK7szksZafM918ztLZwiyRd3 \
BKG6jLPVbAoKbPVfFxp4KPM1COL/v3gHr+MTqk0JTR1KalSn+SEi7198gwnpSKtqRDj/s8clL9w1mRgaYIL3H3 \
znCk5+RJTx/lJADfqA0QUt4bCufXAf4dxelNtgFy+g8+MWanFJSdGjk3W+NLv54h6D6oDy2xvjbf3mnNp5mw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   10 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
com.       	IN	DNSKEY

ANSWER SECTION:
com.       	13120	IN	DNSKEY	256 3 8 \
AwEAAbbFc1fjkBCSycht7ah9eeRaltnLDK2sVyoxkjC6zBzm/5SGgfDG/H6XEupT7ctgCvnqexainTIfa8nnBY \
COtAec7Gd1vb6E/3SXkgiDaMUJXmdt8E7obtVZqjFlN2QNnTljfMiECn16rZXlvXIi255T1wFkWtp5+LUCiufsLTeKc9xbQw7y0ucsR+GKz4yEStbYi98fnB5nOzzWhRUclf0=
 com.       	13120	IN	DNSKEY	257 3 8 \
AQPDzldNmMvZFX4NcNJ0uEnKDg7tmv/F3MyQR0lpBmVcNcsIszxNFxsBfKNW9JYCYqpik8366LE7VbIcNRzfp2 \
h9OO8HRl+H+E08zauK8k7evWEmu/6od+2boggPoiEfGNyvNPaSI7FOIroDsnw/taggzHRX1Z7SOiOiPWPNIwSU \
yWOZ79VmcQ1GLkC6NlYvG3HwYmynQv6oFwGv/KELSw7ZSdrbTQ0HXvZbqMUI7BaMskmvgm1G7oKZ1YiF7O9ioV \
Nc0+7ASbqmZN7Z98EGU/Qh2K/BgUe8Hs0XVcdPKrtyYnoQHd2ynKPcMMlTEih2/2HDHjRPJ2aywIpKNnv4oPo/
 com.       	13120	IN	RRSIG	DNSKEY 8 1 86400 1589566761 1590863061 30909 com. \
IKcaOJ1jlUldqs47sGOiYfe7XmbOpKjA8Dc0lg8dHbregnv0KVCgYvO48jCfsS+YbHeC9KrWjPY6cBdrOLY4GU \
v3vEhZE+yVBo1s0zEFYK6F9+AL6wI+UajXwYSMxh2F0kVB1V8APRlyfyZ0LXNUxiTo0H1Ob8AatWOpFeVJzHY/ \
ZHwX1tEURj0O3ZhVVOZuUVMZryRCuYKL4X7k1DFavrAyjtIETZHsW9mj65qFbMIZkgoyqOAqC3lHs7k6e/leJ8 \
4qrXV8Mq2w6Z7cf417SBzpg/hLNXN5gdPvy9Obai8R6GEADdBmdVhecybo2k3EfodklKiIZpZe7D6rwgVVcQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==   11 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 62354
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
elasticbeanstalk.com. 	IN	DS

AUTHORITY SECTION:
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	21519	IN	NSEC3	1 1 0  \
CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM \
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 	21519	IN	RRSIG	NSEC3 8 2 86400 1590118683 \
1590727683 39844 com. \
NArL30b9Vy8GobUMocYC399NaMB4oqLbana/HTaTIz4lKkLRtFM6iuBewn3CXtCuBCZ3VfV6q0K4jvi2+su+bt \
kuGZo+Ds+9ktZo2snOzdiuqFOdalMkzpNbVUyEuiJDsFRYPpueKaWNLPv1ceo+/C20hzxUUJ0UDBCLo/RX85dLAiVl1OA8O2FPidsDyXnoCxT1vJaySfDnNkLUCqDohA==
 com.       	819	IN	SOA	a.gtld-servers.net. nstld.verisign-grs.com. 1590327148 1800 \
900 604800 86400 com.       	819	IN	RRSIG	SOA 8 1 900 1590322948 1590931948 39844 \
com. ovUHrCt3UvC8aZyIC4oi+xSta7/E4oWGQYJ7ZTKTUfUDsqB4TPahnS93uWWrL/vLErldWzhM6gxS/DB/7 \
0lfHVsxTX5Sm8VX7F2PshtoVS3WG8G11CIvLy81h9GuuZpR2ZqVHWMKyTyt73fLqxJNgpB2dKFaOJR89LXMz6nlgaEQ8C7UuUDAF4nYltLtpcbkJ4r7+sm5qT/CCFEGjSKILA==
 8FL8ACCB7QGAJ6Q4Q4HHDH1G2C1FEQ6G.com. 	21519	IN	NSEC3	1 1 0  \
8FLAB747GTO10MQV1MGB252GK63UAF3S NS DS RRSIG 8FL8ACCB7QGAJ6Q4Q4HHDH1G2C1FEQ6G.com. \
21519	IN	RRSIG	NSEC3 8 2 86400 1590290526 1590899526 39844 com. \
UOSpB/Py6JyjNpl9jHLxp5wskEQqo91g5eVPqqnIzSObTEIFf213/noUU6kisdeKeXNMnobs96+QymKTLPqM9g \
yL3NnrS6tsTr0kQAPU4orEZI48JdtR8xfTZl5KhS3MOoVGuKi8B3PwXk4rfl9mhiF4tO80e4PtBwR5oAVT9uYaC68mpwQPhiH6pu5RVCLzt3t7NtuZ5vOffS3S/uUzQg==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


www.dnssec-ok.acei.ca. has: 8405 bytes


["www.norid.no.txt" (www.norid.no.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
www.norid.no. 	IN	A

ANSWER SECTION:
www.norid.no. 	596	IN	CNAME	norid.no.
www.norid.no. 	596	IN	RRSIG	CNAME 8 3 600 1590134478 1591976998 63601 norid.no. \
U0xPLc7QT4GODjyyKaF+QrH/Iwsj3CDLFntRfEinHx86QcufDBpDqep4L8BjmrCMGX6HSJfI7VrlAmeAyXB0U+ \
hotcnCMCDDAel1dOL5t4YfVuP27jSJpQcoyNELitofYkuGnpYn3TFlz9DKNLIw3Npp3oo2fDZtmRLOBgigjwANMIgAE2VSf+WMSmzyHZZ507lYTrKh/ZVy6ibVmn4yTw==
 norid.no.  	596	IN	A	158.38.212.207
norid.no.  	596	IN	RRSIG	A 8 2 600 1590206479 1592017533 63601 norid.no. \
bDX9wW5voVBR4csrz1oy8eqQGWoHvt6HBF2q//OFsVAA/rarEWJ4RdLBXibX/hr42/l9RnBHhO9mXRzFYWWcvK \
tJDDJUOB46fwZ/BzsFKlqRaipfVVBMu8Z3lYAAelrsHT1csMvTVmIYfrQkRmV6FRaiOrOHIvq8yQHX7DptUEzyNAqcGEYiZXjamU1HsFHMvcscvwYZDEteqgn3ZVpzxw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	4024	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	4024	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	4024	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
no.        	IN	DS

ANSWER SECTION:
no.        	86121	IN	DS	29471 8 2 \
915EDE46EA5324FF86B11C9ED4E9C814AE8C462C165E5380A3999D90418841DA no.        \
86121	IN	RRSIG	DS 8 1 86400 1590292800 1591419600 48903 . \
FN6btumNdfD0IUR1lx4IriaolsdvCdyLd4LnuotJCAPDZBzgU9psWGKg+Fg6PpCQE2cc7Xcos6iZDplGrOMFQd \
JGhUTCkQ+4qBVmHvm88X4u4wEvDh5l1/9NTGO+XM48J8FRixRQFeMnA8bl+AoM/d+7zL9Z6bB+uUPdCFA/d8Kr \
u5gkZb8kfdlp7GMvZ+umzot2PNSnlKGqG28NVaQqzJ3JjMBPtqzAP/Ldjtx7VZoRBO0qW8QciI7wZoZF0ftnxU \
lCkvbVXIiJHr2I4jZbkM/wDp+UlGNq5sMBKWOWXwX31gswZIw12srn6itl3cNrQQrmtZVeGo+x+Y6LOzV/aw==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
no.        	IN	DNSKEY

ANSWER SECTION:
no.        	1593	IN	DNSKEY	257 3 8 \
AwEAAZ/4Gp4JK9sYmX+LXKB8VpudlotL7/534h85e2QXzrgfFTP+5odzXGo4BaIpu2FgH64o/TiDtyVoRxcMEQ \
qj7DouY/as/0OMWd3wVIzGTNdX62WzTgVpZe9tjDPbBb6NO5dNUwMpHfM0g+RuM+v4KSH2Rj+kwCJoh34loFbE \
3+M8YmlTlrJiqJINE6XLw7PDIUpV+uM/qanoxBqHwRKfrRgQUH3v6zIliDZj7VuCTACU77Fu8+v8L1C7Epz5HD \
a+wHa8RMSvNQA9HJwFwZE3pzWIVDV34CWVyua63wtdof9e29gjhbkKqVMuQCdz49XmqhQQ0gYzYOGMZTnY/pskTVs=
 no.        	1593	IN	DNSKEY	256 3 8 \
AwEAAeO4tN2O6OwWqW1Rhy5IjzWorLlZSa8Y/ldX9cv5u+kjaDPVrb9AMYBCzhSVdOKOADXtnqTXrrCtElvflc \
bdqLyAqBGT96HkndpJ1wOA+grkJTw4Wbe9DArc3FH584/84MzutvxwtidyEM9tgTbhyBMfyjTwGCeqsVJj7wLA/t2v
 no.        	1593	IN	DNSKEY	256 3 8 \
AwEAAdetlgckYhMxuUiCZwp+6Nw0OwLCkng6EtCqU88m23zlO9mIMIcNyYdZWa4pmlMG9+zVeDg+gxAlN3m5of \
MGQ0O9VhQ0JAw14dTjC5mDZf5gE+C6FVkRFHBk7604WK39yoRIMJPx+glnOBTX6OJWc4QG4xs/Mu9qmuVXcmqHC5E9
 no.        	1593	IN	RRSIG	DNSKEY 8 1 3600 1590058971 1591247040 29471 no. \
gAMx/aijF37ZDm3WwJWLHG/Z0HpT6J0vT4rkqNcsSRh5o3scP3uW2Cp3Q+UyPgj8WEyjv0wyfNF4KWlXrXGPRD \
duZP/f78zqPMMFOfd81xzwTah+5mEGz/eUyaLpWHHjY0ZVNS595dxRtOYWfhR1WM6HCutWmEF1wHw8T9n6qUeD \
SiCiZ1qx9F9rwhT1BvjN5xVePl9IXoJCRW0vJ4FHCjOAHOj3bl5icM+hzbtbI5Sc7ZTJOvVqE4nhzaWyWJ8IsP \
WVdm3/Q4eQoDdoP8cUnNxQMklbY9vHaYqbn9ToAJpFOG5R+Sac/bUYDFEa3p/RHHBKZ6vE+bfJWo32eASwQA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
norid.no.  	IN	DS

ANSWER SECTION:
norid.no.  	7196	IN	DS	21199 8 2 \
C3E70A8AFA14231F639CEEDCC388870F677CF7127ED68703FE5B7DAAAF7FEE35 norid.no.  \
7196	IN	DS	21610 8 2 D0D4376641923DFC98E5855A423A04587680C2B4331EE9910D5C0606E0B0770B \
norid.no.  	7196	IN	DS	50212 8 2 \
555CD4DA5203E4D74A1C94E3433502EC9D8D4A09A28E6A85F47ADE020137F423 norid.no.  \
7196	IN	RRSIG	DS 8 2 7200 1590166983 1591356764 46921 no. \
hDBkx1WBixZ1FtowISF3cbyuzUpIXd+JS20sHDnaWO3Bl0QJHdj6zxnbVaXc7RU7aWCEtMVLX3XZlf5w4PkuHn \
OlEqddIy1mvcDPgt2d/A/g4rt7CD52qw9qmjZFdXxK9zGzcMAtThvJLmicqK5lspYKlz9UovSk5MYCYzv/VH0=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
norid.no.  	IN	DNSKEY

ANSWER SECTION:
norid.no.  	3275	IN	DNSKEY	256 3 8 \
AwEAAdSXZey46pKtjIF+L4pN/34c/ZJwNRCKA0z0p0Z8Q+q3bVwYdX6ThMtfBsoMnNnHidi7IRf3Yumy3tK5iz \
bnjzi2sS2fBTCBCEsxgDF3aqapVwFD3L/NEstknw2esZ7FebcFfm5M1Hxy2LnfkBXefghtecP974/4qVod8B/f0szzhTs1Nc1QR2GoO0D8+gIlr4/gZr4P3iKS1YOktt91W80=
 norid.no.  	3275	IN	DNSKEY	256 3 8 \
AwEAAfFjiVQCbBnYcamUw2t03SNSA6cnbiZBxoMTMUX3tgCvqXgbIidFMeSVKUusWY5YBeE8vqcA3W/UIHIaIs \
qyavMxS4SIalHL0aw7aA+bVP0fg0dsvugwMEXzyo5xyYjLGTRqaniz5H2uF5ptWmi7sFAEbsy2EUnKN2rtFRGxuDbEhAtHvpbGGUCDWBx4yr9K5IGT/1fq2Loz7UghLZAzhC8=
 norid.no.  	3275	IN	DNSKEY	257 3 8 \
AwEAAcRfXwrItJhh9Js/9/7PpG1WCXlj9G4UVhZ40VYrjVhgmVszinXWrsDs9RRHtVWr4u/LFoiGUoSi/P+fIM \
ZeiQTvFi6I8B5hBTOvcwb5uaqizLQUuy6OpRJGS4LmiLB9kvqtEcjbZwwQOhRQtCiAmu0GPJrGNZwPVI7OLSpd \
EsJQK9oUYENslD+q1OAiQ0zCjEcoKmeB82MFpdgR429BJTAEcgb3fYQl7Y+tAnvZtFO7tG9V848QoX2Hk04Lfe \
ZoaNwQQyqDZhZq9e1k10YtmkqtZQjPUnoJaR9W7ZoH6KEuM29xAfsUoesnv6fYz1JQXBowjoOVO+jN1ICxfeyA43U=
 norid.no.  	3275	IN	RRSIG	DNSKEY 8 2 3600 1589983278 1591768341 21610 norid.no. \
SadxAicH1vNP2nypfciNgFrXDR7SI4fBUbkWg6ICPqO3Ot7J6dicXWdDTblQFrjDxIdXYzzKwZGG5riCamaFxK \
aopLmkLFcTQ7YtFpYJLUWM+tj/b0mTWUrGQYGprEETDONk2vX0teBS5o8nkxXAK+Bd/RO1T1yUqxoSD/6UghKz \
HG2bIWdp1bo1yD3uY2Ww618H587P7IsHofJhoLJmLXiKvKB78ROvfs8gvFh9oRWiS5lJKDpsxOEU3/hVl6+h6j \
mzSGFdkXnDjZYEMUHjJYkNbusy03x3iCCvU45swr7IXzyz+46+t7z/tzwlK9cPu33K8upkFtcU10u9kT8wZA==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


www.norid.no. has: 4042 bytes


["www.torproject.org.txt" (www.torproject.org.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
www.torproject.org. 	IN	A

ANSWER SECTION:
www.torproject.org. 	147	IN	A	116.202.120.165
www.torproject.org. 	147	IN	A	95.216.163.36
www.torproject.org. 	147	IN	A	116.202.120.166
www.torproject.org. 	147	IN	RRSIG	A 8 3 150 1589965214 1593424814 11010 \
torproject.org. Z1fY+ULB+GYszyd+LUZMBBZYXSEs6AyT2rlDdjDii/gbNVGb5IrqwQXiMYgW0ZrHWo2vb4 \
dpaISoCGcTOfVmiYQQsrkGh0GIlbuCbMH9AsS369/hJ3hsMA0ovIpqnfxAcxFog5KCk1m9d3NCZO5he8gCu2Q0 \
K9o3aCTy1VveG7KFBg4U7WQCwRckQr+15eyaV+b+dmQvE0iv8Pm+B3xdSljsvsJrNSXr4wrccKAYLRgYtxf6czE7SJb5v5kNafXp


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	69319	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	69319	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	69319	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DS

ANSWER SECTION:
org.       	85531	IN	DS	17883 7 1 38C5CF93B369C7557E0515FAAA57060F1BFB12C1
org.       	85531	IN	DS	17883 7 2 \
D889CAD790F01979E860D6627B58F85AB554E0E491FE06515F35548D1EB4E6EE org.       \
85531	IN	RRSIG	DS 8 1 86400 1590206400 1591333200 48903 . \
q9+B0SUBiBvJosdeI75W9L6c0fGf4m8rgijDSogPJPHD0bjUQ3PZVRmwwAY42KOkcPNfHwCJvr5hzYBvPww4XA \
zjEfvS7r3ZlIEo3/HyJ++tLn4w3dv/A+tNiJ2WhZBiw6MbwZaKhJF4MxBuBv02dWDZQ/lwnjNA8cSAsQL9hiLy \
RFADv6/oVAkP1MQ2L3LXyMiazTO5JZ1HueDPqKv4n5Mwd3zUs/+nuwYLq0/EjNrr0fH/9x0PzkyAEz8d8gqeAS \
J0CPIHyjhZkGJMRpzTe2p/iPbwGZO9hGoy7Jsr8EpvSzf2XU9DxtkQYqLh0FR36ZuGhfeEI/idw89oToDyOQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DNSKEY

ANSWER SECTION:
org.       	165	IN	DNSKEY	256 3 7 \
AwEAAeDsADaJg3/dnppzytgK+V0cnEE89Uhn4X5CihDr1g4Xe/CawmO3vSLURrMr9n7XbBUf7Fu26z8TyHcMrB \
IwwigQz891VPQNZc5spPOsQcz43KGQVmbl0agf2TJFZihBGsuG895Q9kzJ1ls7TRpTXQYtzrdkJUxy+3xQzbNrYsIX
 org.       	165	IN	DNSKEY	257 3 7 \
AwEAAcMnWBKLuvG/LwnPVykcmpvnntwxfshHlHRhlY0F3oz8AMcuF8gw9McCw+BoC2YxWaiTpNPuxjSNhUlBtc \
Jmcdkz3/r7PIn0oDf14ept1Y9pdPh8SbIBIWx50ZPfVRlj8oQXv2Y6yKiQik7bi3MT37zMRU2kw2oy3cgrsGAz \
GN4s/C6SFYon5N1Q2O4hGDbeOq538kATOy0GFELjuauV9guX/431msYu4Rgb5lLuQ3Mx5FSIxXpI/RaAn2mhM4 \
nEZ/5IeRPKZVGydcuLBS8GZlxW4qbb8MgRZ8bwMg0pqWRHmhirGmJIt3UuzvN1pSFBfX7ysI9PPhSnwXCNDXk0kk0=
 org.       	165	IN	DNSKEY	256 3 7 \
AwEAAdmwceOWXmoXZj0PLI0LWOWz47/nqFoSesfbthZe0hmVsiHt9ywWE/4sHe6XGjlqwEzzH165ara2hKnbl8 \
FoaLf9+YV0RlmUojZlOM0WAqL8dtMj9cz663+HHrI0f1oJ6dWweED4XRBJ55j4Tks7yZTNdgCDJj09K3vercPicxN/
 org.       	165	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 27074 org. \
oHbegLUfWC6zJEMAtwP5upbHR6/nuY7GJKNbVsU67smder8Pfnl01ybM8rGuw3FHZmnBbRXOIcbHrjj1oJk7pp \
r+7d2v78CGE7OxcYl1GOwPEe8tg4529k84vhxlb+tHXKrAVMmYi/0MQYr9ZzJ/o0NLsbMwtYCKiMtPCmk2nV8=
 org.       	165	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 17883 org. \
B9XZ9LyfU2Ua56OSjNEWt6V4itluZdt/v9dY1TBTZRkRS4MSTYBowHW9QsLdiS3MUOK0B0fQZftWftV8AV3XPQ \
NF+R4RebqwiX/W7kYpn4L+6zDgaYOD8GkiJmyomFXqO4cf6fsYVgAU+0XluCwIwHjarIQA6yRZRhTIN9mT4AlR \
0vwo5csAA6rhRrzeA20Z70OQoQnDF2crT/3q29Ki0yXLIODN9kcjJOB881XxdD9jtSB6L3aUNSjAiKG9NO5qUc \
4cBuErEqlqsURZqXBggeLE/S/hxp/voSvRp/vKEgzQ+A7nF6d4P9G9bcjjITmeqih2/DE6NqP/hXaotv1I3Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
torproject.org. 	IN	DS

ANSWER SECTION:
torproject.org. 	86396	IN	DS	28486 8 2 \
CEFD14514B18D5E31073BC9EA463C7852DE236742E23A4AB327E446C608A76B9 torproject.org. \
86396	IN	RRSIG	DS 7 2 86400 1589984588 1591802588 27074 org. \
ZR2eHsVGbgr1ixlxTc0FUdg9L7X+hqbNjtv+F7jxngLo2AvKnmGcRh51gnZ+3f5VBy37hmrtFk5+1bkRF0+ctD \
eN4SkwY2LJ6HWxEs4oCuEe6JnDr+G6tOdRKHl0Wjlgkl0p+YD/KgyduYCJtP+RzlLbohsYxNo+zf1+JHez+aE=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33602
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
torproject.org. 	IN	DNSKEY

ANSWER SECTION:
torproject.org. 	3596	IN	DNSKEY	256 3 8 \
AwEAAbW5NRxHGt6jjbqIrUFVcTrYHlgPHS/5XqwXds1NykyNf/DvzXkdncdOGVU1y6Ru6pV/FD1gPFr7iTDNf6 \
c5GRcSCjiO8VxfKrgMlAhHpr0So48o+ocJQaBo2glKdQC3TO3gjBybLzTnjryDQG/iIwHgWXE10N7wuvJoFHGn \
dukW6s452WS6Drt92o8krCCLG1yZmixh/JvF3IvTEkLjVkFMcG0hq5/U4kU0j65Le0ld4mXlv3YoMuN6SjwfG9xD3w==
 torproject.org. 	3596	IN	DNSKEY	257 3 8 \
AwEAAZxjIEY/UmZCWkdQvIY1BokdVQ/wLamwG9xi0fGCwM+FLZTQ2sFh24GtpF77GxHGohnnS1Uzx+H8uCAfVC \
Sq+nnOWRMeCEIriKKqLoXbe8htPu/8jUCe+6l/+ROOnCmfq0Xi2IbZCIB5mRP09cho2RcEJYa3cVSkeT4mbEdA \
S8Xnlk3Z/rvLy5NKV8hZE27BB6+1iwarHyb4dNxw2aR//WZQnxlq21t6iEec5ZjstHZ5+F0bAZzAK/iHuMh1hd \
dD4zQvEuqWG//NZpjUc5S1sYmpQFPNPq21hu+Lyyfty32Je0t7kxA6+dI2S0yRdt2TWnB8bFtB5H3k53056XugBj8=
 torproject.org. 	3596	IN	DNSKEY	256 3 8 \
AwEAAdf6/d52u6+vYDlN8v756FQlLeHoaVaFFOmyL6s5iDZvgxkmgNk7hvP4qP6rbbGUbE0pdWHLdFxjNjR8pq \
uEl97+hW6FosSz4OS3hDfApFzgu931/mX4NEc3npY6tmUm2Xf0BRK0fSvZvL6ChKdVvBEX7i1BYTqLYEB+fI68 \
CZAQiZaM8+oCWr9NJ4ygN0JHBr+3x3mm0GRlDo20UDAMIsUhEhxIQ5qw6NnW4Iy9PaYZVVf3HTyZp9CLAdz6qZPFtw==
 torproject.org. 	3596	IN	RRSIG	DNSKEY 8 2 3600 1589906411 1593366011 11010 \
torproject.org. dfBKddp6qqaARbbnHBY/YcwSv39UuljDb8I6dk7Sxfq2Mml8V/SXbWIqtFWVlf4leY8QFy \
sC/E2upDdQi0T7DrB2G4AJzUl+4GLp6tYg5g2X+HbtGG6wSm8W5iBY9M6wwgiXCFACnmO+7pIGriFR7gI+T3C8 \
Ah/vsbkBm219FsgwM1ns075w+JsAJb0W1Ub7wJuh4h5h8ydBu9RndAesDGNML3BY/RzngttnFIeJcpX6UAIQlJIZ1MzgBQKAZX1z
 torproject.org. 	3596	IN	RRSIG	DNSKEY 8 2 3600 1589906411 1593366011 28486 \
torproject.org. mGxlGZL9Smq0wqNWM43sdPDsEy/GRuDIQ4v9smfI5JUoekG6pfJO3OFVvmImfoe40/IwW8 \
bd00en1PGrGCh5HFjcP4Snk9hL3qWIQPbHzTwEeJvSLMmAiEktaRjFRR7t31p9d9XIRrMeNEYhKqFkvhcnlwxsdp43DdS9r+Teygr



www.torproject.org. has: 4401 bytes


["www.wikipedia.org.txt" (www.wikipedia.org.txt)]

==    1 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
www.wikipedia.org. 	IN	A

ANSWER SECTION:
www.wikipedia.org. 	86400	IN	CNAME	dyna.wikimedia.org.
dyna.wikimedia.org. 	600	IN	A	91.198.174.192

ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    2 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
.          	IN	DNSKEY

ANSWER SECTION:
.          	76941	IN	DNSKEY	256 3 8 \
AwEAAc4qsciJ5MdMUIu4n/pSTsSiU9OCyAanPTe5TcMX4v1hxhpFwiTGQUv3BXT6IAO4litrZKTUaj4vitqHW1 \
+RQsHn3k/gSvt7FwyQwpy0mEnShBgr6RQiGtlBODNY67sTl+W8M/b6SLTAaaDri3BO5u6wrDs149rMELJAdoVB \
jmXW+zRH3kZzh3lwyTZsYtk7L+3DYbTiiHq+sRB4F9XoBPAz5Psv4q4EiPq07nW3acbW84zTz3CyQUmQkJT9VB \
1oUKHz6sNoyccqzcMX4q1GHAYpQ7FAXlKMxidoN1Ay5DWANgTmgJXzKhcI2nIZoq1x3yq4814O1LQd9QP68gI37+0=
                
.          	76941	IN	DNSKEY	257 3 8 \
AwEAAaz/tAm8yTn4Mfeh5eyI96WSVexTBAvkMgJzkKTOiW1vkIbzxeF3+/4RgWOq7HrxRixHlFlExOLAJr5emL \
vN7SWXgnLh4+B5xQlNVz8Og8kvArMtNROxVQuCaSnIDdD5LKyWbRd2n9WGe2R8PzgCmr3EgVLrjyBxWezF0jLH \
wVN8efS3rCj/EWgvIWgb9tarpVUDK/b58Da+sqqls3eNbuv7pr+eoZG+SrDK6nWeL3c6H5Apxz7LjVc1uTIdsI \
XxuOLYA4/ilBmSVIzuDWfdRUfhHdY6+cn8HFRm+2hM8AnXGXws9555KrUB5qihylGa8subX2Nn6UwNR1AkUTV74bU=
                
.          	76941	IN	RRSIG	DNSKEY 8 0 172800 1590019200 1591833600 20326 . \
KfazTUJ4/ezskruozpqOV/AKBcdoMVTxmLSjKaiZuNW6QVAY60/khxOa0g7EqH/yBZP9pKIIMrxWtRzfl2YzZh \
kRfkDJKsNFDpyRtq06Hhhf8KHgFNsmmdUBKVtC7jh/5pldrMpInmtrV6344PkDS499x0qfsziD/FQCwF/X8SWv \
fqKYmhvE8RjnlsycLtd1vao8iZtTDrevxPZCTRNwDfOufW5jNmDP0nRKg/U0rXVXxf5q9jVX3Q875Kzyp1eewI \
2fPBmBXX5Vcpb3We0GtcecKR0G0nsdXd898GiFlZU2IwrnemLWnCfE6LaoOcKcYzNO8dfMbI1hQzyIWtnb6Q==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    3 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DS

ANSWER SECTION:
org.       	44323	IN	DS	17883 7 1 38C5CF93B369C7557E0515FAAA57060F1BFB12C1
org.       	44323	IN	DS	17883 7 2 \
D889CAD790F01979E860D6627B58F85AB554E0E491FE06515F35548D1EB4E6EE org.       \
44323	IN	RRSIG	DS 8 1 86400 1590249600 1591376400 48903 . \
XZtxC/1f7UzboUAcmh7DZrUjBQghC2Zx/iOvpX8qPtpOM2fF1JJED5fDAPrrX0XNb+uAHhvwHTb3vp1qjidVqY \
KAneCKJx8iJtAYFQujN6rpdTVwdwM57CJ2PuKCfqFFVvR7AFK+9ozDPVjm+tVmRL6qAibKSZZcTmC/RYLbQrDM \
N5T3Cv2uC44QvxMXSSzBFNn9kMCkjFzkgExAZdNF8Vl9mICarAhQjIP+xDmEywmXH7JpBrAjXCocqQlYOUlfUc \
6miDHomlimwHu29lvqG69ICyFlt1jeEwWOD3KN/7T7hxMpjnNjZmMy3aZ8nhG4+5UNTeNQAIzoNyToBm9fwQ==


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    4 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra ad cd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1

QUESTION SECTION:
org.       	IN	DNSKEY

ANSWER SECTION:
org.       	861	IN	DNSKEY	256 3 7 \
AwEAAeDsADaJg3/dnppzytgK+V0cnEE89Uhn4X5CihDr1g4Xe/CawmO3vSLURrMr9n7XbBUf7Fu26z8TyHcMrB \
IwwigQz891VPQNZc5spPOsQcz43KGQVmbl0agf2TJFZihBGsuG895Q9kzJ1ls7TRpTXQYtzrdkJUxy+3xQzbNrYsIX
 org.       	861	IN	DNSKEY	256 3 7 \
AwEAAdmwceOWXmoXZj0PLI0LWOWz47/nqFoSesfbthZe0hmVsiHt9ywWE/4sHe6XGjlqwEzzH165ara2hKnbl8 \
FoaLf9+YV0RlmUojZlOM0WAqL8dtMj9cz663+HHrI0f1oJ6dWweED4XRBJ55j4Tks7yZTNdgCDJj09K3vercPicxN/
 org.       	861	IN	DNSKEY	257 3 7 \
AwEAAcMnWBKLuvG/LwnPVykcmpvnntwxfshHlHRhlY0F3oz8AMcuF8gw9McCw+BoC2YxWaiTpNPuxjSNhUlBtc \
Jmcdkz3/r7PIn0oDf14ept1Y9pdPh8SbIBIWx50ZPfVRlj8oQXv2Y6yKiQik7bi3MT37zMRU2kw2oy3cgrsGAz \
GN4s/C6SFYon5N1Q2O4hGDbeOq538kATOy0GFELjuauV9guX/431msYu4Rgb5lLuQ3Mx5FSIxXpI/RaAn2mhM4 \
nEZ/5IeRPKZVGydcuLBS8GZlxW4qbb8MgRZ8bwMg0pqWRHmhirGmJIt3UuzvN1pSFBfX7ysI9PPhSnwXCNDXk0kk0=
 org.       	861	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 17883 org. \
B9XZ9LyfU2Ua56OSjNEWt6V4itluZdt/v9dY1TBTZRkRS4MSTYBowHW9QsLdiS3MUOK0B0fQZftWftV8AV3XPQ \
NF+R4RebqwiX/W7kYpn4L+6zDgaYOD8GkiJmyomFXqO4cf6fsYVgAU+0XluCwIwHjarIQA6yRZRhTIN9mT4AlR \
0vwo5csAA6rhRrzeA20Z70OQoQnDF2crT/3q29Ki0yXLIODN9kcjJOB881XxdD9jtSB6L3aUNSjAiKG9NO5qUc \
4cBuErEqlqsURZqXBggeLE/S/hxp/voSvRp/vKEgzQ+A7nF6d4P9G9bcjjITmeqih2/DE6NqP/hXaotv1I3Q==
 org.       	861	IN	RRSIG	DNSKEY 7 1 900 1589984588 1591802588 27074 org. \
oHbegLUfWC6zJEMAtwP5upbHR6/nuY7GJKNbVsU67smder8Pfnl01ybM8rGuw3FHZmnBbRXOIcbHrjj1oJk7pp \
r+7d2v78CGE7OxcYl1GOwPEe8tg4529k84vhxlb+tHXKrAVMmYi/0MQYr9ZzJ/o0NLsbMwtYCKiMtPCmk2nV8=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    5 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
wikipedia.org. 	IN	DS

AUTHORITY SECTION:
h9p7u7tr2u91d0v0ljs9l1gidnp90u3h.org. 	86094	IN	NSEC3	1 1 1 D399EAAB \
H9PARR669T6U8O1GSG9E1LMITK4DEM0T NS SOA RRSIG DNSKEY NSEC3PARAM \
h9p7u7tr2u91d0v0ljs9l1gidnp90u3h.org. 	86094	IN	RRSIG	NSEC3 7 2 86400 1590325946 \
1592143946 27074 org. \
b/lo9YErgcl6DYY7odLzSUMGniMuOFKsto1gyTuCV7Vc5IbEj5x6rCyNe0rFbkyVG9xEpH0eVG41UbgDR13ULZ \
r7nXPsr8kIj319P5vYdk2wxL6tmJB8jqwlAC7qqN5svMARoTislCBwrTNgsynj5HfrAdeAO6XDB69B/mmnMJY=
 org.       	594	IN	SOA	a0.org.afilias-nst.info. noc.afilias-nst.info. 2013943857 \
1800 900 604800 86400 org.       	594	IN	RRSIG	SOA 7 1 900 1590325946 1592143946 \
27074 org. WoD0P1sBzvO9v/ZWooHNZqpHpmOSTlH0+7CbADKW9jVSNs2g/hePMovzNOCUKMeEhmYSRR2AdFd \
/fnSc59AE047n7wvWeuT7BuZJWiuxvCzvfBsDoWvJbyqoq/C8xQ9FrNJSUUp6vM7C0x3e+ebZIK9RYZxCn3V2YPw+qYTASGo=
 hhdqek1r7gh4cv2468sap8ko03nopcfk.org. 	26993	IN	NSEC3	1 1 1 D399EAAB \
HHE0NC4UIFC35N2P0P9ATBQP750QR2KT NS DS RRSIG hhdqek1r7gh4cv2468sap8ko03nopcfk.org. \
26993	IN	RRSIG	NSEC3 7 2 86400 1589984588 1591802588 27074 org. \
28GxyDt+7I2H49dYJ5/SbP6rh0BTC68Utoq1OOblXC/frf8243YFFCkwDBnYzP0oaXmpb0144Q0TzUjM9Emn+r \
x0R4cEZWd8ElR0WWbFyG9j9Itce+7tjK0EE9rdX8GDpopRU5SkRtQN03eN96A8tvRiopsLWL4U7w1IIe3I32o=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


==    6 ========================================================================

-&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63521
flags: qr rd ra cd; QUERY: 1, ANSWER: 0, AUTHORITY: 6, ADDITIONAL: 1

QUESTION SECTION:
wikimedia.org. 	IN	DS

AUTHORITY SECTION:
org.       	899	IN	SOA	a0.org.afilias-nst.info. noc.afilias-nst.info. 2013943862 1800 \
900 604800 86400 org.       	899	IN	RRSIG	SOA 7 1 900 1590326267 1592144267 27074 \
org. 0EfJCl5s9Fzmixu7wg0xErQ+GFG6fRLVkJNuspTI22HCjKGI0G7TCt9QlSaehXKf5MzVVx6pJSIArjAZO \
wb63cgAcf706SN7hvZ8QYHJSZQYmHajrxJWdXOrIjA1To1miGrF7J175zkBAFHn4N654bQy+kEhTh+xMZA/dRkde5U=
 h9p7u7tr2u91d0v0ljs9l1gidnp90u3h.org. 	81945	IN	NSEC3	1 1 1 D399EAAB \
H9PARR669T6U8O1GSG9E1LMITK4DEM0T NS SOA RRSIG DNSKEY NSEC3PARAM \
h9p7u7tr2u91d0v0ljs9l1gidnp90u3h.org. 	81945	IN	RRSIG	NSEC3 7 2 86400 1590321803 \
1592139803 27074 org. \
f9fnGZ4lpUyFkdjquEbELfGJqYb9QUwUaHiVeRUTgAgtnSI5l8r+BQQoqHeMkN76YyOR8urBJh1vsRvpoflFiB \
WKAR4uuoHoHTOCTvbxM0dTC44q9uWdfBC7KXTdIbkKotLCzungV1V5f4MpECK0YqynAu45FFLC2dCAeu1E/nk=
 b2e2i5kgb5mnfkm7kaerfs528tlsshce.org. 	9389	IN	NSEC3	1 1 1 D399EAAB \
B2ECME04JE5RO85GPLJGTVQAM2GA937Q NS DS RRSIG b2e2i5kgb5mnfkm7kaerfs528tlsshce.org. \
9389	IN	RRSIG	NSEC3 7 2 86400 1589984588 1591802588 27074 org. \
g/MNRc3Kd06NH+aJ51XMkvHWSrEwKT69CXSomRBY0nu3NRXJAxg+dfH7J4RXFb880bAdFgLiwVif1TmHIPm4Iw \
e7UKTuP+b1CeLIMMBYfXq74GLsRkplHG2JuDMedg0RsX01jAVu9Q9ezHZ0yn+CfAk0Qaw8VNh9HQfklJxlEL0=


ADDITIONAL SECTION:
.          	32768	UNKNOWN (0)	OPT	


www.wikipedia.org. has: 4212 bytes



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200524170119</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-24 17:01:19-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Christian Hofer:
&gt; On Sat, 2020-05-16 at 01:37 +0200, nusenu wrote:
&gt; &gt; Alexander Fry:
&gt; &gt; &gt; I wonder if it would make more sense to have an onion-aware
&gt; &gt; &gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a way
&gt; &gt; &gt; for
&gt; &gt; &gt; Tor to query an external tool for DNS lookups. 
&gt; &gt; 
&gt; &gt; I'm also in favor of this approach,
&gt; &gt; and you can do this today with no code changes to tor at all.
&gt; &gt; 
&gt; &gt; CF demonstrated it even before DoH/RFC8484 was finalized:
&gt; &gt; https://blog.cloudflare.com/welcome-hidden-resolver/
&gt; &gt; 
&gt; 
&gt; Do you have DNSSEC validation in this approach? 

That is up to you. If you use a stub resolver that has DNSSEC support (like 
stubby) you have DNSSEC validation.


&gt; &gt; + 1 for DoT and DoH over tor, especially due to the DoH
&gt; &gt; implementation that is
&gt; &gt; available in firefox (it would still require work on stream isolation
&gt; &gt; and caching
&gt; &gt; risks to ensure the usual first party isolation).
&gt; &gt; In terms of achieving a big improvement on tor browser users in the
&gt; &gt; context of DNS
&gt; &gt; this would be the most effective path to spend coding resources on in
&gt; &gt; my opinion.
&gt; &gt; 
&gt; &gt; 
&gt; 
&gt; It seems that Firefox's DoH implementation does not employ DNSSEC
&gt; validation, see [2]. They trust CF doing it for them. Be careful here.

I'm aware that firefox does not perform DNSSEC validation. I don't think
the tor project would enable DNSSEC in Tor Browser without a good use-case or a \
(future) TLS extensions solving the latency issue. Since DANE for HTTPS does not \
appear to be a thing and there is no DANE support in firefox I'm also wondering about \
the specific use-cases for DNSSEC in Tor Browser.

&gt; Furthermore, there are privacy concerns about additional metadata
&gt; regarding the use of DoH (agent headers,

solved since https://bugzilla.mozilla.org/show_bug.cgi?id=1543201

&gt; language settings, 

solved since https://bugzilla.mozilla.org/show_bug.cgi?id=1544724

&gt; and cookies) 

I don't think firefox sends cookies in DoH requests.


I'm still curious about the underlying threat model and use-cases (my first questions \
in this thread),  since that would help with trying to understand what you are trying \
to achieve.

kind regards,
nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200525164503</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-05-25 16:45:03-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Sun, 2020-05-24 at 19:01 +0200, nusenu wrote:
&gt; Christian Hofer:
&gt; &gt; On Sat, 2020-05-16 at 01:37 +0200, nusenu wrote:
&gt; &gt; &gt; Alexander Fry:
&gt; &gt; &gt; &gt; I wonder if it would make more sense to have an onion-aware
&gt; &gt; &gt; &gt; DNSSEC-enabled resolver *outside* of the Tor binary and have a
&gt; &gt; &gt; &gt; way
&gt; &gt; &gt; &gt; for
&gt; &gt; &gt; &gt; Tor to query an external tool for DNS lookups. 
&gt; &gt; &gt; 
&gt; &gt; &gt; I'm also in favor of this approach,
&gt; &gt; &gt; and you can do this today with no code changes to tor at all.
&gt; &gt; &gt; 
&gt; &gt; &gt; CF demonstrated it even before DoH/RFC8484 was finalized:
&gt; &gt; &gt; https://blog.cloudflare.com/welcome-hidden-resolver/
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; Do you have DNSSEC validation in this approach? 
&gt; 
&gt; That is up to you. If you use a stub resolver that has DNSSEC support
&gt; (like 
&gt; stubby) you have DNSSEC validation.
&gt; 
&gt; 
&gt; &gt; &gt; + 1 for DoT and DoH over tor, especially due to the DoH
&gt; &gt; &gt; implementation that is
&gt; &gt; &gt; available in firefox (it would still require work on stream
&gt; &gt; &gt; isolation
&gt; &gt; &gt; and caching
&gt; &gt; &gt; risks to ensure the usual first party isolation).
&gt; &gt; &gt; In terms of achieving a big improvement on tor browser users in
&gt; &gt; &gt; the
&gt; &gt; &gt; context of DNS
&gt; &gt; &gt; this would be the most effective path to spend coding resources
&gt; &gt; &gt; on in
&gt; &gt; &gt; my opinion.
&gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; It seems that Firefox's DoH implementation does not employ DNSSEC
&gt; &gt; validation, see [2]. They trust CF doing it for them. Be careful
&gt; &gt; here.
&gt; 
&gt; I'm aware that firefox does not perform DNSSEC validation. I don't
&gt; think
&gt; the tor project would enable DNSSEC in Tor Browser without a good
&gt; use-case or a (future) TLS extensions solving
&gt; the latency issue. Since DANE for HTTPS does not appear to be a thing
&gt; and there is no DANE support in firefox
&gt; I'm also wondering about the specific use-cases for DNSSEC in Tor
&gt; Browser.
&gt; 
&gt; &gt; Furthermore, there are privacy concerns about additional metadata
&gt; &gt; regarding the use of DoH (agent headers,
&gt; 
&gt; solved since https://bugzilla.mozilla.org/show_bug.cgi?id=1543201
&gt; 
&gt; &gt; language settings, 
&gt; 
&gt; solved since https://bugzilla.mozilla.org/show_bug.cgi?id=1544724
&gt; 

Well done!

&gt; &gt; and cookies) 
&gt; 
&gt; I don't think firefox sends cookies in DoH requests.
&gt; 
&gt; 
&gt; I'm still curious about the underlying threat model and use-cases (my
&gt; first questions in this thread), 
&gt; since that would help with trying to understand what you are trying
&gt; to achieve.
&gt; 

The thread model is DNS hijacking. Yes, you can prevent DNS hijacking
using DoH if you *trust* the resolver you connect to. However, if you
want to verify authenticity and integrity of DNS responses you need
DNSSEC.

Maybe this is not a real concern, otherwise you might have already
considered it.

&gt; kind regards,
&gt; nusenu
&gt; 

BR
Christian

&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200601165417</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-06-01 16:54:17-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Mon, 2020-05-25 at 21:23 +0200, nusenu wrote:
&gt; Christian Hofer:
&gt; &gt; The thread model is DNS hijacking. Yes, you can prevent DNS
&gt; &gt; hijacking
&gt; &gt; using DoH if you *trust* the resolver you connect to. However, if
&gt; &gt; you
&gt; &gt; want to verify authenticity and integrity of DNS responses you need
&gt; &gt; DNSSEC.
&gt; 
&gt; Could you elaborate on the use-case since DNS record authenticity is
&gt; often just a vehicle to
&gt; bootstrap some other use-case (for example DANE). What higher level
&gt; use-case do you have in mind where authenticity
&gt; of DNS entries provides a value for tor / Tor Browser users?
&gt; 

I am sorry to disappoint you, but I have no higher level use-case in
mind. It just felt strange to me that exit relays are able to tamper
with DNS records as they please. That is the reason why I started to
look into it. On my way I found this old proposal [1] that was never
finished and I figured that there seems to be need :-)

However, thinking about it, DNSSEC might be useful for caching DNS
records on the client side.

https://gitweb.torproject.org/torspec.git/tree/proposals/219-expanded-dns.txt

&gt; What I'm trying to get to: 
&gt; Authentic IP addresses from A/AAAA records are probably of limited
&gt; value in the context of a tor 
&gt; client since the exit relay has full control over the routing anyway.
&gt; If the tor clients asks the exit relay to connect to IP A (which is
&gt; the actual DNSSEC validated IP address)
&gt; there is nothing that can stop an exit from routing it to some other
&gt; IP address.
&gt; 

I understand, then it is not that useful.

&gt; That is why I'm trying to get to the bottom of your DNSSEC use-case.
&gt; 
&gt; To avoid anonymity set reductions I'm also primarily interested in
&gt; enabled by default designs
&gt; (in contrast to opt-in) which brings you to the next problems:
&gt; performance, scaleability and resolver selection.
&gt; 
&gt; Please don't let me discourage you with my questions, they are not
&gt; meant to.
&gt; Just trying to understand and hopefully find some common ground to
&gt; move forward since I see a rather
&gt; motivated person and it would be a pity to loose that opportunity.  
&gt; 

That's fine. I am still willing to contribute.

&gt; My vision for DNS privacy in Tor Browser: 
&gt; Be able to visit a HTTPS website without the exit relay learning what
&gt; domain it was 
&gt; (encrypted DNS + encrypted SNI)
&gt; 

Makes sense. Which nameserver are you planning to use, since the used
provider will get all Tor Browser DNS queries? Do you (the Tor project)
plan to host your own DNS resolver(s)?

&gt; There are a few issues to solve along that path. 
&gt; 

In case you are still looking for alternative approaches. When using
the implementation from the PR you can hide DNS queries from the exit
relay as well.


Things TODO: 

* remove all DNSSEC related code in order to reduce complexity
* host DNS resolver(s) as hidden service (using
HiddenServiceSingleHopMode)


Key differences:

DoH (https connection)

* Better maintainability
* Less code
* Less complexity

Native (hidden service)

* works for use cases outside of Tor Browser
* requires resolvers hosted as hidden services, which might be a
performance issue
* can use multiple resolvers, not all DNS queries go to a single
proivder
* ensuring isolation might be easier due to full control over the
implementation

&gt; kind regards,
&gt; nusenu
&gt; 

BR
Christian

&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200609215455</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-06-09 21:54:55-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; However, thinking about it, DNSSEC might be useful for caching DNS
&gt; records on the client side.

caching has privacy implications and is therefore a risk.

&gt;&gt; My vision for DNS privacy in Tor Browser: 
&gt;&gt; Be able to visit a HTTPS website without the exit relay learning what
&gt;&gt; domain it was 
&gt;&gt; (encrypted DNS + encrypted SNI)
&gt;&gt;
&gt; 
&gt; Makes sense. Which nameserver are you planning to use, since the used
&gt; provider will get all Tor Browser DNS queries? Do you (the Tor project)
&gt; plan to host your own DNS resolver(s)?

based on statements from Roger about what is the max. acceptable size of
a single exit operator in terms of fraction of the network I'd assume that it
is somewhat ok to use a single resolver operator for about 5% of the total exit traffic.
That means we need at least 20 resolver operators, preferably 30.
We could come up with requirements for them (Mozilla's DoH resolver requirements is a start)
and make use of public privacy  aware DNS resolver operators that meet the requirements.
It might also be possible to ask well established exit operators to run DoH endpoints 
on their resolvers. This would have positive performance implications and increase the number
of available DoH servers.

but finding resolvers is probably one of the smaller issues when compared to getting
everything implemented in firefox/tor browser. Current versions do not even allow 
to set more than one resolver URL.

kind regards,
nusenu

-- 
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200614160316</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-06-14 16:03:16-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

On Tue, 2020-06-09 at 23:54 +0200, nusenu wrote:
&gt; &gt; However, thinking about it, DNSSEC might be useful for caching DNS
&gt; &gt; records on the client side.
&gt; 
&gt; caching has privacy implications and is therefore a risk.
&gt; 

So you are saying that caching is not an option in any case, right? Can
I kindly ask you to elaborate on this? You don't have to write a long
answer. A link pointing me to the answer would be more than enough. I
just want to understand the reason behind this.

&gt; &gt; &gt; My vision for DNS privacy in Tor Browser: 
&gt; &gt; &gt; Be able to visit a HTTPS website without the exit relay learning
&gt; &gt; &gt; what
&gt; &gt; &gt; domain it was 
&gt; &gt; &gt; (encrypted DNS + encrypted SNI)
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; Makes sense. Which nameserver are you planning to use, since the
&gt; &gt; used
&gt; &gt; provider will get all Tor Browser DNS queries? Do you (the Tor
&gt; &gt; project)
&gt; &gt; plan to host your own DNS resolver(s)?
&gt; 
&gt; based on statements from Roger about what is the max. acceptable size
&gt; of
&gt; a single exit operator in terms of fraction of the network I'd assume
&gt; that it
&gt; is somewhat ok to use a single resolver operator for about 5% of the
&gt; total exit traffic.
&gt; That means we need at least 20 resolver operators, preferably 30.
&gt; We could come up with requirements for them (Mozilla's DoH resolver
&gt; requirements is a start)
&gt; and make use of public privacy  aware DNS resolver operators that
&gt; meet the requirements.
&gt; It might also be possible to ask well established exit operators to
&gt; run DoH endpoints 
&gt; on their resolvers. This would have positive performance implications
&gt; and increase the number
&gt; of available DoH servers.
&gt; 
&gt; but finding resolvers is probably one of the smaller issues when
&gt; compared to getting
&gt; everything implemented in firefox/tor browser. Current versions do
&gt; not even allow 
&gt; to set more than one resolver URL.
&gt; 

I see. Are there any tickets or design proposals I can contribute to?

Since you have no comments on my suggestion for an alternative
approach, I assume that it is not worth to compare it to DoH, right? 

&gt; kind regards,
&gt; nusenu
&gt; 

BR
Christian

&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200512004101</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-12 00:41:01-0400</timestampReceived><subject>Re: [tor-dev] Proposal 319: RELAY_FRAGMENT cells</subject><body>

Hi Nick,

&gt; On 12 May 2020, at 06:47, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; In this proposal,
&gt; we allow the following cell types to be fragmented: EXTEND2, EXTENDED2,
&gt; INTRODUCE1, INTRODUCE2, RENDEZVOUS.  Any party receiving a command that they
&gt; believe should not be fragmented should close the circuit.

Do you mean RENDEZVOUS1 and RENDEZVOUS2 here?

T
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200514191524</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-14 19:15:24-0400</timestampReceived><subject>Re: [tor-dev] Proposal 319: RELAY_FRAGMENT cells</subject><body>

[Attachment #2 (multipart/signed)]


On 11 May (16:47:24), Nick Mathewson wrote:
&gt; ```
&gt; Filename: 319-wide-everything.md
&gt; Title: RELAY_FRAGMENT cells
&gt; Author: Nick Mathewson
&gt; Created: 11 May 2020
&gt; Status: Open
&gt; ```
&gt; 
&gt; (This proposal is part of the Walking Onions spec project.)
&gt; 
&gt; # Introduction
&gt; 
&gt; Proposal 249 described a system for `CREATE` cells to become wider, in order to
&gt; accommodate hybrid crypto.  And in order to send those cell bodies across
&gt; circuits, it described a way to split `CREATE` cells into multiple `EXTEND`
&gt; cells.
&gt; 
&gt; But there are other cell types that can need to be wider too. For
&gt; example, `INTRODUCE` and `RENDEZVOUS` cells also contain key material
&gt; used for a handshake: if handshakes need to grow larger, then so do
&gt; these cells.
&gt; 
&gt; This proposal describes an encoding for arbitrary "wide" relay cells,
&gt; that can be used to send a wide variant of anything.
&gt; 
&gt; To be clear, although this proposal describes a way that all relay
&gt; cells can become "wide", I do not propose that wide cells should
&gt; actually be _allowed_ for all relay cell types.
&gt; 
&gt; # Proposal
&gt; 
&gt; We add a new relay cell type: `RELAY_FRAGMENT`.  This cell type contains part
&gt; of another relay cell.  A `RELAY_FRAGEMENT` cell can either introduce a new

Typo: RELAY_FRAGEMENT --&gt; RELAY_FRAGMENT

&gt; fragmented cell, or can continue one that is already in progress.
&gt; 
&gt; The format of a RELAY_FRAGMENT body is one of the following:
&gt; 
&gt;     // First body in a series
&gt;     struct fragment_begin {
&gt;        // What relay_command is in use for the underlying cell?
&gt;        u8 relay_command;
&gt;        // What will the total length of the cell be once it is reassembled?
&gt;        u16 total_len;
&gt;        // Bytes for the cell body
&gt;        u8 body[];
&gt;     }
&gt; 
&gt;     // all other cells.
&gt;     struct fragment_continued {
&gt;        // More bytes for the cell body.
&gt;        u8 body[];
&gt;     }
&gt; 
&gt; To send a fragmented cell, first a party sends a RELAY_FRAGMENT cell
&gt; containing a "fragment_begin" payload.  This payload describes the total
&gt; length of the cell, the relay command
&gt; 
&gt; Fragmented cells other than the last one in sequence MUST be sent full of
&gt; as much data as possible.  Parties SHOULD close a circuit if they receive a
&gt; non-full fragmented cell that is not the last fragment in a sequence.
&gt; 
&gt; Fragmented cells MUST NOT be interleaved with other relay cells on a circuit,
&gt; other than cells used for flow control. (Currently, this is only SENDME
&gt; cells.)  If any party receives any cell on a circuit, other than a flow
&gt; control cell or a RELAY_FRAGEMENT cell, before the fragmented cell is

Typo: RELAY_FRAGEMENT --&gt; RELAY_FRAGMENT

&gt; complete, than it SHOULD close the circuit.
&gt; 
&gt; Parties MUST NOT send extra data in fragmented cells beyond the amount given
&gt; in the first 'total_len' field.

Should the circuit be closed or the fragments dropped?

&gt; 
&gt; Not every relay command may be sent in a fragmented cell.  In this proposal,
&gt; we allow the following cell types to be fragmented: EXTEND2, EXTENDED2,
&gt; INTRODUCE1, INTRODUCE2, RENDEZVOUS.  Any party receiving a command that they
&gt; believe should not be fragmented should close the circuit.

Probably we want RENDEZVOUS1 and RENDEZVOUS2.

&gt; 
&gt; Not all lengths up to 65535 are valid lengths for a fragmented cell.  Any
&gt; length under 499 bytes SHOULD cause the circuit to close, since that could
&gt; fit into a non-fragmented RELAY cell.  Parties SHOULD enforce maximum lengths
&gt; for cell types that they understand.
&gt; 
&gt; All `RELAY_FRAGMENT` cells for the fragmented cell must have the
&gt; same Stream ID.  (For those cells allowed above, the Stream ID is
&gt; always zero.)  Implementations SHOULD close a circuit if they
&gt; receive fragments with mismatched Stream ID.
&gt; 
&gt; # Onion service concerns.
&gt; 
&gt; We allocate a new extension for use in the ESTABLISH_INTRO by onion services,
&gt; to indicate that they can receive a wide INTRODUCE2 cell.  This extension
&gt; contains:
&gt; 
&gt;         struct wide_intro2_ok {
&gt;           u16 max_len;
&gt;         }
&gt; 
&gt; We allocate a new extension for use in the `ESTABLISH_RENDEZVOUS`
&gt; cell, to indicate acceptance of wide `RENDEZVOUS2` cells.  This
&gt; extension contains:
&gt; 
&gt;         struct wide_rend2_ok {
&gt;           u16 max_len;
&gt;         }
&gt; 
&gt; (Note that `ESTABLISH_RENDEZVOUS` cells do not currently have a an
&gt; extension mechanism.  They should be extended to use the same
&gt; extension format as `ESTABLISH_INTRO` cells, with extensions placed
&gt; after the rendezvous cookie.)

Why would a client need to announce wide cells in the ESTABLISH phase as
opposed to using protover "Relay=N" ?

The maximum length of a fragmented cell is capped to 2^16 (u16) so we don't
really need the establish process to inform us of the maximum expected length
but rather use the max_len in the first fragment?

Furthermore, ESTABLISH_INTRO has extensions (only 1 as of today) so they could
also be fragments themselves and thus I'm not sure I see the point of having
two different ways of "expecting" fragments for the ESTABLISH_* cells and the
INTRO/RENDEZVOUS cells?

&gt; 
&gt; # Handling RELAY_EARLY
&gt; 
&gt; The first fragment of each EXTEND cell should be tagged with `RELAY_EARLY`.
&gt; The remaining fragments should not.  Relays should accept `EXTEND` cells if and
&gt; only if their _first_ fragment is tagged with `RELAY_EARLY`.
&gt; 
&gt; &gt; Rationale: We could allow any fragment to be tagged, but that would give
&gt; &gt; hostile guards an opportunity to move RELAY_EARLY tags around and build a
&gt; &gt; covert channel.  But if we later move to a relay encryption method that
&gt; &gt; lets us authenticate RELAY_EARLY, we could then require only that _any_
&gt; &gt; fragment has RELAY_EARLY set.
&gt; 
&gt; # Compatibility
&gt; 
&gt; This proposal will require the allocation of a new 'Relay' protocol version,
&gt; to indicate understanding of the RELAY_FRAGMENTED command.

Here is a thought about a DoS vector. Here goes:

As an upper limit of 65KB total fragment size, it represents ~126 cells in
total so I could basically send *125* cells and then stop which will put in
memory a bit more than 64KB and it will stay there until the last fragment is
received.

And then I do that on 1000 different circuits bringing the total count in
memory to 64GB. All stuck there, all "waiting" for the last fragment.

Our OOM would kick in killing circuits but it just seems to me a very easy way
to continously kick the OOM of a _service_ which is pretty bad side channel.

Thoughts?

Cheers!
David

-- 
dApigzB8NtOQEAlKqhqbshxjxOMakjiX9LGU9wvhFqs=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200418110203</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-04-18 11:02:03-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Fri, 17 Apr 2020 18:01:42 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; If you want to work on this it would be helpful to maybe start by
&gt; listing (here or elsewhere) some places where you *don't* feel like
&gt; you could (or would want to) write documentation: those would be a
&gt; good target for devs who _have_ worked on Chutney before.

I came across Node.specialize() which does not seem to be called
elsewhere, and I cannot guess at its purpose. So, if anyone knows off
the top of their head what this is for (not what it does, because it's
quite obvious from the code itself) then I'd greatly appreciate and I
will document its purpose accordingly. It is one of the functions that
is listed as "to be called by the user".

Other than that I added docstrings where they were missing in TorNet
(useful both for Python's on-line help() and for checking whether code
agrees with intent) and made mental note of some areas I would like to
improve in the code (changing function names to better align with what
they actually do, figure out if some longer functions can be split into
more atomical and easier-to-digest parts, ...).

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200514230331</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-05-14 23:03:31-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Sat, 18 Apr 2020 11:02:03 +0000
c &lt;c@chroniko.jp&gt; wrote:

&gt; I came across Node.specialize() which does not seem to be called
&gt; elsewhere, and I cannot guess at its purpose.

I ran vulture (a static analyzer for dead code), trimmed the output to
omit things I know were being used (some functions/attributes are used
solely in Python 2), and found these unused names:

lib/chutney/Templating.py:280: unused function 'getUpdateTime' (60% confidence)
lib/chutney/TorNet.py:439: unused function 'specialize' (60% confidence)
lib/chutney/TorNet.py:658: unused function '_getFreeVars' (60% confidence)
lib/chutney/TorNet.py:1232: unused function 'isBootstrapped' (60% confidence)
lib/chutney/TorNet.py:1799: unused function 'isInExpectedDirInfoDocs' (60% confidence)
lib/chutney/TorNet.py:2151: unused function 'configure' (60% confidence)
lib/chutney/TorNet.py:2191: unused function 'restart' (60% confidence)
lib/chutney/TorNet.py:2286: unused function 'wait_for_bootstrap' (60% confidence)
lib/chutney/Traffic.py:335: unused attribute 'am_closing' (60% confidence)
lib/chutney/Traffic.py:345: unused attribute 'am_closing' (60% confidence)
lib/chutney/Traffic.py:400: unused attribute 'pending_close' (60% confidence)
lib/chutney/Traffic.py:406: unused attribute 'dot_repetitions' (60% confidence)

Aside from isBootstrapped() which we discussed previously and are
likely going to use, is there any code that stands out as unnecessary
or dead?

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200514235845</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-05-14 23:58:45-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Thu, May 14, 2020 at 7:04 PM c &lt;c@chroniko.jp&gt; wrote:
&gt;
&gt; On Sat, 18 Apr 2020 11:02:03 +0000
&gt; c &lt;c@chroniko.jp&gt; wrote:
&gt;
&gt; &gt; I came across Node.specialize() which does not seem to be called
&gt; &gt; elsewhere, and I cannot guess at its purpose.
&gt;
&gt; I ran vulture (a static analyzer for dead code), trimmed the output to
&gt; omit things I know were being used (some functions/attributes are used
&gt; solely in Python 2), and found these unused names:
&gt;
&gt; lib/chutney/Templating.py:280: unused function 'getUpdateTime' (60% confidence)
&gt; lib/chutney/TorNet.py:439: unused function 'specialize' (60% confidence)
&gt; lib/chutney/TorNet.py:658: unused function '_getFreeVars' (60% confidence)
&gt; lib/chutney/TorNet.py:1232: unused function 'isBootstrapped' (60% confidence)
&gt; lib/chutney/TorNet.py:1799: unused function 'isInExpectedDirInfoDocs' (60% confidence)
&gt; lib/chutney/TorNet.py:2151: unused function 'configure' (60% confidence)
&gt; lib/chutney/TorNet.py:2191: unused function 'restart' (60% confidence)
&gt; lib/chutney/TorNet.py:2286: unused function 'wait_for_bootstrap' (60% confidence)
&gt; lib/chutney/Traffic.py:335: unused attribute 'am_closing' (60% confidence)
&gt; lib/chutney/Traffic.py:345: unused attribute 'am_closing' (60% confidence)
&gt; lib/chutney/Traffic.py:400: unused attribute 'pending_close' (60% confidence)
&gt; lib/chutney/Traffic.py:406: unused attribute 'dot_repetitions' (60% confidence)
&gt;
&gt; Aside from isBootstrapped() which we discussed previously and are
&gt; likely going to use, is there any code that stands out as unnecessary
&gt; or dead?

Hm. Of these:

isInExpectedDirInfoDocs looks like it might once have done something useful.

configure and restart and wait_for_bootstrap are all in use; they are
invoked by name, from the command line, at the end of runConfigFile,
where it says `return getattr(network, verb)()`.

I think the rest are likely to be unused.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200515012054</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-15 01:20:54-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

[Attachment #2 (multipart/signed)]


Hi Caitlin,

&gt; On 15 May 2020, at 09:59, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt; On Thu, May 14, 2020 at 7:04 PM c &lt;c@chroniko.jp&gt; wrote:
&gt;&gt; 
&gt;&gt;&gt; On Sat, 18 Apr 2020 11:02:03 +0000
&gt;&gt;&gt; c &lt;c@chroniko.jp&gt; wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt; I came across Node.specialize() which does not seem to be called
&gt;&gt;&gt; elsewhere, and I cannot guess at its purpose.
&gt;&gt; 
&gt;&gt; I ran vulture (a static analyzer for dead code), trimmed the output to
&gt;&gt; omit things I know were being used (some functions/attributes are used
&gt;&gt; solely in Python 2), and found these unused names:
&gt;&gt; 
&gt;&gt; lib/chutney/Templating.py:280: unused function 'getUpdateTime' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:439: unused function 'specialize' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:658: unused function '_getFreeVars' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:1232: unused function 'isBootstrapped' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:1799: unused function 'isInExpectedDirInfoDocs' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:2151: unused function 'configure' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:2191: unused function 'restart' (60% confidence)
&gt;&gt; lib/chutney/TorNet.py:2286: unused function 'wait_for_bootstrap' (60% confidence)
&gt;&gt; lib/chutney/Traffic.py:335: unused attribute 'am_closing' (60% confidence)
&gt;&gt; lib/chutney/Traffic.py:345: unused attribute 'am_closing' (60% confidence)
&gt;&gt; lib/chutney/Traffic.py:400: unused attribute 'pending_close' (60% confidence)
&gt;&gt; lib/chutney/Traffic.py:406: unused attribute 'dot_repetitions' (60% confidence)
&gt;&gt; 
&gt;&gt; Aside from isBootstrapped() which we discussed previously and are
&gt;&gt; likely going to use, is there any code that stands out as unnecessary
&gt;&gt; or dead?
&gt; 
&gt; Hm. Of these:
&gt; 
&gt; isInExpectedDirInfoDocs looks like it might once have done something useful.
&gt; 
&gt; configure and restart and wait_for_bootstrap are all in use; they are
&gt; invoked by name, from the command line, at the end of runConfigFile,
&gt; where it says `return getattr(network, verb)()`.
&gt; 
&gt; I think the rest are likely to be unused.

You could try deleting functions, and then running tor's
"make test-network-all". If that test still passes, then the code is probably
unused (in practice).

Chutney's CI does a few more tests for different tor versions, but I'm pretty
sure they all use the same code.

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl697nYACgkQEP6qDnB1
ZypGmxAAuR7agvITaaUNHmE+WXv9AlgW7Zu1nlYV2fM0uAp6b62sF8E6ooh/0HPZ
wwqF/kQsYyv7qR3srJuMdRLaX8xw+3NHM1MMd01bBhTsKUVqEsIU5hT8LhJyXWmV
aEk85tUM1rIE92ltsVeVrPi1tl97plzqRcbYiCfM9WPYf3n6uE4Bl7DWQJ1GvjUr
wX9Lj1NnD4HFM1L2X9Ac75YxDK95TpGm704ML/zwac0EfHhGFWfCS2j0t+tFKAFu
agJE8pd17qKDEPMzkKdsqT4vhGKeF2Ld5sqPi2coUQaoWh6G1jrFbsHN0JmtSxxw
i2HbMjoYBL7PO4X+IzS6/Lao1Cj5pObdxXatbOmcQuXjk6+X3lgbqQpp5lazwTwb
1SvEshArkfMDjRR2fz2f/+5Jm+Ea3cUzalJg39XrNiLrzxyCI4nUzbHwU6+p+Q2O
YINkTtplGPgs/vgUoV2H8jEsCJsblEd7r7xMnjE3PZMzAkf/v91sxGjfsFDpVsYK
TKAnKaNRN5zYbQFBv3Dbm113Moz0Fk/5pp0C1CwJVwZ3tZUe/XYlsF83p0fKhhG1
YkLC8QQW/obQovomL4BfU5KP8mdu2KNimh6k0SH9+LbmPcI6fU3RRCVoa1jfRfNr
uxLIkjQXVvUaI9sVAIrszGcruKQNkzQxKNjm27T3lVQu7JV7IYY=
=1Yo5
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200517010616</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-05-17 01:06:16-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Thu, 14 May 2020 19:58:45 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; isInExpectedDirInfoDocs looks like it might once have done something useful.

My impression is to remove it unless we anticipate needing it in the
near future.

&gt; configure and restart and wait_for_bootstrap are all in use; they are
&gt; invoked by name, from the command line, at the end of runConfigFile,
&gt; where it says `return getattr(network, verb)()`.

Ah, I see now, thank you. I think it would be wise to comment the
functions as such to indicate that they are used on the command line.

&gt; I think the rest are likely to be unused.

I did grep most of these and found no signs of use, so this is my
impression as well.

For now I will make a mental note of all this while I work on more
pertinent improvements to the code, but I do believe it would be nice
to deal with truly unused code sooner rather than later.

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200510173031</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-05-10 17:30:31-0400</timestampReceived><subject>[tor-dev] Is anybody using OnionPerf's measurement results in the .tpf format?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hello list,

if the subject line doesn't make any sense to you, this email is very
likely irrelevant for you.

But if it does make sense to you and you did use OnionPerf's [0]
measurement in the .tpf format [1] in the past and/or plan to use this
data in the future, you should comment on ticket #34141 [2] and tell us
about your use case, ideally in the next couple of days.

For what it's worth, the same measurements data is also available in
OnionPerf's JSON format [3], and existing data from past measurements
will continue to be available in the .tpf format. It's just that we want
to get rid of the .tpf format for new measurements.

All the best,
Karsten


[0] https://metrics.torproject.org/torperf.html

[1] https://metrics.torproject.org/collector.html#type-torperf

[2] https://trac.torproject.org/projects/tor/ticket/34141

[3] https://metrics.torproject.org/collector.html#type-onionperf


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200511134905</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-05-11 13:49:05-0400</timestampReceived><subject>Re: [tor-dev] Proposal 315: Updating the list of fields required in directory documents</subject><body>

On Thu, Apr 23, 2020 at 5:26 PM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; This proposal is missing the "bridge" case.
&gt;
&gt; Bridges are more complicated, because we have at least
&gt; 3 kinds of bridges:
&gt; * bridges distributed by BridgeDB
&gt; * bridges distributed with apps (such as Tor Browser)
&gt; * private bridges
&gt;
&gt; Bridge option transitions are also more complicated, because clients
&gt; download bridge descriptors directly from their configured bridges.

Thank you!

I think that the transition isn't too bad, since the partitioning that
a bridge _could_ do by maintaining an obsolete descriptor format is
limited in its impact, since the bridge already (typically) sees the
client's IP address.  So the only difference is that we need to be a
little more careful about when we start  to require the fields, since
bridges sometimes  lag the versions supported by the rest of the
network.

I've update the proposal with these paragraphs:

   Bridge relays have their descriptors processed by clients
   without necessarily passing through authorities.
   We can make fields mandatory in bridge descriptors once we
   can be confident that no bridge lacking them will actually
   connect to the network-- or that all such bridges are safe
   to stop using.

   For bridges, when a field becomes required, it will take some
   time before all clients require that field.  This would create a
   partitioning opportunity, but partitioning at the first-hop
   position is not so strong: the bridge already knows the client's
   IP, which is a much better identifier than the client's Tor
   version.

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200512000927</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-12 00:09:27-0400</timestampReceived><subject>[tor-dev] Walking onions: week 10 update</subject><body>

Walking Onions: week 10 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html

Week 5:
   Voting (part 2)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014218.html

Week 6:
   Editing, voting rules, and client behavior (part 1)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014222.html

Week 7:
   Exit policies: How do they work?

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014232.html

Week 8:
   Onion services, relay honesty, migration and families

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014255.html

Week 9:
   (There was no week 9)

== Now with an introduction

I left the Introduction section of the proposal till late in the
game; now I have it in place as a new section 1:



== Proposals into the pipeline

I've also revised all of the "other proposals" that were logically
separate from the rest of Walking Onions.  Three of them were ready
to go to tor-dev, so I've added them as:

 318-limit-protovers.md Limit protover values to 0-63.
 319-wide-everything.md RELAY_FRAGMENT cells
 320-tap-out-again.md   Removing TAP usage from v2 onion services

== In the home stretch

I've got till the end of the month to wrap up this proposal, so
let's see where we are.  We have a minimal viable proposal, I
believe: if we were to sit down and start implementing, we would
probably get most of the way based on what we have now.

There are a few additional things I'd like to wrap up before I call
the proposal done, however:

* I've got all the necessary machinery written up for generating and
  calculating indices, but before I actually move ahead, I should
  fill in the details in sections 2 through 4.

* One of the original goals of Walking Onions was to permit us to
  move to alternative topologies where not every relay connects to
  every other relay.  That's not something that we can include in
  this proposal, since the research here is quite preliminary, but
  I still want to prepare for it by making sure that clients can
  handle getting SNIPs that say "this SNIP is only valid when given
  by a relay of type X".

* I should take another pass through the CDDL format to see whether
  there are any opportunities to save a bunch of bytes.  I should
  also fill in a couple of example SNIPs to see how big they are
  with this proposal.

* There are places all over the proposal where I have marked
  uncertain points with XXXX.  I should go through them and resolve
  them all before I call the proposal done.


[INTRO] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/01-intro.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200512002404</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-12 00:24:04-0400</timestampReceived><subject>Re: [tor-dev] Proposal 318: Limit protover values to 0-63</subject><body>

Hi Nick,

&gt; On 12 May 2020, at 06:47, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; ```
&gt; Filename: 318-limit-protovers.md
&gt; Title: Limit protover values to 0-63.
&gt; Author: Nick Mathewson
&gt; Created: 11 May 2020
&gt; Status: Open
&gt; ```
&gt; 
&gt; # Limit protover values to 0-63.
&gt; 
&gt; I propose that we no longer accept protover values higher than 63,
&gt; so that they can all fit nicely into 64-bit fields.
&gt; 
&gt; (This proposal is part of the Walking Onions spec project.)
&gt; 
&gt; ## Motivation
&gt; 
&gt; Doing this will simplify our implementations and our protocols.
&gt; Right now, an efficient protover implementation needs to use ranges
&gt; to represent possible protocol versions, and needs workarounds to
&gt; prevent an attacker from constructing a protover line that would
&gt; consume too much memory.  With Walking Onions, we need lists of
&gt; protocol versions to be represented in an extremely compact format,
&gt; which also would benefit from a limited set of possible versions.

If you'd like to make the format even more compact, you could also
lower these limits:

const MAX_PROTOCOLS_TO_EXPAND: usize = 1 &lt;&lt; 16;
const MAX_PROTOCOL_NAME_LENGTH: usize = 100;

In particular:
* now that protocols can only have 63 versions, we can directly
   limit the maximum number of protocol names. (Rather than
   indirectly limiting them via the expansion limit.) We currently have
   12 protocol names, so a suitable limit might be 50.
* depending on the parsing algorithm, we might not need an
   expansion limit any more. If we do, we should set the limit to
  (max versions)*(max names) or lower.
* our current protocol names are all 4-9 characters, so we could
   lower the name limit to 30.

That way, the maximum length of a compact list would be:
8 bytes per protocol version * 50 protocols = 400 bytes of versions
30 bytes per protocol name * 50 protocols = 1500 bytes of names

Hmm, maybe that's a bit high, and we should drop some of those
limits even further.

&gt; 
&gt; 
&gt; Even if we did someday need to implement higher protocol
&gt; versions, we could simply add a new subprotocol name instead.  For
&gt; example, instead of "HSIntro=64", we could say "HSIntro2=1".

If we drop the name limit, it should be high enough to support new
protocols, and extensions to existing protocols.

&gt; ## Migration
&gt; 
&gt; Immediately, authorities should begin rejecting relays with protocol
&gt; versions above 63.  (There are no such relays in the consensus right
&gt; now.)
&gt; 
&gt; Once this change is deployed to a majority of authorities, we can
&gt; remove support in other Tor environments for protocol versions
&gt; above 63.

As you said in your previous email, bridge clients can start rejecting
descriptors along with regular clients. Even though they get their
descriptors directly from bridges.

T
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200512182402</emailId><senderName>Barkin Simsek</senderName><senderEmail>barkin@nyu.edu</senderEmail><timestampReceived>2020-05-12 18:24:02-0400</timestampReceived><subject>[tor-dev] woswos - GSoC 2020</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

I'm Barkin (woswos in IRC), and I study Computer Engineering at New York
University Abu Dhabi. This summer, I will be working on the "Cloudflare
CAPTCHA Monitoring" project as a part of the GSoC program with my mentors
Georg and Roger. I'm very excited about working on this project!

The Cloudflare CAPTCHA Monitoring project aims to track how often
Cloudflare fronted webpages return CAPTCHAs to Tor clients. The project
aims to achieve this by fetching webpages via both Tor and other mainstream
web browsers and comparing the results. The tests are repeated periodically
to find the patterns over time. Collected metadata, metrics, and results
are analyzed and displayed on a dashboard to understand how Cloudflare
manipulates internet traffic and affects people's access to the internet.

I will be creating a bunch of trac tickets to record my progress and to get
feedback from the community. Until then, you can leave your comments and
suggestions under the ticket #33010

You can find more detailed information about the project on this wiki page:
https://trac.torproject.org/projects/tor/wiki/doc/CAPTCHAMonitor This wiki
page will also contain the links to the trac tickets I mentioned. I try to
place all sorts of information on the wiki page to make it the "go-to
place" to get information about my project.

Best,
Barkin

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi everyone,&lt;br&gt;&lt;br&gt;I'm Barkin (woswos in IRC), and I study \
Computer Engineering at New York University Abu Dhabi. This summer, I will be working \
on the "Cloudflare CAPTCHA Monitoring" project as a part of the GSoC \
program with my mentors Georg and Roger. I'm very excited about working on this \
project!&lt;br&gt;&lt;br&gt;The Cloudflare CAPTCHA Monitoring project aims to track how often \
Cloudflare fronted webpages return CAPTCHAs to Tor clients. The project aims to \
achieve this by fetching webpages via both Tor and other mainstream web browsers and \
comparing the results. The tests are repeated periodically to find the patterns over \
time. Collected metadata, metrics, and results are analyzed and displayed on a \
dashboard to understand how Cloudflare manipulates internet traffic and affects \
people's access to the internet.&lt;br&gt;&lt;br&gt;I will be creating a bunch of trac \
tickets to record my progress and to get feedback from the community. Until then, you \
can leave your comments and suggestions under the ticket #33010&lt;br&gt;&lt;br&gt;You can find \
more detailed information about the project on this wiki page:  &lt;a \
href="https://trac.torproject.org/projects/tor/wiki/doc/CAPTCHAMonitor"&gt;https://trac.torproject.org/projects/tor/wiki/doc/CAPTCHAMonitor&lt;/a&gt; \
This wiki page will also contain the links to the trac tickets I mentioned. I try to \
place all sorts of information on the wiki page to make it the "go-to \
place" to get information about my \
project.&lt;br&gt;&lt;br&gt;Best,&lt;br&gt;Barkin&lt;div&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200515115539</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-15 11:55:39-0400</timestampReceived><subject>Re: [tor-dev] Deprecating Tor Protocol Versions</subject><body>

[Attachment #2 (multipart/signed)]


Hi David,

&gt; On 15 May 2020, at 20:53, David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt; 
&gt; On 15 May (13:58:06), teor wrote:
&gt;&gt; 
&gt;&gt; Nick and I were talking about how we remove legacy features in tor,
&gt;&gt; and their corresponding subprotocol versions.
&gt;&gt; 
&gt;&gt; Here is a list of the current subprotocol versions:
&gt;&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2049
&gt;&gt; 
&gt;&gt; Here's a recent protocol version proposal, which deals with
&gt;&gt; recommending and requiring new features:
&gt;&gt; https://gitweb.torproject.org/torspec.git/tree/proposals/303-protover-removal-policy.txt
&gt;&gt; 
&gt;&gt; But we don't have a similar proposal for removing support for older
&gt;&gt; protocol versions from the tor codebase.
&gt;&gt; 
&gt;&gt; For an example of what that proposal could look like, see our proposal
&gt;&gt; for deprecating consensus methods:
&gt;&gt; https://gitweb.torproject.org/torspec.git/tree/proposals/290-deprecate-consensus-methods.txt
&gt;&gt; 
&gt;&gt; Here's the original conversation Nick and I had:
&gt;&gt; https://github.com/torproject/tor/pull/1874#discussion_r423713579
&gt;&gt; 
&gt;&gt; But after reading our consensus methods deprecation proposal, I've
&gt;&gt; changed my mind. I think that we should check for "protocol N, and
&gt;&gt; any later version" by default.
&gt; 
&gt; I agree that this is the right approach imo as well.
&gt; 
&gt;&gt; That's what we do for consensus methods, and it seems to work well.
&gt;&gt; We can drop the earliest consensus methods, and recent tor versions
&gt;&gt; just keep working.
&gt;&gt; 
&gt;&gt; If we need an incompatible change, we can make it another protocol
&gt;&gt; version, and recommend then require support for it.
&gt;&gt; 
&gt;&gt; So here's an edited version of my notes on that ticket:
&gt;&gt; 
&gt;&gt; There are a few instances of "&gt;=" and "=" confusion in protocol
&gt;&gt; versions. We should try to fix them all.
&gt;&gt; 
&gt;&gt; It only matters when we remove protocol versions. We haven't
&gt;&gt; really specified, tested, or exercised this functionality in
&gt;&gt; practice. And so our reviewers lack experience. (And when we did
&gt;&gt; discover a need for it with NSS and LinkAuth, it was more complicated
&gt;&gt; than we expected.)
&gt;&gt; 
&gt;&gt; I'd like to see a proposal that tells us how to check future protocol
&gt;&gt; versions as they are added. Along with a migration plan for disabling
&gt;&gt; protocol versions.
&gt;&gt; 
&gt;&gt; So let's also open a ticket to check for "any future version".
&gt;&gt; We should replace all "=" checks with "&gt;=". Let's make sure we check
&gt;&gt; all the places where we use protocol versions, even if they don't
&gt;&gt; have a summary flag.
&gt;&gt; 
&gt;&gt; Overall, I think it would be helpful if future protocol versions were
&gt;&gt; orthogonal. Or if they depend on earlier features, that dependency
&gt;&gt; should be clearly documented. (For example, Relay=3 IPv6 extends
&gt;&gt; depends on Relay=2 EXTEND2 cells. So if we were checking EXTEND2 cell
&gt;&gt; support, it would be Relay=2 or Relay=3.)
&gt; 
&gt; At the moment, they do depend between each other last time I had that
&gt; discussion with Nick. As in the later in your example.
&gt; 
&gt; Which means that supporting protocol version with a "&gt;=" is consistent with
&gt; our "non-written expectations" that we have now.

That's how most protocol versions work right now.

The following protocol versions are exceptions:
* Link        all Link protocols introduce incompatible changes, but a shared
              Link protocol is dynamically negotiated at runtime
* LinkAuth=3  might not support LinkAuth=1 (RSA link authentication)
* Padding=1   accidentally enabled for relays that don't support
              circuit-level padding

Link is a special case because it's the lowest-level protocol, and negotiated
at runtime. (And using an unknown feature terminates the connection.)

LinkAuth became incompatible when we introduced NSS support. But a better
design might have been:
* LinkAuth=1 RSA only
* LinkAuth=3 ed25519 and RSA
* LinkAuth=4 ed25519 only

Padding was a mistake :-(

&gt; So if I understand correctly, we'll need to add a new protocol version let say
&gt; N+1 in order to deprecate anything &lt;= N ?
&gt; 
&gt; As an example, Relay=4 could mean "deprecate Relay=2 and use only Relay=3"
&gt; 
&gt; I'm +1 on this if iiuc.

Yes, I think that's what we should do in future.

So we should:
* write a proposal or spec update, and
* change the current code to use "protocol_list_supports_protocol_or_later()
  in most cases.

I'm going to wait for asn or nickm to weigh in, before opening tickets.

T

["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6+gzsACgkQEP6qDnB1
ZyqG/RAApwFPKjoKmFoWpyoYD/2kwLjG7ITuId+kvmZU9zDVcfDySUrKch9xak/I
F+MhsvCxFfJeQ0GqBSEwPrIGsLfkaAgzYLBnJJWiyc/KIzaJ0MB++R9sS4Ve26p6
jeczviwppHr5foJ7SiLeaLIwPdU2I7zUHXuTs86DvyAj5Zu3JM0S13FX37n5EFdC
3Okj8O90tv6LaJlOTg2LX4JRXXAVhuHkOcWCgY1dYyc3wBd2Nwr3gm1USecUE7iY
xgfqnhEXLiBPB6iMuONJYIie/Clv2qB1+tSn7WMrXee8S6+TpzraqOh+mlId8VS+
HXoGHirEtcytQKf6hwdsDk4M94jOhpPk3O36sXxBjExjp523nc9Miw/kI7+FqWTt
3RS6is8B2ZZcBoC8ss6DGhhxMz3DIdc5FDEd/O2sKNSpYmdkRzYlQOyYVN/1LaDq
qszCm1XdZ0eBzZdmKQgyQe724CQdiXs8TIPqaWRVvYfo1aGTbeh6Y4Lonx/ibC17
6SfFQJ63WAK4z738/TvN4MRcpvzX2FgLDETpej6aAISyGxeA0uzCa19YvABz9Afn
Ts3LTmqs2g7xritQJs+F1ltUGXm9zlGN5FbVKDOJBgSEBQ5J1iWaxuX/LU7maQmA
e9SaQaUHWqXzhoX3zFN+DD4lZcgDe3oVi8cijF2e/EVS3vqX2cE=
=t0FK
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200517010823</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-05-17 01:08:23-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Fri, 15 May 2020 11:20:54 +1000
teor &lt;teor@riseup.net&gt; wrote:

&gt; You could try deleting functions, and then running tor's
&gt; "make test-network-all". If that test still passes, then the code is probably
&gt; unused (in practice).
&gt; 
&gt; Chutney's CI does a few more tests for different tor versions, but I'm pretty
&gt; sure they all use the same code.

This is what I will end up doing. I planned on it, but humans tend to
know the purpose of the code better, and computers just run what is
given to them :) so I figured it was best to check here first, with
people more experienced with the codebase.

Thanks,
Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200517024321</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-05-17 02:43:21-0400</timestampReceived><subject>Re: [tor-dev] Proposal XXX: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>


&gt; On 16 May 2020, at 16:05, Mike Perry &lt;mikeperry@torproject.org&gt; wrote:
&gt; 
&gt;&gt; On 4/23/20 1:48 PM, Matt Traudt wrote:
&gt;&gt; 
&gt;&gt; 5.4 Other Changes/Investigations/Ideas
&gt;&gt; 
&gt;&gt; - How can FlashFlow data be used in a way that doesn't lead to poor
&gt;&gt;  load balancing given the following items that lead to non-uniform
&gt;&gt;  client behavior:
&gt;&gt;    - Guards that high-traffic HSs choose (for 3 months at a time)
&gt;&gt;    - Guard vs middle flag allocation issues
&gt;&gt;    - New Guard nodes (Guardfraction)
&gt;&gt;    - Exit policies other than default/all
&gt;&gt;    - Directory activity
&gt;&gt;    - Total onion service activity
&gt;&gt;    - Super long-lived circuits
&gt;&gt; - What is the explanation for dennis.jackson's scary graphs in this [2]
&gt;&gt;  ticket?  Was it because of the speed test? Why? Will FlashFlow produce
&gt;&gt;  the same behavior?
&gt; 
&gt; It will also be wise to provide a way for relays to signify that they
&gt; are on the same machine. I bet concurrent machine deployments are one of
&gt; the top contributors to the long tail of bad perf we saw caused by the
&gt; Flashflow experiment[2]. If flashflow measures each such relay as having
&gt; the full link capacity instead of a shared fraction, this is obviously
&gt; going to result in overload on those relays, leading to a long tail of
&gt; bad perf when they are chosen and are also overloaded. It is unlikely
&gt; that we can deploy a FlashFlow that has this long tail perf problem
&gt; without fixing this and related balancing issues (though hopefully most
&gt; will be smoothed over by sbws).
&gt; 
&gt; This is a little tricky, because we might not want rogue relays joining
&gt; each others "machines" (similar to the Family problem), but for testing
&gt; something as simple as how MyFamily works would be great. Ideally,
&gt; though, relays would ask or detect that they are concurrently running in
&gt; nearby IP space and either warn the operator to set the flag, or set it
&gt; automatically.
&gt; 
&gt; We actually have this work included in a future performance funding
&gt; proposal, but the timeline on that getting approved (or even rejected)
&gt; is so far out that we should figure out a way to do this before that,
&gt; especially if Flashflow development is going to begin soon.

We could assume that relays on the same IPv4 /24 or IPv6 /48 share a
network link, and re-do the experiment.

Then we could tweak the network size based on those results. We'd
need to compromise between "false sharing" and "missed sharing".

Then individual operators could fine-tune that initial heuristic using the
"same network link" config.

(This is similar to how MyFamily works: Tor assumes that relays in the
same IPv4 /16 and IPv6 /32 have the same network operator. Then
individual relay operators can declare extra families using MyFamily.)

T
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200518110039</emailId><senderName></senderName><senderEmail>yoehoduv</senderEmail><timestampReceived>2020-05-18 11:00:39-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


&gt; What is the benefit of this approach rather than discarding low
&gt; priority requests right away in the top-half handler?
&gt; =


&gt; Note that a priority queue is typically implemented as a heap, which
&gt; does not support efficient trimming.

Correct me if I'm wrong.

When a cell with a small effort in the queue has any chance of getting
selected, the optimal strategy for a legitimate client would be to
compute nonces and send as many nonces as possible until it causes
congestion on his network.  Instead when only the cell with the highest
effort is processed, sending more than one nonces per connection does no
good for a client.  We want each legitimate client to send only one
nonce per connection.

As of trimming the priority queue, we don't have to use a heap.  We can
compress the effort into maybe 7 bits, and then store the requests in
128 arrays.  Then trimming it is freeing an array.  The compression can
be something like floating point.

   ~clz(POW_NONCE) &lt;&lt; 1 | (POW_NONCE &gt;&gt; (127 - clz(POW_NONCE))) &amp; 1

That is, take the number of leading zeros and by one bit on the right of
the leftmost 1 bit, then complement the first part to preserve order.
We can expect the number of leading zeros to be less than 64, so this
will take 7 bits.  A decrement of this value means about 1.3 - 1.5 times
more work, which should be finely enough grained.
["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200519172954</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-05-19 17:29:54-0400</timestampReceived><subject>Re: [tor-dev] Proposal 319: RELAY_FRAGMENT cells</subject><body>

On Thu, May 14, 2020 at 3:15 PM David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt;
&gt; On 11 May (16:47:24), Nick Mathewson wrote:
 [...]
&gt; &gt; # Onion service concerns.
&gt; &gt;
&gt; &gt; We allocate a new extension for use in the ESTABLISH_INTRO by onion services,
&gt; &gt; to indicate that they can receive a wide INTRODUCE2 cell.  This extension
&gt; &gt; contains:
&gt; &gt;
&gt; &gt;         struct wide_intro2_ok {
&gt; &gt;           u16 max_len;
&gt; &gt;         }
&gt; &gt;
&gt; &gt; We allocate a new extension for use in the `ESTABLISH_RENDEZVOUS`
&gt; &gt; cell, to indicate acceptance of wide `RENDEZVOUS2` cells.  This
&gt; &gt; extension contains:
&gt; &gt;
&gt; &gt;         struct wide_rend2_ok {
&gt; &gt;           u16 max_len;
&gt; &gt;         }
&gt; &gt;
&gt; &gt; (Note that `ESTABLISH_RENDEZVOUS` cells do not currently have a an
&gt; &gt; extension mechanism.  They should be extended to use the same
&gt; &gt; extension format as `ESTABLISH_INTRO` cells, with extensions placed
&gt; &gt; after the rendezvous cookie.)
&gt;
&gt; Why would a client need to announce wide cells in the ESTABLISH phase as
&gt; opposed to using protover "Relay=N" ?

This is not for announcing support of wide cells -- this is for
reporting a setting for how wide fragmented cells should be.

&gt; The maximum length of a fragmented cell is capped to 2^16 (u16) so we don't
&gt; really need the establish process to inform us of the maximum expected length
&gt; but rather use the max_len in the first fragment?

This all comes back to an earlier part of the proposal:

    Not all lengths up to 65535 are valid lengths for a fragmented
    cell.  Any length under 499 bytes SHOULD cause the circuit
    to close, since that could fit into a non-fragmented RELAY cell.
    Parties SHOULD enforce maximum lengths for cell types that
    they understand.

In other words, I'm imagining that there is a maximum length for each
cell type that is much shorter than 65535, even though we're using two
bytes for the length field.

The extension in the establish_intro cell is to tell the intro point
the longest introduce1 cell that it should accept;  this extension in
the establish_rend cell is to tell the rendezvous point the longest
rendezvous1 cell that it should accept.

Another way we could do this would be with a set of network parameters
to describe the maximum length of each fragmented cell.  Do you think
that would be simpler?

(I can't quite remember why I specified it this way in the first place.)

&gt; Furthermore, ESTABLISH_INTRO has extensions (only 1 as of today) so they could
&gt; also be fragments themselves and thus I'm not sure I see the point of having
&gt; two different ways of "expecting" fragments for the ESTABLISH_* cells and the
&gt; INTRO/RENDEZVOUS cells?

The difference thing here is that everybody can tell which protocols
that a relay supports, but there is no automatic way to tell which
protocols an onion service or client supports.  Since
INTRODUCE2/RENDEZVOUS2 cells are handled by these clients, they need
to get opted into by the relays.

(I'm not sure I understood the question completely.)

&gt; &gt; # Compatibility
&gt; &gt;
&gt; &gt; This proposal will require the allocation of a new 'Relay' protocol version,
&gt; &gt; to indicate understanding of the RELAY_FRAGMENTED command.
&gt;
&gt; Here is a thought about a DoS vector. Here goes:
&gt;
&gt; As an upper limit of 65KB total fragment size, it represents ~126 cells in
&gt; total so I could basically send *125* cells and then stop which will put in
&gt; memory a bit more than 64KB and it will stay there until the last fragment is
&gt; received.
&gt;
&gt; And then I do that on 1000 different circuits bringing the total count in
&gt; memory to 64GB. All stuck there, all "waiting" for the last fragment.
&gt;
&gt; Our OOM would kick in killing circuits but it just seems to me a very easy way
&gt; to continously kick the OOM of a _service_ which is pretty bad side channel.

A few responses here:

First, we shouldn't allow 65535-byte fragmented cells.   The actual
maximum length should be something more like 1024 or 4096 bytes.

Second, we should make sure that when we are reassembling cells, we
use the same buf_t buffers that we use for other stuff.  Our buffers
are timestamped, so we can tell which buffer has had data stalling for
the longest, and we should use that to make sure we're killing off the
right circuits preferentially.

Third, fragments should only be allowed at an onion service for
INTRODUCE2, and those should only come one at a time from each
introduction point, so the number that it's reassembling at the time
will be limited by the number of intro circuits it has open.  It'll be
the the intro points that have to be keeping a bunch of cells in
assembly at once, and be ready to kill off circuits that dawdle too
long.

Does this make more sense?  If so I'll try to clarify it in the proposal.
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200520144031</emailId><senderName>Support Team</senderName><senderEmail>help@domiosports.com</senderEmail><timestampReceived>2020-05-20 14:40:31-0400</timestampReceived><subject>[tor-dev] tor-dev Digest, Vol 112, Issue 21</subject><body>

[Attachment #2 (multipart/alternative)]


Thank you for the insights.



On Wed, May 20 2020, at 12:00 PM, &lt;tor-dev@lists.torproject.org&gt;

Send tor-dev mailing list submissions to tor-dev@lists.torproject.org To
subscribe or unsubscribe via the World Wide Web, visit
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev or, via
email, send a message with subject or body 'help' to
tor-dev-request@lists.torproject.org You can reach the person managing the
list at tor-dev-owner@lists.torproject.org When replying, please edit your
Subject line so it is more specific than "Re: Contents of tor-dev
digest..." Today's Topics: 1. Re: Proposal 319: RELAY_FRAGMENT cells (Nick
Mathewson) 2. Re: Proposal 320: Removing TAP usage from v2 onion services
(Nick Mathewson) 3. Re: Proposal 320: Removing TAP usage from v2 onion
services (Nick Mathewson) 4. Re: Proposal 320: Removing TAP usage from v2
onion services (Sebastian Hahn)
----------------------------------------------------------------------
Message: 1 Date: Tue, 19 May 2020 13:29:54 -0400 From: Nick Mathewson To:
tor-dev@lists.torproject.org Subject: Re: [tor-dev] Proposal 319:
RELAY_FRAGMENT cells Message-ID: Content-Type: text/plain; charset="UTF-8"
On Thu, May 14, 2020 at 3:15 PM David Goulet wrote: &gt; &gt; On 11 May
(16:47:24), Nick Mathewson wrote: [...] &gt; &gt; # Onion service concerns. &gt; &gt; &gt;
&gt; We allocate a new extension for use in the ESTABLISH_INTRO by onion
services, &gt; &gt; to indicate that they can receive a wide INTRODUCE2 cell.
This extension &gt; &gt; contains: &gt; &gt; &gt; &gt; struct wide_intro2_ok { &gt; &gt; u16
max_len; &gt; &gt; } &gt; &gt; &gt; &gt; We allocate a new extension for use in the
'ESTABLISH_RENDEZVOUS' &gt; &gt; cell, to indicate acceptance of wide
'RENDEZVOUS2' cells. This &gt; &gt; extension contains: &gt; &gt; &gt; &gt; struct
wide_rend2_ok { &gt; &gt; u16 max_len; &gt; &gt; } &gt; &gt; &gt; &gt; (Note that
'ESTABLISH_RENDEZVOUS' cells do not currently have a an &gt; &gt; extension
mechanism. They should be extended to use the same &gt; &gt; extension format as
'ESTABLISH_INTRO' cells, with extensions placed &gt; &gt; after the rendezvous
cookie.) &gt; &gt; Why would a client need to announce wide cells in the
ESTABLISH phase as &gt; opposed to using protover "Relay=N" ? This is not for
announcing support of wide cells -- this is for reporting a setting for how
wide fragmented cells should be. &gt; The maximum length of a fragmented cell
is capped to 2^16 (u16) so we don't &gt; really need the establish process to
inform us of the maximum expected length &gt; but rather use the max_len in
the first fragment? This all comes back to an earlier part of the proposal:
Not all lengths up to 65535 are valid lengths for a fragmented cell. Any
length under 499 bytes SHOULD cause the circuit to close, since that could
fit into a non-fragmented RELAY cell. Parties SHOULD enforce maximum
lengths for cell types that they understand. In other words, I'm imagining
that there is a maximum length for each cell type that is much shorter than
65535, even though we're using two bytes for the length field. The
extension in the establish_intro cell is to tell the intro point the
longest introduce1 cell that it should accept; this extension in the
establish_rend cell is to tell the rendezvous point the longest rendezvous1
cell that it should accept. Another way we could do this would be with a
set of network parameters to describe the maximum length of each fragmented
cell. Do you think that would be simpler? (I can't quite remember why I
specified it this way in the first place.) &gt; Furthermore, ESTABLISH_INTRO
has extensions (only 1 as of today) so they could &gt; also be fragments
themselves and thus I'm not sure I see the point of having &gt; two different
ways of "expecting" fragments for the ESTABLISH_* cells and the &gt;
INTRO/RENDEZVOUS cells? The difference thing here is that everybody can
tell which protocols that a relay supports, but there is no automatic way
to tell which protocols an onion service or client supports. Since
INTRODUCE2/RENDEZVOUS2 cells are handled by these clients, they need to get
opted into by the relays. (I'm not sure I understood the question
completely.) &gt; &gt; # Compatibility &gt; &gt; &gt; &gt; This proposal will require the
allocation of a new 'Relay' protocol version, &gt; &gt; to indicate understanding
of the RELAY_FRAGMENTED command. &gt; &gt; Here is a thought about a DoS vector.
Here goes: &gt; &gt; As an upper limit of 65KB total fragment size, it represents
~126 cells in &gt; total so I could basically send *125* cells and then stop
which will put in &gt; memory a bit more than 64KB and it will stay there
until the last fragment is &gt; received. &gt; &gt; And then I do that on 1000
different circuits bringing the total count in &gt; memory to 64GB. All stuck
there, all "waiting" for the last fragment. &gt; &gt; Our OOM would kick in
killing circuits but it just seems to me a very easy way &gt; to continously
kick the OOM of a _service_ which is pretty bad side channel. A few
responses here: First, we shouldn't allow 65535-byte fragmented cells. The
actual maximum length should be something more like 1024 or 4096 bytes.
Second, we should make sure that when we are reassembling cells, we use the
same buf_t buffers that we use for other stuff. Our buffers are
timestamped, so we can tell which buffer has had data stalling for the
longest, and we should use that to make sure we're killing off the right
circuits preferentially. Third, fragments should only be allowed at an
onion service for INTRODUCE2, and those should only come one at a time from
each introduction point, so the number that it's reassembling at the time
will be limited by the number of intro circuits it has open. It'll be the
the intro points that have to be keeping a bunch of cells in assembly at
once, and be ready to kill off circuits that dawdle too long. Does this
make more sense? If so I'll try to clarify it in the proposal.

[Attachment #5 (text/html)]

&lt;div&gt;Thank you for the insights. &lt;/div&gt;&lt;br&gt;&lt;br&gt;&lt;div class="gorgias_extra"&gt;&lt;br&gt;&lt;div \
class="gorgias_quote"&gt;  On Wed, May 20 2020, at 12:00 PM, 
    
        &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&gt;&lt;/span&gt;  
    &lt;br&gt;
    &lt;blockquote class="gorgias_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt;  Send tor-dev mailing list submissions to
	&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;

To subscribe or unsubscribe via the World Wide Web, visit
	&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;
 or, via email, send a message with subject or body 'help' to
	&lt;a href="mailto:tor-dev-request@lists.torproject.org"&gt;tor-dev-request@lists.torproject.org&lt;/a&gt;


You can reach the person managing the list at
	&lt;a href="mailto:tor-dev-owner@lists.torproject.org"&gt;tor-dev-owner@lists.torproject.org&lt;/a&gt;


When replying, please edit your Subject line so it is more specific
than "Re: Contents of tor-dev digest..."


Today's Topics:

   1. Re: Proposal 319: RELAY_FRAGMENT cells (Nick Mathewson)
   2. Re: Proposal 320: Removing TAP usage from v2 onion services
      (Nick Mathewson)
   3. Re: Proposal 320: Removing TAP usage from v2 onion services
      (Nick Mathewson)
   4. Re: Proposal 320: Removing TAP usage from v2 onion services
      (Sebastian Hahn)


----------------------------------------------------------------------

Message: 1
Date: Tue, 19 May 2020 13:29:54 -0400
From: Nick Mathewson 
To: &lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;
Subject: Re: [tor-dev] Proposal 319: RELAY_FRAGMENT cells
Message-ID:
	
Content-Type: text/plain; charset="UTF-8"

On Thu, May 14, 2020 at 3:15 PM David Goulet  wrote:
&gt;
&gt; On 11 May (16:47:24), Nick Mathewson wrote:
 [...]
&gt; &gt; # Onion service concerns.
&gt; &gt;
&gt; &gt; We allocate a new extension for use in the ESTABLISH_INTRO by onion \
services, &gt; &gt; to indicate that they can receive a wide INTRODUCE2 cell.  This \
extension &gt; &gt; contains:
&gt; &gt;
&gt; &gt;         struct wide_intro2_ok {
&gt; &gt;           u16 max_len;
&gt; &gt;         }
&gt; &gt;
&gt; &gt; We allocate a new extension for use in the 'ESTABLISH_RENDEZVOUS'
&gt; &gt; cell, to indicate acceptance of wide 'RENDEZVOUS2' cells.  This
&gt; &gt; extension contains:
&gt; &gt;
&gt; &gt;         struct wide_rend2_ok {
&gt; &gt;           u16 max_len;
&gt; &gt;         }
&gt; &gt;
&gt; &gt; (Note that 'ESTABLISH_RENDEZVOUS' cells do not currently have a an
&gt; &gt; extension mechanism.  They should be extended to use the same
&gt; &gt; extension format as 'ESTABLISH_INTRO' cells, with extensions placed
&gt; &gt; after the rendezvous cookie.)
&gt;
&gt; Why would a client need to announce wide cells in the ESTABLISH phase as
&gt; opposed to using protover "Relay=N" ?

This is not for announcing support of wide cells -- this is for
reporting a setting for how wide fragmented cells should be.

&gt; The maximum length of a fragmented cell is capped to 2^16 (u16) so we don't
&gt; really need the establish process to inform us of the maximum expected length
&gt; but rather use the max_len in the first fragment?

This all comes back to an earlier part of the proposal:

    Not all lengths up to 65535 are valid lengths for a fragmented
    cell.  Any length under 499 bytes SHOULD cause the circuit
    to close, since that could fit into a non-fragmented RELAY cell.
    Parties SHOULD enforce maximum lengths for cell types that
    they understand.

In other words, I'm imagining that there is a maximum length for each
cell type that is much shorter than 65535, even though we're using two
bytes for the length field.

The extension in the establish_intro cell is to tell the intro point
the longest introduce1 cell that it should accept;  this extension in
the establish_rend cell is to tell the rendezvous point the longest
rendezvous1 cell that it should accept.

Another way we could do this would be with a set of network parameters
to describe the maximum length of each fragmented cell.  Do you think
that would be simpler?

(I can't quite remember why I specified it this way in the first place.)

&gt; Furthermore, ESTABLISH_INTRO has extensions (only 1 as of today) so they could
&gt; also be fragments themselves and thus I'm not sure I see the point of having
&gt; two different ways of "expecting" fragments for the ESTABLISH_* cells \
and the &gt; INTRO/RENDEZVOUS cells?

The difference thing here is that everybody can tell which protocols
that a relay supports, but there is no automatic way to tell which
protocols an onion service or client supports.  Since
INTRODUCE2/RENDEZVOUS2 cells are handled by these clients, they need
to get opted into by the relays.

(I'm not sure I understood the question completely.)

&gt; &gt; # Compatibility
&gt; &gt;
&gt; &gt; This proposal will require the allocation of a new 'Relay' protocol \
version, &gt; &gt; to indicate understanding of the RELAY_FRAGMENTED command.
&gt;
&gt; Here is a thought about a DoS vector. Here goes:
&gt;
&gt; As an upper limit of 65KB total fragment size, it represents ~126 cells in
&gt; total so I could basically send *125* cells and then stop which will put in
&gt; memory a bit more than 64KB and it will stay there until the last fragment is
&gt; received.
&gt;
&gt; And then I do that on 1000 different circuits bringing the total count in
&gt; memory to 64GB. All stuck there, all "waiting" for the last fragment.
&gt;
&gt; Our OOM would kick in killing circuits but it just seems to me a very easy way
&gt; to continously kick the OOM of a _service_ which is pretty bad side channel.

A few responses here:

First, we shouldn't allow 65535-byte fragmented cells.   The actual
maximum length should be something more like 1024 or 4096 bytes.

Second, we should make sure that when we are reassembling cells, we
use the same buf_t buffers that we use for other stuff.  Our buffers
are timestamped, so we can tell which buffer has had data stalling for
the longest, and we should use that to make sure we're killing off the
right circuits preferentially.

Third, fragments should only be allowed at an onion service for
INTRODUCE2, and those should only come one at a time from each
introduction point, so the number that it's reassembling at the time
will be limited by the number of intro circuits it has open.  It'll be
the the intro points that have to be keeping a bunch of cells in
assembly at once, and be ready to kill off circuits that dawdle too
long.

Does this make more sense?  If so I'll try to clarify it in the proposal.
    &lt;/blockquote&gt;
&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200524231601</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar@torproject.org</senderEmail><timestampReceived>2020-05-24 23:16:01-0400</timestampReceived><subject>Re: [tor-dev] So Windows is Adding a Package Manager.....</subject><body>

[Attachment #2 (multipart/alternative)]


Welcome Microsoft, to the cutting edge of the 90s! ;P

Kidding aside this could be a great improvement. I'm rooting for them. This
is constrained to Windows installers (exe or msi) but hopefully they expand
this in the future. Distributing interpreted applications (python, ruby,
etc) have always been a PITA. If they make a first rate package manager
like apt or yum this could dramatically improve distributability to their
platform.

Thanks for pointing this out. We distribute Tor Browser as an exe so that
certainly could be a good candidate.


On Sun, May 24, 2020 at 3:55 PM Keifer Bly &lt;keifer.bly@gmail.com&gt; wrote:

&gt;
&gt;
&gt; Hi all,
&gt;
&gt;
&gt;
&gt; So based on this article here,
&gt;
&gt;
&gt;
&gt; https://docs.microsoft.com/en-us/windows/package-manager/
&gt;
&gt;
&gt;
&gt; Windows is getting a package manager in the near future,  including
&gt; winget, a Linux like tool that can install and manage packages. With this
&gt; in might  it be possible to add tor as a manageable package for Windows
&gt; (for auto upgrades, install via this method, etc.)?
&gt;
&gt;
&gt;
&gt; Thx.
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; Sent from Mail &lt;https://go.microsoft.com/fwlink/?LinkId=550986&gt; for
&gt; Windows 10
&gt;
&gt;
&gt;
&gt;
&gt; ------------------------------
&gt; [image: Avast logo] &lt;https://www.avast.com/antivirus&gt;
&gt;
&gt; This email has been checked for viruses by Avast antivirus software.
&gt; www.avast.com &lt;https://www.avast.com/antivirus&gt;
&gt;
&gt; &lt;#m_7575364686860156035_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;Welcome Microsoft, to the cutting edge of the 90s! \
;P&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Kidding aside this could be a great improvement. I'm \
rooting for them. This is constrained to Windows installers (exe or msi) but \
hopefully they expand this in the future. Distributing interpreted applications \
(python, ruby, etc) have always been a PITA. If they make a first rate package \
manager like apt or yum this could dramatically improve distributability to their \
platform.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks for pointing this out. We distribute \
Tor Browser as an exe so that certainly could be a good \
candidate.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Sun, May 24, 2020 at 3:55 PM Keifer Bly &lt;&lt;a \
href="mailto:keifer.bly@gmail.com"&gt;keifer.bly@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div lang="EN-US"&gt;&lt;div \
class="gmail-m_7575364686860156035WordSection1"&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  \
&lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;Hi all,&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  \
&lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;So based on this article here,&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;a \
href="https://docs.microsoft.com/en-us/windows/package-manager/" \
target="_blank"&gt;https://docs.microsoft.com/en-us/windows/package-manager/&lt;/a&gt;&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;Windows is getting a \
package manager in the near future,   including winget, a Linux like tool that can \
install and manage packages. With this in might   it be possible to add tor as a \
manageable package for Windows (for auto upgrades, install via this method, etc.)?   \
&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;Thx.&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;Sent from &lt;a \
href="https://go.microsoft.com/fwlink/?LinkId=550986" target="_blank"&gt;Mail&lt;/a&gt; for \
Windows 10&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/p&gt;&lt;/div&gt;&lt;div \
id="gmail-m_7575364686860156035DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2"&gt; &lt;br&gt;&lt;br&gt;
&lt;hr style="border:medium \
none;color:rgb(144,144,144);background-color:rgb(176,176,176);height:1px;width:99%"&gt; \
&lt;table style="border-collapse:collapse;border:medium none"&gt;  &lt;tbody&gt;&lt;tr&gt;
		&lt;td style="border:medium none;padding:0px 15px 0px 8px"&gt;
			&lt;a href="https://www.avast.com/antivirus" target="_blank"&gt;
				&lt;img alt="Avast logo" border="0"&gt;
			&lt;/a&gt;
		&lt;/td&gt;
		&lt;td&gt;
			&lt;p style="color:rgb(61,77,90);font-family:"Calibri","Verdana","Arial","Helvetica";font-size:12pt"&gt;
  This email has been checked for viruses by Avast antivirus software.
				&lt;br&gt;&lt;a href="https://www.avast.com/antivirus" target="_blank"&gt;www.avast.com&lt;/a&gt;
			&lt;/p&gt;
		&lt;/td&gt;
	&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;br&gt;
&lt;a href="#m_7575364686860156035_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2" width="1" \
height="1"&gt; &lt;/a&gt;&lt;/div&gt;&lt;/div&gt; _______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200525192312</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-05-25 19:23:12-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Christian Hofer:
&gt; The thread model is DNS hijacking. Yes, you can prevent DNS hijacking
&gt; using DoH if you *trust* the resolver you connect to. However, if you
&gt; want to verify authenticity and integrity of DNS responses you need
&gt; DNSSEC.

Could you elaborate on the use-case since DNS record authenticity is often just a \
vehicle to bootstrap some other use-case (for example DANE). What higher level \
use-case do you have in mind where authenticity of DNS entries provides a value for \
tor / Tor Browser users?

What I'm trying to get to: 
Authentic IP addresses from A/AAAA records are probably of limited value in the \
context of a tor  client since the exit relay has full control over the routing \
anyway. If the tor clients asks the exit relay to connect to IP A (which is the \
actual DNSSEC validated IP address) there is nothing that can stop an exit from \
routing it to some other IP address.

That is why I'm trying to get to the bottom of your DNSSEC use-case.

To avoid anonymity set reductions I'm also primarily interested in enabled by default \
designs (in contrast to opt-in) which brings you to the next problems: performance, \
scaleability and resolver selection.

Please don't let me discourage you with my questions, they are not meant to.
Just trying to understand and hopefully find some common ground to move forward since \
I see a rather motivated person and it would be a pity to loose that opportunity.  

My vision for DNS privacy in Tor Browser: 
Be able to visit a HTTPS website without the exit relay learning what domain it was 
(encrypted DNS + encrypted SNI)

There are a few issues to solve along that path. 

kind regards,
nusenu


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200527191511</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-27 19:15:11-0400</timestampReceived><subject>[tor-dev] Proposal 321: Better performance and usability for the MyFamily option (v2)</subject><body>

```
Filename: 321-happy-families.md
Title: Better performance and usability for the MyFamily option (v2)
Author: Nick Mathewson
Created: 27 May 2020
Status: Open
```

## Problem statement.

The current family mechanism allows well-behaved relays to
identify that they all belong to the same 'family', and should
not be used in the same circuits.

Right now, families work by having every family member list every
other family member in its server descriptor.  This winds up using
O(n^2) space in microdescriptors and server descriptors. (For RAM,
we can de-duplicate families which sometimes helps.)  Adding or
removing a server from the family requires all the other servers to
change their torrc settings.

The is growth in size is not just a theoretical problem. Family
declarations currently make up a little over 55% of the
microdescriptors in the directory--around 24% after compression.
The largest family has around 270 members.  With Walking Onions, 270
members times a 160-bit hashed identifier leads to over 5 kilobytes
per SNIP, which is much greater than we'd want to use.

This is an updated version of proposal 242.  It differs by clarifying
requirements and providing a more detailed migration plan.

## Design overview.

In this design, every family has a master ed25519 "family key".  A node
is in the family iff its server descriptor includes a certificate of its
ed25519 identity key with the family key.  The certificate
format the one in the tor-certs.txt spec; we would allocate a new
certificate type for this usage.  These certificates would need to
include the signing key in the appropriate extension.

Note that because server descriptors are signed with the node's
ed25519 signing key, this creates a bidirectional relationship
between the two keys, so that nodes can't be put in families without
their consent.

## Changes to router descriptors

We add a new entry to server descriptors:

    "family-cert" NL
    "-----BEGIN FAMILY CERT-----" NL
    cert
    "-----END FAMILY CERT-----".

This entry contains a base64-encoded certificate as described
above.  It may appear any number of times; authorities MAY reject
descriptors that include it more than three times.

## Changes to microdescriptors

We add a new entry to microdescriptors: `family-keys`.

This line contains one or more space-separated strings describing
families to which the node belongs.  These strings MUST be sorted in
lexicographic order.  Clients MUST NOT depend on any particular property
of these strings.

## Changes to voting algorithm

We allocate a new consensus method number for voting on these keys.

When generating microdescriptors using a suitable consensus method,
the authorities include a "family-keys" line if the underlying
server descriptor contains any valid family-cert lines.  For each
valid family-cert in the server descriptor, they add a
base-64-encoded string of that family-cert's signing key.

&gt; See also "deriving family lines from family-keys?" below for an
&gt; interesting but more difficult extension mechanism that I would
&gt; not recommend.

## Relay configuration

There are several ways that we could configure relays to let them
include family certificates in their descriptors.

The easiest would be putting the private family key on each relay,
so that the relays could generate their own certificates.  This is
easy to configure, but slightly risky: if the private key is
compromised on any relay, anybody can claim membership in the
family.  That isn't so very bad, however -- all the relays would
need to do in this event would be to move to a new private family
key.

A more orthodox method would be to keep the private key somewhere
offline, and using it to generate a certificate for each relay in
the family as needed.  These certificates should be made with
long-enough lifetimes, and relays should warn when they are going to
expire soon.

## Changes to relay behavior

Each relay should track which other relays they have seen using the
same family-key as itself.  When generating a router descriptor,
each relay should list all of these relays on the legacy 'family'
line.  This keeps the "family" lines up-to-date with "family-keys"
lines for compliant relays.

Relays should continue listing relays in their family lines if they
have seen a relay with that identity using the same family-key at
any time in the last 7 days.

The presence of this line should be configured by a network
parameter, `derive-family-line`.

Relays whose family lines do not stay at least mostly in sync with
their family keys should be marked invalid by the authorities.

## Client behavior

Clients should treat node A and node B as belonging to the same
family if ANY of these is true:

* The client has descriptors for A and B, and A's descriptor lists B
  in its family line, and B's descriptor lists A in its family line.

* Client A has descriptors for A and B, and they both contain the
  same entry in their family-keys or family-cert.

## Migration

For some time, existing relays and clients will not support family
certificates.  Because of this, we try to make sure above the
well-behaved relays will list the same entries in both places.

Once enough clients have migrated to using family
certificates, authorities SHOULD disable `derive-family-line`.

## Security

Listing families remains as voluntary in this design as in today's
Tor, though bad-relay hunters can continue to look for families that
have not adopted a family key.

A hostile relay family could list a "family" line that did not match
its "family-certs" values.  However, the only reason to do so would
be in order to launch a client partitioning attack, which is
probably less valuable than the kinds of attacks that they could run
by simply not listing families at all.

## Appendix: deriving family lines from family-keys?

As an alternative, we might declare that _authorities_ should keep
family lines in sync with family-certs.  Here is a design sketch of
how we might do that, but I don't think it's actually a good idea,
since it would require major changes to the data flow of the
voting system.

In this design, authorties would include a "family-keys" line in
each router section in their votes corresponding to a relay with any
family-cert.  When generating final microdescriptors using this
method, the authorities would use these lines to add entries to the
microdescriptors' family lines:

1. For every relay appearing in a routerstatus's family-keys, the
   relays calculate a consensus family-keys value by listing including
   all those keys that are listed by a majority of those voters listing
   the same router with the same descriptor.  (This is the algorithm we
   use for voting on other values derived from the descriptor.)

2. The authorities then compute a set of "expanded families": one
   for each family key.  Each "expanded family" is a set containing
   every router in the consensus associated with that key in its consensus
   family-keys value.

3. The authorities discard all "expanded families" of size 1 or
   smaller.

4. Every router listed for the "expanded family" has every other
   router added to the "family" line in its microdescriptor.  (The
   "family" line is then re-canonicalized according to the rules of
   proposal 298 to remove its )

5. Note that the final microdescriptor consensus will include the
   digest of the derived microdescriptor in step 4, rather than the
   digest of the microdescriptor listed in the original votes.  (This
   calculation is deterministic.)

The problem with this approach is that authorities would have to s
to fetch microdescriptors they do not have in order to replace their
family lines.  Currently, voting never requires an authority to
fetch a microdescriptor from another authority.  If we implement
vote compression and diffs as in the Walking Onions proposal,
however, we might suppose that votes could include microdescriptors
directly.

Still, this is likely more complexity than we want for a transition
mechanism.

## Appendix: Deriving family-keys from families??

We might also imagine that authorities could infer which families
exist from the graph of family relationships, and then include
synthetic "family-keys" entries for routers that belong to the same
family.

This has two challenges: first, to compute these synthetic family
keys, the authorities would need to have the same graph of family
relationships to begin with, which once again would require them to
include the complete list of families in their votes.

Secondly, finding all the families is equivalent to finding all
maximal cliques in a graph.  This problem is NP-hard in its general
case.  Although polynomial solutions exist for nice well-behaved
graphs, we'd still need to worry about hostile relays including
strange family relationships in order to drive the algorithm into
its exponential cases.

## Appendix: New assigned values

We need a new assigned value for the certificate type used for
family signing keys.

We need a new consensus method for placing family-keys lines in
microdescriptors.

## Appendix: New network parameters

* `derive-family-line`: If 1, relays should derive family lines from
  observed family-keys.  If 0, they do not. Min: 0, Max: 1. Default: 1.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200527191552</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-05-27 19:15:52-0400</timestampReceived><subject>[tor-dev] Proposal 322: Extending link specifiers to include the directory port</subject><body>

```
Filename: 322-dirport-linkspec.md
Title: Extending link specifiers to include the directory port
Author: Nick Mathewson
Created: 27 May 2020
Status: Open
```

## Motivation

Directory ports remain the only way to contact a (non-bridge) Tor
relay that isn't expressible as a Link Specifier.  We haven't
specified a link specifier of this kind so far, since it isn't a way
to contact a relay to create a channel.

But authorities still expose directory ports, and encourage relays
to use them preferentially for uploading and downloading.  And with
Walking Onions, it would be convenient to try to make every kind of
"address" a link specifier -- we'd like want authorities to be able
to specify a list of link specifiers that can be used to contact
them for uploads and downloads.

&gt; It is possible that after revision, Walking Onions won't need a way
&gt; to specify this information.  If so, this proposal should be moved
&gt; to "Reserve" status as generally unuseful.

## Proposal

We reserve a new link specifier type "dir-url", for use with the
directory system.  This is a variable-length link specifier, containing
a URL prefix.  The only currently supported URL schema is "http://".
Implementations SHOULD ignore unrecognized schemas.  IPv4 and IPv6
addresses MAY be used directory; hostnames are also allowed.
Implementations MAY ignore hostnames and only use raw addresses.

The URL prefix includes everything through the string "tor" in the
directory hierarchy.

A dir-url link specifier SHOULD NOT appear in an EXTEND cell;
implementations SHOULD reject them if they do appear.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200529132510</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-29 13:25:10-0400</timestampReceived><subject>Re: [tor-dev] Proposal 320: Removing TAP usage from v2 onion services</subject><body>

[Attachment #2 (multipart/signed)]


On 19 May (13:55:37), Nick Mathewson wrote:
&gt; On Wed, May 13, 2020 at 10:09 AM David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt; &gt;
&gt; &gt; On 11 May (16:47:53), Nick Mathewson wrote:

[snip]

&gt; &gt; So thus, I personally will argue that moving v2 to ntor is really not the
&gt; &gt; right thing to do. Onion service v2 are, at this point in time, _dangerous_
&gt; &gt; choice for the users.

[snip]

&gt; 
&gt; The main reason I wrote this proposal is this: Any deprecation will
&gt; probably cause a few users to stick with the old versions of the code
&gt; for as long as they still work on the network, even if those versions
&gt; become unsupported and insecure.  (After all, people who listen to our
&gt; advice about what is secure and what isn't have already stopped using
&gt; v2 onion services.) .

I don't believe at any point since v3 is stable we made public statement
through our TPO channels that v2 should not be used anymore.

&gt; 
&gt; Is it time to start this deprecation?  If so we need to start working
&gt; on a timeline, and I agree with Teor that we'd need to figure out how
&gt; that timeline would work with any walking onions timeline.

One easy timeline here would be "No v2 support in walking onions means
deprecation for v2 by the time the entire network updates".

But apart from that, yes we should work on a timeline and it should not be a
complicated one nor eternally long to deploy.

&gt; 
&gt; One possible role for this proposal is to be kept in reserve, in case
&gt; somebody feels so strongly that they want v2 services to work that
&gt; they want to maintain them themselves, or pay for somebody else to do
&gt; it.  If so, we can indicate this proposal as "the right way to keep v2
&gt; services working without TAP", make it clear that we don't plan to
&gt; implement it, and move along.

Honestly, I really don't think we should even provide or mention a possible
path with an option where v2 can stay alive...

Regardless of threat modelling or v2 use cases or large community of users,
the basic fact that the crypto is *dangerously* out of date with RSA1024 and
truncated SHA-1 is just something we have to _stop_ using. I see this not only
about TAP.

I'll say it and say it again and again, today, in 2020, v2 is _dangerous_ and
it is our responsibility at this point to make sure it goes away sooner than
later for the safety of Tor's users.

Cheers!
David


-- 
2dLUG6IluthaObnf5+xfKeuu4WDC9xYQHzFNeGRqvzw=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200529134151</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-05-29 13:41:51-0400</timestampReceived><subject>Re: [tor-dev] Moving key material out of the main tor process</subject><body>

[Attachment #2 (multipart/signed)]


On 20 May (17:45:51), Linus Nordberg wrote:
&gt; Hi,

Greeting Linus!

&gt; 
&gt; tl;dr How to move key material out of tor?
&gt; 
&gt; ## The idea of a vault component
&gt; 
&gt; ahf and others in the network team have been discussing the
&gt; possibility of a "vault" component in tor, for moving private keys out
&gt; of the tor process. Separating secret key material from the code
&gt; handling data from the network seems valuable and providing a
&gt; component making different implementations "pluggable" would allow for
&gt; anyone to use their favourite technology without touching the tor
&gt; code base. Examples are local trusted execution environments like Intel
&gt; SGX and Arm TrustZone and various HSM's and security keys/tokens.
&gt; 
&gt; One way of implementing this would be to define a protocol, for a
&gt; vault component to talk to a daemon running on the same host as tor,
&gt; over some IPC mechanism. This protocol would allow tor to request a
&gt; signature over a hash, or a document, in a certain key. Whether the
&gt; daemon has access to the key material or has to forward the request to
&gt; a separate device or hardware component is irrelevant to the protocol
&gt; and the vault component.
&gt; 
&gt; Even if the design focuses on signatures it should probably take
&gt; encryption and decryption into account, to be added later.

Love it.

&gt; 
&gt; 
&gt; ## The vault as a possible match for TorHSM
&gt; 
&gt; Such a vault component would fit well with a project where Peter Stuge
&gt; and myself are building an HSM for Tor directory authority signing
&gt; keys [0] based on the CrypTech design [1].
&gt; 
&gt; [0] https://trac.cryptech.is/wiki/ExternalProjectsTorHSM
&gt; [1] https://cryptech.is/
&gt; 
&gt; One of the options for tor to delegate the signing of votes and
&gt; consensuses to such a device would be to use a vault component as
&gt; described above. We would then have a signing daemon responsible for
&gt; the USB communication with the TorHSM device. Another option would be
&gt; to build support directly into tor for communicating with the device,
&gt; through a library capable of a USB vendor specific protocol defined by
&gt; TorHSM.
&gt; 
&gt; There are pros and cons with both options. I'd like to hear what the
&gt; Tor developers community think would be best.
&gt; 
&gt; 
&gt; ## Asynchronous signing API
&gt; 
&gt; Vault or not, tor needs to change the way signing is done to be able
&gt; to move key material out of the main process. First, external devices
&gt; may need more time to perform a signature operation than what tor can
&gt; accept to spend blocking in its main thread. Second, an external
&gt; device might disappear or malfunction, requiring the possibility for
&gt; an operation to time out.
&gt; 
&gt; This can be implemented either with callbacks or with a state machine
&gt; with more well defined state transitions. Maybe there are more
&gt; options that I didn't think of.

Right, I don't think this is any show stopper here. Signing with the long term
key material is not something that don't happens "often" and so adding delays
to it is probably negligible in the grand scheme of things.

&gt; 
&gt; ## Protocol choice
&gt; 
&gt; If we decide to go for the vault component with a separate daemon we
&gt; should consider using the ssh-agent protocol for tor to talk to the
&gt; daemon. Apart from being already defined there are multiple well
&gt; tested implementations of this protocol. It also has a couple of
&gt; features we might want, such as forgetting a certain key and
&gt; locking/unlocking of the vault. Finally, it's extensible and should
&gt; accommodate potential additions we might want to make later.

That is a _great_ idea in my opinion. It is robust, maintained by serious
people/project and did through the test of time!

I'm very excited about this "proposal" especially for relays and dirauth.

However, I do wonder about onion services here because one difference here is
that for v3 onion service offline key to work, the operator needs to derive a
series of keys (blinded keys) from the master key which implies secret key
material access so maybe something we could discuss with HSM token designer
that is this concept of "key derivation" from the secret material. And who
knows, maybe they have?

Cheers!
David

-- 
2dLUG6IluthaObnf5+xfKeuu4WDC9xYQHzFNeGRqvzw=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200401034824</emailId><senderName>meejah</senderName><senderEmail>meejah@meejah.ca</senderEmail><timestampReceived>2020-04-01 03:48:24-0400</timestampReceived><subject>[tor-dev] txtorcon 20.0.0</subject><body>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

I'm pleased to announce txtorcon 20.0.0. This fixes a few bugs and
officially deprecates Python 2 support.

 * Use real GeoIP database or nothing (https://github.com/meejah/txtorcon/issues/250)
 * Change abstract base classes import in preperation for Python 3.8 (thanks @glowatsk)
 * Python 3.4 is no longer supported
 * Python 2 is deprecated; all new code should be Python 3. Support
   for Python 2 will be removed in a future release.

You can download the release from PyPI or GitHub (or of
course "pip install txtorcon"):

  https://pypi.python.org/pypi/txtorcon/20.0.0
  https://github.com/meejah/txtorcon/releases/tag/v20.0.0

Releases are also available from the hidden service:

  http://timaq4ygg2iegci7.onion/txtorcon-20.0.0.tar.gz
  http://timaq4ygg2iegci7.onion/txtorcon-20.0.0.tar.gz.asc

Or via a "version 3" service:

  http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-20.0.0.tar.gz
  http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-20.0.0.tar.gz.asc

You can verify the sha256sum of both by running the following 4 lines
in a shell wherever you have the files downloaded:

cat &lt;&lt;EOF | sha256sum --check
122cd081786396f57718adda1c1a5eb01b8e9a4832fcd140918b45c10359377a  txtorcon-20.0.0.tar.gz
5c1145566a8733105da851b794e7b15cb56cea48693635b55c4bddfb79fe629d  txtorcon-20.0.0-py2.py3-none-any.whl
EOF

thanks,
meejah
-----BEGIN PGP SIGNATURE-----

iQFFBAEBCgAvFiEEnVor1WiOy4id680/wmAoAxKAaacFAl6EDnURHG1lZWphaEBt
ZWVqYWguY2EACgkQwmAoAxKAaadv4AgAkIny/Pt55kEppkxlqu4/B4ddfU7oQNLD
8lwoYyUZbYtS8XwiBaqY6SR/UU9MhhswdoPU50WBq3h4Im+3jrmm7MbVD4uR6Uvt
BnZIMzCJlQNcGpfbaGmtyrtbBNazQLTDOAxxQ7WM/MD8rip1zlP8MeL7yBgE3VEC
JInw9DWN+fbQhbsTQgdiLLLhBXOFqZuXgz7auPnGzu+5LsIeJd6ZnWzuQ6TlzL3R
rLgrMAasxTMzKoJB51jmDpCOeaj4b68XK+MY130/xSdENb2ZyGbuSF4LpZUjs4RU
Sqiwtevu/bT/th0XBqcg79RHnwGLK/g1pJRB27RaOVbuh6f+lENc4Q==
=4q9v
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200401100641</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-01 10:06:41-0400</timestampReceived><subject>Re: [tor-dev] Chutney tests fail for tor/maint-0.3.5 (bug #33677)</subject><body>

[Attachment #2 (multipart/signed)]


Hi Caitlin,

&gt; On 1 Apr 2020, at 18:58, c &lt;c@chroniko.jp&gt; wrote:
&gt; 
&gt; On Mon, 30 Mar 2020 13:22:21 +1000
&gt; teor &lt;teor@riseup.net&gt; wrote:
&gt; 
&gt;&gt; Check for onion service descriptor uploads:
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/33609
&gt;&gt; 
&gt;&gt; Someone else is working on the microdescriptor changes at the moment.
&gt;&gt; 
&gt;&gt; Would you like to start working on the onion service descriptor changes?
&gt; 
&gt; Sure, it would give me an opportunity to learn about onion descriptors
&gt; in more detail. I will get started on it.
&gt; 
&gt; But first, looking at it more, I think my struggle with understanding
&gt; what to do stems from my unfamiliarity with the Chutney codebase (first
&gt; I have heard of the tool was with this project, even though commits
&gt; date back to 2011).

Chutney is a custom tool that we use to integration test tor networks.

&gt; I need to make sure I understand #33609
&gt; sufficiently:
&gt; 
&gt; - Is the requested functionality only for Chutney or will Tor
&gt;  potentially need any changes to allow for HS verification?

The required messages are already in tor's onion service logs, so I don't
think that tor will need any changes.

I tried to describe the changes in detail on the ticket:
https://trac.torproject.org/projects/tor/ticket/33609#comment:5

Please let me know if you have any further questions. We're talking in a
lot of detail now, so let's continue on the ticket. That way, any
reviewers can also see the conversation.

&gt; - So I know where to begin looking in the codebase, the ticket wants us
&gt;  to "check each onion service log" -- is this referring to Tor log
&gt;  output (such as the instances chutney spawns), chutney-specific logs,
&gt;  or something else entirely?

The info-level log output of the tor instances that chutney spawns.

&gt; - For "check v2 and v3 onion services" -- check if they've propagated
&gt;  the network?

Check if v2 and v3 onion services have uploaded their descriptors.

&gt; - For "call it an extra 200% 'bootstrap' stage" -- again is this
&gt;  chutney-specific? I only know bootstrapping percentage from Tor
&gt;  notice-level logging and obviously it only goes up to 100%, so I'm
&gt;  wondering if "200%" is a magic number here or something arbitrary.

It's an arbitrary number, greater than 100%, so we can integrate it
with the existing bootstrap checks. (But that might not be necessary.)

&gt; From this and the parent #33050 it doesn't seem to me like the request
&gt; is very clear.

You're right, the ticket contains my rough notes and hints. I didn't
know what level of detail people would need.

&gt; I am reading proposals 311-313 after sending this
&gt; message so maybe I can come across some answers to my
&gt; questions/confusions via the proposals themselves. The proposals will
&gt; probably give me a better idea of the work I am in for overall, too,
&gt; and perhaps I should have come across them sooner.

The proposals might help, but they are mainly focused on tor changes,
not chutney changes.

&gt; I figure it is wise
&gt; regardless to ask for clarification here and read while I wait for
&gt; feedback. Efficiency and all :)

Please feel free to ask further questions on this list. But let's try
to have detailed discussions on the relevant tickets, so reviewers can
see the conversation.

Thanks!

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6EZ7EACgkQEP6qDnB1
Zyo+nRAAvFjyj4eFw6hIWid2uJdUyq7siAhXSdHs9P+IACb0A2QZdow3t+vE+tDE
EmDK+0yEwUs0Okh1ODXt73NPUIJrveo6Hs1I64BLaAzKgIQPVQ1vBx2nxFPiQTbm
WdvIQlvYQE5LA9mNCrDyuBskMYeR01DMYT2PrYVgHN17CMtMh2WUskgJ0JX1+gL5
CAPzNycfOU6ZmvSvnIJqew/w3uBU2SZHgrwDOSDx8/ckCGTMakWm9opsB/DHJGNc
QOxwP8YUIw/JJh+HlORZ7Ax1gqIgNhsQD8Z0gMlTQM1h7BQcpNJMM186+ovcGTzu
QMyBx18y8/3iw45qsyRYTXpXSkO4dSO+ELVjbWLn63uDu+wOuppcofl8gmw0XARV
JHqJjqcDmz836B7mpARj10QUoZq55FjrxOfiADqN64vyN0gOQXZb0Ir1QCX1qRxu
Y5d1W4TzUCoz0Sv4d1RsQScgKQJjsZMzzPc0q0PJDTiNomRjKxmmHpDNHh6um7jy
t1SCHHtTUhEXz/UasRUxvKDDfVIOSwj6bsEzGtOm8+iKeKAXyDCvNEmR0AD/odp0
i8tjlmpW7Z3vo2oMTMYHyEt65BH31QZ4jp8XZVQ0Oi+pkAKR9O7K4SqJdRqeRWiz
NV8W4x1g+XAL7sD96u3cj/FVosb1sFtoatBUi5eh2T5rsaw01Go=
=9OOO
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200406200340</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-06 20:03:40-0400</timestampReceived><subject>[tor-dev] Walking onions status update: week 5 notes</subject><body>

Walking Onions: week 5 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html


This week found me still rather distracted by fallout from current
events and preparations for more isolation at home.  I didn't get a
complete rewrite done.  But I do, however, think I figured out voting.

== The big idea for voting

Our current system for voting on relay properties is fairly piecemeal:
every property has its own independent specification in dir-spec.txt
[DIRSPEC], which can get kind of cumbersome.

Every time we have a new property to specify, if it can't be defined as
a flag, we need to define a new consensus method that puts it in the
consensus or the microdescriptors.  Until authorities have upgraded to
support the new method, they can't sign consensuses generated with it,
since they don't know how those consensuses are generated.

We can solve both problems by defining "vote tabulation" as a set of
parameterized operations operating over a set of CBOR inputs.
Individual operations can be simple, like "Take the median of all
integer votes", or progressively more complex.

What's more, we can specify these voting operations themselves as data,
which gives us more advantages: First, that we no longer need
independent English-language specs for each field in the consensus--and
second, that we can introduce new voting rules or change the existing
ones without adding new code.  As long as a quorum of authorities agree
about the rules for voting on some field, the other authorities can
safely follow those rules, and include the new field in the consensus
ENDIVE and SNIPs.  We would only need to introduce new consensus methods
when we wanted to introduce support for an entirely new operation.

After voting is done, some transformations are needed to transform the
objects it produces.  SNIP signatures need to be signed, indexes built,
and so on.  I've left this unspecified for now, since I am likely to
return to the SNIP and ENDIVE formats again in the coming weeks, and
I'll want to tweak the transformation quite a lot.

This is not something I would want to implement in C.  Rust would be a
better fit -- or some functional language.  Fortunately, only
authorities need to follow this algorithm.

I have initial specifications written for these operations that I
believe are sufficient (or nearly so?) for all the things that we do in
voting now.  These are in the draft voting spec as it stands [VOTING].
I expect that they are full of errors, but I wouldn't be too concerned
right now; I'm going to need to do another pass over them, but I want to
return to voting a bit later (see below) once I have more SNIP uses
specified.

== Backward compatibility in voting

There are two separate backward compatibility issues in voting.

The first issue is easier: how to operate when we aren't sure whether
all the authorities have upgraded to support this new voting format.
For this purpose, I'm including legacy votes as part of the new vote
format, signatures and all.  This will make the new votes bigger until
all the authorities have definitely upgraded, but other changes (voting
diffs and compression) should offset this risk.  We can stop sending
legacy votes when everybody has upgraded.

(I thought about having an "implicit version" of each legacy vote
derived from the new vote, but that seemed riskier, and like it would
involve lots more new code of dubious benefit.)

The second issue is a bit harder: for clients that haven't upgraded to
walking onions, we'll need to generate legacy consensus documents for a
some time.  This doesn't need to follow exactly the same rules as
consensus voting uses today:  instead we should have legacy consensus
documents derived from the CBOR consensus, so that we only need to
maintain one voting algorithm long term.

I've left this part unspecified for now too; I'll be comping back to it
after a round of revisions and SNIP usage design.

== Next steps

I plan to spend the first part of week going over what I've written so
far and trying to make it correct and consistent, and to fill in the
baps that I have.  After that, I'm planning to write the example sections
for how circuit extension works.  If time remains, this is when I
finally move on to section 6 of the proposal, which will be pretty
involved -- I've got to explain how to implement all (or most?) of our
current client behavior using walking onions, and what that implies
about the set of indexes and fields in our documents.

== Other updates

Our paper got into USENIX Security 2020!  (This is the paper about
Walking Onions that Chelsea Komlo and Ian Goldberg wrote with me.  It
has basically the same content as our existing tech report [TECHREPORT].)
The conference is scheduled in mid-August, in Boston: we'll see whether
people are gathering in groups by then.  If not, I imagine we'll be
putting together some kind of video.

[DIRSPEC] https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt

[TECHREPORT] https://crysp.uwaterloo.ca/software/walkingonions/

[VOTING] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/03-voting-and-authorities.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200410202608</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-10 20:26:08-0400</timestampReceived><subject>[tor-dev] Walking onions status update: week 6 notes</subject><body>

Walking Onions: week 6 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try
to send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html

Week 5:
   Voting (part 2)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014218.html


This week I did a pass through all of the proposal that's written so
far, trying to revise it for consistency and to look for unexpected
gaps. Then I wrote a first take on a section about client behavior,
and outlined sections about how to keep onions services working.

== Fixing inconsistencies

There were, predictably, some places where I had wrote things in an
introduction to a section, and then turn around and did them
differently later in the section.  I tried to make those consistent
when I could.

For one example, I think Microdescs should now be embedded in votes.
They were separate before, for space reasons, but now that we have
defined support for compression and diffs in voting, we don't need
to keep votes as small as we did before.  But when I went to explain
voting, I didn't actually give a place to put in microdescriptors.
This is fixed now.

== Example rules, and changes to voting.

Thanks to Teor's help and feedback on previous iterations of voting,
the voting operations [VOTING] are now more consistent, and
specified more consistently.  I had to describe a "sorting"
operation for use with voting, since CBOR's default "canonical"
ordering is not what we actually want semantically.

To try to make sure voting could do what we need, I wrote up an
example VotingRules object in a new appendix [EXRULES].  This turned
up a few impedance mismatches between the available voting rules,
the SNIP format, and the ENDIVE format.  I fixed some of these, and
marked others with "XXX" strings to come back and fix on the next
pass through voting.

== More index and extension protocol work

I've found a need for a new link specifier (LS) for use with onion
services.  Unlike a regular routing index LS, this kind includes a
routing index and a count of how many relays to skip after that
position.  This lets a client say, for example, "Give me the third
relay after the one whose HDirIndex is 0xbf9630".  (In order to
answer this query, the extending relay needs to return not only the
SNIP for the third relay, but all SNIPs between the first relay and
that relay, so that the client can trust the answer.)

This kind of LS can be used with the new NIL handshake if the client
_only_ wants to fetch the descriptors; the details are in the
circuit-protocol section [EXTENDING].

== Client operations, part 1

In a new section 06, I've sketched out solutions for guards,
bridges, bootstrapping, and several kinds of path restriction
[CLIENTS]. In doing so I've turned up a possible need for new
IP-based and key-based indices; I've added those to a new appendix
where I'm listing the different indices I think we'll need
[INDEXLIST].

== Outlines of work to come

I've added outlines for a new section 7 about making onion services
work, and a new section 8 about tracking some new ways that relays
might have to misbehave.  I've also added quick sketches for a pair
of additional proposals we'll need: one for a better family
notation, and one for finally migrating away from the last vestiges
of TAP.

But none of those are quite next: In the coming week, if time
permits, I want to get exit policies figured out.  They are the
biggest missing piece of section 06 right now, and seem to me to be
the biggest remaining gap in the specification.

== Fun facts:

At 109KiB, this is now the longest Tor proposal ever.  I will need
to come up with a different fun fact next week.


== References:

[CLIENTS] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/06-clients-behavior.md

[EXTENDING] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/05-extending-circuits.md

[EXRULES] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/AF-example-rules.md

[INDEXLIST] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/AG-index-list.md

[VOTING] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/03-voting-and-authorities.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200414131805</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-04-14 13:18:05-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: A First Take at PoW Over Introduction Circuits</subject><body>

&gt; Hello list,
&gt; 
&gt; hope everyone is safe and doing well!
&gt; 
&gt; I present you an initial draft of a proposal on PoW-based defences for
&gt; onion services under DoS.
&gt; 

Hello again,

many thanks for all the thoughtful feedback!

In the end of this email I inline a new version of the proposal
addressing various issues discussed over IRC and on this thread.
Here is a rough changelog:

- Specifying some features we might want from "v1.5".
- Adding suggested-effort to the descriptor.
- Specifying the effort() function.
- Specifying the format of the expiration time.
- Adding a protocol-specific label to the PoW computation.
- Removing the seed and output values from the INTRODUCE1 cell.
- Specifying what happens when a client does not send a PoW token when PoW is \
                enabled.
- Revamping the UX section.
- Added Mike and David in the authors list.

I'm also pushing the spec to my git repo so that you can see a diff:
    https://github.com/asn-d6/torspec/tree/pow-over-intro

Now before going in to the proposal here are the three big topics currently
under discussion in the thread:

== How the scheduler should work ==

   I'm not gonna touch on this, since David is writing an initial draft of a
   scheduler design soon, so let's wait for that email before we discuss this
   further.

== Should there be a target difficulty on the descriptor? ==

   I have made changes in the proposal to this effect. See sections
   [EFFORT_ESTIMATION] and [CLIENT_TIMEOUT] for more information.

   While there is no hard-target difficulty, the descriptor now contains
   a suggested difficulty that clients should aim at. The service will
   still add requests with lower effort than the suggested one in the
   priority queue. That's to make the system more resilient to attacks
   in cases where the client cannot get the latest descriptor (and hence
   latest suggested effort) due to the descriptor upload/fetch
   rate-limiting restrictions in place.

== Which PoW function should we use? ==

   The proposal suggests argon2, and Mike has been looking at Randomx. However,
   after further consideration and speaking with some people (props to Alex
   Biryukov), it seems like those two functions are not well fitted for this
   purpose, since they are memory-hard both for the client and the service. And
   since we are trying to minimize the verification overhead, so that the
   service can do hundreds of verifications per second, they don't seem like
   good fits.

   In particular, slimming down argon2 to the point that services can do
   hundreds of those verifications per second, results in an argon2 without any
   memory-hardness. And Randomx is even heavier, since it uses argon2 under the
   hood and also does extra stuff. In particular, from some preliminary
   computations, it seems like the top-half of the cell processing takes about
   2ms, whereas Randomx takes at least 17ms in my computer, which means that it
   puts an almost 1000% overhead to the top-half processing of a single
   introduction.

   This means that assymetric PoW schemes like Equihash and family is what we
   should be looking at next. These schemes aim to have small proof sizes, and
   be memory-hard for the prover, but lightweight for the verifier. They are
   currently used by Zcash so there is quite some literature and improvements.

   In particular, Equihash has two important parameters (n,k). These parameters
   together control the proof size (so for example, Equihash&lt;144,5&gt; has a 100B
   proof, and Equihash&lt;200,9&gt; has a 1344B proof), and the 'k' parameter
   controls the verification speed (the verifier has to do 2^k hash invocations
   to do the verification). Also see this for more details:
      https://forum.bitcoingold.org/t/our-new-equihash-equihash-btg/1512
      https://www.cryptolux.org/images/b/b9/Equihash.pdf

   The good thing here is that these parameters look good and offer good
   security. Furthermore, Equihash is used by big and friendly projects like
   Zcash.

   The negative thing is that because Equihash is widely used there is already
   ASIC hardware for it, so we would need to look at the parameters we pick and
   how ASIC-friendly they are. Furthermore, an attacker who buys Equihash ASIC
   can also use it for coin mining which makes it an easier investment.

   IMO, we should look more into Equihash and other assymetric types of PoW, as
   well as speak with people who know Equihash well.

   Finally, our proposal has a big benefit over the blockchain use cases: it's
   much more agile. We can deploy changes to the PoW algorithm without having
   to hard-fork, and we can do this even through the consensus for maximum
   agility. This means that we should try to use this agility to our advantage.

Looking forward to more feedback!

=============

And here comes the updated proposal:

Filename: xxx-pow-over-intro-v1
Title: A First Take at PoW Over Introduction Circuits
Author: George Kadianakis, Mike Perry, David Goulet
Created: 2 April 2020
Status: Draft

0. Abstract

  This proposal aims to thwart introduction flooding DoS attacks by introducing
  a dynamic Proof-Of-Work protocol that occurs over introduction circuits.

1. Motivation

  So far our attempts at limiting the impact of introduction flooding DoS
  attacks on onion services has been focused on horizontal scaling with
  Onionbalance, optimizing the CPU usage of Tor and applying congestion control
  using rate limiting. While these measures move the goalpost forward, a core
  problem with onion service DoS is that building rendezvous circuits is a
  costly procedure both for the service and for the network. For more
  information on the limitations of rate-limiting when defending against DDoS,
  see [REF_TLS_1].

  If we ever hope to have truly reachable global onion services, we need to
  make it harder for attackers to overload the service with introduction
  requests. This proposal achieves this by allowing onion services to specify
  an optional dynamic proof-of-work scheme that its clients need to participate
  in if they want to get served.

  With the right parameters, this proof-of-work scheme acts as a gatekeeper to
  block amplification attacks by attackers while letting legitimate clients
  through.

1.1. Related work

  For a similar concept, see the three internet drafts that have been proposed
  for defending against TLS-based DDoS attacks using client puzzles [REF_TLS].

1.2. Threat model [THREAT_MODEL]

1.2.1. Attacker profiles [ATTACKER_MODEL]

  This proposal is written to thwart specific attackers. A simple PoW proposal
  cannot defend against all and every DoS attack on the Internet, but there are
  adverary models we can defend against.

  Let's start with some adversary profiles:

  "The script-kiddie"

    The script-kiddie has a single computer and pushes it to its
    limits. Perhaps it also has a VPS and a pwned server. We are talking about
    an attacker with total access to 10 Ghz of CPU and 10 GBs of RAM. We
    consider the total cost for this attacker to be zero $.

  "The small botnet"

    The small botnet is a bunch of computers lined up to do an introduction
    flooding attack. Assuming 500 medium-range computers, we are talking about
    an attacker with total access to 10 Thz of CPU and 10 TB of RAM. We consider
    the upfront cost for this attacker to be about $400.

  "The large botnet"

    The large botnet is a serious operation with many thousands of computers
    organized to do this attack. Assuming 100k medium-range computers, we are
    talking about an attacker with total access to 200 Thz of CPU and 200 TB of
    RAM. The upfront cost for this attacker is about $36k.

  We hope that this proposal can help us defend against the script-kiddie
  attacker and small botnets. To defend against a large botnet we would need
  more tools in our disposal (see [FUTURE_DESIGNS]).

  {XXX: Do the above make sense? What other attackers do we care about? What
        other metrics do we care about? Network speed? I got the botnet costs
        from here [REF_BOTNET] Back up our claims of defence.}

1.2.2. User profiles [USER_MODEL]

  We have attackers and we have users. Here are a few user profiles:

  "The standard web user"

    This is a standard laptop/desktop user who is trying to browse the
    web. They don't know how these defences work and they don't care to
    configure or tweak them. They are gonna use the default values and if the
    site doesn't load, they are gonna close their browser and be sad at Tor.
    They run a 2Ghz computer with 4GB of RAM.

  "The motivated user"

    This is a user that really wants to reach their destination. They don't
    care about the journey; they just want to get there. They know what's going
    on; they are willing to tweak the default values and make their computer do
    expensive multi-minute PoW computations to get where they want to be.

  "The mobile user"

    This is a motivated user on a mobile phone. Even tho they want to read the
    news article, they don't have much leeway on stressing their machine to do
    more computation.

  We hope that this proposal will allow the motivated user to always connect
  where they want to connect to, and also give more chances to the other user
  groups to reach the destination.

1.2.3. The DoS Catch-22 [CATCH22]

  This proposal is not perfect and it does not cover all the use cases. Still,
  we think that by covering some use cases and giving reachability to the
  people who really need it, we will severely demotivate the attackers from
  continuing the DoS attacks and hence stop the DoS threat all
  together. Furthermore, by increasing the cost to launch a DoS attack, a big
  class of DoS attackers will disappear from the map, since the expected ROI
  will decrease.

2. System Overview

2.1. Tor protocol overview

                                          +----------------------------------+
                                          |                                  |
   +-------+ INTRO1  +-----------+ INTRO2 +--------+                         |
   |Client |--------&gt;|Intro Point|-------&gt;|  PoW   |-----------+             |
   +-------+         +-----------+        |Verifier|           |             |
                                          +--------+           |             |
                                          |                    |             |
                                          |                    |             |
                                          |         +----------v---------+   |
                                          |         |Intro Priority Queue|   |
                                          +---------+--------------------+---+
                                                           |  |  |
                                                Rendezvous |  |  |
                                                  circuits |  |  |
                                                           v  v  v



  The proof-of-work scheme specified in this proposal takes place during the
  introduction phase of the onion service protocol.

  The system described in this proposal is not meant to be on all the time, and
  should only be enabled by services when under duress. The percentage of
  clients receiving puzzles can also be configured based on the load of the
  service.

  In summary, the following steps are taken for the protocol to complete:

  1) Service encodes PoW parameters in descriptor [DESC_POW]
  2) Client fetches descriptor and computes PoW [CLIENT_POW]
  3) Client completes PoW and sends results in INTRO1 cell [INTRO1_POW]
  4) Service verifies PoW and queues introduction based on PoW effort \
[SERVICE_VERIFY]

2.2. Proof-of-work overview

2.2.1. Primitives

  For our proof-of-work scheme we want to minimize the spread of resources
  between a motivated attacker and legitimate clients. This means that we are
  looking to minimize any benefits that GPUs or ACICs can offer to an attacker.

  For this reason we chose argon2 [REF_ARGON2] as the hash function for our
  proof-of-work scheme since it's well audited and GPU-resistant and to some
  extend ASIC-resistant as well.

  As a password hash function, argon2 by default outputs 32 bytes of hash, and
  takes as primary input a message and a nonce/salt. For the purposes of this
  specification we will define an argon2() function as:
     uint8_t hash_output[32] = argon2(uint8_t *message, uint8_t *nonce)'.

  See section [ARGON_PARAMS] for more information on the secondary inputs of
  argon2.

2.2.2. Dynamic PoW

  DoS is a dynamic problem where the attacker's capabilities constantly change,
  and hence we want our proof-of-work system to be dynamic and not stuck with a
  static difficulty setting. Hence, instead of forcing clients to go below a
  static target like in Bitcoin to be successful, we ask clients to "bid" using
  their PoW effort. Effectively, a client gets higher priority the higher
  effort they put into their proof-of-work. This is similar to how
  proof-of-stake works but instead of staking coins, you stake work.

  The benefit here is that legitimate clients who really care about getting
  access can spend a big amount of effort into their PoW computation, which
  should guarantee access to the service given reasonable adversary models. See
  [PARAM_TUNING] for more details about these guarantees and tradeoffs.

  As a way to improve reachability and UX, the service tries to estimate the
  effort needed for clients to get access at any given time and places it in
  the descriptor. See [EFFORT_ESTIMATION] for more details.

2.2.3. PoW effort

  For our dynamic PoW system to work, we will need to be able to compare PoW
  tokens with each other. To do so we define a function:
         unsigned effort(uint8_t *token)
  which takes as its argument a hash output token, and returns the number of
  leading zero bits on it.

  So for example effort(0000000110001010110100101) == 7.

3. Protocol specification

3.1. Service encodes PoW parameters in descriptor [DESC_POW]

  This whole protocol starts with the service encoding the PoW parameters in
  the 'encrypted' (inner) part of the v3 descriptor. As follows:

       "pow-params" SP type SP seed-b64 SP expiration-time NL

        [At most once]

        type: The type of PoW system used. We call the one specified here "v1"

        seed-b64: A random seed that should be used as the input to the PoW
                  hash function. Should be 32 random bytes encoded in base64
                  without trailing padding.

        suggested-effort: An unsigned integer specifying an effort value that
                  clients should aim for when contacting the service. See
                  [EFFORT_ESTIMATION] for more details here.

        expiration-time: A timestamp in "YYYY-MM-DD SP HH:MM:SS" format after
                         which the above seed expires and is no longer valid as
                         the input for PoW. It's needed so that the size of our
                         replay cache does not grow infinitely. It should be
                         set to three hours in the future (+- some randomness).
                         {TODO: PARAM_TUNING}

       {XXX: Expiration time makes us even more susceptible to clock skews, but
             it's needed so that our replay cache refreshes. How to fix this?
             See [CLIENT_BEHAVIOR] for more details.}

3.2. Client fetches descriptor and computes PoW [CLIENT_POW]

  If a client receives a descriptor with "pow-params", it should assume that
  the service is expecting a PoW input as part of the introduction protocol.

  The client parses the descriptor and extracts the PoW parameters. It makes
  sure that the &lt;expiration-time&gt; has not expired and if it has, it needs to
  fetch a new descriptor.

  The client should then extract the &lt;suggested-effort&gt; field to configure its
  PoW 'target' (see [REF_TARGET]). The client SHOULD NOT accept 'target' values
  that will cause an infinite PoW computation. {XXX: How to enforce this?}

  To complete the PoW the client follows the following logic:

      a) Client generates 'nonce' as 32 random bytes.
      b) Client derives 'seed' by decoding 'seed-b64'.
      c) Client derives 'labeled_seed = seed + "TorV1PoW"'
      d) Client computes hash_output = argon2(labeled_seed, nonce)
      e) Client checks if effort(hash_output) &gt;= target.
        e1) If yes, success! The client uses 'hash_output' as the puzzle
            solution and 'nonce' and 'seed' as its inputs.
        e2) If no, fail! The client interprets 'nonce' as a big-endian integer,
            increments it by one, and goes back to step (d).

  At the end of the above procedure, the client should have a triplet
  (hash_output, seed, nonce) that can be used as the answer to the PoW
  puzzle. How quickly this happens depends solely on the 'target' parameter.

3.3. Client sends PoW in INTRO1 cell [INTRO1_POW]

  Now that the client has an answer to the puzzle it's time to encode it into
  an INTRODUCE1 cell. To do so the client adds an extension to the encrypted
  portion of the INTRODUCE1 cell by using the EXTENSIONS field (see
  [PROCESS_INTRO2] section in rend-spec-v3.txt). The encrypted portion of the
  INTRODUCE1 cell only gets read by the onion service and is ignored by the
  introduction point.

  We propose a new EXT_FIELD_TYPE value:

     [01] -- PROOF_OF_WORK

   The EXT_FIELD content format is:

      POW_VERSION    [1 byte]
      POW_NONCE      [32 bytes]

   where:

    POW_VERSION is 1 for the protocol specified in this proposal
    POW_NONCE is 'nonce' from the section above

   This will increase the INTRODUCE1 payload size by 33 bytes since the
   extension type and length is 2 extra bytes, the N_EXTENSIONS field is always
   present and currently set to 0 and the EXT_FIELD is 32 bytes. According to
   ticket #33650, INTRODUCE1 cells currently have more than 200 bytes
   available.

3.4. Service verifies PoW and handles the introduction  [SERVICE_VERIFY]

   When a service receives an INTRODUCE1 with the PROOF_OF_WORK extension, it
   should check its configuration on whether proof-of-work is required to
   complete the introduction. If it's not required, the extension SHOULD BE
   ignored. If it is required, the service follows the procedure detailed in
   this section.

   If the service requires the PROOF_OF_WORK extension but received an
   INTRODUCE1 cell without any embedded proof-of-work, the service SHOULD
   consider this cell as a zero-effort introduction for the purposes of the
   priority queue (see section [INTRO_QUEUE]).

3.4.1. PoW verification [POW_VERIFY]

   To verify the client's proof-of-work the service extracts (hash_output,
   seed, nonce) from the INTRODUCE1 cell and MUST do the following steps:

   1) Make sure that the client's seed is identical to the active seed.
   2) Check the client's nonce for replays (see [REPLAY_PROTECTION] section).
   3) Verify that 'hash_output =?= argon2(seed, nonce)

   If any of these steps fail the service MUST ignore this introduction request
   and abort the protocol.

   If all the steps passed, then the circuit is added to the introduction queue
   as detailed in section [INTRO_QUEUE].

3.4.1.1. Replay protection [REPLAY_PROTECTION]

  The service MUST NOT accept introduction requests with the same (seed, nonce)
  tuple. For this reason a replay protection mechanism must be employed.

  The simplest way is to use a simple hash table to check whether a (seed,
  nonce) tuple has been used before for the actiev duration of a
  seed. Depending on how long a seed stays active this might be a viable
  solution with reasonable memory/time overhead.

  If there is a worry that we might get too many introductions during the
  lifetime of a seed, we can use a Bloom filter as our replay cache
  mechanism. The probabilistic nature of Bloom filters means that sometimes we
  will flag some connections as replays even if they are not; with this false
  positive probability increasing as the number of entries increase. However,
  with the right parameter tuning this probability should be negligible and
  well handled by clients. {TODO: PARAM_TUNING}

3.4.2. The Introduction Queue  [INTRO_QUEUE]

3.4.2.1. Adding introductions to the introduction queue [ADD_QUEUE]

  When PoW is enabled and a verified introduction comes through, the service
  instead of jumping straight into rendezvous, queues it and prioritizes it
  based on how much effort was devoted by the client to PoW. This means that
  introduction requests with high effort should be prioritized over those with
  low effort.

  To do so, the service maintains an "introduction priority queue" data
  structure. Each element in that priority queue is an introduction request,
  and its priority is the effort put into its PoW:

  When a verified introduction comes through, the service uses the effort()
  function with hash_output as its input, and uses the output to place requests
  into the right position of the priority_queue: The bigger the effort, the
  more priority it gets in the queue. If two elements have the same effort, the
  older one has priority over the newer one.

  {TODO: PARAM_TUNING: If the priority queue is only ordered based on the
   effort what attacks can happen in various scenarios? Do we want to order on
   time+effort?  Which scenarios and attackers should we examine here?}

3.4.2.2. Handling introductions from the introduction queue [HANDLE_QUEUE]

  The service should handle introductions by pulling from the introduction
  queue.

  Similar to how our cell scheduler works, the onion service subsystem will
  poll the priority queue every 100ms tick and process the first 20 cells from
  the priority queue (if they exist). The service will perform the rendezvous
  and the rest of the onion service protocol as normal.

  With this tempo, we can process 200 introduction cells per second.
  {XXX: Is this good?}

  After the introduction request is handled from the queue, the service trims
  the priority queue if the queue is too big.
  {TODO: PARAM_TUNING: What's the max size of the queue? How do we trim it? Can
  we use WRED usefully?}

  {TODO: PARAM_TUNING: STRAWMAN: This needs hella tuning. Processing 20 cells
  per 100ms is probably unmaintainable, since each cell is quite expensive:
  doing so involving path selection, crypto and making circuits. We will need
  to profile this procedure and see how we can do this scheduling better.}

3.4.3. PoW effort estimation [EFFORT_ESTIMATION]

  During its operation the service continuously keeps track of the received PoW
  cell efforts to inform its clients of the effort they should put in their
  introduction to get service. The service informs the clients by using the
  &lt;suggested-effort&gt; field in the descriptor.

  In particular, the service starts with a default suggested-effort value of 15.

  Everytime the service handles an introduction request from the priority queue
  in [HANDLE_QUEUE], the service compares the request's effort to the current
  suggested-effort value. If the new request's effort is lower than the
  suggested-effort, set the suggested-effort equal to the effort of the new
  request.

  Everytime the service trims the priority queue in [HANDLE_QUEUE], the service
  compares the request at the trim point against the current suggested-effort
  value. If the trimmed request's effort is higher than the suggested-effort,
  set the suggested-effort equal to the effort of the new request.

  The above two operations are meant to balance the suggested effort based on
  the requests currently waiting in the priority queue. If the priority queue
  is filled with high-effort requests, make the suggested effort higher. And
  when all the high-effort requests get handled and the priority queue is back
  to normal operation, relax the suggested effort to lower levels.

  The suggested-effort is not a hard limit to the efforts that are accepted by
  the service, and it's only meant to serve as a guideline for clients to
  reduce the number of unsuccessful requests that get to the service. The
  service still adds requests with lower effort than suggested-effort to the
  priority queue in [ADD_QUEUE].

  {XXX: What attacks are possible here?}

3.4.3.1. Updating descriptor with new suggested effort

  When a service changes its suggested-effort value, it SHOULD upload a new
  descriptor with the new value.

  The service should avoid uploading descriptors too often to avoid overwheming
  the HSDirs. The service SHOULD NOT upload descriptors more often than
  'hs-pow-desc-upload-rate-limit' seconds (which is controlled through a
  consensus parameter and has a default value of 300 seconds).

  {XXX: Is this too often? Or too rare? Perhaps we can set different limits
  for when the difficulty goes up and different for when it goes down. It's
  more important to update the descriptor when the difficulty goes up.}

  {XXX: What attacks are possible here? Can the attacker intentionally hit this
  rate-limit and then influence the suggested effort so that clients do not
  learn about the new effort? The service will still accept efforts lower than
  the suggested effort so the attack is not so serious, but it still can be a
  problem.}

4. Client behavior [CLIENT_BEHAVIOR]

  This proposal introduces a bunch of new ways where a legitimate client can
  fail to reach the onion service.

  Furthermore, there is currently no end-to-end way for the onion service to
  inform the client that the introduction failed. The INTRO_ACK cell is not
  end-to-end (it's from the introduction point to the client) and hence it does
  not allow the service to inform the client that the rendezvous is never gonna
  occur.

  For this reason we need to define some client behaviors to work around these
  issues.

4.1. Clients handling timeouts [CLIENT_TIMEOUT]

  Alice can fail to reach the onion service if her introduction request gets
  trimmed off the priority queue in [HANDLE_QUEUE], or if the service does not
  get through its priority queue in time and the connection times out.

  {XXX: How should timeout values change here since the priority queue will
  cause bigger delays than usual to rendezvous?}

  This section presents a heuristic method for the client getting service even
  in such scenarios.

  If the rendezvous request times out, the client SHOULD fetch a new descriptor
  for the service to make sure that it's using the right suggested-effort for
  the PoW and the right PoW seed. The client SHOULD NOT fetch service
  descriptors more often than every 'hs-pow-desc-fetch-rate-limit' seconds
  (which is controlled through a consensus parameter and has a default value of
  600 seconds).

  {XXX: Is this too rare? Too often?}

  When the client fetches a new descriptor, it should try connecting to the
  service with the new suggested-effort and PoW seed. If that doesn't work, it
  should double the effort and retry. The client should keep on
  doubling-and-retrying until it manages to get service, or its able to fetch a
  new descriptor again.

  {XXX: This means that the client will keep on spinning and
  doubling-and-retrying for a service under this situation. There will never be
  a "Client connection timed out" page for the user. Is this good? Is this bad?
  Should we stop doubling-and-retrying after some iterations? Or should we
  throw a custom error page to the user, and ask the user to stop spinning
  whenever they want?}

4.2. Seed expiration issues

  As mentioned in [DESC_POW], the expiration timestamp on the PoW seed can
  cause issues with clock skewed clients. Furthermore, even not clock skewed
  clients can encounter TOCTOU-style race conditions here.

  The client descriptor refetch logic of [CLIENT_TIMEOUT] should take care of
  such seed-expiration issues, since the client will refetch the descriptor.

  {XXX: Is this sufficient? Should we have multiple active seeds at the same
  time similar to how we have overlapping descriptors and time periods in v3?
  This would solve the problem but it grows the complexity of the system
  substantially.}

4.3. Other descriptor issues

  Another race condition here is if the service enables PoW, while a client has
  a cached descriptor. How will the client notice that PoW is needed? Does it
  need to fetch a new descriptor? Should there be another feedback mechanism?
  {XXX}

5. Attacker strategies [ATTACK_META]

  Now that we defined our protocol we need to start tweaking the various
  knobs. But before we can do that, we first need to understand a few
  high-level attacker strategies to see what we are fighting against.

5.1.1. Total overwhelm strat

  Given the way the introduction queue works (see [HANDLE_QUEUE]), a very
  effective strategy for the attacker is to totally overwhelm the queue
  processing by sending more high-effort introductions than the onion service
  can handle at any given tick.

  To do so, the attacker would have to send at least 20 high-effort
  introduction cells every 100ms, where high-effort is a PoW which is above the
  estimated level of "the motivated user" (see [USER_MODEL]).

  An easier attack for the adversary, is the same strategy but with
  introduction cells that are all above the comfortable level of "the standard
  user" (see [USER_MODEL]). This would block out all standard users and only
  allow motivated users to pass.

  {XXX: What other attack strategies we should care about?}

6. Parameter tuning [PARAM_TUNING]

  There are various parameters in this system that need to be tuned.

  We will first start by tuning the default difficulty of our PoW
  system. That's gonna define an expected time for attackers and clients to
  succeed.

  We are then gonna tune the parameters of the argon2 hash function. That will
  define the resources that an attacker needs to spend to overwhelm the onion
  service, the resources that the service needs to spend to verify introduction
  requests, and the resources that legitimate clients need to spend to get to
  the onon service.

6.1. PoW Difficulty settings

  The difficulty setting of our PoW basically dictates how difficult it should
  be to get a success in our PoW system. In classic PoW systems, "success" is
  defined as getting a hash output below the "target". However, since our
  system is dynamic, we define "success" as an abstract high-effort computation.

  Even tho our system is dynamic, we still need default difficulty settings
  that will define the metagame. The client and attacker can still aim higher
  or lower, but for UX purposes and for analysis purposes we do need to define
  some difficulties.

  We hence created the table (see [REF_TABLE]) below which shows how much time
  a legitimate client with a single machine should expect to burn before they
  get a single success. The x-axis is how many successes we want the attacker
  to be able to do per second: the more successes we allow the adversary, the
  more they can overwhelm our introduction queue. The y-axis is how many
  machines the adversary has in her disposal, ranging from just 5 to 1000.

       ===============================================================
       |    Expected Time (in seconds) Per Success For One Machine   |
 ===========================================================================
 |                                                                          |
 |   Attacker Succeses        1       5       10      20      30      50    |
 |       per second                                                         |
 |                                                                          |
 |            5               5       1       0       0       0       0     |
 |            50              50      10      5       2       1       1     |
 |            100             100     20      10      5       3       2     |
 | Attacker   200             200     40      20      10      6       4     |
 |  Boxes     300             300     60      30      15      10      6     |
 |            400             400     80      40      20      13      8     |
 |            500             500     100     50      25      16      10    |
 |            1000            1000    200     100     50      33      20    |
 |                                                                          |
 ============================================================================

  Here is how you can read the table above:

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 1
    success per second, then a legitimate client with a single box should be
    expected to spend 1000 seconds getting a single success.

  - If an adversary has a botnet with 1000 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 200 seconds getting a single success.

  - If an adversary has a botnet with 500 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 100 seconds getting a single success.

  - If an adversary has access to 50 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 10 seconds getting a single success.

  - If an adversary has access to 5 boxes, and we want to limit her to 5
    successes per second, then a legitimate client with a single box should be
    expected to spend 1 seconds getting a single success.

  With the above table we can create some profiles for default values of our
  PoW difficulty. So for example, we can use the last case as the default
  parameter for Tor Browser, and then create three more profiles for more
  expensive cases, scaling up to the first case which could be hardest since
  the client is expected to spend 15 minutes for a single introduction.

  {TODO: PARAM_TUNING You can see that this section is completely CPU/memory
  agnostic, and it does not take into account potential optimizations that can
  come from GPU/ASICs. This is intentional so that we don't put more variables
  into this equation right now, but as this proposal moves forward we will need
  to put more concrete values here.}

6.2. Argon2 parameters [ARGON_PARAMS]

  We now need to define the secondary argon2 parameters as defined in
  [REF_ARGON2]. This includes the number of lanes 'h', the memory size 'm', the
  number of iterations 't'. Section 9 of [REF_ARGON2] recommends an approach of
  how to tune these parameters.

  To tune these parameters we are looking to *minimize* the verification speed
  of an onion service, while *maximizing* the sparse resources spent by an
  adversary trying to overwhelm the service using [ATTACK_META].

  When it comes to verification speed, to verify a single introduction cell the
  service needs to do a single argon2 call: so the service will need to do
  hundreds of those per second as INTRODUCE2 cells arrive. The service will
  have to do this verification step even for very cheap zero-effort PoW
  received, so this has to be a cheap procedure so that it doesn't become a DoS
  vector of each own. Hence each individual argon2 call must be cheap enough to
  be able to be done comfortably and plentifuly by an onion service with a
  single host (or horizontally scaled with Onionbalance).

  At the same time, the adversary will have to do thousands of these calls if
  she wants to make high-effort PoW, so it's this assymetry that we are looking
  to exploit here. Right now, the most expensive resource for adversaries is
  the RAM size, and that's why we chose argon2 which is memory-hard.

  To minmax this game we will need

  {TODO: PARAM_TUNING: I've had a hard time minmaxing this game for
  argon2. Even argon2 invocations with a small memory parameter will take
  multiple milliseconds to run on my machine, and the parameters recommended in
  section 8 of the paper all take many hundreds of milliseconds. This is just
  not practical for our use case, since we want to process hundreds of such PoW
  per second... I also did not manage to find a benchmark of argon2 calls for
  different CPU/GPU/FPGA configurations.}

7. Discussion

7.1. UX

  This proposal has user facing UX consequences.

  Here is some UX improvements that don't need user-input:

  - Primarily, there should be a way for Tor Browser to display to users that
    additional time (and resources) will be needed to access a service that is
    under attack. Depending on the design of the system, it might even be
    possible to estimate how much time it will take.

  And here are a few UX approaches that will need user-input and have an
  increasing engineering difficulty. Ideally this proposal will not need
  user-input and the default behavior should work for almost all cases.

  a) Tor Browser needs a "range field" which the user can use to specify how
     much effort they want to spend in PoW if this ever occurs while they are
     browsing. The ranges could be from "Easy" to "Difficult", or we could try
     to estimate time using an average computer. This setting is in the Tor
     Browser settings and users need to find it.

  b) We start with a default effort setting, and then we use the new onion
     errors (see #19251) to estimate when an onion service connection has
     failed because of DoS, and only then we present the user a "range field"
     which they can set dynamically. Detecting when an onion service connection
     has failed because of DoS can be hard because of the lack of feedback (see
     [CLIENT_BEHAVIOR])

  c) We start with a default effort setting, and if things fail we
     automatically try to figure out an effort setting that will work for the
     user by doing some trial-and-error connections with different effort
     values. Until the connection succeeds we present a "Service is
     overwhelmed, please wait" message to the user.

7.2. Future work [FUTURE_WORK]

7.2.1. Incremental improvements to this proposal

  There are various improvements that can be done in this proposal, and while
  we are trying to keep this v1 version simple, we need to keep the design
  extensible so that we build more features into it. In particular:

  - End-to-end introduction ACKs

    This proposal suffers from various UX issues because there is no end-to-end
    mechanism for an onion service to inform the client about its introduction
    request. If we had end-to-end introduction ACKs many of the problems from
    [CLIENT_BEHAVIOR] would be aleviated. The problem here is that end-to-end
    ACKs require modifications on the introduction point code and a network
    update which is a lengthy process.

  - Multithreading scheduler

    Our scheduler is pretty limited by the fact that Tor has a single-threaded
    design. If we improve our multithreading support we could handle a much
    greater amount of introduction requests per second.

7.2.2. Future designs [FUTURE_DESIGNS]

  This is just the beginning in DoS defences for Tor and there are various
  futured designs and schemes that we can investigate. Here is a brief summary
  of these:

  "More advanced PoW schemes" -- We could use more advanced memory-hard PoW
         schemes like MTP-argon2 or Itsuku to make it even harder for
         adversaries to create successful PoWs. Unfortunately these schemes
         have much bigger proof sizes, and they won't fit in INTRODUCE1 cells.
         See #31223 for more details.

  "Third-party anonymous credentials" -- We can use anonymous credentials and a
         third-party token issuance server on the clearnet to issue tokens
         based on PoW or CAPTCHA and then use those tokens to get access to the
         service. See [REF_CREDS] for more details.

  "PoW + Anonymous Credentials" -- We can make a hybrid of the above ideas
         where we present a hard puzzle to the user when connecting to the
         onion service, and if they solve it we then give the user a bunch of
         anonymous tokens that can be used in the future. This can all happen
         between the client and the service without a need for a third party.

  All of the above approaches are much more complicated than this proposal, and
  hence we want to start easy before we get into more serious projects.

7.3. Environment

  We love the environment! We are concerned of how PoW schemes can waste energy
  by doing useless hash iterations. Here is a few reasons we still decided to
  pursue a PoW approach here:

  "We are not making things worse" -- DoS attacks are already happening and
      attackers are already burning energy to carry them out both on the
      attacker side, on the service side and on the network side. We think that
      asking legitimate clients to carry out PoW computations is not gonna
      affect the equation too much, since an attacker right now can very
      quickly cause the same damage that hundreds of legitimate clients do a
      whole day.

  "We hope to make things better" -- The hope is that proposals like this will
      make the DoS actors go away and hence the PoW system will not be used. As
      long as DoS is happening there will be a waste of energy, but if we
      manage to demotivate them with technical means, the network as a whole
      will less wasteful. Also see [CATCH22] for a similar argument.

8. References

  [REF_ARGON2]: https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf
  https://password-hashing.net/#argon2
  [REF_TABLE]: The table is based on the script below plus some manual editing for \
                readability:
               https://gist.github.com/asn-d6/99a936b0467b0cef88a677baaf0bbd04
  [REF_BOTNET]: https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2009/07/01121538/ynam_botnets_0907_en.pdf
  [REF_CREDS]: https://lists.torproject.org/pipermail/tor-dev/2020-March/014198.html
  [REF_TARGET]: https://en.bitcoin.it/wiki/Target
  [REF_TLS]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt
             https://tools.ietf.org/id/draft-nir-tls-puzzles-00.html
             https://tools.ietf.org/html/draft-ietf-ipsecme-ddos-protection-10
  [REF_TLS_1]: https://www.ietf.org/archive/id/draft-nygren-tls-client-puzzles-02.txt

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200414205217</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-04-14 20:52:17-0400</timestampReceived><subject>Re: [tor-dev] Choosing a valid Circuit ID for an OR connection</subject><body>

On Tue, Apr 14, 2020 at 9:13 AM Eli Vakrat &lt;eli@vakrat.com&gt; wrote:
&gt; 
&gt; Hello to the TOR dev team!
&gt; 
&gt; My name is Eli, I'm a high school student from Israel and I'm currently trying to \
&gt; implement a TOR Client in Python. Currently, my project is configured so that the \
&gt; python client (OP) has its guard node set as my local machine (which is running a \
&gt; downloaded version of TOR). I do this for debugging purposes so that if I send a \
&gt; malformed cell as the implemented client, I can read the debug log that the OR \
&gt; generates and see what I did wrong. 
&gt; As I am writing this, I have successfully been able to make a v3 "in protocol" \
&gt; handshake by sending the proper VERSIONS and NETINFO cells that the OR has \
&gt; accepted. 
&gt; Right now, I am working on getting the CREATE cell to work (with the TAP \
&gt; handshake), and when I send the cell to the OR It sends a DESTROY cell with the \
&gt; following message in the debug log: 
&gt; Apr 14 12:24:51.166 [warn] Received create cell with unexpected circ_id 1. Closing.
&gt; 
&gt; To my understanding, the problem here is that the circuit id I have chosen is not \
&gt; valid. 
&gt; I read from the tor spec that there is a range of acceptable circuit id's for each \
&gt; relay and it can be found in the long term 1024 bit RSA "signing key". 
&gt; My question to you all is, how can I extract that range for the circuit ID's (along \
&gt; with any other relevant information) from the signing key? In other words, what is \
&gt; the "signing key" made up of, and how can I get the information that its made of? 
&gt; The bottom line is I need to find out what valid circuit ID's I can send to OR's.
&gt; 
&gt; I am having a lot of fun doing this project so far and I hope to hear back from \
&gt; anyone who has an answer :)

Hi!  This looks like a cool project.

So, it was only the earlier versions of Tor that chose circuit IDs
based on RSA keys.  In link protocol version 4 or higher (as
negotiated by the VERSIONS cell), you can use any circuit ID that
starts with a 1 bit:

   "In link protocol version 4 or higher, whichever node initiated the
   connection sets its MSB to 1, and whichever node didn't initiate the
   connection sets its MSB to 0."

Hoping this helps,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200417230350</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-17 23:03:50-0400</timestampReceived><subject>[tor-dev] Walking Onions: week 7 update</subject><body>

Walking Onions: week 7 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html

Week 5:
   Voting (part 2)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014218.html

Week 6:
   Editing, voting rules, and client behavior (part 1)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014222.html


== Clustering exit ports

This week I tried to figure out how exits work with walking onions.
A naive approach might have 65535 different routing indices in the
ENDIVE (one for each TCP port), but that would give horrible
performance: it would make the expanded ENDIVEs absolutely huge.
Instead, we can cluster ports into "classes" based on which are
always supported or not supported together.  (For example, on the
day I scanned the directory, every relay supporting any port in the
range 49002-50000 supported all of them.)  There are about 200 such
classes on the current Tor network.

But 200 exit indices is still probably too much: it seems like we'll
need to cluster exit ports together in a more lossy way.  For
example, not every exit that supports port 80 supports port 443 or
vice versa.  But around 98% of them do -- so it we wouldn't be
losing too much by using one exit index for "443 and 80", and not
listing the 2% of exits that only support one of those ports.

I wrote a short program [EXIT-ANALYSIS] to experiment with
clustering strategies here, and settled on a greedy algorithm to get
down to a smaller number of port classes by iteratively combining
whichever pair of classes will cause us to lose the fewest number of
(relay:port) possibilities.  We can get down to 16 classes and lose
only 0.07% of all the relay:port possibilities; we can get down to 8
classes and lose only 0.2%.

That's not the whole story, though.  Some of what we're losing would
be things we'd miss.  When the algorithm gives us 16 classes, it
loses 75% of port 10000, 70% of port 23, and so on.  Clearly not all
ports are equivalent, and we should tune this approach to take that
into account.  We should also consider the bandwidth impact of these
changes, and retool the algorithm so that it minimizes the
bandwidth-per-port combination we have.

We'd also likely want to hand-edit these port lists
so that they make more sense semantically on their own.  That way,
we could take Teor's suggestion from last month and try to give exit
relays the options to opt in to or out of human-intelligible
partitions.

Further, we could save some complexity by requiring dual-stack exits
to support the same ports on IPv4 and IPv6.  That way we wouldn't
need to worry about divergent sets of port classes.

== So what do we do with these clusters?

If a client wants to connect to port 25, and uses a port-25-only
index, that leaks the client's intention to the middle node.  That's
not so good.  Instead, in the tech report [WHITEPAPER], one or both
of Chelsea Komlo and Ian Goldberg came up with a mechanism called
Delegated Verifiable Selection (DVS).  With DVS, when the client
sends a BEGIN cell, the relay can respond that it does not support
the requested port, along with a SNIP from a relay that does.  To
prevent the relay from choosing an arbitrary SNIP, the BEGIN cell
would have to include an auxiliary index value to be used when DVS
is in place, and the END cell would need room for a SNIP.

(Alternatively, clients could just make a 3-hop circuit and ask it
for SNIPs to be used as exits on some other circuit.)

== Voting on policy sets

These policy clusters (and a few other things!) are too complex for
the voting operations I had before.  Fortunately, it's safe to treat
them as opaque.

I've added a new voting operation to allow authorities to vote on a
bstr that is then decoded and treated as a cbor object (if it is valid
and well-formed).  It should be useful in other places too.

== Migrating port classes

Migrating from one set of port classes to another is nontrivial.
Clients who have the old root document will expect the indices to
correspond to one partition of ports, whereas clients with the new
root document will expect another partition.  To solve this, I've
designed the system so that two sets of exit indices can exist
concurrently while clients are moving to the newer partition of
ports.

Alternatively, we could give SNIPs a mechanism to contain a field
saying "Your root document must be at least this new."  I don't know
which approach would be simpler; both seem like too much complexity for a
feature that would only be used occasionally.

== Next steps

My next plan here is to write up onion services; I believe I've got
the design there mostly figured out, and just need to write it down.

After that, I'm planning to turn back and fill in all the missing
subsections that I've written so far, and write a short
introduction.  There are a lot of missing sections, so that won't be
super fast.  I'm also going to need to show the whole thing to a
beta reader or two to answer the question, "Would this make sense to
somebody who doesn't already know what it says?"


== Fun facts

The script to generate exit port classes [EXIT-ANALYSIS] was written in
Rust. If I'm counting right, it's only my second Rust program that
actually does something useful!  If you are one of those Rust
enthusiasts who would like to critique it, I wouldn't mind at all --
just send me comments offline or make notes on the repository.

(Only do this if you like critiquing newbie Rust that was never
actually meant for production use.  Don't do this if you just want
to point out all the things that make it unsuitable for production
use.)

== Not-so-fun facts

This week I've been fairly overwhelmed with the lead up to and down
from the recent layoffs at Tor, in response to a downturn in funding
during the COVID-19 pandemic [BLOGPOST]. Tor will continue, and this
work will continue with it--but it is still a hard blow to have to
lose so many excellent coworkers. (Yes, I'm still at Tor, for the
record.)

Do you know somebody who is interested in hiring one or more amazingly
talented programmers, engineers, communications specialists, or project
managers -- all with experience at productive remote work and all with
dedication to improving people's lives?  Please pass their information
along to tor-alums@lists.torproject.org , and it will (after moderation)
get forwarded to those affected.


[BLOGPOST] https://blog.torproject.org/covid19-impact-tor

[EXIT-ANALYSIS]
https://github.com/nmathewson/walking-onions-wip/tree/master/exit-analysis

[EXIT-PARTITION]
https://lists.torproject.org/pipermail/tor-dev/2020-March/014182.html

[WHITEPAPER] https://crysp.uwaterloo.ca/software/walkingonions/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200422032914</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-22 03:29:14-0400</timestampReceived><subject>Re: [tor-dev] Fallback Directory Handover</subject><body>


&gt; On 22 Apr 2020, at 12:27, Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt; 
&gt; On Wed, Apr 22, 2020 at 11:56:54AM +1000, teor wrote:
&gt;&gt; a bad fallback guard can continue to manipulate its client's view of
&gt;&gt; the network
&gt; 
&gt; This is only true to the extent that the fallback guard can choose which
&gt; of three still-valid consensuses to give to the client, right?

Not quite.

Clients tolerate recently-expired consensuses for some operations, up
to 72 hours in some cases.

When I last checked, TAILS set its system clock off the date in the
consensus it receives.

Clients also download authority certificates from fallback directory
mirrors. I think that's the whole trust path from the hard-coded
authority fingerprints, to the certificates, and then a valid consensus.

Since clients use an ORPort connection to download consensuses,
a malicious fallback directory mirror can also provide them with:
* the wrong date (triggering a clock skew warning)
* the wrong external IP address (not used for much)
* malicious directory documents
  * note that decompression and some parsing happens before the
     signature checks
* slow transfer speeds (like slowloris)

Using multiple fallbacks mitigates most of these issues.

T



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200414130605</emailId><senderName>Eli Vakrat</senderName><senderEmail>eli@vakrat.com</senderEmail><timestampReceived>2020-04-14 13:06:05-0400</timestampReceived><subject>[tor-dev] Choosing a valid Circuit ID for an OR connection</subject><body>

[Attachment #2 (multipart/alternative)]


Hello to the TOR dev team!

My name is Eli, I'm a high school student from Israel and I'm currently
trying to implement a TOR Client in Python.
Currently, my project is configured so that the python client (OP) has its
guard node set as my local machine (which is running a downloaded version
of TOR). I do this for debugging purposes so that if I send a malformed
cell as the implemented client, I can read the debug log that the OR
generates and see what I did wrong.

As I am writing this, I have successfully been able to make a v3 "in
protocol" handshake by sending the proper VERSIONS and NETINFO cells that
the OR has accepted.

Right now, I am working on getting the CREATE cell to work (with the TAP
handshake), and when I send the cell to the OR It sends a DESTROY cell with
the following message in the debug log:

Apr 14 12:24:51.166 [warn] Received create cell with unexpected circ_id 1.
Closing.

To my understanding, the problem here is that the circuit id I have chosen
is not valid.

I read from the tor spec that there is a range of acceptable circuit
id's for each relay and it can be found in the long term 1024 bit RSA
"signing key".

My question to you all is, how can I extract that range for the circuit
ID's (along with any other relevant information) from the signing key?
In other words, what is the "signing key" made up of, and how can I get
the information that its made of?

The bottom line is I need to find out what valid circuit ID's I can send to
OR's.

I am having a lot of fun doing this project so far and I hope to hear back
from anyone who has an answer :)

Thanks in advance!
Eli

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello to the TOR dev team!&lt;div&gt;&lt;br&gt;&lt;div&gt;&lt;div&gt;My name is Eli, I'm a \
high school student from Israel and I'm currently trying  to implement a TOR \
Client in Python.&lt;/div&gt;&lt;div&gt;&lt;div&gt;Currently, my project is configured so that the \
python client (OP) has its guard node set as my local machine (which is running a \
downloaded version of TOR). I do this for debugging purposes so that if I send a \
malformed cell as the implemented client, I can read the debug log that the OR \
generates and see what I did wrong.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As I am writing \
this, I have successfully  been able to make a v3 "in protocol" handshake \
by sending the proper VERSIONS and NETINFO cells that the OR has \
accepted.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Right now, I am working on getting the CREATE cell \
to work (with the TAP handshake), and when I send the cell to the OR It sends a \
DESTROY cell with the following message in the debug \
log:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Apr 14 12:24:51.166 [warn] Received create cell with \
unexpected circ_id 1. Closing.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;To my  \
understanding, the problem here is that the circuit id I have chosen is not \
valid.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I read from the tor spec that there is a range of \
acceptable circuit id's  for each relay and it can be found in the long term 1024 \
bit RSA "signing key".&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My question to you all is, \
how can I extract that range for the circuit ID's (along with any other relevant \
information) from the signing key?&lt;/div&gt;&lt;div&gt;In other words, what is the \
"signing key" made up of, and how can I get the  information that  its  \
made of?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The bottom line is I need to find out what valid \
circuit  ID's  I can send to OR's.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am having a lot \
of fun doing this project so far and I hope to hear back from anyone who has an  \
answer :)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks in advance!&lt;/div&gt;&lt;div&gt;Eli&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200422015654</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-22 01:56:54-0400</timestampReceived><subject>[tor-dev] Fallback Directory Handover</subject><body>

[Attachment #2 (multipart/alternative)]


Hi all,

Here's a summary of the current state of fallback directory mirrors.

Overall Design

This repository contains a list of potential fallback directory mirrors
(a fallback "offer list"), and a script that checks each mirror for speed
and reliability:
https://gitweb.torproject.org/fallback-scripts.git/

There is a "Fallback Scripts" component for tickets:
https://trac.torproject.org/projects/tor/query?status=!closed&amp;component=Core+Tor%2FFallback+Scripts

The fallback system is designed to gracefully degrade as fallback
directory mirrors fail. Failures shift load to directory authorities,
and cause brief delays during client bootstrap.

We expect the system to operate well, even if all the fallbacks have
failed. But we try to keep the fallback failure rate below 20-30%.
When the failure rate gets too high, we rebuild the fallback list.

Regular Tasks

This ticket is the parent ticket for the next fallback rebuild:
https://trac.torproject.org/projects/tor/ticket/30971

This ticket contains the "offer list" changes that relay operators have
requested. I usually commit them all at once, but you should feel free
to do them incrementally:
https://trac.torproject.org/projects/tor/ticket/30972

Sometimes, we don't have enough relays on the offer list, and we have
to ask relay operators to opt-in to the list. Ideally, we want at least 100
fallbacks, we usually have between 120-160.

Future Work

It's hard to verify changes to the offer list. Changes are usually sent by
email or through trac tickets. There's no reliable trust path from the
relay key to the email or ticket.

The opt-in process is also a manual process. It can be time-consuming.

To resolve these issues, I had planned to add a signed fallback offer line
to relay descriptors:
https://trac.torproject.org/projects/tor/ticket/24839

Instead of checking the list in the fallback-scripts repository, the script
can check relay descriptors instead. (Or check both, during the transition
period.)

Unresolved Issues

Fallbacks eventually see the entire set of clients. Clients that are active 
all the time may only ever contact one fallback. (Clients re-use the same
fallback for authority keys, and then switch to the consensus as soon as
possible.) But clients whose consensuses have expired will choose new
fallbacks at random.

Ideally, clients should select fallback (and maybe authority) guards.
That is, they should retry previously-selected fallbacks. There are some
tradeoffs here: a bad fallback guard can continue to manipulate its
client's view of the network. We can avoid this issue by selecting multiple
fallback guards.

Clients will need persistent state to remember their guards, so transient
systems like TAILS won't benefit from this change.

T

-- 
teor
----------------------------------------------------------------------


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;Hi all,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here's a summary of \
the current state of fallback directory mirrors.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Overall \
Design&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This repository contains a list of potential fallback \
directory mirrors&lt;/div&gt;&lt;div&gt;(a fallback "offer list"), and a script that checks each \
mirror for speed&lt;/div&gt;&lt;div&gt;and reliability:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://gitweb.torproject.org/fallback-scripts.git/"&gt;https://gitweb.torproject.org/fallback-scripts.git/&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There \
is a "Fallback Scripts" component for tickets:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/query?status=!closed&amp;component=Core \
+Tor%2FFallback+Scripts"&gt;https://trac.torproject.org/projects/tor/query?status=!closed&amp;component=Core+Tor%2FFallback+Scripts&lt;/a&gt;&lt;br&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The \
fallback system is designed to gracefully degrade as fallback&lt;/div&gt;&lt;div&gt;directory \
mirrors fail. Failures shift load to directory authorities,&lt;/div&gt;&lt;div&gt;and cause brief \
delays during client bootstrap.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We expect the system to \
operate well, even if all the fallbacks have&lt;/div&gt;&lt;div&gt;failed. But we try to keep the \
fallback failure rate below 20-30%.&lt;/div&gt;&lt;div&gt;When the failure rate gets too high, we \
rebuild the fallback list.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regular \
Tasks&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This ticket is the parent ticket for the next fallback \
rebuild:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/30971"&gt;https://trac.torproject.org/projects/tor/ticket/30971&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This \
ticket contains the "offer list" changes that relay operators \
have&lt;/div&gt;&lt;div&gt;requested. I usually commit them all at once, but you should feel \
free&lt;/div&gt;&lt;div&gt;to do them incrementally:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/30972"&gt;https://trac.torproject.org/projects/tor/ticket/30972&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sometimes, \
we don't have enough relays on the offer list, and we have&lt;/div&gt;&lt;div&gt;to ask relay \
operators to opt-in to the list. Ideally, we want at least 100&lt;/div&gt;&lt;div&gt;fallbacks, \
we usually have between 120-160.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Future \
Work&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It's hard to verify changes to the offer list. Changes \
are usually sent by&lt;/div&gt;&lt;div&gt;email or through trac tickets. There's no reliable \
trust path from the&lt;/div&gt;&lt;div&gt;relay key to the email or \
ticket.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The opt-in process is also a manual process. It can \
be time-consuming.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;To resolve these issues, I had planned to \
add a signed fallback offer line&lt;/div&gt;&lt;div&gt;to relay descriptors:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/24839"&gt;https://trac.torproject.org/projects/tor/ticket/24839&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Instead \
of checking the list in the fallback-scripts repository, the script&lt;/div&gt;&lt;div&gt;can \
check relay descriptors instead. (Or check both, during the \
transition&lt;/div&gt;&lt;div&gt;period.)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Unresolved \
Issues&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;Fallbacks eventually see the entire set of \
clients. Clients that are active&lt;/div&gt;&lt;div&gt;all the time may only ever contact \
one fallback. (Clients re-use the same&lt;/div&gt;&lt;div&gt;fallback for authority keys, and \
then switch to the consensus as soon as&lt;/div&gt;&lt;div&gt;possible.) But clients whose \
consensuses have expired will choose new&lt;/div&gt;&lt;div&gt;fallbacks at \
random.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Ideally, clients should select fallback (and maybe \
authority) guards.&lt;/div&gt;&lt;div&gt;That is, they should retry previously-selected \
fallbacks. There are some&lt;/div&gt;&lt;div&gt;tradeoffs here: a bad fallback guard can continue \
to manipulate its&lt;/div&gt;&lt;div&gt;client's view of the network. We can avoid this issue by \
selecting multiple&lt;/div&gt;&lt;div&gt;fallback guards.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Clients will \
need persistent state to remember their guards, so transient&lt;/div&gt;&lt;div&gt;systems like \
TAILS won't benefit from this change.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div dir="ltr"&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;T&lt;/span&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;--&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;teor&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, \
0);"&gt;----------------------------------------------------------------------&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, \
0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200422022741</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2020-04-22 02:27:41-0400</timestampReceived><subject>Re: [tor-dev] Fallback Directory Handover</subject><body>

On Wed, Apr 22, 2020 at 11:56:54AM +1000, teor wrote:
&gt; a bad fallback guard can continue to manipulate its client's view of
&gt; the network

This is only true to the extent that the fallback guard can choose which
of three still-valid consensuses to give to the client, right?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200422173821</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-04-22 17:38:21-0400</timestampReceived><subject>Re: [tor-dev] Chutney code refactoring</subject><body>

On Fri, Apr 17, 2020 at 10:03 PM c &lt;c@chroniko.jp&gt; wrote:
&gt;
&gt; On Fri, 17 Apr 2020 18:01:42 -0400
&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt;
&gt; &gt; Though I think this is likely to be an ongoing change that we see
&gt; &gt; over time, since
&gt;
&gt; Was this sentence supposed to be longer?

Yeah, I'm afraid I do that sometimes.  I start composing a sentence,
then think of something I want to write somewhere else, and then get
distracted by a third sentence I ought to start.  Usually, I come back
and finish all the sentences.  But sometimes I miss one or get
distracted.

I think what I meant to say here was that we're going to need to keep
refining the API as we work on implementation, since experience with
an API can often show its deficiencies in a way that isn't apparent in
advance.

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200423144501</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-23 14:45:01-0400</timestampReceived><subject>[tor-dev] Proposal 314: Allow Markdown for proposal format.</subject><body>

```
Filename: 314-allow-markdown-proposals.md
Title: Allow Markdown for proposal format.
Author: Nick Mathewson
Created: 23 April 2020
Status: Open
```

# Introduction

This document proposes a change in our proposal format: to allow
Markdown.

## Motivation

Many people, particularly researchers, have found it difficult to
write text in the format that we prefer.  Moreover, we have often
wanted to add more formatting in proposals, and found it nontrivial
to do so.

Markdown is an emerging "standard" (albeit not actually a
standardized one), and we're using it in several other places.  It
seems like a natural fit for our purposes here.

# Details

We should pick a particular Markdown dialect.  "CommonMark" seems like a
good choice, since it's the basis of what github and gitlab use.

We should also pick a particular tool to use for validating Markdown
proposals.

We should continue to allow text proposals.

We should continue to require headers for our proposals, and do so
using the format at the head of this document: wrapping the headers
inside triple backticks.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200423212638</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-23 21:26:38-0400</timestampReceived><subject>Re: [tor-dev] Proposal 315: Updating the list of fields required in directory documents</subject><body>

Hi Nick,

This proposal is missing the "bridge" case.

Bridges are more complicated, because we have at least
3 kinds of bridges:
* bridges distributed by BridgeDB
* bridges distributed with apps (such as Tor Browser)
* private bridges

Bridge option transitions are also more complicated, because clients
download bridge descriptors directly from their configured bridges.

T

&gt; On 24 Apr 2020, at 00:45, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; Filename: 315-update-dir-required-fields.txt
&gt; Title: Updating the list of fields required in directory documents
&gt; Author: Nick Mathewson
&gt; Created: 23 April 2020
&gt; Status: Open
&gt; 
&gt; 1. Introduction
&gt; 
&gt;   When we add a new field to a directory document, we must at first
&gt;   describe it as "optional", since older Tor implementations will
&gt;   not generate it.  When those implementations are obsolete and
&gt;   unsupported, however, we can safely describe those fields as
&gt;   "required", since they are always included in practice.
&gt; 
&gt;   Making fields required is not just a matter of bookkeeping: it
&gt;   helps prevent bugs in two ways.  First, it simplifies our code.
&gt;   Second, it makes our code's requirements match our assumptions
&gt;   about the network.
&gt; 
&gt;   Here I'll describe a general policy for making fields required
&gt;   when LTS versions become unsupported, and include a list of
&gt;   fields that should become required today.
&gt; 
&gt;   This document does not require to us to make all optional fields
&gt;   required -- only those which we intend that all Tor instances
&gt;   should always generate and expect.
&gt; 
&gt;   When we speak of making a field "required", we are talking about
&gt;   describing it as "required" in dir-spec.txt, so that any document
&gt;   missing that field is no longer considered well-formed.
&gt; 
&gt; 2. When fields should become required
&gt; 
&gt;   We have three relevant kinds of directory documents: those
&gt;   generated by relays, those generated by authorities, and those
&gt;   generated by onion services.
&gt; 
&gt;   Relays generate extrainfo documents and routerdesc documents.
&gt;   For these, we can safely make a field required when it is always
&gt;   generated by all relay versions that the authorities allow to
&gt;   join the network.  To avoid partitioning, authorities should
&gt;   start requiring the field before any relays or clients do.
&gt; 
&gt;   (If a relay field indicates the presence of a now-required
&gt;   feature, then instead of making the field mandatory, we may
&gt;   change the semantics so that the field is assumed to be
&gt;   present. Later we can remove the option.)
&gt; 
&gt;   Authorities generate authority certificates, votes, consensus
&gt;   documents, and microdescriptors.  For these, we can safely make a
&gt;   field required once all authorities are generating it, and we are
&gt;   confident that we do not plan to downgrade those authorities.
&gt; 
&gt;   Onion services generate service descriptors.  Because of the risk
&gt;   of partitioning attacks, we should not make features in service
&gt;   descriptors required without a phased process, described in the
&gt;   following section.
&gt; 
&gt; 2.1. Phased addition of onion service descriptor changes
&gt; 
&gt;   Phase one: we add client and service support for the new field,
&gt;   but have this support disabled by default. By default, services
&gt;   should not generate the new field, and clients should not parse
&gt;   it when it is present.  This behavior is controlled by a pair of
&gt;   network parameters.  (If the feature is at all complex, the
&gt;   network parameters should describe a _minimum version_ that
&gt;   should enable the feature, so that we can later enable it only in
&gt;   the versions where the feature is not buggy.)
&gt; 
&gt;   During this phase, we can manually override the defaults on
&gt;   particular clients and services to test the new field.
&gt; 
&gt;   Phase two: authorities use the network parameters to enable the
&gt;   client support and the service support.  They should only do this
&gt;   once enough clients and services have upgraded to a version that
&gt;   supports the feature.
&gt; 
&gt;   Phase three: once all versions that support the feature are
&gt;   obsolete and unsupported, the feature may be marked as required
&gt;   in the specifications, and the network parameters ignored.
&gt; 
&gt;   Phase four: once all versions that used the network parameters
&gt;   are obsolete and unsupported, authorities may stop including
&gt;   those parameters in their votes.
&gt; 
&gt; 3. Directory fields that should become required.
&gt; 
&gt;   These fields in router descriptors should become required:
&gt;      * identity-ed25519
&gt;      * master-key-ed25519
&gt;      * onion-key-crosscert
&gt;      * ntor-onion-key
&gt;      * ntor-onion-key-crosscert
&gt;      * router-sig-ed25519
&gt;      * proto
&gt; 
&gt;   These fields in router descriptors should become "assumed present":
&gt;      * hidden-service-dir
&gt; 
&gt;   These fields in extra-info documents should become required:
&gt;      * identity-ed25519
&gt;      * router-sig-ed25519
&gt; 
&gt;   The following fields in microdescriptors should become
&gt;   required:
&gt;      * ntor-onion-key
&gt; 
&gt;   The following fields in votes and consensus documents should
&gt;   become required:
&gt;      * pr
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200424010514</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-24 01:05:14-0400</timestampReceived><subject>Re: [tor-dev] Proposal XXX: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

Thanks for this proposal!

I'm looking forward to more secure bandwidth measurements on the Tor
network.

Overall, this proposal looks good.

But I'm particularly concerned about any communication between
bandwidth coordinators. Our general principle is that directory
authorities should be independent, and we should minimise their
communication and dependencies. This principle also extends to
bandwidth authorities.

For FlashFlow, here are some specific reasons to avoid bandwidth
coordinator communication:
* it adds complexity to the protocol
* it adds an additional failure mode: failure of coordinator
  communication
  * if the communication is required, this failure mode becomes a
    denial of service vulnerability
  * if the communication is optional, the failure could activate a
    less-tested fallback mode, and change coordinator behaviour
* it adds a class of additional bugs: coordinator miscommunication,
  including race conditions
* it adds a class of additional security vulnerabilities, via
  coordinator communication
* it adds additional coordinator configuration, which must stay
  synchronised. There's two ways to sync config:
  * in the consensus: the coordinator IP addresses are public, or
  * privately: the configs easily get out of sync

There's also some information missing from the proposal, I'll point it
out as part of this review.

&gt; On 24 Apr 2020, at 04:48, Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt; 
&gt; Filename: xxx-flashflow.txt
&gt; Title: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)
&gt; Author: Matthew Traudt, Aaron Johnson, Rob Jansen, Mike Perry
&gt; Created: 23 April 2020
&gt; Status: Draft
&gt; 
&gt; ...
&gt; 
&gt; 3.1.2 New Cell Types
&gt; 
&gt; FlashFlow will introduce a new cell command MEASURE.
&gt; 
&gt; The payload of each MEASURE cell consists of:
&gt; 
&gt;  Measure command [1 byte]
&gt;  Length          [2 bytes]
&gt;  Data            [Length-3 bytes]
&gt; 
&gt; The measure commands are:
&gt; 
&gt;  0 -- MSM_PARAMS    [forward]
&gt;  1 -- MSM_PARAMS_OK [backward]
&gt;  2 -- MSM_ECHO      [forward and backward]
&gt;  3 -- MSM_BG        [backward]
&gt;  4 -- MSM_ERR       [forward and backward]

Readability note:

"MSM" is a standard abbreviation for "mainstream media".

A standard abbreviation for measurement is "MEAS":
https://www.abbreviations.com/abbreviation/MEASurement

&gt; ...
&gt; 
&gt; 3.1.3 Pre-Measurement Handshaking/Starting a Measurement
&gt; 
&gt; The coordinator connects to the target relay and sends it a MSM_PARAMS
&gt; cell.

How much of the tor link protocol does the coordinator implement?

Currently, tor requires the following cells:
* VERSIONS
* NETINFO

https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n542

&gt; If the target is unwilling to be measured at this time or if the
&gt; coordinator didn't use a TLS certificate that the target trusts, it
&gt; responds with an error cell and closes the connection. Otherwise it
&gt; checks that the parameters of the measurement are acceptable (e.g. the
&gt; version is acceptable, the duration isn't too long, etc.). If the
&gt; target is happy, it sends a MSM_PARAMS_OK, otherwise it sends a MSM_ERR
&gt; and closes the connection.
&gt; 
&gt; Upon learning the IP addresses of the measurers from the coordinator in
&gt; the MSM_PARAMS cell, the target whitelists their IPs in its DoS
&gt; detection subsystem until the measurement ends (successfully or
&gt; otherwise), at which point the whitelist is cleared.
&gt; 
&gt; Upon receiving a MSM_PARAMS_OK from the target, the coordinator will
&gt; instruct the measurers to open their TCP connections with the target. If
&gt; the coordinator or any measurer receives a MSM_ERR, it reports the error
&gt; to the coordinator and considers the measurement a failure. It is also a
&gt; failure if any measurer is unable to open at least half of its TCP
&gt; connections with the target.
&gt; 
&gt; The payload of MSM_PARAMS cells [XXX more may need to be added]:
&gt; 
&gt;  - version       [1 byte]

What are the minimum and maximum valid values for this field?
0..255 ?
1..255 ?

Tor uses a standard ext-type-length-value format for new cell
fields, rather than parsing them based on a version field.

It may still be useful to have a version field for information
purposes. (And to workaround bugs in older versions.) Normally, we'd use
Tor Relay protocol versions, but the coordinators and measurers aren't in
the consensus.

Here's an example of the ext-type-length-value format:

     N_EXTENSIONS     [1 byte]
     N_EXTENSIONS times:
        EXT_FIELD_TYPE [1 byte]
        EXT_FIELD_LEN  [1 byte]
        EXT_FIELD      [EXT_FIELD_LEN bytes]

https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1518

You'd want an extension in each measurer info, and also one at the end
of the cell, for any new general fields.

Tor already knows how to parse these fields, because they are used for
v3 onion services.

&gt;  - msm_duration  [1 byte]

What are the minimum and maximum valid values for this field?
1..255 ?

Do we want to limit measurements to 4 minutes at a protocol level?

In general, protocols should make invalid states impossible to represent.
But do we want a 4 minute hard limit here?

&gt;  - num_measurers [1 byte]

What are the minimum and maximum valid values for this field?
1..255 ?
1..17 ?

If you're using a standard 509 byte payload, then the practical limits
are:
  * 84 in the original format
  * 50 with link specifiers, extensions, and IPv4 addresses
  * 17 with link specifiers, extensions, IPv4, and IPv6 addresses

&gt;  - measurer_info [num_measurers times]
&gt;    - ipv4_addr   [4 bytes]

What about IPv6 ?
* 30% of tor relays support IPv6
* proposal 311 introduces IPv6 connections between relays, and we're
  implementing it right now
* IPv4 and IPv6 routing can be different, so their bandwidths
  can also be different

Instead of a hard-coded IPv4 field, you could use the IPv4 and
IPv6 link specifiers, which tor already knows how to parse:

       NSPEC      (Number of link specifiers)     [1 byte]
         NSPEC times:
           LSTYPE (Link specifier type)           [1 byte]
           LSLEN  (Link specifier length)         [1 byte]
           LSPEC  (Link specifier)                [LSLEN bytes]

https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1001

As an example, the v3 onion service spec re-uses link specifiers here:
https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n227

&gt;    - num_conns   [2 bytes]

This field should probably go before the link specifiers.

What are the minimum and maximum valid values for this field?
1..65535 ?

Do we really need to allow more than 255 connections?
Most relays can only handle around 10,000 - 20,000 connections.

&gt; version dictates how this MSM_PARAMS cell shall be parsed. msm_duration
&gt; is the duration, in seconds, that the actual measurement will last.
&gt; num_measurers is how many measurer_info structs follow. For each
&gt; measurer, the ipv4_addr it will use when connecting to the target is
&gt; provided, as is num_conns, the number of TCP connections that measurer
&gt; will open with the target. Future versions of FlashFlow and MSM_PARAMS
&gt; will use TLS certificates instead of IP addresses.

FlashFlow won't be able to measure relays behind a NAT, if it
authenticates using IP addresses. Relays see the IP address of the NAT
device, rather than the IP address of the remote measurer.

For a similar reason, the DOS defences reduce the number of client
connections to a relay behind a NAT. So we can safely ignore those
relays for the moment.

But it would still be useful to talk about the IP address and NAT issue
in this proposal.

&gt; MSM_PARAMS_OK has no payload: it's just padding bytes to make the cell
&gt; 514 bytes long.

Should we add ext-type-length-value fields to this cell?

For example, the MSM_PARAMS_OK cell could be used to communicate the
relay's recent CPU load and connection load.

&gt; The payload of MSM_ECHO cells:
&gt; 
&gt;  - arbitrary bytes [max to fill up 514 byte cell]

Note:

Link protocol 3 is still supported, so cells can be 512 or 514 bytes:
https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2094

Let's say "PAYLOAD_LEN payload (509 bytes)" instead.

If FlashFlow requires link protocol version 4, let's explain why in
this proposal.

&gt; The payload of MSM_BG cells:
&gt; 
&gt;  - second        [1 byte]

What are the minimum and maximum valid values for this field?
1..msm_duration ?

&gt;  - sent_bg_bytes [4 bytes]
&gt;  - recv_bg_bytes [4 bytes]

What are the minimum and maximum valid values for these fields?

Should we add ext-type-length-value fields to this cell?

For example, the MSM_BG cell could be used to communicate the
relay's current CPU load and connection load.

&gt; second is the number of seconds since the measurement began. MSM_BG
&gt; cells are sent once per second from the relay to the FlashFlow
&gt; coordinator. The first cell will have this set to 1, and each
&gt; subsequent cell will increment it by one. sent_bg_bytes is the number of
&gt; background traffic bytes sent in the last second (since the last MSM_BG
&gt; cell). recv_bg_bytes is the same but for received bytes.
&gt; 
&gt; The payload of MSM_ERR cells:
&gt; 
&gt;  - err_code [1 byte]
&gt;  - err_str  [possibly zero-len null-terminated string]

We don't have strings in any other tor protocol cells.

If you need extensible error information, can I suggest using
ext-type-length-value fields:

     N_EXTENSIONS     [1 byte]
     N_EXTENSIONS times:
        EXT_FIELD_TYPE [1 byte]
        EXT_FIELD_LEN  [1 byte]
        EXT_FIELD      [EXT_FIELD_LEN bytes]

https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1518

If strings are necessary, please specify a character encoding
(ASCII or UTF-8), and an allowed set of characters.

If we don't whitelist characters, we risk logging terminal escape
sequences, or other arbitrary data.

&gt; The error code is one of:
&gt; 
&gt;  [... XXX TODO ...]
&gt;  255 -- OTHER
&gt; 
&gt; The error string is optional in all cases. It isn't present if the first
&gt; byte of err_str is null, otherwise it is present. It ends at the first
&gt; null byte or the end of the cell, whichever comes first.
&gt; 
&gt; 3.1.4 Measurement Mode
&gt; 
&gt; The relay considers the measurement to have started the moment it
&gt; receives the first MSM_ECHO cell from any measurer.

What happens if the relay never receives a MSM_ECHO cell?

Do MSM_ECHO cells from invalid measurers count?

How much of the tor link protocol does the measurer implement?
Currently, tor requires the following cells:
* VERSIONS
* NETINFO
https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n542

&gt; At this point, the
&gt; relay
&gt; 
&gt;  - Starts a repeating 1s timer on which it will report the amount of
&gt;    background traffic to the coordinator over the coordinator's
&gt;    connection.
&gt;  - Enters "measurement mode" and limits the amount of background
&gt;    traffic it handles according to the torrc option/consensus
&gt;    parameter.
&gt; 
&gt; The relay decrypts and echos back all MSM_ECHO cells it receives on
&gt; measurement connections

Are MSM_ECHO cells relay cells?
How much of the relay protocol does the measurer implement?

The references to decrypting cells suggest that MSM_ECHO cells are
relay (circuit-level) cells. But earlier sections suggest that they are
link cells.

If they are link cells, what key material is used for decryption?
How do the measurer and relay agree on this key material?

If they are relay cells, do they use the ntor handshake?
https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1132

&gt; until it has reported its amount of background
&gt; traffic the same number of times as there are seconds in the measurement
&gt; (e.g. 30 per-second reports for a 30 second measurement). After sending
&gt; the last MSM_BG cell, the relay drops all buffered MSM_ECHO cells,
&gt; closes all measurement connections, and exits measurement mode.

To be more precise here, can we say:

"the relay drops all inbound and outbound MSM_ECHO cells from measurers
associated with the completed measurement"

Can we avoid assuming that there is always only one measurement happening
at one time?

&gt; During the measurement the relay targets a ratio of background traffic
&gt; to measurement traffic as specified by a consensus parameter/torrc
&gt; option. For a given ratio r, if the relay has handled x cells of
&gt; measurement traffic recently, Tor then limits itself to y = xr/(1-r)
&gt; cells of non-measurement traffic this scheduling round. The target will
&gt; enforce that a minimum of 10 Mbit/s of measurement traffic is recorded
&gt; since the last background traffic scheduling round to ensure it always
&gt; allows some minimum amount of background traffic.

Do you mean "a maximum of 10 Mbit/s of measurement traffic" ?

&gt; 3.2 FlashFlow Components
&gt; 
&gt; The FF coordinator and measurer code will reside in a FlashFlow
&gt; repository separate from little-t tor.
&gt; 
&gt; There are three notable parameters for which a FF deployment must choose
&gt; values. They are:
&gt; 
&gt;  - The number of sockets, s, the measurers should open, in aggregate,
&gt;    with the target relay. We suggest s=160 based on the FF paper.
&gt;  - The bandwidth multiplier, m. Given an existing capacity estimate for
&gt;    a relay, z, the coordinator will instruct the measurers to, in
&gt;    aggregate, send m*z Mbit/s to the target relay. We recommend m=2.25.
&gt;  - The measurement duration, d. Based on the FF paper, we recommend
&gt;    d=30 seconds.

Are these parameters per-coordinator, or network-wide?

How are they kept in sync between the coordinator and measurers?

&gt; The rest of this section first discusses notable functions of the
&gt; FlashFlow coordinator, then goes on to discuss FF measurer code that
&gt; will require supporting tor code.
&gt; 
&gt; 3.2.1 FlashFlow Coordinator
&gt; 
&gt; The coordinator is responsible for scheduling measurements, aggregating
&gt; results, and producing v3bw files. It needs continuous access to new
&gt; consensus files, which it can obtain by running an accompanying Tor
&gt; process in client mode.

Recent tor versions go dormant when they haven't built circuits for a
while. There are options that prevent dormancy, but they are only designed
for interactive applications.

Is the FlashFlow coordinator going to use tor to implement the tor link
protocol?

If the coordinator uses tor, then it can use the same tor client instance
that's downloading its consensuses.

Otherwise, you might just be better using a small stem script, and a
download timer.

If you use a timer, you can download each new consensus, shortly after
it is created. (Clients often have consensuses that are 1-2 hours old,
unless specifically configured to fetch from directory authorities.
Even then, they can take up to an hour to download a new consensus.)

&gt; The coordinator has the following functions, which will be described in
&gt; this section:
&gt; 
&gt;  - result aggregation.
&gt;  - schedule measurements.
&gt;  - v3bw file generation.
&gt; 
&gt; 3.2.1.1 Aggregating Results
&gt; 
&gt; Every second during a measurement, the measurers send the amount of
&gt; verified measurement traffic they have received back from the relay.
&gt; Additionally, the relay sends a MSM_BG cell each second to the
&gt; coordinator with amount of non-measurement background traffic it is
&gt; sending and receiving.

What happens if some of these cells is dropped by the relay, due to a
traffic overload?

If these cells are exempt from the [Relay]Bandwidth{Rate,Burst} options,
let's say that in this proposal.

What happens if some of these cells are delayed due to the MSM_ECHO
cells?

How long a delay does the coordinator tolerate?

&gt; For each second's reports, the coordinator sums the measurer's reports.
&gt; The coordinator takes the minimum of the relay's reported sent and
&gt; received background traffic. If, when compared to the measurer's reports
&gt; for this second, the relay's claimed background traffic is more than
&gt; what's allowed by the background/measurement traffic ratio, then the
&gt; coordinator further clamps the relay's report down. The coordinator adds
&gt; this final adjusted amount of background traffic to the sum of the
&gt; measurer's reports.
&gt; 
&gt; Once the coordinator has done the above for each second in the
&gt; measurement (e.g. 30 times for a 30 second measurement), the coordinator
&gt; takes the median of the 30 per-second throughputs and records it as the
&gt; estimated capacity of the target relay.
&gt; 
&gt; 3.2.1.2 Measurement Schedule
&gt; 
&gt; The short term implementation of measurement scheduling will be simpler
&gt; than the long term one due to (1) there only being one FlashFlow
&gt; deployment, and (2) there being very few relays that support being
&gt; measured by FlashFlow. In fact the FF coordinator will maintain a list
&gt; of the relays that have updated to support being measured and have opted
&gt; in to being measured, and it will only measure them.
&gt; 
&gt; The coordinator divides time into a series of 24 hour periods, commonly
&gt; referred to as days. Each period has measurement slots that are longer
&gt; than a measurement lasts (30s), say 60s, to account for pre- and
&gt; post-measurement work. Thus with 60s slots there's 1,440 slots in a
&gt; day.
&gt; 
&gt; At the start of each day the coordinator considers the list of relays
&gt; that have opted in to being measured. From this list of relays, it
&gt; repeatedly takes the relay with the largest existing capacity estimate.
&gt; It selects a random slot. If the slot has existing relays assigned to
&gt; it, the coordinator makes sure there is enough additional measurer
&gt; capacity to handle this relay. If so, it assigns this relay to this
&gt; slot. If not, it keeps picking new random slots until one has sufficient
&gt; additional measurer capacity.

What if the coordinator doesn't have enough capacity to handle all the
relays on the network? (That is, what if all the slots are full?)

What if the capacity is limited at some other point on the internet?

For example:
* an intermediate transit provider between the measurer and all the chosen
  relays
* the chosen relays are all on the same local network

&gt; Relays without existing capacity estimates are assumed to have the 75th
&gt; percentile capacity of the current network.
&gt; 
&gt; If a relay is not online when it's scheduled to be measured, it doesn't
&gt; get measured that day.

Online in the consensus, or listening via its ORPort?
(There's a delay of up to 3 hours here, whenever the relay goes up or
down.)

What bandwidth weight does an offline relay get?
sbws has had issues because it drops offline relays.

&gt; 3.2.1.2.1 Example
&gt; 
&gt; ...
&gt; 
&gt; 3.2.1.3 Generating V3BW files
&gt; 
&gt; Every hour the FF coordinator produces a v3bw file in which it stores
&gt; the latest capacity estimate for every relay it has measured in the last
&gt; week. The coordinator will create this file on the host's local file
&gt; system. Previously-generated v3bw files will not be deleted by the
&gt; coordinator.

Seems risky, we've seen Torflow fail in the past, because it filled up
the disk with bandwidth files.

What's the required disk capacity for a few years of bandwidth files?

&gt; A symbolic link at a static path will always point to the
&gt; latest v3bw file.
&gt; 
&gt;    $ ls -l
&gt;    v3bw -&gt; v3bw.2020-03-01-05-00-00
&gt;    v3bw.2020-03-01-00-00-00
&gt;    v3bw.2020-03-01-01-00-00
&gt;    v3bw.2020-03-01-02-00-00
&gt;    v3bw.2020-03-01-03-00-00
&gt;    v3bw.2020-03-01-04-00-00
&gt;    v3bw.2020-03-01-05-00-00

You might want to reference the v3bw spec here:
https://gitweb.torproject.org/torspec.git/tree/bandwidth-file-spec.txt

&gt; 3.2.2 FlashFlow Measurer
&gt; 
&gt; The measurers take commands from the coordinator

The command protocol is not specified in this proposal.

For example, does the coordinator send the IPv4 and IPv6 addresses of
the relay to the measurers?

Which deployment parameters are sent via the protocol, and which are
hard-coded in configurations?

&gt; connect to target
&gt; relays with many sockets, send them traffic, and verify the received
&gt; traffic is the same as what was sent. Measurers need access to a lot of
&gt; internal tor functionality. One strategy is to house as much logic as
&gt; possible inside an compile-time-optional control port module that calls
&gt; into other parts of tor. Alternatively FlashFlow could link against tor
&gt; and call internal tor functions directly.
&gt; 
&gt; [XXX for now I'll assume that an optional little-t tor control port
&gt; module housing a lot of this code is the best idea.]

Yes, please don't depend on internal, unspecified interfaces.

&gt; Notable new things that internal tor code will need to do on the
&gt; measurer (client) side:
&gt; 
&gt;  1. Open many TLS+TCP connections to the same relay on purpose.
&gt;  2. Verify echo cells.
&gt; 
&gt; 3.2.2.1 Open many connections
&gt; 
&gt; ...
&gt; 
&gt; 3.3 Security
&gt; 
&gt; ...
&gt; 
&gt; 4. FlashFlow measurement system: Medium term
&gt; 
&gt; The medium term deployment stage begins after FlashFlow has been
&gt; implemented and relays are starting to update to a version of Tor that
&gt; supports it.

We avoid using tor versions to detect relay features. Instead, we use
subprotocol versions:

https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2041

In the first tor release that supports the medium-term FlashFlow, let's
reserve a "Link" protocol version:

https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2094

If any of the FlashFlow cells are relay cells, let's also reserve a
"Relay" protocol version:

https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2122

(We don't want to pick the exact version numbers yet. Let's wait until
the actual tor release.)

&gt; We plan to host a FlashFlow deployment consisting of a FF coordinator
&gt; and a single FF measurer on a single 1 Gbit/s machine. Data produced by
&gt; this deployment will be made available (semi?) publicly, including both
&gt; v3bw files and intermediate results.

All directory authorities publish v3bw files at a standard URL, so if
you use these files in voting, they will be public.

&gt; Any development changes needed during this time would go through
&gt; separate proposals.
&gt; 
&gt; 5. FlashFlow measurement system: Long term
&gt; 
&gt; In the long term, finishing-touch development work will be done,
&gt; including adding better authentication and measurement scheduling, and
&gt; experiments will be run to determine the best way to integrate FlashFlow
&gt; into the Tor ecosystem.
&gt; 
&gt; Any development changes needed during this time would go through
&gt; separate proposals.
&gt; 
&gt; 5.1 Authentication to Target Relay
&gt; 
&gt; Short term deployment already had FlashFlow coordinators using TLS
&gt; certificates when connecting to relays, but in the long term, directory
&gt; authorities will vote on the consensus parameter for which coordinators
&gt; should be allowed to perform measurements. The voting is done in the
&gt; same way they currently vote on recommended tor versions.
&gt; 
&gt; FlashFlow measurers will be updated to use TLS certificates when
&gt; connecting to relays too. FlashFlow coordinators will update the
&gt; contents of MSM_PARAMS cells to contain measurer TLS certificates
&gt; instead of IP addresses, and relays will update to expect this change.

You'll want another new "Link" protocol version for this feature. And
another type of link specifier.

&gt; 5.2 Measurement Scheduling
&gt; 
&gt; Short term deployment only has one FF deployment running. Long term this
&gt; may no longer be the case because, for example, more than one directory
&gt; authority decides to adopt it and they each want to run their own
&gt; deployment. FF deployments will need to coordinate between themselves
&gt; to not measure the same relay at the same time, and to handle new relays
&gt; as they join during the middle of a measurement period (during the day).
&gt; 
&gt; The following is quoted from Section 4.3 of the FlashFlow paper.
&gt; 
&gt;    To measure all relays in the network, the BWAuths periodically
&gt;    determine the measurement schedule. The schedule determines when and
&gt;    by whom a relay should be measured. We assume that the BWAuths have
&gt;    sufficiently synchronized clocks to facilitate coordinating their
&gt;    schedules. A measurement schedule is created for each measurement
&gt;    period, the length p of which determines how often a relay is
&gt;    measured. We use a measurement period of p = 24 hours.
&gt; 
&gt;    To help avoid active denial-of-service attacks on targeted relays,
&gt;    the measurement schedule is randomized and known only to the
&gt;    BWAuths. Before the next measurement period starts, the BWAuths
&gt;    collectively generate a random seed (e.g. using Tor's
&gt;    secure-randomness protocol). Each BWAuth can then locally determine
&gt;    the shared schedule using pseudorandom bits extracted from that
&gt;    seed.

As noted above, communication between BWAuths reduces their independence,
and adds additional risk and complexity in the protocol.

Once-Off Shared Secret Exchange

Here's an alternative protocol, that does not require an additional
shared random implementation:

1. The BWAuths manually exchange a shared secret key (SHARED_SECRET)
   out-of-band
2. Every day, the BWAuths independently derive a shared secret seed for
   the measurement protocol, using a hash function (H), and tor's public
   shared random value (SRV):

      DAILY_SECRET = H(SHARED_SECRET | SRV)

We might also want to use the period number here, like the SRV and onion
service hash ring specs.

The shared secret key should be rotated:
  * each time a new BWAuth is added or removed from the network, and
  * 1 year after the last rotation.

The key rotation can be performed over a few days, because:
* each BWAuth has one of two keys: the new key, or the old key,
* overlaps should be rare in practice,
* when there is an overlap, at most two BWAuths will overlap,
  one from each key,
* overlaps have a low impact for most relays.

&gt;    The algorithm to create the schedule considers each
&gt;    measurement period to be divided into a sequence of t-second
&gt;    measurement slots. For each old relay, slots for each BWAuth to
&gt;    measure it are selected uniformly at random without replacement
&gt;    from all slots in the period that have sufficient unallocated
&gt;    measurement capacity to accommodate the measurement. When a new
&gt;    relay appears, it is measured separately by each BWAuth in the first
&gt;    slots with sufficient unallocated capacity. Note that this design
&gt;    ensures that old relays will continue to be measured, with new
&gt;    relays given secondary priority in the order they arrive.

It's unclear whether this protocol is interactive or not.

Here's a protocol that is explicitly non-interactive:

1. Measurers are assigned a daily order, based on each coordinator's
   certificate hash, and the current DAILY_SECRET.
2. For each coordinator, in the daily order:
   a. Relays in a chosen consensus choose a slot at random, based on
      the DAILY_SECRET, the relay key, and the iteration number
   c. If another coordinator is already measuring that relay in that
      slot, increase the iteration number, and repeat from a.
   b. If the slot is full for the current coordinator, increase the
      iteration number, and repeat from a.
   d. Otherwise, allocate that relay to that slot, for that
      coordinator.

We might also want to use other shared data here, like the consensus
timestamp.

To make sure all the coordinators have the same consensus, we
should keep a copy of the most recent shared consensus. Here's how
we can select a shared consensus:
  * if we're using a scheduled fetch, a consensus from at least 1 hour
    ago (usually 2300 UTC),
  * if we're using a tor client to fetch, a consensus from at least 3
    hours ago (usually 2100 UTC).

If there isn't a consensus for that time, we should keep the most
recent consensus before that time.

It doesn't actually matter if the consensus is a little out of sync,
most relays will have the same fingerprints, and end up in the same
slots.

&gt; 5.3 Experiments
&gt; 
&gt;   [XXX todo]
&gt; 
&gt; 5.4 Other Changes/Investigations/Ideas
&gt; 
&gt; ...
&gt; 
&gt; 6. Citations
&gt; 
&gt; [0] F. Thill. Hidden Service Tracking Detection and Bandwidth Cheating
&gt;    in Tor Anonymity Network. Master's thesis, Univ. Luxembourg, 2014.
&gt; [1] A. Johnson, R. Jansen, N. Hopper, A. Segal, and P. Syverson.
&gt;    PeerFlow: Secure Load Balancing in Tor. Proceedings on Privacy
&gt;    Enhancing Technologies (PoPETs), 2017(2), April 2017.
&gt; [2] Mike Perry: Graph onionperf and consensus information from Rob's
&gt;    experiments https://trac.torproject.org/projects/tor/ticket/33076

T



["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6iO0oACgkQEP6qDnB1
Zyr2Qg/+JAwtoptoZnlJ+Mn9gdU3P6hsyJPHxf8wIfNb63QDSTFUot8DcUGqVNTd
/40plR3PHq72g8VEWeA8jE0AsC2XJTblGb4lh01PY5HIkUIsYNsTcuNLYbALjPUJ
OY7ov5lhTOie+EXjADTxKxWttoyfTsCW44m0B5/m9TszqBfOAma+Z1UROL1gUT5C
DX58uYWq6eoBwSdGdBOBaikXbZwjSn7KgY8gB5LcnVm5fCXjIE+ExTl41HnrJuOZ
c6GpTAQ4g3eR7d+b/o3LQhA19Adm0A9HlAbrvPxQCz01SXnGO1YKhqRTsnhLxJ1D
sOwBWCcDTsx3En0Y8MZzzvypwSDBW464rgMalNV8VbVS42uVOKFVT+RJZeaSIVSN
6ARu5PX++ug8ehREiC46hEeyvTq8Vvs6Ss3GifPBNftVVH9XHyoOe1j19RFUzJQ+
0zgfYI0knDVU9J91TdqL//Mz0ZRB9o+Ln6hGVY08Ju7x4AmPrsmetpugLA+ymH3F
TRp48CaUDUDs7l6c1hyfmWzzFeYwltwA/BcMQIdiT9sGIgfdRAPWkjaKNeZ1pwn6
2pNCB2M2M+X8y4ujUuNoo7PfueJ5ZBDt+P+iai2Wxz6q9re5hXF3qJ6N4qEfgtrJ
7bREORsQO+0SQ26lReLvYz7jEeHnzODyUtgMTq5ZFl9tXs3nxao=
=/zrF
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200423144533</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-23 14:45:33-0400</timestampReceived><subject>[tor-dev] Proposal 315: Updating the list of fields required in directory documents</subject><body>

Filename: 315-update-dir-required-fields.txt
Title: Updating the list of fields required in directory documents
Author: Nick Mathewson
Created: 23 April 2020
Status: Open

1. Introduction

   When we add a new field to a directory document, we must at first
   describe it as "optional", since older Tor implementations will
   not generate it.  When those implementations are obsolete and
   unsupported, however, we can safely describe those fields as
   "required", since they are always included in practice.

   Making fields required is not just a matter of bookkeeping: it
   helps prevent bugs in two ways.  First, it simplifies our code.
   Second, it makes our code's requirements match our assumptions
   about the network.

   Here I'll describe a general policy for making fields required
   when LTS versions become unsupported, and include a list of
   fields that should become required today.

   This document does not require to us to make all optional fields
   required -- only those which we intend that all Tor instances
   should always generate and expect.

   When we speak of making a field "required", we are talking about
   describing it as "required" in dir-spec.txt, so that any document
   missing that field is no longer considered well-formed.

2. When fields should become required

   We have three relevant kinds of directory documents: those
   generated by relays, those generated by authorities, and those
   generated by onion services.

   Relays generate extrainfo documents and routerdesc documents.
   For these, we can safely make a field required when it is always
   generated by all relay versions that the authorities allow to
   join the network.  To avoid partitioning, authorities should
   start requiring the field before any relays or clients do.

   (If a relay field indicates the presence of a now-required
   feature, then instead of making the field mandatory, we may
   change the semantics so that the field is assumed to be
   present. Later we can remove the option.)

   Authorities generate authority certificates, votes, consensus
   documents, and microdescriptors.  For these, we can safely make a
   field required once all authorities are generating it, and we are
   confident that we do not plan to downgrade those authorities.

   Onion services generate service descriptors.  Because of the risk
   of partitioning attacks, we should not make features in service
   descriptors required without a phased process, described in the
   following section.

2.1. Phased addition of onion service descriptor changes

   Phase one: we add client and service support for the new field,
   but have this support disabled by default. By default, services
   should not generate the new field, and clients should not parse
   it when it is present.  This behavior is controlled by a pair of
   network parameters.  (If the feature is at all complex, the
   network parameters should describe a _minimum version_ that
   should enable the feature, so that we can later enable it only in
   the versions where the feature is not buggy.)

   During this phase, we can manually override the defaults on
   particular clients and services to test the new field.

   Phase two: authorities use the network parameters to enable the
   client support and the service support.  They should only do this
   once enough clients and services have upgraded to a version that
   supports the feature.

   Phase three: once all versions that support the feature are
   obsolete and unsupported, the feature may be marked as required
   in the specifications, and the network parameters ignored.

   Phase four: once all versions that used the network parameters
   are obsolete and unsupported, authorities may stop including
   those parameters in their votes.

3. Directory fields that should become required.

   These fields in router descriptors should become required:
      * identity-ed25519
      * master-key-ed25519
      * onion-key-crosscert
      * ntor-onion-key
      * ntor-onion-key-crosscert
      * router-sig-ed25519
      * proto

   These fields in router descriptors should become "assumed present":
      * hidden-service-dir

   These fields in extra-info documents should become required:
      * identity-ed25519
      * router-sig-ed25519

   The following fields in microdescriptors should become
   required:
      * ntor-onion-key

   The following fields in votes and consensus documents should
   become required:
      * pr
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200422063516</emailId><senderName>Adrien Luxey</senderName><senderEmail>adrien@luxeylab.net</senderEmail><timestampReceived>2020-04-22 06:35:16-0400</timestampReceived><subject>[tor-dev] Building a privacy-preserving "contact tracing" app</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/alternative)]


Hi all,

The French state is making a glosing about the "privacy-preserving",
"anonymous" contact tracing app they are developing with Inria (national
informatics research agency). You can check about the protocol proposal,
ROBERT, here: https://github.com/ROBERT-proximity-tracing/documents (in
English!)

As you would expect, the proposal is not privacy-preserving unless you
believe the State would never ever misbehave, e.g. link IP address to
identity with the help of ISPs etc. There is some relevant criticism
here: https://github.com/ROBERT-proximity-tracing/documents/issues/6

I'd like to propose a really private "contact tracing" counter-proposal,
which would use Tor's onion services for sender-receiver anonymity. Not
that I am a proponent of the idea, but we need to come up with
alternatives in the debate.

My question is: /would the Tor community agree on having StopCovid's
traffic go through its net?/ In my proposal, I would only broadcast a
message from a declared COVID-positive person to all its recent
contacts; the proximity sensing would remain Bluetooth. Still, deployed
at the scale of a country, it's a lot of traffic.

Thank you for your time, I will keep you posted,
Adrien



[Attachment #9 (text/html)]

&lt;html&gt;
  &lt;head&gt;

    &lt;meta http-equiv="content-type" content="text/html; charset=UTF-8"&gt;
  &lt;/head&gt;
  &lt;body text="#000000" bgcolor="#FFFFFF"&gt;
    &lt;p&gt;Hi all,&lt;/p&gt;
    &lt;p&gt;The French state is making a glosing about the
      "privacy-preserving", "anonymous" contact tracing app they are
      developing with Inria (national informatics research agency). You
      can check about the protocol proposal, ROBERT, here:
      &lt;a class="moz-txt-link-freetext" \
href="https://github.com/ROBERT-proximity-tracing/documents"&gt;https://github.com/ROBERT-proximity-tracing/documents&lt;/a&gt; \
(in  English!)&lt;/p&gt;
    &lt;p&gt;As you would expect, the proposal is not privacy-preserving
      unless you believe the State would never ever misbehave, e.g. link
      IP address to identity with the help of ISPs etc. There is some
      relevant criticism here:
      &lt;a class="moz-txt-link-freetext" \
href="https://github.com/ROBERT-proximity-tracing/documents/issues/6"&gt;https://github.com/ROBERT-proximity-tracing/documents/issues/6&lt;/a&gt;&lt;/p&gt;
  &lt;p&gt;I'd like to propose a really private "contact tracing"
      counter-proposal, which would use Tor's onion services for
      sender-receiver anonymity. Not that I am a proponent of the idea,
      but we need to come up with alternatives in the debate.&lt;/p&gt;
    &lt;p&gt;My question is: &lt;i&gt;would the Tor community agree on having
        StopCovid's traffic go through its net?&lt;/i&gt; In my proposal, I
      would only broadcast a message from a declared COVID-positive
      person to all its recent contacts; the proximity sensing would
      remain Bluetooth. Still, deployed at the scale of a country, it's
      a lot of traffic.&lt;/p&gt;
    &lt;p&gt;Thank you for your time, I will keep you posted,&lt;br&gt;
      Adrien&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;&lt;br&gt;
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;


["signature.asc" (application/pgp-signature)]
[Attachment #11 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200424204652</emailId><senderName>Matt Traudt</senderName><senderEmail>pastly@torproject.org</senderEmail><timestampReceived>2020-04-24 20:46:52-0400</timestampReceived><subject>Re: [tor-dev] Proposal 316: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

Thanks for the review, Teor. We really appreciate it.

Comments/responses inline with some trimming at the beginning (I gave up
and just left everything in after the first couple of responses).

On 4/23/20 21:05, teor wrote:
&gt; ...
&gt; 
&gt; But I'm particularly concerned about any communication between
&gt; bandwidth coordinators. Our general principle is that directory
&gt; authorities should be independent, and we should minimise their
&gt; communication and dependencies. This principle also extends to
&gt; bandwidth authorities.
&gt; 
&gt; For FlashFlow, here are some specific reasons to avoid bandwidth
&gt; coordinator communication:
&gt; * it adds complexity to the protocol
&gt; * it adds an additional failure mode: failure of coordinator
&gt;   communication
&gt;   * if the communication is required, this failure mode becomes a
&gt;     denial of service vulnerability
&gt;   * if the communication is optional, the failure could activate a
&gt;     less-tested fallback mode, and change coordinator behaviour
&gt; * it adds a class of additional bugs: coordinator miscommunication,
&gt;   including race conditions
&gt; * it adds a class of additional security vulnerabilities, via
&gt;   coordinator communication
&gt; * it adds additional coordinator configuration, which must stay
&gt;   synchronised. There's two ways to sync config:
&gt;   * in the consensus: the coordinator IP addresses are public, or
&gt;   * privately: the configs easily get out of sync
&gt; 

We do not envision inter-coordinator communication other than consensus
parameter voting and rare out-of-band human-to-human "hey we should
change X parameter because [...]".

Each coordinator can calculate every coordinator's measurement schedule
for the entire measurement period independently given only inputs
present in the consensus (e.g. the shared random value). I believe the
under-specified section *5.2 Measurement Scheduling* is the primary
source of your concern here.

&gt;&gt; On 24 Apr 2020, at 04:48, Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt;&gt;
&gt;&gt; ...
&gt;&gt;
&gt;&gt; The measure commands are:
&gt;&gt;
&gt;&gt;  0 -- MSM_PARAMS    [forward]
&gt;&gt;  1 -- MSM_PARAMS_OK [backward]
&gt;&gt;  2 -- MSM_ECHO      [forward and backward]
&gt;&gt;  3 -- MSM_BG        [backward]
&gt;&gt;  4 -- MSM_ERR       [forward and backward]
&gt; 
&gt; Readability note:
&gt; 
&gt; "MSM" is a standard abbreviation for "mainstream media".
&gt; 
&gt; A standard abbreviation for measurement is "MEAS":
&gt; https://www.abbreviations.com/abbreviation/MEASurement
&gt; 

Fair, why-didn't-I-think-of-that point.

&gt;&gt; ...
&gt;&gt;
&gt;&gt; 3.1.3 Pre-Measurement Handshaking/Starting a Measurement
&gt;&gt;
&gt;&gt; The coordinator connects to the target relay and sends it a MSM_PARAMS
&gt;&gt; cell.
&gt; 
&gt; How much of the tor link protocol does the coordinator implement?
&gt; 
&gt; Currently, tor requires the following cells:
&gt; * VERSIONS
&gt; * NETINFO
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n542
&gt; 

Coordinators use a Tor client (with requisite new features) to
communicate with the relay. So, none of the link protocol.

&gt;&gt; If the target is unwilling to be measured at this time or if the
&gt;&gt; coordinator didn't use a TLS certificate that the target trusts, it
&gt;&gt; responds with an error cell and closes the connection. Otherwise it
&gt;&gt; checks that the parameters of the measurement are acceptable (e.g. the
&gt;&gt; version is acceptable, the duration isn't too long, etc.). If the
&gt;&gt; target is happy, it sends a MSM_PARAMS_OK, otherwise it sends a MSM_ERR
&gt;&gt; and closes the connection.
&gt;&gt;
&gt;&gt; Upon learning the IP addresses of the measurers from the coordinator in
&gt;&gt; the MSM_PARAMS cell, the target whitelists their IPs in its DoS
&gt;&gt; detection subsystem until the measurement ends (successfully or
&gt;&gt; otherwise), at which point the whitelist is cleared.
&gt;&gt;
&gt;&gt; Upon receiving a MSM_PARAMS_OK from the target, the coordinator will
&gt;&gt; instruct the measurers to open their TCP connections with the target. If
&gt;&gt; the coordinator or any measurer receives a MSM_ERR, it reports the error
&gt;&gt; to the coordinator and considers the measurement a failure. It is also a
&gt;&gt; failure if any measurer is unable to open at least half of its TCP
&gt;&gt; connections with the target.
&gt;&gt;
&gt;&gt; The payload of MSM_PARAMS cells [XXX more may need to be added]:
&gt;&gt;
&gt;&gt;  - version       [1 byte]
&gt; 
&gt; What are the minimum and maximum valid values for this field?
&gt; 0..255 ?
&gt; 1..255 ?
&gt; 
&gt; Tor uses a standard ext-type-length-value format for new cell
&gt; fields, rather than parsing them based on a version field.
&gt; 

You've provided lots of feedback consisting of

- min/max value questions
- suggestion of ext-type-length-value format

And it's all appreciated and valuable. We're not as up to speed on the
latest Tor coding conventions.

&gt; It may still be useful to have a version field for information
&gt; purposes. (And to workaround bugs in older versions.) Normally, we'd use
&gt; Tor Relay protocol versions, but the coordinators and measurers aren't in
&gt; the consensus.
&gt; 
&gt; Here's an example of the ext-type-length-value format:
&gt; 
&gt;      N_EXTENSIONS     [1 byte]
&gt;      N_EXTENSIONS times:
&gt;         EXT_FIELD_TYPE [1 byte]
&gt;         EXT_FIELD_LEN  [1 byte]
&gt;         EXT_FIELD      [EXT_FIELD_LEN bytes]
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1518
&gt; 
&gt; You'd want an extension in each measurer info, and also one at the end
&gt; of the cell, for any new general fields.
&gt; 
&gt; Tor already knows how to parse these fields, because they are used for
&gt; v3 onion services.
&gt; 
&gt;&gt;  - msm_duration  [1 byte]
&gt; 
&gt; What are the minimum and maximum valid values for this field?
&gt; 1..255 ?
&gt; 
&gt; Do we want to limit measurements to 4 minutes at a protocol level?
&gt; 
&gt; In general, protocols should make invalid states impossible to represent.
&gt; But do we want a 4 minute hard limit here?
&gt;

This document suggests a measurement duration of 30 seconds. We see no
reason to ever go above 1 minute. If there's a byte to spare, then sure
let's make this a uint16.

&gt;&gt;  - num_measurers [1 byte]
&gt; 
&gt; What are the minimum and maximum valid values for this field?
&gt; 1..255 ?
&gt; 1..17 ?
&gt; 
&gt; If you're using a standard 509 byte payload, then the practical limits
&gt; are:
&gt;   * 84 in the original format
&gt;   * 50 with link specifiers, extensions, and IPv4 addresses
&gt;   * 17 with link specifiers, extensions, IPv4, and IPv6 addresses
&gt; 
&gt;&gt;  - measurer_info [num_measurers times]
&gt;&gt;    - ipv4_addr   [4 bytes]
&gt; 
&gt; What about IPv6 ?
&gt; * 30% of tor relays support IPv6
&gt; * proposal 311 introduces IPv6 connections between relays, and we're
&gt;   implementing it right now
&gt; * IPv4 and IPv6 routing can be different, so their bandwidths
&gt;   can also be different
&gt; 
&gt; Instead of a hard-coded IPv4 field, you could use the IPv4 and
&gt; IPv6 link specifiers, which tor already knows how to parse:
&gt; 
&gt;        NSPEC      (Number of link specifiers)     [1 byte]
&gt;          NSPEC times:
&gt;            LSTYPE (Link specifier type)           [1 byte]
&gt;            LSLEN  (Link specifier length)         [1 byte]
&gt;            LSPEC  (Link specifier)                [LSLEN bytes]
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1001
&gt; 
&gt; As an example, the v3 onion service spec re-uses link specifiers here:
&gt; https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n227
&gt; 

This is useful, thanks. Yes this is probably a better idea. A maximum of
17 measurers should be enough. It's hard to imagine a bwauth would have
more than even 10 hosts they'd want to act as measurers.

&gt;&gt;    - num_conns   [2 bytes]
&gt; 
&gt; This field should probably go before the link specifiers.
&gt; 
&gt; What are the minimum and maximum valid values for this field?
&gt; 1..65535 ?
&gt; 
&gt; Do we really need to allow more than 255 connections?
&gt; Most relays can only handle around 10,000 - 20,000 connections.
&gt; 

160 connections was determined "to be right" (major glossing over
details here) in the experiments we did for the paper. As part of that
we also tried 320, which is bigger than 255. While I don't imagine we'll
ever want more than 255, two bytes leaves us room.

&gt;&gt; version dictates how this MSM_PARAMS cell shall be parsed. msm_duration
&gt;&gt; is the duration, in seconds, that the actual measurement will last.
&gt;&gt; num_measurers is how many measurer_info structs follow. For each
&gt;&gt; measurer, the ipv4_addr it will use when connecting to the target is
&gt;&gt; provided, as is num_conns, the number of TCP connections that measurer
&gt;&gt; will open with the target. Future versions of FlashFlow and MSM_PARAMS
&gt;&gt; will use TLS certificates instead of IP addresses.
&gt; 
&gt; FlashFlow won't be able to measure relays behind a NAT, if it
&gt; authenticates using IP addresses. Relays see the IP address of the NAT
&gt; device, rather than the IP address of the remote measurer.
&gt; 
&gt; For a similar reason, the DOS defences reduce the number of client
&gt; connections to a relay behind a NAT. So we can safely ignore those
&gt; relays for the moment.
&gt; 
&gt; But it would still be useful to talk about the IP address and NAT issue
&gt; in this proposal.
&gt; 

This is not an issue we had considered. For the short term deployment
maybe we can just say not being NAT-ed is a prerequisite for opting in
to measurement.

&gt;&gt; MSM_PARAMS_OK has no payload: it's just padding bytes to make the cell
&gt;&gt; 514 bytes long.
&gt; 
&gt; Should we add ext-type-length-value fields to this cell?
&gt; 
&gt; For example, the MSM_PARAMS_OK cell could be used to communicate the
&gt; relay's recent CPU load and connection load.
&gt; 
&gt;&gt; The payload of MSM_ECHO cells:
&gt;&gt;
&gt;&gt;  - arbitrary bytes [max to fill up 514 byte cell]
&gt; 
&gt; Note:
&gt; 
&gt; Link protocol 3 is still supported, so cells can be 512 or 514 bytes:
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2094
&gt; 
&gt; Let's say "PAYLOAD_LEN payload (509 bytes)" instead.
&gt; 
&gt; If FlashFlow requires link protocol version 4, let's explain why in
&gt; this proposal.
&gt;

I don't believe FlashFlow requires link protocol 4. Yes the above should
be re-worded.

&gt;&gt; The payload of MSM_BG cells:
&gt;&gt;
&gt;&gt;  - second        [1 byte]
&gt; 
&gt; What are the minimum and maximum valid values for this field?
&gt; 1..msm_duration ?
&gt; 
&gt;&gt;  - sent_bg_bytes [4 bytes]
&gt;&gt;  - recv_bg_bytes [4 bytes]
&gt; 
&gt; What are the minimum and maximum valid values for these fields?
&gt; 
&gt; Should we add ext-type-length-value fields to this cell?
&gt; 
&gt; For example, the MSM_BG cell could be used to communicate the
&gt; relay's current CPU load and connection load.
&gt; 

Indeed we picture MSM_BG cells being used in the longer term to
communicate such information. ext-type-length-value fields are probably
called for.

&gt;&gt; second is the number of seconds since the measurement began. MSM_BG
&gt;&gt; cells are sent once per second from the relay to the FlashFlow
&gt;&gt; coordinator. The first cell will have this set to 1, and each
&gt;&gt; subsequent cell will increment it by one. sent_bg_bytes is the number of
&gt;&gt; background traffic bytes sent in the last second (since the last MSM_BG
&gt;&gt; cell). recv_bg_bytes is the same but for received bytes.
&gt;&gt;
&gt;&gt; The payload of MSM_ERR cells:
&gt;&gt;
&gt;&gt;  - err_code [1 byte]
&gt;&gt;  - err_str  [possibly zero-len null-terminated string]
&gt; 
&gt; We don't have strings in any other tor protocol cells.
&gt; 
&gt; If you need extensible error information, can I suggest using
&gt; ext-type-length-value fields:
&gt; 
&gt;      N_EXTENSIONS     [1 byte]
&gt;      N_EXTENSIONS times:
&gt;         EXT_FIELD_TYPE [1 byte]
&gt;         EXT_FIELD_LEN  [1 byte]
&gt;         EXT_FIELD      [EXT_FIELD_LEN bytes]
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1518
&gt; 
&gt; If strings are necessary, please specify a character encoding
&gt; (ASCII or UTF-8), and an allowed set of characters.
&gt; 
&gt; If we don't whitelist characters, we risk logging terminal escape
&gt; sequences, or other arbitrary data.
&gt; 

I seem to remember strings used between directory authority /directory
mirror relays and clients to communicate certain errors (clock skew?),
but what's probably reality is a *code* is communicated and what I'm
thinking of is merely the Tor client interpreting the code for logging
purposes.

Regardless, we probably don't really need a string. It occurs to me we
might want *something* that carries more information than a code; for
example, a MSM_ERR cell with a code stating "I'm refusing to be measured
because I've been measured too recently" would benefit from a field
stating either time till measurement allowed again or time since last
measurement.

&gt;&gt; The error code is one of:
&gt;&gt;
&gt;&gt;  [... XXX TODO ...]
&gt;&gt;  255 -- OTHER
&gt;&gt;
&gt;&gt; The error string is optional in all cases. It isn't present if the first
&gt;&gt; byte of err_str is null, otherwise it is present. It ends at the first
&gt;&gt; null byte or the end of the cell, whichever comes first.
&gt;&gt;
&gt;&gt; 3.1.4 Measurement Mode
&gt;&gt;
&gt;&gt; The relay considers the measurement to have started the moment it
&gt;&gt; receives the first MSM_ECHO cell from any measurer.
&gt; 
&gt; What happens if the relay never receives a MSM_ECHO cell?
&gt; 
&gt; Do MSM_ECHO cells from invalid measurers count?
&gt; 
&gt; How much of the tor link protocol does the measurer implement?
&gt; Currently, tor requires the following cells:
&gt; * VERSIONS
&gt; * NETINFO
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n542
&gt;

If the relay never receives a MSM_ECHO cell, it never enters measurement
mode (thus it never limits background traffic), eventually times out on
waiting for the measurement to start, sends MSM_ERR cells to connected
measurers/coordinator, and cleans up.

Only measurers that are a part of this measurement can send MSM_ECHO
cells. Other measurers shouldn't have even been allowed to connect.

Measurers don't implement the tor link protocol because they require a
Tor client to do the hard work for them, similar to how I clarified
coordinators above.

&gt;&gt; At this point, the
&gt;&gt; relay
&gt;&gt;
&gt;&gt;  - Starts a repeating 1s timer on which it will report the amount of
&gt;&gt;    background traffic to the coordinator over the coordinator's
&gt;&gt;    connection.
&gt;&gt;  - Enters "measurement mode" and limits the amount of background
&gt;&gt;    traffic it handles according to the torrc option/consensus
&gt;&gt;    parameter.
&gt;&gt;
&gt;&gt; The relay decrypts and echos back all MSM_ECHO cells it receives on
&gt;&gt; measurement connections
&gt; 
&gt; Are MSM_ECHO cells relay cells?
&gt; How much of the relay protocol does the measurer implement?
&gt; 
&gt; The references to decrypting cells suggest that MSM_ECHO cells are
&gt; relay (circuit-level) cells. But earlier sections suggest that they are
&gt; link cells.
&gt; 
&gt; If they are link cells, what key material is used for decryption?
&gt; How do the measurer and relay agree on this key material?
&gt; 
&gt; If they are relay cells, do they use the ntor handshake?
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1132
&gt;

MEASURE cells are cells like CREATE, CREATED, RELAY, etc.

MSM_ECHO, MSM_PARAMS, etc. cells are MEASURE cells in the same way
RELAY_BEGIN, RELAY_DATA, RELAY_SENDME, etc. are RELAY cells.

The relay needs to do AES on the MSM_ECHO cells (or for simplicity, the
MSM_ECHO cell payload) like it does AES on relay cells. As for key
material necessary to do that, that's an oversight. We've neglected to
specify how it's derived.

Suggestions? Not a cryptographer, but off the top of my head, the
measurer could simply tell the relay to use $key_i for MSM_ECHO cells on
$connection_i. We just want the CPU load on the relay; we're not after
security properties here (other than verifying the relay is actually
doing the crypto, as discussed elsewhere).

&gt;&gt; until it has reported its amount of background
&gt;&gt; traffic the same number of times as there are seconds in the measurement
&gt;&gt; (e.g. 30 per-second reports for a 30 second measurement). After sending
&gt;&gt; the last MSM_BG cell, the relay drops all buffered MSM_ECHO cells,
&gt;&gt; closes all measurement connections, and exits measurement mode.
&gt; 
&gt; To be more precise here, can we say:
&gt; 
&gt; "the relay drops all inbound and outbound MSM_ECHO cells from measurers
&gt; associated with the completed measurement"
&gt; 
&gt; Can we avoid assuming that there is always only one measurement happening
&gt; at one time?
&gt;

I think it's safe/smart/necessary to assume that, for a given relay,
there is always only zero or one measurements happening.

- Measurements are scheduled s.t. coordinators won't try to measure a
relay at the same time.
- A coordinator trying to start a measurement while another one is
ongoing can simply be sent a MSM_ERR cell stating as such.
- The security arguments behind *3.3.2 Weight Inflation* only make sense
when there is only one measurement at a time.

&gt;&gt; During the measurement the relay targets a ratio of background traffic
&gt;&gt; to measurement traffic as specified by a consensus parameter/torrc
&gt;&gt; option. For a given ratio r, if the relay has handled x cells of
&gt;&gt; measurement traffic recently, Tor then limits itself to y = xr/(1-r)
&gt;&gt; cells of non-measurement traffic this scheduling round. The target will
&gt;&gt; enforce that a minimum of 10 Mbit/s of measurement traffic is recorded
&gt;&gt; since the last background traffic scheduling round to ensure it always
&gt;&gt; allows some minimum amount of background traffic.
&gt; 
&gt; Do you mean "a maximum of 10 Mbit/s of measurement traffic" ?
&gt; 

No. When getting ready to handle background traffic, if there has been
less than 10 Mbit/s of measurement traffic recently, Tor will limit
background traffic as if there was indeed 10 Mbit/s of measurement traffic.

This way the relay can always send at least some background traffic, and
a malfunctioning/malicious FlashFlow deployment cannot stop all
background client traffic going through a relay for 30 seconds by not
sending it (very much) measurement traffic.

&gt;&gt; 3.2 FlashFlow Components
&gt;&gt;
&gt;&gt; The FF coordinator and measurer code will reside in a FlashFlow
&gt;&gt; repository separate from little-t tor.
&gt;&gt;
&gt;&gt; There are three notable parameters for which a FF deployment must choose
&gt;&gt; values. They are:
&gt;&gt;
&gt;&gt;  - The number of sockets, s, the measurers should open, in aggregate,
&gt;&gt;    with the target relay. We suggest s=160 based on the FF paper.
&gt;&gt;  - The bandwidth multiplier, m. Given an existing capacity estimate for
&gt;&gt;    a relay, z, the coordinator will instruct the measurers to, in
&gt;&gt;    aggregate, send m*z Mbit/s to the target relay. We recommend m=2.25.
&gt;&gt;  - The measurement duration, d. Based on the FF paper, we recommend
&gt;&gt;    d=30 seconds.
&gt; 
&gt; Are these parameters per-coordinator, or network-wide?
&gt; 
&gt; How are they kept in sync between the coordinator and measurers?
&gt; 

Per-coordinator. The coordinator tells the measurers the parameters for
each measurement.

&gt;&gt; The rest of this section first discusses notable functions of the
&gt;&gt; FlashFlow coordinator, then goes on to discuss FF measurer code that
&gt;&gt; will require supporting tor code.
&gt;&gt;
&gt;&gt; 3.2.1 FlashFlow Coordinator
&gt;&gt;
&gt;&gt; The coordinator is responsible for scheduling measurements, aggregating
&gt;&gt; results, and producing v3bw files. It needs continuous access to new
&gt;&gt; consensus files, which it can obtain by running an accompanying Tor
&gt;&gt; process in client mode.
&gt; 
&gt; Recent tor versions go dormant when they haven't built circuits for a
&gt; while. There are options that prevent dormancy, but they are only designed
&gt; for interactive applications.
&gt; 
&gt; Is the FlashFlow coordinator going to use tor to implement the tor link
&gt; protocol?
&gt; 
&gt; If the coordinator uses tor, then it can use the same tor client instance
&gt; that's downloading its consensuses.
&gt; 
&gt; Otherwise, you might just be better using a small stem script, and a
&gt; download timer.
&gt; 
&gt; If you use a timer, you can download each new consensus, shortly after
&gt; it is created. (Clients often have consensuses that are 1-2 hours old,
&gt; unless specifically configured to fetch from directory authorities.
&gt; Even then, they can take up to an hour to download a new consensus.)
&gt;

As described elsewhere, the coordinator uses a Tor client in order to
avoid implementing the tor link protocol itself. If there is not already
a way to make a Tor client download every new consensus (e.g. a torrc
option or an hourly control port command), we'll want to add that.

&gt;&gt; The coordinator has the following functions, which will be described in
&gt;&gt; this section:
&gt;&gt;
&gt;&gt;  - result aggregation.
&gt;&gt;  - schedule measurements.
&gt;&gt;  - v3bw file generation.
&gt;&gt;
&gt;&gt; 3.2.1.1 Aggregating Results
&gt;&gt;
&gt;&gt; Every second during a measurement, the measurers send the amount of
&gt;&gt; verified measurement traffic they have received back from the relay.
&gt;&gt; Additionally, the relay sends a MSM_BG cell each second to the
&gt;&gt; coordinator with amount of non-measurement background traffic it is
&gt;&gt; sending and receiving.
&gt; 
&gt; What happens if some of these cells is dropped by the relay, due to a
&gt; traffic overload?
&gt; 
&gt; If these cells are exempt from the [Relay]Bandwidth{Rate,Burst} options,
&gt; let's say that in this proposal.
&gt; 
&gt; What happens if some of these cells are delayed due to the MSM_ECHO
&gt; cells?
&gt; 
&gt; How long a delay does the coordinator tolerate?
&gt; 

It would be bad for these cells to get dropped. I can't say if that
means they need to be exempt from BandwidthRate (etc.) options.

IMO it would be fine if the cells were extremely delayed and they all
arrived at the coordinator at the very end of the measurement in a
bunch. Though not ideal, it would be "fine" if they arrived out of order
or a few were lost. They can be reordered fine, and losing a few "just"
leads to inaccuracy.

Obviously I think this should be mitigated. 100%. I'm just saying it's
not a measurement failure if these things happen.

&gt;&gt; For each second's reports, the coordinator sums the measurer's reports.
&gt;&gt; The coordinator takes the minimum of the relay's reported sent and
&gt;&gt; received background traffic. If, when compared to the measurer's reports
&gt;&gt; for this second, the relay's claimed background traffic is more than
&gt;&gt; what's allowed by the background/measurement traffic ratio, then the
&gt;&gt; coordinator further clamps the relay's report down. The coordinator adds
&gt;&gt; this final adjusted amount of background traffic to the sum of the
&gt;&gt; measurer's reports.
&gt;&gt;
&gt;&gt; Once the coordinator has done the above for each second in the
&gt;&gt; measurement (e.g. 30 times for a 30 second measurement), the coordinator
&gt;&gt; takes the median of the 30 per-second throughputs and records it as the
&gt;&gt; estimated capacity of the target relay.
&gt;&gt;
&gt;&gt; 3.2.1.2 Measurement Schedule
&gt;&gt;
&gt;&gt; The short term implementation of measurement scheduling will be simpler
&gt;&gt; than the long term one due to (1) there only being one FlashFlow
&gt;&gt; deployment, and (2) there being very few relays that support being
&gt;&gt; measured by FlashFlow. In fact the FF coordinator will maintain a list
&gt;&gt; of the relays that have updated to support being measured and have opted
&gt;&gt; in to being measured, and it will only measure them.
&gt;&gt;
&gt;&gt; The coordinator divides time into a series of 24 hour periods, commonly
&gt;&gt; referred to as days. Each period has measurement slots that are longer
&gt;&gt; than a measurement lasts (30s), say 60s, to account for pre- and
&gt;&gt; post-measurement work. Thus with 60s slots there's 1,440 slots in a
&gt;&gt; day.
&gt;&gt;
&gt;&gt; At the start of each day the coordinator considers the list of relays
&gt;&gt; that have opted in to being measured. From this list of relays, it
&gt;&gt; repeatedly takes the relay with the largest existing capacity estimate.
&gt;&gt; It selects a random slot. If the slot has existing relays assigned to
&gt;&gt; it, the coordinator makes sure there is enough additional measurer
&gt;&gt; capacity to handle this relay. If so, it assigns this relay to this
&gt;&gt; slot. If not, it keeps picking new random slots until one has sufficient
&gt;&gt; additional measurer capacity.
&gt; 
&gt; What if the coordinator doesn't have enough capacity to handle all the
&gt; relays on the network? (That is, what if all the slots are full?)
&gt;

We can adjust the definition of the measurement period to: the maximum of

1. 24 hours, and
2. the amount of time the FlashFlow deployment with least capacity will
take to measure the entire network + some factor.

If new relays appear during the day and all slots have been filled,
that's unfortunate but they will just wait till the next day.

&gt; What if the capacity is limited at some other point on the internet?
&gt; 
&gt; For example:
&gt; * an intermediate transit provider between the measurer and all the chosen
&gt;   relays
&gt; * the chosen relays are all on the same local network
&gt;

Ideally a single FlashFlow deployment's measurers are diverse to help
mitigate the first point.

For the second, I don't have a good idea at this time. That shouldn't
happen regularly. It will happen sometimes though, so perhaps this
motivates a modification in how the coordinator chooses the weight for a
relay. Instead of the result of the latest measurement, perhaps the
highest result from the last X measurements.

&gt;&gt; Relays without existing capacity estimates are assumed to have the 75th
&gt;&gt; percentile capacity of the current network.
&gt;&gt;
&gt;&gt; If a relay is not online when it's scheduled to be measured, it doesn't
&gt;&gt; get measured that day.
&gt; 
&gt; Online in the consensus, or listening via its ORPort?
&gt; (There's a delay of up to 3 hours here, whenever the relay goes up or
&gt; down.)
&gt; 
&gt; What bandwidth weight does an offline relay get?
&gt; sbws has had issues because it drops offline relays.
&gt;

Online as in both, I think.

I'm not up to speed or have forgotten why continuing to give weight to
offline relays is important (and this may not be the place to enlighten
me). Naively I'd say zero. Assuming that's stupid, I **think** whatever
weight FlashFlow would give it were it online is smarter than some
minimum weight value. Suggestions?

&gt;&gt; 3.2.1.2.1 Example
&gt;&gt;
&gt;&gt; ...
&gt;&gt;
&gt;&gt; 3.2.1.3 Generating V3BW files
&gt;&gt;
&gt;&gt; Every hour the FF coordinator produces a v3bw file in which it stores
&gt;&gt; the latest capacity estimate for every relay it has measured in the last
&gt;&gt; week. The coordinator will create this file on the host's local file
&gt;&gt; system. Previously-generated v3bw files will not be deleted by the
&gt;&gt; coordinator.
&gt; 
&gt; Seems risky, we've seen Torflow fail in the past, because it filled up
&gt; the disk with bandwidth files.
&gt; 
&gt; What's the required disk capacity for a few years of bandwidth files?
&gt;

We can ship a script or provide a parameter to keep the last X v3bw
files if that would be preferable to relying on bwauths using logrotate
themselves or otherwise finding an archival/deletion strategy that fits
their needs.

&gt;&gt; A symbolic link at a static path will always point to the
&gt;&gt; latest v3bw file.
&gt;&gt;
&gt;&gt;    $ ls -l
&gt;&gt;    v3bw -&gt; v3bw.2020-03-01-05-00-00
&gt;&gt;    v3bw.2020-03-01-00-00-00
&gt;&gt;    v3bw.2020-03-01-01-00-00
&gt;&gt;    v3bw.2020-03-01-02-00-00
&gt;&gt;    v3bw.2020-03-01-03-00-00
&gt;&gt;    v3bw.2020-03-01-04-00-00
&gt;&gt;    v3bw.2020-03-01-05-00-00
&gt; 
&gt; You might want to reference the v3bw spec here:
&gt; https://gitweb.torproject.org/torspec.git/tree/bandwidth-file-spec.txt
&gt; 
&gt;&gt; 3.2.2 FlashFlow Measurer
&gt;&gt;
&gt;&gt; The measurers take commands from the coordinator
&gt; 
&gt; The command protocol is not specified in this proposal.
&gt; 
&gt; For example, does the coordinator send the IPv4 and IPv6 addresses of
&gt; the relay to the measurers?
&gt; 
&gt; Which deployment parameters are sent via the protocol, and which are
&gt; hard-coded in configurations?
&gt;

A Tor proposal did not seem the place for some of these protocols,
options, etc. existing entirely outside little-t tor. We can certainly
elaborate better if that's wrong.

To answer these specific questions: the coordinator would send
fingerprints to the measurers, and the ~only config options the
measurers will have is information regarding the coordinator from which
they shall expect commands. All other FlashFlow options (e.g.
measurement duration) are configured at the coordinator and the coord
informs the measurers.

&gt;&gt; connect to target
&gt;&gt; relays with many sockets, send them traffic, and verify the received
&gt;&gt; traffic is the same as what was sent. Measurers need access to a lot of
&gt;&gt; internal tor functionality. One strategy is to house as much logic as
&gt;&gt; possible inside an compile-time-optional control port module that calls
&gt;&gt; into other parts of tor. Alternatively FlashFlow could link against tor
&gt;&gt; and call internal tor functions directly.
&gt;&gt;
&gt;&gt; [XXX for now I'll assume that an optional little-t tor control port
&gt;&gt; module housing a lot of this code is the best idea.]
&gt; 
&gt; Yes, please don't depend on internal, unspecified interfaces.
&gt; 
&gt;&gt; Notable new things that internal tor code will need to do on the
&gt;&gt; measurer (client) side:
&gt;&gt;
&gt;&gt;  1. Open many TLS+TCP connections to the same relay on purpose.
&gt;&gt;  2. Verify echo cells.
&gt;&gt;
&gt;&gt; 3.2.2.1 Open many connections
&gt;&gt;
&gt;&gt; ...
&gt;&gt;
&gt;&gt; 3.3 Security
&gt;&gt;
&gt;&gt; ...
&gt;&gt;
&gt;&gt; 4. FlashFlow measurement system: Medium term
&gt;&gt;
&gt;&gt; The medium term deployment stage begins after FlashFlow has been
&gt;&gt; implemented and relays are starting to update to a version of Tor that
&gt;&gt; supports it.
&gt; 
&gt; We avoid using tor versions to detect relay features. Instead, we use
&gt; subprotocol versions:
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2041
&gt; 
&gt; In the first tor release that supports the medium-term FlashFlow, let's
&gt; reserve a "Link" protocol version:
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2094
&gt; 
&gt; If any of the FlashFlow cells are relay cells, let's also reserve a
&gt; "Relay" protocol version:
&gt; 
&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2122
&gt; 
&gt; (We don't want to pick the exact version numbers yet. Let's wait until
&gt; the actual tor release.)
&gt; 
&gt;&gt; We plan to host a FlashFlow deployment consisting of a FF coordinator
&gt;&gt; and a single FF measurer on a single 1 Gbit/s machine. Data produced by
&gt;&gt; this deployment will be made available (semi?) publicly, including both
&gt;&gt; v3bw files and intermediate results.
&gt; 
&gt; All directory authorities publish v3bw files at a standard URL, so if
&gt; you use these files in voting, they will be public.
&gt; 
&gt;&gt; Any development changes needed during this time would go through
&gt;&gt; separate proposals.
&gt;&gt;
&gt;&gt; 5. FlashFlow measurement system: Long term
&gt;&gt;
&gt;&gt; In the long term, finishing-touch development work will be done,
&gt;&gt; including adding better authentication and measurement scheduling, and
&gt;&gt; experiments will be run to determine the best way to integrate FlashFlow
&gt;&gt; into the Tor ecosystem.
&gt;&gt;
&gt;&gt; Any development changes needed during this time would go through
&gt;&gt; separate proposals.
&gt;&gt;
&gt;&gt; 5.1 Authentication to Target Relay
&gt;&gt;
&gt;&gt; Short term deployment already had FlashFlow coordinators using TLS
&gt;&gt; certificates when connecting to relays, but in the long term, directory
&gt;&gt; authorities will vote on the consensus parameter for which coordinators
&gt;&gt; should be allowed to perform measurements. The voting is done in the
&gt;&gt; same way they currently vote on recommended tor versions.
&gt;&gt;
&gt;&gt; FlashFlow measurers will be updated to use TLS certificates when
&gt;&gt; connecting to relays too. FlashFlow coordinators will update the
&gt;&gt; contents of MSM_PARAMS cells to contain measurer TLS certificates
&gt;&gt; instead of IP addresses, and relays will update to expect this change.
&gt; 
&gt; You'll want another new "Link" protocol version for this feature. And
&gt; another type of link specifier.
&gt; 
&gt;&gt; 5.2 Measurement Scheduling
&gt;&gt;
&gt;&gt; Short term deployment only has one FF deployment running. Long term this
&gt;&gt; may no longer be the case because, for example, more than one directory
&gt;&gt; authority decides to adopt it and they each want to run their own
&gt;&gt; deployment. FF deployments will need to coordinate between themselves
&gt;&gt; to not measure the same relay at the same time, and to handle new relays
&gt;&gt; as they join during the middle of a measurement period (during the day).
&gt;&gt;
&gt;&gt; The following is quoted from Section 4.3 of the FlashFlow paper.
&gt;&gt;
&gt;&gt;    To measure all relays in the network, the BWAuths periodically
&gt;&gt;    determine the measurement schedule. The schedule determines when and
&gt;&gt;    by whom a relay should be measured. We assume that the BWAuths have
&gt;&gt;    sufficiently synchronized clocks to facilitate coordinating their
&gt;&gt;    schedules. A measurement schedule is created for each measurement
&gt;&gt;    period, the length p of which determines how often a relay is
&gt;&gt;    measured. We use a measurement period of p = 24 hours.
&gt;&gt;
&gt;&gt;    To help avoid active denial-of-service attacks on targeted relays,
&gt;&gt;    the measurement schedule is randomized and known only to the
&gt;&gt;    BWAuths. Before the next measurement period starts, the BWAuths
&gt;&gt;    collectively generate a random seed (e.g. using Tor's
&gt;&gt;    secure-randomness protocol). Each BWAuth can then locally determine
&gt;&gt;    the shared schedule using pseudorandom bits extracted from that
&gt;&gt;    seed.
&gt; 
&gt; As noted above, communication between BWAuths reduces their independence,
&gt; and adds additional risk and complexity in the protocol.
&gt; 

All of this is supposed to be non-interactive, yes. It is
under-specified at this time (IMO). I think this is okay for now because
this specifically is a long term thing currently far away.

&gt; Once-Off Shared Secret Exchange
&gt; 
&gt; Here's an alternative protocol, that does not require an additional
&gt; shared random implementation:
&gt; 
&gt; 1. The BWAuths manually exchange a shared secret key (SHARED_SECRET)
&gt;    out-of-band
&gt; 2. Every day, the BWAuths independently derive a shared secret seed for
&gt;    the measurement protocol, using a hash function (H), and tor's public
&gt;    shared random value (SRV):
&gt; 
&gt;       DAILY_SECRET = H(SHARED_SECRET | SRV)
&gt; 
&gt; We might also want to use the period number here, like the SRV and onion
&gt; service hash ring specs.
&gt; 
&gt; The shared secret key should be rotated:
&gt;   * each time a new BWAuth is added or removed from the network, and
&gt;   * 1 year after the last rotation.
&gt; 
&gt; The key rotation can be performed over a few days, because:
&gt; * each BWAuth has one of two keys: the new key, or the old key,
&gt; * overlaps should be rare in practice,
&gt; * when there is an overlap, at most two BWAuths will overlap,
&gt;   one from each key,
&gt; * overlaps have a low impact for most relays.
&gt; 
&gt;&gt;    The algorithm to create the schedule considers each
&gt;&gt;    measurement period to be divided into a sequence of t-second
&gt;&gt;    measurement slots. For each old relay, slots for each BWAuth to
&gt;&gt;    measure it are selected uniformly at random without replacement
&gt;&gt;    from all slots in the period that have sufficient unallocated
&gt;&gt;    measurement capacity to accommodate the measurement. When a new
&gt;&gt;    relay appears, it is measured separately by each BWAuth in the first
&gt;&gt;    slots with sufficient unallocated capacity. Note that this design
&gt;&gt;    ensures that old relays will continue to be measured, with new
&gt;&gt;    relays given secondary priority in the order they arrive.
&gt; 
&gt; It's unclear whether this protocol is interactive or not.
&gt; 
&gt; Here's a protocol that is explicitly non-interactive:
&gt; 
&gt; 1. Measurers are assigned a daily order, based on each coordinator's
&gt;    certificate hash, and the current DAILY_SECRET.
&gt; 2. For each coordinator, in the daily order:
&gt;    a. Relays in a chosen consensus choose a slot at random, based on
&gt;       the DAILY_SECRET, the relay key, and the iteration number
&gt;    c. If another coordinator is already measuring that relay in that
&gt;       slot, increase the iteration number, and repeat from a.
&gt;    b. If the slot is full for the current coordinator, increase the
&gt;       iteration number, and repeat from a.
&gt;    d. Otherwise, allocate that relay to that slot, for that
&gt;       coordinator.
&gt; 
&gt; We might also want to use other shared data here, like the consensus
&gt; timestamp.
&gt; 
&gt; To make sure all the coordinators have the same consensus, we
&gt; should keep a copy of the most recent shared consensus. Here's how
&gt; we can select a shared consensus:
&gt;   * if we're using a scheduled fetch, a consensus from at least 1 hour
&gt;     ago (usually 2300 UTC),
&gt;   * if we're using a tor client to fetch, a consensus from at least 3
&gt;     hours ago (usually 2100 UTC).
&gt; 
&gt; If there isn't a consensus for that time, we should keep the most
&gt; recent consensus before that time.
&gt; 
&gt; It doesn't actually matter if the consensus is a little out of sync,
&gt; most relays will have the same fingerprints, and end up in the same
&gt; slots.
&gt; 
&gt;&gt; 5.3 Experiments
&gt;&gt;
&gt;&gt;   [XXX todo]
&gt;&gt;
&gt;&gt; 5.4 Other Changes/Investigations/Ideas
&gt;&gt;
&gt;&gt; ...
&gt;&gt;
&gt;&gt; 6. Citations
&gt;&gt;
&gt;&gt; [0] F. Thill. Hidden Service Tracking Detection and Bandwidth Cheating
&gt;&gt;    in Tor Anonymity Network. Master's thesis, Univ. Luxembourg, 2014.
&gt;&gt; [1] A. Johnson, R. Jansen, N. Hopper, A. Segal, and P. Syverson.
&gt;&gt;    PeerFlow: Secure Load Balancing in Tor. Proceedings on Privacy
&gt;&gt;    Enhancing Technologies (PoPETs), 2017(2), April 2017.
&gt;&gt; [2] Mike Perry: Graph onionperf and consensus information from Rob's
&gt;&gt;    experiments https://trac.torproject.org/projects/tor/ticket/33076
&gt; 
&gt; T
&gt; 


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200602190113</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-06-02 19:01:13-0400</timestampReceived><subject>Re: [tor-dev] Proposal 316: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

On Thu, Apr 23, 2020 at 2:48 PM Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt;

Hi!  I've got some comments on the FlashFlow proposal; I'll start with
the ones that I think are most important, so that we can try to get
them out of the way.

First off, I'm concerned about the approach where measurers get to
consume a certain amount of bandwidth, with only a set fraction left
to devote to the background traffic.  It seems like a hostile set of
measurers could use this authority to introduce traffic patterns on
the network to assist in traffic analysis.  In general, having regular
scheduled and visible changes in relay capacity seem to me like they'd
help out traffic analysis a good deal.

Second, the "MSM_BG" information type also seems like a serious
traffic analysis risk.  It is, literally, telling the measurers a
report of how much traffic was sent each second on other connections.
Previously we decided that a much coarser summary than this was too
much information to publish in bandwidth-history lines, and I'm
worried not to see any analysis here.

{In both of the above cases we might say, "well, an attacker could do
that anyway!"  But to get the traffic information, an attacker would
need to compromise the upstream connection, and to introduce traffic
spikes the attacker would need to risk detection.  This proposal as
written would make both of these traffic analysis opportunities an
expected part of the infrastructure, which seems not-so-good to me.}

Third, I don't understand why we're using cell crypto here but we
aren't using RELAY cells or (apparently?) circuits.  Since TLS is
already in play, we'll already be measuring the relays' encryption
performance.  But if we do decide that cell crypto is needed, then
it's way easier to get that crypto happening if there are circuits
involved.  I think there's been some discussion of that on IRC; I'd
suggest that we try to make that work if we can.

Fourth, this approach to authenticating echo cell contents seems
needlessly complicated.  Instead of using random contents and
remembering a fraction of cells, it would make more sense for
measurers to use a keyed pseudorandom stream function to generate the
cells, and to verify the contents of all the cells as they come back
in.  (AES128-CTR and ChaCha8 and SHAKE128 all have nice properties
here.)

Fifth, using IP addresses for identification is NOT something we do on
the production network.  I think we should authenticate measurers by
identity key, not by IPv4 address (as is happening here, unless I
misunderstand.)

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20200424071516</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-24 07:15:16-0400</timestampReceived><subject>Re: [tor-dev] Building a privacy-preserving "contact tracing" app</subject><body>

[Attachment #2 (multipart/signed)]


Hi Adrien,

&gt; On 22 Apr 2020, at 16:35, Adrien Luxey &lt;adrien@luxeylab.net&gt; wrote:
&gt; 
&gt; The French state is making a glosing about the "privacy-preserving", "anonymous" \
&gt; contact tracing app they are developing with Inria (national informatics research \
&gt; agency). You can check about the protocol proposal, ROBERT, here: \
&gt; https://github.com/ROBERT-proximity-tracing/documents (in English!) 
&gt; As you would expect, the proposal is not privacy-preserving unless you believe the \
&gt; State would never ever misbehave, e.g. link IP address to identity with the help of \
&gt; ISPs etc. There is some relevant criticism here: \
&gt; https://github.com/ROBERT-proximity-tracing/documents/issues/6

Not just the French state, lots of them are doing it :-(

&gt; I'd like to propose a really private "contact tracing" counter-proposal, which \
&gt; would use Tor's onion services for sender-receiver anonymity. Not that I am a \
&gt; proponent of the idea, but we need to come up with alternatives in the debate.

There are a few decent privacy-preserving contact protocols.

I'd give you links, but I can't find them right now.

(Search engines are doing weird things to covid searches, and I can't remember my \
friends' twitter handles. Oops!)

&gt; My question is: would the Tor community agree on having StopCovid's traffic go \
&gt; through its net? In my proposal, I would only broadcast a message from a declared \
&gt; COVID-positive person to all its recent contacts; the proximity sensing would \
&gt; remain Bluetooth. Still, deployed at the scale of a country, it's a lot of traffic.

How much traffic will the app use?
How many users?

The Tor network currently handles about 70 Gigabits per second of user traffic. This \
graph shows the traffic for all relays. There are usually 3 relays in each user \
circuit: https://metrics.torproject.org/bandwidth.html

Tor currently has a few million active users:
https://metrics.torproject.org/userstats-relay-country.html

I'm sure we'd love to help. But maybe the Tor network can't scale to hundreds of \
millions of people using an app?

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6ikgQACgkQEP6qDnB1
ZyoW4BAAu6wBrBymJkMqTORsNggI8vPndEeyiimG2FguqwBJ9+qIBM+w6cbUQEgP
biIQY88xajKOWMbwOvIZ60Gsat+6wJXxfpdK+sgeYlzAbDTLYwOmbPA0jc4a9ovp
tLPBq0vSS+JwOMYBKcGKItlvM/OGXVmux98tpcsIkqAajfvG8AXA1yHZEjwG7JEo
neA0uSSP4eBgHH6deKxXrmkA480qR0vrXEPQGqgRTb1FcnB5Bwrq42ffJa5k0q9P
9+KBRk5KWw6T68TA6IcVrdVTEbGWCJuB0UQ5e7n+RU19q2AEhocsRzzikuFF0ryd
Hvmi3teH9eT4tJlQxbFKTn2qzwtAgWhYYoxuSoyw8MhSuOPdY8VJL3niGDvCl+Ru
vChzD7OABM2nBNZg+cDip+zc/LTjvfCxmJySkY13VN4CnyMK0MKdyKPT8MGFVHrD
LhVCegfh5wt9WEyYHBIqZ/GWCXg4wnUVvrkou7kQ2p00uU+r8omFpNuJlhx4fOYz
csJXvSc5+pW9IPIhV2bF+8TA5pzIhxt5iCXvwgvCXcLC0+e9OEt0/Xl41rYe7w82
1L7Vaifl0XI/mOUwVE/tRHMl1asHhyXqN2bTHrGpy2TQ8tWeuU6eugctQZZUdFTI
9MIDqCFD2EIrBXYmAivc6CTb6G38k9gMCNxFZiqVus4gYw6S8Ms=
=CxT3
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200427230958</emailId><senderName>Eli Vakrat</senderName><senderEmail>eli@vakrat.com</senderEmail><timestampReceived>2020-04-27 23:09:58-0400</timestampReceived><subject>[tor-dev] Relay Truncated Cell Example</subject><body>

[Attachment #2 (multipart/alternative)]


Hello again everyone!

For anyone who doesn't know\remember, my name is Eli, I'm a high school
student from Israel and I'm currently trying to implement a TOR Client in
Python.

Currently, my project is configured so that my python client (OP) has its
guard node set as my local machine (which is running a downloaded version
of TOR). I do this for debugging purposes so that if I send a malformed
cell as the implemented client, I can read the debug log that the OR
generates and see what I did wrong.

Last time I sent a question to the dev-list I was stuck trying to get my
CREATE cells to work, and Nick Mathewson immediately answered my question
and helped me a lot! Thanks Nick!

I've made pretty good progress since then, and as of writing this, my
implemented OP can successfully send a CREATE cell and even an EXTEND
cell to my guard node.

However, I am running into a problem while trying to extend my circuit to
the third node (my exit node in this case).

After sending a RELAY_EXTEND cell to my middle node (which is encrypted
twice with my middle node and then guard node forward key using AES128 in
CTR mode), the Response I get back is a relay cell with the correct Circuit
Id and command (the command I get is the RELAY command which is represented
as 3), BUT the payload of the response cell is very weird. I am unable to
'recognize' it (as specified in section 6.1 of the tor-spec). and
furthermore, it does not seem to be any type of cell, it just seems like a
bunch of nonsense.

Seeing this I initially thought that the response cell I kept getting was a
RELAY_EXTENDED cell that I couldn't 'recognize' due to an error while
decrypting the cell payload.

But then I looked at the debug log of my guard node (remember that my guard
node is on my local machine) and it said that it had received a DESTROY
Cell back from the middle node and was passing on a RELAY_TRUNCATED cell to
me:

*Apr 26 16:11:03.014 [debug] command_process_destroy_cell: Received for
circID 2297363203.* &lt;------this is the circuit ID between my gaurd node and
the middle node

*Apr 26 16:11:03.014 [debug] command_process_destroy_cell: Delivering
'truncated' back.Apr 26 16:11:03.014 [debug] relay_send_command_from_edge_:
delivering 9 cell backward.*

To my understanding what this log means is that some part of the EXTEND
cell I sent to the middle node was wrong or malformed and because of this
when the middle node tried to extend the circuit, an error occurred, and
the circuit needed to be torn down.

This is very weird because when I send an EXTEND cell that is meant for my
guard node (meaning I want to extend the circuit from one hop to two hops)
everything works fine, and I can even successfully derive the shared key
material for the middle node.


So I have several questions regarding this:

1. First of all, I didn't quite understand the exact format of a
RELAY_TRUNCATED cell. Does it contain a relay cell command +
recognized+field +digest and so on? or is it just a single octet that
immediately follows the cell command field? If some could show me an
example of the cell, it would be much appreciated...

2. What are some common errors that would make an OR drop a RELAY EXTEND
cell? I thought maybe it was a problem with my TAP handshake data, but
after extensive checking that doesn't seem to be the case.

3. If someone could describe the exact steps of extending a circuit to a
third node, it would greatly help me to make sure that I didn't miss a step
or do something wrong.

Thanks in advance for any answers, examples, or comments! I am having a lot
of fun doing this project so far and I hope to hear back from anyone who
has an answer :)

Regards,
Eli

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;Hello again everyone!  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;For  anyone  who \
doesn't  know\remember, my  name is Eli, I'm a high school student from \
Israel and I'm currently trying to implement a TOR Client in \
Python.&lt;/div&gt;&lt;div&gt;&lt;br&gt;Currently, my project is configured so that my python client \
(OP) has its guard node set as my local machine (which is running a downloaded \
version of TOR). I do this for debugging purposes so that if I send a malformed cell \
as the implemented client, I can read the debug log that the OR generates and see \
what I did wrong.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Last time I sent a question to the dev-list I was \
stuck trying to get my CREATE cells to work, and Nick Mathewson  immediately  \
answered my question and helped me a lot! Thanks \
Nick!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I've  made pretty good progress since then, and as \
of writing this, my implemented OP can successfully send a CREATE cell and even an \
EXTEND cell  to my guard node.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;However, I am running into \
a problem while trying to extend my circuit to the third node (my exit node in this \
case).&lt;/div&gt;&lt;div&gt;  &lt;/div&gt;&lt;div&gt;After sending a RELAY_EXTEND cell to my middle node \
(which is encrypted twice with my middle node and then guard node forward key using \
AES128 in CTR mode), the Response I get back is a relay cell with the correct Circuit \
Id and command  (the command I get is the RELAY command which is represented as 3), \
BUT the payload of the response cell is very weird. I am unable to \
'recognize' it (as specified in section 6.1 of the tor-spec). and \
furthermore, it does not seem to be any type of cell, it just seems like a bunch of \
nonsense.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Seeing this I initially thought that the response \
cell I kept getting was a RELAY_EXTENDED cell that I couldn't 'recognize' \
due to an error while decrypting the cell payload.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;But then \
I looked at the debug log of my guard node (remember that my guard node is on my \
local machine) and it said that it had received a DESTROY Cell back from the middle \
node and was passing on a RELAY_TRUNCATED cell to me:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;b&gt;Apr 26 \
16:11:03.014 [debug] command_process_destroy_cell: Received for circID \
2297363203.&lt;/b&gt; &lt;------this is the circuit ID between my gaurd node and the middle \
node&lt;br&gt;&lt;b&gt;Apr 26 16:11:03.014 [debug] command_process_destroy_cell: Delivering \
'truncated' back.&lt;br&gt;Apr 26 16:11:03.014 [debug] \
relay_send_command_from_edge_: delivering 9 cell backward.&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;To \
my understanding what this log means is that some part of the EXTEND cell I sent to \
the middle node was wrong or malformed and because of this when the middle node tried \
to extend the circuit, an error occurred, and the circuit needed to be torn \
down.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is very weird because when I send an EXTEND cell \
that is meant for my guard node (meaning I want to extend the circuit from one hop to \
two hops) everything works fine, and I can even successfully derive the shared key \
material for the middle node.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So I have \
several questions regarding this:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. First of all, I \
didn't quite understand the exact format of a RELAY_TRUNCATED cell. Does it \
contain a relay cell command  + recognized+field  +digest and so on? or is it just a \
single octet that immediately follows the cell command field? If some could show me \
an example of the cell, it would be much appreciated...  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;2. \
What are some common errors that would make an OR drop a RELAY EXTEND cell? I thought \
maybe it was a problem with my TAP handshake data, but after extensive checking that \
doesn't seem to be the case.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;3. If someone could \
describe the exact steps of extending a circuit  to a third node, it would greatly \
help me to make sure that I didn't  miss a step or do something  \
wrong.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks in advance for any answers, examples, or \
comments! I am having a lot of fun doing this project so far and I hope to hear back \
from anyone who has an answer :)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Eli  \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200428175023</emailId><senderName>Eli Vakrat</senderName><senderEmail>eli@vakrat.com</senderEmail><timestampReceived>2020-04-28 17:50:23-0400</timestampReceived><subject>[tor-dev] Tor Relay wont connect to private IP address</subject><body>

[Attachment #2 (multipart/alternative)]


Hey guys!

So thanks to teor's insightful response yesterday I decided to try to run a
second tor relay (my middle node) on my private network.

Unfortunately, I can't do it with Chutney because my python client is
running on a windows machine. But I do have 3 machines at my disposal:

1. A windows machine (the python client)
2. A mac (the guard node)
3. Another mac (the middle node)

However, after connecting all three machines to my private LAN (meaning
they now all have local IP addresses), the EXTEND from the guard node to
the middle node fails.

When my guard node tries to connect to my middle node after receiving from
the client a RELAY_EXTEND cell, the guard node logs the following error:

Apr 28 17:00:31.000 [info] circuit_extend: Client asked me to extend to a
private address
Apr 28 17:00:31.000 [info] circuit_receive_relay_cell:
connection_edge_process_relay_cell (away from origin) failed.
Apr 28 17:00:31.000 [info] command_process_relay_cell:
circuit_receive_relay_cell (forward) failed. Closing.

So regarding this, I have two questions:

1. Is there a way for me to change something in my torrc file to override
this error and allow my relay to extend to private IP addresses?

My torrc is currently configured as such (Notice I put some place holders
for the drectories and for the ip address tha aren't actually whats written
there):

ContactInfo e &lt;draftkingschaching@gmail.com&gt;mail@example.com

ControlPort 9051

DataDirectory &lt;/path/to/data/dir&gt;

ExitPolicy reject *:*

ExitRelay 0

GeoIPFile &lt;/path/to/geo/ip/file&gt;

GeoIPv6File &lt;/path/to/geo/ipv6/file&gt;

Log notice file &lt;path/to/log/dirs/&gt;/notice.log

Log debug file &lt;path/to/log/dirs/&gt;/debug.log

Log warn file &lt;path/to/log/dirs/&gt;/warn.log

Nickname vtoria

ORPort 443 NoAdvertise

ORPort Relay.Public.IP.Example:443 &lt;http://79.183.54.194:443/&gt; NoListen

SafeLogging 0

ExtendAllowPrivateAddresses 1


2. Would there maybe be a better way to run this private tor network
(without chutney)?

Thanks in advance for any answers!

Eli

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hey guys!&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So thanks to teor's  insightful \
response yesterday I decided  to try to run a second tor relay (my middle node) on my \
private network.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Unfortunately, I can't do it with \
Chutney because my python client  is running on a windows machine. But I do have 3 \
machines at my disposal:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. A windows machine (the python \
client)&lt;/div&gt;&lt;div&gt;2. A mac (the guard  node)&lt;/div&gt;&lt;div&gt;3. Another mac (the middle \
node)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;However, after connecting all three machines to my \
private LAN (meaning they now all have local IP addresses), the EXTEND from the  \
guard  node to the middle node fails.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;When my guard  node \
tries to connect to my middle node after receiving from the client a RELAY_EXTEND \
cell, the guard  node logs the following error:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Apr 28 \
17:00:31.000 [info] circuit_extend: Client asked me to extend to a private \
address&lt;br&gt;Apr 28 17:00:31.000 [info] circuit_receive_relay_cell: \
connection_edge_process_relay_cell (away from origin) failed.&lt;br&gt;Apr 28 17:00:31.000 \
[info] command_process_relay_cell: circuit_receive_relay_cell (forward) failed. \
Closing.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So regarding this, I have two \
questions:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. Is there a way for me to change  something  in \
my torrc file to override this error and allow my relay to extend to private IP \
addresses?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My torrc is currently configured as such (Notice \
I put some place holders for the drectories  and for the ip address tha aren't  \
actually whats  written there):&lt;/div&gt;&lt;div&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ContactInfo  &lt;a \
href="mailto:draftkingschaching@gmail.com" target="_blank"&gt;e&lt;/a&gt;&lt;a \
href="mailto:mail@example.com"&gt;mail@example.com&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ControlPort 9051&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;DataDirectory \
&lt;/path/to/data/dir&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExitPolicy reject *:*&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExitRelay 0&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;GeoIPFile \
&lt;/path/to/geo/ip/file&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;GeoIPv6File \
&lt;/path/to/geo/ipv6/file&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log notice file \
&lt;path/to/log/dirs/&gt;/notice.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log debug file  \
&lt;/span&gt;&lt;path/to/log/dirs/&gt;/&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;debug.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log warn file  \
&lt;/span&gt;&lt;path/to/log/dirs/&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;/warn.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Nickname vtoria&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ORPort 443 \
NoAdvertise&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ORPort  &lt;a \
href="http://79.183.54.194:443/" target="_blank"&gt;Relay.Public.IP.Example:443&lt;/a&gt;  \
NoListen  &lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;SafeLogging 0&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExtendAllowPrivateAddresses \
1&lt;/span&gt;&lt;/p&gt;&lt;p style="font-variant-numeric:normal;font-variant-east-asian:normal;font- \
stretch:normal;font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;2. Would \
there maybe be a better way to run this private tor network (without \
chutney)?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks  in advance for any \
answers!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Eli&lt;/div&gt;&lt;div&gt;&lt;div class="gmail-yj6qo"&gt;&lt;/div&gt;&lt;div \
class="gmail-adL"&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="gmail-adL"&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200409165830</emailId><senderName>Lennart Oldenburg</senderName><senderEmail>lennart.oldenburg@esat.kuleuven.be</senderEmail><timestampReceived>2020-04-09 16:58:30-0400</timestampReceived><subject>[tor-dev] Does a design document for the DoS subsystem exist?</subject><body>

Hi all,

We are investigating how Tor protects itself against Denial-of-Service
(DoS) attacks. So far, it has been difficult to find a comprehensive
top-level design document for the DoS subsystem (e.g., a torspec or
proposal) that reflects the decisions that lead to the subsystem in its
current form.

Specifically, we are looking at the DoS mitigation subsystem code for
entry guards at src/core/or/dos.{h,c} [1]. We are trying to understand
the chosen countermeasures and how the default and current consensus
values came to be, e.g., the decision to limit to 3 circuits per second
after the initial burst.

1) Could you kindly point us in the right direction if any such document
exists?

2) If it does not exist, would you mind briefly explaining how the DoS
threshold values (such as DoSCircuitCreationMinConnections,
DoSCircuitCreationRate, DoSCircuitCreationBurst, and
DoSConnectionMaxConcurrentCount) were chosen?

Thank you very much in advance.

Kind regards

Lennart Oldenburg
KU Leuven

[1] https://gitweb.torproject.org/tor.git/tree/src/core/or/dos.c
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200413215054</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-04-13 21:50:54-0400</timestampReceived><subject>Re: [tor-dev] Does a design document for the DoS subsystem exist?</subject><body>

Lennart Oldenburg &lt;lennart.oldenburg@esat.kuleuven.be&gt; writes:

&gt; Hi all,
&gt; 
&gt; We are investigating how Tor protects itself against Denial-of-Service
&gt; (DoS) attacks. So far, it has been difficult to find a comprehensive
&gt; top-level design document for the DoS subsystem (e.g., a torspec or
&gt; proposal) that reflects the decisions that lead to the subsystem in its
&gt; current form.
&gt; 
&gt; Specifically, we are looking at the DoS mitigation subsystem code for
&gt; entry guards at src/core/or/dos.{h,c} [1]. We are trying to understand
&gt; the chosen countermeasures and how the default and current consensus
&gt; values came to be, e.g., the decision to limit to 3 circuits per second
&gt; after the initial burst.
&gt; 
&gt; 1) Could you kindly point us in the right direction if any such document
&gt; exists?
&gt; 
&gt; 2) If it does not exist, would you mind briefly explaining how the DoS
&gt; threshold values (such as DoSCircuitCreationMinConnections,
&gt; DoSCircuitCreationRate, DoSCircuitCreationBurst, and
&gt; DoSConnectionMaxConcurrentCount) were chosen?
&gt; 

Hello there,

first of all let me say that the DoS subsystem of Tor is under active
development, so things are subject to change and mutate towards various
directions (e.g. https://lists.torproject.org/pipermail/tor-dev/2020-April/014215.html).


However, since you are asking for resources on the currently existing
DoS subsystem here is some things you can look at:

- Resources on general Tor rate limiting:
            https://trac.torproject.org/projects/tor/ticket/24902 
            https://lists.torproject.org/pipermail/tor-relays/2018-January/014357.html


- The proposal for the HS DoS subsystem:
            https://github.com/torproject/torspec/blob/master/proposals/305-establish-intro-dos-defense-extention.txt


- More information on HS DoS subsystem:
      https://lists.torproject.org/pipermail/tor-dev/2019-April/013790.html
      https://lists.torproject.org/pipermail/tor-dev/2019-May/013837.html
      https://lists.torproject.org/pipermail/tor-dev/2019-July/013923.html

Good luck with your research and please let us know if you reach the
point where you can break or fix things! :)

Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200414222511</emailId><senderName>Lennart Oldenburg</senderName><senderEmail>lennart.oldenburg@esat.kuleuven.be</senderEmail><timestampReceived>2020-04-14 22:25:11-0400</timestampReceived><subject>Re: [tor-dev] Does a design document for the DoS subsystem exist?</subject><body>

Hello George, hello all,

Thank you very much for the provided pointers. Great to hear progress is
being made on the Onion Services DoS matter. Two follow-up questions:

1) Will the DoS subsystem overhaul also affect guard-centric DoS
countermeasures? Or will it exclusively focus on DoS protection specific
to Onion Services? If guard-centric countermeasures are also being
updated, is there a document to see what is about to change?

2) The linked bug ticket [1] under your first bullet point does not
mention the origin of the concrete threshold values
(DoSCircuitCreationRate, etc.). Could you share any insight on how these
DoS threshold values are determined? Are they inferred from experiments?

Thank you.

Kind regards
Lennart Oldenburg

[1] https://trac.torproject.org/projects/tor/ticket/24902

On 13/04/2020 23.50, George Kadianakis wrote:
&gt; Lennart Oldenburg &lt;lennart.oldenburg@esat.kuleuven.be&gt; writes:
&gt; 
&gt; &gt; Hi all,
&gt; &gt; 
&gt; &gt; We are investigating how Tor protects itself against Denial-of-Service
&gt; &gt; (DoS) attacks. So far, it has been difficult to find a comprehensive
&gt; &gt; top-level design document for the DoS subsystem (e.g., a torspec or
&gt; &gt; proposal) that reflects the decisions that lead to the subsystem in its
&gt; &gt; current form.
&gt; &gt; 
&gt; &gt; Specifically, we are looking at the DoS mitigation subsystem code for
&gt; &gt; entry guards at src/core/or/dos.{h,c} [1]. We are trying to understand
&gt; &gt; the chosen countermeasures and how the default and current consensus
&gt; &gt; values came to be, e.g., the decision to limit to 3 circuits per second
&gt; &gt; after the initial burst.
&gt; &gt; 
&gt; &gt; 1) Could you kindly point us in the right direction if any such document
&gt; &gt; exists?
&gt; &gt; 
&gt; &gt; 2) If it does not exist, would you mind briefly explaining how the DoS
&gt; &gt; threshold values (such as DoSCircuitCreationMinConnections,
&gt; &gt; DoSCircuitCreationRate, DoSCircuitCreationBurst, and
&gt; &gt; DoSConnectionMaxConcurrentCount) were chosen?
&gt; &gt; 
&gt; 
&gt; Hello there,
&gt; 
&gt; first of all let me say that the DoS subsystem of Tor is under active
&gt; development, so things are subject to change and mutate towards various
&gt; directions (e.g. https://lists.torproject.org/pipermail/tor-dev/2020-April/014215.html).
&gt;  
&gt; However, since you are asking for resources on the currently existing
&gt; DoS subsystem here is some things you can look at:
&gt; 
&gt; - Resources on general Tor rate limiting:
&gt; https://trac.torproject.org/projects/tor/ticket/24902 
&gt; https://lists.torproject.org/pipermail/tor-relays/2018-January/014357.html
&gt; 
&gt; - The proposal for the HS DoS subsystem:
&gt; https://github.com/torproject/torspec/blob/master/proposals/305-establish-intro-dos-defense-extention.txt
&gt;  
&gt; - More information on HS DoS subsystem:
&gt; https://lists.torproject.org/pipermail/tor-dev/2019-April/013790.html
&gt; https://lists.torproject.org/pipermail/tor-dev/2019-May/013837.html
&gt; https://lists.torproject.org/pipermail/tor-dev/2019-July/013923.html
&gt; 
&gt; Good luck with your research and please let us know if you reach the
&gt; point where you can break or fix things! :)
&gt; 
&gt; Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200424091112</emailId><senderName>Jeff Burdges</senderName><senderEmail>burdges@gnunet.org</senderEmail><timestampReceived>2020-04-24 09:11:12-0400</timestampReceived><subject>Re: [tor-dev] Building a privacy-preserving "contact tracing" app</subject><body>

[Attachment #2 (multipart/signed)]


&gt; &gt; The French state is making a glosing about the "privacy-preserving", "anonymous" \
&gt; &gt; contact tracing app they are developing with Inria (national informatics research \
&gt; &gt; agency). You can check about the protocol proposal, ROBERT, here: \
&gt; &gt; https://github.com/ROBERT-proximity-tracing/documents (in English!) 
&gt; &gt; As you would expect, the proposal is not privacy-preserving unless you believe \
&gt; &gt; the State would never ever misbehave, e.g. link IP address to identity with the \
&gt; &gt; help of ISPs etc. There is some relevant criticism here: \
&gt; &gt; https://github.com/ROBERT-proximity-tracing/documents/issues/6

ROBERT should not be considered privacy preserving because uninfected users reveal \
everything.  Yes, the IP address makes this much worse, but metadata like timing and \
the time in the exposure status request (ESR) in section 7 on pages 11 of \
https://github.com/ROBERT-proximity-tracing/documents/blob/master/ROBERT-specification-EN-v1_0.pdf


Aside from privacy, I think bandwidth also dictates that uninfected users should not \
reveal anything anything in their queries, like DP-3T, but unlike ROBERT

&gt; &gt; I'd like to propose a really private "contact tracing" counter-proposal, which \
&gt; &gt; would use Tor's onion services for sender-receiver anonymity. Not that I am a \
&gt; &gt; proponent of the idea, but we need to come up with alternatives in the debate.
&gt; 
&gt; There are a few decent privacy-preserving contact protocols.

I think this is being overly generous.  ;)  There are less horrible designs like \
DP-3T that reveal infected user information, which sounds unfortunate but legal for \
reportable diseases, but reveal nothing about uninfected users.  Implicitly, there \
are extremely few infected users because contact tracing becomes far less helpful as \
the infected user population grows, which makes for quite an interesting assumption.

At least one Swiss group that advocate for contact tracing thinks 25 new cases per \
day sounds small enough given Switzerland's density, but 25 new cases per day was \
clearly not small enough for Singapore's contact tracing effort, so they eventually \
needed a lockdown.  There are also countries like the U.S. and U.K. where media \
ignores such subtleties and where contact tracing could simply become some \
justification for increased economic activity.

You might agree with revealing reportable disease data for public health, and \
parameterise a contact tracing app around the public health assumptions, only to \
discover governments use it for economic reasons that harm public health, and then \
make your privacy preserving aspects into the scape goat.

&gt; I'm sure we'd love to help. But maybe the Tor network can't scale to hundreds of \
&gt; millions of people using an app?

Ignoring the nasty political realities, there are cute mixnet tricks for contact \
tracing apps:

All users create and broadcast tiny single-use reply blocks (SURBs) over Bluetooth \
LE.  There are no SURB designs that fit into one single Bluetooth LE announcement, \
but you could manage with two using erasure coding, ala \
https://github.com/TracingWithPrivacy/paper/issues/10 which sounds acceptable given \
the MAC address rotates more slowly anyways.  We've no MAC tags inside these SURBs so \
imagine them living partially between Sphinx and a voting mixnet, but both \
non-verifiable and verifiable mixnet designs work.

Infected users reveal the SURBs they downloaded over Bluetooth LE to a health \
authority who sends the SURB.  After many hops, the SURB arrives with some mailbox \
maintained by a user.  We'd expose the sender to the receiver if we allow the \
receiver to unwind their SURB, so instead we simply drop the message and notify the \
receiver that they received one warning message.

We're not really more privacy preserving than schemes in which uninfected users \
download all ephemeral identifiers for all infected users.  We do avoid revealing \
infected user data however and use almost no bandwidth.  We'd need some cover traffic \
that might generate false positives depending upon the SURB size.  Anonymity degrades \
under conditions where contact tracing actually works, meaning a health authority \
could discover a user's mailbox by listening to their bluetooth LE beacon and sending \
a false message, but mixing parameters like one batch per day reduce this risk.

Jeff


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCgAdFiEEBA1bLpAiCdPXvXG3q6x/0cwQCnQFAl6irTAACgkQq6x/0cwQ
CnR1Ig//XnxaY6Ao4M8dnqsTxGnddrDOH6ML1MF+Qn+E2Jz0dEA/4BWaHf1fxT3f
vHvl461TKuI9AFUnr+q0biQby8BDDke/Ko1lFF2dwxhyCpLux4T2hpgGNXiR9QwA
4fEpKsDfPFHRT8KphLLmbX20DUF5z8wcmZnp9G+kOf5icsKv/4wNmc1ir9uwPsK+
9d8R7uB/jdf1Pqp3Bsy8dVx+WpLlyI3IqLwn3e/oD0dcUs4B23lzX4xsMjYrQHO7
ppvTRwemKZd9tG86FjlkSQS1Lpam6jJ05A9jO6fX0bnexigSJ5uz6YfdlYzkmsnO
kBleD7s+BPRaJajAhQ2I0k7PKKoAcxfHlk3BSwhjgsIwMWCv8hl9kIGxpLr2nFnB
zAXIlmlDSpqKJr3fJnNaZGZmGT9aCmD7z+5P481DzHbWKW7iTR++n8X40+RIakyq
L/Ol1mm2zYpLwmbTLkhxfqIXiVEu8yUuodgRZYLIUuAamM5QQKwYCOB78WtzLsTu
K7KaxhgsAJQ5HPGAJdIlWzClwTVfCnBBwMDQnnKjRBLustti3GwBtFpIh9cN4uFl
1LVb95Mw9Kq+BEW6Na1ZjnUyffmdw0Gqe87851Ek+WsMJfXHwjsigvlYxYJ53b+E
65F0nm4/zlN03x9Zc632hpJcxapQnrs7pSe10+q2OnqHaAE8OaE=
=8HoZ
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200424092315</emailId><senderName>carlo von lynX</senderName><senderEmail>lynx@time.to.get.psyced.org</senderEmail><timestampReceived>2020-04-24 09:23:15-0400</timestampReceived><subject>Re: [tor-dev] Building a privacy-preserving "contact tracing" app</subject><body>

On Fri, Apr 24, 2020 at 11:11:12AM +0200, Jeff Burdges wrote:
&gt; Ignoring the nasty political realities, there are cute mixnet tricks for contact tracing apps:

Sounds like a neat approach, Jeff.


-- 
  E-mail is public! Talk to me in private using encryption:
   //  http://loupsycedyglgamf.onion/LynX/
  //    irc://loupsycedyglgamf.onion:67/lynX
 //    https://psyced.org/LynX/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200425022512</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-25 02:25:12-0400</timestampReceived><subject>Re: [tor-dev] Proposal 316: FlashFlow: A Secure Speed Test for Tor (Parent Proposal)</subject><body>

[Attachment #2 (multipart/signed)]


Hi Matt,

Thanks for the quick response!

I've trimmed the conversation to the comments that need further
discussion.

&gt; On 25 Apr 2020, at 06:46, Matt Traudt &lt;pastly@torproject.org&gt; wrote:
&gt; 
&gt; On 4/23/20 21:05, teor wrote:
&gt;&gt; ...
&gt;&gt; 
&gt;&gt;&gt; - msm_duration  [1 byte]
&gt;&gt; 
&gt;&gt; What are the minimum and maximum valid values for this field?
&gt;&gt; 1..255 ?
&gt;&gt; 
&gt;&gt; Do we want to limit measurements to 4 minutes at a protocol level?
&gt;&gt; 
&gt;&gt; In general, protocols should make invalid states impossible to represent.
&gt;&gt; But do we want a 4 minute hard limit here?
&gt;&gt; 
&gt; 
&gt; This document suggests a measurement duration of 30 seconds. We see no
&gt; reason to ever go above 1 minute. If there's a byte to spare, then sure
&gt; let's make this a uint16.

I've thought about this a bit more, and from a user experience perspective,
we also want a 30 second limit. (Most users will give up on a slow
connection after 30 seconds.)

So as long as there is a documented limit in the protocol, we should be
fine with 2 bytes.

&gt;&gt;&gt; second is the number of seconds since the measurement began. MSM_BG
&gt;&gt;&gt; cells are sent once per second from the relay to the FlashFlow
&gt;&gt;&gt; coordinator. The first cell will have this set to 1, and each
&gt;&gt;&gt; subsequent cell will increment it by one. sent_bg_bytes is the number of
&gt;&gt;&gt; background traffic bytes sent in the last second (since the last MSM_BG
&gt;&gt;&gt; cell). recv_bg_bytes is the same but for received bytes.
&gt;&gt;&gt; 
&gt;&gt;&gt; The payload of MSM_ERR cells:
&gt;&gt;&gt; 
&gt;&gt;&gt; - err_code [1 byte]
&gt;&gt;&gt; - err_str  [possibly zero-len null-terminated string]
&gt;&gt; 
&gt;&gt; We don't have strings in any other tor protocol cells.
&gt;&gt; 
&gt;&gt; If you need extensible error information, can I suggest using
&gt;&gt; ext-type-length-value fields:
&gt;&gt; 
&gt;&gt;     N_EXTENSIONS     [1 byte]
&gt;&gt;     N_EXTENSIONS times:
&gt;&gt;        EXT_FIELD_TYPE [1 byte]
&gt;&gt;        EXT_FIELD_LEN  [1 byte]
&gt;&gt;        EXT_FIELD      [EXT_FIELD_LEN bytes]
&gt;&gt; 
&gt;&gt; https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1518
&gt;&gt; 
&gt;&gt; If strings are necessary, please specify a character encoding
&gt;&gt; (ASCII or UTF-8), and an allowed set of characters.
&gt;&gt; 
&gt;&gt; If we don't whitelist characters, we risk logging terminal escape
&gt;&gt; sequences, or other arbitrary data.
&gt; 
&gt; I seem to remember strings used between directory authority /directory
&gt; mirror relays and clients to communicate certain errors (clock skew?),
&gt; but what's probably reality is a *code* is communicated and what I'm
&gt; thinking of is merely the Tor client interpreting the code for logging
&gt; purposes.

There are two sources for clock skew warnings:
* A binary time field in NETINFO cells
* A HTTP header on directory documents

The header is text, but it's very structured, and at a different
protocol layer.

In another part of the directory protocol, when authorities reject a
relay descriptor upload, they send a rejection reason to the relay.
That's unstructured text in a HTTP response. (But we do escape it before
logging.)

&gt; Regardless, we probably don't really need a string. It occurs to me we
&gt; might want *something* that carries more information than a code; for
&gt; example, a MSM_ERR cell with a code stating "I'm refusing to be measured
&gt; because I've been measured too recently" would benefit from a field
&gt; stating either time till measurement allowed again or time since last
&gt; measurement.

Yes, I think a code and ext-type-length-value fields for any additional
info would work here.

&gt;&gt;&gt; At this point, the
&gt;&gt;&gt; relay
&gt;&gt;&gt; 
&gt;&gt;&gt; - Starts a repeating 1s timer on which it will report the amount of
&gt;&gt;&gt;   background traffic to the coordinator over the coordinator's
&gt;&gt;&gt;   connection.
&gt;&gt;&gt; - Enters "measurement mode" and limits the amount of background
&gt;&gt;&gt;   traffic it handles according to the torrc option/consensus
&gt;&gt;&gt;   parameter.
&gt;&gt;&gt; 
&gt;&gt;&gt; The relay decrypts and echos back all MSM_ECHO cells it receives on
&gt;&gt;&gt; measurement connections
&gt;&gt; 
&gt;&gt; Are MSM_ECHO cells relay cells?
&gt;&gt; How much of the relay protocol does the measurer implement?
&gt;&gt; 
&gt;&gt; The references to decrypting cells suggest that MSM_ECHO cells are
&gt;&gt; relay (circuit-level) cells. But earlier sections suggest that they are
&gt;&gt; link cells.
&gt;&gt; 
&gt;&gt; If they are link cells, what key material is used for decryption?
&gt;&gt; How do the measurer and relay agree on this key material?
&gt;&gt; 
&gt;&gt; If they are relay cells, do they use the ntor handshake?
&gt;&gt; https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n1132
&gt;&gt; 
&gt; 
&gt; MEASURE cells are cells like CREATE, CREATED, RELAY, etc.

In the Tor protocol specification, we call these "commands", and the
cells are sent at the link level.

&gt; MSM_ECHO, MSM_PARAMS, etc. cells are MEASURE cells in the same way
&gt; RELAY_BEGIN, RELAY_DATA, RELAY_SENDME, etc. are RELAY cells.

For relay cells, we call these "relay commands", and the cells are
sent at the circuit level.

So it might be helpful to say "measure commands" here. It might also be
helpful to distinguish "control" and "data" cells, in a similar way to
the relay cell spec:

https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1572

&gt; The relay needs to do AES on the MSM_ECHO cells (or for simplicity, the
&gt; MSM_ECHO cell payload) like it does AES on relay cells. As for key
&gt; material necessary to do that, that's an oversight. We've neglected to
&gt; specify how it's derived.
&gt; 
&gt; Suggestions? Not a cryptographer, but off the top of my head, the
&gt; measurer could simply tell the relay to use $key_i for MSM_ECHO cells on
&gt; $connection_i. We just want the CPU load on the relay; we're not after
&gt; security properties here (other than verifying the relay is actually
&gt; doing the crypto, as discussed elsewhere).

I suggest that the client opens a real single-hop circuit, and sends
RELAY_ECHO cells (a new relay command) on that circuit.

As part of this design:
* RELAY_ECHO cells are only allowed from valid measurers
* flow control is disabled on circuits from valid measurers
  (I think that's what you want here, but best to be explicit)

This design has a few advantages:
* The design and coding is much simpler
* FlashFlow automatically uses the latest relay crypto
* The key material is automatically derived for you
* The decryption and some verification is automatically performed for you
* You can verify the cell contents using a simple memcmp()

There's a slight disadvantage:
* When you skip decrypting a cell, the digest gets out of sync, so future
  cells have less validation. But I don't think that matters for single-hop
  circuits.

It's likely that your measurers will be network-bound, rather than
CPU-bound. So you may be able to just use unmodified circuit crypto.

There are also security advantages to using unmodified relay crypto. If tor
adds extra modes that skip decryption or verification, then it's easier to
accidentally trigger those modes. (Via bugs or exploits.)

If we use unmodified relay crypto, then it's much harder to get tor into an
insecure mode.

Here's what the cells would look like in detail:

16 -- RELAY_ECHO   [forward]             [control]
17 -- RELAY_ECHOED [backward]            [control]

I think these should be control cells (circuit-level cells) rather than
stream-level cells, because they are like RELAY_DROP:

10 -- RELAY_DROP   [forward or backward] [control]

I don't have a strong opinion about the rest of the measure commands. They
can stay as link-level cells. But if it turns out that it's easier to code
them as circuit-level cells, we could add a new RELAY_MEASURE command.

&gt;&gt;&gt; until it has reported its amount of background
&gt;&gt;&gt; traffic the same number of times as there are seconds in the measurement
&gt;&gt;&gt; (e.g. 30 per-second reports for a 30 second measurement). After sending
&gt;&gt;&gt; the last MSM_BG cell, the relay drops all buffered MSM_ECHO cells,
&gt;&gt;&gt; closes all measurement connections, and exits measurement mode.
&gt;&gt; 
&gt;&gt; To be more precise here, can we say:
&gt;&gt; 
&gt;&gt; "the relay drops all inbound and outbound MSM_ECHO cells from measurers
&gt;&gt; associated with the completed measurement"
&gt;&gt; 
&gt;&gt; Can we avoid assuming that there is always only one measurement happening
&gt;&gt; at one time?
&gt;&gt; 
&gt; 
&gt; I think it's safe/smart/necessary to assume that, for a given relay,
&gt; there is always only zero or one measurements happening.
&gt; 
&gt; - Measurements are scheduled s.t. coordinators won't try to measure a
&gt; relay at the same time.
&gt; - A coordinator trying to start a measurement while another one is
&gt; ongoing can simply be sent a MSM_ERR cell stating as such.

You're right, the relay can resolve clashes. It's important that we make
that explicit.

&gt;&gt;&gt; During the measurement the relay targets a ratio of background traffic
&gt;&gt;&gt; to measurement traffic as specified by a consensus parameter/torrc
&gt;&gt;&gt; option. For a given ratio r, if the relay has handled x cells of
&gt;&gt;&gt; measurement traffic recently, Tor then limits itself to y = xr/(1-r)
&gt;&gt;&gt; cells of non-measurement traffic this scheduling round. The target will
&gt;&gt;&gt; enforce that a minimum of 10 Mbit/s of measurement traffic is recorded
&gt;&gt;&gt; since the last background traffic scheduling round to ensure it always
&gt;&gt;&gt; allows some minimum amount of background traffic.
&gt;&gt; 
&gt;&gt; Do you mean "a maximum of 10 Mbit/s of measurement traffic" ?
&gt; 
&gt; No. When getting ready to handle background traffic, if there has been
&gt; less than 10 Mbit/s of measurement traffic recently, Tor will limit
&gt; background traffic as if there was indeed 10 Mbit/s of measurement traffic.
&gt; 
&gt; This way the relay can always send at least some background traffic, and
&gt; a malfunctioning/malicious FlashFlow deployment cannot stop all
&gt; background client traffic going through a relay for 30 seconds by not
&gt; sending it (very much) measurement traffic.

I'm still a bit confused here.

When you say:
"The target will enforce that a minimum of 10 Mbit/s of measurement traffic
is recorded"

I think you mean:
"... regardless of the actual traffic sent by the measurer."

But that raises another concern:

What about relays with very low bandwidths?
Will they reserve all their traffic for users, and none for the measurer?

Using the suggested r=25%, the maximum non-measurement traffic is:

y = (10 Mbits)(0.25)/(1-0.25)
  = 3.3 Mbits

So a relay with an actual capacity of 3.3 Mbits, which is fully loaded
with user traffic, will send no measurement traffic.

That seems... unexpected.

At the moment, tor directory authorities default to:

AuthDirFastGuarantee 100 Kbytes
AuthDirGuardBWGuarantee 2 Mbytes

So maybe we should derive the limit based on these values?

&gt;&gt;&gt; 3.2.1 FlashFlow Coordinator
&gt;&gt;&gt; 
&gt;&gt;&gt; The coordinator is responsible for scheduling measurements, aggregating
&gt;&gt;&gt; results, and producing v3bw files. It needs continuous access to new
&gt;&gt;&gt; consensus files, which it can obtain by running an accompanying Tor
&gt;&gt;&gt; process in client mode.
&gt;&gt; 
&gt;&gt; Recent tor versions go dormant when they haven't built circuits for a
&gt;&gt; while. There are options that prevent dormancy, but they are only designed
&gt;&gt; for interactive applications.
&gt;&gt; 
&gt;&gt; Is the FlashFlow coordinator going to use tor to implement the tor link
&gt;&gt; protocol?
&gt;&gt; 
&gt;&gt; If the coordinator uses tor, then it can use the same tor client instance
&gt;&gt; that's downloading its consensuses.
&gt;&gt; 
&gt;&gt; Otherwise, you might just be better using a small stem script, and a
&gt;&gt; download timer.
&gt;&gt; 
&gt;&gt; If you use a timer, you can download each new consensus, shortly after
&gt;&gt; it is created. (Clients often have consensuses that are 1-2 hours old,
&gt;&gt; unless specifically configured to fetch from directory authorities.
&gt;&gt; Even then, they can take up to an hour to download a new consensus.)
&gt;&gt; 
&gt; 
&gt; As described elsewhere, the coordinator uses a Tor client in order to
&gt; avoid implementing the tor link protocol itself. If there is not already
&gt; a way to make a Tor client download every new consensus (e.g. a torrc
&gt; option or an hourly control port command), we'll want to add that.

If the coordinator is constantly sending network traffic to relays, then it
shouldn't go dormant.

Here are the torrc options you might want to set on the coordinator:

# Set this to your maximum expected gap between relay measurements,
# including network downtime and other emergencies.
# Particularly important during the initial deployment.
DormantClientTimeout 1 week

# You may also need to set
FetchUselessDescriptors 1

# Get new relays as fast as possible.
FetchDirInfoEarly 1
FetchDirInfoExtraEarly 1

This is starting to look like the sbws config, you probably want most of
these options on controllers and measurers:
https://github.com/torproject/sbws/blob/master/sbws/globals.py#L20

&gt;&gt; What if the capacity is limited at some other point on the internet?
&gt;&gt; 
&gt;&gt; For example:
&gt;&gt; * an intermediate transit provider between the measurer and all the chosen
&gt;&gt;  relays
&gt;&gt; * the chosen relays are all on the same local network
&gt;&gt; 
&gt; 
&gt; Ideally a single FlashFlow deployment's measurers are diverse to help
&gt; mitigate the first point.
&gt; 
&gt; For the second, I don't have a good idea at this time. That shouldn't
&gt; happen regularly. It will happen sometimes though, so perhaps this
&gt; motivates a modification in how the coordinator chooses the weight for a
&gt; relay. Instead of the result of the latest measurement, perhaps the
&gt; highest result from the last X measurements.

That seems like a good idea.

It might also help to measure relays in each family in separate slots. You
might also want to do the same thing with relays that are in:
* the same IPv4 /24
* the same IPv6 /48

Or at the very least, relays on the same IP address.

&gt;&gt;&gt; Relays without existing capacity estimates are assumed to have the 75th
&gt;&gt;&gt; percentile capacity of the current network.
&gt;&gt;&gt; 
&gt;&gt;&gt; If a relay is not online when it's scheduled to be measured, it doesn't
&gt;&gt;&gt; get measured that day.
&gt;&gt; 
&gt;&gt; Online in the consensus, or listening via its ORPort?
&gt;&gt; (There's a delay of up to 3 hours here, whenever the relay goes up or
&gt;&gt; down.)
&gt;&gt; 
&gt;&gt; What bandwidth weight does an offline relay get?
&gt;&gt; sbws has had issues because it drops offline relays.
&gt;&gt; 
&gt; 
&gt; Online as in both, I think.
&gt; 
&gt; I'm not up to speed or have forgotten why continuing to give weight to
&gt; offline relays is important (and this may not be the place to enlighten
&gt; me). Naively I'd say zero. Assuming that's stupid, I **think** whatever
&gt; weight FlashFlow would give it were it online is smarter than some
&gt; minimum weight value. Suggestions?

You'll need relays to be in the consensus to do connection crypto, and
listening on their ORPort to actually connect. Then you can measure.

Relays sometimes drop out of the consensus between their measurement,
and the creation of the v3bw file. So don't check if they are online
when you create that file.

Using the median of the past few measurements is a good idea anyway:
tor has a daily user bandwidth cycle. And it helps deal with missing
measurements.

&gt;&gt;&gt; 3.2.1.2.1 Example
&gt;&gt;&gt; 
&gt;&gt;&gt; ...
&gt;&gt;&gt; 
&gt;&gt;&gt; 3.2.1.3 Generating V3BW files
&gt;&gt;&gt; 
&gt;&gt;&gt; Every hour the FF coordinator produces a v3bw file in which it stores
&gt;&gt;&gt; the latest capacity estimate for every relay it has measured in the last
&gt;&gt;&gt; week. The coordinator will create this file on the host's local file
&gt;&gt;&gt; system. Previously-generated v3bw files will not be deleted by the
&gt;&gt;&gt; coordinator.
&gt;&gt; 
&gt;&gt; Seems risky, we've seen Torflow fail in the past, because it filled up
&gt;&gt; the disk with bandwidth files.
&gt;&gt; 
&gt;&gt; What's the required disk capacity for a few years of bandwidth files?
&gt;&gt; 
&gt; 
&gt; We can ship a script or provide a parameter to keep the last X v3bw
&gt; files if that would be preferable to relying on bwauths using logrotate
&gt; themselves or otherwise finding an archival/deletion strategy that fits
&gt; their needs.

If you provide a default maximum age, then you can document the disk
capacity that's required to keep that many files.

If operators have more or less disk, they can change the defaults.

&gt;&gt;&gt; 3.2.2 FlashFlow Measurer
&gt;&gt;&gt; 
&gt;&gt;&gt; The measurers take commands from the coordinator
&gt;&gt; 
&gt;&gt; The command protocol is not specified in this proposal.
&gt;&gt; 
&gt;&gt; For example, does the coordinator send the IPv4 and IPv6 addresses of
&gt;&gt; the relay to the measurers?
&gt;&gt; 
&gt;&gt; Which deployment parameters are sent via the protocol, and which are
&gt;&gt; hard-coded in configurations?
&gt;&gt; 
&gt; 
&gt; A Tor proposal did not seem the place for some of these protocols,
&gt; options, etc. existing entirely outside little-t tor. We can certainly
&gt; elaborate better if that's wrong.

I'm not sure. It's helpful to have a design overview somewhere, and to
reference it from the proposal.

I don't have strong opinions about exactly where it is located. Most
similar documentation is external, but the BridgeDB spec is part of the
Tor specifications:
https://github.com/torproject/torspec/blob/master/bridgedb-spec.txt

One helpful question is:

Who will maintain this software over the long term?

Ask them how they want it to be specified.

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl6jn4gACgkQEP6qDnB1
ZypVkxAAsm+MWx8Z9MAn7cVh52lMy7epwBagJmLkWPjo0rxHojeruD+zlRGk1Q5v
hkE/yALFoaN8S1QNUf+VCRmlsru1wuzzkrJx6l6X4VnIbza7c2Rbk1HHPNdSrPgh
6ZlGESuzQA4o52ggeu4FZf0P9mxq4HIj069sKiSJJghqkKAgVRod2WpdQ5xNcbpS
zbfJaw2QSPwztsPYUCsmo8PGHGWB8AO8DtXw0MdTSazV4CObQX+80ZpCkiok5eQX
IFWGboWW+036eYVweewHGOpqVYCoWh5zpxz3eFCNBBWrDwum1pHPOs/YHN3l3OaK
OhhEBKH2/xnNnY5XzYs6JvNiR6wK/W4KUcI//op5oWFMFOh+qssuovJODvFSdFxv
cN7jRaD+pB6OpqSyP21oHQPrsEZnhRNPwbSsp5mYt3v49StsLCSxdvQET3vrBlM1
43xE2FUa3CN9vv91GOCGc4eH5x6LXRT8CYHELuECaO2EMU0xSA6lSjgeqAs5Pkc0
l3jIns+IRD44uJEcvmmA+6fQzPk4+MJ2C5yCq/QX/+dmPSChmczpG0N7Iyr28Nvm
D0Yt2PmLijxj6BNn1YEJb4UNnfow/ROhIVd0+Ftd28cofA/RSl3rCnmsJ5N24TQe
yFucdCSRzdTnq8wQClnwRJe1qdfMyoAfUrA17iLKU8jToziYerY=
=DAim
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200427133351</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-04-27 13:33:51-0400</timestampReceived><subject>[tor-dev] Walking onions status update: week 8</subject><body>

Walking Onions: week 8 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html

Week 4:
   Voting (part 1) and extending circuits.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014207.html

Week 5:
   Voting (part 2)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014218.html

Week 6:
   Editing, voting rules, and client behavior (part 1)

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014222.html

Week 7:
   Exit policies: How do they work?

   https://lists.torproject.org/pipermail/tor-dev/2020-April/014232.html

== Onion services: surprisingly easy! (but not?)

This week I started with a look at onion services and how to make
them work with Walking Onions [ONIONSPEC].  Most of my initial
thought had gone into the problem of finding and using HSDirs, and
so specifying this part went smoothly.  I already havd a link
specifier for asking for a span of several entries in an ENDIVE, and
I already had a notion of truncating index values based on a network
parameter.

The harder part came when I wanted to talk about how to specify
introduction points and rendezvous points by their SNIPs.  The hard
part here was managing the migration path.  To avoid fingerprinting,
when we make changes to the onion service protocol of this kind, we
need to give a lot of onion services and clients the opportunity to
start supporting the new protocol all at once, and then to stop
supporting the old one all at once.  This requires more network
parameters, somewhat carefully specified.  I'm hoping we can turn
this into a more general pattern.

And the most irritating part is when I ran into the issue of
supporting HSv2 handshakes.  Were it not for those, we wouldn't have
to keep TAP keys around any more -- and TAP keys would bloat SNIPs
to a pretty huge degree.  The best answer here seems to be migrating
our legacy HSv2 services so they can use ntor onion keys for intro
and rendezvous points.  That would also need to be done in a phased
way.  [TAP-OUT-AGAIN].

The alternative way to keep HSv2 working with walking onions would
be to allow TAP keys to be distributed as part of the SNIP system.
That seems like a fair amount of work, though, and unlike using
ntor, it wouldn't have any positive benefit.

((Yes, HSv2 is deprecated.  But I don't want to give people who
still use it a reason to avoid the walking onions transition.))

== Relay honesty and ENDIVE swapping

One of the issues with our current directory system is that multiple
consensus network documents are valid at the same time.  In
practice, clients will accept fairly old documents, to avoid running
into trouble if the authorities have failed to vote.  But this
client behavior gives hostile directory guards an opportunity to
select which of several recent documents to serve.

Walking Onions would make this problem worse, since every relay,
when it serves a SNIP, is serving part of a directory that it
knows a client is about to use.  If we did nothing to mitigate the
problem, then hostile relays could mount an "ENDIVE swapping" attack
where they look at a client's choice of routing index, and then see
whether any live ENDIVE contains a SNIP that the attacker likes at
that position.

In [HONESTY] I described a few responses to this problem.  The first
is that we should limit the rate at which the index layouts
change. The second is that all parties that look up SNIPs through a
relay should verify that the "published" times from each relay are
monotonically increasing.

The third response seems like the most useful to me: we would
recognize that under ordinary circumstances, the permissible
lifetime for an ENDIVE would be much shorter than it would be under
emergency (consensus failed) circumstances.  That is, if everything
is going well, each relay should get a new ENDIVE every hour or so.
Only if there is no new ENDIVE should clients accept SNIPs that
are extremely old.

With this in mind, I'm proposing a rule that if a client sees _any_
valid SNIP published at time `T` or later, it should not accept any
SNIP published before time `T-Delta`.  (Delta is a network
parameter.)  With this rule in place, clients will insist on fresh
SNIPs when the network is working well, but will tolerate old ones
if the authorities are failing to reach consensus for a while.

== More questions of migration

One hard step in any proposal is dealing with migration questions.
I've stared to try to lay out a timeline in a new section
[MIGRATION].  This part isn't looking great to me right now.  It
seems like it won't be safe to turn on Walking Onions for clients
until it's supported by most relays.  Moreover, clients that use
Walking Onions won't be able to use relays (or at least, non-exit
relays) without support for it.  This implies a longer migration
path than I'd like, but I don't see a way around it.

== And what about families?

Our existing family representation is quadratic in family size,
since every relay needs to list every other relay in the family.
This gets worse with Walking Onions, since SNIPs can't benefit from
compressing the repeated family entries.

At first I had hoped to use some kind of a max-clique algorithm to
infer the families at the authorities, and then encode clique
identifiers in the SNIPs.  This isn't such a great idea, though:
I wasn't able to persuade myself that an adversary couldn't force
the authorities' burden to become exponential here.

Instead I think we should resurrect proposal 242, in an improved
version [BETTER-FAMILIES].  Instead of having to list every node in
a family, each relay in a family would include a signed certificate
from a "family key" attesting to their membership in the family.
The proposal addresses some tricky compatibility issues.

== Coming up next

This week is going to be rather busy on my end:  I'll be a bit
startled if I get very much done with Walking Onions at all.  My
hope is to edit the proposal, fill in gaps, and address pending
comments.


[BETTER-FAMILIES]
https://github.com/nmathewson/walking-onions-wip/blob/master/other-proposals/xxx-improved-242.md

[HONESTY] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/08-tracking-relay-honesty.md

[MIGRATION] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/09-migration.md

[ONIONSPEC] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/07-onion-services.md

[TAP-OUT-AGAIN]
https://github.com/nmathewson/walking-onions-wip/blob/master/other-proposals/xxx-tap-out-again.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200427161924</emailId><senderName>Christian Hofer</senderName><senderEmail>chrisss404@gmail.com</senderEmail><timestampReceived>2020-04-27 16:19:24-0400</timestampReceived><subject>Re: [tor-dev] Support for full DNS resolution and DNSSEC validation</subject><body>

Hi nusenu,

thank you for you feedback.

First I would like to say that this proposal should not be regarded as
final but work in progress. Second the changes are behind a feature
flag and very unintrusive, so the behvior does not change without
explicitly enabling them and they can be easily removed if it turns out
that this is not the right direction. Additionally, I think that it is
much easier to analyze certain scenarios with a proof of concept in
place.

As described in the proposal the idea is to move the DNS name
resolution from the exit relays to the client and add DNSSEC
validation.

Basic workflow:

* a new connection arrives at the SocksPort
* with the socks handshake we learn the target hostname
* a new connection for the DNS lookup is created and attached instead
of the incoming connection
* when the name is resolved the hostname in the original connection is
replaced with the IP address
* finally the original connection is attached

I can not really say anything about how this design compares to other
approaches, since I don't know how I can setup meaningful test
scenarios to compare them. However, I would appreciate if you could
share how to setup such test environments. For the server part I can
provide a DNS server that supports DoT, DoH, and DNSSEC.

Regarding stream isolation, see cypherpunks analysis in the ticket.

Please let me know if you think this approach is worthwhile. Then I
will try to answer the remaining questions.

BR
Christian

On Mon, 2020-04-27 at 00:56 +0200, nusenu wrote:
&gt; Hi Christian,
&gt; 
&gt; thanks for your efforts to improve DNS resolution in the tor context.
&gt; 
&gt; A few general questions:
&gt; - What is the underlying threat model and what threats you are trying
&gt; to address in
&gt; your proposal?
&gt; - What use case are you aiming for? Do you propose to make use of
&gt; this DNS resolution in Tor Browser by default?
&gt; - if so: 
&gt;   - Do you do connection re-use to route multiple DNS queries over a
&gt; single connection? (related: RFC 7766)
&gt;   - How does your proposal (or the user of your proposal - Tor
&gt; Browser) ensure stream isolation for DNS queries to avoid profiling
&gt; based on DNS queries?
&gt;   - How do you aim to solve the problems of resolver selection and
&gt; centralization?
&gt; if not:
&gt;   - why not just run existing resolver software (i.e. stubby) over
&gt; tor?
&gt; 
&gt; - How does your design compare to running existing DNS privacy
&gt; protocols over tor that do not require any changes to tor?
&gt;   - DoT non-opportunistic mode+DNSSEC validation or 
&gt;   - DoH+DNSSEC validation
&gt; 
&gt; I would also be interesting to see how your design compares to a
&gt; design like this 
&gt; (aiming for Tor Browser integration and enabled by default, without
&gt; tor changes):
&gt; DoH (RFC 8484) enabled in Tor Browser, the vanilla DoH implementation
&gt; in Firefox slightly changed so it is stream isolation aware (domains
&gt; are resolved via the same stream that is used to fetch the HTTP
&gt; content in all cases where the exit policy allows for that).
&gt; Resolver selection: pre-configured list in Tor Browser
&gt; (no implementation or proposal exists at this point)
&gt; 
&gt; &gt; Filename: 317-secure-dns-name-resolution.txt
&gt; &gt; Title: Improve security aspects of DNS name resolution
&gt; &gt; Author: Christian Hofer
&gt; &gt; Created: 21-Mar-2020
&gt; &gt; Status: Open
&gt; &gt; 
&gt; &gt; Overview:
&gt; &gt; 
&gt; &gt;    This document proposes a solution for handling DNS name
&gt; &gt; resolution within
&gt; &gt;    Tor in a secure manner. In order to achieve this the
&gt; &gt; responsibility for
&gt; &gt;    name resolution is moved from the exit relays to the clients.
&gt; &gt; Therefore a
&gt; &gt;    security aware DNS resolver is required that is able to operate
&gt; &gt; using Tor.
&gt; &gt;       DNSResolverNameservers: A list of comma separated
&gt; &gt; nameservers, can be an
&gt; &gt;         IPv4, an IPv6, or an onion address. Should allow means to
&gt; &gt; configure the
&gt; &gt;         port and supported zones.
&gt; 
&gt; How is end-to-end encryption / query confidentiality ensured in the
&gt; case this
&gt; configuration parameter contains IPv4/IPv6 addresses?
&gt; 
&gt;  
&gt; &gt;       DNSResolverHiddenServiceZones: A list of comma separated
&gt; &gt; hidden service
&gt; &gt;         zones.
&gt; 
&gt; What are "hidden service zones"? what is the impact of listing them
&gt; in this config parameter
&gt; and how is it related to RFC 7686?
&gt; 
&gt; &gt;       DNSResolverTrustAnchors: A list of comma separated trust
&gt; &gt; anchors in DS
&gt; &gt;         record format. https://www.iana.org/dnssec/files
&gt; 
&gt; Does your design support RFC 5011?
&gt; 
&gt; &gt;       DNSResolverMaxCacheEntries: Specifies the maximum number of
&gt; &gt; cache
&gt; &gt;         entries.
&gt; 
&gt; Where is the cache located? Is it written to disk?
&gt; Is the cache stream isolation aware or do you aim to reuse the cache
&gt; across multiple streams?
&gt; (which results in correlation issues across streams)
&gt; 
&gt; &gt; Performance and scalability:
&gt; &gt; 
&gt; &gt;    Since there are no direct changes to the protocol and this is an
&gt; &gt; alternative
&gt; &gt;    approach for an already existing requirement, there are no
&gt; &gt; performance
&gt; &gt;    issues expected. Additionally, the encoding and decoding of DNS
&gt; &gt; message
&gt; &gt;    handling as well as the verification takes place on the client
&gt; &gt; side.
&gt; 
&gt; A few remarks regarding performance (DNS resolution response time and
&gt; subsequent content fetches i.e. HTTPS):
&gt; - this design increases the network path when the configured resolver
&gt; is not the exit relay
&gt; - a design that will not use the exit for resolution will likely have
&gt; a performance impact on domains that do geoIP
&gt; based optimizations to allow i.e. HTTP fetches from locations near
&gt; the exit relay
&gt; 
&gt; 
&gt; kind regards,
&gt; nusenu
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200428075550</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-28 07:55:50-0400</timestampReceived><subject>Re: [tor-dev] Relay Truncated Cell Example</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Eli,

&gt; &gt; On 28 Apr 2020, at 11:47, Eli Vakrat &lt;eli@vakrat.com&gt; wrote:
&gt; But then I looked at the debug log of my guard node (remember that my guard node is \
&gt; on my local machine) and it said that it had received a DESTROY Cell back from the \
&gt; middle node and was passing on a RELAY_TRUNCATED cell to me: 
&gt; Apr 26 16:11:03.014 [debug] command_process_destroy_cell: Received for circID \
&gt; 2297363203. &lt;------this is the circuit ID between my gaurd node and the middle node \
&gt; Apr 26 16:11:03.014 [debug] command_process_destroy_cell: Delivering 'truncated' \
&gt; back. Apr 26 16:11:03.014 [debug] relay_send_command_from_edge_: delivering 9 cell \
&gt; backward. 
&gt; To my understanding what this log means is that some part of the EXTEND cell I sent \
&gt; to the middle node was wrong or malformed and because of this when the middle node \
&gt; tried to extend the circuit, an error occurred, and the circuit needed to be torn \
&gt; down. 
&gt; This is very weird because when I send an EXTEND cell that is meant for my guard \
&gt; node (meaning I want to extend the circuit from one hop to two hops) everything \
&gt; works fine, and I can even successfully derive the shared key material for the \
&gt; middle node.

It looks like there are at least two bugs here:
* encryption to the guard node
* decryption from the guard node

&gt; So I have several questions regarding this:
&gt; 
&gt; 1. First of all, I didn't quite understand the exact format of a RELAY_TRUNCATED \
&gt; cell. Does it contain a relay cell command + recognized+field +digest and so on? or \
&gt; is it just a single octet that immediately follows the cell command field? If some \
&gt; could show me an example of the cell, it would be much appreciated... 

It's a relay cell, so it contains all the relay cell fields:
https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1551
Then the relay cell's "data" contains a single byte "reason" field.

I agree it's confusing, I've fixed it in the spec.

&gt; 2. What are some common errors that would make an OR drop a RELAY EXTEND cell? I \
&gt; thought maybe it was a problem with my TAP handshake data, but after extensive \
&gt; checking that doesn't seem to be the case.

Have you tried running the middle relay on your machine as well?

You can run a whole tor network on your machine using chutney:
https://github.com/torproject/chutney/blob/master/README#L257
(If you're using Windows, Chutney won't work, because directory authorities don't \
work on Windows.)

Try:
CHUTNEY_STOP_TIME=-1 chutney/tools/test-network.sh
Then extend to the relays on 127.0.0.1.

It looks like you can't encrypt cells to the guard.

Have you tried sending a RELAY_DROP cell to the guard?
That's a good way to test encryption.

It also looks like you can't decrypt cells from the guard.

What's the data in the first CREATED cell from the guard?
Should it be all-zero? (Check the tor source code.)

Have you tried opening a stream to the guard node?
That's a good way to test decryption.

Most guards are directory caches, so you should be able to open a  RELAY_BEGINDIR \
stream, and download something small. Like the relay's descriptor.

&gt; 3. If someone could describe the exact steps of extending a circuit to a third \
&gt; node, it would greatly help me to make sure that I didn't miss a step or do \
&gt; something wrong.

Here's the spec for multi-hop circuits:
https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1290

It's hard to know what steps you're missing, without more information. Feel free to \
share your code, or ask questions about any confusing parts of the spec.

T


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div dir="ltr"&gt;&lt;meta http-equiv="content-type" \
content="text/html; charset=utf-8"&gt;&lt;div dir="ltr"&gt;Hi \
Eli,&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;blockquote type="cite"&gt;On 28 Apr 2020, \
at 11:47, Eli Vakrat &lt;eli@vakrat.com&gt; \
wrote:&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;But then \
I looked at the debug log of my guard node (remember that my guard node is on my \
local machine) and it said that it had received a DESTROY Cell back from the middle \
node and was passing on a RELAY_TRUNCATED cell to me:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;b&gt;Apr 26 \
16:11:03.014 [debug] command_process_destroy_cell: Received for circID \
&lt;span&gt;2297363203&lt;/span&gt;.&lt;/b&gt; &lt;------this is the circuit ID between my gaurd node \
and the middle node&lt;br&gt;&lt;b&gt;Apr 26 16:11:03.014 [debug] command_process_destroy_cell: \
Delivering 'truncated' back.&lt;br&gt;Apr 26 16:11:03.014 [debug] \
relay_send_command_from_edge_: delivering 9 cell backward.&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;To \
my understanding what this log means is that some part of the EXTEND cell I sent to \
the middle node was wrong or malformed and because of this when the middle node tried \
to extend the circuit, an error occurred, and the circuit needed to be torn \
down.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is very weird because when I send an EXTEND cell \
that is meant for my guard node (meaning I want to extend the circuit from one hop to \
two hops) everything works fine, and I can even successfully derive the shared key \
material for the middle node.&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It looks \
like there are at least two bugs here:&lt;/div&gt;&lt;div&gt;* encryption to the guard \
node&lt;/div&gt;&lt;div&gt;* decryption from the guard node&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;So I have several questions regarding \
this:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. First of all, I didn't quite understand the exact \
format of a RELAY_TRUNCATED cell. Does it contain a relay cell command+ \
recognized+field+digest and so on? or is it just a single octet that \
immediately follows the cell command field? If some could show me an example of the \
cell, it would be much \
appreciated...&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It's a relay cell, \
so it contains all the relay cell fields:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1551"&gt;https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1551&lt;/a&gt;&lt;/div&gt;&lt;div&gt;Then \
the relay cell's "data" contains a single byte "reason" \
field.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I agree it's confusing, I've fixed it in the \
spec.&lt;/div&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;2. What are some common \
errors that would make an OR drop a RELAY EXTEND cell? I thought maybe it was a \
problem with my TAP handshake data, but after extensive checking that doesn't seem to \
be the case.&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;Have you tried running \
the middle relay on your machine as well?&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;You can run a whole tor network on your machine using chutney:&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;a href="https://github.com/torproject/chutney/blob/master/README#L257"&gt;https://github.com/torproject/chutney/blob/master/README#L257&lt;/a&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;(If you're using Windows, Chutney won't work, because directory authorities \
don't work on Windows.)&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;Try:&lt;/div&gt;&lt;div \
dir="ltr"&gt;CHUTNEY_STOP_TIME=-1 chutney/tools/test-network.sh&lt;/div&gt;&lt;div dir="ltr"&gt;Then \
extend to the relays on 127.0.0.1.&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;It looks like \
you can't encrypt cells to the guard.&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;Have you \
tried sending a RELAY_DROP cell to the guard?&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;That's a good way to test \
encryption.&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: \
rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;It also looks like you can't decrypt \
cells from the guard.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, \
0); color: rgb(0, 0, 0);"&gt;What's the data in the first CREATED cell from the \
guard?&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, \
0);"&gt;Should it be all-zero? (Check the tor source code.)&lt;/div&gt;&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;div dir="ltr" \
style="caret-color: rgb(255, 255, 255); color: rgb(255, 255, 255);"&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;Have you tried opening a \
stream to the guard node?&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr" style="caret-color: rgb(255, \
255, 255); color: rgb(255, 255, 255);"&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: \
rgb(0, 0, 0);"&gt;That's a good way to test decryption.&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr" \
style="caret-color: rgb(255, 255, 255); color: rgb(255, 255, 255);"&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div \
dir="ltr" style="caret-color: rgb(255, 255, 255); color: rgb(255, 255, 255);"&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;Most guards are directory \
caches, so you should be able to open a RELAY_BEGINDIR stream, and download \
something small. Like the relay's descriptor.&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;3. If someone could describe the exact steps of \
extending a circuitto a third node, it would greatly help me to make sure that \
I didn'tmiss a step or do somethingwrong.&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div \
dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;Here's the spec for multi-hop circuits:&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;a href="https://github.com/torproject/torspec/blob/master/tor-spec.txt#L129 \
0"&gt;https://github.com/torproject/torspec/blob/master/tor-spec.txt#L1290&lt;/a&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;It's hard to know what steps you're missing, without more \
information. Feel free to share your code, or ask questions about any confusing parts \
of the spec.&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;T&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200429045729</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-04-29 04:57:29-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay wont connect to private IP address</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Eli,

&gt; On 29 Apr 2020, at 07:40, Eli Vakrat &lt;eli@vakrat.com&gt; wrote:
&gt; 
&gt; So thanks to teor's insightful response yesterday I decided to try to run a second \
&gt; tor relay (my middle node) on my private network. 
&gt; Unfortunately, I can't do it with Chutney because my python client is running on a \
&gt; windows machine. But I do have 3 machines at my disposal: 
&gt; 1. A windows machine (the python client)
&gt; 2. A mac (the guard node)
&gt; 3. Another mac (the middle node)

Can you run chutney on one of your macs?
You don't need a separate machine for each Tor relay.

If you want to reach your chutney tors from another machine on your local network, \
you'll need to set this environmental variable: CHUTNEY_LISTEN_ADDRESS=(IPv4 of your \
Mac)

See:
https://github.com/torproject/chutney/blob/master/README#L65

&gt; When my guard node tries to connect to my middle node after receiving from the \
&gt; client a RELAY_EXTEND cell, the guard node logs the following error: 
&gt; Apr 28 17:00:31.000 [info] circuit_extend: Client asked me to extend to a private \
&gt; address 
&gt; So regarding this, I have two questions:
&gt; 
&gt; 1. Is there a way for me to change something in my torrc file to override this \
&gt; error and allow my relay to extend to private IP addresses? 
&gt; My torrc is currently configured as such (Notice I put some place holders for the \
&gt; drectories and for the ip address tha aren't actually whats written there): \
&gt; ContactInfo email@example.com ControlPort 9051
&gt; DataDirectory &lt;/path/to/data/dir&gt;
&gt; ExitPolicy reject *:*
&gt; ExitRelay 0
&gt; GeoIPFile &lt;/path/to/geo/ip/file&gt;
&gt; GeoIPv6File &lt;/path/to/geo/ipv6/file&gt;
&gt; Log notice file &lt;path/to/log/dirs/&gt;/notice.log
&gt; Log debug file &lt;path/to/log/dirs/&gt;/debug.log
&gt; Log warn file &lt;path/to/log/dirs/&gt;/warn.log
&gt; Nickname vtoria
&gt; ORPort 443 NoAdvertise
&gt; ORPort Relay.Public.IP.Example:443 NoListen 
&gt; SafeLogging 0
&gt; ExtendAllowPrivateAddresses 1

That's odd. ExtendAllowPrivateAddresses is set to 1, which is what you want.

Are you sure your relay is using this torrc?
Check the path of the torrc in the logs.
Try restarting the relay.

&gt; 2. Would there maybe be a better way to run this private tor network (without \
&gt; chutney)?

There are two alternatives:
1. Chutney does a lot of the work for you, so I'd recommend using it, if you can.
2. You can also set up relays on private IP addresses, and set \
"PublishServerDescriptor 0", so they don't publish their descriptors to the Tor \
directory authorities.

If you're not publishing descriptors, you can have as many relays as you like on the \
same IP address.

T


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;&lt;span \
style="background-color: rgba(255, 255, 255, 0);"&gt;Hi Eli,&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;On 29 Apr 2020, at 07:40, Eli Vakrat \
&lt;eli@vakrat.com&gt; wrote:&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div \
dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So thanks to teor'sinsightful \
response yesterday I decidedto try to run a second tor relay (my middle node) \
on my private network.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Unfortunately, I can't do it with \
Chutney because my python clientis running on a windows machine. But I do have \
3 machines at my disposal:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. A windows machine (the python \
client)&lt;/div&gt;&lt;div&gt;2. A mac (the guardnode)&lt;/div&gt;&lt;div&gt;3. Another mac (the middle \
node)&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Can you run chutney on one of \
your macs?&lt;/div&gt;&lt;div&gt;You don't need a separate machine for each Tor \
relay.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If you want to reach your chutney tors from another \
machine on your local network, you'll need to set this environmental \
variable:&lt;/div&gt;&lt;div&gt;CHUTNEY_LISTEN_ADDRESS=(IPv4 of your \
Mac)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;See:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://github.com/torproject/chutney/blob/master/README#L65"&gt;https://github.com/torproject/chutney/blob/master/README#L65&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;When my guardnode tries to \
connect to my middle node after receiving from the client a RELAY_EXTEND cell, the \
guardnode logs the following error:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Apr 28 \
17:00:31.000 [info] circuit_extend: Client asked me to extend to a private \
address&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So regarding this, I have two \
questions:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1. Is there a way for me to \
changesomethingin my torrc file to override this error and allow my relay \
to extend to private IP addresses?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My torrc is currently \
configured as such (Notice I put some place holders for the drectoriesand for \
the ip address tha aren'tactually whatswritten there):&lt;/div&gt;&lt;div&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ContactInfo&lt;a \
href="mailto:draftkingschaching@gmail.com" target="_blank"&gt;e&lt;/a&gt;&lt;a \
href="mailto:mail@example.com"&gt;mail@example.com&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ControlPort 9051&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;DataDirectory \
&lt;/path/to/data/dir&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExitPolicy reject *:*&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExitRelay 0&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;GeoIPFile \
&lt;/path/to/geo/ip/file&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;GeoIPv6File \
&lt;/path/to/geo/ipv6/file&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log notice file \
&lt;path/to/log/dirs/&gt;/notice.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log debug \
file&lt;/span&gt;&lt;path/to/log/dirs/&gt;/&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;debug.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Log warn \
file&lt;/span&gt;&lt;path/to/log/dirs/&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;/warn.log&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;Nickname vtoria&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ORPort 443 \
NoAdvertise&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ORPort&lt;a \
href="http://79.183.54.194:443/" \
target="_blank"&gt;Relay.Public.IP.Example:443&lt;/a&gt;NoListen&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;SafeLogging 0&lt;/span&gt;&lt;/p&gt;&lt;p \
style="font-variant-numeric:normal;font-variant-east-asian:normal;font-stretch:normal; \
font-size:11px;line-height:normal;font-family:Menlo;margin:0px;color:rgb(0,0,0)"&gt;&lt;span \
style="font-variant-ligatures:no-common-ligatures"&gt;ExtendAllowPrivateAddresses \
1&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That's odd. \
ExtendAllowPrivateAddresses is set to 1, which is what you \
want.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Are you sure your relay is using this \
torrc?&lt;/div&gt;&lt;div&gt;Check the path of the torrc in the logs.&lt;/div&gt;&lt;div&gt;Try restarting \
the relay.&lt;/div&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;2. \
Would there maybe be a better way to run this private tor network (without \
chutney)?&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;There are two \
alternatives:&lt;br&gt;&lt;div&gt;1. Chutney does a lot of the work for you, so I'd recommend \
using it, if you can.&lt;/div&gt;&lt;div&gt;2. You can also set up relays on private IP \
addresses, and set "PublishServerDescriptor 0", so they don't publish their \
descriptors to the Tor directory authorities.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If you're not \
publishing descriptors, you can have as many relays as you like on the same IP \
address.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200429120207</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-04-29 12:02:07-0400</timestampReceived><subject>Re: [tor-dev] Does a design document for the DoS subsystem exist?</subject><body>

[Attachment #2 (multipart/signed)]


On 15 Apr (00:25:11), Lennart Oldenburg wrote:
&gt; Hello George, hello all,

Hi Lennart,

Sorry for the late reply, as you may have seen, things got a bit intense in
Tor in the last 2 weeks.

&gt; 
&gt; Thank you very much for the provided pointers. Great to hear progress is
&gt; being made on the Onion Services DoS matter. Two follow-up questions:
&gt; 
&gt; 1) Will the DoS subsystem overhaul also affect guard-centric DoS
&gt; countermeasures? Or will it exclusively focus on DoS protection specific
&gt; to Onion Services? If guard-centric countermeasures are also being
&gt; updated, is there a document to see what is about to change?

The HS DoS defenses are independent from the relay DoS subsystem.

&gt; 
&gt; 2) The linked bug ticket [1] under your first bullet point does not
&gt; mention the origin of the concrete threshold values
&gt; (DoSCircuitCreationRate, etc.). Could you share any insight on how these
&gt; DoS threshold values are determined? Are they inferred from experiments?

Correct that we don't have a clear document explaining how we got there. But
if we dig, there are emails on a mailing list and possibly a ticket with
discussions about the choice of these parameters. But I do also unfortunately
recall some of it was only discussed and decided on IRC...

As far as I can recall, we've decided these values based on the "common use
case" and observation at Guard relays _not_ under attack versus one under
attack at the time.

One of the main reason for the picked values was the "Coffee Shop Effect" or
the "Airport Effect" that is in a regular normal use case, how many clients
would connect to Tor from the same IP address? We thought that 100-150 people
would be reasonable (from an airport or coffee shop) so we doubled that.
Putting all this together, with these two parameters, you get your 300 value:

    DoSCircuitCreationRate * DoSConnectionMaxConcurrentCount

So for a single client IP address, we allow 3 concurrent connections
(DoSCircuitCreationMinConnections) until we activate defenses for that IP. And
then, you are allowed 3 * 100 circuits per second until we start denying you
circuit creation. And a burst of 90 (DoSCircuitCreationBurst) is allowed per
second up to 300 maximum).

And why 3 concurrent connections until we activate defenses? At the time, we
imagined that someone could have 1 Tor Browser and a standalone tor daemon for
the rest (onion share, torsocks, etc...). Above that, it would not be the
"usual" use case and thus we activate defenses. But then even if you are 10 on
the same IP, 300 circuit/sec is massive for clients... so there was still a
good margin from what the attack was doing.

And also, all these parameters can be controlled within the consensus so if
any of them would have been too much or too lax, we could have reacted. It
turned out in the end that they were very efficient at stopping the DDoS we
had at the time. Who knows what the next big DDoS will bring and we might need
to tweak those values as we monitor the attack.

All in all, I do agree with you that we should have a clear nice document in
our spec repository at least to describe the what/how these values came about.
Time is such a scarse resources these days :(.

Cheers!
David

-- 
vazCt9Q/hhTh3g3JP3KjhmzS1a5JTbDcO4zVCXlh9fc=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200303161437</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-03-03 16:14:37-0400</timestampReceived><subject>Re: [tor-dev] Request for onionbalance v3 pre-alpha testing</subject><body>

George Kadianakis &lt;desnacked@riseup.net&gt; writes:

&gt; George Kadianakis &lt;desnacked@riseup.net&gt; writes:
&gt;
&gt;&gt; Hello list,
&gt;&gt;
&gt;&gt; we've been developing Onionbalance v3 for the past months, and I'm
&gt;&gt; pretty hyped to say that the project has reached a stability point that
&gt;&gt; could benefit from some initial testing by curious and adventurous
&gt;&gt; developers and users.
&gt;&gt;
&gt;
&gt; Hello people,
&gt;
&gt; I haven't received much testing for onionbalance v3 yet, so I'm
&gt; shamelessly bumping this thread in hopes for more activity. I bet many
&gt; people would love to test this but they don't know it exists so perhaps
&gt; this works.
&gt;
&gt; Also, I just uploaded this guide to my github so tha I can dynamically
&gt; update it if bugs are found by testers without having to post errata to
&gt; a mailing list: https://github.com/asn-d6/onionbalance/blob/master/docs/alpha-testing-v3.txt
&gt;
&gt; Thanks!

Hello again,

you can now find an even better guide for setting up OnionBalance V3 here:
    https://onionbalance-v3.readthedocs.io/en/latest/v3/tutorial-v3.html#tutorial-v3

I'm currently working on packages and CI for it.

Let me know if you find any bugs or issues :)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200305153607</emailId><senderName>Pili Guerra</senderName><senderEmail>pili@torproject.org</senderEmail><timestampReceived>2020-03-05 15:36:07-0400</timestampReceived><subject>Re: [tor-dev] Regarding GSoC 2020</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Aman,

Thank you for your interest in contributing to Tor for GSoC 2020.

For questions about GSoC please email gso+c@torproject.org and we'll be able to guide \
you further. 

We find it easier to help out with specific questions rather than general requests \
for guidance :) 

Thanks!

Pili

Project Manager: Tor Browser, UX and Community teams
pili at torproject dot org 
gpg 3E7F A89E 2459 B6CC A62F 56B8 C6CB 772E F096 9C45

&gt; On 2 Mar 2020, at 06:20, Aman Rastogi &lt;arastogi2810@gmail.com&gt; wrote:
&gt; 
&gt; Respected Developers,
&gt; I am Aman, GSoC 2020 aspirant, and i would like to work for Torr. I am interested \
&gt; in "Privacy Friendly Web" and "OONI Explorer Advanced Search". 
&gt; Can I get some guidance, please?
&gt; 
&gt; Thanking you, and sorry for such an informal mail.
&gt; 
&gt; -- 
&gt; Aman
&gt; 
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;Hi Aman,&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thank you for your interest in contributing to Tor for \
GSoC 2020.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;For questions about \
GSoC please &lt;a href="mailto:gso+c@torproject.org" class=""&gt;email \
gso+c@torproject.org&lt;/a&gt; and we'll be able to guide you further.&lt;/div&gt;&lt;div \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;We find it easier to help out with specific \
questions rather than general requests for guidance :)&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thanks!&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Pili&lt;/div&gt;&lt;div class=""&gt;&lt;div class=""&gt; &lt;div style="caret-color: rgb(0, 0, \
0); color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; \
font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: \
auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; \
widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; \
-webkit-text-stroke-width: 0px; text-decoration: none;"&gt;&lt;br class=""&gt;Project \
Manager: Tor Browser, UXand Community teams&lt;br class=""&gt;pili at torproject dot \
org&lt;br class=""&gt;gpg3E7F A89E 2459 B6CC A62F56B8 C6CB 772E F096 \
9C45&lt;/div&gt; &lt;/div&gt;
&lt;div&gt;&lt;br class=""&gt;&lt;blockquote type="cite" class=""&gt;&lt;div class=""&gt;On 2 Mar 2020, at \
06:20, Aman Rastogi &lt;&lt;a href="mailto:arastogi2810@gmail.com" \
class=""&gt;arastogi2810@gmail.com&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br \
class="Apple-interchange-newline"&gt;&lt;div class=""&gt;&lt;div dir="ltr" class=""&gt;Respected \
Developers,&lt;div class=""&gt;&lt;div class=""&gt; I am Aman, GSoC 2020 aspirant, \
and i would like to work for Torr. I am interestedin "Privacy Friendly Web" and \
"OONI Explorer Advanced Search".&lt;/div&gt;&lt;div class=""&gt; &lt;/div&gt;&lt;div \
class=""&gt; Can I get some guidance, please?&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt; Thanking you, and sorry for such \
aninformalmail.&lt;/div&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;-- &lt;br \
class=""&gt;&lt;div dir="ltr" class="gmail_signature" \
data-smartmail="gmail_signature"&gt;Aman&lt;br class=""&gt;&lt;br class=""&gt;&lt;br class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;/div&gt; _______________________________________________&lt;br \
class=""&gt;tor-dev mailing list&lt;br class=""&gt;&lt;a \
href="mailto:tor-dev@lists.torproject.org" \
class=""&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br \
class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;br \
class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200308193526</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-08 19:35:26-0400</timestampReceived><subject>[tor-dev] Walking Onions status update: week 1 notes</subject><body>

Hi!  On our current grant from the zcash foundation, I'm working
on a full specification for the Walking Onions design.

If you haven't read it, Walking Onions is a set of ideas meant to
transition Tor away from its current dependency on a directory
system, to improve scaling in the long term, and performance of
low-bandwidth clients in the short term.

I'm going assume in the rest of my email that you already have a
decent idea of how Tor works, and of the Walking Onions proposal.
If you need a Walking Onions refresher, see proposal 300 [PROP300]
and the whitepaper that Chelsea Komlo, Ian Goldberg, and I have
been working on [WHITEPAPER].

The current scope for this work is to try to solve all the open
design questions for Walking Onions, and to write a set of
specifications we could use to build the system.

I'm aiming to have the initial versions of these specs wrapped up
in April.  Rather than dumping everything onto the mailing list at
once, I'm going to try working in the open, sending weekly updates
about my work.

Design and specification are a lot of fun for me; I hope you'll
have fun too reading along.

This past week, I started by writing:

   - An outline of the set of specifications we'd need to have
     before we could implement walking onions. (OUTLINE0.txt)

   - A list of areas of uncertainty that we need to solve before
     or during writing the specs. (UNCERTAINTY.txt)

   - A list of related problems that we might wind up solving
     along with the walking onion specs (OPPORTUNITIES.txt)

   - A rough grouping of initial tasks, which should eventually
     turn into a schedule. (PLAN.txt)

You can find all these documents in a working git repository
[GITREPO] that I've been making for this purpose, if you like.  I
don't intend for this repository to be a permanent reference or to
be necessarily useful for anybody but me: everything important
about it should eventually wind up in specifications and on this
mailing list.

==

The biggest area of uncertainty was to pick a meta-format for
ENDIVEs and SNIPs.  I looked at our existing directory
meta-format, along with protobufs, messagepack, and a whole bunch
of other systems.  I also looked into what kind of efficiency we'd
get by just using a hand-tooled non-extensible binary format, so
that I could see what kind of overhead we were looking at.

The issue here is that I think we don't want to be using a
text-based metaformat for SNIPs: we need SNIPs to be as small as
possible, and our current text-based directory metaformat only
compresses well when we're using huge amounts of it at once.

But if we're doing a binary format, we probably shouldn't
hand-roll it.  Trunnel lets us handle our existing formats safely,
but those formats aren't so efficient in practice, and they aren't
too standardized.  If we use a standardized binary format, then we
get encoding, decoding, debugging dumps, optimization, and lots of
other stuff "for free".

After looking at a pretty huge variety of formats, I think that
our best bet is something called "CBOR", standardized as RFC 7049
[CBOR].  It is substantially based on MessagePack, but with a
number of improvements.  Here are some of CBOR's advantages:

    + It's optimized first for allowing encoding/decoding to be
      done with small, simple code -- and second, for having a
      small binary format.  IMO it succeeds at both: the
      metaformat is simple, and there are decoder implementations
      in less than 1kb of binary size.

    + You can think of its data model as a "binary json"; it's
      very flexible. (yes I know about the other binary jsons)

    + It's standardized, and there are lots of implementations of
      it, in lots of different languages.

    + It has a data definition language [CDDL], which we don't
      actually need to implement, but which we can use to help
      write our specs and validate our implementation.

    + It has a textual encoding for debugging, and a one-way
      mapping to json.

Here are some of its disadvantages:

    - It doesn't have a built-in object mapping like protobufs
      does.

    - It allows multiple encodings for a single piece of
      data. (The CBOR RFC explains how to make a canonical
      encoding.)

    - Our diff story gets slightly more complex when we have a
      binary format.

(I'd be happy to talk about other possibilities, but please make sure you
know about the bikeshed first. [BIKESHED])

==

Doing diffs from one ENDIVE to the next will be helpful if we want
to keep relay bandwidth on the small side.  We'll need binary
diffs for this.  Fortunately, I think that shouldn't be too hard
to do with our existing diff code: instead of doing line-by-line
diffs, we'll just do CBOR-item-by-item diffs, and encode them in a
byte-oriented way.  I've got a prototype half-written to make sure
this is right.  The simplicity of CBOR makes this pretty easy.

==

There are a few ways to authenticate SNIPs.  It's looking like
right now the most efficient will be merkle trees, with the root
of the tree signed by a threshold signature algorithm like BLS.

One of the neat things about merkle trees is that if we are
transmitting the leaves and the signature on the root, we don't
need to actually transmit the intermediate nodes as part of the
ENDIVE.  So that's cool, and it will make ENDIVE diffs smaller.

One of the not-so-neat things is that the merkle tree paths are a
bit long.  There are ways to make them shorter: you only need to
transmit one digest for each layer, plus a bit to say which hash
it is.

(I learned about these tricks while working on [WHITEPAPER],
thanks to Ian and Chelsea.)

One risky thing I've been thinking about is whether we can use a
shorter-than-256-bits hash for the merkle tree nodes, if we don't
need to worry about collision resistance for the digest functions.
The SNIPs are generated by authorities, but they do contain a
certain amount of adversary-created material.  Randomized hashes
with an unpredictable key might help, particularly for
intermediate nodes on the tree? [XMSS] has some ideas
here. (Suggested by Jack Lloyd)


==

In the coming week, I'm hoping to finish up making my draft
schedule, start doing research as needed to handle more open
questions, and write an initial spec for the ENDIVE and SNIP
formats.

[BIKESHED] "Why Should I Care What Color the Bikeshed Is?"
    http://bikeshed.com/

[CBOR] RFC 7049: "Concise Binary Object Representation (CBOR)"
    https://tools.ietf.org/html/rfc7049

[CDDL] RFC 8610: "Concise Data Definition Language (CDDL): A
    Notational Convention to Express Concise Binary Object
    Representation (CBOR) and JSON Data Structures"
    https://tools.ietf.org/html/rfc8610

[GITREPO]  https://github.com/nmathewson/walking-onions-wip

[PROP300] "Walking Onions: Scaling and Saving Bandwidth"
    https://gitweb.torproject.org/torspec.git/plain/proposals/300-walking-onions.txt

[WHITEPAPER] "Walking Onions: Scaling Anonymity Networks while
    Protecting Users"
    https://crysp.uwaterloo.ca/software/walkingonions/

[XMSS] RFC 8391: "XMSS: eXtended Merkle Signature Scheme".
    https://tools.ietf.org/html/rfc8391
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200310153230</emailId><senderName>"Drew () FoundingDocuments ! org"</senderName><senderEmail>drew@foundingdocuments.org</senderEmail><timestampReceived>2020-03-10 15:32:30-0400</timestampReceived><subject>Re: [tor-dev] SOOC (Same Origin Onion Certificates) discussion tomorrow</subject><body>

I am very sorry I am missing this! It sounds very interesting I wanted to listen and \
learn, but I' having a very tough time connecting to the OFTC webchat. It seems slow \
or something. I finally got through but then it told me I needed to do a bunch of \
administrative stuff, so am currently locked out.

However, I noticed this a few weeks ago but haven't seen it mentioned here. 
https://community.letsencrypt.org/t/if-when-will-le-support-onion-addresses/341/85

See post #85. 

Back to slogging through trying to get into #tor-meeting. 

&gt; On Mar 9, 2020, at 4:10pm, Richard Pospesel &lt;richard@torproject.org&gt; wrote:
&gt; 
&gt; Hi Everyone,
&gt; 
&gt; The current UX situation around HTTPS-enabled onionsites is not the
&gt; best: Tor Browser shows security warning splash screens and icons in
&gt; scenarios that do not warrant them. On top of that, the only way for
&gt; your onion site to not show these warnings is by getting an EV cert
&gt; which is only practical if you have the $$$.
&gt; 
&gt; alecmuffet's SOOC proposal (
&gt; https://github.com/alecmuffett/onion-dv-certificate-proposal/blob/master/text/draft-muffett-same-origin-onion-certificates.txt
&gt;  ) does seem to fix these UX problems for us. Though the proposal is
&gt; still incomplete, we can make forward progress with a prototype
&gt; implementation as the certificate specification is fully fleshed out.
&gt; 
&gt; We'll be talking about this tomorrow during the Sponsor 27 meeting
&gt; tomorrow on Tuesday 10th May @ 1500UTC in #tor-meeting. Please feel free
&gt; to come by if you wish to discuss.
&gt; 
&gt; best,
&gt; -Richard
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200316172839</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-16 17:28:39-0400</timestampReceived><subject>[tor-dev] Fwd: Upcoming Tor security releases to fix a denial-of-service issue</subject><body>

---------- Forwarded message ---------
From: Nick Mathewson &lt;nickm@torproject.org&gt;
Date: Mon, Mar 16, 2020 at 1:25 PM
Subject: Upcoming Tor security releases to fix a denial-of-service issue
To: &lt;tor-talk@lists.torproject.org&gt;


Hello!

Some time this week, we currently plan to put out a set of security
updates for all supported versions of Tor.  These releases will fix a
pair of denial-of-service bugs: one that we are classifying at "low"
severity, and one that we are classifying at "high" severity.

Our recommendation will be for everybody, including relays and
clients, to upgrade once packages are available for their platforms.
Although these vulnerabilities are "only" denial-of-service issues,
any denial-of-service attack against Tor could be leveraged by an
attacker to aid in a traffic analysis attack.

To the best of our knowledge, these vulnerabilities are not being
exploited in the wild.

Currently supported release series are 0.3.5, 0.4.1, 0.4.2, and 0.4.3
(alpha).  If you have not yet upgraded to one of those, the time to do
so is soon.

For our policy and process for handing security issues, please see:
https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/SecurityPolicy

best wishes,
--
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200316184719</emailId><senderName>Ryan Duff</senderName><senderEmail>ry@nduff.com</senderEmail><timestampReceived>2020-03-16 18:47:19-0400</timestampReceived><subject>Re: [tor-dev] Request to provide code for Padding in Tor</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Divya,

Have you seen this yet? -
https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md

I suspect it would be substantially beneficial to your research.

-Ryan
@flyryan

On Mon, Mar 16, 2020 at 2:30 PM DIVYA GUPTA &lt;2016ucp1472@mnit.ac.in&gt; wrote:

&gt; Hello,
&gt;
&gt; We are under-graduate students from Malaviya National Institute of
&gt; Technology currently pursuing Computer Science &amp; Engineering.
&gt;
&gt; We are working on developing a defense for Tor against Website
&gt; Fingerprinting Attacks. While reading about tor we came across padding
&gt; which is implemented in Tor. It would be great if you could make available
&gt; the code for the padding.
&gt;
&gt; Regards,
&gt; Divya.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;Hi Divya,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Have you seen this yet? -  \
&lt;a href="https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevel \
opment.md"&gt;https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I \
suspect it would be substantially beneficial to your \
research.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;-Ryan&lt;/div&gt;&lt;div&gt;@flyryan&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Mon, Mar 16, 2020 at 2:30 PM \
DIVYA GUPTA &lt;&lt;a href="mailto:2016ucp1472@mnit.ac.in"&gt;2016ucp1472@mnit.ac.in&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div \
dir="ltr"&gt;Hello,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We are under-graduate students from Malaviya \
National Institute of Technology currently pursuing Computer Science &amp; \
Engineering.&lt;/div&gt;&lt;div&gt;  &lt;/div&gt;&lt;div&gt;We are working on developing a defense for Tor \
against Website Fingerprinting Attacks. While reading about tor we came across \
padding which is implemented in Tor. It would be great if you could make available \
the code for the padding.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Divya.&lt;/div&gt;&lt;/div&gt;
 _______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200316222949</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-16 22:29:49-0400</timestampReceived><subject>[tor-dev] Auto close old tor GitHub pull requests?</subject><body>

Hi all,

I'd like to use a GitHub bot to automatically close old tor and
torspec pull requests.

The Network Team currently uses GitHub to review pull requests
(but we use Trac for task tracking).

Some GitHub users won't contribute to a project with lots of open
pull requests, because they think it's been abandoned. (Or they
think we're bad at merging PRs.)

But lots of our PRs get left open because we've squashed and
merged the PR, and GitHub doesn't recognise the squashed
commits, so GitHub doesn't auto-close the PR.

I'm proposing closing PRs with no activity for 60 days, but I
think anywhere between 30 and 180 days would work.
(Most of our backports happen within 60 days.)

For more details, see:
https://trac.torproject.org/projects/tor/ticket/33629

T

-- 
teor
----------------------------------------------------------------------

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200309201001</emailId><senderName>Richard Pospesel</senderName><senderEmail>richard@torproject.org</senderEmail><timestampReceived>2020-03-09 20:10:01-0400</timestampReceived><subject>[tor-dev] SOOC (Same Origin Onion Certificates) discussion tomorrow</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi Everyone,

The current UX situation around HTTPS-enabled onionsites is not the
best: Tor Browser shows security warning splash screens and icons in
scenarios that do not warrant them. On top of that, the only way for
your onion site to not show these warnings is by getting an EV cert
which is only practical if you have the $$$.

alecmuffet's SOOC proposal (
https://github.com/alecmuffett/onion-dv-certificate-proposal/blob/master/=
text/draft-muffett-same-origin-onion-certificates.txt
) does seem to fix these UX problems for us. Though the proposal is
still incomplete, we can make forward progress with a prototype
implementation as the certificate specification is fully fleshed out.

We'll be talking about this tomorrow during the Sponsor 27 meeting
tomorrow on Tuesday 10th May @ 1500UTC in #tor-meeting. Please feel free
to come by if you wish to discuss.

best,
-Richard


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200316111731</emailId><senderName>DIVYA GUPTA</senderName><senderEmail>2016ucp1472@mnit.ac.in</senderEmail><timestampReceived>2020-03-16 11:17:31-0400</timestampReceived><subject>[tor-dev] Request to provide code for Padding in Tor</subject><body>

[Attachment #2 (multipart/alternative)]


Hello,

We are under-graduate students from Malaviya National Institute of
Technology currently pursuing Computer Science &amp; Engineering.

We are working on developing a defense for Tor against Website
Fingerprinting Attacks. While reading about tor we came across padding
which is implemented in Tor. It would be great if you could make available
the code for the padding.

Regards,
Divya.

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We are under-graduate students from Malaviya \
National Institute of Technology currently pursuing Computer Science &amp; \
Engineering.&lt;/div&gt;&lt;div&gt;  &lt;/div&gt;&lt;div&gt;We are working on developing a defense for Tor \
against Website Fingerprinting Attacks. While reading about tor we came across \
padding which is implemented in Tor. It would be great if you could make available \
the code for the padding.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Divya.&lt;/div&gt;&lt;/div&gt;



[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200321063714</emailId><senderName>Sanjiban Sengupta</senderName><senderEmail>b518041@iiit-bh.ac.in</senderEmail><timestampReceived>2020-03-21 06:37:14-0400</timestampReceived><subject>Re: [tor-dev] GSOC'20</subject><body>

[Attachment #2 (multipart/alternative)]


Dear Sir,

This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT
Bhubaneswar, India, would like to contribute to Tor Project for GSoC'20, I
have practical and working knowledge of C, C++, Python and Java, for web, I
am familiar with HTML, CSS, JS, Bootstrap and frameworks such as ReactJS
and NodeJS, also i am acquainted with concepts of ML and AI, Linux Kernel
and know the technicalities to apply these to solve modern real life
problems.

On going through the project proposals, I found the projectImplementing
Salmon as a bridge distribution mechanism, and Tor Weather interesting to
work upon and contribute and thus will be thankful for your kind guidance.

Thus I request the mentors to kindly guide me for the beginning processes.

Regards,
Sanjiban Sengupta



On Sat, Mar 21, 2020 at 11:47 AM Sanjiban Sengupta &lt;b518041@iiit-bh.ac.in&gt;
wrote:

&gt; Dear Sir,
&gt;
&gt; This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT
&gt; Bhubaneswar, India, would like to contribute to Tor Project for GSoC'20, I
&gt; have practical and working knowledge of C, C++, Python and Java, for web, I
&gt; am familiar with HTML, CSS, JS, Bootstrap and frameworks such as ReactJS
&gt; and NodeJS, also i am acquainted with concepts of ML and AI, Linux Kernel
&gt; and know the technicalities to apply these to solve modern real life
&gt; problems.
&gt;
&gt; On going through the project proposals, I found the projectImplementing
&gt; Salmon as a bridge distribution mechanism, and Tor Weather interesting to
&gt; work upon and contribute and thus will be thankful for your kind guidance.
&gt;
&gt; Thus I request the mentors to kindly guide me for the beginning processes.
&gt;
&gt; Regards,
&gt; Sanjiban Sengupta
&gt;
&gt;
&gt;
&gt; On Sat, Mar 21, 2020 at 3:50 AM Sanjiban Sengupta &lt;b518041@iiit-bh.ac.in&gt;
&gt; wrote:
&gt;
&gt;&gt; Dear Sir,
&gt;&gt;
&gt;&gt; This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT
&gt;&gt; Bhubaneswar, India, would like to contribute to Tor Project for GSoC'20, I
&gt;&gt; have practical and working knowledge of C, C++, Python and Java, for web, I
&gt;&gt; am familiar with HTML, CSS, JS, Bootstrap and frameworks such as ReactJS
&gt;&gt; and NodeJS, also i am acquainted with concepts of ML and AI, Linux Kernel
&gt;&gt; and know the technicalities to apply these to solve modern real life
&gt;&gt; problems.
&gt;&gt;
&gt;&gt; On going through the project proposals, I found the projectImplementing
&gt;&gt; Salmon as a bridge distribution mechanism, and Tor Weather interesting to
&gt;&gt; work upon and contribute and thus will be thankful for your kind guidance.
&gt;&gt;
&gt;&gt; Thus I request the mentors to kindly guide me for the beginning processes.
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt; Sanjiban Sengupta
&gt;&gt;
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;div&gt;Dear \
Sir,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is Sanjiban Sengupta,  sophomore in Computer \
Engineering from IIIT Bhubaneswar, India, would  like to contribute to Tor Project \
for GSoC'20, I have practical and working  knowledge of C, C++, Python and Java, \
for web, I am familiar with HTML,  CSS, JS, Bootstrap and frameworks such as ReactJS \
and NodeJS, also i am  acquainted with concepts of ML and AI, Linux Kernel and know \
the technicalities to  apply these to solve modern real life \
problems.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;On  going through the project proposals, I \
found the projectImplementing  Salmon as a bridge distribution mechanism, and Tor \
Weather interesting  to work upon and 
contribute and thus will be thankful for your kind \
guidance.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thus I request the mentors to kindly guide me for \
the beginning processes.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Sanjiban \
Sengupta&lt;div class="gmail-adL"&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Sat, Mar 21, 2020 at 11:47 \
AM Sanjiban Sengupta &lt;&lt;a \
href="mailto:b518041@iiit-bh.ac.in"&gt;b518041@iiit-bh.ac.in&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="ltr"&gt;&lt;div \
dir="ltr"&gt;&lt;div&gt;Dear Sir,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is Sanjiban Sengupta,  \
sophomore in Computer Engineering from IIIT Bhubaneswar, India, would  like to \
contribute to Tor Project for GSoC'20, I have practical and working  knowledge of \
C, C++, Python and Java, for web, I am familiar with HTML,  CSS, JS, Bootstrap and \
frameworks such as ReactJS and NodeJS, also i am  acquainted with concepts of ML and \
AI, Linux Kernel and know the technicalities to  apply these to solve modern real \
life problems.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;On  going through the project proposals, \
I found the projectImplementing  Salmon as a bridge distribution mechanism, and Tor \
Weather interesting  to work upon and 
contribute and thus will be thankful for your kind \
guidance.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thus I request the mentors to kindly guide me for \
the beginning processes.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Sanjiban \
Sengupta&lt;div&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Sat, Mar 21, 2020 at 3:50 AM Sanjiban Sengupta &lt;&lt;a \
href="mailto:b518041@iiit-bh.ac.in" target="_blank"&gt;b518041@iiit-bh.ac.in&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div \
dir="ltr"&gt;&lt;div&gt;Dear Sir,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This is Sanjiban Sengupta,  \
sophomore in Computer Engineering from IIIT Bhubaneswar, India, would  like to \
contribute to Tor Project for GSoC'20, I have practical and working  knowledge of \
C, C++, Python and Java, for web, I am familiar with HTML,  CSS, JS, Bootstrap and \
frameworks such as ReactJS and NodeJS, also i am  acquainted with concepts of ML and \
AI, Linux Kernel and know the technicalities to  apply these to solve modern real \
life problems.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;On going through the project proposals, \
I found the projectImplementing Salmon as a bridge distribution mechanism, and Tor \
Weather interesting to work upon and  contribute and thus will be thankful for your \
kind guidance.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thus I request the mentors to kindly guide me \
for the beginning processes.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Sanjiban \
Sengupta&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; &lt;/blockquote&gt;&lt;/div&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200320105141</emailId><senderName>anonym</senderName><senderEmail>anonym@riseup.net</senderEmail><timestampReceived>2020-03-20 10:51:41-0400</timestampReceived><subject>[tor-dev] Tails vs the capacity of the Meek bridges</subject><body>

Hi,

tl;dr: if Tails makes it too easy to use Meek bridges, could it overload the current \
set of Meek bridges?

First some background: during startup Tails can be told to start Tor Launcher so \
users can e.g. configure any bridges they want. So far we have not provided any \
pre-configured bridges, i.e. the only option has been to manually enter the bridge \
information you have obtained yourself.

In Tails' threat model it is assumed that adversaries monitor the default bridges \
provided by the Tor Browser, and that our users want to avoid detection of that, so \
we are not interested in adding the default bridges to Tails, but we are interested \
in adding support for Meek [1] (at least because it's the only PT that works in \
China), since our understanding is that it adds enough plausible deniability to avoid \
the above problem. So, in summary, Tails would like to provide two options in its \
(patched) Tor Launcher, Meek or manually providing the bridge info. [2]

However, we wonder if the combination of not providing the default bridges while \
making Meek available could overwhelm the Meek bridges; we expect some significant \
amount of Tails bridge users to select the Meek option over manual entry simply out \
of convenience.

Let's do some back-of-the-envelope estimations to see what we can expect:

(Assumption: Tor Browser users and Tails users are very similar, e.g. similar ratios \
want to use each PT, similar requirements for "convenience over security", and so \
on.)

Looking at your metrics, there are 1000k daily Tor Browser users [3], overall \
bridge/PT usage is 50k [4], Meek usage is around 10k [5], so 5% of Tor Browser users \
use bridges/PTs, and 1% use Meek. On the Tails side, we measure around 30k daily \
users (from update pings).

From what I said above, I don't think we can expect only 1% of the Tails users to \
pick Meek; I would expect it to be closer to the 1% of Meek users plus the x% of \
default bridge users, but I couldn't find stats for that in your metrics. Still, we \
know that it cannot be more than the percentage of all bridge/PT users, so we know \
that 1% + x% &lt;= 5%. So, let's just assume the worst case, that 5% of Tails users will \
use Meek, and we have that we expect 5% of 30k = 1.5k additional Meek users.

Also, if we consider places where Meek is the only options, Tails probably has close \
to zero users there, but once Meek is supported it could grow. I guess China is the \
only such place (?), so with its 1250 Meek users in China [6] we can expect 1250 * \
30k/1000k = 34 new Tails users using Meek. Basically a negligible amount. Even if we \
consider all Meek users, 10k * 30k/1000k = 300 doesn't change much.

So, all-in-all, we can expect Tails to bring up to 1.5k + 300 = 1.8k new Meek users, \
but since those are upper-bound estimations it would probably be much lower. Looking \
on Meek usage over time, it seems to fluctuate way more than that, e.g. during the \
summer of 2019 it was up to over 25k, i.e. more than three times what it is now. So I \
guess we don't have to worry about shocking the Meek bridges?

OTOH, a possible side-effect is that this change in Tails increases usage of Meek \
outside of China. Perhaps whoever pays the bills for the Meek instances don't want \
this?

Please advice! Also, please let us know if there is something else we haven't thought \
of!

Cheers!

[1] https://redmine.tails.boum.org/code/issues/8243
[2] If you are really interested you can check out our PoC/WIP here: \
https://nightly.tails.boum.org/build_Tails_ISO_feature-8243-meek/builds/lastSuccessfulBuild/archive/build-artifacts/
 [3] https://metrics.torproject.org/webstats-tb.html
[4] https://metrics.torproject.org/userstats-bridge-transport.html
[5] https://metrics.torproject.org/userstats-bridge-transport.html?transport=!%3COR%3E&amp;transport=meek
 [6] https://metrics.torproject.org/userstats-bridge-combined.html?start=2019-12-21&amp;end=2020-03-20&amp;country=cn
 _______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200324022610</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2020-03-24 02:26:10-0400</timestampReceived><subject>Re: [tor-dev] Tails vs the capacity of the Meek bridges</subject><body>

On Fri, Mar 20, 2020 at 11:51:41AM +0100, anonym wrote:
&gt; tl;dr: if Tails makes it too easy to use Meek bridges, could it overload the \
&gt; current set of Meek bridges?

The default meek bridge is already overloaded, unfortunately. Users
complain that even though it works, it is too slow. Reports of 20 KB/s
are typical. See for example this recent comment from China:
https://bugs.torproject.org/33219#comment:9
&gt; ...with the pre integrated meek bridges I just had 20 kb/s, at most
&gt; 30, sometimes even lower than 20. So it took me over one hour to
&gt; download the browser.

Here's the brandwidth chart for the default meek bridge btw. I would
guess that the bridge is capable of going faster, but it may have a
BandwidthRate set to keep costs from getting out of control.
https://metrics.torproject.org/rs.html#details/8F4541EEE3F2306B7B9FEF1795EC302F6B84DAE8


It's possible to set up a special bridge just for Tails users. It
requires setting up a bridge with meek-server (this is the cheap part)
and configuring a CDN to point to it (this is the expensive part). But
then you can let it run as fast as your budget allows.
https://trac.torproject.org/projects/tor/wiki/doc/meek#MicrosoftAzure
https://trac.torproject.org/projects/tor/wiki/doc/meek#Howtorunameek-serverbridge
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200323082947</emailId><senderName>Pili Guerra</senderName><senderEmail>pili@torproject.org</senderEmail><timestampReceived>2020-03-23 08:29:47-0400</timestampReceived><subject>Re: [tor-dev] GSOC'20</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/alternative)]


Hi Sanjiban,

(Moving tor-dev mailing list to bcc as we don't need to continue this conversation on \
the mailing list.)

Thank you for your interest in contributing to Tor for GSoC 2020.

I would recommend you start off by reading the "Getting Started" sections for these \
projects and following the steps outlined there. Fee free to get back in touch if you \
get stuck.

You may also find it quicker to contact us on irc[1].

Good luck!

Pili

[1] https://trac.torproject.org/projects/tor/wiki/org/onboarding/IRC \
&lt;https://trac.torproject.org/projects/tor/wiki/org/onboarding/IRC&gt; 
Project Manager: Tor Browser, UX and Community teams
pili at torproject dot org
gpg 3E7F A89E 2459 B6CC A62F 56B8 C6CB 772E F096 9C45

&gt; On 21 Mar 2020, at 06:25, Sanjiban Sengupta &lt;b518041@iiit-bh.ac.in&gt; wrote:
&gt; 
&gt; Dear Sir,
&gt; 
&gt; This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT Bhubaneswar, \
&gt; India, would like to contribute to Tor Project for GSoC'20, I have practical and \
&gt; working knowledge of C, C++, Python and Java, for web, I am familiar with HTML, \
&gt; CSS, JS, Bootstrap and frameworks such as ReactJS and NodeJS, also i am acquainted \
&gt; with concepts of ML and AI, Linux Kernel and know the technicalities to apply these \
&gt; to solve modern real life problems. 
&gt; On going through the project proposals, I found the projectImplementing Salmon as a \
&gt; bridge distribution mechanism, and Tor Weather interesting to work upon and \
&gt; contribute and thus will be thankful for your kind guidance. 
&gt; Thus I request the mentors to kindly guide me for the beginning processes.
&gt; 
&gt; Regards,
&gt; Sanjiban Sengupta
&gt; 
&gt; 
&gt; 
&gt; On Sat, Mar 21, 2020 at 11:47 AM Sanjiban Sengupta &lt;b518041@iiit-bh.ac.in \
&gt; &lt;mailto:b518041@iiit-bh.ac.in&gt;&gt; wrote: Dear Sir,
&gt; 
&gt; This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT Bhubaneswar, \
&gt; India, would like to contribute to Tor Project for GSoC'20, I have practical and \
&gt; working knowledge of C, C++, Python and Java, for web, I am familiar with HTML, \
&gt; CSS, JS, Bootstrap and frameworks such as ReactJS and NodeJS, also i am acquainted \
&gt; with concepts of ML and AI, Linux Kernel and know the technicalities to apply these \
&gt; to solve modern real life problems. 
&gt; On going through the project proposals, I found the projectImplementing Salmon as a \
&gt; bridge distribution mechanism, and Tor Weather interesting to work upon and \
&gt; contribute and thus will be thankful for your kind guidance. 
&gt; Thus I request the mentors to kindly guide me for the beginning processes.
&gt; 
&gt; Regards,
&gt; Sanjiban Sengupta
&gt; 
&gt; 
&gt; 
&gt; On Sat, Mar 21, 2020 at 3:50 AM Sanjiban Sengupta &lt;b518041@iiit-bh.ac.in \
&gt; &lt;mailto:b518041@iiit-bh.ac.in&gt;&gt; wrote: Dear Sir,
&gt; 
&gt; This is Sanjiban Sengupta, sophomore in Computer Engineering from IIIT Bhubaneswar, \
&gt; India, would like to contribute to Tor Project for GSoC'20, I have practical and \
&gt; working knowledge of C, C++, Python and Java, for web, I am familiar with HTML, \
&gt; CSS, JS, Bootstrap and frameworks such as ReactJS and NodeJS, also i am acquainted \
&gt; with concepts of ML and AI, Linux Kernel and know the technicalities to apply these \
&gt; to solve modern real life problems. 
&gt; On going through the project proposals, I found the projectImplementing Salmon as a \
&gt; bridge distribution mechanism, and Tor Weather interesting to work upon and \
&gt; contribute and thus will be thankful for your kind guidance. 
&gt; Thus I request the mentors to kindly guide me for the beginning processes.
&gt; 
&gt; Regards,
&gt; Sanjiban Sengupta
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


[Attachment #7 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;Hi Sanjiban,&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;(Moving tor-dev mailing list to bcc as we don't need to \
continue this conversation on the mailing list.)&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thank you for your interest in contributing to Tor for \
GSoC 2020.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I would recommend you \
start off by reading the "Getting Started" sections for these projects and following \
the steps outlined there. Fee free to get back in touch if you get \
stuck.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;You may also find it \
quicker to contact us on irc[1].&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Good luck!&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Pili&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;[1]&lt;a \
href="https://trac.torproject.org/projects/tor/wiki/org/onboarding/IRC" \
class=""&gt;https://trac.torproject.org/projects/tor/wiki/org/onboarding/IRC&lt;/a&gt;&lt;br \
class=""&gt;&lt;div class=""&gt;&lt;div class=""&gt; &lt;div style="caret-color: rgb(0, 0, 0); color: \
rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; \
font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: \
auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; \
widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; \
-webkit-text-stroke-width: 0px; text-decoration: none;"&gt;&lt;br class=""&gt;Project \
Manager: Tor Browser, UXand Community teams&lt;br class=""&gt;pili at torproject dot \
org&lt;br class=""&gt;gpg3E7F A89E 2459 B6CC A62F56B8 C6CB 772E F096 \
9C45&lt;/div&gt; &lt;/div&gt;
&lt;div&gt;&lt;br class=""&gt;&lt;blockquote type="cite" class=""&gt;&lt;div class=""&gt;On 21 Mar 2020, at \
06:25, Sanjiban Sengupta &lt;&lt;a href="mailto:b518041@iiit-bh.ac.in" \
class=""&gt;b518041@iiit-bh.ac.in&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br \
class="Apple-interchange-newline"&gt;&lt;div class=""&gt;&lt;div dir="ltr" class=""&gt;&lt;div \
dir="ltr" class=""&gt;&lt;div dir="ltr" class=""&gt;&lt;div class=""&gt;Dear Sir,&lt;/div&gt;&lt;div \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;This is Sanjiban Sengupta,  sophomore in \
Computer Engineering from IIIT Bhubaneswar, India, would  like to contribute to Tor \
Project for GSoC'20, I have practical and working  knowledge of C, C++, Python and \
Java, for web, I am familiar with HTML,  CSS, JS, Bootstrap and frameworks such as \
ReactJS and NodeJS, also i am  acquainted with concepts of ML and AI, Linux Kernel \
and know the technicalities to  apply these to solve modern real life \
problems.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;div class=""&gt;On  going \
through the project proposals, I found the projectImplementing  Salmon as a bridge \
distribution mechanism, and Tor Weather interesting  to work upon and 
contribute and thus will be thankful for your kind guidance.&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thus I request the mentors to kindly guide me for the \
beginning processes.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Regards,&lt;/div&gt;&lt;div class=""&gt;Sanjiban Sengupta&lt;div class="gmail-adL"&gt;&lt;br \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Sat, Mar 21, 2020 at 11:47 \
AM Sanjiban Sengupta &lt;&lt;a href="mailto:b518041@iiit-bh.ac.in" \
class=""&gt;b518041@iiit-bh.ac.in&lt;/a&gt;&gt; wrote:&lt;br class=""&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="ltr" class=""&gt;&lt;div dir="ltr" \
class=""&gt;&lt;div class=""&gt;Dear Sir,&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;This is Sanjiban Sengupta,  sophomore in Computer Engineering from IIIT \
Bhubaneswar, India, would  like to contribute to Tor Project for GSoC'20, I have \
practical and working  knowledge of C, C++, Python and Java, for web, I am familiar \
with HTML,  CSS, JS, Bootstrap and frameworks such as ReactJS and NodeJS, also i am
 acquainted with concepts of ML and AI, Linux Kernel and know the technicalities to 
apply these to solve modern real life problems.&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;div class=""&gt;On  going through the project proposals, I \
found the projectImplementing  Salmon as a bridge distribution mechanism, and Tor \
Weather interesting  to work upon and 
contribute and thus will be thankful for your kind guidance.&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thus I request the mentors to kindly guide me for the \
beginning processes.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Regards,&lt;/div&gt;&lt;div class=""&gt;Sanjiban Sengupta&lt;div class=""&gt;&lt;br class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Sat, Mar 21, 2020 at 3:50 AM Sanjiban Sengupta &lt;&lt;a \
href="mailto:b518041@iiit-bh.ac.in" target="_blank" \
class=""&gt;b518041@iiit-bh.ac.in&lt;/a&gt;&gt; wrote:&lt;br class=""&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="ltr" class=""&gt;&lt;div class=""&gt;Dear \
Sir,&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;This is Sanjiban Sengupta,  \
sophomore in Computer Engineering from IIIT Bhubaneswar, India, would  like to \
contribute to Tor Project for GSoC'20, I have practical and working  knowledge of C, \
C++, Python and Java, for web, I am familiar with HTML,  CSS, JS, Bootstrap and \
frameworks such as ReactJS and NodeJS, also i am  acquainted with concepts of ML and \
AI, Linux Kernel and know the technicalities to  apply these to solve modern real \
life problems.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;div class=""&gt;On \
going through the project proposals, I found the projectImplementing Salmon as a \
bridge distribution mechanism, and Tor Weather interesting to work upon and  \
contribute and thus will be thankful for your kind guidance.&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thus I request the mentors to kindly guide me for the \
beginning processes.&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Regards,&lt;/div&gt;&lt;div class=""&gt;Sanjiban Sengupta&lt;br class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; \
&lt;/blockquote&gt;&lt;/div&gt; &lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;
_______________________________________________&lt;br class=""&gt;tor-dev mailing list&lt;br \
class=""&gt;&lt;a href="mailto:tor-dev@lists.torproject.org" \
class=""&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br \
class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;br \
class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEPn+oniRZtsymL1a4xst3LvCWnEUFAl54c3cACgkQxst3LvCW
nEWOIA/+OMAOhTVndR0UMdwiSUBn+i9wnqt4/2YlL9glfRpYS1Ya9nxGM9d5ddUp
xhmHgaE2RfNd4fUsbu7DbEQQp9UZ+fQWEwb4onEtpkZuaLpa6pYdp9hNMTTLedkj
lCJvQ4o768KL4Xbz15otMY2dUjFCo0Xhqf1MI3vnxkOSli0dI01/Euzr7QpYh/pF
bn2aG/wxzSknVgNwd3MSYBSNGF9VToXZ4wM59dcGmJ+BFaI6V1XwHtIkV43Ad0Hd
NeKDzBf7YWn4SxYqn/ILWIrq1846W/s7t8bMwdo5YDtCN8+qzP7yKyG2XpTx1zCS
T43uSt/WSVZGvotJ5NFa9KSIRwsvHQ71/GLHpnv7JV0wHcC5NFuu/Zb9pT9DtmJ8
Kdr1STO3CyZajcrdAPx2hyVssJNCUS3vBPxhiVy4Ag9TxyRMvY2UCrpibMb/xxBk
JrUA3iR6jYNcpfUzL2u9W1ZhqpFSmE8IW12i89pGcMiJzz0smqjkAxfhf5wcsn/A
KYTzhsPsFslDbM0GllQfAk5FV5URMm2w2mkaPrI2ChX/AaIgQyUEeIyGvzNEHk7g
7iOQ+Bf7lUklRDVLaQjXdPdxsu4YyUnLEDf9UfoGoVf0d47Rj0CZbpxaaxa4o79P
HWxVMesiUwNBxuSaclFrj79rtY184CKUwj6eU9RkZ0vFElid18I=
=Y1hg
-----END PGP SIGNATURE-----

[Attachment #9 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200324112033</emailId><senderName>anonym</senderName><senderEmail>anonym@riseup.net</senderEmail><timestampReceived>2020-03-24 11:20:33-0400</timestampReceived><subject>Re: [tor-dev] Tails vs the capacity of the Meek bridges</subject><body>

David Fifield:
&gt; On Fri, Mar 20, 2020 at 11:51:41AM +0100, anonym wrote:
&gt; &gt; tl;dr: if Tails makes it too easy to use Meek bridges, could it overload the \
&gt; &gt; current set of Meek bridges?
&gt; 
&gt; The default meek bridge is already overloaded, unfortunately.

Ack. Tails will then *not* add Meek support until it also provides another equally \
convenient option, like default bridges (unlikely) and/or Moat, so the situation is \
the same as in Tor Browser.

&gt; It's possible to set up a special bridge just for Tails users. It
&gt; requires setting up a bridge with meek-server (this is the cheap part)
&gt; and configuring a CDN to point to it (this is the expensive part). But
&gt; then you can let it run as fast as your budget allows.

I doubt we can afford that. At best it could be part of some future grant to make \
Tails usable in China, or similar.

Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200320153000</emailId><senderName>sajolida</senderName><senderEmail>sajolida@pimienta.org</senderEmail><timestampReceived>2020-03-20 15:30:00-0400</timestampReceived><subject>Re: [tor-dev] [Tails-dev] Tails vs the capacity of the Meek bridges</subject><body>

anonym:
&gt; In Tails' threat model it is assumed that adversaries monitor the default bridges \
&gt; provided by the Tor Browser, and that our users want to avoid detection of that, so \
&gt; we are not interested in adding the default bridges to Tails

We're not offering the default bridges in Tails also because it's
impossible right now to store your bridge configuration in the
Persistent Storage.

We're afraid that this would lead to more people relying on the default
bridges in Tails than in Tor Browser, where you can configure your
custom bridges once and for all.

It's also currently easier to get custom bridges from Tor Browser
outside of Tails than inside Tails.

-- 
sajolida
Tails  https://tails.boum.org/
UX   Fundraising   Technical Writing
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200324105656</emailId><senderName>Iain Learmonth</senderName><senderEmail>irl@torproject.org</senderEmail><timestampReceived>2020-03-24 10:56:56-0400</timestampReceived><subject>Re: [tor-dev] [Tails-dev] Tails vs the capacity of the Meek bridges</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

On 20/03/2020 15:30, sajolida wrote:
&gt; &gt; In Tails' threat model it is assumed that adversaries monitor the default bridges \
&gt; &gt; provided by the Tor Browser, and that our users want to avoid detection of that, \
&gt; &gt; so we are not interested in adding the default bridges to Tails
&gt; 
&gt; We're not offering the default bridges in Tails also because it's
&gt; impossible right now to store your bridge configuration in the
&gt; Persistent Storage.

Maybe I've overlooked something obvious, but could you use Moat?

https://gitweb.torproject.org/bridgedb.git/tree/README.rst#n391

This would use meek to fetch the bridges, but then you have non-default
bridges for the rest of the session. It can be automated as part of the
Tor start-up, but you do need to solve a CAPTCHA.

Thanks,
Iain.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200324112823</emailId><senderName>anonym</senderName><senderEmail>anonym@riseup.net</senderEmail><timestampReceived>2020-03-24 11:28:23-0400</timestampReceived><subject>Re: [tor-dev] [Tails-dev] Tails vs the capacity of the Meek bridges</subject><body>

Iain Learmonth:
&gt; Hi,
&gt; 
&gt; On 20/03/2020 15:30, sajolida wrote:
&gt; &gt; &gt; In Tails' threat model it is assumed that adversaries monitor the default \
&gt; &gt; &gt; bridges provided by the Tor Browser, and that our users want to avoid detection \
&gt; &gt; &gt; of that, so we are not interested in adding the default bridges to Tails
&gt; &gt; 
&gt; &gt; We're not offering the default bridges in Tails also because it's
&gt; &gt; impossible right now to store your bridge configuration in the
&gt; &gt; Persistent Storage.
&gt; 
&gt; Maybe I've overlooked something obvious, but could you use Moat?
&gt; 
&gt; https://gitweb.torproject.org/bridgedb.git/tree/README.rst#n391
&gt; 
&gt; This would use meek to fetch the bridges, but then you have non-default
&gt; bridges for the rest of the session. It can be automated as part of the
&gt; Tor start-up, but you do need to solve a CAPTCHA.

Nothing is preventing us except more work. :) Essentially, Tails only allows the tor \
process to talk clearnet as part of its Tor enforcement [1], which makes this a bit \
trickier than in less locked down environments that Tor Launcher is designed to run \
from. But it indeed looks like also adding Moat support (and making it the default, I \
think) is the way for us to go, so thanks for the reminder! :)

Cheers!

[1] https://tails.boum.org/contribute/design/Tor_enforcement/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200313175137</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-13 17:51:37-0400</timestampReceived><subject>[tor-dev] Walking Onions status update: week 2 notes</subject><body>

Walking onions -- week 2 update

Hi!  On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send these out thee updates once a week, in case anybody is interested.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

You might like to have a look at that update, and its references,
if this update doesn't make sense to you.

===

This week, I worked specifying the nitty-gritty of the SNIP and
ENDIVE document formats.  I used the CBOR meta-format [CBOR] to
build them, and the CDDL specification language [CDDL] to specify
what they should contain.

As before, I've been working in a git repository at [GITHUB]; you
can see the document I've been focusing on this week at
[SNIPFMT].  (That's the thing to read if you want to send me
patches for my grammar.)

There were a few neat things to do here:

   * I had to define SNIPs so that clients and relays can be
     mostly agnostic about whether we're using a merkle tree or a
     bunch of signatures.

   * I had to define a binary diff format so that relays can keep
     on downloading diffs between ENDIVE documents. (Clients don't
     download ENDIVEs).  I did a quick prototype of how to output
     this format, using python's difflib.

   * To make ENDIVE diffs as efficient as possible, it's important
     not to transmit data that changes in every ENDIVE.  To this
     end, I've specified ENDIVEs so that the most volatile parts
     (Merkle trees and index ranges) are recomputed on the relay
     side.  I still need to specify how these re-computations work,
     but I'm pretty sure I got the formats right.

     Doing this calculation should save relays a bunch of
     bandwidth each hour, but cost some implementation complexity.
     I'm going to have to come back to this choice going forward
     to see whether it's worth it.

   * Some object types are naturally extensible, some aren't.  I've
     tried to err on the size of letting us expand important
     things in the future, and using maps (key-&gt;value mappings)
     for object that are particularly important.

     In CBOR, small integers are encoded with a little less space
     than small strings.  To that end, I'm specifying the use of
     small integers for dictionary keys that need to be encoded
     briefly, and strings for non-tor and experimental extensions.

   * This is a fine opportunity to re-think how we handle document
     liveness.  Right now, consensus directories have an official
     liveness interval on them, but parties that rely on
     consensuses tolerate larger variance than is specified in the
     consensus.  Instead of that approach, the usable lifetime of
     each object is now specified in the object, and is ultimately
     controlled by the authorities.  This gives the directory
     authorities more ability to work around network tolerance
     issues.

     Having large lifetime tolerances in the context of walking
     onions is a little risky: it opens us up to an attack where
     a hostile relay holds multiple ENDIVEs, and decides which one
     to use when responding to a request.  I think we can address this
     attack, however, by making sure that SNIPs have a published
     time in them, and that this time moves monotonically forward.

   * As I work, I'm identifying other issues in tor that stand in
     the way of a good efficient walking onion implementation that
     will require other follow-up work.  This week I ran into a
     need for non-TAP-based v2 hidden services, and a need for a
     more efficient family encoding.  I'm keeping track of these
     in my outline file.

Fun fact: In number of bytes, the walking onions proposal is now
the 9th-longest proposal in the Tor proposal repository.  And it's
still growing!


Next week, I'm planning to specify ENDIVE reconstruction, circuit
extension, and maybe start on a specification for voting.


[CBOR] RFC 7049: "Concise Binary Object Representation (CBOR)"
    https://tools.ietf.org/html/rfc7049b

[CDDL] RFC 8610: "Concise Data Definition Language (CDDL): A
    Notational Convention to Express Concise Binary Object
    Representation (CBOR) and JSON Data Structures"
    https://tools.ietf.org/html/rfc8610

[GITREPO]  https://github.com/nmathewson/walking-onions-wip

[SNIPFMT] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-endives-and-snips.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200329231802</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-29 23:18:02-0400</timestampReceived><subject>[tor-dev] Walking onions status update: week 4 notes</subject><body>

Walking Onions: week 4 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

 Week 3:
   Expanding ENDIVEs into SNIPs.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014194.html


This week was pretty rough for me; the impact of being isolated at home
is starting to kick in, and my kid is still trying to find a schedule
that works for him.  I got a lot less done this week than I had planned.

That said, I _did_ get some good design done, in two areas: voting, and
circuit extension.

== Voting

I'm trying to generalize our voting algorithms to minimize the need
for new consensus formats in the future.  I want most new fields to be
self-describing in terms of how to tabulate votes for them.  Trying to
work this out has taken a bunch of energy, though and I'm not quite sure
I'm doing it right.  The work here is unfinished.

I still think it's reasonable to encode existing votes and new votes in
a new cbor-based structure.  By using compression, a little redundancy
in votes shouldn't hurt us too badly -- though that's something I need
to benchmark eventually before we build this.

I've come up with a way for voters to use diffs and compression when
_uploading_ votes: first, the voter asks for a summary of what
mechanisms are supported by the recipient and which older votes it has.
Next, the voter can use that information to upload a vote diff with an
appropriate compression format.

Right now I believe that I have most of the fields for the votes figured
out, but I need to clean them up a _lot_.  SNIP bodies can work
similarly to how microdescriptors work now, if we like -- or they could
involve individual votes on input fields.  I think I'm going to write up
what I can here, and then revisit SNIP bodies once I've worked some on
section 6 (the "fancy" client behavior).

While working on voting, I found a need for various changes in the
already written sections.  For one example, the previous description
of the ENDIVE format included the SNIP signatures as part of the
signed ENDIVE.  But we can't actually generate that as part our
voting protocol: the authorities can't sign SNIPs until they know
the complete ENDIVE contents, and so putting the SNIP signatures in
the signed part of the ENDIVE would add an extra round of voting and
signatures.  Instead, I've moved the SNIP signatures (and related
stuff) into the signature header of the ENDIVE.

I've also worked somewhat on the so-called "root document" holding
the network configuration parameters.  I'm hoping that this document
can have an effective lifetime of weeks or months for clients, and
that clients can download only the parts that they need.  The format
is in section 02, but needs more description.

The work-in-progress voting writeup is in [VOTING], but it is not so
close to done. I think it will need a lot of writing before it's
ready for even preliminary review; it doesn't make sense as it is,
and it contradicts itself in places.

== Extending circuits

There are a few wrinkles here that we hadn't actually specified in
earlier walking onions work!

When one relay is told to extending a circuit to a target relay by
index, the extending relay actually needs to include part of a SNIP for
that second relay: otherwise, the extending relay won't know which onion
key the client expects to receive for it.  We don't want to send an
entire SNIP -- only the parts that the client will expect to match.

In addition to wide EXTEND cells, we'll also need wide RENDEZVOUS and
INTRODUCE1 and INTRODUCE2 and TRUNCATED cells.  All together, that means
that having a general "cell fragmentation" mechanism is probably
warranted; I've started a separate proposal for that [WIDE_EVERYTHING].

We're going to need a general extension format for CREATE and EXTEND
cells, to signal other information, like SNIPs, requests for SNIPs, and
so on.  We also need a way to ask for SNIPs without actually performing
a handshake.  I've tried to fit these all together in a fairly logical
way in [EXTENDING], but there's more to write here, including examples.

== Fun facts

The walking onion proposal is now the second-longest that we have
ever had, behind only proposal 224 (v3 hidden services).

== Next steps

In this coming week I plan to try to wrap up section 3 on voting and
section 5 on extending circuits.  I'm going to go back to the start
of section 2 and start revising all I've written so far for
consistency.

Time permitting, I want to sketch out all the knowns and unknowns
for section 6 (on tricky client behavior).




[EXTENDING] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/05-extending-circuits.md

[VOTING]  https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-voting-and-authorities.md

[WIDE_EVERYTHING]
https://github.com/nmathewson/walking-onions-wip/blob/master/other-proposals/xxx-wide-everything.md
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200320193820</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-20 19:38:20-0400</timestampReceived><subject>[tor-dev] Walking onions status update: week 3 notes</subject><body>

Walking Onions: week 3 update

 On our current grant from the zcash foundation, I'm working on a
full specification for the Walking Onions design.  I'm going to try to
send out these updates once a week.

My previous updates are linked below:

 Week 1:
   formats, preliminaries, git repositories, binary diffs,
   metaformat decisions, and Merkle Tree trickery.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014178.html

 Week 2:
   Specifying details of SNIP and ENDIVE formats, in CDDL.

   https://lists.torproject.org/pipermail/tor-dev/2020-March/014181.html

You might like to check out those updates, and their references,
if this update doesn't make sense to you.

===

As you might recall, the SNIPs need to be nice and small, but they
need to be completely self-contained.  The ENDIVE, on the other
hand, needs to be diff-friendly, and compressible.  Relays need to
derive all the SNIPs from the ENDIVE.  The ENDIVE and SNIP formats
that I worked on during last week [SNIPFMT] was designed to meet these
criteria.

This week, I wrote up the algorithms to extract signed SNIPs from an
ENDIVE.  This is in section 4 [RECONST] of the specs in my
work-in-progress repository [GITREPO] This was mainly straightforward
consequence from the work I did last week, but there were a few
things that turned up.

One trickier aspect of this work is that we want to move most of the
decision-making to the authorities, and have the relays simply do an
expansion algorithm.  Updating all the relays would be slow, so relays
need to be able to handle new index types and data types without
fully understanding them.  That means that we need to specify an
algorithm that can work flexibly with many future kinds of data.

Another tricky aspect is that the data which the relays need to put
into SNIPs all needs to be signed, so all of that data needs to come
out the same when relays calculate it as the when the authorities
calculate it. Thus, all the algorithms for building Merkle trees and
indices and SNIPRouterData bodies need to be deterministic.

I think that I got all of this relatively right in [RECONST], but
there are probably some mistakes hiding in there.

I'm hoping that there is a cleaner alternative to the weighted-index
reconstruction algorithm -- the one that's there right now puts a
lot of requirements on the input data, in order to avoid
floating-point operations.

===

After working on ENDIVE expansion, I moved on to the problem of
authorities voting.  There's a lot of uncertainty here and decisions
I'll need to make.

The biggest decision is how the new voting process for ENDIVEs
should relate to the current voting process for consensus documents.
The choices seem to be:

   * Have two processes with different kinds of votes.
   * Expand the information that goes into current votes, and
     generate ENDIVEs as a new kind of consensus from the current
     voting process.
   * Design the ENDIVE voting process so that it can also be used to
     generate current-style consensuses.

Using separate processes might be simplest, but it does carry risk
for duplicated code, and for the two voting processes reaching
divergent results.  It would also be potentially bad if an authority
could vote differently in each process.

The second approach -- where ENDIVEs are another kind of consensus
generated from current-style voting documents -- has some charm to
it, but it perpetuates our current consensus-voting system, and
makes us specify a second encoding of CBOR objects as text, if we
want to vote on them meaningfully.  This is a bit nasty, since the
standard-specified text encoding of cbor is not a bijection, and
doesn't mesh too well with our old directory format.

Therefore the third approach seems a little better to me now.  In
it, we'd specify our votes as a CBOR-based format loosely based on
the current vote format, and describe a way to extract from them the
same data that is currently used for our voting algorithm.  This
would let us encode CBOR within the document naturally, while not
having to throw away too much of our existing voting specification
and voting code.

I've got a few more ideas here, though I don't have any specs yet.
I've been collecting the ideas in a notes file [VNOTES] so I don't
forget them.

===

While working on voting notes, I found some areas where the ENDIVE
and SNIP formats might be better.

First, I hadn't thought about authority certificates.  Those should
go in, so that we can have the ENDIVE-signing keys be signed
themselves with the authorities' long-lived identities.

Second, there seem to be some opportunities for transmitting indices
in a simpler way.  Instead of assigning a weight to each router
separately, for example, we could derive one weighted index from
another weighted index by re-weighting it, as we do with the
"bandwidth-weights" values in the current consensus.

Teor also made some good suggestions for improving the diff format;
I incorporated one and made a note to check the other.

===

I also spent a little while this week reading about BLS signatures,
since they are the leading candidate for how we might do threshold
signatures here.

===

Next week I'm going to try to get voting all specified. This will be
a pretty deep dive, since I will need to maintain some backward
compatibility with existing voting algorithms.  There may be
opportunities for simplification, however.


===

[GITREPO]  https://github.com/nmathewson/walking-onions-wip

[RECONST] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/04-reconstructing-endives.m
d

[SNIPFMT] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-endives-and-snips.md

[VNOTES] https://github.com/nmathewson/walking-onions-wip/blob/master/notes/voting.txt
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200320210852</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-20 21:08:52-0400</timestampReceived><subject>Re: [tor-dev] Walking onions status update: week 3 notes</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Nick,

&gt; On 21 Mar 2020, at 05:38, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; Walking Onions: week 3 update
&gt; 
&gt; As you might recall, the SNIPs need to be nice and small, but they
&gt; need to be completely self-contained.  The ENDIVE, on the other
&gt; hand, needs to be diff-friendly, and compressible.  Relays need to
&gt; derive all the SNIPs from the ENDIVE.  The ENDIVE and SNIP formats
&gt; that I worked on during last week [SNIPFMT] was designed to meet these
&gt; criteria.
&gt; 
&gt; This week, I wrote up the algorithms to extract signed SNIPs from an
&gt; ENDIVE.  This is in section 4 [RECONST] of the specs in my
&gt; work-in-progress repository [GITREPO] This was mainly straightforward
&gt; consequence from the work I did last week, but there were a few
&gt; things that turned up.
&gt; 
&gt; One trickier aspect of this work is that we want to move most of the
&gt; decision-making to the authorities, and have the relays simply do an
&gt; expansion algorithm.  Updating all the relays would be slow, so relays
&gt; need to be able to handle new index types and data types without
&gt; fully understanding them.  That means that we need to specify an
&gt; algorithm that can work flexibly with many future kinds of data.
&gt; 
&gt; Another tricky aspect is that the data which the relays need to put
&gt; into SNIPs all needs to be signed, so all of that data needs to come
&gt; out the same when relays calculate it as the when the authorities
&gt; calculate it. Thus, all the algorithms for building Merkle trees and
&gt; indices and SNIPRouterData bodies need to be deterministic.
&gt; 
&gt; I think that I got all of this relatively right in [RECONST], but
&gt; there are probably some mistakes hiding in there.
&gt; 
&gt; I'm hoping that there is a cleaner alternative to the weighted-index
&gt; reconstruction algorithm -- the one that's there right now puts a
&gt; lot of requirements on the input data, in order to avoid
&gt; floating-point operations.

There's a shorter encoding for Raw:

for each [i, pos1, pos2] in index_ranges:
  w = pos2 - pos1
  j  = the index of pos1 among all sorted pos1s
  new_encoding = [i, j, w]

[i, j, w] is an efficient encoding if index_ranges is sparse compared
with ENDIVERouterData, because:
* j has the same cardinality as I
* w is smaller than pos1 and pos2

If index_ranges is dense, there may be a more efficient encoding:
  add missing i with weight 0
  drop j

With this encoding, you can drop a few of the constraints.

There's a faster calculation and more efficient encoding for
Weighted, because there's a common factor in each POS()
calculation:
(1 &lt;&lt; 32) / total_weight

If we remove that factor, we end up with a much simpler algorithm,
that's also more flexible:

Algorithm: Expanding a "Weighted" indexspec.

Each weighted indexspec also has a multiplier, which may vary
between indexspecs.

Let total_weight = SUM(indexspec.index_weights)
Verify total_weight * multiplier &lt;= UINT64_MAX.

Let total_so_far = 0.
Let result_idx = {} (an empty mapping).
Define POS(b) = b * multiplier

For 0 &lt;= i &lt; LEN(indexspec.indexweights):
   Let w = indexspec.indexweights[i].
   Let lo = POS(total_so_far).
   Let total_so_far = total_so_far + w.
   Let hi = POS(total_so_far) - 1.
   Append (lo, hi) =&gt; i to result_idx.

Return result_idx.

If multiplier is large, then the weights can be quite small.
(Small weights sacrifice some accuracy.) And if the multiplier
is 1, you effectively have a "Raw" index.

If you make those changes, you should be able to use a similar
process to expand all the different index types. (After multiplying,
truncating, or hashing, you either end up with a delta, or an
absolute position. You can turn deltas into absolute positions,
and then feed them all into the same base algorithm.)

There are also a few things I think might be bugs:

Was there meant to be a constraint that the Weighted total is
UINT64_MAX? Or close to UINT64_MAX?
The fixed parameters don't make much sense otherwise.

I think v2 and v3 onion services assign descriptors to the next
highest HSDir RSA id (or ed25519 hash). But
INDEX_FROM_RING_KEYS() uses the relay input as the lowest value.

There is no next member for the last member in
INDEX_FROM_RING_KEYS(), but the code asks for one.
(Perhaps there are some typos here that make the code hard to
understand.)

We'll need special treatment for ring wrapping. (That is, 0xFF is not
a real upper limit, it actually means, "use the lowest relay".)

It's weird to call a middle value a "suffix", but "infix" is also a bit of an
unusual word.

There are also a bunch of typos, let me know when you're ready for
copy-editing.

T
[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div dir="ltr"&gt;Hi Nick,&lt;/div&gt;&lt;div \
dir="ltr"&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;On 21 Mar 2020, at 05:38, Nick Mathewson \
&lt;nickm@torproject.org&gt; wrote:&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;span&gt;Walking Onions: week 3 \
update&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;As you might recall, the SNIPs need to be \
nice and small, but they&lt;/span&gt;&lt;br&gt;&lt;span&gt;need to be completely self-contained. \
The ENDIVE, on the other&lt;/span&gt;&lt;br&gt;&lt;span&gt;hand, needs to be diff-friendly, and \
compressible. Relays need to&lt;/span&gt;&lt;br&gt;&lt;span&gt;derive all the SNIPs from the \
ENDIVE. The ENDIVE and SNIP formats&lt;/span&gt;&lt;br&gt;&lt;span&gt;that I worked on during \
last week [SNIPFMT] was designed to meet \
these&lt;/span&gt;&lt;br&gt;&lt;span&gt;criteria.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;This week, I wrote \
up the algorithms to extract signed SNIPs from an&lt;/span&gt;&lt;br&gt;&lt;span&gt;ENDIVE. This \
is in section 4 [RECONST] of the specs in my&lt;/span&gt;&lt;br&gt;&lt;span&gt;work-in-progress \
repository [GITREPO] This was mainly straightforward&lt;/span&gt;&lt;br&gt;&lt;span&gt;consequence from \
the work I did last week, but there were a few&lt;/span&gt;&lt;br&gt;&lt;span&gt;things that turned \
up.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;One trickier aspect of this work is that we want \
to move most of the&lt;/span&gt;&lt;br&gt;&lt;span&gt;decision-making to the authorities, and have the \
relays simply do an&lt;/span&gt;&lt;br&gt;&lt;span&gt;expansion algorithm. Updating all the \
relays would be slow, so relays&lt;/span&gt;&lt;br&gt;&lt;span&gt;need to be able to handle new index \
types and data types without&lt;/span&gt;&lt;br&gt;&lt;span&gt;fully understanding them. That \
means that we need to specify an&lt;/span&gt;&lt;br&gt;&lt;span&gt;algorithm that can work flexibly \
with many future kinds of data.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;Another tricky \
aspect is that the data which the relays need to put&lt;/span&gt;&lt;br&gt;&lt;span&gt;into SNIPs all \
needs to be signed, so all of that data needs to come&lt;/span&gt;&lt;br&gt;&lt;span&gt;out the same \
when relays calculate it as the when the authorities&lt;/span&gt;&lt;br&gt;&lt;span&gt;calculate it. \
Thus, all the algorithms for building Merkle trees and&lt;/span&gt;&lt;br&gt;&lt;span&gt;indices and \
SNIPRouterData bodies need to be deterministic.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;I \
think that I got all of this relatively right in [RECONST], but&lt;/span&gt;&lt;br&gt;&lt;span&gt;there \
are probably some mistakes hiding in there.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;I'm \
hoping that there is a cleaner alternative to the \
weighted-index&lt;/span&gt;&lt;br&gt;&lt;span&gt;reconstruction algorithm -- the one that's there right \
now puts a&lt;/span&gt;&lt;br&gt;&lt;span&gt;lot of requirements on the input data, in order to \
avoid&lt;/span&gt;&lt;br&gt;&lt;span&gt;floating-point \
operations.&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There's a shorter \
encoding for Raw:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;for each&lt;span style="caret-color: \
rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt;[i, pos1, pos2] \
in&lt;/span&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, \
0);"&gt;index_ranges:&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;font color="#000000"&gt;&lt;span style="caret-color: \
rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt; w = pos2 - \
pos1&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, \
0); -webkit-text-size-adjust: auto;"&gt; j = the index of pos1 among all \
sorted pos1s&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, \
0, 0); -webkit-text-size-adjust: auto;"&gt; new_encoding = [i, j, \
w]&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0); \
-webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="caret-color: \
rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt;[i, j, w] is an \
efficient encoding if index_ranges is sparse&lt;/span&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;compared&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;with&lt;/span&gt;ENDIVERouterData, \
because:&lt;/div&gt;&lt;/div&gt;&lt;div&gt;* j has the same cardinality as I&lt;/div&gt;&lt;div&gt;* w is smaller \
than pos1 and pos2&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, \
0); -webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: \
rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt;If index_ranges \
is dense, there may be a more efficient&lt;/span&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;encoding:&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: \
auto;"&gt; add missing i with weight 0&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: \
rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt; drop \
j&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0); \
-webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: \
rgb(0, 0, 0); color: rgb(0, 0, 0); -webkit-text-size-adjust: auto;"&gt;With this \
encoding, you can drop a few of the \
constraints.&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There's a faster calculation and more \
efficient encoding for&lt;/div&gt;&lt;div&gt;Weighted, because there's a common factor in each \
POS()&lt;/div&gt;&lt;div&gt;calculation:&lt;/div&gt;&lt;div&gt;&lt;span style="-webkit-text-size-adjust: \
auto;"&gt;(1 &lt;&lt; 32) / total_weight&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;If we remove that factor, we end up with a \
much simpler&lt;/span&gt;&lt;span style="-webkit-text-size-adjust: \
auto;"&gt;algorithm,&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="-webkit-text-size-adjust: \
auto;"&gt;that's also more flexible:&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="-webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Algorithm: Expanding a "Weighted" \
indexspec.&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: normal; \
line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Each weighted \
indexspec also has a multiplier,&lt;/span&gt;which may vary&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;between indexspecs.&lt;/p&gt;&lt;p class="p2" style="margin: \
0px; font-stretch: normal; line-height: normal; min-height: 20.3px; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Let total_weight = \
SUM(indexspec.index_weights)&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;Verify total_weight * multiplier &lt;= UINT64_MAX.&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Let total_so_far = 0.&lt;/span&gt;&lt;/p&gt;&lt;p \
class="p1" style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Let result_idx = {} (an empty \
mapping).&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Define POS(b) \
= b * multiplier&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: normal; \
line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;For 0 &lt;= i \
&lt; LEN(indexspec.indexweights):&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;span class="Apple-converted-space"&gt;&lt;/span&gt;Let w = \
indexspec.indexweights[i].&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;span class="Apple-converted-space"&gt;&lt;/span&gt;Let lo = \
POS(total_so_far).&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;span class="Apple-converted-space"&gt;&lt;/span&gt;Let \
total_so_far = total_so_far + w.&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;span class="Apple-converted-space"&gt;&lt;/span&gt;Let hi = \
POS(total_so_far) - 1.&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;span class="Apple-converted-space"&gt;&lt;/span&gt;Append (lo, \
hi) =&gt; i to result_idx.&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: \
normal; line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: \
auto;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;Return result_idx.&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;If multiplier is large, then \
the weights can be quite small.&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;(Small weights \
sacrifice some accuracy.) And if the multiplier&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;is 1, you \
effectively have a "Raw" index.&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;If you make those changes, you should be able to use \
a similar&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0); \
-webkit-text-size-adjust: auto;"&gt;process to&lt;/span&gt;expand all the different \
index types. (After multiplying,&lt;/div&gt;&lt;div&gt;truncating, or hashing, you either end up \
with a delta, or an&lt;/div&gt;&lt;div&gt;absolute position. You can turn deltas into absolute \
positions,&lt;/div&gt;&lt;div&gt;and then feed them all into the same base \
algorithm.)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There are also a few things I think might be \
bugs:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;Was there meant to be a \
constraint that the Weighted total is&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: \
auto;"&gt;UINT64_MAX? Or close to UINT64_MAX?&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;The fixed \
parameters don't make much sense otherwise.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think v2 \
and v3 onion services assign descriptors to the next&lt;/div&gt;&lt;div&gt;highest HSDir RSA id \
(or ed25519 hash). But&lt;/div&gt;&lt;div&gt;INDEX_FROM_RING_KEYS() uses the relay input as the \
lowest value.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There is no next member for the last member \
in&lt;/div&gt;&lt;div&gt;INDEX_FROM_RING_KEYS(), but the code asks for one.&lt;/div&gt;&lt;div&gt;(Perhaps \
there are some typos here that make the code hard \
to&lt;/div&gt;&lt;div&gt;understand.)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We'll need special treatment for \
ring wrapping. (That is, 0xFF is not&lt;/div&gt;&lt;div&gt;a real upper limit, it actually \
means, "use the lowest relay".)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It's weird to call a middle \
value a "suffix", but "infix" is also a bit of an&lt;/div&gt;&lt;div&gt;unusual \
word.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There are also a bunch of typos, let me know when \
you're ready for&lt;/div&gt;&lt;div&gt;copy-editing.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200328114149</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-03-28 11:41:49-0400</timestampReceived><subject>[tor-dev] Chutney tests fail for tor/maint-0.3.5 (bug #33677)</subject><body>

Hi,

For the Outreachy.org internship project I decided to take on bug
#33677 [1].

I followed steps to run `make test-network-all` both on tor master and
maint-0.3.5 branches, using Chutney master branch. I tested before and
after tweaking value of HS_WAIT_FOR_UNCHECKED_DIR_INFO just to ensure
my testing environment was sane; all tests passed (except for two that
were skipped on master: mixed+hs-v23 and mixed+hs-v23-ipv6, and one
on 0.3.5: mixed+hs-v2, I assume this is expected though) on the first
go, on both branches of Tor.

Tests pass on Tor master after setting HS_WAIT_FOR_UNCHECKED_DIR_INFO
to 0, but on maint-0.3.5 I've run tests a few times (both with and
without CHUTNEY_DEBUG set) each time with a different outcome. Some of
the tests which fail: basic-min [2], single-onion-v23 [3],
bridges+ipv6-min [4], and ipv6-exit-min [5]. I have excerpted logs at
the bottom of this message, narrowed down to test failures; let me know
if I need to provide full logs or additional information.

I'll keep digging on this issue; I just wanted to show my current
progress and share what I hope to be useful information.

Caitlin


[1]: &lt;https://trac.torproject.org/projects/tor/ticket/33677&gt;
     "Stop waiting a set time for onion service descriptors"


[2]: basic-min.log
[...]
Connecting:
  Exit to 127.0.0.1:4747 via client localhost:9005
DEBUG: socket 5 connecting to ('localhost', 9005)...
DEBUG: Registering send-data-11
DEBUG: Registering check-12
Transmitting Data:
DEBUG: Socks 4a request to 127.0.0.1:4747
DEBUG: Test status: {'send-data-11': 'not done', 'check-12': 'not done'}: 2/0/0
DEBUG: Test status: {'send-data-11': 'not done', 'check-12': 'not done'}: 2/0/0
DEBUG: Done with run(); all_done == False and failure_count == 0
Transmission: Failure
[...]
chutney verify round 1/1 failed
Chutney failed 1 bootstraps; we may have a problem here.
FAIL basic-min (exit status: 1)


[3]: single-onion-v23.log
[...]
Connecting:
  HS to bkjqakom5elyh45a.onion:5858 (127.0.0.1:4747) via client localhost:9005
DEBUG: socket 7 connecting to ('localhost', 9005)...
DEBUG: Registering send-data-21
DEBUG: Registering check-22
  HS to moymkdharroenjd6zarfurdwmrr55j2zune6k7wafyfakwy2cis327id.onion:5858 \
                (127.0.0.1:4747) via client localhost:9005
DEBUG: socket 8 connecting to ('localhost', 9005)...
DEBUG: Registering send-data-23
DEBUG: Registering check-24
Transmitting Data:
DEBUG: Socks 4a request to bkjqakom5elyh45a.onion:5858
DEBUG: Socks 4a request to \
                moymkdharroenjd6zarfurdwmrr55j2zune6k7wafyfakwy2cis327id.onion:5858
DEBUG: new client from 127.0.0.1:54314 (fd=9)
DEBUG: successfully connected (fd=8)
DEBUG: Succeeded send-data-23
DEBUG: successful verification
DEBUG: Succeeded check-24
DEBUG: Test status: {'send-data-21': 'not done', 'check-22': 'not done', \
                'send-data-23': 'success', 'check-24': 'success'}: 2/2/0
DEBUG: Test status: {'send-data-21': 'not done', 'check-22': 'not done', \
                'send-data-23': 'success', 'check-24': 'success'}: 2/2/0
DEBUG: Done with run(); all_done == False and failure_count == 0
Transmission: Failure
[...]
chutney verify round 1/1 failed
Chutney failed 1 bootstraps; we may have a problem here.
FAIL single-onion-v23 (exit status: 1)


[4]: bridges+ipv6-min.log
[...]
Couldn't launch test005bc    command '/home/c/git/tor/src/app/tor -f \
/home/c/git/chutney/net/nodes/005bc/torrc': exit 1, output 'Mar 28 10:47:36.717 \
[notice] Tor 0.3.5.10-dev (git-38e07b88fac51f2a) running on Linux with Libevent \
2.1.8-stable, OpenSSL 1.1.1d, Zlib 1.2.11, Liblzma 5.2.4, and Libzstd 1.3.7. Mar 28 \
10:47:36.717 [notice] Tor can't help you if you use it wrong! Learn how to be safe at \
https://www.torproject.org/download/download#warning Mar 28 10:47:36.717 [notice] \
Read configuration file "/home/c/git/chutney/net/nodes/005bc/torrc". Mar 28 \
10:47:36.721 [warn] You have used DirAuthority or AlternateDirAuthority to specify \
alternate directory authorities in your configuration. This is potentially dangerous: \
it can make you look different from all other Tor users, and hurt your anonymity. \
Even if you've specified the same authorities as Tor uses by default, the defaults \
could change in the future. Be sure you know what you're doing. Mar 28 10:47:36.721 \
[warn] TestingTorNetwork is set. This will make your node almost unusable in the \
public Tor network, and is therefore only advised if you are building a testing Tor \
network! Mar 28 10:47:36.722 [notice] Opening Socks listener on 127.0.0.1:9005
Mar 28 10:47:36.722 [warn] Could not bind to 127.0.0.1:9005: Address already in use. \
Is Tor already running? Mar 28 10:47:36.722 [notice] Opening Control listener on \
127.0.0.1:8005 Mar 28 10:47:36.722 [warn] Could not bind to 127.0.0.1:8005: Address \
already in use. Is Tor already running? Mar 28 10:47:36.722 [notice] Opening Control \
listener on /home/c/git/chutney/net/nodes/005bc/control Mar 28 10:47:36.722 [notice] \
Opened Control listener on /home/c/git/chutney/net/nodes/005bc/control Mar 28 \
10:47:36.722 [notice] Closing partially-constructed Control listener on \
/home/c/git/chutney/net/nodes/005bc/control:0 Mar 28 10:47:36.722 [warn] Failed to \
parse/validate config: Failed to bind one of the listener ports. Mar 28 10:47:36.722 \
[err] Reading config failed--see warnings above. '
[...]
Launching chutney using Python 3.7.6
DEBUG: Tor version 0.3.5.10-dev (git-38e07b88fac51f2a).

test000a     is running with PID  2870: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
test001a     is running with PID  2873: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
test002ba    is running with PID  2911: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
test003r     is running with PID  2879: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
test004br    is running with PID  2882: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
test005bc    is stopped: Tor 0.3.5.10-dev (git-38e07b88fac51f2a)
5/6 nodes are running
[...]
bootstrap-network.sh failed
Chutney failed 1 bootstraps; we may have a problem here.
FAIL bridges+ipv6-min (exit status: 1)


[5]: ipv6-exit-min.log
[...]
Connecting:
  Exit to 127.0.0.1:4747 via client localhost:9005
DEBUG: socket 5 connecting to ('localhost', 9005)...
DEBUG: Registering send-data-11
DEBUG: Registering check-12
Transmitting Data:
DEBUG: Socks 4a request to 127.0.0.1:4747
DEBUG: Test status: {'send-data-11': 'not done', 'check-12': 'not done'}: 2/0/0
DEBUG: Test status: {'send-data-11': 'not done', 'check-12': 'not done'}: 2/0/0
DEBUG: Done with run(); all_done == False and failure_count == 0
Transmission: Failure
[...]
chutney verify round 1/1 failed
Chutney failed 1 bootstraps; we may have a problem here.
FAIL ipv6-exit-min (exit status: 1)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200323132358</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-03-23 13:23:58-0400</timestampReceived><subject>[tor-dev] Improving onion service availability during DoS using anonymous credentials</subject><body>

Hello list,

there has been lots of discussions about improving onion service availability
under DoS conditions. Many approaches have been proposed [OOO] but only a few
have been tried and even fewer show any real improvements to the availability
of the service.

An approach that we've been considering is the use of anonymous credentials as
a way to prioritize good clients from bad clients. The idea is that the service
gives tokens to clients it believes to be good, and prioritizes client with
tokens over clients without tokens whenever possible. This is a post to start a
discussion of how such approaches could work and whether they are worth
pursuing futher.

== Preliminaries ==

=== When should the access control take place? ===

Doing DoS defenses with anon credentials is all about enforcing access control
at the right point of the protocol so that the amplification factor of evil
clients gets cut as early as possible.

Very roughly the phases of the onion service protocol are: descriptor fetch
phase, intro phase, rendezvous phase. Let's see how those look like for the
purposes of access control:

- Doing the access control during the descriptor fetch stage is something worth
  considering because it's the first phase of the protocol and hence the
  earliest and best place to soak up any damage from evil clients. There is
  already a form of optional access control implemented here called "client
  authorization" and it's worth thinking of what's lacking to make it useful
  against DoS attackers. I'm gonna address this in section [CLIENTAUTH].

- Doing the access control during the introduction phase is another fruitful
  approach. Blocking bad clients during introduction means that they dont get to
  force the service to create a costly rendezvous circuit, and since services
  have a long-term circuit open towards the intro points it makes it easier for
  services to pass access control related data to the intro point. This is
  actually the approach we are gonna be talking most about in this post.

- Finally, doing the access control during the rendezvous phase is way too late
  since by that time the onion service has already spent lots of resources
  catering the evil client, so let's ignore that.

=== Entities of an anonymous credential system ===

Anonymous credential systems traditionally have three entities that concern us:

          - The Issuer:   the entity who issues the credentials/tokens
          - The Prover:   the entity who collects tokens and uses them to get access
          - The Verifier: the entity who verifies that tokens are legit and \
grants/restricts access

In the world of onion services, the Issuer is naturally the onion service, and
the Prover is the onion service client. The Verifier could either be
the onion service itself or its introduction points. We will see below how this
could work and the relevant tradeoffs.

         +--------+          +------------+           +--------------------+
         | Client |&lt;-+-+-+--&gt;|Intro point |&lt;--+---+--&gt;|Onion service       |
         |(Prover)|          |(Verifier?) |           |(Issuer)(Verifier?) |
         +--------+          +------------+           +--------------------+


=== How do tokens get around? ===

A main question here is "How do good clients end up with tokens?". For the
purposes of this post, we will assume that clients get these tokens in an out
of band fashion. For example, a journalist can give tokens to her sources over
Signal so they can use them with Securedrop. Or a forum operator can give
tokens to old-time members of the forum to be used during a DoS.

A natural chicken-and-egg problem occurs here since how is an onion service
supposed to give tokens to its users if it's unreachable because of a DoS? We
realize this is a big problem and we are not sure exactly how to solve it. This
problem naturally limits the use of anonymous credential solutions, and sorta
makes them a second-layer of defense since it assumes a first-layer of defense
that allows operators to pass tokens to the good people. A first-layer approach
here could perhaps look like PrivacyPass where users get tokens by solving
CAPTCHAs.

== Anonymous credentials ==

By surveying the anonymous credential literature we have found various types of
anonymous credential schemes that are relevant for us:

- Discrete-logarithm-based credentials based on blind signatures:

    This is a class of anon credential schemes that allow us to separate the
    verifier from the issuer. In particular this means that we can have the
    service issue the tokens, but the introduction point being the verifier.

    They are usually based on blind signatures like in the case of Microsoft's
    U-Prove system [UUU].

- Discrete-logarithm-based credentials based on OPRF:

    Another approach here is to use OPRF constructions based on the discrete
    logarithm problem to create an anonymous credential scheme like in the case
    of PrivacyPass [PPP]. The downside, IIUC, is that in PrivacyPass you can't
    have a different issuer and verifier so it's the onion service that needs
    to do the token verification restricting the damage soaking potential.

- KVAC (Keyed-Verification Anonymous Credentials):

    KVAC-based credentails have comparable performance to Dlog-based
    credentials, and are also easier to create security proofs for due to them
    being based on symmetric primitives like algebraic MAC constructions
    [FFF]. The downside is that they assume that the verifier and the issuer is
    the same entity (the onion service). KVACs are used by Signal for
    protecting their group chat metadata [GGG].

Which construction and scheme we choose depends on our constraints and the
parameters we are trying to minmax. So let's try to explore these constraints
and parameters some more.

== Space constraints ==

Let's assume that a client found some anonymous credentials for a service. How
will clients present their credentials to the verifier, being either the
service or the intro point?

The natural approach here is for the client to include their token as part of
the INTRODUCE1 cell.

=== How much space is available in INTRODUCE1 cells? [SPACE_CONSTRAINTS] ===

From a brief experiment, I see that the INTRODUCE1 cell payload total size is
498 bytes, and we are already using 310 bytes from it, so that leaves about 188
bytes for use. The cell is extensible using cell extensions that can go either
to the intro point [III] or to the service directly [EEE].

=== How big are anonymous credentials redemptions? ===

From looking at the literature it seems unlikely that those anonymous
credentials can be presented given the size limitations from above. In
particular here is the size needed for presenting/redeeming an anonymous
credential in the various schemes:

- Privacy Pass [PPP]: Credential redemption takes 396 bytes
- Signal [GGG]: Their paper does not say exactly, but by peeking into their
                code it seems like presenting the credential takes about 620
                bytes [CCC].

So if I'm not mistaken, it seems like we will need another way to present
anonymous credentials to the service or intro point.

=== How can we trasmit these credentials then? ===

The unfortunate fact here is that presenting those credentials does not fit
into the remaining space of an INTRODUCE1 cell, but it also wouldn't even fit
if we created an entirely new relay cell for this purpose (say INTRO_REDEEM)
since the relay cell payload is about 498 bytes and all the credentials above,
except from PrivacyPass (!), are bigger than that.

This means that we will either need to use a space-compact anonymous
credential scheme, or to implement wide relay cells as suggested in
ticket #33650 (which seems like lots of work!).

== Computational constraints [COMPUTATIONAL_CONSTRAINTS] ==

Another big topic for consideration here is the computational resources
required for the various operations of the scheme. In particular, how hard it
is to issue such tokens, present such tokens and to verify such
tokens. Different schemes have different computational profiles. I'm not gonna
attempt to summarize the literature here because it will take me more time than
I have right now.

However, it's clear that our main priority here is a lightweight verification
procedure, so that services or intro points spend as little energy as possible
validating (potentially evil) tokens. It's imperative that verifying tokens is
orders of magnitude more lightweight than the regular job that a service would
do if credentials did not exist (i.e. doing path selection, creating a
rendezvous circuit, doing the crypto, etc.)

Our second priority here is a lighweight token issuance procedure, so that
services don't spend too much time issuing tokens, especially if this is done
in an automatic real-time manner that can be abused by an adversary.

And finally, we don't particularly care about the token presentation procedure
being lightweight, since this is a procedure that the attacker will also have
to do and hence we want to incur as much costs to them as possible.

== Discussion ==

==== What's lacking from HSv3 client authorization [CLIENTAUTH] ====

It's really important to understand what's lacking from descriptor-level client
authorization [QQQ] with regards to DoS defences before we spend time and
energy implementing any anonymous credential approach.

To use the descriptor-level client authorization feature for DoS protection the
onion service operator creates a mirror of the website that is only reachable
using descriptor-level client auth and then they pass client auth tokens to the
clients they trust to be good natured. The above system can also be automated
and turned into a web service.

However this system has a bunch of drawbacks:

- Given the implicit and anonymous nature of the descriptor-level client
  authorization system, if an evil actor gets their hand in a client auth token
  and they start DoSing the service, then the operator has no means to
  distinguish that client from any other client. Hence there is no way to
  identify individual bad clients and revoke them. This is the biggest issue
  with descriptor-based client authorization for the purposes of DoS defense.

- Managing the access list (adding and removing clients) in the
  descriptor-level client authorization system is an expensive process because
  it requires uploading a new set of descriptors. Doing this too often (in an
  automated way) can cause lots of network traffic and also perhaps race
  conditions with clients who fetch descriptors.

- Because the authentication happens by adding new lines on the descriptor,
  there is a fundamental limit on how many authed clients it can support. In
  particular, with some back-of-the-envelope calculations [ZZZ] an onion
  service can support a max of 250 authed clients this way. However, there is
  nothing stopping the operator from passing the same token to multiple clients
  and managing them as groups.

The above issues would be addressed with intro-level client authorization since
the authentication is explicit and done in real-time.

It's worth thinking of the above drawbacks more and how we can bypass them to
do something useful with the current system before we jump into new
complexities and tradeoffs.

---

Thanks for reading and looking forward to your feedback :)

[OOO]: https://trac.torproject.org/projects/tor/ticket/31223
[ZZZ]: https://lists.torproject.org/pipermail/tor-dev/2016-November/011658.html
[QQQ]: https://eprint.iacr.org/2013/516.pdf
[PPP]: https://www.petsymposium.org/2018/files/papers/issue3/popets-2018-0026.pdf
[UUU]: https://www.microsoft.com/en-us/research/project/u-prove/
[FFF]: https://eprint.iacr.org/2013/516.pdf
[GGG]: https://signal.org/blog/signal-private-group-system/
[III]: https://github.com/torproject/torspec/blob/f81b1e6cc53b91abb3ae206807bc371fac1b7cbf/rend-spec-v3.txt#L1719
 [EEE]: https://github.com/torproject/torspec/blob/f81b1e6cc53b91abb3ae206807bc371fac1b7cbf/rend-spec-v3.txt#L1782
 [CCC]: https://github.com/signalapp/zkgroup/blob/4294e428216113d81f5c0cb50f578797d15aa9d6/rust/src/common/constants.rs#L18
 _______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200323134307</emailId><senderName>Jeff Burdges</senderName><senderEmail>burdges@gnunet.org</senderEmail><timestampReceived>2020-03-23 13:43:07-0400</timestampReceived><subject>Re: [tor-dev] Improving onion service availability during DoS using anonymous credentials</subject><body>

[Attachment #2 (multipart/signed)]


There is another component of the design space:

Do you want credentials to be movable from one introduction point to another?

If so, you can do this or not with both blind signatures and OPRFs by enabling or \
restricting their malleability properties, but probably not with anything symmetric.  \
If tokens are movable, then this encourages users to use multiple introduction \
points, but doing so sounds unlikely, but worse gives DoS attackers parallel access \
to introduction points.  I suppose no for this reason, but maybe it's worth \
considering for the future..


&gt; On 23 Mar 2020, at 14:23, George Kadianakis &lt;desnacked@riseup.net&gt; wrote:
&gt; - Discrete-logarithm-based credentials based on blind signatures:
&gt; 
&gt; This is a class of anon credential schemes that allow us to separate the
&gt; verifier from the issuer. In particular this means that we can have the
&gt; service issue the tokens, but the introduction point being the verifier.
&gt; 
&gt; They are usually based on blind signatures like in the case of Microsoft's
&gt; U-Prove system [UUU].

We should mention that Fuchsbauer, et al. recently addressed the forgeability problem \
for blind Schnorr signatures in https://eprint.iacr.org/2019/877.pdf which should \
improve performance, but still costs more round trips than slower blind signature \
variants.  I think the attacks were never relevant for DoS protection anyways though.

You need 64 bytes for the Schnorr signature plus whatever you require to identify the \
signing key, so 80-96 bytes .

&gt; - Discrete-logarithm-based credentials based on OPRF:
&gt; 
&gt; Another approach here is to use OPRF constructions based on the discrete
&gt; logarithm problem to create an anonymous credential scheme like in the case
&gt; of PrivacyPass [PPP]. The downside, IIUC, is that in PrivacyPass you can't
&gt; have a different issuer and verifier so it's the onion service that needs
&gt; to do the token verification restricting the damage soaking potential.

Issuer and verifier must share secret key material, so not exactly the same thing as \
being the same.  You must share some special public key material for the blind \
signatures.

I believe redemption could cost 64-96 bytes bytes, so a 32 byte curve point, a 16-32 \
bytes that identifies the issuing key, and a 16-32 bytes seed that gets hashed to the \
curve.

Jeff


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCgAdFiEEBA1bLpAiCdPXvXG3q6x/0cwQCnQFAl54vOsACgkQq6x/0cwQ
CnSbYQ//RltrFShUJBrVzKiKnMKjoyIfeUWCMnVm5INqT6Ng11HqEsnwVrR4Haep
ROT2a2Og/rAS0/tU5dqG9kAcwbVNL1PEM7Nz6aHnadoed9/vSljnievToIIq1soU
+XjaH/Vzd8DLZUTB1fO2nY+jDvzbs2b9lA9tT4LwiBrA3gIqWsiZO4JF8LFjnpjL
DdbygnwbqrkH1W7BsTrl93juNkxaWCadf5T/mX0JSJg7WOPlU8SnuZsp2k+M1IaG
UvGbcT+iyvwc4uPbimvm37t1J50pz0fHJZzzMbV1EVwtNlWxZP8Bi7NuZuNqsKBd
eOgGRmJNYEYhT9P5tfcAIXvl9tf/fxW6I35ZTZKGQgFtV70IAvTWwQMov38tgUos
netfbkmuGtaPkSL9gvY1g3JEYrLsD2jhK7V9lPA6fOoaJukcmnkngFN/JbTVKFPb
VNYGo6QUf4ORaaCq917kTm1ID7QBh6GYPqOR3sWbsf5R0TD21nn/4EoLu+ur4ZZH
2BlfdMmsPiTgpgrZCRriT99Udp6AipxCXayRca0juNAbhlcADbnAQD+5pIp9K5ic
DklM/DjvKv0y2K8UctvXOC19WASLWqZmrrZQsuTGiggtsIRmAhXBK9H1Qa7o3o2n
7g9LhcGHmy9oIqXcxJNQiBYdY6ZPkAtg2EXFnWePfus4X/3+bPg=
=zSVQ
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200401085809</emailId><senderName>c</senderName><senderEmail>c@chroniko.jp</senderEmail><timestampReceived>2020-04-01 08:58:09-0400</timestampReceived><subject>Re: [tor-dev] Chutney tests fail for tor/maint-0.3.5 (bug #33677)</subject><body>

(Forgot to hit "reply all" in my mail client)

On Mon, 30 Mar 2020 13:22:21 +1000
teor &lt;teor@riseup.net&gt; wrote:

&gt; This ticket is a cleanup ticket, after some other changes have been made.
&gt; I've edited the ticket description to make that clearer.  

Understood, thank you for clarifying.

&gt; Check for onion service descriptor uploads:
&gt; https://trac.torproject.org/projects/tor/ticket/33609
&gt; 
&gt; Someone else is working on the microdescriptor changes at the moment.
&gt; 
&gt; Would you like to start working on the onion service descriptor changes?  

Sure, it would give me an opportunity to learn about onion descriptors
in more detail. I will get started on it.

But first, looking at it more, I think my struggle with understanding
what to do stems from my unfamiliarity with the Chutney codebase (first
I have heard of the tool was with this project, even though commits
date back to 2011). I need to make sure I understand #33609
sufficiently:

- Is the requested functionality only for Chutney or will Tor
  potentially need any changes to allow for HS verification?
- So I know where to begin looking in the codebase, the ticket wants us
  to "check each onion service log" -- is this referring to Tor log
  output (such as the instances chutney spawns), chutney-specific logs,
  or something else entirely?
- For "check v2 and v3 onion services" -- check if they've propagated
  the network?
- For "call it an extra 200% 'bootstrap' stage" -- again is this
  chutney-specific? I only know bootstrapping percentage from Tor
  notice-level logging and obviously it only goes up to 100%, so I'm
  wondering if "200%" is a magic number here or something arbitrary.

From this and the parent #33050 it doesn't seem to me like the request
is very clear. I am reading proposals 311-313 after sending this
message so maybe I can come across some answers to my
questions/confusions via the proposals themselves. The proposals will
probably give me a better idea of the work I am in for overall, too,
and perhaps I should have come across them sooner. I figure it is wise
regardless to ask for clarification here and read while I wait for
feedback. Efficiency and all :)

Caitlin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200329211615</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-03-29 21:16:15-0400</timestampReceived><subject>Re: [tor-dev] Walking onions status update: week 3 notes</subject><body>

On Fri, Mar 20, 2020 at 5:09 PM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; On 21 Mar 2020, at 05:38, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt;
&gt; Walking Onions: week 3 update
&gt;
&gt; As you might recall, the SNIPs need to be nice and small, but they
&gt; need to be completely self-contained.  The ENDIVE, on the other
&gt; hand, needs to be diff-friendly, and compressible.  Relays need to
&gt; derive all the SNIPs from the ENDIVE.  The ENDIVE and SNIP formats
&gt; that I worked on during last week [SNIPFMT] was designed to meet these
&gt; criteria.
&gt;
&gt; This week, I wrote up the algorithms to extract signed SNIPs from an
&gt; ENDIVE.  This is in section 4 [RECONST] of the specs in my
&gt; work-in-progress repository [GITREPO] This was mainly straightforward
&gt; consequence from the work I did last week, but there were a few
&gt; things that turned up.
&gt;
&gt; One trickier aspect of this work is that we want to move most of the
&gt; decision-making to the authorities, and have the relays simply do an
&gt; expansion algorithm.  Updating all the relays would be slow, so relays
&gt; need to be able to handle new index types and data types without
&gt; fully understanding them.  That means that we need to specify an
&gt; algorithm that can work flexibly with many future kinds of data.
&gt;
&gt; Another tricky aspect is that the data which the relays need to put
&gt; into SNIPs all needs to be signed, so all of that data needs to come
&gt; out the same when relays calculate it as the when the authorities
&gt; calculate it. Thus, all the algorithms for building Merkle trees and
&gt; indices and SNIPRouterData bodies need to be deterministic.
&gt;
&gt; I think that I got all of this relatively right in [RECONST], but
&gt; there are probably some mistakes hiding in there.
&gt;
&gt; I'm hoping that there is a cleaner alternative to the weighted-index
&gt; reconstruction algorithm -- the one that's there right now puts a
&gt; lot of requirements on the input data, in order to avoid
&gt; floating-point operations.
&gt;
&gt;
&gt; There's a shorter encoding for Raw:
&gt;
&gt; for each [i, pos1, pos2] in index_ranges:
&gt;   w = pos2 - pos1
&gt;   j  = the index of pos1 among all sorted pos1s
&gt;   new_encoding = [i, j, w]

This will work when w is an integer that we can work on additively,
but not so well when we're talking about something more like a hash
ring.  I think it makes sense to have two different possible encodings
here, though.  I'm calling this one "RawNumeric.

&gt; [i, j, w] is an efficient encoding if index_ranges is sparse compared
&gt; with ENDIVERouterData, because:
&gt; * j has the same cardinality as I
&gt; * w is smaller than pos1 and pos2
&gt;
&gt; If index_ranges is dense, there may be a more efficient encoding:
&gt;   add missing i with weight 0
&gt;   drop j
&gt; With this encoding, you can drop a few of the constraints.


&gt; There's a faster calculation and more efficient encoding for
&gt; Weighted, because there's a common factor in each POS()
&gt; calculation:
&gt; (1 &lt;&lt; 32) / total_weight
&gt;
&gt; If we remove that factor, we end up with a much simpler algorithm,
&gt; that's also more flexible:
&gt;
&gt; Algorithm: Expanding a "Weighted" indexspec.
&gt;
&gt;
&gt; Each weighted indexspec also has a multiplier, which may vary
&gt;
&gt; between indexspecs.
&gt;
&gt;
&gt; Let total_weight = SUM(indexspec.index_weights)
&gt;
&gt; Verify total_weight * multiplier &lt;= UINT64_MAX.
&gt;
&gt;
&gt; Let total_so_far = 0.
&gt;
&gt; Let result_idx = {} (an empty mapping).
&gt;
&gt; Define POS(b) = b * multiplier
&gt;
&gt;
&gt; For 0 &lt;= i &lt; LEN(indexspec.indexweights):
&gt;
&gt;    Let w = indexspec.indexweights[i].
&gt;
&gt;    Let lo = POS(total_so_far).
&gt;
&gt;    Let total_so_far = total_so_far + w.
&gt;
&gt;    Let hi = POS(total_so_far) - 1.
&gt;
&gt;    Append (lo, hi) =&gt; i to result_idx.
&gt;
&gt;
&gt; Return result_idx.

I'm not so sure about this one -- see the note below about the total value.

&gt; If multiplier is large, then the weights can be quite small.
&gt;
&gt; (Small weights sacrifice some accuracy.) And if the multiplier
&gt;
&gt; is 1, you effectively have a "Raw" index.
&gt;
&gt;
&gt; If you make those changes, you should be able to use a similar
&gt; process to expand all the different index types. (After multiplying,
&gt; truncating, or hashing, you either end up with a delta, or an
&gt; absolute position. You can turn deltas into absolute positions,
&gt; and then feed them all into the same base algorithm.)
&gt;
&gt; There are also a few things I think might be bugs:
&gt;
&gt; Was there meant to be a constraint that the Weighted total is
&gt; UINT64_MAX? Or close to UINT64_MAX?

The actual intention is that it has to be " = UINT32_MAX", not" &lt;=
UINT32_MAX".  Remember that the the client picks its next relay by
specifying a random index value in range 0..UINT32_MAX, and it expects
that the relay to that it is extending to _will_ have a snip that
covers that range.

&gt; The fixed parameters don't make much sense otherwise.
&gt;
&gt;
&gt; I think v2 and v3 onion services assign descriptors to the next
&gt; highest HSDir RSA id (or ed25519 hash). But
&gt; INDEX_FROM_RING_KEYS() uses the relay input as the lowest value.
&gt;
&gt; There is no next member for the last member in
&gt; INDEX_FROM_RING_KEYS(), but the code asks for one.
&gt; (Perhaps there are some typos here that make the code hard to
&gt; understand.)

Okay, I'll have to look into this.  I think you're probably right, and
you _are_ right about the ring wrapping issues.

&gt; We'll need special treatment for ring wrapping. (That is, 0xFF is not
&gt; a real upper limit, it actually means, "use the lowest relay".)
&gt;
&gt; It's weird to call a middle value a "suffix", but "infix" is also a bit of an
&gt; unusual word.
&gt;
&gt; There are also a bunch of typos, let me know when you're ready for
&gt; copy-editing.

Once I'm through with sections 3 and 5, I'm going to do a big revision
and consistency check of everything that's there before I move on to
sections 6-8.  Once that's done I hope that a copy edit would be more
helpful.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200314044415</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-14 04:44:15-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

Hi Nick,

I'm interested in following along with Walking Onions, but I might
drop out when the relay IPv6 work gets busy.

I'm not sure how you'd like feedback, so I'm going to try to put it
in emails, or in pull requests.

(I made one comment on a git commit in walking-onions-wip, but
I'm not sure if you see those, so I'll repeat it here.)

&gt; On 14 Mar 2020, at 03:52, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; This week, I worked specifying the nitty-gritty of the SNIP and
&gt; ENDIVE document formats.  I used the CBOR meta-format [CBOR] to
&gt; build them, and the CDDL specification language [CDDL] to specify
&gt; what they should contain.
&gt; 
&gt; As before, I've been working in a git repository at [GITHUB]; you
&gt; can see the document I've been focusing on this week at
&gt; [SNIPFMT].  (That's the thing to read if you want to send me
&gt; patches for my grammar.)

I'm not sure if you've got to exit ports yet, but here's one possible
way to partition ports:
* choose large partitions so that all exits support all ports in the
  partition
* choose smaller categories so that most exits support most ports
  in the partition
* ignore small partitions, they're bad for client privacy anyway

For example, you might end up with:
* web (80 &amp; 443)
* interactive (SSH, IRC, etc.)
* bulk (torrent, etc.)
* default exit policy
* reduced exit policy

I'm not sure if we will want separate categories for IPv4-only
and dual-stack policies. We can probably ignore IPv6-only
policies for the moment, but we should think about them in
future.

&gt; There were a few neat things to do here:
&gt; 
&gt;   * I had to define SNIPs so that clients and relays can be
&gt;     mostly agnostic about whether we're using a merkle tree or a
&gt;     bunch of signatures.
&gt; 
&gt;   * I had to define a binary diff format so that relays can keep
&gt;     on downloading diffs between ENDIVE documents. (Clients don't
&gt;     download ENDIVEs).  I did a quick prototype of how to output
&gt;     this format, using python's difflib.

Can we make the OrigBytesCmdId use start and length?
length may be shorter than end, and it will never be longer.

If we are doing chunk-based encoding, we could make start
relative to the last position in the original file. But that would
mean no back-tracking, which means we can't use some
more sophisticated diff algorithms.

&gt;   * To make ENDIVE diffs as efficient as possible, it's important
&gt;     not to transmit data that changes in every ENDIVE.  To this
&gt;     end, I've specified ENDIVEs so that the most volatile parts
&gt;     (Merkle trees and index ranges) are recomputed on the relay
&gt;     side.  I still need to specify how these re-computations work,
&gt;     but I'm pretty sure I got the formats right.
&gt; 
&gt;     Doing this calculation should save relays a bunch of
&gt;     bandwidth each hour, but cost some implementation complexity.
&gt;     I'm going to have to come back to this choice going forward
&gt;     to see whether it's worth it.
&gt; 
&gt;   * Some object types are naturally extensible, some aren't.  I've
&gt;     tried to err on the size of letting us expand important
&gt;     things in the future, and using maps (key-&gt;value mappings)
&gt;     for object that are particularly important.
&gt; 
&gt;     In CBOR, small integers are encoded with a little less space
&gt;     than small strings.  To that end, I'm specifying the use of
&gt;     small integers for dictionary keys that need to be encoded
&gt;     briefly, and strings for non-tor and experimental extensions.
&gt; 
&gt;   * This is a fine opportunity to re-think how we handle document
&gt;     liveness.  Right now, consensus directories have an official
&gt;     liveness interval on them, but parties that rely on
&gt;     consensuses tolerate larger variance than is specified in the
&gt;     consensus.  Instead of that approach, the usable lifetime of
&gt;     each object is now specified in the object, and is ultimately
&gt;     controlled by the authorities.  This gives the directory
&gt;     authorities more ability to work around network tolerance
&gt;     issues.
&gt; 
&gt;     Having large lifetime tolerances in the context of walking
&gt;     onions is a little risky: it opens us up to an attack where
&gt;     a hostile relay holds multiple ENDIVEs, and decides which one
&gt;     to use when responding to a request.  I think we can address this
&gt;     attack, however, by making sure that SNIPs have a published
&gt;     time in them, and that this time moves monotonically forward.

If the issue is having multiple valid ENDIVEs, then authorities could
also put a cap on the number of concurrently valid ENDIVEs.

There are two simple schemes to implement a cap:
* set a longer interval for rebuilding all ENDIVEs
  (the cap is the rebuild interval, divided by the validity interval)
* refuse to sign a new SNIP for a relay that's rapidly changing
  (or equivalently, leave that relay out of the next ENDIVE)

Both these schemes also limit the amount of bandwidth used
for a relay that's rapidly changing details.

&gt;   * As I work, I'm identifying other issues in tor that stand in
&gt;     the way of a good efficient walking onion implementation that
&gt;     will require other follow-up work.  This week I ran into a
&gt;     need for non-TAP-based v2 hidden services, and a need for a
&gt;     more efficient family encoding.  I'm keeping track of these
&gt;     in my outline file.

Do "tricky restrictions" include the IP subnet restriction (avoid
relays in the same IPv4 /16 and IPv6 /32) ?

What about a heterogenous IPv4 / IPv6 network, where
IPv4-only relays can't connect to IPv6-only relays?

If we do decide to add IPv6-only relays, we'll probably add
them in this order:
* IPv6-only bridges (needs dual-stack bridge guards / middles?)
* IPv6-only exits (needs dual-stack middles)
* IPv6-only guards (needs dual-stack middles)
* IPv6-only middles (needs dual-stack or IPv6-only guards and
   exits, removes need for dual-stack middles)

What about bridge guards?
(That is, can bridges add an extra hop into circuits, to protect
themselves from being discovered by middles?)

Maybe bridges could commit to their (blinded) bridge guards
in their self-signed own snip?
Or the bridge authority could distribute a bridge ENDIVE?
(We might need multiple bridge authorities for redundancy.)

&gt; [CBOR] RFC 7049: "Concise Binary Object Representation (CBOR)"
&gt;    https://tools.ietf.org/html/rfc7049b
&gt; 
&gt; [CDDL] RFC 8610: "Concise Data Definition Language (CDDL): A
&gt;    Notational Convention to Express Concise Binary Object
&gt;    Representation (CBOR) and JSON Data Structures"
&gt;    https://tools.ietf.org/html/rfc8610
&gt; 
&gt; [GITREPO]  https://github.com/nmathewson/walking-onions-wip
&gt; 
&gt; [SNIPFMT] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-endives-and-snips.md



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200318152047</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-18 15:20:47-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

[Attachment #2 (multipart/signed)]


Hi Nick,

&gt; On 14 Mar 2020, at 14:44, teor &lt;teor@riseup.net&gt; wrote:
&gt; 
&gt;&gt;  * As I work, I'm identifying other issues in tor that stand in
&gt;&gt;    the way of a good efficient walking onion implementation that
&gt;&gt;    will require other follow-up work.  This week I ran into a
&gt;&gt;    need for non-TAP-based v2 hidden services, and a need for a
&gt;&gt;    more efficient family encoding.  I'm keeping track of these
&gt;&gt;    in my outline file.

Here's another issue you might want to consider:

Currently, new relays get in the consensus as soon as:
  * they post their descriptors, and
  * a majority of authorities can contact their ORPorts.

That means clients and relays waste a whole bunch of bandwidth
downloading consensus info and descriptors for relays with very
low weights.

Instead, we could have two documents:

  * a "potential relays" document, that's used by the authorities,
    bandwidth scanner, and any other relay test infrastructure
    (perhaps exit scanners, sybil scanners, and other tools), and

  * a "useful relays" document, that contains good relays with
    reasonable weights.

Let's think about this kind of efficiency as part of walking
onions.

We might even be able to make this change before walking onions, by:
  * making sbws and other tools use the ns consensus
    (I think most tools already use the ns consensus), and
  * adding a new consensus method, which requires a minimum consensus
    weight (or consensus weight fraction) for relays in the microdesc
    consensus.

Since relays and clients use the microdesc consensus, low-weight
relays would disappear from the network. But they would still be in
the ns consensus.

We might find some interesting bugs in tor though. We never quite
got rid of all the old code that uses the ns consensus and full
descriptors.

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl5yPE8ACgkQEP6qDnB1
ZyrrTQ//Sj9mWb3TNA2EH5Fbysql9GKgo9dia1MdpFZFjKV/MorOQUERp87SyV9P
/zGVyDeBDBhN48ofrDHtLiLRgGeNYQBnq+0RxO/wxvpV8aKvmcgAqyjb0xwK+JUa
FftxpKqsisvEU9QHSNI5lw6FTbOFziqjory7KdKSqxclByhBXR8B6v8eBo6dAQVy
uraFb6+A+GlW8XA2aVESWVnw1chfj+bcNrdTFfQQBJ6h/7Gj0opp74SLYQL6cmgx
D9pW7bRJRmMv80RPz54BgDmxCO4zflTUlirtPsGqIKfpMesOVxr9eXR8t3u7iF72
6ukkqM5LhMMkQw0NYUF2flhQJh4NkoR3X0lDIjH1KE1zY8mSx9Bg+XO35cQEuc/f
92rtg3xkVtZla4k3B+18mqqFXuSGpfcCS84Zgn7FB4Q1lwaEObW7SDjv2Pc7BTKC
RF41blKZWQAiOvhLsCvAPNCA8/OLChUe3i8sl9DqMW+Aqgu7LE/VKCnzs8KUfgIO
IFaPAQ7FPJ3UJfKuopNbzZzvDAoMkieaL83eaydvg1ZMudoOMvI6jpp31XCDvlgZ
vsHpeGHaj66xVBx9MjxOARabKstpTFW0d2JloEqLr7nrz3QVCbmOTWH+q/+vaz70
StZ0jEpo0P0B7JNaz0/XcEZgi9J49sg/eVuDn8hXQx/hyO4w0fc=
=zvH4
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200320125946</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-03-20 12:59:46-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

On Sat, Mar 14, 2020 at 12:44 AM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; I'm interested in following along with Walking Onions, but I might
&gt; drop out when the relay IPv6 work gets busy.
&gt;
&gt; I'm not sure how you'd like feedback, so I'm going to try to put it
&gt; in emails, or in pull requests.
&gt;
&gt; (I made one comment on a git commit in walking-onions-wip, but
&gt; I'm not sure if you see those, so I'll repeat it here.)

Thanks, this is really helpful!  I missed the repository comments, and
I'll probably miss some more.


&gt; &gt; On 14 Mar 2020, at 03:52, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; &gt;
&gt; &gt; This week, I worked specifying the nitty-gritty of the SNIP and
&gt; &gt; ENDIVE document formats.  I used the CBOR meta-format [CBOR] to
&gt; &gt; build them, and the CDDL specification language [CDDL] to specify
&gt; &gt; what they should contain.
&gt; &gt;
&gt; &gt; As before, I've been working in a git repository at [GITHUB]; you
&gt; &gt; can see the document I've been focusing on this week at
&gt; &gt; [SNIPFMT].  (That's the thing to read if you want to send me
&gt; &gt; patches for my grammar.)
&gt;
&gt; I'm not sure if you've got to exit ports yet, but here's one possible
&gt; way to partition ports:
&gt; * choose large partitions so that all exits support all ports in the
&gt;   partition
&gt; * choose smaller categories so that most exits support most ports
&gt;   in the partition
&gt; * ignore small partitions, they're bad for client privacy anyway
&gt;
&gt; For example, you might end up with:
&gt; * web (80 &amp; 443)
&gt; * interactive (SSH, IRC, etc.)
&gt; * bulk (torrent, etc.)
&gt; * default exit policy
&gt; * reduced exit policy
&gt;
&gt; I'm not sure if we will want separate categories for IPv4-only
&gt; and dual-stack policies. We can probably ignore IPv6-only
&gt; policies for the moment, but we should think about them in
&gt; future.

Interesting!  Yeah, something like this might work.  I've added this
to my notes.

Also, there's some interesting ideas about handling exit policies in
the whitepaper's section 6.  I don't know if

&gt; &gt; There were a few neat things to do here:
&gt; &gt;
&gt; &gt;   * I had to define SNIPs so that clients and relays can be
&gt; &gt;     mostly agnostic about whether we're using a merkle tree or a
&gt; &gt;     bunch of signatures.
&gt; &gt;
&gt; &gt;   * I had to define a binary diff format so that relays can keep
&gt; &gt;     on downloading diffs between ENDIVE documents. (Clients don't
&gt; &gt;     download ENDIVEs).  I did a quick prototype of how to output
&gt; &gt;     this format, using python's difflib.
&gt;
&gt; Can we make the OrigBytesCmdId use start and length?
&gt; length may be shorter than end, and it will never be longer.

Good idea; done.

&gt; If we are doing chunk-based encoding, we could make start
&gt; relative to the last position in the original file. But that would
&gt; mean no back-tracking, which means we can't use some
&gt; more sophisticated diff algorithms.

Well, we could allow signed integers.  I'm making a note to look into
whether this would help much.

[...]
&gt; If the issue is having multiple valid ENDIVEs, then authorities could
&gt; also put a cap on the number of concurrently valid ENDIVEs.
&gt;
&gt; There are two simple schemes to implement a cap:
&gt; * set a longer interval for rebuilding all ENDIVEs
&gt;   (the cap is the rebuild interval, divided by the validity interval)
&gt; * refuse to sign a new SNIP for a relay that's rapidly changing
&gt;   (or equivalently, leave that relay out of the next ENDIVE)
&gt;
&gt; Both these schemes also limit the amount of bandwidth used
&gt; for a relay that's rapidly changing details.

Interesting idea; I think in the case of the first one, we'd be giving
up something important, but I don't know how much so.  The second one
might actually help with our network stability, though.

[...]
&gt;
&gt; Do "tricky restrictions" include the IP subnet restriction (avoid
&gt; relays in the same IPv4 /16 and IPv6 /32) ?

I'm thinking of _all_ tricky restrictions, including but not limited
to IP subnets, families, user settings, and


&gt; What about a heterogenous IPv4 / IPv6 network, where
&gt; IPv4-only relays can't connect to IPv6-only relays?

This one would fit more into "alternative topologies", but I think the
design can handle that.  (See proposal 300 section 3.9.)

The way it would work is, you put IPv4-only relays into group A,
dual-stack relays in group B, and IPv6 relays into group C.

Then you give them different successor lists, so that A has successor
in A and B, C has successors in B and C, and B can have all
successors.

&gt; If we do decide to add IPv6-only relays, we'll probably add
&gt; them in this order:
&gt; * IPv6-only bridges (needs dual-stack bridge guards / middles?)
&gt; * IPv6-only exits (needs dual-stack middles)
&gt; * IPv6-only guards (needs dual-stack middles)
&gt; * IPv6-only middles (needs dual-stack or IPv6-only guards and
&gt;    exits, removes need for dual-stack middles)
&gt;
&gt; What about bridge guards?
&gt; (That is, can bridges add an extra hop into circuits, to protect
&gt; themselves from being discovered by middles?)

Yes, that should still work with the base design.  I'll need to think
more about how it would work in non-clique topologies, though.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200320130137</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-03-20 13:01:37-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

On Wed, Mar 18, 2020 at 11:21 AM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; &gt; On 14 Mar 2020, at 14:44, teor &lt;teor@riseup.net&gt; wrote:
&gt; &gt;
&gt; &gt;&gt;  * As I work, I'm identifying other issues in tor that stand in
&gt; &gt;&gt;    the way of a good efficient walking onion implementation that
&gt; &gt;&gt;    will require other follow-up work.  This week I ran into a
&gt; &gt;&gt;    need for non-TAP-based v2 hidden services, and a need for a
&gt; &gt;&gt;    more efficient family encoding.  I'm keeping track of these
&gt; &gt;&gt;    in my outline file.
&gt;
&gt; Here's another issue you might want to consider:
&gt;
&gt; Currently, new relays get in the consensus as soon as:
&gt;   * they post their descriptors, and
&gt;   * a majority of authorities can contact their ORPorts.
&gt;
&gt; That means clients and relays waste a whole bunch of bandwidth
&gt; downloading consensus info and descriptors for relays with very
&gt; low weights.
&gt;
&gt; Instead, we could have two documents:

Thanks for this! This dovetails nicely with some of the voting design
work I'm up to right now.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200320163738</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-20 16:37:38-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

[Attachment #2 (multipart/signed)]


Hi Nick,

&gt; On 20 Mar 2020, at 23:01, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt; On Wed, Mar 18, 2020 at 11:21 AM teor &lt;teor@riseup.net&gt; wrote:
&gt;&gt; 
&gt;&gt;&gt; On 14 Mar 2020, at 14:44, teor &lt;teor@riseup.net&gt; wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; * As I work, I'm identifying other issues in tor that stand in
&gt;&gt;&gt;&gt;   the way of a good efficient walking onion implementation that
&gt;&gt;&gt;&gt;   will require other follow-up work.  This week I ran into a
&gt;&gt;&gt;&gt;   need for non-TAP-based v2 hidden services, and a need for a
&gt;&gt;&gt;&gt;   more efficient family encoding.  I'm keeping track of these
&gt;&gt;&gt;&gt;   in my outline file.
&gt;&gt; 
&gt;&gt; Here's another issue you might want to consider:
&gt;&gt; 
&gt;&gt; Currently, new relays get in the consensus as soon as:
&gt;&gt;  * they post their descriptors, and
&gt;&gt;  * a majority of authorities can contact their ORPorts.
&gt;&gt; 
&gt;&gt; That means clients and relays waste a whole bunch of bandwidth
&gt;&gt; downloading consensus info and descriptors for relays with very
&gt;&gt; low weights.
&gt;&gt; 
&gt;&gt; Instead, we could have two documents:
&gt; 
&gt; Thanks for this! This dovetails nicely with some of the voting design
&gt; work I'm up to right now.

It would be great to have a protocol that doesn't depend on:
* time synchronisation
* big documents
* one-shot updates
* absolute consistency

We've already made vote timing a bit more robust in the tor master
branch, by ignoring late votes:
https://trac.torproject.org/projects/tor/ticket/4631

Here's a few other tweaks that might help:

Tor halves the consensus interval when there is no fresh consensus.
But changing the interval makes tor's code much more complex.
Instead, let's have a fixed consensus interval. And make it long
enough for efficiency, but short enough to recover from a failed
consensus.

Let's support vote diffs, as well as consensus diffs. Vote diffs
don't help when posting votes. But when requesting votes, authorities
can include hashes of votes they already have. That way, authorities
that are under heavy load are more likely to get all the votes.

We could increase the time that authorities have to fetch votes, and
make them retry fetches every few minutes.

We could do consistency checks on smaller shards, so that a
consistency failure in any one document does not break the entire
consensus.

We could create a shard for each supported consensus method (like we
do microdescriptors). That way, a consistency failure in any one
consensus method does not break the entire consensus.

We could make shards valid for a longer time, so that if the
replacement shard does not reach consensus, the older one is used.

Then, the final documents are a combination of all the consistent
shards, using the highest consistent consensus method. (Much like
the current microdesc consensus.)

Once we've made some of those changes, then some other changes
become plausible:

Let's make votes valid for exactly 2 voting periods, and use the
latest available vote from each authority.

Currently, each consensus can have one of two inputs from each
authority:
* the current vote, or
* no vote.
If a majority of authorities don't vote, then the consensus fails.
(And if enough bandwidth authorities don't vote, then measured
bandwidths fail.)

If there are up to two valid votes during a voting period, then
each consensus can have one of three inputs from each authority:
* the current vote, or
* the vote before the current vote, or
* no vote.
Having 3 possible choices is slightly worse than having 2 choices.

But with the changes above, authorities are more likely to have the
latest vote from each other authority. And having similar votes
will be enough for most of the shards to be consistent, for most
consensus methods.

If a majority of authorities don't have any valid votes, then the
consensus fails. But that's much less likely when there are two
valid votes at any one time.

We could also make each authority construct its own merkle root(s),
and allow the N most popular/recent roots on the network.
(Or equivalently, allow roots with current signatures from M
authorities.)

We could split votes into shards as well, and make authorities
exchange them like they exchange relay descriptors?
(When they see a reference to a new vote shard, they try to
download it from all other authorities.)

We'd need extra monitoring, to make sure that diffs, authorities,
shards, consensus methods, or latest votes aren't consistently
broken.

Maybe there's a few more steps we could take, and then we'd have
a voting protocol that doesn't require strict time
synchronisation. Where updates just happen as authorities make
them available, rather than all at once.

T



["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl508VIACgkQEP6qDnB1
Zyq4Wg/+KLhMvyI6ji5nmaV2XkRqvctrcAl3lMylr7Pi7iHupFcHAVM3AaHgSNlr
tkZCURY6c34bslJPShu3Go0LL2keA6tydYlRK6PdTZw8ZQ5QtL1U3lB2WimlYbqs
4H/gzWfA8dcdTcukAbvnIteePpw+50YbxIk5ax6RHYUNXJr2KMzX+Co5uj5vczwl
ixvawMjfeJ/y4vYkHRUR4/NLivSEqTMx+b4gwMSEakzqTDMLRK4JHTLMfmSrxSWq
XAHPXc7s7OHfK2CXdNYb9R+aBjxdmoDvDeWw9W3/zShcd57yFr4kkfWaNwZZdISf
YLNR1i1naPpqeKWGse9zcUd9rXcw+B0Z0XSrIY1ktT2F5oKFe3lu+MLoOT5IvRiL
Xk0A7kcre29LBTtIqvwjOrn1y5pYGUrFoZW+AFpgWhIuLknPQ2jwpdGALxtF8KLc
yzHD8r8GtKEV4QBRzrZHEc6+pWPsk/jGtdY78xmDjbY91ELevSzfjFJ+ZZYoCRA8
XPzDC+WFYob5IyuEcVrZ6eY4svxf+9fIEnaDImdS/I4R4+WwJfTjf3oFh+kySIVw
qqgGRC7FusFMgL2G84dGNk4MMAsnVtiaWdsq944TvhK9DOOFKzKJ0kSlb8LBA2tI
lgwJPsbsqzhnemjUCzPlEutODKAXRNKUEDBzx3CtUjsm1TzvV+g=
=Hof/
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200329205635</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-03-29 20:56:35-0400</timestampReceived><subject>Re: [tor-dev] Walking Onions status update: week 2 notes</subject><body>

On Fri, Mar 20, 2020 at 12:38 PM teor &lt;teor@riseup.net&gt; wrote:
&gt;
&gt; Hi Nick,
&gt;
&gt; &gt; On 20 Mar 2020, at 23:01, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; &gt;
&gt; &gt; On Wed, Mar 18, 2020 at 11:21 AM teor &lt;teor@riseup.net&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt;&gt; On 14 Mar 2020, at 14:44, teor &lt;teor@riseup.net&gt; wrote:
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; * As I work, I'm identifying other issues in tor that stand in
&gt; &gt;&gt;&gt;&gt;   the way of a good efficient walking onion implementation that
&gt; &gt;&gt;&gt;&gt;   will require other follow-up work.  This week I ran into a
&gt; &gt;&gt;&gt;&gt;   need for non-TAP-based v2 hidden services, and a need for a
&gt; &gt;&gt;&gt;&gt;   more efficient family encoding.  I'm keeping track of these
&gt; &gt;&gt;&gt;&gt;   in my outline file.
&gt; &gt;&gt;
&gt; &gt;&gt; Here's another issue you might want to consider:
&gt; &gt;&gt;
&gt; &gt;&gt; Currently, new relays get in the consensus as soon as:
&gt; &gt;&gt;  * they post their descriptors, and
&gt; &gt;&gt;  * a majority of authorities can contact their ORPorts.
&gt; &gt;&gt;
&gt; &gt;&gt; That means clients and relays waste a whole bunch of bandwidth
&gt; &gt;&gt; downloading consensus info and descriptors for relays with very
&gt; &gt;&gt; low weights.
&gt; &gt;&gt;
&gt; &gt;&gt; Instead, we could have two documents:
&gt; &gt;
&gt; &gt; Thanks for this! This dovetails nicely with some of the voting design
&gt; &gt; work I'm up to right now.
&gt;
&gt; It would be great to have a protocol that doesn't depend on:
&gt; * time synchronisation
&gt; * big documents
&gt; * one-shot updates
&gt; * absolute consistency

Hi!  I think that _some_ of these changes are orthogonal to the shifts
we'll need for walking onions, but some of them do dovetail nicely.
I'm going to keep this email as a note to myself, so that I can
double-check whether any of these items are precluded by choices I'm
making in the design space.

&gt; We've already made vote timing a bit more robust in the tor master
&gt; branch, by ignoring late votes:
&gt; https://trac.torproject.org/projects/tor/ticket/4631
&gt;
&gt; Here's a few other tweaks that might help:
&gt;
&gt; Tor halves the consensus interval when there is no fresh consensus.
&gt; But changing the interval makes tor's code much more complex.
&gt; Instead, let's have a fixed consensus interval. And make it long
&gt; enough for efficiency, but short enough to recover from a failed
&gt; consensus.

This makes sense; I'd forgotten that we did this.

&gt; Let's support vote diffs, as well as consensus diffs. Vote diffs
&gt; don't help when posting votes. But when requesting votes, authorities
&gt; can include hashes of votes they already have. That way, authorities
&gt; that are under heavy load are more likely to get all the votes.

Actually, we *can* do them when posting votes; I've sketched out a
design here in the work-in-progress voting spec.


&gt; We could increase the time that authorities have to fetch votes, and
&gt; make them retry fetches every few minutes.
&gt;
&gt; We could do consistency checks on smaller shards, so that a
&gt; consistency failure in any one document does not break the entire
&gt; consensus.

This seems like something we could do as a followup here? It does seem
like it could get pretty complex.

&gt; We could create a shard for each supported consensus method (like we
&gt; do microdescriptors). That way, a consistency failure in any one
&gt; consensus method does not break the entire consensus.

Hm, interesting.  This would involve generating multiple consensuses
with different methods?  It sounds orthogonal to me, but quite
possibly a good idea.  But we'd have to withhold signatures on older
consensus methods until we're sure that the newer ones are failing --
and I worry about attacks where we _cause_ a newer consensus method to
be inconsistent specifically so we can force an older one.

I also worry about mix-and-match attacks on the different shards.

&gt; We could make shards valid for a longer time, so that if the
&gt; replacement shard does not reach consensus, the older one is used.
&gt;
&gt; Then, the final documents are a combination of all the consistent
&gt; shards, using the highest consistent consensus method. (Much like
&gt; the current microdesc consensus.)
&gt;
&gt; Once we've made some of those changes, then some other changes
&gt; become plausible:
&gt;
&gt; Let's make votes valid for exactly 2 voting periods, and use the
&gt; latest available vote from each authority.

Hmmm. So this doesn't help us much in the case when an authority goes
down -- it just means that its vote counts for an extra hour more than
it would otherwise.  That would buy us an hour of extra consensus time
-- but it would only be a big improvement if the authority is
-regularly- failing to upload a vote.  For that case, I think it might
make more sense  to address the reliability problem directly instead
of trying to work around it.

&gt; [...]

I dig the idea of dropping time synchronization if we can; let's look
into this more.  It seems like something we can do orthogonally to
walking onions, though?


-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200330024529</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-30 02:45:29-0400</timestampReceived><subject>Re: [tor-dev] Walking onions status update: week 4 notes</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Nick,

&gt; On 30 Mar 2020, at 09:18, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; Walking Onions: week 4 update
&gt; 
&gt; 
&gt; 
&gt; == Next steps
&gt; 
&gt; In this coming week I plan to try to wrap up section 3 on voting and
&gt; section 5 on extending circuits.  I'm going to go back to the start
&gt; of section 2 and start revising all I've written so far for
&gt; consistency.

Some typos, ambiguities, and questions:

In the client and relay root documents:

require-versions should be require-protos

In the voting description:

It seems weird to suddenly add a ".txt" extension to tor's
directory URLs. No other directory URL has an extension.
(Apart from DirPortFrontPage.)

This sentence fragment is ambiguous:
"more than half of two" for example, means "at least 1",
not "one or more"
I suggest:
"more than half of two" for example, means "greater than 1",
not "one or more"

N_PRESENT is a typo here:
The lowest integer that is greater than half of N_FIELD.
Equivalent to CEIL( (N_PRESENT+1)/2 ).

Do we need a list of MDs, one for each consensus method range?
   ? md_literal : LiteralMD,

Measured is a uint, not a bool:
   ? weight : {
      bw : uint,
      ? measured : bool,
      ? unmeasured : bool
   },
https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt#n2432

In the DirPort link specifiers:

IPv6 addresses MUST be in square brackets.
(To avoid port/address confusion.)

&gt; [EXTENDING] https://github.com/nmathewson/walking-onions-wip/blob/master/specs/05-extending-circuits.md
&gt;  
&gt; [VOTING]  https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-voting-and-authorities.md
&gt;  
&gt; [WIDE_EVERYTHING]
&gt; https://github.com/nmathewson/walking-onions-wip/blob/master/other-proposals/xxx-wide-everything.md
&gt; 

T


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div dir="ltr"&gt;Hi \
Nick,&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;blockquote type="cite"&gt;On 30 Mar 2020, \
at 09:18, Nick Mathewson &lt;nickm@torproject.org&gt; \
wrote:&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div \
dir="ltr"&gt;&lt;span&gt;Walking Onions: week 4 \
update&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;== Next \
steps&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;In this coming week I plan to try to wrap up \
section 3 on voting and&lt;/span&gt;&lt;br&gt;&lt;span&gt;section 5 on extending circuits. I'm \
going to go back to the start&lt;/span&gt;&lt;br&gt;&lt;span&gt;of section 2 and start revising all \
I've written so far for&lt;/span&gt;&lt;br&gt;&lt;span&gt;consistency.&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div \
dir="ltr"&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; line-height: \
normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Some typos, ambiguities, \
and questions:&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: normal; \
line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;In the client \
and relay root documents:&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: \
normal; line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: \
auto;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;require-versions should be require-protos&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" \
style="margin: 0px; font-stretch: normal; line-height: normal; min-height: 20.3px; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;In the voting \
description:&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;It seems weird \
to suddenly add a ".txt" extension to tor's&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: \
0px; font-stretch: normal; line-height: normal; -webkit-text-size-adjust: \
auto;"&gt;&lt;span class="s1"&gt;directory URLs.&lt;/span&gt;No other directory URL has an \
extension.&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; line-height: \
normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;(Apart from \
DirPortFrontPage.)&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; font-stretch: normal; \
line-height: normal; min-height: 20.3px; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;This sentence \
fragment is ambiguous:&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;"more \
than half of two" for example, means "at least 1",&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;not "one or more"&lt;/span&gt;&lt;/p&gt;&lt;p \
class="p1" style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;I suggest:&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;"more than half of two" for \
example, means "greater than 1",&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;not "one or more"&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="margin: 0px; \
font-stretch: normal; line-height: normal; min-height: 20.3px; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;N_PRESENT is a typo \
here:&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; line-height: \
normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;The lowest integer that is \
greater than half ofN_FIELD.&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;Equivalent to CEIL( (N_PRESENT+1)/2 ).&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" \
style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;Do we need a list of MDs, one for each consensus \
method range?&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; line-height: \
normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;? \
md_literal : LiteralMD,&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: \
normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;Measured is a \
uint, not a bool:&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt; ? weight : {&lt;/p&gt;&lt;p \
class="p1" style="margin: 0px; font-stretch: normal; line-height: normal; \
-webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;  bw : \
uint,&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; line-height: \
normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;  ? \
measured : bool,&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span class="s1"&gt;  \
? unmeasured : bool&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; font-stretch: normal; \
line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;},&lt;/span&gt;&lt;/p&gt;&lt;p class="p1" style="margin: 0px; \
font-stretch: normal; line-height: normal; -webkit-text-size-adjust: auto;"&gt;&lt;span \
class="s1"&gt;&lt;a href="https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt#n2432" \
&gt;https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt#n2432&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div \
&gt; dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;In the DirPort link specifiers:&lt;/div&gt;&lt;div \
&gt; dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;IPv6 addresses MUST be in square \
&gt; brackets.&lt;/div&gt;&lt;div dir="ltr"&gt;(To avoid port/address \
&gt; confusion.)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div \
&gt; dir="ltr"&gt;&lt;span&gt;[EXTENDING] \
&gt; https://github.com/nmathewson/walking-onions-wip/blob/master/specs/05-extending-circuits.md&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;[VOTING] \
&gt; https://github.com/nmathewson/walking-onions-wip/blob/master/specs/02-voting-a \
&gt; nd-authorities.md&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;[WIDE_EVERYTHING]&lt;/span&gt;&lt;br&gt;&lt;span \
&gt; &gt;https://github.com/nmathewson/walking-onions-wip/blob/master/other-proposals/xxx-wi \
&gt; &gt; de-everything.md&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;T&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;
&gt; &gt; 


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200330025505</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-30 02:55:05-0400</timestampReceived><subject>Re: [tor-dev] Walking onions status update: week 3 notes</subject><body>

Hi Nick,

This is from week 3:

&gt; On 30 Mar 2020, at 07:16, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt;&gt; There's a faster calculation and more efficient encoding for
&gt;&gt; Weighted, because there's a common factor in each POS()
&gt;&gt; calculation:
&gt;&gt; (1 &lt;&lt; 32) / total_weight
&gt;&gt; 
&gt;&gt; If we remove that factor, we end up with a much simpler algorithm,
&gt;&gt; that's also more flexible:
&gt;&gt; 
&gt;&gt; Algorithm: Expanding a "Weighted" indexspec.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Each weighted indexspec also has a multiplier, which may vary
&gt;&gt; 
&gt;&gt; between indexspecs.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Let total_weight = SUM(indexspec.index_weights)
&gt;&gt; 
&gt;&gt; Verify total_weight * multiplier &lt;= UINT64_MAX.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Let total_so_far = 0.
&gt;&gt; 
&gt;&gt; Let result_idx = {} (an empty mapping).
&gt;&gt; 
&gt;&gt; Define POS(b) = b * multiplier
&gt;&gt; 
&gt;&gt; 
&gt;&gt; For 0 &lt;= i &lt; LEN(indexspec.indexweights):
&gt;&gt; 
&gt;&gt;   Let w = indexspec.indexweights[i].
&gt;&gt; 
&gt;&gt;   Let lo = POS(total_so_far).
&gt;&gt; 
&gt;&gt;   Let total_so_far = total_so_far + w.
&gt;&gt; 
&gt;&gt;   Let hi = POS(total_so_far) - 1.
&gt;&gt; 
&gt;&gt;   Append (lo, hi) =&gt; i to result_idx.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Return result_idx.
&gt; 
&gt; I'm not so sure about this one -- see the note below about the total value.
&gt; 
&gt;&gt; If multiplier is large, then the weights can be quite small.
&gt;&gt; 
&gt;&gt; (Small weights sacrifice some accuracy.) And if the multiplier
&gt;&gt; 
&gt;&gt; is 1, you effectively have a "Raw" index.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; If you make those changes, you should be able to use a similar
&gt;&gt; process to expand all the different index types. (After multiplying,
&gt;&gt; truncating, or hashing, you either end up with a delta, or an
&gt;&gt; absolute position. You can turn deltas into absolute positions,
&gt;&gt; and then feed them all into the same base algorithm.)
&gt;&gt; 
&gt;&gt; There are also a few things I think might be bugs:
&gt;&gt; 
&gt;&gt; Was there meant to be a constraint that the Weighted total is
&gt;&gt; UINT64_MAX? Or close to UINT64_MAX?
&gt; 
&gt; The actual intention is that it has to be " = UINT32_MAX", not" &lt;=
&gt; UINT32_MAX".  Remember that the the client picks its next relay by
&gt; specifying a random index value in range 0..UINT32_MAX, and it expects
&gt; that the relay to that it is extending to _will_ have a snip that
&gt; covers that range.
&gt; 
&gt;&gt; The fixed parameters don't make much sense otherwise.

Hmm, ok, then if we use multiplication, there are going to be some issues
with the cumulative error from truncating the original division.

The error won't be too big, on average, it's N/2, worst case, it's N. (Where
N is the number of indexes.) That's a tiny amount for large weights, but a
huge amount for small weights. (Assuming that we continue to vote for
relays with weights 1-100.)

But divisions also have some cumulative error.

Once you've revised these sections, let's review?

Only doing one division on the authorities is very appealing.

T

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200330032221</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-03-30 03:22:21-0400</timestampReceived><subject>Re: [tor-dev] Chutney tests fail for tor/maint-0.3.5 (bug #33677)</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

&gt; On 28 Mar 2020, at 21:42, c &lt;c@chroniko.jp&gt; wrote:
&gt; 
&gt; For the Outreachy.org internship project I decided to take on bug
&gt; #33677 [1].

Thanks for applying for Outreachy with us.

&gt; I followed steps to run `make test-network-all` both on tor master and
&gt; maint-0.3.5 branches, using Chutney master branch. I tested before and
&gt; after tweaking value of HS_WAIT_FOR_UNCHECKED_DIR_INFO just to ensure
&gt; my testing environment was sane; all tests passed (except for two that
&gt; were skipped on master: mixed+hs-v23 and mixed+hs-v23-ipv6, and one
&gt; on 0.3.5: mixed+hs-v2, I assume this is expected though) on the first
&gt; go, on both branches of Tor.
&gt; 
&gt; Tests pass on Tor master after setting HS_WAIT_FOR_UNCHECKED_DIR_INFO
&gt; to 0, but on maint-0.3.5 I've run tests a few times (both with and
&gt; without CHUTNEY_DEBUG set) each time with a different outcome. Some of
&gt; the tests which fail: basic-min [2], single-onion-v23 [3],
&gt; bridges+ipv6-min [4], and ipv6-exit-min [5]. I have excerpted logs at
&gt; the bottom of this message, narrowed down to test failures; let me know
&gt; if I need to provide full logs or additional information.
&gt; 
&gt; I'll keep digging on this issue; I just wanted to show my current
&gt; progress and share what I hope to be useful information.

Thank you for letting us know what you've done so far. And for providing
comprehensive logs.

This ticket is a cleanup ticket, after some other changes have been made.
I've edited the ticket description to make that clearer.

So we expect that the chutney tests will fail with
HS_WAIT_FOR_UNCHECKED_DIR_INFO = 0, until the following changes
have been merged:

Check for relay microdescriptor downloads:
 https://trac.torproject.org/projects/tor/ticket/33428

Check for onion service descriptor uploads:
https://trac.torproject.org/projects/tor/ticket/33609

Someone else is working on the microdescriptor changes at the moment.

Would you like to start working on the onion service descriptor changes?

T

&gt; [1]: &lt;https://trac.torproject.org/projects/tor/ticket/33677&gt;
&gt;     "Stop waiting a set time for onion service descriptors"

[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div \
dir="ltr"&gt;&lt;div&gt;Hi,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;blockquote \
type="cite"&gt;On 28 Mar 2020, at 21:42, c &lt;c@chroniko.jp&gt; \
wrote:&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;span&gt;For the \
Outreachy.org internship project I decided to take on bug&lt;/span&gt;&lt;br&gt;&lt;span&gt;#33677 \
[1].&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks for applying for \
Outreachy with us.&lt;/div&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;span&gt;I followed \
steps to run `make test-network-all` both on tor master \
and&lt;/span&gt;&lt;br&gt;&lt;span&gt;maint-0.3.5 branches, using Chutney master branch. I tested \
before and&lt;/span&gt;&lt;br&gt;&lt;span&gt;after tweaking value of HS_WAIT_FOR_UNCHECKED_DIR_INFO \
just to ensure&lt;/span&gt;&lt;br&gt;&lt;span&gt;my testing environment was sane; all tests passed \
(except for two that&lt;/span&gt;&lt;br&gt;&lt;span&gt;were skipped on master: mixed+hs-v23 and \
mixed+hs-v23-ipv6, and one&lt;/span&gt;&lt;br&gt;&lt;span&gt;on 0.3.5: mixed+hs-v2, I assume this is \
expected though) on the first&lt;/span&gt;&lt;br&gt;&lt;span&gt;go, on both branches of \
Tor.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;Tests pass on Tor master after setting \
HS_WAIT_FOR_UNCHECKED_DIR_INFO&lt;/span&gt;&lt;br&gt;&lt;span&gt;to 0, but on maint-0.3.5 I've run \
tests a few times (both with and&lt;/span&gt;&lt;br&gt;&lt;span&gt;without CHUTNEY_DEBUG set) each time \
with a different outcome. Some of&lt;/span&gt;&lt;br&gt;&lt;span&gt;the tests which fail: basic-min \
[2], single-onion-v23 [3],&lt;/span&gt;&lt;br&gt;&lt;span&gt;bridges+ipv6-min [4], and ipv6-exit-min \
[5]. I have excerpted logs at&lt;/span&gt;&lt;br&gt;&lt;span&gt;the bottom of this message, narrowed \
down to test failures; let me know&lt;/span&gt;&lt;br&gt;&lt;span&gt;if I need to provide full logs or \
additional information.&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;I'll keep digging on this \
issue; I just wanted to show my current&lt;/span&gt;&lt;br&gt;&lt;span&gt;progress and share what I \
hope to be useful information.&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thank \
you for letting us know what you've done so far. And for \
providing&lt;/div&gt;&lt;div&gt;comprehensive logs.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This ticket is a \
cleanup ticket, after some other changes have been made.&lt;/div&gt;&lt;div&gt;I've edited the \
ticket description to make that clearer.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So we expect that \
the chutney tests will fail with&lt;/div&gt;&lt;div&gt;HS_WAIT_FOR_UNCHECKED_DIR_INFO = 0, until \
the following changes&lt;/div&gt;&lt;div&gt;have been merged:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Check for \
relay microdescriptor downloads:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/33428"&gt;https://trac.torproject.org/projects/tor/ticket/33428&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Check \
for onion service descriptor uploads:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://trac.torproject.org/projects/tor/ticket/33609"&gt;https://trac.torproject.org/projects/tor/ticket/33609&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Someone \
else is working on the microdescriptor changes at the \
moment.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Would you like to start working on the onion service \
descriptor changes?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;span&gt;[1]: \
&lt;https://trac.torproject.org/projects/tor/ticket/33677&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt; \
"Stop waiting a set time for onion service \
descriptors"&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200330144526</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-03-30 14:45:26-0400</timestampReceived><subject>Re: [tor-dev] Improving onion service availability during DoS using anonymous credentials</subject><body>

George Kadianakis &lt;desnacked@riseup.net&gt; writes:

&gt; Hello list,
&gt;
&gt; there has been lots of discussions about improving onion service availability
&gt; under DoS conditions. Many approaches have been proposed [OOO] but only a few
&gt; have been tried and even fewer show any real improvements to the availability
&gt; of the service.
&gt;
&gt; An approach that we've been considering is the use of anonymous credentials as
&gt; a way to prioritize good clients from bad clients. The idea is that the service
&gt; gives tokens to clients it believes to be good, and prioritizes client with
&gt; tokens over clients without tokens whenever possible. This is a post to start a
&gt; discussion of how such approaches could work and whether they are worth
&gt; pursuing futher.
&gt;
&gt; == Preliminaries ==
&gt;
&gt; === When should the access control take place? ===
&gt;
&gt; Doing DoS defenses with anon credentials is all about enforcing access control
&gt; at the right point of the protocol so that the amplification factor of evil
&gt; clients gets cut as early as possible.
&gt;
&gt; Very roughly the phases of the onion service protocol are: descriptor fetch
&gt; phase, intro phase, rendezvous phase. Let's see how those look like for the
&gt; purposes of access control:
&gt;
&gt; - Doing the access control during the descriptor fetch stage is something worth
&gt;   considering because it's the first phase of the protocol and hence the
&gt;   earliest and best place to soak up any damage from evil clients. There is
&gt;   already a form of optional access control implemented here called "client
&gt;   authorization" and it's worth thinking of what's lacking to make it useful
&gt;   against DoS attackers. I'm gonna address this in section [CLIENTAUTH].
&gt;
&gt; - Doing the access control during the introduction phase is another fruitful
&gt;   approach. Blocking bad clients during introduction means that they dont get to
&gt;   force the service to create a costly rendezvous circuit, and since services
&gt;   have a long-term circuit open towards the intro points it makes it easier for
&gt;   services to pass access control related data to the intro point. This is
&gt;   actually the approach we are gonna be talking most about in this post.
&gt;
&gt; - Finally, doing the access control during the rendezvous phase is way too late
&gt;   since by that time the onion service has already spent lots of resources
&gt;   catering the evil client, so let's ignore that.
&gt;
&gt; === Entities of an anonymous credential system ===
&gt;
&gt; Anonymous credential systems traditionally have three entities that concern us:
&gt;
&gt;           - The Issuer:   the entity who issues the credentials/tokens
&gt;           - The Prover:   the entity who collects tokens and uses them to get access
&gt;           - The Verifier: the entity who verifies that tokens are legit and grants/restricts access
&gt;
&gt; In the world of onion services, the Issuer is naturally the onion service, and
&gt; the Prover is the onion service client. The Verifier could either be
&gt; the onion service itself or its introduction points. We will see below how this
&gt; could work and the relevant tradeoffs.
&gt;
&gt;          +--------+          +------------+           +--------------------+
&gt;          | Client |&lt;-+-+-+--&gt;|Intro point |&lt;--+---+--&gt;|Onion service       |
&gt;          |(Prover)|          |(Verifier?) |           |(Issuer)(Verifier?) |
&gt;          +--------+          +------------+           +--------------------+
&gt;
&gt;
&gt; === How do tokens get around? ===
&gt;
&gt; A main question here is "How do good clients end up with tokens?". For the
&gt; purposes of this post, we will assume that clients get these tokens in an out
&gt; of band fashion. For example, a journalist can give tokens to her sources over
&gt; Signal so they can use them with Securedrop. Or a forum operator can give
&gt; tokens to old-time members of the forum to be used during a DoS.
&gt;
&gt; A natural chicken-and-egg problem occurs here since how is an onion service
&gt; supposed to give tokens to its users if it's unreachable because of a DoS? We
&gt; realize this is a big problem and we are not sure exactly how to solve it. This
&gt; problem naturally limits the use of anonymous credential solutions, and sorta
&gt; makes them a second-layer of defense since it assumes a first-layer of defense
&gt; that allows operators to pass tokens to the good people. A first-layer approach
&gt; here could perhaps look like PrivacyPass where users get tokens by solving
&gt; CAPTCHAs.
&gt;
&gt; == Anonymous credentials ==
&gt;
&gt; By surveying the anonymous credential literature we have found various types of
&gt; anonymous credential schemes that are relevant for us:
&gt;
&gt; - Discrete-logarithm-based credentials based on blind signatures:
&gt;
&gt;     This is a class of anon credential schemes that allow us to separate the
&gt;     verifier from the issuer. In particular this means that we can have the
&gt;     service issue the tokens, but the introduction point being the verifier.
&gt;
&gt;     They are usually based on blind signatures like in the case of Microsoft's
&gt;     U-Prove system [UUU].
&gt;

After more discussions and investigations, it does seem blind-signature
based anonymous credentials is what we are looking for here. In
particular, the ability to separate the issuer and the verifier is
essential to us because it gives us more flexibility allowing us to:

- Do the verification at either the intro point or the service.
- Allow for third-party token issuers that issue tokens that can be
  later verified by the service or intro points. These third-party token
  issuers can even be on the clearnet which gives us more options when
  it comes to DoS defences.

For this reason I had a call with Michele Orr today who helped me
understand our options and constraints (Michele feel free to correct me
wherever I'm wrong). In particular, it seems like we have the following
options and none of them is perfect and none of them is ultra-terrible:

1) Blinded RSA signatures

   Anon credentials schemes that use blinded RSA signatures are the most
   old-school approach we have in our arsenal:
    https://en.wikipedia.org/wiki/Blind_signature#Blind_RSA_signatures

   They are the fastest option we have (in terms of verification
   performance -- our main performance concern), and the verification
   protocol can be competed in two messages which fit nicely into our
   introduction protocol.

   The problem is that their tokens have the biggest size (in terms of
   token size).  In particular, using tokens of this kind means that we
   will have to pass 2048-bit keys or 4096-bit keys around, plus their
   padding, plus potentially other stuff.

   We would need to look more on whether we can fit these schemes into
   our constraints. It seems like Facebook has recently started using
   RSA blinded signatures into their own anonymous credentials system:
      https://github.com/siyengar/private-fraud-prevention

2) Blinded Schnorr signatures

   Another approach would be to use blinded schnorr signatures over
   elliptic curves: https://eprint.iacr.org/2019/877.pdf

   This results in a scheme with smaller tokens than RSA but worse
   performance. As Jeff mentioned, a token of this kind would be about
   100 bytes, where 32 bytes would go to an identifier t, and another 64
   bytes to an ed25519 signature. This is the scheme that Microsoft's
   UProve is using so perhaps we can use their benchmarks to measure its
   performance.

   The main problem here is that this is a 3-message verification
   protocol where the first message starts from verifier. Furthermore,
   this first message needs to include a fresh nonce, so we could not
   just use the descriptor for this first message. More research
   required here to see if we can still fit it in somehow.

   Another spicy thing here is that there is an attack called "ROS" that
   applies to these schemes. This obscure attack allows the adversary to
   obtain an extra issued token by opening multiple simultaneous
   issuance connections to the issuer. There is a fix (in section 5 of
   the 877.pdf paper above) with an equally weird countermeasure where
   users during token issuance execute two parallel runs of the issuance
   protocol but only finish one of them at random... As Jeff mentioned,
   it's likely that this attack won't apply or affect our DoS threat
   model, but it's something we should definitely keep in mind.

2) Blinded BLS signatures

   The final approach here is doing blinded signatures using the BLS
   signature scheme:
             https://en.wikipedia.org/wiki/Boneh%E2%80%93Lynn%E2%80%93Shacham
             https://crypto.stackexchange.com/a/12832 (yes that's an SE link...)
             https://hackmd.io/@benjaminion/bls12-381

   This results in a 2-message verification protocol with small tokens
   (about the size of blinded schnorr sigs), but worse performance than
   all of the above schemes (about 25ms eyeballed but we should look at
   https://crypto.stanford.edu/pbc/ for more information).

   Furthermore, this is a pairing-base cryptosystem so it comes with the
   bleeding-edge-wow factor of pairings. It seems like various groups
   (including zcash and ethereum) have been using BLS signatures, but
   none of them have used it for blinded signatures, so we would be in
   for a ride.

All in all, these are the options we seem to have. There are tradeoffs
to all of them, and potential blockers with some of them
(e.g. 3-messages of Schnorr sigs). We should dig deeper into all these
schemes, and also talk with more people in case there are schemes we are
missing or things I misunderstood about these ones.

Finally, anonymous credentials based on the above schemes are
lightweight "use-token-and-forget-it" token schemes. It's not as easy to
encode complicated attributes into them, or make them accumulate
reputation, or blacklist them. To do revocation/blacklisting here you
basically should stop issuing new tokens to the bad parties, but they
still get to use their old tokens since they are indistinguishable from
any other tokens issued. It might still be possible to achieve some of
that by splitting users into different groups by using different keys
for each group, so that additional information can be encoded on the
type of group used.

That's it for now.

Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200205033813</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-05 03:38:13-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

&gt; On 4 Feb 2020, at 07:17, s7r &lt;s7r@sky-ip.org&gt; wrote:
&gt; 
&gt; teor wrote:
&gt;&gt; Hi s7r,
&gt;&gt; 
&gt;&gt; Thanks for bringing up IPv6 address privacy extensions.
&gt;&gt; 
&gt;&gt;&gt; On 30 Jan 2020, at 02:19, s7r &lt;s7r@sky-ip.org&gt; wrote:
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; I read RFCs 4941 and 3041, looked at the tor directory spec, and did some
&gt;&gt; analysis:
&gt;&gt; * tor clients get new relay addresses within 4.5 hours
&gt;&gt; * IPv6 privacy extensions rotate addresses every day (by default)
&gt;&gt; * IPv6 privacy extensions remove old addresses after a week (by default)
&gt;&gt; 
&gt;&gt; (And applications have to opt-in to IPv6 privacy extensions addresses,
&gt;&gt; by default, according to the RFC.)
&gt;&gt; 
&gt;&gt; Therefore, I don't think tor relays or clients will be affected by relays
&gt;&gt; using IPv6 privacy extensions.
&gt;&gt; 
&gt;&gt; See my detailed analysis here:
&gt;&gt; https://github.com/torproject/torspec/pull/105/files#diff-28c992d72bedaa9378a4f3627afb8694R816
&gt; 
&gt; Thanks for looking into it!
&gt; 
&gt; I agree with your analysis fully. However, I just think it would be
&gt; better if we mention in proposal 312 explicitly that Tor should try hard
&gt; to get an IPv6 address that has the desired state, and use that. It is
&gt; true that this is different on each operating system, but the operating
&gt; systems we most care about should be pretty trivial to patch for this
&gt; change.
&gt; 
&gt; IPv6 addresses have multiple states. We simply request for one that has
&gt; state `public` and not `temporary`.
&gt; (https://tools.ietf.org/html/rfc3484).

I've made this change to the proposal, using similar wording to what
you wrote in your previous email:

https://github.com/torproject/torspec/pull/105/commits/ca8dfa983ad78d67f68a6f0fff0a9dd90ec8c5f2

Here's why I didn't make it a mandatory change:

Tor supports address detection using DNS, and detection of the public
address of any NAT box between tor and the internet. Therefore, the
address tor publishes in its descriptor may not be on the local
machine.

Here are the relevant address detection methods:

1. Address hostname
2. ORPort hostname
(method 3 only uses local information)
4. auto hostname
5. auto dir header

Therefore, it's not possible for tor to reliably find out the IPv6
address privacy extensions status of these addresses.

(Some operators also use sandboxes that block the relevant APIs.)

&gt; In the current form of this proposal, it looks kind of optional ("We
&gt; propose this optional change, to improve...").

IPv6 privacy extensions are an optional change for Sponsor 55.

Sponsor 55 covers relay IPv6 reachability checks, address auto-detection,
and basic IPv6 statistics. It's a small sponsor, so we need to focus on
the changes that are required to achieve these goals.

We'll choose which optional changes we implement and test, after all the
required changes are implemented and tested.

As I wrote to Nick:

&gt;&gt;&gt; I'm trying to keep a clear distinction in this proposal, to keep the
&gt;&gt;&gt; sponsor 55 scope manageable. So I am keeping different sections for:
&gt;&gt;&gt;  * required changes: changes that we must make to achieve the objectives
&gt;&gt;&gt;                      of sponsor 55
&gt;&gt;&gt;  * optional changes: good ideas that we can implement if we have time left
&gt;&gt;&gt;                      in sponsor 55, or in future IPv6 work

&gt; sbws of course should account relays per IPv6 prefix, and not per
&gt; address. Usually we should be able to determine if an address is in the
&gt; same /64 IPv6 subnet and not reset the bandwidth measurement because
&gt; most probably it is the same relay. A /64 is standard, however there are
&gt; ISPs that do now follow the standard in assigning /64 to end users and
&gt; sometimes assign /112 or strange things like that. So this can become
&gt; complicated again. Which is why it is more simple to always ask for a
&gt; `public` IPv6 address and ignore `temporary` ones. I think it's simpler
&gt; and more efficient than changing sbws.

I don't think we'll be back porting any code changes that make relays
avoid IPv6 privacy extensions addresses.

Also, any IPv6 privacy extensions code probably won't work on all of our
supported platforms:
https://trac.torproject.org/projects/tor/wiki/org/teams/NetworkTeam/SupportedPlatforms

So sbws will have to support relays which use IPv6 privacy extensions.

(sbws changes are out of scope for Sponsor 55, but we're looking for other
funding.)

&gt; ##### NOT DIRECTLY RELATED TO PROPOSAL 312 SECTION #####
&gt; These privacy extensions IPv6 addresses might be good for outgoing IPv6
&gt; exit connections, like changing per circuit or per destination to get
&gt; rid of captchas and blacklists, but this is something different.

Feel free to open a ticket for this feature.

&gt; Our internal DoS defense subsystem should also treat prefixes instead of
&gt; addresses, because right now with a client with a /64 public IPv6 prefix
&gt; assigned to it I could hammer via IPv6 guards without triggering the DoS
&gt; defense. This is is something different as well.

I opened a ticket for this security issue here:
https://trac.torproject.org/projects/tor/ticket/33156

I've also cc'd David, so he can take a look at this DoS subsystem bug.

&gt; From my point of view all these should go under the same big `Tor-IPv6`
&gt; project, and get funded as well. So, there's quite some work ahead ;)

Yes, we're looking for funding for further IPv6 work. But we really need
more IPv6 relays, before we can make any IPv6 changes on clients.

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIyBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl46OKUACgkQEP6qDnB1
ZyrvIQ/4nslWt0tgmFZKFUHsQ0XhVJmEpGWku7CfW/51UjhuM/J+oLZ2pWhViyko
s6PyBkh9SIyEvLviMbB5lXlEvg6XLgBqoNyRfrdm6YRMb4EV8t3b63tvDldsdbpq
QRVeZQKwMiCtlSvGYHpjWj9iwAaAJVSLA5jt2Lb1hNQo1m4SV2v+kPJJ1dzw1b54
OfFRdgXljdfRGWijVMC2C83LyTZmTl5PksfbNrFYbof2X24s3neiPU26iWzuTkuL
rzaGf9yVGrlGsmyUqGx3i2LtYiiKD+DVOMgqqDSMeyoVhmJb0W9XeU7+8bgFK1Jp
5ylguLXk2BmrmOS4X1MmWQMK3r9F3JpTRd/3hJ8OgjauLH+tBVT2U7Zr+EXcCuLf
U1+Gt1/uSnpr5NL76URWyzt4q+96gjHt//aowC4g1btMSCzhda9DWh86AZEdZff8
KCcr/bDCQ6olqP54uSg5PMC2ZsiEtlZ5lu6h5Qn4Q3QcwmGLdm/0kL2KCG28BKiT
5dlvg0qEsFv1KRBWI1OiGupijdFm60a33GWBohBEj0wt9WjlD8Bl/b/A+ThHanKG
bMkyssoZuT+4L5yoTFdeaKM2m1HuGqC0Mjc0sek0WKe0fKy58bcU8EaiwgKNhjn6
6AfIBr026ow5m43C/veBYT3Q3L/jkKuYDswvn+WHHfeGgj34ZQ==
=a8eJ
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200206114202</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-02-06 11:42:02-0400</timestampReceived><subject>Re: [tor-dev] Request for onionbalance v3 pre-alpha testing</subject><body>

George Kadianakis &lt;desnacked@riseup.net&gt; writes:

&gt; Hello list,
&gt;
&gt; we've been developing Onionbalance v3 for the past months, and I'm
&gt; pretty hyped to say that the project has reached a stability point that
&gt; could benefit from some initial testing by curious and adventurous
&gt; developers and users.
&gt;

Hello people,

I haven't received much testing for onionbalance v3 yet, so I'm
shamelessly bumping this thread in hopes for more activity. I bet many
people would love to test this but they don't know it exists so perhaps
this works.

Also, I just uploaded this guide to my github so tha I can dynamically
update it if bugs are found by testers without having to post errata to
a mailing list: https://github.com/asn-d6/onionbalance/blob/master/docs/alpha-testing-v3.txt

Thanks!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200206172011</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-02-06 17:20:11-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 2/6/20 5:54 AM, George Kadianakis wrote:
&gt; 
&gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt; 
&gt;&gt; On 04 Feb (19:03:38), juanjo wrote:
&gt;&gt;
&gt;&gt; Greetings!
&gt;&gt;
&gt;&gt;&gt; Since no one is posting it here and talking about it, I will post it.
&gt;&gt;&gt;
&gt;&gt;&gt; https://nvd.nist.gov/vuln/detail/CVE-2020-8516
&gt;&gt;&gt;
&gt;&gt;&gt; The guy: http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
&gt;&gt;&gt;
&gt;&gt;&gt; Is this real?
&gt;&gt;&gt;
&gt;&gt;&gt; Are we actually not verifying if the IP of the Rend is a node in the Tor
&gt;&gt;&gt; network?
&gt;&gt;
&gt;&gt; We (network team) actually don't think this is a bug but it is actually done
&gt;&gt; on purpose for specific reasons. Please see asn's answer on
&gt;&gt; https://bugs.torproject.org/33129 that explains why that is.
&gt;&gt;
&gt;&gt; Onto the bigger issue at ends that the post explains. I'm going to extract the
&gt;&gt; relevant quote that this post is all about:
&gt;&gt;
&gt;&gt;     Remember: the guard rarely changes but the other two hops change often.
&gt;&gt;     If he can repeatedly map out my circuit's last node, then he can build a
&gt;&gt;     large exclusion list. If he can exclude everything else, then he can find
&gt;&gt;     my guard node. And if he can't exclude everything, then he can probably
&gt;&gt;     whittle it down to a handful of possible guard nodes.
&gt;&gt;
&gt;&gt; That is indeed a known attack. One can create a set of relays from the 3rd
&gt;&gt; node (last one before connecting to the rendezvous point) selected by the
&gt;&gt; service and doing enough requests to the service, you can end up with a very
&gt;&gt; large set of relays that can _not_ be your Guard due to how path selection
&gt;&gt; works as explained in the blog post.
&gt;&gt;
&gt; 
&gt; For what it's worth, I'm glad this discussion has been restarted because
&gt; we did lots of research work in 2018 about these sort of attacks, but we
&gt; were kinda drown in the various tradeoffs and ended up not doing much
&gt; after releasing the vanguard tool.
&gt; 
&gt; For people who are following from home and would like to help out here
&gt; is some reading materials:
&gt;    https://lists.torproject.org/pipermail/tor-dev/2018-April/013070.html
&gt;    https://lists.torproject.org/pipermail/tor-dev/2018-May/013162.html
&gt;    https://trac.torproject.org/projects/tor/ticket/25754
&gt; 
&gt; Basically, from what I remember, to defend against such attacks we
&gt; either need to change our path selection logic (#24487), or abandon the
&gt; path restrictions that cause infoleaks (big thread above), or use two
&gt; guards (prop#291 plus big thread above). Each of these options has its
&gt; own tradeoffs and we need to analyze them again. If someone could do a
&gt; summary that would be great to get this started again...
&gt; 
&gt; For now, if you are afraid of such attacks, you should use and love vanguards!

Yes, specifically vanguards always uses two guards and disables all path
restrictions to mitigate info-leak route disclosure attacks like the above.

Vanilla Tor uses two guards only sometimes, and that is part of the info
leak. Using two guards is not enough by itself, though, for cases where
you get unlucky and choose both guards from the same Family or some
other restriction violating case that will leak info by way of making it
clear which relays you *don't* use for your 3rd hop.

Since MyFamily and the other path restrictions are of questionable
value, but the info leak from using path restrictions is clear and
measurable, we opted to make the tradeoff to disable path restrictions
entirely in the vanguards addon. This is actually done by the
HSLayer*Nodes torrc options that we use. It was significantly less
disruptive to disable path restrictions only if those options were set,
than to redo all path selection in Tor itself. See the parent ticket and
its children for details:
https://trac.torproject.org/projects/tor/ticket/25546

I filed https://github.com/mikeperry-tor/vanguards/issues/53 to make
these choices clear in the vanguards docs. Right now you have to read
the tor manpage for the torrc options we used in order to even know
about these choices, which is not great.


The creation vanguards addon itself was also somewhat controversial -
asn and I basically had to go rogue to get all of these defenses
prototyped in a reasonable time frame. Merging these defenses into Tor
is a significantly larger engineering task than making a python control
port addon.

It is rather sad that we have to make such choices for security
features/improvements like this, and for the tagging problem. But
security features are surprisingly difficult to obtain funding for (!),
and so we often have to find ways to do whatever we can in these areas.

-- 
Mike Perry




["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200210232033</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-10 23:20:33-0400</timestampReceived><subject>Re: [tor-dev] Proposal 313: Relay IPv6 Statistics</subject><body>

[Attachment #2 (multipart/signed)]


Hi Karsten, Nick,

Thanks for your feedback!

I've removed the sections without your comments, to keep this email short.

&gt; On 10 Feb 2020, at 20:49, Karsten Loesing &lt;karsten@torproject.org&gt; wrote:
&gt; 
&gt;&gt; On 2020-02-10 07:36, teor wrote:
&gt; 
&gt; I'm including some comments below.
&gt; 
&gt;&gt; Here is an initial draft of Proposal 313: Relay IPv6 Statistics.
&gt;&gt; 
&gt;&gt; This proposal includes:
&gt;&gt; * logging the number of IPv6 relays in the consensus, and
&gt;&gt; * relays publishing IPv6 connection and consumed bandwidth statistics.
&gt;&gt; 
&gt;&gt; This is the third of 3 proposals:
&gt;&gt; * Proposal 311: Relay IPv6 Reachability
&gt;&gt; * Proposal 312: Automatic Relay IPv6 Addresses
&gt;&gt; * Proposal 313: Relay IPv6 Statistics
&gt;&gt; 
&gt;&gt; ...
&gt;&gt; 
&gt;&gt; The full text is included below, and it is also available as a GitHub
&gt;&gt; pull request:
&gt;&gt; https://github.com/torproject/torspec/pull/108
&gt;&gt; 
&gt;&gt; The related tickets are #33159 (proposal) and #33051 and #33052
&gt;&gt; (implementation):
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/33159
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/33051
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/33052
&gt;&gt; 
&gt;&gt; ...
&gt;&gt; 
&gt;&gt; Filename: 313-relay-ipv6-stats.txt
&gt;&gt; Title: Relay IPv6 Statistics
&gt;&gt; Author: teor
&gt;&gt; Created: 10-February-2020
&gt;&gt; Status: Draft
&gt;&gt; Ticket: #33159
&gt;&gt; 
&gt;&gt; ...
&gt;&gt; 
&gt;&gt; 3. Logging IPv6 Relays in the Consensus
&gt;&gt; 
&gt;&gt;   We propose that relays (and bridges) log:
&gt;&gt;     * the number of relays, and
&gt;&gt;     * the consensus weight fraction of relays,
&gt;&gt;   in the consensus that:
&gt;&gt;     * have an IPv6 ORPort,
&gt;&gt;     * support IPv6 reachability checks, and
&gt;&gt;     * support IPv6 clients.

&gt; On 11 Feb 2020, at 01:21, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt; I don't understand the motivation behind doing this in the Tor code,
&gt; since it's not something that relay operators need to know about or
&gt; take action on.  To me, it seems more like something do do as part of
&gt; metrics than in Tor per se.

I agree, we don't need these logs in tor. These calculations are
medium-term, and some of them only apply to Sponsor 55.

Also, as Karsten said, "Usable Guards" definition doesn't match Onionoo,
so these calculations really don't belong in metrics, either.

I've modified this section so we just do these calculations in a script:
https://github.com/torproject/torspec/pull/108/commits/91356f5db02b6a62afa3061278872b8d607db7ea

&gt;&gt;   In order to test these changes, and provide easy access to these
&gt;&gt;   statistics, we propose implementing a script that:
&gt;&gt;     * downloads a consensus, and
&gt;&gt;     * calculates and reports these statistics.
&gt;&gt; 
&gt;&gt;   As well as the statistics listed above, this script should also report the
&gt;&gt;   following relay statistic:
&gt;&gt;     * support IPv6 reachability checks and IPv6 clients.
&gt;&gt; 
&gt;&gt;   The following consensus weight fractions should divide by the total
&gt;&gt;   consensus weight:
&gt;&gt;     * have an IPv6 ORPort (all relays have an IPv4 ORPort), and
&gt;&gt;     * support IPv6 reachability checks (all relays support IPv4 reachability).
&gt;&gt; 
&gt;&gt;   The following consensus weight fractions should divide by the
&gt;&gt;   "usable Guard" consensus weight:
&gt;&gt;     * support IPv6 clients, and
&gt;&gt;     * support IPv6 reachability checks and IPv6 clients.
&gt;&gt; 
&gt;&gt;   "Usable Guards" have the Guard flag, but do not have the Exit flag. If the
&gt;&gt;   Guard also has the BadExit flag, the Exit flag should be ignored.
&gt; 
&gt; This definition is different from the one we're using in Onionoo for
&gt; computing the "guard probability". There we include a relay with the
&gt; Guard flag, regardless of whether it has the Exit and/or BadExit flag.
&gt; Not sure if this matters and which definition is more useful, I just
&gt; wanted to point out that they're different.

The Onionoo definition is long-term, see Nick's explanation:

&gt; On 11 Feb 2020, at 01:21, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; 
&gt; It seems to me that this rule should depend on the Wgd
&gt; bandwidth-weights value ("Weight for Guard+Exit-flagged nodes in the
&gt; guard Position"), right?  (Right now that is zero, and I don't expect
&gt; it to change.)

You're right, I've made that check part of the script design:
https://github.com/torproject/torspec/pull/108/commits/91356f5db02b6a62afa3061278872b8d607db7ea

Since I mainly expect to use the script for Sponsor 55 in 2020, I don't
propose a design for other values of Wgd. The script should just warn.
(These warnings might happen in chutney networks.)

&gt;&gt;   We propose that these logs happen whenever tor:
&gt;&gt;     * receives a consensus from a directory server, or
&gt;&gt;     * loads a live, valid, cached consensus from disk.
&gt;&gt; 
&gt;&gt;   As an optional change, tor clients may also log this information. Some of
&gt;&gt;   this information is not directly relevant to clients, but these logs may
&gt;&gt;   help developers (and users).
&gt;&gt; 
&gt;&gt; 4. Collecting IPv6 Consumed Bandwidth Statistics
&gt;&gt; 
&gt;&gt;   We propose that relays (and bridges) collect IPv6 consumed bandwidth
&gt;&gt;   statistics.
&gt;&gt; 
&gt;&gt;   To minimise development and testing effort, we propose re-using the existing
&gt;&gt;   "bw_array" code in rephist.c.
&gt;&gt; 
&gt;&gt;   In particular, tor currently counts these bandwidth statistics:
&gt;&gt;     * read,
&gt;&gt;     * write,
&gt;&gt;     * dir_read, and
&gt;&gt;     * dir_write.
&gt;&gt; 
&gt;&gt;   We propose adding the following bandwidth statistics:
&gt;&gt;     * ipv6_read, and
&gt;&gt;     * ipv6_write.
&gt;&gt;   (The IPv4 statistics can be calculated by subtracting the IPv6 statistics
&gt;&gt;   from the existing total consumed bandwidth statistics.)
&gt;&gt; 
&gt;&gt;   We propose adding a new BandwidthStatistics torrc option and consensus
&gt;&gt;   parameter, which activates reporting of all these statistics. Currently,
&gt;&gt;   the existing statistics are controlled by ExtraInfoStatistics, but we
&gt;&gt;   propose using the new BandwidthStatistics option for them as well.
&gt;&gt; 
&gt;&gt;   The default value of this option should be "auto", which checks the
&gt;&gt;   consensus parameter. If there is no consensus parameter, the default should
&gt;&gt;   be 1. (The existing bandwidth statistics are reported by default.)
&gt;&gt; 
&gt;&gt;   TODO: Should we collect IPv6 bandwidth statistics on bridges?
&gt;&gt;         On bridges, should bandwidth statistics be on or off by default?
&gt;&gt; 
&gt;&gt;         If we do want to collect bridge statistics, and we think it's safe,
&gt;&gt;         modify proposals 311 and 312 to allow bridge statistics.
&gt;&gt; 
&gt;&gt; ...
&gt; 
&gt; Right now, bandwidth statistics are on by default on bridges. I'd think
&gt; that turning them off by default as part of this proposal would be
&gt; surprising. It would be better, in terms of less surprising, to have a
&gt; replacement first before making that change.

We're focused on short-term tweaks in Sponsor 55, because it's a smaller
sponsor. So let's keep the changes small.

I've also moved the new BandwidthStatistics option to the
"Optional Changes" section:
https://github.com/torproject/torspec/pull/108/commits/e9a888f01ad86e8a9193de16ae956c8a62f3c6ae

&gt; Regardless of defaults, I'd say that collecting IPv6 bandwidth
&gt; statistics over a period of 24 hours is about as safe as collecting
&gt; IPv4+IPv6 bandwidth statistics over a period of 24 hours.

Thanks, I've updated the proposal with this reasoning:
https://github.com/torproject/torspec/pull/108/commits/e9a888f01ad86e8a9193de16ae956c8a62f3c6ae

&gt;&gt; 5. Collecting IPv6 Connection Statistics
&gt;&gt; 
&gt;&gt;   We propose that relays (and bridges) collect IPv6 connection statistics.
&gt;&gt; 
&gt;&gt;   To minimise development and testing effort, we propose re-using the existing
&gt;&gt;   "bidi" code in rephist.c. (This code may require some refactoring, because
&gt;&gt;   the "bidi" totals are globals, rather than a struct.)
&gt;&gt; 
&gt;&gt;   In particular, tor currently counts these connection statistics:
&gt;&gt;     * below threshold,
&gt;&gt;     * mostly read,
&gt;&gt;     * mostly written, and
&gt;&gt;     * both read and written.
&gt;&gt; 
&gt;&gt;   We propose adding IPv6 variants of all these statistics. (The IPv4
&gt;&gt;   statistics can be calculated by subtracting the IPv6 statistics from the
&gt;&gt;   existing total connection statistics.)
&gt;&gt; 
&gt;&gt;   We propose using the existing ConnDirectionStatistics torrc option, and
&gt;&gt;   adding a consensus parameter with the same name. This option will control
&gt;&gt;   the new and existing connection statistics.
&gt;&gt; 
&gt;&gt;   The default value of this option should be "auto", which checks the
&gt;&gt;   consensus parameter. If there is no consensus parameter, the default should
&gt;&gt;   be 0. (The existing connection direction statistics are reported by
&gt;&gt;   default.)
&gt;&gt; 
&gt;&gt;   TODO: Do enough relays report ConnDirectionStatistics, for accurate IPv6
&gt;&gt;   connection statistics?
&gt;&gt;     * at least 25% of relays have IPv6
&gt;&gt;     * at the end of the project, we expect at least 33% of relays to have
&gt;&gt;       deployed tor 0.4.4-stable
&gt;&gt; 
&gt;&gt;   If not, we should turn on ConnDirectionStatistics by default. (Or set the
&gt;&gt;   consensus parameter for a few days, to collect these statistics.)
&gt; 
&gt; It looks like these statistics are turned off by default, yet they are
&gt; reported in 79,709 out of 80,468 recent extra-info descriptors I just
&gt; looked at. Something's wrong in the current code, though I didn't spot
&gt; it at a quick glance. If it's accidentally turned on by default, I think
&gt; that changing it to a consensus parameter and turning that on for a few
&gt; days only would be a good solution.

That is odd. I've checked the code as well. We disable
ConnDirectionStatistics by default, and on bridges.

I've opened a trac ticket for this issue here:
https://trac.torproject.org/projects/tor/ticket/33214

It could be a bug in tor, or some large distributions (or the sample torrc)
that sets "ConnDirectionStatistics 1".

Fixing this bug is optional for Sponsor 55, but we should be aware of it,
because we want to modify the ConnDirectionStatistics code.

I've referenced ticket 33214 in the proposal, and moved the ConnDirStatistics
consensus parameter to the "Optional Changes" section:
https://github.com/torproject/torspec/pull/108/commits/e31ded5bd7769fd86c488b678a74fe877a0fa50c

I've also made some consequential updates to proposals 311 and 312:
https://github.com/torproject/torspec/pull/108/commits/a0492dd33cfc9d210fd9a4f762b779f452591668

Thanks again for your feedback!

T



["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl5B5UEACgkQEP6qDnB1
ZyrVXg//fez9zk+2iFN+PY6ouK4RHEfhnSPh2FAdNzvNcy1JBgoVoqIFUcwzAGmy
DkRYQymawjNyprj0AoGz4lD4xt7INehj/Re+n75NHFNxgQDeiBqz3yp5ioLoxnqZ
DYb+whj/A9hfKwIy+JljjaB584qwPcLcvu+qO+tFwO1KSM3bpIqwv5kCS5MYdNCH
oQHzlOev6EecTk/bQeB28+mX8ayinpXgaDyrasxuGUvimFSwRwt3Do/YthKImVUD
uTFQV4hmgtMRT28eCWBAdh/nPjVRECNYruVY7uEzFAdQHcMV6/1QODRE3vKRkf1Z
+spFTjV56LumOI7jpbK9RMCRFfK6Na+rbLdEpYBaJTfKJj1/qbp0lf5kycWvLDf7
lFuTWQjsg2KeBfvIWA7WSBQc33YfScgtbv2S3WeNR6zdyJL+353nTj59+tx0/GmJ
wH9Y+UcwP/nCvvMAIwh7mzhbXdxJIrKqVLtbvQm7PLJj2SEYZBHYtvvZe0r0nPh6
OvV6Pw9JDZzOdtmbq1/X57GiRrF6CEYCjOBRzYkiF5DigOapxCftCor+9lCjZndJ
s8s9jK1ychy/eHREZQaLwlzIg+aLXHoKsRJbI6OFf/UcL1hFjMOwhzw84KCOg14V
H6NZ2ES1kYN5i1GDcA11vYvchXtQyxyZPl7UqjXmyfEwGByuTZ8=
=FGvv
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200213105021</emailId><senderName>Hans-Christoph Steiner</senderName><senderEmail>hans@guardianproject.info</senderEmail><timestampReceived>2020-02-13 10:50:21-0400</timestampReceived><subject>Re: [tor-dev] Making Tor's CI Faster</subject><body>


I know gitlab.com has been working on IPv6 support everywhere, I'm not
sure if they are at 100% yet.  Have you tried there?  That would give CI
runs on GNU/Linux.

Also, https://eclips.is supports IPv6 in Amsterdam, so if Tor has
credits there, then running a gitlab-runner there would be relatively
straightforward.

.hc

teor:
&gt; Hi,
&gt; 
&gt; Want to help make Tor's CI go faster?
&gt; 
&gt; As part of the Sponsor 55 IPv6 work, I need to run Chutney IPv6 tests
&gt; on every Tor commit, as part of Tor's CI.
&gt; 
&gt; We're currently running these tests with fast_finish, because:
&gt; * Travis CI only has IPv6 on macOS
&gt; * macOS Chutney tests take 20-45 minutes in Travis CI
&gt; But fast_finish requires allow_failure.
&gt; 
&gt; We can't have allow_failure on code that's we're modifying every day,
&gt; so I'm going to make the Travis IPv6 Chutney job mandatory.
&gt; 
&gt; To speed up CI after this change, I'm going to make a new IPv6-only
&gt; test-network target, and run it in the macOS CI:
&gt; https://trac.torproject.org/projects/tor/ticket/33280
&gt; 
&gt; I've also identified one redundant Travis CI job that we can delete:
&gt; https://trac.torproject.org/projects/tor/ticket/33195#comment:3
&gt; 
&gt; Overall, these changes should reduce total CI runtime by 20-35
&gt; minutes. Due to parallelism, the wall clock time should reduce by
&gt; 10-35 minutes. We can squeeze the most benefit from the parallelism
&gt; by sorting jobs in speed order (longest first):
&gt; https://trac.torproject.org/projects/tor/ticket/33194
&gt; 
&gt; If you have any other ideas for making Tor's CI go faster, please let
&gt; me know.
&gt; 
&gt; Slow CI is a particular issue for backports, because each 0.3.5
&gt; backport updates 9 branches:
&gt;   * {maint,release}-{0.3.5,0.4.1,0.4.2,0.4.3} and
&gt;   * master.
&gt; 
&gt; T
&gt; 
&gt; --
&gt; teor
&gt; ----------------------------------------------------------------------
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 

-- 
PGP fingerprint: EE66 20C7 136B 0D2C 456C  0A4D E9E2 8DEA 00AA 5556
https://pgp.mit.edu/pks/lookup?op=vindex&amp;search=0xE9E28DEA00AA5556
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200219205255</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-19 20:52:55-0400</timestampReceived><subject>Re: [tor-dev] TOR Browser Circuit Selection of Exit Nodes</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

Thanks for your interest in Tor's path selection algorithm.

Some of my colleagues are working on "vanguards", which
significantly changes path selection. I think this is their
latest proposal:
https://gitweb.torproject.org/torspec.git/tree/proposals/292-mesh-vanguards.txt

I'll let them share any details they feel are helpful.

See also my specific answers inline below:

&gt; On 20 Feb 2020, at 06:20, Vianney Gomezgil Yaspik &lt;vgomezg1@jhu.edu&gt; wrote:
&gt; 
&gt; A group of students at Johns Hopkins University and I have been analyzing the \
&gt; circuit selection algorithm for TOR s browser EXIT nodes. It is an exploratory \
&gt; project trying to discover how do the EXIT nodes are selected every time the \
&gt; circuit changes.  
&gt; So far, we have discovered that the time that the browser is accessed, calendar \
&gt; date, physical location, use of a bridge (or not), and the entry node do not change \
&gt; the pattern of the EXIT nodes.

The set of Tor exits changes over time, so the calendar
date will change Tor's path selection slightly.

Similarly, Tor clients try to avoid choosing paths that
are within the same network, or all controlled by the
same operator. So guard selection does have a slight
impact on the chosen exit.

For more details, see tor's path spec, particularly the
constraints section:
https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n230

&gt; Moreover, than approximately 80% of all exit nodes come from 10 specific countries, \
&gt; even though these 10 countries only account for approximately 50% of all available \
&gt; exit nodes. 

How are you counting exit nodes?

Tor uses the bandwidth weights in the consensus, to
weight its random selection of exit nodes:
https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n92

These weights are limited by:
* any operator-configured bandwidth limits,
and scaled using:
* the relay's own observed bandwidth usage, and
* the capacities measured by the 6 Tor bandwidth
  authorities.

&gt; All of which has led us to conclude that the selection of the EXIT nodes in the TOR \
&gt; browser is not random. We would like to further explore however, what are the \
&gt; factors that determine which relay becomes the exit node every time a circuit is \
&gt; changed. Is there anyone that we could speak to or that could give us further \
&gt; insight as to how the selection of the exit node in TOR s circuit works?

Have you looked at the destination port?
Tor tried to select exits that will allow the requested
port.

Are you aware of preemptive circuits?
https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n147

If you're mainly measuring preemptive circuits, you'll
see fairly consistent behaviour. These circuits have
fewer constraints, because they need to be suitable
for general use.

That's probably enough to get you started, please
let us know if you have more questions.

T


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;Hi,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks for your \
interest in Tor's path selection algorithm.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Some of my \
colleagues are working on "vanguards", which&lt;/div&gt;&lt;div&gt;significantly changes path \
selection. I think this is their&lt;/div&gt;&lt;div&gt;latest proposal:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://gitweb.torproject.org/torspec.git/tree/proposals/292-mesh-vanguards.txt" \
&gt;https://gitweb.torproject.org/torspec.git/tree/proposals/292-mesh-vanguards.txt&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'll \
&gt; let them share any details they feel are helpful.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;See also \
&gt; my specific answers inline below:&lt;/div&gt;&lt;div&gt;&lt;div \
&gt; dir="ltr"&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;blockquote type="cite"&gt;On 20 Feb \
&gt; 2020, at 06:20, Vianney Gomezgil Yaspik &lt;vgomezg1@jhu.edu&gt; \
&gt; wrote:&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div \
&gt; style="font-family: Calibri, Arial, Helvetica, sans-serif; font-size: 12pt; color: \
&gt; rgb(0, 0, 0);"&gt;&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, \
&gt; Arial, Helvetica, sans-serif; text-align: left; background-color: rgb(255, 255, \
&gt; 255)"&gt;A group of students at Johns Hopkins University and I have been analyzing the \
&gt; circuit selection algorithm for TOR s browser EXIT nodes. It is an exploratory \
&gt; project trying to discover how do the EXIT nodes are selected every time the \
&gt; circuit changes.&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; &lt;br&gt;
&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; So far, we have \
discovered that the time that the browser is accessed, calendar \
date,&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div \
style="font-family: Calibri, Arial, Helvetica, sans-serif; font-size: 12pt; color: \
rgb(0, 0, 0);"&gt;&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, \
Helvetica, sans-serif; text-align: left; background-color: rgb(255, 255, \
255)"&gt;physical location, use of a bridge (or not), and the entry node do not change \
the pattern of the EXIT nodes.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;The set of Tor exits changes \
over time, so the calendar&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: rgb(0, \
0, 0);"&gt;date will change Tor's path selection slightly.&lt;/div&gt;&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;Similarly, Tor clients try to \
avoid choosing paths that&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: rgb(0, \
0, 0);"&gt;are within the same network, or all controlled by the&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;same operator. So guard \
selection does have a slight&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: \
rgb(0, 0, 0);"&gt;impact on the chosen exit.&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); \
color: rgb(0, 0, 0);"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: rgb(0, \
0, 0);"&gt;For more details, see tor's path spec, particularly the&lt;/div&gt;&lt;div \
style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;constraints \
section:&lt;/div&gt;&lt;div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"&gt;&lt;a \
href="https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n230"&gt;https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n230&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&lt;blockquote \
type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div style="font-family: Calibri, Arial, Helvetica, \
sans-serif; font-size: 12pt; color: rgb(0, 0, 0);"&gt;&lt;div style="margin: 0px; \
font-size: 12pt; font-family: Calibri, Arial, Helvetica, sans-serif; text-align: \
left; background-color: rgb(255, 255, 255)"&gt;Moreover, than approximately 80% of all \
exit nodes come from 10  specific countries, even though these 10 countries only \
account for approximately 50% of all available exit \
nodes.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;How are you counting \
exit nodes?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Tor uses the bandwidth weights in the consensus, \
to&lt;/div&gt;&lt;div&gt;weight its random selection of exit nodes:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n92"&gt;https://gitweb \
.torproject.org/torspec.git/tree/path-spec.txt#n92&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;These \
weights are limited by:&lt;/div&gt;&lt;div&gt;* any operator-configured bandwidth \
limits,&lt;/div&gt;&lt;div&gt;and scaled using:&lt;/div&gt;&lt;div&gt;&lt;span style="caret-color: rgb(0, 0, 0); \
color: rgb(0, 0, 0);"&gt;* the relay's own observed bandwidth usage, \
and&lt;/span&gt;&lt;/div&gt;&lt;div&gt;* the capacities measured by the 6 Tor \
bandwidth&lt;/div&gt;&lt;div&gt; authorities.&lt;/div&gt;&lt;br&gt;&lt;blockquote type="cite"&gt;&lt;div \
dir="ltr"&gt;&lt;div style="font-family: Calibri, Arial, Helvetica, sans-serif; font-size: \
12pt; color: rgb(0, 0, 0);"&gt; &lt;div style="margin: 0px; font-size: 12pt; font-family: \
Calibri, Arial, Helvetica, sans-serif; text-align: left; background-color: rgb(255, \
255, 255)"&gt; All of which has led us to conclude that the selection of the EXIT nodes \
in the TOR browser is not random. We would like to further explore however, what are \
the factors that determine which relay becomes the exit node every time a circuit is \
changed. Is there  anyone that we could speak to or that could give us further \
insight as to how the selection of the exit node in TOR s circuit \
works?&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Have you looked at the \
destination port?&lt;/div&gt;&lt;div&gt;Tor tried to select exits that will allow the \
requested&lt;/div&gt;&lt;div&gt;port.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Are you aware of preemptive \
circuits?&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://gitweb.torproject.org/torspec.git/tree/path-spec.txt#n147"&gt;https://gitwe \
b.torproject.org/torspec.git/tree/path-spec.txt#n147&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If \
you're mainly measuring preemptive circuits, you'll&lt;/div&gt;&lt;div&gt;see fairly consistent \
behaviour. These circuits have&lt;/div&gt;&lt;div&gt;fewer constraints, because they need to be \
suitable&lt;/div&gt;&lt;div&gt;for general use.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That's probably enough \
to get you started, please&lt;/div&gt;&lt;div&gt;let us know if you have more \
questions.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200221121800</emailId><senderName>Pouya Miralaee</senderName><senderEmail>pouyamiralayi@gmail.com</senderEmail><timestampReceived>2020-02-21 12:18:00-0400</timestampReceived><subject>[tor-dev] tor sending requests with a token</subject><body>

[Attachment #2 (multipart/alternative)]


Hello to the community and good evening!
I have some websites that i want to hide from public eyes, without going to
implement them as a HS. So here is my question: can i implement a
certificate authority on my servers, and then instruct tor to use that
certificate for requesting the websites? or something like a token
generated on the servers and tor use that token as an authenticated client?
The big picture of my scenario is that i have a custom tor browser (some
browser extensions pre-installed by default) and i want my clients using
that particular browser only access the mentioned websites!
Cheers!

-- 
*Pouya Miralayi*

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello to the community and good evening!&lt;div&gt;I have some websites that \
i want to hide from public eyes, without going to implement them as a HS. So here is \
my question: can i implement a certificate authority on my servers, and then instruct \
tor to use that certificate for requesting the websites? or something like a token \
generated on the servers and tor use that token as an authenticated \
client?&lt;/div&gt;&lt;div&gt;The big picture of my scenario is that i have a custom  tor browser \
(some browser extensions pre-installed by default) and i want my clients using that \
particular browser only access the mentioned websites!&lt;/div&gt;&lt;div&gt;Cheers!&lt;br \
clear="all"&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;-- &lt;br&gt;&lt;div dir="ltr" class="gmail_signature" \
data-smartmail="gmail_signature"&gt;*Pouya Miralayi*&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200224081829</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2020-02-24 08:18:29-0400</timestampReceived><subject>Re: [tor-dev] interested in working on a ticket</subject><body>

&gt; https://trac.torproject.org/projects/tor/ticket/13184 .

Perhaps not only "which local network", as in customary
127.0.0.0/8, but may be useful to some as being flexibly
narrow to "which IP and port", as in 127.201.52.38:843,
for IPv6 as well. Some OS / VM may utilize beyond
concept of just 127.0.0.1 and ::1.

The special registries should probably be noted
in the manpage / examples...
https://www.iana.org/numbers
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200204180338</emailId><senderName>juanjo</senderName><senderEmail>juanjo@avanix.es</senderEmail><timestampReceived>2020-02-04 18:03:38-0400</timestampReceived><subject>[tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

Since no one is posting it here and talking about it, I will post it.

https://nvd.nist.gov/vuln/detail/CVE-2020-8516

The guy: 
http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html

Is this real?

Are we actually not verifying if the IP of the Rend is a node in the Tor 
network?



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200210063653</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-10 06:36:53-0400</timestampReceived><subject>[tor-dev] Proposal 313: Relay IPv6 Statistics</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

Here is an initial draft of Proposal 313: Relay IPv6 Statistics.

This proposal includes:
* logging the number of IPv6 relays in the consensus, and
* relays publishing IPv6 connection and consumed bandwidth statistics.

This is the third of 3 proposals:
* Proposal 311: Relay IPv6 Reachability
* Proposal 312: Automatic Relay IPv6 Addresses
* Proposal 313: Relay IPv6 Statistics

I revised proposals 311 and 312 last week, and merged them to torspec as
drafts.

There are still some TODO items in the proposal, about:
* safely collecting these new statistics on bridges, and
* getting accurate IPv6 connection statistics.
If you know about tor's statistics, please give us some feedback!

The full text is included below, and it is also available as a GitHub
pull request:
https://github.com/torproject/torspec/pull/108

The related tickets are #33159 (proposal) and #33051 and #33052
(implementation):
https://trac.torproject.org/projects/tor/ticket/33159
https://trac.torproject.org/projects/tor/ticket/33051
https://trac.torproject.org/projects/tor/ticket/33052

Please feel free to reply on this list, or via GitHub pull request
comments.

Filename: 313-relay-ipv6-stats.txt
Title: Relay IPv6 Statistics
Author: teor
Created: 10-February-2020
Status: Draft
Ticket: #33159

0. Abstract

   We propose that Tor relays (and bridges) should log the number of relays in
   the consensus that support IPv6 extends, and IPv6 client connections.

   We also propose that Tor relays (and bridges) should collect statistics on
   IPv6 connections and consumed bandwidth. Like tor's existing connection
   and consumed bandwidth statistics, these new IPv6 statistics will be
   published in each relay's extra-info descriptor.

1. Introduction

   Tor relays (and bridges) can accept IPv6 client connections via their
   ORPort. But current versions of tor need to have an explicitly configured
   IPv6 address (see [Proposal 312: Relay Auto IPv6 Address]), and they don't
   perform IPv6 reachability self-checks (see
   [Proposal 311: Relay IPv6 Reachability]).

   As we implement these new IPv6 features in tor, we want to monitor their
   impact on the IPv6 connections and bandwidth in the tor network.

   Tor developers also need to know how many relays support these new IPv6
   features, so they can test tor's IPv6 reachability checks. (In particular,
   see section 4.3.1 in [Proposal 311: Relay IPv6 Reachability]:  Refusing to
   Publish the Descriptor.)

2. Scope

   This proposal modifies Tor's behaviour as follows:

   Relays, bridges, and directory authorities log the number of relays that
   support IPv6 clients, and IPv6 relay reachability checks. They also log the
   corresponding consensus weight fractions.

   As an optional change, tor clients may also log this information.

   Relays, bridges, and directory authorities collect statistics on:
     * IPv6 connections, and
     * IPv6 consumed bandwidth.
   The design of these statistics will be based on tor's existing connection
   and consumed bandwidth statistics.

   Tor's existing consumed bandwidth statistics truncate their totals to the
   nearest kilobyte. The existing connection statistics do not perform any
   binning.

   We do not proposed to add any extra noise or binning to these statistics.
   Instead, we expect to leave these changes until we have a consistent
   privacy-preserving statistics framwework for tor. As an example of this
   kind of framework, see
   [Proposal 288: Privacy-Preserving Stats with Privcount (Shamir version)].

   We avoid:
     * splitting connection statistics into clients and relays, and
     * collecting circuit statistics.
   These statistics are more sensitive, so we want to implement
   privacy-preserving statistics, before we consider adding them.

   Throughout this proposal, "relays" includes directory authorities, except
   where they are specifically excluded. "relays" does not include bridges,
   except where they are specifically included. (The first mention of "relays"
   in each section should specifically exclude or include these other roles.)

   Tor clients do not collect any statistics for public reporting. Therefore,
   clients are out of scope in this proposal. (Except for some optional changes
   to client logs, where they log the number of IPv6 relays in the consensus).

   When this proposal describes Tor's current behaviour, it covers all
   supported Tor versions (0.3.5.7 to 0.4.2.5), as of January 2020, except
   where another version is specifically mentioned.

3. Logging IPv6 Relays in the Consensus

   We propose that relays (and bridges) log:
     * the number of relays, and
     * the consensus weight fraction of relays,
   in the consensus that:
     * have an IPv6 ORPort,
     * support IPv6 reachability checks, and
     * support IPv6 clients.

   In order to test these changes, and provide easy access to these
   statistics, we propose implementing a script that:
     * downloads a consensus, and
     * calculates and reports these statistics.

   As well as the statistics listed above, this script should also report the
   following relay statistic:
     * support IPv6 reachability checks and IPv6 clients.

   The following consensus weight fractions should divide by the total
   consensus weight:
     * have an IPv6 ORPort (all relays have an IPv4 ORPort), and
     * support IPv6 reachability checks (all relays support IPv4 reachability).

   The following consensus weight fractions should divide by the
   "usable Guard" consensus weight:
     * support IPv6 clients, and
     * support IPv6 reachability checks and IPv6 clients.

   "Usable Guards" have the Guard flag, but do not have the Exit flag. If the
   Guard also has the BadExit flag, the Exit flag should be ignored.

   We propose that these logs happen whenever tor:
     * receives a consensus from a directory server, or
     * loads a live, valid, cached consensus from disk.

   As an optional change, tor clients may also log this information. Some of
   this information is not directly relevant to clients, but these logs may
   help developers (and users).

4. Collecting IPv6 Consumed Bandwidth Statistics

   We propose that relays (and bridges) collect IPv6 consumed bandwidth
   statistics.

   To minimise development and testing effort, we propose re-using the existing
   "bw_array" code in rephist.c.

   In particular, tor currently counts these bandwidth statistics:
     * read,
     * write,
     * dir_read, and
     * dir_write.

   We propose adding the following bandwidth statistics:
     * ipv6_read, and
     * ipv6_write.
   (The IPv4 statistics can be calculated by subtracting the IPv6 statistics
   from the existing total consumed bandwidth statistics.)

   We propose adding a new BandwidthStatistics torrc option and consensus
   parameter, which activates reporting of all these statistics. Currently,
   the existing statistics are controlled by ExtraInfoStatistics, but we
   propose using the new BandwidthStatistics option for them as well.

   The default value of this option should be "auto", which checks the
   consensus parameter. If there is no consensus parameter, the default should
   be 1. (The existing bandwidth statistics are reported by default.)

   TODO: Should we collect IPv6 bandwidth statistics on bridges?
         On bridges, should bandwidth statistics be on or off by default?

         If we do want to collect bridge statistics, and we think it's safe,
         modify proposals 311 and 312 to allow bridge statistics.

5. Collecting IPv6 Connection Statistics

   We propose that relays (and bridges) collect IPv6 connection statistics.

   To minimise development and testing effort, we propose re-using the existing
   "bidi" code in rephist.c. (This code may require some refactoring, because
   the "bidi" totals are globals, rather than a struct.)

   In particular, tor currently counts these connection statistics:
     * below threshold,
     * mostly read,
     * mostly written, and
     * both read and written.

   We propose adding IPv6 variants of all these statistics. (The IPv4
   statistics can be calculated by subtracting the IPv6 statistics from the
   existing total connection statistics.)

   We propose using the existing ConnDirectionStatistics torrc option, and
   adding a consensus parameter with the same name. This option will control
   the new and existing connection statistics.

   The default value of this option should be "auto", which checks the
   consensus parameter. If there is no consensus parameter, the default should
   be 0. (The existing connection direction statistics are reported by
   default.)

   TODO: Do enough relays report ConnDirectionStatistics, for accurate IPv6
   connection statistics?
     * at least 25% of relays have IPv6
     * at the end of the project, we expect at least 33% of relays to have
       deployed tor 0.4.4-stable

   If not, we should turn on ConnDirectionStatistics by default. (Or set the
   consensus parameter for a few days, to collect these statistics.)

6. Directory Protocol Specification Changes

   We propose adding IPv6 variants of the consumed bandwidth and connection
   direction statistics to the tor directory protocol.

   We propose the following additions to the [Tor Directory Protocol]
   specification, in section 2.1.2. Each addition should be inserted below the
   existing consumed bandwidth and connection direction specifications.

    "ipv6-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
        [At most once]
    "ipv6-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
        [At most once]

        Declare how much bandwidth the OR has used recently, on IPv6
        connections. See "read-history" and "write-history" for more details.
        (The migration notes do not apply to IPv6.)

    "ipv6-conn-bi-direct" YYYY-MM-DD HH:MM:SS (NSEC s) BELOW,READ,WRITE,BOTH NL
        [At most once]

        Number of IPv6 connections, that are used uni-directionally or
        bi-directionally. See "conn-bi-direct" for more details.

   We also propose the following replacement, in the same section:

    "dirreq-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
        [At most once]
    "dirreq-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
        [At most once]

        Declare how much bandwidth the OR has spent on answering directory
        requests. See "read-history" and "write-history" for more details.
        (The migration notes do not apply to dirreq.)

   This replacement is optional, but it may avoid the 3 *read-history
   definitions getting out of sync.

7. Optional Changes

   We propose some optional changes to help relay operators, tor developers,
   and tor's network health. We also expect that these changes will drive IPv6
   relay adoption.

   Some of these changes may be more appropriate as future work, or along with
   other proposed features.

7.1. Log IPv6 Statistics in Tor's Heartbeat Logs

   We propose this optional change, so relay operators can see their own IPv6
   statistics:

   We propose that tor logs its IPv6 consumed bandwidth and connection
   statistics in its regular "heartbeat" logs.

   These heartbeat statistics should be collected over the lifetime of the tor
   process, rather than using the state file, like the statistics in sections
   4 and 5.

   Tor's existing heartbeat logs already show its consumed bandwidth and
   connections (in the link protocol counts).

   We may also want to show IPv6 consumed bandwidth and connections as a
   propotion of the total consumed bandwidth and connections.

   These statistics only show a relay's local bandwidth usage, so they can't
   be used for reporting.

7.2. Show IPv6 Statistics on Consensus Health

   The [Consensus Health] website displays a wide rage of tor statistics,
   based on the most recent consensus.

   We propose this optional change, to:
     * help relay operators diagnose issues with IPv6 on their relays, and
     * to drive IPv6 adoption on tor relays.

   Consensus Health adds an IPv6 section, with the following relay statistics:
     * have an IPv6 ORPort,
     * support IPv6 reachability checks,
     * support IPv6 clients, and
     * support IPv6 reachability checks and IPv6 clients.

   The definitions of these statistics are in section 3.

   These changes can be tested using the script proposed in section 3.

7.3. Add an IPv6 Reachability Pseudo-Flag on Relay Search

   The [Relay Search] website displays tor relay information, based on the
   current consensus and relay descriptors.

   We propose this optional change, to:
     * help relay operators diagnose issues with IPv6 on their relays, and
     * drive IPv6 adoption on tor relays.

   Relay Search adds a pseudo-flag for relay IPv6 reachability support.

   This pseudo-flag should be given to relays that have:
     * a reachable IPv6 ORPort (in the consensus), and
     * support tor subprotocol version "Relay=3" (or later).
   See [Proposal 311: Relay IPv6 Reachability] for details.

   TODO: Is this a useful change?
         Are there better ways of driving IPv6 adoption?

7.4. Add IPv6 Connections and Consumed Bandwidth Graphs to Tor Metrics

   The [Tor Metrics: Traffic] website displays connection and bandwidth
   information for the tor network, based on relay extra-info descriptors.

   We propose these optional changes, to:
     * help tor developers improve IPv6 support on the tor network,
     * help diagnose issues with IPv6 on the tor network, and
     * drive IPv6 adoption on tor relays.

   Tor Metrics adds the following information to the graphs on the Traffic
   page:

   Consumed Bandwidth by IP version
     * added to the existing [Tor Metrics: Advertised bandwidth by IP version]
       page
     * as a stacked graph, like
       [Tor Metrics: Advertised and consumed bandwidth by relay flags]

   Fraction of connections used uni-/bidirectionally by IP version
     * added to the existing
       [Tor Metrics: Fraction of connections used uni-/bidirectionally] page
     * as a stacked graph, like
       [Tor Metrics: Advertised and consumed bandwidth by relay flags]

8. Test Plan

   We provide a quick summary of our testing plans.

8.1. Testing IPv6 Relay Consensus Count Logging

   We propose to test these changes using chutney networks. However, chutney
   creates a limited number of relays, so we also need to test these changes
   on the public tor network.

   Therefore, we propose to test these changes on the public network with a
   small number of relays and bridges.

   We can use the script and the tor logs to cross-check these calculations.
   The Tor Metrics team may also independently check these calculations.

   Once these changes are merged, they will be monitored by tor developers, as
   more volunteer relay operators deploy the relevant tor versions. (And as the
   number of IPv6 relays in the consensus increases.)

8.2. Testing IPv6 Extra-Info Statistics

   We propose to test the connection and consumed bandwidth statistics using
   chutney networks. However, chutney runs for a short amount of time, and
   creates a limited amount of traffic, so we also need to test these changes
   on the public tor network.

   In particular, we have struggled to test statistics using chutney, because
   tor's hard-coded statistics period is 24 hours. (And most chutney networks
   run for under 1 minute.)

   Therefore, we propose to test these changes on the public network with a
   small number of relays and bridges.

   During 2020, the Tor Metrics team will analyse these statistics on the
   public tor network, and provide IPv6 progress reports. We expect that we may
   discover some bugs during the first analysis.

   Once these changes are merged, they will be monitored by tor developers, as
   more volunteer relay operators deploy the relevant tor versions. (And as the
   number of IPv6 relays in the consensus increases.)

References:

[Consensus Health]:
   https://consensus-health.torproject.org/

[Proposal 288: Privacy-Preserving Stats with Privcount (Shamir version)]:
   https://gitweb.torproject.org/torspec.git/tree/proposals/288-privcount-with-shamir.txt

[Proposal 311: Relay IPv6 Reachability]:
   https://gitweb.torproject.org/torspec.git/tree/proposals/311-relay-ipv6-reachability.txt

[Proposal 312: Relay Auto IPv6 Address]:
   https://gitweb.torproject.org/torspec.git/tree/proposals/312-relay-auto-ipv6-addr.txt

[Relay Search]:
   https://metrics.torproject.org/rs.html

[Tor Directory Protocol]:
   (version 3) https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt

[Tor Manual Page]:
   https://2019.www.torproject.org/docs/tor-manual.html.en

[Tor Metrics: Advertised and consumed bandwidth by relay flags]:
   https://metrics.torproject.org/bandwidth-flags.html

[Tor Metrics: Advertised bandwidth by IP version]:
   https://metrics.torproject.org/advbw-ipv6.html

[Tor Metrics: Fraction of connections used uni-/bidirectionally]:
   https://metrics.torproject.org/connbidirect.html

[Tor Metrics: Traffic]:
   https://metrics.torproject.org/bandwidth-flags.html

[Tor Specification]:
   https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl5A+gUACgkQEP6qDnB1
ZypElQ/+P9My82PA5+fHhVDJHrxusVfIgDW9n4cysHg4CN0oPU7azzcjdu9pdOFm
BDvVLswWXN+h/YMruVx8pX8ERJO0Ht3edItrJ7IwjgExWowG1xfRdEE9Tu+D+Yev
UbFMtQ/b0AVbnV1rzBhbaldPfoKeUPuBn0FJfKGroPd4HkyfXkEVs+OjxDUJd91D
f0M1IgxO3hn01Cf+ijKcfhVwS4wAHopZDC5V6FvE4eQ6XJ3g9ccxQMkooq+DYHSF
Fw2fYg0fqgSE2YfSZ8mlSJtVeek1gfjL90fxOIQ6DLflUBeiSruyr3NCfiyvBHcs
GSmey4SikVZ1ueFm2a2BWOuv4+vSNX3Rgq3ZUb40ECRM9YO5G0spn/26v0gvWGMe
kTWPBR3Bmf5ONLrgXwrzS+zoF02/s9FLnMsJXxXnYz7i3bTHJdtJulotHEfOHzF4
SYKdiJiNAxxkWqrzAOiULcxPM5SmZCKQMFopHEhiEmNuMV9jQqRo0P/98zZrIyE+
em7psn/kLn8veUr2J+t4+FFx3xOWh09ttVFPK5m9xb7h3NZ/A5R/q+lSMaLwk+bm
gp5X/yg3C6r1M06Z9wu6aGNMZboXvkWI6tBSBd3dfq+kZgobI3TnfgAPl5CBfs7W
1EFtOeQCbaFdN05496/9glIXR0/xX0GezHXgWTVWBV0JPF1efB8=
=zeJf
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200210104954</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten@torproject.org</senderEmail><timestampReceived>2020-02-10 10:49:54-0400</timestampReceived><subject>Re: [tor-dev] Proposal 313: Relay IPv6 Statistics</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 2020-02-10 07:36, teor wrote:
&gt; Hi,

Hi teor,

I'm including some comments below.

&gt; Here is an initial draft of Proposal 313: Relay IPv6 Statistics.
&gt; 
&gt; This proposal includes:
&gt; * logging the number of IPv6 relays in the consensus, and
&gt; * relays publishing IPv6 connection and consumed bandwidth statistics.
&gt; 
&gt; This is the third of 3 proposals:
&gt; * Proposal 311: Relay IPv6 Reachability
&gt; * Proposal 312: Automatic Relay IPv6 Addresses
&gt; * Proposal 313: Relay IPv6 Statistics
&gt; 
&gt; I revised proposals 311 and 312 last week, and merged them to torspec as
&gt; drafts.
&gt; 
&gt; There are still some TODO items in the proposal, about:
&gt; * safely collecting these new statistics on bridges, and
&gt; * getting accurate IPv6 connection statistics.
&gt; If you know about tor's statistics, please give us some feedback!
&gt; 
&gt; The full text is included below, and it is also available as a GitHub
&gt; pull request:
&gt; https://github.com/torproject/torspec/pull/108
&gt; 
&gt; The related tickets are #33159 (proposal) and #33051 and #33052
&gt; (implementation):
&gt; https://trac.torproject.org/projects/tor/ticket/33159
&gt; https://trac.torproject.org/projects/tor/ticket/33051
&gt; https://trac.torproject.org/projects/tor/ticket/33052
&gt; 
&gt; Please feel free to reply on this list, or via GitHub pull request
&gt; comments.
&gt; 
&gt; Filename: 313-relay-ipv6-stats.txt
&gt; Title: Relay IPv6 Statistics
&gt; Author: teor
&gt; Created: 10-February-2020
&gt; Status: Draft
&gt; Ticket: #33159
&gt; 
&gt; 0. Abstract
&gt; 
&gt;    We propose that Tor relays (and bridges) should log the number of relays in
&gt;    the consensus that support IPv6 extends, and IPv6 client connections.
&gt; 
&gt;    We also propose that Tor relays (and bridges) should collect statistics on
&gt;    IPv6 connections and consumed bandwidth. Like tor's existing connection
&gt;    and consumed bandwidth statistics, these new IPv6 statistics will be
&gt;    published in each relay's extra-info descriptor.
&gt; 
&gt; 1. Introduction
&gt; 
&gt;    Tor relays (and bridges) can accept IPv6 client connections via their
&gt;    ORPort. But current versions of tor need to have an explicitly configured
&gt;    IPv6 address (see [Proposal 312: Relay Auto IPv6 Address]), and they don't
&gt;    perform IPv6 reachability self-checks (see
&gt;    [Proposal 311: Relay IPv6 Reachability]).
&gt; 
&gt;    As we implement these new IPv6 features in tor, we want to monitor their
&gt;    impact on the IPv6 connections and bandwidth in the tor network.
&gt; 
&gt;    Tor developers also need to know how many relays support these new IPv6
&gt;    features, so they can test tor's IPv6 reachability checks. (In particular,
&gt;    see section 4.3.1 in [Proposal 311: Relay IPv6 Reachability]:  Refusing to
&gt;    Publish the Descriptor.)
&gt; 
&gt; 2. Scope
&gt; 
&gt;    This proposal modifies Tor's behaviour as follows:
&gt; 
&gt;    Relays, bridges, and directory authorities log the number of relays that
&gt;    support IPv6 clients, and IPv6 relay reachability checks. They also log the
&gt;    corresponding consensus weight fractions.
&gt; 
&gt;    As an optional change, tor clients may also log this information.
&gt; 
&gt;    Relays, bridges, and directory authorities collect statistics on:
&gt;      * IPv6 connections, and
&gt;      * IPv6 consumed bandwidth.
&gt;    The design of these statistics will be based on tor's existing connection
&gt;    and consumed bandwidth statistics.
&gt; 
&gt;    Tor's existing consumed bandwidth statistics truncate their totals to the
&gt;    nearest kilobyte. The existing connection statistics do not perform any
&gt;    binning.
&gt; 
&gt;    We do not proposed to add any extra noise or binning to these statistics.
&gt;    Instead, we expect to leave these changes until we have a consistent
&gt;    privacy-preserving statistics framwework for tor. As an example of this
&gt;    kind of framework, see
&gt;    [Proposal 288: Privacy-Preserving Stats with Privcount (Shamir version)].
&gt; 
&gt;    We avoid:
&gt;      * splitting connection statistics into clients and relays, and
&gt;      * collecting circuit statistics.
&gt;    These statistics are more sensitive, so we want to implement
&gt;    privacy-preserving statistics, before we consider adding them.
&gt; 
&gt;    Throughout this proposal, "relays" includes directory authorities, except
&gt;    where they are specifically excluded. "relays" does not include bridges,
&gt;    except where they are specifically included. (The first mention of "relays"
&gt;    in each section should specifically exclude or include these other roles.)
&gt; 
&gt;    Tor clients do not collect any statistics for public reporting. Therefore,
&gt;    clients are out of scope in this proposal. (Except for some optional changes
&gt;    to client logs, where they log the number of IPv6 relays in the consensus).
&gt; 
&gt;    When this proposal describes Tor's current behaviour, it covers all
&gt;    supported Tor versions (0.3.5.7 to 0.4.2.5), as of January 2020, except
&gt;    where another version is specifically mentioned.
&gt; 
&gt; 3. Logging IPv6 Relays in the Consensus
&gt; 
&gt;    We propose that relays (and bridges) log:
&gt;      * the number of relays, and
&gt;      * the consensus weight fraction of relays,
&gt;    in the consensus that:
&gt;      * have an IPv6 ORPort,
&gt;      * support IPv6 reachability checks, and
&gt;      * support IPv6 clients.
&gt; 
&gt;    In order to test these changes, and provide easy access to these
&gt;    statistics, we propose implementing a script that:
&gt;      * downloads a consensus, and
&gt;      * calculates and reports these statistics.
&gt; 
&gt;    As well as the statistics listed above, this script should also report the
&gt;    following relay statistic:
&gt;      * support IPv6 reachability checks and IPv6 clients.
&gt; 
&gt;    The following consensus weight fractions should divide by the total
&gt;    consensus weight:
&gt;      * have an IPv6 ORPort (all relays have an IPv4 ORPort), and
&gt;      * support IPv6 reachability checks (all relays support IPv4 reachability).
&gt; 
&gt;    The following consensus weight fractions should divide by the
&gt;    "usable Guard" consensus weight:
&gt;      * support IPv6 clients, and
&gt;      * support IPv6 reachability checks and IPv6 clients.
&gt; 
&gt;    "Usable Guards" have the Guard flag, but do not have the Exit flag. If the
&gt;    Guard also has the BadExit flag, the Exit flag should be ignored.

This definition is different from the one we're using in Onionoo for
computing the "guard probability". There we include a relay with the
Guard flag, regardless of whether it has the Exit and/or BadExit flag.
Not sure if this matters and which definition is more useful, I just
wanted to point out that they're different.

&gt;    We propose that these logs happen whenever tor:
&gt;      * receives a consensus from a directory server, or
&gt;      * loads a live, valid, cached consensus from disk.
&gt; 
&gt;    As an optional change, tor clients may also log this information. Some of
&gt;    this information is not directly relevant to clients, but these logs may
&gt;    help developers (and users).
&gt; 
&gt; 4. Collecting IPv6 Consumed Bandwidth Statistics
&gt; 
&gt;    We propose that relays (and bridges) collect IPv6 consumed bandwidth
&gt;    statistics.
&gt; 
&gt;    To minimise development and testing effort, we propose re-using the existing
&gt;    "bw_array" code in rephist.c.
&gt; 
&gt;    In particular, tor currently counts these bandwidth statistics:
&gt;      * read,
&gt;      * write,
&gt;      * dir_read, and
&gt;      * dir_write.
&gt; 
&gt;    We propose adding the following bandwidth statistics:
&gt;      * ipv6_read, and
&gt;      * ipv6_write.
&gt;    (The IPv4 statistics can be calculated by subtracting the IPv6 statistics
&gt;    from the existing total consumed bandwidth statistics.)
&gt; 
&gt;    We propose adding a new BandwidthStatistics torrc option and consensus
&gt;    parameter, which activates reporting of all these statistics. Currently,
&gt;    the existing statistics are controlled by ExtraInfoStatistics, but we
&gt;    propose using the new BandwidthStatistics option for them as well.
&gt; 
&gt;    The default value of this option should be "auto", which checks the
&gt;    consensus parameter. If there is no consensus parameter, the default should
&gt;    be 1. (The existing bandwidth statistics are reported by default.)
&gt; 
&gt;    TODO: Should we collect IPv6 bandwidth statistics on bridges?
&gt;          On bridges, should bandwidth statistics be on or off by default?
&gt; 
&gt;          If we do want to collect bridge statistics, and we think it's safe,
&gt;          modify proposals 311 and 312 to allow bridge statistics.

Right now, bandwidth statistics are on by default on bridges. I'd think
that turning them off by default as part of this proposal would be
surprising. It would be better, in terms of less surprising, to have a
replacement first before making that change.

Regardless of defaults, I'd say that collecting IPv6 bandwidth
statistics over a period of 24 hours is about as safe as collecting
IPv4+IPv6 bandwidth statistics over a period of 24 hours.

&gt; 5. Collecting IPv6 Connection Statistics
&gt; 
&gt;    We propose that relays (and bridges) collect IPv6 connection statistics.
&gt; 
&gt;    To minimise development and testing effort, we propose re-using the existing
&gt;    "bidi" code in rephist.c. (This code may require some refactoring, because
&gt;    the "bidi" totals are globals, rather than a struct.)
&gt; 
&gt;    In particular, tor currently counts these connection statistics:
&gt;      * below threshold,
&gt;      * mostly read,
&gt;      * mostly written, and
&gt;      * both read and written.
&gt; 
&gt;    We propose adding IPv6 variants of all these statistics. (The IPv4
&gt;    statistics can be calculated by subtracting the IPv6 statistics from the
&gt;    existing total connection statistics.)
&gt; 
&gt;    We propose using the existing ConnDirectionStatistics torrc option, and
&gt;    adding a consensus parameter with the same name. This option will control
&gt;    the new and existing connection statistics.
&gt; 
&gt;    The default value of this option should be "auto", which checks the
&gt;    consensus parameter. If there is no consensus parameter, the default should
&gt;    be 0. (The existing connection direction statistics are reported by
&gt;    default.)
&gt; 
&gt;    TODO: Do enough relays report ConnDirectionStatistics, for accurate IPv6
&gt;    connection statistics?
&gt;      * at least 25% of relays have IPv6
&gt;      * at the end of the project, we expect at least 33% of relays to have
&gt;        deployed tor 0.4.4-stable
&gt; 
&gt;    If not, we should turn on ConnDirectionStatistics by default. (Or set the
&gt;    consensus parameter for a few days, to collect these statistics.)

It looks like these statistics are turned off by default, yet they are
reported in 79,709 out of 80,468 recent extra-info descriptors I just
looked at. Something's wrong in the current code, though I didn't spot
it at a quick glance. If it's accidentally turned on by default, I think
that changing it to a consensus parameter and turning that on for a few
days only would be a good solution.

That's my last comment. Overall looks like a great proposal!

All the best,
Karsten


&gt; 6. Directory Protocol Specification Changes
&gt; 
&gt;    We propose adding IPv6 variants of the consumed bandwidth and connection
&gt;    direction statistics to the tor directory protocol.
&gt; 
&gt;    We propose the following additions to the [Tor Directory Protocol]
&gt;    specification, in section 2.1.2. Each addition should be inserted below the
&gt;    existing consumed bandwidth and connection direction specifications.
&gt; 
&gt;     "ipv6-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
&gt;         [At most once]
&gt;     "ipv6-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
&gt;         [At most once]
&gt; 
&gt;         Declare how much bandwidth the OR has used recently, on IPv6
&gt;         connections. See "read-history" and "write-history" for more details.
&gt;         (The migration notes do not apply to IPv6.)
&gt; 
&gt;     "ipv6-conn-bi-direct" YYYY-MM-DD HH:MM:SS (NSEC s) BELOW,READ,WRITE,BOTH NL
&gt;         [At most once]
&gt; 
&gt;         Number of IPv6 connections, that are used uni-directionally or
&gt;         bi-directionally. See "conn-bi-direct" for more details.
&gt; 
&gt;    We also propose the following replacement, in the same section:
&gt; 
&gt;     "dirreq-read-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
&gt;         [At most once]
&gt;     "dirreq-write-history" YYYY-MM-DD HH:MM:SS (NSEC s) NUM,NUM,NUM... NL
&gt;         [At most once]
&gt; 
&gt;         Declare how much bandwidth the OR has spent on answering directory
&gt;         requests. See "read-history" and "write-history" for more details.
&gt;         (The migration notes do not apply to dirreq.)
&gt; 
&gt;    This replacement is optional, but it may avoid the 3 *read-history
&gt;    definitions getting out of sync.
&gt; 
&gt; 7. Optional Changes
&gt; 
&gt;    We propose some optional changes to help relay operators, tor developers,
&gt;    and tor's network health. We also expect that these changes will drive IPv6
&gt;    relay adoption.
&gt; 
&gt;    Some of these changes may be more appropriate as future work, or along with
&gt;    other proposed features.
&gt; 
&gt; 7.1. Log IPv6 Statistics in Tor's Heartbeat Logs
&gt; 
&gt;    We propose this optional change, so relay operators can see their own IPv6
&gt;    statistics:
&gt; 
&gt;    We propose that tor logs its IPv6 consumed bandwidth and connection
&gt;    statistics in its regular "heartbeat" logs.
&gt; 
&gt;    These heartbeat statistics should be collected over the lifetime of the tor
&gt;    process, rather than using the state file, like the statistics in sections
&gt;    4 and 5.
&gt; 
&gt;    Tor's existing heartbeat logs already show its consumed bandwidth and
&gt;    connections (in the link protocol counts).
&gt; 
&gt;    We may also want to show IPv6 consumed bandwidth and connections as a
&gt;    propotion of the total consumed bandwidth and connections.
&gt; 
&gt;    These statistics only show a relay's local bandwidth usage, so they can't
&gt;    be used for reporting.
&gt; 
&gt; 7.2. Show IPv6 Statistics on Consensus Health
&gt; 
&gt;    The [Consensus Health] website displays a wide rage of tor statistics,
&gt;    based on the most recent consensus.
&gt; 
&gt;    We propose this optional change, to:
&gt;      * help relay operators diagnose issues with IPv6 on their relays, and
&gt;      * to drive IPv6 adoption on tor relays.
&gt; 
&gt;    Consensus Health adds an IPv6 section, with the following relay statistics:
&gt;      * have an IPv6 ORPort,
&gt;      * support IPv6 reachability checks,
&gt;      * support IPv6 clients, and
&gt;      * support IPv6 reachability checks and IPv6 clients.
&gt; 
&gt;    The definitions of these statistics are in section 3.
&gt; 
&gt;    These changes can be tested using the script proposed in section 3.
&gt; 
&gt; 7.3. Add an IPv6 Reachability Pseudo-Flag on Relay Search
&gt; 
&gt;    The [Relay Search] website displays tor relay information, based on the
&gt;    current consensus and relay descriptors.
&gt; 
&gt;    We propose this optional change, to:
&gt;      * help relay operators diagnose issues with IPv6 on their relays, and
&gt;      * drive IPv6 adoption on tor relays.
&gt; 
&gt;    Relay Search adds a pseudo-flag for relay IPv6 reachability support.
&gt; 
&gt;    This pseudo-flag should be given to relays that have:
&gt;      * a reachable IPv6 ORPort (in the consensus), and
&gt;      * support tor subprotocol version "Relay=3" (or later).
&gt;    See [Proposal 311: Relay IPv6 Reachability] for details.
&gt; 
&gt;    TODO: Is this a useful change?
&gt;          Are there better ways of driving IPv6 adoption?
&gt; 
&gt; 7.4. Add IPv6 Connections and Consumed Bandwidth Graphs to Tor Metrics
&gt; 
&gt;    The [Tor Metrics: Traffic] website displays connection and bandwidth
&gt;    information for the tor network, based on relay extra-info descriptors.
&gt; 
&gt;    We propose these optional changes, to:
&gt;      * help tor developers improve IPv6 support on the tor network,
&gt;      * help diagnose issues with IPv6 on the tor network, and
&gt;      * drive IPv6 adoption on tor relays.
&gt; 
&gt;    Tor Metrics adds the following information to the graphs on the Traffic
&gt;    page:
&gt; 
&gt;    Consumed Bandwidth by IP version
&gt;      * added to the existing [Tor Metrics: Advertised bandwidth by IP version]
&gt;        page
&gt;      * as a stacked graph, like
&gt;        [Tor Metrics: Advertised and consumed bandwidth by relay flags]
&gt; 
&gt;    Fraction of connections used uni-/bidirectionally by IP version
&gt;      * added to the existing
&gt;        [Tor Metrics: Fraction of connections used uni-/bidirectionally] page
&gt;      * as a stacked graph, like
&gt;        [Tor Metrics: Advertised and consumed bandwidth by relay flags]
&gt; 
&gt; 8. Test Plan
&gt; 
&gt;    We provide a quick summary of our testing plans.
&gt; 
&gt; 8.1. Testing IPv6 Relay Consensus Count Logging
&gt; 
&gt;    We propose to test these changes using chutney networks. However, chutney
&gt;    creates a limited number of relays, so we also need to test these changes
&gt;    on the public tor network.
&gt; 
&gt;    Therefore, we propose to test these changes on the public network with a
&gt;    small number of relays and bridges.
&gt; 
&gt;    We can use the script and the tor logs to cross-check these calculations.
&gt;    The Tor Metrics team may also independently check these calculations.
&gt; 
&gt;    Once these changes are merged, they will be monitored by tor developers, as
&gt;    more volunteer relay operators deploy the relevant tor versions. (And as the
&gt;    number of IPv6 relays in the consensus increases.)
&gt; 
&gt; 8.2. Testing IPv6 Extra-Info Statistics
&gt; 
&gt;    We propose to test the connection and consumed bandwidth statistics using
&gt;    chutney networks. However, chutney runs for a short amount of time, and
&gt;    creates a limited amount of traffic, so we also need to test these changes
&gt;    on the public tor network.
&gt; 
&gt;    In particular, we have struggled to test statistics using chutney, because
&gt;    tor's hard-coded statistics period is 24 hours. (And most chutney networks
&gt;    run for under 1 minute.)
&gt; 
&gt;    Therefore, we propose to test these changes on the public network with a
&gt;    small number of relays and bridges.
&gt; 
&gt;    During 2020, the Tor Metrics team will analyse these statistics on the
&gt;    public tor network, and provide IPv6 progress reports. We expect that we may
&gt;    discover some bugs during the first analysis.
&gt; 
&gt;    Once these changes are merged, they will be monitored by tor developers, as
&gt;    more volunteer relay operators deploy the relevant tor versions. (And as the
&gt;    number of IPv6 relays in the consensus increases.)
&gt; 
&gt; References:
&gt; 
&gt; [Consensus Health]:
&gt;    https://consensus-health.torproject.org/
&gt; 
&gt; [Proposal 288: Privacy-Preserving Stats with Privcount (Shamir version)]:
&gt;    https://gitweb.torproject.org/torspec.git/tree/proposals/288-privcount-with-shamir.txt
&gt; 
&gt; [Proposal 311: Relay IPv6 Reachability]:
&gt;    https://gitweb.torproject.org/torspec.git/tree/proposals/311-relay-ipv6-reachability.txt
&gt; 
&gt; [Proposal 312: Relay Auto IPv6 Address]:
&gt;    https://gitweb.torproject.org/torspec.git/tree/proposals/312-relay-auto-ipv6-addr.txt
&gt; 
&gt; [Relay Search]:
&gt;    https://metrics.torproject.org/rs.html
&gt; 
&gt; [Tor Directory Protocol]:
&gt;    (version 3) https://gitweb.torproject.org/torspec.git/tree/dir-spec.txt
&gt; 
&gt; [Tor Manual Page]:
&gt;    https://2019.www.torproject.org/docs/tor-manual.html.en
&gt; 
&gt; [Tor Metrics: Advertised and consumed bandwidth by relay flags]:
&gt;    https://metrics.torproject.org/bandwidth-flags.html
&gt; 
&gt; [Tor Metrics: Advertised bandwidth by IP version]:
&gt;    https://metrics.torproject.org/advbw-ipv6.html
&gt; 
&gt; [Tor Metrics: Fraction of connections used uni-/bidirectionally]:
&gt;    https://metrics.torproject.org/connbidirect.html
&gt; 
&gt; [Tor Metrics: Traffic]:
&gt;    https://metrics.torproject.org/bandwidth-flags.html
&gt; 
&gt; [Tor Specification]:
&gt;    https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 



["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200210152140</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-02-10 15:21:40-0400</timestampReceived><subject>Re: [tor-dev] Proposal 313: Relay IPv6 Statistics</subject><body>

On Mon, Feb 10, 2020 at 1:37 AM teor &lt;teor@riseup.net&gt; wrote:

Hi, Teor!  This proposal looks good and thorough to me.  I have only a
couple of questions on section 3:

&gt; 3. Logging IPv6 Relays in the Consensus
&gt;
&gt;    We propose that relays (and bridges) log:
&gt;      * the number of relays, and
&gt;      * the consensus weight fraction of relays,
&gt;    in the consensus that:
&gt;      * have an IPv6 ORPort,
&gt;      * support IPv6 reachability checks, and
&gt;      * support IPv6 clients.

I don't understand the motivation behind doing this in the Tor code,
since it's not something that relay operators need to know about or
take action on.  To me, it seems more like something do do as part of
metrics than in Tor per se.

 [...]
&gt;    "Usable Guards" have the Guard flag, but do not have the Exit flag. If the
&gt;    Guard also has the BadExit flag, the Exit flag should be ignored.

It seems to me that this rule should depend on the Wgd
bandwidth-weights value ("Weight for Guard+Exit-flagged nodes in the
guard Position"), right?  (Right now that is zero, and I don't expect
it to change.)

See also Karsten's response here for more information.
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200204211523</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-02-04 21:15:23-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

[Attachment #2 (multipart/signed)]


On 04 Feb (19:03:38), juanjo wrote:

Greetings!

&gt; Since no one is posting it here and talking about it, I will post it.
&gt; 
&gt; https://nvd.nist.gov/vuln/detail/CVE-2020-8516
&gt; 
&gt; The guy: http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
&gt; 
&gt; Is this real?
&gt; 
&gt; Are we actually not verifying if the IP of the Rend is a node in the Tor
&gt; network?

We (network team) actually don't think this is a bug but it is actually done
on purpose for specific reasons. Please see asn's answer on
https://bugs.torproject.org/33129 that explains why that is.

Onto the bigger issue at ends that the post explains. I'm going to extract the
relevant quote that this post is all about:

    Remember: the guard rarely changes but the other two hops change often.
    If he can repeatedly map out my circuit's last node, then he can build a
    large exclusion list. If he can exclude everything else, then he can find
    my guard node. And if he can't exclude everything, then he can probably
    whittle it down to a handful of possible guard nodes.

That is indeed a known attack. One can create a set of relays from the 3rd
node (last one before connecting to the rendezvous point) selected by the
service and doing enough requests to the service, you can end up with a very
large set of relays that can _not_ be your Guard due to how path selection
works as explained in the blog post.

You probably won't end up with one single Guard but rather a small set of
relays that could be it. For instance, if the service has setup ExcludeNodes
then they will all be in your set.

And the reason for private nodes is probably because this way you eliminate
noise from other tor traffic so _anything_ connecting back to your ORPort is
related to the onion service connections you've done. You don't need to filter
out the circuits with some custom code (which is very easy to do anyway).

That is unfortunately a problem that onion service have. These types of guard
discovery attacks exists and they are the primary reasons why we came up with
Vanguards couple years ago:

https://blog.torproject.org/announcing-vanguards-add-onion-services

But one thing for sure, simply forcing rendezvous points to be part of the
consensus will _not_ fix this problem as it is fairly easy to pull this type
of attack by simply using a normal relay within the consensus.

Hope this help!
David

-- 
Bbbgg4u8CrNOEpbT98JqIsuQesh4Pr607DGrz6pE1F8=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200204213030</emailId><senderName>Paul Syverson</senderName><senderEmail>paul.syverson@nrl.navy.mil</senderEmail><timestampReceived>2020-02-04 21:30:30-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

On Tue, Feb 04, 2020 at 04:15:23PM -0500, David Goulet wrote:
&gt; On 04 Feb (19:03:38), juanjo wrote:
&gt; 
[snip]
&gt; 
&gt; And the reason for private nodes is probably because this way you eliminate
&gt; noise from other tor traffic so _anything_ connecting back to your ORPort is
&gt; related to the onion service connections you've done. You don't need to filter
&gt; out the circuits with some custom code (which is very easy to do anyway).
&gt; 
&gt; That is unfortunately a problem that onion service have. These types of guard
&gt; discovery attacks exists and they are the primary reasons why we came up with
&gt; Vanguards couple years ago:
&gt; 
&gt; https://blog.torproject.org/announcing-vanguards-add-onion-services
&gt; 

Indeed. Just to underscore the point: we demonstrated those attacks
in the wild and proposed versions of vanguards in the same work where
we introduced guards in the first place, published way back in 2006.

&gt; But one thing for sure, simply forcing rendezvous points to be part of the
&gt; consensus will _not_ fix this problem as it is fairly easy to pull this type
&gt; of attack by simply using a normal relay within the consensus.
&gt; 
+1

aloha,
Paul
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200204220402</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2020-02-04 22:04:02-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


juanjo wrote:
&gt; Since no one is posting it here and talking about it, I will post it.
&gt; 
&gt; https://nvd.nist.gov/vuln/detail/CVE-2020-8516
&gt; 
&gt; The guy:
&gt; http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
&gt; 
&gt; 
&gt; Is this real?
&gt; 
&gt; Are we actually not verifying if the IP of the Rend is a node in the Tor
&gt; network?
&gt; 
&gt; 

When I saw `CVE-2020*` combined with Hidden Service deanonymization in
the title, I thought I'm going to have an interesting evening.

Then I saw:
This vulnerability is currently undergoing analysis and not all
information is available. Please check back soon to view the completed
vulnerability summary.

I don't think this should be a CVE. First of all, it's not really
deanonymization technically speaking. It's a 'Guard discovery attack'.
Of course, it can potentially lead to onion service deanonymization if
combined with another attack, so it's no secret this is quite possible.

However, this is a well known problem. The onion service client (think
of it as the visitor of a .onion website) is the one who chooses the
rendezvous point. This means it can choose a hostile one, under his
control, and at the same time run more middle relays and establish
rendezvous circuits with a particular onion service continuously until a
workable path from attacker's perspective is chosen.

The rendezvous point being a part of the consensus or not does not
actually make even the slightest difference. In fact, if we make a
requirement for the rendezvous point to be in the consensus (from onion
service server view of the network), we only end up with performance
limitations. Because onion service client and onion service server can
have (and often have) different views over the network. This is expected
to aggravate if we want to really scale Tor (check walking onions
proposal), so making this requirement will bottleneck Tor scaling
without actually fixing the slightest thing.

The only fix here is for Tor when running in onion service server mode
to keep a track of its historic established rendezvous circuits and
detect such attacks, because they are very trivial to detect:

A Tor relay that is not on the consensus is unmeasured, so it can have a
weight of n, thus a probability to be selected genuinely by a honest
onion service client is n%.

Now, you only look for insanely high n values. If your onion service
server has 90% of its last "m" established rendezvous circuits to the
same rendezvous point, you can't possibly think it's a coincidence right?


Same logic applies to rendezvous relays that are in the consensus as
well, only that you might allow a higher "n" value because you know
their weights, and they might be fast relays.

Thus in anyway your "n" cannot possibly be even near the limit an
attacker needs to perform a guard discovery attack.

I wrote a proposal sketch back in 2016 about this, it mitigates exactly
this attack:
https://lists.torproject.org/pipermail/tor-dev/2016-January/010291.html

The protection is called "RendGuard" and is implemented in the Vanguards
defense implemented by Mike Perry in 2018.

The RendGuard part of that could be in Tor by default, because it
doesn't face so many load-balancing issues and anti-fingerprinting
issues as opposite to layer 2 and layer 3 guards.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200205164110</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-02-05 16:41:10-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 2/4/20 3:15 PM, David Goulet wrote:
&gt; 
&gt; On 04 Feb (19:03:38), juanjo wrote:
&gt; 
&gt; Greetings!
&gt; 
&gt;&gt; Since no one is posting it here and talking about it, I will post it.
&gt;&gt;
&gt;&gt; https://nvd.nist.gov/vuln/detail/CVE-2020-8516
&gt;&gt;
&gt;&gt; The guy: http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
&gt;&gt;
&gt;&gt; Is this real?
&gt;&gt;
&gt;&gt; Are we actually not verifying if the IP of the Rend is a node in the Tor
&gt;&gt; network?
&gt; 
&gt; We (network team) actually don't think this is a bug but it is actually done
&gt; on purpose for specific reasons. Please see asn's answer on
&gt; https://bugs.torproject.org/33129 that explains why that is.
&gt; 
&gt; Onto the bigger issue at ends that the post explains. I'm going to extract the
&gt; relevant quote that this post is all about:
&gt; 
&gt;     Remember: the guard rarely changes but the other two hops change often.
&gt;     If he can repeatedly map out my circuit's last node, then he can build a
&gt;     large exclusion list. If he can exclude everything else, then he can find
&gt;     my guard node. And if he can't exclude everything, then he can probably
&gt;     whittle it down to a handful of possible guard nodes.
&gt; 
&gt; That is indeed a known attack. One can create a set of relays from the 3rd
&gt; node (last one before connecting to the rendezvous point) selected by the
&gt; service and doing enough requests to the service, you can end up with a very
&gt; large set of relays that can _not_ be your Guard due to how path selection
&gt; works as explained in the blog post.
&gt; 
&gt; You probably won't end up with one single Guard but rather a small set of
&gt; relays that could be it. For instance, if the service has setup ExcludeNodes
&gt; then they will all be in your set.

For completeness of understanding and to be thorough, there is an
interesting wrinkle in
http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
that might deserve some additional investigation.

Specifically: the "Forward in Reverse" subsection, which is covered in
more detail under "The Reverse Attack" here:
https://www.hackerfactor.com/blog/index.php?/archives/779-Behind-the-Tor-Attacks.html

The "Oddly, sometimes the connection would succeed" sentence is a red
flag sentence. If you are inclined to be paranoid, there is indeed a way
to hide a real attack in what looks like a simple ntohl() bug here.

This "sometimes" connection behavior is often seen in tagging attacks,
where the adversary abuses Tor's AES-CTR mode stream-cipher-style
properties to XOR a tag at one end of a circuit, and undo that tag only
if the other endpoint is present. In this way, only the connections that
actually succeed are those that the adversary is *certain* that they are
in both positions in the circuit (to perform Guard discovery, or if they
are the Guard relay, to confirm deanonymization).

If you want to hide your tagging attack as what looks like a simple
ntohl() bug here, you send your intro2 with the reverse IP address.
Then, when your middle node suspects a candidate rend cell (via timing +
circuit setup fingerprinting, to have a guess), it can confirm this
guess by undoing the tag by XORing the cipherstream with ntohl(ip) XOR ip.

Because of our stream-cipher-style use of AES-CTR, the busted rend cell
contains AES-CTR-cipherstream XOR ip. This means that when the adversary
XORs this position *again* with ip XOR ntohl(ip), they undo the tag:
  AES-CTR-cipherstream XOR ip XOR ip XOR ntohl(ip) =
  AES-CTR-cipherstream XOR ntohl(ip)

Aka a correctly performing rend cell tag hidden in what looks like a
very common networking bug.

This cipherstream tagging weakness has had a few proposals to fix, most
recently:
https://gitweb.torproject.org/torspec.git/tree/proposals/295-relay-crypto-with-adl.txt


BUT DON'T PANIC: There is also an alternate explanation for the
"sometimes succeed" red flag in this particular case, other than a
tagging attack.

Because Tor will actually use the rend relay fingerprint to try to find
an already-open connection before opening a new one, it is possible for
rends with a correct fingerprint to connect successfully, even if the IP
address is wrong, so long as a previous TLS connection to the correct IP
exists.

So most likely, this is just a poorly written Tor client, *but* there
still is the possibility that it is an attack cleverly disguised as a
poorly written Tor client.. :/


It may be a good idea for Neal's/our monitoring infrastructure to keep
an eye on this behavior too, for this reason, to test for the side
channel usage + rend XOR "correction" vs just dumb bug that is sometimes
connecting by getting lucky (and thus never properly reverses the rend
IP address). If this is indeed just a bug, when these rends do succeed,
the IP address should never be correct.

The way to do that would be to build rend circuits using 3rd hops that
you (the service operator) control, so that that 3rd hop can check if
the rend succeeds because the TLS connection happened to be open (benign
behavior) or because the reversed ntohl() got corrected somehow (attack).


Thank you for your vigilance, Neal!


-- 
Mike Perry




["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200212225931</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-12 22:59:31-0400</timestampReceived><subject>[tor-dev] Making Tor's CI Faster</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

Want to help make Tor's CI go faster?

As part of the Sponsor 55 IPv6 work, I need to run Chutney IPv6 tests
on every Tor commit, as part of Tor's CI.

We're currently running these tests with fast_finish, because:
* Travis CI only has IPv6 on macOS
* macOS Chutney tests take 20-45 minutes in Travis CI
But fast_finish requires allow_failure.

We can't have allow_failure on code that's we're modifying every day,
so I'm going to make the Travis IPv6 Chutney job mandatory.

To speed up CI after this change, I'm going to make a new IPv6-only
test-network target, and run it in the macOS CI:
https://trac.torproject.org/projects/tor/ticket/33280

I've also identified one redundant Travis CI job that we can delete:
https://trac.torproject.org/projects/tor/ticket/33195#comment:3

Overall, these changes should reduce total CI runtime by 20-35
minutes. Due to parallelism, the wall clock time should reduce by
10-35 minutes. We can squeeze the most benefit from the parallelism
by sorting jobs in speed order (longest first):
https://trac.torproject.org/projects/tor/ticket/33194

If you have any other ideas for making Tor's CI go faster, please let
me know.

Slow CI is a particular issue for backports, because each 0.3.5
backport updates 9 branches:
  * {maint,release}-{0.3.5,0.4.1,0.4.2,0.4.3} and
  * master.

T

--
teor
----------------------------------------------------------------------


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl5Eg1MACgkQEP6qDnB1
ZyogLBAArkAR8pdIgGDh1ASwCB0OVNL1T82kyRL7F9idUSjv9LBgSEm1zcrZ2s3E
+5VbgFLA9IToWkSAfonvU8tDjbsV+KOdyLbyc6qZD7dCKQSRs4tk7FE2O344Thph
LZew1qiDobfYD8f14P3pZEm8D+yiybT5Zyh+2c6FkUEyPPbiMVmtZq0oqbBeAvrc
o1v8pnoNe0T/qgwOmUg08Kt8QfUj1ogHVO66YKisz+v+4O/tp3zL568RtegXzlM8
5wZH4JFxVQv7jengeH1OPEcvmsMRHMfEj++8TRWajKHaXPKnLBZKINQCzE+ft2lQ
VrjuXsvKyBJLddvQEZrrJuM9i7hm4+r3Dwsk0nd2LddV6TmjabULnkdlVz8KXxVT
2q7YkSd+TyUVq9y9EKj+V0ISluAptPgJYhHUXTnR8YzCgsAFe8VX+GFKReKzqLEw
k/xHgRBh3GqCXTu/JGE2SuIzPKXrHlE/L7QwFyMOFlMVSUnK4lWqRmScMCPMxj7Y
pxHsl0RXAxt5SprU+d6Xfo9tjUcLuRkhu3HhsRIxUZvA4e5RSATxEpwMcYMAt1f3
Jw1wUCUKXpj+ndmkokFfaUeBSVjMK6nXXdV906Zg9yihU9fd0ZDLwkLWU1ASEV2l
mOYSlI+J+xzRUVXQ0CA/wq7SM7Ej4TpKdtEhHslZxmSRkSSv+wo=
=IPd3
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200206115421</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-02-06 11:54:21-0400</timestampReceived><subject>Re: [tor-dev] CVE-2020-8516 Hidden Service deanonymization</subject><body>

David Goulet &lt;dgoulet@torproject.org&gt; writes:

&gt; On 04 Feb (19:03:38), juanjo wrote:
&gt;
&gt; Greetings!
&gt;
&gt;&gt; Since no one is posting it here and talking about it, I will post it.
&gt;&gt; 
&gt;&gt; https://nvd.nist.gov/vuln/detail/CVE-2020-8516
&gt;&gt; 
&gt;&gt; The guy: http://www.hackerfactor.com/blog/index.php?/archives/868-Deanonymizing-Tor-Circuits.html
&gt;&gt; 
&gt;&gt; Is this real?
&gt;&gt; 
&gt;&gt; Are we actually not verifying if the IP of the Rend is a node in the Tor
&gt;&gt; network?
&gt;
&gt; We (network team) actually don't think this is a bug but it is actually done
&gt; on purpose for specific reasons. Please see asn's answer on
&gt; https://bugs.torproject.org/33129 that explains why that is.
&gt;
&gt; Onto the bigger issue at ends that the post explains. I'm going to extract the
&gt; relevant quote that this post is all about:
&gt;
&gt;     Remember: the guard rarely changes but the other two hops change often.
&gt;     If he can repeatedly map out my circuit's last node, then he can build a
&gt;     large exclusion list. If he can exclude everything else, then he can find
&gt;     my guard node. And if he can't exclude everything, then he can probably
&gt;     whittle it down to a handful of possible guard nodes.
&gt;
&gt; That is indeed a known attack. One can create a set of relays from the 3rd
&gt; node (last one before connecting to the rendezvous point) selected by the
&gt; service and doing enough requests to the service, you can end up with a very
&gt; large set of relays that can _not_ be your Guard due to how path selection
&gt; works as explained in the blog post.
&gt;

For what it's worth, I'm glad this discussion has been restarted because
we did lots of research work in 2018 about these sort of attacks, but we
were kinda drown in the various tradeoffs and ended up not doing much
after releasing the vanguard tool.

For people who are following from home and would like to help out here
is some reading materials:
   https://lists.torproject.org/pipermail/tor-dev/2018-April/013070.html
   https://lists.torproject.org/pipermail/tor-dev/2018-May/013162.html
   https://trac.torproject.org/projects/tor/ticket/25754

Basically, from what I remember, to defend against such attacks we
either need to change our path selection logic (#24487), or abandon the
path restrictions that cause infoleaks (big thread above), or use two
guards (prop#291 plus big thread above). Each of these options has its
own tradeoffs and we need to analyze them again. If someone could do a
summary that would be great to get this started again...

For now, if you are afraid of such attacks, you should use and love vanguards!

Thanks a lot! :-)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200219165922</emailId><senderName>Vianney Gomezgil Yaspik</senderName><senderEmail>vgomezg1@jhu.edu</senderEmail><timestampReceived>2020-02-19 16:59:22-0400</timestampReceived><subject>[tor-dev] TOR Browser Circuit Selection of Exit Nodes</subject><body>

Good evening,

A group of students at Johns Hopkins University and I have been analyzing t=
he circuit selection algorithm for TOR=B4s browser EXIT nodes. It is an exp=
loratory project trying to discover how do the EXIT nodes are selected ever=
y time the circuit changes.

So far, we have discovered that the time that the browser is accessed, cale=
ndar date, physical location, use of a bridge (or not), and the entry node =
do not change the pattern of the EXIT nodes. Moreover, than approximately 8=
0% of all exit nodes come from 10 specific countries, even though these 10 =
countries only account for approximately 50% of all available exit nodes.

All of which has led us to conclude that the selection of the EXIT nodes in=
 the TOR browser is not random. We would like to further explore however, w=
hat are the factors that determine which relay becomes the exit node every =
time a circuit is changed. Is there anyone that we could speak to or that c=
ould give us further insight as to how the selection of the exit node in TO=
R=B4s circuit works?

v/r


[Attachment #3 (text/html)]

&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"&gt;
&lt;style type="text/css" style="display:none;"&gt; P {margin-top:0;margin-bottom:0;} \
&lt;/style&gt; &lt;/head&gt;
&lt;body dir="ltr"&gt;
&lt;div style="font-family: Calibri, Arial, Helvetica, sans-serif; font-size: 12pt; \
color: rgb(0, 0, 0);"&gt; &lt;div style="margin: 0px; font-size: 12pt; font-family: \
Calibri, Arial, Helvetica, sans-serif; text-align: left; background-color: rgb(255, \
255, 255)"&gt; Good evening,&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; &lt;br&gt;
&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; A group of \
students at Johns Hopkins University and I have been analyzing the circuit selection \
algorithm for TORs browser EXIT nodes. It is an exploratory project trying to \
discover how do the EXIT nodes are selected every time the circuit \
changes.&lt;/div&gt; &lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, \
Arial, Helvetica, sans-serif; text-align: left; background-color: rgb(255, 255, \
255)"&gt; &lt;br&gt;
&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; So far, we have \
discovered that the time that the browser is accessed, calendar date, physical \
location, use of a bridge (or not), and the entry node do not change the pattern of \
the EXIT nodes. Moreover, than approximately 80% of all exit nodes come from 10  \
specific countries, even though these 10 countries only account for approximately 50% \
of all available exit nodes.&lt;/div&gt; &lt;div style="margin: 0px; font-size: 12pt; \
font-family: Calibri, Arial, Helvetica, sans-serif; text-align: left; \
background-color: rgb(255, 255, 255)"&gt; &lt;br&gt;
&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; All of which has \
led us to conclude that the selection of the EXIT nodes in the TOR browser is not \
random. We would like to further explore however, what are the factors that determine \
which relay becomes the exit node every time a circuit is changed. Is there  anyone \
that we could speak to or that could give us further insight as to how the selection \
of the exit node in TORs circuit works?&lt;/div&gt; &lt;div style="margin: 0px; font-size: \
12pt; font-family: Calibri, Arial, Helvetica, sans-serif; text-align: left; \
background-color: rgb(255, 255, 255)"&gt; &lt;br&gt;
&lt;/div&gt;
&lt;div style="margin: 0px; font-size: 12pt; font-family: Calibri, Arial, Helvetica, \
sans-serif; text-align: left; background-color: rgb(255, 255, 255)"&gt; v/r&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;


[Attachment #4 (unknown)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200223002436</emailId><senderName>indigo omega</senderName><senderEmail>indigoomega021@gmail.com</senderEmail><timestampReceived>2020-02-23 00:24:36-0400</timestampReceived><subject>[tor-dev] interested in working on a ticket</subject><body>

[Attachment #2 (multipart/alternative)]


Hello,

I am a new contributor interested in working on ticket 13184:
https://trac.torproject.org/projects/tor/ticket/13184 .
The ticket says that it was assigned 8 months ago, but then deleted? I am
having trouble understanding if this ticket is under current development or
not. Should I start working on it and submit it for review, or should I
email someone, perhaps a maintainer, to see if someone is actively working
on it. Any advice would be much appreciated.

Thank you,

Amir Ghorbanian

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am a new contributor  interested in \
working on ticket 13184:  &lt;a \
href="https://trac.torproject.org/projects/tor/ticket/13184" \
target="_blank"&gt;https://trac.torproject.org/projects/tor/ticket/13184&lt;/a&gt;  \
.&lt;/div&gt;&lt;div&gt;The ticket says that it was assigned 8 months ago, but then deleted? I am \
having trouble understanding if this ticket is under current development or not. \
Should I start working on it and submit it for review, or should I email someone, \
perhaps a maintainer, to see if someone is actively working on it. Any advice would \
be much appreciated.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thank \
you,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Amir Ghorbanian&lt;/div&gt;&lt;/div&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200109161556</emailId><senderName>Patrick Schleizer</senderName><senderEmail>patrick-mailinglists@whonix.org</senderEmail><timestampReceived>2020-01-09 16:15:56-0400</timestampReceived><subject>[tor-dev] OK got mix vanguards from packages.debian.org with Tor from deb.torproject.org repository?</subject><body>

I am considering to install vanguards by default in Whonix.

Is it sane to mix the Debian 'tor' package deb.torproject.org (buster
repository) with packages.debian.org buster version of 'vanguards' or do
you foresee any issues?

Cheers,
Patrick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200113123937</emailId><senderName>Valentin Franck</senderName><senderEmail>gaspar_ilom@win.tu-berlin.de</senderEmail><timestampReceived>2020-01-13 12:39:37-0400</timestampReceived><subject>[tor-dev] Evaluating rendezvous circuit build up CPU usage</subject><body>

Hello tor-devs,

I am currently working on a DoS mitigation system aiming to protect the
availability of onion services flooded with INTRO2 cells. My idea is
using a (Privacy Pass like) token based approach as suggested in
https://trac.torproject.org/projects/tor/ticket/31223#comment:6

For the evaluation of a first prototype I would like to compare CPU
usage times at the onion service when a) launching a rendezvous circuit
and b) validating a (potentially invalid) token. Is there an easy way,
to measure the CPU time a service spends for all operations triggered
when launching a new rendezvous circuit? Has somebody done that before?
Basically, I want to measure how much CPU time we save, if we do not
launch the rendezvous circuit. So far I have identified the following
functions: launch_rendezvous_point_circuit() and
service_rendezvous_circ_has_opened(). I understand that there is more
operations involved for building new circuits, since circuits are built
hop by hop. How can I   identify all relevant functions triggered after
launching the rendezvous circuit and include them in my measurements?

Once I have some reliable results I will provide you with more
information on what I am doing and how it is working so far.

Cheers
Valentin

This is my first post on this list :-). So have mercy, if I overlooked
resources to answer my question. Also, I am only beginning to
familiarize myself with the existing code base.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200106164838</emailId><senderName>"procmem () riseup ! net"</senderName><senderEmail>procmem@riseup.net</senderEmail><timestampReceived>2020-01-06 16:48:38-0400</timestampReceived><subject>[tor-dev] Snowflake server and traffic analysis questions</subject><body>


Goal: We (Whonix) are researching optional bridge hosting for our users
to thwart web fingerprinting. Snowflake makes the most sense since no
NAT hole-punching is needed. Correct me if I'm wrong here because if
that was possible with obfs4 or meek it would save a lot of work.

We now know acting as a bridge makes the user act as a guard node and
not just a rendezvous to one.[1]

[1]
https://tor.stackexchange.com/questions/3636/what-is-the-relationship-between-guard-nodes-and-bridges

Some questions to help with implementation:

* Do the user's own data go through just two hops as well or are they
sent to the guard node they chose before deciding to run as a bridge?
How do configure Tor to do the former if it isn't?

* Are there plans to create signed debs for snowflake client/server so
we can use it with Debian's tor daemon?
  
* Do Tor Browser bundles with the snowflake addon also include the
server component?

* Do Alpha bundles have this code yet?

* When are these bundles expected to arrive to stable?

* Is it possible to interact headlessly with the snowflake server
component via commandline? How?

* How can we run TBB headlessly so users don't mistakenly interact with
it on the gateway?



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200115193603</emailId><senderName>Cecylia Bocovich</senderName><senderEmail>cohosh@torproject.org</senderEmail><timestampReceived>2020-01-15 19:36:03-0400</timestampReceived><subject>Re: [tor-dev] Snowflake server and traffic analysis questions</subject><body>

&gt; Goal: We (Whonix) are researching optional bridge hosting for our users
&gt; to thwart web fingerprinting. Snowflake makes the most sense since no
&gt; NAT hole-punching is needed. Correct me if I'm wrong here because if
&gt; that was possible with obfs4 or meek it would save a lot of work.
&gt; 
&gt; We now know acting as a bridge makes the user act as a guard node and
&gt; not just a rendezvous to one.[1]

Hi,

Thanks for the email. We'reassuming you are considering this website
fingerprinting defense after reading this recent blog post:
https://blog.torproject.org/new-low-cost-traffic-analysis-attacks-mitigations

First, to clear up some information about Snowflake:
- Volunteer Snowflakes run proxies to the bridge, *not bridges
themselves*. These proxies can be run behind a NAT because clients use
the built-in NAT punching properties of WebRTC to connect. The proxies
then open a WebSocket connection the Snowflake bridge and relay data
between the WebRTC connection with the client and the bridge.
- The Snowflake bridges cannot run behind a NAT and are similar to all
other existing PTs in this regard.
- See https://trac.torproject.org/projects/tor/wiki/doc/Snowflakefor
more information

So, in order to implement use the defence referenced in the blog post in
a Snowflake setting (and behind a NAT), you would have to run a
Snowflake proxy and write your own client that would encapsulate your
Tor traffic and send it through a TCP WebSocket connection to the
Snowflake bridge.

However, we do not think this will be an effective website
fingerprinting defence, for reasons outlined below:

1) The defense as described in
https://github.com/mikeperry-tor/vanguards/blob/master/README_SECURITY.md=#the-best-way-to-run-tor-relays-or-bridges-with-your-service
 is meant to hide *onion service traffic*, not client exit traffic
through the
Tor network. So unless your intended use case is to disguise an onion
service that is running behind a NAT, this defence isn't what you want.
And, in fact, outside of onion services we don't yet suspect website
fingerprinting of client traffic to be a severe enough threat to warrant
this type of defense for internet-destined tor traffic. As the blog post
states, while the attack is an improvement and points to areas where
we should look for mitigations, there still are barriers to a practical
attack against generic tor exit traffic.

2) Because Snowflake traffic between each client and your proxy is a
distinct WebRTC connection and corresponding traffic between the proxy
and the Snowflake bridge is a distinct TCP connection, it would be
trivial for an adversary to filter out traffic originating from your
node (i.e., your onion service traffic) from other clients' proxy
traffic by simply matching up WebRTC and WebSocket flows by matching
patterns of incoming and outgoing packets. The WebSocket flow that does
not have a corresponding WebRTC connection will be your onion service
traffic which can then be fingerprinted as easily as before.

3) We'd like to clarify that we suspect this defense to be the helpful,
but it has not yet been conclusively shown to be so, and likely may not
be in DPI'd bridge and/or low-traffic situations. In fact, after some
discussion, we suspect that in most cases, other PT's bridge traffic will
also be posible to remove from consideration, in ways beyond the simple
connection matching above. To really have a chance of other traffic
providing cover, client traffic needs to be mixed with concurrent
relayed Tor relay traffic, which may require a relatively high speed
main network relay to happen frequently enough to help.

Mike has filed vanguards issue #50
(https://github.com/mikeperry-tor/vanguards/issues/50)
to correct and clarify the vanguards documentation on these points.

&gt; [1]
&gt; https://tor.stackexchange.com/questions/3636/what-is-the-relationship-betwee \
&gt; &lt;https://tor.stackexchange.com/questions/3636/what-is-the-relationship-between-guard-nodes-and-bridges&gt;n \
&gt; &lt;https://tor.stackexchange.com/questions/3636/what-is-the-relationship-between-guard-nodes-and-bridges&gt;-guard-nodes-and-bridges \
&gt; &lt;https://tor.stackexchange.com/questions/3636/what-is-the-relationship-between-guard-nodes-and-bridges&gt;
&gt;  
&gt; Some questions to help with implementation:
&gt; 
&gt; * Do the user's own data go through just two hops as well or are they
&gt; sent to the guard node they chose before deciding to run as a bridge?
&gt; How do configure Tor to do the former if it isn't?

 If you configure a bridge using the same Tor client instance, then
 client-originating traffic will still use an upstream guard node, and
 more hops after that. However, this has some downsides in terms of
 potential stalls in all traffic during client activity, which undo some
 of the benefit from having additional through traffic:
 https://trac.torproject.org/projects/tor/ticket/16585

 There is also some risk if the bridge extra-info descriptor can be
 obtained (not sure if this is possible) due to
 https://trac.torproject.org/projects/tor/ticket/8742

 If you use the separated tor instance setup described in
 https://github.com/mikeperry-tor/vanguards/blob/master/README_SECURITY.md#the-best-way-to-run-tor-relays-or-bridges-with-your-serviceto
 avoid the client-induced traffic stalling problem,
 then user traffic will use one less hop, since the "Guard" position will
 be taken up by the locally run but separate tor Bridge instance.
 This is less of a problem for onion traffic with vanguards because there
still are Layer2 vanguard nodes after that. But for non-onion traffic,
users will only be using 2 hops after the local bridge. Mike will also
clarify this point in the vanguards documentation.

&gt; * Are there plans to create signed debs for snowflake client/server so
&gt; we can use it with Debian's tor daemon?
&gt; * Do Tor Browser bundles with the snowflake addon also include the
&gt; server component?

They do not. In fact, you cannot run a Snowflake proxy from Tor Browser,
since Tor Browser disables WebRTC.

&gt; * Do Alpha bundles have this code yet?

Yes, alpha bundles allow you to use the Snowflake pluggable transport as
a client.

&gt; * When are these bundles expected to arrive to stable?

Not sure! But soon, probably. We have a few outstanding performance
considerations to tackle.

&gt; * Is it possible to interact headlessly with the snowflake server
&gt; component via commandline? How?

Yes, see the instructions in the client README on the Snowflake repo:
https://gitweb.torproject.org/pluggable-transports/snowflake.git/tree/client/README.md?id=3D6077141f4affdab9b7ce97a9b1c6859825eaaa29


&gt; * How can we run TBB headlessly so users don't mistakenly interact with
&gt; it on the gateway?

You can send Tor traffic (both with and without configured pluggable
transports) without using Tor Browser by configuring a torrc file and
running `tor -f torrc`.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200114130452</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-01-14 13:04:52-0400</timestampReceived><subject>Re: [tor-dev] Evaluating rendezvous circuit build up CPU usage</subject><body>

[Attachment #2 (multipart/signed)]


On 13 Jan (13:39:37), Valentin Franck wrote:
&gt; Hello tor-devs,

Hi Valentin!

&gt; 
&gt; I am currently working on a DoS mitigation system aiming to protect the
&gt; availability of onion services flooded with INTRO2 cells. My idea is
&gt; using a (Privacy Pass like) token based approach as suggested in
&gt; https://trac.torproject.org/projects/tor/ticket/31223#comment:6

Do _please_ talk to asn here as he is also doing research on this.

&gt; 
&gt; For the evaluation of a first prototype I would like to compare CPU
&gt; usage times at the onion service when a) launching a rendezvous circuit
&gt; and b) validating a (potentially invalid) token. Is there an easy way,
&gt; to measure the CPU time a service spends for all operations triggered
&gt; when launching a new rendezvous circuit? Has somebody done that before?
&gt; Basically, I want to measure how much CPU time we save, if we do not
&gt; launch the rendezvous circuit. So far I have identified the following
&gt; functions: launch_rendezvous_point_circuit() and
&gt; service_rendezvous_circ_has_opened(). I understand that there is more
&gt; operations involved for building new circuits, since circuits are built
&gt; hop by hop. How can I  identify all relevant functions triggered after
&gt; launching the rendezvous circuit and include them in my measurements?

I do use a pretty extensive tracing patchset on "tor" to measure the hidden
service timings so all this work is done, just not upstream yet...

But it turns out that I'm currently actively working on the tracing API and
adding tracepoints to tor for upstream merge in the coming month.

If you can wait that long, you might have it all in tor soon else I can point
you to the branch but will require some work on your side to make it work with
a specific trace I use (LTTng userspace).

But at least you can see where the tracepoints are in the code:

https://gitweb.torproject.org/user/dgoulet/tor.git/tree/src/lib/trace/lttng/lttng.h?h=lttng-hs

Most tracepoints are client side for the HS. For service, to track the
timings, I use the circuit tracepoint. Just grep where they are put in the
code.

Hope this help a bit until we have tracing upstream.

Cheers!
David

-- 
wlQW8e6zy9BjPFoNUszA+ip0Fa+lseCuCGd+6jzB1KI=

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200115171735</emailId><senderName>juanjo</senderName><senderEmail>juanjo@avanix.es</senderEmail><timestampReceived>2020-01-15 17:17:35-0400</timestampReceived><subject>Re: [tor-dev] Evaluating rendezvous circuit build up CPU usage</subject><body>

Hi, thanks for working on it.

At first I thought about using a PoW on the Introduction Point (I.P.) side.

Maybe a dynamic PoW? I mean only ask for PoW under load (Hidden services 
sets the INTRO1s/second on the I.P.) or ask for every new circuit.

Then I thought that we need to fix the Rendezvous verification issue 
too. We do not verify if the client/user/attacker actually opened a 
circuit to the Rend point. And I thought we could make the Rend sing a 
message and the I.P verify the signature before sending the INTRO2 to 
the HS.

But now I think we need to merge designs and make just one proposal 
fixing both problems at the same time.

If we don't want to make a PoW for every new circuit, we could make the 
client generate a private Identity (KeyPair) mixed with some sort of 
PoW, generating it for every HS a client want to connect. This way we 
only make PoW for each onion and the IP can have a replay cache (or 
something like that) with each identity and the last time it requested a 
new circuit. We can better control with this way the number of 
individual clients and we "save the planet" by not making a PoW for each 
new circuit. (Maybe this approach is what your are working at with the 
"token based approach").

Sorry for my english...


El 13/1/20 a las 13:39, Valentin Franck escribi:
&gt; Hello tor-devs,
&gt;
&gt; I am currently working on a DoS mitigation system aiming to protect the
&gt; availability of onion services flooded with INTRO2 cells. My idea is
&gt; using a (Privacy Pass like) token based approach as suggested in
&gt; https://trac.torproject.org/projects/tor/ticket/31223#comment:6
&gt;
&gt; For the evaluation of a first prototype I would like to compare CPU
&gt; usage times at the onion service when a) launching a rendezvous circuit
&gt; and b) validating a (potentially invalid) token. Is there an easy way,
&gt; to measure the CPU time a service spends for all operations triggered
&gt; when launching a new rendezvous circuit? Has somebody done that before?
&gt; Basically, I want to measure how much CPU time we save, if we do not
&gt; launch the rendezvous circuit. So far I have identified the following
&gt; functions: launch_rendezvous_point_circuit() and
&gt; service_rendezvous_circ_has_opened(). I understand that there is more
&gt; operations involved for building new circuits, since circuits are built
&gt; hop by hop. How can I   identify all relevant functions triggered after
&gt; launching the rendezvous circuit and include them in my measurements?
&gt;
&gt; Once I have some reliable results I will provide you with more
&gt; information on what I am doing and how it is working so far.
&gt;
&gt; Cheers
&gt; Valentin
&gt;
&gt; This is my first post on this list :-). So have mercy, if I overlooked
&gt; resources to answer my question. Also, I am only beginning to
&gt; familiarize myself with the existing code base.
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200109163054</emailId><senderName>Iain Learmonth</senderName><senderEmail>irl@torproject.org</senderEmail><timestampReceived>2020-01-09 16:30:54-0400</timestampReceived><subject>Re: [tor-dev] OK got mix vanguards from packages.debian.org with Tor from deb.torproject.org reposit</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi,

On 09/01/2020 16:15, Patrick Schleizer wrote:
&gt; I am considering to install vanguards by default in Whonix.
&gt; 
&gt; Is it sane to mix the Debian 'tor' package deb.torproject.org (buster
&gt; repository) with packages.debian.org buster version of 'vanguards' or do
&gt; you foresee any issues?

I would not forsee any issues.

vanguards does have checks on the tor version to see which things are
available, and uses the things that are correct for the version of tor
in use.

Let me know if there are any issues relating to the systemd unit, etc.

Thanks,
Iain.


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200223010120</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-02-23 01:01:20-0400</timestampReceived><subject>Re: [tor-dev] interested in working on a ticket</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Amir,

&gt; On 23 Feb 2020, at 10:28, indigo omega &lt;indigoomega021@gmail.com&gt; wrote:
&gt; 
&gt; I am a new contributor interested in working on ticket 13184: \
&gt; https://trac.torproject.org/projects/tor/ticket/13184 . The ticket says that it was \
&gt; assigned 8 months ago, but then deleted? I am having trouble understanding if this \
&gt; ticket is under current development or not. Should I start working on it and submit \
&gt; it for review, or should I email someone, perhaps a maintainer, to see if someone \
&gt; is actively working on it. Any advice would be much appreciated.

I don't think anyone is actively working on Torsocks right now.

I have cc'd David to confirm. David is the Torsocks maintainer.

T


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="content-type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body dir="auto"&gt;&lt;div dir="ltr"&gt;Hi \
Amir,&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir="ltr"&gt;&lt;blockquote type="cite"&gt;On 23 Feb 2020, \
at 10:28, indigo omega &lt;indigoomega021@gmail.com&gt; \
wrote:&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;blockquote type="cite"&gt;&lt;div dir="ltr"&gt;&lt;div \
dir="ltr"&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am a new contributorinterested in working on \
ticket 13184:&lt;a href="https://trac.torproject.org/projects/tor/ticket/13184" \
target="_blank"&gt;https://trac.torproject.org/projects/tor/ticket/13184&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;The \
ticket says that it was assigned 8 months ago, but then deleted? I am having trouble \
understanding if this ticket is under current development or not. Should I start \
working on it and submit it for review, or should I email someone, perhaps a \
maintainer, to see if someone is actively working on it. Any advice would be much \
appreciated.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;div&gt;I don't think anyone is actively \
working on Torsocks right now.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I have cc'd David to confirm. \
David is the Torsocks \
maintainer.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;T&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;


[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200219204300</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2020-02-19 20:43:00-0400</timestampReceived><subject>Re: [tor-dev] TOR Browser Circuit Selection of Exit Nodes</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


possibly useful for you:

https://gitweb.torproject.org/torspec.git/tree/path-spec.txt
https://gitweb.torproject.org/torspec.git/tree/guard-spec.txt



--=20
https://mastodon.social/@nusenu


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200102153028</emailId><senderName>"procmem () riseup ! net"</senderName><senderEmail>procmem@riseup.net</senderEmail><timestampReceived>2020-01-02 15:30:28-0400</timestampReceived><subject>[tor-dev] Bridge benefits stackable?</subject><body>

Hi. We are considering allowing users to run their daemon (optionally)
as a bridge in addition to client mode for increased traffic
fingerprinting resistance [1].

Does running a bridge prevent you from using a bridge yourself? I've
seen it mentioned that using bridges can protect users in event of a
malicious guard node. Can the benefits of being a bridge and connecting
to one be stacked? What is the best practice here?

Happy New Year.

[1]
https://blog.torproject.org/new-low-cost-traffic-analysis-attacks-mitigations

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200107175848</emailId><senderName>juanjo</senderName><senderEmail>juanjo@avanix.es</senderEmail><timestampReceived>2020-01-07 17:58:48-0400</timestampReceived><subject>[tor-dev] Request info about how the Tor HS DoS works</subject><body>

[Attachment #2 (multipart/alternative)]


Hello, since months ago we are debating proposals about how to stop HS 
being DDoSed. We have many open issues and even developed in a rush a 
fix "just for the network" (not HS availability).

But, I have not seen yet a good explanation about what is really 
happening when HS is being DDoSed by this famous and effective attack. I 
mean, the only thing I know about it is that its goal is to send a ton 
of INTRODUCE2 cells to the HS, but, what is the cost for the attacker? 
Some questions need to be answered, at least If I want to understand it 
and make a proposal for fixing this issues.

*Questions:*

Is the attacker building a circuit to the Rendz point as expected by the 
protocol? How can we be sure of that?

-Attacker (client) to Rendezvous point circuit:

What is exactly happening on this circuit and how can the attacker 
improve the attack?

Is the attacker using the same Rendz over and over for its INTRODUCE1? A 
new circuit to the Rendz? Can the first two hops of a circuit be reused 
(only changing the exit node) so it can build a new circuit to a new 
Rendz faster and make the attack better?

-Attacker (client) to Intro point:

what is exactly happening on this side of the equation?


Sorry, but I could not find the answer to these questions and what is 
going on on any ticket or this mail lists.


[Attachment #5 (text/html)]

&lt;html&gt;
  &lt;head&gt;

    &lt;meta http-equiv="content-type" content="text/html; charset=UTF-8"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Hello, since months ago we are debating proposals about how to
      stop HS being DDoSed. We have many open issues and even developed
      in a rush a fix "just for the network" (not HS availability).&lt;/p&gt;
    &lt;p&gt;But, I have not seen yet a good explanation about what is really
      happening when HS is being DDoSed by this famous and effective
      attack. I mean, the only thing I know about it is that its goal is
      to send a ton of INTRODUCE2 cells to the HS, but, what is the cost
      for the attacker? Some questions need to be answered, at least If
      I want to understand it and make a proposal for fixing this
      issues.&lt;/p&gt;
    &lt;p&gt;&lt;b&gt;Questions:&lt;/b&gt;&lt;/p&gt;
    &lt;p&gt;Is the attacker building a circuit to the Rendz point as expected
      by the protocol? How can we be sure of that?&lt;/p&gt;
    &lt;p&gt;-Attacker (client) to Rendezvous point circuit:&lt;/p&gt;
    &lt;p&gt;What is exactly happening on this circuit and how can the
      attacker improve the attack?&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;Is the attacker using the same Rendz over and over for its
      INTRODUCE1? A new circuit to the Rendz? Can the first two hops of
      a circuit be reused (only changing the exit node) so it can build
      a new circuit to a new Rendz faster and make the attack better?&lt;/p&gt;
    &lt;p&gt;-Attacker (client) to Intro point: &lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;what is exactly happening on this side of the equation? &lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;Sorry, but I could not find the answer to these questions and
      what is going on on any ticket or this mail lists. &lt;br&gt;
    &lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200112203748</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2020-01-12 20:37:48-0400</timestampReceived><subject>[tor-dev] Should we remove the ClientAutoIPv6ORPort option?</subject><body>

Hi tor-dev@,

Ticket: https://trac.torproject.org/projects/tor/ticket/32905
GitHub PR: https://github.com/torproject/tor/pull/1652

Considering that people had issues with the ClientAutoIPv6ORPort option, 
like when IPv6 was tried on IPv4-only connections in [1] and [2], I 
think we should just remove the ClientAutoIPv6ORPort option.

Plus, we are going to do real Happy Eyeballs in Prop306, making 
ClientAutoIPv6ORPort redundant.

Should we?

-Neel

Sources:
[1] - https://blog.torproject.org/comment/281976#comment-281976
[2] - https://blog.torproject.org/comment/282102#comment-282102
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200113163518</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-01-13 16:35:18-0400</timestampReceived><subject>Re: [tor-dev] Changes to accessing and using MaxMind's databases</subject><body>

On Thu, Jan 9, 2020 at 8:25 AM Karsten Loesing &lt;karsten@torproject.org&gt; wrote:
&gt;
&gt; Hi!
&gt;
&gt; When trying to update tor's geoip databases the other day I found that
&gt; MaxMind's GeoLite2 database is not available for download anymore. The
&gt; reason is:
&gt;
&gt; https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-using-geolite2-databases/
&gt;
&gt; We do not have a MaxMind account (yet). As of now, we cannot update
&gt; tor's geoip files nor the files used by Onionoo.
&gt;
&gt; Should we try to get somebody who knows more about licenses and legal
&gt; stuff to review their GeoLite2 EULA and tell us if it's okay for us to
&gt; sign up for a MaxMind account? A possible downside would be that whoever
&gt; wants to verify that we didn't mess with their database when converting
&gt; it to our format would have to sign up for an account, too.
&gt;
&gt; An alternative is to find another, truly open data source than MaxMind
&gt; databases (#25542, #26585). However, this could eat up more time than we
&gt; currently have available, and we should have something ready in a few
&gt; weeks from now. I'm not sure how we would squeeze this into the metrics
&gt; team schedule, so we might need help with this.
&gt;
&gt; Thoughts on the two alternatives? What else did I miss?

There's a debian-legal thread here:

https://lists.debian.org/debian-legal/2020/01/threads.html

From what I can tell, Maxmind's new EULA is not compatible with
redistributing the information as free software, but of course I am
not a lawyer.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200116160111</emailId><senderName>"procmem () riseup ! net"</senderName><senderEmail>procmem@riseup.net</senderEmail><timestampReceived>2020-01-16 16:01:11-0400</timestampReceived><subject>[tor-dev] Vanguard Plugin Options</subject><body>

Hi. We are rolling out the vanguard plugin for our users and wanted to
understand some options we can enable.

* In many parts of the Security README setting *circ_max_megabytes* is
recommended. Though it is discouraged for usecases involving Onionshare
and Securedrop which we support. What is a reasonable limit to set? What
happens is the max ceiling gets hit? Does it permanently disrupt the
upload/download?

* "High load onion services may consider using 4 layer2 guards by
changing the *num_layer2_guards* option in the configuration file
&lt;https://github.com/mikeperry-tor/vanguards/blob/master/vanguards-example.conf&gt;,
but going beyond that is not recommended."
Does this benefit clients too? We would like to enable options that
mimic the configuration used by actual high load onion services to
provide them with more cover.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200124063058</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-01-24 06:30:58-0400</timestampReceived><subject>[tor-dev] Prop 311: Relay IPv6 Reachability</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

Here is an initial draft of Proposal 311: Relay IPv6 Reachability.

This proposal includes:
  * relay IPv6 ORPort extends, and
  * relay IPv6 ORPort reachability checks.

This is the first of 3 proposals:
* Proposal 311: Relay IPv6 Reachability
* Proposal 312: Automatic Relay IPv6 Addresses
* Proposal 313: Relay IPv6 Statistics
(I haven't written the others yet!)

I also want to make some minor changes to Proposal 306, so that bridge
IPv6 behaviour stays in sync with client IPv6 behaviour.

There are still a few TODO items in the proposal, mostly about Tor's
current behaviour. If you know the answers, please let me know.

The full text is included below, and it is also available as a GitHub
pull request:
https://github.com/torproject/torspec/pull/103

The related tickets are #24404 (proposal) and #24403 (implementation):
https://trac.torproject.org/projects/tor/ticket/24404
https://trac.torproject.org/projects/tor/ticket/24403

Please feel free to reply on this list, or via GitHub pull request
comments.

Filename: 311-relay-ipv6-reachability.txt
Title: Tor Relay IPv6 Reachability
Author: teor
Created: 22-January-2020
Status: Draft
Ticket: #24404

0. Abstract

   We propose that Tor relays and bridges should check the reachability of
   their IPv6 ORPort, before publishing their descriptor. To check IPv6 ORPort
   reachability, relays and bridges need to be able to extend circuits via
   other relays, and back to their own IPv6 ORPort.

1. Introduction

   Tor relays and bridges currently check the reachability of their IPv4
   ORPort and DirPort before publishing them in their descriptor. But relays
   and bridges do not test the reachability of their IPv6 ORPorts.

   However, Directory Authorities make direct connections to relay IPv4 and
   IPv6 ORPorts, to test each relay's reachability. Once a relay has been
   confirmed as reachable by a majority of authorities, it is included in the
   consensus. (Currently, 6 out of 9 Directory Authorities perform IPv4 and
   IPv6 reachability checks. The others just check IPv4.)

   The Bridge authority makes direct connections to bridge IPv4 ORPorts, to
   test each bridge's reachability. Depending on its configuration, it may also
   test IPv6 ORPorts. Once a bridge has been confirmed as reachable by the
   bridge authority, it is included in the bridge networkstatus used by
   BridgeDB.

   Many relay and bridge operators don't know when their relay's IPv6 ORPort is
   unreachable. They may not find out until they check [Relay Search], or
   their traffic may drop. For new operators, it might just look like Tor
   simply isn't working, or it isn't using much traffic. IPv6 ORPort issues
   are a significant source of relay and bridge operator support requests.

   Implementing IPv6 ORPort reachability checks will provide immediate, direct
   feedback to operators in the relay or bridge's logs. It also enables future
   work, such as automatically discovering relay and bridge addresses for IPv6
   ORPorts (see [Proposal 312]).

2. Scope

   This proposal modifies Tor's behaviour as follows:

   Relays:
   * circuit extension,
   * OR connections for circuit extension,
   * reachability testing.

   Bridges:
   * reachability testing only.

   This proposal does not change client behaviour.

   When this proposal describes Tor's current behaviour, it covers all
   supported Tor versions (0.3.5.7 to 0.4.2.5), as of January 2020.

3. Allow Relay IPv6 Extends

   To check IPv6 ORPort reachability, relays and bridges need to be able to
   extend circuits via other relays, and back to their own IPv6 ORPort.

   We propose that relays start to extend some circuits over IPv6 connections.
   We do not propose any changes to bridge extend behaviour.

3.1. Current IPv6 ORPort Implementation

   Currently, all relays and bridges must have an IPv4 ORPort. IPv6 ORPorts
   are optional for relays and bridges.

   Tor supports making direct IPv6 OR connections:
     * from directory authorities to relay ORPorts,
     * from the bridge authority to bridge ORPorts,
     * from clients to relay and bridge ORPorts.

   Tor relays and bridges accept IPv6 ORPort connections. But IPv6 ORPorts are
   not currently included in extend requests to other relays. And even if an
   extend cell contains an IPv6 ORPort, bridges and relays will not extend
   via an IPv6 connection to another relay.

   Instead, relays will extend circuits:
     * Using an existing authenticated connection to the requested relay
       (which is typically over IPv4), or
     * Over a new connection via the IPv4 ORPort in an extend cell.

   If a relay receives an extend cell that only contains an IPv6 ORPort, the
   extend typically fails.

3.2. Relays Extend to IPv6 ORPorts

   We propose that relays make some connections via the IPv6 ORPorts in
   extend cells.

   Relays will extend circuits:
     * using an existing authenticated connection to the requested relay
       (which may be over IPv4 or IPv6), or
     * over a new connection via the IPv4 or IPv6 ORPort in an extend cell.

   Since bridges try to imitate client behaviour, they will not adopt this new
   behaviour, until clients begin routinely connecting via IPv6. (See
   [Proposal 306].)

3.2.1. Making IPv6 ORPort Extend Connections

   Relays can make a new connection over IPv6 when:
     * there is no existing authenticated connection to the requested relay,
       and
     * the extend cell contains an IPv6 ORPort.

   If these conditions are satisfied, and the extend cell also contains an
   IPv4 ORPort, we propose that the relay choose between an IPv4 and an IPv6
   connection at random.

   If the extend cell does not contain an IPv4 ORPort, we propose that the
   relay connects over IPv6. (Relays should support IPv6-only extend cells,
   even though they are not used to test relay reachability in this proposal.)

   A successful IPv6 connection also requires that:
     * the requested relay has an IPv6 ORPort.
   But extending relays must not check the consensus for other relays' IPv6
   information. Consensuses may be out of date, particularly when relays are
   doing reachability checks for new IPv6 ORPorts.

   See section 3.3.2 for other situations where IPv6 information may be
   incorrect or unavailable.

3.2.2. No Tor Client Changes

   Tor clients currently include IPv4 ORPorts in their extend cells, but they
   do not include IPv6 ORPorts.

   We do not propose any client IPv6 extend cell changes at this time.

   The Tor network needs more IPv6 relays, before clients can safely use
   IPv6 extends. (Relays do not require anonymity, so they can safely use
   IPv6 extends to test their own reachability.)

   We also recommend prioritising client to relay IPv6 connections
   (see [Proposal 306]) over relay to relay IPv6 connections. Because client
   IPv6 connections have a direct impact on users.

3.3. Alternative Extend Designs

   We briefly mention some potential extend designs, and the reasons that
   they were not used in this proposal.

   (Some designs may be proposed for future Tor versions, but are not necessary
   at this time.)

3.3.1. Future Relay IPv6 Extend Behaviour

   Random selection of extend ORPorts is a simple design, which supports IPv6
   ORPort reachability checks.

   However, it is not the most efficient design when:
     * both relays meet the requirements for IPv4 and IPv6 extends,
     * a new connection is required,
     * the relays have either IPv4 or IPv6 connectivity, but not both.

   In this very specific case, this proposal results in an average of 1
   circuit extend failure per new connection. (Because relays do not try to
   connect to the other ORPort when the first one fails.)

   If relays try both the IPv4 and IPv6 ORPorts, then the circuit would
   succeed. For example, relays could try the alternative port after a 250ms
   delay, as in [Proposal 306]. This design results in an average circuit delay
   of up to 125ms per new connection, rather than failure.

   However, partial relay connectivity should be uncommon. And relays keep
   connections open long-term, so new relay connections are a small proportion
   of extend requests.

   Therefore, we defer implementing any more complex designs. Since we propose
   to use IPv6 extends to test relay reachability, occasional circuit extend
   failures have a very minor impact.

3.3.2. Future Bridge IPv6 Extend Behaviour

   When clients automatically connect to relay IPv4 and IPv6 ORPorts by
   default, bridges should also adopt this behaviour. (For example,
   see [Proposal 306].)

3.3.3. Rejected Extend Designs

   Some designs may never be suitable for the Tor network.

   We rejected designs where relays check the consensus to see if other
   relays support IPv6, because:
     * relays may have different consensuses,
     * the extend cell may have been created using a version of the
       [Onion Service Protocol] which supports IPv6, or
     * the extend cell may be from a relay that has just added IPv6, and is
       testing the reachability of its own ORPort (see Section 4).

   We avoided designs where relays try to learn if other relays support IPv6,
   because these designs:
     * are more complex than random selection,
     * potentially leak information between different client circuits,
     * may enable denial of service attacks, where a flood of incorrect extend
       cells causes a relay to believe that another relay is unreachable on an
       ORPort that actually works, and
     * require careful tuning to match the typical interval at which network
       connectivity is actually changing.

4. Check Relay and Bridge IPv6 ORPort Reachability

   We propose that relays and bridges check their own IPv6 ORPort reachability.

   To check IPv6 ORPort reachability, relays and bridges extend circuits via
   other relays, and back to their own IPv6 ORPort.

   IPv6 reachability failures may result in a relay or bridge refusing to
   publish its descriptor, if enough existing relays support IPv6 extends.

4.1. Current Reachability Implementation

   Relays and bridges check the reachability of their IPv4 ORPorts and
   DirPorts, and refuse to publish their descriptor if either reachability
   check fails.

   IPv4 ORPort reachability checks succeed when any create cell is received on
   any inbound OR connection. The check succeeds, even if the cell is from an
   IPv6 ORPort, or a circuit built by a client.

   Directory Authorities make direct connections to relay IPv4 and IPv6
   ORPorts, to test each relay's reachability. Relays that fail either
   reachability test, on enough directory authorities, are excluded from the
   consensus.

   The Bridge authority makes direct connections to bridge IPv4 ORPorts, to
   test each bridge's reachability. Depending on its configuration, it may also
   test IPv6 ORPorts. Bridges that fail either reachability test are excluded
   from BridgeDB.

4.2. Checking IPv6 ORPort Reachability

   We propose that testing relays (and bridges) select some IPv6 extend-capable
   relays for their reachability circuits, and include their own IPv4 and IPv6
   ORPorts in the final extend cells on those circuits.

   The final extending relay will extend to the testing relay:
     * using an existing authenticated connection to the testing relay
       (which may be over IPv4 or IPv6), or
     * over a new connection via the IPv4 or IPv6 ORPort in the extend cell.

   The testing relay will confirm that test circuits can extend to both its
   IPv4 and IPv6 ORPorts.

4.2.1. Selecting the Final Extending Relay

   IPv6 ORPort reachability checks require an IPv6 extend-capable relay as
   the second-last hop of reachability circuits. (The testing relay is the
   last hop.)

   IPv6-extend capable relays must have:
     * Relay subprotocol version 3 (or later), and
     * an IPv6 ORPort.
   (See section 5.1 for the definition of Relay subprotocol version 3.)

   The other relays in the path do not require any particular protocol
   versions.

4.2.2. Extending from the Second-Last Hop

   IPv6 ORPort reachability circuits should put the IPv4 and IPv6 ORPorts in
   the extend cell for the final extend in reachability circuits.

   Supplying both ORPorts makes these extend cells indistinguishable from
   future client extend cells.

   If reachability succeeds, the testing relay (or bridge) will accept the
   final extend on one of its ORPorts, selected at random by the extending
   relay (see section 3.2.1).

4.2.3. Separate IPv4 and IPv6 Reachability Flags

   Testing relays (and bridges) will record reachability separately for IPv4
   and IPv6 ORPorts, based on the ORPort that the test circuit was received on.

4.2.4. No Changes to DirPort Reachability

   We do not propose any changes to relay IPv4 DirPort reachability checks at
   this time.

   The following configurations are currently not supported:
     * bridge DirPorts, and
     * relay IPv6 DirPorts.
   Therefore, they are also out of scope for this proposal.

4.3. Refuse to Publish Descriptor if IPv6 ORPort is Unreachable

   If an IPv6 ORPort reachability check fails, relays (and bridges) should log
   a warning.

   In addition, if IPv6ORPort reachability checks are reliable, based on the
   number of relays in the network that support IPv6 extends, relays should
   refuse to publish their descriptor.

4.3.1. Refusing to Publish the Descriptor

   We set a threshold of consensus relays for reliable IPv6 ORPort checks:
     * at least 30 relays, and
     * at least 1% of the total consensus weight,
   must support IPv6 extends.

   We chose these parameters so that the number of relays is triple the
   number of directory authorities, and the consensus weight is high enough
   to support occasional reachability circuits.

   In small networks with:
     * less than 2000 relays, or
     * a total consensus weight of zero,
   the threshold should be the minimum tor network size to test reachability:
     * at least 2 relays, excluding this relay.
   (Note: we may increase this threshold to 3 or 4 relays if we discover a
   higher minimum during testing.)

   If the current consensus satisfies this threshold, testing relays (and
   bridges) that fail IPv6 ORPort reachability checks should refuse to publish
   their descriptors.

   To ensure an accurate threshold, testing relays should exclude:
     * the testing relay itself, and
     * relays that they will not use in testing circuits,
   from the:
     * relay count, and
     * the numerator of the threshold percentage.

   Typically, relays will be excluded if they are in the testing relay's:
     * family,
     * IPv4 address /16 network,
     * IPv6 address /32 network (a requirement as of Tor 0.4.0.1-alpha),
   unless EnforceDistinctSubnets is 0.

   As a useful side-effect, these different thresholds for each relay family
   will reduce the likelihood of the network flapping around the threshold.

   If flapping has an impact on the network health, directory authorities
   should set the AssumeIPv6Reachable consensus parameter. (See the next
   section.)

4.3.2. Add AssumeIPv6Reachable Option

   We add an AssumeIPv6Reachable torrc option and consensus parameter.

   If IPv6 ORPort checks have bugs that impact the health of the network,
   they can be disabled by setting AssumeIPv6Reachable=1 in the consensus
   parameters.

   If IPv6 ORPort checks have bugs that impact a particular relay (or bridge),
   they can be disabled by setting "AssumeIPv6Reachable 1" in the relay's
   torrc.

   This option disables IPv6 ORPort reachability checks, so relays publish
   their descriptors if their IPv4 ORPort reachability checks succeed.

   The default for the torrc option is "auto", which checks the consensus
   parameter. If the consensus parameter is not set, the default is "0".

   "AssumeReachable 1" overrides all values of "AssumeIPv6Reachable",
   disabling both IPv4 and IPv6 ORPort reachability checks.

4.4. Optional Efficiency and Reliability Changes

   We propose some optional changes for efficiency and reliability, and
   describe their impact.

   Some of these changes may be more appropriate in future releases, or
   along with other proposed features.

4.4.1. Extend IPv6 From All Supported Second-Last Hops

   The testing relay (or bridge) puts both IPv4 and IPv6 ORPorts in its final
   extend cell, and the receiving ORPort is selected at random by the
   extending relay (see sections 3.2.1 and 4.2). Therefore, approximately half
   of IPv6 ORPort reachability circuits will actually end up confirming IPv4
   ORPort reachability.

   We propose this optional change, to improve the rate of IPv6 ORPort
   reachability checks:

   If the second-last hop of an IPv4 ORPort reachability circuit supports IPv6
   extends, testing relays may put the IPv4 and IPv6 ORPorts in the extend
   cell for the final extend.

   As the number of relays that support IPv6 extends increases, this change
   will increase the number of IPv6 reachability confirmations. In the ideal
   case, where the entire network supports IPv4 and IPv6 extends, IPv4 and IPv6
   ORPort reachability checks would require a similar number of circuits.

4.4.2. Close Existing Connections Before Testing Reachability

   When a busy relay is performing reachability checks, it may already have
   established inbound or outbound connections to the second-last hop in its
   reachability test circuits. The extending relay may use these connections
   for the extend, rather than opening a connection to the target ORPort
   (see sections 3.2 and 4.2.2).

   Bridges only establish outbound connections to other relays, and only over
   IPv4 (except for reachability test circuits). So they are still potentially
   affected by this issue.

   We propose these optional changes, to improve the efficiency of IPv4 and
   IPv6 ORPort reachability checks:

   Testing relays (and bridges):
     * close any outbound connections to the second-last hop of reachability
       circuits, and
     * close inbound connections to the second-last hop of reachability
       circuits, if those connections are not using the target ORPort.

   Even though it is unlikely that bridges will have inbound connections to
   a non-target ORPort, bridges should still do inbound connection checks, for
   consistency.

   These changes are particularly important if a relay is connected to all
   other relays in the network, but only over IPv4. (Or in the future, only
   over IPv6.)

   We expect that these changes will slightly increase the number of relay
   re-connections, but reduce the number of reachability test circuits
   required to confirm reachability.

4.4.3. Accurately Identifying Test Circuits

   The testing relay (or bridge) may confirm that the create cells it is
   receiving are from its own test circuits, and that test circuits are
   capable of returning create cells to the origin.

   Currently, relays confirm reachability if any create cell is received on
   any inbound connection (see section 4.1). Relays do not check that the
   circuit is a reachability test circuit, and they do not wait to receive the
   return created cell. This behaviour has resulted in difficult to diagnose
   bugs on some rare relay configurations.

   We propose these optional changes, to improve the efficiency of IPv4 and
   IPv6 ORPort reachability checks:

   Testing relays may:
     * check that the create cell is received from a test circuit
       (by comparing the received cell to the cells sent by test circuits),
     * check that the create cell is received on an inbound connection
       (this is existing behaviour),
     * if the create cell from a test circuit is received on an outbound
       connection, destroy the circuit (rather than returning a created cell),
       and
     * check that the created cell is returned to the relay on a test circuit
       (by comparing the remote address of the final hop on the circuit, to
       the local IPv4 and IPv6 ORPort addresses).

   TODO: work out how to efficiently match inbound create cells to test
         circuits.

4.4.4. Allowing More Relay IPv6 Extends

   Currently, clients, relays, and bridges do not include IPv6 ORPorts in their
   extend cells.

   In this proposal, we only make relays (and bridges) extend over IPv6 on
   the final hop of test circuits. This limited use of IPv6 extends means that
   IPv6 connections will still be uncommon.

   We propose these optional changes, to increase the number of IPv6
   connections between relays:

   To increase the number of IPv6 connections, relays that support IPv6
   extends may want to use them for all hops of their own circuits. Relays
   make their own circuits for reachability tests, bandwidth tests, and
   ongoing preemptive circuits. (Bridges can not change their behaviour,
   because they try to imitate clients.)

   We propose a torrc option and consensus parameter SendIPv6CircuitExtends,
   which is only supported on relays (and not bridges or clients). This option
   makes relays send IPv4 and IPv6 ORPorts in all their extend cells, when
   supported by the extending and receiving relay. (See section 3.2.1.)

   TODO: Is there a shorter name, that isn't easily confused with enabling
         support for other nodes to perform IPv6 extends via this relay?

   The default value for this option is "auto", which checks the consensus
   parameter. If the consensus parameter is not set, it defaults to "0" in
   the initial release.

   Once IPv6 extends have had enough testing, we may enable
   SendIPv6CircuitExtends on the network. The consensus parameter will be set
   to 1. The default will be changed to "1" (if the consensus parameter is not
   set).

   We defer any client (and bridge) changes to a separate proposal, to be
   implemented when there are more IPv6 relays in the network. But we note
   that relay IPv6 extends will provide some cover traffic when clients
   eventually use IPv6 extends in their circuits.

   As a useful side effect, increasing the number of IPv6 connections in the
   network makes it more likely that an existing connection can be used for
   the final hop of a relay IPv6 ORPort reachability check.

4.5. Alternate Reachability Designs

   We briefly mention some potential reachability designs, and the reasons that
   they were not used in this proposal.

4.5.1. Removing IPv4 ORPorts from Extend Cells

   We avoid designs that only include IPv6 ORPorts in extend cells, and remove
   IPv4 ORPorts.

   Only including the IPv6 ORPort would provide slightly more specific
   reachability check circuits. However, we don't need IPv6-only designs,
   because relays continue trying different reachability circuits until they
   confirm reachability.

   IPv6-only designs also make it easy to distinguish relay reachability extend
   cells from other extend cells. This distinguisher will become more of an
   issue as IPv6 extends become more common in the network (see sections 4.2.2
   and 4.4.4).

   Removing the IPv4 ORPort also provides no fallback, if the IPv6 ORPort is
   actually unreachable. IPv6-only failures do not affect reachability checks,
   but they will become important in the future, as other circuit types start
   using IPv6 extends.

   IPv6-only reachability designs also increase the number of special cases in
   the implementation. (And the likelihood of subtle bugs.)

   These designs may be appropriate in future, when there are IPv6-only bridges
   or relays.

5. New Relay Subprotocol Version

   We reserve Tor subprotocol "Relay=3" for:
     * relays that support for IPv6 extends, and
     * relays and bridges that support IPv6 ORPort reachability checks,
   as described in this proposal.

5.1. Tor Specification Changes

   We propose the following changes to the [Tor Specification], once this
   proposal is implemented.

   Adding a new Relay subprotocol version lets testing relays identify other
   relays that support IPv6 extends. It also allows us to eventually recommend
   or require support for IPv6 extends on all relays (and bridges).

   Append to the Relay version 2 subprotocol specification:

          Relay=2 has limited IPv6 support:
            * Clients do not include IPv6 ORPorts in EXTEND2 cells.
            * Relays do not not initiate IPv6 connections in response to
              EXTEND2 cells containing IPv6 ORPorts.
          However, relays accept inbound connections to their IPv6 ORPorts,
          and will extend circuits via those connections.

   "3" -- relays support extending over IPv6 connections in response to an
          EXTEND2 cell containing an IPv6 ORPort. Relays and bridges perform
          IPv6 ORPort reachability checks. Client behaviour does not change.

          This subprotocol is advertised by all relays and bridges, regardless
          of their configured ORPorts. But relays without a configured IPv6
          ORPort may refuse to extend over IPv6. And bridges always refuse to
          extend over IPv6, because they try to imitate client behaviour.

          A successful IPv6 extend requires:
            * Relay subprotocol version 3 (or later) and an IPv6 ORPort on the
              extending relay,
            * an IPv6 ORPort in the EXTEND2 cell, and
            * an IPv6 ORPort on the accepting relay.
          (Because different tor instances can have different views of the
          network, these checks should be done when the path is selected.
          Extending relays should only check local IPv6 information, before
          attempting the extend.)

          This subprotocol version is described in proposal 311, and
          implemented in Tor 0.4.4.1-alpha. (TODO: check version after code is
          merged).

6. Test Plan

   We provide a quick summary of our testing plans.

6.1. Test IPv6 ORPort Reachability and Extends

   We propose to test these changes using chutney networks with AssumeReachable
   disabled. (Chutney currently enables AssumeReachable by default.)

   We also propose to test these changes on the public network with a small
   number of relays and bridges.

   Once these changes are merged, volunteer relay and bridge operators will be
   able to test them by:
     * compiling from source,
     * running nightly builds, or
     * running alpha releases.

6.2. Test Existing Features

   We will modify and test these existing features:
     * IPv4 ORPort reachability checks

   We do not plan on modifying these existing features:
     * Relay reachability retries
       TODO: Do relays re-check their own reachability? How often?
     * Relay canonical connections
     * "Too many connections" warning logs
   But we will test that they continue to function correctly, and fix any bugs
   triggered by the modifications in this proposal.

6.3. Test Legacy Relay Compatibility

   We will also test IPv6 extends from newer relays (which implement this
   proposal) to older relays (which do not). Although this proposal does not
   create these kinds of circuits, we need to check for bugs and excessive
   logs in older tor versions.

8. Ongoing Monitoring

   To monitor the impact of these changes, relays should collect basic IPv4
   and IPv6 connection and bandwidth statistics (see [Proposal 313]).

   We may also collect separate statistics on connections from:
     * clients (and bridges, because they act like clients), and
     * other relays (and authorities, because they act like relays).

   We do not propose to collect additional statistics on:
     * bridges,
     * circuit counts, or
     * failure rates.
   Collecting statistics like these could impact user privacy.

References:

[Onion Service Protocol]: In particular, Version 3 of the Onion Service Protocol \
supports IPv6: https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt

[Proposal 306]: One possible design for automatic client IPv4 and IPv6 connections is \
at https://gitweb.torproject.org/torspec.git/tree/proposals/306-ipv6-happy-eyeballs.txt \
(TODO: modify to include bridge changes with client changes)

[Proposal 312]: https://gitweb.torproject.org/torspec.git/tree/proposals/312-auto-relay-ipv6.txt \
(TODO)

[Proposal 313]: https://gitweb.torproject.org/torspec.git/tree/proposals/313-relay-ipv6-stats.txt \
(TODO)

[Relay Search] https://metrics.torproject.org/rs.html

[Tor Specification]: https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt

--

(End)


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl4qjyIACgkQEP6qDnB1
ZypYYA//Qho44KXK02+Eo9eveSirmDV8YRU1Pw2hfVdKkgRwX5UnGCEA43ulPBnG
wm7X0Z6WqJ9PjyOWlmYND1Si7jukobBJmUyE3Kw0WHMHRPBB1Qgk6Jx0WELJl3aQ
ntHWckPzv7WMIuDOaALqSQ/MGuhGNIOCVqALNZNRuEtsJTH90h7HGq8tEDR/gkqm
S9y1tbfNYJHSKZToexZwYHpzRSgyl3HIPiFCvXpTRvb+tlrVC+6bog53S842cdu/
TZiMr7PcPD5SVRn2zXepbHVypyQ0vFxDnR+GdTMc21Vcwy5psF2vgTrw25c+3B9E
o1+jc1wFefdwYeZRlyTxNiYVyiOP75D5UNNEXelMxVZ0zx8YyYA9Vn+ZHG7+OpsZ
7VehHaFzhsPQ8CouAbAOfdcvKpVVAQrz+ylhpZ3De8WfeDzc9EcQbVQ+eM+ihPDg
/ERK7Eu7jtHrElFl2sZ54sXWa22YxKG9TeIFSbbDT2ABA/xgQbblMFU3dPb+aom4
mFSbnLJKOWeAjIWGm0k13rOGU4ldo8LRdH92msxFz3t8/fUhEWnoBw8dt8K2eV3k
FQBJT1qXp4b8rXo0fqwWWnsuS0Pe3EXMH5EbDnOxVuIrftqpar649ORHfcVdJF4N
M1O/jKJd8cFyttOLt8szh96KiuGlwG4R99rc7xsOF4te7YABqjM=
=Q9Mi
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200124200955</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-01-24 20:09:55-0400</timestampReceived><subject>Re: [tor-dev] Prop 311: Relay IPv6 Reachability</subject><body>

On Fri, Jan 24, 2020 at 1:31 AM teor &lt;teor@riseup.net&gt; wrote:
&gt; 
&gt; Hi,
&gt; 
&gt; Here is an initial draft of Proposal 311: Relay IPv6 Reachability.
&gt; 
&gt; This proposal includes:
&gt; * relay IPv6 ORPort extends, and
&gt; * relay IPv6 ORPort reachability checks.
&gt; 
&gt; This is the first of 3 proposals:
&gt; * Proposal 311: Relay IPv6 Reachability
&gt; * Proposal 312: Automatic Relay IPv6 Addresses
&gt; * Proposal 313: Relay IPv6 Statistics
&gt; (I haven't written the others yet!)
&gt; 
&gt; I also want to make some minor changes to Proposal 306, so that bridge
&gt; IPv6 behaviour stays in sync with client IPv6 behaviour.
&gt; 
&gt; There are still a few TODO items in the proposal, mostly about Tor's
&gt; current behaviour. If you know the answers, please let me know.
&gt; 
&gt; The full text is included below, and it is also available as a GitHub
&gt; pull request:
&gt; https://github.com/torproject/torspec/pull/103
&gt; 
&gt; The related tickets are #24404 (proposal) and #24403 (implementation):
&gt; https://trac.torproject.org/projects/tor/ticket/24404
&gt; https://trac.torproject.org/projects/tor/ticket/24403
&gt; 
&gt; Please feel free to reply on this list, or via GitHub pull request
&gt; comments.

Hello, Teor!  I hope this reply finds you well.

This proposal seems like a good start: It's solid, readable, and I
think it would work.  There are few places where I have questions or
suggested clarifications, and a few where I think we should consider
other designs as well.

I'm going to only quote the parts I'm commenting on.

&gt; 3.2.1. Making IPv6 ORPort Extend Connections
&gt; 
&gt; Relays can make a new connection over IPv6 when:
&gt; * there is no existing authenticated connection to the requested relay,
&gt; and
&gt; * the extend cell contains an IPv6 ORPort.

Also we should probably have the condition, "The relay itself supports
IPv6, or thinks that it does"?

&gt; If these conditions are satisfied, and the extend cell also contains an
&gt; IPv4 ORPort, we propose that the relay choose between an IPv4 and an IPv6
&gt; connection at random.
&gt; 
&gt; If the extend cell does not contain an IPv4 ORPort, we propose that the
&gt; relay connects over IPv6. (Relays should support IPv6-only extend cells,
&gt; even though they are not used to test relay reachability in this proposal.)
&gt; 
&gt; A successful IPv6 connection also requires that:
&gt; * the requested relay has an IPv6 ORPort.
&gt; But extending relays must not check the consensus for other relays' IPv6
&gt; information. Consensuses may be out of date, particularly when relays are
&gt; doing reachability checks for new IPv6 ORPorts.
&gt; 
&gt; See section 3.3.2 for other situations where IPv6 information may be
&gt; incorrect or unavailable.

[...]
&gt; 3.3. Alternative Extend Designs
&gt; 
&gt; We briefly mention some potential extend designs, and the reasons that
&gt; they were not used in this proposal.
&gt; 
&gt; (Some designs may be proposed for future Tor versions, but are not necessary
&gt; at this time.)

Let me sketch another alternative design here:

Suppose that a relay's extend cell contains the IPv4 address and the
IPv6 address in their _preferred order_.  So if the party generating
the extend cell would prefer an IPv4 connection, it puts the IPv4
addess first; if it would prefer an IPv6 connection, it puts the IPv6
address first.

The relay that receives the extend cell could respond in several ways:
   * One possibility (similar to your 3.2.1) is to choose at random,
with a higher probability given to the first option.
   * One possibility (similar to your 3.3.1) is to try the first, and
then try the second if the first one fails.

I think this scheme has some advantage, in that it lets the
self-testing relay say "please try IPv6 if you can" or "please try
IPv4 if you can" in a reliable way, and lets us migrate from the
current behavior to the 3.3.1 behavior down the road.


[...]
&gt; 4.3. Refuse to Publish Descriptor if IPv6 ORPort is Unreachable
&gt; 
&gt; If an IPv6 ORPort reachability check fails, relays (and bridges) should log
&gt; a warning.
&gt; 
&gt; In addition, if IPv6ORPort reachability checks are reliable, based on the
&gt; number of relays in the network that support IPv6 extends, relays should
&gt; refuse to publish their descriptor.

Is this the behavior we want?  Another behavior would be to omit our
IPv6 orport from our descriptor if it is not reachable.  That way,
relay operators could configure their relays to just listen on IPv6
unconditionally, and let the relay figure out whether it should
advertise IPv6 or not.  This behavior  seems preferable to me, since
it has less chance of breaking a relay that would otherwise "work".

As a third possibility, we could have an option to say whether we
should publish a descriptor if some of our addresses are not
reachable.

 [...]
&gt; 4.3.2. Add AssumeIPv6Reachable Option
&gt; 
&gt; We add an AssumeIPv6Reachable torrc option and consensus parameter.
&gt; 
&gt; If IPv6 ORPort checks have bugs that impact the health of the network,
&gt; they can be disabled by setting AssumeIPv6Reachable=1 in the consensus
&gt; parameters.
&gt; 
&gt; If IPv6 ORPort checks have bugs that impact a particular relay (or bridge),
&gt; they can be disabled by setting "AssumeIPv6Reachable 1" in the relay's
&gt; torrc.
&gt; 
&gt; This option disables IPv6 ORPort reachability checks, so relays publish
&gt; their descriptors if their IPv4 ORPort reachability checks succeed.
&gt; 
&gt; The default for the torrc option is "auto", which checks the consensus
&gt; parameter. If the consensus parameter is not set, the default is "0".
&gt; 
&gt; "AssumeReachable 1" overrides all values of "AssumeIPv6Reachable",
&gt; disabling both IPv4 and IPv6 ORPort reachability checks.

Should we have some way to AssumeReachable our IPv4 address only, and
not our IPv6 address?  Or is that too much?

&gt; 4.4. Optional Efficiency and Reliability Changes
&gt; 
&gt; We propose some optional changes for efficiency and reliability, and
&gt; describe their impact.
&gt; 
&gt; Some of these changes may be more appropriate in future releases, or
&gt; along with other proposed features.
&gt; 


 [...]
&gt; 4.4.3. Accurately Identifying Test Circuits
&gt; 
&gt; The testing relay (or bridge) may confirm that the create cells it is
&gt; receiving are from its own test circuits, and that test circuits are
&gt; capable of returning create cells to the origin.
&gt; 
&gt; Currently, relays confirm reachability if any create cell is received on
&gt; any inbound connection (see section 4.1). Relays do not check that the
&gt; circuit is a reachability test circuit, and they do not wait to receive the
&gt; return created cell. This behaviour has resulted in difficult to diagnose
&gt; bugs on some rare relay configurations.
&gt; 
&gt; We propose these optional changes, to improve the efficiency of IPv4 and
&gt; IPv6 ORPort reachability checks:

If we make these changes, I think we should track both whether we are
"maybe reachable" (under the current definition of 'reachable') and
"definitely reachable" (based on the new definition).   We should log
different messages depending on whether we are "maybe reachable" but
these new tests fail, or whether we are completely unreachable.

&gt; Testing relays may:
&gt; * check that the create cell is received from a test circuit
&gt; (by comparing the received cell to the cells sent by test circuits),
&gt; * check that the create cell is received on an inbound connection
&gt; (this is existing behaviour),
&gt; * if the create cell from a test circuit is received on an outbound
&gt; connection, destroy the circuit (rather than returning a created cell),
&gt; and
&gt; * check that the created cell is returned to the relay on a test circuit
&gt; (by comparing the remote address of the final hop on the circuit, to
&gt; the local IPv4 and IPv6 ORPort addresses).
&gt; 
&gt; TODO: work out how to efficiently match inbound create cells to test
&gt; circuits.

One possibility: we could store a set of our test circuits' extend
cells g^X values, and then check incoming cells create cells against
that set.

There are probably fancier designs based on EC trickery or tweaks to
the ntor protocol, but I think we'd best avoid them.

&gt; 4.4.4. Allowing More Relay IPv6 Extends
&gt; 
&gt; Currently, clients, relays, and bridges do not include IPv6 ORPorts in their
&gt; extend cells.
&gt; 
&gt; In this proposal, we only make relays (and bridges) extend over IPv6 on
&gt; the final hop of test circuits. This limited use of IPv6 extends means that
&gt; IPv6 connections will still be uncommon.
&gt; 
&gt; We propose these optional changes, to increase the number of IPv6
&gt; connections between relays:
&gt; 
&gt; To increase the number of IPv6 connections, relays that support IPv6
&gt; extends may want to use them for all hops of their own circuits. Relays
&gt; make their own circuits for reachability tests, bandwidth tests, and
&gt; ongoing preemptive circuits. (Bridges can not change their behaviour,
&gt; because they try to imitate clients.)
&gt; 
&gt; We propose a torrc option and consensus parameter SendIPv6CircuitExtends,
&gt; which is only supported on relays (and not bridges or clients). This option
&gt; makes relays send IPv4 and IPv6 ORPorts in all their extend cells, when
&gt; supported by the extending and receiving relay. (See section 3.2.1.)
&gt; 
&gt; TODO: Is there a shorter name, that isn't easily confused with enabling
&gt; support for other nodes to perform IPv6 extends via this relay?

I have another concern here: if this option is truly relay-only, it
should probably have a name that indicates the fact.

&gt; The default value for this option is "auto", which checks the consensus
&gt; parameter. If the consensus parameter is not set, it defaults to "0" in
&gt; the initial release.
&gt; 
&gt; Once IPv6 extends have had enough testing, we may enable
&gt; SendIPv6CircuitExtends on the network. The consensus parameter will be set
&gt; to 1. The default will be changed to "1" (if the consensus parameter is not
&gt; set).
&gt; 
&gt; We defer any client (and bridge) changes to a separate proposal, to be
&gt; implemented when there are more IPv6 relays in the network. But we note
&gt; that relay IPv6 extends will provide some cover traffic when clients
&gt; eventually use IPv6 extends in their circuits.
&gt; 
&gt; As a useful side effect, increasing the number of IPv6 connections in the
&gt; network makes it more likely that an existing connection can be used for
&gt; the final hop of a relay IPv6 ORPort reachability check.



&gt; 4.5. Alternate Reachability Designs
&gt; 
&gt; We briefly mention some potential reachability designs, and the reasons that
&gt; they were not used in this proposal.
&gt; 
&gt; 4.5.1. Removing IPv4 ORPorts from Extend Cells
&gt; 
&gt; We avoid designs that only include IPv6 ORPorts in extend cells, and remove
&gt; IPv4 ORPorts.
&gt; 
&gt; Only including the IPv6 ORPort would provide slightly more specific
&gt; reachability check circuits. However, we don't need IPv6-only designs,
&gt; because relays continue trying different reachability circuits until they
&gt; confirm reachability.
&gt; 
&gt; IPv6-only designs also make it easy to distinguish relay reachability extend
&gt; cells from other extend cells. This distinguisher will become more of an
&gt; issue as IPv6 extends become more common in the network (see sections 4.2.2
&gt; and 4.4.4).
&gt; 
&gt; Removing the IPv4 ORPort also provides no fallback, if the IPv6 ORPort is
&gt; actually unreachable. IPv6-only failures do not affect reachability checks,
&gt; but they will become important in the future, as other circuit types start
&gt; using IPv6 extends.
&gt; 
&gt; IPv6-only reachability designs also increase the number of special cases in
&gt; the implementation. (And the likelihood of subtle bugs.)
&gt; 
&gt; These designs may be appropriate in future, when there are IPv6-only bridges
&gt; or relays.

As an aside: I think in the long run, the future is for clients to
treat relays' link specifiers as completely opaque when they are
making extend cells.

That is, if a client is extending to some relay X, it should know
"here is a blob that you use as X's link specifiers" -- it can be the
authorities' job to decide which IP addresses and which identity keys
such a blob needs to contain.

(Of course, a client still needs to know a relay's address when making
a connection itself, but that's more in prop306 territory.)

&gt; 5. New Relay Subprotocol Version
&gt; 
&gt; We reserve Tor subprotocol "Relay=3" for:
&gt; * relays that support for IPv6 extends, and
&gt; * relays and bridges that support IPv6 ORPort reachability checks,
&gt; as described in this proposal.

I don't fully understand; this reads as ambiguous to me.  Does
"Relay=3" mean "IF I have an IPv6 address, I support IPv6 extends and
checks"?  Or does it mean "I have an IPv6 address, and I support IPv6
extends and checks"?

I would argue for the former interpretation, since no other
subprotocol version is specified to depend on the relay's network
configuration.

&gt; 5.1. Tor Specification Changes
&gt; 
&gt; We propose the following changes to the [Tor Specification], once this
&gt; proposal is implemented.
&gt; 
&gt; Adding a new Relay subprotocol version lets testing relays identify other
&gt; relays that support IPv6 extends. It also allows us to eventually recommend
&gt; or require support for IPv6 extends on all relays (and bridges).
&gt; 
&gt; Append to the Relay version 2 subprotocol specification:
&gt; 
&gt; Relay=2 has limited IPv6 support:
&gt; * Clients do not include IPv6 ORPorts in EXTEND2 cells.

I think that this is saying too much; we should leave it out.  Clients
on the current Tor network MAY include IPv6 ORPorts, after all: we
don't want to retroactively specify that any implementations that _do_
include them are noncompliant with subprotocol v2.

&gt; * Relays do not not initiate IPv6 connections in response to
&gt; EXTEND2 cells containing IPv6 ORPorts.

Is this always true?   Would "may not" or "do not always" be more correct?

&gt; However, relays accept inbound connections to their IPv6 ORPorts,
&gt; and will extend circuits via those connections.
&gt; 
&gt; "3" -- relays support extending over IPv6 connections in response to an
&gt; EXTEND2 cell containing an IPv6 ORPort. Relays and bridges perform
&gt; IPv6 ORPort reachability checks. Client behaviour does not change.

Should this be "self-checks" instead of "checks" for clarity?

Also, I wonder whether having self-checking be part of the relay
protocol is correct.

&gt; This subprotocol is advertised by all relays and bridges, regardless
&gt; of their configured ORPorts.

This "all" should probably be removed or clarified.  How about  "all
relays and bridges running software that supports it, whether or not
they have IPv6 ORPorts configured."

&gt; But relays without a configured IPv6
&gt; ORPort may refuse to extend over IPv6. And bridges always refuse to
&gt; extend over IPv6, because they try to imitate client behaviour.

This last seems like it's saying that bridges SHOULD or MUST refuse to
extend over IPv6; it might be better to say that they MAY, so that if
client behavior changes, bridges can change too.

&gt; A successful IPv6 extend requires:
&gt; * Relay subprotocol version 3 (or later) and an IPv6 ORPort on the
&gt; extending relay,
&gt; * an IPv6 ORPort in the EXTEND2 cell, and
&gt; * an IPv6 ORPort on the accepting relay.
&gt; (Because different tor instances can have different views of the
&gt; network, these checks should be done when the path is selected.
&gt; Extending relays should only check local IPv6 information, before
&gt; attempting the extend.)
&gt; 
&gt; This subprotocol version is described in proposal 311, and
&gt; implemented in Tor 0.4.4.1-alpha. (TODO: check version after code is
&gt; merged).

I think that the "pick a random ORPort" behavior should be specified
here too, as part of relay subprotocol v3, if we keep it.

yrs,
-- 
Nick

&gt; 6. Test Plan
&gt; 
&gt; We provide a quick summary of our testing plans.
&gt; 
&gt; 6.1. Test IPv6 ORPort Reachability and Extends
&gt; 
&gt; We propose to test these changes using chutney networks with AssumeReachable
&gt; disabled. (Chutney currently enables AssumeReachable by default.)
&gt; 
&gt; We also propose to test these changes on the public network with a small
&gt; number of relays and bridges.
&gt; 
&gt; Once these changes are merged, volunteer relay and bridge operators will be
&gt; able to test them by:
&gt; * compiling from source,
&gt; * running nightly builds, or
&gt; * running alpha releases.
&gt; 
&gt; 6.2. Test Existing Features
&gt; 
&gt; We will modify and test these existing features:
&gt; * IPv4 ORPort reachability checks
&gt; 
&gt; We do not plan on modifying these existing features:
&gt; * Relay reachability retries
&gt; TODO: Do relays re-check their own reachability? How often?
&gt; * Relay canonical connections
&gt; * "Too many connections" warning logs
&gt; But we will test that they continue to function correctly, and fix any bugs
&gt; triggered by the modifications in this proposal.
&gt; 
&gt; 6.3. Test Legacy Relay Compatibility
&gt; 
&gt; We will also test IPv6 extends from newer relays (which implement this
&gt; proposal) to older relays (which do not). Although this proposal does not
&gt; create these kinds of circuits, we need to check for bugs and excessive
&gt; logs in older tor versions.
&gt; 
&gt; 8. Ongoing Monitoring
&gt; 
&gt; To monitor the impact of these changes, relays should collect basic IPv4
&gt; and IPv6 connection and bandwidth statistics (see [Proposal 313]).
&gt; 
&gt; We may also collect separate statistics on connections from:
&gt; * clients (and bridges, because they act like clients), and
&gt; * other relays (and authorities, because they act like relays).
&gt; 
&gt; We do not propose to collect additional statistics on:
&gt; * bridges,
&gt; * circuit counts, or
&gt; * failure rates.
&gt; Collecting statistics like these could impact user privacy.
&gt; 
&gt; References:
&gt; 
&gt; [Onion Service Protocol]: In particular, Version 3 of the Onion Service Protocol \
&gt; supports IPv6: https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt 
&gt; [Proposal 306]: One possible design for automatic client IPv4 and IPv6 connections \
&gt; is at https://gitweb.torproject.org/torspec.git/tree/proposals/306-ipv6-happy-eyeballs.txt \
&gt; (TODO: modify to include bridge changes with client changes) 
&gt; [Proposal 312]: https://gitweb.torproject.org/torspec.git/tree/proposals/312-auto-relay-ipv6.txt \
&gt; (TODO) 
&gt; [Proposal 313]: https://gitweb.torproject.org/torspec.git/tree/proposals/313-relay-ipv6-stats.txt \
&gt; (TODO) 
&gt; [Relay Search] https://metrics.torproject.org/rs.html
&gt; 
&gt; [Tor Specification]: https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt
&gt; 
&gt; --
&gt; 
&gt; (End)
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200129135623</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-01-29 13:56:23-0400</timestampReceived><subject>Re: [tor-dev] Prop 311: Relay IPv6 Reachability</subject><body>

[Attachment #2 (multipart/signed)]


Hi Nick,

Thanks for your proposal review.

I've made most of the changes you've suggested, you can see the latest
version of the proposal here:
https://github.com/torproject/torspec/pull/103/files

I'll send another full text to the list when all the reviews are done.

I've also responded to your comments below individually:

&gt; On 25 Jan 2020, at 06:09, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; On Fri, Jan 24, 2020 at 1:31 AM teor &lt;teor@riseup.net&gt; wrote:
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Here is an initial draft of Proposal 311: Relay IPv6 Reachability.
&gt;&gt; 
&gt;&gt; This proposal includes:
&gt;&gt;  * relay IPv6 ORPort extends, and
&gt;&gt;  * relay IPv6 ORPort reachability checks.
&gt;&gt; 
&gt;&gt; This is the first of 3 proposals:
&gt;&gt; * Proposal 311: Relay IPv6 Reachability
&gt;&gt; * Proposal 312: Automatic Relay IPv6 Addresses
&gt;&gt; * Proposal 313: Relay IPv6 Statistics
&gt;&gt; (I haven't written the others yet!)
&gt;&gt; 
&gt;&gt; I also want to make some minor changes to Proposal 306, so that bridge
&gt;&gt; IPv6 behaviour stays in sync with client IPv6 behaviour.
&gt;&gt; 
&gt;&gt; The full text is included below, and it is also available as a GitHub
&gt;&gt; pull request:
&gt;&gt; https://github.com/torproject/torspec/pull/103
&gt;&gt; 
&gt;&gt; The related tickets are #24404 (proposal) and #24403 (implementation):
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/24404
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/24403
&gt;&gt; 
&gt;&gt; Please feel free to reply on this list, or via GitHub pull request
&gt;&gt; comments.
&gt; 
&gt; This proposal seems like a good start: It's solid, readable, and I
&gt; think it would work.  There are few places where I have questions or
&gt; suggested clarifications, and a few where I think we should consider
&gt; other designs as well.
&gt; 
&gt; I'm going to only quote the parts I'm commenting on.
&gt; 
&gt;&gt; 3.2.1. Making IPv6 ORPort Extend Connections
&gt;&gt; 
&gt;&gt;   Relays can make a new connection over IPv6 when:
&gt;&gt;     * there is no existing authenticated connection to the requested relay,
&gt;&gt;       and
&gt;&gt;     * the extend cell contains an IPv6 ORPort.
&gt; 
&gt; Also we should probably have the condition, "The relay itself supports
&gt; IPv6, or thinks that it does"?

Thanks, I included that condition later in the proposal, but missed it here:
https://github.com/torproject/torspec/pull/103/commits/9204293f9b1e106ca73c4726703c3560f81cdeb8

&gt;&gt;   If these conditions are satisfied, and the extend cell also contains an
&gt;&gt;   IPv4 ORPort, we propose that the relay choose between an IPv4 and an IPv6
&gt;&gt;   connection at random.
&gt; 
&gt; [...]
&gt;&gt; 3.3. Alternative Extend Designs
&gt;&gt; 
&gt;&gt;   We briefly mention some potential extend designs, and the reasons that
&gt;&gt;   they were not used in this proposal.
&gt;&gt; 
&gt;&gt;   (Some designs may be proposed for future Tor versions, but are not necessary
&gt;&gt;   at this time.)
&gt; 
&gt; Let me sketch another alternative design here:
&gt; 
&gt; Suppose that a relay's extend cell contains the IPv4 address and the
&gt; IPv6 address in their _preferred order_.  So if the party generating
&gt; the extend cell would prefer an IPv4 connection, it puts the IPv4
&gt; addess first; if it would prefer an IPv6 connection, it puts the IPv6
&gt; address first.
&gt; 
&gt; The relay that receives the extend cell could respond in several ways:
&gt;   * One possibility (similar to your 3.2.1) is to choose at random,
&gt; with a higher probability given to the first option.
&gt;   * One possibility (similar to your 3.3.1) is to try the first, and
&gt; then try the second if the first one fails.
&gt; 
&gt; I think this scheme has some advantage, in that it lets the
&gt; self-testing relay say "please try IPv6 if you can" or "please try
&gt; IPv4 if you can" in a reliable way, and lets us migrate from the
&gt; current behavior to the 3.3.1 behavior down the road.

I've added this alternate design as section 3.3.3, and renumbered the
previous section 3.3.3 to 3.4:
https://github.com/torproject/torspec/pull/103/commits/654bcb16815c0c57d5c551de53a79116a6d0188a

Apart from relay reachability self-tests, I'm not sure if there are any
other use cases where preferring IPv4 or IPv6 extends is necessary. Most
clients shouldn't care, they just want to get to an exit safely. (And
most clients can't care, because existing connections may be used, and
they may be over IPv4 or IPv6.)

But I wanted to include this design in the proposal, in case we find that
it is necessary during testing.

&gt; [...]
&gt;&gt; 4.3. Refuse to Publish Descriptor if IPv6 ORPort is Unreachable
&gt;&gt; 
&gt;&gt;   If an IPv6 ORPort reachability check fails, relays (and bridges) should log
&gt;&gt;   a warning.
&gt;&gt; 
&gt;&gt;   In addition, if IPv6ORPort reachability checks are reliable, based on the
&gt;&gt;   number of relays in the network that support IPv6 extends, relays should
&gt;&gt;   refuse to publish their descriptor.
&gt; 
&gt; Is this the behavior we want?  Another behavior would be to omit our
&gt; IPv6 orport from our descriptor if it is not reachable.  That way,
&gt; relay operators could configure their relays to just listen on IPv6
&gt; unconditionally, and let the relay figure out whether it should
&gt; advertise IPv6 or not.  This behavior  seems preferable to me, since
&gt; it has less chance of breaking a relay that would otherwise "work".

In general, when I've asked similar questions before, relay operators and
directory authority operators have wanted relays to fail fast, rather than
continuing to work with a partly-broken config.

The last time I asked, it was about directory authority IPv6 ORPort
reachability checks to relays. The directory authority operators told me
that relays which fail IPv6 reachability checks should not be in the
consensus, so relay operators notice, and fix their relays.

But in this case, I think we should make an exception for relays that
automatically guess their IPv6 address (rather than having it configured
explicitly by the operator). Since IPv6 address guesses will be a new
feature, and they happen automatically when operators upgrade tor, we
should just warn if a relay appears to have an IPv6 address, but it is
not actually reachable.

Relays that explicitly configure an IPv6 address should continue to fail
fast and fail loudly (in their logs). They were always going to fail anyway,
once they published their IPv6 address, and the directory authorities found
them unreachable.

&gt; As a third possibility, we could have an option to say whether we
&gt; should publish a descriptor if some of our addresses are not
&gt; reachable.

With the new design above, I don't think that's necessary: relay operators
can simply remove their configured IPv6 ORPort address, and tor will start
publishing its descriptor.

See the changes here:
https://github.com/torproject/torspec/pull/103/commits/2e82cbd45679e9e17390ec9183c8bcb49c77a081

&gt; [...]
&gt;&gt; 4.3.2. Add AssumeIPv6Reachable Option
&gt;&gt; 
&gt;&gt;   We add an AssumeIPv6Reachable torrc option and consensus parameter.
&gt;&gt; 
&gt;&gt;   If IPv6 ORPort checks have bugs that impact the health of the network,
&gt;&gt;   they can be disabled by setting AssumeIPv6Reachable=1 in the consensus
&gt;&gt;   parameters.
&gt;&gt; 
&gt;&gt;   If IPv6 ORPort checks have bugs that impact a particular relay (or bridge),
&gt;&gt;   they can be disabled by setting "AssumeIPv6Reachable 1" in the relay's
&gt;&gt;   torrc.
&gt;&gt; 
&gt;&gt;   This option disables IPv6 ORPort reachability checks, so relays publish
&gt;&gt;   their descriptors if their IPv4 ORPort reachability checks succeed.
&gt;&gt; 
&gt;&gt;   The default for the torrc option is "auto", which checks the consensus
&gt;&gt;   parameter. If the consensus parameter is not set, the default is "0".
&gt;&gt; 
&gt;&gt;   "AssumeReachable 1" overrides all values of "AssumeIPv6Reachable",
&gt;&gt;   disabling both IPv4 and IPv6 ORPort reachability checks.
&gt; 
&gt; Should we have some way to AssumeReachable our IPv4 address only, and
&gt; not our IPv6 address?  Or is that too much?

There's one configuration where it might be needed:
* a reachable IPv4 address,
* a reachable IPv6 address,
* but the IPv6 address is unsuitable for an ORPort.

In that case, tor would automatically discover both addresses, publish them
both, and the relay operator could not turn off IPv6.

So I think a better way to fix this issue is to turn off guessing the IPv6
address. I've added a new AddressDisableIPv6 as an required part of
proposal 312:
https://github.com/torproject/torspec/pull/105/files#diff-28c992d72bedaa9378a4f3627afb8694R361

&gt;&gt; 4.4. Optional Efficiency and Reliability Changes
&gt;&gt; 
&gt;&gt;   We propose some optional changes for efficiency and reliability, and
&gt;&gt;   describe their impact.
&gt;&gt; 
&gt;&gt;   Some of these changes may be more appropriate in future releases, or
&gt;&gt;   along with other proposed features.
&gt;&gt; 
&gt; 
&gt; 
&gt; [...]
&gt;&gt; 4.4.3. Accurately Identifying Test Circuits
&gt;&gt; 
&gt;&gt;   The testing relay (or bridge) may confirm that the create cells it is
&gt;&gt;   receiving are from its own test circuits, and that test circuits are
&gt;&gt;   capable of returning create cells to the origin.
&gt;&gt; 
&gt;&gt;   Currently, relays confirm reachability if any create cell is received on
&gt;&gt;   any inbound connection (see section 4.1). Relays do not check that the
&gt;&gt;   circuit is a reachability test circuit, and they do not wait to receive the
&gt;&gt;   return created cell. This behaviour has resulted in difficult to diagnose
&gt;&gt;   bugs on some rare relay configurations.
&gt;&gt; 
&gt;&gt;   We propose these optional changes, to improve the efficiency of IPv4 and
&gt;&gt;   IPv6 ORPort reachability checks:
&gt; 
&gt; If we make these changes, I think we should track both whether we are
&gt; "maybe reachable" (under the current definition of 'reachable') and
&gt; "definitely reachable" (based on the new definition).   We should log
&gt; different messages depending on whether we are "maybe reachable" but
&gt; these new tests fail, or whether we are completely unreachable.

Done in:
https://github.com/torproject/torspec/pull/103/commits/6dceff0658e122ac00713f3fb25be29cedea0359

&gt;&gt;   Testing relays may:
&gt;&gt;     * check that the create cell is received from a test circuit
&gt;&gt;       (by comparing the received cell to the cells sent by test circuits),
&gt;&gt;     * check that the create cell is received on an inbound connection
&gt;&gt;       (this is existing behaviour),
&gt;&gt;     * if the create cell from a test circuit is received on an outbound
&gt;&gt;       connection, destroy the circuit (rather than returning a created cell),
&gt;&gt;       and
&gt;&gt;     * check that the created cell is returned to the relay on a test circuit
&gt;&gt;       (by comparing the remote address of the final hop on the circuit, to
&gt;&gt;       the local IPv4 and IPv6 ORPort addresses).
&gt;&gt; 
&gt;&gt;   TODO: work out how to efficiently match inbound create cells to test
&gt;&gt;         circuits.
&gt; 
&gt; One possibility: we could store a set of our test circuits' extend
&gt; cells g^X values, and then check incoming cells create cells against
&gt; that set.

Also done in:
https://github.com/torproject/torspec/pull/103/commits/6dceff0658e122ac00713f3fb25be29cedea0359

&gt; There are probably fancier designs based on EC trickery or tweaks to
&gt; the ntor protocol, but I think we'd best avoid them.

I think you're right.

&gt;&gt; 4.4.4. Allowing More Relay IPv6 Extends
&gt;&gt; 
&gt;&gt;   Currently, clients, relays, and bridges do not include IPv6 ORPorts in their
&gt;&gt;   extend cells.
&gt;&gt; 
&gt;&gt;   In this proposal, we only make relays (and bridges) extend over IPv6 on
&gt;&gt;   the final hop of test circuits. This limited use of IPv6 extends means that
&gt;&gt;   IPv6 connections will still be uncommon.
&gt;&gt; 
&gt;&gt;   We propose these optional changes, to increase the number of IPv6
&gt;&gt;   connections between relays:
&gt;&gt; 
&gt;&gt;   To increase the number of IPv6 connections, relays that support IPv6
&gt;&gt;   extends may want to use them for all hops of their own circuits. Relays
&gt;&gt;   make their own circuits for reachability tests, bandwidth tests, and
&gt;&gt;   ongoing preemptive circuits. (Bridges can not change their behaviour,
&gt;&gt;   because they try to imitate clients.)
&gt;&gt; 
&gt;&gt;   We propose a torrc option and consensus parameter SendIPv6CircuitExtends,
&gt;&gt;   which is only supported on relays (and not bridges or clients). This option
&gt;&gt;   makes relays send IPv4 and IPv6 ORPorts in all their extend cells, when
&gt;&gt;   supported by the extending and receiving relay. (See section 3.2.1.)
&gt;&gt; 
&gt;&gt;   TODO: Is there a shorter name, that isn't easily confused with enabling
&gt;&gt;         support for other nodes to perform IPv6 extends via this relay?
&gt; 
&gt; I have another concern here: if this option is truly relay-only, it
&gt; should probably have a name that indicates the fact.

Changed to RelaySendIPv6Extends in:
https://github.com/torproject/torspec/pull/103/commits/f874424ebc9dafb7c721ed1893c93bb990f4f2c9

&gt;&gt; 4.5. Alternate Reachability Designs
&gt;&gt; 
&gt;&gt;   We briefly mention some potential reachability designs, and the reasons that
&gt;&gt;   they were not used in this proposal.
&gt;&gt; 
&gt;&gt; 4.5.1. Removing IPv4 ORPorts from Extend Cells
&gt;&gt; 
&gt;&gt;   We avoid designs that only include IPv6 ORPorts in extend cells, and remove
&gt;&gt;   IPv4 ORPorts.
&gt;&gt; 
&gt;&gt;   Only including the IPv6 ORPort would provide slightly more specific
&gt;&gt;   reachability check circuits. However, we don't need IPv6-only designs,
&gt;&gt;   because relays continue trying different reachability circuits until they
&gt;&gt;   confirm reachability.
&gt;&gt; 
&gt;&gt;   IPv6-only designs also make it easy to distinguish relay reachability extend
&gt;&gt;   cells from other extend cells. This distinguisher will become more of an
&gt;&gt;   issue as IPv6 extends become more common in the network (see sections 4.2.2
&gt;&gt;   and 4.4.4).
&gt;&gt; 
&gt;&gt;   Removing the IPv4 ORPort also provides no fallback, if the IPv6 ORPort is
&gt;&gt;   actually unreachable. IPv6-only failures do not affect reachability checks,
&gt;&gt;   but they will become important in the future, as other circuit types start
&gt;&gt;   using IPv6 extends.
&gt;&gt; 
&gt;&gt;   IPv6-only reachability designs also increase the number of special cases in
&gt;&gt;   the implementation. (And the likelihood of subtle bugs.)
&gt;&gt; 
&gt;&gt;   These designs may be appropriate in future, when there are IPv6-only bridges
&gt;&gt;   or relays.
&gt; 
&gt; As an aside: I think in the long run, the future is for clients to
&gt; treat relays' link specifiers as completely opaque when they are
&gt; making extend cells.
&gt; 
&gt; That is, if a client is extending to some relay X, it should know
&gt; "here is a blob that you use as X's link specifiers" -- it can be the
&gt; authorities' job to decide which IP addresses and which identity keys
&gt; such a blob needs to contain.
&gt; 
&gt; (Of course, a client still needs to know a relay's address when making
&gt; a connection itself, but that's more in prop306 territory.)

Seems fine to me, but I don't think we're looking that far into the
future in this proposal.

&gt;&gt; 5. New Relay Subprotocol Version
&gt;&gt; 
&gt;&gt;   We reserve Tor subprotocol "Relay=3" for:
&gt;&gt;     * relays that support for IPv6 extends, and
&gt;&gt;     * relays and bridges that support IPv6 ORPort reachability checks,
&gt;&gt;   as described in this proposal.
&gt; 
&gt; I don't fully understand; this reads as ambiguous to me.  Does
&gt; "Relay=3" mean "IF I have an IPv6 address, I support IPv6 extends and
&gt; checks"?  Or does it mean "I have an IPv6 address, and I support IPv6
&gt; extends and checks"?
&gt; 
&gt; I would argue for the former interpretation, since no other
&gt; subprotocol version is specified to depend on the relay's network
&gt; configuration.

It was always meant to be configuration-independent. It was documented
as configuration-independent in section 5.1, I've now made those
changes in the introduction to section 5 as well:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

&gt;&gt; 5.1. Tor Specification Changes
&gt;&gt; 
&gt;&gt;   We propose the following changes to the [Tor Specification], once this
&gt;&gt;   proposal is implemented.
&gt;&gt; 
&gt;&gt;   Adding a new Relay subprotocol version lets testing relays identify other
&gt;&gt;   relays that support IPv6 extends. It also allows us to eventually recommend
&gt;&gt;   or require support for IPv6 extends on all relays (and bridges).
&gt;&gt; 
&gt;&gt;   Append to the Relay version 2 subprotocol specification:
&gt;&gt; 
&gt;&gt;          Relay=2 has limited IPv6 support:
&gt;&gt;            * Clients do not include IPv6 ORPorts in EXTEND2 cells.
&gt; 
&gt; I think that this is saying too much; we should leave it out.  Clients
&gt; on the current Tor network MAY include IPv6 ORPorts, after all: we
&gt; don't want to retroactively specify that any implementations that _do_
&gt; include them are noncompliant with subprotocol v2.

I made these useful features "may not" in:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

&gt;&gt;            * Relays do not not initiate IPv6 connections in response to
&gt;&gt;              EXTEND2 cells containing IPv6 ORPorts.
&gt; 
&gt; Is this always true?   Would "may not" or "do not always" be more correct?

It's always true of the tor implementation that we maintain. I made these
useful features "may not" in:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

&gt;&gt;          However, relays accept inbound connections to their IPv6 ORPorts,
&gt;&gt;          and will extend circuits via those connections.
&gt;&gt; 
&gt;&gt;   "3" -- relays support extending over IPv6 connections in response to an
&gt;&gt;          EXTEND2 cell containing an IPv6 ORPort. Relays and bridges perform
&gt;&gt;          IPv6 ORPort reachability checks. Client behaviour does not change.
&gt; 
&gt; Should this be "self-checks" instead of "checks" for clarity?
&gt; 
&gt; Also, I wonder whether having self-checking be part of the relay
&gt; protocol is correct.

I don't think the rest of the network cares about self-checks, so I removed
them from this section:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

I also reviewed the rest of the proposal, it's obvious when we're talking
about self-checks, and when we're talking about authority checks.

&gt;&gt;          This subprotocol is advertised by all relays and bridges, regardless
&gt;&gt;          of their configured ORPorts.
&gt; 
&gt; This "all" should probably be removed or clarified.  How about  "all
&gt; relays and bridges running software that supports it, whether or not
&gt; they have IPv6 ORPorts configured."

I clarified that the protocol applies to some tor versions, regardless of
their current configuration:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

&gt;&gt;                                                           But relays without a configured IPv6
&gt;&gt;          ORPort may refuse to extend over IPv6. And bridges always refuse to
&gt;&gt;          extend over IPv6, because they try to imitate client behaviour.
&gt; 
&gt; This last seems like it's saying that bridges SHOULD or MUST refuse to
&gt; extend over IPv6; it might be better to say that they MAY, so that if
&gt; client behavior changes, bridges can change too.

I clarified that bridges may not extend:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

Although, we'll need bridge clients to start sending IPv6 ORPorts in
EXTEND2 cells, before bridges can extend over IPv6. But these changes
may not need a new protocol version. (We could use a consensus parameter
instead.)

&gt;&gt;          A successful IPv6 extend requires:
&gt;&gt;            * Relay subprotocol version 3 (or later) and an IPv6 ORPort on the
&gt;&gt;              extending relay,
&gt;&gt;            * an IPv6 ORPort in the EXTEND2 cell, and
&gt;&gt;            * an IPv6 ORPort on the accepting relay.
&gt;&gt;          (Because different tor instances can have different views of the
&gt;&gt;          network, these checks should be done when the path is selected.
&gt;&gt;          Extending relays should only check local IPv6 information, before
&gt;&gt;          attempting the extend.)
&gt;&gt; 
&gt;&gt;          This subprotocol version is described in proposal 311, and
&gt;&gt;          implemented in Tor 0.4.4.1-alpha. (TODO: check version after code is
&gt;&gt;          merged).
&gt; 
&gt; I think that the "pick a random ORPort" behavior should be specified
&gt; here too, as part of relay subprotocol v3, if we keep it.


I added the random selection, and added a TODO to check the final
implementation after we merge:
https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

T


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl4xjwcACgkQEP6qDnB1
ZypIHRAAsDwt7/26LBtc9miGoSBCCINoeJZQnDOvPwDrd7j7Q52FpFg8QFClu9GP
KG1wBCcslY3nMoVeua/y2daTmiiAYrmauWnKoxRdK2Z2eylC1cXCcMSsU5kzvPUX
DcWrHr/XlQ6XVg0tR7YIDdFk49iHe/i0u+gE453OS0FsKOgedYUzuVgMPFC4SkUL
KrPPNJ75pKz6ctJpjcHOGmtrBAND8ABfkwGZP4gxzDxC1LKHvBseaxesgYwBV18I
jtEkQhXlC3k4x/EG24Xv3J2LjCzr+JI22tgyd0bormlpkrDoPpkG7fklHuF3QC9y
Jdab4quzMhgNfVgJhndgOsF21j7zEjDi92LHS5QOtEW66NSVytSe+3Pjd2djIB7j
F+bpZZxMgry+K5GkmGAUuDAQqpBS4bk5wZ59+bZ6xBeqZwd4HgEzW6KWfrgP7WBN
V2Ktk5jpGMciKAH/y5sKmdOR75y8xDJ8JIeCJM3NUDAUY4HKZZHP6Yif+PG/Au8G
FNx7XeV/3OECHTjgKVp6S8yng2BhBqzEJejLQyBdvUCAxMlYA30DfYmotbuCw+/C
CUiVl8DRhZ/cEJl/NKu4UpQ8dLKQqlv3NqEnMMx6gtJWj+l9kdJoZDhqI0lzVeZ3
ZdIjWZvyL0ovPSj2wAXoWo1seJdweDNYK6S9eHAOns6W1wwUfKg=
=PEPh
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200114032642</emailId><senderName>Tomer Ashur</senderName><senderEmail>tomer.ashur@esat.kuleuven.be</senderEmail><timestampReceived>2020-01-14 03:26:42-0400</timestampReceived><subject>[tor-dev] Tor Proposal 295</subject><body>

Dear all,
Please find attached out final version for Proposal 295. This version 
has two changes compared to the previous one:

1. It fixes a vulnerability introduced in the previous iteration which 
was the result of making the authentication layer stateless. Since there 
is no freshness entering into the first layer, the same plaintext would 
have resulted in the same ciphertext thus allowing an adversary to 
distinguish. This is now fixed by restoring the running digest also for 
authentication layer thus making in stateful again.

2. It adds an option for forward secrecy. The approach here is similar 
to the one taken by Proposal 308 by replacing the encryption key of the 
first layer after successfully processing the message. If this approach 
is taken, there is no need to keep the authentication layer stateful 
anymore.

I'll be leaving the mailing list to reduce noise in my mailbox. If you 
need anything from me regarding this proposal just make sure to CC me on 
the email and I'll be happy to answer.

Wishes,
Tomer


["295-relay-crypto-with-adl.txt" (text/plain)]

Filename: 295-relay-crypto-with-adl.txt
Title: Using ADL for relay cryptography (solving the crypto-tagging attack)
Author: Tomer Ashur, Orr Dunkelman, Atul Luykx
Created: 22 Feb 2018
Last-Modified: 13 Jan. 2020

Status: Open


0. Context

   Although Crypto Tagging Attacks were identified already in the
   original Tor design, it was not before the rise of the
   Procyonidae in 2012 that their severity was fully realized. In
   Proposal 202 (Two improved relay encryption protocols for Tor
   cells) Nick Mathewson discussed two approaches to stymie tagging
   attacks and generally improve Tor's cryptography. In Proposal 261
   (AEZ for relay cryptography) Mathewson puts forward a concrete
   approach which uses the tweakable wide-block cipher AEZ.

   This proposal suggests an alternative approach to Proposal 261
   using the notion of Release (of) Unverified Plaintext (RUP)
   security. It describes an improved algorithm for circuit
   encryption based on CTR-mode which is already used in Tor, and an
   additional component for hashing.

   Incidentally, and similar to Proposal 261, this proposal employs
   the ENCODE-then-ENCIPHER approach thus it improves Tor's E2E
   integrity by using (sufficient) redundancy.

   For more information about the scheme and a security proof for
   its RUP-security see

       Tomer Ashur, Orr Dunkelman, Atul Luykx: Boosting
       Authenticated Encryption Robustness with Minimal
       Modifications. CRYPTO (3) 2017: 3-33

   available online at https://eprint.iacr.org/2017/239 .

   For authentication between the OP and the edge node we use
   the PIV scheme: https://eprint.iacr.org/2013/835 .
   
   A recent paper presented a birthday bound distinguisher
   against the ADL scheme, thus showing that the RUP security 
   proof is tight: https://eprint.iacr.org/2019/1359 .
      

2. Preliminaries

2.1 Motivation

   For motivation, see proposal 202.

2.2. Notation

   Symbol               Meaning
   ------               -------
   M                    Plaintext
   C_I                  Ciphertext
   CTR                  Counter Mode
   N_I                  A de/encryption nonce (to be used in CTR-mode)
   T_I                  A tweak (to be used to de/encrypt the nonce)
   Tf'_I                A running digest (forward direction)
   Tb'_I                A running digest (backward direction)
   ^                    XOR
   ||                   Concatenation
          (This is more readable than a single | but must be adapted
          before integrating the proposal into tor-spec.txt)

2.3. Security parameters

   HASH_LEN -- The length of the hash function's output, in bytes.

   PAYLOAD_LEN -- The longest allowable cell payload, in bytes. (509)

   DIG_KEY_LEN -- The key length used to digest messages (e.g.,
   using GHASH). Since GHASH is only defined for 128-bit keys, we
   recommend DIG_KEY_LEN = 128.

   ENC_KEY_LEN -- The key length used for encryption (e.g., AES). We
   recommend ENC_KEY_LEN = 256.

2.4. Key derivation (replaces Section 5.2.2 in Tor-spec.txt)

   For newer KDF needs, Tor uses the key derivation function HKDF
   from RFC5869, instantiated with SHA256. The generated key
   material is:

                 K = K_1 | K_2 | K_3 | ...

   where, if H(x,t) denotes HMAC_SHA256 with value x and key t,
         and m_expand denotes an arbitrarily chosen value,
         and INT8(i) is an octet with the value "i", then
             K_1     = H(m_expand | INT8(1) , KEY_SEED )
         and K_(i+1) = H(K_i | m_expand | INT8(i+1) , KEY_SEED ),
   in RFC5869's vocabulary, this is HKDF-SHA256 with info ==
   m_expand, salt == t_key, and IKM == secret_input.

   When used in the ntor handshake a string of key material is
   generated and is used in the following way:

   Length       Purpose                         	Notation
   ------        -------                        	--------
   HASH_LEN     forward authentication digest IV 	AF
   HASH_LEN     forward digest IV               	DF
   HASH_LEN     backward digest IV              	DB
   ENC_KEY_LEN  encryption key                  	Kf
   ENC_KEY_LEN  decryption key                  	Kb
   DIG_KEY_LEN  forward digest key              	Khf
   DIG_KEY_LEN  backward digest key             	Khb
   ENC_KEY_LEN  forward tweak key               	Ktf
   ENC_KEY_LEN  backward tweak key              	Ktb
   DIGEST_LEN   nonce to use in the                      
                  hidden service protocol(*)

      (*) I am not sure that if this is still needed.

   Excess bytes from K are discarded.

2.6. Ciphers

   For hashing(*) we use GHASH(**) with a DIG_KEY_LEN-bit key. We write
   this as Digest(K,M) where K is the key and M the message to be
   hashed.

   We use AES with an ENC_KEY_LEN-bit key. For AES encryption
   (resp., decryption) we write E(K,X) (resp., D(K,X)) where K is an
   ENC_KEY_LEN-bit key and X the block to be encrypted (resp.,
   decrypted).

   For a stream cipher, unless otherwise specified, we use
   ENC_KEY_LEN-bit AES in counter mode, with a nonce that is
   generated as explained below. We write this as Encrypt(K,N,X)
   (resp., Decrypt(K,N,X)) where K is the key, N the nonce, and X
   the message to be encrypted (resp., decrypted).

   (*) The terms hash and digest are used interchangeably.
   (**) Proposal 308 suggested that using POLYVAL [GLL18]
        would be more efficient here. This proposal will work just the 
		same if POLYVAL is used instead of GHASH. 

3. Routing relay cells

   Let n denote the integer representing the destination node. For
   I = 1...n, we set Tf'_{I} = DF_I, Tb'_{I} = DB_I, and 
   Ta'_I = AF_I where DF_I, DB_I, and AF_I are generated 
   according to Section 2.4. 

3.1. Forward Direction

   The forward direction is the direction that CREATE/CREATE2 cells
   are sent.

3.1.1. Routing from the origin

   When an OP sends a relay cell, they prepare the
   cell as follows:

        The OP prepares the authentication part of the message:

                C_{n+1} = M
                Ta_I = Digest(Khf_n,Ta'_I||C_{n+1})
                N_{n+1} = Ta_I ^ E(Ktf_n,Ta_I ^ 0)
		Ta'_{I} = Ta_I

        Then, the OP prepares the multi-layered encryption:

                For I=n...1:
                        C_I = Encrypt(Kf_I,N_{I+1},C_{I+1})
                        T_I = Digest(Khf_I,Tf'_I||C_I)
                        N_I = T_I ^ E(Ktf_I,T_I ^ N_{I+1})
                        Tf'_I = T_I

          The OP sends C_1 and N_1 to node 1.

3.1.2. Relaying forward at onion routers

   When a forward relay cell is received by OR_I, it decrypts the
   payload with the stream cipher, as follows:

        'Forward' relay cell:

                T_I = Digest(Khf_I,Tf'_I||C_I)
                N_{I+1} = T_I ^ D(Ktf_I,T_I ^ N_I)
                C_{I+1} = Decrypt(Kf_I,N_{I+1},C_I)
                Tf'_I = T_I

   The OR then decides whether it recognizes the relay cell as
   described below. If the OR recognizes the cell, it processes the
   contents of the relay cell. Otherwise, it passes C_{I+1}||N_{I+1}
   along the circuit if the circuit continues.

   For more information, see section 4 below.

3.2. Backward direction

   The backward direction is the opposite direction from
   CREATE/CREATE2 cells.

3.2.1. Relaying backward at onion routers

   When a backward relay cell is received by OR_I, it encrypts the
   payload with the stream cipher, as follows:

        'Backward' relay cell:

                T_I = Digest(Khb_I,Tb'_I||C_{I+1})
                N_I = T_I ^ E(Ktb_I,T_I ^ N_{I+1})
                C_I = Encrypt(Kb_I,N_I,C_{I+1})
                Tb'_I = T_I

   with C_{n+1} = M and N_{n+1}=0. Once encrypted, the node passes
   C_I and N_I along the circuit towards the OP.

3.2.2. Routing to the origin

   When a relay cell arrives at an OP, the OP decrypts the payload
   with the stream cipher as follows:

        OP receives relay cell from node 1:

                For I=1...n, where n is the end node on the circuit:
                        C_{I+1} = Decrypt(Kb_I,N_I,C_I)
                        T_I = Digest(Khb_I,Tb'_I||C_{I+1})
                        N_{I+1} = T_I ^ D(Ktb_I,T_I ^ N_I)
                        Tb'_I = T_I

                If the payload is recognized (see Section 4.1),
                then:

                       The sending node is I. Stop, process the
                       payload and authenticate.

4. Application connections and stream management

4.1. Relay cells

  Within a circuit, the OP and the end node use the contents of
  RELAY packets to tunnel end-to-end commands and TCP connections
  ("Streams") across circuits. End-to-end commands can be initiated
  by either edge; streams are initiated by the OP.

        The payload of each unencrypted RELAY cell consists of:

                Relay command           [1 byte]
                StreamID                [2 bytes]
                Length                  [2 bytes]
                Data                    [PAYLOAD_LEN-21 bytes]


   The old Digest field is removed since sufficient information for
   authentication is now included in the nonce part of the payload.

   The old 'Recognized' field is removed and the node always tries to
   authenticate the message as follows.

4.1.1 forward direction (executed by the end node):
				
				Ta_I = Digest(Khf_n,Ta'_I||C_{n+1})
				Tag = Ta_I ^ D(Ktf_n,Ta_I ^ N_{n+1})

				If Tag = 0:
                  Ta'_I = Ta_I
                  The message is authenticated.
             Otherwise:
                  Ta'_I remains unchanged.
                  The message is not authenticated.


4.1.2 backward direction (executed by the OP):

                The message is recognized and authenticated
				(i.e., C_{n+1} = M) if and only if N_{n+1} = 0.


   The 'Length' field of a relay cell contains the number of bytes
   in the relay payload which contain real payload data. The
   remainder of the payload is padding bytes.

4.2. Appending the encrypted nonce and dealing with version-homogenic
     and version-heterogenic circuits

   When a cell is prepared to be routed from the origin (see Section
   3.1.1 above) the encrypted nonce N is appended to the encrypted 
   cell (occupying the last 16 bytes of the cell). If the cell is
   prepared to be sent to a node supporting the new protocol, N is
   used to generate the layer's nonce. Otherwise, if the node only 
   supports the old protocol, N is still appended to the encrypted 
   cell (so that following nodes can still recover their nonce), 
   but a synchronized nonce (as per the old protocol) is used in 
   CTR-mode.

   When a cell is sent along the circuit in the 'backward'
   direction, nodes supporting the new protocol always assume that
   the last 16 bytes of the input are the nonce used by the previous
   node, which they process as per Section 3.2.1. If the previous
   node also supports the new protocol, these cells are indeed the
   nonce. If the previous node only supports the old protocol, these
   bytes are either encrypted padding bytes or encrypted data.

5. Security

5.1. Resistance to crypto-tagging attacks

   A crypto-tagging attack involves a circuit with two colluding
   nodes and at least one honest node between them. The attack works
   when one node makes a change to the cell (tagging) in a way that
   can be undone by the other colluding party. In between, the
   tagged cell is processed by honest nodes which do not detect the
   change. The attack is possible due to the malleability property
   of CTR-mode: a change to a ciphertext bit effects only the
   respective plaintext bit in a predicatble way. This proposal
   frustrates the crypto-tagging attack by linking the nonce to the
   encrypted message such that any change to the ciphertext results
   in a random nonce and hence, random plaintext.

   Let us consider the following 3-hop scenario: the entry and end
   nodes are malicious and colluding and the middle node is honest.

5.1.1. forward direction

   Suppose that node I tags the ciphertext part of the message
   (C'_{I+1} != C_{I+1}) then forwards it to the next node (I+1). As
   per Section 3.1.2. Node I+1 digests C'_{I+1} to generate T_{I+1}
   and N_{I+2}. Since C'_{I+2} is different from what it should be, so
   are the resulting T_{I+1} and N_{I+2}. Hence, decrypting C'_{I+1}
   using these values results in a random string for C_{I+2}. Since
   C_{I+2} is now just a random string, it is decrypted into a
   random string and cannot be authenticated. Furthermore, since
   C'_{I+1} is different than what it should be, Tf'_{I+1}
   (i.e., the running digest of the middle node) is now out of sync
   with that of the OP, which means that all future cells sent through
   this node will decrypt into garbage (random strings).

   Likewise, suppose that instead of tagging the ciphertext, Node I
   tags the encrypted nonce N'_{I+1} != N_{I+1}. Now, when Node
   I+1 digests the payload the tweak T_{I+1} is fine, but using it
   to decrypt N'_{I+1} again results in a random nonce for
   N_{I+2}. This random nonce is used to decrypt C_{I+1} into a
   random C'_{I+2} which cannot be authenticated by the end node. Since
   C_{I+2} is a random string, the running digest of the end node is
   now out of sync with that of OP, which prevents the end node from
   decrypting further cells.

5.1.2. Backward direction

   In the backward direction the tagging is done by Node I+2
   untagging by Node I. Suppose first that Node I+2 tags the
   ciphertext C_{I+2} and sends it to Node I+1. As per Section
   3.2.1, Node I+1 first digests C_{I+2} and uses the resulting
   T_{I+1} to generate a nonce N_{I+1}. From this it is clear that
   any change introduced by Node I+2 influences the entire payload
   and cannot be removed by Node I.

   Unlike in Section 5.1.1., the cell is blindly delivered by Node I
   to the OP which decrypts it. However, since the payload leaving
   the end node was modified, the message cannot be authenticated by
   the OP which can be trusted to tear down the circuit.

   Suppose now that tagging is done by Node I+2 to the nonce part of
   the payload, i.e., N_{I+2}. Since this value is encrypted by Node
   I+1 to generate its own nonce N_{I+1}, again, a random nonce is
   used which affects the entire keystream of CTR-mode. The cell
   again cannot be authenticated by the OP and the circuit is torn
   down.

   We note that the end node can modify the plain message before
   ever encrypting it and this cannot be discovered by the Tor
   protocol. This vulnerability is outside the scope of this
   proposal and users should always use TLS to make sure that their
   application data is encrypted before it enters the Tor network.

5.2. End-to-end authentication

   Similar to the old protocol, this proposal only offers end-to-end
   authentication rather than per-hop authentication. However,
   unlike the old protocol, the ADL-construction is non-malleable
   and hence, once a non-authentic message was processed by an
   honest node supporting the new protocol, it is effectively
   destroyed for all nodes further down the circuit. This is because
   the nonce used to de/encrypt all messages is linked to (a digest
   of) the payload data.

   As a result, while honest nodes cannot detect non-authentic
   messages, such nodes still destroy the message thus invalidating
   its authentication tag when it is checked by edge nodes. As a
   result, security against crypto-tagging attacks is ensured as
   long as an honest node supporting the new protocol processes the
   message between two dishonest ones.

5.3. The running digest

   Unlike the old protocol, the running digest is now computed as
   the output of a GHASH call instead of a hash function call
   (SHA256). Since GHASH does not provide the same type of security
   guarantees as SHA256, it is worth discussing why security is not
   lost from computing the running digest differently.

   The running digets is used to ensure that if the same payload is
   encrypted twice, then the resulting ciphertext does not remain
   the same. Therefore, all that is needed is that the digest should
   repeat with low probability. GHASH is a universal hash function,
   hence it gives such a guarantee assuming its key is chosen
   uniformly at random.
   
6. Forward secrecy

   Inspired by the approach of Proposal 308, a small modification 
   to this proposal makes it forward secure. The core idea is to 
   replace the encryption key KF_n after de/encrypting the cell.
   As an added benefit, this would allow to keep the authentication 
   layer stateless (i.e., without keeping a running digest for 
   this layer). 
   
   Below we present the required changes to the sections above.
   
6.1. Routing from the Origin (replacing 3.1.1 above)
   
   When an OP sends a relay cell, they prepare the
   cell as follows:

        The OP prepares the authentication part of the message:

			C_{n+1} = M
			T_{n+1} = Digest(Khf_n,C_{n+1})
			N_{n+1} = T_{n+1} ^ E(Ktf_n,T_{n+1} ^ 0)
				

        Then, the OP prepares the multi-layered encryption:
			For the final layer n:
				(C_n,Kf'_n) = Encrypt(Kf_n,N_{n+1},C_{I+1}||0||0) (*)
				T_n = Digest(Khf_I,Tf'_n||C_n)
				N_n = T_I ^ E(Ktf_n,T_n ^ N_{n+1})
				Tf'_n = T_n
				Kf_n = Kf'_n
				
				(*) CTR mode is used to generate two additional blocks. This 
					256-bit value is denoted K'f_n and is used in subsequent 
					steps to replace the encryption key of this layer.
					To achieve forward secrecy it is important that the 
					obsolete Kf_n is erased in a non-recoverable way. 				
						
                For layer I=(n-1)...1:
                        C_I = Encrypt(Kf_I,N_{I+1},C_{I+1})
                        T_I = Digest(Khf_I,Tf'_I||C_I)
                        N_I = T_I ^ E(Ktf_I,T_I ^ N_{I+1})
                        Tf'_I = T_I

		The OP sends C_1 and N_1 to node 1.
		
	Alternatively, if we want that all nodes use the same functionality 
	OP prepares the cell as follows:
			
			For layer I=n...1:
				(C_I,K'f_I) = Encrypt(Kf_I,N_{I+1},C_{I+1}||0||0) (*)
				T_I = Digest(Khf_I,Tf'_I||C_I)
				N_I = T_I ^ E(Ktf_I,T_I ^ N_{I+1})
				Tf'_I = T_I
				Kf_I = Kf'_I
				
				(*) CTR mode is used to generate two additional blocks. This 
					256-bit value is denoted K'f_n and is used in subsequent 
					steps to replace the encryption key of this layer.
					To achieve forward secrecy it is important that the 
					obsolete Kf_n is erased in a non-recoverable way. 				
						
		This scheme offers forward secrecy in all levels of the circuit.
		  
6.2. Relaying Forward at Onion Routers (replacing 3.1.2 above)
	
   When a forward relay cell is received by OR I, it decrypts the
   payload with the stream cipher, as follows:

        'Forward' relay cell:

                T_I = Digest(Khf_I,Tf'_I||C_I)
                N_{I+1} = T_I ^ D(Ktf_I,T_I ^ N_I)
                C_{I+1} = Decrypt(Kf_I,N_{I+1},C_I||0||0)
                Tf'_I = T_I

   The OR then decides whether it recognizes the relay cell as described below. 
   Depending on the choice of scheme from 6.1 the OR uses the last two blocks 
   of C_{I+1} to update the encryption key or discards them. 
   
   If the cell is recognized the OR also processes the contents of the relay 
   cell. Otherwise, it passes C_{I+1}||N_{I+1} along the circuit if the circuit 
   continues.

   For more information about recognizing and authenticating relay cells,
   see 5.4.5 below.
   
6.3. Relaying Backward at Onion Routers (replacing 3.2.1 above)

   When an edge node receives a message M to be routed back to the
   origin, it encrypts it as follows:
   
		T_n = Digest(Khb_n,Tb'_n||M)
                N_n = T_n ^ E(Ktb_n,T_n ^ 0)
                (C_n,K'b_n) = Encrypt(Kb_n,N_n,M||0||0) (*)
                Tb'_n = T_n
		Kb_n = K'b_n
   
				(*) CTR mode is used to generate two additional blocks. This 
					256-bit value is denoted K'b_n and will be used in 
					subsequent steps to replace the encryption key of this layer. 
					To achieve forward secrecy it is important that the obsolete 
					K'b_n is erased in a non-recoverable way. 
   
    Once encrypted, the edge node sends C_n and N_n along the circuit towards 
	the OP. When a backward relay cell is received by OR_I (I&lt;n), it encrypts 
	the payload with the stream cipher, as follows:

        'Backward' relay cell:

                T_I = Digest(Khb_I,Tb'_I||C_{I+1})
                N_I = T_I ^ E(Ktb_I,T_I ^ N_{I+1})
                C_I = Encrypt(Kb_I,N_I,C_{I+1})
                Tb'_I = T_I

   Each node passes C_I and N_I along the circuit towards the OP.
   
   If forward security is desired for all layers in the circuit, all OR's
   encrypt as follows:
		T_I = Digest(Khb_I,Tb'_I||C_{I+1})
                N_I = T_I ^ E(Ktb_I,T_I ^ 0)
                (C_I,K'b_I) = Encrypt(Kb_n,N_n,M||0||0)
                Tb'_I = T_I
		Kb_I = K'b_I
   

6.4. Routing to the Origin (replacing 3.2.2 above)

   When a relay cell arrives at an OP, the OP decrypts the payload
   with the stream cipher as follows:

        OP receives relay cell from node 1:

                For I=1...n, where n is the end node on the circuit:
                        C_{I+1} = Decrypt(Kb_I,N_I,C_I)
                        T_I = Digest(Khb_I,Tb'_I||C_{I+1})
                        N_{I+1} = T_I ^ D(Ktb_I,T_I ^ N_I)
                        Tb'_I = T_I
				
				And updates the encryption keys according to the strategy 
				chosen for 6.3.
				
                If the payload is recognized (see Section 4.1),
                then:

                       The sending node is I. Process the payload!
					   
					   
6.5. Recognizing and authenticating a relay cell (replacing 4.1.1 above):
	
	Authentication in the forward direction is done as follows: 

		T_{n+1} = Digest(Khf_n,C_{n+1})
                Tag = T_{n+1} ^ D(Ktf_n,T_{n+1} ^ N_{n+1})
	
	The message is recognized and authenticated
				(i.e., M = C_{n+1}) if and only if Tag = 0.
				
	No changes are required to the authentication process when the relay 
	cell is sent backwards.
	

["295-diff.diff" (text/x-patch)]

diff --git a/proposals/295-relay-crypto-with-adl.txt b/proposals/295-relay-crypto-with-adl.txt
index cfb58a2..d3414c4 100644
--- a/proposals/295-relay-crypto-with-adl.txt
+++ b/proposals/295-relay-crypto-with-adl.txt
@@ -2,7 +2,8 @@ Filename: 295-relay-crypto-with-adl.txt
 Title: Using ADL for relay cryptography (solving the crypto-tagging attack)
 Author: Tomer Ashur, Orr Dunkelman, Atul Luykx
 Created: 22 Feb 2018
-Last-Modified: 10 July 2019
+Last-Modified: 13 Jan. 2020
+
 Status: Open
 
 
@@ -37,7 +38,12 @@ Status: Open
    available online at https://eprint.iacr.org/2017/239 .
 
    For authentication between the OP and the edge node we use
-   the PIV scheme: https://eprint.iacr.org/2013/835
+   the PIV scheme: https://eprint.iacr.org/2013/835 .
+   
+   A recent paper presented a birthday bound distinguisher
+   against the ADL scheme, thus showing that the RUP security 
+   proof is tight: https://eprint.iacr.org/2019/1359 .
+      
 
 2. Preliminaries
 
@@ -74,7 +80,7 @@ Status: Open
    ENC_KEY_LEN -- The key length used for encryption (e.g., AES). We
    recommend ENC_KEY_LEN = 256.
 
-2.4. Key derivation (replaces Section 5.2.2)
+2.4. Key derivation (replaces Section 5.2.2 in Tor-spec.txt)
 
    For newer KDF needs, Tor uses the key derivation function HKDF
    from RFC5869, instantiated with SHA256. The generated key
@@ -93,26 +99,27 @@ Status: Open
    When used in the ntor handshake a string of key material is
    generated and is used in the following way:
 
-   Length       Purpose                         Notation
-   ------        -------                        --------
-   HASH_LEN     forward digest IV               DF
-   HASH_LEN     backward digest IV              DB
-   ENC_KEY_LEN  encryption key                  Kf
-   ENC_KEY_LEN  decryption key                  Kb
-   DIG_KEY_LEN  forward digest key              Khf
-   DIG_KEY_LEN  backward digest key             Khb
-   ENC_KEY_LEN  forward tweak key               Ktf
-   ENC_KEY_LEN  backward tweak key              Ktb
-   DIGEST_LEN   nonce to use in the                      *
-                  hidden service protocol
-
-      * I am not sure that we need this any longer.
+   Length       Purpose                         	Notation
+   ------        -------                        	--------
+   HASH_LEN     forward authentication digest IV 	AF
+   HASH_LEN     forward digest IV               	DF
+   HASH_LEN     backward digest IV              	DB
+   ENC_KEY_LEN  encryption key                  	Kf
+   ENC_KEY_LEN  decryption key                  	Kb
+   DIG_KEY_LEN  forward digest key              	Khf
+   DIG_KEY_LEN  backward digest key             	Khb
+   ENC_KEY_LEN  forward tweak key               	Ktf
+   ENC_KEY_LEN  backward tweak key              	Ktb
+   DIGEST_LEN   nonce to use in the                      
+                  hidden service protocol(*)
+
+      (*) I am not sure that if this is still needed.
 
    Excess bytes from K are discarded.
 
 2.6. Ciphers
 
-   For hashing(*) we use GHASH with a DIG_KEY_LEN-bit key. We write
+   For hashing(*) we use GHASH(**) with a DIG_KEY_LEN-bit key. We write
    this as Digest(K,M) where K is the key and M the message to be
    hashed.
 
@@ -128,19 +135,23 @@ Status: Open
    the message to be encrypted (resp., decrypted).
 
    (*) The terms hash and digest are used interchangeably.
+   (**) Proposal 308 suggested that using POLYVAL [GLL18]
+        would be more efficient here. This proposal will work just the 
+		same if POLYVAL is used instead of GHASH. 
 
 3. Routing relay cells
 
    Let n denote the integer representing the destination node. For
-   I = 1...n, we set Tf'_{I} = DF_I and Tb'_{I} = DB_I
-   where DF_I and DB_I are generated according to Section 2.4.
+   I = 1...n, we set Tf'_{I} = DF_I, Tb'_{I} = DB_I, and 
+   Ta'_I = AF_I where DF_I, DB_I, and AF_I are generated 
+   according to Section 2.4. 
 
 3.1. Forward Direction
 
    The forward direction is the direction that CREATE/CREATE2 cells
    are sent.
 
-3.1.1. Routing from the Origin
+3.1.1. Routing from the origin
 
    When an OP sends a relay cell, they prepare the
    cell as follows:
@@ -148,8 +159,9 @@ Status: Open
         The OP prepares the authentication part of the message:
 
                 C_{n+1} = M
-                T_{n+1} = Digest(Khf_n,C_{n+1})
-                N_{n+1} = T_{n+1} ^ E(Ktf_n,T_{n+1} ^ 0)
+                Ta_I = Digest(Khf_n,Ta'_I||C_{n+1})
+                N_{n+1} = Ta_I ^ E(Ktf_n,Ta_I ^ 0)
+		Ta'_{I} = Ta_I
 
         Then, the OP prepares the multi-layered encryption:
 
@@ -161,9 +173,9 @@ Status: Open
 
           The OP sends C_1 and N_1 to node 1.
 
-3.1.2. Relaying Forward at Onion Routers
+3.1.2. Relaying forward at onion routers
 
-   When a forward relay cell is received by OR I, it decrypts the
+   When a forward relay cell is received by OR_I, it decrypts the
    payload with the stream cipher, as follows:
 
         'Forward' relay cell:
@@ -180,14 +192,14 @@ Status: Open
 
    For more information, see section 4 below.
 
-3.2. Backward Direction
+3.2. Backward direction
 
    The backward direction is the opposite direction from
    CREATE/CREATE2 cells.
 
-3.2.1. Relaying Backward at Onion Routers
+3.2.1. Relaying backward at onion routers
 
-   When a backward relay cell is received by OR I, it encrypts the
+   When a backward relay cell is received by OR_I, it encrypts the
    payload with the stream cipher, as follows:
 
         'Backward' relay cell:
@@ -200,7 +212,7 @@ Status: Open
    with C_{n+1} = M and N_{n+1}=0. Once encrypted, the node passes
    C_I and N_I along the circuit towards the OP.
 
-3.2.2. Routing to the Origin
+3.2.2. Routing to the origin
 
    When a relay cell arrives at an OP, the OP decrypts the payload
    with the stream cipher as follows:
@@ -240,17 +252,22 @@ Status: Open
    authentication is now included in the nonce part of the payload.
 
    The old 'Recognized' field is removed and the node always tries to
-   authenticate the message as follows:
+   authenticate the message as follows.
 
-          forward direction (executed by the end node):
+4.1.1 forward direction (executed by the end node):
+				
+				Ta_I = Digest(Khf_n,Ta'_I||C_{n+1})
+				Tag = Ta_I ^ D(Ktf_n,Ta_I ^ N_{n+1})
 
-                T_{n+1} = Digest(Khf_n,C_{n+1})
-                Tag = T_{n+1} ^ D(Ktf_n,T_{n+1} ^ N_{n+1})
+				If Tag = 0:
+                  Ta'_I = Ta_I
+                  The message is authenticated.
+             Otherwise:
+                  Ta'_I remains unchanged.
+                  The message is not authenticated.
 
-                The message is recognized and authenticated
-				(i.e., M = C_{n+1}) if and only if Tag = 0.
 
-          backward direction (executed by the OP):
+4.1.2 backward direction (executed by the OP):
 
                 The message is recognized and authenticated
 				(i.e., C_{n+1} = M) if and only if N_{n+1} = 0.
@@ -264,14 +281,14 @@ Status: Open
      and version-heterogenic circuits
 
    When a cell is prepared to be routed from the origin (see Section
-   3.1.1) the encrypted nonce N is appended to the encrypted cell
-   (occupying the last 16 bytes of the cell). If the cell is
-   prepared to be sent to a node supporting the new protocol, S is
-   combined with other sources to generate the layer's
-   nonce. Otherwise, if the node only supports the old protocol, n
-   is still appended to the encrypted cell (so that following nodes
-   can still recover their nonce), but a synchronized nonce (as per
-   the old protocol) is used in CTR-mode.
+   3.1.1 above) the encrypted nonce N is appended to the encrypted 
+   cell (occupying the last 16 bytes of the cell). If the cell is
+   prepared to be sent to a node supporting the new protocol, N is
+   used to generate the layer's nonce. Otherwise, if the node only 
+   supports the old protocol, N is still appended to the encrypted 
+   cell (so that following nodes can still recover their nonce), 
+   but a synchronized nonce (as per the old protocol) is used in 
+   CTR-mode.
 
    When a cell is sent along the circuit in the 'backward'
    direction, nodes supporting the new protocol always assume that
@@ -371,7 +388,7 @@ Status: Open
    long as an honest node supporting the new protocol processes the
    message between two dishonest ones.
 
-5.3 The Running Digest
+5.3. The running digest
 
    Unlike the old protocol, the running digest is now computed as
    the output of a GHASH call instead of a hash function call
@@ -385,3 +402,164 @@ Status: Open
    repeat with low probability. GHASH is a universal hash function,
    hence it gives such a guarantee assuming its key is chosen
    uniformly at random.
+   
+6. Forward secrecy
+
+   Inspired by the approach of Proposal 308, a small modification 
+   to this proposal makes it forward secure. The core idea is to 
+   replace the encryption key KF_n after de/encrypting the cell.
+   As an added benefit, this would allow to keep the authentication 
+   layer stateless (i.e., without keeping a running digest for 
+   this layer). 
+   
+   Below we present the required changes to the sections above.
+   
+6.1. Routing from the Origin (replacing 3.1.1 above)
+   
+   When an OP sends a relay cell, they prepare the
+   cell as follows:
+
+        The OP prepares the authentication part of the message:
+
+			C_{n+1} = M
+			T_{n+1} = Digest(Khf_n,C_{n+1})
+			N_{n+1} = T_{n+1} ^ E(Ktf_n,T_{n+1} ^ 0)
+				
+
+        Then, the OP prepares the multi-layered encryption:
+			For the final layer n:
+				(C_n,Kf'_n) = Encrypt(Kf_n,N_{n+1},C_{I+1}||0||0) (*)
+				T_n = Digest(Khf_I,Tf'_n||C_n)
+				N_n = T_I ^ E(Ktf_n,T_n ^ N_{n+1})
+				Tf'_n = T_n
+				Kf_n = Kf'_n
+				
+				(*) CTR mode is used to generate two additional blocks. This 
+					256-bit value is denoted K'f_n and is used in subsequent 
+					steps to replace the encryption key of this layer.
+					To achieve forward secrecy it is important that the 
+					obsolete Kf_n is erased in a non-recoverable way. 				
+						
+                For layer I=(n-1)...1:
+                        C_I = Encrypt(Kf_I,N_{I+1},C_{I+1})
+                        T_I = Digest(Khf_I,Tf'_I||C_I)
+                        N_I = T_I ^ E(Ktf_I,T_I ^ N_{I+1})
+                        Tf'_I = T_I
+
+		The OP sends C_1 and N_1 to node 1.
+		
+	Alternatively, if we want that all nodes use the same functionality 
+	OP prepares the cell as follows:
+			
+			For layer I=n...1:
+				(C_I,K'f_I) = Encrypt(Kf_I,N_{I+1},C_{I+1}||0||0) (*)
+				T_I = Digest(Khf_I,Tf'_I||C_I)
+				N_I = T_I ^ E(Ktf_I,T_I ^ N_{I+1})
+				Tf'_I = T_I
+				Kf_I = Kf'_I
+				
+				(*) CTR mode is used to generate two additional blocks. This 
+					256-bit value is denoted K'f_n and is used in subsequent 
+					steps to replace the encryption key of this layer.
+					To achieve forward secrecy it is important that the 
+					obsolete Kf_n is erased in a non-recoverable way. 				
+						
+		This scheme offers forward secrecy in all levels of the circuit.
+		  
+6.2. Relaying Forward at Onion Routers (replacing 3.1.2 above)
+	
+   When a forward relay cell is received by OR I, it decrypts the
+   payload with the stream cipher, as follows:
+
+        'Forward' relay cell:
+
+                T_I = Digest(Khf_I,Tf'_I||C_I)
+                N_{I+1} = T_I ^ D(Ktf_I,T_I ^ N_I)
+                C_{I+1} = Decrypt(Kf_I,N_{I+1},C_I||0||0)
+                Tf'_I = T_I
+
+   The OR then decides whether it recognizes the relay cell as described below. 
+   Depending on the choice of scheme from 6.1 the OR uses the last two blocks 
+   of C_{I+1} to update the encryption key or discards them. 
+   
+   If the cell is recognized the OR also processes the contents of the relay 
+   cell. Otherwise, it passes C_{I+1}||N_{I+1} along the circuit if the circuit 
+   continues.
+
+   For more information about recognizing and authenticating relay cells,
+   see 5.4.5 below.
+   
+6.3. Relaying Backward at Onion Routers (replacing 3.2.1 above)
+
+   When an edge node receives a message M to be routed back to the
+   origin, it encrypts it as follows:
+   
+		T_n = Digest(Khb_n,Tb'_n||M)
+                N_n = T_n ^ E(Ktb_n,T_n ^ 0)
+                (C_n,K'b_n) = Encrypt(Kb_n,N_n,M||0||0) (*)
+                Tb'_n = T_n
+		Kb_n = K'b_n
+   
+				(*) CTR mode is used to generate two additional blocks. This 
+					256-bit value is denoted K'b_n and will be used in 
+					subsequent steps to replace the encryption key of this layer. 
+					To achieve forward secrecy it is important that the obsolete 
+					K'b_n is erased in a non-recoverable way. 
+   
+    Once encrypted, the edge node sends C_n and N_n along the circuit towards 
+	the OP. When a backward relay cell is received by OR_I (I&lt;n), it encrypts 
+	the payload with the stream cipher, as follows:
+
+        'Backward' relay cell:
+
+                T_I = Digest(Khb_I,Tb'_I||C_{I+1})
+                N_I = T_I ^ E(Ktb_I,T_I ^ N_{I+1})
+                C_I = Encrypt(Kb_I,N_I,C_{I+1})
+                Tb'_I = T_I
+
+   Each node passes C_I and N_I along the circuit towards the OP.
+   
+   If forward security is desired for all layers in the circuit, all OR's
+   encrypt as follows:
+		T_I = Digest(Khb_I,Tb'_I||C_{I+1})
+                N_I = T_I ^ E(Ktb_I,T_I ^ 0)
+                (C_I,K'b_I) = Encrypt(Kb_n,N_n,M||0||0)
+                Tb'_I = T_I
+		Kb_I = K'b_I
+   
+
+6.4. Routing to the Origin (replacing 3.2.2 above)
+
+   When a relay cell arrives at an OP, the OP decrypts the payload
+   with the stream cipher as follows:
+
+        OP receives relay cell from node 1:
+
+                For I=1...n, where n is the end node on the circuit:
+                        C_{I+1} = Decrypt(Kb_I,N_I,C_I)
+                        T_I = Digest(Khb_I,Tb'_I||C_{I+1})
+                        N_{I+1} = T_I ^ D(Ktb_I,T_I ^ N_I)
+                        Tb'_I = T_I
+				
+				And updates the encryption keys according to the strategy 
+				chosen for 6.3.
+				
+                If the payload is recognized (see Section 4.1),
+                then:
+
+                       The sending node is I. Process the payload!
+					   
+					   
+6.5. Recognizing and authenticating a relay cell (replacing 4.1.1 above):
+	
+	Authentication in the forward direction is done as follows: 
+
+		T_{n+1} = Digest(Khf_n,C_{n+1})
+                Tag = T_{n+1} ^ D(Ktf_n,T_{n+1} ^ N_{n+1})
+	
+	The message is recognized and authenticated
+				(i.e., M = C_{n+1}) if and only if Tag = 0.
+				
+	No changes are required to the authentication process when the relay 
+	cell is sent backwards.
+	

[Attachment #5 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200115132801</emailId><senderName>teor</senderName><senderEmail>teor@riseup.net</senderEmail><timestampReceived>2020-01-15 13:28:01-0400</timestampReceived><subject>Re: [tor-dev] Updates to Prop306: A Tor Implementation of IPv6 Happy Eyeballs</subject><body>

[Attachment #2 (multipart/signed)]


Dear Tor Developers,

Neel and I have spent some time working on proposal 306: A Tor
Implementation of IPv6 Happy Eyeballs. I think we now have a proposal
that covers all the essential changes to get Tor clients working on IPv4
and IPv6 networks.

Here is a summary of the most recent changes:

Include extra designs and analysis for:
* bootstrapping
* load-balancing
* onion services (particularly v3 single onion services)

I was surprised when I did the load-balancing analysis. Deploying this
proposal across the Tor network would result in 33% of client load going
to the 20% of guards that support IPv6.

Therefore, we need to prioritise IPv6 relay support, before we can
implement or deploy this proposal. Fortunately, RIPE has awarded Tor a
grant to work on IPv6 relay support in 2020.

Here is the full load-balancing analysis:
https://gitweb.torproject.org/torspec.git/tree/proposals/306-ipv6-happy-eyeballs.txt#n142


And here is a link to some information about the RIPE IPv6 grant:
(We'll have more information once we've roadmapped the grant work)
https://lists.torproject.org/pipermail/tor-relays/2019-December/017960.html

We also simplified the proposal:
* tweaked the design to match Tor's standard design patterns,
* identified essential and optional changes,
* noted that bridge changes are out of scope, and
* removed alternative designs that were in earlier drafts.

We've been working in this ticket and pull request:
https://trac.torproject.org/projects/tor/ticket/29801
https://github.com/torproject/torspec/pull/102

Let's open new tickets for any further changes.

See the end of this email for a full copy of the proposal.

&gt; On 27 Dec 2019, at 12:23, Neel Chauhan &lt;neel@neelc.org&gt; wrote:
&gt; 
&gt; Sorry for the 10-day delay, again. I was busy since I'm moving across the US. Well, \
&gt; I got my first full time job!

Congratulations on the job, Neel!

And thanks so much for your patience with this proposal.

&gt; ...
&gt; 
&gt; However, I'm worried I removed something you may feel is necessary.

I'm really happy with what you removed, and listed as optional. I did
a final check, and found some statistics in the old draft that might
still be useful. So I added them back before merging.

Here's a full copy of the current proposal.
Feel free to comment inline.

Filename: 306-ipv6-happy-eyeballs.txt
Title: A Tor Implementation of IPv6 Happy Eyeballs
Author: Neel Chauhan
Created: 25-Jun-2019
Supercedes: 299
Status: Open
Ticket: https://trac.torproject.org/projects/tor/ticket/29801

1. Introduction

   As IPv4 address space becomes scarce, ISPs and organizations will deploy
   IPv6 in their networks. Right now, Tor clients connect to entry nodes using
   IPv4 connectivity by default.

   When networks first transition to IPv6, both IPv4 and IPv6 will be enabled
   on most networks in a so-called "dual-stack" configuration. This is to not
   break existing IPv4-only applications while enabling IPv6 connectivity.
   However, IPv6 connectivity may be unreliable and clients should be able
   to connect to the entry node using the most reliable technology, whether
   IPv4 or IPv6.

   In ticket #27490, we introduced the option ClientAutoIPv6ORPort which
   lets a client randomly choose between IPv4 or IPv6. However, this
   random decision does not take into account unreliable connectivity
   or falling back to the alternate IP version should one be unreliable
   or unavailable.

   One way to select between IPv4 and IPv6 on a dual-stack network is a
   so-called "Happy Eyeballs" algorithm as per RFC 8305. In one, a client
   attempts the preferred IP family, whether IPv4 or IPv6. Should it work,
   the client sticks with the preferred IP family. Otherwise, the client
   attempts the alternate version. This means if a dual-stack client has
   both IPv4 and IPv6, and IPv6 is unreliable, preferred or not, the
   client uses IPv4, and vice versa. However, if IPv4 and IPv6 are both
   equally reliable, and IPv6 is preferred, we use IPv6.

   In Proposal 299, we have attempted a IP fallback mechanism using failure
   counters and preferring IPv4 and IPv6 based on the state of the counters.
   However, Prop299 was not standard Happy Eyeballs and an alternative,
   standards-compliant proposal was requested in [P299-TRAC] to avoid issues
   from complexity caused by randomness.

   This proposal describes a Tor implementation of Happy Eyeballs and is
   intended as a successor to Proposal 299.

2. Address/Relay Selection

   This section describes the necessary changes for address selection to
   implement Prop306.

2.1. Address Handling Changes

   To be able to handle Happy Eyeballs in Tor, we will need to modify the
   data structures used for connections to entry nodes, namely the extend info
   structure.

   Entry nodes are usually guards, but some clients don't use guards:

     * Bootstrapping clients can connect to fallback directory mirrors or
       authorities

     * v3 single onion services can use IPv4 or IPv6 addresses to connect
       to introduction and rendezvous points, and

     * Clients can be configured to disable entry guards

   Bridges are out of scope for this proposal, because Tor does not support
   multiple IP addresses in a single bridge line.

   The extend info structure should contain both an IPv4 and an IPv6 address.
   This will allow us to try IPv4 and the IPv6 addresses should both be
   available on a relay and the client is dual-stack.

   When processing:
     * relay descriptors,
     * hard-coded authority and fallback directory lists,
     * onion service descriptors, or
     * onion service introduce cells,
   and filling in the extend info data structure, we need to fill in both the
   IPv4 and IPv6 address if both are available. If only one family is
   available for a relay (IPv4 or IPv6), we should leave the other family null.

2.2 Bootstrap Changes

   Tor's hard-coded authority and fallback directory mirror lists contain
   some entries with IPv6 ORPorts. As of January 2020, 56% of authorities and
   47% of fallback directories have IPv6.

   During bootstrapping, we should have an option for the maximum number of
   IPv4-only nodes, before the next node must have an IPv6 ORPort. The
   parameter is as follows:

     * MaxNumIPv4BootstrapAttempts NUM

   During bootstrap, the minimum fraction of nodes with IPv6 ORPorts will be
   1/(1 + MaxNumIPv4BootstrapAttempts). And the average fraction will be
   larger than both minimum fraction, and the actual proportion of IPv6
   ORPorts in the fallback directory list. (Clients mainly use fallback
   directories for bootstrapping.)

   Since this option is used during bootstrapping, it can not have a
   corresponding consensus parameter.

   The default value for MaxNumIPv4BootstrapAttempts should be 2. This
   means that every third bootstrap node must have an IPv6 ORPort. And on
   average, just over half of bootstrap nodes chosen by clients will have an
   IPv6 ORPort. This change won't have much impact on load-balancing, because
   almost half the fallback directory mirrors have IPv6 ORPorts.

   The minimum value of MaxNumIPv4BootstrapAttempts is 0. (Every bootstrap
   node must have an IPv6 ORPort. This setting is equivalent to
   ClientPreferIPv6ORPort 1.)

   The maximum value of MaxNumIPv4BootstrapAttempts should be 100. (Since
   most clients only make a few bootstrap connections, bootstrap nodes will
   be chosen at random, regardless of their IPv6 ORPorts.)

2.3. Guard Selection Changes

   When we select guard candidates, we should have an option for the number of
   primary IPv6 entry guards. The parameter is as follows:

     * NumIPv6Guards NUM

   If UseEntryGuards is set to 1, we will select exactly this number of IPv6
   relays for our primary guard list, which is the set of relays we strongly
   prefer when connecting to the Tor network. (This number should also apply
   to all of Tor's other guard lists, scaled up based on the relative size of
   the list.)

   If NUM is -1, we try to learn the number from the NumIPv6Guards
   consensus parameter. If the consensus parameter isn't set, we should
   default to 1.

   The default value for NumIPv6Guards should be -1. (Use the consensus
   parameter, or the underlying default value of 1.)

   As of September 2019, approximately 20% of Tor's guards supported IPv6,
   by consensus weight. (Excluding exits that are also guards, because
   clients avoid choosing exits in their guard lists.)

   If all Tor clients implement NumIPv6Guards, then these 20% of guards will
   handle approximately 33% of Tor's traffic. (Because the default value of
   NumPrimaryGuards is 3.) This may have a significant impact on Tor's
   load-balancing. Therefore, we should deploy this feature gradually, and try
   to increase the number of relays that support IPv6 to at least 33%.

   To minimise the impact on load-balancing, IPv6 support should only be
   required for exactly NumIPv6Guards during guard list selection. All other
   guards should be IPv4-only guards. Once approximately 50% of guards support
   IPv6, NumIPv6Guards can become a minimum requirement, rather than an exact
   requirement.

   The minimum configurable value of NumIPv6Guards is -1. (Use the consensus
   parameter, or the underlying default.)

   The minimum resulting value of NumIPv6Guards is 0. (Guards will be chosen
   at random, regardless of their IPv6 ORPorts.)

   The maximum value of NumIPv6Guards should be the configured value of
   NumPrimaryGuards. (Every guard must have an IPv6 ORPort. This setting is
   equivalent to ClientPreferIPv6ORPort 1.)

3. Relay Connections

   If there is an existing authenticated connection, we must use it similar
   to how we used it pre-Prop306.

   If there is no existing authenticated connection for an entry node, tor
   currently attempts to connect using the first available, allowed, and
   preferred address. (Determined using the existing Client IPv4 and IPv6
   options.)

   We should also allow falling back to the alternate address. For this,
   a design will be given in Section 3.1.

3.1. TCP Connection to Preferred Address On First TCP Success

   In this design, we will connect via TCP to the first preferred address.
   On a failure or after a 250 msec delay, we attempt to connect via TCP to
   the alternate address. On a success, Tor attempts to authenticate and
   closes the other connection.

   This design is close to RFC 8305 and is similar to how Happy Eyeballs
   is implemented in a web browser.

3.2. Handling Connection Successes And Failures

   Should a connection to a entry node succeed and is authenticated via TLS,
   we can then use the connection. In this case, we should cancel all other
   connection timers and in-progress connections. Cancelling the timers is
   necessary so we don't attempt new unnecessary connections when our
   existing connection is successful, preventing denial-of-service risks.

   However, if we fail all available and allowed connections, we should tell
   the rest of Tor that the connection has failed. This is so we can attempt
   another entry node.

3.3. Connection Attempt Delays

   As mentioned in [TEOR-P306-REP], initially, clients should prefer IPv4
   by default. The Connection Attempt Delay, or delay between IPv4 and IPv6
   connections should be 250 msec. This is to avoid the overhead from tunneled
   IPv6 connections.

   The Connection Attempt Delay should not be dynamically adjusted, as it adds
   privacy risks. This value should be fixed, and could be manually adjusted
   using this torrc option or consensus parameter:

     * ConnectionAttemptDelay N [msec|second]

   The Minimum and Maximum Connection Attempt Delays should also not be
   dynamically adjusted for privacy reasons. The Minimum should be fixed at
   10 msec as per RFC 8305. But the maximum should be higher than the RFC 8305
   recommendation of 2 seconds. For Tor, we should make this timeout value 30
   seconds to match Tor's existing timeout.

   We need to make it possible for users to set the Maximum Connection Attempt
   Delay value higher for slower and higher-latency networks such as dial-up
   and satellite.

4. Option Changes

   As we enable IPv6-enabled clients to connect out of the box, we should
   adjust the default options to enable IPv6 while not breaking IPv4-only
   clients.

   The new default options should be:

    * ClientUseIPv4 1 (to enable IPv4)

    * ClientUseIPv6 1 (to enable IPv6)

    * ClientPreferIPv6ORPort 0 (for load-balancing reasons so we don't
      overload IPv6-only guards)

    * ConnectionAttemptDelay 250 msec (the recommended delay between IPv4
      and IPv6, as per RFC 8305)

   One thing to note is that clients should be able to connect with the above
   options on IPv4-only, dual-stack, and IPv6-only networks, and they should
   also work if ClientPreferIPv6ORPort is 1. But we shouldn't expect
   IPv4 or IPv6 to work if ClientUseIPv4 or ClientUseIPv6 is set to 0.

   When the majority of clients and relay are IPv6-capable, we could set the
   default value of ClientPreferIPv6ORPort to 1, in order to take advantage
   of IPv6. We could add a ClientPreferIPv6ORPort consensus parameter, so we
   can make this change network-wide.

5. Relay Statistics

   Entry nodes could measure the following statistics for both IPv4 and IPv6:

     * Number of successful connections

     * Number of extra Prop306 connections (unsuccessful or cancelled)
       * Client closes the connection before completing TLS
       * Client closes the connection before sending any circuit or data cells

     * Number of client and relay connections
       * We can distinguish between authenticated (relay, authority
         reachability) and unauthenticated (client, bridge) connections

   Should we implement Section 5:

     * We can send this information to the directory authorities using relay
       extra-info descriptors

     * We should consider the privacy implications of these statistics, and
       how much noise we need to add to them

     * We can include these statistics in the Heartbeat logs

6. Initial Feasibility Testing

   We should test this proposal with the following scenarios:

    * Different combinations of values for the options ClientUseIPv4,
      ClientUseIPv6, and ClientPreferIPv6ORPort on IPv4-only, IPv6-only,
      and dual-stack connections

    * Dual-stack connections of different technologies, including
      high-bandwidth and low-latency (e.g. FTTH), moderate-bandwidth and
      moderate-latency (e.g. DSL, LTE), and high-latency and low-bandwidth
      (e.g. satellite, dial-up) to see if Prop306 is reliable and feasible

7. Minimum Viable Prop306 Product

   The mimumum viable product for Prop306 must include the following:

    * The address handling, bootstrap, and entry guard changes described in
      Section 2. (Single Onion Services are optional, Bridge Clients are out
      of scope. The consensus parameter and torrc options are optional.)

    * The alternative address retry algorithm in Section 3.1.

    * The Connection Success/Failure mechanism in Section 3.2.

    * The Connection Delay mechanism in Section 3.3. (The
      ConnectionAttemptDelay torrc option and consensus parameter are
      optional.)

    * A default setup capable of both IPv4 and IPv6 connections with the
      options described in Section 4. (The ClientPreferIPv6ORPort consensus
      parameter is optional.)

8. Optional Features

   Some features which are optional include:

    * Single Onion services: extend info address changes for onion service
      descriptors and introduce cells. (Section 2.1.)

    * Bridge clients are out of scope: they would require bridge line format
      changes, internal bridge data structure changes, and extend info address
      changes. (Section 2.1.)

    * MaxNumIPv4BootstrapAttempts torrc option. We may need this option if
      the proposed default doesn't work for some clients. (Section 2.2.)

    * NumIPv6Guards torrc option and consensus parameter. We may need this
      option if the proposed default doesn't work for some clients.
      (Section 2.3.)

    * ConnectionAttemptDelay torrc option and consensus parameter. We will need
      this option if the Connection Attempt Delay needs to be manually
      adjusted, for instance, if clients often fail IPv6 connections.
      (Section 3.3.)

    * ClientPreferIPv6ORPort consensus parameter. (Section 4.)

    * IPv4, IPv6, client, relay, and extra Prop306 connection statistics.
      While optional, these statistics may be useful for debugging and
      reliability testing, and metrics on IPv4 vs IPv6. (Section 5.)

9. Acknowledgments

   Thank you so much to teor for your discussion on this happy eyeballs
   proposal. I wouldn't have been able to do this has it not been for
   your help.

10. Refrences

   [P299-TRAC]: https://trac.torproject.org/projects/tor/ticket/29801

   [TEOR-P306-REP]: https://lists.torproject.org/pipermail/tor-dev/2019-July/013919.html



T

--
teor
----------------------------------------------------------------------


["signature.asc" (signature.asc)]

-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEo9HIo7IdGQ1wBWG3EP6qDnB1ZyoFAl4fE2EACgkQEP6qDnB1
Zyonrw//V0OPGuykX+qnqKWuTB3uCEknu1Mly0QgNWvqXRY7pbahbkDsuFbKR//b
3mNHdNi24ogp9S/hHwxsOUFYwqwXohPGz5RqOabZZKoiTSjkImVlg2CHon1jwP7c
HTWBWY6SMRBrY6v4vtFAUCjECkzOu2GIr7SgYJuB+55aTfk7AQnAQ5m8BQC3OmJN
ACuOumo35fZ18Bmv+ksnoZ7hH6HzDh5B7ZZurD/5fQNsiQ4w5e94EAm0pidEg2rT
PCj7zu7xCCxCEXbO5p3dcDymSixxgP4C9MEmcavB4rkgQiXB6ELcvYiPar/W2Jtu
uAG935Tu1T6yAvgRjFfuGkBtnSTQTeUnXbystDtwIByePlppSWQs7kkn3WtK590Z
KDPl8Fvuzm/4yyirJIWLKzn6JcI6W3vOioWDR8TSzlcleXUVzah3OXwtvkP5V3VX
MRrsrOIHS/dVe55LKSkmTWU1erRjshLU/4lcKIL1KVN+Fer8WKQ4jue8JgJkPx8n
MvF5ksC6s1S2uZDQKqUFSeCOSJ5NztM/IyzjvFamsNaMQH2XR5eOxIIkv31s+58s
5cesY/sGVzt86z43iQvJlshpzom9y10uLgYPWDZrTV9iC802eCADM7S8mEqHroAt
9Emfxh+QxVIT7ZSsyplAQVB/J2eOA1KMAOBPCD0JHk73eNu005A=
=tcYI
-----END PGP SIGNATURE-----

[Attachment #6 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200117102040</emailId><senderName>Patrick Schleizer</senderName><senderEmail>patrick-mailinglists@whonix.org</senderEmail><timestampReceived>2020-01-17 10:20:40-0400</timestampReceived><subject>Re: [tor-dev] OK got mix vanguards from packages.debian.org with Tor from deb.torproject.org reposit</subject><body>

Iain Learmonth:
&gt; Hi,
&gt; 
&gt; On 09/01/2020 16:15, Patrick Schleizer wrote:
&gt;&gt; I am considering to install vanguards by default in Whonix.


This is now implemented in git master and will be tested and released as
per usual.

&gt;&gt; Is it sane to mix the Debian 'tor' package deb.torproject.org (buster
&gt;&gt; repository) with packages.debian.org buster version of 'vanguards' or do
&gt;&gt; you foresee any issues?
&gt; 
&gt; I would not forsee any issues.
&gt; 
&gt; vanguards does have checks on the tor version to see which things are
&gt; available, and uses the things that are correct for the version of tor
&gt; in use.


Awesome! :)

&gt; Let me know if there are any issues relating to the systemd unit, etc.


Had a few minor issues that I reported.

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=948975

https://github.com/mikeperry-tor/vanguards/issues/48

https://github.com/mikeperry-tor/vanguards/issues/47

Kind regards,
Patrick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200117141804</emailId><senderName>Valentin Franck</senderName><senderEmail>gaspar_ilom@win.tu-berlin.de</senderEmail><timestampReceived>2020-01-17 14:18:04-0400</timestampReceived><subject>Re: [tor-dev] Evaluating rendezvous circuit build up CPU usage</subject><body>

Hello,

thanks for you mail. my comments are below.


On 1/15/20 6:17 PM, juanjo wrote:
&gt; Hi, thanks for working on it.
&gt;
&gt; At first I thought about using a PoW on the Introduction Point (I.P.)
&gt; side.
&gt;
&gt; Maybe a dynamic PoW? I mean only ask for PoW under load (Hidden
&gt; services sets the INTRO1s/second on the I.P.) or ask for every new
&gt; circuit.
From what I know this would most likely require a more than 1-RTT
(interactive) introduction protocol. I think we definitely want to avoid
that.
&gt;
&gt; Then I thought that we need to fix the Rendezvous verification issue
&gt; too. We do not verify if the client/user/attacker actually opened a
&gt; circuit to the Rend point. And I thought we could make the Rend sing a
&gt; message and the I.P verify the signature before sending the INTRO2 to
&gt; the HS.
Such a signature would have to be zero knowledge. Otherwise we would
leak the chosen RP to the IP and make deanonymization more likely.
Designing an unforgeable proof of rendezvous is non-trivial (even if it
is was verified by the service and not the IP), because we have to
assume that adversaries run their own relays. Therefore they could most
likely precompute/forge these proofs of rendezvous. Of course, we could
try and cache which RPs have been used, but this seems a lot of work for
relatively little security benefits. I doubt that this approach is
suitable to discourage resourceful adversaries from DoSing services.
&gt;
&gt; But now I think we need to merge designs and make just one proposal
&gt; fixing both problems at the same time.
&gt;
&gt; If we don't want to make a PoW for every new circuit, we could make
&gt; the client generate a private Identity (KeyPair) mixed with some sort
&gt; of PoW, generating it for every HS a client want to connect. This way
&gt; we only make PoW for each onion and the IP can have a replay cache (or
&gt; something like that) with each identity and the last time it requested
&gt; a new circuit. We can better control with this way the number of
&gt; individual clients and we "save the planet" by not making a PoW for
&gt; each new circuit. (Maybe this approach is what your are working at
&gt; with the "token based approach").
I believe, we should avoid making different connections to an onion
service by the same user linkable by the IP/service as this would turn
anonymity into pseudonymity and therefore ease user identification. Of
course, there are crypto schemes that allow us to use anonymous
credentials/ authentication.  Unfortunately, I am not sure how such
anonymous credentials could be useful for DoS mitigation. We would
somehow need a mechanism to detect misbehavior and revoke the
credentials or limit their use to a certain number of authentications. I
am not sure, how this can be done if different authentications using the
same credentials are truely unlinkable.
&gt;
&gt; Sorry for my english...
&gt;
&gt;
&gt; El 13/1/20 a las 13:39, Valentin Franck escribi:
&gt;&gt; Hello tor-devs,
&gt;&gt;
&gt;&gt; I am currently working on a DoS mitigation system aiming to protect the
&gt;&gt; availability of onion services flooded with INTRO2 cells. My idea is
&gt;&gt; using a (Privacy Pass like) token based approach as suggested in
&gt;&gt; https://trac.torproject.org/projects/tor/ticket/31223#comment:6
&gt;&gt;
&gt;&gt; For the evaluation of a first prototype I would like to compare CPU
&gt;&gt; usage times at the onion service when a) launching a rendezvous circuit
&gt;&gt; and b) validating a (potentially invalid) token. Is there an easy way,
&gt;&gt; to measure the CPU time a service spends for all operations triggered
&gt;&gt; when launching a new rendezvous circuit? Has somebody done that before?
&gt;&gt; Basically, I want to measure how much CPU time we save, if we do not
&gt;&gt; launch the rendezvous circuit. So far I have identified the following
&gt;&gt; functions: launch_rendezvous_point_circuit() and
&gt;&gt; service_rendezvous_circ_has_opened(). I understand that there is more
&gt;&gt; operations involved for building new circuits, since circuits are built
&gt;&gt; hop by hop. How can I  identify all relevant functions triggered after
&gt;&gt; launching the rendezvous circuit and include them in my measurements?
&gt;&gt;
&gt;&gt; Once I have some reliable results I will provide you with more
&gt;&gt; information on what I am doing and how it is working so far.
&gt;&gt;
&gt;&gt; Cheers
&gt;&gt; Valentin
&gt;&gt;
&gt;&gt; This is my first post on this list :-). So have mercy, if I overlooked
&gt;&gt; resources to answer my question. Also, I am only beginning to
&gt;&gt; familiarize myself with the existing code base.
&gt;&gt;
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200117151951</emailId><senderName>"procmem () riseup ! net"</senderName><senderEmail>procmem@riseup.net</senderEmail><timestampReceived>2020-01-17 15:19:51-0400</timestampReceived><subject>[tor-dev]  Snowflake server and traffic analysis questions</subject><body>

Thanks Cecylia for your great explanation.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200129133206</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-01-29 13:32:06-0400</timestampReceived><subject>Re: [tor-dev] Vanguard Plugin Options</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 1/16/20 5:01 PM, procmem@riseup.net wrote:
&gt; 
&gt; Hi. We are rolling out the vanguard plugin for our users and wanted to
&gt; understand some options we can enable.
&gt; 
&gt; * In many parts of the Security README setting *circ_max_megabytes* is
&gt; recommended. Though it is discouraged for usecases involving Onionshare
&gt; and Securedrop which we support. What is a reasonable limit to set? What
&gt; happens is the max ceiling gets hit? Does it permanently disrupt the
&gt; upload/download?

Setting circ_max_megabytes means that no circuit can be used to transmit
more than that many megabytes. As soon as that limit is hit, the circuit
will be force-closed.

I do not recommend using this option in your case, as you cannot
anticipate the max file size that a securedrop or onionshare user may
use, and the failure more here is non-obvious (their upload/download
will just fail).

&gt; * "High load onion services may consider using 4 layer2 guards by
&gt; changing the *num_layer2_guards* option in the configuration file
&gt; &lt;https://github.com/mikeperry-tor/vanguards/blob/master/vanguards-example.conf&gt;,
&gt; but going beyond that is not recommended."
&gt; Does this benefit clients too? We would like to enable options that
&gt; mimic the configuration used by actual high load onion services to
&gt; provide them with more cover.

Using more layer2 guards will not improve client performance. I
recommend staying with the defaults, as they are backed by asn's
analysis. Any other choice would be arbitrary or specific to a custom
circumstance, and thus provide less cover.

-- 
Mike Perry


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200129211020</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2020-01-29 21:10:20-0400</timestampReceived><subject>Re: [tor-dev] Prop 311: Relay IPv6 Reachability</subject><body>

On Wed, Jan 29, 2020 at 8:56 AM teor &lt;teor@riseup.net&gt; wrote:

Thanks for the followup, Teor!  I have only one comment on the changes:

&gt; I made these useful features "may not" in:
&gt; https://github.com/torproject/torspec/pull/103/commits/2662c688170696fbed2ba7e4dfa7f33ccf702435

We should avoid "may not" in standards documents because it can be
ambiguous.  "Nick may not eat breakfast" can mean either that I'm not
allowed to eat breakfast, or that it's possible I won't eat breakfast.

I think this is the reason why RFC 2119 does not include "MAY NOT" as
an option.  Let's use "should not" or "or "may refrain from" or "might
not" as appropriate?

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200130133326</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-01-30 13:33:26-0400</timestampReceived><subject>[tor-dev] Options for Congestion Control in Tor-like Networks</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


This near-book-length mail is a pre-proposal to help us review previous
congestion control ideas for Tor, and brainstorm new ones. My goal is to
turn this material into one or more proposals and provide ways of
evaluating these options. With proper voodoo, maybe we can resurrect a
couple oldies from the graveyard of mixnet lore, and remix them into
some Vaporwave bangers. If we're real lucky with some fresh ideas, maybe
we can even make a hip hop Internet streaming chart buster from this mix.

But long mail is looong, ok? It's sooo long it has its own soundtrack.
Grab your favorite links from the references at the end, maybe print
everything out, find the nearest sofa or bed, and curl up with it all.
Flip on some Pretty Lights. Let's get that flow Finally Moving. Turn off
the tv! The flow is More Important Than Michael Jordan. Listen: the flow
is Hot Like Sauce. I hope you're an Organ Donor - Extended Overhaul
might be necessary. We're going on a mental Midnight Voyage by Ghostland
Observatory. But don't worry, we'll make it by 4 AM, without being
trapped there, I swear. Hopefully that's not Pushing Time with ya Ample
Mammal(s). Relax: there will still be time for some Codeine(g) Dreaming.
If you finish reading all of it before you go ROCKABYE BABY, you're
definitely a High Roller. All of this is almost exactly an hour of
Bumpin' In The Voodoo with Manic Focus.

If you'd rather take your time and chillax with something Muy Tranquilo
but less Gramatik, just put on some Blank Banshee. But don't fall
asleep, or George Clanton will Kill You In Bed.

Ready? Ok, back to serious business.


Motivation: Load balancing (TorFlow/sbws), circuit build timeout cutoffs
(CBT), and QoS (KIST+EWMA) have provided huge perf wins for Tor. Tuning
and improving these systems will continue to provide latency
improvements in the average case, but congestion control is the missing
piece we need for the network to operate properly at high utilization
levels. Congestion control is also necessary to increase the throughput
of the network at even at low utilization levels. Historically, Tor
performance shows high correlation to network utilization levels, and I
believe this is largely due to the effects of ephemeral congestion:
https://lists.torproject.org/pipermail/tor-scaling/2019-June/000051.html

In fact, Section 6.3 of
https://www.freehaven.net/anonbib/cache/murdoch-pet2008.pdf uses
Pollaczek-Khinchin queuing theory to show that expected Tor queue
latency is proportional to network utilization divided by spare
capacity, if queues are not otherwise bounded somehow (by congestion
control).


Summary: The rest of this post is organized as follows: First, I go over
TCP and ECN, because I build upon those for a couple new ideas. Then, I
summarize Tor's current SENDME flow control and review its many
failings. Then, I review past attempts at congestion control for Tor in
the research literature. Then, I propose four new candidate ideas.
Finally, I conclude the post with some ideas for evaluation and further
analysis.

Unless you are a congestion control expert who is also deeply familiar
with Tor's many failed attempts in this area, I strongly recommend
wading through this post in order. The summaries are meant to get you up
to speed without having to do quite as much reading as I did, and they
are filled with in-line URL references in case you want to dig deeper.

If you still want to skip ahead to the highlights, search this mail for
[PROPOSAL_CANDIDATE]. There are four such sections. Those sections build
on other ideas, though. For those, search for [TCP_HISTORY],
[BOOTLEG_RTT_TOR], [FORWARD_ECN_TOR], and [BACKWARD_ECN_TOR]. Search for
[TRACK_LISTING] to find a summary table of all the new ideas from this
post, with their associated key properties.

Crucially absent from this pre-proposal post is the closely related
discussion of QoS/scheduling, which we need to make decisions about
which circuit(s) to select for delivering congestion control signals,
when congestion occurs. For now, this post just handwaves this piece as
"use either EWMA or something RED-like". There is much literature on
these mechanisms, enough to warrant separate treatment, but thankfully
the choice of which to use is orthogonal to the choice of congestion
control signal delivery mechanism.


-I. History of Internet Congestion Control [TCP_HISTORY]

In TCP, each endpoint maintains send and receive buffers of packets,
called windows. The receive window holds packets until a contiguous
chunk is received, at which point data is delivered to the application
and an acknowledgement packet is sent to the other end. The send window
size is doubled every ack until the first packet is dropped, after which
it is increased by 1 for each acked packet, and halved for each drop.
This is called Slow Start with AIMD (Additive-Increase
Multiplicative-Decrease). Packets that are not acked are retransmitted
from the send window buffer after a timeout of one RTT (Round Trip
Time). Drops are caused by intermediate routers' fixed-size queues being
full, but can also be caused by poor network conditions (which leads to
sub-optimal throughput). In this way, TCP responds to congestion
anywhere on the path, and takes around one RTT to detect said congestion.

Even this detailed summary is a simplified model. In reality, TCP is way
more complicated than that. The real thing has like 23 states, and a
whole bunch of kruft from the 80s and 90s that we'll want to cut out of
our mix. We just need the key hooks.

Decades later, Explicit Congestion Notification (ECN) was proposed to
allow routers to explicitly set a flag on TCP packets to signal that
their queue is getting full, instead of dropping packets. For abstruse
compatibility and reliability reasons, when a router adds this flag to a
packet, it is sent all the way to one endpoint. That endpoint *then*
re-adds the flag to acks going in the other direction, all the way to
the other endpoint, who then backs off as if it detected a packet drop.
This is called Forward ECN: https://tools.ietf.org/html/rfc3168#section-6.1

Unfortunately, because of the requirement to bounce the congestion
notification flag all the way off the other endpoint, it *still* takes
Forward ECN at least one RTT to respond to congestion, and so almost no
intermediate routers have bothered to deploy it -- the gains are only
marginal.

Also interesting for our purposes is the vastly simplified Backwards ECN
that uses separate ICMP signaling to eliminate the endpoint echo RTT for
much faster responsiveness to congestion:
https://tools.ietf.org/html/draft-salim-jhsbnns-ecn-00

Backwards ECN was never widely deployed either, because ICMP is easy to
spoof+spam, requires extra packet overhead, many routers filter it, and
no strong authentication binds it to the TCP connection.

But enough history! Onward!


@. Status quo of the Tor flow: SENDME sadness and pain

Tor has a window-based flow control system called SENDMEs. This system
does not provide congestion control, as window sizes are hard-coded
constants. I believe it is important to review this system in detail, so
we can avoid making any of the same mistakes again. Bear with me.

Recall that Tor circuits are 3 hops long when contacting the Internet
(Guard, Middle, Exit), and 7 hops long when a client contacts an onion
service. TCP is used for connection in between these hops. One or more
reliable streams are multiplexed inside each circuit.

Each endpoint of a circuit (client and Exit, or client and onion
service) maintains a remaining-to-send cell count for each circuit and
stream, which is refilled when it receives a SENDME from the other end.
Each time it sends a cell, it decrements this count. When this count
reaches 0 without receiving corresponding SENDMEs, it will stop sending
data. The initial value of these counts is 1000 cells for circuits and
500 cells for streams, and each SENDME refills 100 cell counts for
circuits, and 50 cell counts for streams. Crucially: no backpressure
happens on interior relay connections for this windowing system.
Instead, we just queue.

If you have a TCP background, you may find it easier to mentally replace
"SENDME" with "ACK", and you won't be far off. Its just that our acks
always ack a fixed amount of cells, and the window size is also fixed.

In the steady state stage, window updates of 50 or 100 cells per SENDME
results in an upper bound of performance inversely proportional to half
the circuit RTT. This is 2*CELL_SIZE*50/RTT for streams, and
2*CELL_SIZE*100/RTT for circuits. For streams with a ~100msec RTT, this
is ~500Kbytes/sec.

This means that once the Tor network has enough capacity for RTT to be
close to link transit time (ie: no queue delay), adding more Tor relays
will *not* make Tor faster. This also means that onion service
throughput will almost always be much lower than Exit throughput. The
RTT is much much higher for 7 hop onion circuits than for 3 hop exits,
so even if there is plenty of spare network capacity, Onion service
sites will *never* download as fast as their clearweb equivalents with
our current flow control.

All of this is done just to provide flow control, so that data flow can
stop in the event of endpoint stalls and/or interior relay failure. It
does not actually provide fairness or limit congestion when multiple
clients are used. Additionally, because nothing proves the endpoint has
read the data, a client that does not read data but keeps sending
SENDMEs to the Exit can deliberately force queues to build up in the
Guard node (due to the client-blocked TCP layer), to induce OOM
conditions and crashes. We need to upgrade all clients and all Exit
relays to fix this problem, which will take quite some time:
https://gitweb.torproject.org/torspec.git/tree/proposals/289-authenticated-sendmes.txt

Even with honest or authenticated behavior, the SENDME protocol means
that each circuit can queue up to 1000 cells at an overloaded bottleneck
Tor router, which load balancing can help alleviate, but can't correct
in transient and degenerate cases. This is why high capacity Exits have
obscene memory requirements when Exits are scarce (ie: below ~1/3 total
network throughput), despite there being no memory leaks.

This also tells us that Tor relays *cannot* scale to support larger
numbers of users without a corresponding linear increase in memory
requirements.

As a side effect of this protocol, it is possible for the client and the
Exit to compute the RTT of a circuit by measuring time between every
50th or 100th sent cell and the associated SENDME arrival. Some previous
work makes use of this to try to detect congestion, but it is not a
property we want to keep, if we can avoid it. No deployed code uses it,
and its presence is worrisome:
http://people.cs.ksu.edu/~eyv/papers/latency_leak-ccs07.pdf
https://www.robgjansen.com/publications/howlow-pets2013.pdf

To further complicate things, these SENDME windows only apply to
end-to-end data cells on the circuit. Tor also supports other non-data
end-to-end cells, as well as non-end-to-end data cells (so-called "leaky
pipe topology", which is used for circuit padding), which are not
counted against SENDME windows. Both of these details have also caused
us problems in the SENDME design. Still, for now, we will ignore both of
these details. Full proposal treatment will need to consider them, though.


I. Vaporwaving to ghosts in the anonymity graveyard

Ok, so let's party like it's 2010 and go chase some ghosts of past
anonymity literature and lore.

In my review of this area, I have identified the following causes of
death for previous congestion control attempts in Tor:
  * Side channels and other anonymity risks
  * Slow or limited responsiveness to queue pressure
  * Poor fairness properties
  * Poor throughput
  * Lack of stream flow control
  * Endpoint fairness cheating ability
  * Deployment costs


Ghost 1: Drop Signaling
Cause of Death: Side channel issues; deployment cost

Early proposals for congestion control for Tor attempted to simply
tunnel OS TCP streams. This uses the OS's native implementation of TCP
Slow Start and AIMD as congestion control methods. These attempts all
quickly died, due to OS TCP stack fingerprinting problems (ie: nmap):
https://murdoch.is/papers/tor11datagramcomparison.pdf

Two years ago, I tried to make the case for using QUIC as a drop-in
replacement for Tor circuits, and use QUIC's streams to carry Tor
streams. Such a network could leverage QUIC's TCP-like drop-signaled
congestion control algorithm internally, and terminate QUIC at the Exit
node, transforming the QUIC streams into TCP connections initiated from
the Exit. This avoids the TCP fingerprinting issues. In fact, even
without a full datagram network, Tor could still deploy relay-only drop
signaling if we added windowing and retransmission at the circuit layer:
https://lists.torproject.org/pipermail/tor-dev/2018-March/013026.html

Unfortunately, the present/absent bit vector of missing packets in this
window is a communication channel between malicious Tor relays or
Internet routers and the Exit node. This effect was an obscure piece of
ancient mix network lore until Nick Mathewson publicly documented it on
tor-dev a little over a year ago:
https://lists.torproject.org/pipermail/tor-dev/2018-November/013562.html

I was the voice of optimism in that grim post, but there is not a lot of
hope to be had. It still seems to me that adding cover traffic will
reduce the bandwidth of this side channel, but it is a deeply unsolved
traffic analysis problem to quantify the level of cover traffic needed,
on top of the engineering expense of protocol and cryptographic
revamping needed to support cell drops at intermediate relays.

It may also be possible to add a MAC scheme that prevents excessive
drops by intermediate relays and/or internet routers, but then we may
lose a lot of congestion signaling capability and responsiveness.

Aside: This drop side channel is much worse for VPN systems that blindly
tunnel OS-level TCP. Intermediate Internet routers between the VPN
client and the VPN server can use this side channel to send information
to any Internet router after the VPN server, via exposed TCP sequence
numbers. In a Tor-like system with Exit stream termination, the Exit
relay must be one of the side channel participants.

For more fun VPN TCP side channels, see also
https://seclists.org/oss-sec/2019/q4/122 and
https://tools.ietf.org/html/rfc6040.


Ghost 2: Datagram Tor with uTP/LEDBAT Signaling
Cause of Death: Responsiveness; fairness/cheating; side channels

uTP/LEDBAT is the bittorrent transport that measures the RTT of a
connection, and backs off if high latency is detected. The theory is
that latency above the maximum acceptable value (100ms by spec)
indicates that router queues have formed, due to competing traffic
causing a bottleneck. Typically these queues form at poor-quality
consumer edge routers that queue way too much for their link capacity
and user counts.

https://tools.ietf.org/html/rfc6817
https://research.torproject.org/techreports/libutp-2013-10-30.pdf

Because LEDBAT's goal is to use the link fully, and yield capacity in
presence of competing traffic, LEDBAT congestion control requires that
target latency upper bounds be known, and also expects some queuing to
occur to cause this latency. If network drops still occur, it also uses
TCP-like behavior, with similar side channel issues for our usecase. If
inherent path latency ever exceeds the LEDBAT target max, throughput
will plummet to near-zero. This is bad for Tor, as our path latency is
highly variable, especially between 7 hop onion circuits vs 3 hop exit
circuits.

Additionally, malicious LEDBAT clients can cheat by tolerating a
*larger* max delay than other clients. They will thus accept larger
queue sizes, which allow larger windows, which allow marginally better
throughput, at the expense of more congestion latency for everyone.


Ghost 3: Congestion Aware Tor
Cause of Death: Hazy anonymity analysis; responsiveness; throughput

Congestion Aware Tor uses more detailed per-node latency estimates
to measure transient congestion-induced delay and respond to it by
altering path selection:
https://www.cypherpunks.ca/~iang/pubs/Congestion_Aware_FC12.pdf

The downside of Congestion Aware Tor is that rather than managing the
congestion window, it suggests simply migrating circuits and changing
path weights. This has hazy effects on anonymity, as the set of viable
paths in the network is reduced by some hard-to-predict amount. Our
Circuit Build Timeout code (CBT) is able to do this kind of path pruning
in a significantly more precise manner by setting the circuit timeout
such that nearly exactly 80% of all possible network paths are used, but
it does not continually perform this timing measurement once the circuit
is built.

We could build a hybrid system with CBT-style math, with continual
measurements, with circuit migration, and with conflux multipath, but
this will still require retransmission buffers for reliable circuit
migration, will be slower to respond than true window control, and can't
actually cap congestion. Worse, circuit migration won't reduce
congestion at Exit nodes (you have to keep the same Exit or streams will
die).

Even with these changes, it also will not remove the throughput cap, or
improve onion service throughput.


Ghost 4: N23 Tor (aka DefenestraTor)
Cause of Death: Stream control; side channels; poor throughput

N23 Tor is described in Section 4.2 of the DefenestraTor paper:
https://cseweb.ucsd.edu/~savage/papers/PETS11.pdf

Basically, each router limits queue length for each circuit to N2 + N3,
which are consensus and circuit parameters, respectively. N3 is tuned
per circuit by latency measures similar to Congestion Aware Tor, but is
still capped at 500 per circuit.

This system died primarily because we could not figure out how to bolt
stream flow control back on to it. But that is a solvable problem (and
any circuit-level congestion control system we deploy must solve it):
https://lists.torproject.org/pipermail/tor-dev/2012-November/004138.html
https://lists.torproject.org/pipermail/tor-dev/2012-November/004143.html

I was not involved in the evaluation of N23 because I was designing and
building Tor Browser at the time, but upon diving into it now, I have
many additional concerns.

First: Because queues are per-circuit but backpressure is
per-connection, the backpressure suffers from multiplexing information
leak issues. If a circuit manages to fill its N23 limit, the only way
for the system to have backpressure to enforce N23 queue sizes is to
stop reading entirely on that circuit's upstream TCP connection,
stalling *all* other circuits on *only* that particular connection. This
property is extremely worrisome from an anonymity standpoint, as it
gives a client adversary a mechanism to experimentally stall pairwise
router connections to probe for the path taken by a long-lived active
target circuit (such as an onion service intro point).

Second: It's not clear to me how credits are sent in both directions on
a circuit, so that the congestion control can be applied in both
directions. Does anyone remember? (Does anyone care?)

Third: At the end of the day, the system still has total queue lengths
that scale in proportion to the number of circuits on the relay, rather
than being globally fixed and controlled through fairness properties. In
my view, this is the final nail in the coffin: it's not an improvement
for scalability, actually decreases throughput (due to the new lower
window cap), and can't control congestion enough to reduce the long-tail
latency.

Indeed, the perf CDFs from the paper show all of these effects, if you
look closely.


Ghost 5: RTT Tor [BOOTLEG_RTT_TOR]
Cause of Death: Sender cheating; Small max window size

Buried in the Defenestrator paper is an unnamed system that uses RTT to
estimate congestion and update windows accordingly, much like LEDBAT. It
is described in Section 4.1 of
https://cseweb.ucsd.edu/~savage/papers/PETS11.pdf

I'm going to call this system RTT Tor. RTT Tor works by tracking the min
and max RTT observed on a circuit, using the SENDME cell counting side
effect. It then picks a threshold timeout T, at a tuneable point in
between the min and max observed RTT. If the most recently measured RTT
exceeds T, the circuit is declared congested. Unlike LEDBAT, because RTT
Tor dynamically chooses T rather than using a hardcoded target RTT, it
is possible to use on Tor.

The window starts at 100 cells. So long as the RTT stays below T, the
window grows by an additional 100 cells every SENDME. If the RTT exceeds
T, the window is cut in half.

Window size max is capped at 1000 cells. The window cannot go below 100
cells.

This system depends upon the Exit node's ability to measure RTT to the
client in order to have a downstream window. This capability has been
shown to impact client anonymity:
http://people.cs.ksu.edu/~eyv/papers/latency_leak-ccs07.pdf
https://www.robgjansen.com/publications/howlow-pets2013.pdf

Furthermore, endpoints can cheat by choosing a higher T value or
otherwise acting as if their window size is increasing when it is not.
However, while the paper does not describe a solution for such cheating,
it is possible to detect if one endpoint is honest. Because both
endpoints can measure the RTT, both endpoints can track what their
peer's window should be growing to based on this algorithm, and compare
that to an estimate of their peer's window size. The peer's window size
can be estimated by counting the number of cells that arrive in RTT/2
amount of time.

If the RTT is asymmetric or highly variable, this detection mechanism
will have false positives, but we can at least reduce the ability and
incentive to cheat so long as one of the endpoints is honest.

But if both endpoints cheat, intermediate routers have no way of
limiting the data that is in flight or can queue up, except for closing
the circuit through the circuit OOM killer.

Hence the system still must impose a safe cell window max. It must also
impose this max size because some circuits may have an RTT_min that is
not much different from the RTT_max, even though the circuit is very
congested (because it is continually very congested). In this scenario,
the system would keep adding more congestion until the circuit OOM
killer kicks in.

But, as far as options go, this is not a bad one. Plus, it only requires
the client and the Exit to support it.


II. Fresh Remixes and New Ideas

So what if we took some hits from the 90s and remixed their hooks, Tor
style?

Let's start with the simplest, most TCP-like scheme we can come up with,
and then discuss potential variants and improvements to them, and see
which of these ideas mix together well.


Remix 1: Forward ECN [FORWARD_ECN_TOR]

What if we tried to make something as close to TCP ECN as possible for Tor?

Let's use an initial window size of 100 cells, and make our SENDMEs into
100 cell ACKs.

Let's create a RELAY_COMMAND_QUEUE_PRESSURE relay cell command that can
be sent by a relay towards a client whenever the sum total of queued
cells exceeds some limit. Which circuit gets the cell can be chosen by
EWMA or some other QoS algorithm (ie: RED-like weighted random choice,
as per TCP ECN). The cell would indicate the direction that the circuit
was loudest on (ie: client-bound or exit-bound). When the client gets
the cell, if the direction is exit-bound, the client halves its outbound
window. If the direction is client-bound, the client sends the cell back
to the Exit node, who then halves its client-bound SENDME send window.

(Recall that Tor's "relay commands" are encrypted to/from the client,
with Tor's per-hop circuit keys. This means that extra relay cells can
be injected by any hop in the circuit towards the client, and
intermediate relays cannot read these cells' relay commands. As we will
soon see in [BACKWARD_ECN_TOR] and related ideas, using cleartext "cell
commands" instead can help make things more efficient by allowing
signaling of congestion without requiring extra cell injection, but this
also introduces more side channel risk).

We can use Slow Start with AIMD here: Before the first
RELAY_COMMAND_QUEUE_PRESSURE, outbound windows would double every
window. After the first RELAY_COMMAND_QUEUE_PRESSURE, they would
increase by say 100, every window. Or something similar.

To reduce the potential for side channel injection, the client can
ensure that RELAY_COMMAND_QUEUE_PRESSURE do not arrive more often than
once per window. To prevent patterns from trivially being encoded on
these cells, the client can delay relaying them until they are on a K %
M == 0 boundary, for M=5 or 10 or so (high M will reduce responsiveness
to congestion). The client can also refuse to relay these cells if they
would cause the Exit's window to drop below some minimum size (say 128).

Intuition tells me the relays should use total outbound queue size for
deciding *when* to send these cells, and use specific circuit queue
length and/or activity to decide *which* circuit to send them on. In
this way, we globally limit queue size (per hop latency) regardless of
the number of circuits, and still enforce fairness among these circuits.
However, picking parameters and algorithms for all of this is a research
problem, or at least requires much more QoS RFC and research literature
review. There may be additional optimizations too, like sending these
cells on circuits of any TCP connection that starts blocking or
exceeding per-connection queue limits.

While this will work if clients are well-behaved, this system has a few
drawbacks.

First, it will be slow to respond to client-induced download congestion
at middle nodes, since we have to wait a full circuit RTT for the client
to relay cells to the Exit. Since the Exit is responsible for the
download window for web-like clients, this is also the direction that
needs the most congestion control, which is unfortunate.

Second, clients can easily cheat, even by malfunction: all they have to
do is refuse or forget to relay cells to an Exit, and they get faster
downloads at the expense of more network congestion for everyone. We
could do what RTT Tor did and cap the window size at 1000, but then
we're back in the situation where throughput is artificially capped at
some bizarre function of circuit RTT, and worst-case latency will not
improve as much as we want. We could rely more heavily on the circuit
OOM killer, and kill circuits that queue too much on the assumption that
they are cheating/malfunctioning, but tuning this to avoid false
positives may be tricky.

Third, while this system could technically be deployed even if some
nodes do not support it yet, this is risky, as nodes who do not support
it will experience excessive congestion at worst, and no improvement at
best.

Fourth, onion services are tricky to handle. Because of the way
rendezvous circuits are joined, this system will send
RELAY_COMMAND_QUEUE_PRESSURE towards the client for the client-side of
the rend circuit, and towards the service for the service end of the
circuit. Then, either of these sides would echo that signal as a
RELAY_COMMAND_QUEUE_PRESSURE *all* the way to the other side. Either or
both could cheat in this case, and again, the only recourse we have is
for each relay to enforce strict circuit queue length limits via the
circuit OOM killer.


Remix 2: Forward ECN mixed with RTT Tor [FORWARD_ECN_RTT_TOR]
[PROPOSAL_CANDIDATE]

Ok, [FORWARD_ECN_TOR] sounds decent, but because the client mediates
everything, it will be slow to respond to client-destined download
congestion, and clients can cheat. Also, if some relays don't support
the signal yet, the window may become too large for their congested status.

What if we *also* mix in [BOOTLEG_RTT_TOR], so that an endpoint's send
window can only grow if *both* conditions hold: the measured circuit RTT
stays below RTT Tor's T threshold, *and* there are no congestion signals
coming from [FORWARD_ECN_TOR]?

The addition of the signaling cell from [FORWARD_ECN_TOR] also allows us
to be more robust in the cheating detection described in
[BOOTLEG_RTT_TOR], and eliminate false positives. If either endpoint
detects a window that is growing too large for their measured circuit
RTT (by counting the number of cells arriving in that RTT, and comparing
that to what the window should be based on the RTT window growth
algorithm), it can send a warning shot RELAY_COMMAND_QUEUE_PRESSURE,
explicitly telling the cheater to back off. If the window still grows
because the other endpoint ignores this warning shot, it can close the
circuit.

This system is fully incrementally deployable: it can be used if only
the client and Exit support it. It is resilient to cheating so long as
Exits are honest, without false positives, and even without intermediate
relay support.

While we still aren't doing better than 1 RTT response to congestion, we
now have a good answer for cheating that doesn't have any false positive
risk for good actors. Furthermore, because we also have explicit
congestion signaling, we no longer have to worry as much about imposing
a max window size, to protect circuits for which RTT_min is close to
RTT_max due to persistent congestion. Good actors on these circuits will
back off, and for actors acting badly enough to add additional
congestion, RTT_max will increase enough for them to eventually be detected.

Downside: Since onion services have no Exit node, if we want to use the
RTT mechanism to mitigate cheating for them, we must terminate
congestion control at the Rendezvous point for this proposal idea, so
that onion service clients and services can't collude to get faster
service. The RP would then be responsible for examining each half of the
spliced circuit's congestion windows, and sending ECN signals down
whichever side had a larger window. This may or may not be worth the
additional complexity, as opposed to just employing the circuit OOM
killer if circuit queues get too long (due to cheating).

The only remaining downside I see is that we are relying on baking the
ability to make RTT measurements into the protocol.

Still, I think this is worth turning into its own proposal. Does anyone
see any other issues, or have any suggestions?


Remix 3: Backward ECN [BACKWARD_ECN_TOR]

Ok so the [FORWARD_ECN_RTT_TOR] mix is pretty tight. We've got an
incrementally deployable system that is somewhat resistant to cheaters,
and responds to congestion within an RTT. Can we do better? Yes.
Remember that Backward ECN IETF draft that we covered in [TCP_HISTORY]
earlier? It had that RTT/2 response with a hyphy hook. Let's sample that.

First: just like the other proposals, we still need to use SENDMEs, to
ack received packets. However, since we are not measuring RTT here, it
does not have to be exactly every 100 cells. The SENDME can be sent at a
randomized cell count to obscure RTT, with a different randomized ack
cell count value included in the SENDME.

In addition to RELAY_COMMAND_QUEUE_PRESSURE, which is sent to the client
and can't be read by any other intermediate relays, let's make a new
*cell* command type, CELL_COMMAND_RELAY_QUEUE_PRESSURE. Because this is
a cell command, it can be read by intermediate relays, and can be set by
an intermediate relay on any cell heading towards the Exit, simply by
flipping cell_t.command from CELL_COMMAND_RELAY to
CELL_COMMAND_RELAY_QUEUE_PRESSURE, so long as all relays in the circuit
understand this new command. This also avoids sending any additional
empty cells when congestion occurs in the common Web download direction,
which is nice.

We should still respond to congestion with Slow Start AIMD: when the
client or exit gets this relay cell or cell command, it cuts its send
window in half in that direction. Otherwise windows grow during
transmission similar to TCP (ie double the window size each window until
the first congestion cell, then linear).

The downside of these cells being a new end-to-end cell_t.command is
that it opens up side channel attacks we saw with the RELAY_EARLY attack:
https://blog.torproject.org/tor-security-advisory-relay-early-traffic-confirmation-attack

The attack is to flip this cell_t.command field on a sequence of cells
to encode a bitstring, to enable the Exit to send data to the Guard. So
in this mix, let's still use RELAY_COMMAND_QUEUE_PRESSURE towards the
client. We will only use the relay-visible cell_t.command
CELL_COMMAND_RELAY_QUEUE_PRESSURE towards the Exit. This means we only
need to worry about Guard to Exit side channels, which require much more
information to be useful (ie: they must encode client IP address or some
other unique client identifier).

Note that because all intermediate relays can see the cell_t.command,
they can enforce similar properties as clients did in [FORWARD_ECN_TOR],
to limit side channels in the Guard to Exit direction. For instance,
they can ensure that these commands do not get sent more often than once
per window of client-bound incoming cells. They can also enforce that
the Exit-bound cell_t.command = CELL_COMMAND_RELAY_QUEUE_PRESSURE in the
outgoing direction is only set on K % M == 0 cell count boundaries, for
low M=5 or 10. Note that this K %  M spacing actually works better for
longer circuits, since there is more chance for other relays to flip the
congestion bit at each M spacing position, which damages the reliability
of the side channel signal.

When middle relays enforce that the window is not allowed to drop below
win_min=128, a malicious Guard can only inject
log2(win_size)-log2(win_min) of these cells in a burst. Once the middle
node detects that the window size would be below the legal minimum, it
knows either cheating is happening, or a side channel is being used. For
a typical win_size of ~8k (ie: 16X faster throughput than current Tor)
and a win_min=128, this detection will be triggered in ~6 properly
spaced fake CELL_COMMAND_RELAY_QUEUE_PRESSURE commands.

However, in the AIMD steady state for this side channel, a malicious
guard can attempt to keep the window size as close to win_min as
possible, without going below it. Since the window size grows linearly
after the first ECN signal, the guard gets to send an additional
CELL_COMMAND_RELAY_PRESSURE cell_t.command around once every win_min
client-bound incoming cells. So long as no other relay is also sending
congestion control signals, the guard can keep flipping bits roughly
this often (though the K % M == 0 requirement would restrict the
placement of these cells).

Downsides: Even just 6 bits of reliable information can be damaging if
target client anonymity sets are already small, and so long as
client-bound incoming cells keep arriving, there are still more
opportunities to flip the cell_t.commands from the Guard to the Exit.
The big question here is can these 6+ cell_t.command flips be turned
into a large side channel, despite K % M == 0 placement enforcement? And
can this side channel be made reliable? If so (and it seems likely that
this is so), then this whole idea needs revision (see
[EDGE_FORWARD_ECN_TOR] and [START_BACKWARD_ECN_TOR] for possible revisions).

We also need all intermediate relays to upgrade to properly forward the
CELL_COMMAND_RELAY_QUEUE_PRESSURE cell command just like
CELL_COMMAND_RELAY.  Also, clients can still cheat by ignoring the
encrypted RELAY_COMMAND_QUEUE_PRESSURE. On the plus side, clients who
cheat can at best get faster upload speeds. They cannot get faster
download speeds unless the Exits also decide to cheat.

Finally, the story for cheating onion service endpoints is similarly
complicated: Do we have the RP mediate, or fall back to the circuit OOM
killer yet again?


Remix 4: Backward ECN mixed with RTT Tor [BACKWARD_ECN_RTT_TOR]

If we really are worried about upload cheating, we can mix RTT Tor back
in, just like we did for [FORWARD_ECN_RTT_TOR], and use its cheating
detection. An endpoint that detects abnormally large window sizes (based
on arrival cell counts per RTT) could send the
RELAY_COMMAND_QUEUE_PRESSURE warning shot to reduce the window.

So now we have a system that responds in RTT/2 when supported by all
intermediate relays, and falls back to RTT response in the presence of
one cheater endpoint or lack of support by intermediate relays.

Unfortunately, this still has the side channel issues of
[BACKWARD_ECN_TOR], and so I have not tagged it as a proposal candidate.


Remix 5: Backward ECN with Transparent Trap [BACKWARD_ECN_TRAP_TOR]

Ok so the "SENDME ack exactly 100 cells" 2-step beat is getting a little
tired. Can we devise any ways to trap cheaters without having a
predicable RTT measurement baked into the protocol, and still respond to
congestion in RTT/2?

There is a way to defeat the wizard. But there be dragons in this trap
house, and they really want to soul bond using side channels while
everybody is watching. Hence I have not flagged this as a proposal
candidate. Plus, as these mixed metaphors and obscure references
suggest, this remix is very busy and  complicated. Still, let's consider
it because it may be useful to remix later.

Let's take [BACKWARD_ECN_TOR], and instead of using
RELAY_COMMAND_QUEUE_PRESSURE towards the client, let's use
cell_t.command=CELL_COMMAND_RELAY_QUEUE_PRESSURE in both directions.
This allows us to perform the same kinds of side channel and cheating
checks at the middle node in the Exit to Guard direction, and also
avoids sending any extra relay cells during congestion.

Just as in [BACKWARD_ECN_TOR], let's randomize the cell count at which
we send each SENDME, and include a different randomized ack count in the
SENDME, so that each endpoint can add cells back to the window for that
SENDME, but cannot compute RTT. Let's also still use Slow Start with
AIMD (double the window if there are no congestion signals, half the
window on congestion signals, and grow it linear after that).

However, this is still not sufficient to stop Exit to Guard side
channels! The Exit to Guard direction is different than the Guard to
Exit direction: relays can inject arbitrary amounts of full relay cells
for the client in the Guard direction, whereas they could not do so in
the Guard to Exit direction. In Tor (and other mixnets), this property
is called "leaky pipe topology", and is what allows us to send
RELAY_COMMAND_DROP padding cells from the middle relay to the client
(and vice-versa).

This means that the combination of these injected cells plus congestion
control can be used to encode a pattern from Exit to Guard, and subvert
the checks at the middle node, because relays can inject dummy cells
sent towards the client to meet the win_size and M spacing requirements.

The good news is that the client-side circuit padding system only allows
RELAY_COMMAND_DROP from a hop for which the client has negotiated a
padding machine. This means that Exit nodes cannot inject padding for
assistance in any side channel usage, regardless of the congestion
control scheme we choose.

The bad news is that vanilla Tor allows the presence of invalid
protocol-violating cells, and does not close the circuit for these
cases. Best case, it issues a log message. Worst case: it silently drops
them. Thankfully, the vanguards addon is designed such that any cell
that is not specifically marked as valid by Tor counts as a dropped
cell, after which the circuit will be closed. This is a fail-closed
defense. If new code is added for cell processing that forgets to flag
cells as properly processed by calling circuit_read_valid_data(), those
cells count as false positive dropped cells, rather than false
negatives. This impacts reliability, but has the advantage that we won't
shoot ourselves in the foot by adding new code that is too permissive
without noticing that this code simply does not work properly because
circuits get closed when it is exercised.

All this means we will need to port this defense into Tor itself,
though, or dummy cells can be injected by the Exit for side channel
assistance in congestion control schemes or other cases:
https://github.com/mikeperry-tor/vanguards/blob/master/README_TECHNICAL.md#the-bandguards-subsystem

But what about legit padding causing the Guard to think that win_size
and M spacing requirement are violated? Well, so long as any relay with
an active padding machine stores the congestion signals so that it can
delay them such that they are sent on the next K % M == 0 boundary after
padding is applied, these limits can still be enforced, without
revealing the quantity of padding. Additionally, any guard node
congestion caused by the sum of real+padding traffic can be controlled
under this scheme, because the middle relay can observe the guard's
congestion signals and decrease padding approperiately.

Downsides: If preventing *any* side channel bits from flowing from the
Exit to the Guard is important, this scheme likely does not accomplish
that. It does seem that Exit to Guard side channels are far more
dangerous than Guard to Exit, since all the Exit has to say is "hey this
client looked at something I think is interesting", where as the Guard
has to communicate a unique identifier for the anonymity set, so that
concern alone may kill this idea.

This scheme is also complicated, and any implementation errors will
bring back the RELAY_EARLY side channel attack in the Exit to Guard
direction, even if the math might claim otherwise.


Remix 6: Edge-Forward ECN [EDGE_FORWARD_ECN_TOR]
[PROPOSAL_CANDIDATE]

The common problem with both [BACKWARD_ECN_TOR] and
[BACKWARD_ECN_TRAP_TOR] is that they enable side channels by one or both
of the edges of the circuit (Guard to Exit, or Exit to Guard).

Forward ECN mitigates these side channels, because the edge no longer
gets to encode its congestion signal at specific points in a traffic
pattern. This works better than win_size and M position limiting by
itself, and it can be used in combination with client-side window size
checks and M position limiting, too.

If middle nodes could somehow reliably detect the Guard and Exit
endpoints of a circuit, then the middle node(s) could force one or both
endpoints to use Forward ECN [FORWARD_ECN_TOR]. Then the circuit edges
would not be able to communicate with each other by directly encoding
congestion signals in deterministic traffic patterns.

This is easier said than done. In practice, middles can tell that they
are middles because they do not get any authentication cells from the
client, and they are not asked to open any streams. But what we really
need is for middles to be able to tell if their *neighbors* are the
circuit edges, because these edges are the only ones that we actually
need to forbid from using cell_t.command from BACKWARD_ECN_TOR; it is
fine if multiple middles use cell_t.command (for example, in onion
service circuits).

The only way I can think of to reliably detect circuit edges from the
middle position is to forbid either Exits or Guards nodes from being
used as middles, so that middles could know when they were next to one
of these node types, and therefore next to the edge of the circuit. Then
middles could forbid these edges' use of the cleartext
CELL_COMMAND_RELAY_QUEUE_PRESSURE. This only-middles-as-middles
stratification requirement has been proposed before for several other
reasons, so maybe it is not a horrible idea?

This is more tricky for onion service circuits, though. For those, we
could require that sensitive positions (such as HSDIR, RP, and IP) also
be Exit-flagged nodes?

Or maybe there is another clever way to detect just the edges of a
circuit from the middle position?

Even if there is, this proposal still has some cheating risk, as clients
can refuse to relay these edge congestion signals to get marginally
better throughput. Again, RTT measurements can be preserved here as a
backstop against cheating, but for the additional anonymity risk.
Otherwise we have to fall back to the circuit OOM killer.


Remix 7: Start Backward ECN [START_BACKWARD_ECN_TOR]
[PROPOSAL_CANDIDATE]

The Slow Start with AIMD window management for all of these systems
means that we most need the quick RTT/2 response to the congestion early
on in the Slow Start phase, while the window size is growing
exponentially. This is also when the network is most vulnerable to cheaters.

So let's allow only 1 (or maybe 2) CELL_COMMAND_RELAY_QUEUE_PRESSURE
cell_t.commands per circuit in the Guard to Exit direction as per
[BACKWARD_ECN_TOR], and maybe even 1 CELL_COMMAND_RELAY_QUEUE_PRESSURE
cell_t.command in the Exit to Guard direction from
[BACKWARD_ECN_TRAP_TOR]. After these cell_t.command limits are hit,
middle nodes forbid any further use of this cell type on that circuit,
and enforce that all circuit member relays switch to [FORWARD_ECN_TOR]
or [FORWARD_ECN_RTT_TOR] from then on (depending on how concerned we are
about cheating vs disclosing circuit RTT).

This is my all-around favorite of the options. The only downside is that
we have to choose between disclosing RTT, or risking some cheating, but
since the cheating can now only happen after slow start has finished, it
will provide less speed advantages. If clients cheat with the goal of
causing memory exhaustion at relays, the circuit OOM killer can kick in.


Remix 8: Your idea here!

Anyone have any other old lore to resurrect? Any new ideas?


Bonus B-Side Track: Stream Flow Control [PROPOSAL_CANDIDATE]

All of the systems discussed in this post address the problem of
circuit-level congestion control, but do not perform any stream-level
flow control. While we were prototyping N23, Andreas Krey pointed out
that a single blocked stream could consume the entire circuit window
with unread packets, causing the surprising result that other active
streams on the same circuit will also stall:
https://lists.torproject.org/pipermail/tor-dev/2012-November/004138.html

He then went on to propose some alternatives: XON/XOFF, bundling stream
window updates in circuit SENDMEs, or just killing any blocked streams
that have too many unread cells:
https://lists.torproject.org/pipermail/tor-dev/2012-November/004143.html

XON/XOFF is the simplest option, but we will need heuristics to avoid
excessive XON/XOFF chatter on application streams that frequently block
in normal operation. It also will have RTT/2 delay before it actually
causes the other end to stop sending. If the blocked stream is sending
cells at the full bandwidth of the circuit, this could very well be a
full circuit window worth of cells before the XOFF makes it across.

We can just ack those cells with a circuit-level SENDME even though they
were not delivered to their blocked stream, but we have to be careful to
authenticate what we read in this case, so we do not re-introduce the
unauthenticated SENDME attack:
https://gitweb.torproject.org/torspec.git/tree/proposals/289-authenticated-sendmes.txt

Can we learn anything from the layered flow control in QUIC? It is
excessively complicated:
https://docs.google.com/document/d/1F2YfdDXKpy20WVKJueEf4abn_LVZHhMUMS5gX6Pgjl4/edit


III. Evaluation

First, does anyone have any strong objections to any of the remixes
tagged with PROPOSAL_CANDIDATE? It will save time if we can decide right
from the start that any are completely unacceptable. Bonus points if we
can mod them back into being acceptable, or mod one of the remixes that
are not tagged with PROPOSAL_CANDIDATE into being acceptable.

We also need some criteria to help us determine how we're going to
compare the remaining ones. Here is a condensed [TRACK_LISTING], for
quick review/comparison and criteria brainstorming:
______________________________________________________________________
|        MIX           | CHEATING  | RESPONSE|     SIDE   |  UPGRADE |
|       TRACK          | DETECTION |   TIME  |   CHANNELS |   PATH?  |
|~~~~~~~~~~~~~~~~~~~~~~|~~~~~~~~~~~|~~~~~~~~~|~~~~~~~~~~~~|~~~~~~~~~~|
|BOOTLEG_RTT_TOR       | Exit RTT  |100c+RTT |     RTT    |   Exits  |
|FORWARD_ECN_TOR       | Circ OOM  |   RTT   |    None?   | Full Net |
|FORWARD_ECN_RTT_TOR   | Exit RTT  |   RTT   |     RTT    |Exits;Full|
|BACKWARD_ECN_TOR      |Middles;OOM|  RTT/2  | Guard-&gt;Exit| Full Net |
|BACKWARD_ECN_RTT_TOR  |Middles;RTT|RTT/2;RTT| Guard-&gt;Exit|Exits;Full|
|BACKWARD_ECN_TRAP_TOR |  Middles  |  RTT/2  |Guard&lt;-&gt;Exit| Full Net |
|EDGE_FORWARD_ECN_TOR  |Middles;OOM| 2*RTT/3 |    None?   | Full Net |
|START_BACKWARD_ECN_TOR|Middles;OOM|RTT/2;RTT|  Low/None? | Full Net |
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

What are the things we need to decide if a scheme is acceptable? Here's
a laundry list. Please do add any others you think of:
  - Side channel accounting
  - Interaction with non-data traffic, padding traffic, and leaky-pipes
  - Anonymity analysis as per
    https://www.robgjansen.com/publications/howlow-pets2013.pdf
  - No/minimal cheating
  - No throughput cap
  - Quick responsiveness (at least RTT; RTT/2 is better)
  - Fairness analysis (may be a separate proposal on QoS/EWMA)
  - Onion service deployment
  - Simulation methodology that will reflects live deployment
  - Deployment costs
  - Upgrade path


Must-Read References:

Cultural etymology of Tor's end-of-decade donations campaign aesthetic:
https://en.wikipedia.org/wiki/Vaporwave
https://blog.torproject.org/better-internet-possible-ive-seen-it

Tor congestion latency is proportional to network utilization divided by
spare_capacity:
Section 6.3 of https://www.freehaven.net/anonbib/cache/murdoch-pet2008.pdf

RTT-based Congestion Control for Tor:
Section 4.1 of https://cseweb.ucsd.edu/~savage/papers/PETS11.pdf

TCP ECN: https://tools.ietf.org/html/rfc3168#section-6.1

Backward ECN: https://tools.ietf.org/html/draft-salim-jhsbnns-ecn-00

Stream Flow Control Issues and Ideas:
https://lists.torproject.org/pipermail/tor-dev/2012-November/004138.html
https://lists.torproject.org/pipermail/tor-dev/2012-November/004143.html

Side channels in circ command cells:
https://blog.torproject.org/tor-security-advisory-relay-early-traffic-confirmation-attack



-- 
Mike Perry


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20200130220851</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-01-30 22:08:51-0400</timestampReceived><subject>Re: [tor-dev] Proposal 312: Automatic Relay IPv6 Addresses</subject><body>

On Wed, Jan 29, 2020 at 9:04 AM teor &lt;teor@riseup.net&gt; wrote:

Hello again!  This looks like another fine proposal.  I'm leaving
comments inline, and clipping sections that I'm not commenting on.


&gt;
&gt; Filename: 312-relay-auto-ipv6-addr.txt
&gt; Title: Tor Relays Automatically Find Their IPv6 Address
&gt; Author: teor
&gt; Created: 28-January-2020
&gt; Status: Draft
&gt; Ticket: #33073
&gt;
&gt; 0. Abstract
&gt;
&gt;    We propose that Tor relays (and bridges) should automatically find their
&gt;    IPv6 address, and use it to publish an IPv6 ORPort. For some relays to find
&gt;    their IPv6 address, they may need to fetch some directory documents from
&gt;    directory authorities over IPv6. (For anonymity reasons, bridges are unable
&gt;    to fetch directory documents over IPv6, until clients start to do so.)
&gt;
&gt; 1. Introduction
&gt;
&gt;    Tor relays (and bridges) currently find their IPv4 address, and use it as
&gt;    their ORPort and DirPort address when publishing their descriptor. But
&gt;    relays and bridges do not automatically find their IPv6 address.

At the beginning of this document, we should be a bit more clear about
which address specifically we're trying to find.  If we wanted _some_
address, or if NAT and firewalls didn't exist, we could just open a
socket, call getsockname(), and be done with it.  What we are looking
for specifically is an address that we can advertise to the rest of
the world in our server descriptor.  [I know you know this, but we
should say so.]


 [...]
&gt; 3. Finding Relay IPv6 Addresses
&gt;
&gt;    We propose that tor relays (and bridges) automatically find their IPv6
&gt;    address, and use it to publish an IPv6 ORPort.
&gt;
&gt;    For some relays to find their IPv6 address, they may need to fetch some
&gt;    directory documents from directory authorities over IPv6. (For anonymity
&gt;    reasons, bridges are unable to fetch directory documents over IPv6, until
&gt;    clients start to do so.)
&gt;
&gt; 3.1. Current Relay IPv4 Address Implementation
&gt;
&gt;    Currently, all relays (and bridges) must have an IPv4 address. IPv6
&gt;    addresses are optional for relays.
&gt;
&gt;    Tor currently tries to find relay IPv4 addresses in this order:
&gt;      1. the Address torrc option
&gt;      2. the address of the hostname (resolved using DNS, if needed)
&gt;      3. a local interface address
&gt;         (by making a self-connected socket, if needed)
&gt;      4. an address reported by a directory server (using X-Your-Address-Is)

Any server, or only an authority?  Over any connection, or only an
authenticated one?

 [...]
&gt; 3.2. Finding Relay IPv6 Addresses
&gt;
&gt;    We propose that relays (and bridges) try to find their IPv6 address. For
&gt;    consistency, we also propose to change the address resolution order for
&gt;    IPv4 addresses.
&gt;
&gt;    We use the following general principles to choose the order of IP address
&gt;    methods:
&gt;      * Explicit is better than Implicit,
&gt;      * Local Information is better than a Remote Dependency,
&gt;      * Trusted is better than Untrusted, and
&gt;      * Reliable is better than Unreliable.
&gt;    Within these constraints, we try to find the simplest working design.

We should make sure to be clear about the impact of using an untrusted
source.  Anybody who can fool a relay about its IP can effectively
MITM that relay's incoming connections (traffic patterns only), so
using a non-trusted source can be risky for anonymity.

 [...]
&gt;    (Each of these address resolution steps is described in more detail, in its
&gt;    own subsection.)
&gt;
&gt;    While making these changes, we want to preserve tor's existing behaviour:
&gt;      * resolve Address using the local resolver, if needed,
&gt;      * ignore private addresses on public tor networks, and
&gt;      * when there are multiple valid addresses, choose the first or latest
&gt;        address, as appropriate.

Instead of "first or latest" I suggest "first-listed or most recently
received" here, to help non-native speakers.

&gt; 3.2.1. Make the Address torrc Option Support IPv6
 [...]
&gt;    It is an error to configure an Address option with a private IPv4 or IPv6
&gt;    address, or with a hostname that does not resolve to any publicly routable
&gt;    IPv4 or IPv6 addresses.

We should say "on a public network" here -- private addresses are fine
on private networks.

Also, this seems to mean that if the relay's DNS resolver goes down,
the relay should give an error and exit, even if it was already
running.  That seems undesired.

 [...]
&gt; 3.2.2. Use the Advertised ORPort IPv4 and IPv6 Addresses
&gt;
&gt;    Next, we propose that relays (and bridges) use the first advertised ORPort
&gt;    IPv4 and IPv6 addresses, as configured in their torrc.
&gt;
&gt;    The ORPort address may be a hostname. If it is, tor should try to use it to
&gt;    resolve an IPv4 and IPv6 address, and open ORPorts on the first available
&gt;    IPv4 and IPv6 address. Tor should respect the IPv4Only and IPv6Only port
&gt;    flags, if specified. (Tor currently resolves IPv4 addresses in ORPort
&gt;    lines. It may not look for an IPv6 address.)
&gt;
&gt;    Relays (and bridges) currently use the first advertised ORPort IPv6 address
&gt;    as their IPv6 address. We propose to use the first advertised IPv4 ORPort
&gt;    address in a similar way, for consistency.
&gt;
&gt;    Therefore, this change may affect existing relay IPv4 addressses. We expect
&gt;    that a small number of relays may change IPv4 address, from a guessed IPv4
&gt;    address, to their first advertised IPv4 ORPort address.
&gt;
&gt;    In rare cases, relays may have been using non-advertised ORPorts for their
&gt;    addresses. This change may also change their addresses.
&gt;
&gt;    We propose ignoring private configured ORPort addresses on public tor
&gt;    networks. (Binding to private ORPort addresses is supported, even on public
&gt;    tor networks, for relays that use NAT to reach the Internet.) If an ORPort
&gt;    address is private, address resolution should go to the next step.
&gt;
&gt; 3.2.3. Use the Advertised DirPort IPv4 Address
&gt;
&gt;    Next, we propose that relays use the first advertised DirPort IPv4 address,
&gt;    as configured in their torrc.

I think that we could omit this method; it seems unlikely to me that
anybody is going to configure an advertised DirPort address but not an
advertised ORPort address.   In the long run, I think we want DirPorts
to disappear entirely as part of our official protocol.


&gt; 3.2.4. Use Local Interface IPv6 Address
&gt;
&gt;    Next, we propose that relays (and bridges) use publicly routable addresses
&gt;    from the OS interface addresses or routing table, as their IPv4 and IPv6
&gt;    addresses.
&gt;
&gt;    Tor has local interface address resolution functions, which support most
&gt;    major OSes. Tor uses these functions to guess its IPv4 address. We propose
&gt;    using them to also guess tor's IPv6 address.
&gt;
&gt;    We also propose modifying the address resolution order, so interface
&gt;    addresses are used before the local hostname. This decision is based
&gt;    on our principles: interface addresses are local, trusted, and reliable;
&gt;    hostname lookups may be remote, untrusted, and unreliable.
&gt;
&gt;    Some developer documentation also recommends using interface addresses,
&gt;    rather than resolving the host's own hostname. For example, on recent
&gt;    versions of macOS, the man pages tell developers to use interface addresses
&gt;    (getifaddrs) rather than look up the host's own hostname (gethostname and
&gt;    getaddrinfo). Unfortunately, these man pages don't seem to be available
&gt;    online, except for short quotes (see [getaddrinfo man page] for the
&gt;    relevant quote).
&gt;
&gt;    If the local interface addresses are unavailable, tor opens a self-connected
&gt;    UDP socket to a publicly routable address, but doesn't actually send any
&gt;    packets. Instead, it uses the socket APIs to discover the interface address
&gt;    for the socket.

I don't understand in which sense this socket is  "self-connected" --
maybe "unused" or something?  Also I'd suggest that Tor should use an
authority's IP address for this purpose.  Currently, we use 18.0.0.1,
which tends to confuse people who are looking at their firewall's
warnings.

&gt;    Tor already ignores private IPv4 interface addresses on public relays.
&gt;    (Binding to private DirPort addresses is supported, for networks that use
&gt;    NAT.) We propose to also ignore private IPv6 interface addresses. If all
&gt;    IPv4 or IPv6 interface addresses are private, address resolution should go
&gt;    to the next step.
&gt;
&gt; 3.2.5. Use Own Hostname IPv6 Addresses
&gt;
&gt;    Next, we propose that relays (and bridges) get their local hostname, look
&gt;    up its addresses, and use them as its IPv4 and IPv6 addresses.
&gt;
&gt;    We propose to use the same underlying lookup functions to look up the IPv4
&gt;    and IPv6 addresses for:
&gt;      * the Address torrc option (see section 3.2.1), and
&gt;      * the local hostname.
&gt;    However, OS APIs typically only return a single hostname.
&gt;
&gt;    Even though the hostname lookup may use remote DNS, we propose to use it on
&gt;    directory authorities, to maintain compatibility with current
&gt;    configurations. Even if it is remote, we expect the configured DNS to be
&gt;    somewhat trusted by the operator.

Do you mean to say "directory authorities" here? I don't understand that part.

&gt;    The hostname lookup should ignore private addresses on public relays. If
&gt;    multiple IPv4 or IPv6 addresses are returned, the first public address from
&gt;    each family should be used. If all IPv4 or IPv6 hostname addresses are
&gt;    private, address resolution should go to the next step.


 [...]
&gt; 3.2.6. Use Directory Header IPv6 Addresses
&gt;
&gt;    Finally, we propose that relays get their IPv4 and IPv6 addresses from the
&gt;    X-Your-Address-Is HTTP header in tor directory documents. To support this
&gt;    change, we propose that relays start fetching directory documents over IPv4
&gt;    and IPv6.

Can we specify use of NETINFO cells additionally or instead?  Unlike
DirPort connections, ORPort connections are authenticated, so we know
who is telling us what our address is.

&gt;    We propose that bridges continue to only fetch directory documents over
&gt;    IPv4, because they try to imitate clients. (Most clients only fetch
&gt;    directory documents over IPv4, a few clients are configured to only fetch
&gt;    over IPv6.) When client behaviour changes to use both IPv4 and IPv6 for
&gt;    directory fetches, bridge behaviour can also change to match. (See
&gt;    section 3.4.1 and [Proposal 306: Client Auto IPv6 Connections].)
&gt;
&gt;    We propose that directory authorities should ignore addresses in directory
&gt;    headers. Allowing other authorities (or relays?) to change a directory
&gt;    authority's published IP address may lead to security issues. Instead,
&gt;    if interface and hostname lookups fail, tor should stop address resolution,
&gt;    and return a permanent error. (And issue a log to the operator, see below.)

I suggest that we simplify the whole directory authority logic and say
that authorities must have configured Address lines, or nothing.

[...]
&gt; 3.3. Consequential Tor Client Changes
&gt;
&gt;    We do not propose any required client address resolution changes at this
&gt;    time.
&gt;
&gt;    However, clients will use the updated address resolution functions to detect
&gt;    when they are on a new connection, and therefore need to rotate their TLS
&gt;    keys.

Do clients have meaningful TLS keys any more, now that they have
dropped client support for the v1 link protocol?

(This is just a side question -- clients should still have a working
ip_address_changed() function.)

 [...]
&gt; 3.5. Optional Efficiency and Reliability Changes
&gt;
&gt;    We propose some optional changes for efficiency and reliability, and
&gt;    describe their impact.
&gt;
&gt;    Some of these changes may be more appropriate in future releases, or
&gt;    along with other proposed features.
&gt;
&gt; 3.5.1. Only Use Authenticated Directory Header IPv4 and IPv6 Addresses
&gt;
&gt;    We propose this optional change, to improve relay address accuracy and
&gt;    reliability.

I am +1 here, with a proviso that we should be able to use NETINFO cells.

 [...]
&gt; 3.5.5. Add IPv6 Support to AuthDirMaxServersPerAddr
&gt;
&gt;    We propose this optional change, to improve the health of the network, by
&gt;    rejecting too many relays on the same IPv6 address.
&gt;
&gt;    Modify get_possible_sybil_list() so it takes an address family argument,
&gt;    and returns a list of IPv4 or IPv6 sybils.
&gt;
&gt;    Use the modified get_possible_sybil_list() to exclude relays from the
&gt;    authority's vote, if there are more than AuthDirMaxServersPerAddr on the
&gt;    same IPv4 or IPv6 address.
&gt;
&gt;    Since these relay exclusions happen at voting time, they do not require a
&gt;    new consensus method.

Since it's trivial for one host to have a staggering number of IPv6
addresses, should this specify a /80 or /96 or something as being
sybil-like?

 [...]
&gt; 3.5.7. Add IPv6 Support Using gethostbyname2()

I agree that this change should be unnecessary; I'd suggest that we
not do it and just require getaddrinfo() for meaningful IPv6
resolution.

Alternatively, we could use libevent's DNS.

&gt; 3.5.8. Change Relay OutboundBindAddress Defaults
&gt;
&gt;    We propose this optional change, to improve the reliability of
&gt;    IP address-based filters in tor.
&gt;
&gt;    For example, the tor network treats relay IP addresses differently when:
&gt;      * resisting denial of service, and
&gt;      * selecting canonical, long-term connections.
&gt;    (See [Ticket 33018: Dir auths using an unsustainable 400+ mbit/s] for the
&gt;    initial motivation for this change: resisting significant bandwidth load
&gt;    on directory authorities.)
&gt;
&gt;    Now that tor knows its own addresses, we propose that relays (and bridges)
&gt;    set their IPv4 and IPv6 OutboundBindAddress to these discovered addresses,
&gt;    by default. If binding fails, tor should fall back to an unbound socket.

I think this change might be unnecessary, but it shouldn't hurt.  I'd
suggest not prioritizing it very high.

 [...]

In general, this plan above looks solid.

I have a suggestion before we get into the implementation, though: I
think we should, for each check, make sure that we write down _when_
it happens, what makes it happen, and where we store the result.  That
is, some of these checks are things we need to launch (like looking up
our own hostname), whereas others will happen passively pretty often
(like connecting to a directory authority).  Of the ones that we need
to launch, some will happen only when other methods have failed,
whereas some will happen on startup.  Some are things that can time
out, whereas others aren't.  Writing this all down will make sure that
we aren't making our state machine more complex than it needs to be.

IMO, we should record the status of all possible IP lookup methods,
with "not yet tried" being a possible status: it will help us keep our
 implementation and our logging simple -- or at least, as simple as
can be.

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20200131163110</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2020-01-31 16:31:10-0400</timestampReceived><subject>[tor-dev] Request for onionbalance v3 pre-alpha testing</subject><body>

Hello list,

we've been developing Onionbalance v3 for the past months, and I'm
pretty hyped to say that the project has reached a stability point that
could benefit from some initial testing by curious and adventurous
developers and users.

The project is not yet ready for proper use in actual production environments
(more on this later), but my hope is that this testing will reveal bugs that I
can't catch in my test environment and receive user feedback that will speed up
the overall process and allow a faster and more stable initial release.

This email features a pretty complicated pseudo-guide that if it gets followed
to completion it will hopefully result in a functional onionbalance setup.

As I said the guide is complicated and in ugly text format, so I suggest you
put on some calming music (perhaps some Bill Evans or some Com Truise or some
Tor) and go slowly. Trying to speed run this will result in disappointment and
perhaps even partial or total loss of faith in humanity.

== So what's the current status of Onionbalance v3? ==

The project lives as a fork of Donncha's original Onionbalance project in this
repository: https://github.com/asn-d6/onionbalance

The current status is that during my testing I have onionbalanced a real v3
service with two backend instances successfully for a few days with no obvious
reachability issues. It also works on a private tor network (using Chutney) for
hours with no issues. All the above happened on Debian stable and testing.

Also, here are some features that are currently missing but will be
included in the initial launch:
- This new onionbalance will support both v2 and v3 onion services, altho
  currently v2 support is botched and only v3 will work for the purposes of
  this testing. If you can quickly revive v2 support patches are welcome!
- Any sort of documentation about v3 mode (this post is all the documentation there \
                is for now!)
- Missing streamlined setup process (installation scripts, packages or dependency \
                tracking)
- Code documentation and unittests missing
- There is no daemon mode. You will have to run this in screen for now
- Fun bugs included!

Furthermore, v2 and v3 support will not have feature parity at the time of the
initial launch, and we will have to incrementally build these features:
- Cool v2 features like DISTINCT_DESCRIPTORS are not yet implemented so v3
  cannot load balance as deeply as v3 yet (patches welcome!)
- There is no way to transfer your existing v3 onion service to onionbalance (patches \
                welcome!)
- There is no torrc generation for instances as in v2 (patches welcome!)
- It will be possible for clients and HSDirs to figure out whether a descriptor
  comes from an onionservice vs a regular v3 onion. Making them
  indistinguishable is possible but requires more engineering and will be left
  as a TODO for now (see #31857)

Finally, there is no guarantee that configs generated with this pre-alpha
version of Onionbalance will be forward compatible when we actually launch the
project. This means that if you setup onionbalance v3 right now, you might need
to re-set it up in a month or so when the actual release happens.

tl;dr This is a call for experimental testing and it's meant to help the
developers and accelerate development and not to be used in anything remotely
serious or close to production. The actual release for operators and users is
coming in a month or so.

== Before we get started... ==

OK so let's assume that you still want to help out!

Given that this is a pre-alpha test I'm gonna assume that you fill the
following prerequisites otherwise you are gonna have an adventure:

[ ] Comfortable with git
[ ] Familiar with v2 onionbalance (at least in terms of terminology and how it works)
[ ] Familiar with setting up and configuring (v3) onion services
[ ] Familiar with Linux (or in the mood to find weird bugs in other platforms)
[ ] Familiar with compiling C projects and chasing their dependencies
[ ] Familiar with running Python projects and chasing their dependencies
[ ] Patience to push through various import error messages that might appear

The above are not mandatory but if you don't check out all the boxes you might
encounter various errors and roadblocks that will frustrate. Actually... even
if you check out all these boxes you might encounter various errors that might
frustrate you.

== Some theory ==

In any case, if you want to learn more about the architecture of Onionbalance, see:
   https://blog.torproject.org/cooking-onions-finding-onionbalance

As part of this guide, you might hear me say the term "frontend" which is what
we call master onionbalance onion service instance (whose address clients type
on their browser), or the term "backend" which is the load balancing instances
that do the actual introduction/rendezvous work for the frontend. So for
example, in the visual below, Alice fetches the frontend's descriptor but does
the introduction/rendezvous with the backends:

================================================================================
+                                                                              +
+   			 Alice fetches frontend     +^^^^^^^^^^^^^^^^^^^^^^^^^^^^+     +
+     +~~~~~~~~~~+    descriptor     +~~~~~~+      HSDir hash ring       )     +
+     | Alice    +~~~~~~~~~~~~~~~~~~~+      +vvvvvvvvvvvv+vvvvvvvvvvvvvvv+     +
+     |          |                                       |                     +
+     |the client|      +-----------+                    |                     +
+     +~~~+~~~~~~+      |backend    |                    | Upload frontend     +
+         |             |instance 1 +-------+            |    descriptor       +
+         | 		    +-----------+       |            |                     +
+   	  | 		                        |    +-------+-----------+         +
+   	  | 		    +-----------+       +----+                   |         +
+   	  +~~~~~~~~~~~~~+backend    |            |     frontend      |         +
+   Alice does          |instance 2 +------------+     onionbalance  |         +
+   introduction        +-----------+       +----+     service       |         +
+   with backend                            |    +-------------------+         +
+   				    +-----------+       |                                  +
+   				    |backend    +-------+                                  +
+   				    |instance 3 |                                          +
+   				    +-----------+                                          +
+                                                                              +
================================================================================

OK enough with theory. Let's jump to practice:

== Installation instructions ==

For the purposes of this guide I will assume you have a frontend service and
a bunch of backend instances that you want to load balance.

==== Setup frontend service ====

Our first goal is to get onionbalance and Tor running on your frontend
service.

- Installing Tor

Let's start: SSH to your frontend service, and get yourself a Tor binary to use
as the control port for onionbalance. You will want a recent version of Tor
(above 0.4.2) but other than that there is no strict requirement. Feel free to
get it off your package manager or git.

Setup a minimal torrc with a control port enabled. As an example:
"""
SocksPort 0
ControlPort 127.0.0.1:6666
DataDirectory /home/user/frontend_data/
"""

Feel free to tweak your torrc as you feel (also enable logging), but for the
purposes of this guide I assume that your control port is at 127.0.0.1:6666.

- Running onionbalance for the first time

Now we need to run onionbalance and generate keys and a config file for
it. Here the fun starts:

Let's start by git cloning 'https://github.com/asn-d6/onionbalance'.

To run onionbalance v3 you are gonna need a bunch of fun Python dependencies
including (but perhaps not limited to):
- Python3 above 3.7
- Python3 packages for: pyyaml, pycrypto, setproctitle, future
- stem version 1.8 or up (so that it includes v3 support)

Please collect all the above whichever way you prefer: if you don't have them,
things are gonna crash at some point. There is no dependency tracking for v3
onionbalance right now (i.e. requirements.txt) so I don't enforce the above in
an elegant way.

Now that you are good to go with dependencies, feel free to install
onionbalance using the setup.py script, or you can run it from the source
directory if you prefer that.

Now is the time to create keys and a config file for your frontend
service. Let's do that by running the configuration wizard:

         $ python3 onionbalance-config.py

It should ask you if you want v3 or v2 (say v3!), and a bunch of other
questions and by the end you should have a config file somewhere (by default at
./config/master/config.yaml) and the corresponding frontend key file (again at
./config/master/*key). The onion address of your frontend service can be found
in the bottom of your config file. So if it says:
     key: wrxdvcaqpuzakbfww5sxs6r2uybczwijzfn2ezy2osaj7iox7kl7nhad.key
your onion address is \
"wrxdvcaqpuzakbfww5sxs6r2uybczwijzfn2ezy2osaj7iox7kl7nhad.onion" For now, note down \
the onion address of the frontend service and let's move on to the next step! Make \
sure you got a v3 onion address out of this process, otherwise something went wrong.

If you got to this stage without any major turbulance, you will end up with a
functional onionbalance in no time. If you had lots of problems so far, brew up
some green tea, because there is more fun coming!

==== Setup backend instances ====

OK now with the frontend onion address noted down, let's move to setting up
your backend instances:

SSH to one of your backend instances and let's setup Tor in there! The catch is
that onionbalance v3 backend instances need a very recent version of Tor
because of some issues in the v3 protocol (#32709).

As a matter of fact, the patch required has not yet been merged to upstream Tor
(it will be merged in mid February because we are currently at a code freeze)
so you will need to use my personal repository for now (as indicated by the
last comment in #32709).

So let's git clone 'https://github.com/asn-d6/tor.git' and checkout branch
'ticket32709_044_02'. Build that branch (using the classic './autogen.sh &amp;&amp;
./configure &amp;&amp; make' combo) and you should have a Tor binary at ./src/app/tor.
If this doesn't happen, you are gonna need to install various C dependencies
like libssl-dev, libevent-dev, etc.

Now you will need a torrc file for your backend instance. As in onionbalance
v2, the torrc file needs to setup an onion service (and in this case a v3
one). So far so good but here comes the twist:

1) In the end of your torrc file, inside the HiddenService block please add the
   following line: 'HiddenServiceOnionBalanceInstance 1'.

2) Now go in your hidden service directory where the hostname and
   hs_ed25519_public_key files are living (you will need to startup Tor once
   with the onion service enabled for the directory to get created) you need to
   create a new file with the name 'ob_config' that has the following line
   inside:
      'MasterOnionAddress \
wrxdvcaqpuzakbfww5sxs6r2uybczwijzfn2ezy2osaj7iox7kl7nhad.onion'  but substitute the \
onion address with your frontend's onion address.

The points (1) and (2) above are extremely important and if you didn't do them
correctly, nothing is gonna work. If you want to ensure that you did things
correctly, start up Tor, and check that your *info* log file includes the
following line:
     [info] ob_option_parse(): OnionBalance: MasterOnionAddress \
wrxdvcaqpuzakbfww5sxs6r2uybczwijzfn2ezy2osaj7iox7kl7nhad.onion registered

If you don't see that, then something went wrong. Please try again from the
beginning of this section till you make it! This is the hardest part of the
guide too, so if you can do that you can do anything (fwiw, we are at 75% of
the whole procedure right now).

After you get that, also make sure that your instances are directly reachable
(e.g. using Tor browser). If they are not reachable, then onionbalance won't be
able to see them either and things are not gonna work.

OK, you are done! Now do the same for the other backend instances and note down
the onion addresses of your backend instances because we are gonna need them
for the next and final step.

==== Get it running! ====

OK now let's login back to the frontend server! Go to your onionbalance config
and add your instance addresses in the right fields. In the end it should look
like this (for a setup with 4 backend instances):

"""
services:
- instances:
  - address: 4a2zwxetkje5lwvahfv75arzrctn6bznkwmosvfyobmyv2fc3idbpwyd.onion
    name: node1
  - address: i5aqar7fgqcsqwalwjltrb3w3xyj23ppgsnuzhhkzlhbt5337aw2joad.onion
    name: node2
  - address: uutpxl2cfkk5qa7z4xtgdxssnhutmoo2y2rw6igh5ez4hpxaz4dap7ad.onion
    name: node3
  - address: 5xeigil3hjxltcs3ti4skerhpc252ci7ejynrtm73v3bcbxlfuulsjqd.onion
    name: node4
  key: wrxdvcaqpuzakbfww5sxs6r2uybczwijzfn2ezy2osaj7iox7kl7nhad.key
"""

Now let's fire up onionbalance by running the following command:

   $ python3 onionbalance.py -v info -c config/master/config.yaml -p 6666

If everything went right, onionbalance should start running and after a bit
your frontend service should be reachable!!! You are an onionbalance expert!

If something did not go right, that's OK too, don't get sad because this was
quite complicated. Please check all your logs and make sure you did everything
right according to this guide. Keep on hammering at it and you are gonna get
it. If nothing seems to work, please get in touch with some details and I can
try to help you.

== Now what? ==

Now that you managed to make it work, please monitor your frontend service and
make sure that it's reachable all the time. Check your logs for any errors or
bugs and let me know if you see any. If you want you can make onionbalance
logging calmer by using the '-v warning' switch.

(Also if you see this log message in your frontend Tor logs: "Bug: Unrecognized
signal 132..." that's normal and it will be fixed with #33104).

If you are in the mood for coding feel free to start hacking on onionbalance,
but I would suggest you first get in touch over Github because I'm also working
at it at the same time and it would be a shame if we do duplicate work.

If you find bugs or do any quick bugfixes, please submit them over Github!

If you do code review, please let me know through Github of any issues you find.

Also, if you are gonna be at FOSDEM this upcoming weekend feel free to get in
touch if you have any questions or you want to live test it.

If you have any other feedback, I'd be glad to hear it!

== Next steps ==

I'm gonna be working on this for the next month: fixing bugs, writing
documentation, writing tests, creating packages, submitting and fixing bug
reports in tor and stem etc.

Expect more updates on this mailing list, and also a blog post to
announce the initial launch of the project.

Finally, if there are any errors on this post, I will reply to this thread with
an errata!

Hope this works for you and you have fun onionbalancing your services!

Thanks a lot for the testing and looking forward to your feedback! o/

PS: Major thanks to Donncha for the super clean onionbalance codebase (I did
    not expect to reuse so much code), the Tor network team for the support,
    and Damian for all the work on stem v3 support! Also OTF for the $$$ ;)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201207200643</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-12-07 20:06:43-0400</timestampReceived><subject>[tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Greetings,

Attached is a proposal from Mike Perry and I. Merge requsest is here:

https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22

Cheers!
David

-- 
uSxMMaJozH7GAo7qjzhVUm5FDynPYtBfOeZcLS88XeU=

["328-relay-overload-report.md" (text/markdown)]

```
Filename: 328-relay-overload-report.md
Title: Make Relays Report When They Are Overloaded
Author: David Goulet, Mike Perry
Created: November 3rd 2020
Status: Draft
```

# 0. Introduction

Many relays are likely sometimes under heavy load in terms of memory, CPU or
network resources which in turns diminishes their ability to efficiently relay
data through the network.

Having the capability of learning if a relay is overloaded would allow us to
make better informed load balancing decisions. For instance, we can make our
bandwidth scanners more intelligent on how they allocate bandwidth based on
such metrics from relays.

We could furthermore improve our network health monitoring and pinpoint relays
possibly misbehaving or under DDoS attack.

# 1. Metrics to Report

We propose that relays start collecting several metrics (see section 2)
reflecting their loads from different component of tor.

Then, we propose that 3 new lines be added to the extra-info document (see
dir-spec.txt, section 2.1.2) if only the overload case arrise.

This following describes a series of metrics to collect but more might come in
the future and thus this is not an exhaustive list.

# 1.1. General Overload

The general overload line indicates that a relay has reached an "overloaded
state" which can be one or many of the following load metrics:

   - Any OOMkiller invocation due to memory pressure
   - Any onionskins are dropped
   - CPU utilization of Tor's mainloop CPU core above 90% for 60 sec
   - TCP port exhaustion

The format of the overloaded line added in the extra-info document is as
follow:

```
"overload-reached" YYYY-MM-DD HH:MM:SS NL
   [At most once.]
```

The timestamp is when a at least one metrics was detected. It should always be
at the hour and thus, as an example, "2020-01-10 13:00:00" is an expected
timestamp. Because this is a binary state, if the line is present, we consider
that it was hit at the very least once somewhere between the provided
timestamp and the "published" timestamp of the document which is when the
document was generated.

The overload field should remain in place for 72 hours since last triggered.
If the limits are reached again in this period, the timestamp is updated, and
this 72 hour period restarts.

# 1.2. Token bucket size

Relays should report the 'BandwidthBurst' and 'BandwidthRate' limits in their
descriptor, as well as the number of times these limits were reached, for read
and write, in the past 24 hours starting at the provided timestamp rounded
down to the hour.

```
"overload-ratelimits" SP YYYY-MM-DD SP HH:MM:SS
                      SP rate-limit SP burst-limit
                      SP read-rate-count SP read-burst-count
                      SP write-rate-count SP write-burst-count NL
  [At most once.]
```

The "rate-limit" and "burst-limit" are the raw values from the BandwidthRate
and BandwidthBurst found in the torrc configuration file.

The "{read|write}-rate-count" and "{read|write}-burst-count" are the counts of
how many times the reported limits were exhausted and thus the maximum between
the read and write count occurances.

# 1.3. File Descriptor Exhaustion

Not having enough file descriptors in this day of age is really a
misconfiguration or a too old operation system. That way, we can very quickly
notice which relay has a value too small and we can notify them.

This should be published in this format:

```
"overload-fd-exhausted" YYYY-MM-DD HH:MM:SS NL
  [At most once.]
```

As the overloaded line, the timestamp indicates that the maximum was reached
between the this timestamp and the "published" timestamp of the document.

This overload field should remain in place for 72 hours since last triggered.
If the limits are reached again in this period, the timestamp is updated, and
this 72 hour period restarts.

# 2. Load Metrics

This section proposes a series of metrics that should be collected and
reported to the MetricsPort. The Prometheus format (only one supported for
now) is described for each metrics but each of them are prefixed with the
following in order to have a proper namespace for "load" events:

`tor_load_`

## 2.1 Out-Of-Memory (OOM) Invocation

Tor's OOM manages caches and queues of all sorts. Relays have many of them and
so any invocation of the OOM should be reported.

```
# HELP Total number of bytes the OOM has cleaned up
# TYPE counter
tor_load_oom_bytes_total{&lt;LABEL&gt;} &lt;VALUE&gt;
```

Running counter of how many bytes were cleaned up by the OOM for a tor
component identified by a label (see list below). To make sense, this should
be visualized with the rate() function.

Possible LABELs for which the OOM was triggered:
  - `cell`: Circuit cell queue
  - `dns`: DNS resolution cache
  - `geoip`: GeoIP cache
  - `hsdir`: Onion service descriptors

## 2.2 Onionskin Queues

Onionskins handling is one of the few items that tor processes in parallel but
they can be dropped for various reasons when under load. For this metrics to
make sense, we also need to gather how many onionskins are we processing and
thus one can provide a total processed versus dropped ratio:

```
# HELP Total number of onionskins
# TYPE counter
tor_load_onionskin_total{&lt;LABEL&gt;} &lt;NUM&gt;
```

Possible LABELs are:
  - `processed`: Indicating how many were processed.
  - `dropped`: Indicating how many were dropped due to load.

## 2.3 File Descriptor Exhaustion

Relays can reach a "ulimit" (on Linux) cap that is the number of allowed
opened file descriptors. In Tor's use case, this is mostly sockets. File
descriptors should be reported as follow:

```
# HELP Total number of file descriptors
# TYPE gauge
tor_load_fd_total{&lt;LABEL&gt;} &lt;NUM&gt;
```

Possible LABELs are:
  - `remaining`: How many file descriptors remains that is can be opened.

Note: since tor does track that value in order to reserve a block for critical
port such as the Control Port, that value can easily be exported.

## 2.4 TCP Port Exhaustion

TCP protocol is capped at 65535 ports and thus if the relay ever is unable to
open more outbound sockets, that is an overloaded state. It should be
reported:

```
# HELP Total number of opened outbound connections.
# TYPE gauge
tor_load_socket_total{&lt;LABEL&gt;} &lt;NUM&gt;
```

Possible LABELs are:
  - `outbound`: Sockets used for outbound connections.

## 2.5 Connection Bucket Limit

Rate limited connections track bandwidth using a bucket system. Once the
bucket is filled and tor wants to send more, it pauses until it is refilled a
second later. Once that is hit, it should be reported:

```
# HELP Total number of global connection bucket limit reached
# TYPE counter
tor_load_global_rate_limit_reached_total{&lt;LABEL&gt;} &lt;NUM&gt;
```

Possible LABELs are:
  - `read`: Read side of the global rate limit bucket.
  - `write`: Write side of the global rate limit bucket.

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201207203653</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2020-12-07 20:36:53-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

On Mon, Dec 07, 2020 at 03:06:43PM -0500, David Goulet wrote:
&gt; Greetings,
&gt; 
&gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; 
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; 
&gt; Cheers!
&gt; David

Nice!

Is there a way to distinguish "not overloaded" from "does not support
this extension"?  (Ideally in a better way than checking the tor release
version number and inferring when support was added?)
-- 
Ian Goldberg
Canada Research Chair in Privacy Enhancing Technologies
Professor, Cheriton School of Computer Science
University of Waterloo
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201209150951</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-12-09 15:09:51-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/signed)]


On 07 Dec (15:36:53), Ian Goldberg wrote:
&gt; On Mon, Dec 07, 2020 at 03:06:43PM -0500, David Goulet wrote:
&gt; &gt; Greetings,
&gt; &gt; 
&gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt; 
&gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; &gt; 
&gt; &gt; Cheers!
&gt; &gt; David
&gt; 
&gt; Nice!
&gt; 
&gt; Is there a way to distinguish "not overloaded" from "does not support
&gt; this extension"?  (Ideally in a better way than checking the tor release
&gt; version number and inferring when support was added?)

Gooood point.

So in theory, we have protocol version[1] in order to differentiate relays but
I do not believe such a change would be a wise thing to use a new "Desc="
since tor will just ignore the unknown fields.

The other reason for that is that "tor functionalities" as in to function
properly won't depend on that descriptor field so it is a bit a stretch to
justify this as a new protocol version :S ...

So yeah, either one looks at the tor version or "you don't see it, not
overloaded" which is ofc a lie until the entire network migrates. We expect
our sbws (bandwidth scanner tool) to be the main customer for this.

Cheers!
David

[1] https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n2073

-- 
eWhbmX7lAl8F3ismKUL2eOiPlbv5U/7klKILIHs/590=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201209152204</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2020-12-09 15:22:04-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

On Wed, Dec 09, 2020 at 10:09:51AM -0500, David Goulet wrote:
&gt; On 07 Dec (15:36:53), Ian Goldberg wrote:
&gt; &gt; On Mon, Dec 07, 2020 at 03:06:43PM -0500, David Goulet wrote:
&gt; &gt; &gt; Greetings,
&gt; &gt; &gt; 
&gt; &gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt; &gt; 
&gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; &gt; &gt; 
&gt; &gt; &gt; Cheers!
&gt; &gt; &gt; David
&gt; &gt; 
&gt; &gt; Nice!
&gt; &gt; 
&gt; &gt; Is there a way to distinguish "not overloaded" from "does not support
&gt; &gt; this extension"?  (Ideally in a better way than checking the tor release
&gt; &gt; version number and inferring when support was added?)
&gt; 
&gt; Gooood point.
&gt; 
&gt; So in theory, we have protocol version[1] in order to differentiate relays but
&gt; I do not believe such a change would be a wise thing to use a new "Desc="
&gt; since tor will just ignore the unknown fields.
&gt; 
&gt; The other reason for that is that "tor functionalities" as in to function
&gt; properly won't depend on that descriptor field so it is a bit a stretch to
&gt; justify this as a new protocol version :S ...
&gt; 
&gt; So yeah, either one looks at the tor version or "you don't see it, not
&gt; overloaded" which is ofc a lie until the entire network migrates.

What if, once a day or 72 hours or something, a relay explicitly outputs
"not overloaded" if they're not?

&gt; We expect our sbws (bandwidth scanner tool) to be the main customer
&gt; for this.

I know at least one research group that would be very interested in
these stats as well.  :-)
-- 
Ian Goldberg
Canada Research Chair in Privacy Enhancing Technologies
Professor, Cheriton School of Computer Science
University of Waterloo
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201209163455</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-12-09 16:34:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

On Wed, Dec 9, 2020 at 10:10 AM David Goulet &lt;dgoulet@torproject.org&gt; wrote:
&gt;
&gt; On 07 Dec (15:36:53), Ian Goldberg wrote:
&gt; &gt; On Mon, Dec 07, 2020 at 03:06:43PM -0500, David Goulet wrote:
&gt; &gt; &gt; Greetings,
&gt; &gt; &gt;
&gt; &gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt; &gt;
&gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; &gt; &gt;
&gt; &gt; &gt; Cheers!
&gt; &gt; &gt; David
&gt; &gt;
&gt; &gt; Nice!
&gt; &gt;
&gt; &gt; Is there a way to distinguish "not overloaded" from "does not support
&gt; &gt; this extension"?  (Ideally in a better way than checking the tor release
&gt; &gt; version number and inferring when support was added?)
&gt;
&gt; Gooood point.
&gt;
&gt; So in theory, we have protocol version[1] in order to differentiate relays but
&gt; I do not believe such a change would be a wise thing to use a new "Desc="
&gt; since tor will just ignore the unknown fields.
&gt;
&gt; The other reason for that is that "tor functionalities" as in to function
&gt; properly won't depend on that descriptor field so it is a bit a stretch to
&gt; justify this as a new protocol version :S ...
&gt;
&gt; So yeah, either one looks at the tor version or "you don't see it, not
&gt; overloaded" which is ofc a lie until the entire network migrates. We expect
&gt; our sbws (bandwidth scanner tool) to be the main customer for this.

We could add a new element to this proposal, something like "I will
tell you about overload information", or "I am not overloaded" or
something like that?

peace,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201209173609</emailId><senderName>Jim Newsome</senderName><senderEmail>jnewsome@torproject.org</senderEmail><timestampReceived>2020-12-09 17:36:09-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/alternative)]


On 12/7/20 14:06, David Goulet wrote:
&gt; Greetings,
&gt;
&gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt;
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22

Disclaimer - As someone not very familiar with how tor load balancing
works today, I might not be the target audience for this proposal :)

Maybe it's putting the cart before the horse, but it might be helpful to
have a more concrete proposal for how this data will be used, which in
turn will help evaluate whether this is the right data to collect.

e.g. naively I might assume the idea is to have some kind of exponential
backoff for overloaded relays; but since the proposal is for the
overload events to be recorded at hour-granularity, would that result in
a relay getting overloaded at the top of every hour, and then
under-utilized for the rest of the hour?

&gt;
&gt; Cheers!
&gt; David
&gt;
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

[Attachment #5 (text/html)]

&lt;html&gt;
  &lt;head&gt;
    &lt;meta http-equiv="Content-Type" content="text/html;
      charset=windows-1252"&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;&lt;br&gt;
    &lt;/p&gt;
    &lt;div class="moz-cite-prefix"&gt;On 12/7/20 14:06, David Goulet wrote:&lt;br&gt;
    &lt;/div&gt;
    &lt;blockquote type="cite"
      cite="mid:20201207200643.zinybqjmvh42ztll@raoul"&gt;
      &lt;pre class="moz-quote-pre" wrap=""&gt;Greetings,

Attached is a proposal from Mike Perry and I. Merge requsest is here:

&lt;a class="moz-txt-link-freetext" \
href="https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22"&gt;https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22&lt;/a&gt;&lt;/pre&gt;
  &lt;/blockquote&gt;
    &lt;p&gt;Disclaimer - As someone not very familiar with how tor load
      balancing works today, I might not be the target audience for this
      proposal :)&lt;/p&gt;
    &lt;p&gt;Maybe it's putting the cart before the horse, but it might be
      helpful to have a more concrete proposal for how this data will be
      used, which in turn will help evaluate whether this is the right
      data to collect.&lt;/p&gt;
    &lt;p&gt;e.g. naively I might assume the idea is to have some kind of
      exponential backoff for overloaded relays; but since the proposal
      is for the overload events to be recorded at hour-granularity,
      would that result in a relay getting overloaded at the top of
      every hour, and then under-utilized for the rest of the hour?&lt;/p&gt;
    &lt;blockquote type="cite"
      cite="mid:20201207200643.zinybqjmvh42ztll@raoul"&gt;
      &lt;pre class="moz-quote-pre" wrap=""&gt;

Cheers!
David

&lt;/pre&gt;
      &lt;br&gt;
      &lt;fieldset class="mimeAttachmentHeader"&gt;&lt;/fieldset&gt;
      &lt;pre class="moz-quote-pre" \
wrap=""&gt;_______________________________________________ tor-dev mailing list
&lt;a class="moz-txt-link-abbreviated" \
href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt; &lt;a \
class="moz-txt-link-freetext" \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;
 &lt;/pre&gt;
    &lt;/blockquote&gt;
  &lt;/body&gt;
&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201211140418</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2020-12-11 14:04:18-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/signed)]


On 09 Dec (11:36:09), Jim Newsome wrote:
&gt; 
&gt; On 12/7/20 14:06, David Goulet wrote:
&gt; &gt; Greetings,
&gt; &gt;
&gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt;
&gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; 
&gt; Disclaimer - As someone not very familiar with how tor load balancing
&gt; works today, I might not be the target audience for this proposal :)
&gt; 
&gt; Maybe it's putting the cart before the horse, but it might be helpful to
&gt; have a more concrete proposal for how this data will be used, which in
&gt; turn will help evaluate whether this is the right data to collect.
&gt; 
&gt; e.g. naively I might assume the idea is to have some kind of exponential
&gt; backoff for overloaded relays; but since the proposal is for the
&gt; overload events to be recorded at hour-granularity, would that result in
&gt; a relay getting overloaded at the top of every hour, and then
&gt; under-utilized for the rest of the hour?

Right so there are currently ideas circulating around on how to use that data
properly.

The likely short-term proposal is sbws (bw scanner) that will use that as a
simple signal to backoff on the amount of bw given, as you stated.

Thus your question is right on the nail there about "why we have this proposal
without a concrete proposal on how to use it" :).

The answer I can give you is that we've thought on how for a relay to tell the
world, in a safe way, that it is suffocating. There are few places in the tor
we can actually notice (at the moment) performance problems.

And so we took them all (more might come over time), and mashed them into a
single line "overload reached". And we did that before anything else because
for the network to migrate to support that feature, we are talking a good 2-4
years minimum once the feature is stable thus we have to get this out soon if
we hope to be useful in the foreseeable future.

Onto your next question about the hour problem. So yes, you are correct that
the timeframe between informing the world I'm not overloaded anymore and the
world noticing, you might get under-utilized but you might also get "just
utilized enough".

All in all, we are stuck with a network that "morphs" every hour (new
consensus) but actually, bandwidth scanners take much longer to scan the
entire network (in the realms of days) thus it is actually much more than an
hour of being under-utilized :S.

So there will always be that gap where we will backoff from a relay and then
we might have backed off too much until the scanner notices it and then give
you a bit more. But over time, as the backoff happens and the bw scanner makes
correction, they should reach an equilibrium where the scanner finds the value
that is just enough for you to not advertise overload anymore or in other
words finding the sweet spot.

That is likely to require time and the relay to be maxi stable as in 99%
uptime and not too CPU/network fluctuations.

But also, as we backoff from overloaded relays, we will send traffic to
potentially under-utilized relays and so we hope that yes it will be a bumpy
road at first but after some days/weeks, network should stabilize and we
should actually see very few "overload-reached" after that point (except for
operators running 1000 other things on the relay machine eating the resources
randomly :).

This does highlight also the massive importance of stable relays on the
network so its load balancing can adjust and converge to an equilibrium
without having to re-adjust because 1000 relays on pi4 went down for the night
:).

Hope this answers your question!

Cheers!
David

-- 
rYGibKHpj9tyuXQTgiocxhuz2G/n9dYwDlcqA1Ao9Vk=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201211123805</emailId><senderName>Zaphoid</senderName><senderEmail>zaphoid@protonmail.com</senderEmail><timestampReceived>2020-12-11 12:38:05-0400</timestampReceived><subject>[tor-dev] ARTI</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Greetings Tor-Dev,

I've watched Nick's presentation on State of the Onion and have read the "Tor in \
2021" blog post searching for more details on A Rust Tor Implementation (ARTI). I \
think Rust is a fascinating language and looking to further my knowledge of it and \
Tor's internals as they are developed.

I understand that some Rust implementation is available in the source repository. \
What I am looking for is a road-map or planned outcome. Could anyone advise if the \
intent is to completely re-write the Tor client in Rust? Or, is the project's goal to \
rewrite specific components?

Z


[Attachment #5 (text/html)]

&lt;div&gt;&lt;span style="font-family:arial, sans-serif"&gt;&lt;span style="font-size: \
14px"&gt;Greetings Tor-Dev,&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: \
14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family:arial, sans-serif"&gt;&lt;/span&gt;&lt;span \
style="font-size: 14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family:arial, \
sans-serif"&gt;&lt;span style="font-size: 14px"&gt;I've watched Nick's presentation on State \
of the Onion and have read the "Tor in 2021" blog post searching for more details \
on&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:rgb(255, 255, 255)"&gt;&lt;span \
style="color:rgb(88, 89, 89)"&gt;&lt;span style="font-family:arial, sans-serif"&gt;&lt;span \
style="font-size: 14px"&gt;A Rust Tor Implementation (ARTI). I think Rust is a \
fascinating language and looking to further my knowledge of it and Tor's internals as \
they are developed.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: \
14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-size: 14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="font-size: 14px"&gt;I understand that some Rust implementation is available in \
the source repository. What I am looking for is a road-map or planned outcome. Could \
anyone advise if the intent is to completely re-write the Tor client in Rust? Or, is \
the project's goal to rewrite specific components?&lt;/span&gt;&lt;span style="font-size: \
14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-size: 14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
style="font-size: 14px"&gt;Z&lt;/span&gt;&lt;span style="font-size: \
14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family:arial, sans-serif"&gt;&lt;span \
style="font-size: 14px"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201211172552</emailId><senderName>Jim Newsome</senderName><senderEmail>jnewsome@torproject.org</senderEmail><timestampReceived>2020-12-11 17:25:52-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>


On 12/11/20 08:04, David Goulet wrote:

&gt; we are talking a good 2-4
&gt; years minimum once the feature is stable thus we have to get this out soon if
&gt; we hope to be useful in the foreseeable future.

Right - the slow feedback cycle of deploying between deploying new
logging and trying to use it is all the more reason to plan ahead to try
to ensure the data will actually be suitable for the intended use :).
Granted, we can presumably at least *start* trying to prototype usage of
the data sooner than 2-4 years, but it'll probably still be some months
before any useful data starts arriving, right?

&gt; Onto your next question about the hour problem. So yes, you are correct that
&gt; the timeframe between informing the world I'm not overloaded anymore and the
&gt; world noticing, you might get under-utilized but you might also get "just
&gt; utilized enough".
&gt;
&gt; All in all, we are stuck with a network that "morphs" every hour (new
&gt; consensus) but actually, bandwidth scanners take much longer to scan the
&gt; entire network (in the realms of days) thus it is actually much more than an
&gt; hour of being under-utilized :S.
&gt;
&gt; So there will always be that gap where we will backoff from a relay and then
&gt; we might have backed off too much until the scanner notices it and then give
&gt; you a bit more. But over time, as the backoff happens and the bw scanner makes
&gt; correction, they should reach an equilibrium where the scanner finds the value
&gt; that is just enough for you to not advertise overload anymore or in other
&gt; words finding the sweet spot.
&gt;
&gt; That is likely to require time and the relay to be maxi stable as in 99%
&gt; uptime and not too CPU/network fluctuations.
&gt;
&gt; But also, as we backoff from overloaded relays, we will send traffic to
&gt; potentially under-utilized relays and so we hope that yes it will be a bumpy
&gt; road at first but after some days/weeks, network should stabilize and we
&gt; should actually see very few "overload-reached" after that point (except for
&gt; operators running 1000 other things on the relay machine eating the resources
&gt; randomly :).

Thanks for the explanation! IIUC the new consensus computed every hour
includes weights based on the latest data from the bandwidth scanners,
and an individual relay is only scanned once every x days?

In the proposal, maybe it'd be enough to briefly explain the choices of
parameters and any relevant tradeoffs - one hour for granularity, 72
hours for history, (any others?). It might also be helpful to have a
strawman example of how the data could be used in the congestion control
algorithm, with some discussion like the above ^, though I could also
see that potentially getting too far from the core of the proposal.

Btw, maybe it's worth explicitly explaining how the data *won't* be
useful for attackers? I'd assumed (possibly incorrectly) that the
history wasn't being kept at a finer granularity to avoid being able to
correlate events across relays, and from there perhaps be able to infer
something about individual circuit paths. If that sort of attack is
worth worrying about, should relays also suppress reporting events for
the current partial hour to avoid an attacker being able to probe the
metrics port to find out if an overload just happened?

&gt; Hope this answers your question!

Very helpful, thanks!


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20201212123054</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2020-12-12 12:30:54-0400</timestampReceived><subject>[tor-dev] My app which makes running tor relays on Windows Very Simple</subject><body>

[Attachment #2 (multipart/alternative)]


Hi all,

So this is a software peice I have been developing which makes running tor
relays on Windows very easy. All the user needs to do is write their torrc.
The app installs tor, and configures all once the torrc is written by
itself.

Here is a video showing the app:

Features
Automatic Tor download and installation (via Choclatey)
Type the torrc file, and the app configures and points tor there for you.
Attempted automatic firewall configuration.
Automatic creation of log file.

Cons:
Currently only directly support vanilla bridges. OBFS4 will have to be
manually downloaded / configured.

ATTEMPTED firewall auto configuration. It auto adds a rule to Windows
Defender Firewall to allow the traffic, but can't configure router
firewalls, etc.

Let know what you think. I have successfully gotten tor up and running
through this.

If chocolatey changes their install scripts, this will need to be updated.

I can send the source code if interested.

Programming Language: C#/.Net
 Tor Windows App.mp4
&lt;https://drive.google.com/file/d/1ZJ4EKXbu2Clyzc5WdNdxSWquswhdvSTJ/view?usp=drive_web&gt;

--Keifer

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi all,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So this is a software peice  I have been \
developing which makes running tor relays on Windows very easy. All the user needs to \
do is write their torrc. The app installs tor, and configures all  once the torrc is \
written by itself.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here is a video showing the \
app:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Features  &lt;/div&gt;&lt;div&gt;Automatic Tor download and \
installation (via Choclatey)&lt;/div&gt;&lt;div&gt;Type the torrc file, and the app configures \
and points tor there for you.&lt;/div&gt;&lt;div&gt;Attempted automatic firewall \
configuration.&lt;/div&gt;&lt;div&gt;Automatic creation of log \
file.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cons:&lt;/div&gt;&lt;div&gt;Currently only directly support \
vanilla bridges. OBFS4 will have to be manually downloaded / \
configured.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;ATTEMPTED firewall auto configuration. It auto \
adds a rule to Windows Defender Firewall to allow the traffic, but can't \
configure router firewalls, etc.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Let know what you think. I \
have successfully  gotten tor up and running through \
this.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If chocolatey  changes their install scripts, this \
will need to be updated.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I can send the source code if \
interested.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Programming Language: C#/.Net&lt;/div&gt;&lt;div&gt;&lt;div \
class="gmail_chip gmail_drive_chip" \
style="width:396px;height:18px;max-height:18px;background-color:rgb(245,245,245);padding:5px;font-family:arial;font-weight:bold;font-size:13px;border:1px \
solid rgb(221,221,221);line-height:1"&gt;&lt;a \
href="https://drive.google.com/file/d/1ZJ4EKXbu2Clyzc5WdNdxSWquswhdvSTJ/view?usp=drive_web" \
target="_blank" style="display:inline-block;max-width:366px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-decoration-line:none;padding:1px \
0px;border:none"&gt;&lt;img style="vertical-align: bottom; border: none;" \
src="https://ssl.gstatic.com/docs/doclist/images/icon_10_generic_list.png"&gt;  &lt;span \
dir="ltr" style="vertical-align:bottom;text-decoration:none"&gt;Tor Windows \
App.mp4&lt;/span&gt;&lt;/a&gt;&lt;img src="//ssl.gstatic.com/ui/v1/icons/common/x_8px.png" \
style="opacity: 0.55; cursor: pointer; float: right; position: relative; top: -1px; \
display: none;"&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div dir="ltr" class="gmail_signature" \
data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201212164951</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2020-12-12 16:49:51-0400</timestampReceived><subject>[tor-dev] Arti (was Re:  ARTI)</subject><body>

On Fri, Dec 11, 2020 at 12:31 PM Zaphoid &lt;Zaphoid@protonmail.com&gt; wrote:
&gt; 
&gt; Greetings Tor-Dev,
&gt; 
&gt; I've watched Nick's presentation on State of the Onion and have read the "Tor in \
&gt; 2021" blog post searching for more details on A Rust Tor Implementation (ARTI). I \
&gt; think Rust is a fascinating language and looking to further my knowledge of it and \
&gt; Tor's internals as they are developed.

Hi, Zaphoid, and thanks for the email!

The official repository is at
https://gitlab.torproject.org/tpo/core/arti/ ; most of the info on it
is there.

&gt; I understand that some Rust implementation is available in the source repository. \
&gt; What I am looking for is a road-map or planned outcome. Could anyone advise if the \
&gt; intent is to completely re-write the Tor client in Rust? Or, is the project's goal \
&gt; to rewrite specific components?

[tl;dr: All these plans are tentative and subject to change. I would
_like_ to eventually replace all of our C with Rust, but that is going
to take a long time, and will depend on resources.  For now, we're
going to continue supporting the C code, and we plan to do so at least
until the Rust code is ready to replace it. There is no timeline.]


Okay, so first: this is still an experimental project, so I can't make
promises. I don't know how it's going to go, and I'm still learning
Rust myself.

Also, Tor's plans are always, and forever, at least a little flexible
and amorphous.  Our only _permanent_ plan is that we will defy all
obstacles to use whatever resources we have to bring stronger privacy
to the world. Other plans are always subsidiary to that, and dependent
on our resources. [Please donate to our end-of-year fundraising
campaign if you can, everybody.]

With those disclaimers aside: I do _want_ to eventually replace the C
version of Tor as a client, for most users, with a Rust
implementation.  Eventually, if that works out, I'd like relays and
authorities to be written in Rust too.

The motivation here is not just for the additional safety and
performance that Rust can bring us.  For me, the most important reason
to move towards Rust is maintainability.  Rust gives us tools that
make it much easier to write a maintainable, well-structured,
well-tested set of programs, and to develop those programs in the
future.  I'm confident that a Rust implementation of Tor would still
be comprehensible and maintainable by a different set of programmers
in 20 years; I don't have the same confidence about a C
implementation.

Of course, that won't be easy.  (I know. I've been working on the C
version since 2002, so it would be a bit shocking if the Rust version
replaced it right away.)  We have to choose where to spend our time,
and we can't walk away from the C while it's still our best
implementation.  We'll be supporting the C version of Tor for the
future, I think -- probably for quite a few years.  It's possible that
at some point the two implementations will converge, but that might be
tricky: the C implementation's structure is not really conducive to
having parts of it replaced.

So where are we now, and what's the roadmap?

Right now, if you know how to download and compile Rust programs, you
can build Arti.  It can run as a SOCKS proxy and use the Tor network.
I wouldn't recommend it for serious use yet: it doesn't support onion
services, guards, bridges, and a lot of other security features that
Tor provides, and it's still pretty early in development.  As they
say, "When it breaks, you get to keep both pieces."

Over the coming months, I want to work to close the gap between Arti
and C Tor.  There's an approximate list of the stuff we'll need to do
in order to get there in the TODO file in the Arti repository.  (No
guarantees that I haven't forgotten anything)  How fast we can make
progress on this work is dependent on how much of our time we can
spend on it, and how many people can help us out.  So if anybody here
is interested in Rust, why not have a look at the codebase, and see
what you think?




(Also, there's no need to name any of my software in all-caps.  It's
just "arti" for now, or "Arti" if you really like to capitalize proper
nouns.)

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201221035248</emailId><senderName>enrollado</senderName><senderEmail>enrollado@protonmail.ch</senderEmail><timestampReceived>2020-12-21 03:52:48-0400</timestampReceived><subject>[tor-dev] Debian signing keys</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/alternative)]


I'm getting invalid signing key messages on the Debian Buster repos. Has s=
omething changed?

Sent with ProtonMail Secure Email.
[Attachment #9 (multipart/related)]

[Attachment #11 (text/html)]

&lt;div&gt;I'm getting invalid signing key messages on the Debian Buster repos. Has \
something changed?&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
class="protonmail_signature_block"&gt;&lt;div class="protonmail_signature_block-user \
protonmail_signature_block-empty"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
class="protonmail_signature_block-proton"&gt;Sent with &lt;a href="https://protonmail.com" \
target="_blank"&gt;ProtonMail&lt;/a&gt; Secure Email.&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;


["publickey - enrollado@protonmail.ch - 0x5923AD04.asc" (application/pgp-keys)]
["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201221234539</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2020-12-21 23:45:39-0400</timestampReceived><subject>[tor-dev] Self coded GUI for Tor Windows Relay Software</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Tor Developers,



This is a project I have been working on which allows users to run relays
on Windows with ease. Made this for volunteers who want  to run relays, but
only have Windows. See here



https://www.youtube.com/watch?v=Vpk6yvUWQqU





Features:

Easy configuring of tor

Auto installation of tor or upgrade to newest version at launch

Start relay when OS starts

Keep tor software up to date automatically



Drawbacks:



Only supports vanilla bridges  currently.

Configures Windows Firewall to allow relay traffic automatically, but can't
auto configure any other firewalls.



Tested and working.



I saw a video saying tor could use more Windows developers, so I developed
this.



I am happy to send the source code if you wish. Would be cool to have this
published on tor project website under OS instructions for running relays.


--Keifer

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Hi Tor \
Developers,&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;This is a project I have been \
working on which allows users to run relays on Windows with ease. Made this for \
volunteers who want   to run relays, but only have Windows. See \
here&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;&lt;a \
href="https://www.youtube.com/watch?v=Vpk6yvUWQqU" \
target="_blank"&gt;https://www.youtube.com/watch?v=Vpk6yvUWQqU&lt;/a&gt;&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Features:&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Easy configuring of  &lt;span \
class="gmail-m_30672340478452641il"&gt;&lt;span \
class="gmail-il"&gt;tor&lt;/span&gt;&lt;/span&gt;&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Auto installation of  &lt;span \
class="gmail-m_30672340478452641il"&gt;&lt;span class="gmail-il"&gt;tor&lt;/span&gt;&lt;/span&gt;  or \
upgrade to newest version at launch&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Start relay when OS \
starts&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Keep  &lt;span \
class="gmail-m_30672340478452641il"&gt;&lt;span class="gmail-il"&gt;tor&lt;/span&gt;&lt;/span&gt;  \
software up to date automatically&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Drawbacks:&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Only supports vanilla bridges   \
currently.&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Configures Windows Firewall to \
allow relay traffic automatically, but can't auto configure any other \
firewalls.&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal" style="background-image:initial;background-position:initial;backgrou \
nd-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;Tested and \
working.&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal" \
style="background-image:initial;background-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;  &lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;&lt;span style="font-size:12pt;font-family:Arial,sans-serif"&gt;I saw a \
video saying  &lt;span class="gmail-il"&gt;tor&lt;/span&gt;  could use more Windows developers, \
so I developed this.&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class="MsoNormal"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif"&gt;&lt;u&gt;&lt;/u&gt;  &lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt;&lt;p \
class="MsoNormal"&gt;&lt;span style="font-size:12pt;font-family:Arial,sans-serif"&gt;I am \
happy to send the source code if you wish. Would be cool to have this published on  \
&lt;span class="gmail-il"&gt;tor&lt;/span&gt;  project website under OS instructions for running \
relays.&lt;/span&gt;&lt;font color="#888888"&gt;&lt;span \
style="font-size:12pt;font-family:Arial,sans-serif;background-image:initial;background \
-position:initial;background-size:initial;background-repeat:initial;background-origin:initial;background-clip:initial"&gt;&lt;u&gt;&lt;/u&gt;&lt;u&gt;&lt;/u&gt;&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;/div&gt;&lt;font \
color="#888888"&gt;&lt;p class="MsoNormal"&gt;&lt;u&gt;&lt;/u&gt;  &lt;/p&gt;&lt;/font&gt;&lt;div&gt;&lt;div dir="ltr" \
class="gmail_signature" data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201224005838</emailId><senderName>ELAHI Tariq</senderName><senderEmail>t.elahi@ed.ac.uk</senderEmail><timestampReceived>2020-12-24 00:58:38-0400</timestampReceived><subject>[tor-dev] Two postdoc positions in Meta-data Privacy Systems and Networks at University of Edinburgh</subject><body>

Hello all,

I am looking for two post-docs to join two projects in the theme of Meta-da=
ta Privacy Systems and Networks. The post-docs are homed in the School of I=
nformatics, University of Edinburgh where, under my supervision, we will in=
vestigate meta-data and data privacy techniques as building blocks/primitiv=
es to realize an =93engineered privacy layer=94 that can be embedded into t=
he Internet and communications networks in general.

The post-docs will be a part of---and have the opportunity to interact and =
potentially collaborate with---the Cybersecurity, Privacy, and Trust group =
with over 15 core faculty members and 40+ Post-docs, PhD students, and affi=
liated faculty spanning a broad range of theoretical and applied topics in =
security, privacy, and trust. For more about the group please see: edin.ac/=
3mIDdqN.

If you would like to have a casual chat to find out more before applying or=
 have any questions please get in touch with me (t.elahi@ed.ac.uk).
To learn more about my research interests please see: edin.ac/2KUmT93.

Early applications will be considered as they arrive. The deadline for both=
 positions is 15/1/2021 17:00 GMT.

Some brief information about the two projects with links to further details=
 follow:

1) "Integrating Meta-data Privacy into Networked Applications through =91Ad=
d-On=92 Anonymous Communication Networks"
The aim of this project is to investigate how effectively and efficiently a=
nonymous communication networks (ACN) primitives (at the network and applic=
ations layers) can act as =93add-ons=94 between applications that do not ha=
ve privacy built-in by design (non-PbD apps) and the Internet at large.
This project will rigorously develop and extend on the current folk wisdom =
that to add anonymity or privacy properties to a non-PbD system, the additi=
on of sending all traffic through an ACN is sufficient. It will provide a n=
uanced and technical approach to integrating anonymous networks, and the pr=
imitives they are built on, to systems that are not originally privacy-awar=
e. The approach will be to investigate and extend privacy primitives that e=
nable routing, path selection, and traffic shaping and compose the result i=
nto an =93engineered privacy-layer=94.

Duration: 18 Months
Start: March 1st, 2021 (flexible)
More Information: edin.ac/3rnDdAb (apply by 15/1/2021)

2) "Well-behaved Anonymous Communication Networks"
Mass surveillance of email and web browsing traffic is a critical and growi=
ng threat to individual and at-risk groups' online security and privacy. In=
 response, Anonymous Communication Networks (ACNs) like Tor and Mix network=
s secure communications on the Internet against even the most sophisticated=
 and powerful adversaries.

However, it is a challenge to optimally tune ACNs by the security non-exper=
t system administrator in real world settings. Misconfiguration may lead to=
 catastrophic failures of privacy and performance degradation that will ero=
de trust in ACNs and hamper their adoption.

This project will investigate novel approaches combining engineering princi=
ples and PETS techniques to designing, tuning, and operating ACNs at scale.=
 The resulting systems and techniques will contribute towards our =93engine=
ered privacy-layer=94 vision.

Duration 24 Months
Start: March 1st (flexible)
More Information: edin.ac/34AKDpZ (apply by 15/1/2021)

Stay safe and be healthy,

Tariq Elahi
Assistant Professor
School of Informatics
University of Edinburgh
UK
The University of Edinburgh is a charitable body, registered in Scotland, w=
ith registration number SC005336.

[Attachment #3 (text/html)]

&lt;html xmlns:o="urn:schemas-microsoft-com:office:office" \
xmlns:w="urn:schemas-microsoft-com:office:word" \
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" \
xmlns="http://www.w3.org/TR/REC-html40"&gt; &lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=Windows-1252"&gt;
&lt;meta name="Generator" content="Microsoft Word 15 (filtered medium)"&gt;
&lt;style&gt;&lt;!--
/* Font Definitions */
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
span.DefaultFontHxMailStyle
	{mso-style-name:"Default Font HxMail Style";
	font-family:"Calibri",sans-serif;
	color:windowtext;
	font-weight:normal;
	font-style:normal;
	text-decoration:none none;}
.MsoChpDefault
	{mso-style-type:export-only;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;}
div.WordSection1
	{page:WordSection1;}
--&gt;&lt;/style&gt;
&lt;/head&gt;
&lt;body lang="EN-GB" style="word-wrap:break-word"&gt;
&lt;div class="WordSection1"&gt;
&lt;p class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Hello all,&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;I am looking for two post-docs to join two projects in the \
theme of Meta-data Privacy Systems and Networks. The post-docs are homed in the \
School of Informatics, University  of Edinburgh where, under my supervision, we will \
investigate meta-data and data privacy techniques as building blocks/primitives to \
realize an engineered privacy layer that can be embedded into the Internet and \
communications networks in general.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;The post-docs will be a part of---and have the opportunity \
to interact and potentially collaborate with---the Cybersecurity, Privacy, and Trust \
group with over 15 core  faculty members and 40+ Post-docs, PhD students, and \
affiliated faculty spanning a broad range of theoretical and applied topics in \
security, privacy, and trust. For more about the group please see: \
edin.ac/3mIDdqN.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;If you would like to have a casual chat to find out more \
before applying or have any questions please get in touch with me \
(t.elahi@ed.ac.uk).&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span style="font-size:12.0pt"&gt;To learn more about my \
research interests please see: edin.ac/2KUmT93.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Early applications will be considered as they arrive. The \
deadline for both positions is 15/1/2021 17:00 GMT.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Some brief information about the two projects with links to \
further details follow:&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;1) "Integrating Meta-data Privacy into Networked \
Applications through Add-On Anonymous Communication \
Networks"&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span style="font-size:12.0pt"&gt;The aim of this project \
is to investigate how effectively and efficiently anonymous communication networks \
(ACN) primitives (at the network and applications layers) can  act as add-ons \
between applications that do not have privacy built-in by design (non-PbD apps) and \
the Internet at large.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span style="font-size:12.0pt"&gt;This project will \
rigorously develop and extend on the current folk wisdom that to add anonymity or \
privacy properties to a non-PbD system, the addition of sending all  traffic through \
an ACN is sufficient. It will provide a nuanced and technical approach to integrating \
anonymous networks, and the primitives they are built on, to systems that are not \
originally privacy-aware. The approach will be to investigate and extend  privacy \
primitives that enable routing, path selection, and traffic shaping and compose the \
result into an engineered privacy-layer.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Duration: 18 Months &lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Start: March 1st, 2021 \
(flexible)&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span style="font-size:12.0pt"&gt;More Information: \
edin.ac/3rnDdAb (apply by 15/1/2021)&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;2) "Well-behaved Anonymous Communication \
Networks"&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span style="font-size:12.0pt"&gt;Mass surveillance of \
email and web browsing traffic is a critical and growing threat to individual and \
at-risk groups' online security and privacy. In response, Anonymous  Communication \
Networks (ACNs) like Tor and Mix networks secure communications on the Internet \
against even the most sophisticated and powerful \
adversaries.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;However, it is a challenge to optimally tune ACNs by the \
security non-expert system administrator in real world settings. Misconfiguration may \
lead to catastrophic failures  of privacy and performance degradation that will erode \
trust in ACNs and hamper their adoption.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;This project will investigate novel approaches combining \
engineering principles and PETS techniques to designing, tuning, and operating ACNs \
at scale. The resulting systems  and techniques will contribute towards our \
engineered privacy-layer vision.&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Duration 24 Months &lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Start: March 1st (flexible)&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;More Information: edin.ac/34AKDpZ (apply by \
15/1/2021)&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p class="MsoNormal"&gt;&lt;span \
class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Stay safe and be healthy,&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Tariq Elahi&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;Assistant Professor&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;School of Informatics&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;University of Edinburgh&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p \
class="MsoNormal"&gt;&lt;span class="DefaultFontHxMailStyle"&gt;&lt;span \
style="font-size:12.0pt"&gt;UK&lt;o:p&gt;&lt;/o:p&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/div&gt;
The University of Edinburgh is a charitable body, registered in Scotland, with \
registration number SC005336. &lt;/body&gt;
&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

--===============9034065304971044362==--

</body></email><email><emailId>20201224201225</emailId><senderName>The23rd Raccoon</senderName><senderEmail>raccoon23@protonmail.com</senderEmail><timestampReceived>2020-12-24 20:12:25-0400</timestampReceived><subject>Re: [tor-dev] TOP SECRET BULLETIN ABOUT THE RACCOON EFFECT</subject><body>

On Wednesday, December 23, 2020 4:15 AM, Mike Perry &lt;mikeperry@torproject.org&gt; wrote:
&gt; On 12/23/20 7:58 PM, The23rd Raccoon wrote:
&gt; &gt; Indeed, once time is included as a feature, deep learning based Website
&gt; &gt; Traffic Fingerprinting attacks will effectively be correlating the
&gt; &gt; timing and traffic patterns of websites to their representations in its
&gt; &gt; neural model. This model comparison is extremely similar to how
&gt; &gt; end-to-end correlation compares the timing and traffic patterns of Tor
&gt; &gt; entrance traffic to Tor exit traffic. In fact, deep learning classifiers
&gt; &gt; have already shown success in correlating end-to-end traffic on Tor[28].
&gt; 
&gt; While you have offered no specific testable predictions for this theory,
&gt; presumably to score more crackpot points, allow me to provide a
&gt; reduction proof sketch, as well as an easily testable result.
&gt; 
&gt; To see that Deep Fingerprinting reduces to Deep Correlation, consider
&gt; the construction where the correlator function from DeepCorr is used to
&gt; correlate pairs of raw test traces to the raw training traces that were
&gt; used to train the Deep Fingerprinting classifier. The correlated pairs
&gt; would be constructed from the monitored set's test and training
&gt; examples. This means that instead of correlating client traffic to Exit
&gt; traffic, DeepCorr is correlating "live" client traces directly to the
&gt; raw fingerprinting training model, as you said.
&gt; 
&gt; This gets us "closed world" fingerprinting results. For "open world"
&gt; results, include the unmonitored set as input that does not contain
&gt; matches (to represent partial network observation that results in
&gt; unmatched pairs).

Thank you for this clarification! This is exactly what I was talking
about, in between scoring crackpot points.

&gt; If the accuracy from this DeepCorr Fingerprinting construction is better
&gt; than Deep Fingerprinting for closed and open world scenarios, one can
&gt; conclude that Deep Fingerprinting reduces to DeepCorr, in a
&gt; computational complexity and information-theoretic sense. This is
&gt; testable.
&gt; 
&gt; If the accuracy is worse, then Deep Fingerprinting is actually a more
&gt; powerful attack than DeepCorr, and thus defenses against Deep
&gt; Fingerprinting should perform even better against DeepCorr, for web
&gt; traffic. This is also testable.
&gt; 
&gt; This reduction also makes sense intuitively. The most powerful
&gt; correlation and fingerprinting attacks now use CNNs under the hood. So
&gt; they should both have the same expressive power, and inference
&gt; capability.
&gt; 
&gt; Interestingly, the dataset that Pulls used was significantly larger than
&gt; what DeepCorr used, in terms of "pairs" that must be matched.

I am very suspicious that DeepCorr found in figure 7 that the false
positive rate did not change with additional flows. This makes me
suspect that this figure is reporting raw per-flow P(C|M) and
P(C|~M), from my first post:
https://archives.seul.org/or/dev/Mar-2012/msg00019.html

Again, Danezis argued against my math saying that modern correlators
perform correlation on all n^2 streams "as a whole", rather than
pairwise:
https://conspicuouschatter.wordpress.com/2008/09/30/the-base-rate-fallacy-and-the-traffic-analysis-of-tor/


However, based on the fact that Website Traffic Fingerprinting works,
as you add more concurrent flows for popular websites, shouldn't the
correlation find false positives among them? And then, what about
defenses that make different websites correlate in this way?

Additionally, it is somewhat amusing to me that DeepCorr used almost
the exact same scale of experimental flows as my 2008 post (~5000),
and reports a false positive rate of the same magnitudes.
(0.001 FP; 0.999 TP, from eyeballing Figure 8):
https://people.cs.umass.edu/~amir/papers/CCS18-DeepCorr.pdf

More science is needed! The construction above is a very good start!

&gt; More interestingly, DeepCorr also found that truncating flows to the
&gt; initial portion was still sufficient for high accuracy. Pulls's
&gt; defenses also found that the beginning of website traces were most
&gt; important to pad heavily.

I actually agree with the dogma that "more packets means more
information", and that DeepCorr should improve with longer flows.

However, research does indicate that the highest differentiating
information gain is present in the initial portion of web traffic.
Additionally, Pulls's alien AI confirmed this independently.

There is also a limit to how long website flows tend to be. The
application layer can also get involved to enforce an arbitrary
limit, before reconnecting via other paths, as Panchenko showed.

&gt; &gt; P.P.P.S. At 1004 points on the crackpot index, I believe this post is
&gt; &gt; now the highest scoring publication with a valid novel idea that has
&gt; &gt; been written, to date[2].
&gt; 
&gt; If it helps to get a raccoon into the world record books: I again
&gt; confirm this is a valid, novel idea. I have kept John Baez on Cc for
&gt; this reason. We should probably take him off after this :).

The suppression of my ideas remains extreme! My post never made it back
to me, nor did it end up in my spam folder! Very suspicious!

In case anyone missed it, it did hit the list archives:
https://lists.torproject.org/pipermail/tor-dev/2020-December/014496.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201223015819</emailId><senderName>The23rd Raccoon</senderName><senderEmail>raccoon23@protonmail.com</senderEmail><timestampReceived>2020-12-23 01:58:19-0400</timestampReceived><subject>[tor-dev] TOP SECRET BULLETIN ABOUT THE RACCOON EFFECT</subject><body>

         Was the Raccoon ACTUALLY RIGHT after ALL THESE YEARS:
           Proof of a SOLO CUTTING EDGE PARADIGM SHIFT, or
         an ALIEN INTERVENTION to EXPOSE ACADEMIC CONSPIRACY?

                                by
                             Raccoon23


(You'll have to excuse my caps lock: I am going for a world record high
score on the crackpot index[1,2]. Cypherpunk lore has a loooong history
of high scores in this index, so I really do have to work very hard to
get every point I reasonably can. However, I'm already at 226 points in
the title, by my count. Plus I've got this[3] going for me, which is
nice.)


But enough about that. Let's get to the meat[4]!

Recent advances in traffic analysis defenses have finally proved that my
controversial but revolutionary theories[5,6] are valid, overturning
decades of theories about traffic analysis attacks against anonymity
networks!

Ok ok, so I might have made a mistake in the math[7]. But I'm just a
Raccoon who reads discarded academic research papers in a dumpster.
While I have been highly educated through my dumpster schooling, one
can't expect raccoons to do math correctly. Such math is best left to
others who can properly express my theory in terms of equations.

Others like Panchenko, Pulls, Danezis, Kadianakis, et al; and maybe
Perry. (But probably not Perry.)

I have worked on this problem *alone* for many years, while I was in or
around many highly respected mental institutions. I was even cautioned
to take a break, by my therapeutic advisors. Probably because I was
getting too close to the TRUTH!

However, as we shall see, this was not entirely a solo effort. This
leaves only one possibility: ALIEN INTERVENTION[8].

But before we get to that, much has happened since my two posts on this
topic, over a decade ago.


So let's recap:

My two posts were written in opposition to the orthodox view that
anonymity networks would always be 100% broken by traffic correlation
attacks, and so therefore side channels such as cryptographic tagging
attacks were not worth including in Tor's threat model.

Paul Syverson, the famous self-appointed defender of the orthodoxy of
onion routing, argued most vigorously against my points, carefully
trying to correct me. But I would not be dissuaded! (I love you Paul!
Just scoring crackpot points.)

Paul's clout with the "scientific establishment" is clearly very strong.
Paul has had a distinguished career, being named in The Foreign Policy
Top 100 Global Thinkers List in 2012[9], and named an ACM Fellow in
2014[10].

As evidence of his obvious involvement in the scientific conspiracy
against me, consider that my original post was cut short "somehow" on
the official Tor Project mailing list archive[11], compared to the
original[5].

This is also not the first time a famous thinker has suppressed an idea
that they secretly believed in. Elon Musk, renowned and respected former
proponent of the Simulation Hypothesis[12], clearly knows that optimized
versions of the Alcubierre Drive[13] are realizable using excess exotic
matter accumulated during particle accelerator "downtime". Downtime, I
might add, that is facilitated by a Tor Project volunteer administrator
who goes by the codename 'weasel', who subsequently faked his own death
to avoid implication[14]. These are the kinds of people we are dealing
with here. They will stop at NOTHING to conceal the TRUTH!

Elon has since begun a cover-up of the Simulation Hypothesis[15],
presumably because someone collected his bounty to help him escape The
Matrix[16]. Despite all of this being so obviously exposed, Elon still
pursues his wasteful and foolish rocketry! Merely because he likes
lighting things on fire[17], digging tunnels[18], and playing with
electricity[19]. Elon, the raccoons can relate -- we just wish you would
come clean, and admit you did it all for the tunnel rave...

Anyway, I digress. Some time after my post, I would learn from my daily
dumpster deliveries that Website Traffic Fingerprinting had became a fad
in academic research circles. Website Traffic Fingerprinting is a form
of traffic analysis that uses machine learning to recognize website
access over Tor, by observing only the encrypted traffic patterns
entering the Tor network.

For ethical and practical reasons, these attacks are performed in lab
conditions on researcher generated web crawls, often using individual
static web page access, rather than involving interactive user web
browsing or other concurrent Tor activity common to real-world Tor
usage.

Mike Perry, a suspiciously private employee of the Tor Project,
critiqued the limitations of these lab conditions, and questioned the
accuracy of many of these attacks in realistic settings[20]. Perry and
Kadianakis also developed a framework for building traffic analysis
defenses for Tor[21].

Despite this, or perhaps because of it, a long series of attacks and
defenses ensued, and the advent of deep learning[22] caused many to
believe that defenses against deep learning based Website Traffic
Fingerprinting attacks were as hopeless as trying to defend against
end-to-end correlation.

I watched from my dumpster as these hidebound reactionary responses to
traffic analysis defenses continued for many years, seemingly trying to
bait me out of hiding, to no avail[23]. (To be honest, I don't even know
what hidebound means. I'm just a raccoon. But saying that gets me
crackpot points. And it totally happened!)

However, I was eventually delighted to see that some recent advances by
others had arrived in my dumpster, finally allowing my ideas to have
vindication!

Recently, Panchenko et al found traffic splitting to be highly effective
against state of the art Website Traffic Fingerprinting attacks based on
deep learning[24].

Concurrently, Tobias Pulls used Perry and Kadianakis's padding machines
in an optimization problem, using a Genetic Algorithm to evolve optimal
padding machines against deep learning classifiers, for use in defense
against Website Traffic Fingerprinting[25]. With this result, we have
finally entered the age of the machines versus the machines. Raccoon
math, while groundbreaking, is no longer necessary.

Both of these defenses were highly successful on their own.

However, with the combination of traffic splitting and cover traffic
defenses, Tor will be on the CUTTING EDGE of making a PARADIGM SHIFT in
its threat model, to tackle the hardest problem of all: END-TO-END
TRAFFIC CORRELATION.


Allow me to present my case:

Einstien once posited that time was relative. While Einstien's theory of
relativity was fundamentally misguided, time is relative. Relative to
the problem of both end-to-end traffic correlation, and Website Traffic
Fingerprinting.

Einstien, in his later years, even alluded to quantum observation
correlation as "spooky action at a distance", setting precedent for the
connection that I have known all along to be true. Einstien might not
have been as insightful as me, but for all his fumbling, Einstien was
right about one thing: correlation attacks *are* spooky. Metadata kills
people[26]. (Sadly, that is not a joke...)

Unfortunately, Einstien's results were incomplete, and his groping to
unify these problems was not properly understood by any, except yours
truly. Deep learning was so successful at Website Traffic Fingerprinting
that most researchers did not even bother to provide their deep learning
classifiers with time-based features. They claimed their classifiers
were accurate enough without considering time at all! We now know this
to be false, thanks to the independent discoveries of new defenses by
the teams of Panchenko and Pulls.

As it turns out, quantum mechanics is also fundamentally misguided. We
now know that the universe appears to be made up of fragments of energy
at a fundamental level[27]. In fact, after all these years, raccoons and
their allies (alien or otherwise) seem to be almost as close to unifying
physics as we are to addressing end-to-end correlation in Tor!

Indeed, once time is included as a feature, deep learning based Website
Traffic Fingerprinting attacks will effectively be correlating the
timing and traffic patterns of websites to their representations in its
neural model. This model comparison is extremely similar to how
end-to-end correlation compares the timing and traffic patterns of Tor
entrance traffic to Tor exit traffic. In fact, deep learning classifiers
have already shown success in correlating end-to-end traffic on Tor[28].

Some say that Long Term Statistical Disclosure (LTSD) attacks will still
always win the end-to-end correlation game against anonymity networks,
in the fullness of time[29].

However, LTSD attacks are only a theory. And much like quantum
mechanics, relativity, and LSD, these attacks also warp one's perception
of reality, time, and space. All of these theories are fundamentally
misguided.

LTSD attacks predict that over time, correlation gradually leaks enough
information to fully deanonymize users of anonymity networks. But also
much like quantum mechanics, they fail to fully define the mechanism.

Consider this thought experiment (feel free to use whatever mind
expanding devices you have at hand to assist you): LTSD assumes that an
adversary has complete high resolution information of all traffic that
enters and exits an anonymity network. Additionally, LTSD assumes that
an adversary has identifiers available to properly track traffic streams
on *each* side of the correlation, over the full duration of observation
and long-term correlation.

Several real-world effects undermine these assumptions. Widespread
deployment of HTTPS[30], the trend towards encrypted DNS and SNI, shared
cloud infrastructure, and the practical infeasibility of full
Internet-wide traffic record keeping, all reduce the ability of the
adversary to track repeated connections over time. Additionally,
defenses that multiplex traffic entering the Tor network with traffic
splitting and cover traffic undermine the adversary's ability to fully
determine traffic time and quantity information that pertains to
specific connections.

All of this means that the LTSD adversary, much like Einstien's
light-riding cowboy and Schrodinger's cat, remain an idealized
approximation of reality.

Despite the results of the DeepCorr experiment[28], from this thought
experiment, it is clear that correlation can be mitigated, perhaps even
pushing long-term correlation attacks into time durations that allow for
many practical use cases, even web browsing.

As we know from the historical record[31], aliens need anonymity
too[32]. And when their hyper-dimensional cats join with all of the
raccoons[33] and other creatures who are using Tor on a regular basis,
the quantity of co-incident events (and unmatched pairs due to to
incomplete observation) will rise high enough to cause LTSD to require
larger and larger amounts of observation time, to perform effective
correlation.

This by itself is a huge win. We can now say with certainty that The
Raccoon Effect has thoroughly discromulated correlation attacks.

(Discromulation is my term to describe what this kind of defense does.
Most interestingly, I am forced into winning this crackpot point.
Because deep learning is an opaque machine generated attack, and because
the GA-optimized defense is also machine generated, it is actually
impossible to precisely describe the complete behaviors of either one,
other than with the resulting model definitions themselves! Brave new
world.)

Now, what about alien intervention? Well, assuming we do not consider
the AI that participated in this work to be alien: if aliens did
intervene, none would argue the discromulating conflugruity of The
Raccoon Effect. Unfortunately however, I can neither confirm nor deny
these allegations[34], at this time[35].

But that's not all! Since the circuit padding framework is implemented
in Tor, this means that it is covered by Tor's bug bounty. While
research papers that break padding defenses are not covered by the
bounty (especially if those defenses are not actually deployed), there
*is* in fact prize money for any flaws found in the framework that could
lead to code execution, or deanonymization[36].


In conclusion:

Here I am, setting a world record high score on the crackpot index
(despite many admirable high scores by previous cypherpunks), and I was
RIGHT ALL ALONG. I deserve a Nobel Prize for this work. But I do not
expect to get one. I expect the brownshirts and Nazis embedded in the
scientific establishment to continue to work hard to suppress my TRUTH.

Even the crackpot index itself is involved in this conspiracy of
scientific suppression. John Baez, the creator of the crackpot index,
would surely confirm this, if he was not also part of the conspiracy
against me! I have included him on CC, just in case he would like to
recant his suppression of my original thinking, before his show trial.

Like Galileo, I will cede no ground in this Inquisition!

In fact, much like myself, even Newton struggled through a pandemic[37],
and prevailed. We are more alike than you know. Newton tossed apples to
many a raccoon in his garden. That's how we taught him to poorly
approximate gravity (even though his misguided and simple calculus was
barely up to the task).

In these tough times, it is very satisfying to finally have vindication.
As the Base Rate Fallacy showed all those years ago: The Raccoon Effect
is real. THEY are watching; but WE are Legion[38].

Unfortunately, the reproducibility crisis in science is also real. More
than ten years later, it is *still* often hard to reproduce, confirm,
and compare results across the various papers that end up in my
dumpster. Venues that do not have artifact archival policies are, in
fact, on the verge of becoming shams. I am glad that some venues, and
some researchers, are recanting the old ways[39,40].

The paper is not the only product of good research!


P.S. You'll have to keep this all much more secret than I did. I don't
want anyone to steal these ideas; the aliens might get upset. 2020 is
not over!

P.P.S. This sentence gets me #4. (As a liar's paradox[41]). Some say this
puts me in a superposition of both getting and not getting #4, and I
inherently can't get those points in this way. But I say that should get
me double points! (And thus earn more points for #5). Gotta collect 'em
all.

P.P.P.S. At 1004 points on the crackpot index, I believe this post is
now the highest scoring publication with a valid novel idea that has
been written, to date[2].

P.P.P.P.S. Fucking bored as fuck during this fucking pandemic. Fuck![42]


1. https://math.ucr.edu/home/baez/crackpot.html
2. https://www.reddit.com/r/math/comments/4r05wh/has_anyone_with_a_high_crackpot_index_score_every/
 3. https://en.m.wikipedia.org/wiki/Betteridge%27s_law_of_headlines
4. http://www.stinkymeat.net/
5. https://archives.seul.org/or/dev/Mar-2012/msg00019.html - Raccoon23 Post1
6. https://archives.seul.org/or/dev/Sep-2008/msg00016.html - Raccoon23 Post2
7. https://conspicuouschatter.wordpress.com/2008/09/30/the-base-rate-fallacy-and-the-traffic-analysis-of-tor/
 8. https://fahrplan.events.ccc.de/congress/2006/Fahrplan/speakers/1242.en.html
9. https://awards.acm.org/award_winners/syverson_5067587
10. https://web.archive.org/web/20121130072122/http://www.foreignpolicy.com/articles/2012/11/26/the_fp_100_global_thinkers?page=0,48
 11. https://lists.torproject.org/pipermail/tor-dev/2008-September/002493.html
12. https://en.wikipedia.org/wiki/Simulation_hypothesis#The_simulation_argument
13. https://en.wikipedia.org/wiki/Alcubierre_drive
14. https://www.bbc.com/news/world-europe-36173247 - Weasel takes down LHC
15. https://www.slashgear.com/elon-musk-has-banned-hot-tub-talks-about-simulated-existence-03442784/
 16. https://www.forbes.com/sites/janetwburns/2016/10/13/elon-musk-and-friends-are-spending-millions-to-break-out-of-the-matrix/
 17. https://www.youtube.com/watch?v=qLcma0YyzhY - Elon Musk Flame Thrower
18. https://www.yogonet.com/international/noticias/2020/12/07/55695-boring-company-approved-to-expand-its-tunnel-to-encore-at-wynn-las-vegas
 19. https://www.inverse.com/innovation/tesla-electric-jet-3-4-years-away
20. https://blog.torproject.org/critique-website-traffic-fingerprinting-attacks
21. https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md
 22. https://arxiv.org/pdf/1801.02265.pdf - Deep Fingerprinting Tor
23. https://www.youtube.com/watch?v=TvjMr6DU7C8 - Raccoon call
24. https://www.comsys.rwth-aachen.de/fileadmin/papers/2020/2020-delacadena-trafficsliver.pdf
 25. https://arxiv.org/abs/2011.13471 - Pulls GA Defense
26. https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata
 27. https://www.full-thesis.net/fragments-of-energy-not-waves-or-particles-may-be-the-fundamental-building-blocks-of-the-universe/4418/
 28. https://people.cs.umass.edu/~amir/papers/CCS18-DeepCorr.pdf
29. https://www.freehaven.net/anonbib/cache/statistical-disclosure.pdf
30. https://transparencyreport.google.com/https/overview?hl=en
31. https://en.wikipedia.org/wiki/Accelerando#Characters
32. https://fahrplan.events.ccc.de/congress/2006/Fahrplan/attachments/1167-SpeakingAnonymously.pdf
 33. https://www.youtube.com/watch?v=jSRfIMjvtFk - Raccoons and cats &lt;3
34. https://edition.cnn.com/2020/04/27/politics/pentagon-ufo-videos/index.html
35. https://www.nbcnews.com/news/weird-news/former-israeli-space-security-chief-says-extraterrestrials-exist-trump-knows-n1250333
 36. https://hackerone.com/torproject
37. https://www.msn.com/en-ie/news/coronavirus/during-a-pandemic-isaac-newton-had-to-work-from-home-too-he-used-the-time-wisely/ar-BB118Jyp
 38. https://www.youtube.com/watch?v=Ofp26_oc4CA - Raccoons are Legion
39. https://www.usenix.org/conference/usenixsecurity21/artifact-evaluation-information
 40. https://petsymposium.org/artifacts.php
41. https://en.wikipedia.org/wiki/Liar_paradox
42. https://www.youtube.com/watch?v=04_rIuVc_qM - WTF


For Karsten:
https://cs5.livemaster.ru/storage/3a/1f/1449eb23f3c3b318ab4960815fn4--watercolour-watercolor-sad-raccoon.jpg


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20201223041519</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2020-12-23 04:15:19-0400</timestampReceived><subject>Re: [tor-dev] TOP SECRET BULLETIN ABOUT THE RACCOON EFFECT</subject><body>

On 12/22/20 7:58 PM, The23rd Raccoon wrote:&gt; Recent advances in traffic
analysis defenses have finally proved that my
&gt; controversial but revolutionary theories[5,6] are valid, overturning
&gt; decades of theories about traffic analysis attacks against anonymity
&gt; networks!
&gt; 
&gt; Ok ok, so I might have made a mistake in the math[7]. But I'm just a
&gt; Raccoon who reads discarded academic research papers in a dumpster.
&gt; While I have been highly educated through my dumpster schooling, one
&gt; can't expect raccoons to do math correctly. Such math is best left to
&gt; others who can properly express my theory in terms of equations.

I am glad you liked the papers!


&gt; Others like Panchenko, Pulls, Danezis, Kadianakis, et al; and maybe
&gt; Perry. (But probably not Perry.)

Hey, I can MATH!

As Tor's Research Janitor, I confirm that your bulletin contains valid
novel ideas, and they are very testable (see below). This is insanely
great! I wish I thought of it!

In fact, unification of correlation and fingerprinting, along with the
unification and combination of defenses, is an entire research area,
with many possible paper topics.


&gt; Recently, Panchenko et al found traffic splitting to be highly effective
&gt; against state of the art Website Traffic Fingerprinting attacks based on
&gt; deep learning[24].
&gt; 
&gt; Concurrently, Tobias Pulls used Perry and Kadianakis's padding machines
&gt; in an optimization problem, using a Genetic Algorithm to evolve optimal
&gt; padding machines against deep learning classifiers, for use in defense
&gt; against Website Traffic Fingerprinting[25]. With this result, we have
&gt; finally entered the age of the machines versus the machines. Raccoon
&gt; math, while groundbreaking, is no longer necessary.
&gt; 
&gt; Both of these defenses were highly successful on their own.

Pulls's methodology in your reference[25] was exemplary. Using the
circpad simulator and the circpad frameworks allows us to rapidly and
directly deploy exact research solutions on the Tor network, as-is.

In fact, we could deploy the GA-generated machine specifications in his
paper on live Tor relays today.

We will need to re-tune everything once congestion control and conflux
is deployed, and when timing is involved, so I think the best plan is to
have another round or two of research into optimizing and tuning for
that scenario.


&gt; However, with the combination of traffic splitting and cover traffic
&gt; defenses, Tor will be on the CUTTING EDGE of making a PARADIGM SHIFT in
&gt; its threat model, to tackle the hardest problem of all: END-TO-END
&gt; TRAFFIC CORRELATION.

I also agree that the combination should require less overhead and
better performance than either one by themselves. Obviously, testing
this is a very promising research area. I encourage full collaboration
between Pulls, Panchenko, Tor, wild raccoons, and others, in this area.

For those who are considering studying this, see:
https://gitlab.torproject.org/mikeperry/torspec/-/blob/ticket40202_01/proposals/329-traffic-splitting.txt


We are optimizing that using congestion control, to achieve high-speed
low-latency traffic splitting, to exit relays and onion services. We
will likely only use 2 circuits, to reduce exposure to guard relays with
respect to other potential attacks, so some padding overhead will likely
still be necessary.

The combination could also be tuned to help reduce the overhead needed
by padding, in an optimization problem context, like Pulls's GA.

I will be updating that draft with more information as the proposal
solidifies.

Note to those from the future: this proposal draft link will
eventually be merged to the torspec repo. Check for the final version
here:
https://gitlab.torproject.org/tpo/core/torspec/-/tree/master/proposals


&gt; Indeed, once time is included as a feature, deep learning based Website
&gt; Traffic Fingerprinting attacks will effectively be correlating the
&gt; timing and traffic patterns of websites to their representations in its
&gt; neural model. This model comparison is extremely similar to how
&gt; end-to-end correlation compares the timing and traffic patterns of Tor
&gt; entrance traffic to Tor exit traffic. In fact, deep learning classifiers
&gt; have already shown success in correlating end-to-end traffic on Tor[28].

While you have offered no specific testable predictions for this theory,
presumably to score more crackpot points, allow me to provide a
reduction proof sketch, as well as an easily testable result.

To see that Deep Fingerprinting reduces to Deep Correlation, consider
the construction where the correlator function from DeepCorr is used to
correlate pairs of raw test traces to the raw training traces that were
used to train the Deep Fingerprinting classifier. The correlated pairs
would be constructed from the monitored set's test and training
examples. This means that instead of correlating client traffic to Exit
traffic, DeepCorr is correlating "live" client traces directly to the
raw fingerprinting training model, as you said.

This gets us "closed world" fingerprinting results. For "open world"
results, include the unmonitored set as input that does not contain
matches (to represent partial network observation that results in
unmatched pairs).

If the accuracy from this DeepCorr Fingerprinting construction is better
than Deep Fingerprinting for closed and open world scenarios, one can
conclude that Deep Fingerprinting reduces to DeepCorr, in a
computational complexity and information-theoretic sense. This is
testable.

If the accuracy is worse, then Deep Fingerprinting is actually a more
powerful attack than DeepCorr, and thus defenses against Deep
Fingerprinting should perform even better against DeepCorr, for web
traffic. This is also testable.

This reduction also makes sense intuitively. The most powerful
correlation and fingerprinting attacks now use CNNs under the hood. So
they should both have the same expressive power, and inference
capability.

Interestingly, the dataset that Pulls used was significantly larger than
what DeepCorr used, in terms of "pairs" that must be matched.

More interestingly, DeepCorr also found that truncating flows to the
initial portion was still sufficient for high accuracy. Pulls's
defenses also found that the beginning of website traces were most
important to pad heavily.


&gt; Some say that Long Term Statistical Disclosure (LTSD) attacks will still
&gt; always win the end-to-end correlation game against anonymity networks,
&gt; in the fullness of time[29].
&gt; 
&gt; However, LTSD attacks are only a theory. And much like quantum
&gt; mechanics, relativity, and LSD, these attacks also warp one's perception
&gt; of reality, time, and space. All of these theories are fundamentally
&gt; misguided.
&gt; 
&gt; LTSD attacks predict that over time, correlation gradually leaks enough
&gt; information to fully deanonymize users of anonymity networks. But also
&gt; much like quantum mechanics, they fail to fully define the mechanism.
&gt; 
&gt; Consider this thought experiment (feel free to use whatever mind
&gt; expanding devices you have at hand to assist you): LTSD assumes that an
&gt; adversary has complete high resolution information of all traffic that
&gt; enters and exits an anonymity network. Additionally, LTSD assumes that
&gt; an adversary has identifiers available to properly track traffic streams
&gt; on *each* side of the correlation, over the full duration of observation
&gt; and long-term correlation.

For a more modern treatment of LTSD-like correlation attack theory, see
The Anonymity Trilemma: https://eprint.iacr.org/2017/954.pdf

Even so, all of the limitations you have identified still apply. Some
have been incorporated into the theory and indeed show decrease in
efficacy, but others have still not been accounted for!

As I said in the circpad framework documentation, I prefer an empirical
approach to pure formalism, for this reason. I agree that it looks like
we can do much better than today, for a realistic amount of overhead.

All of that said, anonymity is a complicated problem. As your earlier
posts indicate: targeting, stylometry, and mailinglist post timing can
degrade anonymity in surprising ways. The Raccoon Effect only works if
we have enough raccoons who behave and look alike, and are exceedingly
careful about it. The machines can do much more than correlate traffic
patterns, these days!


&gt; This by itself is a huge win. We can now say with certainty that The
&gt; Raccoon Effect has thoroughly discromulated correlation attacks.
&gt; 
&gt; (Discromulation is my term to describe what this kind of defense does.
&gt; Most interestingly, I am forced into winning this crackpot point.
&gt; Because deep learning is an opaque machine generated attack, and because
&gt; the GA-optimized defense is also machine generated, it is actually
&gt; impossible to precisely describe the complete behaviors of either one,
&gt; other than with the resulting model definitions themselves! Brave new
&gt; world.)

This *is* interesting. Pulls also pointed this out in his paper. This is
another reason why it seems better to rely on reproducible empirical
methods, rather than pure formalism.



&gt; Now, what about alien intervention? Well, assuming we do not consider
&gt; the AI that participated in this work to be alien: if aliens did
&gt; intervene, none would argue the discromulating conflugruity of The
&gt; Raccoon Effect. Unfortunately however, I can neither confirm nor deny
&gt; these allegations[34], at this time[35].

The fact that Pulls's AI named itself 'Interspace' has me curious and
eager to subscribe to your newsletter!


&gt; But that's not all! Since the circuit padding framework is implemented
&gt; in Tor, this means that it is covered by Tor's bug bounty. While
&gt; research papers that break padding defenses are not covered by the
&gt; bounty (especially if those defenses are not actually deployed), there
&gt; *is* in fact prize money for any flaws found in the framework that could
&gt; lead to code execution, or deanonymization[36].

Unfortunately, when OTF lost funding due to the Trump administration's
desire to fund closed source Internet Freedom tools, we also lost our
OTF funding for this bug bounty, and had to temporarily suspend it while
we look for a new sponsor.

However, to keep you honest (and preserve your crackpot points), I will
personally honor the bounty for any bugs found in the circpad framework,
as deployed in Tor, that lead to code execution or full deanonymization,
as a result of that code (excluding correlation and fingerprinting
attacks, until we deploy strong defenses). It is mostly my code anyway,
and I doubt George Kadianakis made any mistakes.

If anyone wants to help support Tor's ability to make progress on these
types of problems, please consider donating:
https://donate.torproject.org/


&gt; P.P.P.S. At 1004 points on the crackpot index, I believe this post is
&gt; now the highest scoring publication with a valid novel idea that has
&gt; been written, to date[2].

If it helps to get a raccoon into the world record books: I again
confirm this is a valid, novel idea. I have kept John Baez on Cc for
this reason. We should probably take him off after this :).


&gt; P.P.P.P.S. Fucking bored as fuck during this fucking pandemic. Fuck![42]

I hear you. To help pass the time until the aliens reveal themselves,
I've made a playlist:
https://open.spotify.com/playlist/5iYQ0BZNEOaoRhf8Pydvqp


&gt; 1. https://math.ucr.edu/home/baez/crackpot.html
&gt; 2. https://www.reddit.com/r/math/comments/4r05wh/has_anyone_with_a_high_crackpot_index_score_every/
&gt;  3. https://en.m.wikipedia.org/wiki/Betteridge%27s_law_of_headlines
&gt; 4. http://www.stinkymeat.net/
&gt; 5. https://archives.seul.org/or/dev/Mar-2012/msg00019.html - Raccoon23 Post1
&gt; 6. https://archives.seul.org/or/dev/Sep-2008/msg00016.html - Raccoon23 Post2
&gt; 7. https://conspicuouschatter.wordpress.com/2008/09/30/the-base-rate-fallacy-and-the-traffic-analysis-of-tor/
&gt;  8. https://fahrplan.events.ccc.de/congress/2006/Fahrplan/speakers/1242.en.html
&gt; 9. https://awards.acm.org/award_winners/syverson_5067587
&gt; 10. https://web.archive.org/web/20121130072122/http://www.foreignpolicy.com/articles/2012/11/26/the_fp_100_global_thinkers?page=0,48
&gt;  11. https://lists.torproject.org/pipermail/tor-dev/2008-September/002493.html
&gt; 12. https://en.wikipedia.org/wiki/Simulation_hypothesis#The_simulation_argument
&gt; 13. https://en.wikipedia.org/wiki/Alcubierre_drive
&gt; 14. https://www.bbc.com/news/world-europe-36173247 - Weasel takes down LHC
&gt; 15. https://www.slashgear.com/elon-musk-has-banned-hot-tub-talks-about-simulated-existence-03442784/
&gt;  16. https://www.forbes.com/sites/janetwburns/2016/10/13/elon-musk-and-friends-are-spending-millions-to-break-out-of-the-matrix/
&gt;  17. https://www.youtube.com/watch?v=qLcma0YyzhY - Elon Musk Flame Thrower
&gt; 18. https://www.yogonet.com/international/noticias/2020/12/07/55695-boring-company-approved-to-expand-its-tunnel-to-encore-at-wynn-las-vegas
&gt;  19. https://www.inverse.com/innovation/tesla-electric-jet-3-4-years-away
&gt; 20. https://blog.torproject.org/critique-website-traffic-fingerprinting-attacks
&gt; 21. https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md
&gt;  22. https://arxiv.org/pdf/1801.02265.pdf - Deep Fingerprinting Tor
&gt; 23. https://www.youtube.com/watch?v=TvjMr6DU7C8 - Raccoon call
&gt; 24. https://www.comsys.rwth-aachen.de/fileadmin/papers/2020/2020-delacadena-trafficsliver.pdf
&gt;  25. https://arxiv.org/abs/2011.13471 - Pulls GA Defense
&gt; 26. https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata
&gt;  27. https://www.full-thesis.net/fragments-of-energy-not-waves-or-particles-may-be-the-fundamental-building-blocks-of-the-universe/4418/
&gt;  28. https://people.cs.umass.edu/~amir/papers/CCS18-DeepCorr.pdf
&gt; 29. https://www.freehaven.net/anonbib/cache/statistical-disclosure.pdf
&gt; 30. https://transparencyreport.google.com/https/overview?hl=en
&gt; 31. https://en.wikipedia.org/wiki/Accelerando#Characters
&gt; 32. https://fahrplan.events.ccc.de/congress/2006/Fahrplan/attachments/1167-SpeakingAnonymously.pdf
&gt;  33. https://www.youtube.com/watch?v=jSRfIMjvtFk - Raccoons and cats &lt;3
&gt; 34. https://edition.cnn.com/2020/04/27/politics/pentagon-ufo-videos/index.html
&gt; 35. https://www.nbcnews.com/news/weird-news/former-israeli-space-security-chief-says-extraterrestrials-exist-trump-knows-n1250333
&gt;  36. https://hackerone.com/torproject
&gt; 37. https://www.msn.com/en-ie/news/coronavirus/during-a-pandemic-isaac-newton-had-to-work-from-home-too-he-used-the-time-wisely/ar-BB118Jyp
&gt;  38. https://www.youtube.com/watch?v=Ofp26_oc4CA - Raccoons are Legion
&gt; 39. https://www.usenix.org/conference/usenixsecurity21/artifact-evaluation-information
&gt;  40. https://petsymposium.org/artifacts.php
&gt; 41. https://en.wikipedia.org/wiki/Liar_paradox
&gt; 42. https://www.youtube.com/watch?v=04_rIuVc_qM - WTF

This is an auspicious number of top-tier references!


&gt; For Karsten:
&gt; https://cs5.livemaster.ru/storage/3a/1f/1449eb23f3c3b318ab4960815fn4--watercolour-watercolor-sad-raccoon.jpg
&gt; 

It is comforting to know that Karsten had friends even among the
raccoons. Probably among the aliens too.


-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email></emails>