<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20110201025006</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-01 02:50:06-0400</timestampReceived><subject>Proposal 176: Proposed version-3 link handshake for Tor</subject><body>

Filename: 176-revising-handshake.txt
Title: Proposed version-3 link handshake for Tor
Author: Nick Mathewson
Created: 31-Jan-2011
Status: Draft
Target: 0.2.3
Supersedes: 169

1. Overview

   I propose a (mostly) backward-compatible change to the Tor
   connection establishment protocol to avoid the use of TLS
   renegotiation, to avoid certain protocol fingerprinting attacks,
   and to make it easier to write Tor clients and servers.

   Rather than doing a TLS renegotiation to exchange certificates
   and authenticate the original handshake, this proposal takes an
   approach similar to Steven Murdoch's proposal 124 and my old
   proposal 169, and uses Tor cells to finish authenticating the
   parties' identities once the initial TLS handshake is finished.

   I discuss some alternative design choices and why I didn't make
   them in section 7; please have a quick look there before
   telling me that something is pointless or makes no sense.

   Terminological note: I use "client" below to mean the Tor
   instance (a client or a bridge or a relay) that initiates a TLS
   connection, and "server" to mean the Tor instance (a bridge or a
   relay) that accepts it.

2. History and Motivation

   The _goals_ of the Tor link handshake have remained basically uniform
   since our earliest versions.  They are:

      * Provide data confidentiality, data integrity
      * Provide forward secrecy
      * Allow responder authentication or bidirectional authentication.
      * Try to look like some popular too-important-to-block-at-whim
        encryption protocol, to avoid fingerprinting and censorship.
      * Try to be implementatble -- on the client side at least! --
        by as many TLS implementations as possible.

   When we added the v2 handshake, we added another goal:

      * Remain compatible with older versions of the handshake
        protocol.

   In the original Tor TLS connection handshake protocol ("V1", or
   "two-cert"), parties that wanted to authenticate provided a
   two-cert chain of X.509 certificates during the handshake setup
   phase.  Every party that wanted to authenticate sent these
   certificates.  The security properties of this protocol are just
   fine; the problem was that our behavior of sending
   two-certificate chains made Tor easy to identify.

   In the current Tor TLS connection handshake protocol ("V2", or
   "renegotiating"), the parties begin with a single certificate
   sent from the server (responder) to the client (initiator), and
   then renegotiate to a two-certs-from-each-authenticating party.
   We made this change to make Tor's handshake look like a browser
   speaking SSL to a webserver.  (See proposal 130, and
   tor-spec.txt.)  So from an observer's point of view, two parties
   performing the V2 handshake begin by making a regular TLS
   handshake with a single certificate, then renegotiate
   immediately.

   To tell whether to use the V1 or V2 handshake, the servers look
   at the list of ciphers sent by the client.  (This is ugly, but
   there's not much else in the ClientHello that they can look at.)
   If the list contains any cipher not used by the V1 protocol, the
   server sends back a single cert and expects a renegotiation.  If
   the client gets back a single cert, then it withholds its own
   certificates until the TLS renegotiation phase.

   In other words, V2-supporting initiator behavior currently looks
   like this:

      - Begin TLS negotiation with V2 cipher list; wait for
        certificate(s).
      - If we get a certificate chain:
         - Then we are using the V1 handshake.  Send our own
           certificate chain as part of this initial TLS handshake
           if we want to authenticate; otherwise, send no
           certificates.  When the handshake completes, check
           certificates.  We are now mutually authenticated.

        Otherwise, if we get just a single certificate:
         - Then we are using the V2 handshake.  Do not send any
           certificates during this handshake.
         - When the handshake is done, immediately start a TLS
           renegotiation.  During the renegotiation, expect
           a certificate chain from the server; send a certificate
           chain of our own if we want to authenticate ourselves.
         - After the renegotiation, check the certificates. Then
           send (and expect) a VERSIONS cell from the other side to
           establish the link protocol version.

   And V2-supporting responder behavior now looks like this:

      - When we get a TLS ClientHello request, look at the cipher
        list.
      - If the cipher list contains only the V1 ciphersuites:
         - Then we're doing a V1 handshake.  Send a certificate
           chain.  Expect a possible client certificate chain in
           response.
        Otherwise, if we get other ciphersuites:
         - We're using the V2 handshake.  Send back a single
           certificate and let the handshake complete.
         - Do not accept any data until the client has renegotiated.
         - When the client is renegotiating, send a certificate
           chain, and expect (possibly multiple) certificates in
           reply.
         - Check the certificates when the renegotiation is done.
           Then exchange VERSIONS cells.

   Late in 2009, researchers found a flaw in most applications' use
   of TLS renegotiation: Although TLS renegotiation does not
   reauthenticate any information exchanged before the renegotiation
   takes place, many applications were treating it as though it did,
   and assuming that data sent _before_ the renegotiation was
   authenticated with the credentials negotiated _during_ the
   renegotiation.  This problem was exacerbated by the fact that
   most TLS libraries don't actually give you an obvious good way to
   tell where the renegotiation occurred relative to the datastream.
   Tor wasn't directly affected by this vulnerability, but the
   aftermath hurts us in a few ways:

      1) OpenSSL has disabled renegotiation by default, and created
         a "yes we know what we're doing" option we need to set to
         turn it back on.  (Two options, actually: one for openssl
         0.9.8l and one for 0.9.8m and later.)

      2) Some vendors have removed all renegotiation support from
         their versions of OpenSSL entirely, forcing us to tell
         users to either replace their versions of OpenSSL or to
         link Tor against a hand-built one.

      3) Because of 1 and 2, I'd expect TLS renegotiation to become
         rarer and rarer in the wild, making our own use stand out
         more.

   Furthermore, there are other issues related to TLS and
   fingerprinting that we want to fix in any revised handshake:

      1) We should make it easier to use self-signed certs, or maybe
         even existing HTTPS certificates, for the server side
         handshake, since most non-Tor SSL handshakes use either
         self-signed certificates or

      2) We should make it harder to probe for a Tor server.  Right
         now, you can just do a handshake with a server,
         renegotiate, then see if it gives you a VERSIONS cell.
         That's no good.

      3) We should allow other changes in our use of TLS and in our
         certificates so as to resist fingerprinting based on how
         our certificates look.

3. Design

3.1. The view in the large

   Taking a cue from Steven Murdoch's proposal 124 and my old
   proposal 169, I propose that we move the work currently done by
   the TLS renegotiation step (that is, authenticating the parties
   to one another) and do it with Tor cells instead of with TLS
   alone.

   This section outlines the protocol; we go into more detail below.

   To tell the client that it can use the new cell-based
   authentication system, the server sends a "V3 certificate" during
   the initial TLS handshake.  (More on what makes a certificate
   "v3" below.)  If the client recognizes the format of the
   certificate and decides to pursue the V3 handshake, then instead
   of renegotiating immediately on completion of the initial TLS
   handshake, the client instead sends a VERSIONS cell (and the
   negotiation begins).

   So the flowchart on the server side is:

      Wait for a ClientHello.
      IF the client sends a ClientHello that indicates V1:
          - Send a certificate chain.
          - When the TLS handshake is done, if the client sent us a
            certificate chain, then check it.
      If the client sends a ClientHello that indicates V2 or V3:
          - Send a  self-signed certificate or a CA-signed certificate
          - When the TLS handshake is done, wait for renegotiation or data.
            - If renegotiation occurs, the client is V2: send a
              certificate chain and maybe receive one.  Check the
              certificate chain as in V1.
            - If the client sends data without renegotiating, it is
              starting the V3 handshake.  Proceed with the V3
              handshake as below.

   And the client-side flowchart is:

      - Send a ClientHello with a set of ciphers that indicates V2/V3.
      - After the handshake is done:
        - If the server sent us a certificate chain, check it: we
          are using the V1 handshake.
        - If the server sent us a single "V2 certificate", we are
          using the v2 handshake: the client begins to renegotiate
          and proceeds as before.
        - Finally, if the server sent us a "v3 certificate", we are
          doing the V3 handshake below.

   And the cell-based part of the V3 handshake, in summary, is:

    C&lt;-&gt;S: TLS handshake where S sends a "v3 certificate"

    In TLS:

       C-&gt;S: VERSIONS cell
       S-&gt;C: VERSIONS cell, CERT cell, AUTH_CHALLENGE cell, NETINFO cell

       C-&gt;S: Optionally: CERT cell, AUTHENTICATE cell

   A "CERTS" cell contains a set of certificates; an "AUTHENTICATE"
   cell authenticates the client to the server.  More on these
   later.

3.2. Distinguishing V2 and V3 certificates

   In the protocol outline above, we require that the client can
   distinguish between v2 certificates (that is, those sent by
   current servers) and a v3 certificates.  We further require that
   existing clients will accept v3 certificates as they currently
   accept v2 certificates.

   Fortunately, current certificates have a few characteristics that
   make them fairly mannered as it is.  We say that a certificate
   indicates a V2-only server if ALL of the following hold:
      * The certificate is not self-signed.
      * There is no DN field set in the certificate's issuer or
        subject other than "commonName".
      * The commonNames of the issuer and subject both end with
        ".net"
      * The public modulus is at most 1024 bits long.

   Otherwise, the client should assume that the server supports the
   V3 handshake.

   To the best of my knowledge, current clients will behave properly
   on receiving non-v2 certs during the initial TLS handshake so
   long as they eventually get the correct V2 cert chain during the
   renegotiation.

   The v3 requirements are easy to meet: any certificate designed to
   resist fingerprinting will likely be self-signed, or if it's
   signed by a CA, then the issuer will surely have more DN fields
   set.  Certificates that aren't trying to resist fingerprinting
   can trivially become v3 by using a CN that doesn't end with .net,
   or using a 1024-bit key.


3.3. Authenticating via Tor cells: server authentication

   Once the TLS handshake is finished, if the client renegotiates,
   then the server should go on as it does currently.

   If the client implements this proposal, however, and the server
   has shown it can understand the V3+ handshake protocol, the
   client immediately sends a VERSIONS cell to the server
   and waits to receive a VERSIONS cell in return.  We negotiate
   the Tor link protocol version _before_ we proceed with the
   negotiation, in case we need to change the authentication
   protocol in the future.

   Once either party has seen the VERSIONS cell from the other, it
   knows which version they will pick (that is, the highest version
   shared by both parties' VERSIONS cells).  All Tor instances using
   the handshake protocol described in 3.2 MUST support at least
   link protocol version 3 as described here.  If a version lower
   than 3 is negotiated with the V3 handshake in place, a Tor
   instance MUST close the connection.

   On learning the link protocol, the server then sends the client a
   CERT cell and a NETINFO cell.  If the client wants to
   authenticate to the server, it sends a CERT cell, an AUTHENTICATE
   cell, and a NETINFO cell, or it may simply send a NETINFO cell if
   it does not want to authenticate.

   The CERT cell describes the keys that a Tor instance is claiming
   to have.  It is a variable-length cell.  Its payload format is:

        N: Number of certs in cell            [1 octet]
        N times:
           CertType                           [1 octet]
           CLEN                               [2 octets]
           Certificate                        [CLEN octets]

   Any extra octets at the end of a CERT cell MUST be ignored.

     CertType values are:
        1: Link key certificate from RSA1024 identity
        2: RSA1024 Identity certificate
        3: RSA1024 AUTHENTICATE cell link certificate

   The certificate format is X509.

   To authenticate the server, the client MUST check the following:
     * The CERTS cell contains exactly one CertType 1 "Link" certificate.
     * The CERTS cell contains exactly one CertType 2 "ID"
       certificate.
     * Both certificates have validAfter and validUntil dates that
       are not expired.
     * The certified key in the Link certificate matches the
       link key that was used to negotiate the TLS connection.
     * The certified key in the ID certificate is a 1024-bit RSA key.
     * The certified key in the ID certificate was used to sign both
       certificates.
     * The link certificate is correctly signed with the key in the
       ID certificate
     * The ID certificate is correctly self-signed.

   If all of these conditions hold, then the client knows that it is
   connected to the server whose identity key is certified in the ID
   certificate.  If any condition does not hold, the client closes
   the connection.  If the client wanted to connect to a server with
   a different identity key, the client closes the connection.


   An AUTH_CHALLENGE cell is a variable-length cell with the following
   fields:
       Challenge [32 octets]
   It is sent from the server to the client.  Clients MUST ignore
   unexpected bytes at the end of the cell.  Servers MUST generate
   every challenge using a strong RNG or PRNG.

3.4. Authenticating via Tor cells: Client authentication

   A client does not need to authenticate to the server.  If it
   does not wish to, it responds to the server's valid CERT cell by
   sending NETINFO cell: once it has gotten a valid NETINFO cell
   back, the client should consider the connection open, and the
   server should consider the connection as opened by an
   unauthenticated client.

   If a client wants to authenticate, it responds to the
   AUTH_CHALLENGE cell with a CERT cell and an AUTHENTICATE cell.
   The CERT cell is as a server would send, except that instead of
   sending a CertType 1 cert for an arbitrary link certificate, the
   client sends a CertType 3 cert for an RSA AUTHENTICATE key.
   (This difference is because we allow any link key type on a TLS
   link, but the protocol described here will only work for 1024-bit
   RSA keys.  A later protocol version should extend the protocol
   here to work with non-1024-bit, non-RSA keys.)

        AuthType                              [2 octets]
        AuthLen                               [2 octets]
        Authentication                        [AuthLen octets]


   Servers MUST ignore extra bytes at the end of an AUTHENTICATE
   cell.  If AuthType is 1 (meaning "RSA-SHA256-TLSSecret"), then the
   Authentication contains the following:

       CID: A SHA256 hash of the client's RSA1024 identity key [32 octets]
       SID: A SHA256 hash of the server's RSA1024 identity key [32 octets]
       SLOG: A SHA256 hash of all bytes sent from the server to the client
         as part of the negotiation up to and including the
         AUTH_CHALLENGE cell; that is, the VERSIONS cell,
         the CERT cell, and the AUTH_CHALLENGE cell. [32 octets]
       CLOG: A SHA256 hash of all byte sent from the client to the
         server as part of the negotiation so far; that is, the
         VERSIONS cell and the CERT cell. [32 octets]
       SCERT: A SHA256 hash of the server's TLS link
         certificate. [32 octets]
       TLSSECRETS: Either 32 zero octets, or a SHA256 HMAC, using
         the TLS master secret as the secret key, of the following:
           - client_random, as sent in the TLS Client Hello
           - server_random, as sent in the TLS Server Hello
           - the NUL terminated ASCII string:
             "Tor V3 handshake TLS cross-certification"
          [32 octets]
       TIME: The time of day in seconds since the POSIX epoch. [8 octets]
       SIG: A signature of a SHA256 hash of all the previous fields
         using the client's "Authenticate" key as presented.  (As
         always in Tor, we use OAEP-MGF1 padding; see tor-spec.txt
         section 0.3.)
          [variable length]

   To check the AUTHENTICATE cell, a server checks that all fields
   containing a hash contain the correct value, then verifies the
   signature.  The server MUST ignore any extra bytes after
   the SHA256 hash.

   When possible (that is, when implemented using C TLS API),
   implementations SHOULD include and verify the TLSSECRETS field.

3.5. Responding to extra cells, and other security checks.

   If the handshake is a V3+ TLS handshake, both parties MUST reject
   any negotiated link version less than 3.  Both parties MUST check
   this and close the connection if it is violated.

   If the handshake is not a V3+ TLS handshake, both parties MUST
   still advertise all link protocols they support in their versions
   cell.  Both parties MUST close the link if it turns out they both
   would have supported version 3 or higher, but they somehow wound
   up using a v2 or v1 handshake.  (More on this in section 6.4.)

   A server SHOULD NOT send any sequence of cells when starting a v3
   negotiation other than "VERSIONS, CERT, AUTH_CHALLENGE,
   NETINFO".  A client SHOULD drop a CERT, AUTH_CHALLENGE, or
   NETINFO cell that appears at any other time or out of sequence.

   A client should not begin a v3 negotiation with any sequence
   other than "VERSIONS, NETINFO" or "VERSIONS, CERT, AUTHENTICATE,
   NETINFO".   A server SHOULD drop a CERT, AUTH_CHALLENGE, or
   NETINFO cell that appears at any other time or out of sequence.

4. Numbers to assign

   We need a version number for this link protocol.  I've been
   calling it "3".

   We need to reserve command numbers for CERT, AUTH_CHALLENGE, and
   AUTHENTICATE.  I suggest that in link protocol 3 and higher, we
   reserve a separate range of commands for variable-length cells.

5. Efficiency

   This protocol adds a round-trip step when the client sends a
   VERSIONS cell to the server, and waits for the {VERSIONS, CERT,
   NETINFO} response in turn.  (The server then waits for the
   client's {NETINFO} or {CERT, AUTHENTICATE, NETINFO} reply,
   but it would have already been waiting for the client's NETINFO,
   so that's not an additional wait.)

   This is actually fewer round-trip steps than required before for
   TLS renegotiation, so that's a win over v2.

6. Security argument

   These aren't crypto proofs, since I don't write those.  They are
   meant be reasonably convincing.

6.1. The server is authenticated

   TLS guarantees that if the TLS handshake completes successfully,
   the client knows that it is speaking to somebody who knows the
   private key corresponding to the public link key that was used in
   the TLS handshake.

   Because this public link key is signed by the server's identity
   key in the CERT cell, the client knows that somebody who holds
   the server's private identity key says that the server's public
   link key corresponds to the server's public identity key.

   Therefore, if the crypto works, and if TLS works, and if the keys
   aren't compromised, then the client is talking to somebody who
   holds the server's private identity key.

6.2. The client is authenticated

   Once the server has checked the client's certificates, the server
   knows that somebody who knows the client's private identity key
   says that he is the one holding the private key corresponding to
   the client's presented link-authentication public key.

   Once the server has checked the signature in the AUTHENTICATE
   cell, the server knows that somebody holding the client's
   link-authentication private key signed the data in question.  By
   the standard certification argument above, the server knows that
   somebody holding the client's private identity key signed the
   data in question.

   So the server's remaining question is: am I really talking to
   somebody holding the client's identity key, or am I getting a
   replayed or MITM'd AUTHENTICATE cell that was previously sent by
   the client?

   If the client included a non-zero TLSSECRET component, and the
   server is able to verify it, then the answer is easy: the server
   knows for certain that it is talking to the party with whom it
   did the TLS handshake, since if somebody else generated a correct
   TLSSECRET, they would have to know the master secret of the TLS
   connection, which would require them to have broken TLS.

   If the client was not able to include a non-zero TLSSECRET
   component, or the server can't check it, the answer is a little
   trickier.  The server knows that it is not getting a replayed
   AUTHENTICATE cell, since the cell authenticates (among other
   stuff) the server's AUTH_CHALLENGE cell, which it has never used
   before.  The server knows that it is not getting a MITM'd
   AUTHENTICATE cell, since the cell includes a hash of the server's
   link certificate, which nobody else should have been able to use
   in a successful TLS negotiation.

6.3. MITM attacks won't work any better than they do against TLS

   TLS guarantees that a man-in-the-middle attacker can't read the
   content of a successfully negotiated encrypted connection, nor
   alter the content in any way other than truncating it, unless he
   compromises the session keys or one of the key-exchange secret
   keys used to establish that connection.  Let's make sure we do at
   least that well.

   Suppose that a client Alice connects to an MITM attacker Mallory,
   thinking that he is connecting to some server Bob.  Let's assume
   that the TLS handshake between Alice and Mallory finishes
   successfully and the v3 protocol is chosen.  [If the v1 or v2
   protocol is chosen, those already resist MITM.  If the TLS
   handshake doesn't complete, then Alice isn't connected to anybody.]

   During the v3 handshake, Mallory can't convince Alice that she is
   talking to Bob, since she should not be able to produce a CERT
   cell containing a certificate chain signed by Bob's identity key
   and used to authenticate the link key that Mallory used during
   TLS.  (If Mallory used her own link key for the TLS handshake, it
   won't match anything Bob signed unless Bob is compromised.
   Mallory can't use any key that Bob _did_ produce a certificate
   for, since she doesn't know the private key.)

   Even if Alice fails to check the certificates from Bob, Mallory
   still can't convince Bob that she is really Alice.  Assuming that
   Alice's keys aren't compromised, Mallory can't sent a CERT cell
   with a cert chain from Alice's identity key to a key that Mallory
   controls, so if Mallory wants to impersonate Alice's identity
   key, she can only do so by sending an AUTHENTICATE cell really
   generated by Alice.  Because Bob will check that the random bytes
   in the AUTH_CHALLENGE cell will influence the SLOG hash, Mallory
   needs to send Bob's challenge to Alice, and can't use any other
   AUTHENTICATE cell that Alice generated before.  But because the
   AUTHENTICATE cell Alice will generate will include in the SCERT
   field a hash of the link certificate used by Mallory, Bob will
   reject it as not being valid to connect to him.

6.4. Protocol downgrade attacks won't work.

   Assuming that Alice checks the certificates from Bob, she knows
   that Bob really sent her the VERSION cell that she received.

   Because the AUTHENTICATE cell from Alice includes signed hashes
   of the VERSIONS cells from Alice and Bob, Bob knows that Alice
   got the VERSIONS cell he sent and sent the VERSIONS cell that he
   received.

   But what about attempts to downgrade the protocol earlier in the
   handshake?  Here TLS comes to the rescue: because the TLS
   Finished handshake message includes an authenticated digest of
   everything previously said during the handshake, an attacker
   can't replace the client's ciphersuite list (to trigger a
   downgrade to the v1 protocol) or the server's certificate [chain]
   (to trigger a downgrade to the v1 or v2 protocol).

7. Design considerations

   I previously considered adding our own certificate format in
   order to avoid the pain associated with X509, but decided instead
   to simply use X509 since a correct Tor implementation will
   already need to have X509 code to handle the other handshake
   versions and to use TLS.

   The trickiest part of the design here is deciding what to stick
   in the AUTHENTICATE cell.  Some of it is strictly necessary, and
   some of it is left there for security margin in case my other
   security arguments fail.  Because of the CID and SID elements
   you can't use an AUTHENTICATE cell for anything other than
   authenticating a client ID to a server with an appropriate
   server ID.  The SLOG and CLOG elements are there mostly to
   authenticate the VERSIONS cells and resist downgrade attacks
   once there are two versions of this.  The presence of the
   AUTH_CHALLENGE field in the stuff authenticated in SLOG
   prevents replays and ensures that the AUTHENTICATE cell was
   really generated by somebody who is reading what the server is
   sending over the TLS connection.  The SCERT element is meant to
   prevent MITM attacks.  When the TLSSECRET field is
   used, it should prevent the use of the AUTHENTICATE cell for
   anything other than the TLS connection the client had in mind.

   A signature of the TLSSECRET element on its own should be
   sufficient to prevent the attacks we care about, but because we
   don't necessarily have access to the TLS master secret when using
   a non-C TLS library, we can't depend on it.  I added it anyway
   so that, if there is some problem with the rest of the protocol,
   clients and servers that _are_ written in C (that is, the official
   Tor implementation) can still be secure.

   If the client checks the server's certificates and matches them
   to the TLS connection link key before proceding with the
   handshake, then signing the contents of the AUTH_CHALLENGE cell
   would be sufficient to authenticate the client.  But implementers
   of allegedly compatible Tor clients have in the past skipped
   certificate verification steps, and I didn't want a client's
   failure to verify certificates to mean that a server couldn't
   trust that he was really talking to the client.  To prevent this,
   I added the TLS link certificate to the authenticated data: even
   if the Tor client code doesn't check any certificates, the TLS
   library code will still check that the certificate used in the
   handshake contains a link key that matches the one used in the
   handshake.

8. Open questions:

  - May we cache which certificates we've already verified?  It
    might leak in timing whether we've connected with a given server
    before, and how recently.

  - With which TLS libraries is it feasible to yoink client_random,
    server_random, and the master secret?  If the answer is "All
    free C TLS libraries", great.  If the answer is "OpenSSL only",
    not so great.

  - Should we do anything to check the timestamp in the AUTHENTICATE
    cell?

  - Can we give some way for clients to signal "I want to use the
    V3 protocol if possible, but I can't renegotiate, so don't give
    me the V2"?  Clients currently have a fair idea of server
    versions, so they could potentially do the V3+ handshake with
    servers that support it, and fall back to V1 otherwise.

  - What should servers that don't have TLS renegotiation do?  For
    now, I think they should just stick with V1.  Eventually we can
    deprecate the V2 handshake as we did with the V1 handshake.
    When that happens, servers can be V3-only.
</body></email><email><emailId>20110302063512</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-03-02 06:35:12-0400</timestampReceived><subject>[tor-dev] Proposal status, with suggestions for fun stuff to do</subject><body>

Hi, everybody!  This is a long mail, but if you're interested in Tor
development, it could be a good one to read.

As promised at the dev meeting, I've spent a while going over all the
current Tor proposals in state "Accepted", "Open", and "Draft", plus
the documents in proposals/ideas.  With any luck, this will help us
move design discussion forward, and point out some neglected
designs/discussions that people could pick up to
specify/improve/implement.

I've also summarized the stuff in proposals/ideas: I think we should
be more aggressive at putting proposal drafts in "Proposals", and in
making a place for design overviews and/or proposal-proposal documents
that are not themselves proposals.

Of course, if you're looking for a programming project, this isn't the
only place to look: you can also head over to the tracker, and look at
the tickets, particularly those with keyword "easy".

If this is useful to people, I'm hoping to do this once every month or two.

(A reminder: We've moved the tor specifications and proposals to their
own repository.  You can get the latest versions from
https://gitweb.torproject.org/torspec.git .  For an overview on how
the proposal process is supposed to work, see proposal 001, at
https://gitweb.torproject.org/torspec.git/HEAD:/proposals/001-process.txt
.)

===== ACCEPTED:

   110  Avoiding infinite length circuits

    This proposal solves a potential DoS attack.

    This has been nearly completely implemented for a while.  All we
    need to do is verify that there are no clients that do not send
    RELAY_EARLY cells correctly, and if so, turn on the code that
    drops EXTEND cells not sent via RELAY_EARLY.  The hard part here
    is double-checking that all the clients that send EXTEND commands
    inside non-RELAY_EARLY cells are really and truly obsolete.

   117  IPv6 exits [for 0.2.1.x]

    This proposal describes how to transmit IPv6 traffic over Tor.

    It needs updating to work properly with microdescriptors; it
    also has some open questions about DNS.

    I think this should move to 'needs-revision'.

   118  Advertising multiple ORPorts at once

    This proposal describes how an OR can advertise more than one
    address and OR port at a time.  It needs to be updated to work
    with microdescriptors, and to explain how much information can
    be transmitted in the consensus and how (the original proposal
    was written before consensus directories were really figured
    out).

    I think this should move to 'needs-revision'

   140  Provide diffs between consensuses

    This proposal describes a way to transmit less directory traffic
    by sending only differences between consensuses, rather than the
    consensuses themselves.  It is mainly languishing for lack of an
    appropriately licensed, well-written, very small, pure-C
    implementation of the "diff" and "patch" algorithms.  (The good
    diffs seem to be GPL (which we can't use without changing Tor's
    license), or spaghetti code, or not easily usable as a library,
    or not written in C, or very large, or some combination of
    those.)

    ACTION: Move to 'needs-revision', or find a suitable library

   147  Eliminate the need for v2 directories in generating v3 directories

    This proposal explains a way that we can phase out the vestigial
    use of v2 directory documents in keeping authorities
    well-informed enough to generating the v3 consensus.  It's still
    correct; somebody should implement it before the v2 directory
    code rots any further.

   157  Make certificate downloads specific

    This proposal added cross-certification and signing-key-specific
    download URLs for directory authority certificates.  It is IIRC
    mostly implemented; there are just some SHOULDs that we should
    turn into MUSTS if all sufficiently old authority certificates
    are now obsolete.

   166  Including Network Statistics in Extra-Info Documents

    I think this one is implemented (or mostly implemented) by
    Karsten in 0.2.2.x.  If so, we just need to make sure it is
    merged into dir-spec, and closed.  Karsten, is there something
    left here?

    (NOTE TO SELF: I should remember to ask Karsten if he doesn't
    notice the above.)

   172  GETINFO controller option for circuit information
   173  GETINFO Option Expansion

    These would help controllers (particularly arm) provide more useful
    information about a running Tor process.  They're accepted and
    some parts of 173 are even implemented: somebody just needs to
    implement the rest.

   174  Optimistic Data for Tor: Server Side

     This proposal would make streams start faster by allowing
     clients to send DATA cells immediately, without waiting for a
     CONNECTED cell.  There's a patch under review as trac ticket
     #1795: it has some issues that need to get fixed before we can
     merge it.  I really want to get it fixed up soon, and merged in
     the next week or two.


=====  OPEN:

   143  Improvements of Distributed Storage for Tor Hidden Service Descriptors

     Here's a proposal from Karsten about making the hidden service
     DHT more reliable and secure to use.  It could use more
     discussion and analysis.

   145  Separate "suitable as a guard" from "suitable as a new guard"

     Currently, the Guard flag means both "You can use this node as
     a guard if you need to pick a new guard" and "If this node is
     currently your guard, you can keep using it as a guard."  This
     proposal tries to separate these two concepts, so that clients
     can stop picking a router once it is full of existing clients
     using it as a guard, but the clients currently on it won't all
     drop it.

     It's not clear whether this has anonymity issues, and it's not
     clear whether the imagined performance gains are actually
     worthwhile.

   146  Add new flag to reflect losing-term stability

     From time to time we get the idea of having clients ship with a
     reasonably recent consensus (or a list of directory mirrors),
     so instead of bootstrapping from one of the authorities, they
     can bootstrap from a regular directory cache.  The problem here
     is that by the time the client is run, most of the directory
     mirrors will be down or will have changed their IP.  This
     proposal tries to address that.

     It needs analysis based on behavior of actual routers on the
     network to see whether it could work, and what parameters might
     work.

   156  Tracking blocked ports on the client side

     This proposal provides a way for clients to learn which ports
     they are (and aren't) able to connect to, and connect to the
     ones that work.  It comes with a patch, too.  It also lets
     routers track ports that _they_ can't connect to.

     I'm a little unconvinced that : most clients that have some ports
     blocked will need bridges, not just restriction to a smaller
     set of ports.  This could be good behind restrictive firewalls,
     though.

     The router-side part is a little iffy: routers that can't
     connect to each other violate one of our network topology
     assumptions, and even if we do want to track failed
     router-&gt;router connections, the routers need to be sure that
     they aren't fooled into trying to connect repeatedly to a
     series of nonexistent addresses in an attempt to make them
     believe that (say) they can't reach port 443.

     This one is a paradigmatic "open" proposal: it needs more
     discussion.  The patch probably also needs to be ported to
     0.2.3.x; it touches some code that has changed.

   158  Clients download consensus + microdescriptors

     This proposal provides a way for clients to download
     authority-provided summaries of router descriptors instead of
     the descriptors themselves; I'm working on this one; it's going
     in 0.2.3.x.  It needs some cleanup, but it's basically right.

     (NOTE TO SELF: Clean this up and move it to "Accepted!")

   159  Exit Scanning

     This is an overview of SoaT, with some ideas for how to
     integrate it into Tor.

     Mike, is this implemented? Done?  Superseded?  Still open?

     (NOTE TO SELF: I should remember to ask Mike if he doesn't
     notice the above.)

   162  Publish the consensus in multiple flavors

     This proposal describes a way for authorities to migrate from
     one format of consensus to another without bloating the
     consensus forever.  It is mostly implemented in 0.2.3.x, though
     some parts of it need to get work.  I should clean it up too.

     (NOTE TO SELF: Clean this up and move it to "Accepted!")

   163  Detecting whether a connection comes from a client

     This one describes a number of ways to distinguish clients from
     non-clients when rejecting single-hop connections.  Some are
     implemented; others are rejected; others are still
     discussable.  Somebody should figure out what happened here,
     and reopen discussion as interested.

   164  Reporting the status of server votes

     This proposal explains a way for authorities to provide a
     slightly more verbose document that relay operators can use to
     diagnose reasons that their router was or was not listed in the
     consensus.  These documents would be like slightly more verbose
     versions of the authorities' votes, and would explain *why* the
     authority voted as it did.  It wouldn't be too hard to
     implement, and would be a fine project for somebody who wants
     to get to know the directory code.

   165  Easy migration for voting authority sets

     This is a design for how to change the set of authorities
     without having a flag day where the authority operators all
     reconfigure their authorities at once.  It needs more
     discussion.  One difficulty here is that we aren't talking much
     about changing the set of authorities, but that may be a
     chicken-and-egg issue, since changing the set is so onerous.

     If anybody is interested, it would be great to move the
     discussion ahead here.

   168  Reduce default circuit window

     This proposal reduces the default window for circuit sendme
     cells.  I think it's implemented, isn't it?  If so, we should
     make sure that tor-spec.txt is updated and close it.

     (NOTE TO SELF: Ask Roger; This should probably be called
     "Finished", or "Closed" if we have updated the spec.)

   171  Separate streams across circuits by connection metadata

     This proposal describes a way to prevent cross-application
     linking of different anonymized sessions by isolating different
     kinds of streams on different circuits based on their
     characteristics.

     I want this one in 0.2.3.x; it would improve client anonymity.
     A patch would be great; there are efficiency issues to
     consider, though.

     ACTION: This should be "accepted", I believe, unless somebody
     has lingering objections.

   176  Proposed version-3 link handshake for Tor

     Here's my proposal for how to improve our TLS handshake to
     eliminate renegotiation, become less fingerprintable, and
     generally make the world a better place.  It needs more review
     by actual crypto people, but I would like to get it into
     0.2.3.x.

   177  Abstaining from votes on individual flags

     Here's my proposal for letting authorities have opinions about
     some (flag,router) combinations without voting on whether
     _every_ router should have that flag.  It's simple, and I think
     it's basically right.  With more discussion and review,
     somebody could/should build it for 0.2.3.x, I think.

===== DRAFT:

   127  Relaying dirport requests to Tor download site / website

    The idea here was to make it easier to fetch and learn about Tor
    by making it easy for relays to automatically act as proxies to
    the Tor website.  It needs more discussion, and there are some
    significant details to work out.  It's not at all clear whether
    this is actually a good idea or not.

   132  A Tor Web Service For Verifying Correct Browser Configuration

    This proposal was meant to give users a way to see if their
    browser and privoxy (yes, it was a while ago) are correctly
    configured by running a local webserver on 127.0.0.1.  I'm not
    sure the status here.

   133  Incorporate Unreachable ORs into the Tor Network

    This proposal had an idea for letting ORs that can only make
    outgoing connections still relay data usefully in the network.
    It's something we should keep in mind, and it's a pretty neat
    idea, but it radically changes the network topology.  Anybody
    who wants to analyze new network topologies should definitely
    have a look.

   141  Download server descriptors on demand

    The idea of this proposal was for clients to only download the
    consensus, and later ask nodes for their own server descriptors
    while building the circuit through them.  It would make each
    circuit more time-consuming to build, but make bootstrapping
    much cheaper.

    A microdescriptor-based version of this would be even better,
    and microdescriptors would solve a lot of the problem that this
    was meant to resolve.  It still is not wholly superseded by the
    microdescriptor system, though.

   144  Increase the diversity of circuits by detecting nodes
belonging the same provider

    This is a version of the good idea, "Let's do routing in a way
    that tries to keep from routing traffic through the same
    provider too much!"  There are complex issues here that the
    proposal doesn't completely address, but I think it might be a
    fine idea for somebody to see how much more we know now than we
    did in 2008, particularly in light of the relevant paper(s) by
    Matt Edmann and Paul Syverson.

   149  Using data from NETINFO cells

    NETINFO cells currently contain time and address information
    that could be used to estimate skew and provide yet another way
    to learn our IP address.  This proposal starts to discuss ways
    that we could try to use that information safely, but doesn't
    really get anywhere.  See trac issues #2628 for some discussion
    about this stuff.  It would be neat if we had a working design
    here, though I suspect that with the slow and grinding death of
    older operating systems, systems with radically skewed clocks
    may become a thing of the past.

   170  Configuration options regarding circuit building

    This is Sebastian's take on how the *Nodes options should work.
    Roger preferred a more minimal approach that may or may not be
    right; see the discussion starting at
    https://trac.torproject.org/projects/tor/ticket/1090#comment:21
    for his approach.  I'm not going to call this "superseded" or
    "rejected" until  my 1090 code is done, though.  :(

   175  Automatically promoting Tor clients to nodes

    Here's Steven's proposal for adding a mode between "client mode"
    and "relay mode" for "self-test to see if you would be a good
    relay, and if so become one."  It didn't get enough attention
    when it was posted to the list; more people should review it.

   178  Require majority of authorities to vote for consensus parameters

    This is a proposal for making it a little harder for a small
    number of authorities to influence the value of a consensus
    parameter.  It needs more discussion; Sebastian has a draft
    implementation in his "safer_params" branch.

    (NOTE TO SELF: I think this could fairly become "open"; I should ask
    Sebastian.)

=====  NEEDS-REVISION:
   131  Help users to verify they are using Tor

     Here's a proposal for making a torcheck-like website more
     reliable.  If anybody wants to pick it up (especially somebody
     working on torcheck) and see whether it should be reopened or
     rejected, that would be a fine thing.

======  "IDEAS":

   xxx-bwrate-algs.txt

     Here's a note about better round-robin calculations for rate
     limiting.  Mike wrote it; I don't understand what's going on
     with it.

   xxx-choosing-crypto-in-tor-protocol.txt

     Here's the start of a considerations document that Marian was
     writing about how to pick new crypto algorithms to migrate to.

   xxx-controllers-intercept-extends.txt

     Here's an old idea from Geoff Goodell about letting controllers
     intercept EXTEND commands.  It is partially superseded by
     Damian's 172, though there is an additional feature that
     doesn't make sense for the Tor network, but might make sense
     for experimental stuff like Geoff was working on.

   xxx-crypto-migration.txt

     Here's the document I wrote in December about which parts of
     our crypto there are to migrate, and what might be involved.
     This isn't a draft or pre-draft of a design proposal; it is
     more of a new category of "survey of stuff we need to design
     and think about", or "proposal for proposals" or something.

   xxx-crypto-requirements.txt

     Here's Robert Ransom's draft for what crypto properties,
     exactly, we're trying to get out of our circuit crypto.
     It is not a proposal draft or pre-draft: it is again a "design
     considerations" document, and one worth reading.

   xxx-draft-spec-for-TLS-normalization.txt

     Here's Jacob's proposal for certificate normalization.  It
     should get renamed, given a proposal number, and called "Open"
     or "Draft" depending on how much the details are likely to
     change.

   xxx-encrypted-services.txt

     This is a start-of-a-proposal of Rogers that somebody should
     pick up and finish some time: The idea is to use the hidden
     service mechanism to provide a secure naming and encrypted
     connection facility for hosting sites that do not actually want
     anonymity themselves.  There's been more interest in this topic
     lately.  It might also turn into "exit enclaves done right".

   xxx-exit-scanning-outline.txt

     Looks like this was superseded by 159?

   xxx-geoip-survey-plan.txt

     Here's an old document I wrote a while ago about tracking usage
     by country.  Probably it should go into the metrics
     documentation somewhere (if we do this), or get thrown into
     "old" (if we won't do this), or updated (if we might someday do
     this).

   xxx-grand-scaling-plan.txt

     Here are some notes on scaling that Roger wrote in 2008.  There
     might be some smart ideas here!  Have a look some time.

   xxx-hide-platform.txt

     Here's a proposal pre-draft that says we should normalize the
     platform string.  Somebody could turn this into a proposal
     pretty easily.

   xxx-ipv6-plan.txt

     Here's a survey of what we need to do for IPv6 support that
     I started writing.  It's not a proposal; it's a survey of
     proposal and implementation statuses.

   xxx-pluggable-transport.txt

     Here's the thing Jacob and I have been working on for pluggable
     obfuscation techniques.  It should get turned into "Draft"
     status asap, if not "Open".  We should finish writing the
     missing sections, like, yesterday.

   xxx-port-knocking.txt

     Here's a pre-proposal from Jacob about using port knocking to
     make bridges harder to fingerprint.  This could be a good idea
     for somebody to do in terms of the pluggable transport spec.

   xxx-rate-limit-exits.txt

     Here are some notes of Roger's from 2008 claiming that we
     should rate-limit stream creation at exit nodes.  It could help
     avoid port-scans if we do it right, but we would need to be
     exceedingly careful not to disrupt useful traffic.

   xxx-using-spdy.txt

     Here's a document from Steven about opportunistic use of SPDY
     over Tor.

     This should be a "Draft" proposal IMO.

   xxx-what-uses-sha1.txt

     Here's the beginnings of a survey of where Tor uses SHA1, with
     an eye to stopping.  This really isn't a design proposal; it
     might fall into a new category of "issue survey" or
     "information" or something.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110405045157</emailId><senderName>"Jonathan \"Duke\" Leto"</senderName><senderEmail>jonathan@leto.net</senderEmail><timestampReceived>2011-04-05 04:51:57-0400</timestampReceived><subject>[tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

Howdy,

Parrot recently added a GSoC proposal idea to embed Parrot into Tor.
It would be great to get the feedback from Tor developers.

Also, this could be under the Parrot or the Tor GSoC project,
whichever makes the most sense.

The proposal idea could use more detail, but the high-level view that
I imagine is:

1) Allow Parrot to talk to libtor (this will use NCI - Native Call
Interface) via PIR
2) Ability to create Parrot interpreter objects from within Tor via C
3) Write glue code for a High Level Language (HLL) to talk to libtor

There are various HLL's to choose from: Lua, TCL, Perl 6, Winxed, NQP
and others.

Duke

Thanks for your help,

Duke

[0] http://trac.parrot.org/parrot/wiki/GSoc2011

-- 
Jonathan "Duke" Leto
jonathan@leto.net
http://leto.net
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110502021746</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-05-02 02:17:46-0400</timestampReceived><subject>[tor-dev] Moving Orbot to Git from SVN</subject><body>

Sebastian,

I believe you are the one to request this of.

We need this repo/path:
https://svn.torproject.org/svn/projects/android/trunk/Orbot/

moved over to a repo on the git server, as soon as you can. I am also
not sure of my credential status on the git server, whether they are the
same as Trac and SVN or not.

It should have happened a long time ago, but now GSoC 2011 is acting as
a catalyst, such that we can properly have our student branch his work.

Best,
 Nathan

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110603004508</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-03 00:45:08-0400</timestampReceived><subject>[tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

Sorry this took so long.  As usual, things got inserted ahead of it in
the priority queue.  :-p

Anyway, here's the client-side sibling proposal to the
already-implemented 174.  It cuts down time-to-first-byte for HTTP
requests by 25 to 50 percent, so long as your SOCKS client (e.g.
webfetch, polipo, etc.) is patched to support it.  (With that kind of
speedup, I think it's worth it.)

Discuss.  ;-)

   - Ian

["xxx-optimistic-data-client.txt" (text/plain)]

Filename: xxx-optimistic-data-client.txt
Title: Optimistic Data for Tor: Client Side
Author: Ian Goldberg
Created: 2-Jun-2011
Status: Open

Overview:

This proposal (as well as its already-implemented sibling concerning the
server side) aims to reduce the latency of HTTP requests in particular
by allowing:
1. SOCKS clients to optimistically send data before they are notified
    that the SOCKS connection has completed successfully
2. OPs to optimistically send DATA cells on streams in the CONNECT_WAIT
    state
3. Exit nodes to accept and queue DATA cells while in the
    EXIT_CONN_STATE_CONNECTING state

This particular proposal deals with #1 and #2.

For more details (in general and for #3), see the sibling proposal 174
(Optimistic Data for Tor: Server Side), which has been implemented in
0.2.3.1-alpha.

Motivation:

This change will save one OP&lt;-&gt;Exit round trip (down to one from two).
There are still two SOCKS Client&lt;-&gt;OP round trips (negligible time) and
two Exit&lt;-&gt;Server round trips.  Depending on the ratio of the
Exit&lt;-&gt;Server (Internet) RTT to the OP&lt;-&gt;Exit (Tor) RTT, this will
decrease the latency by 25 to 50 percent.  Experiments validate these
predictions. [Goldberg, PETS 2010 rump session; see
https://thunk.cs.uwaterloo.ca/optimistic-data-pets2010-rump.pdf ]

Design:

Currently, data arriving on the SOCKS connection to the OP on a stream
in AP_CONN_STATE_CONNECT_WAIT is queued, and transmitted when the state
transitions to AP_CONN_STATE_OPEN.  Instead, when data arrives on the
SOCKS connection to the OP on a stream in AP_CONN_STATE_CONNECT_WAIT
(connection_edge_process_inbuf):

- Check to see whether optimistic data is allowed at all (see below).
- Check to see whether the exit node for this stream supports optimistic
  data (according to tor-spec.txt section 6.2, this means that the
  exit node's version number is at least 0.2.3.1-alpha).  If you don't
  know the exit node's version number (because it's not in your
  hashtable of fingerprints, for example), assume it does *not* support
  optimistic data.
- If both are true, transmit the data on the stream.

Also, when a stream transitions *to* AP_CONN_STATE_CONNECT_WAIT
(connection_ap_handshake_send_begin), do the above checks, and
immediately send any already-queued data if they pass.

SOCKS clients (e.g. polipo) will also need to be patched to take
advantage of optimistic data.  The simplest solution would seem to be to
just start sending data immediately after sending the SOCKS CONNECT
command, without waiting for the SOCKS server reply.  When the SOCKS
client starts reading data back from the SOCKS server, it will first
receive the SOCKS server reply, which may indicate success or failure.
If success, it just continues reading the stream as normal.  If failure,
it does whatever it used to do when a SOCKS connection failed.

Security implications:

ORs (for sure the Exit, and possibly others, by watching the
pattern of packets), as well as possibly end servers, will be able to
tell that a particular client is using optimistic data.  This of course
has the potential to fingerprint clients, dividing the anonymity set.
The usual kind of solution is suggested:

- There is a boolean consensus parameter UseOptimisticData.
- There is a 3-state (-1, 0, 1) configuration parameter
  UseOptimisticData (or give it a distinct name if you like)
  defaulting to -1.
- If the configuration parameter is -1, the OP obeys the consensus
  value; otherwise, it obeys the configuration parameter.

It may be wise to set the consensus parameter to 1 at the same time as
similar other client protocol changes are made (for example, a new
circuit construction protocol) in order to not further subdivide the
anonymity set.

Specification:

The current tor-spec has already been updated by proposal 174 to handle
optimistic data.  It says, in part:

    If the exit node does not support optimistic data (i.e. its version
    number is before 0.2.3.1-alpha), then the OP MUST wait for a
    RELAY_CONNECTED cell before sending any data.  If the exit node
    supports optimistic data (i.e. its version number is 0.2.3.1-alpha
    or later), then the OP MAY send RELAY_DATA cells immediately after
    sending the RELAY_BEGIN cell (and before receiving either a
    RELAY_CONNECTED or RELAY_END cell).

Should the "MAY" be more specific, referring to the consensus
parameters?  Or does the existence of the configuration parameter
override mean it's really "MAY", regardless?

Compatibility:

There are compatibility issues, as mentioned above.  OPs MUST NOT send
optimistic data to Exit nodes whose version numbers predate
0.2.3.1-alpha.  OPs MAY send optimistic data to Exit nodes whose version
numbers match or follow that value.

Implementation:

My git diff is 42 lines long (+17 lines, -1 line), changing only the two
functions mentioned above (connection_edge_process_inbuf and
connection_ap_handshake_send_begin).  This diff does not, however,
handle the configuration options, or check the version number of the
exit node.

I have patched a command-line SOCKS client (webfetch) to use optimistic
data.  I have not attempted to patch polipo, but I have looked at it a
bit, and it seems pretty straightforward.  (Of course, if and when
polipo is deprecated, whatever else speaks SOCKS to the OP should take
advantage of optimistic data.)

Performance and scalability notes:

OPs may queue a little more data, if the SOCKS client pushes it faster
than the OP can write it out.  But that's also true today after the
SOCKS CONNECT returns success, right?


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110801142605</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-08-01 14:26:05-0400</timestampReceived><subject>Re: [tor-dev] [Patch] or/networkstatus.c</subject><body>

On Sun, Jul 31, 2011 at 7:10 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; Hi list.
&gt;
&gt; In or/networkstatus.c there is a "#if 0" block inside the macro
&gt; "SMARTLIST_FOREACH_JOIN". Not all compilers handle such contructs.
&gt; In the prosess of making solution/projects file for "MS Visual C++ 2010
&gt; Express",
&gt; I hit this problem (cl Version 16.00.30319.01). Can you please accept the
&gt; following patch:

The code is if-0'd out; I say we should just remove it in 0.2.3.

(Erinn  and I ran into this issue last week making draft nmake files.)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110823151646</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-08-23 15:16:46-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Karsten Loesing (karsten.loesing@gmx.net):

&gt; 1 Using Trac features
&gt; 
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

https://trac.torproject.org/projects/tor/report/14
https://trac.torproject.org/projects/tor/report/38
https://trac.torproject.org/projects/tor/report/39

&gt; 1.2 What are typical custom queries that you run?

All kinds, but mostly to add extra filters, columns, grouping, and
sorting to existing reports and milestones.

&gt; 1.3 How do you use milestones and roadmaps?

I use milestones to track TBB development and my deliverables for
sponsors.

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

I am subscribed to tor-bugs. It goes into a folder and is unread.

Trac mail sent directly to me as the Owner, Cc, and/or Reporter goes
directly to my inbox, though.
 
&gt; 1.5 Which wiki pages do you read/edit most often?

The abuse templates, chrome bugs, sponsor pages, HTTPS-Everywhere
design.
 
&gt; 1.6 How do you search for wiki pages?

Urlbar history search.

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

I don't use the trac query to find tickets. Also don't use search
engines, as I've not found one capable of deep-indexing trac. If I'm
not at least Cc'd on a ticket, it does not exist to me.
 
&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

Agile iteration tracking keywords.
 
&gt; 1.9 How relevant are the following ticket fields for you?
&gt; 
&gt; 1.9.1 Reported by

Only insofar as it makes trac email the account that is in this field.
 
&gt; 1.9.2 Owned by

Email+knowing which bugs are mine, and who to pester about other bugs.

&gt; 1.9.3 Priority

Useful for iteration and release planning.

&gt; 1.9.4 Milestone

Useful for release planning and sponsor deliverables.
 
&gt; 1.9.5 Component

Useful for reports, release planning, and filing.

&gt; 1.9.6 Version

Don't use it.

&gt; 1.9.7 Keywords

Useful for agile iteration tracking.

&gt; 1.9.8 Cc

Useful for alerting other people to bugs (unless they send all trac
mail to /dev/null).

&gt; 1.9.9 Parent ID

Useful for tickets with many subtasks, either because the task is too
large for one ticket, or because the task spans multiple components.
 
&gt; 1.9.10 Points

Useful for recording an estimate of how long a ticket will take.

Points are also useful for estimating how much work remains to be done
on a given release. The Point completion rate minus the Point open
rate for a release can be used to project when that release will be
ready.

&gt; 1.9.11 Actual Points

Useful for recording the actual amount of time+effort spent on a
ticket.

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt; 
&gt; 1.10.1 accepted

Useless.

&gt; 1.10.2 assigned

Useless.

&gt; 1.10.3 closed

Very useful.

&gt; 1.10.4 needs_information

Useful.

&gt; 1.10.5 needs_review

Somewhat useful.

&gt; 1.10.6 new

Useless.
 
&gt; 1.10.7 reopened

Useless.

&gt; 1.11 What other features do you use in Trac?

Embedded queries. See for example:
https://trac.torproject.org/projects/tor/ticket/3410

&gt; 1.12 What features are you missing in Trac?

1. Git commit hooks.

We should be able to mention "Bug #XXX" at the start
of a commit message and have that commit get posted as a comment to
trac w/ a link to the gitweb url for the commit. I believe we have a
trac plugin for this, but it is not yet properly configured.

At other employers, commits could only go into stable releases if they
referenced a bug # in the first line. I thought this was a good
policy. Back in the SVN days, this property was actually enforcable on
the server. Git may make this bit more difficult..

2. Trac 0.12-stable.

I would like some of the embedded query syntax that is available in
0.12.x-stable of trac. In particular, 0.12 would make it much easier
to compute the rate of Opened tickets against a given project in a
certain period of time.

3. Better handling of duplicate bugs.

The "dup" feature should have a bug field that causes both bugs to be
updated automatically with links to eachother.

4. Field updates should perhaps not send email

Some field updates don't require emailing everybody on the ticket. I
*think* 0.12 might provide the ability to solve this one, too, but I
am not sure.
 
&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?

I think the 'cypherpunk' user should have to add an email address in
the Cc field. If they put mailinator in there, so be it. But they at
least need to know we need to talk to them, or their bugs will
probably just sit around forever.

&gt; 2 Solving typical software development tasks
&gt; 
&gt; Note that the questions below don't just focus on Trac, but on any tools
&gt; or communication media you use for solving a task.
&gt; 
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

Every two weeks I sort the tickets opened against me by priority and
by component. I then take approximately 20 Points worth of tickets and
assign them to that iteration to work on.

As emergency issues arise during this two week period, I give them a
"Fire" keyword for that iteration. I tend to get anywhere from 5 to 20
extra Points of fires in a given two week iteration, with 10 being the
most common.

&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

I mostly use the Sponsor deliverable pages, but I plan to also use the
milestone field.

&gt; 2.3 How do you memorize new ideas to work on when they come up?

If it is development, it goes into trac immediately. Otherwise, it
goes into my personal TODO list, which I try to run similarly to the
trac iterations.

&gt; 2.4 How do you coordinate working together with someone on something?

I first try to use the Cc field in trac. It doesn't always work. I
fall back to IRC, and then email a couple days later. Sometimes I
forget to email and the task falls on the floor and gets forgotten.
 
&gt; 2.5 How do you learn who you could work together with on something?

The trac component owner.
 
&gt; 2.6 What other software development tasks do you have that may be
&gt; supported by Trac or a Trac-like system?

I could envision Trac having better support for agile, but really that
would just amount to it creating graphs of iteration progress rates
and auto-computing ticket completion rates and ticket open rates.
Since all of the agile plugins for trac seem rather invasive, I can do
this myself for now.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110825005305</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-08-25 00:53:05-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On Mon, Aug 22, 2011 at 5:29 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
&gt; Hi everyone!
&gt; 
&gt; 1 Using Trac features
&gt; 
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

None

&gt; 1.2 What are typical custom queries that you run?

Only one:

https://trac.torproject.org/projects/tor/query?status=accepted&amp;status=assigned&amp;status= \
needs_information&amp;status=needs_review&amp;status=new&amp;status=reopened&amp;component=Torctl&amp;order=priority


&gt; 1.3 How do you use milestones and roadmaps?

I do not.

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

tor-bugs only - I read the mail there looking for controller and TorCtl topics.

&gt; 1.5 Which wiki pages do you read/edit most often?

None

&gt; 1.6 How do you search for wiki pages?

I do not.

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

N/A

&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

No

&gt; 1.9 How relevant are the following ticket fields for you?
&gt; 
&gt; 1.9.1 Reported by
&gt; 1.9.2 Owned by
&gt; 1.9.3 Priority
&gt; 1.9.5 Component

Very important

&gt; 1.9.4 Milestone
&gt; 1.9.6 Version
&gt; 1.9.7 Keywords
&gt; 1.9.8 Cc
&gt; 1.9.9 Parent ID
&gt; 1.9.10 Points
&gt; 1.9.11 Actual Points

Not at all

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt; 
&gt; 1.10.1 accepted
&gt; 1.10.2 assigned

Not at all

&gt; 1.10.3 closed
&gt; 1.10.4 needs_information
&gt; 1.10.5 needs_review
&gt; 1.10.6 new
&gt; 1.10.7 reopened

Important

&gt; 1.11 What other features do you use in Trac?

I am subscribed to a Trac-based RSS feed watching the above Custom Query.

&gt; 1.12 What features are you missing in Trac?

I would have preferred the ability to receive emails for any changes
related to a specific component (i.e. TorCtl).

&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?
&gt; 
&gt; 2 Solving typical software development tasks
&gt; 
&gt; Note that the questions below don't just focus on Trac, but on any tools
&gt; or communication media you use for solving a task.
&gt; 
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

Whatever catches my interest.

&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

N/A

&gt; 2.3 How do you memorize new ideas to work on when they come up?

Local TODO list.

&gt; 2.4 How do you coordinate working together with someone on something?

Mailing list and Trac

&gt; 2.5 How do you learn who you could work together with on something?

Ask on the mailing list and read Trac tickets to see who is working on
the component.

&gt; 2.6 What other software development tasks do you have that may be
&gt; supported by Trac or a Trac-like system?

None


-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110825010957</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-08-25 01:09:57-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Sean Robinson (seankrobinson@gmail.com):

&gt; &gt; 1.10 How relevant are the following ticket statuses for you?
&gt; &gt;
&gt; &gt; 1.10.1 accepted
&gt; &gt; 1.10.2 assigned
&gt; 
&gt; Not at all
&gt; 
&gt; &gt; 1.10.3 closed
&gt; &gt; 1.10.4 needs_information
&gt; &gt; 1.10.5 needs_review
&gt; &gt; 1.10.6 new
&gt; &gt; 1.10.7 reopened
&gt; 
&gt; Important

Out of curiosity, what makes having both "new" and "reopened"
useful? 

I find the numerous ticket statuses to be a pain when using the query
interface, and in my mind "assigned", "accepted", "new", and
"reopened" basically all mean the same thing.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110829000521</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-08-29 00:05:21-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On Wed, Aug 24, 2011 at 6:09 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; Thus spake Sean Robinson (seankrobinson@gmail.com):
&gt;
&gt;&gt; &gt; 1.10 How relevant are the following ticket statuses for you?
&gt;&gt; &gt;
&gt;&gt; &gt; 1.10.1 accepted
&gt;&gt; &gt; 1.10.2 assigned
&gt;&gt;
&gt;&gt; Not at all
&gt;&gt;
&gt;&gt; &gt; 1.10.3 closed
&gt;&gt; &gt; 1.10.4 needs_information
&gt;&gt; &gt; 1.10.5 needs_review
&gt;&gt; &gt; 1.10.6 new
&gt;&gt; &gt; 1.10.7 reopened
&gt;&gt;
&gt;&gt; Important
&gt;
&gt; Out of curiosity, what makes having both "new" and "reopened"
&gt; useful?
&gt;
&gt; I find the numerous ticket statuses to be a pain when using the query
&gt; interface, and in my mind "assigned", "accepted", "new", and
&gt; "reopened" basically all mean the same thing.

  I like them as a way to track where the ticket is in its lifetime.
The difference between "new" and "reopened" for me is whether this is
a brand new ticket or a continuing problem.  "Reopened", to me, is
also a sign of disagreement between the reporter and the maintainer
about the value or status of the ticket.

  Yes, I agree that "assigned", "accepted", and "new" seem too
fine-grained in their meaning to an external audience.  I suppose
these might be useful in a hierarchically staffed project where one
assigns/tracks tickets that one does not work on oneself.  As an
outsider to the TOR project, I don't know whether these make sense
here.


-- 
Sean Robinson
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110829084851</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-08-29 08:48:51-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 8/22/11 2:29 PM, Karsten Loesing wrote:
&gt; Hi everyone!
&gt; 
&gt; At the last annual dev meeting in Waterloo we had a very productive
&gt; discussion about managing the various channels of Tor communication:
&gt; 
&gt; 
&gt; https://trac.torproject.org/projects/tor/wiki/org/meetings/2011TorAnnualDevMeeting/FirehoseOutput
&gt; 
&gt; Related to that discussion, we should talk about how we use Tor's Trac
&gt; system, or more generally how we manage our Tor tasks.  We use Trac as
&gt; issue tracker, wiki, and for project management.  But it seems that
&gt; everyone uses Trac slightly different and has their own expectations how
&gt; other people use it.  This can slow us down.  In addition to that, some
&gt; people may not know how Trac can solve their problems.  Knowing how
&gt; others use Trac might help them manage their tasks more quickly.  Let's
&gt; conduct a survey!
&gt; 
&gt; The survey below consists of two parts:  The first part focuses on
&gt; Trac's features and whether you're using them or not.  The second part
&gt; is about managing your tasks in general, either with or without Trac.
&gt; 
&gt; If you are a Tor developer or volunteer or think you have some input on
&gt; the topic, please fill out this survey until
&gt; 
&gt;   Sunday, August 28, 2011
&gt; 
&gt; and send it either to this list or to me.  I'll try to summarize what
&gt; was said and send the survey results to this list, hopefully before the
&gt; end of the month.

So far, 7 people replied to the survey and I got 1 request to extend the
deadline.  I think it's best to wait for another week if that means
we'll get feedback from more Tor developers and volunteers.  After all,
we might use the survey results to discuss changes to using Trac in the
future.

The new deadline is

  Sunday, September 4, 2011

Dear Tor developers and volunteers who haven't responded yet: If you
have an opinion on using Trac, please let us know!

Thanks,
Karsten



1 Using Trac features

1.1 Which of the reports (stored ticket queries) do you use most often?

1.2 What are typical custom queries that you run?

1.3 How do you use milestones and roadmaps?

1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
you use the mails sent to these lists?

1.5 Which wiki pages do you read/edit most often?

1.6 How do you search for wiki pages?

1.7 What are typical search terms that you use when using the search
features?

1.8 Do you use keywords and the tags page, and if so, what are keywords
that you typically use?

1.9 How relevant are the following ticket fields for you?

1.9.1 Reported by

1.9.2 Owned by

1.9.3 Priority

1.9.4 Milestone

1.9.5 Component

1.9.6 Version

1.9.7 Keywords

1.9.8 Cc

1.9.9 Parent ID

1.9.10 Points

1.9.11 Actual Points

1.10 How relevant are the following ticket statuses for you?

1.10.1 accepted

1.10.2 assigned

1.10.3 closed

1.10.4 needs_information

1.10.5 needs_review

1.10.6 new

1.10.7 reopened

1.11 What other features do you use in Trac?

1.12 What features are you missing in Trac?

1.13 What features would you want our Trac not to offer anymore, because
they're making things only more confusing for you (and for people who
are new to Tor)?

2 Solving typical software development tasks

Note that the questions below don't just focus on Trac, but on any tools
or communication media you use for solving a task.

2.1 How do you decide what to work on, both when fixing bugs or when
implementing new features?

2.2 How do you keep track of what things you're supposed to do for
sponsors and for when?

2.3 How do you memorize new ideas to work on when they come up?

2.4 How do you coordinate working together with someone on something?

2.5 How do you learn who you could work together with on something?

2.6 What other software development tasks do you have that may be
supported by Trac or a Trac-like system?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110901000234</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-09-01 00:02:34-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; &gt; 1.12 What features are you missing in Trac?
&gt; 
&gt; 1. Git commit hooks.
&gt; 
&gt; We should be able to mention "Bug #XXX" at the start
&gt; of a commit message and have that commit get posted as a comment to
&gt; trac w/ a link to the gitweb url for the commit. I believe we have a
&gt; trac plugin for this, but it is not yet properly configured.
&gt; 
&gt; At other employers, commits could only go into stable releases if they
&gt; referenced a bug # in the first line. I thought this was a good
&gt; policy. Back in the SVN days, this property was actually enforcable on
&gt; the server. Git may make this bit more difficult..
&gt; 
&gt; 2. Trac 0.12-stable.
&gt; 
&gt; I would like some of the embedded query syntax that is available in
&gt; 0.12.x-stable of trac. In particular, 0.12 would make it much easier
&gt; to compute the rate of Opened tickets against a given project in a
&gt; certain period of time.
&gt; 
&gt; 3. Better handling of duplicate bugs.
&gt; 
&gt; The "dup" feature should have a bug field that causes both bugs to be
&gt; updated automatically with links to eachother.
&gt; 
&gt; 4. Field updates should perhaps not send email
&gt; 
&gt; Some field updates don't require emailing everybody on the ticket. I
&gt; *think* 0.12 might provide the ability to solve this one, too, but I
&gt; am not sure.
&gt;  
&gt; &gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; &gt; they're making things only more confusing for you (and for people who
&gt; &gt; are new to Tor)?
&gt; 
&gt; I think the 'cypherpunk' user should have to add an email address in
&gt; the Cc field. If they put mailinator in there, so be it. But they at
&gt; least need to know we need to talk to them, or their bugs will
&gt; probably just sit around forever.

I'd like to add the following feature requests to my poll results:

5. Prevent trac from emailing you about your own changes

always_notify_updater = false in trac.ini is close to this, but it is
not exactly what I want. I think it is useful to automatically notify
previous updaters via email, but it seems silly to send me mail for my
own changes. Yet there is only one option for both behaviors in trac..

I could see setting it to false and just being more careful about
adding people to the Cc line as a stopgap.

6. Embargoed/Security tickets

For serious security issues, it would be nice to be able to make
tickets not viewable by accounts not on the Cc, owner, or reporter
lines of the ticket. I don't think trac can do this at all.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110901134954</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2011-09-01 13:49:54-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

Hi Karsten,

things I didn't answer either don't apply to me for some reason, or I
don't use them (if they're Trac fields) or I have nothing to say  for
other reasons.

On Mon, Aug 22, 2011 at 2:29 PM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:

&gt; 1 Using Trac features
&gt;
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

BridgeDB Tickets
GetTor Tickets
Weather Tickets

&gt; 1.2 What are typical custom queries that you run?

Depends. Nothing noteworthy I'd say

&gt; 1.3 How do you use milestones and roadmaps?
&gt;
&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

I filter tor-bugs mails to look for BridgeDB, GetTor and Weather bugs/updates.

&gt; 1.5 Which wiki pages do you read/edit most often?
&gt;
&gt; 1.6 How do you search for wiki pages?
&gt;
&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?
&gt;
&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?
&gt;
&gt; 1.9 How relevant are the following ticket fields for you?
&gt;
&gt; 1.9.1 Reported by

Important

&gt; 1.9.2 Owned by

Important

&gt; 1.9.3 Priority

Somewhat important. This is sometimes used very subjectively by
submitters. "NEEDS TO BE FIXED ASAP OR THE WORLD ENDS!!!!!111eleven"
;-)

&gt; 1.9.4 Milestone
&gt;
&gt; 1.9.5 Component

Important

&gt; 1.9.6 Version
&gt;
&gt; 1.9.7 Keywords
&gt;
&gt; 1.9.8 Cc
&gt;
&gt; 1.9.9 Parent ID
&gt;
&gt; 1.9.10 Points
&gt;
&gt; 1.9.11 Actual Points
&gt;
&gt; 1.10 How relevant are the following ticket statuses for you?
&gt;
&gt; 1.10.1 accepted
&gt;
&gt; 1.10.2 assigned

Important

&gt; 1.10.3 closed

Important

&gt; 1.10.4 needs_information
&gt;
&gt; 1.10.5 needs_review

Important

&gt; 1.10.6 new
&gt;
&gt; 1.10.7 reopened
&gt;
&gt; 1.11 What other features do you use in Trac?
&gt;
&gt; 1.12 What features are you missing in Trac?
&gt;
&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?
&gt;
&gt; 2 Solving typical software development tasks
&gt;
&gt; Note that the questions below don't just focus on Trac, but on any tools
&gt; or communication media you use for solving a task.
&gt;
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

By priority, usually putting out the most important fires on one of
the services like BridgeDB/GetTor/Weather. Usually these important
things come up via IRC conversations or Trac tickets. When I'm looking
for work otherwise, I look through Trac.

&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

Currently doesn't apply to me.

&gt; 2.3 How do you memorize new ideas to work on when they come up?

Trac.

&gt; 2.4 How do you coordinate working together with someone on something?

Usually via IRC or email.

&gt; 2.5 How do you learn who you could work together with on something?

By chance, IRC or email.

&gt; 2.6 What other software development tasks do you have that may be
&gt; supported by Trac or a Trac-like system?

None.

Hope this helps,
/C
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110901195653</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-09-01 19:56:53-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On Mon, Aug 22, 2011 at 8:29 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:

&gt;
&gt; 1 Using Trac features
&gt;
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

I don't use the reports; in the time that it takes me to confirm that
a report will actually give me the ticket that I want, I

&gt; 1.2 What are typical custom queries that you run?

Look for every open ticket in a Tor milestone.

Look for every open ticket on a given non-Tor component

Look for every open ticket on Tor client, Tor server, Tor bridge, Tor
directory authority, Tor hidden services.

&gt; 1.3 How do you use milestones and roadmaps?

I assign Tor tickets to milestones when I'm pretty sure it'd be a good
idea to do them for that milestone.

I've make a wiki page for the stuff I want to get done for 0.2.3.x.

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

Yes; I read all the mails that are sent to those lists that pertain to
components I work on.

&gt; 1.5 Which wiki pages do you read/edit most often?

Currently, https://trac.torproject.org/projects/tor/wiki/org/roadmaps/Tor/023
and the various sponsor deliverable pages.

&gt; 1.6 How do you search for wiki pages?

I go to the Index page and scroll or search on it.

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

n/a

&gt;
&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

no

&gt; 1.9 How relevant are the following ticket fields for you?
&gt;
&gt; 1.9.1 Reported by

not really

&gt; 1.9.2 Owned by

nope.

&gt; 1.9.3 Priority

Within milestones and components, I frequently sort by priority.

If it's "major", it's something I *definitely* want to get done for
the next release if possible.  If it's "minor" or lower, it's nice to
have, but could slip without severe consequence.  If it is "critical"
or "blocker", then I assume either that it is a crash bug that makes
the network unusable for people, that it is a security bug that is
compromising users, or that somebody is being melodramatic.

&gt; 1.9.4 Milestone

I use milestones a lot.  Stuff that is assigned to a "Tor: x-final"
milestone means that it's something we should consider for backport
(if the milestone is older), or stuff that we should do for an
upcoming release (if the milestone is newer)

&gt; 1.9.5 Component

Somewhat important, but there are so many Tor components that just
refer to the software "tor" that I often find myself just looking at
milestones instead.

&gt; 1.9.6 Version

Relevant, though I don't believe it unless the person reporting the
bug actually says "I'm using version foo" in the comments, since
people often get this wrong.

&gt; 1.9.7 Keywords

I assign "easy" to bugs I think are easy to fix. I don't read or
search on keywords much.

&gt; 1.9.8 Cc

I get all the bug mail, so I don't mess with this.

&gt; 1.9.9 Parent ID

Very important; this is how I cluster related bugs and implementation steps.

&gt; 1.9.10 Points
&gt; 1.9.11 Actual Points

I don't use these.

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt;
&gt; 1.10.1 accepted
&gt; 1.10.2 assigned
&gt; 1.10.6 new
&gt; 1.10.7 reopened

These are all identical from my POV.  The distinction between them is
not something I pay attention to.

&gt; 1.10.3 closed

This is the desired end state for all bugs. Very important.

&gt; 1.10.4 needs_information

This state is kinda important.  It means to me, "can't do more here
without feedback."

&gt; 1.10.5 needs_review

Very important.  I try to respond to these first.


&gt; 1.11 What other features do you use in Trac?

Just the tracker and the wiki

&gt; 1.12 What features are you missing in Trac?

I wish I could assign bugs to multiple milestones.

&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?

I don't know what confuses others, but IMO the proliferation of
components that are all "tor" doesn't help me, and makes stuff
slightly harder.

&gt; 2 Solving typical software development tasks
&gt;
&gt; Note that the questions below don't just focus on Trac, but on any tools
&gt; or communication media you use for solving a task.
&gt;
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

I skim the stuff for the relevant milestones weekly, and look at the
023 roadmap when I'm done with a major task.

&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

I'm trying to use
https://trac.torproject.org/projects/tor/wiki/org/roadmaps/Tor/023,
and periodically consult the per-sponsors deliverable pages.

&gt; 2.3 How do you memorize new ideas to work on when they come up?

I don't think I memorize ideas to work on when they come up; I open a
new ticket, or ask the person who's enthusiastic about the new idea to
do so.

&gt; 2.4 How do you coordinate working together with someone on something?

IRC and trac tickets, usually.

&gt; 2.5 How do you learn who you could work together with on something?

IRC and needs_review tickets, usually

&gt; 2.6 What other software development tasks do you have that may be
&gt; supported by Trac or a Trac-like system?

It would be neat to have better code review tools.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110902002411</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-09-02 00:24:11-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On Monday, August 22, 2011 08:29:09 Karsten Loesing wrote:

&gt; 1 Using Trac features
&gt; 
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

All tickets, mine first

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

tor-bugs, as review of all tickets with changes.

&gt; 1.5 Which wiki pages do you read/edit most often?
&gt; 1.6 How do you search for wiki pages?

index page.  trac search is useless for finding any information on the trac.  
ddg or google are better at finding info on our trac.
&gt; 1.10 How relevant are the following ticket statuses for you?
&gt; 1.10.1 accepted
&gt; 1.10.4 needs_information
&gt; 1.10.6 new

I use 'new' to mean 'haven't thought about it yet'.  I use 'accepted' to mean 
I've thought about it and have a plan. I use 'needs_information' to mean the 
user needs to provide info to me before further progress.

&gt; 1.11 What other features do you use in Trac?

I use the timeline heavily to see what's changed.  I mostly subscribe to RSS 
feeds of tickets, wiki pages, and timeline to keep track of the various bits 
that are relevant to me.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110902095317</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-02 09:53:17-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your	tasks</subject><body>

On Mon, Aug 22, 2011 at 02:29:09PM +0200, Karsten Loesing wrote:
&gt; 1 Using Trac features
&gt; 
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

Basically none of them. Every once in a while I use
"{12} Tor: Active Tickets by Milestone"

&gt; 1.2 What are typical custom queries that you run?

In almost every case it is "custom query", press the "-" to get rid of
the "owner is arma" constraint, scroll down on add filter to 'component',
click somewhere so the new box appears, then pick the component I wanted
to get a list of trac tickets on.

If it's a big component, I put a bigger number into "max items per page"
so I can see all the tickets I asked for (and be able to search their
titles using ^F).

&gt; 1.3 How do you use milestones and roadmaps?

I use the Tor 0.2.x.y-final milestones to categorize Tor tickets by which
version they should go in. I don't pick (or look at) milestones on non
tor components, since I assume people have their own policies that vary
by component.

By 'roadmap', do you mean https://trac.torproject.org/projects/tor/roadmap
? If so, I don't use it. In fact, I went so far as to make my own
roadmap-like thing for Tor 0.2.2:
https://trac.torproject.org/projects/tor/ticket/3032

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

I'm subscribed to tor-bugs. I put them in a separate mailbox. If I'm not
travelling, I read them all and use them to know which tickets other
people are active on, so I can be most useful at helping them make
progress. If I am travelling, I let them pile up and generally don't
look back.

I run a nightly r2e on the trac wiki rss. I generally delete the mails
it sends me, unread -- mostly because the wiki notification mails don't
have any useful content about what changed, and getting a useful diff
is too klunky to be worth it. ("Besides, they're just wiki pages.")

&gt; 1.5 Which wiki pages do you read/edit most often?

I use the wiki faq page to point people to faq entries that haven't been
transitioned yet. (Basically nobody knows about the wiki faq now that
we moved the faq over, but we left most of the answers on the wiki. Oops.)

I use the sponsor pages, mostly sponsorf, to remind myself of the various
things we've promised, and to help keep them updated on our progress. I'm
happy to hand the 'keeping them updated' part to somebody else though.

&gt; 1.6 How do you search for wiki pages?

In my browser history. All the important ones (there aren't many)
are there.

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

A few times I've tried searching for trac tickets using phrases I
remembered from them. It always gave me way too many pages, and they
were not easy to thumb through, so I stopped.

&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

Woah, there's a tag page?

I use the keyword 'easy' sometimes, but ignore keywords generally.

&gt; 1.9 How relevant are the following ticket fields for you?
&gt; 
&gt; 1.9.1 Reported by

Important, since it tells me how likely the trac ticket is to make sense.

&gt; 1.9.2 Owned by

Important, since it tells me either who has promised to work on the
ticket, or who somebody else hoped would work on the ticket.

&gt; 1.9.3 Priority

Important. I can signal to other people whether I feel strongly that
the task should be done (major) or think it's not a big deal or at least
not a big deal soon (minor).

&gt; 1.9.4 Milestone

Important for the Tor-component tickets. I don't pay attention to it
for other components.

&gt; 1.9.5 Component

Important since it tells me who is (hopefully) paying attention to the
ticket.

&gt; 1.9.6 Version

I try to fill this one in when I can, but the consistency here is so
spotty that we would not lose much if it disappeared (especially since
it's most useful for bug reports, which mostly come from users who don't
successfully report the right version).

&gt; 1.9.7 Keywords

I ignore it.

&gt; 1.9.8 Cc

We've been using this one increasingly. People who've added themselves
to the cc list indicate that they care about this ticket in particular.
Sometimes I add people to the cc list to indicate that I think they
should care -- but I try to do that only for people that I've witnessed
signing themselves up to some cc list.

&gt; 1.9.9 Parent ID

Rarely used, but relevant when it is used.

&gt; 1.9.10 Points
&gt; 1.9.11 Actual Points

Mike uses these to trac his agile hours. It's a little bit interesting
to see him learn lessons from attempting estimates, but I wouldn't miss
them if they disappeared.

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt; 
&gt; 1.10.1 accepted

I treat this as equivalent to 'new' for most people, and equivalent to
'assigned' for a few people. Not all that useful.

&gt; 1.10.2 assigned

If somebody assigned a ticket to themselves, it's meaningful. If somebody
else assigned it, like happens automatically when you switch a ticket
from one component to another, it's not all that useful.

&gt; 1.10.3 closed

Very important. If we couldn't close tickets, where would we be? :)

&gt; 1.10.4 needs_information

New but promising.

&gt; 1.10.5 needs_review

Very useful. It means there's a patch I should read.

&gt; 1.10.6 new
&gt; 1.10.7 reopened

I wouldn't mind if these merged, but there is a little bit of information
to be gained by knowing that somebody thought it was fixed and somebody
thought it wasn't.

&gt; 1.11 What other features do you use in Trac?

Nothing else comes to mind. I spend most of my trac time going to a
specific trac ticket using a number I found in my tor-bugs mailbox,
looking over the whole discussion, and adding a comment.

&gt; 1.12 What features are you missing in Trac?

Listing tickets for a given component could sure be easier.

One of the main problems we have in general is the proliferation of
tickets. Originally that was a good thing -- "have something we need to
do? Make a ticket, then we'll remember." But now we have so many darn
tickets, especially in some components, that they're tough to manage,
which leads to less active maintenance, which leads to having it get even
more out of control. I'm not sure what to do about it, but sometimes it
makes me less excited to add more tickets since I feel like I'm adding
to the problem. So some feature to do large-scale ticket management
would be good.

&gt; 2 Solving typical software development tasks
&gt; 
&gt; Note that the questions below don't just focus on Trac, but on any tools
&gt; or communication media you use for solving a task.
&gt; 
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

I generally pull from a) whatever is on my todo list, b) whatever people
are working on on irc, and c) whatever is arriving to my tor-bugs mailbox.

Often the urgent items on my todo list are not development tasks, so I
use development work as a break from the 'real' work.

&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

They're on the sponsors wiki pages. As they get closer I move them to my
internal todo file. Recently I've started keeping my todo list in three
priority categories ("rsn, soon, and eventually") so hopefully others
can have a better chance of following along or predicting me.

&gt; 2.3 How do you memorize new ideas to work on when they come up?

Ideally I make a trac ticket about them right then. Otherwise (offline
or no time), I put a line in a todo list somewhere, which sometimes
works out and sometimes gets lost.

&gt; 2.4 How do you coordinate working together with someone on something?

For a lot of the topics I work on (e.g. being at the center of the
research web, or keeping people informed about other parts of the Tor
world they need to know about), I coordinate via eventually sending
emails. There isn't really that much near-term interaction.

Aside from the (increasingly small amount of) development work I do,
a lot of my interactions are helping everybody to move forward on their
own tasks, helping people know the big picture of where we should go,
keeping track of what everybody is up to, and helping to grow the
community. A lot of this happens in person, and some happens over irc.

I would be a more useful developer if I ignored the big picture more,
and then picked out more deep Tor bugs/features to work on. But I can'd
do that and also be keeping the big picture in my head to interact
with other communities, funders, etc. In any case, that's a topic for
a different thread. :)

&gt; 2.5 How do you learn who you could work together with on something?

By watching trac, irc, the mailing lists, and interacting with people
in person, I try to know generally what everybody is up to. Then *I*
can be one of the people that people can come to when they want to know
who else would be a good match for some project.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111003153254</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-10-03 15:32:54-0400</timestampReceived><subject>[tor-dev] Reminder: less than two months left for getting big</subject><body>

Hi, all! This is a reminder about the planned schedule for 0.2.3.x.

See http://archives.seul.org/or/dev/Jul-2011/msg00030.html for the
original announcment.

December 1 is the deadline for getting large features and complicated
bugfixes merged into 0.2.3.x.

January 6 is the deadline for new features and marginal bugfixes.

Please plan accordingly!

cheers,
--
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111003233236</emailId><senderName>Steve Snyder</senderName><senderEmail>swsnyder@snydernet.net</senderEmail><timestampReceived>2011-10-03 23:32:36-0400</timestampReceived><subject>Re: [tor-dev] Reminder: less than two months left for getting big</subject><body>

On 10/03/2011 11:32 AM, Nick Mathewson wrote:
&gt; Hi, all! This is a reminder about the planned schedule for 0.2.3.x.

A related question: is there a document somewhere that lists the changes 
(new features, changed behavior, etc.) in 0.2.3.x relative to 0.2.2.x?

Thanks.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110905222357</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-09-05 22:23:57-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 2011-08-22, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; 1 Using Trac features
&gt;
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

I just used https://trac.torproject.org/projects/tor/report/40 (Tor
tickets by milestone) today as a starting point to find a submitted
patch that I had forgotten to put in needs_review when I saw it in
#tor-bots (#3923).  I also used
https://trac.torproject.org/projects/tor/report/23 (Tor tickets
needing review), and I think I've used it more than once before today.

&gt; 1.2 What are typical custom queries that you run?

I frequently search for tickets in a component with the default set of
statuses, and sometimes search for all closed tickets in a component.
I have also used the default custom query (Owner = me) fairly
frequently.

I occasionally search for tickets containing a keyword in the summary
or description fields, mainly when I'm looking for a particular closed
ticket whose number I have forgotten in a component containing many
tickets.

&gt; 1.3 How do you use milestones and roadmaps?

I use the 'Milestone' ticket field to indicate which version of Tor a
bugfix or feature needs to be applied to.  I would do that with
Vidalia, too, but there is no Vidalia 0.2.x milestone.

What are roadmaps?

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

I am subscribed to tor-bugs.  Back when I was using a tolerable MUA, I
used unread tor-bugs messages to indicate tickets that I needed to
work on or monitor.  Now tor-bugs just fills my unusable inbox.

I am not subscribed to tor-wiki-changes, and I would not subscribe to
it even if I could read the messages.

&gt; 1.5 Which wiki pages do you read/edit most often?

None.

&gt; 1.6 How do you search for wiki pages?

I type "https://trac.torproject.org/projects/tor/wiki/TitleIndex" into
Firefox's URL bar and vgrep the list.  If I'm looking for a wiki page,
I usually know the last component of its title, but I no longer know
its exact URL.

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

If a search term were typical, I would bookmark the wiki page or
remember the ticket number.

&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

I use the 'easy' keyword for tickets that I suspect would be trivial
for someone who knows how to use grep and a TAGS file to
fix/implement.

What is 'the tags page'?

&gt; 1.9 How relevant are the following ticket fields for you?
&gt;
&gt; 1.9.1 Reported by

Very useful for finding tickets that I have filed.

&gt; 1.9.2 Owned by

Useful.

&gt; 1.9.3 Priority

I use this field to indicate the severity of a bug or lack of feature.

&gt; 1.9.4 Milestone

See above.  Very important for tickets on Tor itself; would be
important for Vidalia tickets if I could use it; not useful for
anything else.

&gt; 1.9.5 Component

Very important.

&gt; 1.9.6 Version

Useless.  Current versions of products are never in the list.

&gt; 1.9.7 Keywords

Useless.  No one looks for 'easy' tickets.  Other keywords are chosen
too haphazardly to be useful (usually by users who have never used our
bug tracker before).

&gt; 1.9.8 Cc

Only useful for CC-ing people that notice when they are on a ticket's
CC list (i.e. Erinn), and only useful since yesterday (when Erinn gave
me the Trac permission needed to set the CC field arbitrarily).
Previously, I could only set the CC field when creating a new ticket
or add/remove myself in the CC list; the latter was useless.

&gt; 1.9.9 Parent ID

Rarely useful.

&gt; 1.9.10 Points

DIE DIE DIE

&gt; 1.9.11 Actual Points

DIE DIE DIE

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt;
&gt; 1.10.1 accepted

Equivalent to 'assigned', 'new', and 'reopened'.

&gt; 1.10.2 assigned

Indicates that a ticket's owner has been changed from the default
owner for its component.

&gt; 1.10.3 closed

Indicates that a ticket has been handled or discarded.

&gt; 1.10.4 needs_information

Sometimes indicates that more information is needed before we
can/should continue to handle a ticket.  Sometimes does not (e.g.
#1705).

&gt; 1.10.5 needs_review

Very relevant.  Indicates that a patch exists to fix a bug/add a feature.

&gt; 1.10.6 new

Indicates that a ticket has not had its 'owner' field set explicitly
since it was created.

&gt; 1.10.7 reopened

Often indicates that a user is being an idiot or jerk.  Otherwise,
equivalent to 'accepted', 'assigned', 'new', and 'reopened'.

&gt; 1.11 What other features do you use in Trac?

The 'Timeline' is occasionally useful for finding tickets opened or
modified during some period of time.

&gt; 1.12 What features are you missing in Trac?

A 'ban' feature to get rid of idiots/jerks.

&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?

The Trac wiki should die.

Most of the contents of the wiki consist of obsolete and/or bad
advice.  These pages should be archived in a tarball where they will
not be readily accessible to web browsers and search engines, then
purged from our Trac installation.

The rest of the pages in the Trac wiki should be moved to a wiki which
allows a user who edit a page concurrently with another user to merge
his/her/its changes into the wiki page.  Perhaps we should just use
Git and give up on browser-based wikis.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110906084411</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-06 08:44:11-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 8/29/11 10:48 AM, Karsten Loesing wrote:
&gt; The new deadline is
&gt; 
&gt; Sunday, September 4, 2011
&gt; 
&gt; Dear Tor developers and volunteers who haven't responded yet: If you
&gt; have an opinion on using Trac, please let us know!

First of all, thanks to the 13 people for taking part in the survey!

In this mail I'm trying to summarize the results from part 1 of the
survey and derive some suggestions for making Trac better.  (I'm leaving
out the results from part 2 for now, because it turned out the questions
weren't as useful as I thought.  I may use the replies to design a
second survey in a month or two from now, but for the moment I think
it's best to just focus on our Trac usage.)

Below are the results, plus some suggestions in the paragraphs starting
with "[Suggestion: " to separate my suggestions from result summaries.

Feel free to comment on the suggestions or add your own!

Depending on whether this thread is going to explode, I'll write another
summary in a few days to list the suggestions that people seem to agree
on and that we're going to implement.

Best,
Karsten


&gt; 1 Using Trac features
&gt; 
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

From all the replies, there's 1 person using 5 reports, 2 persons using
3 reports, 1 person using 2 reports, 4 persons using 1 report, and 5
persons using no reports at all.  There's only 1 report being viewed by
more than one person.  5 persons are not using reports at all.

The following reports are viewed: 7, 8, 12 (mentioned twice), 14, 22, 23
(mentioned twice), 27, 28, 34, 35, 36, 38, 39, 40 (mentioned twice).
Hence, the following reports are not viewed: 1, 2, 3, 4, 5, 6, 10, 11,
15, 16, 17, 18, 19, 20, 21, 24, 29, 30, 31, 32, 33, 37.

[Suggestion: Backup and delete all reports with a component name in
them.  The current list of Available Reports list is mostly useless for
newcomers who don't care much about components, but who are interested
in finding something to work on.  Developers and volunteers can bookmark
custom queries or put links to them on a wiki page belonging to a
component.  For example, report 12 "Tor: Active Tickets by Milestone" is
https://trac.torproject.org/projects/tor/query?status=!closed&amp;group=milestone&amp;componen \
t=Tor+Relay&amp;component=Tor+Client&amp;component=Tor+Bridge&amp;component=Tor+Hidden+Services&amp;co \
mponent=Tor+bundles%2Finstallation&amp;component=Tor+Directory+Authority&amp;order=priority&amp;co \
l=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=version&amp;col=keywords
 ]

&gt; 1.2 What are typical custom queries that you run?

There were 11 replies to this question.  4 persons start from a small
set of queries that are always the same, similar to stored ticket
queries, and refine them as needed.  4 persons run many different
queries.  4 persons don't use the custom query feature at all.

&gt; 1.3 How do you use milestones and roadmaps?

7 out of 11 people use milestones.  The components for which milestones
are used are Tor (4 mentions), Vidalia (1 mention), TBB (1 mention), and
sponsors deadlines (1 mention).  4 persons use wiki pages or parent
tickets instead of or in addition to milestones to classify when tickets
should be completed.  Nobody uses the roadmap view of milestones.

Unrelated to this survey, here are some statistics on the milestones in
our Trac:  We have 224 milestones in total, 37 of which having at least
1 ticket assigned.  That leaves 187 milestones with zero tickets
assigned, most of which are a left-over from the flyspray migration.

[Suggestion: Delete all milestones that have no tickets assigned to them
or that seem useful even without assigned tickets.]

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

11 persons are subscribed to tor-bugs, but most people filter the mails
to only learn about components they care about.  5 persons read
tor-wiki-changes, but at least 3 persons would be glad if they contained
diffs.

[Suggestion: Try harder to include diffs in tor-wiki-changes
notifications.  Maybe Trac 0.12 will make this easier.]

&gt; 1.5 Which wiki pages do you read/edit most often?

8 out of 11 persons replying to this question use the wiki.  Mentioned
wiki pages are (multiple selections allowed): sponsor pages (5
mentions), specific pages in doc/ (3 mentions), various FAQ (2
mentions), dev meeting pages (2 mentions), roadmaps in org/roadmaps (1
mention).

&gt; 1.6 How do you search for wiki pages?

People use at least four methods to search the wiki (multiple selections
allowed): TitleIndex (5 mentions), external search engine (4 mentions),
browser auto-completion or history (3 mentions), Trac search (3 mentions).

&gt; 1.7 What are typical search terms that you use when using the search
&gt; features?

3 persons search Trac using key words and 1 person types in ticket
numbers in the search field.  The rest doesn't use the search feature.

&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords
&gt; that you typically use?

1 person uses Agile iteration tracking keywords (D'oh, there goes the
anonymity!) and 2 persons use the "easy" keyword sometimes.  At least 1
person was surprised that there's a tag page.  The rest doesn't use
keywords, nor the tags page.

&gt; 1.9 How relevant are the following ticket fields for you?

Here are the ticket fields sorted by conceived relevance in decreasing
order, plus some comments.  The numbers in brackets are (useful,
somewhat useful, not useful):

The Component field (10, 1, 1) is used to find/filter tickets and guess
who's paying attention to a ticket.  1 person said that the many Tor
components make it hard to refer to the software "tor" and that it's
easier to look at milestones itself.

The Owned by field (10, 1, 1) is important for most people to decide
whether they're responsible for fixing or finding someone else to fix
something.

The Milestone field (9, 0, 2) is used for release planning and sponsor
deliverables, and it also determines the ticket priority to some extent.

The Reported by field (8, 2, 2) is used by some to estimate how useful a
reported defect or suggested enhancement is, and it is useful to know
whether someone will be mailed by Trac when the ticket changes.

The Cc field (7, 1, 3) is used to add people whose input is desired and
to learn who will be mailed when the ticket changes.  There's the
problem that only users with certain permissions can add other persons
to the Cc field of existing tickets.

[Suggestion: Allow all developers and volunteers to edit the Cc field.]

The Priority field (6, 5, 1) is important to some people, but is highly
dependent on who sets the priority.

The Parent ID field (6, 1, 4) is used for complex tickets with many
subtasks and when a task spans multiple components.

The Version field (3, 3, 5) is not used by many components and is
considered not very useful, because bug reporters get versions wrong in
most cases anyway.  Also, current versions of products are never in the
list.

[Suggestion: Delete all obsolete versions from the list, and try harder
to add new versions.]

The Keywords field (2, 1, 8) is only used for agile iteration tracking
and to tag tickets as "easy."

The Points (1, 0, 10) and Actual Points (1, 0, 10) fields are actively
used by only 1 person and read by 1 other person.

[Suggestion: Investigate whether it's possible to suppress email
notifications for changes to the Points and Actual Points fields.]

&gt; 1.10 How relevant are the following ticket statuses for you?

Here are the ticket statuses sorted by relevance from most important to
least important.  Numbers in brackets are (useful, somewhat useful, not
useful):

The closed status (8, 0, 2) is considered useful by pretty much everyone.

The needs_review status (7, 2, 1) is used to determine which tickets to
read and respond to first.

The needs_information status (6, 2, 0) is new, but considered promising
and says that one cannot do more without feedback.

The new (2, 1, 4), assigned (1, 3, 5), reopened (1, 2, 5), and accepted
status (1, 1, 6) have slightly different meanings for some people, but
are mostly equivalent for the majority.  There are 5 persons who'd like
to see these four statuses merged into one, e.g., assigned.  1 person
suggests to narrow down statuses to three statuses: assigned, pending
(with a combo box for reasons: requester information, code review, code
push, schedule), and resolved.

[Suggestion: Investigate whether we can merge "new," "assigned,"
"reopened," and "accepted" into a single "assigned" status.]

&gt; 1.11 What other features do you use in Trac?

4 out of 11 persons mention use of extended features.  These features
include admin functions, e.g., deleting users and spam tickets, embedded
queries (see #3410), and RSS feeds for custom queries, tickets, wiki
pages, and the timeline (2 mentions).

&gt; 1.12 What features are you missing in Trac?

Better search: The current search is ridiculous. I need to specify
things like "I want these three keywords definitely, only in torbutton
tickets that are in status needs-review".

Git commit hooks (2 mentions): We should be able to mention "Bug #XXX"
at the start of a commit message and have that commit get posted as a
comment to trac w/ a link to the gitweb url for the commit. I believe we
have a trac plugin for this, but it is not yet properly configured. At
other employers, commits could only go into stable releases if they
referenced a bug # in the first line. I thought this was a good policy.
Back in the SVN days, this property was actually enforcable on the
server. Git may make this bit more difficult..

[Suggestion: Investigate Git integration in Trac 0.12.]

Trac 0.12-stable: I would like some of the embedded query syntax that is
available in 0.12.x-stable of trac. In particular, 0.12 would make it
much easier to compute the rate of Opened tickets against a given
project in a certain period of time.

[Suggestion: Try out Trac 0.12 on a VM and find out.]

Better handling of duplicate bugs: The "dup" feature should have a bug
field that causes both bugs to be updated automatically with links to
each other.

Field updates should perhaps not send email: Some field updates don't
require emailing everybody on the ticket. I *think* 0.12 might provide
the ability to solve this one, too, but I am not sure.

Prevent trac from emailing you about your own changes (2 mentions):
always_notify_updater = false in trac.ini is close to this, but it is
not exactly what I want. I think it is useful to automatically notify
previous updaters via email, but it seems silly to send me mail for my
own changes. Yet there is only one option for both behaviors in trac.. I
could see setting it to false and just being more careful about adding
people to the Cc line as a stopgap.

Embargoed/Security tickets: For serious security issues, it would be
nice to be able to make tickets not viewable by accounts not on the Cc,
owner, or reporter lines of the ticket. I don't think trac can do this
at all.

Component-specific email notifications: I would have preferred the
ability to receive emails for any changes related to a specific
component (i.e. TorCtl).

[Suggestion: Find out if r2e can do the trick and explain this on the
wiki somewhere.]

Better anonymous reporting (3 mentions): (First reporter) I'd like
better anonymous reporting and commenting.  (Second reporter) I've
bolded the 'New Ticket' and cypherpunks info on the landing page, though
creating a ticket via cypherpunks really should be a fist sized cherry
red button on that page...  (Third reporter) I think the 'cypherpunk'
user should have to add an email address in the Cc field. If they put
mailinator in there, so be it. But they at least need to know we need to
talk to them, or their bugs will probably just sit around forever.

Voting on issues.

Tor-detection: It would be nice to have Tor detection built into tor -
so we can see if a reporting user is actually using Tor!

Multiple milestones: I wish I could assign bugs to multiple milestones.

[Suggestion: Only assign defects and enhancements to software product
milestones and only assign tasks and projects to sponsor milestones.]

Large-scale ticket management: One of the main problems we have in
general is the proliferation of tickets. Originally that was a good
thing -- "have something we need to do? Make a ticket, then we'll
remember." But now we have so many darn tickets, especially in some
components, that they're tough to manage, which leads to less active
maintenance, which leads to having it get even more out of control. I'm
not sure what to do about it, but sometimes it makes me less excited to
add more tickets since I feel like I'm adding to the problem. So some
feature to do large-scale ticket management would be good.

&gt; 1.13 What features would you want our Trac not to offer anymore, because
&gt; they're making things only more confusing for you (and for people who
&gt; are new to Tor)?

No email notifications for certain fields: points, actual points are
annoying because changes in them cause email to be sent as an update. cc
list is the same.

Separate system for users and developers: Trac is used for user support
too much. I wish we had a system that was JUST developer centric, no
user wiki pages or other crap that turns up in searches.

Landing page: Our landing page is a nightmare for newcomers.

[Suggestion: Write a new landing page.]

Single "tor" component: I don't know what confuses others, but IMO the
proliferation of components that are all "tor" doesn't help me, and
makes stuff slightly harder.

Get rid of wiki: Most of the contents of the wiki consist of obsolete
and/or bad advice.  These pages should be archived in a tarball where
they will not be readily accessible to web browsers and search engines,
then purged from our Trac installation.  The rest of the pages in the
Trac wiki should be moved to a wiki which allows a user who edit a page
concurrently with another user to merge his/her/its changes into the
wiki page.  Perhaps we should just use Git and give up on browser-based
wikis.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110906100643</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2011-09-06 10:06:43-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

Hi Karsten,

On Tue, Sep 6, 2011 at 10:44 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:

&gt; First of all, thanks to the 13 people for taking part in the survey!

Thanks for your effort to make Trac life easier for everyone!

&gt; [Suggestion: Backup and delete all reports with a component name in
&gt; them.  The current list of Available Reports list is mostly useless for
&gt; newcomers who don't care much about components, but who are interested
&gt; in finding something to work on.  Developers and volunteers can bookmark
&gt; custom queries or put links to them on a wiki page belonging to a
&gt; component.  For example, report 12 "Tor: Active Tickets by Milestone" is
&gt; https://trac.torproject.org/projects/tor/query?status=!closed&amp;group=milestone&amp;compon \
&gt; ent=Tor+Relay&amp;component=Tor+Client&amp;component=Tor+Bridge&amp;component=Tor+Hidden+Service \
&gt; s&amp;component=Tor+bundles%2Finstallation&amp;component=Tor+Directory+Authority&amp;order=prior \
&gt; ity&amp;col=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=version&amp;col=keywords
&gt;  ]

This is something I'm not entirely happy with. Using the saved query
to look up GetTor, BridgeDB and Weather bugs is like the one feature I
use in Trac. Sure, I can use bookmarks for this in different browsers
I use. On the other hand, I doubt the projected benefit: I might be
wrong, but I wonder if deleting the saved reports will result in even
a single new volunteer starting to fix bugs for us.

/C
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110822122909</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-08-22 12:29:09-0400</timestampReceived><subject>[tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

Hi everyone!

At the last annual dev meeting in Waterloo we had a very productive
discussion about managing the various channels of Tor communication:


https://trac.torproject.org/projects/tor/wiki/org/meetings/2011TorAnnualDevMeeting/FirehoseOutput

Related to that discussion, we should talk about how we use Tor's Trac
system, or more generally how we manage our Tor tasks.  We use Trac as
issue tracker, wiki, and for project management.  But it seems that
everyone uses Trac slightly different and has their own expectations how
other people use it.  This can slow us down.  In addition to that, some
people may not know how Trac can solve their problems.  Knowing how
others use Trac might help them manage their tasks more quickly.  Let's
conduct a survey!

The survey below consists of two parts:  The first part focuses on
Trac's features and whether you're using them or not.  The second part
is about managing your tasks in general, either with or without Trac.

If you are a Tor developer or volunteer or think you have some input on
the topic, please fill out this survey until

  Sunday, August 28, 2011

and send it either to this list or to me.  I'll try to summarize what
was said and send the survey results to this list, hopefully before the
end of the month.

Thanks!
Karsten


1 Using Trac features

1.1 Which of the reports (stored ticket queries) do you use most often?

1.2 What are typical custom queries that you run?

1.3 How do you use milestones and roadmaps?

1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
you use the mails sent to these lists?

1.5 Which wiki pages do you read/edit most often?

1.6 How do you search for wiki pages?

1.7 What are typical search terms that you use when using the search
features?

1.8 Do you use keywords and the tags page, and if so, what are keywords
that you typically use?

1.9 How relevant are the following ticket fields for you?

1.9.1 Reported by

1.9.2 Owned by

1.9.3 Priority

1.9.4 Milestone

1.9.5 Component

1.9.6 Version

1.9.7 Keywords

1.9.8 Cc

1.9.9 Parent ID

1.9.10 Points

1.9.11 Actual Points

1.10 How relevant are the following ticket statuses for you?

1.10.1 accepted

1.10.2 assigned

1.10.3 closed

1.10.4 needs_information

1.10.5 needs_review

1.10.6 new

1.10.7 reopened

1.11 What other features do you use in Trac?

1.12 What features are you missing in Trac?

1.13 What features would you want our Trac not to offer anymore, because
they're making things only more confusing for you (and for people who
are new to Tor)?

2 Solving typical software development tasks

Note that the questions below don't just focus on Trac, but on any tools
or communication media you use for solving a task.

2.1 How do you decide what to work on, both when fixing bugs or when
implementing new features?

2.2 How do you keep track of what things you're supposed to do for
sponsors and for when?

2.3 How do you memorize new ideas to work on when they come up?

2.4 How do you coordinate working together with someone on something?

2.5 How do you learn who you could work together with on something?

2.6 What other software development tasks do you have that may be
supported by Trac or a Trac-like system?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110822165907</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-08-22 16:59:07-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

&gt; 1 Using Trac features
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

"{28} Open Arm Tickets", of course :P

&gt; 1.2 What are typical custom queries that you run?

I don't since I found the search interface to be a pita. I track
tickets via email instead, flagging those I'm interested in and using
gmail's searching functionality.

&gt; 1.3 How do you use milestones and roadmaps?

I keep a wiki with my todo plans for arm
(https://trac.torproject.org/projects/tor/wiki/doc/arm).

&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do you use the \
&gt; mails sent to these lists?

I'm subscribed to tor-bugs but not tor-wiki-changes (I use my own
rss2email instance since I want prompt notices but tor-wiki-changes
seems to be on an hourly batch).

&gt; 1.5 Which wiki pages do you read/edit most often?

I maintain...
https://trac.torproject.org/projects/tor/wiki/doc/arm
https://trac.torproject.org/projects/tor/wiki/doc/badRelays

&gt; 1.6 How do you search for wiki pages?

Most of the time I use my browser's address autocomplete. Otherwise
I've rarely had a need to search or navigate the wiki.

&gt; 1.7 What are typical search terms that you use when using the search features?

N/A

&gt; 1.8 Do you use keywords and the tags page, and if so, what are keywords that you \
&gt; typically use?

Nope

&gt; 1.9 How relevant are the following ticket fields for you?
&gt; 1.9.1 Reported by
&gt; 1.9.2 Owned by

Useful

&gt; 1.9.3 Priority

Meh, it's a rough indicator of somebody's opinion on the importance
but that's it.

&gt; 1.9.4 Milestone

Not used for my project

&gt; 1.9.5 Component

Most important field there is :)

&gt; 1.9.6 Version

Not used for my project

&gt; 1.9.7 Keywords
&gt; 1.9.8 Cc

Not useful (I ignore this)

&gt; 1.9.9 Parent ID

I don't use this

&gt; 1.9.10 Points
&gt; 1.9.11 Actual Points

I don't use this, iirc this is just some metadata field for Mike

&gt; 1.10 How relevant are the following ticket statuses for you?
&gt; 1.10.1 accepted
&gt; 1.10.2 assigned
&gt; 1.10.3 closed
&gt; 1.10.4 needs_information
&gt; 1.10.5 needs_review
&gt; 1.10.6 new
&gt; 1.10.7 reopened

Several of the statuses (accepted/assigned/new/reopened) have
identical meanings since trac assigns them automatically, so they're
not an indicator of a human's intent. The only ones that matter are
'needs_information', 'needs_review', and 'closed'.

I'd like to see this narrowed to just a small set of useful statuses
with a combo box for the reason...
- assigned
- pending
  - requester information
  - code review
  - code push
  - schedule
  - ... etc
- resolved
  - no issue
  - requester disappeared
  - duplicate
  - fixed / implemented
  - ... etc

&gt; 1.11 What other features do you use in Trac?

I use trac as a basic bug tracker and wiki - that's it.

&gt; 1.12 What features are you missing in Trac?

None, I'm happy with it for my use cases. Once upon a time it would
have been nice to have MediaWiki syntax, but the trac derivative is
fine.

&gt; 1.13 What features would you want our Trac not to offer anymore, because they're \
&gt; making things only more confusing for you (and for people who are new to Tor)?

For my use cases I'm happy with it. Assuming that you already know
what you're looking for trac is fine. That said, our landing page,
searching functionality, etc makes it a nightmare for newcomers. From
my point of view it's suitable for our current pool of developers and
if adding something makes a person's life easier (for example, the
"Points" field) then great, go for it.

For everyone else trac serves just two purposes:
1. The wiki, which houses content (ie, we link to it from non-trac
pages like the site and blog) but I don't think we expect people to
navigate trac itself... at least I hope not!

2. Ticket reporting, which we should certainly improve. I've bolded
the 'New Ticket' and cypherpunks info on the landing page, though
creating a ticket via cypherpunks really should be a fist sized cherry
red button on that page...

&gt; 2 Solving typical software development tasks
&gt; 2.1 How do you decide what to work on, both when fixing bugs or when implementing \
&gt; new features?

My priorities are as follows:
1. time critical issues facing arm users (hotfixes for recent releases and such)

2. features, fixes, or answering questions to make someone's life
nicer (where the more involved the requester is, the higher priority
it is for me)

3. whatever I feel like at the moment, usually something that works
toward the next arm release

&gt; 2.2 How do you keep track of what things you're supposed to do for sponsors and for \
&gt; when?

N/A

&gt; 2.3 How do you memorize new ideas to work on when they come up?

Not sure if I understand the question. If you mean 'how do I keep
track of todo notes' I usually email myself the relevant snippets of
irc discussions so I remember to go back and address the issues they
mentioned later.

&gt; 2.4 How do you coordinate working together with someone on something?

There's precious few projects I work with others on, unfortunately.
I'd love to change that but there's little interest in controllers or
UI development (and what little there is focuses on Vidalia). Oh
well...

Mostly this question would just concern my work with TorCtl where I
write a patch, add a link for the branch on a ticket, then pester Mike
every so often until he reviews and merges it.

&gt; 2.5 How do you learn who you could work together with on something?

Not sure I follow. If I have questions about another project I talk
with the project owner, as listed on:
https://www.torproject.org/getinvolved/volunteer.html.en#Projects

&gt; 2.6 What other software development tasks do you have that may be supported by Trac \
&gt; or a Trac-like system?

I dislike the idea of overloading trac. For me it's just a bug tracker
and wiki. If others want to use it for things like project management
then great, but I'd be weary of trying to jerry rig solutions it's not
intended for.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110906121929</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-09-06 12:19:29-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 2011-09-06, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; &gt; 1.1 Which of the reports (stored ticket queries) do you use most often?
&gt; 
&gt; From all the replies, there's 1 person using 5 reports, 2 persons using
&gt; 3 reports, 1 person using 2 reports, 4 persons using 1 report, and 5
&gt; persons using no reports at all.  There's only 1 report being viewed by
&gt; more than one person.  5 persons are not using reports at all.
&gt; 
&gt; The following reports are viewed: 7, 8, 12 (mentioned twice), 14, 22, 23
&gt; (mentioned twice), 27, 28, 34, 35, 36, 38, 39, 40 (mentioned twice).
&gt; Hence, the following reports are not viewed: 1, 2, 3, 4, 5, 6, 10, 11,
&gt; 15, 16, 17, 18, 19, 20, 21, 24, 29, 30, 31, 32, 33, 37.
&gt; 
&gt; [Suggestion: Backup and delete all reports with a component name in
&gt; them.  The current list of Available Reports list is mostly useless for
&gt; newcomers who don't care much about components, but who are interested
&gt; in finding something to work on.  Developers and volunteers can bookmark
&gt; custom queries or put links to them on a wiki page belonging to a
&gt; component.  For example, report 12 "Tor: Active Tickets by Milestone" is
&gt; https://trac.torproject.org/projects/tor/query?status=!closed&amp;group=milestone&amp;compon \
&gt; ent=Tor+Relay&amp;component=Tor+Client&amp;component=Tor+Bridge&amp;component=Tor+Hidden+Service \
&gt; s&amp;component=Tor+bundles%2Finstallation&amp;component=Tor+Directory+Authority&amp;order=prior \
&gt; ity&amp;col=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=version&amp;col=keywords
&gt;  ]

This is unnecessary.  New developers need to find the 'Custom Query'
page anyway; leaving reports on the 'Available Reports' page that no
one reported using in this survey will not make that any harder.
Making the 'Search the Tor bug tracker' link on the wiki main page
bold might help.

Also, at least one of the reports on that page
(https://trac.torproject.org/projects/tor/report/24 (Archived
Mixminion-* Tasks)) is for a query that we can no longer perform using
the 'Custom Query' page; many of the rest would be difficult to
recreate as a custom query.

&gt; &gt; 1.7 What are typical search terms that you use when using the search
&gt; &gt; features?
&gt; 
&gt; 3 persons search Trac using key words and 1 person types in ticket
&gt; numbers in the search field.  The rest doesn't use the search feature.

I type ticket numbers into my browser's search field, too.  I don't
consider typing a Trac link target specifier into the search field to
be searching.

&gt; The Version field (3, 3, 5) is not used by many components and is
&gt; considered not very useful, because bug reporters get versions wrong in
&gt; most cases anyway.  Also, current versions of products are never in the
&gt; list.
&gt; 
&gt; [Suggestion: Delete all obsolete versions from the list, and try harder
&gt; to add new versions.]

This field might receive more useful input from users if it were an
ordinary text field.  There are already far too many possible values
for this field to be useful in searches; allowing arbitrary strings
here cannot make it less useful

&gt; Single "tor" component: I don't know what confuses others, but IMO the
&gt; proliferation of components that are all "tor" doesn't help me, and
&gt; makes stuff slightly harder.

If these components were merged, I would have much more trouble
digging through a custom query to find a particular ticket.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110906210122</emailId><senderName>katmagic</senderName><senderEmail>the.magical.kat@gmail.com</senderEmail><timestampReceived>2011-09-06 21:01:22-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


Sorry for the late reply  I haven't checked my email in a while  but
I'm replying anyway because I've some strong feelings on this issue. In
short, Trac sucks. My issues with it are as follows:

1. The design sucks.

2. There's no AJAX. Now, I know a lot of people on this list hate Web
2.0, but I really think its irrational. Especially over Tor, reloading
pages as many times as Trac makes you do is time consuming and
cumbersome. Of course, I'm not advocating making it *require*
JavaScript, but it would certainly be a nice feature.

3. An unreasonable number of pages must be navigated through in order to
perform simple functions. The difficult of doing this prevents people
from finding bugs, and therefore discourages contribution.

4. There are too many options. There are oodles of options that must be
fiddled with every single time a ticket is created, and if one makes a
mistake, it's not possible to go back and edit the ticket.

5. Searching for tickets is a confusing and somewhat difficult task. In
order to search for one's own tickets, for example, one must navigate a
menu with FORTY choices with unclear labels.

6. Searching in general doesn't work very well. Whatever algorithm Trac
uses for search is awful.

7. Trac sends email about your own modifications, and about a lot of
things people probably don't want email about (i.e. every comment on a
ticket). A significantly improved method would be to offer notifications
on the website itself.

8. Trac does not integrate with Git. It should allow you to reference
commits from tickets, and reference tickets from commit messages (viewed
in the web interface). Being able to close tickets from commit messages
would also be useful.

9. HTTP Basic authentication could be confusing for some users. A
cookies-based system would probably be easier, and allow for persistent
logins (which most people consider a good thing).

10. "Points" are annoying. I'm not personally a fan of 'agile
development', and I really don't want to get notifications about it.
Again, finer-grained control over notifications would probably solve
this.

Because of these reasons, I think Trac actually discourages
contribution. It's *much* easier to report a bug, say, on GitHub than on
Trac, and it's much easier to get updates about progress on it; both of
which are things that are important to the average person reviewing a
bug.

~ Kat

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110912133333</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-12 13:33:33-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 9/6/11 12:06 PM, Christian Fromme wrote:
&gt; &gt; [Suggestion: Backup and delete all reports with a component name in
&gt; &gt; them.  The current list of Available Reports list is mostly useless for
&gt; &gt; newcomers who don't care much about components, but who are interested
&gt; &gt; in finding something to work on.  Developers and volunteers can bookmark
&gt; &gt; custom queries or put links to them on a wiki page belonging to a
&gt; &gt; component.  For example, report 12 "Tor: Active Tickets by Milestone" is
&gt; &gt; https://trac.torproject.org/projects/tor/query?status=!closed&amp;group=milestone&amp;comp \
&gt; &gt; onent=Tor+Relay&amp;component=Tor+Client&amp;component=Tor+Bridge&amp;component=Tor+Hidden+Ser \
&gt; &gt; vices&amp;component=Tor+bundles%2Finstallation&amp;component=Tor+Directory+Authority&amp;order \
&gt; &gt; =priority&amp;col=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=version&amp;col=keywords
&gt; &gt;  ]
&gt; 
&gt; This is something I'm not entirely happy with. Using the saved query
&gt; to look up GetTor, BridgeDB and Weather bugs is like the one feature I
&gt; use in Trac. Sure, I can use bookmarks for this in different browsers
&gt; I use. On the other hand, I doubt the projected benefit: I might be
&gt; wrong, but I wonder if deleting the saved reports will result in even
&gt; a single new volunteer starting to fix bugs for us.

Okay.  Leaving the list of Available Reports unchanged.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110912133845</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-12 13:38:45-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 9/6/11 2:19 PM, Robert Ransom wrote:
&gt; On 2011-09-06, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; 
&gt; &gt; &gt; 1.1 Which of the reports (stored ticket queries) do you use most often?
&gt; &gt; 
&gt; &gt; From all the replies, there's 1 person using 5 reports, 2 persons using
&gt; &gt; 3 reports, 1 person using 2 reports, 4 persons using 1 report, and 5
&gt; &gt; persons using no reports at all.  There's only 1 report being viewed by
&gt; &gt; more than one person.  5 persons are not using reports at all.
&gt; &gt; 
&gt; &gt; The following reports are viewed: 7, 8, 12 (mentioned twice), 14, 22, 23
&gt; &gt; (mentioned twice), 27, 28, 34, 35, 36, 38, 39, 40 (mentioned twice).
&gt; &gt; Hence, the following reports are not viewed: 1, 2, 3, 4, 5, 6, 10, 11,
&gt; &gt; 15, 16, 17, 18, 19, 20, 21, 24, 29, 30, 31, 32, 33, 37.
&gt; &gt; 
&gt; &gt; [Suggestion: Backup and delete all reports with a component name in
&gt; &gt; them.  The current list of Available Reports list is mostly useless for
&gt; &gt; newcomers who don't care much about components, but who are interested
&gt; &gt; in finding something to work on.  Developers and volunteers can bookmark
&gt; &gt; custom queries or put links to them on a wiki page belonging to a
&gt; &gt; component.  For example, report 12 "Tor: Active Tickets by Milestone" is
&gt; &gt; https://trac.torproject.org/projects/tor/query?status=!closed&amp;group=milestone&amp;comp \
&gt; &gt; onent=Tor+Relay&amp;component=Tor+Client&amp;component=Tor+Bridge&amp;component=Tor+Hidden+Ser \
&gt; &gt; vices&amp;component=Tor+bundles%2Finstallation&amp;component=Tor+Directory+Authority&amp;order \
&gt; &gt; =priority&amp;col=id&amp;col=summary&amp;col=component&amp;col=status&amp;col=type&amp;col=priority&amp;col=milestone&amp;col=version&amp;col=keywords
&gt; &gt;  ]
&gt; 
&gt; This is unnecessary.  New developers need to find the 'Custom Query'
&gt; page anyway; leaving reports on the 'Available Reports' page that no
&gt; one reported using in this survey will not make that any harder.
&gt; Making the 'Search the Tor bug tracker' link on the wiki main page
&gt; bold might help.
&gt; 
&gt; Also, at least one of the reports on that page
&gt; (https://trac.torproject.org/projects/tor/report/24 (Archived
&gt; Mixminion-* Tasks)) is for a query that we can no longer perform using
&gt; the 'Custom Query' page; many of the rest would be difficult to
&gt; recreate as a custom query.

Yup.  Not touching the list of Available Reports. :)

&gt; &gt; &gt; 1.7 What are typical search terms that you use when using the search
&gt; &gt; &gt; features?
&gt; &gt; 
&gt; &gt; 3 persons search Trac using key words and 1 person types in ticket
&gt; &gt; numbers in the search field.  The rest doesn't use the search feature.
&gt; 
&gt; I type ticket numbers into my browser's search field, too.  I don't
&gt; consider typing a Trac link target specifier into the search field to
&gt; be searching.

I mentioned this feature, because someone was asking for a way to type
in ticket numbers somewhere.

&gt; &gt; The Version field (3, 3, 5) is not used by many components and is
&gt; &gt; considered not very useful, because bug reporters get versions wrong in
&gt; &gt; most cases anyway.  Also, current versions of products are never in the
&gt; &gt; list.
&gt; &gt; 
&gt; &gt; [Suggestion: Delete all obsolete versions from the list, and try harder
&gt; &gt; to add new versions.]
&gt; 
&gt; This field might receive more useful input from users if it were an
&gt; ordinary text field.  There are already far too many possible values
&gt; for this field to be useful in searches; allowing arbitrary strings
&gt; here cannot make it less useful

I don't think we can turn this field into a text field, unless we start
hacking Trac.  We should probably try harder to keep the versions
up-to-date to make the field at least somewhat useful.

&gt; &gt; Single "tor" component: I don't know what confuses others, but IMO the
&gt; &gt; proliferation of components that are all "tor" doesn't help me, and
&gt; &gt; makes stuff slightly harder.
&gt; 
&gt; If these components were merged, I would have much more trouble
&gt; digging through a custom query to find a particular ticket.

Yup.  I can see both positions here.  I don't think we'll find a
solution in this thread.  This was Nick's suggestion.  Maybe discuss
this with Nick directly?

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110912135126</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-12 13:51:26-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your	tasks</subject><body>

On Tue, Sep 06, 2011 at 10:44:11AM +0200, Karsten Loesing wrote:
&gt; The Component field (10, 1, 1) is used to find/filter tickets and guess
&gt; who's paying attention to a ticket.  1 person said that the many Tor
&gt; components make it hard to refer to the software "tor" and that it's
&gt; easier to look at milestones itself.

I guess that would be Nick. I wouldn't object to making some other Trac
field besides 'component' to categorize things. But lumping 500+ Tor
tickets into one component, with no way to break them down by category,
is going to make it much harder to find tickets.

(I search for tickets by pulling up all the tickets in a given component,
and then using my browser's search feature to thumb through them.)

&gt; The Version field (3, 3, 5) is not used by many components and is
&gt; considered not very useful, because bug reporters get versions wrong in
&gt; most cases anyway.  Also, current versions of products are never in the
&gt; list.
&gt; 
&gt; [Suggestion: Delete all obsolete versions from the list, and try harder
&gt; to add new versions.]

When you delete a version from the list, does it vanish from tickets
that reference it? That is, will we be destroying history by deleting
an old version?

&gt; The Points (1, 0, 10) and Actual Points (1, 0, 10) fields are actively
&gt; used by only 1 person and read by 1 other person.
&gt; 
&gt; [Suggestion: Investigate whether it's possible to suppress email
&gt; notifications for changes to the Points and Actual Points fields.]

I actually find these mails about as useful as the other mails, insofar
as they tell me that Mike is thinking about working on a given ticket.

But I can see how people who don't care what Mike is going to work on
soon would not want to see them.

&gt; The new (2, 1, 4), assigned (1, 3, 5), reopened (1, 2, 5), and accepted
&gt; status (1, 1, 6) have slightly different meanings for some people, but
&gt; are mostly equivalent for the majority.  There are 5 persons who'd like
&gt; to see these four statuses merged into one, e.g., assigned.  1 person
&gt; suggests to narrow down statuses to three statuses: assigned, pending
&gt; (with a combo box for reasons: requester information, code review, code
&gt; push, schedule), and resolved.
&gt; 
&gt; [Suggestion: Investigate whether we can merge "new," "assigned,"
&gt; "reopened," and "accepted" into a single "assigned" status.]

If we merge them, why on earth would it be called 'assigned'? So
new tickets start out assigned, but sometimes not to anybody? That's
confusing.

How about a word that captures them all, like 'open'?

&gt; Better handling of duplicate bugs: The "dup" feature should have a bug
&gt; field that causes both bugs to be updated automatically with links to
&gt; each other.

Great idea. I sometimes do that manually for the other bug, but not
consistently.

&gt; Better anonymous reporting (3 mentions): (First reporter) I'd like
&gt; better anonymous reporting and commenting.  (Second reporter) I've
&gt; bolded the 'New Ticket' and cypherpunks info on the landing page, though
&gt; creating a ticket via cypherpunks really should be a fist sized cherry
&gt; red button on that page...  (Third reporter) I think the 'cypherpunk'
&gt; user should have to add an email address in the Cc field. If they put
&gt; mailinator in there, so be it. But they at least need to know we need to
&gt; talk to them, or their bugs will probably just sit around forever.

Good idea. It is true that tickets created by cypherpunks very often do
not get any good followup. I would be tempted to say that cypherpunks
shouldn't be allowed to open tickets.

I wonder if the real problem here is that it's such a hassle to make a
trac account. (Is it?)

&gt; Voting on issues.

This isn't a democracy here. :)

&gt; Separate system for users and developers: Trac is used for user support
&gt; too much. I wish we had a system that was JUST developer centric, no
&gt; user wiki pages or other crap that turns up in searches.

Yes!

&gt; Landing page: Our landing page is a nightmare for newcomers.
&gt; 
&gt; [Suggestion: Write a new landing page.]

That sounds really valuable. In particular, the first flaw with our
current landing page is that it is not clear that you are looking at a
combination bugtracker and wiki.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110912135716</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-12 13:57:16-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 9/6/11 11:01 PM, katmagic wrote:
&gt; Sorry for the late reply  I haven't checked my email in a while  but
&gt; I'm replying anyway because I've some strong feelings on this issue. In
&gt; short, Trac sucks. My issues with it are as follows:
&gt; 
&gt; 1. The design sucks.

You're right, it needs more green!

&gt; 2. There's no AJAX. Now, I know a lot of people on this list hate Web
&gt; 2.0, but I really think its irrational. Especially over Tor, reloading
&gt; pages as many times as Trac makes you do is time consuming and
&gt; cumbersome. Of course, I'm not advocating making it *require*
&gt; JavaScript, but it would certainly be a nice feature.

This isn't something we can influence.  Well, assuming that we want to
keep using Trac for a while.

&gt; 3. An unreasonable number of pages must be navigated through in order to
&gt; perform simple functions. The difficult of doing this prevents people
&gt; from finding bugs, and therefore discourages contribution.

Can you be more specific how we could fix this?

&gt; 4. There are too many options. There are oodles of options that must be
&gt; fiddled with every single time a ticket is created, and if one makes a
&gt; mistake, it's not possible to go back and edit the ticket.

The survey had questions about all statuses and ticket fields to
evaluate their usefulness.

The fact that it's not possible to go back and edit a ticket may be a
permission problem.  What permissions are you missing?  On the other
hand, you can always add another comment saying what you really meant.

&gt; 5. Searching for tickets is a confusing and somewhat difficult task. In
&gt; order to search for one's own tickets, for example, one must navigate a
&gt; menu with FORTY choices with unclear labels.

Do you mean the custom query form?  Which parts of it do you find hard
to understand for new users?

&gt; 6. Searching in general doesn't work very well. Whatever algorithm Trac
&gt; uses for search is awful.

I don't think we can change this.

&gt; 7. Trac sends email about your own modifications, and about a lot of
&gt; things people probably don't want email about (i.e. every comment on a
&gt; ticket). A significantly improved method would be to offer notifications
&gt; on the website itself.

I think two other people stated that they don't want to have emails for
their own modifications.  Actually, I find that useful, because I'm
using my inbox as an archive that I can search even when I'm offline.

I'm not sure what you mean with notifications on the website itself.

&gt; 8. Trac does not integrate with Git. It should allow you to reference
&gt; commits from tickets, and reference tickets from commit messages (viewed
&gt; in the web interface). Being able to close tickets from commit messages
&gt; would also be useful.

We need to install the Git plugin for that.  This is one of the things
we should change, yes.

&gt; 9. HTTP Basic authentication could be confusing for some users. A
&gt; cookies-based system would probably be easier, and allow for persistent
&gt; logins (which most people consider a good thing).

I don't think we can or should change this.

&gt; 10. "Points" are annoying. I'm not personally a fan of 'agile
&gt; development', and I really don't want to get notifications about it.
&gt; Again, finer-grained control over notifications would probably solve
&gt; this.

Finer-grained control over notifications is probably the answer.

&gt; Because of these reasons, I think Trac actually discourages
&gt; contribution. It's *much* easier to report a bug, say, on GitHub than on
&gt; Trac, and it's much easier to get updates about progress on it; both of
&gt; which are things that are important to the average person reviewing a
&gt; bug.

I still believe we should first try to tweak Trac to fit our needs
before moving on to the next tool.

Thanks for your input!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110912152751</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-12 15:27:51-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your	tasks</subject><body>

On 9/12/11 3:51 PM, Roger Dingledine wrote:
&gt; On Tue, Sep 06, 2011 at 10:44:11AM +0200, Karsten Loesing wrote:
&gt;&gt; The Component field (10, 1, 1) is used to find/filter tickets and guess
&gt;&gt; who's paying attention to a ticket.  1 person said that the many Tor
&gt;&gt; components make it hard to refer to the software "tor" and that it's
&gt;&gt; easier to look at milestones itself.
&gt; 
&gt; I guess that would be Nick. I wouldn't object to making some other Trac
&gt; field besides 'component' to categorize things. But lumping 500+ Tor
&gt; tickets into one component, with no way to break them down by category,
&gt; is going to make it much harder to find tickets.
&gt; 
&gt; (I search for tickets by pulling up all the tickets in a given component,
&gt; and then using my browser's search feature to thumb through them.)

Well, I don't know what to do here.  I think changing the component of
500+ tickets and adding, say, keywords for the category is a lot of work
and will generate a lot of mail for people on tor-bugs.  Is it worth it?

&gt;&gt; The Version field (3, 3, 5) is not used by many components and is
&gt;&gt; considered not very useful, because bug reporters get versions wrong in
&gt;&gt; most cases anyway.  Also, current versions of products are never in the
&gt;&gt; list.
&gt;&gt;
&gt;&gt; [Suggestion: Delete all obsolete versions from the list, and try harder
&gt;&gt; to add new versions.]
&gt; 
&gt; When you delete a version from the list, does it vanish from tickets
&gt; that reference it? That is, will we be destroying history by deleting
&gt; an old version?

I just tried this in #4005.  The version in the ticket will remain the
same, but one cannot create new tickets using this version or change the
version field of existing tickets to it.  So, breaking history shouldn't
be a problem.

&gt;&gt; The Points (1, 0, 10) and Actual Points (1, 0, 10) fields are actively
&gt;&gt; used by only 1 person and read by 1 other person.
&gt;&gt;
&gt;&gt; [Suggestion: Investigate whether it's possible to suppress email
&gt;&gt; notifications for changes to the Points and Actual Points fields.]
&gt; 
&gt; I actually find these mails about as useful as the other mails, insofar
&gt; as they tell me that Mike is thinking about working on a given ticket.
&gt; 
&gt; But I can see how people who don't care what Mike is going to work on
&gt; soon would not want to see them.

The question is: how much will you care if these notifications go away?
 I think the majority of people wouldn't mind if the Points and Actual
Points fields would go away entirely, so suppressing notifications was
already a compromise.

&gt;&gt; The new (2, 1, 4), assigned (1, 3, 5), reopened (1, 2, 5), and accepted
&gt;&gt; status (1, 1, 6) have slightly different meanings for some people, but
&gt;&gt; are mostly equivalent for the majority.  There are 5 persons who'd like
&gt;&gt; to see these four statuses merged into one, e.g., assigned.  1 person
&gt;&gt; suggests to narrow down statuses to three statuses: assigned, pending
&gt;&gt; (with a combo box for reasons: requester information, code review, code
&gt;&gt; push, schedule), and resolved.
&gt;&gt;
&gt;&gt; [Suggestion: Investigate whether we can merge "new," "assigned,"
&gt;&gt; "reopened," and "accepted" into a single "assigned" status.]
&gt; 
&gt; If we merge them, why on earth would it be called 'assigned'? So
&gt; new tickets start out assigned, but sometimes not to anybody? That's
&gt; confusing.
&gt; 
&gt; How about a word that captures them all, like 'open'?

'open' it is then.  (Assuming we can even change this.)

&gt;&gt; Better handling of duplicate bugs: The "dup" feature should have a bug
&gt;&gt; field that causes both bugs to be updated automatically with links to
&gt;&gt; each other.
&gt; 
&gt; Great idea. I sometimes do that manually for the other bug, but not
&gt; consistently.

I'll see if there's a plugin for that.  Or maybe 0.12 does that already.

&gt;&gt; Better anonymous reporting (3 mentions): (First reporter) I'd like
&gt;&gt; better anonymous reporting and commenting.  (Second reporter) I've
&gt;&gt; bolded the 'New Ticket' and cypherpunks info on the landing page, though
&gt;&gt; creating a ticket via cypherpunks really should be a fist sized cherry
&gt;&gt; red button on that page...  (Third reporter) I think the 'cypherpunk'
&gt;&gt; user should have to add an email address in the Cc field. If they put
&gt;&gt; mailinator in there, so be it. But they at least need to know we need to
&gt;&gt; talk to them, or their bugs will probably just sit around forever.
&gt; 
&gt; Good idea. It is true that tickets created by cypherpunks very often do
&gt; not get any good followup. I would be tempted to say that cypherpunks
&gt; shouldn't be allowed to open tickets.
&gt; 
&gt; I wonder if the real problem here is that it's such a hassle to make a
&gt; trac account. (Is it?)
&gt; 
&gt;&gt; Voting on issues.
&gt; 
&gt; This isn't a democracy here. :)
&gt; 
&gt;&gt; Separate system for users and developers: Trac is used for user support
&gt;&gt; too much. I wish we had a system that was JUST developer centric, no
&gt;&gt; user wiki pages or other crap that turns up in searches.
&gt; 
&gt; Yes!

I'm not opposed.  Should we set up a poll somewhere? :)

&gt;&gt; Landing page: Our landing page is a nightmare for newcomers.
&gt;&gt;
&gt;&gt; [Suggestion: Write a new landing page.]
&gt; 
&gt; That sounds really valuable. In particular, the first flaw with our
&gt; current landing page is that it is not clear that you are looking at a
&gt; combination bugtracker and wiki.

Yup.  We should decide first whether we want to solve that by moving
away the wiki.  Though I know at least one person who won't be thrilled
that there will be new URLs for wiki pages---again.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110913032002</emailId><senderName>katmagic</senderName><senderEmail>the.magical.kat@gmail.com</senderEmail><timestampReceived>2011-09-13 03:20:02-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


On Mon, 2011-09-12 at 15:57 +0200, Karsten Loesing wrote:
&gt; On 9/6/11 11:01 PM, katmagic wrote:
&gt; &gt; Sorry for the late reply  I haven't checked my email in a while  but
&gt; &gt; I'm replying anyway because I've some strong feelings on this issue. In
&gt; &gt; short, Trac sucks. My issues with it are as follows:
&gt; &gt; 
&gt; &gt; 1. The design sucks.
&gt; 
&gt; You're right, it needs more green!
&gt; 
&gt; &gt; 2. There's no AJAX. Now, I know a lot of people on this list hate Web
&gt; &gt; 2.0, but I really think its irrational. Especially over Tor, reloading
&gt; &gt; pages as many times as Trac makes you do is time consuming and
&gt; &gt; cumbersome. Of course, I'm not advocating making it *require*
&gt; &gt; JavaScript, but it would certainly be a nice feature.
&gt; 
&gt; This isn't something we can influence.  Well, assuming that we want to
&gt; keep using Trac for a while.

Why should Trac be assumed?

&gt; &gt; 3. An unreasonable number of pages must be navigated through in order to
&gt; &gt; perform simple functions. The difficult of doing this prevents people
&gt; &gt; from finding bugs, and therefore discourages contribution.
&gt; 
&gt; Can you be more specific how we could fix this?

Maybe hierarchical CSS menus on the header? There are a myriad of ways
to do it, though I don't think Trac can implement any of them.

&gt; &gt; 4. There are too many options. There are oodles of options that must be
&gt; &gt; fiddled with every single time a ticket is created, and if one makes a
&gt; &gt; mistake, it's not possible to go back and edit the ticket.
&gt; 
&gt; The survey had questions about all statuses and ticket fields to
&gt; evaluate their usefulness.


&gt; 1.9 How relevant are the following ticket fields for you?

&gt; 1.9.5 Component
There are way too many of these for a flat list. A hierarchy of some
sort might work, but the component could just as easily be a keyword.

&gt; 1.9.6 Version
Wow, that list is long.

&gt; 1.9.7 Keywords
It would be helpful to have a (perhaps hierarchical) list of previous
keywords to choose from, in addition to creating custom ones.

&gt; 1.9.9 Parent ID
Tickets need to be in a hierarchy. Entering the parent ID manually like
this is really cumbersome.

&gt; 1.9.10 Points
&gt; 1.9.11 Actual Points
What are these things for, anyway? If only mikeperry uses them, maybe
they should be local to a user? Maybe there should be a generic,
user-local field for annotations.

&gt; The fact that it's not possible to go back and edit a ticket may be a
&gt; permission problem.  What permissions are you missing?  On the other
&gt; hand, you can always add another comment saying what you really meant.

How am I supposed to know what permissions I have? And having to correct
things in separate comments will lead to a bunch of poorly worded,
inaccurate, or superfluous comments or tickets.

&gt; &gt; 5. Searching for tickets is a confusing and somewhat difficult task. In
&gt; &gt; order to search for one's own tickets, for example, one must navigate a
&gt; &gt; menu with FORTY choices with unclear labels.
&gt; 
&gt; Do you mean the custom query form?  Which parts of it do you find hard
&gt; to understand for new 

Even the 'View Tickets' view is confusing. Firstly, sorting shouldn't be
listed on the View Tickets page, but as an option chosen on that
sub-page. Secondly, the option descriptions are ambiguous. What does 'My
Tickets (all)' mean? Does it mean tickets I reported? Tickets assigned
to me? Tickets I'm CCed on? Tickets I've commented on? or some
combination of these?

&gt; &gt; 6. Searching in general doesn't work very well. Whatever algorithm Trac
&gt; &gt; uses for search is awful.

&gt; I don't think we can change this [without switching from Trac].


&gt; &gt; 7. Trac sends email about your own modifications, and about a lot of
&gt; &gt; things people probably don't want email about (i.e. every comment on a
&gt; &gt; ticket). A significantly improved method would be to offer notifications
&gt; &gt; on the website itself.
&gt; 
&gt; I think two other people stated that they don't want to have emails for
&gt; their own modifications.  Actually, I find that useful, because I'm
&gt; using my inbox as an archive that I can search even when I'm offline.
&gt; 
&gt; I'm not sure what you mean with notifications on the website itself.

There'd be a notice on the website navigation header alerting you that
you have messages. When you click on it, you'd be taken to a page with a
list of new tickets, replies, etc. You could also have notifications for
saved searches here, rather like Twitter.
 
&gt; &gt; 8. Trac does not integrate with Git. It should allow you to reference
&gt; &gt; commits from tickets, and reference tickets from commit messages (viewed
&gt; &gt; in the web interface). Being able to close tickets from commit messages
&gt; &gt; would also be useful.
&gt; 
&gt; We need to install the Git plugin for that.  This is one of the things
&gt; we should change, yes.
&gt; 
&gt; &gt; 9. HTTP Basic authentication could be confusing for some users. A
&gt; &gt; cookies-based system would probably be easier, and allow for persistent
&gt; &gt; logins (which most people consider a good thing).
&gt; 
&gt; I don't think we can or should change this.
&gt; 
&gt; &gt; 10. "Points" are annoying. I'm not personally a fan of 'agile
&gt; &gt; development', and I really don't want to get notifications about it.
&gt; &gt; Again, finer-grained control over notifications would probably solve
&gt; &gt; this.
&gt; 
&gt; Finer-grained control over notifications is probably the answer.
&gt; 
&gt; &gt; Because of these reasons, I think Trac actually discourages
&gt; &gt; contribution. It's *much* easier to report a bug, say, on GitHub than on
&gt; &gt; Trac, and it's much easier to get updates about progress on it; both of
&gt; &gt; which are things that are important to the average person reviewing a
&gt; &gt; bug.
&gt; 
&gt; I still believe we should first try to tweak Trac to fit our needs
&gt; before moving on to the next tool.
&gt; 
&gt; Thanks for your input!
&gt; 
&gt; Best,
&gt; Karsten



["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110913104834</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-13 10:48:34-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 9/13/11 5:20 AM, katmagic wrote:
&gt; On Mon, 2011-09-12 at 15:57 +0200, Karsten Loesing wrote:
&gt;&gt; On 9/6/11 11:01 PM, katmagic wrote:
&gt;&gt;&gt; Sorry for the late reply  I haven't checked my email in a while  but
&gt;&gt;&gt; I'm replying anyway because I've some strong feelings on this issue. In
&gt;&gt;&gt; short, Trac sucks. My issues with it are as follows:
&gt;&gt;&gt;
&gt;&gt;&gt; 1. The design sucks.
&gt;&gt;
&gt;&gt; You're right, it needs more green!
&gt;&gt;
&gt;&gt;&gt; 2. There's no AJAX. Now, I know a lot of people on this list hate Web
&gt;&gt;&gt; 2.0, but I really think its irrational. Especially over Tor, reloading
&gt;&gt;&gt; pages as many times as Trac makes you do is time consuming and
&gt;&gt;&gt; cumbersome. Of course, I'm not advocating making it *require*
&gt;&gt;&gt; JavaScript, but it would certainly be a nice feature.
&gt;&gt;
&gt;&gt; This isn't something we can influence.  Well, assuming that we want to
&gt;&gt; keep using Trac for a while.
&gt; 
&gt; Why should Trac be assumed?

This is primarily a question of effort.  We should first try to improve
the current situation by making simple changes to Trac.  Then we can try
more difficult changes to Trac.  And then we can think about moving to
another tool.  It's also unclear though whether another tool would solve
all our problems without introducing new ones.

&gt;&gt;&gt; 3. An unreasonable number of pages must be navigated through in order to
&gt;&gt;&gt; perform simple functions. The difficult of doing this prevents people
&gt;&gt;&gt; from finding bugs, and therefore discourages contribution.
&gt;&gt;
&gt;&gt; Can you be more specific how we could fix this?
&gt; 
&gt; Maybe hierarchical CSS menus on the header? There are a myriad of ways
&gt; to do it, though I don't think Trac can implement any of them.

OK.

&gt;&gt;&gt; 4. There are too many options. There are oodles of options that must be
&gt;&gt;&gt; fiddled with every single time a ticket is created, and if one makes a
&gt;&gt;&gt; mistake, it's not possible to go back and edit the ticket.
&gt;&gt;
&gt;&gt; The survey had questions about all statuses and ticket fields to
&gt;&gt; evaluate their usefulness.
&gt; 
&gt; 
&gt;&gt; 1.9 How relevant are the following ticket fields for you?
&gt; 
&gt;&gt; 1.9.5 Component
&gt; There are way too many of these for a flat list. A hierarchy of some
&gt; sort might work, but the component could just as easily be a keyword.

There's already a hierarchy in the list in the naming.  Tor Client, Tor
Relay, etc. are all related to (little-t) tor.  What we can do is rename
a few components to make it clearer what's a Tor sub-component and
what's a different tool:

"Tor Bridge" -&gt; "Tor (Bridge)"
"Tor Browser" -&gt; "Browser"
"Tor Check" -&gt; "Check"
"Tor Client" -&gt; "Tor (Client)"
"Tor Cloud" -&gt; "ServerCloud"
"Tor Directory Authority" -&gt; "Tor (Directory Authority)"
"Tor Hidden Services" -&gt; "Tor (Hidden Services)"
"Tor Relay" -&gt; "Tor (Relay)"
"Tor VM" -&gt; "VM"
"Tor Weather" -&gt; "Weather"
"Tor bundles/installation" -&gt; "Bundles/Installation"

I think I wanted to suggest something like this in my mail with the
other suggestions, but forgot.

&gt;&gt; 1.9.6 Version
&gt; Wow, that list is long.

It is!  Therefore the suggestion to throw out old versions.

&gt;&gt; 1.9.7 Keywords
&gt; It would be helpful to have a (perhaps hierarchical) list of previous
&gt; keywords to choose from, in addition to creating custom ones.

I don't think we can restrict what people are writing there.

&gt;&gt; 1.9.9 Parent ID
&gt; Tickets need to be in a hierarchy. Entering the parent ID manually like
&gt; this is really cumbersome.

I think we can assume that whoever wants to create child tickets is
capable of typing in or pasting a ticket number.  This is nothing that
the average bug reporter needs to do.

&gt;&gt; 1.9.10 Points
&gt;&gt; 1.9.11 Actual Points
&gt; What are these things for, anyway? If only mikeperry uses them, maybe
&gt; they should be local to a user? Maybe there should be a generic,
&gt; user-local field for annotations.

I don't think we can implement either of these two suggestions.

&gt;&gt; The fact that it's not possible to go back and edit a ticket may be a
&gt;&gt; permission problem.  What permissions are you missing?  On the other
&gt;&gt; hand, you can always add another comment saying what you really meant.
&gt; 
&gt; How am I supposed to know what permissions I have? And having to correct
&gt; things in separate comments will lead to a bunch of poorly worded,
&gt; inaccurate, or superfluous comments or tickets.

Well, your statement was that you cannot go back and edit a ticket.  I
didn't look into the permissions in detail and don't have a non-admin
user to test this, which is why I asked which permissions you think you
need.  But I guess I can find out myself.

&gt;&gt;&gt; 5. Searching for tickets is a confusing and somewhat difficult task. In
&gt;&gt;&gt; order to search for one's own tickets, for example, one must navigate a
&gt;&gt;&gt; menu with FORTY choices with unclear labels.
&gt;&gt;
&gt;&gt; Do you mean the custom query form?  Which parts of it do you find hard
&gt;&gt; to understand for new 
&gt; 
&gt; Even the 'View Tickets' view is confusing. Firstly, sorting shouldn't be
&gt; listed on the View Tickets page, but as an option chosen on that
&gt; sub-page. Secondly, the option descriptions are ambiguous. What does 'My
&gt; Tickets (all)' mean? Does it mean tickets I reported? Tickets assigned
&gt; to me? Tickets I'm CCed on? Tickets I've commented on? or some
&gt; combination of these?

I agree that the current list of Active Reports is confusing.  It seems
that Tor devs have quite different opinions on how to fix this, so I'll
save it for the second round of changes.  Easy fixes first.

&gt;&gt;&gt; 6. Searching in general doesn't work very well. Whatever algorithm Trac
&gt;&gt;&gt; uses for search is awful.
&gt; 
&gt;&gt; I don't think we can change this [without switching from Trac].
&gt; 
&gt; 
&gt;&gt;&gt; 7. Trac sends email about your own modifications, and about a lot of
&gt;&gt;&gt; things people probably don't want email about (i.e. every comment on a
&gt;&gt;&gt; ticket). A significantly improved method would be to offer notifications
&gt;&gt;&gt; on the website itself.
&gt;&gt;
&gt;&gt; I think two other people stated that they don't want to have emails for
&gt;&gt; their own modifications.  Actually, I find that useful, because I'm
&gt;&gt; using my inbox as an archive that I can search even when I'm offline.
&gt;&gt;
&gt;&gt; I'm not sure what you mean with notifications on the website itself.
&gt; 
&gt; There'd be a notice on the website navigation header alerting you that
&gt; you have messages. When you click on it, you'd be taken to a page with a
&gt; list of new tickets, replies, etc. You could also have notifications for
&gt; saved searches here, rather like Twitter.

Sounds useful, but unless it's in Trac 0.12, we won't have it.

&gt;&gt;&gt; 8. Trac does not integrate with Git. It should allow you to reference
&gt;&gt;&gt; commits from tickets, and reference tickets from commit messages (viewed
&gt;&gt;&gt; in the web interface). Being able to close tickets from commit messages
&gt;&gt;&gt; would also be useful.
&gt;&gt;
&gt;&gt; We need to install the Git plugin for that.  This is one of the things
&gt;&gt; we should change, yes.
&gt;&gt;
&gt;&gt;&gt; 9. HTTP Basic authentication could be confusing for some users. A
&gt;&gt;&gt; cookies-based system would probably be easier, and allow for persistent
&gt;&gt;&gt; logins (which most people consider a good thing).
&gt;&gt;
&gt;&gt; I don't think we can or should change this.
&gt;&gt;
&gt;&gt;&gt; 10. "Points" are annoying. I'm not personally a fan of 'agile
&gt;&gt;&gt; development', and I really don't want to get notifications about it.
&gt;&gt;&gt; Again, finer-grained control over notifications would probably solve
&gt;&gt;&gt; this.
&gt;&gt;
&gt;&gt; Finer-grained control over notifications is probably the answer.
&gt;&gt;
&gt;&gt;&gt; Because of these reasons, I think Trac actually discourages
&gt;&gt;&gt; contribution. It's *much* easier to report a bug, say, on GitHub than on
&gt;&gt;&gt; Trac, and it's much easier to get updates about progress on it; both of
&gt;&gt;&gt; which are things that are important to the average person reviewing a
&gt;&gt;&gt; bug.
&gt;&gt;
&gt;&gt; I still believe we should first try to tweak Trac to fit our needs
&gt;&gt; before moving on to the next tool.
&gt;&gt;
&gt;&gt; Thanks for your input!

Again, thanks for taking the time!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110913122134</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-09-13 12:21:34-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your	tasks</subject><body>

[Attachment #2 (multipart/signed)]


I'm replying to Roger's email because he condensed Karsten's email, but I can
probably answer lots of Trac questions in general. Will try to do so in this
thread.

* Roger Dingledine &lt;arma@mit.edu&gt; [2011:09:12 09:51 -0400]: 
&gt; On Tue, Sep 06, 2011 at 10:44:11AM +0200, Karsten Loesing wrote:
&gt; &gt; The Version field (3, 3, 5) is not used by many components and is
&gt; &gt; considered not very useful, because bug reporters get versions wrong in
&gt; &gt; most cases anyway.  Also, current versions of products are never in the
&gt; &gt; list.
&gt; &gt; 
&gt; &gt; [Suggestion: Delete all obsolete versions from the list, and try harder
&gt; &gt; to add new versions.]
&gt; 
&gt; When you delete a version from the list, does it vanish from tickets
&gt; that reference it? That is, will we be destroying history by deleting
&gt; an old version?

I just tested this:
https://trac.torproject.org/projects/tor/ticket/2926#comment:1

I created a Version (called Test), assigned a bug to it, then deleted the
Version. It appears to still be in the bug, so I think it is probably safe to
delete old versions. We could try a few more times with versions we don't
really care about anymore just to be sure. How useful are the versions when
deciding a bug applied to a very old version of Tor and is still present in a
current one? That mostly gets mentioned in the changelog and not on Trac,
right?

&gt; &gt; The Points (1, 0, 10) and Actual Points (1, 0, 10) fields are actively
&gt; &gt; used by only 1 person and read by 1 other person.
&gt; &gt; 
&gt; &gt; [Suggestion: Investigate whether it's possible to suppress email
&gt; &gt; notifications for changes to the Points and Actual Points fields.]
&gt; 
&gt; I actually find these mails about as useful as the other mails, insofar
&gt; as they tell me that Mike is thinking about working on a given ticket.
&gt; 
&gt; But I can see how people who don't care what Mike is going to work on
&gt; soon would not want to see them.

I can't see an obvious way to suppress these, looking through our trac.ini. 

In general, I think we should let the firehose spew and try to give people
methods for dealing with what comes out. Randomly 'hiding' parts of automatic
communication seems sketchy, and doing it because people can't figure out how
to configure their mail doesn't seem like a good reason. If we could figure out
a way to differentiate between 'mostly useful to everyone' and 'only useful to
information sponges' -- i.e., the latter gets Mike's emails, all ticket changes
and notifications, and the former just gets whatever we decide is important --
then I could see an argument for making a separate tor-bugs-full that gets
everything and letting tor-bugs keep the high-level stuff (opened tickets,
replies, reassignment, closed tickets).
 
&gt; How about a word that captures them all, like 'open'?

I think we can do this in Trac. (And I like 'open').
 
&gt; &gt; Better handling of duplicate bugs: The "dup" feature should have a bug
&gt; &gt; field that causes both bugs to be updated automatically with links to
&gt; &gt; each other.
&gt; 
&gt; Great idea. I sometimes do that manually for the other bug, but not
&gt; consistently.

There were a few plugins for this that we tried last year and they totally
sucked. This is a very old problem with Trac, in fact:
http://trac.edgewall.org/ticket/31

We could try again!

&gt; &gt; Better anonymous reporting (3 mentions): (First reporter) I'd like
&gt; &gt; better anonymous reporting and commenting.  (Second reporter) I've
&gt; &gt; bolded the 'New Ticket' and cypherpunks info on the landing page, though
&gt; &gt; creating a ticket via cypherpunks really should be a fist sized cherry
&gt; &gt; red button on that page...  (Third reporter) I think the 'cypherpunk'
&gt; &gt; user should have to add an email address in the Cc field. If they put
&gt; &gt; mailinator in there, so be it. But they at least need to know we need to
&gt; &gt; talk to them, or their bugs will probably just sit around forever.
&gt; 
&gt; Good idea. It is true that tickets created by cypherpunks very often do
&gt; not get any good followup. I would be tempted to say that cypherpunks
&gt; shouldn't be allowed to open tickets.
&gt; 
&gt; I wonder if the real problem here is that it's such a hassle to make a
&gt; trac account. (Is it?)

It isn't a hassle. It is literally one screen which asks for all your
information, at which point you hit 'Submit' and you have a trac account. The
whole process takes about 20 seconds.

I don't like the cypherpunks account either, for all reasons mentioned above.
But people creating new accounts in general are not required to provide an
email address either, so even if we removed cypherpunks's ability to create
tickets, we could potentially have the exact same problem anyway, unless we
decide to enforce email as part of account creation.

&gt; &gt; Separate system for users and developers: Trac is used for user support
&gt; &gt; too much. I wish we had a system that was JUST developer centric, no
&gt; &gt; user wiki pages or other crap that turns up in searches.
&gt; 
&gt; Yes!

Can I take this opportunity to plug ikiwiki again, if we do make a separate
wiki? It uses git, and we can use text editors to write documentation, rather
than writing in web boxes. For people who travel a lot it would be very useful
as an offline tool. (Inability to do bug-stuff offline is one thing that annoys
Roger, but I can't remember if he already mentioned that.)

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111019141245</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-10-19 14:12:45-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 9/6/11 10:44 AM, Karsten Loesing wrote:
&gt; Below are the results, plus some suggestions in the paragraphs starting
&gt; with "[Suggestion: " to separate my suggestions from result summaries.
&gt; 
&gt; Feel free to comment on the suggestions or add your own!
&gt; 
&gt; Depending on whether this thread is going to explode, I'll write another
&gt; summary in a few days to list the suggestions that people seem to agree
&gt; on and that we're going to implement.

Now that a few days have passed (43 to be precise), I'm writing the
first summary of the suggested changes that we should implement.  We can
always implement more changes later, but let's start somewhere:

1. Delete all milestones that have no tickets assigned to them or that
seem useful even without assigned tickets.  We have 224 milestones in
total, 37 of which having at least 1 ticket assigned.  That leaves 187
milestones with zero tickets assigned, most of which are a left-over
from the flyspray migration.

2. Try harder to include diffs in tor-wiki-changes notifications.  I
looked for an option that does this in Trac 0.12, but didn't find one.
Erinn, do you know how we could implement this change?

3. Delete all obsolete versions from the list, and try harder to add new
versions.  Erinn and I tried to delete old versions and found that it's
safe to do so.  The deleted version string in a ticket will remain the
same, but one cannot create new tickets using the deleted version or
change the version field of existing tickets to it.

4. Investigate whether we can merge "new", "assigned", "reopened", and
"accepted" into a single "open" status.  Erinn said we can do this in
Trac.  I had some trouble getting rid of the "new" status when trying
this in Trac 0.12, but didn't look too closely.  Erinn, can you try to
implement this in our Trac?

I'm aware that the full list of changes is longer.  These are just the
suggestions that everyone seemed to agree on and that are (hopefully)
easy to implement.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111019155003</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-10-19 15:50:03-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 2011-10-19, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; 3. Delete all obsolete versions from the list, and try harder to add new
&gt; versions.  Erinn and I tried to delete old versions and found that it's
&gt; safe to do so.  The deleted version string in a ticket will remain the
&gt; same, but one cannot create new tickets using the deleted version or
&gt; change the version field of existing tickets to it.

If a vandal changes the version field of an existing ticket, we will
be unable to undo that change.

I would still prefer that we make the Version' field a plain
text-entry field.  I think we still won't add new versions to the list
reliably, and I assume you don't plan to add the many different TBB
version numbers to the list.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111020064241</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-10-20 06:42:41-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 10/19/11 5:50 PM, Robert Ransom wrote:
&gt; On 2011-10-19, Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; 
&gt;&gt; 3. Delete all obsolete versions from the list, and try harder to add new
&gt;&gt; versions.  Erinn and I tried to delete old versions and found that it's
&gt;&gt; safe to do so.  The deleted version string in a ticket will remain the
&gt;&gt; same, but one cannot create new tickets using the deleted version or
&gt;&gt; change the version field of existing tickets to it.
&gt; 
&gt; If a vandal changes the version field of an existing ticket, we will
&gt; be unable to undo that change.

Ugh, you're right.  Haven't thought of that case.  I'll leave old
versions untouched for the moment and will only add new versions to the
list.

&gt; I would still prefer that we make the Version' field a plain
&gt; text-entry field.

I think if we don't give users a list of choices, the field will become
even less useful.

&gt; I think we still won't add new versions to the list
&gt; reliably, and I assume you don't plan to add the many different TBB
&gt; version numbers to the list.

Maybe we should add a line "Add version string to Trac" to the release
process?

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111020153446</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-10-20 15:34:46-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

[Attachment #2 (multipart/signed)]


* Karsten Loesing &lt;karsten.loesing@gmx.net&gt; [2011:10:19 16:12 +0200]: 
&gt; 2. Try harder to include diffs in tor-wiki-changes notifications.  I
&gt; looked for an option that does this in Trac 0.12, but didn't find one.
&gt; Erinn, do you know how we could implement this change?

I found this: http://trac.edgewall.org/ticket/1660 

If we are feeling adventurous, I suppose we could try the very old patches
listed there. Otherwise we might just want to comment on the bug and say we
wish to have this feature and ask what the status is.

&gt; 4. Investigate whether we can merge "new", "assigned", "reopened", and
&gt; "accepted" into a single "open" status.  Erinn said we can do this in
&gt; Trac.  I had some trouble getting rid of the "new" status when trying
&gt; this in Trac 0.12, but didn't look too closely.  Erinn, can you try to
&gt; implement this in our Trac?

How did you try it? I am nervous to try it on our current trac unless we
schedule a 'maintenance' window where we tell everyone trac might be broken. I
believe weasel has a test trac installed, I will look into testing it there
instead.


[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110604184233</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-06-04 18:42:33-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

[Attachment #2 (multipart/signed)]


Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

&gt; Anyway, here's the client-side sibling proposal to the
&gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt; speedup, I think it's worth it.)

Me too, although 25 to 50 percent seem to be more of best case
scenario and for some requests it's unlikely to make a difference.

&gt; Filename: xxx-optimistic-data-client.txt
&gt; Title: Optimistic Data for Tor: Client Side
&gt; Author: Ian Goldberg
&gt; Created: 2-Jun-2011
&gt; Status: Open
&gt; 
&gt; Overview:
&gt; 
&gt; This proposal (as well as its already-implemented sibling concerning the
&gt; server side) aims to reduce the latency of HTTP requests in particular
&gt; by allowing:
&gt; 1. SOCKS clients to optimistically send data before they are notified
&gt;     that the SOCKS connection has completed successfully

So it should mainly reduce the latence of HTTP requests
that need a completely new circuit, right?

Do you have a rough estimate of what percentage of requests would
actually be affected? I mean, how may HTTP requests that need a new
circuit are there usually compared to requests that can reuse an
already existing one (or even reuse the whole connection)?

I'm aware that this depends on various factors, but I think even
having an estimate that is only valid for a certain SOCKS client
visiting a certain site would be useful.

Did you also measure the differences between requests that need
a new circuit and requests that only need a new connection from
the exit node to the destination server?

&gt; 2. OPs to optimistically send DATA cells on streams in the CONNECT_WAIT
&gt;     state
&gt; 3. Exit nodes to accept and queue DATA cells while in the
&gt;     EXIT_CONN_STATE_CONNECTING state
&gt; 
&gt; This particular proposal deals with #1 and #2.
&gt; 
&gt; For more details (in general and for #3), see the sibling proposal 174
&gt; (Optimistic Data for Tor: Server Side), which has been implemented in
&gt; 0.2.3.1-alpha.
&gt; 
&gt; Motivation:
&gt; 
&gt; This change will save one OP&lt;-&gt;Exit round trip (down to one from two).
&gt; There are still two SOCKS Client&lt;-&gt;OP round trips (negligible time) and
&gt; two Exit&lt;-&gt;Server round trips.  Depending on the ratio of the
&gt; Exit&lt;-&gt;Server (Internet) RTT to the OP&lt;-&gt;Exit (Tor) RTT, this will
&gt; decrease the latency by 25 to 50 percent.  Experiments validate these
&gt; predictions. [Goldberg, PETS 2010 rump session; see
&gt; https://thunk.cs.uwaterloo.ca/optimistic-data-pets2010-rump.pdf ]

Can you describe the experiment some more?

I'm a bit puzzled by your "Results" graph. How many requests does
it actually represent and what kind of request were used?

&gt; Design:
&gt; 
&gt; Currently, data arriving on the SOCKS connection to the OP on a stream
&gt; in AP_CONN_STATE_CONNECT_WAIT is queued, and transmitted when the state
&gt; transitions to AP_CONN_STATE_OPEN.  Instead, when data arrives on the
&gt; SOCKS connection to the OP on a stream in AP_CONN_STATE_CONNECT_WAIT
&gt; (connection_edge_process_inbuf):
&gt; 
&gt; - Check to see whether optimistic data is allowed at all (see below).
&gt; - Check to see whether the exit node for this stream supports optimistic
&gt;   data (according to tor-spec.txt section 6.2, this means that the
&gt;   exit node's version number is at least 0.2.3.1-alpha).  If you don't
&gt;   know the exit node's version number (because it's not in your
&gt;   hashtable of fingerprints, for example), assume it does *not* support
&gt;   optimistic data.
&gt; - If both are true, transmit the data on the stream.
&gt; 
&gt; Also, when a stream transitions *to* AP_CONN_STATE_CONNECT_WAIT
&gt; (connection_ap_handshake_send_begin), do the above checks, and
&gt; immediately send any already-queued data if they pass.

How much data is the SOCKS client allowed to send optimistically?
I'm assuming there is a limit of how much data Tor will accept?

And if there is a limit, it would be useful to know if optimistically
sending data is really worth it in situations where the HTTP request
can't be optimistically sent as a whole.

While cutting down the time-to-first-byte for the HTTP request is always
nice, in most situations the time-to-last-byte is more important as the
HTTP server is unlikely to respond until the whole HTTP request has been
received.

&gt; SOCKS clients (e.g. polipo) will also need to be patched to take
&gt; advantage of optimistic data.  The simplest solution would seem to be to
&gt; just start sending data immediately after sending the SOCKS CONNECT
&gt; command, without waiting for the SOCKS server reply.  When the SOCKS
&gt; client starts reading data back from the SOCKS server, it will first
&gt; receive the SOCKS server reply, which may indicate success or failure.
&gt; If success, it just continues reading the stream as normal.  If failure,
&gt; it does whatever it used to do when a SOCKS connection failed.

For a SOCKS client that happens to be a HTTP proxy, it can be easier
to limit the support for "SOCKS with optimistic data" to "small"
requests instead to support it for all. (At least it would be for
Privoxy.)

For small requests it's (simplified):

1. Read the whole request from the client
2. Connect to SOCKS server/Deal with the response
3. Send the whole request
4. Read the response

As opposed to:

1. Read as much of the response as necessary to decide
   how to handle it (which usually translates to reading
   at least all the headers)
2. Connect to SOCKS server/Deal with the response
3. Send as much of the request as already known
4. Read some more of the client request
5. Send some more of the request to the server
6. Repeat steps 4 and 5 until the whole request has been
   sent or one of the connections is prematurely disconnected
7. Read the response

Implementing it for the latter case as well would be more work
and given that most requests are small enough to be read completely
before opening the SOCKS connections, the benefits may not be big
enough to justify it.

I wouldn't be surprised if there's a difference for some browsers, too.

And even if there isn't, it may still be useful to only implement
it for some requests to reduce the memory footprint of the local
Tor process.

&gt; Security implications:
&gt; 
&gt; ORs (for sure the Exit, and possibly others, by watching the
&gt; pattern of packets), as well as possibly end servers, will be able to
&gt; tell that a particular client is using optimistic data.  This of course
&gt; has the potential to fingerprint clients, dividing the anonymity set.

If some clients only use optimistic data for certain requests
it would divide the anonymity set some more, so maybe the
proposal should make a suggestion and maybe Tor should even
enforce a limit on the client side.

&gt; Performance and scalability notes:
&gt; 
&gt; OPs may queue a little more data, if the SOCKS client pushes it faster
&gt; than the OP can write it out.  But that's also true today after the
&gt; SOCKS CONNECT returns success, right?

It's my impression that there's currently a limit of how much
data Tor will read and buffer from the SOCKS client. Otherwise
Tor could end up buffering the whole request, which could be
rather large.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110604200608</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-04 20:06:08-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

On Sat, Jun 04, 2011 at 08:42:33PM +0200, Fabian Keil wrote:
&gt; Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; 
&gt; &gt; Anyway, here's the client-side sibling proposal to the
&gt; &gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt; &gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt; &gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt; &gt; speedup, I think it's worth it.)
&gt; 
&gt; Me too, although 25 to 50 percent seem to be more of best case
&gt; scenario and for some requests it's unlikely to make a difference.

The only requests for which it wouldn't make a difference are I think
ones that can reuse an existing stream (that is, you've visited that
same website recently enough that your browser is reusing an open TCP
connection to the HTTP server, but not so recently (e.g. at the same
time) that it's opening parallel connections).  So I think most of the
time, you'll see the benefit.

&gt; &gt; Filename: xxx-optimistic-data-client.txt
&gt; &gt; Title: Optimistic Data for Tor: Client Side
&gt; &gt; Author: Ian Goldberg
&gt; &gt; Created: 2-Jun-2011
&gt; &gt; Status: Open
&gt; &gt; 
&gt; &gt; Overview:
&gt; &gt; 
&gt; &gt; This proposal (as well as its already-implemented sibling concerning the
&gt; &gt; server side) aims to reduce the latency of HTTP requests in particular
&gt; &gt; by allowing:
&gt; &gt; 1. SOCKS clients to optimistically send data before they are notified
&gt; &gt;     that the SOCKS connection has completed successfully
&gt; 
&gt; So it should mainly reduce the latence of HTTP requests
&gt; that need a completely new circuit, right?

No, just ones that need a new TCP stream.  The optimistic data stuff is
about quickly sending data in just-being-constructed streams within an
already-constructed circuit.

&gt; Do you have a rough estimate of what percentage of requests would
&gt; actually be affected? I mean, how may HTTP requests that need a new
&gt; circuit are there usually compared to requests that can reuse an
&gt; already existing one (or even reuse the whole connection)?

Assuming you mean "stream" instead of "circuit" here, then, as above, I
think most HTTP connections would be in this category.  It might be
interesting to examine some HTTP traces to see, though.  &lt;shoutout
target="Kevin"&gt;Kevin, you were looking at some HTTP traces for other
reasons, right?  Anything in there that may help answer this
question?&lt;/shoutout&gt;

&gt; I'm aware that this depends on various factors, but I think even
&gt; having an estimate that is only valid for a certain SOCKS client
&gt; visiting a certain site would be useful.

I think overall across sites would be a better number, no?

&gt; Did you also measure the differences between requests that need
&gt; a new circuit and requests that only need a new connection from
&gt; the exit node to the destination server?

If there's a new connection from the exit node to the destination
server, then there's a new stream, and you would see the full benefit of
this proposal.

&gt; &gt; This change will save one OP&lt;-&gt;Exit round trip (down to one from two).
&gt; &gt; There are still two SOCKS Client&lt;-&gt;OP round trips (negligible time) and
&gt; &gt; two Exit&lt;-&gt;Server round trips.  Depending on the ratio of the
&gt; &gt; Exit&lt;-&gt;Server (Internet) RTT to the OP&lt;-&gt;Exit (Tor) RTT, this will
&gt; &gt; decrease the latency by 25 to 50 percent.  Experiments validate these
&gt; &gt; predictions. [Goldberg, PETS 2010 rump session; see
&gt; &gt; https://thunk.cs.uwaterloo.ca/optimistic-data-pets2010-rump.pdf ]
&gt; 
&gt; Can you describe the experiment some more?

A webfetch client, using a single circuit, downloaded a web page from a
fixed server (to eliminate variance due to different server RTTs and
performance) 950 times.  Each time, it randomly decided whether to use
optimistic data (the "SOCKS 4b" line) or not (the "SOCKS 4a" line).
The time from the start of the request (webfetch making the SOCKS
connection) to the time the first data byte of the HTTP response
("HTTP/1.1 200 OK") arrived at webfetch was recorded, and the two CDFs
of those values were plotted.

&gt; I'm a bit puzzled by your "Results" graph. How many requests does
&gt; it actually represent and what kind of request were used?

As above, approximately 475 HTTP GET requests of each type.  Note that
the size of the fetched page is irrelevant to this measurement.

&gt; How much data is the SOCKS client allowed to send optimistically?
&gt; I'm assuming there is a limit of how much data Tor will accept?

One stream window.

&gt; And if there is a limit, it would be useful to know if optimistically
&gt; sending data is really worth it in situations where the HTTP request
&gt; can't be optimistically sent as a whole.

I suspect it's rare that an HTTP request doesn't fit in one stream
window (~250 KB).

&gt; While cutting down the time-to-first-byte for the HTTP request is always
&gt; nice, in most situations the time-to-last-byte is more important as the
&gt; HTTP server is unlikely to respond until the whole HTTP request has been
&gt; received.

What?  No, I think you misunderstand.  The time-to-first-byte is the
time until the first byte of the *response* is received back at the
client.  That's when the user's screen will start changing; previous
work (does someone have a cite handy?) has indicated that if a page
takes too long to start to change, users get frustrated with the
slowness.

&gt; &gt; SOCKS clients (e.g. polipo) will also need to be patched to take
&gt; &gt; advantage of optimistic data.  The simplest solution would seem to be to
&gt; &gt; just start sending data immediately after sending the SOCKS CONNECT
&gt; &gt; command, without waiting for the SOCKS server reply.  When the SOCKS
&gt; &gt; client starts reading data back from the SOCKS server, it will first
&gt; &gt; receive the SOCKS server reply, which may indicate success or failure.
&gt; &gt; If success, it just continues reading the stream as normal.  If failure,
&gt; &gt; it does whatever it used to do when a SOCKS connection failed.
&gt; 
&gt; For a SOCKS client that happens to be a HTTP proxy, it can be easier
&gt; to limit the support for "SOCKS with optimistic data" to "small"
&gt; requests instead to support it for all. (At least it would be for
&gt; Privoxy.)
&gt; 
&gt; For small requests it's (simplified):
&gt; 
&gt; 1. Read the whole request from the client
&gt; 2. Connect to SOCKS server/Deal with the response
&gt; 3. Send the whole request
&gt; 4. Read the response
&gt; 
&gt; As opposed to:
&gt; 
&gt; 1. Read as much of the response as necessary to decide
&gt;    how to handle it (which usually translates to reading
&gt;    at least all the headers)
&gt; 2. Connect to SOCKS server/Deal with the response
&gt; 3. Send as much of the request as already known
&gt; 4. Read some more of the client request
&gt; 5. Send some more of the request to the server
&gt; 6. Repeat steps 4 and 5 until the whole request has been
&gt;    sent or one of the connections is prematurely disconnected
&gt; 7. Read the response
&gt; 
&gt; Implementing it for the latter case as well would be more work
&gt; and given that most requests are small enough to be read completely
&gt; before opening the SOCKS connections, the benefits may not be big
&gt; enough to justify it.

A reasonable proxy server (e.g. polipo, I'm pretty sure) streams data
wherever possible.  Certainly for responses: I seem to remember that
privoxy indeed reads the whole response from the HTTP server before
starting to send it to the web client, which adds a ton of extra delay
in TTFB.  I'm pretty sure polipo doesn't do that, but just streams the
data as it arrives.  Each program is likely to do the corresponding
thing with the requests.

&gt; I wouldn't be surprised if there's a difference for some browsers, too.

How so?  The browser sends the HTTP request to the proxy, and reads the
response.  What different behaviour might it have?  The only one I can
think of is "pipelining" requests, which some browsers/proxies/servers
support and others don't.  That is, if you've got 4 files to download
from the same server, send the 4 HTTP requests on the same TCP stream
before getting responses from any of them.  In that case, you'll see the
benefit for the first request in the stream, but not the others, since
the stream will already be open.

&gt; And even if there isn't, it may still be useful to only implement
&gt; it for some requests to reduce the memory footprint of the local
&gt; Tor process.

Roger/Nick: is there indeed a limit to how much data from the SOCKS
client the OP will queue up today before the stream is open?

&gt; &gt; Security implications:
&gt; &gt; 
&gt; &gt; ORs (for sure the Exit, and possibly others, by watching the
&gt; &gt; pattern of packets), as well as possibly end servers, will be able to
&gt; &gt; tell that a particular client is using optimistic data.  This of course
&gt; &gt; has the potential to fingerprint clients, dividing the anonymity set.
&gt; 
&gt; If some clients only use optimistic data for certain requests
&gt; it would divide the anonymity set some more, so maybe the
&gt; proposal should make a suggestion and maybe Tor should even
&gt; enforce a limit on the client side.

I think the worse case is when most people are using optimistic data,
but some older clients don't.  They'll stand out more readily.

&gt; &gt; Performance and scalability notes:
&gt; &gt; 
&gt; &gt; OPs may queue a little more data, if the SOCKS client pushes it faster
&gt; &gt; than the OP can write it out.  But that's also true today after the
&gt; &gt; SOCKS CONNECT returns success, right?
&gt; 
&gt; It's my impression that there's currently a limit of how much
&gt; data Tor will read and buffer from the SOCKS client. Otherwise
&gt; Tor could end up buffering the whole request, which could be
&gt; rather large.

It would be.  As above, is this actually true, though?

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110604215843</emailId><senderName>Kevin Bauer</senderName><senderEmail>ksbauer@gmail.com</senderEmail><timestampReceived>2011-06-04 21:58:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

&gt; Assuming you mean "stream" instead of "circuit" here, then, as above, I
&gt; think most HTTP connections would be in this category.  It might be
&gt; interesting to examine some HTTP traces to see, though.  &lt;shoutout
&gt; target="Kevin"&gt;Kevin, you were looking at some HTTP traces for other
&gt; reasons, right?  Anything in there that may help answer this
&gt; question?&lt;/shoutout&gt;


This is a great question. 

Google released a study about a year ago [1] that characterized crawled web pages in \
terms of their total size, the number of distinct destination hosts per page, the \
number of HTTP GETs per page, and other attributes. Their data indicates that the \
median web page requires that the client connect to 5 distinct destination hosts and \
issue 6.25 GETs per host. 

Put another way, a typical web page requires 5 streams, each of which issue multiple \
GETs. The full distributions of these statistics are available at [1].

Assuming persistent HTTP connections, with this proposal, only a stream's initial GET \
request would experience an improvement in time-to-first-byte, while subsequent GETs \
would be unaffected. 

However, by reducing the time-to-first-byte for even just the first request per \
stream, the user is able to start fetching subsequent streams sooner, and thus, \
retrieve the whole page faster. 

Kevin

[1] https://code.google.com/speed/articles/web-metrics.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110605031553</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-06-05 03:15:53-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

On Thu, Jun 2, 2011 at 8:45 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; Sorry this took so long.  As usual, things got inserted ahead of it in
&gt; the priority queue.  :-p
&gt;
&gt; Anyway, here's the client-side sibling proposal to the
&gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt; speedup, I think it's worth it.)
&gt;

Added as proposal 181.

I'm a little worried about the robustness issue: currently, if an exit
node refuses a BEGIN request (because of its exit policy typically)
the Tor client will retry at another exit node.  But if optimistic
data is in use, it seems that the client's initial data will be lost,
unless the client keeps a copy around to send to other exits as
required.

As for the application support matter, I wonder how hard it will be to
actually get support.  We're trying to phase out HTTP proxies in our
bundles, so it seems we'd need to tweak browsers to send
optimistically.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110605122943</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-05 12:29:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

On Sat, Jun 04, 2011 at 11:15:53PM -0400, Nick Mathewson wrote:
&gt; On Thu, Jun 2, 2011 at 8:45 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt; Sorry this took so long.  As usual, things got inserted ahead of it in
&gt; &gt; the priority queue.  :-p
&gt; &gt;
&gt; &gt; Anyway, here's the client-side sibling proposal to the
&gt; &gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt; &gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt; &gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt; &gt; speedup, I think it's worth it.)
&gt; &gt;
&gt; 
&gt; Added as proposal 181.
&gt; 
&gt; I'm a little worried about the robustness issue: currently, if an exit
&gt; node refuses a BEGIN request (because of its exit policy typically)
&gt; the Tor client will retry at another exit node.  But if optimistic
&gt; data is in use, it seems that the client's initial data will be lost,
&gt; unless the client keeps a copy around to send to other exits as
&gt; required.

That's a good point.  Perhaps the latter is the right thing to do?  That
would be sort of a combination of what we do now and the above proposal:
buffer the data (as we do now), but also send it (as the proposal).
When you eventually receive the CONNECTED, flush anything in the buffer
you've already sent.  If you eventually receive END instead of
CONNECTED, try another circuit, using the buffered data?

&gt; As for the application support matter, I wonder how hard it will be to
&gt; actually get support.  We're trying to phase out HTTP proxies in our
&gt; bundles, so it seems we'd need to tweak browsers to send
&gt; optimistically.

Don't we already modify the browser in the bundle?  You need _something_
(either modifications to the browser or a privacy-aware proxy) to remove
any application-level privacy leaks that might exist, right?

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110605132955</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-06-05 13:29:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

[Attachment #2 (multipart/signed)]


Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

&gt; On Sat, Jun 04, 2011 at 08:42:33PM +0200, Fabian Keil wrote:
&gt; &gt; Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

&gt; &gt; &gt; Overview:
&gt; &gt; &gt; 
&gt; &gt; &gt; This proposal (as well as its already-implemented sibling concerning the
&gt; &gt; &gt; server side) aims to reduce the latency of HTTP requests in particular
&gt; &gt; &gt; by allowing:
&gt; &gt; &gt; 1. SOCKS clients to optimistically send data before they are notified
&gt; &gt; &gt;     that the SOCKS connection has completed successfully
&gt; &gt; 
&gt; &gt; So it should mainly reduce the latence of HTTP requests
&gt; &gt; that need a completely new circuit, right?
&gt; 
&gt; No, just ones that need a new TCP stream.  The optimistic data stuff is
&gt; about quickly sending data in just-being-constructed streams within an
&gt; already-constructed circuit.

I see.
 
&gt; &gt; Do you have a rough estimate of what percentage of requests would
&gt; &gt; actually be affected? I mean, how may HTTP requests that need a new
&gt; &gt; circuit are there usually compared to requests that can reuse an
&gt; &gt; already existing one (or even reuse the whole connection)?
&gt; 
&gt; Assuming you mean "stream" instead of "circuit" here, then, as above, I
&gt; think most HTTP connections would be in this category.  It might be
&gt; interesting to examine some HTTP traces to see, though.  &lt;shoutout
&gt; target="Kevin"&gt;Kevin, you were looking at some HTTP traces for other
&gt; reasons, right?  Anything in there that may help answer this
&gt; question?&lt;/shoutout&gt;

I actually meant "how many HTTP requests that need a new circuit
are there usually compared to requests that only need an new stream
(or reuse the whole connection)?"

You've already written above that HTTP request that need a completely
new circuit aren't affected anyway, so that leaves the requests that
need a new stream and those that don't and I can get a rough idea
about those myself by looking at my logs (your mileage is likely to
vary of course):

fk@r500 ~ $privoxy-log-parser.pl --statistics /usr/jails/privoxy-jail/var/log/privoxy/privoxy.log.*
Client requests total: 430598
[...]
Outgoing requests: 300971 (69.90%)
Server keep-alive offers: 156193 (36.27%)
New outgoing connections: 237488 (55.15%)
Reused connections: 63483 (14.74%; server offers accepted: 40.64%)
Empty responses: 5244 (1.22%)
Empty responses on new connections: 430 (0.10%)
Empty responses on reused connections: 4814 (1.12%)
[...]

&gt; &gt; I'm aware that this depends on various factors, but I think even
&gt; &gt; having an estimate that is only valid for a certain SOCKS client
&gt; &gt; visiting a certain site would be useful.
&gt; 
&gt; I think overall across sites would be a better number, no?

Sure.

&gt; &gt; How much data is the SOCKS client allowed to send optimistically?
&gt; &gt; I'm assuming there is a limit of how much data Tor will accept?
&gt; 
&gt; One stream window.
&gt; 
&gt; &gt; And if there is a limit, it would be useful to know if optimistically
&gt; &gt; sending data is really worth it in situations where the HTTP request
&gt; &gt; can't be optimistically sent as a whole.
&gt; 
&gt; I suspect it's rare that an HTTP request doesn't fit in one stream
&gt; window (~250 KB).

I agree, I expected the stream window to be a lot smaller.

&gt; &gt; While cutting down the time-to-first-byte for the HTTP request is always
&gt; &gt; nice, in most situations the time-to-last-byte is more important as the
&gt; &gt; HTTP server is unlikely to respond until the whole HTTP request has been
&gt; &gt; received.
&gt; 
&gt; What?  No, I think you misunderstand.  The time-to-first-byte is the
&gt; time until the first byte of the *response* is received back at the
&gt; client.

Makes sense. Thanks for the clarification.

&gt; &gt; &gt; SOCKS clients (e.g. polipo) will also need to be patched to take
&gt; &gt; &gt; advantage of optimistic data.  The simplest solution would seem to be to
&gt; &gt; &gt; just start sending data immediately after sending the SOCKS CONNECT
&gt; &gt; &gt; command, without waiting for the SOCKS server reply.  When the SOCKS
&gt; &gt; &gt; client starts reading data back from the SOCKS server, it will first
&gt; &gt; &gt; receive the SOCKS server reply, which may indicate success or failure.
&gt; &gt; &gt; If success, it just continues reading the stream as normal.  If failure,
&gt; &gt; &gt; it does whatever it used to do when a SOCKS connection failed.
&gt; &gt; 
&gt; &gt; For a SOCKS client that happens to be a HTTP proxy, it can be easier
&gt; &gt; to limit the support for "SOCKS with optimistic data" to "small"
&gt; &gt; requests instead to support it for all. (At least it would be for
&gt; &gt; Privoxy.)
&gt; &gt; 
&gt; &gt; For small requests it's (simplified):
&gt; &gt; 
&gt; &gt; 1. Read the whole request from the client
&gt; &gt; 2. Connect to SOCKS server/Deal with the response
&gt; &gt; 3. Send the whole request
&gt; &gt; 4. Read the response
&gt; &gt; 
&gt; &gt; As opposed to:
&gt; &gt; 
&gt; &gt; 1. Read as much of the response as necessary to decide
&gt; &gt;    how to handle it (which usually translates to reading
&gt; &gt;    at least all the headers)
&gt; &gt; 2. Connect to SOCKS server/Deal with the response
&gt; &gt; 3. Send as much of the request as already known
&gt; &gt; 4. Read some more of the client request
&gt; &gt; 5. Send some more of the request to the server
&gt; &gt; 6. Repeat steps 4 and 5 until the whole request has been
&gt; &gt;    sent or one of the connections is prematurely disconnected
&gt; &gt; 7. Read the response
&gt; &gt; 
&gt; &gt; Implementing it for the latter case as well would be more work
&gt; &gt; and given that most requests are small enough to be read completely
&gt; &gt; before opening the SOCKS connections, the benefits may not be big
&gt; &gt; enough to justify it.
&gt; 
&gt; A reasonable proxy server (e.g. polipo, I'm pretty sure) streams data
&gt; wherever possible.

Sure, but even polipo can't stream data the client didn't send yet and
in case of requests larger than a few MTU sizes, for example file uploads,
the SOCKS connection is probably established before the whole client
request has been received.

&gt;                    Certainly for responses: I seem to remember that
&gt; privoxy indeed reads the whole response from the HTTP server before
&gt; starting to send it to the web client, which adds a ton of extra delay
&gt; in TTFB.

Privoxy buffers the whole response if it's configured to filter it
(as the decision to modify the first response byte could depend on
the last byte).

If no filters are enabled (this seems to be the case for the
configuration Orbot uses), or no filters apply, the response
data is forwarded to the client as it arrives.

&gt; &gt; I wouldn't be surprised if there's a difference for some browsers, too.
&gt; 
&gt; How so?  The browser sends the HTTP request to the proxy, and reads the
&gt; response.  What different behaviour might it have?  The only one I can
&gt; think of is "pipelining" requests, which some browsers/proxies/servers
&gt; support and others don't.  That is, if you've got 4 files to download
&gt; from the same server, send the 4 HTTP requests on the same TCP stream
&gt; before getting responses from any of them.  In that case, you'll see the
&gt; benefit for the first request in the stream, but not the others, since
&gt; the stream will already be open.

I was thinking about file uploads. Currently it's not necessary for
the client to read the whole file before the SOCKS connection is even
established, but it would be, to optimistically send it (or at least
the first part of it).

Even old browsers support file uploads up to ~2GB, so this would
also be a case where the request might be too large to fit in the
stream window.

While file uploads are certainly rare (and successfully pushing
2GB through Tor might be a challenge), it might be worth thinking
about how to handle them anyway. Letting the Tor client cache the
whole file is probably not the best solution above a certain file
size.


I also thought about another case where it's not obvious to me
what to do: a HTTPS connection made by a browser through a HTTP
proxy.

Currently the browser will not start sending data for the server
until the proxy has signaled that the connection has been established,
which the proxy doesn't know until told so by the SOCKS server.

If the HTTP proxy "optimistically lies" to the client it will
not be able to send a proper error message if the SOCKS connection
actually can't be established. Of course this only matters if
the client does something useful with the error message, and at
least Firefox stopped doing that a while ago.

The impact on SSL connections is probably less significant anyway,
though.


Thanks a lot for the detailed response.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110608215141</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-06-08 21:51:41-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

On Sun, Jun 5, 2011 at 8:29 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; On Sat, Jun 04, 2011 at 11:15:53PM -0400, Nick Mathewson wrote:
&gt;&gt; On Thu, Jun 2, 2011 at 8:45 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;&gt; &gt; Sorry this took so long.  As usual, things got inserted ahead of it in
&gt;&gt; &gt; the priority queue.  :-p
&gt;&gt; &gt;
&gt;&gt; &gt; Anyway, here's the client-side sibling proposal to the
&gt;&gt; &gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt;&gt; &gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt;&gt; &gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt;&gt; &gt; speedup, I think it's worth it.)
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt; Added as proposal 181.
&gt;&gt;
&gt;&gt; I'm a little worried about the robustness issue: currently, if an exit
&gt;&gt; node refuses a BEGIN request (because of its exit policy typically)
&gt;&gt; the Tor client will retry at another exit node.  But if optimistic
&gt;&gt; data is in use, it seems that the client's initial data will be lost,
&gt;&gt; unless the client keeps a copy around to send to other exits as
&gt;&gt; required.
&gt;
&gt; That's a good point.  Perhaps the latter is the right thing to do?  That
&gt; would be sort of a combination of what we do now and the above proposal:
&gt; buffer the data (as we do now), but also send it (as the proposal).
&gt; When you eventually receive the CONNECTED, flush anything in the buffer
&gt; you've already sent.  If you eventually receive END instead of
&gt; CONNECTED, try another circuit, using the buffered data?

Maybe!  It seems plausible to me, though we should definitely ponder
the security/performance implications.

&gt;&gt; As for the application support matter, I wonder how hard it will be to
&gt;&gt; actually get support.  We're trying to phase out HTTP proxies in our
&gt;&gt; bundles, so it seems we'd need to tweak browsers to send
&gt;&gt; optimistically.
&gt;
&gt; Don't we already modify the browser in the bundle?  You need _something_
&gt; (either modifications to the browser or a privacy-aware proxy) to remove
&gt; any application-level privacy leaks that might exist, right?

Yeah.  Actually, handling application-level privacy leaks *can't* be
done with a regular proxy, unless the proxy gets to MITM ssl
connections, which probably isn't a good idea.

All I'm saying here, though, is that I'm wondering how hard the change
will be to actually make.  Most socks client code tends to get
isolated in an application's network layer as a replacement for
"connect", so unless the application is already set up to do "connect,
send send send" rather than "connect, wait for connect, send send
send", the application modifications will be tricky.

As an alternative, the socks proxy (Tor) could be told to say
"connected" immediately, so that the app starts sending. I don't know
how badly this would break browsers, though.  Probably not a good
idea.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110405075644</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-04-05 07:56:44-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

[Attachment #2 (multipart/signed)]


On Mon, 4 Apr 2011 21:51:57 -0700
"Jonathan \"Duke\" Leto" &lt;jonathan@leto.net&gt; wrote:

&gt; Parrot recently added a GSoC proposal idea to embed Parrot into Tor.
&gt; It would be great to get the feedback from Tor developers.
&gt; 
&gt; Also, this could be under the Parrot or the Tor GSoC project,
&gt; whichever makes the most sense.
&gt; 
&gt; The proposal idea could use more detail, but the high-level view that
&gt; I imagine is:
&gt; 
&gt; 1) Allow Parrot to talk to libtor (this will use NCI - Native Call
&gt; Interface) via PIR
&gt; 2) Ability to create Parrot interpreter objects from within Tor via C
&gt; 3) Write glue code for a High Level Language (HLL) to talk to libtor

I've never heard of libtor'.  What's that?

&gt; There are various HLL's to choose from: Lua, TCL, Perl 6, Winxed, NQP
&gt; and others.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110405141716</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-04-05 14:17:16-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

[Attachment #2 (multipart/signed)]


On Tue, 5 Apr 2011 00:56:44 -0700
Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:

&gt; On Mon, 4 Apr 2011 21:51:57 -0700
&gt; "Jonathan \"Duke\" Leto" &lt;jonathan@leto.net&gt; wrote:
&gt; 
&gt; &gt; Parrot recently added a GSoC proposal idea to embed Parrot into Tor.
&gt; &gt; It would be great to get the feedback from Tor developers.
&gt; &gt; 
&gt; &gt; Also, this could be under the Parrot or the Tor GSoC project,
&gt; &gt; whichever makes the most sense.
&gt; &gt; 
&gt; &gt; The proposal idea could use more detail, but the high-level view that
&gt; &gt; I imagine is:
&gt; &gt; 
&gt; &gt; 1) Allow Parrot to talk to libtor (this will use NCI - Native Call
&gt; &gt; Interface) via PIR
&gt; &gt; 2) Ability to create Parrot interpreter objects from within Tor via C
&gt; &gt; 3) Write glue code for a High Level Language (HLL) to talk to libtor
&gt; 
&gt; I've never heard of libtor'.  What's that?

And why do you think we should want to embed Parrot into Tor?


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110405162907</emailId><senderName>"Jonathan \"Duke\" Leto"</senderName><senderEmail>jonathan@leto.net</senderEmail><timestampReceived>2011-04-05 16:29:07-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

Howdy,

&gt;&gt; I've never heard of libtor.  What's that?

I assumed that there was some type of core C/C++ library that implements the
core functionality of Tor.

It is the thing that this email thread references:

https://lists.torproject.org/pipermail/tor-talk/2009-October/017378.html

&gt; And why do you think we should want to embed Parrot into Tor?

It would allow scripting Tor with a variety of languages, but I understand if
embedding is not wanted.  I would like for Parrot to be able to talk to libtor,
so a project that worked on bindings from Parrot VM would be
interesting as well,
and not involve any embedding.

Mostly, I wanted feedback from Tor developers about the feasibility and interest
in mentoring something like this.

Duke

-- 
Jonathan "Duke" Leto
jonathan@leto.net
http://leto.net
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110405163928</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-04-05 16:39:28-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

Hi Jonathan. Are you aware of the Tor control protocol [1]? This
already provides an RPC method for other applications to communicate
with a Tor instance. Most often this is used via TorCtl which is in
Python [2], though there's Java and C# counterparts too.

This gives a means of querying information, receiving events,
creating/destroying circuits (which was your initial project idea),
etc.

Cheers! -Damian

[1] https://gitweb.torproject.org/torspec.git/blob/HEAD:/control-spec.txt
[2] https://gitweb.torproject.org/pytorctl.git
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110405164943</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-04-05 16:49:43-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

On Tue, Apr 05, 2011 at 09:29:07AM -0700, Jonathan Duke Leto wrote:
&gt; &gt;&gt; I've never heard of ?libtor?.  What's that?
&gt; 
&gt; I assumed that there was some type of core C/C++ library that implements the
&gt; core functionality of Tor.
&gt; 
&gt; It is the thing that this email thread references:
&gt; 
&gt; https://lists.torproject.org/pipermail/tor-talk/2009-October/017378.html

There is a libtor, but it's just an internal library that contains some
of the functions shared between the various Tor tools as they're built.
It isn't designed for outside apps to link to, and it doesn't actually
offer the API that you'd want.

But you're in luck -- Tor has a controller interface that lets other
applications interact with the Tor process over a local socket, using
a simple smtp-style protocol:
https://gitweb.torproject.org/torspec.git/blob/HEAD:/control-spec.txt

So that means you can write your controller application in whatever
language you like. Vidalia uses C++, but it hasn't really broken out
its controller support into a reusable library. The best we've got is
a Python library:
https://gitweb.torproject.org/pytorctl.git
that is used by a variety of applications, ranging from a curses-based
Tor UI:
http://www.atagar.com/arm/
to a set of back-end scripts to build paths in nonstandard ways, measure
bandwidth, and do other experiments:
https://gitweb.torproject.org/torflow.git

&gt; &gt; And why do you think we should want to embed Parrot into Tor?
&gt; 
&gt; It would allow scripting Tor with a variety of languages, but I understand if
&gt; embedding is not wanted.  I would like for Parrot to be able to talk to libtor,
&gt; so a project that worked on bindings from Parrot VM would be
&gt; interesting as well,
&gt; and not involve any embedding.

A Parrot library that talks to Tor via the controller interface would
be the right way to do it. The next question would be: if such a thing
existed, would anybody use it? That one is harder to answer. It probably
depends in part on how good it is. :)

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110303000453</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-03-03 00:04:53-0400</timestampReceived><subject>Re: [tor-dev] Proposal status, with suggestions for fun stuff to do</subject><body>

On 03/01/2011 10:35 PM, Nick Mathewson wrote:
&gt; 
&gt;    xxx-draft-spec-for-TLS-normalization.txt
&gt; 
&gt;      Here's Jacob's proposal for certificate normalization.  It
&gt;      should get renamed, given a proposal number, and called "Open"
&gt;      or "Draft" depending on how much the details are likely to
&gt;      change.

I've renamed it and created it as prop 179, it's now pushed into the
main torspec repo as "179 [DRAFT] TLS certificate and parameter
normalization"

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110201025200</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-01 02:52:00-0400</timestampReceived><subject>Re: Proposal 176: Proposed version-3 link handshake for Tor</subject><body>

On Mon, Jan 31, 2011 at 9:50 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
 [...]
&gt;   To authenticate the server, the client MUST check the following:
&gt;     * The CERTS cell contains exactly one CertType 1 "Link" certificate.
&gt;     * The CERTS cell contains exactly one CertType 2 "ID"
&gt;       certificate.
&gt;     * Both certificates have validAfter and validUntil dates that
&gt;       are not expired.
&gt;     * The certified key in the Link certificate matches the
&gt;       link key that was used to negotiate the TLS connection.
&gt;     * The certified key in the ID certificate is a 1024-bit RSA key.
&gt;     * The certified key in the ID certificate was used to sign both
&gt;       certificates.
&gt;     * The link certificate is correctly signed with the key in the
&gt;       ID certificate
&gt;     * The ID certificate is correctly self-signed.

Robert Ransom responded to an earlier draft of this proposal,
suggesting that instead of being self-signed, the ID certificate
should be cross-certified by the link key.  He said:


&gt; &gt; Yes.  I'm not exactly sure why I'm suggesting it.
&gt; &gt;
&gt; &gt; When an OpenPGP public key has a subkey which can be used to generate
&gt; &gt; signatures, GPG requires that that subkey sign the main public key, in
&gt; &gt; addition to requiring that the main public key sign the subkey.  The
&gt; &gt; GPG man page states that this prevents some attacks.  I don't know
&gt; &gt; whether the cross-certification I'm asking for above prevents any
&gt; &gt; attacks we care about.

[Posted here with permission]

yrs,
-- 
Nick

</body></email><email><emailId>20110201034627</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-02-01 03:46:27-0400</timestampReceived><subject>Re: Proposal 176: Proposed version-3 link handshake for Tor</subject><body>

On Mon, Jan 31, 2011 at 9:50 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;   certificates.  The security properties of this protocol are just
&gt;   fine; the problem was that our behavior of sending
&gt;   two-certificate chains made Tor easy to identify.

Actually, two (or more) certificates are very common when talking to
HTTPS servers. (See mail.google.com:443 for example.)
&gt;   And the cell-based part of the V3 handshake, in summary, is:
&gt;
&gt;    C&lt;-&gt;S: TLS handshake where S sends a "v3 certificate"
&gt;
&gt;    In TLS:
&gt;
&gt;       C-&gt;S: VERSIONS cell
&gt;       S-&gt;C: VERSIONS cell, CERT cell, AUTH_CHALLENGE cell, NETINFO cell
&gt;
&gt;       C-&gt;S: Optionally: CERT cell, AUTHENTICATE cell

Forgive my ignorance here. I have only a passing knowledge of the Tor
protocol these days.

If you wish to prevent scanning for Tor nodes then you could have the
client put the SHA256 of the server's identity key in its initial
cell. This supposes that the client always knows the identity of the
server that it's connecting to; which may not be the case.

If the client doesn't care about authenticating to the server, then it
could optimistically send cells predicated on a correct version
prediction. SSH does this (see RFC 4253, section 7.1,
'first_kex_packet_follows'). The server will know if the prediction
was correct once it sees the client's version and can discard
optimistic cells.


AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org

</body></email><email><emailId>20110202171626</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-02 17:16:26-0400</timestampReceived><subject>Re: Proposal 176: Proposed version-3 link handshake for Tor</subject><body>

On Mon, Jan 31, 2011 at 10:46 PM, Adam Langley &lt;agl@imperialviolet.org&gt; wrote:
&gt; On Mon, Jan 31, 2011 at 9:50 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;&gt;   certificates.  The security properties of this protocol are just
&gt;&gt;   fine; the problem was that our behavior of sending
&gt;&gt;   two-certificate chains made Tor easy to identify.
&gt;
&gt; Actually, two (or more) certificates are very common when talking to
&gt; HTTPS servers. (See mail.google.com:443 for example.)
&gt;&gt;   And the cell-based part of the V3 handshake, in summary, is:
&gt;&gt;
&gt;&gt;    C&lt;-&gt;S: TLS handshake where S sends a "v3 certificate"
&gt;&gt;
&gt;&gt;    In TLS:
&gt;&gt;
&gt;&gt;       C-&gt;S: VERSIONS cell
&gt;&gt;       S-&gt;C: VERSIONS cell, CERT cell, AUTH_CHALLENGE cell, NETINFO cell
&gt;&gt;
&gt;&gt;       C-&gt;S: Optionally: CERT cell, AUTHENTICATE cell
&gt;
&gt; Forgive my ignorance here. I have only a passing knowledge of the Tor
&gt; protocol these days.
&gt;
&gt; If you wish to prevent scanning for Tor nodes then you could have the
&gt; client put the SHA256 of the server's identity key in its initial
&gt; cell. This supposes that the client always knows the identity of the
&gt; server that it's connecting to; which may not be the case.

Alas it isn't; for usability reasons we require that clients can
connect to bridges without knowing their ID.  But maybe we could do
something like that for connections to non-bridges.  One problem is
that if we had a cell type like this, we'd want to have it appear
*before* the versions cell, which means you can't really have it
negotiated as part of the protocol.

&gt; If the client doesn't care about authenticating to the server, then it
&gt; could optimistically send cells predicated on a correct version
&gt; prediction. SSH does this (see RFC 4253, section 7.1,
&gt; 'first_kex_packet_follows'). The server will know if the prediction
&gt; was correct once it sees the client's version and can discard
&gt; optimistic cells.

That's a pretty neat idea.  I wonder what cells we'd actually want to
send, though: we don't want to send any actual data to the server
until we've authenticated the server, and we can't do that until we
get the CERTS cell from the server, which doesn't come until after the
server sends us its VERSIONS cell.

-- 
Nick

</body></email><email><emailId>20110920181315</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-20 18:13:15-0400</timestampReceived><subject>Re: [tor-dev] Proposal 176: Proposed version-3 link handshake for</subject><body>

On Mon, Jan 31, 2011 at 09:50:06PM -0500, Nick Mathewson wrote:
&gt;       1) We should make it easier to use self-signed certs, or maybe
&gt;          even existing HTTPS certificates, for the server side
&gt;          handshake, since most non-Tor SSL handshakes use either
&gt;          self-signed certificates or

or... CA-signed certificates?

&gt;      2) We should make it harder to probe for a Tor server.  Right
&gt;         now, you can just do a handshake with a server,
&gt;         renegotiate, then see if it gives you a VERSIONS cell.
&gt;         That's no good.

Does this proposal address this goal in any way? I don't see why it's
on the list.

&gt;      3) We should allow other changes in our use of TLS and in our
&gt;         certificates so as to resist fingerprinting based on how
&gt;         our certificates look.

Or this goal. Or do we simply mean here that proposal 176's results
should not prevent results from other proposals like 179?

&gt;    And the cell-based part of the V3 handshake, in summary, is:
&gt; 
&gt;     C&lt;-&gt;S: TLS handshake where S sends a "v3 certificate"
&gt; 
&gt;     In TLS:
&gt; 
&gt;        C-&gt;S: VERSIONS cell
&gt;        S-&gt;C: VERSIONS cell, CERT cell, AUTH_CHALLENGE cell, NETINFO cell
&gt; 
&gt;        C-&gt;S: Optionally: CERT cell, AUTHENTICATE cell

Would probably be clearer to append an explicit line here:

         C-&gt;S: NETINFO cell

&gt;    The v3 requirements are easy to meet: any certificate designed to
&gt;    resist fingerprinting will likely be self-signed, or if it's
&gt;    signed by a CA, then the issuer will surely have more DN fields
&gt;    set.  Certificates that aren't trying to resist fingerprinting
&gt;    can trivially become v3 by using a CN that doesn't end with .net,
&gt;    or using a 1024-bit key.

I assume you mean "or using a key longer than 1024 bits."

&gt;   If the client implements this proposal, however, and the server
&gt;   has shown it can understand the V3+ handshake protocol, the

This is the first point where you use "V3+" where you had otherwise used
"V3". Should the + just be implicit, or do you mean to imply something
different when you say V3+ vs V3? I don't see how we can predict that
a given behavior could imply V4 without knowing what V4 will be.

&gt;   An AUTH_CHALLENGE cell is a variable-length cell with the following
&gt;   fields:
&gt;       Challenge [32 octets]

On IRC you suggested that the AUTH_CHALLENGE cell might want to list the
authtypes it knows how to parse. Thus if we bump the AuthType version,
we may not need to bump the whole link version.

&gt; 3.4. Authenticating via Tor cells: Client authentication
&gt; 
&gt;    A client does not need to authenticate to the server.  If it
&gt;    does not wish to, it responds to the server's valid CERT cell by
&gt;    sending NETINFO cell: once it has gotten a valid NETINFO cell
&gt;    back, the client should consider the connection open, and the
&gt;    server should consider the connection as opened by an
&gt;    unauthenticated client.

The word 'back' is misleading here, since it implies that the server
waits to send its netinfo cell until it sees one from the client.

&gt;        CID: A SHA256 hash of the client's RSA1024 identity key [32 octets]
&gt;        SID: A SHA256 hash of the server's RSA1024 identity key [32 octets]
&gt;        SLOG: A SHA256 hash of all bytes sent from the server to the client
&gt;          as part of the negotiation up to and including the
&gt;          AUTH_CHALLENGE cell; that is, the VERSIONS cell,
&gt;          the CERT cell, and the AUTH_CHALLENGE cell. [32 octets]
&gt;        CLOG: A SHA256 hash of all byte sent from the client to the
&gt;          server as part of the negotiation so far; that is, the
&gt;          VERSIONS cell and the CERT cell. [32 octets]
&gt;        SCERT: A SHA256 hash of the server's TLS link
&gt;          certificate. [32 octets]
&gt;        TLSSECRETS: Either 32 zero octets, or a SHA256 HMAC, using
&gt;          the TLS master secret as the secret key, of the following:
&gt;            - client_random, as sent in the TLS Client Hello
&gt;            - server_random, as sent in the TLS Server Hello
&gt;            - the NUL terminated ASCII string:
&gt;              "Tor V3 handshake TLS cross-certification"
&gt;           [32 octets]
&gt;        TIME: The time of day in seconds since the POSIX epoch. [8 octets]
&gt;        NONCE: A 16 byte value, randomly chosen by the client [16 octets]

In the server section you specify that the randomness needs to be strong.
Does the omission of that specification for the client mean it doesn't
need to be? :)

(I'd hate for somebody to misinterpret 'nonce' as 'value that was not
previously used', and implement it as a counter, which would do perfectly
fine for the protocol but also reveal how many authenticate cells we've
sent since the last time you saw one.)

&gt;        SIG: A signature of a SHA256 hash of all the previous fields
&gt;          using the client's "Authenticate" key as presented.  (As
&gt;          always in Tor, we use OAEP-MGF1 padding; see tor-spec.txt
&gt;          section 0.3.)
&gt;           [variable length]
&gt; 
&gt;    To check the AUTHENTICATE cell, a server checks that all fields
&gt;    containing a hash contain the correct value, then verifies the
&gt;    signature.  The server MUST ignore any extra bytes after
&gt;    the SHA256 hash.

You mean extra bytes after the signature?

&gt; 4. Numbers to assign
&gt; 
&gt;    We need a version number for this link protocol.  I've been
&gt;    calling it "3".
&gt; 
&gt;    We need to reserve command numbers for CERT, AUTH_CHALLENGE, and
&gt;    AUTHENTICATE.  I suggest that in link protocol 3 and higher, we
&gt;    reserve a separate range of commands for variable-length cells.

Sounds good to me.

&gt; 6. Security argument
&gt; 
&gt;    These aren't crypto proofs, since I don't write those.  They are
&gt;    meant be reasonably convincing.

They look plausible to me.

&gt; 8. Open questions:
&gt; 
&gt;   - May we cache which certificates we've already verified?  It
&gt;     might leak in timing whether we've connected with a given server
&gt;     before, and how recently.

Would this be much of a win anyway? Seems like more code for not much
of a win.

&gt;   - With which TLS libraries is it feasible to yoink client_random,
&gt;     server_random, and the master secret?  If the answer is "All
&gt;     free C TLS libraries", great.  If the answer is "OpenSSL only",
&gt;     not so great.

Good question.

&gt;   - Should we do anything to check the timestamp in the AUTHENTICATE
&gt;     cell?

Does having the timestamp give us anything that having the nonce doesn't
already provide?

I pondered for a while that it might actually be bad to have the timestamp
there, since its offset from 'real' time is a cookie that lets us track
the user. But there are plenty of other ways that we can learn the
client's time, like the NETINFO cell.

&gt;   - Can we give some way for clients to signal "I want to use the
&gt;     V3 protocol if possible, but I can't renegotiate, so don't give
&gt;     me the V2"?  Clients currently have a fair idea of server
&gt;     versions, so they could potentially do the V3+ handshake with
&gt;     servers that support it, and fall back to V1 otherwise.

Given that corporations like Bluecoat sell censorship devices that
censor our V2 handshake -- and we've seen them deployed in Syria --
but we know of no places that censor our V1 handshake, it would not be
crazy to declare that V3-supporting clients all prefer V1 to V2.

That said, bridges are a good example of a case where we don't know the
server version, and also a prime use case here.

One hack would be to change Tor versions that don't support V3 (like
0.2.2.x) so they don't support V2.

*That* said, I think we shouldn't waste too much time on this topic.
There aren't any Tors that can't renegotiate now (if we ignore Tor clients
in Syria), so if we are forced to make some in the future before V3 is
deployed, we could just make those Tors only support V1.

&gt;   - What should servers that don't have TLS renegotiation do?  For
&gt;     now, I think they should just stick with V1.  Eventually we can
&gt;     deprecate the V2 handshake as we did with the V1 handshake.
&gt;     When that happens, servers can be V3-only.

Who are these servers you're thinking of?

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110921175856</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-09-21 17:58:56-0400</timestampReceived><subject>Re: [tor-dev] Proposal 176: Proposed version-3 link handshake for</subject><body>

On Tue, Sep 20, 2011 at 2:13 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:

Hi!  I'm going to snip every point where I agree with you, and just
patch the proposal accordingly.

&gt; On Mon, Jan 31, 2011 at 09:50:06PM -0500, Nick Mathewson wrote:
[...]
&gt;&gt;      2) We should make it harder to probe for a Tor server.  Right
&gt;&gt;         now, you can just do a handshake with a server,
&gt;&gt;         renegotiate, then see if it gives you a VERSIONS cell.
&gt;&gt;         That's no good.
&gt;
&gt; Does this proposal address this goal in any way? I don't see why it's
&gt; on the list.

Hm.  I think we had hoped to solve that in an earlier version of the
proposal, but decided that we probably couldn't do so in any really
reasonable way.  Adam Langley suggested that we could add a new
'be-a-tor' cell with a hash of the server's identity key that the
client has to send after the TLS handshake but before any cells, but
that would require that the client know the server's identity to
connect to it, which would break some bridge users.

I'll take this goal out, since we don't have a solution.  But should
we try to get one?  It seems like it will be really annoying to add
later.

 [...]
&gt;&gt;   An AUTH_CHALLENGE cell is a variable-length cell with the following
&gt;&gt;   fields:
&gt;&gt;       Challenge [32 octets]
&gt;
&gt; On IRC you suggested that the AUTH_CHALLENGE cell might want to list the
&gt; authtypes it knows how to parse. Thus if we bump the AuthType version,
&gt; we may not need to bump the whole link version.

Agreed; I'll add such a list.

[...]
&gt;&gt;        TIME: The time of day in seconds since the POSIX epoch. [8 octets]
&gt;&gt;        NONCE: A 16 byte value, randomly chosen by the client [16 octets]
&gt;
&gt; In the server section you specify that the randomness needs to be strong.
&gt; Does the omission of that specification for the client mean it doesn't
&gt; need to be? :)

Hah.

&gt; (I'd hate for somebody to misinterpret 'nonce' as 'value that was not
&gt; previously used', and implement it as a counter, which would do perfectly
&gt; fine for the protocol but also reveal how many authenticate cells we've
&gt; sent since the last time you saw one.)

We already have a note in tor-spec.txt that tries to say that
everything that we say is "random" has to really be random.  I'm
strengthening it to:

   All "random" values MUST be generated with a cryptographically
   strong pseudorandom number generator seeded from a strong entropy
   source, unless otherwise noted.

Additionally, I'm renaming it the field to RAND.

&gt;&gt;        SIG: A signature of a SHA256 hash of all the previous fields
&gt;&gt;          using the client's "Authenticate" key as presented.  (As
&gt;&gt;          always in Tor, we use OAEP-MGF1 padding; see tor-spec.txt
&gt;&gt;          section 0.3.)
&gt;&gt;           [variable length]
&gt;&gt;
&gt;&gt;    To check the AUTHENTICATE cell, a server checks that all fields
&gt;&gt;    containing a hash contain the correct value, then verifies the
&gt;&gt;    signature.  The server MUST ignore any extra bytes after
&gt;&gt;    the SHA256 hash.
&gt;
&gt; You mean extra bytes after the signature?

No.  I mean that if you check the signature and you do the signature
check (RSA public-key decrypt, then check and remove padding), you get
the thing that was signed.  The thing that was signed must start with
a SHA256 hash, but it is allowed to contain other stuff (so that we
can, say, add a SHA3 hash seamlessly later on).

&gt;&gt; 8. Open questions:
&gt;&gt;
&gt;&gt;   - May we cache which certificates we've already verified?  It
&gt;&gt;     might leak in timing whether we've connected with a given server
&gt;&gt;     before, and how recently.
&gt;
&gt; Would this be much of a win anyway? Seems like more code for not much
&gt; of a win.

It saves a couple of public-key operations every time we do a connect.
 I think these will in practice be swamped by DH costs.

&gt;&gt;   - With which TLS libraries is it feasible to yoink client_random,
&gt;&gt;     server_random, and the master secret?  If the answer is "All
&gt;&gt;     free C TLS libraries", great.  If the answer is "OpenSSL only",
&gt;&gt;     not so great.
&gt;
&gt; Good question.

I continue to believe that the answer is "all free C TLS libraries,
and Java libraries where you can hack them or ".

If RFC5705 is ever widely implemented, we can use that instead for TLS
1.2 and later, so we don't need to go mucking about in the crypto
library's guts.  I am currently not so happy about using the RFC5705
construction with TLS 1.1 and earlier, though, because of the
wackypants SSL PRF.  ("Split your key in two, and use one half of it
to key a SHA1 PRF and the other half to key a MD5 PRF!")

I think on reflection that we should change the TLSSECRETS field from
optional to required in all AUTHENTICATE cells.  Only relays need to
send it, after all.

&gt;&gt;   - Should we do anything to check the timestamp in the AUTHENTICATE
&gt;&gt;     cell?
&gt;
&gt; Does having the timestamp give us anything that having the nonce doesn't
&gt; already provide?

I added it because Adam told me I should.  I don't know for sure.
Maybe it helps defend against bad nonces?

&gt; I pondered for a while that it might actually be bad to have the timestamp
&gt; there, since its offset from 'real' time is a cookie that lets us track
&gt; the user. But there are plenty of other ways that we can learn the
&gt; client's time, like the NETINFO cell.

Right, also keep in mind that "client" here means "connection
initiator."  Regular clients shouldn't send AUTHENTICATE cells at all.

[...]
&gt;&gt;   - What should servers that don't have TLS renegotiation do?  For
&gt;&gt;     now, I think they should just stick with V1.  Eventually we can
&gt;&gt;     deprecate the V2 handshake as we did with the V1 handshake.
&gt;&gt;     When that happens, servers can be V3-only.
&gt;
&gt; Who are these servers you're thinking of?

AFAIK there are none.  I have no idea what January-Nick was thinking.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111004170500</emailId><senderName>Steven Murdoch</senderName><senderEmail>steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-10-04 17:05:00-0400</timestampReceived><subject>Re: [tor-dev] Proposal 176: Proposed version-3 link handshake for</subject><body>

&gt; From a first look at 176 it looks good. Some comments and suggestions inline:

&gt; Terminological note: I use "client" below to mean the Tor
&gt; instance (a client or a bridge or a relay) that initiates a TLS
&gt; connection, and "server" to mean the Tor instance (a bridge or a
&gt; relay) that accepts it.

There are still some initiator/responder below, which I've pointed out.

&gt; * Allow responder authentication or bidirectional authentication.

responder -&gt; server

&gt; In other words, V2-supporting initiator behavior currently looks
&gt; like this:

initiator -&gt; client

&gt; And V2-supporting responder behavior now looks like this:

responder -&gt; server

&gt; And the cell-based part of the V3 handshake, in summary, is:
&gt; 
&gt; C&lt;-&gt;S: TLS handshake where S sends a "v3 certificate"
&gt; 
&gt; In TLS:
&gt; 
&gt; C-&gt;S: VERSIONS cell

I would be concerned that at some later point in the arms race, someone will block \
connections where the first application record doesn't look like a HTTP request. I'd \
therefore suggest that we permit variable length padding cells at all points, \
especially after the first VERSIONS cell. Then the client could pad out the first \
application record to a convincing length before flushing.

&gt; To check the AUTHENTICATE cell, a server checks that all fields
&gt; containing a hash contain the correct value, then verifies the
&gt; signature.  The server MUST ignore any extra bytes in the signed
&gt; data after the SHA256 hash.

I'd suggest expanding on what "correct value" means for each of the fields. Some \
might be obvious but others are not (e.g. TIME, which I see later on is not currently \
checked).

If we allow padding cells then I think we should probably include them in SLOG and \
CLOG.

[If we want to avoid the empty application record trick to fix the CBC vulnerability \
in TLS 1.0 then we could use padding cells with random data before every application \
record.]

&gt; A server SHOULD NOT send any sequence of cells when starting a v3
&gt; negotiation other than "VERSIONS, CERT, AUTH_CHALLENGE,
&gt; NETINFO".  A client SHOULD drop a CERT, AUTH_CHALLENGE, or
&gt; NETINFO cell that appears at any other time or out of sequence.
&gt; 
&gt; A client should not begin a v3 negotiation with any sequence
&gt; other than "VERSIONS, NETINFO" or "VERSIONS, CERT, AUTHENTICATE,
&gt; NETINFO".   A server SHOULD drop a CERT, AUTH_CHALLENGE, or
&gt; NETINFO cell that appears at any other time or out of sequence.

Padding cells should be permitted.

&gt; If the client was not able to include a non-zero TLSSECRET
&gt; component, or the server can't check it, the answer is a little
&gt; trickier.  The server knows that it is not getting a replayed
&gt; AUTHENTICATE cell, since the cell authenticates (among other
&gt; stuff) the server's AUTH_CHALLENGE cell, which it has never used
&gt; before.  The server knows that it is not getting a MITM'd
&gt; AUTHENTICATE cell, since the cell includes a hash of the server's
&gt; link certificate, which nobody else should have been able to use
&gt; in a successful TLS negotiation.

Is a zero TLSSECRET permitted anymore?

&gt; A signature of the TLSSECRET element on its own should be
&gt; sufficient to prevent the attacks we care about, but because we
&gt; don't necessarily have access to the TLS master secret when using
&gt; a non-C TLS library, we can't depend on it.  I added it anyway
&gt; so that, if there is some problem with the rest of the protocol,
&gt; clients and servers that _are_ written in C (that is, the official
&gt; Tor implementation) can still be secure.

Again, it looks like TLSSECRET is now mandatory.

Steven.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110101032841</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-01 03:28:41-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>

On Fri, Dec 31, 2010 at 4:17 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On Sun, 19 Dec 2010 08:46:13 -0500
&gt; Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt;
&gt;&gt; On Sat, Dec 18, 2010 at 10:34 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt;&gt; &gt; You're right that it's important to limit partitioning opportunities
&gt;&gt; &gt; in any protocol revision; I tried to go over that in section 2, but we
&gt;&gt; &gt; shouldn't assume that I've said the last word on this.  We should
&gt;&gt; &gt; continue to look for ways to revise and improve whatever we come up
&gt;&gt; &gt; with to get the partitioning and other undesirable things down to a
&gt;&gt; &gt; minimum.
&gt;
&gt; My current plan to minimize partitioning of the client anonymity set is:
&gt;
&gt; * The directory authorities should specify lists of cryptographic
&gt;  primitives (identity key signature systems, circuit-extension
&gt;  handshakes, circuit ciphersuites, etc.) that relays are permitted to
&gt;  support in the consensus.

This should probably incorporate allowable key sizes.  We don't want
some twit generating 16384-bit identity keys just to slow down all the
clients, but we also don't want somebody using 512-bit RSA keys.

&gt; * The directory authorities should specify lists of cryptographic
&gt;  primitives that clients should consider using in the consensus.
&gt;
&gt; * Each relay should specify lists of cryptographic primitives that it
&gt;  is willing to use in its descriptor, ordered by the relay's
&gt;  preference (e.g. the relay puts its favorite primitive in a list
&gt;  first).

Hm.  If this involves multiple onion keys, this can potentially bloat
server descriptor sizes; we should consider carefully how we can avoid
that.  Perhaps there should be an upper bound on how many onion keys
you can advertise.

&gt; * A client should select the first cryptographic primitive in a relay's
&gt;  list that (a) the consensus recommends that clients use, and (b) the
&gt;  client supports.

Hm. This puts the onus on relay operators of picking the best
primitives.  I'm not sure that's such a great idea.  Perhaps the
client should pick whichever method supported by both the client and
the relay that the *consensus* recommends first.

&gt; * The Tor developers should not introduce new cryptographic primitives
&gt;  between two stable releases in the same branch.
&gt;
&gt; The Tor client will need to support torrc options that override the
&gt; lists of recommended cryptographic primitives in the consensus in order
&gt; to allow testing of not-yet-recommended primitives on the public Tor
&gt; network, but the manual page will need to warn explicitly that setting
&gt; those options will harm a Tor user's anonymity.

One thing we will need to think about here is the risk of having
seldom-used code.  Remember the time that GPG had broken ElGamal keys
for ages, and it went unnoticed since almost nobody used ElGamal keys?
(CVE-2003-0971)  More code does come with more risk.


&gt; This plan relies on the directory authorities not recommending a new
&gt; cryptographic primitive until a large fraction of Tor clients support
&gt; it.
&gt;
&gt;
&gt;&gt; One way is to be very conservative in suite choices so we don't have
&gt;&gt; to change them that often. I'm going to also go out on a limb and say
&gt;&gt; that we also want a crypto API like NaCL that lets us just say
&gt;&gt; enciphered=encrypt(key, unenciphered) and doesn't force us to worry
&gt;&gt; about padding or modes because this is a much simpler abstraction
&gt;&gt; layer and so offers less opportunity for mistakes that could threaten
&gt;&gt; security.
&gt;
&gt; I think that if we follow the plan above, we don't need to limit the
&gt; number of cryptographic primitives of each type in order to preserve
&gt; the client anonymity set.  It's more important to have at least two
&gt; cryptographic primitives of each type implemented, even if we expect
&gt; that few relays will prefer one of them, in order to ensure that we get
&gt; the APIs for each primitive right.

I am a little skeptical that it will turn out to be quite this simple
once we design it, but at this point I think the easiest way to see
whether we can get away with a good design with all the properties we
want is to just try to make one, and see how it works out.

peace &amp; happy new year,
-- 
Nick

</body></email><email><emailId>20111001001038</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-10-01 00:10:38-0400</timestampReceived><subject>Re: [tor-dev]</subject><body>

On Fri, Sep 30, 2011 at 12:19:28PM -0700, mohammad_20101389@yahoo.com wrote 2.7K \
bytes in 52 lines about: :      \
         \


This has nothing to do with developing tor. Please email
community-support@lists.torproject.org.

I've unsubscribed you from the list.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111004000453</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-10-04 00:04:53-0400</timestampReceived><subject>Re: [tor-dev] Reminder: less than two months left for getting big</subject><body>

On Mon, Oct 3, 2011 at 7:32 PM, Steve Snyder &lt;swsnyder@snydernet.net&gt; wrote:
&gt; On 10/03/2011 11:32 AM, Nick Mathewson wrote:
&gt;&gt;
&gt;&gt; Hi, all! This is a reminder about the planned schedule for 0.2.3.x.
&gt;
&gt; A related question: is there a document somewhere that lists the changes
&gt; (new features, changed behavior, etc.) in 0.2.3.x relative to 0.2.2.x?

Every release we put out has a changelog.  The latest 0.2.3.x
changelog is at
https://gitweb.torproject.org/tor.git/blob/HEAD:/ChangeLog

There intentionally isn't a document about what _will_ be new in
0.2.3.x when it becomes stable; this time I'm aiming for a fixed
schedule on fixed resources, and that means that promising fixed
output would probably amount to hubris.

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111005141023</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-10-05 14:10:23-0400</timestampReceived><subject>Re: [tor-dev] Proposal 176: Proposed version-3 link handshake for</subject><body>

On Tue, Oct 4, 2011 at 1:05 PM, Steven Murdoch
&lt;Steven.Murdoch@cl.cam.ac.uk&gt; wrote:
&gt; From a first look at 176 it looks good. Some comments and suggestions inline:

Thanks, Steven!

&gt; &gt; Terminological note: I use "client" below to mean the Tor
&gt; &gt; instance (a client or a bridge or a relay) that initiates a TLS
&gt; &gt; connection, and "server" to mean the Tor instance (a bridge or a
&gt; &gt; relay) that accepts it.
&gt; 
&gt; There are still some initiator/responder below, which I've pointed out.

I've changed the above paragraph to make "client" and "initiator" are
synonyms, as are "server" and "Responder".


On padding: agreed; I've added references to padding in the
appropriate places, and referenced proposal 184.

&gt; &gt; To check the AUTHENTICATE cell, a server checks that all fields
&gt; &gt; containing a hash contain the correct value, then verifies the
&gt; &gt; signature.  The server MUST ignore any extra bytes in the signed
&gt; &gt; data after the SHA256 hash.
&gt; 
&gt; I'd suggest expanding on what "correct value" means for each of the fields. Some \
&gt; might be obvious but others are not (e.g. TIME, which I see later on is not \
&gt; currently checked).

I've changed that statement to say that all fields from TYPE through
TLSSECRETS should be checked to make sure their "unique correct value
as specified above."

&gt; If we allow padding cells then I think we should probably include them in SLOG and \
&gt; CLOG.

Agreed.



&gt; &gt; If the client was not able to include a non-zero TLSSECRET
&gt; &gt; component, or the server can't check it, the answer is a little
&gt; &gt; trickier.  The server knows that it is not getting a replayed
&gt; &gt; AUTHENTICATE cell, since the cell authenticates (among other
&gt; &gt; stuff) the server's AUTH_CHALLENGE cell, which it has never used
&gt; &gt; before.  The server knows that it is not getting a MITM'd
&gt; &gt; AUTHENTICATE cell, since the cell includes a hash of the server's
&gt; &gt; link certificate, which nobody else should have been able to use
&gt; &gt; in a successful TLS negotiation.
&gt; 
&gt; Is a zero TLSSECRET permitted anymore?

Nope; I've reworded this paragraph.

&gt; &gt; A signature of the TLSSECRET element on its own should be
&gt; &gt; sufficient to prevent the attacks we care about, but because we
&gt; &gt; don't necessarily have access to the TLS master secret when using
&gt; &gt; a non-C TLS library, we can't depend on it.  I added it anyway
&gt; &gt; so that, if there is some problem with the rest of the protocol,
&gt; &gt; clients and servers that _are_ written in C (that is, the official
&gt; &gt; Tor implementation) can still be secure.
&gt; 
&gt; Again, it looks like TLSSECRET is now mandatory.

Also reworded this one.

Thanks,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111010122443</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2011-10-10 12:24:43-0400</timestampReceived><subject>Re: [tor-dev] Tor download link</subject><body>

----- Original Message -----
&gt; In fact, current versions are there too.  Build systems should use
&gt; archive.torproject.org and not torproject.org/dist for their source
&gt; code
&gt; needs.
&gt; 
&gt; /dist is for the current release only.
Thanks again for clarifying this.

Changes made on my github repo, I will submit them with the next version upgrade.

-- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111011205219</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-10-11 20:52:19-0400</timestampReceived><subject>Re: [tor-dev] pid_t and MSVC</subject><body>

On Tue, Oct 11, 2011 at 7:16 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; The use of 'pid_t' confuses me a bit:
&gt;
&gt;  In common/procmon.c (inside MS_WINDOWS), it's typedef'ed to  'int'
&gt; unconditionally.
&gt;
&gt;  And then in common/util.* (tor_terminate_process()) it is assumed to be
&gt;  defined in orconfig.h or somewhere else. It's not AFAICS.
&gt;
&gt; It is true that _getpid() returns an 'int', but the way Tor uses it seems
&gt; wrong; the last argument to OpenProcess() takes a 'DWORD'. So 'pid_t'
&gt; should be 'DWORD' IMHO.

If that's what we're going to do, we should make sure that we don't
use any posix-compatibility functions that return/expect an int pid,
like _getpid().  So perhaps we should have a tor_pid_t that's a DWORD
on windows and pid_t elsewhere, and we should stop using _getpid() in
favor of GetCurrentProcessId, assuming that that's really what we
ought to be calling.

&gt; So maybe we should introduce a 'typedef DWORD tor_pid_t;' in orconfig.h?

Well, if we add AC_TYPE_PID_T in configure.in, then we can make sure
that pid_t is defined on autoconf-based builds, and we can define it
to DWORD for MSVC builds in src/win32/orconfig.h.  But I worry there:
it's a little error-prone to have a type that is unsigned in some
places and signed elsewhere.  We should audit all our pid_t uses if
we're going to try something like that.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111014205700</emailId><senderName>Rob Jansen</senderName><senderEmail>rob.g.jansen@nrl.navy.mil</senderEmail><timestampReceived>2011-10-14 20:57:00-0400</timestampReceived><subject>Re: [tor-dev] tor-dev Digest, Vol 9, Issue 8</subject><body>


On 10/14/2011 08:00 AM, tor-dev-request@lists.torproject.org wrote:
&gt; On Tue, Sep 27, 2011 at 4:20 PM, Rob Jansen&lt;rob.g.jansen@nrl.navy.mil&gt;  wrote:
&gt;&gt; &gt;  If you have the need to run Tor experiments, or are just interested in the
&gt;&gt; &gt;  Software, please try it out. We would love any feedback or comments or
&gt;&gt; &gt;  suggestions if you have them!
&gt; i've got more, but first off:
&gt;
&gt; - why secondary dependencies not in git and not opt-in?
&gt;   e.g. downloading
&gt; http://shadow.cs.umn.edu/downloads/shadow-resources.tar.gz  - if you
&gt; run fully offline build systems this default behavior breaks builds.
&gt;

True, this is a good point. My original reason is that I thought the 
latency data we collected from PlanetLab was too large to put in git. 
Since then, my experience with git and its way of handling changes leads 
me to believe this isn't an issue after all. Also, it is unclear to me 
that resources should be versioned the same way that source code is.

&gt; - what about hw acceleration in performance estimates?
&gt;   e.g. openssl dynamic engines in virtual CPU processing.
&gt;

We incorporate CPU delays into Shadow by giving it a CDF distribution of 
real measurements of application and CPU throughput, and "delaying" the 
processing of events based on this distribution. You can model HW accel 
by skewing the distribution, or better yet creating a new one based on 
real measurements of an accelerated OpenSSL/Tor.

&gt; - is there a shadow-dev in addition to shadow-support?:)
&gt;

Not yet. Since you asked, it will be up in a few days:)

&gt;
&gt;&gt; &gt;  We are continuously working on improving the simulator, including more
&gt;&gt; &gt;  efficient use of multiple CPU cores and a command-line interface to help
&gt;&gt; &gt;  with installing Shadow and some of its dependencies.
&gt; https://github.com/shadow/shadow-cli  also handy.
&gt;
&gt; thanks!

Thanks for the comments, feel free to share your others.
Rob
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111015011404</emailId><senderName>Rob Jansen</senderName><senderEmail>rob.g.jansen@nrl.navy.mil</senderEmail><timestampReceived>2011-10-15 01:14:04-0400</timestampReceived><subject>Re: [tor-dev] Running Real Tor Code Over Simulated Networks</subject><body>


&gt;&gt; - is there a shadow-dev in addition to shadow-support?:)
&gt;&gt;
&gt;
&gt; Not yet. Since you asked, it will be up in a few days:)
&gt;
Join the shadow dev list at
https://wwws.cs.umn.edu/mm-cs/listinfo/shadow-dev

or send mail to shadow-dev@cs.umn.edu

Thanks,
Rob

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111018072728</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-10-18 07:27:28-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On 8/25/11 10:08 AM, Karsten Loesing wrote:
&gt; we have been discussing sanitizing and publishing our web server logs
&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt; website, and analyze them for top visited pages, top downloaded
&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt; 
&gt; Here's a suggested sanitizing procedure for our web logs, which are in
&gt; Apache's combined log format:
&gt; 
&gt;  - Ignore everything except GET requests.
&gt;  - Ignore all requests that resulted in a 404 status code.
&gt;  - Rewrite log lines so that they only contain the following fields:
&gt;    - IP address 0.0.0.0 for HTTP request or 0.0.0.1 for HTTPS requests
&gt; (as logged by our Apache configuration),
&gt;    - the request date (with the time part set to 00:00:00),
&gt;    - the requested URL (cut off at the first encountered "?"),
&gt;    - the HTTP version,
&gt;    - the server's HTTP status code, and
&gt;    - the size of the returned object.
&gt;  - Write all lines from a given virtual host and day to a single output
&gt; file.
&gt;  - Sort the output file alphanumerically to conceal the original order
&gt; of requests.

Pushing this forward.  Here are the sanitized web logs that we'd like to
publish on a daily basis for all our web servers and virtual domains for
all of 2010 (155M):

http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-01.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-02.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-03.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-04.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-05.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-06.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-07.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-08.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-09.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-10.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-11.tar
http://freehaven.net/~karsten/volatile/torproject-weblogs-2010-12.tar

The webalizer output for www.torproject.org can be viewed here:

http://freehaven.net/~karsten/volatile/www.torproject.org-webalizer/

So.  Is it safe to publish these logs on a daily basis?  The same
questions from my original mail apply here:

&gt; Is there still anything sensitive in that log file that we should
&gt; remove?  For example:
&gt;  - Do the logs reveal how many pages were cached already on the
&gt; requestor's site (e.g. as repeat accesses)?  Note that log files are
&gt; sorted before being published.
&gt;  - Are there other concerns about making these sanitized log files
&gt; publicly available?
&gt; 
&gt; Are the decisions to remove parts from the logs reasonable?  In particular:
&gt;  - Do we have to take out all requests with 404 status codes?  Some of
&gt; these requests for non-existing URLs contain typos which may not be safe
&gt; to make public.  Should we instead put in some placeholder for the URL
&gt; part and keep the 404 lines to know how many 404's we have per day?
&gt;  - Is there any good reason to keep the portion of a URL after a "?"?
&gt;  - Is it possible to leave some part of Referers in the logs that helps
&gt; us figure out where our traffic originates and what search terms people
&gt; use to find us?
&gt;  - Can we resolve client IP addresses to country codes and include those
&gt; in the logs instead of our 0.0.0.0/0.0.0.1 code for HTTP/HTTPS?  How
&gt; would we handle countries with only a few users per day, e.g., should
&gt; there be a threshold below which we consider requests to come from "a
&gt; country with less than XY users?"

The next steps will be to make these sanitized logs available on a daily
basis and to publish the sanitized archives from 2008, 2009, and 2011.

I'm going to wait another week (probably longer) for feedback before
taking these next steps.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111019192402</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-10-19 19:24:02-0400</timestampReceived><subject>[tor-dev] [Patch] or/eventdns.c</subject><body>

I've made eventdns.c + '-DEVDNS_MAIN' compile and work
under Windows / MSVC. Some simple patches:

* Use set_socket_nonblocking() instead of the F_SETFL hacks.
* Preserve the ret-val from evdns_config_windows_nameservers().
* In main(), call network_init() to call WSAStartup() etc.
* Removed 'evdns_resolv_conf_parse(DNS_OPTION_NAMESERVERS, ...'
  and call evdns_init() instead. This uses 'DNS_OPTIONS_ALL'. Does that
  really matter?

Attached diff-1.txt. (sorry, I'm a Git neophyte).

--gv

["diff-1.txt;" (text/plain)]

--- Git-latest\src\or\eventdns.c	Wed Oct 19 21:11:09 2011
+++ or\eventdns.c	Wed Oct 19 20:44:05 2011
@@ -2293,14 +2293,7 @@

 	ns-&gt;socket = tor_open_socket(address-&gt;sa_family, SOCK_DGRAM, 0);
 	if (ns-&gt;socket &lt; 0) { err = 1; goto out1; }
-#ifdef WIN32
-	{
-		u_long nonblocking = 1;
-		ioctlsocket(ns-&gt;socket, FIONBIO, &amp;nonblocking);
-	}
-#else
-	fcntl(ns-&gt;socket, F_SETFL, O_NONBLOCK);
-#endif
+	set_socket_nonblocking(ns-&gt;socket);

 	if (global_bind_addr_is_set &amp;&amp;
 	    !sockaddr_is_loopback((struct sockaddr*)&amp;global_bind_address)) {
@@ -3305,11 +3298,10 @@
 {
 		int res = 0;
 #ifdef WIN32
-		evdns_config_windows_nameservers();
+		res = evdns_config_windows_nameservers();
 #else
 		res = evdns_resolv_conf_parse(DNS_OPTIONS_ALL, "/etc/resolv.conf");
 #endif
-
 		return (res);
 }

@@ -3453,15 +3445,17 @@
 			fprintf(stderr, "Unknown option %s\n", v[idx]);
 		++idx;
 	}
+	network_init();
 	event_init();
+	evdns_init();
 	if (verbose)
 		evdns_set_log_fn(logfn);
-	evdns_resolv_conf_parse(DNS_OPTION_NAMESERVERS, "/etc/resolv.conf");
+
 	if (servertest) {
 		int sock;
 		struct sockaddr_in my_addr;
 		sock = tor_open_socket(PF_INET, SOCK_DGRAM, 0);
-		fcntl(sock, F_SETFL, O_NONBLOCK);
+		set_socket_nonblocking(sock);
 		my_addr.sin_family = AF_INET;
 		my_addr.sin_port = htons(10053);
 		my_addr.sin_addr.s_addr = INADDR_ANY;


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111020000917</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-10-20 00:09:17-0400</timestampReceived><subject>[tor-dev] Proposal 188: Bridge Guards and other anti-enumeration</subject><body>

Filename: 188-bridge-guards.txt
Title: Bridge Guards and other anti-enumeration defenses
Author: Nick Mathewson
Created: 14 Oct 2011
Status: Open

1. Overview

   Bridges are useful against censors only so long as the adversary
   cannot easily enumerate their addresses. I propose a design to make
   it harder for an adversary who controls or observes only a few
   nodes to enumerate a large number of bridges.

   Briefly: bridges should choose guard nodes, and use the Tor
   protocol's "Loose source routing" feature to re-route all extend
   requests from clients through an additional layer of guard nodes
   chosen by the bridge.  This way, only a bridge's guard nodes can
   tell that it is a bridge, and the attacker needs to run many more
   nodes in order to enumerate a large number of bridges.

   I also discuss other ways to avoid enumeration, recommending some.

   These ideas are due to a discussion at the 2011 Tor Developers'
   Meeting in Waterloo, Ontario.  Practically none of the ideas here
   are mine; I'm just writing up what I remember.

2. History and Motivation

   Under the current bridge design, an attacker who runs a node can
   identify bridges by seeing which "clients" make a large number of
   connections to it, or which "clients" make connections to it in the
   same way clients do.  This has been a known attack since early
   versions {XXXX check} of the design document; let's try to fix it.

2.1. Related ideas: Guard nodes

   The idea of guard nodes isn't new: since 0.1.1, Tor has used guard
   nodes (first designed as "Helper" nodes by Wright et al in {XXXX})
   to make it harder for an adversary who controls a smaller number of
   nodes to eavesdrop on clients.  The rationale was: an adversary who
   controls or observes only one entry and one exit will have a low
   probability of correlating any single circuit, but over time, if
   clients choose a random entry and exit for each circuit, such an
   adversary will eventually see some circuits from each client with a
   probability of 1, thereby building a statistical profile of the
   client's activities.  Therefore, let each client choose its entry
   node only from among a small number of client-selected "guard"
   nodes: the client is still correlated with the same probability as
   before, but now the client has a nonzero chance of remaining
   unprofiled.

2.2. Related idea: Loose source routing

   Since the earliest versions of Onion Routing, the protocol has
   provided "loose source routing".  In strict source routing, the
   source of a message chooses every hop on the message's path.  But
   in loose source routing, the message traverses the selected nodes,
   but may also traverse other nodes as well.  In other words, the
   client selects nodes N_a, N_b, and N_c, but the message may in fact
   traverse any sequence of nodes N_1...N_j, so long as N_1=N_a,
   N_x=N_b, and N_y=N_c, for 1 &lt; x &lt; y.

   Tor has retained this feature, but has not yet made use of it.

3. Design

   Every bridge currently chooses a set of guard nodes for its
   circuits.  Bridges should also re-route client circuits through
   these circuits.

   Specifically, when a bridge receives a request from a client to
   extend a circuit, it should first create a circuit to its guard,
   and then relay that extend cell through the guard.  The bridge
   should add an additional layer of encryption to outgoing cells on
   that circuit corresponding to the encryption that the guard will
   remove, and remove a layer of encryption on incoming cells on that
   circuit corresponding to the encryption that the guard will add.

3.1. An example

   This example doesn't add anything to the design above, but has some
   interesting inline notes.

      - Alice has connected to her bridge Bob, and built a circuit
        through Bob, with the negotiated forward and reverse keys KB_f
        and KB_r.

      - Alice then wants to extend the circuit to node Charlie.  She
        makes a hybrid-encrypted onionskin, encrypted to Charlie's
        public key, containing her chosen g^x value.  She puts this in
        an extend cell: "Extend (Charlie's address) (Charlie's OR
        Port) (Onionskin) (Charlie's ID)".  She encrypts this with
        KB_f and sends it as a RELAY_EARLY cell to Bob.

      - Bob receives the RELAY_EARLY cell, and decrypts it with KB_f.
        He then sees that it's an extend cell for him.

        So far, this is exactly the same as the current procedure that
        Alice and Bob would follow.  Now we diverge:

      - Instead of connecting to Charlie directly, Bob makes sure that
        he is connected to his guard, Guillaume.  Bob uses a
        CREATE_FAST cell (or a CREATE cell, but see 4.1 below) to open a
        circuit to Guillaume.  Now Bob and Guillaume share keys KG_f
        and KG_b.

      - Now Bob encrypts the Extend cell body with KG_f and sends it
        as a RELAY_EARLY cell to Guillaume.

      - Guillaume receives it, decrypts it with KG_f, and sees:
        "Extend (Charlie's address) (Charlie's OR Port) (Onionskin)
        (Charlie's ID)".  Guillaume acts accordingly: creating a
        connection to Charlie if he doesn't have one, ensuring that
        the ID is as expected, and then sending the onionskin in a
        create cell on that connection.

        Note that Guillaume is behaving exactly as a regular node
        would upon receiving an Extend cell.

      - Now the handshake finishes.  Charlie receives the onionskin
        and sends Guillaume "CREATED g^y,KH".  Guillaume sends Bob
        "E(KG_r, EXTENDED g^y KH)".  (Charlie and Guillaume are still
        running as regular Tor nodes do today).

      - With this extend cell, and with all future relay cells
        received on this circuit, Bob first decrypts the cell with
        KG_r, then re-encrypts it with KB_r, then passes it to Alice.
        When Alice receives the cell, it will be just as she would
        have received if Bob had extended to Charlie directly.

      - With all future outgoing cells that he receives from Alice,
        Bob first decrypts the cell with KA_f, and if the cell does
        not have Bob as its destination, Bob encrypts it with KG_f
        before passing it to Guillaume.

   Note that this design does not require that our stream cipher
   operations be transitive, even though they are.

   Note also that this design requires no change in behavior from any
   node other than Bob the bridge.

   Finally, observe that even though the circuit is one hop longer
   than it would be otherwise, no relay's count of permissible
   RELAY_EARLY cells falls lower than it otherwise would.  This is
   because the extra hop that Bob adds is done with a CREATE_FAST
   cell, and so he does not need to send any RELAY_EARLY cells not
   originated by Alice.

4. Other ideas and alternative designs

   In addition to the design above, there are more ways to try to
   prevent enumeration.

4.1. Make it harder to tell clients from bridges

   Right now, there are multiple ways for the node after a bridge to
   distinguish a circuit extended through the bridge from one
   originating at the bridge.  (This lets the node after the bridge
   tell that a bridge is talking to it.)

   One of the giveaways here is that the first hop in a circuit is
   created with CREATE_FAST cells, but all subsequent hops are created
   with CREATE cells.  In the above design, it's no longer quite so
   simple to tell, since all of the circuits that extend through a
   bridge now reach its guards through CREATE_FAST cells, whether the
   bridge originated them or not.

   (If we adopt a faster circuit extension algorithm -- for example,
   Goldberg, Stebila, and Ustaoglu's design instantiated over
   curve25519 -- we could also solve this issue by eliminating
   CREATE_FAST/CREATED_FAST entirely, which would also help our
   security margin a little.)

   The CREATE/CREATE_FAST distinction is not the only way for a
   bridge's guard to tell bridges from orginary clients, however.
   Most importantly, a busy bridge will open far more circuits than a
   client would.  More subtly, the timing on response from the client
   will be higher and more highly variable that it would be with an
   ordinary client.  I don't think we can make bridges behave wholly
   indistinguishably from clients: that's why we should go with guard
   nodes for bridges.

4.2. Client-enforced bridge guards

   What if Tor didn't have loose source routing?  We could have
   bridges tell clients what guards to use by advertising those guard
   in their descriptors, and then refusing to extend circuits to any
   other nodes.  This change would require all clients to upgrade in
   order to be able to use the newer bridges, and would quite possibly
   cause a fair amount of pain along the way.

   Fortunately, we don't need to go down this path.  So let's not!

4.3. Separate bridge-guards and client-guards

   In the design above, I specify that bridges should use the same
   guard nodes for extending client circuits as they use for their own
   circuits.  It's not immediately clear whether this is a good idea
   or not.  Having separate sets would seem to make the two kinds of
   circuits more easily distinguishable (even though we already assume
   they are distinguishable).  Having different sets of guards would
   also seem like a way to keep the nodes who guard our own traffic
   from learning that we're a bridge... but another set of nodes will
   learn that anyway, so it's not clear what we'd gain.

5. Other considerations

   What fraction of our traffic is bridge traffic?  Will this alter
   our circuit selection weights?

   Are the current guard selection/evaluation/replacement mechanisms
   adequate for bridge guards, or do bridges need to get more
   sophisticated?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111020180020</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-10-20 18:00:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 188: Bridge Guards and other</subject><body>

On 2011-10-20, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:

&gt; 4.3. Separate bridge-guards and client-guards
&gt;
&gt;    In the design above, I specify that bridges should use the same
&gt;    guard nodes for extending client circuits as they use for their own
&gt;    circuits.  It's not immediately clear whether this is a good idea
&gt;    or not.  Having separate sets would seem to make the two kinds of
&gt;    circuits more easily distinguishable (even though we already assume
&gt;    they are distinguishable).  Having different sets of guards would
&gt;    also seem like a way to keep the nodes who guard our own traffic
&gt;    from learning that we're a bridge... but another set of nodes will
&gt;    learn that anyway, so it's not clear what we'd gain.

Any attacker who can extend circuits through a bridge can enumerate
the set of guard nodes which it routes its clients' circuits through.
A malicious middle relay can easily determine the set of entry guards
used by a hidden service, and over time, can determine the set of
entry guards used by a user with a long-term pseudonym.  If a bridge
uses the same set of entry guards for its clients' circuits as it does
for its own, users who operate bridges can be deanonymized quite
trivially.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111023172621</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-10-23 17:26:21-0400</timestampReceived><subject>Re: [tor-dev] Proposal 186: Multiple addresses for one OR or bridge</subject><body>

[Quoting the original mail, but it's actually the file in git that I
read and am commenting on.]

On Wed, Sep 21, 2011 at 02:13:18PM -0400, Nick Mathewson wrote:
&gt;   The 'AllAddrs' option tells Tor that if no address is given in the
&gt;   PortDescription part, we should bind/advertise every one of our
&gt;   publicly visible unicast addresses; and that if a hostname address
&gt;   is given in the PortDescription, we should bind/advertise every
&gt;   publicly visible unicast address that the hostname resolves to.
&gt;   (Q: Should this be on by default?)

Yes, I think. And if it's on by default, does the option need to exist
at all?

&gt;   Example: Our firewall is redirecting ports 80, 443, and 7000-8000
&gt;   on all hosts in x.244.2.0/24 onto our port 2929.
&gt; 
&gt;      SocksPort 2929 no-advertise
&gt;      SocksPort x.244.2.0/24:80,443,7000-8000 no-listen

This address has a bitmask, but your note at the end says the bitmask
feature is no longer in the proposal.

&gt;   Example: We have a dynamic DNS provider that maps
&gt;   tornode.example.com to our current external IPv4 and IPv6
&gt;   addresses.  Our firewall forwards port 443 on those address to our
&gt;   port 1337.
&gt; 
&gt;      SocksPort 1337 no-advertise alladdrs
&gt;      SocksPort tornode.example.com:443 no-bind alladdrs

This drives home the issue with alladdrs: what would we do if that flag
isn't listed here?

&gt;   {Until support is added for extend cells to IPv6 addresses, it
&gt;   will only be possible to test IPv6 addresses by connecting
&gt;   directly.  We might want to just skip self-testing those until we
&gt;   have IPv6 extend support.}

Agreed that we don't want to waste time with some temporary alternate
checking mechanism.

&gt;   (Q: Any reason to allow more than 2?  Multiple interfaces, I guess.)

By the same logic that we chose not to allow bitmasks in addresses, it's
easy to argue that we shouldn't list more than 2 addresses (one ipv4,
one ipv6). But does limiting it to 2 in the spec simplify the design in
any way, or just constrain us down the road?

&gt;   An authority shouldn't list a node as Running unless every
&gt;   or-address line it advertises looks like it will work.

This part makes me sad -- I worry that we'll end up with situations
where most addresses work but we discard the whole relay because of a
network hiccup somewhere (e.g. between the directory authority and one
of the relay's addresses). How much more would it complexify things if
we list the ones we think are up in the consensus, and then the voting
process decides which ones get advertised?

&gt; Consensus directories and microdescriptors:
&gt; 
&gt;   We introduce a new line type for microdescriptors and consensuses,
&gt;   "a".  Each "a" line has the same format as an or-address line.
&gt;   The "a" lines (if any) appear immediately after the "r" line for a
&gt;   router in the consensus, and immediately after the "onion-key"
&gt;   entry in a microdescriptor.

We should clarify which flavors we mean when we say consensuses. That is,
are we going to add "a" lines to the microdescriptor-flavor consensus
too, even though clients will soon find the same lines when they fetch
the microdescriptors? I think yes, on the theory that clients will find
the addresses useful in fetching microdescriptors. But it feels like a
shame to include this mostly static info in every consensus when it's
only really helpful for initial bootstrap for a tiny subset of users.

I could imagine an ipv6-micro flavored consensus which includes ipv6
addresses for the clients who need that, and then those clients fetch
the normal consensus after that. But maybe I'm trying to optimize too
much for bandwidth.

&gt;  We will have to define a new voting algorithm version; when using
&gt;  this version or later, votes should include a single "a" line for
&gt;  every relay that has an IPv6 address, to include the first IPv6
&gt;  line in its descriptor.  (If there are no or-address lines, then

You meant "If there are no IPv6 or-address lines", yes?

&gt;   As with other data in the vote derived from the descriptor,
&gt;   the vote will include whichever set of "a" lines are given by the
&gt;   most authorities who voted for the descriptor digest that will be
&gt;   used for the router.

Just to clarify, we treat the whole set of "a" lines for the router as
an atomic blob, and vote for the blob that is most common? We could also
do something more fine-grained, but I don't think we want to.

&gt; Directory authorities with more addresses:
&gt; 
&gt;   We need a way for a client to configure a TrustedDirServer as
&gt;   having multiple OR addresses, specifically so that we can give at
&gt;   least one default authority an IPv6 address for bootstrapping
&gt;   purposes.

Looks like there are lots of ways to do this. For example, looking
at the code, it seems easy to add an ipv6=[...] argument that shows up
before the addr:port argument.

&gt;   (Q: Do any of the current authorities have stable IPv6 addresses?)

I'd look to tor26 and maatuska.

&gt;   We will want to allow the address in a "dir-source" line in a vote
&gt;   to contain an IPv6 address, and/or allow voters to list themselves
&gt;   with more addresses in votes/consensuses.  But right now, nothing
&gt;   actually uses the addresses listed for voters in dir-source lines
&gt;   for anything besides log messages.

Yeah, I wouldn't worry about this yet (or ever).

&gt; Client behavior:
&gt; 
&gt;   I propose that initially we shouldn't change client behavior too
&gt;   much here.
&gt; 
&gt;   (Q: Is there any advantage to having a client choose a random
&gt;   address?  If so we can do it later.  If not, why list any more
&gt;   than one IPv4 and one IPv6 address?)
&gt; 
&gt;   Tor clients not running with bridges, and running with IPv4
&gt;   support, should still use the address and ORPort as advertised in
&gt;   the router or r line of the appropriate directory object.
&gt;
&gt;   Tor clients not running with bridges, and running without IPv4
&gt;   support, should use the first listed IPv6 address for a node,
&gt;   using the lowest-numbered listed port for that address.  They
&gt;   should only connect to nodes with an IPv6 address.

A) What's the recommended way for the Tor client to discover that it
doesn't have ipv4 support?

B) What if the client supports ipv4 and ipv6 yet the public ipv4 relays
are blocked? We need some way for the user to explicitly ask for ipv6,
and ideally some way to auto detect that Tor should try the other.

&gt;   Clients should accept Bridge lines with IPv6 addresses, and
&gt;   address:port sets, in addition to the lines they currently accept.

Do you mean address:portlist sets?

&gt;   Right now, there's no way to do that: if anything but an IPv4
&gt;   address appears in a router line of a routerdesc, or the "r" line of
&gt;   a consensus, then it won't parse.  If something that looks like an
&gt;   IPv4 address appears there, clients will (I believe) try to
&gt;   connect to it.

They will.

&gt;   We can make this work, though: let's allow nodes to list themselves
&gt;   with a magic IPv4 address (say, 127.1.1.1) if they have
&gt;   or-address entries containing only IPv6 address.  We could give
&gt;   these nodes a new flag other than Running to indicate that they're
&gt;   up, and not give them the Running flag.  That way, old clients
&gt;   would never try to use them, but new clients could know to treat
&gt;   the new flag as indicating that the node is running, and know not
&gt;   to connect to a node listed with address 127.1.1.1.

It would be nice to come up with a color for the fence that doesn't
involve forever maintaining a separate Running6 flag and forever including
a hack in the consensus. For example, what if we have an "r6" line that
is like an "r" line except its address is v6? I think we can't do that
because the "w", "p", etc lines in the r6 stanza would be interpreted by
old clients as part of the previous router's stanza. Does that realization
mean we should declare one of the lines in the router stanza "at end,
exactly once" in the spec, so in the future we can add new types of
stanzas? Does it mean we can't add a "w" line to the directory footer
stanza because it would confuse clients who don't know there's a directory
footer stanza? Whee.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111010095352</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2011-10-10 09:53:52-0400</timestampReceived><subject>[tor-dev] Tor download link</subject><body>

Hello all,
I have noticed that the distribution directory: https://www.torproject.org/dist/ only \
contains source code for the latest stable and unstable version. This somehow breaks \
package distribution mechanism like SlackBuilds.org which do not host source code by \
themselves. I have already submitted an up to date SlackBuild: as soon it will be \
accepted, new Slackware users will be able again to build Tor again so it's not a \
ground breaking issue but nevertheless a bit annoying. So, is there a directory which \
hosts older but still accepted as valid version of Tor which I did not see or is a \
torproject.org policy to just keep latest versions online? Again, not a very \
important issue but it will make package maintenance easier if I could link to a \
source package which will not be removed when still valid.

Thanks in advance,
Marco

-- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111011111650</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-10-11 11:16:50-0400</timestampReceived><subject>[tor-dev] pid_t and MSVC</subject><body>

The use of 'pid_t' confuses me a bit:

  In common/procmon.c (inside MS_WINDOWS), it's typedef'ed to 
  'int' unconditionally.

  And then in common/util.* (tor_terminate_process()) it is assumed to be 
  defined in orconfig.h or somewhere else. It's not AFAICS.

It is true that _getpid() returns an 'int', but the way Tor uses it seems
wrong; the last argument to OpenProcess() takes a 'DWORD'. So 'pid_t'
should be 'DWORD' IMHO.

So maybe we should introduce a 'typedef DWORD tor_pid_t;' in orconfig.h?

Btw. MingW does have 'pid_t' in it's &lt;sys/types.h&gt;.

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111014055216</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-10-14 05:52:16-0400</timestampReceived><subject>Re: [tor-dev] Running Real Tor Code Over Simulated Networks</subject><body>

On Tue, Sep 27, 2011 at 4:20 PM, Rob Jansen &lt;rob.g.jansen@nrl.navy.mil&gt; wrote:
&gt; ...
&gt; For the unaware, we have been working on the design and development of
&gt; Shadow, a simulator capable of running real binaries over a simulated
&gt; network, and a plug-in that runs real Tor. Shadow can simulate roughly 1000
&gt; Tor nodes in 10 GB of RAM and is easy to setup and use (no root required).
&gt; You can generate realistic Tor topologies using a consensus, and test
&gt; changes implemented in Tor extremely quickly.

pretty cool :)


&gt; If you have the need to run Tor experiments, or are just interested in the
&gt; Software, please try it out. We would love any feedback or comments or
&gt; suggestions if you have them!

i've got more, but first off:

- why secondary dependencies not in git and not opt-in?
 e.g. downloading
http://shadow.cs.umn.edu/downloads/shadow-resources.tar.gz - if you
run fully offline build systems this default behavior breaks builds.

- what about hw acceleration in performance estimates?
 e.g. openssl dynamic engines in virtual CPU processing.

- is there a shadow-dev in addition to shadow-support? :)


&gt; We are continuously working on improving the simulator, including more
&gt; efficient use of multiple CPU cores and a command-line interface to help
&gt; with installing Shadow and some of its dependencies.

https://github.com/shadow/shadow-cli also handy.

thanks!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111020145425</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-10-20 14:54:25-0400</timestampReceived><subject>Re: [tor-dev] Proposal 188: Bridge Guards and other</subject><body>

On Wed, Oct 19, 2011 at 08:09:17PM -0400, Nick Mathewson wrote:
&gt;    Note that this design does not require that our stream cipher
&gt;    operations be transitive, even though they are.

Did you mean "commutative"?

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111020000812</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-10-20 00:08:12-0400</timestampReceived><subject>[tor-dev] Proposal 187: Reserve a cell type to allow client</subject><body>

Filename: 187-allow-client-auth.txt
Title: Reserve a cell type to allow client authorization
Author: Nick Mathewson
Created: 16-Oct-2011
Status: Open
Target: 0.2.3.x

Overview:

  Proposals 176 and 184 introduce a new "v3" handshake, coupled with
  a new version 3 link protocol.  This is a good time to introduce
  other stuff we might need.

  One thing we might want is a scanning resistance feature for
  bridges.  This proposal suggests a change we should make right
  away to enable us to deploy such a feature in future versions of
  Tor.

Motivation:

  If an adversary has a suspected bridge address/port combination,
  the easiest way for them to confirm or disconfirm their suspicion
  is to connect to the address and see whether they can do a Tor
  handshake.  The easiest way to fix this problem seems to be to
  give out bridge addresses along with some secret that clients
  should know, but which an adversary shouldn't be able to learn
  easily.  The client should prove to the bridge that it's
  authorized to know about the bridge, before the bridge acts like a
  bridge.  If the client doesn't show knowledge of the proper
  secret, the bridge should at like an HTTPS server or a bittorrent
  tracker or something.

  This proposal *does not* specify a way for clients to authorize
  themselves at bridges; rather, it specifies changes that we should
  make now in order to allow this kind of authorization in the
  future.

Design:

  Currently, now that proposal 176 is implemented, if a server
  provides a certificate that indicates a v3 handshake, and the
  client understands how to do a V3 handshake, we specify that the
  client's first cell must be a VERSIONS cell.

  Instead, we make the following specification changes:

  We reserve a new variable-length cell type, "AUTHORIZE."

  We specify that any number of PADDING or VPADDING or AUTHORIZE
  cells may be sent by the client before it sends a VERSIONS cell.
  Servers that do not require client authorization MUST ignore such
  cells, except to include them when calculating the HMAC that will
  appear in the CLOG part of a client's AUTHENTICATE cell.

  We still specify that clients SHOULD send VERSIONS as their first
  cell; only in some future version of Tor will an AUTHORIZE cell be sent
  first.

Discussion:

  This change allows future versions of the Tor client to know that
  some bridges need authorization, and to send them authentication
  before sending them anything recognizably Tor-like.

  The authorization cell needs to be received before the server can
  send any Tor cells, so we can't just patch it in after the
  VERSIONS cell exchange: the server's VERSIONS cell is unsendable
  until after the AUTHORIZE has been accepted.

  Note that to avoid scanning attacks, it's not sufficient to wait
  for a single cell, and then either handle it as authorization or
  reject the connection.  Instead, we need to decide what kind of
  server we're impersonating, and respond once the client has
  provided *either* an authorization cell, *or* a recognizably valid
  or invalid command in the impersonated protocol.


Alternative design: Just use pluggable transports

  Pluggable transports can do this too, but in general, we want to
  avoid designing the Tor protocol so that any particular desirable
  feature can only be done with a pluggable transport.  That is, any
  feature that *every* bridge should want, should be doable in Tor
  proper.

  Also, as of 16 Oct 2011, pluggable transports aren't in general
  use.  Past experience IMO suggests that we shouldn't offload
  architectural responsibilities to our chickens until they've
  hatched.

Alternative design: Out-of-TLS authorization

  There are features (like port-knocking) designed to allow a client
  to show that it's authorized to use a bridge before the TLS
  handshake even happens.  These are appropriate for bunches of
  applications, but they're trickier with an adversary who is
  MITMing the client.

Alternative design: Just use padding.

  Arguably, we could only add the "VPADDING" cell type to the list
  of those allowed before VERSIONS cells, and say that any client
  authorization we specify later on will be sent as a VPADDING
  cell.  But that design is kludgy: padding should be padding, not
  semantically significant.  Besides, cell types are still fairly
  plentiful.

Counterargument: specify it later

  We could, later on, say that if a client learns that a bridge
  needs authorization, it should send an AUTHORIZE cell.  So long as
  a client never sends an AUTHORIZE to anything other than a bridge that
  needs authorization, it'll never violate the spec.

  But all things considered, it seems easier (just a few lines of
  spec and code) to let bridges eat unexpected authorization now
  than it does to have stuff fail later when clients think that a
  bridge needs authorization but it doesn't.

Counterargument: it's too late!

  We've already got the prop176 branch merged and running on a few
  servers.  But as of this writing, it isn't in any Tor version.

  Even if it *is* out in an alpha before we can get this proposal
  accepted and implemented, that's not a big disaster.  In the worst
  case, where future clients don't know whom to send authorization
  to so they need to send it to _all_ v3 servers, they will at worst
  break their connections only to a couple of alpha versions which
  one hopes by then will be long-deprecated already.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111025231903</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-10-25 23:19:03-0400</timestampReceived><subject>Re: [tor-dev] Proposal 187: Reserve a cell type to allow</subject><body>

On Wed, Oct 19, 2011 at 08:08:12PM -0400, Nick Mathewson wrote:
&gt;   We reserve a new variable-length cell type, "AUTHORIZE."
&gt; 
&gt;   We specify that any number of PADDING or VPADDING or AUTHORIZE
&gt;   cells may be sent by the client before it sends a VERSIONS cell.
&gt;   Servers that do not require client authorization MUST ignore such
&gt;   cells, except to include them when calculating the HMAC that will
&gt;   appear in the CLOG part of a client's AUTHENTICATE cell.
&gt; 
&gt;   We still specify that clients SHOULD send VERSIONS as their first
&gt;   cell; only in some future version of Tor will an AUTHORIZE cell be sent
&gt;   first.

Sounds good to me. Feel free.

Thanks,
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111020175329</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-10-20 17:53:29-0400</timestampReceived><subject>Re: [tor-dev] Proposal 188: Bridge Guards and other</subject><body>

On Thu, Oct 20, 2011 at 10:54 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; On Wed, Oct 19, 2011 at 08:09:17PM -0400, Nick Mathewson wrote:
&gt;&gt; =A0 =A0Note that this design does not require that our stream cipher
&gt;&gt; =A0 =A0operations be transitive, even though they are.
&gt;
&gt; Did you mean "commutative"?

Indeed so.  Fixing.

thanks,
-- =

Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111010102300</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-10-10 10:23:00-0400</timestampReceived><subject>Re: [tor-dev] Tor download link</subject><body>

On 2011-10-10, Marco Bonetti &lt;sid77@slackware.it&gt; wrote:
&gt; Hello all,
&gt; I have noticed that the distribution directory:
&gt; https://www.torproject.org/dist/ only contains source code for the latest
&gt; stable and unstable version.
&gt; This somehow breaks package distribution mechanism like SlackBuilds.org
&gt; which do not host source code by themselves. I have already submitted an up
&gt; to date SlackBuild: as soon it will be accepted, new Slackware users will be
&gt; able again to build Tor again so it's not a ground breaking issue but
&gt; nevertheless a bit annoying.
&gt; So, is there a directory which hosts older but still accepted as valid
&gt; version of Tor which I did not see or is a torproject.org policy to just
&gt; keep latest versions online?

Non-current Tor packages are somewhere on
https://archive.torproject.org/ .  Current Tor packages may also be
there.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111010103519</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2011-10-10 10:35:19-0400</timestampReceived><subject>Re: [tor-dev] Tor download link</subject><body>

Thanks! Looks like current version is up there too.

-- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111010122034</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-10-10 12:20:34-0400</timestampReceived><subject>Re: [tor-dev] Tor download link</subject><body>

On Mon, Oct 10, 2011 at 10:23:00AM +0000, rransom.8774@gmail.com wrote 1.0K bytes in 24 lines about:
: Non-current Tor packages are somewhere on
: https://archive.torproject.org/ .  Current Tor packages may also be
: there.

In fact, current versions are there too.  Build systems should use
archive.torproject.org and not torproject.org/dist for their source code
needs.

/dist is for the current release only.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111025092748</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-10-25 09:27:48-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On 10/20/11 5:34 PM, Erinn Clark wrote:
&gt; * Karsten Loesing &lt;karsten.loesing@gmx.net&gt; [2011:10:19 16:12 +0200]: 
&gt;&gt; 2. Try harder to include diffs in tor-wiki-changes notifications.  I
&gt;&gt; looked for an option that does this in Trac 0.12, but didn't find one.
&gt;&gt; Erinn, do you know how we could implement this change?
&gt; 
&gt; I found this: http://trac.edgewall.org/ticket/1660 
&gt; 
&gt; If we are feeling adventurous, I suppose we could try the very old patches
&gt; listed there. Otherwise we might just want to comment on the bug and say we
&gt; wish to have this feature and ask what the status is.

Hmm, not sure if I feel this adventurous.  Patching Trac means we'll
have to patch it every time there's an update, right?  Probably not
worth it for this change.  I'd say it's better to let people click on a
link in an email if they care about the wiki diff than to risk breaking
Trac.

Thanks for looking this up!

&gt;&gt; 4. Investigate whether we can merge "new", "assigned", "reopened", and
&gt;&gt; "accepted" into a single "open" status.  Erinn said we can do this in
&gt;&gt; Trac.  I had some trouble getting rid of the "new" status when trying
&gt;&gt; this in Trac 0.12, but didn't look too closely.  Erinn, can you try to
&gt;&gt; implement this in our Trac?
&gt; 
&gt; How did you try it? I am nervous to try it on our current trac unless we
&gt; schedule a 'maintenance' window where we tell everyone trac might be broken. I
&gt; believe weasel has a test trac installed, I will look into testing it there
&gt; instead.

I tried this by editing trac.conf, probably similar to how you
implemented our needs_review and needs_information statuses.  I don't
have a clean diff yet.  If you give me our trac.conf (maybe via private
mail), I'll try again next week.

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111029121146</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-10-29 12:11:46-0400</timestampReceived><subject>[tor-dev] Fwd: [guardian-dev] Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2</subject><body>

[Attachment #2 (multipart/alternative)]


-- 
Sent from my Android phone with K-9 Mail. Please excuse my brevity.

Nathan of Guardian &lt;nathan@guardianproject.info&gt; wrote:

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256


Major update to Orbot is now available for testing on Android devices:
https://github.com/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2.apk/qr_code

(sig:
https://github.com/downloads/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2.apk.sig)

This includes work from GSathya of GSoC, as well as the new "make your
phone a Tor Wifi hotspot" feature.

code, commits, whatnot is here now:
https://gitweb.torproject.org/orbot.git

+n
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iF4EAREIAAYFAk6rpcgACgkQ0qzSA7N0y9IJaQD/avI5IVCV4+Zy9yaz/XbVGDrO
ZFIcUVe27zWSa8c8X3cA/j05eJhwnoGAIPLsIQ0jaywd+HcqKQmSI8FHfRgLqgus
=ToXu
-----END PGP SIGNATURE-----
_____________________________________________

Guardian-dev mailing list

Post: Guardian-dev@lists.mayfirst.org
List info: https://lists.mayfirst.org/mailman/listinfo/guardian-dev

To Unsubscribe
Send email to: Guardian-dev-unsubscribe@lists.mayfirst.org
Or visit: https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info

You are subscribed as: nathan@guardianproject.info


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;br&gt;
-- &lt;br&gt;
Sent from my Android phone with K-9 Mail. Please excuse my brevity.&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;Nathan of Guardian &lt;nathan@guardianproject.info&gt; \
wrote:&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: \
1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; &lt;pre style="white-space: pre-wrap; \
word-wrap:break-word; font-family: sans-serif"&gt;-----BEGIN PGP SIGNED MESSAGE-----&lt;br \
/&gt;Hash: SHA256&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Major update to Orbot is now available for testing on \
Android devices:&lt;br /&gt;&lt;a \
href="https://github.com/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2.apk/q \
r_code"&gt;https://github.com/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2.apk/qr_code&lt;/a&gt;&lt;br \
/&gt;&lt;br /&gt;(sig:&lt;br /&gt;&lt;a \
href="https://github.com/downloads/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha \
-RC2.apk.sig"&gt;https://github.com/downloads/guardianproject/Orbot/Orbot-1.0.6-Tor-0.2.3.6-alpha-RC2.apk.sig&lt;/a&gt;)&lt;br \
/&gt;&lt;br /&gt;This includes work from GSathya of GSoC, as well as the new "make your&lt;br \
/&gt;phone a Tor Wifi hotspot" feature.&lt;br /&gt;&lt;br /&gt;code, commits, whatnot is here \
now:&lt;br /&gt;&lt;a href="https://gitweb.torproject.org/orbot.git"&gt;https://gitweb.torproject.org/orbot.git&lt;/a&gt;&lt;br \
/&gt;&lt;br /&gt;+n&lt;br /&gt;-----BEGIN PGP SIGNATURE-----&lt;br /&gt;Version: GnuPG v1.4.11 \
(GNU/Linux)&lt;br /&gt;Comment: Using GnuPG with Mozilla - &lt;a \
href="http://enigmail.mozdev.org"&gt;http://enigmail.mozdev.org&lt;/a&gt;/&lt;br /&gt;&lt;br \
/&gt;iF4EAREIAAYFAk6rpcgACgkQ0qzSA7N0y9IJaQD/avI5IVCV4+Zy9yaz/XbVGDrO&lt;br \
/&gt;ZFIcUVe27zWSa8c8X3cA/j05eJhwnoGAIPLsIQ0jaywd+HcqKQmSI8FHfRgLqgus&lt;br /&gt;=ToXu&lt;br \
/&gt;-----END PGP SIGNATURE-----&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;Guardian-dev mailing list&lt;br /&gt;&lt;br \
/&gt;Post: Guardian-dev@lists.mayfirst.org&lt;br /&gt;List info: &lt;a \
href="https://lists.mayfirst.org/mailman/listinfo/guardian-dev"&gt;https://lists.mayfirst.org/mailman/listinfo/guardian-dev&lt;/a&gt;&lt;br \
/&gt;&lt;br /&gt;To Unsubscribe&lt;br /&gt;        Send email to:  \
Guardian-dev-unsubscribe@lists.mayfirst.org&lt;br /&gt;        Or visit: &lt;a \
href="https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject \
.info"&gt;https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info&lt;/a&gt;&lt;br \
/&gt;&lt;br /&gt;You are subscribed as: nathan@guardianproject.info&lt;br \
/&gt;&lt;/pre&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111029132120</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-10-29 13:21:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 187: Reserve a cell type to allow client</subject><body>

I like the proposal; what I think we now have to figure out, is what
kind and how much of 'scanning resistance' to put into the tor binary.

If we assume that tor must act as something innocuous in the case of a
false AUTHORIZE, we have to find out how much of that innocuous
behavior should be implemented into tor. 
We probably want to avoid putting megabytes of innocuous-looking HTML
pages or implement a bittorrent tracker into tor.
Not only because the implementation will make the tor codebase even
more bloated, but also because we would have to ship a new tor every
time the censors manage to block an obfuscation.

What I think is saner - at least for the short term future - is find a
couple of web services (not necessarily HTTP(S)) whose interface is
easy to implement and have bridges stick to one of them at random, for
as long as they stay on an IP address.

Some examples of such interfaces:

* A "HTTP server" whose index page is protected by HTTP basic access
  authentication. 
  It's easy to code (a couple of HTTP headers and some HTML), with a
  small distinguishing surface and it also defends the fact that the
  same "web server" serves lots of data to other clients (read: the
  actual bridge users).

* A "HTTP server" whose index page is an Apache "It Works!". It serves
  404s to any HTTP request.

* An "FTPS server" which asks for a username/password and obviously
  accepts none.

* An "SSH server" which asks for a username/password and obviously
  accepts none.

Then we can also add a torrc option, say
"ScanningResistanceServicePort", that takes a local port as an
argument and pipes all the input of the attacker (the person who
failed the AUTHORIZE) to that port. In that port the user should have
configured an actual web service which will handle that input.

In the future we can also code a project that pretends to be different
web services for the sake of sitting behind
"ScanningResistanceServicePort". That way we don't polute the tor
codebase and we can also use high level programming languages.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111030214547</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-10-30 21:45:47-0400</timestampReceived><subject>[tor-dev] git-rw moved hosts - new ssh host key</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey there people who have repositories hosted on tpo hardware,

weasel migrated cupani to our shiny new VM server. Along with this came
a change of ssh host key, so please be ready to modify your known_hosts
file accordingly when you next push. The new ssh key fingerprint is:

ssh-rsa e7:a0:63:15:a6:d3:41:e3:cf:92:6e:78:ea:cb:d7:ee

After doing the migration, we took the opportunity to run a full
git gc --aggressive on each repository, which should result in smaller
clone sizes and generally faster clones. Take this as a reminder to
occasionally optimize your local repositories too, your pushes will
benefit and you can reclaim some lost space :)

Sorry this went through without prior notice, I hope nobody's work
was interrupted.

Let me know if there is anything amiss, we don't expect any
kind of issues tho.

All the best
Sebastian
-----BEGIN PGP SIGNATURE-----

iQEcBAEBAgAGBQJOrbUZAAoJEKlsb90UDJYb77AIAIXIW5bkuXVfOB8DEYwh93vN
ddIlxAea8QvrY8hebqHNYGC9a/GgHkgT3+fDGRLW1EsHgTb6YzpYT4Jhnrj1BKHu
37Kn1UzIyuS1X6X1CzFKJzoa6Z2Wej8lmpcOMk5m8GXE+MTMnYV/3kAZ+qsRgJOi
GLO75HIFZc4FbD/wy2xAU6it3aBMPP1wszKK30wtU0oCldo20FDeltqaXt9GlWav
jimBI+AcWBhgFr6hx7FKVLsLNlNkVEeH911E7qtDTF2lNzQAh7mHnzDU4sIZ6FhK
wTNJOV3n/eCiyOp6amNmWC9mk+5RO0qjtNsdG+0aiPcmeKPzNNeIPiH1oQFVBWc=
=rYix
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111031174136</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-10-31 17:41:36-0400</timestampReceived><subject>[tor-dev] Reminder: one month left for big features in 0.2.3.x</subject><body>

Hi, all! This is the final reminder about the December 1 deadline for
getting large stuff merged into 0.2.3.x.

See http://archives.seul.org/or/dev/Jul-2011/msg00030.html for the
original announcment.  It should answer many questions.

December 1 is the deadline for getting large features and complicated
bugfixes merged into 0.2.3.x.

January 6 is the deadline for new features and marginal bugfixes.

I am looking forward to being able to release 0.2.3.x on a
faster-than-previous-Tor-releases schedule. Please plan accordingly!

cheers,
--
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110903213801</emailId><senderName>Doug Ransom</senderName><senderEmail>doug.ransom@alumni.uvic.ca</senderEmail><timestampReceived>2011-09-03 21:38:01-0400</timestampReceived><subject>[tor-dev] Run Tor relay in background on OS X</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/alternative)]


Hi,

I was thinking of tweaking TOR and/or Vidalia so users can easily (i.e. w/o being a \
skilled unix sysadmin) to configure TOR to run at boot.

Any thoughts or concerns before I poke at the source code? 

In the past I have had some success running TOR at boot using Launchd, but its hard \
and doesnt play nice with Vidalia.


Doug Ransom
doug.ransom@alumni.uvic.ca


[Attachment #7 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
-webkit-line-break: after-white-space; "&gt;&lt;div&gt;Hi,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I was \
thinking of tweaking TOR and/or Vidalia so users can easily (i.e. w/o being a skilled \
unix sysadmin) to configure TOR to run at boot.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Any thoughts \
or concerns before I poke at the source code?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In the \
past I have had some success running TOR at boot using Launchd, but its hard and \
doesnt play nice with Vidalia.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div&gt; &lt;span \
class="Apple-style-span" style="border-collapse: separate; color: rgb(0, 0, 0); \
font-family: Helvetica; font-style: normal; font-variant: normal; font-weight: \
normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: \
-webkit-auto; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; \
word-spacing: 0px; -webkit-border-horizontal-spacing: 0px; \
-webkit-border-vertical-spacing: 0px; -webkit-text-decorations-in-effect: none; \
-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; font-size: medium; \
"&gt;&lt;div&gt;Doug Ransom&lt;/div&gt;&lt;div&gt;&lt;a \
href="mailto:doug.ransom@alumni.uvic.ca"&gt;doug.ransom@alumni.uvic.ca&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/span&gt;&lt;br \
class="Apple-interchange-newline"&gt; &lt;/div&gt;
&lt;br&gt;&lt;/body&gt;&lt;/html&gt;


["smime.p7s" (smime.p7s)]

0	*H
 010	+0	*H
 00 4=+'44pT0
	*H
0o10	USE10U
AddTrust AB1&amp;0$UAddTrust External TTP Network1"0 UAddTrust External CA \
Root0 050607080910Z
200530104838Z010	UUS10	UUT10USalt Lake City10U
The USERTRUST Network1!0Uhttp://www.usertrust.com1604U-UTN-USERFirst-Client \
Authentication and Email0"0 	*H
0
9}A;bF7`u9eJGHjM5BI/|1Nd.)dQ5yNh{z2O0 \
nFxoY^/m/j.g5yiF v:z'[=s"HaLi.1 \
,CZqY  gT:
wetbh~GeMW(t40b0,00U#0z4&amp;&amp;T$T0Ug}&amp;pKPH|=n}0U0U00U \
 00U 0DU=0;09 7 \
53http://crl.usertrust.com/AddTrustExternalCARoot.crl05+)0'0%+0http://ocsp.usertrust.com0
 	*H
c(1 {b \
#1sSQL/g~x3t&amp;dpbP#4Vp4nx7_j \
_|&gt;Q5|`k:+}[|P-sxt1^7urDg%R%G &lt; N \
6wH\-?`q` q6  lKuI;M x&amp;-n_00 \
mOj3""2zq0 	*H
010	UUS10	UUT10USalt Lake City10U
The USERTRUST Network1!0Uhttp://www.usertrust.com1604U-UTN-USERFirst-Client \
Authentication and Email0 110428000000Z
200530104838Z010	UGB10UGreater Manchester10USalford10U
COMODO CA Limited1907U0COMODO Client Authentication and Secure Email CA0"0
	*H
0
[KW^/@SX_fe2N2}UxLUB'qi2@'Vbqi \
c^`AjHmeC*.+c8w 2jgo \5Tq 7
PSlY1	LR@[HhJ$:q_;%qh=XF&lt;hmz!W42~JRrd&amp;N`ohQcB}"c \
D\[5K0G0U#0g}&amp;pKPH|=n}0UzNt[xcd'/ \
[y{0U0U00U  00U 0XUQ0O0M K \
IGhttp://crl.usertrust.com/UTN-USERFirst-ClientAuthenticationandEmail.crl0t+ \
h0f0=+01http://crt.usertrust.com/UTNAddTrustClient_CA.crt0%+0http://ocsp.usertrust.com0
 	*H
xWUm3DRB
JAIZsn&gt;&amp;|L0(B&lt;%&gt;
u=9fMo(ltZuz/yVtCr`9 G:eH&lt;=%`I?C
3_`j;:&lt;I3B)93i.EMi=]|Gm]W0KID~y83 \
:]&amp;XaU!C@B0un060 &gt;;Jf0 	*H
010	UGB10UGreater Manchester10USalford10U
COMODO CA Limited1907U0COMODO Client Authentication and Secure Email CA0
110902000000Z
120901235959Z0+1)0'	*H
	doug.ransom@alumni.uvic.ca0"0
	*H
0
nuhR2KQj"9@*pAyljAt`(VMey  \
)gxEZW_]${I|6 3&amp;6/6o5K^&lt; \
s[!.=x49 ,nlON# \
CCr0Gk@)_6$mm~3^ceY{jyk00U#0zNt[xcd'/ \
[y{0Uja0^Rke 0U 0U00 \
U%0++10	`HB 0FU \
?0=0;+10+0)+https://secure.comodo.net/CPS0WUP0N0L J \
HFhttp://crl.comodoca.com/COMODOClientAuthenticationandSecureEmailCA.crl0+ \
|0z0R+0Fhttp://crt.comodoca.com/COMODOClientAuthenticationandSecureEmailCA.crt0$+0http://ocsp.comodoca.com0%U0doug.ransom@alumni.uvic.ca0
 	*H
&gt;
 pVA)};`#o*h.*$F#N&amp;&gt;&gt;vpN \
lJa02&gt;HO\(1PL+N@:35NXSZSi~VqL6Jv)y_ \
Jm"!	51|F(OcamwS&gt;`I-!t8&lt;! \
)Dz\IV 100010	UGB10UGreater \
Manchester10USalford10U COMODO CA Limited1907U0COMODO Client \
Authentication and Secure Email CA&gt;;Jf0	+ 0	*H \
	1	*H 0	*H
	1
110903213801Z0#	*H
	1!VNPy&amp;8?0	+710010	UGB10UGreater \
Manchester10USalford10U COMODO CA Limited1907U0COMODO Client \
Authentication and Secure Email CA&gt;;Jf0*H 	1 \
010	UGB10UGreater Manchester10USalford10U COMODO CA \
Limited1907U0COMODO Client Authentication and Secure Email \
CA&gt;;Jf0 	*H
Mm*%6eQSycAxhyelKS}D"gATtQ6~C75c{K&gt;T8;xI"&amp;6j
 N&amp;kIY K{YAFFkD|t'7Gfl&amp;Oe4&amp;i \
}/Gvxl"p|W4``P'[n"rn';``{Y' -ic 5.Mi?e`V



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110914120609</emailId><senderName>Peter Palfrader</senderName><senderEmail>peter@palfrader.org</senderEmail><timestampReceived>2011-09-14 12:06:09-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

On Mon, 12 Sep 2011, Karsten Loesing wrote:

&gt; &gt;&gt; 3 persons search Trac using key words and 1 person types in ticket
&gt; &gt;&gt; numbers in the search field.  The rest doesn't use the search feature.
&gt; &gt; 
&gt; &gt; I type ticket numbers into my browser's search field, too.  I don't
&gt; &gt; consider typing a Trac link target specifier into the search field to
&gt; &gt; be searching.
&gt; 
&gt; I mentioned this feature, because someone was asking for a way to type
&gt; in ticket numbers somewhere.

Does the brower's address bar count?  Like in http://bugs.torproject.org/1234?

-- 
                           |  .''`.       ** Debian **
      Peter Palfrader      | : :' :      The  universal
 http://www.palfrader.org/ | `. `'      Operating System
                           |   `-    http://www.debian.org/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110914201136</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-09-14 20:11:36-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On Friday, September 02, 2011 10:08:37 Brian Szymanski wrote:
&gt; What exactly are we hoping to gain from the analysis of the (hopefully
&gt; correctly) stripped logs?

Overall, all of our data collected can be analyzed to see if any of it can be 
used to discover users, sets of users, or other personally identifying info.  

It will also be helpful to know more about our websites, usage, referrers, 
etc.  If Tor is going to be transparent in its data collection practices, we 
should be able to publish our web server logs without issue.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110917163810</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2011-09-17 16:38:10-0400</timestampReceived><subject>Re: [tor-dev] Building an automatic censorship-detection system for</subject><body>

Apologies for breaking the thread, I didn't have the original message.

From the mentioned paper (which I've only skimmed):

``The deployed model considers a time interval of seven (7) days to
model connection rates (i.e. $t_i - t_{i1} = 7$ days).''

If I understand correctly, this means trends occurring on a
week-to-week basis (or larger periods) are considered and
higher-frequency trends are undesirable? In that case, perhaps
pre-processing the data by filtering would be useful.

Attached (1.png) is an example (in red) of filtering out all
frequencies higher than that corresponding to a one week period,
compared to the original data (green). This is the entire data for
Switzerland, abscissa in seconds.

The result is a little less noise, which might help with your algorithm.

The same filter applied to the Egypt and Iran data (2.png and 3.png
respectively) doesn't harm the signal for those two censorship events,
at least not by visual inspection. (You'd probably want to use a
Hanning window or something, to avoid those artifacts at the extreme
ends of the red graphs.)

But filtering like this would also mean that the signal of an event
which occurs and is over in less than a week, like this week's, is
also lost...

-- 
Mansour

["1.png" (image/png)]
["2.png" (image/png)]
["3.png" (image/png)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110919234645</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-09-19 23:46:45-0400</timestampReceived><subject>[tor-dev] Tor-related postdoc position available</subject><body>

In case you're interested but hadn't yet heard, I've got a postdoctoral
researcher position available "in the field of privacy-enhancing
technologies, preferably on the topic of privacy-preserving
communications systems".

If you (or someone you know) is finishing up a PhD and would like to
work on PETs/Tor stuff with us Waterloo folks, drop me a line (noting
"Postdoctoral position" in the subject line).

Details are here: http://crysp.uwaterloo.ca/prospective/postdoc/

Thanks,

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110922194441</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-09-22 19:44:41-0400</timestampReceived><subject>Re: [tor-dev] connection_edge_process_relay_cell(): data cell</subject><body>

[Attachment #2 (multipart/signed)]


Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt; On Wed, Sep 21, 2011 at 10:20:22PM +0200, Fabian Keil wrote:

&gt; &gt; I assume it can take several seconds for the exit relay to stop sending
&gt; &gt; data and the Tor client has to continue reading from the stream to keep
&gt; &gt; the circuit usable. Is that correct?
&gt; 
&gt; Yes. The client closes the stream, and sends an end cell toward the
&gt; exit. Meanwhile, the exit sends stuff toward the client. Because of that
&gt; pesky "the intermediate hops can't look inside the circuit" feature,
&gt; there's nothing that the relays can do to realize that these cells aren't
&gt; wanted anymore.
&gt; 
&gt; This behavior is particularly unfortunate when the client is on a modem,
&gt; asks for a page, gives up on the page, asks for another one, and then
&gt; the first one fills his pipe for a little while, making the second one
&gt; not work either.

In my case the feed reader seems to request most images twice,
aborting the first request prematurely. I'm not sure how much
this actually affects the performance.

&gt; I guess we could kill the whole circuit that the stream was on, which
&gt; would propagate forward and meet up with the data cells propagating back.
&gt; But that wouldn't work in situations where you wanted the circuit to
&gt; stick around, e.g. for its other streams.

Maybe I should experiment with that.

&gt; &gt; Is it intended behaviour for the Tor client to forget a stream
&gt; &gt; id before the stream is actually closed on the remote end?
&gt; 
&gt; Yes. No good can come of remembering the streamid just so we can know
&gt; that we meant to throw the cells away. Unless you have something in mind?

Nope. I just wasn't sure if my interpretation of the logs was correct,
and from the code it wasn't obvious to me in what kind of situation
unknown cells are to be expected.

Thanks for the explanation, Roger.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110922211917</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-09-22 21:19:17-0400</timestampReceived><subject>Re: [tor-dev] Proposal 186: Multiple addresses for one OR or bridge</subject><body>

On Thu, Sep 22, 2011 at 3:43 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
&gt; Hi Nick,
&gt;
&gt; a few comments to proposal 186 below:
&gt;
&gt; On 9/21/11 8:13 PM, Nick Mathewson wrote:
&gt;&gt;   In consonance with our changes to the (Socks|Trans|NATD|DNS)Port
&gt;&gt;   options made in 0.2.3.x for proposal 171, I make a corresponding
&gt;&gt;   change to allow multiple SocksPort options and deprecate
&gt;&gt;   SocksListenAddress.
&gt;
&gt; When you say "Socks" in this document in most cases you mean "OR".

Yeowch, you're right.

&gt;&gt;   The new syntax will be:
&gt;&gt;
&gt;&gt;       "SocksPort" PortDescription Options?
&gt;
&gt; The syntax allows multiple options per SocksPort line, right?  Would
&gt; that be "Options*" then?

Yup.

&gt;&gt;   The 'NoListen' option tells Tor to advertise an address, but not
&gt;&gt;   bind to it.  The operator needs to use some other mechanism to
&gt;&gt;   ensure that ports are redirected to ports that _are_ listened on.
&gt;
&gt; Do we need to check that we have at least one SocksPort line without the
&gt; NoListen option?

s/SocksPort/ORPort/

No, but we shouldn't advertise ourselves unless we do, just like we
currently don't advertise ourselves unless we have an ORPort set.

&gt;&gt;   In current operating systems (unless we get into crazy nonportable
&gt;&gt;   tricks) we need to use one socket for every address:port that Tor
&gt;&gt;   bind on.  As a sanity check, we can limit the number of such
&gt;&gt;   sockets we use to, say, 64.  If you want to bind lots more
&gt;&gt;   address:port combinations, you'll want to do it at the
&gt;&gt;   firewall/routing level.
&gt;
&gt; 64 seems very high for the number sockets to open.  If someone wants to
&gt; open more than 8 sockets and doesn't know how to edit firewall rules,
&gt; that person probably shouldn't be opening this number of sockets.

Feels bikesheddy to me; any power of two between 8 and 64 seems fine here.

&gt;&gt;   Example: Our firewall is redirecting ports 80, 443, and 7000-8000
&gt;&gt;   on all hosts in x.244.2.0/24 onto our port 2929.
&gt;&gt;
&gt;&gt;      SocksPort 2929 no-advertise
&gt;&gt;      SocksPort x.244.2.0/24:80,443,7000-8000 no-listen
&gt;
&gt; "no-advertise" -&gt; "noadvertise"
&gt;
&gt; "no-listen" -&gt; "nolisten"
&gt;
&gt; The "/24" should probably also go away.

Done.

&gt;&gt;   Example: We have a dynamic DNS provider that maps
&gt;&gt;   tornode.example.com to our current external IPv4 and IPv6
&gt;&gt;   addresses.  Our firewall forwards port 443 on those address to our
&gt;&gt;   port 1337.
&gt;&gt;
&gt;&gt;      SocksPort 1337 no-advertise alladdrs
&gt;&gt;      SocksPort tornode.example.com:443 no-bind alladdrs
&gt;
&gt; "no-advertise" -&gt; "noadvertise"
&gt;
&gt; "no-bind" -&gt; "nolisten"

done.

&gt; I wonder what the effect of putting in a dynamic hostname is.  Tor uses
&gt; an IP address in the server descriptor anyway, and wouldn't it find out
&gt; the IP address(es) by itself?

You can already specify a hostname as your Address, I believe; this is
meant to work the same.

&gt;&gt;   It will now be possible for a Tor node to find that some addresses
&gt;&gt;   work and others do not.  In this case, the node should only
&gt;&gt;   advertise socksport lines that have been checked.
&gt;
&gt; What if a partial SocksPort line was found to work, that is, if only a
&gt; few ports work?

Then, by the terms of this document, the whole socksport line is discarded.

&gt;&gt;   A node must not list more than 8 or-address lines.
&gt;
&gt; Should there also be a restriction of PORTSPECs per line?  I can imagine
&gt; how these lines can get quite long: 1.2.3.4:1-2,4-5,7-8,...

Good point.  Also, they should be disjoint.

I've made changes in the torspec git repo corresponding to notes above.  Thanks!
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110902001840</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-09-02 00:18:40-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On Thursday, August 25, 2011 04:08:00 Karsten Loesing wrote:
&gt; we have been discussing sanitizing and publishing our web server logs
&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt; website, and analyze them for top visited pages, top downloaded
&gt; packages, etc.  See the tickets #1641 and #2489 for details.

My concern is that we have the data at all.  We shouldn't have any
sensitive information logged on the webservers. Therefore sanitizing the
logs should not be necessary.  I would like to replace the current
0.0.0.0/0.0.0.1 scheme with a geoip lookup and just log the country code
in place of the IP address. Apache can do this on the fly between
request and the log entry.

&gt; Is there still anything sensitive in that log file that we should
&gt; remove?  For example:

Referrers and requested urls will be a nightmare to clean up. We
literally get thousands of probes a day per site trying to exploit
apache (or tomcat, or cgi, or a million other things). If we were the US
military, we'd claim each probe is a hostile attack and whine about
millions of attacks on our infrastructure a year. Clearly this is
cyberwar and we need $3 billion to stop it or retaliate.

On the other hand, seeing the referrer data has been interesting because
it tells us where our traffic originates. Our top referrers are google
and the wikipedia pages about tor in various languages. The search terms
are also valuable if we want to buy keywords for ads some day. We've had
two volunteers do this already through google adwords and the results
are surprising.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110914061705</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-14 06:17:05-0400</timestampReceived><subject>[tor-dev] Building an automatic censorship-detection system for Tor</subject><body>

In the past years we observed sudden drops in Tor usage in certain
countries.  Some of these events may be attributed to countries
specifically wanting to block Tor, as it enables their citizens to
circumvent their censorship infrastructure.  Other events likely result
from country-wide Internet outages that are unrelated to Tor.

Two such events happened in January 2011 in Iran [0] and Egypt [1].

The key point is that we can derive from observed Tor usage when
something potentially interesting is going on in a country.  We should
be able to build a system that keeps track of our daily user estimates
per country and automatically sends out a warning whenever there are
sudden changes.

George Danezis wrote "An anomaly-based censorship-detection system for
Tor" [2].  George's detection code [3] uses our daily user estimates [4]
as input and gives a list of sudden upturns and downturns per country as
output.  We integrated the results of his script in the metrics website
[5] to demonstrate what events the detector recognizes as possible
censorship events.

For example, the detector would have warned in January 2011 about the
events in Iran [6] and Egypt [7], shown as red dots for downturns.

However, as one can see, George's script also detects quite a few false
positives.  Whenever there's a red or blue dot, the script would have
issued a warning for a human to check.  It would be neat to reduce these
false warnings while still catching the really suspicious events.

Want to help us make our censorship-detection system better?  Any
suggestion to improve George's algorithm or to come up with an
alternative approach to detect possible censorship events in our data
would be much appreciated!  Let us know if we can help you get started.


[0]
https://metrics.torproject.org/users.html?graph=direct-users&amp;start=2011-01-01&amp;country=ir&amp;#direct-users


[1]
https://metrics.torproject.org/users.html?graph=direct-users&amp;start=2011-01-01&amp;country=eg#direct-users


[2] https://metrics.torproject.org/papers/detector-2011-08-11.pdf

[3] https://gitweb.torproject.org/metrics-tasks.git/tree/HEAD:/task-2718

[4] https://metrics.torproject.org/csv/direct-users.csv

[5] https://metrics.torproject.org/users.html#censorship-events

[6]
https://metrics.torproject.org/users.html?graph=direct-users&amp;start=2011-01-01&amp;country=ir&amp;events=on#direct-users


[7]
https://metrics.torproject.org/users.html?graph=direct-users&amp;start=2011-01-01&amp;country=eg&amp;events=on#direct-users
 _______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110921202022</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-09-21 20:20:22-0400</timestampReceived><subject>[tor-dev] connection_edge_process_relay_cell(): data cell dropped,</subject><body>

[Attachment #2 (multipart/signed)]


While experimenting with Tor v0.2.3.4-alpha's "optimistic data" and
thus keeping an eye on the logs, I noticed that I get a lot of the
following messages (with and without "optimistic data"):

Sep 20 13:47:57.428 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8236 relay cells here (command 2, stream 49411).
Sep 20 13:47:57.428 [debug] {APP} connection_edge_process_relay_cell(): cir=
c deliver_window now 911.
Sep 20 13:47:57.428 [info] {APP} connection_edge_process_relay_cell(): data=
 cell dropped, unknown stream (streamid 49411).
Sep 20 13:47:57.431 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8237 relay cells here (command 2, stream 49411).
Sep 20 13:47:57.431 [debug] {APP} connection_edge_process_relay_cell(): cir=
c deliver_window now 910.
Sep 20 13:47:57.431 [info] {APP} connection_edge_process_relay_cell(): data=
 cell dropped, unknown stream (streamid 49411).
Sep 20 13:47:57.432 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8238 relay cells here (command 2, stream 49411).
Sep 20 13:47:57.432 [debug] {APP} connection_edge_process_relay_cell(): cir=
c deliver_window now 909.
Sep 20 13:47:57.432 [info] {APP} connection_edge_process_relay_cell(): data=
 cell dropped, unknown stream (streamid 49411).
Sep 20 13:47:57.432 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8239 relay cells here (command 2, stream 49411).
[...]
Sep 20 13:48:01.479 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8379 relay cells here (command 2, stream 49411).
Sep 20 13:48:01.479 [debug] {APP} connection_edge_process_relay_cell(): cir=
c deliver_window now 968.
Sep 20 13:48:01.479 [info] {APP} connection_edge_process_relay_cell(): data=
 cell dropped, unknown stream (streamid 49411).
Sep 20 13:48:01.479 [debug] {APP} relay_lookup_conn(): found conn for strea=
m 49410.

Sometimes up to 400-500 dropped cells per unknown stream id.
The deliver window seems to go down to 900 and then starts at
999 again.

It's my impression that it always happens after the client
connection is closed prematurely, something my feed reader
unfortunately does frequently:

Sep 20 13:47:56.608 [debug] {APP} connection_edge_process_relay_cell(): Now=
 seen 8235 relay cells here (command 2, stream 49411).
Sep 20 13:47:56.608 [debug] {APP} connection_edge_process_relay_cell(): cir=
c deliver_window now 912.
Sep 20 13:47:56.792 [debug] {APP} circuit_consider_stop_edge_reading(): con=
sidering layer_hint-&gt;package_window 995
Sep 20 13:47:56.792 [info] {EDGE} connection_edge_reached_eof(): conn (fd 1=
4) reached eof. Closing.

I assume it can take several seconds for the exit relay to stop sending
data and the Tor client has to continue reading from the stream to keep
the circuit usable. Is that correct?

Is it intended behaviour for the Tor client to forget a stream
id before the stream is actually closed on the remote end?

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110921210019</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-21 21:00:19-0400</timestampReceived><subject>Re: [tor-dev] connection_edge_process_relay_cell(): data</subject><body>

On Wed, Sep 21, 2011 at 10:20:22PM +0200, Fabian Keil wrote:
&gt; While experimenting with Tor v0.2.3.4-alpha's "optimistic data" and
&gt; thus keeping an eye on the logs, I noticed that I get a lot of the
&gt; following messages (with and without "optimistic data"):
&gt; 
&gt; Sep 20 13:47:57.428 [debug] {APP} connection_edge_process_relay_cell(): Now seen \
&gt; 8236 relay cells here (command 2, stream 49411). Sep 20 13:47:57.428 [debug] {APP} \
&gt; connection_edge_process_relay_cell(): circ deliver_window now 911. Sep 20 \
&gt; 13:47:57.428 [info] {APP} connection_edge_process_relay_cell(): data cell dropped, \
&gt; unknown stream (streamid 49411). 
&gt; Sometimes up to 400-500 dropped cells per unknown stream id.
&gt; The deliver window seems to go down to 900 and then starts at
&gt; 999 again.
&gt; 
&gt; It's my impression that it always happens after the client
&gt; connection is closed prematurely, something my feed reader
&gt; unfortunately does frequently:

Exactly so.

&gt; I assume it can take several seconds for the exit relay to stop sending
&gt; data and the Tor client has to continue reading from the stream to keep
&gt; the circuit usable. Is that correct?

Yes. The client closes the stream, and sends an end cell toward the
exit. Meanwhile, the exit sends stuff toward the client. Because of that
pesky "the intermediate hops can't look inside the circuit" feature,
there's nothing that the relays can do to realize that these cells aren't
wanted anymore.

This behavior is particularly unfortunate when the client is on a modem,
asks for a page, gives up on the page, asks for another one, and then
the first one fills his pipe for a little while, making the second one
not work either.

I guess we could kill the whole circuit that the stream was on, which
would propagate forward and meet up with the data cells propagating back.
But that wouldn't work in situations where you wanted the circuit to
stick around, e.g. for its other streams.

&gt; Is it intended behaviour for the Tor client to forget a stream
&gt; id before the stream is actually closed on the remote end?

Yes. No good can come of remembering the streamid just so we can know
that we meant to throw the cells away. Unless you have something in mind?

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110921181318</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-09-21 18:13:18-0400</timestampReceived><subject>[tor-dev] Proposal 186: Multiple addresses for one OR or bridge</subject><body>

Filename: 186-multiple-orports.txt
Title: Multiple addresses for one OR or bridge
Author: Nick Mathewson
Created: 19-Sep-2011
Supersedes: 118
Status: Draft

Overview:

  This document is a proposal for servers to advertise multiple
  address/port combinations for their ORPort.

  It supersedes proposal 118.

Motivation:

  Sometimes servers want to support multiple ports for incoming
  connections, either in order to support multiple address families
  (ie, to add IPv6 support), to better use multiple interfaces, or
  to support a variety of FascistFirewallPorts settings.  This is
  easy to set up now, but there's no way to advertise it to clients.

Configuring additional addresses and ports:

  In consonance with our changes to the (Socks|Trans|NATD|DNS)Port
  options made in 0.2.3.x for proposal 171, I make a corresponding
  change to allow multiple SocksPort options and deprecate
  SocksListenAddress.

  The new syntax will be:

      "SocksPort" PortDescription Options?

      Options = "NoAdvertise" | "NoListen" | "AllAddrs" | "IPV4Only"
          | "IPV6Only"

      PortDescription = PORTLIST |
                        ADDRESS ":" PORTLIST |
                        Hostname ":" PORTLIST

      (PORTLIST and ADDRESS are defined below.)

  The 'NoAdvertise' option performs the function of the old
  SocksListenAddress option.  If it is set, we bind a port, but
  don't put it in our descriptor.

  The 'NoListen' option tells Tor to advertise an address, but not
  bind to it.  The operator needs to use some other mechanism to
  ensure that ports are redirected to ports that _are_ listened on.

  The 'AllAddrs' option tells Tor that if no address is given in the
  PortDescription part, we should bind/advertise every one of our
  publicly visible unicast addresses; and that if a hostname address
  is given in the PortDescription, we should bind/advertise every
  publicly visible unicast address that the hostname resolves to.
  (Q: Should this be on by default?)   The 'IPv4Only' and 'IPv6Only'
  options tell Tor to interpret such situations as applying only to
  IPv4 addresses or to IPv6 addresses.

  As with the client *Port options, only the old format or the new
  format are allowed: either a single numeric socksport and zero or
  more sockslistenaddress options, or a set of one or more
  SocksPorts in the new extended format.

  In current operating systems (unless we get into crazy nonportable
  tricks) we need to use one socket for every address:port that Tor
  bind on.  As a sanity check, we can limit the number of such
  sockets we use to, say, 64.  If you want to bind lots more
  address:port combinations, you'll want to do it at the
  firewall/routing level.

  Example: We want to bind on 0.0.0.0:9001

     SocksPort 9001

  Example: Our firewall is redirecting ports 80, 443, and 7000-8000
  on all hosts in x.244.2.0/24 onto our port 2929.

     SocksPort 2929 no-advertise
     SocksPort x.244.2.0/24:80,443,7000-8000 no-listen

  Example: We have a dynamic DNS provider that maps
  tornode.example.com to our current external IPv4 and IPv6
  addresses.  Our firewall forwards port 443 on those address to our
  port 1337.

     SocksPort 1337 no-advertise alladdrs
     SocksPort tornode.example.com:443 no-bind alladdrs

Self-testing:

  Right now, Tor nodes need to check every port that they advertise
  before they declare themselves reachable.  If a Tor has
  a lot of advertised ports, that could be prohibitive.
  Instead, it should try a sample of ports for each address.  It should
  not advertise any given SocksPort line until it has tried
  extending to or connecting to a sample of the address/port
  combinations.

  It will now be possible for a Tor node to find that some addresses
  work and others do not.  In this case, the node should only
  advertise socksport lines that have been checked.

  {Until support is added for extend cells to IPv6 addresses, it
  will only be possible to test IPv6 addresses by connecting
  directly.  We might want to just skip self-testing those until we
  have IPv6 extend support.}

New descriptor syntax:

  We add a new line in the router descriptor, "or-address".  This line
  can occur zero, one, or multiple times.  Its format is:

      or-address SP ADDRESS ":" PORTLIST NL

      ADDRESS = IP6ADDR | IP4ADDR
      IPV6ADDR = an ipv6 address, surrounded by square brackets.
      IPV4ADDR = an ipv4 address, represented as a dotted quad.
      PORTLIST = PORTSPEC | PORTSPEC "," PORTLIST
      PORTSPEC = PORT | PORT "-" PORT
      PORT = a number between 1 and 65535 inclusive.

  [This is the regular format for specifying sets of addresses and
  ports in Tor.]

  A descriptor should not include an or-address line that does
  nothing but duplicate the address:port pair from its "router"
  line.

  A node must not list more than 8 or-address lines.

  (Q: Any reason to allow more than 2?  Multiple interfaces, I guess.)

New authority behavior:

  The same rationale applies as for self-testing.  An authority
  needs to test the main address:port from the router line, and
  every or-address line.  For or-address lines that contains
  multiple ports, it needs to test all of them if they are few, or a
  sample if they are not.

  An authority shouldn't list a node as Running unless every
  or-address line it advertises looks like it will work.

Consensus directories and microdescriptors:

  We introduce a new line type for microdescriptors and consensuses,
  "a".  Each "a" line has the same format as an or-address line.
  The "a" lines (if any) appear immediately after the "r" line for a
  router in the consensus, and immediately after the "onion-key"
  entry in a microdescriptor.

  Clients that use microdescriptors should consider a node's
  addresses to be the address:port listed in the "r" line of a
  consensus, plus all "a" lines for that node in the consensus, plus
  all "a" lines for that node in the its microdescriptor.  Clients
  that use full descriptors should consider a node's addresses to be
  everything listed in its descriptor.

  We will have to define a new voting algorithm version; when using
  this version or later, votes should include a single "a" line for
  every relay that has an IPv6 address, to include the first IPv6
  line in its descriptor.  (If there are no or-address lines, then
  they shouldn't include any "a" lines.)  The remaining or-address
  lines will turn into "a" lines in the microdescriptor.

  As with other data in the vote derived from the descriptor,
  the vote will include whichever set of "a" lines are given by the
  most authorities who voted for the descriptor digest that will be
  used for the router.

Directory authorities with more addresses:

  We need a way for a client to configure a TrustedDirServer as
  having multiple OR addresses, specifically so that we can give at
  least one default authority an IPv6 address for bootstrapping
  purposes.

  (Q: Do any of the current authorities have stable IPv6 addresses?)

  We will want to allow the address in a "dir-source" line in a vote
  to contain an IPv6 address, and/or allow voters to list themselves
  with more addresses in votes/consensuses.  But right now, nothing
  actually uses the addresses listed for voters in dir-source lines
  for anything besides log messages.

Client behavior:

  I propose that initially we shouldn't change client behavior too
  much here.

  (Q: Is there any advantage to having a client choose a random
  address?  If so we can do it later.  If not, why list any more
  than one IPv4 and one IPv6 address?)

  Tor clients not running with bridges, and running with IPv4
  support, should still use the address and ORPort as advertised in
  the router or r line of the appropriate directory object.

  Tor clients not running with bridges, and running without IPv4
  support, should use the first listed IPv6 address for a node,
  using the lowest-numbered listed port for that address.  They
  should only connect to nodes with an IPv6 address.

  Clients should accept Bridge lines with IPv6 addresses, and
  address:port sets, in addition to the lines they currently accept.

  Clients, for now, should only use the address:port from the router
  line when making EXTEND cells; see below.

Nodes without IPv4 addresses:

  Currently Tor requires every node or bridge to have an IPv4
  address.  We will want to maintain this property for the
  foreseeable future, but we should define how a node without an IPv4
  address would advertise itself.

  Right now, there's no way to do that: if anything but an IPv4
  address appears in a router line of a routerdesc, or the "r" line of
  a consensus, then it won't parse.  If something that looks like an
  IPv4 address appears there, clients will (I believe) try to
  connect to it.

  We can make this work, though: let's allow nodes to list themselves
  with a magic IPv4 address (say, 127.1.1.1) if they have
  or-address entries containing only IPv6 address.  We could give
  these nodes a new flag other than Running to indicate that they're
  up, and not give them the Running flag.  That way, old clients
  would never try to use them, but new clients could know to treat
  the new flag as indicating that the node is running, and know not
  to connect to a node listed with address 127.1.1.1.

Interaction with EXTEND and NETINFO:

  Currently, EXTEND cells only support IPv4 addresses, so we should
  use only those.  There is a proposal draft to support more address
  types.

  A server's NETINFO cells must list all configured addresses for a
  server.

Why not extend DirPort this way too?

  Because clients are all using BEGINDIR these days.

  That is, clients tunnel their directory requests inside OR
  connections, and don't generally connect to DirPorts at all.

Why not have address ranges?

  Earlier drafts of this proposal suggested that clients should
  provide not only ranges of ports, but also ranges of addresses,
  specified with bitmasks.  That's a neat idea for circumvention,
  but if we did that, you wouldn't want to advertise publicly that
  you have an entire address range.

Coding impact:

  In addition to the obvious changes, we need to audit everything
  that looks up or compares OR connections and nodes by address:port
  under the assumptions that each node has only a single address or
  ORPort.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110920193342</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-09-20 19:33:42-0400</timestampReceived><subject>[tor-dev] Proposal 184: Miscellaneous changes for a v3 Tor link</subject><body>

Filename: 184-v3-link-protocol.txt
Title: Miscellaneous changes for a v3 Tor link protocol
Author: Nick Mathewson
Created: 19-Sep-2011
Status: Open
Target: 0.2.3.x

Overview:

  When proposals 176 and 179 are implemented, Tor will have a new
  link protocol.  I propose two simple improvements for the v3 link
  protocol: a more partitioned set of which types indicate
  variable-length cells, and a better way to handle link padding if
  and when we come up with a decent scheme for it.

Motivation:

  We're getting a new link protocol in 0.2.3.x, thanks (again) to
  TLS fingerprinting concerns.  When we do, it'd be nice to take
  care of some small issues that require a link protocol version
  increment.

  First, our system for introducing new variable-length cell types
  has required a protocol increment for each one.  Unlike
  fixed-length (512 byte) cells, we can't add new variable-length
  cells in the existing link protocols and just let older clients
  ignore them, because unless the recipient knows which cells are
  variable-length, it will treat them as 512-byte cells and discard
  too much of the stream or too little.  In the past, it's been
  useful to be able to introduce new cell types without having to
  increment the link protocol version.

  Second, once we have our new TLS handshake in place, we will want
  a good way to address the remaining fingerprinting opportunities.
  Some of those will likely involve traffic volume.  We can't fix
  that easily with our existing PADDING cell type, since PADDING
  cells are fixed-length, and wouldn't be so easy to use to break up
  our TLS record sizes.

Design: Indicating variable-length cells.

  Beginning with the v3 link protocol, we specify that all cell
  types in the range 128..255 indicate variable-length cells.
  Cell types in the range 0..127 are still used for 512-byte
  cells, except that the VERSIONS cell type (7) also indicates a
  variable-length cell (for backward compatibility).

  As before, all Tor instances must ignore cells with types that
  they don't recognize.

Design: Variable-length padding.

  We add a new variable-length cell type, "VPADDING", to be used for
  padding.  All Tor instances may send a DROP cell at any point that
  a VERSIONS cell is not required; a VPADDING cell's body may be any
  length; the body of a VPADDING cell MAY have any content.  Upon
  receiving a VPADDING cell, the recipient should drop it, as with a
  PADDING cell.

Interaction with proposal 176:

  Proposal 176 says that during the v3 handshake, no cells other
  than VERSIONS, AUTHENTICATE, AUTH_CHALLENGE, CERT, and NETINFO are
  allowed, and those are only allowed in their standard order.  If
  this proposal is accepted, then VPADDING cells should also be
  allowed in the handshake at any point after the VERSIONS cell.
  They should be included when computing the "SLOG" and "CLOG"
  handshake-digest fields of the AUTHENTICATE cell.

Notes on future-proofing:

  It may be in the future we need a new cell format that is neither the
  original 512-byte format nor the variable-length format.  If we
  do, we can just increment the link protocol version number again.

  Right now we have 10 cell types; with this proposal and proposal
  176, we will have 14.  It's unlikely that we'll run out any time
  soon, but if we start to approach the number 64 with fixed-length
  cell types or 196 with var-length cell types, we should consider
  tweaking the link protocol to have a variable-length cell type
  encoding.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110920193416</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-09-20 19:34:16-0400</timestampReceived><subject>[tor-dev] Proposal 185: Directory caches without DirPort</subject><body>

Filename: 185-dir-without-dirport.txt
Title: Directory caches without DirPort
Author: Nick Mathewson
Created: 20-Sep-2011
Status: Open

Overview:

  Exposing a directory port is no longer necessary for running as a
  directory cache.  This proposal suggests that we eliminate that
  requirement, and describes how.

Motivation:

  Now that we tunnel directory connections by default, it is no
  longer necessary to have a DirPort to be a directory cache.  In
  fact, bridges act as directory caches but do not actually have a
  DirPort exposed.  It would be nice and tidy to expand that
  property to the rest of the network.

Configuration:

  Add a new torrc option, "DirCache".  Its values can be "0", "1",
  and "auto".  If it is 0, we never act as a directory cache, even
  if DirPort is set.  If it is 1, then we act as a directory cache
  according to same rules as those used for nodes that set a
  DirPort.  If it is "auto", then Tor decides whether to act as a
  directory cache.

Advertising cache status:

  Nodes which are running as a directory cache but which do not have
  a DirPort set should set the entry "dir-cache 1" in their router
  descriptors.

Consensus:

  Authorities should assign a "DirCache" flag to all nodes running
  as a directory cache that do not set a DirPort.

  This does not require a new version of the consensus algorithm.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110923135225</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-09-23 13:52:25-0400</timestampReceived><subject>[tor-dev] MITM for TOR</subject><body>

Hi Folks,

I build a small Monitor In The Middle (MITM) proxy that can be used to
study the communication between TOR and the browser. Hope this can be
used to improve TOR.

It's small but quite powerful. Wrote an article about it on my blog:

http://freedomboxblog.nl/mitm-for-tor/

Enjoy,
Rob van der Hoeven.

http://freedomboxblog.nl


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110926112440</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-09-26 11:24:40-0400</timestampReceived><subject>Re: [tor-dev] MITM for TOR</subject><body>

On Fri, Sep 23, 2011 at 03:52:25PM +0200, robvanderhoeven@ziggo.nl wrote 0.5K bytes in 20 lines about:
: I build a small Monitor In The Middle (MITM) proxy that can be used to
: study the communication between TOR and the browser. Hope this can be
: used to improve TOR.
: 
: It's small but quite powerful. Wrote an article about it on my blog:
: 
: http://freedomboxblog.nl/mitm-for-tor/

It seems you responded to another thread with a new subject, perhaps
this has confused others.

How does this differ from the tamper data extension in Firefox?
https://addons.mozilla.org/en-US/firefox/addon/tamper-data/

In either case, did you find anything in the interaction between firefox
and the Tor socks proxy? From you blog post, it looks like Tor socks
interaction is quick, and the performance of everything else is
dependent on the active circuit.

And, it's Tor, not TOR.  See
https://www.torproject.org/docs/faq.html.en#WhyCalledTor for the
details.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110929181545</emailId><senderName>Mohammad Mo</senderName><senderEmail>mohammad_20101389@yahoo.com</senderEmail><timestampReceived>2011-09-29 18:15:45-0400</timestampReceived><subject>[tor-dev] =?utf-8?b?2LPZhNin2YUg2KjYsdmG2KfZhdmHINiq2YjYsSDZgdin?=</subject><body>

[Attachment #2 (multipart/alternative)]


       

          

[Attachment #5 (text/html)]

&lt;html&gt;&lt;body&gt;&lt;div style="color:#000; background-color:#fff; font-family:tahoma, new \
york, times, serif;font-size:12pt"&gt;&lt;div&gt;    \
   &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt; \
       \
&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110929191625</emailId><senderName>"Thomas S. Benjamin"</senderName><senderEmail>tomb@acm.org</senderEmail><timestampReceived>2011-09-29 19:16:25-0400</timestampReceived><subject>[tor-dev] Future direction for torperf</subject><body>

Dear all,

I am working on a re-design of torperf that will use a central python
script to automate initiation and control of torperf experiments.

I have a very rough draft that provides the most basic level of
functionality in tomb/torperf.git branch 3280, and have ticket #3280
as wanting review.

The code needs substantial improvement, but I would love feedback on
my general approach before I spend a lot of time on grooming this
specific version.

If you use torperf please consider giving me feedback on the direction
in which I am heading with this.  I want to make sure that I am
designing something that will work for other people, rather than just
for my own experiments.

I have chosen not to merge into a branch of torperf.git because my
working style involves lots of frequent verbose commits, which would
be distracting for most people.  I will roll together the many commits
before merging into torperf.git

-- 
Sincerely Yours,
              ---Thomas S. Benjamin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110914171542</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-09-14 17:15:42-0400</timestampReceived><subject>Re: [tor-dev]</subject><body>

On Monday, September 12, 2011 11:27:51 Karsten Loesing wrote:
&gt; Well, I don't know what to do here.  I think changing the component of
&gt; 500+ tickets and adding, say, keywords for the category is a lot of work
&gt; and will generate a lot of mail for people on tor-bugs.  Is it worth it?

Is there any way to automate the keyword creation for tickets?  

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110926125858</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-09-26 12:58:58-0400</timestampReceived><subject>Re: [tor-dev] MITM for TOR</subject><body>

&gt; On Fri, Sep 23, 2011 at 03:52:25PM +0200, robvanderhoeven@ziggo.nl wrote 0.5K bytes in 20 lines about:
&gt; : I build a small Monitor In The Middle (MITM) proxy that can be used to
&gt; : study the communication between TOR and the browser. Hope this can be
&gt; : used to improve TOR.
&gt; : 
&gt; : It's small but quite powerful. Wrote an article about it on my blog:
&gt; : 
&gt; : http://freedomboxblog.nl/mitm-for-tor/
&gt; 
&gt; It seems you responded to another thread with a new subject, perhaps
&gt; this has confused others.
&gt; 
&gt; How does this differ from the tamper data extension in Firefox?
&gt; https://addons.mozilla.org/en-US/firefox/addon/tamper-data/
&gt; 

I don't know tamper-data but i tried firebug and was not happy with it.

MITM is written for Tor, it measures Tor performance.
MITM is not a Firefox extension, it can be used with any browser.
MITM can be used at both the entry as the exit node of the Tor network.
MITM is written in Python and can (in my opinion) be easily adapted to
produce all kinds of reports. The code can be used as a base for an
automatic monitoring program.

&gt; In either case, did you find anything in the interaction between firefox
&gt; and the Tor socks proxy? From you blog post, it looks like Tor socks
&gt; interaction is quick, and the performance of everything else is
&gt; dependent on the active circuit.

First: I'm not very up-to-date with the internal workings of Tor. I hope
to learn more in the future! For the moment i think it is best to have
an unbiased view. I just want to measure what the system does.   

Some results:

If you look at the graph in my article you see multiple parallel
connections to the same webserver. Each connection has the same Socks
DNS round-trip. Why? After the first round-trip the address of the
requested server is known to Tor. For *HTTP* traffic the DNS round-trip
is in my opinion not needed. If a server cannot be resolved the exit
node can simply send an error page back to the browser (just like the
browser does if it can't resolve a name)

I noticed that some connections stay open for a long time after the last
request (several minutes are not uncommon). This is bad because
connections use up valuable resources. Ideally the Tor exit node should
not keep *HTTP* connections open for more than lets say 10 seconds. It
is very cheap to reconnect. 

Note: Both remarks are ONLY valid for HTTP traffic. As i understand it
Tor is protocol neutral at the moment?

Another observation: Sometimes the DNS part is very slow (more than 10
seconds) Is this because a new circuit is being build?

&gt; 
&gt; And, it's Tor, not TOR.  See
&gt; https://www.torproject.org/docs/faq.html.en#WhyCalledTor for the
&gt; details.

Sorry, i will correct this.

Rob van der Hoeven.
http://freedomboxblog.nl


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110922084904</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-22 08:49:04-0400</timestampReceived><subject>Re: [tor-dev] Proposal 185: Directory caches without DirPort</subject><body>

Hi Nick,

and here are a few comments to your proposal 185:

On 9/20/11 9:34 PM, Nick Mathewson wrote:
&gt; Configuration:
&gt; 
&gt;   Add a new torrc option, "DirCache".  Its values can be "0", "1",
&gt;   and "auto".  If it is 0, we never act as a directory cache, even
&gt;   if DirPort is set.

Do these relays set "dir-cache 0" in their router descriptors?  Or do
they just not include "dir-cache 1"?  But if they set a non-zero
DirPort, how will the directory authorities and clients know that the
node doesn't want to act as a directory cache?

&gt;  If it is 1, then we act as a directory cache
&gt;   according to same rules as those used for nodes that set a
&gt;   DirPort.  If it is "auto", then Tor decides whether to act as a
&gt;   directory cache.

What are the rules when setting a DirPort?  Successful self-test and
minimum advertised bandwidth?  How's "1" different from "auto" if Tor
decides whether to act as a directory cache in both cases?

&gt; Consensus:
&gt; 
&gt;   Authorities should assign a "DirCache" flag to all nodes running
&gt;   as a directory cache that do not set a DirPort.

Would it make sense to have them assign the "DirCache" flag for nodes
with a non-zero DirPort, too?

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110922224134</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-22 22:41:34-0400</timestampReceived><subject>Re: [tor-dev] Proposal 185: Directory caches without DirPort</subject><body>

On Thu, Sep 22, 2011 at 10:49:04AM +0200, Karsten Loesing wrote:
&gt; On 9/20/11 9:34 PM, Nick Mathewson wrote:
&gt; &gt; Configuration:
&gt; &gt; 
&gt; &gt;   Add a new torrc option, "DirCache".  Its values can be "0", "1",
&gt; &gt;   and "auto".  If it is 0, we never act as a directory cache, even
&gt; &gt;   if DirPort is set.
&gt; 
&gt; Do these relays set "dir-cache 0" in their router descriptors?  Or do
&gt; they just not include "dir-cache 1"?  But if they set a non-zero
&gt; DirPort, how will the directory authorities and clients know that the
&gt; node doesn't want to act as a directory cache?

It seems like there are really two behaviors we want to control here.
Question 1: "do you fetch and cache directory info and answer questions
if somebody asks you questions?"
Question 2: "should you be identified in the consensus as a relay that
wants to answer questions?"

If the answer to #2 is yes, the answer to #1 must be yes also.

Every exit relay fetches and caches directory info already (see the last
check in directory_caches_dir_info()). So do bridges. I'd say our life
would get a lot easier if we just declare that anybody with an ORPort
set should say yes to #1. To be clear, the change in behavior there is
that non-exit non-dirport relays would now start fetching dir info from
authorities on the mirror schedule.

And at that point it's just a question of deciding how to answer #2.

See decide_to_advertise_dirport() in router.c for the complex set of
topics we consider now for answering #2.

One simple answer would be that if you're in the consensus and have
a new enough version, the answer to #2 is simply yes. Everybody is a
suitable choice for answering dir info. Hibernating relays aren't in the
consensus. Clients already weight their selection by capacity to shift
load to faster relays. Relays with set but unreachable dirports should
list "0" for their dirport, but still answer questions.

Variation A would be that clients entirely avoid relays under a certain
capacity (say, 50KB) when making their selection. If we want to get
super fancy, we could have authorities vote on a consensus param that
describes the capacity under which clients should choose not to ask a
relay about dir info.

Variation B would be to make a new relay status flag NoDirCache that
authorities set if you put a line in your descriptor asking for clients
to avoid you, for example if you have accounting set. But I think that's
probably more trouble than it's worth.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110922235558</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-09-22 23:55:58-0400</timestampReceived><subject>Re: [tor-dev] Proposal 184: Miscellaneous changes for a v3 Tor	link</subject><body>

On Tue, Sep 20, 2011 at 03:33:42PM -0400, Nick Mathewson wrote:
&gt; Design: Indicating variable-length cells.
&gt; 
&gt;   Beginning with the v3 link protocol, we specify that all cell
&gt;   types in the range 128..255 indicate variable-length cells.
&gt;   Cell types in the range 0..127 are still used for 512-byte
&gt;   cells, except that the VERSIONS cell type (7) also indicates a
&gt;   variable-length cell (for backward compatibility).
&gt; 
&gt;   As before, all Tor instances must ignore cells with types that
&gt;   they don't recognize.

Sounds good.

&gt; Design: Variable-length padding.
&gt; 
&gt;   We add a new variable-length cell type, "VPADDING", to be used for
&gt;   padding.  All Tor instances may send a DROP cell at any point that
&gt;   a VERSIONS cell is not required; a VPADDING cell's body may be any
&gt;   length; the body of a VPADDING cell MAY have any content.  Upon
&gt;   receiving a VPADDING cell, the recipient should drop it, as with a
&gt;   PADDING cell.

Also sounds fine. But to clarify, did you mean to talk about a DROP cell
in one of those sentences? I think you meant to say VPADDING there?

Also to be clear, there's no way to send a variable-length padding
cell that's less than 5 bytes, right? I don't imagine that will bite us
immediately, but we should call it out as a known constraint.

By "the body of a vpadding cell may have any content", did you have in
mind to randomize it to help protect against future TLS gotchas? Or just
to leave us the option to do so in the future?

&gt; Interaction with proposal 176:
&gt; 
&gt;   Proposal 176 says that during the v3 handshake, no cells other
&gt;   than VERSIONS, AUTHENTICATE, AUTH_CHALLENGE, CERT, and NETINFO are
&gt;   allowed, and those are only allowed in their standard order.  If
&gt;   this proposal is accepted, then VPADDING cells should also be
&gt;   allowed in the handshake at any point after the VERSIONS cell.
&gt;   They should be included when computing the "SLOG" and "CLOG"
&gt;   handshake-digest fields of the AUTHENTICATE cell.

Ok.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110922074339</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-22 07:43:39-0400</timestampReceived><subject>Re: [tor-dev] Proposal 186: Multiple addresses for one OR or bridge</subject><body>

Hi Nick,

a few comments to proposal 186 below:

On 9/21/11 8:13 PM, Nick Mathewson wrote:
&gt;   In consonance with our changes to the (Socks|Trans|NATD|DNS)Port
&gt;   options made in 0.2.3.x for proposal 171, I make a corresponding
&gt;   change to allow multiple SocksPort options and deprecate
&gt;   SocksListenAddress.

When you say "Socks" in this document in most cases you mean "OR".

&gt;   The new syntax will be:
&gt; 
&gt;       "SocksPort" PortDescription Options?

The syntax allows multiple options per SocksPort line, right?  Would
that be "Options*" then?

&gt;   The 'NoListen' option tells Tor to advertise an address, but not
&gt;   bind to it.  The operator needs to use some other mechanism to
&gt;   ensure that ports are redirected to ports that _are_ listened on.

Do we need to check that we have at least one SocksPort line without the
NoListen option?

&gt;   In current operating systems (unless we get into crazy nonportable
&gt;   tricks) we need to use one socket for every address:port that Tor
&gt;   bind on.  As a sanity check, we can limit the number of such
&gt;   sockets we use to, say, 64.  If you want to bind lots more
&gt;   address:port combinations, you'll want to do it at the
&gt;   firewall/routing level.

64 seems very high for the number sockets to open.  If someone wants to
open more than 8 sockets and doesn't know how to edit firewall rules,
that person probably shouldn't be opening this number of sockets.

&gt;   Example: Our firewall is redirecting ports 80, 443, and 7000-8000
&gt;   on all hosts in x.244.2.0/24 onto our port 2929.
&gt; 
&gt;      SocksPort 2929 no-advertise
&gt;      SocksPort x.244.2.0/24:80,443,7000-8000 no-listen

"no-advertise" -&gt; "noadvertise"

"no-listen" -&gt; "nolisten"

The "/24" should probably also go away.

&gt;   Example: We have a dynamic DNS provider that maps
&gt;   tornode.example.com to our current external IPv4 and IPv6
&gt;   addresses.  Our firewall forwards port 443 on those address to our
&gt;   port 1337.
&gt; 
&gt;      SocksPort 1337 no-advertise alladdrs
&gt;      SocksPort tornode.example.com:443 no-bind alladdrs

"no-advertise" -&gt; "noadvertise"

"no-bind" -&gt; "nolisten"

I wonder what the effect of putting in a dynamic hostname is.  Tor uses
an IP address in the server descriptor anyway, and wouldn't it find out
the IP address(es) by itself?

&gt;   It will now be possible for a Tor node to find that some addresses
&gt;   work and others do not.  In this case, the node should only
&gt;   advertise socksport lines that have been checked.

What if a partial SocksPort line was found to work, that is, if only a
few ports work?

&gt;   A node must not list more than 8 or-address lines.

Should there also be a restriction of PORTSPECs per line?  I can imagine
how these lines can get quite long: 1.2.3.4:1-2,4-5,7-8,...

Rest looks good!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110916201558</emailId><senderName>Steven Murdoch</senderName><senderEmail>steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-09-16 20:15:58-0400</timestampReceived><subject>Re: [tor-dev] Building an automatic censorship-detection system for</subject><body>

Hi Karsten,

On 14 Sep 2011, at 07:17, Karsten Loesing wrote:
&gt; However, as one can see, George's script also detects quite a few false
&gt; positives.  Whenever there's a red or blue dot, the script would have
&gt; issued a warning for a human to check.  It would be neat to reduce these
&gt; false warnings while still catching the really suspicious events.
&gt; 
&gt; Want to help us make our censorship-detection system better?  Any
&gt; suggestion to improve George's algorithm or to come up with an
&gt; alternative approach to detect possible censorship events in our data
&gt; would be much appreciated!  Let us know if we can help you get started.

Well the easiest thing to do would be to change the parameter which decides whether \
to send an alert out. According to the paper: "We consider that a ratio of \
connections is typical if it falls within the 99.99 % percentile of the Normal \
distribution N(m, v) modelling ratios." Maybe 99.995% or 99.999% would be better?

Can we look at the alerts and categorise them into ones which were not censorship \
events (false positives) and ones which were events that we would like to be alerted \
about (true positives). Also look for any censorship events which were missed (false \
negatives). Then for each event, see how much the ratio of connections diverges from \
that predicted by the model. If the divergence is larger for true positives than it \
is for false positives, and there are few false negatives, then the model can be left \
unchanged, but the alert-criteria needs to be lifted. If the divergence for each of \
the categories are tightly clustered then the model would have to be changed.

But do remember this is a very challenging problem. The vast majority of the time a \
censorship event has not happened. This means that even if we have an extremely \
accurate detector, we will still get quite a few false positives (perhaps more than \
we do true positives). For the reason, see \
http://en.wikipedia.org/wiki/Base_rate_fallacy. It might be that we will have to \
filter out the false negatives manually by asking people in country.

Steven.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110902124636</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-02 12:46:36-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

Hi Andrew,

On 9/2/11 2:18 AM, Andrew Lewman wrote:
&gt; On Thursday, August 25, 2011 04:08:00 Karsten Loesing wrote:
&gt;&gt; we have been discussing sanitizing and publishing our web server logs
&gt;&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt;&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt;&gt; website, and analyze them for top visited pages, top downloaded
&gt;&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt; 
&gt; My concern is that we have the data at all.  We shouldn't have any
&gt; sensitive information logged on the webservers. Therefore sanitizing the
&gt; logs should not be necessary.

My concern is that we remove details from the logs and learn in a few
months that we wanted to analyze them.  I'd like to sanitize the
existing logs first, make them available for people to analyze, and only
change the Apache configuration once we're really sure we found the
level of detail that we want.  There's no rush in changing the Apache
configuration now, right?

&gt; I would like to replace the current
&gt; 0.0.0.0/0.0.0.1 scheme with a geoip lookup and just log the country code
&gt; in place of the IP address. Apache can do this on the fly between
&gt; request and the log entry.

Runa and I discussed one major drawback of this approach: even though
there are no timestamps in the logs, the order of requests can reveal a
lot about user sessions.  Now, if we put in country codes, it's quite
easy to track single user sessions.  Even sorting logs before publishing
them may not help, because there may only be a handful users from a
given country.

If we want country codes in the logs, we'll have to define a threshold
and change all requests from countries with fewer requests to some "less
than XY users" country code.  Also, we'll absolutely have to
reorder/sort requests per day.

Finally, we'll have to find a way to encode the country code in the logs
and still keep Apache's Combined Log Format.  And do we still care about
the HTTP vs. HTTPS bit?  Because if we use the IP column for the country
code, we'll have to encode the HTTP/HTTPS thing somewhere else.

So, it should be possible to implement GeoIP lookups in the future.  I'd
like to consider that a separate task from sanitizing the existing web
logs, though.

&gt;&gt; Is there still anything sensitive in that log file that we should
&gt;&gt; remove?  For example:
&gt; 
&gt; Referrers and requested urls will be a nightmare to clean up. We
&gt; literally get thousands of probes a day per site trying to exploit
&gt; apache (or tomcat, or cgi, or a million other things). If we were the US
&gt; military, we'd claim each probe is a hostile attack and whine about
&gt; millions of attacks on our infrastructure a year. Clearly this is
&gt; cyberwar and we need $3 billion to stop it or retaliate.
&gt; 
&gt; On the other hand, seeing the referrer data has been interesting because
&gt; it tells us where our traffic originates. Our top referrers are google
&gt; and the wikipedia pages about tor in various languages. The search terms
&gt; are also valuable if we want to buy keywords for ads some day. We've had
&gt; two volunteers do this already through google adwords and the results
&gt; are surprising.

I understand that removing referrers and changing URLs (removing them
for 4xx status codes, cutting off GET parameters, etc.) makes the logs
less useful.  Maybe there are ways to keep at least the top referrers in
the sanitized logs.  (I don't think this is something we can leave to
Apache, so we'll have to post-process logs for that.)

But how about we start without GET parameters and referrers and see how
useful those logs are for analysis?  We can still add more detail later on.

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110902130657</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-09-02 13:06:57-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>


On Sep 2, 2011, at 2:46 PM, Karsten Loesing wrote:

&gt; Hi Andrew,
&gt; 
&gt; On 9/2/11 2:18 AM, Andrew Lewman wrote:
&gt;&gt; On Thursday, August 25, 2011 04:08:00 Karsten Loesing wrote:
&gt;&gt;&gt; we have been discussing sanitizing and publishing our web server logs
&gt;&gt;&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt;&gt;&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt;&gt;&gt; website, and analyze them for top visited pages, top downloaded
&gt;&gt;&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt;&gt; 
&gt;&gt; My concern is that we have the data at all.  We shouldn't have any
&gt;&gt; sensitive information logged on the webservers. Therefore sanitizing the
&gt;&gt; logs should not be necessary.
&gt; 
&gt; My concern is that we remove details from the logs and learn in a few
&gt; months that we wanted to analyze them.  I'd like to sanitize the
&gt; existing logs first, make them available for people to analyze, and only
&gt; change the Apache configuration once we're really sure we found the
&gt; level of detail that we want.  There's no rush in changing the Apache
&gt; configuration now, right?

So, if we decide in a few months that we need more detail, we can
change the logging then. Sure, we won't have history, but that just
means that the graphs we make start in 2012 instead of 2007.

&gt; Finally, we'll have to find a way to encode the country code in the logs
&gt; and still keep Apache's Combined Log Format.  And do we still care about
&gt; the HTTP vs. HTTPS bit?  Because if we use the IP column for the country
&gt; code, we'll have to encode the HTTP/HTTPS thing somewhere else.

IP addresses have plenty of bits for a country code and http/https
encoding, we could for example use the first bytes for country code.

&gt; So, it should be possible to implement GeoIP lookups in the future.  I'd
&gt; like to consider that a separate task from sanitizing the existing web
&gt; logs, though.

It's separate, but without the on-the-fly geoip lookups we won't have
any, because the sanitizing process doesn't get them magically.

All the best
Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110902140837</emailId><senderName>Brian Szymanski</senderName><senderEmail>ski@allafrica.com</senderEmail><timestampReceived>2011-09-02 14:08:37-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

What exactly are we hoping to gain from the analysis of the (hopefully 
correctly) stripped logs?

On 09/02/2011 09:06 AM, Sebastian Hahn wrote:
&gt; On Sep 2, 2011, at 2:46 PM, Karsten Loesing wrote:
&gt;
&gt;&gt; Hi Andrew,
&gt;&gt;
&gt;&gt; On 9/2/11 2:18 AM, Andrew Lewman wrote:
&gt;&gt;&gt; On Thursday, August 25, 2011 04:08:00 Karsten Loesing wrote:
&gt;&gt;&gt;&gt; we have been discussing sanitizing and publishing our web server logs
&gt;&gt;&gt;&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt;&gt;&gt;&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt;&gt;&gt;&gt; website, and analyze them for top visited pages, top downloaded
&gt;&gt;&gt;&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt;&gt;&gt; My concern is that we have the data at all.  We shouldn't have any
&gt;&gt;&gt; sensitive information logged on the webservers. Therefore sanitizing the
&gt;&gt;&gt; logs should not be necessary.
&gt;&gt; My concern is that we remove details from the logs and learn in a few
&gt;&gt; months that we wanted to analyze them.  I'd like to sanitize the
&gt;&gt; existing logs first, make them available for people to analyze, and only
&gt;&gt; change the Apache configuration once we're really sure we found the
&gt;&gt; level of detail that we want.  There's no rush in changing the Apache
&gt;&gt; configuration now, right?
&gt; So, if we decide in a few months that we need more detail, we can
&gt; change the logging then. Sure, we won't have history, but that just
&gt; means that the graphs we make start in 2012 instead of 2007.
&gt;
&gt;&gt; Finally, we'll have to find a way to encode the country code in the logs
&gt;&gt; and still keep Apache's Combined Log Format.  And do we still care about
&gt;&gt; the HTTP vs. HTTPS bit?  Because if we use the IP column for the country
&gt;&gt; code, we'll have to encode the HTTP/HTTPS thing somewhere else.
&gt; IP addresses have plenty of bits for a country code and http/https
&gt; encoding, we could for example use the first bytes for country code.
&gt;
&gt;&gt; So, it should be possible to implement GeoIP lookups in the future.  I'd
&gt;&gt; like to consider that a separate task from sanitizing the existing web
&gt;&gt; logs, though.
&gt; It's separate, but without the on-the-fly geoip lookups we won't have
&gt; any, because the sanitizing process doesn't get them magically.
&gt;
&gt; All the best
&gt; Sebastian
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110902173253</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-09-02 17:32:53-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On 08/25/2011 03:08 AM, Karsten Loesing wrote:
&gt; Hi everyone,
&gt;
&gt; we have been discussing sanitizing and publishing our web server logs
&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt; website, and analyze them for top visited pages, top downloaded
&gt; packages, etc.  See the tickets #1641 and #2489 for details.

Why?

I.e., what are the great benefits hoped to arise from such publication 
to outweigh the considerable risks?

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110905075142</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-05 07:51:42-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On 9/2/11 3:06 PM, Sebastian Hahn wrote:
&gt; 
&gt; On Sep 2, 2011, at 2:46 PM, Karsten Loesing wrote:
&gt; 
&gt;&gt; Hi Andrew,
&gt;&gt;
&gt;&gt; On 9/2/11 2:18 AM, Andrew Lewman wrote:
&gt;&gt;&gt; On Thursday, August 25, 2011 04:08:00 Karsten Loesing wrote:
&gt;&gt;&gt;&gt; we have been discussing sanitizing and publishing our web server logs
&gt;&gt;&gt;&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt;&gt;&gt;&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt;&gt;&gt;&gt; website, and analyze them for top visited pages, top downloaded
&gt;&gt;&gt;&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt;&gt;&gt;
&gt;&gt;&gt; My concern is that we have the data at all.  We shouldn't have any
&gt;&gt;&gt; sensitive information logged on the webservers. Therefore sanitizing the
&gt;&gt;&gt; logs should not be necessary.
&gt;&gt;
&gt;&gt; My concern is that we remove details from the logs and learn in a few
&gt;&gt; months that we wanted to analyze them.  I'd like to sanitize the
&gt;&gt; existing logs first, make them available for people to analyze, and only
&gt;&gt; change the Apache configuration once we're really sure we found the
&gt;&gt; level of detail that we want.  There's no rush in changing the Apache
&gt;&gt; configuration now, right?
&gt; 
&gt; So, if we decide in a few months that we need more detail, we can
&gt; change the logging then. Sure, we won't have history, but that just
&gt; means that the graphs we make start in 2012 instead of 2007.

You're right.  Once we change the logging we'll only have graphs from
then on.  But there's no immediate need to change the logging now.  We
can still do that in a few months from now when we have more experience
with the sanitizing process (which we need anyway, if only for
reordering requests) and subsequent analysis.

&gt;&gt; Finally, we'll have to find a way to encode the country code in the logs
&gt;&gt; and still keep Apache's Combined Log Format.  And do we still care about
&gt;&gt; the HTTP vs. HTTPS bit?  Because if we use the IP column for the country
&gt;&gt; code, we'll have to encode the HTTP/HTTPS thing somewhere else.
&gt; 
&gt; IP addresses have plenty of bits for a country code and http/https
&gt; encoding, we could for example use the first bytes for country code.

Sounds like a hack to me (not that I'm too opposed to it).  How do other
people encode country codes in Apache logs?

&gt;&gt; So, it should be possible to implement GeoIP lookups in the future.  I'd
&gt;&gt; like to consider that a separate task from sanitizing the existing web
&gt;&gt; logs, though.
&gt; 
&gt; It's separate, but without the on-the-fly geoip lookups we won't have
&gt; any, because the sanitizing process doesn't get them magically.

Right.  I'm just trying to keep the scope of this first discussion round
small to speed things up.  This is something to revisit in a few months
from now.

Thanks for your comments!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110905082835</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-05 08:28:35-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On 9/2/11 7:32 PM, Marsh Ray wrote:
&gt; On 08/25/2011 03:08 AM, Karsten Loesing wrote:
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; we have been discussing sanitizing and publishing our web server logs
&gt;&gt; for quite a while now.  The idea is to remove all potentially sensitive
&gt;&gt; parts from the logs, publish them in monthly tarballs on the metrics
&gt;&gt; website, and analyze them for top visited pages, top downloaded
&gt;&gt; packages, etc.  See the tickets #1641 and #2489 for details.
&gt; 
&gt; Why?
&gt; 
&gt; I.e., what are the great benefits hoped to arise from such publication
&gt; to outweigh the considerable risks?

The benefits are, e.g., that we learn more about our website visitors
and can make our websites more useful for them.  And we can learn which
packages users download, including their platforms, languages, etc.
which may help us concentrate our efforts better.  These are just two
examples, but I think we agree that analyzing web logs does provide a
benefit.

Our general approach with analyzing potentially sensitive data is to
openly discuss the algorithm to remove any sensitive parts, make the
resulting data publicly available, and only analyze those.  Ideally, we
don't want to collect the sensitive parts at all, but sometimes that's
not feasible (IP addresses in bridge descriptors, request order in web
server logs), so we need to post-process the data before publication.

I think the overall risk of our approach is considerably lower than
trying to keep the data you're planning to analyze private, because
there's always the risk of losing data.

See this paper and website for a better answer:

  https://metrics.torproject.org/papers/wecsr10.pdf

  https://metrics.torproject.org/formats.html


What are the considerable risks you're referring to?

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111201114641</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-12-01 11:46:41-0400</timestampReceived><subject>Re: [tor-dev] Sanitizing and publishing our web server logs</subject><body>

On Tue, Oct 18, 2011 at 8:27 AM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
&gt; The webalizer output for www.torproject.org can be viewed here:
&gt;
&gt; http://freehaven.net/~karsten/volatile/www.torproject.org-webalizer/

I have looked into four different web log analysis tools, see
https://trac.torproject.org/projects/tor/ticket/4463#comment:4 for
details.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110923014130</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-09-23 01:41:30-0400</timestampReceived><subject>Re: [tor-dev] Proposal 184: Miscellaneous changes for a v3 Tor link</subject><body>

On Thu, Sep 22, 2011 at 7:55 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Tue, Sep 20, 2011 at 03:33:42PM -0400, Nick Mathewson wrote:
&gt;&gt; Design: Indicating variable-length cells.
&gt;&gt;
&gt;&gt;   Beginning with the v3 link protocol, we specify that all cell
&gt;&gt;   types in the range 128..255 indicate variable-length cells.
&gt;&gt;   Cell types in the range 0..127 are still used for 512-byte
&gt;&gt;   cells, except that the VERSIONS cell type (7) also indicates a
&gt;&gt;   variable-length cell (for backward compatibility).
&gt;&gt;
&gt;&gt;   As before, all Tor instances must ignore cells with types that
&gt;&gt;   they don't recognize.
&gt;
&gt; Sounds good.
&gt;
&gt;&gt; Design: Variable-length padding.
&gt;&gt;
&gt;&gt;   We add a new variable-length cell type, "VPADDING", to be used for
&gt;&gt;   padding.  All Tor instances may send a DROP cell at any point that
&gt;&gt;   a VERSIONS cell is not required; a VPADDING cell's body may be any
&gt;&gt;   length; the body of a VPADDING cell MAY have any content.  Upon
&gt;&gt;   receiving a VPADDING cell, the recipient should drop it, as with a
&gt;&gt;   PADDING cell.
&gt;
&gt; Also sounds fine. But to clarify, did you mean to talk about a DROP cell
&gt; in one of those sentences? I think you meant to say VPADDING there?

Yup; will fix.

&gt; Also to be clear, there's no way to send a variable-length padding
&gt; cell that's less than 5 bytes, right? I don't imagine that will bite us
&gt; immediately, but we should call it out as a known constraint.

Correct. I'll add a note.

&gt; By "the body of a vpadding cell may have any content", did you have in
&gt; mind to randomize it to help protect against future TLS gotchas? Or just
&gt; to leave us the option to do so in the future?

Both, but I think "randomize it now" is the answer.  I'll add a note.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110923065139</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-09-23 06:51:39-0400</timestampReceived><subject>Re: [tor-dev] Proposal 185: Directory caches without DirPort</subject><body>

Looks like we lost tor-dev somewhere.  Quoting Nick's reply without
cutting out stuff I have no comments to.


On 9/22/11 10:16 PM, Nick Mathewson wrote:
&gt; On Thu, Sep 22, 2011 at 4:49 AM, Karsten Loesing
&gt; &lt;karsten.loesing@gmx.net&gt; wrote:
&gt;&gt; Hi Nick,
&gt;&gt;
&gt;&gt; and here are a few comments to your proposal 185:
&gt;&gt;
&gt;&gt; On 9/20/11 9:34 PM, Nick Mathewson wrote:
&gt;&gt;&gt; Configuration:
&gt;&gt;&gt;
&gt;&gt;&gt;   Add a new torrc option, "DirCache".  Its values can be "0", "1",
&gt;&gt;&gt;   and "auto".  If it is 0, we never act as a directory cache, even
&gt;&gt;&gt;   if DirPort is set.
&gt;&gt;
&gt;&gt; Do these relays set "dir-cache 0" in their router descriptors?  Or do
&gt;&gt; they just not include "dir-cache 1"?
&gt; 
&gt; They just do not include "dir-cache 1".  I'll make this more explicit.
&gt; 
&gt;&gt; But if they set a non-zero
&gt;&gt; DirPort, how will the directory authorities and clients know that the
&gt;&gt; node doesn't want to act as a directory cache?
&gt; 
&gt; If you don't want to act as a directory cache, you don't publish DirPort.
&gt; 
&gt; "dir-cache 0" wouldn't work to disable a dirport published in your
&gt; "router" line, since old Tors wouldn't recognize the dir-cache option,
&gt; and so wouldn't know that they weren't supposed to use DirPort.
&gt; 
&gt;&gt;
&gt;&gt;&gt;  If it is 1, then we act as a directory cache
&gt;&gt;&gt;   according to same rules as those used for nodes that set a
&gt;&gt;&gt;   DirPort.  If it is "auto", then Tor decides whether to act as a
&gt;&gt;&gt;   directory cache.
&gt;&gt;
&gt;&gt; What are the rules when setting a DirPort?  Successful self-test and
&gt;&gt; minimum advertised bandwidth?
&gt; 
&gt; I believe so, except of course you don't need to have a reachable
&gt; DirPort in this case.
&gt; 
&gt;&gt; How's "1" different from "auto" if Tor
&gt;&gt; decides whether to act as a directory cache in both cases?
&gt; 
&gt; "1" is "I want to be a directory cache"; "auto" is "use me as a
&gt; directory cache if that would help".  I think that auto might be in
&gt; the future be more adaptive, depending on the state of the network and
&gt; the number of directory caches.
&gt; 
&gt; I would like "DirCache auto" to be something we're comfortable making
&gt; the new default.
&gt; 
&gt;&gt;&gt; Consensus:
&gt;&gt;&gt;
&gt;&gt;&gt;   Authorities should assign a "DirCache" flag to all nodes running
&gt;&gt;&gt;   as a directory cache that do not set a DirPort.
&gt;&gt;
&gt;&gt; Would it make sense to have them assign the "DirCache" flag for nodes
&gt;&gt; with a non-zero DirPort, too?
&gt; 
&gt; IMO that would just use up space.  Is there an argument in favor?

Yup, I agree with you that it uses up space.

My thinking was that clients wouldn't have to check two things (non-zero
Dir port or DirCache flag) to learn whether a relay has directory info
for them, but just one thing.  And it could lead to some confusion when
people try to understand dir-spec.txt or the TorStatus output (once it
displays this flag).  Not very strong arguments though.

I also wasn't certain if the proposal was wrong here and you really
meant that the flag would be assigned to all directory caches.  If the
proposal says what you meant, carry on. :)

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110924082007</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-09-24 08:20:07-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Sun, 2011-04-24 at 19:36 -0400, andrew@torproject.org wrote:

&gt; Torouter based on openwrt is an experiment.  It seems it's going to
cost
&gt; us more time, effort, and people than we have to spare.  The entire
&gt; torouter, or bridge/relay-by-default in hardware, is an experiment.  
&gt; 
&gt; I'd much rather see a debian-based torouter exist.  We can more easily
&gt; integrate debian packages of the necessary architecture, likely ARM,
&gt; into our build farm than we can an entirely new OS and build
&gt; environment. 

I recently came across:

http://www.debwrt.net/

DebWrt is all about running Debian GNU/Linux on embedded devices, for
example wireless routers. DebWrt connects two very powerful
technologies: Debian and OpenWrt.

http://dev.debwrt.net/wiki/TableOfSupportedHardware

Cheers,
Rob van der Hoeven.

http://freedomboxblog.nl



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110924085316</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-09-24 08:53:16-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

[Attachment #2 (multipart/signed)]


Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

&gt; Anyway, here's the client-side sibling proposal to the
&gt; already-implemented 174.  It cuts down time-to-first-byte for HTTP
&gt; requests by 25 to 50 percent, so long as your SOCKS client (e.g.
&gt; webfetch, polipo, etc.) is patched to support it.  (With that kind of
&gt; speedup, I think it's worth it.)

After patching my client to support this (for most requests)
I'd be interested to know how much this actually improves things
in the real world.

Does anyone already have a script that reads a Tor log file
and generates statistics that answer this question?

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110926134230</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-09-26 13:42:30-0400</timestampReceived><subject>Re: [tor-dev] MITM for TOR</subject><body>

&gt; MITM can be used at both the entry as the exit node of the Tor network.

MITM has it's own internal webserver for reports. If used at an exit
node this server can send you a report "from the other side". Scary.....

Rob vander Hoeven
http://freedomboxblog.nl


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110927143614</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-09-27 14:36:14-0400</timestampReceived><subject>Re: [tor-dev] Proposal 176: Proposed version-3 link handshake for</subject><body>

On Wed, Sep 21, 2011 at 1:58 PM, Nick Mathewson &lt;nickm@alum.mit.edu&gt; wrote:

I'm thinking of a few more tweaks to this proposal, based on implementation.

Here's one:

&gt; I think on reflection that we should change the TLSSECRETS field from
&gt; optional to required in all AUTHENTICATE cells.  Only relays need to
&gt; send it, after all.

Doing this makes us more secure, at the expense of making it a little
harder for now to write a relay using an inflexible TLS library that
you can't change.

Another change: Previously I had said that every server (including
relays and bridges) should send an AUTH_CHALLENGE cell to say "I'd
like authentication".  In fact, that should only apply to relays:
There is never a point in authenticating to a bridge, right?
Similarly, bridges should only authenticate to their clients, not to
the relays that they're extending to.

So here, I think, are the  right behaviors for the possible
interactions in the v3 protocol now:
  Client connects to bridge:
    C-&gt;B: VERSIONS
    B-&gt;C: VERSIONS, CERT, NETINFO
    C-&gt;B: NETINFO
  Client or bridge connects to relay:
    C-&gt;R: VERSIONS
    R-&gt;C: VERSIONS, CERT, AUTH_CHALLENGE, NETINFO
    C-&gt;R: NETINFO
  Relay connects to relay:
    R1-&gt;R2: VERSIONS
    R2-&gt;R1: VERSIONS, CERT, AUTH_CHALLENGE, NETINFO
    R1-&gt;R2: CERT, AUTHENTICATE, NETINFO

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110927232020</emailId><senderName>Rob Jansen</senderName><senderEmail>rob.g.jansen@nrl.navy.mil</senderEmail><timestampReceived>2011-09-27 23:20:20-0400</timestampReceived><subject>[tor-dev] Running Real Tor Code Over Simulated Networks</subject><body>

Hello,

For the unaware, we have been working on the design and development of 
Shadow, a simulator capable of running real binaries over a simulated 
network, and a plug-in that runs real Tor. Shadow can simulate roughly 
1000 Tor nodes in 10 GB of RAM and is easy to setup and use (no root 
required). You can generate realistic Tor topologies using a consensus, 
and test changes implemented in Tor extremely quickly.

Earlier this year, I had an idea for a new algorithm on Sunday, thought 
about how it might work and discussed it with Nick [Hopper - my adviser] 
on Monday, implemented it in Tor and tested it on Tuesday and Wednesday, 
started running experiments and had results by Friday.

Honestly. That fast.

If you have the need to run Tor experiments, or are just interested in 
the Software, please try it out. We would love any feedback or comments 
or suggestions if you have them!

We are continuously working on improving the simulator, including more 
efficient use of multiple CPU cores and a command-line interface to help 
with installing Shadow and some of its dependencies. (Because really, 
who wants to install dependencies?)

More details on Shadow's design can be found in our technical report:
http://www-users.cs.umn.edu/~jansen/papers/shadow-umntr11-020.pdf

A release version that is somewhat stable is available on the Shadow 
webpage:
http://shadow.cs.umn.edu/

Our code is public at
https://github.com/shadow

Best regards,
Rob

--
Rob G. Jansen
U.S. Naval Research Laboratory
rob.g.jansen@nrl.navy.mil
202.767.2389
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110927234133</emailId><senderName>Rob Jansen</senderName><senderEmail>rob.g.jansen@nrl.navy.mil</senderEmail><timestampReceived>2011-09-27 23:41:33-0400</timestampReceived><subject>[tor-dev] Dynamic Throttling in Tor</subject><body>

Hello,

We've been exploring dynamic algorithms for throttling Tor clients. 
We've come up with three algorithms that are easier to maintain than 
static throttling (i.e. don't need to be reconfigured often), and 
produce significant performance benefits for web clients at the expense 
of bulk clients. Details are available in our technical report:

http://www-users.cs.umn.edu/~jansen/papers/throttling-umntr11-019.pdf

We are looking for feedback and are wondering if these algorithms look 
useful to Tor. They have already been implemented, and patches can be 
prepared if there is interest.

Best regards,
Rob

--
Rob G. Jansen
U.S. Naval Research Laboratory
rob.g.jansen@nrl.navy.mil
202.767.2389
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110928212253</emailId><senderName>Tim Wilde</senderName><senderEmail>twilde@cymru.com</senderEmail><timestampReceived>2011-09-28 21:22:53-0400</timestampReceived><subject>[tor-dev] Proposed addition to Proposal 179</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey All,

In some recent research we came across another easily-fingerprintable
attribute of the Tor TLS handshake, so I would like to propose this
addition to Proposal 179:

https://github.com/twilde/torspec/commit/c202230b40c72cbdbe43bbda9cc1a7caad35e78c

Or, if in my git-newb-ish-ways I represent this correctly:

git://github.com/twilde/torspec.git@c202230b40

Short summary: we should send an SSL Session ID, even if we don't
track it or ever use it (which I wouldn't suggest we do) because not
sending one makes us stick out like a sore thumb. :)

Apologies if my git-newb-ish-nes makes this more difficult to grab,
pointers welcome (I may be a git newb but I'm totally in love with it,
mmm, sexy VCS :)).

Thanks,
Tim

- -- 
Tim Wilde, Senior Software Engineer, Team Cymru, Inc.
twilde@cymru.com | +1-847-378-3333 | http://www.team-cymru.org/
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAk6DkC0ACgkQluRbRini9tgfGACeKF41vKvoOvGFEHq5JXU9/u38
RWsAn1mb6MX0gvut6/ROYl0Kg6NQoF/e
=2PWa
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110929182312</emailId><senderName>Mohammad Mo</senderName><senderEmail>mohammad_20101389@yahoo.com</senderEmail><timestampReceived>2011-09-29 18:23:12-0400</timestampReceived><subject>[tor-dev] =?utf-8?b?2LPZhNin2YUg2KjYsdmG2KfZhdmHINiq2YjYsSDZgdin?=</subject><body>

[Attachment #2 (multipart/alternative)]


        \
      

mohammad_20101389@yahoo.com


[Attachment #5 (text/html)]

&lt;html&gt;&lt;body&gt;&lt;div style="color:#000; background-color:#fff; font-family:tahoma, new \
york, times, serif;font-size:12pt"&gt;&lt;div&gt;    \
         \
 &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;mohammad_20101389@yahoo.com&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110930153028</emailId><senderName>Arturo_Filast</senderName><senderEmail>art@baculo.org</senderEmail><timestampReceived>2011-09-30 15:30:28-0400</timestampReceived><subject>Re: [tor-dev] Future direction for torperf</subject><body>

I have some requirements for torperf. I would like it to be able to give
me some useful data about tor2web improvements.

We have made a list of the things we think we are interesting in taking
note of: https://github.com/globaleaks/tor2web-2.0/issues/2.

- Art.

On 9/29/11 9:16 PM, Thomas S. Benjamin wrote:
&gt; Dear all,
&gt; 
&gt; I am working on a re-design of torperf that will use a central python
&gt; script to automate initiation and control of torperf experiments.
&gt; 
&gt; I have a very rough draft that provides the most basic level of
&gt; functionality in tomb/torperf.git branch 3280, and have ticket #3280
&gt; as wanting review.
&gt; 
&gt; The code needs substantial improvement, but I would love feedback on
&gt; my general approach before I spend a lot of time on grooming this
&gt; specific version.
&gt; 
&gt; If you use torperf please consider giving me feedback on the direction
&gt; in which I am heading with this.  I want to make sure that I am
&gt; designing something that will work for other people, rather than just
&gt; for my own experiments.
&gt; 
&gt; I have chosen not to merge into a branch of torperf.git because my
&gt; working style involves lots of frequent verbose commits, which would
&gt; be distracting for most people.  I will roll together the many commits
&gt; before merging into torperf.git
&gt; 

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110930191928</emailId><senderName>Mohammad Mo</senderName><senderEmail>mohammad_20101389@yahoo.com</senderEmail><timestampReceived>2011-09-30 19:19:28-0400</timestampReceived><subject>Re: [tor-dev]</subject><body>

[Attachment #2 (multipart/alternative)]







________________________________



        \
      

mohammad_20101389@yahoo.com


[Attachment #5 (text/html)]

&lt;html&gt;&lt;body&gt;&lt;div style="color:#000; background-color:#fff; font-family:tahoma, new \
york, times, serif;font-size:12pt"&gt;&lt;div id="yiv214857808"&gt;&lt;div&gt;&lt;div \
style="color:#000;background-color:#fff;font-family:tahoma, new york, times, \
serif;font-size:12pt;"&gt;&lt;div&gt;&lt;span id="yiv214857808yui_3_2_0_16_1310200745626103"&gt;&lt;br \
id="yiv214857808yui_3_2_0_16_1310200745626104"&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
style="font-family:tahoma, new york, times, serif;font-size:12pt;"&gt;&lt;div \
style="font-family:times new roman, new york, times, serif;font-size:12pt;"&gt;&lt;font \
face="Arial" size="2"&gt;&lt;hr size="1"&gt;&lt;b&gt;&lt;span \
style="font-weight:bold;"&gt;&lt;/span&gt;&lt;/b&gt;&lt;b&gt;&lt;span \
style="font-weight:bold;"&gt;&lt;/span&gt;&lt;/b&gt;&lt;br&gt;&lt;/font&gt;&lt;br&gt; &lt;div \
id="yiv214857808"&gt;&lt;div&gt;&lt;div \
style="color:#000;background-color:#fff;font-family:tahoma, new york, times, \
serif;font-size:12pt;"&gt;&lt;div&gt;     \
         \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;mohammad_20101389@yahoo.com&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110930194843</emailId><senderName>Mohammad Mo</senderName><senderEmail>mohammad_20101389@yahoo.com</senderEmail><timestampReceived>2011-09-30 19:48:43-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/alternative)]



[Attachment #5 (text/html)]

&lt;html&gt;&lt;body&gt;&lt;div style="color:#000; background-color:#fff; font-family:tahoma, new \
york, times, serif;font-size:12pt"&gt;&lt;div id="yiv817761026"&gt;&lt;div&gt;&lt;div \
style="color:#000;background-color:#fff;font-family:tahoma, new york, times, \
serif;font-size:12pt;"&gt;&lt;div \
id="yiv817761026yui_3_2_0_18_131014712364840"&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110801154546</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-08-01 15:45:46-0400</timestampReceived><subject>Re: [tor-dev] [Patch] or/networkstatus.c</subject><body>

"Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:

&gt; On Sun, Jul 31, 2011 at 7:10 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt;&gt; Hi list.
&gt;&gt;
&gt;&gt; In or/networkstatus.c there is a "#if 0" block inside the macro
&gt;&gt; "SMARTLIST_FOREACH_JOIN". Not all compilers handle such contructs.
&gt;&gt; In the prosess of making solution/projects file for "MS Visual C++ 2010
&gt;&gt; Express",
&gt;&gt; I hit this problem (cl Version 16.00.30319.01). Can you please accept the
&gt;&gt; following patch:
&gt; 
&gt; The code is if-0'd out; I say we should just remove it in 0.2.3.

That would be just fine.

--gv

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110802114601</emailId><senderName>"Zaher F."</senderName><senderEmail>the_one_man_85@hotmail.com</senderEmail><timestampReceived>2011-08-02 11:46:01-0400</timestampReceived><subject>Re: [tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

[Attachment #2 (multipart/alternative)]


how i can confirm that all dns traffic are going through tor proxy after running \
tordsn????


thx


Date: Tue, 26 Jul 2011 23:43:41 +0000
From: m8rovpdyd@gmail.com
To: tor-dev@lists.torproject.org
Subject: Re: [tor-dev] Requesting feedback on TorDNSd v1.1

Hello,

+ Currently, when a query fails, it'll use the next configured DNS server and \
reattempt to query on that one.  Nothing special is done at the moment, but I'm open \
for suggestions.

+ A possible issue I see is that retrying a(n invalid) query on all possible domains \
may give a delay since it'll attempt to query all configured dns servers.


+ If I had to add additional DNS servers, I'd add in the OpenDNS servers.

I'd like to add that one of the other nice features of TorDNSd are the filters : An \
internet connection not leaking out any DNS requests could look suspicious, but using \
'filter-direct' rules you could define a couple of 'legal' queries to leak 'on \
purpose'.


- LETO

On Tue, Jul 26, 2011 at 11:16 PM, intrigeri &lt;intrigeri@boum.org&gt; wrote:

Hi,



LETO wrote (26 Jul 2011 22:45:21 GMT) :

&gt; It can use one or multiple remote dns servers (by default the google

&gt; ones) meaning you can perform all queries (not just 'A' ones)



Ok. I see the point of using ttdnsd-like functionality to supplement

what the Tor DNS resolver is able to achieve itself. See our page

about this issue on the Tails wiki in case you want to understand the

place I'm speaking from:



  https://tails.boum.org/todo/support_arbitrary_dns_queries/



I also see the point of not granting one (and maybe a few) company/ies

the power to decide example.com does not exist for TorDNSd (and Tails)

users. Hence my past, present and future questions:



How exactly does TorDNSd deal with multiple remote DNS servers?



What issues could be possibly caused by using multiple remote DNS

recursive servers by default in TorDNSd?



What additional recursive servers would you consider worth adding to

the default TorDNSd configuration?



Bye,

--

  intrigeri &lt;intrigeri@boum.org&gt;

  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc

  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc

  | Did you exchange a walk on part in the war

  | for a lead role in the cage?

_______________________________________________

tor-dev mailing list

tor-dev@lists.torproject.org

https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev 		 	   		  


[Attachment #5 (text/html)]

&lt;html&gt;
&lt;head&gt;
&lt;style&gt;&lt;!--
.hmmessage P
{
margin:0px;
padding:0px
}
body.hmmessage
{
font-size: 10pt;
font-family:Tahoma
}
--&gt;&lt;/style&gt;
&lt;/head&gt;
&lt;body class='hmmessage'&gt;&lt;div dir='ltr'&gt;
how i can confirm that all dns traffic are going through tor proxy after running \
tordsn????&lt;BR&gt;&lt;br&gt;&lt;BR&gt;thx&lt;br&gt;&lt;BR&gt;&lt;br&gt;&lt;div&gt;&lt;hr id="stopSpelling"&gt;Date: Tue, 26 Jul \
2011 23:43:41 +0000&lt;br&gt;From: m8rovpdyd@gmail.com&lt;br&gt;To: \
tor-dev@lists.torproject.org&lt;br&gt;Subject: Re: [tor-dev] Requesting feedback on TorDNSd \
v1.1&lt;br&gt;&lt;br&gt;Hello,&lt;br&gt;&lt;br&gt;+ Currently, when a query fails, it'll use the next \
configured DNS server and reattempt to query on that one.  Nothing special is done at \
the moment, but I'm open for suggestions.&lt;br&gt;&lt;br&gt;+ A possible issue I see is that \
retrying a(n invalid) query on all possible domains may give a delay since it'll \
attempt to query all configured dns servers.&lt;br&gt; &lt;br&gt;+ If I had to add additional DNS \
servers, I'd add in the OpenDNS servers.&lt;br&gt;&lt;br&gt;I'd like to add that one of the other \
nice features of TorDNSd are the filters : An internet connection not leaking out any \
DNS requests could look suspicious, but using 'filter-direct' rules you could define \
a couple of 'legal' queries to leak 'on purpose'.&lt;br&gt; &lt;br&gt;- LETO&lt;br&gt;&lt;br&gt;&lt;div \
class="ecxgmail_quote"&gt;On Tue, Jul 26, 2011 at 11:16 PM, intrigeri &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="ecxgmail_quote" style="padding-left:1ex"&gt; Hi,&lt;br&gt;
&lt;br&gt;
LETO wrote (26 Jul 2011 22:45:21 GMT) :&lt;br&gt;
&lt;div class="ecxim"&gt;&gt; It can use one or multiple remote dns servers (by default the \
google&lt;br&gt; &gt; ones) meaning you can perform all queries (not just 'A' ones)&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Ok. I see the point of using ttdnsd-like functionality to supplement&lt;br&gt;
what the Tor DNS resolver is able to achieve itself. See our page&lt;br&gt;
about this issue on the Tails wiki in case you want to understand the&lt;br&gt;
place I'm speaking from:&lt;br&gt;
&lt;br&gt;
 &lt;a href="https://tails.boum.org/todo/support_arbitrary_dns_queries/" \
target="_blank"&gt;https://tails.boum.org/todo/support_arbitrary_dns_queries/&lt;/a&gt;&lt;br&gt; \
&lt;br&gt; I also see the point of not granting one (and maybe a few) company/ies&lt;br&gt;
the power to decide &lt;a href="http://example.com" target="_blank"&gt;example.com&lt;/a&gt; does \
not exist for TorDNSd (and Tails)&lt;br&gt; users. Hence my past, present and future \
questions:&lt;br&gt; &lt;br&gt;
How exactly does TorDNSd deal with multiple remote DNS servers?&lt;br&gt;
&lt;br&gt;
What issues could be possibly caused by using multiple remote DNS&lt;br&gt;
recursive servers by default in TorDNSd?&lt;br&gt;
&lt;br&gt;
What additional recursive servers would you consider worth adding to&lt;br&gt;
the default TorDNSd configuration?&lt;br&gt;
&lt;div class="ecxim"&gt;&lt;br&gt;
Bye,&lt;br&gt;
--&lt;br&gt;
 intrigeri &lt;&lt;a \
href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;br&gt;  | GnuPG key @ \
&lt;a href="https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc&lt;/a&gt;&lt;br&gt;  \
| OTR fingerprint @ &lt;a \
href="https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc&lt;/a&gt;&lt;br&gt; &lt;/div&gt; \
| Did you exchange a walk on part in the war&lt;br&gt;  | for a lead role in \
the cage?&lt;br&gt; &lt;div&gt;&lt;div \
class="h5"&gt;_______________________________________________&lt;br&gt; tor-dev mailing \
list&lt;br&gt; &lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
 &lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt; \
&lt;br&gt;_______________________________________________ tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/div&gt; 		 	   		  \
&lt;/div&gt;&lt;/body&gt; &lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110805170246</emailId><senderName>"Steve Snyder"</senderName><senderEmail>swsnyder@snydernet.net</senderEmail><timestampReceived>2011-08-05 17:02:46-0400</timestampReceived><subject>[tor-dev] =?utf-8?q?Instructions_for_building_the_Vidalia-bundle?=</subject><body>

Is there documentation anywhere on how to build the Vidalia-bundle for Windows?  If so, where can I find it?

Thanks.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110805211724</emailId><senderName>Brandon Wiley</senderName><senderEmail>brandon@blanu.net</senderEmail><timestampReceived>2011-08-05 21:17:24-0400</timestampReceived><subject>[tor-dev] GSoC Update</subject><body>

[Attachment #2 (multipart/alternative)]


With the TorDev meetup and everything it's been a while since I sent out an
update on the state of the project, although I think we more or less caught
up on the status at the meetup. The bulk of the implementation work had
already been completed, so what I've been working on since then is just
cleaning up the code and rewriting some parts. In particular this week I
rewrote the detectors to be mostly python. The core Bayesian model is still
in BUGS/JAGS and there is still R code to interface with that. However, the
output of the models after training is now converted to a CSV file and the
actually detection code is a python program which reads the CSV file with
the trained model's prediction data and the compares it to the data of a
stream to be classified. This means that you only need R for training the
models. If we can put together a canonical model for each protocol then you
can use it to classify new traffic just using python. I think this is a win
because R was the bulkiest dependency. It also segments the process more
nicely in that there can be some people gathering traces, other people
building models, and then other people running detectors against new traces.

In terms of code cleanup, I've been adding comments and refactoring large
files (in particular pavement.py) to be more readable. I also have the
scoring tasks implemented so that, given the output of the detectors, the
various detectors and encoders are scored based on their number of correct
guesses, false positives, and false negatives. The only functionality left
to implement is some sort of reporting, probably in the form of graphs of
the scores so that detectors and encoders can be compared. The rest of the
work is just going to be refining everything and getting both the workflow
and the code structure to be smooth.

Also, I've stopped working on the string detector because I realized that
it's irrelevant for the two encoders I actually have support for right now:
obfs2 and Dust. They both already use totally randomized packet contents and
so will not be vulnerable to this kind of detector. Other encodings will be
vulnerable, but the string detector can wait until we support these
encodings. So instead I've implemented an entropy detector, which should
work very well against both obfs2 and the current implementation of Dust.
The entropy detector is actually the easiest model so far as the entropy of
a trace is just a single number, so that's convenient.

[Attachment #5 (text/html)]

With the TorDev meetup and everything it's been a while since I sent ou=
t an update on the state of the project, although I think we more or less c=
aught up on the status at the meetup. The bulk of the implementation work h=
ad already been completed, so what I've been working on since then is j=
ust cleaning up the code and rewriting some parts. In particular this week =
I rewrote the detectors to be mostly python. The core Bayesian model is sti=
ll in BUGS/JAGS and there is still R code to interface with that. However, =
the output of the models after training is now converted to a CSV file and =
the actually detection code is a python program which reads the CSV file wi=
th the trained model's prediction data and the compares it to the data =
of a stream to be classified. This means that you only need R for training =
the models. If we can put together a canonical model for each protocol then=
 you can use it to classify new traffic just using python. I think this is =
a win because R was the bulkiest dependency. It also segments the process m=
ore nicely in that there can be some people gathering traces, other people =
building models, and then other people running detectors against new traces=
.&lt;br&gt;
&lt;br&gt;In terms of code cleanup, I've been adding comments and refactoring=
 large files (in particular pavement.py) to be more readable. I also have t=
he scoring tasks implemented so that, given the output of the detectors, th=
e various detectors and encoders are scored based on their number of correc=
t guesses, false positives, and false negatives. The only functionality lef=
t to implement is some sort of reporting, probably in the form of graphs of=
 the scores so that detectors and encoders can be compared. The rest of the=
 work is just going to be refining everything and getting both the workflow=
 and the code structure to be smooth.&lt;br&gt;
&lt;br&gt;Also, I've stopped working on the string detector because I realize=
d that it's irrelevant for the two encoders I actually have support for=
 right now: obfs2 and Dust. They both already use totally randomized packet=
 contents and so will not be vulnerable to this kind of detector. Other enc=
odings will be vulnerable, but the string detector can wait until we suppor=
t these encodings. So instead I've implemented an entropy detector, whi=
ch should work very well against both obfs2 and the current implementation =
of Dust. The entropy detector is actually the easiest model so far as the e=
ntropy of a trace is just a single number, so that's convenient.&lt;br&gt;
&lt;br&gt;


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110809211200</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-08-09 21:12:00-0400</timestampReceived><subject>Re: [tor-dev] Instructions for building the Vidalia-bundle?</subject><body>

On Tuesday, August 09, 2011 06:07:13 Robert Ransom wrote:
&gt; On 2011-08-06, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
&gt; &gt; On Friday, August 05, 2011 13:02:46 Steve Snyder wrote:
&gt; &gt;&gt; Is there documentation anywhere on how to build the Vidalia-bundle for
&gt; &gt;&gt; Windows?  If so, where can I find it?
&gt; &gt; 
&gt; &gt; Build vidalia first,
&gt; &gt; https://svn.torproject.org/vidalia/vidalia/trunk/pkg/win32/build-vidalia-
&gt; &gt; installer.txt
&gt; 
&gt; Vidalia has moved to Git. 

Ok.  Can we purge the vidalia svn and put in a MOVED_TO_GIT notice?

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110812205028</emailId><senderName>Brandon Wiley</senderName><senderEmail>brandon@blanu.net</senderEmail><timestampReceived>2011-08-12 20:50:28-0400</timestampReceived><subject>[tor-dev] Blocking-Test: GSoC Penultimate Status Report</subject><body>

[Attachment #2 (multipart/alternative)]


Scoring and reporting for detectors and encoders is pretty much done. The
graphs aren't quite ready yet, for aesthetic reasons, but I have some nice
tables to report:

Length detector: 16% accuracy
Timing detector: 89% accuracy
Entropy detector: 94% accuracy

SSL was correctly identified 25% of the time, 70% of the time other
protocols were misidentified as being SSL, and 5% of the time SSL was
misidentified as another protocol.
obfsproxy was correctly identified 55% of the time, 10% of the time other
protocols were misidentified as being obfsproxy, and 35% of the time
obfsproxy was misidentified as another protocol.
Dust was correctly identified 48% of the time, 4% of the time other
protocols were misidentified as being Dust, and 48% of the time Dust was
misidentified as another protocol.

obfsproxy is distinguishable from SSL 96% of the time.
obfsproxy is distinguishable from Dust 98% of the time.
Dust is distinguishable from SSL 56% of the time.

I'm sure these numbers are confusing as several different sorts of things
are being measured, all with similar numbers. It is probably quite unclear
how all of these percentages add up. I think this is where the graphs will
help. In particular I think it's hard to visualize accuracy when there are
both false positives and false negatives to take into account.

I think the most interesting result here is the entropy detector. It's the
simplest and also the most effective. Not only that, but the entropy
detector only looks at the entropy of the first packet, so it's inexpensive.
The original reason that I implemented this detector was that there was an
argument against Dust that it could be trivially filtered by setting an
entropy threshold above which all traffic is filtered. Surprisingly, Dust
has lower entropy than SSL, so this attack will not work to specifically
target Dust. This is unexpected because Dust uses totally random bytes,
whereas the SSL handshake does not. This is a result of a general issue with
how Shannon entropy is defined. Shannon entropy is normally defined across a
large statistical sampling, in which case all three protocols tested will
converge to maximum since they are all encrypted and therefore apparently
random. However, the attacker does not in this case get a large statistical
sample. Since they don't know a priori which connections are Dust
connections, they only get however many packets are in each trace to use as
samples. The current version of Dust that I'm testing has most of the
advanced obfuscation stripped out as I haven't had time to add it back in
after completely reimplementing the protocol to use TCP instead of UDP and
all of the modified assumptions that come with that change. So this version
of Dust is basically just the ntor protocol with no packet length or timing
hiding in use. The first packet is therefore 32 random bytes consisting of
the curve25519 ephemeral ECDH key, as compared to the 1k first packet of
SSL. This is the reason for the low entropy calculation, because given only
32 bytes to sample almost all possible bytes are going to have a probability
of 0 or 1. There is an upper bound on entropy when sample sizes are small.
Achieving maximum first-order entropy here would require at least 512 bytes
so that each value 0 to 255 could occur exactly twice.

There are of course many ways to measure entropy and you could say that I'm
just doing it wrong. Some alternative measurements have already been
suggested that I might implement as well. I am not suggesting that Dust is
in any way immune to entropy-based detection. In fact, Dust is currently
detected very well by the current entropy detector (it passed 100% of the
packet length and timing tests, so all detection of Dust was done by the
entropy detector) precisely because it has strangely low entropy because of
it's small first packets. I bring this up only as an interesting example of
how intuition can fail when trying to use Shannon entropy to measure
individual messages instead of channels.

As far as the state of the project goes, I think the project can be
considered done. Looking at the project
documentation&lt;http://stepthreeprivacy.org/documentation&gt;,
everything didn't work out exactly as originally planned, I think it all
worked out for the best and the project is where I wanted it to be by the
completion of Summer of Code. I have generation of HTTP and HTTPS traffic,
both over Tor and plain. I have two encoders: obfs2 and Dust. I have three
detectors: length, timing, and entropy. The string detector didn't work out,
but the entropy detector worked out better than planned, so on balance I
think it was a win. I didn't implement all of the detector modes because
upon further reflection it doesn't really make sense to just try all of
these different modes. You want the mode that works best. So for packet
lengths and timing that is full conversations and for entropy that's the
first packet (could be first N packets, but I tried N=1 and it worked
great). Random sampling of packets just seems like a way to limit your
success at this point when non-random sampling of just the first packet
seems to be so effective. All of the utilities have been written, and more.
I have the specified utilities for separating the pcap files into streams,
and extracting the strings, lengths, and timings. Additionally, I have some
utilities for extracting the entropy of streams, tagging the streams with
what protocol they are using (by port), and extracting dictionary and corpus
models for latent semantic analysis. I also have some utilities for graphing
distributions of properties of different protocols which I hope to finish up
next week during the wrap-up period.

Looking to the future, I have changed my goals somewhat from what I had in
mind at the beginning of the project. After having attended the TorDev
meetup in Waterloo and the PETS conference, I am much more interested in
integrating my work with the Tor project instead of just testing the various
protocols that have been proposed in order to see how my own protocol stacks
up against the competition. As part of this transition, I have rewritten
Dust from scratch, both in terms of implementation and in terms of the
protocol, in order to be better suited for use as a pluggable transport for
Tor. My goal for Dust is to have it shipped with both Tor clients and
bridges so that it can be used in the field to contact bridges despite DPI
filtering of Tor connections. My goal now for the blocking-test project is
to focus on blocking resistance for Tor. So instead of adding all of the
protocols under the sun, I'm going to concentrate on protocols that have
been implemented or are under consideration to become pluggable transports.
Additionally, the next protocol I'm going to add after GSoC is over is just
plain Tor. There is at least one bug filed about a suspicion that Tor can
currently be fingerprinted based on some packet characteristics and I'd like
to be able to close that bug because we now have the capability to easily
generate the necessary information.

Finally, I would like to offer some insight into what I think is the future
of blocking-resistant transports now that I have done some work trying to
break them. Fundamentally, the only thing an attacker can do is limit the
bitrate of the connection. Given any sort of channel, we can encode
arbitrary information over that channel. However, the smaller the channel
the slower the bitrate. The goal of encodings should be to maximize the
bitrate given the constraints of the censor. It's easy to develop very slow
encodings such as natural language encodings over HTTP. However, in order to
maximize the throughput you need to have a good definition of the attack
model. All encoding for blocking-resistant purposes lowers the efficiency
above just transmitting the normal content (assumed it has already been
compressed). Therefore all encoded conversations are going to be longer than
unencoded conversations. I think this is the future of writing detectors
because it's a fundamental constraint on encoding. I think this should even
be able to defeat something like Telex (although let's not get into the
details of attacks on Telex specifically, I'm talking about a general idea
here). Given a (static, for the sake of argument simplicity) website, I can
download every page on that website. Then I can compare the length of
intercepted downloads and detect when they don't match up. For dynamic
websites you can do the same thing with a statistical model. I think,
therefore, that the future of blocking-resisting protocols is to encode
single logical connections over an ensemble of multiple actual connections.
Ideally these connections would mimic normal traffic in terms of number of
connections, duration, directional flow rates, etc.. It's something to think
about anyway. It could be an interesting problem.

[Attachment #5 (text/html)]

Scoring and reporting for detectors and encoders is pretty much done. The graphs \
aren't quite ready yet, for aesthetic reasons, but I have some nice tables to \
report:&lt;br&gt;&lt;br&gt;Length detector: 16% accuracy&lt;br&gt;Timing detector: 89% accuracy&lt;br&gt;

Entropy detector: 94% accuracy&lt;br&gt;&lt;br&gt;SSL was correctly identified 25% of the time, \
70% of the time other protocols were misidentified as being SSL, and 5% of the time \
SSL was misidentified as another protocol.&lt;br&gt;obfsproxy was correctly identified 55% \
of the time, 10% of the time other  protocols were misidentified as being obfsproxy, \
and 35% of the time obfsproxy was misidentified  as another protocol.&lt;br&gt;Dust was \
correctly identified 48% of the time, 4% of the time other  protocols were \
misidentified as being Dust, and 48% of the time Dust was misidentified  as another \
protocol.&lt;br&gt;&lt;br&gt;obfsproxy is distinguishable from SSL 96% of the time.&lt;br&gt;obfsproxy \
is distinguishable from Dust 98% of the time.&lt;br&gt;Dust is distinguishable from SSL 56% \
of the time.&lt;br&gt;&lt;br&gt;I'm sure these numbers are confusing as several different \
sorts of things are being measured, all with similar numbers. It is probably quite \
unclear how all of these percentages add up. I think this is where the graphs will \
help. In particular I think it's hard to visualize accuracy when there are both \
false positives and false negatives to take into account.&lt;br&gt;

&lt;br&gt;I think the most interesting result here is the entropy detector. It's the \
simplest and also the most effective. Not only that, but the entropy detector only \
looks at the entropy of the first packet, so it's inexpensive. The original \
reason that I implemented this detector was that there was an argument against Dust \
that it could be trivially filtered by setting an entropy threshold above which all \
traffic is filtered. Surprisingly, Dust has lower entropy than SSL, so this attack \
will not work to specifically target Dust. This is unexpected because Dust uses \
totally random bytes, whereas the SSL handshake does not. This is a result of a \
general issue with how Shannon entropy is defined. Shannon entropy is normally \
defined across a large statistical sampling, in which case all three protocols tested \
will converge to maximum since they are all encrypted and therefore apparently \
random. However, the attacker does not in this case get a large statistical sample. \
Since they don't know a priori which connections are Dust connections, they only \
get however many packets are in each trace to use as samples. The current version of \
Dust that I'm testing has most of the advanced obfuscation stripped out as I \
haven't had time to add it back in after completely reimplementing the protocol \
to use TCP instead of UDP and all of the modified assumptions that come with that \
change. So this version of Dust is basically just the ntor protocol with no packet \
length or timing hiding in use. The first packet is therefore 32 random bytes \
consisting of the curve25519 ephemeral ECDH key, as compared to the 1k first packet \
of SSL. This is the reason for the low entropy calculation, because given only 32 \
bytes to sample almost all possible bytes are going to have a probability of 0 or 1. \
There is an upper bound on entropy when sample sizes are small. Achieving maximum \
first-order entropy here would require at least 512 bytes so that each value 0 to 255 \
could occur exactly twice.&lt;br&gt;

&lt;br&gt;There are of course many ways to measure entropy and you could say that I'm \
just doing it wrong. Some alternative measurements have already been suggested that I \
might implement as well. I am not suggesting that Dust is in any way immune to \
entropy-based detection. In fact, Dust is currently detected very well by the current \
entropy detector (it passed 100% of the packet length and timing tests, so all \
detection of Dust was done by the entropy detector) precisely because it has \
strangely low entropy because of it's small first packets. I bring this up only \
as an interesting example of how intuition can fail when trying to use Shannon \
entropy to measure individual messages instead of channels.&lt;br&gt;

&lt;br&gt;As far as the state of the project goes, I think the project can be considered \
done. Looking at the &lt;a href="http://stepthreeprivacy.org/documentation"&gt;project \
documentation&lt;/a&gt;, everything didn't work out exactly as originally planned, I \
think it all worked out for the best and the project is where I wanted it to be by \
the completion of Summer of Code. I have generation of HTTP and HTTPS traffic, both \
over Tor and plain. I have two encoders: obfs2 and Dust. I have three detectors: \
length, timing, and entropy. The string detector didn't work out, but the entropy \
detector worked out better than planned, so on balance I think it was a win. I \
didn't implement all of the detector modes because upon further reflection it \
doesn't really make sense to just try all of these different modes. You want the \
mode that works best. So for packet lengths and timing that is full conversations and \
for entropy that's the first packet (could be first N packets, but I tried N=1 \
and it worked great). Random sampling of packets just seems like a way to limit your \
success at this point when non-random sampling of just the first packet seems to be \
so effective. All of the utilities have been written, and more. I have the specified \
utilities for separating the pcap files into streams, and extracting the strings, \
lengths, and timings. Additionally, I have some utilities for extracting the entropy \
of streams, tagging the streams with what protocol they are using (by port), and \
extracting dictionary and corpus models for latent semantic analysis. I also have \
some utilities for graphing distributions of properties of different protocols which \
I hope to finish up next week during the wrap-up period.&lt;br&gt; &lt;br&gt;Looking to the \
future, I have changed my goals somewhat from what I had in mind at the beginning of \
the project. After having attended the TorDev meetup in Waterloo and the PETS \
conference, I am much more interested in integrating my work with the Tor project \
instead of just testing the various protocols that have been proposed in order to see \
how my own protocol stacks up against the competition. As part of this transition, I \
have rewritten Dust from scratch, both in terms of implementation and in terms of the \
protocol, in order to be better suited for use as a pluggable transport for Tor. My \
goal for Dust is to have it shipped with both Tor clients and bridges so that it can \
be used in the field to contact bridges despite DPI filtering of Tor connections. My \
goal now for the blocking-test project is to focus on blocking resistance for Tor. So \
instead of adding all of the protocols under the sun, I'm going to concentrate on \
protocols that have been implemented or are under consideration to become pluggable \
transports. Additionally, the next protocol I'm going to add after GSoC is over \
is just plain Tor. There is at least one bug filed about a suspicion that Tor can \
currently be fingerprinted based on some packet characteristics and I'd like to \
be able to close that bug because we now have the capability to easily generate the \
necessary information.&lt;br&gt; &lt;br&gt;Finally, I would like to offer some insight into what \
I think is the future of blocking-resistant transports now that I have done some work \
trying to break them. Fundamentally, the only thing an attacker can do is limit the \
bitrate of the connection. Given any sort of channel, we can encode arbitrary \
information over that channel. However, the smaller the channel the slower the \
bitrate. The goal of encodings should be to maximize the bitrate given the \
constraints of the censor. It's easy to develop very slow encodings such as \
natural language encodings over HTTP. However, in order to maximize the throughput \
you need to have a good definition of the attack model. All encoding for \
blocking-resistant purposes lowers the efficiency above just transmitting the normal \
content (assumed it has already been compressed). Therefore all encoded conversations \
are going to be longer than unencoded conversations. I think this is the future of \
writing detectors because it's a fundamental constraint on encoding. I think this \
should even be able to defeat something like Telex (although let's not get into \
the details of attacks on Telex specifically, I'm talking about a general idea \
here). Given a (static, for the sake of argument simplicity) website, I can download \
every page on that website. Then I can compare the length of intercepted downloads \
and detect when they don't match up. For dynamic websites you can do the same \
thing with a statistical model. I think, therefore, that the future of \
blocking-resisting protocols is to encode single logical connections over an ensemble \
of multiple actual connections. Ideally these connections would mimic normal traffic \
in terms of number of connections, duration, directional flow rates, etc.. It's \
something to think about anyway. It could be an interesting problem.&lt;br&gt; &lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110820175444</emailId><senderName>Arturo_Filast</senderName><senderEmail>art@globaleaks.org</senderEmail><timestampReceived>2011-08-20 17:54:44-0400</timestampReceived><subject>[tor-dev] Tor2web 2.0 is live!</subject><body>

Hi all,

We are glad to announce the release of the new tor2web software.

For those of you who are not aware of what tor2web is let us give you a
brief description. The goal of tor2web is that of promoting the use of
Tor Hidden Services
(https://www.torproject.org/docs/hidden-services.html.en). Hidden
Services allow people to run TCP based services without disclosing the
identity/location of their server. In the specific they allow people to
anonymously publish content to the web. Also, since you are being
reached trough the Tor network, you are not required to have a static ip
address or purchase a domain. This lowers the entry barrier to content
publishing and protect the content publisher from retaliation and Denial
of Service attacks.

The problem though is that Hidden Services are usually only accessible
by installing a Tor client
(https://www.torproject.org/projects/torbrowser.html.en). Tor2web
creates a transport, by acting as a web proxy, between the internet and
the Tor network. This means that anonymous publishers are able to reach
a much wider audience. The user visiting a website though tor2web is
always advised to install a Tor client as by doing so he will protect
his identity and leverage Hidden Services end-to-end encryption.

This version of tor2web (called tor2web 2.0) is based on glype PHP web
proxy (http://www.glype.com) and it is by no means the definitive
solution. We are currently working on a new design that will be able to
withstand other "attacks" that are currently possible.

What we have implemented is:
* A clear disclaimer warning the user that the content is not being
served directly from the server, but it comes from the Tor network
* Contact forms for abuse complaints and to report broken websites
* Transparent rewriting of URLs into the tor2web form (i.e.
so4rmjdiwmqjosxz.onion become so4rmjdiwmqjosxz.tor2web.org)
* Blocklists to allow a tor2web node maintainer to block particular
websites, the blocklists are stored in md5 format so the node maintainer
does not need to store potentially illegal site lists.

At this current stage we would like the community to stand-up and help
us by:
* Finding security and functional bugs in the existing implementation
* Volounteering to run new tor2web servers:
   In this first stage we are looking for reliable systems, run or
endorsed by trustworthy organizations involved in anonymity and privacy
research and development.

For the new release the goals that we wish to further pursue are:
* Distribute responsibility across multiple actors
* Minimize the probability of takedown of a tor2web node

If you want further information on the tor2web project visit:
Wiki for new developments: http://wiki.tor2web.org/
Tor2web original website: http://www.tor2web.org
Github: https://github.com/globaleaks/tor2web-2.0
Mailing List: tor2web-talk@lists.tor2web.org on http://bit.ly/pxFwNS .
IRC: irc.oftc.net #tor2web

Have a nice day,
Some Random GlobaLeaks Contributors

Please spread across the anonimity communities and mailing lists

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110824175348</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-08-24 17:53:48-0400</timestampReceived><subject>Re: [tor-dev] lround() missing in MSVC</subject><body>

On Tue, Aug 23, 2011 at 6:27 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; lround() is missing in MS Visual-C's &lt;math.h&gt;. Not available anywhere.
&gt; Here is an easy patch:

Looks good; applied it.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110824221018</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-08-24 22:10:18-0400</timestampReceived><subject>Re: [tor-dev] Tor and slow DOS attacks</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; today, I read that blog post:
&gt; 
&gt; http://www.guerilla-ciso.com/archives/2049
&gt; 
&gt; It is talking about the rise of slow DOS attacks and that Tor could play
&gt; an important role in it (in fact the post links to an already existing
&gt; tool for this attack properly configured to get used with Tor).
&gt; As one of the defenses (granted the last one on his list) the author
&gt; mentions:
&gt; 
&gt; "Block TOR exit nodes before the traffic reaches your webservers (IE, at
&gt; layer 3/4)."

Heh, guy describes an attack that can bring down a webserver from a
coffeeshop and his solution is to block Tor. I love people like this.
If he was just listing it for completeness, he should also have
recommended a national open wireless and open proxy registry, so
everyone can block that too. You know, to stop attacks. At least it
was last on the list.. 

This attack definitely sounds like it should be mitigated by Apache
config options, and possibly also some form of load-based connection
pruning support in Apache itself for use when the server comes close
to the MaxClients limit.

&gt; Well, as this is not good for the Tor network and makes it unnecessary
&gt; easy for censors to argue for blocking Tor ("we just want to defend us
&gt; against slow DOS attacks") I am wondering whether there is already some
&gt; effort under way to detect and ban such kind of traffic. Or should there
&gt; be such effort at all?

There have been proposals to run IDSs at exit nodes before. In
theory, they can be supported by the Tor protocol without damaging
traffic:
https://lists.torproject.org/pipermail/tor-relays/2011-March/000675.html

So far no one seems interested in doing exit IDS the right way though.
We probably have a few exit operators running IDSs already, but they
are doing so at risk of being BadExited if they are discovered to be
interfering with *any* amount of normal traffic.

In general though, the belief is that this is not really our job. If
an attack is possible through Tor, blocking Tor or making Tor illegal
is akin to burying your head in the ground. Sure, you might stop the
script kiddie who ran their attack script with 'torsocks' today, but
some other attacker will knock your site over from a coffee shop or
open proxy tomorrow.

This core philosophy is the basis behind the abuse template set for
exit operators:
https://trac.torproject.org/projects/tor/wiki/doc/TorAbuseTemplates

This philosophy obviously puts us at odds with all the DNSRBL/honeypot
folks out there that believe that vigilante justice should be metered
out by threatening and spamming ISP abuse departments into pulling the
plug on "noisy" IP addresses, but we believe they are just wasting
their lives playing wack-a-mole. I guess if it makes them feel better,
that's great for them. Everybody deserves their Prozac. But they're
not really solving any real problems.

Fix the software. Don't fight brain damge with network damage.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110825080800</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-08-25 08:08:00-0400</timestampReceived><subject>[tor-dev] Sanitizing and publishing our web server logs</subject><body>

Hi everyone,

we have been discussing sanitizing and publishing our web server logs
for quite a while now.  The idea is to remove all potentially sensitive
parts from the logs, publish them in monthly tarballs on the metrics
website, and analyze them for top visited pages, top downloaded
packages, etc.  See the tickets #1641 and #2489 for details.

Here's a suggested sanitizing procedure for our web logs, which are in
Apache's combined log format:

 - Ignore everything except GET requests.
 - Ignore all requests that resulted in a 404 status code.
 - Rewrite log lines so that they only contain the following fields:
   - IP address 0.0.0.0 for HTTP request or 0.0.0.1 for HTTPS requests
(as logged by our Apache configuration),
   - the request date (with the time part set to 00:00:00),
   - the requested URL (cut off at the first encountered "?"),
   - the HTTP version,
   - the server's HTTP status code, and
   - the size of the returned object.
 - Write all lines from a given virtual host and day to a single output
file.
 - Sort the output file alphanumerically to conceal the original order
of requests.

Here's a sample sanitized log file for www.torproject.org from May 1,
2009 (462K):


http://freehaven.net/~karsten/volatile/www.torproject.org-access.log-20090501.gz

Is there still anything sensitive in that log file that we should
remove?  For example:
 - Do the logs reveal how many pages were cached already on the
requestor's site (e.g. as repeat accesses)?  Note that log files are
sorted before being published.
 - Are there other concerns about making these sanitized log files
publicly available?

Are the decisions to remove parts from the logs reasonable?  In particular:
 - Do we have to take out all requests with 404 status codes?  Some of
these requests for non-existing URLs contain typos which may not be safe
to make public.  Should we instead put in some placeholder for the URL
part and keep the 404 lines to know how many 404's we have per day?
 - Is there any good reason to keep the portion of a URL after a "?"?
 - Is it possible to leave some part of Referers in the logs that helps
us figure out where our traffic originates and what search terms people
use to find us?
 - Can we resolve client IP addresses to country codes and include those
in the logs instead of our 0.0.0.0/0.0.0.1 code for HTTP/HTTPS?  How
would we handle countries with only a few users per day, e.g., should
there be a threshold below which we consider requests to come from "a
country with less than XY users?"

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110829105327</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-08-29 10:53:27-0400</timestampReceived><subject>[tor-dev] Exit Enclaving and the future of?</subject><body>

Hi,

I'll try to sum up Exit Enclaving in no certain terms and hope that Nick
or someone else will chime in to correct my assumptions. This should
probably be formalized and put into the path-spec at some point. I was
surprised to not see it in there to begin with but I probably just
missed it. Anyway, without further delay...

When Tor builds a circuit it does so with certain constraints in mind -
most of these are described in the path-spec. Exit Enclaving is a set of
client circuit building constraints that all go together. When a user
wishes to connect to a given IP address, Tor will check this IP against
all of the Tor nodes in the Tor consensus. If the IP address in question
is a Tor node in the consensus, the Tor client will check the selected
Tor node's exit policy. If the Tor node's exit policy allows connections
to *itself* - that is the IP address of Tor node - we check that the
requested port is allowed by that policy. If we find that this set of
constraints is matched, we build a *four* hop circuit to the Tor node
that has the same IP as our request. The Tor node that matches is the
fourth hop and we force exiting to the service offered by that node. The
user then exits from the Tor node that met the constraints and they're
connected to the service offered by that Tor node. As a result, client
security is greatly improved by using Tor as the full path to the
services offered on that Tor node.

Obviously, with a bit of firewall trickery, it would be possible to
offer the services on another physical host but the general point still
stands - the service on a given IP address may only be enclaved by an IP
address that is a confirmed Tor relay.

I think Exit Enclaving is confusing for the uninitiated. It is
documented but not in the standard Tor ways and it appears to be one of
the lesser understood things in Tor land. Here's the official
documentation as far as I've found it :
https://trac.torproject.org/projects/tor/wiki/doc/ExitEnclave

Here's the important bits from that page:

SocksPort 9050 # what port to open for local application connections
SocksListenAddress 127.0.0.1 # accept connections only from localhost
ORPort 9001
Nickname archivetpo
ExitPolicyRejectPrivate 0
ExitPolicy accept 38.229.70.19:443
ExitPolicy reject *:*

There are a few references to the term (Exit) Enclave in the torspec.git
repo but none of them actually define how it works with absolute
authority. At best we've described how to try to become one without
actually explaining the essence concretely in a specification. I think
we should add a paragraph to the man page as well as the torspec. I'd be
happy to write it once we actually hammer out the current and pas client
behaviour.

There is a problem with the current Exit Enclaving approach and if
anything, it's not the worst one to have. If the user attempts to
connect with a name, we are unable to try to satisfy the constraints
that require an IP address; so we just skip Enclaving entirely for that
connection. After the first sucessful connection or the first time Tor
resolves the name, we're able to take the above steps in our attempt to
opportunistically enclave. Before that - the Tor client only knows the
name and thus the IP address is a mystery. Generally this results in the
first connection exiting via any other node that allows exiting to the
target host. I think this is perhaps an anonymity concern as it shows
that the Tor client has likely not connected to the host in question -
an evil Exit might take note of this and watch for correlated streams
over time, etc.

Here's an example of a semi-popular website documenting their enclaving
experience:
http://www.gabrielweinberg.com/blog/2010/08/duckduckgo-now-operates-a-tor-exit-enclave.html

Recently the CCC jabber server became an exit enclave and a hidden
service, similar to the DuckDuckGo setup:
https://twitter.com/#!/jabbercccde/status/107850926638895104
https://twitter.com/#!/jabbercccde/status/107850540842627072

As I stated previously, I think that the use of Exit Enclaves greatly
improves client security. It reduces the chances of a network sniffer
getting lucky, it helps to mitigate the severity of services getting
crypto stuff wrong, etc.

I think it would be nice to make this easier to set-up and configure for
server administrators. I'd also like to make this more flexible for Tor
clients and if possible, find some methods for making Tor clients
automatically enclave on the first connection.

There are a few ways that we might see Exit Enclaving happen on the
first connection. It is possible to make the first connection enclave if
the client is using the TorDNSPort; Tor will have resolved and cached
the names used by all clients, connections by names should then Enclave
and connections by IP will Enclave as well. Alternatively, having all
connections to Tor happen by IP address only would force all clients to
Enclave on first connection. I think this is probably dangerous in all
cases except a Transparent Tor network. Another possible hack is to set
MapAddress for the hosts that matter to you - this doesn't scale very
well and it's confusing for most people; it isn't dynamic and it seems
that it will likely desynchronise over time.

I'd like to advocate for a simple set of options to make this stuff
easier to use and more likely to be used by a server admin.

Here's a bug where I suggest an option OfferExitEnclave that is either a
bool or a port list:
https://trac.torproject.org/projects/tor/ticket/800

My thought was that a service provider who wants to offer enhanced
service to Tor users could set a single flag and it would create a Tor
Exit node that only exits to itself; I imagine that it might make sense
to change the advertised bandwidth. It might even be a good idea to set
a reasonable bandwidth cap of sorts but I think this is probably not
great until we can automatically guess intelligently. I imagine that
flipping the hypothetical OfferExitEnclave switch would actually be
short hand for the following:

ORPort auto
Nickname exitenclave
MaxAdvertisedBandwidth 20KB
ExitPolicyRejectPrivate 0
ExitPolicy accept ORListenConfirmedPublicAddress:*
ExitPolicy reject *:*

Thus when we want to help someone enclave their entire host - we tell
them to flip a single flag like so:

OfferExitEnclave 1

If they want to enclave a specific service on their host - we tell them
to flip the same flag like so:
OfferExitEnclave 1
ExitEnclavePorts 5222

I'm not sold on that set of options but I think offering at least the
OfferExitEnclave option as a bool would result in a lot more clarity for
a server admin who wants to enhance their services for use with Tor.

I think that generally, the nice part about Exit Enclaving is that it
works as well as the rest of Tor - it does not really rely on external
dependencies at all - no need for DNS or DNSSEC stuff, no need for the
authorities to do any extra work on a per node basis, the client can use
a different exit if they like, etc.

On the client side, I think that would could make some improvements that
aren't merely cosmetic but when enabled would improve client security.
As I've already stated, Transparent Tor networks with TorDNSPort do this
automatically by the nature of how they function. Other than the
Torouter and probably TAILS, I'm not sure of other projects that takes
advantage of this option. I'm not even certain that it will work in the
long term for Torouter because of SRV records and jabber clients.

Generally the client situation as it stands today lacks a general switch
to force attempts at Exit Enclaving by name. Such an option would force
a full round trip. Certainly we lack a general manner that attempts to
Exit Enclave for all hosts and I'd like to see that change.

I think it would be nice to have a few options and I'm far from sold on
any of them. I'll lay them out as if they were already implemented.

LearnExitEnclaveNames 0|1

This option could learn what possible names are frequently used and
opportunistically resolve them, perhaps even caching some meta-data
about exit enclaves that we've used, if it was stable, etc - this is
could be something like a mash up TrackHostExits, LongLivedPorts,
MapAddress, and something that learns overtime the hosts you use regularly.

I think it would need some work to be done in a privacy preserving
manner, probably with something like scrypt, if it needed to be cached
on disk. This would solve the problem of a host being a known Exit
Enclave after the first resovle and then later expiring from Tor's
internal DNS cache. I think this is a common problem for IM connections
and simply marking that name as something worth the round trip would be
a huge gain, even if only for a single Tor run where the results are
never cached on disk. My Tor often runs for days at a time and I think
that the DNS cache internally expires before my Tor client exits. I'm
pretty sure that means that it's up to my IM client or other software to
cache the IP or we're back to square zero.

AttemptExitEnclaving 0|1

This option could simply force the full round trip for all connections.
Simple enough but likely a major performance hit. The default would be
zero and keep things as they are today.

AttemptExitEnclavingPorts [port list]

This option could attempt Enclaving for any connections to any host if
the connection is to one of the listed ports.

AlwaysAttemptEnclaveNames [list of names]

This option could take a list of names where we want to force a full
round trip and that we'd like to enclave. Perhaps it would even fail to
work if the Enclaving would fail and perhaps it could fail in a helpful
manner. I imagine that some people might like this for customised
browser bundles or if they're a power user who knows what they want, etc.

I know that Nick had some suggestions - perhaps adding known Exit
Enclaving names into the consensus or into descriptors or something that
the directory authorities handle. I'm not sure that I fully understand
his suggestions and I look forward to his reply to this email. :)

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110829172921</emailId><senderName>"Thomas S. Benjamin"</senderName><senderEmail>tomb@acm.org</senderEmail><timestampReceived>2011-08-29 17:29:21-0400</timestampReceived><subject>Re: [tor-dev] Survey on Tor Trac usage and how you manage your tasks</subject><body>

&gt; 1 Using Trac features
&gt;
&gt; 1.1 Which of the reports (stored ticket queries) do you use most often?

https://trac.torproject.org/projects/tor/report/8

&gt;
&gt; 1.2 What are typical custom queries that you run?

I sometimes search on a tag if one is being used for a particular
multi-ticket task.

&gt;
&gt; 1.3 How do you use milestones and roadmaps?

not.

&gt;
&gt; 1.4 Are you subscribed to tor-bugs and/or tor-wiki-changes, and how do
&gt; you use the mails sent to these lists?

I am not.

&gt;
&gt; 1.5 Which wiki pages do you read/edit most often?

Pages that have to do with internal processes.

&gt;
&gt; 1.6 How do you search for wiki pages?

search window inside wiki.

&gt; 1.9 How relevant are the following ticket fields for you?
&gt;
&gt; 1.9.1 Reported by
&gt;
&gt; 1.9.2 Owned by

Important

&gt;
&gt; 1.9.3 Priority

Important

&gt;
&gt; 1.9.4 Milestone

Important

&gt;
&gt; 1.9.5 Component
&gt;
&gt; 1.9.6 Version
&gt;
&gt; 1.9.7 Keywords
&gt;
&gt; 1.9.8 Cc
&gt;
&gt; 1.9.9 Parent ID

Important

&gt;
&gt; 1.9.10 Points
&gt;
&gt; 1.9.11 Actual Points
&gt;
&gt; 1.10 How relevant are the following ticket statuses for you?

All of those statuses are relevant to me.


&gt; 2.1 How do you decide what to work on, both when fixing bugs or when
&gt; implementing new features?

Discussion with the people working on the most closely related things.

&gt;
&gt; 2.2 How do you keep track of what things you're supposed to do for
&gt; sponsors and for when?

In order:  A personal list, trac, the master list of sponsor goals on the wiki.

&gt; 2.4 How do you coordinate working together with someone on something?

I really do best coordinating over private email, which I am still
working on changing because I perceive that it doesn't work well with
how everyone else coordinates.  I've been trying to find a balance
between day to day coordination in private, and then making sure that
major milestones get communicated to a list.  I have started using
this approach as with the GSoC coordination in the latter portion of
the summer.

&gt; 2.5 How do you learn who you could work together with on something?

Face to face interaction.  Again, I know this is something I have to
change because it doesn't work well in the context of Tor.


-- 
Sincerely Yours,
              ---Thomas S. Benjamin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110830023621</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-08-30 02:36:21-0400</timestampReceived><subject>[tor-dev] Research problem: better guard rotation parameters</subject><body>

The next in my series of research blog posts is up:

https://blog.torproject.org/blog/research-problem-better-guard-rotation-parameters

"What algorithm should we use to assign Guard flags such that a) we
assign the flag to as many relays as possible, yet b) we minimize the
chance that Alice will use the adversary's node as a guard?"

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110806025145</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-08-06 02:51:45-0400</timestampReceived><subject>Re: [tor-dev] Instructions for building the Vidalia-bundle?</subject><body>

On Friday, August 05, 2011 13:02:46 Steve Snyder wrote:
&gt; Is there documentation anywhere on how to build the Vidalia-bundle for
&gt; Windows?  If so, where can I find it?

Build vidalia first, 
https://svn.torproject.org/vidalia/vidalia/trunk/pkg/win32/build-vidalia-
installer.txt

then build the bundle

https://svn.torproject.org/vidalia/vidalia/trunk/pkg/win32/build-bundle-
installer.txt

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110809100713</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-08-09 10:07:13-0400</timestampReceived><subject>Re: [tor-dev] Instructions for building the Vidalia-bundle?</subject><body>

On 2011-08-06, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
&gt; On Friday, August 05, 2011 13:02:46 Steve Snyder wrote:
&gt;&gt; Is there documentation anywhere on how to build the Vidalia-bundle for
&gt;&gt; Windows?  If so, where can I find it?
&gt;
&gt; Build vidalia first,
&gt; https://svn.torproject.org/vidalia/vidalia/trunk/pkg/win32/build-vidalia-
&gt; installer.txt

Vidalia has moved to Git. See
https://gitweb.torproject.org/vidalia.git/blob/HEAD:/pkg/win32/build-vidalia-installer.txt
.

&gt; then build the bundle
&gt;
&gt; https://svn.torproject.org/vidalia/vidalia/trunk/pkg/win32/build-bundle-
&gt; installer.txt

https://gitweb.torproject.org/vidalia.git/blob/HEAD:/pkg/win32/build-bundle-installer.txt


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110823222715</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-08-23 22:27:15-0400</timestampReceived><subject>[tor-dev] lround() missing in MSVC</subject><body>

lround() is missing in MS Visual-C's &lt;math.h&gt;. Not available anywhere.
Here is an easy patch:

--- Git-latest\src\common\util.c        Sun Aug 14 13:48:49 2011
+++ src\common\util.c   Tue Aug 23 21:15:25 2011
@@ -335,7 +335,11 @@
 long
 tor_lround(double d)
 {
+#ifdef _MSC_VER
+  return (long)(d &gt; 0 ? d + 0.5 : ceil(d - 0.5));
+#else
   return lround(d);
+#endif
 }

 /** Returns floor(log2(u64)).  If u64 is 0, (incorrectly) returns 0. */

----------------

--gv

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110824192100</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-08-24 19:21:00-0400</timestampReceived><subject>[tor-dev] Tor and slow DOS attacks</subject><body>

[Attachment #2 (multipart/signed)]


Hi,

today, I read that blog post:

http://www.guerilla-ciso.com/archives/2049

It is talking about the rise of slow DOS attacks and that Tor could play
an important role in it (in fact the post links to an already existing
tool for this attack properly configured to get used with Tor).
As one of the defenses (granted the last one on his list) the author
mentions:

"Block TOR exit nodes before the traffic reaches your webservers (IE, at
layer 3/4)."

Well, as this is not good for the Tor network and makes it unnecessary
easy for censors to argue for blocking Tor ("we just want to defend us
against slow DOS attacks") I am wondering whether there is already some
effort under way to detect and ban such kind of traffic. Or should there
be such effort at all?

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110824212011</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-08-24 21:20:11-0400</timestampReceived><subject>Re: [tor-dev] Tor and slow DOS attacks</subject><body>

On Wed, Aug 24, 2011 at 12:21 PM, Georg Koppen &lt;g.koppen@jondos.de&gt; wrote:
&gt; ...
&gt; [blah blah] about the rise of slow DOS attacks and that Tor could play
&gt; an important role in it
&gt; ... I am wondering whether there is already some
&gt; effort under way to detect and ban such kind of traffic. Or should there
&gt; be such effort at all?


there should not be an effort.  or better said, slow DoS protections
begin in design stage, continue through development and are supported
by operations.

in nearly every instance of a successful slow DoS there is a negligent
or incompetent sysadmin or developer (or both!) at fault.

the fact that millions of poorly configured webservers are unable to
service requests to their poorly designed and implemented webapps
should have no bearing on Tor efforts or exit traffic.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110704075650</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-04 07:56:50-0400</timestampReceived><subject>[tor-dev] Tech report: An Analysis of Tor Relay Stability</subject><body>

Hello tor-dev,

I just added a tech report called "An Analysis of Tor Relay Stability"
that might be interesting to people here to the metrics website:

  https://metrics.torproject.org/papers/relay-stability-2011-06-30.pdf

From the introduction:

"The Tor network consists of around 2,000 relays and 500 bridges run by
volunteers, some of which are on dedicated servers and some on laptops
or mobile devices.  Obviously, we can expect the relays run on dedicated
servers to be more "stable" than those on mobile phones. But it is
difficult to draw a line between stable and unstable relays. In most
cases it depends on the context which relays count as stable:

[...]

In this analysis, we use a simulator to resemble how the directory
authorities assign the Stable and Guard relay flags.  This simulator
uses archived directory data to decide when a relay was running and when
it failed or was restarted.  We further use this simulator to calculate
future stability metrics that help us evaluate the quality of a given
relay flag assignment.  We modify the input parameters to Tor's
stability metrics to see whether we can improve how the directory
authorities should assign relay flags.  The analysis data and simulator
used in this report are available on the Tor metrics website at
https://metrics.torproject.org/."

I also made the simulator code and input data available here:

  https://metrics.torproject.org/papers.html

As always, feedback is highly appreciated!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110706150553</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-07-06 15:05:53-0400</timestampReceived><subject>[tor-dev] Feedback on new Orbot data stats</subject><body>


Sathya (our fantastic GSoC 2011 dev) has been working on improving the
display of information that we can glean from Tor via the control port
interface.

You can see the results of his work (including an initial screenshot) so
far here: http://gsathya.in/blog/?p=66

We would like feedback from Tor/Vidalia and Orbot users out there on
what data from Tor that you feel is useful and necessary both as a
general case, and perhaps what might be more relevant in a mobile context.

One case to consider is that in mobile, we are constantly losing our IP
connection, switching from 2G to 3G to Wifi to no service at all. What
information does Tor produce that can help the user understand better
the state that Orbot is actually in?

We are also trying to consider three modes of display: the main screen
"dashboard", a full screen detail view, and background notifications
that alert the user to important state changes.

Thanks!

+n8fr8

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110711102150</emailId><senderName></senderName><senderEmail>"re:[tor-dev]"@tail-f.com, improving@tail-f.com, private</senderEmail><timestampReceived>2011-07-11 10:21:50-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/signed)]


&gt;&gt; Hmmm... If that is the answer to my questions then there is nothing like
&gt;&gt; avoiding getting tracked by exit mixes in the concept offered in the
&gt;&gt; blog post. Okay.
&gt; 
&gt; That is not entirely true. Because identifiers would be linked to
&gt; top-level urlbar domain, gone are the days where exits could insert an
&gt; iframe or web-bug into any arbitrary page and use that to track the
&gt; user for the duration of the session, regardless of page view.
&gt; 
&gt; Instead, they would be pushed back to doing some sort of top-level
&gt; redirect (which we hope would be way more visible), or maybe not even
&gt; that, depending on how we define redirects with respect to
&gt; "top-level".
&gt; 
&gt; So no, we are not completely abandoning exits as an adversary with
&gt; this threat model. If I'm wrong about something, or you think there
&gt; are still attacks exits can perform that we should address somehow,
&gt; let me know.

See my last mail.

&gt;&gt; Another question came to my mind: You seem to be at pains not to break
&gt;&gt; parts of the web even in the anon mode even if that boils down to not
&gt;&gt; implement features that would better fit the needs for people looking
&gt;&gt; for unlinkability (one thing that comes to my mind here would be having
&gt;&gt; a context being tab dependent additionally). Why? Why not saying: "This
&gt;&gt; is Tor's anon mode. It is meant for people that strive for unlinkability
&gt;&gt; and might break some functionality. You may still use Tor in normal or
&gt;&gt; private browsing mode though (providing no or less unlinkability on the
&gt;&gt; browser level)." Do you think that's not worth the effort as Tor's IP
&gt;&gt; unlinkability is enough here (especially combined with the things you
&gt;&gt; suggested in the blog post)? I do not know Tor's user base very well but
&gt;&gt; could imagine that it contains a lot of users that would like to have
&gt;&gt; more unlinkability than the "we do not want to break any (or almost any)
&gt;&gt; part of the web for a better anonymity" fraction.
&gt; 
&gt; I wish I had better science to give you here on the trade-off we're
&gt; going for, but the reality is that we're best-guessing over a very
&gt; complex cost/benefit landscape.

That's true.

&gt; We do know for a fact that the easier Tor is to use (which includes
&gt; installation, configuration, overall intuitiveness/"familiarity",
&gt; compatibility, and performance), the more people will use it
&gt; regularly.

That seems to hold for every piece of software, I guess.

&gt; We also know for a fact that the more people use Tor, the better the
&gt; baseline privacy, anonymity, and censorship resistance properties all
&gt; become.

Agreed.

&gt; Hence, I tend to make decisions in favor of the usability direction
&gt; over minor details, especially ones that don't really prevent bad
&gt; actors/adversaries from accomplishing their goals.

That is definitely a good approach. But maybe there is research to be
done here as well. Just a rough (and in part research) idea that I had
in mind while asking you the question above: What about if we first
started looking at different services offered in the web whether they
can be deployed anonymously *at all* (or maybe more precisely (but not
much): that can be deployed in a way that there is either no linkability
at all or the linkability is not strong enough to endanger the user)
(that would be worth some research, I guess)? We would probably find
some services where we had to say: "Well, there is no way to get them
used anonymously due to their nature and the power of the companies
and/or owners behind them." (Facebook comes here to my mind as a
candidate and the Google universe as well due to the power Google has).
Should we say we make the Tor anon mode compatible with these services
nevertheless (due to usability issues) and abandon stronger anonymity
measures? I would say no. Not at all. Rather we should be honest and
say: "Dear User, surfing anonymously AND using Facebook does not work.
You may use the Tor anon mode for that purpose though but there is a
high probability that it breaks functionality." The idea of getting more
users due to being not too strict here might be appealing but is not the
right decision in the end. I think one has to realize that there are
services in the web that are *designed* in a way that one EITHER may use
them OR use anonymity services. Sure, the devil is in the details (e.g.
there are probably a lot of services that may be usable anonymously but
then are accompanied with a certain lack of usability. What about them?
Should we decide against usability again or should we loosen our means
to provide unlinkability here?) but that does not mean there is no way
to find a good solution though. In short (and still roughly): I would
like to start thinking from having all means available to surf the web
anonymously and then downgrade them piece-by-piece to reach a trade-off
between anonymity and usability. Services that may not be used
anonymously at all would not trigger such a painful downgrade ("painful"
as one usually tries first to hack around existing problems encountering
unbelievable design issues and bugs and has to concede finally that it
is in the user's interest to exclude that feature (again)).

&gt; The need for science especially comes in on the fingerprinting arena.
&gt; Some fingerprinting opportunities may not actually be appealing to
&gt; adversaries. Some may even appear appealing in theory, but in practice
&gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt; Hence I called for more panopticlick-style studies, especially of
&gt; Javascript features, in the blog post.

Yes, that is definitely a good idea though I tend to avoid them all even
if currently no adversary is using them (especially if no usability
issue is at stake). First: no one knows whether one did not miss an
attacker using this kind of attack vector and second: Getting rid of
attack vectors is a good thing per se.

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110714055632</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-14 05:56:32-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay Setup Wizard</subject><body>

On 7/14/11 5:52 AM, Damian Johnson wrote:
&gt;&gt; In that case,
&gt;&gt; setting "Internal Relay" as the default could be problematic.  If people
&gt;&gt; use arm on their clients, they shouldn't be tricked into becoming a
&gt;&gt; relay only because that's the default.  They should know what they're
&gt;&gt; doing when setting up a relay.  But 90% of all users go with the
&gt;&gt; default, so if "Internal Relay" is the default, they'll just pick that
&gt;&gt; and hope for the best.  (Ignore this comment if the wizard is explicitly
&gt;&gt; called "Tor Relay Setup Wizard" and if people need to actively start it.)
&gt; 
&gt; I disagree. For the network to scale it needs some portion of its
&gt; userbase to be relays. There's certainly use cases where that isn't
&gt; practical (either when it's a burden or they need to hide the fact
&gt; that they're using tor), but for just about anything else operating a
&gt; middle-hop relay is an easy and complaint-free way of helping. I kinda
&gt; like having people opt-out of being a relay since it makes them aware
&gt; when they're using the network without contributing to it. Also,
&gt; weren't we talking earlier about making people bridges by default in
&gt; Vidalia?

I didn't follow the whole "make all users relays or bridges" discussion.
 But I think there are a few arguments against turning clients into
relays by default:

- If people aren't really aware that they're becoming a relay, we'll end
up with a lot of slow and unstable relays.  I imagine there could be
hundreds if not thousands of those relays if we start shipping packages
with arm.  This could become problematic for the directory system at
some point.  Sure, we could start excluding relays from the consensus
that don't contribute much.  But why create a problem (or making it
worse) if we can avoid it?

- Another effect of surprising people by turning their clients into
relays is that they might stop liking Tor.  They shouldn't learn that
they're contributing to something they only discovered a few hours ago,
only because it eats all their bandwidth.  Even worse, what if people
try out Tor, use it for a bit, let it run, and learn at the end of the
month that they exceeded their bandwidth quota and have to pay for it?
It would be better to make them like Tor first and then ask them to give
something back.

- If you make Client at position 4 the default and have three more
options at positions 1 to 3 to contribute to the network, a fair amount
of people will already feel bad that they don't contribute.  If we can
give these people an easy way to contribute to the network by re-running
the wizard, we win.

- I'm not sure if making people bridges by default in Vidalia is a good
idea, either.  I think you're referring to the Tor proposal where
clients measure if they're stable enough to be a bridge and whether
they're reachable from outside and then turn into bridges automatically.
 I'm not a big fan of this idea, but at least it makes sure the new
bridges or relays will be useful for the network.  It also means people
had the chance to like Tor enough to accept that they're now giving
something back.

&gt; That said, I'll change the default if people would rather it be something else.

Sure, having more opinions here would be useful.  This discussion isn't
even arm-specific, but could apply to Vidalia or packaging in general.
I'm curious what other people think, too.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714135034</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-07-14 13:50:34-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

Rob van der Hoeven &lt;robvanderhoeven@ziggo.nl&gt; writes:

&gt; Hi folks,
&gt;
&gt; Bridges serve as "unknown" entry points to the TOR network. For this,
&gt; part of the TOR network nodes are reserved and unlisted. This is not
&gt; good for the performance of the network, and because the network is
&gt; relatively small i think the unlisted-nodes strategy will only be a
&gt; short term solution.
&gt;
&gt; At the moment i'm working on my own FreedomBox. From this work i got the
&gt; following idea: Why not use the DNAT function of a router to forward TOR
&gt; traffic to a TOR node? This way you don't need unlisted nodes anymore. A
&gt; router-bridge does not have to be a full TOR node....
&gt;
&gt; Unfortunately the standard DNAT functionality of most routers only
&gt; support DNAT from the internet to internal addresses. So you need
&gt; modified firmware to make this work. Maybe a (slightly modified?)
&gt; version of OpenWRT will work.
&gt;
&gt; Router-bridges have a second advantage over real TOR nodes. They can be
&gt; easily moved. If a router-bridge gets blocked, you can simply give the
&gt; router-bridge to a friend.
&gt;
&gt; To give you an example of internet-internet DNAT i have configured one
&gt; of my systems to forward traffic to the TOR website. The URL is:
&gt;
&gt; https://wordpress.hoevenstein.nl/
&gt;
&gt; (If you try the URL you get a message about an invalid certificate of
&gt; course)
&gt;
&gt; Let me know what you think about this idea...
&gt; Rob van der Hoeven.
&gt; http://freedomboxblog.nl
&gt;
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

Just mentioning that more-or-less your idea is the matter of
discussion of Tor trac ticket #2764.

[https://trac.torproject.org/projects/tor/ticket/2764]
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714150033</emailId><senderName>Tim Wilde</senderName><senderEmail>twilde@cymru.com</senderEmail><timestampReceived>2011-07-14 15:00:33-0400</timestampReceived><subject>Re: [tor-dev] Nick's planned schedule for Tor 0.2.3.x development</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/14/2011 10:41 AM, Nick Mathewson wrote:
&gt; Obviously, this is still up for discussion.  But please remember
&gt; about the bikeshed.

For what it's worth, +1 from this section of the peanut gallery.  Sounds
like a very reasonable plan to me.  Thanks for all your hard work Nick &amp;
everyone else who contributes!

Regards,
Tim

- -- 
Tim Wilde, Senior Software Engineer, Team Cymru, Inc.
twilde@cymru.com | +1-630-230-5433 | http://www.team-cymru.org/
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAk4fBI4ACgkQluRbRini9tjnygCfQ3TitxpUtPGhEpvrAWNX+8H9
jPoAnRm7Tc4T3/rETdHysJQiBlOPKsf2
=AbKL
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110715183859</emailId><senderName></senderName><senderEmail>swsnyder</senderEmail><timestampReceived>2011-07-15 18:38:59-0400</timestampReceived><subject>Re: [tor-dev] CPU utilization for relay</subject><body>

Mike Perry wrote:

&gt; Thus spake swsnyder at snydernet.net (swsnyder at snydernet.net):
&gt; 
&gt; &gt; FYI, this is a profile of my Tor v0.2.2.30-rc relay, taken in a 10-minute \
&gt; &gt; sampling: 
&gt; &gt; CPU: CPU with timer interrupt, speed 0 MHz (estimated)
&gt; &gt; Profiling through timer interrupt
&gt; &gt; samples  %        linenr info                 symbol name
&gt; &gt; 3126     29.7290  cast-586.s:9                CAST_encrypt
&gt; 
&gt; Can you attach gdb to your relay and set a breakpoint for
&gt; CAST_encrypt? We have no idea why this function should be called at
&gt; all (unless it is for something like reading keyfiles off disk?) let
&gt; alone dominate your profile output.

I didn't break on CAST_encrypt() either in a running process or in tor started from a \
gdb command line.  Either way, I could set a breakpoint on the symbol but never \
actually got there.

I think the symbols were screwed-up from building Tor with GCC's Profile Guided \
Optimization.  When I built the same code without PGO I get this from another \
10-minute run:

CPU: CPU with timer interrupt, speed 0 MHz (estimated)
Profiling through timer interrupt
samples  %        linenr info                 symbol name
2386     58.6241  x86-mont.s:8                bn_mul_mont
262       6.4373  aes-586.s:269               _sse_AES_encrypt_compact
207       5.0860  sha1-586.s:8                sha1_block_data_order
199       4.8894  aes-586.s:424               _x86_AES_encrypt
189       4.6437  aes-586.s:1610              _x86_AES_decrypt
55        1.3514  aes.c:329                   aes_crypt_inplace
48        1.1794  di_ops.c:97                 tor_memeq

Breakpoints *do* hit on bn_mul_mont().  I assume the reduced number of samples is a \
result of only having half as many active connection as the prior profiling run.

Thanks for the reply.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110715204027</emailId><senderName>Brandon Wiley</senderName><senderEmail>brandon@blanu.net</senderEmail><timestampReceived>2011-07-15 20:40:27-0400</timestampReceived><subject>Re: [tor-dev] New Paper: Cloud-based Onion Routing</subject><body>

[Attachment #2 (multipart/alternative)]


On Fri, Jul 15, 2011 at 3:16 PM, Nick Jones &lt;najones@cs.princeton.edu&gt;wrote:

&gt;
&gt;
&gt; On Wednesday, July 13, 2011 at 8:02 PM, Brandon Wiley wrote:
&gt;
&gt; &gt;
&gt; &gt; Cool stuff. I like how the system can be automated and self-funding.
&gt; &gt;
&gt; &gt; With regards to bootstrapping, giving out one node at a time is not a
&gt; useful defense because requests can be parallelized. [1] Moving nodes is
&gt; similarly useless because the attacker can continually map the network using
&gt; free parallelized requests. Therefore, requesting a node address needs to
&gt; cost something. [2] Since you already have tokens, you can just make it cost
&gt; a token to request a node address.
&gt;
&gt; I agree with most of your points, but if we make users redeem a token to in
&gt; order to access bootstrapping, they have to already have tokens, which is
&gt; another bootstrapping problem in itself. Also, a determined adversary could
&gt; just purchase enough tokens to perform the same attacks. Admittedly, we
&gt; might make a lot of money from the censors in the process, which would be
&gt; cool.
&gt;

You have hit upon the two main challenges of censorship-resistant
bootstrapping. Most solutions add a layer which is itself vulnerable to the
same attacks and is therefore not helpful. Through recursive analysis you
eventually come to the initial introduction problem, which you must solve
anyway because the users must obtain the software in the first place. You
therefore need an out-of-band (from the perspective of the censor)
introduction channel. As long as you have such a channel, you might as well
use it to do the rest of the communication necessary for bootstrapping. See
for example my Dust &lt;http://blanu.net/Dust.pdf&gt; paper on using out-of-band
channels to establish secure communication over censored channels.

The second challenge is that, given a method of introduction, the attacker
can map and block the entire network easily. Therefore introductions must
have a non-parallelizable cost. However, if your attacker has enough
resources to pay the cost then you're out of luck. So there is an ongoing
search for a resource which is sufficiently plentiful for normal users to
spend for the purpose of normal introduction, but which is difficult to
obtain in large amounts. Alternatives to money have been suggested such as
computing power, human labor or attention, storage space, etc.. Ultimately,
though, all resources are convertible to and from money. I know of no ideal
solutions to this problem, but the best I've seen limit the damage the
attacker can do by requiring continual expenditure of resources in order to
maintain an ongoing attack.

[Attachment #5 (text/html)]

On Fri, Jul 15, 2011 at 3:16 PM, Nick Jones &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:najones@cs.princeton.edu"&gt;najones@cs.princeton.edu&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;&lt;br&gt;
&lt;br&gt;
On Wednesday, July 13, 2011 at 8:02 PM, Brandon Wiley wrote:&lt;br&gt;
&lt;br&gt;
&gt;&lt;br&gt;
&gt; Cool stuff. I like how the system can be automated and self-funding.&lt;br&gt;
&gt;&lt;br&gt;
&gt; With regards to bootstrapping, giving out one node at a time is not a useful \
defense because requests can be parallelized. [1] Moving nodes is similarly useless \
because the attacker can continually map the network using free parallelized \
requests. Therefore, requesting a node address needs to cost something. [2] Since you \
already have tokens, you can just make it cost a token to request a node address.&lt;br&gt;

&lt;br&gt;
&lt;/div&gt;I agree with most of your points, but if we make users redeem a token to in \
order to access bootstrapping, they have to already have tokens, which is another \
bootstrapping problem in itself. Also, a determined adversary could just purchase \
enough tokens to perform the same attacks. Admittedly, we might make a lot of money \
from the censors in the process, which would be cool.&lt;br&gt; &lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;You \
have hit upon the two main challenges of censorship-resistant bootstrapping. Most \
solutions add a layer which is itself vulnerable to the same attacks and is therefore \
not helpful. Through recursive analysis you eventually come to the initial \
introduction problem, which you must solve anyway because the users must obtain the \
software in the first place. You therefore need an out-of-band (from the perspective \
of the censor) introduction channel. As long as you have such a channel, you might as \
well use it to do the rest of the communication necessary for bootstrapping. See for \
example my &lt;a href="http://blanu.net/Dust.pdf"&gt;Dust&lt;/a&gt; paper on using out-of-band \
channels to establish secure communication over censored channels.&lt;br&gt; &lt;br&gt;The second \
challenge is that, given a method of introduction, the attacker can map and block the \
entire network easily. Therefore introductions must have a non-parallelizable cost. \
However, if your attacker has enough resources to pay the cost then you're out of \
luck. So there is an ongoing search for a resource which is sufficiently plentiful \
for normal users to spend for the purpose of normal introduction, but which is \
difficult to obtain in large amounts. Alternatives to money have been suggested such \
as computing power, human labor or attention, storage space, etc.. Ultimately, \
though, all resources are convertible to and from money. I know of no ideal solutions \
to this problem, but the best I've seen limit the damage the attacker can do by \
requiring continual expenditure of resources in order to maintain an ongoing \
attack.&lt;br&gt; &lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110713170118</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-07-13 17:01:18-0400</timestampReceived><subject>[tor-dev] Tor Relay Setup Wizard</subject><body>

Hi all. Over the last few weeks I've been working on a relay setup
wizard for arm. Its purpose is to make volunteering to be a relay
easy, narrowing the options to those most commonly used and giving
nice descriptions/defaults to encourage good configurations.

At present relay setup for new users, particularly exits, is either
confusing or limited. For users doing it without a controller we have
a deluge of man page options and a confusing bundle of docs. For
Vidalia users, however, it's easy to become a middle hop or bridge,
but the configurations it makes for exits are poor (default exit
policy, no front page, no notice for how to reduce abuse complaints
which probably leads Vidalia exits to be short lived...).

This wizard consists of three pages...

1. Selection for what you'd like to be
http://www.atagar.com/transfer/tmp/arm_wizard1.png

2. Picking your relay options, with both descriptions of the options
and why you'd want to set them
http://www.atagar.com/transfer/tmp/arm_wizard2.png

3. Confirmation for the configuration it's making
http://www.atagar.com/transfer/tmp/arm_wizard3.png

4. ... then in the frozen land of Nador they were forced to eat Sir
Robin's minstrels. And there was much rejoicing.
http://www.atagar.com/transfer/tmp/arm_wizard4.png

My not-so-humble goals for this wizard is for it to become a method we
suggest on the site for setting up an exit (and maybe relays/bridges
too later) so I'd appreciate some feedback! The 1.4.3 release
candidate is available at...
http://www.atagar.com/transfer/tmp/arm-1.4.3rc.tar.bz2

Future plans are automatic signup for Tor Weather and a "Run Tor at
Startup" option (this later one is gonna be tricky, but it's vital if
we want systems like laptops that frequently shut down to be
meaningful relays/bridges).

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714120334</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-07-14 12:03:34-0400</timestampReceived><subject>[tor-dev] Using routers as bridges</subject><body>

Hi folks,

Bridges serve as "unknown" entry points to the TOR network. For this,
part of the TOR network nodes are reserved and unlisted. This is not
good for the performance of the network, and because the network is
relatively small i think the unlisted-nodes strategy will only be a
short term solution.

At the moment i'm working on my own FreedomBox. From this work i got the
following idea: Why not use the DNAT function of a router to forward TOR
traffic to a TOR node? This way you don't need unlisted nodes anymore. A
router-bridge does not have to be a full TOR node....

Unfortunately the standard DNAT functionality of most routers only
support DNAT from the internet to internal addresses. So you need
modified firmware to make this work. Maybe a (slightly modified?)
version of OpenWRT will work.

Router-bridges have a second advantage over real TOR nodes. They can be
easily moved. If a router-bridge gets blocked, you can simply give the
router-bridge to a friend.

To give you an example of internet-internet DNAT i have configured one
of my systems to forward traffic to the TOR website. The URL is:

https://wordpress.hoevenstein.nl/

(If you try the URL you get a message about an invalid certificate of
course)

Let me know what you think about this idea...
Rob van der Hoeven.
http://freedomboxblog.nl


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714144140</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-07-14 14:41:40-0400</timestampReceived><subject>[tor-dev] Nick's planned schedule for Tor 0.2.3.x development</subject><body>

Hi, all!

I'll try to avoid a long-winded mail and instead cut to the chase: I
want Tor releases to come out more frequently, and I'm going to plan a
release schedule for 0.2.3 to make sure it happens.

It's July 2011 now; I want to get 0.2.3.x released in early 2012.  To
that end, I'm going to declare the following tentative and somewhat
arbitrary schedule:

December 1, 2011: Big feature freeze.  No new features that "feel big"
to me get merged into 0.2.3.x after this date, barring exceptional
circumstances[*].

January 6, 2012: Feature freeze.  Barring exceptional circumstances,
no new features get merged to 0.2.3.x after this date, barring
exceptional circumstances[*].  Fixes for non-regression bugs (that is,
those that also existed in 0.2.2.x) may also get deferred if they
aren't too severe.

Some time between Jan 6 and Jan 30: we fork off a maint-0.2.3 branch
and have master become 0.2.4.

When it's ready, 2012: We release 0.2.3.x-rc, see how long everything
took us, and adjust our plans or 0.2.4.x.

Note that the deadlines above are _merge_ freezes, not _submission_
freezes.  If you give me a big patch on Dec 1, and it needs more
review or revision than can get done that day, then it needs to wait
for 0.2.4.

Obviously, this is still up for discussion.  But please remember about
the bikeshed.  Also, please keep the following in mind:

   * Delaying a release in order to merge "one more feature" means
that every *other* feature in the release gets delayed so that the
"one more feature" can hit stable earlier.
   * If we can actually get releases out on a 7-9 month schedule (or
better), the impact of making a feature wait for the next release
becomes less severe than it's been in the past.

[*] Let's not waste time trying in advance to enumerate exceptional
circumstances.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110715164517</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-07-15 16:45:17-0400</timestampReceived><subject>Re: [tor-dev] [tor-relays] CPU utilization for relay</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake swsnyder@snydernet.net (swsnyder@snydernet.net):

&gt; FYI, this is a profile of my Tor v0.2.2.30-rc relay, taken in a 10-minute sampling:
&gt; 
&gt; CPU: CPU with timer interrupt, speed 0 MHz (estimated)
&gt; Profiling through timer interrupt
&gt; samples  %        linenr info                 symbol name
&gt; 3126     29.7290  cast-586.s:9                CAST_encrypt

Can you attach gdb to your relay and set a breakpoint for
CAST_encrypt? We have no idea why this function should be called at
all (unless it is for something like reading keyfiles off disk?) let
alone dominate your profile output.

gdb -p &lt;tor_pid&gt;
(gdb) break CAST_encrypt
(gdb) cont

You may need to stick a 'file /usr/bin/tor' or similar in there.

If you get no hits, try to do it on startup:

gdb /usr/bin/tor

(gdb) break CAST_encrypt
Function "CAST_encrypt" not defined.
Make breakpoint pending on future shared library load? (y or [n]) y
(gdb) run [&lt;tor args&gt;]


If you get any hits, run 'backtrace' and give us the output. You may
need to install some debuginfo packages, but gdb should tell you this
if so.

If anyone playing along at home gets any hits on either of these
breakpoints, let us know.

&gt; 1677     15.9486  sha256-586.s:8              sha256_block_data_order
&gt; 1149     10.9272  aes-586.s:424               _x86_AES_encrypt
&gt; 844       8.0266  sha1-586.s:8                sha1_block_data_order
&gt; 273       2.5963  crypto.c:1649               crypto_digest_get_digest
&gt; 221       2.1018  md32_common.h:283           SHA1_Update
&gt; 182       1.7309  encode.c:190                EVP_EncodeBlock
&gt; 171       1.6262  OpenBSD_malloc_Linux.c:1793 ifree
&gt; 136       1.2934  cast-586.s:379              CAST_decrypt
&gt; 130       1.2363  md32_common.h:348           SHA1_Final
&gt; 127       1.2078  obj_lib.c:66                OBJ_dup
&gt; 122       1.1602  memarea.c:221               memarea_alloc
&gt; 110       1.0461  aes-586.s:1610              _x86_AES_decrypt
&gt; 
&gt; After running for 14 hours, the Tor relay has consumed 1.6% of CPU time.  It is now \
&gt; using 45MB of RAM, servicing 112 active connections. 
&gt; According to http://torstatus.blutmagie.de my Max/Burst/Observed (Bps) bandwidth \
&gt; is: 
&gt; 153600 / 307200 / 127170
&gt; 
&gt; Environment:
&gt; 
&gt; CPU: Pentium-M (Dothan) @ 1.80 GHz
&gt; RAM: 1.0 GB DDR1
&gt; Net: Fast Ethernet connected to a Surfboard cable modem
&gt; 
&gt; CentOS v5.6
&gt; Tor v0.2.2.30-rc
&gt; libevent 2.0.12-stable
&gt; openssl 1.0.0d
&gt; zlib 1.2.5
&gt; glibc 2.5-58
&gt; 
&gt; Just another data point.
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-relays mailing list
&gt; tor-relays@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-relays

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs


[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110713184747</emailId><senderName>Nick Jones</senderName><senderEmail>najones@cs.princeton.edu</senderEmail><timestampReceived>2011-07-13 18:47:47-0400</timestampReceived><subject>[tor-dev] New Paper: Cloud-based Onion Routing</subject><body>

Hi All, 

I'm a graduate student at Princeton, and our research group has recently submitted a \
paper proposing a design for cloud based onion routing. The goal of our research is \
to securely perform onion routing on cloud based infrastructure (like Amazon EC2 and \
Rackspace) while allowing users to retain the same (or almost the same) privacy as \
when using Tor. We distribute trust across multiple cloud providers, and use Chaum's \
e-cash for payment and access control. Additionally, we hope that the elasticity of \
cloud infrastructure will make cloud based OR more censorship resistant than current \
systems. 

This project is still in a relatively early stage, and we would love to get feedback \
from the Tor community. We would welcome any comments/questions/criticisms. 



Our project's website is available at: 

http://sns.cs.princeton.edu/projects/cor/ 


A direct link to our paper is here:

http://www.cs.princeton.edu/~najones/publications/cor-foci11.pdf


Our abstract:

Internet censorship and surveillance have made anonymity tools increasingly critical \
for free and open Internet access. Tor, and its associated ecosystem of vol- unteer \
traffic relays, provides one of the most secure and widely-available means for \
achieving Internet anonymity today. Unfortunately, Tor has limitations, including \
poor performance, inadequate capacity, and a susceptibility to wholesale blocking. \
Rather than utilizing a large number of volunteers (as Tor does), we propose mov- ing \
onion-routing services to the "cloud" to leverage the large capacities, robust \
connectivity, and economies of scale inherent to commercial datacenters. This paper \
de- scribes Cloud-based Onion Routing (COR), which builds onion-routed tunnels over \
multiple anonymity service providers and through multiple cloud hosting providers, \
dividing trust while forcing censors to incur large collat- eral damage. We discuss \
the new security policies and mechanisms needed for such a provider-based ecosys- \
tem, and present some preliminary benchmarks. At to- day's prices, a user could gain \
fast, anonymous network access through COR for only pennies per day.


Thanks!

Nick Jones
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110724154611</emailId><senderName>LETO</senderName><senderEmail>m8rovpdyd@gmail.com</senderEmail><timestampReceived>2011-07-24 15:46:11-0400</timestampReceived><subject>[tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

[Attachment #2 (multipart/alternative)]


Could some of you be so kind to try out my latest version of TorDNSd?

It works a lot like ttdnsd with some additional features:

- Filters to tell TorDNSd what requests to forward directly, forward through
the SOCKS proxy or reject.
- Remaps to define your own query replies (Currently only supports A, MX and
NS replies)
- Interactive shell (tordnsd-shell.exe): config-add settings and see them in
action right away, will add extra features in the future.
- Accepts both UDP and TPC DNS requests, forwards both through TCP requests
- Basic caching of replies (optional)

The rejects are handy to for example prevent leaking .onion requests (or any
request if you want)

You can also find some additional information about this release on my blog
( http://leto-r.blogspot.com/2011/07/tordnsd-v11-is-out.html )

It is written in C# and has been tested by myself under mono 2.6.7 / ubuntu
natty.

Check the default configuration @
https://raw.github.com/LETO-R/TorDNSd/b7aa04e980ad62308d4f2fa3143700c85b537de7/TorDNSd/tordnsd.conffor
the full list of available settings.

You can either download the mono compatible bins (
https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-all-bin.zip ) or
the windows installer (
https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-win-setup.exe )

You can find the source code of these bins @
https://github.com/LETO-R/TorDNSd/tree/b7aa04e980ad62308d4f2fa3143700c85b537de7(make
sure to get the submodules too)

The sourcecode should be compilable using either MonoDevelop 2.4.2 (using
the mono runtime) or Visual Studio 2010.

If you do not run it as root on a non-windows system, a fatal error is
printed since TorDNSd will most likely not be able to bind on port 53.
Specify --no-root to skip this check.

Kind of feedback I'd like of you:

- What OS did you try it on? When ran using mono, what version?
- Did it work? Did it require the elevated rights (root / administrator)?
Did the root-checking work on non-windows systems?
- Did the shell work for you? If not, what issues did you notice? Any
improvements that you suggest?
- Are the settings explained well enough (check tordnsd.conf)?
- Is the supplied default configuration sufficient? Any filter / remaps I
forgot?
- Any other feedback you can think of, don't hold back!

This is my first attempt at a cross-platform .NET project that contains some
non-windows specific code / workarounds (mostly for the shell) so I really
could use the feedback.

If you do not wish to run it as your main dns resolver 'just yet', you can
always test it by using dig (examples: 'dig @127.0.0.1 bla.onion' to test
rejection, or 'dig @127.0.0.1 vescum.tor' to test the remap feature)

All I ask is to stay constructive.

If you wonder, I constantly have TorDNSd (shell) running now and have
configured it as my main dns resolver as I consider it secure. Hope you find
this to be true as well.

- LETO

[Attachment #5 (text/html)]

Could some of you be so kind to try out my latest version of TorDNSd?&lt;br&gt;&lt;br&gt;It works \
a lot like ttdnsd with some additional features:&lt;br&gt;&lt;br&gt;- Filters to tell TorDNSd \
what requests to forward directly, forward through the SOCKS proxy or reject.&lt;br&gt;

- Remaps to define your own query replies (Currently only supports A, MX and NS \
replies)&lt;br&gt;- Interactive shell (tordnsd-shell.exe): config-add settings and see them \
in action right away, will add extra features in the future.&lt;br&gt;

- Accepts both UDP and TPC DNS requests, forwards both through TCP requests&lt;br&gt;- \
Basic caching of replies (optional)&lt;br&gt;&lt;br&gt;The rejects are handy to for example \
prevent leaking .onion requests (or any request if you want)&lt;br&gt;

&lt;br&gt;You can also find some additional information about this release on my blog ( &lt;a \
href="http://leto-r.blogspot.com/2011/07/tordnsd-v11-is-out.html" \
target="_blank"&gt;http://leto-r.blogspot.com/2011/07/tordnsd-v11-is-out.html&lt;/a&gt; )&lt;br&gt; \
&lt;br&gt; It is written in C# and has been tested by myself under mono 2.6.7 / ubuntu \
natty.&lt;br&gt;&lt;br&gt;Check the default configuration @ &lt;a \
href="https://raw.github.com/LETO-R/TorDNSd/b7aa04e980ad62308d4f2fa3143700c85b537de7/TorDNSd/tordnsd.conf" \
target="_blank"&gt;https://raw.github.com/LETO-R/TorDNSd/b7aa04e980ad62308d4f2fa3143700c85b537de7/TorDNSd/tordnsd.conf&lt;/a&gt; \
for the full list of available settings.&lt;br&gt;

&lt;br&gt;You can either download the mono compatible bins ( &lt;a \
href="https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-all-bin.zip" \
target="_blank"&gt;https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-all-bin.zip&lt;/a&gt; \
) or the windows installer ( &lt;a \
href="https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-win-setup.exe" \
target="_blank"&gt;https://github.com/downloads/LETO-R/TorDNSd/tordnsd-v1.1-win-setup.exe&lt;/a&gt; \
)&lt;br&gt;

&lt;br&gt;You can find the source code of these bins @ &lt;a \
href="https://github.com/LETO-R/TorDNSd/tree/b7aa04e980ad62308d4f2fa3143700c85b537de7" \
target="_blank"&gt;https://github.com/LETO-R/TorDNSd/tree/b7aa04e980ad62308d4f2fa3143700c85b537de7&lt;/a&gt; \
(make sure to get the submodules too)&lt;br&gt;

&lt;br&gt;The sourcecode should be compilable using either MonoDevelop 2.4.2 (using the \
mono runtime) or Visual Studio 2010.&lt;br&gt;&lt;br&gt;If you do not run it as root on a \
non-windows system, a fatal error is printed since TorDNSd will most likely not be \
able to bind on port 53. Specify --no-root to skip this check.&lt;br&gt;

&lt;br&gt;Kind of feedback I'd like of you:&lt;br&gt;&lt;br&gt;- What OS did you try it on? When \
ran using mono, what version?&lt;br&gt;- Did it work? Did it require the elevated rights \
(root / administrator)? Did the root-checking work on non-windows systems?&lt;br&gt;

- Did the shell work for you? If not, what issues did you notice? Any improvements \
that you suggest?&lt;br&gt;- Are the settings explained well enough (check \
tordnsd.conf)?&lt;br&gt;- Is the supplied default configuration sufficient? Any filter / \
remaps I forgot?&lt;br&gt;

- Any other feedback you can think of, don't hold back!&lt;br&gt;&lt;br&gt;This is my first \
attempt at a cross-platform .NET project that contains some non-windows specific code \
/ workarounds (mostly for the shell) so I really could use the feedback.&lt;br&gt;

&lt;br&gt;If you do not wish to run it as your main dns resolver 'just yet', you \
can always test it by using dig (examples: 'dig @&lt;a href="http://127.0.0.1" \
target="_blank"&gt;127.0.0.1&lt;/a&gt; bla.onion' to test rejection, or 'dig @&lt;a \
href="http://127.0.0.1" target="_blank"&gt;127.0.0.1&lt;/a&gt; vescum.tor' to test the \
remap feature)&lt;br&gt;

&lt;br&gt;All I ask is to stay constructive.&lt;br&gt;&lt;br&gt;If you wonder, I constantly have \
TorDNSd (shell) running now and have configured it as my main dns resolver as I \
consider it secure. Hope you find this to be true as well.&lt;br&gt; &lt;br&gt;- LETO&lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110622203040</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-06-22 20:30:40-0400</timestampReceived><subject>[tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


After reading Mike's blog post and the material contained in it (via
links) I thought it would be helpful to start a discussion about it.
First of all thanks for explaining the idea of improving the private
browsing mode. That aim seems worthwile but I want to focus more on the
needs for high anonymity systems like Tor (I am one of the JonDos people
to set the records straight).

Thus, first I am not sure about the relationship of the improved private
browsing and the anon mode. It seems like the former is kind of
precondition of the latter and the latter adds some special anon
features (or just layout stuff??): "We would love to be able to ship a
vastly simplified browser extension that contains only a compiled Tor
binary and some minimal addon code that simply "upgrades" the user's
private browsing mode into a fully functional anonymous mode." What
shall the upgrade do exactly? And why having again add-ons that can
probably be toggled on/off and are thus more error-prone than just
having an, say, Tor anon mode? Or is this already included in the Tor
anon mode but only separated in the blog post for explanatory purposes?

Sticking to the blog post (one of) its central idea seems to be to
isolate the identifiers and state to the top-level domain in the URL bar
as "activity in Tor Browser on one site should not trivially
de-anonymize their activity [i.e. the activity of Tor users, G.K.] on
another site to ad networks and exits". I am wondering whether this idea
really helps here at least regarding exit mixes. If one user requests
google.com, mail.google.com and other Google services within the 10
minutes interval (I am simplifying here a bit) without deploying TLS the
exit is still able to connect the whole activity and "sees" which
services that particular user is requesting/using. Even worse, if the
browser session is quite long there is a chance of recognizing that user
again if she happens to have the same exit mix more than once. Thus, I
do not see how that helps avoiding linkability for users that need/want
strong anonymity while surfing the web. Would be good to get that
explained in some detail. Or maybe I am missing a point here.

Now something to the proposed behavior of the referer and window.name.
It is said that they should adhere to the "same-origin policy where
sites from different origins get either no referer, or a referer that is
truncated to the top-level domain". Assuming I understood TorButton's
Smart-Spoofing option properly: Why is it not applied to the
referer/window.name anymore? In other words: Why is the referer (and
window.name) not kept if the user surfs within one domain (let's say
from example.com to foo.example.com and then to foo.bar.example.com)?
Before we implemented almost the same algorithm than Torbutton's
smart-spoof algo in our own extension a while ago we had some
compatibility issues (I remember yahoo.com that needed to have the
referer untouched while surfing within the domain) that got fixed by it
and never popped up again. Why stepping back? The idea "sites should
also be allowed to request an exemption to this rule on a per-site basis
using an html attribute, which could trigger a chrome permissions
request, or simply be granted automatically (on the assumption that they
could just URL smuggle the data)" seems rather awkward and not a good
solution to a problem that is not really one.

One final point: Leaving my previous section aside: Why is the referer
and window.name not treated in the same way as cookies and others in the
proposal. Why having two different policies for identifiers? I am not
sure whether there could emerge some attacks out of that distinction but
my feeling tells me that there should ideally be just one policy that
governs all those identifiers. At least it would probably be easier to
implement and to audit them.

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110622213348</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-22 21:33:48-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

On Wed, 22 Jun 2011 22:30:40 +0200
Georg Koppen &lt;g.koppen@jondos.de&gt; wrote:

&gt; Sticking to the blog post (one of) its central idea seems to be to
&gt; isolate the identifiers and state to the top-level domain in the URL bar
&gt; as "activity in Tor Browser on one site should not trivially
&gt; de-anonymize their activity [i.e. the activity of Tor users, G.K.] on
&gt; another site to ad networks and exits". I am wondering whether this idea
&gt; really helps here at least regarding exit mixes. If one user requests
&gt; google.com, mail.google.com and other Google services within the 10
&gt; minutes interval (I am simplifying here a bit) without deploying TLS the
&gt; exit is still able to connect the whole activity and "sees" which
&gt; services that particular user is requesting/using. Even worse, if the
&gt; browser session is quite long there is a chance of recognizing that user
&gt; again if she happens to have the same exit mix more than once. Thus, I
&gt; do not see how that helps avoiding linkability for users that need/want
&gt; strong anonymity while surfing the web. Would be good to get that
&gt; explained in some detail. Or maybe I am missing a point here.

If you maintain two long sessions within the same Tor Browser Bundle
instance, you're screwed -- not because the exit nodes might be
watching you, but because the web sites' logs can be correlated, and
the *sequence* of exit nodes that your Tor client chose is very likely
to be unique.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110728193303</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-07-28 19:33:03-0400</timestampReceived><subject>[tor-dev] Unused -v and -F options in torperf/trivsocks-client?</subject><body>

Running "make" in torperf, I get errors about unused variables:

$ make
gcc -Wall -Werror -ggdb -c trivsocks-client.c
trivsocks-client.c: In function main':
trivsocks-client.c:452:51: error: variable force' set but not used \
[-Werror=unused-but-set-variable] trivsocks-client.c:452:21: error: variable \
                isVerbose' set but not used [-Werror=unused-but-set-variable]
cc1: all warnings being treated as errors

make: *** [trivsocks-client.o] Error 1

The variables have to do with the -v and -F options, which appear not to
do anything. This patch removes the options, but is it intentional?

David Fifield


["0001-Remove-unused-command-line-options-v-and-F.patch" (text/x-diff)]

From 57b03530ba40e2c24d07daaa38d2b42295b49d8b Mon Sep 17 00:00:00 2001
From: David Fifield &lt;david@bamsoftware.com&gt;
Date: Thu, 28 Jul 2011 19:17:59 +0000
Subject: [PATCH] Remove unused command-line options -v and -F.

---
 trivsocks-client.c |    8 ++------
 1 files changed, 2 insertions(+), 6 deletions(-)

diff --git a/trivsocks-client.c b/trivsocks-client.c
index 1c3d895..70e29a7 100644
--- a/trivsocks-client.c
+++ b/trivsocks-client.c
@@ -449,7 +449,7 @@ main(int argc, char **argv)
 {
   uint32_t sockshost;
   uint16_t socksport;
-  int isSocks4 = 0, isVerbose = 0, isReverse = 0, force = 0;
+  int isSocks4 = 0, isReverse = 0;
   char **arg;
   int n_args;
   uint32_t result = 0;
@@ -470,16 +470,12 @@ main(int argc, char **argv)
   }
 
   while (n_args &amp;&amp; *arg[0] == '-') {
-    if (!strcmp("-v", arg[0]))
-      isVerbose = 1;
-    else if (!strcmp("-4", arg[0]))
+    if (!strcmp("-4", arg[0]))
       isSocks4 = 1;
     else if (!strcmp("-5", arg[0]))
       isSocks4 = 0;
     else if (!strcmp("-x", arg[0]))
       isReverse = 1;
-    else if (!strcmp("-F", arg[0]))
-      force = 1;
     else {
       fprintf(stderr, "Unrecognized flag '%s'\n", arg[0]);
       usage();
-- 
1.7.6



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110729040049</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-29 04:00:49-0400</timestampReceived><subject>Re: [tor-dev] Unused -v and -F options in torperf/trivsocks-client?</subject><body>

Hi David,

On 7/28/11 3:33 PM, David Fifield wrote:
&gt; Running "make" in torperf, I get errors about unused variables:
&gt; 
&gt; $ make
&gt; gcc -Wall -Werror -ggdb -c trivsocks-client.c
&gt; trivsocks-client.c: In function main':
&gt; trivsocks-client.c:452:51: error: variable force' set but not used \
&gt; [-Werror=unused-but-set-variable] trivsocks-client.c:452:21: error: variable \
&gt;                 isVerbose' set but not used [-Werror=unused-but-set-variable]
&gt; cc1: all warnings being treated as errors
&gt; 
&gt; make: *** [trivsocks-client.o] Error 1
&gt; 
&gt; The variables have to do with the -v and -F options, which appear not to
&gt; do anything. This patch removes the options, but is it intentional?

Hmm, for some reason I don't get those errors (or warnings) about unused
variables.  But I think you're right in that these variables can go away.

This is Steven's code, so I'd like to hear his opinion before applying
the patch.  Steven?

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110729193915</emailId><senderName>Steven Murdoch</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-07-29 19:39:15-0400</timestampReceived><subject>Re: [tor-dev] Unused -v and -F options in torperf/trivsocks-client?</subject><body>

Hi Karsten, David,

On 29 Jul 2011, at 05:00, Karsten Loesing wrote:
&gt; Hmm, for some reason I don't get those errors (or warnings) about unused
&gt; variables.  But I think you're right in that these variables can go away.
&gt; 
&gt; This is Steven's code, so I'd like to hear his opinion before applying
&gt; the patch.  Steven?

That patch looks fine to me. I didn't get the warnings either, so perhaps you're using a newer GCC.

While I was testing it, I also wrote a patch to fix compilation on MacOS X.

Steven.

["0001-Fix-compilation-on-MacOS-X.patch" (application/octet-stream)]

From 5179b7f03e77b821de46d9cd3ddfe5e68821a866 Mon Sep 17 00:00:00 2001
From: Steven Murdoch &lt;Steven.Murdoch@cl.cam.ac.uk&gt;
Date: Fri, 29 Jul 2011 16:54:44 +0100
Subject: [PATCH] Fix compilation on MacOS X

- Properly cast parameters to printf
- Replace GNU-specific strndup with tor_strndup
---
 trivsocks-client.c |    2 +-
 util.c             |   23 ++++++++++++++++++++++-
 2 files changed, 23 insertions(+), 2 deletions(-)

diff --git a/trivsocks-client.c b/trivsocks-client.c
index 1c3d895..cff2512 100644
--- a/trivsocks-client.c
+++ b/trivsocks-client.c
@@ -249,7 +249,7 @@ do_http_get(int s, const char *path, const char *hostname, size_t *read_bytes, s
 
 static int
 print_time(struct timeval t) {
-  return printf("%ld %ld ", t.tv_sec, t.tv_usec);
+  return printf("%ld %ld ", (long int)t.tv_sec, (long int)t.tv_usec);
 }
 
 // Timestamps of important events
diff --git a/util.c b/util.c
index 96cee0a..fcc8ef9 100644
--- a/util.c
+++ b/util.c
@@ -73,6 +73,27 @@ read_all(int fd, char *buf, size_t count, int isSocket)
   return numread;
 }
 
+/** Allocate and return a new string containing the first &lt;b&gt;n&lt;/b&gt;
+ * characters of &lt;b&gt;s&lt;/b&gt;.  If &lt;b&gt;s&lt;/b&gt; is longer than &lt;b&gt;n&lt;/b&gt;
+ * characters, only the first &lt;b&gt;n&lt;/b&gt; are copied.  The result is
+ * always NUL-terminated.
+ */
+char *
+tor_strndup(const char *s, size_t n)
+{
+  char *dup;
+  dup = malloc(n+1);
+  /* Performance note: Ordinarily we prefer strlcpy to strncpy.  But
+   * this function gets called a whole lot, and platform strncpy is
+   * much faster than strlcpy when strlen(s) is much longer than n.
+   */
+  if (!dup)
+      return dup;
+  strncpy(dup, s, n);
+  dup[n]='\0';
+  return dup;
+}
+
 /**
  * Read a 16-bit value beginning at &lt;b&gt;cp&lt;/b&gt;.  Equivalent to
  * *(uint16_t*)(cp), but will not cause segfaults on platforms that forbid
@@ -207,7 +228,7 @@ parse_addr_port(int severity, const char *addrport, char **address,
 
   colon = strchr(addrport, ':');
   if (colon) {
-    _address = strndup(addrport, colon-addrport);
+    _address = tor_strndup(addrport, colon-addrport);
     _port = (int) parse_long(colon+1,10,1,65535,NULL,NULL);
     if (!_port) {
       fprintf(stderr, "Port %s out of range\n", colon+1);
-- 
1.7.3.1



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110729203423</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-07-29 20:34:23-0400</timestampReceived><subject>Re: [tor-dev] Unused -v and -F options in torperf/trivsocks-client?</subject><body>

On Fri, Jul 29, 2011 at 08:39:15PM +0100, Steven Murdoch wrote:
&gt; Hi Karsten, David,
&gt; 
&gt; On 29 Jul 2011, at 05:00, Karsten Loesing wrote:
&gt; &gt; Hmm, for some reason I don't get those errors (or warnings) about unused
&gt; &gt; variables.  But I think you're right in that these variables can go away.
&gt; &gt; 
&gt; &gt; This is Steven's code, so I'd like to hear his opinion before applying
&gt; &gt; the patch.  Steven?
&gt; 
&gt; That patch looks fine to me. I didn't get the warnings either, so perhaps you're using a newer GCC.

I've only started seeing those warnings since GCC 4.6. I noticed some
tor commits to fix similar things, for example
https://gitweb.torproject.org/tor.git/commit/a5232e0c4c572cdff85701f698b8b90c9443d7e4.

David Fifield
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110623013442</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 01:34:42-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; Thus, first I am not sure about the relationship of the improved private
&gt; browsing and the anon mode. It seems like the former is kind of
&gt; precondition of the latter and the latter adds some special anon
&gt; features (or just layout stuff??): "We would love to be able to ship a
&gt; vastly simplified browser extension that contains only a compiled Tor
&gt; binary and some minimal addon code that simply "upgrades" the user's
&gt; private browsing mode into a fully functional anonymous mode." What
&gt; shall the upgrade do exactly?

What the upgrade does depends on how good the private browsing mode
is. Historically, browser makers have been very conservative, and are
reluctant to implement new features if there is any possibility of
site breakage.

Additionally, we expect that fingerprinting resistance will be an
ongoing battle: as new browser features are added, new fingerprinting
defenses will be needed. Furthermore, we'll likely be inclined to
deploy unproven but better-than-nothing fingerprinting defenses (so
long as they don't break much), where as the browser vendors may be
more conservative on this front, too.

&gt; And why having again add-ons that can probably be toggled on/off and
&gt; are thus more error-prone than just having an, say, Tor anon mode?
&gt; Or is this already included in the Tor anon mode but only separated
&gt; in the blog post for explanatory purposes?

If we operate by upgrading private browsing mode, we'll effectively
have the "toggle" in a place where users have already been trained by
the UI to go for privacy. Torbutton would become an addon that is only
active in private browsing mode. We expect that the browser vendors
will perform usability studies to determine the best way to provide
users with the UI to enter private browsing mode easily.

We also expect that if browser vendors become serious enough about
privacy, they will be the ones who deal with all the linkability
issues between the private and non-private states, not us.

&gt; Sticking to the blog post (one of) its central idea seems to be to
&gt; isolate the identifiers and state to the top-level domain in the URL bar
&gt; as "activity in Tor Browser on one site should not trivially
&gt; de-anonymize their activity [i.e. the activity of Tor users, G.K.] on
&gt; another site to ad networks and exits". I am wondering whether this idea
&gt; really helps here at least regarding exit mixes. If one user requests
&gt; google.com, mail.google.com and other Google services within the 10
&gt; minutes interval (I am simplifying here a bit) without deploying TLS the
&gt; exit is still able to connect the whole activity and "sees" which
&gt; services that particular user is requesting/using. Even worse, if the
&gt; browser session is quite long there is a chance of recognizing that user
&gt; again if she happens to have the same exit mix more than once. Thus, I
&gt; do not see how that helps avoiding linkability for users that need/want
&gt; strong anonymity while surfing the web. Would be good to get that
&gt; explained in some detail. Or maybe I am missing a point here.

We also hope to provide a "New Identity" functionality to address the
persistent state issue, but perhaps this also should be an explicit
responsibility of the mode rather than the addon..

I hear that Google has actually done some studies of Incognito mode,
and users do expect that they have to close the Incognito mode windows
to clear the Incognito cookies and state from memory. They may only
expect this because it's clear that they're not entirely exiting the
browser via this action, though...

&gt; Now something to the proposed behavior of the referer and window.name.
&gt; It is said that they should adhere to the "same-origin policy where
&gt; sites from different origins get either no referer, or a referer that is
&gt; truncated to the top-level domain". Assuming I understood TorButton's
&gt; Smart-Spoofing option properly: Why is it not applied to the
&gt; referer/window.name anymore? In other words: Why is the referer (and
&gt; window.name) not kept if the user surfs within one domain (let's say
&gt; from example.com to foo.example.com and then to foo.bar.example.com)?

I don't really understand this question. The referer should be kept in
these cases.

&gt; Before we implemented almost the same algorithm than Torbutton's
&gt; smart-spoof algo in our own extension a while ago we had some
&gt; compatibility issues (I remember yahoo.com that needed to have the
&gt; referer untouched while surfing within the domain) that got fixed by it
&gt; and never popped up again. Why stepping back? The idea "sites should
&gt; also be allowed to request an exemption to this rule on a per-site basis
&gt; using an html attribute, which could trigger a chrome permissions
&gt; request, or simply be granted automatically (on the assumption that they
&gt; could just URL smuggle the data)" seems rather awkward and not a good
&gt; solution to a problem that is not really one.
&gt; 
&gt; One final point: Leaving my previous section aside: Why is the referer
&gt; and window.name not treated in the same way as cookies and others in the
&gt; proposal. Why having two different policies for identifiers? I am not
&gt; sure whether there could emerge some attacks out of that distinction but
&gt; my feeling tells me that there should ideally be just one policy that
&gt; governs all those identifiers. At least it would probably be easier to
&gt; implement and to audit them.

Neither of these properties are really identifiers (yes yes,
window.name can store identifiers, but it is more than that). Both are
more like cross-page information channels.

Hence it doesn't make sense to "clear" them like cookies. Instead, It
makes more sense to prohibit information transmission through them in
certain cases. I believe the cases where you want to prohibit the
information transmission end up being the same for both of these
information channels.

To respond to your previous paragraph, it is debatable exactly how
strict a policy we want here, but my guess is that for Tor, we have
enough IP unlinkability such that the answer can be "not very", in
favor of not breaking sites that use these information channels
legitimately.

The fact is that other information channels exist for sites to
communicate information about visitors to their 3rd party content. If
you consider what you actually *can* restrict in terms of information
transmission between sites and their 3rd party elements, the answer is
"not much".

So in my mind, it becomes a question of "What would you be actually
preventing by *completely disabling* referers (and window.name)
entirely?"

It seems to me that the answer to this question is "You only prevent
accidental leakage", because bad actors can use URL params as an
information channel to their 3rd party elements just fine, and
tracking and ad-targeting will continue. In a world without referers,
sites would actually be incentivized to do this information passing,
because ad networks will be able to serve better ads and pay them more
money.

If someone did a crawl of the top 10k sites and found that none of
them would break by disabling or restricting referers, I might change
my mind for Torbutton, because it is unlikely that sites will adapt
just for Torbutton users. However, you still have the property that if
the browser vendors decided to disable referers, sites would build
mechanisms to transmit referer-style information anyway. Hence, when
talking to browser makers, it doesn't make sense to recommend that
they disable referer information. They should instead simply allow
sites to have better privacy controls over them if they wish.

Does this reasoning make sense? I suppose it is somewhat abstract, and
very conditional.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623081924</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-06-23 08:19:24-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt; If you maintain two long sessions within the same Tor Browser Bundle
&gt; instance, you're screwed -- not because the exit nodes might be
&gt; watching you, but because the web sites' logs can be correlated, and
&gt; the *sequence* of exit nodes that your Tor client chose is very likely
&gt; to be unique.

Ah, okay, I did not know that. Thanks for that information. I was just
wondering how the proposed changes to the private browsing mode would
avoid being tracked by exit mixes (as the blog post claimed).

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623095549</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-06-23 09:55:49-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt; Additionally, we expect that fingerprinting resistance will be an
&gt; ongoing battle: as new browser features are added, new fingerprinting
&gt; defenses will be needed. Furthermore, we'll likely be inclined to
&gt; deploy unproven but better-than-nothing fingerprinting defenses (so
&gt; long as they don't break much), where as the browser vendors may be
&gt; more conservative on this front, too.

Yes, that seems likely.

&gt;&gt; And why having again add-ons that can probably be toggled on/off and
&gt;&gt; are thus more error-prone than just having an, say, Tor anon mode?
&gt;&gt; Or is this already included in the Tor anon mode but only separated
&gt;&gt; in the blog post for explanatory purposes?
&gt; 
&gt; If we operate by upgrading private browsing mode, we'll effectively
&gt; have the "toggle" in a place where users have already been trained by
&gt; the UI to go for privacy. Torbutton would become an addon that is only
&gt; active in private browsing mode. 

Okay. That means there is no additional toggling of Torbutton in this
enhanced private mode. The user just enters it and Torbutton is running
and doing its job and if the user does not want it anymore she does not
toggle anything but leaves this enhanced private browsing mode and
that's it, right?

&gt; We also expect that if browser vendors become serious enough about
&gt; privacy, they will be the ones who deal with all the linkability
&gt; issues between the private and non-private states, not us.

Yes, that would be really helpful.

&gt;&gt; If one user requests
&gt;&gt; google.com, mail.google.com and other Google services within the 10
&gt;&gt; minutes interval (I am simplifying here a bit) without deploying TLS the
&gt;&gt; exit is still able to connect the whole activity and "sees" which
&gt;&gt; services that particular user is requesting/using. Even worse, if the
&gt;&gt; browser session is quite long there is a chance of recognizing that user
&gt;&gt; again if she happens to have the same exit mix more than once. Thus, I
&gt;&gt; do not see how that helps avoiding linkability for users that need/want
&gt;&gt; strong anonymity while surfing the web. Would be good to get that
&gt;&gt; explained in some detail. Or maybe I am missing a point here.
&gt; 
&gt; We also hope to provide a "New Identity" functionality to address the
&gt; persistent state issue, but perhaps this also should be an explicit
&gt; responsibility of the mode rather than the addon..

Hmmm... If that is the answer to my questions then there is nothing like
avoiding getting tracked by exit mixes in the concept offered in the
blog post. Okay. How should the "New Identity" functionality work? Is
that identity generated automatically after a certain amount of time has
passed or does a user have to click manually on a button every time?

&gt;&gt; Assuming I understood TorButton's
&gt;&gt; Smart-Spoofing option properly: Why is it not applied to the
&gt;&gt; referer/window.name anymore? In other words: Why is the referer (and
&gt;&gt; window.name) not kept if the user surfs within one domain (let's say
&gt;&gt; from example.com to foo.example.com and then to foo.bar.example.com)?
&gt; 
&gt; I don't really understand this question. The referer should be kept in
&gt; these cases.

That sounds good. Then we probably had just different concepts of SOP in
mind. I was thinking about
http://tools.ietf.org/html/draft-abarth-origin-09 (see: section 3 and
4). That would treat http://example.com, http://foo.example.com and
http://foo.bar.example.com as different origins (let alone mixing
"http://" and "https://" and having different ports).

&gt; Neither of these properties are really identifiers (yes yes,
&gt; window.name can store identifiers, but it is more than that). Both are
&gt; more like cross-page information channels.

Agreed, although the distinction is somewhat blurred here.

&gt; Hence it doesn't make sense to "clear" them like cookies. Instead, It
&gt; makes more sense to prohibit information transmission through them in
&gt; certain cases.

I am not sure about that as "clearing" them for *certain contexts* seems
a good means to prohibit information transmission *in these contexts*:
If there isn't any information it cannot be transmitted (at least not by
referer or windows.name).

&gt; I believe the cases where you want to prohibit the
&gt; information transmission end up being the same for both of these
&gt; information channels.

Yes, that's true.

&gt; To respond to your previous paragraph, it is debatable exactly how
&gt; strict a policy we want here, but my guess is that for Tor, we have
&gt; enough IP unlinkability such that the answer can be "not very", in
&gt; favor of not breaking sites that use these information channels
&gt; legitimately.
&gt; 
&gt; The fact is that other information channels exist for sites to
&gt; communicate information about visitors to their 3rd party content. If
&gt; you consider what you actually *can* restrict in terms of information
&gt; transmission between sites and their 3rd party elements, the answer is
&gt; "not much".
&gt; 
&gt; So in my mind, it becomes a question of "What would you be actually
&gt; preventing by *completely disabling* referers (and window.name)
&gt; entirely?"
&gt; 
&gt; It seems to me that the answer to this question is "You only prevent
&gt; accidental leakage", because bad actors can use URL params as an
&gt; information channel to their 3rd party elements just fine, and
&gt; tracking and ad-targeting will continue. In a world without referers,
&gt; sites would actually be incentivized to do this information passing,
&gt; because ad networks will be able to serve better ads and pay them more
&gt; money.
&gt; 
&gt; If someone did a crawl of the top 10k sites and found that none of
&gt; them would break by disabling or restricting referers, I might change
&gt; my mind for Torbutton, because it is unlikely that sites will adapt
&gt; just for Torbutton users. However, you still have the property that if
&gt; the browser vendors decided to disable referers, sites would build
&gt; mechanisms to transmit referer-style information anyway. Hence, when
&gt; talking to browser makers, it doesn't make sense to recommend that
&gt; they disable referer information. They should instead simply allow
&gt; sites to have better privacy controls over them if they wish.
&gt; 
&gt; Does this reasoning make sense? I suppose it is somewhat abstract, and
&gt; very conditional.

It makes perfect sense to me. Thanks.

Another question came to my mind: You seem to be at pains not to break
parts of the web even in the anon mode even if that boils down to not
implement features that would better fit the needs for people looking
for unlinkability (one thing that comes to my mind here would be having
a context being tab dependent additionally). Why? Why not saying: "This
is Tor's anon mode. It is meant for people that strive for unlinkability
and might break some functionality. You may still use Tor in normal or
private browsing mode though (providing no or less unlinkability on the
browser level)." Do you think that's not worth the effort as Tor's IP
unlinkability is enough here (especially combined with the things you
suggested in the blog post)? I do not know Tor's user base very well but
could imagine that it contains a lot of users that would like to have
more unlinkability than the "we do not want to break any (or almost any)
part of the web for a better anonymity" fraction.

Georg





["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623165545</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 16:55:45-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt;&gt; And why having again add-ons that can probably be toggled on/off and
&gt; &gt;&gt; are thus more error-prone than just having an, say, Tor anon mode?
&gt; &gt;&gt; Or is this already included in the Tor anon mode but only separated
&gt; &gt;&gt; in the blog post for explanatory purposes?
&gt; &gt; 
&gt; &gt; If we operate by upgrading private browsing mode, we'll effectively
&gt; &gt; have the "toggle" in a place where users have already been trained by
&gt; &gt; the UI to go for privacy. Torbutton would become an addon that is only
&gt; &gt; active in private browsing mode. 
&gt; 
&gt; Okay. That means there is no additional toggling of Torbutton in this
&gt; enhanced private mode. The user just enters it and Torbutton is running
&gt; and doing its job and if the user does not want it anymore she does not
&gt; toggle anything but leaves this enhanced private browsing mode and
&gt; that's it, right?

That's correct. If the user wants their regular private browsing mode
back, they would presumably uninstall the extension.

&gt; &gt;&gt; If one user requests
&gt; &gt;&gt; google.com, mail.google.com and other Google services within the 10
&gt; &gt;&gt; minutes interval (I am simplifying here a bit) without deploying TLS the
&gt; &gt;&gt; exit is still able to connect the whole activity and "sees" which
&gt; &gt;&gt; services that particular user is requesting/using. Even worse, if the
&gt; &gt;&gt; browser session is quite long there is a chance of recognizing that user
&gt; &gt;&gt; again if she happens to have the same exit mix more than once. Thus, I
&gt; &gt;&gt; do not see how that helps avoiding linkability for users that need/want
&gt; &gt;&gt; strong anonymity while surfing the web. Would be good to get that
&gt; &gt;&gt; explained in some detail. Or maybe I am missing a point here.
&gt; &gt; 
&gt; &gt; We also hope to provide a "New Identity" functionality to address the
&gt; &gt; persistent state issue, but perhaps this also should be an explicit
&gt; &gt; responsibility of the mode rather than the addon..
&gt; 
&gt; Hmmm... If that is the answer to my questions then there is nothing like
&gt; avoiding getting tracked by exit mixes in the concept offered in the
&gt; blog post. Okay.

That is not entirely true. Because identifiers would be linked to
top-level urlbar domain, gone are the days where exits could insert an
iframe or web-bug into any arbitrary page and use that to track the
user for the duration of the session, regardless of page view.

Instead, they would be pushed back to doing some sort of top-level
redirect (which we hope would be way more visible), or maybe not even
that, depending on how we define redirects with respect to
"top-level".

So no, we are not completely abandoning exits as an adversary with
this threat model. If I'm wrong about something, or you think there
are still attacks exits can perform that we should address somehow,
let me know.

&gt; How should the "New Identity" functionality work? Is
&gt; that identity generated automatically after a certain amount of time has
&gt; passed or does a user have to click manually on a button every time?

I don't know the answer here. This may vary by browser and use case.
For a communications-suite style use case, I think we probably want to
detect inactivity and ask the user if they want to clear state,
because communications-suites are heavy and a pain to relaunch (hence
once opened, they probably will stay open).

For something lighter, like Chrome's Incognito, we may just rely on
the user to leave the mode. This divergence is one of the reasons I
didn't mention the feature in the blog post. 

If you want to track what solution we ultimately deploy for TBB, here
is the ticket you should follow:
https://trac.torproject.org/projects/tor/ticket/523
 
&gt; &gt;&gt; Assuming I understood TorButton's
&gt; &gt;&gt; Smart-Spoofing option properly: Why is it not applied to the
&gt; &gt;&gt; referer/window.name anymore? In other words: Why is the referer (and
&gt; &gt;&gt; window.name) not kept if the user surfs within one domain (let's say
&gt; &gt;&gt; from example.com to foo.example.com and then to foo.bar.example.com)?
&gt; &gt; 
&gt; &gt; I don't really understand this question. The referer should be kept in
&gt; &gt; these cases.
&gt; 
&gt; That sounds good. Then we probably had just different concepts of SOP in
&gt; mind. I was thinking about
&gt; http://tools.ietf.org/html/draft-abarth-origin-09 (see: section 3 and
&gt; 4). That would treat http://example.com, http://foo.example.com and
&gt; http://foo.bar.example.com as different origins (let alone mixing
&gt; "http://" and "https://" and having different ports).

Yeah. The reality is we're basically picking an arbitrary heuristic
for squelching this information channel to find some sweet spot that
minimizes breakage for maximal gain. True same-origin policy may or
may not be relevant here.

Since I personally believe any heuristic squelch is futile against bad
actors, I haven't thought terribly hard about the best "sweet spot"
policy. I just took what Kory Kirk came up with for a GSoC project and
tweaked it slightly to make it symmetric:
https://trac.torproject.org/projects/tor/ticket/2148

This policy will appear as a non-default option in 1.4.0 (it is
already in 1.3.x-alpha), but I think we should make a real decision
about the behavior soon, because having an option just creates a
fingerprinting opportunity as I said in the blog post. I believe the
fingerprinting effect of an option to be worse than doing nothing at
all to referer, since it is global linkability, not just an
information channel between two parties:
https://trac.torproject.org/projects/tor/ticket/3100

I'm still pretty convinced the best solution for Tor is "leave referer
alone", at least until someone shows me the breakage results of a
thorough crawl (which would include web-app site use).

&gt; &gt; Hence it doesn't make sense to "clear" them like cookies. Instead, It
&gt; &gt; makes more sense to prohibit information transmission through them in
&gt; &gt; certain cases.
&gt; 
&gt; I am not sure about that as "clearing" them for *certain contexts* seems
&gt; a good means to prohibit information transmission *in these contexts*:
&gt; If there isn't any information it cannot be transmitted (at least not by
&gt; referer or windows.name).

Perhaps. Right before I abandoned the toggle model for torbutton, one
of the last fixes I did to it was to "clear" window.name on toggle:
https://trac.torproject.org/projects/tor/ticket/1968

I now believe that is the wrong way to think about things.

I think the better solution is to "clear" window.name when the user
enters a new url in the urlbar, which gets covered by making
window.name behave like referer in all cases:
https://trac.torproject.org/projects/tor/ticket/3414

&gt; Another question came to my mind: You seem to be at pains not to break
&gt; parts of the web even in the anon mode even if that boils down to not
&gt; implement features that would better fit the needs for people looking
&gt; for unlinkability (one thing that comes to my mind here would be having
&gt; a context being tab dependent additionally). Why? Why not saying: "This
&gt; is Tor's anon mode. It is meant for people that strive for unlinkability
&gt; and might break some functionality. You may still use Tor in normal or
&gt; private browsing mode though (providing no or less unlinkability on the
&gt; browser level)." Do you think that's not worth the effort as Tor's IP
&gt; unlinkability is enough here (especially combined with the things you
&gt; suggested in the blog post)? I do not know Tor's user base very well but
&gt; could imagine that it contains a lot of users that would like to have
&gt; more unlinkability than the "we do not want to break any (or almost any)
&gt; part of the web for a better anonymity" fraction.

I wish I had better science to give you here on the trade-off we're
going for, but the reality is that we're best-guessing over a very
complex cost/benefit landscape.

We do know for a fact that the easier Tor is to use (which includes
installation, configuration, overall intuitiveness/"familiarity",
compatibility, and performance), the more people will use it
regularly.

We also know for a fact that the more people use Tor, the better the
baseline privacy, anonymity, and censorship resistance properties all
become.

Hence, I tend to make decisions in favor of the usability direction
over minor details, especially ones that don't really prevent bad
actors/adversaries from accomplishing their goals.

The need for science especially comes in on the fingerprinting arena.
Some fingerprinting opportunities may not actually be appealing to
adversaries. Some may even appear appealing in theory, but in practice
would be noticeable to the user, too noisy, and/or too error-prone.
Hence I called for more panopticlick-style studies, especially of
Javascript features, in the blog post.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623171035</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 17:10:35-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt; If you maintain two long sessions within the same Tor Browser Bundle
&gt; &gt; instance, you're screwed -- not because the exit nodes might be
&gt; &gt; watching you, but because the web sites' logs can be correlated, and
&gt; &gt; the *sequence* of exit nodes that your Tor client chose is very likely
&gt; &gt; to be unique.

I'm actually not sure I get what Robert meant by this statement. In
the absence of linked identifiers, the sequence of exit nodes should
not be visible to the adversary. It may be unique, but what allows the
adversary to link it to actually track the user? Reducing the
linkability that allows the adversary to track this sequence is what
the blog post is about...

Or are we assuming that the predominant use case is for a user to
continually navigate only by following links for the duration of their
session (thus being tracked by referer across circuits and exits), as
opposed to entering new urls frequently?

I rarely follow a chain of links for very long. I'd say my mean
link-following browsing session lifetime is waay, waay below the Tor
circuit lifetime of 10min. Unless I fall into a wikipedia hole and
don't stop until I hit philosophy... But that is all the same site,
which can link me with temporary cache or session cookies.

Are my browsing habits atypical?

&gt; Ah, okay, I did not know that. Thanks for that information. I was just
&gt; wondering how the proposed changes to the private browsing mode would
&gt; avoid being tracked by exit mixes (as the blog post claimed).

See my other reply for a response to this question.



--=20
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623173319</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-23 17:33:19-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

On Thu, 23 Jun 2011 10:10:35 -0700
Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt; Thus spake Georg Koppen (g.koppen@jondos.de):
&gt; 
&gt; &gt; &gt; If you maintain two long sessions within the same Tor Browser Bundle
&gt; &gt; &gt; instance, you're screwed -- not because the exit nodes might be
&gt; &gt; &gt; watching you, but because the web sites' logs can be correlated, and
&gt; &gt; &gt; the *sequence* of exit nodes that your Tor client chose is very likely
&gt; &gt; &gt; to be unique.
&gt; 
&gt; I'm actually not sure I get what Robert meant by this statement. In
&gt; the absence of linked identifiers, the sequence of exit nodes should
&gt; not be visible to the adversary. It may be unique, but what allows the
&gt; adversary to link it to actually track the user? Reducing the
&gt; linkability that allows the adversary to track this sequence is what
&gt; the blog post is about...

By session, I meant a sequence of browsing actions that one web site
can link.  (For example, a session in which the user is authenticated
to a web application.)  If the user performs two or more distinct
sessions within the same TBB instance, the browsing actions within
those sessions will use very similar sequences of exit nodes.


&gt; Or are we assuming that the predominant use case is for a user to
&gt; continually navigate only by following links for the duration of their
&gt; session (thus being tracked by referer across circuits and exits), as
&gt; opposed to entering new urls frequently?
&gt; 
&gt; I rarely follow a chain of links for very long. I'd say my mean
&gt; link-following browsing session lifetime is waay, waay below the Tor
&gt; circuit lifetime of 10min. Unless I fall into a wikipedia hole and
&gt; don't stop until I hit philosophy... But that is all the same site,
&gt; which can link me with temporary cache or session cookies.

The issue is that two different sites can use the sequences of exit
nodes to link a session on one site with a concurrent session on
another.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110623175800</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 17:58:00-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Robert Ransom (rransom.8774@gmail.com):

&gt; On Thu, 23 Jun 2011 10:10:35 -0700
&gt; Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; 
&gt; &gt; Thus spake Georg Koppen (g.koppen@jondos.de):
&gt; &gt; 
&gt; &gt; &gt; &gt; If you maintain two long sessions within the same Tor Browser Bundle
&gt; &gt; &gt; &gt; instance, you're screwed -- not because the exit nodes might be
&gt; &gt; &gt; &gt; watching you, but because the web sites' logs can be correlated, and
&gt; &gt; &gt; &gt; the *sequence* of exit nodes that your Tor client chose is very likely
&gt; &gt; &gt; &gt; to be unique.
&gt; &gt; 
&gt; &gt; I'm actually not sure I get what Robert meant by this statement. In
&gt; &gt; the absence of linked identifiers, the sequence of exit nodes should
&gt; &gt; not be visible to the adversary. It may be unique, but what allows the
&gt; &gt; adversary to link it to actually track the user? Reducing the
&gt; &gt; linkability that allows the adversary to track this sequence is what
&gt; &gt; the blog post is about...
&gt; 
&gt; By session, I meant a sequence of browsing actions that one web site
&gt; can link.  (For example, a session in which the user is authenticated
&gt; to a web application.)  If the user performs two or more distinct
&gt; sessions within the same TBB instance, the browsing actions within
&gt; those sessions will use very similar sequences of exit nodes.
&gt; 
&gt; The issue is that two different sites can use the sequences of exit
&gt; nodes to link a session on one site with a concurrent session on
&gt; another.

Woah, we're in the hinterlands, tread carefully :).

When performed by websites, this attack assumes a certain duration of
concurrent use that is sufficient to disambiguate the entire user
population. It also assumes exact concurrent use, or the error starts
to go up at an unknown and population-size dependent rate.

However, when performed by the exits, this linkability is a real
concern. Let's think about that. That sounds more like our
responsibility than the browser makers. Now I think I see what Georg
was getting at. We didn't mention this because the blog post was
directed towards the browser makers.

I've actually been pondering the exit side of this attack for years,
but we've never come to a good conclusion about what solution to
deploy for various reasons. There are impasses in every direction.

Observe:

Does this mean we want a more automatic version of Proposal 171,
something like Robert Hogan proposed? Something per-IP or per
top-level domain name? That is what I've historically argued for, but
I keep getting told it will consume too many circuits and help
bittorrent users (though we have recently discovered how to throttle
those motherfuckers, so perhaps we should just do that).

Or does this mean that Torbutton should be handing different SOCKS
usernames+passwords down to the SOCKS proxy per tab? This latter piece
is very hard to do, it turns out. SOCKS usernames and passwords are
not supported by the Firefox APIs. But that is the easy part, now that
we have control over the source.

The harder problem is the Foxyproxy API problem.. The APIs to do this
type of proxy tracking don't exist, and they don't exist because of
Firefox architectural problems.. But maybe there's a bloody hack to
the source that we can do because we just don't give a damn about
massively violating their architecture to get exactly what we want in
the most expedient way. Maybe.

I still think Tor should just do this, though. Every app should be
made unlinkable by a simple policy there by default, and we should
just rate limit it if it gets to intense (similar to NEWNYM rate
limiting).


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623181945</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 18:19:45-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Mike Perry (mikeperry@fscked.org):

&gt; Thus spake Robert Ransom (rransom.8774@gmail.com):
&gt; 
&gt; &gt; On Thu, 23 Jun 2011 10:10:35 -0700
&gt; &gt; Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; &gt; 
&gt; &gt; &gt; Thus spake Georg Koppen (g.koppen@jondos.de):
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; If you maintain two long sessions within the same Tor Browser Bundle
&gt; &gt; &gt; &gt; &gt; instance, you're screwed -- not because the exit nodes might be
&gt; &gt; &gt; &gt; &gt; watching you, but because the web sites' logs can be correlated, and
&gt; &gt; &gt; &gt; &gt; the *sequence* of exit nodes that your Tor client chose is very likely
&gt; &gt; &gt; &gt; &gt; to be unique.
&gt; &gt; &gt; 
&gt; &gt; &gt; I'm actually not sure I get what Robert meant by this statement. In
&gt; &gt; &gt; the absence of linked identifiers, the sequence of exit nodes should
&gt; &gt; &gt; not be visible to the adversary. It may be unique, but what allows the
&gt; &gt; &gt; adversary to link it to actually track the user? Reducing the
&gt; &gt; &gt; linkability that allows the adversary to track this sequence is what
&gt; &gt; &gt; the blog post is about...
&gt; &gt; 
&gt; &gt; By session, I meant a sequence of browsing actions that one web site
&gt; &gt; can link.  (For example, a session in which the user is authenticated
&gt; &gt; to a web application.)  If the user performs two or more distinct
&gt; &gt; sessions within the same TBB instance, the browsing actions within
&gt; &gt; those sessions will use very similar sequences of exit nodes.
&gt; &gt; 
&gt; &gt; The issue is that two different sites can use the sequences of exit
&gt; &gt; nodes to link a session on one site with a concurrent session on
&gt; &gt; another.
&gt; 
&gt; Woah, we're in the hinterlands, tread carefully :).
&gt;
&gt; I still think Tor should just do this, though. Every app should be
&gt; made unlinkable by a simple policy there by default, and we should
&gt; just rate limit it if it gets to intense (similar to NEWNYM rate
&gt; limiting).

Arg. The demons in my head just told me that there exists a stupid
mashup web-app out there just waiting to ruin our day if we do this in
Tor without browser interaction. The demons tell me at least one
stupid banking or shopping-cart site checks to make sure both the IP
address and the cookies match for all pieces of the app to work
together across domains. I think the demons are right. I think this is
why we created TrackHostExits, but the demons just laugh and tell me
that the hosts are not the same in this case.

So perhaps Torbutton controlled per-tab proxy username+password is the
best option? Oh man am I dreading doing that... (The demons laugh
again.)


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110623184047</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-23 18:40:47-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

On Thu, 23 Jun 2011 11:19:45 -0700
Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt; So perhaps Torbutton controlled per-tab proxy username+password is the
&gt; best option? Oh man am I dreading doing that... (The demons laugh
&gt; again.)

If you do this, you will need to give the user some indication of each
tab's compartment', and some way to move tabs between compartments.

Coloring each tab to indicate its compartment may fail for anomalous
trichromats like me and *will* fail for more thoroughly colorblind
users.  Putting a number or symbol in each tab will confuse most users.

I suggest one compartment per browser window.  (Of course, you can and
should leave more detailed hooks in the browser's source if possible,
in case someone wants to experiment with a different scheme.)


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110710130014</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-07-10 13:00:14-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt; However, when performed by the exits, this linkability is a real
&gt; concern. Let's think about that. That sounds more like our
&gt; responsibility than the browser makers. Now I think I see what Georg
&gt; was getting at. We didn't mention this because the blog post was
&gt; directed towards the browser makers.

Well, my idea was not that sophisticated but yes, it belongs to the
passive attacks available to exit mixes I generally had in mind (and I
agree that the current domain-based proposal makes it way harder for an
active mix attacker). My example used just one session. And I still
would claim that even this gives an exit mix means to track users during
the 10 minutes (and later if the user happens to get the same exit mix
again within the same browsing session). If this is true do you mean
that it is just not worth the effort or is to difficult to explain to
the user (as it is highly probably that avoiding this kind of tracking
implies breaking some functionality in the web (a kind of tab separation
would be necessary but not sufficient))?

Georg




["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110710142024</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-07-10 14:20:24-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt;&gt; Hmmm... If that is the answer to my questions then there is nothing like
&gt;&gt; avoiding getting tracked by exit mixes in the concept offered in the
&gt;&gt; blog post. Okay.
&gt; 
&gt; That is not entirely true. Because identifiers would be linked to
&gt; top-level urlbar domain, gone are the days where exits could insert an
&gt; iframe or web-bug into any arbitrary page and use that to track the
&gt; user for the duration of the session, regardless of page view.
&gt; 
&gt; Instead, they would be pushed back to doing some sort of top-level
&gt; redirect (which we hope would be way more visible), or maybe not even
&gt; that, depending on how we define redirects with respect to
&gt; "top-level".
&gt; 
&gt; So no, we are not completely abandoning exits as an adversary with
&gt; this threat model. If I'm wrong about something, or you think there
&gt; are still attacks exits can perform that we should address somehow,
&gt; let me know.

See my last mail.

&gt;&gt; Another question came to my mind: You seem to be at pains not to break
&gt;&gt; parts of the web even in the anon mode even if that boils down to not
&gt;&gt; implement features that would better fit the needs for people looking
&gt;&gt; for unlinkability (one thing that comes to my mind here would be having
&gt;&gt; a context being tab dependent additionally). Why? Why not saying: "This
&gt;&gt; is Tor's anon mode. It is meant for people that strive for unlinkability
&gt;&gt; and might break some functionality. You may still use Tor in normal or
&gt;&gt; private browsing mode though (providing no or less unlinkability on the
&gt;&gt; browser level)." Do you think that's not worth the effort as Tor's IP
&gt;&gt; unlinkability is enough here (especially combined with the things you
&gt;&gt; suggested in the blog post)? I do not know Tor's user base very well but
&gt;&gt; could imagine that it contains a lot of users that would like to have
&gt;&gt; more unlinkability than the "we do not want to break any (or almost any)
&gt;&gt; part of the web for a better anonymity" fraction.
&gt; 
&gt; I wish I had better science to give you here on the trade-off we're
&gt; going for, but the reality is that we're best-guessing over a very
&gt; complex cost/benefit landscape.

That's true.

&gt; We do know for a fact that the easier Tor is to use (which includes
&gt; installation, configuration, overall intuitiveness/"familiarity",
&gt; compatibility, and performance), the more people will use it
&gt; regularly.

That seems to hold for every piece of software, I guess.

&gt; We also know for a fact that the more people use Tor, the better the
&gt; baseline privacy, anonymity, and censorship resistance properties all
&gt; become.

Agreed.

&gt; Hence, I tend to make decisions in favor of the usability direction
&gt; over minor details, especially ones that don't really prevent bad
&gt; actors/adversaries from accomplishing their goals.

That is definitely a good approach. But maybe there is research to be
done here as well. Just a rough (and in part research) idea that I had
in mind while asking you the question above: What about if we first
started looking at different services offered in the web whether they
can be deployed anonymously *at all* (or maybe more precisely (but not
much): that can be deployed in a way that there is either no linkability
at all or the linkability is not strong enough to endanger the user)
(that would be worth some research, I guess)? We would probably find
some services where we had to say: "Well, there is no way to get them
used anonymously due to their nature and the power of the companies
and/or owners behind them." (Facebook comes here to my mind as a
candidate and the Google universe as well due to the power Google has).
Should we say we make the Tor anon mode compatible with these services
nevertheless (due to usability issues) and abandon stronger anonymity
measures? I would say no. Not at all. Rather we should be honest and
say: "Dear User, surfing anonymously AND using Facebook does not work.
You may use the Tor anon mode for that purpose though but there is a
high probability that it breaks functionality." The idea of getting more
users due to being not too strict here might be appealing but is not the
right decision in the end. I think one has to realize that there are
services in the web that are *designed* in a way that one EITHER may use
them OR use anonymity services. Sure, the devil is in the details (e.g.
there are probably a lot of services that may be usable anonymously but
then are accompanied with a certain lack of usability. What about them?
Should we decide against usability again or should we loosen our means
to provide unlinkability here?) but that does not mean there is no way
to find a good solution though. In short (and still roughly): I would
like to start thinking from having all means available to surf the web
anonymously and then downgrade them piece-by-piece to reach a trade-off
between anonymity and usability. Services that may not be used
anonymously at all would not trigger such a painful downgrade ("painful"
as one usually tries first to hack around existing problems encountering
unbelievable design issues and bugs and has to concede finally that it
is in the user's interest to exclude that feature (again)).

&gt; The need for science especially comes in on the fingerprinting arena.
&gt; Some fingerprinting opportunities may not actually be appealing to
&gt; adversaries. Some may even appear appealing in theory, but in practice
&gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt; Hence I called for more panopticlick-style studies, especially of
&gt; Javascript features, in the blog post.

Yes, that is definitely a good idea though I tend to avoid them all even
if currently no adversary is using them (especially if no usability
issue is at stake). First: no one knows whether one did not miss an
attacker using this kind of attack vector and second: Getting rid of
attack vectors is a good thing per se.

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110711224453</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-07-11 22:44:53-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt; However, when performed by the exits, this linkability is a real
&gt; &gt; concern. Let's think about that. That sounds more like our
&gt; &gt; responsibility than the browser makers. Now I think I see what Georg
&gt; &gt; was getting at. We didn't mention this because the blog post was
&gt; &gt; directed towards the browser makers.
&gt; 
&gt; Well, my idea was not that sophisticated but yes, it belongs to the
&gt; passive attacks available to exit mixes I generally had in mind (and I
&gt; agree that the current domain-based proposal makes it way harder for an
&gt; active mix attacker). My example used just one session. And I still
&gt; would claim that even this gives an exit mix means to track users during
&gt; the 10 minutes (and later if the user happens to get the same exit mix
&gt; again within the same browsing session). If this is true do you mean
&gt; that it is just not worth the effort or is to difficult to explain to
&gt; the user (as it is highly probably that avoiding this kind of tracking
&gt; implies breaking some functionality in the web (a kind of tab separation
&gt; would be necessary but not sufficient))?

I'm confused now. You're basically just talking about cookies, cache,
and other stored identifiers at this point, right?

Single-site linkability due to information the user has provided to
the website is outside of Tor's threat model. That is what https is
for (and also why we ship HTTPS-Everywhere with the Tor Browser
Bundle).


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110711230848</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-07-11 23:08:48-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt; Hence, I tend to make decisions in favor of the usability direction
&gt; &gt; over minor details, especially ones that don't really prevent bad
&gt; &gt; actors/adversaries from accomplishing their goals.
&gt; 
&gt; That is definitely a good approach. But maybe there is research to be
&gt; done here as well. Just a rough (and in part research) idea that I had
&gt; in mind while asking you the question above: What about if we first
&gt; started looking at different services offered in the web whether they
&gt; can be deployed anonymously *at all* (or maybe more precisely (but not
&gt; much): that can be deployed in a way that there is either no linkability
&gt; at all or the linkability is not strong enough to endanger the user)
&gt; (that would be worth some research, I guess)?

What technical properties of the web makes such services impossible to
use? Most of the ones I can think of are problematic because of "Layer
8" issues like users divilging too much information to specific
services.

&gt; We would probably find some services where we had to say: "Well,
&gt; there is no way to get them used anonymously due to their nature and
&gt; the power of the companies and/or owners behind them." (Facebook
&gt; comes here to my mind as a candidate and the Google universe as well
&gt; due to the power Google has).  Should we say we make the Tor anon
&gt; mode compatible with these services nevertheless (due to usability
&gt; issues) and abandon stronger anonymity measures? I would say no. Not
&gt; at all. Rather we should be honest and say: "Dear User, surfing
&gt; anonymously AND using Facebook does not work.  You may use the Tor
&gt; anon mode for that purpose though but there is a high probability
&gt; that it breaks functionality." 

How do we be "honest"? Filter their browsing?

&gt; The idea of getting more users due to being not too strict here
&gt; might be appealing but is not the right decision in the end. I think
&gt; one has to realize that there are services in the web that are
&gt; *designed* in a way that one EITHER may use them OR use anonymity
&gt; services. Sure, the devil is in the details (e.g.  there are
&gt; probably a lot of services that may be usable anonymously but then
&gt; are accompanied with a certain lack of usability. What about them?
&gt; Should we decide against usability again or should we loosen our
&gt; means to provide unlinkability here?) but that does not mean there
&gt; is no way to find a good solution though. 

At the end of the day, I don't believe we have to sacrifice much in
terms of usability if we properly reason through the adversary
capabilities.

&gt; In short (and still roughly): I would like to start thinking from
&gt; having all means available to surf the web anonymously and then
&gt; downgrade them piece-by-piece to reach a trade-off between anonymity
&gt; and usability.  Services that may not be used anonymously at all
&gt; would not trigger such a painful downgrade ("painful" as one usually
&gt; tries first to hack around existing problems encountering
&gt; unbelievable design issues and bugs and has to concede finally that
&gt; it is in the user's interest to exclude that feature (again)).

Downgrading privacy would be a UI nightmare that no one would
understand how to use, but assuming we can solve that problem: if we
can find a way to apply these downgrade options to specific urlbar
domains, this might make sense. Otherwise you introduce too many
global fingerprinting issues by providing different privacy options.

What do you have in mind in terms of stricter controls?

&gt; &gt; The need for science especially comes in on the fingerprinting arena.
&gt; &gt; Some fingerprinting opportunities may not actually be appealing to
&gt; &gt; adversaries. Some may even appear appealing in theory, but in practice
&gt; &gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt; &gt; Hence I called for more panopticlick-style studies, especially of
&gt; &gt; Javascript features, in the blog post.
&gt; 
&gt; Yes, that is definitely a good idea though I tend to avoid them all even
&gt; if currently no adversary is using them (especially if no usability
&gt; issue is at stake). First: no one knows whether one did not miss an
&gt; attacker using this kind of attack vector and second: Getting rid of
&gt; attack vectors is a good thing per se.

But going back to your original point, I contend you're not getting
rid of any attack vectors by eliminating window.name and referer
transmission. The adversary still has plenty of other ways to
transmit the same information to 3rd party elements..

You're just preventing "accidental" information leakage at the cost of
breaking functionality.

The ad networks will adapt to this sort of change, and then you're
right back where you started in terms of actual tracking, after years
of punishing your users with broken sites..


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110712051736</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-07-12 05:17:36-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt; I'm confused now. You're basically just talking about cookies, cache,
&gt; and other stored identifiers at this point, right?

Yes.

&gt; Single-site linkability due to information the user has provided to
&gt; the website is outside of Tor's threat model. That is what https is
&gt; for (and also why we ship HTTPS-Everywhere with the Tor Browser
&gt; Bundle).

Ah, okay that makes sense. I did not know that. Sorry for bothering you
in this regard.


Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110712055758</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-07-12 05:57:58-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt;&gt; That is definitely a good approach. But maybe there is research to be
&gt;&gt; done here as well. Just a rough (and in part research) idea that I had
&gt;&gt; in mind while asking you the question above: What about if we first
&gt;&gt; started looking at different services offered in the web whether they
&gt;&gt; can be deployed anonymously *at all* (or maybe more precisely (but not
&gt;&gt; much): that can be deployed in a way that there is either no linkability
&gt;&gt; at all or the linkability is not strong enough to endanger the user)
&gt;&gt; (that would be worth some research, I guess)?
&gt; 
&gt; What technical properties of the web makes such services impossible to
&gt; use?

The web is not the right object to reason about here. The more
interesting question would be "What techical properties of a service
makes it impossible to get used anonymously?" That remains to be
researched. At the end, maybe there isn't any (though I doubt that).

&gt; Most of the ones I can think of are problematic because of "Layer
&gt; 8" issues like users divilging too much information to specific
&gt; services.

That may hold for most services, yes.

&gt;&gt; We would probably find some services where we had to say: "Well,
&gt;&gt; there is no way to get them used anonymously due to their nature and
&gt;&gt; the power of the companies and/or owners behind them." (Facebook
&gt;&gt; comes here to my mind as a candidate and the Google universe as well
&gt;&gt; due to the power Google has).  Should we say we make the Tor anon
&gt;&gt; mode compatible with these services nevertheless (due to usability
&gt;&gt; issues) and abandon stronger anonymity measures? I would say no. Not
&gt;&gt; at all. Rather we should be honest and say: "Dear User, surfing
&gt;&gt; anonymously AND using Facebook does not work.  You may use the Tor
&gt;&gt; anon mode for that purpose though but there is a high probability
&gt;&gt; that it breaks functionality." 
&gt; 
&gt; How do we be "honest"? Filter their browsing?

No, not at all. That sentence in quotes was not meant literally (in the
sense that we pop up a dialog and show that sentence to the user). The
idea would be (as I wrote above) not to start a race to the bottom and
adapt (i.e. weaken) the unlinkability features to get the anon mode
working with thoses sites as well. That in turn could mean that these
sites break (worst case) while being used in anon mode or are "just"
more inconvenient to use then.

&gt;&gt; The idea of getting more users due to being not too strict here
&gt;&gt; might be appealing but is not the right decision in the end. I think
&gt;&gt; one has to realize that there are services in the web that are
&gt;&gt; *designed* in a way that one EITHER may use them OR use anonymity
&gt;&gt; services. Sure, the devil is in the details (e.g.  there are
&gt;&gt; probably a lot of services that may be usable anonymously but then
&gt;&gt; are accompanied with a certain lack of usability. What about them?
&gt;&gt; Should we decide against usability again or should we loosen our
&gt;&gt; means to provide unlinkability here?) but that does not mean there
&gt;&gt; is no way to find a good solution though. 
&gt; 
&gt; At the end of the day, I don't believe we have to sacrifice much in
&gt; terms of usability if we properly reason through the adversary
&gt; capabilities.

I would be glad if that would be the case but I doubt that (having e.g.
Facebook in mind).

&gt;&gt; In short (and still roughly): I would like to start thinking from
&gt;&gt; having all means available to surf the web anonymously and then
&gt;&gt; downgrade them piece-by-piece to reach a trade-off between anonymity
&gt;&gt; and usability.  Services that may not be used anonymously at all
&gt;&gt; would not trigger such a painful downgrade ("painful" as one usually
&gt;&gt; tries first to hack around existing problems encountering
&gt;&gt; unbelievable design issues and bugs and has to concede finally that
&gt;&gt; it is in the user's interest to exclude that feature (again)).
&gt; 
&gt; Downgrading privacy would be a UI nightmare that no one would
&gt; understand how to use, but assuming we can solve that problem: if we
&gt; can find a way to apply these downgrade options to specific urlbar
&gt; domains, this might make sense. Otherwise you introduce too many
&gt; global fingerprinting issues by providing different privacy options.

No, you got me wrong here. The downgrading occurs while designing the
anon mode not while using it. There should be just one mode in order to
avoid fingerprinting issues. It is merely meant as a design principle
for the dev: starting with all we can get and then downgrading our
defenses until we reach a good balance between usability and anon features.

&gt; What do you have in mind in terms of stricter controls?

Hmmm... Dunno what you mean here.

&gt;&gt;&gt; The need for science especially comes in on the fingerprinting arena.
&gt;&gt;&gt; Some fingerprinting opportunities may not actually be appealing to
&gt;&gt;&gt; adversaries. Some may even appear appealing in theory, but in practice
&gt;&gt;&gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt;&gt;&gt; Hence I called for more panopticlick-style studies, especially of
&gt;&gt;&gt; Javascript features, in the blog post.
&gt;&gt;
&gt;&gt; Yes, that is definitely a good idea though I tend to avoid them all even
&gt;&gt; if currently no adversary is using them (especially if no usability
&gt;&gt; issue is at stake). First: no one knows whether one did not miss an
&gt;&gt; attacker using this kind of attack vector and second: Getting rid of
&gt;&gt; attack vectors is a good thing per se.
&gt; 
&gt; But going back to your original point, I contend you're not getting
&gt; rid of any attack vectors by eliminating window.name and referer
&gt; transmission. The adversary still has plenty of other ways to
&gt; transmit the same information to 3rd party elements..

Yes, that's true.

&gt; You're just preventing "accidental" information leakage at the cost of
&gt; breaking functionality.
&gt; The ad networks will adapt to this sort of change, and then you're
&gt; right back where you started in terms of actual tracking, after years
&gt; of punishing your users with broken sites..

This depends on how one designs the single features. But I got your point.


Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110714022659</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-07-14 02:26:59-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt;&gt; That is definitely a good approach. But maybe there is research to be
&gt; &gt;&gt; done here as well. Just a rough (and in part research) idea that I had
&gt; &gt;&gt; in mind while asking you the question above: What about if we first
&gt; &gt;&gt; started looking at different services offered in the web whether they
&gt; &gt;&gt; can be deployed anonymously *at all* (or maybe more precisely (but not
&gt; &gt;&gt; much): that can be deployed in a way that there is either no linkability
&gt; &gt;&gt; at all or the linkability is not strong enough to endanger the user)
&gt; &gt;&gt; (that would be worth some research, I guess)?
&gt; &gt; 
&gt; &gt; What technical properties of the web makes such services impossible to
&gt; &gt; use?
&gt; 
&gt; The web is not the right object to reason about here. The more
&gt; interesting question would be "What techical properties of a service
&gt; makes it impossible to get used anonymously?" That remains to be
&gt; researched. At the end, maybe there isn't any (though I doubt that).

Sure, anonymity is by definition impossible for things that require a
name. As long as that name can be an ephemeral pseudonym, I think
we're good on the web. 

But once you start getting into real personal and/or biometric (even
just a photo) details, you obviously lose your anonymity set. Again, I
think what we're talking about here is "Layer 8".

&gt; &gt; Most of the ones I can think of are problematic because of "Layer
&gt; &gt; 8" issues like users divilging too much information to specific
&gt; &gt; services.
&gt; 
&gt; That may hold for most services, yes.
&gt;
&gt; &gt;&gt; The idea of getting more users due to being not too strict here
&gt; &gt;&gt; might be appealing but is not the right decision in the end. I think
&gt; &gt;&gt; one has to realize that there are services in the web that are
&gt; &gt;&gt; *designed* in a way that one EITHER may use them OR use anonymity
&gt; &gt;&gt; services. Sure, the devil is in the details (e.g.  there are
&gt; &gt;&gt; probably a lot of services that may be usable anonymously but then
&gt; &gt;&gt; are accompanied with a certain lack of usability. What about them?
&gt; &gt;&gt; Should we decide against usability again or should we loosen our
&gt; &gt;&gt; means to provide unlinkability here?) but that does not mean there
&gt; &gt;&gt; is no way to find a good solution though. 
&gt; &gt; 
&gt; &gt; At the end of the day, I don't believe we have to sacrifice much in
&gt; &gt; terms of usability if we properly reason through the adversary
&gt; &gt; capabilities.
&gt; 
&gt; I would be glad if that would be the case but I doubt that (having e.g.
&gt; Facebook in mind).

Can you provide specific concerns about facebook wrt the properties
from the blog post?

&gt; &gt;&gt; In short (and still roughly): I would like to start thinking from
&gt; &gt;&gt; having all means available to surf the web anonymously and then
&gt; &gt;&gt; downgrade them piece-by-piece to reach a trade-off between anonymity
&gt; &gt;&gt; and usability.  Services that may not be used anonymously at all
&gt; &gt;&gt; would not trigger such a painful downgrade ("painful" as one usually
&gt; &gt;&gt; tries first to hack around existing problems encountering
&gt; &gt;&gt; unbelievable design issues and bugs and has to concede finally that
&gt; &gt;&gt; it is in the user's interest to exclude that feature (again)).
&gt; &gt; 
&gt; &gt; Downgrading privacy would be a UI nightmare that no one would
&gt; &gt; understand how to use, but assuming we can solve that problem: if we
&gt; &gt; can find a way to apply these downgrade options to specific urlbar
&gt; &gt; domains, this might make sense. Otherwise you introduce too many
&gt; &gt; global fingerprinting issues by providing different privacy options.
&gt; 
&gt; No, you got me wrong here. The downgrading occurs while designing the
&gt; anon mode not while using it. There should be just one mode in order to
&gt; avoid fingerprinting issues. It is merely meant as a design principle
&gt; for the dev: starting with all we can get and then downgrading our
&gt; defenses until we reach a good balance between usability and anon features.

Ok. Let's try to do this. Where do we start from? Can we start from
the design I proposed and make it more strict?
 
&gt; &gt; What do you have in mind in terms of stricter controls?
&gt; 
&gt; Hmmm... Dunno what you mean here.

What changes to the design might you propose?

&gt; &gt;&gt;&gt; The need for science especially comes in on the fingerprinting arena.
&gt; &gt;&gt;&gt; Some fingerprinting opportunities may not actually be appealing to
&gt; &gt;&gt;&gt; adversaries. Some may even appear appealing in theory, but in practice
&gt; &gt;&gt;&gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt; &gt;&gt;&gt; Hence I called for more panopticlick-style studies, especially of
&gt; &gt;&gt;&gt; Javascript features, in the blog post.
&gt; &gt;&gt;
&gt; &gt;&gt; Yes, that is definitely a good idea though I tend to avoid them all even
&gt; &gt;&gt; if currently no adversary is using them (especially if no usability
&gt; &gt;&gt; issue is at stake). First: no one knows whether one did not miss an
&gt; &gt;&gt; attacker using this kind of attack vector and second: Getting rid of
&gt; &gt;&gt; attack vectors is a good thing per se.
&gt; &gt; 
&gt; &gt; But going back to your original point, I contend you're not getting
&gt; &gt; rid of any attack vectors by eliminating window.name and referer
&gt; &gt; transmission. The adversary still has plenty of other ways to
&gt; &gt; transmit the same information to 3rd party elements..
&gt; 
&gt; Yes, that's true.

Amusing story: I checked to see if Google+ might be using Google
Chrome's privacy-preserving web-send feature
(http://web-send.org/features.html) for their "+1" like button, and I
discovered that sites who source the +1 button were encoding their
URLs as a GET parameter to plus.google.com. So any referer protection
you might expect to gain in the short term is already gone against
Google. I think identifier transmission is really what is important in
this case.

I am also pretty disappointed that Google is not even opting to use
their own privacy-preserving submission system. Google+ seems like a
great opportuity to push the adoption of web-send, so that 3rd-party
identifier isolation can be done without breakage.

Folks who are inclined to making media shitstorms should try to jump
on this one..

&gt; &gt; You're just preventing "accidental" information leakage at the cost of
&gt; &gt; breaking functionality.
&gt; &gt; The ad networks will adapt to this sort of change, and then you're
&gt; &gt; right back where you started in terms of actual tracking, after years
&gt; &gt; of punishing your users with broken sites..
&gt; 
&gt; This depends on how one designs the single features. But I got your point.

If you want to suggest how to fine-tune the referer/window.name
policy, let's discuss that. 

More broadly, perhaps there is some balance of per-tab isolation and
origin isolation that is easily achievable in Firefox? In my
experience, per-tab isolation is extremely hard. How much of that have
you already implemented?



-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110718143831</emailId><senderName>Georg Koppen</senderName><senderEmail>g.koppen@jondos.de</senderEmail><timestampReceived>2011-07-18 14:38:31-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


&gt;&gt;&gt; What technical properties of the web makes such services impossible to
&gt;&gt;&gt; use?
&gt;&gt;
&gt;&gt; The web is not the right object to reason about here. The more
&gt;&gt; interesting question would be "What techical properties of a service
&gt;&gt; makes it impossible to get used anonymously?" That remains to be
&gt;&gt; researched. At the end, maybe there isn't any (though I doubt that).
&gt; 
&gt; Sure, anonymity is by definition impossible for things that require a
&gt; name. As long as that name can be an ephemeral pseudonym, I think
&gt; we're good on the web. 
&gt; 
&gt; But once you start getting into real personal and/or biometric (even
&gt; just a photo) details, you obviously lose your anonymity set. Again, I
&gt; think what we're talking about here is "Layer 8".

Sure, as no layer between 1 and 7 is involved it is per definitionem
"layer" 8.

&gt;&gt; I would be glad if that would be the case but I doubt that (having e.g.
&gt;&gt; Facebook in mind).
&gt; 
&gt; Can you provide specific concerns about facebook wrt the properties
&gt; from the blog post?

Not yet, no. I am not a Facebook user and have therefore to look at
research papers investigating it. And the things I read e.g. in
http://www.research.att.com/~bala/papers/w2sp11.pdf or in
http://www.research.att.com/~bala/papers/wosn09.pdf do not seem to break
the idea proposed in the blog post. But again, there is research to be
done here, I guess. Redirects (you mentioned them already) could pose a
serious threat to the approach in the blog post, though (systems like
Phorm http://www.cl.cam.ac.uk/~rnc1/080518-phorm.pdf come to my mind).

&gt;&gt; No, you got me wrong here. The downgrading occurs while designing the
&gt;&gt; anon mode not while using it. There should be just one mode in order to
&gt;&gt; avoid fingerprinting issues. It is merely meant as a design principle
&gt;&gt; for the dev: starting with all we can get and then downgrading our
&gt;&gt; defenses until we reach a good balance between usability and anon features.
&gt; 
&gt; Ok. Let's try to do this. Where do we start from? Can we start from
&gt; the design I proposed and make it more strict?

Yes, good idea.

&gt;&gt;&gt; What do you have in mind in terms of stricter controls?
&gt;&gt;
&gt;&gt; Hmmm... Dunno what you mean here.
&gt; 
&gt; What changes to the design might you propose?

There are basically two points to be mentioned here IMO:

1) Having a tab (window) isolation additionally (see my comments below)

and

2) Having some means to break the linkage between the same domain called
more than once in a tab. That would be the best I can imagine and would
help against attacks using redirects as well but is hard to get right.
E.g. one had to give the user means to fine-tune the default setting to
their needs without ending up in a UI nightmare. And there are probably
numerous other pitfalls lurking here... We have already done some basic
research (we supervised a BA thesis investigating this concerning
cookies) but there is still a lot to do. But yes, I would like to have
that feature and invest some energy to investigate if one can get it
right in a meaningful way.

&gt;&gt;&gt; You're just preventing "accidental" information leakage at the cost of
&gt;&gt;&gt; breaking functionality.
&gt;&gt;&gt; The ad networks will adapt to this sort of change, and then you're
&gt;&gt;&gt; right back where you started in terms of actual tracking, after years
&gt;&gt;&gt; of punishing your users with broken sites..
&gt;&gt;
&gt;&gt; This depends on how one designs the single features. But I got your point.
&gt; 
&gt; If you want to suggest how to fine-tune the referer/window.name
&gt; policy, let's discuss that. 

Dunno. I think the smart-spoof functionality is working pretty well. I
am not sure if you take special care regarding third party content. We
check for this and leave the referer unmodified as an attacker does not
gain any information out of it (to the contrary it might be strange if
someone does not send a referer while requesting a third party image or
an other third party resource).

&gt; More broadly, perhaps there is some balance of per-tab isolation and
&gt; origin isolation that is easily achievable in Firefox?

I hope so (at least if we had a Firefox fork that would not be much of a
problem anymore). The Multifox Add-On
(http://br.mozdev.org/multifox/all.html) claims to have implemented per
tab identities and I have looked at it superficially. It is quite
promising and deserves a thorough test.

&gt; In my
&gt; experience, per-tab isolation is extremely hard.

I know.

&gt; How much of that have you already implemented?

Nothing yet. Frankly, I have not had the time to do so. But we have good
chances to get a research grant in the near future (i.e. next 3-4
months) for the next 2 years and the tab isolation (not only for cookies
but for DOM storage and similar stuff as well) and ( 2) mentioned above
(we'll see how far I'll get in this regard) are my first
(sub)project(s). And even if we do not get that grant implementing at
least a tab separation will be my next major task I guess.

Regarding the research grant: I already wrote pde and asked him whether
he has some interesting stuff that we should try to incorporate into the
application. If you (Mike) have something don't hesitate and drop me a
mail. We still have the opportunity to move the things we already have a
bit around to get something we overlooked into our proposal (the
deadline is end of July). The topic is investigating and solving issues
regarding an anonymous browser (profile) and to develop one that is
resilient to e.g. different fingerprinting attacks and tracking means in
general.

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110726222616</emailId><senderName>intrigeri</senderName><senderEmail>intrigeri@boum.org</senderEmail><timestampReceived>2011-07-26 22:26:16-0400</timestampReceived><subject>Re: [tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

Hi,

LETO wrote (24 Jul 2011 15:46:11 GMT) :
&gt; Could some of you be so kind to try out my latest version of TorDNSd?

&gt; It works a lot like ttdnsd with some additional features:

Does TorDNSd use a single remote recursive DNS listener as its main
source, like ttdnsd does? Or does it use the Tor resolver for requests
it is able to deal with (namely: A requests)?

Bye,
--
  intrigeri &lt;intrigeri@boum.org&gt;
  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
  | So what?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110726224521</emailId><senderName>LETO</senderName><senderEmail>m8rovpdyd@gmail.com</senderEmail><timestampReceived>2011-07-26 22:45:21-0400</timestampReceived><subject>Re: [tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

[Attachment #2 (multipart/alternative)]


It can use one or multiple remote dns servers (by default the google ones)
meaning you can perform all queries (not just 'A' ones)

- LETO

On Tue, Jul 26, 2011 at 10:26 PM, intrigeri &lt;intrigeri@boum.org&gt; wrote:

&gt; Hi,
&gt;
&gt; LETO wrote (24 Jul 2011 15:46:11 GMT) :
&gt; &gt; Could some of you be so kind to try out my latest version of TorDNSd?
&gt;
&gt; &gt; It works a lot like ttdnsd with some additional features:
&gt;
&gt; Does TorDNSd use a single remote recursive DNS listener as its main
&gt; source, like ttdnsd does? Or does it use the Tor resolver for requests
&gt; it is able to deal with (namely: A requests)?
&gt;
&gt; Bye,
&gt; --
&gt;   intrigeri &lt;intrigeri@boum.org&gt;
&gt;  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
&gt;  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
&gt;  | So what?
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

It can use one or multiple remote dns servers (by default the google ones) meaning \
you can perform all queries (not just 'A' ones)&lt;br&gt;&lt;br&gt;- LETO&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Tue, Jul 26, 2011 at 10:26 PM, intrigeri &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt;Hi,&lt;br&gt; &lt;br&gt;
LETO wrote (24 Jul 2011 15:46:11 GMT) :&lt;br&gt;
&lt;div class="im"&gt;&gt; Could some of you be so kind to try out my latest version of \
TorDNSd?&lt;br&gt; &lt;br&gt;
&gt; It works a lot like ttdnsd with some additional features:&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Does TorDNSd use a single remote recursive DNS listener as its main&lt;br&gt;
source, like ttdnsd does? Or does it use the Tor resolver for requests&lt;br&gt;
it is able to deal with (namely: A requests)?&lt;br&gt;
&lt;br&gt;
Bye,&lt;br&gt;
--&lt;br&gt;
&lt;font color="#888888"&gt;  intrigeri &lt;&lt;a \
href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;br&gt;  | GnuPG key @ &lt;a \
href="https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc&lt;/a&gt;&lt;br&gt;  | \
OTR fingerprint @ &lt;a href="https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc&lt;/a&gt;&lt;br&gt;  | So \
what?&lt;br&gt; _______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110726231607</emailId><senderName>intrigeri</senderName><senderEmail>intrigeri@boum.org</senderEmail><timestampReceived>2011-07-26 23:16:07-0400</timestampReceived><subject>Re: [tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

Hi,

LETO wrote (26 Jul 2011 22:45:21 GMT) :
&gt; It can use one or multiple remote dns servers (by default the google
&gt; ones) meaning you can perform all queries (not just 'A' ones)

Ok. I see the point of using ttdnsd-like functionality to supplement
what the Tor DNS resolver is able to achieve itself. See our page
about this issue on the Tails wiki in case you want to understand the
place I'm speaking from:

  https://tails.boum.org/todo/support_arbitrary_dns_queries/

I also see the point of not granting one (and maybe a few) company/ies
the power to decide example.com does not exist for TorDNSd (and Tails)
users. Hence my past, present and future questions:

How exactly does TorDNSd deal with multiple remote DNS servers?

What issues could be possibly caused by using multiple remote DNS
recursive servers by default in TorDNSd?

What additional recursive servers would you consider worth adding to
the default TorDNSd configuration?

Bye,
--
  intrigeri &lt;intrigeri@boum.org&gt;
  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
  | Did you exchange a walk on part in the war
  | for a lead role in the cage?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110713205807</emailId><senderName>Aaron</senderName><senderEmail>aagbsn@extc.org</senderEmail><timestampReceived>2011-07-13 20:58:07-0400</timestampReceived><subject>Re: [tor-dev] New Paper: Cloud-based Onion Routing</subject><body>

I have a few questions

Q1: Regarding network bootstrap protocol: Consider the scenario where
a censor mines the boostrap node list and blocks these nodes. Do you
implement any mechanisms to prevent a censor from obtaining the entire
set of bootstrap nodes? Similarly, aren't public directory servers
also vulnerable to censorship?

Q2: Regarding token redemption: Does an ASP relay contact the ASP
token bank through COR? Could the token verification history be used
to reveal which paths were constructed?

--Aaron

On Wed, Jul 13, 2011 at 11:47 AM, Nick Jones &lt;najones@cs.princeton.edu&gt; wrote:
&gt; Hi All,
&gt; 
&gt; I'm a graduate student at Princeton, and our research group has recently submitted \
&gt; a paper proposing a design for cloud based onion routing. The goal of our research \
&gt; is to securely perform onion routing on cloud based infrastructure (like Amazon EC2 \
&gt; and Rackspace) while allowing users to retain the same (or almost the same) privacy \
&gt; as when using Tor. We distribute trust across multiple cloud providers, and use \
&gt; Chaum's e-cash for payment and access control. Additionally, we hope that the \
&gt; elasticity of cloud infrastructure will make cloud based OR more censorship \
&gt; resistant than current systems. 
&gt; This project is still in a relatively early stage, and we would love to get \
&gt; feedback from the Tor community. We would welcome any \
&gt; comments/questions/criticisms. 
&gt; 
&gt; 
&gt; Our project's website is available at:
&gt; 
&gt; http://sns.cs.princeton.edu/projects/cor/
&gt; 
&gt; 
&gt; A direct link to our paper is here:
&gt; 
&gt; http://www.cs.princeton.edu/~najones/publications/cor-foci11.pdf
&gt; 
&gt; 
&gt; Our abstract:
&gt; 
&gt; Internet censorship and surveillance have made anonymity tools increasingly \
&gt; critical for free and open Internet access. Tor, and its associated ecosystem of \
&gt; vol- unteer traffic relays, provides one of the most secure and widely-available \
&gt; means for achieving Internet anonymity today. Unfortunately, Tor has limitations, \
&gt; including poor performance, inadequate capacity, and a susceptibility to wholesale \
&gt; blocking. Rather than utilizing a large number of volunteers (as Tor does), we \
&gt; propose mov- ing onion-routing services to the cloud to leverage the large \
&gt; capacities, robust connectivity, and economies of scale inherent to commercial \
&gt; datacenters. This paper de- scribes Cloud-based Onion Routing (COR), which builds \
&gt; onion-routed tunnels over multiple anonymity service providers and through multiple \
&gt; cloud hosting providers, dividing trust while forcing censors to incur large \
&gt; collat- eral damage. We discuss the new security policies and mechanisms needed for \
&gt; such a provider-based ecosys- tem, and present some preliminary benchmarks. At to- \
&gt; days prices, a user could gain fast, anonymous network access through COR for only \
&gt; pennies per day. 
&gt; 
&gt; Thanks!
&gt; 
&gt; Nick Jones
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110713233200</emailId><senderName>Nick Jones</senderName><senderEmail>najones@cs.princeton.edu</senderEmail><timestampReceived>2011-07-13 23:32:00-0400</timestampReceived><subject>Re: [tor-dev] New Paper: Cloud-based Onion Routing</subject><body>



On Wednesday, July 13, 2011 at 4:58 PM, Aaron wrote:

&gt; I have a few questions
&gt; 
&gt; Q1: Regarding network bootstrap protocol: Consider the scenario where
&gt; a censor mines the boostrap node list and blocks these nodes. Do you
&gt; implement any mechanisms to prevent a censor from obtaining the entire
&gt; set of bootstrap nodes? Similarly, aren't public directory servers
&gt; also vulnerable to censorship?
&gt; 

Currently, we don't have any major protection from enumerating the list of \
bootstrapping nodes. It is definitely a problem we are aware of, and we're thinking \
about possible ways to protect  them. In our design, we only give out one \
bootstrapping node at a time, with the hope that this  makes enumerating them \
somewhat more difficult. Additionally, if we can detect that a  bootstrapping node \
has been blocked, we can use the elasticity of cloud hosting to move it to a  new IP \
or a new cloud. Admittedly, this may devolve into a cat and mouse game of moving the  \
bootstrapping nodes around. 

Similarly, since you learn about the bootstrapping nodes through the directories, the \
directories have many of the same problems and solutions. If the directories stay at \
a static IP/DNS name,  then they will be blocked quickly. However, if the user still \
has a cached valid directory from the  last time he was connected to COR, he could \
build a circuit and then retrieve an updated directory, assuming at least some of the \
nodes from the last directory retrieval were still active. We can  move the \
directories around within the cloud, but then you need a "directory of directories", \
and  that gets messy. 

Admittedly, our system doesn't fundamentally solve the bootstrapping problem (of new \
users  gaining access), but we hope that it makes it more difficult for existing \
users to be blocked.

&gt; Q2: Regarding token redemption: Does an ASP relay contact the ASP
&gt; token bank through COR? Could the token verification history be used
&gt; to reveal which paths were constructed?
&gt; 

The ASP relay contacts the ASP token bank directly. If multiple malicious ASPs \
colluded, they  might use token redemption timing analysis to figure out the \
circuit's path. However, this isn't really  any different than normal timing attacks. \
The tokens themselves can't be traced back to the user in any way. You need to use \
multiple ASPs to be protected, much like you need to use relays in Tor from multiple \
ISPs.

&gt; --Aaron
&gt; 
&gt; On Wed, Jul 13, 2011 at 11:47 AM, Nick Jones &lt;najones@cs.princeton.edu \
&gt; (mailto:najones@cs.princeton.edu)&gt; wrote:
&gt; &gt; Hi All,
&gt; &gt; 
&gt; &gt; I'm a graduate student at Princeton, and our research group has recently \
&gt; &gt; submitted a paper proposing a design for cloud based onion routing. The goal of \
&gt; &gt; our research is to securely perform onion routing on cloud based infrastructure \
&gt; &gt; (like Amazon EC2 and Rackspace) while allowing users to retain the same (or \
&gt; &gt; almost the same) privacy as when using Tor. We distribute trust across multiple \
&gt; &gt; cloud providers, and use Chaum's e-cash for payment and access control. \
&gt; &gt; Additionally, we hope that the elasticity of cloud infrastructure will make cloud \
&gt; &gt; based OR more censorship resistant than current systems. 
&gt; &gt; This project is still in a relatively early stage, and we would love to get \
&gt; &gt; feedback from the Tor community. We would welcome any \
&gt; &gt; comments/questions/criticisms. 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; Our project's website is available at:
&gt; &gt; 
&gt; &gt; http://sns.cs.princeton.edu/projects/cor/
&gt; &gt; 
&gt; &gt; 
&gt; &gt; A direct link to our paper is here:
&gt; &gt; 
&gt; &gt; http://www.cs.princeton.edu/~najones/publications/cor-foci11.pdf
&gt; &gt; 
&gt; &gt; 
&gt; &gt; Our abstract:
&gt; &gt; 
&gt; &gt; Internet censorship and surveillance have made anonymity tools increasingly \
&gt; &gt; critical for free and open Internet access. Tor, and its associated ecosystem of \
&gt; &gt; vol- unteer traffic relays, provides one of the most secure and widely-available \
&gt; &gt; means for achieving Internet anonymity today. Unfortunately, Tor has limitations, \
&gt; &gt; including poor performance, inadequate capacity, and a susceptibility to \
&gt; &gt; wholesale blocking. Rather than utilizing a large number of volunteers (as Tor \
&gt; &gt; does), we propose mov- ing onion-routing services to the "cloud" to leverage the \
&gt; &gt; large capacities, robust connectivity, and economies of scale inherent to \
&gt; &gt; commercial datacenters. This paper de- scribes Cloud-based Onion Routing (COR), \
&gt; &gt; which builds onion-routed tunnels over multiple anonymity service providers and \
&gt; &gt; through multiple cloud hosting providers, dividing trust while forcing censors to \
&gt; &gt; incur large collat- eral damage. We discuss the new security policies and \
&gt; &gt; mechanisms needed for such a provider-based ecosys- tem, and present some \
&gt; &gt; preliminary benchmarks. At to- day's prices, a user could gain fast, anonymous \
&gt; &gt; network access through COR for only pennies per day. 
&gt; &gt; 
&gt; &gt; Thanks!
&gt; &gt; 
&gt; &gt; Nick Jones
&gt; &gt; _______________________________________________
&gt; &gt; tor-dev mailing list
&gt; &gt; tor-dev@lists.torproject.org (mailto:tor-dev@lists.torproject.org)
&gt; &gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org (mailto:tor-dev@lists.torproject.org)
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


Hopefully that answers your questions. If anything isn't clear, please let me know. \
We  appreciate and welcome the feedback.

Thanks,

Nick Jones




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110714000203</emailId><senderName>Brandon Wiley</senderName><senderEmail>brandon@blanu.net</senderEmail><timestampReceived>2011-07-14 00:02:03-0400</timestampReceived><subject>Re: [tor-dev] New Paper: Cloud-based Onion Routing</subject><body>

[Attachment #2 (multipart/alternative)]


Cool stuff. I like how the system can be automated and self-funding.

With regards to bootstrapping, giving out one node at a time is not a useful
defense because requests can be parallelized. [1] Moving nodes is similarly
useless because the attacker can continually map the network using free
parallelized requests. Therefore, requesting a node address needs to cost
something. [2] Since you already have tokens, you can just make it cost a
token to request a node address.

To solve the initial introduction problem, you need to include fresh node
addresses with the distribution of the executable. You could in fact
dispense with the directory servers, which add no defense, and include fresh
node addresses with each executable upon download. For instance, with
BitTorrent we had a neat trick where we would encode the URL to a torrent
file at the end of the uTorrent executable (dynamically for each user when
they downloaded it from the web server) and the program new how to look for
and extract this URL upon startup. If present, uTorrent would automatically
start downloading this torrent. You could use a similar technique here. Much
as above, getting fresh peers, in this case by downloading the executable,
should cost something so that it can't be parallelized for free.

An alternative to paying per node address is to pay to establish an identity
and then use a DHT to map node addresses to identities so that you have a
way to obtain new addresses as they change due to churn, but mapping the
whole network requires multiple identities and so once again incurs a linear
cost. [2]

Best of luck with your project!

[1] Sybil attack &lt;http://www.cs.rice.edu/Conferences/IPTPS02/101.pdf&gt;
[2] Arcadia &lt;http://blanu.net/Arcadia.pdf&gt;

On Wed, Jul 13, 2011 at 6:32 PM, Nick Jones &lt;najones@cs.princeton.edu&gt;wrote:

&gt;
&gt;
&gt; On Wednesday, July 13, 2011 at 4:58 PM, Aaron wrote:
&gt;
&gt; &gt; I have a few questions
&gt; &gt;
&gt; &gt; Q1: Regarding network bootstrap protocol: Consider the scenario where
&gt; &gt; a censor mines the boostrap node list and blocks these nodes. Do you
&gt; &gt; implement any mechanisms to prevent a censor from obtaining the entire
&gt; &gt; set of bootstrap nodes? Similarly, aren't public directory servers
&gt; &gt; also vulnerable to censorship?
&gt; &gt;
&gt;
&gt; Currently, we don't have any major protection from enumerating the list of
&gt; bootstrapping nodes.
&gt; It is definitely a problem we are aware of, and we're thinking about
&gt; possible ways to protect
&gt; them. In our design, we only give out one bootstrapping node at a time,
&gt; with the hope that this
&gt; makes enumerating them somewhat more difficult. Additionally, if we can
&gt; detect that a
&gt; bootstrapping node has been blocked, we can use the elasticity of cloud
&gt; hosting to move it to a
&gt; new IP or a new cloud. Admittedly, this may devolve into a cat and mouse
&gt; game of moving the
&gt; bootstrapping nodes around.
&gt;
&gt; Similarly, since you learn about the bootstrapping nodes through the
&gt; directories, the directories
&gt; have many of the same problems and solutions. If the directories stay at a
&gt; static IP/DNS name,
&gt; then they will be blocked quickly. However, if the user still has a cached
&gt; valid directory from the
&gt; last time he was connected to COR, he could build a circuit and then
&gt; retrieve an updated directory,
&gt; assuming at least some of the nodes from the last directory retrieval were
&gt; still active. We can
&gt; move the directories around within the cloud, but then you need a
&gt; "directory of directories", and
&gt; that gets messy.
&gt;
&gt; Admittedly, our system doesn't fundamentally solve the bootstrapping
&gt; problem (of new users
&gt; gaining access), but we hope that it makes it more difficult for existing
&gt; users to be blocked.
&gt;

[Attachment #5 (text/html)]

&lt;br&gt;Cool stuff. I like how the system can be automated and self-funding.&lt;br&gt;&lt;br&gt;With \
regards to bootstrapping, giving out one node at a time is not a useful defense \
because requests can be parallelized. [1] Moving nodes is similarly useless because \
the attacker can continually map the network using free parallelized requests. \
Therefore, requesting a node address needs to cost something. [2] Since you already \
have tokens, you can just make it cost a token to request a node address.&lt;br&gt; &lt;br&gt;To \
solve the initial introduction problem, you need to include fresh node addresses with \
the distribution of the executable. You could in fact dispense with the directory \
servers, which add no defense, and include fresh node addresses with each executable \
upon download. For instance, with BitTorrent we had a neat trick where we would \
encode the URL to a torrent file at the end of the uTorrent executable (dynamically \
for each user when they downloaded it from the web server) and the program new how to \
look for and extract this URL upon startup. If present, uTorrent would automatically \
start downloading this torrent. You could use a similar technique here. Much as \
above, getting fresh peers, in this case by downloading the executable, should cost \
something so that it can't be parallelized for free.&lt;br&gt; &lt;br&gt;An alternative to \
paying per node address is to pay to establish an identity and then use a DHT to map \
node addresses to identities so that you have a way to obtain new addresses as they \
change due to churn, but mapping the whole network requires multiple identities and \
so once again incurs a linear cost. [2]&lt;br&gt; &lt;br&gt;Best of luck with your \
project!&lt;br&gt;&lt;br&gt;[1] &lt;a \
href="http://www.cs.rice.edu/Conferences/IPTPS02/101.pdf"&gt;Sybil attack&lt;/a&gt;&lt;br&gt;[2] &lt;a \
href="http://blanu.net/Arcadia.pdf"&gt;Arcadia&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On \
Wed, Jul 13, 2011 at 6:32 PM, Nick Jones &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:najones@cs.princeton.edu"&gt;najones@cs.princeton.edu&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt;&lt;div class="im"&gt;&lt;br&gt; &lt;br&gt;
On Wednesday, July 13, 2011 at 4:58 PM, Aaron wrote:&lt;br&gt;
&lt;br&gt;
&gt; I have a few questions&lt;br&gt;
&gt;&lt;br&gt;
&gt; Q1: Regarding network bootstrap protocol: Consider the scenario where&lt;br&gt;
&gt; a censor mines the boostrap node list and blocks these nodes. Do you&lt;br&gt;
&gt; implement any mechanisms to prevent a censor from obtaining the entire&lt;br&gt;
&gt; set of bootstrap nodes? Similarly, aren't public directory servers&lt;br&gt;
&gt; also vulnerable to censorship?&lt;br&gt;
&gt;&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Currently, we don't have any major protection from enumerating the list of \
bootstrapping nodes.&lt;br&gt; It is definitely a problem we are aware of, and we're \
thinking about possible ways to protect&lt;br&gt; them. In our design, we only give out one \
bootstrapping node at a time, with the hope that this&lt;br&gt; makes enumerating them \
somewhat more difficult. Additionally, if we can detect that a&lt;br&gt; bootstrapping node \
has been blocked, we can use the elasticity of cloud hosting to move it to a&lt;br&gt; new \
IP or a new cloud. Admittedly, this may devolve into a cat and mouse game of moving \
the&lt;br&gt; bootstrapping nodes around.&lt;br&gt;
&lt;br&gt;
Similarly, since you learn about the bootstrapping nodes through the directories, the \
directories&lt;br&gt; have many of the same problems and solutions. If the directories stay \
at a static IP/DNS name,&lt;br&gt; then they will be blocked quickly. However, if the user \
still has a cached valid directory from the&lt;br&gt; last time he was connected to COR, he \
could build a circuit and then retrieve an updated directory,&lt;br&gt; assuming at least \
some of the nodes from the last directory retrieval were still active. We can&lt;br&gt; \
move the directories around within the cloud, but then you need a "directory of \
directories", and&lt;br&gt; that gets messy.&lt;br&gt;
&lt;br&gt;
Admittedly, our system doesn't fundamentally solve the bootstrapping problem (of \
new users&lt;br&gt; gaining access), but we hope that it makes it more difficult for \
existing users to be blocked.&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110715201654</emailId><senderName>Nick Jones</senderName><senderEmail>najones@cs.princeton.edu</senderEmail><timestampReceived>2011-07-15 20:16:54-0400</timestampReceived><subject>Re: [tor-dev] New Paper: Cloud-based Onion Routing</subject><body>



On Wednesday, July 13, 2011 at 8:02 PM, Brandon Wiley wrote:

&gt; 
&gt; Cool stuff. I like how the system can be automated and self-funding.
&gt; 
&gt; With regards to bootstrapping, giving out one node at a time is not a useful \
&gt; defense because requests can be parallelized. [1] Moving nodes is similarly useless \
&gt; because the attacker can continually map the network using free parallelized \
&gt; requests. Therefore, requesting a node address needs to cost something. [2] Since \
&gt; you already have tokens, you can just make it cost a token to request a node \
&gt; address.

I agree with most of your points, but if we make users redeem a token to in order to \
access bootstrapping, they have to already have tokens, which is another \
bootstrapping problem in itself. Also, a determined adversary could just purchase \
enough tokens to perform the same attacks. Admittedly, we might make a lot of money \
from the censors in the process, which would be cool. 

&gt; 
&gt; To solve the initial introduction problem, you need to include fresh node addresses \
&gt; with the distribution of the executable. You could in fact dispense with the \
&gt; directory servers, which add no defense, and include fresh node addresses with each \
&gt; executable upon download. For instance, with BitTorrent we had a neat trick where \
&gt; we would encode the URL to a torrent file at the end of the uTorrent executable \
&gt; (dynamically for each user when they downloaded it from the web server) and the \
&gt; program new how to look for and extract this URL upon startup. If present, uTorrent \
&gt; would automatically start downloading this torrent. You could use a similar \
&gt; technique here. Much as above, getting fresh peers, in this case by downloading the \
&gt; executable, should cost something so that it can't be parallelized for free.
This is a cool idea. Definitely will investigate this more.

&gt; An alternative to paying per node address is to pay to establish an identity and \
&gt; then use a DHT to map node addresses to identities so that you have a way to obtain \
&gt; new addresses as they change due to churn, but mapping the whole network requires \
&gt; multiple identities and so once again incurs a linear cost. [2] 
&gt; Best of luck with your project!
&gt; 
&gt; [1] Sybil attack (http://www.cs.rice.edu/Conferences/IPTPS02/101.pdf)
&gt; [2] Arcadia (http://blanu.net/Arcadia.pdf)

Thanks for your comments. Very much appreciated!

-Nick Jones










&gt; 
&gt; On Wed, Jul 13, 2011 at 6:32 PM, Nick Jones &lt;najones@cs.princeton.edu \
&gt; (mailto:najones@cs.princeton.edu)&gt; wrote:
&gt; &gt; 
&gt; &gt; 
&gt; &gt; On Wednesday, July 13, 2011 at 4:58 PM, Aaron wrote:
&gt; &gt; 
&gt; &gt; &gt; I have a few questions
&gt; &gt; &gt; 
&gt; &gt; &gt; Q1: Regarding network bootstrap protocol: Consider the scenario where
&gt; &gt; &gt; a censor mines the boostrap node list and blocks these nodes. Do you
&gt; &gt; &gt; implement any mechanisms to prevent a censor from obtaining the entire
&gt; &gt; &gt; set of bootstrap nodes? Similarly, aren't public directory servers
&gt; &gt; &gt; also vulnerable to censorship?
&gt; &gt; 
&gt; &gt; Currently, we don't have any major protection from enumerating the list of \
&gt; &gt; bootstrapping nodes. It is definitely a problem we are aware of, and we're \
&gt; &gt; thinking about possible ways to protect them. In our design, we only give out one \
&gt; &gt; bootstrapping node at a time, with the hope that this makes enumerating them \
&gt; &gt; somewhat more difficult. Additionally, if we can detect that a bootstrapping node \
&gt; &gt; has been blocked, we can use the elasticity of cloud hosting to move it to a new \
&gt; &gt; IP or a new cloud. Admittedly, this may devolve into a cat and mouse game of \
&gt; &gt; moving the bootstrapping nodes around.
&gt; &gt; 
&gt; &gt; Similarly, since you learn about the bootstrapping nodes through the directories, \
&gt; &gt; the directories have many of the same problems and solutions. If the directories \
&gt; &gt; stay at a static IP/DNS name, then they will be blocked quickly. However, if the \
&gt; &gt; user still has a cached valid directory from the last time he was connected to \
&gt; &gt; COR, he could build a circuit and then retrieve an updated directory, assuming at \
&gt; &gt; least some of the nodes from the last directory retrieval were still active. We \
&gt; &gt; can move the directories around within the cloud, but then you need a "directory \
&gt; &gt; of directories", and that gets messy.
&gt; &gt; 
&gt; &gt; Admittedly, our system doesn't fundamentally solve the bootstrapping problem (of \
&gt; &gt; new users gaining access), but we hope that it makes it more difficult for \
&gt; &gt; existing users to be blocked.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org (mailto:tor-dev@lists.torproject.org)
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110714122211</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-07-14 12:22:11-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

On Thu, Jul 14, 2011 at 1:03 PM, Rob van der Hoeven
&lt;robvanderhoeven@ziggo.nl&gt; wrote:
&gt; Hi folks,

Hi,

&gt; Bridges serve as "unknown" entry points to the TOR network. For this,
&gt; part of the TOR network nodes are reserved and unlisted. This is not
&gt; good for the performance of the network, and because the network is
&gt; relatively small i think the unlisted-nodes strategy will only be a
&gt; short term solution.

Roger wrote a good blog post about strategies for getting more bridge
addresses: https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses
(you may have seen this already, it was written three months ago).

&gt; At the moment i'm working on my own FreedomBox. From this work i got the
&gt; following idea: Why not use the DNAT function of a router to forward TOR
&gt; traffic to a TOR node? This way you don't need unlisted nodes anymore. A
&gt; router-bridge does not have to be a full TOR node....
&gt;
&gt; Unfortunately the standard DNAT functionality of most routers only
&gt; support DNAT from the internet to internal addresses. So you need
&gt; modified firmware to make this work. Maybe a (slightly modified?)
&gt; version of OpenWRT will work.

Have you heard about the Torouter project? We are currently working on
two versions; the DreamPlug for technical users who don't mind doing
some hacking on their own, and the Excito B3 for non-tech users. We
have documented the project here:
https://trac.torproject.org/projects/tor/wiki/doc/Torouter - Maybe
this is something you'd like to help with?

&gt; Router-bridges have a second advantage over real TOR nodes. They can be
&gt; easily moved. If a router-bridge gets blocked, you can simply give the
&gt; router-bridge to a friend.

You could also just change the IP address of the Tor relay (probably
easier to do if it's a VPS than if you have it at home).

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714123944</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-07-14 12:39:44-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

On Thu, Jul 14, 2011 at 02:03:34PM +0200, Rob van der Hoeven wrote:
&gt; Hi folks,
&gt; 
&gt; Bridges serve as "unknown" entry points to the TOR network. For this,
&gt; part of the TOR network nodes are reserved and unlisted. This is not
&gt; good for the performance of the network, and because the network is
&gt; relatively small i think the unlisted-nodes strategy will only be a
&gt; short term solution.
&gt; 
&gt; At the moment i'm working on my own FreedomBox. From this work i got the
&gt; following idea: Why not use the DNAT function of a router to forward TOR
&gt; traffic to a TOR node? This way you don't need unlisted nodes anymore. A
&gt; router-bridge does not have to be a full TOR node....
&gt; 
&gt; Unfortunately the standard DNAT functionality of most routers only
&gt; support DNAT from the internet to internal addresses. So you need
&gt; modified firmware to make this work. Maybe a (slightly modified?)
&gt; version of OpenWRT will work.
&gt; 
&gt; Router-bridges have a second advantage over real TOR nodes. They can be
&gt; easily moved. If a router-bridge gets blocked, you can simply give the
&gt; router-bridge to a friend.
&gt; 
&gt; To give you an example of internet-internet DNAT i have configured one
&gt; of my systems to forward traffic to the TOR website. The URL is:
&gt; 
&gt; https://wordpress.hoevenstein.nl/
&gt; 
&gt; (If you try the URL you get a message about an invalid certificate of
&gt; course)
&gt; 
&gt; Let me know what you think about this idea...
&gt; Rob van der Hoeven.
&gt; http://freedomboxblog.nl

What's happening to the reply packets?  Do you also SNAT so that the
replies come back to you, or is it doing triangle routing?

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714130830</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-07-14 13:08:30-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

On Thu, 2011-07-14 at 13:22 +0100, Runa A. Sandvik wrote:
&gt; On Thu, Jul 14, 2011 at 1:03 PM, Rob van der Hoeven
&gt; &lt;robvanderhoeven@ziggo.nl&gt; wrote:
&gt; &gt; Hi folks,
&gt; 
&gt; Hi,
&gt; 
&gt; &gt; Bridges serve as "unknown" entry points to the TOR network. For this,
&gt; &gt; part of the TOR network nodes are reserved and unlisted. This is not
&gt; &gt; good for the performance of the network, and because the network is
&gt; &gt; relatively small i think the unlisted-nodes strategy will only be a
&gt; &gt; short term solution.
&gt; 
&gt; Roger wrote a good blog post about strategies for getting more bridge
&gt; addresses: https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses
&gt; (you may have seen this already, it was written three months ago).
&gt; 

As a FreedomBox builder i'm very interested in TOR. I am not very
up-to-date however, so i have not read this article.

&gt; &gt; At the moment i'm working on my own FreedomBox. From this work i got the
&gt; &gt; following idea: Why not use the DNAT function of a router to forward TOR
&gt; &gt; traffic to a TOR node? This way you don't need unlisted nodes anymore. A
&gt; &gt; router-bridge does not have to be a full TOR node....
&gt; &gt;
&gt; &gt; Unfortunately the standard DNAT functionality of most routers only
&gt; &gt; support DNAT from the internet to internal addresses. So you need
&gt; &gt; modified firmware to make this work. Maybe a (slightly modified?)
&gt; &gt; version of OpenWRT will work.
&gt; 
&gt; Have you heard about the Torouter project? We are currently working on
&gt; two versions; the DreamPlug for technical users who don't mind doing
&gt; some hacking on their own, and the Excito B3 for non-tech users. We
&gt; have documented the project here:
&gt; https://trac.torproject.org/projects/tor/wiki/doc/Torouter - Maybe
&gt; this is something you'd like to help with?
&gt; 

The beauty of the DNAT solution is that the router does not have to run
TOR at all. Much more lightweight. To give you an example: configuring
my firewall to do internet-internet DNAT only involved 3 lines in the
configuration files (see Shorewall FAQ 1g)

Rob.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714131228</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-07-14 13:12:28-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

&gt; &gt; 
&gt; &gt; To give you an example of internet-internet DNAT i have configured one
&gt; &gt; of my systems to forward traffic to the TOR website. The URL is:
&gt; &gt; 
&gt; &gt; https://wordpress.hoevenstein.nl/
&gt; &gt; 
&gt; &gt; (If you try the URL you get a message about an invalid certificate of
&gt; &gt; course)
&gt; &gt; 
&gt; &gt; Let me know what you think about this idea...
&gt; &gt; Rob van der Hoeven.
&gt; &gt; http://freedomboxblog.nl
&gt; 
&gt; What's happening to the reply packets?  Do you also SNAT so that the
&gt; replies come back to you, or is it doing triangle routing?

Good question. I'm no firewall expert, so i am not sure how this works
in my simple example. Maybe someone wants to comment? I'm usung
Shorewall and used the setup from FAQ 1g

Rob. 


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714134412</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-07-14 13:44:12-0400</timestampReceived><subject>Re: [tor-dev] Using routers as bridges</subject><body>

On Thu, 2011-07-14 at 13:22 +0100, Runa A. Sandvik wrote:
&gt; On Thu, Jul 14, 2011 at 1:03 PM, Rob van der Hoeven
&gt; &lt;robvanderhoeven@ziggo.nl&gt; wrote:
&gt; &gt; Hi folks,
&gt; 
&gt; Hi,
&gt; 
&gt; &gt; Bridges serve as "unknown" entry points to the TOR network. For
this,
&gt; &gt; part of the TOR network nodes are reserved and unlisted. This is not
&gt; &gt; good for the performance of the network, and because the network is
&gt; &gt; relatively small i think the unlisted-nodes strategy will only be a
&gt; &gt; short term solution.
&gt; 
&gt; Roger wrote a good blog post about strategies for getting more bridge
&gt; addresses:
https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses
&gt; (you may have seen this already, it was written three months ago).
&gt; 

As a FreedomBox builder i'm very interested in TOR. I am not very
up-to-date however, so i have not read this article.

&gt; &gt; At the moment i'm working on my own FreedomBox. From this work i got
the
&gt; &gt; following idea: Why not use the DNAT function of a router to forward
TOR
&gt; &gt; traffic to a TOR node? This way you don't need unlisted nodes
anymore. A
&gt; &gt; router-bridge does not have to be a full TOR node....
&gt; &gt;
&gt; &gt; Unfortunately the standard DNAT functionality of most routers only
&gt; &gt; support DNAT from the internet to internal addresses. So you need
&gt; &gt; modified firmware to make this work. Maybe a (slightly modified?)
&gt; &gt; version of OpenWRT will work.
&gt; 
&gt; Have you heard about the Torouter project? We are currently working on
&gt; two versions; the DreamPlug for technical users who don't mind doing
&gt; some hacking on their own, and the Excito B3 for non-tech users. We
&gt; have documented the project here:
&gt; https://trac.torproject.org/projects/tor/wiki/doc/Torouter - Maybe
&gt; this is something you'd like to help with?
&gt; 

The beauty of the DNAT solution is that the router does not have to run
TOR at all. Much more lightweight. To give you an example: configuring
my firewall to do internet-internet DNAT only involved 3 lines in the
configuration files (see Shorewall FAQ 1g)

Rob.



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110713201241</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-13 20:12:41-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay Setup Wizard</subject><body>

Hi Damian,

On 7/13/11 7:01 PM, Damian Johnson wrote:
&gt; Hi all. Over the last few weeks I've been working on a relay setup
&gt; wizard for arm. Its purpose is to make volunteering to be a relay
&gt; easy, narrowing the options to those most commonly used and giving
&gt; nice descriptions/defaults to encourage good configurations.
&gt; 
&gt; At present relay setup for new users, particularly exits, is either
&gt; confusing or limited. For users doing it without a controller we have
&gt; a deluge of man page options and a confusing bundle of docs. For
&gt; Vidalia users, however, it's easy to become a middle hop or bridge,
&gt; but the configurations it makes for exits are poor (default exit
&gt; policy, no front page, no notice for how to reduce abuse complaints
&gt; which probably leads Vidalia exits to be short lived...).
&gt; 
&gt; This wizard consists of three pages...

arm and this wizard look really great! :)

Just a few minor comments below...

&gt; 1. Selection for what you'd like to be
&gt; http://www.atagar.com/transfer/tmp/arm_wizard1.png

I wonder if the order of configurations on that page should rather be:
Exit Relay - Internal Relay - Bridge - Client - Cancel.  The default
could still be "Internal Relay," but the order could imply to people
that the higher something's in the list, the more they contribute.

Or does this wizard start automatically when arm starts?  In that case,
setting "Internal Relay" as the default could be problematic.  If people
use arm on their clients, they shouldn't be tricked into becoming a
relay only because that's the default.  They should know what they're
doing when setting up a relay.  But 90% of all users go with the
default, so if "Internal Relay" is the default, they'll just pick that
and hope for the best.  (Ignore this comment if the wizard is explicitly
called "Tor Relay Setup Wizard" and if people need to actively start it.)

Missing word: "This is a safe and easy _way_ of making the Tor network
better."

&gt; 2. Picking your relay options, with both descriptions of the options
&gt; and why you'd want to set them
&gt; http://www.atagar.com/transfer/tmp/arm_wizard2.png

I wonder if there's a short torproject.org URL containing tips for exit
relay operators that you can show users here.

Again, this looks great!

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110713202623</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-07-13 20:26:23-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay Setup Wizard</subject><body>

On Wed, Jul 13, 2011 at 10:01:18AM -0700, Damian Johnson wrote:
&gt; 1. Selection for what you'd like to be
&gt; http://www.atagar.com/transfer/tmp/arm_wizard1.png

I'd suggest sticking with the name 'Non-exit' relay rather than making up
a new term ('Internal Relay') that nobody else uses. Unless you want to
convince everybody that non-exit relay is a bad name and we should switch?
I'd be amenable to switching, but I don't think "Internal" is the right
word. Which leads me to:

Your description of an exit relay may mislead people into thinking that
it *only* handles exit traffic -- meaning it doesn't get connections
from users.

Perhaps changing 'Connects...' to 'Also connects...' would do it?

&gt; 2. Picking your relay options, with both descriptions of the options
&gt; and why you'd want to set them
&gt; http://www.atagar.com/transfer/tmp/arm_wizard2.png

Does "Low Relaying Ports" mean 'try to bind to 80 and 443'? Perhaps that
should be 'Listen on Popular Ports'? I guess it depends if your users
know what 'Low' is and what it implies.

You point to a url at atagar.com here. If your not-so-humble goals are to
come true, it seems we should have a page on the website that has these
pointers? Or maybe it's better as a faq entry (to avoid "omg there are
so many pages how was I ever supposed to find that one")?

&gt; 3. Confirmation for the configuration it's making
&gt; http://www.atagar.com/transfer/tmp/arm_wizard3.png

In the comments at the very top, I'd suggest changing "restart tor" to
"or restart tor", to make it clearer that any one of the three steps
will accomplish the goal.

You might also want to change the comments on the Log and DirPortFrontPage
lines so they show up before the config line, meaning you can actually
read the comment.

&gt; 4. ... then in the frozen land of Nador they were forced to eat Sir
&gt; Robin's minstrels. And there was much rejoicing.
&gt; http://www.atagar.com/transfer/tmp/arm_wizard4.png

Woah, your logs are in reverse order. :)

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714035207</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-07-14 03:52:07-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay Setup Wizard</subject><body>

Thanks, Karsten!

&gt; Or does this wizard start automatically when arm starts?

If tor is installed but not currently running on the control port then
arm starts the wizard.

&gt; In that case,
&gt; setting "Internal Relay" as the default could be problematic.  If people
&gt; use arm on their clients, they shouldn't be tricked into becoming a
&gt; relay only because that's the default.  They should know what they're
&gt; doing when setting up a relay.  But 90% of all users go with the
&gt; default, so if "Internal Relay" is the default, they'll just pick that
&gt; and hope for the best.  (Ignore this comment if the wizard is explicitly
&gt; called "Tor Relay Setup Wizard" and if people need to actively start it.)

I disagree. For the network to scale it needs some portion of its
userbase to be relays. There's certainly use cases where that isn't
practical (either when it's a burden or they need to hide the fact
that they're using tor), but for just about anything else operating a
middle-hop relay is an easy and complaint-free way of helping. I kinda
like having people opt-out of being a relay since it makes them aware
when they're using the network without contributing to it. Also,
weren't we talking earlier about making people bridges by default in
Vidalia?

That said, I'll change the default if people would rather it be something else.

&gt; Missing word: "This is a safe and easy _way_ of making the Tor network
&gt; better."

Thanks, fixed

&gt; I wonder if there's a short torproject.org URL containing tips for exit
&gt; relay operators that you can show users here.

Ah, I was wondering when someone would mention that. I made two simple
landing pages with resources for wizard users...
http://www.atagar.com/torUsageTips/
http://www.atagar.com/torExitTips/

I did it this way since...
- it needed to be short urls (originally I was planning trac wikis)
- I could make the site look just how I wanted, my goal being
something minimal that draws eyes to the content which the dark
background does
- it kinda seemed fitting since this is where arm's homepage resides

However, in the long run I agree that these should be torproject.org
pages (for the recognizable url, translations, and since it provides
https).

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110714044922</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-07-14 04:49:22-0400</timestampReceived><subject>Re: [tor-dev] Tor Relay Setup Wizard</subject><body>

&gt; I'd suggest sticking with the name 'Non-exit' relay rather than making up
&gt; a new term ('Internal Relay') that nobody else uses. Unless you want to
&gt; convince everybody that non-exit relay is a bad name and we should switch?

Sebastian had the same concern. We adopted the term "exit" and
"non-exit" because we were describe ExitPolicy entries rather than
relay roles. The term "non-exit" says... well, that you're not an exit
but not what you are, which is providing interconnections between
participants in the tor network.

Personally I think that we should be offering users the analogy that
tor is a network of participants (users and middle hops) with exit
points from that network out into the wider Internet. This gives a
good, simple abstraction for why this last role produces abuse
complaints and the former doesn't.

Though again, if I'm outnumbered on this then I'll go with the majority.

&gt; Your description of an exit relay may mislead people into thinking that
&gt; it *only* handles exit traffic -- meaning it doesn't get connections
&gt; from users.

True, though I don't think that we should try to include that in the
description. Why do you think that this is an important detail for new
relay operators to understand?

&gt; Does "Low Relaying Ports" mean 'try to bind to 80 and 443'? Perhaps that
&gt; should be 'Listen on Popular Ports'? I guess it depends if your users
&gt; know what 'Low' is and what it implies.

Very good idea - changed to "Use Popular Ports"

&gt; Or maybe it's better as a faq entry (to avoid "omg there are
&gt; so many pages how was I ever supposed to find that one")?

I tried that for a while. Our faqs make bad landing pages and the trac
urls are too long. As mentioned in my reply to Karsten I agree that
this will need to become tpo pages, however I think my pages turned
out very nicely so until there's tpo alternatives this doesn't strike
me as a large concern.

&gt; In the comments at the very top, I'd suggest changing "restart tor" to
&gt; "or restart tor", to make it clearer that any one of the three steps
&gt; will accomplish the goal.

Good idea. Changed.

&gt; You might also want to change the comments on the Log and DirPortFrontPage
&gt; lines so they show up before the config line, meaning you can actually
&gt; read the comment.

The audience I had in mind for the comments were people hand editing
the torrc, where those lines look fine (the confirmation dialog's
width is only 58). Though I probably should add line wrapping...

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110725110822</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-25 11:08:22-0400</timestampReceived><subject>[tor-dev] New mailing list for wiki changes</subject><body>

Hi everyone,

yesterday we found that a few people run their own rss-to-email service
to be notified of wiki changes.  We decided that it's easier to set up a
new mailing list that has all the wiki changes and that everyone can
subscribe to.

If you're interested in learning when something in the wiki changed,
subscribe to:

  https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-wiki-changes

(And if you have suggestions to make the r2e output more useful, please
say so.  The current configuration is simply 'r2e add
"https://trac.torproject.org/projects/tor/timeline?wiki=on&amp;max=50&amp;daysback=2&amp;format=rss"
tor-wiki-changes@lists.torproject.org'.)

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110726234341</emailId><senderName>LETO</senderName><senderEmail>m8rovpdyd@gmail.com</senderEmail><timestampReceived>2011-07-26 23:43:41-0400</timestampReceived><subject>Re: [tor-dev] Requesting feedback on TorDNSd v1.1</subject><body>

[Attachment #2 (multipart/alternative)]


Hello,

+ Currently, when a query fails, it'll use the next configured DNS server
and reattempt to query on that one. Nothing special is done at the moment,
but I'm open for suggestions.

+ A possible issue I see is that retrying a(n invalid) query on all possible
domains may give a delay since it'll attempt to query all configured dns
servers.

+ If I had to add additional DNS servers, I'd add in the OpenDNS servers.

I'd like to add that one of the other nice features of TorDNSd are the
filters : An internet connection not leaking out any DNS requests could look
suspicious, but using 'filter-direct' rules you could define a couple of
'legal' queries to leak 'on purpose'.

- LETO

On Tue, Jul 26, 2011 at 11:16 PM, intrigeri &lt;intrigeri@boum.org&gt; wrote:

&gt; Hi,
&gt;
&gt; LETO wrote (26 Jul 2011 22:45:21 GMT) :
&gt; &gt; It can use one or multiple remote dns servers (by default the google
&gt; &gt; ones) meaning you can perform all queries (not just 'A' ones)
&gt;
&gt; Ok. I see the point of using ttdnsd-like functionality to supplement
&gt; what the Tor DNS resolver is able to achieve itself. See our page
&gt; about this issue on the Tails wiki in case you want to understand the
&gt; place I'm speaking from:
&gt;
&gt;  https://tails.boum.org/todo/support_arbitrary_dns_queries/
&gt;
&gt; I also see the point of not granting one (and maybe a few) company/ies
&gt; the power to decide example.com does not exist for TorDNSd (and Tails)
&gt; users. Hence my past, present and future questions:
&gt;
&gt; How exactly does TorDNSd deal with multiple remote DNS servers?
&gt;
&gt; What issues could be possibly caused by using multiple remote DNS
&gt; recursive servers by default in TorDNSd?
&gt;
&gt; What additional recursive servers would you consider worth adding to
&gt; the default TorDNSd configuration?
&gt;
&gt; Bye,
&gt; --
&gt;  intrigeri &lt;intrigeri@boum.org&gt;
&gt;  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
&gt;  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
&gt;   | Did you exchange a walk on part in the war
&gt;  | for a lead role in the cage?
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

Hello,&lt;br&gt;&lt;br&gt;+ Currently, when a query fails, it'll use the next configured DNS \
server and reattempt to query on that one.  Nothing special is done at the moment, \
but I'm open for suggestions.&lt;br&gt;&lt;br&gt;+ A possible issue I see is that retrying \
a(n invalid) query on all possible domains may give a delay since it'll attempt \
to query all configured dns servers.&lt;br&gt; &lt;br&gt;+ If I had to add additional DNS \
servers, I'd add in the OpenDNS servers.&lt;br&gt;&lt;br&gt;I'd like to add that one of \
the other nice features of TorDNSd are the filters : An internet connection not \
leaking out any DNS requests could look suspicious, but using 'filter-direct' \
rules you could define a couple of 'legal' queries to leak 'on \
purpose'.&lt;br&gt; &lt;br&gt;- LETO&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Tue, Jul 26, 2011 at \
11:16 PM, intrigeri &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; Hi,&lt;br&gt;
&lt;br&gt;
LETO wrote (26 Jul 2011 22:45:21 GMT) :&lt;br&gt;
&lt;div class="im"&gt;&gt; It can use one or multiple remote dns servers (by default the \
google&lt;br&gt; &gt; ones) meaning you can perform all queries (not just 'A' \
ones)&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Ok. I see the point of using ttdnsd-like functionality to supplement&lt;br&gt;
what the Tor DNS resolver is able to achieve itself. See our page&lt;br&gt;
about this issue on the Tails wiki in case you want to understand the&lt;br&gt;
place I'm speaking from:&lt;br&gt;
&lt;br&gt;
  &lt;a href="https://tails.boum.org/todo/support_arbitrary_dns_queries/" \
target="_blank"&gt;https://tails.boum.org/todo/support_arbitrary_dns_queries/&lt;/a&gt;&lt;br&gt; \
&lt;br&gt; I also see the point of not granting one (and maybe a few) company/ies&lt;br&gt;
the power to decide &lt;a href="http://example.com" target="_blank"&gt;example.com&lt;/a&gt; does \
not exist for TorDNSd (and Tails)&lt;br&gt; users. Hence my past, present and future \
questions:&lt;br&gt; &lt;br&gt;
How exactly does TorDNSd deal with multiple remote DNS servers?&lt;br&gt;
&lt;br&gt;
What issues could be possibly caused by using multiple remote DNS&lt;br&gt;
recursive servers by default in TorDNSd?&lt;br&gt;
&lt;br&gt;
What additional recursive servers would you consider worth adding to&lt;br&gt;
the default TorDNSd configuration?&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;
Bye,&lt;br&gt;
--&lt;br&gt;
  intrigeri &lt;&lt;a href="mailto:intrigeri@boum.org"&gt;intrigeri@boum.org&lt;/a&gt;&gt;&lt;br&gt;
  | GnuPG key @ &lt;a href="https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc&lt;/a&gt;&lt;br&gt;  | \
OTR fingerprint @ &lt;a href="https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc" \
target="_blank"&gt;https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc&lt;/a&gt;&lt;br&gt; &lt;/div&gt;  | \
Did you exchange a walk on part in the war&lt;br&gt;  | for a lead role in the cage?&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110728224215</emailId><senderName>Jrmy Bobbio</senderName><senderEmail>lunar@debian.org</senderEmail><timestampReceived>2011-07-28 22:42:15-0400</timestampReceived><subject>[tor-dev] Report from the "Tor ecosystem" BoF at DebConf 11</subject><body>

[Attachment #2 (multipart/signed)]


Hi!

Here is a report from DebConf 11, the annual conference of the Debian
project. We had the opportunity to hold a "Tor ecosystem" BoF. It was
short (we had only 45 minutes), but productive from my perspective.
Here's an (obviously partial) report.

A lot more people showed up (  25) than we expected for a pure work
meeting, so there is definitely an interest in having Tor and its
ecosystem working well in Debian. Among the attendees we had:
 * Peter Palfrader, maintainer of the 'tor' package,
 * Ulises Vitulli, (co-)maintainer of 'vidalia', 'tor-arm', 'python-torctl',
   'torchat',
 * Jrmy Bobbio, maintainer of 'torbutton',
 * intrigeri and bertagaz, developers of Tails (which is a live system
   based on Debian).

A summary follows from some notes and memory. Feel free to
correct me if you feel that things happened differently.


New upstream packaging policy
=============================

We took some time to discuss the changes to the packaging policy that
were proposed by Andrew Lewman last June.
See &lt;https://lists.torproject.org/pipermail/tor-dev/2011-June/002780.html&gt;

Quoting the relevant part:

    GNU/Linux (deb and rpm)
    1. tor-client.  The same TBB we ship today.
    2. tor-relay. Create tor-relay.(deb|rpm) that includes geoipdb and a
       pre-configured torrc that is for a non-exit relay.
    3. tor-exit-relay. Create tor-exit-relay.(deb|rpm) that includes
       geoipdb and a pre-configured torrc that is for an exit relay.
    4. tor-bridge. Create tor-bridge.(deb|rpm) that includes geoipdb
       and a pre-configured torrc that is for a bridge.

The 'tor' source package in Debian already builds a binary package
called 'tor-geoipdb' which contains GeoIP information. We have not
even discussed about changing, as it is how it is supposed to be in
Debian (pure data package as separate, architecture-independent
packages).

The proposed 'tor-client' and TBB in general was discussed later.
For the rest, the hard part of the discussion also revolved around
defining who are target users of these packages. Pure desktop users?
People that can fiddle with a command-line and edit a configuration
file? Experienced sysadmins?

Having 3 different "configuration" packages for relays, exit-relays and
bridges is something that could be done in Debian. But we had a rough
consensus that it would actually complicate things for most Debian
users.

For bridges, pure desktop users would probably benefit from a better
integration with Vidalia; so that made us rule out the need for a
dedicated 'tor-bridge' package.

Which left us with the "relay" and "exit relay" use cases and it looked
like those could be better adressed by either a debconf question, or by
some examples better integrated.

Integration with other software, derivatives and custom distributions
=====================================================================

While discussing how we could actually make it easier to setup relays,
we got back to the lack of a way to source extra configuration files in
`torrc`.

We outlined some benefits that would have a `/etc/tor/torrc.d` directory
full of configuration snippets:

 * The 'tor' package will not (or less) need patches to change the
   default settings.
 * It would make it much easier to implement example setups
   (relays, exit relays, bridges) either through a debconf question
   or through a system script like 'tor-setup-relay'.
 * Tails developers will only need to drop a very small extra
   configuration file instead of having to rewrite the whole, which
   should ease development and reviewing.
 * Other packages which need a hidden service to work (e.g. 'onioncat')
   would be able to create it automatically by installing the proper
   configuration snippet. That would enable them to work right after being
   installed.

Feature request: https://trac.torproject.org/projects/tor/ticket/2863

Control of the system-wide 'tor' daemon
=======================================

We finally have (currently in 'experimental') an easy way for
applications to control the system-wide 'tor' daemon: the ControlSocket
option is on by default.

Vidalia, ARM and others now only require users to be in the system
'debian-tor' group to be able to control Tor.

We did not have the time to properly discuss if, and how, we offer an
easy way to add users to this group.

Tor Browser Bundle (e.g tor-client)
===================================

There is an incentive to have something as close as the Tor
Browser Bundle in Debian. Otherwise, desktop users on Debian get a
smaller anonymity set (such strong partitioning already happened in the
past, see &lt;http://bugs.debian.org/595375&gt;).

The main issue is the Tor fork of Firefox. There are a few possibilities on
how it can be handled within Debian. Summary: this is doable, but
requires a lot of work, and the cooperation of quite a few different
parties.

One other thing that TBB is doing is to start its own instance of Tor.
We agreed that it was a behaviour that would be quite desirable to have.
It will make setup even more easier and it might limit users exposure
when they are not using Tor.

In order to achieve that, we need either to make the 'tor' package not
start Tor after being installed or we need a way have the `tor` binary
without the rest of the daemon infrastructure (e.g initscript).

The former will probably be quite confusing to sysadmins, so we agreed
on splitting out the daemon binary from the current 'tor' package to a
new 'tor-bin' package.

How TorBrowser could get in Debian?
===================================

Having a full separate source package for TorBrowser is not possible due
to Debian Policy 4.13. But there are still other options, all having
their shortcomings:

1. Make the 'iceweasel' source package (that's how Firefox is called in Debian
   due to trademark issues) produce an extra 'tor-browser' binary package.

   Issues:

   - Mike Hommey (iceweasel maintainer) stated clearly that he did
     not want to maintain the Tor patches. But we can probably settle
     on a policy like "if it does not build, just drop it". The removal
     of a binary package does not trigger NEW queue processing. It is
     also not triggered if the same binary packages returns before
     two weeks.
   - Double (?) the build time of 'iceweasel' which is already huge.
     Security team will not be happy, and it's going to be harder to
     actually maintain the TorBrowser side of things.

   Pros: until the patches do not apply anymore, it'll be less
   maintainance from our side.

2. Make the 'iceweasel' source package produce an extra binary package
   (e.g 'iceweasel-src') that will contain the full Iceweasel source.
   Create a 'tor-browser' package that Build-Depends on the former.

   Issues:

   - 'iceweasel' is a pretty fast moving target. This will need us
     to follow its uploads quite closely to ask for binNMU or to
     upload updated versions quickly.
   - The security team will have two packages to track instead of
     one. They might not like it at all.

   Pros: much easier for Mike Hommey and we are autonomous to upload
   the 'tor-browser' package if changes are only needed there.

Looks like the latter is probably better. But it definitely needs to be
checked with all parties involved first.

For browser extensions curretly shipped with TBB, Debian already has
'torbutton' and 'noscript'. But we miss 'httpseverwhere' (#591579) and
'betterprivacy'.

There are a few open issues that still need to be figured out:
 * TorBrowser should create dedicated profiles in the user home
   directories,
 * How can default values be set? Do we need 'locked down' preferences?
 * How should we handle other system-wide extensions? Active like for
   the main Iceweasel, totally ignored, or disabled by default?
 * If Debian ships the TorBrowser, should we prevent Torbutton from
   appearing in the usual Iceweasel?

This will require a lot of work for the initial bootstrap and a decent
amount of work for the daily maintainance after that. But it looked
worthwhile anyhow


Cheers,
-- 
Jrmy Bobbio                        .''`. 
lunar@debian.org                    : :  :  # apt-get install anarchism
                                    `. `'` 
                                      `-   

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110729181547</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-07-29 18:15:47-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Georg Koppen (g.koppen@jondos.de):

&gt; &gt; Can you provide specific concerns about facebook wrt the properties
&gt; &gt; from the blog post?
&gt; 
&gt; Not yet, no. I am not a Facebook user and have therefore to look at
&gt; research papers investigating it. And the things I read e.g. in
&gt; http://www.research.att.com/~bala/papers/w2sp11.pdf or in
&gt; http://www.research.att.com/~bala/papers/wosn09.pdf do not seem to break
&gt; the idea proposed in the blog post. But again, there is research to be
&gt; done here, I guess. Redirects (you mentioned them already) could pose a
&gt; serious threat to the approach in the blog post, though (systems like
&gt; Phorm http://www.cl.cam.ac.uk/~rnc1/080518-phorm.pdf come to my mind).

Wrt redirects: https://trac.torproject.org/projects/tor/ticket/3600

&gt; &gt;&gt;&gt; What do you have in mind in terms of stricter controls?
&gt; &gt;&gt;
&gt; &gt;&gt; Hmmm... Dunno what you mean here.
&gt; &gt; 
&gt; &gt; What changes to the design might you propose?
&gt; 
&gt; There are basically two points to be mentioned here IMO:
&gt; 
&gt; 1) Having a tab (window) isolation additionally (see my comments below)
&gt; 
&gt; and
&gt; 
&gt; 2) Having some means to break the linkage between the same domain called
&gt; more than once in a tab. That would be the best I can imagine and would
&gt; help against attacks using redirects as well but is hard to get right.
&gt; E.g. one had to give the user means to fine-tune the default setting to
&gt; their needs without ending up in a UI nightmare. And there are probably
&gt; numerous other pitfalls lurking here... We have already done some basic
&gt; research (we supervised a BA thesis investigating this concerning
&gt; cookies) but there is still a lot to do. But yes, I would like to have
&gt; that feature and invest some energy to investigate if one can get it
&gt; right in a meaningful way.

Yeah, the issue I see with both this and tab isolation is that it
seems like it will be difficult to teach users who are used to being
able to log into their gmail/etc that they have to keep doing this if
they use a different tab, or try to open pieces of the interface in
new tabs/windows... A non-trivial number of expert users may also like
to have multiple windows open to the same site for live updates from the
same service (which in some cases may prevent multiple concurrent
logins).

&gt; &gt; More broadly, perhaps there is some balance of per-tab isolation and
&gt; &gt; origin isolation that is easily achievable in Firefox?
&gt; 
&gt; I hope so (at least if we had a Firefox fork that would not be much of a
&gt; problem anymore). The Multifox Add-On
&gt; (http://br.mozdev.org/multifox/all.html) claims to have implemented per
&gt; tab identities and I have looked at it superficially. It is quite
&gt; promising and deserves a thorough test.

This is very interesting. If you get around to evaluating it, let me
know. I am still concerned about the usability approach, but if this
dropdown menu is smart enough, maybe it can work out. (If the download
wasn't http-only I would have installed it already).

&gt; Regarding the research grant: I already wrote pde and asked him whether
&gt; he has some interesting stuff that we should try to incorporate into the
&gt; application. If you (Mike) have something don't hesitate and drop me a
&gt; mail. We still have the opportunity to move the things we already have a
&gt; bit around to get something we overlooked into our proposal (the
&gt; deadline is end of July). The topic is investigating and solving issues
&gt; regarding an anonymous browser (profile) and to develop one that is
&gt; resilient to e.g. different fingerprinting attacks and tracking means in
&gt; general.

Funding for user studies and breakage studies would be top of the list
for me, esp if we're talking about tab-isolation, and browser/user
behavior changes.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110730012339</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-07-30 01:23:39-0400</timestampReceived><subject>Re: [tor-dev] Unused -v and -F options in torperf/trivsocks-client?</subject><body>

On 7/29/11 3:39 PM, Steven Murdoch wrote:
&gt; Hi Karsten, David,
&gt; 
&gt; On 29 Jul 2011, at 05:00, Karsten Loesing wrote:
&gt;&gt; Hmm, for some reason I don't get those errors (or warnings) about unused
&gt;&gt; variables.  But I think you're right in that these variables can go away.
&gt;&gt;
&gt;&gt; This is Steven's code, so I'd like to hear his opinion before applying
&gt;&gt; the patch.  Steven?
&gt; 
&gt; That patch looks fine to me. I didn't get the warnings either, so perhaps you're using a newer GCC.
&gt; 
&gt; While I was testing it, I also wrote a patch to fix compilation on MacOS X.

I applied both David's and Steven's patch.

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110731111058</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-07-31 11:10:58-0400</timestampReceived><subject>[tor-dev] [Patch] or/networkstatus.c</subject><body>

Hi list.

In or/networkstatus.c there is a "#if 0" block inside the macro 
"SMARTLIST_FOREACH_JOIN". Not all compilers handle such contructs. 

In the prosess of making solution/projects file for "MS Visual C++ 2010 Express",
I hit this problem (cl Version 16.00.30319.01). Can you please accept the 
following patch:

diff --git a/src/or/networkstatus.c b/src/or/networkstatus.c
index 2586ce6..d8d6680 100644
--- a/src/or/networkstatus.c
+++ b/src/or/networkstatus.c
@@ -2001,19 +2001,25 @@ routers_update_status_from_consensus_networkstatus(smartlist_t *routers,

   routers_sort_by_identity(routers);

+  /* Since not all compilers handles '#' inside macros, we use a helper-macro. */
+#if 0
+  #define CHECK_ROUTER_PURPOSE() do { \
+    /* We have no routerstatus for this router. Clear flags and skip it. */ \
+    if (!authdir) { \
+      if (router-&gt;purpose == ROUTER_PURPOSE_GENERAL) \
+        router_clear_status_flags(router); \
+    } \
+   } while (0)
+#else
+  #define CHECK_ROUTER_PURPOSE()
+#endif
+
   SMARTLIST_FOREACH_JOIN(ns-&gt;routerstatus_list, routerstatus_t *, rs,
                          routers, routerinfo_t *, router,
                          tor_memcmp(rs-&gt;identity_digest,
                                router-&gt;cache_info.identity_digest, DIGEST_LEN),
+                        {  CHECK_ROUTER_PURPOSE(); })
   {
-#if 0
-    /* We have no routerstatus for this router. Clear flags and skip it. */
-    if (!authdir) {
-      if (router-&gt;purpose == ROUTER_PURPOSE_GENERAL)
-        router_clear_status_flags(router);
-    }
-#endif
-  }) {
     /* We have a routerstatus for this router. */
     const char *digest = router-&gt;cache_info.identity_digest;

------------------------

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110601103905</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-01 10:39:05-0400</timestampReceived><subject>[tor-dev] Control-port circuit event/status format</subject><body>

[Attachment #2 (multipart/signed)]


Subject: Control-port circuit event/status format

Will any Tor controllers that I should care about break if I modify Tor
to report a CANNIBALIZED' circuit event to all controllers that send
SETEVENTS CIRC' to Tor?

Will any Tor controllers that I should care about break if I modify Tor
to report a CANNIBALIZED' circuit state in response to a GETINFO
circuit-status' control-port command?


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110601151152</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-06-01 15:11:52-0400</timestampReceived><subject>Re: [tor-dev] [PATCH] Signed-off-by: Gisle &lt;gvanem@broadpark.no&gt;</subject><body>

On Tue, May 31, 2011 at 5:44 PM, Gisle &lt;gvanem@broadpark.no&gt; wrote:
&gt; An elusive compile-error (MingW-gcc v4.50 on Win_XP); a missing
&gt; comma (!) and a typo ('err_msg' at line 277 changed to 'errmsg').
&gt; Aso changed the format for 'err_code' at line 293 into a "%ld" to suppress
&gt; a warning. How did this go unnoticed for ~1 month? Btw. This is my 1st ever
&gt; 'git commit', so it better work.

Merged  into 0.2.2; thanks!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610100846</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-06-10 10:08:46-0400</timestampReceived><subject>[tor-dev] Too many cooks spoil the broth---or: how about we clean</subject><body>

Hello everyone,

&lt;rant&gt;Today I looked at our wiki to add roadmaps for some products and
realized what a mess the wiki is.  This wasn't obvious to me, because I
stopped using the wiki long ago, well, because it was such a mess.  But
boy, it has become worse!&lt;/rant&gt;

I think the main problem is that there's no obvious structure in the
wiki, so everyone just adds their stuff anywhere, maybe thinking that
someone else will move it to the right place.  The other problem is that
there's no such person cleaning up.

Here's my plan: I'd like to rename (possibly a lot of) wiki pages so
that the naming scheme implies a kind of wiki structure.  I'd also add a
page saying where stuff should go, and we'll beat up everyone not
adhering to the structure in a joint effort.

By the way, what happens if we rename wiki pages?  I guess Trac will
update all internal links, but external links (e.g., from the website)
will be broken?  We could fix our own website, but other websites would
still be broken.  How bad would that be?

Here's a suggested naming scheme.  In this scheme, there are three
top-level directories (or rather, page prefixes):

 - doc/ contains all documentation for Tor users, relay operators, and
the community in general.  This is the stuff that people would usually
expect in a wiki.

 - org/ contains deliverables promised to our sponsors, meeting plans,
product roadmaps, project progress, etc.  This stuff is in the wiki to
make Tor development as transparent as possible.  In theory,
non-developers wouldn't require write permissions to these pages.

 - trac/ contains Trac's own documentation that it generously dumped
into our Tor wiki.  In theory, nobody would require write permissions to
these pages.

I'll go through the existing wiki pages and say where they should go.

The following pages would move to doc/ (e.g., "DNS Hijacking" would
become "doc/DNS Hijacking"):

DNS Hijacking
HTTPSEverywhere/SSLObservatorySubmission
ImportantGoogleChromeBugs
OnionCat
TorALaymansGuide
TorFAQUnanswered
TorInChroot
TorToggle
UsingTorWithVservers
badRelays
badRelays/trotskyIps
talks
talks/MoscowState2010
TheOnionRouter
TheOnionRouter/AnonymousPublicSpeech
TheOnionRouter/BIND
TheOnionRouter/BandwidthLimitChangeController
TheOnionRouter/BlockNonTorTrafficDebian
TheOnionRouter/BlockingDiagnostics
TheOnionRouter/BlockingIrc
TheOnionRouter/CentralizedTorServer
TheOnionRouter/ConnectOverSSH
TheOnionRouter/ContestEntries
TheOnionRouter/ContestEntries/DesignFeedback
TheOnionRouter/CronBandwidthLimit
TheOnionRouter/DebianLive
TheOnionRouter/EmbeddedTips
TheOnionRouter/ExitEnclave
TheOnionRouter/FAQUnanswered
TheOnionRouter/FireFoxTorPerf
TheOnionRouter/FirefoxRemoteDNS
TheOnionRouter/GoodBadISPs
TheOnionRouter/Gsoc2009
TheOnionRouter/Gsoc2009/ThandyTorrents
TheOnionRouter/HiddenServiceNames
TheOnionRouter/HowTo_post_on_or-talk_mailinglist
TheOnionRouter/LegalStuff
TheOnionRouter/LiveCDBestPractices
TheOnionRouter/MacOSXUpgradeToTrunk
TheOnionRouter/OpenbsdChrootedTor
TheOnionRouter/OpenbsdChrootedTorControlScript
TheOnionRouter/OpenbsdChrootedTorScript
TheOnionRouter/OperationalSecurity
TheOnionRouter/Portable_Tor
TheOnionRouter/PreventingDnsLeaksInTor
TheOnionRouter/Preventing_Tor_DNS_Leaks
TheOnionRouter/PrivoxyConfig
TheOnionRouter/PrivoxyPatches
TheOnionRouter/Publicfile
TheOnionRouter/ReducedExitPolicy
TheOnionRouter/RemailingAndTor
TheOnionRouter/RunTwoPrivoxys
TheOnionRouter/SshPortForwardedTor
TheOnionRouter/SummerOfCode
TheOnionRouter/SupportPrograms
TheOnionRouter/SupportPrograms/Polipo
TheOnionRouter/TSocksPatches
TheOnionRouter/TermsObserved
TheOnionRouter/TorAbuseTemplates
TheOnionRouter/TorExitNodeHowto
TheOnionRouter/TorGuideUniversities
TheOnionRouter/TorInChroot
TheOnionRouter/TorInChroot-new
TheOnionRouter/TorInTheMedia
TheOnionRouter/TorMirror
TheOnionRouter/TorOnDebian/PackagesForArchitectures
TheOnionRouter/TorShirt
TheOnionRouter/TorWin32TorWS
TheOnionRouter/TorALaymansGuide
TheOnionRouter/TorDNSExitList
TheOnionRouter/TorFAQ
TheOnionRouter/TorIPCOP
TheOnionRouter/TorifyHOWTO
TheOnionRouter/TorifyHOWTO/EMail
TheOnionRouter/TorifyHOWTO/FTP
TheOnionRouter/TorifyHOWTO/InstantMessaging
TheOnionRouter/TorifyHOWTO/IrcSilc
TheOnionRouter/TorifyHOWTO/Misc
TheOnionRouter/TorifyHOWTO/Misc/Putty
TheOnionRouter/TorifyHOWTO/Putty
TheOnionRouter/TorifyHOWTO/SystracePolicy
TheOnionRouter/TorifyHOWTO/WebBrowsers
TheOnionRouter/Torouter
TheOnionRouter/Torouter_notes
TheOnionRouter/Torwin32DNS
TheOnionRouter/Transocks
TheOnionRouter/TransocksifyingTor
TheOnionRouter/TransparentProxy
TheOnionRouter/VMWareThroughTor
TheOnionRouter/VerifyingSignatures
TheOnionRouter/WebProxyHowto
TheOnionRouter/Wikipedia
TheOnionRouter/WindowsBufferProblems
CodingForTor
CodingForTor/CodingInC
CodingForTor/CodingInR
CodingForTor/LoggingAndDocumentation
CodingInC
CoreTorTracUsers
build
build/AddingBuildSlaves
build/BuildSignoff
build/ListOfPackages
dev/HowToReleaseTor
dev/SupportPolicy
dev/SupportPolicy_v2

The following pages would move to org/meetings/:

2010TorAnnualDevMeeting
2011MiniDevMeeting
2011MiniDevMeeting/notes
2011StockholmHackfest
2011TorAnnualDevMeeting

The product roadmaps that are not there yet would go into org/roadmaps/.

Everything related to project management would go into org/projects/:

TorAgileProcess
projects/HowWeDoProjectManagement
projects/ProjMgt/SetUpProjectMgt
Products
projects/ProductsandAssignments
projects
projects/2009FinancialandComplianceAudit
projects/BridgeDB
projects/CalculateDirreqShares
projects/EmailAutoResponder
projects/ExperimentalBridgeBundles
projects/Infrastructure
projects/Metrics
projects/Metrics/DesignAndDeployDescriptorDatabase
projects/Metrics/ImproveMetricsPortal
projects/Metrics/PublishMetricsDataAndTools
projects/Metrics/SafelyCountClients
projects/Thandy
projects/Tor
projects/TorBrowserBundle
projects/TorBrowserBundle/Alpha
projects/TorBrowserBundle/OSX
projects/TorBrowserBundle/OSX/Security
projects/TorBulkExitlist
projects/TorButton
projects/TorCheck
projects/TorFlow
projects/TorStatus
projects/Tor/MultithreadedCrypto
projects/Weather
projects/arm
projects/mirror
projects/mirror/torrent
projects/vidalia

The deliverables promised to our sponsors would go into org/sponsors/:

sponsors
sponsors/SponsorA
sponsors/SponsorB
sponsors/SponsorD
sponsors/SponsorD/December2010
sponsors/SponsorD/June2011
sponsors/SponsorD/March2011
sponsors/SponsorD/September2010
sponsors/SponsorE
sponsors/SponsorE/PhaseOne
sponsors/SponsorF
sponsors/SponsorF/Year1

And finally, the following pages are about using Trac and would go into
trac/ (it's possible that Trac wouldn't like us renaming some of its
pages, but I guess we'll find out):

InterTrac
InterWiki
RecentChanges
TitleIndex
TracAccessibility
TracAdmin
TracBackup
TracBrowser
TracCgi
TracChangeset
TracEnvironment
TracFastCgi
TracFineGrainedPermissions
TracGuide
TracImport
TracIni
TracInstall
TracInterfaceCustomization
TracLinks
TracLogging
TracModPython
TracModWSGI
TracNavigation
TracNotification
TracPermissions
TracPlugins
TracQuery
TracReports
TracRevisionLog
TracRoadmap
TracRss
TracSearch
TracStandalone
TracSupport
TracSyntaxColoring
TracTickets
TracTicketsCustomFields
TracTimeline
TracUnicode
TracUpgrade
TracWiki
TracWorkflow
WikiDeletePage
WikiFormatting
WikiHtml
WikiMacros
WikiNewPage
WikiPageNames
WikiProcessors
WikiRestructuredText
WikiRestructuredTextLinks
WikiStart

That's it.  I realize there are lots of cooks on this list, so I expect
there will be feedback.

Thanks,
Karsten

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611165942</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-06-11 16:59:42-0400</timestampReceived><subject>[tor-dev] Will people running a relay be blocked from accessing CN</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Ian, I made a new thread to avoid this discussion in the
'The Torouter and the DreamPlug' thread.

&gt; On Thu, Jun 09, 2011 at 11:47:10PM +0200, tagnaq wrote:
&gt;&gt;&gt; &gt; &gt; Doesn't "make random people into public (middle-only) relays" have the
&gt;&gt;&gt; &gt; &gt; (well maybe not "problem", but "issue"?) that when GFW blocks them, they
&gt;&gt;&gt; &gt; &gt; (the random people who bought an Excito/etc.) won't be able to connect
&gt;&gt;&gt; &gt; &gt; to anything in .cn any more?  Although I don't _often_ connect to .cn
&gt;&gt;&gt; &gt; &gt; domains, it seems unfortunate to effectively auto-ban these people from
&gt;&gt;&gt; &gt; &gt; Chinese websites.
&gt;&gt; &gt; 
&gt;&gt; &gt; I did not experience any problems connecting to .cn while using a relay
&gt;&gt; &gt; IP address. I think they are just blocking an IP:port combination and
&gt;&gt; &gt; not the entire IP address.
&gt;&gt; &gt; ...but things might change
&gt; Hmm.  I wonder what happens if the packets are fragmented so that the
&gt; TCP port information isn't in the first fragment...

possibilities:
a) a fragmented IP packet doesn't get blocked
b) they don't allow IP fragmentation (Don't Framgent Bit set)
c) their firewall is able to find out whether the fragment is part of a
blocked destination (IP:port)
-----BEGIN PGP SIGNATURE-----

iF4EAREKAAYFAk3znv4ACgkQyM26BSNOM7ZB5QD+J7p1OSqD7uopViiigmop84sp
nlzbSV6dqK2ZvT+PrbUA/i2hLQKHkYZfVUQqTp4hu2o9bp5GbHsNylNP6l1lKByB
=aKCK
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611155759</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-11 15:57:59-0400</timestampReceived><subject>[tor-dev] Python TorCtl development questions</subject><body>

  I have begun using the Python TorCtl package to develop a gui TOR
controller.  So, I am looking at the TorCtl source to understand how
to use it properly.  In this examination, I have begun adding
comments, renaming vars to be more explicit, etc.  How open are the
developers to these changes?

  Will the devs accept patches to remove unused code.  I'm looking at
you, TorCtl.TorUtil.Enum.

  Is there interest in making TorCtl into a more mainstream form of
Python package?  See
https://trac.torproject.org/projects/tor/ticket/2585

  How far back in Python versions are we trying to maintain
compatibility?  As an example: TorCtl.TorUtil.Callable seems to be
used to create static methods, but the staticmethod function to do
this was added in Py2.2 (Dec 2001) and the @staticmethod decorator
form was added in Py2.4 (Nov 2004).

  And thank you for TorCtl, it certainly saved me time not to have to
implement a protocol engine from scratch.

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110614211622</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-06-14 21:16:22-0400</timestampReceived><subject>[tor-dev] Thoughts on simplified packaging</subject><body>

As I talk to more and more people, they are confused by all of the
different software packages we offer.  From the simple, 

"I just want to be a relay, why is this so hard?"

to 

"I just want to safely get to the BBC, I don't care about configuration
and such. Can't you just make it a simple download and have it work by
default?"

I've written down my thoughts at
https://svn.torproject.org/svn/projects/roadmaps/proposed-package-roadmap.txt.

I'm looking for your thoughts and feedback.  The goal is to simplify
what we produce and make it easy for people to get the software and
configuration they want.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110616145129</emailId><senderName>"Frederic Bor"</senderName><senderEmail>frederic.bor@wanadoo.fr</senderEmail><timestampReceived>2011-06-16 14:51:29-0400</timestampReceived><subject>[tor-dev] license question</subject><body>

Hello,


I=92m currently implementing transparent proxying for tor with Layered =
Service
Provider feature on windows. Microsoft provides a sample to demonstrate =
how
to implement an empty LSP (this is a lot of work, even to do nothing). =
This
sample is distributed under the license attached in this email. I have =
been
advised on #tor-dev to ask here about its compatibility with 3-clause =
BSD.

It seems compatible to me but the following restriction may be a problem =
in
an open source context:

"You may not [...] modify or distribute the source code of any =
Distributable
Code so that any part of it becomes subject to an Excluded License. An
Excluded License is one that requires, as a condition of use, =
modification
or distribution, that:
- the code be disclosed or distributed in source code form, or
- others have the right to modify it."

The wording "requires, as a condition of use, modification or =
distribution"
seems to allow to use the sample in tor, since there is no such =
requirement
in 3-clause BSD.

Does this seem right to you?


Cheers,
Frederic

["License.htm" (text/html)]

&lt;html&gt;

&lt;head&gt;
&lt;meta http-equiv=Content-Type content="text/html; charset=windows-1252"&gt;
&lt;meta name=Generator content="Microsoft Word 11 (filtered)"&gt;
&lt;title&gt;MICROSOFT SOFTWARE LICENSE TERMS&lt;/title&gt;

&lt;style&gt;
&lt;!--
 /* Font Definitions */
 @font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:2 11 6 3 2 2 2 2 2 4;}
@font-face
	{font-family:"Palatino Linotype";
	panose-1:2 4 5 2 5 5 5 3 3 4;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;}
@font-face
	{font-family:"Franklin Gothic Book";
	panose-1:2 11 5 3 2 1 2 2 2 4;}
@font-face
	{font-family:"\@SimSun";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MS Mincho";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
h1
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
h2
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
h3
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:normal;}
h4
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:71.75pt;
	text-indent:-17.9pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:normal;}
h5
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:89.6pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:normal;}
h6
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:107.45pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:normal;}
p.MsoHeading7, li.MsoHeading7, div.MsoHeading7
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:125.3pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.MsoHeading8, li.MsoHeading8, div.MsoHeading8
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:143.15pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.MsoHeading9, li.MsoHeading9, div.MsoHeading9
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:161.05pt;
	text-indent:-17.9pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.MsoCommentText, li.MsoCommentText, div.MsoCommentText
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:purple;
	text-decoration:underline;}
p.MsoDocumentMap, li.MsoDocumentMap, div.MsoDocumentMap
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	background:navy;
	font-size:10.0pt;
	font-family:Tahoma;}
p.MsoCommentSubject, li.MsoCommentSubject, div.MsoCommentSubject
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:bold;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:8.0pt;
	font-family:Tahoma;}
p.body1, li.body1, div.body1
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body2, li.body2, div.body2
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:.5in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body3, li.body3, div.body3
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body4, li.body4, div.body4
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:71.75pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body5, li.body5, div.body5
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:90.15pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body6, li.body6, div.body6
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:1.5in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body7, li.body7, div.body7
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:125.3pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body8, li.body8, div.body8
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:143.15pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.body9, li.body9, div.body9
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:161.05pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet1, li.bullet1, div.bullet1
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:17.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet2, li.bullet2, div.bullet2
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:.5in;
	text-indent:-18.15pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet3, li.bullet3, div.bullet3
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet4, li.bullet4, div.bullet4
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:71.75pt;
	text-indent:-17.9pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet5, li.bullet5, div.bullet5
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:89.6pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet6, li.bullet6, div.bullet6
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:107.45pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet7, li.bullet7, div.bullet7
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:125.3pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet8, li.bullet8, div.bullet8
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:143.15pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet9, li.bullet9, div.bullet9
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:161.05pt;
	text-indent:-17.9pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.headingeula, li.headingeula, div.headingeula
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:14.0pt;
	font-family:"Trebuchet MS";
	font-weight:bold;}
p.headingsoftwaretitle, li.headingsoftwaretitle, div.headingsoftwaretitle
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:14.0pt;
	font-family:"Trebuchet MS";
	font-weight:bold;}
p.preamble, li.preamble, div.preamble
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:bold;}
p.preambleborder, li.preambleborder, div.preambleborder
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:0in;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	font-weight:bold;}
p.style1, li.style1, div.style1
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	text-decoration:underline;}
p.heading3underline, li.heading3underline, div.heading3underline
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";
	text-decoration:underline;}
p.3inumbered2ndlevel, li.3inumbered2ndlevel, div.3inumbered2ndlevel
	{margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:31.2pt;
	margin-bottom:.0001pt;
	text-indent:-17.0pt;
	line-height:8.0pt;
	font-size:7.0pt;
	font-family:"Franklin Gothic Book";
	color:black;}
p.3cnumbered, li.3cnumbered, div.3cnumbered
	{margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:13.5pt;
	margin-bottom:.0001pt;
	text-indent:-13.5pt;
	line-height:9.0pt;
	font-size:8.0pt;
	font-family:"Book Antiqua";}
p.body10, li.body10, div.body10
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.bullet30, li.bullet30, div.bullet30
	{margin-top:6.0pt;
	margin-right:0in;
	margin-left:53.85pt;
	text-indent:-17.85pt;
	font-size:10.0pt;
	font-family:"Trebuchet MS";}
p.3inumbered2ndlevel0, li.3inumbered2ndlevel0, div.3inumbered2ndlevel0
	{margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:31.2pt;
	margin-bottom:.0001pt;
	text-indent:-17.0pt;
	line-height:8.0pt;
	font-size:7.0pt;
	font-family:"Franklin Gothic Book";
	color:black;}
p.HeadingSoftwareTitle0, li.HeadingSoftwareTitle0, div.HeadingSoftwareTitle0
	{margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	border:none;
	padding:0in;
	font-size:14.0pt;
	font-family:Tahoma;
	font-weight:bold;}
span.body1char
	{font-family:"Trebuchet MS";}
span.body2char
	{font-family:"Trebuchet MS";}
span.heading2char
	{font-family:"Trebuchet MS";
	font-weight:bold;}
span.heading1char
	{font-family:"Trebuchet MS";
	font-weight:bold;}
span.heading3char
	{font-family:"Trebuchet MS";}
span.heading3underlinechar
	{font-family:"Trebuchet MS";
	text-decoration:underline;}
span.body3char
	{font-family:"Trebuchet MS";}
span.heading4char
	{font-family:"Trebuchet MS";}
span.heading2char1
	{font-family:"Trebuchet MS";
	font-weight:bold;}
span.body1char0
	{font-family:"Trebuchet MS";}
span.body1char00
	{font-family:"Trebuchet MS";}
span.3inumbered2ndlevelchar
	{font-family:"Franklin Gothic Book";
	color:black;}
span.emailstyle66
	{font-family:"Palatino Linotype";
	color:navy;
	font-weight:normal;
	font-style:normal;
	text-decoration:none none;}
@page Section1
	{size:595.3pt 841.9pt;
	margin:.7in .7in .7in .7in;}
div.Section1
	{page:Section1;}
 /* List Definitions */
 --&gt;
&lt;/style&gt;

&lt;/head&gt;

&lt;body lang=EN-US link=blue vlink=purple&gt;

&lt;div class=Section1&gt;

&lt;p class=headingeula&gt;&lt;span style='font-size:10.0pt;color:black'&gt;MICROSOFT
SOFTWARE LICENSE TERMS&lt;/span&gt;&lt;/p&gt;

&lt;div style='border:none;border-top:solid windowtext 1.0pt;padding:1.0pt 0in 0in 0in'&gt;

&lt;div style='border:none;border-bottom:solid windowtext 1.0pt;padding:0in 0in 1.0pt \
0in'&gt;

&lt;p class=HeadingSoftwareTitle0&gt;&lt;span style='font-size:10.0pt'&gt;MICROSOFT
PLATFORM SOFTWARE DEVELOPMENT KIT FOR WINDOWS SERVER 2003 R2&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p class=preambleborder style='margin-bottom:6.0pt'&gt;&lt;span style='font-weight:
normal'&gt;These license terms are an agreement between Microsoft Corporation (or
based on where you live, one of its affiliates) and you. Please read
them. They apply to the software named above, which includes the media on
which you received it, if any. The terms also apply to any Microsoft: \
&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span \
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times \
New Roman"'&gt; &lt;/span&gt;updates,&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span \
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times \
New Roman"'&gt; &lt;/span&gt;supplements,&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span \
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times \
New Roman"'&gt; &lt;/span&gt;Internet-based \
services, and &lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span \
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times \
New Roman"'&gt; &lt;/span&gt;support \
services&lt;/p&gt;

&lt;p class=bullet3 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;
margin-left:0in;text-indent:0in'&gt;for this software, unless other terms
accompany those items. If so, those terms apply.&lt;/p&gt;

&lt;p class=bullet3 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;
margin-left:0in;text-indent:0in'&gt;&lt;b&gt;By using this software, you accept these
terms. If you do not accept them, do not use the software.&lt;/b&gt;&lt;/p&gt;

&lt;div style='border:none;border-bottom:solid windowtext 1.5pt;padding:0in 0in 1.0pt \
0in'&gt;

&lt;p class=preamble&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p class=preamble&gt;&lt;span class=body1char&gt;If you comply with these license terms,
you have the rights below:&lt;/span&gt;&lt;/p&gt;

&lt;h1 style='margin-left:.25in;text-indent:-.25in'&gt;&lt;span class=body1char&gt;&lt;span
style='color:black'&gt;1.&lt;/span&gt;&lt;/span&gt;&lt;span class=body1char&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;/span&gt;USE RIGHTS. \
&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
35.85pt;text-indent:-.25in'&gt;&lt;span style='font-family:Tahoma'&gt;a.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New Roman"'&gt;
&lt;/span&gt;&lt;span class=body1char&gt;Use. &lt;/span&gt;&lt;span style='font-weight:normal'&gt;You
may install the software on any number of devices to design, develop and test
your programs that run on a Microsoft Windows operating system.&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
35.85pt;text-indent:-.25in'&gt;&lt;span class=heading2char1&gt;&lt;span style='font-family:
Tahoma;color:black'&gt;b.&lt;/span&gt;&lt;/span&gt;&lt;span class=heading2char1&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;Other Microsoft \
Programs. &lt;/span&gt;&lt;span class=heading2char1&gt;&lt;span \
style='color:black;font-weight:normal'&gt;The software may contain other Microsoft \
programs that include license terms. The license terms with those programs \
apply to your use of them.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
35.85pt;text-indent:-.25in'&gt;&lt;span class=heading2char1&gt;&lt;span style='font-family:
Tahoma'&gt;c.&lt;/span&gt;&lt;/span&gt;&lt;span class=heading2char1&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New Roman"'&gt; \
&lt;/span&gt;Distributable Code. &lt;/span&gt;&lt;span class=heading2char1&gt;&lt;span \
style='font-weight:normal'&gt;The software contains code that you are permitted to copy \
and distribute in programs you develop if you comply with the terms \
below.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:0in;margin-right:0in;margin-bottom:0in;margin-left:.75in;
margin-bottom:.0001pt;text-indent:-.25in'&gt;i. Right to Use and
Distribute. &lt;span style='font-weight:normal'&gt;The code and text files
listed below are Distributable Code. You may:&lt;/span&gt;&lt;/h1&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:
"Times New Roman"'&gt; \
&lt;/span&gt;&lt;u&gt;REDIST.TXT Files&lt;/u&gt;. Copy and distribute the object code form of \
code listed in REDIST.TXT files;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:
"Times New Roman"'&gt; &lt;/span&gt;&lt;u&gt;Sample
Code&lt;/u&gt;. Modify, copy and distribute the source and object code form of
code marked as sample except for files identified as MFCs, ATLs and CRTs (see
below);&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:
"Times New Roman"'&gt; &lt;/span&gt;&lt;u&gt;MFCs,
ATLs and CRTs&lt;/u&gt;. Modify the source code form of Microsoft Foundation Classes
(MFCs), Active Template Libraries (ATLs), and C runtimes (CRTs) to design,
develop and test your programs, and copy and distribute the object code form of
your modified files under a new name; and&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:
"Times New Roman"'&gt; &lt;/span&gt;&lt;u&gt;Third
Party Distribution&lt;/u&gt;. Permit distributors of your programs to copy and
distribute the Distributable Code as part of those programs.&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:12.0pt;margin-right:0in;margin-bottom:
6.0pt;margin-left:.75in;text-indent:-.25in'&gt;&lt;b&gt;ii.&lt;/b&gt; &lt;b&gt;Distribution
Requirements&lt;/b&gt;.&lt;i&gt; &lt;/i&gt;For any Distributable Code you distribute, you
must:&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;add significant primary functionality to it in your \
programs;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;only invoke the software via interfaces described in the software \
documentation;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;for any Distributable Code having a filename extension of .lib, \
distribute only the results of running such Distributable Code through a linker with \
your application;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;distribute Distributable Code included in a setup program only as \
part of that setup program without modification;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;require distributors and external end users to agree to terms \
that protect it at least as much as this agreement; &lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;display your valid copyright notice on your programs;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;for \
Distributable Code from the Windows Media Services SDK portions of the software, \
include in your programs Help-About box (or in another obvious place if there is no \
box) the following copyright notice: Portions utilize Microsoft Windows Media \
Technologies. Copyright (c) 1999-2005 Microsoft Corporation. All Rights \
Reserved&lt;span style='color:black'&gt;; and&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:
"Times New Roman"'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;indemnify, defend, and hold harmless Microsoft from any
claims, including attorneys fees, related to the distribution or use of your
programs.&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-left:.75in;text-indent:-.25in'&gt;&lt;b&gt;iii.&lt;/b&gt;
&lt;b&gt;Distribution Restrictions.&lt;/b&gt; You may not:&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;alter any copyright, trademark or patent notice in the \
Distributable Code; &lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;use Microsofts trademarks in your programs names or in a way \
that suggests your programs come from or are endorsed by Microsoft; &lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;distribute Distributable Code to run on a platform other than the \
Windows platform;&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;include Distributable Code in malicious, deceptive or unlawful \
programs; or&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:1.0in;margin-bottom:.0001pt;text-indent:-.25in'&gt;&lt;span
style='font-family:Symbol;color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;modify or distribute the source code of any Distributable Code so \
that any part of it becomes subject to an Excluded License. An Excluded License \
is one that requires, as a condition of use, modification or distribution, \
that:&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:69.0pt;margin-bottom:.0001pt;text-indent:3.0pt'&gt;&lt;span
style='font-family:"Courier New";color:black'&gt;o&lt;/span&gt;&lt;span style='font-size:
7.0pt;font-family:"Times New \
Roman";color:black'&gt;
 &lt;/span&gt;&lt;span style='color:black'&gt;the code be disclosed or distributed in source
code form, or&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal style='margin-top:6.0pt;margin-right:0in;margin-bottom:0in;
margin-left:69.0pt;margin-bottom:.0001pt;text-indent:3.0pt'&gt;&lt;span
style='font-family:"Courier New"'&gt;o&lt;/span&gt;&lt;span style='font-size:7.0pt;
font-family:"Times New \
Roman"'&gt;
 &lt;/span&gt;&lt;span style='color:black'&gt;others have the right to modify it. &lt;/span&gt;&lt;/p&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;2.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;TRANSFER. &lt;span \
class=body2char&gt;&lt;span style='color:black; font-weight:normal'&gt;The first user of the \
software may transfer it and this agreement directly to a third party. Before \
the transfer, that party must agree that this agreement applies to the transfer and \
use of the software. The first user must uninstall the software before \
transferring it separately from the device. The first user may not retain any \
copies.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;3.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;BACKUP COPY. &lt;/span&gt;&lt;span \
style='color:black;font-weight:normal'&gt;You&lt;/span&gt;&lt;span style='color:black'&gt; \
&lt;/span&gt;&lt;span style='color:black;font-weight:normal'&gt;may make one backup copy of the
software. You may use it only to reinstall the software.&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;4.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;DOCUMENTATION. &lt;/span&gt;&lt;span \
style='color:black;font-weight:normal'&gt;You may copy and use the documentation for \
your internal, reference purposes.&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;5.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;EXPORT RESTRICTIONS. &lt;/span&gt;&lt;span \
style='font-weight:normal'&gt;The software is subject to United States export laws and \
regulations. You must comply with all domestic and international export laws \
and regulations that apply to the software. These laws include restrictions on \
destinations, end users and end use. For additional information, see &lt;a \
href="http://www.microsoft.com/exporting"&gt;&lt;span \
style='color:windowtext;text-decoration:none'&gt;www.microsoft.com/exporting&lt;/span&gt;&lt;/a&gt;.&lt;/span&gt;&lt;/h1&gt;


&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;6.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;SUPPORT SERVICES. &lt;/span&gt;&lt;span \
style='color:black;font-weight:normal'&gt;Because this software is as is, we may not \
provide support services for it.&lt;span class=body1char&gt; &lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;7.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;SCOPE OF LICENSE. &lt;/span&gt;&lt;span class=body1char&gt;&lt;span \
style='color:black;font-weight:normal'&gt;The software is licensed, not sold. This \
agreement only gives you some rights to use the software. Microsoft reserves \
all other rights. Unless applicable law gives you more rights despite this \
limitation, you may use the software only as expressly permitted in this \
agreement. In doing so, you must comply with any technical limitations in the \
software that only allow you to use it in certain ways. You may \
not:&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;work around any technical limitations in the software,&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;reverse engineer, decompile or disassemble the software,
except and only to the extent that applicable law expressly permits, despite
this limitation,&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;make more copies of the software than specified in this
agreement or allowed by applicable law, despite this limitation,&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;publish the software for others to copy,&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;rent, lease or lend the software, or&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-bottom:6.0pt'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;use the software for commercial software hosting \
services.&lt;/span&gt;&lt;/p&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;8.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;ENTIRE AGREEMENT. &lt;/span&gt;&lt;span class=body1char&gt;&lt;span \
style='color:black;font-weight:normal'&gt;This agreement and the terms for supplements, \
updates, Internet-based services and support services that you use are the entire \
agreement for the software and support services.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;9.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
style='color:black'&gt;APPLICABLE LAW.&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-left:35.85pt;text-indent:-.25in'&gt;&lt;span class=body1char&gt;&lt;span
style='color:black'&gt;a.&lt;/span&gt;&lt;/span&gt;&lt;span class=body1char&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;/span&gt;&lt;span \
class=heading2char1&gt;&lt;span style='color:black'&gt;United States&lt;/span&gt;&lt;/span&gt;&lt;span \
class=heading2char1&gt;&lt;span style='color:black'&gt;.&lt;/span&gt;&lt;/span&gt;&lt;span \
class=body1char&gt;&lt;span style='color:black;font-weight:normal'&gt; If you acquired \
the software in the United States, Washington state law governs the interpretation of \
this agreement and applies to claims for breach of it, regardless of conflict of laws \
principles. The laws of the state where you live govern all other claims, \
including claims under state consumer protection laws, unfair competition laws, and \
in tort.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-left:35.85pt;text-indent:-.25in'&gt;&lt;span \
style='color:black'&gt;b.&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New \
Roman";color:black'&gt; &lt;/span&gt;&lt;span \
class=heading2char1&gt;&lt;span style='color:black'&gt;Outside the United \
States.&lt;/span&gt;&lt;/span&gt;&lt;span class=body1char&gt;&lt;span style='color:black;font-weight: \
normal'&gt; If you acquired the software in any other country, the laws of that \
country apply.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span class=body1char&gt;&lt;span \
style='color:black'&gt;10.&lt;/span&gt;&lt;/span&gt;&lt;span class=body1char&gt;&lt;span \
style='font-size:7.0pt;font-family:"Times New Roman"; color:black'&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style='color:black'&gt;LEGAL EFFECT. &lt;/span&gt;&lt;span \
class=body1char&gt;&lt;span style='color:black;font-weight:normal'&gt;This agreement describes \
certain legal rights. You may have other rights under the laws of your \
country. You may also have rights with respect to the party from whom you \
acquired the software. This agreement does not change your rights under the \
laws of your country if the laws of your country do not permit it to do \
so.&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;11.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New Roman";color:black'&gt; \
&lt;/span&gt;DISCLAIMER OF WARRANTY. The software is licensed as-is. \
You bear the risk of using it. Microsoft gives no express warranties, \
guarantees or conditions. You may have additional consumer rights under your \
local laws which this agreement cannot change. To the extent permitted under \
your local laws, Microsoft excludes the implied warranties of merchantability,
fitness for a particular purpose and non-infringement.&lt;/h1&gt;

&lt;h1 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;margin-left:
.25in;text-indent:-.25in'&gt;&lt;span style='color:black'&gt;12.&lt;/span&gt;&lt;span
style='font-size:7.0pt;font-family:"Times New Roman";color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;LIMITATION ON AND EXCLUSION OF REMEDIES AND DAMAGES. &lt;span
class=body1char&gt;You can recover from Microsoft and its suppliers only direct
damages up to U.S. $5.00. You cannot recover any other damages, including
consequential, lost profits, special, indirect or incidental damages. \
&lt;/span&gt;&lt;/span&gt;&lt;span style='font-weight:normal'&gt;This limitation applies \
to:&lt;/span&gt;&lt;/h1&gt;

&lt;p class=bullet3 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;
margin-left:.75in;text-indent:-.25in'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;anything related to the software, services, content
(including code) on third party Internet sites, or third party programs, \
and&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;
margin-left:.75in;text-indent:-.25in'&gt;&lt;span style='font-family:Symbol;
color:black'&gt;&lt;/span&gt;&lt;span style='font-size:7.0pt;font-family:"Times New Roman";
color:black'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;claims for breach of contract, breach of warranty,
guarantee or condition, strict liability, negligence, or other tort to the
extent permitted by applicable law.&lt;/span&gt;&lt;/p&gt;

&lt;p class=bullet3 style='margin-top:6.0pt;margin-right:0in;margin-bottom:6.0pt;
margin-left:.25in;text-indent:0in'&gt;&lt;span style='color:black'&gt;It also applies
even if Microsoft knew or should have known about the possibility of the
damages.&lt;/span&gt;&lt;span style='color:blue;layout-grid-mode:line'&gt; &lt;/span&gt;&lt;span
style='color:black'&gt;The&lt;/span&gt;&lt;span style='color:blue;layout-grid-mode:line'&gt; \
&lt;/span&gt;&lt;span class=body1char&gt;&lt;span style='color:black'&gt;above&lt;/span&gt;&lt;/span&gt;&lt;span
style='color:blue;layout-grid-mode:line'&gt; &lt;/span&gt;&lt;span style='color:black'&gt;limitation
or exclusion may not apply to you because your country may not allow the
exclusion or limitation of incidental, consequential or other damages.&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal&gt;Please note: As this software is distributed in Quebec, Canada, \
some of the clauses in this agreement are provided below in French.&lt;/p&gt;

&lt;p class=MsoNormal&gt;&lt;span lang=FR&gt;Remarque: Ce logiciel tant distribu au
Qubec, Canada, certaines des clauses dans ce contrat sont fournies ci-dessous
en franais.&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal&gt;&lt;b&gt;&lt;span lang=FR&gt;EXONRATION DE GARANTIE.&lt;/span&gt;&lt;/b&gt;&lt;span
lang=FR&gt; &lt;span class=body1char0&gt;Le logiciel vis&lt;/span&gt;&lt;span class=body1char0&gt;
par une licence est offert tel quel&lt;/span&gt;. Toute utilisation de
ce logiciel est  votre seule risque et pril. Microsoft naccorde aucune
garantie ou condition expresse. Vous pouvez disposer de droits de consommateur
additionnels que vous confrent vos lois locales, que la prsente licence ne
peut modifier. Dans la mesure permise par vos lois locales, les garanties
implicites de qualit marchande, dadaptation &lt;span class=body1char0&gt; un usage
particulier et dabsence de contrefa&lt;/span&gt;on sont exclues.&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal&gt;&lt;b&gt;&lt;span lang=FR&gt;LIMITATION DES DOMMAGES-INTRTS ET
EXCLUSION DE RESPONSABILIT POUR LES DOMMAGES.&lt;/span&gt;&lt;/b&gt;&lt;span lang=FR&gt; &lt;span
class=body1char0&gt;Vous pouvez obtenir de Microsoft et de ses fournisseurs une
indemnisation en cas de dommages directs uniquement  hauteur de
5,00$US. Vous ne pouvez prtendre  aucune indemnisation pour les
autres dommages, y compris les dommages spciaux, indirects ou accessoires et
pertes de bnfices.&lt;/span&gt;&lt;/span&gt; &lt;span lang=FR&gt;Cette limitation
concerne:&lt;/span&gt;&lt;/p&gt;

&lt;ul style='margin-top:0in' type=disc&gt;
 &lt;li class=MsoNormal style='color:black'&gt;&lt;span lang=FR&gt;toute matire relie au
     logiciel, aux services ou au contenu (y compris le code) figurant sur des
     sites Internet dune tirce partie ou dans des programmes dune tirce
     partie, et &lt;/span&gt;&lt;/li&gt;
 &lt;li class=MsoNormal style='color:black'&gt;&lt;span lang=FR&gt;les rclamations au
     titre de violation de contrat ou de garantie, ou au titre de
     responsabilit stricte, de ngligence ou dune autre faute dans la limite
     autorise par la loi en vigueur. &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=MsoNormal&gt;&lt;span lang=FR&gt;Elle sapplique galement, mme
siMicrosoft connaissait ou devrait connatre lventualit dun tel
dommage. Si votre pays nautorise pas lexclusion ou la limitation de
responsabilit pour les dommages indirects, accessoires ou de quelque nature
que ce soit, il se peut que la limitation ou lexclusion ci-dessus ne
sappliquera pas  votre gard.&lt;/span&gt;&lt;/p&gt;

&lt;p class=MsoNormal&gt;&lt;b&gt;&lt;span lang=FR&gt;EFFET JURIDIQUE. &lt;/span&gt;&lt;/b&gt;Le
prsent contrat dcrit certains droits juridiques. Vous pourriez avoir dautres
droits prvus par les lois de votre pays. Le prsent contrat ne modifie
pas les droits que vous confrent les lois de votre pays si cellesci ne
le permettent pas.&lt;/p&gt;

&lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110618231207</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-18 23:12:07-0400</timestampReceived><subject>[tor-dev] RFC: remove TorUtil.Enum</subject><body>

I have been reviewing the TorCtl package and I will be submitting
tickets (usually with patches) for clean-ups, fixes, etc.  Before I
submit a ticket for removing TorUtil.Enum, I wanted to hear from other
devs.  There are no users of this class within TorCtl, so Enum is now
cruft.  Does anyone have a problem with removing Enum?  If I do not
get negative feedback about this patch, I will submit it later in the
week.

  The following patch is also attached to this message as a gzipped patch file.

diff --git a/TorUtil.py b/TorUtil.py
index 3163d09..1d27144 100644
--- a/TorUtil.py
+++ b/TorUtil.py
@@ -22,7 +22,7 @@ if sys.version_info &lt; (2, 5):
 else:
   from hashlib import sha1

-__all__ = ["Enum", "Enum2", "Callable", "sort_list", "quote",
"escape_dots", "unescape_dots",
+__all__ = ["Enum2", "Callable", "sort_list", "quote", "escape_dots",
"unescape_dots",
       "BufSock", "secret_to_key", "urandom_rng", "s2k_gen",
"s2k_check", "plog",
      "ListenSocket", "zprob", "logfile", "loglevel", "loglevels"]

@@ -127,16 +127,6 @@ def read_config(filename):
   loglevel = config.get('TorCtl', 'loglevel')


-class Enum(object):
-  """ Defines an ordered dense name-to-number 1-1 mapping """
-  def __init__(self, start, names):
-    self.nameOf = {}
-    idx = start
-    for name in names:
-      setattr(self,name,idx)
-      self.nameOf[idx] = name
-      idx += 1
-
 class Enum2(object):
   """ Defines an ordered sparse name-to-number 1-1 mapping """
   def __init__(self, **args):
--
1.7.5.1

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org

["Remove-TorUtil.Enum.patch.gz" (application/x-gzip)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110618232520</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-06-18 23:25:20-0400</timestampReceived><subject>Re: [tor-dev] RFC: remove TorUtil.Enum</subject><body>

I don't have a problem with it being removed (though this is Mike's
call). I looked at it a bit for arm's enum implementation...
https://gitweb.torproject.org/arm.git/blob/HEAD:/src/util/enum.py

but that's about it. -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110619213542</emailId><senderName>Jrmy Bobbio</senderName><senderEmail>lunar@debian.org</senderEmail><timestampReceived>2011-06-19 21:35:42-0400</timestampReceived><subject>[tor-dev] [PATCH] Allow tordnsel to build on Squeeze</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi!

Quoting IRC:

  &lt;phobos&gt; I give up on tordnsel, I'm unable to get git head to compile
           in squeeze

Attached are 3 patches that allow tordnsel to build on a Squeeze system.
I unfortunately lack a test environment to ensure that the resulting
binary works fine. Haskell has proven quite trusty, though.

The work needed to make it work for the next versions of GHC (7.x) is
going to be an order of magnitude bigger, so it probably makes sense to
get the Python implementation working until Squeeze is EOL.

Cheers,
-- 
Jrmy Bobbio                        .''`. 
lunar@debian.org                    : :  :  # apt-get install anarchism
                                    `. `'` 
                                      `-   

["0001-Fix-cabal-warning.patch" (text/x-diff)]

From e21b7eaf5f54f5c56cd59c8651d0cf4bf1b6e3cf Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?J=C3=A9r=C3=A9my=20Bobbio?= &lt;lunar@debian.org&gt;
Date: Sun, 19 Jun 2011 21:32:05 +0200
Subject: [PATCH 1/3] Fix cabal warning

`-D` is actually an option relevant to the preprocessor and not GHC itself, so
move it to CPP-Options, as suggested.
---
 tordnsel.cabal |    3 ++-
 1 files changed, 2 insertions(+), 1 deletions(-)

diff --git a/tordnsel.cabal b/tordnsel.cabal
index 10f2bbb..b932533 100644
--- a/tordnsel.cabal
+++ b/tordnsel.cabal
@@ -59,7 +59,8 @@ Other-Modules:   TorDNSEL.Config,
 HS-Source-Dirs:  src
 Includes:        sys/types.h, unistd.h, sysexits.h, netinet/in.h, openssl/rand.h
 Extra-Libraries: crypto
-GHC-Options:     -O2 -Wall -Werror -DVERSION="0.0.6-dev"
+GHC-Options:     -O2 -Wall -Werror
+CPP-Options:     -DVERSION="0.0.6-dev"
 
 Executable:      runtests
 Buildable:       False
-- 
1.7.2.5


["0002-Reimplement-hGetLine-in-a-more-stupid-way.patch" (text/x-diff)]

From a114bdb9a296071c7b08761283c2a5bf17c3c2c4 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?J=C3=A9r=C3=A9my=20Bobbio?= &lt;lunar@debian.org&gt;
Date: Sun, 19 Jun 2011 23:16:26 +0200
Subject: [PATCH 2/3] Reimplement hGetLine (in a more stupid way)

hGetLine was previously neat and clever, but it does not build with GHC 6.12.
All callers were actually looking for "\n" or "\r\n". So let's simplify, look
out for '\n' and strip '\r' if it is the character right before.
---
 src/TorDNSEL/ExitTest/Request.hs     |    4 +-
 src/TorDNSEL/TorControl/Internals.hs |    4 +-
 src/TorDNSEL/Util.hsc                |  124 +++++-----------------------------
 3 files changed, 21 insertions(+), 111 deletions(-)

diff --git a/src/TorDNSEL/ExitTest/Request.hs b/src/TorDNSEL/ExitTest/Request.hs
index 87a2fbd..570699b 100644
--- a/src/TorDNSEL/ExitTest/Request.hs
+++ b/src/TorDNSEL/ExitTest/Request.hs
@@ -73,14 +73,14 @@ getRequest client = do
     crlfLen = 2
 
     getHeader = do
-      reqLine &lt;- hGetLine client crlf maxHeaderLen
+      reqLine &lt;- hGetLine client maxHeaderLen
       headers &lt;- getHeaders (maxHeaderLen - B.length reqLine - crlfLen)
       return (reqLine, M.fromList headers)
 
     getHeaders remain
       | remain &lt;= 0 = return []
       | otherwise = do
-          header &lt;- hGetLine client crlf remain
+          header &lt;- hGetLine client remain
           if B.null header
             then return []
             else do
diff --git a/src/TorDNSEL/TorControl/Internals.hs b/src/TorDNSEL/TorControl/Internals.hs
index 015bd76..bace805 100644
--- a/src/TorDNSEL/TorControl/Internals.hs
+++ b/src/TorDNSEL/TorControl/Internals.hs
@@ -847,7 +847,7 @@ startSocketReader handle sendRepliesToIOManager =
   forkLinkIO . forever $ readReplies &gt;&gt;= sendRepliesToIOManager
   where
     readReplies = do
-      line &lt;- parseReplyLine =&lt;&lt; hGetLine handle crlf maxLineLength
+      line &lt;- parseReplyLine =&lt;&lt; hGetLine handle maxLineLength
       case line of
         MidReply reply  -&gt; fmap (reply :) readReplies
         LastReply reply -&gt; return [reply]
@@ -865,7 +865,7 @@ startSocketReader handle sendRepliesToIOManager =
                       cat "Malformed reply line type " (esc 1 typ) '.'
 
     readData = do
-      line &lt;- hGetLine handle (B.pack "\n") maxLineLength
+      line &lt;- hGetLine handle maxLineLength
       case (if B.last line == '\r' then B.init else id) line of
         line' | line == (B.pack ".\r")   -&gt; return []
               | any B.null [line, line'] -&gt; readData
diff --git a/src/TorDNSEL/Util.hsc b/src/TorDNSEL/Util.hsc
index bb81b43..0f471fd 100644
--- a/src/TorDNSEL/Util.hsc
+++ b/src/TorDNSEL/Util.hsc
@@ -132,18 +132,12 @@ import Network.Socket
 import System.Directory (doesFileExist, removeFile)
 import System.Environment (getProgName)
 import System.Exit (exitWith, ExitCode)
-import System.IO (hPutStr)
+import System.IO (Handle, hPutStr, hGetChar)
 import System.IO.Error (isEOFError)
 import System.Posix.Files (setFileMode)
 import System.Posix.Types (FileMode)
 import Text.Printf (printf)
 
-import GHC.Handle
-  (wantReadableHandle, fillReadBuffer, readCharFromBuffer, ioe_EOF)
-import GHC.IOBase
-  ( Handle, Handle__(..), Buffer(..), readIORef, writeIORef
-  , BufferMode(NoBuffering) )
-
 import Data.Binary (Binary(..))
 
 import TorDNSEL.DeepSeq
@@ -368,113 +362,29 @@ instance Error e =&gt; MonadError e Maybe where
 foreign import ccall unsafe "htonl" htonl :: Word32 -&gt; Word32
 foreign import ccall unsafe "ntohl" ntohl :: Word32 -&gt; Word32
 
--- | Read a line terminated by an arbitrary sequence of bytes from a handle. The
+-- | Read a line terminated by an LF or CRLF from a handle. The
 -- end-of-line sequence is stripped before returning the line. @maxLen@
 -- specifies the maximum line length to read, not including the end-of-line
 -- sequence. If the line length exceeds @maxLen@, return the first @maxLen@
 -- bytes. If EOF is encountered, return the bytes preceding it. The handle
 -- should be in 'LineBuffering' mode.
-hGetLine :: Handle -&gt; ByteString -&gt; Int -&gt; IO ByteString
-hGetLine h eol maxLen | B.null eol = B.hGet h maxLen
-hGetLine h eol@(B.PS _ _ eolLen) maxLen
-  = wantReadableHandle "TorDNSEL.Util.hGetLine" h $ \handle_ -&gt; do
-      case haBufferMode handle_ of
-        NoBuffering -&gt; error "no buffering"
-        _other      -&gt; hGetLineBuffered handle_
+hGetLine :: Handle -&gt; Int -&gt; IO ByteString
+hGetLine h maxLen =
+  do str &lt;- readStr maxLen B.empty
+     let result = case B.uncons str of
+           Nothing           -&gt; B.empty
+           Just ('\r', str') -&gt; str'
+           Just _            -&gt; str
+     return $ B.reverse result
 
   where
-    hGetLineBuffered handle_ = do
-      let ref = haBuffer handle_
-      buf &lt;- readIORef ref
-      hGetLineBufferedLoop handle_ ref buf 0 0 []
-
-    hGetLineBufferedLoop handle_ ref
-      buf@Buffer{ bufRPtr=r, bufWPtr=w, bufBuf=raw } !len !eolIx xss = do
-        (new_eolIx,off) &lt;- findEOL eolIx r w raw
-        let new_len = len + off - r
-
-        if maxLen &gt; 0 &amp;&amp; new_len - new_eolIx &gt; maxLen
-          -- If the line length exceeds maxLen, return a partial line.
-          then do
-            let maxOff = off - (new_len - maxLen)
-            writeIORef ref buf{ bufRPtr = maxOff }
-            mkBigPS . (:xss) =&lt;&lt; mkPS raw r maxOff
-          else if new_eolIx == eolLen
-            -- We have a complete line; strip the EOL sequence and return it.
-            then do
-              if w == off
-                then writeIORef ref buf{ bufRPtr=0, bufWPtr=0 }
-                else writeIORef ref buf{ bufRPtr = off }
-              if eolLen &lt;= off - r
-                then mkBigPS . (:xss) =&lt;&lt; mkPS raw r (off - eolLen)
-                else fmap stripEOL . mkBigPS . (:xss) =&lt;&lt; mkPS raw r off
-            else do
-              xs &lt;- mkPS raw r off
-              maybe_buf &lt;- maybeFillReadBuffer (haFD handle_) True
-                             (haIsStream handle_) buf{ bufWPtr=0, bufRPtr=0 }
-              case maybe_buf of
-                -- Nothing indicates we caught an EOF, and we may have a
-                -- partial line to return.
-                Nothing -&gt; do
-                  writeIORef ref buf{ bufRPtr=0, bufWPtr=0 }
-                  if new_len &gt; 0
-                    then mkBigPS (xs:xss)
-                    else ioe_EOF
-                Just new_buf -&gt;
-                  hGetLineBufferedLoop handle_ ref new_buf new_len new_eolIx
-                                       (xs:xss)
-
-    maybeFillReadBuffer fd is_line is_stream buf
-      = catch (Just `fmap` fillReadBuffer fd is_line is_stream buf)
-              (\e -&gt; if isEOFError e then return Nothing else ioError e)
-
-    findEOL eolIx
-      | eolLen == 1 = findEOLChar (B.w2c $ B.unsafeHead eol)
-      | otherwise   = findEOLSeq eolIx
-
-    findEOLChar eolChar r w raw
-      | r == w = return (0, r)
-      | otherwise = do
-          (!c,!r') &lt;- readCharFromBuffer raw r
-          if c == eolChar
-            then return (1, r')
-            else findEOLChar eolChar r' w raw
-
-    -- find the end-of-line sequence, if there is one
-    findEOLSeq !eolIx r w raw
-      | eolIx == eolLen || r == w = return (eolIx, r)
-      | otherwise = do
-          (!c,!r') &lt;- readCharFromBuffer raw r
-          findEOLSeq (next c eolIx + 1) r' w raw
-
-    -- get the next index into the EOL sequence we should match against
-    next !c !i = if i &gt;= 0 &amp;&amp; c /= eolIndex i then next c (table ! i) else i
-
-    eolIndex = B.w2c . B.unsafeIndex eol
-
-    -- build a match table for the Knuth-Morris-Pratt algorithm
-    table = runSTUArray (do
-      arr &lt;- newArray_ (0, if eolLen == 1 then 1 else eolLen - 1)
-      zipWithM_ (writeArray arr) [0,1] [-1,0]
-      loop arr 2 0)
-      where
-        loop arr !t !p
-          | t &gt;= eolLen = return arr
-          | eolIndex (t - 1) == eolIndex p
-          = let p' = p + 1 in writeArray arr t p' &gt;&gt; loop arr (t + 1) p'
-          | p &gt; 0 = readArray arr p &gt;&gt;= loop arr t
-          | otherwise = writeArray arr t 0 &gt;&gt; loop arr (t + 1) p
-
-    stripEOL (B.PS p s l) = E.assert (new_len &gt;= 0) . B.copy $ B.PS p s new_len
-      where new_len = l - eolLen
-
-    mkPS buf start end = B.create len $ \p -&gt; do
-      B.memcpy_ptr_baoff p buf (fromIntegral start) (fromIntegral len)
-      return ()
-      where len = end - start
-
-    mkBigPS [ps] = return ps
-    mkBigPS pss  = return $! B.concat (reverse pss)
+
+  readStr 0   str = return str
+  readStr rem str = catch
+      (do c &lt;- hGetChar h
+          if c == '\n' then return str
+                       else readStr (rem - 1) (c `B.cons` str))
+      (\e -&gt; if isEOFError e then return str else ioError e)
 
 -- | Split @bs@ into pieces delimited by @delimiter@, consuming the delimiter.
 -- The result for overlapping delimiters is undefined.
-- 
1.7.2.5


["0003-Continue-using-Control.OldException-with-GHC-6.12.patch" (text/x-diff)]

From cff25673b99a4e776b97635e59308f6957b38ccd Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?J=C3=A9r=C3=A9my=20Bobbio?= &lt;lunar@debian.org&gt;
Date: Sun, 19 Jun 2011 23:29:54 +0200
Subject: [PATCH 3/3] Continue using Control.OldException with GHC 6.12

We also need to build without -Werror as OldException are very much deprecated.
---
 src/TorDNSEL/Compat/Exception.hs |    2 +-
 tordnsel.cabal                   |    2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/src/TorDNSEL/Compat/Exception.hs b/src/TorDNSEL/Compat/Exception.hs
index b206513..73249ce 100644
--- a/src/TorDNSEL/Compat/Exception.hs
+++ b/src/TorDNSEL/Compat/Exception.hs
@@ -19,7 +19,7 @@ module TorDNSEL.Compat.Exception (
     module Exception
   ) where
 
-#if __GLASGOW_HASKELL__ == 610
+#if (__GLASGOW_HASKELL__ == 610) || (__GLASGOW_HASKELL__ == 612)
 import Control.OldException as Exception
 #else
 import Control.Exception as Exception
diff --git a/tordnsel.cabal b/tordnsel.cabal
index b932533..a7942ca 100644
--- a/tordnsel.cabal
+++ b/tordnsel.cabal
@@ -59,7 +59,7 @@ Other-Modules:   TorDNSEL.Config,
 HS-Source-Dirs:  src
 Includes:        sys/types.h, unistd.h, sysexits.h, netinet/in.h, openssl/rand.h
 Extra-Libraries: crypto
-GHC-Options:     -O2 -Wall -Werror
+GHC-Options:     -O2 -Wall
 CPP-Options:     -DVERSION="0.0.6-dev"
 
 Executable:      runtests
-- 
1.7.2.5


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110608121906</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-06-08 12:19:06-0400</timestampReceived><subject>[tor-dev] Tor AF independence patch - first big step to Tor IPv6</subject><body>

Hi,

As this is World IPv6 day, let me present the first big step to Tor
IPv6: the Address Family independence Patch ;)

https://unfix.org/projects/ipv6/tor/tor-af-independent.diff

it is diff against a recent git checkout and should apply more or less
cleanly.

Why AF independence[1,2] and not "IPv6 patch", well, for a program to be
able to support IPv6 it should first not care about IP in the first
place. With Tor that is a tricky thing as it actually needs to know
about IP for quite a few places.

As such this patch primary function is to make most functions use
toraddr_t, that way both IPv6 and IPv4 are supported.

Note that a lot of functionality for supporting IPv6 (or any other IP
protocol in the longer term) is already present in current versions of
Tor (even unittests are present already!).

Note also that this is not a 'true' AF indepencence patch as in that
case we would have to swap toraddr_t with a sockaddr_storage structure,
which, when recompiled, would be true AF independent. In the case though
that ever a new IP-alike protocol arises and then we still use BSD style
sockets, this patch should make it easy to use that new address family
too, but don't hold your breath ;)

The problem with that though is that at this stage that means that
everywhere IPv6 can be stuck just like IPv4 while these should be
separate. And to make it a bit worse, one should actually have them also
properly in the packets being sent between nodes and there is no
separation between exit policies etc.

There is thus a lot to discuss on this subject, and one of the first
things that really need to be done is ORMultiPort (proposal 118) to be
able to separate IPv4 and IPv6 ports.

A question there also becomes, do we want to show a Tor node as separate
IPv4 and IPv6 routers, or are they to be seen as one, if it is one, we
require the above ORMultiport, so that we can have multiple IP addresses
and ports on a single node.

As such, I suggest we have a big discussion on the flaws of my patch and
how to resolve some of the remaining problems and then start moving work
to the ORMultPort patch so that we can start enabling IPv6 everywhere,
as then we are getting quite close.

And maybe, it could be useful to have a special branch on torproject's
git server for this, as it is quite a bit of patch ;)

Greets,
 Jeroen

(fuzzel on #tor-dev)

[1] = http://www.kame.net/newsletter/19980604/
[2] = http://gsyc.escet.urjc.es/~eva/IPv6-web/ipv6.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110619160330</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-19 16:03:30-0400</timestampReceived><subject>[tor-dev] TOR control protocol timeout</subject><body>

  Is there a defined timeout for the TOR control protocol?  How long
should a control port client wait around for socket data when reading?
 Or writing?  The only references to timeouts that I find in
control-spec.txt are about circuit and stream timeouts reported back
through the control port.

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609001158</emailId><senderName>Sambuddho Chakravarty</senderName><senderEmail>sc2516@columbia.edu</senderEmail><timestampReceived>2011-06-09 00:11:58-0400</timestampReceived><subject>[tor-dev] Reg : using the keep alive messages</subject><body>

[Attachment #2 (multipart/alternative)]


Hi All
I read in the Tor design spec that Tor control protocol supports keepalive
messages which could be used for link padding . I wonder if anyone has ever
explored using them...

Thanks
Sambuddho

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi All  &lt;div&gt;I read in the Tor design spec that Tor control protocol \
supports keepalive messages which could be used for link padding . I wonder if anyone \
has ever explored using them...&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;

Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110620223207</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-06-20 22:32:07-0400</timestampReceived><subject>[tor-dev] WIN32_WINNT in or/or.h</subject><body>

I think that the values for 'WIN32_WINNT' and '_WIN32_WINNT'
should be protected against redefinement. 

Reason: In order for MingW to prototype getaddrinfo() and freeaddrinfo() 
correctly (in &lt;ws2tcpip.h&gt;), '_WIN32_WINNT' *must* be defined as 0x0501
or higher. or/or.h blindly defines them as 0x0400. So, building with 
-DHAVE_GETADDRINFO needs _WIN32_WINNT to be set to 0x0501.

As of now, MingW would simply fallback to use gethostbyname(). So I think this
little patch is in order:

--- ..\Git-latest\src\or\or.h   Mon Jun 20 23:58:06 2011
+++ or\or.h     Tue Jun 21 00:04:42 2011
@@ -23,8 +23,12 @@
 #endif

 #ifdef MS_WINDOWS
+#ifndef WIN32_WINNT
 #define WIN32_WINNT 0x400
+#endif
+#ifndef _WIN32_WINNT
 #define _WIN32_WINNT 0x400
+#endif
 #define WIN32_LEAN_AND_MEAN
 #endif

-----------------------------

What do you say?

--gv

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609145955</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 14:59:55-0400</timestampReceived><subject>[tor-dev] Tor and BGP integration</subject><body>

[Attachment #2 (multipart/alternative)]


Hello from Iceland,

Linus invited me to Reykjavik to talk about Tor at the NORDUnet conference
and this idea is the result of a bit of feedback from some network operators
here.

Tor needs a way to be friendly to large network operators who wish to enable
exiting to anonymous communication for their networks. These network
operators are happy to allow anyone to pass traffic to their relays as entry
nodes, middle nodes and even limited exit nodes.

Linus and I have been discussing methods of automating this process and of
course BGP integration makes a lot of sense. Generally, a network operator
has a set of AS numbers for their network blocks and as they want people to
connect to many of their services, it helps quite a bit to allow exiting to
those services from their own Tor relays.

We came up with two main ideas for making this happen.

One method would be to write a program where given an AS number and a BGP
feed, we parse all of the advertised network blocks and emit exit policy
lines that accepts all traffic for the AS. This would allow for a web
service similar to BulkExitList.py for network aware exit policy generation
and relay operators would simply need to add this to their Tor configs
manually. For mostly static networks, a cronjob would be fine and Tor
doesn't need to know about AS numbers internally.

Another method would be to write a controller that watches for BGP network
updates and Tor would add relevant exit policy lines for any configured AS.
This would allow any Tor relay to dynamically learn about network changes if
it has access to a BGP feed patched into a controller. This could be
implemented by adding some configuration options to Tor that let Tor know
which AS numbers matter to which router. It may also allow for the router to
auto learn it's own likely family network but it lacks any kind of
bi-directional confirmation, still it seems useful information to have...

It would be fantastic if someone offered a hidden service NORDUNet BGPMon
feed. This would help enable the first method of generating network aware
exit policies; this would also help with the development of AS awareness in
Tor itself. In the future, I imagine that it makes a lot of sense for
circuit building to be BGP aware as mere netblocks will not be very useful
in an ipv6 world, they're already mostly irrelevant.

Anyway, food for thought. Linus and I will probably hack on some of these
ideas in the near future.

All the best,
Jake

[Attachment #5 (text/html)]

&lt;meta http-equiv="content-type" content="text/html; charset=utf-8"&gt;&lt;div&gt;Hello from \
Iceland,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Linus invited me to Reykjavik to talk about Tor at \
the NORDUnet conference and this idea is the result of a bit of feedback from some \
network operators here.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Tor needs a way to be friendly to \
large network operators who wish to enable exiting to anonymous communication for \
their networks. These network operators are happy to allow anyone to pass traffic to \
their relays as entry nodes, middle nodes and even limited exit nodes.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Linus and I have been discussing methods of automating this \
process and of course BGP integration makes a lot of sense. Generally, a network \
operator has a set of AS numbers for their network blocks and as they want people to \
connect to many of their services, it helps quite a bit to allow exiting to those \
services from their own Tor relays.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We came up with two \
main ideas for making this happen.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;One method would be to \
write a program where given an AS number and a BGP feed, we parse all of the \
advertised network blocks and emit exit policy lines that accepts all traffic for the \
AS. This would allow for a web service similar to BulkExitList.py for network aware \
exit policy generation and relay operators would simply need to add this to their Tor \
configs manually. For mostly static networks, a cronjob would be fine and Tor \
doesn't need to know about AS numbers internally.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Another method would be to write a controller that watches for \
BGP network updates and Tor would add relevant exit policy lines for any configured \
AS. This would allow any Tor relay to dynamically learn about network changes if it \
has access to a BGP feed patched into a controller. This could be implemented by \
adding some configuration options to Tor that let Tor know which AS numbers matter to \
which router. It may also allow for the router to auto learn it's own likely \
family network but it lacks any kind of bi-directional confirmation, still it seems \
useful information to have...&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It would be fantastic if \
someone offered a hidden service NORDUNet BGPMon feed. This would help enable the \
first method of generating network aware exit policies; this would also help with the \
development of AS awareness in Tor itself. In the future, I imagine that it makes a \
lot of sense for circuit building to be BGP aware as mere netblocks will not be very \
useful in an ipv6 world, they're already mostly irrelevant.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Anyway, food for thought. Linus and I will probably hack on some \
of these ideas in the near future.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the \
best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609170932</emailId><senderName>Arturo</senderName><senderEmail>art@baculo.org</senderEmail><timestampReceived>2011-06-09 17:09:32-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

Hello,

This seems to me like a really neat idea!

Reading from real time BGP feeds is not a simple task and I think it
might be a bit of an overhead for the average Tor user.

On the other hand it could be a good idea to have some nodes run tools
to generate exit policies or at least provide BGP routing information in
a easy to consume format for the tor clients to use.

I have been doing some experimenting on getting and analysing BGP
information and these are the resources that I have found useful:

- http://archive.routeviews.org/ - For getting raw MRT format BGP feeds
and also the output of `bgp show ip`

- http://www-01.pch.net/resources/data/routing-tables/archive/2011/ -
Routing information from other "probes"

- https://github.com/hellais/PyRT - A quick patch I made to make PyRT
work on python &gt; 2.3 (useful for parsing MRT format files), original:
https://research.sprintlabs.com/pyrt/

IXPs:

- http://www.pch.net/resources/data/routing-tables/looking-glass/

- https://www.peeringdb.com/private/index.php - Very complete database
on peers and ASN information. They also provide a very nice API for
interacting with their database.

I have been working on some python code for adding BGP support to
blockfinder. It basically just parses the results of the `bgp show ip`
command outputs obtainable from route views and stores the routing paths
inside a database.
It needs to be cleaned up a bit, but if you are interested in using it I
can hack on it some more.

Let me know of the progress you make :)

- Arturo `hellais`

&gt; Hello from Iceland,
&gt; 
&gt; Linus invited me to Reykjavik to talk about Tor at the NORDUnet conference
&gt; and this idea is the result of a bit of feedback from some network operators
&gt; here.
&gt; 
&gt; Tor needs a way to be friendly to large network operators who wish to enable
&gt; exiting to anonymous communication for their networks. These network
&gt; operators are happy to allow anyone to pass traffic to their relays as entry
&gt; nodes, middle nodes and even limited exit nodes.
&gt; 
&gt; Linus and I have been discussing methods of automating this process and of
&gt; course BGP integration makes a lot of sense. Generally, a network operator
&gt; has a set of AS numbers for their network blocks and as they want people to
&gt; connect to many of their services, it helps quite a bit to allow exiting to
&gt; those services from their own Tor relays.
&gt; 
&gt; We came up with two main ideas for making this happen.
&gt; 
&gt; One method would be to write a program where given an AS number and a BGP
&gt; feed, we parse all of the advertised network blocks and emit exit policy
&gt; lines that accepts all traffic for the AS. This would allow for a web
&gt; service similar to BulkExitList.py for network aware exit policy generation
&gt; and relay operators would simply need to add this to their Tor configs
&gt; manually. For mostly static networks, a cronjob would be fine and Tor
&gt; doesn't need to know about AS numbers internally.
&gt; 
&gt; Another method would be to write a controller that watches for BGP network
&gt; updates and Tor would add relevant exit policy lines for any configured AS.
&gt; This would allow any Tor relay to dynamically learn about network changes if
&gt; it has access to a BGP feed patched into a controller. This could be
&gt; implemented by adding some configuration options to Tor that let Tor know
&gt; which AS numbers matter to which router. It may also allow for the router to
&gt; auto learn it's own likely family network but it lacks any kind of
&gt; bi-directional confirmation, still it seems useful information to have...
&gt; 
&gt; It would be fantastic if someone offered a hidden service NORDUNet BGPMon
&gt; feed. This would help enable the first method of generating network aware
&gt; exit policies; this would also help with the development of AS awareness in
&gt; Tor itself. In the future, I imagine that it makes a lot of sense for
&gt; circuit building to be BGP aware as mere netblocks will not be very useful
&gt; in an ipv6 world, they're already mostly irrelevant.
&gt; 
&gt; Anyway, food for thought. Linus and I will probably hack on some of these
&gt; ideas in the near future.
&gt; 
&gt; All the best,
&gt; Jake

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609180717</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2011-06-09 18:07:17-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote
Thu, 9 Jun 2011 14:59:55 +0000:

| Hello from Iceland,

Hello from a strikestrucken Keflavkurflugvllur,


| We came up with two main ideas for making this happen.

Thanks for the writeup.


| Another method would be to write a controller that watches for BGP network
| updates and Tor would add relevant exit policy lines for any configured AS.
| This would allow any Tor relay to dynamically learn about network changes if
| it has access to a BGP feed patched into a controller. This could be
| implemented by adding some configuration options to Tor that let Tor know
| which AS numbers matter to which router. It may also allow for the router to
| auto learn it's own likely family network but it lacks any kind of
| bi-directional confirmation, still it seems useful information to have...

This is what I'd prefer.


| It would be fantastic if someone offered a hidden service NORDUNet BGPMon
| feed. This would help enable the first method of generating network aware

Yes.


| exit policies; this would also help with the development of AS awareness in
| Tor itself. In the future, I imagine that it makes a lot of sense for
| circuit building to be BGP aware as mere netblocks will not be very useful
| in an ipv6 world, they're already mostly irrelevant.

The BGPmon we were discussing is the one at colostate.edu[0], not the
other one.


| Anyway, food for thought. Linus and I will probably hack on some of these
| ideas in the near future.

I'm already running something[1] that is collecting a feed and storing
it in an SQL database.  I should tech it i) how to emit torrc Export
lines and ii) the Tor control protocol ("exit-policy/default").


[0] http://bgpmon.netsec.colostate.edu
[1] http://git.nordu.net/?p=bgp-logger.git
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110528215228</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-28 21:52:28-0400</timestampReceived><subject>[tor-dev] The Torouter and the DreamPlug</subject><body>

Hi everyone,

DreamPlug is a new plug computer from GlobalScale Technologies:
http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
looks good, it runs Ubuntu by default and it doesn't cost too much. I
thought that the DreamPlug was going to be very user friendly and a
potential candidate for the Torouter project. (Maybe) I was wrong.

When the SheevaPlug came out a couple of years ago, it shipped with a
web interface that enabled users to change various network options. I
thought the DreamPlug would ship with some kind of interface as well
(and my plan was to just plug in a Tor page). This is not the case; it
ships with lighthttpd by default and displays a static and very simple
placeholder page on 192.168.1.1.

If we want to use the DreamPlug for the Torouter, we will have to
write a web interface for easy configuration of Tor. The interface
should probably also provide options to better secure the DreamPlug.
Downloading and installing Tor isn't a problem, but the configuration
side of things can be tricky for users who aren't used to the command
line.

Thoughts? Comments?

Thanks,

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110529232100</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-05-29 23:21:00-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; Hi everyone,
&gt;
&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt; thought that the DreamPlug was going to be very user friendly and a
&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt;

When the SheevaPlug came out a couple of years ago, it shipped with a
&gt; web interface that enabled users to change various network options. I
&gt; thought the DreamPlug would ship with some kind of interface as well
&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt; ships with lighthttpd by default and displays a static and very simple
&gt; placeholder page on 192.168.1.1.
&gt;

That's great news. A complex web app is just a giant PITA and huge attack
surface anyhow.


&gt;
&gt; If we want to use the DreamPlug for the Torouter, we will have to
&gt; write a web interface for easy configuration of Tor. The interface
&gt; should probably also provide options to better secure the DreamPlug.
&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt; side of things can be tricky for users who aren't used to the command
&gt; line.
&gt;

Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
a basic status of Tor out to a static html file?


&gt;
&gt; Thoughts? Comments?
&gt;
&gt;
The Freedombox will likely run on the dream plug, it's the reference
platform. I think we should work on ensuring that if we ship a dream plug,
we ship a freedombox pre-configured to run Tor - this will likely be the
case with the FB anyway:
http://wiki.debian.org/FreedomBox

Basically Tor needs some kind of webui package in Debian and we'd be good to
go.

All the best from Egypt,
Jake

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; Hi everyone,&lt;br&gt;
&lt;br&gt;
DreamPlug is a new plug computer from GlobalScale Technologies:&lt;br&gt;
&lt;a href="http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx" \
target="_blank"&gt;http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx&lt;/a&gt;. The \
spec&lt;br&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. \
I&lt;br&gt; thought that the DreamPlug was going to be very user friendly and a&lt;br&gt;
potential candidate for the Torouter project. (Maybe) I was wrong.&lt;br&gt; \
&lt;/blockquote&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; When the SheevaPlug came out a couple of years ago, it \
shipped with a&lt;br&gt; web interface that enabled users to change various network \
options. I&lt;br&gt; thought the DreamPlug would ship with some kind of interface as \
well&lt;br&gt; (and my plan was to just plug in a Tor page). This is not the case; it&lt;br&gt;
ships with lighthttpd by default and displays a static and very simple&lt;br&gt;
placeholder page on 192.168.1.1.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That's great \
news. A complex web app is just a giant PITA and huge attack surface \
anyhow.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

&lt;br&gt;
If we want to use the DreamPlug for the Torouter, we will have to&lt;br&gt;
write a web interface for easy configuration of Tor. The interface&lt;br&gt;
should probably also provide options to better secure the DreamPlug.&lt;br&gt;
Downloading and installing Tor isn't a problem, but the configuration&lt;br&gt;
side of things can be tricky for users who aren't used to the command&lt;br&gt;
line.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Or perhaps we can just turn Tor on by \
default, ship tor-fw-helper and write a basic status of Tor out to a static html \
file?&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

&lt;br&gt;
Thoughts? Comments?&lt;br&gt;&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The Freedombox will \
likely run on the dream plug, it's the reference platform. I think we should work \
on ensuring that if we ship a dream plug, we ship a freedombox pre-configured to run \
Tor - this will likely be the case with the FB anyway:&lt;/div&gt; &lt;div&gt;&lt;meta \
http-equiv="content-type" content="text/html; charset=utf-8"&gt;&lt;a \
href="http://wiki.debian.org/FreedomBox"&gt;http://wiki.debian.org/FreedomBox&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Basically \
Tor needs some kind of webui package in Debian and we'd be good to go.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best from Egypt,&lt;/div&gt;&lt;div&gt;Jake &lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110529233524</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-29 23:35:24-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 12:21 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt;&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt;&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt;&gt; thought that the DreamPlug was going to be very user friendly and a
&gt;&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt;&gt;
&gt;&gt;
&gt;&gt; When the SheevaPlug came out a couple of years ago, it shipped with a
&gt;&gt; web interface that enabled users to change various network options. I
&gt;&gt; thought the DreamPlug would ship with some kind of interface as well
&gt;&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt;&gt; ships with lighthttpd by default and displays a static and very simple
&gt;&gt; placeholder page on 192.168.1.1.
&gt;
&gt; That's great news. A complex web app is just a giant PITA and huge attack
&gt; surface anyhow.

Yeah, that's true.

&gt;&gt; If we want to use the DreamPlug for the Torouter, we will have to
&gt;&gt; write a web interface for easy configuration of Tor. The interface
&gt;&gt; should probably also provide options to better secure the DreamPlug.
&gt;&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt;&gt; side of things can be tricky for users who aren't used to the command
&gt;&gt; line.
&gt;
&gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt; a basic status of Tor out to a static html file?

Users who aren't familiar with the command line will probably still
have a problem configuring Tor. I think that a webui package in
Debian/Ubuntu is the best way to go.

&gt;&gt;
&gt;&gt; Thoughts? Comments?
&gt;&gt;
&gt;
&gt; The Freedombox will likely run on the dream plug, it's the reference
&gt; platform. I think we should work on ensuring that if we ship a dream plug,
&gt; we ship a freedombox pre-configured to run Tor - this will likely be the
&gt; case with the FB anyway:
&gt; http://wiki.debian.org/FreedomBox
&gt; Basically Tor needs some kind of webui package in Debian and we'd be good to
&gt; go.

Yep, sounds good.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110529234527</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-05-29 23:45:27-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Mon, May 30, 2011 at 1:35 AM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; On Mon, May 30, 2011 at 12:21 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt; wrote:
&gt; &gt; On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik &lt;
&gt; runa.sandvik@gmail.com&gt;
&gt; &gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Hi everyone,
&gt; &gt;&gt;
&gt; &gt;&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt; &gt;&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt; &gt;&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt; &gt;&gt; thought that the DreamPlug was going to be very user friendly and a
&gt; &gt;&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; When the SheevaPlug came out a couple of years ago, it shipped with a
&gt; &gt;&gt; web interface that enabled users to change various network options. I
&gt; &gt;&gt; thought the DreamPlug would ship with some kind of interface as well
&gt; &gt;&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt; &gt;&gt; ships with lighthttpd by default and displays a static and very simple
&gt; &gt;&gt; placeholder page on 192.168.1.1.
&gt; &gt;
&gt; &gt; That's great news. A complex web app is just a giant PITA and huge attack
&gt; &gt; surface anyhow.
&gt;
&gt; Yeah, that's true.
&gt;
&gt; &gt;&gt; If we want to use the DreamPlug for the Torouter, we will have to
&gt; &gt;&gt; write a web interface for easy configuration of Tor. The interface
&gt; &gt;&gt; should probably also provide options to better secure the DreamPlug.
&gt; &gt;&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt; &gt;&gt; side of things can be tricky for users who aren't used to the command
&gt; &gt;&gt; line.
&gt; &gt;
&gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and
&gt; write
&gt; &gt; a basic status of Tor out to a static html file?
&gt;
&gt; Users who aren't familiar with the command line will probably still
&gt; have a problem configuring Tor. I think that a webui package in
&gt; Debian/Ubuntu is the best way to go.
&gt;
&gt;
Why would they have to configure anything on our router? They just need to
open a port or let it happen automatically, right?


&gt; &gt;&gt;
&gt; &gt;&gt; Thoughts? Comments?
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; The Freedombox will likely run on the dream plug, it's the reference
&gt; &gt; platform. I think we should work on ensuring that if we ship a dream
&gt; plug,
&gt; &gt; we ship a freedombox pre-configured to run Tor - this will likely be the
&gt; &gt; case with the FB anyway:
&gt; &gt; http://wiki.debian.org/FreedomBox
&gt; &gt; Basically Tor needs some kind of webui package in Debian and we'd be good
&gt; to
&gt; &gt; go.
&gt;
&gt; Yep, sounds good.
&gt;
&gt; --
&gt; Runa A. Sandvik
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;On Mon, May 30, 2011 at 1:35 AM, Runa A. Sandvik &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Mon, May 30, 2011 at 12:21 AM, \
Jacob Appelbaum &lt;&lt;a href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt; &gt; On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik &lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;br&gt; &gt; \
wrote:&lt;br&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; Hi everyone,&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; DreamPlug is a new plug computer from GlobalScale Technologies:&lt;br&gt;
&gt;&gt; &lt;a href="http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx" \
target="_blank"&gt;http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx&lt;/a&gt;. The \
spec&lt;br&gt; &gt;&gt; looks good, it runs Ubuntu by default and it doesn't cost too \
much. I&lt;br&gt; &gt;&gt; thought that the DreamPlug was going to be very user friendly \
and a&lt;br&gt; &gt;&gt; potential candidate for the Torouter project. (Maybe) I was \
wrong.&lt;br&gt; &gt;&gt;&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; When the SheevaPlug came out a couple of years ago, it shipped with a&lt;br&gt;
&gt;&gt; web interface that enabled users to change various network options. I&lt;br&gt;
&gt;&gt; thought the DreamPlug would ship with some kind of interface as well&lt;br&gt;
&gt;&gt; (and my plan was to just plug in a Tor page). This is not the case; it&lt;br&gt;
&gt;&gt; ships with lighthttpd by default and displays a static and very simple&lt;br&gt;
&gt;&gt; placeholder page on 192.168.1.1.&lt;br&gt;
&gt;&lt;br&gt;
&gt; That's great news. A complex web app is just a giant PITA and huge \
attack&lt;br&gt; &gt; surface anyhow.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Yeah, that's true.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;
&gt;&gt; If we want to use the DreamPlug for the Torouter, we will have to&lt;br&gt;
&gt;&gt; write a web interface for easy configuration of Tor. The interface&lt;br&gt;
&gt;&gt; should probably also provide options to better secure the DreamPlug.&lt;br&gt;
&gt;&gt; Downloading and installing Tor isn't a problem, but the \
configuration&lt;br&gt; &gt;&gt; side of things can be tricky for users who aren't used \
to the command&lt;br&gt; &gt;&gt; line.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write&lt;br&gt;
&gt; a basic status of Tor out to a static html file?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Users who aren't familiar with the command line will probably still&lt;br&gt;
have a problem configuring Tor. I think that a webui package in&lt;br&gt;
Debian/Ubuntu is the best way to go.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Why would they have to \
configure anything on our router? They just need to open a port or let it happen \
automatically, right?&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div \
class="im"&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; Thoughts? Comments?&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; The Freedombox will likely run on the dream plug, it's the reference&lt;br&gt;
&gt; platform. I think we should work on ensuring that if we ship a dream plug,&lt;br&gt;
&gt; we ship a freedombox pre-configured to run Tor - this will likely be the&lt;br&gt;
&gt; case with the FB anyway:&lt;br&gt;
&gt; &lt;a href="http://wiki.debian.org/FreedomBox" \
target="_blank"&gt;http://wiki.debian.org/FreedomBox&lt;/a&gt;&lt;br&gt; &gt; Basically Tor needs \
some kind of webui package in Debian and we'd be good to&lt;br&gt; &gt; go.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Yep, sounds good.&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;
--&lt;br&gt;
Runa A. Sandvik&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110530000114</emailId><senderName>intrigeri</senderName><senderEmail>intrigeri@boum.org</senderEmail><timestampReceived>2011-05-30 00:01:14-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

Hi,

Runa A. Sandvik wrote (29 May 2011 23:35:24 GMT) :
&gt;&gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper
&gt;&gt; and write a basic status of Tor out to a static html file?

&gt; Users who aren't familiar with the command line will probably still
&gt; have a problem configuring Tor. I think that a webui package in
&gt; Debian/Ubuntu is the best way to go.

Here are my 2cts of the day.

/etc/tor/torrc is currently shipped as a conffile by the Tor Debian
package. This means it's a bit hard to edit it programmatically while
ensuring painful and robust upgrade paths.

If the configuration bits that are relevant to Torouter were managed
using debconf (and possibly ucf), not only the webui's job would be a
bit easier to do, but other Debian derivatives (such as the FreedomBox
and Tails) could ship their customizations to the default
configuration as a preseeding file rather than as a full-blown torrc
forked from the default one.

Using Config::Model (Debian package: libconfig-model-perl) would
probably be even better on the long run, but the initial investment of
writing a model might be too much for the Torouter project.

What are the settings the Torouter user would want to customize?

Bye,
--
  intrigeri &lt;intrigeri@boum.org&gt;
  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
  | Did you exchange a walk on part in the war
  | for a lead role in the cage?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110530035556</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2011-05-30 03:55:56-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Runa,

On Sat, May 28, 2011 at 2:52 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; Hi everyone,
&gt;
&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt; thought that the DreamPlug was going to be very user friendly and a
&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt;
&gt; I got one of these.


&gt; When the SheevaPlug came out a couple of years ago, it shipped with a
&gt; web interface that enabled users to change various network options. I
&gt; thought the DreamPlug would ship with some kind of interface as well
&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt; ships with lighthttpd by default and displays a static and very simple
&gt; placeholder page on 192.168.1.1.
&gt;

If we want to use the DreamPlug for the Torouter, we will have to
&gt; write a web interface for easy configuration of Tor. The interface
&gt; should probably also provide options to better secure the DreamPlug.
&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt; side of things can be tricky for users who aren't used to the command
&gt; line.


You don't HAVE to have a web interface, but it sure does make it nice.
However, SSH is really the only secure way to ensure you don't have some XSS
or CSRF attack from your browser (cause that can be really bad when your
browser takes over Tor... ;)


&gt; Thoughts? Comments?
&gt;
&gt; I got lots of experience with these types of devices.  The DreamPlug  is
using an ARM processor, much like the Yoggie Open Firewalls did.  Maybe you
heard of JanusPA(.com)...basically it was a Tor / OpenVPN Router that you
could put inline on your ethernet connection, required zero config to make
it work out of the box, and worked with any IPv4 device.

I have a build environment for the ARM architecture already, and I have a
SheevaPlug and a DreamPlug , but I haven't put Tor on it yet due to being
way overloaded with my day/night job.

If you want, I could probably get all the development stuff tarball'd up and
posted somewhere with basic instructions.  Or I could probably just take 2
hours, do a build, and stuff it into the DreamPlug , then make a tarball of
that.

As for the "Freedombox", it sounds like a over-glorified JanusPA or
DreamPlug or Gumstix.  Getting Tor running on these things isn't difficult,
and to have it automatically use Tor on boot and route all your traffic over
Tor isn't that difficult either.  It's setting up the build environment and
testing that takes the most time.

Give me a few days, maybe a week, and I'll dust off some old drives and see
what I can dig up for you.  I could probably save you a lot of time in
Development, but your on your own to tackle the learning curve.

Best Regards,

Kyle

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;Hi Runa,&lt;/div&gt;&lt;div class="gmail_quote"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
class="gmail_quote"&gt;On Sat, May 28, 2011 at 2:52 PM, Runa A. Sandvik &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt;Hi everyone,&lt;br&gt; &lt;br&gt;
DreamPlug is a new plug computer from GlobalScale Technologies:&lt;br&gt;
&lt;a href="http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx" \
target="_blank"&gt;http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx&lt;/a&gt;. The \
spec&lt;br&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. \
I&lt;br&gt; thought that the DreamPlug was going to be very user friendly and a&lt;br&gt;
potential candidate for the Torouter project. (Maybe) I was wrong.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;I got one of these.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; When the SheevaPlug came out a couple of years ago, it \
shipped with a&lt;br&gt; web interface that enabled users to change various network \
options. I&lt;br&gt; thought the DreamPlug would ship with some kind of interface as \
well&lt;br&gt; (and my plan was to just plug in a Tor page). This is not the case; it&lt;br&gt;
ships with lighthttpd by default and displays a static and very simple&lt;br&gt;
placeholder page on 192.168.1.1.&lt;br&gt; &lt;/blockquote&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; If we want to \
use the DreamPlug for the Torouter, we will have to&lt;br&gt; write a web interface for \
easy configuration of Tor. The interface&lt;br&gt; should probably also provide options to \
better secure the DreamPlug.&lt;br&gt; Downloading and installing Tor isn't a problem, \
but the configuration&lt;br&gt; side of things can be tricky for users who aren't used \
to the command&lt;br&gt; line.&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You don't HAVE to have a \
web interface, but it sure does make it nice. However, SSH is really the only secure \
way to ensure you don't have some XSS or CSRF attack from your browser (cause \
that can be really bad when your browser takes over Tor... ;)  &lt;/div&gt; &lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; Thoughts? Comments?&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;span class="Apple-style-span"&gt;I got lots of experience with \
these types of devices.  The &lt;/span&gt;DreamPlug &lt;span class="Apple-style-span"&gt; is \
using an ARM processor, much like the Yoggie Open Firewalls did.  Maybe you heard of \
JanusPA(.com)...basically it was a Tor / OpenVPN Router that you could put inline on \
your ethernet connection, required zero config to make it work out of the box, and \
worked with any IPv4 device.&lt;/span&gt;&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
class="Apple-style-span"&gt;I have a build environment for the ARM architecture already, \
and I have a SheevaPlug and a &lt;/span&gt;DreamPlug &lt;span class="Apple-style-span"&gt;, but I \
haven't put Tor on it yet due to being way overloaded with my day/night \
job.&lt;/span&gt;&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span class="Apple-style-span"&gt;If you want, I \
could probably get all the development stuff tarball'd up and posted somewhere \
with basic instructions.  Or I could probably just take 2 hours, do a build, and \
stuff it into the &lt;/span&gt;DreamPlug &lt;span class="Apple-style-span"&gt;, then make a \
tarball of that.&lt;/span&gt;&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span class="Apple-style-span"&gt;As \
for the "Freedombox", it sounds like a over-glorified JanusPA or \
&lt;/span&gt;DreamPlug &lt;span class="Apple-style-span"&gt;or Gumstix.  Getting Tor running on \
these things isn't difficult, and to have it automatically use Tor on boot and \
route all your traffic over Tor isn't that difficult either.  It's setting up \
the build environment and testing that takes the most time.&lt;/span&gt;&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Give me a few days, maybe a week, and I'll dust off some old \
drives and see what I can dig up for you.  I could probably save you a lot of time in \
Development, but your on your own to tackle the learning curve.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Best Regards,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Kyle&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110530113716</emailId><senderName></senderName><senderEmail>bertagaz</senderEmail><timestampReceived>2011-05-30 11:37:16-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 02:01:14AM +0200, intrigeri wrote:
&gt; Hi,
&gt; 
&gt; If the configuration bits that are relevant to Torouter were managed
&gt; using debconf (and possibly ucf), not only the webui's job would be a
&gt; bit easier to do, but other Debian derivatives (such as the FreedomBox
&gt; and Tails) could ship their customizations to the default
&gt; configuration as a preseeding file rather than as a full-blown torrc
&gt; forked from the default one.
&gt; 
&gt; Using Config::Model (Debian package: libconfig-model-perl) would
&gt; probably be even better on the long run, but the initial investment of
&gt; writing a model might be too much for the Torouter project.

Actually I've done some work on this area, but the feedback from my mail
on (at that time) ot-talk [1] being not so positive, I've stalled a bit on
this task.

It's a big one as there isn't a policy on the configuration file format
that guides it and assure some consistency for the torrc file you can rely
on to write the rules. Plus, comments are not very well handled by
config-model, which I'm not sure will help in having debconf reacting
smoothly if the comments were stripped off the torrc file by config-model.
This is an area were I needed some more researches, but if one of you have
some hints on this, I'd be glad to hear. :)

The last thread and ticket about the excito plug did raise again this
topic in my mind though, but haven't found some spare time to go on with
it.

bert.

[1] https://lists.torproject.org/pipermail/tor-talk/2011-March/thread.html#19761
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110530122910</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-30 12:29:10-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 12:45 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On Mon, May 30, 2011 at 1:35 AM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; On Mon, May 30, 2011 at 12:21 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt;&gt; wrote:
&gt;&gt; &gt; On Sat, May 28, 2011 at 11:52 PM, Runa A. Sandvik
&gt;&gt; &gt; &lt;runa.sandvik@gmail.com&gt;
&gt;&gt; &gt; wrote:
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Hi everyone,
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt;&gt; &gt;&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt;&gt; &gt;&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt;&gt; &gt;&gt; thought that the DreamPlug was going to be very user friendly and a
&gt;&gt; &gt;&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; When the SheevaPlug came out a couple of years ago, it shipped with a
&gt;&gt; &gt;&gt; web interface that enabled users to change various network options. I
&gt;&gt; &gt;&gt; thought the DreamPlug would ship with some kind of interface as well
&gt;&gt; &gt;&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt;&gt; &gt;&gt; ships with lighthttpd by default and displays a static and very simple
&gt;&gt; &gt;&gt; placeholder page on 192.168.1.1.
&gt;&gt; &gt;
&gt;&gt; &gt; That's great news. A complex web app is just a giant PITA and huge
&gt;&gt; &gt; attack
&gt;&gt; &gt; surface anyhow.
&gt;&gt;
&gt;&gt; Yeah, that's true.
&gt;&gt;
&gt;&gt; &gt;&gt; If we want to use the DreamPlug for the Torouter, we will have to
&gt;&gt; &gt;&gt; write a web interface for easy configuration of Tor. The interface
&gt;&gt; &gt;&gt; should probably also provide options to better secure the DreamPlug.
&gt;&gt; &gt;&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt;&gt; &gt;&gt; side of things can be tricky for users who aren't used to the command
&gt;&gt; &gt;&gt; line.
&gt;&gt; &gt;
&gt;&gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and
&gt;&gt; &gt; write
&gt;&gt; &gt; a basic status of Tor out to a static html file?
&gt;&gt;
&gt;&gt; Users who aren't familiar with the command line will probably still
&gt;&gt; have a problem configuring Tor. I think that a webui package in
&gt;&gt; Debian/Ubuntu is the best way to go.
&gt;&gt;
&gt;
&gt; Why would they have to configure anything on our router? They just need to
&gt; open a port or let it happen automatically, right?

We should at least give our users the option of running a private /
public bridge, non-exit relay or exit relay, just like on the Excito
B3.

&gt;&gt;
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Thoughts? Comments?
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; The Freedombox will likely run on the dream plug, it's the reference
&gt;&gt; &gt; platform. I think we should work on ensuring that if we ship a dream
&gt;&gt; &gt; plug,
&gt;&gt; &gt; we ship a freedombox pre-configured to run Tor - this will likely be the
&gt;&gt; &gt; case with the FB anyway:
&gt;&gt; &gt; http://wiki.debian.org/FreedomBox
&gt;&gt; &gt; Basically Tor needs some kind of webui package in Debian and we'd be
&gt;&gt; &gt; good to
&gt;&gt; &gt; go.
&gt;&gt;
&gt;&gt; Yep, sounds good.
&gt;&gt;
&gt;&gt; --
&gt;&gt; Runa A. Sandvik
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
&gt;



-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110530124838</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-30 12:48:38-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 1:01 AM, intrigeri &lt;intrigeri@boum.org&gt; wrote:
&gt; Hi,
&gt;
&gt; Runa A. Sandvik wrote (29 May 2011 23:35:24 GMT) :
&gt;&gt;&gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper
&gt;&gt;&gt; and write a basic status of Tor out to a static html file?
&gt;
&gt;&gt; Users who aren't familiar with the command line will probably still
&gt;&gt; have a problem configuring Tor. I think that a webui package in
&gt;&gt; Debian/Ubuntu is the best way to go.
&gt;
&gt; Here are my 2cts of the day.
&gt;
&gt; /etc/tor/torrc is currently shipped as a conffile by the Tor Debian
&gt; package. This means it's a bit hard to edit it programmatically while
&gt; ensuring painful and robust upgrade paths.

You may want to look at
https://trac.torproject.org/projects/tor/ticket/1922 (torrc.d-style
configuration directories).

&gt; What are the settings the Torouter user would want to customize?

I think that users should, at a minimum, be able to choose whether to
run a public/private bridge, non-exit relay or exit relay. This means
that users should be able to set the nickname, contact info, relay
port, directory port and so on. At some point, we may want to add a
client mode as well.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110602100048</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-06-02 10:00:48-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On 05/29/2011 07:21 PM, Jacob Appelbaum wrote:
&gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt; a basic status of Tor out to a static html file?

Why not allow Vidalia running from a LAN-based computer to control it?
The control port could autogenerate from the MAC address.

This is not unlike how you might control an Airport Express or Extreme
device, which does not offer a web UI.



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110602104129</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-02 10:41:29-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 02 Jun 2011 06:00:48 -0400
Nathan Freitas &lt;nathan@freitas.net&gt; wrote:

&gt; On 05/29/2011 07:21 PM, Jacob Appelbaum wrote:
&gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt; &gt; a basic status of Tor out to a static html file?
&gt; 
&gt; Why not allow Vidalia running from a LAN-based computer to control it?
&gt; The control port could autogenerate from the MAC address.

Vidalia is not designed to control or configure a Tor process that it
did not start.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110602112950</emailId><senderName>Tomas Touceda</senderName><senderEmail>chiiph@gentoo.org</senderEmail><timestampReceived>2011-06-02 11:29:50-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/signed)]


On 03:41 Thu 02 Jun     , Robert Ransom wrote:
&gt; On Thu, 02 Jun 2011 06:00:48 -0400
&gt; Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt; 
&gt; &gt; On 05/29/2011 07:21 PM, Jacob Appelbaum wrote:
&gt; &gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt; &gt; &gt; a basic status of Tor out to a static html file?
&gt; &gt; 
&gt; &gt; Why not allow Vidalia running from a LAN-based computer to control it?
&gt; &gt; The control port could autogenerate from the MAC address.
&gt; 
&gt; Vidalia is not designed to control or configure a Tor process that it
&gt; did not start.

Actually, it is. It may not be perfect (yet :) ), but I use it like that
every day. Although I haven't tested it controlling a Tor instance on
another host.

But either way, if the device already has a webui, controlling just Tor
from another app seems not too practical.

-- 
Tomas Touceda
Gentoo Developer - Qt, Scheme, Lisp

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110603145546</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-03 14:55:46-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 2, 2011 at 12:29 PM, Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:
&gt; On 03:41 Thu 02 Jun     , Robert Ransom wrote:
&gt;&gt; On Thu, 02 Jun 2011 06:00:48 -0400
&gt;&gt; Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt;&gt;
&gt;&gt; &gt; On 05/29/2011 07:21 PM, Jacob Appelbaum wrote:
&gt;&gt; &gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt;&gt; &gt; &gt; a basic status of Tor out to a static html file?
&gt;&gt; &gt;
&gt;&gt; &gt; Why not allow Vidalia running from a LAN-based computer to control it?
&gt;&gt; &gt; The control port could autogenerate from the MAC address.
&gt;&gt;
&gt;&gt; Vidalia is not designed to control or configure a Tor process that it
&gt;&gt; did not start.
&gt;
&gt; Actually, it is. It may not be perfect (yet :) ), but I use it like that
&gt; every day. Although I haven't tested it controlling a Tor instance on
&gt; another host.

This sounds interesting. I'll give it a go and see what happens / how
well it works.

&gt; But either way, if the device already has a webui, controlling just Tor
&gt; from another app seems not too practical.

The issue here is that the device does not have a webui. So the
question is if we need to create one, or if there are better /
existing options out there.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110607200848</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-07 20:08:48-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 2, 2011 at 11:41 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On Thu, 02 Jun 2011 06:00:48 -0400
&gt; Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt;
&gt;&gt; On 05/29/2011 07:21 PM, Jacob Appelbaum wrote:
&gt;&gt; &gt; Or perhaps we can just turn Tor on by default, ship tor-fw-helper and write
&gt;&gt; &gt; a basic status of Tor out to a static html file?
&gt;&gt;
&gt;&gt; Why not allow Vidalia running from a LAN-based computer to control it?
&gt;&gt; The control port could autogenerate from the MAC address.
&gt;
&gt; Vidalia is not designed to control or configure a Tor process that it
&gt; did not start.

I have tested this, and it works just fine. The question is; are we
happy with something that works, even if it's being used in a way that
it was not designed for?

If the answer is yes; We can ship plugs with Tor installed and
configured (bridge by default, perhaps), and users can connect to the
Tor process using Vidalia on their home computer. Users will then be
able to configure Tor as a bridge, non-exit relay and exit relay, and
we don't have to spend lots of time creating a web interface.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609194725</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-06-09 19:47:25-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

On 2011-Jun-09 20:07, Linus Nordberg wrote:
[..]
&gt; I'm already running something[1] that is collecting a feed and storing
&gt; it in an SQL database.  I should tech it i) how to emit torrc Export
&gt; lines and ii) the Tor control protocol ("exit-policy/default").

If you want an IPv6 dump (aka grh.sixxs.net) don't hesitate to yell what
information you would love to see out of it and in what format.
(Better design this all with IPv6 in mind eh ;)

Greets,
 Jeroen

(Who will be finally doing his own BGP daemon in the next month so that
GRH can actually scale again and will also become IPv4 aware and will
retain 'best path' per peer instead of for all).
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609204033</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-06-09 20:40:33-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

Some thoughts from a quasi network operator...

Perhaps a tracking reason not to do this...

Normally exit traffic is free to travel the globe across jurisdictions
on its way to its final destination (ie: webserver). Doing this
forces that traffic to sink at the exit jurisdiction... removing
that part of its independence.

As to why it could be of help...

Restricting exit policy to only the networks announced via BGP by
the operator (primarily destinations within their own AS's) could
save some bandwidth (transit) costs. Mostly because you wouldn't
be shuffling bits into your AS and straight back out across the
border (cost point) again to a third party. You'd be saying to Tor
that traffic destined within your AS is essentially free once it
gets to your border.

As to making it happen...

- For network operators who also run their own nodes

They already have easy ways of generating their CIDR blocks.
Databases, 'sh ip bgp', etc. They can easily pipe that into a script
to generate an exit policy. It would take all of about 15 minutes
to set it all up. Beyond some project publicity that says, 'Hey,
you could maybe save some costs by doing this...' any competent
operator would not need any tools or services to do this.

- For nodes run by third parties

Sure, if the node operator wants to be friendly to their ISP,
particularly as a means of qualifying the existance of their node.

You definitely don't to task the user with BGP stuff. So a web
service that spits out an exit list based on the nodes IP would
suffice. If you're worried about network slush, email them once a
quarter with the new list, etc.

For Tor itself doing some programmatic things... There are plenty
of BGP looking glasses out there. But for the purposes of some
script banging away at them (times the number of nodes doing so),
yes, it is definitely considered proper to set up a dedicated feed.
I don't think the project would have any problem running its own
Quagga, OpenBGPD, etc instance. And then if it asked around, finding
a couple of friendly ISP's to peer with (and to even host the query
interface) for this purpose.

The controller method obviously makes more sense than messing with
config files and restarts. Option: ExitToMyASTracking


&gt; In the future, I imagine that it makes a lot of sense for circuit
&gt; building to be BGP aware.

Yes. I think I posted something about this a while back. Discrimination
based on AS is one of many ways to help ensure the independence of
nodes in the path.

Consider putting these different types of data/metrics into some
form of DHT or database that runs internal to, alongside, or on top
of Tor...
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609213417</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 21:34:17-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

[Attachment #2 (multipart/alternative)]


On Thu, Jun 9, 2011 at 8:40 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:

&gt; Some thoughts from a quasi network operator...
&gt;
&gt; Perhaps a tracking reason not to do this...
&gt;
&gt; Normally exit traffic is free to travel the globe across jurisdictions
&gt; on its way to its final destination (ie: webserver). Doing this
&gt; forces that traffic to sink at the exit jurisdiction... removing
&gt; that part of its independence.
&gt;
&gt;
No, it does not change anything except adding more exiting bandwidth to the
network. People who otherwise would run a middle node are willing to endure
Tor connections *to their own netblocks* from their own Tor nodes. That will
only improve things and it does not aide in tracking and Tor will still use
three hop circuits...


&gt; As to why it could be of help...
&gt;
&gt; Restricting exit policy to only the networks announced via BGP by
&gt; the operator (primarily destinations within their own AS's) could
&gt; save some bandwidth (transit) costs. Mostly because you wouldn't
&gt; be shuffling bits into your AS and straight back out across the
&gt; border (cost point) again to a third party. You'd be saying to Tor
&gt; that traffic destined within your AS is essentially free once it
&gt; gets to your border.
&gt;

It will probably also reduce concerns about abuse.


&gt;
&gt; As to making it happen...
&gt;
&gt; - For network operators who also run their own nodes
&gt;
&gt; They already have easy ways of generating their CIDR blocks.
&gt; Databases, 'sh ip bgp', etc. They can easily pipe that into a script
&gt; to generate an exit policy. It would take all of about 15 minutes
&gt; to set it all up. Beyond some project publicity that says, 'Hey,
&gt; you could maybe save some costs by doing this...' any competent
&gt; operator would not need any tools or services to do this.
&gt;
&gt;
Sure or we can make a supported method of doing this and help the operators
who are competent but wouldn't mind a little integration.


&gt; - For nodes run by third parties
&gt;
&gt; Sure, if the node operator wants to be friendly to their ISP,
&gt; particularly as a means of qualifying the existance of their node.
&gt;
&gt; You definitely don't to task the user with BGP stuff. So a web
&gt; service that spits out an exit list based on the nodes IP would
&gt; suffice. If you're worried about network slush, email them once a
&gt; quarter with the new list, etc.
&gt;
&gt;
If it's like BulkExitList.py, anyone who wants a list of network blocks can
download it. It would probably only be useful for Tor node operators who
don't have a BGP feed. This may also be useful for say, a node operator who
is willing to talk to his own ISP (and knows their ASN).


&gt; For Tor itself doing some programmatic things... There are plenty
&gt; of BGP looking glasses out there. But for the purposes of some
&gt; script banging away at them (times the number of nodes doing so),
&gt; yes, it is definitely considered proper to set up a dedicated feed.
&gt; I don't think the project would have any problem running its own
&gt; Quagga, OpenBGPD, etc instance. And then if it asked around, finding
&gt; a couple of friendly ISP's to peer with (and to even host the query
&gt; interface) for this purpose.
&gt;
&gt;
I think the NORDUnet people are interested in doing this; I suspect they're
the biggest ISP we'll find and one of their hackers works on Tor quite a
bit, he even runs a Directory Authority....


&gt; The controller method obviously makes more sense than messing with
&gt; config files and restarts. Option: ExitToMyASTracking
&gt;
&gt;
Well, I was thinking:
ASExitingAllowed asn asn asn asn

We'd probably want something that also takes port numbers and all the other
stuff we have in exit policies.


&gt; &gt; In the future, I imagine that it makes a lot of sense for circuit
&gt; &gt; building to be BGP aware.
&gt;
&gt; Yes. I think I posted something about this a while back. Discrimination
&gt; based on AS is one of many ways to help ensure the independence of
&gt; nodes in the path.
&gt;
&gt;
Yes but sadly, without some kind of verification, I'm not sure that BGP is
really up to the task either.


&gt; Consider putting these different types of data/metrics into some
&gt; form of DHT or database that runs internal to, alongside, or on top
&gt; of Tor...


We need a proposal for a circuit selection process that is BGP aware. I
guess we'll need it around the time that we want to support IPv6 entirely...

All the best,
Jake

[Attachment #5 (text/html)]

On Thu, Jun 9, 2011 at 8:40 PM, grarpamp &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:grarpamp@gmail.com"&gt;grarpamp@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; Some thoughts from a quasi \
network operator...&lt;br&gt; &lt;br&gt;
Perhaps a tracking reason not to do this...&lt;br&gt;
&lt;br&gt;
Normally exit traffic is free to travel the globe across jurisdictions&lt;br&gt;
on its way to its final destination (ie: webserver). Doing this&lt;br&gt;
forces that traffic to sink at the exit jurisdiction... removing&lt;br&gt;
that part of its independence.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;No, it does not change anything except adding \
more exiting bandwidth to the network. People who otherwise would run a middle node \
are willing to endure Tor connections *to their own netblocks* from their own Tor \
nodes. That will only improve things and it does not aide in tracking and Tor will \
still use three hop circuits...&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; As to why it \
could be of help...&lt;br&gt; &lt;br&gt;
Restricting exit policy to only the networks announced via BGP by&lt;br&gt;
the operator (primarily destinations within their own AS's) could&lt;br&gt;
save some bandwidth (transit) costs. Mostly because you wouldn't&lt;br&gt;
be shuffling bits into your AS and straight back out across the&lt;br&gt;
border (cost point) again to a third party. You'd be saying to Tor&lt;br&gt;
that traffic destined within your AS is essentially free once it&lt;br&gt;
gets to your border.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It will probably also reduce \
concerns about abuse.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

&lt;br&gt;
As to making it happen...&lt;br&gt;
&lt;br&gt;
- For network operators who also run their own nodes&lt;br&gt;
&lt;br&gt;
They already have easy ways of generating their CIDR blocks.&lt;br&gt;
Databases, 'sh ip bgp', etc. They can easily pipe that into a script&lt;br&gt;
to generate an exit policy. It would take all of about 15 minutes&lt;br&gt;
to set it all up. Beyond some project publicity that says, 'Hey,&lt;br&gt;
you could maybe save some costs by doing this...' any competent&lt;br&gt;
operator would not need any tools or services to do this.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sure or we can make a supported method of doing \
this and help the operators who are competent but wouldn't mind a little \
integration.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

- For nodes run by third parties&lt;br&gt;
&lt;br&gt;
Sure, if the node operator wants to be friendly to their ISP,&lt;br&gt;
particularly as a means of qualifying the existance of their node.&lt;br&gt;
&lt;br&gt;
You definitely don't to task the user with BGP stuff. So a web&lt;br&gt;
service that spits out an exit list based on the nodes IP would&lt;br&gt;
suffice. If you're worried about network slush, email them once a&lt;br&gt;
quarter with the new list, etc.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If it's like BulkExitList.py, anyone who \
wants a list of network blocks can download it. It would probably only be useful for \
Tor node operators who don't have a BGP feed. This may also be useful for say, a \
node operator who is willing to talk to his own ISP (and knows their ASN).&lt;/div&gt; \
&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; For Tor itself doing some programmatic things... There \
are plenty&lt;br&gt; of BGP looking glasses out there. But for the purposes of some&lt;br&gt;
script banging away at them (times the number of nodes doing so),&lt;br&gt;
yes, it is definitely considered proper to set up a dedicated feed.&lt;br&gt;
I don't think the project would have any problem running its own&lt;br&gt;
Quagga, OpenBGPD, etc instance. And then if it asked around, finding&lt;br&gt;
a couple of friendly ISP's to peer with (and to even host the query&lt;br&gt;
interface) for this purpose.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think the NORDUnet people are interested in \
doing this; I suspect they're the biggest ISP we'll find and one of their \
hackers works on Tor quite a bit, he even runs a Directory Authority....&lt;/div&gt; &lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; The controller method obviously makes more sense than \
messing with&lt;br&gt; config files and restarts. Option: ExitToMyASTracking&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Well, I was \
thinking:&lt;/div&gt;&lt;div&gt;ASExitingAllowed asn asn asn \
asn&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We'd probably want something that also takes port \
numbers and all the other stuff we have in exit policies.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &lt;br&gt;
&gt; In the future, I imagine that it makes a lot of sense for circuit&lt;br&gt;
&lt;/div&gt;&gt; building to be BGP aware.&lt;br&gt;
&lt;br&gt;
Yes. I think I posted something about this a while back. Discrimination&lt;br&gt;
based on AS is one of many ways to help ensure the independence of&lt;br&gt;
nodes in the path.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yes but sadly, without some kind of \
verification, I'm not sure that BGP is really up to the task either.&lt;/div&gt;&lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;

Consider putting these different types of data/metrics into some&lt;br&gt;
form of DHT or database that runs internal to, alongside, or on top&lt;br&gt;
of Tor...&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We need a proposal for a circuit selection \
process that is BGP aware. I guess we'll need it around the time that we want to \
support IPv6 entirely...&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt; All the \
best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609214631</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-06-09 21:46:31-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

On 2011-Jun-09 23:34, Jacob Appelbaum wrote:
&gt;     For Tor itself doing some programmatic things... There are plenty
&gt;     of BGP looking glasses out there. But for the purposes of some
&gt;     script banging away at them (times the number of nodes doing so),
&gt;     yes, it is definitely considered proper to set up a dedicated feed.
&gt;     I don't think the project would have any problem running its own
&gt;     Quagga, OpenBGPD, etc instance. And then if it asked around, finding
&gt;     a couple of friendly ISP's to peer with (and to even host the query
&gt;     interface) for this purpose.
&gt; 
&gt; 
&gt; I think the NORDUnet people are interested in doing this; I suspect
&gt; they're the biggest ISP we'll find and one of their hackers works on Tor
&gt; quite a bit, he even runs a Directory Authority....

We could create a hidden service that provides this feature then people
who query stay anonymous too.

I don't see any harm or difficulty in setting that up for a GRH
interface if one would want that. If one can define the values that need
to come out, then that can be setup quickly.

Greets,
 Jeroen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609222339</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-09 22:23:39-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 9 Jun 2011 21:34:17 +0000
Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:

&gt; On Thu, Jun 9, 2011 at 8:40 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:
&gt; 
&gt; &gt; Some thoughts from a quasi network operator...
&gt; &gt;
&gt; &gt; Perhaps a tracking reason not to do this...
&gt; &gt;
&gt; &gt; Normally exit traffic is free to travel the globe across jurisdictions
&gt; &gt; on its way to its final destination (ie: webserver). Doing this
&gt; &gt; forces that traffic to sink at the exit jurisdiction... removing
&gt; &gt; that part of its independence.
&gt; &gt;
&gt; &gt;
&gt; No, it does not change anything except adding more exiting bandwidth to the
&gt; network. People who otherwise would run a middle node are willing to endure
&gt; Tor connections *to their own netblocks* from their own Tor nodes. That will
&gt; only improve things and it does not aide in tracking and Tor will still use
&gt; three hop circuits...

No.

Three hops are enough for normal Tor circuits because in a three-hop
circuit, although the second hop knows some information about the
client (one of its guard nodes) and the third hop knows the
destination, no single hop has useful information about both.  When a
client's choice of exit node leaks useful information about its
intended destination, as it does when using an exit enclave' and would
when using an exit node that exits to a small number of destinations.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609223514</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 22:35:14-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

[Attachment #2 (multipart/alternative)]


On Thu, Jun 9, 2011 at 10:23 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt;wrot=
e:

&gt; On Thu, 9 Jun 2011 21:34:17 +0000
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt; &gt; On Thu, Jun 9, 2011 at 8:40 PM, grarpamp &lt;grarpamp@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; Some thoughts from a quasi network operator...
&gt; &gt; &gt;
&gt; &gt; &gt; Perhaps a tracking reason not to do this...
&gt; &gt; &gt;
&gt; &gt; &gt; Normally exit traffic is free to travel the globe across jurisdiction=
s
&gt; &gt; &gt; on its way to its final destination (ie: webserver). Doing this
&gt; &gt; &gt; forces that traffic to sink at the exit jurisdiction... removing
&gt; &gt; &gt; that part of its independence.
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; No, it does not change anything except adding more exiting bandwidth to
&gt; the
&gt; &gt; network. People who otherwise would run a middle node are willing to
&gt; endure
&gt; &gt; Tor connections *to their own netblocks* from their own Tor nodes. That
&gt; will
&gt; &gt; only improve things and it does not aide in tracking and Tor will still
&gt; use
&gt; &gt; three hop circuits...
&gt;
&gt; No.
&gt;
&gt; Three hops are enough for normal Tor circuits because in a three-hop
&gt; circuit, although the second hop knows some information about the
&gt; client (one of its guard nodes) and the third hop knows the
&gt; destination, no single hop has useful information about both.  When a
&gt; client's choice of exit node leaks useful information about its
&gt; intended destination, as it does when using an =91exit enclave=92 and wou=
ld
&gt; when using an exit node that exits to a small number of destinations.
&gt;
&gt;
Sure but this in no way changes the picture. It's not like exit enclaving a=
t
all, except that it encourages nodes that would otherwise reject *:* to
accept some exiting traffic. There would be no change to the way that the
Tor client builds the circuit; this is just a way to encourage network
operators (who want to play nice) to run more than a middle node without a
lot of overhead. Or do I misunderstand?

All the best,
Jake

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;On Thu, Jun 9, 2011 at 10:23 PM, Robert Ransom &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:rransom.8774@gmail.com"&gt;rransom.8774@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Thu, 9 Jun 2011 21:34:17 +0000&lt;br&gt;
Jacob Appelbaum &lt;&lt;a href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt; &lt;br&gt;
&gt; On Thu, Jun 9, 2011 at 8:40 PM, grarpamp &lt;&lt;a \
href="mailto:grarpamp@gmail.com"&gt;grarpamp@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt;&lt;br&gt;
&gt; &gt; Some thoughts from a quasi network operator...&lt;br&gt;
&gt; &gt;&lt;br&gt;
&gt; &gt; Perhaps a tracking reason not to do this...&lt;br&gt;
&gt; &gt;&lt;br&gt;
&gt; &gt; Normally exit traffic is free to travel the globe across jurisdictions&lt;br&gt;
&gt; &gt; on its way to its final destination (ie: webserver). Doing this&lt;br&gt;
&gt; &gt; forces that traffic to sink at the exit jurisdiction... removing&lt;br&gt;
&gt; &gt; that part of its independence.&lt;br&gt;
&gt; &gt;&lt;br&gt;
&gt; &gt;&lt;br&gt;
&gt; No, it does not change anything except adding more exiting bandwidth to the&lt;br&gt;
&gt; network. People who otherwise would run a middle node are willing to endure&lt;br&gt;
&gt; Tor connections *to their own netblocks* from their own Tor nodes. That will&lt;br&gt;
&gt; only improve things and it does not aide in tracking and Tor will still use&lt;br&gt;
&gt; three hop circuits...&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;No.&lt;br&gt;
&lt;br&gt;
Three hops are enough for normal Tor circuits because in a three-hop&lt;br&gt;
circuit, although the second hop knows some information about the&lt;br&gt;
client (one of its guard nodes) and the third hop knows the&lt;br&gt;
destination, no single hop has useful information about both.  When a&lt;br&gt;
client's choice of exit node leaks useful information about its&lt;br&gt;
intended destination, as it does when using an exit enclave and would&lt;br&gt;
when using an exit node that exits to a small number of destinations.&lt;br&gt;&lt;font \
class="Apple-style-span" \
color="#888888"&gt;&lt;br&gt;&lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sure but this in no way \
changes the picture. It's not like exit enclaving at all, except that it \
encourages nodes that would otherwise reject *:* to accept some exiting traffic. \
There would be no change to the way that the Tor client builds the circuit; this is \
just a way to encourage network operators (who want to play nice) to run more than a \
middle node without a lot of overhead. Or do I misunderstand?&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake &lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110610083333</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-06-10 08:33:33-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

&gt; this is just a way to encourage network operators
&gt;(who want to play nice) to run more than a middle node without a
&gt; lot of overhead. Or do I misunderstand?

You're fine. I was only speaking of the internet path between the
exit and regular internet services. Such as what happens if a Tier-1/2
props up some fast nodes and might be able to vacuum up Tor traffic
destined to itself. How that would affect the current presumption of reasonably
randomized exit sources of traffic to that AS. Mostly from an abuse jurisdiction
standpoint as it's harder to complain about (or apply policy to) roving exits
halfway around the globe than it is one on your front door. Yet since anyone
can prop up such a server today, it's moot I guess. That leaves just the Tor
traffic skewing to consider. Also similarly mooted.

(My understanding of an adversary being able to effectively force traffic
to a destination through their exit... is weak. But if so, that's the skewing
part of this.)


Would this also mean that ISP's (or users) who deploy such a node
would be more likely to block all other nodes such that all they need
to manage/filter/etc, good or bad, is their own 'peering' node?
Whether such nodes reside in/out of their AS, or use 0.0.0.0/0 exit
or AS only exit.

Is all.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110627185703</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-06-27 18:57:03-0400</timestampReceived><subject>Re: [tor-dev] WIN32_WINNT in or/or.h</subject><body>

On Mon, Jun 20, 2011 at 6:32 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt;juswrote:
&gt; I think that the values for 'WIN32_WINNT' and '_WIN32_WINNT'
&gt; should be protected against redefinement.
&gt; Reason: In order for MingW to prototype getaddrinfo() and freeaddrinfo()
&gt; correctly (in &lt;ws2tcpip.h&gt;), '_WIN32_WINNT' *must* be defined as 0x0501
&gt; or higher. or/or.h blindly defines them as 0x0400. So, building with
&gt; -DHAVE_GETADDRINFO needs _WIN32_WINNT to be set to 0x0501.

I'm confused about the situation here.  Does "-DHAVE_GETADDRINFO" mean
that you're overriding the value in orconfig.h from the command line,
and presumably setting your own _WIN32_WINNT value there too?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609162923</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-06-09 16:29:23-0400</timestampReceived><subject>Re: [tor-dev] Reg : using the keep alive messages</subject><body>

On Wed, Jun 08, 2011 at 08:11:58PM -0400, Sambuddho Chakravarty wrote:
&gt; Hi All
&gt; I read in the Tor design spec that Tor control protocol supports keepalive
&gt; messages which could be used for link padding . I wonder if anyone has ever
&gt; explored using them...

I don't think you mean the Tor control protocol. There's no need to pad
that connection (or if there is, you've screwed up badly somewhere else).

The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:

   PADDING cells are currently used to implement connection keepalive.
   If there is no other traffic, ORs and OPs send one another a PADDING
   cell every few minutes.

There's also a DROP relay cell. While PADDING cells can only be sent to
the adjacent relay, the client can send DROP cells to any relay on her
circuit, and any relay on the circuit can inject DROP cells to the client.
See also sec 7.2 of tor-spec.

But that said, I think the answer to your question is no. AFAIK nobody
has understood passive correlation attacks well enough to get to the
"if I change the design like this, does the attack work less well"
research stage.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609190332</emailId><senderName>Sambuddho Chakravarty</senderName><senderEmail>sc2516@columbia.edu</senderEmail><timestampReceived>2011-06-09 19:03:32-0400</timestampReceived><subject>Re: [tor-dev] Reg : using the keep alive messages</subject><body>

[Attachment #2 (multipart/alternative)]


Dear Roger
 Thanks for your response. I read the spec document about the RELAY_DROP
cells. You say that no one has understood the passive correlation attack to
utilize the RELAY_DROP cells. I am however little curious to see if
"moderate padding" (enough to not mess up QoS of various services) can be
used to prevent some of the attacks that rely on parameters such as OWD ,
RTT and B/W variation to link relays that are being used in a circuit. I am
curious from the practical point of view of exploring such padding to
prevent our bandwidth based confirmation attack or the M&amp;D attack (and its
2009 variant) .

Thanks
Sambuddho

On Thu, Jun 9, 2011 at 12:29 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt; On Wed, Jun 08, 2011 at 08:11:58PM -0400, Sambuddho Chakravarty wrote:
&gt; &gt; Hi All
&gt; &gt; I read in the Tor design spec that Tor control protocol supports
&gt; keepalive
&gt; &gt; messages which could be used for link padding . I wonder if anyone has
&gt; ever
&gt; &gt; explored using them...
&gt;
&gt; I don't think you mean the Tor control protocol. There's no need to pad
&gt; that connection (or if there is, you've screwed up badly somewhere else).
&gt;
&gt; The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:
&gt;
&gt;   PADDING cells are currently used to implement connection keepalive.
&gt;   If there is no other traffic, ORs and OPs send one another a PADDING
&gt;   cell every few minutes.
&gt;
&gt; There's also a DROP relay cell. While PADDING cells can only be sent to
&gt; the adjacent relay, the client can send DROP cells to any relay on her
&gt; circuit, and any relay on the circuit can inject DROP cells to the client.
&gt; See also sec 7.2 of tor-spec.
&gt;
&gt; But that said, I think the answer to your question is no. AFAIK nobody
&gt; has understood passive correlation attacks well enough to get to the
&gt; "if I change the design like this, does the attack work less well"
&gt; research stage.
&gt;
&gt; --Roger
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Dear Roger&lt;div&gt;  Thanks for your response. I read the spec document \
about the RELAY_DROP cells. You say that no one has understood the passive \
correlation attack to utilize the RELAY_DROP cells. I am however little curious to \
see if "moderate padding" (enough to not mess up QoS of various services) \
can be used to prevent some of the attacks that rely on parameters such as OWD , RTT \
and B/W variation to link relays that are being used in a circuit. I am curious from \
the practical point of view of exploring such padding to prevent our bandwidth based \
confirmation attack or the M&amp;D attack (and its 2009 variant) .  &lt;/div&gt;

&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On \
Thu, Jun 9, 2011 at 12:29 PM, Roger Dingledine &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:arma@mit.edu"&gt;arma@mit.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;

&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;On Wed, Jun 08, 2011 at 08:11:58PM -0400, Sambuddho \
Chakravarty wrote:&lt;br&gt; &gt; Hi All&lt;br&gt;
&gt; I read in the Tor design spec that Tor control protocol supports keepalive&lt;br&gt;
&gt; messages which could be used for link padding . I wonder if anyone has ever&lt;br&gt;
&gt; explored using them...&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;I don't think you mean the Tor control protocol. There's no need \
to pad&lt;br&gt; that connection (or if there is, you've screwed up badly somewhere \
else).&lt;br&gt; &lt;br&gt;
The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:&lt;br&gt;
&lt;br&gt;
    PADDING cells are currently used to implement connection keepalive.&lt;br&gt;
    If there is no other traffic, ORs and OPs send one another a PADDING&lt;br&gt;
    cell every few minutes.&lt;br&gt;
&lt;br&gt;
There's also a DROP relay cell. While PADDING cells can only be sent to&lt;br&gt;
the adjacent relay, the client can send DROP cells to any relay on her&lt;br&gt;
circuit, and any relay on the circuit can inject DROP cells to the client.&lt;br&gt;
See also sec 7.2 of tor-spec.&lt;br&gt;
&lt;br&gt;
But that said, I think the answer to your question is no. AFAIK nobody&lt;br&gt;
has understood passive correlation attacks well enough to get to the&lt;br&gt;
"if I change the design like this, does the attack work less well"&lt;br&gt;
research stage.&lt;br&gt;
&lt;br&gt;
--Roger&lt;br&gt;
&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;br&gt; &lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110625003620</emailId><senderName>Sambuddho Chakravarty</senderName><senderEmail>sc2516@columbia.edu</senderEmail><timestampReceived>2011-06-25 00:36:20-0400</timestampReceived><subject>Re: [tor-dev] Reg : using the keep alive messages</subject><body>

[Attachment #2 (multipart/alternative)]


 Which is the relevant part of the that should I look into for injecting
such cells in streams ?

Thanks
Sambuddho


On Thu, Jun 9, 2011 at 3:03 PM, Sambuddho Chakravarty
&lt;sc2516@columbia.edu&gt;wrote:

&gt; Dear Roger
&gt;  Thanks for your response. I read the spec document about the RELAY_DROP
&gt; cells. You say that no one has understood the passive correlation attack to
&gt; utilize the RELAY_DROP cells. I am however little curious to see if
&gt; "moderate padding" (enough to not mess up QoS of various services) can be
&gt; used to prevent some of the attacks that rely on parameters such as OWD ,
&gt; RTT and B/W variation to link relays that are being used in a circuit. I am
&gt; curious from the practical point of view of exploring such padding to
&gt; prevent our bandwidth based confirmation attack or the M&amp;D attack (and its
&gt; 2009 variant) .
&gt;
&gt; Thanks
&gt; Sambuddho
&gt;
&gt;
&gt; On Thu, Jun 9, 2011 at 12:29 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt;
&gt;&gt; On Wed, Jun 08, 2011 at 08:11:58PM -0400, Sambuddho Chakravarty wrote:
&gt;&gt; &gt; Hi All
&gt;&gt; &gt; I read in the Tor design spec that Tor control protocol supports
&gt;&gt; keepalive
&gt;&gt; &gt; messages which could be used for link padding . I wonder if anyone has
&gt;&gt; ever
&gt;&gt; &gt; explored using them...
&gt;&gt;
&gt;&gt; I don't think you mean the Tor control protocol. There's no need to pad
&gt;&gt; that connection (or if there is, you've screwed up badly somewhere else).
&gt;&gt;
&gt;&gt; The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:
&gt;&gt;
&gt;&gt;   PADDING cells are currently used to implement connection keepalive.
&gt;&gt;   If there is no other traffic, ORs and OPs send one another a PADDING
&gt;&gt;   cell every few minutes.
&gt;&gt;
&gt;&gt; There's also a DROP relay cell. While PADDING cells can only be sent to
&gt;&gt; the adjacent relay, the client can send DROP cells to any relay on her
&gt;&gt; circuit, and any relay on the circuit can inject DROP cells to the client.
&gt;&gt; See also sec 7.2 of tor-spec.
&gt;&gt;
&gt;&gt; But that said, I think the answer to your question is no. AFAIK nobody
&gt;&gt; has understood passive correlation attacks well enough to get to the
&gt;&gt; "if I change the design like this, does the attack work less well"
&gt;&gt; research stage.
&gt;&gt;
&gt;&gt; --Roger
&gt;&gt;
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;
&gt;&gt;
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;br&gt;&lt;div&gt;  Which is the relevant part of the that should I look into \
for injecting such cells in streams \
?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;/div&gt;&lt;div&gt;  &lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Thu, Jun 9, 2011 at 3:03 PM, Sambuddho Chakravarty &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:sc2516@columbia.edu"&gt;sc2516@columbia.edu&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div dir="ltr"&gt;Dear Roger&lt;div&gt;  Thanks for your response. I \
read the spec document about the RELAY_DROP cells. You say that no one has understood \
the passive correlation attack to utilize the RELAY_DROP cells. I am however little \
curious to see if "moderate padding" (enough to not mess up QoS of various \
services) can be used to prevent some of the attacks that rely on parameters such as \
OWD , RTT and B/W variation to link relays that are being used in a circuit. I am \
curious from the practical point of view of exploring such padding to prevent our \
bandwidth based confirmation attack or the M&amp;D attack (and its 2009 variant) .  \
&lt;/div&gt;


&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Thu, Jun 9, 2011 at 12:29 PM, Roger \
Dingledine &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:arma@mit.edu" \
target="_blank"&gt;arma@mit.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;On Wed, Jun 08, 2011 at 08:11:58PM \
-0400, Sambuddho Chakravarty wrote:&lt;br&gt; &gt; Hi All&lt;br&gt;
&gt; I read in the Tor design spec that Tor control protocol supports keepalive&lt;br&gt;
&gt; messages which could be used for link padding . I wonder if anyone has ever&lt;br&gt;
&gt; explored using them...&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;I don't think you mean the Tor control protocol. There's no need \
to pad&lt;br&gt; that connection (or if there is, you've screwed up badly somewhere \
else).&lt;br&gt; &lt;br&gt;
The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:&lt;br&gt;
&lt;br&gt;
    PADDING cells are currently used to implement connection keepalive.&lt;br&gt;
    If there is no other traffic, ORs and OPs send one another a PADDING&lt;br&gt;
    cell every few minutes.&lt;br&gt;
&lt;br&gt;
There's also a DROP relay cell. While PADDING cells can only be sent to&lt;br&gt;
the adjacent relay, the client can send DROP cells to any relay on her&lt;br&gt;
circuit, and any relay on the circuit can inject DROP cells to the client.&lt;br&gt;
See also sec 7.2 of tor-spec.&lt;br&gt;
&lt;br&gt;
But that said, I think the answer to your question is no. AFAIK nobody&lt;br&gt;
has understood passive correlation attacks well enough to get to the&lt;br&gt;
"if I change the design like this, does the attack work less well"&lt;br&gt;
research stage.&lt;br&gt;
&lt;br&gt;
--Roger&lt;br&gt;
&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;br&gt; &lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110619165525</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-06-19 16:55:25-0400</timestampReceived><subject>Re: [tor-dev] TOR control protocol timeout</subject><body>

&gt;  Is there a defined timeout for the TOR control protocol?  How long
&gt; should a control port client wait around for socket data when reading?
&gt;  Or writing?  The only references to timeouts that I find in
&gt; control-spec.txt are about circuit and stream timeouts reported back
&gt; through the control port.

I'm not aware of one (though that certainly doesn't mean there isn't
any). What in particular are you trying to solve? -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110619175034</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-19 17:50:34-0400</timestampReceived><subject>Re: [tor-dev] TOR control protocol timeout</subject><body>

On Sun, Jun 19, 2011 at 9:55 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;&gt;  Is there a defined timeout for the TOR control protocol?  How long
&gt;&gt; should a control port client wait around for socket data when reading?
&gt;&gt;  Or writing?  The only references to timeouts that I find in
&gt;&gt; control-spec.txt are about circuit and stream timeouts reported back
&gt;&gt; through the control port.
&gt;
&gt; I'm not aware of one (though that certainly doesn't mean there isn't
&gt; any). What in particular are you trying to solve? -Damian

I've been looking at TorUtil.BufSock.readline() and the problems
atagar has found.  I have found similar problems and I would like to
solve this issue.

The recent merges mikeperry did from you and atagar do not really fix
the problem (as I see it).  atagar's timeout was way too short in my
testing.  And your commits returned the tree to a blocking socket
mode.

I would like to have readline() detect when a socket error has
occurred.  My research indicates that timeouts are the only reliable
method to decide a problem has occurred with a socket.  But, there
seems there is no guidance from the TOR docs about how long a client
should wait for a reply from the TOR daemon.

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110619181840</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-06-19 18:18:40-0400</timestampReceived><subject>Re: [tor-dev] TOR control protocol timeout</subject><body>

&gt; you and atagar...

I am atagar.

&gt; atagar's timeout was way too short in my testing.

I picked 20 ms because that's the runtime for fast queries, like
'GETINFO version'. There was a tradeoff in picking the timeout
duration, but since it was within a loop it didn't impact correctness.
Lowering meant more work (looping rather than sleeping on input) and
higher meant a raised shutdown time.

This said, a later change to shut down the socket unblocked the recv
call when closing, so this timeout was removed.

&gt; I have found similar problems and I would like to solve this issue.

All the concurrency issues for shutting down should have been
addressed. What sort of problems are you encountering? Do you have a
use case for reproducing the issue?

&gt; I would like to have readline() detect when a socket error has
&gt; occurred.

A socket error should result in a None return value that shuts down _thread.

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110620212222</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-06-20 21:22:22-0400</timestampReceived><subject>Re: [tor-dev] Tor AF independence patch - first big step to Tor IPv6</subject><body>

On Wed, Jun 8, 2011 at 8:19 AM, Jeroen Massar &lt;jeroen@unfix.org&gt; wrote:
&gt; Hi,
&gt;
&gt; As this is World IPv6 day, let me present the first big step to Tor
&gt; IPv6: the Address Family independence Patch ;)
&gt;
&gt; https://unfix.org/projects/ipv6/tor/tor-af-independent.diff
&gt;
&gt; it is diff against a recent git checkout and should apply more or less
&gt; cleanly.

Hi!

Do you remember which git checkout it was?  I can't find one that it
applies cleanly to.

 [...]
&gt; Note also that this is not a 'true' AF indepencence patch as in that
&gt; case we would have to swap toraddr_t with a sockaddr_storage structure,
&gt; which, when recompiled, would be true AF independent. In the case though
&gt; that ever a new IP-alike protocol arises and then we still use BSD style
&gt; sockets, this patch should make it easy to use that new address family
&gt; too, but don't hold your breath ;)

Yeah, I wouldn't hold my breath for a shift from sockaddr_storage from
tor_addr_t.  The point of tor_addr_t is to be small; it's about 20
bytes (as opposed to the ~128 bytes used for a sockaddr_storage).  We
allocate a pretty huge number of addresses, and using a needlessly
large type here could waste a few megabytes  on a busy relay.

 [...]
&gt; A question there also becomes, do we want to show a Tor node as separate
&gt; IPv4 and IPv6 routers, or are they to be seen as one, if it is one, we
&gt; require the above ORMultiport, so that we can have multiple IP addresses
&gt; and ports on a single node.

It's one router; it has to be.  After all, it needs to be able

 [...]
&gt; And maybe, it could be useful to have a special branch on torproject's
&gt; git server for this, as it is quite a bit of patch ;)

This should definitely get a git repository someplace.  In the future,
if it's possible, please try to do stuff like this as a series of
patches rather than as one huge patch.  Stuff this big is hard to
merge and hard to review.

Some initial thoughts:

* I think that the code in tor_addr_parse_reverse_lookup_name is
wrong: it should call tor_addr_from_ipv4h, not _ipv4n.  The 'h' means
"host order", and you're constructing the address in host order.

* In tor_addr_from_loopback, I really don't like the type-punning from
array-of-uint32 to array-of-byte.

* The tor_inet_pton and tor_inet_ntop functions were meant to be
platform-independent clones of inet_pton and inet_ntop; now they do
something different.  Not sure that's what we want.

* tor_addr_mask_get_bits looks like it'd be broken for anything but an
IPv4 address.  That's fine -- we don't expect other masks to be used
except for IPv4 -- but it should probably check its input.

* tor_addr_from_null() seems to be used in someplaces where af_unspec
would make more sense than af_inet.

* I think tor_addr_protocol and friends can get the boot unless we
actually find a platform we care about where AF_* is not the same as
PF_*.  As near as I can tell, there are no platforms like that.
Instead of making our address-family-to-protocol-family code generic,
we should just axe it.

* Some of the new code in tor_inet_pton is duplicated from elsewhere,
and has the same bug.  We try to avoid copy-paste code.  (Also, the
reason to compare the sscanf output to 4 is to see if there is an
extra character or no.)

* In some places (I noticed this in
get_configured_bridge_by_addr_port) you've replaced !tor_addr_compare
with !tor_addr_eq.  But that's backwards; compare returns 0 when stuff
is equal and eq returns 1 when it's equal.  There are a bunches of
cases like this.  If this was a patch series instead of a great big
patch, then I could just fix that one patch.  As it is, I don't dare
even think about merging it, because it has this error scattered
throughout.

* Changing resolve_my_addr to return an arbitrary address type will
break lots of stuff; it needs to return only IPv4 addresses until the
rest of the code learns how to handle them.  After all, these are the
addresses we advertise.   Same with last_interface_ip, I think.  In
general, lots of functions that keep track of "my address" or "my last
address" will instead need to keep track of "my addresses" plural.

* I think that removing the "if (last_resolved_addr != *addr_out) {"
in resolve_my_address() is wrong.  Previously, the second block would
get invoked when we changed from "no address" to addr_out.  Now it
only gets called when we change from "some address".  I see later that
we initialize our "last_resolved_addr" to loopback: why?  Can that
really be safe?

* The virtaddress_entry_t change feels weird; I'll need to come back
and revisit that.  The conversion in parse_virtual_addr_network etc
also look half-finisheed: it seems like it can only handle ipv4
addresses.

* All of the connection_ap_handshake_socks_resolved changes seem to
imply that it's trying to handle looking up and connecting to IPv6
addresses already.  Odd!

* Converting generate_v2_networkstatus_opinion(), and other functions
that generate directory objects, seems dangerous to me.  As it stands,
they must never output an IPv6 address in any field where clients
currently only accept IPv4 addresses.  As such, using the generic
functions here seems potentially error-prone.

* Our eventdns.c was forked from Libevent's, which was necessary for a
time, but is not a long-term good idea.  I'd like to avoid changes in
eventdns.c that don't correspond to changes in Libevent's eventdns.c .

* The geoip.c file should IMO just be ignored for now; we don't have a
source of IPv6 geoip information.  If we did, we'd probably want a
more optimal representation than one that made every geoip_entry_t
become 5 times as long.  That's an extra 5MB to store the IPv4 geoip
table with this representation!

* In router_pick_published_address, can it really now pick an IPv6
address?  That would cause trouble with existing clients.  Here too,
we can't treat all AFs as equivalent, since existing clients only
allow IPv4.

* All of the routerparse.c changes need to be tighter: we can't start
allowing IPv6 addresses in places that previously supported IPv4
addresses, since old clients won't accept them.

And that's it for my comments on v1 -- looks like a good beginning!
Do you have time to clean this stuff up soon, or shall I start hacking
on it?  I'd like to get IPv6 support into 0.2.3.x if at all possible.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110620214426</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-06-20 21:44:26-0400</timestampReceived><subject>Re: [tor-dev] Tor AF independence patch - first big step to Tor IPv6</subject><body>

On Mon, Jun 20, 2011 at 5:22 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; On Wed, Jun 8, 2011 at 8:19 AM, Jeroen Massar &lt;jeroen@unfix.org&gt; wrote:
 [...]
&gt;&gt; A question there also becomes, do we want to show a Tor node as separate
&gt;&gt; IPv4 and IPv6 routers, or are they to be seen as one, if it is one, we
&gt;&gt; require the above ORMultiport, so that we can have multiple IP addresses
&gt;&gt; and ports on a single node.
&gt;
&gt; It's one router; it has to be.  After all, it needs to be able

Missing sentence:

After all, every IPv6-enabled router needs to be able to connect to
IPv4 and IPv6 addresses both, or else there will be two completely
separate networks, which would be bad for anonymity.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110615060544</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-06-15 06:05:44-0400</timestampReceived><subject>Re: [tor-dev] Thoughts on simplified packaging</subject><body>

On workload and stuff...

&gt; the idea we had at the 2010 Potsdam meeting where we had primary
&gt; and secondary developers for each product.

There is Tor core (ported to various platforms). This is code and
docs. This is what matters. It is not config or packaging.

Above and beyond that, if there is a demand for it, why not introduce
a secondary level of suitably trusted enthusiasts to develop and
manage all the various modes of operation. Officially disclaim it
appropriately as an unofficial vaporware framework, wikify it, put
a couple public developer packaging boxes online and see what
happens.

Also, you could easily publish just a set of torrc's tailored to
various purposes. Or even create an online config generator with
various feature checkboxes.

Also, a visible and similarly adjunct FAQ and docs team for those
of us who ask silly questions like myself :) And I guess, a searchable
and downloadable email archive. It could save some time of some of
the people who reply to 'Subject: Please help' people.

TBB... Tor Browser Bundle... sure, this is useful. But a pain for
each platform. I would punt it to the secondary team. Then focus
on one, Torify everything, bootable Unix platform.

&gt; 1. If a user wants to run both a tor-client and &gt;
tor-(relay|exit-relay|bridge) on the same host, we run into port

Goes to config generator or posted configs. Plus to some degree you
get config modernization out there in Torland for free.

&gt; 3. The conversion from legacy to new packaging could be a mess.

I've never had a problem being forced to accept breakage of backward
compatibility. Then again, I'm not Joe user. Still, assuming there
is constant new user influx, such breakage won't lead to lost
capacity. That's what major.minor.rev revision numbering is for.

&gt; 5. The *BSD ports system ... for non-exit, exit, and bridge relay.

Really? Users who can deal with ports can certainly deal with a
little Tor config.

&gt; Conclusion

I've no objection to flag days that result in good long term gains.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110615111653</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-15 11:16:53-0400</timestampReceived><subject>Re: [tor-dev] Thoughts on simplified packaging</subject><body>

On Wed, Jun 15, 2011 at 02:05:44AM -0400, grarpamp wrote:
&gt; On workload and stuff...
&gt; 
&gt; &gt; the idea we had at the 2010 Potsdam meeting where we had primary
&gt; &gt; and secondary developers for each product.
&gt; 
&gt; There is Tor core (ported to various platforms). This is code and
&gt; docs. This is what matters. It is not config or packaging.
&gt; 
&gt; Above and beyond that, if there is a demand for it, why not introduce
&gt; a secondary level of suitably trusted enthusiasts to develop and
&gt; manage all the various modes of operation. Officially disclaim it
&gt; appropriately as an unofficial vaporware framework, wikify it, put
&gt; a couple public developer packaging boxes online and see what
&gt; happens.
&gt; 
&gt; Also, you could easily publish just a set of torrc's tailored to
&gt; various purposes. Or even create an online config generator with
&gt; various feature checkboxes.

I don't think most of the target audience knows (or wants to know) what
a torrc is.  They want one-click download, install, and run.  And that's
what we should give them.

&gt; I've no objection to flag days that result in good long term gains.

Well, Flag Day was yesterday, so you've got a whole year to figure out
the plan for next time.  ;-)

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611192803</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-06-11 19:28:03-0400</timestampReceived><subject>Re: [tor-dev] Python TorCtl development questions</subject><body>

&gt;  I have begun using the Python TorCtl package to develop a gui TOR
&gt; controller.

Great! What are your planned use cases for this gui? Kamran is also
beginning work on a gtk gui for arm (http://www.atagar.com/arm/ - a
python project that uses torctl) so that might be of interest too.
We'd certainly be glad to have the help.

Btw, there's also a wrapper library:
https://gitweb.torproject.org/arm.git/blob/HEAD:/src/util/torTools.py

which provides caching improvements, pid fetching, reattachability,
and an expanded api on top of torctl. At some point I should turn this
into a standalone library but its never been a high enough priority...

&gt; In this examination, I have begun adding
&gt; comments, renaming vars to be more explicit, etc.  How open are the
&gt; developers to these changes?

Changes need to support backward comparability but besides that it's
all good (commenting and var renaming of course are safe). It will be
up to Mike to decide if the changes are accepted or not.

&gt;  Will the devs accept patches to remove unused code.  I'm looking at
&gt; you, TorCtl.TorUtil.Enum.

I'm not sure, up to Mike.

&gt;  Is there interest in making TorCtl into a more mainstream form of
&gt; Python package?

TorCtl already has been packaged for Debian (the python-torctl
package) so a big advantage of a distutils installer have already been
covered. I'm not sure if there's interest in an rpm or distutils for
standalone installation.

&gt;  How far back in Python versions are we trying to maintain
&gt; compatibility?

Definitely back to 2.4, I'm not sure how much further than that.

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110612151043</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-12 15:10:43-0400</timestampReceived><subject>Re: [tor-dev] Python TorCtl development questions</subject><body>

On Sat, Jun 11, 2011 at 12:28 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;&gt;  I have begun using the Python TorCtl package to develop a gui TOR
&gt;&gt; controller.
&gt;
&gt; Great! What are your planned use cases for this gui? Kamran is also
&gt; beginning work on a gtk gui for arm (http://www.atagar.com/arm/ - a
&gt; python project that uses torctl) so that might be of interest too.
&gt; We'd certainly be glad to have the help.

  The one feature I really, really miss from Tork is the Tor Console
&lt;http://sourceforge.net/dbimage.php?id=95124&gt;. So, Syboa replicates
that screen.  I still have not decided whether I will try to release
this software.  But, I can still provide developer feedback for
TorCtl.

&gt;&gt; In this examination, I have begun adding
&gt;&gt; comments, renaming vars to be more explicit, etc.  How open are the
&gt;&gt; developers to these changes?
&gt;
&gt; Changes need to support backward comparability but besides that it's

  I completely agree.  One of my first steps is to write unit tests
for those parts I am tweaking so that I can verify behavior before and
after changes.  I, also, would like to submit these unit tests to the
TorCtl package.

&gt;&gt;  Is there interest in making TorCtl into a more mainstream form of
&gt;&gt; Python package?
&gt;
&gt; TorCtl already has been packaged for Debian (the python-torctl
&gt; package) so a big advantage of a distutils installer have already been
&gt; covered. I'm not sure if there's interest in an rpm or distutils for
&gt; standalone installation.

  I would encourage a distutils-compatible form.  Since the Debian
package seems to move the TorCtl modules into a distutils package
form, it should make things easier for the Debian packager and other
potential OS/distribution packagers.  Also, this would enable
developers on any platform to install just the TorCtl Python package
with minimal work.  Currently, (as far as I can see) the only way for
a non-Debian-based developer to get TorCtl is through git clone.

&gt;&gt;  How far back in Python versions are we trying to maintain
&gt;&gt; compatibility?
&gt;
&gt; Definitely back to 2.4, I'm not sure how much further than that.

  I would agree that Py2.4 is a good threshold.  I was afraid someone
was going to want Py1.x compatibility.


-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110611172153</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-06-11 17:21:53-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 06/11/2011 06:59 PM, tagnaq wrote:
&gt;&gt; Hmm.  I wonder what happens if the packets are fragmented so that the
&gt;&gt; TCP port information isn't in the first fragment...

An IP packet must be very small to fulfil this scenario (first IP
fragment is so small that it is not able enclose the entire TCP header).
IP hosts are required to be able to handle at least 576 bytes.
-----BEGIN PGP SIGNATURE-----

iF4EAREKAAYFAk3zpDEACgkQyM26BSNOM7brYgD/dUu7sTsZ26ODAUFW0PzdYUgX
h0I4P2uzEWdcNaTF7YAA/RmHV/eUckPykTLGtdMppiy+05CAI6m9d/KHCYwAMJaO
=KEOD
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611175845</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-11 17:58:45-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>

On Sat, Jun 11, 2011 at 07:21:53PM +0200, tagnaq wrote:
&gt; On 06/11/2011 06:59 PM, tagnaq wrote:
&gt; &gt;&gt; Hmm.  I wonder what happens if the packets are fragmented so that the
&gt; &gt;&gt; TCP port information isn't in the first fragment...
&gt; 
&gt; An IP packet must be very small to fulfil this scenario (first IP
&gt; fragment is so small that it is not able enclose the entire TCP header).
&gt; IP hosts are required to be able to handle at least 576 bytes.

Yes, but the client (say, inside China) is perfectly capable of
artificially fragmenting its SYN packet.  It shouldn't be too hard to
check what actually happens in this case?  (At least, for the current
GFW configuration.)

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611190737</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-06-11 19:07:37-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 06/11/2011 07:58 PM, Ian Goldberg wrote:
&gt; Yes, but the client (say, inside China) is perfectly capable of
&gt; artificially fragmenting its SYN packet.  It shouldn't be too hard to
&gt; check what actually happens in this case?  (At least, for the current
&gt; GFW configuration.)

No it wouldn't be hard and I would be surprised if no one actually tried
that already. To be honest I didn't do any search on this.
-----BEGIN PGP SIGNATURE-----

iF4EAREKAAYFAk3zvPkACgkQyM26BSNOM7YdTAD/eGCsr/Yf69yQvauMxGPGjoz1
ZE/LAJuY6oL5kIHOWJUA/38s60FXnb5mePbBvlhlmSI9VXIfC38KKs3EAoquh90j
=9KuF
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611191452</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-11 19:14:52-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>

&gt; On 06/11/2011 07:58 PM, Ian Goldberg wrote:
&gt;&gt; Yes, but the client (say, inside China) is perfectly capable of
&gt;&gt; artificially fragmenting its SYN packet.  It shouldn't be too hard to
&gt;&gt; check what actually happens in this case?  (At least, for the current
&gt;&gt; GFW configuration.)
&gt;
&gt; No it wouldn't be hard and I would be surprised if no one actually tried
&gt; that already. To be honest I didn't do any search on this.

It seems prudent to mention sniffjoke at this point:
http://www.delirandom.net/sniffjoke/

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110611192002</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-11 19:20:02-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>

On Sat, Jun 11, 2011 at 07:14:52PM +0000, Jacob Appelbaum wrote:
&gt; &gt; On 06/11/2011 07:58 PM, Ian Goldberg wrote:
&gt; &gt;&gt; Yes, but the client (say, inside China) is perfectly capable of
&gt; &gt;&gt; artificially fragmenting its SYN packet.  It shouldn't be too hard to
&gt; &gt;&gt; check what actually happens in this case?  (At least, for the current
&gt; &gt;&gt; GFW configuration.)
&gt; &gt;
&gt; &gt; No it wouldn't be hard and I would be surprised if no one actually tried
&gt; &gt; that already. To be honest I didn't do any search on this.
&gt; 
&gt; It seems prudent to mention sniffjoke at this point:
&gt; http://www.delirandom.net/sniffjoke/

Right. Blocking by IP is simple enough to do.  But go much deeper (even
to TCP), and you can play such packetization games.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110607202841</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-06-07 20:28:41-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Tue, 7 Jun 2011 21:08:48 +0100
"Runa A. Sandvik" &lt;runa.sandvik@gmail.com&gt; wrote:
&gt; &gt; Vidalia is not designed to control or configure a Tor process that
&gt; &gt; it did not start.
&gt; 
&gt; I have tested this, and it works just fine. The question is; are we
&gt; happy with something that works, even if it's being used in a way that
&gt; it was not designed for?

Vidalia was designed to do this from the start, which is why it uses
tcp/ip instead of some ephermeral file descriptor locally.  The
connection between their vidalia and the tor process is in plaintext.
That should be the concern.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110607210010</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-07 21:00:10-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On 06/07/2011 01:28 PM, Andrew Lewman wrote:
&gt; On Tue, 7 Jun 2011 21:08:48 +0100
&gt; "Runa A. Sandvik" &lt;runa.sandvik@gmail.com&gt; wrote:
&gt;&gt;&gt; Vidalia is not designed to control or configure a Tor process that
&gt;&gt;&gt; it did not start.
&gt;&gt;
&gt;&gt; I have tested this, and it works just fine. The question is; are we
&gt;&gt; happy with something that works, even if it's being used in a way that
&gt;&gt; it was not designed for?
&gt; 
&gt; Vidalia was designed to do this from the start, which is why it uses
&gt; tcp/ip instead of some ephermeral file descriptor locally.  The
&gt; connection between their vidalia and the tor process is in plaintext.
&gt; That should be the concern.
&gt; 

Yes, it should be SSL/TLS, as I've previously suggested, if we're going
to use that as the controller.

I still think that a web interface isn't that big of a deal if we're
just shipping Debian...

We just need to get a list of requirements and them hammer it out.

(Though it might be neat to add a basic webserver to Tor itself.
Libevent can do this but it doesn't have any concept of a CGI as far as
I've seen..)

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110607215535</emailId><senderName>Runa Sandvik</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-07 21:55:35-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On 7 Jun 2011, at 22:00, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:

&gt; On 06/07/2011 01:28 PM, Andrew Lewman wrote:
&gt; &gt; On Tue, 7 Jun 2011 21:08:48 +0100
&gt; &gt; "Runa A. Sandvik" &lt;runa.sandvik@gmail.com&gt; wrote:
&gt; &gt; &gt; &gt; Vidalia is not designed to control or configure a Tor process that
&gt; &gt; &gt; &gt; it did not start.
&gt; &gt; &gt; 
&gt; &gt; &gt; I have tested this, and it works just fine. The question is; are we
&gt; &gt; &gt; happy with something that works, even if it's being used in a way that
&gt; &gt; &gt; it was not designed for?
&gt; &gt; 
&gt; &gt; Vidalia was designed to do this from the start, which is why it uses
&gt; &gt; tcp/ip instead of some ephermeral file descriptor locally.  The
&gt; &gt; connection between their vidalia and the tor process is in plaintext.
&gt; &gt; That should be the concern.
&gt; &gt; 
&gt; 
&gt; Yes, it should be SSL/TLS, as I've previously suggested, if we're going
&gt; to use that as the controller.

Any idea about how we can do this between Vidalia and a Tor process? Would stunnel be \
useful in this case?

We would also need a way for users to easily change the hashed password. I can't \
remember if this is a feature that is already present in Vidalia. 

&gt; I still think that a web interface isn't that big of a deal if we're
&gt; just shipping Debian...
&gt; 
&gt; We just need to get a list of requirements and them hammer it out.

It's not a big deal, but it will take more time to get the Torouter ready. If Vidalia \
can do what we want, why not use it? The user experience might be a bit better with a \
web interface, though.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110607223645</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-07 22:36:45-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Tue, Jun 7, 2011 at 2:55 PM, Runa Sandvik &lt;runa.sandvik@gmail.com&gt; wrote:

&gt; On 7 Jun 2011, at 22:00, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt; &gt; On 06/07/2011 01:28 PM, Andrew Lewman wrote:
&gt; &gt;&gt; On Tue, 7 Jun 2011 21:08:48 +0100
&gt; &gt;&gt; "Runa A. Sandvik" &lt;runa.sandvik@gmail.com&gt; wrote:
&gt; &gt;&gt;&gt;&gt; Vidalia is not designed to control or configure a Tor process that
&gt; &gt;&gt;&gt;&gt; it did not start.
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; I have tested this, and it works just fine. The question is; are we
&gt; &gt;&gt;&gt; happy with something that works, even if it's being used in a way that
&gt; &gt;&gt;&gt; it was not designed for?
&gt; &gt;&gt;
&gt; &gt;&gt; Vidalia was designed to do this from the start, which is why it uses
&gt; &gt;&gt; tcp/ip instead of some ephermeral file descriptor locally.  The
&gt; &gt;&gt; connection between their vidalia and the tor process is in plaintext.
&gt; &gt;&gt; That should be the concern.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Yes, it should be SSL/TLS, as I've previously suggested, if we're going
&gt; &gt; to use that as the controller.
&gt;
&gt; Any idea about how we can do this between Vidalia and a Tor process? Would
&gt; stunnel be useful in this case?
&gt;
&gt;
Vidalia needs to run a TLS server on whatever port it opens. Tor would need
to know how to communicate with a TLS control port. I believe that it would
be an interesting problem to try to authenticate the certificate of the
remote Tor and actually one that could be solved without too much issue.


&gt; We would also need a way for users to easily change the hashed password. I
&gt; can't remember if this is a feature that is already present in Vidalia.
&gt;
&gt;
Yes, we do need a way to change the password. We will also need a way to
reset the password if the user is locked out of the control port. I
generally think that this means we'll need a web UI... :-)


&gt; &gt; I still think that a web interface isn't that big of a deal if we're
&gt; &gt; just shipping Debian...
&gt; &gt;
&gt; &gt; We just need to get a list of requirements and them hammer it out.
&gt;
&gt; It's not a big deal, but it will take more time to get the Torouter ready.
&gt; If Vidalia can do what we want, why not use it? The user experience might be
&gt; a bit better with a web interface, though.
&gt;
&gt;
Well, I see a number of issues. One of the main issues is that you cannot
safely connect to Vidalia over a network until TLS support is added to both
Vidalia and Tor. Another is authentication of that connection. Yet another
is that it will be extremely confusing for a user who doesn't understand
what Vidalia does or why they'd need it.

I think the best thing is to make an autoconfiguring device with a web UI;
we can easily rate limit Tor to something reasonable and make it a middle
node by default. In all cases it stands alone and simply plugging it into a
wall (power/ethernet) will provide more capacity to the network if the OR
port is reachable (ala tor-fw-helper + tor + init.d scripts to start Tor on
boot).

Adding Vidalia to the mix seems like a nice to have but I don't think it's
currently up to the task...

All the best,
Jake

[Attachment #5 (text/html)]

On Tue, Jun 7, 2011 at 2:55 PM, Runa Sandvik &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On 7 Jun 2011, \
at 22:00, Jacob Appelbaum &lt;&lt;a \
href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; wrote:&lt;br&gt; &lt;br&gt;
&gt; On 06/07/2011 01:28 PM, Andrew Lewman wrote:&lt;br&gt;
&gt;&gt; On Tue, 7 Jun 2011 21:08:48 +0100&lt;br&gt;
&gt;&gt; "Runa A. Sandvik" &lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt;&gt;&gt;&gt; Vidalia is not designed to control or configure a Tor process \
that&lt;br&gt; &gt;&gt;&gt;&gt; it did not start.&lt;br&gt;
&gt;&gt;&gt;&lt;br&gt;
&gt;&gt;&gt; I have tested this, and it works just fine. The question is; are we&lt;br&gt;
&gt;&gt;&gt; happy with something that works, even if it's being used in a way \
that&lt;br&gt; &gt;&gt;&gt; it was not designed for?&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Vidalia was designed to do this from the start, which is why it uses&lt;br&gt;
&gt;&gt; tcp/ip instead of some ephermeral file descriptor locally.  The&lt;br&gt;
&gt;&gt; connection between their vidalia and the tor process is in plaintext.&lt;br&gt;
&gt;&gt; That should be the concern.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; Yes, it should be SSL/TLS, as I've previously suggested, if we're \
going&lt;br&gt; &gt; to use that as the controller.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Any idea about how we can do this between Vidalia and a Tor process? Would \
stunnel be useful in this case?&lt;br&gt; &lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Vidalia \
needs to run a TLS server on whatever port it opens. Tor would need to know how to \
communicate with a TLS control port. I believe that it would be an interesting \
problem to try to authenticate the certificate of the remote Tor and actually one \
that could be solved without too much issue.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; We would also need a way for users to easily change the \
hashed password. I can't remember if this is a feature that is already present in \
Vidalia.&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yes, we do \
need a way to change the password. We will also need a way to reset the password if \
the user is locked out of the control port. I generally think that this means \
we'll need a web UI... :-)&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div \
class="im"&gt; &gt; I still think that a web interface isn't that big of a deal if \
we're&lt;br&gt; &gt; just shipping Debian...&lt;br&gt;
&gt;&lt;br&gt;
&gt; We just need to get a list of requirements and them hammer it out.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;It's not a big deal, but it will take more time to get the Torouter ready. \
If Vidalia can do what we want, why not use it? The user experience might be a bit \
better with a web interface, though.&lt;br&gt;&lt;font class="Apple-style-span" \
color="#888888"&gt;&lt;br&gt; &lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Well, I see a number of \
issues. One of the main issues is that you cannot safely connect to Vidalia over a \
network until TLS support is added to both Vidalia and Tor. Another is authentication \
of that connection. Yet another is that it will be extremely confusing for a user who \
doesn't understand what Vidalia does or why they'd need it.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think the best thing is to make an autoconfiguring device with \
a web UI; we can easily rate limit Tor to something reasonable and make it a middle \
node by default. In all cases it stands alone and simply plugging it into a wall \
(power/ethernet) will provide more capacity to the network if the OR port is \
reachable (ala tor-fw-helper + tor + init.d scripts to start Tor on boot).&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Adding Vidalia to the mix seems like a nice to have but I \
don't think it's currently up to the task...&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the \
best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110608150217</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-06-08 15:02:17-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Tue, 7 Jun 2011 15:36:45 -0700
Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:

&gt; &gt; We would also need a way for users to easily change the hashed
&gt; &gt; password. I can't remember if this is a feature that is already
&gt; &gt; present in Vidalia.
&gt; Yes, we do need a way to change the password. We will also need a way
&gt; to reset the password if the user is locked out of the control port. I
&gt; generally think that this means we'll need a web UI... :-)

It's built into vidalia.  Just click Advanced and you can change the
password all you want.

&gt; I think the best thing is to make an autoconfiguring device with a
&gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt; it a middle node by default. In all cases it stands alone and simply
&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt; init.d scripts to start Tor on boot).

Most of me wants to wait for the freedombox people to derive their web
interface, and then we can plug tor into it.  I realize this could be
years at the current rate of progress. If someone whips up a quick
interface that isn't a security nightmare, we could use that until
freedombox has something tangible.

I suggest we ship the dreamplug with cli access only for those who want
a cheap device to be a bridge or relay.  

I suggest we ship the excito with the web ui as the easy to use
option.  

In either case, we need to start testing, not keep thinking about what
we could do.  We're going to get a flood of feedback from actual people
testing the excito or dreamplug.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110608152829</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-08 15:28:29-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Wed, Jun 8, 2011 at 8:02 AM, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt; &gt; &gt; We would also need a way for users to easily change the hashed
&gt; &gt; &gt; password. I can't remember if this is a feature that is already
&gt; &gt; &gt; present in Vidalia.
&gt; &gt; Yes, we do need a way to change the password. We will also need a way
&gt; &gt; to reset the password if the user is locked out of the control port. I
&gt; &gt; generally think that this means we'll need a web UI... :-)
&gt;
&gt; It's built into vidalia.  Just click Advanced and you can change the
&gt; password all you want.
&gt;
&gt;
Sure, I think that's good for a local socket but not going to help with
remote control ports or a locked out password.


&gt; &gt; I think the best thing is to make an autoconfiguring device with a
&gt; &gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt; &gt; it a middle node by default. In all cases it stands alone and simply
&gt; &gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt; &gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt; &gt; init.d scripts to start Tor on boot).
&gt;
&gt; Most of me wants to wait for the freedombox people to derive their web
&gt; interface, and then we can plug tor into it.  I realize this could be
&gt; years at the current rate of progress. If someone whips up a quick
&gt; interface that isn't a security nightmare, we could use that until
&gt; freedombox has something tangible.
&gt;
&gt;
I generally agree.


&gt; I suggest we ship the dreamplug with cli access only for those who want
&gt; a cheap device to be a bridge or relay.
&gt;
&gt;
That seems reasonable.


&gt; I suggest we ship the excito with the web ui as the easy to use
&gt; option.
&gt;
&gt;
How's that web UI doing?


&gt; In either case, we need to start testing, not keep thinking about what
&gt; we could do.  We're going to get a flood of feedback from actual people
&gt; testing the excito or dreamplug.
&gt;
&gt;
I agree. My excito is pushing a lot of data without any trouble, my
dreamplug hasn't arrived.

I was thinking that we should talk about clocks. I think djb solved the main
problem of syncing clocks a while ago:
http://cr.yp.to/clockspeed.html

I think we should consider this as something we push for any embedded system
with Tor.

All the best,
Jake

[Attachment #5 (text/html)]

On Wed, Jun 8, 2011 at 8:02 AM, Andrew Lewman &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; On Tue, 7 Jun 2011 15:36:45 \
-0700&lt;br&gt; &lt;div class="im"&gt;Jacob Appelbaum &lt;&lt;a \
href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; wrote:&lt;br&gt; &lt;br&gt;
&lt;/div&gt;&lt;div class="im"&gt;&gt; &gt; We would also need a way for users to easily change \
the hashed&lt;br&gt; &gt; &gt; password. I can't remember if this is a feature that is \
already&lt;br&gt; &gt; &gt; present in Vidalia.&lt;br&gt;
&gt; Yes, we do need a way to change the password. We will also need a way&lt;br&gt;
&gt; to reset the password if the user is locked out of the control port. I&lt;br&gt;
&gt; generally think that this means we'll need a web UI... :-)&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;It's built into vidalia.  Just click Advanced and you can change the&lt;br&gt;
password all you want.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sure, I think that's \
good for a local socket but not going to help with remote control ports or a locked \
out password.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;
&gt; I think the best thing is to make an autoconfiguring device with a&lt;br&gt;
&gt; web UI; we can easily rate limit Tor to something reasonable and make&lt;br&gt;
&gt; it a middle node by default. In all cases it stands alone and simply&lt;br&gt;
&gt; plugging it into a wall (power/ethernet) will provide more capacity&lt;br&gt;
&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +&lt;br&gt;
&gt; init.d scripts to start Tor on boot).&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Most of me wants to wait for the freedombox people to derive their web&lt;br&gt;
interface, and then we can plug tor into it.  I realize this could be&lt;br&gt;
years at the current rate of progress. If someone whips up a quick&lt;br&gt;
interface that isn't a security nightmare, we could use that until&lt;br&gt;
freedombox has something tangible.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I generally agree.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; I suggest we ship the dreamplug with cli access only for \
those who want&lt;br&gt; a cheap device to be a bridge or relay.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That seems reasonable.&lt;/div&gt;&lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; I suggest we ship the excito with the web ui as the easy to \
use&lt;br&gt; option.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;How's that web UI doing?&lt;/div&gt;&lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; In either case, we need to start testing, not keep thinking \
about what&lt;br&gt; we could do.  We're going to get a flood of feedback from actual \
people&lt;br&gt; testing the excito or dreamplug.&lt;br&gt;&lt;font class="Apple-style-span" \
color="#888888"&gt;&lt;br&gt;&lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I agree. My excito is \
pushing a lot of data without any trouble, my dreamplug hasn't arrived.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I was thinking that we should talk about clocks. I think djb \
solved the main problem of syncing clocks a while ago:&lt;/div&gt;&lt;meta \
http-equiv="content-type" content="text/html; charset=utf-8"&gt;&lt;div&gt;&lt;a \
href="http://cr.yp.to/clockspeed.html"&gt;http://cr.yp.to/clockspeed.html&lt;/a&gt;&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think we should consider this as something we push for any \
embedded system with Tor.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake \
&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609145756</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-09 14:57:56-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
&gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt;&gt; &gt; We would also need a way for users to easily change the hashed
&gt;&gt; &gt; password. I can't remember if this is a feature that is already
&gt;&gt; &gt; present in Vidalia.
&gt;&gt; Yes, we do need a way to change the password. We will also need a way
&gt;&gt; to reset the password if the user is locked out of the control port. I
&gt;&gt; generally think that this means we'll need a web UI... :-)
&gt;
&gt; It's built into vidalia.  Just click Advanced and you can change the
&gt; password all you want.
&gt;
&gt;&gt; I think the best thing is to make an autoconfiguring device with a
&gt;&gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt;&gt; it a middle node by default. In all cases it stands alone and simply
&gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt;&gt; init.d scripts to start Tor on boot).
&gt;
&gt; Most of me wants to wait for the freedombox people to derive their web
&gt; interface, and then we can plug tor into it.  I realize this could be
&gt; years at the current rate of progress. If someone whips up a quick
&gt; interface that isn't a security nightmare, we could use that until
&gt; freedombox has something tangible.

Yeah, I was hoping the freedombox people would have something we could
use. Doesn't seem like it, though. I think that, at some point, we
should create a web ui for the dreamplug. But not having one right now
should not be a blocker for the dreamplug-torouter.

&gt; I suggest we ship the dreamplug with cli access only for those who want
&gt; a cheap device to be a bridge or relay.

I guess we can set up dreamplugs as bridges by default and include a
leaflet explaining the steps to take to change the configuration. Do
you think we should touch the default setup of the dreamplug (it
serves an open wifi by default, for example)?

&gt; I suggest we ship the excito with the web ui as the easy to use
&gt; option.

Yep, the Tor web ui for the Excito B3 should be ready at the end of the month.

&gt; In either case, we need to start testing, not keep thinking about what
&gt; we could do.  We're going to get a flood of feedback from actual people
&gt; testing the excito or dreamplug.

Valid point.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110609155543</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 15:55:43-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Thu, Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;andrew@torproject.org&gt;
&gt; wrote:
&gt; &gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt; &gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; &gt;
&gt; &gt;&gt; &gt; We would also need a way for users to easily change the hashed
&gt; &gt;&gt; &gt; password. I can't remember if this is a feature that is already
&gt; &gt;&gt; &gt; present in Vidalia.
&gt; &gt;&gt; Yes, we do need a way to change the password. We will also need a way
&gt; &gt;&gt; to reset the password if the user is locked out of the control port. I
&gt; &gt;&gt; generally think that this means we'll need a web UI... :-)
&gt; &gt;
&gt; &gt; It's built into vidalia.  Just click Advanced and you can change the
&gt; &gt; password all you want.
&gt; &gt;
&gt; &gt;&gt; I think the best thing is to make an autoconfiguring device with a
&gt; &gt;&gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt; &gt;&gt; it a middle node by default. In all cases it stands alone and simply
&gt; &gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt; &gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt; &gt;&gt; init.d scripts to start Tor on boot).
&gt; &gt;
&gt; &gt; Most of me wants to wait for the freedombox people to derive their web
&gt; &gt; interface, and then we can plug tor into it.  I realize this could be
&gt; &gt; years at the current rate of progress. If someone whips up a quick
&gt; &gt; interface that isn't a security nightmare, we could use that until
&gt; &gt; freedombox has something tangible.
&gt;
&gt; Yeah, I was hoping the freedombox people would have something we could
&gt; use. Doesn't seem like it, though. I think that, at some point, we
&gt; should create a web ui for the dreamplug. But not having one right now
&gt; should not be a blocker for the dreamplug-torouter.
&gt;
&gt;
Well, I'm not sure what you mean... The FB is just a Debian machine. Pick a
web server, write a cgi and perhaps that will be the main interface? :-) I'd
email the FBF list and ask. Perhaps the best web UI is one that is already
written? Is the web UI for the Excito free software?

&gt; I suggest we ship the dreamplug with cli access only for those who want
&gt; &gt; a cheap device to be a bridge or relay.
&gt;
&gt; I guess we can set up dreamplugs as bridges by default and include a
&gt; leaflet explaining the steps to take to change the configuration. Do
&gt; you think we should touch the default setup of the dreamplug (it
&gt; serves an open wifi by default, for example)?
&gt;
&gt;
I believe that by default we should be shipping middle relays and we should
be shipping 0.2.3.x with tor-fw-helper enabled by default as well.

I think the boxes should be re-flashed to have Debian or a modern Ubuntu and
locked down except with Tor and OpenSSH as listening services. We also need
things to sync time and so on.


&gt; &gt; I suggest we ship the excito with the web ui as the easy to use
&gt; &gt; option.
&gt;
&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of the
&gt; month.
&gt;
&gt;
Is it Free Software? Can we use it on the DreamPlug until we have something
else?


&gt; &gt; In either case, we need to start testing, not keep thinking about what
&gt; &gt; we could do.  We're going to get a flood of feedback from actual people
&gt; &gt; testing the excito or dreamplug.
&gt;
&gt; Valid point.
&gt;
&gt;
I think we need to talk about what we need for the OS. I suspect we need
OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files + time
syncing (clockskew for example) + a randomly generated password that we
uniquely key for each router in some non-silly way.

Is there a trac ticket for the OS part of the Torouter?

All the best,
Jake

[Attachment #5 (text/html)]

On Thu, Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Wed, Jun 8, \
2011 at 4:02 PM, Andrew Lewman &lt;&lt;a \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&lt;/div&gt;&lt;div class="im"&gt;&gt; On Tue, 7 Jun 2011 15:36:45 -0700&lt;br&gt; &gt; Jacob Appelbaum \
&lt;&lt;a href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt;&lt;br&gt; &gt;&gt; &gt; We would also need a way for users to easily change the \
hashed&lt;br&gt; &gt;&gt; &gt; password. I can't remember if this is a feature that is \
already&lt;br&gt; &gt;&gt; &gt; present in Vidalia.&lt;br&gt;
&gt;&gt; Yes, we do need a way to change the password. We will also need a way&lt;br&gt;
&gt;&gt; to reset the password if the user is locked out of the control port. I&lt;br&gt;
&gt;&gt; generally think that this means we'll need a web UI... :-)&lt;br&gt;
&gt;&lt;br&gt;
&gt; It's built into vidalia.  Just click Advanced and you can change the&lt;br&gt;
&gt; password all you want.&lt;br&gt;
&gt;&lt;br&gt;
&gt;&gt; I think the best thing is to make an autoconfiguring device with a&lt;br&gt;
&gt;&gt; web UI; we can easily rate limit Tor to something reasonable and make&lt;br&gt;
&gt;&gt; it a middle node by default. In all cases it stands alone and simply&lt;br&gt;
&gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity&lt;br&gt;
&gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +&lt;br&gt;
&gt;&gt; init.d scripts to start Tor on boot).&lt;br&gt;
&gt;&lt;br&gt;
&gt; Most of me wants to wait for the freedombox people to derive their web&lt;br&gt;
&gt; interface, and then we can plug tor into it.  I realize this could be&lt;br&gt;
&gt; years at the current rate of progress. If someone whips up a quick&lt;br&gt;
&gt; interface that isn't a security nightmare, we could use that until&lt;br&gt;
&gt; freedombox has something tangible.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Yeah, I was hoping the freedombox people would have something we could&lt;br&gt;
use. Doesn't seem like it, though. I think that, at some point, we&lt;br&gt;
should create a web ui for the dreamplug. But not having one right now&lt;br&gt;
should not be a blocker for the dreamplug-torouter.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Well, I'm not sure \
what you mean... The FB is just a Debian machine. Pick a web server, write a cgi and \
perhaps that will be the main interface? :-) I'd email the FBF list and ask. \
Perhaps the best web UI is one that is already written? Is the web UI for the Excito \
free software?&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt; I suggest \
we ship the dreamplug with cli access only for those who want&lt;br&gt; &gt; a cheap device \
to be a bridge or relay.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;I guess we can set up dreamplugs as bridges by default and include a&lt;br&gt;
leaflet explaining the steps to take to change the configuration. Do&lt;br&gt;
you think we should touch the default setup of the dreamplug (it&lt;br&gt;
serves an open wifi by default, for example)?&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I believe that by default \
we should be shipping middle relays and we should be shipping 0.2.3.x with \
tor-fw-helper enabled by default as well.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt; &lt;div&gt;I think the boxes \
should be re-flashed to have Debian or a modern Ubuntu and locked down except with \
Tor and OpenSSH as listening services. We also need things to sync time and so \
on.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;
&gt; I suggest we ship the excito with the web ui as the easy to use&lt;br&gt;
&gt; option.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Yep, the Tor web ui for the Excito B3 should be ready at the end of the \
month.&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is it Free \
Software? Can we use it on the DreamPlug until we have something else?&lt;/div&gt;&lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;
&gt; In either case, we need to start testing, not keep thinking about what&lt;br&gt;
&gt; we could do.  We're going to get a flood of feedback from actual people&lt;br&gt;
&gt; testing the excito or dreamplug.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Valid point.&lt;br&gt;&lt;font class="Apple-style-span" \
color="#888888"&gt;&lt;br&gt;&lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think we need to talk \
about what we need for the OS. I suspect we need OpenSSH + Tor (tor-fw-helper, etc) + \
a few stock configuration files + time syncing (clockskew for example) + a randomly \
generated password that we uniquely key for each router in some non-silly way.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is there a trac ticket for the OS part of the Torouter? \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609193410</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-09 19:34:10-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 9, 2011 at 4:55 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On Thu, Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;andrew@torproject.org&gt;
&gt;&gt; wrote:
&gt;&gt; &gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt;&gt; &gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt;&gt; &gt; We would also need a way for users to easily change the hashed
&gt;&gt; &gt;&gt; &gt; password. I can't remember if this is a feature that is already
&gt;&gt; &gt;&gt; &gt; present in Vidalia.
&gt;&gt; &gt;&gt; Yes, we do need a way to change the password. We will also need a way
&gt;&gt; &gt;&gt; to reset the password if the user is locked out of the control port. I
&gt;&gt; &gt;&gt; generally think that this means we'll need a web UI... :-)
&gt;&gt; &gt;
&gt;&gt; &gt; It's built into vidalia.  Just click Advanced and you can change the
&gt;&gt; &gt; password all you want.
&gt;&gt; &gt;
&gt;&gt; &gt;&gt; I think the best thing is to make an autoconfiguring device with a
&gt;&gt; &gt;&gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt;&gt; &gt;&gt; it a middle node by default. In all cases it stands alone and simply
&gt;&gt; &gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt;&gt; &gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt;&gt; &gt;&gt; init.d scripts to start Tor on boot).
&gt;&gt; &gt;
&gt;&gt; &gt; Most of me wants to wait for the freedombox people to derive their web
&gt;&gt; &gt; interface, and then we can plug tor into it.  I realize this could be
&gt;&gt; &gt; years at the current rate of progress. If someone whips up a quick
&gt;&gt; &gt; interface that isn't a security nightmare, we could use that until
&gt;&gt; &gt; freedombox has something tangible.
&gt;&gt;
&gt;&gt; Yeah, I was hoping the freedombox people would have something we could
&gt;&gt; use. Doesn't seem like it, though. I think that, at some point, we
&gt;&gt; should create a web ui for the dreamplug. But not having one right now
&gt;&gt; should not be a blocker for the dreamplug-torouter.
&gt;&gt;
&gt;
&gt; Well, I'm not sure what you mean... The FB is just a Debian machine. Pick a
&gt; web server, write a cgi and perhaps that will be the main interface? :-) I'd
&gt; email the FBF list and ask. Perhaps the best web UI is one that is already
&gt; written? Is the web UI for the Excito free software?

I was hoping there would be an existing ui what we could just plug Tor
into, just like we did with the Excito B3 interface.

&gt;&gt; &gt; I suggest we ship the dreamplug with cli access only for those who want
&gt;&gt; &gt; a cheap device to be a bridge or relay.
&gt;&gt;
&gt;&gt; I guess we can set up dreamplugs as bridges by default and include a
&gt;&gt; leaflet explaining the steps to take to change the configuration. Do
&gt;&gt; you think we should touch the default setup of the dreamplug (it
&gt;&gt; serves an open wifi by default, for example)?
&gt;&gt;
&gt;
&gt; I believe that by default we should be shipping middle relays and we should
&gt; be shipping 0.2.3.x with tor-fw-helper enabled by default as well.
&gt; I think the boxes should be re-flashed to have Debian or a modern Ubuntu and
&gt; locked down except with Tor and OpenSSH as listening services. We also need
&gt; things to sync time and so on.

Sounds like a plan. I prefer bridge by default, but we can discuss that later.

&gt;&gt; &gt; I suggest we ship the excito with the web ui as the easy to use
&gt;&gt; &gt; option.
&gt;&gt;
&gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of the
&gt;&gt; month.
&gt;&gt;
&gt;
&gt; Is it Free Software? Can we use it on the DreamPlug until we have something
&gt; else?

Yes, it's free software and will be available in the Excito GitHub
repository when it's released (not sure if it's there already, I don't
think so). The web interface is probably a bit too "heavy" (and
includes a good mix of php and perl) for the dreamplug, so we should
probably look for something else.

&gt;&gt; &gt; In either case, we need to start testing, not keep thinking about what
&gt;&gt; &gt; we could do.  We're going to get a flood of feedback from actual people
&gt;&gt; &gt; testing the excito or dreamplug.
&gt;&gt;
&gt;&gt; Valid point.
&gt;&gt;
&gt;
&gt; I think we need to talk about what we need for the OS. I suspect we need
&gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files + time
&gt; syncing (clockskew for example) + a randomly generated password that we
&gt; uniquely key for each router in some non-silly way.
&gt; Is there a trac ticket for the OS part of the Torouter?

There is now: https://trac.torproject.org/projects/tor/ticket/3374

We can move the discussion to #3374 if you want.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110609195009</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 19:50:09-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Thu, Jun 9, 2011 at 7:34 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; On Thu, Jun 9, 2011 at 4:55 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt; wrote:
&gt; &gt; On Thu, Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; &gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;andrew@torproject.org&gt;
&gt; &gt;&gt; wrote:
&gt; &gt;&gt; &gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt; &gt;&gt; &gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; We would also need a way for users to easily change the hashed
&gt; &gt;&gt; &gt;&gt; &gt; password. I can't remember if this is a feature that is already
&gt; &gt;&gt; &gt;&gt; &gt; present in Vidalia.
&gt; &gt;&gt; &gt;&gt; Yes, we do need a way to change the password. We will also need a way
&gt; &gt;&gt; &gt;&gt; to reset the password if the user is locked out of the control port.
&gt; I
&gt; &gt;&gt; &gt;&gt; generally think that this means we'll need a web UI... :-)
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; It's built into vidalia.  Just click Advanced and you can change the
&gt; &gt;&gt; &gt; password all you want.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; I think the best thing is to make an autoconfiguring device with a
&gt; &gt;&gt; &gt;&gt; web UI; we can easily rate limit Tor to something reasonable and make
&gt; &gt;&gt; &gt;&gt; it a middle node by default. In all cases it stands alone and simply
&gt; &gt;&gt; &gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt; &gt;&gt; &gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor +
&gt; &gt;&gt; &gt;&gt; init.d scripts to start Tor on boot).
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; Most of me wants to wait for the freedombox people to derive their web
&gt; &gt;&gt; &gt; interface, and then we can plug tor into it.  I realize this could be
&gt; &gt;&gt; &gt; years at the current rate of progress. If someone whips up a quick
&gt; &gt;&gt; &gt; interface that isn't a security nightmare, we could use that until
&gt; &gt;&gt; &gt; freedombox has something tangible.
&gt; &gt;&gt;
&gt; &gt;&gt; Yeah, I was hoping the freedombox people would have something we could
&gt; &gt;&gt; use. Doesn't seem like it, though. I think that, at some point, we
&gt; &gt;&gt; should create a web ui for the dreamplug. But not having one right now
&gt; &gt;&gt; should not be a blocker for the dreamplug-torouter.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Well, I'm not sure what you mean... The FB is just a Debian machine. Pick
&gt; a
&gt; &gt; web server, write a cgi and perhaps that will be the main interface? :-)
&gt; I'd
&gt; &gt; email the FBF list and ask. Perhaps the best web UI is one that is
&gt; already
&gt; &gt; written? Is the web UI for the Excito free software?
&gt;
&gt; I was hoping there would be an existing ui what we could just plug Tor
&gt; into, just like we did with the Excito B3 interface.
&gt;
&gt;
I think it's fine to ship one web interface for us now and later find a good
integration point with the Freedom Box later...


&gt; &gt;&gt; &gt; I suggest we ship the dreamplug with cli access only for those who
&gt; want
&gt; &gt;&gt; &gt; a cheap device to be a bridge or relay.
&gt; &gt;&gt;
&gt; &gt;&gt; I guess we can set up dreamplugs as bridges by default and include a
&gt; &gt;&gt; leaflet explaining the steps to take to change the configuration. Do
&gt; &gt;&gt; you think we should touch the default setup of the dreamplug (it
&gt; &gt;&gt; serves an open wifi by default, for example)?
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; I believe that by default we should be shipping middle relays and we
&gt; should
&gt; &gt; be shipping 0.2.3.x with tor-fw-helper enabled by default as well.
&gt; &gt; I think the boxes should be re-flashed to have Debian or a modern Ubuntu
&gt; and
&gt; &gt; locked down except with Tor and OpenSSH as listening services. We also
&gt; need
&gt; &gt; things to sync time and so on.
&gt;
&gt; Sounds like a plan. I prefer bridge by default, but we can discuss that
&gt; later.
&gt;
&gt;
What's the rational there? While we certainly need more bridges, I'd like to
see an increase in relays and encourage more Friend of Friend bridge
sharing. We should include a bunch of common configs and make it easy to
setup. Also, a public relay will be much easier to help with in terms of
setup, I suspect.


&gt; &gt;&gt; &gt; I suggest we ship the excito with the web ui as the easy to use
&gt; &gt;&gt; &gt; option.
&gt; &gt;&gt;
&gt; &gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of the
&gt; &gt;&gt; month.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Is it Free Software? Can we use it on the DreamPlug until we have
&gt; something
&gt; &gt; else?
&gt;
&gt; Yes, it's free software and will be available in the Excito GitHub
&gt; repository when it's released (not sure if it's there already, I don't
&gt; think so). The web interface is probably a bit too "heavy" (and
&gt; includes a good mix of php and perl) for the dreamplug, so we should
&gt; probably look for something else.
&gt;
&gt;
Can we rip out everything except the basics? If so, I think their web front
end is perfect and it already has a Tor UI thanks to you... :-)


&gt; &gt;&gt; &gt; In either case, we need to start testing, not keep thinking about what
&gt; &gt;&gt; &gt; we could do.  We're going to get a flood of feedback from actual
&gt; people
&gt; &gt;&gt; &gt; testing the excito or dreamplug.
&gt; &gt;&gt;
&gt; &gt;&gt; Valid point.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; I think we need to talk about what we need for the OS. I suspect we need
&gt; &gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files +
&gt; time
&gt; &gt; syncing (clockskew for example) + a randomly generated password that we
&gt; &gt; uniquely key for each router in some non-silly way.
&gt; &gt; Is there a trac ticket for the OS part of the Torouter?
&gt;
&gt; There is now: https://trac.torproject.org/projects/tor/ticket/3374
&gt;
&gt; We can move the discussion to #3374 if you want.
&gt;
&gt;
I'm happy to keep hammering stuff out here and the we can dump the results
into the bug report.

What do you think about a DreamPlug with Debian or Ubuntu? Do we have a
preference?
What other software do we need beyond ntp, ssh, tor and a web UI?
Do we want to support a transparent Tor wifi network by default?

I think Ubuntu's latest release is the best in terms of security and in
theory support. It is however not as beloved as Debian for a number of solid
reasons. I think NTP, OpenSSH with key auth (and perhaps fail2ban or
something similar) and password auth, a very minimal web UI but still
functional for real Tor configuration and that's about all we'll need.

I also like the idea of a Tor wifi network by default for laptops like the
CR-48 that I'm using right now. I'd kill to have a way to Torify the laptop
because my main concern isn't privacy from my local network, it's data
retention from the remote hosts... :-/

All the best,
Jake

[Attachment #5 (text/html)]

On Thu, Jun 9, 2011 at 7:34 PM, Runa A. Sandvik &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;On Thu, Jun 9, 2011 at 4:55 PM, Jacob Appelbaum &lt;&lt;a \
href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; On Thu, \
Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;br&gt; &gt; \
wrote:&lt;br&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;&lt;a \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt;&lt;br&gt; &gt;&gt; \
wrote:&lt;br&gt; &gt;&gt; &gt; On Tue, 7 Jun 2011 15:36:45 -0700&lt;br&gt;
&gt;&gt; &gt; Jacob Appelbaum &lt;&lt;a \
href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt;&gt; \
&gt;&lt;br&gt; &gt;&gt; &gt;&gt; &gt; We would also need a way for users to easily change \
the hashed&lt;br&gt; &gt;&gt; &gt;&gt; &gt; password. I can't remember if this is a \
feature that is already&lt;br&gt; &gt;&gt; &gt;&gt; &gt; present in Vidalia.&lt;br&gt;
&gt;&gt; &gt;&gt; Yes, we do need a way to change the password. We will also need a \
way&lt;br&gt; &gt;&gt; &gt;&gt; to reset the password if the user is locked out of the \
control port. I&lt;br&gt; &gt;&gt; &gt;&gt; generally think that this means we'll need \
a web UI... :-)&lt;br&gt; &gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt; It's built into vidalia.  Just click Advanced and you can change \
the&lt;br&gt; &gt;&gt; &gt; password all you want.&lt;br&gt;
&gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt;&gt; I think the best thing is to make an autoconfiguring device with \
a&lt;br&gt; &gt;&gt; &gt;&gt; web UI; we can easily rate limit Tor to something reasonable \
and make&lt;br&gt; &gt;&gt; &gt;&gt; it a middle node by default. In all cases it stands \
alone and simply&lt;br&gt; &gt;&gt; &gt;&gt; plugging it into a wall (power/ethernet) will \
provide more capacity&lt;br&gt; &gt;&gt; &gt;&gt; to the network if the OR port is \
reachable (ala tor-fw-helper + tor +&lt;br&gt; &gt;&gt; &gt;&gt; init.d scripts to start \
Tor on boot).&lt;br&gt; &gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt; Most of me wants to wait for the freedombox people to derive their \
web&lt;br&gt; &gt;&gt; &gt; interface, and then we can plug tor into it.  I realize this \
could be&lt;br&gt; &gt;&gt; &gt; years at the current rate of progress. If someone whips up \
a quick&lt;br&gt; &gt;&gt; &gt; interface that isn't a security nightmare, we could use \
that until&lt;br&gt; &gt;&gt; &gt; freedombox has something tangible.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Yeah, I was hoping the freedombox people would have something we could&lt;br&gt;
&gt;&gt; use. Doesn't seem like it, though. I think that, at some point, we&lt;br&gt;
&gt;&gt; should create a web ui for the dreamplug. But not having one right now&lt;br&gt;
&gt;&gt; should not be a blocker for the dreamplug-torouter.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; Well, I'm not sure what you mean... The FB is just a Debian machine. Pick \
a&lt;br&gt; &gt; web server, write a cgi and perhaps that will be the main interface? :-) \
I'd&lt;br&gt; &gt; email the FBF list and ask. Perhaps the best web UI is one that is \
already&lt;br&gt; &gt; written? Is the web UI for the Excito free software?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;I was hoping there would be an existing ui what we could just plug \
Tor&lt;br&gt; into, just like we did with the Excito B3 interface.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think it's fine to \
ship one web interface for us now and later find a good integration point with the \
Freedom Box later...&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 \
0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;
&gt;&gt; &gt; I suggest we ship the dreamplug with cli access only for those who \
want&lt;br&gt; &gt;&gt; &gt; a cheap device to be a bridge or relay.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; I guess we can set up dreamplugs as bridges by default and include a&lt;br&gt;
&gt;&gt; leaflet explaining the steps to take to change the configuration. Do&lt;br&gt;
&gt;&gt; you think we should touch the default setup of the dreamplug (it&lt;br&gt;
&gt;&gt; serves an open wifi by default, for example)?&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; I believe that by default we should be shipping middle relays and we should&lt;br&gt;
&gt; be shipping 0.2.3.x with tor-fw-helper enabled by default as well.&lt;br&gt;
&gt; I think the boxes should be re-flashed to have Debian or a modern Ubuntu and&lt;br&gt;
&gt; locked down except with Tor and OpenSSH as listening services. We also need&lt;br&gt;
&gt; things to sync time and so on.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Sounds like a plan. I prefer bridge by default, but we can discuss that \
later.&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What's the \
rational there? While we certainly need more bridges, I'd like to see an increase \
in relays and encourage more Friend of Friend bridge sharing. We should include a \
bunch of common configs and make it easy to setup. Also, a public relay will be much \
easier to help with in terms of setup, I suspect.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt;&gt; &gt; I suggest we ship the excito \
with the web ui as the easy to use&lt;br&gt; &gt;&gt; &gt; option.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of the&lt;br&gt;
&gt;&gt; month.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; Is it Free Software? Can we use it on the DreamPlug until we have something&lt;br&gt;
&gt; else?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Yes, it's free software and will be available in the Excito GitHub&lt;br&gt;
repository when it's released (not sure if it's there already, I \
don't&lt;br&gt; think so). The web interface is probably a bit too "heavy" \
(and&lt;br&gt; includes a good mix of php and perl) for the dreamplug, so we should&lt;br&gt;
probably look for something else.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Can we rip out everything \
except the basics? If so, I think their web front end is perfect and it already has a \
Tor UI thanks to you... :-)&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div \
class="im"&gt; &gt;&gt; &gt; In either case, we need to start testing, not keep thinking \
about what&lt;br&gt; &gt;&gt; &gt; we could do.  We're going to get a flood of feedback \
from actual people&lt;br&gt; &gt;&gt; &gt; testing the excito or dreamplug.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Valid point.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; I think we need to talk about what we need for the OS. I suspect we need&lt;br&gt;
&gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files + time&lt;br&gt;
&gt; syncing (clockskew for example) + a randomly generated password that we&lt;br&gt;
&gt; uniquely key for each router in some non-silly way.&lt;br&gt;
&gt; Is there a trac ticket for the OS part of the Torouter?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;There is now: &lt;a href="https://trac.torproject.org/projects/tor/ticket/3374" \
target="_blank"&gt;https://trac.torproject.org/projects/tor/ticket/3374&lt;/a&gt;&lt;br&gt; &lt;br&gt;
We can move the discussion to #3374 if you want.&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'm happy to keep \
hammering stuff out here and the we can dump the results into the bug \
report.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What do you think about a DreamPlug with Debian or \
Ubuntu? Do we have a preference?&lt;/div&gt; &lt;div&gt;What other software do we need beyond \
ntp, ssh, tor and a web UI?&lt;/div&gt;&lt;div&gt;Do we want to support a transparent Tor wifi \
network by default?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think Ubuntu's latest release is \
the best in terms of security and in theory support. It is however not as beloved as \
Debian for a number of solid reasons. I think NTP, OpenSSH with key auth (and perhaps \
fail2ban or something similar) and password auth, a very minimal web UI but still \
functional for real Tor configuration and that's about all we'll need.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I also like the idea of a Tor wifi network by default for laptops \
like the CR-48 that I'm using right now. I'd kill to have a way to Torify the \
laptop because my main concern isn't privacy from my local network, it's data \
retention from the remote hosts... :-/&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the \
best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609195755</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-09 19:57:55-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 09, 2011 at 07:50:09PM +0000, Jacob Appelbaum wrote:
&gt; &gt; Sounds like a plan. I prefer bridge by default, but we can discuss that
&gt; &gt; later.
&gt; &gt;
&gt; What's the rational there? While we certainly need more bridges, I'd like to
&gt; see an increase in relays and encourage more Friend of Friend bridge
&gt; sharing. We should include a bunch of common configs and make it easy to
&gt; setup. Also, a public relay will be much easier to help with in terms of
&gt; setup, I suspect.

Doesn't "make random people into public (middle-only) relays" have the
(well maybe not "problem", but "issue"?) that when GFW blocks them, they
(the random people who bought an Excito/etc.) won't be able to connect
to anything in .cn any more?  Although I don't _often_ connect to .cn
domains, it seems unfortunate to effectively auto-ban these people from
Chinese websites.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110609200406</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 20:04:06-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Thu, Jun 9, 2011 at 7:57 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

&gt; On Thu, Jun 09, 2011 at 07:50:09PM +0000, Jacob Appelbaum wrote:
&gt; &gt; &gt; Sounds like a plan. I prefer bridge by default, but we can discuss that
&gt; &gt; &gt; later.
&gt; &gt; &gt;
&gt; &gt; What's the rational there? While we certainly need more bridges, I'd like
&gt; to
&gt; &gt; see an increase in relays and encourage more Friend of Friend bridge
&gt; &gt; sharing. We should include a bunch of common configs and make it easy to
&gt; &gt; setup. Also, a public relay will be much easier to help with in terms of
&gt; &gt; setup, I suspect.
&gt;
&gt; Doesn't "make random people into public (middle-only) relays" have the
&gt; (well maybe not "problem", but "issue"?) that when GFW blocks them, they
&gt; (the random people who bought an Excito/etc.) won't be able to connect
&gt; to anything in .cn any more?  Although I don't _often_ connect to .cn
&gt; domains, it seems unfortunate to effectively auto-ban these people from
&gt; Chinese websites.
&gt;

Yes, it might. It depends on which part of the GFW you're connecting
through. Also, I believe the same is true for public bridge nodes as well.
The main difference is that the bridges may not be as useful as the relays
and I suspect they will also be less easy to troubleshoot
for reach-ability reasons.

In an ideal world, we'll write an enumeration of issues or benefits that
arise from the different modes of helping.

All the best,
Jake

[Attachment #5 (text/html)]

On Thu, Jun 9, 2011 at 7:57 PM, Ian Goldberg &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:iang@cs.uwaterloo.ca"&gt;iang@cs.uwaterloo.ca&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Thu, Jun 09, \
2011 at 07:50:09PM +0000, Jacob Appelbaum wrote:&lt;br&gt; &gt; &gt; Sounds like a plan. I \
prefer bridge by default, but we can discuss that&lt;br&gt; &gt; &gt; later.&lt;br&gt;
&gt; &gt;&lt;br&gt;
&gt; What's the rational there? While we certainly need more bridges, I'd \
like to&lt;br&gt; &gt; see an increase in relays and encourage more Friend of Friend \
bridge&lt;br&gt; &gt; sharing. We should include a bunch of common configs and make it easy \
to&lt;br&gt; &gt; setup. Also, a public relay will be much easier to help with in terms \
of&lt;br&gt; &gt; setup, I suspect.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Doesn't "make random people into public (middle-only) relays" \
have the&lt;br&gt; (well maybe not "problem", but "issue"?) that when \
GFW blocks them, they&lt;br&gt; (the random people who bought an Excito/etc.) won't be \
able to connect&lt;br&gt; to anything in .cn any more?  Although I don't _often_ \
connect to .cn&lt;br&gt; domains, it seems unfortunate to effectively auto-ban these people \
from&lt;br&gt; Chinese websites.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yes, it might. It \
depends on which part of the GFW you're connecting through. Also, I believe the \
same is true for public bridge nodes as well. The main difference is that the bridges \
may not be as useful as the relays and I suspect they will also be less easy to \
troubleshoot for reach-ability reasons.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In an ideal world, \
we'll write an enumeration of issues or benefits that arise from the different \
modes of helping.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609201406</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-09 20:14:06-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 9, 2011 at 8:50 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On Thu, Jun 9, 2011 at 7:34 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; On Thu, Jun 9, 2011 at 4:55 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt;&gt; wrote:
&gt;&gt; &gt; On Thu, Jun 9, 2011 at 2:57 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt;&gt; &gt; wrote:
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; On Wed, Jun 8, 2011 at 4:02 PM, Andrew Lewman &lt;andrew@torproject.org&gt;
&gt;&gt; &gt;&gt; wrote:
&gt;&gt; &gt;&gt; &gt; On Tue, 7 Jun 2011 15:36:45 -0700
&gt;&gt; &gt;&gt; &gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;&gt; &gt;&gt; &gt;
&gt;&gt; &gt;&gt; &gt;&gt; &gt; We would also need a way for users to easily change the hashed
&gt;&gt; &gt;&gt; &gt;&gt; &gt; password. I can't remember if this is a feature that is already
&gt;&gt; &gt;&gt; &gt;&gt; &gt; present in Vidalia.
&gt;&gt; &gt;&gt; &gt;&gt; Yes, we do need a way to change the password. We will also need a
&gt;&gt; &gt;&gt; &gt;&gt; way
&gt;&gt; &gt;&gt; &gt;&gt; to reset the password if the user is locked out of the control port.
&gt;&gt; &gt;&gt; &gt;&gt; I
&gt;&gt; &gt;&gt; &gt;&gt; generally think that this means we'll need a web UI... :-)
&gt;&gt; &gt;&gt; &gt;
&gt;&gt; &gt;&gt; &gt; It's built into vidalia.  Just click Advanced and you can change the
&gt;&gt; &gt;&gt; &gt; password all you want.
&gt;&gt; &gt;&gt; &gt;
&gt;&gt; &gt;&gt; &gt;&gt; I think the best thing is to make an autoconfiguring device with a
&gt;&gt; &gt;&gt; &gt;&gt; web UI; we can easily rate limit Tor to something reasonable and
&gt;&gt; &gt;&gt; &gt;&gt; make
&gt;&gt; &gt;&gt; &gt;&gt; it a middle node by default. In all cases it stands alone and simply
&gt;&gt; &gt;&gt; &gt;&gt; plugging it into a wall (power/ethernet) will provide more capacity
&gt;&gt; &gt;&gt; &gt;&gt; to the network if the OR port is reachable (ala tor-fw-helper + tor
&gt;&gt; &gt;&gt; &gt;&gt; +
&gt;&gt; &gt;&gt; &gt;&gt; init.d scripts to start Tor on boot).
&gt;&gt; &gt;&gt; &gt;
&gt;&gt; &gt;&gt; &gt; Most of me wants to wait for the freedombox people to derive their
&gt;&gt; &gt;&gt; &gt; web
&gt;&gt; &gt;&gt; &gt; interface, and then we can plug tor into it.  I realize this could be
&gt;&gt; &gt;&gt; &gt; years at the current rate of progress. If someone whips up a quick
&gt;&gt; &gt;&gt; &gt; interface that isn't a security nightmare, we could use that until
&gt;&gt; &gt;&gt; &gt; freedombox has something tangible.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Yeah, I was hoping the freedombox people would have something we could
&gt;&gt; &gt;&gt; use. Doesn't seem like it, though. I think that, at some point, we
&gt;&gt; &gt;&gt; should create a web ui for the dreamplug. But not having one right now
&gt;&gt; &gt;&gt; should not be a blocker for the dreamplug-torouter.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; Well, I'm not sure what you mean... The FB is just a Debian machine.
&gt;&gt; &gt; Pick a
&gt;&gt; &gt; web server, write a cgi and perhaps that will be the main interface? :-)
&gt;&gt; &gt; I'd
&gt;&gt; &gt; email the FBF list and ask. Perhaps the best web UI is one that is
&gt;&gt; &gt; already
&gt;&gt; &gt; written? Is the web UI for the Excito free software?
&gt;&gt;
&gt;&gt; I was hoping there would be an existing ui what we could just plug Tor
&gt;&gt; into, just like we did with the Excito B3 interface.
&gt;&gt;
&gt;
&gt; I think it's fine to ship one web interface for us now and later find a good
&gt; integration point with the Freedom Box later...

Yep, I agree.

&gt;&gt; &gt;&gt; &gt; I suggest we ship the dreamplug with cli access only for those who
&gt;&gt; &gt;&gt; &gt; want
&gt;&gt; &gt;&gt; &gt; a cheap device to be a bridge or relay.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; I guess we can set up dreamplugs as bridges by default and include a
&gt;&gt; &gt;&gt; leaflet explaining the steps to take to change the configuration. Do
&gt;&gt; &gt;&gt; you think we should touch the default setup of the dreamplug (it
&gt;&gt; &gt;&gt; serves an open wifi by default, for example)?
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; I believe that by default we should be shipping middle relays and we
&gt;&gt; &gt; should
&gt;&gt; &gt; be shipping 0.2.3.x with tor-fw-helper enabled by default as well.
&gt;&gt; &gt; I think the boxes should be re-flashed to have Debian or a modern Ubuntu
&gt;&gt; &gt; and
&gt;&gt; &gt; locked down except with Tor and OpenSSH as listening services. We also
&gt;&gt; &gt; need
&gt;&gt; &gt; things to sync time and so on.
&gt;&gt;
&gt;&gt; Sounds like a plan. I prefer bridge by default, but we can discuss that
&gt;&gt; later.
&gt;&gt;
&gt;
&gt; What's the rational there? While we certainly need more bridges, I'd like to
&gt; see an increase in relays and encourage more Friend of Friend bridge
&gt; sharing. We should include a bunch of common configs and make it easy to
&gt; setup. Also, a public relay will be much easier to help with in terms of
&gt; setup, I suspect.

Well, bridge by default is what they B3's are set up with. I also
figure that a bridge sees less traffic than a relay, and so it might
be more "friendly" for new users. But I like the idea of having a
bunch of common configs, and we can also suggest bandwidth limits.

&gt;&gt; &gt;&gt; &gt; I suggest we ship the excito with the web ui as the easy to use
&gt;&gt; &gt;&gt; &gt; option.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of the
&gt;&gt; &gt;&gt; month.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; Is it Free Software? Can we use it on the DreamPlug until we have
&gt;&gt; &gt; something
&gt;&gt; &gt; else?
&gt;&gt;
&gt;&gt; Yes, it's free software and will be available in the Excito GitHub
&gt;&gt; repository when it's released (not sure if it's there already, I don't
&gt;&gt; think so). The web interface is probably a bit too "heavy" (and
&gt;&gt; includes a good mix of php and perl) for the dreamplug, so we should
&gt;&gt; probably look for something else.
&gt;&gt;
&gt;
&gt; Can we rip out everything except the basics? If so, I think their web front
&gt; end is perfect and it already has a Tor UI thanks to you... :-)

Maaaaybe. I haven't tried, but it can't be that hard. I'll look into it.

&gt;&gt; &gt;&gt; &gt; In either case, we need to start testing, not keep thinking about
&gt;&gt; &gt;&gt; &gt; what
&gt;&gt; &gt;&gt; &gt; we could do.  We're going to get a flood of feedback from actual
&gt;&gt; &gt;&gt; &gt; people
&gt;&gt; &gt;&gt; &gt; testing the excito or dreamplug.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Valid point.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; I think we need to talk about what we need for the OS. I suspect we need
&gt;&gt; &gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files +
&gt;&gt; &gt; time
&gt;&gt; &gt; syncing (clockskew for example) + a randomly generated password that we
&gt;&gt; &gt; uniquely key for each router in some non-silly way.
&gt;&gt; &gt; Is there a trac ticket for the OS part of the Torouter?
&gt;&gt;
&gt;&gt; There is now: https://trac.torproject.org/projects/tor/ticket/3374
&gt;&gt;
&gt;&gt; We can move the discussion to #3374 if you want.
&gt;&gt;
&gt;
&gt; I'm happy to keep hammering stuff out here and the we can dump the results
&gt; into the bug report.

Works for me. It's great to get feedback that will help get me started.

&gt; What do you think about a DreamPlug with Debian or Ubuntu? Do we have a
&gt; preference?

Good question. I love Debian, but I'm sure Ubuntu would be great to
use as well. I'll do some research and see if there is a good reason
we should pick one over the other.

&gt; What other software do we need beyond ntp, ssh, tor and a web UI?

&gt; Do we want to support a transparent Tor wifi network by default?

Maybe this is something we can add later, and focus on bridge/relay
support first?

&gt; I think Ubuntu's latest release is the best in terms of security and in
&gt; theory support. It is however not as beloved as Debian for a number of solid
&gt; reasons. I think NTP, OpenSSH with key auth (and perhaps fail2ban or
&gt; something similar) and password auth, a very minimal web UI but still
&gt; functional for real Tor configuration and that's about all we'll need.

Yeah, I agree.

&gt; I also like the idea of a Tor wifi network by default for laptops like the
&gt; CR-48 that I'm using right now. I'd kill to have a way to Torify the laptop
&gt; because my main concern isn't privacy from my local network, it's data
&gt; retention from the remote hosts... :-/

I'm sure it would be useful for a number of users. I wouldn't be too
difficult to include, and maybe the web interface can have an on/off
button so that they can choose whether or not to enable the Tor wifi
network.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110609203131</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-09 20:31:31-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


&gt;
&gt; &gt; I think it's fine to ship one web interface for us now and later find a
&gt; good
&gt; &gt; integration point with the Freedom Box later...
&gt;
&gt; Yep, I agree.
&gt;
&gt;
Great. I'm sure that if the web UI is free software and it works well, we
can see if the FB will be interested in using it.


&gt; &gt; What's the rational there? While we certainly need more bridges, I'd like
&gt; to
&gt; &gt; see an increase in relays and encourage more Friend of Friend bridge
&gt; &gt; sharing. We should include a bunch of common configs and make it easy to
&gt; &gt; setup. Also, a public relay will be much easier to help with in terms of
&gt; &gt; setup, I suspect.
&gt;
&gt; Well, bridge by default is what they B3's are set up with. I also
&gt; figure that a bridge sees less traffic than a relay, and so it might
&gt; be more "friendly" for new users. But I like the idea of having a
&gt; bunch of common configs, and we can also suggest bandwidth limits.
&gt;
&gt;
Hrm. The B3 is certainly able to handle traffic. Also in both cases, we'll
want to configure them to limit bandwidth. There is no promise that a relay
or a bridge will see a certain amount of traffic if they're not configured
to hibernate/rate limit/etc.

I'd like a device that I can plug into a wall and it will automatically join
a network, probe for upnp/natpmp and become a relay. I'd also like a hidden
service so that I can connect and administrate it from anywhere in the
world; though this is clearly a nice to have and not a requirement. :-)


&gt; &gt;&gt; &gt;&gt; &gt; I suggest we ship the excito with the web ui as the easy to use
&gt; &gt;&gt; &gt;&gt; &gt; option.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of
&gt; the
&gt; &gt;&gt; &gt;&gt; month.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; Is it Free Software? Can we use it on the DreamPlug until we have
&gt; &gt;&gt; &gt; something
&gt; &gt;&gt; &gt; else?
&gt; &gt;&gt;
&gt; &gt;&gt; Yes, it's free software and will be available in the Excito GitHub
&gt; &gt;&gt; repository when it's released (not sure if it's there already, I don't
&gt; &gt;&gt; think so). The web interface is probably a bit too "heavy" (and
&gt; &gt;&gt; includes a good mix of php and perl) for the dreamplug, so we should
&gt; &gt;&gt; probably look for something else.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Can we rip out everything except the basics? If so, I think their web
&gt; front
&gt; &gt; end is perfect and it already has a Tor UI thanks to you... :-)
&gt;
&gt; Maaaaybe. I haven't tried, but it can't be that hard. I'll look into it.
&gt;
&gt;
It seems like it may be modular from what you've said and if so, I mean,
we've got the work put into the web UI already... :-)


&gt; &gt;&gt; &gt;&gt; &gt; In either case, we need to start testing, not keep thinking about
&gt; &gt;&gt; &gt;&gt; &gt; what
&gt; &gt;&gt; &gt;&gt; &gt; we could do.  We're going to get a flood of feedback from actual
&gt; &gt;&gt; &gt;&gt; &gt; people
&gt; &gt;&gt; &gt;&gt; &gt; testing the excito or dreamplug.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; Valid point.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; I think we need to talk about what we need for the OS. I suspect we
&gt; need
&gt; &gt;&gt; &gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration files +
&gt; &gt;&gt; &gt; time
&gt; &gt;&gt; &gt; syncing (clockskew for example) + a randomly generated password that
&gt; we
&gt; &gt;&gt; &gt; uniquely key for each router in some non-silly way.
&gt; &gt;&gt; &gt; Is there a trac ticket for the OS part of the Torouter?
&gt; &gt;&gt;
&gt; &gt;&gt; There is now: https://trac.torproject.org/projects/tor/ticket/3374
&gt; &gt;&gt;
&gt; &gt;&gt; We can move the discussion to #3374 if you want.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; I'm happy to keep hammering stuff out here and the we can dump the
&gt; results
&gt; &gt; into the bug report.
&gt;
&gt; Works for me. It's great to get feedback that will help get me started.
&gt;
&gt;
I plan on hacking on it with you. In theory my DreamPlug arrives next week.


&gt; &gt; What do you think about a DreamPlug with Debian or Ubuntu? Do we have a
&gt; &gt; preference?
&gt;
&gt; Good question. I love Debian, but I'm sure Ubuntu would be great to
&gt; use as well. I'll do some research and see if there is a good reason
&gt; we should pick one over the other.
&gt;
&gt;
The main reason is security and possibly support on the Ubuntu front. The
main reason for Debian is quite frankly, weasel. Without him, we'd be lost.
:-)


&gt; &gt; What other software do we need beyond ntp, ssh, tor and a web UI?
&gt;
&gt; &gt; Do we want to support a transparent Tor wifi network by default?
&gt;
&gt; Maybe this is something we can add later, and focus on bridge/relay
&gt; support first?
&gt;
&gt;
Sure, I think it's pretty much done though - I've got lots of transparent
configs, etc. If we're using Debian or Ubuntu, it's dead simple and these
boxes have enough memory to just run a second Tor for that purpose.


&gt; &gt; I think Ubuntu's latest release is the best in terms of security and in
&gt; &gt; theory support. It is however not as beloved as Debian for a number of
&gt; solid
&gt; &gt; reasons. I think NTP, OpenSSH with key auth (and perhaps fail2ban or
&gt; &gt; something similar) and password auth, a very minimal web UI but still
&gt; &gt; functional for real Tor configuration and that's about all we'll need.
&gt;
&gt; Yeah, I agree.
&gt;

Ok. Great.


&gt;
&gt; &gt; I also like the idea of a Tor wifi network by default for laptops like
&gt; the
&gt; &gt; CR-48 that I'm using right now. I'd kill to have a way to Torify the
&gt; laptop
&gt; &gt; because my main concern isn't privacy from my local network, it's data
&gt; &gt; retention from the remote hosts... :-/
&gt;
&gt; I'm sure it would be useful for a number of users. I wouldn't be too
&gt; difficult to include, and maybe the web interface can have an on/off
&gt; button so that they can choose whether or not to enable the Tor wifi
&gt; network.
&gt;
&gt;
Sure - I can see the on/off button as just bringing up and down a network
interface, basically. That network interface might also need ttdnsd/Tor's
DNSPort/dhcpd and a custom MAC adddress... Seems straight forward, am I
missing anything?

All the best,
Jake

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div&gt;&lt;div class="h5"&gt;&gt; I think \
it's fine to ship one web interface for us now and later find a good&lt;br&gt;

&gt; integration point with the Freedom Box later...&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;Yep, I agree.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Great. I'm sure that \
if the web UI is free software and it works well, we can see if the FB will be \
interested in using it.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div \
class="im"&gt;&gt; What's the rational there? While we certainly need more bridges, \
I'd like to&lt;br&gt; &gt; see an increase in relays and encourage more Friend of \
Friend bridge&lt;br&gt; &gt; sharing. We should include a bunch of common configs and make \
it easy to&lt;br&gt; &gt; setup. Also, a public relay will be much easier to help with in \
terms of&lt;br&gt; &gt; setup, I suspect.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Well, bridge by default is what they B3's are set up with. I also&lt;br&gt;
figure that a bridge sees less traffic than a relay, and so it might&lt;br&gt;
be more "friendly" for new users. But I like the idea of having a&lt;br&gt;
bunch of common configs, and we can also suggest bandwidth limits.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Hrm. The B3 is certainly \
able to handle traffic. Also in both cases, we'll want to configure them to limit \
bandwidth. There is no promise that a relay or a bridge will see a certain amount of \
traffic if they're not configured to hibernate/rate limit/etc.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'd like a device that I can plug into a wall and it will \
automatically join a network, probe for upnp/natpmp and become a relay. I'd also \
like a hidden service so that I can connect and administrate it from anywhere in the \
world; though this is clearly a nice to have and not a requirement. :-)&lt;/div&gt; &lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt;&gt; &gt;&gt; &gt; I suggest we ship \
the excito with the web ui as the easy to use&lt;br&gt; &gt;&gt; &gt;&gt; &gt; option.&lt;br&gt;
&gt;&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; &gt;&gt; Yep, the Tor web ui for the Excito B3 should be ready at the end of \
the&lt;br&gt; &gt;&gt; &gt;&gt; month.&lt;br&gt;
&gt;&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt; Is it Free Software? Can we use it on the DreamPlug until we have&lt;br&gt;
&gt;&gt; &gt; something&lt;br&gt;
&gt;&gt; &gt; else?&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Yes, it's free software and will be available in the Excito GitHub&lt;br&gt;
&gt;&gt; repository when it's released (not sure if it's there already, I \
don't&lt;br&gt; &gt;&gt; think so). The web interface is probably a bit too \
"heavy" (and&lt;br&gt; &gt;&gt; includes a good mix of php and perl) for the \
dreamplug, so we should&lt;br&gt; &gt;&gt; probably look for something else.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; Can we rip out everything except the basics? If so, I think their web front&lt;br&gt;
&gt; end is perfect and it already has a Tor UI thanks to you... :-)&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Maaaaybe. I haven't tried, but it can't be that hard. I'll look \
into it.&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It seems like \
it may be modular from what you've said and if so, I mean, we've got the work \
put into the web UI already... :-)&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div \
class="im"&gt; &gt;&gt; &gt;&gt; &gt; In either case, we need to start testing, not keep \
thinking about&lt;br&gt; &gt;&gt; &gt;&gt; &gt; what&lt;br&gt;
&gt;&gt; &gt;&gt; &gt; we could do.  We're going to get a flood of feedback from \
actual&lt;br&gt; &gt;&gt; &gt;&gt; &gt; people&lt;br&gt;
&gt;&gt; &gt;&gt; &gt; testing the excito or dreamplug.&lt;br&gt;
&gt;&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; &gt;&gt; Valid point.&lt;br&gt;
&gt;&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; &gt;&lt;br&gt;
&gt;&gt; &gt; I think we need to talk about what we need for the OS. I suspect we \
need&lt;br&gt; &gt;&gt; &gt; OpenSSH + Tor (tor-fw-helper, etc) + a few stock configuration \
files +&lt;br&gt; &gt;&gt; &gt; time&lt;br&gt;
&gt;&gt; &gt; syncing (clockskew for example) + a randomly generated password that \
we&lt;br&gt; &gt;&gt; &gt; uniquely key for each router in some non-silly way.&lt;br&gt;
&gt;&gt; &gt; Is there a trac ticket for the OS part of the Torouter?&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; There is now: &lt;a href="https://trac.torproject.org/projects/tor/ticket/3374" \
target="_blank"&gt;https://trac.torproject.org/projects/tor/ticket/3374&lt;/a&gt;&lt;br&gt; \
&gt;&gt;&lt;br&gt; &gt;&gt; We can move the discussion to #3374 if you want.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&lt;br&gt;
&gt; I'm happy to keep hammering stuff out here and the we can dump the \
results&lt;br&gt; &gt; into the bug report.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Works for me. It's great to get feedback that will help get me started.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I plan on hacking on it \
with you. In theory my DreamPlug arrives next week.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;
&gt; What do you think about a DreamPlug with Debian or Ubuntu? Do we have a&lt;br&gt;
&gt; preference?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Good question. I love Debian, but I'm sure Ubuntu would be great to&lt;br&gt;
use as well. I'll do some research and see if there is a good reason&lt;br&gt;
we should pick one over the other.&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The main reason is \
security and possibly support on the Ubuntu front. The main reason for Debian is \
quite frankly, weasel. Without him, we'd be lost. :-)&lt;/div&gt; &lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt; What other software do we need beyond \
ntp, ssh, tor and a web UI?&lt;br&gt; &lt;br&gt;
&gt; Do we want to support a transparent Tor wifi network by default?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Maybe this is something we can add later, and focus on bridge/relay&lt;br&gt;
support first?&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sure, I think it's \
pretty much done though - I've got lots of transparent configs, etc. If we're \
using Debian or Ubuntu, it's dead simple and these boxes have enough memory to \
just run a second Tor for that purpose.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt; I think Ubuntu's latest release is \
the best in terms of security and in&lt;br&gt; &gt; theory support. It is however not as \
beloved as Debian for a number of solid&lt;br&gt; &gt; reasons. I think NTP, OpenSSH with \
key auth (and perhaps fail2ban or&lt;br&gt; &gt; something similar) and password auth, a \
very minimal web UI but still&lt;br&gt; &gt; functional for real Tor configuration and \
that's about all we'll need.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Yeah, I agree.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Ok. Great.&lt;/div&gt;&lt;div&gt; \
&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;&lt;br&gt;
&gt; I also like the idea of a Tor wifi network by default for laptops like the&lt;br&gt;
&gt; CR-48 that I'm using right now. I'd kill to have a way to Torify the \
laptop&lt;br&gt; &gt; because my main concern isn't privacy from my local network, \
it's data&lt;br&gt; &gt; retention from the remote hosts... :-/&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;I'm sure it would be useful for a number of users. I wouldn't be \
too&lt;br&gt; difficult to include, and maybe the web interface can have an on/off&lt;br&gt;
button so that they can choose whether or not to enable the Tor wifi&lt;br&gt;
network.&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sure \
- I can see the on/off button as just bringing up and down a network interface, \
basically. That network interface might also need ttdnsd/Tor's DNSPort/dhcpd and \
a custom MAC adddress... Seems straight forward, am I missing anything?&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110609214710</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-06-09 21:47:10-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 06/09/2011 09:57 PM, Ian Goldberg wrote:
&gt; On Thu, Jun 09, 2011 at 07:50:09PM +0000, Jacob Appelbaum wrote:
&gt;&gt;&gt; Sounds like a plan. I prefer bridge by default, but we can discuss that
&gt;&gt;&gt; later.
&gt;&gt;&gt;
&gt;&gt; What's the rational there? While we certainly need more bridges, I'd like to
&gt;&gt; see an increase in relays and encourage more Friend of Friend bridge
&gt;&gt; sharing. We should include a bunch of common configs and make it easy to
&gt;&gt; setup. Also, a public relay will be much easier to help with in terms of
&gt;&gt; setup, I suspect.
&gt; 
&gt; Doesn't "make random people into public (middle-only) relays" have the
&gt; (well maybe not "problem", but "issue"?) that when GFW blocks them, they
&gt; (the random people who bought an Excito/etc.) won't be able to connect
&gt; to anything in .cn any more?  Although I don't _often_ connect to .cn
&gt; domains, it seems unfortunate to effectively auto-ban these people from
&gt; Chinese websites.

I did not experience any problems connecting to .cn while using a relay
IP address. I think they are just blocking an IP:port combination and
not the entire IP address.
...but things might change
-----BEGIN PGP SIGNATURE-----

iF4EAREKAAYFAk3xP14ACgkQyM26BSNOM7Zm+wEAmXNZbIQsAPhvOKTfUt9aSv4j
2SrhlQ+YagUsBDhnE3kA/2n6w8+XagJhxPXpvpX7kIxwUujp/nTa50PCZ2I7tOek
=Vz+U
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610114855</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-10 11:48:55-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 09, 2011 at 07:50:09PM +0000, jacob@appelbaum.net wrote 15K bytes in 359 lines about:
: What's the rational there? While we certainly need more bridges, I'd like to

Our funding for this project is to create more bridges to allow censored
users to access the less-censored Internet from somewhere else in the
world.  It is not to create more relays.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610115532</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-10 11:55:32-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote 2.9K bytes in 75 lines about:
: The whole point with the Torouter is to allow more people to run a
: bridge or a relay, so I see a web interface as something mandatory. So
: yeah, we'd have to make sure that the interface is secure.

Right, so we have two torouters, an expert model which is the dreamplug,
and a non-expert model which is the excito.

Experts use ssh and follow some instructions for configuring their
device.  Plus, they get some cheap hardware to do whatever else they
want to do with it.

Non-experts get the excito with the web interface: point, click,
configured, done.  

I have 10 dreamplugs with US power config arriving soon.  Once Excito
has their new version ready, we can get 10 of those.  Then we find 20
volunteers willing to test the default configs and provide feedback.  In
exchange, they get to help censored users and get free hardware.

Rather than arguing about web interfaces that do not exist, we should be
figuring out how to update the routers, make sure new tor packages are
updated timely, and how to handle support issues from the simple "it
doesn't work, at all" through "your router ate my cat and soured my
milk".

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610155438</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-10 15:54:38-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 12:55 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt; On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote 2.9K bytes in 75 lines about:
&gt; : The whole point with the Torouter is to allow more people to run a
&gt; : bridge or a relay, so I see a web interface as something mandatory. So
&gt; : yeah, we'd have to make sure that the interface is secure.
&gt;
&gt; Right, so we have two torouters, an expert model which is the dreamplug,
&gt; and a non-expert model which is the excito.
&gt;
&gt; Experts use ssh and follow some instructions for configuring their
&gt; device.  Plus, they get some cheap hardware to do whatever else they
&gt; want to do with it.

Do you think we should ship the plugs as they are, or should we
re-flash and harden first?

&gt; Non-experts get the excito with the web interface: point, click,
&gt; configured, done.
&gt;
&gt; I have 10 dreamplugs with US power config arriving soon.  Once Excito
&gt; has their new version ready, we can get 10 of those.  Then we find 20
&gt; volunteers willing to test the default configs and provide feedback.  In
&gt; exchange, they get to help censored users and get free hardware.

We should probably discuss how we want users to provide feedback and
what kind of data we'd like to see (i.e. we want more feedback than
just "yay, it works" or "it doesn't work and I'm giving up").

&gt; Rather than arguing about web interfaces that do not exist, we should be
&gt; figuring out how to update the routers, make sure new tor packages are
&gt; updated timely, and how to handle support issues from the simple "it
&gt; doesn't work, at all" through "your router ate my cat and soured my
&gt; milk".

We're going to need a web interface sooner or later, and I guess users
will also start asking about client mode and a hidden service at some
point. But we don't need all that to kick off the test phase.

How to update the routers:

- Excito: they roll out their own software updates and users can
point-and-click to update via the interface.

- DreamPlug: good question, I wonder if users would have to re-flash
with a new image.

Make sure new Tor packages are updated timely:

- Excito: we'll need to drop them an email whenever there are new
packages available so that they can update the Excito package repo.
Users can also add the torproject Debian repo to their
/etc/apt/sources.list if they don't want to wait for Excito.

- DreamPlug: default OS is Ubuntu, so I guess users will want to add
the torproject Debian repo to their /etc/apt/sources.list. Or we can
do it for them.

How to handle support issues:

We should probably set up a mailing list, such as torouter@lists... I
already have a B3 and a DreamPlug, so I should be able to reply to
most (if not all) of the support requests.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110610161400</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-10 16:14:00-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 4:54 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt; wrote:
&gt; On Fri, Jun 10, 2011 at 12:55 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt;&gt; On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote 2.9K bytes in 75 lines about:
&gt;&gt; : The whole point with the Torouter is to allow more people to run a
&gt;&gt; : bridge or a relay, so I see a web interface as something mandatory. So
&gt;&gt; : yeah, we'd have to make sure that the interface is secure.
&gt;&gt;
&gt;&gt; Right, so we have two torouters, an expert model which is the dreamplug,
&gt;&gt; and a non-expert model which is the excito.
&gt;&gt;
&gt;&gt; Experts use ssh and follow some instructions for configuring their
&gt;&gt; device.  Plus, they get some cheap hardware to do whatever else they
&gt;&gt; want to do with it.
&gt;
&gt; Do you think we should ship the plugs as they are, or should we
&gt; re-flash and harden first?

After a short discussion with Andrew on IRC, we agreed on the
following plan; re-flash with debian, harden/lock down, install tor,
test and ship.

&gt;&gt; Non-experts get the excito with the web interface: point, click,
&gt;&gt; configured, done.
&gt;&gt;
&gt;&gt; I have 10 dreamplugs with US power config arriving soon.  Once Excito
&gt;&gt; has their new version ready, we can get 10 of those.  Then we find 20
&gt;&gt; volunteers willing to test the default configs and provide feedback.  In
&gt;&gt; exchange, they get to help censored users and get free hardware.
&gt;
&gt; We should probably discuss how we want users to provide feedback and
&gt; what kind of data we'd like to see (i.e. we want more feedback than
&gt; just "yay, it works" or "it doesn't work and I'm giving up").
&gt;
&gt;&gt; Rather than arguing about web interfaces that do not exist, we should be
&gt;&gt; figuring out how to update the routers, make sure new tor packages are
&gt;&gt; updated timely, and how to handle support issues from the simple "it
&gt;&gt; doesn't work, at all" through "your router ate my cat and soured my
&gt;&gt; milk".
&gt;
&gt; We're going to need a web interface sooner or later, and I guess users
&gt; will also start asking about client mode and a hidden service at some
&gt; point. But we don't need all that to kick off the test phase.
&gt;
&gt; How to update the routers:
&gt;
&gt; - Excito: they roll out their own software updates and users can
&gt; point-and-click to update via the interface.
&gt;
&gt; - DreamPlug: good question, I wonder if users would have to re-flash
&gt; with a new image.
&gt;
&gt; Make sure new Tor packages are updated timely:
&gt;
&gt; - Excito: we'll need to drop them an email whenever there are new
&gt; packages available so that they can update the Excito package repo.
&gt; Users can also add the torproject Debian repo to their
&gt; /etc/apt/sources.list if they don't want to wait for Excito.
&gt;
&gt; - DreamPlug: default OS is Ubuntu, so I guess users will want to add
&gt; the torproject Debian repo to their /etc/apt/sources.list. Or we can
&gt; do it for them.
&gt;
&gt; How to handle support issues:
&gt;
&gt; We should probably set up a mailing list, such as torouter@lists... I
&gt; already have a B3 and a DreamPlug, so I should be able to reply to
&gt; most (if not all) of the support requests.
&gt;
&gt; --
&gt; Runa A. Sandvik
&gt;



-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110610161543</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-10 16:15:43-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Fri, Jun 10, 2011 at 3:54 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; On Fri, Jun 10, 2011 at 12:55 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt; &gt; On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote
&gt; 2.9K bytes in 75 lines about:
&gt; &gt; : The whole point with the Torouter is to allow more people to run a
&gt; &gt; : bridge or a relay, so I see a web interface as something mandatory. So
&gt; &gt; : yeah, we'd have to make sure that the interface is secure.
&gt; &gt;
&gt; &gt; Right, so we have two torouters, an expert model which is the dreamplug,
&gt; &gt; and a non-expert model which is the excito.
&gt; &gt;
&gt; &gt; Experts use ssh and follow some instructions for configuring their
&gt; &gt; device.  Plus, they get some cheap hardware to do whatever else they
&gt; &gt; want to do with it.
&gt;
&gt; Do you think we should ship the plugs as they are, or should we
&gt; re-flash and harden first?
&gt;
&gt;
I think we should re-flash with an OS that makes hardening a priority. We
should only harden the OS in the sense that we should strip out anything
that we do not require for our uses. Debian and Ubuntu both have compiler
hardening flags enabled by default but in general, I'd consider Ubuntu's
userspace to be proactively improved and their kernel ships with quite a few
security improvements. I'm not sure about the kernel status for Debian or
who is proactively working on security in Debian.

In either case, the very old version of Ubuntu on the DreamPlugs is worse
than modern Debian or modern Ubuntu; we should not ship the plugs without an
OS update at the *very* least.

I think that we should probably setup a hidden service on each one and
ensure that we can remotely administrate them with the consent of the
testers. This will help us to perhaps make some of these choices differently
down the road.

I think the user experience should be that they plug in the router, it
auto-configures the upstream firewall/NAT device if possible and that's it.
If the NAT device can't be configured, I propose we use some common ports so
that our instructions to people are basically generic and easy for everyone
to follow.

&gt; Non-experts get the excito with the web interface: point, click,
&gt; &gt; configured, done.
&gt; &gt;
&gt; &gt; I have 10 dreamplugs with US power config arriving soon.  Once Excito
&gt; &gt; has their new version ready, we can get 10 of those.  Then we find 20
&gt; &gt; volunteers willing to test the default configs and provide feedback.  In
&gt; &gt; exchange, they get to help censored users and get free hardware.
&gt;
&gt; We should probably discuss how we want users to provide feedback and
&gt; what kind of data we'd like to see (i.e. we want more feedback than
&gt; just "yay, it works" or "it doesn't work and I'm giving up").
&gt;
&gt;
I think a mailing list and an open bug report or ten is a good idea. Also, a
wiki page that explains how the devices operate from a user perspective.
This page should be different from the how-we-build-it wiki page.


&gt; &gt; Rather than arguing about web interfaces that do not exist, we should be
&gt; &gt; figuring out how to update the routers, make sure new tor packages are
&gt; &gt; updated timely, and how to handle support issues from the simple "it
&gt; &gt; doesn't work, at all" through "your router ate my cat and soured my
&gt; &gt; milk".
&gt;
&gt; We're going to need a web interface sooner or later, and I guess users
&gt; will also start asking about client mode and a hidden service at some
&gt; point. But we don't need all that to kick off the test phase.
&gt;
&gt;
Well, I think we can easily push out a wifi network that is transparently
sent via Tor and if users want that, we can provide it easily. I do not
think we should offer a remote client other than this without some security
discussions.

Again, I think we should enable OpenSSH on localhost and add a hidden
service to connect to it. This should enable us to remotely test things on a
router and see where it fails.

We don't need a web service when we launch, although I do believe it is good
to discuss the requirements.


&gt; How to update the routers:
&gt;
&gt; - Excito: they roll out their own software updates and users can
&gt; point-and-click to update via the interface.
&gt;
&gt;
They do not yet have a Tor package with tor-fw-helper, we need to make some
packages of 0.2.3.x for this to happen, I think. Perhaps weasel can tell us
of the best way to make this happen? I suspect we'll need to use a B3 device
as a build machine and we'll also need the explicitly have packages for
these devices.


&gt; - DreamPlug: good question, I wonder if users would have to re-flash
&gt; with a new image.
&gt;

The users should not do anything about re-flashing. We will have about two
dozen and we should just reflash them, it's easy.


&gt;
&gt; Make sure new Tor packages are updated timely:
&gt;
&gt; - Excito: we'll need to drop them an email whenever there are new
&gt; packages available so that they can update the Excito package repo.
&gt; Users can also add the torproject Debian repo to their
&gt; /etc/apt/sources.list if they don't want to wait for Excito.
&gt;
&gt;
I think we should ask Excito to ship with our repo or commit to pulling in
our packages for their repo. Will they do this?


&gt; - DreamPlug: default OS is Ubuntu, so I guess users will want to add
&gt; the torproject Debian repo to their /etc/apt/sources.list. Or we can
&gt; do it for them.
&gt;
&gt;
The user should not consider this a general purpose Ubuntu device, they
should consider it a Tor bridge/router device that happens to run Ubuntu or
Debian. We should configure it for them and they shouldn't have to think
about it beyond perhaps removing bandwidth limits. :-)

We should probably include apticron and automatically update packages on
these routers. I trust the Debian Q&amp;A process and I do not believe it will
result in bricked routers; anything less will result in a lot of collective
sysadmin time that none of us have and that we should not expect our users
to even comprehend unless they *want* to understand it.

How to handle support issues:
&gt;
&gt; We should probably set up a mailing list, such as torouter@lists... I
&gt; already have a B3 and a DreamPlug, so I should be able to reply to
&gt; most (if not all) of the support requests.
&gt;
&gt;
That sounds good. I will also help with this list.

All the best,
Jake

[Attachment #5 (text/html)]

&lt;div class="gmail_quote"&gt;On Fri, Jun 10, 2011 at 3:54 PM, Runa A. Sandvik &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Fri, Jun 10, 2011 at 12:55 PM,  \
&lt;&lt;a href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt; wrote:&lt;br&gt; \
&gt; On Mon, May 30, 2011 at 01:56:25PM +0100, &lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt; wrote 2.9K bytes in \
75 lines about:&lt;br&gt; &gt; : The whole point with the Torouter is to allow more people \
to run a&lt;br&gt; &gt; : bridge or a relay, so I see a web interface as something \
mandatory. So&lt;br&gt; &gt; : yeah, we'd have to make sure that the interface is \
secure.&lt;br&gt; &gt;&lt;br&gt;
&gt; Right, so we have two torouters, an expert model which is the dreamplug,&lt;br&gt;
&gt; and a non-expert model which is the excito.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Experts use ssh and follow some instructions for configuring their&lt;br&gt;
&gt; device.  Plus, they get some cheap hardware to do whatever else they&lt;br&gt;
&gt; want to do with it.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;Do you think we should ship the plugs as they are, or should we&lt;br&gt;
re-flash and harden first?&lt;br&gt;
&lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think we should re-flash \
with an OS that makes hardening a priority. We should only harden the OS in the sense \
that we should strip out anything that we do not require for our uses. Debian and \
Ubuntu both have compiler hardening flags enabled by default but in general, I'd \
consider Ubuntu's userspace to be proactively improved and their kernel ships \
with quite a few security improvements. I'm not sure about the kernel status for \
Debian or who is proactively working on security in Debian.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In either case, the very old version of Ubuntu on the DreamPlugs \
is worse than modern Debian or modern Ubuntu; we should not ship the plugs without an \
OS update at the *very* least.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt; &lt;div&gt;I think that we should \
probably setup a hidden service on each one and ensure that we can remotely \
administrate them with the consent of the testers. This will help us to perhaps make \
some of these choices differently down the road.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;div&gt;I think the \
user experience should be that they plug in the router, it auto-configures the \
upstream firewall/NAT device if possible and that's it. If the NAT device \
can't be configured, I propose we use some common ports so that our instructions \
to people are basically generic and easy for everyone to follow.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt; Non-experts \
get the excito with the web interface: point, click,&lt;br&gt; &gt; configured, done.&lt;br&gt;
&gt;&lt;br&gt;
&gt; I have 10 dreamplugs with US power config arriving soon.  Once Excito&lt;br&gt;
&gt; has their new version ready, we can get 10 of those.  Then we find 20&lt;br&gt;
&gt; volunteers willing to test the default configs and provide feedback.  In&lt;br&gt;
&gt; exchange, they get to help censored users and get free hardware.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;We should probably discuss how we want users to provide feedback and&lt;br&gt;
what kind of data we'd like to see (i.e. we want more feedback than&lt;br&gt;
just "yay, it works" or "it doesn't work and I'm giving \
up").&lt;br&gt; &lt;div class="im"&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think a \
mailing list and an open bug report or ten is a good idea. Also, a wiki page that \
explains how the devices operate from a user perspective. This page should be \
different from the how-we-build-it wiki page.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div class="im"&gt; &gt; Rather than arguing about web \
interfaces that do not exist, we should be&lt;br&gt; &gt; figuring out how to update the \
routers, make sure new tor packages are&lt;br&gt; &gt; updated timely, and how to handle \
support issues from the simple "it&lt;br&gt; &gt; doesn't work, at all" \
through "your router ate my cat and soured my&lt;br&gt; &gt; milk".&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;We're going to need a web interface sooner or later, and I guess users&lt;br&gt;
will also start asking about client mode and a hidden service at some&lt;br&gt;
point. But we don't need all that to kick off the test phase.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Well, I think we can easily push out a wifi \
network that is transparently sent via Tor and if users want that, we can provide it \
easily. I do not think we should offer a remote client other than this without some \
security discussions.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Again, I think we should enable \
OpenSSH on localhost and add a hidden service to connect to it. This should enable us \
to remotely test things on a router and see where it fails.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt; \
We don't need a web service when we launch, although I do believe it is good to \
discuss the requirements.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

How to update the routers:&lt;br&gt;
&lt;br&gt;
- Excito: they roll out their own software updates and users can&lt;br&gt;
point-and-click to update via the interface.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;They do not yet have a Tor package with \
tor-fw-helper, we need to make some packages of 0.2.3.x for this to happen, I think. \
Perhaps weasel can tell us of the best way to make this happen? I suspect we'll \
need to use a B3 device as a build machine and we'll also need the explicitly \
have packages for these devices.&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" \
                style="margin:0 0 0 .8ex;border-left:1px #ccc \
                solid;padding-left:1ex;"&gt;
- DreamPlug: good question, I wonder if users would have to re-flash&lt;br&gt;
with a new image.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The users should not do \
anything about re-flashing. We will have about two dozen and we should just reflash \
them, it's easy.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 \
0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

&lt;br&gt;
Make sure new Tor packages are updated timely:&lt;br&gt;
&lt;br&gt;
- Excito: we'll need to drop them an email whenever there are new&lt;br&gt;
packages available so that they can update the Excito package repo.&lt;br&gt;
Users can also add the torproject Debian repo to their&lt;br&gt;
/etc/apt/sources.list if they don't want to wait for Excito.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I think we should ask Excito to ship with our \
repo or commit to pulling in our packages for their repo. Will they do \
this?&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;

- DreamPlug: default OS is Ubuntu, so I guess users will want to add&lt;br&gt;
the torproject Debian repo to their /etc/apt/sources.list. Or we can&lt;br&gt;
do it for them.&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The user should not consider this a general \
purpose Ubuntu device, they should consider it a Tor bridge/router device that \
happens to run Ubuntu or Debian. We should configure it for them and they \
shouldn't have to think about it beyond perhaps removing bandwidth limits. \
:-)&lt;/div&gt; &lt;div&gt; &lt;/div&gt;&lt;div&gt;We should probably include apticron and automatically \
update packages on these routers. I trust the Debian Q&amp;A process and I do not \
believe it will result in bricked routers; anything less will result in a lot of \
collective sysadmin time that none of us have and that we should not expect our users \
to even comprehend unless they *want* to understand it.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; How to handle support issues:&lt;br&gt;
&lt;br&gt;
We should probably set up a mailing list, such as torouter@lists... I&lt;br&gt;
already have a B3 and a DreamPlug, so I should be able to reply to&lt;br&gt;
most (if not all) of the support requests.&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;&lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;That sounds good. I \
will also help with this list.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the \
best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110610161724</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-10 16:17:24-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/alternative)]


On Fri, Jun 10, 2011 at 4:14 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;wrote:

&gt; On Fri, Jun 10, 2011 at 4:54 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt; &gt; On Fri, Jun 10, 2011 at 12:55 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt; &gt;&gt; On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote
&gt; 2.9K bytes in 75 lines about:
&gt; &gt;&gt; : The whole point with the Torouter is to allow more people to run a
&gt; &gt;&gt; : bridge or a relay, so I see a web interface as something mandatory. So
&gt; &gt;&gt; : yeah, we'd have to make sure that the interface is secure.
&gt; &gt;&gt;
&gt; &gt;&gt; Right, so we have two torouters, an expert model which is the dreamplug,
&gt; &gt;&gt; and a non-expert model which is the excito.
&gt; &gt;&gt;
&gt; &gt;&gt; Experts use ssh and follow some instructions for configuring their
&gt; &gt;&gt; device.  Plus, they get some cheap hardware to do whatever else they
&gt; &gt;&gt; want to do with it.
&gt; &gt;
&gt; &gt; Do you think we should ship the plugs as they are, or should we
&gt; &gt; re-flash and harden first?
&gt;
&gt; After a short discussion with Andrew on IRC, we agreed on the
&gt; following plan; re-flash with debian, harden/lock down, install tor,
&gt; test and ship.
&gt;
&gt;
 We should automate this into a single script that will do this with any
DreamPlug. Have you currently converted any of the DreamPlug devices to
Debian? If so, what's the process and where is it documented? If not, how
shall we proceed with it? I'll have my DreamPlug next week and I'm happy to
experiment.

All the best,
Jake

[Attachment #5 (text/html)]

On Fri, Jun 10, 2011 at 4:14 PM, Runa A. Sandvik &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 \
0 .8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;On Fri, Jun 10, \
2011 at 4:54 PM, Runa A. Sandvik &lt;&lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; \
On Fri, Jun 10, 2011 at 12:55 PM,  &lt;&lt;a \
href="mailto:andrew@torproject.org"&gt;andrew@torproject.org&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt;&gt; \
On Mon, May 30, 2011 at 01:56:25PM +0100, &lt;a \
href="mailto:runa.sandvik@gmail.com"&gt;runa.sandvik@gmail.com&lt;/a&gt; wrote 2.9K bytes in \
75 lines about:&lt;br&gt; &gt;&gt; : The whole point with the Torouter is to allow more \
people to run a&lt;br&gt; &gt;&gt; : bridge or a relay, so I see a web interface as \
something mandatory. So&lt;br&gt; &gt;&gt; : yeah, we'd have to make sure that the \
interface is secure.&lt;br&gt; &gt;&gt;&lt;br&gt;
&gt;&gt; Right, so we have two torouters, an expert model which is the dreamplug,&lt;br&gt;
&gt;&gt; and a non-expert model which is the excito.&lt;br&gt;
&gt;&gt;&lt;br&gt;
&gt;&gt; Experts use ssh and follow some instructions for configuring their&lt;br&gt;
&gt;&gt; device.  Plus, they get some cheap hardware to do whatever else they&lt;br&gt;
&gt;&gt; want to do with it.&lt;br&gt;
&gt;&lt;br&gt;
&gt; Do you think we should ship the plugs as they are, or should we&lt;br&gt;
&gt; re-flash and harden first?&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;After a short discussion with Andrew on IRC, we agreed on the&lt;br&gt;
following plan; re-flash with debian, harden/lock down, install tor,&lt;br&gt;
test and ship.&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt; We \
should automate this into a single script that will do this with any DreamPlug. Have \
you currently converted any of the DreamPlug devices to Debian? If so, what's the \
process and where is it documented? If not, how shall we proceed with it? I'll \
have my DreamPlug next week and I'm happy to experiment.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;All the best,&lt;/div&gt;&lt;div&gt;Jake&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110610163233</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-06-10 16:32:33-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 5:17 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On Fri, Jun 10, 2011 at 4:14 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; On Fri, Jun 10, 2011 at 4:54 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt;&gt; wrote:
&gt;&gt; &gt; On Fri, Jun 10, 2011 at 12:55 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt;&gt; &gt;&gt; On Mon, May 30, 2011 at 01:56:25PM +0100, runa.sandvik@gmail.com wrote
&gt;&gt; &gt;&gt; 2.9K bytes in 75 lines about:
&gt;&gt; &gt;&gt; : The whole point with the Torouter is to allow more people to run a
&gt;&gt; &gt;&gt; : bridge or a relay, so I see a web interface as something mandatory.
&gt;&gt; &gt;&gt; So
&gt;&gt; &gt;&gt; : yeah, we'd have to make sure that the interface is secure.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Right, so we have two torouters, an expert model which is the
&gt;&gt; &gt;&gt; dreamplug,
&gt;&gt; &gt;&gt; and a non-expert model which is the excito.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Experts use ssh and follow some instructions for configuring their
&gt;&gt; &gt;&gt; device.  Plus, they get some cheap hardware to do whatever else they
&gt;&gt; &gt;&gt; want to do with it.
&gt;&gt; &gt;
&gt;&gt; &gt; Do you think we should ship the plugs as they are, or should we
&gt;&gt; &gt; re-flash and harden first?
&gt;&gt;
&gt;&gt; After a short discussion with Andrew on IRC, we agreed on the
&gt;&gt; following plan; re-flash with debian, harden/lock down, install tor,
&gt;&gt; test and ship.
&gt;&gt;
&gt;
&gt;  We should automate this into a single script that will do this with any
&gt; DreamPlug. Have you currently converted any of the DreamPlug devices to
&gt; Debian? If so, what's the process and where is it documented? If not, how
&gt; shall we proceed with it? I'll have my DreamPlug next week and I'm happy to
&gt; experiment.

I haven't converted my DreamPlug to Debian yet, but will try to do
this over the weekend. I'll be sure to document the process as well.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110610175712</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-10 17:57:12-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

&gt;
&gt; I haven't converted my DreamPlug to Debian yet, but will try to do
&gt; this over the weekend. I'll be sure to document the process as well.
&gt;

Ok. This seems like a good starting point:
http://blog.davideaves.com/archives/2011/03/21/installing_debian_gnulinux_6_0_1_squeeze_on_the_dreamplug/
I love the intro:

"Installing Debian GNU/Linux 6.0.1 (squeeze) on the DreamPlug."

"After about a month of waiting the DreamPlug and JTAG module that I
ordered was finally delivered. So far as a dedicated home server goes,
the specs, physical size, price and longterm energy saving made it
almost a no-brainer to purchase. However once it arrived it did not
take me very long to realize that the preinstalled Ubuntu version on
it was already obsolete and was not going to be supported. Without
fully realizing what I was doing I quickly bricked the HostOS in an
attempt to force a release update via a "do-release-upgrade" courtesy
of the update-manager-core utilities. So there I was, frustrated, with
a new brick of a system, and was forced to try to do a restore only to
find out that there was no documentation out on the Internet to
assist. I decided to document what all it took to get the DreamPlug
back up and working and to install Debian on it, so hopefully I can
save someone from all the pain and anguish I suffered while trying to
get past the learning curve it took to get the system up and
working.."

Well, I think that settles it for me! Debian!

Also:
http://code.google.com/p/dreamplug/

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110610182757</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-10 18:27:57-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 10 Jun 2011 16:15:43 +0000
Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:

&gt; I think that we should probably setup a hidden service on each one and
&gt; ensure that we can remotely administrate them with the consent of the
&gt; testers. This will help us to perhaps make some of these choices differen=
tly
&gt; down the road.

The Tor Project cannot ship a backdoored product of any kind, *ever*.
No one would ever trust *any* of our hardware or software ever again,
and rightly so.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110610191225</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-06-10 19:12:25-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 6:27 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On Fri, 10 Jun 2011 16:15:43 +0000
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt;&gt; I think that we should probably setup a hidden service on each one and
&gt;&gt; ensure that we can remotely administrate them with the consent of the
&gt;&gt; testers. This will help us to perhaps make some of these choices differently
&gt;&gt; down the road.
&gt;
&gt; The Tor Project cannot ship a backdoored product of any kind, *ever*.
&gt; No one would ever trust *any* of our hardware or software ever again,
&gt; and rightly so.
&gt;

Hi Robert,

I did not suggest a backdoor! I suggested a method of remotely helping
a limited number of (alpha testing) users debug reach-ability issues
with their consent. We've never tested tor-fw-helper in the wild and
we have never deployed something like the Torouter, we're also
discussing an alpha test deployment without any user friendly UI. It
is totally reasonable to explain that we're willing to help this
specific, special group of people out with the bumps that will appear
along the way.

Please re-read what I wrote again and try to assume good faith FFS.
Also, consider that if a user wasn't interested, we could simply not
enable it. We're talking about hand flashing a bunch of devices, we're
not talking about what we want to ship to every user on the planet
someday. It's a bad idea to just mail off a bunch of hardware and hope
for the best. We should provide some kind of support and help for the
device during the alpha testing phase of the project.

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611124519</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-11 12:45:19-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 07:12:25PM +0000, jacob@appelbaum.net wrote 1.7K bytes in 39 lines about:
: I did not suggest a backdoor! I suggested a method of remotely helping

This comes across as "it's not a backdoor, it's a highly secured front
door that only law enforcement will have access to in order to catch
criminals".   

: someday. It's a bad idea to just mail off a bunch of hardware and hope
: for the best. We should provide some kind of support and help for the
: device during the alpha testing phase of the project.

Then we shouldn't ship the hardware yet.  The hardware needs to stand on
its own, with real users, and not have a way we can remotely access
anything. 

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611130030</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-11 13:00:30-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Fri, Jun 10, 2011 at 04:15:43PM +0000, jacob@appelbaum.net wrote 15K bytes in 322 lines about:
: I think we should re-flash with an OS that makes hardening a priority. We
: should only harden the OS in the sense that we should strip out anything
: that we do not require for our uses. Debian and Ubuntu both have compiler
: hardening flags enabled by default but in general, I'd consider Ubuntu's
: userspace to be proactively improved and their kernel ships with quite a few
: security improvements. I'm not sure about the kernel status for Debian or
: who is proactively working on security in Debian.

Let's go back to the original point of the tor router.  It is to
provide a consumer-level Internet NAT/router that is a tor bridge.
This way, people have a functional Internet gateway, and also give
blocked users access to information via tor.  The target user is someone
who cannot configure tor themselves, but wants to help out with nearly
zero effort.  From what we're discussing, the excito is still that device.

We're only attracted to the dreamplug because it's cheaper.  If we're
going to ship a device that is only usable to 10 people in the world,
then we shouldn't waste our time and ship anything.  We can simply
document how to turn your dreamplug into a secure tor relay/bridge and
let those so interested do it. As it is, the dreamplug is already
difficult to use for 90% of the world because it's ssh only.  ssh and
vi only and consumer friendly generally do not go together.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611141159</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-06-11 14:11:59-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/signed)]


andrew@torproject.org wrote:

&gt; On Fri, Jun 10, 2011 at 07:12:25PM +0000, jacob@appelbaum.net wrote 1.7K bytes in 39 lines about:
&gt; : I did not suggest a backdoor! I suggested a method of remotely helping
&gt; 
&gt; This comes across as "it's not a backdoor, it's a highly secured front
&gt; door that only law enforcement will have access to in order to catch
&gt; criminals".   

I think that's stretching it quite a bit.

If the SSH access is documented, optional and is only intended be
used with the user's consent (something Jakob stated several time
already), the risk seems to be comparable to accepting binary-updates
(or only checking signatures when building from source).

Personally I think even if the optional SSH access would be available
after the alpha testing phase, the main problem would be that it
doesn't scale.

How useful it would be is another question. In a lot of situations
where the user reports that the "Torouter does not work" the SSH
access may "not work" either ...

&gt; : someday. It's a bad idea to just mail off a bunch of hardware and hope
&gt; : for the best. We should provide some kind of support and help for the
&gt; : device during the alpha testing phase of the project.
&gt; 
&gt; Then we shouldn't ship the hardware yet.  The hardware needs to stand on
&gt; its own, with real users, and not have a way we can remotely access
&gt; anything. 

Are you objecting to auto-updates, too, then?

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110611142518</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-06-11 14:25:18-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

[Attachment #2 (multipart/signed)]


Fabian Keil &lt;freebsd-listen@fabiankeil.de&gt; wrote:

&gt; andrew@torproject.org wrote:
&gt; 
&gt; &gt; On Fri, Jun 10, 2011 at 07:12:25PM +0000, jacob@appelbaum.net wrote 1.7K bytes in 39 lines about:
&gt; &gt; : I did not suggest a backdoor! I suggested a method of remotely helping
&gt; &gt; 
&gt; &gt; This comes across as "it's not a backdoor, it's a highly secured front
&gt; &gt; door that only law enforcement will have access to in order to catch
&gt; &gt; criminals".   
&gt; 
&gt; I think that's stretching it quite a bit.
&gt; 
&gt; If the SSH access is documented, optional and is only intended be
&gt; used with the user's consent (something Jakob stated several time

                                      ... Jacob ...

Sorry.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110610113012</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-06-10 11:30:12-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On 2011-Jun-10 12:08, Karsten Loesing wrote:
[..]
&gt; Here's my plan: I'd like to rename (possibly a lot of) wiki pages so
&gt; that the naming scheme implies a kind of wiki structure.  I'd also add a
&gt; page saying where stuff should go, and we'll beat up everyone not
&gt; adhering to the structure in a joint effort.

Why not use Categories? That avoids changing any URLs and also puts them
into a kind-of-structure.

I agree though, that a structure in the URL is probably better from a
visible point of view, but most folks don't look at URLs anymore anyway.

Greets,
 Jeroen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610120337</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-10 12:03:37-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On Fri, Jun 10, 2011 at 12:08:46PM +0200, karsten.loesing@gmx.net wrote 7.5K bytes in 279 lines about:
: I think the main problem is that there's no obvious structure in the
: wiki, so everyone just adds their stuff anywhere, maybe thinking that
: someone else will move it to the right place.  The other problem is that
: there's no such person cleaning up.

You're looking at the structure as created and migrated over 8 years.
Also see https://trac.torproject.org/projects/tor/ticket/1939 for
another option.  Our wiki is trying to be all things to all people, and
is clearly failing, or at least confusing everywhere. 

Trac search isn't very good.  Lots of people use
https://trac.torproject.org/projects/tor/wiki/TitleIndex to find their
way around the wiki.

Most of this is going to be a "do-acracy", he/she who does the work,
wins.  The only part to be careful with is the actual faq pages.  Those
are heavily linked from around the world.  I can pull up the view of our
trac according to google's webmaster tools if you're interested.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610135019</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-06-10 13:50:19-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On 6/10/11 2:03 PM, andrew@torproject.org wrote:
&gt; On Fri, Jun 10, 2011 at 12:08:46PM +0200, karsten.loesing@gmx.net wrote 7.5K bytes in 279 lines about:
&gt; : I think the main problem is that there's no obvious structure in the
&gt; : wiki, so everyone just adds their stuff anywhere, maybe thinking that
&gt; : someone else will move it to the right place.  The other problem is that
&gt; : there's no such person cleaning up.
&gt; 
&gt; You're looking at the structure as created and migrated over 8 years.
&gt; Also see https://trac.torproject.org/projects/tor/ticket/1939 for
&gt; another option.  Our wiki is trying to be all things to all people, and
&gt; is clearly failing, or at least confusing everywhere. 

Interesting, I hadn't seen #1939 before.  I think having a development
status page would be great.  I might even write one at some point.  But
I think having a clearer separation between the documentation part of
the wiki and the development part would be even useful when we have such
a development status page.

&gt; Trac search isn't very good.  Lots of people use
&gt; https://trac.torproject.org/projects/tor/wiki/TitleIndex to find their
&gt; way around the wiki.

Yes, that's how I find stuff, too.  Unfortunately, that approach depends
very much on meaningful URLs/wiki page names.

&gt; Most of this is going to be a "do-acracy", he/she who does the work,
&gt; wins.  The only part to be careful with is the actual faq pages.  Those
&gt; are heavily linked from around the world.

Which pages are that?  The ones starting with TheOnionRouter/ ?  And
should we put in redirects for those pages, at least for the next 6 or
12 months?

&gt; I can pull up the view of our
&gt; trac according to google's webmaster tools if you're interested.

Yes, having the Google Webmaster Tools output might be useful.  Can you
make that available somewhere?

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110610135613</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-06-10 13:56:13-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On 6/10/11 1:30 PM, Jeroen Massar wrote:
&gt; On 2011-Jun-10 12:08, Karsten Loesing wrote:
&gt; [..]
&gt;&gt; Here's my plan: I'd like to rename (possibly a lot of) wiki pages so
&gt;&gt; that the naming scheme implies a kind of wiki structure.  I'd also add a
&gt;&gt; page saying where stuff should go, and we'll beat up everyone not
&gt;&gt; adhering to the structure in a joint effort.
&gt; 
&gt; Why not use Categories? That avoids changing any URLs and also puts them
&gt; into a kind-of-structure.
&gt; 
&gt; I agree though, that a structure in the URL is probably better from a
&gt; visible point of view, but most folks don't look at URLs anymore anyway.

I guess Categories are a Trac plugin that's not installed by default,
right?  And of course I was unable to find it.  Do you have a link?

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611041326</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-11 04:13:26-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 10 Jun 2011 12:08:46 +0200
Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; By the way, what happens if we rename wiki pages?  I guess Trac will
&gt; update all internal links, but external links (e.g., from the website)
&gt; will be broken?  We could fix our own website, but other websites would
&gt; still be broken.  How bad would that be?

Do you plan to fix links in the mailing list archives as well?  How
about links in our e-mail inboxes?

Also, I would expect Trac to *not* update wiki-internal links -- it
doesn't update ticket components' when a component is renamed or
deleted.


&gt; And finally, the following pages are about using Trac and would go into
&gt; trac/ (it's possible that Trac wouldn't like us renaming some of its
&gt; pages, but I guess we'll find out):

Several parts of the Trac interface that you would be unable to modify
link to these pages.  (Most notably, there is a link to
WikiFormatting' above the Comment' entry box on every ticket.)


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110611061735</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-06-11 06:17:35-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On 6/11/11 6:13 AM, Robert Ransom wrote:
&gt; On Fri, 10 Jun 2011 12:08:46 +0200
&gt; Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; 
&gt;&gt; By the way, what happens if we rename wiki pages?  I guess Trac will
&gt;&gt; update all internal links, but external links (e.g., from the website)
&gt;&gt; will be broken?  We could fix our own website, but other websites would
&gt;&gt; still be broken.  How bad would that be?
&gt; 
&gt; Do you plan to fix links in the mailing list archives as well?  How
&gt; about links in our e-mail inboxes?

Nope.  But we could add redirects for those pages linked from the
mailing list archives and everyone's inbox.  Similar to how we added
redirects when moving from
https://wiki.torproject.org/noreply/TheOnionRouter/ to the current location.

&gt; Also, I would expect Trac to *not* update wiki-internal links -- it
&gt; doesn't update ticket components' when a component is renamed or
&gt; deleted.

I just tried it and it looks good.  So yes, Trac does update
wiki-internal links.

&gt;&gt; And finally, the following pages are about using Trac and would go into
&gt;&gt; trac/ (it's possible that Trac wouldn't like us renaming some of its
&gt;&gt; pages, but I guess we'll find out):
&gt; 
&gt; Several parts of the Trac interface that you would be unable to modify
&gt; link to these pages.  (Most notably, there is a link to
&gt; WikiFormatting' above the Comment' entry box on every ticket.)

Right, I had pages like WikiFormatting in mind when adding the comment
that Trac might not like us renaming some of its pages.  I guess we can
find out if Trac is smart enough to update these links, too.  Or we can
try using redirects for these pages, too.  If neither works, it's not
the end of the world to leave these pages where they are.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110611124103</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-06-11 12:41:03-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On Sat, Jun 11, 2011 at 08:17:35AM +0200, karsten.loesing@gmx.net wrote 2.5K bytes in 34 lines about:
: &gt; Do you plan to fix links in the mailing list archives as well?  How
: &gt; about links in our e-mail inboxes?
: 
: Nope.  But we could add redirects for those pages linked from the
: mailing list archives and everyone's inbox.  Similar to how we added
: redirects when moving from
: https://wiki.torproject.org/noreply/TheOnionRouter/ to the current location.

Why this need to preserve old links forever?  Websites change. If we
migrate from trac to something else, I'm not going back and updating
every website that ever linked to trac.  When we changed from flyspray
to trac, google, yahoo, bing, etc search engines all update their
databases of links within 3 days.  

I'm fine with not putting in any redirects.  If the new structure is
sufficiently logical, people will figure it out. torproject.org is the
largest link farm to trac, we can update that.  Attached is the linking
domains, according to google, to trac.tpo.

-- 
Andrew
pgp key: 0x74ED336B

["LinkingDomains_trac_torproject_org_20110611T122930Z.csv" (text/csv)]

Domains,Links,Linked pages
torproject.org,"514,582","3,600"
seul.org,"11,250",304
mail-archive.com,"5,119",53
hermann-uwe.de,668,3
cybermirror.org,476,46
slyck.com,321,3
spline.de,278,18
hermetix.org,236,23
szb66.net,207,23
hacktivistas.net,190,2
vidalia-project.net,171,5
wordpress.com,146,16
neoturbine.net,145,3
blogspot.com,123,16
swik.net,111,4
bitchx.com,94,57
gmane.org,86,30
infosecurity.ch,78,3
thruhere.net,68,14
flossmanuals.net,60,2
ath.cx,58,7
marc.info,56,34
amorphis.eu,52,10
hak5.org,50,3
sesawe.net,42,2
wikipedia.org,34,6
slacknews.org,31,5
swfc.edu.cn,27,4
wilderssecurity.com,27,6
soup.io,24,6
ubuntuforums.org,23,9
boum.org,23,16
ngoinabox.org,21,1
pgpru.com,19,6
facebook.com,18,13
google.com,17,10
ubuntu.com,17,9
thaijobpost.com,16,12
zendfile.com,15,13
mozilla-russia.org,15,4
mozillazine.org,14,8
chinagfw.org,13,4
eff.org,13,5
gulli.com,13,5
ubuntuusers.de,12,4
osdir.com,12,4
sesawe.org,12,2
i2p2.de,12,2
newscn.org,11,9
torproject.org.in,11,4
fscked.org,11,11
ubuntu-fr.org,10,4
noirbizarre.info,10,1
linuxquestions.org,10,6
dslreports.com,9,1
linux-bg.org,9,3
zuo.la,9,3
ubuntu-it.org,9,3
appspot.com,8,4
baldric.net,8,2
bullog.org,8,4
jugem.jp,8,2
ethr.net,8,6
livejournal.com,8,5
debian.net,8,4
globalvoicesonline.org,8,1
guiguishow.info,7,1
launchpad.net,7,6
archlinux.org,7,4
wapedia.mobi,7,4
atagar.com,7,6
walkyr.fr,7,5
sensagent.com,7,2
slashdot.org,7,4
livelyblog.com,7,2
hispasec.com,6,6
antivirusgratis.com.ar,6,6
baidu.com,6,4
ncmilitia.org,6,4
utorrent.com,6,4
rakuten.co.jp,6,3
privacydigest.com,6,2
linux.org.ru,6,2
typepad.com,6,2
kairaven.de,6,5
haygus.fr,6,4
security-forums.com,6,3
indymedia.org.uk,6,1
guardianproject.info,6,1
boingboing.net,6,4
schneier.com,6,2
tor2web.org,6,4
derkeiler.com,6,5
metafilter.com,6,3
bodhizazen.net,6,3
seclists.org,5,5
twitter.com,5,4
bitcoin.org,5,2
gentoo.org,5,5
chzv.net,5,5
wiredwings.com,5,3
mobileactive.org,5,2
cousingirls.com,5,1
nerdbynature.de,5,2
beakkon.com,5,3
dbform.com,5,1
reddit.com,5,4
pczone.com.tw,5,3
rightpaths.com,5,5
txoof.com,5,3
pub.ne.jp,5,1
forsv.com,5,1
experts123.com,5,2
kirishimaya.com,5,1
html.it,5,3
v3-labs.info,5,1
taringa.net,5,2
koolfy.be,5,1
webhosting.pl,5,2
askapache.com,5,4
openwrt.org,5,1
hostingprod.com,5,1
sina.com.cn,4,2
opera.com,4,2
98.15.0.194,4,2
naver.com,4,2
dcluo.info,4,2
xmarks.com,4,2
pff.org,4,2
akarouche.com,4,2
frishit.com,4,1
ubuntu.org.cn,4,2
opennet.ru,4,1
fusselwurm.de,4,1
38.229.0.70,4,4
archetwist.com,4,1
altervista.org,4,1
uwaterloo.ca,4,2
korykirk.com,4,4
boards.ie,4,1
vuikhoe-vn.co.cc,4,2
cnnvd.org.cn,4,4
hermesblog.co.cc,4,1
kubieziel.de,4,3
bsdforen.de,4,4
canalblog.com,4,1
excito.net,4,3
anahuac.mx,4,1
linuxreviews.org,4,2
kriptopolis.org,4,2
pentbox.net,4,1
anarchopedia.org,4,2
headstrong.de,4,3
i2p.to,4,2
cnet.com,4,4
linuxmint.com,4,3
theonionrouter.com,4,2
meneame.net,4,2
over-blog.es,4,2
myners.net,4,2
thedarkrising.com,4,1
antichat.ru,4,1
sourceforge.net,4,4
gigaom.com,4,2
luna.com.tw,4,3
4pda.ru,4,1
bsdprojects.net,4,2
ndaru.net,4,2
linuxcenter.ru,3,3
as-ansar.com,3,2
vmware.com,3,2
dator.lv,3,1
myp2pforum.eu,3,2
ossblog.it,3,1
psycosismental.co.cc,3,3
mimizun.com,3,2
peio.org,3,3
fwolf.com,3,1
torproject.tk,3,2
swerat.com,3,1
filesharefreak.com,3,1
jovenescarmelitas.com,3,1
habrahabr.ru,3,1
libellug.org,3,3
protecus.de,3,3
blogfa.com,3,1
iteye.com,3,3
beme-it.de,3,2
noblogs.org,3,3
cpunk.de,3,3
thegeniusfiles.com,3,1
kicks-ass.net,3,3
pearltrees.com,3,2
bridges4tor.org,3,3
virus.org,3,3
unfix.org,3,1
esoeslodemenos.com,3,3
ubuntu.ru,3,2
heise.de,3,2
mail.ru,3,3
xda-developers.com,3,1
ubuntu-nl.org,3,3
es.tl,3,3
wired.com,3,1
transmissionbt.com,3,2
security-portal.cz,3,2
github.com,3,3
nabble.com,3,2
lightbluetouchpaper.org,3,3
dprox.org,3,1
experts-exchange.com,3,2
kak-gde.ru,3,3
dancersblogs.com,3,3
planetpeer.de,3,2
broadbandreports.com,3,2
answers.com,3,3
ebenben.com,3,1
osvdb.org,3,3
ru-board.com,3,2
azofreeware.com,3,1
tecchannel.de,3,2
malucospc.net,3,1
dyndns.org,3,3
piratenpartei.de,3,2
linuxfr.org,3,1
belawan.co.cc,3,3
hackaday.com,3,2
zoomquiet.org,3,3
whirlpool.net.au,3,1
ubuntu.pl,3,1
privacyfoundation.ch,3,1
nihongodeok.net,3,2
sans.org,3,2
fedoraproject.org,3,2
commondork.com,3,3
mozilla.org,3,3
schaeufele.org,3,1
mozilla.com,3,1
criticalsecurity.net,3,3
dvgu.ru,3,1
cannabis-world.org,3,2
xpdm.us,3,3
proxyroller.com,3,2
luca-mercatanti.com,3,3
tehzomb.info,3,2
ubuntu.ro,3,1
clubic.com,3,2
freetz.org,2,2
consenser.org,2,1
tistory.com,2,1
postgresql.org,2,1
agusnaim.web.id,2,2
torservers.net,2,2
ynnsl.com,2,2
lwn.net,2,2
iranelection2009.com,2,2
extradisambiguator.co.uk,2,1
isnofate.com,2,1
ethanzuckerman.com,2,1
debian-administration.org,2,1
gnu.org,2,1
blogger-index.com,2,2
sapo.pt,2,1
szrocket.com,2,1
unixboard.de,2,2
informationelle-selbstbestimmung-im-internet.de,2,2
webupd8.org,2,2
i-hacked.com,2,1
forumfree.it,2,1
interessantes.at,2,2
nordrus.org,2,1
antionline.com,2,1
bit-tech.nl,2,1
bitcoin.it,2,1
chicchedicala.it,2,1
polippix.dk,2,2
das-labor.org,2,1
computerbase.de,2,2
hostzi.com,2,1
traficantes.net,2,2
macgeneration.com,2,1
stackoverflow.com,2,2
dee.su,2,2
essential-freebies.de,2,2
omgili.com,2,1
privacyfoundation.de,2,2
emacswiki.org,2,2
hatena.ne.jp,2,2
kunxi.org,2,1
networksteve.com,2,2
rikers.org,2,2
betanews.com,2,1
isep.fr,2,2
kometo.com,2,1
netsons.org,2,1
wn.com,2,1
gabrielweinberg.com,2,2
sixxs.net,2,2
nazioneindiana.com,2,1
anarcrypt.net,2,1
tacticaltech.org,2,1
holablogs.com,2,1
hwupgrade.it,2,2
oignon.net,2,1
pcformat.pl,2,1
portablefreeware.com,2,2
wintricks.it,2,2
segu-info.com.ar,2,1
163.com,2,2
c3llgeek.com,2,1
tfode.com,2,1
sinbloqueo.com,2,2
computacao-em-acao.com,2,2
gentoo-wiki.info,2,2
foebud.org,2,2
recurity-labs.com,2,1
kaspersky.com,2,1
mandrakeitalia.org,2,1
cl.o.se,2,2
punbb-hosting.com,2,2
martini.nu,2,2
over-blog.com,2,1
leonardocastillo.com,2,2
winboard.org,2,2
entartete-kunst.com,2,1
alheka.com,2,1
utfs.org,2,2
folin.nu,2,2
suseitalia.org,2,1
gda.pl,2,2
xchat.org,2,1
unex.es,2,1
kryptera.eu,2,1
cyberarmy.at,2,2
koumbit.net,2,2
desktop2ch.jp,2,1
e-limbo.org,2,2
mykunci.com,2,2
terminal23.net,2,1
bplaced.net,2,2
outpostfirewall.com,2,1
piratbyran.org,2,2
advosys.ca,2,1
23j.de,2,2
debianizzati.org,2,2
w3cool.com,2,2
ccc.de,2,2
securityfocus.com,2,1
mozdev.org,2,2
halo.gen.nz,2,2
kryptera.se,2,1
ip-phone-forum.de,2,2
qxbbs.org,2,1
framasoft.net,2,2
chaostreff.ch,2,2
ismokpats.lt,2,2
camp-firefox.de,2,1
invisionfree.com,2,2
tor-proxy.net,2,1
linux.com,2,1
opendns.com,2,1
macbidouille.com,2,1
forospyware.com,2,2
0x61.com,2,2
springerlink.com,2,2
worldlingo.com,2,1
netzpolitik.org,2,2
mepis.org,2,1
pcworld.pl,2,1
lulu.com,2,2
hekko.pl,2,2
techmonkey.de,2,1
ylmf.net,2,1
virginia.edu,2,2
twitbrowser.net,2,1
hackerboard.de,2,1
plsearch.com,2,2
roothausen.de,2,1
libertarianizm.net,2,2
ubuntu-rs.org,2,2
jedenbod.cz,2,1
intern0t.net,2,1
3dgames.com.ar,2,1
ibiblio.org,2,1
hep-cat.de,2,1
chip.de,2,2
techliberation.com,2,2
grasscity.com,2,1
prxbx.com,2,1
pidgin.im,2,2
debian.org,2,2
wiredvision.jp,2,1
scientist.pl,2,1
hackerjournal.it,2,1
hackbloc.org,2,1
stanford.edu,2,2
bogushome.net,2,2
arstechnica.com,2,1
zataz.com,2,1
tumblr.com,2,2
hishamrana.com,2,1
xpheas.com,2,1
webwereld.nl,2,2
servinghistory.com,2,1
baywords.com,2,1
synapseninferno.org,2,1
mihanblog.com,2,1
mandriva.org.pl,2,1
whyweprotest.net,2,2
unkar.org,2,1
all.de,2,2
harvard.edu,2,2
comodo.com,2,1
wikibooks.org,2,2
glitcheaven.com,2,2
samthammel.de,2,1
igfw.tk,2,2
linuzeros.org,2,1
rebellyon.info,2,2
multiply.com,2,1
yasni.de,2,1
superuser.com,2,2
hackers.mu,2,2
ins0mnia.net,1,1
penguins-underground.net,1,1
todoappleblog.com,1,1
magazeta.com,1,1
hilpers.pl,1,1
apfeltalk.de,1,1
squidoo.com,1,1
iang.org,1,1
bytes.com,1,1
indirbak.com,1,1
chomikuj.pl,1,1
techenclave.com,1,1
silc.org.ua,1,1
webgenomeproject.org,1,1
psicofxp.com,1,1
admuncher.com,1,1
woditsch.net,1,1
quantenblog.net,1,1
blogs.com,1,1
itmedia.co.jp,1,1
techwire.in,1,1
homelandstupidity.us,1,1
visualbeta.es,1,1
stormfront.org,1,1
eeeuser.com,1,1
stackexchange.com,1,1
decisionstats.com,1,1
wer-weiss-was.de,1,1
pokazywarka.pl,1,1
420spjall.net,1,1
die.net,1,1
givv.org,1,1
encrypted.cc,1,1
copytaste.com,1,1
uusisuomi.fi,1,1
franceschelli.eu,1,1
true-random.com,1,1
grepular.com,1,1
83.141.0.4,1,1
whatthetech.com,1,1
pcfreunde.de,1,1
archives-ouvertes.fr,1,1
twit88.com,1,1
pc-facile.com,1,1
pclab.pl,1,1
freenode.net,1,1
ilune.fr,1,1
spyworld-actu.com,1,1
pestilenz.org,1,1
defcon5.biz,1,1
slax.org,1,1
ls-themes.org,1,1
lurkmore.ru,1,1
backtrack-fr.net,1,1
chinadigitaltimes.net,1,1
princeton.edu,1,1
hugopoi.net,1,1
computertotaal.nl,1,1
4pda.ws,1,1
hr-cjpc.si,1,1
uckanleitungen.de,1,1
scriptlance.com,1,1
unsyncopated.com,1,1
webplanet.ru,1,1
onestyle.com.ua,1,1
servehttp.com,1,1
technologizer.com,1,1
eviltux.de,1,1
landinux.org,1,1
nuovaresistenza.org,1,1
indymedia.org.au,1,1
shroomery.org,1,1
pro-linux.de,1,1
anontalk.se,1,1
nwomedia.pl,1,1
security.nl,1,1
abtechno.org,1,1
justlinux.com,1,1
gozareforum.com,1,1
vbodns.com,1,1
hachisvertas.net,1,1
sysphere.org,1,1
abforum.be,1,1
hamsterpaj.net,1,1
douban.com,1,1
wikimedia.org,1,1
ywp2p.com,1,1
libertarianactivism.com,1,1
blino.org,1,1
fabiankeil.de,1,1
ubuntu-fi.org,1,1
augix.com,1,1
hackcollege.com,1,1
proxomitron.ru,1,1
chambana.net,1,1
perfect-privacy.com,1,1
guzik.net.pl,1,1
matrixlist.com,1,1
geowab.net,1,1
trykker.com,1,1
is-a-geek.net,1,1
pseudo-flaw.net,1,1
vorratsdatenspeicherung.de,1,1
nas78.net,1,1
zotero.org,1,1
meroguff.com,1,1
guru3d.com,1,1
linuxsir.org,1,1
netoearth.com,1,1
cypherpunks.ca,1,1
rolffreitag.de,1,1
quest.lv,1,1
meetingsnet.com,1,1
fengbin.net,1,1
duckduckgo.com,1,1
digsby.com,1,1
lanik.us,1,1
emule-project.net,1,1
wikihow.com,1,1
ubuntu-tutorials.com,1,1
fizwig.com,1,1
fossplanet.com,1,1
geeksjoy.com,1,1
symlink.ch,1,1
privoxy.org,1,1
zoklet.net,1,1
icarsupplynation.info,1,1
bigblueball.com,1,1
suggestafix.com,1,1
fixunix.com,1,1
zdnet.com,1,1
iugrina.com,1,1
freak-search.com,1,1
valhalla.fr,1,1
unforgivingminute.com,1,1
tuxfamily.org,1,1
salon.com,1,1
requestpolicy.com,1,1
narodni-bolsevik.org,1,1
pastoutafait.org,1,1
squat.net,1,1
flashdance.cx,1,1
itech.web.id,1,1
jabe.ru,1,1
kapitalizm.org,1,1
jpautopartville.info,1,1
programmingforums.org,1,1
tahribat.com,1,1
headlinestodaynews.com,1,1
networkworld.com,1,1
web2.in.th,1,1
filepie.us,1,1
chakradeo.net,1,1
webhost.ru,1,1
rstack.org,1,1
0009.org,1,1
symbianize.com,1,1
lowendtalk.com,1,1
chengduliving.com,1,1
space-ip.ru,1,1
sensiseeds.com,1,1
daemonforums.org,1,1
battlecn.net,1,1
msfn.org,1,1
googlecode.com,1,1
tu-darmstadt.de,1,1
salafsoft.com,1,1
bluetouff.com,1,1
ericamos.com,1,1
netbsd.org,1,1
vuze.com,1,1
apocryph.org,1,1
emilsit.net,1,1
predeina-zaural.ru,1,1
50webs.com,1,1
sans.edu,1,1
bandaancha.eu,1,1
open-slx.de,1,1
zuola.com,1,1
gearhack.com,1,1
iranchannel.org,1,1
meisterkuehler.de,1,1
rohitab.com,1,1
zebroblog.com,1,1
jppf.org,1,1
ftots.com,1,1
suseforum.de,1,1
hxsdblog.com,1,1
asent.com,1,1
linux.se,1,1
sinfocol.org,1,1
ilsoftware.it,1,1
ssi.gouv.fr,1,1
paulstamatiou.com,1,1
amazonaws.com,1,1
aldeid.com,1,1
neurot1k.com,1,1
pixielive.org,1,1
eof.cl,1,1
kire.ch,1,1
thefiringline.com,1,1
all-internet-security.com,1,1
blogwind.com,1,1
uni-regensburg.de,1,1
lexort.com,1,1
toypark.in,1,1
forumtopics.com,1,1
genussmaenner.de,1,1
howtobypassinternetcensorship.org,1,1
erodov.com,1,1
kevin-peter.de,1,1
110mb.com,1,1
lewrockwell.com,1,1
openmeshproject.org,1,1
rednetjob.net,1,1
pcforum.hu,1,1
archlinux.it,1,1
debian-linux.fr,1,1
forumcommunity.net,1,1
rus-linux.net,1,1
salon24.pl,1,1
eduardogonzalezloumiet.com,1,1
nadgryzione.pl,1,1
somethingawful.com,1,1
umn.edu,1,1
2ch.net,1,1
christoph-probst.com,1,1
neilesquibel.com,1,1
hackpedia.info,1,1
horrendum.de,1,1
emcu.it,1,1
indipedia.it,1,1
takku.net,1,1
clemson.edu,1,1
funtener.org,1,1
metagames-eu.com,1,1
byethost15.com,1,1
blazingangles.net,1,1
h75.de,1,1
distrowatch.com,1,1
browserwire.com,1,1
seesaa.net,1,1
h-online.com,1,1
jetbrains.net,1,1
mediauser.de,1,1
piriform.com,1,1
kurtkraut.net,1,1
fedoraunity.org,1,1
over-blog.net,1,1
91bjb.com,1,1
goo.ne.jp,1,1
ghisler.ch,1,1
eioba.pl,1,1
mozillaitalia.org,1,1
linuxac.org,1,1
siamanswer.com,1,1
myre.org,1,1
suicidegirls.com,1,1
blackhatworld.com,1,1
funus.net,1,1
newdigest.com,1,1
getsatisfaction.com,1,1
maemo.org,1,1
789chan.org,1,1
perlmonks.org,1,1
parallaxed.net,1,1
openrce.org,1,1
webanhalter.de,1,1
goblocksite.com,1,1
shizhao.org,1,1
linux-club.de,1,1
cprogramming.com,1,1
techrepublic.com,1,1
atomicmpc.com.au,1,1
pclinuxos.com,1,1
paper.li,1,1
bgu.ac.il,1,1
qjcm.com,1,1
randomoid.com,1,1
anti-state.com,1,1
carahackfacebook.com,1,1
bodylens.com,1,1
encrypt-the-planet.com,1,1
bloguje.cz,1,1
root.cz,1,1
blox.pl,1,1
tomyn.com,1,1
facepunch.com,1,1
supportnet.de,1,1
yangzh.net,1,1
fxp.co.il,1,1
yobi.be,1,1
anonymous-proxy-servers.net,1,1
latentexistence.me.uk,1,1
runpaint.org,1,1
jogger.pl,1,1
sdcv.pl,1,1
freedomradar.com,1,1
pbworks.com,1,1
usenix.org,1,1
pep.com.cn,1,1
school-survival.net,1,1
freelists.org,1,1
streamreader.org,1,1
kenapa-ada.co.cc,1,1
net16.net,1,1
fedora.pl,1,1
christianschenk.org,1,1
itwadi.com,1,1
oppserver.net,1,1
zonanostra.it,1,1
myblog.it,1,1
mcmaster.ca,1,1
silicon-safari.net,1,1
cfanclub.net,1,1
barrapunto.com,1,1
theregister.co.uk,1,1
pcnews.ru,1,1
wechsel-zu-linux.de,1,1
f0x.ru,1,1
s3cure.gr,1,1
sysd.org,1,1
ask.com,1,1
hampedia.org,1,1
smoile.com,1,1
cybernetnews.com,1,1
webalice.it,1,1
uberreview.com,1,1
xaixoui.com,1,1
ripway.com,1,1
midiblogs.com,1,1
tec-search.net,1,1
emuleitalia.net,1,1
free.fr,1,1
contribs.org,1,1
freesoft-board.to,1,1
dyc.edu,1,1
oreilly.com,1,1
nerdfabrik.de,1,1
supersized.org,1,1
stakhov.ru,1,1
selfsolved.com,1,1
anonymous-p2p.org,1,1
mloovi.com,1,1
wirelessanten.com,1,1
geekotic.com,1,1
noncombatant.org,1,1
codeidol.com,1,1
wu.cz,1,1
hackforums.net,1,1
vsure.org,1,1
lm7.fr,1,1
rechtenforum.nl,1,1
softpedia.com,1,1
aizatto.com,1,1
infoshop.org,1,1
elhacker.net,1,1
usf.edu,1,1
nawaat.org,1,1
tor4iran.net,1,1
microsoft.com,1,1
mrwhat.is,1,1
mixminion.net,1,1
jamasp.ir,1,1
hce.edu.vn,1,1
gionn.net,1,1
anticopyright.ru,1,1
patriarchia.info,1,1
supersaid.net,1,1
read2ch.com,1,1
freeno.de,1,1
powers.cl,1,1
ugr.es,1,1
blogosfere.it,1,1
msdn.com,1,1
cronopios.org,1,1
idg.se,1,1
gazeta.pl,1,1
mauriziodimatteo.it,1,1
cmu.edu,1,1
dupnica.net,1,1
computerdefense.org,1,1
44342.com,1,1
jabber.ru,1,1
unidownload.com,1,1
manualissimo.it,1,1
opensourceproject.org.cn,1,1
hardware.com.br,1,1
haker.com.pl,1,1
5gme.com,1,1
sg.hu,1,1
nana10.co.il,1,1
netzwelt.de,1,1
erikcrane.com,1,1
gamesbrasil.com.br,1,1
rlcarpartsdepot.info,1,1
hostmatrix.org,1,1
seltzer.org,1,1
boincatpoland.org,1,1
macuser.de,1,1
studeorama.de,1,1
gutocarvalho.net,1,1
fraggod.net,1,1
samibengharbia.com,1,1
autosaleinsider.info,1,1
daviddarts.com,1,1
whitton.me,1,1
zeropaid.com,1,1
ubuntu-es.org,1,1
inboxrevenge.com,1,1
jetcityorange.com,1,1
ukfindit.com,1,1
unix-revolution.info,1,1
asymo.net,1,1
vgroupnetwork.com,1,1
wsnow.info,1,1
raidrush.ws,1,1
freeyourphone.de,1,1
yahoo.com,1,1
freebsd.org,1,1
commentcamarche.net,1,1
icarcareinsiders.info,1,1
tweakers.net,1,1
kamagurka.org,1,1
rokop-security.de,1,1
sciax2.it,1,1
secumania.org,1,1
vagla.pl,1,1
c0t0d0s0.org,1,1
downloadxmp3.com,1,1
kabbage.de,1,1
treein.com,1,1
macshadows.com,1,1
hiceshice.de,1,1
mldonkey.org,1,1
makeuseof.com,1,1
bobopo.com,1,1
62live.ru,1,1
messageinabox-mm.org,1,1
links.org,1,1
lullar.com,1,1
livingstonbuzz.com,1,1
ecologielibidinale.org,1,1
nautile.nc,1,1
atareao.es,1,1
sumans.net,1,1
citizen428.net,1,1
kaman.lt,1,1
enigmagroup.org,1,1
serverfault.com,1,1
sciagnij.pl,1,1
iwantabro.com,1,1
udn.com,1,1
xbmc.org,1,1
berlios.de,1,1
ubuntuclub.com,1,1
bugtraq.ru,1,1
pixnet.net,1,1
bajery.pl,1,1
nordrus.info,1,1
afterdawn.com,1,1
ycombinator.com,1,1
freak.no,1,1
nixser.com,1,1
freenode.us,1,1
linuxspace.org,1,1
vaidigital.com.br,1,1
anonymator.cc,1,1
christopherkullenberg.se,1,1
nack.ch,1,1
byethost13.com,1,1
united-forum.de,1,1
numerama.com,1,1
fanqiangsesawe.info,1,1
openbuddha.com,1,1
bitflop.com,1,1
mydealz.de,1,1
jenkinslaw.org,1,1
ethersex.de,1,1
123people.de,1,1
huffingtonpost.com,1,1
torserver.ch,1,1
ludwig.im,1,1
uni-hamburg.de,1,1
gaetan-grigis.eu,1,1
jeuxvideo.com,1,1
usenetexplorer.com,1,1
secuobs.com,1,1
seattleweekly.com,1,1
talk4her.com,1,1
ump2002.net,1,1
debianadmin.com,1,1
extrastrony.info,1,1
hwmania.org,1,1
owca.info,1,1
pokerai.org,1,1
anho.org,1,1
net-und-web.de,1,1
toile-libre.org,1,1
mises.org,1,1
legalhighguides.com,1,1


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110602060049</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-06-02 06:00:49-0400</timestampReceived><subject>Re: [tor-dev] [Patch] common/procmon.c</subject><body>

[Attachment #2 (multipart/signed)]


On Tue, 31 May 2011 23:12:09 +0200
Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:

&gt; I've been staring at this file for some time trying to find the elusive
&gt; compile-error (MingW-gcc v4.50) on Win_XP). The bug was a missing 
&gt; comma (!) and a typo ('err_msg' at line 277 changed to 'err_msg').
&gt; 
&gt; I've also changed the format for 'err_code' at line 293 into a "%ld" to suppress
&gt; a warning. How did this go unnoticed for ~1 month?

The short answer to that is that it is a PITA to compile Tor on
Windows, and the process starts with installing an unsigned binary
package that automatically downloads several other unsigned binary
packages.  I (the person that wrote that broken code) didn't have a
compilation environment set up to build Tor for Windows, and didn't
want to use the instructions I was given to set one up.  Sorry about
the bug, and thanks for finding and fixing it!

I'm setting up a cross-compiler now, and I'll compile OpenSSL and
libevent for Windows Real Soon Now, so this shouldn't happen again.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110608221037</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-08 22:10:37-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Optimistic Data for Tor: Client Side</subject><body>

On Wed, Jun 08, 2011 at 05:51:41PM -0400, Nick Mathewson wrote:
&gt; &gt;&gt; I'm a little worried about the robustness issue: currently, if an exit
&gt; &gt;&gt; node refuses a BEGIN request (because of its exit policy typically)
&gt; &gt;&gt; the Tor client will retry at another exit node.  But if optimistic
&gt; &gt;&gt; data is in use, it seems that the client's initial data will be lost,
&gt; &gt;&gt; unless the client keeps a copy around to send to other exits as
&gt; &gt;&gt; required.
&gt; &gt;
&gt; &gt; That's a good point.  Perhaps the latter is the right thing to do?  That
&gt; &gt; would be sort of a combination of what we do now and the above proposal:
&gt; &gt; buffer the data (as we do now), but also send it (as the proposal).
&gt; &gt; When you eventually receive the CONNECTED, flush anything in the buffer
&gt; &gt; you've already sent.  If you eventually receive END instead of
&gt; &gt; CONNECTED, try another circuit, using the buffered data?
&gt; 
&gt; Maybe!  It seems plausible to me, though we should definitely ponder
&gt; the security/performance implications.

Indeed.  They don't seem bad at first glance, at least.

&gt; All I'm saying here, though, is that I'm wondering how hard the change
&gt; will be to actually make.  Most socks client code tends to get
&gt; isolated in an application's network layer as a replacement for
&gt; "connect", so unless the application is already set up to do "connect,
&gt; send send send" rather than "connect, wait for connect, send send
&gt; send", the application modifications will be tricky.

Right.  So it turns out this is a case where using an HTTP proxy makes
things easier.  Hasn't some Tor person been fiddling with Firefox code?
Maybe even Firefox SOCKS code?

&gt; As an alternative, the socks proxy (Tor) could be told to say
&gt; "connected" immediately, so that the app starts sending. I don't know
&gt; how badly this would break browsers, though.  Probably not a good
&gt; idea.

You also lose the ability to tell the SOCKS client if the connection
ended up failing.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110611141957</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-06-11 14:19:57-0400</timestampReceived><subject>Re: [tor-dev] Too many cooks spoil the broth---or: how about we</subject><body>

On 6/11/11 2:41 PM, andrew@torproject.org wrote:
&gt; On Sat, Jun 11, 2011 at 08:17:35AM +0200, karsten.loesing@gmx.net wrote 2.5K bytes in 34 lines about:
&gt; : &gt; Do you plan to fix links in the mailing list archives as well?  How
&gt; : &gt; about links in our e-mail inboxes?
&gt; : 
&gt; : Nope.  But we could add redirects for those pages linked from the
&gt; : mailing list archives and everyone's inbox.  Similar to how we added
&gt; : redirects when moving from
&gt; : https://wiki.torproject.org/noreply/TheOnionRouter/ to the current location.
&gt; 
&gt; Why this need to preserve old links forever?  Websites change. If we
&gt; migrate from trac to something else, I'm not going back and updating
&gt; every website that ever linked to trac.  When we changed from flyspray
&gt; to trac, google, yahoo, bing, etc search engines all update their
&gt; databases of links within 3 days.

Okay, I don't feel strongly about this.  I think if we can add redirects
easily we should do that.

&gt; I'm fine with not putting in any redirects.  If the new structure is
&gt; sufficiently logical, people will figure it out. torproject.org is the
&gt; largest link farm to trac, we can update that.  Attached is the linking
&gt; domains, according to google, to trac.tpo.

Great!  Thanks for the info!

Alright.  I think there's no way to make everybody happy.  But I believe
the lesser pain is to have a better wiki structure than we have right now.

I'm going to start moving around stuff soon.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611160222</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-11 16:02:22-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Thu, Jun 09, 2011 at 11:47:10PM +0200, tagnaq wrote:
&gt; &gt; Doesn't "make random people into public (middle-only) relays" have the
&gt; &gt; (well maybe not "problem", but "issue"?) that when GFW blocks them, they
&gt; &gt; (the random people who bought an Excito/etc.) won't be able to connect
&gt; &gt; to anything in .cn any more?  Although I don't _often_ connect to .cn
&gt; &gt; domains, it seems unfortunate to effectively auto-ban these people from
&gt; &gt; Chinese websites.
&gt; 
&gt; I did not experience any problems connecting to .cn while using a relay
&gt; IP address. I think they are just blocking an IP:port combination and
&gt; not the entire IP address.
&gt; ...but things might change

Hmm.  I wonder what happens if the packets are fragmented so that the
TCP port information isn't in the first fragment...

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110611222739</emailId><senderName>Dave</senderName><senderEmail>protocolgeek@verizon.net</senderEmail><timestampReceived>2011-06-11 22:27:39-0400</timestampReceived><subject>Re: [tor-dev] Will people running a relay be blocked from accessing</subject><body>


If you want to confirm whether a UDP or TCP port (or range of ports) is being 
blocked or not, try http://www.firebind.com

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110612174418</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-06-12 17:44:18-0400</timestampReceived><subject>Re: [tor-dev] Python TorCtl development questions</subject><body>

&gt;  The one feature I really, really miss from Tork is the Tor Console...

Gotcha. Arm provides similar information (application connections,
your circuits, and much more via detail dialogs):
http://www.atagar.com/transfer/tmp/connPanelWithCircuits.png

and the gui will be providing this information in a nice way like Tork
(country flags, status indicators, etc). One thing that Tork has that
I'm surprised by is the application connection to circuit mappings...
I should look into how he does that.

Kamran: Have you looked at Tork yet for ideas on the gui? It's a lot
different from Vidalia, providing different information in a very
graceful way. I'd highly suggest it if you haven't yet.

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110614120609</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-06-14 12:06:09-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 10:31:47AM -0400, Paul Syverson wrote:
&gt; Ian tells me that he has another paper dealing with these further
&gt; issues as well, which he will check into being able to make available
&gt; in tech report. So maybe there will be a further discussion and
&gt; proposal on those issues.

It just got approved at eprint.

http://eprint.iacr.org/2011/308

Thanks,

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110615115438</emailId><senderName></senderName><senderEmail>"another_base_name2001-debase</senderEmail><timestampReceived>2011-06-15 11:54:38-0400</timestampReceived><subject>Re: [tor-dev] Thoughts on simplified packaging</subject><body>

[Attachment #2 (multipart/alternative)]


There is...

BlackBelt Privacy.
https://sourceforge.net/projects/blackbeltpriv/
Its a one click install package with sensible defaults. Its unofficial, 
with some people warning against using it and others embracing it.

Advanced Onion Router
https://sourceforge.net/projects/advtor/
A zip file that provides an easy to use interface to Tor, I admit this 
is akin to Vidalia. Vidalia may be more elegant.

Ian Goldberg wrote:
&gt; On Wed, Jun 15, 2011 at 02:05:44AM -0400, grarpamp wrote:
&gt;   
&gt;&gt; On workload and stuff...
&gt;&gt;
&gt;&gt;     
&gt;&gt;&gt; the idea we had at the 2010 Potsdam meeting where we had primary
&gt;&gt;&gt; and secondary developers for each product.
&gt;&gt;&gt;       
&gt;&gt; There is Tor core (ported to various platforms). This is code and
&gt;&gt; docs. This is what matters. It is not config or packaging.
&gt;&gt;
&gt;&gt; Above and beyond that, if there is a demand for it, why not introduce
&gt;&gt; a secondary level of suitably trusted enthusiasts to develop and
&gt;&gt; manage all the various modes of operation. Officially disclaim it
&gt;&gt; appropriately as an unofficial vaporware framework, wikify it, put
&gt;&gt; a couple public developer packaging boxes online and see what
&gt;&gt; happens.
&gt;&gt;
&gt;&gt; Also, you could easily publish just a set of torrc's tailored to
&gt;&gt; various purposes. Or even create an online config generator with
&gt;&gt; various feature checkboxes.
&gt;&gt;     
&gt;
&gt; I don't think most of the target audience knows (or wants to know) what
&gt; a torrc is.  They want one-click download, install, and run.  And that's
&gt; what we should give them.
&gt;
&gt;   
&gt;&gt; I've no objection to flag days that result in good long term gains.
&gt;&gt;     
&gt;
&gt; Well, Flag Day was yesterday, so you've got a whole year to figure out
&gt; the plan for next time.  ;-)
&gt;
&gt;    - Ian
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;   


[Attachment #5 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
There is...&lt;br&gt;
&lt;br&gt;
BlackBelt Privacy.&lt;br&gt;
&lt;a class="moz-txt-link-freetext" \
href="https://sourceforge.net/projects/blackbeltpriv/"&gt;https://sourceforge.net/projects/blackbeltpriv/&lt;/a&gt;&lt;br&gt;
 Its a one click install package with sensible defaults. Its unofficial,
with some people warning against using it and others embracing it.&lt;br&gt;
&lt;br&gt;
Advanced Onion Router&lt;br&gt;
&lt;a class="moz-txt-link-freetext" \
href="https://sourceforge.net/projects/advtor/"&gt;https://sourceforge.net/projects/advtor/&lt;/a&gt;&lt;br&gt;
 A zip file that provides an easy to use interface to Tor, I admit this
is akin to Vidalia. Vidalia may be more elegant.&lt;br&gt;
&lt;br&gt;
Ian Goldberg wrote:
&lt;blockquote cite="mid:20110615111653.GC2072@yoink.cs.uwaterloo.ca"
 type="cite"&gt;
  &lt;pre wrap=""&gt;On Wed, Jun 15, 2011 at 02:05:44AM -0400, grarpamp wrote:
  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;On workload and stuff...

    &lt;/pre&gt;
    &lt;blockquote type="cite"&gt;
      &lt;pre wrap=""&gt;the idea we had at the 2010 Potsdam meeting where we had primary
and secondary developers for each product.
      &lt;/pre&gt;
    &lt;/blockquote&gt;
    &lt;pre wrap=""&gt;There is Tor core (ported to various platforms). This is code and
docs. This is what matters. It is not config or packaging.

Above and beyond that, if there is a demand for it, why not introduce
a secondary level of suitably trusted enthusiasts to develop and
manage all the various modes of operation. Officially disclaim it
appropriately as an unofficial vaporware framework, wikify it, put
a couple public developer packaging boxes online and see what
happens.

Also, you could easily publish just a set of torrc's tailored to
various purposes. Or even create an online config generator with
various feature checkboxes.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
I don't think most of the target audience knows (or wants to know) what
a torrc is.  They want one-click download, install, and run.  And that's
what we should give them.

  &lt;/pre&gt;
  &lt;blockquote type="cite"&gt;
    &lt;pre wrap=""&gt;I've no objection to flag days that result in good long term gains.
    &lt;/pre&gt;
  &lt;/blockquote&gt;
  &lt;pre wrap=""&gt;&lt;!----&gt;
Well, Flag Day was yesterday, so you've got a whole year to figure out
the plan for next time.  ;-)

   - Ian
_______________________________________________
tor-dev mailing list
&lt;a class="moz-txt-link-abbreviated" \
href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt; &lt;a \
class="moz-txt-link-freetext" \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;
  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;/body&gt;
&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110616153902</emailId><senderName>Ted Smith</senderName><senderEmail>teddks@gmail.com</senderEmail><timestampReceived>2011-06-16 15:39:02-0400</timestampReceived><subject>Re: [tor-dev] license question</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 2011-06-16 at 16:51 +0200, Frederic Bor wrote:
&gt; Hello,
&gt; 
&gt; 
&gt; I m currently implementing transparent proxying for tor with Layered Service
&gt; Provider feature on windows. Microsoft provides a sample to demonstrate how
&gt; to implement an empty LSP (this is a lot of work, even to do nothing). This
&gt; sample is distributed under the license attached in this email. I have been
&gt; advised on #tor-dev to ask here about its compatibility with 3-clause BSD.
&gt; 
&gt; It seems compatible to me but the following restriction may be a problem in
&gt; an open source context:
&gt; 
&gt; "You may not [...] modify or distribute the source code of any Distributable
&gt; Code so that any part of it becomes subject to an Excluded License. An
&gt; Excluded License is one that requires, as a condition of use, modification
&gt; or distribution, that:
&gt; - the code be disclosed or distributed in source code form, or
&gt; - others have the right to modify it."
&gt; 
&gt; The wording "requires, as a condition of use, modification or distribution"
&gt; seems to allow to use the sample in tor, since there is no such requirement
&gt; in 3-clause BSD.
&gt; 
&gt; Does this seem right to you?

You might want to ask licensing@fsf.org -- that looks like a clause
designed to exclude copyleft licenses, so they'd probably know about it
and what effects it would have on non-copyleft licenses.

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110617211815</emailId><senderName>Arturo</senderName><senderEmail>art@baculo.org</senderEmail><timestampReceived>2011-06-17 21:18:15-0400</timestampReceived><subject>[tor-dev] Looking at Bridge users oddities</subject><body>

Hi,

Jake made me notice that there has been a huge spike in tor bridge users
in Italy in the past week
(https://metrics.torproject.org/users.html?graph=bridge-users&amp;start=2011-02-19&amp;end=2011-06-17&amp;country=it&amp;dpi=72#bridge-users).


This prompted me to hack up a quick little script to analyse the Tor
bridge usage data and see if it is possible to draw some conclusions
from some patterns that emerge in it.
I don't feel like expressing a personal an opinion at this point on what
this data might mean, but I think spikes in Bridge usage could be used
do draw conclusions on socio-political happenings.

What the script does is it basically looks for spikes in Bridge traffic
by giving it a time frame and a factor for triggering the alert. As
already said it's just a quick hack so don't expect it to be performing
or even well written :P.

A couple of neat things that came out:

factor | date1 date2 1: users at date1 2: users at date2 (country code)

23.0512820513 | 2011-06-10 2011-05-29 1: 1798 2: 78 (es)

22.0707070707 | 2011-06-10 2011-06-05 1: 4370 2: 198 (it)

4.14 | 2011-06-11 2011-06-04 1: 207 2: 50 (tw)

5.13333333333 | 2011-06-11 2011-06-05 1: 231 2: 45 (ar)

5.42857142857 | 2011-06-11 2011-06-05 1: 836 2: 154 (br)

4.38181818182 | 2011-06-11 2011-06-01 1: 241 2: 55 (il)

16.5208333333 | 2011-02-15 2011-01-18 1: 48 2: 793 (de)

15.4285714286 | 2010-08-23 2010-07-26 1: 648 2: 42 (au)

13.7916666667 | 2011-03-11 2011-02-15 1: 1655 2: 120 (sa)

A one liner to get some interesting stats:

python bridge-user-alert.py -f 4 | sort -g

Hope somebody finds this little research useful,

Cheers,
Art.


["bridge-user-alert.py" (text/x-python-script)]

#!/usr/bin/env python

import csv
import pprint,sys
from datetime import date
from optparse import OptionParser

class BridgeCSV:
	def __init__(self):
		fp = open('bridge-users.csv', 'r')
		self.bridgeReader = csv.reader(fp,delimiter=',')
		self.names = self.bridgeReader.next()
		self.minimum = 40
		self.data = []

	def read(self):
		for row in self.bridgeReader:
			self.data.append(row)

	def get_date(self, date):
		for row in self.data:
			if(row[0] == date):
				return row
		return False

	def anomaly(self, row1, row2, fact):
		if(row1 == False or row2 == False):
			a = 0
			#print "ERROR!"
		else:
			for i in range(1,len(row1)):
				if(row1[i] != "NA" and row2[i] != "NA"):
					if(int(row2[i]) &gt; self.minimum and int(row1[i]) &gt; self.minimum): 
						if(float(row2[i]) &gt; float(row1[i])):
							#print "%s %s %s 1: %s 2: %s (%s)" % \
(float(row2[i])/float(row1[i]),row1[0],row2[0],row1[i],row2[i],self.names[i])  \
                if(float(row2[i])/float(row1[i]) &gt; float(fact)):
								print "%s | %s %s 1: %s 2: %s (%s)" % \
(float(row2[i])/float(row1[i]),row1[0],row2[0],row1[i],row2[i],self.names[i])  else:
							if(float(row1[i])/float(row2[i]) &gt; float(fact)):
								print "%s | %s %s 1: %s 2: %s (%s)" % \
(float(row1[i])/float(row2[i]),row1[0],row2[0],row1[i],row2[i],self.names[i])  

	def print_row(self, row):
		if(row == False):
			print "error no data found!"
			return False
		for i in range(0,len(row)):
			print "%s: %s" % (self.names[i],row[i])

a = BridgeCSV()
a.read()

parser = OptionParser()
parser.add_option("-s", "--start", dest="startdate",
                  help="Start date in format X day after 1. 1. 0001", default=734000)
parser.add_option("-e", "--end",
                  dest="enddate",
                  help="End date in format X day after 1. 1. 0001", default=734300)
parser.add_option("-p", "--period",
									help="timeframe to use when looking for anomalies", dest="period", \
default=30)

parser.add_option("-f", "--factor",
									help="The factor to use when detecting anomalies, low factor means \
sensitive, factor &lt; 1 looks for decreases", dest="factor",  default=3)

(options, args) = parser.parse_args()


print "Analysing from %s to %s" % \
(date.fromordinal(options.startdate).strftime("%Y-%m-%d"),date.fromordinal(options.enddate).strftime("%Y-%m-%d"))
 print "using a factor of %s and a timeframe of %s" % (options.factor, \
options.period)

for i in range(options.startdate,options.enddate):
	for j in range(i-options.period,i):
		date1 = date.fromordinal(i).strftime("%Y-%m-%d")
		date2 = date.fromordinal(j).strftime("%Y-%m-%d")
		#print "%s %s"  % (date1,date2)
		a.anomaly(a.get_date(date1),a.get_date(date2),options.factor)
#a.print_row(a.get_date("2010-12-10"))



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110618234524</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-18 23:45:24-0400</timestampReceived><subject>Re: [tor-dev] RFC: remove TorUtil.Enum</subject><body>

On Sat, Jun 18, 2011 at 4:25 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt; I don't have a problem with it being removed (though this is Mike's
&gt; call). I looked at it a bit for arm's enum implementation...
&gt; https://gitweb.torproject.org/arm.git/blob/HEAD:/src/util/enum.py
&gt;
&gt; but that's about it. -Damian

The primary difference between TorUtil.Enum and the arm Enum class:
arm has a well-documented, full, useful implementation of an enum
class.  And, secondarily, I assume it is actually used by code.

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110620145304</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-06-20 14:53:04-0400</timestampReceived><subject>Re: [tor-dev] [PATCH] Allow tordnsel to build on Squeeze</subject><body>

On Sun, 19 Jun 2011 23:35:42 +0200
Jrmy Bobbio &lt;lunar@debian.org&gt; wrote:
&gt;   &lt;phobos&gt; I give up on tordnsel, I'm unable to get git head to
&gt; compile in squeeze
&gt; 
&gt; Attached are 3 patches that allow tordnsel to build on a Squeeze
&gt; system. I unfortunately lack a test environment to ensure that the
&gt; resulting binary works fine. Haskell has proven quite trusty, though.

Thanks!  I can only get patch 0001 to apply cleanly.  The other two
fail. I'll keep poking at it.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110620214007</emailId><senderName>Tomas Touceda</senderName><senderEmail>chiiph@gentoo.org</senderEmail><timestampReceived>2011-06-20 21:40:07-0400</timestampReceived><subject>[tor-dev] Thandy and what's next</subject><body>

[Attachment #2 (multipart/signed)]


Hello everyone,

Thandy, for those who haven't heard about it by now, in few words is a
package system for Tor packages and the like. One of the biggest
problems we have right now is keeping users' Tor up to date, so we are
trying to make time to get this going.

(For more detailed information about Thandy check [1], specially the
doc/ and specs/ directories)

A couple of months ago, nickm and erinn worked in writing the package
format spec (see [2] for more details), and now I'm going to start
working as fast as I can (which may be slow) in implementing this last
spec and get a working Thandy.

On the more technical side, the idea is to implement this in Python as a
first approach. In terms of distribution, Python isn't the best choice
for platforms like Windows, but right now porting Thandy to another
language isn't among the top priorities.

This will probably be merged with the alpha track of releases we are
making, so this can have as much testing as it can before going to
stable.

[1] https://gitweb.torproject.org/thandy.git/tree
[2]
https://gitweb.torproject.org/erinn/thandy.git/blob/934300a7c4c6c0493bedaf0503fb61c45045942e:/specs/thp-first-draft.txt


Cheers,
-- 
Tomas Touceda
Gentoo Developer - Qt, Scheme, Lisp


[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110620215444</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-06-20 21:54:44-0400</timestampReceived><subject>Re: [tor-dev] Tor AF independence patch - first big step to Tor IPv6</subject><body>

On 2011-06-20 23:22 , Nick Mathewson wrote:
[..]
&gt; Do you remember which git checkout it was?  I can't find one that it
&gt; applies cleanly to.

I am too much of a git noob, but:

git status reveals:
# On branch master
# Your branch is behind 'origin/master' by 142 commits, and can be
fast-forwarded.

How to get the current md5/hash out is eehmmm, help!? :)

Nevertheless, I can just take the patch and apply it to a check out and
then I can make it match cleanly against the current master again.

See also the point at the end.

&gt;  [...]
&gt;&gt; A question there also becomes, do we want to show a Tor node as separate
&gt;&gt; IPv4 and IPv6 routers, or are they to be seen as one, if it is one, we
&gt;&gt; require the above ORMultiport, so that we can have multiple IP addresses
&gt;&gt; and ports on a single node.
&gt; 
&gt; It's one router; it has to be.  After all, it needs to be able

[from the follow-up mail]
&gt; After all, every IPv6-enabled router needs to be able to connect to
&gt; IPv4 and IPv6 addresses both, or else there will be two completely
&gt; separate networks, which would be bad for anonymity.

Good point, but we need to settle on how to cleanly handle this.

&gt;  [...]
&gt;&gt; And maybe, it could be useful to have a special branch on torproject's
&gt;&gt; git server for this, as it is quite a bit of patch ;)
&gt; 
&gt; This should definitely get a git repository someplace.  In the future,
&gt; if it's possible, please try to do stuff like this as a series of
&gt; patches rather than as one huge patch.  Stuff this big is hard to
&gt; merge and hard to review.

Agree and point taken. I'll need to do a git crash course I guess ;)

&gt; Some initial thoughts:
[..snip..]

I'll get to these tomorrow after sleep ;)

[..]
&gt; And that's it for my comments on v1 -- looks like a good beginning!
&gt; Do you have time to clean this stuff up soon, or shall I start hacking
&gt; on it?  I'd like to get IPv6 support into 0.2.3.x if at all possible.

I'll work on this tomorrow:
 - get it into a git repo
 - reply&amp;fix the initial points made above (the snipped stuff ;)

Then we can go for round two.

Greets,
 Jeroen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110623190241</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-06-23 19:02:41-0400</timestampReceived><subject>Re: [tor-dev] Improving Private Browsing Mode/Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Robert Ransom (rransom.8774@gmail.com):

&gt; On Thu, 23 Jun 2011 11:19:45 -0700
&gt; Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; 
&gt; &gt; So perhaps Torbutton controlled per-tab proxy username+password is the
&gt; &gt; best option? Oh man am I dreading doing that... (The demons laugh
&gt; &gt; again.)
&gt; 
&gt; If you do this, you will need to give the user some indication of each
&gt; tab's ???compartment???, and some way to move tabs between compartments.
&gt;
&gt; Coloring each tab to indicate its compartment may fail for anomalous
&gt; trichromats like me and *will* fail for more thoroughly colorblind
&gt; users.  Putting a number or symbol in each tab will confuse most users.
&gt; 
&gt; I suggest one compartment per browser window.  (Of course, you can and
&gt; should leave more detailed hooks in the browser's source if possible,
&gt; in case someone wants to experiment with a different scheme.)

As soon as I sent the previous email, I wanted to edit it to change
"per-tab" to something else.  I think any kind of per-tab and
per-window isolation does not correspond to how people have been
trained to use their existing browsers.

In fact, I think we should also treat this linkability just like the
window.name and referer. So, how about we set the Proposal 171 SOCKS
username to a function of the hostname in the referer header (possibly
caching the first referer for subsequent link navigation). If the
referer is blank, use the request URL hostname. This policy should
effectively give us the top-level origin isolation we want for other
identifiers.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110625215948</emailId><senderName>Sean Robinson</senderName><senderEmail>seankrobinson@gmail.com</senderEmail><timestampReceived>2011-06-25 21:59:48-0400</timestampReceived><subject>Re: [tor-dev] TOR control protocol timeout</subject><body>

On Sun, Jun 19, 2011 at 11:18 AM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;&gt; you and atagar...
&gt;
&gt; I am atagar.

LOL!  It's a small world, eh?

&gt; All the concurrency issues for shutting down should have been
&gt; addressed. What sort of problems are you encountering? Do you have a
&gt; use case for reproducing the issue?

I had not done more testing since the socket.shutdown() was added.
Now I have tested and I no longer have TOR connections hanging.  Thank
you.

&gt;&gt; I would like to have readline() detect when a socket error has
&gt;&gt; occurred.
&gt;
&gt; A socket error should result in a None return value that shuts down _thread.

As long as the socket error is local, then None is returned.  I was
concerned about remote (silent) errors going undetected.  But, further
tests (e.g. 10 minute timeout) also did not work on a long-running
client listening for TOR events.  I now believe that absent a defined
keep-alive framework in the control protocol, it is best for any
client which cares to check the connection status to periodically run
a small query (i.e. "GETINFO version") and check for a response.

-- 
Sean Robinson
WiFi Radar - http://wifi-radar.berlios.de
Python WiFi - http://pythonwifi.wikispot.org
pymnl - http://pymnl.wikispot.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110627195022</emailId><senderName>Sambuddho Chakravarty</senderName><senderEmail>sc2516@columbia.edu</senderEmail><timestampReceived>2011-06-27 19:50:22-0400</timestampReceived><subject>Re: [tor-dev] Reg : using the keep alive messages</subject><body>

[Attachment #2 (multipart/alternative)]


Sorry about the typo..I meant which is the relevant part of the code which I
can begin looking into if I want to inject RELAY_DROP cells in a circuit in
forward direction (from the OP towards the exit) and backward direction
(from exit to OP).

Thanks
Sambuddho

On Fri, Jun 24, 2011 at 8:36 PM, Sambuddho Chakravarty
&lt;sc2516@columbia.edu&gt;wrote:

&gt;
&gt;  Which is the relevant part of the that should I look into for injecting
&gt; such cells in streams ?
&gt;
&gt; Thanks
&gt; Sambuddho
&gt;
&gt;
&gt; On Thu, Jun 9, 2011 at 3:03 PM, Sambuddho Chakravarty &lt;sc2516@columbia.edu
&gt; &gt; wrote:
&gt;
&gt;&gt; Dear Roger
&gt;&gt;  Thanks for your response. I read the spec document about the RELAY_DROP
&gt;&gt; cells. You say that no one has understood the passive correlation attack to
&gt;&gt; utilize the RELAY_DROP cells. I am however little curious to see if
&gt;&gt; "moderate padding" (enough to not mess up QoS of various services) can be
&gt;&gt; used to prevent some of the attacks that rely on parameters such as OWD ,
&gt;&gt; RTT and B/W variation to link relays that are being used in a circuit. I am
&gt;&gt; curious from the practical point of view of exploring such padding to
&gt;&gt; prevent our bandwidth based confirmation attack or the M&amp;D attack (and its
&gt;&gt; 2009 variant) .
&gt;&gt;
&gt;&gt; Thanks
&gt;&gt; Sambuddho
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Jun 9, 2011 at 12:29 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; On Wed, Jun 08, 2011 at 08:11:58PM -0400, Sambuddho Chakravarty wrote:
&gt;&gt;&gt; &gt; Hi All
&gt;&gt;&gt; &gt; I read in the Tor design spec that Tor control protocol supports
&gt;&gt;&gt; keepalive
&gt;&gt;&gt; &gt; messages which could be used for link padding . I wonder if anyone has
&gt;&gt;&gt; ever
&gt;&gt;&gt; &gt; explored using them...
&gt;&gt;&gt;
&gt;&gt;&gt; I don't think you mean the Tor control protocol. There's no need to pad
&gt;&gt;&gt; that connection (or if there is, you've screwed up badly somewhere else).
&gt;&gt;&gt;
&gt;&gt;&gt; The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:
&gt;&gt;&gt;
&gt;&gt;&gt;   PADDING cells are currently used to implement connection keepalive.
&gt;&gt;&gt;   If there is no other traffic, ORs and OPs send one another a PADDING
&gt;&gt;&gt;   cell every few minutes.
&gt;&gt;&gt;
&gt;&gt;&gt; There's also a DROP relay cell. While PADDING cells can only be sent to
&gt;&gt;&gt; the adjacent relay, the client can send DROP cells to any relay on her
&gt;&gt;&gt; circuit, and any relay on the circuit can inject DROP cells to the
&gt;&gt;&gt; client.
&gt;&gt;&gt; See also sec 7.2 of tor-spec.
&gt;&gt;&gt;
&gt;&gt;&gt; But that said, I think the answer to your question is no. AFAIK nobody
&gt;&gt;&gt; has understood passive correlation attacks well enough to get to the
&gt;&gt;&gt; "if I change the design like this, does the attack work less well"
&gt;&gt;&gt; research stage.
&gt;&gt;&gt;
&gt;&gt;&gt; --Roger
&gt;&gt;&gt;
&gt;&gt;&gt; _______________________________________________
&gt;&gt;&gt; tor-dev mailing list
&gt;&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Sorry about the typo..I meant which is the relevant part of the code \
which I can begin looking into if I want to inject RELAY_DROP cells in a circuit in \
forward direction (from the OP towards the exit) and backward direction (from exit to \
OP).&lt;div&gt;

&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On \
Fri, Jun 24, 2011 at 8:36 PM, Sambuddho Chakravarty &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:sc2516@columbia.edu"&gt;sc2516@columbia.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;div&gt;  Which is the relevant part of the \
that should I look into for injecting such cells in streams ?&lt;/div&gt;

&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;&lt;div&gt;  &lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Thu, Jun 9, 2011 at 3:03 PM, \
Sambuddho Chakravarty &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:sc2516@columbia.edu" \
target="_blank"&gt;sc2516@columbia.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;


&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt;&lt;div dir="ltr"&gt;Dear Roger&lt;div&gt;  Thanks for your response. I \
read the spec document about the RELAY_DROP cells. You say that no one has understood \
the passive correlation attack to utilize the RELAY_DROP cells. I am however little \
curious to see if "moderate padding" (enough to not mess up QoS of various \
services) can be used to prevent some of the attacks that rely on parameters such as \
OWD , RTT and B/W variation to link relays that are being used in a circuit. I am \
curious from the practical point of view of exploring such padding to prevent our \
bandwidth based confirmation attack or the M&amp;D attack (and its 2009 variant) .  \
&lt;/div&gt;



&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;/div&gt;&lt;div&gt;Sambuddho&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Thu, Jun 9, 2011 at 12:29 PM, Roger Dingledine &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:arma@mit.edu" \
target="_blank"&gt;arma@mit.edu&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;


&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;On Wed, Jun 08, 2011 at 08:11:58PM \
-0400, Sambuddho Chakravarty wrote:&lt;br&gt; &gt; Hi All&lt;br&gt;
&gt; I read in the Tor design spec that Tor control protocol supports keepalive&lt;br&gt;
&gt; messages which could be used for link padding . I wonder if anyone has ever&lt;br&gt;
&gt; explored using them...&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;I don't think you mean the Tor control protocol. There's no need \
to pad&lt;br&gt; that connection (or if there is, you've screwed up badly somewhere \
else).&lt;br&gt; &lt;br&gt;
The Tor protocol supports PADDING cells -- see sec 3 of tor-spec.txt:&lt;br&gt;
&lt;br&gt;
    PADDING cells are currently used to implement connection keepalive.&lt;br&gt;
    If there is no other traffic, ORs and OPs send one another a PADDING&lt;br&gt;
    cell every few minutes.&lt;br&gt;
&lt;br&gt;
There's also a DROP relay cell. While PADDING cells can only be sent to&lt;br&gt;
the adjacent relay, the client can send DROP cells to any relay on her&lt;br&gt;
circuit, and any relay on the circuit can inject DROP cells to the client.&lt;br&gt;
See also sec 7.2 of tor-spec.&lt;br&gt;
&lt;br&gt;
But that said, I think the answer to your question is no. AFAIK nobody&lt;br&gt;
has understood passive correlation attacks well enough to get to the&lt;br&gt;
"if I change the design like this, does the attack work less well"&lt;br&gt;
research stage.&lt;br&gt;
&lt;br&gt;
--Roger&lt;br&gt;
&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;br&gt; &lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110627195922</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-06-27 19:59:22-0400</timestampReceived><subject>[tor-dev] Proposal 182: Credit Bucket</subject><body>

Here's a proposal by Florian and Bjrn about improving our queueing
times.  Per usual procedure, I'm sending it here as I put it in the
proposals directory.


Filename: 182-creditbucket.txt
Title: Credit Bucket
Author: Florian Tschorsch and Bjrn Scheuermann
Created: 22 Jun 2011
Status: Draft

Overview:

  The following proposal targets the reduction of queuing times in onion
  routers. In particular, we focus on the token bucket algorithm in Tor and
  point out that current usage unnecessarily locks cells for long time spans.
  We propose a non-intrusive change in Tor's design which overcomes the
  deficiencies.

Motivation and Background:

  Cell statistics from the Tor network [1] reveal that cells reside in
  individual onion routers' cell queues for up to several seconds. These
  queuing times increase the end-to-end delay very significantly and are
  apparently the largest contributor to overall cell latency in Tor.

  In Tor there exist multiple token buckets on different logical levels. They
  all work independently. They are used to limit the up- and downstream of an
  onion router. All token buckets are refilled every second with a constant
  amount of tokens that depends on the configured bandwidth limits. For
  example, the so-called RelayedTokenBucket limits relay traffic only. All
  read data of incoming connections are bound to a dedicated read token
  bucket. An analogous mechanism exists for written data leaving the onion
  router. We were able to identify the specific usage and implementation of
  the token bucket algorithm as one cause for very high (and unnecessary)
  queuing times in an onion router.

  We observe that the token buckets in Tor are (surprisingly at a first
  glance) allowed to take on negative fill levels. This is justified by the
  TLS connections between onion routers where whole TLS records need to be
  processed. The token bucket on the incoming side (i.e., the one which
  determines at which rate it is allowed to read from incoming TCP
  connections) in particular often runs into non-negligible negative fill
  levels. As a consequence of this behavior, sometimes slightly more data is
  read than it would be admissible upon strict interpretation of the token
  bucket concept.

  However, the token bucket for limiting the outgoing rate does not take on
  negative fill levels equally often. Consequently, it regularly happens
  that somewhat more data are read on the incoming side than the outgoing
  token bucket allows to be written during the same cycle, even if their
  configured data rates are the same. The respective cells will thus not be
  allowed to leave the onion router immediately. They will thus necessarily
  be queued for at least as long as it takes until the token bucket on the
  outgoing side is refilled again. The refill interval currently is, as
  mentioned before, one second -- so, these cells are delayed for a very
  substantial time. In summary, one could say that the two buckets, on the
  incoming and outgoing side, work like a double door system and frequently
  lock cells for a full token bucket refill interval length.

General Design:

  In order to overcome the described problem, we propose the following
  changes related to the token bucket algorithm.

  We observe that the token bucket on the outgoing connections with its
  current design is contra productive in the sense of queuing times. We
  therefore propose modifications to the token bucket algorithm that will
  eliminate the "double door effect" discussed above.

  Let us start from Tor's current approach: Thus, we have a regular token
  bucket on the reading side with a certain rate and a certain burst size.
  Let x denote the current amount of tokens in the bucket. On the outgoing
  side we need something appropriate that monitors and constrains the
  outgoing rate, but at the same time avoids holding back cells (cf. double
  door effects) whenever possible.

  Here we propose something that adopts the role of a token bucket, but
  realizes this functionality in a slightly different way. We call it a
  "credit bucket". Like a token bucket, the credit bucket also has a current
  fill level, denoted by y. However, the credit bucket is refilled in a
  different way.

  To understand how it works, let us look at the possible operations:

  As said, x is the fill level of a regular token bucket on the incoming
  side   and thus gets incremented periodically according to the configured
  rate. No changes here.

  If x&lt;=0, we are obviously not allowed to read. If x&gt;0, we are allowed to
  read up to x bytes of incoming data. If k bytes are read (k&lt;=x), then we
  update x and y as follows:

    x = x - k        (1)
    y = y + k        (2)

  (1) is the standard token bucket operation on the incoming side. Whenever
  data is admitted in, though, an additional operation is performed: (2)
  allocates the same number of bytes on the outgoing side, which will later
  on allow the same number of bytes to leave the onion router without any
  delays.

  If y + x &gt; -M, we are allowed to write up to y + x + M bytes on the
  outgoing side, where M is a positive constant. M specifies a burst size for
  the outgoing side. M should be higher than the number of tokens that get
  refilled during a refill interval, we would suggest to have M in the order
  of a few seconds "worth" of data. Now if k bytes are written on the
  outgoing side, we proceed as follows:

    If k &lt;= y then y = y - k

  In this case we use "saved" credits, previously allocated on the incoming
  side when incoming data has been processed.

    If k &gt; y then y = 0 and x = x - (k-y)

  We generated additional traffic in the onion router, so that more data is
  to be sent than has been read (the credit is not sufficient). We therefore
  "steal" tokens from the token buffer on the incoming side to compensate for
  the additionally generated data. This will result in correspondingly less
  data being read on the incoming side subsequently. As a result of such an
  operation, the token bucket fill level x on the incoming side may become
  negative (but it can never fall below -M).

  If y + x &lt;= -M then outgoing data will be held back. This may lead to
  double-door effects, but only in extreme cases where the outgoing traffic
  largely exceeds the incoming traffic, so that the outgoing bursts size M is
  exceeded.

  Aside from short-term bursts of configurable size (as with every token
  bucket), this procedure guarantees that the configured rate may never be
  exceeded (on the application layer, that is; as with the current
  implementation, an attacker may easily cause the onion router to
  arbitrarily exceed the limits on the lower layers). Over time, we never
  send more data than the configured rate: every sent byte needs a
  corresponding token on the incoming side; this token must either have been
  consumed by an incoming byte before (it then became a "credit"), or it is
  "stolen" from the incoming bucket to compensate for data generated within
  the onion router.

Specific Design Changes:

  In the following we briefly point out the specific changes that need to be
  done in Tor's source code. By doing so one can see how non intrusive our
  modifications are.

  First we need to address the bucket increment and decrement operations.
  According to the described logic above, this should be done in the methods
  connection_bucket_refill and connection_buckets_decrement respectively. In
  particular allocating, saving and "stealing" of tokens need to be
  considered here.

  Second the rate limiting, i.e. the amount we are allowed to write
  (connection_bucket_write_limit) needs to be adapted in lines of the credit
  bucket logic. Meaning in order to avoid  the here identified unnecessary
  queuing of cells, we need to consider the new burst parameter M. Here we
  also need to take non rate limited connections such as from the localhost
  into account. The rate limiting on the reading side remains the same.

  At last we need to find good values/ ratios for the parameter M such that
  the trade off between avoiding "double door effects" and maintaining
  strict rate limits work as expected. As future work and after insights
  about the performance gain of the here described proposal we need to find a
  way to implement this both using bufferevent rate limiting with libevent
  2.3.x and Tor's rate limiting code.

Conclusion:

  This proposal can be implemented with moderate effort and requires changes
  only at the points where currently the token bucket operations are
  performed.

  We feel that this is not the be-all and end-all solution, because it again
  introduces a feedback loop between the incoming and the outgoing side. We
  therefore still hope that we will be able to come to a both simpler and
  more effective design in the future. However, we believe that what we
  proposed here is a good compromise between avoiding double-door effects to
  the furthest possible extent, strictly enforcing an application-layer data
  rate, and keeping the extent of changes to the code small.

  Feedback is highly appreciated.

References:

  [1] Karsten Loesing. Analysis of Circuit Queues in Tor. August 25, 2009.
  [2] https://trac.torproject.org/projects/tor/wiki/sponsors/SponsorD/June2011
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110627214539</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-06-27 21:45:39-0400</timestampReceived><subject>Re: [tor-dev] WIN32_WINNT in or/or.h</subject><body>

"Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:

&gt; On Mon, Jun 20, 2011 at 6:32 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt;juswrote:
&gt;&gt; I think that the values for 'WIN32_WINNT' and '_WIN32_WINNT'
&gt;&gt; should be protected against redefinement.
&gt;&gt; Reason: In order for MingW to prototype getaddrinfo() and freeaddrinfo()
&gt;&gt; correctly (in &lt;ws2tcpip.h&gt;), '_WIN32_WINNT' *must* be defined as 0x0501
&gt;&gt; or higher. or/or.h blindly defines them as 0x0400. So, building with
&gt;&gt; -DHAVE_GETADDRINFO needs _WIN32_WINNT to be set to 0x0501.
&gt; 
&gt; I'm confused about the situation here.  Does "-DHAVE_GETADDRINFO" mean
&gt; that you're overriding the value in orconfig.h from the command line,

Yes.

&gt; and presumably setting your own _WIN32_WINNT value there too?

Yes, the "MingW way" to use and prototype some of these enhanced function is 
to set _WIN32_WINNT with the proper value (0x0501 in this case. On cmd-line etc).
The trouble is specifically that &lt;or/or.h&gt; overrides that with value 0x0400.

Here are some lines from MingW's &lt;ws2tcpip.h&gt;

#if (_WIN32_WINNT &gt;= 0x0501)
void WSAAPI freeaddrinfo (struct addrinfo*);
int WSAAPI getaddrinfo (const char*,const char*,const struct addrinfo*,
                        struct addrinfo**);
int WSAAPI getnameinfo(const struct sockaddr*,socklen_t,char*,DWORD,
                       char*,DWORD,int);
#else
/* FIXME: Need WS protocol-independent API helpers.  */
#endif

----------------------

--gv

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110629034819</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-06-29 03:48:19-0400</timestampReceived><subject>Re: [tor-dev] Tor and BGP integration</subject><body>

On Thu, Jun 9, 2011 at 2:34 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; ...
&gt; We need a proposal for a circuit selection process that is BGP aware. I
&gt; guess we'll need it around the time that we want to support IPv6 entirely...

why stop at BGP? at that point, might as well pay for a telegeography
subscription and map AS-&gt;RoW for physically aware route building along
sufficiently diverse fiber paths...

(in other words, BGP aware route building is sufficiently complicated
as to make the next jump past logical domains of administration
worthwhile.)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110502070206</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-02 07:02:06-0400</timestampReceived><subject>Re: [tor-dev] Moving Orbot to Git from SVN</subject><body>

On Mon, May 2, 2011 at 3:17 AM, Nathan Freitas &lt;nathan@freitas.net&gt; wrote:
&gt; Sebastian,
&gt;
&gt; I believe you are the one to request this of.
&gt;
&gt; We need this repo/path:
&gt; https://svn.torproject.org/svn/projects/android/trunk/Orbot/
&gt;
&gt; moved over to a repo on the git server, as soon as you can. I am also
&gt; not sure of my credential status on the git server, whether they are the
&gt; same as Trac and SVN or not.
&gt;
&gt; It should have happened a long time ago, but now GSoC 2011 is acting as
&gt; a catalyst, such that we can properly have our student branch his work.

Hi,

When this move happens, please let me know so that I can update the
path to the .pot file in our translation portal. Also, please make
sure that I have commit access to some part of the git repo for
translations.

Thanks,

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110504001405</emailId><senderName>Cav</senderName><senderEmail>cav@gotadsl.co.uk</senderEmail><timestampReceived>2011-05-04 00:14:05-0400</timestampReceived><subject>Re: [tor-dev] Mingw ann non-autoconf build</subject><body>

[Attachment #2 (multipart/alternative)]


You could also use MinGW shell coupled with Eclipse for C/C++.
Builds can be reduced to a few button clicks.

This way, if you need to use different #defines and versions you can 
have separate projects with linked source folders.

I am happy to help you achieve this, and I can send you docs - you might 
discover a few tricks that elude me.

Enclosed is a screen shot revealing what can be achieved.


Hope it helps.

*** if the attachment gets stripped, I can resend under separate cover.

Gisle Vanem wrote:
&gt; "Nick Mathewson" &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt;&gt; But hey, it's free software. If you wanted to write and maintain an
&gt;&gt; alternative set of build scripts to work with different versions of
&gt;&gt; mingw, that would be great. 
&gt;
&gt; I'm using the top of the line version of MingW (v3.18). I don't think
&gt; MingW has changed too much the last 5 years that it would matter for 
&gt; Tor. Except for the added gettimeofday() (in MingW v.316 I believe), an
&gt; orconfig.h should be unaware of any MingW version.
&gt;
&gt;&gt; I'd greatly
&gt;&gt; prefer a separate orconfig.h if you take this route: sharing the same
&gt;&gt; one between msvc and mingw seems like it's asking for trouble.
&gt;
&gt; Okay, but I'm now building Tor with the attached orconfig.h. This has
&gt; "only" 5 tests for __MINGW32__. I don't think that is asking for trouble.
&gt;
&gt; Gisle V.
&gt;
&gt; # rm -v /bin/laden /bin/laden: removed /bin/laden
&gt; /* orconfig.h for Windows -- This file is *not* generated by autoconf.
&gt; * Instead, it has to be hand-edited to keep Win32 happy.
&gt; */
&gt;
&gt; /* Windows-only defines. */
&gt; #define MS_WINDOWS
&gt; #define MS_WIN32
&gt; #define CONFDIR ""
&gt;
&gt; /* Define to 1 if you have the &lt;arpa/inet.h&gt; header file. */
&gt; #undef HAVE_ARPA_INET_H
&gt;
&gt; /* Define to 1 if you have the &lt;assert.h&gt; header file. */
&gt; #define HAVE_ASSERT_H
&gt;
&gt; /* Define to 1 if you have the &lt;ctype.h&gt; header file. */
&gt; #define HAVE_CTYPE_H
&gt;
&gt; #define ENABLE_THREADS
&gt;
&gt; /* Define to 1 if you have the &lt;errno.h&gt; header file. */
&gt; #define HAVE_ERRNO_H
&gt;
&gt; /* Define to 1 if you have the `event_get_method' function. */
&gt; #define HAVE_EVENT_GET_METHOD 1
&gt;
&gt; /* Define to 1 if you have the `event_get_version' function. */
&gt; #define HAVE_EVENT_GET_VERSION 1
&gt;
&gt; /* Define to 1 if you have the `event_set_log_callback' function. */
&gt; #define HAVE_EVENT_SET_LOG_CALLBACK 1
&gt;
&gt; /* Define to 1 if you have the &lt;fcntl.h&gt; header file. */
&gt; #define HAVE_FCNTL_H
&gt;
&gt; /* Define to 1 if you have the `ftime' function. */
&gt; #define HAVE_FTIME
&gt;
&gt; /* Define to 1 if you have the `gettimeofday' function. */
&gt; #ifndef __MINGW32__
&gt; #undef HAVE_GETTIMEOFDAY
&gt; #endif
&gt;
&gt; /* Define to 1 if you have the &lt;grp.h&gt; header file. */
&gt; #undef HAVE_GRP_H
&gt;
&gt; /* Define to 1 if you have the `inet_aton' function. */
&gt; #undef HAVE_INET_ATON
&gt;
&gt; /* Define to 1 if you have the &lt;inttypes.h&gt; header file. */
&gt; /* #define HAVE_INTTYPES_H */
&gt;
&gt; /* Define to 1 if you have the &lt;limits.h&gt; header file. */
&gt; #define HAVE_LIMITS_H
&gt;
&gt; /* Define to 1 if you have the &lt;machine/limits.h&gt; header file. */
&gt; #undef HAVE_MACHINE_LIMITS_H
&gt;
&gt; /* Define to 1 if you have the &lt;memory.h&gt; header file. */
&gt; #define HAVE_MEMORY_H
&gt;
&gt; /* Define to 1 if you have the &lt;netdb.h&gt; header file. */
&gt; #undef HAVE_NETDB_H
&gt;
&gt; /* Define to 1 if you have the &lt;netinet/in.h&gt; header file. */
&gt; #undef HAVE_NETINET_IN_H
&gt;
&gt; /* Define to 1 if you have the &lt;poll.h&gt; header file. */
&gt; #undef HAVE_POLL_H
&gt;
&gt; /* Define to 1 if you have the &lt;pwd.h&gt; header file. */
&gt; #undef HAVE_PWD_H
&gt;
&gt; /* Define to 1 if you have the &lt;signal.h&gt; header file. */
&gt; #define HAVE_SIGNAL_H
&gt;
&gt; /* Define to 1 if you have the `socketpair' function. */
&gt; #undef HAVE_SOCKETPAIR
&gt;
&gt; /* Define to 1 if you have the &lt;stdint.h&gt; header file. */
&gt; #undef HAVE_STDINT_H
&gt;
&gt; /* Define to 1 if you have the &lt;stdlib.h&gt; header file. */
&gt; #define HAVE_STDLIB_H
&gt;
&gt; /* Define to 1 if you have the &lt;strings.h&gt; header file. */
&gt; #undef HAVE_STRINGS_H
&gt;
&gt; /* Define to 1 if you have the &lt;string.h&gt; header file. */
&gt; #define HAVE_STRING_H
&gt;
&gt; /* Define to 1 if you have the `strlcat' function. */
&gt; #if defined (WINCE)
&gt; #define HAVE_STRLCAT
&gt; #else
&gt; #undef HAVE_STRLCAT
&gt; #endif
&gt;
&gt; /* Define to 1 if you have the `strlcpy' function. */
&gt; #if defined (WINCE)
&gt; #define HAVE_STRLCPY
&gt; #else
&gt; #undef HAVE_STRLCPY
&gt; #endif
&gt; /* Define to 1 if you have the `strptime' function. */
&gt; #undef HAVE_STRPTIME
&gt;
&gt; /* Define to 1 if your timeval has a tv_sec element. */
&gt; #define HAVE_STRUCT_TIMEVAL_TV_SEC
&gt; /* Change to #undef if you're using BCC */
&gt;
&gt; /* Define to 1 if you have the &lt;sys/fcntl.h&gt; header file. */
&gt; #ifndef __MINGW32__
&gt; #undef HAVE_SYS_FCNTL_H
&gt; #endif
&gt;
&gt; /* Define to 1 if you have the &lt;sys/ioctl.h&gt; header file. */
&gt; #ifndef __MINGW32__
&gt; #undef HAVE_SYS_IOCTL_H
&gt; #endif
&gt;
&gt; /* Define to 1 if you have the &lt;sys/limits.h&gt; header file. */
&gt; #undef HAVE_SYS_LIMITS_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/poll.h&gt; header file. */
&gt; #undef HAVE_SYS_POLL_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/socket.h&gt; header file. */
&gt; #undef HAVE_SYS_SOCKET_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/stat.h&gt; header file. */
&gt; #define HAVE_SYS_STAT_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/time.h&gt; header file. */
&gt; #ifndef __MINGW32__
&gt; #undef HAVE_SYS_TIME_H
&gt; #endif
&gt;
&gt; /* Define to 1 if you have the &lt;sys/types.h&gt; header file. */
&gt; #define HAVE_SYS_TYPES_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/utime.h&gt; header file. */
&gt; #define HAVE_SYS_UTIME_H
&gt;
&gt; /* Define to 1 if you have the &lt;sys/wait.h&gt; header file. */
&gt; #undef HAVE_SYS_WAIT_H
&gt;
&gt; /* Define to 1 if you have the &lt;time.h&gt; header file. */
&gt; #define HAVE_TIME_H
&gt;
&gt; /* Define to 1 if you have the `uname' function. */
&gt; #undef HAVE_UNAME
&gt;
&gt; /* Define to 1 if you have the &lt;unistd.h&gt; header file. */
&gt; #ifndef __MINGW32__
&gt; #undef HAVE_UNISTD_H
&gt; #endif
&gt;
&gt; /* Define to 1 iff NULL is represented by a 0 in memory. */
&gt; #define NULL_REP_IS_ZERO_BYTES 1
&gt;
&gt; /* Name of package */
&gt; #define PACKAGE "tor"
&gt;
&gt; /* Define to the address where bug reports for this package should be 
&gt; sent. */
&gt; #undef PACKAGE_BUGREPORT
&gt;
&gt; /* Define to the full name of this package. */
&gt; #undef PACKAGE_NAME
&gt;
&gt; /* Define to the full name and version of this package. */
&gt; #undef PACKAGE_STRING
&gt;
&gt; /* Define to the one symbol short name of this package. */
&gt; #undef PACKAGE_TARNAME
&gt;
&gt; /* Define to the version of this package. */
&gt; #undef PACKAGE_VERSION
&gt;
&gt; /* The size of a `char', as computed by sizeof. */
&gt; #define SIZEOF_CHAR 1
&gt;
&gt; /* The size of a `int', as computed by sizeof. */
&gt; #define SIZEOF_INT 4
&gt;
&gt; /* The size of a `int16_t', as computed by sizeof. */
&gt; #undef SIZEOF_INT16_T
&gt;
&gt; /* The size of a `int32_t', as computed by sizeof. */
&gt; #undef SIZEOF_INT32_T
&gt;
&gt; /* The size of a `int64_t', as computed by sizeof. */
&gt; #undef SIZEOF_INT64_T
&gt;
&gt; /* The size of a `int8_t', as computed by sizeof. */
&gt; #undef SIZEOF_INT8_T
&gt;
&gt; /* The size of a `long', as computed by sizeof. */
&gt; #define SIZEOF_LONG 4
&gt;
&gt; /* The size of a `long long', as computed by sizeof. */
&gt; #undef SIZEOF_LONG_LONG
&gt;
&gt; /* The size of a `short', as computed by sizeof. */
&gt; #define SIZEOF_SHORT 2
&gt;
&gt; /* The size of a `time_t', as computed by sizeof. */
&gt; #define SIZEOF_TIME_T 4
&gt;
&gt; /* The size of a `uint16_t', as computed by sizeof. */
&gt; #undef SIZEOF_UINT16_T
&gt;
&gt; /* The size of a `uint32_t', as computed by sizeof. */
&gt; #undef SIZEOF_UINT32_T
&gt;
&gt; /* The size of a `uint64_t', as computed by sizeof. */
&gt; #undef SIZEOF_UINT64_T
&gt;
&gt; /* The size of a `uint8_t', as computed by sizeof. */
&gt; #undef SIZEOF_UINT8_T
&gt;
&gt; /* The size of a `void *', as computed by sizeof. */
&gt; #define SIZEOF_VOID_P 4
&gt;
&gt; /* The size of a `__int64', as computed by sizeof. */
&gt; #define SIZEOF___INT64 8
&gt;
&gt; /* The sizeof a size_t, as computed by sizeof. */
&gt; #define SIZEOF_SIZE_T 4
&gt;
&gt; /* Define to 1 if you have the ANSI C header files. */
&gt; #define STDC_HEADERS
&gt;
&gt; /* Define to 1 if time_t is signed. */
&gt; #define TIME_T_IS_SIGNED
&gt;
&gt; /* Define to 1 iff unaligned int access is allowed */
&gt; #define UNALIGNED_INT_ACCESS_OK
&gt;
&gt; #define HAVE_EVENT_H
&gt;
&gt; /* Define to 1 iff we represent negative integers with two's 
&gt; complement */
&gt; #define USING_TWOS_COMPLEMENT
&gt;
&gt; /* Version number of package */
&gt; #define VERSION "0.2.3.0-alpha-dev"
&gt; ------------------------------------------------------------------------
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;   

[Attachment #5 (multipart/related)]

[Attachment #7 (text/html)]

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta content="text/html;charset=ISO-8859-1" http-equiv="Content-Type"&gt;
  &lt;title&gt;&lt;/title&gt;
&lt;/head&gt;
&lt;body bgcolor="#ffffff" text="#000000"&gt;
You could also use MinGW shell coupled with Eclipse for C/C++.&lt;br&gt;
Builds can be reduced to a few button clicks.&lt;br&gt;
&lt;br&gt;
This way, if you need to use different #defines and versions you can
have separate projects with linked source folders.&lt;br&gt;
&lt;br&gt;
I am happy to help you achieve this, and I can send you docs - you
might discover a few tricks
that elude me.&lt;br&gt;
&lt;br&gt;
Enclosed is a screen shot revealing what can be achieved.&lt;br&gt;
&lt;br&gt;
&lt;img src="cid:part1.06020302.07040405@gotadsl.co.uk" alt=""&gt;&lt;br&gt;
Hope it helps.&lt;br&gt;
&lt;br&gt;
*** if the attachment gets stripped, I can resend under separate cover.&lt;br&gt;
&lt;br&gt;
Gisle Vanem wrote:
&lt;blockquote cite="mid:925F8E58788B47B381F05E19B110892F@broadpark.no"
 type="cite"&gt;"Nick Mathewson" &lt;a class="moz-txt-link-rfc2396E"
 href="mailto:nickm@freehaven.net"&gt;&lt;nickm@freehaven.net&gt;&lt;/a&gt;
wrote: &lt;br&gt;
  &lt;br&gt;
  &lt;blockquote type="cite"&gt;But hey, it's free software. If you wanted to
write and maintain an &lt;br&gt;
alternative set of build scripts to work with different versions of &lt;br&gt;
mingw, that would be great. &lt;/blockquote&gt;
  &lt;br&gt;
I'm using the top of the line version of MingW (v3.18). I don't think &lt;br&gt;
MingW has changed too much the last 5 years that it would matter for
Tor. Except for the added gettimeofday() (in MingW v.316 I believe), an
  &lt;br&gt;
orconfig.h should be unaware of any MingW version. &lt;br&gt;
  &lt;br&gt;
  &lt;blockquote type="cite"&gt;I'd greatly &lt;br&gt;
prefer a separate orconfig.h if you take this route: sharing the same &lt;br&gt;
one between msvc and mingw seems like it's asking for trouble. &lt;br&gt;
  &lt;/blockquote&gt;
  &lt;br&gt;
Okay, but I'm now building Tor with the attached orconfig.h. This has &lt;br&gt;
"only" 5 tests for __MINGW32__. I don't think that is asking for
trouble. &lt;br&gt;
  &lt;br&gt;
Gisle V. &lt;br&gt;
  &lt;br&gt;
# rm -v /bin/laden /bin/laden: removed /bin/laden &lt;br&gt;
/* orconfig.h for Windows -- This file is *not* generated by autoconf. &lt;br&gt;
* Instead, it has to be hand-edited to keep Win32 happy. &lt;br&gt;
*/ &lt;br&gt;
  &lt;br&gt;
/* Windows-only defines. */ &lt;br&gt;
#define MS_WINDOWS &lt;br&gt;
#define MS_WIN32 &lt;br&gt;
#define CONFDIR "" &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;arpa/inet.h&gt; header file. */ &lt;br&gt;
#undef HAVE_ARPA_INET_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;assert.h&gt; header file. */ &lt;br&gt;
#define HAVE_ASSERT_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;ctype.h&gt; header file. */ &lt;br&gt;
#define HAVE_CTYPE_H &lt;br&gt;
  &lt;br&gt;
#define ENABLE_THREADS &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;errno.h&gt; header file. */ &lt;br&gt;
#define HAVE_ERRNO_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `event_get_method' function. */ &lt;br&gt;
#define HAVE_EVENT_GET_METHOD 1 &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `event_get_version' function. */ &lt;br&gt;
#define HAVE_EVENT_GET_VERSION 1 &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `event_set_log_callback' function. */ &lt;br&gt;
#define HAVE_EVENT_SET_LOG_CALLBACK 1 &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;fcntl.h&gt; header file. */ &lt;br&gt;
#define HAVE_FCNTL_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `ftime' function. */ &lt;br&gt;
#define HAVE_FTIME &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `gettimeofday' function. */ &lt;br&gt;
#ifndef __MINGW32__ &lt;br&gt;
#undef HAVE_GETTIMEOFDAY &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;grp.h&gt; header file. */ &lt;br&gt;
#undef HAVE_GRP_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `inet_aton' function. */ &lt;br&gt;
#undef HAVE_INET_ATON &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;inttypes.h&gt; header file. */ &lt;br&gt;
/* #define HAVE_INTTYPES_H */ &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;limits.h&gt; header file. */ &lt;br&gt;
#define HAVE_LIMITS_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;machine/limits.h&gt; header file. */
  &lt;br&gt;
#undef HAVE_MACHINE_LIMITS_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;memory.h&gt; header file. */ &lt;br&gt;
#define HAVE_MEMORY_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;netdb.h&gt; header file. */ &lt;br&gt;
#undef HAVE_NETDB_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;netinet/in.h&gt; header file. */ &lt;br&gt;
#undef HAVE_NETINET_IN_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;poll.h&gt; header file. */ &lt;br&gt;
#undef HAVE_POLL_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;pwd.h&gt; header file. */ &lt;br&gt;
#undef HAVE_PWD_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;signal.h&gt; header file. */ &lt;br&gt;
#define HAVE_SIGNAL_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `socketpair' function. */ &lt;br&gt;
#undef HAVE_SOCKETPAIR &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;stdint.h&gt; header file. */ &lt;br&gt;
#undef HAVE_STDINT_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;stdlib.h&gt; header file. */ &lt;br&gt;
#define HAVE_STDLIB_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;strings.h&gt; header file. */ &lt;br&gt;
#undef HAVE_STRINGS_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;string.h&gt; header file. */ &lt;br&gt;
#define HAVE_STRING_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `strlcat' function. */ &lt;br&gt;
#if defined (WINCE) &lt;br&gt;
#define HAVE_STRLCAT &lt;br&gt;
#else &lt;br&gt;
#undef HAVE_STRLCAT &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `strlcpy' function. */ &lt;br&gt;
#if defined (WINCE) &lt;br&gt;
#define HAVE_STRLCPY &lt;br&gt;
#else &lt;br&gt;
#undef HAVE_STRLCPY &lt;br&gt;
#endif &lt;br&gt;
/* Define to 1 if you have the `strptime' function. */ &lt;br&gt;
#undef HAVE_STRPTIME &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if your timeval has a tv_sec element. */ &lt;br&gt;
#define HAVE_STRUCT_TIMEVAL_TV_SEC &lt;br&gt;
/* Change to #undef if you're using BCC */ &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/fcntl.h&gt; header file. */ &lt;br&gt;
#ifndef __MINGW32__ &lt;br&gt;
#undef HAVE_SYS_FCNTL_H &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/ioctl.h&gt; header file. */ &lt;br&gt;
#ifndef __MINGW32__ &lt;br&gt;
#undef HAVE_SYS_IOCTL_H &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/limits.h&gt; header file. */ &lt;br&gt;
#undef HAVE_SYS_LIMITS_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/poll.h&gt; header file. */ &lt;br&gt;
#undef HAVE_SYS_POLL_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/socket.h&gt; header file. */ &lt;br&gt;
#undef HAVE_SYS_SOCKET_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/stat.h&gt; header file. */ &lt;br&gt;
#define HAVE_SYS_STAT_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/time.h&gt; header file. */ &lt;br&gt;
#ifndef __MINGW32__ &lt;br&gt;
#undef HAVE_SYS_TIME_H &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/types.h&gt; header file. */ &lt;br&gt;
#define HAVE_SYS_TYPES_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/utime.h&gt; header file. */ &lt;br&gt;
#define HAVE_SYS_UTIME_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;sys/wait.h&gt; header file. */ &lt;br&gt;
#undef HAVE_SYS_WAIT_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;time.h&gt; header file. */ &lt;br&gt;
#define HAVE_TIME_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the `uname' function. */ &lt;br&gt;
#undef HAVE_UNAME &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the &lt;unistd.h&gt; header file. */ &lt;br&gt;
#ifndef __MINGW32__ &lt;br&gt;
#undef HAVE_UNISTD_H &lt;br&gt;
#endif &lt;br&gt;
  &lt;br&gt;
/* Define to 1 iff NULL is represented by a 0 in memory. */ &lt;br&gt;
#define NULL_REP_IS_ZERO_BYTES 1 &lt;br&gt;
  &lt;br&gt;
/* Name of package */ &lt;br&gt;
#define PACKAGE "tor" &lt;br&gt;
  &lt;br&gt;
/* Define to the address where bug reports for this package should be
sent. */ &lt;br&gt;
#undef PACKAGE_BUGREPORT &lt;br&gt;
  &lt;br&gt;
/* Define to the full name of this package. */ &lt;br&gt;
#undef PACKAGE_NAME &lt;br&gt;
  &lt;br&gt;
/* Define to the full name and version of this package. */ &lt;br&gt;
#undef PACKAGE_STRING &lt;br&gt;
  &lt;br&gt;
/* Define to the one symbol short name of this package. */ &lt;br&gt;
#undef PACKAGE_TARNAME &lt;br&gt;
  &lt;br&gt;
/* Define to the version of this package. */ &lt;br&gt;
#undef PACKAGE_VERSION &lt;br&gt;
  &lt;br&gt;
/* The size of a `char', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_CHAR 1 &lt;br&gt;
  &lt;br&gt;
/* The size of a `int', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_INT 4 &lt;br&gt;
  &lt;br&gt;
/* The size of a `int16_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_INT16_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `int32_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_INT32_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `int64_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_INT64_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `int8_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_INT8_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `long', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_LONG 4 &lt;br&gt;
  &lt;br&gt;
/* The size of a `long long', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_LONG_LONG &lt;br&gt;
  &lt;br&gt;
/* The size of a `short', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_SHORT 2 &lt;br&gt;
  &lt;br&gt;
/* The size of a `time_t', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_TIME_T 4 &lt;br&gt;
  &lt;br&gt;
/* The size of a `uint16_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_UINT16_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `uint32_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_UINT32_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `uint64_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_UINT64_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `uint8_t', as computed by sizeof. */ &lt;br&gt;
#undef SIZEOF_UINT8_T &lt;br&gt;
  &lt;br&gt;
/* The size of a `void *', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_VOID_P 4 &lt;br&gt;
  &lt;br&gt;
/* The size of a `__int64', as computed by sizeof. */ &lt;br&gt;
#define SIZEOF___INT64 8 &lt;br&gt;
  &lt;br&gt;
/* The sizeof a size_t, as computed by sizeof. */ &lt;br&gt;
#define SIZEOF_SIZE_T 4 &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if you have the ANSI C header files. */ &lt;br&gt;
#define STDC_HEADERS &lt;br&gt;
  &lt;br&gt;
/* Define to 1 if time_t is signed. */ &lt;br&gt;
#define TIME_T_IS_SIGNED &lt;br&gt;
  &lt;br&gt;
/* Define to 1 iff unaligned int access is allowed */ &lt;br&gt;
#define UNALIGNED_INT_ACCESS_OK &lt;br&gt;
  &lt;br&gt;
#define HAVE_EVENT_H &lt;br&gt;
  &lt;br&gt;
/* Define to 1 iff we represent negative integers with two's complement
*/ &lt;br&gt;
#define USING_TWOS_COMPLEMENT &lt;br&gt;
  &lt;br&gt;
/* Version number of package */ &lt;br&gt;
#define VERSION "0.2.3.0-alpha-dev" &lt;br&gt;
  &lt;pre wrap=""&gt;&lt;hr size="4" width="90%"&gt;
_______________________________________________
tor-dev mailing list
&lt;a class="moz-txt-link-abbreviated"
 href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;
&lt;a class="moz-txt-link-freetext"
 href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;
  &lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/body&gt;
&lt;/html&gt;


[Attachment #8 (image/jpeg)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110504052056</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-05-04 05:20:56-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On May 4, 2011, at 2:49 AM, Nick Mathewson wrote:

&gt; On Mon, May 2, 2011 at 5:23 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;&gt; 
&gt;&gt; On Mar 2, 2011, at 8:06 AM, Nick Mathewson wrote:
&gt;&gt; 
&gt;&gt;&gt; On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Design:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; When the consensus is generated, the directory authorities ensure that
&gt;&gt;&gt;&gt; a param is only included in the list of params if at least half of the
&gt;&gt;&gt;&gt; total number of authorities votes for that param. The value chosen is
&gt;&gt;&gt;&gt; the low-median of all the votes. We don't mandate that the authorities
&gt;&gt;&gt;&gt; have to vote on exactly the same value for it to be included because
&gt;&gt;&gt;&gt; some consensus parameters could be the result of active measurements
&gt;&gt;&gt;&gt; that individual authorities make.
&gt;&gt;&gt; 
&gt;&gt;&gt; This is possibly bikeshed, but I would suggest that instead of
&gt;&gt;&gt; requiring half of  existing authorities to vote on a particular
&gt;&gt;&gt; parameter, we require 3 or more to vote on it. (As a degenerate case,
&gt;&gt;&gt; fall back to "at least half" if there are fewer than 6 authorities in
&gt;&gt;&gt; the clique.)
&gt;&gt; 
&gt;&gt; Hrm. I'm not too happy with this,
&gt; 
&gt; My rationale was that in practice, it's a pain in practice to try to
&gt; get more than 3 or so authority operators to try out an experimental
&gt; parameter in a timely basis.  If the set of authority operators ever
&gt; grows, getting half of the ops to tweak a parameter in a hurry will
&gt; get even harder.

Yes, I understand that argument. On the other hand, getting a hold
of n-3 authority operators that did set a param can also be hard
(I'm thinking about the last time we thought that dirauths might crash
the network by distributing ipv6 descriptors, where it took a while to
even reach those who had applied our first patch).

&gt;&gt; unless we also include a way for a
&gt;&gt; majority of authorities to prevent voting on that parameter altogether.
&gt; 
&gt; What if we say that as a matter of design, there should always be, for
&gt; each parameter, a value that's semantically equivalent to the absence
&gt; of the parameter?  That way a majority of authorities can "turn off"
&gt; any parameter without any additional machinery during the vote.

This could work, but that means we need to re-implement a bunch of
our parameters that don't currently work that way. I'm thinking about
bug 1947 here, for example. Overloading the param value to mean
"this special integer means this specific param is not set" might also
lead to interesting situations where we aren't quite sure if 0 or
INT32_MIN or something else is responsible for disabling a param.
Maybe that's still easier to do than other ideas, and more convenient
in the common case where we don't have a bad param that we must
not set, which is what we should care about. I'm not sold on your
idea just yet, but I do think it can work.

Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507072623</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-07 07:26:23-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

[Attachment #2 (multipart/signed)]


On Sat, 7 May 2011 00:57:12 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Sat, May 7, 2011 at 12:47 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; &gt; On Fri, 6 May 2011 23:14:58 -0400
&gt; &gt; Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; &gt;
&gt; &gt;&gt; Also, as I said on the bug, doing a memcmp in constant time is harder
&gt; &gt;&gt; than doing eq/neq.   I *think* that all of the cases where we care
&gt; &gt;&gt; about memcmp returning a tristate -1/0/1 result, we don't need
&gt; &gt;&gt; data-independence... but in case we *do* need one, we'll have to do
&gt; &gt;&gt; some malarkey like
&gt; &gt;&gt;
&gt; &gt;&gt; int memcmp(const void *m1, const void *m2, size_t n)
&gt; &gt;&gt; {
&gt; &gt;&gt; /*XXX I don't know if this is even right; I haven't tested it at all */
&gt; &gt;&gt;    const uint8_t *b1 = m1, *b2 = m2;
&gt; &gt;&gt;    int retval = 0;
&gt; &gt;&gt;
&gt; &gt;&gt;    while (n--) {
&gt; &gt;&gt;       const uint8_t v1 = b1[n], v2 = b2[n];
&gt; &gt;&gt;       int diff = (int)v1 - (int)v2;
&gt; &gt;&gt;       retval = (v1 == v2) * retval + diff;
&gt; &gt;&gt;    }
&gt; &gt;&gt;
&gt; &gt;&gt;    return retval;
&gt; &gt;&gt; }
&gt; &gt;&gt;
&gt; &gt;&gt; which frankly makes me sad.   I bet there's a better way to go.
&gt; &gt;
&gt; &gt; See attached.   This one is also untested (and I didn't even put the
&gt; &gt; "#include &lt;stdint.h&gt;" in the file), but it *should* work.
&gt; &gt;
&gt; &gt; My technique for calculating equal_p came from my uint32-based
&gt; &gt; crypto_verify function in my previous message, which was in turn based
&gt; &gt; partly on DJB's crypto_verify functions and partly on a disassembly of
&gt; &gt; what GCC compiled DJB's functions to on a Fedora 12 AMD64 box.   But I
&gt; &gt; couldn't tell that the technique was correct, so this time I added
&gt; &gt; comments to it.
&gt; 
&gt; Clever!  It does look it *should* work.  Somewhere along the line we
&gt; should test the heck out of it and more sure it does.

It worked for me once I fixed it so it would compile.  See
&lt;http://repo.or.cz/w/tor-utils/rransom.git/shortlog/refs/heads/tor-safe-memcmp&gt;.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110509140003</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-05-09 14:00:03-0400</timestampReceived><subject>[tor-dev] Orbot 1.0.5 Release Candidate</subject><body>


Based on feedback from our core test group in the Guardian Project, it
seems like we have a solid new version of Orbot that includes Tor
0.2.2.25, as well as improved handling of transparent proxying. This new
build also includes our own version of iptables, and proactively checks
if the device has netfilter/owner support in the kernel. This should
lead to overall less support requests from confused users who have
"root" but still can't transproxy.

We have a few UI tweaks to make, and need to make sure all of our
translations are up-to-date, but otherwise, the app feels very ready to go.

I invite any of you with a few spare cycles and an Android device handy
to try it out if you haven't already. As this is a dev build, it is not
signed by the official Tor distro key, so you will have to uninstall any
existing Orbot official release. The final app we release to the market
will be signed by the Tor key, and users will get an automatic "updates
available" message from the Android market.

https://guardianproject.info/downloads/0.2.2.25-orbot-alpha-1.0.5.20110508a-dev.apk
(.asc - signed by nathan@guardianproject.info 0xB374CBD2)

If you aren't on our guardian-dev or -alpha lists, but are an Android
user, then I encourage you to join, as we keep most of the day to day
traffic on those lists:
https://guardianproject.info/contact/

Best,
 Nathan
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110503025115</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-03 02:51:15-0400</timestampReceived><subject>Re: [tor-dev] Mingw ann non-autoconf build</subject><body>

On Thu, Apr 28, 2011 at 8:29 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; I have a question regarding src/win32/orconfig.h. I guess this hand-
&gt; edited file is supposed to be used by MSVC (targeting Win32, WinCE and
&gt; whatnot).

That's the idea.

&gt;  Or? What prevents it from being used by e.g. MingW in a non-
&gt; autoconf build?

Nobody's tried it. :)

&gt; If someone (like me that doesn't want to touch autotool with a ten-feet
&gt; pole) want to use this file unchanged, things like:
&gt;  #undef HAVE_SYS_TIME_H
&gt;
&gt; has to be treated specifically for MingW. E.g.:
&gt;  #ifndef __MINGW32__
&gt;  #undef HAVE_SYS_TIME_H
&gt;  #endif
&gt;
&gt; Same goes for HAVE_UNISTD_H, HAVE_GETTTIMEOFDAY etc.
&gt;
&gt; BTW. Older MingW does not have gettimeofday(). I'm not sure
&gt; when the function was added. So to be perfect, an "#ifndef" test should
&gt; consider the __MINGW32_VERSION too.

It sounds a lot like you're using what I'd call an "unsupported build
environment": you want to build Tor on an old version of mingw, and
you don't want to use our regular autotools build process.  That's
fine, and we're not going to send out the Tor goon squad to go
confiscate your compiler or make you use autotools or anything, but
it's not something that I think we're going to put effort into
supporting.

But hey, it's free software. If you wanted to write and maintain an
alternative set of build scripts to work with different versions of
mingw, that would be great.  I could see merging those if they were
clean and didn't affect the mainline code too much.  I'd greatly
prefer a separate orconfig.h if you take this route: sharing the same
one between msvc and mingw seems like it's asking for trouble.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110502092302</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-05-02 09:23:02-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On Mar 2, 2011, at 8:06 AM, Nick Mathewson wrote:

&gt; On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt; 
&gt;&gt; Design:
&gt;&gt; 
&gt;&gt; When the consensus is generated, the directory authorities ensure that
&gt;&gt; a param is only included in the list of params if at least half of the
&gt;&gt; total number of authorities votes for that param. The value chosen is
&gt;&gt; the low-median of all the votes. We don't mandate that the authorities
&gt;&gt; have to vote on exactly the same value for it to be included because
&gt;&gt; some consensus parameters could be the result of active measurements
&gt;&gt; that individual authorities make.
&gt; 
&gt; This is possibly bikeshed, but I would suggest that instead of
&gt; requiring half of  existing authorities to vote on a particular
&gt; parameter, we require 3 or more to vote on it. (As a degenerate case,
&gt; fall back to "at least half" if there are fewer than 6 authorities in
&gt; the clique.)

Hrm. I'm not too happy with this, unless we also include a way for a
majority of authorities to prevent voting on that parameter altogether.
Doing the design as presented above would then be simpler.

&gt; I think we don't want the number to be _less_ than 3, since 3 is the
&gt; smallest number of parties who can come up with a low-median that
&gt; isn't just the diktat of a single member (1 party), or as low as
&gt; either member wants it to be (2 parties).

Yes, anything less than 3 is bad imo.

Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110506231338</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-05-06 23:13:38-0400</timestampReceived><subject>[tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>


Greetings all,

I happened to download the tor-0.2.2.25-alpha.tar.gz source yesterday 
and I noticed something. Apologies in advance if this has already been 
discussed and resolved, I did a cursory web search and didn't see anything.

There are a lot of places in the code where memcmp() is called on memory 
buffers that look like they might contain various hashes or digests:

    ~/tor-0.2.2.25-alpha$ grep -r memcmp . | grep -i digest | wc -l
    137

     ~/tor-0.2.2.25-alpha$ grep -r memcmp . | grep -i key | wc -l
     14

The built-in memcmp typically runs in time proportional to the common 
prefix of the two memory buffers being compared. In networked 
applications, this is often a significant source of timing information. 
Sometimes these are severe enough to result in disclosure of secret key 
material. A good resource for remote timing attacks is Nate Lawson's blog:

http://rdist.root.org/2010/07/19/exploiting-remote-timing-attacks/

Some cases look particularly concerning. For example, in the following 
code 'handshake_reply' appears to be supplied by the remote party and it 
is compared with something called "key material".

src/or/onion.c:331:
   if (memcmp(key_material, handshake_reply+DH_KEY_LEN, DIGEST_LEN)) {
     /* H(K) does *not* match. Something fishy. */
      log_warn(LD_PROTOCOL,"Digest DOES NOT MATCH on onion handshake. "
            "Bug or attack.");
     goto err;
   }

In the worst-case, the attacker could simply supply different values of 
handshake_reply, observe how long each takes to compare, and figure out 
the value of key_material statistically byte-by-byte.

Perhaps this key material is never used again, or there are other 
reasons this timing informaion is not useful. But in general, it's very 
difficult to determine whether or not such a timing info disclosure 
represents a vulnerability or how difficult it would be to exploit. 
Expert programmers seem to consistently underestimate the severtiy of 
these weaknesses, perhaps because they are so subtle. I've just started 
learning about Tor so it's not possible for me to review every instance.

I think the quickest and easiest solution would be to replace every 
usage of memcmp and str*cmp in the source with an alternate version that 
guarantees a constant time comparison.

I'd expect this could be done with negligible performance impact, 
especially for short comparisons like 20-byte hash values.

Regards,

- Marsh





_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110506155146</emailId><senderName>       Bjrn Scheuermann</senderName><senderEmail></senderEmail><timestampReceived>2011-05-06 15:51:46-0400</timestampReceived><subject>[tor-dev] Fairness between circuits</subject><body>

Hi all,

my group and I have recently been working on the question whether
multiple circuits in Tor share the available bandwidth fairly and
reasonably. What we found is: they don't. Not at all.

First, we developed an analytical model for the fairness between
circuits in an anonymity overlay, and thought about how to define
fairness in a setting like Tor: when can the bandwidth sharing between
many circuits in a complex anonymity overlay with varying available
router bandwidth be called "fair"? In short: an adaptation of the
max-min fairness concept does a very good job here.

In order to overcome the existing fairness problems in Tor, we also
developed a (surprisingly simple) mechanism which achieves max-min
fairness without exchanging any additional data about the circuits
between onion routers - the latter is clearly a nice trait with respect
to privacy. We found that this approach goes very well with the recently
proposed N23 congestion feedback scheme from the guys at
Waterloo/Colorado/San Diego.

We implemented Tor's scheduling mechanisms, the N23 extension, and our
fairness mechanism in an event-based network simulator (ns-3).
Independent from the question of inter-circuit fairness, we were able to
confirm the key findings in the DefenestraTor tech report with respect
to N23 based on this independent implementation. Moreover, we found that
N23 does not solve the fundamental fairness problems - but N23 in
combination with our fairness mechanism does an excellent job in this
regard.

We explain all this in much more detail in a paper:

  F. Tschorsch, B. Scheuermann: Tor is Unfair - and What to Do About It
  http://robotik.informatik.uni-wuerzburg.de/tr481.pdf

We're hoping for feedback and vivid discussions - we would be really
interested in bringing these mechanisms into Tor.


Best regards

Bjrn


-- 
Prof. Dr. Bjrn Scheuermann
Chair of Computer Science VII
University of Wrzburg
Am Hubland, 97074 Wrzburg, Germany

Tel.: +49 931 31 85402
scheuermann@informatik.uni-wuerzburg.de
http://www7.informatik.uni-wuerzburg.de


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512025937</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-12 02:59:37-0400</timestampReceived><subject>Re: [tor-dev] Fairness between circuits</subject><body>

2011/5/6 Bjrn Scheuermann &lt;scheuermann@informatik.uni-wuerzburg.de&gt;:
[...]
&gt; We implemented Tor's scheduling mechanisms, the N23 extension, and our
&gt; fairness mechanism in an event-based network simulator (ns-3).
&gt; Independent from the question of inter-circuit fairness, we were able to
&gt; confirm the key findings in the DefenestraTor tech report with respect
&gt; to N23 based on this independent implementation. Moreover, we found that
&gt; N23 does not solve the fundamental fairness problems - but N23 in
&gt; combination with our fairness mechanism does an excellent job in this
&gt; regard.
&gt;
&gt; We explain all this in much more detail in a paper:
&gt;
&gt;  F. Tschorsch, B. Scheuermann: Tor is Unfair - and What to Do About It
&gt;  http://robotik.informatik.uni-wuerzburg.de/tr481.pdf
&gt;
&gt; We're hoping for feedback and vivid discussions - we would be really
&gt; interested in bringing these mechanisms into Tor.

Hi!  Let me kick the discussion off by asking how your work relates
(if at all!) to:

  1) This other work on using N23 with Tor ("DefenstraTor: Throwing
out Windows in Tor" by AlSabah, Bauer, Goldberg, Grunwald, McCoy,
Savage, and Voelker):
       http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-06.pdf
      (IMO it's a promising sign that two groups seem to be
independently converging on the same basic algorithm family.)

  2) The priority-queue-based circuit scheduling code originally
merged in Tor 0.2.2.7-alpha (starting with commit d3be00e0f).

  3) Your other scheduling/bandwidth allocation work (ticket 2536)

I'd also be interested in hearing what the DefenestraTor authors think
about above-linked paper and
the topic in general.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512085406</emailId><senderName>       Bjrn Scheuermann</senderName><senderEmail></senderEmail><timestampReceived>2011-05-12 08:54:06-0400</timestampReceived><subject>Re: [tor-dev] Fairness between circuits</subject><body>

Hi Nick,

thanks for the feedback!

&gt;   1) This other work on using N23 with Tor ("DefenstraTor: Throwing
&gt; out Windows in Tor" by AlSabah, Bauer, Goldberg, Grunwald, McCoy,
&gt; Savage, and Voelker):
&gt;        http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-06.pdf
&gt;       (IMO it's a promising sign that two groups seem to be
&gt; independently converging on the same basic algorithm family.)

Actually, it's not independent. 

I should maybe give a bit more context here. Fairness is very closely
related to congestion control - in fact, both aspects can hardly be
separated at all in practice. When thinking about fairness and
congestion control, there's basically two (closely interrelated) key
questions to answer: 1) how to provide feedback on whether the source
should send less/more, and 2) how to determine which user is allowed to
send how much. The latter is the fairness aspect.

In order to tackle Tor's congestion problems, we started from the
fairness "side" some time ago - and, as we believe, we found a nice
solution. Such a solution doesn't help much, though, if you don't have a
feedback mechanism to throttle the sources accordingly - just like a
feedback mechanism without reasonable fairness properties is just half
as much fun.

When we saw the DefenestraTor paper, we noticed that the feedback
mechanism they proposed - using N23 from ATM in Tor - is in fact a very
nice "counterpart" to our fairness mechanism. So, "their" N23 is the
same as "our" N23 - we contribute the other "half", the fairness side.

More details on the interrelation are described in our paper.

&gt;   2) The priority-queue-based circuit scheduling code originally
&gt; merged in Tor 0.2.2.7-alpha (starting with commit d3be00e0f).

We expect that if the bandwidth allocation to circuits is fair right
from the start, the problem addessed there will no longer exist. To put
it short: this mechanism is kind of a "hotfix" addressing the
"symptoms", we aim to cure the root cause. :)

It might, at some point in the future, be wise to assess whether this
expectation is true or whether we missed an important effect. If really
necessary, then it will be easy to implement something similar in
combination with our fairness mechanism. For my part, I would really
like to avoid this, though - not because I don't like the mechanism, but
because I firmly believe that the best solution is the simplest good
solution. That is: the aim should be to get rid of the problems *and* of
the high complexity of the current design.

&gt;   3) Your other scheduling/bandwidth allocation work (ticket 2536)

This addresses a different problem. Ticket 2536 is concerned with the
bandwidth management "within" one OR - don't read more than you are
allowed to write within a reasonable time frame. The fairness tech
report looks at it from the perspective of the network as a whole. It
addresses the question which circuit should receive which share of the
overlay's resources so that no user can gain an unfair advantage.

When, at some point, the fairness mechanisms get closer towards
deployment, it would of course be advisable to have a closer look at the
combination of these mechanisms and their interplay. After all, they
require modifications in similar parts of the code. But I don't think
that it is necessary (or particularly helpful) to do so now, due to the
different time frame: the time horizon for 2536 is certainly much
shorter than that for our fairness proposal and/or N23, because 2536 is
far less "intrusive".


Cheers

Bjrn


-- 
Prof. Dr. Bjrn Scheuermann
Chair of Computer Science VII
University of Wrzburg
Am Hubland, 97074 Wrzburg, Germany

Tel.: +49 931 31 85402
scheuermann@informatik.uni-wuerzburg.de
http://www7.informatik.uni-wuerzburg.de

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512112604</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 11:26:04-0400</timestampReceived><subject>Re: [tor-dev] Fairness between circuits</subject><body>

I agree with most of Bjrn's post, but disagree slightly here:

On Thu, May 12, 2011 at 10:54:06AM +0200, Bjrn Scheuermann wrote:
&gt; &gt;   2) The priority-queue-based circuit scheduling code originally
&gt; &gt; merged in Tor 0.2.2.7-alpha (starting with commit d3be00e0f).
&gt; 
&gt; We expect that if the bandwidth allocation to circuits is fair right
&gt; from the start, the problem addessed there will no longer exist. To put
&gt; it short: this mechanism is kind of a "hotfix" addressing the
&gt; "symptoms", we aim to cure the root cause. :)
&gt; 
&gt; It might, at some point in the future, be wise to assess whether this
&gt; expectation is true or whether we missed an important effect. If really
&gt; necessary, then it will be easy to implement something similar in
&gt; combination with our fairness mechanism. For my part, I would really
&gt; like to avoid this, though - not because I don't like the mechanism, but
&gt; because I firmly believe that the best solution is the simplest good
&gt; solution. That is: the aim should be to get rid of the problems *and* of
&gt; the high complexity of the current design.

The EWMA stuff isn't _trying_ to be fair; it's explicitly trying to
prioritize circuits for which users will gain utility from lower
latency, and deprioritize circuits for which users don't care about
latency.  That said, it's still kind of fair, as circuits with similar
usage patterns will get similar service.

The main difference is that if you've got a bunch of circuits that need
servicing, a fair round-robin doesn't care if you service them in the
order A,B,C,D,E,A,B,C,D,E or E,B,A,C,D,E,B,A,C,D, or even
E,B,D,A,C,A,E,B,C,D.  All are equally fair.  The observation in our CCS
paper is that it _does_ matter to the user, if some of the circuits are
interactive, and others are not.  Indeed, if A is interactive and hasn't
sent packets in a while, it might get A,A,A,C,E,B,D so that it can
"catch up".

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110507000813</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-05-07 00:08:13-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

Hi Marsh,

Thanks for writing to or-dev, welcome to the list!

On 05/06/2011 04:13 PM, Marsh Ray wrote:
&gt; 
&gt; Greetings all,
&gt; 
&gt; I happened to download the tor-0.2.2.25-alpha.tar.gz source yesterday
&gt; and I noticed something. Apologies in advance if this has already been
&gt; discussed and resolved, I did a cursory web search and didn't see anything.

After some of our discussions and some thinking, I opened this bug:
https://trac.torproject.org/projects/tor/ticket/3122

&gt; 
&gt; There are a lot of places in the code where memcmp() is called on memory
&gt; buffers that look like they might contain various hashes or digests:
&gt; 
&gt;    ~/tor-0.2.2.25-alpha$ grep -r memcmp . | grep -i digest | wc -l
&gt;    137
&gt; 
&gt;     ~/tor-0.2.2.25-alpha$ grep -r memcmp . | grep -i key | wc -l
&gt;     14
&gt; 
&gt; The built-in memcmp typically runs in time proportional to the common
&gt; prefix of the two memory buffers being compared. In networked
&gt; applications, this is often a significant source of timing information.
&gt; Sometimes these are severe enough to result in disclosure of secret key
&gt; material. A good resource for remote timing attacks is Nate Lawson's blog:
&gt; 
&gt; http://rdist.root.org/2010/07/19/exploiting-remote-timing-attacks/
&gt; 

Nate's post is great and anyone reading this email should read the above
url for context. I'd also suggest this one:
http://rdist.root.org/2010/01/07/timing-independent-array-comparison/

&gt; Some cases look particularly concerning. For example, in the following
&gt; code 'handshake_reply' appears to be supplied by the remote party and it
&gt; is compared with something called "key material".
&gt; 
&gt; src/or/onion.c:331:
&gt;   if (memcmp(key_material, handshake_reply+DH_KEY_LEN, DIGEST_LEN)) {
&gt;     /* H(K) does *not* match. Something fishy. */
&gt;      log_warn(LD_PROTOCOL,"Digest DOES NOT MATCH on onion handshake. "
&gt;            "Bug or attack.");
&gt;     goto err;
&gt;   }
&gt; 
&gt; In the worst-case, the attacker could simply supply different values of
&gt; handshake_reply, observe how long each takes to compare, and figure out
&gt; the value of key_material statistically byte-by-byte.
&gt; 
&gt; Perhaps this key material is never used again, or there are other
&gt; reasons this timing informaion is not useful. But in general, it's very
&gt; difficult to determine whether or not such a timing info disclosure
&gt; represents a vulnerability or how difficult it would be to exploit.
&gt; Expert programmers seem to consistently underestimate the severtiy of
&gt; these weaknesses, perhaps because they are so subtle. I've just started
&gt; learning about Tor so it's not possible for me to review every instance.
&gt; 

I generally agree - I think it's best to use a constant time comparison
unless you're *certain* that you want something else.

&gt; I think the quickest and easiest solution would be to replace every
&gt; usage of memcmp and str*cmp in the source with an alternate version that
&gt; guarantees a constant time comparison.

I think it's probably a good idea to write a new set of functions, say
safe_memcmp and safe_strcmp, that are properly implemented. We can
#define over memcmp but I fear that it's better to specifically
eradicate each one by hand and really think things over on a case by
case basis.

&gt; 
&gt; I'd expect this could be done with negligible performance impact,
&gt; especially for short comparisons like 20-byte hash values.
&gt; 

I think so too.

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110506145005</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-06 14:50:05-0400</timestampReceived><subject>[tor-dev] New paper by Goldberg, Stebila,</subject><body>

Crypto people who have been following threads about the
circuit-establishment handshake will be interested in the new paper,
"Anonymity and one-way authentication in key-exchange protocols", by
Goldberg, Stebila, and Ostaoglu. Here's the version they updated
today:

http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-11.pdf

If we're moving to an improved handshake, this might be a good
candidate to consider.  The protocol itself is on page 14.

Some notes, written by a guy who knows less crypto than everybody involved:

  * It's a pure Diffie-Hellman based system, which would lend itself
nicely to use with ECC.

  * It seems to require the same number of exponentiations as our
current system, but Ian Goldberg notes that if you want to compute X^a
and X^b at the same time you can do so more efficiently by taking into
account the shared base.

  * The security proof requires that the Gap DH assumption holds over
the group -- basically, that computing the Decisional DH problem is
easy, but computing the Computational DH problem is hard.  This
assumption isn't true of most basic ECC groups -- I think it means you
need to use a pairing-based system instead for the proof to hold. I'd
bet that the authors aren't seriously suggesting that we use
pairing-based crypto, but I'm wondering how much they were able to
prove in a groups where DDH is hard.

  * I haven't read over the security model closely yet; folks should
review it for reasonableness.

  * I'm hoping to write this up as a proposed spec soon, unless Ian or
somebody wants to give it a shot.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110506151227</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-06 15:12:27-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

[+ Douglas, Berkant]

On Fri, May 06, 2011 at 10:50:05AM -0400, Nick Mathewson wrote:
&gt; Crypto people who have been following threads about the
&gt; circuit-establishment handshake will be interested in the new paper,
&gt; "Anonymity and one-way authentication in key-exchange protocols", by
&gt; Goldberg, Stebila, and Ostaoglu. Here's the version they updated
&gt; today:
&gt; 
&gt; http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-11.pdf
&gt; 
&gt; If we're moving to an improved handshake, this might be a good
&gt; candidate to consider.  The protocol itself is on page 14.
&gt; 
&gt; Some notes, written by a guy who knows less crypto than everybody involved:
&gt; 
&gt;   * It's a pure Diffie-Hellman based system, which would lend itself
&gt; nicely to use with ECC.
&gt; 
&gt;   * It seems to require the same number of exponentiations as our
&gt; current system, but Ian Goldberg notes that if you want to compute X^a
&gt; and X^b at the same time you can do so more efficiently by taking into
&gt; account the shared base.
&gt; 
&gt;   * The security proof requires that the Gap DH assumption holds over
&gt; the group -- basically, that computing the Decisional DH problem is
&gt; easy, but computing the Computational DH problem is hard.  This
&gt; assumption isn't true of most basic ECC groups -- I think it means you
&gt; need to use a pairing-based system instead for the proof to hold. I'd
&gt; bet that the authors aren't seriously suggesting that we use
&gt; pairing-based crypto, but I'm wondering how much they were able to
&gt; prove in a groups where DDH is hard.

Not quite: it's saying that, if you can break the protocol (_with or
without_ the ability to solve DDH), then if you _do_ have a DDH oracle,
you can also solve CDH.  Since being able to solve CDH given a DDH
oracle (the "GDH problem") would be extremely surprising, we conclude
the protocol is secure.

&gt;   * I haven't read over the security model closely yet; folks should
&gt; review it for reasonableness.
&gt; 
&gt;   * I'm hoping to write this up as a proposed spec soon, unless Ian or
&gt; somebody wants to give it a shot.

Please go ahead.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110502093826</emailId><senderName>"Jan G."</senderName><senderEmail>me@nubix.net</senderEmail><timestampReceived>2011-05-02 09:38:26-0400</timestampReceived><subject>[tor-dev] TorStatus</subject><body>

Hey,

im trying to port TorNetworkStatus to Ruby.

I took a look at the Trac and it looks like it's project that should be  
done at the GSoC.
https://trac.torproject.org/projects/tor/wiki/projects/TorStatus

Is anyone working at this now?


Greetings,

J
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110515215328</emailId><senderName>Lucky Green</senderName><senderEmail>shamrock@cypherpunks.to</senderEmail><timestampReceived>2011-05-15 21:53:28-0400</timestampReceived><subject>[tor-dev] IPv6 Thoughts</subject><body>

I just read nickm's post on Tor IPv6 migration at
https://blog.torproject.org/blog/ipv6-future-i-hear
---
What needs to change
Tor uses the Internet in many ways. There are three main ways that will
need to change for IPv6 support, from most urgent to least urgent.

Tor must allow connections from IPv6-only clients. (Currently, routers
and bridges do not listen on IPv6 addresses, and can't advertise that
they support IPv6 addresses, so clients can't learn that they do.)

Tor must transport IPv6 traffic and IPv6-related DNS traffic.
(Currently, Tor only allows BEGIN cells to ask for connections to IPv4
targets or to hostnames, and only allows RESOLVE cells to request A and
PTR records.)

Tor must allow nodes to connect to one another over IPv6.
Allowing IPv6-only clients is the most important, since unless we do,
these clients will be unable to connect to Tor at all. Next most
important is to support IPv6 DNS related dependencies and exiting to
IPv6 services. Finally, allowing Tor nodes to support a dual stack of
both IPv4 and IPv6 for interconnection seems like a reasonable step
towards a fully hybrid v4/v6 Tor network.
---

One thought that may or may not be relevant to your sequence of
implementation, but that you should be made aware of if you aren't
already. (You may well be already be aware of it).

The most important IPv6 compatibility task in Tor is that the Tor
servers can accept inbound connections over IPv6. The second most
important task is that Tor servers can make outbound IPv6 connections to
services on the Internet.

This is, and that may not be intuitive, not isomorphic with Tor clients
being able to perform outbound connections to Tor servers over IPv6.

Jane Tor User's laptop does, in all likelihood, not have a globally
routable IP address. Instead, Jane's laptop has been assigned an RFC
1918 address by her cable modem or the NAT at the Internet cafe.

It is Jane's cable modem that either does today or very soon will use an
IPv6 address to communicate upstream. If the Tor server to which Jane is
connecting does not support native IPv6, then Jane's provider will have
to force her Tor traffic through a provider-level IPv6-to-IPv4 gateway.

Some days that gateway will work well. Other days that proxy will be
overloaded and won't work all that well. Both days, traffic latency will
be increased unless the Tor server to which Jane connects accepts
inbound IPv6.

This talk by ARIN's CEO John Curran explains the issue beautifully.
Watch from the 8 minute mark:
http://www.youtube.com/watch?v=S3i4RRubCvI

(When traffic has to be forced through a provider-level gateway out of
technical necessity, obvious opportunities for easy filtering arise that
I will not explore further in this post).

In summary, outbound IPv6 Tor connections from end-users can wait until
after Tor servers accept inbound IPv6 connections (and after exit nodes
can make outbound IPv6 connections to other services).

--Lucky
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110509165412</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-09 16:54:12-0400</timestampReceived><subject>[tor-dev] May Tor proposal status, and proposal plans for 0.2.3</subject><body>

Hi, all!  When Roger was at my house the week before last, we spent
some time trying to triage currently open proposals for 0.2.3.x.  I've
spent some time revising the list of proposal statuses that I sent out
in early March to reflect that conversation.  Here's the current list
of proposal statuses, plus a list of those that we would like to
target for 0.2.3.

Note that this is a *tentative* list of stuff for 0.2.3, not a final
list.  Given a goal of getting 0.2.3.x-stable out much more quickly
than 0.2.2.x-stable, we may need to let unfinished items wait until
0.2.4.  I'll be trying to work out a release schedule over the course
of this week (to fit in with commitments we've made and time we have).
 That said, the distinction between "nice to have for 0.2.3" and
"targeted for 0.2.3" is that the "targeted for 0.2.3" items are the
ones I would currently consider delaying the release a little for,
whereas the others would be neat to focus on, but great whenever they
land.


===== FINISHED SINCE MARCH 2:

These were actually implemented and merged since March 2:
  158  Clients download consensus + microdescriptors
  162  Publish the consensus in multiple flavors
  174  Optimistic Data for Tor: Server Side [CLOSED]

These ones were implemented (in full or in part) all along:
  149  Using data from NETINFO cells
  163  Detecting whether a connection comes from a client
  166  Including Network Statistics in Extra-Info Documents

These were superseded in full:
  170  Configuration options regarding circuit building

===== TARGETED FOR 0.2.3

  110 Avoiding infinite length circuits

    This proposal solves a potential DoS attack.

    This has been nearly completely implemented for a while.  All we
    need to do is verify that there are no clients that do not send
    RELAY_EARLY cells correctly, and if so, turn on the code that drops
    EXTEND cells not sent via RELAY_EARLY.  The hard part here is
    double-checking that all the clients that send EXTEND commands
    inside non-RELAY_EARLY cells are really and truly obsolete.

  117 IPv6 exits

    This proposal describes how to transmit IPv6 traffic over Tor.

    It needs updating to work properly with microdescriptors; it also
    has some open questions about DNS.

    We should revise this to bring it up-to-date for microdescriptors
    and what we now know about DNS, and try to get it into 0.2.3.x.

  147 Eliminate the need for v2 directories in generating v3 directories

    This proposal explains a way that we can phase out the vestigial use
    of v2 directory documents in keeping authorities well-informed
    enough to generating the v3 consensus.  It's still correct; somebody
    should implement it before the v2 directory code rots any further.

  157 Make certificate downloads specific

    This proposal added cross-certification and signing-key-specific
    download URLs for directory authority certificates.  It is IIRC
    mostly implemented; there are just some SHOULDs that we should turn
    into MUSTS if all sufficiently old authority certificates are now
    obsolete.

  171 Separate streams across circuits by connection metadata

    This proposal describes a way to prevent cross-application linking
    of different anonymized sessions by isolating different kinds of
    streams on different circuits based on their characteristics.

    Robert Hogan did an implementation for a much earlier version of
    this proposal that distinguished only based on ports; this could
    serve as the basis of a new proposal, or not.

  176 Proposed version-3 link handshake for Tor

    Here's my proposal for how to improve our TLS handshake to eliminate
    renegotiation, become less fingerprintable, and generally make the
    world a better place.  It needs more review by actual crypto people,
    but I would like to get it into 0.2.3.x.

  178 Require majority of authorities to vote for consensus parameters

    This is a proposal for making it a little harder for a small number
    of authorities to influence the value of a consensus parameter.  It
    needs more discussion; Sebastian has a draft implementation in his
    "safer_params" branch.

  179 TLS certificate and parameter normalization

    Here's a proposal that describes better ways to come up with TLS
    parameters (including DH parameter values and X.509 cetificates) to
    make our protocol even harder to fingerprint.

    Jacob has an implementation in progress.

  180 Pluggable transports for circumvention

    And this one is the sledgehammer of circumvention support: it
    describes

    There's Google Summer of Code student (George) planning to spend
    some time working on this one.

===== NICE-TO-HAVE FOR 0.2.3

   118 Advertising multiple ORPorts at once

    This proposal describes how an OR can advertise more than one
    address and OR port at a time.  It needs to be updated to work with
    microdescriptors, and to explain how much information can be
    transmitted in the consensus and how (the original proposal was
    written before consensus directories were really figured out).

   140 Provide diffs between consensuses

    This proposal describes a way to transmit less directory traffic by
    sending only differences between consensuses, rather than the
    consensuses themselves.  It is mainly languishing for lack of an
    appropriately licensed, well-written, very small, pure-C
    implementation of the "diff" and "patch" algorithms.  (The good
    diffs seem to be GPL (which we can't use without changing Tor's
    license), or spaghetti code, or not easily usable as a library, or
    not written in C, or very large, or some combination of those.)

   143 Improvements of Distributed Storage for Tor Hidden Service
   Descriptors

     Here's a proposal from Karsten about making the hidden service DHT
     more reliable and secure to use.  It could use more discussion and
     analysis.

   164 Reporting the status of server votes

     This proposal explains a way for authorities to provide a slightly
     more verbose document that relay operators can use to diagnose
     reasons that their router was or was not listed in the consensus.
     These documents would be like slightly more verbose versions of the
     authorities' votes, and would explain *why* the authority voted as
     it did.  It wouldn't be too hard to implement, and would be a fine
     project for somebody who wants to get to know the directory code.

   168 Reduce default circuit window

     This proposal reduces the default window for circuit sendme cells.
     I think it's implemented, isn't it?  If so, we should make sure
     that tor-spec.txt is updated and close it.

   172 GETINFO controller option for circuit information
   173 GETINFO Option Expansion

    These would help controllers (particularly arm) provide more useful
    information about a running Tor process.  They're accepted and some
    parts of 173 are even implemented: somebody just needs to implement
    the rest.

   177 Abstaining from votes on individual flags

     Here's my proposal for letting authorities have opinions about some
     (flag,router) combinations without voting on whether _every_ router
     should have that flag.  It's simple, and I think it's basically
     right.  With more discussion and review, somebody could/should
     build it for 0.2.3.x, I think.

===== OPEN:

   145 Separate "suitable as a guard" from "suitable as a new guard"

     Currently, the Guard flag means both "You can use this node as a
     guard if you need to pick a new guard" and "If this node is
     currently your guard, you can keep using it as a guard."  This
     proposal tries to separate these two concepts, so that clients can
     stop picking a router once it is full of existing clients using it
     as a guard, but the clients currently on it won't all drop it.

     It's not clear whether this has anonymity issues, and it's not
     clear whether the imagined performance gains are actually
     worthwhile.

   146 Add new flag to reflect losing-term stability

     From time to time we get the idea of having clients ship with a
     reasonably recent consensus (or a list of directory mirrors), so
     instead of bootstrapping from one of the authorities, they can
     bootstrap from a regular directory cache.  The problem here is that
     by the time the client is run, most of the directory mirrors will
     be down or will have changed their IP.  This proposal tries to
     address that.

     It needs analysis based on behavior of actual routers on the
     network to see whether it could work, and what parameters might
     work.

   156 Tracking blocked ports on the client side

     This proposal provides a way for clients to learn which ports they
     are (and aren't) able to connect to, and connect to the ones that
     work.  It comes with a patch, too.  It also lets routers track
     ports that _they_ can't connect to.

     I'm a little unconvinced that : most clients that have some ports
     blocked will need bridges, not just restriction to a smaller set of
     ports.  This could be good behind restrictive firewalls, though.

     The router-side part is a little iffy: routers that can't connect
     to each other violate one of our network topology assumptions, and
     even if we do want to track failed router-&gt;router connections, the
     routers need to be sure that they aren't fooled into trying to
     connect repeatedly to a series of nonexistent addresses in an
     attempt to make them believe that (say) they can't reach port 443.

     This one is a paradigmatic "open" proposal: it needs more
     discussion.  The patch probably also needs to be ported to 0.2.3.x;
     it touches some code that has changed.

   159 Exit Scanning

     This is an overview of SoaT, with some ideas for how to integrate
     it into Tor.

   165 Easy migration for voting authority sets

     This is a design for how to change the set of authorities without
     having a flag day where the authority operators all reconfigure
     their authorities at once.  It needs more discussion.  One
     difficulty here is that we aren't talking much about changing the
     set of authorities, but that may be a chicken-and-egg issue, since
     changing the set is so onerous.

     If anybody is interested, it would be great to move the discussion
     ahead here.

===== DRAFT:

   127 Relaying dirport requests to Tor download site / website

    The idea here was to make it easier to fetch and learn about Tor by
    making it easy for relays to automatically act as proxies to the Tor
    website.  It needs more discussion, and there are some significant
    details to work out.  It's not at all clear whether this is actually
    a good idea or not.

   132 A Tor Web Service For Verifying Correct Browser Configuration

    This proposal was meant to give users a way to see if their browser
    and privoxy (yes, it was a while ago) are correctly configured by
    running a local webserver on 127.0.0.1.  I'm not sure the status
    here.

   133 Incorporate Unreachable ORs into the Tor Network

    This proposal had an idea for letting ORs that can only make
    outgoing connections still relay data usefully in the network.  It's
    something we should keep in mind, and it's a pretty neat idea, but
    it radically changes the network topology.  Anybody who wants to
    analyze new network topologies should definitely have a look.

   141 Download server descriptors on demand

    The idea of this proposal was for clients to only download the
    consensus, and later ask nodes for their own server descriptors
    while building the circuit through them.  It would make each circuit
    more time-consuming to build, but make bootstrapping much cheaper.

    A microdescriptor-based version of this would be even better, and
    microdescriptors would solve a lot of the problem that this was
    meant to resolve.  It still is not wholly superseded by the
    microdescriptor system, though.

   144 Increase the diversity of circuits by detecting nodes belonging
   the same provider

    This is a version of the good idea, "Let's do routing in a way that
    tries to keep from routing traffic through the same provider too
    much!"  There are complex issues here that the proposal doesn't
    completely address, but I think it might be a fine idea for somebody
    to see how much more we know now than we did in 2008, particularly
    in light of the relevant paper(s) by Matt Edmann and Paul Syverson.

   175 Automatically promoting Tor clients to nodes

    Here's Steven's proposal for adding a mode between "client mode" and
    "relay mode" for "self-test to see if you would be a good relay, and
    if so become one."  It didn't get enough attention when it was
    posted to the list; more people should review it.


===== NEEDS-REVISION: 131 Help users to verify they are using Tor

     Here's a proposal for making a torcheck-like website more reliable.
     If anybody wants to pick it up (especially somebody working on
     torcheck) and see whether it should be reopened or rejected, that
     would be a fine thing.

====== "IDEAS":

   xxx-bwrate-algs.txt

     Here's a note about better round-robin calculations for rate
     limiting.  Mike wrote it; I don't understand what's going on with
     it.

   xxx-choosing-crypto-in-tor-protocol.txt

     Here's the start of a considerations document that Marian was
     writing about how to pick new crypto algorithms to migrate to.

   xxx-controllers-intercept-extends.txt

     Here's an old idea from Geoff Goodell about letting controllers
     intercept EXTEND commands.  It is partially superseded by Damian's
     172, though there is an additional feature that doesn't make sense
     for the Tor network, but might make sense for experimental stuff
     like Geoff was working on.

   xxx-crypto-migration.txt

     Here's the document I wrote in December about which parts of our
     crypto there are to migrate, and what might be involved.  This
     isn't a draft or pre-draft of a design proposal; it is more of a
     new category of "survey of stuff we need to design and think
     about", or "proposal for proposals" or something.

   xxx-crypto-requirements.txt

     Here's Robert Ransom's draft for what crypto properties, exactly,
     we're trying to get out of our circuit crypto.  It is not a
     proposal draft or pre-draft: it is again a "design considerations"
     document, and one worth reading.

   xxx-draft-spec-for-TLS-normalization.txt

     Here's Jacob's proposal for certificate normalization.  It should
     get renamed, given a proposal number, and called "Open" or "Draft"
     depending on how much the details are likely to change.

   xxx-encrypted-services.txt

     This is a start-of-a-proposal of Rogers that somebody should pick
     up and finish some time: The idea is to use the hidden service
     mechanism to provide a secure naming and encrypted connection
     facility for hosting sites that do not actually want anonymity
     themselves.  There's been more interest in this topic lately.  It
     might also turn into "exit enclaves done right".

   xxx-exit-scanning-outline.txt

     Looks like this was superseded by 159?

   xxx-geoip-survey-plan.txt

     Here's an old document I wrote a while ago about tracking usage by
     country.  Probably it should go into the metrics documentation
     somewhere (if we do this), or get thrown into "old" (if we won't do
     this), or updated (if we might someday do this).

   xxx-grand-scaling-plan.txt

     Here are some notes on scaling that Roger wrote in 2008.  There
     might be some smart ideas here!  Have a look some time.

   xxx-hide-platform.txt

     Here's a proposal pre-draft that says we should normalize the
     platform string.  Somebody could turn this into a proposal pretty
     easily.

   xxx-ipv6-plan.txt

     Here's a survey of what we need to do for IPv6 support that I
     started writing.  It's not a proposal; it's a survey of proposal
     and implementation statuses.

   xxx-pluggable-transport.txt

     Here's the thing Jacob and I have been working on for pluggable
     obfuscation techniques.  It should get turned into "Draft" status
     asap, if not "Open".  We should finish writing the missing
     sections, like, yesterday.

   xxx-port-knocking.txt

     Here's a pre-proposal from Jacob about using port knocking to make
     bridges harder to fingerprint.  This could be a good idea for
     somebody to do in terms of the pluggable transport spec.

   xxx-rate-limit-exits.txt

     Here are some notes of Roger's from 2008 claiming that we should
     rate-limit stream creation at exit nodes.  It could help avoid
     port-scans if we do it right, but we would need to be exceedingly
     careful not to disrupt useful traffic.

   xxx-using-spdy.txt

     Here's a document from Steven about opportunistic use of SPDY over
     Tor.

     This should be a "Draft" proposal IMO.

   xxx-what-uses-sha1.txt

     Here's the beginnings of a survey of where Tor uses SHA1, with an
     eye to stopping.  This really isn't a design proposal; it might
     fall into a new category of "issue survey" or "information" or
     something.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512145911</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-05-12 14:59:11-0400</timestampReceived><subject>[tor-dev] Tor meets real users</subject><body>

A short while ago, I did a training for some activists from a country
that is hostile to the Internet.  These people were some of the more
technical people from their community.  There was a mix of Windows and
OS X laptops in the session.  English was their third language, for
added fun.

I walked them through finding tor browser bundle, downloading it,
verifying it, unzipping it, and starting it.  Here was the first
problem.  They couldn't find tbb on the download page.  Their comments
were that all these files and releases on the page were confusing.
They wanted just one thing to look at, pick their operating system, and
go.  And they wanted the one thing to automatically detect their
language preferences for tbb.

I ended up pointing them at tpo/torbrowser, which they also thought was
confusing.  The aforementioned desires weren't satisfied on this page,
but at least they could find their preferred language.  They all
commented that back home, a 24MB file was too big, and can't they get
it via bittorrent or some other piecemeal way?  A 24mb file would take
hours to download.

Once they finally downloaded it, they all double clicked on their
resulting zip file.  In fact, all of the mac people ended up
downloading the windows tbb and unzipped it correctly.  In all cases,
their operating system handled the zip file correctly. After fixing the
mac people with mac tbb, we moved on to the next step.

None of them had pgp installed, and therefore no way to verify the .asc
and zip file.

Most of them figured out to click inside the resulting folder and start
the 'start tor browser' program.  For all of the macs, the tbb didn't
start.  The people had to restart the system and then clicking on
'start tor browser' worked as expected.  

As tbb was starting up, nearly all of them clicked on 'start tor
browser' one to three times more, because they didn't see anything
starting up.  In fact, it was starting, it just wasn't instantaneous.
I worry about forcing a splash screen that announces "I'm using Tor!"
on the screen, but at the same time, it would let users know that tbb
is starting.

Once vidalia started, no one waited for tbb firefox to start, but
rather started their own browser and tried to use it.  Once tbb firefox
started up, in some cases, minutes later, they were confused.  Why
didn't tbb firefox start right away instead of this useless vidalia
control panel?  

A few of them felt the need to explore the vidalia control panel since
we showed it to them.  As if to say, 'there are buttons you are showing
me, I just click and explore.'

Once tbb firefox started, they were ok with using firefox over tor just
fine.  The first thing many of them did was to login to facebook or
gmail over tor to see if it was different.  None of them verified the
ssl cert presented for facebook or gmail logins.  For those that did
login to gmail, gchat didn't work due to the lack of Flash in tbb
firefox.  

We then tried to configure their chat clients for tor.  Adium on the
mac was fairly easy.  The variety of clients on windows wasn't so
easy.  A few wondered about logging in over ssl, but never did because
the services didn't offer it (aol, msn, gchat).  I showed the windows
people pidgin, but they liked their native apps and didn't see why one
multi-protocol app was better.  

The experience continued through pidgin with OTR, installing pgp for
email and verifying files, and a general talk about openssl
certificates, what they mean, and what verification of a cert entails.

The relevant tor experience was what I wanted to communicate and for us
to start thinking through ways to address it.  Perhaps Mike's desire
for a anonymous browser is a correct path for usability and better
anonymity for the user.  I believe torfox and torora have both come to
the same conclusion (at different times) as well.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110527200749</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-05-27 20:07:49-0400</timestampReceived><subject>[tor-dev] Code Review (arm) - Initial commit for the menu code</subject><body>

Hi all. Kamran and I are gonna doing code reviews publicly so if
you're interested and spot issues we miss then feel free to chime in.
-Damian

Change: https://gitweb.torproject.org/user/krkhan/arm.git/commitdiff/5fd9b5f74a86eb7e641366ae1c0a1a47404cf873


&gt; ARM_CONTROLLER = Controller(stdscr, stickyPanels, pagePanels, menu)

What sort of persistent state will the menu require? If we can make it
a popup function (like "showHelpPopup()") that would be preferable
(less parameter juggling). But if you expect it to remember something
between menu requests then this makes sense.

&gt; menu.draw()

Maybe rename this to "showMenu()"? The draw method is part of panel
which threw me off a bit.

&gt; self._rootEntry = (entry and isinstance(entry, ParentEntry)) and entry or \
&gt; DEFAULT_ROOT

Interesting pattern, but it's kinda hard to read (or make sense of
unless you've seen it before). Maybe something a little less compact
would be clearer?

if entry and isinstance(entry, ParentEntry):
  self._rootEntry = entry
else: self._rootEntry = DEFAULT_ROOT

&gt; titles = map(attrgetter('title'), self._rootEntry.children)

This took me a couple minutes with the interactive interpretor to make
sense of too. Maybe list comprehension instead of the attrgetter would
help?

titles = [menuItem.title for menuItem in self._rootEntry.children]

&gt; titlewidth = max(map(lambda title: len(title), titles)) + 2

Neat. Honestly I'm greener than I should be with lamdas. The pattern
I'd use for this is...
titlewidth = max([len(entry) for entry in titles]) + 2

but up to you. The later is more familiar to me but I'm not sure which
can claim the best readability.

&gt; # total number of titles that can be printed in current width

Why are you giving all titles equal distance? Does this make it look
better? I'd assume that would be best to have dynamic widths, leaving
some entries unprinted if we run out of room (this is done all around
so I can get you an example if you'd like).

I'm thrilled you're taking variable screen sizes into account!

&gt; titleformat = curses.A_NORMAL
&gt; 
&gt; if index == self._selection[0]:
&gt; titleformat = curses.A_STANDOUT

Alternative option...

titleformat = curses.A_STANDOUT if index == self._selection[0] else
curses.A_NORMAL

&gt; popup.win.addch(top, left, curses.ACS_VLINE)
&gt; popup.win.addstr(top, left, entry.title.center(titlewidth), titleformat)
&gt; popup.win.addch(top, left, curses.ACS_VLINE)

Noooooooo! Don't do this!

If you can help it _never_ draw to the raw curses window. If this ever
attempts to draw outside the curses window it will crash. The panel
class has safe proxies for everything that you should need. In this
case...

popup.addch(top, left, curses.ACS_VLINE)
popup.addstr(top, left, entry.title.center(titlewidth), titleformat)
popup.addch(top, left, curses.ACS_VLINE)

will do the same. There's, of course, exceptions like popup.win.box()
and popup.win.refresh() (those are safe).

&gt; DEFAULT_ROOT = ParentEntry(title="Root", children=(

I've been defining constants outside of classes so they can be easier
to spot at the top of files. However, this is just a stylistic
preference of mine - if you prefer constants to be a class attribute
then that's fine.

&gt; for index in self._selection:
&gt; if isinstance(entry, ParentEntry):
&gt; entry = entry.children[index]
&gt; else:
&gt; break
&gt; 
&gt; if isinstance(entry, LeafEntry):
&gt; entry.callback(entry)

It looks like if self._selection is an invalid path you do nothing?
Maybe we should log something or raise an exception...

Your usage of named tuples and index lists will, I think, make this
harder and more confusing than it needs to be. Instead I'd suggest a
MenuItem class that has...

getLabel()     -&gt; text for the option
isLeaf()       -&gt; boolean for if we're a leaf or not
getSubmenu()   -&gt; returns a list of MenuItems below it - either an
empty list or None if a leaf node (whatever makes most sense to you)
getParent()    -&gt; parent MenuItem
next(), prev() -&gt; returns a MenuItem instance for the next or previous
option for the menu list we're in
select()       -&gt; event handler

Constructing the menu will be a little more interesting, but rendering
it, navigation, and selection will all become trivial. It'll also
avoid the situation where _selection is out of sync with _rootEntry
(for that matter, we wouldn't need a rootEntry...).
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110528021042</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-28 02:10:42-0400</timestampReceived><subject>Re: [tor-dev] Code Review (arm) - Initial commit for the menu code</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 27 May 2011 13:07:49 -0700
Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Hi all. Kamran and I are gonna doing code reviews publicly so if
&gt; you're interested and spot issues we miss then feel free to chime in.
&gt; -Damian
&gt; 
&gt; Change: https://gitweb.torproject.org/user/krkhan/arm.git/commitdiff/5fd9b5f74a86eb7e641366ae1c0a1a47404cf873
&gt; 

&gt; &gt; titlewidth = max(map(lambda title: len(title), titles)) + 2

Why not "titlewidth = max(map(len, titles)) + 2"?


Robert Ransom


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110513072500</emailId><senderName>Lucky Green</senderName><senderEmail>shamrock@cypherpunks.to</senderEmail><timestampReceived>2011-05-13 07:25:00-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

On 2011-05-12 07:59, Andrew Lewman wrote:
&gt; A short while ago, I did a training for some activists from a country
&gt; that is hostile to the Internet.  These people were some of the more
&gt; technical people from their community.  There was a mix of Windows and
&gt; OS X laptops in the session.  English was their third language, for
&gt; added fun.
&gt; 
&gt; I walked them through finding tor browser bundle, downloading it,
&gt; verifying it, unzipping it, and starting it.  Here was the first
&gt; problem.  They couldn't find tbb on the download page.  Their comments
&gt; were that all these files and releases on the page were confusing.
&gt; They wanted just one thing to look at, pick their operating system, and
&gt; go.  And they wanted the one thing to automatically detect their
&gt; language preferences for tbb.

Easily solved. A download page should be workflow based. You can lay it
out as columns or successive pages. Example:

What is your OS? (pre-selected based on the browser string)-&gt; drop down
list -&gt; download link. For the main recommended product only,
alternative versions should not be suggested, but be available on a
drill-down page. See next comment.

(You will also want an index page containing all downloadable versions,
but that page should be linked from the bottom of the download page.
"For alternative versions of our product, click here")

&gt; I ended up pointing them at tpo/torbrowser, which they also thought was
&gt; confusing.  The aforementioned desires weren't satisfied on this page,
&gt; but at least they could find their preferred language.  They all
&gt; commented that back home, a 24MB file was too big, and can't they get
&gt; it via bittorrent or some other piecemeal way?  A 24mb file would take
&gt; hours to download.

This is one of those rare situations where two entirely unrelated issues
combine to confuse even some of the more experienced product managers.

The first issue is the UE problem, meaning page design bug, of giving
the user choices inside the default work flow of having to select a
particular product, such as tpo/torbrowser. There should only be one
default choice per OS.

The other issue has too sub-issues. The first sub-issue is that users
can be whiny, as they are here. How are those users with their shiny
MacOS laptops getting OS updates? How large are those OS updates? How
big was that last iTunes update? Oh, those updates are larger than 24 MB?

Granted, how users obtain other software is a follow-up question the PM
must ask in this situation to either learn how to best adjust user
expectation or learn which distribution mechanism to emulate.

The second sub-issue (only useful to know after having figured out the
first) is which download options to offer as part of the regular work
flow. http/our download manager/BT are common, but that doesn't
necessary make them the correct choices for Tor.

&gt; None of them had pgp installed, and therefore no way to verify the .asc
&gt; and zip file.

That is to be expected. (And I am confident was expected by Andrew).

&gt; Most of them figured out to click inside the resulting folder and start
&gt; the 'start tor browser' program.  For all of the macs, the tbb didn't
&gt; start.  The people had to restart the system and then clicking on
&gt; 'start tor browser' worked as expected.  

Bug of some sort. (Possibly in the installer not prompting the user for
the required reboot).

&gt; As tbb was starting up, nearly all of them clicked on 'start tor
&gt; browser' one to three times more, because they didn't see anything
&gt; starting up.  In fact, it was starting, it just wasn't instantaneous.
&gt; I worry about forcing a splash screen that announces "I'm using Tor!"
&gt; on the screen, but at the same time, it would let users know that tbb
&gt; is starting.

You are striving for user notification of actions in 3/10th of a second.
Anything more than that and the user will perceive lag. Note that 3/10
of a second is plenty of time to load a stub that reads "Please wait,
Tor is loading". Take much longer after that notice is presented to the
user for the final app to load and you'll want some visual indicator of
progress, such as a spinning ball.

&gt; Once vidalia started, no one waited for tbb firefox to start, but
&gt; rather started their own browser and tried to use it.  Once tbb firefox
&gt; started up, in some cases, minutes later, they were confused.  Why
&gt; didn't tbb firefox start right away instead of this useless vidalia
&gt; control panel?  

Again, multiple issues here. Clearly the browser is loading too slowly,
which may be inherent to the browser. If so - and if it is not possible
to make the browser load faster by stripping it down - you are using the
wrong default browser. Obvious area to explore here is how fast the
users' regular browsers are loading. Must be faster than tbb firefox or
they wouldn't have been able to start their own browsers in the interim.
Figure out why their default browsers are loading faster and go from there.

&gt; A few of them felt the need to explore the vidalia control panel since
&gt; we showed it to them.  As if to say, 'there are buttons you are showing
&gt; me, I just click and explore.'

UE design bug. The user should only be presented with UI elements that
the user needs to interact with to complete the task. Anything else
should be buried in a "Tools" (think Chrome) menu or Tray icon. If what
you are loading is a new browser, there shouldn't even be a Tray icon,
but an additional button or sub-menu in the browser.

&gt; Once tbb firefox started, they were ok with using firefox over tor just
&gt; fine.  The first thing many of them did was to login to facebook or
&gt; gmail over tor to see if it was different.  None of them verified the
&gt; ssl cert presented for facebook or gmail logins.  For those that did
&gt; login to gmail, gchat didn't work due to the lack of Flash in tbb
&gt; firefox.  

Expected behavior. No normal user verifies SSL server certs, knows they
exist, or knows how to verify a cert even if they knew it existed. If
the browser had reported an error with the cert the users would have
clicked to ignore the mismatch. If the browser were to block access to
the site due to a bad cert, the user would have switched to a browser
that doesn't exhibit the blocking behavior. Human factor studies abound.

&gt; We then tried to configure their chat clients for tor.  Adium on the
&gt; mac was fairly easy.  The variety of clients on windows wasn't so
&gt; easy.  A few wondered about logging in over ssl, but never did because
&gt; the services didn't offer it (aol, msn, gchat).  I showed the windows
&gt; people pidgin, but they liked their native apps and didn't see why one
&gt; multi-protocol app was better.  

Unachievable scope combined with misguided user expectations.

The Tor Project would do well to not ADHD its activities into fixing all
security ills of this world, such as email encryption, full disk
encryption, or how to secure data once it leaves the exit node. All are
real problems, but the one problem that is the core focus of Tor is
difficult enough and you have barely enough resources to address even that.

There more interesting lesson that comes out of your experience is far
from novel, but it bears repeating: absent other guidance, users expect
security products, including anonymity products, to sprinkle security
fairy dust over the user's existing work flow. We do not know how to
achieve this goal given the present state of the art in computer science.

Consequently, providing anonymity services to the user requires work
flow changes from the user. Users will not engage in work flow changes
within their normal user environment. You have to change the environment
to make the work flow changes acceptable and employed by the user. You
still run the very real risk that the user will not accept the new
environment, but at least it is possible to get the user to change
behavior in a new environment, while it is not possible to get the user
to change behavior in the old environment.

The conclusion from this is pretty straight forward, though perhaps not
welcome: it is called a virtual machine.

&gt; The experience continued through pidgin with OTR, installing pgp for
&gt; email and verifying files, and a general talk about openssl
&gt; certificates, what they mean, and what verification of a cert entails.

Yikes. Talk about ambitious. :-)

&gt; The relevant tor experience was what I wanted to communicate and for us
&gt; to start thinking through ways to address it.  Perhaps Mike's desire
&gt; for a anonymous browser is a correct path for usability and better
&gt; anonymity for the user.  I believe torfox and torora have both come to
&gt; the same conclusion (at different times) as well.

Hope my comments help, they are based on decades in this industry and
are intended to help. Feel free to contact me with any questions.

--Lucky
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110513220904</emailId><senderName>katmagic</senderName><senderEmail>the.magical.kat@gmail.com</senderEmail><timestampReceived>2011-05-13 22:09:04-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 2011-05-12 at 10:59 -0400, Andrew Lewman wrote:
&gt; A short while ago, I did a training for some activists from a country
&gt; that is hostile to the Internet.  These people were some of the more
&gt; technical people from their community.  There was a mix of Windows and
&gt; OS X laptops in the session.  English was their third language, for
&gt; added fun.
&gt; 
&gt; I walked them through finding tor browser bundle, downloading it,
&gt; verifying it, unzipping it, and starting it.  Here was the first
&gt; problem.  They couldn't find tbb on the download page.  Their comments
&gt; were that all these files and releases on the page were confusing.
&gt; They wanted just one thing to look at, pick their operating system, and
&gt; go.  And they wanted the one thing to automatically detect their
&gt; language preferences for tbb.

As Torbutton has taught us, browsers send quite a bit of information
with them. It seems like it would be helpful to automatically detect the
user's language and operating system, via the User-Agent and
Accept-Language headers.

&gt; I ended up pointing them at tpo/torbrowser, which they also thought was
&gt; confusing.  The aforementioned desires weren't satisfied on this page,
&gt; but at least they could find their preferred language.  They all
&gt; commented that back home, a 24MB file was too big, and can't they get
&gt; it via bittorrent or some other piecemeal way?  A 24mb file would take
&gt; hours to download.

Torrents are already auto-generated somewhere, though I can't seem to
find the link at the moment.

&gt; Once they finally downloaded it, they all double clicked on their
&gt; resulting zip file.  In fact, all of the mac people ended up
&gt; downloading the windows tbb and unzipped it correctly.  In all cases,
&gt; their operating system handled the zip file correctly. After fixing the
&gt; mac people with mac tbb, we moved on to the next step.
&gt; 
&gt; None of them had pgp installed, and therefore no way to verify the .asc
&gt; and zip file.

GPG4Win[1] somewhat usable, though it's still not as easy as Seahorse
and such on Linux. Doesn't Microsoft have a built-in way to digitally
sign binaries?
[1]: http://www.gpg4win.org/

&gt; Most of them figured out to click inside the resulting folder and start
&gt; the 'start tor browser' program.  For all of the macs, the tbb didn't
&gt; start.  The people had to restart the system and then clicking on
&gt; 'start tor browser' worked as expected.  
&gt; 
&gt; As tbb was starting up, nearly all of them clicked on 'start tor
&gt; browser' one to three times more, because they didn't see anything
&gt; starting up.  In fact, it was starting, it just wasn't instantaneous.
&gt; I worry about forcing a splash screen that announces "I'm using Tor!"
&gt; on the screen, but at the same time, it would let users know that tbb
&gt; is starting.

This is a problem among many users, though one that is rather unrelated
to anything Tor-specific. The solution to this is probably better
startup notification systems, but that's very much out of scope for Tor.

&gt; Once vidalia started, no one waited for tbb firefox to start, but
&gt; rather started their own browser and tried to use it.  Once tbb firefox
&gt; started up, in some cases, minutes later, they were confused.  Why
&gt; didn't tbb firefox start right away instead of this useless vidalia
&gt; control panel?  
&gt; 
&gt; A few of them felt the need to explore the vidalia control panel since
&gt; we showed it to them.  As if to say, 'there are buttons you are showing
&gt; me, I just click and explore.'

Maybe Vidalia should just start in the background and display a little
bubble at startup?

&gt; Once tbb firefox started, they were ok with using firefox over tor just
&gt; fine.  The first thing many of them did was to login to facebook or
&gt; gmail over tor to see if it was different.  None of them verified the
&gt; ssl cert presented for facebook or gmail logins.  For those that did
&gt; login to gmail, gchat didn't work due to the lack of Flash in tbb
&gt; firefox.  
&gt; 
&gt; We then tried to configure their chat clients for tor.  Adium on the
&gt; mac was fairly easy.  The variety of clients on windows wasn't so
&gt; easy.  A few wondered about logging in over ssl, but never did because
&gt; the services didn't offer it (aol, msn, gchat).  I showed the windows
&gt; people pidgin, but they liked their native apps and didn't see why one
&gt; multi-protocol app was better.  

Google Chat, as it uses XMPP, has SSL support by default. Pidgin's
better because it has OTR and SOCKS support (minus the XMPP DNS
resolution thing), of course!

&gt; The experience continued through pidgin with OTR, installing pgp for
&gt; email and verifying files, and a general talk about openssl
&gt; certificates, what they mean, and what verification of a cert entails.

Trying to get anyone, let alone 'real people', to understand the SSL
certificate model is futile.

&gt; The relevant tor experience was what I wanted to communicate and for us
&gt; to start thinking through ways to address it.  Perhaps Mike's desire
&gt; for a anonymous browser is a correct path for usability and better
&gt; anonymity for the user.  I believe torfox and torora have both come to
&gt; the same conclusion (at different times) as well.


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110515222340</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-15 22:23:40-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 13 May 2011 18:09:04 -0400
katmagic &lt;the.magical.kat@gmail.com&gt; wrote:

&gt; On Thu, 2011-05-12 at 10:59 -0400, Andrew Lewman wrote:
&gt; &gt; A short while ago, I did a training for some activists from a country
&gt; &gt; that is hostile to the Internet.  These people were some of the more
&gt; &gt; technical people from their community.  There was a mix of Windows and
&gt; &gt; OS X laptops in the session.  English was their third language, for
&gt; &gt; added fun.
&gt; &gt; 
&gt; &gt; I walked them through finding tor browser bundle, downloading it,
&gt; &gt; verifying it, unzipping it, and starting it.  Here was the first
&gt; &gt; problem.  They couldn't find tbb on the download page.  Their comments
&gt; &gt; were that all these files and releases on the page were confusing.
&gt; &gt; They wanted just one thing to look at, pick their operating system, and
&gt; &gt; go.  And they wanted the one thing to automatically detect their
&gt; &gt; language preferences for tbb.
&gt; 
&gt; As Torbutton has taught us, browsers send quite a bit of information
&gt; with them. It seems like it would be helpful to automatically detect the
&gt; user's language and operating system, via the User-Agent and
&gt; Accept-Language headers.

That would require either using JavaScript on www.torproject.org or
running a script on the web server.  The latter would make mirroring
the website much harder, so we're stuck with JavaScript if we take that
path.

This would break for people who already use Torbutton, but at least we
can detect Torbutton's User-Agent string, time zone, and other
characteristics when it is enabled.


&gt; &gt; I ended up pointing them at tpo/torbrowser, which they also thought was
&gt; &gt; confusing.  The aforementioned desires weren't satisfied on this page,
&gt; &gt; but at least they could find their preferred language.  They all
&gt; &gt; commented that back home, a 24MB file was too big, and can't they get
&gt; &gt; it via bittorrent or some other piecemeal way?  A 24mb file would take
&gt; &gt; hours to download.
&gt; 
&gt; Torrents are already auto-generated somewhere, though I can't seem to
&gt; find the link at the moment.

Moritz Bartl generates them and hosts them somewhere on
torservers.net.  Unfortunately, the script currently puts each
package's GPG signature in a separate torrent from the package it signs.

&gt; &gt; Once they finally downloaded it, they all double clicked on their
&gt; &gt; resulting zip file.  In fact, all of the mac people ended up
&gt; &gt; downloading the windows tbb and unzipped it correctly.  In all cases,
&gt; &gt; their operating system handled the zip file correctly. After fixing the
&gt; &gt; mac people with mac tbb, we moved on to the next step.
&gt; &gt; 
&gt; &gt; None of them had pgp installed, and therefore no way to verify the .asc
&gt; &gt; and zip file.
&gt; 
&gt; GPG4Win[1] somewhat usable, though it's still not as easy as Seahorse
&gt; and such on Linux. Doesn't Microsoft have a built-in way to digitally
&gt; sign binaries?

GPA (the main GUI tool shipped in GPG4Win) doesn't provide a way to
check detached signatures, and GPGEx (the shell extension shipped in
GPG4Win) isn't compiled for 64-bit Windows.  (I don't know whether
GPGEx provides a way to check detached signatures on 32-bit Windows
installations.)

Windows does provide a way to check signatures on .exe files, but it
uses the SSL trust model (i.e. any member of the Authenticode'
equivalent of the SSL mafia' can issue a code-signing certificate with
any signer name).  It is possible to verify the fingerprint of the
certificate for the key which actually signed the program file, but
users are unlikely to do that.


&gt; &gt; Most of them figured out to click inside the resulting folder and start
&gt; &gt; the 'start tor browser' program.  For all of the macs, the tbb didn't
&gt; &gt; start.  The people had to restart the system and then clicking on
&gt; &gt; 'start tor browser' worked as expected.  
&gt; &gt; 
&gt; &gt; As tbb was starting up, nearly all of them clicked on 'start tor
&gt; &gt; browser' one to three times more, because they didn't see anything
&gt; &gt; starting up.  In fact, it was starting, it just wasn't instantaneous.
&gt; &gt; I worry about forcing a splash screen that announces "I'm using Tor!"
&gt; &gt; on the screen, but at the same time, it would let users know that tbb
&gt; &gt; is starting.
&gt; 
&gt; This is a problem among many users, though one that is rather unrelated
&gt; to anything Tor-specific. The solution to this is probably better
&gt; startup notification systems, but that's very much out of scope for Tor.

We can't fix design flaws in the host operating system or desktop
environment from within Tor Browser Bundle.  But we can display a small
splash screen the first time a user starts TBB, and allow the user to
select a more discreet startup indicator or none at all for future use.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110518073903</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-05-18 07:39:03-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

[Attachment #2 (multipart/signed)]


We should definitely translate Andrew's report and this commentary
into tickets in the bug tracker, otherwise it will be forgotten..

Any volunteers? :)

Thus spake Lucky Green (shamrock@cypherpunks.to):

&gt; On 2011-05-12 07:59, Andrew Lewman wrote:
&gt; &gt; A short while ago, I did a training for some activists from a country
&gt; &gt; that is hostile to the Internet.  These people were some of the more
&gt; &gt; technical people from their community.  There was a mix of Windows and
&gt; &gt; OS X laptops in the session.  English was their third language, for
&gt; &gt; added fun.
&gt; &gt; 
&gt; &gt; I walked them through finding tor browser bundle, downloading it,
&gt; &gt; verifying it, unzipping it, and starting it.  Here was the first
&gt; &gt; problem.  They couldn't find tbb on the download page.  Their comments
&gt; &gt; were that all these files and releases on the page were confusing.
&gt; &gt; They wanted just one thing to look at, pick their operating system, and
&gt; &gt; go.  And they wanted the one thing to automatically detect their
&gt; &gt; language preferences for tbb.
&gt; 
&gt; Easily solved. A download page should be workflow based. You can lay it
&gt; out as columns or successive pages. Example:
&gt; 
&gt; What is your OS? (pre-selected based on the browser string)-&gt; drop down
&gt; list -&gt; download link. For the main recommended product only,
&gt; alternative versions should not be suggested, but be available on a
&gt; drill-down page. See next comment.
&gt; 
&gt; (You will also want an index page containing all downloadable versions,
&gt; but that page should be linked from the bottom of the download page.
&gt; "For alternative versions of our product, click here")
&gt; 
&gt; &gt; I ended up pointing them at tpo/torbrowser, which they also thought was
&gt; &gt; confusing.  The aforementioned desires weren't satisfied on this page,
&gt; &gt; but at least they could find their preferred language.  They all
&gt; &gt; commented that back home, a 24MB file was too big, and can't they get
&gt; &gt; it via bittorrent or some other piecemeal way?  A 24mb file would take
&gt; &gt; hours to download.
&gt; 
&gt; This is one of those rare situations where two entirely unrelated issues
&gt; combine to confuse even some of the more experienced product managers.
&gt; 
&gt; The first issue is the UE problem, meaning page design bug, of giving
&gt; the user choices inside the default work flow of having to select a
&gt; particular product, such as tpo/torbrowser. There should only be one
&gt; default choice per OS.
&gt; 
&gt; The other issue has too sub-issues. The first sub-issue is that users
&gt; can be whiny, as they are here. How are those users with their shiny
&gt; MacOS laptops getting OS updates? How large are those OS updates? How
&gt; big was that last iTunes update? Oh, those updates are larger than 24 MB?
&gt; 
&gt; Granted, how users obtain other software is a follow-up question the PM
&gt; must ask in this situation to either learn how to best adjust user
&gt; expectation or learn which distribution mechanism to emulate.
&gt; 
&gt; The second sub-issue (only useful to know after having figured out the
&gt; first) is which download options to offer as part of the regular work
&gt; flow. http/our download manager/BT are common, but that doesn't
&gt; necessary make them the correct choices for Tor.
&gt; 
&gt; &gt; None of them had pgp installed, and therefore no way to verify the .asc
&gt; &gt; and zip file.
&gt; 
&gt; That is to be expected. (And I am confident was expected by Andrew).
&gt; 
&gt; &gt; Most of them figured out to click inside the resulting folder and start
&gt; &gt; the 'start tor browser' program.  For all of the macs, the tbb didn't
&gt; &gt; start.  The people had to restart the system and then clicking on
&gt; &gt; 'start tor browser' worked as expected.  
&gt; 
&gt; Bug of some sort. (Possibly in the installer not prompting the user for
&gt; the required reboot).
&gt; 
&gt; &gt; As tbb was starting up, nearly all of them clicked on 'start tor
&gt; &gt; browser' one to three times more, because they didn't see anything
&gt; &gt; starting up.  In fact, it was starting, it just wasn't instantaneous.
&gt; &gt; I worry about forcing a splash screen that announces "I'm using Tor!"
&gt; &gt; on the screen, but at the same time, it would let users know that tbb
&gt; &gt; is starting.
&gt; 
&gt; You are striving for user notification of actions in 3/10th of a second.
&gt; Anything more than that and the user will perceive lag. Note that 3/10
&gt; of a second is plenty of time to load a stub that reads "Please wait,
&gt; Tor is loading". Take much longer after that notice is presented to the
&gt; user for the final app to load and you'll want some visual indicator of
&gt; progress, such as a spinning ball.
&gt; 
&gt; &gt; Once vidalia started, no one waited for tbb firefox to start, but
&gt; &gt; rather started their own browser and tried to use it.  Once tbb firefox
&gt; &gt; started up, in some cases, minutes later, they were confused.  Why
&gt; &gt; didn't tbb firefox start right away instead of this useless vidalia
&gt; &gt; control panel?  
&gt; 
&gt; Again, multiple issues here. Clearly the browser is loading too slowly,
&gt; which may be inherent to the browser. If so - and if it is not possible
&gt; to make the browser load faster by stripping it down - you are using the
&gt; wrong default browser. Obvious area to explore here is how fast the
&gt; users' regular browsers are loading. Must be faster than tbb firefox or
&gt; they wouldn't have been able to start their own browsers in the interim.
&gt; Figure out why their default browsers are loading faster and go from there.
&gt; 
&gt; &gt; A few of them felt the need to explore the vidalia control panel since
&gt; &gt; we showed it to them.  As if to say, 'there are buttons you are showing
&gt; &gt; me, I just click and explore.'
&gt; 
&gt; UE design bug. The user should only be presented with UI elements that
&gt; the user needs to interact with to complete the task. Anything else
&gt; should be buried in a "Tools" (think Chrome) menu or Tray icon. If what
&gt; you are loading is a new browser, there shouldn't even be a Tray icon,
&gt; but an additional button or sub-menu in the browser.
&gt; 
&gt; &gt; Once tbb firefox started, they were ok with using firefox over tor just
&gt; &gt; fine.  The first thing many of them did was to login to facebook or
&gt; &gt; gmail over tor to see if it was different.  None of them verified the
&gt; &gt; ssl cert presented for facebook or gmail logins.  For those that did
&gt; &gt; login to gmail, gchat didn't work due to the lack of Flash in tbb
&gt; &gt; firefox.  
&gt; 
&gt; Expected behavior. No normal user verifies SSL server certs, knows they
&gt; exist, or knows how to verify a cert even if they knew it existed. If
&gt; the browser had reported an error with the cert the users would have
&gt; clicked to ignore the mismatch. If the browser were to block access to
&gt; the site due to a bad cert, the user would have switched to a browser
&gt; that doesn't exhibit the blocking behavior. Human factor studies abound.
&gt; 
&gt; &gt; We then tried to configure their chat clients for tor.  Adium on the
&gt; &gt; mac was fairly easy.  The variety of clients on windows wasn't so
&gt; &gt; easy.  A few wondered about logging in over ssl, but never did because
&gt; &gt; the services didn't offer it (aol, msn, gchat).  I showed the windows
&gt; &gt; people pidgin, but they liked their native apps and didn't see why one
&gt; &gt; multi-protocol app was better.  
&gt; 
&gt; Unachievable scope combined with misguided user expectations.
&gt; 
&gt; The Tor Project would do well to not ADHD its activities into fixing all
&gt; security ills of this world, such as email encryption, full disk
&gt; encryption, or how to secure data once it leaves the exit node. All are
&gt; real problems, but the one problem that is the core focus of Tor is
&gt; difficult enough and you have barely enough resources to address even that.
&gt; 
&gt; There more interesting lesson that comes out of your experience is far
&gt; from novel, but it bears repeating: absent other guidance, users expect
&gt; security products, including anonymity products, to sprinkle security
&gt; fairy dust over the user's existing work flow. We do not know how to
&gt; achieve this goal given the present state of the art in computer science.
&gt; 
&gt; Consequently, providing anonymity services to the user requires work
&gt; flow changes from the user. Users will not engage in work flow changes
&gt; within their normal user environment. You have to change the environment
&gt; to make the work flow changes acceptable and employed by the user. You
&gt; still run the very real risk that the user will not accept the new
&gt; environment, but at least it is possible to get the user to change
&gt; behavior in a new environment, while it is not possible to get the user
&gt; to change behavior in the old environment.
&gt; 
&gt; The conclusion from this is pretty straight forward, though perhaps not
&gt; welcome: it is called a virtual machine.
&gt; 
&gt; &gt; The experience continued through pidgin with OTR, installing pgp for
&gt; &gt; email and verifying files, and a general talk about openssl
&gt; &gt; certificates, what they mean, and what verification of a cert entails.
&gt; 
&gt; Yikes. Talk about ambitious. :-)
&gt; 
&gt; &gt; The relevant tor experience was what I wanted to communicate and for us
&gt; &gt; to start thinking through ways to address it.  Perhaps Mike's desire
&gt; &gt; for a anonymous browser is a correct path for usability and better
&gt; &gt; anonymity for the user.  I believe torfox and torora have both come to
&gt; &gt; the same conclusion (at different times) as well.
&gt; 
&gt; Hope my comments help, they are based on decades in this industry and
&gt; are intended to help. Feel free to contact me with any questions.
&gt; 
&gt; --Lucky
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110518193728</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-05-18 19:37:28-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

On Fri, 13 May 2011 00:25:00 -0700
Lucky Green &lt;shamrock@cypherpunks.to&gt; wrote:
&gt; Easily solved. A download page should be workflow based. You can lay
&gt; it out as columns or successive pages. Example:

We have this, sort of, at
https://www.torproject.org/download/download-easy

&gt; The first issue is the UE problem, meaning page design bug, of giving
&gt; the user choices inside the default work flow of having to select a
&gt; particular product, such as tpo/torbrowser. There should only be one
&gt; default choice per OS.

If we used javascript to magically detect their preferred language,
then we could default the page to that, for their OS too.

&gt; The other issue has too sub-issues. The first sub-issue is that users
&gt; can be whiny, as they are here. How are those users with their shiny
&gt; MacOS laptops getting OS updates? How large are those OS updates? How
&gt; big was that last iTunes update? Oh, those updates are larger than 24
&gt; MB?

Assume for this set of users, everything is possibly not legally
obtained. They swap cdroms and usb drives around.  They may not be able
to legally buy the software in their home country.  

&gt; The second sub-issue (only useful to know after having figured out the
&gt; first) is which download options to offer as part of the regular work
&gt; flow. http/our download manager/BT are common, but that doesn't
&gt; necessary make them the correct choices for Tor.

I was thinking of thandy/secure updater here.  They download one tiny
thandy-stub program, which then does the rest via https or bittorrent.

&gt; &gt; None of them had pgp installed, and therefore no way to verify
&gt; &gt; the .asc and zip file.
&gt; That is to be expected. (And I am confident was expected by Andrew).

Yes, expected.

&gt; &gt; Most of them figured out to click inside the resulting folder and
&gt; &gt; start the 'start tor browser' program.  For all of the macs, the
&gt; &gt; tbb didn't start.  The people had to restart the system and then
&gt; &gt; clicking on 'start tor browser' worked as expected. 
&gt; Bug of some sort. (Possibly in the installer not prompting the user
&gt; for the required reboot).

It's a bug.  There is no installer for TBB by design.  It should just
unzip and work.

&gt; You are striving for user notification of actions in 3/10th of a
&gt; second. Anything more than that and the user will perceive lag. Note
&gt; that 3/10 of a second is plenty of time to load a stub that reads
&gt; "Please wait, Tor is loading". Take much longer after that notice is
&gt; presented to the user for the final app to load and you'll want some
&gt; visual indicator of progress, such as a spinning ball.

Something optional that loads the first time, with a check
box that says 'never load this message again' would also work.

&gt; Again, multiple issues here. Clearly the browser is loading too
&gt; slowly, which may be inherent to the browser. If so - and if it is
&gt; not possible to make the browser load faster by stripping it down -
&gt; you are using the wrong default browser. Obvious area to explore here
&gt; is how fast the users' regular browsers are loading. Must be faster
&gt; than tbb firefox or they wouldn't have been able to start their own
&gt; browsers in the interim. Figure out why their default browsers are
&gt; loading faster and go from there.

This is firefox, stripped down already.  I think the problem here isn't
that firefox was a dog on OSX, because it loaded fast on the window's
systems, but rather they didn't even know a browser was going to load.  

&gt; UE design bug. The user should only be presented with UI elements that
&gt; the user needs to interact with to complete the task. Anything else
&gt; should be buried in a "Tools" (think Chrome) menu or Tray icon. If
&gt; what you are loading is a new browser, there shouldn't even be a Tray
&gt; icon, but an additional button or sub-menu in the browser.

I like what TAILS has done here.  They strip out all of the
configuration options from Vidalia, so you can't click to change any
settings.

&gt; The Tor Project would do well to not ADHD its activities into fixing
&gt; all security ills of this world, such as email encryption, full disk
&gt; encryption, or how to secure data once it leaves the exit node. 

If not us, then who?  ;)  Yes, I agree, but users invariably ask us
about this stuff because we all use it daily.

&gt; We do not
&gt; know how to achieve this goal given the present state of the art in
&gt; computer science.

Well, I look at TAILS and Haven as two anonymous OSes that make strides
towards this.  Anonymous and mostly-secure by default enforce the
'power of the defaults'. 

And yes, your comments are always welcome.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110518193757</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-05-18 19:37:57-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

On Wed, 18 May 2011 00:39:03 -0700
Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt; We should definitely translate Andrew's report and this commentary
&gt; into tickets in the bug tracker, otherwise it will be forgotten..

On my todo list.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110518194409</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-05-18 19:44:09-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

On Fri, 13 May 2011 18:09:04 -0400
katmagic &lt;the.magical.kat@gmail.com&gt; wrote:
&gt; As Torbutton has taught us, browsers send quite a bit of information
&gt; with them. It seems like it would be helpful to automatically detect
&gt; the user's language and operating system, via the User-Agent and
&gt; Accept-Language headers.

For a long time, we at Tor have had a love/hate relationship with
javascript.  We want the website to work well without it, but at the
same time, having it would make our site more usable to those with it
enabled.  

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512143513</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-05-12 14:35:13-0400</timestampReceived><subject>Re: [tor-dev] May Tor proposal status, and proposal plans for 0.2.3</subject><body>

On 2011-May-09 18:54, Nick Mathewson wrote:
[..]
&gt;   117 IPv6 exits

Working on it, but due to the scope I am actually attacking it on most
of the networking stack inside Tor so it will not only cover 'exits'.

&gt;    118 Advertising multiple ORPorts at once

This is actually needed for IPv6, as most IPv6 stacks require separate
IPv4/IPv6 listen sockets. Some IPv6 stacks allow to accept IPv4
connections on IPv6 ports though.

&gt;     This proposal describes how an OR can advertise more than one
&gt;     address and OR port at a time.  It needs to be updated to work with
&gt;     microdescriptors, and to explain how much information can be
&gt;     transmitted in the consensus and how (the original proposal was
&gt;     written before consensus directories were really figured out).

It thus also needs to be updated with IPv6 addresses.

&gt;    xxx-ipv6-plan.txt
&gt; 
&gt;      Here's a survey of what we need to do for IPv6 support that I
&gt;      started writing.  It's not a proposal; it's a survey of proposal
&gt;      and implementation statuses.

I'll have a look again at this and provide diffs to my current findings.

Greets,
 Jeroen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110502103138</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-05-02 10:31:38-0400</timestampReceived><subject>Re: [tor-dev] TorStatus</subject><body>

&gt; im trying to port TorNetworkStatus to Ruby.
&gt; 
&gt; I took a look at the Trac and it looks like it's project that should be
&gt; done at the GSoC.
&gt; https://trac.torproject.org/projects/tor/wiki/projects/TorStatus
&gt; 
&gt; Is anyone working at this now?

No one is working on/maintaining TorStatus (it is not even a Tor Project
"product").

As far as I've understood the plan is to extent metrics-web to have the
TorStatus functionality on metrics.tpo.

best regards,
tagnaq
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110511173317</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-11 17:33:17-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Fri, May 6, 2011 at 11:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
 [...]
&gt;&gt;   * I'm hoping to write this up as a proposed spec soon, unless Ian or
&gt;&gt; somebody wants to give it a shot.
&gt;
&gt; Please go ahead.

Here's a draft sketch that I've put into proposals/ideas in the the
torspec repository.  Please let me know what I've gotten wrong, what
is over/under-engineered, and so on.

Filename: xxx-ntor-handshake.txt
Title: Improved circuit-creation key exchange
Author:  Nick Mathewson
Created: 11-May-2011
Status: Draft


This is an attempt to translate the proposed circuit handshake from
"Anonymity and one-way authentication in key-exchange protocols" by
Goldberg, Stebila, and Ustaoglu, into a Tor proposal format.

It assumes something like Robert Ransom's proposal draft is in place to
provide an extended CREATE cell format that can indicate what type of
handshake is in use.

Notation:

  Let a|b be the concatenation of a with b.

  Let H(x,t) be a tweakable hash function of output width H_LENGTH bytes.

  Let t_keyid, t_mac, t_key, and t_verify be a set of arbitrarily-chosen tweaks
  for the hash function.

  Let EXP(a,b) be a^b in some appropriate group G where the appropriate DH
  parameters hold.  Let's say elements of this group, when represented as
  byte strings, are all G_LENGTH bytes long.  Let's say we are using a
  generator g for this group.

  Let PROTOID be a string designating this variant of the protocol.

  Let KEYID be a collision-resistant (but not necessarily preimage-resistant)
     hash function on members of G, of output length H_LENGTH bytes.

Instantiation:

  Let's call this PROTOID "ntor-curve25519-sha256-1"

  Set H(x,t) == HMAC_SHA256 with message x and key t. So H_LENGTH == 32.
  Set t_mac   == PROTOID | ":mac"
      t_key1  == PROTOID | ":key1"
      t_key2  == PROTOID | ":verify"
  Set EXP(a,b) == curve25519(a,b), and g == 9 .

  Set KEYID(B) == B.  (We don't need to use a hash function here, since our
     keys are already very short.  It is trivially collision-resistant, since
     KEYID(A)====KEYID(B) iff A==B.)

Protocol:

  Take a router with identity key digest ID.

  As setup, the router generates a secret key b, and a public onion key
  B = EXP(g,b).  The router publishes B in its server descriptor.

  To send a create cell, the client generates a keypair of x, X=EXP(g,y) and
  sends a CREATE cell with contents:

    NODEID:     ID             -- H_LENGTH bytes
    KEYID:      KEYID(B)       -- H_LENGTH bytes
    CLIENT_PK:  X              -- G_LENGTH bytes

  The server checks X, generates a keypair of y, Y=EXP(g,y) and computes

    secret_input = EXP(X,y) | EXP(X,b) | ID | B | X | Y | PROTOID
    KEY_SEED = H(secret_input, t_key)
    verify = H(secret_input, t_verify)
    auth_input = verify | ID | B | Y | X | PROTOID | "Server"

  The server sends a CREATED cell containing:

    SERVER_PK:  Y                     -- G_LENGTH bytes
    AUTH:       H(auth_input, t_mac)  -- H_LENGTH byets

  The client then checks Y, and computes

    secret_input = EXP(Y,x) | EXP(B,x) | ID | B | X | Y | PROTOID
    KEY_SEED = H(secret_input, t_key1)
    verify = H(secret_input, t_verify)
    auth_input = verify | ID | B | Y | X | PROTOID | "Server"

    The client verifies that AUTH == H(auth_input, t_mac).

  Both parties now have a shared value for KEY_SEED.  They expand this into
  the keys needed for the Tor relay protocol.

Key expansion:

  Currently, the key expansion formula used by Tor here is

       K = SHA(K0 | [00]) | SHA(K0 | [01]) | SHH(K0 | [02]) | ...

       where K0==g^xy, and K is divvied up into Df, Db, Kf, and Kb portions.

  Instead, let's have it be

       K = H(KEY_SEED, t_expand1) | H(KEY_SEED, t_expand2) | ...

  where t_expand1..N are tweaks for the hash.

Performance notes:

  In Tor's current circuit creation handshake, the client does:
     One RSA public-key encryption
     A full DH handshake in Z_p
     A short AES encryption
     Five SHA1s for key expansion
  And the server does:
     One RSA private-key decryption
     A full DH handshake in Z_p
     A short AES decryption
     Five SHA1s for key expansion

  While in the revised handshake, the client does:
     A full DH handshake
     A public-half of a DH handshake
     3 H operations for the handshake
     3 H operations for the key expansion
  and the server does:
     A full DH handshake
     A private-half of a DH handshake
     3 H operations for the handshake
     3 H operations for the key expansion
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110511181948</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-11 18:19:48-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 01:33:17PM -0400, Nick Mathewson wrote:
&gt; On Fri, May 6, 2011 at 11:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;  [...]
&gt; &gt;&gt;   * I'm hoping to write this up as a proposed spec soon, unless Ian or
&gt; &gt;&gt; somebody wants to give it a shot.
&gt; &gt;
&gt; &gt; Please go ahead.
&gt; 
&gt; Here's a draft sketch that I've put into proposals/ideas in the the
&gt; torspec repository.  Please let me know what I've gotten wrong, what
&gt; is over/under-engineered, and so on.
&gt; 
&gt; Filename: xxx-ntor-handshake.txt
&gt; Title: Improved circuit-creation key exchange
&gt; Author:  Nick Mathewson
&gt; Created: 11-May-2011
&gt; Status: Draft
&gt; 
&gt; 
&gt; This is an attempt to translate the proposed circuit handshake from
&gt; "Anonymity and one-way authentication in key-exchange protocols" by
&gt; Goldberg, Stebila, and Ustaoglu, into a Tor proposal format.
&gt; 
&gt; It assumes something like Robert Ransom's proposal draft is in place to
&gt; provide an extended CREATE cell format that can indicate what type of
&gt; handshake is in use.
&gt; 
&gt; Notation:
&gt; 
&gt;   Let a|b be the concatenation of a with b.
&gt; 
&gt;   Let H(x,t) be a tweakable hash function of output width H_LENGTH bytes.
&gt; 
&gt;   Let t_keyid, t_mac, t_key, and t_verify be a set of arbitrarily-chosen tweaks
&gt;   for the hash function.
&gt; 
&gt;   Let EXP(a,b) be a^b in some appropriate group G where the appropriate DH
&gt;   parameters hold.  Let's say elements of this group, when represented as
&gt;   byte strings, are all G_LENGTH bytes long.  Let's say we are using a
&gt;   generator g for this group.
&gt; 
&gt;   Let PROTOID be a string designating this variant of the protocol.
&gt; 
&gt;   Let KEYID be a collision-resistant (but not necessarily preimage-resistant)
&gt;      hash function on members of G, of output length H_LENGTH bytes.
&gt; 
&gt; Instantiation:
&gt; 
&gt;   Let's call this PROTOID "ntor-curve25519-sha256-1"

Note that if the things you're hashing spill over a (56 mod 64) byte
boundary, you pay extra.  So it may behoove us to count bytes and see if
PROTOID couldn't be a little shorter.

&gt;   Set H(x,t) == HMAC_SHA256 with message x and key t. So H_LENGTH == 32.
&gt;   Set t_mac   == PROTOID | ":mac"
&gt;       t_key1  == PROTOID | ":key1"
&gt;       t_key2  == PROTOID | ":verify"
&gt;   Set EXP(a,b) == curve25519(a,b), and g == 9 .

Careful!  The arguments to curve25519 are (output, exponent, base).
(Note the order; that confused me when we were coding up Sphinx.)
Presumably you meant for EXP(a,b) to mean a^b, though.

Note that 9 does not have prime order in curve25519; it has order 8
times a prime.  But if the client always ensures private keys are 0 mod
8 (as djb requires; see below), this problem is mostly elided.

&gt;   Set KEYID(B) == B.  (We don't need to use a hash function here, since our
&gt;      keys are already very short.  It is trivially collision-resistant, since
&gt;      KEYID(A)====KEYID(B) iff A==B.)

Is "====" intentional?

&gt; Protocol:
&gt; 
&gt;   Take a router with identity key digest ID.
&gt; 
&gt;   As setup, the router generates a secret key b, and a public onion key

All "generates a secret key" operations should follow djb's
recommendation, of course (fiddle with the 2 high bits, and clear the
low 3 bits).

&gt;   B = EXP(g,b).  The router publishes B in its server descriptor.
&gt; 
&gt;   To send a create cell, the client generates a keypair of x, X=EXP(g,y) and

X=EXP(g,x) presumably?

&gt;   sends a CREATE cell with contents:
&gt; 
&gt;     NODEID:     ID             -- H_LENGTH bytes
&gt;     KEYID:      KEYID(B)       -- H_LENGTH bytes
&gt;     CLIENT_PK:  X              -- G_LENGTH bytes
&gt; 
&gt;   The server checks X,

What is "checks X" here?  Since the server doesn't really care whether
or not the crypto is good, this check can probably be elided.

&gt; generates a keypair of y, Y=EXP(g,y) and computes
&gt; 
&gt;     secret_input = EXP(X,y) | EXP(X,b) | ID | B | X | Y | PROTOID
&gt;     KEY_SEED = H(secret_input, t_key)
&gt;     verify = H(secret_input, t_verify)

Depending on the lengths involved, the above may be doing some
unnecessary work.

&gt;     auth_input = verify | ID | B | Y | X | PROTOID | "Server"
&gt; 
&gt;   The server sends a CREATED cell containing:
&gt; 
&gt;     SERVER_PK:  Y                     -- G_LENGTH bytes
&gt;     AUTH:       H(auth_input, t_mac)  -- H_LENGTH byets
&gt; 
&gt;   The client then checks Y, and computes

Here, the check is more important.  Ideally, one would check that Y \in
G^* (which should have prime order, but doesn't here).  But in
curve25519, I think you can get away with something a bit cheaper.  If Y
isn't in G at all, but is on the twist curve, the AUTH verification
below is certain to fail, so that's OK.  If it's in G, but has low order
(i.e. order dividing 8), then EXP(Y,x) will end up being the point at
infinity, which would be bad.  (Indeed, it would be pretty much the same
problem that Tor had lo those many years ago.) So I think it's probably
OK to check that EXP(Y,x), which you're computing anyway, is not the
point at infinity.  I don't remember offhand how curve25519 represents
that point; it may be as simple as all-0s, but you should check.

Berkant and Doug, opinions on this?

&gt;     secret_input = EXP(Y,x) | EXP(B,x) | ID | B | X | Y | PROTOID
&gt;     KEY_SEED = H(secret_input, t_key1)

Above, you used t_key, not t_key1, to create the KEY_SEED.

&gt;     verify = H(secret_input, t_verify)
&gt;     auth_input = verify | ID | B | Y | X | PROTOID | "Server"
&gt; 
&gt;     The client verifies that AUTH == H(auth_input, t_mac).
&gt; 
&gt;   Both parties now have a shared value for KEY_SEED.  They expand this into
&gt;   the keys needed for the Tor relay protocol.
&gt; 
&gt; Key expansion:
&gt; 
&gt;   Currently, the key expansion formula used by Tor here is
&gt; 
&gt;        K = SHA(K0 | [00]) | SHA(K0 | [01]) | SHH(K0 | [02]) | ...

SHH =&gt; SHA

&gt;        where K0==g^xy, and K is divvied up into Df, Db, Kf, and Kb portions.
&gt; 
&gt;   Instead, let's have it be
&gt; 
&gt;        K = H(KEY_SEED, t_expand1) | H(KEY_SEED, t_expand2) | ...
&gt; 
&gt;   where t_expand1..N are tweaks for the hash.

Krawczyk has a paper on how to do this crypto-correctly:

http://eprint.iacr.org/2010/264

See section 8 for an explanation of why the above is not ideal.  Note
that our "KEY_SEED" is approximately his "PRK", not his "SKM", as it's
already been hashed.  So if t_expand = PROTOID | ":expand", what's he's
suggesting is

K = K_1 | K_2 | ...
where
K_1 = H(t_expand | 0, KEY_SEED)
K_(i+1) = H(K_i | t_expand | i, KEY_SEED)

Note that KEY_SEED is used as the HMAC *key*, not the *message*.

&gt; Performance notes:
&gt; 
&gt;   In Tor's current circuit creation handshake, the client does:
&gt;      One RSA public-key encryption
&gt;      A full DH handshake in Z_p
&gt;      A short AES encryption
&gt;      Five SHA1s for key expansion
&gt;   And the server does:
&gt;      One RSA private-key decryption
&gt;      A full DH handshake in Z_p
&gt;      A short AES decryption
&gt;      Five SHA1s for key expansion
&gt; 
&gt;   While in the revised handshake, the client does:
&gt;      A full DH handshake
&gt;      A public-half of a DH handshake
&gt;      3 H operations for the handshake
&gt;      3 H operations for the key expansion
&gt;   and the server does:
&gt;      A full DH handshake
&gt;      A private-half of a DH handshake
&gt;      3 H operations for the handshake
&gt;      3 H operations for the key expansion

Note that each H operation is 2 underlying hashes.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110511194230</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-11 19:42:30-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 2:19 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:

Thanks!  I think the git version has most of the trivial stuff cleaned
up now (thanks for a patch from George Kadianakis).  I've also made
notes for most of your suggestions.

&gt; On Wed, May 11, 2011 at 01:33:17PM -0400, Nick Mathewson wrote:

 [...]
&gt;&gt; generates a keypair of y, Y=EXP(g,y) and computes
&gt;&gt;
&gt;&gt;     secret_input = EXP(X,y) | EXP(X,b) | ID | B | X | Y | PROTOID
&gt;&gt;     KEY_SEED = H(secret_input, t_key)
&gt;&gt;     verify = H(secret_input, t_verify)
&gt;
&gt; Depending on the lengths involved, the above may be doing some
&gt; unnecessary work.

What would you suggest instead?

 [...]
&gt;&gt;   where t_expand1..N are tweaks for the hash.
&gt;
&gt; Krawczyk has a paper on how to do this crypto-correctly:
&gt;
&gt; http://eprint.iacr.org/2010/264
&gt;
&gt; See section 8 for an explanation of why the above is not ideal.  Note
&gt; that our "KEY_SEED" is approximately his "PRK", not his "SKM", as it's
&gt; already been hashed.  So if t_expand = PROTOID | ":expand", what's he's
&gt; suggesting is
&gt;
&gt; K = K_1 | K_2 | ...
&gt; where
&gt; K_1 = H(t_expand | 0, KEY_SEED)
&gt; K_(i+1) = H(K_i | t_expand | i, KEY_SEED)
&gt;
&gt; Note that KEY_SEED is used as the HMAC *key*, not the *message*.

Changed.

 [...]
&gt; Note that each H operation is 2 underlying hashes.

RIght.  If we can get away with something faster than HMAC_SHA256
here, I'd love to move to it.  SHA3 is right around the corner, and
most of the candidates seem to allow better constructions for
"tweakability" than HMAC.

Would this make a difference, actually?  Let's see.  Looking at the
numbers from my desktop and doing some back-of-the-envelope
calculations.

I would expect the old handshake to take, total, about 3500
microseconds.  (This is counting both client and server crypto.)

If we tried to do that with 2048-bit keys, it would take, total, about
14700 microseconds.

And I would expect the new handshake to take, total, something like
830 microseconds.  That's more than 4x faster than the old one, and
more than 17x faster than the old one using keys with equivalent
security.  (Nice!)

Of that 830 microseconds, I'd spend something like 3-5% doing SHA256
hashes.  So it might not be worthwhile spending too much time
optimizing the number of hashes here.



thoughts?
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110511195543</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-05-11 19:55:43-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 1:19 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; On Wed, May 11, 2011 at 01:33:17PM -0400, Nick Mathewson wrote:
&gt;&gt; On Fri, May 6, 2011 at 11:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;&gt;  [...]
&gt;&gt; [...]
&gt;
&gt;&gt;   Set H(x,t) == HMAC_SHA256 with message x and key t. So H_LENGTH == 32.
&gt;&gt;   Set t_mac   == PROTOID | ":mac"
&gt;&gt;       t_key1  == PROTOID | ":key1"
&gt;&gt;       t_key2  == PROTOID | ":verify"
&gt;&gt;   Set EXP(a,b) == curve25519(a,b), and g == 9 .
&gt;
&gt; Careful!  The arguments to curve25519 are (output, exponent, base).
&gt; (Note the order; that confused me when we were coding up Sphinx.)
&gt; Presumably you meant for EXP(a,b) to mean a^b, though.
&gt;
&gt; Note that 9 does not have prime order in curve25519; it has order 8
&gt; times a prime.  But if the client always ensures private keys are 0 mod
&gt; 8 (as djb requires; see below), this problem is mostly elided.

More technically we have H=the curve25519 group, which is Z/pZxZ/8Z.
Since private keys are 0 mod 8 they always annihilate the Z/8Z part.
So the curve25519 group is in fact one that is cyclic with prime order
when we generate private keys the right way. The problem is completely
elided
&gt;
&gt;&gt;   Set KEYID(B) == B.  (We don't need to use a hash function here, since our
&gt;&gt;      keys are already very short.  It is trivially collision-resistant, since
&gt;&gt;      KEYID(A)====KEYID(B) iff A==B.)
&gt;
&gt; Is "====" intentional?
&gt;
&gt;&gt; Protocol:
&gt;&gt;
&gt;&gt;   Take a router with identity key digest ID.
&gt;&gt;
&gt;&gt;   As setup, the router generates a secret key b, and a public onion key
&gt;
&gt; All "generates a secret key" operations should follow djb's
&gt; recommendation, of course (fiddle with the 2 high bits, and clear the
&gt; low 3 bits).
&gt;
&gt;&gt;   B = EXP(g,b).  The router publishes B in its server descriptor.
&gt;&gt;
&gt;&gt;   To send a create cell, the client generates a keypair of x, X=EXP(g,y) and
&gt;
&gt; X=EXP(g,x) presumably?
&gt;
&gt;&gt;   sends a CREATE cell with contents:
&gt;&gt;
&gt;&gt;     NODEID:     ID             -- H_LENGTH bytes
&gt;&gt;     KEYID:      KEYID(B)       -- H_LENGTH bytes
&gt;&gt;     CLIENT_PK:  X              -- G_LENGTH bytes
&gt;&gt;
&gt;&gt;   The server checks X,
&gt;
&gt; What is "checks X" here?  Since the server doesn't really care whether
&gt; or not the crypto is good, this check can probably be elided.
In the GSO paper it is required that X be a non identity element. This
is nontrivial given the curve25519 wire format,  but is either
squaring four times or checking that EXP(X,y) is not zero. when we
calculate it.
&gt;
&gt;&gt; generates a keypair of y, Y=EXP(g,y) and computes
&gt;&gt;
&gt;&gt;     secret_input = EXP(X,y) | EXP(X,b) | ID | B | X | Y | PROTOID
&gt;&gt;     KEY_SEED = H(secret_input, t_key)
&gt;&gt;     verify = H(secret_input, t_verify)
&gt;
&gt; Depending on the lengths involved, the above may be doing some
&gt; unnecessary work.
Counting time! EXP(X,y), EXP(X,b), B, X and Y are all 32 bytes, so we
have 160 bytes there. The nearest boundary above is 184, but PROTOID
is 23 bytes and ID is 32 bytes (H_LENG), so we have a total of 215
bytes, wasting 33 bytes in the hash (This is assuming I interpreted 56
(mod 64) correctly). We could take a page out of DJB's book and make
ID simply B to fix this.
&gt;
&gt;&gt;     auth_input = verify | ID | B | Y | X | PROTOID | "Server"
&gt;&gt;
&gt;&gt;   The server sends a CREATED cell containing:
&gt;&gt;
&gt;&gt;     SERVER_PK:  Y                     -- G_LENGTH bytes
&gt;&gt;     AUTH:       H(auth_input, t_mac)  -- H_LENGTH byets
&gt;&gt;
&gt;&gt;   The client then checks Y, and computes
Here we want to count the bytes in the inner and outer hashes. The
outer hash hashes 64 bytes: nothing we can do about that. But the
inner one hashes the key length plus the message length, which here is
189 bytes, 5 bytes over
a nice block boundary.
&gt;
&gt; Here, the check is more important.  Ideally, one would check that Y \in
&gt; G^* (which should have prime order, but doesn't here).  But in
&gt; curve25519, I think you can get away with something a bit cheaper.  If Y
&gt; isn't in G at all, but is on the twist curve, the AUTH verification
&gt; below is certain to fail, so that's OK.  If it's in G, but has low order
&gt; (i.e. order dividing 8), then EXP(Y,x) will end up being the point at
&gt; infinity, which would be bad.  (Indeed, it would be pretty much the same
&gt; problem that Tor had lo those many years ago.) So I think it's probably
&gt; OK to check that EXP(Y,x), which you're computing anyway, is not the
&gt; point at infinity.  I don't remember offhand how curve25519 represents
&gt; that point; it may be as simple as all-0s, but you should check.
Checking EXP(Y,x) is non zero is correct, according to my reading of
the Curve25519 paper and the GSO paper. Again, curve25519 takes place
on a group that has structure Z/pZxZ/8Z, and valid private keys
annihilate the Z/8Z component.

&gt;
&gt; Berkant and Doug, opinions on this?
&gt;
&gt;&gt;     secret_input = EXP(Y,x) | EXP(B,x) | ID | B | X | Y | PROTOID
&gt;&gt;     KEY_SEED = H(secret_input, t_key1)
&gt;
&gt; Above, you used t_key, not t_key1, to create the KEY_SEED.
&gt;
&gt;&gt;     verify = H(secret_input, t_verify)
&gt;&gt;     auth_input = verify | ID | B | Y | X | PROTOID | "Server"
&gt;&gt;
&gt;&gt;     The client verifies that AUTH == H(auth_input, t_mac).
&gt;&gt;
&gt;&gt;   Both parties now have a shared value for KEY_SEED.  They expand this into
&gt;&gt;   the keys needed for the Tor relay protocol.
Here the counting is the same, as the same things are being HMACed.
&gt;&gt;
&gt;&gt; Key expansion:
&gt;&gt;
&gt;&gt;   Currently, the key expansion formula used by Tor here is
&gt;&gt;
&gt;&gt;        K = SHA(K0 | [00]) | SHA(K0 | [01]) | SHH(K0 | [02]) | ...
&gt;
&gt; SHH =&gt; SHA
&gt;
&gt;&gt;        where K0==g^xy, and K is divvied up into Df, Db, Kf, and Kb portions.
&gt;&gt;
&gt;&gt;   Instead, let's have it be
&gt;&gt;
&gt;&gt;        K = H(KEY_SEED, t_expand1) | H(KEY_SEED, t_expand2) | ...
&gt;&gt;
&gt;&gt;   where t_expand1..N are tweaks for the hash.
&gt;
&gt; Krawczyk has a paper on how to do this crypto-correctly:
&gt;
&gt; http://eprint.iacr.org/2010/264
&gt;
&gt; See section 8 for an explanation of why the above is not ideal.  Note
&gt; that our "KEY_SEED" is approximately his "PRK", not his "SKM", as it's
&gt; already been hashed.  So if t_expand = PROTOID | ":expand", what's he's
&gt; suggesting is
&gt;
&gt; K = K_1 | K_2 | ...
&gt; where
&gt; K_1 = H(t_expand | 0, KEY_SEED)
&gt; K_(i+1) = H(K_i | t_expand | i, KEY_SEED)
&gt;
&gt; Note that KEY_SEED is used as the HMAC *key*, not the *message*.
&gt;
&gt;&gt; Performance notes:
&gt;&gt;
&gt;&gt;   In Tor's current circuit creation handshake, the client does:
&gt;&gt;      One RSA public-key encryption
&gt;&gt;      A full DH handshake in Z_p
&gt;&gt;      A short AES encryption
&gt;&gt;      Five SHA1s for key expansion
&gt;&gt;   And the server does:
&gt;&gt;      One RSA private-key decryption
&gt;&gt;      A full DH handshake in Z_p
&gt;&gt;      A short AES decryption
&gt;&gt;      Five SHA1s for key expansion
&gt;&gt;
&gt;&gt;   While in the revised handshake, the client does:
&gt;&gt;      A full DH handshake
&gt;&gt;      A public-half of a DH handshake
&gt;&gt;      3 H operations for the handshake
&gt;&gt;      3 H operations for the key expansion
&gt;&gt;   and the server does:
&gt;&gt;      A full DH handshake
&gt;&gt;      A private-half of a DH handshake
&gt;&gt;      3 H operations for the handshake
&gt;&gt;      3 H operations for the key expansion
&gt;
&gt; Note that each H operation is 2 underlying hashes.
&gt;
&gt;   - Ian
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
The GSO paper uses HMAC for only some of the operations that we are
doing them on and use hash functions of double the length of the HMAC.
Is this an important detail or an unimportant one?

Sincerely,
Watson Ladd
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110511204824</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-11 20:48:24-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Fri, May 6, 2011 at 11:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; [+ Douglas, Berkant]
&gt;

BTW, apologies to Berkant for misspelling his name!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110511220707</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-11 22:07:07-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 02:55:43PM -0500, Watson Ladd wrote:
&gt; &gt; Careful!  The arguments to curve25519 are (output, exponent, base).
&gt; &gt; (Note the order; that confused me when we were coding up Sphinx.)
&gt; &gt; Presumably you meant for EXP(a,b) to mean a^b, though.
&gt; &gt;
&gt; &gt; Note that 9 does not have prime order in curve25519; it has order 8
&gt; &gt; times a prime.  But if the client always ensures private keys are 0 mod
&gt; &gt; 8 (as djb requires; see below), this problem is mostly elided.

I just checked again, and 9 *is* a generator of the prime-order
subgroup, it turns out.  That doesn't affect anything we've said before,
though.

&gt; More technically we have H=the curve25519 group, which is Z/pZxZ/8Z.

Actually, the curve25519 group is isomorphic to Z/pZxZ/4ZxZ/2Z, I'm
pretty sure.  (Oddly, djb's page claims that
325606250916557431795983626356110631294008115727848805560023387167927233504
has order 8, but when I try it, it looks to have order 4 to me.)

But even more correctly, curve25519 is the union of two groups, one
Z/pZxZ/4ZxZ/2Z and the other Z/qZxZ/2ZxZ/2Z, for large primes p and q.
(And even more more correctly, it's the x-coordinates of the elements of
the above groups, which technically doesn't form a group at all, but
does allow for unambiguous exponentiation.)

&gt; Since private keys are 0 mod 8 they always annihilate the Z/8Z part.
&gt; So the curve25519 group is in fact one that is cyclic with prime order
&gt; when we generate private keys the right way. The problem is completely
&gt; elided

I said "mostly" because you still have to check that you don't end up
with the identity element, since you might start out in the small
subgroup.

&gt; &gt; What is "checks X" here?  Since the server doesn't really care whether
&gt; &gt; or not the crypto is good, this check can probably be elided.
&gt; In the GSO paper it is required that X be a non identity element. This
&gt; is nontrivial given the curve25519 wire format,  but is either
&gt; squaring four times or checking that EXP(X,y) is not zero. when we
&gt; calculate it.

The paper does indeed say that, but I'm questioning whether we actually
needed that restriction.  All it's checking is that the client isn't
stupidly picking x=0.  But the server doesn't really care, as it doesn't
know who it's speaking with, anyway.  The client could just as easily
broadcast whatever x it chose.  But yes, for symmetry, we could abort if
EXP(X,y) is the identity element.  (Which I just verified is indeed
represented by all-0s.)

&gt; The GSO paper uses HMAC for only some of the operations that we are
&gt; doing them on and use hash functions of double the length of the HMAC.
&gt; Is this an important detail or an unimportant one?

Nick implemented the "double the length" hashes by simply hashing twice
with different tweaks.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110511221026</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-11 22:10:26-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 03:42:30PM -0400, Nick Mathewson wrote:
&gt; RIght.  If we can get away with something faster than HMAC_SHA256
&gt; here, I'd love to move to it.  SHA3 is right around the corner, and
&gt; most of the candidates seem to allow better constructions for
&gt; "tweakability" than HMAC.
&gt; 
&gt; Would this make a difference, actually?  Let's see.  Looking at the
&gt; numbers from my desktop and doing some back-of-the-envelope
&gt; calculations.
&gt; 
&gt; I would expect the old handshake to take, total, about 3500
&gt; microseconds.  (This is counting both client and server crypto.)
&gt; 
&gt; If we tried to do that with 2048-bit keys, it would take, total, about
&gt; 14700 microseconds.
&gt; 
&gt; And I would expect the new handshake to take, total, something like
&gt; 830 microseconds.  That's more than 4x faster than the old one, and
&gt; more than 17x faster than the old one using keys with equivalent
&gt; security.  (Nice!)
&gt; 
&gt; Of that 830 microseconds, I'd spend something like 3-5% doing SHA256
&gt; hashes.  So it might not be worthwhile spending too much time
&gt; optimizing the number of hashes here.

You're totally right.  No sense stressing about how many hash blocks
we're processing.

Remember also that if you have non-black-box access to the
exponentiation routine, the server can compute X^y and X^b
simultaneously.  That will make a bigger difference in time, but is not
really relevant from a spec-level standpoint.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512000128</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-12 00:01:28-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 6:10 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
 [...]
&gt; Remember also that if you have non-black-box access to the
&gt; exponentiation routine, the server can compute X^y and X^b
&gt; simultaneously.  That will make a bigger difference in time, but is not
&gt; really relevant from a spec-level standpoint.

Can you expand on how this would work?  I didn't ask the first time
you told me this, on the theory that I could figure it out if I
thought about it for long enough, but several days later I still don't
have it.  All the ways I can think of are inefficient,
non-constant-time, or both.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512003309</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 00:33:09-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Wed, May 11, 2011 at 08:01:28PM -0400, Nick Mathewson wrote:
&gt; On Wed, May 11, 2011 at 6:10 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;  [...]
&gt; &gt; Remember also that if you have non-black-box access to the
&gt; &gt; exponentiation routine, the server can compute X^y and X^b
&gt; &gt; simultaneously.  That will make a bigger difference in time, but is not
&gt; &gt; really relevant from a spec-level standpoint.
&gt; 
&gt; Can you expand on how this would work?  I didn't ask the first time
&gt; you told me this, on the theory that I could figure it out if I
&gt; thought about it for long enough, but several days later I still don't
&gt; have it.  All the ways I can think of are inefficient,
&gt; non-constant-time, or both.

Use right-to-left exponentiation.  This is totally off the top of my
head.

def exp(base,expon):
    a = base
    mask = 1
    res = 1
    # Invariant: a = base^mask
    do:
	# Be a little cleverer about the if if you
	# care about constant-time; just save the output
	# somewhere useless
	if (expon &amp; mask): # bitwise and
	    res = res*a
	a *= a
	mask &lt;&lt;= 1
    until (mask is larger than the maximum possible expon)
    return res

Then exp2(base, expon1, expon2) will be:

def exp2(base,expon1, expon2):
    a = base
    mask = 1
    res1 = 1
    res2 = 1
    # Invariant: a = base^mask
    do:
	# Be a little cleverer about the if if you
	# care about constant-time; just save the output
	# somewhere useless
	if (expon1 &amp; mask): # bitwise and
	    res1 = res1*a
	if (expon2 &amp; mask): # bitwise and
	    res2 = res2*a
	a *= a
	mask &lt;&lt;= 1
    until (mask is larger than the maximum possible expon)
    return (res1, res2)


The idea is that the squarings are common between the exps, and just the
multiplications have to be done separately.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512040710</emailId><senderName>Douglas Stebila</senderName><senderEmail>stebila@qut.edu.au</senderEmail><timestampReceived>2011-05-12 04:07:10-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On 2011/05/12, at 10:33, Ian Goldberg wrote:

&gt; &gt; &gt; Remember also that if you have non-black-box access to the
&gt; &gt; &gt; exponentiation routine, the server can compute X^y and X^b
&gt; &gt; &gt; simultaneously.  That will make a bigger difference in time, but is not
&gt; &gt; &gt; really relevant from a spec-level standpoint.
&gt; &gt; 
&gt; &gt; Can you expand on how this would work?  I didn't ask the first time
&gt; &gt; you told me this, on the theory that I could figure it out if I
&gt; &gt; thought about it for long enough, but several days later I still don't
&gt; &gt; have it.  All the ways I can think of are inefficient,
&gt; &gt; non-constant-time, or both.
&gt; 
&gt; Use right-to-left exponentiation.  This is totally off the top of my
&gt; head.
...
&gt; Then exp2(base, expon1, expon2) will be:
...

Implementing simultaneous exponentiation for curve25519 is going to be problematic, \
no matter how simple the algorithm, because Dan Bernstein's curve25519 main loop code \
is an unravelled assembly file.  Modifying it directly to do simultaneous \
exponentiation will be a huge pain.  I expect he actually wrote the code using his \
personal pseudo-assembly language called qhasm and then generated the .s Athlon \
assembly from that.  We could email him to ask.  Without it, and without spending \
decades decoding the assembly, his curve25519 code, even when run twice, will likely \
be faster than any simultaneous exponentiation code I write myself.

On 2011/05/12, at 04:19, Ian Goldberg wrote:

&gt; &gt; CLIENT_PK:  X              -- G_LENGTH bytes
&gt; &gt; 
&gt; &gt; The server checks X,
&gt; 
&gt; What is "checks X" here?  Since the server doesn't really care whether
&gt; or not the crypto is good, this check can probably be elided.
&gt; 
&gt; &gt; The server sends a CREATED cell containing:
&gt; &gt; 
&gt; &gt; SERVER_PK:  Y                     -- G_LENGTH bytes
&gt; &gt; AUTH:       H(auth_input, t_mac)  -- H_LENGTH byets
&gt; &gt; 
&gt; &gt; The client then checks Y, and computes
&gt; 
&gt; Here, the check is more important.  Ideally, one would check that Y \in
&gt; G^* (which should have prime order, but doesn't here).  But in
&gt; curve25519, I think you can get away with something a bit cheaper.  If Y
&gt; isn't in G at all, but is on the twist curve, the AUTH verification
&gt; below is certain to fail, so that's OK.  If it's in G, but has low order
&gt; (i.e. order dividing 8), then EXP(Y,x) will end up being the point at
&gt; infinity, which would be bad.  (Indeed, it would be pretty much the same
&gt; problem that Tor had lo those many years ago.) So I think it's probably
&gt; OK to check that EXP(Y,x), which you're computing anyway, is not the
&gt; point at infinity.  I don't remember offhand how curve25519 represents
&gt; that point; it may be as simple as all-0s, but you should check.


In curve25519, every 32-byte string is a valid public key.  The curve25519 webpage
	http://cr.yp.to/ecdh.html
says that public key validation is not required for Diffie-Hellman key agreement.  \
The webpage also lists several points that do not guarantee "contributory" behaviour, \
which the webpage suggests may be important in non-DH protocols.  Contributory, as I \
know it, refers to when it is important that both parties contributed some randomness \
to the protocol.  I would think that being contributory is a desirable property of \
key agreement, as it seems necessary for forward secrecy.  Perhaps I'm \
misunderstanding this, however.

Douglas
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110512093206</emailId><senderName>Berkant Ustaoglu</senderName><senderEmail>bustaoglu@cryptolounge.net</senderEmail><timestampReceived>2011-05-12 09:32:06-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

Quoting Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt;:
&gt;&gt; &gt; What is "checks X" here?  Since the server doesn't really care whether
&gt;&gt; &gt; or not the crypto is good, this check can probably be elided.
&gt;&gt; In the GSO paper it is required that X be a non identity element. This
&gt;&gt; is nontrivial given the curve25519 wire format,  but is either
&gt;&gt; squaring four times or checking that EXP(X,y) is not zero. when we
&gt;&gt; calculate it.
&gt;
&gt; The paper does indeed say that, but I'm questioning whether we actually
&gt; needed that restriction.  All it's checking is that the client isn't
&gt; stupidly picking x=0.  But the server doesn't really care, as it doesn't
&gt; know who it's speaking with, anyway.  The client could just as easily
&gt; broadcast whatever x it chose.  But yes, for symmetry, we could abort if
&gt; EXP(X,y) is the identity element.  (Which I just verified is indeed
&gt; represented by all-0s.)
&gt;

In theory, the check X \in G* does a bit more than selecting x=0,  
namely prevents invalid curve attacks. A server doesn't really care  
for the security of a single connection (the anonymous client may  
decide on purpose to reveal it's secrets and only the client would  
suffer, server and other clients will remain unaffected). If however,  
the server blindly accepts anything, then server would accept X' that  
lies on an invalid curve where X' has small prime order. As a result  
an adversary could potentially learn server's "b" - for comparison  
invalid curve attacks apply to MQV, HMQV with similar result (leaked  
static keys); I think it took a day for Alfred to verify the attack  
works on HMQV for a curve defined in FIPS 186-2. Having server's Y and  
the secret X'^y would complicate the attack a bit, but for  
sufficiently motivated adversary I suspect it will not be a barrier.  
As a result, if a client does establish a connection with the server,  
the adversary cannot compromise the security of that particular  
connection, but it would be trivial to fool the client to establish  
connection with the adversary thinking the connection is with an  
honest server.

In practice, I haven't read D. Bernsteins curve25519-20060209.pdf in  
detail. It claims (as pointed out by Doug) that there is "free key  
validation", which seems to imply invalid curves are not an issue.  
However, I'd still suggest to keep the check X \in G* if at least to  
serve as warning should there be a decision to move away from  
curve25519.

There may be an alternative form of validation: instead of computing  
X^y and X^b, the shared secret can be set as X^8y and X^8b. The  
results is verified to not match identity point (assuming X \in G of  
course). This will kill any multiples coming from the cofactor 8. If I  
recall correctly something along these lines is going on in SP800-56A  
for ECMQV.

- BU

-- 
Berkant Ustaoglu
http://cryptolounge.net

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512105754</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 10:57:54-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 05:32:06AM -0400, Berkant Ustaoglu wrote:
&gt; There may be an alternative form of validation: instead of computing
&gt; X^y and X^b, the shared secret can be set as X^8y and X^8b. The
&gt; results is verified to not match identity point (assuming X \in G of
&gt; course). This will kill any multiples coming from the cofactor 8. If
&gt; I recall correctly something along these lines is going on in
&gt; SP800-56A for ECMQV.

Indeed, private keys for curve25519 _must_ be multiples of 8, for
exactly this reason.  So b and y will already be multiples of 8, and if
the client's X is on the twist curve, it still ends up with large prime
order, and all is OK.

I think this suggestion merits examination, though:

&gt; However, I'd still suggest to keep the check X \in G* if at least to
&gt; serve as warning should there be a decision to move away from
&gt; curve25519.

Indeed, any "optimizations" we do knowing we're using special properties
of curve25519 need to be thoroughly documents, preferably both as inline
comments and in the spec documentation.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512111358</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 11:13:58-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 02:07:10PM +1000, Douglas Stebila wrote:
&gt; Implementing simultaneous exponentiation for curve25519 is going to be
&gt; problematic, no matter how simple the algorithm, because Dan
&gt; Bernstein's curve25519 main loop code is an unravelled assembly file.
&gt; Modifying it directly to do simultaneous exponentiation will be a huge
&gt; pain.  I expect he actually wrote the code using his personal
&gt; pseudo-assembly language called qhasm and then generated the .s Athlon
&gt; assembly from that.  We could email him to ask.  Without it, and
&gt; without spending decades decoding the assembly, his curve25519 code,
&gt; even when run twice, will likely be faster than any simultaneous
&gt; exponentiation code I write myself.

Nick, were you planning on using djb's qhasm code, or the C version
(curve25519-donna)?  (A quick look at the latter suggests it's doing
left-to-right, so some changes would still be required, but not evil
assembly ones.

&gt; In curve25519, every 32-byte string is a valid public key.  The
&gt; curve25519 webpage
&gt; 	http://cr.yp.to/ecdh.html
&gt; says that public key validation is not required for Diffie-Hellman key
&gt; agreement.  The webpage also lists several points that do not
&gt; guarantee "contributory" behaviour, which the webpage suggests may be
&gt; important in non-DH protocols.  Contributory, as I know it, refers to
&gt; when it is important that both parties contributed some randomness to
&gt; the protocol.  I would think that being contributory is a desirable
&gt; property of key agreement, as it seems necessary for forward secrecy.
&gt; Perhaps I'm misunderstanding this, however.

Every string is a valid public key, but half of them are on the twist
curve instead of the normal curve.  As discussed in the other part of
the thread, this turns out not to matter because the twist curve has
order 4*p_2.

Now that I think about it, I'm no longer positive that the client
absolutely needs to check that Y has large order, since the adversary
still won't know B^x = X^b.

So *either* the client should check this, *or* the directory authorities
should check that submitted B's are in G^*.  (Or both.  I think both is
best.)

That said, the client check is practically free; it's calculating
EXP(Y,x) anyway, and it just needs to memcmp that with 32 bytes of 0.

The directory authorities should probably checks the B's anyway, just to
be sane.  They should all have order exactly p_1, so check that
EXP(B,8) is not O, and check that EXP(B,p_1) is O.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512121255</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 12:12:55-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 07:13:58AM -0400, Ian Goldberg wrote:
&gt; The directory authorities should probably checks the B's anyway, just to
&gt; be sane.  They should all have order exactly p_1, so check that
&gt; EXP(B,8) is not O, and check that EXP(B,p_1) is O.

While we're talking about this, note that our paper says that the CA
(the directory authority here) should check that the node submitting B
actually does know b (the private key).  This could be as simple as the
standard Fiat-Shamir NIZKPK.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110512125639</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-05-12 12:56:39-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 7:13 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; Nick, were you planning on using djb's qhasm code, or the C version
&gt; (curve25519-donna)?   (A quick look at the latter suggests it's doing
&gt; left-to-right, so some changes would still be required, but not evil
&gt; assembly ones.

donna is much faster than the reference implementation on 64-bit, but
much slower at 32-bit. The reference implementation was, indeed,
derived from a qhasm source, although I don't have it. (donna was only
intended to work on 64-bit systems, the 32-bit version is just for
completeness.)

Since both use Montgomery's trick for operating in the group, it's not
clear that either are amenable to implementing simultaneous
exponentiation. However, curve25519 is generally sufficiently fast
that calling it twice is still faster than a simultaneous
exponentiation on other curves:
http://www.imperialviolet.org/2010/12/21/eccspeed.html


Cheers

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512135155</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-12 13:51:55-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 8:56 AM, Adam Langley &lt;agl@imperialviolet.org&gt; wrote:
&gt; On Thu, May 12, 2011 at 7:13 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;&gt; Nick, were you planning on using djb's qhasm code, or the C version
&gt;&gt; (curve25519-donna)?  (A quick look at the latter suggests it's doing
&gt;&gt; left-to-right, so some changes would still be required, but not evil
&gt;&gt; assembly ones.
&gt;
&gt; donna is much faster than the reference implementation on 64-bit, but
&gt; much slower at 32-bit. The reference implementation was, indeed,
&gt; derived from a qhasm source, although I don't have it. (donna was only
&gt; intended to work on 64-bit systems, the 32-bit version is just for
&gt; completeness.)

It's likely we'll want to use the fast reference implementation on
32-bit intel (It's assembly, right?), and donna on 64-bit platforms.
We're going to need to find an answer for 32-bit PPC and ARM
platforms, though.  Any suggestions there?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512141011</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-12 14:10:11-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 8:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; On Thu, May 12, 2011 at 07:13:58AM -0400, Ian Goldberg wrote:
&gt;&gt; The directory authorities should probably checks the B's anyway, just to
&gt;&gt; be sane.  They should all have order exactly p_1, so check that
&gt;&gt; EXP(B,8) is not O, and check that EXP(B,p_1) is O.
&gt;
&gt; While we're talking about this, note that our paper says that the CA
&gt; (the directory authority here) should check that the node submitting B
&gt; actually does know b (the private key).  This could be as simple as the
&gt; standard Fiat-Shamir NIZKPK.

Hm.  What goes wrong in the protocol as I've written it if the
authorities *don't* check this?  As "simple" as you say Fiat-Shamir
is, it would seem to add a few round trips to the server publication
protocol.

So let's see.  If we don't check that the server really knows the
private key for B, then the server could either publish a junk value
of B for which nobody knows the private key, or the server could
publish somebody else's B.  What would this hurt?

In the junk-B case, nobody knows b, so nobody can compute EXP(X,b)
without knowing x, so the server cant generate a created cell that the
client will accept.

In the stolen-B case, the attacker could try to do an MITM and pass
the client's CREATE cell to the server that *does* know b.  But that
won't work in the variant I specified, since secret_input and
auth_input both include an ID field based on the server's identity
key.  The client will only accept a CREATED cell whose AUTH field is
based on the desired server's identity key, but the server that *does*
know b will only generate a CREATED cell whose AUTH field is based on
its own identity key.

So I think that adding the ID field to secret_input and auth_input
solves the problem here.  Am I missing something?

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512142555</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 14:25:55-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 10:10:11AM -0400, Nick Mathewson wrote:
&gt; On Thu, May 12, 2011 at 8:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt; On Thu, May 12, 2011 at 07:13:58AM -0400, Ian Goldberg wrote:
&gt; &gt;&gt; The directory authorities should probably checks the B's anyway, just to
&gt; &gt;&gt; be sane.  They should all have order exactly p_1, so check that
&gt; &gt;&gt; EXP(B,8) is not O, and check that EXP(B,p_1) is O.
&gt; &gt;
&gt; &gt; While we're talking about this, note that our paper says that the CA
&gt; &gt; (the directory authority here) should check that the node submitting B
&gt; &gt; actually does know b (the private key).  This could be as simple as the
&gt; &gt; standard Fiat-Shamir NIZKPK.
&gt; 
&gt; Hm.  What goes wrong in the protocol as I've written it if the
&gt; authorities *don't* check this?  As "simple" as you say Fiat-Shamir
&gt; is, it would seem to add a few round trips to the server publication
&gt; protocol.

No, Fiat-Shamir is the non-interactive (the NI in NIZKPK) version, so
the node would just attach the proof to B when it submits it.

Node knows b and B = g^b
Node picks random t \in Z/p_Z where p is the order of g
Node computes c = H(g^t | B | ID | D)
    where ID is the node ID, D is any other data already sent or
    received in the server publication protocol
Node computes r = t - c*b mod p
Node sends (c,r) along with B to be registered.  (256+256 bits)

The DA checks that c =?= H(g^r * B^c | B | ID | D) before accepting the
registration.

You're right that it seems unlikely anything will go wrong in this
particular protocol if B is unattested.  But then you're getting back to
lots of moving parts relying on the properties of other moving parts.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512142830</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-05-12 14:28:30-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 09:51:55AM -0400, Nick Mathewson wrote:
&gt; On Thu, May 12, 2011 at 8:56 AM, Adam Langley &lt;agl@imperialviolet.org&gt; wrote:
&gt; &gt; On Thu, May 12, 2011 at 7:13 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt;&gt; Nick, were you planning on using djb's qhasm code, or the C version
&gt; &gt;&gt; (curve25519-donna)?  (A quick look at the latter suggests it's doing
&gt; &gt;&gt; left-to-right, so some changes would still be required, but not evil
&gt; &gt;&gt; assembly ones.
&gt; &gt;
&gt; &gt; donna is much faster than the reference implementation on 64-bit, but
&gt; &gt; much slower at 32-bit. The reference implementation was, indeed,
&gt; &gt; derived from a qhasm source, although I don't have it. (donna was only
&gt; &gt; intended to work on 64-bit systems, the 32-bit version is just for
&gt; &gt; completeness.)
&gt; 
&gt; It's likely we'll want to use the fast reference implementation on
&gt; 32-bit intel (It's assembly, right?), and donna on 64-bit platforms.
&gt; We're going to need to find an answer for 32-bit PPC and ARM
&gt; platforms, though.  Any suggestions there?

Does "the 32-bit version is just for completeness" mean there _is_ a
(slower?) 32-bit version in donna?  Or only for x86?

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512142932</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-05-12 14:29:32-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 9:51 AM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; It's likely we'll want to use the fast reference implementation on
&gt; 32-bit intel (It's assembly, right?), and donna on 64-bit platforms.
&gt; We're going to need to find an answer for 32-bit PPC and ARM
&gt; platforms, though.   Any suggestions there?

The 32-bit C version will function for these platforms and they're
only clients, right? So if they're slower it's dramatically less
important. I'm sure that I can also tune up the 32-bit version should
there be anyone using it.


Cheers

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512143021</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-05-12 14:30:21-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

On Thu, May 12, 2011 at 10:28 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; Does "the 32-bit version is just for completeness" mean there _is_ a
&gt; (slower?) 32-bit version in donna?   Or only for x86?

Yes, there's a 32-bit version:
https://github.com/agl/curve25519-donna/blob/master/curve25519-donna.c
with room for improvement.


Cheers

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110512143147</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2011-05-12 14:31:47-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

This is just a headsup message that the discussion and progress on
this topic is great, but should not be viewed as the whole picture for
a circuit protocol.

I was just talking to Ian and noting that, despite calling it
"culminating" in their paper, the fourth protocol that Lasse and I did
was not intended to be culminating but only, well fourth.
The question of how to build the circuit is not just about the
crypto of the handshake, but also about which messages get passed
when and what sorts of forward anonymity guarantees are provided 
and/or needed. This was at least as much a focus of my paper with Lasse
as the suggested way of trying to be efficient in the exponentiation
in the fourth protocol. Ian tells me that he has another paper dealing
with these further issues as well, which he will check into being
able to make available in tech report. So maybe there will be
a further discussion and proposal on those issues.

Anyway, keep up the good work all. Just keep in mind that there may
be other issues. Hopefully they can be addressed modularly so
won't imply pulling apart what is provable in what is currently
progressing (or giving up on them because at that point it would
be too hard to go back).

aloha,
Paul
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507004932</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-05-07 00:49:32-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On May 6, 2011, at 5:08 PM, Jacob Appelbaum wrote:

&gt; We can
&gt; #define over memcmp but I fear that it's better to specifically
&gt; eradicate each one by hand and really think things over on a case by
&gt; case basis.

FWIW, I agree.

Nice work, Marsh!


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation
https://www.eff.org/code

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507010037</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-07 01:00:37-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On Fri, May 6, 2011 at 7:13 PM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt;
&gt; Greetings all,
&gt;
Hi, Marsh!

I replied on https://trac.torproject.org/projects/tor/ticket/3122#comment:4
.  The particular case that you mention is (I think) safe (see
discussion there), but the problem in general is worrisome and we
should indeed replace (nearly) all of our memcmps with
data-independent variants.

(Pedantic nit-pick: we should be saying "data-independent," not
"constant-time."  We want a memcmp(a,b,c) that takes the same number
of cycles for a given value of c no matter what a and b are.  That's
data-independence.  A constant-time version would be one that took the
same number of cycles no matter what c is.)

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507024032</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-05-07 02:40:32-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On 05/06/2011 08:00 PM, Nick Mathewson wrote:
&gt; .  The particular case that you mention is (I think) safe (see
&gt; discussion there),

I figured it probably was, but illustrated some red flags.

&gt; but the problem in general is worrisome and we
&gt; should indeed replace (nearly) all of our memcmps with
&gt; data-independent variants.

Maybe some of the str*cmps too? I grep 681 of them.

We should also look for other cases where any data or padding might be 
checked, decompressed, or otherwise operated on without being as obvious 
as calling memcmp. Lots of error conditions can disclose timing information.

&gt; (Pedantic nit-pick: we should be saying "data-independent," not
&gt; "constant-time."  We want a memcmp(a,b,c) that takes the same number
&gt; of cycles for a given value of c no matter what a and b are.  That's
&gt; data-independence.  A constant-time version would be one that took the
&gt; same number of cycles no matter what c is.)

That's a good point. In most of the code I glanced at, the length was 
fixed at compile-time. I suppose a proper "constant-time" function would 
have to take as much time as a 2GB comparison (on 32) :-).

&gt; int mem_neq(const void *m1, const void *m2, size_t n)
&gt; {
&gt;   const uint8_t *b1 = m1, *b2 = m2;
&gt;   uint8_t diff = 0;
&gt;   while (n--)
&gt;     diff |= *b1++ ^ *b2++;
&gt;   return diff != 0;
&gt; }
&gt; #define mem_eq(m1, m2, n) (!mem_neq((m1), (m2),(n)))

Looks good to me.

What if n is 0? Is 'equals' or 'neq' a more conservative default ?

Would it make sense to die in a well-defined way if m1 or m2 is NULL?

Also, if the MSB of n is set it's an invalid condition, the kind that 
could result from a conversion from a signed value.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507031458</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-07 03:14:58-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On Fri, May 6, 2011 at 10:40 PM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
[...]
&gt;&gt; but the problem in general is worrisome and we
&gt;&gt; should indeed replace (nearly) all of our memcmps with
&gt;&gt; data-independent variants.
&gt;
&gt; Maybe some of the str*cmps too? I grep 681 of them.

Yeah; most of these are not parsing anything secret, but we should
audit all of them to look for worrisome cases.  It's even less clear
what data-independence means for strcmp: possibly it means that the
run-time should depend only on the length of the shorter string, or
the longer string, or on one of the arguments arbitrarily designated
as the "non-secret" string, or such.  All of these could be reasonable
under some circumstances, but we should figure out what we actually
mean.

&gt; We should also look for other cases where any data or padding might be
&gt; checked, decompressed, or otherwise operated on without being as obvious as
&gt; calling memcmp. Lots of error conditions can disclose timing information.

Yeah.  This is going to be a reasonably big job.

&gt;&gt; (Pedantic nit-pick: we should be saying "data-independent," not
&gt;&gt; "constant-time."  We want a memcmp(a,b,c) that takes the same number
&gt;&gt; of cycles for a given value of c no matter what a and b are.  That's
&gt;&gt; data-independence.  A constant-time version would be one that took the
&gt;&gt; same number of cycles no matter what c is.)
&gt;
&gt; That's a good point. In most of the code I glanced at, the length was fixed
&gt; at compile-time. I suppose a proper "constant-time" function would have to
&gt; take as much time as a 2GB comparison (on 32) :-).
&gt;
&gt;&gt; int mem_neq(const void *m1, const void *m2, size_t n)
&gt;&gt; {
&gt;&gt;  const uint8_t *b1 = m1, *b2 = m2;
&gt;&gt;  uint8_t diff = 0;
&gt;&gt;  while (n--)
&gt;&gt;    diff |= *b1++ ^ *b2++;
&gt;&gt;  return diff != 0;
&gt;&gt; }
&gt;&gt; #define mem_eq(m1, m2, n) (!mem_neq((m1), (m2),(n)))
&gt;
&gt; Looks good to me.
&gt;
&gt; What if n is 0? Is 'equals' or 'neq' a more conservative default ?

If n is 0, then "equals" is the answer: all empty strings are equal, right? :)

&gt; Would it make sense to die in a well-defined way if m1 or m2 is NULL?

Adding a tor_assert(m1 &amp;&amp; m2) would be fine.

&gt; Also, if the MSB of n is set it's an invalid condition, the kind that could
&gt; result from a conversion from a signed value.

Adding a tor_assert(n &lt; SIZE_T_CEILING) is our usual way of handling this.

Also, as I said on the bug, doing a memcmp in constant time is harder
than doing eq/neq.  I *think* that all of the cases where we care
about memcmp returning a tristate -1/0/1 result, we don't need
data-independence... but in case we *do* need one, we'll have to do
some malarkey like

int memcmp(const void *m1, const void *m2, size_t n)
{
/*XXX I don't know if this is even right; I haven't tested it at all */
  const uint8_t *b1 = m1, *b2 = m2;
  int retval = 0;

  while (n--) {
    const uint8_t v1 = b1[n], v2 = b2[n];
    int diff = (int)v1 - (int)v2;
    retval = (v1 == v2) * retval + diff;
  }

  return retval;
}

which frankly makes me sad.  I bet there's a better way to go.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110507035310</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-07 03:53:10-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On Fri, 6 May 2011 23:14:58 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Fri, May 6, 2011 at 10:40 PM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt; [...]
&gt; &gt;&gt; but the problem in general is worrisome and we
&gt; &gt;&gt; should indeed replace (nearly) all of our memcmps with
&gt; &gt;&gt; data-independent variants.
&gt; &gt;
&gt; &gt; Maybe some of the str*cmps too? I grep 681 of them.
&gt; 
&gt; Yeah; most of these are not parsing anything secret, but we should
&gt; audit all of them to look for worrisome cases.  It's even less clear
&gt; what data-independence means for strcmp: possibly it means that the
&gt; run-time should depend only on the length of the shorter string, or
&gt; the longer string, or on one of the arguments arbitrarily designated
&gt; as the "non-secret" string, or such.  All of these could be reasonable
&gt; under some circumstances, but we should figure out what we actually
&gt; mean.
&gt; 
&gt; &gt; We should also look for other cases where any data or padding might be
&gt; &gt; checked, decompressed, or otherwise operated on without being as obvious as
&gt; &gt; calling memcmp. Lots of error conditions can disclose timing information.
&gt; 
&gt; Yeah.  This is going to be a reasonably big job.
&gt; 
&gt; &gt;&gt; (Pedantic nit-pick: we should be saying "data-independent," not
&gt; &gt;&gt; "constant-time."   We want a memcmp(a,b,c) that takes the same number
&gt; &gt;&gt; of cycles for a given value of c no matter what a and b are.   That's
&gt; &gt;&gt; data-independence.   A constant-time version would be one that took the
&gt; &gt;&gt; same number of cycles no matter what c is.)
&gt; &gt;
&gt; &gt; That's a good point. In most of the code I glanced at, the length was fixed
&gt; &gt; at compile-time. I suppose a proper "constant-time" function would have to
&gt; &gt; take as much time as a 2GB comparison (on 32) :-).
&gt; &gt;
&gt; &gt;&gt; int mem_neq(const void *m1, const void *m2, size_t n)
&gt; &gt;&gt; {
&gt; &gt;&gt;   const uint8_t *b1 = m1, *b2 = m2;
&gt; &gt;&gt;   uint8_t diff = 0;
&gt; &gt;&gt;   while (n--)
&gt; &gt;&gt;      diff |= *b1++ ^ *b2++;
&gt; &gt;&gt;   return diff != 0;
&gt; &gt;&gt; }
&gt; &gt;&gt; #define mem_eq(m1, m2, n) (!mem_neq((m1), (m2),(n)))
&gt; &gt;
&gt; &gt; Looks good to me.
&gt; &gt;
&gt; &gt; What if n is 0? Is 'equals' or 'neq' a more conservative default ?
&gt; 
&gt; If n is 0, then "equals" is the answer: all empty strings are equal, right? :)
&gt; 
&gt; &gt; Would it make sense to die in a well-defined way if m1 or m2 is NULL?
&gt; 
&gt; Adding a tor_assert(m1 &amp;&amp; m2) would be fine.
&gt; 
&gt; &gt; Also, if the MSB of n is set it's an invalid condition, the kind that could
&gt; &gt; result from a conversion from a signed value.
&gt; 
&gt; Adding a tor_assert(n &lt; SIZE_T_CEILING) is our usual way of handling this.
&gt; 
&gt; Also, as I said on the bug, doing a memcmp in constant time is harder
&gt; than doing eq/neq.  I *think* that all of the cases where we care
&gt; about memcmp returning a tristate -1/0/1 result, we don't need
&gt; data-independence... but in case we *do* need one, we'll have to do
&gt; some malarkey like
&gt; 
&gt; int memcmp(const void *m1, const void *m2, size_t n)
&gt; {
&gt; /*XXX I don't know if this is even right; I haven't tested it at all */
&gt;   const uint8_t *b1 = m1, *b2 = m2;
&gt;   int retval = 0;
&gt; 
&gt;   while (n--) {
&gt;     const uint8_t v1 = b1[n], v2 = b2[n];
&gt;     int diff = (int)v1 - (int)v2;
&gt;     retval = (v1 == v2) * retval + diff;
&gt;   }
&gt; 
&gt;   return retval;
&gt; }

GCC is likely to turn (v1 == v2) into a backdoor.  Also, we would need
to make sure sign extension is constant-time; it *probably* is on IA-32
and AMD64, but we may need to disassemble the compiler's output to
verify that on ARM.

Other than that, it looks correct.  We *can* fix the dependence on ==
and make the multiply unnecessary at the same time, though.


I've attached my optimized constant-time comparison functions for
16-byte and 32-byte values to this message.  They're packaged in the
format for a submission to SUPERCOP and/or NaCl, but for some reason I
never actually submitted them.


Robert Ransom

[Attachment #7 (application/x-xz)]
["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110507044738</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-07 04:47:38-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On Fri, 6 May 2011 23:14:58 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; Also, as I said on the bug, doing a memcmp in constant time is harder
&gt; than doing eq/neq.  I *think* that all of the cases where we care
&gt; about memcmp returning a tristate -1/0/1 result, we don't need
&gt; data-independence... but in case we *do* need one, we'll have to do
&gt; some malarkey like
&gt; 
&gt; int memcmp(const void *m1, const void *m2, size_t n)
&gt; {
&gt; /*XXX I don't know if this is even right; I haven't tested it at all */
&gt;   const uint8_t *b1 = m1, *b2 = m2;
&gt;   int retval = 0;
&gt; 
&gt;   while (n--) {
&gt;     const uint8_t v1 = b1[n], v2 = b2[n];
&gt;     int diff = (int)v1 - (int)v2;
&gt;     retval = (v1 == v2) * retval + diff;
&gt;   }
&gt; 
&gt;   return retval;
&gt; }
&gt; 
&gt; which frankly makes me sad.  I bet there's a better way to go.

See attached.  This one is also untested (and I didn't even put the
"#include &lt;stdint.h&gt;" in the file), but it *should* work.

My technique for calculating equal_p came from my uint32-based
crypto_verify function in my previous message, which was in turn based
partly on DJB's crypto_verify functions and partly on a disassembly of
what GCC compiled DJB's functions to on a Fedora 12 AMD64 box.  But I
couldn't tell that the technique was correct, so this time I added
comments to it.


Robert Ransom

[Attachment #7 (text/x-c++src)]

int tor_memcmp(const void *x_, const void *y_, size_t len) {
  const uint8_t *x = x_;
  const uint8_t *y = y_;
  size_t i = len;
  int retval = 0;

  /* The following assumes we are on a system with two's-complement
   * arithmetic. */
  while (i--) {
    int v1 = x_[i];
    int v2 = y_[i];
    int equal_p = v1 ^ v2;

    /* The following sets bits 8 and above of equal_p to equal_p == 0,
       and thus to v1 == v2. */
    --equal_p;

    equal_p &gt;&gt;= 8;
    /* Now equal_p is equal to -(v1 == v2), which is exactly
     * what we need below. */

    /* If v1 == v2, leave retval unchanged; otherwise, zero it. */
    retval &amp;= equal_p;

    /* If we just zeroed retval, set it to v1 - v2; otherwise, leave
     * it unchanged. */
    retval += (v1 - v2);
  }

  return retval;
}


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110507045712</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-07 04:57:12-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On Sat, May 7, 2011 at 12:47 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On Fri, 6 May 2011 23:14:58 -0400
&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt;&gt; Also, as I said on the bug, doing a memcmp in constant time is harder
&gt;&gt; than doing eq/neq.  I *think* that all of the cases where we care
&gt;&gt; about memcmp returning a tristate -1/0/1 result, we don't need
&gt;&gt; data-independence... but in case we *do* need one, we'll have to do
&gt;&gt; some malarkey like
&gt;&gt;
&gt;&gt; int memcmp(const void *m1, const void *m2, size_t n)
&gt;&gt; {
&gt;&gt; /*XXX I don't know if this is even right; I haven't tested it at all */
&gt;&gt;   const uint8_t *b1 = m1, *b2 = m2;
&gt;&gt;   int retval = 0;
&gt;&gt;
&gt;&gt;   while (n--) {
&gt;&gt;     const uint8_t v1 = b1[n], v2 = b2[n];
&gt;&gt;     int diff = (int)v1 - (int)v2;
&gt;&gt;     retval = (v1 == v2) * retval + diff;
&gt;&gt;   }
&gt;&gt;
&gt;&gt;   return retval;
&gt;&gt; }
&gt;&gt;
&gt;&gt; which frankly makes me sad.  I bet there's a better way to go.
&gt;
&gt; See attached.  This one is also untested (and I didn't even put the
&gt; #include &lt;stdint.h&gt; in the file), but it *should* work.
&gt;
&gt; My technique for calculating equal_p came from my uint32-based
&gt; crypto_verify function in my previous message, which was in turn based
&gt; partly on DJB's crypto_verify functions and partly on a disassembly of
&gt; what GCC compiled DJB's functions to on a Fedora 12 AMD64 box.  But I
&gt; couldn't tell that the technique was correct, so this time I added
&gt; comments to it.

Clever!  It does look it *should* work.  Somewhere along the line we
should test the heck out of it and more sure it does.

(Also, Tor *does* assume that the arithmetic is two's complement: we
check for it in configure.in and die horribly in torint.h if it
isn't.)

Also, I suggest that we move as much of this as possible over to the
bugtracker: discussing this in two places is giving me whiplash.  I've
posted a suggested plan of attack there.

Now alas I should sleep.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110507051106</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-05-07 05:11:06-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On May 6, 2011, at 8:53 PM, Robert Ransom wrote:

&gt;&gt; int memcmp(const void *m1, const void *m2, size_t n)
&gt;&gt; {
&gt;&gt; /*XXX I don't know if this is even right; I haven't tested it at all */
&gt;&gt;  const uint8_t *b1 = m1, *b2 = m2;
&gt;&gt;  int retval = 0;
&gt;&gt; 
&gt;&gt;  while (n--) {
&gt;&gt;    const uint8_t v1 = b1[n], v2 = b2[n];
&gt;&gt;    int diff = (int)v1 - (int)v2;
&gt;&gt;    retval = (v1 == v2) * retval + diff;
&gt;&gt;  }
&gt;&gt; 
&gt;&gt;  return retval;
&gt;&gt; }
&gt; 
&gt; GCC is likely to turn (v1 == v2) into a backdoor.

Can you explain what you mean?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507052552</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-07 05:25:52-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 6 May 2011 22:11:06 -0700
Chris Palmer &lt;chris@eff.org&gt; wrote:

&gt; On May 6, 2011, at 8:53 PM, Robert Ransom wrote:

&gt; &gt; GCC is likely to turn (v1 == v2) into a backdoor.
&gt; 
&gt; Can you explain what you mean?

I would expect GCC (and most other C compilers) to use a
non-constant-time implementation of (v1 == v2).


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110507053526</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-05-07 05:35:26-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On 05/06/2011 09:40 PM, Marsh Ray wrote:
&gt; On 05/06/2011 08:00 PM, Nick Mathewson wrote:
&gt;
&gt;&gt; int mem_neq(const void *m1, const void *m2, size_t n)
&gt;&gt; {
&gt;&gt; const uint8_t *b1 = m1, *b2 = m2;
&gt;&gt; uint8_t diff = 0;
&gt;&gt; while (n--)
&gt;&gt; diff |= *b1++ ^ *b2++;
&gt;&gt; return diff != 0;
&gt;&gt; }
&gt;&gt; #define mem_eq(m1, m2, n) (!mem_neq((m1), (m2),(n)))
&gt;
&gt; Looks good to me.

Spoke too soon.

A little birdie (goes by the name of Skywing) pointed out to me in chat 
that certain compilers are smart enough to realize that the 
externally-visible result of the function can only go from 0 to 1 one 
time. This might enable them to break out of the loop early once that 
happened.

A workaround may be the 'volatile sledgehammer':

int mem_neq(const void *m1, const void *m2, size_t n)
{
     const uint8_t *b1 = m1, *b2 = m2;
     uint8_t diff = 0;
     volatile uint8_t * pdiff = 
     while (n--)
         *pdiff |= *b1++ ^ *b2++;
     return *pdiff != 0;
}

or perhaps

int mem_neq(const void *m1, const void *m2, size_t n)
{
     const uint8_t *b1 = m1, *b2 = m2;
     uint8_t diff = 0;
     while (n--)
     {
         diff |=   *(volatile const uint8_t *)b1
                 ^ *(volatile const uint8_t *)b2;
         b1++; b2++;
     }
     return diff != 0;
}

Of course, we could always just compute SHA-256 hashes of each side and 
then compare those, right? :-)

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507055631</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-05-07 05:56:31-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On May 6, 2011, at 10:35 PM, Marsh Ray wrote:

&gt; Of course, we could always just compute SHA-256 hashes of each side and then \
&gt; compare those, right? :-)

Yes, Brad Hill suggested that (in a Java/C# context). Nate Lawson didn't like it on \
performance grounds, but I don't recall hearing any correctness-related complaints.

http://www.isecpartners.com/blog/2011/2/18/double-hmac-verification.html

You could use the volatile sledgehammer, and then use a unit test to make sure that \
it remains working over time. And/or you could put it in its own file, and compile it \
with -O0, in case that helps.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation
https://www.eff.org/code

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110507061614</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-05-07 06:16:14-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

On May 6, 2011, at 10:25 PM, Robert Ransom wrote:

&gt; I would expect GCC (and most other C compilers) to use a
&gt; non-constant-time implementation of (v1 == v2).

Are there machines that implement uint8_t comparison in a data-dependent way? What's an example?


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation
https://www.eff.org/code

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110507065023</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-07 06:50:23-0400</timestampReceived><subject>Re: [tor-dev] memcmp() &amp; co. timing info disclosures?</subject><body>

[Attachment #2 (multipart/signed)]


On Fri, 6 May 2011 23:16:14 -0700
Chris Palmer &lt;chris@eff.org&gt; wrote:

&gt; On May 6, 2011, at 10:25 PM, Robert Ransom wrote:
&gt; 
&gt; &gt; I would expect GCC (and most other C compilers) to use a
&gt; &gt; non-constant-time implementation of (v1 == v2).
&gt; 
&gt; Are there machines that implement uint8_t comparison in a data-dependent way? What's an example?

That comparison expression can be implemented in non-constant time on
IA-32 processors:

    ; ECX = v1; EDX = v2; result in EAX
    XOR EAX, EAX
    CMP ECX, EDX
    JE done
    INC EAX
  done:

I think I've seen GCC emit something similar to that within the last
few years, and I assume that some compilers still emit code containing
a conditional branch for that expression.  In general, we don't want to
assume that conditional expressions are safe to use, even if a compiler
*could* implement them in a safe way (e.g. by compiling Nick's function
into something resembling mine).


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110502184342</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-05-02 18:43:42-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On May 2, 2011, at 11:23 AM, Sebastian Hahn wrote:
&gt; On Mar 2, 2011, at 8:06 AM, Nick Mathewson wrote:
&gt; &gt; This is possibly bikeshed, but I would suggest that instead of
&gt; &gt; requiring half of  existing authorities to vote on a particular
&gt; &gt; parameter, we require 3 or more to vote on it. (As a degenerate case,
&gt; &gt; fall back to "at least half" if there are fewer than 6 authorities in
&gt; &gt; the clique.)
&gt; 
&gt; Hrm. I'm not too happy with this, unless we also include a way for a
&gt; majority of authorities to prevent voting on that parameter altogether.
&gt; Doing the design as presented above would then be simpler.

I updated the proposal without taking into account the
suggested change. If people feel strongly I'm happy to revise
it as I indicated above. I've pushed an updated version to
my torspec repository, where the old version [0], the new
version [1] and a diff [2] between the two is available.

I updated the example implementation to be compatible with
the current code, and changed it to refer to this proposal
correctly instead of 178. I hope that with this clarification on
the intentions this proposal can go into the accepted category,
unless concerns remain.

Below I am replicating the new version of the proposal
fully.

Thanks
Sebastian

[0]: https://gitweb.torproject.org/sebastian/torspec.git/blob/e52b2be829a9a8027c173568b6d841feb3c1096a:/proposals/178-param-voting.txt
 [1]: https://gitweb.torproject.org/sebastian/torspec.git/blob/0fe8b85897a8919b2911bedcf475b578b0b67ec6:/proposals/178-param-voting.txt
 [2]: https://gitweb.torproject.org/sebastian/torspec.git/commitdiff/0fe8b85897a8919b2911bedcf475b578b0b67ec6



Filename: 178-param-voting.txt
Title: Require majority of authorities to vote for consensus parameters
Author: Sebastian Hahn
Created: 16-Feb-2011
Status: Open

Overview:

The consensus that the directory authorities create may contain one or
more parameters (32-bit signed integers) that influence the behavior
of Tor nodes (see proposal 167, "Vote on network parameters in
consensus" for more details).

Currently (as of consensus method 11), a consensus will end up
containing a parameter if at least one directory authority votes for
that paramater. The value of the parameter will be the low-median of
all the votes for this parameter.

This proposal aims at changing this voting process to be more secure
against tampering by a non-majority of directory authorities.

Motivation:

To prevent a minority of the directory authorities from influencing
the value of a parameter unduly, the majority of directory authorities
has to vote for that parameter. This is not currently happening, and
it was in fact not uncommon for a single authority to govern the value
of a consensus parameter.

Design:

When the consensus is generated, the directory authorities ensure that
a param is only included in the list of params if at least half of the
total number of authorities votes for that param. The value chosen is
the low-median of all the votes. We don't mandate that the authorities
have to vote on exactly the same value for it to be included because
some consensus parameters could be the result of active measurements
that individual authorities make.

Security implications:

This change is aimed at improving the security of Tor nodes against
attacks carried out by a minority of directory authorities. It is
possible that a consensus parameter that would be helpful to the
network is not included because not enough directory authorities
voted for it, but since clients are required to have sane defaults
in case the parameter is absent this does not carry a security risk.

Specification:

dir-spec section 3.4 currently says:

     Entries are given on the "params" line for every keyword on which any
     authority voted.  The values given are the low-median of all votes on
     that keyword.

It is proposed that the above is changed to:

     Entries are given on the "params" line for every keyword on which a
     majority of authorities (total authorities, not just those
     participating this vote) voted on. The values given are the
     low-median of all votes on that keyword.

     Consensus methods 11 and before, entries are given on the "params"
     line for every keyword on which any authority voted, the value given
     being the low-median of all votes on that keyword.

The following should be added to the bottom of section 3.4.:

        * If consensus method 12 or later is used, only consensus
          parameters that more than half of the total number of
          authorities voted for are included in the consensus.

The following line should be added to the bottom of section 3.4.1.:

     "12" -- Params are only included if a majority voted for them

Compatibility:

A sufficient number of directory authorities must upgrade to the new
consensus method used to calculate the params in the way this proposal
calls for, otherwise the old mechanism is used. Nodes that do not act
as directory authorities do not need to be upgraded and should
experience no change in behaviour.

Implementation:

An example implementation of this feature can be found in
https://gitweb.torproject.org/sebastian/tor.git, branch safer_params.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110504004939</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-05-04 00:49:39-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>

On Mon, May 2, 2011 at 5:23 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;
&gt; On Mar 2, 2011, at 8:06 AM, Nick Mathewson wrote:
&gt;
&gt;&gt; On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Design:
&gt;&gt;&gt;
&gt;&gt;&gt; When the consensus is generated, the directory authorities ensure that
&gt;&gt;&gt; a param is only included in the list of params if at least half of the
&gt;&gt;&gt; total number of authorities votes for that param. The value chosen is
&gt;&gt;&gt; the low-median of all the votes. We don't mandate that the authorities
&gt;&gt;&gt; have to vote on exactly the same value for it to be included because
&gt;&gt;&gt; some consensus parameters could be the result of active measurements
&gt;&gt;&gt; that individual authorities make.
&gt;&gt;
&gt;&gt; This is possibly bikeshed, but I would suggest that instead of
&gt;&gt; requiring half of  existing authorities to vote on a particular
&gt;&gt; parameter, we require 3 or more to vote on it. (As a degenerate case,
&gt;&gt; fall back to "at least half" if there are fewer than 6 authorities in
&gt;&gt; the clique.)
&gt;
&gt; Hrm. I'm not too happy with this,

My rationale was that in practice, it's a pain in practice to try to
get more than 3 or so authority operators to try out an experimental
parameter in a timely basis.  If the set of authority operators ever
grows, getting half of the ops to tweak a parameter in a hurry will
get even harder.

&gt; unless we also include a way for a
&gt; majority of authorities to prevent voting on that parameter altogether.

What if we say that as a matter of design, there should always be, for
each parameter, a value that's semantically equivalent to the absence
of the parameter?  That way a majority of authorities can "turn off"
any parameter without any additional machinery during the vote.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111125202754</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-11-25 20:27:54-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On May 4, 2011, at 7:20 AM, Sebastian Hahn wrote:
&gt; On May 4, 2011, at 2:49 AM, Nick Mathewson wrote:
&gt;&gt; On Mon, May 2, 2011 at 5:23 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;&gt;&gt; On Mar 2, 2011, at 8:06 AM, Nick Mathewson wrote:
&gt;&gt;&gt;&gt; On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt;&gt;&gt;&gt;&gt; Design:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; When the consensus is generated, the directory authorities ensure that
&gt;&gt;&gt;&gt;&gt; a param is only included in the list of params if at least half of the
&gt;&gt;&gt;&gt;&gt; total number of authorities votes for that param. The value chosen is
&gt;&gt;&gt;&gt;&gt; the low-median of all the votes. We don't mandate that the authorities
&gt;&gt;&gt;&gt;&gt; have to vote on exactly the same value for it to be included because
&gt;&gt;&gt;&gt;&gt; some consensus parameters could be the result of active measurements
&gt;&gt;&gt;&gt;&gt; that individual authorities make.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; This is possibly bikeshed, but I would suggest that instead of
&gt;&gt;&gt;&gt; requiring half of  existing authorities to vote on a particular
&gt;&gt;&gt;&gt; parameter, we require 3 or more to vote on it. (As a degenerate case,
&gt;&gt;&gt;&gt; fall back to "at least half" if there are fewer than 6 authorities in
&gt;&gt;&gt;&gt; the clique.)
&gt;&gt;&gt; 
&gt;&gt;&gt; Hrm. I'm not too happy with this,
&gt;&gt; 
&gt;&gt; My rationale was that in practice, it's a pain in practice to try to
&gt;&gt; get more than 3 or so authority operators to try out an experimental
&gt;&gt; parameter in a timely basis.  If the set of authority operators ever
&gt;&gt; grows, getting half of the ops to tweak a parameter in a hurry will
&gt;&gt; get even harder.
&gt; 
&gt; Yes, I understand that argument. On the other hand, getting a hold
&gt; of n-3 authority operators that did set a param can also be hard
&gt; (I'm thinking about the last time we thought that dirauths might crash
&gt; the network by distributing ipv6 descriptors, where it took a while to
&gt; even reach those who had applied our first patch).
&gt; 
&gt;&gt;&gt; unless we also include a way for a
&gt;&gt;&gt; majority of authorities to prevent voting on that parameter altogether.
&gt;&gt; 
&gt;&gt; What if we say that as a matter of design, there should always be, for
&gt;&gt; each parameter, a value that's semantically equivalent to the absence
&gt;&gt; of the parameter?  That way a majority of authorities can "turn off"
&gt;&gt; any parameter without any additional machinery during the vote.
&gt; 
&gt; This could work, but that means we need to re-implement a bunch of
&gt; our parameters that don't currently work that way. I'm thinking about
&gt; bug 1947 here, for example. Overloading the param value to mean
&gt; "this special integer means this specific param is not set" might also
&gt; lead to interesting situations where we aren't quite sure if 0 or
&gt; INT32_MIN or something else is responsible for disabling a param.
&gt; Maybe that's still easier to do than other ideas, and more convenient
&gt; in the common case where we don't have a bad param that we must
&gt; not set, which is what we should care about. I'm not sold on your
&gt; idea just yet, but I do think it can work.
&gt; 
&gt; Sebastian

I have since become convinced that it would be better to get
this implemented quickly, even if it doesn't have a generic
"prevent this param from being set" mechanism. I would thus like
to change the proposal to the following (also available in my
prop178 branch in my torspec repository). The diff is available at
https://gitweb.torproject.org/sebastian/torspec.git/commitdiff/db9a429d005ae05ad0841e6026941594d5740b0b

The branch safer_params in my repository has been updated to
reflect the new state of the proposal, the original branch is
available as safer_params_old. I'm still targetting this for 0.2.3,
but if that's not possible we can also easily delay it.

Thanks
Sebastian



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111125205818</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-11-25 20:58:18-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On Nov 25, 2011, at 9:27 PM, Sebastian Hahn wrote:
&gt; I have since become convinced that it would be better to get
&gt; this implemented quickly, even if it doesn't have a generic
&gt; "prevent this param from being set" mechanism. I would thus like
&gt; to change the proposal to the following (also available in my
&gt; prop178 branch in my torspec repository). The diff is available at
&gt; https://gitweb.torproject.org/sebastian/torspec.git/commitdiff/db9a429d005ae05ad0841e6026941594d5740b0b

I meant to also send the proposal here, inline. Looks like I messed
that up. Here goes:



Filename: 178-param-voting.txt
Title: Require majority of authorities to vote for consensus parameters
Author: Sebastian Hahn
Created: 16-Feb-2011
Status: Open
Target: 0.2.3.x

Overview:

The consensus that the directory authorities create may contain one or
more parameters (32-bit signed integers) that influence the behavior
of Tor nodes (see proposal 167, "Vote on network parameters in
consensus" for more details).

Currently (as of consensus method 11), a consensus will end up
containing a parameter if at least one directory authority votes for
that paramater. The value of the parameter will be the low-median of
all the votes for this parameter.

This proposal aims at changing this voting process to be more secure
against tampering by a small fraction of directory authorities.

Motivation:

To prevent a small fraction of the directory authorities from
influencing the value of a parameter unduly, a big enough fraction
of all directory authorities authorities has to vote for that
parameter. This is not currently happening, and it is in fact not
uncommon for a single authority to govern the value of a consensus
parameter.

Design:

When the consensus is generated, the directory authorities ensure that
a param is only included in the list of params if at least three of the
authorities (or a simple majority, whichever is the smaller number)
votes for that param. The value chosen is the low-median of all the
votes. We don't mandate that the authorities have to vote on exactly
the same value for it to be included because some consensus parameters
could be the result of active measurements that individual authorities
make.

Security implications:

This change is aimed at improving the security of Tor nodes against
attacks carried out by a small fraction of directory authorities. It
is possible that a consensus parameter that would be helpful to the
network is not included because not enough directory authorities
voted for it, but since clients are required to have sane defaults
in case the parameter is absent this does not carry a security risk.

This proposal makes a security vs coordination effort tradeoff. When
considering only the security of the design, it would be better to
require a simple majority of directory authorities to agree on
voting on a parameter, but it would involve requiring more
directory authority operators to coordinate their actions to set the
parameter successfully.

Specification:

dir-spec section 3.4 currently says:

     Entries are given on the "params" line for every keyword on which any
     authority voted.  The values given are the low-median of all votes on
     that keyword.

It is proposed that the above is changed to:

     Entries are given on the "params" line for every keyword on which a
     majority of authorities (total authorities, not just those
     participating in this vote) voted on, or if at least three
     authorities voted for that parameter. The values given are the
     low-median of all votes on that keyword.

     Consensus methods 11 and before, entries are given on the "params"
     line for every keyword on which any authority voted, the value given
     being the low-median of all votes on that keyword.

The following should be added to the bottom of section 3.4.:

        * If consensus method 12 or later is used, only consensus
          parameters that more than half of the total number of
          authorities voted for are included in the consensus.

The following line should be added to the bottom of section 3.4.1.:

     "12" -- Params are only included if a enough auths voted for them

Compatibility:

A sufficient number of directory authorities must upgrade to the new
consensus method used to calculate the params in the way this proposal
calls for, otherwise the old mechanism is used. Nodes that do not act
as directory authorities do not need to be upgraded and should
experience no change in behaviour.

Implementation:

An example implementation of this feature can be found in
https://gitweb.torproject.org/sebastian/tor.git, branch safer_params.



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111127144920</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-11-27 14:49:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>


On Nov 25, 2011, at 9:58 PM, Sebastian Hahn wrote:
&gt; On Nov 25, 2011, at 9:27 PM, Sebastian Hahn wrote:
&gt; &gt; I have since become convinced that it would be better to get
&gt; &gt; this implemented quickly, even if it doesn't have a generic
&gt; &gt; "prevent this param from being set" mechanism. I would thus like
&gt; &gt; to change the proposal to the following (also available in my
&gt; &gt; prop178 branch in my torspec repository). The diff is available at
&gt; &gt; https://gitweb.torproject.org/sebastian/torspec.git/commitdiff/db9a429d005ae05ad0841e6026941594d5740b0b
&gt; &gt; 
&gt; 
&gt; I meant to also send the proposal here, inline. Looks like I messed
&gt; that up. Here goes:

Looks like Nick liked the revised proposal and implementation after
fixups, the code and spec changes have been merged and the
proposal was marked closed just a few minutes ago.

Thanks all!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110503231652</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-05-03 23:16:52-0400</timestampReceived><subject>Re: [tor-dev] Mingw ann non-autoconf build</subject><body>

"Nick Mathewson" &lt;nickm@freehaven.net&gt; wrote:

&gt; But hey, it's free software. If you wanted to write and maintain an
&gt; alternative set of build scripts to work with different versions of
&gt; mingw, that would be great. 

I'm using the top of the line version of MingW (v3.18). I don't think
MingW has changed too much the last 5 years that it would matter for 
Tor. Except for the added gettimeofday() (in MingW v.316 I believe), an
orconfig.h should be unaware of any MingW version.

&gt; I'd greatly
&gt; prefer a separate orconfig.h if you take this route: sharing the same
&gt; one between msvc and mingw seems like it's asking for trouble.

Okay, but I'm now building Tor with the attached orconfig.h. This has
"only" 5 tests for __MINGW32__. I don't think that is asking for trouble.

Gisle V.

# rm -v /bin/laden 
/bin/laden: removed /bin/laden

["orconfig.h;" (text/plain)]

/* orconfig.h for Windows -- This file is *not* generated by autoconf.
 * Instead, it has to be hand-edited to keep Win32 happy.
 */

/* Windows-only defines. */
#define MS_WINDOWS
#define MS_WIN32
#define CONFDIR ""

/* Define to 1 if you have the &lt;arpa/inet.h&gt; header file. */
#undef HAVE_ARPA_INET_H

/* Define to 1 if you have the &lt;assert.h&gt; header file. */
#define HAVE_ASSERT_H

/* Define to 1 if you have the &lt;ctype.h&gt; header file. */
#define HAVE_CTYPE_H

#define ENABLE_THREADS

/* Define to 1 if you have the &lt;errno.h&gt; header file. */
#define HAVE_ERRNO_H

/* Define to 1 if you have the `event_get_method' function. */
#define HAVE_EVENT_GET_METHOD 1

/* Define to 1 if you have the `event_get_version' function. */
#define HAVE_EVENT_GET_VERSION 1

/* Define to 1 if you have the `event_set_log_callback' function. */
#define HAVE_EVENT_SET_LOG_CALLBACK 1

/* Define to 1 if you have the &lt;fcntl.h&gt; header file. */
#define HAVE_FCNTL_H

/* Define to 1 if you have the `ftime' function. */
#define HAVE_FTIME

/* Define to 1 if you have the `gettimeofday' function. */
#ifndef __MINGW32__
#undef HAVE_GETTIMEOFDAY
#endif

/* Define to 1 if you have the &lt;grp.h&gt; header file. */
#undef HAVE_GRP_H

/* Define to 1 if you have the `inet_aton' function. */
#undef HAVE_INET_ATON

/* Define to 1 if you have the &lt;inttypes.h&gt; header file. */
/* #define HAVE_INTTYPES_H */

/* Define to 1 if you have the &lt;limits.h&gt; header file. */
#define HAVE_LIMITS_H

/* Define to 1 if you have the &lt;machine/limits.h&gt; header file. */
#undef HAVE_MACHINE_LIMITS_H

/* Define to 1 if you have the &lt;memory.h&gt; header file. */
#define HAVE_MEMORY_H

/* Define to 1 if you have the &lt;netdb.h&gt; header file. */
#undef HAVE_NETDB_H

/* Define to 1 if you have the &lt;netinet/in.h&gt; header file. */
#undef HAVE_NETINET_IN_H

/* Define to 1 if you have the &lt;poll.h&gt; header file. */
#undef HAVE_POLL_H

/* Define to 1 if you have the &lt;pwd.h&gt; header file. */
#undef HAVE_PWD_H

/* Define to 1 if you have the &lt;signal.h&gt; header file. */
#define HAVE_SIGNAL_H

/* Define to 1 if you have the `socketpair' function. */
#undef HAVE_SOCKETPAIR

/* Define to 1 if you have the &lt;stdint.h&gt; header file. */
#undef HAVE_STDINT_H

/* Define to 1 if you have the &lt;stdlib.h&gt; header file. */
#define HAVE_STDLIB_H

/* Define to 1 if you have the &lt;strings.h&gt; header file. */
#undef HAVE_STRINGS_H

/* Define to 1 if you have the &lt;string.h&gt; header file. */
#define HAVE_STRING_H

/* Define to 1 if you have the `strlcat' function. */
#if defined (WINCE)
#define HAVE_STRLCAT
#else
#undef HAVE_STRLCAT
#endif

/* Define to 1 if you have the `strlcpy' function. */
#if defined (WINCE)
#define HAVE_STRLCPY
#else
#undef HAVE_STRLCPY
#endif
/* Define to 1 if you have the `strptime' function. */
#undef HAVE_STRPTIME

/* Define to 1 if your timeval has a tv_sec element. */
#define HAVE_STRUCT_TIMEVAL_TV_SEC
/* Change to #undef if you're using BCC */

/* Define to 1 if you have the &lt;sys/fcntl.h&gt; header file. */
#ifndef __MINGW32__
#undef HAVE_SYS_FCNTL_H
#endif

/* Define to 1 if you have the &lt;sys/ioctl.h&gt; header file. */
#ifndef __MINGW32__
#undef HAVE_SYS_IOCTL_H
#endif

/* Define to 1 if you have the &lt;sys/limits.h&gt; header file. */
#undef HAVE_SYS_LIMITS_H

/* Define to 1 if you have the &lt;sys/poll.h&gt; header file. */
#undef HAVE_SYS_POLL_H

/* Define to 1 if you have the &lt;sys/socket.h&gt; header file. */
#undef HAVE_SYS_SOCKET_H

/* Define to 1 if you have the &lt;sys/stat.h&gt; header file. */
#define HAVE_SYS_STAT_H

/* Define to 1 if you have the &lt;sys/time.h&gt; header file. */
#ifndef __MINGW32__
#undef HAVE_SYS_TIME_H
#endif

/* Define to 1 if you have the &lt;sys/types.h&gt; header file. */
#define HAVE_SYS_TYPES_H

/* Define to 1 if you have the &lt;sys/utime.h&gt; header file. */
#define HAVE_SYS_UTIME_H

/* Define to 1 if you have the &lt;sys/wait.h&gt; header file. */
#undef HAVE_SYS_WAIT_H

/* Define to 1 if you have the &lt;time.h&gt; header file. */
#define HAVE_TIME_H

/* Define to 1 if you have the `uname' function. */
#undef HAVE_UNAME

/* Define to 1 if you have the &lt;unistd.h&gt; header file. */
#ifndef __MINGW32__
#undef HAVE_UNISTD_H
#endif

/* Define to 1 iff NULL is represented by a 0 in memory. */
#define NULL_REP_IS_ZERO_BYTES 1

/* Name of package */
#define PACKAGE "tor"

/* Define to the address where bug reports for this package should be sent. */
#undef PACKAGE_BUGREPORT

/* Define to the full name of this package. */
#undef PACKAGE_NAME

/* Define to the full name and version of this package. */
#undef PACKAGE_STRING

/* Define to the one symbol short name of this package. */
#undef PACKAGE_TARNAME

/* Define to the version of this package. */
#undef PACKAGE_VERSION

/* The size of a `char', as computed by sizeof. */
#define SIZEOF_CHAR 1

/* The size of a `int', as computed by sizeof. */
#define SIZEOF_INT 4

/* The size of a `int16_t', as computed by sizeof. */
#undef SIZEOF_INT16_T

/* The size of a `int32_t', as computed by sizeof. */
#undef SIZEOF_INT32_T

/* The size of a `int64_t', as computed by sizeof. */
#undef SIZEOF_INT64_T

/* The size of a `int8_t', as computed by sizeof. */
#undef SIZEOF_INT8_T

/* The size of a `long', as computed by sizeof. */
#define SIZEOF_LONG 4

/* The size of a `long long', as computed by sizeof. */
#undef SIZEOF_LONG_LONG

/* The size of a `short', as computed by sizeof. */
#define SIZEOF_SHORT 2

/* The size of a `time_t', as computed by sizeof. */
#define SIZEOF_TIME_T 4

/* The size of a `uint16_t', as computed by sizeof. */
#undef SIZEOF_UINT16_T

/* The size of a `uint32_t', as computed by sizeof. */
#undef SIZEOF_UINT32_T

/* The size of a `uint64_t', as computed by sizeof. */
#undef SIZEOF_UINT64_T

/* The size of a `uint8_t', as computed by sizeof. */
#undef SIZEOF_UINT8_T

/* The size of a `void *', as computed by sizeof. */
#define SIZEOF_VOID_P 4

/* The size of a `__int64', as computed by sizeof. */
#define SIZEOF___INT64 8

/* The sizeof a size_t, as computed by sizeof. */
#define SIZEOF_SIZE_T 4

/* Define to 1 if you have the ANSI C header files. */
#define STDC_HEADERS

/* Define to 1 if time_t is signed. */
#define TIME_T_IS_SIGNED

/* Define to 1 iff unaligned int access is allowed */
#define UNALIGNED_INT_ACCESS_OK

#define HAVE_EVENT_H

/* Define to 1 iff we represent negative integers with two's complement */
#define USING_TWOS_COMPLEMENT

/* Version number of package */
#define VERSION "0.2.3.0-alpha-dev"


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110510221618</emailId><senderName>Prateek Mittal</senderName><senderEmail>mittal.prateek@gmail.com</senderEmail><timestampReceived>2011-05-10 22:16:18-0400</timestampReceived><subject>[tor-dev] regd throughput fingerprinting based attacks</subject><body>

[Attachment #2 (multipart/alternative)]


Hi Roger,

Hope things are going well. I wanted to point you to an updated version of
our technical report on throughput-fingerprinting based attacks in Tor,
available at
https://netfiles.uiuc.edu/mittal2/www/throughput-fingerprinting.pdf.

Thanks,
Prateek

[Attachment #5 (text/html)]

Hi Roger, &lt;br&gt;&lt;br&gt;Hope things are going well. I wanted to point you to an updated \
version of our technical report on throughput-fingerprinting based attacks in Tor, \
available at &lt;a href="https://netfiles.uiuc.edu/mittal2/www/throughput-fingerprinting.pdf"&gt;https://netfiles.uiuc.edu/mittal2/www/throughput-fingerprinting.pdf&lt;/a&gt;. \
&lt;br&gt; &lt;br&gt;Thanks,&lt;br&gt;Prateek&lt;br&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110512114946</emailId><senderName>       Bjrn Scheuermann</senderName><senderEmail></senderEmail><timestampReceived>2011-05-12 11:49:46-0400</timestampReceived><subject>Re: [tor-dev] Fairness between circuits</subject><body>

Hi,

&gt; I agree with most of Bjrn's post, but disagree slightly here:

I fully agree with what Ian said, except for one point. ;)

&gt; The EWMA stuff isn't _trying_ to be fair; it's explicitly trying to
&gt; prioritize circuits for which users will gain utility from lower
&gt; latency, and deprioritize circuits for which users don't care about
&gt; latency.  That said, it's still kind of fair, as circuits with similar
&gt; usage patterns will get similar service.
&gt; 
&gt; The main difference is that if you've got a bunch of circuits that need
&gt; servicing, a fair round-robin doesn't care if you service them in the
&gt; order A,B,C,D,E,A,B,C,D,E or E,B,A,C,D,E,B,A,C,D, or even
&gt; E,B,D,A,C,A,E,B,C,D.  All are equally fair.  The observation in our CCS
&gt; paper is that it _does_ matter to the user, if some of the circuits are
&gt; interactive, and others are not.  Indeed, if A is interactive and hasn't
&gt; sent packets in a while, it might get A,A,A,C,E,B,D so that it can
&gt; "catch up".

I think this is also a question of the time scale. If the queues are
excessively long due to non-working congestion control as in current
Tor, then this is certainly an issue - because you can save significant
time by scheduling in the right order. If the queues are short and
scheduling is more fine-grained than now, then the minimal resulting
time differences will not matter.

As I said in my previous mail, it is still conceivable to implement
something along similar lines with our proposal. In the end, this would
mean the introduction of (short-term) unfairness in order to give a
(short-term) advantage to interactive traffic. This can be done without
hurting the long-term fairness between circuits. However, it would
increase the complexity, and thus significantly reduces our chances to
understand what happens and why it happens.

It may well turn out that this is beneficial - this remains to be
assessed at some point further down the road. For the moment, my guts
tell me that the problem will not exist to the same extent. My guts
might be wrong with that, and we should verify that once the ideas have
become a bit more stable. If I am right, however, we should IMHO seize
the opportunity to reduce the system complexity if it doesn't hurt
performance.


Best regards

Bjrn


-- 
Prof. Dr. Bjrn Scheuermann
Chair of Computer Science VII (Robotics and Telematics)
University of Wrzburg
Am Hubland, 97074 Wrzburg, Germany

Tel.: +49 931 31 85402
scheuermann@informatik.uni-wuerzburg.de
http://www7.informatik.uni-wuerzburg.de

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110513065810</emailId><senderName>Berkant Ustaoglu</senderName><senderEmail>bustaoglu@cryptolounge.net</senderEmail><timestampReceived>2011-05-13 06:58:10-0400</timestampReceived><subject>Re: [tor-dev] New paper by Goldberg, Stebila,</subject><body>

Quoting Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt;:

&gt; On Thu, May 12, 2011 at 10:10:11AM -0400, Nick Mathewson wrote:
&gt;&gt; On Thu, May 12, 2011 at 8:12 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt;&gt; &gt; On Thu, May 12, 2011 at 07:13:58AM -0400, Ian Goldberg wrote:
&gt;&gt; &gt;&gt; The directory authorities should probably checks the B's anyway, just to
&gt;&gt; &gt;&gt; be sane.  They should all have order exactly p_1, so check that
&gt;&gt; &gt;&gt; EXP(B,8) is not O, and check that EXP(B,p_1) is O.
&gt;&gt; &gt;
&gt;&gt; &gt; While we're talking about this, note that our paper says that the CA
&gt;&gt; &gt; (the directory authority here) should check that the node submitting B
&gt;&gt; &gt; actually does know b (the private key).  This could be as simple as the
&gt;&gt; &gt; standard Fiat-Shamir NIZKPK.
&gt;&gt;
&gt;&gt; Hm.  What goes wrong in the protocol as I've written it if the
&gt;&gt; authorities *don't* check this?  As "simple" as you say Fiat-Shamir
&gt;&gt; is, it would seem to add a few round trips to the server publication
&gt;&gt; protocol.
&gt;
&gt; No, Fiat-Shamir is the non-interactive (the NI in NIZKPK) version, so
&gt; the node would just attach the proof to B when it submits it.
&gt;
&gt; Node knows b and B = g^b
&gt; Node picks random t \in Z/p_Z where p is the order of g
&gt; Node computes c = H(g^t | B | ID | D)
&gt;     where ID is the node ID, D is any other data already sent or
&gt;     received in the server publication protocol
&gt; Node computes r = t - c*b mod p
&gt; Node sends (c,r) along with B to be registered.  (256+256 bits)
&gt;
&gt; The DA checks that c =?= H(g^r * B^c | B | ID | D) before accepting the
&gt; registration.
&gt;
&gt; You're right that it seems unlikely anything will go wrong in this
&gt; particular protocol if B is unattested.  But then you're getting back to
&gt; lots of moving parts relying on the properties of other moving parts.
&gt;
&gt;    - Ian
&gt;

Proof of possession of private key is indeed the more sound  
cryptographic thing to do, but for security it suffices to verify B  
lies on the correct group. Hijacking someone else's public key is not  
going to help the adversary to break ntor's security. That is what  
ntor's argument suggests. Given that is it really worth creating and  
maintaining the extra code to run a NIZKPK, when validation - a  
routine already required for the protocol, suffices?

This does not mean foolproof security, for example using B also as a  
signature key is likely to be problematic. However, such problems feel  
independent from whether you know or don't know "b". The only case  
where this would be issue is if two server use their respective Bs not  
only to establish connection with clients but between each other *and*  
the protocol used to establish server-to-server channel relies  
non-trivially on the assumption that your peer knows its own private  
key. Well in that case it's better to simply use a protocol that  
doesn't rely on proof of possession.

Last remark: I think in Ian's algorithm the DA must also check that B  
lies in the correct group. Otherwise, it's still possible to register  
invalid keys: for example with finite fields set B = 0 and it's easy  
to fool the verification step; a similar idea can be applied to  
elliptic curves (if validation is free then not on curve25519). I'm  
not familiar with how exactly Tor handles registration, but can come  
up with a few "reasonable" scenarios where an adversary can  
successfully impersonate servers by posting invalid static keys.

Berkant

-- 
Berkant Ustaoglu
http://cryptolounge.net

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110515235138</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-05-15 23:51:38-0400</timestampReceived><subject>Re: [tor-dev] TorStatus</subject><body>

Hi Jan,

On 5/2/11 12:31 PM, tagnaq wrote:
&gt; On 5/2/11 11:38 AM, Jan G. wrote:
&gt;&gt; im trying to port TorNetworkStatus to Ruby.
&gt;&gt;
&gt;&gt; I took a look at the Trac and it looks like it's project that should be
&gt;&gt; done at the GSoC.
&gt;&gt; https://trac.torproject.org/projects/tor/wiki/projects/TorStatus
&gt;&gt;
&gt;&gt; Is anyone working at this now?
&gt; 
&gt; No one is working on/maintaining TorStatus (it is not even a Tor Project
&gt; "product").
&gt; 
&gt; As far as I've understood the plan is to extent metrics-web to have the
&gt; TorStatus functionality on metrics.tpo.

tagnaq is right, extending metrics-web to be more useful for displaying
the _current_ network status, too, would be good!  After all, the
database contained in metrics-web already has this information, and the
website part displays similar information.  So, extending metrics-web
shouldn't be that hard.  But the website is written in JSP/servlets
which keeps many people away.

There are plans to rewrite TorStatus in Python/Django, which is much
more popular in Tor land, and make it use the metrics database from
metrics-web.  If this goes well, we might extend that new TorStatus to
cover the metrics part, too, and end up with a single website for both.
 Don't expect any results here in the next, say, three to six months,
though.

But these plans shouldn't really stop you from writing a TorStatus in
Ruby!  I'd be curious to see what user interface you come up with.
Like, what information would you put in a relay list, what information
would you make searchable, etc.  Even a paper prototype or click dummy
would be cool as a start!  And who knows, if your TorStatus turns out to
be better than the current one, we might change our plans to rewrite
stuff in Python/Django.  Hard to say.

I can help you with setting up the database part of metrics-web if you
want.  Or I can help you make sense of most parts Tor's directory
protocol, if needed.  Just let me know!

Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110516002335</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-05-16 00:23:35-0400</timestampReceived><subject>Re: [tor-dev] IPv6 Thoughts</subject><body>

On 2011-May-15 23:53, Lucky Green wrote:
[..]
&gt; In summary, outbound IPv6 Tor connections from end-users can wait until
&gt; after Tor servers accept inbound IPv6 connections (and after exit nodes
&gt; can make outbound IPv6 connections to other services).

Correct, but the bigger issue, which I have mostly tackled is that the
current in-git tor is not address family agnostic.

The moment Tor is address family agnostic it can listen on any address
type, the next step is to teach the internal protocol, the onion routing
portion, to support IPv6 connectivity and a probably more intrusive
patch to teach it to support multiple address/port combo's per node.

Most of that "client" code is there already as SOCKS5 fortunately
supports IPv6 resolving and that code is implemented already, SOCKS4(a)
does not support IPv6 though, possibly if one connects by hostname.

Current IPv6 diff (that does not compile completely yet though):

$ wc tor-ipv6.diff
  2968  12526 116496 tor-ipv6.diff

Need some sleep now, and got a concert tomorrow evening (and that thing
called work during the day...), but I'll try to finish it off on tuesday
evening and then get it here on the list in a chunked way so that the
changes can easily be read and then that it gets integrated into the
master branch.

Greets,
 Jeroen
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110516165901</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-05-16 16:59:01-0400</timestampReceived><subject>Re: [tor-dev] May Tor proposal status, and proposal plans for 0.2.3</subject><body>

On 5/9/11 6:54 PM, Nick Mathewson wrote:
&gt;    xxx-geoip-survey-plan.txt
&gt; 
&gt;      Here's an old document I wrote a while ago about tracking usage by
&gt;      country.  Probably it should go into the metrics documentation
&gt;      somewhere (if we do this), or get thrown into "old" (if we won't do
&gt;      this), or updated (if we might someday do this).

This proposal idea is already in the "old" directory, and I think that's
okay.  The idea is superseded by this tech report:

  https://metrics.torproject.org/papers/countingusers-2010-11-30.pdf

&gt;    xxx-hide-platform.txt
&gt; 
&gt;      Here's a proposal pre-draft that says we should normalize the
&gt;      platform string.  Somebody could turn this into a proposal pretty
&gt;      easily.

This proposal idea doesn't say what platform string would be published
when HidePlatform is set to Yes.

I think #2988 has much more discussion on this topic than the proposal
idea.  Whenever #2988 results in a design, it'd be just as simple to
write a new proposal than to rewrite this one.  Does such a change even
require a proposal?  Which specification document would be changed when
making this change?  It's probably okay to throw this proposal into
"old," too.

Best,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110519205840</emailId><senderName>intrigeri</senderName><senderEmail>intrigeri@boum.org</senderEmail><timestampReceived>2011-05-19 20:58:40-0400</timestampReceived><subject>Re: [tor-dev] Tor meets real users</subject><body>

Hi,

Andrew Lewman wrote (18 May 2011 19:37:28 GMT) :
&gt; I like what TAILS has done here. They strip out all of the
&gt; configuration options from Vidalia, so you can't click to change any
&gt; settings.

FWIW, the Settings dialog is nevertheless reachable, in Tails, from
the menu one get by right-clicking the Vidalia taskbar icon.
Many users sometimes need it to workaround so-called Internet access
with filtered egress, and our upcoming bridges support needs it as
well.

Bye,
--
  intrigeri &lt;intrigeri@boum.org&gt;
  | GnuPG key @ https://gaffer.ptitcanardnoir.org/intrigeri/intrigeri.asc
  | OTR fingerprint @ https://gaffer.ptitcanardnoir.org/intrigeri/otr.asc
  | So what?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110523053812</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-05-23 05:38:12-0400</timestampReceived><subject>Re: [tor-dev] [tor-commits] [tor/maint-0.2.2] The first argument</subject><body>

[Attachment #2 (multipart/signed)]


On Mon, 23 May 2011 05:18:07 +0000 (UTC)
nickm@torproject.org wrote:

&gt; commit 1e69c60dccc358a7146c2b5e7825ea729498b41b
&gt; Author: Nick Mathewson &lt;nickm@torproject.org&gt;
&gt; Date:   Mon May 23 01:12:00 2011 -0400
&gt; 
&gt;     The first argument for a libevent callback should be evutil_socket_t
&gt; ---
&gt;  src/common/procmon.c |    5 +++--
&gt;  1 files changed, 3 insertions(+), 2 deletions(-)
&gt; 
&gt; diff --git a/src/common/procmon.c b/src/common/procmon.c
&gt; index cee956a..bd25bc1 100644
&gt; --- a/src/common/procmon.c
&gt; +++ b/src/common/procmon.c
&gt; @@ -34,7 +34,7 @@ typedef int pid_t;
&gt;  /* Currently we need to poll in some way on all systems. */
&gt;  
&gt;  #ifdef PROCMON_POLLS
&gt; -static void tor_process_monitor_poll_cb(int unused1, short unused2,
&gt; +static void tor_process_monitor_poll_cb(evutil_socket_t unused1, short unused2,
&gt;                                          void *procmon_);

This will break the build on libevent 1.x systems (until you merge your
bug3270 branch that #defines evutil_socket_t on such systems).


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110523145744</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-05-23 14:57:44-0400</timestampReceived><subject>Re: [tor-dev] arm - new identity ...</subject><body>

Hi Dominik. Sounds good, we should keep this simple (at least for the
first version) so lets go with #2 and #3. Developing this should be
pretty straight forward...

1. Add "sendNewnym", "isNewnymAvailable", and "getNewnymWait" methods
to 'src/util/torTools.py'. All of these should be very easy.

2. Add a handler for sending a newnym in 'src/cli/headerPanel.py'.
This is done by overwriting the "handleKey(self, key)" method - for an
example see just about any of the other panels. I'm currently working
on another feature for the header panel (reattaching to tor instances)
so there might be a handler here by the time you start.

I'm fine with F5. From the curses documentation it sounds like you can
compare the keycode to the curses.KEY_F5 constant.

3. Adding the newnym to the header panel - this will be the hardest
part (but still not too difficult). This will only be visible when
we're a non-relay, and involves filling in...
https://gitweb.torproject.org/arm.git/blob/HEAD:/src/cli/headerPanel.py#l259

Normally this could say something like "Press F5 for a new identity",
then after they send a newnym instead display "Building circuits
(newnym signal unavailable for X seconds)".

4. Coordinate with Kamran for the menu option. Maybe we want to
somehow make it disabled while sending a newnym is unavailable?

&gt; - mumble with krkhan (and you?)

I'm looking forward to it. We should be able to set this up next week.

Cheers! -Damian

On Mon, May 23, 2011 at 7:04 AM, dominik &lt;d.schuetzdeller@gmx.de&gt; wrote:
&gt; hello atagar,
&gt; im sorry for not sending this email yesterday. my vserver hoster has reset
&gt; the wrong vserver and caused some trouble =(
&gt; ... anyway
&gt;
&gt; i had 3 ideas realizing this:
&gt; 1. build a new "page"
&gt;   that page should contain possibilities for adding nodes to use (entry or
&gt; bridges, relay and exit). it should also contain
&gt;   some informations about flags from that nodes; especially if that node is
&gt; a known bad node. there should also be a
&gt;   new identity button.
&gt; 2. implement it within the menues krkhan is working on
&gt;   as i now heard krkhan is working on a menu, what would be the best and
&gt; user friendliest way for implementing the
&gt;   stuff in there and create some masks for the according informations to be
&gt; put in there.
&gt; 3. using a hotkey for some things like "new identity"
&gt;   first of all i thought about using the "f5"-button as a hotkey for using
&gt; new circuits. i like the idea of using the same hotkey
&gt;   as it is used in the browser.
&gt; that new identity thing how ever needs to have a check whether the node
&gt; where it runs on is a client or some other thing.
&gt;
&gt; ok... before you are going to ask how i am going further - this is what my
&gt; todo list says:
&gt; - delete torsh from monitoring programs in the thesis
&gt; - describe whether there is a magical setup for nagios for ~6 different
&gt; nodes or not ...
&gt; - describe and edit features for arm
&gt; - search an elegant way for recreating a new circuit in pytorctl
&gt; - mumble with krkhan (and you?)
&gt; - based on the things said i am going to begin implementations (from
&gt; saturday on fulltime)
&gt;
&gt; after all my decision of working on arm after my thesis still is the same...
&gt; even if python3 has a weird utf8 handling.
&gt; i will also work on torsh as a fun project
&gt;
&gt; best regards
&gt; dominik
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110525221553</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-05-25 22:15:53-0400</timestampReceived><subject>[tor-dev] was my LDAP account ever setup?</subject><body>


Seems like this ticket is still open:
https://trac.torproject.org/projects/tor/ticket/3068

and I am problems like this:

git remote add public ssh://git-rw.torproject.org/n8fr8/orbot
git push public master
Permission denied (publickey).
fatal: The remote end hung up unexpectedly

thx!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110528024524</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-05-28 02:45:24-0400</timestampReceived><subject>Re: [tor-dev] Code Review (arm) - Initial commit for the menu code</subject><body>

&gt; Why not titlewidth = max(map(len, titles)) + 2?

Thanks, Robert. Actually, I've never messed with the map function
before - that'll be a nice improvement for several points in the
codebase. :)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110530125625</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-05-30 12:56:25-0400</timestampReceived><subject>Re: [tor-dev] The Torouter and the DreamPlug</subject><body>

On Mon, May 30, 2011 at 4:55 AM, Kyle Williams &lt;kyle.kwilliams@gmail.com&gt; wrote:
&gt; Hi Runa,
&gt; On Sat, May 28, 2011 at 2:52 PM, Runa A. Sandvik &lt;runa.sandvik@gmail.com&gt;
&gt; wrote:
&gt;&gt;
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; DreamPlug is a new plug computer from GlobalScale Technologies:
&gt;&gt; http://www.globalscaletechnologies.com/c-5-dreamplugs.aspx. The spec
&gt;&gt; looks good, it runs Ubuntu by default and it doesn't cost too much. I
&gt;&gt; thought that the DreamPlug was going to be very user friendly and a
&gt;&gt; potential candidate for the Torouter project. (Maybe) I was wrong.
&gt;&gt;
&gt; I got one of these.

Happy with it so far? Any issues with overheating or something similar?

&gt;&gt;
&gt;&gt; When the SheevaPlug came out a couple of years ago, it shipped with a
&gt;&gt; web interface that enabled users to change various network options. I
&gt;&gt; thought the DreamPlug would ship with some kind of interface as well
&gt;&gt; (and my plan was to just plug in a Tor page). This is not the case; it
&gt;&gt; ships with lighthttpd by default and displays a static and very simple
&gt;&gt; placeholder page on 192.168.1.1.
&gt;&gt;
&gt;&gt;
&gt;&gt; If we want to use the DreamPlug for the Torouter, we will have to
&gt;&gt; write a web interface for easy configuration of Tor. The interface
&gt;&gt; should probably also provide options to better secure the DreamPlug.
&gt;&gt; Downloading and installing Tor isn't a problem, but the configuration
&gt;&gt; side of things can be tricky for users who aren't used to the command
&gt;&gt; line.
&gt;
&gt; You don't HAVE to have a web interface, but it sure does make it nice.
&gt; However, SSH is really the only secure way to ensure you don't have some XSS
&gt; or CSRF attack from your browser (cause that can be really bad when your
&gt; browser takes over Tor... ;)

The whole point with the Torouter is to allow more people to run a
bridge or a relay, so I see a web interface as something mandatory. So
yeah, we'd have to make sure that the interface is secure.

&gt;&gt;
&gt;&gt; Thoughts? Comments?
&gt;&gt;
&gt; I got lots of experience with these types of devices.  The DreamPlug  is
&gt; using an ARM processor, much like the Yoggie Open Firewalls did.  Maybe you
&gt; heard of JanusPA(.com)...basically it was a Tor / OpenVPN Router that you
&gt; could put inline on your ethernet connection, required zero config to make
&gt; it work out of the box, and worked with any IPv4 device.
&gt; I have a build environment for the ARM architecture already, and I have a
&gt; SheevaPlug and a DreamPlug , but I haven't put Tor on it yet due to being
&gt; way overloaded with my day/night job.
&gt; If you want, I could probably get all the development stuff tarball'd up and
&gt; posted somewhere with basic instructions.  Or I could probably just take 2
&gt; hours, do a build, and stuff it into the DreamPlug , then make a tarball of
&gt; that.

What is "the development stuff"?

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110531211209</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-05-31 21:12:09-0400</timestampReceived><subject>[tor-dev] [Patch] common/procmon.c</subject><body>

Hi list!

I've been staring at this file for some time trying to find the elusive
compile-error (MingW-gcc v4.50) on Win_XP). The bug was a missing 
comma (!) and a typo ('err_msg' at line 277 changed to 'err_msg').

I've also changed the format for 'err_code' at line 293 into a "%ld" to suppress
a warning. How did this go unnoticed for ~1 month?

--- Git-latest\src\common\procmon.c       Thu May 26 19:30:24 2011
+++ common/procmon.c   Tue May 31 22:54:14 2011
@@ -252,7 +252,7 @@
     if (!GetExitCodeProcess(procmon-&gt;hproc, &amp;exit_code)) {
       char *errmsg = format_win32_error(GetLastError());
       log_warn(procmon-&gt;log_domain, "Error \"%s\" occurred while polling "
-               "handle for monitored process %d; assuming it's dead."
+               "handle for monitored process %d; assuming it's dead.",
                errmsg, procmon-&gt;pid);
       tor_free(errmsg);
       its_dead_jim = 1;
@@ -287,12 +287,12 @@

       if (!its_dead_jim)
         log_info(procmon-&gt;log_domain, "Failed to open handle to monitored "
-                 "process %d, and error code %d (%s) is not 'invalid "
+                 "process %d, and error code %lu (%s) is not 'invalid "
                  "parameter' -- assuming the process is still alive.",
                  procmon-&gt;pid,
-                 err_code, err_msg);
+                 err_code, errmsg);

-      tor_free(err_msg);
+      tor_free(errmsg);
     }
   }
 #else

-------------

Sorry, no git patch. I'm a git newbie.

Gisle V.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110531214430</emailId><senderName>Gisle</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-05-31 21:44:30-0400</timestampReceived><subject>[tor-dev] [PATCH] Signed-off-by: Gisle &lt;gvanem@broadpark.no&gt;</subject><body>

An elusive compile-error (MingW-gcc v4.50 on Win_XP); a missing
comma (!) and a typo ('err_msg' at line 277 changed to 'errmsg').
Aso changed the format for 'err_code' at line 293 into a "%ld" to suppress
a warning. How did this go unnoticed for ~1 month? Btw. This is my 1st ever
'git commit', so it better work.
---
 src/common/procmon.c |    8 ++++----
 1 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/src/common/procmon.c b/src/common/procmon.c
index 8fcc1af..5c10e9a 100644
--- a/src/common/procmon.c
+++ b/src/common/procmon.c
@@ -252,7 +252,7 @@ tor_process_monitor_poll_cb(evutil_socket_t unused1, short unused2,
     if (!GetExitCodeProcess(procmon-&gt;hproc, &amp;exit_code)) {
       char *errmsg = format_win32_error(GetLastError());
       log_warn(procmon-&gt;log_domain, "Error \"%s\" occurred while polling "
-               "handle for monitored process %d; assuming it's dead."
+               "handle for monitored process %d; assuming it's dead.",
                errmsg, procmon-&gt;pid);
       tor_free(errmsg);
       its_dead_jim = 1;
@@ -287,12 +287,12 @@ tor_process_monitor_poll_cb(evutil_socket_t unused1, short unused2,
 
       if (!its_dead_jim)
         log_info(procmon-&gt;log_domain, "Failed to open handle to monitored "
-                 "process %d, and error code %d (%s) is not 'invalid "
+                 "process %d, and error code %lu (%s) is not 'invalid "
                  "parameter' -- assuming the process is still alive.",
                  procmon-&gt;pid,
-                 err_code, err_msg);
+                 err_code, errmsg);
 
-      tor_free(err_msg);
+      tor_free(errmsg);
     }
   }
 #else
-- 
1.7.0.2.msysgit.0

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110404071217</emailId><senderName>Sukhbir Singh</senderName><senderEmail>sukhbir.in@gmail.com</senderEmail><timestampReceived>2011-04-04 07:12:17-0400</timestampReceived><subject>[tor-dev] Torbutton for Thunderbird</subject><body>

Hi!

I am interested in participating in Google's Summer of Code this year
and implementing the Torbutton equivalent for Thunderbird [0].

I have been discussing the project with Mike Perry and we feel that it
is possible to implement this. The first step was removing the
hostname Thunderbird puts in the outgoing message header, which we
easily fixed. That gave us the initial motivation to pursue this
further.

There are a number of issue that still remain, however we feel that
those can be easily worked out. We have put all probable solutions to
Torbutton requirements from [1] in the attachment with this mail and
are looking for your suggestions/ comments about this.

We have not submitted an application for this to Google yet; I intend
to do that after gauging the response towards this proposal from the
mailing list.

Let's hope that we can make this a success,

--
Thanks,

Sukhbir Singh

[0] - https://www.torproject.org/getinvolved/volunteer.html.en#torbuttonForThunderbird
[1] - https://www.torproject.org/torbutton/en/design/#requirements

Attachment - Plain text

["Torbutton" (application/octet-stream)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110407210349</emailId><senderName>"Jonathan \"Duke\" Leto"</senderName><senderEmail>jonathan@leto.net</senderEmail><timestampReceived>2011-04-07 21:03:49-0400</timestampReceived><subject>Re: [tor-dev] Embedding Parrot in Tor as GSoC Project</subject><body>

Howdy,

&gt; There is a libtor, but it's just an internal library that contains some
&gt; of the functions shared between the various Tor tools as they're built.
&gt; It isn't designed for outside apps to link to, and it doesn't actually
&gt; offer the API that you'd want.

Thanks for clarifying that.

&gt; But you're in luck -- Tor has a controller interface that lets other
&gt; applications interact with the Tor process over a local socket, using
&gt; a simple smtp-style protocol:
&gt; https://gitweb.torproject.org/torspec.git/blob/HEAD:/control-spec.txt
&gt;
&gt; So that means you can write your controller application in whatever
&gt; language you like. Vidalia uses C++, but it hasn't really broken out
&gt; its controller support into a reusable library. The best we've got is
&gt; a Python library:
&gt; https://gitweb.torproject.org/pytorctl.git
&gt; that is used by a variety of applications, ranging from a curses-based
&gt; Tor UI:
&gt; http://www.atagar.com/arm/
&gt; to a set of back-end scripts to build paths in nonstandard ways, measure
&gt; bandwidth, and do other experiments:
&gt; https://gitweb.torproject.org/torflow.git

I did not know about these things and they mostly seem to obviate the need
for the kind of embedding project I was thinking about. This is good :)

&gt; A Parrot library that talks to Tor via the controller interface would
&gt; be the right way to do it. The next question would be: if such a thing
&gt; existed, would anybody use it? That one is harder to answer. It probably
&gt; depends in part on how good it is. :)

Yes, that question *is* harder to answer. But, I don't think anybody can know
unless it is tried. From what I see, if Parrot wanted bindings to Tor, we can
start by seeing how the above-mentioned libraries work and go from there.

Thank you very much for your detailed and informative response.

Duke

-- 
Jonathan "Duke" Leto
jonathan@leto.net
http://leto.net
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407223715</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 22:37:15-0400</timestampReceived><subject>Re: [tor-dev] [Patch] src/test.c</subject><body>

On Thu, Apr 7, 2011 at 6:26 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; Another patch for this:

Looks good, except that tmp is a non-const variable and the string is
going to be const.  Does the tweaked version I attached work for you?

-- 
Nick

["0001-Use-GetTempDir-instead-of-hardcoded-path-to-c-window.patch" (text/x-patch)]

From 70e02914682eb1959d8b385f76b5acf7486158cc Mon Sep 17 00:00:00 2001
From: Gisle Vanem &lt;gvanem@broadpark.no&gt;
Date: Thu, 7 Apr 2011 18:34:11 -0400
Subject: [PATCH] Use GetTempDir instead of hardcoded path to c:\windows\tmp for unittests

---
 changes/win_tmp_dir |    4 ++++
 src/test/test.c     |   14 ++++++++++----
 2 files changed, 14 insertions(+), 4 deletions(-)
 create mode 100644 changes/win_tmp_dir

diff --git a/changes/win_tmp_dir b/changes/win_tmp_dir
new file mode 100644
index 0000000..13f6e7f
--- /dev/null
+++ b/changes/win_tmp_dir
@@ -0,0 +1,4 @@
+  o Unit tests:
+    - Use GetTempDir to find the proper temporary directory location on
+      Windows when generating temporary files for the unit tests.  Patch
+      by Gisle Vanem.
diff --git a/src/test/test.c b/src/test/test.c
index f5b6a22..9b24a99 100644
--- a/src/test/test.c
+++ b/src/test/test.c
@@ -84,10 +84,16 @@ setup_directory(void)
   if (is_setup) return;
 
 #ifdef MS_WINDOWS
-  // XXXX
-  tor_snprintf(temp_dir, sizeof(temp_dir),
-               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
-  r = mkdir(temp_dir);
+  {
+    char buf[MAX_PATH];
+    const char *tmp = buf;
+    /* If this fails, we're probably screwed anyway */
+    if (!GetTempPath(sizeof(buf),buf))
+      tmp = "c:\\windows\\temp";
+    tor_snprintf(temp_dir, sizeof(temp_dir),
+                 "%s\\tor_test_%d", tmp, (int)getpid());
+    r = mkdir(temp_dir);
+  }
 #else
   tor_snprintf(temp_dir, sizeof(temp_dir), "/tmp/tor_test_%d", (int) getpid());
   r = mkdir(temp_dir, 0700);
-- 
1.7.4.2



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110408065915</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-04-08 06:59:15-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 7 Apr 2011 17:18:12 -0400
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Thu, Mar 31, 2011 at 5:52 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; 
&gt; Hi!  I'm going to wait on a full review of your create/extend proposal
&gt; till it's done, but I though I could potentially answer some questions
&gt; and offer some comments:
&gt; 
&gt; 1) I think CREATE cells need to get a field asking for a specific way
&gt; of handling RELAY cells.  If we ever update the relay crypto (that is,
&gt; the stuff described in 5.5 and 6.1 today) to do something other than
&gt; AES128_CTR for the encryption, SHA1 for the digest, we'll need a way
&gt; to ask for it.  I suppose that we could do that via adding a new
&gt; handshake type for a new desired link protocol, but it seems like the
&gt; two could be more or less orthogonal.

I thought the desired relay ciphersuite should be specified in the
handshake data, so that circuit handshakes could encrypt the relay
ciphersuite specifier chosen by the client until we make a more
thoughtful decision as to whether it's safe to expose that to the
preceding relay.


&gt; 2) I don't get the rationale behind the variable-length type names.
&gt; Elsewhere in our protocol we'd just use a 1- or 2-byte type field.  Do
&gt; we win a lot by letting these be longer?

I don't know, but we certainly don't lose anything -- I don't expect to
overflow the 509 bytes currently available for EXTEND-ish cells until
we start using a post-quantum cryptosystem, and I assume the PQ
encryption systems with short enough keys that we would be willing to
use them purely for performance reasons are patented, so we can't
switch to them for at least a few years.


&gt; 3) By convention, everything in our protocol is in "network"
&gt; (big-endian) byte-order.

Good.


&gt; 4) There needs to be an authenticated way for the client to know which
&gt; handshake types and link specifier types a given node supports.  This
&gt; could be as simple as a series of statements like "Tor versions xyz
&gt; and later will support handshake type Y", or as complex as advertising
&gt; them in router descriptors.

The protocols that a relay is willing to support do need to be
specified in its descriptor.


&gt; 5) I like the idea of separating the link specifiers from the
&gt; handshake type in EXTENDED cells.

s/EXTENDED/EXTEND2/

There is no way to avoid separating the part which the relay receiving
the EXTEND2 cell must process from the part which the relay being
extended to must process.  Splitting up those two pieces further is
bad: in my earlier drafts, I made the mistake of specifying the format
of link specifiers by separating the connection address from an
identity key fingerprint.  That would have precluded link specifiers
that contain an encryption key instead of the hash of a signature key
(see below for more details).


&gt; 6) I also think it'd be smart to figure out the actual link specifier
&gt; and handshake types that we want to move to before we decide that we
&gt; are confident that this format is right.  Those can be a different
&gt; proposal, though.

See below, but yes, they should be in separate proposals.


&gt; 7) Here's a first cut of what I think might go in a link specifier format:
&gt; 
&gt;   * V4Address -- an ipv4 address, set to 0 if there is no IPv4 address
&gt; for the node [4 bytes]
&gt;   * V4ORPort [2 bytes]
&gt;   * V6Address -- an ipv6 address, set to 0 if there is no IPv6 address
&gt; for the node [16 bytes]
&gt;   * V6ORPort [2 bytes]
&gt;   * SHA256 of RSA1024 identity key [32 bytes]
&gt; 
&gt; When we decide what longer identity keys should look like, we can add
&gt; a new link specifier format that supports those.

There is no reason to fix the identity key length in that link
specifier.  Your link specifier format is clearly tied to TLS-over-TCP
link protocols, so the SHA256 hash might as well be computed over any
public key (or, alternatively, certificate) that the relay presents in
its certificate chain.  It would be useful to include some indication of
which certificate in the chain needs to match the hash, though.

But when we switch to a UDP-based link protocol, we will want to
include an encryption key (which serves as a link
handshake-authentication key) in the link specifier, so that the first
CREATE cell can be sent in the UDP packet that opens the link.  This
means that the first CREATE cell on a newly opened link won't get
forward secrecy from the link protocol, but we need to design circuit
handshakes to provide forward secrecy even if the attacker sees *both*
messages in the handshake anyway, so I don't consider this a problem.


&gt; 8) This is totally back-of-the-envelope stuff, but it might be a good
&gt; starting point for crypto discussion.
&gt; 
&gt; Here's a first cut of what I think might go in an improved RSA handshake:
&gt; 
&gt;   * First 8 bytes of the SHA256 hash of the onion key [8 bytes]
&gt;     (This is here so that onion key rotation can work without having
&gt; to sometimes try the wrong onion key incorrectly.)
&gt;   * PK-encrypted:
&gt;     * Padding [PK_PAD_LEN bytes]
&gt;     * SHA256 hash of all remaining fields. [32 bytes]
&gt;     * Symmetric key seed [16 bytes]
&gt;     * The first part of g^x. [as much will fit in the PK-encrypted portion]
&gt;   * Symmetrically encrypted:
&gt;      * The rest of g^x.
&gt;      * 0 bytes for padding.

If you really want to keep using RSA, I would suggest just grizzling'
the data (affix a random nonce and an integrity check computed over the
nonce and data, then BEAR/LION/LIONESS-encrypt with a fixed key), then
RSA-encrypting the grizzle'.  According to
&lt;http://www.cl.cam.ac.uk/~rja14/Papers/grizzle.pdf&gt;, that is provably
secure, for some definitions of "provably" and "secure".  (I haven't
followed the reference to the Jakobsson-Stern-Yung paper yet.)  That
appears to me to be a plaintext-aware' encryption algorithm (in the
terms of &lt;http://freehaven.net/anonbib/#tap:pet2006&gt;).

But in that case, we would also benefit from replacing the
Diffie-Hellman handshake with the obvious RSA-only one.  The client
generates an ephemeral RSA keypair, encrypts its public key, a random
256-bit string, and the desired relay ciphersuite specifier with the
relay's public onion key', and sends the encrypted blob in the
EXTEND-ish cell; the relay encrypts a random string with the client's
ephemeral public key, and sends the encrypted blob back to the client;
the resulting shared secret key is the SHA256 hash of the client's
random 256-bit string followed by the string chosen and sent by the
relay. This has two advantages: (1) an attacker who grabs a relay's
onion key after the fact can no longer benefit from performing
index-calculus precomputations in a fixed DH group, but must attack
each client's RSA key separately, and (2) computing x^65537 (or better,
x^3) is faster than computing g^x for large random x.  Some schemes
very close to this one are described (and proved secure, again for some
values of "proved" and "secure") in &lt;http://eprint.iacr.org/1999/012&gt;.


&gt; Here's a first cut of what I think might go in a hypothetical
&gt; diffie-hellman based handshake, for use with something like
&gt; Curve25519.  (I'm using g^x and g^y notation here as if this were
&gt; diffie-hellman in Z_p, since I don't yet trust myself to write ECC
&gt; stuff correctly.  I'm assuming that the node's public onion key is
&gt; g^x.)
&gt; 
&gt;    * SHA256 of all remaining fields. [32 bytes]
&gt;    * First 8 bytes of the SHA256 hash of the onion key (8 bytes)
&gt;    * g^y1 [DH_LEN bytes]
&gt;    * Encrypted using a symmetric key based on g^(x*y1):
&gt;        * g^y2 [DH_LEN bytes]
&gt;        * 0 bytes for padding
&gt; 
&gt; In both cases, we'll want a new key derivation function.

I see no MAC here -- the symmetrically encrypted blob *must* be
MAC-ed.  (I suggest using Salsa20 encryption, and using 32 extra bytes
of Salsa20 output as a key for a Poly1305 MAC.)  Also, the SHA256 at
the beginning is unnecessary, and we will want to include a relay
ciphersuite specifier in the encrypted blob.  Other than those changes,
that is what I had in mind.

This is essentially TAP using a better DH group and a stronger
encryption algorithm, and it clearly inherits TAP's security proof.


I have another possible design, mainly to force us to stop calling the
circuit handshake-authentication key an onion key':  The client sends
an ephemeral DH public key and a relay ciphersuite specifier to the
relay, and the relay replies with an EDH public key of its own and a
hash of the client's message, signed with the relay's circuit HA key.
(I assume this is basically what our TLS configuration does at the link
layer.)  I doubt that we will want to use this, but I'm quite sure that
it meets all of the circuit-extension handshake requirements that I
listed in torspec.git/proposals/ideas/xxx-crypto-requirements.txt , and
the HA key for this protocol cannot be accurately referred to as an
onion key' because nothing is ever encrypted with it.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110408192745</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-04-08 19:27:45-0400</timestampReceived><subject>[tor-dev] Nick+Roger IRC chat time for developers, Monday,</subject><body>

Nick and I are going to attempt this 'office hours' concept again, this
coming Monday afternoon. Drop by if you need anything from us!
--Roger

On Sat, Mar 05, 2011 at 11:47:01AM -0500, Nick Mathewson wrote:
&gt; Frequently, developers (including Nick and Roger) block on having both
&gt; Nick and Roger online at the same time.  We're trying to solve this by
&gt; scheduling time to make sure that we're online and available to work
&gt; with others on stuff that's blocking on is.  We'll be on the
&gt; development IRC channel (#tor-dev on OFTC) on March 8 and 9, from 1400
&gt; to 1800 EST (1900-2300 UTC, if I can add right).  If you're doing
&gt; something developmenty that's blocking on one or both of us, please
&gt; stop by and have a chat.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110408195942</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-08 19:59:42-0400</timestampReceived><subject>Re: [tor-dev] Redirecting network traffic to tor</subject><body>

On Wed, Apr 6, 2011 at 11:01 AM, rp &lt;romanpauk@gmail.com&gt; wrote:
 [...]
&gt; Although this is rather crude, it should prevent traffic leaks. What do you think
&gt; about this? Could it be to some use? I have already tested all points except number
&gt; 3), which would need more work, so before it I have to ask for your opinions -
&gt; whether this is a waste of time or not. Please let me know.

Hello, Roman!  This is interesting stuff, but the mention of
LD_PRELOAD makes me wonder how this compares to Torsocks.  In
particular, what can you do with this approach that the Torsocks
approach can't achieve?

Also, hooking connect isn't enough: you can send network traffic with
sendto and sendmsg over an unconnected socket; I bet there are other
ways to do it too.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110413235745</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-04-13 23:57:45-0400</timestampReceived><subject>[tor-dev] Request for website commit review</subject><body>

[Attachment #2 (multipart/signed)]


Please review Tor Subversion commits 24619, 24620, and 24621, then
update the website.


Regarding r24619: This change should be self-explanatory.

Regarding r24620: I confirmed Robert Hogan's OpenPGP fingerprint on
&lt;https://trac.torproject.org/projects/tor/ticket/2883&gt;.

Regarding r24621: I obtained Tom=C3=A1s Touceda's OpenPGP fingerprint from
his Tor LDAP account request on
&lt;https://trac.torproject.org/projects/tor/ticket/2621&gt;, and I verified
that the key with that fingerprint signed the Git tag vidalia-0.2.12 in
&lt;git://git.torproject.org/vidalia.git&gt; and the release tarball at
&lt;https://www.torproject.org/dist/vidalia/vidalia-0.2.12.tar.gz&gt;.


I believe that these changes are appropriate, but they need to be
reviewed before they are put onto The Tor Project's website.


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110414203143</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-04-14 20:31:43-0400</timestampReceived><subject>Re: [tor-dev] [tor-commits] r24618: {website} Update Vidalia's</subject><body>

[Attachment #2 (multipart/signed)]


Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:

&gt; On 22:10 Wed 13 Apr     , Fabian Keil wrote:
&gt; &gt; Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:
&gt; &gt; 
&gt; &gt; &gt; Author: chiiph
&gt; &gt; &gt; Date: 2011-04-13 19:55:14 +0000 (Wed, 13 Apr 2011)
&gt; &gt; &gt; New Revision: 24618
&gt; &gt; &gt; 
&gt; &gt; &gt; Modified:
&gt; &gt; &gt;    website/trunk/projects/en/vidalia.wml
&gt; &gt; &gt; Log:
&gt; &gt; &gt; Update Vidalia's project page
&gt; &gt; &gt; 
&gt; &gt; &gt; Modified: website/trunk/projects/en/vidalia.wml
&gt; &gt; &gt; ===================================================================
&gt; &gt; &gt; --- website/trunk/projects/en/vidalia.wml	2011-04-13 18:58:21 UTC (rev 24617)
&gt; &gt; &gt; +++ website/trunk/projects/en/vidalia.wml	2011-04-13 19:55:14 UTC (rev 24618)
&gt; &gt; &gt; @@ -55,26 +55,26 @@
&gt; &gt; 
&gt; &gt; &gt; -         &lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; &gt; -        (&lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz.asc"&gt;sig&lt;/a&gt;)
&gt; &gt; &gt; +         &lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; &gt; +        (&lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz.sig"&gt;sig&lt;/a&gt;)
&gt; &gt; &gt;        &lt;/li&gt;
&gt; &gt; 
&gt; &gt; I'm having trouble locating the new signing key. Any pointers?
&gt; &gt; Thanks.
 
&gt; http://dev.gentoo.org/~chiiph/chiiph.asc

Thanks.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110407194842</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-04-07 19:48:42-0400</timestampReceived><subject>[tor-dev] [Patch] src/test.c</subject><body>

I don't think it's a good idea to use hard-coded paths. Even in a
test source-file. Easy patch:

--- Git-latest\src\test\test.c       Wed Mar 30 11:58:28 2011
+++ src\test\test.c  Thu Mar 31 14:06:14 2011
@@ -86,7 +86,7 @@
 #ifdef MS_WINDOWS
   // XXXX
   tor_snprintf(temp_dir, sizeof(temp_dir),
-               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
+               "%s\\tor_test_%d", getenv("TEMP"), (int)getpid());
   r = mkdir(temp_dir);
 #else
   tor_snprintf(temp_dir, sizeof(temp_dir), "/tmp/tor_test_%d", (int) getpid());

----------

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407211812</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 21:18:12-0400</timestampReceived><subject>[tor-dev] Improved circuit-setup protocol [was: Re: Designing and</subject><body>

On Thu, Mar 31, 2011 at 5:52 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:

Hi!  I'm going to wait on a full review of your create/extend proposal
till it's done, but I though I could potentially answer some questions
and offer some comments:

1) I think CREATE cells need to get a field asking for a specific way
of handling RELAY cells.  If we ever update the relay crypto (that is,
the stuff described in 5.5 and 6.1 today) to do something other than
AES128_CTR for the encryption, SHA1 for the digest, we'll need a way
to ask for it.  I suppose that we could do that via adding a new
handshake type for a new desired link protocol, but it seems like the
two could be more or less orthogonal.

2) I don't get the rationale behind the variable-length type names.
Elsewhere in our protocol we'd just use a 1- or 2-byte type field.  Do
we win a lot by letting these be longer?

3) By convention, everything in our protocol is in "network"
(big-endian) byte-order.

4) There needs to be an authenticated way for the client to know which
handshake types and link specifier types a given node supports.  This
could be as simple as a series of statements like "Tor versions xyz
and later will support handshake type Y", or as complex as advertising
them in router descriptors.

5) I like the idea of separating the link specifiers from the
handshake type in EXTENDED cells.

6) I also think it'd be smart to figure out the actual link specifier
and handshake types that we want to move to before we decide that we
are confident that this format is right.  Those can be a different
proposal, though.

7) Here's a first cut of what I think might go in a link specifier format:

  * V4Address -- an ipv4 address, set to 0 if there is no IPv4 address
for the node [4 bytes]
  * V4ORPort [2 bytes]
  * V6Address -- an ipv6 address, set to 0 if there is no IPv6 address
for the node [16 bytes]
  * V6ORPort [2 bytes]
  * SHA256 of RSA1024 identity key [32 bytes]

When we decide what longer identity keys should look like, we can add
a new link specifier format that supports those.

8) This is totally back-of-the-envelope stuff, but it might be a good
starting point for crypto discussion.

Here's a first cut of what I think might go in an improved RSA handshake:

  * First 8 bytes of the SHA256 hash of the onion key [8 bytes]
    (This is here so that onion key rotation can work without having
to sometimes try the wrong onion key incorrectly.)
  * PK-encrypted:
    * Padding [PK_PAD_LEN bytes]
    * SHA256 hash of all remaining fields. [32 bytes]
    * Symmetric key seed [16 bytes]
    * The first part of g^x. [as much will fit in the PK-encrypted portion]
  * Symmetrically encrypted:
     * The rest of g^x.
     * 0 bytes for padding.

Here's a first cut of what I think might go in a hypothetical
diffie-hellman based handshake, for use with something like
Curve25519.  (I'm using g^x and g^y notation here as if this were
diffie-hellman in Z_p, since I don't yet trust myself to write ECC
stuff correctly.  I'm assuming that the node's public onion key is
g^x.)

   * SHA256 of all remaining fields. [32 bytes]
   * First 8 bytes of the SHA256 hash of the onion key (8 bytes)
   * g^y1 [DH_LEN bytes]
   * Encrypted using a symmetric key based on g^(x*y1):
       * g^y2 [DH_LEN bytes]
       * 0 bytes for padding

In both cases, we'll want a new key derivation function.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110406150122</emailId><senderName>rp</senderName><senderEmail>romanpauk@gmail.com</senderEmail><timestampReceived>2011-04-06 15:01:22-0400</timestampReceived><subject>[tor-dev] Redirecting network traffic to tor</subject><body>

Hi,

I've become interested in one problem stated on tor web pages which deals with
redirecting all traffic to tor (in windows). 

Redirecting traffic to tor seems to seek the goal of preventing traffic leaks.
Openvpn does it's tunneling by rerouting all traffic to virtual network device
and by changing dns resolver to the one on the remote tunnel side.

Using openvpn's code, there is one possible way to prevent trafic leaks -
by initializing fake route for all network traffic except for tor's, so only
tor traffic can leave to the network. To try it, I have written simple .so 
library, that is linked to openvpn and uses openvpn code to manipulate routes
(and possibly dns settings). Library gets loaded with tor using LD_PRELOAD and 
hooks connect and close calls on sockets.

It works in the following way:

1) default route is overriden with fake one
 - now no traffic except dns can leave (assuming dns server is default gateway)
2) with each tor's connect, a route is added so traffic is routed through old route
and not fake one, on close call the route is deleted
 - now only tor traffic and dns can leave
3) dns is set up to use tor's resolver
 - now only tor traffic will leave (assuming dns is properly redirected)
4) local connections fe. from web browser to local privoxy and from local privoxy
to tor socks proxy are working, so this could be in principle used to help user
with web browser gain more safety.

The drawback is that to manipulate routes, one needs admin privileges. But this
shouldn't be a problem - LD_PRELOAD way of doing things was the fastest to try this
out.

Although this is rather crude, it should prevent traffic leaks. What do you think
about this? Could it be to some use? I have already tested all points except number
3), which would need more work, so before it I have to ask for your opinions - 
whether this is a waste of time or not. Please let me know. 

Roman

PS: sorry for the noise with messages to various lists - i've got somewhat excited
that there is a possibility for me to help with something useful..
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407220415</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-04-07 22:04:15-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

On Thu, Apr 07, 2011 at 05:18:12PM -0400, Nick Mathewson wrote:
&gt; 8) This is totally back-of-the-envelope stuff, but it might be a good
&gt; starting point for crypto discussion.
&gt; 
&gt; Here's a first cut of what I think might go in an improved RSA handshake:
&gt; 
&gt;   * First 8 bytes of the SHA256 hash of the onion key [8 bytes]
&gt;     (This is here so that onion key rotation can work without having
&gt; to sometimes try the wrong onion key incorrectly.)
&gt;   * PK-encrypted:
&gt;     * Padding [PK_PAD_LEN bytes]
&gt;     * SHA256 hash of all remaining fields. [32 bytes]
&gt;     * Symmetric key seed [16 bytes]
&gt;     * The first part of g^x. [as much will fit in the PK-encrypted portion]
&gt;   * Symmetrically encrypted:
&gt;      * The rest of g^x.
&gt;      * 0 bytes for padding.
&gt; 
&gt; Here's a first cut of what I think might go in a hypothetical
&gt; diffie-hellman based handshake, for use with something like
&gt; Curve25519.  (I'm using g^x and g^y notation here as if this were
&gt; diffie-hellman in Z_p, since I don't yet trust myself to write ECC
&gt; stuff correctly.  I'm assuming that the node's public onion key is
&gt; g^x.)
&gt; 
&gt;    * SHA256 of all remaining fields. [32 bytes]
&gt;    * First 8 bytes of the SHA256 hash of the onion key (8 bytes)
&gt;    * g^y1 [DH_LEN bytes]
&gt;    * Encrypted using a symmetric key based on g^(x*y1):
&gt;        * g^y2 [DH_LEN bytes]
&gt;        * 0 bytes for padding

The phrase that jumps to mind is, "Danger Will Robinson!".  ;-)  If
we're redesigning the AKE (authenticated key agreement) bits, we
probably shouldn't just make up our own stuff.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407221047</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 22:10:47-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

On Thu, Apr 7, 2011 at 6:04 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
 [...]
&gt; The phrase that jumps to mind is, "Danger Will Robinson!".  ;-)  If
&gt; we're redesigning the AKE (authenticated key agreement) bits, we
&gt; probably shouldn't just make up our own stuff.

Indeed!  I am hoping that by threatening to do so, I can get the
cryptographers on the list to take an interest and tell us what to do
instead. ;)

(For background on why we would want to do crypto migration at atll,
see https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xxx-crypto-migration.txt
, for which there was never really enough comment.  See also proposal
176, which is totally Made Of Crypto.)

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110407221345</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 22:13:45-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

On Thu, Apr 7, 2011 at 5:18 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
 [...]
&gt; Here's a first cut of what I think might go in a hypothetical
&gt; diffie-hellman based handshake

I'm deliberately *not* using MQV, HMQV, FHMQV, etc etc here.  They're
faster than the "Just do DH twice" thing I wrote up, but the patent
situation seems unfavorable from what I can tell.  Also, curve25519 is
about 5x faster than our current 1024-bit DH, and about 11 times
faster than the 1536-bit DH we'd probably want to move towards for an
upgraded variant of current our RSA+DH handshake.  So replacing an RSA
and a DH with two ECC DH operations seems a find thing to do, assuming
that we decide that curve25519 is a good idea for us.

&gt; In both cases, we'll want a new key derivation function.

Oh!  Also, for a bit of redundancy, I'm thinking that the symmetric
crypto parts of the improved onion handshakes ought to be with a less
malleable mode of operation than the counter-mode stuff we do now.
Perhaps we could make use of an all-or-nothing mode of operation like
LIONESS or biIGE.  (They're both slower than counter mode, but for
purposes of CREATE cells, I don't think the hit will matter in
comparison with the cost of the public-key operations.)

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407222000</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-04-07 22:20:00-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re:</subject><body>

On Thu, Apr 07, 2011 at 06:13:45PM -0400, Nick Mathewson wrote:
&gt; Oh!  Also, for a bit of redundancy, I'm thinking that the symmetric
&gt; crypto parts of the improved onion handshakes ought to be with a less
&gt; malleable mode of operation than the counter-mode stuff we do now.
&gt; Perhaps we could make use of an all-or-nothing mode of operation like
&gt; LIONESS or biIGE.  (They're both slower than counter mode, but for
&gt; purposes of CREATE cells, I don't think the hit will matter in
&gt; comparison with the cost of the public-key operations.)

This is another thing that triggers my crypto-spidey-sense. The
particular problem that I'm thinking of is that for MAC-then-encrypt,
only some modes of operation are secure (CTR is, CBC is not). In some
ways, the malleability of CTR is a strength, and I'd be concerned that
something else might be able to be leveraged in an attack.

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407222224</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-04-07 22:22:24-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

On Thu, Apr 07, 2011 at 06:13:45PM -0400, Nick Mathewson wrote:
&gt; Oh!  Also, for a bit of redundancy, I'm thinking that the symmetric
&gt; crypto parts of the improved onion handshakes ought to be with a less
&gt; malleable mode of operation than the counter-mode stuff we do now.

Yes.  Absolute necessity.

&gt; Perhaps we could make use of an all-or-nothing mode of operation like
&gt; LIONESS or biIGE.  (They're both slower than counter mode, but for
&gt; purposes of CREATE cells, I don't think the hit will matter in
&gt; comparison with the cost of the public-key operations.)

A MAC (or a cipher mode that includes integrity like GCM) would be a
good start.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407222530</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-04-07 22:25:30-0400</timestampReceived><subject>Re: [tor-dev] Improved circuit-setup protocol [was: Re: Designing</subject><body>

On Thu, Apr 07, 2011 at 11:20:00PM +0100, Steven J. Murdoch wrote:
&gt; On Thu, Apr 07, 2011 at 06:13:45PM -0400, Nick Mathewson wrote:
&gt; &gt; Oh!  Also, for a bit of redundancy, I'm thinking that the symmetric
&gt; &gt; crypto parts of the improved onion handshakes ought to be with a less
&gt; &gt; malleable mode of operation than the counter-mode stuff we do now.
&gt; &gt; Perhaps we could make use of an all-or-nothing mode of operation like
&gt; &gt; LIONESS or biIGE.  (They're both slower than counter mode, but for
&gt; &gt; purposes of CREATE cells, I don't think the hit will matter in
&gt; &gt; comparison with the cost of the public-key operations.)
&gt; 
&gt; This is another thing that triggers my crypto-spidey-sense. The
&gt; particular problem that I'm thinking of is that for MAC-then-encrypt,
&gt; only some modes of operation are secure (CTR is, CBC is not). In some
&gt; ways, the malleability of CTR is a strength, and I'd be concerned that
&gt; something else might be able to be leveraged in an attack.

But we're currently doing "encrypt", not "MAC-then-encrypt".  And we
should be doing "encrypt-then-MAC", in my opinion, which ensures the
ciphertext can't be undetectably messed with.

In any event, yes, crypto-spidey-sense.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110413201026</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-04-13 20:10:26-0400</timestampReceived><subject>Re: [tor-dev] [tor-commits] r24618: {website} Update Vidalia's</subject><body>

[Attachment #2 (multipart/signed)]


Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:

&gt; Author: chiiph
&gt; Date: 2011-04-13 19:55:14 +0000 (Wed, 13 Apr 2011)
&gt; New Revision: 24618
&gt; 
&gt; Modified:
&gt;    website/trunk/projects/en/vidalia.wml
&gt; Log:
&gt; Update Vidalia's project page
&gt; 
&gt; Modified: website/trunk/projects/en/vidalia.wml
&gt; ===================================================================
&gt; --- website/trunk/projects/en/vidalia.wml	2011-04-13 18:58:21 UTC (rev 24617)
&gt; +++ website/trunk/projects/en/vidalia.wml	2011-04-13 19:55:14 UTC (rev 24618)
&gt; @@ -55,26 +55,26 @@

&gt; -         &lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; -        (&lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz.asc"&gt;sig&lt;/a&gt;)
&gt; +         &lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; +        (&lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz.sig"&gt;sig&lt;/a&gt;)
&gt;        &lt;/li&gt;

I'm having trouble locating the new signing key. Any pointers?
Thanks.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110413203432</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-04-13 20:34:32-0400</timestampReceived><subject>Re: [tor-dev] [tor-commits] r24618: {website} Update Vidalia's</subject><body>

[Attachment #2 (multipart/signed)]


On Wed, 13 Apr 2011 22:10:26 +0200
Fabian Keil &lt;freebsd-listen@fabiankeil.de&gt; wrote:

&gt; Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:
&gt; 
&gt; &gt; Author: chiiph
&gt; &gt; Date: 2011-04-13 19:55:14 +0000 (Wed, 13 Apr 2011)
&gt; &gt; New Revision: 24618
&gt; &gt; 
&gt; &gt; Modified:
&gt; &gt;    website/trunk/projects/en/vidalia.wml
&gt; &gt; Log:
&gt; &gt; Update Vidalia's project page
&gt; &gt; 
&gt; &gt; Modified: website/trunk/projects/en/vidalia.wml
&gt; &gt; ===================================================================
&gt; &gt; --- website/trunk/projects/en/vidalia.wml	2011-04-13 18:58:21 UTC (rev 24617)
&gt; &gt; +++ website/trunk/projects/en/vidalia.wml	2011-04-13 19:55:14 UTC (rev 24618)
&gt; &gt; @@ -55,26 +55,26 @@
&gt; 
&gt; &gt; -         &lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; -        (&lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz.asc"&gt;sig&lt;/a&gt;)
&gt; &gt; +         &lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; +        (&lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz.sig"&gt;sig&lt;/a&gt;)
&gt; &gt;        &lt;/li&gt;
&gt; 
&gt; I'm having trouble locating the new signing key. Any pointers?

That key is probably the one whose fingerprint is here:
https://trac.torproject.org/projects/tor/ticket/2621


Robert Ransom

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110416131106</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-04-16 13:11:06-0400</timestampReceived><subject>Re: [tor-dev] Orbot's inclusion of Privoxy</subject><body>

Thanks for the note, Fabian.

On 04/16/2011 06:24 AM, Fabian Keil wrote:
&gt; This seems to be (or based on) Privoxy 3.0.12 released in 2009.
&gt; What's the rationale for not using a more recent version?

At this point, that is the latest version we have successfully
cross-compiled for Android. We are working on updating our build process
to the new Android Native Dev Kit cross-compiler, and updating all
relevant components.

I will admit that our focus on keep bundled versions current have been
more focused on Tor, than on Privoxy. I will make sure that we keep as
close tabs on that component, as well.

We have not included the binary files in the repo historically. However,
there have been a number of Android app/UI developers who wished to
contribute code there, but were unable to setup the entire OS build
chain on their Mac or Windows machines, that is required to build the C
binaries. If we provide them pre-built binaries for dev purposes, it
increases the likelihood we will have more contributors.

&gt; Is this vanilla Privoxy or are there any custom patches?

It is vanilla, save for one setting:
export ac_cv_func_setpgrp_void=yes

as documented here:
https://svn.torproject.org/svn/projects/android/trunk/Orbot/BUILD

&gt; I get the impression that you are currently distributing the
&gt; Privoxy binary as part of Orbot without even mentioning the
&gt; license. Is that correct, or am I missing something?

We mention the inclusion in our app About screen, but you are current
that our inclusion is not mentioned in the license file or screens. This
is an unfortunate oversight, that I will address today.

Best,
 Nathan
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110404071804</emailId><senderName>Sukhbir Singh</senderName><senderEmail>sukhbir.in@gmail.com</senderEmail><timestampReceived>2011-04-04 07:18:04-0400</timestampReceived><subject>[tor-dev] GSoC - Torbutton for Thunderbird</subject><body>

Hi!

I am interested in participating in Google's Summer of Code this year
and implementing the Torbutton equivalent for Thunderbird [0].

I have been discussing the project with Mike Perry and we feel that it
is possible to implement this. The first step was removing the
hostname Thunderbird puts in the outgoing message header, which we
easily fixed. That gave us the initial motivation to pursue this
further.

There are a number of issue that still remain, however we feel that
those can be easily worked out. We have put all probable solutions to
Torbutton requirements from [1] in the attachment with this mail and
are looking for your suggestions/ comments about this.

We have not submitted an application for this to Google yet; I intend
to do that after gauging the response towards this proposal from the
mailing list.

Let's hope that we can make this a success,

--
Thanks,

Sukhbir Singh

[0] - https://www.torproject.org/getinvolved/volunteer.html.en#torbuttonForThunderbird
[1] - https://www.torproject.org/torbutton/en/design/#requirements

Attachment - Plain text

["Torbutton" (application/octet-stream)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110419101717</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-04-19 10:17:17-0400</timestampReceived><subject>[tor-dev] The Torouter project - where are we now?</subject><body>

Hi everyone,

I am trying to figure out how we can move the Torouter project
forward. In this email, I will try to summarize the current status of
this project.

The Torouter project has a total of four bugs in Trac. These are
#2334, #2376, #2370 and #2596.

#2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
files. The quick and easy solution here is to attach a USB stick to
the router and use it as Tor's data directory. However, it would be
great if someone could take a look at this and figure out a way to
solve it.

#2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
The problem with having Tor's data directory in /tmp is that whenever
Torouter is rebooted, Tor generates new keys and gets a new
fingerprint.

There are a couple of different ways to solve this problem; Karsten
suggested that we could modify OpenWrt to stop creating a /tmp
partition. This probably means that we will have to ship our own
OpenWrt image. I'm thinking that another option would be to modify the
Tor-OpenWrt-package to use / as the data directory instead of /tmp.
However, I wonder if 64M (no matter how it's partitioned) of space on
the Buffalo router is insufficient as long as #2334 remains open.

#2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
interface myself, but development seems to be moving along nicely. I'm
not sure what the remaining steps are, other than packaging it as
tor-ui (or similar) for OpenWrt.

#2596: Figure out a better name than "torouter". Andrew thinks we
should come up with a better name for this project, one that does not
have "Tor" in the name. Suggestions?

The Torouter project also has some open questions (some are mentioned
on https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Torouter
as well):

1. How can we make sure that the version of Tor in OpenWrt is always
up to date? Should we set up our own OpenWrt repository? Right now,
the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
packages for both stable and unstable?

2. We want to collect statistics, which means that we need to ship a
GeoIP file as well. I'm thinking we should create a tor-geoipdb
package for OpenWrt. Thoughts?

3. Do we want one Tor process for bridging and one for the transparent
wifi network? I think this sounds good, if the router can handle it.
If not, then just running a bridge is ok too.

Have I missed anything important? Are there any other packages that we
should include in OpenWrt? Other comments or suggestions? If you have
more information or would like to help out, please let me know.

Thanks,

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110427215905</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-04-27 21:59:05-0400</timestampReceived><subject>[tor-dev] Fwd: Re: [guardian-dev] ORBot Alpha, some candles,</subject><body>

fyi

-------- Original Message --------
Subject: Re: [guardian-dev] ORBot Alpha, some candles, a few glasses of
wine and a packet sniffer
Date: Wed, 27 Apr 2011 14:49:01 -0700
From: Nathan of Guardian &lt;nathan@guardianproject.info&gt;
Organization: The Guardian Project
To: guardian-dev@lists.mayfirst.org
CC: tor-dev@lists.torproject.org

Fantastic, Manuel. Looks like we are going to need some wine over to
patch this up. This type of look at how our transproxy all rules are
working (or not) is long overdue. I really appreciate your effort.

The first thing that comes to mind is that we are setting up the
iptables rules on an app-by-app basis, using the list of user IDs we are
provided by Android API calls. It is quite possible that certain
subsystems are not represented in that list.

There may be a better way to implement the transproxy all implementation
that is more of a "everything but tor" approach.

Our transproxy configuration is based on the approach outlined here:
https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TransparentProxy

We'll have to go through additional recommended configurations that we
are not addressing in our current "all" setup, and see if they address
the leakage you have found.

Best,
 Nathan

On 04/27/2011 12:40 PM, Manuel wrote:
&gt; Hi all!
&gt; 
&gt; Mini-intro: Hi, I'm Manuel (aka __sporkbomb), infosec researcher from
&gt; Austria, got bored and asked Nathan if he wanted help with ORBot ;)
&gt; 
&gt; Setup: Simply an open AP, a Desire HD running CM 7.0.2 and
&gt; 0.2.2.22-orbot-alpha-1.0.5.20110417a-dev plus airodump.
&gt; 
&gt; Methodology: The dump was started after the tor connection (and full
&gt; transproxying) was established in order to reduce false positives. Total
&gt; dump length is around 3h15m, around 57MB of data. Of course the phone
&gt; was left idle for a quite a while, also to ensure that it didn't do
&gt; nasty untorified stuff when waking up to check mails. Afterwards, I used
&gt; Wireshark's 'Endpoints' statistics function to determine all TCP
&gt; endpoints in the dump[0] and awk'd &amp; uniq'd the IPs out of it[1]. As the
&gt; next step, I determined which of these IPs was in my cached-consensus[2]
&gt; (somewhat ill-advised, because I compared with my laptop's
&gt; cached-consensus rather than the phone's, causing two false positives
&gt; [false non-tor nodes] that actually were nodes). I also ran a reverse
&gt; lookup on all IPs [3]. As the last step, I went through all
&gt; communication with IPs that were not found in cached-consensus[4].
&gt; 
&gt; You can find links to most of the files I produced at the end of this
&gt; mail, excluding the dump, which I can provide if requested, but would
&gt; rather not hand out publicly (mostly because of the size).
&gt; 
&gt; All in all, the phone connected to 88 IPs during that time. 37 of those
&gt; were not contained in the laptop's cached-consensus, two of which were
&gt; actually legitimate nodes (according to metrics.torproject.org) that
&gt; just went down throughout the duration of the test, leaving us with 35
&gt; non-Tor IPs. They can be categorized as follows:
&gt; 
&gt; - 27 of those nodes had no other communication than multiple TCP
&gt; packets, sometimes from a few different source ports (i.e. different TCP
&gt; connections), all originating from the phone and having FIN+PSH+ACK set.
&gt; (PSH is the 'push flag', which requests that this data bypass buffers
&gt; and be handed directly to the application)
&gt; 
&gt; - 4 existing connections that still transmitted data; one even contained
&gt; Market HTTP (cleartext) API requests.
&gt; 
&gt; - 4 were completely unencrypted and newly established connections to
&gt; YouTube or Revision3 video servers. This one is rather bad - it seems
&gt; that the video player subsystem of Android ignores the proxy setting and
&gt; leaks everything, including DNS. I also mentioned this yesterday on
&gt; Twitter, but didn't want to post it yet without confirmation, but it's
&gt; definitely reproducible on my end.
&gt; 
&gt; --------------------
&gt; Sumup of this part: Generally solid performance, but already established
&gt; connections might pose a threat (a minor one I'd guess, however...unless
&gt; one of you can think of a scenario where that causes Bad Things to
&gt; happen?). Additionally, the video player completely ignores the proxy
&gt; setting and communicates untorified. While video streaming isn't a
&gt; strong point of Tor anyway, it's still not good...does anyone have good
&gt; contact to CyanogenMod people and can ask about that one?
&gt; 
&gt; Various tidbits of slight UX annoyances plus a few suggestions:
&gt; - ORBot ignores the "Transparent proxy" setting when connecting, I
&gt; always have to enter the Settings menu, untick and re-tick "Transparent
&gt; proxying" and press back to actually cause it to be enabled.
&gt; - Related to this: Is it possible to colour-code the "Transparent
&gt; proxying {DIS,EN}ABLED" notification? The bug above might have serious
&gt; consequences, because if someone doesn't visit check.torproject.org to
&gt; assure that he/she is actually torified, chances are that he/she will
&gt; browse in clear. DISABLED and ENABLED are only three characters away
&gt; from each other, whereas a red vs green notification would probably
&gt; catch the eye.
&gt; - Install fails when installing/uncompressing tor binary
&gt; https://trac.torproject.org/projects/tor/ticket/2989 [turns out that
&gt; this is only a bug on Android&lt;2.3, but still...see comment #1 for more
&gt; details]
&gt; - Blank semi-permanent status box
&gt; https://trac.torproject.org/projects/tor/ticket/2993 [haven't updated
&gt; this one yet; the bug actually occured only before the first reboot for
&gt; me, and one time afterwards when I had b0rked the network badly]
&gt; - ORBot vs DroidWall: Starts with 'You don't preserve my chains like you
&gt; used to :(' and ends with, if I remember correctly, ORBot flushing
&gt; iptables rules. I'll have a look at that one tomorrow (or is there
&gt; already some data on it?).
&gt; 
&gt; For now, have a nice evening!
&gt; 
&gt; Cheers,
&gt; 
&gt; __sporkbomb
&gt; 
&gt; 
&gt; 
&gt; 
&gt; 
&gt; [0] http://sporkbomb.eu/orbot/endpoints
&gt; [1] http://sporkbomb.eu/orbot/ips
&gt; [2] http://sporkbomb.eu/orbot/inconsensus (result of a grep -c - IPs
&gt; with '0' in the second field are not contained in the consensus)
&gt; [3] http://sporkbomb.eu/orbot/dig-result
&gt; [4] http://sporkbomb.eu/orbot/not-inconsensus.notes
&gt; _______________________________________________
&gt; Guardian-dev mailing list
&gt; 
&gt; Post: Guardian-dev@lists.mayfirst.org
&gt; List info: https://lists.mayfirst.org/mailman/listinfo/guardian-dev
&gt; 
&gt; To Unsubscribe
&gt;         Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
&gt;         Or visit: https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info
&gt; 
&gt; You are subscribed as: nathan@guardianproject.info

_______________________________________________
Guardian-dev mailing list

Post: Guardian-dev@lists.mayfirst.org
List info: https://lists.mayfirst.org/mailman/listinfo/guardian-dev

To Unsubscribe
        Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
        Or visit:
https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info

You are subscribed as: nathan@guardianproject.info
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110419203934</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-04-19 20:39:34-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Tue, 19 Apr 2011 11:17:17 +0100
"Runa A. Sandvik" &lt;runa.sandvik@gmail.com&gt; wrote:
&gt; I am trying to figure out how we can move the Torouter project
&gt; forward. In this email, I will try to summarize the current status of
&gt; this project.

My general thoughts are that we figure out the web ui, a config that is
a bridge by default, and start sending some out to users to get some
real feedback.

&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt; files. The quick and easy solution here is to attach a USB stick to
&gt; the router and use it as Tor's data directory. However, it would be
&gt; great if someone could take a look at this and figure out a way to
&gt; solve it.

Shipping a beta test router with a 1 gb disk stuck in it isn't so bad.
Fixing tor to handle such a constrained environment is better, but
clearly longer term.

&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt; fingerprint.

I don't see this as a real problem, actually.  

&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt; interface myself, but development seems to be moving along nicely. I'm
&gt; not sure what the remaining steps are, other than packaging it as
&gt; tor-ui (or similar) for OpenWrt.

A tor-ui for openwrt sounds good.


&gt; 1. How can we make sure that the version of Tor in OpenWrt is always
&gt; up to date? Should we set up our own OpenWrt repository? Right now,
&gt; the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
&gt; packages for both stable and unstable?

A tor openwrt package sounds good.  

&gt; 2. We want to collect statistics, which means that we need to ship a
&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt; package for OpenWrt. Thoughts?

A tor-geoipdb package sounds good.

&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt; wifi network? I think this sounds good, if the router can handle it.
&gt; If not, then just running a bridge is ok too.

I think starting with a bridge config is good.  Starting with
transparent tor wifi may be too much to start.  The original goal of
the router was to provide automatically configured bridges and relays
for people who want to help.

-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110421082616</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-04-21 08:26:16-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/19/2011 03:17 AM, Runa A. Sandvik wrote:
&gt; Hi everyone,
&gt; 
&gt; I am trying to figure out how we can move the Torouter project
&gt; forward. In this email, I will try to summarize the current status of
&gt; this project.
&gt; 
&gt; The Torouter project has a total of four bugs in Trac. These are
&gt; #2334, #2376, #2370 and #2596.
&gt; 
&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt; files. The quick and easy solution here is to attach a USB stick to
&gt; the router and use it as Tor's data directory. However, it would be
&gt; great if someone could take a look at this and figure out a way to
&gt; solve it.

This is only a problem on smaller hardware - so if we really want the
Buffalo router, we'll need to fix this or create a work around that
isn't a total PITA. For now, I think we can just add a USB disk and deal
with it later.

If we find that the router can't handle being a bridge, I'm not really
concerned with this bug.

&gt; 
&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt; fingerprint.

I commented on the bug - it's easy enough to change this by submitting a
patch to openwrt-devel@lists.openwrt.org


&gt; 
&gt; There are a couple of different ways to solve this problem; Karsten
&gt; suggested that we could modify OpenWrt to stop creating a /tmp
&gt; partition. This probably means that we will have to ship our own
&gt; OpenWrt image. I'm thinking that another option would be to modify the
&gt; Tor-OpenWrt-package to use / as the data directory instead of /tmp.
&gt; However, I wonder if 64M (no matter how it's partitioned) of space on
&gt; the Buffalo router is insufficient as long as #2334 remains open.

If we're shipping our own image, we can do a bunch of stuff. Is that
what we want to do?

&gt; 
&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt; interface myself, but development seems to be moving along nicely. I'm
&gt; not sure what the remaining steps are, other than packaging it as
&gt; tor-ui (or similar) for OpenWrt.
&gt; 

The web interface should go into version control, it should be added to
the tor-alpha package in the OpenWRT svn (that's why I created it), and
it should be used by some people.

&gt; #2596: Figure out a better name than "torouter". Andrew thinks we
&gt; should come up with a better name for this project, one that does not
&gt; have "Tor" in the name. Suggestions?
&gt; 

I think torouter is a perfectly fine name until we actually have a
shipping prototype.

&gt; The Torouter project also has some open questions (some are mentioned
&gt; on https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Torouter
&gt; as well):
&gt; 
&gt; 1. How can we make sure that the version of Tor in OpenWrt is always
&gt; up to date? Should we set up our own OpenWrt repository? Right now,
&gt; the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
&gt; packages for both stable and unstable?

I think we should contribute back to OpenWRT (as I've been doing) and
for our router, we should consider adding a feed for the specific
hardware we intend to support. Still, we'll need to ensure the versions
of _everything_ are up to date and not just Tor.

So what's our general update strategy for any platform we ship?

&gt; 
&gt; 2. We want to collect statistics, which means that we need to ship a
&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt; package for OpenWrt. Thoughts?
&gt; 

There's a tor-geoip package created by the tor package in the OpenWRT
svn repo (from looking at the Makefile).

&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt; wifi network? I think this sounds good, if the router can handle it.
&gt; If not, then just running a bridge is ok too.

I think we should run both in a single Tor for now but I think we should
only enable the bridge by default. The web UI can enable the transparent
stuff if we want it.

&gt; 
&gt; Have I missed anything important? Are there any other packages that we
&gt; should include in OpenWrt? Other comments or suggestions? If you have
&gt; more information or would like to help out, please let me know.
&gt; 

We need to make packages for the libnatpmp and miniupnpc libraries
because we need tor-fw-helper support in tor-alpha.

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110421142447</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-04-21 14:24:47-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Thu, Apr 21, 2011 at 9:26 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On 04/19/2011 03:17 AM, Runa A. Sandvik wrote:
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; I am trying to figure out how we can move the Torouter project
&gt;&gt; forward. In this email, I will try to summarize the current status of
&gt;&gt; this project.
&gt;&gt;
&gt;&gt; The Torouter project has a total of four bugs in Trac. These are
&gt;&gt; #2334, #2376, #2370 and #2596.
&gt;&gt;
&gt;&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt;&gt; files. The quick and easy solution here is to attach a USB stick to
&gt;&gt; the router and use it as Tor's data directory. However, it would be
&gt;&gt; great if someone could take a look at this and figure out a way to
&gt;&gt; solve it.
&gt;
&gt; This is only a problem on smaller hardware - so if we really want the
&gt; Buffalo router, we'll need to fix this or create a work around that
&gt; isn't a total PITA. For now, I think we can just add a USB disk and deal
&gt; with it later.
&gt;
&gt; If we find that the router can't handle being a bridge, I'm not really
&gt; concerned with this bug.

As far as I know, the router can handle being a bridge as long as it
has enough disk space.

&gt;&gt;
&gt;&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt;&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt;&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt;&gt; fingerprint.
&gt;
&gt; I commented on the bug - it's easy enough to change this by submitting a
&gt; patch to openwrt-devel@lists.openwrt.org

Great.

&gt;&gt;
&gt;&gt; There are a couple of different ways to solve this problem; Karsten
&gt;&gt; suggested that we could modify OpenWrt to stop creating a /tmp
&gt;&gt; partition. This probably means that we will have to ship our own
&gt;&gt; OpenWrt image. I'm thinking that another option would be to modify the
&gt;&gt; Tor-OpenWrt-package to use / as the data directory instead of /tmp.
&gt;&gt; However, I wonder if 64M (no matter how it's partitioned) of space on
&gt;&gt; the Buffalo router is insufficient as long as #2334 remains open.
&gt;
&gt; If we're shipping our own image, we can do a bunch of stuff. Is that
&gt; what we want to do?

I don't think we should ship our own image, for the simple reason that
we already have enough stuff to maintain.

&gt;&gt;
&gt;&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt;&gt; interface myself, but development seems to be moving along nicely. I'm
&gt;&gt; not sure what the remaining steps are, other than packaging it as
&gt;&gt; tor-ui (or similar) for OpenWrt.
&gt;&gt;
&gt;
&gt; The web interface should go into version control, it should be added to
&gt; the tor-alpha package in the OpenWRT svn (that's why I created it), and
&gt; it should be used by some people.

Ok, do you want to take care of this? That is, putting the web
interface into version control and packaging it for OpenWrt.

&gt;&gt; #2596: Figure out a better name than "torouter". Andrew thinks we
&gt;&gt; should come up with a better name for this project, one that does not
&gt;&gt; have "Tor" in the name. Suggestions?
&gt;&gt;
&gt;
&gt; I think torouter is a perfectly fine name until we actually have a
&gt; shipping prototype.

Sure, that works too.

&gt;&gt; The Torouter project also has some open questions (some are mentioned
&gt;&gt; on https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Torouter
&gt;&gt; as well):
&gt;&gt;
&gt;&gt; 1. How can we make sure that the version of Tor in OpenWrt is always
&gt;&gt; up to date? Should we set up our own OpenWrt repository? Right now,
&gt;&gt; the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
&gt;&gt; packages for both stable and unstable?
&gt;
&gt; I think we should contribute back to OpenWRT (as I've been doing) and
&gt; for our router, we should consider adding a feed for the specific
&gt; hardware we intend to support. Still, we'll need to ensure the versions
&gt; of _everything_ are up to date and not just Tor.
&gt;
&gt; So what's our general update strategy for any platform we ship?
&gt;
&gt;&gt;
&gt;&gt; 2. We want to collect statistics, which means that we need to ship a
&gt;&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt;&gt; package for OpenWrt. Thoughts?
&gt;&gt;
&gt;
&gt; There's a tor-geoip package created by the tor package in the OpenWRT
&gt; svn repo (from looking at the Makefile).

So, it turns out that packages in OpenWrt are not updated after a
release. That explains why I got 0.2.1.26 when 0.2.1.30 is available
in the OpenWrt SVN.

The best way to ensure that users can easily upgrade Tor and related
packages is to set up a torproject.org repository for OpenWrt
packages. This repository would then have to be added to
/etc/opkg.conf.

&gt;&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt;&gt; wifi network? I think this sounds good, if the router can handle it.
&gt;&gt; If not, then just running a bridge is ok too.
&gt;
&gt; I think we should run both in a single Tor for now but I think we should
&gt; only enable the bridge by default. The web UI can enable the transparent
&gt; stuff if we want it.

Sounds good.

&gt;&gt; Have I missed anything important? Are there any other packages that we
&gt;&gt; should include in OpenWrt? Other comments or suggestions? If you have
&gt;&gt; more information or would like to help out, please let me know.
&gt;&gt;
&gt;
&gt; We need to make packages for the libnatpmp and miniupnpc libraries
&gt; because we need tor-fw-helper support in tor-alpha.

Is this something you can / want to take care of?

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110421161756</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-04-21 16:17:56-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/21/2011 07:24 AM, Runa A. Sandvik wrote:
&gt; On Thu, Apr 21, 2011 at 9:26 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;&gt; On 04/19/2011 03:17 AM, Runa A. Sandvik wrote:
&gt;&gt;&gt; Hi everyone,
&gt;&gt;&gt;
&gt;&gt;&gt; I am trying to figure out how we can move the Torouter project
&gt;&gt;&gt; forward. In this email, I will try to summarize the current status of
&gt;&gt;&gt; this project.
&gt;&gt;&gt;
&gt;&gt;&gt; The Torouter project has a total of four bugs in Trac. These are
&gt;&gt;&gt; #2334, #2376, #2370 and #2596.
&gt;&gt;&gt;
&gt;&gt;&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt;&gt;&gt; files. The quick and easy solution here is to attach a USB stick to
&gt;&gt;&gt; the router and use it as Tor's data directory. However, it would be
&gt;&gt;&gt; great if someone could take a look at this and figure out a way to
&gt;&gt;&gt; solve it.
&gt;&gt;
&gt;&gt; This is only a problem on smaller hardware - so if we really want the
&gt;&gt; Buffalo router, we'll need to fix this or create a work around that
&gt;&gt; isn't a total PITA. For now, I think we can just add a USB disk and deal
&gt;&gt; with it later.
&gt;&gt;
&gt;&gt; If we find that the router can't handle being a bridge, I'm not really
&gt;&gt; concerned with this bug.
&gt; 
&gt; As far as I know, the router can handle being a bridge as long as it
&gt; has enough disk space.
&gt; 

What tests indicate this? How many clients can it handle and at what rate?

&gt;&gt;&gt;
&gt;&gt;&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt;&gt;&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt;&gt;&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt;&gt;&gt; fingerprint.
&gt;&gt;
&gt;&gt; I commented on the bug - it's easy enough to change this by submitting a
&gt;&gt; patch to openwrt-devel@lists.openwrt.org
&gt; 
&gt; Great.
&gt; 
&gt;&gt;&gt;
&gt;&gt;&gt; There are a couple of different ways to solve this problem; Karsten
&gt;&gt;&gt; suggested that we could modify OpenWrt to stop creating a /tmp
&gt;&gt;&gt; partition. This probably means that we will have to ship our own
&gt;&gt;&gt; OpenWrt image. I'm thinking that another option would be to modify the
&gt;&gt;&gt; Tor-OpenWrt-package to use / as the data directory instead of /tmp.
&gt;&gt;&gt; However, I wonder if 64M (no matter how it's partitioned) of space on
&gt;&gt;&gt; the Buffalo router is insufficient as long as #2334 remains open.
&gt;&gt;
&gt;&gt; If we're shipping our own image, we can do a bunch of stuff. Is that
&gt;&gt; what we want to do?
&gt; 
&gt; I don't think we should ship our own image, for the simple reason that
&gt; we already have enough stuff to maintain.
&gt; 

I generally agree but I think we're going to have to deal with this
issue one way or another.

If we're shipping people a router, I'd like to harden it. For example -
it does not appear that all of the gcc hardening features are enabled by
default.

We can commit to a simple, fixed release cycle for the OS and a constant
stream of updates for Tor.

&gt;&gt;&gt;
&gt;&gt;&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt;&gt;&gt; interface myself, but development seems to be moving along nicely. I'm
&gt;&gt;&gt; not sure what the remaining steps are, other than packaging it as
&gt;&gt;&gt; tor-ui (or similar) for OpenWrt.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; The web interface should go into version control, it should be added to
&gt;&gt; the tor-alpha package in the OpenWRT svn (that's why I created it), and
&gt;&gt; it should be used by some people.
&gt; 
&gt; Ok, do you want to take care of this? That is, putting the web
&gt; interface into version control and packaging it for OpenWrt.

Not really? :-)

In an ideal world, I think we should make these changes in the tor-alpha
package. Currently, I'm not familiar with the webui at all.

I'd prefer that someone involved in developing the webui actually built
a stand alone package.

&gt; 
&gt;&gt;&gt; #2596: Figure out a better name than "torouter". Andrew thinks we
&gt;&gt;&gt; should come up with a better name for this project, one that does not
&gt;&gt;&gt; have "Tor" in the name. Suggestions?
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; I think torouter is a perfectly fine name until we actually have a
&gt;&gt; shipping prototype.
&gt; 
&gt; Sure, that works too.
&gt; 
&gt;&gt;&gt; The Torouter project also has some open questions (some are mentioned
&gt;&gt;&gt; on https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Torouter
&gt;&gt;&gt; as well):
&gt;&gt;&gt;
&gt;&gt;&gt; 1. How can we make sure that the version of Tor in OpenWrt is always
&gt;&gt;&gt; up to date? Should we set up our own OpenWrt repository? Right now,
&gt;&gt;&gt; the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
&gt;&gt;&gt; packages for both stable and unstable?
&gt;&gt;
&gt;&gt; I think we should contribute back to OpenWRT (as I've been doing) and
&gt;&gt; for our router, we should consider adding a feed for the specific
&gt;&gt; hardware we intend to support. Still, we'll need to ensure the versions
&gt;&gt; of _everything_ are up to date and not just Tor.
&gt;&gt;
&gt;&gt; So what's our general update strategy for any platform we ship?
&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; 2. We want to collect statistics, which means that we need to ship a
&gt;&gt;&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt;&gt;&gt; package for OpenWrt. Thoughts?
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; There's a tor-geoip package created by the tor package in the OpenWRT
&gt;&gt; svn repo (from looking at the Makefile).
&gt; 
&gt; So, it turns out that packages in OpenWrt are not updated after a
&gt; release. That explains why I got 0.2.1.26 when 0.2.1.30 is available
&gt; in the OpenWrt SVN.
&gt; 

Makes sense.

&gt; The best way to ensure that users can easily upgrade Tor and related
&gt; packages is to set up a torproject.org repository for OpenWrt
&gt; packages. This repository would then have to be added to
&gt; /etc/opkg.conf.

That's similar to what I said on IRC; it seems reasonable to keep the
Tor package updated in OpenWRT. We need to decide if we want to build
regular packages for installation and also if we want to host them. I
think this is mostly an Erinn question - helix?

&gt; 
&gt;&gt;&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt;&gt;&gt; wifi network? I think this sounds good, if the router can handle it.
&gt;&gt;&gt; If not, then just running a bridge is ok too.
&gt;&gt;
&gt;&gt; I think we should run both in a single Tor for now but I think we should
&gt;&gt; only enable the bridge by default. The web UI can enable the transparent
&gt;&gt; stuff if we want it.
&gt; 
&gt; Sounds good.

What's the default config that we want to ship?

&gt; 
&gt;&gt;&gt; Have I missed anything important? Are there any other packages that we
&gt;&gt;&gt; should include in OpenWrt? Other comments or suggestions? If you have
&gt;&gt;&gt; more information or would like to help out, please let me know.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; We need to make packages for the libnatpmp and miniupnpc libraries
&gt;&gt; because we need tor-fw-helper support in tor-alpha.
&gt; 
&gt; Is this something you can / want to take care of?

I'm a little more interested in making these packages. Do you want to
open a set of bugs and we can continue deeper discussion in bugs?

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110421175703</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-04-21 17:57:03-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

[Attachment #2 (multipart/signed)]


* Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 09:17 -0700]: 
&gt; &gt; The best way to ensure that users can easily upgrade Tor and related
&gt; &gt; packages is to set up a torproject.org repository for OpenWrt
&gt; &gt; packages. This repository would then have to be added to
&gt; &gt; /etc/opkg.conf.
&gt; 
&gt; That's similar to what I said on IRC; it seems reasonable to keep the
&gt; Tor package updated in OpenWRT. We need to decide if we want to build
&gt; regular packages for installation and also if we want to host them. I
&gt; think this is mostly an Erinn question

I'm not sure if this is actually a question for me, since I'm not involved in
the Tor router stuff and don't currently have any plans to maintain a new
package. Give me more information about the format of the package and
repository?

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110421181517</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-04-21 18:15:17-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Thu, Apr 21, 2011 at 5:17 PM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On 04/21/2011 07:24 AM, Runa A. Sandvik wrote:
&gt;&gt; On Thu, Apr 21, 2011 at 9:26 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;&gt;&gt; On 04/19/2011 03:17 AM, Runa A. Sandvik wrote:
&gt;&gt;&gt;&gt; Hi everyone,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I am trying to figure out how we can move the Torouter project
&gt;&gt;&gt;&gt; forward. In this email, I will try to summarize the current status of
&gt;&gt;&gt;&gt; this project.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; The Torouter project has a total of four bugs in Trac. These are
&gt;&gt;&gt;&gt; #2334, #2376, #2370 and #2596.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt;&gt;&gt;&gt; files. The quick and easy solution here is to attach a USB stick to
&gt;&gt;&gt;&gt; the router and use it as Tor's data directory. However, it would be
&gt;&gt;&gt;&gt; great if someone could take a look at this and figure out a way to
&gt;&gt;&gt;&gt; solve it.
&gt;&gt;&gt;
&gt;&gt;&gt; This is only a problem on smaller hardware - so if we really want the
&gt;&gt;&gt; Buffalo router, we'll need to fix this or create a work around that
&gt;&gt;&gt; isn't a total PITA. For now, I think we can just add a USB disk and deal
&gt;&gt;&gt; with it later.
&gt;&gt;&gt;
&gt;&gt;&gt; If we find that the router can't handle being a bridge, I'm not really
&gt;&gt;&gt; concerned with this bug.
&gt;&gt;
&gt;&gt; As far as I know, the router can handle being a bridge as long as it
&gt;&gt; has enough disk space.
&gt;&gt;
&gt;
&gt; What tests indicate this? How many clients can it handle and at what rate?

My mistake. I thought someone had a bridge running and that the only
problem was disk space. I'll see if I can set up my router as a bridge
this weekend and get things working.

&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt;&gt;&gt;&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt;&gt;&gt;&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt;&gt;&gt;&gt; fingerprint.
&gt;&gt;&gt;
&gt;&gt;&gt; I commented on the bug - it's easy enough to change this by submitting a
&gt;&gt;&gt; patch to openwrt-devel@lists.openwrt.org
&gt;&gt;
&gt;&gt; Great.
&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; There are a couple of different ways to solve this problem; Karsten
&gt;&gt;&gt;&gt; suggested that we could modify OpenWrt to stop creating a /tmp
&gt;&gt;&gt;&gt; partition. This probably means that we will have to ship our own
&gt;&gt;&gt;&gt; OpenWrt image. I'm thinking that another option would be to modify the
&gt;&gt;&gt;&gt; Tor-OpenWrt-package to use / as the data directory instead of /tmp.
&gt;&gt;&gt;&gt; However, I wonder if 64M (no matter how it's partitioned) of space on
&gt;&gt;&gt;&gt; the Buffalo router is insufficient as long as #2334 remains open.
&gt;&gt;&gt;
&gt;&gt;&gt; If we're shipping our own image, we can do a bunch of stuff. Is that
&gt;&gt;&gt; what we want to do?
&gt;&gt;
&gt;&gt; I don't think we should ship our own image, for the simple reason that
&gt;&gt; we already have enough stuff to maintain.
&gt;&gt;
&gt;
&gt; I generally agree but I think we're going to have to deal with this
&gt; issue one way or another.
&gt;
&gt; If we're shipping people a router, I'd like to harden it. For example -
&gt; it does not appear that all of the gcc hardening features are enabled by
&gt; default.

Are you talking about hardening Tor or OpenWrt? Or both?

&gt; We can commit to a simple, fixed release cycle for the OS and a constant
&gt; stream of updates for Tor.

Sure, that would work. I believe users will have to re-flash their
routers to install a new image, though. Or maybe there's a nice way to
handle upgrades in OpenWrt?

&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt;&gt;&gt;&gt; interface myself, but development seems to be moving along nicely. I'm
&gt;&gt;&gt;&gt; not sure what the remaining steps are, other than packaging it as
&gt;&gt;&gt;&gt; tor-ui (or similar) for OpenWrt.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; The web interface should go into version control, it should be added to
&gt;&gt;&gt; the tor-alpha package in the OpenWRT svn (that's why I created it), and
&gt;&gt;&gt; it should be used by some people.
&gt;&gt;
&gt;&gt; Ok, do you want to take care of this? That is, putting the web
&gt;&gt; interface into version control and packaging it for OpenWrt.
&gt;
&gt; Not really? :-)
&gt;
&gt; In an ideal world, I think we should make these changes in the tor-alpha
&gt; package. Currently, I'm not familiar with the webui at all.
&gt;
&gt; I'd prefer that someone involved in developing the webui actually built
&gt; a stand alone package.

I've sent Daniel an email asking if he wants to package the GUI.

&gt;&gt;
&gt;&gt;&gt;&gt; #2596: Figure out a better name than "torouter". Andrew thinks we
&gt;&gt;&gt;&gt; should come up with a better name for this project, one that does not
&gt;&gt;&gt;&gt; have "Tor" in the name. Suggestions?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; I think torouter is a perfectly fine name until we actually have a
&gt;&gt;&gt; shipping prototype.
&gt;&gt;
&gt;&gt; Sure, that works too.
&gt;&gt;
&gt;&gt;&gt;&gt; The Torouter project also has some open questions (some are mentioned
&gt;&gt;&gt;&gt; on https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Torouter
&gt;&gt;&gt;&gt; as well):
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; 1. How can we make sure that the version of Tor in OpenWrt is always
&gt;&gt;&gt;&gt; up to date? Should we set up our own OpenWrt repository? Right now,
&gt;&gt;&gt;&gt; the version of Tor in OpenWrt is 0.2.1.26. Also, should we offer
&gt;&gt;&gt;&gt; packages for both stable and unstable?
&gt;&gt;&gt;
&gt;&gt;&gt; I think we should contribute back to OpenWRT (as I've been doing) and
&gt;&gt;&gt; for our router, we should consider adding a feed for the specific
&gt;&gt;&gt; hardware we intend to support. Still, we'll need to ensure the versions
&gt;&gt;&gt; of _everything_ are up to date and not just Tor.
&gt;&gt;&gt;
&gt;&gt;&gt; So what's our general update strategy for any platform we ship?
&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; 2. We want to collect statistics, which means that we need to ship a
&gt;&gt;&gt;&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt;&gt;&gt;&gt; package for OpenWrt. Thoughts?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; There's a tor-geoip package created by the tor package in the OpenWRT
&gt;&gt;&gt; svn repo (from looking at the Makefile).
&gt;&gt;
&gt;&gt; So, it turns out that packages in OpenWrt are not updated after a
&gt;&gt; release. That explains why I got 0.2.1.26 when 0.2.1.30 is available
&gt;&gt; in the OpenWrt SVN.
&gt;&gt;
&gt;
&gt; Makes sense.
&gt;
&gt;&gt; The best way to ensure that users can easily upgrade Tor and related
&gt;&gt; packages is to set up a torproject.org repository for OpenWrt
&gt;&gt; packages. This repository would then have to be added to
&gt;&gt; /etc/opkg.conf.
&gt;
&gt; That's similar to what I said on IRC; it seems reasonable to keep the
&gt; Tor package updated in OpenWRT. We need to decide if we want to build
&gt; regular packages for installation and also if we want to host them. I
&gt; think this is mostly an Erinn question - helix?
&gt;
&gt;&gt;
&gt;&gt;&gt;&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt;&gt;&gt;&gt; wifi network? I think this sounds good, if the router can handle it.
&gt;&gt;&gt;&gt; If not, then just running a bridge is ok too.
&gt;&gt;&gt;
&gt;&gt;&gt; I think we should run both in a single Tor for now but I think we should
&gt;&gt;&gt; only enable the bridge by default. The web UI can enable the transparent
&gt;&gt;&gt; stuff if we want it.
&gt;&gt;
&gt;&gt; Sounds good.
&gt;
&gt; What's the default config that we want to ship?

I was thinking about a config similar to the one in the
bridge-by-default bundle.

&gt;&gt;
&gt;&gt;&gt;&gt; Have I missed anything important? Are there any other packages that we
&gt;&gt;&gt;&gt; should include in OpenWrt? Other comments or suggestions? If you have
&gt;&gt;&gt;&gt; more information or would like to help out, please let me know.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; We need to make packages for the libnatpmp and miniupnpc libraries
&gt;&gt;&gt; because we need tor-fw-helper support in tor-alpha.
&gt;&gt;
&gt;&gt; Is this something you can / want to take care of?
&gt;
&gt; I'm a little more interested in making these packages. Do you want to
&gt; open a set of bugs and we can continue deeper discussion in bugs?

Sure, I can do that.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110421185420</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-04-21 18:54:20-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/21/2011 10:57 AM, Erinn Clark wrote:
&gt; * Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 09:17 -0700]: 
&gt;&gt;&gt; The best way to ensure that users can easily upgrade Tor and related
&gt;&gt;&gt; packages is to set up a torproject.org repository for OpenWrt
&gt;&gt;&gt; packages. This repository would then have to be added to
&gt;&gt;&gt; /etc/opkg.conf.
&gt;&gt;
&gt;&gt; That's similar to what I said on IRC; it seems reasonable to keep the
&gt;&gt; Tor package updated in OpenWRT. We need to decide if we want to build
&gt;&gt; regular packages for installation and also if we want to host them. I
&gt;&gt; think this is mostly an Erinn question
&gt; 
&gt; I'm not sure if this is actually a question for me, since I'm not involved in
&gt; the Tor router stuff and don't currently have any plans to maintain a new
&gt; package. Give me more information about the format of the package and
&gt; repository?
&gt; 

It's a question for what we as a project can handle supporting - when a
new Tor is released, we'll need to build it unless we rely on upstream
builds. Runa and I suggest that we (Tor) may want our own OpenWRT
repository - that by default seems to fall directly on our main build
person, I think.

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110423233252</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-04-23 23:32:52-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

[Attachment #2 (multipart/signed)]


* Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 11:54 -0700]: 
&gt; It's a question for what we as a project can handle supporting - when a
&gt; new Tor is released, we'll need to build it unless we rely on upstream
&gt; builds. Runa and I suggest that we (Tor) may want our own OpenWRT
&gt; repository - that by default seems to fall directly on our main build
&gt; person, I think.

Jake and I discussed this on IRC and the basic summary is that for now we'll
wait and see -- probably longer term we can support maintaining a repository,
if that turns out to be the right route, but my role is going to be mainly
infrastructure related so I can help make sure people are able to do what they
need without blocking on me. 

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110424025518</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-04-24 02:55:18-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/23/2011 04:32 PM, Erinn Clark wrote:
&gt; * Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 11:54 -0700]: 
&gt;&gt; It's a question for what we as a project can handle supporting - when a
&gt;&gt; new Tor is released, we'll need to build it unless we rely on upstream
&gt;&gt; builds. Runa and I suggest that we (Tor) may want our own OpenWRT
&gt;&gt; repository - that by default seems to fall directly on our main build
&gt;&gt; person, I think.
&gt; 
&gt; Jake and I discussed this on IRC and the basic summary is that for now we'll
&gt; wait and see -- probably longer term we can support maintaining a repository,
&gt; if that turns out to be the right route, but my role is going to be mainly
&gt; infrastructure related so I can help make sure people are able to do what they
&gt; need without blocking on me. 

One other important point made in that discussion is that no one seems
to have time for supporting an entirely new platform for every Tor
release. So while The Tor Project may support it - we have no one
willing to bell the cat today.

What this means practically is that as we've seen with Android, we're
going to seriously lag releases as it won't be the responsibility of any
single person or group of people. This won't work if we ship our own OS
(such as a custom OpenWRT image) and it will simply be difficult if
we're just shipping Tor (with or without supporting libraries).

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110424030508</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-04-24 03:05:08-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/23/2011 10:55 PM, Jacob Appelbaum wrote:
&gt; What this means practically is that as we've seen with Android, we're
&gt; going to seriously lag releases as it won't be the responsibility of any
&gt; single person or group of people. 

As a note on this, I think I and/or whoever wants to be responsible for
Android builds, needs to just understand how to get into the workflow
for updating releases with the latest Tor binaries. In addition, it
would be good to understand when a release is optional, vs recommended
vs. absolutely necessary. I don't quite have my head around that yet.

At some point, we had a good flow going b/c Erinn had Android as part of
her critical path of updates to do, and I was regularly pushing new
ready to ship builds, instead of getting sidetracked on unshippable code
to handle esoteric Android issues.

Lastly, I think what we did with 1.0.4 made sense, where we just updated
the Tor binary and not the Android code, smoked test that, then shipped,
made a lot of sense.

+n
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110424081406</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-04-24 08:14:06-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Sun, Apr 24, 2011 at 3:55 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt; On 04/23/2011 04:32 PM, Erinn Clark wrote:
&gt;&gt; * Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 11:54 -0700]:
&gt;&gt;&gt; It's a question for what we as a project can handle supporting - when a
&gt;&gt;&gt; new Tor is released, we'll need to build it unless we rely on upstream
&gt;&gt;&gt; builds. Runa and I suggest that we (Tor) may want our own OpenWRT
&gt;&gt;&gt; repository - that by default seems to fall directly on our main build
&gt;&gt;&gt; person, I think.
&gt;&gt;
&gt;&gt; Jake and I discussed this on IRC and the basic summary is that for now we'll
&gt;&gt; wait and see -- probably longer term we can support maintaining a repository,
&gt;&gt; if that turns out to be the right route, but my role is going to be mainly
&gt;&gt; infrastructure related so I can help make sure people are able to do what they
&gt;&gt; need without blocking on me.
&gt;
&gt; One other important point made in that discussion is that no one seems
&gt; to have time for supporting an entirely new platform for every Tor
&gt; release. So while The Tor Project may support it - we have no one
&gt; willing to bell the cat today.
&gt;
&gt; What this means practically is that as we've seen with Android, we're
&gt; going to seriously lag releases as it won't be the responsibility of any
&gt; single person or group of people. This won't work if we ship our own OS
&gt; (such as a custom OpenWRT image) and it will simply be difficult if
&gt; we're just shipping Tor (with or without supporting libraries).

We already know that we can't rely on upstream builds. If we want to
our users to have the latest version of Tor, we need to set up an okpg
repository ourselves.

Jake; it was my impression that you wanted to do this. Is that not the
case anymore?

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110424102905</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-04-24 10:29:05-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On 04/24/2011 01:14 AM, Runa A. Sandvik wrote:
&gt; On Sun, Apr 24, 2011 at 3:55 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;&gt; On 04/23/2011 04:32 PM, Erinn Clark wrote:
&gt;&gt;&gt; * Jacob Appelbaum &lt;jacob@appelbaum.net&gt; [2011:04:21 11:54 -0700]:
&gt;&gt;&gt;&gt; It's a question for what we as a project can handle supporting - when a
&gt;&gt;&gt;&gt; new Tor is released, we'll need to build it unless we rely on upstream
&gt;&gt;&gt;&gt; builds. Runa and I suggest that we (Tor) may want our own OpenWRT
&gt;&gt;&gt;&gt; repository - that by default seems to fall directly on our main build
&gt;&gt;&gt;&gt; person, I think.
&gt;&gt;&gt;
&gt;&gt;&gt; Jake and I discussed this on IRC and the basic summary is that for now we'll
&gt;&gt;&gt; wait and see -- probably longer term we can support maintaining a repository,
&gt;&gt;&gt; if that turns out to be the right route, but my role is going to be mainly
&gt;&gt;&gt; infrastructure related so I can help make sure people are able to do what they
&gt;&gt;&gt; need without blocking on me.
&gt;&gt;
&gt;&gt; One other important point made in that discussion is that no one seems
&gt;&gt; to have time for supporting an entirely new platform for every Tor
&gt;&gt; release. So while The Tor Project may support it - we have no one
&gt;&gt; willing to bell the cat today.
&gt;&gt;
&gt;&gt; What this means practically is that as we've seen with Android, we're
&gt;&gt; going to seriously lag releases as it won't be the responsibility of any
&gt;&gt; single person or group of people. This won't work if we ship our own OS
&gt;&gt; (such as a custom OpenWRT image) and it will simply be difficult if
&gt;&gt; we're just shipping Tor (with or without supporting libraries).
&gt; 
&gt; We already know that we can't rely on upstream builds. If we want to
&gt; our users to have the latest version of Tor, we need to set up an okpg
&gt; repository ourselves.
&gt; 

I'm of a mixed feeling here - we can easily rely on upstream packaging
work but we need to have a commitment inside of Tor to actually support
a repository, if we need to run our own. It's probably the case that for
rapid development, we'll need to do so. Stuff like x-wrt are a hybrid
example where we may be able to have regular builds of Tor. I haven't
really understood the process by which a package is actually ever
compiled by OpenWRT or x-wrt and then shipped to users; the exception is
when OpenWRT cuts a release...

&gt; Jake; it was my impression that you wanted to do this. Is that not the
&gt; case anymore?

I want a lot of things. After talking with Erinn, I'm a little more
enlightened on build issues. No one will take our work and cut a new Tor
release as part of their work flow unless we somehow allocate resources
or indicate that this is a priority.

With that said - I'm happy to handle packaging of Tor on OpenWRT as I've
been working on already. However, that is not enough - we have to
actually have a task that is going to be done regularly - no matter what
OS or hardware choice we make. Android is a good example, we have
repeatedly dropped the ball for a number of (good and bad) reasons. We
should not repeat those mistakes - one of the biggest was simply that we
did lacked a clear support plan - when a security release for Tor is
tagged, Orbot needs to have at least a new Tor binary in a reasonable
amount of time. We have utterly failed at this in a few cases - we
should avoid re-creating this problem with Torouter.

We're adding a new "product" to The Tor Project - one of the things we
need to do is actually plan for the software maintenance phase of that
product. As it stands, I don't believe we have a build machine (see bug
#2969) that either you (Runa) or I have access to. That makes it hard to
build an OpenWRT image or even have a system where we can co-work on
packages together but also where we trust the compiler for cutting a
release.  Speaking of which, we also lack a plan for actually cutting
releases - for a real beta test, I believe we'll really need to solve
this issue. It's not reasonable to ship the Torouter project without
having a good way forward and that includes a solid commitment from
someone or someones that will ensure Tor builds kick off for each major
or security important release.

All the best,
JAke
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110424233656</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-04-24 23:36:56-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Thu, Apr 21, 2011 at 07:15:17PM +0100, runa.sandvik@gmail.com wrote 7.4K bytes in 195 lines about:
: My mistake. I thought someone had a bridge running and that the only
: problem was disk space. I'll see if I can set up my router as a bridge
: this weekend and get things working.

I did, on the buffalo.  It worked fine with a 1gb usb drive stuck in the
router.

: Sure, that would work. I believe users will have to re-flash their
: routers to install a new image, though. Or maybe there's a nice way to
: handle upgrades in OpenWrt?

99% of users are not going to reflash their router.  If it isn't a point
and click automatic update, it won't happen.  I hate reflashing openwrt
on the buffalo. 

: &gt; That's similar to what I said on IRC; it seems reasonable to keep the
: &gt; Tor package updated in OpenWRT. We need to decide if we want to build
: &gt; regular packages for installation and also if we want to host them. I
: &gt; think this is mostly an Erinn question - helix?

We can barely keep up with the current build load, nevermind adding new
operating systems.  

Torouter based on openwrt is an experiment.  It seems it's going to cost
us more time, effort, and people than we have to spare.  The entire
torouter, or bridge/relay-by-default in hardware, is an experiment.  

I'd much rather see a debian-based torouter exist.  We can more easily
integrate debian packages of the necessary architecture, likely ARM,
into our build farm than we can an entirely new OS and build
environment. 

The openwrt-based torouter can be a community-run and maintained
project.  I'd rather Tor Project spend its time and effort on making tor
work on debian-compatible low-cost hardware, like a dreamplug or excito,
than trying to force tor into a new OS and platform.

-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110425041437</emailId><senderName>Daniel Bryg</senderName><senderEmail>fermenthor@gmail.com</senderEmail><timestampReceived>2011-04-25 04:14:37-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

Sorry for jumping in late, see my comments below.

On Thu, Apr 21, 2011 at 9:26 AM, Jacob Appelbaum &lt;jacob at appelbaum.net&gt; wrote:
&gt; On 04/19/2011 03:17 AM, Runa A. Sandvik wrote:
&gt;&gt; The Torouter project has a total of four bugs in Trac. These are
&gt;&gt; #2334, #2376, #2370 and #2596.
&gt;&gt;
&gt;&gt; #2334: Torouter on Buffalo breaks with large cached-descriptors[.new]
&gt;&gt; files. The quick and easy solution here is to attach a USB stick to
&gt;&gt; the router and use it as Tor's data directory. However, it would be
&gt;&gt; great if someone could take a look at this and figure out a way to
&gt;&gt; solve it.
&gt;
&gt; This is only a problem on smaller hardware - so if we really want the
&gt; Buffalo router, we'll need to fix this or create a work around that
&gt; isn't a total PITA. For now, I think we can just add a USB disk and deal
&gt; with it later.
&gt;
&gt; If we find that the router can't handle being a bridge, I'm not really
&gt; concerned with this bug.

Buffalo with a 1Gb USB flash works as a bridge/client but the bridge
is not very busy so I don't know what the limits are. See my stats
I've just posted to #2334. I don't really see a quick solution that
would work without adding extra storage. Fortunately, the flash drives
can be small and barely visible. But one thing that must be improved
here is formatting it with a usb-friendly filesystem as I'm using ext2
which was the easiest to install.

&gt;&gt; #2376: Torouter on OpenWrt shouldn't have its data directory in /tmp/.
&gt;&gt; The problem with having Tor's data directory in /tmp is that whenever
&gt;&gt; Torouter is rebooted, Tor generates new keys and gets a new
&gt;&gt; fingerprint.
&gt;
&gt; I commented on the bug - it's easy enough to change this by submitting a
&gt; patch to openwrt-devel at lists.openwrt.org

I believe the only files that can stay unchanged over router's
lifetime is secret_id_key in (the fingerprint file is recalculated
from it on each start). In my patch I moved this one file to /etc/tor.
Should I be worried about getting new descriptors on each reboot which
hopefully happens only once every few weeks?

&gt;&gt; #2370: Torouter basic Web UI for OpenWrt. I haven't tried the web
&gt;&gt; interface myself, but development seems to be moving along nicely. I'm
&gt;&gt; not sure what the remaining steps are, other than packaging it as
&gt;&gt; tor-ui (or similar) for OpenWrt.
&gt;&gt;
&gt;
&gt; The web interface should go into version control, it should be added to
&gt; the tor-alpha package in the OpenWRT svn (that's why I created it), and
&gt; it should be used by some people.

I can package it that way and then you can submit. As discussed in
#2370, I'm of opinion that once we have a mature release, the UI
should be made into a separate package. Vidalia is separate on other
linux systems, and this situation is similar. Maybe the Luci guys
should express themselves on that as i think they maintain all of the
UI code, but i may be wrong.

&gt;&gt; #2596: Figure out a better name than "torouter". Andrew thinks we
&gt;&gt; should come up with a better name for this project, one that does not
&gt;&gt; have "Tor" in the name. Suggestions?
&gt;&gt;
&gt;
&gt; I think torouter is a perfectly fine name until we actually have a
&gt; shipping prototype.

I agree but if you want something corny: RoutOr - there's no Tor in it ;)

&gt;&gt; 2. We want to collect statistics, which means that we need to ship a
&gt;&gt; GeoIP file as well. I'm thinking we should create a tor-geoipdb
&gt;&gt; package for OpenWrt. Thoughts?
&gt;
&gt; There's a tor-geoip package created by the tor package in the OpenWRT
&gt; svn repo (from looking at the Makefile).

If we're including the UI in the package, and the UI uses geoip should
we include geoipdb as well?

&gt;&gt; 3. Do we want one Tor process for bridging and one for the transparent
&gt;&gt; wifi network? I think this sounds good, if the router can handle it.
&gt;&gt; If not, then just running a bridge is ok too.
&gt;
&gt; I think we should run both in a single Tor for now but I think we should
&gt; only enable the bridge by default. The web UI can enable the transparent
&gt; stuff if we want it.

My current package enables both by default. Easy to change.

&gt;&gt; Have I missed anything important? Are there any other packages that we
&gt;&gt; should include in OpenWrt? Other comments or suggestions? If you have
&gt;&gt; more information or would like to help out, please let me know.

There are a few things there that I'm not entirely happy and I am
planning to work on them. The config situation should be clarified,
for example. I'll get back to you on this.

All in all, I know I'll be working on this project so I can take the
responsibility of creating packages once it's been decided what goes
in to what repo and such. I could probably help with a build machine,
too.

Cheers,
Daniel
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110405022235</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-05 02:22:35-0400</timestampReceived><subject>Re: [tor-dev] GSoC - Torbutton for Thunderbird</subject><body>

On Mon, Apr 4, 2011 at 3:06 AM, Sukhbir Singh &lt;sukhbir.in@gmail.com&gt; wrote:
&gt; Hi!
&gt;
&gt; I am interested in participating in Google's Summer of Code this year
&gt; and implementing the Torbutton equivalent for Thunderbird [0].
&gt;
&gt; I have been discussing the project with Mike Perry and we feel that it
&gt; is possible to implement this. The first step was removing the
&gt; hostname Thunderbird puts in the outgoing message header, which we
&gt; easily fixed. That gave us the initial motivation to pursue this
&gt; further.
&gt;
&gt; There are a number of issue that still remain, however we feel that
&gt; those can be easily worked out. We have put all probable solutions to
&gt; Torbutton requirements from [1] in the attachment with this mail and
&gt; are looking for your suggestions/ comments about this.
&gt;
&gt; We have not submitted an application for this to Google yet; I intend
&gt; to do that after gauging the response towards this proposal from the
&gt; mailing list.

Hi!  Plenty of people have wanted a good mail client for use with Tor;
this would be a fine thing to build.

Our application template is at
https://www.torproject.org/about/gsoc.html.en#Template -- of the
things it asks for, a couple of the most important are trying to
figure out what your work plan is in as much detail as possible, and
making sure that you include good coding samples to let the
organization know what you can do.

Please let us know if you've got any specific questions that we can answer.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110413235243</emailId><senderName>Tomas Touceda</senderName><senderEmail>chiiph@gentoo.org</senderEmail><timestampReceived>2011-04-13 23:52:43-0400</timestampReceived><subject>Re: [tor-dev] [tor-commits] r24618: {website} Update Vidalia's</subject><body>

On 22:10 Wed 13 Apr     , Fabian Keil wrote:
&gt; Tomas Touceda &lt;chiiph@gentoo.org&gt; wrote:
&gt; 
&gt; &gt; Author: chiiph
&gt; &gt; Date: 2011-04-13 19:55:14 +0000 (Wed, 13 Apr 2011)
&gt; &gt; New Revision: 24618
&gt; &gt; 
&gt; &gt; Modified:
&gt; &gt;    website/trunk/projects/en/vidalia.wml
&gt; &gt; Log:
&gt; &gt; Update Vidalia's project page
&gt; &gt; 
&gt; &gt; Modified: website/trunk/projects/en/vidalia.wml
&gt; &gt; ===================================================================
&gt; &gt; --- website/trunk/projects/en/vidalia.wml	2011-04-13 18:58:21 UTC (rev 24617)
&gt; &gt; +++ website/trunk/projects/en/vidalia.wml	2011-04-13 19:55:14 UTC (rev 24618)
&gt; &gt; @@ -55,26 +55,26 @@
&gt; 
&gt; &gt; -         &lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; -        (&lt;a href="../dist/vidalia/vidalia-0.2.10.tar.gz.asc"&gt;sig&lt;/a&gt;)
&gt; &gt; +         &lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz"&gt;Source Tarball&lt;/a&gt;
&gt; &gt; +        (&lt;a href="../dist/vidalia/vidalia-0.2.12.tar.gz.sig"&gt;sig&lt;/a&gt;)
&gt; &gt;        &lt;/li&gt;
&gt; 
&gt; I'm having trouble locating the new signing key. Any pointers?
&gt; Thanks.
&gt; 
&gt; Fabian

http://dev.gentoo.org/~chiiph/chiiph.asc

Cheers,
-- 
Tomas Touceda
Gentoo Developer - Qt, Scheme, Lisp
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110407211005</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 21:10:05-0400</timestampReceived><subject>Re: [tor-dev] [Patch] src/test.c</subject><body>

On Thu, Apr 7, 2011 at 3:48 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; I don't think it's a good idea to use hard-coded paths. Even in a
&gt; test source-file. Easy patch:
&gt;
&gt; --- Git-latest\src\test\test.c       Wed Mar 30 11:58:28 2011
&gt; +++ src\test\test.c  Thu Mar 31 14:06:14 2011
&gt; @@ -86,7 +86,7 @@
&gt; #ifdef MS_WINDOWS
&gt;  // XXXX
&gt;  tor_snprintf(temp_dir, sizeof(temp_dir),
&gt; -               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
&gt; +               "%s\\tor_test_%d", getenv("TEMP"), (int)getpid());
&gt;  r = mkdir(temp_dir);
&gt; #else
&gt;  tor_snprintf(temp_dir, sizeof(temp_dir), "/tmp/tor_test_%d", (int)
&gt; getpid());

What guarantees that TEMP will always be defined?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110407211739</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-04-07 21:17:39-0400</timestampReceived><subject>Re: [tor-dev] [Patch] src/test.c</subject><body>

On Thu, Apr 07, 2011 at 05:10:05PM -0400, Nick Mathewson wrote:
&gt; On Thu, Apr 7, 2011 at 3:48 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; &gt; -               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
&gt; &gt; +               "%s\\tor_test_%d", getenv("TEMP"), (int)getpid());
&gt; 
&gt; What guarantees that TEMP will always be defined?

A Windows (or DOS) system with %TEMP% undefined can reasonably be
expected to not work properly. On the other hand, a Windows system
which doesn't have a C: drive should work correctly. We could be a bit
defensive and if %TEMP% isn't defined, fall back on C:\WINDOWS\TEMP?

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110407213247</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-04-07 21:32:47-0400</timestampReceived><subject>Re: [tor-dev] [Patch] src/test.c</subject><body>

On Thu, Apr 7, 2011 at 5:17 PM, Steven J. Murdoch
&lt;tor+Steven.Murdoch@cl.cam.ac.uk&gt; wrote:
&gt; On Thu, Apr 07, 2011 at 05:10:05PM -0400, Nick Mathewson wrote:
&gt;&gt; On Thu, Apr 7, 2011 at 3:48 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt;&gt; &gt; -               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
&gt;&gt; &gt; +               "%s\\tor_test_%d", getenv("TEMP"), (int)getpid());
&gt;&gt;
&gt;&gt; What guarantees that TEMP will always be defined?
&gt;
&gt; A Windows (or DOS) system with %TEMP% undefined can reasonably be
&gt; expected to not work properly. On the other hand, a Windows system
&gt; which doesn't have a C: drive should work correctly. We could be a bit
&gt; defensive and if %TEMP% isn't defined, fall back on C:\WINDOWS\TEMP?

Sounds fine to me.  Alternatively, I believe we could just call
GetTempPath(): that's what it's there for.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110407222644</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-04-07 22:26:44-0400</timestampReceived><subject>Re: [tor-dev] [Patch] src/test.c</subject><body>

"Nick Mathewson" &lt;nickm@freehaven.net&gt; wrote:

&gt; Sounds fine to me.  Alternatively, I believe we could just call
&gt; GetTempPath(): that's what it's there for.

Agreed. I first thought of using GetTempPath() but that involves another 
buffer and checking the ret-val. It's safes though. From:
http://msdn.microsoft.com/en-us/library/aa364992(v=vs.85).aspx

The GetTempPath function checks for the existence of environment 
variables in the following order and uses the first path found:
  1.. The path specified by the TMP environment variable.
  2.. The path specified by the TEMP environment variable.
  3.. The path specified by the USERPROFILE environment variable.
  4.. The Windows directory.

Another patch for this:

--- ../../Git-latest/src/test/test.c    2011-03-30 08:58:28 -0100
+++ test.c      2011-04-07 21:25:51 -0100
@@ -85,9 +85,15 @@

 #ifdef MS_WINDOWS
   // XXXX
-  tor_snprintf(temp_dir, sizeof(temp_dir),
-               "c:\\windows\\temp\\tor_test_%d", (int)getpid());
-  r = mkdir(temp_dir);
+  {
+    char buf[MAX_PATH], *tmp = buf;
+    /* If this fails, we're probably screwed anyway */
+    if (!GetTempPath(sizeof(buf),buf))
+      tmp = "c:\\windows\\temp";
+    tor_snprintf(temp_dir, sizeof(temp_dir),
+                 "%s\\tor_test_%d", tmp, (int)getpid());
+    r = mkdir(temp_dir);
+  }
 #else
   tor_snprintf(temp_dir, sizeof(temp_dir), "/tmp/tor_test_%d", (int) getpid());
   r = mkdir(temp_dir, 0700);

--------------

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110416102405</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-04-16 10:24:05-0400</timestampReceived><subject>[tor-dev] Orbot's inclusion of Privoxy (was: [tor-commits] r24630:</subject><body>

[Attachment #2 (multipart/signed)]


Nathan Freitas &lt;nathan@freitas.net&gt; wrote:

&gt; Author: n8fr8
&gt; Date: 2011-04-15 16:38:53 +0000 (Fri, 15 Apr 2011)
&gt; New Revision: 24630

&gt; Log:
&gt; adding binaries to res/raw folder

&gt; ___________________________________________________________________
&gt; Added: svn:mime-type
&gt;    + application/octet-stream
&gt; 
&gt; Added: projects/android/trunk/Orbot/res/raw/privoxy
&gt; ===================================================================
&gt; (Binary files differ)

This seems to be (or based on) Privoxy 3.0.12 released in 2009.
What's the rationale for not using a more recent version?

Is this vanilla Privoxy or are there any custom patches?

I get the impression that you are currently distributing the
Privoxy binary as part of Orbot without even mentioning the
license. Is that correct, or am I missing something?

&gt; Property changes on: projects/android/trunk/Orbot/res/raw/privoxy
&gt; ___________________________________________________________________
&gt; Added: svn:executable
&gt;    + *
&gt; Added: svn:mime-type
&gt;    + application/octet-stream
&gt; 
&gt; Added: projects/android/trunk/Orbot/res/raw/privoxy_config
&gt; ===================================================================
&gt; --- projects/android/trunk/Orbot/res/raw/privoxy_config	                        (rev 0)
&gt; +++ projects/android/trunk/Orbot/res/raw/privoxy_config	2011-04-15 16:38:53 UTC (rev 24630)
&gt; @@ -0,0 +1,27 @@
&gt; +# Generally, this file goes in /etc/privoxy/config
&gt; +#
&gt; +# Tor listens as a SOCKS4a proxy here:
&gt; +forward-socks4a / 127.0.0.1:9050 .

Privoxy 3.0.12 already supports SOCKS5 which allows
superior error messages in case of connection failures.

Note that this requires the templates to be available
and according to
https://trac.torproject.org/projects/tor/ticket/2168
at least some of them aren't.

&gt; +confdir /data/data/org.torproject.android
&gt; +logdir /data/data/org.torproject.android
&gt; +# actionsfile standard  # Internal purpose, recommended
&gt; +#actionsfile default.action   # Main actions file
&gt; +#actionsfile user.action      # User customizations
&gt; +#filterfile default.filter
&gt; +
&gt; +# Don't log interesting things, only startup messages, warnings and errors
&gt; +#logfile logfile
&gt; +#jarfile jarfile

FEATURE_COOKIE_JAR shouldn't be supported in the
vanilla 3.0.12 release. It has been removed in 3.0.11
due to being useless.

&gt; +#debug 1
&gt; +#debug   0    # show each GET/POST/CONNECT request

debug 0 has no effect.

&gt; +#debug   4096 # Startup banner and warnings
&gt; +#debug   8192 # Errors - *we highly recommended enabling this*
&gt; +
&gt; +#user-manual /usr/share/doc/privoxy/user-manual
&gt; +listen-address  127.0.0.1:8118
&gt; +toggle  1
&gt; +accept-intercepted-requests 1

Are the iptables rules used documented somewhere?

Did you run into any issues with Privoxy on Android
in general?

Are the considerations that lead to the use of Privoxy
documented somewhere?

Thanks
Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110417194033</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-04-17 19:40:33-0400</timestampReceived><subject>Re: [tor-dev] Orbot's inclusion of Privoxy</subject><body>

[Attachment #2 (multipart/signed)]


Nathan Freitas &lt;nathan@freitas.net&gt; wrote:

&gt; On 04/16/2011 06:24 AM, Fabian Keil wrote:
&gt; &gt; This seems to be (or based on) Privoxy 3.0.12 released in 2009.
&gt; &gt; What's the rationale for not using a more recent version?
&gt; 
&gt; At this point, that is the latest version we have successfully
&gt; cross-compiled for Android. We are working on updating our build process
&gt; to the new Android Native Dev Kit cross-compiler, and updating all
&gt; relevant components.
&gt; 
&gt; I will admit that our focus on keep bundled versions current have been
&gt; more focused on Tor, than on Privoxy. I will make sure that we keep as
&gt; close tabs on that component, as well.

Great. Please let me know if you run into any issues.

&gt; We have not included the binary files in the repo historically. However,
&gt; there have been a number of Android app/UI developers who wished to
&gt; contribute code there, but were unable to setup the entire OS build
&gt; chain on their Mac or Windows machines, that is required to build the C
&gt; binaries. If we provide them pre-built binaries for dev purposes, it
&gt; increases the likelihood we will have more contributors.

Makes sense.
 
&gt; &gt; Is this vanilla Privoxy or are there any custom patches?
&gt; 
&gt; It is vanilla, save for one setting:
&gt; export ac_cv_func_setpgrp_void=yes
&gt; 
&gt; as documented here:
&gt; https://svn.torproject.org/svn/projects/android/trunk/Orbot/BUILD

Interesting. I see that you aren't copying the template
files Privoxy uses for the CGI messages. Is this intentional
because of space constraints or just an oversight?

&gt; &gt; I get the impression that you are currently distributing the
&gt; &gt; Privoxy binary as part of Orbot without even mentioning the
&gt; &gt; license. Is that correct, or am I missing something?
&gt; 
&gt; We mention the inclusion in our app About screen, but you are current
&gt; that our inclusion is not mentioned in the license file or screens. This
&gt; is an unfortunate oversight, that I will address today.

Thanks.

Fabian

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110420145231</emailId><senderName>tagnaq</senderName><senderEmail>tagnaq@gmail.com</senderEmail><timestampReceived>2011-04-20 14:52:31-0400</timestampReceived><subject>[tor-dev]  GSoC - Torbutton for Thunderbird</subject><body>

Hi,

this is a reply to:
https://lists.torproject.org/pipermail/tor-dev/2011-April/002551.html
(I was not on the list at that point in time.)

I wanted to let you know that I'm also researching in this area, but my
goal is not to build an extension and I'm not involved in GsoC.

I'm looking into issues that would negatively
affect the pseudonymous use of Thunderbird with Tor.
(Application level concerns when using Thunderbird with Tor)
As a side effect I'm also playing around with Thunderbird/Lanikai.

The outcome of my research (~08/2011) is hopefully useful to those
actually implementing stuff.

best regards,
tagnaq
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110425050725</emailId><senderName>Daniel Bryg</senderName><senderEmail>fermenthor@gmail.com</senderEmail><timestampReceived>2011-04-25 05:07:25-0400</timestampReceived><subject>Re: [tor-dev] The Torouter project - where are we now?</subject><body>

On Sun, Apr 24, 2011 at 11:36 PM,  &lt;andrew@torproject.org&gt; wrote:
&gt; On Thu, Apr 21, 2011 at 07:15:17PM +0100, runa.sandvik@gmail.com wrote 7.4K bytes in 195 lines about:
&gt; : My mistake. I thought someone had a bridge running and that the only
&gt; : problem was disk space. I'll see if I can set up my router as a bridge
&gt; : this weekend and get things working.
&gt;
&gt; I did, on the buffalo.  It worked fine with a 1gb usb drive stuck in the
&gt; router.
&gt;
&gt; : Sure, that would work. I believe users will have to re-flash their
&gt; : routers to install a new image, though. Or maybe there's a nice way to
&gt; : handle upgrades in OpenWrt?
&gt;
&gt; 99% of users are not going to reflash their router.  If it isn't a point
&gt; and click automatic update, it won't happen.  I hate reflashing openwrt
&gt; on the buffalo.

The most user-friendly way now is to upload an upgrade image via UI.
It shouldn't be very difficult to make LuCI download the image from a
website automatically.

&gt;
&gt; : &gt; That's similar to what I said on IRC; it seems reasonable to keep the
&gt; : &gt; Tor package updated in OpenWRT. We need to decide if we want to build
&gt; : &gt; regular packages for installation and also if we want to host them. I
&gt; : &gt; think this is mostly an Erinn question - helix?
&gt;
&gt; We can barely keep up with the current build load, nevermind adding new
&gt; operating systems.
&gt;
&gt; Torouter based on openwrt is an experiment.  It seems it's going to cost
&gt; us more time, effort, and people than we have to spare.  The entire
&gt; torouter, or bridge/relay-by-default in hardware, is an experiment.
&gt;
&gt; I'd much rather see a debian-based torouter exist.  We can more easily
&gt; integrate debian packages of the necessary architecture, likely ARM,
&gt; into our build farm than we can an entirely new OS and build
&gt; environment.
&gt;
&gt; The openwrt-based torouter can be a community-run and maintained
&gt; project.  I'd rather Tor Project spend its time and effort on making tor
&gt; work on debian-compatible low-cost hardware, like a dreamplug or excito,
&gt; than trying to force tor into a new OS and platform.

I understand that, if you're trying to provide Tor on a router as a
packaged product, it would certainly be better to have one that can
handle it well without hardware modifications. And apparently we
haven't seen it with OpenWRT. But i hope that someone will help make
Tor run better and friendlier on OpenWRT as it's probably the most
popular system on home routers that people actually use with Tor and
it would be of benefit to everybody to convert many of these clients
into stable bridges.

Daniel.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110428032708</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-04-28 03:27:08-0400</timestampReceived><subject>Re: [tor-dev] Fwd: Re: [guardian-dev] ORBot Alpha, some candles,</subject><body>

[Attachment #2 (multipart/signed)]


This is great stuff. One of the things that would be interesting
future work is how safe are the protocols to use over tor in terms of
cleartext exposure to exit nodes. I thought all of the google apps on
the phone were using SSL, and it surprises greatly me to learn that
the app market uses cleartext in any way.

Is that all market activity, or just some API calls? Can exit nodes
(or open wifi access points) give you altered apps, for example? Or
simply delay critical updates by breaking connections because they can
see you are trying to update from a vulnerable version of a particular
app? This seems like a huge nightmare...


Thus spake Nathan Freitas (nathan@freitas.net):

&gt; Fantastic, Manuel. Looks like we are going to need some wine over to
&gt; patch this up. This type of look at how our transproxy all rules are
&gt; working (or not) is long overdue. I really appreciate your effort.
&gt; 
&gt; The first thing that comes to mind is that we are setting up the
&gt; iptables rules on an app-by-app basis, using the list of user IDs we are
&gt; provided by Android API calls. It is quite possible that certain
&gt; subsystems are not represented in that list.
&gt; 
&gt; There may be a better way to implement the transproxy all implementation
&gt; that is more of a "everything but tor" approach.
&gt; 
&gt; Our transproxy configuration is based on the approach outlined here:
&gt; https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TransparentProxy
&gt; 
&gt; We'll have to go through additional recommended configurations that we
&gt; are not addressing in our current "all" setup, and see if they address
&gt; the leakage you have found.
&gt; 
&gt; Best,
&gt; Nathan
&gt; 
&gt; On 04/27/2011 12:40 PM, Manuel wrote:
&gt; &gt; Hi all!
&gt; &gt; 
&gt; &gt; Mini-intro: Hi, I'm Manuel (aka __sporkbomb), infosec researcher from
&gt; &gt; Austria, got bored and asked Nathan if he wanted help with ORBot ;)
&gt; &gt; 
&gt; &gt; Setup: Simply an open AP, a Desire HD running CM 7.0.2 and
&gt; &gt; 0.2.2.22-orbot-alpha-1.0.5.20110417a-dev plus airodump.
&gt; &gt; 
&gt; &gt; Methodology: The dump was started after the tor connection (and full
&gt; &gt; transproxying) was established in order to reduce false positives. Total
&gt; &gt; dump length is around 3h15m, around 57MB of data. Of course the phone
&gt; &gt; was left idle for a quite a while, also to ensure that it didn't do
&gt; &gt; nasty untorified stuff when waking up to check mails. Afterwards, I used
&gt; &gt; Wireshark's 'Endpoints' statistics function to determine all TCP
&gt; &gt; endpoints in the dump[0] and awk'd &amp; uniq'd the IPs out of it[1]. As the
&gt; &gt; next step, I determined which of these IPs was in my cached-consensus[2]
&gt; &gt; (somewhat ill-advised, because I compared with my laptop's
&gt; &gt; cached-consensus rather than the phone's, causing two false positives
&gt; &gt; [false non-tor nodes] that actually were nodes). I also ran a reverse
&gt; &gt; lookup on all IPs [3]. As the last step, I went through all
&gt; &gt; communication with IPs that were not found in cached-consensus[4].
&gt; &gt; 
&gt; &gt; You can find links to most of the files I produced at the end of this
&gt; &gt; mail, excluding the dump, which I can provide if requested, but would
&gt; &gt; rather not hand out publicly (mostly because of the size).
&gt; &gt; 
&gt; &gt; All in all, the phone connected to 88 IPs during that time. 37 of those
&gt; &gt; were not contained in the laptop's cached-consensus, two of which were
&gt; &gt; actually legitimate nodes (according to metrics.torproject.org) that
&gt; &gt; just went down throughout the duration of the test, leaving us with 35
&gt; &gt; non-Tor IPs. They can be categorized as follows:
&gt; &gt; 
&gt; &gt; - 27 of those nodes had no other communication than multiple TCP
&gt; &gt; packets, sometimes from a few different source ports (i.e. different TCP
&gt; &gt; connections), all originating from the phone and having FIN+PSH+ACK set.
&gt; &gt; (PSH is the 'push flag', which requests that this data bypass buffers
&gt; &gt; and be handed directly to the application)
&gt; &gt; 
&gt; &gt; - 4 existing connections that still transmitted data; one even contained
&gt; &gt; Market HTTP (cleartext) API requests.
&gt; &gt; 
&gt; &gt; - 4 were completely unencrypted and newly established connections to
&gt; &gt; YouTube or Revision3 video servers. This one is rather bad - it seems
&gt; &gt; that the video player subsystem of Android ignores the proxy setting and
&gt; &gt; leaks everything, including DNS. I also mentioned this yesterday on
&gt; &gt; Twitter, but didn't want to post it yet without confirmation, but it's
&gt; &gt; definitely reproducible on my end.
&gt; &gt; 
&gt; &gt; --------------------
&gt; &gt; Sumup of this part: Generally solid performance, but already established
&gt; &gt; connections might pose a threat (a minor one I'd guess, however...unless
&gt; &gt; one of you can think of a scenario where that causes Bad Things to
&gt; &gt; happen?). Additionally, the video player completely ignores the proxy
&gt; &gt; setting and communicates untorified. While video streaming isn't a
&gt; &gt; strong point of Tor anyway, it's still not good...does anyone have good
&gt; &gt; contact to CyanogenMod people and can ask about that one?
&gt; &gt; 
&gt; &gt; Various tidbits of slight UX annoyances plus a few suggestions:
&gt; &gt; - ORBot ignores the "Transparent proxy" setting when connecting, I
&gt; &gt; always have to enter the Settings menu, untick and re-tick "Transparent
&gt; &gt; proxying" and press back to actually cause it to be enabled.
&gt; &gt; - Related to this: Is it possible to colour-code the "Transparent
&gt; &gt; proxying {DIS,EN}ABLED" notification? The bug above might have serious
&gt; &gt; consequences, because if someone doesn't visit check.torproject.org to
&gt; &gt; assure that he/she is actually torified, chances are that he/she will
&gt; &gt; browse in clear. DISABLED and ENABLED are only three characters away
&gt; &gt; from each other, whereas a red vs green notification would probably
&gt; &gt; catch the eye.
&gt; &gt; - Install fails when installing/uncompressing tor binary
&gt; &gt; https://trac.torproject.org/projects/tor/ticket/2989 [turns out that
&gt; &gt; this is only a bug on Android&lt;2.3, but still...see comment #1 for more
&gt; &gt; details]
&gt; &gt; - Blank semi-permanent status box
&gt; &gt; https://trac.torproject.org/projects/tor/ticket/2993 [haven't updated
&gt; &gt; this one yet; the bug actually occured only before the first reboot for
&gt; &gt; me, and one time afterwards when I had b0rked the network badly]
&gt; &gt; - ORBot vs DroidWall: Starts with 'You don't preserve my chains like you
&gt; &gt; used to :(' and ends with, if I remember correctly, ORBot flushing
&gt; &gt; iptables rules. I'll have a look at that one tomorrow (or is there
&gt; &gt; already some data on it?).
&gt; &gt; 
&gt; &gt; For now, have a nice evening!
&gt; &gt; 
&gt; &gt; Cheers,
&gt; &gt; 
&gt; &gt; __sporkbomb
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; [0] http://sporkbomb.eu/orbot/endpoints
&gt; &gt; [1] http://sporkbomb.eu/orbot/ips
&gt; &gt; [2] http://sporkbomb.eu/orbot/inconsensus (result of a grep -c - IPs
&gt; &gt; with '0' in the second field are not contained in the consensus)
&gt; &gt; [3] http://sporkbomb.eu/orbot/dig-result
&gt; &gt; [4] http://sporkbomb.eu/orbot/not-inconsensus.notes
&gt; &gt; _______________________________________________
&gt; &gt; Guardian-dev mailing list
&gt; &gt; 
&gt; &gt; Post: Guardian-dev@lists.mayfirst.org
&gt; &gt; List info: https://lists.mayfirst.org/mailman/listinfo/guardian-dev
&gt; &gt; 
&gt; &gt; To Unsubscribe
&gt; &gt; Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
&gt; &gt; Or visit: https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info
&gt; &gt;  
&gt; &gt; You are subscribed as: nathan@guardianproject.info
&gt; 
&gt; _______________________________________________
&gt; Guardian-dev mailing list
&gt; 
&gt; Post: Guardian-dev@lists.mayfirst.org
&gt; List info: https://lists.mayfirst.org/mailman/listinfo/guardian-dev
&gt; 
&gt; To Unsubscribe
&gt; Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
&gt; Or visit:
&gt; https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info
&gt;  
&gt; You are subscribed as: nathan@guardianproject.info
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs


[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110428122953</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-04-28 12:29:53-0400</timestampReceived><subject>[tor-dev] Mingw ann non-autoconf build</subject><body>

I have a question regarding src/win32/orconfig.h. I guess this hand-
edited file is supposed to be used by MSVC (targeting Win32, WinCE and
whatnot). Or? What prevents it from being used by e.g. MingW in a non-
autoconf build? 

If someone (like me that doesn't want to touch autotool with a ten-feet
pole) want to use this file unchanged, things like:
  #undef HAVE_SYS_TIME_H

has to be treated specifically for MingW. E.g.:
  #ifndef __MINGW32__
  #undef HAVE_SYS_TIME_H
  #endif

Same goes for HAVE_UNISTD_H, HAVE_GETTTIMEOFDAY etc.

BTW. Older MingW does not have gettimeofday(). I'm not sure
when the function was added. So to be perfect, an "#ifndef" test 
should consider the __MINGW32_VERSION too.

--gv

For every credibility gap, there is a gullibility fill.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110428210804</emailId><senderName>"nathanfreitas () gmail ! com"</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-04-28 21:08:04-0400</timestampReceived><subject>[tor-dev] In SF tonight</subject><body>

[Attachment #2 (multipart/alternative)]


Got some time this evening if anyone wants or can meet up to hang and talk Tor and \
Android.

+n8fr8
7185697272
-- 
Sent from my Guardian-powered Android phone with K-9 Mail. Please excuse my brevity.

Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

This is great stuff. One of the things that would be interesting future work is how \
safe are the protocols to use over tor in terms of cleartext exposure to exit nodes. \
I thought all of the google apps on the phone were using SSL, and it surprises \
greatly me to learn that the app market uses cleartext in any way. Is that all market \
activity, or just some API calls? Can exit nodes (or open wifi access points) give \
you altered apps, for example? Or simply delay critical updates by breaking \
connections because they can see you are trying to update from a vulnerable version \
of a particular app? This seems like a huge nightmare... Thus spake Nathan Freitas \
(nathan@freitas.net): &gt; Fantastic, Manuel. Looks like we are going to need some wine \
over to &gt; patch this up. This type of look at how our transproxy all rules are &gt; \
working (or not) is long overdue. I really appreciate your effort. &gt; &gt; The first \
thing that comes to mind is that we are setting up the &gt; iptables rules on an app-b  \
y-app basis, using the list of user IDs we are &gt; provided by Android API calls. It is \
quite possible that certain &gt; subsystems are not represented in that list. &gt; &gt; There \
may be a better way to implement the transproxy all implementation &gt; that is more of \
a "everything but tor" approach. &gt; &gt; Our transproxy configuration is based on the \
approach outlined here: &gt; \
https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TransparentProxy &gt; &gt; \
We'll have to go through additional recommended configurations that we &gt; are not \
addressing in our current "all" setup, and see if they address &gt; the leakage you have \
found. &gt; &gt; Best, &gt; Nathan &gt; &gt; On 04/27/2011 12:40 PM, Manuel wrote: &gt; &gt; Hi all! &gt; &gt; &gt; \
&gt; Mini-intro: Hi, I'm Manuel (aka __sporkbomb), infosec researcher from &gt; &gt; Austria, \
&gt; got bored and asked Nathan if he wanted help with ORBot ;) &gt; &gt; &gt; &gt; Setup: Simply an \
&gt; open AP, a Desire HD running CM 7.0.2 and &gt; &gt; \
&gt; 0.2.2.22-orbot-alpha-1.0.5.20110417a-dev plus airodump. &gt; &gt; &gt; &gt; Methodology: The d
 ump was
started after the tor connection (and full &gt; &gt; transproxying) was established in \
order to reduce false positives. Total &gt; &gt; dump length is around 3h15m, around 57MB \
of data. Of course the phone &gt; &gt; was left idle for a quite a while, also to ensure \
that it didn't do &gt; &gt; nasty untorified stuff when waking up to check mails. \
Afterwards, I used &gt; &gt; Wireshark's 'Endpoints' statistics function to determine all \
TCP &gt; &gt; endpoints in the dump[0] and awk'd &amp; uniq'd the IPs out of it[1]. As the &gt; &gt; \
next step, I determined which of these IPs was in my cached-consensus[2] &gt; &gt; \
(somewhat ill-advised, because I compared with my laptop's &gt; &gt; cached-consensus \
rather than the phone's, causing two false positives &gt; &gt; [false non-tor nodes] that \
actually were nodes). I also ran a reverse &gt; &gt; lookup on all IPs [3]. As the last \
step, I went through all &gt; &gt; communication with IPs that were not found in \
cached-consensus[4]. &gt; &gt; &gt; &gt; You can find links to most of the files I produced at \
the end of this   &gt; &gt;
mail, excluding the dump, which I can provide if requested, but would &gt; &gt; rather not \
hand out publicly (mostly because of the size). &gt; &gt; &gt; &gt; All in all, the phone \
connected to 88 IPs during that time. 37 of those &gt; &gt; were not contained in the \
laptop's cached-consensus, two of which were &gt; &gt; actually legitimate nodes (according \
to metrics.torproject.org) that &gt; &gt; just went down throughout the duration of the \
test, leaving us with 35 &gt; &gt; non-Tor IPs. They can be categorized as follows: &gt; &gt; &gt; &gt; \
- 27 of those nodes had no other communication than multiple TCP &gt; &gt; packets, \
sometimes from a few different source ports (i.e. different TCP &gt; &gt; connections), all \
originating from the phone and having FIN+PSH+ACK set. &gt; &gt; (PSH is the 'push flag', \
which requests that this data bypass buffers &gt; &gt; and be handed directly to the \
application) &gt; &gt; &gt; &gt; - 4 existing connections that still transmitted data; one even \
contained &gt; &gt; Market HTTP (cleartext) API requests. &gt; &gt; &gt; &gt; - 4 were completely \
unencrypted and newly established connections to &gt; &gt; YouTube or Revision3 video \
servers. This one is rather bad - it seems &gt; &gt; that the video player subsystem of \
Android ignores the proxy setting and &gt; &gt; leaks everything, including DNS. I also \
mentioned this yesterday on &gt; &gt; Twitter, but didn't want to post it yet without \
confirmation, but it's &gt; &gt; definitely reproducible on my end. &gt; &gt; &gt; &gt; \
-------------------- &gt; &gt; Sumup of this part: Generally solid performance, but already \
established &gt; &gt; connections might pose a threat (a minor one I'd guess, \
however...unless &gt; &gt; one of you can think of a scenario where that causes Bad Things \
to &gt; &gt; happen?). Additionally, the video player completely ignores the proxy &gt; &gt; \
setting and communicates untorified. While video streaming isn't a &gt; &gt; strong point \
of Tor anyway, it's still not good...does anyone have good &gt; &gt; contact to CyanogenMod \
people and can ask about that one? &gt; &gt; &gt; &gt; Various tidbits of slight UX annoyances \
plus a few suggesti  ons: &gt;
&gt; - ORBot ignores the "Transparent proxy" setting when connecting, I &gt; &gt; always have \
&gt; to enter the Settings menu, untick and re-tick "Transparent &gt; &gt; proxying" and press \
&gt; back to actually cause it to be enabled. &gt; &gt; - Related to this: Is it possible to \
&gt; colour-code the "Transparent &gt; &gt; proxying {DIS,EN}ABLED" notification? The bug \
&gt; above might have serious &gt; &gt; consequences, because if someone doesn't visit \
&gt; check.torproject.org to &gt; &gt; assure that he/she is actually torified, chances are \
&gt; that he/she will &gt; &gt; browse in clear. DISABLED and ENABLED are only three \
&gt; characters away &gt; &gt; from each other, whereas a red vs green notification would \
&gt; probably &gt; &gt; catch the eye. &gt; &gt; - Install fails when installing/uncompressing tor \
&gt; binary &gt; &gt; https://trac.torproject.org/projects/tor/ticket/2989 [turns out that &gt; &gt; \
&gt; this is only a bug on Android&lt;2.3, but still...see comment #1 for more &gt; &gt; details] \
&gt; &gt; &gt; - Blank semi-permanent status box &gt; &gt; \
&gt; &gt; &gt; https://trac.torproject.org/projects/tor/ticket/2993 [have
 n't
updated &gt; &gt; this one yet; the bug actually occured only before the first reboot for &gt; \
&gt; me, and one time afterwards when I had b0rked the network badly] &gt; &gt; - ORBot vs \
&gt; DroidWall: Starts with 'You don't preserve my chains like you &gt; &gt; used to :(' and \
&gt; ends with, if I remember correctly, ORBot flushing &gt; &gt; iptables rules. I'll have a \
&gt; look at that one tomorrow (or is there &gt; &gt; already some data on it?). &gt; &gt; &gt; &gt; For \
&gt; now, have a nice evening! &gt; &gt; &gt; &gt; Cheers, &gt; &gt; &gt; &gt; __sporkbomb &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; \
&gt; &gt; [0] http://sporkbomb.eu/orbot/endpoints &gt; &gt; [1] http://sporkbomb.eu/orbot/ips &gt; &gt; \
&gt; &gt; [2] http://sporkbomb.eu/orbot/inconsensus (result of a grep -c - IPs &gt; &gt; with '0' \
&gt; &gt; in the second field are not contained in the consensus) &gt; &gt; [3] \
&gt; &gt; http://sporkbomb.eu/orbot/dig-result &gt; &gt; [4] \
&gt; &gt; http://sporkbomb.eu/orbot/not-inconsensus.notes &gt; \
&gt; &gt; &gt;_____________________________________________ Guardian-dev mailing list &gt; &gt; &gt; &gt; \
&gt; &gt; &gt; Post: Guardian-dev@lists.mayfirst.org &gt; &gt; List info: \
&gt; &gt; &gt; https://lists.mayfirst.org/mailman/listinfo/guardian-dev &gt; &gt; &gt; &gt; To Unsubscribe \
&gt; &gt; &gt; &gt; &gt; Send email to: Guardian-dev-unsubscribe@lists.mayfirst.org &gt; &gt; Or visit: \
&gt; &gt; &gt; &gt; &gt; https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info \
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; You are subscribed as: nathan@guardianproject.info &gt; \
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;_____________________________________________
&gt; Guardian-dev mailing list &gt; &gt; Post: Guardian-dev@lists.mayfirst.org &gt; List info: \
&gt; https://lists.mayfirst.org/mailman/listinfo/guardian-dev &gt; &gt; To Unsubscribe &gt; Send \
&gt; email to: Guardian-dev-unsubscribe@lists.mayfirst.org &gt; Or visit: &gt; \
&gt; https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info \
&gt; &gt; &gt; You are subscribed as: nathan@guardianproject.info \
&gt; &gt; &gt; &gt;_____________________________________________
&gt; tor-dev mailing list &gt; tor-dev@lists.torproject.org &gt; \
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev -- Mike Perry Mad \
&gt; Computer Scientist fscked.org evil \
&gt; labs_____________________________________________
tor-dev mailing list tor-dev@lists.torproject.org \
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev 


[Attachment #5 (text/html)]

&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;Got some time this evening if anyone wants or can meet up to \
hang and talk Tor and Android.&lt;br&gt; &lt;br&gt;
+n8fr8&lt;br&gt;
7185697272&lt;br&gt;
-- &lt;br&gt;
Sent from my Guardian-powered Android phone with K-9 Mail. Please excuse my \
brevity.&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;Mike Perry &lt;mikeperry@fscked.org&gt; \
wrote:&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; border-left: \
1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; &lt;div style="white-space: pre-wrap; \
word-wrap:break-word; "&gt;This is great stuff. One of the things that would be \
interesting future work is how safe are the protocols to use over tor in terms of \
cleartext exposure to exit nodes. I thought all of the google apps on the phone were \
using SSL, and it surprises greatly me to learn that the app market uses cleartext in \
any way.

Is that all market activity, or just some API calls? Can exit nodes
(or open wifi access points) give you altered apps, for example? Or simply delay \
critical updates by breaking connections because they can see you are trying to \
update from a vulnerable version of a particular app? This seems like a huge \
nightmare...


Thus spake Nathan Freitas (nathan@freitas.net):

&gt; Fantastic, Manuel. Looks like we are going to need some wine over to
&gt; patch this up. This type of look at how our transproxy all rules are
&gt; working (or not) is long overdue. I really appreciate your effort.
&gt; 
&gt; The first thing that comes to mind is that we are setting up the
&gt; iptables rules on an app-by-app basis, using the list of user IDs we are
&gt; provided by Android API calls. It is quite possible that certain
&gt; subsystems are not represented in that list.
&gt; 
&gt; There may be a better way to implement the transproxy all implementation
&gt; that is more of a "everything but tor" approach.
&gt; 
&gt; Our transproxy configuration is based on the approach outlined here:
&gt; &lt;a href="https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/Transparent \
Proxy"&gt;https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TransparentProxy&lt;/a&gt;
 &gt; 
&gt; We'll have to go through additional recommended configurations that we
&gt; are not addressing in our current "all" setup, and see if they address
&gt; the leakage you have found.
&gt; 
&gt; Best,
&gt;  Nathan
&gt; 
&gt; On 04/27/2011 12:40 PM, Manuel wrote:
&gt; &gt; Hi all!
&gt; &gt; 
&gt; &gt; Mini-intro: Hi, I'm Manuel (aka __sporkbomb), infosec researcher from
&gt; &gt; Austria, got bored and asked Nathan if he wanted help with ORBot ;)
&gt; &gt; 
&gt; &gt; Setup: Simply an open AP, a Desire HD running CM 7.0.2 and
&gt; &gt; 0.2.2.22-orbot-alpha-1.0.5.20110417a-dev plus airodump.
&gt; &gt; 
&gt; &gt; Methodology: The dump was started after the tor connection (and full
&gt; &gt; transproxying) was established in order to reduce false positives. Total
&gt; &gt; dump length is around 3h15m, around 57MB of data. Of course the phone
&gt; &gt; was left idle for a quite a while, also to ensure that it didn't do
&gt; &gt; nasty untorified stuff when waking up to check mails. Afterwards, I used
&gt; &gt; Wireshark's 'Endpoints' statistics function to determine all TCP
&gt; &gt; endpoints in the dump[0] and awk'd &amp; uniq'd the IPs out of it[1]. As \
the &gt; &gt; next step, I determined which of these IPs was in my \
cached-consensus[2] &gt; &gt; (somewhat ill-advised, because I compared with my \
laptop's &gt; &gt; cached-consensus rather than the phone's, causing two false \
positives &gt; &gt; [false non-tor nodes] that actually were nodes). I also ran a \
reverse &gt; &gt; lookup on all IPs [3]. As the last step, I went through all
&gt; &gt; communication with IPs that were not found in cached-consensus[4].
&gt; &gt; 
&gt; &gt; You can find links to most of the files I produced at the end of this
&gt; &gt; mail, excluding the dump, which I can provide if requested, but would
&gt; &gt; rather not hand out publicly (mostly because of the size).
&gt; &gt; 
&gt; &gt; All in all, the phone connected to 88 IPs during that time. 37 of those
&gt; &gt; were not contained in the laptop's cached-consensus, two of which were
&gt; &gt; actually legitimate nodes (according to &lt;a \
href="http://metrics.torproject.org"&gt;metrics.torproject.org&lt;/a&gt;) that &gt; &gt; just \
went down throughout the duration of the test, leaving us with 35 &gt; &gt; non-Tor \
IPs. They can be categorized as follows: &gt; &gt; 
&gt; &gt; - 27 of those nodes had no other communication than multiple TCP
&gt; &gt; packets, sometimes from a few different source ports (i.e. different TCP
&gt; &gt; connections), all originating from the phone and having FIN+PSH+ACK set.
&gt; &gt; (PSH is the 'push flag', which requests that this data bypass buffers
&gt; &gt; and be handed directly to the application)
&gt; &gt; 
&gt; &gt; - 4 existing connections that still transmitted data; one even contained
&gt; &gt; Market HTTP (cleartext) API requests.
&gt; &gt; 
&gt; &gt; - 4 were completely unencrypted and newly established connections to
&gt; &gt; YouTube or Revision3 video servers. This one is rather bad - it seems
&gt; &gt; that the video player subsystem of Android ignores the proxy setting and
&gt; &gt; leaks everything, including DNS. I also mentioned this yesterday on
&gt; &gt; Twitter, but didn't want to post it yet without confirmation, but it's
&gt; &gt; definitely reproducible on my end.
&gt; &gt; 
&gt; &gt; --------------------
&gt; &gt; Sumup of this part: Generally solid performance, but already established
&gt; &gt; connections might pose a threat (a minor one I'd guess, however...unless
&gt; &gt; one of you can think of a scenario where that causes Bad Things to
&gt; &gt; happen?). Additionally, the video player completely ignores the proxy
&gt; &gt; setting and communicates untorified. While video streaming isn't a
&gt; &gt; strong point of Tor anyway, it's still not good...does anyone have good
&gt; &gt; contact to CyanogenMod people and can ask about that one?
&gt; &gt; 
&gt; &gt; Various tidbits of slight UX annoyances plus a few suggestions:
&gt; &gt; - ORBot ignores the "Transparent proxy" setting when connecting, I
&gt; &gt; always have to enter the Settings menu, untick and re-tick "Transparent
&gt; &gt; proxying" and press back to actually cause it to be enabled.
&gt; &gt; - Related to this: Is it possible to colour-code the "Transparent
&gt; &gt; proxying {DIS,EN}ABLED" notification? The bug above might have serious
&gt; &gt; consequences, because if someone doesn't visit &lt;a \
href="http://check.torproject.org"&gt;check.torproject.org&lt;/a&gt; to &gt; &gt; assure that \
he/she is actually torified, chances are that he/she will &gt; &gt; browse in clear. \
DISABLED and ENABLED are only three characters away &gt; &gt; from each other, \
whereas a red vs green notification would probably &gt; &gt; catch the eye.
&gt; &gt; - Install fails when installing/uncompressing tor binary
&gt; &gt; &lt;a href="https://trac.torproject.org/projects/tor/ticket/2989"&gt;https://trac.torproject.org/projects/tor/ticket/2989&lt;/a&gt; \
[turns out that &gt; &gt; this is only a bug on Android&lt;2.3, but still...see \
comment #1 for more &gt; &gt; details]
&gt; &gt; - Blank semi-permanent status box
&gt; &gt; &lt;a href="https://trac.torproject.org/projects/tor/ticket/2993"&gt;https://trac.torproject.org/projects/tor/ticket/2993&lt;/a&gt; \
[haven't updated &gt; &gt; this one yet; the bug actually occured only before the \
first reboot for &gt; &gt; me, and one time afterwards when I had b0rked the network \
badly] &gt; &gt; - ORBot vs DroidWall: Starts with 'You don't preserve my chains like \
you &gt; &gt; used to :(' and ends with, if I remember correctly, ORBot flushing
&gt; &gt; iptables rules. I'll have a look at that one tomorrow (or is there
&gt; &gt; already some data on it?).
&gt; &gt; 
&gt; &gt; For now, have a nice evening!
&gt; &gt; 
&gt; &gt; Cheers,
&gt; &gt; 
&gt; &gt; __sporkbomb
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; [0] &lt;a href="http://sporkbomb.eu/orbot/endpoints"&gt;http://sporkbomb.eu/orbot/endpoints&lt;/a&gt;
 &gt; &gt; [1] &lt;a href="http://sporkbomb.eu/orbot/ips"&gt;http://sporkbomb.eu/orbot/ips&lt;/a&gt;
 &gt; &gt; [2] &lt;a href="http://sporkbomb.eu/orbot/inconsensus"&gt;http://sporkbomb.eu/orbot/inconsensus&lt;/a&gt; \
(result of a grep -c - IPs &gt; &gt; with '0' in the second field are not contained \
in the consensus) &gt; &gt; [3] &lt;a \
href="http://sporkbomb.eu/orbot/dig-result"&gt;http://sporkbomb.eu/orbot/dig-result&lt;/a&gt; \
&gt; &gt; [4] &lt;a href="http://sporkbomb.eu/orbot/not-inconsensus.notes"&gt;http://sporkbomb.eu/orbot/not-inconsensus.notes&lt;/a&gt;
 &gt; &gt;&lt;hr /&gt;&gt; &gt; Guardian-dev mailing list
&gt; &gt; 
&gt; &gt; Post: Guardian-dev@lists.mayfirst.org
&gt; &gt; List info: &lt;a \
href="https://lists.mayfirst.org/mailman/listinfo/guardian-dev"&gt;https://lists.mayfirst.org/mailman/listinfo/guardian-dev&lt;/a&gt;
 &gt; &gt; 
&gt; &gt; To Unsubscribe
&gt; &gt;         Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
&gt; &gt;         Or visit: &lt;a \
href="https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject \
.info"&gt;https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info&lt;/a&gt;
 &gt; &gt; 
&gt; &gt; You are subscribed as: nathan@guardianproject.info
&gt; 
&gt;&lt;hr /&gt;&gt; Guardian-dev mailing list
&gt; 
&gt; Post: Guardian-dev@lists.mayfirst.org
&gt; List info: &lt;a href="https://lists.mayfirst.org/mailman/listinfo/guardian-dev"&gt;https://lists.mayfirst.org/mailman/listinfo/guardian-dev&lt;/a&gt;
 &gt; 
&gt; To Unsubscribe
&gt;         Send email to:  Guardian-dev-unsubscribe@lists.mayfirst.org
&gt;         Or visit:
&gt; &lt;a href="https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardia \
nproject.info"&gt;https://lists.mayfirst.org/mailman/options/guardian-dev/nathan%40guardianproject.info&lt;/a&gt;
 &gt; 
&gt; You are subscribed as: nathan@guardianproject.info
&gt;&lt;hr /&gt;&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; &lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;


-- 
Mike Perry
Mad Computer Scientist &lt;a href="http://fscked.org"&gt;fscked.org&lt;/a&gt; evil labs&lt;hr \
/&gt;tor-dev mailing list tor-dev@lists.torproject.org
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;
 &lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110302070642</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-03-02 07:06:42-0400</timestampReceived><subject>Re: [tor-dev] Proposal 178: Require majority of authorities to vote</subject><body>

On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:

&gt; Design:
&gt;
&gt; When the consensus is generated, the directory authorities ensure that
&gt; a param is only included in the list of params if at least half of the
&gt; total number of authorities votes for that param. The value chosen is
&gt; the low-median of all the votes. We don't mandate that the authorities
&gt; have to vote on exactly the same value for it to be included because
&gt; some consensus parameters could be the result of active measurements
&gt; that individual authorities make.

This is possibly bikeshed, but I would suggest that instead of
requiring half of  existing authorities to vote on a particular
parameter, we require 3 or more to vote on it. (As a degenerate case,
fall back to "at least half" if there are fewer than 6 authorities in
the clique.)

I think we don't want the number to be _less_ than 3, since 3 is the
smallest number of parties who can come up with a low-median that
isn't just the diktat of a single member (1 party), or as low as
either member wants it to be (2 parties).

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110303052600</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-03-03 05:26:00-0400</timestampReceived><subject>Re: [tor-dev] Proposal status, with suggestions for fun stuff to do</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Nick Mathewson (nickm@torproject.org):

&gt;    159  Exit Scanning
&gt; 
&gt;      This is an overview of SoaT, with some ideas for how to
&gt;      integrate it into Tor.
&gt; 
&gt;      Mike, is this implemented? Done?  Superseded?  Still open?

We are most of the way through the "Human Review" phase of this
proposal, but only for the HTTP and HTTPS versions of the scans. I would
like to re-enable HTML, and implement an SSH scan, too. The authority
integration pieces are not present in either tor core or the scanners.

&gt;    xxx-exit-scanning-outline.txt
&gt; 
&gt;      Looks like this was superseded by 159?

Yes, and also the 2009 HotPETS paper on TorFlow.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110303194233</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-03-03 19:42:33-0400</timestampReceived><subject>Re: [tor-dev] xxx-triangleboy-transport.txt (+comments on</subject><body>

On Fri, Feb 25, 2011 at 9:34 PM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt; Thus spake Nick Mathewson (nickm@freehaven.net):
&gt;
&gt;&gt; On Tue, Feb 1, 2011 at 12:08 AM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:

&gt;&gt; &gt; 3. The relay plugin side needs some way to communicate EXTRAINFO lines
&gt;&gt; &gt; to be added to its extrainfo descriptor. In this proposal, we use the
&gt;&gt; &gt; SMETHOD reply to do this.
&gt;&gt;
&gt;&gt; Needs spec, not just an example.
&gt;
&gt; Ok. Well, does the example I gave look like an instance of what we
&gt; want to specify as the behavior?

Sounds plausible.

&gt;&gt; &gt; 4. Is extrainfo really the best place to keep this information?
&gt;&gt; &gt; Shouldn't it just be in the relay/bridge descriptor? Putting it in
&gt;&gt; &gt; extrainfo requires our TransportBridges to enable the wasteful
&gt;&gt; &gt; DownloadExtraInfo=1 torrc setting, which will consume more scarce
&gt;&gt; &gt; resources and RAM on what will probably be cheap routers with 32-64M
&gt;&gt; &gt; of RAM.
&gt;&gt;
&gt;&gt; Hm.  Relay/bridge descriptor should be okay, I guess.  I'm not sure
&gt;&gt; why the TransportBridges are getting those anyway, though:  I see why
&gt;&gt; the client needs it, but not what the transportbridge needs it.
&gt;
&gt; The transport bridge should avoid being an open proxy. I suppose it
&gt; can only properly carry full TCP streams to an endpoint, but without
&gt; restricting who those endpoints are, it becomes a reflector open to
&gt; abuse such as portscans.

Hm. For bridges, at least, the transportbridge will need to get a
supported list from some other mechanism, since it can't get an
exhaustive list from any particular source.  For relays, though, this
makes sense.

I think your original point is a good argument that sometimes this
information doesn't belong in the extrainfo document.  (I think it
does in the case that only a bridge authority needs to care about it,
but not otherwise.)

&gt;&gt; Also, why are transportbridges even running tor?  They don't seem to
&gt;&gt; be doing anything particularly tor-like.
&gt;
&gt; Mostly for the consensus, for reasons above. Not strictly required, if
&gt; we don't mind being an arbitrary SYN proxy.
&gt;
&gt;&gt; &gt; 5. How would we go about chaining an actual obfuscation mechanism with
&gt;&gt; &gt; this transport? Would we just create new and separate transport called
&gt;&gt; &gt; TriangleBoyOverHTTP, for example, or is there a better way to chain
&gt;&gt; &gt; different mechanisms?
&gt;&gt;
&gt;&gt; On the client side, socks-over-socks-over-socks is not actually a
&gt;&gt; terrible way of doing things there.  We'll need to distinguish between
&gt;&gt; which transports are chainable and which aren't, though[*], and maybe
&gt;&gt; revise the design to make sure there's a way to tell to tell tor to do
&gt;&gt; said chaining.
&gt;&gt;
&gt;&gt; On the server side, you need some way to distinguish which processing
&gt;&gt; method to do for incoming data. Separate ports seems ok there.  We
&gt;&gt; still need to figure out the server side.
&gt;&gt;
&gt;&gt; [*] generally, obfuscation is chainable but transport isn't.
&gt;
&gt; This is not a bad generalization. Do we want to make this distinction
&gt; (between obfuscation vs transport) elsewhere in the spec, I wonder?

I'm not sure.  I can imagine chaining most of these mechanisms under
sufficiently weird circumstances.  For example, you might want to
obfuscate the protocol (make it not resemble SSL) before you do
another transform to make it impersonate HTTP, before you send it over
a triangleboy-like transport.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110305164701</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-03-05 16:47:01-0400</timestampReceived><subject>[tor-dev] Nick+Roger IRC chat time for developers,</subject><body>

Hi, all!

Frequently, developers (including Nick and Roger) block on having both
Nick and Roger online at the same time.  We're trying to solve this by
scheduling time to make sure that we're online and available to work
with others on stuff that's blocking on is.  We'll be on the
development IRC channel (#tor-dev on OFTC) on March 8 and 9, from 1400
to 1800 EST (1900-2300 UTC, if I can add right).  If you're doing
something developmenty that's blocking on one or both of us, please
stop by and have a chat.

peace,
--
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110309214050</emailId><senderName>"Steve Snyder"</senderName><senderEmail>swsnyder@snydernet.net</senderEmail><timestampReceived>2011-03-09 21:40:50-0400</timestampReceived><subject>[tor-dev] Is this "fix" Ok for BSD malloc?</subject><body>

When configured using the --enable-openbsd-malloc option Tor v0.2.1.30 will build \
without error on RHEL5, but then won't run.  The cause of the runtime problem is that \
the symbol __libc_enable_secure is defined in OpenBSD_malloc_Linux.c but not actually \
built into the GLibC used in RHEL5.

Can I "fix" this problem my simply removing the reference to __libc_enable_secure?  

Let me rephrase that.  This does actually fix the problem, but I wonder if it creates \
a different problem, one which has not become apparent in 2 days of run time.  So my \
question is: what functionality have I lost by removing the __libc_enable_secure \
test?

Thanks.

--------------------------

--- tor-0.2.1.30/src/common/OpenBSD_malloc_Linux.c.original     2009-05-18 \
                19:47:00.000000000 -0400
+++ tor-0.2.1.30/src/common/OpenBSD_malloc_Linux.c      2011-03-07 11:19:36.000000000 \
-0500 @@ -77,11 +77,11 @@
 static int align = 0;
 static size_t g_alignment = 0;

-extern int __libc_enable_secure;
+// extern int __libc_enable_secure;

 static int issetugid(void)
 {
-       if (__libc_enable_secure) return 1;
+//     if (__libc_enable_secure) return 1;
        if (getuid() != geteuid()) return 1;
        if (getgid() != getegid()) return 1;
        return 0;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110314063928</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-03-14 06:39:28-0400</timestampReceived><subject>Re: [tor-dev] DefenestraTor: Throwing out Windows in Tor</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Roger Dingledine (arma@mit.edu):

&gt; http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-06.pdf
&gt; 
&gt; To reduce congestion, we first evaluate small fixed-size circuit win-
&gt; dows and a dynamic circuit window that adaptively resizes in response to
&gt; perceived congestion. While these solutions improve web page response
&gt; times and require modification only to exit routers, they generally
&gt; offer poor flow control and slower downloads relative to Tor's
&gt; current design.To improve flow control while reducing congestion,
&gt; we implement N23, an ATM-style per-link algorithm that allows Tor
&gt; routers to explicitly cap their queue lengths and signal congestion
&gt; via back-pressure. Our results show that N23 offers better congestion
&gt; and flow control, resulting in improved web page response times and
&gt; faster page loads compared to Tor's current design and the other
&gt; window-based approaches. We also argue that our proposals do not enable
&gt; any new attacks on Tor users' privacy.

Great stuff!

So to summarize, they took the reduced circwindow stuff we've already
tried out, improved it to make it dynamic, and then found something
still better (N23). 

It also looks like they've reproduced the fact that the circwindow
changes weren't significantly better than stock tor on a more tor-like
simulator (ModelNet), which we observed during our tests. That's
great: it gives a good confidence boost to results from ModelNet.
Hopefully this means the simulator is good enough so that N23 really
is better for live tor. 

According to Appendix A, it also looks like if we use N23, we won't
need ewma? I wonder what this means for an orconn-level ewma.. Is N23
supposed to be the solution to all our fairness problems? I don't see
any statements about the simulation setup used for Appendix A, either.
Is it still their full ModelNet setup?

Perhaps we should work with them to hook up a full Torperf setup to
this, and/or document a proper standard Tor simulator and evaluation
framework.

Overall, I'm very excited. If we can manage to try out both the
optimistic data patch and N23 in 0.2.3.x (independent of eachother, of
course), tor might actually be usably fast ;).

 
-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110318032333</emailId><senderName>katmagic</senderName><senderEmail>the.magical.kat@gmail.com</senderEmail><timestampReceived>2011-03-18 03:23:33-0400</timestampReceived><subject>Re: [tor-dev] Logging [Enhancement]</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 17 Mar 2011 21:45:04 -0400
grarpamp &lt;grarpamp@gmail.com&gt; wrote:

&gt; - An FYI, found while grokking, thanks.
&gt; - These various log entries could really have their format normalized
&gt; sometime.
&gt; - If it's going to tell us why it's giving up in one case, it should
&gt; do so in all cases.
&gt; - The fingerprints should be printed instead of the ambigous router names.
&gt; - Eliminate personal pronouns 'We'.
&gt; - Remove 'Have'.
&gt; - Shorten seconds to sec.
&gt; - Change 'get a connection' to 'build a circuit'
&gt; - Remove quoting, parenthesis, etc. Or create, and consistently use,
&gt; parseable entries.
&gt; 
&gt; We tried for 15 seconds to connect to '[scrubbed]' using exit
&gt; 'Unnamed'. Retrying on a new circuit.
&gt; Have tried resolving or connecting to address '[scrubbed]' at 3
&gt; different places. Giving up.
&gt; Tried for 123 seconds to get a connection to [scrubbed]:80. Giving up.
&gt; Tried for 120 seconds to get a connection to [scrubbed]:80. Giving up.
&gt; (waiting for circuit)
&gt; Tried for 120 seconds to get a connection to [scrubbed]:0. Giving up.
&gt; (waiting for socks info)
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

-
  9r0O9hMDqm7TfOirRV9slKfPyntTfYx6i1VYOuLWBNhhJrcHhM3V9SZybbIcKiHhXqb8IJ+TQf62aLEERv2J1Q
  Im4t3zgPlMd2bim2ZzmB0FFU/GxnhUo/L5Fbm5/0PMTkiQ6j3vZf7qD9XXANcPM5h1RpEsjwTXXOCY2iUNGFzg,
  sEKrl8WYH83LiXfZCSO7EkEJJptfZMUgjGS2mHA20zgdxXjVY7qC4APCkeEjEjKyfuCMuALJ7euzOex7AfRDJg
  4fGUpvf+6rsP6io8i8wueQpVM5/KdSvHyKh2RvGtG6CDfk/97teUFJ47Fv5tgtoCQ8kBFajNEdgTchNEAcD35w
  zWXWsE8bWCn7MQhTU8jaAYezrKflN+8osBU2FjoZCR8ii57KY+NdocP9OJwDrWkPOr84HldfNiwbaDJ8R8M2hA,
  1cJJKe1/dF9eC22goaUsTvWfJAb/G5EnLrVMN8vmNlybSb4VNgWv9k6wKJaF4AMXQyPb6Ai1po7KW6s6Z0HQDA.
                
- /KInxZUU6OlaqhX96OvBlnMTVWyUqmQWZmvyME5815kyq93p5PLitMmkrrPjnVrwUyLiysRezEgtyFFr3toN9A
  INH9F09TXhAg8YczpsDl1Ijv5qpOPemMCOkHgpflC78fPKVtmm6RprR4uGW/7Vg63gowTbPgEwsPAhc3uqhdfQ
  hzvMN+USt9qGR2NndpyTIAn8G+5ZySmHnxCsid9UESTbUBCucpfscduPcaCa3M0nwALwD8/JPKfhVxBedQXyTQ
  PfKBU1CChpDMZxT6CKFOut2xo/rsxT4A4gdkX3adb+Eb+ppRxb96VlQYFHHLSQWzozAAZVJSwHeNnjBML/khQQ
  1S4eLWPFObTKoZ/84v0npYRcoDwH9mqaWOMI9etDgKjCYbtGZfPAZD9EQ91Dpbg8jhiH0sE/lTKDRKQv/ZOpRQ
  VMN3YjUawlt+hkd9igePrzR/z6vfBExDdtByjObNz+SAHg4bzbwOLXEEL78gd5st1YCXWsbFnRVyUNDOOY98aQ
  v8VnR5XVi2Up6OG3AqHK/qfV9OO02wBUeXXcnrRp3uzh+RVryj9dmF+NpdTc6DPhYmbNyqakoNDipnCVJt6S/g
  SJs2SFcyih3anup4F9INGS6/jergIyo0uW1FF2SZfvdrwTgnq1mNvPS5+kGFRskQpY29SOOP/6fSwkK5P2wQOQ
  Nysda2vbguyZrS5/ShpzCj9gh5IyWEnaPVoNQbmiRpHQKMoUMqZEh9RfP7Xrz7xexw18jZx3TD2LH8GRRVWrSA
  h4M8d+Faigk2QWIvF4rAiX9bH/7p0ljoqg8tw25jeGyWe4sFCduyLJN+JQQDOP9VS96mXacihsfZjukPY4CrRw
  YyFCZRzBRFG2LYE4ZrrmlSDClqgxJ4ZhNwig27FJn0CUF5kYICbIzH0g6TubjTCDDpWIRreu3p6yfcm7DS9sEA.
                
-
  +4cyEFOoJKM4sR8H67PZjBlIt/5qxhtzgMUNpjmaUFCdGdhyTGD/4kRp0Lngf3zxwxdLD2GsIJzj0r24r1WRSg
  lSfWXHU1qDqV8kNV2F5f7Uboz8egw0CuiUdMepYTObHPwFPLohIe6nFcCIoXFy5AGXA/wo3ewsHhYQCSNURZ \
lA'LB7mg3IhWxzgZEJrXNvU7yWBrODdOyH6K+J/NkgnJC6D9otovgP1s+JL5dG0MV+YoKltGXE/s6GdxFX7atw0MQ
  kONHg/b/K2D/1nU3QbOBjo7OQRZSJsrl6BLASeg8+8XsfYHlRHcf40f4nN3ZZL1tRsjn4MMf5jRph0uDfW3MoQ
  NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
  iSUWI4Q/W6WXhzIWZne8yb/fuapL4gPoFkXxuDetv2MGpmC74MgZ6cE4lfy6q5XBrct2juZVJh6FgYu1ROq8Bg
  LORFkCBhm11W4vvkhUgA9DoY+0zS/+l5viljfgZTreHIjC09rxbCB0V75Q14D2NGQeusHaysLEGWtwSQ8IXOMA
  CyOwnnemjkRSURPea6jOFJhS6XW7q4rf5agoLCQ7qQykOWt/3cM+iMG6Hp+s4xSA0KCUDbHvQlL4L62o3X0sZA
  lSfWXHU1qDqV8kNV2F5f7Uboz8egw0CuiUdMepYTObHPwFPLohIe6nFcCIoXFy5AGXA/wo3ewsHhYQCSNURZ \
lA'LB7mg3IhWxzgZEJrXNvU7yWBrODdOyH6K+J/NkgnJC6D9otovgP1s+JL5dG0MV+YoKltGXE/s6GdxFX7atw0MQ
  7XW5krWxXf15ELxYN+QxF4ZU/77XDCW51BxsUO25lAdDD8eIhHATAu0SCexzOZ1YqDB9Ym8CoQEx2e5kfBHkZQ
  TpCbI5K7Mic6wVTmZJi1EzsZdPWXo+FbhJnvn9mCNWeJp9Sy3vnBAKm7d5E5BIrz52wkiOHlNb2px917M9cLHQ
  6ISjoQ9Mkh03DEtw9a9FHm4S/601yW9uYSIfnPLvur3QbbPt65O90RglSdnZS9htuqQgW6myZyFSTpxCDljINA
  BfcDQQeKz2oG1CPSFyD5ZD1flTYm2IoCY23DqeeVgq6wyCCFf9P43FAqqDYNLI+pephf2ltim4CcrRj/ti04mQ
  VW6Aael1UIyTn1yI5bGDZmgbs/lmDB+s04yPnnSlBC1mJW7N9KADQbWFgM6js6s0n0qGGpc5FYUMU8o0PpMscA,
  lSfWXHU1qDqV8kNV2F5f7Uboz8egw0CuiUdMepYTObHPwFPLohIe6nFcCIoXFy5AGXA/wo3ewsHhYQCSNURZlA
  lfuL2g+WBhLbNKDol3Xv0OduCbLfjibaWO/r1XhzEJOOov18jjahq0LgU3/s43jBDcaXPZIpWbUFYyBvSlEakg
  iNRWErjnPTcAUgWnNYNT55I8thrtY+1Sf271pP2zUK+vAGxFTWvwxDzh3li/XzaqHSr616RvUa8tyosZcIw7yg
  tk81vPu6gtu4qYDiL07g3EB4lU74lpLMeWDCtf3gTXZCATQMMFAfEFwGkWFWjExG/qTQZgVE02VtH+Ob+XRdFw
  6ISjoQ9Mkh03DEtw9a9FHm4S/601yW9uYSIfnPLvur3QbbPt65O90RglSdnZS9htuqQgW6myZyFSTpxCDljINA
  g/sonn1xOt3IzJFL1Z0NckJY10cNUUYphdZvbi5NuuGm9QVGDIbmiRTfl6xkJOkzdQuTemusUW/jj2tvtROpVQ
  I+nxyPqm0faWRfc6n77xZz98oQCyy+00ieY/QlardqlMF5bqJWb952AHH2iy/Ueo80IvgGS/ddsM9DSoV8yCmw.
                
-
  0euPyhjx7RPCVPIoQ1uiO6IDtC1vs4v4SqrlR2Cjlk5nEUm10QMXoNPs3NACEFPmxZb7CwXDMhTP1UVdMlq1Pg
  8U3VKAfxYxubQjZz9YO4qJ5PE1F8QJupBOIa9OYjVtjcwxm+PE2zbkHaIRSdhFVcb8bE9vTQYIjioWI+QRWctQ
  lfuL2g+WBhLbNKDol3Xv0OduCbLfjibaWO/r1XhzEJOOov18jjahq0LgU3/s43jBDcaXPZIpWbUFYyBvSlEakg
  YK38AwVbkDBMt9/l5hlIiRQX0QoQ9RWbUgXPAzmN8Hs1v6NuJOiOqAiQdIggWJt81lb3cy4fT7Bx8Ts51xpAYA
  oCMusNbAiiWwa1Dpwuv1EEy2cz9YEt5rG9Qo/Qup8tjfaGMpjOBMou/ZzWPc+tb7fpqkLJ7lmzWSzWt0HkU+zA
  ZgVpURf+kverMAzshPqmr3GSUayuRSwAPoShes++aaXFX5Ta28a08aQJ2Xejj9bBCYVq+LluY8hyYTPPdWOfYg
  C9WGEuJVecA9WkSqFzBkDF+XshjZxuSE2IflzQQ6V8My6BBmYMJ9TPmU/n+xW9fxNVxmIJGo2/mCDLetPYdEHg
  H+rs+lMp5d0cwH8S2tNAb+slfbERoGeD5oV7RJiwvJoo1Rz7MjVKHtY2zZnk0rv8RGaxfBAUdjI2YjTmouiy9g
  YJBzjLAfYHN/W2WEUxN/9obf9VaMs1D3mo13nacXiL+ZpaZSIjoCmBtld0D3u80mcAQ4m56sCkUM8KJZUkpssg
  g5GXbaHoIJL6OYk5edJflxTjnvk2fs2QsV7vuLe4BUDn78ka10q+E10OfqruveweEm6EBHGyumkuBER+6FNm2g
  2R5eJqhl92k9VnWGESHCJ7bxZkceZ4QM6Ci6K7JPFZtDd/cZuRNiq6rDXeMz4CZ/p5UJ0X9u/qK/vppJqrWTHA.
                
-
  hPmfG91GatAxwXBbxlg1eF6JYfKB0lSNjJICeYWiWpGUdoG0NDQagujGPb/g2gMk8EpmyGbgU3jselM7a54zpg
  i9G870CeZml2au+aiLHn/YdSyYTjJy7Dod/sCIn/bPsUoaydoH02XJo1xeGgNLmc2NcHaaUcHn23J7tcVqQlWg
  Vv91VhP5rH7ZjomyYQ5EVvRYCDFnzFXrjcfoXetnkIXhD58vC/Rtp5OMfX+TSU1EsRyzFeum6NSi2Xm+9xjfYQ
  'p02wWlGXK3MV+LlSw+Tp+a/Mr289Ml8DOLz/aJHy6xR//ltgakVmEMZC7EyGht4WHbB+Qk3VqmqQj3YMjTCMPQ'.
                
-
  G/yZLul6P1qWagwB+codRLo4ZZUyVjpg4iNGhFyIFzxANrAxedTMp0+HiRoZR081JtRsweBLXy6iCyhPJVMKVA
  'CNiUEMDftOqZY3eNnF+u8UvNAsS2dYnO1g101RKO0Su5gUNZtAz02FPEmwEAXMMtPzFrz8x7um3gUcPRYLKgnA'.
                
-
  lQ/npK+ixt3r+3YeAO4E1ElBbtg4ZzphW7SFg2cr8Fchd1uUc8E65zph9SSORRBJlNHBAMMNdVP6zkb3H5ZIlQ
  8TQoLRh7EaNhixxFyJXQm2VniAft15ZVXku1KQ5M5ILAlmldiJws7T2FyLDXQu7jZXQkUZhUKyKpdjtNRy7W+w
  NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
  nCxC7RdoUcm08gpCxrpXyh0e86AX436XOct5E/aAZgtyMnNYFcV4tCNHwuTY1ESl6pNRivHjBfLKewf17edaFw.
                
-
  BY343C3tWsxIyqD4Wc56jUV8g1979HVzdmdEffmwNyS3qLBtQN6IWzB+00/5cdZwaQZxehro2pF+vAMpv6/NRQ
  'WAv50aior+FThK6nxV6pdbohDozN/C+1mB6DqFdE++w/xNgoAyW1l6zU3gESjWGOAg0VSuQA02IWXD6s7Owalg
  H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
  OjzRQozaVtKNjup1kUGLTKoLz0/i6d74eiVbxWRs54iZy5My7f2g/pIapbaE5//j2/23iifeMfK/QQXqnU/7qw'
  NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
  'sW8YbP1O30bVBky1SlVdV1feG8yXN2Fs4ozBeozo9m3ucqyEypMrif6Q0jQEAH1jttsKxDtR6FuBThnU27CUrQ
  H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
  9QN7p/bfLkThpzn1zGSPROVN7zI33L5R4GZRWuin+ie/JvKGBWCABrgEOEubu/s5qdbCTIxiDSmVcgpsXeutjg'
                
-
  G/yZLul6P1qWagwB+codRLo4ZZUyVjpg4iNGhFyIFzxANrAxedTMp0+HiRoZR081JtRsweBLXy6iCyhPJVMKVA
  4rgGVMLWreieN270Z2rgPT3eNk7LYUv/9jcYZ1gLc0suFyLxnzniof3w9rZ0UjAl4A4dLJF8nwA0rgYd3YNR5Q,
  +8tkyrBTfM2l/FTeU6K1zZ81k3YLLNEXO4hISs6HPLFAXwffifaNK3NFp2+ETqKK3ifvR2Plp2lfdlcdw34Dmw,
  CD04lhNBzhrrjy1vRKAbIhEMA2AVr2p7GDsOm8UP0+aXcTL7IVpk6vYm2LzbQ7KC+cacHhkqL0RMcBrQWXp0qA.
  4wpUNcvCbOPsa3IWzzvSjvdQJAbif5H4ehx4FTijfxvwXNHpE1Uo6/OHHblXUJcyXCitT3lirdlLGR84OzMnMA
  C6QAK4jdF/zTih/9d+MpI/xOoWZ7GO5iJ4PFy2ovAc2Rpjzx2BvJhSiP6g/wyyRg0go535V0rDruyE5zSBFULg,
  3mvL2Q/wDGBKg2/ioJWcaoauq9RA2JgpcGE+3/PNJ5ls1KIcAF5N1NyonJpdekb6nZfSsiBSHd3zs3b9BPLQug
  zZY7FaxkXrJup4GGRnnBeSwvDfX3pjNJtj+OwcFZctp3cr7SCeaosJ822fC6q+gUl9/ANNqWF4JCsSKtEuYrIA
  LGNLom1Lc7QFOEKoSf/RputjtpCRZUWkhDb1mj8aN7/KBZINbJgoDmWZCgRwzoKkcDbD990PcmkZzEASNLeQaQ,
  buZI1fleMVB9UqZ2KeD3BgpJAUvtI6N6z8j0cg/zTh5CoQZIr4FelRf02DwQUm/JYnNw6c/0F5B7+wnTOXJLAQ
  PfKBU1CChpDMZxT6CKFOut2xo/rsxT4A4gdkX3adb+Eb+ppRxb96VlQYFHHLSQWzozAAZVJSwHeNnjBML/khQQ.


p02wWlGXK3MV+LlSw+Tp+a/Mr289Ml8DOLz/aJHy6xR//ltgakVmEMZC7EyGht4WHbB+Qk3VqmqQj3YMjTCMPQ
 sRi3frnBUJKCEWEf2oJNA6V86jVB4uW+KmFXzKJ6+xgWhmEUar+U6AR7DWUYJ5/SBopyzjn8tvh2XYkEq6kXbA
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 mmOYz/xVreNbOfHkHPRsfEkXRJYYU/+VcdCau1WniXb3LDTNeoeHZ076HCJuqiSU29ChMxacnk4jaafS0C3jGg
 8TQoLRh7EaNhixxFyJXQm2VniAft15ZVXku1KQ5M5ILAlmldiJws7T2FyLDXQu7jZXQkUZhUKyKpdjtNRy7W+w
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 uJTdhHKGtrUhzPf8MwBza18dqnEVqsLiricE4my4gq8iZPzNXfmfwxL7prm0mBXtrfv/T3AlPKfY2p4lNZYOdw
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 '[71/drU9W2kKynoZKPh1OrOunK0sF4SRsgbgxdF9r0wO9ORmvN7xayxU7acRlJ/0pyEE0t0m0AJcc3djeEetLPw]'
 AQtjYgoZEUKdOdpGF79hSuHNu5D0703La73qpk8kGVG7wcXVFi2g4ZYbdC+Y3cJu9Jltti2h4tlGRuMBtx/lOA
 wmNq1Xj3uSXuTPVzlp1OxmQN57AXa/FwGt7OOnWTfcIGqxuO5TQzQdECw77R7IBKXCqeEiKn+1OjzALaVUhzKQ
 'uq4QAgDMJewneviGhfCj1kc/LO4KkDBaRDfk/vGUegWO0yLq5A09m7Inq5W4M+Sl3kIGLtzT6i+Hj9zFR9CrIg'.
 6p8IsgqkXUMvkUnBmYy4N9skY3FRjDNvpVMtOMgCSxSe4roe/uz5L1okgHd5gcjhc0wtNDpGfx1zufYkaVoNTQ
 t9qEPuxkyTy3u+4uhOf1MLt8m2N/Aob+Wm7ccqYabiGTxFiE/WuOE8sxnynWAjFcS89ww/dKwiIk86rObh8grg
 H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
 qlTe+eC7EcHrv8l6nuY6+elcT98dAysd3MDyFmH3SGUdKyuPuU6a4EF4BVTbKYFdqhwP6ZHdrlTv8MTCjNnSDA
 9QN7p/bfLkThpzn1zGSPROVN7zI33L5R4GZRWuin+ie/JvKGBWCABrgEOEubu/s5qdbCTIxiDSmVcgpsXeutjg.
 CNiUEMDftOqZY3eNnF+u8UvNAsS2dYnO1g101RKO0Su5gUNZtAz02FPEmwEAXMMtPzFrz8x7um3gUcPRYLKgnA
 sRi3frnBUJKCEWEf2oJNA6V86jVB4uW+KmFXzKJ6+xgWhmEUar+U6AR7DWUYJ5/SBopyzjn8tvh2XYkEq6kXbA
 ahVNIfs2sQVaZAJu/UEpw6s8mFOgVV5N84KVsiUOrkyZZ+StiiOK+7m8V9+CWQcSErSxkMXvegcW4QSjeoOCBQ
 Ntjkqd0GjZ4CPSjK6Jj0ASGN+/gxn3IY9XAtocUdZn36IswRw1P/E9ZUkafqCVZMb2yV+Lnfw/0eve6bAHJ8pg
 Jq6Kxp4GRRhUFdQ3MVsHzpnFrOcKjNiFrmdCt01Zt6TSUvg+7bmPFJwH9sbXPceC443FskGxBlzHZPfiI5VqdA
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 Oa/XSPSgLuGPdRUMuEXoRQD6LVl16E2N1cvnDFO8rruGJHimcG71CfGpRudpyoOeAkHDrAKJUYCD9Q1RN4pZDg
 '[71/drU9W2kKynoZKPh1OrOunK0sF4SRsgbgxdF9r0wO9ORmvN7xayxU7acRlJ/0pyEE0t0m0AJcc3djeEetLPw]'
 dTR5nNqNrsxqjWP/lCTH2ESWpeTv9f1yZraJ/wsSjjE1+u08+M6rvKB/wkE3Gel9sQOwWe2JyJgj2l4eydzvPg
 O6+/CIgqLRATMJOhuEM/UFY7k8FKzQW3kCjrHRJ5kCckFFCYBlGZRQFCOmbCdq4mxDtzm8ZcThaxDDr2wgKuuw
 SdW4eZVY4i04kNA7VqbHpG+qGn0hbC3yJQc5YkKrNUDiMXuHCIKyOE1wclQzOoQ5/Tyhkekyk/dFeG/3jvBp+A
 +FWruuE2d/1JPU/+5aP9Lg7SR9TeXsBB84bZzLQFpEVyusw2OZgiHnZ9hTGZmOAxtGg24rckZABj8dHawdDe4Q.
 mKQrf8HyEg5V5aU8g1Z1+eNoP2TG2Ck09I6fPVnG8sHW13u3Jp18nUVvnOtBOCrPCE01j/kFUyKcYf5kIU4ifA
 TpCbI5K7Mic6wVTmZJi1EzsZdPWXo+FbhJnvn9mCNWeJp9Sy3vnBAKm7d5E5BIrz52wkiOHlNb2px917M9cLHQ.
 rw+MMTNIk2dm46l+AppFxNChg9CvyyD5kZC5Y5CGGG3Fnwf6v/McfDI1g16bvUYZ16MnO95BiHIT39+3iX7IrA
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 PJkJr+wlNU1VHa4hWQuybjjVPyFzuNPcPu5MBH56scHri4UQPjvnumE7MbtcnDYhTcnxSkL9ei/bhIVrylxEwg
 8TQoLRh7EaNhixxFyJXQm2VniAft15ZVXku1KQ5M5ILAlmldiJws7T2FyLDXQu7jZXQkUZhUKyKpdjtNRy7W+w
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 WAv50aior+FThK6nxV6pdbohDozN/C+1mB6DqFdE++w/xNgoAyW1l6zU3gESjWGOAg0VSuQA02IWXD6s7Owalg
 H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
 OjzRQozaVtKNjup1kUGLTKoLz0/i6d74eiVbxWRs54iZy5My7f2g/pIapbaE5//j2/23iifeMfK/QQXqnU/7qw
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 [71/drU9W2kKynoZKPh1OrOunK0sF4SRsgbgxdF9r0wO9ORmvN7xayxU7acRlJ/0pyEE0t0m0AJcc3djeEetL \
Pw]:gN7wo3y1ib514bl2rDp2Zub5zpw4MJARB/sXCqoOO9F/+WxYcZcuypH1BljrYyqkMbgE4rprLf/OKtCuZHEngg.
 mKQrf8HyEg5V5aU8g1Z1+eNoP2TG2Ck09I6fPVnG8sHW13u3Jp18nUVvnOtBOCrPCE01j/kFUyKcYf5kIU4ifA
 TpCbI5K7Mic6wVTmZJi1EzsZdPWXo+FbhJnvn9mCNWeJp9Sy3vnBAKm7d5E5BIrz52wkiOHlNb2px917M9cLHQ.
 rw+MMTNIk2dm46l+AppFxNChg9CvyyD5kZC5Y5CGGG3Fnwf6v/McfDI1g16bvUYZ16MnO95BiHIT39+3iX7IrA
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 PbcmBNPg4GNYySlVKnFLGW+bqW3i+XBwT1rB8cglfDAkdk3Njj3yyQiha/bFmN8jXwk4rbWgP/3PUqB/NEEwYw
 8TQoLRh7EaNhixxFyJXQm2VniAft15ZVXku1KQ5M5ILAlmldiJws7T2FyLDXQu7jZXQkUZhUKyKpdjtNRy7W+w
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 WAv50aior+FThK6nxV6pdbohDozN/C+1mB6DqFdE++w/xNgoAyW1l6zU3gESjWGOAg0VSuQA02IWXD6s7Owalg
 H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
 OjzRQozaVtKNjup1kUGLTKoLz0/i6d74eiVbxWRs54iZy5My7f2g/pIapbaE5//j2/23iifeMfK/QQXqnU/7qw
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 [71/drU9W2kKynoZKPh1OrOunK0sF4SRsgbgxdF9r0wO9ORmvN7xayxU7acRlJ/0pyEE0t0m0AJcc3djeEetL \
Pw]:gN7wo3y1ib514bl2rDp2Zub5zpw4MJARB/sXCqoOO9F/+WxYcZcuypH1BljrYyqkMbgE4rprLf/OKtCuZHEngg.
 mKQrf8HyEg5V5aU8g1Z1+eNoP2TG2Ck09I6fPVnG8sHW13u3Jp18nUVvnOtBOCrPCE01j/kFUyKcYf5kIU4ifA
 TpCbI5K7Mic6wVTmZJi1EzsZdPWXo+FbhJnvn9mCNWeJp9Sy3vnBAKm7d5E5BIrz52wkiOHlNb2px917M9cLHQ.
 (9O+ASntnOp+p3eCelqMTJDeMBWpDmrHZYzpWOmKkXhOYhUfSDWC/g/YC0goLoSSX+X4zw677WNqmc/7G5FkuHg
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 9QN7p/bfLkThpzn1zGSPROVN7zI33L5R4GZRWuin+ie/JvKGBWCABrgEOEubu/s5qdbCTIxiDSmVcgpsXeutjg)
 rw+MMTNIk2dm46l+AppFxNChg9CvyyD5kZC5Y5CGGG3Fnwf6v/McfDI1g16bvUYZ16MnO95BiHIT39+3iX7IrA
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 PbcmBNPg4GNYySlVKnFLGW+bqW3i+XBwT1rB8cglfDAkdk3Njj3yyQiha/bFmN8jXwk4rbWgP/3PUqB/NEEwYw
 8TQoLRh7EaNhixxFyJXQm2VniAft15ZVXku1KQ5M5ILAlmldiJws7T2FyLDXQu7jZXQkUZhUKyKpdjtNRy7W+w
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 WAv50aior+FThK6nxV6pdbohDozN/C+1mB6DqFdE++w/xNgoAyW1l6zU3gESjWGOAg0VSuQA02IWXD6s7Owalg
 H0D8ktokFpR1CXnubPWC8tXX0o4YM13gWrxU0FYOD1MChgxlK/CNVgJSql50IQVG82n7u86MEs/HlXsmUv6adQ
 OjzRQozaVtKNjup1kUGLTKoLz0/i6d74eiVbxWRs54iZy5My7f2g/pIapbaE5//j2/23iifeMfK/QQXqnU/7qw
 NLeFGnA9M4EWLaCsG72rNskdOPmdPQTLxdj0nFHFvOZNbbYjX5M9XCAozKnx+LE3xoAWEmH5gvl6shKmitI8yA
 [71/drU9W2kKynoZKPh1OrOunK0sF4SRsgbgxdF9r0wO9ORmvN7xayxU7acRlJ/0pyEE0t0m0AJcc3djeEetL \
Pw]:MbygIJTreBJqUXsgaojHPPqexvcExwMNGCEsrOgg8CXwC/DqaNvz86VDbKY7U797+ArY1d59g1nQt/7Z28OrmQ.
 mKQrf8HyEg5V5aU8g1Z1+eNoP2TG2Ck09I6fPVnG8sHW13u3Jp18nUVvnOtBOCrPCE01j/kFUyKcYf5kIU4ifA
 TpCbI5K7Mic6wVTmZJi1EzsZdPWXo+FbhJnvn9mCNWeJp9Sy3vnBAKm7d5E5BIrz52wkiOHlNb2px917M9cLHQ.
 (9O+ASntnOp+p3eCelqMTJDeMBWpDmrHZYzpWOmKkXhOYhUfSDWC/g/YC0goLoSSX+X4zw677WNqmc/7G5FkuHg
 wMoBuSMmJ3b/2CXua031zCVmwtLuVtXeAW0IXgmZzLRndi9MpAiEat/LusOgK9DHuAYenZWP0OKxgleUGdZzSg
 SxRDcVEicxA6uVJcbrtJi9cvmc1eWmkVnpCzCogbW1iLRlf6Eo5f9OgkTflItzS0Ct9+s+ktQyby6+feuu/4ag
 ZTrIoy36oJiB13sxwDqYcuYJHt0mpZcZMYLXCFyR3WgptCbkR99r4GOkE58K9SxKptY23mykT0BUPaw6lY3NwA)



-- 
Please use encryption. My PGP key ID is E51DFE2C.


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110321161633</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-03-21 16:16:33-0400</timestampReceived><subject>Re: [tor-dev] (revised) Proposal 180: Pluggable Transports for</subject><body>

On Wed, Mar 16, 2011 at 10:05 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; I just took a very quick look.  Generally, I like it.  ;-)
&gt;
&gt; On Tue, Mar 15, 2011 at 05:17:23PM -0400, Nick Mathewson wrote:
&gt;&gt;   To configure one of these programs, it should be sufficient simply to
&gt;&gt;   list it in your torrc.  The program tells Tor which transports it
&gt;&gt;   provides.  The Tor consensus should carry a new approved version number that
&gt;&gt;   is specific for pluggable transport; this will allow Tor to know when a
&gt;&gt;   particular transport is known to be unsafe safe or non-functional.
&gt;
&gt; I'm not sure I understand the above.

Ah, this idea didn't seem to go anywhere during the design phase.  It
might need more attention.  The original idea (IIUC) was that the
consensus should be able to recommend/disrecommend given transport
types and versions, so that if there were a nasty bug discovered in
one, we could tell folks not to use it.  If/when we finally get good
automated updates working, this ought to be less necessary.  I don't
have a good sense for whether or not it's something we want to design
and build.

I fixed up the other issues you mentioned in the git repo as of commit
eda9c36984 .  Thanks!
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110331095222</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-03-31 09:52:22-0400</timestampReceived><subject>Re: [tor-dev] Designing and implementing improved circuit-setup</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On Thu, 24 Mar 2011 01:28:42 +0100
George Kadianakis &lt;desnacked@gmail.com&gt; wrote:

&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; writes:
&gt; &gt;               &lt;SNIP: asn: Tidying up the thread a bit&gt;
&gt; &gt; On Wed, Mar 23, 2011 at 1:36 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; The first step in the Great Tor Crypto Migration is to add new CREATE2
&gt; &gt;&gt; and EXTEND2 RELAY cell types. They can be used with the existing
&gt; &gt;&gt; circuit-extension handshake and link protocol initially, but will be
&gt; &gt;&gt; extensible to support new ones.
&gt; &gt;&gt;
&gt; &gt;&gt; Further steps, all independent of each other:
&gt; &gt;&gt;
&gt; &gt;&gt; * Add 128-byte and 2048-byte RELAY cells and a circuit-configuration
&gt; &gt;&gt;   cell, initially to allow the client to change the cell size to be
&gt; &gt;&gt;   used on a circuit.
&gt; &gt;&gt;
&gt; &gt;&gt; * Refactor Tor's cryptographic primitive abstractions to accommodate
&gt; &gt;&gt;   public-key encryption primitives, public-key signature primitives,
&gt; &gt;&gt;   symmetric authenticated encryption, symmetric block encryption, and
&gt; &gt;&gt;   hashes.
&gt; &gt;&gt;
&gt; &gt;&gt; * Implement one or more new link protocols that do not constrain a
&gt; &gt;&gt;   relay's choice of identity key cryptosystem.
&gt; &gt;&gt;
&gt; &gt;&gt; Further mutually independent steps building on those above:
&gt; &gt;&gt;
&gt; &gt;&gt; * Modify the directory protocol and implementation to support relays
&gt; &gt;&gt;   with multiple identity keys.
&gt; &gt;&gt;
&gt; &gt;&gt; * Implement a new circuit-extension handshake (the part that involves
&gt; &gt;&gt;   onionskins').
&gt; &gt;&gt;
&gt; &gt;&gt; * Implement a new circuit ciphersuite (the part that mangles cell data
&gt; &gt;&gt;   so that relay A can't see what data relay C sees).
&gt; &gt;
&gt; &gt; Hm.  These steps all stretch pretty far beyond what's just described
&gt; &gt; in 3.2 of xxx-crypto-migration.  I think they're probably more than we
&gt; &gt; can promise to design before summer, and possibly more than a typical
&gt; &gt; gsoc scope all put together.
&gt; &gt;
&gt; 
&gt; This part:
&gt; &gt;&gt; * Implement a new circuit-extension handshake (the part that involves
&gt; &gt;&gt;   onionskins').
&gt; is in the xxx-crypto-migration, and it might be worthwhile to tackle
&gt; during GSoC. I'm not sure about the BEAR/LIONESS operation (are you?),
&gt; but if we are to design the new CREATE2 cells and we indeed don't
&gt; like the current way of passing DH paramaters around, maybe we should
&gt; find another protocol to do it.

Currently, we do not pass DH parameters around in the circuit-extension
protocol, just DH public keys. If we could pass new DH parameters in
that protocol, we wouldn't need new circuit-extension protocols quite
yet (although a new one would be a Good Thing anyway for performance
reasons).


&gt; Of course, Robert's other ideas are holy and everything, but I think
&gt; we should keep our goals humble so that we can produce an algorithmic
&gt; implementation plan which will allow us to try to predict an
&gt; implementation timeframe and see how many ideas we can fit into this
&gt; GSoC project.

The list I gave above was purely to indicate some of the dependencies
between crypto migration tasks.  I don't expect you to do all of them
for GSoC this summer; that list was intended to explain why you would
most likely not be able to migrate Tor to a new size or type of
identity key this summer.


&gt; For example, things that definitely must be done are: 
&gt; - Implement CREATE2 cells aiming to:
&gt;   * Upgrade onion keys.
&gt;   * Upgrade DH group
&gt;   * Upgrade hash function.
&gt; - Implement EXTEND2 cells aiming to:
&gt;   * Remove length limit, so as to be able to carry the new onion-skins and
&gt;     identity key fingerprints.
&gt; Of course all these, while having in mind the upgradability of
&gt; our design (ie. being versatile wrt the identity key)

The *entire point* of the EXTEND2 and CREATE2 cells must be to allow
future extension to new circuit and link protocols.  We *will* want to
add new circuit and link protocols in the near future, and we shouldn't
need to add a new EXTEND17 or CREATE42 cell (and spend a cell type
number) for each new protocol.


&gt; Then we can move on to:
&gt; - Design a new onion-skin protocol.
&gt; - Play with some of Robert's ideas above.
&gt; - Touch the relay protocol.
&gt; 'till the GSoC bell rings.  
&gt; 
&gt; What are your priorities on this project?
&gt;  
&gt; &gt;&gt;&gt; I'm also a little concerned about the interaction of 3.2 and 3.3
&gt; &gt;&gt;&gt; ("Relay crypto") : I'll be surprised if it turns out that we can
&gt; &gt;&gt;&gt; design a good circuit extend protocol without thinking about the
&gt; &gt;&gt;&gt; countours of a new relay protocol.   (Not that you'd have to build both
&gt; &gt;&gt;&gt; at once, but we should think about them all as we design.)
&gt; &gt;&gt;
&gt; &gt;&gt; It's actually the other way around -- we need a new EXTEND cell before
&gt; &gt;&gt; we can use a new link protocol.   (Otherwise, we would have to build in
&gt; &gt;&gt; a covert channel (i.e. a backdoor for people who want to block Tor by
&gt; &gt;&gt; handshake) in the new link protocol to indicate client and server link
&gt; &gt;&gt; protocol versions, and that really *really* sucks.)
&gt; &gt;
&gt; &gt; I'm talking about the stuff in 3.3: the relay protocol, where we
&gt; &gt; process cells.  Link protocol stuff is 3.1.
&gt; &gt;
&gt; &gt; Also, I'm talking about *design order*, not *implementation order*:
&gt; &gt; The different parts of the Tor protocol are not sufficiently
&gt; &gt; orthogonal that we can do them independently.  Thus, we need to get
&gt; &gt; most of the design changes sketched out before we can be reasonably
&gt; &gt; say that any part of the redesign does what the other parts need.

Circuit-extension handshake protocols and link protocols can be
designed independently of the rest of the protocol.  Link protocols are
reasonably independent of the stuff sent over the link, and the
proposals/ideas/xxx-crypto-requirements.txt document should specify
*all* of the requirements for a new circuit-extension handshake
protocol to not break the rest of Tor's protocols.  (We should still
dig through and annotate tor-spec.txt and rend-spec.txt with exactly
what properties each part requires of circuit handshake protocols, but
I'm quite sure I got all of those properties into
xxx-crypto-requirements.)

&gt; &gt;&gt;&gt; Maybe we should get a protocol sketch together this week if the app is
&gt; &gt;&gt;&gt; due April 8.
&gt; &gt;&gt;
&gt; &gt;&gt; Yes.   I have the EXTEND2 cell draft written; I bogged down on writing
&gt; &gt;&gt; explanatory text (I thought I didn't have enough in the draft, but
&gt; &gt;&gt; didn't know what to add).

&gt; Sharing is caring!

See attached for a nearly-finished draft.


Robert Ransom


Filename: xxx-new-create-and-extend-cells.txt
Title: Adding new, extensible CREATE, EXTEND, and related cells
Author: Robert Ransom
Created: 2010-12-27
Status: Open

Overview and Motivation:

  In Tor's current circuit protocol, every field, including the 'onion
  skin', in the EXTEND relay cell has a fixed meaning and length.
  This prevents us from extending the current EXTEND cell to support
  IPv6 relays, efficient UDP-based link protocols, larger 'onion
  keys', new circuit-extension handshake protocols, or larger
  identity-key fingerprints.  We will need to support all of these
  extensions in the near future.  This proposal specifies a
  replacement EXTEND2 cell and related cells that provide more room
  for future extension.

Design:

  FIXME - allocate command ID numbers (non-RELAY commands for CREATE2 and CREATED2; \
RELAY commands for EXTEND2 and EXTENDED2)                                        

  The CREATE2 cell contains the following payload:

        Handshake type length                 [1 byte]
        Handshake type                        [variable]
        Handshake data length                 [2 bytes]
        Handshake data                        [variable]

  The relay payload for an EXTEND2 relay cell contains the following
  payload:

        Link target specifier type length     [1 byte]
        Link target specifier type            [variable]
        Link target specifier length          [2 bytes]
        Link target specifier                 [variable]
        Handshake type length                 [1 byte]
        Handshake type                        [variable]
        Handshake data length                 [2 bytes]
        Handshake data                        [variable]

  The CREATED2 cell and EXTENDED2 relay cell contain the following
  payload:

        Handshake data length                 [2 bytes]
        Handshake data                        [variable]

  All four cell types are padded to 512-byte cells.

  When a relay X receives an EXTEND2 relay cell:

  * X finds or opens a link to the relay Y using the link target
    specifier in the EXTEND2 relay cell; if X fails to open a link, it
    replies with a TRUNCATED relay cell. (FIXME: what do we do now?)

  * X copies the handshake type and data into a CREATE2 cell and sends
    it along the link to Y.

  * If the handshake data is valid, Y replies by sending a CREATED2
    cell along the link to X; otherwise, Y replies with a TRUNCATED
    relay cell. (XXX: we currently use a DESTROY cell?)

  * X copies the contents of the CREATED2 cell into an EXTENDED2 relay
    cell and sends it along the circuit to the OP.


  A link target specifier of type "legacy" contains the following
  data:

        Relay IP address (FIXME: byte order?) [4 bytes]
        Relay OR port (FIXME: byte order?)    [2 bytes]
        Relay identity key SHA-1 digest       [20 bytes]

  These values are processed as section 5.1 of tor-spec.txt specifies
  for the current EXTEND relay cell.


  The first (client-&gt;relay) message in a handshake of type "legacy"
  contains the following data:

        Onion skin' (as in CREATE cell)      [DH_LEN+KEY_LEN+PK_PAD_LEN bytes]

  This value is generated and processed as sections 5.1 and 5.2 of
  tor-spec.txt specify for the current CREATE cell.

  The second (relay-&gt;client) message in a handshake of type "legacy"
  contains the following data:

        Relay DH public key                   [DH_LEN bytes]
        KH (see section 5.2 of tor-spec.txt)  [HASH_LEN bytes]

  These values are generated and processed as sections 5.1 and 5.2 of
  tor-spec.txt specify for the current CREATED cell.

  After successfully completing a handshake of type "legacy", the
  client and relay use the current relay cryptography protocol.

Bugs:

  This specification does not accommodate:

  * circuit-extension handshakes requiring more than one round

    No circuit-extension handshake should ever require more than one
    round (i.e. more than one message from the client and one reply
    from the relay).  We can easily extend the protocol to handle
    this, but we will never need to.

  * circuit-extension handshakes in which either message cannot fit in
    a single 512-byte cell along with the other required fields

    This can be handled by specifying a dummy handshake type whose
    data (sent from the client) consists of another handshake type and
    the beginning of the data required by that handshake type, and
    then using several (newly defined) HANDSHAKE_COMPLETION relay
    cells sent in each direction to transport the remaining handshake
    data.

    The specification of a HANDSHAKE_COMPLETION relay cell and its
    associated dummy handshake type can safely be postponed until we
    develop a circuit-extension handshake protocol that would require
    it.

  * link target specifiers that cause EXTEND2 cells to exceed 512
    bytes

    This can be handled by specifying a LONG_COMMAND relay cell type
    that can be used to transport a large virtual cell' in multiple
    512-byte cells.

    The specification of a LONG_COMMAND relay cell can safely be
    postponed until we develop a link target specifier, a RELAY_BEGIN2
    relay cell and stream target specifier, or some other relay cell
    type that would require it.


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110331205409</emailId><senderName>katmagic</senderName><senderEmail>the.magical.kat@gmail.com</senderEmail><timestampReceived>2011-03-31 20:54:09-0400</timestampReceived><subject>Re: [tor-dev] First draft: Thandy Package Format spec</subject><body>

[Attachment #2 (multipart/signed)]


On Thu, 31 Mar 2011 21:12:24 +0200
Erinn Clark &lt;erinn@torproject.org&gt; wrote:
&gt;     'install-order'
&gt;        Optional: number between 0 and 100 inclusive to indicate that this
&gt;        package must be installed before or after others.  Defaults to "50".

As I'm sure anyone who's used a system with SysV-style runlevels can attest to,
this sort of numbering scheme does not lend itself to easy modification. The
main problem with this is that one has to constantly monitor the priority of
dependent packages, and worse, that a lack of granularity in order will force
contacting the authors of other programs in order to resolve it. (This
sometimes happens, and is incredibly difficult to resolve, in package
management systems.) A better solution would be to use an Upstart-like method,
where packages to install before or after are explicitly named.

&gt;     'require-packages'
&gt;        Optional. A list of objects for all packages that must be installed
&gt;        before this package can be installed.  Each object has these fields:
&gt;         'package-name'
&gt;         'min-version-tuple'

It might be useful to have an option to specify a location or method to obtain
the package.

&gt; F.1 Configuration file updates
&gt; 
&gt;    We need a smart way to handle configuration file updates and changes in the
&gt;    future. There are several three-way merge tools available that we can
&gt; model our behavior on, or re-use the code of, such as Debian's ucf tool.

A set of scripts to upgrade configuration files to the next version would be
very useful here. This could, of course, be done in pre/post install scripts,
but it would be easier, and cleaner, to keep a number of scripts, which could
be run consecutively, if one were upgrading by more than one version, to modify
configuration files. In this way, backward-incompatible changes could be easily
implemented.

-- 
Please use encryption. My PGP key ID is E51DFE2C.

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110313032856</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-03-13 03:28:56-0400</timestampReceived><subject>[tor-dev] DefenestraTor: Throwing out Windows in Tor</subject><body>

http://www.cacr.math.uwaterloo.ca/techreports/2011/cacr2011-06.pdf

"Tor is the most widely used privacy enhancing technology for achieving
online anonymity and resisting censorship. While conventional wisdom
dictates that the level of anonymity offered by Tor increases as its
user base grows, the most significant obstacle to Tor adoption contin-
ues to be its slow performance. We seek to enhance Tor's performance
by offering techniques to control congestion and improve flow control,
thereby reducing unnecessary delays.

To reduce congestion, we first evaluate small fixed-size circuit win-
dows and a dynamic circuit window that adaptively resizes in response to
perceived congestion. While these solutions improve web page response
times and require modification only to exit routers, they generally
offer poor flow control and slower downloads relative to Tor's
current design.  To improve flow control while reducing congestion,
we implement N23, an ATM-style per-link algorithm that allows Tor
routers to explicitly cap their queue lengths and signal congestion
via back-pressure. Our results show that N23 offers better congestion
and flow control, resulting in improved web page response times and
faster page loads compared to Tor's current design and the other
window-based approaches. We also argue that our proposals do not enable
any new attacks on Tor users' privacy.
"

I haven't read it yet, but figured I'd share it with others here in
the meantime.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110318014504</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-03-18 01:45:04-0400</timestampReceived><subject>[tor-dev] Logging [Enhancement]</subject><body>

- An FYI, found while grokking, thanks.
- These various log entries could really have their format normalized sometime.
- If it's going to tell us why it's giving up in one case, it should
do so in all cases.
- The fingerprints should be printed instead of the ambigous router names.
- Eliminate personal pronouns 'We'.
- Remove 'Have'.
- Shorten seconds to sec.
- Change 'get a connection' to 'build a circuit'
- Remove quoting, parenthesis, etc. Or create, and consistently use,
parseable entries.

We tried for 15 seconds to connect to '[scrubbed]' using exit
'Unnamed'. Retrying on a new circuit.
Have tried resolving or connecting to address '[scrubbed]' at 3
different places. Giving up.
Tried for 123 seconds to get a connection to [scrubbed]:80. Giving up.
Tried for 120 seconds to get a connection to [scrubbed]:80. Giving up.
(waiting for circuit)
Tried for 120 seconds to get a connection to [scrubbed]:0. Giving up.
(waiting for socks info)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110202170202</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-02 17:02:02-0400</timestampReceived><subject>Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

On Tue, Jan 25, 2011 at 9:04 AM, Lucky Green &lt;shamrock@cypherpunks.to&gt; wrote:
&gt; On 2011-01-25 01:09, Erinn Clark wrote:
&gt;&gt; I think supporting multiple versions back is a laudable goal, and one we should
&gt;&gt; consider, but right now it's not feasible (for me, anyway, as the primary
&gt;&gt; packager with the current infrastructure). The following is my initial sketch
&gt;&gt; of the package support policy, which is an accurate snapshot of what's
&gt;&gt; currently out there (specifically for Tor and Vidalia):
&gt;
&gt; Erinn,
&gt; My feedback is that the Tor Project really, really will want a written
&gt; and published policy of how far back an OS is supposed to be supported.
&gt; Otherwise, you will get to have this discussion every time a new OS
&gt; version is released.
&gt;
&gt; Industry standard for consumer software that goes into the far corners
&gt; of the world is "current and previous major version", which has
&gt; different meanings depending on OS.

Hi, Lucky!  I generally agree with you, but I do want to point out a
point that makes me balk at applying your experience without more
consideration.

It seems to me that the "industry standard for computer consumer
software" is chosen to serve the goals of the software industry: that
is, to sell software to people who can pay for it.  As a means to that
end, commercial software enterprises sometimes additionally support
marginal userbases (those who can't pay, those who can't pay much) in
order to increase the install base of their software and provide
positive network effects for their paying customers.

We're in a slightly different position: we're achieving our mission to
the extent that lots of users -- whether they can pay or not! -- can
use our software.  Also, we want volunteers with free (to them)
bandwidth to be able to run our server software on the hardware and
software they have lying around.

I suspect that, when all is said and done, the set of operating
systems that it makes sense to support in the commercial software
industry will work out to be almost the same as the ones Tor want to
support -- but the reasoning is a little different, since industry
needs to optimize profit-per-developer-hour, and we're trying to
optimize social-benefit-per-developer-hour.

peace,
-- 
Nick
</body></email><email><emailId>20110315211723</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-03-15 21:17:23-0400</timestampReceived><subject>[tor-dev] (revised) Proposal 180: Pluggable Transports for</subject><body>

We sent out an earlier version of this, well, earlier.  Here it is
more complete and more revised.

I've tried to incorporate people's comments.  There's some worthwhile
stuff it doesn't do yet, like provide automatic and easy ways to
compose plugins.  I think it should work well enough, but more comment
is always worthwhile.

yrs, -- Nick

=====
Filename: 180-pluggable-transport.txt
Title: Pluggable transports for circumvention
Author: Jacob Appelbaum, Nick Mathewson
Created: 15-Oct-2010
Status: Open

Overview

  This proposal describes a way to decouple protocol-level obfuscation
  from the core Tor protocol in order to better resist client-bridge
  censorship.  Our approach is to specify a means to add pluggable
  transport implementations to Tor clients and bridges so that they can
  negotiate a superencipherment for the Tor protocol.

Scope

  This is a document about transport plugins; it does not cover
  discovery improvements, or bridgedb improvements.  While these
  requirements might be solved by a program that also functions as a
  transport plugin, this proposal only covers the requirements and
  operation of transport plugins.

Motivation

  Frequently, people want to try a novel circumvention method to help
  users connect to Tor bridges.  Some of these methods are already
  pretty easy to deploy: if the user knows an unblocked VPN or open
  SOCKS proxy, they can just use that with the Tor client today.

  Less easy to deploy are methods that require participation by both the
  client and the bridge.  In order of increasing sophistication, we
  might want to support:

  1. A protocol obfuscation tool that transforms the output of a TLS
     connection into something that looks like HTTP as it leaves the
     client, and back to TLS as it arrives at the bridge.
  2. An additional authentication step that a client would need to
     perform for a given bridge before being allowed to connect.
  3. An information passing system that uses a side-channel in some
     existing protocol to convey traffic between a client and a bridge
     without the two of them ever communicating directly.
  4. A set of clients to tunnel client-&gt;bridge traffic over an existing
     large p2p network, such that the bridge is known by an identifier
     in that network rather than by an IP address.

  We could in theory support these almost fine with Tor as it stands
  today: every Tor client can take a SOCKS proxy to use for its outgoing
  traffic, so a suitable client proxy could handle the client's traffic
  and connections on its behalf, while a corresponding program on the
  bridge side could handle the bridge's side of the protocol
  transformation.  Nevertheless, there are some reasons to add support
  for transportation plugins to Tor itself:

  1. It would be good for bridges to have a standard way to advertise
     which transports they support, so that clients can have multiple
     local transport proxies, and automatically use the right one for
     the right bridge.

  2. There are some changes to our architecture that we'll need for a
     system like this to work.  For testing purposes, if a bridge blocks
     off its regular ORPort and instead has an obfuscated ORPort, the
     bridge authority has no way to test it.  Also, unless the bridge
     has some way to tell that the bridge-side proxy at 127.0.0.1 is not
     the origin of all the connections it is relaying, it might decide
     that there are too many connections from 127.0.0.1, and start
     paring them down to avoid a DoS.

  3. Censorship and anticensorship techniques often evolve faster than
     the typical Tor release cycle.  As such, it's a good idea to
     provide ways to test out new anticensorship mechanisms on a more
     rapid basis.

  4. Transport obfuscation is a relatively distinct problem
     from the other privacy problems that Tor tries to solve, and it
     requires a fairly distinct skill-set from hacking the rest of Tor.
     By decoupling transport obfuscation from the Tor core, we hope to
     encourage people working on transport obfuscation who would
     otherwise not be interested in hacking Tor.

  5. Finally, we hope that defining a generic transport obfuscation plugin
     mechanism will be useful to other anticensorship projects.

Non-Goals

  We're not going to talk about automatic verification of plugin
  correctness and safety via sandboxing, proof-carrying code, or
  whatever.

  We need to do more with discovery and distribution, but that's not
  what this proposal is about.  We're pretty convinced that the problems
  are sufficiently orthogonal that we should be fine so long as we don't
  preclude a single program from implementing both transport and
  discovery extensions.

  This proposal is not about what transport plugins are the best ones
  for people to write.  We do, however, make some general
  recommendations for plugin authors in an appendix.

  We've considered issues involved with completely replacing Tor's TLS
  with another encryption layer, rather than layering it inside the
  obfuscation layer.  We describe how to do this in an appendix to the
  current proposal, though we are not currently sure whether it's a good
  idea to implement.

  We deliberately reject any design that would involve linking more code
  into Tor's process space.

Design overview

  To write a new transport protocol, an implementer must provide two
  pieces: a "Client Proxy" to run at the initiator side, and a "Server
  Proxy" to run at the server side.  These two pieces may or may not be
  implemented by the same program.

  Each client may run any number of Client Proxies.  Each one acts like
  a SOCKS proxy that accepts connections on localhost.  Each one
  runs on a different port, and implements one or more transport
  methods.  If the protocol has any parameters, they are passed from Tor
  inside the regular username/password parts of the SOCKS protocol.

  Bridges (and maybe relays) may run any number of Server Proxies: these
  programs provide an interface like stunnel: they get connections from the
  network (typically by listening for connections on the network) and relay
  them to the Bridge's real ORPort.

  To configure one of these programs, it should be sufficient simply to
  list it in your torrc.  The program tells Tor which transports it
  provides.  The Tor consensus should carry a new approved version number that
  is specific for pluggable transport; this will allow Tor to know when a
  particular transport is known to be unsafe safe or non-functional.

  Bridges (and maybe relays) report in their descriptors which transport
  protocols they support.  This information can be copied into bridge
  lines.  Bridges using a transport protocol may have multiple bridge
  lines.

  Any methods that are wildly successful, we can bake into Tor.

Specifications: Client behavior

  We extend the bridge line format to allow you to say which method
  to use to connect to a bridge.

  The new format is:
     "bridge method address:port [[keyid=]id-fingerprint] [k=v] [k=v] [k=v]"

  To connect to such a bridge, the Tor program needs to know which
  local SOCKS proxy will support the transport called "method".  It
  then connects to this proxy, and asks it to connect to
  address:port.  If [id-fingerprint] is provided, Tor should expect
  the public identity key on the TLS connection to match the digest
  provided in [id-fingerprint].  If any [k=v] items are provided,
  they are configuration parameters for the proxy: Tor should
  separate them with semicolons and put them in the user and
  password fields of the request, splitting them across the fields
  as necessary.  If a key or value value must contain a semicolon or
  a backslash, it is escaped with a backslash.

  The "id-fingerprint" field is always provided in a field named
  "keyid", if it was given.  Method names must be C identifiers.

  Example: if the bridge line is "bridge trebuchet www.example.com:3333
     rocks=20 height=5.6m" AND if the Tor client knows that the
     'trebuchet' method is provided by a SOCKS5 proxy on
     127.0.0.1:19999, the client should connect to that proxy, ask it to
     connect to www.example.com, and provide the string
     "rocks=20;height=5.6m" as the username, the password, or split
     across the username and password.

  There are two ways to tell Tor clients about protocol proxies:
  external proxies and managed proxies.  An external proxy is configured
  with
     ClientTransportPlugin method socks4 address:port [auth=X]
  or
     ClientTransportPlugin method socks5 address:port [username=X] [password=Y]
  as in
     "ClientTransportPlugin trebuchet socks5 127.0.0.1:9999".
  This example tells Tor that another program is already running to handle
  'trubuchet' connections, and Tor doesn't need to worry about it.

  A managed proxy is configured with
     ClientTransportPlugin &lt;method&gt; exec &lt;path&gt; [options]
  as in
    "ClientTransportPlugin trebuchet exec /usr/libexec/trebuchet --managed"
  This example tells Tor to launch an external program to provide a
  socks proxy for 'trebuchet' connections. The Tor client only
  launches one instance of each external program with a given set of
  options, even if the same executable and options are listed for
  more than one method.

  If instead of a transport name, the torrc lists "*" for a managed proxy,
  tor uses that proxy for all transports that it supports.  So
  "ClientTransportPlugin * exec /usr/libexec/tor/foobar" tells Tor
  that it should use the foobar plugin for everything that it supports.

  If two proxies support the same method, Tor should use whichever
  one is listed first.

  The same program can implement a managed or an external proxy: it just
  needs to take an argument saying which one to be.

  See "Managed proxy behavior" for more information on the managed
  proxy interface.

Server behavior

  Server proxies are configured similarly to client proxies.  When
  launching a proxy, the server must tell it what ORPort it has
  configured, and what address (if any) it can listen on.  The
  server must tell the proxy which (if any) methods it should
  provide if it can; the proxy needs to tell the server which
  methods it is actually providing, and on what ports.

  When a client connects to the proxy, the proxy may need a way to
  tell the server some identifier for the client address.  It does
  this in-band.

  As before, the server lists proxies in its torrc.  These can be
  external proxies that run on their own, or managedproxies that Tor
  launches.

  An external server proxy is configured as
     ServerTransportPlugin method proxy address:port param=val..
  as in
     ServerTransportPlugin trebuchet proxy 127.0.0.1:999 rocks=heavy
  The param=val pairs and the address are used to make the bridge
  configuration information that we'll tell users.

  A managed proxy is configured as
      ServerTransportPlugin method exec /path/to/binary [options]
  or
      ServerTransportPlugin * exec /path/to/binary [options]

  When possible, Tor should launch only one binary of each binary/option
  pair configured.  So if the torrc contains

     ClientTransportPlugin foo exec /usr/bin/megaproxy --foo
     ClientTransportPlugin bar exec /usr/bin/megaproxy --bar
     ServerTransportPlugin * exec /usr/bin/megaproxy --foo

  then Tor will launch the megaproxy binary twice: once with the option
  --foo and once with the option --bar.

Managed proxy interface

   When the Tor client launches a client proxy from the command
   line, it communicates via environment variables.  At a minimum,
   it sets:

      {Client and server}
      HOME, PATH -- as you'd expect.

      "STATE_LOCATION" -- a directory where the proxy should store
       state if it wants to.  This directory is not required to
       exist, but the proxy SHOULD be able to create it if it
       doesn't.  The proxy SHOULD NOT store state elsewhere.

      "MANAGED_TRANSPORT_VER=1" -- To tell the proxy which versions
       of this configuration protocol Tor supports.  Future versions
       will give a comma-separated list.  Clients MUST accept
       comma-separated lists containing any version that they
       recognize, and MUST work correctly even if some of the
       versions they don't recognize are non-numeric.

      {Client only}

      "CLIENT_TRANSPORTS" -- a comma-separated list of which methods
        this client should enable, or * if all methods should be
        enabled.  The proxy SHOULD ignore methods that it doesn't
        recognize.

      {Server only}

      "EXT_SERVER_PORT=addr:portnum" -- A port (probably on localhost) that
        speaks the extended server protocol.

      "ORPORT=addr:portnum" -- Our regular ORPort in a form suitable
        for local connections.

      "BINDADDR=addr" -- An address on which to listen for local
         connections.  This might be the advertised address, or might
         be a local address that Tor will forward ports to.  It MUST
         be an address that will work with bind().

      "SERVER_TRANSPORTS=..." -- A comma-separated list of server
          methods that the proxy should support, or *

  The transport proxy replies by writing NL-terminated lines to
  stdout.  The metaformat is

      Keyword OptArgs NL
      OptArgs = Args |
      Args = SP ArgChar | Args ArgChar
      ArgChar = Any character but NUL or NL
      Keyword = KeywordChar | Keyword KeywordChar
      KeyWordChar = All alphanumeric characters, dash, and underscore.

  Tor MUST ignore lines with keywords that it doesn't recognize.

  First, the proxy writes "VERSION 1" to say that it supports this
  protocol. It must either pick a version that Tor told it about, or
  pick no version at all, and say "ERROR no-version\n" and exit.

  The proxy should then open its ports.  If running as a client
  proxy, it should not use fixed ports; instead it should autoselect
  ports to avoid conflicts.  A client proxy should by default only
  listen on localhost for connections.

  A server proxy SHOULD try listen at a consistent port, though it
  SHOULD pick a different one if the port it last used is now allocated.

  A client or server proxy then should tell which methods it has
  made available and how.  It does this by printing zero or more
  CMETHOD and SMETHOD lines to its stdout.  These lines look like:

   CMETHOD methodname SOCKS4/SOCKS5 address:port [ARGS=arglist] \
        [OPT-ARGS=arglist]

  as in

   CMETHOD trebuchet SOCKS5 127.0.0.1:19999 ARGS=rocks,height \
              OPT-ARGS=tensile-strength

  The ARGS field lists mandatory parameters that must appear in
  every bridge line for this method. The OPT-ARGS field lists
  optional parameters.  If no ARGS or OPT-ARGS field is provided,
  Tor should not check the parameters in bridge lines for this
  method.

  The proxy should print a single "CMETHODS DONE" line after it is
  finished telling Tor about the client methods it provides.  If it
  tries to supply a client method but can't for some reason, it
  should say:
    CMETHOD-ERROR methodname "Message"

  A proxy should tell Tor about the server methods it is providing
  by printing zero or more SMETHOD lines.  These lines look like:

    SMETHOD methodname address:port  [Options]

  If there's an error setting up a configured server method, the
  proxy should say:
    SMETHOD-ERROR methodname "message"

  The 'address:port' part of an SMETHOD line is the address to put
  in the bridge line.  The ARGS: part is a list of key-value pairs
  that the client needs to know.  The Options part is a list of
  space-separated K:V flags that Tor should know about.  Recognized
  options are:

      - FORWARD:1

        If this option is set, and address:port is not a publicly
        accessible address, then the bridge needs to forward some
        other address:port to address:port via upnp-helper.

      - ARGS:k=v,k=v,k=v

        If this option is set, the K=V arguments are added to the
        extrainfo document.

      - DECLARE:K=V,...

        If this option is set, all the K=V options should be
        added as extension entries to the router descriptor.  (See
        below)

      - USE-EXTPORT:1

        If this option is set, the server plugin is using the
        extended server port.

  SMETHOD and CMETHOD lines may be interspersed.  After the list
  SMETHOD line, the proxy says "SMETHODS DONE"

  The proxy SHOULD NOT tell Tor about a server or client method
  unless it is actually open and ready to use.

  Tor clients SHOULD NOT use any method from a client proxy or
  advertise any method from a server proxy UNLESS it is listed as a
  possible method for that proxy in torrc, and it is listed by the
  proxy as a method it supports.

  Proxies should respond to a single INT signal by closing their
  listener ports and not accepting any new connections, but keeping
  all connections open, then terminating when connections are all
  closed.  Proxies should respond to a second INT signal by shutting
  down cleanly.

The extended ORPort protocol.

  Server transports may need to connect to the bridge and pass
  additional information about client connections that the bridge
  would ordinarily receive from the kernel's TCP stack.  To to this,
  they connect to the "extended server port" as given in
  SERVER_PORT, sent a short amount of information, wait for a
  response, and then send the user traffic on that port.

  The extended server port protocol is as follows:

     COMMAND [2 bytes, big-endian]
     BODYLEN [2 bytes, big-endian]
     BODY [Bodylen bytes]

     Commands sent from the transport to the server are:

     [0x0000] DONE: There is no more information to give. (body ignored)

     [0x0001] USERADDR: an address:port string that represents the user's
       address.  If the transport doesn't actually do addresses,
       this shouldn't be sent.

     Replies sent from tor to the proxy are:

     [0x1001] OKAY: Send the user's traffic. (body ignored)

     [0x1002] DENY: Tor would prefer not to get more traffic from
       this address for a while. (body ignored)

  [We could also use an out-of-band signalling method to tell Tor
  about client addresses, but that's a historically error-prone way
  to go about annotating connections.]

Advertising bridge methods:

  Bridges put the 'method' lines in their extra-info documents.

     method SP methodname SP address:port SP arglist NL

  The address:port parse are as returned from an SMETHOD line.  The
  arglist is a K=V,... list as retuned in the ARGS part of the
  SMETHOD line.

  If the SMETHOD line includes a DECLARE: part, the routerinfo gets
  a new line:

     method-info SP methodname SP arglist NL

Bridge authority behavior

  We need to specify a way to test different transport methods that
  bridges claim to support.  We should test as many as possible.  We
  should NOT require that we have a way to tra

Bridgedb behavior:

  Bridgedb can, given a set of router descriptors and their
  corresponding extrainfo documents, generate a set of bridge lines
  for each descriptor.  Bridgedb may want to avoid handing out
  methods that seem to get bridges blocked quickly.

Implementation plan

  First, we should implement per-bridge socks settings (as
  described above in "manually configuring a client proxy for a
  bridge") and the extended-server-port mechanism.  This will let
  bridges run transport proxies such that they can hand-generate
  bridge lines to give to clients for testing.

  Once that's done, we can improve usability a little bit by
  implementing external proxies.  Once that's done, we can see if we
  need any managed proxies, or if the whole idea there is silly.

  If we do, the next most important part seems to be getting
  the client-side automatic part written.  And once that's done, we
  can evaluate how much of the server side is easy for people to do
  and how much is hard.

  The "obfsproxy" obfuscating proxy is a likely candidate for an
  initial transport, as is Steven Murdoch's http thing or something
  similar.

Notes on plugins to write:

   We should ship a couple of null plugin implementations in one or two
   popular, portable languages so that people get an idea of how to
   write the stuff.

   1. We should have one that's just a proof of concept that does
      nothing but transfer bytes back and forth.

   1. We should not do a rot13 one.

   2. We should implement a basic proxy that does not transform the bytes at all

   1. We should implement DNS or HTTP using other software (as goodesll
      did years ago with DNS) as an example of wrapping existing code into
      our plugin model.

   2. The obfuscated-ssh superencipherment is pretty trivial and pretty
   useful.  It makes the protocol stringwise unfingerprintable.

      1. Nick needs to be told firmly not to bikeshed the obfuscated-ssh
        superencipherment too badly

         1. Go ahead, bikeshed my day

   1. If we do a raw-traffic proxy, openssh tunnels would be the logical choice.

Appendix: recommendations for transports

  Be free/open-source software.  Also, if you think your code might
  someday do so well at circumvention that it should be implemented
  inside Tor, it should use the same license as Tor.

  Use libraries that Tor already requires. (You can rely on openssl and
  libevent being present if current Tor is present.)

  Be portable: most Tor users are on Windows, and most Tor developers
  are not, so designing your code for just one of these platforms will
  make it either get a small userbase, or poor auditing.

  Think secure: if your code is in a C-like language, and it's hard to
  read it and become convinced it's safe, then it's probably not safe.

  Think small: we want to minimize the bytes that a Windows user needs
  to download for a transport client.

  Avoid security-through-obscurity if possible.  Specify.

  Resist trivial fingerprinting: There should be no good string or regex
  to search for to distinguish your protocol from protocols permitted by
  censors.

  Imitate a real profile: There are many ways to implement most
  protocols -- and in many cases, most possible variants of a given
  protocol won't actually exist in the wild.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110316140536</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-03-16 14:05:36-0400</timestampReceived><subject>Re: [tor-dev] (revised) Proposal 180: Pluggable Transports for</subject><body>

I just took a very quick look.  Generally, I like it.  ;-)

On Tue, Mar 15, 2011 at 05:17:23PM -0400, Nick Mathewson wrote:
&gt;   To configure one of these programs, it should be sufficient simply to
&gt;   list it in your torrc.  The program tells Tor which transports it
&gt;   provides.  The Tor consensus should carry a new approved version number that
&gt;   is specific for pluggable transport; this will allow Tor to know when a
&gt;   particular transport is known to be unsafe safe or non-functional.

I'm not sure I understand the above.

&gt;       "MANAGED_TRANSPORT_VER=1" -- To tell the proxy which versions
&gt;        of this configuration protocol Tor supports.  Future versions
&gt;        will give a comma-separated list.  Clients MUST accept
&gt;        comma-separated lists containing any version that they
&gt;        recognize, and MUST work correctly even if some of the
&gt;        versions they don't recognize are non-numeric.

Then you need to say what the valid characters in any future version
numbers can be.

&gt; Bridge authority behavior
&gt; 
&gt;   We need to specify a way to test different transport methods that
&gt;   bridges claim to support.  We should test as many as possible.  We
&gt;   should NOT require that we have a way to tra

This paragraph is truncated.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110323175959</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-03-23 17:59:59-0400</timestampReceived><subject>[tor-dev] Designing and implementing improved circuit-setup</subject><body>

Quoting the whole message in my reply, since we're moving this to
tor-dev where it belongs.

On Wed, Mar 23, 2011 at 1:36 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On Wed, 23 Mar 2011 12:54:17 -0400
&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt;
&gt;&gt; On Wed, Mar 23, 2011 at 8:10 AM, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt;&gt; &gt; Hey Robert and Nick,
&gt;&gt; &gt;
&gt;&gt; &gt; I hate bureaucratic procedures and yet I have to send my GSoC
&gt;&gt; &gt; application 'till the 8th of April; so I want to get done with it.
&gt;&gt; &gt;
&gt;&gt; &gt; My application should have "a project proposal, why you'd like to
&gt;&gt; &gt; execute on this particular project, and the reason you're the best
&gt;&gt; &gt; individual to do so." (that was taken from GSoC FAQ).
&gt;&gt; &gt;
&gt;&gt; &gt; So regarding the project proposal, I talked with Robert yesterday and he
&gt;&gt; &gt; told me:
&gt;&gt; &gt; 02:18:24 &lt;rransom&gt; asn: Implementing the new circuit protocol will be
&gt;&gt; &gt;                   a good GSoC project for you. I think identity key
&gt;&gt; &gt;                   migration (and thus link protocol migration) will
&gt;&gt; &gt;                   require too much beyond the new circuit protocol.
&gt;&gt; &gt; I suppose that by "new circuit protocol" you mean the section 3.2 of
&gt;&gt; &gt; xxx-crypto-migration.txt, Robert.
&gt;&gt; &gt;
&gt;&gt; &gt; How do you feel about this, Nick?
&gt;&gt;
&gt;&gt; It could be helpful.  I don't have a good sense of how much work this
&gt;&gt; would be, since I don't have a good sense of what the new protocol
&gt;&gt; would actually be.  Robert -- how would you think this would break
&gt;&gt; down into a summer's worth of work?
&gt;
&gt; The first step in the Great Tor Crypto Migration is to add new CREATE2
&gt; and EXTEND2 RELAY cell types. They can be used with the existing
&gt; circuit-extension handshake and link protocol initially, but will be
&gt; extensible to support new ones.
&gt;
&gt; Further steps, all independent of each other:
&gt;
&gt; * Add 128-byte and 2048-byte RELAY cells and a circuit-configuration
&gt;  cell, initially to allow the client to change the cell size to be
&gt;  used on a circuit.
&gt;
&gt; * Refactor Tor's cryptographic primitive abstractions to accommodate
&gt;  public-key encryption primitives, public-key signature primitives,
&gt;  symmetric authenticated encryption, symmetric block encryption, and
&gt;  hashes.
&gt;
&gt; * Implement one or more new link protocols that do not constrain a
&gt;  relay's choice of identity key cryptosystem.
&gt;
&gt; Further mutually independent steps building on those above:
&gt;
&gt; * Modify the directory protocol and implementation to support relays
&gt;  with multiple identity keys.
&gt;
&gt; * Implement a new circuit-extension handshake (the part that involves
&gt;  onionskins).
&gt;
&gt; * Implement a new circuit ciphersuite (the part that mangles cell data
&gt;  so that relay A can't see what data relay C sees).

Hm.  These steps all stretch pretty far beyond what's just described
in 3.2 of xxx-crypto-migration.  I think they're probably more than we
can promise to design before summer, and possibly more than a typical
gsoc scope all put together.

&gt;&gt; I'm also a little concerned about the interaction of 3.2 and 3.3
&gt;&gt; ("Relay crypto") : I'll be surprised if it turns out that we can
&gt;&gt; design a good circuit extend protocol without thinking about the
&gt;&gt; countours of a new relay protocol.  (Not that you'd have to build both
&gt;&gt; at once, but we should think about them all as we design.)
&gt;
&gt; It's actually the other way around -- we need a new EXTEND cell before
&gt; we can use a new link protocol.  (Otherwise, we would have to build in
&gt; a covert channel (i.e. a backdoor for people who want to block Tor by
&gt; handshake) in the new link protocol to indicate client and server link
&gt; protocol versions, and that really *really* sucks.)

I'm talking about the stuff in 3.3: the relay protocol, where we
process cells.  Link protocol stuff is 3.1.

Also, I'm talking about *design order*, not *implementation order*:
The different parts of the Tor protocol are not sufficiently
orthogonal that we can do them independently.  Thus, we need to get
most of the design changes sketched out before we can be reasonably
say that any part of the redesign does what the other parts need.


&gt;&gt; Maybe we should get a protocol sketch together this week if the app is
&gt;&gt; due April 8.
&gt;
&gt; Yes.  I have the EXTEND2 cell draft written; I bogged down on writing
&gt; explanatory text (I thought I didn't have enough in the draft, but
&gt; didn't know what to add).
&gt;
&gt;
&gt;&gt; Either way, I think this might be drifting into design work, so if
&gt;&gt; there are no objections, I'd suggest that we follow up on the tor-dev
&gt;&gt; mailing list. :)
&gt;
&gt; Good idea.
&gt;
&gt;
&gt; Robert Ransom
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110331191224</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-03-31 19:12:24-0400</timestampReceived><subject>[tor-dev] First draft: Thandy Package Format spec</subject><body>

[Attachment #2 (multipart/signed)]


Also available here:
https://gitweb.torproject.org/erinn/thandy.git/blob/refs/heads/thp-draft-spec:/specs/thp-first-draft.txt

Title: Specification for a TBB/Thandy package format.
Status: Draft
Authors: nickm, erinn
Started-On: 9 Feb 2011
Finished-On:

Introduction

   On some platforms, in some environments, Thandy can use existing
   platform-provided mechanisms for packages.  But for the Tor Browser Bundle, and
   for Windows, we can't use built-in packaging systems (because they put data in
   a database or registry, because they require root).  

Requirements, Goals:

   Thandy has these requirements for a packaging system:
     - It needs to be able to install/upgrade packages.
     - It needs to be able to check which version of a package is installed

   For use in TBB, we we need a few more features:
     - It needs to be able to remove packages
     - It needs to be able to leave cofiguration files alone when upgrading
     
   To use this right, Thandy needs these features:
     - download packages as-needed in the background
     - report when packages are ready to install
     - Have a way to upgrade the TBB as it restarts

   To avoid big problems, package installation needs these features:
     - Idempotence
     - Validatability

     - Spending as little time as possible in non-functional states.  (We can't
       get true atomicity on some OSs, but we should get as much as reasonable
       as we can.)

Nongoals:

   This is a packagesystem for TBB and similar things for use with Thandy.  It
   is not a more general system, a replacement for rpm/deb, an all-purpose
   software distribution mechanism, or a dessert topping.

   This is not the spec for Thandy.
   
   This is not a spec for interfaces to Thandy. It lists some interfaces that
   are necessary but it doesn't explain how they work.

   This is not the spec for any modes of operation for thandy, interfaces to
   thandy, or a thandy net installer.  We need specs for those, of course.

   Though this document has suggestions on how to make good packages and install
   them well, there may be additional requirements for a high-quality installer
   not listed here.  We're trying to design this system to _support_ being the
   most solid tool it can be, but we're not trying to figure out every possible
   implementation detail here.

Mode of operation:

   While TBB is running, Vidalia should periodically launch Thandy, telling it,
   "Fetch packages as needed" or "Tell me if you could fetch packages."

   While TBB is running, Vidalia should periodically launch Thandy, asking it,
   "Are there packages downloaded and ready to install?"  If so, it should tell
   the user.

   When TBB first starts, it should start a launcher program that asks Thandy,
   "Are there packages downloaded and ready to install?"  If so, it should tell
   Thandy to install them.

   To make Thandy and the launcher self-upgrade, here's a two-step process: the
   install process installs new stuff into a new directory to the side of the old
   directory, and then launches a new "replacer" program to move the new stuff
   over the old stuff.  The replacer, when it's done, re-launches the launcher.

     "It's not pretty, and you can't dance to it." - Frank Zappa

The "thandy installable" file format:

   The file metaformat is a zip file, with the file extension .thp.  It has these directories:
   content/
   meta/

   The "content" tree has the actual package contents, in a directory layout
   mirroring the layout of the installed package.  The "meta" tree has information
   about the package.

   The meta tree has one required file, "package.json".  Its contents are a
   single json object, with the following required fields:

   'format-version'
       The number 1.  An installer SHOULD NOT try to install a package with a
       format-version that it doesn't recognize.

   'manifest'
       A list of files relative to the thp's content directory.  Each file is an
       object with these fields:
	 'name': the name of the file relative to thp's content directory
	 'digest': optionally, a 2-tuple of a digest algorithm and a
           hexadecimal digest value.  The following algorithms are supported: SHA256.
          'length': optionally, the length of the file in bytes
	 'isconfig': optionally, a boolean.  If it is present and true, this
            file is considered "configuration".

    'package-name'
       The name of this package.  There shouldn't be two packages with the same
       name installed at once in the same hierarchy.  Ex: "Tor".

    'package-version'
       The version of the package as a human-readable string.  This should
       include both the version of the thing being packaged, and the version of of the
       package itself.  Ex: "0.2.2.35-rc-7" is the seventh release of a thp file for
       Tor 0.2.2.35-rc.

    'package-version-tuple'
       The version of the package as a list of numbers and strings such that a
       lexical comparison of two package version tuples is a   correct version
       comparison.  Ex: [ 0, 2, 2, 35, "rc", 7 ]

    'timestamp'
       The time when this thp was generated, as a YYYY-MM-DD HH:MM:SS string,
       relative to UTC.  Ex: "2011-03-02 17:33:07"

    'additional-files'
       Optional: A list of files or file sets relative to the install root, to
       decribe files that the package is responsible for, even if they're not
       distributed with the package.  This is used to kill off temporary and cache
       files on uninstall.  Each file is an object with these fields: 'name': The name
       of the file relative to the install root.  This name may contain "*" and "**"
       file-globbing patterns.  'isconfig': as for manifest.

    'install-order'
       Optional: number between 0 and 100 inclusive to indicate that this
       package must be installed before or after others.  Defaults to "50".

    'options'
       Optional: a map from option strings to values.  Known options are:
        'cycle-install': This package should be installed to a separate
         install root from the currently installed package, then moved over.

    'platform'
       Optional. The OS and CPU type that this package is for.

    'require-features'
       Optional. A list of strings naming installer features that the installer
       needs to support to install this package correctly. An installer SHOULD NOT try
       to install the package if it does not recognize and support all members of this
       list.  Ex: [ "pythonscripts" ]

    'require-packages'
       Optional. A list of objects for all packages that must be installed
       before this package can be installed.  Each object has these fields:
        'package-name'
        'min-version-tuple'

   'scripts'
       Optional: a map from scripting language to set of scripts.  Supported
       scripting languages are python2, sh, none.  (We can add more later.)  If the
       'scripts' field is present, the installer SHOULD NOT install the package unless
       it supports one or more of the scripting languages.  Each set of scripts
       contains one or more of the following fields: 'checkinst' 'preinst' 'postinst'
       'prerm' 'postrm' Each names a file relative to meta/scripts in the thp zip
       file.

   Implementations SHOULD NOT generate other files or subdirectories of the main
   zip root directory; implementations MUST ignore files and subdirectories that
   they do not recognize.

The package database:

   The installer keeps a directory that contains files describing the status of
   the packages we have installed.  It has a subdirectory: "pkg-status".

   "pkg-status" has, for each package, two files: packagename.json, and
   packagename.status.  Optionally, it has a packagename.json.new file.

   The packagename.json file contains a copy of the package.json file from
   the most recent successfully installed version of the the package.  The
   packagename.status file contains a json object containing at least the field
   'status' set to one of the following: "INSTALLED", "IN-PROGRESS".  If a package
   install or upgrade is in-progress, packagename.json.new has the package.json
   file from the new version of the package.

Scripts:

   Each script should be callable by a language- and platform-specific calling
   convention for invoking a script with named arguments.  The arguments to the
   script are:

       THP_PACKAGE_NAME
       THP_OLD_VERSION (absent if we are doing a fresh installation)
       THP_NEW_VERSION
       THP_OLD_INSTALL_ROOT
       THP_INSTALL_ROOT
       THP_JSON_FILE
       THP_VERBOSE (flag: "1" if the script should log verbosely.)
       THP_PURGE (flag: "1" if we are doing a remove and we want to get rid of
       absolutely everything.)
       THP_TEMP_DIR

   For sh and python2 scripts, these arguments are passed as environment variables.

   Scripts need a way to signal success or failure.  For sh and python2 scripts,
   this is done via return value.

   The 'none' script type must never have any scripts.  Installers should never
   choose it if they support any other script type: it only exists to tell the
   installer that the scripts are optional.

Directories:

   All installation happens relative to a single "install root".
   
   Thandy maintains a cache directory of its own, containing (among other
   things) downloaded thp files.
   
   The thp installer has a database directory explaining package status.

Steps of operation:

   Checking for and downloading packages is done by thandy, and out-of-scope
   here, except inasmuch as Thandy needs the thp installer to say which version
   (if any) of package X is installed.  The installer can do this by looking at
   the X.status file and the X.json file.

   To validate a package, the thp installer verifies that all files listed in
   the manifest are in fact installed with the sizes and digests listed, unless
   they are config files.

   {THIS NEXT PART IS A DRAFT AND NEEDS MORE THOUGHT! IT COULD BE WAY MORE ATOMIC}

   Installing and updating a downloaded package is done by Thandy teling the thp
   installer, "install/update these packages" with a list of thp files. To do
   this, the installer:

      * Grabs a lockfile.
      * Finds the current version, if any, of all of the packages.
      * Runs the checkinst script if present for every package that might need
        installing or updating.  If any fails, the update can't happen.
      * For each package, sorted in topological order by 'requires'
        relationships, with ties broken by 'install-order' fields:
        * Overwrite the status file for the package in the database, changing
          the status to "IN-PROGRESS". Copy the package's package.json file to
          packagename.json.new in the database.
        * Run the package's preinst script.  If that fails, abort.
        * Unpack all files in the package's content fork to their target
          locations.  If files tagged 'config' are present, ignore them.
        * If any files are listed in the manifest for the old version of the
          package but not for the new version, and they are not config files,
          remove them.  (Have an option to override this?)
        * Run the postinst script
        * Replace the packagename.json file with the packagename.json.new file.
        * Change the package status to "INSTALLED".

    CHANGES TO MAKE TO THE INSTALL PROCESS ABOVE:
      - Instead of overwrite-as-we-go, perhaps have overwrite as the very last step?
      - Perhaps checkpoint all files first for easy rollback?
      - Specify how to do the cycle-install feature.

    "Is it... atomic?"
    "Yes!  VERY atomic!"
        -- The 5000 Fingers of Dr T


Future directions and open questions:

F.1 Configuration file updates

   We need a smart way to handle configuration file updates and changes in the
   future. There are several three-way merge tools available that we can model our
   behavior on, or re-use the code of, such as Debian's ucf tool. 

F.1 Binary patching
   
   There are auto-update tools (courgette for Chrome, as an example) which do
   smart binary patching, thus often drastically reducing the download time of
   updates. When the tool is more mature, we should look into ways to do this.



[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110202222639</emailId><senderName>Bjarni_Rnar_Einarsson</senderName><senderEmail>bre@pagekite.net</senderEmail><timestampReceived>2011-02-02 22:26:39-0400</timestampReceived><subject>Tor and an HTTPS server sharing port 443 (was: Re: xxx-draft-spec-for-TLS-normalization.txt)</subject><body>

2011/2/2 Bjarni Rnar Einarsson &lt;bre@pagekite.net&gt;

&gt; 2011/2/2 Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt;
&gt;&gt; Hi Bjarni!
&gt;&gt;
&gt;&gt; Is there any reason that you can't route SSL/TLS traffic to Tor for all
&gt;&gt; non-SNI requests? Another thing that might work is knowing that all Tor
&gt;&gt; certificates currently end in .net. So while they're random, it's
&gt;&gt; certainly possible to know when someone explicitly wants to reach a
&gt;&gt; different server you certainly know about and isn't in your allowed
&gt;&gt; lookup table. Anything else can be routed to Tor.
&gt;&gt;
&gt;
&gt; This would work, but the "default fallback" is somewhat of a coveted
&gt; position as there are lots of web browsers out there that don't send SNI. So
&gt; in a shared environment you want to define your "favorite" web-site as the
&gt; default fall-back, not Tor.
&gt;
&gt; I suppose I could add a feature to Pagekite where the default is different
&gt; for requests with SNI from requests without... best add that to the list, I
&gt; guess. :-)
&gt;

OK, I think I've got the required support in pagekite.py for this - it only
took 3 lines of tweaks, unless I'm overlooking something. :-)

I haven't got an entry node up and running to test this myself, and am
getting on a plane to FOSDEM in the morning so I have to go pack now... but
it works for normal HTTPS. If anyone wants to help out and test this on a
real entry node, that would save me the hassle, otherwise I'll get around to
it myself after the conference and report back.

The code is here:
https://github.com/pagekite/PyPagekite/raw/main/pagekite.py
Run it like this:

sudo pagekite.py --clean \
   --isfrontend \
   --ports=443 \
   --protos=https \
   --runas=nobody:nogroup \
   --tls_default=foo.com \
   --backend=https:foo.com:localhost:1443: \
   --backend=https:unknown:localhost:1337:

This should proxy browsers requestiong foo.com and old browsers without SNI
to localhost:1443, but any other SNI bearing request will get proxied to
port 1337, which is where one would put Tor in this configuration.

Yeah, I'm asking you to run a gigantic python program as root... sorry about
that! Only way I know to get port 443... :-)

-- 
Bjarni R. Einarsson
The Beanstalks Project ehf.

Making personal web-pages fly: http://pagekite.net/

[Attachment #3 (text/html)]

2011/2/2 Bjarni Rnar Einarsson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:bre@pagekite.net"&gt;bre@pagekite.net&lt;/a&gt;&gt;&lt;/span&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; 2011/2/2 Jacob \
Appelbaum &lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:jacob@appelbaum.net" \
target="_blank"&gt;jacob@appelbaum.net&lt;/a&gt;&gt;&lt;/span&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
class="im"&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt;

&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;Hi Bjarni!&lt;br&gt;&lt;/div&gt;&lt;/div&gt;
&lt;br&gt;
Is there any reason that you can't route SSL/TLS traffic to Tor for all&lt;br&gt;
non-SNI requests? Another thing that might work is knowing that all Tor&lt;br&gt;
certificates currently end in .net. So while they're random, it's&lt;br&gt;
certainly possible to know when someone explicitly wants to reach a&lt;br&gt;
different server you certainly know about and isn't in your allowed&lt;br&gt;
lookup table. Anything else can be routed to Tor.&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;This \
would work, but the "default fallback" is somewhat of a coveted position as \
there are lots of web browsers out there that don't send SNI. So in a shared \
environment you want to define your "favorite" web-site as the default \
fall-back, not Tor.&lt;br&gt;

&lt;br&gt;I suppose I could add a feature to Pagekite where the default is different for \
requests with SNI from requests without... best add that to the list, I guess. \
:-)&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;OK, I think I've got the required \
support in pagekite.py for this - it only took 3 lines of tweaks, unless I'm \
overlooking something. :-)&lt;br&gt; &lt;br&gt;I haven't got an entry node up and running to \
test this myself, and am getting on a plane to FOSDEM in the morning so I have to go \
pack now... but it works for normal HTTPS. If anyone wants to help out and test this \
on a real entry node, that would save me the hassle, otherwise I'll get around to \
it myself after the conference and report back.&lt;br&gt; &lt;br&gt;The code is here: &lt;a \
href="https://github.com/pagekite/PyPagekite/raw/main/pagekite.py"&gt;https://github.com/pagekite/PyPagekite/raw/main/pagekite.py&lt;/a&gt;&lt;br&gt;
 Run it like this:&lt;br&gt;&lt;br&gt;sudo pagekite.py --clean \&lt;br&gt;   --isfrontend \&lt;br&gt;   \
                --ports=443 \&lt;br&gt;
   --protos=https \&lt;br&gt;   --runas=nobody:nogroup \&lt;br&gt;   --tls_default=&lt;a \
                href="http://foo.com"&gt;foo.com&lt;/a&gt; \&lt;br&gt;
   --backend=https:foo.com:localhost:1443: \&lt;br&gt;   \
--backend=https:unknown:localhost:1337:&lt;br&gt;&lt;br&gt;This should proxy browsers requestiong \
&lt;a href="http://foo.com"&gt;foo.com&lt;/a&gt; and old browsers without SNI to localhost:1443, \
but any other SNI bearing request will get proxied to port 1337, which is where one \
would put Tor in this configuration.&lt;br&gt; &lt;/div&gt;&lt;/div&gt;&lt;br&gt;Yeah, I'm asking you to \
run a gigantic python program as root... sorry about that! Only way I know to get \
port 443... :-)&lt;br&gt; &lt;br&gt;-- &lt;br&gt;Bjarni R. Einarsson&lt;br&gt;The Beanstalks Project \
ehf.&lt;br&gt;&lt;br&gt;Making personal web-pages fly: &lt;a href="http://pagekite.net/" \
target="_blank"&gt;http://pagekite.net/&lt;/a&gt;&lt;br&gt;



</body></email><email><emailId>20110324002842</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-03-24 00:28:42-0400</timestampReceived><subject>Re: [tor-dev] Designing and implementing improved circuit-setup</subject><body>

Nick Mathewson &lt;nickm@freehaven.net&gt; writes:
&gt;               &lt;SNIP: asn: Tidying up the thread a bit&gt;
&gt; On Wed, Mar 23, 2011 at 1:36 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt;&gt;
&gt;&gt; The first step in the Great Tor Crypto Migration is to add new CREATE2
&gt;&gt; and EXTEND2 RELAY cell types. They can be used with the existing
&gt;&gt; circuit-extension handshake and link protocol initially, but will be
&gt;&gt; extensible to support new ones.
&gt;&gt;
&gt;&gt; Further steps, all independent of each other:
&gt;&gt;
&gt;&gt; * Add 128-byte and 2048-byte RELAY cells and a circuit-configuration
&gt;&gt;  cell, initially to allow the client to change the cell size to be
&gt;&gt;  used on a circuit.
&gt;&gt;
&gt;&gt; * Refactor Tor's cryptographic primitive abstractions to accommodate
&gt;&gt;  public-key encryption primitives, public-key signature primitives,
&gt;&gt;  symmetric authenticated encryption, symmetric block encryption, and
&gt;&gt;  hashes.
&gt;&gt;
&gt;&gt; * Implement one or more new link protocols that do not constrain a
&gt;&gt;  relay's choice of identity key cryptosystem.
&gt;&gt;
&gt;&gt; Further mutually independent steps building on those above:
&gt;&gt;
&gt;&gt; * Modify the directory protocol and implementation to support relays
&gt;&gt;  with multiple identity keys.
&gt;&gt;
&gt;&gt; * Implement a new circuit-extension handshake (the part that involves
&gt;&gt;  onionskins).
&gt;&gt;
&gt;&gt; * Implement a new circuit ciphersuite (the part that mangles cell data
&gt;&gt;  so that relay A can't see what data relay C sees).
&gt;
&gt; Hm.  These steps all stretch pretty far beyond what's just described
&gt; in 3.2 of xxx-crypto-migration.  I think they're probably more than we
&gt; can promise to design before summer, and possibly more than a typical
&gt; gsoc scope all put together.
&gt;

This part:
&gt;&gt; * Implement a new circuit-extension handshake (the part that involves
&gt;&gt;  onionskins).
is in the xxx-crypto-migration, and it might be worthwhile to tackle
during GSoC. I'm not sure about the BEAR/LIONESS operation (are you?),
but if we are to design the new CREATE2 cells and we indeed don't
like the current way of passing DH paramaters around, maybe we should
find another protocol to do it.

Of course, Robert's other ideas are holy and everything, but I think
we should keep our goals humble so that we can produce an algorithmic
implementation plan which will allow us to try to predict an
implementation timeframe and see how many ideas we can fit into this
GSoC project.

For example, things that definitely must be done are: 
- Implement CREATE2 cells aiming to:
  * Upgrade onion keys.
  * Upgrade DH group
  * Upgrade hash function.
- Implement EXTEND2 cells aiming to:
  * Remove length limit, so as to be able to carry the new onion-skins and
    identity key fingerprints.
Of course all these, while having in mind the upgradability of
our design (ie. being versatile wrt the identity key)

Then we can move on to:
- Design a new onion-skin protocol.
- Play with some of Robert's ideas above.
- Touch the relay protocol.
'till the GSoC bell rings.  

What are your priorities on this project?
 
&gt;&gt;&gt; I'm also a little concerned about the interaction of 3.2 and 3.3
&gt;&gt;&gt; ("Relay crypto") : I'll be surprised if it turns out that we can
&gt;&gt;&gt; design a good circuit extend protocol without thinking about the
&gt;&gt;&gt; countours of a new relay protocol.  (Not that you'd have to build both
&gt;&gt;&gt; at once, but we should think about them all as we design.)
&gt;&gt;
&gt;&gt; It's actually the other way around -- we need a new EXTEND cell before
&gt;&gt; we can use a new link protocol.  (Otherwise, we would have to build in
&gt;&gt; a covert channel (i.e. a backdoor for people who want to block Tor by
&gt;&gt; handshake) in the new link protocol to indicate client and server link
&gt;&gt; protocol versions, and that really *really* sucks.)
&gt;
&gt; I'm talking about the stuff in 3.3: the relay protocol, where we
&gt; process cells.  Link protocol stuff is 3.1.
&gt;
&gt; Also, I'm talking about *design order*, not *implementation order*:
&gt; The different parts of the Tor protocol are not sufficiently
&gt; orthogonal that we can do them independently.  Thus, we need to get
&gt; most of the design changes sketched out before we can be reasonably
&gt; say that any part of the redesign does what the other parts need.
&gt;
&gt;
&gt;&gt;&gt; Maybe we should get a protocol sketch together this week if the app is
&gt;&gt;&gt; due April 8.
&gt;&gt;
&gt;&gt; Yes.  I have the EXTEND2 cell draft written; I bogged down on writing
&gt;&gt; explanatory text (I thought I didn't have enough in the draft, but
&gt;&gt; didn't know what to add).
&gt;&gt;
&gt;&gt;

Sharing is caring!

&gt;&gt;&gt; Either way, I think this might be drifting into design work, so if
&gt;&gt;&gt; there are no objections, I'd suggest that we follow up on the tor-dev
&gt;&gt;&gt; mailing list. :)
&gt;&gt;
&gt;&gt; Good idea.
&gt;&gt;
&gt;&gt;
&gt;&gt; Robert Ransom
&gt;&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110202221151</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-02-02 22:11:51-0400</timestampReceived><subject>Re: Proposal 176: Proposed version-3 link handshake for Tor</subject><body>

Nick Mathewson &lt;nickm@freehaven.net&gt; writes:

&gt; 2) We should make it harder to probe for a Tor server.  Right
&gt; now, you can just do a handshake with a server,
&gt; renegotiate, then see if it gives you a VERSIONS cell.
&gt; That's no good.
&gt; 

Since a way to avoid Tor server probing was not mentioned in the proposal
and the problem mentioned above is still present (although now the
prober sends a VERSIONS cell and waits for reply), I think we need to
define our probe-resistance.

Do we need all Tor servers, including normal relays and exit servers,
to be probe-resistant or just the bridges?

Since the Tor network is public - as far as the relays and exits are
concerned - making it probe-resistant would serve little purpose,
except for providing flexibility in case the network scheme changes in
the future [1].

On the other hand, probe-resistant bridges are essential - especially
with the increasing role of Tor as a circumvention tool. 
The good thing with this is that bridge addresses are already provided
out of band, which allows us to also provide non-public information to
bridge users that will help anti-probing [2].

So do we care about a probe-resistant Tor network, or do we keep the
probe resistance for the circumvention tool part of Tor?

[1]:
https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TorFAQ#YoushouldhidethelistofTorrelayssopeoplecantblocktheexits.


[2]: 
For example, a silly scheme would be to provide the bridge user with
another field called 'secret' - basically a per-bridge hash value -
that comes with the bridge address and bridge fingerprint. The
'secret' field should be sent to the bridge on the beginning of the
cell-based part of the V3 handshake and the handshake should proceed
only if the 'secret' field matches the 'secret' of the
bridge. Otherwise, the bridge should act accordingly as if it's
getting probed.


</body></email><email><emailId>20110203002629</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-03 00:26:29-0400</timestampReceived><subject>Re: Tor and an HTTPS server sharing port 443 (was: Re: xxx-draft-spec-for-TLS-normalization.txt)</subject><body>

2011/2/2 Bjarni Rnar Einarsson &lt;bre@pagekite.net&gt;:
 [...]
&gt; Yeah, I'm asking you to run a gigantic python program as root... sorry about
&gt; that! Only way I know to get port 443... :-)

Run on some other (nonprivileged) port, then use firewall rules to
port-forward port 443 to the port it's running on.  There are
instructions for doing this with Tor at

https://trac.torproject.org/projects/tor/wiki/TheOnionRouter/TorFAQ#HowcanImakemyrelayaccessibletopeoplestuckbehindrestrictivefirewalls


; it should be easy to adapt them as needed.

yrs,
-- 
Nick


</body></email><email><emailId>20110206221107</emailId><senderName>Foxjazz</senderName><senderEmail>fox21@foxjazz.net</senderEmail><timestampReceived>2011-02-06 22:11:07-0400</timestampReceived><subject>unsubscribe</subject><body>

Hello Or-dev,

  foxr3@foxjazz.net


-- 
Best regards,
 Foxjazz                          mailto:fox21@foxjazz.net


</body></email><email><emailId>20110207065651</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-02-07 06:56:51-0400</timestampReceived><subject>Research problem: measuring the safety of the Tor network</subject><body>

Looking for a paper topic (or a thesis topic)? Here's a Tor research area
that needs more attention. The short version is: for various diversity
metrics, how has the diversity of the Tor network changed over time? How
robust is it to change or attack? These results can help us make better
design decisions.

We'd love to work with you to help answer these questions.

Read more here:
https://blog.torproject.org/blog/research-problem-measuring-safety-tor-network

--Roger

</body></email><email><emailId>20110207071925</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-02-07 07:19:25-0400</timestampReceived><subject>Twin online developer parties on Wednesday and Thursday, 20:00 to</subject><body>

I hereby schedule twin developer parties for this coming Wednesday and
Thursday, 3pm to 5pm Eastern time, noon to 2pm Pacific time, 20:00 to
22:00 GMT. The location is the #tor-dev channel on irc.oftc.net.

For these particular parties, the only verboten topic will be broad-scale
planning and prioritizing for the future (which we'll save for the mini
dev meeting and hackathon the following week). Instead, you should bring
your current concrete development projects (especially the ones you're
having trouble making progress on) and plan to get some work done on
them and/or help others on theirs. Non-core developers are welcome too!

If you don't make it to both of them, that's fine -- that's why there
are two.

For those new to this developer party concept, I've quoted Nick's earlier
summary below.

--Roger

On Wed, Aug 04, 2010 at 02:19:39PM -0400, Nick Mathewson wrote:
&gt; Hi, folks!  This email is a heads-up about our next online
&gt; nonstructured mass developer meeting, still called a "developer party"
&gt; on the superstitious belief that if we act like it's supposed to be
&gt; fun, it will be.   The last one was fun, after all.
&gt; 
&gt; (I'm announcing this one on or-dev, since that's where people
&gt; suggested that I announce it after I announced the last one on another
&gt; list.  If you don't think these messages should be on or-dev, please
&gt; email me personally [not the list] to say so.)
&gt; 
&gt; It's going to be from 18:00 to 20:00 UTC on Monday on the #tor-dev
&gt; channel on irc.oftc.net.  That's 14:00 to 16:00 eastern, and 11:00 to
&gt; 13:00 pacific, if I can still do math with my current jetlag.
&gt; 
&gt; General notes:
&gt; * If you're not free to make it, or if you're not free to make it for
&gt; the whole time, don't worry.  There will be more of these at other
&gt; times ranging from "too late in Europe" to "too early in California".
&gt; * If you're not an actual developer on Tor, you're welcome to come and
&gt; hang out, but this is mainly a time for developers to chat and plot
&gt; and generally confab.
&gt; * We're probably not going to be "partying" for every minute of all 2
&gt; hours; think of this as a salon where people wander in and out and
&gt; take breaks to go into a corner and eat cheese or debug trac or
&gt; whatever.
&gt; * The format will probably change in the future as we get some
&gt; experience with it and learn more about what does (and doesn't) work
&gt; for us.  If having 2 open hours is too much, let's do less.
&gt; * I'm going to try to "host" this developer party.  Since you can't
&gt; serve food over IRC, and there's no need to vacuum the floor before
&gt; the party starts, I'm not quite sure what my responsibility will be
&gt; other than being around the whole time and trying to make sure the
&gt; conversation stays interesting.  I'll play it by ear.
&gt; 
&gt; peace,
&gt; -- 
&gt; Nick
</body></email><email><emailId>20110208085118</emailId><senderName>SiNA</senderName><senderEmail>sina@anarchy.cx</senderEmail><timestampReceived>2011-02-08 08:51:18-0400</timestampReceived><subject>Bridges with no DirPort failing?</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I am having issues connecting to one of my own Bridges that is only
listening on ORPort.

However when I add DirPort 9030, I am able to successfully connect to
the Bridge!

My Tor client and the 'failing Bridge' configuration:

Bridge config:
==============
log debug file /usr/local/var/log/tor/debug-2.log
RunAsDaemon 1
DataDirectory /usr/local/var/lib/tor-2
SocksPort 0
ORPort	993
ORListenAddress 50.7.249.43:993
Nickname 25bahman002
Address 50.7.249.43
RelayBandwidthRate 1000 KB  # Throttle traffic to 100KB/s (800Kbps)
RelayBandwidthBurst 5000 KB # But allow bursts up to 200KB/s (1600Kbps)
ContactInfo 4096R/0B47D56D SiNA &lt;sina AT anarchy dot cx&gt;
MyFamily 25bahman001,25bahman002,25bahman003



Tor Client debug:
================

Feb 08 00:39:22.611 [Notice] Tor v0.2.2.22-alpha (git-21b3de6cf37d4e60).
This is experimental software. Do not rely on it for strong anonymity.
(Running on Linux i686)
Feb 08 00:39:22.612 [Notice] Initialized libevent version 1.4.13-stable
using method epoll. Good.
Feb 08 00:39:22.612 [Notice] Opening Socks listener on 127.0.0.1:9050
Feb 08 00:39:22.641 [Notice] Opening Control listener on 127.0.0.1:9051
Feb 08 00:39:22.642 [Notice] Parsing GEOIP file /usr/share/tor/geoip.
Feb 08 00:39:23.973 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:23.973 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:23.974 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:39:23.974 [Info] connection_ap_make_link(): Making internal
direct tunnel to [scrubbed]:443 ...
Feb 08 00:39:23.974 [Info] onion_pick_cpath_exit(): Using requested exit
node '0000000000000000000000000000000000000000'
Feb 08 00:39:23.974 [Info] circuit_handle_first_hop(): Next router is
[scrubbed]: Router not connected (nothing is).  Connecting.
Feb 08 00:39:23.974 [Notice] Bootstrapped 5%: Connecting to directory
server.
Feb 08 00:39:23.975 [Info] connection_ap_make_link(): ... application
connection created and linked.
Feb 08 00:39:23.975 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:23.975 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:23.975 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:39:23.976 [Info] or_state_save(): Saved state to
"/home/architect/.tor/state"
Feb 08 00:39:23.976 [Info] connection_edge_process_inbuf(): data from
edge while in 'waiting for circuit' state. Leaving it on buffer.
Feb 08 00:39:23.976 [Info] connection_edge_process_inbuf(): data from
edge while in 'waiting for circuit' state. Leaving it on buffer.
Feb 08 00:39:34.993 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:34.993 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:34.994 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:39:45.020 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:45.021 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:45.021 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:39:45.044 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:45.044 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:45.045 [Info] control_event_bootstrap_problem(): Problem
bootstrapping. Stuck at 5%: Connecting to directory server. (Connection
timed out; TIMEOUT; count 1; recommendation ignore)
Feb 08 00:39:45.045 [Info] circuit_n_conn_done(): or_conn failed.
Closing circ.
Feb 08 00:39:45.045 [Info] circuit_build_failed(): Our circuit died
before the first hop with no connection
Feb 08 00:39:45.045 [Info] connection_ap_fail_onehop(): Closing one-hop
stream to '$0000000000000000000000000000000000000000/50.7.249.43'
because the OR conn just failed.
Feb 08 00:39:45.045 [Info] _connection_free(): Freeing linked Socks
connection [waiting for circuit] with 63 bytes on inbuf, 0 on outbuf.
Feb 08 00:39:45.045 [Info] connection_dir_client_reached_eof(): 'fetch'
response not all here, but we're at eof. Closing.
Feb 08 00:39:45.045 [Info] connection_dir_request_failed(): Giving up on
directory server at '50.7.249.43'; retrying
Feb 08 00:39:45.046 [Info] _connection_free(): Freeing linked Directory
connection [client reading] with 0 bytes on inbuf, 0 on outbuf.
Feb 08 00:39:56.036 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:39:56.039 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:39:56.039 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:07.060 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:07.065 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:07.065 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:18.076 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:18.077 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:18.077 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:24.088 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:24.089 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:24.089 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:29.100 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:29.101 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:29.101 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:40.120 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:40.121 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:40.121 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:40:51.137 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:40:51.138 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:40:51.138 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:02.156 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:02.157 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:02.157 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:13.168 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:13.169 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:13.169 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:24.193 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:24.193 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:24.194 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:25.193 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:25.193 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:25.194 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:35.212 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:35.214 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:35.214 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:46.233 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:46.235 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:46.235 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:41:57.261 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:41:57.261 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:41:57.261 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:08.284 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:08.285 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:08.285 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:19.316 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:19.317 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:19.317 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:26.337 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:26.337 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:26.338 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:30.344 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:30.345 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:30.345 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:41.357 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:41.357 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:41.358 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:42:52.373 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:42:52.373 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:42:52.374 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:03.389 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:03.389 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:03.390 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:14.413 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:14.414 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:14.415 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:25.432 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:25.433 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:25.434 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:27.436 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:27.439 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:27.440 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:36.448 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:36.449 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:36.450 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:47.464 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:47.465 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:47.466 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:43:58.173 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:58.173 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:58.174 [Info] connection_edge_process_inbuf(): data from
edge while in 'waiting for circuit' state. Leaving it on buffer.
Feb 08 00:43:58.480 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:43:58.481 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:43:58.481 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:09.509 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:09.509 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:09.510 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:20.520 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:20.521 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:20.521 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:28.528 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:28.529 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:28.529 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:31.532 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:31.533 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:31.533 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:42.544 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:42.545 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:42.545 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:44:53.560 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:44:53.561 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:44:53.561 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:04.581 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:04.581 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:04.582 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:15.609 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:15.609 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:15.610 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:26.624 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:26.625 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:26.625 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:29.628 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:29.629 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:29.629 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:37.636 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:37.637 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:37.637 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:48.652 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:48.653 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:48.653 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:45:58.664 [Notice] Tried for 120 seconds to get a connection
to [scrubbed]:5222. Giving up. (waiting for circuit)
Feb 08 00:45:58.691 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:58.692 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:58.692 [Info] connection_edge_process_inbuf(): data from
edge while in 'waiting for circuit' state. Leaving it on buffer.
Feb 08 00:45:59.664 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:45:59.665 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:45:59.665 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:46:10.688 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:46:10.689 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:46:10.689 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:46:21.700 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:46:21.701 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:46:21.701 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 00:46:30.717 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 00:46:30.717 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 00:46:30.718 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)

- -- 
- --
SiNA
pgp 0x0B47D56D
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQIcBAEBAgAGBQJNUQQGAAoJEJPBwXYLR9VthUQQAL7+Xnh10e7RqvhX3o+7mlJy
aqlw4iktFqoqsFHOHgDUtd0yrc9RPl7xvTAWzDUuvqVXNzrqbRZXthEI64+O+31F
GOkMFa5O6I6uvi4Pzj5ufJzANbI2vp9nxJpz5foGegORHsAHbidbrxr/crj9tIwd
5x9dUkppnHx6BbpKNpNESuiGjvDC/bc+2jZEbZof98Fw1cmxCou357X+1T4pg4y3
45tU6ftKfR/AkCZ0bgrL19W+2MOeEb/1fbBPzecgGnFV7fe2t+wy0D0lwr9IbKDt
AIIz7GaBdGiZh7FzVnmzGW3CcJWc+9tt6X5VqzZujRY29tEBE5n2yYmKmmElVn6L
/9VGmfn9jjVO6K9Irs4b18KFD3FkIxbL2TK7zQ0gY4zuUEOs25uzfMgAzqG8ie4T
2ihSE2eUG+bIDppeO28IjHbTbCeadHYBBKOuLoeUlaZN0SylUA7dV3xMxiKQ8R9+
/AwvG4hvm2ovg31CurkZjzx4hUcbClz1WkXFQObeFmYjP+WWNBhznH3LQkatGC36
tSPMxGdt8Ybe8noZ7phrEDV5GfbSFEUsdbV1fIiyjAHIUa0l710vTYU00u3NxNIa
azBQC5ikurE4Pu0EY5V+nZ5boOtskGEflpjwWMabmZSm3rlt4dmiA8VLPcuThgaf
RuNon38PJxR8ToEngLuJ
=v7B0
-----END PGP SIGNATURE-----
</body></email><email><emailId>20110204154120</emailId><senderName>Paulo Roberto</senderName><senderEmail>betobrandao@gmail.com</senderEmail><timestampReceived>2011-02-04 15:41:20-0400</timestampReceived><subject>IPV6 address support on exit nodes</subject><body>

Hi,
My name is Beto and I'm an undergraduate student and I wish to do my
course's final project based on Tor. I have interest in work with the
session g of "Other conding and Design Ideas" of the volunteer page.
Add IPV6 support for destination address on exit nodes. I had some
Unix Programming and network skills.
I would like some directions where to start and to know what you
really expect in the end.

Thank you in advance.

Regards

Beto
</body></email><email><emailId>20110214023720</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-02-14 02:37:20-0400</timestampReceived><subject>Re: or-dev mailing list migration February 19, 2011</subject><body>

A reminder that this migration occurs this weekend.

On Mon, 24 Jan 2011 15:28:30 -0500
Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; Hello or-dev subscribers,
&gt; 
&gt; On February 19, 2011, we are migrating or-dev from or-dev@seul.org to
&gt; tor-dev@lists.torproject.org.  We will migrate your e-mail address's
&gt; subscription to the new list. You will receive a confirmation from the
&gt; new mailing list software on the 19th.
&gt; 
&gt; Current or-dev archives will be migrated.  Roger plans to leave the
&gt; current archives in place at seul.org as well.
&gt; 
&gt; We're using this migration to spread administration out to Tor's
&gt; sysadmin team rather than making Roger do everything himself.  The
&gt; secondary benefits of having the lists on the torproject.org domain
&gt; include SSL-enabled login, archives, and easier account management.
&gt; 
&gt; You can subscribe to the new list at
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 
&gt; I will send out a reminder on the day of the migration.
&gt; 
&gt; Please e-mail tor-assistants@torproject.org with any questions.
&gt; 
&gt; Thank you.
&gt; 



-- 
Andrew
pgp 0x74ED336B
</body></email><email><emailId>20110221022955</emailId><senderName>Lucky Green</senderName><senderEmail>shamrock@cypherpunks.to</senderEmail><timestampReceived>2011-02-21 02:29:55-0400</timestampReceived><subject>Re: [tor-dev] Thoughts on</subject><body>

On 2011-02-02 09:02, Nick Mathewson wrote:
&gt; &gt; On Tue, Jan 25, 2011 at 9:04 AM, Lucky Green
&lt;shamrock@cypherpunks.to&gt; wrote:
&gt;&gt; &gt;&gt; On 2011-01-25 01:09, Erinn Clark wrote:
[...]
&gt;&gt; &gt;&gt; Erinn,
&gt;&gt; &gt;&gt; My feedback is that the Tor Project really, really will want a written
&gt;&gt; &gt;&gt; and published policy of how far back an OS is supposed to be
supported.
&gt;&gt; &gt;&gt; Otherwise, you will get to have this discussion every time a new OS
&gt;&gt; &gt;&gt; version is released.
&gt;&gt; &gt;&gt;
&gt;&gt; &gt;&gt; Industry standard for consumer software that goes into the far corners
&gt;&gt; &gt;&gt; of the world is "current and previous major version", which has
&gt;&gt; &gt;&gt; different meanings depending on OS.
&gt; &gt;
&gt; &gt; Hi, Lucky!  I generally agree with you, but I do want to point out a
&gt; &gt; point that makes me balk at applying your experience without more
&gt; &gt; consideration.
&gt; &gt;
&gt; &gt; It seems to me that the "industry standard for computer consumer
&gt; &gt; software" is chosen to serve the goals of the software industry: that
&gt; &gt; is, to sell software to people who can pay for it.  As a means to that
&gt; &gt; end, commercial software enterprises sometimes additionally support
&gt; &gt; marginal userbases (those who can't pay, those who can't pay much) in
&gt; &gt; order to increase the install base of their software and provide
&gt; &gt; positive network effects for their paying customers.
&gt; &gt;
&gt; &gt; We're in a slightly different position: we're achieving our mission to
&gt; &gt; the extent that lots of users -- whether they can pay or not! -- can
&gt; &gt; use our software.  Also, we want volunteers with free (to them)
&gt; &gt; bandwidth to be able to run our server software on the hardware and
&gt; &gt; software they have lying around.
&gt; &gt;
&gt; &gt; I suspect that, when all is said and done, the set of operating
&gt; &gt; systems that it makes sense to support in the commercial software
&gt; &gt; industry will work out to be almost the same as the ones Tor want to
&gt; &gt; support -- but the reasoning is a little different, since industry
&gt; &gt; needs to optimize profit-per-developer-hour, and we're trying to
&gt; &gt; optimize social-benefit-per-developer-hour.

Hmm. My emails on this topic must have been quite poorly written to
result in your feedback about them focusing on what I had intended to be
little more than a footnote or parenthetical at the very end of the
communication thread.

I am aware of and concur that Tor's success metrics are different from
those of most commercial software vendors. My analysis was entirely
focused on helping Tor devise the best OS version support policy
possible while assuming Tor's goal of
"social-benefit-per-developer-hour". My bad if that was not clear from
my writings.

Though I am not quite certain what the best path would have been for me
to take: omit any references to commercial software development best
practices, even in annexes and footnotes, when discussing open source
software? Somehow that doesn't strike me as the optimal answer. But be
that as it may, I assure you wholeheartedly that my analysis was solely
intended to guide Tor and its ecosystem, not that of commercial software
development.

Either way, even more core to my advice than which particular OS
versions to support (the one area where any dichotomy between open
source and the commercial world may or may not come in) was my point
that Tor needs a written and published OS support policy, agreed-upon by
the Tor team. Whichever version support policy the Tor team may arrive
at and for whatever reasons. And whether or not the Tor team takes my
advice as to which particular versions to support.

--Lucky
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110222063434</emailId><senderName>"Sebastian Hahn"</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-02-22 06:34:34-0400</timestampReceived><subject>[tor-dev] Proposal idea: Require majority of authorities to vote</subject><body>

Filename: xxx-param-voting.txt
Title: Require majority of authorities to vote for consensus parameters
Author: Sebastian Hahn	
Created: 16-Feb-2011
Status: Draft

Overview:

The consensus that the directory authorities create may contain one or
more parameters (32-bit signed integers) that influence the behavior
of Tor nodes (see proposal 167, "Vote on network parameters in
consensus" for more details).

Currently (as of consensus method 11), a consensus will end up
containing a parameter if at least one directory authority votes for
that paramater. The value of the parameter will be the low-median of
all the votes for this parameter.

This proposal aims at changing this voting process to be more secure
against tampering by a non-majority of directory authorities.

Motivation:

To prevent a minority of the directory authorities from influencing
the value of a parameter unduly, the majority of directory authorities
has to vote for that parameter. This is not currently happening, and
it was in fact not uncommon for a single authority to govern the value
of a consensus parameter.

Design:

When the consensus is generated, the directory authorities ensure that
a param is only included in the list of params if at least half of the
total number of authorities votes for that param. The value chosen is
the low-median of all the votes. We don't mandate that the authorities
have to vote on exactly the same value for it to be included because
some consensus parameters could be the result of active measurements
that individual authorities make.

Security implications:

This change is aimed at improving the security of Tor nodes against
attacks carried out by a minority of directory authorities. It is
possible that a consensus parameter that would be helpful to the
network is not included because not enough directory authorities
voted for it, but since clients are required to have sane defaults
in case the parameter is absent this does not carry a security risk.

Specification:

dir-spec section 3.4 currently says:

     Entries are given on the "params" line for every keyword on which any
     authority voted.  The values given are the low-median of all votes on
     that keyword.

It is proposed that the above is changed to:

     Entries are given on the "params" line for every keyword on which a
     majority of authorities (total authorities, not just those
     participating this vote) voted on. The values given are the
     low-median of all votes on that keyword. XXX note previous behaviour.

The following should be added to the bottom of section 3.4.:

        * If consensus method 12 or later is used, only consensus 
          parameters that more than half of the total number of
          authorities voted for are included in the consensus.

The following line should be added to the bottom of section 3.4.1.:

     "12" -- Params are only included if a majority voted for them

Compatibility:

A sufficient number of directory authorities must upgrade to the new
consensus method used to calculate the params in the way this proposal
calls for, otherwise the old mechanism is used. Nodes that do not act
as directory authorities do not need to be upgraded and should
experience no change in behaviour.

Implementation:

An example implementation of this feature can be found in
https://gitweb.torproject.org/sebastian/tor.git, branch safer_params.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110125111245</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-01-25 11:12:45-0400</timestampReceived><subject>Publishing sanitized bridge pool assignments</subject><body>

Hi everyone,

we're pondering to publish the information which distribution pool a
bridge is assigned to.  The distribution pool defines whether we're giving
out bridges via HTTP, via email, or not at all (reserved pool).  The plan
is to remove all sensitive information from bridge pool assignments before
making them available on https://metrics.torproject.org/data.html.

For the long version see task 2372 and comments:

  https://trac.torproject.org/projects/tor/ticket/2372

For the summary version read on:

We want to make sanitized bridge pool assignments available, so that we
can answer questions like these:

 - What's the correlation between which pool the bridge is in and whether
   that bridge sees a lot of use from a given country?

 - Is bridge uptime affected by the pool assignment, because operators of
   bridges in the reserved pool decide that their bridge is not useful?

Here's a proposed data format for bridge pool assignments:

  bridge-pool-assignment 2011-01-10 01:41:14
  b 127.0.0.1:443 abcdef0123456789abcdef0123456789abcdef01
  b 127.0.0.1:443 0123456789abcdef0123456789abcdef01234567
  s IP ring 1 (port-443 subring)
  s IP ring 1 (stable subring)
  s IP ring 1

The timestamp in the bridge-pool-assignment line is the time when the
assignment is written to disk (twice an hour).  Lines starting with b
contain IP address, port, and fingerprint of a bridge.  For sanitizing
purposes, we replace bridge IP addresses with 127.0.0.1 and bridge
identities with their SHA-1 hashes.  That's the same approach that we take
for sanitizing bridge descriptors.  Lines starting with s contain the
rings or subrings that a bridge is allocated to.  If a bridge is not
assigned to any pool, it doesn't have an s line.

While this information is useful for analysis, we need to be aware that
these lists can be misused by a censor to learn what fraction of bridges
is contained in which pool and what percentage of bridges of a given pool
they can block.  So far, they can only tell how many bridges there are in
total and what fraction of these bridges they know.  We'll have to decide
if the questions we expect to answer using these data are worth it.

Thoughts?

Thanks,
Karsten

</body></email><email><emailId>20110221142145</emailId><senderName>Tim Wilde</senderName><senderEmail>twilde@cymru.com</senderEmail><timestampReceived>2011-02-21 14:21:45-0400</timestampReceived><subject>[tor-dev] SSL Observatory Observations</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

G'morning all!

Last weekend's hackfest inspired me to attempt to run some numbers on
the EFF SSL Observatory data[1], in particular looking at two things:
the commonality of the "Internet Widgits Pty" organization string (a
default in OpenSSL's CSR generator) in self-signed certificate subjects,
and, further to that, the most commonly seen self-signed certificates in
the data.

Using the CSV data from the observatory, I found that out of 5,618,558
total certs in the all-certs file, only 8,891 contained subjects that
matched the regex /Internet Widg[ie]ts Pty/ (a quick search observed
both spellings; my OpenSSL used Widgits, FWIW.  I further recorded the
subjects of all certs where subject == issuer, and counted each, with
the following results for the top 10:

' C=--, ST=SomeState, L=SomeCity, O=SomeOrganization,
OU=SomeOrganizationalUnit,
CN=localhost.localdomain/emailAddress=root@localhost.localdomain': 154867
' C=US, ST=California, L=Sunnyvale, O=HTTPS Management Certificate for
SonicWALL (self-signed), OU=HTTPS Management Certificate for SonicWALL
(self-signed), CN=192.168.168.168': 111453
' C=US, ST=Virginia, L=Herndon, O=Parallels, OU=Plesk,
CN=plesk/emailAddress=info@plesk.com': 82689
' CN=Fortinet, O=Fortinet Ltd.': 54975
' C=US, ST=Virginia, L=Herndon, O=SWsoft, Inc., OU=Plesk,
CN=plesk/emailAddress=info@plesk.com': 53184
' C=USA, ST=California, L=Sunnyvale, O=HTTPS Management Certificate for
SonicWALL (self-signed), OU=HTTPS Management Certificate for SonicWALL
(self-signed), CN=192.168.168.168': 22987
' CN=SpeedTouch 605, O=THOMSON, OU=DSL Internet Gateway Device': 16790
' C=US, ST=Someprovince, L=Sometown, O=none, OU=none,
CN=localhost/emailAddress=webaster@localhost': 16638
' CN=SpeedTouch 5x6, O=THOMSON, OU=DSL Internet Gateway Device': 15286
' C=US, ST=CA, L=Sunnyvale, O=SonicWALL, Inc., OU=SSL-VPN,
CN=192.168.200.1': 11760

(Apologies for the lousy wrapping; initial spaces are present in the
source data.)  The numbers after the colons are, as you may guess, the
total number of self-signed certificates with that subject.

It may be instructive to dig into the netblocks where these subjects
occur and attempt to determine the context in which they occur.  For the
purposes of making Tor appear unblockable due to collateral damage, my
strong suspicion is that these will not be all that helpful, as they are
quite likely (and in some cases, clearly) used by CPE devices and the
like for internal management, and thus won't really be likely to cause
much difficulty for the censors if blocked.

My personal thinking is that the methodology in Jake's TLS normalization
proposal[2] makes a lot of sense.  Perhaps one modification, per the
discussion at the hackfest, would be to stick to making the server's
presented certificates self-signed, as that is probably more normal than
having random unknown issuers, and less provably false than faking a
known issuer like GoDaddy.

Even ignoring the question of whether or not a censor may be willing to
sustain the collateral damage of blocking one of the common self-signed
subjects above, by using a commonName that varies per bridge/relay and
other certificate fields that also vary widely (and in fact may be
randomized to some extent), we don't present any blockable static values
in our certificate subject or issuer and can focus on other fun stuff in
the certs. :)

Hopefully Jake hasn't already made this all a moot point while I was in
the other room working with Andrew on Saturday and I just haven't heard
about it yet. :)  Further thoughts/discussions/flames welcome (but only
if the flames come from Mike).

Regards,
Tim

[1] https://www.eff.org/observatory
[2]
https://gitweb.torproject.org/tor.git/blob/HEAD:/doc/spec/proposals/ideas/xxx-draft-spec-for-TLS-normalization.txt


- -- 
Tim Wilde, Senior Software Engineer, Team Cymru, Inc.
twilde@cymru.com | +1-630-230-5433 | http://www.team-cymru.org/
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAk1idPgACgkQluRbRini9tgmZACfSBNRhJ+ozVgIyDIdA4nWbOpI
25oAnRbbXvMkA+ttGkStfB2VFkcal1jd
=vU04
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110201050818</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-02-01 05:08:18-0400</timestampReceived><subject>xxx-triangleboy-transport.txt (+comments on pluggable-transport)</subject><body>


One of the things I've decided to do on the side was see if I could
write up a proposal for a plugable transport plugin that implemented
the TriangleBoy technique:
http://www.webrant.com/safeweb_site/html/www/tboy_whitepaper.html

I figured this would be a good stress test of the plugable transport
proposal, to see if it is robust enough to support this rather
complicated plugin, and to prevent us from generalizing from zero.

One of the other transports we should really spec out before calling
xxx-pluggable-transport.txt "done" is a Skype-based transport. Rumor
is the JAP people already have a Skype transport working that they
created by instrumenting legitimate, registered Skype clients to
transmit data to other legitimate, registered Skype clients. 


This document should be added as:

Filename: ideas/xxx-triangleboy-transport.txt
Title: The Triangle Boy Transport
Author: Mike Perry
Created: 31-Jan-2011
Status: Draft


Introduction

In this proposal, we describe a transport plugin known as the Triangle
Boy transport:
http://www.webrant.com/safeweb_site/html/www/tboy_whitepaper.html

The basic idea is to be able to utilize an asymmetric residential IP
with minimal CPU and memory resources, and limited upstream. We would
use the bridge for only half of the stream, avoiding the upstream
bottleneck of most residential connections. The return direction
will be spoofed by a supporting high-capacity Tor relay.


Overview

The high level packet flow diagram would look like this.

  Client -&gt; Client Plugin -&gt; Transport Bridge -&gt; Relay Plugin -&gt; Relay
  Client &lt;- Client Plugin      &lt;--(spoof)---     Relay Plugin &lt;- Relay

Testing in the field has demonstrated that most residential
connections also perform egress filtering, where as many colo centers
do not. This means that the spoofing logic needs to be present at the
Relay endpoint, and not in the Transport Bridge (though the Transport
Bridge will still need raw sockets to listen for TCP fragments).

It is this egress filter constraint that requires that this transport
use the pluggable-transport spec, as opposed to creating a very simple
spoofing Transport Bridge.

There are two possible designs for the operation of the Transport
Bridge. The bridge can either be peered with a relay of its choosing,
or it can be peered with a client-specified relay. Since using a
client-specified relay in a censored location is prone to failure due
to unobservable changing network conditions, we will consider the case
where the Transport Bridge chooses which relay to forward the
connections to.

The client will use the Transport Bridge IP with a bridge line like:
   "bridge TriangleBoy address:port"

On the client side, the TriangleBoy transport keyword would only mean
that the Tor client should not try to cache the identity key of the
bridge in question, nor should it perform any strict checks to ensure
that the IP reported by the relay is consistent or matches its
endpoint.

Other than these basic loosened constraints, it should be able to use
the Transport Bridge IP as if it were any other bridge. This is
uniquely different from the what the pluggable-transport spec assumes.
Most of the complexity involved in supporting this transport will be
in the Transport Bridge, and in the Relay Plugin side of the equation.


Transport Bridge Operation

The Transport Bridge will require raw sockets to operate. It will also
require a tor client to fetch and authenticate the Tor directory.

The current pluggable transport spec suggests that extrainfo
descriptors be used to describe which transport plugins a bridge
supports. This would require that the Transport Bridge set
DownloadExtraInfo=1 in its torrc.

The extrainfo document would need to list the following information:
TriangleBoyTransport ip:port
TriangleBoyCert &lt;Certificate&gt;

The Transport Bridge would attempt to select an appropriate relay or
relays to forward all client connections.

The forwarding operation by the Transport Bridge would involve a TLS
connection to the ip and port specified in the extrainfo document and
authenticated by the certificate there, and speak cells of the
following format:

   &lt;data_len&gt;: 2 bytes
   &lt;data&gt;: data_len bytes

Each new raw TCP packet that arrives at the transport bridge would be
packaged up according to this scheme. The data portion of the packet
would be the raw IP frame received by the transport bridge.

The TLS connection can be reused to multiplex many different raw
datagrams for many different clients.


Relay Plugin Startup

Not all relays can support the TriangleBoy transport. Many relays are
behind egress filters that will prevent the transmission of spoofed
packets. The transport plugin should be robust enough to be able to
determine if it can properly spoof the packets. This involves both
ensuring that the plugin process has sufficient permissions, and also
sending some spoofed test packets to a server to receive the response.

If either of these tests fail, the plugin needs to inform Tor of this
fact so that Tor does *not* provide the lines for the TriangleBoy
transport in its extrainfo document.

The relay would configure the plugin using its torrc:

ServerTransportPlugin TriangleBoy /path/to/triangleboy ip=&lt;ip&gt; port=&lt;port&gt; \
 tor_ip=&lt;ip&gt; tor_port=&lt;port&gt; free_rfc1918=&lt;ip&gt;

Tor would launch the triangleboy process, which would perform the
appropriate uid checks, and send test spoofed packets to $SERVER (the
bridgedb?). If the tests pass, it would reply with:

SMETHOD: TriangleBoy &lt;ip&gt;:&lt;port&gt; \
 EXTRAINFO:TriangleBoyTransport=&lt;ip&gt;:&lt;port&gt;,TriangleBoyCert=&lt;Certificate&gt;
METHODS: DONE

If there are any errors with permissions or spoofing, the transport
should reply with:

METHODS: NONE

and then exit.


Relay Plugin Operation

The relay plugin will listen for TLS connections on its port, using
the certificate it created and sent to Tor during startup.

It will perform some verification on the integrity of incoming
datagrams: ensuring that they are in fact TCP/IP, that their destination
IP was in fact the Transport Bridge, and that their source IP is in
publicly routable IP space.

It would then perform a form of NAT in order to translate the raw IP
frames coming in to be sourced from the free_rfc1918 IP (specified in
the configuration line) and a random free port. It will maintain an
internal mapping between these randomized local source ports and the
originating Client IP and port (as well as the Transport Bridge IP).

The Relay will then proceed believing that it has a TCP connection
from an unused, local rfc1918 ip and source port. This ip+port will
not actually exist, but instead will be handled by a raw socket
listening in the Relay Plugin.

Upon receiving packets from the Tor process on its raw socket, the
Relay Plugin will use the destination port to look up the original
Client IP and port, and the Transport Bridge IP. It will rewrite the
packets to spoof the source IP as the Transport Bridge IP, and set the
destination IP and port as the one it found for the Client in the its
NAT table.

In this way, the NAT will properly seamlessly translate packets for
the Relay, and the Client will communicate with what it believes to be
the Transport Bridge IP, while using the capacity of the supporting
Tor Relay for the downstream direction.


Appendix: List of key xxx-pluggable-transport.txt shortcomings

1. This pluggable transport does not need any intelligence or process
launching on the Client side, aside from a way to tell Tor not to be
so pedantic about ensuring identity key and IP address consistency.

2. The relay side needs to be able to detect if it has both the
permissions and the network ability to send spoofed packets. It needs
to communicate this fact with the Relay Plugin by responding with the
appropriate extrainfo lines, or with "METHODS: NONE" to indicate
error. This relay-side handshake should be specified in the
pluggable-transport spec.

3. The relay plugin side needs some way to communicate EXTRAINFO lines
to be added to its extrainfo descriptor. In this proposal, we use the
SMETHOD reply to do this.

4. Is extrainfo really the best place to keep this information?
Shouldn't it just be in the relay/bridge descriptor? Putting it in
extrainfo requires our TransportBridges to enable the wasteful
DownloadExtraInfo=1 torrc setting, which will consume more scarce
resources and RAM on what will probably be cheap routers with 32-64M
of RAM.

5. How would we go about chaining an actual obfuscation mechanism with
this transport? Would we just create new and separate transport called
TriangleBoyOverHTTP, for example, or is there a better way to chain
different mechanisms?


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20110210041744</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-10 04:17:44-0400</timestampReceived><subject>Re: xxx-triangleboy-transport.txt (+comments on pluggable-transport)</subject><body>

On Tue, Feb 1, 2011 at 12:08 AM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
 [...]
&gt;
&gt; Appendix: List of key xxx-pluggable-transport.txt shortcomings
&gt;
&gt; 1. This pluggable transport does not need any intelligence or process
&gt; launching on the Client side, aside from a way to tell Tor not to be
&gt; so pedantic about ensuring identity key and IP address consistency.

What pedanticism exactly do you mean?  Matching the IP addr in the
netinfo cell, or something else?

&gt; 2. The relay side needs to be able to detect if it has both the
&gt; permissions and the network ability to send spoofed packets. It needs
&gt; to communicate this fact with the Relay Plugin by responding with the
&gt; appropriate extrainfo lines, or with "METHODS: NONE" to indicate
&gt; error. This relay-side handshake should be specified in the
&gt; pluggable-transport spec.

To be clear, you mean that the plugin checks whether it can spoof (and
tell Tor "I do nothing!" if it can't), or that Tor needs to find out
whether it can spoof and tell the plugin that whether it can spoof or
not.  The first sounds reasonable.  The second doesn't so much: most
Tors won't want to try to spoof, so building the checks into Tor
wouldn't make sense to me, unless I'm missing something.

&gt; 3. The relay plugin side needs some way to communicate EXTRAINFO lines
&gt; to be added to its extrainfo descriptor. In this proposal, we use the
&gt; SMETHOD reply to do this.

Needs spec, not just an example.

&gt; 4. Is extrainfo really the best place to keep this information?
&gt; Shouldn't it just be in the relay/bridge descriptor? Putting it in
&gt; extrainfo requires our TransportBridges to enable the wasteful
&gt; DownloadExtraInfo=1 torrc setting, which will consume more scarce
&gt; resources and RAM on what will probably be cheap routers with 32-64M
&gt; of RAM.

Hm.  Relay/bridge descriptor should be okay, I guess.  I'm not sure
why the TransportBridges are getting those anyway, though:  I see why
the client needs it, but not what the transportbridge needs it.

Also, why are transportbridges even running tor?  They don't seem to
be doing anything particularly tor-like.

&gt; 5. How would we go about chaining an actual obfuscation mechanism with
&gt; this transport? Would we just create new and separate transport called
&gt; TriangleBoyOverHTTP, for example, or is there a better way to chain
&gt; different mechanisms?

On the client side, socks-over-socks-over-socks is not actually a
terrible way of doing things there.  We'll need to distinguish between
which transports are chainable and which aren't, though[*], and maybe
revise the design to make sure there's a way to tell to tell tor to do
said chaining.

On the server side, you need some way to distinguish which processing
method to do for incoming data. Separate ports seems ok there.  We
still need to figure out the server side.

[*] generally, obfuscation is chainable but transport isn't.

yrs,
-- 
Nick
</body></email><email><emailId>20110131193700</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-01-31 19:37:00-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Tue, Jan 25, 2011 at 12:12:45PM +0100, Karsten Loesing wrote:
&gt; Hi everyone,
&gt; 
&gt; we're pondering to publish the information which distribution pool a
&gt; bridge is assigned to.  The distribution pool defines whether we're giving
&gt; out bridges via HTTP, via email, or not at all (reserved pool).  The plan
&gt; is to remove all sensitive information from bridge pool assignments before
&gt; making them available on https://metrics.torproject.org/data.html.
&gt; 
&gt; For the long version see task 2372 and comments:
&gt; 
&gt;   https://trac.torproject.org/projects/tor/ticket/2372
&gt; 
&gt; For the summary version read on:
&gt; 
&gt; We want to make sanitized bridge pool assignments available, so that we
&gt; can answer questions like these:
&gt; 
&gt;  - What's the correlation between which pool the bridge is in and whether
&gt;    that bridge sees a lot of use from a given country?
&gt; 
&gt;  - Is bridge uptime affected by the pool assignment, because operators of
&gt;    bridges in the reserved pool decide that their bridge is not useful?
&gt; 
&gt; Here's a proposed data format for bridge pool assignments:
&gt; 
&gt;   bridge-pool-assignment 2011-01-10 01:41:14
&gt;   b 127.0.0.1:443 abcdef0123456789abcdef0123456789abcdef01
&gt;   b 127.0.0.1:443 0123456789abcdef0123456789abcdef01234567
&gt;   s IP ring 1 (port-443 subring)
&gt;   s IP ring 1 (stable subring)
&gt;   s IP ring 1
&gt; 
&gt; The timestamp in the bridge-pool-assignment line is the time when the
&gt; assignment is written to disk (twice an hour).  Lines starting with b
&gt; contain IP address, port, and fingerprint of a bridge.  For sanitizing
&gt; purposes, we replace bridge IP addresses with 127.0.0.1 and bridge
&gt; identities with their SHA-1 hashes.  That's the same approach that we take
&gt; for sanitizing bridge descriptors.  Lines starting with s contain the
&gt; rings or subrings that a bridge is allocated to.  If a bridge is not
&gt; assigned to any pool, it doesn't have an s line.
&gt; 
&gt; While this information is useful for analysis, we need to be aware that
&gt; these lists can be misused by a censor to learn what fraction of bridges
&gt; is contained in which pool and what percentage of bridges of a given pool
&gt; they can block.  So far, they can only tell how many bridges there are in
&gt; total and what fraction of these bridges they know.  We'll have to decide
&gt; if the questions we expect to answer using these data are worth it.

Here's a sample bridge pool assignment from September 2010 that is
sanitized as described above (all IP addresses set to 127.0.0.1, contained
fingerprints are SHA-1 hashes of the original fingerprints):

  http://freehaven.net/~karsten/volatile/bridge-pool-assignment-sample

This sample is there, so that everyone gets a better idea of what is meant
by a bridge pool assignment.  Does anyone object to publishing tarballs of
these sanitized bridge pool assignments on the metrics website, so that we
(and anyone else) can analyze them?

Best,
Karsten

</body></email><email><emailId>20110131200357</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-01-31 20:03:57-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Mon, Jan 31, 2011 at 08:37:00PM +0100, Karsten Loesing wrote:
&gt; Here's a sample bridge pool assignment from September 2010 that is
&gt; sanitized as described above (all IP addresses set to 127.0.0.1, contained
&gt; fingerprints are SHA-1 hashes of the original fingerprints):
&gt; 
&gt;   http://freehaven.net/~karsten/volatile/bridge-pool-assignment-sample
&gt; 
&gt; This sample is there, so that everyone gets a better idea of what is meant
&gt; by a bridge pool assignment.  Does anyone object to publishing tarballs of
&gt; these sanitized bridge pool assignments on the metrics website, so that we
&gt; (and anyone else) can analyze them?

Is there enough entropy in the things you're hashing to prevent
reversing the hash?

   - Ian
</body></email><email><emailId>20110131205228</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-01-31 20:52:28-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Mon, Jan 31, 2011 at 03:03:57PM -0500, Ian Goldberg wrote:
&gt; On Mon, Jan 31, 2011 at 08:37:00PM +0100, Karsten Loesing wrote:
&gt; &gt; Here's a sample bridge pool assignment from September 2010 that is
&gt; &gt; sanitized as described above (all IP addresses set to 127.0.0.1, contained
&gt; &gt; fingerprints are SHA-1 hashes of the original fingerprints):
&gt; &gt; 
&gt; &gt;   http://freehaven.net/~karsten/volatile/bridge-pool-assignment-sample
&gt; &gt; 
&gt; &gt; This sample is there, so that everyone gets a better idea of what is meant
&gt; &gt; by a bridge pool assignment.  Does anyone object to publishing tarballs of
&gt; &gt; these sanitized bridge pool assignments on the metrics website, so that we
&gt; &gt; (and anyone else) can analyze them?
&gt; 
&gt; Is there enough entropy in the things you're hashing to prevent
&gt; reversing the hash?

Well, I guess so.  We're hashing the bridge identity fingerprints.  From
dir-spec.txt:

    "fingerprint" fingerprint NL

       [At most once]

       A fingerprint (a HASH_LEN-byte of asn1 encoded public key, encoded in
       hex, with a single space after every 4 characters) for this router's
       identity key.

Does this mean we're safe here?

Thanks,
Karsten

</body></email><email><emailId>20110202145025</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-02 14:50:25-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Mon, Jan 31, 2011 at 05:50:02PM -0500, Nick Mathewson wrote:
&gt; On Mon, Jan 31, 2011 at 3:52 PM, Karsten Loesing
&gt; &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; &gt; On Mon, Jan 31, 2011 at 03:03:57PM -0500, Ian Goldberg wrote:
&gt; &gt;&gt; Is there enough entropy in the things you're hashing to prevent
&gt; &gt;&gt; reversing the hash?
&gt; &gt;
&gt; &gt; Well, I guess so.  We're hashing the bridge identity fingerprints.  From
&gt; &gt; dir-spec.txt:
&gt; &gt;
&gt; &gt;    "fingerprint" fingerprint NL
&gt; &gt;
&gt; &gt;       [At most once]
&gt; &gt;
&gt; &gt;       A fingerprint (a HASH_LEN-byte of asn1 encoded public key, encoded in
&gt; &gt;       hex, with a single space after every 4 characters) for this router's
&gt; &gt;       identity key.
&gt; &gt;
&gt; &gt; Does this mean we're safe here?
&gt; 
&gt; I think we're okay.  A censor could in theory correlate this with
&gt; certificates, if it had them, but I think most automated certificate
&gt; crawlers will wind up with link certs only, so the censor will need to
&gt; do their own crawling to find bridges.
&gt; 
&gt; If we care a lot, we could instead have the sanitization process use
&gt; some secret X and report H(X|H(ID key)) in place of H(ID key).

Your call.  If you think adding a secret X is important here, we can
change the process.  Note that this change affects all published sanitized
bridge descriptors, because they contain these hashed fingerprints, too.
We should be consistent with the fingerprints we put into bridge pool
assignments and bridge descriptors.  That doesn't exactly make this a
cheap change, because I'll have to sanitize two years of descriptors
again.  But if it's important, I can do it.

Speaking of sanitizing bridge descriptors, there's a related change to the
current sanitizing process discussed in Trac ticket #2435.  I'd really
like to hear your opinions to that ticket (either here or as comments to
the ticket), because that change is about preserving hashed IP addresses
in sanitized bridge descriptors:

  https://trac.torproject.org/projects/tor/ticket/2435

Thanks,
Karsten

</body></email><email><emailId>20110202145605</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-02-02 14:56:05-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt; On Mon, Jan 31, 2011 at 05:50:02PM -0500, Nick Mathewson wrote:
&gt; &gt; On Mon, Jan 31, 2011 at 3:52 PM, Karsten Loesing
&gt; &gt; &lt;karsten.loesing@gmx.net&gt; wrote:
&gt; &gt; &gt; On Mon, Jan 31, 2011 at 03:03:57PM -0500, Ian Goldberg wrote:
&gt; &gt; &gt;&gt; Is there enough entropy in the things you're hashing to prevent
&gt; &gt; &gt;&gt; reversing the hash?
&gt; &gt; &gt;
&gt; &gt; &gt; Well, I guess so.  We're hashing the bridge identity fingerprints.  From
&gt; &gt; &gt; dir-spec.txt:
&gt; &gt; &gt;
&gt; &gt; &gt;    "fingerprint" fingerprint NL
&gt; &gt; &gt;
&gt; &gt; &gt;       [At most once]
&gt; &gt; &gt;
&gt; &gt; &gt;       A fingerprint (a HASH_LEN-byte of asn1 encoded public key, encoded in
&gt; &gt; &gt;       hex, with a single space after every 4 characters) for this router's
&gt; &gt; &gt;       identity key.
&gt; &gt; &gt;
&gt; &gt; &gt; Does this mean we're safe here?
&gt; &gt; 
&gt; &gt; I think we're okay.  A censor could in theory correlate this with
&gt; &gt; certificates, if it had them, but I think most automated certificate
&gt; &gt; crawlers will wind up with link certs only, so the censor will need to
&gt; &gt; do their own crawling to find bridges.
&gt; &gt; 
&gt; &gt; If we care a lot, we could instead have the sanitization process use
&gt; &gt; some secret X and report H(X|H(ID key)) in place of H(ID key).
&gt; 
&gt; Your call.  If you think adding a secret X is important here, we can
&gt; change the process.  Note that this change affects all published sanitized
&gt; bridge descriptors, because they contain these hashed fingerprints, too.
&gt; We should be consistent with the fingerprints we put into bridge pool
&gt; assignments and bridge descriptors.  That doesn't exactly make this a
&gt; cheap change, because I'll have to sanitize two years of descriptors
&gt; again.  But if it's important, I can do it.
&gt; 
&gt; Speaking of sanitizing bridge descriptors, there's a related change to the
&gt; current sanitizing process discussed in Trac ticket #2435.  I'd really
&gt; like to hear your opinions to that ticket (either here or as comments to
&gt; the ticket), because that change is about preserving hashed IP addresses
&gt; in sanitized bridge descriptors:
&gt; 
&gt;   https://trac.torproject.org/projects/tor/ticket/2435

"Never rely on a secret that's expensive to change".

For sure the secret should be long.  20 bytes is probably OK, but why
not 256 bits?  As long as the whole thing you're hashing fits in one
hash block, it's not more expensive.  (And why SHA1?)

What happens if someone _does_ brute the secret?  How important is it to
keep a consistent secret?

   - Ian
</body></email><email><emailId>20110202150851</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-02 15:08:51-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt; Your call.  If you think adding a secret X is important here, we can
&gt; change the process.  Note that this change affects all published sanitized
&gt; bridge descriptors, because they contain these hashed fingerprints, too.
&gt; We should be consistent with the fingerprints we put into bridge pool
&gt; assignments and bridge descriptors.  That doesn't exactly make this a
&gt; cheap change, because I'll have to sanitize two years of descriptors
&gt; again.  But if it's important, I can do it.

Argh!  There's one major problem about adding a secret X.  We're comparing
hashed bridge identites to hashed relay identities to exclude bridges that
have been running as relays from the bridge usage statistics.  The reason
is that bridges that have been running as relays before report much higher
user numbers than other bridges, which are very likely direct Tor users.

If we now include a secret X in the sanitizing process, we'd either have
to include the same secret in the calculation of bridge usage statistics,
or we wouldn't be able to remove former relays.  I really want to avoid
the former, because we're trying to only make use of data for statistics
that we're giving out to everyone.  And the latter would make our bridge
usage statistics useless.

So, I'm afraid we cannot include a secret X easily. :(

&gt; Speaking of sanitizing bridge descriptors, there's a related change to the
&gt; current sanitizing process discussed in Trac ticket #2435.  I'd really
&gt; like to hear your opinions to that ticket (either here or as comments to
&gt; the ticket), because that change is about preserving hashed IP addresses
&gt; in sanitized bridge descriptors:
&gt; 
&gt;   https://trac.torproject.org/projects/tor/ticket/2435

(This question is unaffected from the discussion of secret X above.)

Best,
Karsten

</body></email><email><emailId>20110202170319</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-02-02 17:03:19-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Wed, Feb 02, 2011 at 04:29:05PM +0100, Karsten Loesing wrote:
&gt; On Wed, Feb 02, 2011 at 09:56:05AM -0500, Ian Goldberg wrote:
&gt; &gt; On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt; &gt;&gt; Speaking of sanitizing bridge descriptors, there's a related change to the
&gt; &gt;&gt; current sanitizing process discussed in Trac ticket #2435.  I'd really
&gt; &gt;&gt; like to hear your opinions to that ticket (either here or as comments to
&gt; &gt;&gt; the ticket), because that change is about preserving hashed IP addresses
&gt; &gt;&gt; in sanitized bridge descriptors:
&gt; &gt;&gt; 
&gt; &gt;&gt;   https://trac.torproject.org/projects/tor/ticket/2435
&gt; &gt; 
&gt; &gt; "Never rely on a secret that's expensive to change".
&gt; &gt; 
&gt; &gt; For sure the secret should be long.  20 bytes is probably OK, but why
&gt; &gt; not 256 bits?  As long as the whole thing you're hashing fits in one
&gt; &gt; hash block, it's not more expensive.  (And why SHA1?)
&gt; 
&gt; Pasting the proposed hash function here so that people can follow the
&gt; discussion without opening the Trac ticket:
&gt; 
&gt;   H(IP address + bridge identity + secret)[:3]
&gt; 
&gt; 20 bytes was just a suggestion.  We already have 24 bytes as input to the
&gt; hash function (IP address = 4 bytes, bridge identity = 20 bytes) plus the
&gt; suggested 20 bytes for the secret.  We can as well make the secret 32
&gt; bytes long, or 40.

Actually, to keep it to one SHA block (447 bits, not including padding),
you can have at most 255 bits (31 bytes, if we're byte-aligned) for the
secret.  I wouldn't suggest spanning the secret across SHA blocks.

&gt; SHA1 was just a suggestion, too.  No reason not to use SHA-256, SHA-384,
&gt; or SHA-512 (which are the digests in the Java implementation we use).
&gt; 
&gt; How about using SHA-512 and making the secret 40 bytes long?

SHA-512 seems like overkill if we're only using 3 bytes of the output.
SHA-256 should be fine.  Indeed, there's no _actual_ reason to believe
SHA-1 isn't fine here, except for the general "don't be mandating SHA-1
for anything new at this point" rule.

&gt; &gt; What happens if someone _does_ brute the secret?  How important is it to
&gt; &gt; keep a consistent secret?
&gt; 
&gt; If someone brute forces the secret, they only need the bridge identity to
&gt; further brute force the bridge's past IP addresses.  We usually assume
&gt; that the adversary doesn't have original bridge identities, unless they
&gt; request bridges on their own.  And if they do request bridges, they
&gt; already know current IP addresses.  But when they also have the secret,
&gt; they can use our archives to learn about the bridge's past IP addresses.
&gt; It's unclear whether that's a problem for someone.  Possibly.
&gt; 
&gt; With a changing secret, the adversary could only use the found secret for
&gt; descriptor archives of that month.  And they'll have a much harder time
&gt; brute forcing secrets for past months, for which they cannot set up their
&gt; own bridges (as described in comment #1 in #2435).

A 31-byte secret is far more likely to leak than be brute-forced, of
course.  If it's leaked one month, is it likely to leak again another
month?

   - Ian
</body></email><email><emailId>20110202152905</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-02 15:29:05-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Wed, Feb 02, 2011 at 09:56:05AM -0500, Ian Goldberg wrote:
&gt; On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt;&gt; Speaking of sanitizing bridge descriptors, there's a related change to the
&gt;&gt; current sanitizing process discussed in Trac ticket #2435.  I'd really
&gt;&gt; like to hear your opinions to that ticket (either here or as comments to
&gt;&gt; the ticket), because that change is about preserving hashed IP addresses
&gt;&gt; in sanitized bridge descriptors:
&gt;&gt; 
&gt;&gt;   https://trac.torproject.org/projects/tor/ticket/2435
&gt; 
&gt; "Never rely on a secret that's expensive to change".
&gt; 
&gt; For sure the secret should be long.  20 bytes is probably OK, but why
&gt; not 256 bits?  As long as the whole thing you're hashing fits in one
&gt; hash block, it's not more expensive.  (And why SHA1?)

Pasting the proposed hash function here so that people can follow the
discussion without opening the Trac ticket:

  H(IP address + bridge identity + secret)[:3]

20 bytes was just a suggestion.  We already have 24 bytes as input to the
hash function (IP address = 4 bytes, bridge identity = 20 bytes) plus the
suggested 20 bytes for the secret.  We can as well make the secret 32
bytes long, or 40.

SHA1 was just a suggestion, too.  No reason not to use SHA-256, SHA-384,
or SHA-512 (which are the digests in the Java implementation we use).

How about using SHA-512 and making the secret 40 bytes long?

&gt; What happens if someone _does_ brute the secret?  How important is it to
&gt; keep a consistent secret?

If someone brute forces the secret, they only need the bridge identity to
further brute force the bridge's past IP addresses.  We usually assume
that the adversary doesn't have original bridge identities, unless they
request bridges on their own.  And if they do request bridges, they
already know current IP addresses.  But when they also have the secret,
they can use our archives to learn about the bridge's past IP addresses.
It's unclear whether that's a problem for someone.  Possibly.

With a changing secret, the adversary could only use the found secret for
descriptor archives of that month.  And they'll have a much harder time
brute forcing secrets for past months, for which they cannot set up their
own bridges (as described in comment #1 in #2435).

Best,
Karsten

</body></email><email><emailId>20110203101653</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-03 10:16:53-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Wed, Feb 02, 2011 at 12:03:19PM -0500, Ian Goldberg wrote:
&gt; Actually, to keep it to one SHA block (447 bits, not including padding),
&gt; you can have at most 255 bits (31 bytes, if we're byte-aligned) for the
&gt; secret.  I wouldn't suggest spanning the secret across SHA blocks.
&gt; 
&gt; SHA-512 seems like overkill if we're only using 3 bytes of the output.
&gt; SHA-256 should be fine.  Indeed, there's no _actual_ reason to believe
&gt; SHA-1 isn't fine here, except for the general "don't be mandating SHA-1
&gt; for anything new at this point" rule.

These sound like fine suggestions to me!  I added a short summary to the
Trac entry here:

  https://trac.torproject.org/projects/tor/ticket/2435#comment:2

&gt; A 31-byte secret is far more likely to leak than be brute-forced, of
&gt; course.  If it's leaked one month, is it likely to leak again another
&gt; month?

Leaking shouldn't be a problem here, because the secret will only be known
to the machine that's sanitizing bridge descriptors.  If someone learns
about the secret on that machine, they could as well learn about the
original descriptors, too, and save themselves all the trouble of brute
forcing things.

Thanks a lot for your feedback so far!

Best,
Karsten

</body></email><email><emailId>20110204071931</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-02-04 07:19:31-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>


On Wed, 2 Feb 2011 16:08:51 +0100
Karsten Loesing &lt;karsten.loesing@gmx.net&gt; wrote:

&gt; On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt; &gt; Your call.  If you think adding a secret X is important here, we can
&gt; &gt; change the process.  Note that this change affects all published sanitized
&gt; &gt; bridge descriptors, because they contain these hashed fingerprints, too.
&gt; &gt; We should be consistent with the fingerprints we put into bridge pool
&gt; &gt; assignments and bridge descriptors.  That doesn't exactly make this a
&gt; &gt; cheap change, because I'll have to sanitize two years of descriptors
&gt; &gt; again.  But if it's important, I can do it.
&gt; 
&gt; Argh!  There's one major problem about adding a secret X.  We're comparing
&gt; hashed bridge identites to hashed relay identities to exclude bridges that
&gt; have been running as relays from the bridge usage statistics.  The reason
&gt; is that bridges that have been running as relays before report much higher
&gt; user numbers than other bridges, which are very likely direct Tor users.
&gt; 
&gt; If we now include a secret X in the sanitizing process, we'd either have
&gt; to include the same secret in the calculation of bridge usage statistics,
&gt; or we wouldn't be able to remove former relays.  I really want to avoid
&gt; the former, because we're trying to only make use of data for statistics
&gt; that we're giving out to everyone.  And the latter would make our bridge
&gt; usage statistics useless.
&gt; 
&gt; So, I'm afraid we cannot include a secret X easily. :(

Publish lists of relay identities sanitized using the same function
used to sanitize bridge identities.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110208144239</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-08 14:42:39-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

(Just in case people have difficulties following this thread, because we
discussed different things about sanitizing bridge descriptors, all having
to do with adding secrets to hash functions:  This suggestion had to do
with replacing bridge identity fingerprints with H(secret | fingerprint)
instead of the current H(fingerprint).)

On Thu, Feb 03, 2011 at 11:19:31PM -0800, Robert Ransom wrote:
&gt; &gt; On Wed, Feb 02, 2011 at 03:50:25PM +0100, Karsten Loesing wrote:
&gt; &gt; &gt; Your call.  If you think adding a secret X is important here, we can
&gt; &gt; &gt; change the process.  Note that this change affects all published sanitized
&gt; &gt; &gt; bridge descriptors, because they contain these hashed fingerprints, too.
&gt; &gt; &gt; We should be consistent with the fingerprints we put into bridge pool
&gt; &gt; &gt; assignments and bridge descriptors.  That doesn't exactly make this a
&gt; &gt; &gt; cheap change, because I'll have to sanitize two years of descriptors
&gt; &gt; &gt; again.  But if it's important, I can do it.
&gt; &gt; 
&gt; &gt; Argh!  There's one major problem about adding a secret X.  We're comparing
&gt; &gt; hashed bridge identites to hashed relay identities to exclude bridges that
&gt; &gt; have been running as relays from the bridge usage statistics.  The reason
&gt; &gt; is that bridges that have been running as relays before report much higher
&gt; &gt; user numbers than other bridges, which are very likely direct Tor users.
&gt; &gt; 
&gt; &gt; If we now include a secret X in the sanitizing process, we'd either have
&gt; &gt; to include the same secret in the calculation of bridge usage statistics,
&gt; &gt; or we wouldn't be able to remove former relays.  I really want to avoid
&gt; &gt; the former, because we're trying to only make use of data for statistics
&gt; &gt; that we're giving out to everyone.  And the latter would make our bridge
&gt; &gt; usage statistics useless.
&gt; &gt; 
&gt; &gt; So, I'm afraid we cannot include a secret X easily. :(
&gt; 
&gt; Publish lists of relay identities sanitized using the same function
&gt; used to sanitize bridge identities.

Right, that would work, even though it involves even more work.  It's
still unclear to me whether we need to act here.  Are we really concerned
that censors crawl certificates and fetch our sanitized bridge descriptor
archives to find out whether nodes are running bridges?

Best,
Karsten

</body></email><email><emailId>20110210110040</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-10 11:00:40-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Thu, Feb 03, 2011 at 11:16:53AM +0100, Karsten Loesing wrote:
&gt; On Wed, Feb 02, 2011 at 12:03:19PM -0500, Ian Goldberg wrote:
&gt; &gt; Actually, to keep it to one SHA block (447 bits, not including padding),
&gt; &gt; you can have at most 255 bits (31 bytes, if we're byte-aligned) for the
&gt; &gt; secret.  I wouldn't suggest spanning the secret across SHA blocks.
&gt; &gt; 
&gt; &gt; SHA-512 seems like overkill if we're only using 3 bytes of the output.
&gt; &gt; SHA-256 should be fine.  Indeed, there's no _actual_ reason to believe
&gt; &gt; SHA-1 isn't fine here, except for the general "don't be mandating SHA-1
&gt; &gt; for anything new at this point" rule.
&gt; 
&gt; These sound like fine suggestions to me!  I added a short summary to the
&gt; Trac entry here:
&gt; 
&gt;   https://trac.torproject.org/projects/tor/ticket/2435#comment:2
&gt; 
&gt; &gt; A 31-byte secret is far more likely to leak than be brute-forced, of
&gt; &gt; course.  If it's leaked one month, is it likely to leak again another
&gt; &gt; month?
&gt; 
&gt; Leaking shouldn't be a problem here, because the secret will only be known
&gt; to the machine that's sanitizing bridge descriptors.  If someone learns
&gt; about the secret on that machine, they could as well learn about the
&gt; original descriptors, too, and save themselves all the trouble of brute
&gt; forcing things.

So, I implemented the new sanitizing algorithm that replaces bridge IPs
with 10.x.x.x addresses derived from the original bridge IPs.  I also
sanitized the descriptors from November 2008 and performed an early
analysis on the results.

The last remaining step is to sanitize our archives of bridge descriptors
once again and make the sanitized data available.  I don't expect to have
new tarballs before next Tuesday.

Before publishing the new tarballs, I'd like to invite people to review
the new sanitizing process:

 - A specification-like description of the sanitizing process is in
   Section 3 of https://metrics.torproject.org/papers/data-2011-02-10.pdf

 - The early analysis results of bridges changing their IP addresses are
   here: https://trac.torproject.org/projects/tor/ticket/2435#comment:3

 - The tarball with sanitized bridge descriptors from November 2008 is
   here (6.2M):
   http://freehaven.net/~karsten/volatile/bridge-descriptors-hashed-ips-2008-11.tar.bz2

Any questions, comments, and concerns are highly appreciated!

Best,
Karsten

</body></email><email><emailId>20110220041002</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-02-20 04:10:02-0400</timestampReceived><subject>Re: [tor-dev] or-dev mailing list migration February 19, 2011</subject><body>

And this is complete.  Mail archive migration is coming soon.

On Sun, 13 Feb 2011 21:37:20 -0500
Andrew Lewman &lt;andrew@torproject.org&gt; wrote:

&gt; A reminder that this migration occurs this weekend.
&gt; 
&gt; On Mon, 24 Jan 2011 15:28:30 -0500
&gt; Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
&gt; 
&gt; &gt; Hello or-dev subscribers,
&gt; &gt; 
&gt; &gt; On February 19, 2011, we are migrating or-dev from or-dev@seul.org
&gt; &gt; to tor-dev@lists.torproject.org.  We will migrate your e-mail
&gt; &gt; address's subscription to the new list. You will receive a
&gt; &gt; confirmation from the new mailing list software on the 19th.
&gt; &gt; 
&gt; &gt; Current or-dev archives will be migrated.  Roger plans to leave the
&gt; &gt; current archives in place at seul.org as well.
&gt; &gt; 
&gt; &gt; We're using this migration to spread administration out to Tor's
&gt; &gt; sysadmin team rather than making Roger do everything himself.  The
&gt; &gt; secondary benefits of having the lists on the torproject.org domain
&gt; &gt; include SSL-enabled login, archives, and easier account management.
&gt; &gt; 
&gt; &gt; You can subscribe to the new list at
&gt; &gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; &gt; 
&gt; &gt; I will send out a reminder on the day of the migration.
&gt; &gt; 
&gt; &gt; Please e-mail tor-assistants@torproject.org with any questions.
&gt; &gt; 
&gt; &gt; Thank you.
&gt; &gt; 
&gt; 
&gt; 
&gt; 



-- 
Andrew
pgp 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110204155513</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-04 15:55:13-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On Fri, Feb 4, 2011 at 10:41 AM, Paulo Roberto &lt;betobrandao@gmail.com&gt; wrote:
&gt; Hi,
&gt; My name is Beto and I'm an undergraduate student and I wish to do my
&gt; course's final project based on Tor. I have interest in work with the
&gt; session g of "Other conding and Design Ideas" of the volunteer page.
&gt; Add IPV6 support for destination address on exit nodes. I had some
&gt; Unix Programming and network skills.
&gt; I would like some directions where to start and to know what you
&gt; really expect in the end.

I'd have a start by looking at proposal 117 at

https://gitweb.torproject.org/tor.git/blob_plain/HEAD:/doc/spec/proposals/117-ipv6-exits.txt

It's a few years old, but it's still mostly right, and its unanswered
questions are still in need of answers.  It assumes that you've read
the tor specification at

https://gitweb.torproject.org/tor.git/blob_plain/HEAD:/doc/spec/tor-spec.txt

To get started with the Tor code itself here, I'd suggest having a
look at how exit nodes behave on getting a "begin" cell (the function
connection_exit_begin_conn()) , and how clients behave when they get a
new stream to tunnel (look for functions that call
connection_ap_handshake_send_begin(), functions that call those, and
so on).  If you want to chat and ask questions about the code in
realtime, try the #tor-dev channel on irc.oftc.net.

cheers,
-- 
Nick Mathewson
</body></email><email><emailId>20110206101542</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-02-06 10:15:42-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On 2011-02-04 16:41, Paulo Roberto wrote:
&gt; Hi,
&gt; My name is Beto and I'm an undergraduate student and I wish to do my
&gt; course's final project based on Tor. I have interest in work with the
&gt; session g of "Other conding and Design Ideas" of the volunteer page.
&gt; Add IPV6 support for destination address on exit nodes. I had some
&gt; Unix Programming and network skills.
&gt; I would like some directions where to start and to know what you
&gt; really expect in the end.

Note that I am running a private testbed of Tor nodes that support IPv6
already for bridge, relay and exit functionality.

Currently I am focusing on getting the consensus part to only tell nodes
to start using IPv6 when a certain ratio of nodes have IPv6 support
available. Bridge functionality is thus always enabled in the network so
that other nodes can come in over IPv6, but relay/exit is not enabled
yet if there are not enough nodes otherwise the ones running the few
IPv6 nodes would control everything.

Another issue is what to do with hostnames, connect over IPv4 or IPv6,
or, what the current implementation does, try AAAA's first and then A's,
as one is supposed to according to the IETF.

I also need to add a little "does IPv6 actually work" check to it,
though that is more a general system thing. This, because it could avoid
a lot of timeouts if some host thinks it has IPv6 connectivity (or IPv4
for that matter) but it actually does not work or times out.

Hopefully I will be able to invest a bit more time on this work in the
coming week and come up with a beta patch for other people to try and
then join my test network so that it can all be tested on a larger
scale. (The test network is not using the real tor network and thus
changes to the code work without affecting the live network ;)
Work is busy though, thus that is holding me off for a bit.

Greets,
 Jeroen
</body></email><email><emailId>201102061015420</emailId><senderName>Jeroen Massar</senderName><senderEmail>jeroen@unfix.org</senderEmail><timestampReceived>2011-02-06 10:15:42-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On 2011-02-04 16:41, Paulo Roberto wrote:
&gt; Hi,
&gt; My name is Beto and I'm an undergraduate student and I wish to do my
&gt; course's final project based on Tor. I have interest in work with the
&gt; session g of "Other conding and Design Ideas" of the volunteer page.
&gt; Add IPV6 support for destination address on exit nodes. I had some
&gt; Unix Programming and network skills.
&gt; I would like some directions where to start and to know what you
&gt; really expect in the end.

Note that I am running a private testbed of Tor nodes that support IPv6
already for bridge, relay and exit functionality.

Currently I am focusing on getting the consensus part to only tell nodes
to start using IPv6 when a certain ratio of nodes have IPv6 support
available. Bridge functionality is thus always enabled in the network so
that other nodes can come in over IPv6, but relay/exit is not enabled
yet if there are not enough nodes otherwise the ones running the few
IPv6 nodes would control everything.

Another issue is what to do with hostnames, connect over IPv4 or IPv6,
or, what the current implementation does, try AAAA's first and then A's,
as one is supposed to according to the IETF.

I also need to add a little "does IPv6 actually work" check to it,
though that is more a general system thing. This, because it could avoid
a lot of timeouts if some host thinks it has IPv6 connectivity (or IPv4
for that matter) but it actually does not work or times out.

Hopefully I will be able to invest a bit more time on this work in the
coming week and come up with a beta patch for other people to try and
then join my test network so that it can all be tested on a larger
scale. (The test network is not using the real tor network and thus
changes to the code work without affecting the live network ;)
Work is busy though, thus that is holding me off for a bit.

Greets,
 Jeroen
</body></email><email><emailId>20110208182847</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-08 18:28:47-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On Sun, Feb 6, 2011 at 5:15 AM, Jeroen Massar &lt;jeroen@unfix.org&gt; wrote:
 [...]
&gt; Hopefully I will be able to invest a bit more time on this work in the
&gt; coming week and come up with a beta patch for other people to try and
&gt; then join my test network so that it can all be tested on a larger
&gt; scale. (The test network is not using the real tor network and thus
&gt; changes to the code work without affecting the live network ;)
&gt; Work is busy though, thus that is holding me off for a bit.

Neat!  I am looking forward to seeing your code and spec changes.  (Do
you have spec changes here, or are you just "winging it"
protocolwise?)  Even if you don't have a chance to finish soon, it
might be a good idea (depending on the state of stuff) to use your
patches as a starting-off point rather than trying to implement IPv6
from scratch.

peace,
-- 
Nick Mathewson
</body></email><email><emailId>20110209110823</emailId><senderName>"Bjoern A. Zeeb"</senderName><senderEmail>bzeeb-lists@lists.zabbadoz.net</senderEmail><timestampReceived>2011-02-09 11:08:23-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On Tue, 8 Feb 2011, Nick Mathewson wrote:

Hey,

&gt; On Sun, Feb 6, 2011 at 5:15 AM, Jeroen Massar &lt;jeroen@unfix.org&gt; wrote:
&gt; [...]
&gt;&gt; Hopefully I will be able to invest a bit more time on this work in the
&gt;&gt; coming week and come up with a beta patch for other people to try and
&gt;&gt; then join my test network so that it can all be tested on a larger
&gt;&gt; scale. (The test network is not using the real tor network and thus
&gt;&gt; changes to the code work without affecting the live network ;)
&gt;&gt; Work is busy though, thus that is holding me off for a bit.
&gt;
&gt; Neat!  I am looking forward to seeing your code and spec changes.  (Do
&gt; you have spec changes here, or are you just "winging it"
&gt; protocolwise?)  Even if you don't have a chance to finish soon, it
&gt; might be a good idea (depending on the state of stuff) to use your
&gt; patches as a starting-off point rather than trying to implement IPv6
&gt; from scratch.

Having known about the changes I have been waiting for quite a while
to see them;-) I'd be happy to test patches.  I am really less interested
in the relay things currently and ideally that's a different matter to the
other two: proxy and exit node.

When it comes to AAAA lookups and what to do, I'd do whatever the
resovler on the host does. I talked to ayourtch last weekend.  Some
people have plans to implement draft-wing-v6ops-happy-eyeballs-ipv6
but I think we'll still see adjustments to the draft.  It will be
something that can be adopted easily at any later time on the exit
node (again ignoring any relay stuff for now where I'd hope it'd never
matter actually).

/bz

-- 
Bjoern A. Zeeb                                 You have to have visions!
          Stop bit received. Insert coin for new address family.
</body></email><email><emailId>20110210033335</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-02-10 03:33:35-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On Wed, Feb 9, 2011 at 3:08 AM, Bjoern A. Zeeb
&lt;bzeeb-lists@lists.zabbadoz.net&gt; wrote:
&gt; ...
&gt; When it comes to AAAA lookups and what to do, I'd do whatever the
&gt; resovler on the host does. I talked to ayourtch last weekend.  Some
&gt; people have plans to implement draft-wing-v6ops-happy-eyeballs-ipv6
&gt; but I think we'll still see adjustments to the draft.

it would be nice to "pass the buck" for resolver behavior to host,
however, this exposes partitioning and functional difficulties. Tor
must be consistent and resilient in its resolver behavior.

the happy eyeballs approach is aggressive but effective. downside is
roughly twice the circuit creation per stream on average than the
current case.

pragmatically some sane mostly common resolver compromises will be
needed. i am fond of relying on out-of-band hinting or other context
to suggest a preference for one type of resolution over another and
completing accordingly.

for example, when domains return both A and AAAA records for a given
FQDN, ignore/mask the A responses so that IPv6 connectivity is
default. there are other details that may differ from host resolver
behavior, but worth handling explicitly. [0]

these are mostly covered in the proposal sections listed below,

https://gitweb.torproject.org/tor.git/blob_plain/HEAD:/doc/spec/proposals/117-ipv6-exits.txt
1.3. DNS name resolution of IPv6 addresses (AAAA records)
1.4.2. SOCKSv5 IPv6 client behavior
1.4.3. MAPADDRESS behavior
1.4.4. DNSProxy IPv6 client behavior
1.4.5. TransPort IPv6 client behavior
3.1. DNS A6 records
3.2. IPv4 and IPv6 preference
3.3. Support for IPv6 only transparent proxy clients


0. regarding the AAAA preference when a domain has both A and AAAA
records associated. ideally the webhosts would do things like google
does, where an ipv6 resource only returns AAAA records, or a CNAME and
AAAA record configuration for usability. returning both A and AAAA
records to ipv6 preferred servers is not useful default behavior,
particularly considering the limitations of some client resolvers.

in any case, the devil in clearly in these many details. i am glad to
see progress being made and interest picking up!

best regards,

</body></email><email><emailId>20110210085409</emailId><senderName>"Bjoern A. Zeeb"</senderName><senderEmail>bzeeb-lists@lists.zabbadoz.net</senderEmail><timestampReceived>2011-02-10 08:54:09-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>


On Wed, 9 Feb 2011, coderman wrote:

&gt; On Wed, Feb 9, 2011 at 3:08 AM, Bjoern A. Zeeb
&gt; &lt;bzeeb-lists@lists.zabbadoz.net&gt; wrote:
&gt;&gt; ...
&gt;&gt; When it comes to AAAA lookups and what to do, I'd do whatever the
&gt;&gt; resovler on the host does. I talked to ayourtch last weekend.  Some
&gt;&gt; people have plans to implement draft-wing-v6ops-happy-eyeballs-ipv6
&gt;&gt; but I think we'll still see adjustments to the draft.
&gt;
&gt; it would be nice to "pass the buck" for resolver behavior to host,
&gt; however, this exposes partitioning and functional difficulties. Tor
&gt; must be consistent and resilient in its resolver behavior.
&gt;
&gt; the happy eyeballs approach is aggressive but effective. downside is
&gt; roughly twice the circuit creation per stream on average than the
&gt; current case.

why would that be given the router (exit node) would do the resolving
on behalf of the proxy and initiate multiple connects.  That should be
transparent to the proxy and OR network, shouldn't it?

/bz

-- 
Bjoern A. Zeeb                                 You have to have visions!
          Stop bit received. Insert coin for new address family.

</body></email><email><emailId>20110210104506</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-02-10 10:45:06-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

On Thu, Feb 10, 2011 at 12:54 AM, Bjoern A. Zeeb
&lt;bzeeb-lists@lists.zabbadoz.net&gt; wrote:
&gt; ...
&gt; why would that be given the router (exit node) would do the resolving
&gt; on behalf of the proxy and initiate multiple connects.  That should be
&gt; transparent to the proxy and OR network, shouldn't it?

if you could structure streams such that the exit chosen could always
satisfy both IPv4 and IPv6 to same named destination this could be
delegated to the endpoints.

note that depending on how the client is using Tor there may be
multiple resolve requests, following by one or more stream exit
requests, and exit policies or destinations (v4 or v6) may entail
distinct paths across to different exits depending on IPv4 or IPv6
transit.

put another way: you cannot assume exit requests will be by name
rather than explicit address.

best regards,

</body></email><email><emailId>20110208105808</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-02-08 10:58:08-0400</timestampReceived><subject>Re: Bridges with no DirPort failing?</subject><body>

On Tue, Feb 08, 2011 at 12:51:18AM -0800, SiNA wrote:
&gt; I am having issues connecting to one of my own Bridges that is only
&gt; listening on ORPort.
[snip]
&gt; ORPort	993
&gt; ORListenAddress 50.7.249.43:993
[snip]

&gt; Feb 08 00:39:23.974 [Info] connection_ap_make_link(): Making internal
&gt; direct tunnel to [scrubbed]:443 ...

You didn't show us the client's torrc, but I'm guessing you configured
your client to look for the bridge on 50.7.249.43:443, and there wasn't
a bridge there.

While you're debugging, you may enjoy setting "SafeLogging 0" in your
torrcs, so it gives you an actual address rather than "[scrubbed]".

--Roger

</body></email><email><emailId>20110208170248</emailId><senderName>SiNA</senderName><senderEmail>sina@anarchy.cx</senderEmail><timestampReceived>2011-02-08 17:02:48-0400</timestampReceived><subject>Re: Bridges with no DirPort failing?</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hello,

Please note that I erased my ~/.tor directory before running Tor client,
to generate this error:

Tor Client Config:
====================
AutomapHostsOnResolve 1
SafeLogging 0
#DNSListenAddress 127.0.0.1
#DNSPort 53
ExcludeNodes {US}
# Log debug file /var/log/tor/debug.log
TransListenAddress 127.0.0.1
TransPort 9040

UseBridges 1
TunnelDirConns 1
Bridge 50.7.249.43:993



Tor Client Log:
===============
Feb 08 08:58:34.953 [Notice] Tor v0.2.2.22-alpha (git-21b3de6cf37d4e60).
This is experimental software. Do not rely on it for strong anonymity.
(Running on Linux i686)
Feb 08 08:58:34.954 [Notice] Initialized libevent version 1.4.13-stable
using method epoll. Good.
Feb 08 08:58:34.955 [Notice] Opening Socks listener on 127.0.0.1:9050
Feb 08 08:58:34.955 [Notice] Opening Transparent pf/netfilter listener
on 127.0.0.1:9040
Feb 08 08:58:34.955 [Notice] Opening Control listener on 127.0.0.1:9051
Feb 08 08:58:34.956 [Warning] Fixing permissions on directory
/home/architect/.tor
Feb 08 08:58:34.956 [Notice] Parsing GEOIP file /usr/share/tor/geoip.
Feb 08 08:58:37.873 [Debug] conn_read_callback(): socket 10 wants to read.
Feb 08 08:58:37.874 [Debug] conn_read_callback(): socket 10 wants to read.
Feb 08 08:58:37.874 [Debug] conn_read_callback(): socket 10 wants to read.
Feb 08 08:58:38.094 [Debug] conn_write_callback(): socket 11 wants to write.
Feb 08 08:58:38.095 [Debug] connection_or_finished_connecting(): OR
connect() to router at 50.7.249.43:993 finished.
Feb 08 08:58:38.095 [Notice] Bootstrapped 10%: Finishing handshake with
directory server.
Feb 08 08:58:38.099 [Debug] rectify_client_ciphers(): List was:
ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES256-SHA:DHE-DSS-AES256-SHA:ECDH \
-RSA-AES256-SHA:ECDH-ECDSA-AES256-SHA:AES256-SHA:ECDHE-ECDSA-RC4-SHA:ECDHE-ECDSA-AES12 \
8-SHA:ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:ECD \
H-RSA-RC4-SHA:ECDH-RSA-AES128-SHA:ECDH-ECDSA-RC4-SHA:ECDH-ECDSA-AES128-SHA:RC4-MD5:RC4 \
-SHA:AES128-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:EDH-DSS-DES-CBC3-SHA:ECDH-RSA-DES-CBC3-SHA:ECDH-ECDSA-DES-CBC3-SHA:DES-CBC3-SHA:
 Feb 08 08:58:38.100 [Debug] rectify_client_ciphers(): Cipher 0: 300c00a
ECDHE-ECDSA-AES256-SHA
Feb 08 08:58:38.101 [Debug] rectify_client_ciphers(): Cipher 1: 300c014
ECDHE-RSA-AES256-SHA
Feb 08 08:58:38.101 [Debug] rectify_client_ciphers(): Cipher 2: 3000039
DHE-RSA-AES256-SHA
Feb 08 08:58:38.103 [Debug] rectify_client_ciphers(): Cipher 3: 3000038
DHE-DSS-AES256-SHA
Feb 08 08:58:38.103 [Debug] rectify_client_ciphers(): Cipher 4: 300c00f
ECDH-RSA-AES256-SHA
Feb 08 08:58:38.104 [Debug] rectify_client_ciphers(): Cipher 5: 300c005
ECDH-ECDSA-AES256-SHA
Feb 08 08:58:38.104 [Debug] rectify_client_ciphers(): Cipher 6: 3000035
AES256-SHA
Feb 08 08:58:38.105 [Debug] rectify_client_ciphers(): Cipher 7: 300c007
ECDHE-ECDSA-RC4-SHA
Feb 08 08:58:38.105 [Debug] rectify_client_ciphers(): Cipher 8: 300c009
ECDHE-ECDSA-AES128-SHA
Feb 08 08:58:38.106 [Debug] rectify_client_ciphers(): Cipher 9: 300c011
ECDHE-RSA-RC4-SHA
Feb 08 08:58:38.106 [Debug] rectify_client_ciphers(): Cipher 10: 300c013
ECDHE-RSA-AES128-SHA
Feb 08 08:58:38.107 [Debug] rectify_client_ciphers(): Cipher 11: 3000033
DHE-RSA-AES128-SHA
Feb 08 08:58:38.107 [Debug] rectify_client_ciphers(): Cipher 12: 3000032
DHE-DSS-AES128-SHA
Feb 08 08:58:38.108 [Debug] rectify_client_ciphers(): Cipher 13: 300c00c
ECDH-RSA-RC4-SHA
Feb 08 08:58:38.108 [Debug] rectify_client_ciphers(): Cipher 14: 300c00e
ECDH-RSA-AES128-SHA
Feb 08 08:58:38.109 [Debug] rectify_client_ciphers(): Cipher 15: 300c002
ECDH-ECDSA-RC4-SHA
Feb 08 08:58:38.109 [Debug] rectify_client_ciphers(): Cipher 16: 300c004
ECDH-ECDSA-AES128-SHA
Feb 08 08:58:38.110 [Debug] rectify_client_ciphers(): Cipher 17: 3000004
RC4-MD5
Feb 08 08:58:38.110 [Debug] rectify_client_ciphers(): Cipher 18: 2010080
RC4-MD5
Feb 08 08:58:38.110 [Debug] rectify_client_ciphers(): Cipher 19: 3000005
RC4-SHA
Feb 08 08:58:38.111 [Debug] rectify_client_ciphers(): Cipher 20: 300002f
AES128-SHA
Feb 08 08:58:38.111 [Debug] rectify_client_ciphers(): Cipher 21: 300c008
ECDHE-ECDSA-DES-CBC3-SHA
Feb 08 08:58:38.112 [Debug] rectify_client_ciphers(): Cipher 22: 300c012
ECDHE-RSA-DES-CBC3-SHA
Feb 08 08:58:38.112 [Debug] rectify_client_ciphers(): Cipher 23: 3000016
EDH-RSA-DES-CBC3-SHA
Feb 08 08:58:38.113 [Debug] rectify_client_ciphers(): Cipher 24: 3000013
EDH-DSS-DES-CBC3-SHA
Feb 08 08:58:38.113 [Debug] rectify_client_ciphers(): Cipher 25: 300c00d
ECDH-RSA-DES-CBC3-SHA
Feb 08 08:58:38.114 [Debug] rectify_client_ciphers(): Cipher 26: 300c003
ECDH-ECDSA-DES-CBC3-SHA
Feb 08 08:58:38.114 [Debug] rectify_client_ciphers(): Cipher 27: 300000a
DES-CBC3-SHA
Feb 08 08:58:38.115 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-ECDSA-AES256-SHA
Feb 08 08:58:38.115 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-RSA-AES256-SHA
Feb 08 08:58:38.116 [Debug] rectify_client_ciphers(): Found cipher
DHE-RSA-AES256-SHA
Feb 08 08:58:38.116 [Debug] rectify_client_ciphers(): Found cipher
DHE-DSS-AES256-SHA
Feb 08 08:58:38.116 [Debug] rectify_client_ciphers(): Found cipher
ECDH-RSA-AES256-SHA
Feb 08 08:58:38.117 [Debug] rectify_client_ciphers(): Found cipher
ECDH-ECDSA-AES256-SHA
Feb 08 08:58:38.118 [Debug] rectify_client_ciphers(): Found cipher
AES256-SHA
Feb 08 08:58:38.118 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-ECDSA-RC4-SHA
Feb 08 08:58:38.119 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-ECDSA-AES128-SHA
Feb 08 08:58:38.119 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-RSA-RC4-SHA
Feb 08 08:58:38.120 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-RSA-AES128-SHA
Feb 08 08:58:38.121 [Debug] rectify_client_ciphers(): Found cipher
DHE-RSA-AES128-SHA
Feb 08 08:58:38.121 [Debug] rectify_client_ciphers(): Found cipher
DHE-DSS-AES128-SHA
Feb 08 08:58:38.122 [Debug] rectify_client_ciphers(): Found cipher
ECDH-RSA-RC4-SHA
Feb 08 08:58:38.122 [Debug] rectify_client_ciphers(): Found cipher
ECDH-RSA-AES128-SHA
Feb 08 08:58:38.123 [Debug] rectify_client_ciphers(): Found cipher
ECDH-ECDSA-RC4-SHA
Feb 08 08:58:38.124 [Debug] rectify_client_ciphers(): Found cipher
ECDH-ECDSA-AES128-SHA
Feb 08 08:58:38.124 [Debug] rectify_client_ciphers(): Found cipher RC4-MD5
Feb 08 08:58:38.124 [Debug] rectify_client_ciphers(): Skipping v2 cipher
RC4-MD5
Feb 08 08:58:38.125 [Debug] rectify_client_ciphers(): Found cipher RC4-SHA
Feb 08 08:58:38.125 [Debug] rectify_client_ciphers(): Found cipher
AES128-SHA
Feb 08 08:58:38.125 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-ECDSA-DES-CBC3-SHA
Feb 08 08:58:38.126 [Debug] rectify_client_ciphers(): Found cipher
ECDHE-RSA-DES-CBC3-SHA
Feb 08 08:58:38.126 [Debug] rectify_client_ciphers(): Found cipher
EDH-RSA-DES-CBC3-SHA
Feb 08 08:58:38.126 [Debug] rectify_client_ciphers(): Found cipher
EDH-DSS-DES-CBC3-SHA
Feb 08 08:58:38.127 [Debug] rectify_client_ciphers(): Found cipher
ECDH-RSA-DES-CBC3-SHA
Feb 08 08:58:38.127 [Debug] rectify_client_ciphers(): Found cipher
ECDH-ECDSA-DES-CBC3-SHA
Feb 08 08:58:38.127 [Debug] rectify_client_ciphers(): Inserting fake
SSL3_TXT_RSA_FIPS_WITH_3DES_EDE_CBC_SHA
Feb 08 08:58:38.128 [Debug] rectify_client_ciphers(): Found cipher
DES-CBC3-SHA
Feb 08 08:58:38.128 [Debug] connection_tls_start_handshake(): starting
TLS handshake on fd 11
Feb 08 08:58:38.128 [Debug] tor_tls_handshake(): About to call
SSL_connect on 0x20be9d30 (Unknown state 24576)
Feb 08 08:58:38.129 [Debug] tor_tls_handshake(): After call, 0x20be9d30
was in state SSL23_ST_CR_SRVR_HELLO_A
Feb 08 08:58:38.129 [Debug] connection_tls_continue_handshake(): wanted read
Feb 08 08:58:38.129 [Debug] tor_tls_handshake(): About to call
SSL_connect on 0x20be9d30 (SSL23_ST_CR_SRVR_HELLO_A)
Feb 08 08:58:38.130 [Debug] connection_tls_continue_handshake(): wanted read
Feb 08 08:58:38.417 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:38.417 [Debug] tor_tls_handshake(): About to call
SSL_connect on 0x20be9d30 (SSL23_ST_CR_SRVR_HELLO_A)
Feb 08 08:58:38.418 [Debug] tor_tls_handshake(): After call, 0x20be9d30
was in state SSL3_ST_CR_SESSION_TICKET_A
Feb 08 08:58:38.418 [Debug] connection_tls_continue_handshake(): wanted read
Feb 08 08:58:38.646 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:38.646 [Debug] tor_tls_handshake(): About to call
SSL_connect on 0x20be9d30 (SSL3_ST_CR_SESSION_TICKET_A)
Feb 08 08:58:38.647 [Debug] tor_tls_handshake(): After call, 0x20be9d30
was in state SSL_ST_OK
Feb 08 08:58:38.647 [Debug] tor_tls_handshake(): Server sent back a
single certificate; looks like a v2 handshake on 0x20be9d30.
Feb 08 08:58:38.648 [Debug] connection_tls_continue_handshake(): wanted read
Feb 08 08:58:38.987 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:38.987 [Debug] connection_tls_continue_handshake(): wanted read
Feb 08 08:58:39.227 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:39.228 [Debug] connection_tls_finish_handshake(): tls
handshake with 50.7.249.43 done. verifying.
Feb 08 08:58:39.229 [Debug] connection_or_check_valid_tls_handshake():
The certificate seems to be valid on outgoing connection with
50.7.249.43:993
Feb 08 08:58:39.229 [Info] connection_or_check_valid_tls_handshake():
Connected to router $956B9E3D11C26F77B8EC878ECC7C830A543867D2 at
50.7.249.43:993 without knowing its key. Hoping for the best.
Feb 08 08:58:39.230 [Notice] Learned fingerprint
956B9E3D11C26F77B8EC878ECC7C830A543867D2 for bridge 50.7.249.43:993
Feb 08 08:58:39.231 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 0 (0 pending in tls object).
Feb 08 08:58:39.232 [Debug] conn_write_callback(): socket 11 wants to write.
Feb 08 08:58:39.233 [Debug] flush_chunk_tls(): flushed 9 bytes, 0 ready
to flush, 0 remain.
Feb 08 08:58:39.233 [Debug] connection_handle_write_impl(): After TLS
write of 9: 3508 read, 1902 written
Feb 08 08:58:39.459 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:39.460 [Debug] connection_read_to_buf(): 11: starting,
inbuf_datalen 0 (0 pending in tls object). at_most 16384.
Feb 08 08:58:39.462 [Debug] connection_read_to_buf(): After TLS read of
521: 586 read, 0 written
Feb 08 08:58:39.462 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 521 (0 pending in tls object).
Feb 08 08:58:39.463 [Info] command_process_versions_cell(): Negotiated
version 2 with 50.7.249.43:993; sending NETINFO.
Feb 08 08:58:39.463 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 512 (0 pending in tls object).
Feb 08 08:58:39.464 [Debug] circuit_n_conn_done(): or_conn to
$956B9E3D11C26F77B8EC878ECC7C830A543867D2/50.7.249.43, status=1
Feb 08 08:58:39.465 [Debug] circuit_n_conn_done(): Found circ, sending
create cell.
Feb 08 08:58:39.465 [Debug] circuit_send_next_onion_skin(): First skin;
sending create cell.
Feb 08 08:58:39.466 [Notice] Bootstrapped 15%: Establishing an encrypted
directory connection.
Feb 08 08:58:39.468 [Debug] circuit_deliver_create_cell(): Chosen circID
49970.
Feb 08 08:58:39.469 [Debug] append_cell_to_circuit_queue(): Made a
circuit active.
Feb 08 08:58:39.470 [Info] circuit_send_next_onion_skin(): First hop:
finished sending CREATE_FAST cell to '&lt;unnamed&gt;'
Feb 08 08:58:39.471 [Info] command_process_netinfo_cell(): Got good
NETINFO cell from 50.7.249.43:993; OR connection is now open, using
protocol version 2
Feb 08 08:58:39.471 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 0 (0 pending in tls object).
Feb 08 08:58:39.471 [Debug] conn_write_callback(): socket 11 wants to write.
Feb 08 08:58:39.472 [Debug] flush_chunk_tls(): flushed 512 bytes, 0
ready to flush, 0 remain.
Feb 08 08:58:39.472 [Debug] connection_handle_write_impl(): After TLS
write of 512: 0 read, 586 written
Feb 08 08:58:39.473 [Debug]
connection_or_flush_from_first_active_circuit(): Made a circuit inactive.
Feb 08 08:58:39.473 [Debug] conn_write_callback(): socket 11 wants to write.
Feb 08 08:58:39.473 [Debug] flush_chunk_tls(): flushed 512 bytes, 0
ready to flush, 0 remain.
Feb 08 08:58:39.474 [Debug] connection_handle_write_impl(): After TLS
write of 512: 0 read, 586 written
Feb 08 08:58:39.926 [Debug] global_read_bucket now 10485760.
Feb 08 08:58:39.933 [Debug] global_write_bucket now 10485760.
Feb 08 08:58:39.933 [Debug] global_relayed_read_bucket now 10485760.
Feb 08 08:58:39.934 [Debug] global_relayed_write_bucket now 10485760.
Feb 08 08:58:39.934 [Debug] or_conn-&gt;write_bucket now 10485760.
Feb 08 08:58:39.990 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:39.995 [Debug] connection_read_to_buf(): 11: starting,
inbuf_datalen 0 (0 pending in tls object). at_most 16384.
Feb 08 08:58:39.996 [Debug] connection_read_to_buf(): After TLS read of
512: 586 read, 0 written
Feb 08 08:58:39.996 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 512 (0 pending in tls object).
Feb 08 08:58:39.997 [Debug] command_process_created_cell(): at OP.
Finishing handshake.
Feb 08 08:58:39.997 [Info] circuit_finish_handshake(): Finished building
fast circuit hop:
Feb 08 08:58:39.998 [Info] exit circ (length 1, exit
0000000000000000000000000000000000000000):
$0000000000000000000000000000000000000000(open)
Feb 08 08:58:39.998 [Debug] command_process_created_cell(): Moving to
next skin.
Feb 08 08:58:39.998 [Debug] circuit_send_next_onion_skin(): starting to
send subsequent skin.
Feb 08 08:58:39.999 [Info] circuit_send_next_onion_skin(): circuit built!
Feb 08 08:58:39.999 [Notice] Bootstrapped 20%: Asking for networkstatus
consensus.
Feb 08 08:58:40.001 [Debug] connection_ap_handshake_attach_circuit():
Attaching apconn to circ 49970 (stream 2 sec old).
Feb 08 08:58:40.002 [Info] exit circ (length 1):
$0000000000000000000000000000000000000000(open)
Feb 08 08:58:40.003 [Debug] link_apconn_to_circ(): attaching new conn to
circ. n_circ_id 49970.
Feb 08 08:58:40.004 [Debug] connection_ap_handshake_send_begin():
Sending relay cell to begin stream 16864.
Feb 08 08:58:40.005 [Debug] relay_send_command_from_edge(): delivering
13 cell forward.
Feb 08 08:58:40.005 [Debug] circuit_package_relay_cell(): crypting a
layer of the relay cell.
Feb 08 08:58:40.006 [Debug] append_cell_to_circuit_queue(): Made a
circuit active.
Feb 08 08:58:40.006 [Debug] append_cell_to_circuit_queue(): Primed a buffer.
Feb 08 08:58:40.007 [Debug]
connection_or_flush_from_first_active_circuit(): Made a circuit inactive.
Feb 08 08:58:40.007 [Info] connection_ap_handshake_send_begin():
Address/port sent, ap socket -1, n_circ_id 49970
Feb 08 08:58:40.008 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 0 (0 pending in tls object).
Feb 08 08:58:40.008 [Debug] conn_write_callback(): socket 11 wants to write.
Feb 08 08:58:40.009 [Debug] flush_chunk_tls(): flushed 512 bytes, 0
ready to flush, 0 remain.
Feb 08 08:58:40.009 [Debug] connection_handle_write_impl(): After TLS
write of 512: 0 read, 586 written
Feb 08 08:58:40.194 [Debug] conn_read_callback(): socket 11 wants to read.
Feb 08 08:58:40.197 [Debug] connection_read_to_buf(): 11: starting,
inbuf_datalen 0 (0 pending in tls object). at_most 16384.
Feb 08 08:58:40.198 [Debug] connection_read_to_buf(): After TLS read of
512: 586 read, 0 written
Feb 08 08:58:40.198 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 512 (0 pending in tls object).
Feb 08 08:58:40.199 [Debug] relay_lookup_conn(): found conn for stream
16864.
Feb 08 08:58:40.199 [Debug] circuit_receive_relay_cell(): Sending to origin.
Feb 08 08:58:40.200 [Debug] connection_edge_process_relay_cell(): Now
seen 1 relay cells here (command 3, stream 16864).
Feb 08 08:58:40.200 [Info] connection_ap_process_end_not_open(): Edge
got end (not a directory) before we're connected. Marking for close.
Feb 08 08:58:40.200 [Info] exit circ (length 1):
$0000000000000000000000000000000000000000(open)
Feb 08 08:58:40.201 [Info] stream_end_reason_to_socks5_response():
Reason for ending (526) not recognized; sending generic socks error.
Feb 08 08:58:40.202 [Debug] connection_or_process_cells_from_inbuf():
11: starting, inbuf_datalen 0 (0 pending in tls object).
Feb 08 08:58:40.202 [Debug] conn_close_if_marked(): Cleaning up
connection (fd -1).
Feb 08 08:58:40.203 [Debug] connection_remove(): removing socket -1
(type Socks), n_conns now 7
Feb 08 08:58:40.203 [Info] _connection_free(): Freeing linked Socks
connection [waiting for connect response] with 63 bytes on inbuf, 0 on
outbuf.
Feb 08 08:58:40.204 [Debug] conn_read_callback(): socket -1 wants to read.
Feb 08 08:58:40.204 [Info] connection_dir_client_reached_eof(): 'fetch'
response not all here, but we're at eof. Closing.
Feb 08 08:58:40.205 [Debug] conn_close_if_marked(): Cleaning up
connection (fd -1).
Feb 08 08:58:40.205 [Info] connection_dir_request_failed(): Giving up on
directory server at '50.7.249.43'; retrying
Feb 08 08:58:40.205 [Debug] connection_remove(): removing socket -1
(type Directory), n_conns now 6
Feb 08 08:58:40.206 [Info] _connection_free(): Freeing linked Directory
connection [client reading] with 0 bytes on inbuf, 0 on outbuf.
Feb 08 08:58:40.866 [Debug] global_read_bucket now 10485760.
Feb 08 08:58:40.868 [Debug] global_write_bucket now 10485760.
Feb 08 08:58:40.870 [Debug] or_conn-&gt;read_bucket now 10485760.
Feb 08 08:58:40.871 [Debug] or_conn-&gt;write_bucket now 10485760.
Feb 08 08:58:48.882 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:58:48.883 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:58:48.884 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:58:59.921 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:58:59.923 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:58:59.925 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:59:10.954 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:59:10.956 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:59:10.956 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:59:21.990 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:59:21.992 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:59:21.992 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:59:32.017 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:59:32.019 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:59:32.019 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:59:38.034 [Info] smartlist_choose_by_bandwidth_weights():
Empty routerlist passed in to consensus weight node selection for rule
weight as guard
Feb 08 08:59:38.036 [Info] smartlist_choose_by_bandwidth(): Empty
routerlist passed in to old node selection for rule weight as guard
Feb 08 08:59:38.037 [Info] should_delay_dir_fetches(): delaying dir
fetches (no running bridges known)
Feb 08 08:59:42.520 [Debug] conn_read_callback(): socket 10 wants to read.
Feb 08 08:59:42.541 [Debug] conn_read_callback(): socket 10 wants to read.


- --
SiNA
pgp 0x0B47D56D

On 02/08/2011 02:58 AM, Roger Dingledine wrote:
&gt; SafeLogging 0
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQIcBAEBAgAGBQJNUXcwAAoJEJPBwXYLR9Vt6lcP/0h0B8WA2PAYjBqw1gev9krm
dNc5wWyrwB7O5HEr5whAdPQ5HOuE3kYqzQ7SgULJoWajwNncjRfgVTCsnJqsAMLW
cs+r8uvadzYWxCrWk/23qdIQp9yA8dVlQKNSfdyYgDG/8l1DiEV/DS/XsAW7QgFx
D+h4W1s6uML3U9Mi0nt7922hm1G6cScBZ+dokuwOXZrodQvVQ5JJuadBYp011GjD
aAjqyXf5J8YvZld8Z8HWQwqeUsxJzIwgerKdid6A8G7fBrJvebLSAy/OA0wIK0tF
OYkJ/JZ/R/CjHbvCzd5efcj0yHhHpOeMF9R79MZO9FGVPuyzeKwiy/l9YsqIfggk
j25nRPdCXbFxU4GdyUVYI6adbF0QOc2Yqjq+ptqyUyRYhwS88rXwUATrBNa7uYwm
PH6h1H134551lnhAmhT/V1D5qLr94kQyUrT234LOtrQJF97bQ/L+k094BQx+9kU1
kfKoIF56njsMENwfwBOlJEeUzZ7y2ghB/gKUQBA8jMe4Lw0qY7HKWGtcHuR3Wxr7
hOifaASzwFhdFA3bxvoIKRhTV+d9+RVcmASRt9hdDsd3ZE5AC6RYbGTqQ5UsAXHV
Ia7fuGWk4MhLLUS48BsqulSnh3hluKyJnXbp6f4psySAj+5guWEzQN/03vwf5giu
qWxfbhkCJ8/UVNssp6f9
=eU28
-----END PGP SIGNATURE-----


</body></email><email><emailId>20110208223828</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-02-08 22:38:28-0400</timestampReceived><subject>Re: Bridges with no DirPort failing?</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On Tue, 08 Feb 2011 00:51:18 -0800
SiNA &lt;sina@anarchy.cx&gt; wrote:

&gt; I am having issues connecting to one of my own Bridges that is only
&gt; listening on ORPort.
&gt; 
&gt; However when I add DirPort 9030, I am able to successfully connect to
&gt; the Bridge!
&gt; 
&gt; My Tor client and the 'failing Bridge' configuration:
&gt; 
&gt; Bridge config:
&gt; ==============
&gt; log debug file /usr/local/var/log/tor/debug-2.log
&gt; RunAsDaemon 1
&gt; DataDirectory /usr/local/var/lib/tor-2
&gt; SocksPort 0
&gt; ORPort	993
&gt; ORListenAddress 50.7.249.43:993
&gt; Nickname 25bahman002
&gt; Address 50.7.249.43
&gt; RelayBandwidthRate 1000 KB  # Throttle traffic to 100KB/s (800Kbps)
&gt; RelayBandwidthBurst 5000 KB # But allow bursts up to 200KB/s (1600Kbps)
&gt; ContactInfo 4096R/0B47D56D SiNA &lt;sina AT anarchy dot cx&gt;
&gt; MyFamily 25bahman001,25bahman002,25bahman003

This is a published relay (and an exit node), not a bridge (a bridge
needs "BridgeRelay 1" and should have "ExitPolicy reject *;*" in its
torrc).

As I understand it, Tor bridges handle BEGIN_DIR requests, Tor clients
that are configured to use bridges request directory information from
their bridges using BEGIN_DIR requests, and non-bridge Tor relays with
no DirPort configured may or may not handle BEGIN_DIR requests.  That
may be the issue with your configuration.


Robert Ransom
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iJwEAQEIAAYFAk1RxeQACgkQ4sl+edAygsTMWAP6AtaP0iQBhOMAIwxtzv/n12tp
zd0UkVLBM575cab7XvkJDRaQgEtgp2uZRlyFYAdpTkk99Fg1/d0v+2U5QMu5Snxu
F5QNatuvke0Ozew7JwlRxp6uGSU9viDO66ehUzu+mlKrRjeJnSkLSxgtDKLuYmHJ
00PqNmQnFs2OK6j92GQ=
=d7Me
-----END PGP SIGNATURE-----

</body></email><email><emailId>20110209123558</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-02-09 12:35:58-0400</timestampReceived><subject>Re: Bridges with no DirPort failing?</subject><body>

On Tue, Feb 08, 2011 at 02:38:28PM -0800, Robert Ransom wrote:
&gt; &gt; I am having issues connecting to one of my own Bridges that is only
&gt; &gt; listening on ORPort.
&gt; &gt; 
&gt; &gt; However when I add DirPort 9030, I am able to successfully connect to
&gt; &gt; the Bridge!
&gt; &gt; 
&gt; &gt; My Tor client and the 'failing Bridge' configuration:
&gt; &gt; 
&gt; &gt; Bridge config:
&gt; &gt; ==============
&gt; &gt; log debug file /usr/local/var/log/tor/debug-2.log
&gt; &gt; RunAsDaemon 1
&gt; &gt; DataDirectory /usr/local/var/lib/tor-2
&gt; &gt; SocksPort 0
&gt; &gt; ORPort	993
&gt; &gt; ORListenAddress 50.7.249.43:993
&gt; &gt; Nickname 25bahman002
&gt; &gt; Address 50.7.249.43
&gt; &gt; RelayBandwidthRate 1000 KB  # Throttle traffic to 100KB/s (800Kbps)
&gt; &gt; RelayBandwidthBurst 5000 KB # But allow bursts up to 200KB/s (1600Kbps)
&gt; &gt; ContactInfo 4096R/0B47D56D SiNA &lt;sina AT anarchy dot cx&gt;
&gt; &gt; MyFamily 25bahman001,25bahman002,25bahman003
&gt; 
&gt; This is a published relay (and an exit node), not a bridge (a bridge
&gt; needs "BridgeRelay 1"

Ah ha! Yes, good catch. I believe that's the answer here.

&gt; and should have "ExitPolicy reject *;*" in its torrc).

Yep. As of Tor 0.2.2.6-alpha the default exit policy for a bridge is
reject *:*. But before 0.2.2.6-alpha, it looks like you will need to
set your exitpolicy to reject *:* explicitly.

&gt; As I understand it, Tor bridges handle BEGIN_DIR requests, Tor clients
&gt; that are configured to use bridges request directory information from
&gt; their bridges using BEGIN_DIR requests, and non-bridge Tor relays with
&gt; no DirPort configured may or may not handle BEGIN_DIR requests.  That
&gt; may be the issue with your configuration.

Correct.

--Roger

</body></email><email><emailId>20110210104913</emailId><senderName>Marcus Wolschon</senderName><senderEmail>marcus@wolschon.biz</senderEmail><timestampReceived>2011-02-10 10:49:13-0400</timestampReceived><subject>Re: IPV6 address support on exit nodes</subject><body>

Am 10.02.2011 11:45, schrieb coderman:
&gt; On Thu, Feb 10, 2011 at 12:54 AM, Bjoern A. Zeeb
&gt; &lt;bzeeb-lists@lists.zabbadoz.net&gt;  wrote:
&gt;&gt; ...
&gt;&gt; why would that be given the router (exit node) would do the resolving
&gt;&gt; on behalf of the proxy and initiate multiple connects.  That should be
&gt;&gt; transparent to the proxy and OR network, shouldn't it?
&gt; if you could structure streams such that the exit chosen could always
&gt; satisfy both IPv4 and IPv6 to same named destination this could be
&gt; delegated to the endpoints.
&gt;
&gt; note that depending on how the client is using Tor there may be
&gt; multiple resolve requests, following by one or more stream exit
&gt; requests, and exit policies or destinations (v4 or v6) may entail
&gt; distinct paths across to different exits depending on IPv4 or IPv6
&gt; transit.
&gt;
&gt; put another way: you cannot assume exit requests will be by name
&gt; rather than explicit address.
&gt;
&gt; best regards,


During all this planning please keep in mind that IPv6-only will exist too.

Marcus
</body></email><email><emailId>20110210184615</emailId><senderName>Florian Tschorsch</senderName><senderEmail>tschorsch@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2011-02-10 18:46:15-0400</timestampReceived><subject>Re: Proposal: Token Bucket</subject><body>

Hi Nick,

sorry for the long round-trip time (even exceeding those in the Tor
network ;) ).

On Mo, 2011-01-24 at 13:40 -0500, Nick Mathewson wrote: 
&gt;&gt; If incoming and outgoing bandwidth limits are equal, an increase in the
&gt;&gt; volume of traffic within the onion router, in fact, even constitutes an
&gt;&gt; even stronger argument for our proposed modifications: if you have a
&gt;&gt; system (here: the queues in the onion router) where you continuously
&gt;&gt; admit more data into the system (incoming bandwidth limit + additional
&gt;&gt; overhead and traffic) than you allow to leave the system (outgoing
&gt;&gt; bandwidth limit), you will necessarily build up longer and longer queues
&gt;&gt; within the system, which will in turn cause very long cell delays -
&gt;&gt; which is just what we currently observe in Tor. Therefore, limiting the
&gt;&gt; amount of traffic on both ends is simply not a good idea.
&gt; 
&gt; Ah, I think I wasn't clear about the scope of my objection.  I'm not
&gt; arguing against the idea of doing something useful to ameliorate the
&gt; queueing issue: I am arguing against the original proposal, which was
&gt; (if I understood correctly) to eliminate outbound rate limiting
&gt; entirely.  The other proposals you suggest below (limiting read to a
&gt; fraction of write, either adaptively or at a fixed degree) are much
&gt; IMO better.

we were indeed proposing to eliminate the outgoing rate limitation
completely, and instead to establish other means to keep Tor's bandwidth
within the desired limits - by limiting the amount of data going into a
relay and/or being "produced" in a relay. This will avoid data "piling
up" in the system. I admit that there may exist scenarios where a too
simple solution could cause trouble, though - I don't have much to say
against your attacker driving a relay to exceed its configured bandwidth
limits.

I would nevertheless still very much prefer a solution that can get rid
of outgoing rate limitation entirely, if (and only if - you're perfectly
right about this) we manage to build the rest of the system in a way
that it will anyway stay within the configured limits. Simply because
such a solution is much easier to understand and analyze, and will thus
be much less likely to cause any unexpected trouble in the future (like
the side effects that we observe with the current design).

&gt; The reason that I can't agree with the original proposal ("remove the
&gt; rate limiting mechanism on the outgoing side") is that it will make
&gt; Tor nodes potentially write much, much more than they have been
&gt; configured to write.  Operators often configure rate limits for good
&gt; reasons: to conserve limited bandwidth, to save money if they're
&gt; paying by the byte, or to avoid bothering their local network
&gt; administrators.  When Tor violates its configured rate limits,
&gt; operators get angry.  Since we depend on volunteers to operate the Tor
&gt; network, we need to keep them happy, and so using more of their
&gt; bandwidth than they've agreed to provide us is not a good idea.

I fully agree with your point, and that aspect is certainly to be kept
in mind. So, the question is: how can we ensure that the configured rate
limits are not exceeded with the lowest possible system complexity, and
in conjunction with a queueing design that is stable and has good
performance.

&gt;&gt; One may of course argue that the (admittely in extreme cases
&gt;&gt; significant) packaging overhead should be accounted for when Tor
&gt;&gt; enforces the configured bandwidth limits. However, to be consistent, one
&gt;&gt; would then also have to account for TLS, TCP, and IP header overhead,
&gt;&gt; which is currently neglected. This overhead will also be very
&gt;&gt; significant if traffic arrives *that* slowly, i.e., if you have TCP
&gt;&gt; segments far smaller than a cell size.
&gt;&gt; 
&gt;&gt; This will certainly be interesting to assess in more detail. In case it
&gt;&gt; actually turns out to be an issue, I see two options:
&gt;&gt; 
&gt;&gt; i) the pragmatic solution: based on a measurement study how much the
&gt;&gt; traffic typically "grows" due to packaging overhead etc., reduce the
&gt;&gt; configured bandwidth limit by an appropriate percentage
&gt;&gt; 
&gt;&gt; ii) an "observe+adjust" mechanism: observe how much traffic is actually
&gt;&gt; leaving the router; if the outgoing traffic exceeds the configured
&gt;&gt; limit, reduce the rate at which data is read on the incoming side
&gt;&gt; accordingly
&gt;&gt; 
&gt;&gt; The latter, if done right, would be able to guarantee that configured
&gt;&gt; bandwidth limits are strictly enforced, despite additional traffic being
&gt;&gt; generated in the router, and in even in case of an arbitrarily high
&gt;&gt; packaging overhead. However, my feeling is that this is a too complex
&gt;&gt; solution for a very simple problem.
&gt; 
&gt; I think we do need to go with something closer to the latter more
&gt; sophisticated approach for a couple of reasons.
&gt; 
&gt; First, as noted above, we really do need to enforce the configured
&gt; bandwidth limits.
&gt; 
&gt; Second, we must consider attackers.  It's not enough to say that based
&gt; on empirical evidence, directory responses currently occupy a small
&gt; fraction of data written, or that with current traffic loads each cell
&gt; is on average (say) 70% full.  If an attacker can make lots of
&gt; directory requests, or trickle data one byte at a time on a large
&gt; number of streams, he can cause the outbound data to exceed the
&gt; inbound data by much more than expected.

Well - I could answer that pragmatically: you cannot enforce these rate
limits anyway (at least not from within the Tor software). An attacker
can easily generate arbitrary amounts of *incoming* data - which will
likely make the network administrators equally angry. :) But anyway,
yes, I do see your point, and we should take such attacks into account.

&gt; So I think the only approach that's going to work here is to hold the
&gt; outbound rate fixed while adaptively adjusting the input rate
&gt; downwards until we stop generating outbound traffic faster than we can
&gt; send it.

In our discussions here Florian Tschorsch had an IMHO very nice idea: we
continue to use a token bucket on the incoming side to limit the
incoming rate anyway. It will also be easy to monitor (not limit!) the
outgoing rate. We might make use of these two mechanisms to proceed as
follows: if we notice that the outgoing rate exceeds the configured
limit, then we might remove a corresponding amount of tokens from the
bucket on the *incoming* side, thereby slowing down the rate at which
data (including relay traffic, directory requests,...) flows into the
router. (We might allow the incoming bucket to take on negative fill
levels as we do so, so that temporarily exceeding the configured rate
will be compensated by entirely stopping the incoming data flow until
the excess has been compensated by "future" tokens.)

I like that solution because it appears effective - it is easy to see
that it will strictly limit the outgoing traffic to the configured limit
- while at the same time it does not need any rate limiting mechanism on
the outgoing side (it therefore avoids any double-door effects). It is
also reasonably simple and will thus (hopefully) not cause undesired
side effects.

It is still an additional closed control loop within the Tor router
(which will hopefully not cause stability problems in the future), but
in any case it appears much simpler than the current solution. It might
be worth to think about this for some more time, but so far Florian's
idea appears quite convincing to me.

&gt;&gt; We did some measurements on our onion router, and also many simulations.
&gt;&gt; 1/3 second still seems far too coarse. One would have to come
&gt;&gt; significantly below the RTT of the TCP links between onion routers. We
&gt;&gt; therefore tend more towards something in the order of 1/100 s. (We did
&gt;&gt; not notice any difference in CPU utilization when we made this change -
&gt;&gt; so this apparently isn't an issue.)
&gt; 
&gt; Exciting!  I'd be interested to see whether this also holds with the
&gt; Libevent 2 ratelimiting code as run on a live network, or if there is
&gt; some inefficiency there that we need to address.

What we (or rather: Florian) did during the past two weeks is to prepare
a more "complete" and "clean" patch for the libevent1 code, in
collaboration with Karsten Loesing and Sebastian Hahn (btw, thanks for
your efforts!). The patch removes the outgoing rate limitations; in the
light of the discussion above, this should be reconsidered, but should
IMHO be fine for testing purposes. The patch also allows for shorter
refill intervals. We would like to test this on two or three more
"real-world" relays, collecting statistics on the cell queueing time
with and without the patch. 

As of my understanding, Karsten and/or Florian will contact you soon
regarding this patch.


Best regards

Bjrn (and Florian) 



-- 
Florian Tschorsch
Mobile and Decentralized Networks
Heinrich-Heine-University
Universittsstr. 1, D-40225 Dsseldorf

Building 25.12, Room 02.43
Phone +49 211 81 11635
Fax +49 211 81 11638

tschorsch@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20110211064056</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-02-11 06:40:56-0400</timestampReceived><subject>Fwd: Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>



-------- Original Message --------
Subject: Re: xxx-draft-spec-for-TLS-normalization.txt
Date: Mon, 31 Jan 2011 23:33:25 +1300
From: Peter Gutmann &lt;pgut001@cs.auckland.ac.nz&gt;
To: jacob@appelbaum.net,, or-dev@seul.org

[Not sure if I can post into the list, but I'll give it a go...]

Jacob Appelbaum &lt;jacob@appelbaum.net&gt; writes:

&gt;This is a document that proposes improvements to problems with Tor's current
&gt;TLS (Transport Layer Security) certificates and handshake that will reduce the
&gt;distinguishability of Tor traffic from other encrypted traffic that uses TLS.
&gt;It also addresses some of the possible fingerprinting attacks possible against
&gt;the current Tor TLS protocol setup process.

In this case why not make the Tor certs as close as possible to generic
OpenSSL ones?  In other words do a scan of HOWTOs and whatnot and use
that as
a ruleset to create a cert, making them indistinguishable from a zillion
other
certs flying around that someone threw together on an as-needed basis.

&gt;We currently send a static Diffie??Hellman parameter, prime p (or ??prime p
&gt;outlaw??) as specified in RFC2409 as part of the TLS Server Hello response.

These are the universal-standard primes, I'd stick with these in order to
blend in with the crowd.

&gt;The second stage init_tls_dh_param() should randomly generate a new prime on
&gt;a regular basis; this is designed to make the prime difficult to outlaw or
&gt;filter.

Unless there's evidence of a large deployed base that does this, I'd
avoid it,
since the use of fresh primes rather than the Oakley ones will make you
stick
out.

As a general comment, if you're worried about filtering/fingerprinting I'd
make the traffic as close as possible to OpenSSL, since half the SSL apps on
the net end up using this and Tor would get lost in the noise.

(Note, having implemented both SSH and SSL and interop-tested it against God
knows what sort of implementations, you can pretty much always
fingerprint SSH
due to its incredible complexity and implementation bugs ("oh, it's
doing X in
packet Y, that's version 123 of XYZ") and probably fingerprint SSL in a
large
number of cases, so there's a limit to how far you can take this).

Peter.

</body></email><email><emailId>20110214192824</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-02-14 19:28:24-0400</timestampReceived><subject>Proposal 177: Abstaining from votes on individual flags</subject><body>

Filename: 177-flag-abstention.txt
Title: Abstaining from votes on individual flags
Author: Nick Mathewson
Created: 14 Feb 2011
Status: Draft

Overview:

   We should have a way for authorities to vote on flags in
   particular instances, without having to vote on that flag for all
   servers.

Motivation:

   Suppose that the status of some router becomes controversial, and
   an authority wants to vote for or against the BadExit status of
   that router.  Suppose also that the authority is not currently
   voting on the BadExit flag.  If the authority wants to say that
   the router is or is not "BadExit", it cannot currently do so
   without voting yea or nay on the BadExit status of all other
   routers.

   Suppose that an authority wants to vote "Valid" or "Invalid" on a
   large number of routers, but does not have an opinion on some of
   them.  Currently, it cannot do so: if it votes for the Valid flag
   anywhere, it votes for it everywhere.

Design:

   We add a new line "extra-flags" in directory votes, to appear
   after "known-flags".  It lists zero or more flags that an
   authority has occasional opinions on, but for which the authority
   will usually abstain.  No flag may appear in both extra-flags and
   known-flags.

   In the router-status section for each directory vote, we allow an
   optional "s2" line to appear after the "s" line.  It contains
   zero or more flag votes.  A flag vote is of the form of one of
   "+", "-", or "/" followed by the name of a flag.  "+" denotes a
   yea vote, and "-" denotes a nay vote, and "/" notes an
   abstention.  Authorities may omit most abstentions, except as
   noted below.  No flag may appear in an s2 line unless it appears
   in the known-flags or extra-flags line.We retain the rule that no
   flag may appear in an s line unless it appears in the known-flags
   line.

   When using an appropriate consensus method to vote, we use these
   new rules to determine flags:

   A flag is listed in the consensus if it is in the known-flags
   section of at least one voter, and in the known-flags or
   extra-flags section of at least three voters (or half the
   authorities, whichever set is smaller).

   A single authority's vote for a given flag on a given router is
   interpreted as follows:

      - If the authority votes +Flag or -Flag or /Flag in the s2 line for
        that router, the vote is "yea" or "nay" or "abstain" respectively.
      - Otherwise, if the flag is listed on the "s" line for the
        router, then the vote is "yea".
      - Otherwise, if the flag is listed in the known-flags line,
        then the vote is "nay".
      - Otherwise, the vote is "abstain".

   A router is assigned a flag in the consensus iff the total "yeas"
   outnumber the total "nays".

   As an exception, this proposal does not affect the behavior of
   the "Named" and "Unnamed" flags; these are still treated as
   before.  (An authority can already abstain from a single naming
   decision by not voting Named on any router with a given name.)

Examples:

   Suppose that it becomes important to know which Tor servers are
   operated by burrowing marsupials.  Some authority operators
   diligently research this question; others want to vote about
   individual routers on an ad hoc basis when they learn about a
   particular router's being e.g. located underground in New South
   Wales.

   If an authority usually has no opinions on the RunByWombats flag,
   it should list it in the "extra-flags" of its votes.  If it
   occasionally wants to vote that a router is (or is not) run by
   wombats, it should list "s2 +RunByWombats" or "s2 -RunByWombats"
   for the routers in question.  Otherwise it can omit the flag from
   its s and s2 lines entirely.

   If an authority usually has an opinion on the RunByWombats flag,
   but wants to abstain in some cases, it should list "RunByWombats"
   in the "known-flags" part of its votes, and include
   "RunByWombats" in the s line for every router that it believes is
   run by wombats. When it wants to vote that a router is not run
   by wombats, it should list the RunByWombats flag in neither the s
   nor the s2 line.  When it wants to abstain, it should list "s2
   /RunByWombats".

   In both cases, when the new consensus method is used, a router
   will get listed as "RunByWombats" if there are more authorities
   that say it is run by wombats than there are authorities saying
   it is not run by wombats.  (As now, "no" votes win ties.)
</body></email><email><emailId>20110220045427</emailId><senderName>Erik de Castro Lopo</senderName><senderEmail>mle+tools@mega-nerd.com</senderEmail><timestampReceived>2011-02-20 04:54:27-0400</timestampReceived><subject>Re: [tor-dev] or-dev mailing list migration February 19, 2011</subject><body>

Andrew Lewman wrote:

&gt; And this is complete.  Mail archive migration is coming soon.

Andrew,

The torprojects.org domain doesn't seem to have an SPF [0] record. It
would be really helpful if you added one.

CHeers,
Erik


[0] http://www.openspf.org/
-- 
----------------------------------------------------------------------
Erik de Castro Lopo
http://www.mega-nerd.com/
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110221023959</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-02-21 02:39:59-0400</timestampReceived><subject>Re: [tor-dev] Thoughts on</subject><body>

On Sun, Feb 20, 2011 at 06:29:55PM -0800, shamrock@cypherpunks.to wrote 3.6K bytes in 74 lines about:
: Either way, even more core to my advice than which particular OS
: versions to support (the one area where any dichotomy between open
: source and the commercial world may or may not come in) was my point
: that Tor needs a written and published OS support policy, agreed-upon by
: the Tor team. Whichever version support policy the Tor team may arrive
: at and for whatever reasons. And whether or not the Tor team takes my
: advice as to which particular versions to support.

We attempted to have a discussion about this over the past few days. I
think our best option, for now, is to simply state what we can build
ourselves, make these OSes our supported OSes, and encourage others to
make their own builds if their favorite OS is not officially supported.


-- 
Andrew
pgp key: 0x74ED336B
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110221032430</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-02-21 03:24:30-0400</timestampReceived><subject>[tor-dev] Fw: curvecpclient+curvecpserver alpha test</subject><body>

[Attachment #2 (multipart/signed)]


See below.


Robert Ransom



Begin forwarded message:

Date: 21 Feb 2011 02:51:21 -0000
From: "D. J. Bernstein" &lt;djb@cr.yp.to&gt;
To: curvecp@list.cr.yp.to
Subject: curvecpclient+curvecpserver alpha test


Hi everybody,

I've posted information about CurveCP at http://curvecp.org; and today's
release of NaCl includes command-line curvecpclient and curvecpserver
tools. There are many reasons that this curvecpclient+curvecpserver
software isn't ready for users yet---among other things,

   * the software hasn't gone through anywhere near my usual levels of
     testing and security review;
   * the software prioritizes simplicity over efficiency in several
     ways, missing some of the speed that CurveCP can provide; and
   * the software handles only CurveCP, without HTTPCurve, SMTPCurve,
     etc.

---but if you're a programmer interested in CurveCP then I think this
software is a reasonable starting point for experimentation and further
development.

---D. J. Bernstein
   Research Professor, Computer Science, University of Illinois at Chicago

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110221220847</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-02-21 22:08:47-0400</timestampReceived><subject>Re: [tor-dev] xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Feb 21, 2011, at 12:54 PM, Adam Langley wrote:

&gt; I agree that forcing collateral damage is the key here. The current
&gt; code generates `random' certificates, but it's pretty easy to pattern
&gt; match them and there's no collateral damage to doing so.

The thing that seems most correct to me, and most true, and is also likely to look \
like a lot of self-signed HTTPS hosts, is to just create a cert that looks like what \
a "good" self-signed cert would look like: a subject name that matches the host's \
internet-facing identity (IP and/or hostname), with reasonably common cryptographic \
parameters, and real-ish information in the fields like OU and so on (perhaps \
automatically culled from hostnames or Tor relay names or something).

As the Observatory shows, self-signed certificates outnumber CA-signed certificates. \
Fitting in with the self-signed world, of which those CPE things like printers and \
routers are just a subset, seems reasonable.

I don't know if it's possible to do better than to "just sort of look like a web \
server with a self-signed cert".


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110711101955</emailId><senderName></senderName><senderEmail>"re:[tor-dev]"@tail-f.com, improving@tail-f.com, private</senderEmail><timestampReceived>2011-07-11 10:19:55-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/signed)]


&gt; However, when performed by the exits, this linkability is a real
&gt; concern. Let's think about that. That sounds more like our
&gt; responsibility than the browser makers. Now I think I see what Georg
&gt; was getting at. We didn't mention this because the blog post was
&gt; directed towards the browser makers.

Well, my idea was not that sophisticated but yes, it belongs to the
passive attacks available to exit mixes I generally had in mind (and I
agree that the current domain-based proposal makes it way harder for an
active mix attacker). My example used just one session. And I still
would claim that even this gives an exit mix means to track users during
the 10 minutes (and later if the user happens to get the same exit mix
again within the same browsing session). If this is true do you mean
that it is just not worth the effort or is to difficult to explain to
the user (as it is highly probably that avoiding this kind of tracking
implies breaking some functionality in the web (a kind of tab separation
would be necessary but not sufficient))?

Georg




["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>201107111019550</emailId><senderName></senderName><senderEmail>"re:[tor-dev]"@tail-f.com, improving@tail-f.com, private</senderEmail><timestampReceived>2011-07-11 10:19:55-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/signed)]


&gt;&gt; Hmmm... If that is the answer to my questions then there is nothing like
&gt;&gt; avoiding getting tracked by exit mixes in the concept offered in the
&gt;&gt; blog post. Okay.
&gt; 
&gt; That is not entirely true. Because identifiers would be linked to
&gt; top-level urlbar domain, gone are the days where exits could insert an
&gt; iframe or web-bug into any arbitrary page and use that to track the
&gt; user for the duration of the session, regardless of page view.
&gt; 
&gt; Instead, they would be pushed back to doing some sort of top-level
&gt; redirect (which we hope would be way more visible), or maybe not even
&gt; that, depending on how we define redirects with respect to
&gt; "top-level".
&gt; 
&gt; So no, we are not completely abandoning exits as an adversary with
&gt; this threat model. If I'm wrong about something, or you think there
&gt; are still attacks exits can perform that we should address somehow,
&gt; let me know.

See my last mail.

&gt;&gt; Another question came to my mind: You seem to be at pains not to break
&gt;&gt; parts of the web even in the anon mode even if that boils down to not
&gt;&gt; implement features that would better fit the needs for people looking
&gt;&gt; for unlinkability (one thing that comes to my mind here would be having
&gt;&gt; a context being tab dependent additionally). Why? Why not saying: "This
&gt;&gt; is Tor's anon mode. It is meant for people that strive for unlinkability
&gt;&gt; and might break some functionality. You may still use Tor in normal or
&gt;&gt; private browsing mode though (providing no or less unlinkability on the
&gt;&gt; browser level)." Do you think that's not worth the effort as Tor's IP
&gt;&gt; unlinkability is enough here (especially combined with the things you
&gt;&gt; suggested in the blog post)? I do not know Tor's user base very well but
&gt;&gt; could imagine that it contains a lot of users that would like to have
&gt;&gt; more unlinkability than the "we do not want to break any (or almost any)
&gt;&gt; part of the web for a better anonymity" fraction.
&gt; 
&gt; I wish I had better science to give you here on the trade-off we're
&gt; going for, but the reality is that we're best-guessing over a very
&gt; complex cost/benefit landscape.

That's true.

&gt; We do know for a fact that the easier Tor is to use (which includes
&gt; installation, configuration, overall intuitiveness/"familiarity",
&gt; compatibility, and performance), the more people will use it
&gt; regularly.

That seems to hold for every piece of software, I guess.

&gt; We also know for a fact that the more people use Tor, the better the
&gt; baseline privacy, anonymity, and censorship resistance properties all
&gt; become.

Agreed.

&gt; Hence, I tend to make decisions in favor of the usability direction
&gt; over minor details, especially ones that don't really prevent bad
&gt; actors/adversaries from accomplishing their goals.

That is definitely a good approach. But maybe there is research to be
done here as well. Just a rough (and in part research) idea that I had
in mind while asking you the question above: What about if we first
started looking at different services offered in the web whether they
can be deployed anonymously *at all* (or maybe more precisely (but not
much): that can be deployed in a way that there is either no linkability
at all or the linkability is not strong enough to endanger the user)
(that would be worth some research, I guess)? We would probably find
some services where we had to say: "Well, there is no way to get them
used anonymously due to their nature and the power of the companies
and/or owners behind them." (Facebook comes here to my mind as a
candidate and the Google universe as well due to the power Google has).
Should we say we make the Tor anon mode compatible with these services
nevertheless (due to usability issues) and abandon stronger anonymity
measures? I would say no. Not at all. Rather we should be honest and
say: "Dear User, surfing anonymously AND using Facebook does not work.
You may use the Tor anon mode for that purpose though but there is a
high probability that it breaks functionality." The idea of getting more
users due to being not too strict here might be appealing but is not the
right decision in the end. I think one has to realize that there are
services in the web that are *designed* in a way that one EITHER may use
them OR use anonymity services. Sure, the devil is in the details (e.g.
there are probably a lot of services that may be usable anonymously but
then are accompanied with a certain lack of usability. What about them?
Should we decide against usability again or should we loosen our means
to provide unlinkability here?) but that does not mean there is no way
to find a good solution though. In short (and still roughly): I would
like to start thinking from having all means available to surf the web
anonymously and then downgrade them piece-by-piece to reach a trade-off
between anonymity and usability. Services that may not be used
anonymously at all would not trigger such a painful downgrade ("painful"
as one usually tries first to hack around existing problems encountering
unbelievable design issues and bugs and has to concede finally that it
is in the user's interest to exclude that feature (again)).

&gt; The need for science especially comes in on the fingerprinting arena.
&gt; Some fingerprinting opportunities may not actually be appealing to
&gt; adversaries. Some may even appear appealing in theory, but in practice
&gt; would be noticeable to the user, too noisy, and/or too error-prone.
&gt; Hence I called for more panopticlick-style studies, especially of
&gt; Javascript features, in the blog post.

Yes, that is definitely a good idea though I tend to avoid them all even
if currently no adversary is using them (especially if no usability
issue is at stake). First: no one knows whether one did not miss an
attacker using this kind of attack vector and second: Getting rid of
attack vectors is a good thing per se.

Georg


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110711102149</emailId><senderName></senderName><senderEmail>"re:[tor-dev]"@tail-f.com, improving@tail-f.com, private</senderEmail><timestampReceived>2011-07-11 10:21:49-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/signed)]


&gt; However, when performed by the exits, this linkability is a real
&gt; concern. Let's think about that. That sounds more like our
&gt; responsibility than the browser makers. Now I think I see what Georg
&gt; was getting at. We didn't mention this because the blog post was
&gt; directed towards the browser makers.

Well, my idea was not that sophisticated but yes, it belongs to the
passive attacks available to exit mixes I generally had in mind (and I
agree that the current domain-based proposal makes it way harder for an
active mix attacker). My example used just one session. And I still
would claim that even this gives an exit mix means to track users during
the 10 minutes (and later if the user happens to get the same exit mix
again within the same browsing session). If this is true do you mean
that it is just not worth the effort or is to difficult to explain to
the user (as it is highly probably that avoiding this kind of tracking
implies breaking some functionality in the web (a kind of tab separation
would be necessary but not sufficient))?

Georg




["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110222220314</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-22 22:03:14-0400</timestampReceived><subject>Re: [tor-dev] Proposal idea: Require majority of authorities to</subject><body>

On Tue, Feb 22, 2011 at 1:34 AM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt; Filename: xxx-param-voting.txt
&gt; Title: Require majority of authorities to vote for consensus parameters
&gt; Author: Sebastian Hahn
&gt; Created: 16-Feb-2011
&gt; Status: Draft

Added as proposal 178.

(As a sidenote, the specifications and proposals are  no longer part
of the tor source repository; they've got their own repository now.
You can browse them at
   https://gitweb.torproject.org/torspec.git/tree

To check out the specification repository, run
    git clone git://git.torproject.org/torspec.git

For other information on the repository, see
    https://gitweb.torproject.org/torspec.git  )

This is probably a bit bikeshed, but the ability to add new parameters
in a hurry has been pretty useful in the past.  Instead of requiring a
majority of authorities, I'd suggest that we require 3, or a majority,
whichever is smaller.  (I suggest "3" because it's the smallest number
of voters on a parameter for which the median is not unilaterally
determined by a single authority.)

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110225134828</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-02-25 13:48:28-0400</timestampReceived><subject>Re: [tor-dev] Publishing sanitized bridge pool assignments</subject><body>

On Thu, Feb 10, 2011 at 12:00:40PM +0100, Karsten Loesing wrote:
&gt; So, I implemented the new sanitizing algorithm that replaces bridge IPs
&gt; with 10.x.x.x addresses derived from the original bridge IPs.  I also
&gt; sanitized the descriptors from November 2008 and performed an early
&gt; analysis on the results.
&gt; 
&gt; The last remaining step is to sanitize our archives of bridge descriptors
&gt; once again and make the sanitized data available.  I don't expect to have
&gt; new tarballs before next Tuesday.

The new tarballs are available here:

  https://metrics.torproject.org/data.html#bridgedesc

&gt; Before publishing the new tarballs, I'd like to invite people to review
&gt; the new sanitizing process:
&gt; 
&gt;  - A specification-like description of the sanitizing process is in
&gt;    Section 3 of https://metrics.torproject.org/papers/data-2011-02-10.pdf
&gt; 
&gt;  - The early analysis results of bridges changing their IP addresses are
&gt;    here: https://trac.torproject.org/projects/tor/ticket/2435#comment:3
&gt; 
&gt;  - The tarball with sanitized bridge descriptors from November 2008 is
&gt;    here (6.2M):
&gt;    http://freehaven.net/~karsten/volatile/bridge-descriptors-hashed-ips-2008-11.tar.bz2
&gt; 
&gt; Any questions, comments, and concerns are highly appreciated!

Feedback still much appreciated!

Best,
Karsten

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110225203325</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-02-25 20:33:25-0400</timestampReceived><subject>Re: [tor-dev] SSL Observatory Observations</subject><body>

Hi Tim,

This is cool! Thanks for reporting what you found.

Is there any chance you could show us the code you used to noodle through the CSV \
data? I created it on the off chance that someone would find it more appropriate for \
their needs than the MySQL DB, but we have no code for coping with it. All our \
examples use the MySQL database, since that's what Peter and Jesse originally \
intended.


On Feb 21, 2011, at 6:21 AM, Tim Wilde wrote:

&gt; Last weekend's hackfest inspired me to attempt to run some numbers on
&gt; the EFF SSL Observatory data[1], in particular looking at two things:


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110226023442</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-02-26 02:34:42-0400</timestampReceived><subject>Re: [tor-dev] xxx-triangleboy-transport.txt (+comments on</subject><body>

[Attachment #2 (multipart/signed)]


Thus spake Nick Mathewson (nickm@freehaven.net):

&gt; On Tue, Feb 1, 2011 at 12:08 AM, Mike Perry &lt;mikeperry@fscked.org&gt; wrote:
&gt;  [...]
&gt; &gt;
&gt; &gt; Appendix: List of key xxx-pluggable-transport.txt shortcomings
&gt; &gt;
&gt; &gt; 1. This pluggable transport does not need any intelligence or process
&gt; &gt; launching on the Client side, aside from a way to tell Tor not to be
&gt; &gt; so pedantic about ensuring identity key and IP address consistency.
&gt; 
&gt; What pedanticism exactly do you mean?  Matching the IP addr in the
&gt; netinfo cell, or something else?

I actually don't know the full list there. I think the last time we
tried to enumerate this, we decided that "try it and see what actually
breaks" was a more efficient approach.

&gt; &gt; 2. The relay side needs to be able to detect if it has both the
&gt; &gt; permissions and the network ability to send spoofed packets. It needs
&gt; &gt; to communicate this fact with the Relay Plugin by responding with the
&gt; &gt; appropriate extrainfo lines, or with "METHODS: NONE" to indicate
&gt; &gt; error. This relay-side handshake should be specified in the
&gt; &gt; pluggable-transport spec.
&gt; 
&gt; To be clear, you mean that the plugin checks whether it can spoof (and
&gt; tell Tor "I do nothing!" if it can't), or that Tor needs to find out
&gt; whether it can spoof and tell the plugin that whether it can spoof or
&gt; not.  The first sounds reasonable.  The second doesn't so much: most
&gt; Tors won't want to try to spoof, so building the checks into Tor
&gt; wouldn't make sense to me, unless I'm missing something.

Yes, the first is what we want here.

&gt; &gt; 3. The relay plugin side needs some way to communicate EXTRAINFO lines
&gt; &gt; to be added to its extrainfo descriptor. In this proposal, we use the
&gt; &gt; SMETHOD reply to do this.
&gt; 
&gt; Needs spec, not just an example.

Ok. Well, does the example I gave look like an instance of what we
want to specify as the behavior?
 
&gt; &gt; 4. Is extrainfo really the best place to keep this information?
&gt; &gt; Shouldn't it just be in the relay/bridge descriptor? Putting it in
&gt; &gt; extrainfo requires our TransportBridges to enable the wasteful
&gt; &gt; DownloadExtraInfo=1 torrc setting, which will consume more scarce
&gt; &gt; resources and RAM on what will probably be cheap routers with 32-64M
&gt; &gt; of RAM.
&gt; 
&gt; Hm.  Relay/bridge descriptor should be okay, I guess.  I'm not sure
&gt; why the TransportBridges are getting those anyway, though:  I see why
&gt; the client needs it, but not what the transportbridge needs it.

The transport bridge should avoid being an open proxy. I suppose it
can only properly carry full TCP streams to an endpoint, but without
restricting who those endpoints are, it becomes a reflector open to
abuse such as portscans.

&gt; Also, why are transportbridges even running tor?  They don't seem to
&gt; be doing anything particularly tor-like.

Mostly for the consensus, for reasons above. Not strictly required, if
we don't mind being an arbitrary SYN proxy.
 
&gt; &gt; 5. How would we go about chaining an actual obfuscation mechanism with
&gt; &gt; this transport? Would we just create new and separate transport called
&gt; &gt; TriangleBoyOverHTTP, for example, or is there a better way to chain
&gt; &gt; different mechanisms?
&gt; 
&gt; On the client side, socks-over-socks-over-socks is not actually a
&gt; terrible way of doing things there.  We'll need to distinguish between
&gt; which transports are chainable and which aren't, though[*], and maybe
&gt; revise the design to make sure there's a way to tell to tell tor to do
&gt; said chaining.
&gt; 
&gt; On the server side, you need some way to distinguish which processing
&gt; method to do for incoming data. Separate ports seems ok there.  We
&gt; still need to figure out the server side.
&gt; 
&gt; [*] generally, obfuscation is chainable but transport isn't.

This is not a bad generalization. Do we want to make this distinction
(between obfuscation vs transport) elsewhere in the spec, I wonder?

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #5 (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20110101035635</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-01-01 03:56:35-0400</timestampReceived><subject>Re: Some draft notes on migrating Tor's ciphersuites</subject><body>


On Fri, 31 Dec 2010 22:28:41 -0500
Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:

&gt; On Fri, Dec 31, 2010 at 4:17 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; &gt; On Sun, 19 Dec 2010 08:46:13 -0500
&gt; &gt; Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt;&gt; On Sat, Dec 18, 2010 at 10:34 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; &gt;
&gt; &gt;&gt; &gt; You're right that it's important to limit partitioning opportunities
&gt; &gt;&gt; &gt; in any protocol revision; I tried to go over that in section 2, but we
&gt; &gt;&gt; &gt; shouldn't assume that I've said the last word on this.   We should
&gt; &gt;&gt; &gt; continue to look for ways to revise and improve whatever we come up
&gt; &gt;&gt; &gt; with to get the partitioning and other undesirable things down to a
&gt; &gt;&gt; &gt; minimum.
&gt; &gt;
&gt; &gt; My current plan to minimize partitioning of the client anonymity set is:
&gt; &gt;
&gt; &gt; * The directory authorities should specify lists of cryptographic
&gt; &gt;   primitives (identity key signature systems, circuit-extension
&gt; &gt;   handshakes, circuit ciphersuites, etc.) that relays are permitted to
&gt; &gt;   support in the consensus.
&gt; 
&gt; This should probably incorporate allowable key sizes.  We don't want
&gt; some twit generating 16384-bit identity keys just to slow down all the
&gt; clients, but we also don't want somebody using 512-bit RSA keys.

Yes.


&gt; &gt; * The directory authorities should specify lists of cryptographic
&gt; &gt;   primitives that clients should consider using in the consensus.
&gt; &gt;
&gt; &gt; * Each relay should specify lists of cryptographic primitives that it
&gt; &gt;   is willing to use in its descriptor, ordered by the relay's
&gt; &gt;   preference (e.g. the relay puts its favorite primitive in a list
&gt; &gt;   first).
&gt; 
&gt; Hm.  If this involves multiple onion keys, this can potentially bloat
&gt; server descriptor sizes; we should consider carefully how we can avoid
&gt; that.  Perhaps there should be an upper bound on how many onion keys
&gt; you can advertise.

That may be a good idea, but I expect to allow only one or two types of
handshake-authentication key (my term for the onion key).


&gt; &gt; * A client should select the first cryptographic primitive in a relay's
&gt; &gt;   list that (a) the consensus recommends that clients use, and (b) the
&gt; &gt;   client supports.
&gt; 
&gt; Hm. This puts the onus on relay operators of picking the best
&gt; primitives.  I'm not sure that's such a great idea.  Perhaps the
&gt; client should pick whichever method supported by both the client and
&gt; the relay that the *consensus* recommends first.

No -- this puts the burden on the directory authority operators to
forbid all 'bad' primitives, and puts the burden on Tor to measure the
performance of each primitive on a relay and list the *fastest*
primitive on that relay first in its preference list.

I expect that all relays will choose the same circuit-handshake
protocol and primitives, and we can turn off the rest.  However, I want
to make sure that relays running on processors with hardware AES
support can continue to use AES, while allowing other relays to choose
Salsa20.  (I am assuming that we will have a portable AES
implementation immune to side-channel attacks included in Tor.)


&gt; &gt; * The Tor developers should not introduce new cryptographic primitives
&gt; &gt;   between two stable releases in the same branch.
&gt; &gt;
&gt; &gt; The Tor client will need to support torrc options that override the
&gt; &gt; lists of recommended cryptographic primitives in the consensus in order
&gt; &gt; to allow testing of not-yet-recommended primitives on the public Tor
&gt; &gt; network, but the manual page will need to warn explicitly that setting
&gt; &gt; those options will harm a Tor user's anonymity.
&gt; 
&gt; One thing we will need to think about here is the risk of having
&gt; seldom-used code.  Remember the time that GPG had broken ElGamal keys
&gt; for ages, and it went unnoticed since almost nobody used ElGamal keys?
&gt; (CVE-2003-0971)  More code does come with more risk.

We clearly will need to test the cryptographic code heavily, both as
part of Tor and separately.


&gt; &gt; This plan relies on the directory authorities not recommending a new
&gt; &gt; cryptographic primitive until a large fraction of Tor clients support
&gt; &gt; it.
&gt; &gt;
&gt; &gt;
&gt; &gt;&gt; One way is to be very conservative in suite choices so we don't have
&gt; &gt;&gt; to change them that often. I'm going to also go out on a limb and say
&gt; &gt;&gt; that we also want a crypto API like NaCL that lets us just say
&gt; &gt;&gt; enciphered=encrypt(key, unenciphered) and doesn't force us to worry
&gt; &gt;&gt; about padding or modes because this is a much simpler abstraction
&gt; &gt;&gt; layer and so offers less opportunity for mistakes that could threaten
&gt; &gt;&gt; security.
&gt; &gt;
&gt; &gt; I think that if we follow the plan above, we don't need to limit the
&gt; &gt; number of cryptographic primitives of each type in order to preserve
&gt; &gt; the client anonymity set.   It's more important to have at least two
&gt; &gt; cryptographic primitives of each type implemented, even if we expect
&gt; &gt; that few relays will prefer one of them, in order to ensure that we get
&gt; &gt; the APIs for each primitive right.
&gt; 
&gt; I am a little skeptical that it will turn out to be quite this simple
&gt; once we design it, but at this point I think the easiest way to see
&gt; whether we can get away with a good design with all the properties we
&gt; want is to just try to make one, and see how it works out.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110102142807</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-01-02 14:28:07-0400</timestampReceived><subject>Re: [guardian-dev] Flaws in Tor anonymity network spotlighted</subject><body>

On Sun, Jan 02, 2011 at 09:16:36AM -0500, Nathan Freitas wrote:
&gt; On 01/01/2011 06:33 PM, Hans-Christoph Steiner wrote:
&gt; &gt; At CCC, some people presented some possible ways of defeating the Tor
&gt; &gt; anonymity.  Its hard to do, so it's not like Tor is useless in the face
&gt; &gt; of this, but it seems like something to be aware of:
&gt; 
&gt; I am curious to hear a more formal or public response on this, but I do
&gt; believe there are ways this flaw is addressed, and as you said, this
&gt; attack lives with the realm of possible, but not probable.

See
http://archives.seul.org/or/talk/Dec-2010/threads.html#00253
ending with Lexi's post.

--Roger

</body></email><email><emailId>20110106125804</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2011-01-06 12:58:04-0400</timestampReceived><subject>Re: Pre-Boston dev party Sunday, Jan 9 at 3pm EST (20:00 UTC)</subject><body>

On Thu, Jan 06, 2011 at 12:05:26AM -0800, mikeperry@fscked.org wrote 2.3K bytes in 62 lines about:
: We're going to have another IRC dev party this Sunday in preparation
: for our dev meeting in Boston:

If I need to be there, I can't do Sunday.

: The plan is to discuss preliminary details, agenda, and ideas for the
: Boston dev meeting, and to generally include the larger community who

The agenda for the meeting is already organized and set.  It's designed to
force us to work through what we're doing in the next year without
relentless pontification and navel gazing.  Everyone attending it should
read through the two mentioned Sponsors and think about what they're
going to present in their 300 seconds.  

Having a dev meeting about known Dec and Mar deliverable progress and
whatever else occurs in a normal irc dev meeting sounds like a fine
plan.

-- 
Andrew
pgp key: 0x74ED336B
</body></email><email><emailId>20110102141636</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-01-02 14:16:36-0400</timestampReceived><subject>Re: [guardian-dev] Flaws in Tor anonymity network spotlighted</subject><body>


On 01/01/2011 06:33 PM, Hans-Christoph Steiner wrote:
&gt; 
&gt; At CCC, some people presented some possible ways of defeating the Tor
&gt; anonymity.  Its hard to do, so it's not like Tor is useless in the face
&gt; of this, but it seems like something to be aware of:


I am curious to hear a more formal or public response on this, but I do
believe there are ways this flaw is addressed, and as you said, this
attack lives with the realm of possible, but not probable.

However, in relation to mobile, which is more app-centric than
browser-centric, I do believe one of the main vectors for this attack
was being able to start with "what are the most popular 100 websites",
and using the page/fetch size of accessing those sites as a starting
point for analysing traffic.

I am curious that with the more API-centric approach of a mobile app,
would the potential of this attack be lessened? I suppose you could
create a similar fingerprint based on JSON or XML data access patterns,
but I also feel that the relative difference in request/response size of
an API call would be harder to differentiate between sites and services.

Unfortunately, mobile apps introduce a new significant risk to user
privacy, in terms of this attack, I feel they offer a potential advantage.

+nathan



</body></email><email><emailId>20110106080526</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2011-01-06 08:05:26-0400</timestampReceived><subject>Pre-Boston dev party Sunday, Jan 9 at 3pm EST (20:00 UTC)</subject><body>


We're going to have another IRC dev party this Sunday in preparation
for our dev meeting in Boston:

https://trac.torproject.org/projects/tor/wiki/2011MiniDevMeeting
https://blog.torproject.org/blog/boston-tor-hackers-join-us-saturday-january-15th

The plan is to discuss preliminary details, agenda, and ideas for the
Boston dev meeting, and to generally include the larger community who
may or may not be able to join us in person in Boston on the 15th.
Most of the discussion will likely be around figuring out what Tor
will be doing for the next few years, but we can also discuss specific
development issues as well.


Standard party notes (stolen from Nick):

* This is called a "party" because calling our IRC meetings "parties"
has produced better outcomes in the past than calling them "meetings".
* If you're not free to make it, or if you're not free to make it for
the whole time, don't worry.  There will be more of these at other
times ranging from "too late in Europe" to "too early in California".
* If you're not an actual developer on Tor, you're welcome to come and
hang out, but this is mainly a time for developers to chat and plot
and generally confab.
* We're probably not going to be "partying" for every minute of all 2
hours; think of this as a salon where people wander in and out and
take breaks to go into a corner and eat cheese or debug trac or
whatever.
* The format will probably change in the future as we get some
experience with it and learn more about what does (and doesn't) work
for us.  If having 2 open hours is too much, let's do less.
* I'm going to try to "host" this developer party.  Since you can't
serve food over IRC, and there's no need to vacuum the floor before
the party starts, I'm not quite sure what my responsibility will be
other than being around the whole time and trying to make sure the
conversation stays interesting.  I'll play it by ear.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20110102061440</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-02 06:14:40-0400</timestampReceived><subject>Re: RFC/proposal for Thandy changes</subject><body>

On Sun, Oct 17, 2010 at 10:46 PM, Justin Samuel &lt;js@justinsamuel.com&gt; wrote:
&gt; Hi all,

Hi, and sorry about the delay!  I think I like most of it, dislike a
couple of details, and have some points where I don't get it.  More
detail follows.

[ lines re-wrapped]
&gt;
&gt; 0. Proposed Thandy Changes
&gt; ==========================
&gt;
&gt; This is a set of proposals that includes a section of simple changes
&gt; that can be considered on their own (Section 1) as well as a more
&gt; fundamental Thandy restructuring proposal (Section 2).
&gt;
&gt; This isn't meant to be at the level of detail needed for a spec and
&gt; subsequent implementation. This is to get feedback and promote
&gt; discussion. It's not an official proposal at this point but more of a
&gt; request for comment.

Okay.  I'm going to omit all comments of the form "Could be okay, but
needs more detail", then. :)

&gt; A few relevant documents for reference:
&gt;
&gt;  * Thandy spec:
&gt;    https://gitweb.torproject.org/thandy.git/blob_plain/HEAD:/specs/thandy-spec.txt
&gt;  * TUF spec: https://www.updateframework.com/browser/specs/tuf-spec.txt
&gt;  * High-level differences between Thandy and TUF:
&gt;    https://www.updateframework.com/wiki/ThandyDifferences
&gt;  * Paper on TUF: http://www.freehaven.net/~arma/tuf-ccs2010.pdf
&gt;
&gt; 1. Individual Thandy Changes
&gt; ============================
&gt;
&gt; These are changes that could be made to Thandy without major overhaul
&gt; and can be considered separately of the restructuring proposal (Section
&gt; 2).
&gt;
&gt; 1.1. Multiple File Hashes
&gt; -------------------------
&gt;
&gt; Make all file hashes be a set of (algorithm, digest) pairs rather than a
&gt; single digest of a predefined algorithm. Thus, instead of describing a
&gt; file's hash in metadata with:
&gt;
&gt;   "hash" : 349dceb3de2db82e363c3d73063f031c56c5aac5
&gt;
&gt; It would be described as:
&gt;
&gt;   "hash" : ["sha1" : 349dceb3de2db82e363c3d73063f031c56c5aac5,
&gt;             "sha256" : 95eaa1682a99fba24b26c94499b545...747d7759ba845c8b5c]

(To be pedantic, what you describe is NOT well-formed.  You'd need to
 say
    "hash" : [ ("sha1", "349dceb3db...") ,
               ("sha256", "95eaa...") ]
 if you mean a list of algorithm digest pairs, but
    "hash" : { "sha1" : "349dceb3db...",
               "sha256: "95eaa..." }
 if you mean a map from algorithm names to digest values.)

&gt; Note that it could still be allowed to list only one digest. This just
&gt; allows the ability to use multiple hashes. It's up to the client
&gt; implementation to determine which are checked.

I like this approach adding support for more hash algorithm.  We'd need
to say more about interoperability, however, since unless the party
verifying the hash and the party generating it have at least one hash
algorithm in common, the hash can't get verified.

Also, if we've got multiple hashes that not everybody can verify, we
create the possibility of making documents that some people will accept
but others will not.  For example, suppose that when the digests D1 and
D2 are both included, client C1 only checks D1, but client C2 only
checks D2.  A corrupt signer can then make an update that C1 will reject
but C2 will accept.  Worse, if the C1 implementation is relatively
unpopular among developers and code signers, then the bad digest might
not get noticed until the update was widely distributed

To solve the first problem (compatibility), let's define at least one
reasonably good hash algorithm that all verifiers must recognize, and
that all formats must include.  I suggest SHA256 for now, plus SHA3
when it is finalized.

Solving the second problem (not everybody verifying the same digests or
accepting the same updates) is harder.  It's not possible in general to
avoid it, so long as there is ever a digest algorithm that some client
knows about and others don't.  We can, however, avoid the worst attacks
here if we stipulate:

   - When verifying hashes on relatively small inputs, all parties
     should check that they match ALL of the provided hashes that they
     recognize.  In other words, if you're checking hashes on anything
     smaller than a raw binary file, and more than one hash is given
     that you know how to calculate, you should calculate and check them
     all.

   - Code that builds bundles, releases, or whatever, should check all
     possible hashes.

   - Implementors SHOULD NOT add client support for any digest algorithm
     to a client without also getting it widely deployed among parties
     that generate it.

The issue as a whole isn't so bad, since any party that could


&gt; 1.2. Refer to Keys by Their ID when Delegating
&gt; ----------------------------------------------
&gt;
&gt; In the Thandy key list file (the "root metadata"), the full keys are
&gt; listed each time they are referenced. This may decrease the human
&gt; readability of the key list.
&gt;
&gt; An alternative approach is to use a separate section in the file that
&gt; defines the keys that will be used in the rest of this metadata file,
&gt; list them with their ID (a hash of the canonical format of the key), and
&gt; then refer to them later by this ID. This is similar to how signatures
&gt; are already done in Thandy: the ID of the key is listed along with the
&gt; signature.
&gt;
&gt; An implementation of this needs to check for ID collisions when reading
&gt; keys from metadata. It's fine to see the same key specified with the
&gt; same ID, but a different key with the same ID as one that has been seen
&gt; indicates something wrong. (Note that the implementation would always
&gt; check that the specified IDs are correct for the corresponding key, even
&gt; without collisions.)

Sounds fine to me.

But I wasn't originally envisioning the same key ever being used for
multiple roles, but there's no reason why it can't be.  The spec says,
"Separate keys should be used for different people and different
roles.")  But there's no inherent reason that one person couldn't use
one key to sign everything they do: if two private keys would have been
stored in the same user's keystore, any compromise on one would probably
compromise the other.

We _should_ probably require that the same key never be used for two
different types of role.  For instance, a root key should never sign
packages, a timestamp key should never sign anything but the timestamp,
and so on on.

&gt; 1.3. Indicate Signature Thresholds
&gt; ----------------------------------
&gt;
&gt; The current Thandy spec isn't clear about how multiple keys are
&gt; specified for a role. There also doesn't appear to be a way to specify a
&gt; threshold that is less than the total number of keys. The method of
&gt; specifying multiple keys should be made clear and the ability to
&gt; indicate the number of signatures of those keys that are required should
&gt; be added. (There's an example of how this can be specified in metadata
&gt; in Section 2.2.)

Sounds fine.

&gt; 1.4. Add a 'Release' Role
&gt; -------------------------
&gt;
&gt; Thandy currently lists the hashes of all other metadata in the timestamp
&gt; file.  There are certain attacks that could be mitigated if the
&gt; Timestamp role signed a separate Release role's metadata that listed the
&gt; hashes of all other metadata files. The idea here is that an attacker
&gt; who compromises only the Timestamp role cannot present clients with a
&gt; mix-and-match of signed metadata files that were available from the
&gt; repository at different times. The separation helps because the
&gt; Timestamp role has a higher likelihood of key compromise because the
&gt; keys are used in an automated fashion, whereas the Release role would
&gt; not be used in an automated fashion.
&gt;
&gt; Though the idea of a metadata mix-and-match attack is in general
&gt; something worth keeping in mind, it may be the case that Thandy isn't at
&gt; much risk because bundles serve a similar role of grouping together
&gt; package versions in a way that attackers can't cause the clients to use
&gt; an unintended combination of package versions. The risk to Thandy
&gt; depends on whether packagers ever replace a package version rather than
&gt; increment it (they aren't supposed to ever replace a version) and
&gt; whether Thandy bundles always specify exact package versions rather than
&gt; minimum/maximum package versions or package version ranges.

Sounds okay to me.

&gt; 2. Thandy Restructuring Proposal
&gt; ================================
&gt;
&gt; Primary goal: Keep Thandy's concepts of bundles and packages but overlay
&gt; them on top of the generic 'targets' approach of TUF.

I don't get this as a goal.  Obviously, you're not advocating that we
should use TUF's 'targets' approach for it's own sake: you're advocating
that we use it in order to get some concrete benefit that it provides.
_That benefit_ is the real goal, not mere use of TUF's approach for its
own sake.  (I know this sounds like nitpicking, but unless we're clear
about what actual benefits a change is meant to provide, it's harder to
evaluate it.)

If I had to guess, I would say that the real goal is probably something
like, "separate Thandy's notion of packages and bundles from Thandy's
notion of authenticated downloads."

&gt; Note: This proposal is not advocating using/maintaining/relying on TUF
&gt; as a separate project. That depends on factors such as the future of TUF
&gt; according to the current TUF maintainers, whether Python is an
&gt; appropriate choice for Windows clients, etc.
&gt;
&gt; 2.1 Approach
&gt; ------------
&gt;
&gt; Two separate layers:
&gt;
&gt;   1. An authentication layer that downloads and authenticates opaque
&gt;      'target' files according to metadata it understands that lists
&gt;      hashes and sizes of the target files. This layer doesn't understand
&gt;      what bundles and packages are.
&gt;
&gt;   2. A decision/installation layer that uses the authentication layer to
&gt;      download bundle/package info and associated files. This layer
&gt;      doesn't know the details of the authentication mechanisms or roles;
&gt;      it gets files from the authentication layer that the authentication
&gt;      layer has already authenticated.
&gt;
&gt;      * Note that the update decision and installation code are probably
&gt;        separate, but for the sake of this proposal all that matters is
&gt;        that the Thandy authentication layer is logically separate from
&gt;        the rest of Thandy.

Hm.  It would help to know what exactly the interface to layer 1 should
be.  I'm guessing it's something like, "Update the metadata", "Tell me
what files are available", "Download the following files".

&gt; For the authentication layer, we start with the following roles (the
&gt; same as TUF uses):
&gt;
&gt;   * Root
&gt;     o Root of trust for the entire PKI. Indicates through signed
&gt;       metadata which keys are trusted for the Release, Targets,
&gt;       Timestamp, and Mirror roles.
&gt;
&gt;   * Timestamp
&gt;     o Signs a frequently regenerated timestamp file with a short
&gt;       expiration indicating the most recent release metadata.
&gt;
&gt;   * Release
&gt;     o Signs the release metadata which lists the hashes and sizes of all
&gt;       other metadata files (other than the timestamp file). Note that
&gt;       bundleinfo and pkginfo are not considered metadata at the
&gt;       authentication layer.
&gt;
&gt;   * Targets
&gt;     o Signs a metadata file that lists the hashes and sizes of target
&gt;       files: the files that the decision layer ultimately wants to
&gt;       obtain.
&gt;
&gt;     o Can delegate to sub-roles the responsibility for providing target
&gt;       files from specific paths on the repository (e.g. Role A is
&gt;       trusted to provide files from the /targets/role_a/ directory).

It sounds like you're combining the roles of signing code (which the
targets key can do, and delegates) with the role of deciding who can
sign code.  Is that wise?  Nowhere else in the Thandy design is this
done.

In practice, I'd assume that the Targets role should be pretty much
*only* used for delegation.  But in that case, what's the benefit of
separating this from the root role?

&gt;   * Mirror
&gt;     o Signs a metadata file that lists the locations and details of
&gt;       repository mirrors.
&gt;
&gt; From here we use delegation by the Targets role to create the roles for
&gt; bundlers and packagers. The top-level Targets role delegates a separate
&gt; role for each bundle and each package.
&gt;
&gt; The targets role hierarchy looks like this (with many more bundle and
&gt; package roles):
&gt;
&gt; Root
&gt; `-- Targets
&gt;     |-- bundles/tor-browser-stable
&gt;     |-- bundles/tor-browser-beta
&gt;     `-- pkgs/openssl
&gt;
&gt; Each bundle version and package version that bundlers and packagers
&gt; released has a separate bundleinfo and pkginfo file, respectively. These
&gt; bundleinfo and pkginfo files are opaque to the authentication layer: it
&gt; considers them target files like any other. However, the decision layer
&gt; understands the contents of these files and uses them to make subsequent
&gt; download and installation decisions (with the downloads always being
&gt; done through the authentication layer).
&gt;
&gt; 2.2. Repository Structure
&gt; -------------------------
&gt;
&gt; Top-level metadata files are:
&gt;
&gt; /meta/root.txt
&gt; /meta/release.txt
&gt; /meta/timestamp.txt
&gt; /meta/targets.txt
&gt; /meta/mirrors.txt
&gt;
&gt; The /meta/targets.txt file would include a delegations section such as:
&gt;
&gt; delegations : {
&gt;     keys : {
&gt;         'ABC...' : { details },
&gt;         '123...' : { details },
&gt;         ...
&gt;       },
&gt;     roles : {
&gt;         'bundles/tor-browser-stable' : {
&gt;             keys : ['ABC...', '123...'],
&gt;             threshold : 2,
&gt;             paths : ['bundles/tor-browser-stable/**'],
&gt;           },
&gt;         'pkgs/openssl' : {
&gt;             keys : ['DEF...', '456...'],
&gt;             threshold : 2,
&gt;             paths : ['pkgs/openssl/**'],
&gt;           },
&gt;         ...
&gt;       }
&gt;   }

To be clear, are you proposing that *every* role be able to delegate
itself in its particular file, or that a single level of delegation
exist in the targets.txt file?

&gt; The above would mean that the top-level Targets role had delegated a
&gt; role whose full name would be targets/bundles/tor-browser-stable (as it
&gt; is delegated by the targets role, the prepended targets/ is implicit in
&gt; the delegated role's name). This role for the tor-browser-stable bundle
&gt; would be trusted for the specified paths relative to the repository's
&gt; targets/ directory. Thus, a specific version's bundleinfo file created
&gt; by the bundler could be placed on the repository at, for example:
&gt;
&gt;   /targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.bundleinfo
&gt;
&gt; (Note that this bundle role is trusted for all targets files matching
&gt; the path 'bundles/tor-browser-stable/**' under the repository's targets/
&gt; directory, as specified when this role was created through the above
&gt; delegation.)
&gt;
&gt; The bundle maintainer would sign a metadata file listing the hash and
&gt; size of this bundleinfo. This metadata would be placed on the repository
&gt; at:
&gt;
&gt;   /meta/targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.txt
&gt;
&gt; (Note that the basename of these files isn't crucial to this aspect of
&gt; the design. They don't need to repeat the path info, though that's
&gt; probably helpful for humans.)
&gt;
&gt; More generally, the metadata location is:
&gt;
&gt;   /meta/ROLE_NAME/[ANY_PATH/]ANY_NAME.txt
&gt;
&gt; Packages are similar to bundles with the difference that there are one
&gt; or more target files in addition to the pkginfo file. A package
&gt; maintainer may supply the following files to be placed on the
&gt; repository:
&gt;
&gt;   /targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.pkginfo
&gt;   /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll
&gt;   /targets/pkgs/openssl/win32/0.9.8m/ssleay32.dll
&gt;
&gt; The hashes and sizes of these files are listed in metadata signed by the
&gt; targets/pkgs/openssl role (that is, the openssl package maintainer's
&gt; role).  This metadata would be placed on the repository at:
&gt;
&gt;   /meta/targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.txt

So to see if I have it right:

  - Every target file corresponds to exactly one target metadata file,
    though any target metadata file can in principle correspond to one
    or more target files.
  - It is trivial, given a target metadata file, to learn which target
    files it authenticates.  It is not trivial, given a target file, to
    learn which target metadata file authenticates it; ideally, it will
    be in a corresponding location in the metadata.  (Is this required?)
  - Both layers of the updater (the authentication layer and the
    decision layer) need to be able to verify hashes and signatures.

&gt; 2.3. Update Procedure
&gt; ---------------------
&gt;
&gt; The update procedure is:
&gt;
&gt;   * The decision layer uses the authentication layer to retrieve a list
&gt;     of all available bundleinfo files.
&gt;     o Implementation: the decision layer asks the authentication layer
&gt;       for a list of all available metadata file paths/names. The
&gt;       authentication layer obtains this information from the release
&gt;       metadata.
&gt;   * Looking at the paths/names of available bundleinfo files, the
&gt;     decision layer identifies whether there is a newer version of a
&gt;     bundle it is interested in.
&gt;     o Implementation: the bundle names, OS, arch, and bundle version are
&gt;       all contained in paths of the available bundle metadata files.

This seems to add a requirement that you can do a mapping from bundle
name to bundle version.  Specifying string-to-version mappings in a
reliable way can be really nasty.  Sure you want to do that?

&gt;   * The decision layer notices a bundle version in the list that it
&gt;     wants and uses the authentication layer to retrieve the bundleinfo
&gt;     file for that version.
&gt;   * The decision layer reads the contents of the bundleinfo file which
&gt;     indicate the necessary package versions and any other info the
&gt;     decision layer needs.
&gt;   * The decision layer uses the authentication layer to retrieve the
&gt;     pkginfo files for each of the package versions that it wants.
&gt;   * The decision layer understands the contents of the pkginfo
&gt;     files. These files indicate the individual files that are part of
&gt;     this version of the package.
&gt;   * The decision layer uses the authentication layer to retrieve the
&gt;     individual files (e.g. /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll)
&gt;     that are needed.
&gt;   * The decision layer hands off the relevant installation instructions
&gt;     (from the bundleinfo and pkginfo files) and individual package files
&gt;     to the code that performs the installation/upgrade.
&gt;
&gt;
&gt; 2.4.bundleinfo and pkginfo
&gt; --------------------------
&gt;
&gt; As the contents of the bundleinfo and pkginfo are opaque to the
&gt; authentication layer, essentially there are two completely separate sets
&gt; of metadata in this design. It would make sense to have them use the
&gt; same format (e.g. Canonical JSON) and be parsed/generated by the same
&gt; code.

This argues for three components, then: the two you described, plus a
generic data-format layer that they both could use.

&gt; The bundleinfo and pkginfo files would contain largely the same
&gt; information as these files do in the current Thandy spec (though they
&gt; wouldn't be directly signed but rather would be described in signed
&gt; authentication-layer metadata).
&gt;
&gt; There are a few reasons it is good to have the bundleinfo/pkginfo be
&gt; opaque to the authentication layer. One reason is that changes to
&gt; bundleinfo/pkginfo fields can be tested independently of the
&gt; authentication layer. Also, non-backwards-compatible changes could be
&gt; made by introducing a new file name such as bundleinfo.v2 which would be
&gt; effectively invisible to legacy clients.
&gt;
&gt; 2.5. Differences with TUF
&gt; -------------------------
&gt;
&gt; The authentication layer's metadata and roles are very similar to the
&gt; current TUF specification. However, there are a few differences.
&gt;
&gt; TUF currently does not allow a single role to directly delegate multiple
&gt; roles deep. In TUF, one would need the following role structure:
&gt;
&gt; Root
&gt; `-- Targets
&gt;     |-- bundles
&gt;     |   `-- tor-browser-stable
&gt;     `-- pkgs
&gt;         `-- openssl
&gt;
&gt; That is, the Targets role would have to first delegate a bundles role
&gt; which then delegates a tor-browser-stable role.
&gt;
&gt; Relatedly, TUF gives each delegated role the ability to sign a single
&gt; metadata file whose name is exactly the role's name. This may be
&gt; non-ideal for Thandy because bundlers and packagers would need to keep a
&gt; continuously growing metadata file that lists all of the versions that
&gt; they want to be available to clients or, alternatively, delegate
&gt; subroles for each version in order to use separate metadata files for
&gt; each. (Note that this is talking about the authentication layer's
&gt; metadata, not bundleinfo and pkginfo files.)
&gt;
&gt; In contrast, with this proposal, a bundler/packager would sign a
&gt; metadata file that lists only the new target files they are adding to
&gt; the repository.---This isn't a case where there's one correct way to do
&gt; things, but my understanding is that Thandy would like old versions to
&gt; remain available within their expiration times and would like
&gt; bundlers/packagers to not have to deal with issues such as accidentally
&gt; removing an old version they didn't mean to remove when generating and
&gt; signing metadata to make a new version available.
&gt;
&gt; [end of proposal]
&gt;

peace &amp; happy new year,
-- 
Nick
</body></email><email><emailId>20110111180831</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-01-11 18:08:31-0400</timestampReceived><subject>Re: Arm Release 1.4.1</subject><body>

[Attachment #2 (multipart/mixed)]


Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Hi everyone. The next version of arm (1.4.1) is available including
&gt; the proc querying enhancements, Fabian's BSD compatibility patches,
&gt; and numerous other improvements:
&gt; https://blog.torproject.org/blog/arm-release-141
&gt; 
&gt; Updates to the packages and repositories will be staggered a week
&gt; (just in case issues are discovered over the next new days). Feedback
&gt; and bug reports are always welcome! -Damian

I'm a bit behind on my Tor-related mails, so this one is out of order.

Anyway, 1.4.1 seems to have issues in the !self._useProc case
and (at least on FreeBSD) messes up the screen with exceptions
like these if Tor has only recently been started:

Exception in thread Thread-3:
Traceback (most recent call last):
File "/usr/local/lib/python2.6/threading.py", line 532, in __bootstrap_inner
self.run()
File "/usr/home/fk/arm/src/util/sysTools.py", line 538, in run
newValues["cpuSampling"] = newValues["cpuAvg"]
KeyError: 'cpuAvg'

The attached patch (0003) seems to fix it for me,
but I didn't properly test it yet.

Fabian

[Attachment #5 (text/x-patch)]

From 0400ec3b28acd5818763f9f30a6b93275c228927 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Tue, 11 Jan 2011 17:56:28 +0100
Subject: [PATCH 1/3] Fix the ps output in a comment

---
 src/util/sysTools.py |    5 +++--
 1 files changed, 3 insertions(+), 2 deletions(-)

diff --git a/src/util/sysTools.py b/src/util/sysTools.py
index ad9cd3c..b303d24 100644
--- a/src/util/sysTools.py
+++ b/src/util/sysTools.py
@@ -479,8 +479,9 @@ class ResourceTracker(threading.Thread):
           newValues["memUsagePercentage"] = float(memUsage) / totalMemory
         else:
           # the ps call formats results as:
-          # %CPU   RSS %MEM     ELAPSED
-          # 0.3 14096  1.3       29:51
+          #     TIME     ELAPSED   RSS %MEM
+          # 3-08:06:32 21-00:00:12 121844 23.5
+
           psCall = call("ps -p %s -o cputime,etime,rss,%%mem" % self.processPid)
           
           isSuccessful = False
-- 
1.7.3.5


[Attachment #6 (text/x-patch)]

From c18fc6796b7210fb5bb464b8e1e6105556e44a9f Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Tue, 11 Jan 2011 18:01:22 +0100
Subject: [PATCH 2/3] Mention another possible ps output that isn't yet covered

---
 src/util/sysTools.py |    6 ++++++
 1 files changed, 6 insertions(+), 0 deletions(-)

diff --git a/src/util/sysTools.py b/src/util/sysTools.py
index b303d24..cea9374 100644
--- a/src/util/sysTools.py
+++ b/src/util/sysTools.py
@@ -479,8 +479,14 @@ class ResourceTracker(threading.Thread):
           newValues["memUsagePercentage"] = float(memUsage) / totalMemory
         else:
           # the ps call formats results as:
+          #
           #     TIME     ELAPSED   RSS %MEM
           # 3-08:06:32 21-00:00:12 121844 23.5
+          #
+          # or if Tor has only recently been started:
+          #
+          #     TIME      ELAPSED    RSS %MEM
+          #  0:04.40        37:57  18772  0.9
 
           psCall = call("ps -p %s -o cputime,etime,rss,%%mem" % self.processPid)
           
-- 
1.7.3.5


[Attachment #7 (text/x-patch)]

From cfa1a3b06f8fabe8b0ddffa56ecc0d1b5fff6e5e Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Tue, 11 Jan 2011 18:30:39 +0100
Subject: [PATCH 3/3] Let parseShortTimeLabel() deal with timestamps that use a dot \
between minutes and seconds

---
 src/util/uiTools.py |    5 ++++-
 1 files changed, 4 insertions(+), 1 deletions(-)

diff --git a/src/util/uiTools.py b/src/util/uiTools.py
index 854ca39..07ea949 100644
--- a/src/util/uiTools.py
+++ b/src/util/uiTools.py
@@ -333,7 +333,7 @@ def parseShortTimeLabel(timeEntry):
   """
   Provides the number of seconds corresponding to the formatting used for the
   cputime and etime fields of ps:
-  [[dd-]hh:]mm:ss
+  [[dd-]hh:]mm:ss or hh:mm.ss
   
   If the input entry is malformed then this raises a ValueError.
   
@@ -349,6 +349,9 @@ def parseShortTimeLabel(timeEntry):
     days = int(timeEntry[:dateDivider])
     timeEntry = timeEntry[dateDivider+1:]
   
+  # normalise the seconds delimiter
+  timeEntry = timeEntry.replace(".", ":")
+  
   timeComp = timeEntry.split(":")
   if len(timeComp) == 3:
     hours, minutes, seconds = timeComp
-- 
1.7.3.5


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110112214338</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-01-12 21:43:38-0400</timestampReceived><subject>Stack blowout in 0.2.3.0-alpha-dev?</subject><body>

gurgle (our tor node) kept crashing, so I ran it under gdb.  It crashed
again, with a SEGV and the attached stack trace.  I truncated it; the
whole trace goes on for &gt;1600 frames (then I gave up hitting Enter).

   - Ian

["bt" (text/plain)]

Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule \
weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory Jan 09 05:25:03.000 [warn] \
Weighted bandwidth is 0.000000 in node selection for rule weight as directory Jan 09 \
05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule weight \
as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory Jan 09 05:25:03.000 [warn] \
Weighted bandwidth is 0.000000 in node selection for rule weight as directory Jan 09 \
05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule weight \
as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory Jan 09 05:25:03.000 [warn] \
Weighted bandwidth is 0.000000 in node selection for rule weight as directory Jan 09 \
05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule weight \
as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory Jan 09 05:25:03.000 [warn] \
Weighted bandwidth is 0.000000 in node selection for rule weight as directory Jan 09 \
05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule weight \
as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory Jan 09 05:25:03.000 [warn] \
Weighted bandwidth is 0.000000 in node selection for rule weight as directory Jan 09 \
05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node selection for rule weight \
as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth is 0.000000 in node \
selection for rule weight as directory Jan 09 05:25:03.000 [warn] Weighted bandwidth \
is 0.000000 in node selection for rule weight as directory

Program received signal SIGSEGV, Segmentation fault.
0xb7d5cdbb in ?? () from /lib/tls/i686/cmov/libc.so.6
(gdb) bt
#0  0xb7d5cdbb in ?? () from /lib/tls/i686/cmov/libc.so.6
#1  0xb7d5d329 in ?? () from /lib/tls/i686/cmov/libc.so.6
#2  0xb7d159f8 in getaddrinfo () from /lib/tls/i686/cmov/libc.so.6
#3  0x0810cecd in tor_addr_lookup (name=0xbf6012ac "gurgle", family=2,
    addr=0xbf601238) at address.c:171
#4  0x0810db7f in tor_lookup_hostname (name=0xbf6012ac "gurgle",
    addr=0xbf6012a4) at compat.c:1671
#5  0x080b9aa4 in resolve_my_address (warn_severity=6, options=0x81754b8,
    addr_out=0xbf60141c, hostname_out=0x0) at config.c:2390
#6  0x080793d9 in router_pick_published_address (options=0x81754b8,
    addr=0xbf60141c) at router.c:1349
#7  0x080edc4f in directory_fetches_from_authorities (options=0x81754b8)
    at dirserv.c:1186
#8  0x080e31b7 in directory_command_should_use_begindir (
    address=&lt;value optimized out&gt;, _addr=0xbf601534,
    or_port=&lt;value optimized out&gt;, dir_port=80,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb46888b8 \
"\362\004D\023\332\302\340.=k\317G5\241\233\312\035\351r\201U\017\063g\310NQ\352\071T\230\035\330;*OR\036\377)", \
dir_purpose=14 '\016',  router_purpose=0 '\000', anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:795
#9  directory_initiate_command_rend (address=&lt;value optimized out&gt;,
    _addr=0xbf601534, or_port=&lt;value optimized out&gt;, dir_port=80,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb46888b8 \
"\362\004D\023\332\302\340.=k\317G5\241\233\312\035\351r\201U\017\063g\310NQ\352\071T\230\035\330;*OR\036\377)", \
dir_purpose=14 '\016',  router_purpose=0 '\000', anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:846
#10 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb46888a0, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#11 0x080e37bc in directory_initiate_command_routerstatus (status=0xb46888a0,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#12 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#13 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#14 0x080e683b in connection_dir_request_failed (conn=0xad51a420)
    at directory.c:636
#15 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb402fd58 \
"\275j\202\222U\313\b\346o\276}7H65\206\344k8\020N@!\345\031:,'V\355\372\rPc*\220\362", \
&lt;incomplete sequence \364&gt;,  dir_purpose=14 '\016', router_purpose=0 '\000', \
anonymized_connection=0,  resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#16 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb402fd40, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#17 0x080e37bc in directory_initiate_command_routerstatus (status=0xb402fd40,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#18 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#19 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#20 0x080e683b in connection_dir_request_failed (conn=0xad51a330)
    at directory.c:636
#21 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb402fd58 \
"\275j\202\222U\313\b\346o\276}7H65\206\344k8\020N@!\345\031:,'V\355\372\rPc*\220\362", \
&lt;incomplete sequence \364&gt;,  dir_purpose=14 '\016', router_purpose=0 '\000', \
anonymized_connection=0,  resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#22 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb402fd40, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#23 0x080e37bc in directory_initiate_command_routerstatus (status=0xb402fd40,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#24 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#25 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#26 0x080e683b in connection_dir_request_failed (conn=0xad51a248)
    at directory.c:636
#27 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb2127470 \
"\204{\037\205\003Dd\221\245H\222\371\004\223NN\270]\252s\256\061\347&lt;clY\302\217\230\211\356E\310{\217\022", \
&lt;incomplete sequence \374&gt;, dir_purpose=14 '\016', router_purpose=0 '\000', \
anonymized_connection=0,  resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#28 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb2127458, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#29 0x080e37bc in directory_initiate_command_routerstatus (status=0xb2127458,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#30 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#31 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#32 0x080e683b in connection_dir_request_failed (conn=0xad51a160)
    at directory.c:636
#33 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb42b8e20 "\226\225\337\303_\376\270a2\233\237\032\260LF9p \
\316\061\337/\240\062\303\345\202!\220\252,#$\036IO6\340\064\234",  dir_purpose=14 \
'\016', router_purpose=0 '\000', anonymized_connection=0,  resource=0x812d270 \
"microdesc", payload=0x0, payload_len=0,  if_modified_since=1294459380, \
rend_query=0x0) at directory.c:902 #34 0x080e36e9 in \
directory_initiate_command_routerstatus_rend (  status=0xb42b8e08, dir_purpose=&lt;value \
optimized out&gt;,  router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#35 0x080e37bc in directory_initiate_command_routerstatus (status=0xb42b8e08,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#36 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#37 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#38 0x080e683b in connection_dir_request_failed (conn=0xad51a070)
    at directory.c:636
#39 0x080e30ce in directory_initiate_command_rend (
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb46888b8 \
"\362\004D\023\332\302\340.=k\317G5\241\233\312\035\351r\201U\017\063g\310NQ\352\071T\230\035\330;*OR\036\377)", \
dir_purpose=14 '\016',  router_purpose=0 '\000', anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#40 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb46888a0, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#41 0x080e37bc in directory_initiate_command_routerstatus (status=0xb46888a0,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#42 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#43 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#44 0x080e683b in connection_dir_request_failed (conn=0xad519f80)
    at directory.c:636
#45 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb3b76c88 \
"{\346\203\346]H\024\023!\305\355\222\360u\305Sd\254q#\335\354\345\032s\022\213y\363\062\"7t\265\202\265\022\250",
  dir_purpose=14 '\016', router_purpose=0 '\000', anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#46 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb3b76c70, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#47 0x080e37bc in directory_initiate_command_routerstatus (status=0xb3b76c70,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#48 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#49 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#50 0x080e683b in connection_dir_request_failed (conn=0xad519e90)
    at directory.c:636
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
#51 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb20a5cd0 \
"J\f\315-\334y\225\b=s\365\326g\020\f\212X1\361m\\\027\332\340\177\262\355/\374\335;\036\367\020\350\f\037\030T\257",
  dir_purpose=14 '\016', router_purpose=0 '\000', anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#52 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb20a5cb8, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#53 0x080e37bc in directory_initiate_command_routerstatus (status=0xb20a5cb8,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#54 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#55 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#56 0x080e683b in connection_dir_request_failed (conn=0xad519da0)
    at directory.c:636
#57 0x080e30ce in directory_initiate_command_rend (
    address=&lt;value optimized out&gt;, _addr=&lt;value optimized out&gt;,
    or_port=&lt;value optimized out&gt;, dir_port=&lt;value optimized out&gt;,
    supports_conditional_consensus=1, supports_begindir=1,
    digest=0xb5b1f460 \
"\n\323\372\210M\030\370\236\352-\211\300\031\067\236\016\177\331D\027Q2\277(*&amp;\350\034\252Z%\271c\345\365tx", \
&lt;incomplete sequence \324&gt;, dir_purpose=14 '\016', router_purpose=0 '\000', \
anonymized_connection=0,  resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:902
#58 0x080e36e9 in directory_initiate_command_routerstatus_rend (
    status=0xb5b1f448, dir_purpose=&lt;value optimized out&gt;,
    router_purpose=&lt;value optimized out&gt;, anonymized_connection=0,
    resource=0x812d270 "microdesc", payload=0x0, payload_len=0,
    if_modified_since=1294459380, rend_query=0x0) at directory.c:549
#59 0x080e37bc in directory_initiate_command_routerstatus (status=0xb5b1f448,
    dir_purpose=&lt;value optimized out&gt;, router_purpose=&lt;value optimized out&gt;,
    anonymized_connection=0, resource=0x812d270 "microdesc", payload=0x0,
    payload_len=0, if_modified_since=1294459380) at directory.c:584
#60 0x080e3a52 in directory_get_from_dirserver (dir_purpose=14 '\016',
    router_purpose=0 '\000', resource=0x812d270 "microdesc", pds_flags=2)
    at directory.c:475
#61 0x080556f1 in update_consensus_networkstatus_downloads (
    now=&lt;value optimized out&gt;) at networkstatus.c:1244
#62 0x080e683b in connection_dir_request_failed (conn=0xad519cb0)
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---q
 at directory.cQuit



</body></email><email><emailId>20110107232829</emailId><senderName></senderName><senderEmail>travis+ml-tor-dev</senderEmail><timestampReceived>2011-01-07 23:28:29-0400</timestampReceived><subject>polipo-tor debian package 1.3 released</subject><body>

[Attachment #2 (multipart/mixed)]


On Wed, Oct 27, 2010 at 05:44:49PM +1100, Erik de Castro Lopo wrote:
&gt; travis+ml-tor-dev@subspacefield.org wrote:
&gt; If you want people to look at the packaging, you should provide
&gt; the Debian .dsc file, the original tarball and a diff.gz file
&gt; (assuming this packaging of some upstream source).

I've attached the dsc and deb; this is a native package.

&gt; You should be using something like debuild to build a debian package
&gt; and that will provide the three files I was asking about.

I am.

I will follow up with debian-mentors.

&gt; Building Debian packages is very well documented on debian.org.

Well, sort of but not really.  Once you get into making them,
you'll know what I mean - it's at once too much and not enough,
not towards native packages most of the time.

Although, I must admit, I relied a lot on Ubuntu guides.  I looked at
the Debian stuff and balked.  There's a lot of tools, and it's not
always clear what tool to use, though each tool is well-documented,
and there are several competing systems (CDBS, dh-make, quilt), and
most of the info is geared towards non-native packages.

&gt; &gt; My emails do not have attachments;
&gt; This email did have an attachment.

True :-)  This one too.
-- 
Good code works on most inputs; correct code works on all inputs.
My emails do not have attachments; it's a digital signature that your mail
program doesn't understand. | http://www.subspacefield.org/~travis/ 
If you are a spammer, please email john@subspacefield.org to get blacklisted.

["polipo-tor_1.3_all.deb" (application/x-debian-package)]
["polipo-tor_1.3.dsc" (text/plain)]

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Format: 3.0 (native)
Source: polipo-tor
Binary: polipo-tor
Architecture: all
Version: 1.3
Maintainer: Travis H. &lt;travis+o-ubuntu@subspacefield.org&gt;
Homepage: none
Standards-Version: 3.8.4
Build-Depends: debhelper (&gt;= 7.0.50~)
Checksums-Sha1: 
 e0d0b23f1ce596973cda0423fcdf07830e22ab17 8862 polipo-tor_1.3.tar.gz
Checksums-Sha256: 
 845f03fd580935549e199c6128b2816895ff3db4704d373d6ef49fc5a0152b65 8862 polipo-tor_1.3.tar.gz
Files: 
 8e840461eb7fc8eaf4eea60204b23752 8862 polipo-tor_1.3.tar.gz

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iQIcBAEBAgAGBQJNHhrSAAoJEP52h2ubEmAIvYsP/RuifW1aDBzHqlnxu9IoBUVY
0LlS/Z+MsPVuuoIwqH/72Tra+rhRQFLNSTSVzBq8S57FzteJQa5zfXcktNrs+s+g
0ZTiUsxZtKeMfjh+9TxgnBaTRmaTiCY+OW/FmUKeYurY95GYhI0+lVbdZ9QiuHi/
6ZvupzfnP6XdyHrxHAX+gM0P9QqlEAOamI6AfyIos7zMQvWprwr8/172tLib5oFT
VtM4cyrqWblSqtcoWBZpaiAq+yXFnjlhkYBrjOwGwva6ZiiMxRHg9kK5hFudEG6B
/GAoaKL5IY9kSbYDukBwYDJZ1ymDv0TtvVY8qrFxhc+MQJIoH+IxyIucknbVFWf+
EkahhS3SOIE/Eh5m/N1MfXpBwvlxnOkfACdGQpD8mbikqOPmisS88dOjV9tXsNc7
ITclj3OAgO2tmRoXQDzkBktRAk569z4o9+wsBvlor1oc/Fb7rB1Y4GOKqESyQhBB
iFgtgn8+UvkznUbWDEED5VRO/69VpC/MPRnm/bUrY8g4XxSyLx3Yd0LZUlDRN5CT
aW8Q3NbrjkLDUi2u6WAo+IoxfDrnr41FllsSx69+fii/sjD6ouJ5z2Fg1Snd0Aqv
yGpo+lweUCy1q5JiTXoKiDUJ5bAJejMlKeqWrOJcU/nGCJND1ssvk53Pe/OI4VHz
jE1A2DKSvSRiAO35YPl2
=47G4
-----END PGP SIGNATURE-----

[Attachment #7 (application/pgp-signature)]

</body></email><email><emailId>20110116020440</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2011-01-16 02:04:40-0400</timestampReceived><subject>Comments on proposal idea xxx-pluggable-transport</subject><body>

I've been working on some code to make it more difficult for someone
observing traffic between a Tor client and bridge to know that it is
Tor traffic (and therefore blocking it). It works by making the
traffic look more like HTTP, but it would be desirable to have other
alternative transports. Making this work easily is the topic of
xxx-pluggable-transport:

 https://gitweb.torproject.org/tor.git/blob/HEAD:/doc/spec/proposals/ideas/xxx-pluggable-transport.txt

My code for sending Tor over (not quite) HTTP can be found here:

 http://gitweb.torproject.org/sjm217/pluggable-transport.git

It is far from being HTTP compliant, but is good enough to make
Wireshark think it is HTTP, and it shouldn't have any static strings
which make it easy to block (as it implements a very simple
repeating-pad xor obfuscation of underlying Tor data).

 http://www.cl.cam.ac.uk/~sjm217/volatile/pluggable-transport.png

N.B. This code runs, but it is trivially recognizable by someone who
knows what they are doing. It might get through an automated firewall
that blocks Tor, but please don't use it in situations where users
would be at risk of recriminations if they are caught using this
software.

Currently this code isn't compliant with the xxx-pluggable-transport
proposal, but in thinking about it, I have had a few thoughts.

1) The proposal talks about SOCKS, and my code implements SOCKS4.
However from my reading, the proposal depends on SOCKS5 because it
talks about putting NUL-separated key/value pairs in the username and
password fields of the SOCKS handshake. SOCKS4 there is no password
field and the username is NUL terminated, so NUL characters are not
permitted inside.

We could mandate that protocol obfuscators support SOCKS5 (it's not
much harder to implement than SOCKS4), or change the spec to not
require NULs in the username field. Either way it doesn't make a big
difference but it should be clear which version of SOCKS we are
talking about.

2) The syntax for specifying obfuscated access to bridges is:

 bridge method address:port [[keyid=]id-fingerprint] [k=v] [k=v] [k=v]

This could be a bit confusing considering the current syntax (which we
will have to keep for backwards compatibility:

 bridge address:port [fingerprint]

If we require that method does not contain a ":" and a port is always
specified, I can see how this could be unambiguously parsed, but that
seems a bit ugly.

3) The two options for specifying a transport are:

 ClientTransportPlugin trebuchet socks5 127.0.0.1:9999

 ClientTransportPlugin trebuchet /usr/libexec/tor-proxies/trebuchet [options]

These seem ambiguous. How can Tor reliably tell that the first form is
intended when both could have the same number of arguments?

4) When Tor launches the client proxy, the client proxy decides what
port it is listening on. This raises the possibility of conflicts. How
about if Tor picks the ports the client proxy should listen on, and
tells it via a command line parameter. Note that this can't be simply
the first parameter, because on Windows (where scripts are not
executable) the user would have to specify the path as
C:/Python/python.exe SCRIPTNAME.py.

5) Minor. Methods are specified as "CMETHOD: methodname", but
terminated with "METHODS:DONE". I think we should be consistent about
whether there is a space between the colon and value.

Steven.

-- 
http://www.cl.cam.ac.uk/users/sjm217/
</body></email><email><emailId>20110113024703</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-13 02:47:03-0400</timestampReceived><subject>Re: Stack blowout in 0.2.3.0-alpha-dev?</subject><body>

On Wed, Jan 12, 2011 at 4:43 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; gurgle (our tor node) kept crashing, so I ran it under gdb.  It crashed
&gt; again, with a SEGV and the attached stack trace.  I truncated it; the
&gt; whole trace goes on for &gt;1600 frames (then I gave up hitting Enter).
&gt;
&gt;   - Ian
&gt;

Ug.  Doesn't look like I'm going to figure this out today.  Could you
please add a trac entry so that it goes in with the other bugs and
doesn't get forgotten about?

many thanks,
-- 
Nick

</body></email><email><emailId>20110112051439</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-01-12 05:14:39-0400</timestampReceived><subject>Re: Arm Release 1.4.1</subject><body>

Thanks! Patches applied and I've released a fixed version (1.4.1.1).
There were two issues...

- If an error occurred while resolving connections for the first time
then a missing dictionary key caused that stacktrace you saw. Trystero
also reported this on irc.

- The root cause of that failure was the issue that you found (being
unable to parse the ps output due to an unexpected decimal value).

Dumb question, but are you sure that it's hh:mm.ss rather than
mm:ss.ss (ie, it's providing decimal seconds)?

Many thanks for the patches! -Damian
</body></email><email><emailId>20110112192236</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2011-01-12 19:22:36-0400</timestampReceived><subject>Re: Arm Release 1.4.1</subject><body>

[Attachment #2 (multipart/mixed)]


Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Thanks! Patches applied and I've released a fixed version (1.4.1.1).
&gt; There were two issues...
&gt; 
&gt; - If an error occurred while resolving connections for the first time
&gt; then a missing dictionary key caused that stacktrace you saw. Trystero
&gt; also reported this on irc.
&gt; 
&gt; - The root cause of that failure was the issue that you found (being
&gt; unable to parse the ps output due to an unexpected decimal value).
&gt; 
&gt; Dumb question, but are you sure that it's hh:mm.ss rather than
&gt; mm:ss.ss (ie, it's providing decimal seconds)?

Looks like you're right, so my patch actual made it worse. Oops.

I attached another one. Again only briefly tested, though.

Fabian

[Attachment #5 (text/x-patch)]

From 89bde2e5412bc8a50df9a65b367fa5fb85394de5 Mon Sep 17 00:00:00 2001
From: Fabian Keil &lt;fk@fabiankeil.de&gt;
Date: Wed, 12 Jan 2011 18:53:23 +0100
Subject: [PATCH] Unbreak parseShortTimeLabel(). As Damian pointed out it's mm:ss.ss not hh:mm.ss

---
 src/util/uiTools.py |    6 ++----
 1 files changed, 2 insertions(+), 4 deletions(-)

diff --git a/src/util/uiTools.py b/src/util/uiTools.py
index 07ea949..89fa1c3 100644
--- a/src/util/uiTools.py
+++ b/src/util/uiTools.py
@@ -333,7 +333,7 @@ def parseShortTimeLabel(timeEntry):
   """
   Provides the number of seconds corresponding to the formatting used for the
   cputime and etime fields of ps:
-  [[dd-]hh:]mm:ss or hh:mm.ss
+  [[dd-]hh:]mm:ss or mm:ss.ss
   
   If the input entry is malformed then this raises a ValueError.
   
@@ -349,14 +349,12 @@ def parseShortTimeLabel(timeEntry):
     days = int(timeEntry[:dateDivider])
     timeEntry = timeEntry[dateDivider+1:]
   
-  # normalise the seconds delimiter
-  timeEntry = timeEntry.replace(".", ":")
-  
   timeComp = timeEntry.split(":")
   if len(timeComp) == 3:
     hours, minutes, seconds = timeComp
   elif len(timeComp) == 2:
     minutes, seconds = timeComp
+    seconds = round(float(seconds))
   else:
     raise ValueError(errorMsg)
   
-- 
1.7.3.5


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110122165558</emailId><senderName>Bernd Kreuss</senderName><senderEmail>prof7bit@googlemail.com</senderEmail><timestampReceived>2011-01-22 16:55:58-0400</timestampReceived><subject>how to checkout current stable branch</subject><body>

This is probably a stupid question but how do I checkout the 0.2.1
branch from git? With svn I knew how to do such things but I don't get
how this git thing is meant to be used.

I have successfully checked out the master branch via git clone
git://git.torproject.org/tor.git and can compile it but what is the URL
for the 0.2.1 branch? I can't find any instructions about this.

Bernd
</body></email><email><emailId>20110103203800</emailId><senderName>Florian Tschorsch</senderName><senderEmail>tschorsch@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2011-01-03 20:38:00-0400</timestampReceived><subject>Proposal: Token Bucket</subject><body>


Filename: xxx-tokenbucket.txt
Title: Token Bucket
Author: Florian Tschorsch and Bjrn Scheuermann
Created: 03-Dec-2010
Status: Draft / Open

Overview:

  The following proposal targets the reduction of queuing times in onion
  routers. In particular, we focus on the token bucket algorithm in Tor and
  point out that current usage unnecessarily locks cells for long time spans.
  We propose a non-intrusive change in Tor's design which overcomes the
  deficiencies.

Motivation and Background:

  Cell statistics from the Tor network [1] reveal that cells reside in
  individual onion routers' cell queues for up to several seconds. These
  queuing times increase the end-to-end delay very significantly and are
  apparently the largest contributor to overall cell latency in Tor.

  In Tor there exist multiple token buckets on different logical levels. They
  all work independently. They are used to limit the up- and downstream of an
  onion router. All token buckets are refilled every second with a constant
  amount of tokens that depends on the configured bandwidth limits. For
  example, the so-called RelayedTokenBucket limits relay traffic only. All
  read data of incoming connections are bound to a dedicated read token
  bucket. An analogous mechanism exists for written data leaving the onion
  router. We were able to identify the specific usage and implementation of
  the token bucket algorithm as one cause for very high (and unnecessary)
  queuing times in an onion router.

  First, we observe that the token buckets in Tor are (surprisingly at a first
  glance) allowed to take on negative fill levels. This is justified by the
  TLS connections between onion routers where whole TLS records need to be
  processed. The token bucket on the incoming side (i.e., the one which
  determines at which rate it is allowed to read from incoming TCP
  connections) in particular often runs into non-negligible negative fill
  levels. As a consequence of this behavior, sometimes slightly more data is
  read than it would be admissible upon strict interpretation of the token
  bucket concept.

  However, the token bucket for limiting the outgoing rate does not take on
  negative fill levels equally often. Consequently, it regularly happens
  that somewhat more data are read on the incoming side than the outgoing
  token bucket allows to be written during the same cycle, even if their
  configured data rates are the same. The respective cells will thus not be
  allowed to leave the onion router immediately. They will thus necessarily
  be queued for at least as long as it takes until the token bucket on the
  outgoing side is refilled again. The refill interval currently is, as
  mentioned before, one second -- so, these cells are delayed for a very
  substantial time. In summary, one could say that the two buckets, on the
  incoming and outgoing side, work like a double door system and frequently
  lock cells for a full token bucket refill interval length.

  Apart from the above described effects, it should be noted that the very
  coarse-grained refill interval of one second also has other detrimental
  effects. First, consider an onion router with multiple TLS connections over
  which cells arrive. If there is high activity (i.e., many incoming cells in
  total), then the coarse refill interval will cause unfairness. Assume (just
  for simplicity) that C doesn't share its TLS connection with any other
  circuit. Moreover, assume that C hasn't transmitted any data for some time
  (e.g., due a typical bursty HTTP traffic pattern). Consequently, there are
  no cells from this circuit in the incoming socket buffers. When the buckets
  are refilled, the incoming token bucket will immediately spend all its
  tokens on other incoming connections. Now assume that cells from C arrive
  soon after. For fairness' sake, these cells should be serviced timely --
  circuit C hasn't received any bandwidth for a significant time before.
  However, it will take a very long time (one refill interval) before the
  current implementation will fetch these cells from the incoming TLS
  connection, because the token bucket will remain empty for a long time. Just
  because the cells happened to arrive at the "wrong" point in time, they must
  wait. Such situations may occur even though the configured admissible
  incoming data rate is not exceeded by incoming cells: the long refill
  intervals often lead to an operational state where all the cells that were
  admissible during a given one-second period are queued until the end of this
  second, before the onion router even just starts processing them. This
  results in unnecessary, long queueing delays in the incoming socket buffers.
  These delays are in *addition* to the above discussed queueing delays in the
  circuit buffers. Because they occur in a different buffer, the socket buffer
  queueing times are not visible in the Tor circuit queue delay statistics [1].

  Finally, the coarse-grained refill intervals result in a very bursty outgoing
  traffic pattern at the onion routers (one large chunk of data once per
  second, instead of smooth transmission progress). This is undesirable, since
  such a traffic pattern can interfere with TCP's control mechanisms and can
  be the source of suboptimal TCP performance on the TLS links between onion
  routers.

Design:

  In order to overcome the described problems, we propose two changes related
  to the token bucket algorithm.

  First, we observe that the token bucket for the relayed traffic on the
  outgoing connections is unnecessary: since no new such traffic is generated
  in an onion router, the rate of this traffic is already limited by the read
  bucket on the incoming side (cp. RelayedTokenBucket). We therefore propose
  to remove the rate limiting mechanism on the outgoing side. This will
  eliminate the "double door effect" discussed above, since all cells are
  allowed to flow freely out of the router once they passed the incoming rate
  limiter.

  Second, the refill interval of the buckets should be shortened. The
  remaining token buckets should be refilled more often, with a
  correspondingly smaller amount of tokens. For instance, the buckets might
  be refilled every 10 milliseconds with one-hundredth of the amount of data
  admissible per second. This will help to overcome the problem of unfairness
  when reading from the incoming socket buffers. At the same time it smoothes
  the traffic leaving the onion routers. We are aware that this latter change
  has apparently been discussed before [2]; we are not sure why this change
  has not been implemented yet.

Conclusion:

  The proposed measures are very simple to implement, but nevertheless a
  significant reduction of cell queueing times can be expected. Experiments
  which we performed with a patched onion router software revealed that
  the CPU utilization of an onion router is not significantly
  impacted by the reduction of the refill interval length and that cell
  queueing times are indeed significantly shorter.

  The presented design proposal is minimally intrusive and does not
  fundamentally change the current Tor design. It is therefore highly
  migratable into the existing architecture. Onion routers can be updated
  independently. As more onion routers use a changed version, gradual
  performance improvements can be expected. We believe that our contribution
  can improve Tor's performance substantially.

  Feedback is highly appreciated.

References:

  [1] Karsten Loesing. Analysis of Circuit Queues in Tor. August 25, 2009.
  [2] https://trac.torproject.org/projects/tor/wiki/sponsors/SponsorD/June2011



-- 
Florian Tschorsch
Mobile and Decentralized Networks
Heinrich-Heine-University
Universittsstr. 1, D-40225 Dsseldorf

Building 25.12, Room 02.43
Phone +49 211 81 11635
Fax +49 211 81 11638

tschorsch@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de



</body></email><email><emailId>20110125090902</emailId><senderName>Erinn Clark</senderName><senderEmail>erinn@torproject.org</senderEmail><timestampReceived>2011-01-25 09:09:02-0400</timestampReceived><subject>Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>


* Andrew Lewman &lt;andrew@torproject.org&gt; [2010:11:23 00:06 -0500]: 
&gt; As for packages, I suggest we support the current release of an OS plus
&gt; two previous versions.  We could rely upon the OS versions of
&gt; libraries rather than bundle our own.  In an optimal world, we ship our
&gt; own libraries for Tor rather than relying upon various vendors to keep
&gt; up to date.  This lets us control features and some part of an operating
&gt; environment for tor.  I'm primarily thinking of zlib, openssl, and
&gt; libevent 1 or 2 for inclusion here.  My idea of an optimal world may
&gt; need thandy implemented to make it a reality.  

I think supporting multiple versions back is a laudable goal, and one we should
consider, but right now it's not feasible (for me, anyway, as the primary
packager with the current infrastructure). The following is my initial sketch
of the package support policy, which is an accurate snapshot of what's
currently out there (specifically for Tor and Vidalia):

For virtually all operating systems and distributions, we support the same 
versions the distributors themselves support. In many cases this means the 
current and previous version, with exceptions made for long-term releases, as
in the case of Ubuntu. If the OS is too old to build packages without a lot of
effort, it is also unsupported, but currently this mainly affects Vidalia.

Linux
--------- 
Tor:
Centos 4.8, Centos 5
Fedora 13, 14
OpenSuSE 11  
Debian (oldstable, stable, testing, and unstable)
Ubuntu (dapper, hardy, intrepid, jaunty, karmic, lucid, maverick)

Vidalia:
Fedora 13, 14
OpenSuSE 11 
Debian (stable, testing, and unstable)
Ubuntu (intrepid, jaunty, karmic, lucid, maverick)

OS X 
---------
10.6 
10.5
10.4 is marginally supported for as long as packages will build without 
difficulty, but probably not for more than a year from today.  Its last
security update was in September 2009. (Safari was updated for Tiger as 
recently as November 2010, however.)

Windows
---------
WinXP to Windows 7

...

This can be more fully fleshed out probably. Feedback is welcome.

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20110121222255</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-01-21 22:22:55-0400</timestampReceived><subject>(FWD) Re: Proposal 171 (revised): Separate streams across circuits</subject><body>

[Forwarding because Nikita isn't subscribed at this address. -RD]

----- Forwarded message from owner-or-dev@freehaven.net -----

From: Nikita Borisov &lt;nikita@illinois.edu&gt;
Date: Fri, 21 Jan 2011 16:00:44 -0600
Subject: Re: Proposal 171 (revised): Separate streams across circuits by
 connection metadata
To: or-dev@freehaven.net

I have a suggestion: streams that have been explicitly designated for
isolation by the use of different ports or usernames should also use a
different set of guard nodes.  My thinking is that there have been
attacks proposed in the past that can profile the set of guard nodes
used by a client over time, as long as it's possible to externally
link the connections (e.g., the connections contain a pseudonymous
username in the cleartext).  If these attacks are used to profile two
sets of externally linkable connections (i.e., two pseudonyms) and
they come up with the same set of guards, that is a pretty strong
indication that the pseudonyms are in fact linked to each other.  If I
used a different port to separate the two pseudonyms, however, and Tor
used a different guard set for each, this would not be a problem.
Conversely, the advantage of using (the same set of) guard nodes
disappears for streams that are not externally linkable, since the
guards do not change the overall probability that each individual
stream will be compromised.

(I think it's harder to make the case that you want to do this based
on implicit session indicators, since there's a chance that those
streams will still be somehow linked, particularly if the indicators
are short-lived, such as PIDs or source ports.)

Thanks,
- Nikita


On Tue, Dec 7, 2010 at 10:02 AM, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; Hi, all.  I'm trying to get the proposal-171 discussion settled down a
&gt; bit more, so I revised the proposal to try to say more like what I
&gt; think it should say.  Here goes:
&gt;
&gt;
&gt; Filename: 171-separate-streams.txt
&gt; Title: Separate streams across circuits by connection metadata
&gt; Author: Robert Hogan, Jacob Appelbaum, Damon McCoy, Nick Mathewson
&gt; Created: 21-Oct-2008
&gt; Modified: 7-Dec-2010
&gt; Status: Open
&gt;
&gt; Summary:
&gt;
&gt;  We propose a new set of options to isolate unrelated streams from one
&gt;  another, putting them on separate circuits so that semantically
&gt;  unrelated traffic is not inadvertently made linkable.
&gt;
&gt; Motivation:
&gt;
&gt;  Currently, Tor attaches regular streams (that is, ones not carrying
&gt;  rendezvous or directory traffic) to circuits based only on whether Tor
&gt;  circuit's current exit node supports the destination, and whether the
&gt;  circuit has been dirty (that is, in use) for too long.
&gt;
&gt;  This means that traffic that would otherwise be unrelated sometimes
&gt;  gets sent over the same circuit, allowing the exit node to link such
&gt;  streams with certainty, and allowing other parties to link such
&gt;  streams probabilistically.
&gt;
&gt;  Older versions of onion routing tried to address this problem by
&gt;  sending every stream over a separate circuit; performance issues made
&gt;  this unfeasible. Moreover, in the presence of a localized adversary,
&gt;  separating streams by circuits increases the odds that, for any given
&gt;  linked set of streams, at least one will go over a compromised
&gt;  circuit.
&gt;
&gt;  Therefore we ought to look for ways to allow streams that ought to be
&gt;  linked to travel over a single circuit, while keeping streams that
&gt;  ought not be linked isolated to separate circuits.
&gt;
&gt; Discussion:
&gt;
&gt;  Let's call a series of inherently-linked streams (like a set of
&gt;  streams downloading objects from the same webpage, or a browsing
&gt;  session where the user requests several related webpages) a "Session".
&gt;
&gt;  "Sessions" are a necessarily a fuzzy concept.  While users typically
&gt;  consider some activities as wholly unrelated to each other ("My IM
&gt;  session has nothing to do with my web browsing!"), the boundaries
&gt;  between activities are sometimes hard to determine.  If I'm reading
&gt;  lolcats in one browser tab and reading about treatments for an
&gt;  embarrassing disease in another, those are probably separate sessions.
&gt;  If I search for a forum, log in, read it for a while, and post a few
&gt;  messages on unrelated topics, that's probably all the same session.
&gt;
&gt;  So with the proviso that no automated process can identify sessions
&gt;  100% accurately, let's see which options we have available.
&gt;
&gt;  Generally, all the streams on a session come from a single
&gt;  application.  Unfortunately, isolating streams by application
&gt;  automatically isn't feasible, given the lack of any nice
&gt;  cross-platform way to tell which local process originated a given
&gt;  connection.  (Yes, lsof works.  But a quick review of the lsof code
&gt;  should be sufficient to scare you away from thinking there is a
&gt;  portable option, much less a portable O(1) option.)  So instead, we'll
&gt;  have to use some other aspect of a Tor request as a proxy for the
&gt;  application.
&gt;
&gt;  Generally, traffic from separate applications is not in the same
&gt;  session.
&gt;
&gt;  With some applications (IRC, for example), each stream is a session.
&gt;
&gt;  Some applications (most notably web browsing) can't be meaningfully
&gt;  split into sessions without inspecting the traffic itself and
&gt;  maintaining a lot of state.
&gt;
&gt;  How well do ports correspond to sessions?  Early versions of this
&gt;  proposal focused on using destination ports as a proxy for
&gt;  application, since a connection to port 22 for SSH is probably not in
&gt;  the same session as one to port 80. This only works with some
&gt;  applications better than others, though: while SSH users typically
&gt;  know when they're on port 22 and when they aren't, a web browser can
&gt;  be coaxed (though img urls or any number of releated tricks) into
&gt;  connecting to any port at all.  Moreover, when Tor gets a DNS lookup
&gt;  request, it doesn't know in advance which port the resulting address
&gt;  will be used to connect to.
&gt;
&gt;  So in summary, each kind of traffic wants to follow different rules,
&gt;  and assuming the existence of a web browser and a hostile web page or
&gt;  exit node, we can't tell one kind of traffic from another by simply
&gt;  looking at the destination:port of the traffic.
&gt;
&gt;  Fortunately, we're not doomed.
&gt;
&gt; Design:
&gt;
&gt;  When a stream arrives at Tor, we have the following data to examine:
&gt;    1) The destination address
&gt;    2) The destination port (unless this a DNS lookup)
&gt;    3) The protocol used by the application to send the stream to Tor:
&gt;       SOCKS4, SOCKS4A, SOCKS5, or whatever local "transparent proxy"
&gt;       mechanism the kernel gives us.
&gt;    4) The port used by the application to send the stream to Tor --
&gt;       that is, the SOCKSListenAddress or TransListenAddress that the
&gt;       application used, if we have more than one.
&gt;    5) The SOCKS username and password, if any.
&gt;    6) The source address and port for the application.
&gt;
&gt;  We propose to use 3, 4, and 5 as a backchannel for applications to
&gt;  tell Tor about different sessions.  Rather than running only one
&gt;  SOCKSPort, a Tor user who would prefer better session isolation should
&gt;  run multiple SOCKSPorts/TransPorts, and configure different
&gt;  applications to use separate ports. Applications that support SOCKS
&gt;  authentication can further be separated on a single port by their
&gt;  choice of username/password.  Streams sent to separate ports or using
&gt;  different authentication information should never be sent over the
&gt;  same circuit.  We allow each port to have its own settings for
&gt;  isolation based on destination port, destination address, or both.
&gt;
&gt;  Handling DNS can be a challenge.  We can get hostnames by one of three
&gt;  means:
&gt;
&gt;    A) A SOCKS4a request, or a SOCKS5 request with a hostname.  This
&gt;       case is handled trivially using the rules above.
&gt;    B) A RESOLVE request on a SOCKSPort.  This case is handled using the
&gt;       rules above, except that port isolation can't work to isolate
&gt;       RESOLVE requests into a proper session, since we don't know which
&gt;       port will eventually be used when we connect to the returned
&gt;       address.
&gt;    C) A request on a DNSPort.  We have no way of knowing which
&gt;       address/port will be used to connect to the requested address.
&gt;
&gt;  When B or C is required but problematic, we could favor the use of
&gt;  AutomapHostsOnResolve.
&gt;
&gt; Interface:
&gt;
&gt;  We propose that {SOCKS,Natd,Trans,DNS}ListenAddr be deprecated in
&gt;  favor of an expanded {SOCKS,Natd,Trans,DNS}Port syntax:
&gt;
&gt;  ClientPortLine = OptionName SP (Addr ":")? Port (SP Options?)
&gt;  OptionName = "SOCKSPort" / "NatdPort" / "TransPort" / "DNSPort"
&gt;  Addr = An IPv4 address / an IPv6 address surrounded by brackets.
&gt;         If optional, we default to 127.0.0.1
&gt;  Port = An integer from 1 through 65535 inclusive
&gt;  Options = Option
&gt;  Options = Options SP Option
&gt;  Option = IsolateOption / GroupOption
&gt;  GroupOption = "SessionGroup=" UINT
&gt;  IsolateOption =  OptNo ("IsolateDestPort" / "IsolateDestAddr" /
&gt;         "IsolateSOCKSUser"/ "IsolateClientProtocol" /
&gt;         "IsolateClientAddr") OptPlural
&gt;  OptNo = "No" ?
&gt;  OptPlural = "s" ?
&gt;  SP = " "
&gt;  UINT = An unsigned integer
&gt;
&gt;  All options are case-insensitive.
&gt;
&gt;  The "IsolateSOCKSUser" and "IsolateClientAddr" options are on by
&gt;  default; "NoIsolateSOCKSUser" and "NoIsolateClientAddr" respectively
&gt;  turn them off.  The IsolateDestPort and IsolateDestAddr and
&gt;  IsolateClientProtocol options are off by default.  NoIsolateDestPort and
&gt;  NoIsolateDestAddr and NoIsolateClientProtocol have no effect.
&gt;
&gt;  Given a set of ClientPortLines, streams must NOT be placed on the same
&gt;  circuit if ANY of the following hold:
&gt;
&gt;    * They were sent to two different client ports, unless the two
&gt;      client ports both specify a "SessionGroup" option with the same
&gt;      integer value.
&gt;    * At least one was sent to a client port with the IsolateDestPort
&gt;      active, and they have different destination ports.
&gt;    * At least one was sent to a client port with IsolateDestAddr
&gt;      active, and they have different destination addresses.
&gt;    * At least one was sent to a client port with IsolateClientProtocol
&gt;      active, and they use different protocols (where SOCKS4, SOCKS4a,
&gt;      SOCKS5, TransPort, NatdPort, and DNS are the protocols in question)
&gt;    * At least one was sent to a client port with IsolateSOCKSUser
&gt;      active, and they have different SOCKS username/password values
&gt;      configurations.  (For the purposes of this option, the
&gt;      username/password pair of ""/"" is distinct from SOCKS without
&gt;      authentication, and both are distinct from any non-SOCKS client's
&gt;      non-authentication.)
&gt;    * At least one was sent to a client port with IsolateClientAddr
&gt;      active, and they came from different client addresses.  (For the
&gt;      purpose of this option, any local interface counts as the same
&gt;      address.  So if the host is configured with addresses 10.0.0.1,
&gt;      192.0.32.10, and 127.0.0.1, then traffic from those addresses can
&gt;      leave on the same circuit, but traffic to from 10.0.0.2 (for
&gt;      example) could not share a circuit with any of them.)
&gt;
&gt;  These rules apply regardless of whether the streams are active at the
&gt;  same time.  In other words, if the rules say that streams A and B must
&gt;  not be on the same circuit, and stream A is attached to circuit X,
&gt;  then stream B must never be attached to stream X, even if stream A is
&gt;  closed first.
&gt;
&gt; Alternative Interface:
&gt;
&gt;  We're cramming a lot onto one line in the design above.  Perhaps
&gt;  instead it would be a better idea to have grouped lines of the form:
&gt;
&gt;    StreamGroup 1
&gt;    SOCKSPort 9050
&gt;    TransPort 9051
&gt;    IsolateDestPort 1
&gt;    IsolateClientProtocol 0
&gt;    EndStreamGroup
&gt;
&gt;    StreamGroup 2
&gt;    SOCKSPort 9052
&gt;    DNSPort 9053
&gt;    IsolateDestAddr 1
&gt;    EndStreamGroup
&gt;
&gt;  This would be equivalent to:
&gt;   SOCKSPort 9050 SessionGroup=1 IsolateDestPort NoIsolateClientProtocol
&gt;   TransPort 9051 SessionGroup=1 IsolateDestPort NoIsolateClientProtocol
&gt;   SOCKSPort 9052 SessionGroup=2 IsolateDestAddr
&gt;   DNSPort   9053 SessionGroup=2 IsolateDestAddr
&gt;
&gt;  But it would let us extend range of allowed options later without
&gt;  having client port lines group without bound.  For example, we might
&gt;  give different circuit building parameters to different session
&gt;  groups.
&gt;
&gt; Example of use:
&gt;
&gt;  Suppose that we want to use a web browser, an IRC client, and a SSH
&gt;  client all at the same time.  Let's assume that we want web traffic to
&gt;  be isolated from all other traffic, even if the browser makes
&gt;  connections to ports usually used for IRC or SSH.  Let's also assume
&gt;  that IRC and SSH are both used for relatively long-lived connections,
&gt;  and we want to keep all IRC/SSH sessions separate from one another.
&gt;
&gt;  In this case, we could say:
&gt;
&gt;    SOCKSPort 9050
&gt;    SOCKSPort 9051 IsolateDestAddr IsolateDestPort
&gt;
&gt;  We would then configure our browser to use 9050 and our IRC/SSH
&gt;  clients to use 9051.
&gt;
&gt; Advanced example of use, #2:
&gt;
&gt;  Suppose that we have a bunch of applications, and we launch them all
&gt;  using torsocks, and we want to keep each applications isolated from
&gt;  one another.  We just create a shell script, "torlaunch":
&gt;    #!/bin/bash
&gt;    export TORSOCKS_USERNAME="$1"
&gt;    exec torsocks $@
&gt;  And we configure our SOCKSPort with IsolateSOCKSUser.
&gt;
&gt;  Or if we're on Linux and we want to isolate by application invocation,
&gt;  we would change the TORSOCKS_USERNAME line to:
&gt;
&gt;    export TORSOCKS_USERNAME="`cat /proc/sys/kernel/random/uuid`"
&gt;
&gt; Advanced example of use, #2:
&gt;
&gt;  Now suppose that we want to achieve the benefits of the first example
&gt;  of use, but we are stuck using transparent proxies.  Let's suppose
&gt;  this is Linux.
&gt;
&gt;    TransPort 9090
&gt;    TransPort 9091 IsolateDestAddr IsolateDestPort
&gt;    DNSPort 5353
&gt;    AutomapHostsOnResolve 1
&gt;
&gt;  Here we use the iptables --cmd-owner filter to distinguish which
&gt;  command is originating the packets, directing traffic from our irc
&gt;  client and our SSH client to port 9091, and directing other traffic to
&gt;  9090.  Using AutomapHostsOnResolve will confuse ssh in its default
&gt;  configuration; we'll need to find a way around that.
&gt;
&gt; Security Risks:
&gt;
&gt;  Disabling IsolateClientAddr is a pretty bad idea.
&gt;
&gt;  Setting up a set of applications to use this system effectively is a
&gt;  big problem.  It's likely that lots of people who try to do this will
&gt;  mess it up.  We should try to see which setups are sensible, and see
&gt;  if we can provide good feedback to explain which streams are isolated
&gt;  how.
&gt;
&gt; Performance Risks:
&gt;
&gt;  This proposal will result in clients building many more circuits than
&gt;  they do today.  To avoid accidentally hammering the network, we should
&gt;  have in-process limits on the maximum circuit creation rate and the
&gt;  total maximum client circuits.
&gt;
&gt; Specification:
&gt;
&gt;  The Tor client circuit selection process is not entirely specified.
&gt;  Any client circuit specification must take these changes into account.
&gt;
&gt; Implementation notes:
&gt;
&gt;  The more obvious ways to implement the "find a good circuit to attach
&gt;  to" part of this proposal involve doing an O(n_circuits) operation
&gt;  every time we have a stream to attach.  We already do such an
&gt;  operation, so it's not as if we need to hunt for fancy ways to make it
&gt;  O(1).  What will be harder is implementing the "launch circuits as
&gt;  needed" part of the proposal.  Still, it should come down to "a simple
&gt;  matter of programming."
&gt;
&gt;  The SOCKS4 spec has the client provide authentication info when it
&gt;  connects; accepting such info is no problem.  But the SOCKS5 spec has
&gt;  the client send a list of known auth methods, then has the server send
&gt;  back the authentication method it chooses.  We'll need to update the
&gt;  SOCKS5 implementation so it can accept user/password authentication if
&gt;  it's offered.
&gt;
&gt;  If we use the second syntax for describing these options, we'll want
&gt;  to add a new "section-based" entry type for the configuration parser.
&gt;  Not a huge deal; we already have kludged up something similar for
&gt;  hidden service configurations.
&gt;
&gt;  Opening circuits for predicted ports has the potential to get a little
&gt;  more complicated; we can probably get away with the existing
&gt;  algorithm, though, to see where its weak points are and look for
&gt;  better ones.
&gt;
&gt;  Perhaps we can get our next-gen HTTP proxy to communicate browser tab
&gt;  or session into to tor via authentication, or have torbutton do it
&gt;  directly.  More design is needed here, though.
&gt;
&gt; Alternative designs:
&gt;
&gt;  The implementation of this option may want to consider cases where the
&gt;  same exit node is shared by two or more circuits and
&gt;  IsolateStreamsByPort is in force.  Since one possible use of the option
&gt;  is to reduce the opportunity of Exit Nodes to attack traffic from the
&gt;  same source on multiple ports, the implementation may need to ensure
&gt;  that circuits reserved for the exclusive use of given ports do not
&gt;  share the same exit node.  On the other hand, if our goal is only that
&gt;  streams should be unlinkable, deliberately shunting them to different
&gt;  exit nodes is unnecessary and slightly counterproductive.
&gt;
&gt;  Earlier versions of this design included a mechanism to isolate
&gt;  _particular_ destination ports and addresses, so that traffic sent to,
&gt;  say, port 22 would never share a port with any traffic *not* sent to
&gt;  port 22.  You can achieve this here by having all applications that
&gt;  send traffic to one of these ports use a separate SOCKSPort, and
&gt;  then setting IsolateDestPorts on that SOCKSPort.
&gt;
&gt; Lingering questions:
&gt;
&gt;  I suspect there are issues remaining with DNS and TransPort users, and
&gt;  that my "just use AutomapHostsOnResolve" suggestion may be
&gt;  insufficient.
&gt;
&gt;



-- 
Nikita Borisov - http://hatswitch.org/~nikita/
Assistant Professor, Electrical and Computer Engineering
Tel: (217) 903-4401, Office: 460 CSL


----- End forwarded message -----
</body></email><email><emailId>20110124224823</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-01-24 22:48:23-0400</timestampReceived><subject>xxx-draft-spec-for-TLS-normalization.txt</subject><body>

I've written a draft to address both blocking and TLS certificate
related fingerprinting issues. Please see the attached text file for
submission into tor/doc/spec/proposals/idea and I'd like to request a
proposal number from nickm.

All the best,
Jake

["xxx-draft-spec-for-TLS-normalization.txt" (text/plain)]

Filename: xxx-draft-spec-for-TLS-normalization.txt
Title: Draft spec for TLS certificate and handshake normalization
Author: Jacob Appelbaum
Created: 24-Jan-2011
Status: Draft


        Draft spec for TLS certificate and handshake normalization


                                    Overview

Scope

This is a document that covers issues with current TLS  (Transport Layer
Security) related certificates generated and used by Tor. It also intends to
cover some of the possible fingerprinting issues present in the current Tor TLS
protocol setup process.

Motivation and history

Censorship is an arms race and this is a step forward in the defense of Tor.
This proposal outlines ideas that attempt to limit the ability of an attack who
wishes to fingerprint and block Tor.

Goals

This proposal intends to normalize or remove easy to predict or static values
in the Tor TLS certificates and with the Tor TLS setup process. TLS certificate
observatories should not be able to trivially detect Tor merely by receiving or
observing the certificate used or advertised by a Tor relay. Additionally I
propose that when these changes are implemented, a covert channel will be
available to signal that a server supports the third version ("V3") of the Tor
handshake protocol.

Non-Goals

This document is not intended to solve all of the possible active or passive
Tor fingerprinting problems. Beyond basic certificate examination or TLS setup
issues, we attempt to make no guarantees about resisting other kinds of
fingerprinting of Tor traffic.

                                Implementation details


Certificate Issues

The CN or commonName ASN1 field

Tor generates certificates with a commonName field that is predictable and the
field is within a given value range that is specific to Tor. Additionally, the
generated host names have other undesirable properties. The host names do not
resolve as they are generally for host names that have not and will not ever
exist in the DNS. They are also often host names that while RFC compliant, they
have almost certainly never been registered by any domain name registrar.

An example of the current commonName field: CN=www.s4ku5skci.net

An example of OpenSSL's asn1parse over a typical Tor certificate:

   0:d=0  hl=4 l= 438 cons: SEQUENCE          
    4:d=1  hl=4 l= 287 cons: SEQUENCE          
    8:d=2  hl=2 l=   3 cons: cont [ 0 ]        
   10:d=3  hl=2 l=   1 prim: INTEGER           :02
   13:d=2  hl=2 l=   4 prim: INTEGER           :4D3C763A
   19:d=2  hl=2 l=  13 cons: SEQUENCE          
   21:d=3  hl=2 l=   9 prim: OBJECT            :sha1WithRSAEncryption
   32:d=3  hl=2 l=   0 prim: NULL              
   34:d=2  hl=2 l=  35 cons: SEQUENCE          
   36:d=3  hl=2 l=  33 cons: SET               
   38:d=4  hl=2 l=  31 cons: SEQUENCE          
   40:d=5  hl=2 l=   3 prim: OBJECT            :commonName
   45:d=5  hl=2 l=  24 prim: PRINTABLESTRING   :www.vsbsvwu5b4soh4wg.net
   71:d=2  hl=2 l=  30 cons: SEQUENCE          
   73:d=3  hl=2 l=  13 prim: UTCTIME           :110123184058Z
   88:d=3  hl=2 l=  13 prim: UTCTIME           :110123204058Z
  103:d=2  hl=2 l=  28 cons: SEQUENCE          
  105:d=3  hl=2 l=  26 cons: SET               
  107:d=4  hl=2 l=  24 cons: SEQUENCE          
  109:d=5  hl=2 l=   3 prim: OBJECT            :commonName
  114:d=5  hl=2 l=  17 prim: PRINTABLESTRING   :www.s4ku5skci.net
  133:d=2  hl=3 l= 159 cons: SEQUENCE          
  136:d=3  hl=2 l=  13 cons: SEQUENCE          
  138:d=4  hl=2 l=   9 prim: OBJECT            :rsaEncryption
  149:d=4  hl=2 l=   0 prim: NULL              
  151:d=3  hl=3 l= 141 prim: BIT STRING        
  295:d=1  hl=2 l=  13 cons: SEQUENCE          
  297:d=2  hl=2 l=   9 prim: OBJECT            :sha1WithRSAEncryption
  308:d=2  hl=2 l=   0 prim: NULL              
  310:d=1  hl=3 l= 129 prim: BIT STRING

I propose that the commonName field is generated to match a specific property
of the server in question. It is reasonable to set the commonName element to
match either the hostname of the relay, the detected IP address of the relay,
or for the relay operator to override certificate generation entirely by
loading a custom certificate. For custom certificates, see the Custom
Certificates section.

I propose that the value for the commonName field shall be populated with the
fully qualified host name as detected by reverse and forward resolution of the
IP address of the relay. If the host name is in the DNS, this host name should
be set as the common name. When forward and reverse DNS is not available, I
propose that the IP address alone is used.

The commonName field for the issuer should be set to known issuer names, random
words or left out entirely.

Some host names may trigger certain censorship keyword filters and so it may be
reasonable to provide an option to force certain values into the commonName
field.

Considerations for commonName normalization

Any host name supplied for the commonName field should resolve - even if it
does not resolve to the IP address of the relay. If the commonName field does
include an IP address, it should be the current IP address of the relay.

Certificate serial numbers

Currently our certificate serial numbers is set to the of number of seconds
since the epoch at creation time. I propose that we should ensure that our
serial numbers are un-related to the epoch. I propose that we use a randomly
generated number that is subsequently hashed with SHA-512 and truncated. The
serial number should be similar in bit width to commonly found certificate
serial numbers in the wild.

This randomly generated field may now serve as a covert channel that signals to
the client that the OR will not support TLS renegotiation; this means that the
client can expect to perform a V3 TLS handshake setup. Otherwise, if the serial
number is a reasonable time since the epoch, we should assume it expects
renegotiation.

As a security note, care must be taken to ensure that supporting this covert
channel will not lead to an attacker having a method to downgrade client
behavior.

Other certificate fields

It may be advantageous to also generate values for the O, L, ST, C, and OU
certificate fields. The C and ST fields may be populated from GeoIP information
that is already available to Tor. The other fields should contain some
semblance of a word or grouping of words.

Certificate dating and validity issues

TLS certificates found in the wild are generally found to be long lived or old
and often expired. The current Tor certificate validity time is a very small
time window starting at generation time and ending shortly thereafter as
defined by MAX_SSL_KEY_LIFETIME (2*60*60).

I propose that the certificate validity time length is extended to a period of
twelve Earth months possibly with a small random skew to be determined by the
implementer. Tor should randomly set the start date in the past or some
currently unspecified window of time before the current date.

The certificate values, such as expiration, should not be used for anything
relating to security.

The expiration time should not be a fixed time that is simple to calculate by
any Deep Packet Inspection device or it will become a new Tor TLS setup
fingerprint.

Custom Certificates

It should be possible for a Tor relay operator to use a specifically supplied
certificate and secret key. This will allow a relay or bridge operator to use a
certificate signed by a member of the certificate authority racket; it will
also allow for any other user supplied certificate. This may be desirable in
some kinds of filtered networks or when attempting to blend in with the TLS web
server certificate crowd.

Problematic DiffieHellman parameters

We currently send a static DiffieHellman parameter, prime p (or "prime p
outlaw") as specified in RFC2409 as part of the TLS Server Hello response.
While amusing to have the power to make specific prime numbers into a new class
of numbers (cf. imaginary, irrational, illegal) - our new friend prime p outlaw
is not required.

I propose that the function to initialize and generate DH parameters is split
into two functions.

First, init_dh_param() should be used only for OR to OR DH setup and
communication. Secondly, it it proposed that we create a new function
init_tls_dh_param() that will have a two stage development process.

The first stage init_tls_dh_param() will use the same prime that Apache2.x [0]
sends (or "dh1024_apache_p") and this change should be made immediately. This
is a known good and safe prime number that is currently not known to be
blocked.

The second stage init_tls_dh_param() should randomly generate a new hard to
outlaw or filter prime p ("evasive prime p") on a regular basis; this should be
added to the 0.2.3.x branch of Tor. This prime can be generated at setup or
execution time and probably does not need to be stored on disk. Evasive prime p
only needs to be generated by Tor relays as Tor clients will never send it. It
should absolutely not be shared between different Tor relays nor should it ever
be static after the 0.2.3.x release.

As a security precaution, care must be taken to ensure that we do not generate
weak primes or known filtered primes. Both weak and filtered primes will
undermine the TLS connection security properties. OpenSSH solves this issue
dynamically in RFC 4419 [1] and may provide a solution that works reasonably
well for Tor. More research in this area including MillerRabin primality tests
will need to be analyzed and probably added to Tor.

Practical key size

Currently we use 1024 bit RSA keys. I propose that we increase the RSA key size
to 1280 or to 2048 as an additional covert channel to signal support for the V3
handshake setup. 2048 is likely a more common certificate size and also
provides a reasonable security boost with regard to key security properties.

The implementer should choose a key size that is common and meaningfully above
1024 bits.

Possible future filtering nightmares

At some point it may cost effective or politically feasible for a network
filter to simply block all signed or unsigned certificates without a known
valid CA trust chain. This will break many applications on the internet and
hopefully, our option for custom certificates will ensure that this step is
simply avoided by the censors.  Appendix: Other issues


What other obvious TLS certificate issues exist? What other static values are
present in the Tor TLS setup?

[0] httpd-2.2.17/modules/ss/ssl_engine_dh.c
[1] http://tools.ietf.org/html/rfc4419


</body></email><email><emailId>20110126214212</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-01-26 21:42:12-0400</timestampReceived><subject>xxx-draft-spec-for-TLS-normalization.txt</subject><body>

I've re-worded and added some feedback from Tom and others to this
draft. If anyone has any further comments before this becomes a numbered
proposal - please reply on or-dev rather than privately as I'd like to
keep the thread going in the open.

All the best,
Jake

["xxx-draft-spec-for-TLS-normalization.txt" (text/plain)]

Filename: xxx-draft-spec-for-TLS-normalization.txt
Title: Draft spec for TLS certificate and handshake normalization
Author: Jacob Appelbaum
Created: 24-Jan-2011
Status: Draft


        Draft spec for TLS certificate and handshake normalization


                                    Overview

Scope

This is a document that proposes improvements to problems with Tor's
current TLS (Transport Layer Security) certificates and handshake that will
reduce the distinguishability of Tor traffic from other encrypted traffic that
uses TLS.  It also addresses some of the possible fingerprinting attacks
possible against the current Tor TLS protocol setup process.

Motivation and history

Censorship is an arms race and this is a step forward in the defense
of Tor.  This proposal outlines ideas to make it more difficult to
fingerprint and block Tor traffic.

Goals

This proposal intends to normalize or remove easy-to-predict or static
values in the Tor TLS certificates and with the Tor TLS setup process.
These values can be used as criteria for the automated classification of
encrypted traffic as Tor traffic. Network observers should not be able
to trivially detect Tor merely by receiving or observing the certificate
used or advertised by a Tor relay. I also propose the creation of
a hard-to-detect covert channel through which a server can signal that it
supports the third version ("V3") of the Tor handshake protocol.

Non-Goals

This document is not intended to solve all of the possible active or passive
Tor fingerprinting problems. This document focuses on removing distinctive
and predictable features of TLS protocol negotiation; we do not attempt to
make guarantees about resisting other kinds of fingerprinting of Tor
traffic, such as fingerprinting techniques related to timing or volume of
transmitted data.

                                Implementation details


Certificate Issues

The CN or commonName ASN1 field

Tor generates certificates with a predictable commonName field; the
field is within a given range of values that is specific to Tor.
Additionally, the generated host names have other undesirable properties.
The host names typically do not resolve in the DNS because the domain
names referred to are generated at random. Although they are syntatically
valid, they usually refer to domains that have never been registered by
any domain name registrar.

An example of the current commonName field: CN=www.s4ku5skci.net

An example of OpenSSL's asn1parse over a typical Tor certificate:

   0:d=0  hl=4 l= 438 cons: SEQUENCE
    4:d=1  hl=4 l= 287 cons: SEQUENCE
    8:d=2  hl=2 l=   3 cons: cont [ 0 ]
   10:d=3  hl=2 l=   1 prim: INTEGER           :02
   13:d=2  hl=2 l=   4 prim: INTEGER           :4D3C763A
   19:d=2  hl=2 l=  13 cons: SEQUENCE
   21:d=3  hl=2 l=   9 prim: OBJECT            :sha1WithRSAEncryption
   32:d=3  hl=2 l=   0 prim: NULL
   34:d=2  hl=2 l=  35 cons: SEQUENCE
   36:d=3  hl=2 l=  33 cons: SET
   38:d=4  hl=2 l=  31 cons: SEQUENCE
   40:d=5  hl=2 l=   3 prim: OBJECT            :commonName
   45:d=5  hl=2 l=  24 prim: PRINTABLESTRING   :www.vsbsvwu5b4soh4wg.net
   71:d=2  hl=2 l=  30 cons: SEQUENCE
   73:d=3  hl=2 l=  13 prim: UTCTIME           :110123184058Z
   88:d=3  hl=2 l=  13 prim: UTCTIME           :110123204058Z
  103:d=2  hl=2 l=  28 cons: SEQUENCE
  105:d=3  hl=2 l=  26 cons: SET
  107:d=4  hl=2 l=  24 cons: SEQUENCE
  109:d=5  hl=2 l=   3 prim: OBJECT            :commonName
  114:d=5  hl=2 l=  17 prim: PRINTABLESTRING   :www.s4ku5skci.net
  133:d=2  hl=3 l= 159 cons: SEQUENCE
  136:d=3  hl=2 l=  13 cons: SEQUENCE
  138:d=4  hl=2 l=   9 prim: OBJECT            :rsaEncryption
  149:d=4  hl=2 l=   0 prim: NULL
  151:d=3  hl=3 l= 141 prim: BIT STRING
  295:d=1  hl=2 l=  13 cons: SEQUENCE
  297:d=2  hl=2 l=   9 prim: OBJECT            :sha1WithRSAEncryption
  308:d=2  hl=2 l=   0 prim: NULL
  310:d=1  hl=3 l= 129 prim: BIT STRING

I propose that the commonName field be generated to match a specific property
of the server in question. It is reasonable to set the commonName element to
match either the hostname of the relay, the detected IP address of the relay,
or for the relay operator to override certificate generation entirely by
loading a custom certificate. For custom certificates, see the Custom
Certificates section.

I propose that the value for the commonName field be populated with the
fully qualified host name as detected by reverse and forward resolution of the
IP address of the relay. If the host name is in the DNS, this host name should
be set as the common name. When forward and reverse DNS is not available, I
propose that the IP address alone be used.

The commonName field for the issuer should be set to known issuer names,
random words or omitted entirely.

Since some host names may themselves trigger censorship keyword filters,
it may be reasonable to provide an option to override the defaults and
force certain values in the commonName field.

Considerations for commonName normalization

Any host name supplied for the commonName field should resolve - even if it
does not resolve to the IP address of the relay. If the commonName field does
include an IP address, it should be the current IP address of the relay as
seen by other Internet hosts.

Certificate serial numbers

Currently our generated certificate serial number is set to the of number of
seconds since the epoch at the time of the certificate's creation. I propose
that we should ensure that our serial numbers are un-related to the epoch,
since the generation methods are potentially recognizable as Tor-related.
Instead, I propose that we use a randomly generated number that is
subsequently hashed with SHA-512 and then truncated. The serial number
should be similar in bit width to commonly found certificate serial numbers
in the wild.

This randomly generated field may now serve as a covert channel that signals to
the client that the OR will not support TLS renegotiation; this means that the
client can expect to perform a V3 TLS handshake setup. Otherwise, if the serial
number is a reasonable time since the epoch, we should assume the OR is
using an earlier protocol version and hence that it expects renegotiation.

As a security note, care must be taken to ensure that supporting this
covert channel will not lead to an attacker having a method to downgrade client
behavior.

Other certificate fields

It may be advantageous to also generate values for the O, L, ST, C, and OU
certificate fields. The C and ST fields may be populated from GeoIP information
that is already available to Tor to reflect a plausible geographic location
for the OR. The other fields should contain some semblance of a word or
grouping of words.

Certificate dating and validity issues

TLS certificates found in the wild are generally found to be long-lived;
they are frequently old and often even expired. The current Tor certificate
validity time is a very small time window starting at generation time and
ending shortly thereafter, as defined in or.h by MAX_SSL_KEY_LIFETIME
(2*60*60).

I propose that the certificate validity time length is extended to a period of
twelve Earth months, possibly with a small random skew to be determined by the
implementer. Tor should randomly set the start date in the past or some
currently unspecified window of time before the current date. This would
more closely track the typical distribution of non-Tor TLS certificate
expiration times.

The certificate values, such as expiration, should not be used for anything
relating to security; for example, if the OR presents an expired TLS
certificate, this does not imply that the client should terminate the
connection (as would be appropriate for an ordinary TLS implementation).

The expiration time should not be a fixed time that is simple to calculate by
any Deep Packet Inspection device or it will become a new Tor TLS setup
fingerprint.

Custom Certificates

It should be possible for a Tor relay operator to use a specifically supplied
certificate and secret key. This will allow a relay or bridge operator to use a
certificate signed by any member of any geographically relevant certificate
authority racket; it will also allow for any other user-supplied certificate.
This may be desirable in some kinds of filtered networks or when attempting to
avoid attracting suspicion by blending in with the TLS web server certificate
crowd.

Problematic DiffieHellman parameters

We currently send a static DiffieHellman parameter, prime p (or "prime p
outlaw") as specified in RFC2409 as part of the TLS Server Hello response.

The use of this prime in TLS negotiations may, as a result, be filtered and
effectively banned by certain networks. We do not have to use this particular
prime in all cases.

While amusing to have the power to make specific prime numbers into a new class
of numbers (cf. imaginary, irrational, illegal [0]) - our new friend prime p
outlaw is not required.

The use of this prime in TLS negotiations may, as a result, be filtered and
effectively banned by certain networks. We do not have to use this particular
prime in all cases.

I propose that the function to initialize and generate DH parameters be
split into two functions.

First, init_dh_param() should be used only for OR-to-OR DH setup and
communication. Second, it is proposed that we create a new function
init_tls_dh_param() that will have a two-stage development process.

The first stage init_tls_dh_param() will use the same prime that
Apache2.x [1] sends (or "dh1024_apache_p"), and this change should be
made immediately. This is a known good and safe prime number (p-1 / 2
is also prime) that is currently not known to be blocked.

The second stage init_tls_dh_param() should randomly generate a new prime on a
regular basis; this is designed to make the prime difficult to outlaw or
filter.  Call this a shape-shifting or "Rakshasa" prime.  This should be added
to the 0.2.3.x branch of Tor. This prime can be generated at setup or execution
time and probably does not need to be stored on disk. Rakshasa primes only
need to be generated by Tor relays as Tor clients will never send them. Such
a prime should absolutely not be shared between different Tor relays nor
should it ever be static after the 0.2.3.x release.

As a security precaution, care must be taken to ensure that we do not generate
weak primes or known filtered primes. Both weak and filtered primes will
undermine the TLS connection security properties. OpenSSH solves this issue
dynamically in RFC 4419 [2] and may provide a solution that works reasonably
well for Tor. More research in this area including Miller-Rabin primality tests
will need to be analyzed and probably added to Tor.

Practical key size

Currently we use 1024-bit RSA keys. I propose that we increase the RSA key size
to 1280 or to 2048 as an additional channel to signal support for the V3
handshake setup. 2048 is likely a more common key size in certificates today
and also provides a reasonable security boost with regard to key security
properties.

The implementer should choose a key size that is common and meaningfully above
1024 bits.

Possible future filtering nightmares

At some point it may cost effective or politically feasible for a network
filter to simply block all signed or unsigned certificates without a known
valid CA trust chain. This will break many applications on the internet and
hopefully, our option for custom certificates will ensure that this step is
simply avoided by the censors.

The Rakshasa prime approach may cause censors to specifically allow only
certain known and accepted DH parameters.

Appendix: Other issues

What other obvious TLS certificate issues exist? What other static values are
present in the Tor TLS setup process?

[0] To be fair this is hardly a new class of numbers. History is rife with
    similar examples of inane authoritarian attempts at mathematical secrecy.
    Probably the most dramatic example is the story of the pupil Hipassus of
    Metapontum, pupil of the famous Pythagoras, who, legend goes, proved the
    fact that Root2 cannot be expressed as a fraction of whole numbers (now
    called an irrational number) and was assassinated for revealing this
    secret.  Further reading on the subject may be found on the Wikipedia:
    http://en.wikipedia.org/wiki/Hippasus

[1] httpd-2.2.17/modules/ss/ssl_engine_dh.c
[2] http://tools.ietf.org/html/rfc4419


</body></email><email><emailId>20110126221010</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2011-01-26 22:10:10-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

&gt; As a security precaution, care must be taken to ensure that we do not generate
&gt; weak primes or known filtered primes. Both weak and filtered primes will
&gt; undermine the TLS connection security properties. OpenSSH solves this issue
&gt; dynamically in RFC 4419 [2] and may provide a solution that works reasonably
&gt; well for Tor. More research in this area including Miller-Rabin primality tests
&gt; will need to be analyzed and probably added to Tor.

RFC 4419 suggests the Miller-Rabin test because it is efficient and
well-known. Perhaps Tor could use the AKS primality test, which is
also efficient, and deterministic.
</body></email><email><emailId>20110127094701</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-01-27 09:47:01-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

Jacob Appelbaum &lt;jacob@appelbaum.net&gt; writes:

&gt; I've re-worded and added some feedback from Tom and others to this
&gt; draft. If anyone has any further comments before this becomes a numbered
&gt; proposal - please reply on or-dev rather than privately as I'd like to
&gt; keep the thread going in the open.
&gt;
&gt; All the best,
&gt; Jake

As far as the certificate fields [1], the key size [2] and the
certificate time length are concerned, I'm wondering if it would be
worth it using the EFF's SSL Observatory data [3] to figure out the most
conservative values to use (and in the case of cert. fields, which
fields are actually usually used in the real world).

Mansour Moufid &lt;mansourmoufid@gmail.com&gt; writes:

&gt;&gt; As a security precaution, care must be taken to ensure that we do not generate
&gt;&gt; weak primes or known filtered primes. Both weak and filtered primes will
&gt;&gt; undermine the TLS connection security properties. OpenSSH solves this issue
&gt;&gt; dynamically in RFC 4419 [2] and may provide a solution that works reasonably
&gt;&gt; well for Tor. More research in this area including Miller-Rabin primality tests
&gt;&gt; will need to be analyzed and probably added to Tor.
&gt;
&gt;RFC 4419 suggests the Miller-Rabin test because it is efficient and
&gt;well-known. Perhaps Tor could use the AKS primality test, which is
&gt;also efficient, and deterministic.

The problem with AKS - and the reason it's not used in real life
applications - is it's terrible performance when in contrast with all
the other probabilistic primality tests [4].

[1]: Like you said, one could claim that the current Tor TLS
certificates could be fingerprinted by their empty O/L/ST/C/OU fields.

[2]: By the way, the key size upgrade (and the addition of more
ciphersuites) is also planned as part of the Tor ciphersuite migration.

[3]:
https://www.eff.org/files/downloaded-certificates.tar.lzma.torrent
https://www.eff.org/files/csv-db-files.tar.lzma.torrent

[4]: Check out "An Implementation of the AKS Primality Test" from
Robert G. Salembier and Paul Southerington, for example.
</body></email><email><emailId>20110127141203</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-01-27 14:12:03-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On 01/27/2011 03:47 AM, George Kadianakis wrote:
&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; writes:
&gt; 
&gt;&gt; I've re-worded and added some feedback from Tom and others to this
&gt;&gt; draft. If anyone has any further comments before this becomes a numbered
&gt;&gt; proposal - please reply on or-dev rather than privately as I'd like to
&gt;&gt; keep the thread going in the open.
&gt;&gt;
&gt;&gt; All the best,
&gt;&gt; Jake
&gt; 
&gt; As far as the certificate fields [1], the key size [2] and the
&gt; certificate time length are concerned, I'm wondering if it would be
&gt; worth it using the EFF's SSL Observatory data [3] to figure out the most
&gt; conservative values to use (and in the case of cert. fields, which
&gt; fields are actually usually used in the real world).

I've previously inquired with Seth (of the EFF) to see if he has any
ideas about these fields. Perhaps when he's had the time to look, he'll
reply to this thread?

&gt; 
&gt; Mansour Moufid &lt;mansourmoufid@gmail.com&gt; writes:
&gt; 
&gt;&gt;&gt; As a security precaution, care must be taken to ensure that we do not generate
&gt;&gt;&gt; weak primes or known filtered primes. Both weak and filtered primes will
&gt;&gt;&gt; undermine the TLS connection security properties. OpenSSH solves this issue
&gt;&gt;&gt; dynamically in RFC 4419 [2] and may provide a solution that works reasonably
&gt;&gt;&gt; well for Tor. More research in this area including Miller-Rabin primality tests
&gt;&gt;&gt; will need to be analyzed and probably added to Tor.
&gt;&gt;
&gt;&gt; RFC 4419 suggests the Miller-Rabin test because it is efficient and
&gt;&gt; well-known. Perhaps Tor could use the AKS primality test, which is
&gt;&gt; also efficient, and deterministic.
&gt; 
&gt; The problem with AKS - and the reason it's not used in real life
&gt; applications - is it's terrible performance when in contrast with all
&gt; the other probabilistic primality tests [4].
&gt; 

I guess that if we only generate p a single time at startup, it won't
matter too much.

&gt; [1]: Like you said, one could claim that the current Tor TLS
&gt; certificates could be fingerprinted by their empty O/L/ST/C/OU fields.
&gt; 

Yes, I'm certain that it's possible. I'm unsure about the collateral damage.

&gt; [2]: By the way, the key size upgrade (and the addition of more
&gt; ciphersuites) is also planned as part of the Tor ciphersuite migration.
&gt; 

Yes, that's part of the big picture. Doing the switch all at once seems
like a good idea.

&gt; [3]:
&gt; https://www.eff.org/files/downloaded-certificates.tar.lzma.torrent
&gt; https://www.eff.org/files/csv-db-files.tar.lzma.torrent
&gt; 

I'd like to run these queries on a live DB. I don't currently have a
machine to load these files where it won't take a century, so I'm going
to punt and see if Seth has any suggestions. If he doesn't, I'll find a
fast machine for some computing...

&gt; [4]: Check out "An Implementation of the AKS Primality Test" from
&gt; Robert G. Salembier and Paul Southerington, for example.

Thanks for the pointer and the feedback!

All the best,
Jake
</body></email><email><emailId>20110127222921</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-01-27 22:29:21-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Jan 27, 2011, at 6:12 AM, Jacob Appelbaum wrote:

&gt;&gt; https://www.eff.org/files/downloaded-certificates.tar.lzma.torrent
&gt;&gt; https://www.eff.org/files/csv-db-files.tar.lzma.torrent
&gt; 
&gt; I'd like to run these queries on a live DB. I don't currently have a
&gt; machine to load these files where it won't take a century, so I'm going
&gt; to punt and see if Seth has any suggestions. If he doesn't, I'll find a
&gt; fast machine for some computing...

Yes, we want to provide that (possibly on EC2), but it's going to be a while.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation

</body></email><email><emailId>20110130221633</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-01-30 22:16:33-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Thu, Jan 27, 2011 at 2:29 PM, Chris Palmer &lt;chris@eff.org&gt; wrote:
&gt; ...
&gt;&gt;&gt; https://www.eff.org/files/downloaded-certificates.tar.lzma.torrent
&gt;&gt;&gt; https://www.eff.org/files/csv-db-files.tar.lzma.torrent
&gt;...
&gt; Yes, we want to provide that (possibly on EC2), but it's going to be a while.


is anyone seeding or mirroring the above?  i'm not having any luck...
</body></email><email><emailId>20110130230400</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-01-30 23:04:00-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>


On Sun, 30 Jan 2011 14:16:33 -0800
coderman &lt;coderman@gmail.com&gt; wrote:

&gt; On Thu, Jan 27, 2011 at 2:29 PM, Chris Palmer &lt;chris@eff.org&gt; wrote:
&gt; &gt; ...
&gt; &gt;&gt;&gt; https://www.eff.org/files/downloaded-certificates.tar.lzma.torrent
&gt; &gt;&gt;&gt; https://www.eff.org/files/csv-db-files.tar.lzma.torrent
&gt; &gt;...
&gt; &gt; Yes, we want to provide that (possibly on EC2), but it's going to be a while.
&gt; 
&gt; 
&gt; is anyone seeding or mirroring the above?  i'm not having any luck...

I'm seeding it, and other people are, but the tracker (web4.eff.org)
seems to be down, so you'll need a client with DHT support.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110131050134</emailId><senderName>Mansour Moufid</senderName><senderEmail>mansourmoufid@gmail.com</senderEmail><timestampReceived>2011-01-31 05:01:34-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Thu, Jan 27, 2011 at 4:47 AM, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt; The problem with AKS - and the reason it's not used in real life
&gt; applications - is it's terrible performance when in contrast with all
&gt; the other probabilistic primality tests [4].

Thanks for the info, an excellent read. In that case, might as well
borrow from OpenSSH, it's all done in moduli.c. There are also some
groups in RFC 3526 that could be useful.
</body></email><email><emailId>20110131061643</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-01-31 06:16:43-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Jan 30, 2011, at 3:04 PM, Robert Ransom wrote:

&gt; I'm seeding it, and other people are, but the tracker (web4.eff.org)
&gt; seems to be down, so you'll need a client with DHT support.

I think it is up again.

Sorry about that, and sorry for invading or-dev with OT stuff. Feel free to poke me \
individually if problems recur, and you can also discuss this on our mailing list: \
https://mail1.eff.org/mailman/listinfo/observatory.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation


</body></email><email><emailId>20110131230729</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-31 23:07:29-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Thu, Jan 27, 2011 at 9:12 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
 [...]
&gt; I'd like to run these queries on a live DB. I don't currently have a
&gt; machine to load these files where it won't take a century, so I'm going
&gt; to punt and see if Seth has any suggestions. If he doesn't, I'll find a
&gt; fast machine for some computing...

Cut the files down; take a random sample of a (say) million
certificates.  This should fit easily into a one-computer DB.

Rationale: for the purpose of fingerprint normalization, we don't
actually care about answering questions like "does anybody at all do X
with their certificates?"  We care about an easier question: "can a
censor that wants to allow SSL but not Tor afford to block everybody
whose certificates look like X?"  The version of this that the SSL
observatory can answer boils down to something like "Is there a hefty
fraction of SSL certificates that look like X?"  And *this* is a
question that can get answered with a random sample.

yrs,
-- 
Nick
</body></email><email><emailId>20110201004833</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-02-01 00:48:33-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Jan 31, 2011, at 3:59 PM, Nick Mathewson wrote:

&gt; I'm not sure that an IP address is better than a random hostname.  Do
&gt; any CAs issue certs where the CN is an IP address?  Do many
&gt; self-signed certificates actually look that way?
&gt; 
&gt; If the answers are "no" and "not many", then we'll probably be better
&gt; off with randomly generated hostnames when we can't find a real
&gt; hostname to use.

The answer is "yes and yes".

valid_names is CA-validated CNs from observed certs that browsers would consider \
valid:

mysql&gt; select name from valid_names where name rlike '^([0-9]{1,3}\\.){3}[0-9]{1,3}$' \
limit 10 offset 1000; +-----------------+
&gt; name            |
+-----------------+
&gt; 213.221.122.163 |
&gt; 213.222.193.229 |
&gt; 213.23.117.165  |
&gt; 213.23.120.186  |
&gt; 213.239.192.102 |
&gt; 213.239.193.166 |
&gt; 213.239.223.66  |
&gt; 213.239.223.68  |
&gt; 213.239.223.70  |
&gt; 213.239.223.72  |
+-----------------+
10 rows in set (1.03 sec)

all_names is all names, not just names from valid certificates:

mysql&gt; select name from all_names where name rlike '^([0-9]{1,3}\\.){3}[0-9]{1,3}$' \
limit 10 offset 10000; +-------------+
&gt; name        |
+-------------+
&gt; 10.1.28.254 |
&gt; 10.1.29.4   |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
&gt; 10.1.3.1    |
+-------------+
10 rows in set (3.28 sec)

&gt; There are two certificate profiles to imitate here: self-signed and
&gt; CA-issued.  For self-signed ones, both DNs typically match, I think.
&gt; This is worth checking too

I don't know, but I suspect, that mimicking a typical self-signed cert for an Apache \
HTTPS server install will blend in well. Certainly, there are many more self-signed \
certs than CA-signed certs. It might even work just fine to set the CN to an RFC 1918 \
address, rather than going to the trouble to sign the true \
publically-visible/-routable IP. There are TON of 10.* IPs in here.

&gt; &gt; Certificate serial numbers
&gt; &gt; 
&gt; I'd want to back off here to see what certificates look like in the
&gt; wild.  Do they look random?  Do they look like timestamps?  Do they
&gt; increase sequentially?  Are they typically small for self-signed
&gt; certificates?

Here are some examples from all_certs; you can see that they are kind of wackadoodle:

mysql&gt; select `Serial Number` from all_certs limit 10 offset 10000;
+-------------------------------------------------+
&gt; Serial Number                                   |
+-------------------------------------------------+
&gt; 0a:bb:68:a0:59:18:bf:41:b9:e0:ca:77:78:1e:81:d8 |
&gt; 945343 (0xe6cbf)                               |
&gt; 2 (0x2)                                        |
&gt; 1129306560 (0x434fd9c0)                        |
&gt; c0:21:49:06:50:74:85:9e:c0:26:c0:82:38:0c:52:d9 |
&gt; 33:e4:41:16:d4:92:b0:db:cc:5f:a4:48:cd:8a:15:67 |
&gt; 04:37:f8:4c:1b:8f:91                            |
&gt; 0 (0x0)                                        |
&gt; 1171916762 (0x45da07da)                        |
&gt; 31:47:86:bf:68                                  |
+-------------------------------------------------+
10 rows in set (0.59 sec)

mysql&gt; select `Serial Number` from all_certs limit 10 offset 100;
+-------------------------------------------------+
&gt; Serial Number                                   |
+-------------------------------------------------+
&gt; 269 (0x10d)                                    |
&gt; 1 (0x1)                                        |
&gt; 23:2d:97:f0:0f:2a:44:85:e0:4c:40:7a:81:2a:bd:57 |
&gt; 1879052797 (0x700011fd)                        |
&gt; 1879051733 (0x70000dd5)                        |
&gt; 7 (0x7)                                        |
&gt; 1158643580 (0x450f7f7c)                        |
&gt; 0 (0x0)                                        |
&gt; a9:4f:56:e5:27:0a:c2:7c                         |
&gt; -1606448784 (-0x5fc07690)                      |
+-------------------------------------------------+
10 rows in set (0.01 sec)

(love that negative one)

Serial numbers for valid_certs are more uniform and random-looking:

mysql&gt; select `Serial Number` from valid_certs limit 10 offset 10000;
+-------------------------------------------------+
&gt; Serial Number                                   |
+-------------------------------------------------+
&gt; a1:ea:33:78:c4:80:ee:b1:f7:27:5a:0b:60:c7:b0:ef |
&gt; 03:fd:e4:a0:4a:8e:6f:21:e8:03:69:38:7f:66:66:5a |
&gt; 3b:b0:dd:a9:4a:db:c9:e7:c2:03:69:5c:f6:8c:ba:35 |
&gt; 6d:9f:45:41:fe:80:9a:ea:75:bb:6a:25:45:e6:ec:c7 |
&gt; a7:27:09:e9:2d:bb:ef:72:06:fc:78:b4:e5:4f:5d:31 |
&gt; 1d:c3:ea:d4:8a:96:bb:95:0c:5e:47:3a:ae:68:ce:37 |
&gt; 7c:4c:e4:45:bf:e2:96:63:0a:8e:1f:62:8d:0b:df:6f |
&gt; 2b:33:c8:dc:ff:8a:e9:a3:99:65:4d:32:1a:90:f6:97 |
&gt; 1260410972 (0x4b20585c)                        |
&gt; 04:72:74:a1:f2:a1:fc                            |
+-------------------------------------------------+
10 rows in set (0.13 sec)


&gt; &gt; Practical key size
&gt; 
&gt; Possibly; we should get data on this before we guess.  Also, as we
&gt; start to support longer sizes, we may want a way to advertise "maximum
&gt; allowed keysize" in the consensus to keep some wiseguy from making a
&gt; 16384-bit key as a DOS attack.

I suspect a serious inquiry will find that the sizes between 1024 and 2048 are much \
less common than 1024 and 2048. Here is more anecdotal entertainment for you:

mysql&gt; select RSA_Modulus_Bits from all_certs limit 10;
+------------------+
&gt; RSA_Modulus_Bits |
+------------------+
&gt; 1024             |
&gt; 2048             |
&gt; 2048             |
&gt; 1024             |
&gt; 768              |
&gt; 1024             |
&gt; 2048             |
&gt; 2048             |
&gt; 1024             |
&gt; 2048             |
+------------------+
10 rows in set (0.00 sec)

mysql&gt; select RSA_Modulus_Bits from all_certs limit 10 offset 3000;
+------------------+
&gt; RSA_Modulus_Bits |
+------------------+
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
&gt; 1024             |
+------------------+
10 rows in set (0.05 sec)

Anyway, I think a serious drive around in the database would help you guys nail down \
these practical concerns. Overall, I think this "normalize our OR certs" effort makes \
good sense.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation


</body></email><email><emailId>20110202133418</emailId><senderName>Bjarni_Rnar_Einarsson</senderName><senderEmail>bre@pagekite.net</senderEmail><timestampReceived>2011-02-02 13:34:18-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

Hi all!

(Hopefully this threads correctly, I copy-pasted the subject from the web,
as I just subscribed and had no messages to reply to.)

I wanted to chime in and mention one advantage of using a non-random,
predictable name for the certificate in the TLS handshake: leveraging TLS
name-based virtual hosting to coexist with normal TLS-web servers.

Currently, the operator of a Tor entry node has to choose between running
Tor on port 443, or running a normal HTTPS server. If you make the TLS cert
name predictable (at least the name requested in the SNI header of the
incoming request), then it becomes possible to use name-based virtual
hosting tech to allow Tor and a regular HTTPS server to coexist on the same
IP and the same port.

Software supporting this already exists: my pagekite.py front-end
proxy/tunnel already does name-based proxying of TLS traffic (it doesn't
terminate the TLS tunnel, just routes the stream to a back-end based on the
SNI data in the handshake), the only reason I can't use it unmodified to
route Tor connections is because of the random certificate names. I tried to
start a discussion about the pros and cons of using Pagekite for this on
or-talk a few weeks ago, following up on a suggestion from Linus Nordberg at
FSCONS, but didn't get many takers. :-)

Presumably the main benefit of this would be to further hiding the Tor
traffic. Not only can the entry node look like an HTTPS web server, it can
*be* a normal HTTPS web server serving live web traffic. A secondary benefit
would be making all the boxes currently serving HTTPS traffic into potential
Tor entry nodes.

-- 
Bjarni R. Einarsson
The Beanstalks Project ehf.

Making personal web-pages fly: http://pagekite.net/

[Attachment #3 (text/html)]

Hi all!&lt;br&gt;&lt;br&gt;(Hopefully this threads correctly, I copy-pasted the subject from the \
web, as I just subscribed and had no messages to reply to.)&lt;br clear="all"&gt;&lt;br&gt;I \
wanted to chime in and mention one advantage of using a non-random, predictable name \
for the certificate in the TLS handshake: leveraging TLS name-based virtual hosting \
to coexist with normal TLS-web servers.&lt;br&gt; &lt;br&gt;Currently, the operator of a Tor \
entry node has to choose between running Tor on port 443, or running a normal HTTPS \
server. If you make the TLS cert name predictable (at least the name requested in the \
SNI header of the incoming request), then it becomes possible to use name-based \
virtual hosting tech to allow Tor and a regular HTTPS server to coexist on the same \
IP and the same port.&lt;br&gt; &lt;br&gt;Software supporting this already exists: my pagekite.py \
front-end proxy/tunnel already does name-based proxying of TLS traffic (it \
doesn't terminate the TLS tunnel, just routes the stream to a back-end based on \
the SNI data in the handshake), the only reason I can't use it unmodified to \
route Tor connections is because of the random certificate names. I tried to start a \
discussion about the pros and cons of using Pagekite for this on or-talk a few weeks \
ago, following up on a suggestion from Linus Nordberg at FSCONS, but didn't get \
many takers. :-)&lt;br&gt; &lt;br&gt;Presumably the main benefit of this would be to further \
hiding the Tor traffic. Not only can the entry node look like an HTTPS web server, it \
can *be* a normal HTTPS web server serving live web traffic. A secondary benefit \
would be making all the boxes currently serving HTTPS traffic into potential Tor \
entry nodes.&lt;br&gt; &lt;br&gt;-- &lt;br&gt;Bjarni R. Einarsson&lt;br&gt;The Beanstalks Project \
ehf.&lt;br&gt;&lt;br&gt;Making personal web-pages fly: &lt;a href="http://pagekite.net/" \
target="_blank"&gt;http://pagekite.net/&lt;/a&gt;&lt;br&gt;



</body></email><email><emailId>20110202164826</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-02-02 16:48:26-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On 02/02/2011 05:34 AM, Bjarni Rnar Einarsson wrote:
&gt; Hi all!
&gt; 
&gt; (Hopefully this threads correctly, I copy-pasted the subject from the web,
&gt; as I just subscribed and had no messages to reply to.)
&gt; 
&gt; I wanted to chime in and mention one advantage of using a non-random,
&gt; predictable name for the certificate in the TLS handshake: leveraging TLS
&gt; name-based virtual hosting to coexist with normal TLS-web servers.
&gt; 
&gt; Currently, the operator of a Tor entry node has to choose between running
&gt; Tor on port 443, or running a normal HTTPS server. If you make the TLS cert
&gt; name predictable (at least the name requested in the SNI header of the
&gt; incoming request), then it becomes possible to use name-based virtual
&gt; hosting tech to allow Tor and a regular HTTPS server to coexist on the same
&gt; IP and the same port.
&gt; 
&gt; Software supporting this already exists: my pagekite.py front-end
&gt; proxy/tunnel already does name-based proxying of TLS traffic (it doesn't
&gt; terminate the TLS tunnel, just routes the stream to a back-end based on the
&gt; SNI data in the handshake), the only reason I can't use it unmodified to
&gt; route Tor connections is because of the random certificate names. I tried to
&gt; start a discussion about the pros and cons of using Pagekite for this on
&gt; or-talk a few weeks ago, following up on a suggestion from Linus Nordberg at
&gt; FSCONS, but didn't get many takers. :-)
&gt; 
&gt; Presumably the main benefit of this would be to further hiding the Tor
&gt; traffic. Not only can the entry node look like an HTTPS web server, it can
&gt; *be* a normal HTTPS web server serving live web traffic. A secondary benefit
&gt; would be making all the boxes currently serving HTTPS traffic into potential
&gt; Tor entry nodes.
&gt; 

Hi Bjarni!

Is there any reason that you can't route SSL/TLS traffic to Tor for all
non-SNI requests? Another thing that might work is knowing that all Tor
certificates currently end in .net. So while they're random, it's
certainly possible to know when someone explicitly wants to reach a
different server you certainly know about and isn't in your allowed
lookup table. Anything else can be routed to Tor.

Older clients without SNI will of course have issues and all be routed
to Tor but perhaps this can be documented - surely some people will
still use it?

All the best,
Jake
</body></email><email><emailId>20110202171809</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-02-02 17:18:09-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On 01/31/2011 04:48 PM, Chris Palmer wrote:
&gt; On Jan 31, 2011, at 3:59 PM, Nick Mathewson wrote:
&gt; 
&gt;&gt; I'm not sure that an IP address is better than a random hostname.
&gt;&gt; Do any CAs issue certs where the CN is an IP address?  Do many 
&gt;&gt; self-signed certificates actually look that way?
&gt;&gt; 
&gt;&gt; If the answers are "no" and "not many", then we'll probably be
&gt;&gt; better off with randomly generated hostnames when we can't find a
&gt;&gt; real hostname to use.
&gt; 
&gt; The answer is "yes and yes".
&gt; 
&gt; valid_names is CA-validated CNs from observed certs that browsers
&gt; would consider valid:
&gt; 
&gt; mysql&gt; select name from valid_names where name rlike
&gt; '^([0-9]{1,3}\\.){3}[0-9]{1,3}$' limit 10 offset 1000; 
&gt; +-----------------+ | name            | +-----------------+ |
&gt; 213.221.122.163 | | 213.222.193.229 | | 213.23.117.165  | |
&gt; 213.23.120.186  | | 213.239.192.102 | | 213.239.193.166 | |
&gt; 213.239.223.66  | | 213.239.223.68  | | 213.239.223.70  | |
&gt; 213.239.223.72  | +-----------------+ 10 rows in set (1.03 sec)


That's good - that seems to weight putting (current relay) IP addresses
into certificates.

&gt; 
&gt; all_names is all names, not just names from valid certificates:
&gt; 
&gt; mysql&gt; select name from all_names where name rlike
&gt; '^([0-9]{1,3}\\.){3}[0-9]{1,3}$' limit 10 offset 10000; 
&gt; +-------------+ | name        | +-------------+ | 10.1.28.254 | |
&gt; 10.1.29.4   | | 10.1.3.1    | | 10.1.3.1    | | 10.1.3.1    | |
&gt; 10.1.3.1    | | 10.1.3.1    | | 10.1.3.1    | | 10.1.3.1    | |
&gt; 10.1.3.1    | +-------------+ 10 rows in set (3.28 sec)

This also seems to suggest that any IP address we choose may be
reasonable - perhaps we can mix it up with RFC1918 and likely routed IP
addresses?

&gt; 
&gt;&gt; There are two certificate profiles to imitate here: self-signed
&gt;&gt; and CA-issued.  For self-signed ones, both DNs typically match, I
&gt;&gt; think. This is worth checking too
&gt; 
&gt; I don't know, but I suspect, that mimicking a typical self-signed
&gt; cert for an Apache HTTPS server install will blend in well.
&gt; Certainly, there are many more self-signed certs than CA-signed
&gt; certs. It might even work just fine to set the CN to an RFC 1918
&gt; address, rather than going to the trouble to sign the true
&gt; publically-visible/-routable IP. There are TON of 10.* IPs in here.
&gt; 
&gt;&gt;&gt; Certificate serial numbers
&gt;&gt;&gt; 
&gt;&gt; I'd want to back off here to see what certificates look like in
&gt;&gt; the wild.  Do they look random?  Do they look like timestamps?  Do
&gt;&gt; they increase sequentially?  Are they typically small for
&gt;&gt; self-signed certificates?
&gt; 
&gt; Here are some examples from all_certs; you can see that they are kind
&gt; of wackadoodle:
&gt; 
&gt; mysql&gt; select `Serial Number` from all_certs limit 10 offset 10000; 
&gt; +-------------------------------------------------+ | Serial Number
&gt; | +-------------------------------------------------+ |
&gt; 0a:bb:68:a0:59:18:bf:41:b9:e0:ca:77:78:1e:81:d8 | |  945343 (0xe6cbf)
&gt; | |  2 (0x2)                                        | |  1129306560
&gt; (0x434fd9c0)                        | |
&gt; c0:21:49:06:50:74:85:9e:c0:26:c0:82:38:0c:52:d9 | |
&gt; 33:e4:41:16:d4:92:b0:db:cc:5f:a4:48:cd:8a:15:67 | |
&gt; 04:37:f8:4c:1b:8f:91                            | |  0 (0x0)
&gt; | |  1171916762 (0x45da07da)                        | |
&gt; 31:47:86:bf:68                                  | 
&gt; +-------------------------------------------------+ 10 rows in set
&gt; (0.59 sec)
&gt; 
&gt; mysql&gt; select `Serial Number` from all_certs limit 10 offset 100; 
&gt; +-------------------------------------------------+ | Serial Number
&gt; | +-------------------------------------------------+ |  269 (0x10d)
&gt; | |  1 (0x1)                                        | |
&gt; 23:2d:97:f0:0f:2a:44:85:e0:4c:40:7a:81:2a:bd:57 | |  1879052797
&gt; (0x700011fd)                        | |  1879051733 (0x70000dd5)
&gt; | |  7 (0x7)                                        | |  1158643580
&gt; (0x450f7f7c)                        | |  0 (0x0)
&gt; | | a9:4f:56:e5:27:0a:c2:7c                         | |  -1606448784
&gt; (-0x5fc07690)                      | 
&gt; +-------------------------------------------------+ 10 rows in set
&gt; (0.01 sec)
&gt; 
&gt; (love that negative one)

That's wacky (the negative one) but not too unexpected.

&gt; 
&gt; Serial numbers for valid_certs are more uniform and random-looking:
&gt; 
&gt; mysql&gt; select `Serial Number` from valid_certs limit 10 offset
&gt; 10000; +-------------------------------------------------+ | Serial
&gt; Number                                   | 
&gt; +-------------------------------------------------+ |
&gt; a1:ea:33:78:c4:80:ee:b1:f7:27:5a:0b:60:c7:b0:ef | |
&gt; 03:fd:e4:a0:4a:8e:6f:21:e8:03:69:38:7f:66:66:5a | |
&gt; 3b:b0:dd:a9:4a:db:c9:e7:c2:03:69:5c:f6:8c:ba:35 | |
&gt; 6d:9f:45:41:fe:80:9a:ea:75:bb:6a:25:45:e6:ec:c7 | |
&gt; a7:27:09:e9:2d:bb:ef:72:06:fc:78:b4:e5:4f:5d:31 | |
&gt; 1d:c3:ea:d4:8a:96:bb:95:0c:5e:47:3a:ae:68:ce:37 | |
&gt; 7c:4c:e4:45:bf:e2:96:63:0a:8e:1f:62:8d:0b:df:6f | |
&gt; 2b:33:c8:dc:ff:8a:e9:a3:99:65:4d:32:1a:90:f6:97 | |  1260410972
&gt; (0x4b20585c)                        | | 04:72:74:a1:f2:a1:fc
&gt; | +-------------------------------------------------+ 10 rows in set
&gt; (0.13 sec)

That's likely because some CAs but not all CAs will insert random data
into the serial number field as a method of injecting entropy into
issued certificates. Can you dump the CA names with those?

&gt; 
&gt; 
&gt;&gt;&gt; Practical key size
&gt;&gt; 
&gt;&gt; Possibly; we should get data on this before we guess.  Also, as we 
&gt;&gt; start to support longer sizes, we may want a way to advertise
&gt;&gt; "maximum allowed keysize" in the consensus to keep some wiseguy
&gt;&gt; from making a 16384-bit key as a DOS attack.
&gt; 
&gt; I suspect a serious inquiry will find that the sizes between 1024 and
&gt; 2048 are much less common than 1024 and 2048. Here is more anecdotal
&gt; entertainment for you:
&gt; 
&gt; mysql&gt; select RSA_Modulus_Bits from all_certs limit 10; 
&gt; +------------------+ | RSA_Modulus_Bits | +------------------+ | 1024
&gt; | | 2048             | | 2048             | | 1024             | |
&gt; 768              | | 1024             | | 2048             | | 2048
&gt; | | 1024             | | 2048             | +------------------+ 10
&gt; rows in set (0.00 sec)
&gt; 
&gt; mysql&gt; select RSA_Modulus_Bits from all_certs limit 10 offset 3000; 
&gt; +------------------+ | RSA_Modulus_Bits | +------------------+ | 1024
&gt; | | 1024             | | 1024             | | 1024             | |
&gt; 1024             | | 1024             | | 1024             | | 1024
&gt; | | 1024             | | 1024             | +------------------+ 10
&gt; rows in set (0.05 sec)
&gt; 

It does seem that 1024 bit certs are the most popular and 2048 is likely
the next reasonable jump.

&gt; Anyway, I think a serious drive around in the database would help you
&gt; guys nail down these practical concerns. Overall, I think this
&gt; "normalize our OR certs" effort makes good sense.
&gt; 
&gt; 

Awesome. Thanks for your input Chris!

All the best,
Jake
</body></email><email><emailId>20110202205153</emailId><senderName>Bjarni_Rnar_Einarsson</senderName><senderEmail>bre@pagekite.net</senderEmail><timestampReceived>2011-02-02 20:51:53-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

2011/2/2 Jacob Appelbaum &lt;jacob@appelbaum.net&gt;

&gt; Hi Bjarni!
&gt;
&gt; Is there any reason that you can't route SSL/TLS traffic to Tor for all
&gt; non-SNI requests? Another thing that might work is knowing that all Tor
&gt; certificates currently end in .net. So while they're random, it's
&gt; certainly possible to know when someone explicitly wants to reach a
&gt; different server you certainly know about and isn't in your allowed
&gt; lookup table. Anything else can be routed to Tor.
&gt;

This would work, but the "default fallback" is somewhat of a coveted
position as there are lots of web browsers out there that don't send SNI. So
in a shared environment you want to define your "favorite" web-site as the
default fall-back, not Tor.

I suppose I could add a feature to Pagekite where the default is different
for requests with SNI from requests without... best add that to the list, I
guess. :-)

I was also approaching this from the POV of a service provider, offering
front-ends to a large number of random people. Most of them would be running
websites, but if some wanted to contribute to Tor via my service, I would
like to let them. But without a SNI name I can use to choose between them,
that doesn't really work, as picking a random tor backend would probably
break the path decision logic in Tor if I understand things correctly.

Older clients without SNI will of course have issues and all be routed
&gt; to Tor but perhaps this can be documented - surely some people will
&gt; still use it?
&gt;

Hopefully!

-- 
Bjarni R. Einarsson
The Beanstalks Project ehf.

Making personal web-pages fly: http://pagekite.net/

[Attachment #3 (text/html)]

2011/2/2 Jacob Appelbaum &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:jacob@appelbaum.net"&gt;jacob@appelbaum.net&lt;/a&gt;&gt;&lt;/span&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; &lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div \
class="h5"&gt;Hi Bjarni!&lt;br&gt;&lt;/div&gt;&lt;/div&gt; &lt;br&gt;
Is there any reason that you can't route SSL/TLS traffic to Tor for all&lt;br&gt;
non-SNI requests? Another thing that might work is knowing that all Tor&lt;br&gt;
certificates currently end in .net. So while they're random, it's&lt;br&gt;
certainly possible to know when someone explicitly wants to reach a&lt;br&gt;
different server you certainly know about and isn't in your allowed&lt;br&gt;
lookup table. Anything else can be routed to Tor.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;This would \
work, but the "default fallback" is somewhat of a coveted position as there \
are lots of web browsers out there that don't send SNI. So in a shared \
environment you want to define your "favorite" web-site as the default \
fall-back, not Tor.&lt;br&gt; &lt;br&gt;I suppose I could add a feature to Pagekite where the \
default is different for requests with SNI from requests without... best add that to \
the list, I guess. :-)&lt;br&gt;&lt;br&gt;I was also approaching this from the POV of a service \
provider, offering front-ends to a large number of random people. Most of them would \
be running websites, but if some wanted to contribute to Tor via my service, I would \
like to let them. But without a SNI name I can use to choose between them, that \
doesn't really work, as picking a random tor backend would probably break the \
path decision logic in Tor if I understand things correctly.&lt;br&gt; \
&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin: 0pt 0pt 0pt 0.8ex; \
border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;"&gt; Older clients without \
SNI will of course have issues and all be routed&lt;br&gt; to Tor but perhaps this can be \
documented - surely some people will&lt;br&gt; still use \
it?&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;Hopefully!&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;-- &lt;br&gt;Bjarni R. \
Einarsson&lt;br&gt;The Beanstalks Project ehf.&lt;br&gt;&lt;br&gt;Making personal web-pages fly: &lt;a \
href="http://pagekite.net/" target="_blank"&gt;http://pagekite.net/&lt;/a&gt;&lt;br&gt;



</body></email><email><emailId>20110203183249</emailId><senderName>Chris Palmer</senderName><senderEmail>chris@eff.org</senderEmail><timestampReceived>2011-02-03 18:32:49-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Feb 2, 2011, at 9:18 AM, Jacob Appelbaum wrote:

&gt; That's likely because some CAs but not all CAs will insert random data
&gt; into the serial number field as a method of injecting entropy into
&gt; issued certificates. Can you dump the CA names with those?

No, almost all the valid_certs are like this, so it would be a huge list. Also, even \
if the CA just hashes a timestamp, it will "look" random in my query results.


-- 
Chris Palmer
Technology Director, Electronic Frontier Foundation


</body></email><email><emailId>20110211193226</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-11 19:32:26-0400</timestampReceived><subject>Re: Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Fri, Feb 11, 2011 at 1:40 AM, Jacob Appelbaum &lt;jacob@appelbaum.net&gt; wrote:
&gt;
&gt;
&gt; -------- Original Message --------
&gt; Subject: Re: xxx-draft-spec-for-TLS-normalization.txt
&gt; Date: Mon, 31 Jan 2011 23:33:25 +1300
&gt; From: Peter Gutmann &lt;pgut001@cs.auckland.ac.nz&gt;
&gt; To: jacob@appelbaum.net,, or-dev@seul.org

Hi, Peter, and thanks for having a look at this!

&gt; [Not sure if I can post into the list, but I'll give it a go...]

Looks like your address wasn't subscribed to the list.  Roger just
added it to the list of addresses that are allowed to post.

&gt; Jacob Appelbaum &lt;jacob@appelbaum.net&gt; writes:
&gt;
&gt;&gt;This is a document that proposes improvements to problems with Tor's current
&gt;&gt;TLS (Transport Layer Security) certificates and handshake that will reduce the
&gt;&gt;distinguishability of Tor traffic from other encrypted traffic that uses TLS.
&gt;&gt;It also addresses some of the possible fingerprinting attacks possible against
&gt;&gt;the current Tor TLS protocol setup process.
&gt;
&gt; In this case why not make the Tor certs as close as possible to generic
&gt; OpenSSL ones?  In other words do a scan of HOWTOs and whatnot and use
&gt; that as
&gt; a ruleset to create a cert, making them indistinguishable from a zillion
&gt; other
&gt; certs flying around that someone threw together on an as-needed basis.

I think that's a fine idea.  We'd want to mine the EFF "SSL
observatory" data to see which HOWTO approaches have significant
adoption.

&gt;&gt;We currently send a static Diffie??Hellman parameter, prime p (or ??prime p
&gt;&gt;outlaw??) as specified in RFC2409 as part of the TLS Server Hello response.
&gt;
&gt; These are the universal-standard primes, I'd stick with these in order to
&gt; blend in with the crowd.

Preliminary results suggest that there wasn't actually a crowd here:
the reason that we switched the browser DH paramaters in the most
recent releases is that the old (standard!) primes were in fact
blocked by at least one nation-level censor because we used them.  It
seems that in practice, if we want to blend with a crowd, we need to
use the hardwired DH parameters from mod_ssl.

[...]
&gt; As a general comment, if you're worried about filtering/fingerprinting I'd
&gt; make the traffic as close as possible to OpenSSL, since half the SSL apps on
&gt; the net end up using this and Tor would get lost in the noise.
&gt;
&gt; (Note, having implemented both SSH and SSL and interop-tested it against God
&gt; knows what sort of implementations, you can pretty much always
&gt; fingerprint SSH
&gt; due to its incredible complexity and implementation bugs ("oh, it's
&gt; doing X in
&gt; packet Y, that's version 123 of XYZ") and probably fingerprint SSL in a
&gt; large
&gt; number of cases, so there's a limit to how far you can take this).

Right.  Once challenge is "openssl as configured by whom for what?"  I
think that just going with a default OpenSSL profile to begin with
will be fine for some while, though.

cheers,
-- 
Nick

</body></email><email><emailId>20110221183618</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-02-21 18:36:18-0400</timestampReceived><subject>Re: [tor-dev] xxx-draft-spec-for-TLS-normalization.txt</subject><body>

Aha.  Let's see if I have the tor-dev address right at long long last.
 Apologies to Peter, who will have received more than one copy of this
already.

(Apparently , I am told, the "lists." in tor-dev@lists.torproject.org
is not optional.)

On Mon, Feb 21, 2011 at 12:52 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; On Sun, Feb 20, 2011 at 10:49 PM, Peter Gutmann
&gt; &lt;pgut001@cs.auckland.ac.nz&gt; wrote:
&gt;&gt; Nick Mathewson &lt;nickm@freehaven.net&gt; writes:
&gt;&gt;
&gt;&gt;&gt;Preliminary results suggest that there wasn't actually a crowd here: the
&gt;&gt;&gt;reason that we switched the browser DH paramaters in the most recent releases
&gt;&gt;&gt;is that the old (standard!) primes were in fact blocked by at least one
&gt;&gt;&gt;nation-level censor because we used them.  It seems that in practice, if we
&gt;&gt;&gt;want to blend with a crowd, we need to use the hardwired DH parameters from
&gt;&gt;&gt;mod_ssl.
&gt;&gt;
&gt;&gt; So the SSL handshake was blocked if you used the Oakley (RFC 2412) DH values?
&gt;
&gt; Just the 1024-bit one, I would guess (the one in section E.2 of
&gt; RFC2412, a.k.a. the one from RFC2409 section 6.2, a.k.a Second Oakley
&gt; Group).  Or to be precise, we used to use that group, and then we were
&gt; blocked, and when we changed to a different group, we weren't.  It
&gt; might be that they were blocking based on more than one factor, only
&gt; one of which was the use of the prime in a TLS ephemeral DH handshake.
&gt;
&gt;&gt; Is there a server in said location for which access gets blocked that I could
&gt;&gt; test against?  I'd love to try some variations on SSL handshakes to see what
&gt;&gt; gets blocked and what doesn't.
&gt;
&gt; The use in question was a client in the country trying to connect to a
&gt; server outside the country, and the server providing this DH parameter
&gt; value.  I'll ask our contacts if they can get you shell access there.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110221185439</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-02-21 18:54:39-0400</timestampReceived><subject>Re: [tor-dev] xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Mon, Feb 21, 2011 at 1:36 PM, Nick Mathewson &lt;nickm@freehaven.net&gt; wrote:
&gt; Aha.  Let's see if I have the tor-dev address right at long long last.
&gt;  Apologies to Peter, who will have received more than one copy of this
&gt; already.

I did a quick scan of a subset of the EFF Observatory data (where
`subset' is defined as: I hit Ctrl-C after letting tar run for a
while).

Selecting only self-signed certs and sorting by Organization, here are
the counts:

    &lt;snip&gt;
    691 Internet Widgits Pty Ltd
    757 NetKlass Techonoloy Inc
    825 Apache Friends
    882 HTTPS Management Certificate for SonicWALL (self-signed)
    952 Cisco-Linksys, LLC
   1141 DrayTek Corp.
   1933 Xtera Communications, Taiwan
   6803 SomeOrganization
  10253 Hewlett-Packard Co.
  11811 Fortinet Ltd.

(from 52341 total self-signed certs)

"Internet Widgits Pty Ltd" is the OpenSSL default. "Hewlett-Packard
Co." are JetDirect printers. "Fortinet Ltd." is some gateway
manufacturer.

Tor doesn't have to pick a single type I believe. It could pick
between some number of templates at first-run (although Forinet tend
to be 2048-bit and HP are 1024-bit). Here are examples of the HP and
Fortinet certs:

Fortinet:

-----BEGIN CERTIFICATE-----
MIIC4jCCAcqgAwIBAgIEllaMYTANBgkqhkiG9w0BAQUFADAzMRkwFwYDVQQDExBG
RzEwMEMzRzA5NjAwMzM3MRYwFAYDVQQKEw1Gb3J0aW5ldCBMdGQuMB4XDTA5MDEy
MTIyNTYwM1oXDTE5MDEyMjIyNTYwM1owMzEZMBcGA1UEAxMQRkcxMDBDM0cwOTYw
MDMzNzEWMBQGA1UEChMNRm9ydGluZXQgTHRkLjCCASIwDQYJKoZIhvcNAQEBBQAD
ggEPADCCAQoCggEBAM4qbL3qGi71AZBUB1mTkhFO03qP7Z7b7dXrT1fhw8QXknlA
UtAGWBs5ZPWB39OKpyJoRK4+HG8D4fJ0kuwiTnpP/3WBe+manK5S13wCKgME05aV
q5gRgWw/R5/1xyXF9a9YvuR3fJZvODtlR9MKjAa44YGHZguaPEucBKw8BtA7wCYc
d8rVh8hNBH67QVSLLCm48lytrnmccjshNxo5eI8x3ESxc0Am7+8vrNkNsttsUMG+
D8knI0rJqf9JCaogtfv1lKzYF0I1EOpTsT+lwyS9g5yPAZ2qGGFeLt3C9aoGiXUS
iX7tn3krpVn5/eM7gpG0VpY/4AnlUyvPevHRuqcCAwEAATANBgkqhkiG9w0BAQUF
AAOCAQEAGT6/jxUOEWJ1YCliKZtdhY9K1/uz8da9FYrlmhFdPPIwnUh8sgtC4bSP
bifq1hQIDPXTcJ6PirYc85EhaH/JiI5inAIUUQTJk8Cu13j+/DtxiiprOVa4iu73
VY2x0qFaxGfK0wOOFnbvqodibUmSKoCxKnowwqcPC8ZpSAojtLibGv1OcIHzoWSA
WrmMGFxyilPb4nsuvFDcgjK6OlccI+sy0vLTzkOrRXq+hyCu05NCai99mnD1tWwG
TBKXqKYTpQI+kuZ5HyUfzzOV47DyZ71BI3zqCxN0DEMWW4Mu/lw97rNY7iiiuZcC
Qp5iGquemw/lF1FaAKRQEXS351SS8w==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIC4jCCAcqgAwIBAgIEaAxnSjANBgkqhkiG9w0BAQUFADAzMRkwFwYDVQQDExBG
RzMwMEIzOTA5NjAzMDA1MRYwFAYDVQQKEw1Gb3J0aW5ldCBMdGQuMB4XDTEwMDMy
NDIxMzYyNFoXDTIwMDMyNDIxMzYyNFowMzEZMBcGA1UEAxMQRkczMDBCMzkwOTYw
MzAwNTEWMBQGA1UEChMNRm9ydGluZXQgTHRkLjCCASIwDQYJKoZIhvcNAQEBBQAD
ggEPADCCAQoCggEBAKRnRUhLqL6DVQCcyao97X+l+7ntSaoU41ngK3tEIWgmlIdV
rQ7kDyxkH0xPt7C/D6FEEfV3PNGs0QBgVa9Hp5jLKtJBKCgYvlFzaR0/tQcw+g+s
j5yl6EoXDVtNdcR/Nfe4GaXSf9NKMMTskeHC71STak1l5wdB40Wjxm+YYR9/aQjB
mypm7nzq+G+keOOmsOvJFlhFpvHaTwymdqyodeXrSS+t1Day07RfgLhPzvVXdm74
87XF+349foaxfVHdHVvsnM9JmJqwIoZFFvIp3Eo5K5xJllCL+x6yUJp8WdASflq7
qUnu1EQpw7J3Q65fzshr6pp3W5Ii7Vu6ScwOmvECAwEAATANBgkqhkiG9w0BAQUF
AAOCAQEAk5tgoqJ0uUCdqn6bvzB/qClkCk+uWLg+SSJnPEAsM4WMfmmcdnuGSObl
co4bcPSCNCsT2DYP69lMAuK3BfgFv45tfklOuFDzxvN3zr2S6NE+SG1jgpdQleov
J5UQB8qJx0neKlXZBSlTDk/xbWhs9gUaY+DT+tS0aEmTvLha8/da/BzDMIlC1FCc
igZu0oQ2nUnZrfKHvt+XimJW/5jJFXRgUN1KYPtJTRGrPm8pqb87aJvnPeEYPmt8
Wmo1pkLY8NPtn7uS8GN/8REQ2Wu0mc22mqGbifHBJgvwRNagPFId8E6D6bhsz7b+
2YSmWPbgbCO0sll9OK3XAInkn7D0cw==
-----END CERTIFICATE-----

HP:

-----BEGIN CERTIFICATE-----
MIICYzCCAcygAwIBAgIBAjANBgkqhkiG9w0BAQQFADBmMR4wHAYDVQQDExVIUCBK
ZXRkaXJlY3QgMEFFQ0MwNjcxHDAaBgNVBAoTE0hld2xldHQtUGFja2FyZCBDby4x
FTATBgNVBAsTDDAwMTEwQUVDQzA2NzEPMA0GA1UECxMGSjc5MzRHMB4XDTA2MDQw
MTAwMDAwMFoXDTExMDQwMTAwMDAwMFowZjEeMBwGA1UEAxMVSFAgSmV0ZGlyZWN0
IDBBRUNDMDY3MRwwGgYDVQQKExNIZXdsZXR0LVBhY2thcmQgQ28uMRUwEwYDVQQL
EwwwMDExMEFFQ0MwNjcxDzANBgNVBAsTBko3OTM0RzCBnzANBgkqhkiG9w0BAQEF
AAOBjQAwgYkCgYEAvEP7Lbw4+vQTXzNFZYlJhwuSXDLir8UapfVFXYWhrqNQw4kO
VUFhI5DIhY5AFIQA3oXKqMmIzUQALugkYhCd9Wt+CGrR0uocx0Ea++5K9mnsvJPQ
JFzketi/Ow8pEA5X18VhlIflwQ/GhezG/a9IA/DjeLs0lIUy9iaoR6hsZ7MCAwEA
AaMhMB8wHQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMA0GCSqGSIb3DQEB
BAUAA4GBAANeDCx2M7ToEIf/Pt/EKFtZ+9nLb7byaqXzOv35hFum9ZqhWtBwa/yD
+YQU33nakbM0UXsTQ8S3r8ojMNbmQMZMqqXg7M4Vh8bCPem9rWm33oKvBxYeQk9A
ZTbWY3M+9TDV1OYim2BCKr6XkTjV8S65vNtpW+r5+znYcCnPCwlt
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIICYzCCAcygAwIBAgIBAjANBgkqhkiG9w0BAQQFADBmMR4wHAYDVQQDExVIUCBK
ZXRkaXJlY3QgMzg4RUMyOTgxHDAaBgNVBAoTE0hld2xldHQtUGFja2FyZCBDby4x
FTATBgNVBAsTDDAwMTQzODhFQzI5ODEPMA0GA1UECxMGSjc5NDlFMB4XDTA1MTEw
MTAwMDAwMFoXDTEwMTEwMTAwMDAwMFowZjEeMBwGA1UEAxMVSFAgSmV0ZGlyZWN0
IDM4OEVDMjk4MRwwGgYDVQQKExNIZXdsZXR0LVBhY2thcmQgQ28uMRUwEwYDVQQL
EwwwMDE0Mzg4RUMyOTgxDzANBgNVBAsTBko3OTQ5RTCBnzANBgkqhkiG9w0BAQEF
AAOBjQAwgYkCgYEAxwIexEqFIClHQTjSELGOg5K5BvKVGbTYx8SHKL1TE5Wp9OSi
geca3Nac4lURC+WEMZUIn8mo+EZ20w/NgsTx6igTSrK8kPQ9sjboKh3sCTHQORbw
2Tv8sNnrOp92IWRVeZl3p+zJ+c1XvKXFPPyL59d6o+SWPkb/2RP9X5SUOwkCAwEA
AaMhMB8wHQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMA0GCSqGSIb3DQEB
BAUAA4GBAGoaU8ZXqzke+qfb3yYpfY68V0wVTeqiJApLRnQZ/YBfdvpapqr5mfus
AoWTWDsqL0yQPAUaD7KngYhIO2FPNWV9Wy8gC8TtX6Zkr3s/4OiBXMBdwxVZ/Rab
J2JGtyI2s0zILEXcwtQq1fM86Z4RCAOpz2EuIBbzmxcdLfsqGW0I
-----END CERTIFICATE-----


-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110221193431</emailId><senderName>Tim Wilde</senderName><senderEmail>twilde@cymru.com</senderEmail><timestampReceived>2011-02-21 19:34:31-0400</timestampReceived><subject>Re: [tor-dev] xxx-draft-spec-for-TLS-normalization.txt</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 2/21/2011 1:54 PM, Adam Langley wrote:
&gt; "Internet Widgits Pty Ltd" is the OpenSSL default. "Hewlett-Packard
&gt; Co." are JetDirect printers. "Fortinet Ltd." is some gateway
&gt; manufacturer.
&gt; 
&gt; Tor doesn't have to pick a single type I believe. It could pick
&gt; between some number of templates at first-run (although Forinet tend
&gt; to be 2048-bit and HP are 1024-bit).

Any time we define a single list of cert templates like this and choose
from among them, we're creating an easy set of items which can be
blocked.  As I mentioned in my earlier posting today [1], I strongly
doubt that an oppressive regime's censors are going to care if they
block JetDirect printers or home routers as collateral damage when
blocking Tor.  Even if they do, what does this actually gain us over
randomized organization names chosen from a large wordlist (or even
total gibberish)?

Any static list is going to, by definition, have to exist within the
source code, and thus will be very easy for an even moderately
determined censor to find.  If we're going to do that we had better be
doing it with something that we know will cause massive collateral
damage and thus would be much more likely to be avoided; I just don't
see that happening with any of these devices.

Regards,
Tim

[1] https://lists.torproject.org/pipermail/tor-dev/2011-February/000005.html

- -- 
Tim Wilde, Senior Software Engineer, Team Cymru, Inc.
twilde@cymru.com | +1-630-230-5433 | http://www.team-cymru.org/
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAk1ivkcACgkQluRbRini9tganQCeOTZ71jkAW42IVZ1G8H1KXN9U
3CUAniaXAA3wg7yHSjSBWvfqdIlntMa/
=144p
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20110221205403</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-02-21 20:54:03-0400</timestampReceived><subject>Re: [tor-dev] xxx-draft-spec-for-TLS-normalization.txt</subject><body>

On Mon, Feb 21, 2011 at 2:34 PM, Tim Wilde &lt;twilde@cymru.com&gt; wrote:
&gt; Any static list is going to, by definition, have to exist within the
&gt; source code, and thus will be very easy for an even moderately
&gt; determined censor to find.   If we're going to do that we had better be
&gt; doing it with something that we know will cause massive collateral
&gt; damage and thus would be much more likely to be avoided; I just don't
&gt; see that happening with any of these devices.

I agree that forcing collateral damage is the key here. The current
code generates `random' certificates, but it's pretty easy to pattern
match them and there's no collateral damage to doing so.

The hope was that something would be an obvious candidate. I've seen
the Internet Widgets certificate a fair bit in personal experience,
but it appears much less frequently than I expected.

If the random generation could be made much better then it's a
reasonable answer, at the cost of more code complexity and no
collateral damage. I suspect that the cat and mouse game only stops
when the collateral damage is too large, or all self-signed certs are
blocked.


AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20110125093706</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-01-25 09:37:06-0400</timestampReceived><subject>Re: Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

&gt; Looks like I did not send this (rather old email) to the mailing list as
&gt; intended. Since the discussion how far back an OS should be supported
&gt; appears to remain live and well, here ya go:

I'm pretty much with Lucky on this one. Sure, off in some poor
repressed and constantly raided dark corner, there are going to be
those using antiques. Yet something tells me that there are always
internal communication channels and the important info will make
it up to couriers that are current. The world is growing up fast.

I'd feel pretty comfy in saying that as long as someone can plug
into the net, they're going to be doing it with something, as Lucky
says, no more than a major or two back, and current in that branch.
Not to mention simply being connected enables, umm, free major
release upgrades.

Given that, I think it's far better for projects to forge ahead
than be bogged down in the past. Especially ones that don't
speak directly to long lived hardware. ie: apps, not OS's.

Similar to the corporate quagmire example, take a look at OpenBSD.
Their release process and maintenance policy is ridiculously simple.
There's no way they could do what they do with such a small team
if they had to maintain a half dozen branches.

Which by the way, FreeBSD does do, largely out of some perceived
need to be excessively corporate friendly, and IMO it's hobbling
them a good bit.

I think XP SP3, vista and 7 is perfectly reasonable. Put the time
saved into other things.

Besides, XP is 10 years old. And by the time MS drops it, I'd bet
more of the world will making the decision to drop MS for open
systems.
</body></email><email><emailId>20110125100007</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2011-01-25 10:00:07-0400</timestampReceived><subject>Re: Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

&gt; I'm pretty much with Lucky on this one. Sure, off in some poor

Another thing that never quite made sense is packaging,
especially under open systems... GNU/Linux, *BSD.
Porting the source tarball itself to the current release
branch and maybe a rev or two back I can understand.

But being beholden to building, packaging and releasing
binaries, and playing the distro of the year quirk game
has baffled me. That's the job of the distros, and most
apps exist in their package systems anyways. If they're
not current enough, the users should be using the same
brains they used to install, learn and operate their
open OS to untar, make, make install the conveniently
ported source tarball.

I do like the embedded/smartphone ideas and of choosing
one open OS to make a cd/memory stick. So long as they're
all current majors of course.

Tis all.
</body></email><email><emailId>20110119192417</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-19 19:24:17-0400</timestampReceived><subject>Re: Proposal: Token Bucket</subject><body>

2011/1/3 Florian Tschorsch &lt;tschorsch@cs.uni-duesseldorf.de&gt;:
 [...]
&gt;  First, we observe that the token bucket for the relayed traffic on the
&gt;  outgoing connections is unnecessary: since no new such traffic is generated
&gt;  in an onion router, the rate of this traffic is already limited by the read
&gt;  bucket on the incoming side (cp. RelayedTokenBucket).

This is not strictly true, I think.  Outbound cells with no
corresponding incoming can be generated by local directory requests,
by local bandwidth testing, and probably a couple of other things too.

Also, when traffic arrives slowly on an edge connection, packaging it
into cells adds significant overhead (since every outgoing cell is 512
bytes+TLS overhead but not every outgoing cell is full).

&gt;  We therefore propose
&gt;  to remove the rate limiting mechanism on the outgoing side. This will
&gt;  eliminate the "double door effect" discussed above, since all cells are
&gt;  allowed to flow freely out of the router once they passed the incoming rate
&gt;  limiter.
&gt;
&gt;  Second, the refill interval of the buckets should be shortened. The
&gt;  remaining token buckets should be refilled more often, with a
&gt;  correspondingly smaller amount of tokens. For instance, the buckets might
&gt;  be refilled every 10 milliseconds with one-hundredth of the amount of data
&gt;  admissible per second.

Smaller bucket refill intervals are already implemented in Tor master
if you build with Libevent 2.0 and use the buffervents backend by
passing --enable-bufferevents to configure.  The refill interval is
currently set to 1/3 of a second, but that value was chosen more or
less at random; it would be neat to see other values benchmarked as
well.

yrs,
-- 
Nick

</body></email><email><emailId>20110119221430</emailId><senderName>Bjrn Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2011-01-19 22:14:30-0400</timestampReceived><subject>Re: Proposal: Token Bucket</subject><body>

Dear Nick,

thanks a lot for the feedback.

On Mi, 2011-01-19 at 14:24 -0500, Nick Mathewson wrote:
&gt; 2011/1/3 Florian Tschorsch &lt;tschorsch@cs.uni-duesseldorf.de&gt;:
&gt;  [...]
&gt; &gt;  First, we observe that the token bucket for the relayed traffic on the
&gt; &gt;  outgoing connections is unnecessary: since no new such traffic is generated
&gt; &gt;  in an onion router, the rate of this traffic is already limited by the read
&gt; &gt;  bucket on the incoming side (cp. RelayedTokenBucket).
&gt; 
&gt; This is not strictly true, I think.  Outbound cells with no
&gt; corresponding incoming can be generated by local directory requests,
&gt; by local bandwidth testing, and probably a couple of other things too.

In the strict sense, you are of course right. However, the amount of
traffic caused by these functions is likely to be negligibly small (if I
remember that correctly, someone [Karsten Loesing?] investigated the
amount of directory traffic in some other context, and found that it
*is* negligible).

If incoming and outgoing bandwidth limits are equal, an increase in the
volume of traffic within the onion router, in fact, even constitutes an
even stronger argument for our proposed modifications: if you have a
system (here: the queues in the onion router) where you continuously
admit more data into the system (incoming bandwidth limit + additional
overhead and traffic) than you allow to leave the system (outgoing
bandwidth limit), you will necessarily build up longer and longer queues
within the system, which will in turn cause very long cell delays -
which is just what we currently observe in Tor. Therefore, limiting the
amount of traffic on both ends is simply not a good idea.

I really believe that this is a major issue which significantly (and
unnecessarily) limits the performance. Florian and I will be happy to
contribute a patch if everyone agrees.

&gt; Also, when traffic arrives slowly on an edge connection, packaging it
&gt; into cells adds significant overhead (since every outgoing cell is 512
&gt; bytes+TLS overhead but not every outgoing cell is full).

One may of course argue that the (admittely in extreme cases
significant) packaging overhead should be accounted for when Tor
enforces the configured bandwidth limits. However, to be consistent, one
would then also have to account for TLS, TCP, and IP header overhead,
which is currently neglected. This overhead will also be very
significant if traffic arrives *that* slowly, i.e., if you have TCP
segments far smaller than a cell size.

This will certainly be interesting to assess in more detail. In case it
actually turns out to be an issue, I see two options:

i) the pragmatic solution: based on a measurement study how much the
traffic typically "grows" due to packaging overhead etc., reduce the
configured bandwidth limit by an appropriate percentage

ii) an "observe+adjust" mechanism: observe how much traffic is actually
leaving the router; if the outgoing traffic exceeds the configured
limit, reduce the rate at which data is read on the incoming side
accordingly

The latter, if done right, would be able to guarantee that configured
bandwidth limits are strictly enforced, despite additional traffic being
generated in the router, and in even in case of an arbitrarily high
packaging overhead. However, my feeling is that this is a too complex
solution for a very simple problem.

&gt; &gt;  We therefore propose
&gt; &gt;  to remove the rate limiting mechanism on the outgoing side. This will
&gt; &gt;  eliminate the "double door effect" discussed above, since all cells are
&gt; &gt;  allowed to flow freely out of the router once they passed the incoming rate
&gt; &gt;  limiter.
&gt; &gt;
&gt; &gt;  Second, the refill interval of the buckets should be shortened. The
&gt; &gt;  remaining token buckets should be refilled more often, with a
&gt; &gt;  correspondingly smaller amount of tokens. For instance, the buckets might
&gt; &gt;  be refilled every 10 milliseconds with one-hundredth of the amount of data
&gt; &gt;  admissible per second.
&gt; 
&gt; Smaller bucket refill intervals are already implemented in Tor master
&gt; if you build with Libevent 2.0 and use the buffervents backend by
&gt; passing --enable-bufferevents to configure.  The refill interval is
&gt; currently set to 1/3 of a second, but that value was chosen more or
&gt; less at random; it would be neat to see other values benchmarked as
&gt; well.

We did some measurements on our onion router, and also many simulations.
1/3 second still seems far too coarse. One would have to come
significantly below the RTT of the TCP links between onion routers. We
therefore tend more towards something in the order of 1/100 s. (We did
not notice any difference in CPU utilization when we made this change -
so this apparently isn't an issue.)


Best regards

Bjrn



</body></email><email><emailId>20110122170308</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-01-22 17:03:08-0400</timestampReceived><subject>Re: how to checkout current stable branch</subject><body>

On Sat, Jan 22, 2011 at 11:55 AM, Bernd Kreuss &lt;prof7bit@googlemail.com&gt; wrote:
&gt; This is probably a stupid question but how do I checkout the 0.2.1
&gt; branch from git? With svn I knew how to do such things but I don't get
&gt; how this git thing is meant to be used.
&gt;
&gt; I have successfully checked out the master branch via git clone
&gt; git://git.torproject.org/tor.git and can compile it but what is the URL
&gt; for the 0.2.1 branch? I can't find any instructions about this.

% git branch -a

will list all the heads. I think that you want

% git checkout -b 0.2.1 remotes/origin/maint-0.2.1

That will create a new local branch pointing to
remotes/origin/maint-0.2.1 and switch to it.

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
</body></email><email><emailId>20110102180814</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-01-02 18:08:14-0400</timestampReceived><subject>Re: RFC/proposal for Thandy changes</subject><body>


On Sun, 17 Oct 2010 19:46:22 -0700
Justin Samuel &lt;js@justinsamuel.com&gt; wrote:

&gt;   1. An authentication layer that downloads and authenticates opaque 'tar=
get'
&gt;      files according to metadata it understands that lists hashes and siz=
es of
&gt;      the target files. This layer doesn't understand what bundles and pac=
kages
&gt;      are.

&gt;   * The decision layer uses the authentication layer to retrieve a list of
&gt;     all available bundleinfo files.

&gt;   * The decision layer notices a bundle version in the list that it wants
&gt;     and uses the authentication layer to retrieve the bundleinfo file for=
 that
&gt;     version.

&gt;   * The decision layer uses the authentication layer to retrieve the pkgi=
nfo
&gt;     files for each of the package versions that it wants.

&gt;   * The decision layer uses the authentication layer to retrieve the
&gt;     individual files (e.g. /targets/pkgs/openssl/win32/0.9.8m/libeay32.dl=
l)
&gt;     that are needed.

Perhaps 'download layer' would be a better term than 'authentication
layer'.


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110110040236</emailId><senderName>Justin Samuel</senderName><senderEmail>js@justinsamuel.com</senderEmail><timestampReceived>2011-01-10 04:02:36-0400</timestampReceived><subject>Re: RFC/proposal for Thandy changes</subject><body>

On 01/01/2011 10:14 PM, Nick Mathewson wrote:
&gt; On Sun, Oct 17, 2010 at 10:46 PM, Justin Samuel &lt;js@justinsamuel.com&gt; wrote:
&gt;&gt; Hi all,
&gt; 
&gt; Hi, and sorry about the delay!  I think I like most of it, dislike a
&gt; couple of details, and have some points where I don't get it.  More
&gt; detail follows.

No worries about the delay. I was pretty bogged down until mid-December.

&gt; [ lines re-wrapped]
&gt;&gt;
&gt;&gt; 0. Proposed Thandy Changes
&gt;&gt; ==========================
&gt;&gt;
&gt;&gt; This is a set of proposals that includes a section of simple changes
&gt;&gt; that can be considered on their own (Section 1) as well as a more
&gt;&gt; fundamental Thandy restructuring proposal (Section 2).
&gt;&gt;
&gt;&gt; This isn't meant to be at the level of detail needed for a spec and
&gt;&gt; subsequent implementation. This is to get feedback and promote
&gt;&gt; discussion. It's not an official proposal at this point but more of a
&gt;&gt; request for comment.
&gt; 
&gt; Okay.  I'm going to omit all comments of the form "Could be okay, but
&gt; needs more detail", then. :)
&gt; 
&gt;&gt; A few relevant documents for reference:
&gt;&gt;
&gt;&gt;  * Thandy spec:
&gt;&gt;    https://gitweb.torproject.org/thandy.git/blob_plain/HEAD:/specs/thandy-spec.txt
&gt;&gt;  * TUF spec: https://www.updateframework.com/browser/specs/tuf-spec.txt
&gt;&gt;  * High-level differences between Thandy and TUF:
&gt;&gt;    https://www.updateframework.com/wiki/ThandyDifferences
&gt;&gt;  * Paper on TUF: http://www.freehaven.net/~arma/tuf-ccs2010.pdf
&gt;&gt;
&gt;&gt; 1. Individual Thandy Changes
&gt;&gt; ============================
&gt;&gt;
&gt;&gt; These are changes that could be made to Thandy without major overhaul
&gt;&gt; and can be considered separately of the restructuring proposal (Section
&gt;&gt; 2).

Your comments on these individual changes make sense, but I'm going to
skip replying to these for the moment. I think the more pressing issue
is deciding whether it's worthwhile to further consider the
restructuring proposal (below).

&gt; 
&gt;&gt; 2. Thandy Restructuring Proposal
&gt;&gt; ================================
&gt;&gt;
&gt;&gt; Primary goal: Keep Thandy's concepts of bundles and packages but overlay
&gt;&gt; them on top of the generic 'targets' approach of TUF.
&gt; 
&gt; I don't get this as a goal.  Obviously, you're not advocating that we
&gt; should use TUF's 'targets' approach for it's own sake: you're advocating
&gt; that we use it in order to get some concrete benefit that it provides.
&gt; _That benefit_ is the real goal, not mere use of TUF's approach for its
&gt; own sake.  (I know this sounds like nitpicking, but unless we're clear
&gt; about what actual benefits a change is meant to provide, it's harder to
&gt; evaluate it.)
&gt; 
&gt; If I had to guess, I would say that the real goal is probably something
&gt; like, "separate Thandy's notion of packages and bundles from Thandy's
&gt; notion of authenticated downloads."

Right, separation is the goal. The motivations behind this goal could
really use some discussion.

The first motivation was to see if this split-layer design would be easy
to explain, understand, and reason about.

The second motivation with this goal was to make Thandy's design and
implementation as useful to other projects as possible. I feel (with no
evidence and little experience to back this up) that an approach which
tightly integrates the concepts of bundles and packages would be less
likely to be used by highly diverse projects than one which offered a
more generic system for authenticated downloads. Of course, there are
probably plenty of projects that would use Thandy in the same way that
Tor uses it even if the concepts of bundles and packages didn't exactly
fit their project's or organization's model.

Regarding the first motivation, I'd love to be make the claim that this
separation makes it easier to reason about the security of Thandy.
However, especially after writing the initial informal proposal, I'm not
sure that's true. My impression is that this separation makes Thandy's
design more complex. It seems to trade simplicity for flexibility, where
Tor may not be the direct beneficiary of the flexibility down the road.

&gt;&gt; Note: This proposal is not advocating using/maintaining/relying on TUF
&gt;&gt; as a separate project. That depends on factors such as the future of TUF
&gt;&gt; according to the current TUF maintainers, whether Python is an
&gt;&gt; appropriate choice for Windows clients, etc.
&gt;&gt;
&gt;&gt; 2.1 Approach
&gt;&gt; ------------
&gt;&gt;
&gt;&gt; Two separate layers:
&gt;&gt;
&gt;&gt;   1. An authentication layer that downloads and authenticates opaque
&gt;&gt;      'target' files according to metadata it understands that lists
&gt;&gt;      hashes and sizes of the target files. This layer doesn't understand
&gt;&gt;      what bundles and packages are.
&gt;&gt;
&gt;&gt;   2. A decision/installation layer that uses the authentication layer to
&gt;&gt;      download bundle/package info and associated files. This layer
&gt;&gt;      doesn't know the details of the authentication mechanisms or roles;
&gt;&gt;      it gets files from the authentication layer that the authentication
&gt;&gt;      layer has already authenticated.
&gt;&gt;
&gt;&gt;      * Note that the update decision and installation code are probably
&gt;&gt;        separate, but for the sake of this proposal all that matters is
&gt;&gt;        that the Thandy authentication layer is logically separate from
&gt;&gt;        the rest of Thandy.
&gt; 
&gt; Hm.  It would help to know what exactly the interface to layer 1 should
&gt; be.  I'm guessing it's something like, "Update the metadata", "Tell me
&gt; what files are available", "Download the following files".

That's pretty much it. There could be some ability to filter the "tell
me what files are available" by file path or by signing roles. The
"download the following files" call wouldn't make the files available to
the calling code until signatures and hashes had been verified.

&gt;&gt; For the authentication layer, we start with the following roles (the
&gt;&gt; same as TUF uses):
&gt;&gt;
&gt;&gt;   * Root
&gt;&gt;     o Root of trust for the entire PKI. Indicates through signed
&gt;&gt;       metadata which keys are trusted for the Release, Targets,
&gt;&gt;       Timestamp, and Mirror roles.
&gt;&gt;
&gt;&gt;   * Timestamp
&gt;&gt;     o Signs a frequently regenerated timestamp file with a short
&gt;&gt;       expiration indicating the most recent release metadata.
&gt;&gt;
&gt;&gt;   * Release
&gt;&gt;     o Signs the release metadata which lists the hashes and sizes of all
&gt;&gt;       other metadata files (other than the timestamp file). Note that
&gt;&gt;       bundleinfo and pkginfo are not considered metadata at the
&gt;&gt;       authentication layer.
&gt;&gt;
&gt;&gt;   * Targets
&gt;&gt;     o Signs a metadata file that lists the hashes and sizes of target
&gt;&gt;       files: the files that the decision layer ultimately wants to
&gt;&gt;       obtain.
&gt;&gt;
&gt;&gt;     o Can delegate to sub-roles the responsibility for providing target
&gt;&gt;       files from specific paths on the repository (e.g. Role A is
&gt;&gt;       trusted to provide files from the /targets/role_a/ directory).
&gt; 
&gt; It sounds like you're combining the roles of signing code (which the
&gt; targets key can do, and delegates) with the role of deciding who can
&gt; sign code.  Is that wise?  Nowhere else in the Thandy design is this
&gt; done.

Whether or not it is a bad idea to combine code-signer roles with
delegator roles depends on how they are used. Also, the extent of
delegation could be limited by having the delegating role indicate
whether the delegated role can delegate further. --- This may be an
example of how trying to make a Thandy download/authentication layer
highly flexible ultimately just makes security harder to reason about.

&gt; In practice, I'd assume that the Targets role should be pretty much
&gt; *only* used for delegation.  But in that case, what's the benefit of
&gt; separating this from the root role?

One benefit is that it allows more choices in the balance between how
often certain keys are used vs. what level of privilege those keys have.
In general, any time an organization has a project that could benefit
from being split into subprojects or components with different
authors/maintainers, allowing delegation by roles other than the root
role can decrease how often the root keys need to be used. There may not
be much benefit in Tor's case. I think it's safe to say that this is
oriented more towards flexibility in potential use cases rather than
practicality with Tor's current use case.

&gt;&gt;   * Mirror
&gt;&gt;     o Signs a metadata file that lists the locations and details of
&gt;&gt;       repository mirrors.
&gt;&gt;
&gt;&gt; From here we use delegation by the Targets role to create the roles for
&gt;&gt; bundlers and packagers. The top-level Targets role delegates a separate
&gt;&gt; role for each bundle and each package.
&gt;&gt;
&gt;&gt; The targets role hierarchy looks like this (with many more bundle and
&gt;&gt; package roles):
&gt;&gt;
&gt;&gt; Root
&gt;&gt; `-- Targets
&gt;&gt;     |-- bundles/tor-browser-stable
&gt;&gt;     |-- bundles/tor-browser-beta
&gt;&gt;     `-- pkgs/openssl
&gt;&gt;
&gt;&gt; Each bundle version and package version that bundlers and packagers
&gt;&gt; released has a separate bundleinfo and pkginfo file, respectively. These
&gt;&gt; bundleinfo and pkginfo files are opaque to the authentication layer: it
&gt;&gt; considers them target files like any other. However, the decision layer
&gt;&gt; understands the contents of these files and uses them to make subsequent
&gt;&gt; download and installation decisions (with the downloads always being
&gt;&gt; done through the authentication layer).
&gt;&gt;
&gt;&gt; 2.2. Repository Structure
&gt;&gt; -------------------------
&gt;&gt;
&gt;&gt; Top-level metadata files are:
&gt;&gt;
&gt;&gt; /meta/root.txt
&gt;&gt; /meta/release.txt
&gt;&gt; /meta/timestamp.txt
&gt;&gt; /meta/targets.txt
&gt;&gt; /meta/mirrors.txt
&gt;&gt;
&gt;&gt; The /meta/targets.txt file would include a delegations section such as:
&gt;&gt;
&gt;&gt; delegations : {
&gt;&gt;     keys : {
&gt;&gt;         'ABC...' : { details },
&gt;&gt;         '123...' : { details },
&gt;&gt;         ...
&gt;&gt;       },
&gt;&gt;     roles : {
&gt;&gt;         'bundles/tor-browser-stable' : {
&gt;&gt;             keys : ['ABC...', '123...'],
&gt;&gt;             threshold : 2,
&gt;&gt;             paths : ['bundles/tor-browser-stable/**'],
&gt;&gt;           },
&gt;&gt;         'pkgs/openssl' : {
&gt;&gt;             keys : ['DEF...', '456...'],
&gt;&gt;             threshold : 2,
&gt;&gt;             paths : ['pkgs/openssl/**'],
&gt;&gt;           },
&gt;&gt;         ...
&gt;&gt;       }
&gt;&gt;   }
&gt; 
&gt; To be clear, are you proposing that *every* role be able to delegate
&gt; itself in its particular file, or that a single level of delegation
&gt; exist in the targets.txt file?

With what I proposed, the root role and all targets roles (that is,
including delegated targets roles) would be allowed to delegate. I
attempted to arrange the metadata file names and formats such that there
would be a clean and consistent way to allow other roles to delegate in
the future, if needed. However, I find that thinking of cases where the
mirrors role, release role, or timestamp role might need to delegate
starts to feel like an academic exercise and an attempt to solve
problems that don't exist.

&gt;&gt; The above would mean that the top-level Targets role had delegated a
&gt;&gt; role whose full name would be targets/bundles/tor-browser-stable (as it
&gt;&gt; is delegated by the targets role, the prepended targets/ is implicit in
&gt;&gt; the delegated role's name). This role for the tor-browser-stable bundle
&gt;&gt; would be trusted for the specified paths relative to the repository's
&gt;&gt; targets/ directory. Thus, a specific version's bundleinfo file created
&gt;&gt; by the bundler could be placed on the repository at, for example:
&gt;&gt;
&gt;&gt;   /targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.bundleinfo
&gt;&gt;
&gt;&gt; (Note that this bundle role is trusted for all targets files matching
&gt;&gt; the path 'bundles/tor-browser-stable/**' under the repository's targets/
&gt;&gt; directory, as specified when this role was created through the above
&gt;&gt; delegation.)
&gt;&gt;
&gt;&gt; The bundle maintainer would sign a metadata file listing the hash and
&gt;&gt; size of this bundleinfo. This metadata would be placed on the repository
&gt;&gt; at:
&gt;&gt;
&gt;&gt;   /meta/targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.txt
&gt;&gt;
&gt;&gt; (Note that the basename of these files isn't crucial to this aspect of
&gt;&gt; the design. They don't need to repeat the path info, though that's
&gt;&gt; probably helpful for humans.)
&gt;&gt;
&gt;&gt; More generally, the metadata location is:
&gt;&gt;
&gt;&gt;   /meta/ROLE_NAME/[ANY_PATH/]ANY_NAME.txt
&gt;&gt;
&gt;&gt; Packages are similar to bundles with the difference that there are one
&gt;&gt; or more target files in addition to the pkginfo file. A package
&gt;&gt; maintainer may supply the following files to be placed on the
&gt;&gt; repository:
&gt;&gt;
&gt;&gt;   /targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.pkginfo
&gt;&gt;   /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll
&gt;&gt;   /targets/pkgs/openssl/win32/0.9.8m/ssleay32.dll
&gt;&gt;
&gt;&gt; The hashes and sizes of these files are listed in metadata signed by the
&gt;&gt; targets/pkgs/openssl role (that is, the openssl package maintainer's
&gt;&gt; role).  This metadata would be placed on the repository at:
&gt;&gt;
&gt;&gt;   /meta/targets/pkgs/openssl/win32/0.9.8m/openssl_win32_0.9.8m.txt
&gt; 
&gt; So to see if I have it right:
&gt; 
&gt;   - Every target file corresponds to exactly one target metadata file,
&gt;     though any target metadata file can in principle correspond to one
&gt;     or more target files.

Correct for Tor's usage of the download/authentication layer. In other
(non-Tor) usages, it would be possible for separate targets metadata
files to list the same target file, potentially having the same target
file described with conflicting sets of hashes+filesize (I'm not saying
this would be a good thing, but just that it would be possible unless
this was prohibited by imposing restrictions on delegation, see below).

&gt;   - It is trivial, given a target metadata file, to learn which target
&gt;     files it authenticates.  It is not trivial, given a target file, to
&gt;     learn which target metadata file authenticates it; ideally, it will
&gt;     be in a corresponding location in the metadata.  (Is this required?)

Correct. The contents of targets metadata files always state which
targets files that role has directly authenticated.

For going the other direction (given a target file, which metadata files
might it be listed in), if the delegation is done in such a way that:

  a) there isn't overlap in the paths for which delegated targets roles
are responsible (e.g. "a/**" and "b/**" are fine because they don't
overlap), and

  b) targets roles that perform delegation don't authenticate target
files in those same delegated paths (e.g. authenticating "foo.rpm" and
delegating "a/**" is fine, but not authenticating "a/foo.rpm" and
delegating "a/**"),

then an individual target file can only be listed in a single targets
metadata file. This doesn't make it trivial to know which targets
metadata file listed a given target file, but it does ensure that there
is at most one targets metadata file that listed it.

&gt;   - Both layers of the updater (the authentication layer and the
&gt;     decision layer) need to be able to verify hashes and signatures.

This doesn't have to be the case. The requirement is that the targets
role delegation be done in such a way that a target file's path limits
the roles that could have provided the file. If that is the case, then
successfully obtaining the target file through the authentication layer
means that the authentication layer was able to verify signatures by
whichever targets roles are trusted to provide files at that path.

For example, if delegated targets roles "linux" and "win" are only
trusted to provide files from paths "linux/**" and "win/**",
respectively, then the decision layer can use the authentication layer
to download a target file at "linux/foo.rpm" without having to know
details of signature, hashes, or even the underlying roles. Properly
restricting the paths that the various delegated targets roles are
trusted for is an absolute requirement with this approach.

&gt;&gt; 2.3. Update Procedure
&gt;&gt; ---------------------
&gt;&gt;
&gt;&gt; The update procedure is:
&gt;&gt;
&gt;&gt;   * The decision layer uses the authentication layer to retrieve a list
&gt;&gt;     of all available bundleinfo files.
&gt;&gt;     o Implementation: the decision layer asks the authentication layer
&gt;&gt;       for a list of all available metadata file paths/names. The
&gt;&gt;       authentication layer obtains this information from the release
&gt;&gt;       metadata.
&gt;&gt;   * Looking at the paths/names of available bundleinfo files, the
&gt;&gt;     decision layer identifies whether there is a newer version of a
&gt;&gt;     bundle it is interested in.
&gt;&gt;     o Implementation: the bundle names, OS, arch, and bundle version are
&gt;&gt;       all contained in paths of the available bundle metadata files.
&gt; 
&gt; This seems to add a requirement that you can do a mapping from bundle
&gt; name to bundle version.  Specifying string-to-version mappings in a
&gt; reliable way can be really nasty.  Sure you want to do that?

That does seem potentially problem-prone. A solution would be to include
additional information for each item listed in the release.txt file.
Keeping in the spirit of over-generality, I've always envisioned an
optional "custom" field that could be used in various places in the
authentication layer metadata. For example, the targets metadata for a
bundle file could look like this when listed in release.txt:


"/meta/targets/bundles/tor-browser-stable/win32/0.1/tor-browser-stable_win32_0.1.txt":
{
     "hashes": {
       "sha256":
"af58c844e1088ccfc696c80f9ddcc6a9ef2856669615aa59d11dc325bc271219"
     },
     "length": 680,
     "custom": {
       "type": "bundle",
       "name": "tor-browser-stable",
       "OS": "win32",
       "version": "0.1",
     },
   },

Format-wise, that could even be:

       "version": [0, 1],

Either way, this version information isn't authoritative (because the
release.txt file is signed by the release role, not the individual
bundle role) and the decision layer would need to verify that the
version information listed in the bundle file, once downloaded, is the same.

The Thandy spec should probably describe the allowed version formats and
how ordering is determined or refer to an existing Tor spec if that's
already described somewhere.

&gt;&gt;   * The decision layer notices a bundle version in the list that it
&gt;&gt;     wants and uses the authentication layer to retrieve the bundleinfo
&gt;&gt;     file for that version.
&gt;&gt;   * The decision layer reads the contents of the bundleinfo file which
&gt;&gt;     indicate the necessary package versions and any other info the
&gt;&gt;     decision layer needs.
&gt;&gt;   * The decision layer uses the authentication layer to retrieve the
&gt;&gt;     pkginfo files for each of the package versions that it wants.
&gt;&gt;   * The decision layer understands the contents of the pkginfo
&gt;&gt;     files. These files indicate the individual files that are part of
&gt;&gt;     this version of the package.
&gt;&gt;   * The decision layer uses the authentication layer to retrieve the
&gt;&gt;     individual files (e.g. /targets/pkgs/openssl/win32/0.9.8m/libeay32.dll)
&gt;&gt;     that are needed.
&gt;&gt;   * The decision layer hands off the relevant installation instructions
&gt;&gt;     (from the bundleinfo and pkginfo files) and individual package files
&gt;&gt;     to the code that performs the installation/upgrade.
&gt;&gt;
&gt;&gt;
&gt;&gt; 2.4.bundleinfo and pkginfo
&gt;&gt; --------------------------
&gt;&gt;
&gt;&gt; As the contents of the bundleinfo and pkginfo are opaque to the
&gt;&gt; authentication layer, essentially there are two completely separate sets
&gt;&gt; of metadata in this design. It would make sense to have them use the
&gt;&gt; same format (e.g. Canonical JSON) and be parsed/generated by the same
&gt;&gt; code.
&gt; 
&gt; This argues for three components, then: the two you described, plus a
&gt; generic data-format layer that they both could use.

That makes sense.

&gt; peace &amp; happy new year,

Happy new year. Hopefully 2011 will be the year I actually help with Thandy.

I'm not sure if I've provided a clear enough idea of how this
split-layer design would work in order for people to form opinions about
it. At the moment, the way it looks to me is that this split-layer
approach increases complexity for what could be considered theoretical
and debatable future benefits. If a tested, used, and supported
download/authentication layer already existed in the form Thandy needed
it and it could be essentially dropped in as a library, the increased
design complexity might be offset by decreased development time and
increased reliability. Does this seem like a fair assessment?

I defer to those with more experience to decide whether the ideas and
remaining questions/concerns of the split-layer approach should be
fleshed out further, possibly into an actual proposal. Otherwise, I
should probably instead focus on addressing Nick's comments on the
simpler changes.

Justin
</body></email><email><emailId>20110110094940</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-01-10 09:49:40-0400</timestampReceived><subject>Re: Draft document and notes from rransom: requirements for circuit</subject><body>


On Sat, 18 Dec 2010 01:23:49 -0500
Nick Mathewson &lt;nickm@torproject.org&gt; wrote:

&gt; On Tue, Dec 14, 2010 at 11:35 PM, Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt; 
&gt; I'm going to try to kick off discussion here in hopes of moving the
&gt; design effort forward.  I don't have the crypto chops of Robert, so
&gt; I'm hoping that people with more experience in formal cryptography can
&gt; have a look here too.
&gt; 
&gt; &gt; ===
&gt; &gt; Title: Requirements for Tor's circuit cryptography
&gt; 
&gt; This document might morph into a larger "requirements for Tor's
&gt; cryptography" document, or one of a set of such documents.  Unless I'm
&gt; forgetting something, the other areas of cryptography Tor has are:
&gt; 
&gt;   * link cryptography
&gt;   * directory authentication
&gt;   * hidden-service protocol
&gt;   * hidden-service directory protocol
&gt; 
&gt; &gt; Author: Robert Ransom
&gt; &gt; Created: 12 December 2010
&gt; &gt;
&gt; &gt; Overview
&gt; &gt;
&gt; &gt;   This draft is intended to specify the meaning of 'secure' for a Tor
&gt; &gt;   circuit protocol, hopefully in enough detail that
&gt; &gt;   mathematically-inclined cryptographers can use this definition to
&gt; &gt;   prove that a Tor circuit protocol (or component thereof) is secure
&gt; &gt;   under reasonably well-accepted assumptions.
&gt; &gt;
&gt; &gt;   Tor's current circuit protocol consists of the CREATE, CREATED, RELAY,
&gt; &gt;   DESTROY, CREATE_FAST, CREATED_FAST, and RELAY_EARLY cells (including
&gt; &gt;   all subtypes of RELAY and RELAY_EARLY cells).
&gt; 
&gt; So as written, this would make the circuit protocol consist of all
&gt; hidden service cells too, since they are also RELAY_* cells.  Can we
&gt; exclude them from consideration here?  The rendezvous protocol is
&gt; pretty complicated, and almost wholly orthogonal from the rest of the
&gt; circuit protocol.

A client which has opened a circuit to a node with fingerprint
KEY-TYPE$FINGERPRINT should be able to use the same command to open a
stream at that node to any of the following services:

* KEY-TYPE$FINGERPRINT/directory
* KEY-TYPE$FINGERPRINT/dns
* KEY-TYPE$FINGERPRINT/exit/127.0.0.1/80
* KEY-TYPE$FINGERPRINT/exit/example.com/80
* KEY-TYPE$FINGERPRINT/exit/::1/80
* KEY-TYPE$FINGERPRINT/persistent-circuit
* KEY-TYPE$FINGERPRINT/establish-introduce-v0
* HS-EPHEMERAL-KEY-TYPE$HS-EPHEMERAL-FINGERPRINT/introduce-v0
* KEY-TYPE$FINGERPRINT/establish-rendezvous-v0
* rendezvous$RENDEZVOUS-COOKIE/rendezvous-v0
* KEY-TYPE$FINGERPRINT/establish-rendezvous-v1
* HS-EPHEMERAL-KEY-TYPE$HS-EPHEMERAL-FINGERPRINT/rendezvous-v1


A new hidden service protocol should reuse circuit-handshake protocols
for the new introduction point mechanism, and should reuse circuit 
ciphersuites for the new rendezvous point mechanism.


&gt; (At first I wanted to say that the circuit protocol should consist
&gt; only of the crypto done to transmit relay cells, and not their
&gt; contents, but saying that would exclude the contents of  RELAY EXTEND
&gt; cells, which would be silly.)

I have been using the term "circuit ciphersuite" for the layer of
cryptography used on RELAY cells, and the term "circuit-extension
handshake protocol" for the protocol currently performed using CREATE,
CREATED, EXTEND, and EXTENDED cells.  A circuit protocol relies on both
a circuit ciphersuite and a circuit-extension handshake protocol.


&gt; &gt;    Tor currently has two
&gt; &gt;   circuit-extension handshake protocols: one consists of the CREATE and
&gt; &gt;   CREATED cells; the other, used only over the TLS connection to the
&gt; &gt;   first node in a circuit, consists of the CREATE_FAST and CREATED_FAST
&gt; &gt;   cells.
&gt; &gt;
&gt; &gt; Requirements
&gt; 
&gt; 
&gt; &gt;   1. Every circuit-extension handshake protocol must provide forward
&gt; &gt;   secrecy -- the protocol must allow both the client and the relay to
&gt; &gt;   destroy, immediately after a circuit is closed, enough key material
&gt; &gt;   that no attacker who can eavesdrop on all handshake and circuit cells
&gt; &gt;   and who can seize and inspect the client and relay after the circuit
&gt; &gt;   is closed will be able to decrypt any non-handshake data sent along
&gt; &gt;   the circuit.
&gt; &gt;
&gt; &gt;   In particular, the protocol must not require that a key which can be
&gt; &gt;   used to decrypt non-handshake data be stored for a predetermined
&gt; &gt;   period of time, as such a key must be written to persistent storage.
&gt; 
&gt; It would also be nice if we could do better here: if for example we
&gt; could re-key an existing circuit and drop the old keys so that the
&gt; nodes long-lived circuit didn't need to keep the key material needed
&gt; to decrypt all the stuff they had already received.

I agree, but that is not part of the handshake protocol or its
cryptographic primitives.  That goal relates to the circuit ciphersuite.


&gt; &gt;   2. Every circuit-extension handshake protocol must specify what key
&gt; &gt;   material must be used only once in order to allow unlinkability of
&gt; &gt;   circuit-extension handshakes.
&gt; &gt;
&gt; &gt;   3. Every circuit-extension handshake protocol must authenticate the relay
&gt; &gt;   to the client -- an attacker who can eavesdrop on all handshake and
&gt; &gt;   circuit cells and who can participate in handshakes with the client
&gt; &gt;   must not be able to determine a symmetric session key that a circuit
&gt; &gt;   will use without either knowing a secret key corresponding to a
&gt; &gt;   handshake-authentication public key published by the relay or breaking
&gt; &gt;   a cryptosystem for which the relay published a
&gt; &gt;   handshake-authentication public key.
&gt; &gt;
&gt; &gt;   4. Every circuit-extension handshake protocol must ensure that neither
&gt; &gt;   the client nor the relay can cause the handshake to result in a
&gt; &gt;   predetermined symmetric session key.
&gt; 
&gt; I think you want something a little stronger here; by the literal
&gt; reading of 4, it's okay if the relay can force _one of two_ keys, but
&gt; of course that's not okay.

Indeed.


&gt; Also, what is the problem if the *client* can force a particular
&gt; session key?  If the client is hostile to her own anonymity, then the
&gt; system is not expected to work.

Some parts of the current Tor protocol (at least the ESTABLISH_INTRO
relay cell in the rendezvous protocol) use KH (a value derived from the
shared session key produced by the circuit-extension handshake
protocol) as a nonce to prevent an attacker from replaying a cell on a
later circuit.


&gt; &gt;   5. Every circuit-extension handshake protocol should ensure that an
&gt; &gt;   attacker who can predict the relay's ephemeral secret input to the
&gt; &gt;   handshake and can eavesdrop on all handshake and circuit cells, but
&gt; &gt;   does not know a secret key corresponding to the
&gt; &gt;   handshake-authentication public key used in the handshake, cannot
&gt; &gt;   break the handshake-authentication public key's cryptosystem, and
&gt; &gt;   cannot predict the client's ephemeral secret input to the handshake,
&gt; &gt;   cannot predict the symmetric session keys used for the resulting
&gt; &gt;   circuit.
&gt; &gt;
&gt; &gt;   6. The circuit protocol must specify an end-to-end flow-control
&gt; &gt;   mechanism, and must allow for the addition of new mechanisms.
&gt; &gt;
&gt; &gt;   7. The circuit protocol should specify the statistics to be exchanged
&gt; &gt;   between circuit endpoints in order to support end-to-end flow control,
&gt; &gt;   and should specify how such statistics can be verified.
&gt; &gt;
&gt; &gt;
&gt; &gt;   8. The circuit protocol should allow an endpoint to verify that the other
&gt; &gt;   endpoint is participating in an end-to-end flow-control protocol
&gt; &gt;   honestly.
&gt; 
&gt; I note that this doesn't actually say much about the content of RELAY
&gt; cells themselves.  IMO, that's a little cart-before-the-horseish,
&gt; since the whole point of establishing circuits is to use them to send
&gt; RELAY cells back and forth.   I don't have a complete list, but here's
&gt; a sketch:
&gt; 
&gt;  * The point of the circuit crypto protocol is to transmit data
&gt; between the client and the nodes in the circuit so they can handle it
&gt; appropriately.  This data is sent in RELAY cells.  Each RELAY cell
&gt; originated by the client goes to exactly one node on the circuit; each
&gt; RELAY cell originated by a node on the circuit goes to the client.
&gt; 
&gt;  * Relay cells should get encrypted with one layer of cryptography per
&gt; node in the circuit.  We want a property here something like, "A cell
&gt; sent by the client cannot be read by anybody but the relay it is
&gt; intended for; a cell sent by the relay cannot be read by anybody but
&gt; the client."

Circuit ciphersuites also must provide some amount of integrity
protection and replay prevention.


&gt; There's probably more to say here, though we could probably also just
&gt; incorporate the appropriate part of the design paper by reference and
&gt; say "it works like that".  We might also want to mention some
&gt; properties that you get for free from the rest of the Tor design,
&gt; including:
&gt; 
&gt;  * Link crypto exists.
&gt;  * Clients know circuit-establishment public keys (a.k.a onion keys)
&gt; for all relays they want to use.
&gt; 
&gt; Also, here are a few more nice-to-have properties that might be worth
&gt; considering if they can be done without too much trouble.    I realize
&gt; that all of these probably fall under the heading of "Second System"
&gt; desiderata, but I feel unable to keep myself from writing them down
&gt; *somewhere*.
&gt; 
&gt;   * It would be nice to make it a little harder for end-to-end bitwise
&gt; tagging attacks to work.  This isn't a huge priority, though, since
&gt; these are already outside our threat model (as noted in the Tor design
&gt; paper), and there are plenty of other and less detectable ways to do
&gt; active and passive end-to-end correlation.
&gt; 
&gt;   * Some work in resisting traffic analysis relies on an ability for
&gt; _all_ nodes in the circuit to introduce long-range padding in both
&gt; directions.  In our current protocol, only the client can add outbound
&gt; padding, while each node can only add inbound padding.  I'm not
&gt; putting a high priority on this one personally, since it's only a
&gt; building block for future work and not actually applicable to anything
&gt; solid today.
&gt; 
&gt;   * There shouldn't be any high-multiplier DoS attacks against the
&gt; protocol.  In particular, maybe an attacker shouldn't be able to force
&gt; a node to do an expensive secret-key operation just by sending some
&gt; undecodable junk data.  Proof-of-work might be one way to do this.
&gt; 
&gt;   * The protocol should not be very hard to implement; hard things are
&gt; error-prone.  In particular, it shouldn't require any particular
&gt; cryptographic algorithm not commonly available in Free/Open Source
&gt; crypto libraries.
&gt; 
&gt; 
&gt; 
&gt; &gt; ===========
&gt; &gt; NOTES:
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; All circuit handshake protocols must provide forward security.   This
&gt; &gt; requires that the client send a public key for some asymmetric
&gt; &gt; protocol that can provide secrecy (RSA, ElGamal, DH, McEliece,
&gt; &gt; Ajtai-Dwork, Lyubashevsky-Palacio-Segev, etc.) to each node in each
&gt; &gt; circuit.
&gt; &gt;
&gt; &gt; The public keys and public parameters used in different handshakes
&gt; &gt; must be unlinkable.   This will restrict different cryptosystems in
&gt; &gt; different ways:
&gt; &gt;
&gt; &gt; * An RSA or LPS key must be used only once, and then the entire secret
&gt; &gt;   key must be destroyed.
&gt; &gt;
&gt; &gt; * An ElGamal or DH key must be used only once, and then the secret
&gt; &gt;   exponent must be destroyed.   In addition, if the client generated
&gt; &gt;   the public parameters used by the key, the public parameters must
&gt; &gt;   also be destroyed.   (Public parameters published by a third party
&gt; &gt;   may be used multiple times.)
&gt; 
&gt; To be clear, the above applies only to keys used for forward-secrecy,
&gt; right?  IOW, our current CREATE/CREATED format uses a long-term RSA
&gt; public key for authentication and encryption of the DH handshake, and
&gt; a short-term DH handshake to generate the actual key material used for
&gt; encrypting cells.

This applies to all ephemeral forward-secrecy public keys sent by a
*client*.

It does not apply to hidden-service identity public keys, or to
forward-secrecy keys sent by a relay.


&gt; &gt; special wants to make it impossible for a node in the hidserv
&gt; &gt; directory DHT to determine the address a hidserv descriptor describes
&gt; &gt; unless it already knows the address.   The problem here is that the
&gt; &gt; following are absolutely required:
&gt; &gt;
&gt; &gt; * Each client must be able to compute, from the hidserv's address and
&gt; &gt;   a public nonce, the DHT retrieval key needed to retrieve the
&gt; &gt;   hidserv's descriptor and any decryption key needed to use the
&gt; &gt;   descriptor.
&gt; &gt;
&gt; &gt; * Each hidserv must give each DHT node responsible for its retrieval
&gt; &gt;   key the DHT retrieval key and a descriptor, and must prove to the
&gt; &gt;   DHT node that it knows a secret key which owns' a hidserv address
&gt; &gt;   which currently owns' the retrieval key.
&gt; &gt;
&gt; &gt; The proof of knowledge of a hidserv secret key is needed not to keep
&gt; &gt; jerks from crapflooding a DHT node (they can still do that by
&gt; &gt; generating lots of hidserv secret keys), but to prevent a censor from
&gt; &gt; overwriting someone else's hidserv descriptor and thereby blocking
&gt; &gt; access to the hidserv.
&gt; 
&gt; I want to call all of this hidden service stuff orthogonal for now,
&gt; but we should come up for it when we're writing requirements and
&gt; nice-to-haves for
&gt; 
&gt; &gt; Other questions:
&gt; &gt;
&gt; &gt; * What types of attackers should Tor's crypto protect against?
&gt; &gt;
&gt; &gt; * What types of attacks should Tor's crypto protect against?
&gt; 
&gt; My rule of thumb is: attacking the crypto should never be the easiest
&gt; way to attack Tor users for any attacker.  So for attackers and
&gt; attacks that Tor currently defeats, has a reasonable prospect of
&gt; evolving to defeat, or aspires to defeat (see the paper and other work
&gt; on the threat model), the cryptography should be hard enough to attack
&gt; that they cannot link or trace users.  Even for attackers we currently
&gt; *don't* know how to defeat with today's low-latency anonymity net
&gt; designs (e.g., those who can do end-to-end correlation attacks against
&gt; users), the cryptography should be strong enough that attacking it is
&gt; far more expensive than all their current plausible attacks.
&gt; 
&gt; (My rationale here is that today's cryptography research can give far
&gt; more impressive results than today's anonymity research, so we might
&gt; as well get them.)
&gt; 
&gt; &gt; * How do we transition relay identity key cryptosystems, now and in
&gt; &gt;   the future?
&gt; &gt;
&gt; &gt; * How do we transition directory identity key cryptosystems, now and
&gt; &gt;   in the future?
&gt; 
&gt; My other proposal draft starts to answer these, I hope.  Comments
&gt; welcome and invited!


Robert Ransom

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110111081236</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-01-11 08:12:36-0400</timestampReceived><subject>Flaw in bridge descriptor sanitizing process</subject><body>

Hi everyone,

back in Nov 2009, I posted our approach to sanitize bridge descriptors
before publishing them for everyone to analyze:

  http://archives.seul.org/or/dev/Nov-2009/msg00000.html

Now I found a flaw in this process that affects roughly 2.5 % of bridge
descriptors:  When a bridge is configured to use the default exit policy,
it adds a reject line containing its own IP address which we don't
sanitize.  Here's an example of a sanitized bridge descriptor.  Note that
I manually sanitized part of the bridge's IP address with '---' here!

  router Unnamed 127.0.0.1 9001 0 8030
  platform Tor 0.2.1.28 (r6e5496a2407ee589) on FreeBSD i386
  opt protocols Link 1 2 Circuit 1
  published 2010-12-21 17:59:41
  opt fingerprint 16D6 49EA 83CF 23A1 BAD3 90DC 921E E83F 310A CC7F
  uptime 64
  bandwidth 51200 102400 0
  opt extra-info-digest F2BD0C7AB741648D9CFC982C790B9221B8C04516
  opt hidden-service-dir
  contact somebody
  reject 0.0.0.0/8:*
  reject 169.254.0.0/16:*
  reject 127.0.0.0/8:*
  reject 192.168.0.0/16:*
  reject 10.0.0.0/8:*
  reject 172.16.0.0/12:*
  reject 80.---.--.---:*       &lt;--- bridge's IP address
  accept *:21
  accept *:23
  accept *:80
  accept *:110
  accept *:143
  accept *:443
  reject *:*

The fix is to replace the bridge's IP address in reject lines with
127.0.0.1, too.  See this commit for details:

  https://gitweb.torproject.org/metrics-db.git/commitdiff/e9d42a8

I started sanitizing the bridge descriptors since May 2008 once again, but
this takes at least another week to finish.  Here are the newly sanitized
bridge descriptors:

  https://metrics.torproject.org/data.html#bridgedesc

Can other people look at the sanitized descriptors and try to find other
sensitive parts (IP addresses, fingerprints, contact information, etc.)
that we should remove?  It took me 1 year to find this flaw, and I only
found it by chance when refactoring the code.  More eyes needed!

Thanks,
Karsten

</body></email><email><emailId>20110113031835</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-01-13 03:18:35-0400</timestampReceived><subject>Re: Arm Release 1.4.1</subject><body>

Thanks Fabian. Patch applied and made another hotfix release
(1.4.1.2). Cheers! -Damian

On Wed, Jan 12, 2011 at 11:22 AM, Fabian Keil
&lt;freebsd-listen@fabiankeil.de&gt; wrote:
&gt; Damian Johnson &lt;atagar1@gmail.com&gt; wrote:
&gt;
&gt;&gt; Thanks! Patches applied and I've released a fixed version (1.4.1.1).
&gt;&gt; There were two issues...
&gt;&gt;
&gt;&gt; - If an error occurred while resolving connections for the first time
&gt;&gt; then a missing dictionary key caused that stacktrace you saw. Trystero
&gt;&gt; also reported this on irc.
&gt;&gt;
&gt;&gt; - The root cause of that failure was the issue that you found (being
&gt;&gt; unable to parse the ps output due to an unexpected decimal value).
&gt;&gt;
&gt;&gt; Dumb question, but are you sure that it's hh:mm.ss rather than
&gt;&gt; mm:ss.ss (ie, it's providing decimal seconds)?
&gt;
&gt; Looks like you're right, so my patch actual made it worse. Oops.
&gt;
&gt; I attached another one. Again only briefly tested, though.
&gt;
&gt; Fabian
&gt;
</body></email><email><emailId>20110113190203</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-01-13 19:02:03-0400</timestampReceived><subject>Re: Stack blowout in 0.2.3.0-alpha-dev?</subject><body>

On Wed, Jan 12, 2011 at 09:47:03PM -0500, Nick Mathewson wrote:
&gt; On Wed, Jan 12, 2011 at 4:43 PM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; &gt; gurgle (our tor node) kept crashing, so I ran it under gdb.  It crashed
&gt; &gt; again, with a SEGV and the attached stack trace.  I truncated it; the
&gt; &gt; whole trace goes on for &gt;1600 frames (then I gave up hitting Enter).
&gt; &gt;
&gt; &gt;   - Ian
&gt; &gt;
&gt; 
&gt; Ug.  Doesn't look like I'm going to figure this out today.  Could you
&gt; please add a trac entry so that it goes in with the other bugs and
&gt; doesn't get forgotten about?

Done.  https://trac.torproject.org/projects/tor/ticket/2381
(I think I did that right.)

   - Ian
</body></email><email><emailId>20110117200243</emailId><senderName></senderName><senderEmail>travis+ml-tor-dev</senderEmail><timestampReceived>2011-01-17 20:02:43-0400</timestampReceived><subject>Re: polipo-tor debian package 1.3 released</subject><body>


I've published the package in a repo here:

http://www.subspacefield.org/packages/ubuntu/

So far, no complaints.

Follow instructions there, aptitude install polipo-tor, install
torbutton - done.
-- 
Effing the ineffable since 1997. | http://www.subspacefield.org/~travis/
My emails do not usually have attachments; it's a digital signature
that your mail program doesn't understand.
If you are a spammer, please email john@subspacefield.org to get blacklisted.

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20110119193823</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-19 19:38:23-0400</timestampReceived><subject>Re: Comments on proposal idea xxx-pluggable-transport</subject><body>

On Sat, Jan 15, 2011 at 9:04 PM, Steven J. Murdoch
&lt;tor+Steven.Murdoch@cl.cam.ac.uk&gt; wrote:
 [...]
&gt; Currently this code isn't compliant with the xxx-pluggable-transport
&gt; proposal, but in thinking about it, I have had a few thoughts.
&gt;
&gt; 1) The proposal talks about SOCKS, and my code implements SOCKS4.
&gt; However from my reading, the proposal depends on SOCKS5 because it
&gt; talks about putting NUL-separated key/value pairs in the username and
&gt; password fields of the SOCKS handshake. SOCKS4 there is no password
&gt; field and the username is NUL terminated, so NUL characters are not
&gt; permitted inside.
&gt;
&gt; We could mandate that protocol obfuscators support SOCKS5 (it's not
&gt; much harder to implement than SOCKS4), or change the spec to not
&gt; require NULs in the username field. Either way it doesn't make a big
&gt; difference but it should be clear which version of SOCKS we are
&gt; talking about.

Good catch.  Tor can currently speak socks4 or socks5, so I would
suggest having the choice of socks protocol be up to the transport.
Instead of NUL-separated parameters, we can pick some other
non-printing separator (0x01, for instance), or we could move to a
K=V;K=V;K=V format so long as we provide a way to escape any ; bytes
that occur in the V portions.  Suggestions?

Whatever encoding we pick, we should pick one that works just as well
for socks4 or socks5, so that we don't need to implement two versions
of it.

&gt; 2) The syntax for specifying obfuscated access to bridges is:
&gt;
&gt;  bridge method address:port [[keyid=]id-fingerprint] [k=v] [k=v] [k=v]
&gt;
&gt; This could be a bit confusing considering the current syntax (which we
&gt; will have to keep for backwards compatibility:
&gt;
&gt;  bridge address:port [fingerprint]
&gt;
&gt; If we require that method does not contain a ":" and a port is always
&gt; specified, I can see how this could be unambiguously parsed, but that
&gt; seems a bit ugly.

We could require that a method be a valid C identifier.  Any other
suggestions for making it less ugly?

&gt; 3) The two options for specifying a transport are:
&gt;
&gt;  ClientTransportPlugin trebuchet socks5 127.0.0.1:9999
&gt;
&gt;  ClientTransportPlugin trebuchet /usr/libexec/tor-proxies/trebuchet [options]
&gt;
&gt; These seem ambiguous. How can Tor reliably tell that the first form is
&gt; intended when both could have the same number of arguments?

Hm.  I had assumed that all programs would be specified by an absolute
path, but you're right that it's ambiguous as-is. How about instead
the second syntax becomes:

ClientTransportPlugin trebuchet program /usr/libexec/tor-proxies/trebuchet.

?

&gt; 4) When Tor launches the client proxy, the client proxy decides what
&gt; port it is listening on. This raises the possibility of conflicts. How
&gt; about if Tor picks the ports the client proxy should listen on, and
&gt; tells it via a command line parameter. Note that this can't be simply
&gt; the first parameter, because on Windows (where scripts are not
&gt; executable) the user would have to specify the path as
&gt; C:/Python/python.exe SCRIPTNAME.py.

How do you see the conflict arising?  I'd assume that any decent
client proxy should try a few possible ports until it gets one that
works... or just bind to port 0, and have the kernel pick.

&gt; 5) Minor. Methods are specified as "CMETHOD: methodname", but
&gt; terminated with "METHODS:DONE". I think we should be consistent about
&gt; whether there is a space between the colon and value.

Agreed; let's have a space.

-- 
Nick

</body></email><email><emailId>201101221703080</emailId><senderName>Adam Langley</senderName><senderEmail>agl@imperialviolet.org</senderEmail><timestampReceived>2011-01-22 17:03:08-0400</timestampReceived><subject>Re: how to checkout current stable branch</subject><body>

On Sat, Jan 22, 2011 at 11:55 AM, Bernd Kreuss &lt;prof7bit@googlemail.com&gt; wrote:
&gt; This is probably a stupid question but how do I checkout the 0.2.1
&gt; branch from git? With svn I knew how to do such things but I don't get
&gt; how this git thing is meant to be used.
&gt;
&gt; I have successfully checked out the master branch via git clone
&gt; git://git.torproject.org/tor.git and can compile it but what is the URL
&gt; for the 0.2.1 branch? I can't find any instructions about this.

% git branch -a

will list all the heads. I think that you want

% git checkout -b 0.2.1 remotes/origin/maint-0.2.1

That will create a new local branch pointing to
remotes/origin/maint-0.2.1 and switch to it.

AGL

-- 
Adam Langley agl@imperialviolet.org http://www.imperialviolet.org
</body></email><email><emailId>20110124184000</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-24 18:40:00-0400</timestampReceived><subject>Re: Proposal: Token Bucket</subject><body>

2011/1/19 Bjrn Scheuermann &lt;scheuermann@cs.uni-duesseldorf.de&gt;:
&gt; Dear Nick,
&gt;
&gt; thanks a lot for the feedback.
&gt;
&gt; On Mi, 2011-01-19 at 14:24 -0500, Nick Mathewson wrote:
&gt;&gt; 2011/1/3 Florian Tschorsch &lt;tschorsch@cs.uni-duesseldorf.de&gt;:
&gt;&gt;  [...]
&gt;&gt; &gt;  First, we observe that the token bucket for the relayed traffic on the
&gt;&gt; &gt;  outgoing connections is unnecessary: since no new such traffic is generated
&gt;&gt; &gt;  in an onion router, the rate of this traffic is already limited by the read
&gt;&gt; &gt;  bucket on the incoming side (cp. RelayedTokenBucket).
&gt;&gt;
&gt;&gt; This is not strictly true, I think.  Outbound cells with no
&gt;&gt; corresponding incoming can be generated by local directory requests,
&gt;&gt; by local bandwidth testing, and probably a couple of other things too.
&gt;
&gt; In the strict sense, you are of course right. However, the amount of
&gt; traffic caused by these functions is likely to be negligibly small (if I
&gt; remember that correctly, someone [Karsten Loesing?] investigated the
&gt; amount of directory traffic in some other context, and found that it
&gt; *is* negligible).
&gt;
&gt; If incoming and outgoing bandwidth limits are equal, an increase in the
&gt; volume of traffic within the onion router, in fact, even constitutes an
&gt; even stronger argument for our proposed modifications: if you have a
&gt; system (here: the queues in the onion router) where you continuously
&gt; admit more data into the system (incoming bandwidth limit + additional
&gt; overhead and traffic) than you allow to leave the system (outgoing
&gt; bandwidth limit), you will necessarily build up longer and longer queues
&gt; within the system, which will in turn cause very long cell delays -
&gt; which is just what we currently observe in Tor. Therefore, limiting the
&gt; amount of traffic on both ends is simply not a good idea.

Ah, I think I wasn't clear about the scope of my objection.  I'm not
arguing against the idea of doing something useful to ameliorate the
queueing issue: I am arguing against the original proposal, which was
(if I understood correctly) to eliminate outbound rate limiting
entirely.  The other proposals you suggest below (limiting read to a
fraction of write, either adaptively or at a fixed degree) are much
IMO better.

The reason that I can't agree with the original proposal ("remove the
rate limiting mechanism on the outgoing side") is that it will make
Tor nodes potentially write much, much more than they have been
configured to write.  Operators often configure rate limits for good
reasons: to conserve limited bandwidth, to save money if they're
paying by the byte, or to avoid bothering their local network
administrators.  When Tor violates its configured rate limits,
operators get angry.  Since we depend on volunteers to operate the Tor
network, we need to keep them happy, and so using more of their
bandwidth than they've agreed to provide us is not a good idea.

&gt; I really believe that this is a major issue which significantly (and
&gt; unnecessarily) limits the performance. Florian and I will be happy to
&gt; contribute a patch if everyone agrees.
&gt;
&gt;&gt; Also, when traffic arrives slowly on an edge connection, packaging it
&gt;&gt; into cells adds significant overhead (since every outgoing cell is 512
&gt;&gt; bytes+TLS overhead but not every outgoing cell is full).
&gt;
&gt; One may of course argue that the (admittely in extreme cases
&gt; significant) packaging overhead should be accounted for when Tor
&gt; enforces the configured bandwidth limits. However, to be consistent, one
&gt; would then also have to account for TLS, TCP, and IP header overhead,
&gt; which is currently neglected. This overhead will also be very
&gt; significant if traffic arrives *that* slowly, i.e., if you have TCP
&gt; segments far smaller than a cell size.
&gt;
&gt; This will certainly be interesting to assess in more detail. In case it
&gt; actually turns out to be an issue, I see two options:
&gt;
&gt; i) the pragmatic solution: based on a measurement study how much the
&gt; traffic typically "grows" due to packaging overhead etc., reduce the
&gt; configured bandwidth limit by an appropriate percentage
&gt;
&gt; ii) an "observe+adjust" mechanism: observe how much traffic is actually
&gt; leaving the router; if the outgoing traffic exceeds the configured
&gt; limit, reduce the rate at which data is read on the incoming side
&gt; accordingly
&gt;
&gt; The latter, if done right, would be able to guarantee that configured
&gt; bandwidth limits are strictly enforced, despite additional traffic being
&gt; generated in the router, and in even in case of an arbitrarily high
&gt; packaging overhead. However, my feeling is that this is a too complex
&gt; solution for a very simple problem.

I think we do need to go with something closer to the latter more
sophisticated approach for a couple of reasons.

First, as noted above, we really do need to enforce the configured
bandwidth limits.

Second, we must consider attackers.  It's not enough to say that based
on empirical evidence, directory responses currently occupy a small
fraction of data written, or that with current traffic loads each cell
is on average (say) 70% full.  If an attacker can make lots of
directory requests, or trickle data one byte at a time on a large
number of streams, he can cause the outbound data to exceed the
inbound data by much more than expected.

So I think the only approach that's going to work here is to hold the
outbound rate fixed while adaptively adjusting the input rate
downwards until we stop generating outbound traffic faster than we can
send it.


&gt;&gt; &gt;  We therefore propose
&gt;&gt; &gt;  to remove the rate limiting mechanism on the outgoing side. This will
&gt;&gt; &gt;  eliminate the "double door effect" discussed above, since all cells are
&gt;&gt; &gt;  allowed to flow freely out of the router once they passed the incoming rate
&gt;&gt; &gt;  limiter.
&gt;&gt; &gt;
&gt;&gt; &gt;  Second, the refill interval of the buckets should be shortened. The
&gt;&gt; &gt;  remaining token buckets should be refilled more often, with a
&gt;&gt; &gt;  correspondingly smaller amount of tokens. For instance, the buckets might
&gt;&gt; &gt;  be refilled every 10 milliseconds with one-hundredth of the amount of data
&gt;&gt; &gt;  admissible per second.
&gt;&gt;
&gt;&gt; Smaller bucket refill intervals are already implemented in Tor master
&gt;&gt; if you build with Libevent 2.0 and use the buffervents backend by
&gt;&gt; passing --enable-bufferevents to configure.  The refill interval is
&gt;&gt; currently set to 1/3 of a second, but that value was chosen more or
&gt;&gt; less at random; it would be neat to see other values benchmarked as
&gt;&gt; well.
&gt;
&gt; We did some measurements on our onion router, and also many simulations.
&gt; 1/3 second still seems far too coarse. One would have to come
&gt; significantly below the RTT of the TCP links between onion routers. We
&gt; therefore tend more towards something in the order of 1/100 s. (We did
&gt; not notice any difference in CPU utilization when we made this change -
&gt; so this apparently isn't an issue.)

Exciting!  I'd be interested to see whether this also holds with the
Libevent 2 ratelimiting code as run on a live network, or if there is
some inefficiency there that we need to address.

-- 
Nick

</body></email><email><emailId>20110124202830</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2011-01-24 20:28:30-0400</timestampReceived><subject>or-dev mailing list migration February 19, 2011</subject><body>


Hello or-dev subscribers,

On February 19, 2011, we are migrating or-dev from or-dev@seul.org to
tor-dev@lists.torproject.org.  We will migrate your e-mail address's
subscription to the new list. You will receive a confirmation from the
new mailing list software on the 19th.

Current or-dev archives will be migrated.  Roger plans to leave the
current archives in place at seul.org as well.

We're using this migration to spread administration out to Tor's
sysadmin team rather than making Roger do everything himself.  The
secondary benefits of having the lists on the torproject.org domain
include SSL-enabled login, archives, and easier account management.

You can subscribe to the new list at
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

I will send out a reminder on the day of the migration.

Please e-mail tor-assistants@torproject.org with any questions.

Thank you.

--=20
Andrew
pgp 0x74ED336B

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20110124210520</emailId><senderName>Lucky Green</senderName><senderEmail>shamrock@cypherpunks.to</senderEmail><timestampReceived>2011-01-24 21:05:20-0400</timestampReceived><subject>Fwd: Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

Looks like I did not send this (rather old email) to the mailing list as
intended. Since the discussion how far back an OS should be supported
appears to remain live and well, here ya go:


On 2010-11-22 21:06, Andrew Lewman wrote:
[...]
&gt; As for operating system support, I'm fine with supporting whatever the
&gt; current OS manufacturer (for loose meanings of organization that
&gt; creates the releases) supports.  I'd caution this with finding out what
&gt; our users actually need.  There are a many places in the world where
&gt; they use operating systems from more than 10 years ago.  If we truly
&gt; want to help people, both -alpha and -stable branches should have wide
&gt; and a variety of OS functionality.

The intuition that OS version adoption _significantly_ (i.e. by many
years) lags in certain "places in the world" is often retold, generally
without hard proof. Yet research does not support this intuition.

Just looking at Windows versions, actual surveys show Windows 98, ME,
2000, and 95 to all be well under the 1% mark of Internet connected
devices with many of these versions coming in at below 0.1%. Meaning
they are obsolete.

(PCs that never connect to the Internet, which are not part of such
automated surveys, are of course of no relevance to
Tor and we need not concern ourselves with by how many years OS versions
may or may not lag on such unconnected devices).

Detailed per-country drill-downs of OS version surveys tend to cost
money and are copyrighted, which precludes me from linking to them here.
However, global views (which include Africa, Asia, and the Middle East)
can be readily found for free on the Internet. Here is one example:
http://marketshare.hitslink.com/operating-system-market-share.aspx?qprid=10

Having seen the for-pay versions of OS version drill-downs, the
inescapable conclusion is that Windows 95, ME, 98, and 2000 are dead
world-wide. Sure, existence proof of users can be found. I had one
customer request support for Windows 3.x only a couple of years ago. And
he was from US.

The continued existence of some Windows 3.1 users however does not mean
that investing development effort into Windows 3.1 or 98 support is a
reasonable engineering trade-off for Tor when that same development
effort could be invested in adding features or improving performance on
Windows 7. Even if Tor's target market were exclusively those other
places in the world.

From a policy perspective, the standard approach when serving
international consumer markets is to support one major Windows version
back. Considering the fact that Windows 7 is basically the /real/
release of Windows Vista, this means that today Tor should run on
Windows XP, Windows Vista, and Windows 7. I believe that policy would
serve the Tor Project well.

Another important policy decision to codify is which Service Pack level
to support. Here the answer is "latest", for a number of reasons:

1) Tor will have no choice but to be compatible with the latest shipping
Service Pack due to the sheer number of users that will upgrade to the
SP upon release.

2) OS bugs that prevented an application from operating correctly prior
to a particular SP release can rarely be worked around in the
application if that workaround has not been found by the time the SP is
released. (Nor is creating such a workaround at that time an appropriate
investment of resources when a functional, no-cost, SP exists).

3) SPs are readily available to most anybody with an Internet connected
PC. Even in areas of poor bandwidth SPs tend to readily be available
in CD-R format in such communities and news of such availability quickly
spreads.

Indeed, the longest laggards in SP adoption tend not be faraway places,
but large corporate IT environments with corporate PC images that cannot
upgrade to a particular SP because of poor coding practices in
mission-critical enterprise applications that cannot be worked around
since the original dev team has long left the company and source code is
incomplete/cannot be found.

Hope this helps,
--Lucky
</body></email><email><emailId>20110125140439</emailId><senderName>Lucky Green</senderName><senderEmail>shamrock@cypherpunks.to</senderEmail><timestampReceived>2011-01-25 14:04:39-0400</timestampReceived><subject>Re: Thoughts on https://trac.torproject.org/projects/tor/wiki/dev/SupportPolicy</subject><body>

On 2011-01-25 01:09, Erinn Clark wrote:
&gt; I think supporting multiple versions back is a laudable goal, and one we should
&gt; consider, but right now it's not feasible (for me, anyway, as the primary
&gt; packager with the current infrastructure). The following is my initial sketch
&gt; of the package support policy, which is an accurate snapshot of what's
&gt; currently out there (specifically for Tor and Vidalia):

Erinn,
My feedback is that the Tor Project really, really will want a written
and published policy of how far back an OS is supposed to be supported.
Otherwise, you will get to have this discussion every time a new OS
version is released.

Industry standard for consumer software that goes into the far corners
of the world is "current and previous major version", which has
different meanings depending on OS.

I.e, in MacOS "major version" translates to "minor version number".
Also, MacOS upgrades happen quickly in the field, which means that MacOS
can have support for older versions deprecated with less pain than most
other OS'es. MacOS upgrade uptake is to Windows upgrade uptake what
Adobe Flash upgrade cycles are to Adobe Reader's.

In Windows, "current and previous major version" translates cleanly to
major version numbers, though that means that during the current Windows
cycle you have to support three versions of Windows due to Vista's
special status of Win7 market beta. A temporary oddity and burden on Tor
Release Engineering that will soon go away.

In Debian, that translates into "stable" and "oldstable". Plus of course
whatever dev and beta versions you want to support.

Similar hardcodable rules apply to other OS'es.

Supporting older OS'es, perhaps non-intuitively, leads to reduced
overall deployment of most software as coding for less-evolved IP stacks
and GUIs takes away engineering resources, constraining beneficial
features that would attract more users.

--Lucky, wearing his day job hat for brief moment.
</body></email><email><emailId>20110131222633</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-31 22:26:33-0400</timestampReceived><subject>Re: (FWD) Re: Proposal 171 (revised): Separate streams across</subject><body>

On Fri, Jan 21, 2011 at 5:22 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; [Forwarding because Nikita isn't subscribed at this address. -RD]
&gt;
&gt; ----- Forwarded message from owner-or-dev@freehaven.net -----
&gt;
&gt; From: Nikita Borisov &lt;nikita@illinois.edu&gt;
&gt; Date: Fri, 21 Jan 2011 16:00:44 -0600
&gt; Subject: Re: Proposal 171 (revised): Separate streams across circuits by
&gt;  connection metadata
&gt; To: or-dev@freehaven.net
&gt;
&gt; I have a suggestion: streams that have been explicitly designated for
&gt; isolation by the use of different ports or usernames should also use a
&gt; different set of guard nodes.  My thinking is that there have been
&gt; attacks proposed in the past that can profile the set of guard nodes
&gt; used by a client over time, as long as it's possible to externally
&gt; link the connections (e.g., the connections contain a pseudonymous
&gt; username in the cleartext).  If these attacks are used to profile two
&gt; sets of externally linkable connections (i.e., two pseudonyms) and
&gt; they come up with the same set of guards, that is a pretty strong
&gt; indication that the pseudonyms are in fact linked to each other.  If I
&gt; used a different port to separate the two pseudonyms, however, and Tor
&gt; used a different guard set for each, this would not be a problem.
&gt; Conversely, the advantage of using (the same set of) guard nodes
&gt; disappears for streams that are not externally linkable, since the
&gt; guards do not change the overall probability that each individual
&gt; stream will be compromised.
&gt;
&gt; (I think it's harder to make the case that you want to do this based
&gt; on implicit session indicators, since there's a chance that those
&gt; streams will still be somehow linked, particularly if the indicators
&gt; are short-lived, such as PIDs or source ports.)

This is a cool idea; I think it can be done orthogonally to the other
stream-separation stuff.  I've added a note to Proposal 171.

A possible issue is that number of  guard nodes used is visible to a
local adversary, who can use this to infer the number of different
session types that the user has.  I'm not sure how big of a problem
this is.

yrs,
-- 
Nick

-- 
Nick

</body></email><email><emailId>20110131225002</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-31 22:50:02-0400</timestampReceived><subject>Re: Publishing sanitized bridge pool assignments</subject><body>

On Mon, Jan 31, 2011 at 3:52 PM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
&gt; On Mon, Jan 31, 2011 at 03:03:57PM -0500, Ian Goldberg wrote:
&gt;&gt; On Mon, Jan 31, 2011 at 08:37:00PM +0100, Karsten Loesing wrote:
&gt;&gt; &gt; Here's a sample bridge pool assignment from September 2010 that is
&gt;&gt; &gt; sanitized as described above (all IP addresses set to 127.0.0.1, contained
&gt;&gt; &gt; fingerprints are SHA-1 hashes of the original fingerprints):
&gt;&gt; &gt;
&gt;&gt; &gt;   http://freehaven.net/~karsten/volatile/bridge-pool-assignment-sample
&gt;&gt; &gt;
&gt;&gt; &gt; This sample is there, so that everyone gets a better idea of what is meant
&gt;&gt; &gt; by a bridge pool assignment.  Does anyone object to publishing tarballs of
&gt;&gt; &gt; these sanitized bridge pool assignments on the metrics website, so that we
&gt;&gt; &gt; (and anyone else) can analyze them?
&gt;&gt;
&gt;&gt; Is there enough entropy in the things you're hashing to prevent
&gt;&gt; reversing the hash?
&gt;
&gt; Well, I guess so.  We're hashing the bridge identity fingerprints.  From
&gt; dir-spec.txt:
&gt;
&gt;    "fingerprint" fingerprint NL
&gt;
&gt;       [At most once]
&gt;
&gt;       A fingerprint (a HASH_LEN-byte of asn1 encoded public key, encoded in
&gt;       hex, with a single space after every 4 characters) for this router's
&gt;       identity key.
&gt;
&gt; Does this mean we're safe here?

I think we're okay.  A censor could in theory correlate this with
certificates, if it had them, but I think most automated certificate
crawlers will wind up with link certs only, so the censor will need to
do their own crawling to find bridges.

If we care a lot, we could instead have the sanitization process use
some secret X and report H(X|H(ID key)) in place of H(ID key).

-- 
Nick

</body></email><email><emailId>20110131235901</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-01-31 23:59:01-0400</timestampReceived><subject>Re: xxx-draft-spec-for-TLS-normalization.txt</subject><body>

&gt; Filename: xxx-draft-spec-for-TLS-normalization.txt
&gt; Title: Draft spec for TLS certificate and handshake normalization
&gt; Author: Jacob Appelbaum
&gt; Created: 24-Jan-2011
&gt; Status: Draft
&gt;
&gt;
&gt;         Draft spec for TLS certificate and handshake normalization
&gt;
&gt;
&gt;                                     Overview
&gt;
&gt; Scope
&gt;
&gt; This is a document that proposes improvements to problems with Tor's
&gt; current TLS (Transport Layer Security) certificates and handshake that will
&gt; reduce the distinguishability of Tor traffic from other encrypted traffic that
&gt; uses TLS.  It also addresses some of the possible fingerprinting attacks
&gt; possible against the current Tor TLS protocol setup process.
&gt;
&gt; Motivation and history
&gt;
&gt; Censorship is an arms race and this is a step forward in the defense
&gt; of Tor.  This proposal outlines ideas to make it more difficult to
&gt; fingerprint and block Tor traffic.
&gt;
&gt; Goals
&gt;
&gt; This proposal intends to normalize or remove easy-to-predict or static
&gt; values in the Tor TLS certificates and with the Tor TLS setup process.
&gt; These values can be used as criteria for the automated classification of
&gt; encrypted traffic as Tor traffic. Network observers should not be able
&gt; to trivially detect Tor merely by receiving or observing the certificate
&gt; used or advertised by a Tor relay. I also propose the creation of
&gt; a hard-to-detect covert channel through which a server can signal that it
&gt; supports the third version ("V3") of the Tor handshake protocol.

This last bit might or might not be needed; let's see how stuff looks
after my v3 protocol proposal is more discussed.


 [...]
&gt; Certificate Issues
&gt;
&gt; The CN or commonName ASN1 field
&gt;
&gt; Tor generates certificates with a predictable commonName field; the
&gt; field is within a given range of values that is specific to Tor.
&gt; Additionally, the generated host names have other undesirable properties.
&gt; The host names typically do not resolve in the DNS because the domain
&gt; names referred to are generated at random.

Also, when they do resolve, they do not resolve to any IP that the
certificate was served from.  Also, they're all .net.

 [...]
&gt; I propose that the commonName field be generated to match a specific property
&gt; of the server in question. It is reasonable to set the commonName element to
&gt; match either the hostname of the relay, the detected IP address of the relay,
&gt; or for the relay operator to override certificate generation entirely by
&gt; loading a custom certificate.   For custom certificates, see the Custom
&gt; Certificates section.
&gt;
&gt; I propose that the value for the commonName field be populated with the
&gt; fully qualified host name as detected by reverse and forward resolution of the
&gt; IP address of the relay. If the host name is in the DNS, this host name should
&gt; be set as the common name. When forward and reverse DNS is not available, I
&gt; propose that the IP address alone be used.

I'm not sure that an IP address is better than a random hostname.  Do
any CAs issue certs where the CN is an IP address?  Do many
self-signed certificates actually look that way?

If the answers are "no" and "not many", then we'll probably be better
off with randomly generated hostnames when we can't find a real
hostname to use.

&gt; The commonName field for the issuer should be set to known issuer names,
&gt; random words or omitted entirely.

There are two certificate profiles to imitate here: self-signed and
CA-issued.  For self-signed ones, both DNs typically match, I think.
This is worth checking too

 [...]
&gt; Certificate serial numbers
&gt;
&gt; Currently our generated certificate serial number is set to the of number of
&gt; seconds since the epoch at the time of the certificate's creation. I propose
&gt; that we should ensure that our serial numbers are un-related to the epoch,
&gt; since the generation methods are potentially recognizable as Tor-related.
&gt; Instead, I propose that we use a randomly generated number that is
&gt; subsequently hashed with SHA-512 and then truncated. The serial number
&gt; should be similar in bit width to commonly found certificate serial numbers
&gt; in the wild.

I'd want to back off here to see what certificates look like in the
wild.  Do they look random?  Do they look like timestamps?  Do they
increase sequentially?  Are they typically small for self-signed
certificates?

Also, taking a random number then computing its hash is redundant: if
it's random, just use it.

[...]
&gt; Certificate dating and validity issues
&gt;
&gt; TLS certificates found in the wild are generally found to be long-lived;
&gt; they are frequently old and often even expired. The current Tor certificate
&gt; validity time is a very small time window starting at generation time and
&gt; ending shortly thereafter, as defined in or.h by MAX_SSL_KEY_LIFETIME
&gt; (2*60*60).
&gt;
&gt; I propose that the certificate validity time length is extended to a period of
&gt; twelve Earth months, possibly with a small random skew to be determined by the
&gt; implementer. Tor should randomly set the start date in the past or some
&gt; currently unspecified window of time before the current date. This would
&gt; more closely track the typical distribution of non-Tor TLS certificate
&gt; expiration times.
&gt;
&gt; The certificate values, such as expiration, should not be used for anything
&gt; relating to security; for example, if the OR presents an expired TLS
&gt; certificate, this does not imply that the client should terminate the
&gt; connection (as would be appropriate for an ordinary TLS implementation).

Hm.  Tor currently *does* check validAfter and validUntil times on
certificates.  Also, we *do* want a way to say "do not treat this cert
as valid forever" as a way to limit the impact of a key compromise.

[...]
&gt; Problematic DiffieHellman parameters

We should get more data; right now, it seems that it's okay to use the
default DH parameter used by apache's mod_ssl, since it's very
frequently used in the wild.  We should only use randomly DH
parameters of some length P if it is in fact the case that such
parameters are not infrequent in the wild.

 [...]
&gt;
&gt; Practical key size
&gt;
&gt; Currently we use 1024-bit RSA keys. I propose that we increase the RSA key size
&gt; to 1280 or to 2048 as an additional channel to signal support for the V3
&gt; handshake setup. 2048 is likely a more common key size in certificates today
&gt; and also provides a reasonable security boost with regard to key security
&gt; properties.

Possibly; we should get data on this before we guess.  Also, as we
start to support longer sizes, we may want a way to advertise "maximum
allowed keysize" in the consensus to keep some wiseguy from making a
16384-bit key as a DOS attack.

&gt; The implementer should choose a key size that is common and meaningfully above
&gt; 1024 bits.
&gt;
&gt; Possible future filtering nightmares
&gt;
&gt; At some point it may cost effective or politically feasible for a network
&gt; filter to simply block all signed or unsigned certificates without a known
&gt; valid CA trust chain.

There's no such thing as an unsigned certificate; I think you mean
"self-signed."

-- 
Nick Mathewson

</body></email><email><emailId>20111101190519</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 19:05:19-0400</timestampReceived><subject>[tor-dev] is ECC patented? (was: Draft sketch document with ideas</subject><body>

A few pointers. On the happy "yay we can use it freely" side, we have:

* RFC 6090

Pure gold! A catalog of ECC techniques which were published so long
ago that they cannot still be under patent. It includes digital
signatures and Diffie-Hellman.

* DJB's page stating that certain patents don't apply to Curve25519
(which you mentioned): http://cr.yp.to/ecdh/patents.html

* Jack Lloyd's statement that he avoided techniques newer than about
1990 in Botan: https://bugzilla.redhat.com/show_bug.cgi?id=615372#c19

On the sad "no we can't use it" side, we have:

* Fedora's insistence on removing all elliptic curve cryptography from
their Linux distribution and refusing to answer questions about why:
https://bugzilla.redhat.com/show_bug.cgi?id=615372

Regards,

Zooko
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111207175159</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-12-07 17:51:59-0400</timestampReceived><subject>[tor-dev] AES_ctr128_encrypt() on Windows</subject><body>

Seems that this function isn't available in OpenSSL 1.1.0. On Windows
at least. The function is enclosed in a "#if 0" in OpenSSL's &lt;aes.h&gt; and 
util/libeay.num also has this:
  AES_ctr128_encrypt    3216    NOEXIST::FUNCTION:

So should we make an exception for Windows in common/aes.c:

--- Git-latest/src/common/aes.c      Mon Dec 05 16:54:55 2011
+++ src/common/aes.c        Wed Dec 07 18:42:37 2011
@@ -17,7 +17,7 @@
 #include &lt;openssl/aes.h&gt;
 #include &lt;openssl/evp.h&gt;
 #include &lt;openssl/engine.h&gt;
-#if OPENSSL_VERSION_NUMBER &gt;= 0x10000000L
+#if (OPENSSL_VERSION_NUMBER &gt;= 0x10000000L) &amp;&amp; !defined(MS_WINDOWS)
 /* See comments about which counter mode implementation to use below. */
 #include &lt;openssl/modes.h&gt;
 #define USE_OPENSSL_CTR

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111207182523</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-07 18:25:23-0400</timestampReceived><subject>Re: [tor-dev] AES_ctr128_encrypt() on Windows</subject><body>

On Wed, Dec 7, 2011 at 12:51 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; Seems that this function isn't available in OpenSSL 1.1.0. On Windows
&gt; at least. The function is enclosed in a "#if 0" in OpenSSL's &lt;aes.h&gt; and
&gt; util/libeay.num also has this:
&gt; =A0AES_ctr128_encrypt =A0 =A03216 =A0 =A0NOEXIST::FUNCTION:
&gt;
&gt; So should we make an exception for Windows in common/aes.c:

It looks like you're using a version of openssl that isn't actually
released.  (There is no openssl 1.1.0 yet; only a series of
not-yet-released development snapshots.)

(Also, what's with your fix?  There's nothing windows-specific about
the openssl 1.1.0 breakage here.)

-- =

Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111222053152</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-12-22 05:31:52-0400</timestampReceived><subject>[tor-dev] Browser-based proxies for circumvention</subject><body>

A few months ago, Roger wrote about ideas for getting more bridge
addresses (https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses).
One of the ideas is to make lightweight bridges that can run in a web
browser. I and some others have been working on this for a few months. I
want to promulgate our ideas and code among you developers, and ask for
your opinions and suggestions.

== Summary

The overall idea is a little applet that can be installed on a web page.
We call it a "flash proxy." As long as you have the page open in your
browser, you are a proxy. These proxies may only last a few seconds or
minutes, but the code we've written allows switching between active
proxies in a fairly transparent manner, enough to make web browsing
possible. The idea is that web browsers provide a large, diverse, and
ever-changing pool of bridge addresses. A censor will not be able to
block all of them in a timely manner--at least that's what we hope.

This is our overview and demo page. Down at the bottom of the page is a
flash proxy badge.
	https://crypto.stanford.edu/flashproxy/

It's called a "flash proxy," and the implementation happens to be in
Flash, but the "flash" should rather make you think "quick." I'm pretty
sure the same thing can be done with WebSockets or other technologies.

== Howto

You can easily but slightly artificially test the flash proxy transport
with this command:
	$ tor UseBridges 1 Bridge 127.0.0.1:9001 Socks4Proxy tor-facilitator.bamsoftware.com:9999
(Make sure a flash proxy is running somewhere, and wait about 30 seconds
for a connection.) What's artificial about this example is that the
service at tor-facilitator.bamsoftware.com:9999 (the "connector") is
something you would normally run on your own computer. We run one on the
Internet for the ease of demos like this. See the instructions in the
README for how to test it more realistically.

We are using the torproject.org git server, so our code is
	$ git clone git://git.torproject.org/flashproxy.git
	https://gitweb.torproject.org/flashproxy.git
	https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README
Though you need Adobe's Flash Player to *run* the flash proxy, you can
*build* it using only free software (details are in the README).

== Architecture

Most of the architecture is dictated by a limitation of web socket
technologies, namely that they can only make outgoing TCP connections,
and cannot receive connections. This leads to a funny model where the
proxy connects to the client, instead of the other way around.

The pieces that work together are:
 * Tor client (e.g. /usr/sbin/tor on the local host).
 * Tor relay (e.g. /usr/sbin/tor on the Internet).
 * Flash proxy, running in someone's web browser. Imagine that there are
   many of these online at once, but they have a lifetime on the order
   of minutes.
 * Connector, a little program that sits between the flash proxy and the
   Tor client, and receives connections from the proxy. It acts as an
   upstream SOCKS4 proxy to Tor (but ignores whatever address Tor gives
   it). The connector also does the switching between proxies as they go
   offline.
 * Facilitator, which keeps track of clients that need addresses, and
   gives those addresses to proxies as they come online. We are running
   one of these at tor-facilitator.bamsoftware.com:9002.

A sample session goes like this:
1. The user starts a connector and a Tor client. The connector sends its
   address to the facilitator, so that a proxy will know where to
   connect to. (We call this step "rendezvous.")
2. A flash proxy appears in a browser and asks the facilitator for an
   address.
3. The facilitator sends a remembered client address to the proxy.
4. The proxy connects to the client address. The client's connector
   receives the connection.
5. The proxy connects to a Tor relay, then begins copying data between
   its two sockets.

Something to note is that the flash proxy doesn't do any crypto. It is
just a dumb pipe for ciphertext. There are still three relay hops after
the proxy. (But the proxy effectively gets to pick the first hop.)

== Objections

Doesn't this shift the problem from bridges begin blocked to the
facilitator being blocked, since the client has to send its address to
the facilitator? The short answer is yes, we expect the facilitator to
be permanently blocked by IP address, so the client must find a covert,
uncensorable channel over which to rendezvous. The good news is that
we've turned a big problem--how to make all your Tor traffic
unblockable--into a small problem--how to make a one-time, write-only
connection of a dozen bytes unblockable. This lesser constraint opens up
new possibilities, for example you could email your address to someone
you know and have them rendezvous on your behalf, even though you
couldn't push all your Tor traffic over such a channel.

Isn't blocking by protocol/DPI still possible? Yes, there are many
components to circumvention, and bridge creation is just one part.
Against such a censor it will be necessary to layer some kind of
obfuscation, but that's an issue of its own. It also may be a revealing
signature for a client IP address to receive lots of incoming
connections, but how much this stands out we don't know yet.

== Shortcomings

I should mention that the implementation doesn't live up to everything
I've stated above. The "rendezvous" step is just an HTTP POST to the
facilitator. Also, the connector re-registers itself unnecessarily: that
should happen only once, and thereafter the facilitator should remember
it.

== Next steps

Here are the next things I'd like to accomplish:

* Get the proxy installed on more blogs and web pages. Currently it's
  only on the demo page and on my web site, which only provide enough
  proxies to have service about 60% of the time.
* Implement a bona fide rendezvous protocol. Though this is somewhat
  separable from flash proxies themselves, it's essential for a complete
  working system. We have done a couple of limited prototypes; please
  ask me if you are interested in or have knowledge of this.
* Build an installer for client programs.
* Try a plain JavaScript proxy.

Unfortunately this has been very much a spare-time project for me. I'd
love to share some of this development with anyone who's interested.
I've had a couple of people contact me about possibly supporting
development in various ways.

But what I'd like most of all are your comments and ideas. I really want
to invite discussion on the architecture, with the goal of making it
robust and secure. Though the system is already partly usable, I still
consider it a research project, not a finished product. Circumvention is
such a big topic I haven't covered all the details in this message, so I
value your clarifying questions.

David Fifield
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104173712</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-04 17:37:12-0400</timestampReceived><subject>[tor-dev] Proposal 190: Password-based Bridge Client Authorization</subject><body>


Filename: 190-password-bridge-authorization.txt
Title: Password-based Bridge Client Authorization
Author: George Kadianakis
Created: 04 Nov 2011
Status: Open

1. Overview

   Proposals 187 and 189 introduced the AUTHORIZE and AUTHORIZED cells.
   Their purpose is to make bridge relays scanning resistant against
   censoring adversaries capable of probing hosts to observe whether
   they speak the Tor protocol.

   This proposal specifies a bridge client authorization scheme based
   on a shared password between the bridge user and bridge operator.

2. Motivation

   A proper bridge client authorization scheme should:

   - request information from a client that only an authorized bridge
     client would know.

   - ensure that the shared secret sent by the bridge client during
     the authorization can only be read and validated by the proper
     bridge relay. This is important since the v3 link handshake which
     authenticates the bridge to the client is carried out *after* the
     bridge client authorization, which means that when the AUTHORIZE
     cell is sent, the client might be actually speaking to a Man In
     The Middle.

   The bridge client authorization scheme presented in this proposal
   is based on a shared password and attempts to satisfy both of the
   above requirements.

3. Design

   If the AuthMethod of an AUTHORIZE cell is '0x1', the client wants
   to become authorized using a shared secret based on a password.

   The short name of this authorization scheme is 'BRIDGE_AUTH_PSK'.

3.1. Notation

   '||', denotes concatenation.

   'HMAC(k, m)', is the Hash-based Message Authentication Code of
                 message 'm' using 'k' as the secret key.

   'H(m)', is a cryptographic hash function applied on a message 'm'.

   'HASH_LEN', is the output size of the hash function 'H'.

3.2. Shared secret format

   A bridge client and a bridge relay willing to use this
   authorization scheme, should have already exchanged out-of-band
   (for example, during the bridge credentials exchange) a shared
   password.

   In this case, the shared secret of this scheme becomes:

      shared_secret = H( H(bridge_identity_key) || ":" || password)

   where:

   'bridge_identity_key', is the PKCS#1 ASN1 encoding of the bridge's
                          public identity key.

   '":"', is the colon character (0x3a in UTF-8).

   'password', is the bridge password.

3.3. Password-based authorization AUTHORIZE cell format

   In password-based authorization, the MethodFields field of the
   AUTHORIZE cell becomes:

       'HMAC(shared_secret, tls_cert)'               [HASH_LEN octets]

   where:

   'HMAC(shared_secret, tls_cert), is the HMAC construction of the TLS
   certificate of the bridge relay, using the shared secret of section
   3.2 as the secret key.

3.4. Password-based authorization notes

   Bridge implementations MUST reject clients who provide malformed
   AUTHORIZE cells or HMAC values that do not verify the appropriate
   TLS certificate.

   Bridge implementations SHOULD provide an easy way to create and
   change the bridge shared secret.

3.5. Security arguments

   An adversary who does not know the 'shared_secret' of a bridge
   cannot construct an HMAC that verifies its TLS certificate when
   used with the correct 'shared_secret'.

   An adversary who attempts to MITM the TLS connection of a bridge
   user to steal the 'shared_secret' will instead steal an HMAC value
   created by the 'tls_cert' of the TLS certificate that the attacker
   used to MITM the TLS connection. Replaying that 'shared_secret'
   value to the actual bridge will fail to verify the correct
   'tls_cert'.

   The two above paragraphs resolve the requirements of the
   'Motivation' section.

   Furthermore, an adversary who compromises a bridge, steals the
   shared secret and attempts to replay it to other bridges of the
   same bridge operator will fail since each shared secret has a
   digest of the bridge's identity key baked in it.

   The bridge's identity key digest also serves as a salt to counter
   rainbow table precomputation attacks.

4. Tor implementation

   The Tor implementation of the above scheme uses SHA256 as the hash
   function 'H'.

   SHA256 also makes HASH_LEN equal to 32.

5. Discussion

5.1. Do we need more authorization schemes?

   Probably yes.

   The centuries-old problem with passwords is that humans can't get
   their passwords right.

   To avoid problems associated with the human condition, schemes
   based on public key cryptography and certificates can be used. A
   public and well tested protocol that can be used as the basis of a
   future authorization scheme is the SSH "publickey" authorization
   protocol.

5.2. What should actually happen when a bridge rejects an AUTHORIZE
     cell?

   When a bridge detects a badly formed or malicious AUTHORIZE cell,
   it should assume that the other side is an adversary scanning for
   bridges. The bridge should then act accordingly to avoid detection.

   This proposal does not try to specify how a bridge can avoid
   detection by an adversary.

6. Acknowledgements

   Without Nick Mathewson and Robert Ransom this proposal would
   actually be specifying a useless and broken authentication scheme.
   Thanks!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104193120</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-04 19:31:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 190: Password-based Bridge Client</subject><body>

On 2011-11-04, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt;
&gt; Filename: 190-password-bridge-authorization.txt
&gt; Title: Password-based Bridge Client Authorization
&gt; Author: George Kadianakis
&gt; Created: 04 Nov 2011
&gt; Status: Open
&gt;
&gt; 1. Overview
&gt;
&gt;    Proposals 187 and 189 introduced the AUTHORIZE and AUTHORIZED cells.
&gt;    Their purpose is to make bridge relays scanning resistant against
&gt;    censoring adversaries capable of probing hosts to observe whether
&gt;    they speak the Tor protocol.
&gt;
&gt;    This proposal specifies a bridge client authorization scheme based
&gt;    on a shared password between the bridge user and bridge operator.
&gt;
&gt; 2. Motivation
&gt;
&gt;    A proper bridge client authorization scheme should:
&gt;
&gt;    - request information from a client that only an authorized bridge
&gt;      client would know.

   - request information from a client that only an authorized client
     of the bridge would know.


&gt;    - ensure that the shared secret sent by the bridge client during
&gt;      the authorization can only be read and validated by the proper
&gt;      bridge relay.

The shared secret cannot be read by the bridge relay, only validated.
(That's a feature.)


&gt;                    This is important since the v3 link handshake which
&gt;      authenticates the bridge to the client is carried out *after* the
&gt;      bridge client authorization, which means that when the AUTHORIZE
&gt;      cell is sent, the client might be actually speaking to a Man In
&gt;      The Middle.

And the reason that the client might be speaking to a MITM attacker is
that the client has no way to determine whether it should accept
whatever link certificate chain it receives.  Hmm.


&gt;    The bridge client authorization scheme presented in this proposal
&gt;    is based on a shared password and attempts to satisfy both of the
&gt;    above requirements.
&gt;
&gt; 3. Design
&gt;
&gt;    If the AuthMethod of an AUTHORIZE cell is '0x1', the client wants
&gt;    to become authorized using a shared secret based on a password.
&gt;
&gt;    The short name of this authorization scheme is 'BRIDGE_AUTH_PSK'.
&gt;
&gt; 3.1. Notation
&gt;
&gt;    '||', denotes concatenation.
&gt;
&gt;    'HMAC(k, m)', is the Hash-based Message Authentication Code of
&gt;                  message 'm' using 'k' as the secret key.
&gt;
&gt;    'H(m)', is a cryptographic hash function applied on a message 'm'.
&gt;
&gt;    'HASH_LEN', is the output size of the hash function 'H'.
&gt;
&gt; 3.2. Shared secret format
&gt;
&gt;    A bridge client and a bridge relay willing to use this
&gt;    authorization scheme, should have already exchanged out-of-band
&gt;    (for example, during the bridge credentials exchange) a shared
&gt;    password.
&gt;
&gt;    In this case, the shared secret of this scheme becomes:
&gt;
&gt;       shared_secret = H( H(bridge_identity_key) || ":" || password)
&gt;
&gt;    where:
&gt;
&gt;    'bridge_identity_key', is the PKCS#1 ASN1 encoding of the bridge's
&gt;                           public identity key.
&gt;
&gt;    '":"', is the colon character (0x3a in UTF-8).
&gt;
&gt;    'password', is the bridge password.

At the time that the client needs to compute shared_secret from
password (before it receives a CERT cell from the bridge for the first
time), the client does not know the bridge's identity key.

There is no reason to have shared_secret and password be different
strings.


&gt; 3.3. Password-based authorization AUTHORIZE cell format
&gt;
&gt;    In password-based authorization, the MethodFields field of the
&gt;    AUTHORIZE cell becomes:
&gt;
&gt;        'HMAC(shared_secret, tls_cert)'               [HASH_LEN octets]
&gt;
&gt;    where:
&gt;
&gt;    'HMAC(shared_secret, tls_cert), is the HMAC construction of the TLS
&gt;    certificate of the bridge relay, using the shared secret of section
&gt;    3.2 as the secret key.

Which TLS certificate, encoded in what way?  (The bridge may send a
CA-signed certificate and its issuer chain.)


&gt; 3.4. Password-based authorization notes
&gt;
&gt;    Bridge implementations MUST reject clients who provide malformed
&gt;    AUTHORIZE cells or HMAC values that do not verify the appropriate
&gt;    TLS certificate.
&gt;
&gt;    Bridge implementations SHOULD provide an easy way to create and
&gt;    change the bridge shared secret.
&gt;
&gt; 3.5. Security arguments
&gt;
&gt;    An adversary who does not know the 'shared_secret' of a bridge
&gt;    cannot construct an HMAC that verifies its TLS certificate when
&gt;    used with the correct 'shared_secret'.
&gt;
&gt;    An adversary who attempts to MITM the TLS connection of a bridge
&gt;    user to steal the 'shared_secret' will instead steal an HMAC value
&gt;    created by the 'tls_cert' of the TLS certificate that the attacker
&gt;    used to MITM the TLS connection. Replaying that 'shared_secret'
&gt;    value to the actual bridge will fail to verify the correct
&gt;    'tls_cert'.

An adversary who MITMs the TLS connection and receives a Tor AUTHORIZE
cell will know that the client is trying to connect to a Tor bridge.

Should the client send a string of the form "GET
/?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
cell, where "correct+horse+battery+staple" is a semi-plausible search
phrase derived from the HMAC in some way?


&gt;    The two above paragraphs resolve the requirements of the
&gt;    'Motivation' section.
&gt;
&gt;    Furthermore, an adversary who compromises a bridge, steals the
&gt;    shared secret and attempts to replay it to other bridges of the
&gt;    same bridge operator will fail since each shared secret has a
&gt;    digest of the bridge's identity key baked in it.

Where do passwords come from?

In my opinion, each Tor bridge configured to require a password should
generate its own password, as a sufficiently long random string.  80
bits of entropy should be far more than enough for a bridge password.
In this case, different bridges should never have the same password.


&gt;    The bridge's identity key digest also serves as a salt to counter
&gt;    rainbow table precomputation attacks.

Precomputation should not be useful if each password contains 80 bits
of entropy.  The bridge's identity key digest is not used in the
protocol specified above; only the identity key itself.


&gt; 4. Tor implementation
&gt;
&gt;    The Tor implementation of the above scheme uses SHA256 as the hash
&gt;    function 'H'.
&gt;
&gt;    SHA256 also makes HASH_LEN equal to 32.
&gt;
&gt; 5. Discussion
&gt;
&gt; 5.1. Do we need more authorization schemes?
&gt;
&gt;    Probably yes.
&gt;
&gt;    The centuries-old problem with passwords is that humans can't get
&gt;    their passwords right.

Passwords used for this purpose should be provided to clients as part
of a Bridge torrc line, in either written or electronic form.  The
user will not retype them every time he/she/it starts Tor.


&gt;    To avoid problems associated with the human condition, schemes
&gt;    based on public key cryptography and certificates can be used. A
&gt;    public and well tested protocol that can be used as the basis of a
&gt;    future authorization scheme is the SSH "publickey" authorization
&gt;    protocol.

Secret keys for DSA (with a fixed group) and EC-based signature
schemes can be short enough to be fairly easy to transport.  Secret
keys for RSA are a PITA to transport, unless you either (a) specify a
deterministic key-generation procedure, or (b) make the public key
available to all clients somehow, and provide enough information to
clients intended to access a bridge that the client can factor the
modulus efficiently.


&gt; 5.2. What should actually happen when a bridge rejects an AUTHORIZE
&gt;      cell?
&gt;
&gt;    When a bridge detects a badly formed or malicious AUTHORIZE cell,
&gt;    it should assume that the other side is an adversary scanning for
&gt;    bridges. The bridge should then act accordingly to avoid detection.
&gt;
&gt;    This proposal does not try to specify how a bridge can avoid
&gt;    detection by an adversary.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104194100</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-04 19:41:00-0400</timestampReceived><subject>Re: [tor-dev] Proposal 190: Password-based Bridge Client</subject><body>

On 2011-11-04, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On 2011-11-04, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:

&gt;&gt;    To avoid problems associated with the human condition, schemes
&gt;&gt;    based on public key cryptography and certificates can be used. A
&gt;&gt;    public and well tested protocol that can be used as the basis of a
&gt;&gt;    future authorization scheme is the SSH "publickey" authorization
&gt;&gt;    protocol.
&gt;
&gt; Secret keys for DSA (with a fixed group) and EC-based signature
&gt; schemes can be short enough to be fairly easy to transport.  Secret
&gt; keys for RSA are a PITA to transport, unless you either (a) specify a
&gt; deterministic key-generation procedure, or (b) make the public key
&gt; available to all clients somehow, and provide enough information to
&gt; clients intended to access a bridge that the client can factor the
&gt; modulus efficiently.

Um.  On second thought, this is just freaking ridiculous (especially
my paragraph).  We don't want each client to have to generate a
public-key authentication keypair and send its public key to the
bridge in advance; that would be a nightmare to implement with our
current bridge infrastructure.

So the only sensible ways to use public-key authentication seems to be
to give the same secret key to every authorized client (i.e.
distribute it like a password) (see Telex), and then we might as well
use a (shorter) shared-secret password (unless we need magic features
of a specific cryptosystem like the public-key steganography' used in
Telex).


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111222073721</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-12-22 07:37:21-0400</timestampReceived><subject>Re: [tor-dev] Browser-based proxies for circumvention</subject><body>

On 12/21/2011 09:31 PM, David Fifield wrote:
&gt; A few months ago, Roger wrote about ideas for getting more bridge
&gt; addresses (https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses).
&gt; One of the ideas is to make lightweight bridges that can run in a web
&gt; browser. I and some others have been working on this for a few months. I
&gt; want to promulgate our ideas and code among you developers, and ask for
&gt; your opinions and suggestions.


Thanks, I think this is great work!

&gt; 
&gt; == Summary
&gt; 
&gt; The overall idea is a little applet that can be installed on a web page.
&gt; We call it a "flash proxy." As long as you have the page open in your
&gt; browser, you are a proxy. These proxies may only last a few seconds or
&gt; minutes, but the code we've written allows switching between active
&gt; proxies in a fairly transparent manner, enough to make web browsing
&gt; possible. The idea is that web browsers provide a large, diverse, and
&gt; ever-changing pool of bridge addresses. A censor will not be able to
&gt; block all of them in a timely manner--at least that's what we hope.
&gt; 
&gt; This is our overview and demo page. Down at the bottom of the page is a
&gt; flash proxy badge.
&gt; 	https://crypto.stanford.edu/flashproxy/
&gt; 
&gt; It's called a "flash proxy," and the implementation happens to be in
&gt; Flash, but the "flash" should rather make you think "quick." I'm pretty
&gt; sure the same thing can be done with WebSockets or other technologies.
&gt; 

That was my read at first - has anyone tried the basic concept with
WebSockets?

&gt; == Howto
&gt; 
&gt; You can easily but slightly artificially test the flash proxy transport
&gt; with this command:
&gt; 	$ tor UseBridges 1 Bridge 127.0.0.1:9001 Socks4Proxy tor-facilitator.bamsoftware.com:9999
&gt; (Make sure a flash proxy is running somewhere, and wait about 30 seconds
&gt; for a connection.) What's artificial about this example is that the
&gt; service at tor-facilitator.bamsoftware.com:9999 (the "connector") is
&gt; something you would normally run on your own computer. We run one on the
&gt; Internet for the ease of demos like this. See the instructions in the
&gt; README for how to test it more realistically.
&gt; 

That worked for me as expected:
Dec 21 23:29:08.000 [notice] new bridge descriptor '3VXRyxz67OeRoqHn'
(fresh): $7C03D29CA58BE8EED5F483F31A2DEDF6FD7CC444~3VXRyxz67OeRoqHn at
127.0.0.1

&gt; We are using the torproject.org git server, so our code is
&gt; 	$ git clone git://git.torproject.org/flashproxy.git
&gt; 	https://gitweb.torproject.org/flashproxy.git
&gt; 	https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README
&gt; Though you need Adobe's Flash Player to *run* the flash proxy, you can
&gt; *build* it using only free software (details are in the README).
&gt; 

Thanks for ensuring that this works with Free Software!

&gt; == Architecture
&gt; 
&gt; Most of the architecture is dictated by a limitation of web socket
&gt; technologies, namely that they can only make outgoing TCP connections,
&gt; and cannot receive connections. This leads to a funny model where the
&gt; proxy connects to the client, instead of the other way around.
&gt; 
&gt; The pieces that work together are:
&gt;  * Tor client (e.g. /usr/sbin/tor on the local host).
&gt;  * Tor relay (e.g. /usr/sbin/tor on the Internet).
&gt;  * Flash proxy, running in someone's web browser. Imagine that there are
&gt;    many of these online at once, but they have a lifetime on the order
&gt;    of minutes.
&gt;  * Connector, a little program that sits between the flash proxy and the
&gt;    Tor client, and receives connections from the proxy. It acts as an
&gt;    upstream SOCKS4 proxy to Tor (but ignores whatever address Tor gives
&gt;    it). The connector also does the switching between proxies as they go
&gt;    offline.
&gt;  * Facilitator, which keeps track of clients that need addresses, and
&gt;    gives those addresses to proxies as they come online. We are running
&gt;    one of these at tor-facilitator.bamsoftware.com:9002.
&gt; 

This all reduces to a very time limited set of bridges - they provide
availability and nothing more.

&gt; A sample session goes like this:
&gt; 1. The user starts a connector and a Tor client. The connector sends its
&gt;    address to the facilitator, so that a proxy will know where to
&gt;    connect to. (We call this step "rendezvous.")
&gt; 2. A flash proxy appears in a browser and asks the facilitator for an
&gt;    address.
&gt; 3. The facilitator sends a remembered client address to the proxy.
&gt; 4. The proxy connects to the client address. The client's connector
&gt;    receives the connection.
&gt; 5. The proxy connects to a Tor relay, then begins copying data between
&gt;    its two sockets.

Where is the list of all facilitators?

&gt; 
&gt; Something to note is that the flash proxy doesn't do any crypto. It is
&gt; just a dumb pipe for ciphertext. There are still three relay hops after
&gt; the proxy. (But the proxy effectively gets to pick the first hop.)
&gt; 

Perhaps TLS or HTTP would be a good idea? If the blocking of bridges is
done by protocol fingerprinting, I worry that this will also be
automatically blocked.

&gt; == Objections
&gt; 
&gt; Doesn't this shift the problem from bridges begin blocked to the
&gt; facilitator being blocked, since the client has to send its address to
&gt; the facilitator? The short answer is yes, we expect the facilitator to
&gt; be permanently blocked by IP address, so the client must find a covert,
&gt; uncensorable channel over which to rendezvous. The good news is that
&gt; we've turned a big problem--how to make all your Tor traffic
&gt; unblockable--into a small problem--how to make a one-time, write-only
&gt; connection of a dozen bytes unblockable. This lesser constraint opens up
&gt; new possibilities, for example you could email your address to someone
&gt; you know and have them rendezvous on your behalf, even though you
&gt; couldn't push all your Tor traffic over such a channel.

DNS names generated from a shared secret come to mind.

&gt; Isn't blocking by protocol/DPI still possible? Yes, there are many
&gt; components to circumvention, and bridge creation is just one part.
&gt; Against such a censor it will be necessary to layer some kind of
&gt; obfuscation, but that's an issue of its own. It also may be a revealing
&gt; signature for a client IP address to receive lots of incoming
&gt; connections, but how much this stands out we don't know yet.
&gt; 

You could transform the Tor client's first hop into something that looks
a lot like HTTP. I think sjm was working on this?

&gt; == Shortcomings
&gt; 
&gt; I should mention that the implementation doesn't live up to everything
&gt; I've stated above. The "rendezvous" step is just an HTTP POST to the
&gt; facilitator. Also, the connector re-registers itself unnecessarily: that
&gt; should happen only once, and thereafter the facilitator should remember
&gt; it.
&gt; 
&gt; == Next steps
&gt; 
&gt; Here are the next things I'd like to accomplish:
&gt; 
&gt; * Get the proxy installed on more blogs and web pages. Currently it's
&gt;   only on the demo page and on my web site, which only provide enough
&gt;   proxies to have service about 60% of the time.

I think the demo text is missing some bytes?

&gt; * Implement a bona fide rendezvous protocol. Though this is somewhat
&gt;   separable from flash proxies themselves, it's essential for a complete
&gt;   working system. We have done a couple of limited prototypes; please
&gt;   ask me if you are interested in or have knowledge of this.

Do you mean something similar to the way GNUnet does nat punching?

&gt; * Build an installer for client programs.

This would be good to bundle in the Tor Browser bundle, I bet.

&gt; * Try a plain JavaScript proxy.

I like that idea very much - I don't use Adobe anything and while I'd
like to try it with Gnash, I'm not sure that Gnash is ready, is it?

&gt; Unfortunately this has been very much a spare-time project for me. I'd
&gt; love to share some of this development with anyone who's interested.
&gt; I've had a couple of people contact me about possibly supporting
&gt; development in various ways.
&gt; 

Thanks for working on this!

&gt; But what I'd like most of all are your comments and ideas. I really want
&gt; to invite discussion on the architecture, with the goal of making it
&gt; robust and secure. Though the system is already partly usable, I still
&gt; consider it a research project, not a finished product. Circumvention is
&gt; such a big topic I haven't covered all the details in this message, so I
&gt; value your clarifying questions.
&gt; 

Have you tried this with gnash?

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111222183000</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-12-22 18:30:00-0400</timestampReceived><subject>Re: [tor-dev] Browser-based proxies for circumvention</subject><body>

On Wed, Dec 21, 2011 at 11:37:21PM -0800, Jacob Appelbaum wrote:
&gt; On 12/21/2011 09:31 PM, David Fifield wrote:
&gt; &gt; This is our overview and demo page. Down at the bottom of the page is a
&gt; &gt; flash proxy badge.
&gt; &gt; 	https://crypto.stanford.edu/flashproxy/
&gt; &gt; 
&gt; &gt; It's called a "flash proxy," and the implementation happens to be in
&gt; &gt; Flash, but the "flash" should rather make you think "quick." I'm pretty
&gt; &gt; sure the same thing can be done with WebSockets or other technologies.
&gt; &gt; 
&gt; 
&gt; That was my read at first - has anyone tried the basic concept with
&gt; WebSockets?

Thank you for giving it a try! That means a lot to me.

No one has tried it, as far as I know. The only vaguely tricky part is
that you need a shim at both ends to convert the WebSocket into a normal
socket. On the client side, we would build it into the connector. On the
relay side, there would have to be some tiny proxy to receive the
WebSocket connection and forward it to Tor. A similar shim is needed
when using Flash sockets--you have to serve a "crossdomain policy" or
Flash will refuse to connect. connector.py and crossdomain.py do this.

&gt; &gt; == Howto
&gt; &gt; 
&gt; &gt; You can easily but slightly artificially test the flash proxy transport
&gt; &gt; with this command:
&gt; &gt; 	$ tor UseBridges 1 Bridge 127.0.0.1:9001 Socks4Proxy tor-facilitator.bamsoftware.com:9999
&gt; &gt; (Make sure a flash proxy is running somewhere, and wait about 30 seconds
&gt; &gt; for a connection.) What's artificial about this example is that the
&gt; &gt; service at tor-facilitator.bamsoftware.com:9999 (the "connector") is
&gt; &gt; something you would normally run on your own computer. We run one on the
&gt; &gt; Internet for the ease of demos like this. See the instructions in the
&gt; &gt; README for how to test it more realistically.
&gt; &gt; 
&gt; 
&gt; That worked for me as expected:
&gt; Dec 21 23:29:08.000 [notice] new bridge descriptor '3VXRyxz67OeRoqHn'
&gt; (fresh): $7C03D29CA58BE8EED5F483F31A2DEDF6FD7CC444~3VXRyxz67OeRoqHn at
&gt; 127.0.0.1

Something I should mention is that the "127.0.0.1:9001" actually has no
meaning in this case. You can substitute any address. The connector,
acting as a SOCKS proxy, is going to throw that address away and you get
connected to wherever you get connected to--the local Tor just thinks
that the bridge is at 127.0.0.1.

&gt; Thanks for ensuring that this works with Free Software!
&gt; 
&gt; &gt; == Architecture
&gt; &gt; 
&gt; &gt; Most of the architecture is dictated by a limitation of web socket
&gt; &gt; technologies, namely that they can only make outgoing TCP connections,
&gt; &gt; and cannot receive connections. This leads to a funny model where the
&gt; &gt; proxy connects to the client, instead of the other way around.
&gt; &gt; 
&gt; 
&gt; This all reduces to a very time limited set of bridges - they provide
&gt; availability and nothing more.

Yes, that's a good way to think about it. Rather than creating new
full-fledged bridges, we create disposable addresses by which they may
be accessed.

&gt; &gt; A sample session goes like this:
&gt; &gt; 1. The user starts a connector and a Tor client. The connector sends its
&gt; &gt;    address to the facilitator, so that a proxy will know where to
&gt; &gt;    connect to. (We call this step "rendezvous.")
&gt; &gt; 2. A flash proxy appears in a browser and asks the facilitator for an
&gt; &gt;    address.
&gt; &gt; 3. The facilitator sends a remembered client address to the proxy.
&gt; &gt; 4. The proxy connects to the client address. The client's connector
&gt; &gt;    receives the connection.
&gt; &gt; 5. The proxy connects to a Tor relay, then begins copying data between
&gt; &gt;    its two sockets.
&gt; 
&gt; Where is the list of all facilitators?

There is only one (not that there couldn't be more), and its address is
hardcoded into the proxy badge.

&gt; &gt; Something to note is that the flash proxy doesn't do any crypto. It is
&gt; &gt; just a dumb pipe for ciphertext. There are still three relay hops after
&gt; &gt; the proxy. (But the proxy effectively gets to pick the first hop.)
&gt; &gt; 
&gt; 
&gt; Perhaps TLS or HTTP would be a good idea? If the blocking of bridges is
&gt; done by protocol fingerprinting, I worry that this will also be
&gt; automatically blocked.

I hadn't thought of that. I recall looking up whether Flash can do TLS
sockets a few months ago, and it couldn't then, at least not in Flash
Player in a browser. But I just found this beta reference for the newest
Flash Player:
http://help.adobe.com/en_US/FlashPlatform/beta/reference/actionscript/3/flash/net/SecureSocket.html

&gt; &gt; == Next steps
&gt; &gt; 
&gt; &gt; Here are the next things I'd like to accomplish:
&gt; &gt; 
&gt; &gt; * Get the proxy installed on more blogs and web pages. Currently it's
&gt; &gt;   only on the demo page and on my web site, which only provide enough
&gt; &gt;   proxies to have service about 60% of the time.
&gt; 
&gt; I think the demo text is missing some bytes?

Do you mean the 'src="//crypto.st..."'? That just means to use http on
http pages, and https on https, so you don't get mixed-content warnings.
Though I guess just fixing https would also do that.

&gt; &gt; * Implement a bona fide rendezvous protocol. Though this is somewhat
&gt; &gt;   separable from flash proxies themselves, it's essential for a complete
&gt; &gt;   working system. We have done a couple of limited prototypes; please
&gt; &gt;   ask me if you are interested in or have knowledge of this.
&gt; 
&gt; Do you mean something similar to the way GNUnet does nat punching?

Not exactly; NAT punching is related but different. While we were
designing this I did some reading on GNUnet and pwnat (I think that's
what you're referring to) and thought it wouldn't work for us. The
problem is that the "client" (a flash proxy) can't use raw sockets to
craft the time exceeded message.

By "rendezvous" we mean: How does a client send a request for service
out through the censor? (More generally, it's any way by which clients
and bridges get to know one another, for example I think of BridgeDB as
a rendezvous mechanism.)

I can give you an idea of ideas we've thought of or tried:
* Writing client registrations to append-only volumes on
  multiple cloud storage providers. The facilitator (which alone has
  read access) polls from these.
* Encrypting a message of the form "register X.X.X.X" and embedding it
  in a session cookie or other random field to a friendly web server.
  The server, if it is able to decrypt the cookie intelligibly,
  registers X.X.X.X in the background and returns whatever web page it
  was going to return. This requires having enough friendly web servers
  that they can't just be blocked. With identity-based encryption,
  clients don't have to know a server's private key in advance.
* A similar idea that uses the cooperation of ISPs rather than web
  servers is Telex (https://telex.cc/). I think this could also be used
  for rendezvous.

&gt; &gt; * Try a plain JavaScript proxy.
&gt; 
&gt; I like that idea very much - I don't use Adobe anything and while I'd
&gt; like to try it with Gnash, I'm not sure that Gnash is ready, is it?

I tried Gnash and Lightspark early on, but I couldn't make them work. (I
think they didn't support sockets, or didn't support ActionScript 3, or
something.) I think a JavaScript implementation would obviate the need
for Flash Player better than a port to Gnash or similar.

ActionScript source code (the source code for Flash programs) is
basically JavaScript with some funny type suffixes and a different
standard library. So maybe a port wouldn't be too difficult.
	https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/swfcat.as
	https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/ProxyPair.as
In fact if you go way back in the git history, you'll find my first
prototype called jscat, which used the Rhino JS engine.

David Fifield
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111201144016</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-01 14:40:16-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance against</subject><body>

On Mon, Nov 7, 2011 at 6:46 PM, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt;
&gt;
&gt; Filename: XXX-mitm-bridge-detection-resistance.txt
&gt; Title: Bridge Detection Resistance against MITM-capable Adversaries
&gt; Author: George Kadianakis
&gt; Created: 07 Nov 2011
&gt; Status: Open
&gt;

This is added as proposal 191.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111201144045</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-01 14:40:45-0400</timestampReceived><subject>Re: [tor-dev] Automatically retrieve and store information about</subject><body>

On Wed, Nov 30, 2011 at 5:31 PM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:
&gt; Filename: xxx-store-bridge-information.txt
&gt; Title: Automatically retrieve and store information about bridges
&gt; Author: Sebastian Hahn
&gt; Created: 16-Nov-2011
&gt; Status: Open
&gt; Target: 0.2.[45].x
&gt;

This is now proposal 192.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111206132158</emailId><senderName>Rob van der Hoeven</senderName><senderEmail>robvanderhoeven@ziggo.nl</senderEmail><timestampReceived>2011-12-06 13:21:58-0400</timestampReceived><subject>[tor-dev] routers as bridges</subject><body>

In July i posted a message on this list proposing to use a router as a
Tor bridge. Recently i liberated one of my routers with OpenWrt which
made it possible to test this idea. Seems to work. Wrote a small article
about it on my blog:

http://freedomboxblog.nl/routers-as-tor-bridges/

Cheers,
Rob.

http://freedomboxblog.nl


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111206134444</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-12-06 13:44:44-0400</timestampReceived><subject>[tor-dev] Reduce TBB/OSX from 32MB to 23MB</subject><body>

Hi all,

made the following tricks that you can find attached to reduce the size
of TBB/OSX from 32MB to 23MB .

With this tricks it's possible to send TBB/OSX via Gmail using Gettor.

It goes from:
 32M    /tmp/TorBrowser-2.2.34-3-dev-osx-x86_64-en-US.zip
to
 23M    /tmp/TorBrowser-7z-wrap2.2.34-3-dev-osx-x86_64-en-US.zip


Probably it would require some better cleanup and integration, that's
just a working poc.

-naif

["osx_tbb_reduce.txt" (text/plain)]

# Reducing TBB from 32MB to 23MB 

# PRE-REQ
# Download TBB OSX
cd /tmp/
wget https://www.torproject.org/dist/torbrowser/osx/TorBrowser-2.2.34-3-dev-osx-x86_64-en-US.zip
 # Size is 32MB
# du -sh /tmp/TorBrowser-2.2.34-3-dev-osx-x86_64-en-US.zip 
 32M	/tmp/TorBrowser-2.2.34-3-dev-osx-x86_64-en-US.zip

# Install p7zip binary on system
# we use brew https://github.com/mxcl/homebrew
brew install p7zip

# Unzip TBB
 unzip TorBrowser-2.2.34-3-dev-osx-x86_64-en-US.zip

 cd TorBrowser_en-US.app/Contents/MacOS
 cp -pr /usr/local/Cellar/p7zip/9.20.1/ p7zip

# Strip strippable files (-1MB of uncompressed size)
 find . -type f -exec strip -S -x -X {} \; 2&gt; /dev/null

# Compress Firefox.app, Vidalia.app and tor
# Using those parameters we can save 1.5MB of additional size
 p7zip/lib/p7zip/7z a -mx=9 -md=64m -mfb=256 Firefox.app.7z Firefox.app
 p7zip/lib/p7zip/7z a -mx=9 -md=64m -mfb=256 Vidalia.app.7z Vidalia.app
 p7zip/lib/p7zip/7z a -mx=9 -md=64m -mfb=256 tor.7z tor
# Delete the uncompressed version
 rm -rf tor Vidalia.app Firefox.app

# Modify the Shell Script wrapper of TorBrowserBundle 
# To add automatic 1st launch 7zip decompression
 vim TorBrowserBundle

# Decompress at first run
# Move to TorBrowser_en-US.app/Contents/MacOS/ directory
WORKDIR=`dirname $0`
cd $WORKDIR

echo "Verifying if TBB still need to uncompress itself..."
if [[ -f tor.7z &amp;&amp; -f Vidalia.app.7z &amp;&amp; -f Firefox.app.7z &amp;&amp; -f p7zip/lib/p7zip/7z \
]];  then
                echo "Files tor.7z - Vidalia.app.7z - Firefox.app.7z available" 
                echo "Decompressing files..."
                echo -n "...tor.7z..."
                p7zip/lib/p7zip/7z x tor.7z
                echo -n "...Vidalia.app.7z..."
                p7zip/lib/p7zip/7z x Vidalia.app.7z
                echo -n "...Firefox.app.7z..."
                p7zip/lib/p7zip/7z x Firefox.app.7z
                echo "Deleting archives..."
                rm -f tor.7z
                echo -n "...tor.7z..."
                rm -f Vidalia.app.7z
                echo -n "...Vidalia.app.7z..."
                rm -f Firefox.app.7z
                echo -n "...Firefox.app.7z..."
        else
                echo "Compressed files not found: TBB already uncompressed"
        fi


# Make a new ZIP image (better to use DMG)
 cd ../../../
# Current size with built-in 7zip compressed app
 du -sh TorBrowser_en-US.app
 35M	TorBrowser_en-US.app
 
# Create compresed archive
zip -r -9 TorBrowser-7z-wrap2.2.34-3-dev-osx-x86_64-en-US.zip TorBrowser_en-US.app

# New size of Compressed file
 du -sh TorBrowser-7z-wrap2.2.34-3-dev-osx-x86_64-en-US.zip
 23M	TorBrowser-7z-wrap2.2.34-3-dev-osx-x86_64-en-US.zip

# Now move the file in some other place and just download and run it as usual
# The first run will compress and delete the internal .7z file transparently

I tried sending via GMAIL and it works fine.

I am confident that playing another little bit, using this method and going further, \
it would be possible to make additional reduction in size.

-naif
naif@globaleaks.org



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111207184215</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-12-07 18:42:15-0400</timestampReceived><subject>Re: [tor-dev] AES_ctr128_encrypt() on Windows</subject><body>

"Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:

&gt; It looks like you're using a version of openssl that isn't actually
&gt; released.  (There is no openssl 1.1.0 yet; only a series of
&gt; not-yet-released development snapshots.)

True when you mention it. I have a "work-in-progress" from:
ftp://ftp.openssl.org/snapshot/openssl-SNAP-20111128.tar.gz

&gt; (Also, what's with your fix?  There's nothing windows-specific about
&gt; the openssl 1.1.0 breakage here.)

My bad. I just assumed I had a "offical" OpenSSL version with only
a Windows breakage. Lets hope the function gets put back before
the next release then.

--gv


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111211171036</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-12-11 17:10:36-0400</timestampReceived><subject>Re: [tor-dev] Uploading video over Orbot</subject><body>


On 12/11/2011 11:54 AM, Nathan Freitas wrote:
&gt; Some progress to share on Tor-related efforts with our Secure Smart Cam
&gt; project with WITNESS. (More here:
&gt; https://guardianproject.info/apps/securecam/ )

oops, and the specific repo and test APK app download are here:
https://github.com/guardianproject/sscxfer

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111213214259</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2011-12-13 21:42:59-0400</timestampReceived><subject>[tor-dev] How to try out the new shiny IPv6 bridge support</subject><body>

Hi,

With great help from Jeroen Massars address independence patch posted
to this list earlier this year, a first milestone of IPv6 support in
tor was reached in the 0.2.3.9-alpha release.  Clients can now connect
to private bridges over IPv6 if configured for that.  If you are at
all interested in trying out the new IPv6 support, this short HOWTO is
for you.

Please note that this is new code.  Be prepared to run into bugs, hunt
them down, report them, help out solve them and earn eternal fame and
glory.  It's a pain, but someone's got to do it.


As part of proposal 186 ("Multiple addresses for one OR or bridge"),
the ORPort configuration option has changed and ORListenAddress will
be deprecated.  We can use this for adding an IPv6 address to a bridge
already running on an IPv4 address.  (Another option is to run a
bridge listening _only_ to IPv6 but note that every relay need IPv4
too, in order to speak to other OR's in the Tor network.)


In order to configure a bridge to listen to an IPv6 address, add an
ORPort option with an IPv6 address within square brackets and a port
number like this:

  ORPort [2001:DB8::42]:4711


In order to have your client connect to a bridge over IPv6, simply
state the address of the bridge within square brackets and a port
number in a Bridge line:

  Bridge [2001:DB8::42]:4711


Note that there's still no support for IPv6 in BridgeDB.  There is no
harm in specifying PublishServerDescriptor 1 but nothing good will
come out of it.  You will have to find other ways of getting your
bridge addresses to your users.

Note also that if you configure your client with two (or more)
addresses belonging to the very same bridge, your client will pick one
of them and try to use that.  This behaviour is not perfect and will
change in future versions of tor.  This behaviour isn't even bug free
and should not be counted on -- especially when an IPv6 address is
preferred over an IPv4 address, in which case the IPv4 address in many
cases is the one being used anyway.  Short story: Don't configure your
client with more than one address per bridge.


Please let me know if there are any questions about this and if you
run in to any trouble setting it up.  Then, when you run into the
bugs, please go to https://trac.torproject.org/ and fire away.

Thanks,
Linus
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111214111117</emailId><senderName>Tarik Karaoglu</senderName><senderEmail>tarik.karaoglu@gmail.com</senderEmail><timestampReceived>2011-12-14 11:11:17-0400</timestampReceived><subject>[tor-dev] Purpose Controller Bug</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

I am trying to create circuits for use of my controller application however
I got the following warning
after my unsuccessful attempt.

Dec 14 02:43:35.239 [warn] circuit_launch_by_extend_info(): Bug: unexpected
purpose 19 when cannibalizing a circ.

If I don't specify any purpose, I am able to create general purpose
circuits.


Another problem is that, is there a way to tell Tor to use separate
circuits for each flow if possible when Tor attaches
streams to circuits?

Currently I am trying to attach streams to circuits using my controller but
I am facing Proxy timeout issues like below:

Dec 14 02:45:35.690 [notice] Tried for 120 seconds to get a connection to
[scrubbed]:40000. Giving up. (waiting for controller)


Any help will be appreciated.

Thanks,

Tarik

[Attachment #5 (text/html)]

Hi,&lt;br&gt;&lt;br&gt;I am trying to create circuits for use of my controller applicat=
ion however I got the following warning&lt;br&gt;after my unsuccessful attempt.&lt;b=
r&gt;&lt;br&gt;Dec 14 02:43:35.239 [warn] circuit_launch_by_extend_info(): Bug: unex=
pected purpose 19 when cannibalizing a circ.&lt;br&gt;

&lt;br&gt;If I don't specify any purpose, I am able to create general purpose=
 circuits.&lt;br&gt;&lt;br&gt;&lt;br&gt;Another problem is that, is there a way to tell Tor t=
o use separate circuits for each flow if possible when Tor attaches&lt;br&gt;

streams to circuits?&lt;br&gt;&lt;br&gt;Currently I am trying to attach streams to circ=
uits using my controller but I am facing Proxy timeout issues like below:&lt;b=
r&gt;&lt;br&gt;Dec 14 02:45:35.690 [notice] Tried for 120 seconds to get a connectio=
n to [scrubbed]:40000. Giving up. (waiting for controller)&lt;br&gt;

&lt;br&gt;&lt;br&gt;Any help will be appreciated.&lt;br&gt;&lt;br&gt;Thanks,&lt;br&gt;&lt;br&gt;Tarik&lt;br&gt;&lt;br&gt;&lt;b=
r&gt;


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111211165435</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-12-11 16:54:35-0400</timestampReceived><subject>[tor-dev] Uploading video over Orbot</subject><body>

Some progress to share on Tor-related efforts with our Secure Smart Cam
project with WITNESS. (More here:
https://guardianproject.info/apps/securecam/ )

I know that "uploading HD video over a mobile network on Tor" has long
been one of these cringe-inducing requests from NGOs, but at least for
short clips, it seems to be working fairly well, both to YouTube and to
the self-hostabled Videobin.org software.

SSCXfer is my reduction of the Vidiom.mobi (http://vidiom.mobi/) app to
be a focused, clean secure video uploader for YouTube and the
self-hostable videobin.org software.

Vidiom is pretty fantastic, but is a bit too kitchen sink, and also
included features like FTP and Facebook upload which I don't feel
comfortable putting a "secure" stamp on. The YouTube upload code comes
from the very interesting "YouTube Direct" project's Android client:
http://code.google.com/p/ytd-android/

The basic user story for SSCXfer is:

"Alice has sensitive video evidence of a human rights crime recorded on
her smartphone and wants to upload it to YouTube, but is in a country
where YouTube is often blocked, and always monitored."

a more complex one is:

"Bob is a trained human rights defender working in a restrictive region,
using his smartphone to interview victims about their experiences, and
he needs to safely offload the videos from his phone to a secure private
site as soon as possible, without raising any flags in the internet
monitor systems."

In this case "secure" and "safe", mean it will 1) use HTTPS as
available, 2) store any local data in SQLCipher, and 3) support upload
over proxy servers, specifically Orbot's built-in SOCKS or HTTP proxy
without requiring root. In addition, the uploader must support low-bw,
high latency connections, and support resumeable uploads. Finally, since
videobin.org can be self-hosted, it is possible that a server could be
run by WITNESS or any organization on a Tor hidden service .onion
address, or at least on their own, https site.

At this point, I've implemented support for Orbot/Tor working by
enabling HTTP proxying support in all the HTTP connection code, and it
is working quite well for both uploads to YouTube and the default
Videobin.org site instance. Resume and retry seem to work, but I have
not done extensive testing. I think the most extreme test scenario is
uploading over Tor over EDGE network, and then going up and down into
the subway. We'll see how we do in that case.

Best,
 Nathan

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111214201332</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-14 20:13:32-0400</timestampReceived><subject>Re: [tor-dev] Two questions about dir-spec.txt</subject><body>

On Wed, Dec 14, 2011 at 1:37 PM, Karsten Loesing
&lt;karsten.loesing@gmx.net&gt; wrote:
&gt; Hi Nick,
&gt;
&gt; as the subject says, two quick questions about dir-spec.txt:
&gt;
&gt;
&gt; 1. The "s" lines of network status entries are specified as:
&gt;
&gt; =A0 =A0"s" SP Flags NL
&gt;
&gt; Now, when a relay has no flags at all, which can happen in a vote or
&gt; could happen in older consensus methods, that relay would have an "s"
&gt; line just consisting of "s", not "s ".
&gt;
&gt; I think it makes sense to omit the SP, but should this be specified?

Yes.

&gt;=A0If so, how?

One of the easiest ways would be "s" NL | "s" SP Flags NL

&gt; There are other lines where it's not specified whether a trailing SP is
&gt; permitted or not. =A0But I think I only encountered "s" lines without any
&gt; list elements so far.

IIRC trailing space is permitted while parsing but should never be
required or emitted.

&gt; (I ran into problems here a while ago, when I looked for lines starting
&gt; with "s " to overwrite an sLine string variable. =A0But there was no "s "
&gt; line for some relays, so the program used the "s " line from the
&gt; previous relay. =A0Went unnoticed. =A0Ugh.)
&gt;
&gt;
&gt; 2. The "m" lines in votes are not in dir-spec.txt. =A0I haven't looked at
&gt; proposal 158 yet. =A0Is that proposal up-to-date?

It should be, IIRC, but see also 162.  I have a ticket somewhere to
merge it back into dir-spec
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111215174712</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-12-15 17:47:12-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!) - TorTV</subject><body>

Hi all,

TorTV Project has been implemented by Jaromil:

TorTV : http://dyne.org/software/tortv/
Jaromil : http://rastasoft.org - @jaromil

Cool, testing have to be done!

-naif


On 11/23/11 8:57 AM, Fabio Pietrosanti (naif) wrote:
&gt; Hi all,
&gt; 
&gt; i got a WDTV Live
&gt; (http://support.wdc.com/product/install.asp?groupid=1003=en) that's
&gt; part of bigger family of consumer mediaplayer from Western Digital
&gt; (http://support.wdc.com/product/install.asp?level1=10=en).
&gt; 
&gt; It seems it can run Tor without any major issue.
&gt; There is a very nice hacked firmware community around WDTV users, that's
&gt; a very cheap hardware (retail price 70-80EUR).
&gt; 
&gt; What's about making a "promotional" campaign like for the Tor Cloud to
&gt; have people running Tor Relay "right on their TV" ?
&gt; 
&gt; I mean, the "hacked firmware" installation process of WDTV works that way:
&gt; - Plug an USB Key formatted FAT32 with 3 files (boot, kernel, image) on WDTV
&gt; - Poweron
&gt; 
&gt; So it may be possible to make a campaign where users are invited to "run
&gt; their tor relay" on their TV in 3 simple steps:
&gt; - Get a USB Key
&gt; - Load that files on it
&gt; - Plug to your WDTV
&gt; - Poweron your WDTV
&gt; You are now helping poor sirian, iranian and chinese censored people.
&gt; 
&gt; That way even the average fat guy sitting on his couch drinking beer and
&gt; eating wing chicken can support freedom of speech.
&gt; 
&gt; That kind of user can just "poweron" the WDTV and with his "remote
&gt; control" after seeing his favorite telefilm on paytv, can just "zap" to
&gt; see how his Tor Router is working: On TV!
&gt; 
&gt; This could be defined as the "very lazy Tor user" who doesn't even want
&gt; to use a computer, but just do TV zapping :P
&gt; 
&gt; So, the idea could be to do a custom hacked firmware of WDTV and a WDTV
&gt; Apps that you can "click" via remote control, seeing the statistics of
&gt; your Tor Relay.
&gt; 
&gt; # uname -a
&gt; Linux WDTVLIVE 2.6.22.19-19-4 #28 PREEMPT Mon Mar 22 20:08:14 CST 2010
&gt; mips GNU/Linux
&gt; 
&gt; # tor --version
&gt; Jan 01 15:41:37.533 [notice] Tor v0.2.2.32 (git-877e17749725ab88). This
&gt; is experimental software. Do not rely on it for strong anonymity.
&gt; (Running on Linux mips)
&gt; Tor version 0.2.2.32 (git-877e17749725ab88).
&gt; 
&gt; # free
&gt;               total         used         free       shared      buffers
&gt;   Mem:       199056       193664         5392            0        10832
&gt;  Swap:            0            0            0
&gt; Total:       199056       193664         5392
&gt; 
&gt; # cat /proc/cpuinfo
&gt; system type             : Sigma Designs TangoX
&gt; processor               : 0
&gt; cpu model               : MIPS 24K V7.12  FPU V0.0
&gt; Initial BogoMIPS        : 332.59
&gt; wait instruction        : yes
&gt; microsecond timers      : yes
&gt; tlb_entries             : 32
&gt; extra interrupt vector  : yes
&gt; hardware watchpoint     : yes
&gt; ASEs implemented        : mips16
&gt; shadow register sets    : 1
&gt; VCED exceptions         : not available
&gt; VCEI exceptions         : not available
&gt; 
&gt; System bus frequency    : 333000000 Hz
&gt; CPU frequency           : 499500000 Hz
&gt; DSP frequency           : 333000000 Hz
&gt; 
&gt; 
&gt; -naif

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111214183730</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-12-14 18:37:30-0400</timestampReceived><subject>[tor-dev] Two questions about dir-spec.txt</subject><body>

Hi Nick,

as the subject says, two quick questions about dir-spec.txt:


1. The "s" lines of network status entries are specified as:

    "s" SP Flags NL

Now, when a relay has no flags at all, which can happen in a vote or
could happen in older consensus methods, that relay would have an "s"
line just consisting of "s", not "s ".

I think it makes sense to omit the SP, but should this be specified?  If
so, how?

There are other lines where it's not specified whether a trailing SP is
permitted or not.  But I think I only encountered "s" lines without any
list elements so far.

(I ran into problems here a while ago, when I looked for lines starting
with "s " to overwrite an sLine string variable.  But there was no "s "
line for some relays, so the program used the "s " line from the
previous relay.  Went unnoticed.  Ugh.)


2. The "m" lines in votes are not in dir-spec.txt.  I haven't looked at
proposal 158 yet.  Is that proposal up-to-date?


Thanks,
Karsten
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217011452</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-12-17 01:14:52-0400</timestampReceived><subject>[tor-dev] A modest proposal for a petname system in</subject><body>

Hi,

Arturo and I have discussed a possible petname system for tor2web that
would make it simple to remember hidden service names; it's not perfect,
it's not secure and it requires comment from the community. The basic
idea is to make it easy to deploy and see if anyone cares to use it.

Here's the proposal in url form:
https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xxx-on=
ion-nyms.txt

Here's the proposal as text:
Filename: xxx-onion-nyms.txt
Title: .onion nym system
Author: Arturo Filast=C3=B2, Jacob Appelbaum
Created: 17 December 2011
Status: Draft

1. Intro and Motivation

  The main issue that prohibits the wide scale adoption of .onion addressing
  is the fact that they are not human memorable. While Zooko's triangle
says that
  you can only have at most two of "memorable", "secure" and "global" it is
  possible to build a simple nym mechanism that relies on the current .onion
  addressing system.  We define a basic registration system generally
and also
  it's particual application to the tor2web network. This is a very
simple kind
  of petname system for applications such as tor2web.

2. Definitions

  These are the definitions of the actors involved in the process.

  Beppe - The owner of the Tor Hidden Service
  User - A random user of Tor/tor2web
  v2cbb2l4lsnpio4q.onion - The .onion address that Beppe is interested
in registering
  antani - The nym Beppe is interested in associating to
v2cbb2l4lsnpio4q.onion
  t2w - A tor2web node


3. Registration

  This is the process through which Beppe is able to make a registration
for his chosen
  nym.

3.1 General implementation

  Beppe wishes to register "antani" to point to v2cbb2l4lsnpio4q.onion
so he creates a
  a TCP service listening on his .onion will respond with the string
"reg antani" when
  interrogated. The requester will make a lookup in his database to see if
  "antani" is already registered. If it is not registered the "antani" &lt;-&gt;
  v2cbb2l4lsnpio4q.onion mapping is created. A timestamp is added to the
  database.

3.2 Tor2web implementation

  Beppe creates a file called "onion.txt" containing the string "reg
antani" and uploads
  it to the root of his web server. When User visits
v2cbb2l4lsnpio4q.tor2web.org the
  t2w checks if his database contains a mapping with
v2cbb2l4lsnpio4q.onion, if it does
  not, it requests the http://v2cbb2l4lsnpio4q.onion/onion.txt file.
  If the file exists t2w reads it and extracts the "antani" string. A
lookup is made in
  his database. If "antani" is not registered he creates a mapping
between "antani" and
  v2cbb2l4lsnpio4q.onion. A timestamp is added to the database.

4. Expiration

  A nym will expire if either the HS goes offline for longer than a
given time
  threshold or if he explicitly requests removal of the association to that
  particualr nym. This allows dynamic reallocation of nyms and avoids nym
  squatting.

4.1 Time delay

  We define the default tiem threshold to be 30 days since the last
check. At
  the time of expiry or anytime before, another request is made to
either the TCP
  service or for the "onion.txt" file. If the Hidden Service is offline
or if
  the requested mapping has changed the mapping is removed or modified.
 If the
  onion.txt is unchanged, the nym remains valid and the database timestamp
  entry is updated.

  4.2 Release

  The HS can specify the "release" string to delete the entry from the
nym database.

5. Synchronization

  To keep the database of registered nyms up to date in for many t2w
nodes, a synchronization
  mechanism is required but currently out of scope for this document.


All the best,
Jacob
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111206003849</emailId><senderName>Aaron</senderName><senderEmail>aagbsn@extc.org</senderEmail><timestampReceived>2011-12-06 00:38:49-0400</timestampReceived><subject>[tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>

Attached is a draft document describing proposed changes to BridgeDB to
accommodate the new or-address spec (186-multiple-orports.txt) and IPv6 bridges.

I am especially interested in comments on sections tagged #XXX.

Thanks!

--Aaron

["xxx-bridgedb-learns-ipv6.txt" (text/plain)]

Filename: xxx-bridgedb-learns-ipv6.txt
Title: BridgeDB Learns IPv6
Author: Aaron Gibson
Created: 5 Dec 2011
Status: Draft

Overview:

  This document outlines what we'll do to make BridgeDB fully support IPv6
  bridges, and fully support IPv6 with the email, https, and bucket
  distributors.

Motivation:

  IPv6 bridges need a BridgeDB too.

What needs to change:

  There are two main tasks that must be completed for BridgeDB to support IPv6.

    1. BridgeDB must be able to parse IPv6 addresses from router descriptors.
    (Currently, BridgeDB does not recognize the or-address line described in
    186-multiple-orports.txt)
    
    2. BridgeDB must decide how to hand out IPv6 addresses.  (Currently,
    BridgeDB distributors are not IPv6 aware, and provide no support for
    distinguishing bridges by address class)

    
1. BridgeDB learns to parse or-address

    BridgeDB must learn how to parse the new or-address line from server
    descriptors. The new or-address line allows a router to specify a list of
    addresses and ports or port-ranges. 
    
    Here is the or-address specification (see: 186-multiple-orports.txt)
          
      or-address SP ADDRESS ":" PORTLIST NL
      ADDRESS = IP6ADDR | IP4ADDR
      IPV6ADDR = an ipv6 address, surrounded by square brackets.
      IPV4ADDR = an ipv4 address, represented as a dotted quad.
      PORTLIST = PORTSPEC | PORTSPEC "," PORTLIST
      PORTSPEC = PORT | PORT "-" PORT
      PORT = a number between 1 and 65535 inclusive.

    BridgeDB must now comprehend and store multiple listening addresses and
    ports. BridgeDB currently assumes that each bridge has only one listen
    address. BridgeDB must be modified to take one of the following approaches:
    
      a. Treat each ADDRESS:PORT combination as a separate bridge entity
      b. Display a subset of each bridges ADDRESS:PORT entries in a response
      c. Display all of each bridges ADDRESS:PORT entries in a response

    Given any address of the bridge you can learn its fingerprint, and use that
    to look up its descriptor at tonga and learn the rest of the addresses. so
    counting a bridge with 5 addresses as 5 bridges makes it more likely to get
    blocked by a smart adversary. but more useful against a weaker adversary.
    #XXX: thanks arma!
    # any other thoughts here? option c. seems to be the simplest to implement.

    BridgeDB should be able to mark specific IP:port pairs as blocked, and
    indicate where it is blocked (e.g. by country code). This requirement is
    complicated by the fact that or-address may specify a range of listening
    ports.

    How are IPv6 Addresses stored in BridgeDB?

      IPv6 Addresses are stored as strings, the same way as IPv4 addresses.
      #XXX: is this better than using the ipaddr.IPAddress class?

    How are Bridges differentiated by address class?

      Bridges are differentiated by the string representation of their IP
      address.

      When BridgeDB needs to make a distinction between IP address classes, the
      python module ipaddr-py (https://code.google.com/p/ipaddr-py/) will be
      used to determine address class.

2. BridgeDB learns how to selectively distribute IPv6 bridges

    BridgeDB's 3 distributors must be able to selectively provide both
    IPv4 and/or IPv6 bridges to clients. Deployment of these distributors must
    take care to mitigate reachability issues due partly to the ongoing
    transition from IPv4 to IPv6. 

    [One such issue is clients who have IPv6 support on their local network but
    the client's ISP does not; such a client may try to reach the IPv6 address
    specified by a AAAA record and fail to connect.]

    The 3 distributor types that BridgeDB currently features are:

      1. HTTPS Distributor
         
        The HTTPS distributor must be able to selectively offer both IPv4 and
        IPv6 bridges to its' clients, and BridgeDB must support both IPv4 and
        IPv6 connections.
        
        #XXX the twisted framework does not currently support ipv6. However,
        # it is possible to place BridgeDB behind a forwarding proxy such as
        # apache or nginx, which will pass the client address to BridgeDB in the
        # X_FORWARDED_FOR header. BridgeDB HTTPS distributor must be able to
        # parse the X_FORWARDED_FOR header for both IPv4 and IPv6 addresses.
        # Additionally, BridgeDB should eventually support IPv6 natively when
        # the twisted framework provides adequate IPv6 support.

        How does bridgedb determine whether to respond with ipv4 or ipv6
        bridges?

          Users select IPv4 or IPv6 bridges by visiting different URLs. An
          informational message added to the BridgeDB response will include the
          other URL. Two separate BridgeDB instances are run, one for each URL.

          Alternately, ipv6 bridges could be requested by visiting
          bridges.tpo/ipv6 or similar URL path scheme.

        Proposed Additional Hostname For IPv6 Bridges

          BridgeDB shall listen for requests on two different hostnames,
          bridges.torproject.org and bridgesv6.torproject.org.

        DNS Configuration Details

          bridges.torproject.org shall not have an AAAA record until the
          addition of the record is determined to be sound.

          bridgesv6.torproject.org shall have both an AAAA and A record.
          
          This is to avoid the confused-client scenario described above.

        How does BridgeDB know which URL was requested?

          This section describes how BridgeDB could be modified to support
          requests to both bridges.torproject.org and bridgesv6.torproject.org
          with a single BridgeDB instance.

          A single BridgeDB instance could handle requests to both
          bridges.torproject.org and bridgesv6.torproject.org by checking the
          Host header sent by the browser. The Host header is optional. In
          order to expose the selector explitely BridgeDB must check the query
          string for the following parameters:

            q=ipv4  - Request IPv4 bridges.
            q=ipv6  - Request IPv6 bridges.  

          Parameters may be repeated to select multiple classes, e.g.
          
            q=ipv4&amp;q=ipv6  - Request both IPv4 and IPv6 bridges.

          When no parameters are set, by default BridgeDB must return addresses
          of the same class as the client. This default may promote IPv6 use
          where possible.

        How does someone end up at bridgesv6.torproject.org?

          BridgeDB should include a message at the end of its' response.  
          e.g.

            "Get IPv4 bridges https://bridges.torproject.org"
            "Get IPv6 bridges from https://bridgesv6.torproject.org"
            "You must have IPv6 for these bridges to work."
          #XXX: will users understand what this means?

        How does IPv6 affect address datamining of https distribution?
          A user may be allocated a /128, or a /64.
          An adversary may control a /32 or perhaps larger
          Proposal: Enable reCAPTCHA support by default.

        How do IPv6 addresses work with the IPBasedDistributor?
        #XXX: I need feedback on this
        # do we use all 128 bits here?
        # upper N bits? lower N bits? random or specific N bits?

        How are IPv6 Bridges actually distinguished?

          A new type of BridgeSplitter (sort of like a BridgeHolder)
          is devised; the function of which is to split bridges into different
          rings determined by a filter function.

          The filtering mechanism here is similar to BridgeDB's ipCategories
          implementation, the difference is that both the filters and ring
          names are specified at instance construction.

          The construction of a BridgeSplitter instance should be done by
          passing lists of tuples (ringName,filterFunction) to the constructor.
          This feature allows for dynamically creating filtered BridgeRings, 
          which would prove useful for constructing more complex filters, for
          example, filtering by both address class and reachability from
          specific countries.

          This implementation could increase the rate at which bridges are
          detected and blocked, although the rate could be controlled by the
          frequency that BridgeDB updates its knowledge of blocked bridges.
          
          #XXX: I have some concern about the performance of
          # filtering bridges dynamically for each response. BridgeDB should
          # learn to cache recently used dynamic filters so that the impact of
          # popular requests will be reduced, and BridgeDB does not have to
          # pre-compute or identify which types of requests will be popular.

          The implementation could look similar to the current 'subring'
          implementation; or the current 'ipCategories' implementation. Both of
          the features are implemented using subrings that hold a subset of
          the parent ring's bridges; the subset being defined by a filtering
          function.

          An accompanying Distributor based on the existing IPBasedDistributor
          shall be designed to use the above BridgeSplitter so that sorted
          Bridges are selectable by address type. Because a bridge
          may now have both IPv6 and IPv4 addresses, BridgeDB needs to take
          one of the following approaches when only a single address class is
          requested:

            a. filter addresses of the other address class from the response
            b. include the other addresses in the response

      2. Email Distributor

        The Email Distributor must accept additional new commands parsed from
        the subject or a single line in the body of an email message.

          ipv4  - request IPv4 bridges.
          ipv6  - request IPv6 bridges.

        The default action may be set in bridgedb.conf with the option
        EMAIL_DEFAULT_ADDRESS_CLASS, which must be one of 'ipv6' or 'ipv4'.  If
        the option is not given in the config, EMAIL_DEFAULT_ADDRESS_CLASS shall
        default to 'ipv4'.

        Similar to the IPBasedDistributor, BridgeDB must determine how the
        response should accommodate bridges with both address classes.

      3. Unassigned Distributor and Buckets

        BridgeDB must provide a selector to choose between exporting
        IPv4, IPv6, or both types of bridges.

        BridgeDB currently provides a way to export bucket files with
        unallocated bridges. The existing syntax provides no mechanism to
        differentiate by address class.

        Proposed new FILE_BUCKET syntax:

          A dictionary of dictionaries with the following acceptable keys and
          values.

          'filename_prefix' shall be a unique string used as the output filename
          prefix. This is string is also the key to a dictionary that contains
          the following key/values:

          'address-class' : one of either 'ipv6' or 'ipv4'
          'number'        : an integer &gt; 0

        Users may wish to provide descriptive names,
        e.g.
        
          FILE_BUCKETS = {
                  'filename_prefix': {'address-class': 'ipv6', 'number': 10},
                  'descriptive_name': {'address-class': 'ipv6', 'number': 10},
          }

        Future BridgeDB enhancements may expand these options to include other
        filters.
        #XXX: e.g. buckets of bridges 'not-blocked-in'


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111214112848</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-12-14 11:28:48-0400</timestampReceived><subject>[tor-dev] common/aes.c troubles</subject><body>

In common/aes.c:

#include "orconfig.h"
#include &lt;openssl/opensslv.h&gt;
...
#include &lt;openssl/aes.h&gt;
..
#include "compat.h"

By default &lt;winsock.h&gt; is included in &lt;windows.h&gt; when
WIN32_LEAN_AND_MEAN is not defined. But this is defined too
late; in compat.h. So when &lt;e_os.h&gt; in OpenSSL pulls in &lt;winsock.h&gt;
and &lt;winsock2.h&gt; gets included in compat.h, I'm getting lots of warnings
and redefinitions errors. E.g.

        g:\VC_2010\SDK\include\winsock.h(787) : see declaration of 'inet_ntoa'
g:\VC_2010\SDK\include\winsock2.h(1815) : error C2375: 'listen' : redefinition; different linkage

An easy fix would be to move "#define WIN32_LEAN_AND_MEAN"
into win32/orconfg.h:

diff --git a/src/common/compat.h b/src/common/compat.h
index a228a46..5c66a11 100644
--- a/src/common/compat.h
+++ b/src/common/compat.h
@@ -15,7 +15,9 @@
 #ifndef _WIN32_WINNT
 #define _WIN32_WINNT 0x400
 #endif
+#ifndef WIN32_LEAN_AND_MEAN
 #define WIN32_LEAN_AND_MEAN
+#endif
 #if defined(_MSC_VER) &amp;&amp; (_MSC_VER &lt; 1300)
 #include &lt;winsock.h&gt;
 #else

diff --git a/src/win32/orconfig.h b/src/win32/orconfig.h
index e51b638..b9fe31f 100644
--- a/src/win32/orconfig.h
+++ b/src/win32/orconfig.h
@@ -5,6 +5,7 @@
 /* Windows-only defines. */
 #define MS_WINDOWS
 #define MS_WIN32
+#define WIN32_LEAN_AND_MEAN
 #define CONFDIR ""

 /* Define to 1 if you have the &lt;arpa/inet.h&gt; header file. */

How about it?

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217190836</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-17 19:08:36-0400</timestampReceived><subject>Re: [tor-dev] common/aes.c troubles</subject><body>

On Wed, Dec 14, 2011 at 6:28 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:

&gt; How about it?

I'd say "not so good" if it only applies to MSVC builds.  The
orconfig.h files is supposed to correspond exactly to the one that
would ordinarily be generated by the autoconf script for on other
platforms.

Of course, if we patched the autoconf script so that it defined the
macro when building on windows with mingw, that would be fine, since
it would make the behavior consistent.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111218124639</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-12-18 12:46:39-0400</timestampReceived><subject>Re: [tor-dev] common/aes.c troubles</subject><body>

"Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:

&gt; I'd say "not so good" if it only applies to MSVC builds. 

I applies to all Win builds. Are you not getting any warnings
and errors when compiling aes.c?

&gt; Of course, if we patched the autoconf script so that it defined the
&gt; macro when building on windows with mingw, that would be fine, since
&gt; it would make the behavior consistent.

Excactly. It wouldn't hurt to move WIN32_LEAN_AND_MEAN further up
in the list of defines. It makes everyting compile faster too.

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111206094530</emailId><senderName>Linus Nordberg</senderName><senderEmail>linus@nordberg.se</senderEmail><timestampReceived>2011-12-06 09:45:30-0400</timestampReceived><subject>Re: [tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>

Aaron &lt;aagbsn@extc.org&gt; wrote
Mon, 5 Dec 2011 16:38:49 -0800:

|       IPv6 Addresses are stored as strings, the same way as IPv4 addresses.
|       #XXX: is this better than using the ipaddr.IPAddress class?

What kind of database is this?  If it is possible to use the rest of the
database for a program written in a language without (the exact same
implementation of) this particular version of Python ipaddr a string
representation might have a value.  If not, for easier debugging?
Unclear to me.


|           Parameters may be repeated to select multiple classes, e.g.
|           
|             q=ipv4&amp;q=ipv6  - Request both IPv4 and IPv6 bridges.
| 
|           When no parameters are set, by default BridgeDB must return addresses
|           of the same class as the client. This default may promote IPv6 use
|           where possible.

This might cause confusion in cases where the equipment used for getting
a bridge address is not the same as the equipment which is going to use
it.  Very few computer users know if they're using IPv4 or IPv6.

Is it worth it?


| 
|         How does someone end up at bridgesv6.torproject.org?
| 
|           BridgeDB should include a message at the end of its' response.  
|           e.g.
| 
|             "Get IPv4 bridges https://bridges.torproject.org"
|             "Get IPv6 bridges from https://bridgesv6.torproject.org"
|             "You must have IPv6 for these bridges to work."
|           #XXX: will users understand what this means?

I'd like to stress the case where a user fetches a bridge address on a
computer which is not the consumer(s) of the address and suggest "These
bridges will work only on computers with functional IPv6." or similar.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111206181101</emailId><senderName>Aaron</senderName><senderEmail>aagbsn@extc.org</senderEmail><timestampReceived>2011-12-06 18:11:01-0400</timestampReceived><subject>Re: [tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>

Thanks for your feedback!

On Tue, Dec 6, 2011 at 1:45 AM, Linus Nordberg &lt;linus@nordberg.se&gt; wrote:
&gt; Aaron &lt;aagbsn@extc.org&gt; wrote
&gt; Mon, 5 Dec 2011 16:38:49 -0800:
&gt;
&gt; |       IPv6 Addresses are stored as strings, the same way as IPv4 addresses.
&gt; |       #XXX: is this better than using the ipaddr.IPAddress class?
&gt;
&gt; What kind of database is this?  If it is possible to use the rest of the
&gt; database for a program written in a language without (the exact same
&gt; implementation of) this particular version of Python ipaddr a string
&gt; representation might have a value.  If not, for easier debugging?
&gt; Unclear to me.

The backend database (sqlite3) will still store the addresses as strings.
Once a Bridge object is constructed (loaded from the database or from a
bridge descriptor) - should the address representation
(e.g. Bridge.ip or Bridge.or-addresses[n]) continue to be stored
as a string or the more convenient ipaddr.IPAddress class?
ipaddr.IPAddress.__str__() will return the string representation (for example,
when storing Bridges to the database).

The advantage of using ipaddr is that class(Bridge.ip) will return
either ipaddr.IPv4Address
or ipaddr.IPv6Address. It's convenient, works, and already written.

The disadvantage is that for every Bridge object, at least one
ipaddr.IPAddress object
will be created. The overhead (if any, depending on how compact the
packed addresses
are and python object size) may not significant (depending on your
perspective of significant)
but it is worth thinking about as we want BridgeDB to scale to 10k
bridges or more.

The alternative approach is to always store addresses as strings and
detect the address
class when necessary (e.g. sorting Bridges). If BridgeDB needs to sort
or filter Bridges
frequently then this approach could present performance issues.

I don't want to optimize prematurely either. Either approach should be
replaceable without
too much effort.

&gt;
&gt;
&gt; |           Parameters may be repeated to select multiple classes, e.g.
&gt; |
&gt; |             q=ipv4&amp;q=ipv6  - Request both IPv4 and IPv6 bridges.
&gt; |
&gt; |           When no parameters are set, by default BridgeDB must return addresses
&gt; |           of the same class as the client. This default may promote IPv6 use
&gt; |           where possible.
&gt;
&gt; This might cause confusion in cases where the equipment used for getting
&gt; a bridge address is not the same as the equipment which is going to use
&gt; it.  Very few computer users know if they're using IPv4 or IPv6.
&gt;
&gt; Is it worth it?
The scenario where this hurts us is when a user with IPv6 who needs IPv4 bridges
lands on the https://bridgesv6.tpo page, and doesn't click the link
for IPv4 bridges.
That scenario likely leads to a support request, but I suspect it will
not be a very
common one -- or at least not until IPv6 is adopted more widely. Our strategy in
the future should change as we get feedback.

For example, in a 'mostly-ipv6' world, perhaps https://bridges.tpo
will be dual-stack,
and the https://bridgesv4.tpo page will give out ipv4 bridges. As long
as we have
the flexibility to change our approach, we can make the best decision
when we have
better data about the types of requests https://bridges.tpo sees

The selectors described above are proposed because some clients may not set a
'Host' header, and adding support for parameters in the request string
is easy. If
a client does not specify anything (Host header, or query string) then BridgeDB
could instead default to giving out IPv4 addresses. We want people to use IPv6
(right?) so promoting it to users who can take advantage of it makes
sense to me.

&gt;
&gt;
&gt; |
&gt; |         How does someone end up at bridgesv6.torproject.org?
&gt; |
&gt; |           BridgeDB should include a message at the end of its' response.
&gt; |           e.g.
&gt; |
&gt; |             "Get IPv4 bridges https://bridges.torproject.org"
&gt; |             "Get IPv6 bridges from https://bridgesv6.torproject.org"
&gt; |             "You must have IPv6 for these bridges to work."
&gt; |           #XXX: will users understand what this means?
&gt;
&gt; I'd like to stress the case where a user fetches a bridge address on a
&gt; computer which is not the consumer(s) of the address and suggest "These
&gt; bridges will work only on computers with functional IPv6." or similar.

I agree. I do think that the warning string is a good first approach
to reducing the
confusion.

&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111210150734</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-12-10 15:07:34-0400</timestampReceived><subject>Re: [tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>

On 2011-12-06, Aaron &lt;aagbsn@extc.org&gt; wrote:

&gt;         How does IPv6 affect address datamining of https distribution?
&gt;           A user may be allocated a /128, or a /64.
&gt;           An adversary may control a /32 or perhaps larger
&gt;           Proposal: Enable reCAPTCHA support by default.

How much would it cost China to have 1000 (or even 10000) CAPTCHAs
solved?  How much of our bridge pool would such an attack obtain?

&gt;         How do IPv6 addresses work with the IPBasedDistributor?
&gt;         #XXX: I need feedback on this
&gt;         # do we use all 128 bits here?
&gt;         # upper N bits? lower N bits? random or specific N bits?

I doubt that a single prefix length would be appropriate for all
networks.  There is no point in using a fixed bitmask other than a
prefix; even if we do not publish the mask, an attacker can easily
determine which bits within the suffix that it controls are used to
select a portion of the bridge pool.  A more complex mapping of IP
addresses to bridge pool locations might work.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217162322</emailId><senderName>Daniel Cohen</senderName><senderEmail>danielc192@gmail.com</senderEmail><timestampReceived>2011-12-17 16:23:22-0400</timestampReceived><subject>[tor-dev] Is Taking Checksum of Packet Payloads a Vulnerability?</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

I am new to Tor, but after reading about its design, and reading a few
research papers on its vulnerabilities (specifically timing attacks), I had
the following thought:

Suppose Alice is connecting to Bob via Tor, using HTTPS encryption. She
sends a packet to the Tor entry node (call it En). The packet travels
through the network, emerges from an exit node (call it Ex), and arrives at
Bob.

Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; Bob

Now suppose that Alice's connection is being monitored, as well as a group
of the exit nodes (which are either hostile or having their packets
sniffed). When the encrypted packet leaves Alice on its way to En, it is
sniffed, and a checksum is made of its encrypted payload. The packet then
continues through the network as usual, and emerges from an exit node.

It appears to me that the attacker need only check packets coming out of
exit nodes to see if their payload checksums match that of the packet
observed leaving Alice. Unlike timing attacks, which require a reasonable
number of packets to confirm Alice's identity, this attack would require
only one, since checksums have an almost 0% chance of collision. If a
packet with the same payload checksum as Alice's is discovered, it almost
certainly originated from her.

Is this a problem with Tor's architecture? If so, has this issue already
been addressed?

Thanks,

Daniel Cohen

[Attachment #5 (text/html)]

Hi,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am new to Tor, but after reading about its design, and \
reading a few research papers on its vulnerabilities (specifically timing attacks), I \
had the following thought:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Suppose Alice is connecting to \
Bob via Tor, using HTTPS encryption. She sends a packet to the Tor entry node (call \
it En). The packet travels through the network, emerges from an exit node (call it \
Ex), and arrives at Bob.&lt;/div&gt;

&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; \
Bob&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Now suppose that Alice's connection is being \
monitored, as well as a group of the exit nodes (which are either hostile or having \
their packets sniffed). When the encrypted packet leaves Alice on its way to En, it \
is sniffed, and a checksum is made of its encrypted payload. The packet then \
continues through the network as usual, and emerges from an exit node.&lt;/div&gt;

&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It appears to me that the attacker need only check packets coming \
out of exit nodes to see if their payload checksums match that of the packet observed \
leaving Alice. Unlike timing attacks, which require a reasonable number of packets to \
confirm Alice's identity, this attack would require only one, since checksums \
have an almost 0% chance of collision. If a packet with the same payload checksum as \
Alice's is discovered, it almost certainly originated from her.&lt;/div&gt;

&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is this a problem with Tor's architecture? If so, has this \
issue already been addressed?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Daniel \
Cohen&lt;br&gt; &lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111221042043</emailId><senderName>Sai</senderName><senderEmail>tor@saizai.com</senderEmail><timestampReceived>2011-12-21 04:20:43-0400</timestampReceived><subject>[tor-dev] Drafting a proposal for mnemonic onion URLs</subject><body>

Howdy all.

I would like to make a mnemonic translation method for onion URLs. Not
as in a full petname system with registration and so forth, just a
"four little words" style way of rendering and entering existing
80-bit hashes in a way that is memorable to not just detect
partial-overlap fuzzing attacks but actually memorize and produce the
URL directly.

I'm not yet ready to make a formal proposal for serious review, but
here is an edit-authorized link to a draft document which has a bit
more detail. Feel free to edit and comment there.
https://docs.google.com/document/d/1IFMnMGh8ZqJIXYBhZOK4IW5KKG0fTatpTJiTS67nJlE/edit?hl=en_US

I'll update tor-dev when I feel it's ready for review as an actual
draft proposal; it's certainly not there yet. This is just meant as a
courtesy notice in case you're interested enough to help make it, and
following up from a discussion earlier today on tor-assistants.

Cheers,
Sai
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111222143829</emailId><senderName>Okhin</senderName><senderEmail>okhin@okhin.fr</senderEmail><timestampReceived>2011-12-22 14:38:29-0400</timestampReceived><subject>[tor-dev] [flashproxy] Not running using gnash</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hello,

I was trying to run flashproxy using gnash following the RTMFP part of
the tutorial located here:
https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README

I do not use the gnash-plugin embedded in a browser, but the CLI tool
gnash packaged with debian (and invoking it like this, as a standard
user: gnash swfcat.swf -p client=1 -p debug=1

I've got the following output with the connector.py script:

$ ./connector.py 127.0.0.1:9001
127.0.0.1:9002 2011-12-22 15:34:07 Local connection from
127.0.0.1:54335. 2011-12-22 15:34:07 SOCKS request from 127.0.0.1:54335.
2011-12-22 15:34:07 handle_socks_request
2011-12-22 15:34:07 Got SOCKS request for 127.0.0.1:9001.
2011-12-22 15:34:07 handle_local_connection
2011-12-22 15:34:07 locals  (1): [u'127.0.0.1:54335']
2011-12-22 15:34:07 remotes (0): []
2011-12-22 15:34:07 Data from unconnected local 127.0.0.1:54335 (141
bytes). 2011-12-22 15:34:07 locals  (1): [u'127.0.0.1:54335']
2011-12-22 15:34:07 remotes (0): []
2011-12-22 15:34:33 Local connection from 127.0.0.1:54336.
2011-12-22 15:34:33 SOCKS request from 127.0.0.1:54336.
2011-12-22 15:34:33 handle_socks_request
2011-12-22 15:34:33 Couldn't unpack SOCKS4 header.
2011-12-22 15:34:33 locals  (1): [u'127.0.0.1:54335']
2011-12-22 15:34:33 remotes (0): []
2011-12-22 15:34:56 EOF from unconnected local 127.0.0.1:54335 with 141
bytes buffered. 2011-12-22 15:34:56 locals  (0): []
2011-12-22 15:34:56 remotes (0): []

And I enlcosed a gnash debug logfile to this mail.

I'm running a squeeze with this kernel: $ uname -ar
Linux desktop 2.6.32-5-amd64 #1 SMP Fri Sep 9 20:23:16 UTC 2011
x86_64 GNU/Linux

Regards,
Okhin

[Attachment #7 (text/x-log)]

3338:1] 15:33:34: DEBUG: Created top level window
3338:1] 15:33:34: DEBUG: gnash_canvas_size_allocate 265 1
3338:1] 15:33:34: DEBUG: Framebuffer pixel format is BGRA32 (little-endian host)
3338:1] 15:33:34: DEBUG: Initialized AGG buffer &lt;0x7f0e58f5c000&gt;, 1060 bytes, 265x1, \
rowsize is 1060 bytes 3338:1] 15:33:34: DEBUG: /home/okhin/ appended to local \
sandboxes 3338:1] 15:33:34: DEBUG: /home/okhin/swfcat.swf appended to local sandboxes
3338:1] 15:33:34: SECURITY: Checking security of URL 'file:///home/okhin/swfcat.swf'
3338:1] 15:33:34: SECURITY: Load of file /home/okhin/swfcat.swf granted (under local \
sandbox /home/okhin/) 3338:1] 15:33:34: version: 10, file_length: 19862
3338:1] 15:33:34: UNIMPLEMENTED: SWF10 is not fully supported, trying anyway but \
don't expect it to work 3338:1] 15:33:34: file is compressed
3338:1] 15:33:34: frame size = RECT(0,0,10000,7500), frame rate = 24.000000, frames = \
1 3338:1] 15:33:34: DEBUG: Movie file:///home/okhin/swfcat.swf (SWF10) added to \
library 3338:1] 15:33:35: DEBUG: Plugins path: /usr/lib/gnash/plugins
3338:1] 15:33:35: SECURITY: Extensions disabled
3338:1] 15:33:35: DEBUG: Player Host FD #-1, Player Control FD #-1
3338:1] 15:33:35: DEBUG: Advance interval timer set to 10 ms (~ 100 FPS)
3338:1] 15:33:35: DEBUG: Loading native class MovieClip
3338:2] 15:33:35: SWF[21]: tag type = 69, tag length = 4, end tag = 27
3338:2] 15:33:35: File attributes: metadata=true network=true
3338:2] 15:33:35: DEBUG: This SWF uses AVM2
3338:2] 15:33:35: ERROR: This SWF file requires AVM2, which was not enabled at \
compile time. 3338:2] 15:33:35: SWF[27]: tag type = 77, tag length = 459, end tag = \
492 3338:2] 15:33:35:   RDF metadata (information only): [[
&lt;rdf:RDF xmlns:rdf='http://www.w3.org/1999/02/22-rdf-syntax-ns#'&gt;&lt;rdf:Description \
rdf:about='' xmlns:dc='http://purl.org/dc/elements/1.1'&gt;&lt;dc:format&gt;application/x-shockwave-flash&lt;/dc:format&gt;&lt;dc:title&gt;Adobe \
Flex 4 Application&lt;/dc:title&gt;&lt;dc:description&gt;http://www.adobe.com/products/flex&lt;/dc:de \
scription&gt;&lt;dc:publisher&gt;unknown&lt;/dc:publisher&gt;&lt;dc:creator&gt;unknown&lt;/dc:creator&gt;&lt;dc:language&gt;EN&lt;/dc:language&gt;&lt;dc:date&gt;Oct \
30, 2011&lt;/dc:date&gt;&lt;/rdf:Description&gt;&lt;/rdf:RDF&gt; ]]
3338:2] 15:33:35: DEBUG: Descriptive metadata from movie \
file:///home/okhin/swfcat.swf: &lt;rdf:RDF \
xmlns:rdf='http://www.w3.org/1999/02/22-rdf-syntax-ns#'&gt;&lt;rdf:Description rdf:about='' \
xmlns:dc='http://purl.org/dc/elements/1.1'&gt;&lt;dc:format&gt;application/x-shockwave-flash&lt;/dc:format&gt;&lt;dc:title&gt;Adobe \
Flex 4 Application&lt;/dc:title&gt;&lt;dc:description&gt;http://www.adobe.com/products/flex&lt;/dc:de \
scription&gt;&lt;dc:publisher&gt;unknown&lt;/dc:publisher&gt;&lt;dc:creator&gt;unknown&lt;/dc:creator&gt;&lt;dc:language&gt;EN&lt;/dc:language&gt;&lt;dc:date&gt;Oct \
30, 2011&lt;/dc:date&gt;&lt;/rdf:Description&gt;&lt;/rdf:RDF&gt; 3338:2] 15:33:35: SWF[492]: tag type = \
65, tag length = 4, end tag = 498 3338:2] 15:33:35:   ScriptLimits tag: recursion: \
1000, timeout: 60 3338:2] 15:33:35: SWF[498]: tag type = 9, tag length = 3, end tag = \
503 3338:2] 15:33:35:   SetBackgroundColor: rgba: 255,255,255,255
3338:2] 15:33:35: SWF[503]: tag type = 41, tag length = 26, end tag = 531
3338:2] 15:33:35: DEBUG: SERIALNUMBER: Version 3.6.4.5 - Build 0 - Timestamp \
1320006991989 3338:2] 15:33:35: SWF[531]: tag type = 43, tag length = 7, end tag = \
540 3338:2] 15:33:35: SWF[540]: tag type = 36, tag length = 230, end tag = 776
3338:2] 15:33:35:   defbitslossless2: tag = 36, id = 1, fmt = , w = 70, h = 23
3338:2] 15:33:35: SWF[776]: tag type = 82, tag length = 19044, end tag = 19826
3338:2] 15:33:35: ERROR: *** no tag loader for type 82 (movie)
3338:2] 15:33:35: ERROR: tag dump follows: 
01 00 00 00 66 72 61 6d 65 31 00 10 00 2e 00 05 | ....frame1......
00 0a c4 98 93 02 ff ff ff 07 00 05 00 00 00 00 | ................
00 00 24 40 00 00 00 00 00 00 f0 3f 00 00 00 00 | ..$@.......?....
00 00 14 40 00 00 00 00 00 00 00 00 c1 03 00 06 | ...@............
4f 62 6a 65 63 74 06 53 74 72 69 6e 67 04 76 6f | Object.String.vo
69 64 0c 66 6c 61 73 68 2e 65 76 65 6e 74 73 05 | id.flash.events.
45 76 65 6e 74 06 4e 75 6d 62 65 72 0c 49 4f 45 | Event.Number.IOE
72 72 6f 72 45 76 65 6e 74 12 53 65 63 75 72 69 | rrorEvent.Securi
74 79 45 72 72 6f 72 45 76 65 6e 74 0b 52 54 4d | tyErrorEvent.RTM
46 50 53 6f 63 6b 65 74 09 50 72 6f 78 79 50 61 | FPSocket.ProxyPa
69 72 0a 4d 6f 75 73 65 45 76 65 6e 74 07 42 6f | ir.MouseEvent.Bo
6f 6c 65 61 6e 06 73 77 66 63 61 74 08 46 75 6e | olean.swfcat.Fun
63 74 69 6f 6e 0d 50 72 6f 67 72 65 73 73 45 76 | ction
ProgressEv
65 6e 74 04 75 69 6e 74 0d 66 6c 61 73 68 2e 64 | ent.uint
flash.d
69 73 70 6c 61 79 0a 42 69 74 6d 61 70 44 61 74 | isplay.BitmapDat
61 04 61 75 74 6f 0d 44 69 73 70 6c 61 79 4f 62 | a.auto
DisplayOb
6a 65 63 74 05 53 74 61 67 65 16 44 69 73 70 6c | ject.Stage.Displ
61 79 4f 62 6a 65 63 74 43 6f 6e 74 61 69 6e 65 | ayObjectContaine
72 0a 66 6c 61 73 68 2e 67 65 6f 6d 09 52 65 63 | r.flash.geom.Rec
74 61 6e 67 6c 65 05 41 72 72 61 79 09 54 72 61 | tangle.Array.Tra
6e 73 66 6f 72 6d 05 50 6f 69 6e 74 0a 4c 6f 61 | nsform.Point.Loa
64 65 72 49 6e 66 6f 13 66 6c 61 73 68 2e 61 63 | derInfo.flash.ac
63 65 73 73 69 62 69 6c 69 74 79 17 41 63 63 65 | cessibility.Acce
73 73 69 62 69 6c 69 74 79 50 72 6f 70 65 72 74 | ssibilityPropert
69 65 73 0e 4e 65 74 53 74 61 74 75 73 45 76 65 | ies.NetStatusEve
6e 74 09 66 6c 61 73 68 2e 6e 65 74 09 4e 65 74 | nt.flash.net.Net
53 74 72 65 61 6d 0b 66 6c 61 73 68 2e 75 74 69 | Stream.flash.uti
6c 73 09 42 79 74 65 41 72 72 61 79 06 4d 61 74 | ls.ByteArray.Mat
72 69 78 08 4d 61 74 72 69 78 33 44 07 6d 78 2e | rix.Matrix3D.mx.
63 6f 72 65 0f 49 52 65 70 65 61 74 65 72 43 6c | core.IRepeaterCl
69 65 6e 74 06 53 70 72 69 74 65 09 52 54 4d 46 | ient.Sprite.RTMF
50 5f 55 52 4c 27 72 74 6d 66 70 3a 2f 2f 74 6f | P_URL'rtmfp://to
72 2d 66 61 63 69 6c 69 74 61 74 6f 72 2e 62 61 | r-facilitator.ba
6d 73 6f 66 74 77 61 72 65 2e 63 6f 6d 18 44 45 | msoftware.com.DE
46 41 55 4c 54 5f 46 41 43 49 4c 49 54 41 54 4f | FAULT_FACILITATO
52 5f 41 44 44 52 1d 44 45 46 41 55 4c 54 5f 4c | R_ADDR.DEFAULT_L
4f 43 41 4c 5f 54 4f 52 5f 43 4c 49 45 4e 54 5f | OCAL_TOR_CLIENT_
41 44 44 52 1b 44 45 46 41 55 4c 54 5f 4d 41 58 | ADDR.DEFAULT_MAX
5f 4e 55 4d 5f 50 52 4f 58 59 5f 50 41 49 52 53 | _NUM_PROXY_PAIRS
21 44 45 46 41 55 4c 54 5f 46 41 43 49 4c 49 54 | !DEFAULT_FACILIT
41 54 4f 52 5f 50 4f 4c 4c 5f 49 4e 54 45 52 56 | ATOR_POLL_INTERV
41 4c 1d 4d 49 4e 5f 46 41 43 49 4c 49 54 41 54 | AL.MIN_FACILITAT
4f 52 5f 50 4f 4c 4c 5f 49 4e 54 45 52 56 41 4c | OR_POLL_INTERVAL
0b 6f 75 74 70 75 74 5f 74 65 78 74 0a 66 6c 61 | .output_text.fla
73 68 2e 74 65 78 74 09 54 65 78 74 46 69 65 6c | sh.text.TextFiel
64 05 62 61 64 67 65 05 42 61 64 67 65 0b 70 72 | d.badge.Badge.pr
6f 78 79 5f 70 61 69 72 73 05 64 65 62 75 67 08 | oxy_pairs.debug.
66 61 63 5f 61 64 64 72 13 6d 61 78 5f 6e 75 6d | fac_addr.max_num
5f 70 72 6f 78 79 5f 70 61 69 72 73 19 66 61 63 | _proxy_pairs.fac
69 6c 69 74 61 74 6f 72 5f 70 6f 6c 6c 5f 69 6e | ilitator_poll_in
74 65 72 76 61 6c 0a 6c 6f 63 61 6c 5f 61 64 64 | terval.local_add
72 0a 72 61 74 65 5f 6c 69 6d 69 74 09 52 61 74 | r.rate_limit.Rat
65 4c 69 6d 69 74 04 70 75 74 73 13 6c 6f 61 64 | eLimit.puts.load
65 72 69 6e 66 6f 5f 63 6f 6d 70 6c 65 74 65 0e | erinfo_complete.
67 65 74 5f 70 61 72 61 6d 5f 61 64 64 72 10 67 | get_param_addr.g
65 74 5f 70 61 72 61 6d 5f 6e 75 6d 62 65 72 12 | et_param_number.
67 65 74 5f 70 61 72 61 6d 5f 74 69 6d 65 73 70 | get_param_timesp
65 63 0a 70 72 6f 78 79 5f 6d 61 69 6e 0c 66 61 | ec.proxy_main.fa
63 5f 63 6f 6d 70 6c 65 74 65 0b 63 6c 69 65 6e | c_complete.clien
74 5f 6d 61 69 6e 0d 63 6c 69 65 6e 74 5f 61 63 | t_main
client_ac
63 65 70 74 08 72 65 67 69 73 74 65 72 0f 6d 61 | cept.register.ma
6b 65 5f 70 72 6f 78 79 5f 70 61 69 72 12 73 77 | ke_proxy_pair.sw
66 63 61 74 2e 61 73 24 32 39 3a 42 61 64 67 65 | fcat.as$29:Badge
13 46 4c 41 53 48 50 52 4f 58 59 5f 49 4e 46 4f | .FLASHPROXY_INFO
5f 55 52 4c 27 68 74 74 70 73 3a 2f 2f 63 72 79 | _URL'https://cry
70 74 6f 2e 73 74 61 6e 66 6f 72 64 2e 65 64 75 | pto.stanford.edu
2f 66 6c 61 73 68 70 72 6f 78 79 2f 0f 6e 75 6d | /flashproxy/.num
5f 70 72 6f 78 79 5f 70 61 69 72 73 03 69 6e 74 | _proxy_pairs.int
11 74 6f 74 61 6c 5f 70 72 6f 78 79 5f 70 61 69 | .total_proxy_pai
72 73 0a 42 61 64 67 65 49 6d 61 67 65 05 43 6c | rs.BadgeImage.Cl
61 73 73 13 74 6f 74 5f 63 6c 69 65 6e 74 5f 63 | ass.tot_client_c
6f 75 6e 74 5f 74 66 14 74 6f 74 5f 63 6c 69 65 | ount_tf.tot_clie
6e 74 5f 63 6f 75 6e 74 5f 66 6d 74 0a 54 65 78 | nt_count_fmt.Tex
74 46 6f 72 6d 61 74 13 63 75 72 5f 63 6c 69 65 | tFormat.cur_clie
6e 74 5f 63 6f 75 6e 74 5f 74 66 14 63 75 72 5f | nt_count_tf.cur_
63 6c 69 65 6e 74 5f 63 6f 75 6e 74 5f 66 6d 74 | client_count_fmt
0b 70 72 6f 78 79 5f 62 65 67 69 6e 09 70 72 6f | .proxy_begin.pro
78 79 5f 65 6e 64 13 75 70 64 61 74 65 5f 63 6c | xy_end.update_cl
69 65 6e 74 5f 63 6f 75 6e 74 0d 6d 6f 75 73 65 | ient_count
mouse
5f 63 6c 69 63 6b 65 64 16 73 77 66 63 61 74 2e | _clicked.swfcat.
61 73 24 32 39 3a 52 61 74 65 4c 69 6d 69 74 06 | as$29:RateLimit.
75 70 64 61 74 65 04 77 68 65 6e 0a 69 73 5f 6c | update.when.is_l
69 6d 69 74 65 64 0b 52 61 74 65 55 6e 6c 69 6d | imited.RateUnlim
69 74 18 73 77 66 63 61 74 2e 61 73 24 32 39 3a | it.swfcat.as$29:
52 61 74 65 55 6e 6c 69 6d 69 74 0f 42 75 63 6b | RateUnlimit.Buck
65 74 52 61 74 65 4c 69 6d 69 74 1c 73 77 66 63 | etRateLimit.swfc
61 74 2e 61 73 24 32 39 3a 42 75 63 6b 65 74 52 | at.as$29:BucketR
61 74 65 4c 69 6d 69 74 06 61 6d 6f 75 6e 74 08 | ateLimit.amount.
63 61 70 61 63 69 74 79 04 74 69 6d 65 0b 6c 61 | capacity.time.la
73 74 5f 75 70 64 61 74 65 03 61 67 65 0f 45 76 | st_update.age.Ev
65 6e 74 44 69 73 70 61 74 63 68 65 72 04 6e 61 | entDispatcher.na
6d 65 03 73 5f 63 09 63 6f 6e 6e 65 63 74 5f 63 | me.s_c.connect_c
03 73 5f 72 09 63 6f 6e 6e 65 63 74 5f 72 02 75 | .s_r.connect_r.u
69 0c 72 32 63 5f 73 63 68 65 64 75 6c 65 0c 63 | i.r2c_schedule.c
32 72 5f 73 63 68 65 64 75 6c 65 08 66 6c 75 73 | 2r_schedule.flus
68 5f 69 64 03 6c 6f 67 08 6c 6f 67 64 65 62 75 | h_id.log.logdebu
67 08 73 65 74 5f 6e 61 6d 65 0c 73 6f 63 6b 65 | g.set_name.socke
74 5f 65 72 72 6f 72 07 63 6f 6e 6e 65 63 74 0f | t_error.connect.
72 65 6c 61 79 5f 63 6f 6e 6e 65 63 74 65 64 10 | relay_connected.
63 6c 69 65 6e 74 5f 63 6f 6e 6e 65 63 74 65 64 | client_connected
0c 72 65 6c 61 79 5f 63 6c 6f 73 65 64 0d 63 6c | .relay_closed
cl
69 65 6e 74 5f 63 6c 6f 73 65 64 0f 72 65 6c 61 | ient_closed.rela
79 5f 74 6f 5f 63 6c 69 65 6e 74 0f 63 6c 69 65 | y_to_client.clie
6e 74 5f 74 6f 5f 72 65 6c 61 79 0e 74 72 61 6e | nt_to_relay.tran
73 66 65 72 5f 63 68 75 6e 6b 05 66 6c 75 73 68 | sfer_chunk.flush
0a 49 46 6c 65 78 41 73 73 65 74 0a 46 6c 65 78 | .IFlexAsset.Flex
42 69 74 6d 61 70 06 42 69 74 6d 61 70 12 6d 78 | Bitmap.Bitmap.mx
2e 63 6f 72 65 3a 46 6c 65 78 42 69 74 6d 61 70 | .core:FlexBitmap
08 74 6f 53 74 72 69 6e 67 17 49 4c 61 79 6f 75 | .toString.ILayou
74 44 69 72 65 63 74 69 6f 6e 45 6c 65 6d 65 6e | tDirectionElemen
74 1f 6d 78 2e 63 6f 72 65 3a 49 4c 61 79 6f 75 | t.mx.core:ILayou
74 44 69 72 65 63 74 69 6f 6e 45 6c 65 6d 65 6e | tDirectionElemen
74 0f 6c 61 79 6f 75 74 44 69 72 65 63 74 69 6f | t.layoutDirectio
6e 19 69 6e 76 61 6c 69 64 61 74 65 4c 61 79 6f | n.invalidateLayo
75 74 44 69 72 65 63 74 69 6f 6e 12 49 46 6c 65 | utDirection.IFle
78 44 69 73 70 6c 61 79 4f 62 6a 65 63 74 0f 49 | xDisplayObject.I
42 69 74 6d 61 70 44 72 61 77 61 62 6c 65 10 49 | BitmapDrawable.I
45 76 65 6e 74 44 69 73 70 61 74 63 68 65 72 1a | EventDispatcher.
6d 78 2e 63 6f 72 65 3a 49 46 6c 65 78 44 69 73 | mx.core:IFlexDis
70 6c 61 79 4f 62 6a 65 63 74 04 72 6f 6f 74 05 | playObject.root.
73 74 61 67 65 06 70 61 72 65 6e 74 04 6d 61 73 | stage.parent.mas
6b 07 76 69 73 69 62 6c 65 01 78 01 79 06 73 63 | k.visible.x.y.sc
61 6c 65 58 06 73 63 61 6c 65 59 06 6d 6f 75 73 | aleX.scaleY.mous
65 58 06 6d 6f 75 73 65 59 08 72 6f 74 61 74 69 | eX.mouseY.rotati
6f 6e 05 61 6c 70 68 61 05 77 69 64 74 68 06 68 | on.alpha.width.h
65 69 67 68 74 0d 63 61 63 68 65 41 73 42 69 74 | eight
cacheAsBit
6d 61 70 10 6f 70 61 71 75 65 42 61 63 6b 67 72 | map.opaqueBackgr
6f 75 6e 64 0a 73 63 72 6f 6c 6c 52 65 63 74 07 | ound.scrollRect.
66 69 6c 74 65 72 73 09 62 6c 65 6e 64 4d 6f 64 | filters.blendMod
65 09 74 72 61 6e 73 66 6f 72 6d 0a 73 63 61 6c | e.transform.scal
65 39 47 72 69 64 0d 67 6c 6f 62 61 6c 54 6f 4c | e9Grid
globalToL
6f 63 61 6c 0d 6c 6f 63 61 6c 54 6f 47 6c 6f 62 | ocal
localToGlob
61 6c 09 67 65 74 42 6f 75 6e 64 73 07 67 65 74 | al.getBounds.get
52 65 63 74 0a 6c 6f 61 64 65 72 49 6e 66 6f 0d | Rect.loaderInfo
68 69 74 54 65 73 74 4f 62 6a 65 63 74 0c 68 69 | hitTestObject.hi
74 54 65 73 74 50 6f 69 6e 74 17 61 63 63 65 73 | tTestPoint.acces
73 69 62 69 6c 69 74 79 50 72 6f 70 65 72 74 69 | sibilityProperti
65 73 0e 6d 65 61 73 75 72 65 64 48 65 69 67 68 | es.measuredHeigh
74 0d 6d 65 61 73 75 72 65 64 57 69 64 74 68 04 | t
measuredWidth.
6d 6f 76 65 0d 73 65 74 41 63 74 75 61 6c 53 69 | move
setActualSi
7a 65 0b 42 69 74 6d 61 70 41 73 73 65 74 13 6d | ze.BitmapAsset.m
78 2e 63 6f 72 65 3a 42 69 74 6d 61 70 41 73 73 | x.core:BitmapAss
65 74 13 6c 61 79 6f 75 74 46 65 61 74 75 72 65 | et.layoutFeature
73 43 6c 61 73 73 0e 6c 61 79 6f 75 74 46 65 61 | sClass.layoutFea
74 75 72 65 73 14 49 41 73 73 65 74 4c 61 79 6f | tures.IAssetLayo
75 74 46 65 61 74 75 72 65 73 01 7a 07 5f 68 65 | utFeatures.z._he
69 67 68 74 09 72 6f 74 61 74 69 6f 6e 58 09 72 | ight.rotationX.r
6f 74 61 74 69 6f 6e 59 09 72 6f 74 61 74 69 6f | otationY.rotatio
6e 5a 06 73 63 61 6c 65 5a 10 5f 6c 61 79 6f 75 | nZ.scaleZ._layou
74 44 69 72 65 63 74 69 6f 6e 03 6c 74 72 0c 61 | tDirection.ltr.a
64 64 65 64 48 61 6e 64 6c 65 72 1a 69 6e 69 74 | ddedHandler.init
41 64 76 61 6e 63 65 64 4c 61 79 6f 75 74 46 65 | AdvancedLayoutFe
61 74 75 72 65 73 17 76 61 6c 69 64 61 74 65 54 | atures.validateT
72 61 6e 73 66 6f 72 6d 4d 61 74 72 69 78 10 42 | ransformMatrix.B
61 64 67 65 5f 42 61 64 67 65 49 6d 61 67 65 09 | adge_BadgeImage.
63 6f 6e 6e 65 63 74 65 64 02 6e 63 0d 4e 65 74 | connected.nc
Net
43 6f 6e 6e 65 63 74 69 6f 6e 08 69 6e 63 6f 6d | Connection.incom
69 6e 67 08 6f 75 74 67 6f 69 6e 67 0f 63 6f 6e | ing.outgoing.con
6e 65 63 74 5f 70 65 65 72 5f 69 64 06 62 75 66 | nect_peer_id.buf
66 65 72 0a 63 69 72 72 75 73 5f 75 72 6c 0a 63 | fer.cirrus_url.c
69 72 72 75 73 5f 6b 65 79 02 69 64 07 70 65 65 | irrus_key.id.pee
72 5f 69 64 17 67 65 6e 65 72 69 63 5f 6e 65 74 | r_id.generic_net
73 74 61 74 75 73 5f 65 76 65 6e 74 16 6c 69 73 | status_event.lis
74 65 6e 5f 6e 65 74 73 74 61 74 75 73 5f 65 76 | ten_netstatus_ev
65 6e 74 14 6c 69 73 74 65 6e 5f 6f 6e 70 65 65 | ent.listen_onpee
72 63 6f 6e 6e 65 63 74 17 63 6f 6e 6e 65 63 74 | rconnect.connect
5f 6e 65 74 73 74 61 74 75 73 5f 65 76 65 6e 74 | _netstatus_event
0c 72 65 63 65 69 76 65 5f 64 61 74 61 06 6c 69 | .receive_data.li
73 74 65 6e 05 63 6c 6f 73 65 09 72 65 61 64 42 | sten.close.readB
79 74 65 73 0a 77 72 69 74 65 42 79 74 65 73 08 | ytes.writeBytes.
6d 78 2e 75 74 69 6c 73 08 4e 61 6d 65 55 74 69 | mx.utils.NameUti
6c 11 6d 78 2e 75 74 69 6c 73 3a 4e 61 6d 65 55 | l.mx.utils:NameU
74 69 6c 1c 6d 78 2e 63 6f 72 65 3a 49 41 73 73 | til.mx.core:IAss
65 74 4c 61 79 6f 75 74 46 65 61 74 75 72 65 73 | etLayoutFeatures
07 6c 61 79 6f 75 74 58 07 6c 61 79 6f 75 74 59 | .layoutX.layoutY
07 6c 61 79 6f 75 74 5a 0b 6c 61 79 6f 75 74 57 | .layoutZ.layoutW
69 64 74 68 0a 74 72 61 6e 73 66 6f 72 6d 58 0a | idth.transformX.
74 72 61 6e 73 66 6f 72 6d 59 0a 74 72 61 6e 73 | transformY.trans
66 6f 72 6d 5a 0f 6c 61 79 6f 75 74 52 6f 74 61 | formZ.layoutRota
74 69 6f 6e 58 0f 6c 61 79 6f 75 74 52 6f 74 61 | tionX.layoutRota
74 69 6f 6e 59 0f 6c 61 79 6f 75 74 52 6f 74 61 | tionY.layoutRota
74 69 6f 6e 5a 0c 6c 61 79 6f 75 74 53 63 61 6c | tionZ.layoutScal
65 58 0c 6c 61 79 6f 75 74 53 63 61 6c 65 59 0c | eX.layoutScaleY.
6c 61 79 6f 75 74 53 63 61 6c 65 5a 0c 6c 61 79 | layoutScaleZ.lay
6f 75 74 4d 61 74 72 69 78 0e 6c 61 79 6f 75 74 | outMatrix.layout
4d 61 74 72 69 78 33 44 04 69 73 33 44 0a 6c 61 | Matrix3D.is3D.la
79 6f 75 74 49 73 33 44 06 6d 69 72 72 6f 72 08 | youtIs3D.mirror.
73 74 72 65 74 63 68 58 08 73 74 72 65 74 63 68 | stretchX.stretch
59 0e 63 6f 6d 70 75 74 65 64 4d 61 74 72 69 78 | Y.computedMatrix
10 63 6f 6d 70 75 74 65 64 4d 61 74 72 69 78 33 | .computedMatrix3
44 17 6d 78 2e 63 6f 72 65 3a 49 52 65 70 65 61 | D.mx.core:IRepea
74 65 72 43 6c 69 65 6e 74 0f 69 6e 73 74 61 6e | terClient.instan
63 65 49 6e 64 69 63 65 73 0a 69 73 44 6f 63 75 | ceIndices.isDocu
6d 65 6e 74 0f 72 65 70 65 61 74 65 72 49 6e 64 | ment.repeaterInd
69 63 65 73 09 72 65 70 65 61 74 65 72 73 18 69 | ices.repeaters.i
6e 69 74 69 61 6c 69 7a 65 52 65 70 65 61 74 65 | nitializeRepeate
72 41 72 72 61 79 73 0a 52 41 54 45 5f 4c 49 4d | rArrays.RATE_LIM
49 54 12 52 41 54 45 5f 4c 49 4d 49 54 5f 48 49 | IT.RATE_LIMIT_HI
53 54 4f 52 59 0f 70 61 72 73 65 5f 61 64 64 72 | STORY.parse_addr
5f 73 70 65 63 2a 68 74 74 70 3a 2f 2f 77 77 77 | _spec*http://www
2e 61 64 6f 62 65 2e 63 6f 6d 2f 32 30 30 36 2f | .adobe.com/2006/
66 6c 65 78 2f 6d 78 2f 69 6e 74 65 72 6e 61 6c | flex/mx/internal
07 56 45 52 53 49 4f 4e 07 34 2e 35 2e 30 2e 30 | .VERSION.4.5.0.0
10 46 6c 65 78 56 65 72 73 69 6f 6e 43 6c 61 73 | .FlexVersionClas
73 0f 4d 61 74 72 69 78 55 74 69 6c 43 6c 61 73 | s.MatrixUtilClas
73 0c 41 43 43 45 50 54 5f 45 56 45 4e 54 06 61 | s.ACCEPT_EVENT.a
63 63 65 70 74 07 63 6f 75 6e 74 65 72 10 63 72 | ccept.counter.cr
65 61 74 65 55 6e 69 71 75 65 4e 61 6d 65 15 64 | eateUniqueName.d
69 73 70 6c 61 79 4f 62 6a 65 63 74 54 6f 53 74 | isplayObjectToSt
72 69 6e 67 17 67 65 74 55 6e 71 75 61 6c 69 66 | ring.getUnqualif
69 65 64 43 6c 61 73 73 4e 61 6d 65 0b 6d 78 5f | iedClassName.mx_
69 6e 74 65 72 6e 61 6c 09 75 6e 64 65 66 69 6e | internal.undefin
65 64 01 3a 21 68 74 74 70 3a 2f 2f 61 64 6f 62 | ed.:!http://adob
65 2e 63 6f 6d 2f 41 53 33 2f 32 30 30 36 2f 62 | e.com/AS3/2006/b
75 69 6c 74 69 6e 05 73 70 6c 69 74 06 6c 65 6e | uiltin.split.len
67 74 68 08 70 61 72 73 65 49 6e 74 14 66 6c 61 | gth.parseInt.fla
73 68 2e 64 69 73 70 6c 61 79 3a 53 70 72 69 74 | sh.display:Sprit
65 24 66 6c 61 73 68 2e 64 69 73 70 6c 61 79 3a | e$flash.display:
44 69 73 70 6c 61 79 4f 62 6a 65 63 74 43 6f 6e | DisplayObjectCon
74 61 69 6e 65 72 1f 66 6c 61 73 68 2e 64 69 73 | tainer.flash.dis
70 6c 61 79 3a 49 6e 74 65 72 61 63 74 69 76 65 | play:Interactive
4f 62 6a 65 63 74 1b 66 6c 61 73 68 2e 64 69 73 | Object.flash.dis
70 6c 61 79 3a 44 69 73 70 6c 61 79 4f 62 6a 65 | play:DisplayObje
63 74 1c 66 6c 61 73 68 2e 65 76 65 6e 74 73 3a | ct.flash.events:
45 76 65 6e 74 44 69 73 70 61 74 63 68 65 72 04 | EventDispatcher.
68 6f 73 74 04 70 6f 72 74 01 0a 0a 61 70 70 65 | host.port...appe
6e 64 54 65 78 74 0a 6d 61 78 53 63 72 6f 6c 6c | ndText.maxScroll
56 07 73 63 72 6f 6c 6c 56 1f 74 6f 72 2d 66 61 | V.scrollV.tor-fa
63 69 6c 69 74 61 74 6f 72 2e 62 61 6d 73 6f 66 | cilitator.bamsof
74 77 61 72 65 2e 63 6f 6d 09 31 32 37 2e 30 2e | tware.com.127.0.
30 2e 31 0e 53 74 61 67 65 53 63 61 6c 65 4d 6f | 0.1.StageScaleMo
64 65 08 4e 4f 5f 53 43 41 4c 45 09 73 63 61 6c | de.NO_SCALE.scal
65 4d 6f 64 65 0a 53 74 61 67 65 41 6c 69 67 6e | eMode.StageAlign
08 54 4f 50 5f 4c 45 46 54 05 61 6c 69 67 6e 08 | .TOP_LEFT.align.
43 4f 4d 50 4c 45 54 45 10 61 64 64 45 76 65 6e | COMPLETE.addEven
74 4c 69 73 74 65 6e 65 72 0a 70 61 72 61 6d 65 | tListener.parame
74 65 72 73 06 63 6c 69 65 6e 74 0a 73 74 61 67 | ters.client.stag
65 57 69 64 74 68 0b 73 74 61 67 65 48 65 69 67 | eWidth.stageHeig
68 74 0a 62 61 63 6b 67 72 6f 75 6e 64 0f 62 61 | ht.background.ba
63 6b 67 72 6f 75 6e 64 43 6f 6c 6f 72 09 74 65 | ckgroundColor.te
78 74 43 6f 6c 6f 72 08 61 64 64 43 68 69 6c 64 | xtColor.addChild
12 50 61 72 61 6d 65 74 65 72 73 20 6c 6f 61 64 | .Parameters load
65 64 2e 0b 66 61 63 69 6c 69 74 61 74 6f 72 38 | ed..facilitator8
45 72 72 6f 72 3a 20 46 61 63 69 6c 69 74 61 74 | Error: Facilitat
6f 72 20 73 70 65 63 20 6d 75 73 74 20 62 65 20 | or spec must be 
69 6e 20 74 68 65 20 66 6f 72 6d 20 22 68 6f 73 | in the form "hos
74 3a 70 6f 72 74 22 2e 0b 6d 61 78 5f 63 6c 69 | t:port"..max_cli
65 6e 74 73 31 45 72 72 6f 72 3a 20 6d 61 78 5f | ents1Error: max_
63 6c 69 65 6e 74 73 20 6d 75 73 74 20 62 65 20 | clients must be 
61 20 6e 6f 6e 6e 65 67 61 74 69 76 65 20 69 6e | a nonnegative in
74 65 67 65 72 2e 47 45 72 72 6f 72 3a 20 66 61 | teger.GError: fa
63 69 6c 69 74 61 74 6f 72 5f 70 6f 6c 6c 5f 69 | cilitator_poll_i
6e 74 65 72 76 61 6c 20 6d 75 73 74 20 62 65 20 | nterval must be 
61 20 6e 6f 6e 6e 65 67 61 74 69 76 65 20 6e 75 | a nonnegative nu
6d 62 65 72 20 61 74 20 6c 65 61 73 74 20 01 2e | mber at least ..
05 6c 6f 63 61 6c 32 45 72 72 6f 72 3a 20 4c 6f | .local2Error: Lo
63 61 6c 20 73 70 65 63 20 6d 75 73 74 20 62 65 | cal spec must be
20 69 6e 20 74 68 65 20 66 6f 72 6d 20 22 68 6f |  in the form "ho
73 74 3a 70 6f 72 74 22 2e 05 69 73 4e 61 4e 18 | st:port"..isNaN.
46 61 63 69 6c 69 74 61 74 6f 72 3a 20 49 2f 4f | Facilitator: I/O
20 65 72 72 6f 72 3a 20 04 74 65 78 74 1d 46 61 |  error: .text.Fa
63 69 6c 69 74 61 74 6f 72 3a 20 73 65 63 75 72 | cilitator: secur
69 74 79 20 65 72 72 6f 72 3a 20 09 55 52 4c 4c | ity error: .URLL
6f 61 64 65 72 0a 73 65 74 54 69 6d 65 6f 75 74 | oader.setTimeout
13 55 52 4c 4c 6f 61 64 65 72 44 61 74 61 46 6f | .URLLoaderDataFo
72 6d 61 74 09 56 41 52 49 41 42 4c 45 53 0a 64 | rmat.VARIABLES.d
61 74 61 46 6f 72 6d 61 74 08 49 4f 5f 45 52 52 | ataFormat.IO_ERR
4f 52 0e 53 45 43 55 52 49 54 59 5f 45 52 52 4f | OR.SECURITY_ERRO
52 07 68 74 74 70 3a 2f 2f 12 65 6e 63 6f 64 65 | R.http://.encode
55 52 49 43 6f 6d 70 6f 6e 65 6e 74 01 2f 1b 46 | URIComponent./.F
61 63 69 6c 69 74 61 74 6f 72 3a 20 63 6f 6e 6e | acilitator: conn
65 63 74 69 6e 67 20 74 6f 20 0a 55 52 4c 52 65 | ecting to .URLRe
71 75 65 73 74 04 6c 6f 61 64 07 66 61 63 5f 75 | quest.load.fac_u
72 6c 06 6c 6f 61 64 65 72 0a 70 72 6f 78 79 5f | rl.loader.proxy_
70 61 69 72 09 43 6f 6d 70 6c 65 74 65 2e 07 69 | pair.Complete..i
6e 64 65 78 4f 66 06 73 70 6c 69 63 65 06 74 61 | ndexOf.splice.ta
72 67 65 74 04 64 61 74 61 0b 4e 6f 20 63 6c 69 | rget.data.No cli
65 6e 74 73 2e 24 45 72 72 6f 72 3a 20 6d 69 73 | ents.$Error: mis
73 69 6e 67 20 22 63 6c 69 65 6e 74 22 20 69 6e | sing "client" in
20 72 65 73 70 6f 6e 73 65 2e 05 72 65 6c 61 79 |  response..relay
23 45 72 72 6f 72 3a 20 6d 69 73 73 69 6e 67 20 | #Error: missing 
22 72 65 6c 61 79 22 20 69 6e 20 72 65 73 70 6f | "relay" in respo
6e 73 65 2e 19 46 61 63 69 6c 69 74 61 74 6f 72 | nse..Facilitator
3a 20 67 6f 74 20 63 6c 69 65 6e 74 3a 22 02 22 | : got client:"."
20 07 72 65 6c 61 79 3a 22 02 22 2e 07 45 72 72 |  .relay:"."..Err
6f 72 3a 20 04 70 75 73 68 0d 41 72 67 75 6d 65 | or: .push
Argume
6e 74 45 72 72 6f 72 01 65 0b 63 6c 69 65 6e 74 | ntError.e.client
5f 73 70 65 63 0a 72 65 6c 61 79 5f 73 70 65 63 | _spec.relay_spec
0d 47 6f 74 20 52 54 4d 46 50 20 69 64 20 02 72 | 
Got RTMFP id .r
73 14 4d 61 6b 69 6e 67 20 52 54 4d 46 50 20 73 | s.Making RTMFP s
6f 63 6b 65 74 2e 03 73 5f 74 06 53 6f 63 6b 65 | ocket..s_t.Socke
74 1a 47 6f 74 20 52 54 4d 46 50 20 63 6f 6e 6e | t.Got RTMFP conn
65 63 74 69 6f 6e 20 66 72 6f 6d 20 18 46 61 63 | ection from .Fac
69 6c 69 74 61 74 6f 72 3a 20 72 65 67 69 73 74 | ilitator: regist
65 72 65 64 2e 10 55 52 4c 52 65 71 75 65 73 74 | ered..URLRequest
4d 65 74 68 6f 64 04 50 4f 53 54 06 6d 65 74 68 | Method.POST.meth
6f 64 0c 55 52 4c 56 61 72 69 61 62 6c 65 73 07 | od.URLVariables.
72 65 71 75 65 73 74 06 61 64 64 72 5f 63 06 61 | request.addr_c.a
64 64 72 5f 72 2b 52 65 6c 61 79 20 73 70 65 63 | ddr_r+Relay spec
20 6d 75 73 74 20 62 65 20 69 6e 20 74 68 65 20 |  must be in the 
66 6f 72 6d 20 22 68 6f 73 74 3a 70 6f 72 74 22 | form "host:port"
2e 01 3c 01 2c 01 3e 06 52 65 67 45 78 70 11 5e | ..&lt;.,.&gt;.RegExp.^
5b 30 2d 39 41 2d 46 61 2d 66 5d 7b 36 34 7d 24 | [0-9A-Fa-f]{64}$
05 6d 61 74 63 68 06 73 75 62 73 74 72 04 2e 2e | .match.substr...
2e 2c 19 43 61 6e 27 74 20 70 61 72 73 65 20 63 | .,.Can't parse c
6c 69 65 6e 74 20 73 70 65 63 20 22 05 63 6f 6c | lient spec ".col
6f 72 06 63 65 6e 74 65 72 0b 63 6f 75 72 69 65 | or.center.courie
72 2d 6e 65 77 04 66 6f 6e 74 04 62 6f 6c 64 04 | r-new.font.bold.
73 69 7a 65 11 64 65 66 61 75 6c 74 54 65 78 74 | size.defaultText
46 6f 72 6d 61 74 05 43 4c 49 43 4b 01 30 0d 6e | Format.CLICK.0
n
61 76 69 67 61 74 65 54 6f 55 52 4c 05 45 72 72 | avigateToURL.Err
6f 72 03 65 72 72 08 67 65 74 54 69 6d 65 72 11 | or.err.getTimer.
49 6e 74 65 72 61 63 74 69 76 65 4f 62 6a 65 63 | InteractiveObjec
74 02 3a 20 09 54 65 78 74 45 76 65 6e 74 07 6d | t.: .TextEvent.m
65 73 73 61 67 65 05 6f 74 68 65 72 0d 64 69 73 | essage.other
dis
70 61 74 63 68 45 76 65 6e 74 07 43 4f 4e 4e 45 | patchEvent.CONNE
43 54 05 43 4c 4f 53 45 10 52 65 6c 61 79 3a 20 | CT.CLOSE.Relay: 
49 2f 4f 20 65 72 72 6f 72 15 52 65 6c 61 79 3a | I/O error.Relay:
20 73 65 63 75 72 69 74 79 20 65 72 72 6f 72 0b |  security error.
53 4f 43 4b 45 54 5f 44 41 54 41 11 43 6c 69 65 | SOCKET_DATA.Clie
6e 74 3a 20 49 2f 4f 20 65 72 72 6f 72 16 43 6c | nt: I/O error.Cl
69 65 6e 74 3a 20 73 65 63 75 72 69 74 79 20 65 | ient: security e
72 72 6f 72 12 52 65 6c 61 79 3a 20 63 6f 6e 6e | rror.Relay: conn
65 63 74 69 6e 67 2e 13 43 6c 69 65 6e 74 3a 20 | ecting..Client: 
63 6f 6e 6e 65 63 74 69 6e 67 2e 11 52 65 6c 61 | connecting..Rela
79 3a 20 63 6f 6e 6e 65 63 74 65 64 2e 12 43 6c | y: connected..Cl
69 65 6e 74 3a 20 63 6f 6e 6e 65 63 74 65 64 2e | ient: connected.
0e 52 65 6c 61 79 3a 20 63 6c 6f 73 65 64 2e 0f | .Relay: closed..
43 6c 69 65 6e 74 3a 20 63 6c 6f 73 65 64 2e 0b | Client: closed..
62 79 74 65 73 4c 6f 61 64 65 64 07 3a 20 72 65 | bytesLoaded.: re
61 64 20 0c 63 6c 65 61 72 54 69 6d 65 6f 75 74 | ad .clearTimeout
05 73 68 69 66 74 05 52 65 6c 61 79 06 43 6c 69 | .shift.Relay.Cli
65 6e 74 10 43 6c 69 65 6e 74 3a 20 63 6c 6f 73 | ent.Client: clos
69 6e 67 2e 0f 52 65 6c 61 79 3a 20 63 6c 6f 73 | ing..Relay: clos
69 6e 67 2e 0c 66 6c 61 73 68 2e 73 79 73 74 65 | ing..flash.syste
6d 11 41 70 70 6c 69 63 61 74 69 6f 6e 44 6f 6d | m.ApplicationDom
61 69 6e 0d 63 75 72 72 65 6e 74 44 6f 6d 61 69 | ain
currentDomai
6e 14 6d 78 2e 63 6f 72 65 3a 3a 46 6c 65 78 56 | n.mx.core::FlexV
65 72 73 69 6f 6e 0d 68 61 73 44 65 66 69 6e 69 | ersion
hasDefini
74 69 6f 6e 0d 67 65 74 44 65 66 69 6e 69 74 69 | tion
getDefiniti
6f 6e 14 63 6f 6d 70 61 74 69 62 69 6c 69 74 79 | on.compatibility
56 65 72 73 69 6f 6e 14 66 6c 61 73 68 2e 64 69 | Version.flash.di
73 70 6c 61 79 3a 42 69 74 6d 61 70 0b 56 45 52 | splay:Bitmap.VER
53 49 4f 4e 5f 34 5f 30 05 41 44 44 45 44 0d 74 | SION_4_0.ADDED
t
72 61 6e 73 66 6f 72 6d 53 69 7a 65 06 6d 61 74 | ransformSize.mat
72 69 78 04 4d 61 74 68 03 61 62 73 0a 62 69 74 | rix.Math.abs.bit
6d 61 70 44 61 74 61 1f 6d 78 2e 63 6f 72 65 3a | mapData.mx.core:
3a 41 64 76 61 6e 63 65 64 4c 61 79 6f 75 74 46 | :AdvancedLayoutF
65 61 74 75 72 65 73 14 6d 78 2e 75 74 69 6c 73 | eatures.mx.utils
3a 3a 4d 61 74 72 69 78 55 74 69 6c 08 6d 61 74 | ::MatrixUtil.mat
72 69 78 33 44 06 6e 65 61 72 49 44 05 66 61 72 | rix3D.nearID.far
49 44 04 69 6e 66 6f 04 63 6f 64 65 1c 4e 65 74 | ID.info.code.Net
43 6f 6e 6e 65 63 74 69 6f 6e 2e 43 6f 6e 6e 65 | Connection.Conne
63 74 2e 43 6c 6f 73 65 64 18 4e 65 74 53 74 72 | ct.Closed.NetStr
65 61 6d 2e 43 6f 6e 6e 65 63 74 2e 43 6c 6f 73 | eam.Connect.Clos
65 64 12 44 49 52 45 43 54 5f 43 4f 4e 4e 45 43 | ed.DIRECT_CONNEC
54 49 4f 4e 53 0d 6f 6e 50 65 65 72 43 6f 6e 6e | TIONS
onPeerConn
65 63 74 06 73 65 72 76 65 72 07 70 75 62 6c 69 | ect.server.publi
73 68 1d 4e 65 74 43 6f 6e 6e 65 63 74 69 6f 6e | sh.NetConnection
2e 43 6f 6e 6e 65 63 74 2e 53 75 63 63 65 73 73 | .Connect.Success
19 4e 65 74 53 74 72 65 61 6d 2e 43 6f 6e 6e 65 | .NetStream.Conne
63 74 2e 53 75 63 63 65 73 73 01 72 04 70 6c 61 | ct.Success.r.pla
79 0e 62 79 74 65 73 41 76 61 69 6c 61 62 6c 65 | y.bytesAvailable
0a 4e 45 54 5f 53 54 41 54 55 53 05 63 6c 65 61 | .NET_STATUS.clea
72 04 73 65 6e 64 15 67 65 74 51 75 61 6c 69 66 | r.send.getQualif
69 65 64 43 6c 61 73 73 4e 61 6d 65 02 3a 3a 0a | iedClassName.::.
63 68 61 72 43 6f 64 65 41 74 01 5f 01 5b 02 5d | charCodeAt._.[.]
5b 04 6a 6f 69 6e 01 5d 0d 53 65 63 75 72 69 74 | [.join.]
Securit
79 45 72 72 6f 72 39 16 01 16 05 16 12 16 18 16 | yError9.........
1e 16 21 16 23 16 27 18 0e 05 00 16 32 05 00 18 | ..!.#.'.....2...
49 05 00 18 5a 18 5f 18 61 05 00 18 0b 05 00 18 | I...Z._.a.......
81 01 08 84 01 08 8a 01 18 ae 01 05 00 18 bd 01 | ................
18 0a 05 00 16 d2 01 18 d4 01 08 d5 01 08 ec 01 | ................
08 f5 01 05 00 08 83 02 17 01 1a 0e 1a 87 02 1a | ................
88 02 1a 89 02 1a 8a 02 1a 8b 02 1a 02 05 00 1a | ................
0b 16 94 03 05 00 17 27 1a ae 01 1a 81 01 1a 9b | .......'........
03 05 00 1a 0a 05 00 17 d2 01 1a d4 01 0c 01 03 | ................
01 02 01 08 0d 0a 01 23 0c 24 09 25 26 27 28 29 | ....
..#.$.%&amp;'()
2a 2b 01 01 01 0c 09 14 01 24 2c 23 13 2d 2a 2b | *+.......$,#.-*+
0d 19 01 2f 08 30 23 18 31 32 33 29 2a 2b 09 1c | 
../.0#.123)*+..
01 34 24 23 1b 35 2a 2b 09 22 23 01 36 1d 37 1e | .4$#.5*+."#.6.7.
38 2b 01 1d 85 03 07 01 02 07 01 03 07 01 04 07 | 8+..............
02 06 07 01 07 07 02 08 07 02 09 07 01 0a 07 01 | ................
0b 07 02 0c 07 01 0d 07 01 0e 07 01 0f 07 02 10 | ......
.........
07 01 11 07 03 13 07 03 15 07 03 16 07 03 17 07 | ................
04 19 07 01 1a 07 04 1b 07 04 1c 07 03 1d 07 05 | ................
1f 07 02 20 07 06 22 07 07 24 07 04 25 07 04 26 | ... .."..$..%..&amp;
07 08 28 07 03 29 07 0a 2a 07 0a 2c 07 0a 2d 07 | ..(..)..*..,..-.
0a 2e 07 0a 2f 07 0a 30 07 0a 31 07 0b 33 07 0a | ..../..0..1..3..
34 07 0c 35 07 0a 36 07 01 37 07 0a 38 07 0a 39 | 4..5..6..7..8..9
07 0a 3a 07 0a 3b 07 01 3c 07 0c 3d 07 01 3e 07 | ..:..;..&lt;..=..&gt;.
0a 3f 07 0a 40 07 0a 41 07 0a 42 07 0a 43 07 0a | .?..@..A..B..C..
44 07 0a 45 07 0a 46 07 0a 47 07 0a 48 07 0e 4a | D..E..F..G..H..J
07 0e 4c 07 01 4d 07 0e 4e 07 0e 4f 07 01 50 07 | ..L..M..N..O..P.
0e 51 07 0e 52 07 0b 53 07 0e 54 07 0e 55 07 01 | .Q..R..S..T..U..
56 07 01 57 07 0e 58 07 0e 59 07 01 5b 07 01 5c | V..W..X..Y..[..\
07 01 5d 07 0c 5e 07 0c 60 07 12 62 07 12 63 07 | ..]..^..`..b..c.
12 64 07 12 65 07 12 66 07 02 67 07 01 68 07 14 | .d..e..f..g..h..
69 07 14 6a 07 14 6b 07 14 6c 07 14 6d 07 14 6e | i..j..k..l..m..n
07 14 6f 07 14 70 07 01 71 07 01 72 07 01 73 07 | ..o..p..q..r..s.
14 74 07 01 75 07 14 76 07 14 77 07 14 78 07 14 | .t..u..v..w..x..
79 07 14 7a 07 14 7b 07 14 7c 07 14 7d 07 08 7e | y..z..{..|..}..~
07 08 7f 07 03 80 01 07 01 82 01 07 08 83 01 07 | ................
16 85 01 07 16 86 01 07 08 87 01 09 88 01 01 09 | ................
89 01 02 07 17 8b 01 07 17 8c 01 07 17 68 07 17 | .............h..
8d 01 07 17 8e 01 07 17 8f 01 07 17 90 01 07 17 | ................
91 01 07 17 92 01 07 17 93 01 07 17 94 01 07 17 | ................
95 01 07 17 96 01 07 17 97 01 07 17 98 01 07 17 | ................
99 01 07 17 9a 01 07 17 9b 01 07 17 9c 01 07 17 | ................
9d 01 07 17 9e 01 07 17 9f 01 07 17 a0 01 07 17 | ................
a1 01 07 17 a2 01 07 17 a3 01 07 17 a4 01 07 17 | ................
a5 01 07 17 a6 01 07 17 a7 01 07 17 a8 01 07 17 | ................
a9 01 07 17 aa 01 07 17 ab 01 07 17 ac 01 07 08 | ................
ad 01 09 7e 03 09 87 01 03 09 83 01 03 07 19 af | ...~............
01 07 19 b0 01 07 08 b1 01 07 01 90 01 07 01 91 | ................
01 07 01 b2 01 07 01 98 01 07 19 b3 01 07 01 99 | ................
01 07 01 b4 01 07 01 b5 01 07 01 b6 01 07 01 96 | ................
01 07 01 92 01 07 01 93 01 07 01 b7 01 07 19 b8 | ................
01 07 01 85 01 07 01 a9 01 07 01 aa 01 07 01 86 | ................
01 07 01 ab 01 07 01 ac 01 07 19 ba 01 07 19 bb | ................
01 07 19 bc 01 07 01 bd 01 07 01 be 01 07 1c bf | ................
01 07 06 c0 01 07 1c c1 01 07 1c c2 01 07 1c c3 | ................
01 07 1c c4 01 07 1c c5 01 07 1c c6 01 07 01 c7 | ................
01 07 01 c8 01 07 1c c9 01 07 1c ca 01 07 1c cb | ................
01 07 1c cc 01 07 1c cd 01 07 01 ce 01 07 01 cf | ................
01 07 01 d0 01 07 01 d1 01 07 01 7d 07 1d d3 01 | ...........}....
07 1f d6 01 07 1f d7 01 07 1f d8 01 07 1f d9 01 | ................
07 1f da 01 07 1f db 01 07 1f dc 01 07 1f dd 01 | ................
07 1f de 01 07 1f df 01 07 1f e0 01 07 1f e1 01 | ................
07 1f e2 01 07 1f e3 01 07 1f e4 01 07 1f e5 01 | ................
07 1f e6 01 07 1f e7 01 07 1f e8 01 07 1f e9 01 | ................
07 1f ea 01 07 1f eb 01 07 20 ed 01 07 20 ee 01 | ......... ... ..
07 20 ef 01 07 20 f0 01 07 20 f1 01 07 01 f2 01 | . ... ... ......
07 0a f3 01 07 0a f4 01 07 21 f6 01 07 19 f8 01 | .........!......
07 19 f9 01 07 01 fa 01 07 22 fc 01 07 01 fd 01 | ........."......
07 01 fe 01 07 01 ff 01 07 08 80 02 07 01 81 02 | ................
07 23 84 02 07 01 85 02 07 01 86 02 1b 04 09 8c | .#..............
02 04 09 8d 02 04 07 01 8f 02 07 01 90 02 07 01 | ................
91 02 07 01 8c 01 07 03 94 02 07 01 95 02 07 01 | ................
96 02 07 03 97 02 07 01 98 02 07 01 99 02 07 01 | ................
a5 01 07 01 9a 02 07 01 9b 02 07 01 9c 02 07 01 | ................
9e 02 07 01 9f 02 07 01 a0 02 07 01 a1 02 07 01 | ................
a2 02 07 01 a3 02 07 01 ad 02 07 01 af 02 07 06 | ................
b1 02 07 07 b2 02 07 06 b3 02 07 01 b4 02 07 01 | ................
b5 02 07 01 b6 02 07 01 b7 02 07 01 b9 02 07 06 | ................
bc 02 07 01 bd 02 07 24 be 02 07 24 bf 02 07 24 | .......$...$...$
c0 02 09 71 04 07 23 c2 02 07 23 c3 02 07 01 c4 | ...q..#...#.....
02 07 01 c5 02 09 9d 02 04 09 c8 02 04 07 23 cf | ..............#.
02 09 9b 02 04 09 75 04 07 01 d0 02 07 01 d1 02 | ......u.........
07 24 d1 02 07 24 d2 02 07 24 d3 02 07 24 d5 02 | .$...$...$...$..
07 24 d7 02 07 06 d8 02 07 06 db 02 07 01 dc 02 | .$..............
07 01 dd 02 07 06 de 02 07 24 df 02 07 24 69 07 | .........$...$i.
24 e0 02 07 24 6b 07 24 e1 02 07 01 e6 02 07 23 | $...$k.$.......#
e8 02 07 23 e9 02 07 01 ec 02 07 01 ef 02 07 01 | ...#............
f0 02 07 01 f1 02 07 01 f2 02 07 01 f3 02 07 06 | ................
f5 02 07 01 f6 02 07 01 f7 02 07 07 f8 02 09 0e | ................
05 07 03 f9 02 09 35 06 09 3d 06 09 5e 06 09 60 | ......5..=..^..`
06 07 02 fb 02 07 24 fc 02 07 24 fd 02 09 be 01 | ......$...$.....
07 09 cf 01 07 07 01 fe 02 07 01 ff 02 09 9b 02 | ................
07 07 01 80 03 07 01 83 03 07 01 8c 03 09 d0 01 | ................
07 09 d1 01 07 09 7d 07 07 07 8e 03 07 23 8f 03 | ......}......#..
09 0b 05 09 7f 03 07 2e 95 03 07 01 96 03 07 01 | ................
98 03 07 01 99 03 1b 08 07 01 9d 03 07 01 9f 01 | ................
07 01 9f 03 07 01 a0 03 07 01 a1 03 07 01 a2 03 | ................
07 01 8d 01 07 01 a5 03 09 ad 01 03 09 bd 01 05 | ................
07 01 a6 03 07 01 a7 03 07 01 a8 03 09 a9 03 09 | ................
07 01 ac 03 07 01 9d 02 07 01 af 03 07 01 b3 03 | ................
07 01 b4 03 07 01 b5 03 07 01 b6 03 07 01 b7 03 | ................
09 0a 05 07 07 b8 03 07 23 ba 03 1b 0a 07 23 be | ........#.....#.
03 07 01 c0 03 09 d3 01 0b 09 b1 01 03 09 28 03 | ..............(.
fe 01 00 00 00 00 01 01 02 00 00 01 03 02 00 00 | ................
00 00 00 00 01 03 04 00 00 02 01 02 01 00 00 02 | ................
01 02 05 00 00 02 01 02 05 00 00 01 03 06 00 00 | ................
01 03 07 00 00 00 03 00 02 01 03 04 00 00 01 03 | ................
04 00 02 01 03 04 00 00 00 03 00 02 00 03 00 00 | ................
00 03 00 00 01 03 04 00 02 01 03 04 00 00 01 03 | ................
07 00 00 01 03 06 00 00 01 03 08 00 02 00 03 00 | ................
00 00 03 00 00 00 03 00 00 00 03 00 00 02 09 02 | ................
02 00 02 00 00 00 00 00 00 00 00 00 03 00 00 00 | ................
03 00 00 00 03 00 00 01 03 0a 00 00 00 00 00 00 | ................
00 00 00 00 01 0b 05 00 00 00 05 00 00 00 0b 00 | ................
00 00 00 00 00 00 00 00 00 01 0b 05 00 00 00 05 | ................
00 00 00 0b 00 00 00 00 00 00 02 00 05 05 00 00 | ................
00 03 00 00 01 0b 05 00 00 00 05 00 00 00 0b 00 | ................
00 00 00 00 00 00 00 00 00 01 03 02 00 00 01 03 | ................
02 00 00 01 03 02 00 00 05 00 0c 00 0d 00 0d 00 | ............
.
.
00 01 03 04 00 00 02 0d 02 00 00 02 00 03 00 00 | .......
........
01 03 04 00 00 01 03 04 00 00 01 03 04 00 00 01 | ................
03 04 00 00 01 03 0e 00 00 01 03 0e 00 00 04 03 | ................
00 00 0f 02 00 00 00 03 00 00 00 00 00 00 00 00 | ................
00 00 00 00 00 00 00 00 00 00 00 00 00 00 03 00 | ................
10 02 0b 00 08 03 0c 0c 14 01 0a 0a 00 02 00 00 | ................
00 00 00 00 00 00 00 00 00 02 00 00 01 03 02 00 | ................
00 00 03 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................
00 00 11 00 00 00 12 00 00 00 02 00 00 01 03 02 | ................
00 00 00 13 00 00 00 11 00 00 01 03 11 00 00 00 | ................
0b 00 00 01 03 0b 00 00 00 05 00 00 01 03 05 00 | ................
00 00 05 00 00 01 03 05 00 00 00 05 00 00 01 03 | ................
05 00 00 00 05 00 00 01 03 05 00 00 00 05 00 00 | ................
00 05 00 00 00 05 00 00 01 03 05 00 00 00 05 00 | ................
00 01 03 05 00 00 00 05 00 00 01 03 05 00 00 00 | ................
05 00 00 01 03 05 00 00 00 0b 00 00 01 03 0b 00 | ................
00 00 01 00 00 01 03 01 00 00 00 14 00 00 01 03 | ................
14 00 00 00 15 00 00 01 03 15 00 00 00 02 00 00 | ................
01 03 02 00 00 00 16 00 00 01 03 16 00 00 00 14 | ................
00 00 01 03 14 00 00 01 17 17 00 00 01 17 17 00 | ................
00 01 14 11 00 00 01 14 11 00 00 00 18 00 00 01 | ................
0b 11 00 00 03 0b 05 05 0b 00 08 01 0a 0a 00 19 | ................
00 00 01 03 19 00 00 00 05 00 00 00 05 00 00 02 | ................
03 05 05 00 00 02 03 05 05 00 00 00 00 00 00 00 | ................
00 00 00 00 00 00 00 03 00 10 02 0b 00 08 03 0c | ................
0c 14 01 0a 0a 00 05 00 00 01 03 05 00 00 00 05 | ................
00 00 01 03 05 00 00 00 05 00 00 01 03 05 00 00 | ................
00 05 00 00 01 03 05 00 00 00 05 00 00 01 03 05 | ................
00 00 00 05 00 00 01 03 05 00 00 00 05 00 00 01 | ................
03 05 00 00 00 05 00 00 01 03 05 00 00 00 05 00 | ................
00 01 03 05 00 00 00 05 00 00 01 03 05 00 00 00 | ................
05 00 00 01 03 05 00 00 00 05 00 00 01 03 05 00 | ................
00 00 02 00 00 01 03 02 00 00 00 05 00 00 00 05 | ................
00 00 00 03 00 00 02 03 05 05 00 00 02 03 05 05 | ................
00 00 01 03 04 00 00 00 03 00 00 00 03 00 00 00 | ................
00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 | ................
00 00 00 02 00 02 02 00 08 01 01 01 00 02 00 00 | ................
00 02 00 00 01 03 1a 00 00 01 03 1a 00 00 01 0b | ................
1b 00 00 01 03 1a 00 00 01 03 1c 00 00 00 03 00 | ................
00 01 03 02 00 00 00 03 00 00 03 03 1c 0f 0f 00 | ................
08 02 01 03 01 03 03 03 1c 0f 0f 00 08 02 01 03 | ................
01 03 00 03 00 00 00 00 00 00 00 00 00 00 00 00 | ................
00 00 01 02 01 00 00 01 02 11 00 00 01 02 01 00 | ................
00 00 00 00 00 00 00 00 00 00 00 00 00 01 03 05 | ................
00 00 00 05 00 00 01 03 05 00 00 00 05 00 00 01 | ................
03 05 00 00 00 05 00 00 00 05 00 00 01 03 05 00 | ................
00 01 03 05 00 00 00 05 00 00 01 03 05 00 00 00 | ................
05 00 00 01 03 05 00 00 00 05 00 00 01 03 05 00 | ................
00 00 05 00 00 01 03 05 00 00 00 05 00 00 01 03 | ................
05 00 00 00 05 00 00 01 03 05 00 00 00 05 00 00 | ................
01 03 05 00 00 00 05 00 00 01 03 05 00 00 00 05 | ................
00 00 01 03 1d 00 00 00 1d 00 00 01 03 1e 00 00 | ................
00 1e 00 00 00 0b 00 00 00 0b 00 00 00 0b 00 00 | ................
01 03 0b 00 00 00 05 00 00 01 03 05 00 00 00 05 | ................
00 00 01 03 05 00 00 00 1d 00 00 00 1e 00 00 00 | ................
00 00 00 00 00 00 00 00 00 00 00 00 15 00 00 01 | ................
03 15 00 00 00 0b 00 00 00 15 00 00 01 03 15 00 | ................
00 00 15 00 00 01 03 15 00 00 01 03 1f 00 00 00 | ................
00 00 00 00 00 00 00 00 10 0c 20 09 09 00 03 1a | .......... .....
21 06 00 02 2b 01 22 06 00 01 00 23 06 00 01 00 | !...+."....#....
24 06 00 0f 02 03 25 06 00 05 01 06 26 06 00 05 | $.....%.....&amp;...
02 06 27 00 00 28 00 29 00 00 2a 00 2b 00 00 15 | ..'..(.)..*.+...
00 2c 00 00 0b 00 2d 00 00 01 00 2e 00 00 0f 00 | .,....-.........
2f 00 00 05 00 30 00 00 01 00 31 00 00 32 00 33 | /....0....1..2.3
01 00 02 34 01 00 04 35 01 00 05 36 01 00 06 37 | ...4...5...6...7
01 00 07 38 01 00 0a 39 01 00 0c 3a 01 00 0e 3b | ...8...9...:...;
01 00 11 3c 01 00 15 3d 01 00 1a 2a 20 09 0d 00 | ...&lt;...=...* .
.
1c 0c 3e 06 00 02 4b 01 3f 00 00 40 01 03 41 00 | ..&gt;...K.?..@..A.
00 40 01 03 42 00 00 43 00 44 00 00 28 00 45 00 | .@..B..C.D..(.E.
00 46 00 47 00 00 28 00 48 00 00 46 00 49 01 00 | .F.G..(.H..F.I..
1d 4a 01 00 1e 4b 01 00 1f 4c 01 00 20 32 01 09 | .J...K...L.. 2..
0f 00 22 03 4d 01 00 23 4e 01 00 24 4f 01 00 25 | ..".M..#N..$O..%
50 32 09 10 00 27 03 4d 21 00 28 4e 21 00 29 4f | P2...'.M!.(N!.)O
21 00 2a 51 32 09 11 00 2c 08 52 00 00 05 00 53 | !.*Q2...,.R....S
00 00 05 00 54 00 00 05 00 55 00 00 0f 00 56 01 | ....T....U....V.
00 2d 4d 21 00 2e 4e 21 00 2f 4f 21 00 30 09 57 | .-M!..N!./O!.0.W
09 13 00 36 16 58 00 00 02 00 59 00 00 00 00 5a | ...6.X....Y....Z
00 00 0d 00 5b 00 00 00 00 5c 00 00 0d 00 5d 00 | ..
.[....\..
.].
00 0c 00 5e 00 00 15 00 5f 00 00 15 00 60 00 00 | ...^...._....`..
0f 00 61 01 00 33 62 01 00 34 63 01 00 35 64 01 | ..a..3b..4c..5d.
00 38 65 01 00 39 66 01 00 3a 67 01 00 3b 68 01 | .8e..9f..:g..;h.
00 3c 69 01 00 3d 6a 01 00 3e 6b 01 00 3f 6c 01 | .&lt;i..=j..&gt;k..?l.
00 40 6d 01 00 41 6e 00 05 00 44 00 6f 70 09 15 | .@m..An...D.op..
00 47 01 71 21 00 48 72 00 05 00 4e 03 73 02 00 | .G.q!.Hr...N.s..
4b 73 03 00 4c 74 01 00 4d 75 00 05 02 76 77 87 | Ks..Lt..Mu...vw.
01 36 78 02 00 51 79 02 00 52 7a 02 00 53 7a 03 | .6x..Qy..Rz..Sz.
00 54 7b 02 00 55 7c 02 00 56 7c 03 00 57 7d 02 | .T{..U|..V|..W}.
00 58 7d 03 00 59 7e 02 00 5a 7e 03 00 5b 7f 02 | .X}..Y~..Z~..[..
00 5c 7f 03 00 5d 80 01 02 00 5e 80 01 03 00 5f | .\...]....^...._
81 01 02 00 60 81 01 03 00 61 82 01 02 00 62 83 | ....`....a....b.
01 02 00 63 84 01 02 00 64 84 01 03 00 65 85 01 | ...c....d....e..
02 00 66 85 01 03 00 67 86 01 02 00 68 86 01 03 | ..f....g....h...
00 69 87 01 02 00 6a 87 01 03 00 6b 88 01 02 00 | .i....j....k....
6c 88 01 03 00 6d 89 01 02 00 6e 89 01 03 00 6f | l....m....n....o
8a 01 02 00 70 8a 01 03 00 71 8b 01 02 00 72 8b | ....p....q....r.
01 03 00 73 8c 01 02 00 74 8c 01 03 00 75 8d 01 | ...s....t....u..
02 00 76 8d 01 03 00 77 8e 01 02 00 78 8e 01 03 | ..v....w....x...
00 79 8f 01 01 00 7a 90 01 01 00 7b 91 01 01 00 | .y....z....{....
7c 92 01 01 00 7d 93 01 02 00 7e 94 01 01 00 7f | |....}....~.....
95 01 01 00 80 01 96 01 02 00 81 01 96 01 03 00 | ................
82 01 97 01 02 00 83 01 98 01 02 00 84 01 99 01 | ................
01 00 85 01 9a 01 01 00 86 01 9b 01 6f 09 18 03 | ............o...
9c 01 9d 01 9e 01 8a 01 26 9f 01 00 00 43 00 a0 | ........&amp;....C..
01 00 00 a1 01 00 a2 01 22 00 8b 01 a2 01 23 00 | ........".....#.
8c 01 a3 01 22 00 8d 01 a3 01 23 00 8e 01 a4 01 | ....".....#.....
22 00 8f 01 a4 01 23 00 90 01 a5 01 22 00 91 01 | ".....#....."...
a5 01 23 00 92 01 a6 01 00 00 05 00 a7 01 22 00 | ..#...........".
93 01 a7 01 23 00 94 01 a8 01 22 00 95 01 a8 01 | ....#.....".....
23 00 96 01 a9 01 22 00 97 01 a9 01 23 00 98 01 | #.....".....#...
aa 01 22 00 99 01 aa 01 23 00 9a 01 ab 01 22 00 | ..".....#.....".
9b 01 ab 01 23 00 9c 01 ac 01 22 00 9d 01 ac 01 | ....#.....".....
23 00 9e 01 ad 01 22 00 9f 01 ad 01 23 00 a0 01 | #.....".....#...
ae 01 22 00 a1 01 ae 01 23 00 a2 01 af 01 00 00 | ..".....#.......
02 b9 01 01 b0 01 02 00 a3 01 b0 01 03 00 a4 01 | ................
b1 01 02 00 a5 01 b2 01 02 00 a6 01 b3 01 01 00 | ................
a7 01 b4 01 01 00 a8 01 b5 01 01 00 a9 01 b6 01 | ................
01 00 aa 01 b7 01 01 00 ab 01 b8 01 01 00 ac 01 | ................
b9 01 9b 01 09 1a 00 af 01 00 08 57 09 1b 00 b2 | ...........W....
01 15 ba 01 00 00 0b 00 bb 01 00 00 bc 01 00 bd | ................
01 00 00 1b 00 be 01 00 00 1b 00 bf 01 00 00 02 | ................
00 c0 01 00 00 1c 00 c1 01 00 00 02 00 c2 01 00 | ................
00 02 00 c3 01 02 00 b3 01 c4 01 02 00 b4 01 c5 | ................
01 01 00 b5 01 c6 01 01 00 b6 01 c7 01 01 00 b7 | ................
01 c8 01 01 00 b8 01 c9 01 01 00 b9 01 ca 01 01 | ................
00 ba 01 65 01 00 bb 01 cb 01 01 00 bc 01 cc 01 | ...e............
01 00 bd 01 cd 01 01 00 be 01 ce 01 01 00 bf 01 | ................
cf 01 01 09 1e 00 c6 01 00 a1 01 00 05 00 f1 01 | ................
28 d0 01 03 00 c9 01 d0 01 02 00 ca 01 d1 01 03 | (...............
00 cb 01 d1 01 02 00 cc 01 d2 01 03 00 cd 01 d2 | ................
01 02 00 ce 01 d3 01 02 00 cf 01 d3 01 03 00 d0 | ................
01 d4 01 03 00 d1 01 d4 01 02 00 d2 01 d5 01 03 | ................
00 d3 01 d5 01 02 00 d4 01 d6 01 03 00 d5 01 d6 | ................
01 02 00 d6 01 d7 01 03 00 d7 01 d7 01 02 00 d8 | ................
01 d8 01 03 00 d9 01 d8 01 02 00 da 01 d9 01 03 | ................
00 db 01 d9 01 02 00 dc 01 da 01 03 00 dd 01 da | ................
01 02 00 de 01 db 01 03 00 df 01 db 01 02 00 e0 | ................
01 dc 01 03 00 e1 01 dc 01 02 00 e2 01 dd 01 03 | ................
00 e3 01 dd 01 02 00 e4 01 de 01 03 00 e5 01 de | ................
01 02 00 e6 01 df 01 02 00 e7 01 e0 01 02 00 e8 | ................
01 e1 01 02 00 e9 01 e1 01 03 00 ea 01 e2 01 02 | ................
00 eb 01 e2 01 03 00 ec 01 e3 01 02 00 ed 01 e3 | ................
01 03 00 ee 01 e4 01 02 00 ef 01 e5 01 02 00 f0 | ................
01 1f 00 05 00 fc 01 08 e6 01 02 00 f4 01 e6 01 | ................
03 00 f5 01 e7 01 02 00 f6 01 e8 01 02 00 f7 01 | ................
e8 01 03 00 f8 01 e9 01 02 00 f9 01 e9 01 03 00 | ................
fa 01 ea 01 01 00 fb 01 00 03 eb 01 06 01 05 00 | ................
ec 01 06 02 05 03 06 ed 01 11 03 01 1b 00 21 00 | ..............!.
26 00 2b 00 32 00 43 00 46 01 ee 01 06 01 02 f7 | &amp;.+.2.C.F.......
01 01 4a 00 50 00 89 01 03 ee 01 06 01 02 f7 01 | ..J.P...........
01 ef 01 00 02 43 00 f0 01 00 03 43 00 ae 01 00 | .....C.....C....
b1 01 01 f1 01 06 01 02 fb 01 01 c2 01 05 ee 01 | ................
06 01 02 f7 01 01 f2 01 00 02 40 01 03 f3 01 11 | ..........@.....
03 c3 01 f4 01 11 04 c4 01 f5 01 11 05 c5 01 c8 | ................
01 00 f3 01 00 0d 31 05 0c 04 00 00 2a 04 00 01 | .....
1.....*...
32 04 00 02 50 04 00 03 51 04 00 04 42 01 09 04 | 2...P...Q...B...
00 05 45 01 6e 04 00 06 49 01 6f 04 00 07 4f 01 | ..E.n...I.o...O.
72 04 00 08 88 01 01 75 04 00 09 ad 01 01 9b 01 | r......u........
04 00 0a b0 01 01 b9 01 04 00 0b c0 01 01 08 04 | ................
00 0c c1 01 01 f6 01 06 00 00 21 08 c7 01 01 cf | ..........!.....
01 04 00 0d f2 01 01 a1 01 04 00 0e fd 01 01 1f | ...
............
04 00 0f 90 01 00 02 01 08 09 14 d0 30 5e eb 01 | ............0^..
60 f7 01 68 eb 01 5e ec 01 24 05 68 ec 01 47 00 | `..h..^..$.h..G.
00 01 04 04 08 09 5b d0 30 20 80 15 d6 20 80 01 | ......[.0 ... ..
d7 d1 2c 82 02 24 02 46 f8 01 02 80 15 d6 d2 66 | ..,..$.F.......f
f9 01 24 02 ab 96 2a 11 0f 00 00 29 5d fa 01 d2 | ..$...*....)]...
24 01 66 fb 01 46 fa 01 01 96 12 02 00 00 20 48 | $.f..F........ H
55 00 80 01 d7 d3 d2 24 00 66 fb 01 61 fc 01 d3 | U......$.f..a...
5d fa 01 d2 24 01 66 fb 01 46 fa 01 01 61 fd 01 | ]...$.f..F...a..
d3 48 00 00 02 03 02 09 0a 22 d0 30 d0 66 27 12 | .H.......".0.f'.
18 00 00 d0 66 27 d1 2c 8e 02 a0 4f fe 01 01 d0 | ....f'.,...O....
66 27 d0 66 27 66 ff 01 61 80 02 47 00 00 03 05 | f'.f'f..a..G....
01 09 0a 83 01 d0 30 d0 2c 8c 02 2c 92 02 2c 8d | ......0.,..,..,.
02 25 aa 46 55 02 68 22 d0 2c 8c 02 2c 93 02 2c | .%.FU.h".,..,..,
8d 02 25 aa 46 55 02 68 23 d0 49 00 60 81 02 60 | ..%.FU.h#.I.`..`
82 02 66 83 02 61 84 02 60 81 02 60 85 02 66 86 | ..f..a..`..`..f.
02 61 87 02 d0 5d 2a 4a 2a 00 68 29 d0 56 00 68 | .a...]*J*.h).V.h
2b 60 eb 01 12 17 00 00 d0 5d 51 60 eb 01 60 ec | +`.......]Q`..`.
01 a2 75 60 ec 01 4a 51 02 68 31 10 08 00 00 d0 | ..u`..JQ.h1.....
5d 50 4a 50 00 68 31 d0 66 88 02 60 04 66 89 02 | ]PJP.h1.f..`.f..
d0 66 34 4f 8a 02 02 47 00 00 04 04 03 09 0a c4 | .f4O...G........
02 d0 30 20 80 01 d6 d0 d0 66 88 02 66 8b 02 2c | ..0 .....f..f..,
37 66 fb 01 68 2c d0 66 2c 76 2a 11 0f 00 00 29 | 7f..h,.f,v*....)
d0 66 88 02 66 8b 02 2c 9d 02 66 fb 01 76 12 46 | .f..f..,..f..v.F
00 00 d0 5d 28 4a 28 00 68 27 d0 66 27 60 81 02 | ...](J(.h'.f'`..
66 8c 02 61 a5 01 d0 66 27 60 81 02 66 8d 02 61 | f..a...f'`..f..a
a7 01 d0 66 27 26 61 8e 02 d0 66 27 25 8f 3e 61 | ...f'&amp;a...f'%.&gt;a
8f 02 d0 66 27 2d 03 61 90 02 5d 91 02 d0 66 27 | ...f'-.a..]...f'
4f 91 02 01 10 0a 00 00 5d 91 02 d0 66 29 4f 91 | O.......]...f)O.
02 01 d0 2c a4 02 4f 33 01 d0 d0 2c a5 02 d0 66 | ...,..O3...,...f
22 46 35 02 68 2d d0 66 2d 11 08 00 00 d0 2c a6 | "F5.h-.f-.....,.
02 4f 33 01 47 d0 2c a7 02 d0 66 24 46 36 02 80 | .O3.G.,...f$F6..
01 d6 d2 20 ab 2a 11 05 00 00 29 d2 24 00 ad 12 | ... .*....).$...
08 00 00 d0 2c a8 02 4f 33 01 47 d0 5d 0f d2 46 | ....,..O3.G.]..F
0f 01 68 2e d0 2c 3a d0 66 25 46 37 02 80 01 d6 | ..h..,:.f%F7....
d2 20 ab 2a 11 06 00 00 29 d2 d0 66 26 ad 12 10 | . .*....)..f&amp;...
00 00 d0 2c a9 02 d0 66 26 a0 2c aa 02 a0 4f 33 | ...,...f&amp;.,...O3
01 47 d0 5d 05 d2 46 05 01 68 2f d0 d0 2c ab 02 | .G.]..F..h/..,..
d0 66 23 46 35 02 68 30 d0 66 30 11 08 00 00 d0 | .f#F5.h0.f0.....
2c ac 02 4f 33 01 47 d0 66 88 02 66 8b 02 2c 9d | ,..O3.G.f..f..,.
02 66 fb 01 12 08 00 00 d0 4f 3a 00 10 04 00 00 | .f.......O:.....
d0 4f 38 00 47 00 00 05 02 04 09 0a 22 d0 30 20 | .O8.G.......".0 
85 d7 d0 66 88 02 66 8b 02 d1 66 fb 01 85 d7 d3 | ...f..f...f.....
12 09 00 00 5d ed 01 d3 46 ed 01 01 48 d2 48 00 | ....]...F...H.H.
00 06 02 05 09 0a 3b d0 30 20 85 d7 28 63 04 d0 | ......;.0 ..(c..
66 88 02 66 8b 02 d1 66 fb 01 85 d7 d3 12 1f 00 | f..f...f........
00 5d 05 d3 46 05 01 75 63 04 5d 92 02 62 04 46 | .]..F..uc.]..b.F
92 02 01 12 02 00 00 20 48 62 04 48 10 02 00 00 | ....... Hb.H....
d2 48 00 00 07 03 03 09 0a 09 d0 30 d0 d1 d2 46 | .H.........0...F
36 02 48 00 00 08 03 02 0a 0a 12 5d 33 2c ae 02 | 6.H........]3,..
d1 66 93 02 a0 2c aa 02 a0 4f 33 01 47 00 00 09 | .f...,...O3.G...
03 02 0a 0a 12 5d 33 2c b0 02 d1 66 93 02 a0 2c | .....]3,...f...,
aa 02 a0 4f 33 01 47 00 00 0a 05 02 0a 0c d0 01 | ...O3.G.........
d0 30 57 2a d5 30 65 01 20 85 6d 01 65 01 20 80 | .0W*.0e. .m.e. .
94 02 6d 02 d0 66 2b 66 f9 01 d0 66 2e 0f 17 00 | ..m..f+f...f....
00 5d 95 02 d0 66 38 5d 0f d0 66 2f 25 e8 07 a2 | .]...f8]..f/%...
46 0f 01 4f 95 02 02 47 65 01 5d 94 02 4a 94 02 | F..O...Ge.]..J..
00 80 94 02 6d 02 65 01 6c 02 60 96 02 66 97 02 | ....m.e.l.`..f..
61 98 02 65 01 6c 02 60 04 66 89 02 d0 66 39 4f | a..e.l.`.f...f9O
8a 02 02 65 01 6c 02 60 06 66 99 02 40 08 4f 8a | ...e.l.`.f..@.O.
02 02 65 01 6c 02 60 07 66 9a 02 40 09 4f 8a 02 | ..e.l.`.f..@.O..
02 65 01 2c b8 02 5d 9b 02 d0 66 2d 66 fc 01 46 | .e.,..]...f-f..F
9b 02 01 a0 2c 82 02 a0 5d 9b 02 d0 66 2d 66 fd | ....,...]...f-f.
01 46 9b 02 01 a0 2c ba 02 a0 6d 01 d0 2c bb 02 | .F....,...m..,..
65 01 6c 01 a0 2c aa 02 a0 4f 33 01 65 01 6c 02 | e.l..,...O3.e.l.
5d 9c 02 65 01 6c 01 4a 9c 02 01 4f 9d 02 01 47 | ]..e.l.J...O...G
00 02 9e 02 00 01 02 00 9f 02 00 02 94 02 00 0b | ................
03 02 0a 0a 21 60 a0 02 2c c1 02 4f a1 02 01 60 | ....!`..,..O...`
2b 60 2b 60 a0 02 46 a2 02 01 24 01 4f a3 02 02 | +`+`..F...$.O...
60 29 4f 4a 00 47 00 00 0c 05 04 0a 0f 98 02 d0 | `)OJ.G..........
30 57 2a d6 30 65 01 20 80 94 02 6d 02 65 01 20 | 0W*.0e. ...m.e. 
85 6d 03 65 01 20 85 6d 04 65 01 20 80 01 6d 05 | .m.e. .m.e. ..m.
65 01 d1 6d 01 5d 95 02 d0 66 38 5d 0f d0 66 2f | e..m.]...f8]..f/
25 e8 07 a2 46 0f 01 4f 95 02 02 65 01 65 01 6c | %...F..O...e.e.l
01 66 a4 02 60 94 02 87 80 94 02 6d 02 65 01 65 | .f..`......m.e.e
01 6c 02 66 a5 02 66 a6 02 85 6d 03 65 01 6c 03 | .l.f..f...m.e.l.
2c 01 14 08 00 00 d0 2c c6 02 4f 33 01 47 65 01 | ,......,..O3.Ge.
6c 03 11 08 00 00 d0 2c c7 02 4f 33 01 47 65 01 | l......,..O3.Ge.
65 01 6c 02 66 a5 02 66 a7 02 85 6d 04 65 01 6c | e.l.f..f...m.e.l
04 11 08 00 00 d0 2c c9 02 4f 33 01 47 d0 2c ca | ......,..O3.G.,.
02 65 01 6c 03 a0 2c cb 02 a0 2c cc 02 a0 65 01 | .e.l..,...,...e.
6c 04 a0 2c cd 02 a0 4f 33 01 65 01 d0 65 01 6c | l..,...O3.e..e.l
03 65 01 6c 04 46 3d 02 80 01 6d 05 10 1e 00 00 | .e.l.F=...m.....
d0 30 d2 30 5a 00 2a d7 2a 30 2b 6d 01 5d 33 2c | .0.0Z.*.*0+m.]3,
ce 02 65 02 6c 01 a0 4f 33 01 47 1d 08 03 d0 66 | ..e.l..O3.G....f
2b 65 01 6c 05 4f a8 02 01 65 01 6c 05 60 04 66 | +e.l.O...e.l.`.f
89 02 40 0b 4f a9 02 02 65 01 6c 05 4f aa 02 00 | ..@.O...e.l.O...
d0 66 29 4f 49 00 47 01 bb 01 cd 01 d1 01 ab 02 | .f)OI.G.........
ac 02 05 ad 02 00 01 04 00 9f 02 00 02 94 02 00 | ................
ae 02 00 03 02 00 af 02 00 04 02 00 a0 02 00 05 | ................
01 00 0d 03 02 0a 0a 18 5d 33 2c d4 02 60 b0 02 | ..
.....]3,..`..
66 c3 01 a0 4f 33 01 5d 3c 60 b0 02 4f 3c 01 47 | f...O3.]&lt;`..O&lt;.G
00 00 0e 03 02 0a 0c 4a d0 30 57 2a d5 30 65 01 | .......J.0W*.0e.
20 80 08 6d 01 d0 2c d6 02 4f 33 01 65 01 5d 08 |  ..m..,..O3.e.].
d0 66 21 4a 08 01 80 08 6d 01 65 01 6c 01 60 04 | .f!J....m.e.l.`.
66 89 02 40 0d 4f 8a 02 02 65 01 6c 01 60 08 66 | f..@
O...e.l.`.f
f1 01 d0 66 3b 4f 8a 02 02 65 01 6c 01 4f ca 01 | ...f;O...e.l.O..
00 47 00 01 b0 02 00 01 08 00 0f 00 01 0a 0a 01 | .G..............
47 00 00 10 03 01 0a 0a 11 60 b1 02 60 30 66 fc | G........`..`0f.
01 60 30 66 fd 01 4f 65 02 47 00 00 11 07 03 0a | .`0f..Oe.G......
0c 6e d0 30 57 2a d6 30 65 01 20 80 08 6d 02 65 | .n.0W*.0e. ..m.e
01 20 80 b2 02 6d 03 65 01 20 80 09 6d 04 65 01 | . ...m.e. ..m.e.
d1 6d 01 65 01 65 01 6c 01 66 a4 02 60 08 87 80 | .m.e.e.l.f..`...
08 6d 02 65 01 5d b2 02 4a b2 02 00 80 b2 02 6d | .m.e.]..J......m
03 d0 2c d9 02 65 01 6c 02 66 c4 01 a0 4f 33 01 | ..,..e.l.f...O3.
65 01 5d 09 d0 65 01 6c 02 40 0f 65 01 6c 03 40 | e.]..e.l.@.e.l.@
10 4a 09 05 80 09 6d 04 65 01 6c 04 4f 65 00 47 | .J....m.e.l.Oe.G
00 04 ad 02 00 01 04 00 b0 02 00 02 08 00 b1 02 | ................
00 03 b2 02 00 a0 02 00 04 09 00 12 02 02 0a 0a | ................
09 5d 33 2c da 02 4f 33 01 47 00 00 13 03 02 0a | .]3,..O3.G......
0a 19 5d 33 2c b0 02 d1 66 93 02 a0 2c aa 02 a0 | ..]3,...f...,...
4f 33 01 60 b0 02 4f cb 01 00 47 00 00 14 03 02 | O3.`..O...G.....
0a 0a 19 5d 33 2c ae 02 d1 66 93 02 a0 2c aa 02 | ...]3,...f...,..
a0 4f 33 01 60 b0 02 4f cb 01 00 47 00 00 15 04 | .O3.`..O...G....
03 0a 0c e5 01 d0 30 57 2a d6 30 65 01 20 85 6d | ......0W*.0e. .m
02 65 01 20 80 94 02 6d 03 65 01 20 80 9c 02 6d | .e. ...m.e. ...m
04 65 01 d1 6d 01 65 01 5d 94 02 4a 94 02 00 80 | .e..m.e.]..J....
94 02 6d 03 65 01 6c 03 60 04 66 89 02 40 12 4f | ..m.e.l.`.f..@.O
8a 02 02 65 01 6c 03 60 07 66 9a 02 40 13 4f 8a | ...e.l.`.f..@.O.
02 02 65 01 6c 03 60 06 66 99 02 40 14 4f 8a 02 | ..e.l.`.f..@.O..
02 65 01 2c b8 02 5d 9b 02 d0 66 2d 66 fc 01 46 | .e.,..]...f-f..F
9b 02 01 a0 2c 82 02 a0 5d 9b 02 d0 66 2d 66 fd | ....,...]...f-f.
01 46 9b 02 01 a0 2c ba 02 a0 6d 02 65 01 5d 9c | .F....,...m.e.].
02 65 01 6c 02 4a 9c 02 01 80 9c 02 6d 04 65 01 | .e.l.J......m.e.
6c 04 60 b3 02 66 b4 02 61 b5 02 65 01 6c 04 5d | l.`..f..a..e.l.]
b6 02 4a b6 02 00 61 a5 02 65 01 6c 04 66 a5 02 | ..J...a..e.l.f..
2c 9d 02 65 01 6c 01 66 c3 01 61 fb 01 d0 2c bb | ,..e.l.f..a...,.
02 65 01 6c 02 a0 2c aa 02 a0 4f 33 01 65 01 6c | .e.l..,...O3.e.l
03 65 01 6c 04 4f 9d 02 01 47 00 04 b0 02 00 01 | .e.l.O...G......
08 00 9e 02 00 02 02 00 9f 02 00 03 94 02 00 b7 | ................
02 00 04 9c 02 00 16 03 01 0a 0a 14 60 b8 02 60 | ............`..`
b9 02 66 fc 01 60 b9 02 66 fd 01 4f aa 02 02 47 | ..f..`..f..O...G
00 00 17 03 01 0a 0a 13 60 ba 02 60 bb 02 66 fc | ........`..`..f.
01 60 bb 02 66 fd 01 4f 65 02 47 00 00 18 02 01 | .`..f..Oe.G.....
0a 0a 0b 60 b8 02 60 ae 02 4f aa 02 01 47 00 00 | ...`..`..O...G..
19 03 01 0a 0a 13 60 ba 02 60 bb 02 66 fc 01 60 | ......`..`..f..`
bb 02 66 fd 01 4f 65 02 47 00 00 1a 07 04 0a 0c | ..f..Oe.G.......
f2 02 d0 30 57 2a d7 30 65 01 20 80 09 6d 03 65 | ...0W*.0e. ..m.e
01 20 80 01 6d 04 65 01 20 80 01 6d 05 65 01 21 | . ..m.e. ..m.e.!
82 6d 06 65 01 20 80 b2 02 6d 07 65 01 d1 6d 01 | .m.e. ...m.e..m.
65 01 d2 6d 02 65 01 60 0c 65 01 6c 02 46 ed 01 | e..m.e.`.e.l.F..
01 80 01 6d 05 65 01 6c 05 11 0b 00 00 5d ab 02 | ...m.e.l.....]..
2c e2 02 4a ab 02 01 03 65 01 60 0c 65 01 6c 01 | ,..J....e.`.e.l.
46 ed 01 01 80 01 6d 04 65 01 6c 04 12 71 00 00 | F.....m.e.l..q..
65 01 5d b2 02 4a b2 02 00 82 6d 06 65 01 5d b2 | e.]..J....m.e.].
02 4a b2 02 00 80 b2 02 6d 07 65 01 5d 09 d0 65 | .J......m.e.]..e
01 6c 06 40 16 65 01 6c 07 40 17 4a 09 05 80 09 | .l.@.e.l.@.J....
6d 03 65 01 6c 03 2c e3 02 65 01 6c 04 66 fc 01 | m.e.l.,..e.l.f..
a0 2c 82 02 a0 65 01 6c 04 66 fd 01 a0 2c e4 02 | .,...e.l.f...,..
a0 65 01 6c 05 66 fc 01 a0 2c 82 02 a0 65 01 6c | .e.l.f...,...e.l
05 66 fd 01 a0 2c e5 02 a0 4f 63 01 65 01 6c 03 | .f...,...Oc.e.l.
48 65 01 6c 01 60 bc 02 2c e7 02 42 01 46 bd 02 | He.l.`..,..B.F..
01 12 6b 00 00 65 01 5d 08 d0 66 21 4a 08 01 82 | ..k..e.]..f!J...
6d 06 65 01 5d b2 02 4a b2 02 00 80 b2 02 6d 07 | m.e.]..J......m.
65 01 5d 09 d0 65 01 6c 06 40 18 65 01 6c 07 40 | e.]..e.l.@.e.l.@
19 4a 09 05 80 09 6d 03 65 01 6c 03 2c e3 02 65 | .J....m.e.l.,..e
01 6c 01 24 00 24 04 46 be 02 02 a0 2c ea 02 a0 | .l.$.$.F....,...
65 01 6c 05 66 fc 01 a0 2c 82 02 a0 65 01 6c 05 | e.l.f...,...e.l.
66 fd 01 a0 2c e5 02 a0 4f 63 01 65 01 6c 03 48 | f...,...Oc.e.l.H
5d ab 02 2c eb 02 65 01 6c 01 a0 2c cd 02 a0 4a | ]..,..e.l..,...J
ab 02 01 03 00 07 ae 02 00 01 02 00 af 02 00 02 | ................
02 00 a0 02 00 03 09 00 b9 02 00 04 01 00 bb 02 | ................
00 05 01 00 b8 02 00 06 00 00 ba 02 00 07 b2 02 | ................
00 1b 01 01 08 09 03 d0 30 47 00 00 1c 03 01 09 | ........0G......
0a 90 02 d0 30 d0 60 b9 01 68 42 d0 49 00 d0 5d | ....0.`..hB.I..]
46 4a 46 00 68 45 d0 66 45 2d 04 61 bf 02 d0 66 | FJF.hE.fE-.a...f
45 2c ed 02 61 87 02 d0 66 45 2c ee 02 61 c0 02 | E,..a...fE,..a..
d0 66 45 26 61 c1 02 d0 66 45 24 0a 61 c2 02 d0 | .fE&amp;a...fE$.a...
5d 28 4a 28 00 68 44 d0 66 44 24 14 61 a5 01 d0 | ](J(.hD.fD$.a...
66 44 24 11 61 a7 01 d0 66 44 27 61 8e 02 d0 66 | fD$.a...fD'a...f
44 d0 66 45 61 c3 02 d0 66 44 24 2f 61 a2 01 d0 | D.fEa...fD$/a...
66 44 24 00 61 a3 01 d0 5d 46 4a 46 00 68 48 d0 | fD$.a...]FJF.hH.
66 48 2d 04 61 bf 02 d0 66 48 2c ed 02 61 87 02 | fH-.a...fH,..a..
d0 66 48 2c ee 02 61 c0 02 d0 66 48 26 61 c1 02 | .fH,..a...fH&amp;a..
d0 66 48 24 0a 61 c2 02 d0 5d 28 4a 28 00 68 47 | .fH$.a...](J(.hG
d0 66 47 24 14 61 a5 01 d0 66 47 24 11 61 a7 01 | .fG$.a...fG$.a..
d0 66 47 27 61 8e 02 d0 66 47 d0 66 48 61 c3 02 | .fG'a...fG.fHa..
d0 66 47 24 2f 61 a2 01 d0 66 47 24 06 61 a3 01 | .fG$/a...fG$.a..
5d 91 02 d0 4a 42 00 4f 91 02 01 5d 91 02 d0 66 | ]...JB.O...]...f
44 4f 91 02 01 5d 91 02 d0 66 47 4f 91 02 01 d0 | DO...]...fGO....
4f 4b 00 5d 8a 02 60 0a 66 c4 02 d0 66 4c 4f 8a | OK.]..`.f...fLO.
02 02 47 00 00 1d 02 03 09 0a 25 d0 30 d0 2a d5 | ..G.......%.0.*.
66 3f c0 d6 d1 d2 61 3f 08 02 08 01 d0 2a d5 66 | f?....a?.....*.f
41 c0 d6 d1 d2 61 41 08 02 08 01 d0 4f 4b 00 47 | A....aA.....OK.G
00 00 1e 02 03 09 0a 16 d0 30 d0 2a d5 66 3f c1 | .........0.*.f?.
d6 d1 d2 61 3f 08 02 08 01 d0 4f 4b 00 47 00 00 | ...a?.....OK.G..
1f 04 02 09 0a 5f d0 30 5d 02 d0 66 41 46 02 01 | ....._.0]..fAF..
66 f9 01 24 01 14 16 00 00 d0 66 44 2c f4 02 5d | f..$......fD,..]
02 d0 66 41 46 02 01 a0 61 93 02 10 0e 00 00 d0 | ..fAF...a.......
66 44 5d 02 d0 66 41 46 02 01 61 93 02 d0 66 47 | fD]..fAF..a...fG
2c 01 61 93 02 24 00 75 d5 10 0f 00 00 09 d0 66 | ,.a..$.u.......f
47 2c aa 02 4f fe 01 01 d1 91 75 d5 d1 d0 66 3f | G,..O.....u...f?
15 e9 ff ff 47 00 00 20 03 03 09 0c 26 d0 30 5d | ....G.. ....&amp;.0]
c5 02 5d 9c 02 d0 66 3e 4a 9c 02 01 4f c5 02 01 | ..]...f&gt;J...O...
10 0e 00 00 d0 30 5a 00 2a d6 2a 30 2b 6d 01 1d | .....0Z.*.*0+m..
08 02 47 01 02 13 17 c6 02 c7 02 00 21 01 01 03 | ..G.........!...
04 03 d0 30 47 00 00 22 01 01 04 05 06 d0 30 d0 | ...0G.."......0.
49 00 47 00 00 23 01 02 04 05 04 d0 30 26 48 00 | I.G..#......0&amp;H.
00 24 01 01 04 05 05 d0 30 2f 04 48 00 00 25 01 | .$......0/.H..%.
01 04 05 04 d0 30 27 48 00 00 26 01 01 04 05 03 | .....0'H..&amp;.....
d0 30 47 00 00 27 01 01 05 06 06 d0 30 d0 49 00 | .0G..'......0.I.
47 00 00 28 01 02 05 06 04 d0 30 26 48 00 00 29 | G..(......0&amp;H..)
01 01 05 06 05 d0 30 2f 04 48 00 00 2a 01 01 05 | ......0/.H..*...
06 04 d0 30 27 48 00 00 2b 01 01 04 05 03 d0 30 | ...0'H..+......0
47 00 00 2c 02 03 05 06 1d d0 30 d0 49 00 d0 2f | G..,......0.I../
04 68 52 d0 d1 68 53 d0 d2 68 54 d0 5d c8 02 46 | .hR..hS..hT.]..F
c8 02 00 68 55 47 00 00 2d 04 03 05 06 3f d0 30 | ...hUG..-....?.0
24 00 74 d5 28 d6 5d c8 02 46 c8 02 00 74 d5 d1 | $.t.(.]..F...t..
d0 66 55 a1 25 e8 07 a3 75 d6 d0 d1 68 55 d0 d0 | .fU.%...u...hU..
66 52 d2 d0 66 53 a2 d0 66 54 a3 a1 68 52 d0 66 | fR..fS..fT..hR.f
52 2f 04 0c 05 00 00 d0 2f 04 68 52 47 00 00 2e | R/....../.hRG...
03 02 05 06 16 d0 30 d0 4f 56 00 d0 d0 66 52 d1 | ......0.OV...fR.
a0 68 52 d0 66 52 d0 66 53 ae 48 00 00 2f 03 01 | .hR.fR.fS.H../..
05 06 16 d0 30 d0 4f 56 00 d0 66 52 d0 66 53 a1 | ....0.OV..fR.fS.
d0 66 53 d0 66 54 a3 a3 48 00 00 30 02 01 05 06 | .fS.fT..H..0....
0e d0 30 d0 4f 56 00 d0 66 52 d0 66 53 af 48 00 | ..0.OV..fR.fS.H.
00 31 02 01 01 08 76 d0 30 5d c9 02 60 01 30 60 | .1....v.0]..`.0`
57 30 60 11 30 60 ca 02 30 60 13 30 60 20 30 60 | W0`.0`..0`.0` 0`
20 58 00 1d 1d 1d 1d 1d 1d 68 0c 5d cb 02 60 01 |  X.......h.]..`.
30 60 57 30 60 11 30 60 ca 02 30 60 13 30 60 20 | 0`W0`.0`..0`.0` 
30 60 20 58 01 1d 1d 1d 1d 1d 1d 68 2a 5d cc 02 | 0` X.......h*]..
60 01 30 60 01 58 02 1d 68 32 5d cd 02 60 01 30 | `.0`.X..h2]..`.0
60 32 30 60 32 58 03 1d 1d 68 50 5d ce 02 60 01 | `20`2X...hP]..`.
30 60 32 30 60 32 58 04 1d 1d 68 51 47 00 00 32 | 0`20`2X...hQG..2
01 01 04 05 03 d0 30 47 00 00 33 03 02 05 06 24 | ......0G..3....$
d0 30 d0 66 58 12 13 00 00 d0 66 5d d0 66 58 2c | .0.fX.....f].fX,
fa 02 a0 d1 a0 4f 33 01 10 07 00 00 d0 66 5d d1 | .....O3......f].
4f 33 01 47 00 00 34 02 02 05 06 11 d0 30 d0 66 | O3.G..4......0.f
5d 66 2c 12 05 00 00 d0 d1 4f 61 01 47 00 00 35 | ]f,......Oa.G..5
02 02 05 06 07 d0 30 d0 d1 61 58 47 00 00 36 02 | ......0..aXG..6.
06 05 06 26 d0 30 d0 49 00 d0 d1 68 5d d0 d2 68 | ...&amp;.0.I...h]..h
59 d0 d3 68 5a d0 62 04 68 5b d0 62 05 68 5c d0 | Y..hZ.b.h[.b.h\.
56 00 68 5f d0 56 00 68 5e 47 00 00 37 04 02 06 | V.h_.V.h^G..7...
06 60 d1 60 cf 02 b3 12 1d 00 00 5d 61 60 d0 02 | .`.`.......]a`..
2c fa 02 a0 d1 60 cf 02 87 66 93 02 a0 2c aa 02 | ,....`...f...,..
a0 4f 61 01 10 0c 00 00 5d 61 60 d0 02 2c aa 02 | .Oa.....]a`..,..
a0 4f 61 01 60 d1 02 76 2a 12 08 00 00 29 60 d1 | .Oa.`..v*....)`.
02 66 d2 02 76 12 07 00 00 60 d1 02 4f d3 02 00 | .f..v....`..O...
5d d4 02 5d 04 60 04 66 89 02 4a 04 01 4f d4 02 | ]..].`.f..J..O..
01 47 00 00 38 02 04 06 08 13 d0 30 57 2a d7 30 | .G..8......0W*.0
65 01 d1 6d 01 65 01 d2 6d 02 40 37 48 00 02 d0 | e..m.e..m.@7H...
02 00 01 02 00 d1 02 00 02 00 00 39 05 01 05 06 | ...........9....
cb 01 d0 30 d0 66 5b 60 04 66 d5 02 d0 66 66 4f | ...0.f[`.f...ffO
d6 02 02 d0 66 5b 60 04 66 d7 02 d0 66 68 4f d6 | ....f[`.f...fhO.
02 02 d0 66 5b 60 06 66 99 02 d0 2c 81 03 d0 66 | ...f[`.f...,...f
59 46 64 02 4f d6 02 02 d0 66 5b 60 07 66 9a 02 | YFd.O....f[`.f..
d0 2c 82 03 d0 66 59 46 64 02 4f d6 02 02 d0 66 | .,...fYFd.O....f
5b 60 0e 66 d8 02 d0 66 6a 4f d6 02 02 d0 66 59 | [`.f...fjO....fY
60 04 66 d5 02 d0 66 67 4f d6 02 02 d0 66 59 60 | `.f...fgO....fY`
04 66 d7 02 d0 66 69 4f d6 02 02 d0 66 59 60 06 | .f...fiO....fY`.
66 99 02 d0 2c 84 03 d0 66 5b 46 64 02 4f d6 02 | f...,...f[Fd.O..
02 d0 66 59 60 07 66 9a 02 d0 2c 85 03 d0 66 5b | ..fY`.f...,...f[
46 64 02 4f d6 02 02 d0 66 59 60 0e 66 d8 02 d0 | Fd.O....fY`.f...
66 6b 4f d6 02 02 d0 2c 86 03 4f 61 01 d0 4f 5c | fkO....,..Oa..O\
00 d0 2c 87 03 4f 61 01 d0 4f 5a 00 47 00 00 3a | ..,..Oa..OZ.G..:
02 02 05 06 0a d0 30 d0 2c 88 03 4f 61 01 47 00 | ......0.,..Oa.G.
00 3b 02 02 05 06 0a d0 30 d0 2c 89 03 4f 61 01 | .;......0.,..Oa.
47 00 00 3c 02 02 05 06 0e d0 30 d0 2c 8a 03 4f | G..&lt;......0.,..O
61 01 d0 4f 6d 00 47 00 00 3d 02 02 05 06 0e d0 | a..Om.G..=......
30 d0 2c 8b 03 4f 61 01 d0 4f 6d 00 47 00 00 3e | 0.,..Oa..Om.G..&gt;
02 02 05 06 12 d0 30 d0 66 5e d1 66 d9 02 4f a8 | ......0.f^.f..O.
02 01 d0 4f 6d 00 47 00 00 3f 02 02 05 06 12 d0 | ...Om.G..?......
30 d0 66 5f d1 66 d9 02 4f a8 02 01 d0 4f 6d 00 | 0.f_.f..O....Om.
47 00 00 40 04 06 05 06 44 d0 30 20 80 1c 63 05 | G..@....D.0 ..c.
5d 1c 4a 1c 00 80 1c 63 05 d1 62 05 24 00 d3 4f | ].J....c..b.$..O
da 02 03 d2 62 05 4f db 02 01 d2 4f dc 02 00 d0 | ....b.O....O....
66 5d 66 31 d3 4f 4d 01 d0 62 04 2c 8d 03 a0 62 | f]f1.OM..b.,...b
05 66 f9 01 a0 2c aa 02 a0 4f 62 01 47 00 00 41 | .f...,...Ob.G..A
05 02 05 06 e5 02 d0 30 27 d5 d0 66 60 12 0a 00 | .......0'..f`...
00 5d dd 02 d0 66 60 4f dd 02 01 d0 60 f7 01 68 | .]...f`O....`..h
60 d0 66 5b 66 d2 02 96 2a 12 08 00 00 29 d0 66 | `.f[f...*....).f
59 66 d2 02 96 12 01 00 00 47 26 d5 10 63 00 00 | Yf.......G&amp;..c..
09 27 d5 d0 66 59 66 d2 02 76 2a 12 0a 00 00 29 | .'..fYf..v*....)
d0 66 5e 66 f9 01 24 00 af 12 16 00 00 d0 d0 66 | .f^f..$........f
5b d0 66 59 d0 66 5e 46 de 02 00 2c 90 03 4f 6c | [.fY.f^F...,..Ol
04 26 d5 d0 66 5b 66 d2 02 76 2a 12 0a 00 00 29 | .&amp;..f[f..v*....)
d0 66 5f 66 f9 01 24 00 af 12 16 00 00 d0 d0 66 | .f_f..$........f
59 d0 66 5b d0 66 5f 46 de 02 00 2c 91 03 4f 6c | Y.f[.f_F...,..Ol
04 26 d5 d1 76 2a 12 0a 00 00 29 d0 66 5d 66 31 | .&amp;..v*....).f]f1
46 4f 00 96 11 88 ff ff d0 66 5b 66 d2 02 96 2a | FO.......f[f...*
12 0a 00 00 29 d0 66 5e 66 f9 01 24 00 ab 12 0e | ....).f^f..$....
00 00 d0 2c 92 03 4f 61 01 d0 66 59 4f d3 02 00 | ...,..Oa..fYO...
d0 66 59 66 d2 02 96 2a 12 0a 00 00 29 d0 66 5f | .fYf...*....).f_
66 f9 01 24 00 ab 12 0e 00 00 d0 2c 93 03 4f 61 | f..$.......,..Oa
01 d0 66 5b 4f d3 02 00 d0 66 59 66 d2 02 96 2a | ..f[O....fYf...*
12 08 00 00 29 d0 66 5b 66 d2 02 96 12 15 00 00 | ....).f[f.......
5d d4 02 5d 04 60 04 66 89 02 4a 04 01 4f d4 02 | ]..].`.f..J..O..
01 10 35 00 00 d0 66 5e 66 f9 01 24 00 af 2a 11 | ..5...f^f..$..*.
0a 00 00 29 d0 66 5f 66 f9 01 24 00 af 12 19 00 | ...).f_f..$.....
00 d0 5d 95 02 d0 66 6d d0 66 5d 66 31 46 4e 00 | ..]...fm.f]f1FN.
25 e8 07 a2 46 95 02 02 68 60 47 00 00 42 02 01 | %...F...h`G..B..
01 04 14 d0 30 5d df 02 60 01 30 60 57 30 60 57 | ....0]..`.0`W0`W
58 05 1d 1d 68 09 47 00 00 43 00 01 03 03 01 47 | X...h.G..C.....G
00 00 45 02 01 01 02 0b d0 30 5d 9c 01 20 58 06 | ..E......0].. X.
68 6e 47 00 00 46 02 01 06 07 0c d0 30 5e ee 01 | hnG..F......0^..
2c f7 01 68 ee 01 47 00 00 47 04 05 07 0a 28 d0 | ,..h..G..G....(.
30 d0 d1 d2 d3 49 03 5e 58 60 cf 01 d0 46 f3 01 | 0....I.^X`...F..
01 68 58 10 0f 00 00 d0 30 5a 00 2a 63 04 2a 30 | .hX.....0Z.*c.*0
2b 6d 01 1d 08 04 47 01 08 14 18 c6 02 ac 02 00 | +m....G.........
48 02 01 07 08 0b d0 30 60 cf 01 d0 46 f4 01 01 | H......0`...F...
48 00 00 49 02 01 01 06 1c d0 30 5d e0 02 60 01 | H..I......0]..`.
30 60 57 30 60 11 30 60 70 30 60 70 58 07 1d 1d | 0`W0`.0`p0`pX...
1d 1d 68 6f 47 00 00 4a 00 01 03 03 01 47 00 00 | ..hoG..J.....G..
4f 02 01 01 02 0b d0 30 5d 9e 01 20 58 08 68 72 | O......0].. X.hr
47 00 00 50 00 01 04 04 01 47 00 00 88 01 02 01 | G..P.....G......
01 02 0b d0 30 5d 9d 01 20 58 09 68 75 47 00 00 | ....0].. X.huG..
89 01 02 01 07 08 0c d0 30 5e ee 01 2c f7 01 68 | ........0^..,..h
ee 01 47 00 00 8a 01 04 05 08 09 71 d0 30 20 80 | ..G........q.0 .
e1 02 63 04 d0 d1 d2 d3 49 03 60 ef 01 20 14 2b | ..c.....I.`.. .+
00 00 60 e1 02 66 e2 02 80 e1 02 2a 63 04 2c 97 | ..`..f.....*c.,.
03 46 e3 02 01 12 14 00 00 5e ef 01 5d 43 62 04 | .F.......^..]Cb.
2c 97 03 46 e4 02 01 46 43 01 61 ef 01 60 ef 01 | ,..F...FC.a..`..
76 2a 12 14 00 00 29 60 ef 01 2c 9a 03 66 e5 02 | v*....)`..,..f..
60 ef 01 2c 9c 03 66 e5 02 b0 12 0e 00 00 d0 60 | `..,..f........`
04 66 e6 02 d0 66 b6 01 4f 8a 02 02 47 00 00 8b | .f...f..O...G...
01 02 01 08 09 1d d0 30 d0 66 a0 01 20 14 09 00 | .......0.f.. ...
00 d0 04 a2 01 75 10 08 00 00 d0 66 a0 01 66 d0 | .....u.....f..f.
01 75 48 00 00 8c 01 02 02 08 09 2c d0 30 d0 66 | .uH........,.0.f
a2 01 d1 14 01 00 00 47 d0 66 a0 01 20 14 09 00 | .......G.f.. ...
00 d0 d1 05 a2 01 10 0d 00 00 d0 66 a0 01 d1 61 | .......
...f...a
d0 01 d0 4f b8 01 00 47 00 00 8d 01 02 01 08 09 | ...O...G........
1d d0 30 d0 66 a0 01 20 14 09 00 00 d0 04 a3 01 | ..0.f.. ........
75 10 08 00 00 d0 66 a0 01 66 d1 01 75 48 00 00 | u.....f..f..uH..
8e 01 02 02 08 09 2c d0 30 d0 66 a3 01 d1 14 01 | ......,.0.f.....
00 00 47 d0 66 a0 01 20 14 09 00 00 d0 d1 05 a3 | ..G.f.. ........
01 10 0d 00 00 d0 66 a0 01 d1 61 d1 01 d0 4f b8 | ..
...f...a...O.
01 00 47 00 00 8f 01 02 01 08 09 1d d0 30 d0 66 | ..G..........0.f
a0 01 20 14 09 00 00 d0 04 a4 01 75 10 08 00 00 | .. ........u....
d0 66 a0 01 66 d2 01 75 48 00 00 90 01 02 02 08 | .f..f..uH.......
09 2c d0 30 d0 66 a4 01 d1 14 01 00 00 47 d0 66 | .,.0.f.......G.f
a0 01 20 14 09 00 00 d0 d1 05 a4 01 10 0d 00 00 | .. ..........
..
d0 66 a0 01 d1 61 d2 01 d0 4f b8 01 00 47 00 00 | .f...a...O...G..
91 01 05 03 08 09 54 d0 30 20 80 17 d5 d0 66 a0 | ......T.0 ....f.
01 20 14 05 00 00 d0 04 a5 01 48 60 f0 01 20 13 | . ........H`.. .
24 00 00 60 f0 01 2a d6 2c 9e 03 66 e5 02 d2 d0 | $..`..*.,..f....
66 a0 01 66 d3 01 d0 66 a6 01 60 e7 02 66 e8 02 | f..f...f..`..f..
41 03 08 02 80 17 d5 d1 12 09 00 00 d1 66 a2 01 | A............f..
75 10 05 00 00 d0 04 a5 01 75 48 00 00 92 01 03 | u........uH.....
02 08 09 4b d0 30 d0 66 a5 01 d1 14 01 00 00 47 | ...K.0.f.......G
d0 66 a0 01 20 14 09 00 00 d0 d1 05 a5 01 10 2c | .f.. ..........,
00 00 d0 66 a0 01 d1 61 d3 01 d0 66 a0 01 d0 66 | ...f...a...f...f
b2 01 24 00 13 0b 00 00 d1 d0 66 b2 01 a3 75 10 | ..$.......f...u.
03 00 00 24 00 75 61 da 01 d0 4f b8 01 00 47 00 | ...$.ua...O...G.
00 93 01 05 03 08 09 54 d0 30 20 80 17 d5 d0 66 | .......T.0 ....f
a0 01 20 14 05 00 00 d0 04 a7 01 48 60 f0 01 20 | .. ........H`.. 
13 24 00 00 60 f0 01 2a d6 2c 9e 03 66 e5 02 d2 | .$..`..*.,..f...
d0 66 a0 01 66 d3 01 d0 66 a6 01 60 e7 02 66 e8 | .f..f...f..`..f.
02 41 03 08 02 80 17 d5 d1 12 09 00 00 d1 66 a3 | .A............f.
01 75 10 05 00 00 d0 04 a7 01 75 48 00 00 94 01 | .u........uH....
03 02 08 09 48 d0 30 d0 66 a7 01 d1 14 01 00 00 | ....H.0.f.......
47 d0 66 a0 01 20 14 09 00 00 d0 d1 05 a7 01 10 | G.f.. ..........
29 00 00 d0 d1 68 a6 01 d0 66 a0 01 d0 66 b1 01 | )....h...f...f..
24 00 13 0b 00 00 d1 d0 66 b1 01 a3 75 10 03 00 | $.......f...u...
00 24 00 75 61 db 01 d0 4f b8 01 00 47 00 00 95 | .$.ua...O...G...
01 02 01 08 09 1d d0 30 d0 66 a0 01 20 14 09 00 | .......0.f.. ...
00 d0 04 a8 01 75 10 08 00 00 d0 66 a0 01 66 d7 | .....u.....f..f.
01 75 48 00 00 96 01 02 02 08 09 2c d0 30 d0 66 | .uH........,.0.f
a8 01 d1 14 01 00 00 47 d0 66 a0 01 20 14 09 00 | .......G.f.. ...
00 d0 d1 05 a8 01 10 0d 00 00 d0 66 a0 01 d1 61 | .......
...f...a
d7 01 d0 4f b8 01 00 47 00 00 97 01 02 01 08 09 | ...O...G........
1d d0 30 d0 66 a0 01 20 14 09 00 00 d0 04 a9 01 | ..0.f.. ........
75 10 08 00 00 d0 66 a0 01 66 d8 01 75 48 00 00 | u.....f..f..uH..
98 01 02 02 08 09 2c d0 30 d0 66 a9 01 d1 14 01 | ......,.0.f.....
00 00 47 d0 66 a0 01 20 14 09 00 00 d0 d1 05 a9 | ..G.f.. ........
01 10 0d 00 00 d0 66 a0 01 d1 61 d8 01 d0 4f b8 | ..
...f...a...O.
01 00 47 00 00 99 01 02 01 08 09 1d d0 30 d0 66 | ..G..........0.f
a0 01 20 14 09 00 00 d0 04 aa 01 75 10 08 00 00 | .. ........u....
d0 66 a0 01 66 d9 01 75 48 00 00 9a 01 02 02 08 | .f..f..uH.......
09 2c d0 30 d0 66 aa 01 d1 14 01 00 00 47 d0 66 | .,.0.f.......G.f
a0 01 20 14 09 00 00 d0 d1 05 aa 01 10 0d 00 00 | .. ..........
..
d0 66 a0 01 d1 61 d9 01 d0 4f b8 01 00 47 00 00 | .f...a...O...G..
9b 01 02 01 08 09 1d d0 30 d0 66 a0 01 20 14 09 | ........0.f.. ..
00 00 d0 04 ab 01 75 10 08 00 00 d0 66 a0 01 66 | ......u.....f..f
d9 01 75 48 00 00 9c 01 02 02 08 09 2c d0 30 d0 | ..uH........,.0.
66 ab 01 d1 14 01 00 00 47 d0 66 a0 01 20 14 09 | f.......G.f.. ..
00 00 d0 d1 05 ab 01 10 0d 00 00 d0 66 a0 01 d1 | ........
...f...
61 d9 01 d0 4f b8 01 00 47 00 00 9d 01 02 01 08 | a...O...G.......
09 1d d0 30 d0 66 a0 01 20 14 09 00 00 d0 04 ac | ...0.f.. .......
01 75 10 08 00 00 d0 66 a0 01 66 da 01 75 48 00 | .u.....f..f..uH.
00 9e 01 03 02 08 09 40 d0 30 d0 66 ac 01 d1 14 | .......@.0.f....
01 00 00 47 d0 66 a0 01 20 14 09 00 00 d0 d1 05 | ...G.f.. .......
ac 01 10 21 00 00 d0 66 a0 01 d1 61 da 01 d0 66 | ...!...f...a...f
a0 01 60 e9 02 d1 46 ea 02 01 d0 66 b2 01 a2 61 | ..`...F....f...a
d3 01 d0 4f b8 01 00 47 00 00 9f 01 02 01 08 09 | ...O...G........
1d d0 30 d0 66 a0 01 20 14 09 00 00 d0 04 ad 01 | ..0.f.. ........
75 10 08 00 00 d0 66 a0 01 66 db 01 75 48 00 00 | u.....f..f..uH..
a0 01 03 02 08 09 3d d0 30 d0 66 ad 01 d1 14 01 | ......=.0.f.....
00 00 47 d0 66 a0 01 20 14 09 00 00 d0 d1 05 ad | ..G.f.. ........
01 10 1e 00 00 d0 66 a0 01 d1 61 db 01 d0 60 e9 | ......f...a...`.
02 d1 46 ea 02 01 d0 66 b1 01 a2 68 a6 01 d0 4f | ..F....f...h...O
b8 01 00 47 00 00 a1 01 02 01 08 09 1d d0 30 d0 | ...G..........0.
66 a0 01 20 14 09 00 00 d0 04 ae 01 75 10 08 00 | f.. ........u...
00 d0 66 a0 01 66 dc 01 75 48 00 00 a2 01 02 02 | ..f..f..uH......
08 09 2c d0 30 d0 66 ae 01 d1 14 01 00 00 47 d0 | ..,.0.f.......G.
66 a0 01 20 14 09 00 00 d0 d1 05 ae 01 10 0d 00 | f.. ..........
.
00 d0 66 a0 01 d1 61 dc 01 d0 4f b8 01 00 47 00 | ..f...a...O...G.
00 a3 01 01 01 08 09 07 d0 30 d0 66 af 01 48 00 | .........0.f..H.
00 a4 01 02 02 08 09 17 d0 30 d1 d0 66 af 01 14 | .........0..f...
01 00 00 47 d0 d1 68 af 01 d0 4f b3 01 00 47 00 | ...G..h...O...G.
00 a5 01 01 01 08 09 13 d0 30 60 eb 02 12 07 00 | .........0`.....
00 60 eb 02 66 a7 01 48 24 00 48 00 00 a6 01 01 | .`..f..H$.H.....
01 08 09 13 d0 30 60 eb 02 12 07 00 00 60 eb 02 | .....0`......`..
66 a5 01 48 24 00 48 00 00 a7 01 03 03 08 09 aa | f..H$.H.........
01 d0 30 27 d6 60 ec 02 80 13 d5 10 96 00 00 09 | ..0'.`..........
d1 60 72 b3 12 86 00 00 d0 66 af 01 20 ab 96 2a | .`r......f.. ..*
12 0c 00 00 29 5d 72 d1 46 72 01 66 73 20 ab 96 | ....)]r.Fr.fs ..
2a 12 0f 00 00 29 d0 66 af 01 5d 72 d1 46 72 01 | *....).f..]r.Fr.
66 73 ab 96 76 d6 d2 76 2a 12 07 00 00 29 d0 66 | fs..v..v*....).f
a0 01 20 ab 12 1f 00 00 d0 4f b7 01 00 d0 66 a0 | .. ......O....f.
01 20 13 0d 00 00 d0 66 a0 01 d2 61 e1 01 d0 4f | . .
...f...a...O
b8 01 00 10 23 00 00 d2 96 2a 12 06 00 00 29 d0 | ....#....*....).
66 a0 01 76 12 12 00 00 d0 66 a0 01 d2 61 e1 01 | f..v.....f...a..
d0 4f b8 01 00 d0 20 68 a0 01 10 0c 00 00 d1 66 | .O.... h.......f
ec 02 80 13 d5 d1 11 65 ff ff 47 00 00 a8 01 02 | .......e..G.....
03 08 09 0d d0 30 d0 d1 61 a2 01 d0 d2 61 a3 01 | ...
.0..a....a..
47 00 00 a9 01 02 03 08 09 0d d0 30 d0 d1 68 a5 | G........
.0..h.
01 d0 d2 68 a7 01 47 00 00 aa 01 01 02 08 09 08 | ...h..G.........
d0 30 d0 4f b3 01 00 47 00 00 ab 01 04 03 08 09 | .0.O...G........
d3 01 d0 30 20 80 e1 02 d5 20 80 a1 01 d6 d0 66 | ...0 .... .....f
9f 01 20 14 4e 00 00 60 e1 02 66 e2 02 80 e1 02 | .. .N..`..f.....
d5 d1 2c a3 03 46 e3 02 01 12 11 00 00 d0 5d 43 | ..,..F........]C
d1 2c a3 03 46 e4 02 01 46 43 01 68 9f 01 60 f0 | .,..F...FC.h..`.
01 20 14 1f 00 00 d1 2c a4 03 46 e3 02 01 12 13 | . .....,..F.....
00 00 5e f0 01 5d 43 d1 2c a4 03 46 e4 02 01 46 | ..^..]C.,..F...F
43 01 61 f0 01 d0 66 9f 01 20 13 66 00 00 d0 4a | C.a...f.. .f...J
9f 01 00 80 a1 01 d6 d2 d0 66 ac 01 61 da 01 d2 | .........f..a...
d0 66 ad 01 61 db 01 d2 d0 66 ae 01 61 dc 01 d2 | .f..a....f..a...
d0 66 a8 01 61 d7 01 d2 d0 66 a9 01 61 d8 01 d2 | .f..a....f..a...
d0 66 ab 01 61 d9 01 d2 d0 66 a2 01 61 d0 01 d2 | .f..a....f..a...
d0 66 a3 01 61 d1 01 d2 d0 66 a4 01 61 d2 01 d2 | .f..a....f..a...
d0 66 a5 01 61 d3 01 d0 d0 66 a7 01 68 a6 01 d0 | .f..a....f..h...
d2 68 a0 01 47 00 00 ac 01 02 01 08 09 37 d0 30 | .h..G........7.0
d0 66 a0 01 20 13 2b 00 00 d0 66 a0 01 66 df 01 | .f.. .+...f..f..
12 12 00 00 d0 04 e7 02 d0 66 a0 01 66 e5 01 61 | .........f..f..a
ed 02 10 0e 00 00 d0 04 e7 02 d0 66 a0 01 66 e4 | ...........f..f.
01 61 e8 02 47 00 00 ad 01 02 01 01 07 21 d0 30 | .a..G........!.0
5d ee 02 60 01 30 60 57 30 60 11 30 60 70 30 60 | ]..`.0`W0`.0`p0`
6f 30 60 6f 58 0a 1d 1d 1d 1d 1d 68 9b 01 47 00 | o0`oX......h..G.
00 ae 01 01 01 08 09 03 d0 30 47 00 00 af 01 01 | .........0G.....
01 09 0a 06 d0 30 d0 49 00 47 00 00 b0 01 02 01 | .....0.I.G......
01 08 27 d0 30 5d ef 02 60 01 30 60 57 30 60 11 | ..'.0]..`.0`W0`.
30 60 70 30 60 6f 30 60 9b 01 30 60 9b 01 58 0b | 0`p0`o0`..0`..X.
1d 1d 1d 1d 1d 1d 68 b9 01 47 00 00 b1 01 02 01 | ......h..G......
04 05 0c d0 30 5e f1 01 2c fb 01 68 f1 01 47 00 | ....0^..,..h..G.
00 b2 01 02 03 05 06 29 d0 30 d0 49 00 d0 27 68 | .......).0.I..'h
ba 01 d0 5d 1c 4a 1c 00 68 c0 01 d0 d1 68 c1 01 | ...].J..h....h..
d0 d2 68 c2 01 d0 5d bc 01 4a bc 01 00 68 bb 01 | ..h...]..J...h..
47 00 00 b3 01 01 01 05 06 0a d0 30 d0 66 bb 01 | G..........0.f..
66 f0 02 48 00 00 b4 01 01 01 05 06 0a d0 30 d0 | f..H..........0.
66 bd 01 66 f1 02 48 00 00 b5 01 03 04 05 06 9e | f..f..H.........
01 d0 30 20 80 06 d6 10 53 00 00 09 d0 27 68 ba | ..0 ....S....'h.
01 5d d4 02 5d 04 60 04 66 d7 02 4a 04 01 4f d4 | .]..].`.f..J..O.
02 01 10 78 00 00 09 d0 27 68 ba 01 d0 4f cb 01 | ...x....'h...O..
00 10 69 00 00 09 5d 06 60 06 66 99 02 4a 06 01 | ..i...].`.f..J..
80 06 d6 d2 d1 66 f2 02 66 f3 02 61 93 02 5d d4 | .....f..f..a..].
02 d2 4f d4 02 01 10 44 00 00 10 40 00 00 d1 66 | ..O....D...@...f
f2 02 66 f3 02 d7 2c aa 03 d3 1a 06 00 00 24 00 | ..f...,.......$.
10 1a 00 00 2c ab 03 d3 1a 06 00 00 24 01 10 0c | ....,.......$...
00 00 10 06 00 00 24 02 10 02 00 00 24 02 08 03 | ......$.....$...
1b a5 ff ff 02 7b ff ff 96 ff ff a5 ff ff 47 00 | .....{........G.
00 b6 01 04 03 05 06 9b 01 d0 30 10 54 00 00 09 | ..........0.T...
d0 5d 1b d0 66 bb 01 60 1b 66 f4 02 4a 1b 02 68 | .]..f..`.f..J..h
be 01 d0 66 be 01 2c ad 03 d0 66 c7 01 55 01 61 | ...f..,...f..U.a
f5 02 d0 66 be 01 2c ae 03 4f f6 02 01 5d d4 02 | ...f..,..O...]..
5d 04 60 04 66 89 02 4a 04 01 4f d4 02 01 10 51 | ].`.f..J..O....Q
00 00 09 10 4c 00 00 09 d0 d1 46 c5 01 01 48 10 | ....L.....F...H.
40 00 00 d1 66 f2 02 66 f3 02 d6 2c b0 03 d2 1a | @...f..f...,....
06 00 00 24 00 10 1a 00 00 2c b1 03 d2 1a 06 00 | ...$.....,......
00 24 01 10 0c 00 00 10 06 00 00 24 02 10 02 00 | .$.........$....
00 24 02 08 02 1b c2 ff ff 02 7a ff ff bd ff ff | .$........z.....
c2 ff ff 47 00 00 b7 01 04 02 05 06 44 d0 30 d0 | ...G........D.0.
5d 1b d0 66 bb 01 d1 66 f1 02 4a 1b 02 68 bd 01 | ]..f...f..J..h..
d0 66 bd 01 2c b2 03 d0 66 c9 01 55 01 61 f5 02 | .f..,...f..U.a..
d0 66 bd 01 2c 9d 02 4f f7 02 01 d0 26 68 ba 01 | .f..,..O....&amp;h..
5d d4 02 5d 04 60 f1 01 4a 04 01 4f d4 02 01 26 | ]..].`..J..O...&amp;
48 00 00 b8 01 04 03 05 06 bc 01 d0 30 10 75 00 | H...........0.u.
00 09 d0 5d 1b d0 66 bb 01 60 1b 66 f4 02 4a 1b | ...]..f..`.f..J.
02 68 be 01 d0 66 be 01 2c 9d 02 4f f6 02 01 d0 | .h...f..,..O....
5d 1b d0 66 bb 01 d0 66 bf 01 4a 1b 02 68 bd 01 | ]..f...f..J..h..
d0 66 bd 01 2c b2 03 d0 66 c9 01 55 01 61 f5 02 | .f..,...f..U.a..
d0 66 bd 01 2c ae 03 4f f7 02 01 10 67 00 00 09 | .f..,..O....g...
d0 26 68 ba 01 5d d4 02 5d 04 60 04 66 d5 02 4a | .&amp;h..]..].`.f..J
04 01 4f d4 02 01 10 4c 00 00 09 d0 d1 46 c5 01 | ..O....L.....F..
01 48 10 40 00 00 d1 66 f2 02 66 f3 02 d6 2c b0 | .H.@...f..f...,.
03 d2 1a 06 00 00 24 00 10 1a 00 00 2c b1 03 d2 | ......$.....,...
1a 06 00 00 24 01 10 0c 00 00 10 06 00 00 24 02 | ....$.........$.
10 02 00 00 24 02 08 02 1b c2 ff ff 02 59 ff ff | ....$........Y..
a7 ff ff c2 ff ff 47 00 00 b9 01 04 03 05 06 38 | ......G........8
d0 30 20 80 0e d6 5d 0e 60 0e 66 d8 02 4a 0e 01 | .0 ...].`.f..J..
80 0e d6 d2 d1 66 f8 02 61 d9 02 d1 d0 66 c0 01 | .....f..a....f..
d0 66 c0 01 66 f9 01 d1 66 f8 02 4f cc 01 03 5d | .f..f...f..O...]
d4 02 d2 4f d4 02 01 47 00 00 ba 01 03 01 05 06 | ...O...G........
23 d0 30 d0 66 bb 01 60 1a 66 f9 02 d0 66 c6 01 | #.0.f..`.f...f..
4f 8a 02 02 d0 66 bb 01 d0 66 c1 01 d0 66 c2 01 | O....f...f...f..
4f 65 02 47 00 00 bb 01 03 02 05 06 28 d0 30 d0 | Oe.G........(.0.
d1 61 bf 01 d0 66 bb 01 60 1a 66 f9 02 d0 66 c8 | .a...f..`.f...f.
01 4f 8a 02 02 d0 66 bb 01 d0 66 c1 01 d0 66 c2 | .O....f...f...f.
01 4f 65 02 47 00 00 bc 01 01 01 05 06 33 d0 30 | .Oe.G........3.0
d0 66 be 01 12 08 00 00 d0 66 be 01 4f cb 01 00 | .f.......f..O...
d0 66 bd 01 12 08 00 00 d0 66 bd 01 4f cb 01 00 | .f.......f..O...
d0 66 bb 01 12 08 00 00 d0 66 bb 01 4f cb 01 00 | .f.......f..O...
47 00 00 bd 01 04 04 05 06 23 d0 30 d0 66 c0 01 | G........#.0.f..
d1 d2 d3 4f cc 01 03 d0 66 c0 01 66 f8 02 24 00 | ...O....f..f..$.
14 08 00 00 d0 66 c0 01 4f fa 02 00 47 00 00 be | .....f..O...G...
01 04 05 05 06 26 d0 30 20 80 1c 63 04 5d 1c 4a | .....&amp;.0 ..c.].J
1c 00 80 1c 2a 63 04 d1 d2 d3 4f cd 01 03 d0 66 | ....*c....O....f
be 01 2c b2 03 62 04 4f fb 02 02 47 00 00 bf 01 | ..,..b.O...G....
01 01 05 06 03 d0 30 47 00 00 c0 01 02 01 01 04 | ......0G........
14 d0 30 5d fc 02 60 01 30 60 57 30 60 57 58 0c | ..0]..`.0`W0`WX.
1d 1d 68 08 47 00 00 c1 01 01 01 01 02 03 d0 30 | ..h.G..........0
47 00 00 c2 01 02 01 03 04 14 d0 30 5e ee 01 2c | G..........0^..,
f7 01 68 ee 01 5e f2 01 24 00 61 f2 01 47 00 00 | ..h..^..$.a..G..
c3 01 04 07 03 04 70 d0 30 d1 11 02 00 00 20 48 | ......p.0..... H
5d fd 02 d1 46 fd 02 01 85 d6 d2 2c b9 03 46 a2 | ]...F......,..F.
02 01 73 d7 d3 24 ff 13 0b 00 00 d2 d3 24 02 a0 | ..s..$.......$..
46 be 02 01 85 d6 d2 d2 66 f9 01 93 46 fe 02 01 | F.......f...F...
73 2a 63 04 24 30 b0 2a 12 06 00 00 29 62 04 24 | s*c.$0.*....)b.$
39 ae 12 06 00 00 d2 2c bb 03 a0 d6 d2 5d f2 01 | 9......,.....]..
2a 63 05 66 f2 01 2a c0 63 06 62 05 62 06 61 f2 | *c.f..*.c.b.b.a.
01 08 06 08 05 a0 48 00 00 c4 01 04 07 03 06 da | ......H.........
01 d0 30 20 85 d6 20 80 11 d7 20 85 63 04 20 80 | ..0 .. ... .c. .
15 63 05 d1 80 11 d7 10 a5 00 00 09 d3 66 ec 02 | .c...........f..
82 76 2a 12 07 00 00 29 d3 66 81 02 82 76 2a 12 | .v*....).f...v*.
0a 00 00 29 d3 66 ec 02 d3 66 81 02 ab 12 04 00 | ...).f...f......
00 10 81 00 00 2c c7 01 d3 b4 2a 12 09 00 00 29 | .....,....*....)
d3 2c c7 01 66 ff 02 76 12 0c 00 00 d3 2c c7 01 | .,..f..v.....,..
66 ff 02 85 10 04 00 00 d3 66 58 85 85 63 04 d3 | f........fX..c..
60 1f b3 12 29 00 00 5d 1f d3 46 1f 01 66 e6 01 | `...)..]..F..f..
80 15 2a 63 05 12 17 00 00 62 04 2c bc 03 62 05 | ..*c.....b.,..b.
2c bd 03 46 80 03 01 a0 2c bf 03 a0 a0 85 63 04 | ,..F....,.....c.
d2 20 ab 12 07 00 00 62 04 85 10 09 00 00 62 04 | . .....b......b.
2c aa 02 a0 d2 a0 85 85 d6 d3 66 ec 02 80 11 d7 | ,.........f.....
d3 20 14 55 ff ff 10 0f 00 00 d0 30 5a 00 2a 63 | . .U.......0Z.*c
06 2a 30 2b 6d 01 1d 08 06 d2 48 01 12 c5 01 c9 | .*0+m.....H.....
01 81 03 ac 02 00 c5 01 03 04 03 04 3f d0 30 20 | ............?.0 
85 d6 d1 60 02 b3 12 0a 00 00 d1 60 02 87 85 d6 | ...`.......`....
10 0a 00 00 5d fd 02 d1 46 fd 02 01 85 d6 d2 2c | ....]...F......,
b9 03 46 a2 02 01 73 d7 d3 24 ff 13 0b 00 00 d2 | ..F...s..$......
d3 24 02 a0 46 be 02 01 85 d6 d2 48 00 00 c6 01 | .$..F......H....
01 01 04 05 06 d0 30 d0 49 00 47 00 00 c7 01 02 | ......0.I.G.....
01 01 03 11 d0 30 5d 82 03 60 01 30 60 01 58 0d | .....0]..`.0`.X
1d 68 cf 01 47 00 00 c8 01 00 01 03 03 01 47 00 | .h..G.........G.
00 f2 01 02 01 01 02 0c d0 30 5d 83 03 20 58 0e | .........0].. X.
68 a1 01 47 00 00 f3 01 00 01 03 03 01 47 00 00 | h..G.........G..
fd 01 02 01 01 02 0b d0 30 5d 84 03 20 58 0f 68 | ........0].. X.h
1f 47 00 00                                     | .G..


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111223033159</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-12-23 03:31:59-0400</timestampReceived><subject>Re: [tor-dev] [flashproxy] Not running using gnash</subject><body>

On Thu, Dec 22, 2011 at 03:38:29PM +0100, Okhin wrote:
&gt; Hello,
&gt; 
&gt; I was trying to run flashproxy using gnash following the RTMFP part of
&gt; the tutorial located here:
&gt; https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README
&gt; 
&gt; I do not use the gnash-plugin embedded in a browser, but the CLI tool
&gt; gnash packaged with debian (and invoking it like this, as a standard
&gt; user: gnash swfcat.swf -p client=1 -p debug=1

Thank you for testing this and for the thorough report. Unfortunately
I'm not surprised that it doesn't work with Gnash. I don't think Gnash
has some of the features we use, and probably doesn't have RTMFP, which
has only been partially reverse-engineered in another project. Some log
messages suggest this:

&gt; 3338:1] 15:33:34: UNIMPLEMENTED: SWF10 is not fully supported, trying anyway but \
&gt; don't expect it to work 3338:2] 15:33:35: DEBUG: This SWF uses AVM2
&gt; 3338:2] 15:33:35: ERROR: This SWF file requires AVM2, which was not enabled at \
&gt; compile time.

RTMFP is only useful for NAT traversal, so if you can enable port
forwarding or something else, don't use it. Personally, I don't
recommend using the RTMFP transport at all, for these reasons:
1. It requires a static third party to assist in NAT traversal. By
   default this is some Adobe server, which is clearly unacceptable. We
   found a way to use our own server, so you at least don't have to
   trust any additional parties, but that server still sits at a static
   address and is trivially blockable, defeating the whole purpose.
2. It requires running Flash on the client, which is not normally
   required when using flash proxies.
3. The fact that normally Flash is run in the browser may encourage
   people to run Flash in their Tor browser, which is a bad idea.

I think you had the right idea in trying to run it with Gnash from the
command line. But if you can avoid using RTMFP, that's what I recommend.

This is how I use flash proxies with port forwarding at home:
	Set up my router to forward port 7000 to my PC.
	sudo iptables -A INPUT --proto tcp --dport 7000 -j ACCEPT
	./connector.py -f tor-facilitator.bamsoftware.com :9001 :7000

David Fifield
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111223160001</emailId><senderName>Mauricio Pasquier Juan</senderName><senderEmail>mauricio@pasquierjuan.com.ar</senderEmail><timestampReceived>2011-12-23 16:00:01-0400</timestampReceived><subject>Re: [tor-dev] [flashproxy] Not running using gnash</subject><body>

On Thu, Dec 22, 2011 at 07:31:59PM -0800, David Fifield wrote:
&gt; On Thu, Dec 22, 2011 at 03:38:29PM +0100, Okhin wrote:
&gt; &gt; Hello,
&gt; &gt; 
&gt; &gt; I was trying to run flashproxy using gnash following the RTMFP part of
&gt; &gt; the tutorial located here:
&gt; &gt; https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README
&gt; &gt; 
&gt; &gt; I do not use the gnash-plugin embedded in a browser, but the CLI tool
&gt; &gt; gnash packaged with debian (and invoking it like this, as a standard
&gt; &gt; user: gnash swfcat.swf -p client=1 -p debug=1
&gt; 
&gt; Thank you for testing this and for the thorough report. Unfortunately
&gt; I'm not surprised that it doesn't work with Gnash. I don't think Gnash
&gt; has some of the features we use, and probably doesn't have RTMFP, which
&gt; has only been partially reverse-engineered in another project. Some log
&gt; messages suggest this:

If the only reason to use flash is RTMFP, maybe it can be replaced with this
technique: http://samy.pl/pwnat/ (if I didn't misunderstood the architecture of
flashproxy)

Anyway, if there is some javascript code to check, I'd like to help with that
development.

--
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111221051658</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-21 05:16:58-0400</timestampReceived><subject>Re: [tor-dev] Drafting a proposal for mnemonic onion URLs</subject><body>

On Tue, Dec 20, 2011 at 11:20 PM, Sai &lt;tor@saizai.com&gt; wrote:
&gt; Howdy all.
&gt;
&gt; I would like to make a mnemonic translation method for onion URLs. Not
&gt; as in a full petname system with registration and so forth, just a
&gt; "four little words" style way of rendering and entering existing
&gt; 80-bit hashes in a way that is memorable to not just detect
&gt; partial-overlap fuzzing attacks but actually memorize and produce the
&gt; URL directly.
&gt;

So, the last time I was talking about this (with a grad student whose
name I have just asked for permission to cite), I came up with the
following scheme.  Let BW be the number of bits per natural-language
word; let BH be the number of bits per hidden service identity key
hash.  Let H() be some hash function.  Represent the onion key
identity hash as a sequence of BH/BW natural-language words, letting
each word W represent the first BW bits of H(W).

So if H() is SHA256, and BW is 20, and BH is 80, the hostname
  bookbind.electrodynamism.unsurnamed.squibbish
would represent the 80-bit sequence
  Ht("bookbind") Ht("electrodynamism") H("unsurnamed") H("squibbish")
where Ht(x) is the first 20 bits of SHA256(x).

(In practice, 80 bits is feeling way too short these days; but that's
another discussion.)

The main advantages and disadvantages of this idea are:

  + You don't need to ship a shared wordlist with the client software.
 (That's a good thing, since big dictionaries get annoying fast.)
  + You don't need to restrict yourself to any particular language; it
is not English-centric.
  - If bw is large enough, there will be sequences of bits that are
not represented as the hash of any particular English word.  (e.g., if
bw is 32, you are in trouble: no language has 4 billion words!)  You
can work around this by having your search program generate new
english-sounding sequences, by using a bigger wordlist or by
generating keys until you find one whose fingerprint *is*
representable with words you have.
  - If you make BW big, you are going to get some pretty obscure words.
  - Encodings are not unique.
  + You can get a lot of bits per word.  If you're willing to do stuff
like "every word in english" x "the numbers 00-99", you can get even
more.
  + It scales to more than 80 bits pretty easily.
  - It doesn't make pretty sentences by default, though you can keep
generating words till you find something you like the sound of.
  - We'd need to watch out for words that look equivalent to a human,
but aren't.
  / You actually need to write a reasonably good search program.  This
isn't too hard, and the database it generates isn't too big.

There are other issues and other possible solutions too.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217164033</emailId><senderName>Dave Jevans</senderName><senderEmail>djevans@ironkey.com</senderEmail><timestampReceived>2011-12-17 16:40:33-0400</timestampReceived><subject>Re: [tor-dev] Is Taking Checksum of Packet Payloads a Vulnerability?</subject><body>


This attach will not work.  Alice's tor client on her computer creates a
 Multi layered encrypted connection, hence the term onion routing.  If Alice's \
connection to the exit node goes through 3 tor nodes (eg entry, middle, exit) then \
the connection is encrypted three times with different keys as it enters the entry \
node EN.  This decrypts the first layer, and this traffic is sent to the middle node. \
This node decrypts the second layer of the onion, and sends ti to the exit node.   \
The exit node decrypts the third level of onion encryption and forwards to Bob.

Thus a packet sniffer doing checksums anywhere in between wil Not see the same \
traffic, and will not be able to correlate between Alice's packets and those that \
traverse to Bob, or between any of the intermediate nodes.



On Dec 17, 2011, at 8:25 AM, "Daniel Cohen" &lt;danielc192@gmail.com&gt; wrote:

&gt; Hi,
&gt; 
&gt; I am new to Tor, but after reading about its design, and reading a few research \
&gt; papers on its vulnerabilities (specifically timing attacks), I had the following \
&gt; thought: 
&gt; Suppose Alice is connecting to Bob via Tor, using HTTPS encryption. She sends a \
&gt; packet to the Tor entry node (call it En). The packet travels through the network, \
&gt; emerges from an exit node (call it Ex), and arrives at Bob. 
&gt; Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; Bob
&gt; 
&gt; Now suppose that Alice's connection is being monitored, as well as a group of the \
&gt; exit nodes (which are either hostile or having their packets sniffed). When the \
&gt; encrypted packet leaves Alice on its way to En, it is sniffed, and a checksum is \
&gt; made of its encrypted payload. The packet then continues through the network as \
&gt; usual, and emerges from an exit node. 
&gt; It appears to me that the attacker need only check packets coming out of exit nodes \
&gt; to see if their payload checksums match that of the packet observed leaving Alice. \
&gt; Unlike timing attacks, which require a reasonable number of packets to confirm \
&gt; Alice's identity, this attack would require only one, since checksums have an \
&gt; almost 0% chance of collision. If a packet with the same payload checksum as \
&gt; Alice's is discovered, it almost certainly originated from her. 
&gt; Is this a problem with Tor's architecture? If so, has this issue already been \
&gt; addressed? 
&gt; Thanks,
&gt; 
&gt; Daniel Cohen
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111217165119</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-12-17 16:51:19-0400</timestampReceived><subject>Re: [tor-dev] Is Taking Checksum of Packet Payloads a Vulnerability?</subject><body>

[Attachment #2 (multipart/alternative)]


Note that the data sent from Alice to En is encrypted with a key only they
share, rendering this attack impossible.
On Dec 17, 2011 11:25 AM, "Daniel Cohen" &lt;danielc192@gmail.com&gt; wrote:

&gt; Hi,
&gt;
&gt; I am new to Tor, but after reading about its design, and reading a few
&gt; research papers on its vulnerabilities (specifically timing attacks), I had
&gt; the following thought:
&gt;
&gt; Suppose Alice is connecting to Bob via Tor, using HTTPS encryption. She
&gt; sends a packet to the Tor entry node (call it En). The packet travels
&gt; through the network, emerges from an exit node (call it Ex), and arrives at
&gt; Bob.
&gt;
&gt; Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; Bob
&gt;
&gt; Now suppose that Alice's connection is being monitored, as well as a group
&gt; of the exit nodes (which are either hostile or having their packets
&gt; sniffed). When the encrypted packet leaves Alice on its way to En, it is
&gt; sniffed, and a checksum is made of its encrypted payload. The packet then
&gt; continues through the network as usual, and emerges from an exit node.
&gt;
&gt; It appears to me that the attacker need only check packets coming out of
&gt; exit nodes to see if their payload checksums match that of the packet
&gt; observed leaving Alice. Unlike timing attacks, which require a reasonable
&gt; number of packets to confirm Alice's identity, this attack would require
&gt; only one, since checksums have an almost 0% chance of collision. If a
&gt; packet with the same payload checksum as Alice's is discovered, it almost
&gt; certainly originated from her.
&gt;
&gt; Is this a problem with Tor's architecture? If so, has this issue already
&gt; been addressed?
&gt;
&gt; Thanks,
&gt;
&gt; Daniel Cohen
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
&gt;

[Attachment #5 (text/html)]

&lt;p&gt;Note that the data sent from Alice to En is encrypted with a key only they share, \
rendering this attack impossible.&lt;/p&gt; &lt;div class="gmail_quote"&gt;On Dec 17, 2011 11:25 \
AM, "Daniel Cohen" &lt;&lt;a \
href="mailto:danielc192@gmail.com"&gt;danielc192@gmail.com&lt;/a&gt;&gt; wrote:&lt;br \
type="attribution"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex"&gt; Hi,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am new to \
Tor, but after reading about its design, and reading a few research papers on its \
vulnerabilities (specifically timing attacks), I had the following \
thought:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Suppose Alice is connecting to Bob via Tor, using \
HTTPS encryption. She sends a packet to the Tor entry node (call it En). The packet \
travels through the network, emerges from an exit node (call it Ex), and arrives at \
Bob.&lt;/div&gt;


&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; \
Bob&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Now suppose that Alice's connection is being \
monitored, as well as a group of the exit nodes (which are either hostile or having \
their packets sniffed). When the encrypted packet leaves Alice on its way to En, it \
is sniffed, and a checksum is made of its encrypted payload. The packet then \
continues through the network as usual, and emerges from an exit node.&lt;/div&gt;


&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It appears to me that the attacker need only check packets coming \
out of exit nodes to see if their payload checksums match that of the packet observed \
leaving Alice. Unlike timing attacks, which require a reasonable number of packets to \
confirm Alice's identity, this attack would require only one, since checksums \
have an almost 0%  chance of  collision. If a packet with the same payload checksum \
as Alice's is discovered, it almost certainly originated from her.&lt;/div&gt;


&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is this a problem with Tor's architecture? If so, has this \
issue already been addressed?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Daniel \
Cohen&lt;br&gt; &lt;/div&gt;
&lt;br&gt;_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111210201956</emailId><senderName>Ralf-Philipp Weinmann</senderName><senderEmail>ralf@coderpunks.org</senderEmail><timestampReceived>2011-12-10 20:19:56-0400</timestampReceived><subject>Re: [tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>


On Dec 10, 2011, at 4:07 PM, Robert Ransom wrote:

&gt; On 2011-12-06, Aaron &lt;aagbsn@extc.org&gt; wrote:
&gt; =

&gt;&gt;        How does IPv6 affect address datamining of https distribution?
&gt;&gt;          A user may be allocated a /128, or a /64.
&gt;&gt;          An adversary may control a /32 or perhaps larger
&gt;&gt;          Proposal: Enable reCAPTCHA support by default.
&gt; =

&gt; How much would it cost China to have 1000 (or even 10000) CAPTCHAs
&gt; solved?  How much of our bridge pool would such an attack obtain?


Apparently prices are as low as USD 2.00 for 1000 CAPTCHAs (solved by human=
s): =


http://decaptcher.com

Assuming those prices, it's cheaper to deplete Tor's bridge pool than going=
 out on a night in the town=85

Cheers,
Ralf
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217020720</emailId><senderName>Aaron</senderName><senderEmail>aagbsn@extc.org</senderEmail><timestampReceived>2011-12-17 02:07:20-0400</timestampReceived><subject>Re: [tor-dev] Draft Proposal for BridgeDB IPv6 Support</subject><body>

On Sat, Dec 10, 2011 at 12:19 PM, Ralf-Philipp Weinmann
&lt;ralf@coderpunks.org&gt; wrote:
&gt;
&gt; On Dec 10, 2011, at 4:07 PM, Robert Ransom wrote:
&gt;
&gt;&gt; On 2011-12-06, Aaron &lt;aagbsn@extc.org&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; =A0 =A0 =A0 =A0How does IPv6 affect address datamining of https distrib=
ution?
&gt;&gt;&gt; =A0 =A0 =A0 =A0 =A0A user may be allocated a /128, or a /64.
&gt;&gt;&gt; =A0 =A0 =A0 =A0 =A0An adversary may control a /32 or perhaps larger
&gt;&gt;&gt; =A0 =A0 =A0 =A0 =A0Proposal: Enable reCAPTCHA support by default.
&gt;&gt;
&gt;&gt; How much would it cost China to have 1000 (or even 10000) CAPTCHAs
&gt;&gt; solved? =A0How much of our bridge pool would such an attack obtain?

If China controls enough geographically diverse addresses, presumably
most or all of the
bridges assigned to the https distributor. CAPTCHA is not the limiting fact=
or,
it seems.

&gt;
&gt;
&gt; Apparently prices are as low as USD 2.00 for 1000 CAPTCHAs (solved by hum=
ans):
&gt;
&gt; http://decaptcher.com
&gt;
&gt; Assuming those prices, it's cheaper to deplete Tor's bridge pool than goi=
ng out on a night in the town=85
&gt;
&gt; Cheers,
&gt; Ralf

Unfortunately that is the reality given any adversary with a large
budget. I don't know
if that means we should give up on CAPTCHA; it is still an incremental
improvement
that forces attackers to adapt and spend resources with a low cost to
us and our users.
CAPTCHA is widely deployed and understood, and we stand to benefit
from any future
improvements made in the anti-spam arms race. And it's worth pointing out t=
hat
CAPTCHA does rate-limit the requests to some degree.

That said, perhaps we should save CAPTCHA for a rainy day; it might
buy a week or two
window when we most need it. If we enable CAPTCHA by default and it is
quickly broken
we end up inconveniencing our users and add another point of failure.

--Aaron
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217021739</emailId><senderName>Aaron</senderName><senderEmail>aagbsn@extc.org</senderEmail><timestampReceived>2011-12-17 02:17:39-0400</timestampReceived><subject>[tor-dev] BridgeDB IPv6 Support (!)</subject><body>

code is here:
https://gitweb.torproject.org/user/aagbsn/bridgedb.git/shortlog/refs/heads/4297-ipv6-bridges

running code is here:
https://tor.extc.org/

and here (ipv6):
https://tor.extc.org/ipv6

None of the bridges at these addresses are valid, except by coincidence.

Any feedback or questions are very welcome. Thanks!

--Aaron
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111217095026</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-12-17 09:50:26-0400</timestampReceived><subject>Re: [tor-dev] [tor-announce] Tor 0.2.2.35 is released (security</subject><body>

Should we think to have all tor-users that run a version minor than X,
go automatically off-the-network?

I mean, if we have let's say 10% of outdated users, it means that 10% of
the network can be compromised with a single remote exploit.

I mean, running a Tor node today it's a responsibility.

If a node maintainer it not going to update within a possibly defined
grace period, it should imho get kicked-out from the network.

Has been this concept already considered somehow?
I mean, at least if a node is not updated for example, it would never be
able to achieve a certain "status" or functionalities.
For example never become a Guard node or never became an Exit Node?

-naif

On 12/16/11 7:19 PM, Roger Dingledine wrote:
&gt; Tor 0.2.2.35 fixes a critical heap-overflow security issue in Tor's
&gt; buffers code. Absolutely everybody should upgrade.
&gt; 
&gt; The bug relied on an incorrect calculation when making data continuous
&gt; in one of our IO buffers, if the first chunk of the buffer was
&gt; misaligned by just the wrong amount. The miscalculation would allow an
&gt; attacker to overflow a piece of heap-allocated memory. To mount this
&gt; attack, the attacker would need to either open a SOCKS connection to
&gt; Tor's SocksPort (usually restricted to localhost), or target a Tor
&gt; instance configured to make its connections through a SOCKS proxy
&gt; (which Tor does not do by default).
&gt; 
&gt; Good security practice requires that all heap-overflow bugs should be
&gt; presumed to be exploitable until proven otherwise, so we are treating
&gt; this as a potential code execution attack. Please upgrade immediately!
&gt; This bug does not affect bufferevents-based builds of Tor. Special
&gt; thanks to "Vektor" for reporting this issue to us!
&gt; 
&gt; Tor 0.2.2.35 also fixes several bugs in previous versions, including
&gt; crash bugs for unusual configurations, and a long-term bug that
&gt; would prevent Tor from starting on Windows machines with draconian
&gt; AV software.
&gt; 
&gt; With this release, we remind everyone that 0.2.0.x has reached its
&gt; formal end-of-life. Those Tor versions have many known flaws, and
&gt; nobody should be using them. You should upgrade -- ideally to the
&gt; 0.2.2.x series. If you're using a Linux or BSD and its packages are
&gt; obsolete, stop using those packages and upgrade anyway.
&gt; 
&gt; The Tor 0.2.1.x series is also approaching its end-of-life: it will no
&gt; longer receive support after some time in early 2012.
&gt; 
&gt; https://www.torproject.org/download/download
&gt; 
&gt; Note that the tarball and git tags are signed by Nick Mathewson (gpg
&gt; key 165733EA) this time around.
&gt; 
&gt; Changes in version 0.2.2.35 - 2011-12-16
&gt;   o Major bugfixes:
&gt;     - Fix a heap overflow bug that could occur when trying to pull
&gt;       data into the first chunk of a buffer, when that chunk had
&gt;       already had some data drained from it. Fixes CVE-2011-2778;
&gt;       bugfix on 0.2.0.16-alpha. Reported by "Vektor".
&gt;     - Initialize Libevent with the EVENT_BASE_FLAG_NOLOCK flag enabled, so
&gt;       that it doesn't attempt to allocate a socketpair. This could cause
&gt;       some problems on Windows systems with overzealous firewalls. Fix for
&gt;       bug 4457; workaround for Libevent versions 2.0.1-alpha through
&gt;       2.0.15-stable.
&gt;     - If we mark an OR connection for close based on a cell we process,
&gt;       don't process any further cells on it. We already avoid further
&gt;       reads on marked-for-close connections, but now we also discard the
&gt;       cells we'd already read. Fixes bug 4299; bugfix on 0.2.0.10-alpha,
&gt;       which was the first version where we might mark a connection for
&gt;       close based on processing a cell on it.
&gt;     - Correctly sanity-check that we don't underflow on a memory
&gt;       allocation (and then assert) for hidden service introduction
&gt;       point decryption. Bug discovered by Dan Rosenberg. Fixes bug 4410;
&gt;       bugfix on 0.2.1.5-alpha.
&gt;     - Fix a memory leak when we check whether a hidden service
&gt;       descriptor has any usable introduction points left. Fixes bug
&gt;       4424. Bugfix on 0.2.2.25-alpha.
&gt;     - Don't crash when we're running as a relay and don't have a GeoIP
&gt;       file. Bugfix on 0.2.2.34; fixes bug 4340. This backports a fix
&gt;       we've had in the 0.2.3.x branch already.
&gt;     - When running as a client, do not print a misleading (and plain
&gt;       wrong) log message that we're collecting "directory request"
&gt;       statistics: clients don't collect statistics. Also don't create a
&gt;       useless (because empty) stats file in the stats/ directory. Fixes
&gt;       bug 4353; bugfix on 0.2.2.34.
&gt; 
&gt;   o Minor bugfixes:
&gt;     - Detect failure to initialize Libevent. This fix provides better
&gt;       detection for future instances of bug 4457.
&gt;     - Avoid frequent calls to the fairly expensive cull_wedged_cpuworkers
&gt;       function. This was eating up hideously large amounts of time on some
&gt;       busy servers. Fixes bug 4518; bugfix on 0.0.9.8.
&gt;     - Resolve an integer overflow bug in smartlist_ensure_capacity().
&gt;       Fixes bug 4230; bugfix on Tor 0.1.0.1-rc. Based on a patch by
&gt;       Mansour Moufid.
&gt;     - Don't warn about unused log_mutex in log.c when building with
&gt;       --disable-threads using a recent GCC. Fixes bug 4437; bugfix on
&gt;       0.1.0.6-rc which introduced --disable-threads.
&gt;     - When configuring, starting, or stopping an NT service, stop
&gt;       immediately after the service configuration attempt has succeeded
&gt;       or failed. Fixes bug 3963; bugfix on 0.2.0.7-alpha.
&gt;     - When sending a NETINFO cell, include the original address
&gt;       received for the other side, not its canonical address. Found
&gt;       by "troll_un"; fixes bug 4349; bugfix on 0.2.0.10-alpha.
&gt;     - Fix a typo in a hibernation-related log message. Fixes bug 4331;
&gt;       bugfix on 0.2.2.23-alpha; found by "tmpname0901".
&gt;     - Fix a memory leak in launch_direct_bridge_descriptor_fetch() that
&gt;       occurred when a client tried to fetch a descriptor for a bridge
&gt;       in ExcludeNodes. Fixes bug 4383; bugfix on 0.2.2.25-alpha.
&gt;     - Backport fixes for a pair of compilation warnings on Windows.
&gt;       Fixes bug 4521; bugfix on 0.2.2.28-beta and on 0.2.2.29-beta.
&gt;     - If we had ever tried to call tor_addr_to_str on an address of
&gt;       unknown type, we would have done a strdup on an uninitialized
&gt;       buffer. Now we won't. Fixes bug 4529; bugfix on 0.2.1.3-alpha.
&gt;       Reported by "troll_un".
&gt;     - Correctly detect and handle transient lookup failures from
&gt;       tor_addr_lookup. Fixes bug 4530; bugfix on 0.2.1.5-alpha.
&gt;       Reported by "troll_un".
&gt;     - Fix null-pointer access that could occur if TLS allocation failed.
&gt;       Fixes bug 4531; bugfix on 0.2.0.20-rc. Found by "troll_un".
&gt;     - Use tor_socket_t type for listener argument to accept(). Fixes bug
&gt;       4535; bugfix on 0.2.2.28-beta. Found by "troll_un".
&gt; 
&gt;   o Minor features:
&gt;     - Add two new config options for directory authorities:
&gt;       AuthDirFastGuarantee sets a bandwidth threshold for guaranteeing the
&gt;       Fast flag, and AuthDirGuardBWGuarantee sets a bandwidth threshold
&gt;       that is always sufficient to satisfy the bandwidth requirement for
&gt;       the Guard flag. Now it will be easier for researchers to simulate
&gt;       Tor networks with different values. Resolves ticket 4484.
&gt;     - When Tor ignores a hidden service specified in its configuration,
&gt;       include the hidden service's directory in the warning message.
&gt;       Previously, we would only tell the user that some hidden service
&gt;       was ignored. Bugfix on 0.0.6; fixes bug 4426.
&gt;     - Update to the December 6 2011 Maxmind GeoLite Country database.
&gt; 
&gt;   o Packaging changes:
&gt;     - Make it easier to automate expert package builds on Windows,
&gt;       by removing an absolute path from makensis.exe command.
&gt; 
&gt; 
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-announce mailing list
&gt; tor-announce@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-announce

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111219025211</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-19 02:52:11-0400</timestampReceived><subject>Re: [tor-dev] common/aes.c troubles</subject><body>

On Sun, Dec 18, 2011 at 7:46 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; "Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:
&gt;
&gt;&gt; I'd say "not so good" if it only applies to MSVC builds.
&gt;
&gt;
&gt; I applies to all Win builds. Are you not getting any warnings
&gt; and errors when compiling aes.c?

I was referring to your idea of orconfig.h changes.  The orconfig.h in
src/win32 is only used by msvc.


-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111219111322</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-12-19 11:13:22-0400</timestampReceived><subject>[tor-dev] Python SSL/TLS Security enhancement</subject><body>

Hi all,

following the new Tor2web development based on Python by hellais
(ongoing http://github.com/hellais/tor2web) we realized that the Python
SSL binding are quite crap.

We opened a set of Tickets on Python Issue tracker where i think that
the Tor Project Community (that use a lot Python) could contribute
and/or give out ideas.

Having a secure Python SSL/TLS binding can be very valuable:


Python SSL stack doesn't support DH ciphers
http://bugs.python.org/issue13626

Python SSL stack doesn't support Elliptic Curve ciphers
http://bugs.python.org/issue13627

Python SSL stack doesn't support ordering of Ciphers
http://bugs.python.org/issue13635

Python SSL stack doesn't support Compression configuration
http://bugs.python.org/issue13634

In particular one idea, following the assessment of implementation,
would be to provide to Python a default set of secure ciphers,
considering performance and compatibility issues where i think that the
Tor Project knowledge could be helpful:

Python SSL Stack doesn't have a Secure Default set of ciphers
http://bugs.python.org/issue13636

Defining a method of selection that can convince the Python project to
be "Secure by default" (yet compatible and high performance) without
leaving enable by default SSLv2 or DES 40bit ciphers.

Hope in some contribution and testing

-naif

p.s. basically DHE,ECDHE, Ordered ciphers are needed for tor2web
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111219135440</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2011-12-19 13:54:40-0400</timestampReceived><subject>Re: [tor-dev] Is Taking Checksum of Packet Payloads a	Vulnerability?</subject><body>

Dave is correct. This attack will not work for the reaseons he said.

Just a minor quibble: Dave is not quite correct about the origins of
'onion routing'. We called it that because of a data structure that we
used in the original system (and shared by our second generation
system and also ZKS Freedom and some others, given an abstract enough
description). This data structure does not exist in Tor, which instead
uses "onion skins". The original design created a layered public-key
structure: each layer contained the address of the next hop and
material sufficient to create the symmetric keys that would be used to
encrypt and decrypt data passing on the established circuit. There was
nothing but layers, with no message or data in the middle---just like
an onion. Anything that emerged from the exit node headed for Bob
would not be encrypted by the onion that built the circuit; it would
be encrypted by the symmetric keys that were distributed via the
onion.  It's true that this is encryption is layered, but there is
something at the middle of it, the traffic to be sent to Bob. We did
sometimes call this 'data onion' because of the layering, but we
called it 'onion routing' because of the circuit-creating data
structure being comprised of nothing but layers.  Tor uses onion
skins, which roughly are one-layer onions, to build circuits. Among
other things, this gives Tor's traffic forward secrecty.  Onions, per
se, were never used in Tor (even though Tor's onion routing ;&gt;)

HTH,
Paul

On Sat, Dec 17, 2011 at 08:40:33AM -0800, Dave Jevans wrote:
&gt; 
&gt; This attach will not work.  Alice's tor client on her computer
&gt; creates a Multi layered encrypted connection, hence the term onion
&gt; routing.  If Alice's connection to the exit node goes through 3 tor
&gt; nodes (eg entry, middle, exit) then the connection is encrypted
&gt; three times with different keys as it enters the entry node EN.
&gt; This decrypts the first layer, and this traffic is sent to the
&gt; middle node.  This node decrypts the second layer of the onion, and
&gt; sends ti to the exit node.  The exit node decrypts the third level
&gt; of onion encryption and forwards to Bob.
&gt; 
&gt; Thus a packet sniffer doing checksums anywhere in between wil Not
&gt; see the same traffic, and will not be able to correlate between
&gt; Alice's packets and those that traverse to Bob, or between any of
&gt; the intermediate nodes.
&gt; 
&gt; 
&gt; 
&gt; On Dec 17, 2011, at 8:25 AM, "Daniel Cohen" &lt;danielc192@gmail.com&gt; wrote:
&gt; 
&gt; &gt; Hi,
&gt; &gt; 
&gt; &gt; I am new to Tor, but after reading about its design, and reading a few research \
&gt; &gt; papers on its vulnerabilities (specifically timing attacks), I had the following \
&gt; &gt; thought: 
&gt; &gt; Suppose Alice is connecting to Bob via Tor, using HTTPS encryption. She sends a \
&gt; &gt; packet to the Tor entry node (call it En). The packet travels through the \
&gt; &gt; network, emerges from an exit node (call it Ex), and arrives at Bob. 
&gt; &gt; Alice =&gt; En =&gt; Tor Network =&gt; Ex =&gt; Bob
&gt; &gt; 
&gt; &gt; Now suppose that Alice's connection is being monitored, as well as a group of the \
&gt; &gt; exit nodes (which are either hostile or having their packets sniffed). When the \
&gt; &gt; encrypted packet leaves Alice on its way to En, it is sniffed, and a checksum is \
&gt; &gt; made of its encrypted payload. The packet then continues through the network as \
&gt; &gt; usual, and emerges from an exit node. 
&gt; &gt; It appears to me that the attacker need only check packets coming out of exit \
&gt; &gt; nodes to see if their payload checksums match that of the packet observed leaving \
&gt; &gt; Alice. Unlike timing attacks, which require a reasonable number of packets to \
&gt; &gt; confirm Alice's identity, this attack would require only one, since checksums \
&gt; &gt; have an almost 0% chance of collision. If a packet with the same payload checksum \
&gt; &gt; as Alice's is discovered, it almost certainly originated from her. 
&gt; &gt; Is this a problem with Tor's architecture? If so, has this issue already been \
&gt; &gt; addressed? 
&gt; &gt; Thanks,
&gt; &gt; 
&gt; &gt; Daniel Cohen
&gt; &gt; _______________________________________________
&gt; &gt; tor-dev mailing list
&gt; &gt; tor-dev@lists.torproject.org
&gt; &gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111219160828</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-12-19 16:08:28-0400</timestampReceived><subject>Re: [tor-dev] Is Taking Checksum of Packet Payloads a Vulnerability?</subject><body>

On Mon, Dec 19, 2011 at 8:54 AM, Paul Syverson
&lt;syverson@itd.nrl.navy.mil&gt; wrote:
&gt;                                                             =A0Onions, per
&gt; se, were never used in Tor (even though Tor's onion routing ;&gt;)

As long as we're doing historical notes, let me amend that to "onions,
per se, were never used in any *released version* of Tor."  It looks
like I implemented the  backend for the onionskin-based circuit
handshake back in May 2003 (svn revision 259, git commit 1eeb3f65fc),
which predates any version of Tor we ever put out a public tarball
for.  So Tor *did* once use onions for circuit setup; just not any Tor
that ever got a public release.

peace,
-- =

Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111221055124</emailId><senderName>Sai</senderName><senderEmail>tor@saizai.com</senderEmail><timestampReceived>2011-12-21 05:51:24-0400</timestampReceived><subject>Re: [tor-dev] Drafting a proposal for mnemonic onion URLs</subject><body>

A couple issues:

1. There's no such thing as "bits per word" without a dictionary, or
better yet, a frequency-sorted dictionary. :-P (See Alex's comments in
https://plus.google.com/u/0/103112149634414554669/posts/FMDg2Vht8sb
for a good idea on this.)

For reference, the OED is ~250k words (~18 bits at most, without
considering frequency).

2. People cannot remember a random ordered set of even four rare
words. Consider for instance that memory competitions involve doing
*exactly that* and that untrained people generally can't retain even a
small number. What people do in competitions, and what I've proposed
in the draft, is remember *scenes*  e.g. something you can state in a
sentence.

Also, you can't use words that people don't know. "Squibbish" might as
well be "kaftorn". Merely being a word is not sufficient; it has to be
something with semantic value. "English-sounding" is useless except
for the very low bar of "can be spoken over a telephone".

This of course constrains the dictionary considerably, such that
assembling even 12 bits (4k) is not completely trivial. But remember,
the point of my proposal is *not* "can you output some random crap
that's word-ish"  la the horrible RFC2289. It's "can you give people
something they'll actually remember".

3. People are not going to remember whether it was, say, 48 or 49 or
84. Numbers are effectively useless for recall. People don't even
think in decimal, they think in very rough logarithmic approximations.
:-P

4. How would you 'keep generating words'? My proposal was that every
hash have a single, canonical phrasal mapping. You would not be able
to change it unless you change your hidden service descriptor. (You
could do that if you're willing to "move" your site, or are making a
new one.)

If you don't have canonical mapping, siteops can't tell people what
their phrasal descriptor is, which means you lose a majority of its
utility for security.

For that matter, how would you ship it without a dictionary? Are you
expecting that most users will already have a common dictionary file?

5. Not having it be in English means you have to support
internationalized domain names (nearly all other languages have
non-ASCII characters). AIUI that's just not technologically up to
speed yet.


I should emphasize that this is *not* a technical problem, it's a
problem of cognitive linguistics. Writing the code is relatively
trivial; it's just a simple parser / generator layer.

- Sai

On Wed, Dec 21, 2011 at 00:16, Nick Mathewson &lt;nickm@alum.mit.edu&gt; wrote:
&gt; On Tue, Dec 20, 2011 at 11:20 PM, Sai &lt;tor@saizai.com&gt; wrote:
&gt;&gt; Howdy all.
&gt;&gt;
&gt;&gt; I would like to make a mnemonic translation method for onion URLs. Not
&gt;&gt; as in a full petname system with registration and so forth, just a
&gt;&gt; "four little words" style way of rendering and entering existing
&gt;&gt; 80-bit hashes in a way that is memorable to not just detect
&gt;&gt; partial-overlap fuzzing attacks but actually memorize and produce the
&gt;&gt; URL directly.
&gt;&gt;
&gt;
&gt; So, the last time I was talking about this (with a grad student whose
&gt; name I have just asked for permission to cite), I came up with the
&gt; following scheme.  Let BW be the number of bits per natural-language
&gt; word; let BH be the number of bits per hidden service identity key
&gt; hash.  Let H() be some hash function.  Represent the onion key
&gt; identity hash as a sequence of BH/BW natural-language words, letting
&gt; each word W represent the first BW bits of H(W).
&gt;
&gt; So if H() is SHA256, and BW is 20, and BH is 80, the hostname
&gt;  bookbind.electrodynamism.unsurnamed.squibbish
&gt; would represent the 80-bit sequence
&gt;  Ht("bookbind") Ht("electrodynamism") H("unsurnamed") H("squibbish")
&gt; where Ht(x) is the first 20 bits of SHA256(x).
&gt;
&gt; (In practice, 80 bits is feeling way too short these days; but that's
&gt; another discussion.)
&gt;
&gt; The main advantages and disadvantages of this idea are:
&gt;
&gt;  + You don't need to ship a shared wordlist with the client software.
&gt;  (That's a good thing, since big dictionaries get annoying fast.)
&gt;  + You don't need to restrict yourself to any particular language; it
&gt; is not English-centric.
&gt;  - If bw is large enough, there will be sequences of bits that are
&gt; not represented as the hash of any particular English word.  (e.g., if
&gt; bw is 32, you are in trouble: no language has 4 billion words!)  You
&gt; can work around this by having your search program generate new
&gt; english-sounding sequences, by using a bigger wordlist or by
&gt; generating keys until you find one whose fingerprint *is*
&gt; representable with words you have.
&gt;  - If you make BW big, you are going to get some pretty obscure words.
&gt;  - Encodings are not unique.
&gt;  + You can get a lot of bits per word.  If you're willing to do stuff
&gt; like "every word in english" x "the numbers 00-99", you can get even
&gt; more.
&gt;  + It scales to more than 80 bits pretty easily.
&gt;  - It doesn't make pretty sentences by default, though you can keep
&gt; generating words till you find something you like the sound of.
&gt;  - We'd need to watch out for words that look equivalent to a human,
&gt; but aren't.
&gt;  / You actually need to write a reasonably good search program.  This
&gt; isn't too hard, and the database it generates isn't too big.
&gt;
&gt; There are other issues and other possible solutions too.
&gt;
&gt; yrs,
&gt; --
&gt; Nick
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111223231702</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-12-23 23:17:02-0400</timestampReceived><subject>Re: [tor-dev] Browser-based proxies for circumvention</subject><body>

On Wed, Dec 21, 2011 at 09:31:52PM -0800, David Fifield wrote:
&gt; A few months ago, Roger wrote about ideas for getting more bridge
&gt; addresses (https://blog.torproject.org/blog/strategies-getting-more-bridge-addresses).
&gt; One of the ideas is to make lightweight bridges that can run in a web
&gt; browser. I and some others have been working on this for a few months. I
&gt; want to promulgate our ideas and code among you developers, and ask for
&gt; your opinions and suggestions.

Hi David,

Great stuff. To give it a bit more exposure, shall we set you up with
a Tor blog account and you can post this there too? Mail me a preferred
username and I'll get that started.

And like everybody else here, please put my vote in for switching to
another nat-punching protocol that is more open. Plus a websocket or
javascript variant if that is starting to look feasible -- I feel pretty
dumb telling everybody how dangerous flash is, but then also telling
them about this cool flash bridge idea. :)

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111223233953</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2011-12-23 23:39:53-0400</timestampReceived><subject>Re: [tor-dev] [flashproxy] Not running using gnash</subject><body>

On Fri, Dec 23, 2011 at 01:00:01PM -0300, Mauricio Pasquier Juan wrote:
&gt; On Thu, Dec 22, 2011 at 07:31:59PM -0800, David Fifield wrote:
&gt; &gt; On Thu, Dec 22, 2011 at 03:38:29PM +0100, Okhin wrote:
&gt; &gt; &gt; Hello,
&gt; &gt; &gt; 
&gt; &gt; &gt; I was trying to run flashproxy using gnash following the RTMFP part of
&gt; &gt; &gt; the tutorial located here:
&gt; &gt; &gt; https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/README
&gt; &gt; &gt; 
&gt; &gt; &gt; I do not use the gnash-plugin embedded in a browser, but the CLI tool
&gt; &gt; &gt; gnash packaged with debian (and invoking it like this, as a standard
&gt; &gt; &gt; user: gnash swfcat.swf -p client=1 -p debug=1
&gt; &gt; 
&gt; &gt; Thank you for testing this and for the thorough report. Unfortunately
&gt; &gt; I'm not surprised that it doesn't work with Gnash. I don't think Gnash
&gt; &gt; has some of the features we use, and probably doesn't have RTMFP, which
&gt; &gt; has only been partially reverse-engineered in another project. Some log
&gt; &gt; messages suggest this:
&gt; 
&gt; If the only reason to use flash is RTMFP, maybe it can be replaced with this
&gt; technique: http://samy.pl/pwnat/ (if I didn't misunderstood the architecture of
&gt; flashproxy)

Yes, the only reason to use Flash on the client is for RTMFP, and the
only reason to use RTMFP is to get across a NAT. I looked a pwnat and
didn't think it would work in this case, because a flash proxy doesn't
have raw socket access to send a Time Exceeded message. I could be
working under incorrect assumptions, though.

Long ago I wrote a very crude NAT puncher that doesn't require an
intermediary. It uses birthday collisions between randomly generated UDP
port numbers.
https://gitweb.torproject.org/flashproxy.git/blob/9c471b4b99d07c8db197d15fe6eb4d37d85b0ea6:/nat-birthday.py
 We gave up on it because (1) it requires both client and server to know
each other's address in advance, (2) it takes a few hundred packets, and
(3) we don't have access to UDP sockets anyway, except through
abstractions like RTMFP.

&gt; Anyway, if there is some javascript code to check, I'd like to help with that
&gt; development.

There's no JavaScript yet, but we want to port the ActionScript (which
is similar). These are the primary source files:
https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/swfcat.as
https://gitweb.torproject.org/flashproxy.git/blob/HEAD:/ProxyPair.as
I don't have any experience with JavaScript network programming yet, but
porting doesn't look too hard, as long as you get reasonable event
callbacks for things like reads.

David Fifield
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111231135221</emailId><senderName>Max Maass</senderName><senderEmail>0maass@informatik.uni-hamburg.de</senderEmail><timestampReceived>2011-12-31 13:52:21-0400</timestampReceived><subject>[tor-dev] Some naive Ideas for Bridge Distribution</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi there,

first off, I am only a third-semester computer science student from
germany, so most likely, you will already have thought about these
Ideas and discarded them. The reason I am writing them anyway is that
there is still the small chance that it might help, and that I would
like to learn why the other ideas won't work.

So, during 28C3 I heard the TOR-Talk and it was mentioned that you are
looking for ways to distribute Bridges that are harder to ban by the
GFW, and it was mentioned that you are in need of more changing IPs.
It was also mentioned that the GFW is following up every SSL
connection and is trying to "speak TOR" on them to identify Bridges.

So, some ideas:
- - You mentioned that these follow-up connections are of an old version
of TOR. That version doesn't have any blatant security holes, does it? ;-)

- - I think you are already doing IP forwarding for bridges to gain some
more IPs. Why not give us a small tool we can run on our PC / Server
that is doing this forwarding. I think you can get many people to run
this tool, and maybe you can even build a flash version of it, like
the flash TOR Node you (or someone else, I don't remember) did a few
weeks ago.

- - You could also use HTTP Requests for these forwarders, to confuse
the GFW a bit if it tries to follow them up.

- - And, if you want to annoy them even more, you can maybe make the
first response the default "I don't know what you are talking about"
HTTP Response, so the GFW get's a lot of false positives if they
follow up every SSL connection (Because the other Servers they are
contacting will most likely will throw this Response if someone tries
to contact them with the TOR-Version of HTTP Requests).

- - Make it easier to host a bridge. I tried it a while ago and it did
not work for me, for some reason (I don't remember anymore what the
reason was, but I always got some weird error message, and the
internet could not help me with it. I might try again now, though).
For example: Work with the guys from DD-WRT or OpenWRT to add a
TOR-Module to the Router firmware. If it only takes one checkmark to
create a TOR Node / Bridge, more people will be likely to do it, and
most routers are online 24/7, as opposed to maybe 10 hours a day or
less if you use a regular PC.

- - In addition to that: A ARM-Version of TOR that runs on Network
Attached storages (For example: Synology gives the users the ability
to SSH into their Box and install a packet manager). I have seen that
you are already developing a ARM-Version, but I have also read that it
does not work properly on Synology Hardware. I would be willing to
test any ARM-Release for you on my DS211j.

So, I hope that I have not wasted your time completely, and I am
looking forward to being told why these things won't work (Or that you
are already working on implementing them).

Keep up your great and important work!

Max
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.17 (MingW32)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJO/xOVAAoJEDxYz0BvOJH8E78H/AuS1gSx6Bb7tP3JeqHqZVL0
j0tDSTqW9554CmGA9TmSe5OWc+tbkDc0ULrmr2smNucE8NOT/ylCEr5Ck/JR7ra1
nwILRzrjVwV5MyOrOgtsAce57+K/SFQCBo4N+mdhOOIMfcMnjxDWr3LVFkdO0PQ4
/eP2Zfuj7aDj3nHDiG8ipqnYlfg+bCPxEcx93dHyHqf8LIuPfYBTVp7v6T+ntLKI
q1HI3INqvjpMdcbOtbPSAXqXci6kIK2Y6v5gfXD5v3qI0LDW81wL5mFV5vUvRT0p
cUc8AxYoxjsK7E+JXGBmihdrGgO6GXxfyRIcR5eHZCHRqRA78wPP0fBIj0CwrnY=
=xyJ5
-----END PGP SIGNATURE-----
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111101012558</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2011-11-01 01:25:58-0400</timestampReceived><subject>[tor-dev] Draft sketch document with ideas for future crypto ops</subject><body>

Here's an early draft document trying to sketch out the parameters for
migrating to better crypto ops and designs in the future.

Comments are invited, even comments of the form "you will need to be
much more specific here before I can say anything sensible."

This is proposals/ideas/xxx-new-crypto-sketch.txt in the torspec repository.



Title: Design sketch for new crypto ops
Date: 31 Oct 2011
Author: Nick Mathewson

0. Overview

  The point of this document is to discuss what crypto we ought to be using.
  See "Initial Thoughts on Migrating Tor to New Cryptography" from last year
  for general guidelines and principles.

  In broad strokes, the parts of our crypto are:

    IDENTITY KEYS AND FINGERPRINTS
       Addressed here in Section 2.
    LINK CRYPTO (TLS) --
       Addressed in proposals 176, 184.  We say a little here in section 5,
       though.
    CREATE/EXTEND CRYPTO --
       Addressed in xxx-ntor-handshake.txt and rransom's EXTEND draft at
       [*] and subsequent discussion on the tor-dev mailing list.  Not
       considered here.
    RELAY CRYPTO
       Addressed here in Section 6.
    DIRECTORY SYSTEM
       Addressed here.
    HIDDEN SERVICE SYSTEM
       Addressed in a forthcoming document by rransom.

[*] https://lists.torproject.org/pipermail/tor-dev/2011-March/002547.html

1. Base algorithm choice

  There seem to be two main candidate algorithms for signatures: RSA
  with big keys (hereinafter "RSA&gt;1024"); and Ed25519, which is DSA with
  the sharp edges filed off on an Edwards curve related to DJB's
  Curve25519.  We can look at other ECC groups too.  {But see ECC
  Notes in 1.1 below.}

  FOR DIFFIE-HELLMAN: Curve25519 seems like a decent choice; failing
  that, one of the NIST P-groups.  Failing that, DH on Z_p with big
  groups (hereinafter "DH&gt;1024").  {But see ECC Notes in 1.1 below.}

  FOR A HASH FUNCTION: SHA256, switching to SHA3 in 2012 when it comes
  out.  It might be worthwhile waiting for SHA3 in most places and
  skipping over the SHA256 stage entirely.

  FOR A STREAM CIPHER: AES-CTR is in one sense a conservative choice
  inasmuch as AES is well-analyzed, but AES's well-known issues with
  cache-based timing attacks are pretty worrisome.  We can mitigate that
  some by using random secret IVs for AES-CTR, so that we will be
  encrypting neither attacker-chosen nor attacker-known plaintext with
  our AES cipher, but that's a bit kludgy.  There are also supposed to
  be time-invariant implementations that use Intel's AESNI instructions
  where available, and time-invariant implementations that use
  bit-slicing.

  Salsa20 is what rransom likes these days, but IMO we aren't competent
  to tell whether it looks good or not; the existing attacks against it
  don't look like very bad news to me, but who knows whether it's
  getting enough attention that we can read.  See also ChaCha; see also
  the other eSTREAM winners/finalists; see also SHA3 if the SHA3 winner
  specifies a way to use it as a stream cipher, or specifies an
  underlying stream/block cipher.

  If we're feeling cautious, we could run two independently-keyed stream
  ciphers and xor their streams together.

  FOR A RANDOM NUMBER GENERATOR: We currently use OpenSSL seeded with
  RAND_poll and with platform entropy.  OpenSSL uses a message-digest-
  based algorithm from SSLeay (See http://linux.die.net/man/3/sslrand
  for the ugly details.)  The platform entropy management can be messy,
  obscure, or both.  I suggest that:

    * We should seed our PRNG with more entropy sources if we can find
      some promising code with an appropriate license
    * Instead of just using OpenSSL's PRNG, we should use OpenSSL's
      MD-based PRNG xor'd with some other good PRNG.  (Fortuna,
      maybe. Is there a combine operation better than xor? See also SHA3
      if the SHA3 winner is one that specifies a PRNG mode of
      operation.)
    * We should consider splicing this combined-stream PRNG into OpenSSL
      as the RNG it uses for SSL and key generation.
    * We should re-seed the RNG before and after very sensitive
      operations, like private key generation.

1.1. ECC notes

  ECC is the brave new[*] crypto of the future!  It's faster[**] than
  doing crypto in Z_n (as we do for RSA and DH now) for equivalent
  levels of security, and the resulting outputs are much shorter.

  As near as I can tell as a layman, Certicom is muddying the waters as
  much as possible wrt claiming that it's nigh-impractical to deploy ECC
  without licensing their patents.  This is rather like the silliness
  that PKP used to pull back in the day, where they claimed that their
  patents covered not only the existing public key cryptography
  algorithms, but also the very idea of public key cryptography itself.

  DJB claims that for every patent he's aware of, either that patent
  doesn't cover his code, or that patent is invalid because of prior
  art.  I'm not going to try to evaluate these claims, since I'm not
  supposed to be reading patents for typical "let's avoid the appearance
  of knowing infringement" reasons.  But before we dive into the world
  of ECC, we should see if we can ask any friendly patent attorneys and
  ECC experts for a second or third opinion here.

  I note in passing that nearly all of the patents that DJB mentions in
  his list would appear to expire over the next 12 months or so.

  Additionally, there are ECC groups out there less fast than DJB's, but
  more widely available and analyzed.  We should consider some of those
  too.

  One final issue to investigate is whether using these algorithms will
  make any major free software distribution decide not to include us.  I
  seem to recall seeing that one or two of the big ones had at one point
  decided to ship OpenSSL only with ECC disabled, either because of real
  patent concerns, or because of an opinion that the Certicom license
  for ECC use in TLS was problematic for free software, or something
  like that.  We should check that out.

  [*] Actually, it's older than onion routing, and older than some
  members of the Tor Project.

  [**] Actually, because of the common practice of choosing a small-ish
  prime value (65537) for e in RSA, RSA public key operations can be a
  little faster than equivalent-security ECDH or ECDSA operations.  The
  private key operations in RSA are still much much slower.

2. New identities

  Identity keys and their fingerprints are used:
    - To sign router descriptors.
    - To identify nodes in consensus directories.
    - To make sure we're talking to the right node in the link handshake.
    - To make sure that the extending node is talking to the right next
      node when sending an extend cell.
    - To identify particular nodes in the hidden service subsystem.
    - To identify nodes in the UI in various places.
    - Internally, to identify a node uniquely in the codebase.
    - To determine which part of the circuit ID space to use on a Tor
      instance's links.

2.1. New identities, option 1: "RSA&gt;1024, slow migration"

  In this option, we use RSA for identity keys indefinitely.  Nearly all
  operations done with an identity key are signature checking; signing
  happens only a few times an hour per node even with pathological
  cases.  Since signature checking is really cheap with RSA, there's no
  speed advantage for ECC here.  (There is a space advantage, since the
  keys are much smaller.)

  The easiest way to migrate to longer identity keys is to tell all Tors
  to begin accepting longer identity keys now, and to tweak all our
  protocols so that longer RSA identity keys are understood.  We should
  then have a pair of parameters in the consensus that determines the
  largest and smallest acceptable identity key size in the network.
  Clients and servers should reject any keys longer or shorter than
  specified.  Once all versions of Tor can accept long identity keys, we
  raise the maximum size from 1024 to somewhere in the 2048-4096 range.

2.2. New identities option 2: "RSA&gt;1024, faster migration"

  In this option, we use RSA for identity keys indefinitely as above.
  But we allow nodes to begin having longer identities now, even though
  older Tors won't understand them.  This implies, of course, that every
  such node needs to have at least 2 identities: one RSA1024 identity
  for backward compatibility, one RSA&gt;1024 identity for more secure
  identification.

  We would have these identities cross-certify as follows: All keys
  would be listed in the router descriptor.  RSA&gt;1024 keys would be
  called something other than identity-key, so as not to confuse older
  clients.  A signature with the RSA&gt;1024 key would appear right before
  the current RSA1024 signature.  This way, signed material would
  include both keys, and would be signed by both keys.

     [In other words, descriptors would look something like:

      router foo...
      ...
      identity-key
      -----BEGIN RSA KEY-----
      1024-bit RSA key here
      -----END RSA KEY-----
      ext-identity-key
      -----BEGIN RSA KEY-----
      3072-bit RSA key here
      -----END RSA KEY-----
      ...
      ext-signature
      -----BEGIN SIGNATURE-----
      signature of everything through "ext-signature\n",
      using the long key
      -----END SIGNATURE-----
      router-signature
      -----BEGIN SIGNATURE-----
      signature of everything through "router-signature\n",
      using the short key
      -----END SIGNATURE-----

     ]

  See "UI notes" in the "new fingerprints" section below for some of the
  implications of letting nodes have multiple identity keys.

  We'll need to advertise these new identities in consensus directories
  too; see 4.2 below for more info there.

2.3. New identities option 3: "RSA&gt;1024 and/or Ed25519, faster migration"

  As in option 2 above, but new keys can also be Ed25519.  If we expect
  that not all installations will allow Ed25519 (see "ECC Notes",
  section 1.1), we'll need to say that every server with an Ed25519 key
  must also have an RSA&gt;1024 key.

2.4. Implications for current use of identity keys

  Let's review our use of identity keys again and make sure that we can
  handle all of them with the ideas above.

    - To sign router descriptors.

  We discussed this in 2.2.

    - To make sure we're talking to the right node in the link handshake.

  The current v3 link handshake can handle presenting multiple identity
  certificates in the CERT cell.  We should consider ourselves to be
  connected to a node with identity X if _any_ of the identity
  certificates that it presents in its authenticated CERT cell has
  identity X.  To handle EXTEND cells correctly, we should verify every
  identity we can.

    - To make sure that the extending node is talking to the right next node
      when sending an extend cell.

  The new extend cell format needs to allow the client to tell the
  extending node about some identity for the destination node that the
  extending node will be able to understand.  This is a capability of
  the extending node that the client needs to be able to check. (Also,
  the extend cell needs to hash that identity in a form the extending
  node can understand, but that's a fingerprint issue.)

    - To determine which part of the circuit ID space to use on a Tor
      instance's links.

  We can continue to use RSA1024 identity key comparison here by
  default.  We can also use some other parameter of the v3 handshake, or
  introduce a new link protocol where if the initiator authenticates,
  the initiator always gets the low circIDs and the responder always
  gets the high ones.

    - To identify nodes in consensus directories.
    - To identify nodes in the UI in various places.
    - Internally, to identify a node uniquely in the codebase.

  See sections 3 and 4 below.

    - To identify particular nodes in the hidden service subsystem.

  Out of scope.

2.5. Migrating away from short ID keys entirely

  Eventually, no version of Tor that requires 1024-bit identity keys will
  remain.  When that happens, we should stop using them entirely.  That
  means that if we take any path other than the "slow migration" path of
  2.1, we'll need to make everything that looks at a node's identity
  also accept nodes with _only_ a RSA&gt;1024/Ed25519 identity.

  At the directory service level, we should have an option to allow
  nodes without RSA1024 identity keys (off until all clients and nodes
  accept new identity keys).

2.6. Selective correctness attacks

  For any scheme based on having multiple signature types on a router
  descriptor or other document, an attacker could mount a partitioning
  attack by making a document which older clients will accept but newer
  clients will reject.

  It's easy to prevent this at the consensus step: directory authorities
  MUST NOT accept any descriptor unless all clients will be able to
  verify it.

  For bridge descriptors, we need to investigate more carefully.

3. New fingerprints

  Right now we compute fingerprints by taking the SHA1 hash of an ASN1
  encoding of the RSA1024 identity key.  We encode this in hex almost
  everywhere, and sometimes prefix it with a $.

  I propose that fingerprints of the future be determined by taking a
  digest using SHA256 or SHA3 of:

      "Hash Algorithm Name", "Key Type Name", encoded key

  When representing these internally, we should include the hash
  algorithm that was used.  When representing them in the UI, we should
  use the notation %b64, where b64 is a base-64 encoding, omitting the
  trailing =s.

  (Other plausible characters to use are @, ?, +, ~, =, etc.  I like %,
  but can be persuaded.  Bikeshed bikeshed bikeshed.)

  Since 43 base-64 characters is enough to represent a 256-bit digest,
  with 2 bits left over, I propose that the b64 value encode

      hh | D(hash algorithm name, key type, encoded key)

  where hh is a 2-bit value, with one of the following values:

      00 -- sha256
      01 -- sha3
      10 -- to be determined
      11 -- reserved.

  We should investigate in the interface whether it's plausible to allow
  a prefix of a node ID where the full ID would otherwise be required.
  That seems risky for short prefixes, though.

3.1. How many fingerprints is that anyway?!

  Suppose that we allow sha256 and sha3 as hash algorithms, and we allow
  each node to have 3 identity keys: one RSA1024, one RSA&gt;1024, and one
  ECC.  Then we would have 7 fingerprints (6 plus the legacy
  SHA1(RSA1024) fingerprint), for a total of 20+6*32==212 bytes per
  node.

  It's not a horrible problem to accept them all in the UI, but the UI
  isn't the only place that needs to know fingerprints.  Instead, let's
  say that RSA1024 identities are only identified with SHA1 hashes.
  This limits our fingerprint load to a more manageable 20+32*2 == 84
  bytes per node.  Still not great, though.

3.2. What does this imply for the UI?

  In the UI we'll lose the property that no node has more than one
  fingerprint: I do not believe that this actually hurts us.

3.3. Implications for directory information

  Clients must know a hash for each node's identity key, or else they
  can't make an authenticated connection to the node or tell ORs how to
  extend to the node.

  This means that if client Alice wants to connect to node Bob, Alice
  must have a fingerprint of Bob's ID key such that she understands the
  ID key type and the fingerprint algorithm.  If Alice wants to extend
  from Bob to Carol, she must have a fingerprint of Carol's ID key such
  that Bob understands the ID key type and the fingerprint algorithm.

  So for every node, Alice must not only know a fingerprint that *she*
  can use for that node, but also a set of fingerprints such that every
  node can understand at least one fingerprint in the set.

  This implies a proliferation of fingerprints!  We should tread
  carefully here.  To prevent proliferation, the easiest solution is not
  to add too many new types and to have a good plan for retiring older
  types.

3.4. Implications for EXTEND cells

  As mentioned in 3.3, when a client Alice tells node Bob to extend
  to node Carol, she needs to give Bob a fingerprint for Carol that Bob
  will understand: one where Bob understands the digest algorithm, and
  understands the identity key type.

  There are two ways we can do this:

    1) Alice's EXTEND cell contains every fingerprint for Carol that
       Alice knows about.  Bob treats the cell as valid if every one he
       can verify is correct.

    2) Alice knows which fingerprint types Bob understands (either via
       his version, or something else in his directory info).  She
       selects a fingerprint for Carol using the best one of these
       types.

  The first seems more robust to me, if we have space for enough bytes.
  If we proliferate too many types, though, we'll need to do the second.

4. Directory changes

4.1. Better cross-referencing

  In some places, directory objects cross-reference one another by SHA1
  hash.  They should use a better hash algorithm instead.

  This does make problems in a few cases.

  Router descriptors and extrainfo descriptors:

     One problematic case is in determining node families.  If node A
     and node B want to list each other as being in the same family,
     they need to do so in a way that clients can interpret.  That could
     mean listing SHA1-RSA1024 fingerprints so old clients understand,
     AND new fingerprints for security. (But *that* could create
     interesting partitioning attacks wherein your family looks
     different depending on who's looking.)

       Solution: we need to move the responsibility for combining node
       families into the consensus voting process, so clients don't
       need to understand the cross-reference types themselves.

     Another case is in certifying extrainfo documents from descriptors.
     For that, we can list multiple extrainfo digests, either on the
     extrainfo line, or on additional lines.

  Voting and consensus documents:

     Adding more fingerprints in votes isn't a problem; votes are a tiny
     fraction of authority bw usage.  Adding more hashes is easy.

     For consensus documents, we ought to have flavors that you can
     download depending on what set of fingerprint types you
     understand.

     For integrity purposes, consensuses can refer to microdescriptors
     or descriptors by any digest type that the client understands.  But
     for downloading purposes, the digest type must be one that
     directory caches also support: see 4.4.

4.2. More fingerprints

  Because extending from node A to node B requires that we have node B's
  fingerprint in a way that node A will understand, it is not enough to
  get a set of identity fingerprints for each node in the format that
  the client likes best -- see 3.3 and 3.4 above.  So every flavor of
  consensus we serve needs to include a node identity in a format the
  client understands, and node identities in formats such that every
  node will understand at least one.

4.3. An option: compound signatures on directory objects

   In Tor 0.2.2.x and later, when we check a signature on a directory
   object (not including hidden service descriptors), we only look at
   the first DIGEST_LEN bytes of the RSA-signed data.  Once 0.2.1.x is
   obsolete, or on any types of signatures not checked in 0.2.1.x, we
   can use the rest of the space.  (We're using PKCS1 padding on our
   signatures, which has an overhead of 11 bytes.  Signing a SHA1 hash
   with a 1024-bit key therefore leaves 128-11-20==97 more bytes we
   could use for a SHA2 or a SHA3 hash.)

4.4. Downloading by digest

   We should have directory caches support downloading objects by more
   hash types.  Right now, descriptors are downloaded by their SHA1
   hashes and microdescriptors by their SHA256 hashes.  This is okay for
   now, but once SHA3 is out, we should support downloading all of these
   by SHA3 digest.

5. Link crypto changes

  Currently we use TLS.  That's fine.

  We should however look to longer link keys, bigger DH groups, etc.

  Once TLS versions 1.1/1.2 are available in OpenSSL, we should move to
  use them, I think.  We should also look into how quickly we can
  deprecate TLS 1.0 and SSL &lt;= 3 usage.

6. Relay crypto changes

  There are a few things we might want out of improved relay crypto.
  They include:
   - Resistance to end-to-end bitwise tagging attacks.
   - Better resistance to malleability.
   - If using counter mode, no block-cipher operations on any value
     known to the attacker.

  I'll try to provide these in increasing order of difficulty.  None of
  these is necessarily correct; I should look for a security proof or a
  better construction for any that we seem likely to use.

  Rationales: Our existing malleability resistance is a kludge.  Doing
  no block-cipher ops on attacker-known values increases our security
  margins a little.  Our arguments about tagging attacks hold that an
  attacker who controls both ends has plenty of ways to win even if
  tagging attacks are foiled; nonetheless, most of these ways are
  technically slightly more difficult than xor-based tagging, and it
  could be useful to boost our defense-in-depth a little bit, just in
  case other active end-to-end attacks turn out to be harder than we'd
  thought.

6.1. Option 1: Use AES-CTR in a less scary mode

   When doing key expansion, in addition to establishing Kf, Kb, Df, and
   Db, also establish IVf and IVb.  Use the current relay crypto, except
   instead of starting the counters at 0, start them at IVf and IVb.
   This way, an attacker doesn't have any known plaintexts to work with,
   which makes AES a little more robust.

6.2. Option 2: As 1, but tagging attacks garble the circuit after one block.

   Keep an HMAC of all previously received encrypted cells on a circuit.
   When decrypting a cell, use this HMAC value to determine the first 64
   bits of the counter; increment the low 64 bits of the counter as
   usual.

   This way, if an adversary flips any bits before passing the stream
   through an honest node, no _subsequent_ block will be recoverable.

   To prevent any part of the stream from being re-used, close any
   circuit if the low 64 bits of the counter would ever wrap (that is,
   around 295 million terabytes).

   (If we're using a stream cipher with fast re-key, then we can just
   have the key used for each block be an HMAC of all previously
   received ciphertext.)

6.3. Option 3: As 1, but tagging attacks garble the circuit in the same block.

   Use a large-block cipher mode, such as BEAR or LIONESS (depending on
   whether we need a PRP or SPRP).  Base the key material for each block
   on an HMAC of all previous blocks' ciphertexts.

   This way, if an adversary makes any alteration in a block, that block
   and all subsequent blocks will be garbled.  It's more expensive than
   2, though, especially if we need to use a LIONESS construction.

   {I considered IGE here, with a trick where odd-numbered nodes on a
   circuit start from the front of the block and even-numbered nodes
   start from the end, but it didn't seem much better.  We should
   investigate relative performance, though.}

6.4. Option 4: Shall we have middle nodes be able to fast-stop bad data?

   In all the above options, if a cell is altered, the middle node can
   at best turn that cell and the rest of the cells on the circuit into
   garbage, which the last node won't deliver (if honest) or can't
   deliver (if dishonest).

   Might we prefer to do as in mixnets, and have nodes kill circuits
   upon receiving altered cells?

   It's not such an obvious improvement.  Including more MACs is more
   expensive in per-cell overhead.  The attacks that we would foil this
   way but not with Option 3 are not so much better than the the passive or
   timing-based-active end-to-end attacks that would still remain.

   Consider that if option 3 is in place, an end-to-end attacker who
   wants to do a tagging attack at one node can garble the rest of the
   circuit and see if the output is garbled at the exit node.  But such
   an attacker could just as easily close the circuit at one of those
   nodes and watch for a corresponding close event, or even better --
   simply pause traffic on that circuit for a while and watch for a
   corresponding gap at the exit.  The only advantage of the garbling
   attack would be that garbled cells are presumably rarer than circuit
   closes or traffic pauses, and thus easier to use to distinguish
   target circuits.  But that's still questionable: the other attacks
   win fine, and the pause attack doesn't risk detection as much.

   So why might we want to do this?  First, the overhead doesn't need to
   be as bad as you might first expect (see below).  Second, it would be
   nice to increase the security margin as much as possible: "attacks
   only get better".

   So let's figure out how it would look.

   To do this one, we'd want to have outgoing and incoming circuits
   treated differently.  Incoming cells would get decrypted as in 1
   above, except that we'd have a MAC on them.  For outgoing cells,
   each node would check that the first N bytes of the cell
   match a MAC of all data seen so far, *including the rest of the
   cell*.  They'd then remove the first N bytes, re-pad the cell
   with bytes from a PRNG, and decrypt the resulting re-padded cell.
   (This is basically how mixmaster works, and how mixminion works in
   the common case.)

   The space overhead here is kind of large: N bits per cell per node.
   In the most paranoid case, if we used 256-bit HMACs on 3-node paths,
   that's 96 bytes per cell, which is more than 20% of the total length.
   But we can probably do better if we let the CREATE operation also
   tell the node some N to check.  For example, the first node doesn't
   need to check any bits.  The second and third nodes could check 64
   bits apiece; that only has 16 bytes overhead total, and high
   probability of catching any changes. (Birthday attacks don't matter
   here, and an attacker who mounts this attack for long enough to
   accidentally find a 64-bit MAC will break so many circuits in the
   process as to become totally unreliable.)

   All of this leaks the path lengths and position on the path to
   various nodes.  We might open ourselves up to partitioning attacks if
   different clients choose different numbers of bits.  What's more, we
   might leak the length of the path to the last node by how much junk
   there is at the end of the cell.  So we'd need to be careful!

   Here's a simple construction for this format, to be concrete:

     The CREATE operation's KDF produces the following outputs:
           Kf, IVf  (stream cipher key and IV for forward direction)
           Kb, IVb  (stream cipher key and IV for reverse direction)
           Mf       (MAC key for forward direction)
           Mb       (MAC key for reverse direction)
           SEEDf    (PRNG key for forward direction)
     And it also sets the following user-selected parameter:
           MACBYTESf (an integer between 0 and 32 inclusive)
           MACBYTESb (an integer between 0 and 32 inclusive)
           CANEXIT   (boolean: can we exit from this hop?)

     Let Kf[i], Mf[i], etc denote the parameter Kf, Mf, etc as shared
     between the client and the i'th node in its circuit.

     Relay cells sent towards the client have the following plaintext
     format:
         Body:
           Content:
             Relay Command [1 byte]
             StreamID      [2 bytes]
             Length        [2 bytes]
             Data          [Up to CELL_DATA_LEN-5-MACBYTESb bytes]
             Padding       [randomly generated as needed to fill the
                            cell]
           MAC(All previous encrypted content + encrypted content,
                                  Mb)[:MACBYTESb]   [MACBYTESb bytes]

     The originator of the client-bound cell encrypts the content with
     the next part of its Kb,IVb stream, then appends the MAC.

     Non-clients receiving a client-bound relay cell encrypt the entire
     cell body, MAC included, with the next part of the stream cipher
     that was keyed with Kb,IVb.

     When the client receives a relay cell body, it iteratively does:

       For node i in circuit from 1..N:
           Let cells_i = all previous cells which we previously decided
              were from node i, or relayed by node i,
           and let cellbody = the body of the cell, except for the last
              MACBYTESb[i] bytes,
           and let cellmac = the last MACBYTESb[i] bytes of this cell.

           If cellmac is nonempty, check wither cellmac = mac_received,
           where mac_received is the first MACBYTESb[i] bytes of
           MAC(cells_i | cellbody, Mb[i]). If so, this cell is from node
           i.

           If this cell is from node i, add cellbody to cells_i, then
           decrypt cellbody using the stream keyed with Kb[i],IVb[i].
           Act on it as a relay cell.

           Otherwise add the entire cell to cells_i, and decrypt it, MAC
           included, with the stream keyed with Kb[i], IVb[i].

       If no node sent this cell: it's junk and somebody is probably
       messing with us!  Destroy the circuit.


     When the client *sends* a cell outbound to node N:

         Let cells[i] start at "" for all i in 1...N initially, and get
         updated as below.

         Let MACLEN = SUM(MACBYTESf[1...N])

         Let Body =
             Relay Command [1 byte]
             StreamID      [2 bytes]
             Length        [2 bytes]
             Data          [Up to CELL_DATA_LEN-5-MACLEN bytes]
             Padding       [randomly generated,
                            CELL_DATA_LEN-5-MACLEN-len(Data) bytes]

         Let PAD[i] = the next MACBYTESf[i] bytes from the PRNG keyed
         with SEEDf[i], for i in 1...N

         Let STREAM[i] = the next CELL_DATA_LEN bytes of
           the stream keyed by Kf[i],IV[i], for i in 1...N

         Let PADSEEN[1] == ""

         For i in 2...N:
             Let L = len(PADSEEN[i-1]) + len(PAD[i-1])
             Let PADSEEN[i] = (PADSEEN[i-1] | PAD[i-1]) xor
                              STREAM[i-1][CELL_DATA_LEN-L:]

         For i in N down to 1:

            Let Encbody = Body xor STREAM[i][:len(Body)]
            Let extra = "RECOGNIZED" if i == N, "OK" otherwise
            Let cells[i] = cells[i] | Body | PADSEEN[i]
            Let M = MAC(cells[i] | extra , Mf[i])

            Let Body = M[:MACBYTESf[i]] | EncBody


     To receive an outbound cell:

         Let M be the first MACBYTESf bytes of the cell, let REST be the
         rest of the cell, and let "cells" be all previous cells on this
         circuit.  If CANEXIT, and M = MAC(cells|rest|"RECOGNIZED",
         Mb)[:MACBYTESf], and MACBYTESf &gt; 0, this cell is for us.  If M
         = MAC(cells|rest|"OK", Mb)[:MACBYTESf], this cell is not for
         us, but is valid.  Otherwise, destroy the circuit.

         Let PAD = the next MACBYTESf[i] bytes of the PRNG keyed with
         SEEDf, and decrypt REST | PAD using the stream cipher keyed
         with Kf,IVf.  If this cell is for us, act on it as a relay
         cell.  Otherwise, relay it.

     ANOTHER VARIANT:

         If we restrict MACBYTESf values to range 0..HL/2, where HL is the
         length of the MAC output, we can replace
           MAC(x | "RECOGNIZED")[:MACBYTESf] and MAC(x | "OK")[:MACBYTESf]
         with
           MAC(x)[:MACBYTESf] and MAC(x)[HL-MACBYTESf:]

     PICKING MACBYTESf,MACBYTESb.

         We don't need to worry about birthday attacks:

            Because we're using a MAC, only the parties who are making
            the MACs could try to do a brute-force search for a
            collision, but they have no reason to do so.

            If a collision occurs accidentally, an adversary can't
            substitute an earlier-seen cell for a later one with the
            same MAC, since the MAC covers not only the cell, but all
            previous cells on the circuit.

         So 16 bytes is about the most we should ever do, given our
         usual security parameters.  Let me moot the number 8 for
         MACBYTESb.

         For outbound cells, for any hop we can exit from, choosing
         MACBYTESf=6 gets us the current security level.  For the first
         hop, assuming we don't exit from it, choosing MACBYTESf=0 is
         totally safe, since the link crypto guarantees that nothing was
         corrupted on the way.

         In general, to prevent an end-to-end tagging attack, it seems
         sufficient to do something like setting MACBYTES=8 for the last
         hop, and MACBYTES=8 for one hop in the middle.

     OTHER VARIANTS:

         Can we combine this approach with one of the approaches in 2 or
         3 above to ensure that if corrupt data passes (because of our
         use of truncated HMACs) it still corrupts the stream?

         Can/should we use GCM or something here instead of separate
         encrypt/hmac operations?  It doesn't seem that GCM per se would
         apply without some tweaking, which we probably do not have the
         expertise to do.

    OVERHEAD NOTES:

         When computing additional overhead with this method, note that
         it lets us replace the old 4 byte "digest" field and the 2 byte
         "recognized" field.

         I note in passing that we need at most 9 bits for the length
         field, and at most 6 bits for the command field, yet we're using a
         total of 3 bytes for those 15 bits.  That's an opportunity to
         save another byte.

ACKS

   Lots of the good ideas and concerns here are due to Robert Ransom.

   Michael Stone helped some with "relay option 4" above.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111101060824</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 06:08:24-0400</timestampReceived><subject>[tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

In reference to:
https://lists.torproject.org/pipermail/tor-dev/2011-November/002999.html

&gt;  FOR A HASH FUNCTION: SHA256, switching to SHA3 in 2012 when it comes
&gt;  out.  It might be worthwhile waiting for SHA3 in most places and
&gt;  skipping over the SHA256 stage entirely.

The AES contest resulted in a cipher that was much faster than 3-DES
and probably safer as well.

It is looking like the SHA-3 contest will result in a hash function
that is slightly slower than SHA-256, and not obviously safer either!

There are some details about the performance issue: the most efficient
SHA-3 candidates are faster than SHA-256 on large, expensive, powerful
x86_64 servers, and they are faster on long messages (more than a
couple thousand bytes). This almost certainly doesn't matter to the
tor project! (Nor, I suspect, to almost anyone else.)

I'm guessing (sorry for my ignorance about these important facts) that
tor uses secure hashes in two ways: first as the "nails" holding the
crypto together, such as in commitments, key-derivation, HMAC, and so
forth, and second to integrity-check the bulk data in chunks that are
approximately "packet sized" -- a few thousand bytes. On a powerful
x86_64 server for 4096 bytes [1], the most efficient SHA-3 candidate
(Blake-256) takes about 33,000 cycles and SHA-256 takes about 73,000.
So the difference is about 40,000 CPU cycles. Assuming that all of
this is done on a single core of a 3.4 GHz chip, that means SHA-256
takes about 12 microseconds longer to hash this 4096-byte packet.

I don't think that makes much of a difference to anyone. You'd have to
process data at more than 190,000,000 bytes per second before this
would exceed your ability to do it that with SHA-256 on a single one
of the 4 cores that come in that chip. Is that a realistic amount of
data for a single tor node to process per second in forseeable future?
(Honest question: I have no idea if it is although I would guess not.)
Anyway, if you *do* want to process more than 190 MBytes/s on a fancy
server in the next few years, you can probably just use more than one
of its cores.

On the other hand, what if someone wants to deploy Tor in a 32-bit ARM
CPU such as in a Freedom Box or in a smart phone. When it is doing
4096-byte packets, Blake-256 is actually less efficient than SHA-256
by about 36,000 cycles. Since the chip in that device is running at a
slower clock rate (maybe 800 MHz), then it takes 45 microseconds more
to hash that 4096-byte packet with Blake-256 than with SHA-256. If you
hash those packets with the slower of the two algorithms (Blake-256),
you could handle about 25 MBytes/s using 100% of the only CPU in the
system. If you used SHA-256 instead you could handle 35 MBytes/s. If
you are using say, 90% of that CPU for other tasks. such as playing a
game or watching a movie while running Tor in the background, or even
playing a movie which is streaming in over Tor live, then this is the
difference between being able to process 2.5 MBytes/s (Blake-256) and
3.5 MBytes/s (SHA-256). That seems be a difference that might matter
in practice, unlike the performance difference on expensive x86_64
servers.


Okay, what about the "not obviously safer" part? I think there was a
bit of a panic a few years ago, in the aftermath of Wang Xiaoyun's
breakthrough on SHA-1, that someone might suddenly figure out a way to
find collisions in SHA-256. This panic spurred the creation of the
SHA-3 project. However, it seems like in the intervening years nobody
has published any techniques that really threaten the safety of
SHA-256, so now I'm personally no longer so confident that SHA-3
candidates like Blake will endure longer before someone finds a fatal
flaw in them than SHA-256 will. SHA-256 has endured substantial
analysis by experts for about a decade now. Blake and its fellow
competitors have had about three years.

I'm not saying that I'm confident that SHA-256 will outlast Blake! I'm
saying it could go either way.

Bottom line: I would probably move ahead toward SHA-256 and let SHA-3
mature for a few extra years before planning to move to that, if I
were you.

Regards,

Zooko

[1] http://bench.cr.yp.to/results-hash.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102155922</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-02 15:59:22-0400</timestampReceived><subject>[tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

Dear All,
Rather then get further sucked into a debate that is producing more
heat then light about Wegman-Carter, I've decided to make a concrete
proposal for how Tor can better protect its streams from manipulation.

Right now Tor encrypts the streams of data from a client to a OR with
AES-CTR and no integrity checks.
I propose the following: On establishment of a new connection between
a client and an OR (using either the Goldman et al paper or
ephermental DH) the client and the OR derive a single 16-byte K. The
client has an 8 byte counter which starts at 1, the client counter,
the OR an 8 byte counter which starts at 0, the OR counter. Each cell
from the client to the OR is protected by AES-GCM defined as in the
NIST standard, with a 4 byte string "TorC" being used to make our
counter 12 bytes. (If you read the standard you will see this is the
method for generating nonces recommended). The counter is incremented
by 2 each time a packet is sent. Under no circumstances can it go
backward. Under no circumstances does an OR or Client accept a packet
that reuses a nonce (nonces should be sent along if we make transport
unreliable). Under no circumstances are more then 2^64 packets sent.
Under no circumstances are packets longer then 2^32 bytes. Following
these rules an attacker who sends 2^64 forgery attempts has
probability 2^-36 of successfully forging one message. If we limit the
attacker to 2 billion forgery attempts (forgery must be online) then
the probability of forgery is 2^-68. I think we can live with that.
These numbers come from
http://cr.yp.to/antiforgery/securitywcs-20050227.pdf. Note that these
numbers assume AES is secure, and are theorems if AES is secure.

This proposal is independent from the establishment of streams. This
proposal eliminates issues relating to an intermediate node flipping
bits in an HTTP request, thereby tagging the traffic, amongst other
evil things manipulation can do. If we want more performance the
evaluation
of a polynomial over GF(2^128) can be replaced by GF(2^130-5), or AES
could be replaced by xsalsa20, and the nonce lengthened.
Sincerely,
Watson Ladd
---
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither   Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111103012546</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-03 01:25:46-0400</timestampReceived><subject>[tor-dev] Rewriting tor-spec to be crypto agnostic</subject><body>

Dear all,
I'm busy rewriting tor-spec (well, mangling it) to be crypto agnostic
(read: shoving hard choices to later). In the process I am trying to
make it a bit clearer.
The spec seems to hold open the possibility that nodes not on the two
ends of a circuit can send recognized RELAY cells (the role of OPs in
processing
RELAY cells is also unclear). Is this the case, or is this not
supported given that there are no points at which the spec explicitly
calls for them to be sent?
Sincerely,
Watson Ladd
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111103223056</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-03 22:30:56-0400</timestampReceived><subject>[tor-dev] patch to torspec that seperates out the crypto.</subject><body>

Dear all,
Here is a patch that removes crypto cruft from torspec.txt. It does
make torspec unusable because we haven't written crypto.txt yet.
In the process I noticed a few things I cleaned up, and also noticed
that RELAY_EXTEND cells have to be understood by both ORs, which
could be an impediment to migration.
Sincerely,
Watson Ladd

["torspec.patch" (application/octet-stream)]

24,115d23
&lt; 0.1.  Notation and encoding
&lt;
&lt;    PK -- a public key.
&lt;    SK -- a private key.
&lt;    K  -- a key for a symmetric cipher.
&lt;
&lt;    a|b -- concatenation of 'a' and 'b'.
&lt;
&lt;    [A0 B1 C2] -- a three-byte sequence, containing the bytes with
&lt;    hexadecimal values A0, B1, and C2, in that order.
&lt;
&lt;    All numeric values are encoded in network (big-endian) order.
&lt;
&lt;    H(m) -- a cryptographic hash of m.
&lt;
&lt; 0.2. Security parameters
&lt;
&lt;    Tor uses a stream cipher, a public-key cipher, the Diffie-Hellman
&lt;    protocol, and a hash function.
&lt;
&lt;    KEY_LEN -- the length of the stream cipher's key, in bytes.
&lt;
&lt;    PK_ENC_LEN -- the length of a public-key encrypted message, in bytes.
&lt;    PK_PAD_LEN -- the number of bytes added in padding for public-key
&lt;      encryption, in bytes. (The largest number of bytes that can be encrypted
&lt;      in a single public-key operation is therefore PK_ENC_LEN-PK_PAD_LEN.)
&lt;
&lt;    DH_LEN -- the number of bytes used to represent a member of the
&lt;      Diffie-Hellman group.
&lt;    DH_SEC_LEN -- the number of bytes used in a Diffie-Hellman private key (x).
&lt;
&lt;    HASH_LEN -- the length of the hash function's output, in bytes.
&lt;
&lt;    PAYLOAD_LEN -- The longest allowable cell payload, in bytes. (509)
&lt;
&lt;    CELL_LEN -- The length of a Tor cell, in bytes.
&lt;
&lt; 0.3. Ciphers
&lt;
&lt;    For a stream cipher, we use 128-bit AES in counter mode, with an IV of all
&lt;    0 bytes.
&lt;
&lt;    For a public-key cipher, we use RSA with 1024-bit keys and a fixed
&lt;    exponent of 65537.  We use OAEP-MGF1 padding, with SHA-1 as its digest
&lt;    function.  We leave the optional "Label" parameter unset. (For OAEP
&lt;    padding, see ftp://ftp.rsasecurity.com/pub/pkcs/pkcs-1/pkcs-1v2-1.pdf)
&lt;
&lt;    For Diffie-Hellman, we use a generator (g) of 2.  For the modulus (p), we
&lt;    use the 1024-bit safe prime from rfc2409 section 6.2 whose hex
&lt;    representation is:
&lt;
&lt;      "FFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E08"
&lt;      "8A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B"
&lt;      "302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9"
&lt;      "A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE6"
&lt;      "49286651ECE65381FFFFFFFFFFFFFFFF"
&lt;
&lt;    As an optimization, implementations SHOULD choose DH private keys (x) of
&lt;    320 bits.  Implementations that do this MUST never use any DH key more
&lt;    than once.
&lt;    [May other implementations reuse their DH keys?? -RD]
&lt;    [Probably not. Conceivably, you could get away with changing DH keys once
&lt;    per second, but there are too many oddball attacks for me to be
&lt;    comfortable that this is safe. -NM]
&lt;
&lt;    For a hash function, we use SHA-1.
&lt;
&lt;    KEY_LEN.
&lt;    DH_LEN8; DH_SEC_LEN@.
&lt;    PK_ENC_LEN8; PK_PAD_LENB.
&lt;    HASH_LEN .
&lt;
&lt;    When we refer to "the hash of a public key", we mean the SHA-1 hash of the
&lt;    DER encoding of an ASN.1 RSA public key (as specified in PKCS.1).
&lt;
&lt;    All "random" values MUST be generated with a cryptographically
&lt;    strong pseudorandom number generator seeded from a strong entropy
&lt;    source, unless otherwise noted.
&lt;
&lt;    The "hybrid encryption" of a byte sequence M with a public key PK is
&lt;    computed as follows:
&lt;       1. If M is less than PK_ENC_LEN-PK_PAD_LEN, pad and encrypt M with PK.
&lt;       2. Otherwise, generate a KEY_LEN byte random key K.
&lt;          Let M1 = the first PK_ENC_LEN-PK_PAD_LEN-KEY_LEN bytes of M,
&lt;          and let M2 = the rest of M.
&lt;          Pad and encrypt K|M1 with PK.  Encrypt M2 with our stream cipher,
&lt;          using the key K.  Concatenate these encrypted values.
&lt;    [XXX Note that this "hybrid encryption" approach does not prevent
&lt;    an attacker from adding or removing bytes to the end of M. It also
&lt;    allows attackers to modify the bytes not covered by the OAEP --
&lt;    see Goldberg's PET2006 paper for details. We will add a MAC to this
&lt;    scheme one day. -RD]
117c25
&lt; 0.4. Other parameter values
---
&gt; 0.1. Other parameter values
134,145d41
&lt;    Every Tor relay has multiple public/private keypairs:
&lt;
&lt;     - A long-term signing-only "Identity key" used to sign documents and
&lt;       certificates, and used to establish relay identity.
&lt;     - A medium-term "Onion key" used to decrypt onion skins when accepting
&lt;       circuit extend attempts.  (See 5.1.)  Old keys MUST be accepted for at
&lt;       least one week after they are no longer advertised.  Because of this,
&lt;       relays MUST retain old keys for a while after they're rotated.
&lt;     - A short-term "Connection key" used to negotiate TLS connections.
&lt;       Tor implementations MAY rotate this key as often as they like, and
&lt;       SHOULD rotate this key at least once a day.
&lt;
147c43,44
&lt;    dir-spec.txt.
---
&gt;    dir-spec.txt. The cryptography spec in crypto.txt defines the proper
&gt;    handling of keys.
150,300c47,48
&lt;
&lt;    Connections between two Tor relays, or between a client and a relay,
&lt;    use TLS/SSLv3 for link authentication and encryption.  All
&lt;    implementations MUST support the SSLv3 ciphersuite
&lt;    "SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA", and SHOULD support the TLS
&lt;    ciphersuite "TLS_DHE_RSA_WITH_AES_128_CBC_SHA" if it is available.
&lt;
&lt;    There are three ways to perform TLS handshakes with a Tor server.  In
&lt;    the first way, "certificates-up-front", both the initiator and
&lt;    responder send a two-certificate chain as part of their initial
&lt;    handshake.  (This is supported in all Tor versions.)  In the second
&lt;    way, "renegotiation", the responder provides a single certificate,
&lt;    and the initiator immediately performs a TLS renegotiation.  (This is
&lt;    supported in Tor 0.2.0.21 and later.)  And in the third way,
&lt;    "in-protocol", the initial TLS renegotiation completes, and the
&lt;    parties bootstrap themselves to mutual authentication via use of the
&lt;    Tor protocol without further TLS handshaking.  (This is supported in
&lt;    0.2.3.6-alpha and later.)
&lt;
&lt;    Each of these options provides a way for the parties to learn it is
&lt;    available: a client does not need to know the version of the Tor
&lt;    server in order to connect to it properly.
&lt;
&lt;    In "certificates up-front" (a.k.a "the v1 handshake"),
&lt;    the connection initiator always sends a
&lt;    two-certificate chain, consisting of an X.509 certificate using a
&lt;    short-term connection public key and a second, self-signed X.509
&lt;    certificate containing its identity key.  The other party sends a similar
&lt;    certificate chain.  The initiator's ClientHello MUST NOT include any
&lt;    ciphersuites other than:
&lt;      TLS_DHE_RSA_WITH_AES_256_CBC_SHA
&lt;      TLS_DHE_RSA_WITH_AES_128_CBC_SHA
&lt;      SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA
&lt;      SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA
&lt;
&lt;    In "renegotiation" (a.k.a. "the v2 handshake"),
&lt;    the connection initiator sends no certificates, and
&lt;    the responder sends a single connection certificate.  Once the TLS
&lt;    handshake is complete, the initiator renegotiates the handshake, with each
&lt;    party sending a two-certificate chain as in "certificates up-front".
&lt;    The initiator's ClientHello MUST include at least one ciphersuite not in
&lt;    the list above -- that's how the initiator indicates that it can
&lt;    handle this handshake.  The responder SHOULD NOT select any
&lt;    ciphersuite besides those in the list above.
&lt;      [The above "should not" is because some of the ciphers that
&lt;      clients list may be fake.]
&lt;
&lt;    In "in-protocol" (a.k.a. "the v3 handshake"), the initiator sends no
&lt;    certificates, and the
&lt;    responder sends a single connection certificate.  The choice of
&lt;    ciphersuites must be as in a "renegotiation" handshake.  There are
&lt;    additionally a set of constraints on the connection certificate,
&lt;    which the initiator can use to learn that the in-protocol handshake
&lt;    is in use.  Specifically, at least one of these properties must be
&lt;    true of the certificate:
&lt;       * The certificate is self-signed
&lt;       * Some component other than "commonName" is set in the subject or
&lt;         issuer DN of the certificate.
&lt;       * The commonName of the subject or issuer of the certificate ends
&lt;         with a suffix other than ".net".
&lt;       * The certificate's public key modulus is longer than 1024 bits.
&lt;    The initiator then sends a VERSIONS cell to the responder, which then
&lt;    replies with a VERSIONS cell; they have then negotiated a Tor
&lt;    protocol version.  Assuming that the version they negotiate is 3 (the
&lt;    only one specified for use with this handshake right now), the
&lt;    responder sends a CERTS cell, an AUTH_CHALLENGE cell, and a NETINFO
&lt;    cell to the initiator, which may send either CERTS, AUTHENTICATE,
&lt;    NETINFO if it wants to authenticate, or just NETINFO if it does not.
&lt;
&lt;    For backward compatibility between later handshakes and "certificates
&lt;    up-front", the ClientHello of an initiator that supports a later
&lt;    handshake MUST include at least one ciphersuite other than those listed
&lt;    above. The connection responder examines the initiator's ciphersuite list
&lt;    to see whether it includes any ciphers other than those included in the
&lt;    list above.  If extra ciphers are included, the responder proceeds as in
&lt;    "renegotiation" and "in-protocol": it sends a single certificate and
&lt;    does not request
&lt;    client certificates.  Otherwise (in the case that no extra ciphersuites
&lt;    are included in the ClientHello) the responder proceeds as in
&lt;    "certificates up-front": it requests client certificates, and sends a
&lt;    two-certificate chain.  In either case, once the responder has sent its
&lt;    certificate or certificates, the initiator counts them.  If two
&lt;    certificates have been sent, it proceeds as in "certificates up-front";
&lt;    otherwise, it proceeds as in "renegotiation" or "in-protocol".
&lt;
&lt;    To decide whether to do "renegotiation" or "in-protocol", the
&lt;    initiator checks whether the responder's initial certificate matches
&lt;    the criteria listed above.
&lt;
&lt;    All new relay implementations of the Tor protocol MUST support
&lt;    backwards-compatible renegotiation; clients SHOULD do this too.  If
&lt;    this is not possible, new client implementations MUST support both
&lt;    "renegotiation" and "in-protocol" and use the router's
&lt;    published link protocols list (see dir-spec.txt on the "protocols" entry)
&lt;    to decide which to use.
&lt;
&lt;    In all of the above handshake variants, certificates sent in the clear
&lt;    SHOULD NOT include any strings to identify the host as a Tor relay. In
&lt;    the "renegotiation" and "backwards-compatible renegotiation" steps, the
&lt;    initiator SHOULD choose a list of ciphersuites and TLS extensions
&lt;    to mimic one used by a popular web browser.
&lt;
&lt;    Responders MUST NOT select any TLS ciphersuite that lacks ephemeral keys,
&lt;    or whose symmetric keys are less then KEY_LEN bits, or whose digests are
&lt;    less than HASH_LEN bits.  Responders SHOULD NOT select any SSLv3
&lt;    ciphersuite other than those listed above.
&lt;
&lt;    Even though the connection protocol is identical, we will think of the
&lt;    initiator as either an onion router (OR) if it is willing to relay
&lt;    traffic for other Tor users, or an onion proxy (OP) if it only handles
&lt;    local requests. Onion proxies SHOULD NOT provide long-term-trackable
&lt;    identifiers in their handshakes.
&lt;
&lt;    In all handshake variants, once all certificates are exchanged, all
&lt;    parties receiving certificates must confirm that the identity key is as
&lt;    expected.  (When initiating a connection, the expected identity key is
&lt;    the one given in the directory; when creating a connection because of an
&lt;    EXTEND cell, the expected identity key is the one given in the cell.)  If
&lt;    the key is not as expected, the party must close the connection.
&lt;
&lt;    When connecting to an OR, all parties SHOULD reject the connection if that
&lt;    OR has a malformed or missing certificate.  When accepting an incoming
&lt;    connection, an OR SHOULD NOT reject incoming connections from parties with
&lt;    malformed or missing certificates.  (However, an OR should not believe
&lt;    that an incoming connection is from another OR unless the certificates
&lt;    are present and well-formed.)
&lt;
&lt;    [Before version 0.1.2.8-rc, ORs rejected incoming connections from ORs and
&lt;    OPs alike if their certificates were missing or malformed.]
&lt;
&lt;    Once a TLS connection is established, the two sides send cells
&lt;    (specified below) to one another.  Cells are sent serially.  Standard
&lt;    cells are CELL_LEN bytes long, but variable-length cells also exist; see
&lt;    Section 3.  Cells may be sent embedded in TLS
&lt;    records of any size or divided across TLS records, but the framing
&lt;    of TLS records MUST NOT leak information about the type or contents
&lt;    of the cells.
&lt;
&lt;    TLS connections are not permanent. Either side MAY close a connection
&lt;    if there are no circuits running over it and an amount of time
&lt;    (KeepalivePeriod, defaults to 5 minutes) has passed since the last time
&lt;    any traffic was transmitted over the TLS connection.  Clients SHOULD
&lt;    also hold a TLS connection with no circuits open, if it is likely that a
&lt;    circuit will be built soon using that connection.
&lt;
&lt;    Client-only Tor instances are encouraged to avoid using handshake
&lt;    variants that include certificates, if those certificates provide
&lt;    any persistent tags to the relays they contact. If clients do use
&lt;    certificates, they SHOULD NOT keep using the same certificates when
&lt;    their IP address changes.  Clients MAY send certificates using any
&lt;    of the above handshake variants.
---
&gt;
&gt;    Connections are discussed in connect-spec.txt
378,403c126
&lt;
&lt;    After Tor instances negotiate handshake with either the "renegotiation" or
&lt;    "in-protocol" handshakes, they must exchange a set of cells to set up
&lt;    the Tor connection and make it "open" and usable for circuits.
&lt;
&lt;    When the renegotiation handshake is used, both parties immediately
&lt;    send a VERSIONS cell (4.1 below), and after negotiating a link
&lt;    protocol version (which will be 2), each send a NETINFO cell (4.5
&lt;    below) to confirm their addresses and timestamps.  No other intervening
&lt;    cell types are allowed.
&lt;
&lt;    When the in-protocol handshake is used, the initiator sends a
&lt;    VERSIONS cell to indicate that it will not be renegotiating.  The
&lt;    responder sends a VERSIONS cell, a CERTS cell (4.2 below) to give the
&lt;    initiator the certificates it needs to learn the responder's
&lt;    identity, an AUTH_CHALLENGE cell (4.3) that the initiator must include
&lt;    as part of its answer if it chooses to authenticate, and a NETINFO
&lt;    cell (4.5).  The initiator can use the CERTS cell to confirm whether
&lt;    the responder is correctly authenticated. If the initiator does not wish
&lt;    to authenticate, it can send a NETINFO cell once it has received the
&lt;    VERSIONS cell from the responder. If the initiator does wish to
&lt;    authenticate, it waits until it gets the AUTH_CHALLENGE cell, and then
&lt;    sends a CERTS cell, an AUTHENTICATE cell (4.4), and a NETINFO
&lt;    cell.  When this handshake is in use, the first cell must
&lt;    still be VERSIONS, and no other cell type is allowed to intervene
&lt;    besides those specified, except for PADDING and VPADDING cells.
---
&gt;    This is discussed in connect-spec.txt, except for VERSION cells
439,492c162,163
&lt;
&lt;    The CERTS cell describes the keys that a Tor instance is claiming
&lt;    to have.  It is a variable-length cell.  Its payload format is:
&lt;
&lt;         N: Number of certs in cell            [1 octet]
&lt;         N times:
&lt;            CertType                           [1 octet]
&lt;            CLEN                               [2 octets]
&lt;            Certificate                        [CLEN octets]
&lt;
&lt;    Any extra octets at the end of a CERTS cell MUST be ignored.
&lt;
&lt;      CertType values are:
&lt;         1: Link key certificate certified by RSA1024 identity
&lt;         2: RSA1024 Identity certificate
&lt;         3: RSA1024 AUTHENTICATE cell link certificate
&lt;
&lt;    The certificate format for the above certificate types is X509.
&lt;
&lt;    A CERTS cell may have no more than one certificate of each CertType.
&lt;
&lt;    To authenticate the responder, the initiator MUST check the following:
&lt;      * The CERTS cell contains exactly one CertType 1 "Link" certificate.
&lt;      * The CERTS cell contains exactly one CertType 2 "ID" certificate.
&lt;      * Both certificates have validAfter and validUntil dates that
&lt;        are not expired.
&lt;      * The certified key in the Link certificate matches the
&lt;        link key that was used to negotiate the TLS connection.
&lt;      * The certified key in the ID certificate is a 1024-bit RSA key.
&lt;      * The certified key in the ID certificate was used to sign both
&lt;        certificates.
&lt;      * The link certificate is correctly signed with the key in the
&lt;        ID certificate
&lt;      * The ID certificate is correctly self-signed.
&lt;    Checking these conditions is sufficient to authenticate that the
&lt;    initiator is talking to the Tor node with the expected identity,
&lt;    as certified in the ID certificate.
&lt;
&lt;    To authenticate the initiator, the responder MUST check the
&lt;    following:
&lt;      * The CERTS cell contains exactly one CertType 3 "AUTH" certificate.
&lt;      * The CERTS cell contains exactly one CertType 2 "ID" certificate.
&lt;      * Both certificates have validAfter and validUntil dates that
&lt;        are not expired.
&lt;      * The certified key in the AUTH certificate is a 1024-bit RSA key.
&lt;      * The certified key in the ID certificate is a 1024-bit RSA key.
&lt;      * The certified key in the ID certificate was used to sign both
&lt;        certificates.
&lt;      * The auth certificate is correctly signed with the key in the
&lt;        ID certificate.
&lt;      * The ID certificate is correctly self-signed.
&lt;    Checking these conditions is NOT sufficient to authenticate that the
&lt;    initiator has the ID it claims; to do so, the cells in 4.3 and 4.4
&lt;    below must be exchanged.
---
&gt;      The CERTS cell is not backwards compatible. Handling it is
&gt;      in crypto.txt
507,510c178,179
&lt;    initiator must sign (a hash of) as part of authenticating.  The
&lt;    methods are the authentication methods that the responder will
&lt;    accept.  Only one authentication method is defined right now:
&lt;    see 4.4 below.
---
&gt;    initiator must sign (a hash of) as part of authenticating.
&gt;    crypto.txt details the existing methods and their uses.
531,566c200
&lt;    cell.  If AuthType is 1 (meaning "RSA-SHA256-TLSSecret"), then the
&lt;    Authentication contains the following:
&lt;
&lt;        TYPE: The characters "AUTH0001" [8 octets]
&lt;        CID: A SHA256 hash of the initiator's RSA1024 identity key [32 octets]
&lt;        SID: A SHA256 hash of the responder's RSA1024 identity key [32 octets]
&lt;        SLOG: A SHA256 hash of all bytes sent from the responder to the
&lt;          initiator as part of the negotiation up to and including the
&lt;          AUTH_CHALLENGE cell; that is, the VERSIONS cell, the CERTS cell,
&lt;          the AUTH_CHALLENGE cell, and any padding cells.  [32 octets]
&lt;        CLOG: A SHA256 hash of all bytes sent from the initiator to the
&lt;          responder as part of the negotiation so far; that is, the
&lt;          VERSIONS cell and the CERTS cell and any padding cells. [32
&lt;          octets]
&lt;        SCERT: A SHA256 hash of the responder's TLS link certificate. [32
&lt;          octets]
&lt;        TLSSECRETS: A SHA256 HMAC, using the TLS master secret as the
&lt;          secret key, of the following:
&lt;            - client_random, as sent in the TLS Client Hello
&lt;            - server_random, as sent in the TLS Server Hello
&lt;            - the NUL terminated ASCII string:
&lt;              "Tor V3 handshake TLS cross-certification"
&lt;           [32 octets]
&lt;        TIME: The time of day in seconds since the POSIX epoch. [8 octets]
&lt;        RAND: A 16 byte value, randomly chosen by the initiator [16 octets]
&lt;        SIG: A signature of a SHA256 hash of all the previous fields
&lt;          using the initiator's "Authenticate" key as presented.  (As
&lt;          always in Tor, we use OAEP-MGF1 padding; see tor-spec.txt
&lt;          section 0.3.)
&lt;           [variable length]
&lt;
&lt;    To check the AUTHENTICATE cell, a responder checks that all fields
&lt;    from TYPE through TLSSECRETS contain their unique
&lt;    correct values as described above, and then verifies the signature.
&lt;    signature.  The server MUST ignore any extra bytes in the signed
&lt;    data after the SHA256 hash.
---
&gt;    cell.  crypto.txt specifies how to handle these cells.
579,580c213,215
&lt;    6.4 below.  The timestamp is a big-endian unsigned integer number of
&lt;    seconds since the Unix epoch.
---
&gt;    6.4 below.  The timestamp is a big-endian unsigned integer of seconds
&gt;    since 1 January 1970, 00:00:00 UTC. This is the time value returned
&gt;    by gettimeofday(2) on Unix systems.
596,599c231,232
&lt;    new circuit, OPs send a CREATE cell to the first node, with the
&lt;    first half of the DH handshake; that node responds with a CREATED
&lt;    cell with the second half of the DH handshake plus the first 20 bytes
&lt;    of derivative key data (see section 5.2). To extend a circuit past
---
&gt;    new circuit, OPs send a CREATE cell to the first node,
&gt;    with interpretation in crypto.txt. To extend a circuit past
604,615c237,238
&lt;    The payload for a CREATE cell is an 'onion skin', which consists
&lt;    of the first step of the DH handshake data (also known as g^x).
&lt;    This value is hybrid-encrypted (see 0.3) to Bob's onion key, giving
&lt;    an onion-skin of:
&lt;        PK-encrypted:
&lt;          Padding                       [PK_PAD_LEN bytes]
&lt;          Symmetric key                 [KEY_LEN bytes]
&lt;          First part of g^x             [PK_ENC_LEN-PK_PAD_LEN-KEY_LEN bytes]
&lt;        Symmetrically encrypted:
&lt;          Second part of g^x            [DH_LEN-(PK_ENC_LEN-PK_PAD_LEN-KEY_LEN)
&lt;                                            bytes]
&lt;
---
&gt;    The payload for a CREATE cell is defined in crypto.txt
&gt;    [--world of pain when extending this-- Watson Ladd]
628c251,252
&lt;
---
&gt;    [-- end massive pain. The issue is that both ORs must understand EXTEND
&gt;    cells--]
630,632c254
&lt;    EXTENDED cell, contains:
&lt;          DH data (g^y)                 [DH_LEN bytes]
&lt;          Derivative key data (KH)      [HASH_LEN bytes]   &lt;see 5.2 below&gt;
---
&gt;    EXTENDED cell, is described in crypto.txt
644,646c266
&lt;    Public keys are compared numerically by modulus.
&lt;
&lt;    As usual with DH, x and y MUST be generated randomly.
---
&gt;    Public keys are compared numerically as defined in crypto.txt
657,668c277,279
&lt;
&lt;    A CREATE_FAST cell contains:
&lt;
&lt;        Key material (X)    [HASH_LEN bytes]
&lt;
&lt;    A CREATED_FAST cell contains:
&lt;
&lt;        Key material (Y)    [HASH_LEN bytes]
&lt;        Derivative key data [HASH_LEN bytes] (See 5.2 below)
&lt;
&lt;    The values of X and Y must be generated randomly.
&lt;
---
&gt;
&gt;    crypto.txt specifies the contents of CREATE_FAST
&gt;
675,711c286,287
&lt;
&lt;    Once the handshake between the OP and an OR is completed, both can
&lt;    now calculate g^xy with ordinary DH.  Before computing g^xy, both parties
&lt;    MUST verify that the received g^x or g^y value is not degenerate;
&lt;    that is, it must be strictly greater than 1 and strictly less than p-1
&lt;    where p is the DH modulus.  Implementations MUST NOT complete a handshake
&lt;    with degenerate keys.  Implementations MUST NOT discard other "weak"
&lt;    g^x values.
&lt;
&lt;    (Discarding degenerate keys is critical for security; if bad keys
&lt;    are not discarded, an attacker can substitute the OR's CREATED
&lt;    cell's g^y with 0 or 1, thus creating a known g^xy and impersonating
&lt;    the OR. Discarding other keys may allow attacks to learn bits of
&lt;    the private key.)
&lt;
&lt;    If CREATE or EXTEND is used to extend a circuit, both parties
&lt;    base their key material on K0=g^xy, represented as a big-endian unsigned
&lt;    integer.
&lt;
&lt;    If CREATE_FAST is used, both parties base their key material on
&lt;    K0=X|Y.
&lt;
&lt;    From the base key material K0, they compute KEY_LEN*2+HASH_LEN*3 bytes of
&lt;    derivative key data as
&lt;        K = H(K0 | [00]) | H(K0 | [01]) | H(K0 | [02]) | ...
&lt;
&lt;    The first HASH_LEN bytes of K form KH; the next HASH_LEN form the forward
&lt;    digest Df; the next HASH_LEN 41-60 form the backward digest Db; the next
&lt;    KEY_LEN 61-76 form Kf, and the final KEY_LEN form Kb.  Excess bytes from K
&lt;    are discarded.
&lt;
&lt;    KH is used in the handshake response to demonstrate knowledge of the
&lt;    computed shared key. Df is used to seed the integrity-checking hash
&lt;    for the stream of data going from the OP to the OR, and Db seeds the
&lt;    integrity-checking hash for the data stream from the OR to the OP. Kf
&lt;    is used to encrypt the stream of data going from the OP to the OR, and
&lt;    Kb is used to encrypt the stream of data going from the OR to the OP.
---
&gt;      crypto.txt specifies how circuit keys are calculated and what nonces
&gt;      must be tracked for security.
742c318
&lt;       1. Create an onion skin, encrypted to R_M's public onion key.
---
&gt;       1. Follow crypto.txt
744,745c320
&lt;       2. Send the onion skin in a relay EXTEND cell along
&lt;          the circuit (see section 5).
---
&gt;       2. Send the outgoing data in a RELAY_EXTEND cell
747,748c322,323
&lt;       3. When a relay EXTENDED cell is received, verify KH, and
&lt;          calculate the shared keys.  The circuit is now extended.
---
&gt;       3. When a relay EXTENDED cell is received, carry out the calculations
&gt;       in crypto.txt
751c326
&lt;    cell to the next onion router, with the enclosed onion skin as its
---
&gt;    cell to the next onion router, with the enclosed crypto data as its
861,866c436,437
&lt;    with the stream cipher, as follows:
&lt;         'Forward' relay cell (same direction as CREATE):
&lt;             Use Kf as key; decrypt.
&lt;         'Back' relay cell (opposite direction from CREATE):
&lt;             Use Kb as key; encrypt.
&lt;    Note that in counter mode, decrypt and encrypt are the same operation.
---
&gt;    as specified in crypto.txt
&gt;
869c440
&lt;    inspecting the payload as described in section 6.1 below.  If the OR
---
&gt;    a method in crypto.txt.  If the OR
877,881c448
&lt;    with the stream cipher as follows:
&lt;          OP receives data cell:
&lt;             For I=N...1,
&lt;                 Decrypt with Kb_I.  If the payload is recognized (see
&lt;                 section 6..1), then stop and process the payload.
---
&gt;    as specified in crypto.txt
914a482,483
&gt;    crypto.txt specifies the decryption and recognition of relay cells
&gt;    [--I had to take out some fields here, which crypto.txt should describe].
917d485
&lt;          'Recognized'            [2 bytes]
919d486
&lt;          Digest                  [4 bytes]
945,962d511
&lt;    The 'recognized' field in any unencrypted relay payload is always set
&lt;    to zero; the 'digest' field is computed as the first four bytes of
&lt;    the running digest of all the bytes that have been destined for
&lt;    this hop of the circuit or originated from this hop of the circuit,
&lt;    seeded from Df or Db respectively (obtained in section 5.2 above),
&lt;    and including this RELAY cell's entire payload (taken with the digest
&lt;    field set to zero).
&lt;
&lt;    When the 'recognized' field of a RELAY cell is zero, and the digest
&lt;    is correct, the cell is considered "recognized" for the purposes of
&lt;    decryption (see section 5.5 above).
&lt;
&lt;    (The digest does not include any bytes from relay cells that do
&lt;    not start or end at this hop of the circuit. That is, it does not
&lt;    include forwarded data. Therefore if 'recognized' is zero but the
&lt;    digest does not match, the running digest at that node should
&lt;    not be updated, and the cell should be forwarded on.)
&lt;
964,969c513,518
&lt;    same stream ID.  StreamIDs are chosen arbitrarily by the OP.  RELAY
&lt;    cells that affect the entire circuit rather than a particular
&lt;    stream use a StreamID of zero -- they are marked in the table above
&lt;    as "[control]" style cells. (Sendme cells are marked as "sometimes
&lt;    control" because they can take include a StreamID or not depending
&lt;    on their purpose -- see Section 7.)
---
&gt;    same stream ID.  StreamIDs MUST NOT be zero, and are chosen by the
&gt;    OP.  RELAY cells that affect the entire circuit rather than a
&gt;    particular stream use a StreamID of zero -- they are marked in the
&gt;    table above as "[control]" style cells. (Sendme cells are marked as
&gt;    "sometimes control" because they can take include a StreamID or not
&gt;    depending on their purpose -- see Section 7.)
976,977c525
&lt;    understood, the cell must be dropped and ignored. Its contents
&lt;    still count with respect to the digests, though.
---
&gt;    understood, the cell must be dropped and ignored.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111104040822</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-04 04:08:22-0400</timestampReceived><subject>[tor-dev] The consequences of key compromise (or the reasons for</subject><body>

Dear all,

Recently Zooko forwarded an email asking why we have to migrate. I am
outlining the reasons in this email why I believe Tor needs to
use stronger cryptography very soon.

Tor currently uses RSA-1024 bit keys for OR public identities and
1024-bit Diffie Hellman for the negotiation of keys protecting
circuits.
It also uses SHA-1 for a hash in serveral applications, including key
fingerprints.
When deciding if these are adequate it is necessary to think about
what compromise gives an attacker and what it costs to compromise Tor
cryptography. We are aiming to protect users from TLAs with ASICs.

Directory keys are 3024 bit RSA. Compromising a directory key is sufficient
to generate directories containing fake entries, and thus break the
anonymityof all users who see the fake directory.
In the event of a compromise, Tor would be unusable until a new
version is put out with a longer key length and new directory keys.
But these are long keys.

However, the keys that actually sign the directories are 1024 bits,
but rotate every 3 months.

OR keys are also 1024 bit RSA. Compromise of an OR key enables
impersonation of the OR to an OP.
Combined with fun and games with BGP it enables impersonation of an OR
to other ORs,
which can direct significant traffic to the fake OR. Detection is
likely as the real OR will notice various
refusals to connect by other OR to whom it is not connected. And if
you can break the directory key why bother with ORs.


Hidden services are also identified by 1024 bit RSA keys.
At the circuit level DH keys are 1024 bits.
An attacker who compromises these can read data intended for further
down in the circuit.
In particular they can determine the rest of a circuit if they are the
first node.

There is also the issue of keysize. A Tor cell is 512 bytes long.
Thisis sufficent for only 4 keys, if we pack them very tightly.
Smaller keys could enable fast circuit initiation or other cool tricks
we cannot use today.

So, how strong or weak are RSA-1024 and DH-1024 currently?
We are using DH over F_q* where q = a big prime. For DH the best known
algorithm is the index calculus. This attack proceeds in 3 steps.

The first step, which can be spread over multiple keys is the
collection of relations among a factor base, usually of small primes.
The second step, again spread over multiple keys, is solving the
linear system of equations from the first step.
The third step is fast and key specific: given an element h,and
generator g we attempt to factor g^s*h over the factor base.
The general number field sieve is a very similar algorithm for factoring.
It is more complicated but again relies on finding smooth numbers and
factoring them with respect to a factor base of small primes.

Currently the complexity of these algorithms is
L_n[1/3,\sqrt^3_{\frac{64}{9}}]for GNFS and L_n[1/2,c] for index
calculus. (From wikipedia). Sadly the sieving stepscan be done very
well on special hardware. TWIRL, a specialized hardwaredevice designed
by Adi Shamir and Eran Tromer is believed by Shamir and Tromer to be
capable of factoring a 1024-bit RSA key in a year at a cost of $10
million dollars. To break 10 directory
keys in 3 months is 10 times as many keys, and 4 times the speed. That
will be $400 million dollars.

That is half the cost of Golden Shield for a year: an amount of money
that is not ludicrous. And such a machine once built can crack the
next 10 keys for free. The cost is design and fabrication of this
device: power is comparatively cheap. Of course, such a machine would
be
unsuited to other bit sizes.

If the attacker instead decides to find a discrete logarithm base for
DH over 1024, then
they will have the ability to break DH-1024 fairly quickly. I haven't
seen a good estimate
for the time it would take to do this, but it will be a bit more. It
will not be much more. And it
will be a total break: once a factor basis is found discrete logs are
very fast. So an adversary can spend more
time and still be happy with the results.

So it isn't just directory signing that is an issue but the link
protocol as well. And $400 million is a lot. But when you are the
Golden Shield director and someone says "for $400 million we can break
Tor for a long time" that is not entirely out of the picture.
As technology for ASIC fabrication gets better, this price drops. As
GNFS gets better it also drops. As index calculus gets better it
drops. And as Balmol's cost disease drives up the cost and budget of
Golden Shields regular activities, the price drops.

Sincerely,
Watson Ladd
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104071438</emailId><senderName>"Markku-Juhani O. Saarinen"</senderName><senderEmail>mjos@reveresecurity.com</senderEmail><timestampReceived>2011-11-04 07:14:38-0400</timestampReceived><subject>[tor-dev] Subject: Re: The consequences of key compromise (or the</subject><body>


From: Jon Callas &lt;joncallas@me.com&gt;

&gt; People should get off of 80-bit crypto as soon as is reasonably possible. This \
&gt; means RSA 1024, SHA-1, etc. NIST recommended doing this by the end of 2010, but are \
&gt; now holding their nose and saying that 2013 is the real new date.

Absolutely agree. The 80-bit figure was apparently adopted by U.S.
Government some 25+ years ago (skipjack etc).

&gt; This seems basically reasonable to me. No one has yet factored a 768-bit number, \
&gt; let alone a 1K one. 

768-bit RSA was factored in 2009 and the authors of that paper
conjecture that 1024 bits would be factored "within a decade" and
recommend that 1024-bit RSA should be phased out within a couple of
years. http://eprint.iacr.org/2010/006.pdf

I am certainly doing that with the stuff that I am maintaining.

&gt; SHA-1 actually looks safer today than it did in 2005. But still. Moving away is a \
&gt; Good Thing, so long as it doesn't make you do something stupid.

Well, after the 2005 Wang-Yin-Yu paper which had a 2^69 attack, there
was a claimed 2^52 attack in 2009 which turned out to have a flawed cost
evaluation. There has also been talk of a 2^63 attack, but that
difference can be put down to attack implementation skill and detail.

I was always doubtful whether or not those techniques could be expanded
to work against the SHA-2 algorithms. 

It is also funny that many people talk about SHA-2 as if was a single
algorithm; there are actually two quite distinct algorithms, one for
(now fading) 32-bit architectures (SHA-224,SHA-256) and one for 64-bit
algorithms (SHA-384,SHA-512,SHA-512/224,SHA-512/256). The variants of
these two algorithms only differ in the number of output bits and the IV
values and hence have a constant speed regardless of their digest size.
You can run "openssl speed sha" to see a real-world performance
comparison on a particular box.

Cheers,
- markku

Dr. Markku-Juhani O. Saarinen &lt;mjos@reveresecurity.com&gt;

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111102012529</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-02 01:25:29-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

On Tue, Nov 1, 2011 at 4:40 PM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt;
&gt; On 11/01/2011 03:06 PM, Watson Ladd wrote:
&gt;&gt;
&gt;&gt; GCM is a Wegman-Carter authenticator with polynomial evaluation in
&gt;&gt; GF2^128 as the universal hash and AES as the encryption. As NIST
&gt;&gt; pointed out, neither of those papers had anything to say about the
&gt;&gt; actual security of GCM: the security claims in the GCM paper are still
&gt;&gt; valid. The Microsoft paper is simply irrelevant. 2^{n-k} looks scary,
&gt;&gt; but messages are 2^k blocks long, where a block is 128 bits. And the
&gt;&gt; GCM paper limited the length of messages to 2^36 bytes. The Joux paper
&gt;&gt; was a threat to a misfeature: Theorem 1 still holds from the GCM paper
&gt;&gt; (http://eprint.iacr.org/2004/193.pdf). Its just a matter of
&gt;&gt; remembering that unique means unique, and that supporting variable
&gt;&gt; length IVs by padding changes the meaning of the word unique.
&gt;
&gt; But those are exactly the kinds of details that get overlooked time and time
&gt; again. Whether or not you consider it a "real attack", a little bit of
&gt; controversy can help raise the important design constraints out of footnote
&gt; status.

Definition of attack: something that breaks a security claim.
Microsoft breaks a claim the GCM designers never made, Joux very
cleverly breaks a part of the standard that their proof doesn't cover.
The designers also didn't claim anything near the real security.
(http://cr.yp.to/antiforgery/securitywcs-20050227.pdf is a tighter
proof).
True, NIST should put the claims front and center in the document,
especially when they have such a nice form.
But it is the responsibility of implementators of cryptography to
exhaustively document what their security claims
are. Hiding behind NIST won't save your data if you do something stupid.
&gt;
&gt;&gt; I don't
&gt;&gt; think stupidity by standards designers is a strike against what they
&gt;&gt; are standardizing.
&gt;
&gt; :-)
&gt;
&gt; Everyone except fools and specialized cryptographers look to the recognized
&gt; experts to guide them. NIST's function is to provide expert, conservative
&gt; guidance on these topics, and they're pretty well regarded by engineers and
&gt; others who choose which standard to use. By following NIST, at the very
&gt; least it's not your fault if it turns out to be broken.

NIST is standardizing cryptographic algorithms for government use.
They make tradeoffs in
their algorithms the same as any other user: speed vs. security.
Blindly implementing standards
is a way to fall into a trap. DES is a standard, Blowfish isn't as
much. Which would you rather use?

Furthermore, NIST didn't write the draft that the comments from
Ferguson were about. As the response
indicates GCM could be secure if you made the right parameter choices.
Its not substantially different from
RSA in that regard. Now, why the options, why q=2^128 instead of some
prime? Because NIST wanted to support
high speed encryption of fiber optic links in hardware, and Galois
fields are easy in hardware.  This is the
story I get from the comments on the standard. If you are working in
software, I would suggest something else.

&gt;
&gt; If, as you suggest, NIST can't get this unambiguously correct the first time
&gt; then in peoples' minds it naturally raises the question of the whole scheme
&gt; maybe being too complicated in practice.

The standard is complicated But the problem is the picking the IV. I
have no idea why NIST decided to use 96 bit IVs but fix the first 32
bits, so you are left with a 64 bit counter, then support longer ones
through hashing, and then ultimately have to backtrack and support
only 64 bit counters as nonces. But GCM is simple: it is polynomial
evaluation, and encryption of the resulting value. The NSA has had
these incidents before: ECMQV used to be
in Suit B, before unknown key share attacks were published against it.
The NIST P-256 was fast on 32 bit
machines, but put a reflection right in the middle of a word on 64 bit
machines. Etc, etc,. I'm sure there are
many we never hear about.

More fundamentally implementing a system such as Tor requires making
choices about how standards are used
and fit together. It is the rare (and wonderful!) standard that has no
options. Making those choices requires knowledge of the security
offered by the standard. It is never going to be possible to rely on
guidance alone.
Implementors who implement AES with giant tables are in for a surprise
when they run on cloud machines.
Hashing a password is pointless when that hash is a hash function:
checking all 10 character passwords takes about a week on a nice
graphics card. Understanding of cryptography is required even if
standards exist.

Nonces are required for protection against replay attacks. If nonces
are unique, GCM is secure and pretty fast.
Poly1305 is faster. HMAC does not have as high a margin of security
proven, and when a hash function breaks
so does HMAC. This is a good case for  GCM or Poly1305 in Tor. Right
now we have nothing: cells are encrypted
with AES in counter mode only.

In order to do something constructive I might go through Torspec and
look at how things are used and what we
rely on them for. This might give us a better idea of what the requirements are.
&gt;
&gt;&gt; KDF!=turn a password into a bunch of bits. The KDF Tor uses is used to
&gt;&gt; turn the result of a DH negotiation into keying material for several
&gt;&gt; different algorithms. The KDF we need just needs to take some
&gt;&gt; distribution to something random looking. We have enough randomness in
&gt;&gt; the initial DH negotiation to not have to worry about slowing down
&gt;&gt; brute force attacks.
&gt;
&gt; So you could almost use MD5(counter + DH material) for that :-)
You can indeed. Or any stream cipher really. (Provided it doesn't do
very bad things)
&gt;
&gt;&gt; Where we use hashing to protect a password we
&gt;&gt; should use scrypt or similar functions.
&gt;
&gt; I didn't know if passwords was a use case under discussion. PBKDFs has been
&gt; a hot topic lately and was just ranting in general.
&gt;
&gt; Thanks,
&gt;
&gt; - Marsh
&gt;
Sincerely,
Watson Ladd

-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither   Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111104173616</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-04 17:36:16-0400</timestampReceived><subject>[tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>


Filename: 189-authorize-cell.txt
Title: AUTHORIZE and AUTHORIZED cells
Author: George Kadianakis
Created: 04 Nov 2011
Status: Open

1. Overview

   Proposal 187 introduced the concept of the AUTHORIZE cell, a cell
   whose purpose is to make Tor bridges resistant to scanning attacks.

   This is achieved by having the bridge and the client share a secret
   out-of-band and then use AUTHORIZE cells to validate that the
   client indeed knows that secret before proceeding with the Tor
   protocol.

   This proposal specifies the format of the AUTHORIZE cell and also
   introduces the AUTHORIZED cell, a way for bridges to announce to
   clients that the authorization process is complete and successful.

2. Motivation

   AUTHORIZE cells should be able to perform a variety of
   authorization protocols based on a variety of shared secrets. This
   forces the AUTHORIZE cell to have a dynamic format based on the
   authorization method used.

   AUTHORIZED cells are used by bridges to signal the end of a
   successful bridge client authorization and the beginning of the
   actual link handshake. AUTHORIZED cells have no other use and for
   this reason their format is very simple.

   Both AUTHORIZE and AUTHORIZED cells are to be used under censorship
   conditions and they should look innocuous to any adversary capable
   of monitoring network traffic.

   As an attack example, an adversary could passively monitor the
   traffic of a bridge host, looking at the packets directly after the
   TLS handshake and trying to deduce from their packet size if they
   are AUTHORIZE and AUTHORIZED cells. For this reason, AUTHORIZE and
   AUTHORIZED cells are padded with a random amount of padding before
   sending.

3. Design

3.1. AUTHORIZE cell

   The AUTHORIZE cell is a variable-sized cell.

   The generic AUTHORIZE cell format is:

         AuthMethod                       [1 octet]
         MethodFields                     [...]
         PadLen                           [2 octets]
         Padding                          ['PadLen' octets]

   where:

   'AuthMethod', is the authorization method to be used.

   'MethodFields', is dependent on the authorization Method used. It's
                   a meta-field hosting an arbitrary amount of fields.

   'PadLen', specifies the amount of padding in octets.

   'Padding', is 'PadLen' octets of random content.

3.2. AUTHORIZED cell format

   The AUTHORIZED cell is a variable-sized cell.

   The AUTHORIZED cell format is:

         'AuthMethod'                       [1 octet]
         'PadLen'                           [2 octets]
         'Padding'                          ['PadLen' octets]

   where all fields have the same meaning as in section 3.1.

3.3. Cell parsing

   Implementations MUST ignore the contents of 'Padding'.

   Implementations MUST reject an AUTHORIZE or AUTHORIZED cell where
   the 'Padding' field is not 'PadLen' octets long.

   Implementations MUST reject an AUTHORIZE cell with an 'AuthMethod'
   they don't recognize.

4. Discussion

4.1. Why not let the pluggable transports do the padding, like they
     are supposed to do for the rest of the Tor protocol?

   The arguments of section "Alternative design: Just use pluggable
   transports" of proposal 187, apply here as well:

   All bridges who use client authorization will also need camouflaged
   AUTHORIZE/AUTHORIZED cell.

4.2. How should multiple round-trip authorization protocols be handled?

   Protocols that require multiple round-trips between the client and
   the bridge should use AUTHORIZE cells for communication.

   The format of the AUTHORIZE cell is flexible enough to support
   messages from the client to the bridge and the inverse.

   In the end of a successful multiple round-trip protocol, an
   AUTHORIZED cell must be issued from the bridge to the client.

4.3. AUTHORIZED seems useless. Why not use VPADDING instead?

   As noted in proposal 187, the Tor protocol uses VPADDING cells for
   padding; any other use of VPADDING makes the Tor protocol kludgy.

   In the future, and in the example case of a v3 handshake, a client
   can optimistically send a VERSIONS cell along with the final
   AUTHORIZE cell of an authorization protocol. That allows the
   bridge, in the case of successful authorization, to also process
   the VERSIONS cell and begin the v3 handshake promptly.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111106012641</emailId><senderName>Arturo_Filast</senderName><senderEmail>art@baculo.org</senderEmail><timestampReceived>2011-11-06 01:26:41-0400</timestampReceived><subject>[tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

I have made a patch to check.torproject.org to expose a JSONP interface
that would allow people to have the user check client side if (s)he is
using Tor.

This would allow people to embed a badge on their website
(privacybadge.html) that congratulates the user of using Tor or warns
him of non Tor usage with a link to torproject.org.

I can imagine privacy advocates having this deployed on their websites
or systems that engourage users to connect to them anonymously.

Compared to what check.torproject.org does at the moment the risk does
not change, it is erogating exactly the same service, just making it
more useful and flexible.

Basically what it does is check if the ip doing the connection is
connected through Tor. The web service will reply with a JSON encoded
array that can be loaded from the user and display in the browser a nice
looking badge.

You can see how this works on the live demo hosted here:

http://hellais.github.com/torcheck/privacybadge.html

I still need to finish the styling of the badge to contain links to
torproject.org and generally make it cooler.

Also, the check.torproject repo should be moved to svn.

- Art.

["checkbadge.diff" (text/plain)]

Index: privacybadge.html
===================================================================
--- privacybadge.html	(revision 0)
+++ privacybadge.html	(revision 0)
@@ -0,0 +1,44 @@
+&lt;script type="text/javascript" src="http://code.jquery.com/jquery-1.7.min.js"&gt;&lt;/script&gt;
+&lt;script type="text/javascript"&gt;
+        $(document).ready(function() {
+            $("#PrivacyBox").ready(function() {
+                function anonymous(value) {
+                    var box = $('#PrivacyBox');
+                    if (value) {
+                        //box.children("#image").addClass("anonymous");
+                        box.children("#image").replaceWith('&lt;img src="anonymous.png"/&gt;');
+                        box.children("#status").replaceWith('&lt;p id="status"&gt;Anonymous&lt;/p&gt;');
+                    } else {
+                        //box.children("#image").addClass("notanonymous");
+                        box.children("#image").replaceWith('&lt;img src="notanonymous.png"/&gt;');
+
+                        box.children("#status").replaceWith('&lt;p id="status"&gt;Not Anonymous&lt;/p&gt;');
+                    }
+                }
+                if ( $.cookie('privacystatus') ){
+                    console.log("hehe");
+                    if ($.cookie('privacystatus') == "True") {
+                        anonymous(true);
+                    } else {
+                        anonymous(false);
+                    }
+                } else {
+                    $.getJSON('https://check.torproject.org/badge', function(data) {
+                        if (data.Tor) {
+                            anonymous(data.Tor);
+                            $.cookie('privacystatus', 'True', { expires: 1, path: '/' });
+                        } else {
+                            anonymous(data.Tor);
+                            $.cookie('privacystatus', 'False', { expires: 1, path: '/' });
+                        }
+                    });
+                }
+            });
+        });
+&lt;/script&gt;
+&lt;div id="PrivacyBox"&gt;
+    &lt;div id="image"&gt;&lt;/div&gt;
+    &lt;p id="status"&gt;&lt;/p&gt;
+&lt;/div&gt;
+
+
Index: cgi-bin/JSONPCheck.py
===================================================================
--- cgi-bin/JSONPCheck.py	(revision 0)
+++ cgi-bin/JSONPCheck.py	(revision 0)
@@ -0,0 +1,149 @@
+#!/usr/bin/python
+# -*- coding: utf-8 -*-
+"""
+ TorCheck.py
+
+ https://check.torproject.org - originally in perl, rewritten in python
+
+ By Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
+ Written at ToorCon Seattle 2008 (Thanks for the great time h1kari!)
+ Thanks to Crispen for a power outlet :-)
+
+ Additional python suggestions from nickm
+
+ Best used with the Debian packages:
+    python-dns
+    libapache2-mod-python
+    locales-all
+
+"""
+
+__program__ = 'TorCheck.py'
+__version__ = '20100429.01'
+__url__ = 'https://svn.torproject.org/svn/check/'
+__author__ = 'Jacob Appelbaum &lt;jacob@appelbaum.net&gt;'
+__copyright__ = 'Copyright (c) 2008, Jacob Appelbaum'
+__license__ = 'See LICENSE for licensing information'
+
+try:
+    from future import antigravity
+except ImportError:
+    antigravity = None
+
+import cgi
+import DNS
+from DNS import DNSError
+# This is pydns and can be downloaded from http://pydns.sourceforge.net/
+# Or use the Debian package listed above
+import cgitb; cgitb.enable()
+import gettext
+import locale
+import os
+
+#os.environ['LOCPATH']='/usr/share/locale:/srv/check.torproject.org/trunk/i18n/locale'
+localedir ='/srv/check.torproject.org/trunk/i18n/locale'
+
+# We could also explictly query the remote EL server
+# This is not as good as using a cache for obvious reasons
+DNS.DiscoverNameServers()
+
+def isUsingTor(clientIp, ELPort):
+    # This is the exit node ip address
+    # This is where we want to dynamically recieve this from Apache
+    splitIp = clientIp.split('.')
+    splitIp.reverse()
+    ELExitNode = ".".join(splitIp)
+
+    # We'll attempt to reach this port on the Target host
+    # ELPort is now set by the caller
+
+    # We'll try to reach this host
+    ElTarget = "38.229.70.31"
+
+    # This is the ExitList DNS server we want to query
+    ELHost = "ip-port.exitlist.torproject.org"
+
+    # Prepare the question as an A record request
+    ELQuestion = ELExitNode + "." + ELPort + "." + ElTarget + "." + ELHost
+    request = DNS.DnsRequest(name=ELQuestion,qtype='A')
+
+    # Ask the question and load the data into our answer
+    try:
+      answer=request.req()
+    except DNSError:
+      return 2
+
+    # Parse the answer and decide if it's allowing exits
+    # 127.0.0.2 is an exit and NXDOMAIN is not
+    if answer.header['status'] == "NXDOMAIN":
+        # We're not exiting from a Tor exit
+        return 1
+    else:
+        if not answer.answers:
+            # We're getting unexpected data - fail closed
+            return 2
+        for a in answer.answers:
+            if a['data'] != "127.0.0.2":
+                return 2
+        # If we're here, we've had a positive exit answer
+        return 0
+
+
+def isUpToDate(queryString):
+    """
+    determine if TBB is aware of newer versions
+    """
+    if 'uptodate=1' in queryString.lower():
+        return True
+    if 'uptodate=0' in queryString.lower():
+        return False
+    # This will be true until Torbutton 1.4.4 is released
+    if 'small=1' in queryString.lower():
+        return False
+
+    # The default case; No update information to provide
+    return True
+
+def handler(req, environ, start_response):
+    # Make a DNS request to the EL and decide what to tell the user
+    UsingTor = isUsingTor(environ['REMOTE_ADDR'], "80")
+    # Try to hit a cornercase where the user can exit to 443 but not 80
+    if UsingTor != 0:
+        UsingTor = isUsingTor(environ['REMOTE_ADDR'], "443")
+
+    # figure out if the client passed uptodate=0 or uptodate=1
+    # defaults to 1 if uptodate was not present in the query string
+    UpToDate = isUpToDate(environ['QUERY_STRING'])
+
+    response_headers = [('Content-type', 'text/html; charset=utf-8')]
+    start_response('200 OK', response_headers)
+
+    data = cgi.FieldStorage()
+    callback = data.getvalue('callback')
+
+    if callback:
+        if UsingTor == 0:
+            req.write(callback + "({'Tor': True});")
+        # This is the case where we have an NXDOMAIN and they aren't using Tor
+        elif UsingTor == 1:
+            req.write(callback + "({'Tor': False});")
+        # This means we have some strange data response we don't understand
+        # It's better that we fail closed and let the user know everything went wrong
+        elif UsingTor == 2:
+            req.write(callback + "({'Tor': 'Error'});")
+
+    else:
+        req.write("No callback set")
+
+class FakeReq(list):
+    def write(self, str):
+        self.append(str)
+
+def application(environ, start_response):
+    req = FakeReq()
+    handler(req, environ, start_response)
+    return req
+
+# vim:set ts=4:
+# vim:set et:
+# vim:set shiftwidth=4:

Property changes on: cgi-bin/JSONPCheck.py
___________________________________________________________________
Added: svn:executable
   + *



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111107234645</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-07 23:46:45-0400</timestampReceived><subject>[tor-dev] Proposal: Bridge Detection Resistance against</subject><body>



Filename: XXX-mitm-bridge-detection-resistance.txt
Title: Bridge Detection Resistance against MITM-capable Adversaries
Author: George Kadianakis
Created: 07 Nov 2011
Status: Open

1. Overview

   Proposals 187, 189 and 190 make the first steps toward scanning
   resistant bridges. They attempt to block attacks from censoring
   adversaries who provoke bridges into speaking the Tor protocol.

   An attack vector that hasn't been explored in those previous
   proposals is that of an adversary capable of performing Man In The
   Middle attacks to Tor clients. At the moment, Tor clients using the
   v3 link protocol have no way to detect such an MITM attack, and
   will gladly send an VERSIONS or an AUTHORIZE cell to the MITMed
   connection, thereby revealing the Tor protocol and thus the bridge.

   This proposal introduces a way for clients to detect an MITMed SSL
   connection, allowing them to protect against the above attack.

2. Motivation

   When the v3 link handshake protocol is performed, Tor's SSL
   handshake is performed with the server sending a self-signed
   certificate and the client blindly accepting it. This allows the
   adversary to perform an MITM attack.

   A Tor client must detect the MITM attack before he initializes the
   Tor protocol by sending a VERSIONS or an AUTHORIZE cell. A good
   moment to detect such an MITM attack is during the SSL handshake.

   To achieve that, bridge operators provide their bridge users with a
   hash digest of the public-key certificate their bridge is using for
   SSL. Bridge clients store that hash digest locally and associate it
   with that specific bridge. Bridge clients who have "pinned" a
   bridge to a certificate "fingerprint" can thereafter validate that
   their SSL connection peer is the intended bridge.

   Of course, the hash digest must be provided to users out-of-band
   and before the actual SSL handshake. Usually, the bridge operator
   gives the hash digest to her bridge users along with the rest of
   the bridge credentials, like the bridge's address and port.

3. Security implications

   Bridge clients who have pinned a bridge to a certificate
   fingerprint will be able to detect an MITMing adversary in timely
   fashion. If after detection they act as an innocuous Internet
   client, they can successfully remove suspicion from the SSL
   connection and subvert bridge detection.

   Pinning a certificate fingerprint and detecting an MITMing attacker
   does not automatically aleviate suspicions from the bridge or the
   client. Clients must have a behavior to follow after detecting the
   MITM attack so that they look like innocent Netizens. This proposal
   does not try to specify such a behavior.

   Implementation and use of this scheme does not render bridges and
   clients immune to scanning or DPI attacks. This scheme should be
   used along with bridge client authorization schemes like the ones
   detailed in proposal 190.

4. Tor Implementation

4.1. Certificate fingerprint creation

   The certificate fingerprints used on this scheme MUST be computed
   by applying the SHA256 cryptographic hash function upon the ASN.1
   DER encoding of a public-key certificate.

4.2. Bridge side implementation

   Tor bridge implementations SHOULD provide a command line option
   that exports a fully equipped Bridge line containing the bridge
   address and port, the link certificate fingerprint and any other
   enabled Bridge options, so that bridge operators can easily send it
   to their users.

   In the case of expiring SSL certificates, Tor bridge
   implementations SHOULD warn the bridge operator a sensible amount
   of time before the expiration, so that she can warn her clients and
   potentially rotate the certificate herself.

4.3. Client side implementation

   Tor client implementations MUST extend their Bridge line format to
   support bridge SSL certificate fingerprints. The new format is:
     Bridge &lt;method&gt; &lt;address:port&gt; [["keyid="]&lt;id-fingerprint&gt;] \
       ["shared_secret="&lt;shared_secret&gt;] ["link_cert_fpr="&lt;fingerprint&gt;]

   where &lt;fingerprint&gt; is the bridge's SSL certificate fingerprint in
   hexademical encoding.

   Tor clients who use bridges and want to pin their SSL certificates
   must specify the bridge's SSL certificate fingerprint as in:
     Bridge 12.34.56.78 shared_secret=934caff420aa7852b855 \
         link_cert_fpr=38b0712e90bed729df81f2a22811d3dd89e91406d2522f4482ae4079e5245187

4.4. Implementation prerequisites

   Tor bridges currently rotate their SSL certificates every 2
   hours. This not only acts as a fingerprint for the bridges, but it
   also acts as a blocker for this proposal.

   Tor trac ticket #4390 and proposal YYY were created to resolve this
   issue.

5. Acknowledgements

   Thanks to Robert Ransom for his great help and suggestions on
   devising this scheme and writing this proposal!

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111109051557</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-09 05:15:57-0400</timestampReceived><subject>Re: [tor-dev] [Patch] or/eventdns.c</subject><body>

On Wed, Oct 19, 2011 at 3:24 PM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:

Ow.  Sorry for the delay here.  Patches that don't make it onto the
bugtracker tend to drop off my radar far too easily. :(

I can't merge this one because we're trying to minimize drift between
Libevent's evdns.c and Tor's eventdns.c.  Once we (eventually) require
libevent 2.0, we can just throw out our own eventdns.c .  (We can't
easily just grab the evdns.c from Libevent, since it requires Libevent
2.0 in a few really-hard-to-disentangle ways.)

On the other hand, it ought to be worth doing a couple of these
changes for Libevent's dns-sample.c code. I'll apply them there.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111111164657</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-11-11 16:46:57-0400</timestampReceived><subject>[tor-dev] [Patch] test_util.c</subject><body>

Those '{}' constructs are not well liked by MSVC (cl v.16.xx).
An easy fix:

diff --git a/src/test/test_util.c b/src/test/test_util.c
index 2146299..64bf52e 100644
--- a/src/test/test_util.c
+++ b/src/test/test_util.c
@@ -1597,7 +1597,7 @@ test_util_join_win_cmdline(void *ptr)
     {"a\\\\\\b", "de fg", "H", NULL}, // Backslashes
     {"a\\\"b", "\\c", "D\\", NULL}, // Backslashes before quote
     {"a\\\\b c", "d", "E", NULL}, // Backslashes not before quote
-    {} // Terminator
+    { NULL } // Terminator
   };

   const char *cmdlines[] = {
@@ -1649,7 +1649,7 @@ test_util_split_lines(void *ptr)
     {"\n\rfoo\n\rbar\r\n", 12, {"foo", "bar", NULL}},
     {"fo o\r\nb\tar", 10, {"fo o", "b.ar", NULL}},
     {"\x0f""f\0o\0\n\x01""b\0r\0\r", 12, {".f.o.", ".b.r.", NULL}},
-    {NULL, 0, {}}
+    {NULL, 0, { NULL }}
   };

   int i, j;

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111109161224</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-09 16:12:24-0400</timestampReceived><subject>[tor-dev] What Should Tor Bridges and Clients Do When They Get</subject><body>

This is not a proposal.

So, since some people in this list, who are not in IRC, seemed
interested in censorship resistance, I pose this new question: What
should Tor bridges and clients do when they hosed in previous schemes?

All those previous proposals dealed with ways to detect fingerprinting
adversaries, but not with ways to persuade them that what they are
seeing is not Tor. There should be a proposal specifying exactly that,
and this is a discussion thread (even monologue can be considered a
discussion).

Let's start with a quick threat model:

---
We consider a nation-state adversary who:
a) has a list of hosts suspected to be Tor bridges and wants to
   block them without suffering huge false positives.
OR
b) sails the Internet to find Tor bridges.

The adversary is controlling the state's Internet infrastructure
and can inject, modify or block incoming or outgoing traffic.

He can build software that speaks and understands network protocols
but he cannot deploy humans to do the necessary testing.

To complete his goals, the adversary can directly probe hosts to
see what protocol they speak, OR he can MITM all connections
towards those hosts to see what protocol their clients speak.
---

tl;dr we are dealing with MITMs and direct probes here.

Naturally, it would be cool if we could just say "Oh right, all
bridges and clients speak HTTPS in case of detection; all is cool",
but remember that HTTPS is quite hard to spoof right, both in the
server and in the client case [1], especially when it has to be done
in C and in the tor.git codebase.

Ideally, we would want to be as application-layer-neutral [2] as
possible, and with the minimum implementation cost possible.

So let's handle client and bridge cases separately and have a go.

Clients:

Proposal 191 allows clients to detect MITM attempts during the SSL
handshake, this is good because we don't have to pretend speaking a
specific application layer protocol.

I think a good solution would be to send an SSL Alert of "Bad
Certificate" type and close the connection when clients detect an SSL
MITM attempt.

That's what Firefox does when a user selects "Get Me Out Of Here!" on
the self-signed certificate dialog, and that's what all applications
should do (?) when an MITM attack is detected either by certificate or
public-key pinning.

In the future we might also want to send innocuous HTTP queries like
GETting index.html, but we have to be aware of [1].

Bridges:

Bridges have it harder.

Proposal 187, allows bridges to detect probing attempts after the SSL
handshake, when the probing client sends any sort of packet or a badly
formed AUTHORIZE cell.

This forces bridges to respond with an application-layer-specific
message (or close the connection, but that would be rude).

This is where I'm not sure what should be done.

I think all implementations MUST provide a way for the bridge operator
to configure a network service of his own (FTPS, HTTPS, SMTPS, etc.)
and have the bridge send all the adversary traffic to that service.

That should do it for technical bridge operators, but there probably
should also be something on by default, for bridge operators who don't
know how to setup net services on their own.

The easy choice is an "HTTPS" server with the default Apache "It
Works!", or a closed basic access authentication, but really
implementing a spoofed HTTPS server in tor will be a PITA, because
censors can easily test us by provoking one of [0] (there is a reason
that HTTP servers usually require lots of LoCs to work).

Maybe we should ship a configured Apache server with the long-term
future "Anti-censorship Tor Bundle"?

Also, what happens to Tor on Linux when it can't listen on port 443?
Or when port 443 is already taken? HTTPS servers on 9001 sure look
sketchy.

Any ideas are welcome.

Any services widely used, frequently seen with SSL support, that
handle traffic that kinda looks like Tor's and are easily
implementable, are also welcome.


[0]: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
[1]: https://en.wikipedia.org/wiki/List_of_HTTP_header_fields
     https://trac.torproject.org/projects/tor/ticket/2907
[2]: Let's place SSL on the transport layer for now.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108075534</emailId><senderName>Jrmy Bobbio</senderName><senderEmail>lunar@debian.org</senderEmail><timestampReceived>2011-11-08 07:55:34-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance against</subject><body>

[Attachment #2 (multipart/signed)]


On Tue, Nov 08, 2011 at 12:46:45AM +0100, George Kadianakis wrote:
&gt;    Tor clients who use bridges and want to pin their SSL certificates
&gt;    must specify the bridge's SSL certificate fingerprint as in:
&gt;      Bridge 12.34.56.78 shared_secret=934caff420aa7852b855 \
&gt;          link_cert_fpr=38b0712e90bed729df81f2a22811d3dd89e91406d2522f4482ae4079e5245187

This starts to look like a lot of numbers. The kind that will be hard to
hand out on paper without making a mistake

Supporting paper and pen as a way to give out bridges is even more
likely to be important in areas where a powerful entity is actively
trying to enumerate all bridges (and thus can do MITM). Also think about
users of epheremal systems (Tails) which needs to type bridge
informations at every boot.


How about using base32 instead of hex? The former means shorter strings
and disambiguate 'l' &amp; '1' and '0' &amp; 'o'.

Is it really needed to have such a long number as a fingerprint?


My 2 cents,
-- 
Jrmy Bobbio                        .''`. 
lunar@debian.org                    : :  :  # apt-get install anarchism
                                    `. `'` 
                                      `-   

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111117001120</emailId><senderName>Qiang Wang</senderName><senderEmail>wangq1979@gmail.com</senderEmail><timestampReceived>2011-11-17 00:11:20-0400</timestampReceived><subject>[tor-dev] About JTor project</subject><body>

[Attachment #2 (multipart/alternative)]


Hello there,

I am very interested in Tor project, and I want to contribute something to
it. In particular, I'd like to work on JTor. Could anyone tell me whom I
can contact with for further information regarding getting involved in?

-- 

Thanks &amp; best regards

Qiang Wang

[Attachment #5 (text/html)]

Hello there,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am very interested in Tor project, and I want to \
contribute something to it. In particular, I'd like to work on JTor. Could anyone \
tell me whom I can contact with for further information regarding getting involved \
in?&lt;br clear="all"&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;-- &lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;Thanks &amp; best \
regards&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Qiang Wang&lt;/div&gt;&lt;br&gt; &lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111117002646</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2011-11-17 00:26:46-0400</timestampReceived><subject>Re: [tor-dev] About JTor project</subject><body>

&gt; I am very interested in Tor project, and I want to contribute something to
&gt; it. In particular, I'd like to work on JTor. Could anyone tell me whom I can
&gt; contact with for further information regarding getting involved in?

Hi Qiang. Glad you want to help! JTor has been without a maintainer
for quite a while so the project's author, Bruce (cc-ed), will be your
best bet if you have questions or need a mentor. If you're interested
in java projects in general then Orbot and Metrics are both java
codebases as well.

Cheers! -Damian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108112837</emailId><senderName>Julian Yon</senderName><senderEmail>julian@yon.org.uk</senderEmail><timestampReceived>2011-11-08 11:28:37-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance against</subject><body>

[Attachment #2 (multipart/signed)]


On 08/11/11 07:55, Jrmy Bobbio wrote:
&gt; On Tue, Nov 08, 2011 at 12:46:45AM +0100, George Kadianakis wrote:
&gt;&gt;    Tor clients who use bridges and want to pin their SSL certificates
&gt;&gt;    must specify the bridge's SSL certificate fingerprint as in:
&gt;&gt;      Bridge 12.34.56.78 shared_secret=934caff420aa7852b855 \
&gt;&gt;          link_cert_fpr=38b0712e90bed729df81f2a22811d3dd89e91406d2522f4482ae4079e5245187
&gt; 
&gt; This starts to look like a lot of numbers. The kind that will be hard to
&gt; hand out on paper without making a mistake

In another thread (admittedly the wrong thread), there was brief
discussion around the idea of using some sort of covert
challenge/response handshake where the bridge proved that it knew the
connection's SSL fingerprint. This would avoid having to distribute the
fingerprint itself. George had some concerns about this but it wasn't
clear whether he was intending to write the idea off entirely or whether
there was room to explore it further.


Julian

-- 
3072D/D2DE707D Julian Yon (2011 General Use) &lt;pgp.2011@jry.me&gt;


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111108153644</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-08 15:36:44-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance against</subject><body>

Julian Yon &lt;julian@yon.org.uk&gt; writes:

&gt; On 08/11/11 07:55, Jrmy Bobbio wrote:
&gt;&gt; On Tue, Nov 08, 2011 at 12:46:45AM +0100, George Kadianakis wrote:
&gt;&gt;&gt;    Tor clients who use bridges and want to pin their SSL certificates
&gt;&gt;&gt;    must specify the bridge's SSL certificate fingerprint as in:
&gt;&gt;&gt;      Bridge 12.34.56.78 shared_secret=934caff420aa7852b855 \
&gt;&gt;&gt;          link_cert_fpr=38b0712e90bed729df81f2a22811d3dd89e91406d2522f4482ae4079e5245187
&gt;&gt; 
&gt;&gt; This starts to look like a lot of numbers. The kind that will be hard to
&gt;&gt; hand out on paper without making a mistake
&gt;
&gt; In another thread (admittedly the wrong thread), there was brief
&gt; discussion around the idea of using some sort of covert
&gt; challenge/response handshake where the bridge proved that it knew the
&gt; connection's SSL fingerprint. This would avoid having to distribute the
&gt; fingerprint itself. 

Hi there,

I was not aware that the volume of the bridge credentials is an actual
concern. I assumed that most people just receive the credentials
through the Internet and copy/paste them to their torrc. With that in
mind, I thought that passing an extra hash to the bridge user, and
avoiding the need for steganography magic, is a better idea.

Still, I can truncate the fingerprint to something like 12 bytes and
use base32 so that it becomes more manageable. It will look like this:
'GM4GEMBXGEZGKOJQMJSWINZSHFSGMOBRMYZGCMQ='

It's not terribly bad. I'll update the proposal.

&gt;                     George had some concerns about this but it wasn't
&gt; clear whether he was intending to write the idea off entirely or whether
&gt; there was room to explore it further.
&gt;
&gt;
&gt; Julian

By the way, I'm not completely rejecting the tagging idea yet since
it:
a) needs no extra bridge credentials apart from the shared secret of prop190.
b) doesn't need any maintenance in case of certificate expiration.

Some arguments to consider against the tagging idea are:
a) In the case of self-signed certificates, OpenSSL creates an 8-bytes
random Serial number, and we would probably need something more than
8-bytes to tag. We might want to explore some x509v3 extensions like
the "X509v3 {Subject,Authority} Key Identifier", which OpenSSL also
sets by default.
b) It complicates the scheme, and if not implemented/researched wisely
it might make the scheme fingerprintable as well.
c) We most probably won't be able to tag CA-signed certificates.

The whole idea is to find a nice place on the certificate to stick a
(possibly truncated) HMAC of the link public key, using the prop190
shared secret as the key.

I will probably also mention this idea in the proposal, so that we can
get some more opinions out of people; hoping that when the time for
implementation comes we will know what to do.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111106191038</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-11-06 19:10:38-0400</timestampReceived><subject>Re: [tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

On 11/05/2011 06:26 PM, Arturo Filast=F2 wrote:
&gt; I have made a patch to check.torproject.org to expose a JSONP interface
&gt; that would allow people to have the user check client side if (s)he is
&gt; using Tor.
&gt; =

&gt; This would allow people to embed a badge on their website
&gt; (privacybadge.html) that congratulates the user of using Tor or warns
&gt; him of non Tor usage with a link to torproject.org.
&gt; =

&gt; I can imagine privacy advocates having this deployed on their websites
&gt; or systems that engourage users to connect to them anonymously.
&gt; =

&gt; Compared to what check.torproject.org does at the moment the risk does
&gt; not change, it is erogating exactly the same service, just making it
&gt; more useful and flexible.
&gt; =

&gt; Basically what it does is check if the ip doing the connection is
&gt; connected through Tor. The web service will reply with a JSON encoded
&gt; array that can be loaded from the user and display in the browser a nice
&gt; looking badge.
&gt; =


I think this is a fine idea - it reminds me of the only IPv6 demo turtle.

I think it's quite ironic to use these technologies to encourage people
to deploy real privacy solutions.

&gt; You can see how this works on the live demo hosted here:
&gt; =

&gt; http://hellais.github.com/torcheck/privacybadge.html

I'd suggest that it have an onion and say "You're using Tor" or
something similar - it might also make sense to put it in the web 2.0
web badge format that many companies use.

&gt; =

&gt; I still need to finish the styling of the badge to contain links to
&gt; torproject.org and generally make it cooler.
&gt; =

&gt; Also, the check.torproject repo should be moved to svn.
&gt; =


Isn't it already in svn? Shouldn't we move it to git?

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108082903</emailId><senderName>"warms0x"</senderName><senderEmail>warms0x@riseup.net</senderEmail><timestampReceived>2011-11-08 08:29:03-0400</timestampReceived><subject>Re: [tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

&gt; On 11/05/2011 06:26 PM, Arturo Filast wrote:
&gt;&gt; I have made a patch to check.torproject.org to expose a JSONP interface
&gt;&gt; that would allow people to have the user check client side if (s)he is
&gt;&gt; using Tor.
&gt;&gt;
&gt;&gt; This would allow people to embed a badge on their website
&gt;&gt; (privacybadge.html) that congratulates the user of using Tor or warns
&gt;&gt; him of non Tor usage with a link to torproject.org.
&gt;&gt;
&gt;&gt; I can imagine privacy advocates having this deployed on their websites
&gt;&gt; or systems that engourage users to connect to them anonymously.
&gt;&gt;
&gt;&gt; Compared to what check.torproject.org does at the moment the risk does
&gt;&gt; not change, it is erogating exactly the same service, just making it
&gt;&gt; more useful and flexible.
&gt;&gt;
&gt;&gt; Basically what it does is check if the ip doing the connection is
&gt;&gt; connected through Tor. The web service will reply with a JSON encoded
&gt;&gt; array that can be loaded from the user and display in the browser a nice
&gt;&gt; looking badge.
&gt;&gt;
&gt;
&gt; I think this is a fine idea - it reminds me of the only IPv6 demo turtle.
&gt;
&gt; I think it's quite ironic to use these technologies to encourage people
&gt; to deploy real privacy solutions.


I also like the idea, but I immediately thought of nefarious uses for such
an API. No more nefarious than what one can do with a proper list of exit
nodes I suppose.

Is there any general difference between having a queryable API to
determine if a client is using Tor and the periodic fetching of the list
of exit nodes?

Apologies if this isn't a particularly -dev-like question, I'm still fresh
on a lot of the Tor internals and I'm still not sure what data is public
versus protected.


Cheers.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111108085326</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-11-08 08:53:26-0400</timestampReceived><subject>Re: [tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

On 11/08/2011 12:29 AM, warms0x wrote:
&gt;&gt; On 11/05/2011 06:26 PM, Arturo Filast wrote:
&gt;&gt;&gt; I have made a patch to check.torproject.org to expose a JSONP interface
&gt;&gt;&gt; that would allow people to have the user check client side if (s)he is
&gt;&gt;&gt; using Tor.
&gt;&gt;&gt;
&gt;&gt;&gt; This would allow people to embed a badge on their website
&gt;&gt;&gt; (privacybadge.html) that congratulates the user of using Tor or warns
&gt;&gt;&gt; him of non Tor usage with a link to torproject.org.
&gt;&gt;&gt;
&gt;&gt;&gt; I can imagine privacy advocates having this deployed on their websites
&gt;&gt;&gt; or systems that engourage users to connect to them anonymously.
&gt;&gt;&gt;
&gt;&gt;&gt; Compared to what check.torproject.org does at the moment the risk does
&gt;&gt;&gt; not change, it is erogating exactly the same service, just making it
&gt;&gt;&gt; more useful and flexible.
&gt;&gt;&gt;
&gt;&gt;&gt; Basically what it does is check if the ip doing the connection is
&gt;&gt;&gt; connected through Tor. The web service will reply with a JSON encoded
&gt;&gt;&gt; array that can be loaded from the user and display in the browser a nice
&gt;&gt;&gt; looking badge.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; I think this is a fine idea - it reminds me of the only IPv6 demo turtle.
&gt;&gt;
&gt;&gt; I think it's quite ironic to use these technologies to encourage people
&gt;&gt; to deploy real privacy solutions.
&gt; 
&gt; 
&gt; I also like the idea, but I immediately thought of nefarious uses for such
&gt; an API. No more nefarious than what one can do with a proper list of exit
&gt; nodes I suppose.

It is a real time version of this - powered by... a Tor client. :)

&gt; 
&gt; Is there any general difference between having a queryable API to
&gt; determine if a client is using Tor and the periodic fetching of the list
&gt; of exit nodes?
&gt; 

No, not for a user who is using Tor - the exiting from the network is
generally considered "Tor" and we've supported this to help quash crappy
attempts:
https://check.torproject.org/cgi-bin/TorBulkExitList.py

(note the svn link, it's actually code anyone may run)

In other words, we'd like everyone to enter the Tor network - we won't
help block _entry_ into Tor. But generally, it's OK if some people block
Tor exits as the anonymous user can just go somewhere else...

&gt; Apologies if this isn't a particularly -dev-like question, I'm still fresh
&gt; on a lot of the Tor internals and I'm still not sure what data is public
&gt; versus protected

It's not private information.

The biggest problem with this proposal is simply that many people may
use it and it will generate a lot of load.

All the best,
Jacob
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111108090156</emailId><senderName>"warms0x"</senderName><senderEmail>warms0x@riseup.net</senderEmail><timestampReceived>2011-11-08 09:01:56-0400</timestampReceived><subject>Re: [tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

(Off-list reply to avoid unnecessary archive bits :))


Thanks for the clarification, I wasn't even aware of the bulk exit exporter!


Cheers.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104211016</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-04 21:10:16-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

On 2011-11-04, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt;
&gt; Filename: 189-authorize-cell.txt
&gt; Title: AUTHORIZE and AUTHORIZED cells
&gt; Author: George Kadianakis
&gt; Created: 04 Nov 2011
&gt; Status: Open
&gt;
&gt; 1. Overview
&gt;
&gt;    Proposal 187 introduced the concept of the AUTHORIZE cell, a cell
&gt;    whose purpose is to make Tor bridges resistant to scanning attacks.
&gt;
&gt;    This is achieved by having the bridge and the client share a secret
&gt;    out-of-band and then use AUTHORIZE cells to validate that the
&gt;    client indeed knows that secret before proceeding with the Tor
&gt;    protocol.
&gt;
&gt;    This proposal specifies the format of the AUTHORIZE cell and also
&gt;    introduces the AUTHORIZED cell, a way for bridges to announce to
&gt;    clients that the authorization process is complete and successful.
&gt;
&gt; 2. Motivation
&gt;
&gt;    AUTHORIZE cells should be able to perform a variety of
&gt;    authorization protocols based on a variety of shared secrets. This
&gt;    forces the AUTHORIZE cell to have a dynamic format based on the
&gt;    authorization method used.
&gt;
&gt;    AUTHORIZED cells are used by bridges to signal the end of a
&gt;    successful bridge client authorization and the beginning of the
&gt;    actual link handshake. AUTHORIZED cells have no other use and for
&gt;    this reason their format is very simple.
&gt;
&gt;    Both AUTHORIZE and AUTHORIZED cells are to be used under censorship
&gt;    conditions and they should look innocuous to any adversary capable
&gt;    of monitoring network traffic.

I wrote the following in my reply to proposal 190, but it probably
belongs here instead:

| An adversary who MITMs the TLS connection and receives a Tor AUTHORIZE
| cell will know that the client is trying to connect to a Tor bridge.
|
| Should the client send a string of the form "GET
| /?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
| cell, where "correct+horse+battery+staple" is a semi-plausible search
| phrase derived from the HMAC in some way?


&gt;    As an attack example, an adversary could passively monitor the
&gt;    traffic of a bridge host, looking at the packets directly after the
&gt;    TLS handshake and trying to deduce from their packet size if they
&gt;    are AUTHORIZE and AUTHORIZED cells. For this reason, AUTHORIZE and
&gt;    AUTHORIZED cells are padded with a random amount of padding before
&gt;    sending.

What distribution should this 'random amount' be chosen from?


&gt; 3. Design
&gt;
&gt; 3.1. AUTHORIZE cell
&gt;
&gt;    The AUTHORIZE cell is a variable-sized cell.
&gt;
&gt;    The generic AUTHORIZE cell format is:
&gt;
&gt;          AuthMethod                       [1 octet]
&gt;          MethodFields                     [...]
&gt;          PadLen                           [2 octets]
&gt;          Padding                          ['PadLen' octets]
&gt;
&gt;    where:
&gt;
&gt;    'AuthMethod', is the authorization method to be used.
&gt;
&gt;    'MethodFields', is dependent on the authorization Method used. It's
&gt;                    a meta-field hosting an arbitrary amount of fields.
&gt;
&gt;    'PadLen', specifies the amount of padding in octets.
&gt;
&gt;    'Padding', is 'PadLen' octets of random content.
&gt;
&gt; 3.2. AUTHORIZED cell format
&gt;
&gt;    The AUTHORIZED cell is a variable-sized cell.
&gt;
&gt;    The AUTHORIZED cell format is:
&gt;
&gt;          'AuthMethod'                       [1 octet]
&gt;          'PadLen'                           [2 octets]
&gt;          'Padding'                          ['PadLen' octets]
&gt;
&gt;    where all fields have the same meaning as in section 3.1.
&gt;
&gt; 3.3. Cell parsing
&gt;
&gt;    Implementations MUST ignore the contents of 'Padding'.
&gt;
&gt;    Implementations MUST reject an AUTHORIZE or AUTHORIZED cell where
&gt;    the 'Padding' field is not 'PadLen' octets long.
&gt;
&gt;    Implementations MUST reject an AUTHORIZE cell with an 'AuthMethod'
&gt;    they don't recognize.

What does "reject" mean here?


&gt; 4. Discussion
&gt;
&gt; 4.1. Why not let the pluggable transports do the padding, like they
&gt;      are supposed to do for the rest of the Tor protocol?
&gt;
&gt;    The arguments of section "Alternative design: Just use pluggable
&gt;    transports" of proposal 187, apply here as well:
&gt;
&gt;    All bridges who use client authorization will also need camouflaged
&gt;    AUTHORIZE/AUTHORIZED cell.

What does "camouflaged" mean here?


&gt; 4.2. How should multiple round-trip authorization protocols be handled?

s/multiple round/multiple-round/ # it's part of a phrase acting as an
ad-something

&gt;    Protocols that require multiple round-trips between the client and
&gt;    the bridge should use AUTHORIZE cells for communication.

.-1s/round-trips/round trips/ # it's part of a top-level noun phrase

&gt;    The format of the AUTHORIZE cell is flexible enough to support
&gt;    messages from the client to the bridge and the inverse.

s/inverse/reverse/

When can an AUTHORIZE cell be sent, and by whom?

Can a bridge which requires client authorization perform reachability
and bandwidth self-tests?  If so, how?


&gt;    In the end of a successful multiple round-trip protocol, an
&gt;    AUTHORIZED cell must be issued from the bridge to the client.

.-1s/multiple round/multiple-round/ # it's part of a phrase acting as
an ad-something
s/In/At/

&gt; 4.3. AUTHORIZED seems useless. Why not use VPADDING instead?
&gt;
&gt;    As noted in proposal 187, the Tor protocol uses VPADDING cells for
&gt;    padding; any other use of VPADDING makes the Tor protocol kludgy.
&gt;
&gt;    In the future, and in the example case of a v3 handshake, a client
&gt;    can optimistically send a VERSIONS cell along with the final
&gt;    AUTHORIZE cell of an authorization protocol. That allows the
&gt;    bridge, in the case of successful authorization, to also process
&gt;    the VERSIONS cell and begin the v3 handshake promptly.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104213701</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-04 21:37:01-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

On Fri, Nov 4, 2011 at 4:10 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On 2011-11-04, George Kadianakis &lt;desnacked@gmail.com&gt; wrote:
&gt;&gt;
&gt;&gt; Filename: 189-authorize-cell.txt
&gt;&gt; Title: AUTHORIZE and AUTHORIZED cells
&gt;&gt; Author: George Kadianakis
&gt;&gt; Created: 04 Nov 2011
&gt;&gt; Status: Open
&gt;&gt;
&gt;&gt; 1. Overview
&gt;&gt;
&gt;&gt;    Proposal 187 introduced the concept of the AUTHORIZE cell, a cell
&gt;&gt;    whose purpose is to make Tor bridges resistant to scanning attacks.
&gt;&gt;
&gt;&gt;    This is achieved by having the bridge and the client share a secret
&gt;&gt;    out-of-band and then use AUTHORIZE cells to validate that the
&gt;&gt;    client indeed knows that secret before proceeding with the Tor
&gt;&gt;    protocol.
&gt;&gt;
&gt;&gt;    This proposal specifies the format of the AUTHORIZE cell and also
&gt;&gt;    introduces the AUTHORIZED cell, a way for bridges to announce to
&gt;&gt;    clients that the authorization process is complete and successful.
&gt;&gt;
&gt;&gt; 2. Motivation
&gt;&gt;
&gt;&gt;    AUTHORIZE cells should be able to perform a variety of
&gt;&gt;    authorization protocols based on a variety of shared secrets. This
&gt;&gt;    forces the AUTHORIZE cell to have a dynamic format based on the
&gt;&gt;    authorization method used.
&gt;&gt;
&gt;&gt;    AUTHORIZED cells are used by bridges to signal the end of a
&gt;&gt;    successful bridge client authorization and the beginning of the
&gt;&gt;    actual link handshake. AUTHORIZED cells have no other use and for
&gt;&gt;    this reason their format is very simple.
&gt;&gt;
&gt;&gt;    Both AUTHORIZE and AUTHORIZED cells are to be used under censorship
&gt;&gt;    conditions and they should look innocuous to any adversary capable
&gt;&gt;    of monitoring network traffic.
&gt;
&gt; I wrote the following in my reply to proposal 190, but it probably
&gt; belongs here instead:
&gt;
&gt; | An adversary who MITMs the TLS connection and receives a Tor AUTHORIZE
&gt; | cell will know that the client is trying to connect to a Tor bridge.
&gt; |
&gt; | Should the client send a string of the form "GET
&gt; | /?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
&gt; | cell, where "correct+horse+battery+staple" is a semi-plausible search
&gt; | phrase derived from the HMAC in some way?

Seems to me at that point we are hosed anyway. If you see
correct+horse+battery+staple
and the response is garbled data, not an HTTP response, its probably
something unusual.
Bridge descriptors should include enough information for Tor to ensure
that the TLS connection is
safe. If we are protecting against passive scanning then we just need
to make it look like a webserver. One good way of doing that: ask
people who have webservers to run bridges, and have Tor simply pass
any confused HTTP requests to the actual webserver. (These shouldn't
be popular sites)
Sincerely,
Watson Ladd
-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111105010102</emailId><senderName>Julian Yon</senderName><senderEmail>julian@yon.org.uk</senderEmail><timestampReceived>2011-11-05 01:01:02-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

[Attachment #2 (multipart/signed)]


On 04/11/11 21:37, Watson Ladd wrote:
&gt; On Fri, Nov 4, 2011 at 4:10 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt;&gt; | Should the client send a string of the form "GET
&gt;&gt; | /?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
&gt;&gt; | cell, where "correct+horse+battery+staple" is a semi-plausible search
&gt;&gt; | phrase derived from the HMAC in some way?
&gt; 
&gt; Seems to me at that point we are hosed anyway. If you see
&gt; correct+horse+battery+staple
&gt; and the response is garbled data, not an HTTP response, its probably
&gt; something unusual.
&gt; Bridge descriptors should include enough information for Tor to ensure
&gt; that the TLS connection is safe.

What if the GET request can be anything innocuous (e.g. robots.txt,
index.html) and a valid document is sent back. But the headers include
an ETag derived in some way from the document content (or just the URL),
the shared secret and the bridge's TLS cert. If there's a MITM then the
client will compute a different ETag (due to the wrong cert) and can
close the connection. Otherwise it can immediately initiate the full
authorisation sequence.

(NB. I'm not a cryptographer; feel free to tell me where the flaw in my
logic lies)

Julian

-- 
3072D/D2DE707D Julian Yon (2011 General Use) &lt;pgp.2011@jry.me&gt;


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111105021945</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-05 02:19:45-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

On Fri, Nov 4, 2011 at 8:01 PM, Julian Yon &lt;julian@yon.org.uk&gt; wrote:
&gt; On 04/11/11 21:37, Watson Ladd wrote:
&gt;&gt; On Fri, Nov 4, 2011 at 4:10 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt;&gt;&gt; | Should the client send a string of the form "GET
&gt;&gt;&gt; | /?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
&gt;&gt;&gt; | cell, where "correct+horse+battery+staple" is a semi-plausible search
&gt;&gt;&gt; | phrase derived from the HMAC in some way?
&gt;&gt;
&gt;&gt; Seems to me at that point we are hosed anyway. If you see
&gt;&gt; correct+horse+battery+staple
&gt;&gt; and the response is garbled data, not an HTTP response, its probably
&gt;&gt; something unusual.
&gt;&gt; Bridge descriptors should include enough information for Tor to ensure
&gt;&gt; that the TLS connection is safe.
&gt;
&gt; What if the GET request can be anything innocuous (e.g. robots.txt,
&gt; index.html) and a valid document is sent back. But the headers include
&gt; an ETag derived in some way from the document content (or just the URL),
&gt; the shared secret and the bridge's TLS cert. If there's a MITM then the
&gt; client will compute a different ETag (due to the wrong cert) and can
&gt; close the connection. Otherwise it can immediately initiate the full
&gt; authorisation sequence.
&gt;
&gt; (NB. I'm not a cryptographer; feel free to tell me where the flaw in my
&gt; logic lies)

ETag is a great idea. We can then have bridges run their own web
content or specify a page to serve up (with suitably redirected links)
or forwards real requests to an actual webserver. This
way every bridge can hide differently: serving tor.eff.org everywhere
would be a dead giveaway.

Sincerely,
Watson Ladd
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111105032155</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-05 03:21:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

Julian Yon &lt;julian@yon.org.uk&gt; writes:

&gt; On 04/11/11 21:37, Watson Ladd wrote:
&gt;&gt; On Fri, Nov 4, 2011 at 4:10 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt;&gt;&gt; | Should the client send a string of the form "GET
&gt;&gt;&gt; | /?q=correct+horse+battery+staple\r\n\r\n" instead of an AUTHORIZE
&gt;&gt;&gt; | cell, where "correct+horse+battery+staple" is a semi-plausible search
&gt;&gt;&gt; | phrase derived from the HMAC in some way?
&gt;&gt; 
&gt;&gt; Seems to me at that point we are hosed anyway. If you see
&gt;&gt; correct+horse+battery+staple
&gt;&gt; and the response is garbled data, not an HTTP response, its probably
&gt;&gt; something unusual.
&gt;&gt; Bridge descriptors should include enough information for Tor to ensure
&gt;&gt; that the TLS connection is safe.
&gt;
&gt; What if the GET request can be anything innocuous (e.g. robots.txt,
&gt; index.html) and a valid document is sent back. But the headers include
&gt; an ETag derived in some way from the document content (or just the URL),
&gt; the shared secret and the bridge's TLS cert. If there's a MITM then the
&gt; client will compute a different ETag (due to the wrong cert) and can
&gt; close the connection. Otherwise it can immediately initiate the full
&gt; authorisation sequence.
&gt;
&gt; (NB. I'm not a cryptographer; feel free to tell me where the flaw in my
&gt; logic lies)
&gt;
&gt; Julian

There are some things in these HTTP solutions that make me nervous.

In the "GET /?q=correct+horse+battery+staple\r\n\r\n" client-side case
we will have to build HTTP header spoofing into the tor client, which
is not fun since modern browsers send loads of HTTP headers in their
first GET.

In the Etags/Cookies/whatever server-side case we will probably have
to build some sort of 'valid document'/'innocuous webpage' generator
into the Tor bridge, which is also not fun. Fortunately, we might be
able to reuse such a construction when Bridge Passwords fail:
https://lists.torproject.org/pipermail/tor-dev/2011-October/002996.html

Still, I would very much enjoy if we could find a way to authenticate
the bridge using the shared secret without relying on HTTP covert
channel wizardry. 

I've been thinking of having bridges that use Bridge Passwords, "tag"
their SSL certificate, say the Serial Number, with their password, and
have clients validate them before proceeding with AUTHORIZE cells.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111105043531</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-11-05 04:35:31-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

On 11/04/2011 09:19 PM, Watson Ladd wrote:
&gt; On Fri, Nov 4, 2011 at 8:01 PM, Julian Yon&lt;julian@yon.org.uk&gt;  wrote:
&gt; &gt; 
&gt; &gt; What if the GET request can be anything innocuous (e.g. robots.txt,
&gt; &gt; index.html) and a valid document is sent back. But the headers include
&gt; &gt; an ETag derived in some way from the document content (or just the URL),
&gt; &gt; the shared secret and the bridge's TLS cert. If there's a MITM then the
&gt; &gt; client will compute a different ETag (due to the wrong cert) and can
&gt; &gt; close the connection. Otherwise it can immediately initiate the full
&gt; &gt; authorisation sequence.
&gt; 
&gt; ETag is a great idea. We can then have bridges run their own web
&gt; content or specify a page to serve up (with suitably redirected links)
&gt; or forwards real requests to an actual webserver. This
&gt; way every bridge can hide differently: serving tor.eff.org everywhere
&gt; would be a dead giveaway.

I love this line of thinking. But what if the MitM calls your bluff and 
returns his own cookie, ETag header and a 302 Redirect to the same page? 
What would the client do then? If the client did observe the redirect as 
a browser would, he may be unable to try again for some time. Otherwise, 
it would tend to confirm the status of the server as a Tor node.

Seems like what we want is like TLS channel bindings to detect the MitM. 
This is standardized. http://tools.ietf.org/html/rfc5056
Microsoft IE+IIS implemented it, it thwarts their MitM tool:
&gt; http://blogs.msdn.com/b/fiddler/archive/2010/10/15/fiddler-https-decryption-and-channel-binding-token-authentication-problems.aspx
&gt; 

Tossing out an idea here: maybe this would work better backwards.

What if the client were to choose any innocuous-looking URL to request 
before initiating the handshake? Then he could bury an HMAC for a 
message including that URL in the TLS client_hello.random. The HMAC key 
could derived from the AUTHORIZE secret.

The client_random is supposed to contain a (generous) 28 random bytes 
transmitted in the clear. AFAICT, it's mainly to prevent replay attacks 
and is most important in special cases like session resumption and certs 
with fixed DH parameters. The encrypted premaster secret adds 
significant client-supplied entropy to the handshake too. Replacing some 
of the true random bytes with an HMAC formed from a secret key should 
not reduce the entropy (as perceived by the active attacker) too much I 
think.

The message input to the HMAC should probably include the rest of the 
client_random.

The client could also include some unpredictable stuff in the request 
(e.g., some meaningless cookies). This could prevent any net 
unpredictability loss in the client_random, so even if an attacker knew 
the AUTHORIZE secret it would not enable any additional attacks on the 
TLS handshake.

I would like other people to double-check my reasoning on this obviously.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111105060154</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-05 06:01:54-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

On Fri, Nov 4, 2011 at 11:35 PM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt; On 11/04/2011 09:19 PM, Watson Ladd wrote:
&gt; &gt; 
&gt; &gt; On Fri, Nov 4, 2011 at 8:01 PM, Julian Yon&lt;julian@yon.org.uk&gt;  wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; What if the GET request can be anything innocuous (e.g. robots.txt,
&gt; &gt; &gt; index.html) and a valid document is sent back. But the headers include
&gt; &gt; &gt; an ETag derived in some way from the document content (or just the URL),
&gt; &gt; &gt; the shared secret and the bridge's TLS cert. If there's a MITM then the
&gt; &gt; &gt; client will compute a different ETag (due to the wrong cert) and can
&gt; &gt; &gt; close the connection. Otherwise it can immediately initiate the full
&gt; &gt; &gt; authorisation sequence.
&gt; &gt; 
&gt; &gt; ETag is a great idea. We can then have bridges run their own web
&gt; &gt; content or specify a page to serve up (with suitably redirected links)
&gt; &gt; or forwards real requests to an actual webserver. This
&gt; &gt; way every bridge can hide differently: serving tor.eff.org everywhere
&gt; &gt; would be a dead giveaway.
&gt; 
&gt; I love this line of thinking. But what if the MitM calls your bluff and
&gt; returns his own cookie, ETag header and a 302 Redirect to the same page?
&gt; What would the client do then? If the client did observe the redirect as a
&gt; browser would, he may be unable to try again for some time. Otherwise, it
&gt; would tend to confirm the status of the server as a Tor node.
&gt; 
&gt; Seems like what we want is like TLS channel bindings to detect the MitM.
&gt; This is standardized. http://tools.ietf.org/html/rfc5056
&gt; Microsoft IE+IIS implemented it, it thwarts their MitM tool:
&gt; &gt; 
&gt; &gt; 
&gt; &gt; http://blogs.msdn.com/b/fiddler/archive/2010/10/15/fiddler-https-decryption-and-channel-binding-token-authentication-problems.aspx
&gt; &gt; 
&gt; 
&gt; Tossing out an idea here: maybe this would work better backwards.
&gt; 
&gt; What if the client were to choose any innocuous-looking URL to request
&gt; before initiating the handshake? Then he could bury an HMAC for a message
&gt; including that URL in the TLS client_hello.random. The HMAC key could
&gt; derived from the AUTHORIZE secret.
I don't know enough aboutTLS to comment on this. But I do know Telex
used a covert channel in TLS to good effect. Maybe we can do some kind
of similar stunt.
&gt; 
&gt; The client_random is supposed to contain a (generous) 28 random bytes
&gt; transmitted in the clear. AFAICT, it's mainly to prevent replay attacks and
&gt; is most important in special cases like session resumption and certs with
&gt; fixed DH parameters. The encrypted premaster secret adds significant
&gt; client-supplied entropy to the handshake too. Replacing some of the true
&gt; random bytes with an HMAC formed from a secret key should not reduce the
&gt; entropy (as perceived by the active attacker) too much I think.
&gt; 
&gt; The message input to the HMAC should probably include the rest of the
&gt; client_random.
&gt; 
&gt; The client could also include some unpredictable stuff in the request (e.g.,
&gt; some meaningless cookies). This could prevent any net unpredictability loss
&gt; in the client_random, so even if an attacker knew the AUTHORIZE secret it
&gt; would not enable any additional attacks on the TLS handshake.
&gt; 
&gt; I would like other people to double-check my reasoning on this obviously.
&gt; 
&gt; - Marsh
&gt; 



-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111105143109</emailId><senderName>Julian Yon</senderName><senderEmail>julian@yon.org.uk</senderEmail><timestampReceived>2011-11-05 14:31:09-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

[Attachment #2 (multipart/signed)]


On 05/11/11 03:21, George Kadianakis wrote:
&gt; There are some things in these HTTP solutions that make me nervous.
&gt; 
&gt; In the "GET /?q=correct+horse+battery+staple\r\n\r\n" client-side case
&gt; we will have to build HTTP header spoofing into the tor client, which
&gt; is not fun since modern browsers send loads of HTTP headers in their
&gt; first GET.

A valid concern. Also applies to the ETag proposal.

&gt; In the Etags/Cookies/whatever server-side case we will probably have
&gt; to build some sort of 'valid document'/'innocuous webpage' generator
&gt; into the Tor bridge, which is also not fun. Fortunately, we might be
&gt; able to reuse such a construction when Bridge Passwords fail:
&gt; https://lists.torproject.org/pipermail/tor-dev/2011-October/002996.html

My thought was that it's not too hard to proxy to a real webserver for
content and inject/modify headers as required.

&gt; Still, I would very much enjoy if we could find a way to authenticate
&gt; the bridge using the shared secret without relying on HTTP covert
&gt; channel wizardry. 

We're really talking about steganography here rather than a true covert
channel. I believe the purpose is to avoid bridge enumeration due to the
initial connection having a fingerprint? So you need an invisible method
of authentication. It may be that distributing more information to
bridge users out-of-band is actually the best approach. But to me the
advantage of a technical solution is increased resistance to social
engineering.

&gt; I've been thinking of having bridges that use Bridge Passwords, "tag"
&gt; their SSL certificate, say the Serial Number, with their password, and
&gt; have clients validate them before proceeding with AUTHORIZE cells.

That's certainly subtle. You're left with the problem of what the client
should do if it can't authenticate the bridge. It still needs to send
something down the pipe that it opened, and the server still needs to
respond to that, otherwise the unused connection will look suspicious.


J
-- 
3072D/D2DE707D Julian Yon (2011 General Use) &lt;pgp.2011@jry.me&gt;


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111105151816</emailId><senderName>Julian Yon</senderName><senderEmail>julian@yon.org.uk</senderEmail><timestampReceived>2011-11-05 15:18:16-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

[Attachment #2 (multipart/signed)]


On 05/11/11 04:35, Marsh Ray wrote:
&gt; I love this line of thinking. But what if the MitM calls your bluff and
&gt; returns his own cookie, ETag header and a 302 Redirect to the same page?
&gt; What would the client do then? If the client did observe the redirect as
&gt; a browser would, he may be unable to try again for some time. Otherwise,
&gt; it would tend to confirm the status of the server as a Tor node.

The problem is more general. What should the client do under any
circumstance when it's unable to authenticate the bridge? Assuming a
degree of justified paranoia, you probably want to leave it as long as
possible before retrying. You may not even want to risk connecting to a
*different* bridge, as it could be your own connection being intercepted
and then you're just giving your adversary more information.

&gt; Seems like what we want is like TLS channel bindings to detect the MitM.
&gt; This is standardized. http://tools.ietf.org/html/rfc5056
&gt; Microsoft IE+IIS implemented it, it thwarts their MitM tool:
&gt; &gt; http://blogs.msdn.com/b/fiddler/archive/2010/10/15/fiddler-https-decryption-and-channel-binding-token-authentication-problems.aspx
&gt; &gt; 

I don't know enough about this. I'll have to read the documents before I
can comment.


J

-- 
3072D/D2DE707D Julian Yon (2011 General Use) &lt;pgp.2011@jry.me&gt;


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111106004543</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-06 00:45:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

I improved the original proposal based on the comments of Robert.
Inlining:

Filename: 189-authorize-cell.txt
Title: AUTHORIZE and AUTHORIZED cells
Author: George Kadianakis
Created: 04 Nov 2011
Status: Open

1. Overview

   Proposal 187 introduced the concept of the AUTHORIZE cell, a cell
   whose purpose is to make Tor bridges resistant to scanning attacks.

   This is achieved by having the bridge and the client share a secret
   out-of-band and then use AUTHORIZE cells to validate that the
   client indeed knows that secret before proceeding with the Tor
   protocol.

   This proposal specifies the format of the AUTHORIZE cell and also
   introduces the AUTHORIZED cell, a way for bridges to announce to
   clients that the authorization process is complete and successful.

2. Motivation

   AUTHORIZE cells should be able to perform a variety of
   authorization protocols based on a variety of shared secrets. This
   forces the AUTHORIZE cell to have a dynamic format based on the
   authorization method used.

   AUTHORIZED cells are used by bridges to signal the end of a
   successful bridge client authorization and the beginning of the
   actual link handshake. AUTHORIZED cells have no other use and for
   this reason their format is very simple.

   Both AUTHORIZE and AUTHORIZED cells are to be used under censorship
   conditions and they should look innocuous to any adversary capable
   of monitoring network traffic.

   As an attack example, an adversary could passively monitor the
   traffic of a bridge host, looking at the packets directly after the
   TLS handshake and trying to deduce from their packet size if they
   are AUTHORIZE and AUTHORIZED cells. For this reason, AUTHORIZE and
   AUTHORIZED cells are padded with a random amount of padding before
   sending.

3. Design

3.1. AUTHORIZE cell

   The AUTHORIZE cell is a variable-sized cell.

   The generic AUTHORIZE cell format is:

         AuthMethod                       [1 octet]
         MethodFields                     [...]
         PadLen                           [2 octets]
         Padding                          ['PadLen' octets]

   where:

   'AuthMethod', is the authorization method to be used.

   'MethodFields', is dependent on the authorization Method used. It's
                   a meta-field hosting an arbitrary amount of fields.

   'PadLen', specifies the amount of padding in octets.
   Implementations SHOULD pick 'PadLen' to be a random integer from 1
   to 3141 inclusive.

   'Padding', is 'PadLen' octets of random content.

3.2. AUTHORIZED cell format

   The AUTHORIZED cell is a variable-sized cell.

   The AUTHORIZED cell format is:

         'AuthMethod'                       [1 octet]
         'PadLen'                           [2 octets]
         'Padding'                          ['PadLen' octets]

   where all fields have the same meaning as in section 3.1.

3.3. Cell parsing

   Implementations MUST ignore the contents of 'Padding'.

   Implementations MUST reject an AUTHORIZE or AUTHORIZED cell where
   the 'Padding' field is not 'PadLen' octets long.

   Implementations MUST reject an AUTHORIZE cell with an 'AuthMethod'
   they don't recognize.

4. Discussion

4.1. What's up with the [1,3141] padding bytes range?

   The upper limit is larger than the Ethernet MTU so that AUTHORIZE
   and AUTHORIZED cells are not always transmitted into a single
   packet. Other than that, it's indeed pretty much arbitrary.

4.2. Why not let the pluggable transports do the padding, like they
     are supposed to do for the rest of the Tor protocol?

   The arguments of section "Alternative design: Just use pluggable
   transports" of proposal 187, apply here as well:

   All bridges who use client authorization will also need padded
   AUTHORIZE and AUTHORIZED cells.

4.3. How should multiple round-trip authorization protocols be handled?

   Protocols that require multiple-round trips between the client and
   the bridge should use AUTHORIZE cells for communication.

   The format of the AUTHORIZE cell is flexible enough to support
   messages from the client to the bridge and the reverse.

   At the end of a successful multiple round-trip protocol, an
   AUTHORIZED cell must be issued from the bridge to the client.

4.4. AUTHORIZED seems useless. Why not use VPADDING instead?

   As noted in proposal 187, the Tor protocol uses VPADDING cells for
   padding; any other use of VPADDING makes the Tor protocol kludgy.

   In the future, and in the example case of a v3 handshake, a client
   can optimistically send a VERSIONS cell along with the final
   AUTHORIZE cell of an authorization protocol. That allows the
   bridge, in the case of successful authorization, to also process
   the VERSIONS cell and begin the v3 handshake promptly.

4.5. What should actually happen when a bridge rejects an AUTHORIZE
     cell?

   When a bridge detects a badly formed or malicious AUTHORIZE cell,
   it should assume that the other side is an adversary scanning for
   bridges. The bridge should then act accordingly to avoid detection.

   This proposal does not try to specify how a bridge can avoid
   detection by an adversary.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102082031</emailId><senderName>"Markku-Juhani O. Saarinen"</senderName><senderEmail>mjos@reveresecurity.com</senderEmail><timestampReceived>2011-11-02 08:20:31-0400</timestampReceived><subject>[tor-dev] SHA-3 isn't looking so hot to me</subject><body>

Watson Ladd:

&gt; (HMAC is a bad idea anyway: quadratic security bounds are not the best
&gt; possible, we have to use nonces anyway to prevent replay attacks, so 
&gt; Wegman-Carter is a better idea for better in{faster, more secure}. GCM
&gt; would be an example of this.)

GCM has quadratic security bounds, not only in the proof but in practice
too. Furthermore a 128-bit GCM MAC offers much less than 128-bit
security; in this sense it is certainly weaker than, say, MD5-HMAC ! And
there are the implementation caveats mentioned already mentioned in the
list, including Joux's "forbidden attack" which may indeed be very real
in many implementations. 

GCM also tends to be slow on software. I've been told that GCM was
pushed through the NIST standardization process mainly by CISCO who were
concerned about the performance of their hardware crypto accelerators
(many hash functions are tricky to implement on hardware).

There's also the issue of weak keys etc. See

http://eprint.iacr.org/2011/202.pdf

This came out in ECRYPT II Hash Workshop 2011, 19-20 May 2011, Tallinn,
Estonia. The current ECRYPT recommendations take this into account, see
section 8.5.5 of "ECRYPT II Yearly Report on Algorithms and
Keysizes (2010-2011)" for a brief discussion:

http://www.ecrypt.eu.org/documents/D.SPA.17.pdf

I should be expanding this work as Niels Ferguson noted in the Redmond
Crypto Retreat workshop last August that there's a trivial extension of
this attack that allows arbitrary message modification. Also a
significantly faster method for identifying weak AES-GCM keys has been
discovered.

As a hash function researcher I would personally select SHA-512 with
digest truncated to required number of bits as an interim solution.
SHA-512/256 tends to be faster than SHA-256 in software. Also it makes
sense to implement a single hash core rather than two (SHA-256 and
SHA-512 are fundamentally different). This is also in the standards,
see:

http://csrc.nist.gov/publications/drafts/fips180-4/Draft-FIPS180-4_Feb2011.pdf

Cheers,
- markku

Dr. Markku-Juhani O. Saarinen &lt;mjos@reveresecurity.com&gt;


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102161822</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-02 16:18:22-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

For what it is worth, I would probably prefer Poly1305-AES over HMAC
if I were needing message integrity. I don't know if I would prefer
Poly1305-AES over using an integrated-integrity mode like GCM.


On Wed, Nov 2, 2011 at 2:20 AM, Markku-Juhani O. Saarinen
&lt;mjos@reveresecurity.com&gt; wrote:
&gt;
&gt; As a hash function researcher I would personally select SHA-512 with
&gt; digest truncated to required number of bits as an interim solution.
&gt; SHA-512/256 tends to be faster than SHA-256 in software.

I like this suggestion because it seems very safe.

However, it isn't the full story to say that SHA-512 tends to be
faster than SHA-256 in software. That's true for 64-bit chips, but
untrue for 32-bit.

According to [1], while SHA-512 requires only about 2/3 as many CPU
cycles as SHA-256 on a powerful Sandy Bridge server chip ("sandy0"),
it requires 4 times as many CPU cycles on a 32-bit ARM ("gcc33"). As
I've argued recently on this list, it might not matter whether hashing
your 4096-byte packet on one core of a powerful server (sandy0) takes
15 sec (SHA-512) or 22 sec (SHA-256), but it might matter whether
hashing it on a cheap, power-efficient embedded chip (gcc33) takes
120sec (SHA-256) or 481 sec (SHA-512).

On the other hand, maybe ~500 sec time spent hashing per packet is
good enough on Freedom Boxes, smart phones, and ARM servers [2], and
the added safety of SHA-512/256 vs. SHA-256 would be worth it.

Regards,

Zooko

[1] http://bench.cr.yp.to/results-hash.html
[2] http://www.pcworld.com/article/242946/calxedas_chip_boosts_arms_server_fight_with_intel.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111103221601</emailId><senderName>Jon Callas</senderName><senderEmail>joncallas@me.com</senderEmail><timestampReceived>2011-11-03 22:16:01-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

Zooko forwarded a hash question over to the SHA-3 competition mailing list, and \
mentioned the discussion that has been going on here. He's going to forward over \
comments that I made and John Kelsey made. Nonetheless, I'd like to offer some \
comments on what I've read in a larger context.

I don't see any discussions of requirements, goals, or anything like that. I see \
discussions of what hash function to use, ECC, symmetric modes, and so on, and yet no \
reasons why you would do anything. If you don't have requirements, you aren't going \
to get a good answer. Any of those proposed solutions needs to have an answer to the \
question "What is this trying to solve?" at the very least. The next question should \
be, "How does it solve it?" 

Protocols are almost never broken because of the crypto. That's not the problem. Tor \
as a protocol and as a *service* has many things it needs to worry about long before \
you should worry about the crypto. Don't lose sight of the real issues. Trust me, \
they aren't the crypto. You need to stick to well-understood ciphers. Do not be \
frightened by warts on a function. The property of being well-understood means that \
it will have warts.

Additionally, you should stick to well-recognized constructions, too. The main reason \
is that warts and all, we know most about these things. The alternatives frequently \
either have different warts, or have unknown warts that will bite you in the ass when \
they're finally found. Moreover, Tor is an important protocol, service, and system. \
If you use a weird-ass construction, then a flaw in that will be publicized as a flaw \
in Tor. If someone finds a non-important problem in AES or SHA256, you'll be shielded \
by ubiquity. If you use the Whizzy2^n-1 whatever, then when a problem is found in it, \
that will hit the press as "FLAW FOUND IN TOR! EVERYONE RUN FOR THEIR LIVES!" and \
you'll be left defending it yourself. The crypto elders will also cluck their tongues \
and say, "Yeah, they really should have used what NIST documented in SP 800-9999." \
Lastly on that, Tor is no important that you'll be a target. People *will* target Tor \
because a teenie, tiny, unimportant break in Tor is a g  uaranteed paper acceptance \
in Usenix Security or Eurocrypt. Anonymity loves crowds; so do cryptographers.

Here are some specifics:

* Hash functions. Zooko will forward my full response, the summary of which is to use \
SHA-2 in whatever length or form. Should you not want to do that, why? What are you \
after? Speed? How much speed? Again, I don't see what you're trying to solve, but \
I'll recommend using Skein if you don't like SHA-2. I'm a co-designer of it, for full \
disclosure. 

Skein is secure, fast (under 7 clocks per byte on x64, and at 15.5 on armv7), and has \
lots of Swiss Army Knife features. You can use it as a KDF, PRNG, and so on. It has a \
one-pass MAC that has a proof of security on it, so it is a valuable alternative to \
HMAC. ZRTP is using Skein's MAC to speed up VOIP encryption as an alternative to HMAC \
(more full disclosure, I'm a co-author of ZRTP, too, but Phil Z had to talk me into \
it, and he had real performance goals to meet).

However, the safe, sane thing to do is use SHA-256.

* ECC. I don't see a reason why you're looking at it; my remark isn't code for \
thinking it's a bad idea, it means I don't see *reasons*, and yeah, yeah, I keep \
harping on that. 

ECC can be faster than RSA. But sometimes it isn't. I have seen RSA 1280 running at \
10x the speed of P-256. Note that P-256 has the security properties of RSA 3072, so \
it's not comparing apples to apples. But I'll bet that Tor could run for the next \
five years on RSA 1280 or RSA 1536, and punt the problem into the future. It is my \
gut feel that if you migrate to 256 bit ECC from RSA 1024, you will see a performance \
drop. Nonetheless, you need to move from RSA 1024 to *something*. I am just noting \
that from a performance standpoint, you're not at the place where ECC is clearly \
better yet. Yet.

Now on the other hand, ECC is the wave of the future and why not bite the bullet now? \
The patent issues are still thorny and that's another reason to punt the decision \
into the future. The major ECC patents started expiring this last summer, and if you \
delay the decision for three to five years, it'll be pretty much a non-issue. On the \
other, other hand, I don't think the Tor project has a lot to worry about. It is \
unlikely that RIM/Certicom will come after Tor. Heck, they are as likely to donate a \
license to the project as anything else. The IP issues shouldn't be much of a \
concern, but if they are -- wait. I see no requirements that say why you need ECC, \
and as I've said, you might find that ECC is slower than RSA 1280 or 1536.

Should you go to ECC, use P-256; do not use some variant of 25519. You want to be in \
a crowd. You want to use something that lots of smart people have looked at. That \
means P-256. For *any* counter argument, please supply the requirement or goal that \
makes P-256 the inferior choice, preferably with a metric. Absent such, P-256 is your \
baby.

* Stream ciphers. For a stream cipher, you should be doing at AES-CTR. Really. Stop \
worrying about the warts. There are hardware implementations with AES-NI, or attached \
hardware that don't have problems. ArmV8 has AES in hardware along with SHA256, which \
another reason to stick to the well-understood. AES-NI on an x64 processor runs at \
under 1 clock per byte. That's all goodness.

If, for some reason, you really, really want to go off on a limb, then look seriously \
at counter mode with either Twofish or Serpent, as they're likely the next \
best-understood algorithms there are. However, there's not a lot of glory in breaking \
them, so they haven't seen nearly as much work. Ditto for any eStream cipher. If you \
must be trendy, then heck, please look at Threefish, which runs twice as fast as AES \
and is inherently tweakable (note again, that I'm a co-designer). But really, just \
use AES-CTR.

GCM is an alternative, but I'd use CTR and an HMAC, myself, especially since you \
don't seem to have performance goals that are driving it. As others have noted, it's \
really tetchy to use correctly, and there are limits on the security it gives you. \
There is a 128-bit hardware multiply in the same Intel processors that have AES-NI to \
speed it up, but I'd stick to the tried-and-true HMAC, absent reasons with metrics.

Whatever you do, please do not do something as gosh-darned daft as XOR two keystreams \
together. The crypto is not the problem, and every time someone tries to do something \
like that to strengthen the crypto it all ends up with someone's eye out.

* Random number generators. You're bikeshedding. Any of those are great things to do, \
and there's no reason why continuing with what you've been doing (yeah, throw in more \
entropy sources, it never hurts) is wrong or suboptimal. Whatever. Do what you want, \
but I think you have bigger fish to fry.

* Fingerprints. Also a reasonable discussion of what color the shed should be. My \
sole comment is that the gods punish hubris, and coding your hash function into two \
bits is hubris. One of the major lessons of the obsessive bit-conservation that PGP \
did is that you write more code and make more bugs saving those bits than the bits \
were worth. If you use something smaller than a byte, you will regret it.

* Other comments. In the relay crypto comments, there was something about counter "in \
a less scary mode" -- just use what they describe in NIST SP800-whatever. 

Okay, that's it for me.

	Regards,
	Jon

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111104130109</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-04 13:01:09-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

On 2011-11-03, Jon Callas &lt;joncallas@me.com&gt; wrote:
&gt; Zooko forwarded a hash question over to the SHA-3 competition mailing list,
&gt; and mentioned the discussion that has been going on here. He's going to
&gt; forward over comments that I made and John Kelsey made. Nonetheless, I'd
&gt; like to offer some comments on what I've read in a larger context.
&gt;
&gt; I don't see any discussions of requirements, goals, or anything like that. I
&gt; see discussions of what hash function to use, ECC, symmetric modes, and so
&gt; on, and yet no reasons why you would do anything. If you don't have
&gt; requirements, you aren't going to get a good answer. Any of those proposed
&gt; solutions needs to have an answer to the question "What is this trying to
&gt; solve?" at the very least. The next question should be, "How does it solve
&gt; it?"

For What is this trying to solve?', see:

* https://www.torproject.org/docs/documentation#DesignDoc

* https://svn.torproject.org/svn/projects/design-paper/tor-design.html

* https://svn.torproject.org/svn/projects/design-paper/challenges.pdf

* https://blog.torproject.org/blog/one-cell-enough


See also the tor-dev mailing-list threads started with these
documents:

* https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xxx-crypto-migration.txt

* https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xxx-crypto-requirements.txt


But as you may have seen, the tor-dev Cryptographic Bikeshed Design
Task Force has ignored that part because it's more fun to talk
endlessly about the least important details.  (Based on the rest of
your message, I assume they didn't even tell you about that part
before inviting you into the discussion.)


&gt; Protocols are almost never broken because of the crypto. That's not the
&gt; problem. Tor as a protocol and as a *service* has many things it needs to
&gt; worry about long before you should worry about the crypto. Don't lose sight
&gt; of the real issues. Trust me, they aren't the crypto. You need to stick to
&gt; well-understood ciphers. Do not be frightened by warts on a function. The
&gt; property of being well-understood means that it will have warts.
&gt;
&gt; Additionally, you should stick to well-recognized constructions, too. The
&gt; main reason is that warts and all, we know most about these things. The
&gt; alternatives frequently either have different warts, or have unknown warts
&gt; that will bite you in the ass when they're finally found. Moreover, Tor is
&gt; an important protocol, service, and system. If you use a weird-ass
&gt; construction, then a flaw in that will be publicized as a flaw in Tor. If
&gt; someone finds a non-important problem in AES or SHA256, you'll be shielded
&gt; by ubiquity. If you use the Whizzy2^n-1 whatever, then when a problem is
&gt; found in it, that will hit the press as "FLAW FOUND IN TOR! EVERYONE RUN FOR
&gt; THEIR LIVES!" and you'll be left defending it yourself. The crypto elders
&gt; will also cluck their tongues and say, "Yeah, they really should have used
&gt; what NIST documented in SP 800-9999." Lastly on that, Tor is no important
&gt; that you'll be a target. People *will* target Tor because a teenie, tiny,
&gt; unimportant break in Tor is a g
&gt;  uaranteed paper acceptance in Usenix Security or Eurocrypt. Anonymity loves
&gt; crowds; so do cryptographers.

Tor's use of well-recognized constructions hasn't stopped the recent
wave of semi-technical bullshit attacks' and plagiarisms of old,
not-particularly-effective attacks from winning the attention economy.

(One of the claims in the latest anti-Tor publicity campaign is that
using AES in CTR mode is a bugdoor', and that we knew that we should
have used CBC mode instead.  This is even after the news that use of
block ciphers in CBC mode breaks SSL's security.  Yes, people *lie* in
order to get publicity for an alleged attack on Tor.)


&gt; Here are some specifics:
&gt;
&gt; * Hash functions. Zooko will forward my full response, the summary of which
&gt; is to use SHA-2 in whatever length or form. Should you not want to do that,
&gt; why? What are you after? Speed? How much speed? Again, I don't see what
&gt; you're trying to solve, but I'll recommend using Skein if you don't like
&gt; SHA-2. I'm a co-designer of it, for full disclosure.
&gt;
&gt; Skein is secure, fast (under 7 clocks per byte on x64, and at 15.5 on
&gt; armv7), and has lots of Swiss Army Knife features. You can use it as a KDF,
&gt; PRNG, and so on. It has a one-pass MAC that has a proof of security on it,
&gt; so it is a valuable alternative to HMAC. ZRTP is using Skein's MAC to speed
&gt; up VOIP encryption as an alternative to HMAC (more full disclosure, I'm a
&gt; co-author of ZRTP, too, but Phil Z had to talk me into it, and he had real
&gt; performance goals to meet).

Skein sucks on 32-bit processors, and on AMD64 processors in 32-bit
mode.  All of our Windows packages are 32-bit.

And I'm not a fan of using a cryptographic primitive with as many
features as Skein has.  Implementation complexity sucks, especially in
crypto software.

&gt; However, the safe, sane thing to do is use SHA-256.

SHA-256 sucks unnecessarily on 64-bit processors.  Our fast relays are
64-bit.


&gt; * ECC. I don't see a reason why you're looking at it; my remark isn't code
&gt; for thinking it's a bad idea, it means I don't see *reasons*, and yeah,
&gt; yeah, I keep harping on that.

* RSA public keys are long.  Every client needs to download at least
  one public key (the circuit-extension handshake authentication key
  (called an onion key' in our current design documents)) for every
  relay.  (Clients also need enough information about each relay to
  open and authenticate a link' to it, but a hash of the relay's
  identity key suffices in our current (TLS-based) link protocols.)

* RSA private-key operations are slow.  Every time a client extends a
  circuit to a relay, the relay must perform one private-key operation
  using its circuit-extension handshake key.  (See also
  https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xxx-ntor-handshake.txt
  for one thing that we might replace our circuit-extension handshake
  with.  We might use an EC-based signature system for
  circuit-extension handshake authentication instead, so that more of
  the relay-side scalar-multiply operations can be performed in
  advance.)

* We want forward secrecy for circuits, so we use Diffie-Hellman, too.
  For every circuit extended to a relay, the relay must perform two
  scalar-multiply operations.  Currently, we use 320-bit exponents in
  a 1024-bit mod-p group published in the 1990s.  ECDH using
  Curve25519 is likely to be faster *and* more secure.

* With ECC, we can use whole public keys instead of fingerprints.
  This actually matters in the new hidden service protocol, so we will
  use an EC-based signature system there.


&gt; ECC can be faster than RSA. But sometimes it isn't. I have seen RSA 1280
&gt; running at 10x the speed of P-256. Note that P-256 has the security
&gt; properties of RSA 3072, so it's not comparing apples to apples. But I'll bet
&gt; that Tor could run for the next five years on RSA 1280 or RSA 1536, and punt
&gt; the problem into the future. It is my gut feel that if you migrate to 256
&gt; bit ECC from RSA 1024, you will see a performance drop. Nonetheless, you
&gt; need to move from RSA 1024 to *something*. I am just noting that from a
&gt; performance standpoint, you're not at the place where ECC is clearly better
&gt; yet. Yet.

We are.  (Yes, I know no one told you that.)

&gt; Now on the other hand, ECC is the wave of the future and why not bite the
&gt; bullet now? The patent issues are still thorny and that's another reason to
&gt; punt the decision into the future. The major ECC patents started expiring
&gt; this last summer, and if you delay the decision for three to five years,
&gt; it'll be pretty much a non-issue. On the other, other hand, I don't think
&gt; the Tor project has a lot to worry about. It is unlikely that RIM/Certicom
&gt; will come after Tor. Heck, they are as likely to donate a license to the
&gt; project as anything else. The IP issues shouldn't be much of a concern, but
&gt; if they are -- wait. I see no requirements that say why you need ECC, and as
&gt; I've said, you might find that ECC is slower than RSA 1280 or 1536.

See above for the requirements no one told you about.


&gt; Should you go to ECC, use P-256; do not use some variant of 25519. You want
&gt; to be in a crowd. You want to use something that lots of smart people have
&gt; looked at. That means P-256. For *any* counter argument, please supply the
&gt; requirement or goal that makes P-256 the inferior choice, preferably with a
&gt; metric. Absent such, P-256 is your baby.

In the proposed ntor' handshake, the relay performs a scalar-multiply
operation on a user-specified group element, using a long-term secret
key.  Curve25519 has a secure twist', so the relay can skip the
group-membership test which might be required with other EC groups.
Because of that (potentially significant) performance advantage, we
have put some effort into improving at least one Curve25519
implementation.  (I should note here that relays do become overloaded
with circuit-extension crypto in the deployed Tor network, so we
really do need to care about performance.)

I have also seen parameters for an Edwards curve equivalent to
Curve25519; we will need the Edwards-curve parameters in order to
implement point addition efficiently in constant time for our EC
signature scheme.  I would rather not have to fuss around with finding
the/an Edwards curve corresponding to NIST P-256.

We can represent a Curve25519 public key in 51 base32 characters; we
would need one additional character for a base32-encoded P-256 public
key (assuming point reduction), and we wouldn't gain much (if any)
security.

Any one of these reasons should be sufficient to outweigh NSA told us
to use X'.


&gt; * Stream ciphers. For a stream cipher, you should be doing at AES-CTR.
&gt; Really. Stop worrying about the warts. There are hardware implementations
&gt; with AES-NI, or attached hardware that don't have problems. ArmV8 has AES in
&gt; hardware along with SHA256, which another reason to stick to the
&gt; well-understood. AES-NI on an x64 processor runs at under 1 clock per byte.
&gt; That's all goodness.

I don't have one of those.  Why should I have to use a cipher which no
one has implemented securely *and* efficiently on my computer?  Why do
you want to continue to inflict side-channel leaks on our users in
oppressed countries who have even older computers?

&gt; If, for some reason, you really, really want to go off on a limb, then look
&gt; seriously at counter mode with either Twofish or Serpent, as they're likely
&gt; the next best-understood algorithms there are. However, there's not a lot of
&gt; glory in breaking them, so they haven't seen nearly as much work. Ditto for
&gt; any eStream cipher. If you must be trendy, then heck, please look at
&gt; Threefish, which runs twice as fast as AES and is inherently tweakable (note
&gt; again, that I'm a co-designer). But really, just use AES-CTR.

Twofish is designed to be implemented using S-boxes, just like AES.
Using Twofish gives us all of the side-channel attack risk and no
speed benefit.

Serpent is ridiculously slow.

Salsa20 looks like a Good Thing.  Salsa20/8 would be even better.

In general, if we don't have to write a paragraph or two explaining
why the published attacks on an algorithm used in our relay crypto are
bogus or irrelevant to Tor, we're using too many rounds of it.  The
relay crypto only needs to make cryptographic attacks harder enough
than the end-to-end timing correlation attack that no one will ever
benefit by implementing an attack on our crypto.  Anything we are
willing to use will far exceed that goal.


&gt; GCM is an alternative, but I'd use CTR and an HMAC, myself, especially since
&gt; you don't seem to have performance goals that are driving it. As others have
&gt; noted, it's really tetchy to use correctly, and there are limits on the
&gt; security it gives you. There is a 128-bit hardware multiply in the same
&gt; Intel processors that have AES-NI to speed it up, but I'd stick to the
&gt; tried-and-true HMAC, absent reasons with metrics.
&gt;
&gt; Whatever you do, please do not do something as gosh-darned daft as XOR two
&gt; keystreams together. The crypto is not the problem, and every time someone
&gt; tries to do something like that to strengthen the crypto it all ends up with
&gt; someone's eye out.
&gt;
&gt; * Random number generators. You're bikeshedding. Any of those are great
&gt; things to do, and there's no reason why continuing with what you've been
&gt; doing (yeah, throw in more entropy sources, it never hurts) is wrong or
&gt; suboptimal. Whatever. Do what you want, but I think you have bigger fish to
&gt; fry.
&gt;
&gt; * Fingerprints. Also a reasonable discussion of what color the shed should
&gt; be. My sole comment is that the gods punish hubris, and coding your hash
&gt; function into two bits is hubris. One of the major lessons of the obsessive
&gt; bit-conservation that PGP did is that you write more code and make more bugs
&gt; saving those bits than the bits were worth. If you use something smaller
&gt; than a byte, you will regret it.

I agree here.  We currently use a leading "$" to distinguish relay
identity-key fingerprints from relay nicknames; we should distinguish
new-style fingerprints by placing an algorithm identifier before the
"$".


&gt; * Other comments. In the relay crypto comments, there was something about
&gt; counter "in a less scary mode" -- just use what they describe in NIST
&gt; SP800-whatever.

This is less scary' from the point of view of resisting side-channel
attacks.  NSA was warned that array lookups with secret indices would
allow side-channel attacks.  NSA told us to not worry about the
side-channel attacks.  Now we know that we should have been worrying
about side-channel attacks all along, instead of just using the cipher
NSA told us to.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111104142432</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@cs.uwaterloo.ca</senderEmail><timestampReceived>2011-11-04 14:24:32-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

On Fri, Nov 04, 2011 at 01:01:09PM +0000, Robert Ransom wrote:
&gt; I have also seen parameters for an Edwards curve equivalent to
&gt; Curve25519; we will need the Edwards-curve parameters in order to
&gt; implement point addition efficiently in constant time for our EC
&gt; signature scheme.

Hmm?  curve25519 _is_ an Edwards curve (that's why it has that slightly
annoying non-prime order), and djb's implementation, at least, is
supposed to be constant-time.

   - Ian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104160722</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-11-04 16:07:22-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>


On 11/04/2011 08:01 AM, Robert Ransom wrote:
&gt; On 2011-11-03, Jon Callas&lt;joncallas@me.com&gt;  wrote:
&gt;&gt; However, the safe, sane thing to do is use SHA-256.
&gt;
&gt; SHA-256 sucks unnecessarily on 64-bit processors.  Our fast relays are
&gt; 64-bit.

It may be worth mentioning the newly-standardized SHA-512/256 here. This 
is not a new function, it's "SHA-2". I.e., its SHA-512 with a unique IV 
and output truncated to 256 (or 224) bits.
&gt; http://csrc.nist.gov/publications/drafts/fips180-4/FRN_Draft-FIPS180-4.pdf

SHA-512 is based on 64 bit integer operations and seems to run a bit 
faster than SHA-256 on 64 bit processors. It looks quite competitive 
with even the SHA-3 candidates and no less conservative for security.

Of course, whether or not it's better to be faster on 32-bit CPUs or 
64-bit CPUs is another interesting discussion. Given the complex cache 
and bus organization on modern chips, my guess is that a design decision 
like CELL_LEN=512 is likely to have as much of an effect on overall 
throughput as a difference of a half-dozen clocks per byte in the hash 
function.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104162149</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-04 16:21:49-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

On Fri, Nov 4, 2011 at 9:24 AM, Ian Goldberg &lt;iang@cs.uwaterloo.ca&gt; wrote:
&gt; On Fri, Nov 04, 2011 at 01:01:09PM +0000, Robert Ransom wrote:
&gt;&gt; I have also seen parameters for an Edwards curve equivalent to
&gt;&gt; Curve25519; we will need the Edwards-curve parameters in order to
&gt;&gt; implement point addition efficiently in constant time for our EC
&gt;&gt; signature scheme.
&gt;
&gt; Hmm?  curve25519 _is_ an Edwards curve (that's why it has that slightly
&gt; annoying non-prime order), and djb's implementation, at least, is
&gt; supposed to be constant-time.
Dear all,

curve25519 is rationally equivalent to ed25519. Point addition isn't
defined for curve25519 because public keys do not encode sign, because
they are only the x coordinate. This is to take
advantage of the special form y^2=x^3+a_2x^2+x. Until recently this
was the fastest point exponentiation available, at the cost of making
addition impossible.

ed25519 supports point addition, and point compression without
patents. This is because Edwards curves have never been discussed in
Certicom patents. ed25519 is also faster
then curve25519, due to new algorithms. In the future DJB has
indicated he will have curve25519
convert into Edwards form for calculation. But signing requires
ed25519 be used because addition
is not defined on packed curve25519 keys.

P-256 sadly does not support point compression without infringing on
patents. So keys will have to be 64 bytes long.

Edwards curves always exist over closures. The problem is that they
only exist when the order
is divisible by 4. Twisted Edward curves have points of order 2. P-256
could only be put into Edwards form with extension fields, and
extension fields are slow.

If we go with curve25519 we should not implement it ourselves. DJB has
written an implementation that is quite nice to use in the form of
NaCL. Signing is implemented along
with batch signature verification (not in NaCL yet, but written). NaCL
is also a lot nicer to use
then OpenSSL, and is very fast (and ensures it always goes the fastest).

Sincerely,
Watson Ladd

&gt;
&gt;   - Ian
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;



-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111104170517</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-04 17:05:17-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

Hi, Robert!  Hi, Jon!

As usual, please take me not as being "That fellow who is a pompous
ass and says things that aren't true" but rather as "that fellow who
knows that he is probably wrong about some stuff, and doesn't know a
better way to find out what he's wrong about than getting corrected."

IOW, this is what I think now, but if it's not reasonable, I want to
thing something else.
On Fri, Nov 4, 2011 at 9:01 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrot=
e:
&gt; On 2011-11-03, Jon Callas &lt;joncallas@me.com&gt; wrote:
&gt;&gt; Zooko forwarded a hash question over to the SHA-3 competition mailing li=
st,
&gt;&gt; and mentioned the discussion that has been going on here. He's going to
&gt;&gt; forward over comments that I made and John Kelsey made. Nonetheless, I'd
&gt;&gt; like to offer some comments on what I've read in a larger context.
&gt;&gt;
&gt;&gt; I don't see any discussions of requirements, goals, or anything like tha=
t. I
&gt;&gt; see discussions of what hash function to use, ECC, symmetric modes, and =
so
&gt;&gt; on, and yet no reasons why you would do anything. If you don't have
&gt;&gt; requirements, you aren't going to get a good answer. Any of those propos=
ed
&gt;&gt; solutions needs to have an answer to the question "What is this trying to
&gt;&gt; solve?" at the very least. The next question should be, "How does it sol=
ve
&gt;&gt; it?"
&gt;
&gt; For =91What is this trying to solve?=92, see:
&gt;
&gt; * https://www.torproject.org/docs/documentation#DesignDoc
&gt;
&gt; * https://svn.torproject.org/svn/projects/design-paper/tor-design.html
&gt;
&gt; * https://svn.torproject.org/svn/projects/design-paper/challenges.pdf
&gt;
&gt; * https://blog.torproject.org/blog/one-cell-enough

On this last point about cell-tagging attacks, see also
https://lists.torproject.org/pipermail/tor-dev/2011-November/003024.html
for my current thinking.

&gt; See also the tor-dev mailing-list threads started with these
&gt; documents:
&gt;
&gt; * https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xx=
x-crypto-migration.txt
&gt;
&gt; * https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/ideas/xx=
x-crypto-requirements.txt

Right; and keep in mind that the requirements themselves are also in a
evolving draft status.

I think that one of the main problems with the draft I circulated the
other week is that it tried to start discussion on three questions:

  * Should we keep using our current primitive operations (SHA1,
AES-CTR starting at IV 0, 1024-bit DH, 1024-bit RSA, OpenSSL PRNG) or
switch to something else?
  * Regardless of what primitive operations we're using, should we
keep using them in the same ways in our protocol, or are their
protocol improvements we could reasonably make?  (That's the main
point of Section 6 for relay crypto, and of the
Goldberg-Stebilia-Ustaoglu "ntor" design for circuit exension.)
  * Assuming that we pick any primitives and protocols other than the
ones we currently have, how can we best migrate?

It should probably have been predictable that the first one would have
gotten all the attention.  Still, I'm not going to call "bike shed"
too loudly here, since it helps people get involved in design, *and*
the end result is actually important.

Let me try to motivate this and explain goals a bit better.  We want
to choose our crypto primitives and protocols for a few properties.
Some of the more justifiable ones from an engineering perspective are:

[Please treat the above as a draft and tentative set of goals,
motivations, and requirements.  If you think any of these are stupid
and wrongheaded, or just unmotivated, please tell me so!]

  A) They should be strong enough that attacking the crypto primitives
and protocols is not the best attack on Tor. (We have this property
today, I believe, and will continue to have it so long as nobody in
the research community comes up with a solution to the low-latency
traffic correlation attack.)

  B) Further, crypto attacks should not be even _close_ to the best
attacks on Tor.  (Except for the cell tagging attack, I think we have
this property today.  With cell tagging, however, the attack is IMO
only a little worse than the end-to-end timing-attacks that a smart
attacker would be doing instead.  Moreover,, to the extent that it's
feasible, I'd like to reach a situation where every crypto- or
protocol-based attack on Tor is (and remains!) many orders of
magnitude more expensive than the traffic correlation attacks that the
research community doesn't know how to solve.  Ideally, I'd like every
crypto- or protocol-based attack to be hideously expensive on an
absolute scale, if not downright impossible.)

  C) We need good performance.  Our original design goal was
"commodity hardware should be able to saturate commodity bandwidth."
Right now, though, some of the busier servers do seem to be getting
CPU-bound.  (If I'm remembering what I've seen from profiles, the time
sink seems to be to some extent AES and SHA1, and in larger part
exponentiation for RSA and DH.  But I'd want to double-check that to
be sure. See comments below on performance requirements.)  We also
need our cell-crypto protocol to be space-efficient: bandwidth is at a
premium on the Tor network.

  D) We'd like a large security margin in our protocol designs.  For
example, if we have a choice between two protocols, where one of them
requires that SHA256 be collision-resistant while the other one only
requires preimage-resistance, it would be nicer (ceteris paribus!) to
use the second.  Or if we can use our cipher in two modes, one of
which requires that it resist adaptive chosen plaintext attacks, and
the other one only requires that it resist known-plaintext attacks,
the second one would seem (again, all other things being equal)
better.

  E) Because our crypto aims to provide forward secrecy, the parts
that do so need to have higher life expectancy than the rest of the
rest of the system.  For example, it's no big deal if somebody in the
future manages to forge signatures from a key that's no longer valid:
that doesn't open up new attacks.  But if they break a stream cipher
or a DH-based key agreement scheme that we are no longer using, that
would be poor.  That argues (I think) for higher security margins in
our key agreement, key derivation, and encryption than in signatures
and integrity.

  F) We ought to look for DOS opportunities and resist or mitigate
them as possible.  (This isn't limited to crypto stuff, but it does
show up here a bit.)

And here are some implementation concerns:
  G) As much as possible, we shouldn't have to be the primary
maintainers of our crypto primitives.

  H) We need portable implementations of our primitives.

  I) We need high-quality implementations. To me, right now, this
suggests that I'd like categorical rather than empirical arguments for
non-viability of timing attacks.  (IOW, I would much rather say "This
implementation cannot have a timing side channel" than "Any timing
side-channel that this implementation might have is probably tiny,
infrequent, and hard to exploit.")

And here are some more fluffy concerns:

  J) Nothing should be embarrassing, even if it's safe.  It provokes
unconfidence and uncertainty when there turns out to be a weakness in
a primitive or protocol... even if as in D above we give ourselves
enough margin to tolerate unforeseen weaknesses in our protocols or
primitives, and even if as in B above we ensure that crypto attacks
remain a deeply stupid way to attack Tor.

  K) It would be nice not to be the biggest or most prominent user of
anything if we can possibly help it.  This ensures that a wider
variety of cryptographers are looking at it,

[...]
&gt;&gt; Protocols are almost never broken because of the crypto. That's not the
&gt;&gt; problem. Tor as a protocol and as a *service* has many things it needs to
&gt;&gt; worry about long before you should worry about the crypto. Don't lose si=
ght
&gt;&gt; of the real issues.  Trust me, they aren't the crypto.

Believe me, we know.  Just because this is the Tor development topic
that you're seeing first does not mean that it is the only one, or
even the highest-priority one on my plate. :)

&gt;&gt;                You need to stick to
&gt;&gt; well-understood ciphers. Do not be frightened by warts on a function. The
&gt;&gt; property of being well-understood means that it will have warts.

I think I either agree or disagree with you here depending on what you
mean by 'warts'.  I agree with you when it means stuff that's
undesirable but easy to work around (like the length-extension
properties of Merkle-Damg=E5rd hashes), or that is undesirable but
impossible to exploit (like a 2^126.5 attack on a 128-bit system).

But I am less sanguine about stuff that weakens a primitive to a
degree that I don't understand.  For example, consider the AES256 key
schedule problems, which as I understand them are interesting but as
yet unexploitable, since (again, if I understand right) you need a
ridiculous number of plaintexts encrypted with a related keys, and any
decent KDF will ensure that you don't have such related keys.  But
these attacks do seem to get better every year, they make me nervous
about AES256.  (We're using AES128 these days, as noted elsewhere.)

You're right that it's a major cognitive error to think that a system
with fewer known problems is necessarily better than one with more
known problems, unless you know how much attention both systems have
received.

&gt;&gt; Additionally, you should stick to well-recognized constructions, too. The
&gt;&gt; main reason is that warts and all, we know most about these things. The
&gt;&gt; alternatives frequently either have different warts, or have unknown war=
ts
&gt;&gt; that will bite you in the ass when they're finally found.

Agreed; we shouldn't be rolling our own MACs, for example.

This is an area BTW where our existing protocols are not so great:
there are some places in the protocol where we use H(x||y) when HMAC
would be a better choice.  Our ersatz KDF is as-yet-unbroken but kinda
idiosyncratic. [ H(secret || [0]) || H(secret || [1]) || ... ].  We
made some roll-our-own choices when we were getting started, and I'd
like to move towards standard and well-analyzed stuff instead.

Also, this is an area where we don't have off-the-shelf solutions for
everything.  For better or worse, there are not a good set of highly
analyzed protocols for some of the things we need to build a working
onion routing network these days.  Most notably, the circuit
establishment protocol and the cell relay protocol are ones where we
had to invent stuff as we began, since there didn't seem to be a
preexisting solution for either.  In both cases, we wound up with
something kind of inefficient with some well-known but not-so-bad
issues.

And in both cases we wound up with protocols where I believe we could
do better today, given care and attention.

&gt;&gt; Moreover, Tor is
&gt;&gt; an important protocol, service, and system. If you use a weird-ass
&gt;&gt; construction, then a flaw in that will be publicized as a flaw in Tor. If
&gt;&gt; someone finds a non-important problem in AES or SHA256, you'll be shield=
ed
&gt;&gt; by ubiquity. If you use the Whizzy2^n-1 whatever, then when a problem is
&gt;&gt; found in it, that will hit the press as "FLAW FOUND IN TOR! EVERYONE RUN=
 FOR
&gt;&gt; THEIR LIVES!" and you'll be left defending it yourself. The crypto elders
&gt;&gt; will also cluck their tongues and say, "Yeah, they really should have us=
ed
&gt;&gt; what NIST documented in SP 800-9999." Lastly on that, Tor is no important
&gt;&gt; that you'll be a target. People *will* target Tor because a teenie, tiny,
&gt;&gt; unimportant break in Tor is a g
&gt;&gt; =A0uaranteed paper acceptance in Usenix Security or Eurocrypt. Anonymity=
 loves
&gt;&gt; crowds; so do cryptographers.

And how!

&gt; Tor's use of well-recognized constructions hasn't stopped the recent
&gt; wave of =91semi-technical bullshit attacks=92 and plagiarisms of old,
&gt; not-particularly-effective attacks from winning the attention economy.
&gt;
&gt; (One of the claims in the latest anti-Tor publicity campaign is that
&gt; using AES in CTR mode is a =91bugdoor=92, and that we knew that we should
&gt; have used CBC mode instead. =A0This is even after the news that use of
&gt; block ciphers in CBC mode breaks SSL's security. =A0Yes, people *lie* in
&gt; order to get publicity for an alleged attack on Tor.)

I don't think that's a lie -- I think that's a combination of a
probably-independent rediscovery of the cell-tagging attack with an
inadequate understanding of Tor's threat model and the problems with
CBC for our use.[*]  Never attribute to malice etc.

(And never attribute to plagiarism what can be explained by an
unfamiliarity with parts of the literature, or a
buried-but-still-present credit. The more serious the charge, the more
caution and forbearance is warranted, especially when people are
already ticked off with one another.)

[*]  The problems with "let's use CBC" in summary: If you do CBC wrong
and don't do a new IV per cell, you're exposing yourself to something
like the Rizzo-Duong attack on SSL.  If you do CBC right, you need one
IV per layer per cell, which is a pretty high overhead for Tor.  CBC
doesn't get particularly good tagging resistance: it just lowers the
number of bits you can tag and your ability to recover the stream
afterwards.  So if you're willing to burn one block per hop per cell,
you're better off using those bytes for a real MAC or GCM or something
than for a CBC IV.  [And if you are hoping to avoid transmitting IVs
by having each cell get a fresh set of IV derived from a keyed PRNG or
something, you aren't really doing orthodox CBC any more.]

&gt;&gt; Here are some specifics:
&gt;&gt;
&gt;&gt; * Hash functions.
[...]

Skipping this part for now.  FWIW, I like Skein myself, and actually
like its "pile of features" approach.  (To my mind, if you don't
provide a construction in a hash function for doing X (where X is
personalization, MAC, PRNG, or whatever), people will go and do it
badly. I know I have!)  But you're right that we ought to write up
speed requirements first.

I think that for all our speed discussions, we ought to stop,
instrument some busy servers, and look at how many cell encryptions,
circuit extension handshakes, connection handshakes, and miscellaneous
"other" crypto operations they actually spend their time on.  Then we
can talk categorically about which parts of the system matter how much
for performance.

We do need to be reasonably good on weak clients, but it's more
important to be fast on servers IMO.

 [...]
&gt;&gt; * ECC. I don't see a reason why you're looking at it; my remark isn't co=
de
&gt;&gt; for thinking it's a bad idea, it means I don't see *reasons*, and yeah,
&gt;&gt; yeah, I keep harping on that.

For me, the big reason is this one:
&gt; * We want forward secrecy for circuits, so we use Diffie-Hellman, too.
&gt; =A0For every circuit extended to a relay, the relay must perform two
&gt; =A0scalar-multiply operations. =A0Currently, we use 320-bit exponents in
&gt; =A0a 1024-bit mod-p group published in the 1990s.

Because of reasons C (gotta be fast), D (gotta have security margins),
and E (forward secrecy needs the biggest margins) from above, I think
our DH operations are the ones where we should be most conservative
about key size, and that plus performance requirements suggests a move
to ECDH to me.  Whether it's next year, in two years, or in three
years is going to depend mostly on what the lawyers say.

[...]
&gt;&gt; Should you go to ECC, use P-256; do not use some variant of 25519. You w=
ant
&gt;&gt; to be in a crowd. You want to use something that lots of smart people ha=
ve
&gt;&gt; looked at. That means P-256. For *any* counter argument, please supply t=
he
&gt;&gt; requirement or goal that makes P-256 the inferior choice, preferably wit=
h a
&gt;&gt; metric. Absent such, P-256 is your baby.

Possible!  I want to talk to a bunch of ECC people here.

Robert: from your list of properties, I think some of them are
desirable, but not flatly compelling on their own. Nothing in ntor
will _fail_ if we need to do group membership tests.  Smaller keys and
point representations are nice-to-have, but not so critical on their
own.

The overall speed advantage is what has been most attractive to me,
but before we can decide whether it's compelling, we need more
analysis and data.

I think we can reach the best conclusions here by avoiding getting too
married to any particular solution.

[...]
&gt;&gt; * Stream ciphers. For a stream cipher, you should be doing at AES-CTR.
&gt;&gt; Really. Stop worrying about the warts. There are hardware implementations
&gt;&gt; with AES-NI, or attached hardware that don't have problems. ArmV8 has AE=
S in
&gt;&gt; hardware along with SHA256, which another reason to stick to the
&gt;&gt; well-understood. AES-NI on an x64 processor runs at under 1 clock per by=
te.
&gt;&gt; That's all goodness.
&gt;
&gt; I don't have one of those. =A0Why should I have to use a cipher which no
&gt; one has implemented securely *and* efficiently on my computer? =A0Why do
&gt; you want to continue to inflict side-channel leaks on our users in
&gt; oppressed countries who have even older computers?

I doubt Jon wants to inflict anything on anybody.

At their best, hardware-based AES implementations can be pretty good
these days.  We do however need to see whether we can find better
software-based implementations than openssl's, which is not making me
thrilled at the moment.  (Its solutions for avoiding cached-based
timing seem kludgier than I would like, if I am understanding them
correctly.)

For software AES, some of what I've reading about bit-slicing
implementations AES is pretty impressive.  Assuming that we use as
much of any given counter stream as I believe we typically do, we can
easily tolerate the requirement of having to encrypt 1-4k of stream
material in a go.

Of course, there could be issues here that I don't at all know about!
More knowledge and analysis is needed.

[...]
&gt; In general, if we don't have to write a paragraph or two explaining
&gt; why the published attacks on an algorithm used in our relay crypto are
&gt; bogus or irrelevant to Tor, we're using too many rounds of it. =A0The
&gt; relay crypto only needs to make cryptographic attacks harder enough
&gt; than the end-to-end timing correlation attack that no one will ever
&gt; benefit by implementing an attack on our crypto. =A0Anything we are
&gt; willing to use will far exceed that goal.

I think some of the goals I list above suggest that we want more of a
security margin that you suggest here.  In particular, consider that
the security of our cipher affects our forward secrecy.  (Not that
you're necessarily wrong, but it is not 100% clear-cut to me.)

[...]
&gt;&gt; * Other comments. In the relay crypto comments, there was something about
&gt;&gt; counter "in a less scary mode" -- just use what they describe in NIST
&gt;&gt; SP800-whatever.

Guessing that you mean SP800-38A appendix B?  There's more than one
thing that looks like counter mode or a variation thereof in the
SP800-... series.

Assuming we're still on counter mode, yeah, what you said.  Right now
we use counter mode with a fixed initial IV, which isn't *bad*
necessarily, but random-IV would be better.


Ugh, what a long mail!  I hope we are closer to asking the right questions =
soon.


cheers,
-- =

Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104063916</emailId><senderName>Jon Callas</senderName><senderEmail>joncallas@me.com</senderEmail><timestampReceived>2011-11-04 06:39:16-0400</timestampReceived><subject>Re: [tor-dev] The consequences of key compromise (or the reasons</subject><body>


On Nov 3, 2011, at 9:08 PM, Watson Ladd wrote:

&gt; Dear all,
&gt; 
&gt; Recently Zooko forwarded an email asking why we have to migrate. I am
&gt; outlining the reasons in this email why I believe Tor needs to
&gt; use stronger cryptography very soon.
&gt; 
&gt; Tor currently uses RSA-1024 bit keys for OR public identities and
&gt; 1024-bit Diffie Hellman for the negotiation of keys protecting
&gt; circuits.
&gt; It also uses SHA-1 for a hash in serveral applications, including key
&gt; fingerprints.
&gt; When deciding if these are adequate it is necessary to think about
&gt; what compromise gives an attacker and what it costs to compromise Tor
&gt; cryptography. We are aiming to protect users from TLAs with ASICs.

People should get off of 80-bit crypto as soon as is reasonably possible. This means \
RSA 1024, SHA-1, etc. NIST recommended doing this by the end of 2010, but are now \
holding their nose and saying that 2013 is the real new date.

This seems basically reasonable to me. No one has yet factored a 768-bit number, let \
alone a 1K one. SHA-1 actually looks safer today than it did in 2005. But still. \
Moving away is a Good Thing, so long as it doesn't make you do something stupid. 

It's certainly laudable to worry about TLAs with ASICs. They probably can't break \
80-bit crypto yet, but that's why you need to get off of it now.

On the other hand, no TLA worth their salt is buying ASICs to crack crypto. They are \
buying zero-day kernel 'sploits. That's how the Germans are beating Skype. Keep that \
in perspective. The half life of an ASIC is 18 months. Zero-days are much more \
effective and much cheaper. 

&gt; 
&gt; Directory keys are 3024 bit RSA. Compromising a directory key is sufficient
&gt; to generate directories containing fake entries, and thus break the
&gt; anonymityof all users who see the fake directory.
&gt; In the event of a compromise, Tor would be unusable until a new
&gt; version is put out with a longer key length and new directory keys.
&gt; But these are long keys.
&gt; 
&gt; However, the keys that actually sign the directories are 1024 bits,
&gt; but rotate every 3 months.
&gt; 
&gt; OR keys are also 1024 bit RSA. Compromise of an OR key enables
&gt; impersonation of the OR to an OP.
&gt; Combined with fun and games with BGP it enables impersonation of an OR
&gt; to other ORs,
&gt; which can direct significant traffic to the fake OR. Detection is
&gt; likely as the real OR will notice various
&gt; refusals to connect by other OR to whom it is not connected. And if
&gt; you can break the directory key why bother with ORs.
&gt; 
&gt; 
&gt; Hidden services are also identified by 1024 bit RSA keys.
&gt; At the circuit level DH keys are 1024 bits.
&gt; An attacker who compromises these can read data intended for further
&gt; down in the circuit.
&gt; In particular they can determine the rest of a circuit if they are the
&gt; first node.
&gt; 
&gt; There is also the issue of keysize. A Tor cell is 512 bytes long.
&gt; Thisis sufficent for only 4 keys, if we pack them very tightly.
&gt; Smaller keys could enable fast circuit initiation or other cool tricks
&gt; we cannot use today.
&gt; 
&gt; So, how strong or weak are RSA-1024 and DH-1024 currently?
&gt; We are using DH over F_q* where q = a big prime. For DH the best known
&gt; algorithm is the index calculus. This attack proceeds in 3 steps.
&gt; 
&gt; The first step, which can be spread over multiple keys is the
&gt; collection of relations among a factor base, usually of small primes.
&gt; The second step, again spread over multiple keys, is solving the
&gt; linear system of equations from the first step.
&gt; The third step is fast and key specific: given an element h,and
&gt; generator g we attempt to factor g^s*h over the factor base.
&gt; The general number field sieve is a very similar algorithm for factoring.
&gt; It is more complicated but again relies on finding smooth numbers and
&gt; factoring them with respect to a factor base of small primes.
&gt; 
&gt; Currently the complexity of these algorithms is
&gt; L_n[1/3,\sqrt^3_{\frac{64}{9}}]for GNFS and L_n[1/2,c] for index
&gt; calculus. (From wikipedia). Sadly the sieving stepscan be done very
&gt; well on special hardware. TWIRL, a specialized hardwaredevice designed
&gt; by Adi Shamir and Eran Tromer is believed by Shamir and Tromer to be
&gt; capable of factoring a 1024-bit RSA key in a year at a cost of $10
&gt; million dollars. To break 10 directory
&gt; keys in 3 months is 10 times as many keys, and 4 times the speed. That
&gt; will be $400 million dollars.
&gt; 
&gt; That is half the cost of Golden Shield for a year: an amount of money
&gt; that is not ludicrous. And such a machine once built can crack the
&gt; next 10 keys for free. The cost is design and fabrication of this
&gt; device: power is comparatively cheap. Of course, such a machine would
&gt; be
&gt; unsuited to other bit sizes.

And for $400 million, you can probably buy about a thousand zero days, if not more. \
You can buy a zero day for any OS in the world for between $50K and a million bucks, \
with the exception of iOS. For iOS, just Google "iPhone jailbreak" and they're free.

&gt; 
&gt; If the attacker instead decides to find a discrete logarithm base for
&gt; DH over 1024, then
&gt; they will have the ability to break DH-1024 fairly quickly. I haven't
&gt; seen a good estimate
&gt; for the time it would take to do this, but it will be a bit more. It
&gt; will not be much more. And it
&gt; will be a total break: once a factor basis is found discrete logs are
&gt; very fast. So an adversary can spend more
&gt; time and still be happy with the results.
&gt; 
&gt; So it isn't just directory signing that is an issue but the link
&gt; protocol as well. And $400 million is a lot. But when you are the
&gt; Golden Shield director and someone says "for $400 million we can break
&gt; Tor for a long time" that is not entirely out of the picture.
&gt; As technology for ASIC fabrication gets better, this price drops. As
&gt; GNFS gets better it also drops. As index calculus gets better it
&gt; drops. And as Balmol's cost disease drives up the cost and budget of
&gt; Golden Shields regular activities, the price drops.

You're right on all of this, and you're right that the crypto needs to be upgraded, \
but software is still far weaker than the crypto.

On the other hand -- the crypto is something we can do something about. That's why we \
should. It would be truly embarrassing to have crypto weaker than the software. 

	Jon


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111102164553</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-02 16:45:53-0400</timestampReceived><subject>Re: [tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

On 2011-11-02, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; Dear All,
&gt; Rather then get further sucked into a debate that is producing more
&gt; heat then light about Wegman-Carter, I've decided to make a concrete
&gt; proposal for how Tor can better protect its streams from manipulation.

Your proposal is so detailed and concrete that I'm not even going to
try to figure out what it means.

I propose Salsa20/8 and CubeHash-256 as our general-purpose stream
cipher and message digest for the first new crypto designs
(seriously), and I propose that we implement multiple new crypto
designs as soon as possible (seriously) so that we know we will get
future migrations right.

But if this bikeshedding about the low-level details of cryptographic
primitives keeps up, I'm going to design my own stream cipher and
message digest.


&gt; Right now Tor encrypts the streams of data from a client to a OR with
&gt; AES-CTR and no integrity checks.

Bullshit.  We have a 32-bit-per-cell integrity check at the ends of a circuit.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102173013</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-02 17:30:13-0400</timestampReceived><subject>Re: [tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

On Wed, Nov 2, 2011 at 12:45 PM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wro=
te:
&gt; On 2011-11-02, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt;&gt; Dear All,
&gt;&gt; Rather then get further sucked into a debate that is producing more
&gt;&gt; heat then light about Wegman-Carter, I've decided to make a concrete
&gt;&gt; proposal for how Tor can better protect its streams from manipulation.
&gt;
&gt; Your proposal is so detailed and concrete that I'm not even going to
&gt; try to figure out what it means.

I'm going to suggest that we ought to isolate protocol discussions
from primitives discussions here.  The discussion of how to put
together a good relay packet format using a stream cipher and a MAC
(or a stream cipher with an authenticating mode of operation) ought to
be separable from the discussion of which stream
cipher/MAC/authenticating mode we use.

(If it isn't separable -- if the format relies on particular
properties of a given primitive -- that strikes me as a point against
the format.)

[...]
&gt;&gt; Right now Tor encrypts the streams of data from a client to a OR with
&gt;&gt; AES-CTR and no integrity checks.
&gt;
&gt; Bullshit. =A0We have a 32-bit-per-cell integrity check at the ends of a c=
ircuit.

Let's keep this polite, please.  "Not so" is a perfectly fine
alternative to "bullshit," and is likelier to keep future
conversations productive.

cheers,
-- =

Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102181952</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-02 18:19:52-0400</timestampReceived><subject>Re: [tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

On Wed, Nov 2, 2011 at 11:45 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; On 2011-11-02, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt;&gt; Dear All,
&gt;[...omitted..]
&gt;
&gt;&gt; Right now Tor encrypts the streams of data from a client to a OR with
&gt;&gt; AES-CTR and no integrity checks.
&gt;
&gt; Bullshit.  We have a 32-bit-per-cell integrity check at the ends of a circuit.
So let's say that I am a malicious 1st hop and a malicious 3rd hop,
and I want to find out. If I have known plaintext I can modify it, say
the packet type headers.  Then the third router will see nonsense and
know that it this circuit is compromised. The second router can detect
this with my proposal, it
cannot right now. Ends of circuit alone are not enough.
&gt;
&gt;
&gt; Robert Ransom
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;
Sincerely,
Watson Ladd


-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111102184015</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2011-11-02 18:40:15-0400</timestampReceived><subject>Re: [tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

On Wed, Nov 02, 2011 at 01:19:52PM -0500, Watson Ladd wrote:
&gt; On Wed, Nov 2, 2011 at 11:45 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; wrote:
&gt; &gt; On 2011-11-02, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; &gt;&gt; Dear All,
&gt; &gt;[...omitted..]
&gt; &gt;
&gt; &gt;&gt; Right now Tor encrypts the streams of data from a client to a OR with
&gt; &gt;&gt; AES-CTR and no integrity checks.
&gt; &gt;
&gt; &gt; Bullshit. We have a 32-bit-per-cell integrity check at the ends
&gt; &gt; of a circuit.
&gt; So let's say that I am a malicious 1st hop and a malicious 3rd hop,
&gt; and I want to find out. If I have known plaintext I can modify it,
&gt; say the packet type headers.  Then the third router will see
&gt; nonsense and know that it this circuit is compromised. The second
&gt; router can detect this with my proposal, it cannot right now. Ends
&gt; of circuit alone are not enough.

There may be other virtues to integrity checks besides at the end
nodes, but this example is not compelling. All our experiments and
analyses have indicated that it is trivial for end nodes to know when
they share a circuit. You mention an active adversary, but it is
trivial for such an adversary to put a timing signature on traffic
detectable at the other end---trivial but unnecessary. My own work
showed a passive adversary is sufficient, and Bauer et al. showed that
you don't even need to pass application data cells: circuit setup is
enough.  Despite extensive research, nobody has yet come up with a
padding/dropping scheme to resist a passive, let alone active, adversary
adequate and practical enough to consider implementing and deploying.

aloha,
Paul
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111101115011</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-01 11:50:11-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

[Attachment #2 (multipart/alternative)]


Turns out that almost everything you said about SHA3 vs SHA256 performance
is wrong:
http://bench.cr.yp.to/impl-hash/blake256.html
http://bench.cr.yp.to/impl-hash/blake256.html
Blake256 performs better except on the Cortex A. On the ARM v6 it
outperforms SHA256. This includes
the ppc32, hardly anyones idea of a server powerhouse.
Furthermore, crypto efficiency is less likely to be a bottleneck on a
client then a node: server architectures matter
much more because we do a lot more crypto on them. (This isn't true for
each connection but servers handle more
connections then clients.)

Secondly SHA256 is already weaker then an ideal hash function. Joux's
multicollision attack works on all Merkel-Damgard constructions, and gives
multicollisions faster then is possible for an ideal hash. Length extension
attacks make HMAC use 2 hashes instead of 1, something that any
speed comparison should remember. (HMAC is a bad idea anyway: quadratic
security bounds are not the best possible, we have to use nonces anyway to
prevent replay attacks, so Wegman-Carter is a better idea for better
in{faster, more secure}. GCM would be an example of this.)

As a KDF none of this really matters, and for signatures collision
resistance is still the most important thing. But sometimes we do depend on
random oracle assumptions in proofs, and SHA3 is designed to be a better
approximation to a random oracle then SHA2.

Sincerely,
Watson Ladd

-- 
"Those who would give up Essential Liberty to purchase a little Temporary
Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin

[Attachment #5 (text/html)]

Turns out that almost everything you said about SHA3 vs SHA256 performance is \
wrong:&lt;div&gt;&lt;a href="http://bench.cr.yp.to/impl-hash/blake256.html"&gt;http://bench.cr.yp.to/impl-hash/blake256.html&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="http://bench.cr.yp.to/impl-hash/blake256.html"&gt;http://bench.cr.yp.to/impl-hash/blake256.html&lt;/a&gt;&lt;/div&gt;
 &lt;div&gt;Blake256 performs better except on the Cortex A. On the ARM v6 it outperforms \
SHA256. This includes&lt;/div&gt;&lt;div&gt;the ppc32, hardly anyones idea of a server \
powerhouse.&lt;/div&gt;&lt;div&gt;Furthermore, crypto efficiency is less likely to be a \
bottleneck on a client then a node: server architectures matter&lt;/div&gt; &lt;div&gt;much more \
because we do a lot more crypto on them. (This isn't true for each connection but \
servers handle more&lt;/div&gt;&lt;div&gt;connections then \
clients.)&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Secondly SHA256 is already weaker then an ideal \
hash function. Joux's multicollision attack works on all Merkel-Damgard \
constructions, and gives multicollisions faster then is possible for an ideal hash. \
Length extension attacks make HMAC use 2 hashes instead of 1, something that any \
speed  comparison  should remember. (HMAC is a bad idea anyway: quadratic security \
bounds are not the best possible, we have to use nonces anyway to prevent replay \
attacks, so Wegman-Carter is a better idea for better in{faster, more secure}. GCM \
would be an example of this.)&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As a KDF none of this really \
matters, and for signatures collision resistance is still the most important thing. \
But sometimes we do depend on random oracle assumptions in proofs, and SHA3 is \
designed to be a better approximation to a random oracle then SHA2.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sincerely,&lt;/div&gt;&lt;div&gt;Watson Ladd&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;-- \
&lt;br&gt;"Those who would give up Essential Liberty to purchase a little Temporary \
Safety deserve neither   Liberty nor Safety."&lt;br&gt;-- Benjamin Franklin &lt;br&gt;

&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111101153004</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-11-01 15:30:04-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>


I too have been following the development of SHA-3 and will toss in my 
2c here.

On 11/01/2011 06:50 AM, Watson Ladd wrote:
&gt; Turns out that almost everything you said about SHA3 vs SHA256
&gt; performance is wrong:
&gt; http://bench.cr.yp.to/impl-hash/blake256.html
&gt; http://bench.cr.yp.to/impl-hash/blake256.html
&gt; Blake256 performs better except on the Cortex A. On the ARM v6 it
&gt; outperforms SHA256. This includes
&gt; the ppc32, hardly anyones idea of a server powerhouse.

I don't know about the specific benchmarks you mentioned, but most of 
the choices fall in this range of 5 to 12 cycles per hashed byte on 
modern CPUs.

SHA-3 is also being developed with attention to the amount of circuitry 
("die area") needed to implement it in hardware. So it's possible that 
hardware acceleration will appear for SHA-3 sooner/instead of SHA-2.

&gt; Furthermore, crypto efficiency is less likely to be a bottleneck on a
&gt; client then a node:

Desktop PCs with a 50 W CPU are shrinking relative to the whole client 
pie. Mobile devices are the growing slice, there the concerns are 
different: is hardware acceleration available? and what is power 
consumption?

If I had to guess what would be most available and power-efficient on 
mobile devices 5 years from now, I'd guess SHA-3.

&gt; server architectures matter
&gt; much more because we do a lot more crypto on them. (This isn't true for
&gt; each connection but servers handle more
&gt; connections then clients.)

How big of a network pipe does a dedicated Tor server need to bottleneck 
on the crypto?

Doesn't the architecture of Tor prefer a larger number of smaller nodes?

&gt; Secondly SHA256 is already weaker then an ideal hash function. Joux's
&gt; multicollision attack works on all Merkel-Damgard constructions, and
&gt; gives multicollisions faster then is possible for an ideal hash.

Agreed, SHA-3 will fix some problems. Some of these things we've been 
working around so long that they seem normal.

&gt; Length
&gt; extension attacks make HMAC use 2 hashes instead of 1, something that
&gt; any speed comparison should remember. (HMAC is a bad idea anyway:
&gt; quadratic security bounds are not the best possible, we have to use
&gt; nonces anyway to prevent replay attacks, so Wegman-Carter is a better
&gt; idea for better in{faster, more secure}. GCM would be an example of this.)

I know Wegman-Carter is not new, but where is it being used in practice?

It looks like NIST took a while to figure out the security on GCM:
&gt; http://www.csrc.nist.gov/groups/ST/toolkit/BCM/documents/comments/CWC-GCM/Ferguson2.pdf
&gt; http://csrc.nist.gov/groups/ST/toolkit/BCM/documents/Joux_comments.pdf


&gt; As a KDF none of this really matters,

What matters for a KDF is some assurance that the attacker will not have 
access to a significantly faster implementation than the defender. I 
believe scrypt has the best claim to that right now, although something 
based on the arcfour algorithm could do a little better.

This is a case where performance for the defender translates to 
additional security (he can set the iteration count higher).

Having benchmarks on optimized hardware implementations is thus important.

&gt; and for signatures collision
&gt; resistance is still the most important thing. But sometimes we do depend
&gt; on random oracle assumptions in proofs, and SHA3 is designed to be a
&gt; better approximation to a random oracle then SHA2.

There's sometimes also a benefit of being with the current NIST 
recommendation. I suspect more users will migrate off of SHA-1 to SHA-3 
than they will to SHA-2.

NIST may eventually 'deprecate' SHA-2 in favor of SHA-3 due to just the 
length extension issue. Which is not to say that I think there's a real 
problem using SHA-2 correctly, only that you may end up having to 
explain repeatedly why it's not a problem.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111101173403</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 17:34:03-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, Nov 1, 2011 at 5:50 AM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; Turns out that almost everything you said about SHA3 vs SHA256 performance is \
&gt; wrong:

I should have specified that from the page I referenced --
http://bench.cr.yp.to/results-hash.html -- I was looking at the first
x86_64 machine: amd64 Sandy Bridge (206a7); 2011 Intel Core i7-2600K;
4 x 3400MHz; "sandy0" and the first ARM machine: armeabi (v7-A, Cortex
A8); 2009 Freescale i.MX515; 1 x 800MHz; "gcc33". Given that I was
using the numbers from those two machines, I believe what I wrote was
correct.

Now, perhaps those weren't the right machines to use for examples. My
reasoning was that they are the newest and most efficient of their
respective instruction sets, so they're likely to be more
representative of their successors. I don't know why SHA-256 was
slower on the ARMv6 that you mentioned.

&gt; Furthermore, crypto efficiency is less likely to be a bottleneck on a client then a \
&gt; node: server architectures matter much more because we do a lot more crypto on \
&gt; them. (This isn't true for each connection but servers handle more connections then \
&gt; clients.)

My letter, to which you replied is a quantitative argument to the
contrary. The bottom line quantities that I came up with were that if
you used 100% of one Sandy Bridge core, then you could hash at least
190 Mbytes/s, even with the less efficient of the two hash functions
(SHA-256), and if you used 10% of a Cortex-A8, then you could hash at
least 2.5 Mbytes/s even with the less efficient of the two
(Blake-256).

As far as I understand, the case where a server would be asked to
handle more than 190 Mbytes/s will be rarer than the case where a
client will be asked to handle more than 2.5 Mbytes/s, during the
lifetime of the next version of the Tor protocol. I don't know much
about Tor performance so I could be all wrong about that.

Now, maybe the assumption that you can afford to dedicate 100% of a
server core but only 10% of the embedded CPU is wrong. Even if you
change the assumption to 50% of one server core vs. 50% of your
embedded CPU, the server will probably still be network-limited but
the embedded chip may be CPU-limited.

&gt; Secondly SHA256 is already weaker then an ideal hash function.

&gt; and SHA3 is designed to be a better approximation to a random oracle then SHA2.

I'm aware of these considerations, and I don't disagree! Thank you for
bringing them up. But they don't prove that SHA-256 will prove
vulnerable to any real attack. Likewise, there could be some
unforeseen critical weakness in a SHA-3 candidate. We don't have any
proof one way or the other about these questions. My personal,
under-informed guess is that none of SHA-256, Blake, Skein will prove
vulnerable to any real attack during the lifespan of the next version
of the Tor protocol.

I would be interested in other people's personal guesses about that
question, especially if you've studied the actual algorithms and
attacks closely.

Regards,

Zooko
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111101174607</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 17:46:07-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, Nov 1, 2011 at 9:30 AM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt; I too have been following the development of SHA-3 and will toss in my 2c here.

Hi Marsh! You made several good points, a few of which I quoted below.
Your points make me think, speaking loosely, that SHA-3 will turn out
to be the best function to use due to reasons of popularity or
bureaucratic fiat. Perhaps someday the chips you buy will come with
SHA-3 circuits built-in but not SHA-2, and perhaps people will start
looking at you funny if you use SHA-2 when everyone else is using
SHA-3. These may be good reasonsperhaps better reasons that the
moderate performance issues I previously mentioned or the completely
indefensible vague unease I've expressed about SHA-3 being too new.

You did make one small technical mistake though:

&gt; SHA-3 is also being developed with attention to the amount of circuitry
&gt; ("die area") needed to implement it in hardware. So it's possible that
&gt; hardware acceleration will appear for SHA-3 sooner/instead of SHA-2.

Although the SHA-3 designers have indeed tried to optimize for that, I
think SHA-256 is actually still better. See Fig. 17 of
http://eprint.iacr.org/2009/510.pdf .

Below my signature is just me quoting a few of the points you made. :-)

Regards,

Zooko

&gt; Agreed, SHA-3 will fix some problems. Some of these things we've been
&gt; working around so long that they seem normal.

&gt; There's sometimes also a benefit of being with the current NIST
&gt; recommendation. I suspect more users will migrate off of SHA-1 to SHA-3 than
&gt; they will to SHA-2.

&gt; NIST may eventually 'deprecate' SHA-2 in favor of SHA-3 due to just the
&gt; length extension issue. Which is not to say that I think there's a real
&gt; problem using SHA-2 correctly, only that you may end up having to explain
&gt; repeatedly why it's not a problem.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111101193603</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-01 19:36:03-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, Nov 1, 2011 at 12:46 PM, Zooko O'Whielacronx &lt;zooko@zooko.com&gt; wrote:
&gt;
&gt; On Tue, Nov 1, 2011 at 9:30 AM, Marsh Ray &lt;marsh@extendedsubset.com&gt; wrote:
&gt; &gt; I too have been following the development of SHA-3 and will toss in my 2c here.

[....ommitted...]
&gt;
&gt; Although the SHA-3 designers have indeed tried to optimize for that, I
&gt; think SHA-256 is actually still better. See Fig. 17 of
&gt; http://eprint.iacr.org/2009/510.pdf .


Its wonderful that you provided references, and even told me what
diagram to look for.
But figure 17 has every finalist other then Skein outperforming SHA2
in hardware (last column is bits per second), and that was optimizing
for speed. In the case of Keccak, that performance is impressively
greater. Its possible at the 512 level these reverse, but I don't see
that in there.
Sincerely,
Watson Ladd

&gt;
&gt; Below my signature is just me quoting a few of the points you made. :-)
&gt;
&gt; Regards,
&gt;
&gt; Zooko
&gt;
&gt; &gt; Agreed, SHA-3 will fix some problems. Some of these things we've been
&gt; &gt; working around so long that they seem normal.
&gt; 
&gt; &gt; There's sometimes also a benefit of being with the current NIST
&gt; &gt; recommendation. I suspect more users will migrate off of SHA-1 to SHA-3 than
&gt; &gt; they will to SHA-2.
&gt; 
&gt; &gt; NIST may eventually 'deprecate' SHA-2 in favor of SHA-3 due to just the
&gt; &gt; length extension issue. Which is not to say that I think there's a real
&gt; &gt; problem using SHA-2 correctly, only that you may end up having to explain
&gt; &gt; repeatedly why it's not a problem.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev



--
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither   Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111101202013</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 20:20:13-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, Nov 1, 2011 at 1:36 PM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; 
&gt; &gt; See Fig. 17 of http://eprint.iacr.org/2009/510.pdf .
&gt; 
&gt; Its wonderful that you provided references, and even told me what diagram to look \
&gt; for. But figure 17 has every finalist other then Skein outperforming SHA2 in \
&gt; hardware (last column is bits per second), and that was optimizing for speed. In \
&gt; the case of Keccak, that performance is impressively greater. Its possible at the \
&gt; 512 level these reverse, but I don't see that in there.

I'm sorry, once again I failed to spell out explicitly what I was thinking.

In this case it is that the relevant metric is area rather than
throughput. This is because of what Marsh Ray brought upthe prospect
that future chips might come with a SHA-3 or a SHA-256 circuit built
in. The advantage to a chip designer of adding such a circuit in is,
of course, that their customers may want it and so buy their chip
instead of their competitors'. The disadvantage is the cost in design
complexity (~= time) and die area (~= marginal cost to print one of
these chips). I'm told that some of these embedded chips are
exquisitely sensitive to marginal costs, such that a few pennies can
make the difference between success and failure of the product!

Therefore, in the context of whether we can expect SHA-3 and/or
SHA-256 circuits to come built into our chips in the future, the fact
that SHA-256 can be implemented in a smaller circuit means it would be
cheaper for a chip maker to include it.

As for performance, note that the vertical axis of Fig. 17 is in
Gbit/s. Even the slowest implementation of SHA-256 was at something
like 0.8 Gbit/s, which is about 0.1 Gbyte/s which is about 100
MByte/s, which is more than any one circuit will probably be asked to
handle. If the chip designer expects the user to need more than 100
MByte/s throughput, he can put multiple circuits in there. For example
the new SPARC T4 chip comes with 8 CPU cores, each with its own
SHA-256 circuit (as well as AES and other algorithms).

On the other hand, I still think back to Marsh's observation that the
*perception* of superiority of SHA-3 over SHA-2 might mean that the
actual chips of the future come with SHA-3 even if it is more
expensive.

Oh neat! I just learned that the 64-bit ARMv8 is going to come with
SHA-256: http://www.theregister.co.uk/2011/10/28/arm_holdings_arm_v8/

Very cool.

Another factor which might prolong SHA-256's life is its role as the
proof-of-work in Bitcoin. This causes there to be a global race for
efficient SHA-256 implementation, and whoever gets even a little bit
ahead in that race can rake in profits. The current leading
technologies are ATI GPUs and FPGAs, but if there were a chip with an
efficient enough SHA-256 built in, perhaps they could sell it to
Bitcoin miners.

Regards,

Zooko
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111101215100</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2011-11-01 21:51:00-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, Nov 1, 2011 at 1:20 PM, Zooko O'Whielacronx &lt;zooko@zooko.com&gt; wrote:
&gt; ...
&gt; Therefore, in the context of whether we can expect SHA-3 and/or
&gt; SHA-256 circuits to come built into our chips in the future, the fact
&gt; that SHA-256 can be implemented in a smaller circuit means it would be
&gt; cheaper for a chip maker to include it.

my strong preference for SHA-2-256 is precisely for this reason. i use
multiple systems with hardware accelerated SHA-2-256. these systems
will never have accelerated SHA-3.

adoption of SHA-3 into hardware designs may change this in the future;
i am skeptical :)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111101045955</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-01 04:59:55-0400</timestampReceived><subject>Re: [tor-dev] Draft sketch document with ideas for future crypto ops</subject><body>

[Attachment #2 (multipart/alternative)]


What about this for modification resistance?
We keep a count of all cells passing and use AES in CTR mode with a 2 part
counter: the first part the cell counter, the second one a block counter.
Then to authenticate the cell we can use a 16 byte tag and a Wegman-Carter
MAC. This gives a total overhead of 48 bytes for a three hop link, which is
half the cited one, and which
is provably as secure as AES.

ChaCha is a component part of one of the SHA-3 finalists, namely JH. If JH
is selected as the SHA3 candidate, this may (read may) entail something
about the security of ChaCha. The HAIFA construction JH uses doesn't say
much about proofs of security, unlike the sponge papers.

ECC groups don't matter much: there are some really bad choices out there,
but any attack against Curve25519 is
going to probably imply an attack against NIST P-256 as well. Its not that
different from picking a particular DH prime: some are bad because p-1 is
smooth, but if not then they all look the same.

2012 is coming soon: The schedule says between March and June of this year
SHA3 will be announced. Everything after that involves bureaucracy. Why
switch to SHA256 and then to SHA3 when we won't be done before March anyway?

In general options are bad in crypto: we should migrate as few times as
possible to avoid various attacks that might involve degrading a
negotiation. As for Certicom their patents were licensed by NIST.
Unfortunately for them they openly admit on their website that these are
mostly implementation patents. To my untrained eye DJB's analysis is spot
on. There is also http://tools.ietf.org/html/rfc6090 which seems to do
something similar.

Sincerely,
Watson Ladd
On Mon, Oct 31, 2011 at 8:25 PM, Nick Mathewson &lt;nickm@torproject.org&gt;wrote:

&gt; Here's an early draft document trying to sketch out the parameters for
&gt; migrating to better crypto ops and designs in the future.
&gt;
&gt; Comments are invited, even comments of the form "you will need to be
&gt; much more specific here before I can say anything sensible."
&gt;
&gt; This is proposals/ideas/xxx-new-crypto-sketch.txt in the torspec
&gt; repository.
&gt;
&gt;
&gt;
&gt; Title: Design sketch for new crypto ops
&gt; Date: 31 Oct 2011
&gt; Author: Nick Mathewson
&gt;
&gt; 0. Overview
&gt;
&gt;  The point of this document is to discuss what crypto we ought to be using.
&gt;  See "Initial Thoughts on Migrating Tor to New Cryptography" from last year
&gt;  for general guidelines and principles.
&gt;
&gt;  In broad strokes, the parts of our crypto are:
&gt;
&gt;    IDENTITY KEYS AND FINGERPRINTS
&gt;       Addressed here in Section 2.
&gt;    LINK CRYPTO (TLS) --
&gt;       Addressed in proposals 176, 184.  We say a little here in section 5,
&gt;       though.
&gt;    CREATE/EXTEND CRYPTO --
&gt;       Addressed in xxx-ntor-handshake.txt and rransom's EXTEND draft at
&gt;       [*] and subsequent discussion on the tor-dev mailing list.  Not
&gt;       considered here.
&gt;    RELAY CRYPTO
&gt;       Addressed here in Section 6.
&gt;    DIRECTORY SYSTEM
&gt;       Addressed here.
&gt;    HIDDEN SERVICE SYSTEM
&gt;       Addressed in a forthcoming document by rransom.
&gt;
&gt; [*] https://lists.torproject.org/pipermail/tor-dev/2011-March/002547.html
&gt;
&gt; 1. Base algorithm choice
&gt;
&gt;  There seem to be two main candidate algorithms for signatures: RSA
&gt;  with big keys (hereinafter "RSA&gt;1024"); and Ed25519, which is DSA with
&gt;  the sharp edges filed off on an Edwards curve related to DJB's
&gt;  Curve25519.  We can look at other ECC groups too.  {But see ECC
&gt;  Notes in 1.1 below.}
&gt;
&gt;  FOR DIFFIE-HELLMAN: Curve25519 seems like a decent choice; failing
&gt;  that, one of the NIST P-groups.  Failing that, DH on Z_p with big
&gt;  groups (hereinafter "DH&gt;1024").  {But see ECC Notes in 1.1 below.}
&gt;
&gt;  FOR A HASH FUNCTION: SHA256, switching to SHA3 in 2012 when it comes
&gt;  out.  It might be worthwhile waiting for SHA3 in most places and
&gt;  skipping over the SHA256 stage entirely.
&gt;
&gt;  FOR A STREAM CIPHER: AES-CTR is in one sense a conservative choice
&gt;  inasmuch as AES is well-analyzed, but AES's well-known issues with
&gt;  cache-based timing attacks are pretty worrisome.  We can mitigate that
&gt;  some by using random secret IVs for AES-CTR, so that we will be
&gt;  encrypting neither attacker-chosen nor attacker-known plaintext with
&gt;  our AES cipher, but that's a bit kludgy.  There are also supposed to
&gt;  be time-invariant implementations that use Intel's AESNI instructions
&gt;  where available, and time-invariant implementations that use
&gt;  bit-slicing.
&gt;
&gt;  Salsa20 is what rransom likes these days, but IMO we aren't competent
&gt;  to tell whether it looks good or not; the existing attacks against it
&gt;  don't look like very bad news to me, but who knows whether it's
&gt;  getting enough attention that we can read.  See also ChaCha; see also
&gt;  the other eSTREAM winners/finalists; see also SHA3 if the SHA3 winner
&gt;  specifies a way to use it as a stream cipher, or specifies an
&gt;  underlying stream/block cipher.
&gt;
&gt;  If we're feeling cautious, we could run two independently-keyed stream
&gt;  ciphers and xor their streams together.
&gt;
&gt;  FOR A RANDOM NUMBER GENERATOR: We currently use OpenSSL seeded with
&gt;  RAND_poll and with platform entropy.  OpenSSL uses a message-digest-
&gt;  based algorithm from SSLeay (See http://linux.die.net/man/3/sslrand
&gt;  for the ugly details.)  The platform entropy management can be messy,
&gt;  obscure, or both.  I suggest that:
&gt;
&gt;    * We should seed our PRNG with more entropy sources if we can find
&gt;      some promising code with an appropriate license
&gt;    * Instead of just using OpenSSL's PRNG, we should use OpenSSL's
&gt;      MD-based PRNG xor'd with some other good PRNG.  (Fortuna,
&gt;      maybe. Is there a combine operation better than xor? See also SHA3
&gt;      if the SHA3 winner is one that specifies a PRNG mode of
&gt;      operation.)
&gt;    * We should consider splicing this combined-stream PRNG into OpenSSL
&gt;      as the RNG it uses for SSL and key generation.
&gt;    * We should re-seed the RNG before and after very sensitive
&gt;      operations, like private key generation.
&gt;
&gt; 1.1. ECC notes
&gt;
&gt;  ECC is the brave new[*] crypto of the future!  It's faster[**] than
&gt;  doing crypto in Z_n (as we do for RSA and DH now) for equivalent
&gt;  levels of security, and the resulting outputs are much shorter.
&gt;
&gt;  As near as I can tell as a layman, Certicom is muddying the waters as
&gt;  much as possible wrt claiming that it's nigh-impractical to deploy ECC
&gt;  without licensing their patents.  This is rather like the silliness
&gt;  that PKP used to pull back in the day, where they claimed that their
&gt;  patents covered not only the existing public key cryptography
&gt;  algorithms, but also the very idea of public key cryptography itself.
&gt;
&gt;  DJB claims that for every patent he's aware of, either that patent
&gt;  doesn't cover his code, or that patent is invalid because of prior
&gt;  art.  I'm not going to try to evaluate these claims, since I'm not
&gt;  supposed to be reading patents for typical "let's avoid the appearance
&gt;  of knowing infringement" reasons.  But before we dive into the world
&gt;  of ECC, we should see if we can ask any friendly patent attorneys and
&gt;  ECC experts for a second or third opinion here.
&gt;
&gt;  I note in passing that nearly all of the patents that DJB mentions in
&gt;  his list would appear to expire over the next 12 months or so.
&gt;
&gt;  Additionally, there are ECC groups out there less fast than DJB's, but
&gt;  more widely available and analyzed.  We should consider some of those
&gt;  too.
&gt;
&gt;  One final issue to investigate is whether using these algorithms will
&gt;  make any major free software distribution decide not to include us.  I
&gt;  seem to recall seeing that one or two of the big ones had at one point
&gt;  decided to ship OpenSSL only with ECC disabled, either because of real
&gt;  patent concerns, or because of an opinion that the Certicom license
&gt;  for ECC use in TLS was problematic for free software, or something
&gt;  like that.  We should check that out.
&gt;
&gt;  [*] Actually, it's older than onion routing, and older than some
&gt;  members of the Tor Project.
&gt;
&gt;  [**] Actually, because of the common practice of choosing a small-ish
&gt;  prime value (65537) for e in RSA, RSA public key operations can be a
&gt;  little faster than equivalent-security ECDH or ECDSA operations.  The
&gt;  private key operations in RSA are still much much slower.
&gt;
&gt; 2. New identities
&gt;
&gt;  Identity keys and their fingerprints are used:
&gt;    - To sign router descriptors.
&gt;    - To identify nodes in consensus directories.
&gt;    - To make sure we're talking to the right node in the link handshake.
&gt;    - To make sure that the extending node is talking to the right next
&gt;      node when sending an extend cell.
&gt;    - To identify particular nodes in the hidden service subsystem.
&gt;    - To identify nodes in the UI in various places.
&gt;    - Internally, to identify a node uniquely in the codebase.
&gt;    - To determine which part of the circuit ID space to use on a Tor
&gt;      instance's links.
&gt;
&gt; 2.1. New identities, option 1: "RSA&gt;1024, slow migration"
&gt;
&gt;  In this option, we use RSA for identity keys indefinitely.  Nearly all
&gt;  operations done with an identity key are signature checking; signing
&gt;  happens only a few times an hour per node even with pathological
&gt;  cases.  Since signature checking is really cheap with RSA, there's no
&gt;  speed advantage for ECC here.  (There is a space advantage, since the
&gt;  keys are much smaller.)
&gt;
&gt;  The easiest way to migrate to longer identity keys is to tell all Tors
&gt;  to begin accepting longer identity keys now, and to tweak all our
&gt;  protocols so that longer RSA identity keys are understood.  We should
&gt;  then have a pair of parameters in the consensus that determines the
&gt;  largest and smallest acceptable identity key size in the network.
&gt;  Clients and servers should reject any keys longer or shorter than
&gt;  specified.  Once all versions of Tor can accept long identity keys, we
&gt;  raise the maximum size from 1024 to somewhere in the 2048-4096 range.
&gt;
&gt; 2.2. New identities option 2: "RSA&gt;1024, faster migration"
&gt;
&gt;  In this option, we use RSA for identity keys indefinitely as above.
&gt;  But we allow nodes to begin having longer identities now, even though
&gt;  older Tors won't understand them.  This implies, of course, that every
&gt;  such node needs to have at least 2 identities: one RSA1024 identity
&gt;  for backward compatibility, one RSA&gt;1024 identity for more secure
&gt;  identification.
&gt;
&gt;  We would have these identities cross-certify as follows: All keys
&gt;  would be listed in the router descriptor.  RSA&gt;1024 keys would be
&gt;  called something other than identity-key, so as not to confuse older
&gt;  clients.  A signature with the RSA&gt;1024 key would appear right before
&gt;  the current RSA1024 signature.  This way, signed material would
&gt;  include both keys, and would be signed by both keys.
&gt;
&gt;     [In other words, descriptors would look something like:
&gt;
&gt;      router foo...
&gt;      ...
&gt;      identity-key
&gt;      -----BEGIN RSA KEY-----
&gt;      1024-bit RSA key here
&gt;      -----END RSA KEY-----
&gt;      ext-identity-key
&gt;      -----BEGIN RSA KEY-----
&gt;      3072-bit RSA key here
&gt;      -----END RSA KEY-----
&gt;      ...
&gt;      ext-signature
&gt;      -----BEGIN SIGNATURE-----
&gt;      signature of everything through "ext-signature\n",
&gt;      using the long key
&gt;      -----END SIGNATURE-----
&gt;      router-signature
&gt;      -----BEGIN SIGNATURE-----
&gt;      signature of everything through "router-signature\n",
&gt;      using the short key
&gt;      -----END SIGNATURE-----
&gt;
&gt;     ]
&gt;
&gt;  See "UI notes" in the "new fingerprints" section below for some of the
&gt;  implications of letting nodes have multiple identity keys.
&gt;
&gt;  We'll need to advertise these new identities in consensus directories
&gt;  too; see 4.2 below for more info there.
&gt;
&gt; 2.3. New identities option 3: "RSA&gt;1024 and/or Ed25519, faster migration"
&gt;
&gt;  As in option 2 above, but new keys can also be Ed25519.  If we expect
&gt;  that not all installations will allow Ed25519 (see "ECC Notes",
&gt;  section 1.1), we'll need to say that every server with an Ed25519 key
&gt;  must also have an RSA&gt;1024 key.
&gt;
&gt; 2.4. Implications for current use of identity keys
&gt;
&gt;  Let's review our use of identity keys again and make sure that we can
&gt;  handle all of them with the ideas above.
&gt;
&gt;    - To sign router descriptors.
&gt;
&gt;  We discussed this in 2.2.
&gt;
&gt;    - To make sure we're talking to the right node in the link handshake.
&gt;
&gt;  The current v3 link handshake can handle presenting multiple identity
&gt;  certificates in the CERT cell.  We should consider ourselves to be
&gt;  connected to a node with identity X if _any_ of the identity
&gt;  certificates that it presents in its authenticated CERT cell has
&gt;  identity X.  To handle EXTEND cells correctly, we should verify every
&gt;  identity we can.
&gt;
&gt;    - To make sure that the extending node is talking to the right next node
&gt;      when sending an extend cell.
&gt;
&gt;  The new extend cell format needs to allow the client to tell the
&gt;  extending node about some identity for the destination node that the
&gt;  extending node will be able to understand.  This is a capability of
&gt;  the extending node that the client needs to be able to check. (Also,
&gt;  the extend cell needs to hash that identity in a form the extending
&gt;  node can understand, but that's a fingerprint issue.)
&gt;
&gt;    - To determine which part of the circuit ID space to use on a Tor
&gt;      instance's links.
&gt;
&gt;  We can continue to use RSA1024 identity key comparison here by
&gt;  default.  We can also use some other parameter of the v3 handshake, or
&gt;  introduce a new link protocol where if the initiator authenticates,
&gt;  the initiator always gets the low circIDs and the responder always
&gt;  gets the high ones.
&gt;
&gt;    - To identify nodes in consensus directories.
&gt;    - To identify nodes in the UI in various places.
&gt;    - Internally, to identify a node uniquely in the codebase.
&gt;
&gt;  See sections 3 and 4 below.
&gt;
&gt;    - To identify particular nodes in the hidden service subsystem.
&gt;
&gt;  Out of scope.
&gt;
&gt; 2.5. Migrating away from short ID keys entirely
&gt;
&gt;  Eventually, no version of Tor that requires 1024-bit identity keys will
&gt;  remain.  When that happens, we should stop using them entirely.  That
&gt;  means that if we take any path other than the "slow migration" path of
&gt;  2.1, we'll need to make everything that looks at a node's identity
&gt;  also accept nodes with _only_ a RSA&gt;1024/Ed25519 identity.
&gt;
&gt;  At the directory service level, we should have an option to allow
&gt;  nodes without RSA1024 identity keys (off until all clients and nodes
&gt;  accept new identity keys).
&gt;
&gt; 2.6. Selective correctness attacks
&gt;
&gt;  For any scheme based on having multiple signature types on a router
&gt;  descriptor or other document, an attacker could mount a partitioning
&gt;  attack by making a document which older clients will accept but newer
&gt;  clients will reject.
&gt;
&gt;  It's easy to prevent this at the consensus step: directory authorities
&gt;  MUST NOT accept any descriptor unless all clients will be able to
&gt;  verify it.
&gt;
&gt;  For bridge descriptors, we need to investigate more carefully.
&gt;
&gt; 3. New fingerprints
&gt;
&gt;  Right now we compute fingerprints by taking the SHA1 hash of an ASN1
&gt;  encoding of the RSA1024 identity key.  We encode this in hex almost
&gt;  everywhere, and sometimes prefix it with a $.
&gt;
&gt;  I propose that fingerprints of the future be determined by taking a
&gt;  digest using SHA256 or SHA3 of:
&gt;
&gt;      "Hash Algorithm Name", "Key Type Name", encoded key
&gt;
&gt;  When representing these internally, we should include the hash
&gt;  algorithm that was used.  When representing them in the UI, we should
&gt;  use the notation %b64, where b64 is a base-64 encoding, omitting the
&gt;  trailing =s.
&gt;
&gt;  (Other plausible characters to use are @, ?, +, ~, =, etc.  I like %,
&gt;  but can be persuaded.  Bikeshed bikeshed bikeshed.)
&gt;
&gt;  Since 43 base-64 characters is enough to represent a 256-bit digest,
&gt;  with 2 bits left over, I propose that the b64 value encode
&gt;
&gt;      hh | D(hash algorithm name, key type, encoded key)
&gt;
&gt;  where hh is a 2-bit value, with one of the following values:
&gt;
&gt;      00 -- sha256
&gt;      01 -- sha3
&gt;      10 -- to be determined
&gt;      11 -- reserved.
&gt;
&gt;  We should investigate in the interface whether it's plausible to allow
&gt;  a prefix of a node ID where the full ID would otherwise be required.
&gt;  That seems risky for short prefixes, though.
&gt;
&gt; 3.1. How many fingerprints is that anyway?!
&gt;
&gt;  Suppose that we allow sha256 and sha3 as hash algorithms, and we allow
&gt;  each node to have 3 identity keys: one RSA1024, one RSA&gt;1024, and one
&gt;  ECC.  Then we would have 7 fingerprints (6 plus the legacy
&gt;  SHA1(RSA1024) fingerprint), for a total of 20+6*32==212 bytes per
&gt;  node.
&gt;
&gt;  It's not a horrible problem to accept them all in the UI, but the UI
&gt;  isn't the only place that needs to know fingerprints.  Instead, let's
&gt;  say that RSA1024 identities are only identified with SHA1 hashes.
&gt;  This limits our fingerprint load to a more manageable 20+32*2 == 84
&gt;  bytes per node.  Still not great, though.
&gt;
&gt; 3.2. What does this imply for the UI?
&gt;
&gt;  In the UI we'll lose the property that no node has more than one
&gt;  fingerprint: I do not believe that this actually hurts us.
&gt;
&gt; 3.3. Implications for directory information
&gt;
&gt;  Clients must know a hash for each node's identity key, or else they
&gt;  can't make an authenticated connection to the node or tell ORs how to
&gt;  extend to the node.
&gt;
&gt;  This means that if client Alice wants to connect to node Bob, Alice
&gt;  must have a fingerprint of Bob's ID key such that she understands the
&gt;  ID key type and the fingerprint algorithm.  If Alice wants to extend
&gt;  from Bob to Carol, she must have a fingerprint of Carol's ID key such
&gt;  that Bob understands the ID key type and the fingerprint algorithm.
&gt;
&gt;  So for every node, Alice must not only know a fingerprint that *she*
&gt;  can use for that node, but also a set of fingerprints such that every
&gt;  node can understand at least one fingerprint in the set.
&gt;
&gt;  This implies a proliferation of fingerprints!  We should tread
&gt;  carefully here.  To prevent proliferation, the easiest solution is not
&gt;  to add too many new types and to have a good plan for retiring older
&gt;  types.
&gt;
&gt; 3.4. Implications for EXTEND cells
&gt;
&gt;  As mentioned in 3.3, when a client Alice tells node Bob to extend
&gt;  to node Carol, she needs to give Bob a fingerprint for Carol that Bob
&gt;  will understand: one where Bob understands the digest algorithm, and
&gt;  understands the identity key type.
&gt;
&gt;  There are two ways we can do this:
&gt;
&gt;    1) Alice's EXTEND cell contains every fingerprint for Carol that
&gt;       Alice knows about.  Bob treats the cell as valid if every one he
&gt;       can verify is correct.
&gt;
&gt;    2) Alice knows which fingerprint types Bob understands (either via
&gt;       his version, or something else in his directory info).  She
&gt;       selects a fingerprint for Carol using the best one of these
&gt;       types.
&gt;
&gt;  The first seems more robust to me, if we have space for enough bytes.
&gt;  If we proliferate too many types, though, we'll need to do the second.
&gt;
&gt; 4. Directory changes
&gt;
&gt; 4.1. Better cross-referencing
&gt;
&gt;  In some places, directory objects cross-reference one another by SHA1
&gt;  hash.  They should use a better hash algorithm instead.
&gt;
&gt;  This does make problems in a few cases.
&gt;
&gt;  Router descriptors and extrainfo descriptors:
&gt;
&gt;     One problematic case is in determining node families.  If node A
&gt;     and node B want to list each other as being in the same family,
&gt;     they need to do so in a way that clients can interpret.  That could
&gt;     mean listing SHA1-RSA1024 fingerprints so old clients understand,
&gt;     AND new fingerprints for security. (But *that* could create
&gt;     interesting partitioning attacks wherein your family looks
&gt;     different depending on who's looking.)
&gt;
&gt;       Solution: we need to move the responsibility for combining node
&gt;       families into the consensus voting process, so clients don't
&gt;       need to understand the cross-reference types themselves.
&gt;
&gt;     Another case is in certifying extrainfo documents from descriptors.
&gt;     For that, we can list multiple extrainfo digests, either on the
&gt;     extrainfo line, or on additional lines.
&gt;
&gt;  Voting and consensus documents:
&gt;
&gt;     Adding more fingerprints in votes isn't a problem; votes are a tiny
&gt;     fraction of authority bw usage.  Adding more hashes is easy.
&gt;
&gt;     For consensus documents, we ought to have flavors that you can
&gt;     download depending on what set of fingerprint types you
&gt;     understand.
&gt;
&gt;     For integrity purposes, consensuses can refer to microdescriptors
&gt;     or descriptors by any digest type that the client understands.  But
&gt;     for downloading purposes, the digest type must be one that
&gt;     directory caches also support: see 4.4.
&gt;
&gt; 4.2. More fingerprints
&gt;
&gt;  Because extending from node A to node B requires that we have node B's
&gt;  fingerprint in a way that node A will understand, it is not enough to
&gt;  get a set of identity fingerprints for each node in the format that
&gt;  the client likes best -- see 3.3 and 3.4 above.  So every flavor of
&gt;  consensus we serve needs to include a node identity in a format the
&gt;  client understands, and node identities in formats such that every
&gt;  node will understand at least one.
&gt;
&gt; 4.3. An option: compound signatures on directory objects
&gt;
&gt;   In Tor 0.2.2.x and later, when we check a signature on a directory
&gt;   object (not including hidden service descriptors), we only look at
&gt;   the first DIGEST_LEN bytes of the RSA-signed data.  Once 0.2.1.x is
&gt;   obsolete, or on any types of signatures not checked in 0.2.1.x, we
&gt;   can use the rest of the space.  (We're using PKCS1 padding on our
&gt;   signatures, which has an overhead of 11 bytes.  Signing a SHA1 hash
&gt;   with a 1024-bit key therefore leaves 128-11-20==97 more bytes we
&gt;   could use for a SHA2 or a SHA3 hash.)
&gt;
&gt; 4.4. Downloading by digest
&gt;
&gt;   We should have directory caches support downloading objects by more
&gt;   hash types.  Right now, descriptors are downloaded by their SHA1
&gt;   hashes and microdescriptors by their SHA256 hashes.  This is okay for
&gt;   now, but once SHA3 is out, we should support downloading all of these
&gt;   by SHA3 digest.
&gt;
&gt; 5. Link crypto changes
&gt;
&gt;  Currently we use TLS.  That's fine.
&gt;
&gt;  We should however look to longer link keys, bigger DH groups, etc.
&gt;
&gt;  Once TLS versions 1.1/1.2 are available in OpenSSL, we should move to
&gt;  use them, I think.  We should also look into how quickly we can
&gt;  deprecate TLS 1.0 and SSL &lt;= 3 usage.
&gt;
&gt; 6. Relay crypto changes
&gt;
&gt;  There are a few things we might want out of improved relay crypto.
&gt;  They include:
&gt;   - Resistance to end-to-end bitwise tagging attacks.
&gt;   - Better resistance to malleability.
&gt;   - If using counter mode, no block-cipher operations on any value
&gt;     known to the attacker.
&gt;
&gt;  I'll try to provide these in increasing order of difficulty.  None of
&gt;  these is necessarily correct; I should look for a security proof or a
&gt;  better construction for any that we seem likely to use.
&gt;
&gt;  Rationales: Our existing malleability resistance is a kludge.  Doing
&gt;  no block-cipher ops on attacker-known values increases our security
&gt;  margins a little.  Our arguments about tagging attacks hold that an
&gt;  attacker who controls both ends has plenty of ways to win even if
&gt;  tagging attacks are foiled; nonetheless, most of these ways are
&gt;  technically slightly more difficult than xor-based tagging, and it
&gt;  could be useful to boost our defense-in-depth a little bit, just in
&gt;  case other active end-to-end attacks turn out to be harder than we'd
&gt;  thought.
&gt;
&gt; 6.1. Option 1: Use AES-CTR in a less scary mode
&gt;
&gt;   When doing key expansion, in addition to establishing Kf, Kb, Df, and
&gt;   Db, also establish IVf and IVb.  Use the current relay crypto, except
&gt;   instead of starting the counters at 0, start them at IVf and IVb.
&gt;   This way, an attacker doesn't have any known plaintexts to work with,
&gt;   which makes AES a little more robust.
&gt;
&gt; 6.2. Option 2: As 1, but tagging attacks garble the circuit after one
&gt; block.
&gt;
&gt;   Keep an HMAC of all previously received encrypted cells on a circuit.
&gt;   When decrypting a cell, use this HMAC value to determine the first 64
&gt;   bits of the counter; increment the low 64 bits of the counter as
&gt;   usual.
&gt;
&gt;   This way, if an adversary flips any bits before passing the stream
&gt;   through an honest node, no _subsequent_ block will be recoverable.
&gt;
&gt;   To prevent any part of the stream from being re-used, close any
&gt;   circuit if the low 64 bits of the counter would ever wrap (that is,
&gt;   around 295 million terabytes).
&gt;
&gt;   (If we're using a stream cipher with fast re-key, then we can just
&gt;   have the key used for each block be an HMAC of all previously
&gt;   received ciphertext.)
&gt;
&gt; 6.3. Option 3: As 1, but tagging attacks garble the circuit in the same
&gt; block.
&gt;
&gt;   Use a large-block cipher mode, such as BEAR or LIONESS (depending on
&gt;   whether we need a PRP or SPRP).  Base the key material for each block
&gt;   on an HMAC of all previous blocks' ciphertexts.
&gt;
&gt;   This way, if an adversary makes any alteration in a block, that block
&gt;   and all subsequent blocks will be garbled.  It's more expensive than
&gt;   2, though, especially if we need to use a LIONESS construction.
&gt;
&gt;   {I considered IGE here, with a trick where odd-numbered nodes on a
&gt;   circuit start from the front of the block and even-numbered nodes
&gt;   start from the end, but it didn't seem much better.  We should
&gt;   investigate relative performance, though.}
&gt;
&gt; 6.4. Option 4: Shall we have middle nodes be able to fast-stop bad data?
&gt;
&gt;   In all the above options, if a cell is altered, the middle node can
&gt;   at best turn that cell and the rest of the cells on the circuit into
&gt;   garbage, which the last node won't deliver (if honest) or can't
&gt;   deliver (if dishonest).
&gt;
&gt;   Might we prefer to do as in mixnets, and have nodes kill circuits
&gt;   upon receiving altered cells?
&gt;
&gt;   It's not such an obvious improvement.  Including more MACs is more
&gt;   expensive in per-cell overhead.  The attacks that we would foil this
&gt;   way but not with Option 3 are not so much better than the the passive or
&gt;   timing-based-active end-to-end attacks that would still remain.
&gt;
&gt;   Consider that if option 3 is in place, an end-to-end attacker who
&gt;   wants to do a tagging attack at one node can garble the rest of the
&gt;   circuit and see if the output is garbled at the exit node.  But such
&gt;   an attacker could just as easily close the circuit at one of those
&gt;   nodes and watch for a corresponding close event, or even better --
&gt;   simply pause traffic on that circuit for a while and watch for a
&gt;   corresponding gap at the exit.  The only advantage of the garbling
&gt;   attack would be that garbled cells are presumably rarer than circuit
&gt;   closes or traffic pauses, and thus easier to use to distinguish
&gt;   target circuits.  But that's still questionable: the other attacks
&gt;   win fine, and the pause attack doesn't risk detection as much.
&gt;
&gt;   So why might we want to do this?  First, the overhead doesn't need to
&gt;   be as bad as you might first expect (see below).  Second, it would be
&gt;   nice to increase the security margin as much as possible: "attacks
&gt;   only get better".
&gt;
&gt;   So let's figure out how it would look.
&gt;
&gt;   To do this one, we'd want to have outgoing and incoming circuits
&gt;   treated differently.  Incoming cells would get decrypted as in 1
&gt;   above, except that we'd have a MAC on them.  For outgoing cells,
&gt;   each node would check that the first N bytes of the cell
&gt;   match a MAC of all data seen so far, *including the rest of the
&gt;   cell*.  They'd then remove the first N bytes, re-pad the cell
&gt;   with bytes from a PRNG, and decrypt the resulting re-padded cell.
&gt;   (This is basically how mixmaster works, and how mixminion works in
&gt;   the common case.)
&gt;
&gt;   The space overhead here is kind of large: N bits per cell per node.
&gt;   In the most paranoid case, if we used 256-bit HMACs on 3-node paths,
&gt;   that's 96 bytes per cell, which is more than 20% of the total length.
&gt;   But we can probably do better if we let the CREATE operation also
&gt;   tell the node some N to check.  For example, the first node doesn't
&gt;   need to check any bits.  The second and third nodes could check 64
&gt;   bits apiece; that only has 16 bytes overhead total, and high
&gt;   probability of catching any changes. (Birthday attacks don't matter
&gt;   here, and an attacker who mounts this attack for long enough to
&gt;   accidentally find a 64-bit MAC will break so many circuits in the
&gt;   process as to become totally unreliable.)
&gt;
&gt;   All of this leaks the path lengths and position on the path to
&gt;   various nodes.  We might open ourselves up to partitioning attacks if
&gt;   different clients choose different numbers of bits.  What's more, we
&gt;   might leak the length of the path to the last node by how much junk
&gt;   there is at the end of the cell.  So we'd need to be careful!
&gt;
&gt;   Here's a simple construction for this format, to be concrete:
&gt;
&gt;     The CREATE operation's KDF produces the following outputs:
&gt;           Kf, IVf  (stream cipher key and IV for forward direction)
&gt;           Kb, IVb  (stream cipher key and IV for reverse direction)
&gt;           Mf       (MAC key for forward direction)
&gt;           Mb       (MAC key for reverse direction)
&gt;           SEEDf    (PRNG key for forward direction)
&gt;     And it also sets the following user-selected parameter:
&gt;           MACBYTESf (an integer between 0 and 32 inclusive)
&gt;           MACBYTESb (an integer between 0 and 32 inclusive)
&gt;           CANEXIT   (boolean: can we exit from this hop?)
&gt;
&gt;     Let Kf[i], Mf[i], etc denote the parameter Kf, Mf, etc as shared
&gt;     between the client and the i'th node in its circuit.
&gt;
&gt;     Relay cells sent towards the client have the following plaintext
&gt;     format:
&gt;         Body:
&gt;           Content:
&gt;             Relay Command [1 byte]
&gt;             StreamID      [2 bytes]
&gt;             Length        [2 bytes]
&gt;             Data          [Up to CELL_DATA_LEN-5-MACBYTESb bytes]
&gt;             Padding       [randomly generated as needed to fill the
&gt;                            cell]
&gt;           MAC(All previous encrypted content + encrypted content,
&gt;                                  Mb)[:MACBYTESb]   [MACBYTESb bytes]
&gt;
&gt;     The originator of the client-bound cell encrypts the content with
&gt;     the next part of its Kb,IVb stream, then appends the MAC.
&gt;
&gt;     Non-clients receiving a client-bound relay cell encrypt the entire
&gt;     cell body, MAC included, with the next part of the stream cipher
&gt;     that was keyed with Kb,IVb.
&gt;
&gt;     When the client receives a relay cell body, it iteratively does:
&gt;
&gt;       For node i in circuit from 1..N:
&gt;           Let cells_i = all previous cells which we previously decided
&gt;              were from node i, or relayed by node i,
&gt;           and let cellbody = the body of the cell, except for the last
&gt;              MACBYTESb[i] bytes,
&gt;           and let cellmac = the last MACBYTESb[i] bytes of this cell.
&gt;
&gt;           If cellmac is nonempty, check wither cellmac = mac_received,
&gt;           where mac_received is the first MACBYTESb[i] bytes of
&gt;           MAC(cells_i | cellbody, Mb[i]). If so, this cell is from node
&gt;           i.
&gt;
&gt;           If this cell is from node i, add cellbody to cells_i, then
&gt;           decrypt cellbody using the stream keyed with Kb[i],IVb[i].
&gt;           Act on it as a relay cell.
&gt;
&gt;           Otherwise add the entire cell to cells_i, and decrypt it, MAC
&gt;           included, with the stream keyed with Kb[i], IVb[i].
&gt;
&gt;       If no node sent this cell: it's junk and somebody is probably
&gt;       messing with us!  Destroy the circuit.
&gt;
&gt;
&gt;     When the client *sends* a cell outbound to node N:
&gt;
&gt;         Let cells[i] start at "" for all i in 1...N initially, and get
&gt;         updated as below.
&gt;
&gt;         Let MACLEN = SUM(MACBYTESf[1...N])
&gt;
&gt;         Let Body =
&gt;             Relay Command [1 byte]
&gt;             StreamID      [2 bytes]
&gt;             Length        [2 bytes]
&gt;             Data          [Up to CELL_DATA_LEN-5-MACLEN bytes]
&gt;             Padding       [randomly generated,
&gt;                            CELL_DATA_LEN-5-MACLEN-len(Data) bytes]
&gt;
&gt;         Let PAD[i] = the next MACBYTESf[i] bytes from the PRNG keyed
&gt;         with SEEDf[i], for i in 1...N
&gt;
&gt;         Let STREAM[i] = the next CELL_DATA_LEN bytes of
&gt;           the stream keyed by Kf[i],IV[i], for i in 1...N
&gt;
&gt;         Let PADSEEN[1] == ""
&gt;
&gt;         For i in 2...N:
&gt;             Let L = len(PADSEEN[i-1]) + len(PAD[i-1])
&gt;             Let PADSEEN[i] = (PADSEEN[i-1] | PAD[i-1]) xor
&gt;                              STREAM[i-1][CELL_DATA_LEN-L:]
&gt;
&gt;         For i in N down to 1:
&gt;
&gt;            Let Encbody = Body xor STREAM[i][:len(Body)]
&gt;            Let extra = "RECOGNIZED" if i == N, "OK" otherwise
&gt;            Let cells[i] = cells[i] | Body | PADSEEN[i]
&gt;            Let M = MAC(cells[i] | extra , Mf[i])
&gt;
&gt;            Let Body = M[:MACBYTESf[i]] | EncBody
&gt;
&gt;
&gt;     To receive an outbound cell:
&gt;
&gt;         Let M be the first MACBYTESf bytes of the cell, let REST be the
&gt;         rest of the cell, and let "cells" be all previous cells on this
&gt;         circuit.  If CANEXIT, and M = MAC(cells|rest|"RECOGNIZED",
&gt;         Mb)[:MACBYTESf], and MACBYTESf &gt; 0, this cell is for us.  If M
&gt;         = MAC(cells|rest|"OK", Mb)[:MACBYTESf], this cell is not for
&gt;         us, but is valid.  Otherwise, destroy the circuit.
&gt;
&gt;         Let PAD = the next MACBYTESf[i] bytes of the PRNG keyed with
&gt;         SEEDf, and decrypt REST | PAD using the stream cipher keyed
&gt;         with Kf,IVf.  If this cell is for us, act on it as a relay
&gt;         cell.  Otherwise, relay it.
&gt;
&gt;     ANOTHER VARIANT:
&gt;
&gt;         If we restrict MACBYTESf values to range 0..HL/2, where HL is the
&gt;         length of the MAC output, we can replace
&gt;           MAC(x | "RECOGNIZED")[:MACBYTESf] and MAC(x | "OK")[:MACBYTESf]
&gt;         with
&gt;           MAC(x)[:MACBYTESf] and MAC(x)[HL-MACBYTESf:]
&gt;
&gt;     PICKING MACBYTESf,MACBYTESb.
&gt;
&gt;         We don't need to worry about birthday attacks:
&gt;
&gt;            Because we're using a MAC, only the parties who are making
&gt;            the MACs could try to do a brute-force search for a
&gt;            collision, but they have no reason to do so.
&gt;
&gt;            If a collision occurs accidentally, an adversary can't
&gt;            substitute an earlier-seen cell for a later one with the
&gt;            same MAC, since the MAC covers not only the cell, but all
&gt;            previous cells on the circuit.
&gt;
&gt;         So 16 bytes is about the most we should ever do, given our
&gt;         usual security parameters.  Let me moot the number 8 for
&gt;         MACBYTESb.
&gt;
&gt;         For outbound cells, for any hop we can exit from, choosing
&gt;         MACBYTESf=6 gets us the current security level.  For the first
&gt;         hop, assuming we don't exit from it, choosing MACBYTESf=0 is
&gt;         totally safe, since the link crypto guarantees that nothing was
&gt;         corrupted on the way.
&gt;
&gt;         In general, to prevent an end-to-end tagging attack, it seems
&gt;         sufficient to do something like setting MACBYTES=8 for the last
&gt;         hop, and MACBYTES=8 for one hop in the middle.
&gt;
&gt;     OTHER VARIANTS:
&gt;
&gt;         Can we combine this approach with one of the approaches in 2 or
&gt;         3 above to ensure that if corrupt data passes (because of our
&gt;         use of truncated HMACs) it still corrupts the stream?
&gt;
&gt;         Can/should we use GCM or something here instead of separate
&gt;         encrypt/hmac operations?  It doesn't seem that GCM per se would
&gt;         apply without some tweaking, which we probably do not have the
&gt;         expertise to do.
&gt;
&gt;    OVERHEAD NOTES:
&gt;
&gt;         When computing additional overhead with this method, note that
&gt;         it lets us replace the old 4 byte "digest" field and the 2 byte
&gt;         "recognized" field.
&gt;
&gt;         I note in passing that we need at most 9 bits for the length
&gt;         field, and at most 6 bits for the command field, yet we're using a
&gt;         total of 3 bytes for those 15 bits.  That's an opportunity to
&gt;         save another byte.
&gt;
&gt; ACKS
&gt;
&gt;   Lots of the good ideas and concerns here are due to Robert Ransom.
&gt;
&gt;   Michael Stone helped some with "relay option 4" above.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;



-- 
"Those who would give up Essential Liberty to purchase a little Temporary
Safety deserve neither  Liberty nor Safety."
-- Benjamin Franklin

[Attachment #5 (text/html)]

What about this for modification resistance?&lt;br&gt;&lt;div&gt;We keep a count of all cells \
passing and use AES in CTR mode with a 2 part counter: the first part the cell \
counter, the second one a block counter. Then to authenticate the cell we can use a \
16 byte tag and a Wegman-Carter MAC. This gives a  total overhead of 48 bytes for a \
three hop link, which is half the cited one, and which&lt;/div&gt; &lt;div&gt;is provably as \
secure as AES.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;ChaCha is a component part of one of the \
SHA-3 finalists, namely JH. If JH is selected as the SHA3 candidate, this may (read \
may) entail something about the security of ChaCha. The HAIFA construction JH uses \
doesn't say much about proofs of security, unlike the sponge papers.&lt;/div&gt; \
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;ECC groups don't matter much: there are some really bad \
choices out there, but any attack against Curve25519 is&lt;/div&gt;&lt;div&gt;going to probably \
imply an attack against NIST P-256 as well. Its not that different from picking a \
particular DH prime: some are bad because p-1 is smooth, but if not then they all \
look the same.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;2012 is coming soon: The schedule says \
between March and June of this year SHA3 will be announced. Everything after that \
involves  bureaucracy. Why switch to SHA256 and then to SHA3 when we won't be \
done before March anyway?&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;In general options are bad in \
crypto: we should migrate as few times as possible to avoid various attacks that \
might involve degrading a negotiation. As for Certicom their patents were licensed by \
NIST. Unfortunately for them they openly admit on their website that these are mostly \
implementation patents. To my untrained eye DJB's analysis is spot on. There is \
also  &lt;a href="http://tools.ietf.org/html/rfc6090"&gt;http://tools.ietf.org/html/rfc6090&lt;/a&gt; \
which seems to do something similar.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Sincerely,&lt;br&gt;Watson \
Ladd&lt;/div&gt;&lt;div&gt;&lt;div class="gmail_quote"&gt;On Mon, Oct 31, 2011 at 8:25 PM, Nick \
Mathewson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:nickm@torproject.org"&gt;nickm@torproject.org&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt; \
&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px #ccc \
solid;padding-left:1ex;"&gt;Here's an early draft document trying to sketch out the \
parameters for&lt;br&gt; migrating to better crypto ops and designs in the future.&lt;br&gt;
&lt;br&gt;
Comments are invited, even comments of the form "you will need to be&lt;br&gt;
much more specific here before I can say anything sensible."&lt;br&gt;
&lt;br&gt;
This is proposals/ideas/xxx-new-crypto-sketch.txt in the torspec repository.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Title: Design sketch for new crypto ops&lt;br&gt;
Date: 31 Oct 2011&lt;br&gt;
Author: Nick Mathewson&lt;br&gt;
&lt;br&gt;
0. Overview&lt;br&gt;
&lt;br&gt;
   The point of this document is to discuss what crypto we ought to be using.&lt;br&gt;
   See "Initial Thoughts on Migrating Tor to New Cryptography" from last \
year&lt;br&gt;  for general guidelines and principles.&lt;br&gt;
&lt;br&gt;
   In broad strokes, the parts of our crypto are:&lt;br&gt;
&lt;br&gt;
      IDENTITY KEYS AND FINGERPRINTS&lt;br&gt;
          Addressed here in Section 2.&lt;br&gt;
      LINK CRYPTO (TLS) --&lt;br&gt;
          Addressed in proposals 176, 184.   We say a little here in section 5,&lt;br&gt;
          though.&lt;br&gt;
      CREATE/EXTEND CRYPTO --&lt;br&gt;
          Addressed in xxx-ntor-handshake.txt and rransom's EXTEND draft at&lt;br&gt;
          [*] and subsequent discussion on the tor-dev mailing list.   Not&lt;br&gt;
          considered here.&lt;br&gt;
      RELAY CRYPTO&lt;br&gt;
          Addressed here in Section 6.&lt;br&gt;
      DIRECTORY SYSTEM&lt;br&gt;
          Addressed here.&lt;br&gt;
      HIDDEN SERVICE SYSTEM&lt;br&gt;
          Addressed in a forthcoming document by rransom.&lt;br&gt;
&lt;br&gt;
[*] &lt;a href="https://lists.torproject.org/pipermail/tor-dev/2011-March/002547.html" \
target="_blank"&gt;https://lists.torproject.org/pipermail/tor-dev/2011-March/002547.html&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;
1. Base algorithm choice&lt;br&gt;
&lt;br&gt;
   There seem to be two main candidate algorithms for signatures: RSA&lt;br&gt;
   with big keys (hereinafter "RSA&gt;1024"); and Ed25519, which is DSA \
with&lt;br&gt;  the sharp edges filed off on an Edwards curve related to DJB's&lt;br&gt;
   Curve25519.   We can look at other ECC groups too.   {But see ECC&lt;br&gt;
   Notes in 1.1 below.}&lt;br&gt;
&lt;br&gt;
   FOR DIFFIE-HELLMAN: Curve25519 seems like a decent choice; failing&lt;br&gt;
   that, one of the NIST P-groups.   Failing that, DH on Z_p with big&lt;br&gt;
   groups (hereinafter "DH&gt;1024").   {But see ECC Notes in 1.1 \
below.}&lt;br&gt; &lt;br&gt;
   FOR A HASH FUNCTION: SHA256, switching to SHA3 in 2012 when it comes&lt;br&gt;
   out.   It might be worthwhile waiting for SHA3 in most places and&lt;br&gt;
   skipping over the SHA256 stage entirely.&lt;br&gt;
&lt;br&gt;
   FOR A STREAM CIPHER: AES-CTR is in one sense a conservative choice&lt;br&gt;
   inasmuch as AES is well-analyzed, but AES's well-known issues with&lt;br&gt;
   cache-based timing attacks are pretty worrisome.   We can mitigate that&lt;br&gt;
   some by using random secret IVs for AES-CTR, so that we will be&lt;br&gt;
   encrypting neither attacker-chosen nor attacker-known plaintext with&lt;br&gt;
   our AES cipher, but that's a bit kludgy.   There are also supposed to&lt;br&gt;
   be time-invariant implementations that use Intel's AESNI instructions&lt;br&gt;
   where available, and time-invariant implementations that use&lt;br&gt;
   bit-slicing.&lt;br&gt;
&lt;br&gt;
   Salsa20 is what rransom likes these days, but IMO we aren't competent&lt;br&gt;
   to tell whether it looks good or not; the existing attacks against it&lt;br&gt;
   don't look like very bad news to me, but who knows whether it's&lt;br&gt;
   getting enough attention that we can read.   See also ChaCha; see also&lt;br&gt;
   the other eSTREAM winners/finalists; see also SHA3 if the SHA3 winner&lt;br&gt;
   specifies a way to use it as a stream cipher, or specifies an&lt;br&gt;
   underlying stream/block cipher.&lt;br&gt;
&lt;br&gt;
   If we're feeling cautious, we could run two independently-keyed stream&lt;br&gt;
   ciphers and xor their streams together.&lt;br&gt;
&lt;br&gt;
   FOR A RANDOM NUMBER GENERATOR: We currently use OpenSSL seeded with&lt;br&gt;
   RAND_poll and with platform entropy.   OpenSSL uses a message-digest-&lt;br&gt;
   based algorithm from SSLeay (See &lt;a href="http://linux.die.net/man/3/sslrand" \
target="_blank"&gt;http://linux.die.net/man/3/sslrand&lt;/a&gt;&lt;br&gt;  for the ugly details.)   \
The platform entropy management can be messy,&lt;br&gt;  obscure, or both.   I suggest \
that:&lt;br&gt; &lt;br&gt;
      * We should seed our PRNG with more entropy sources if we can find&lt;br&gt;
         some promising code with an appropriate license&lt;br&gt;
      * Instead of just using OpenSSL's PRNG, we should use OpenSSL's&lt;br&gt;
         MD-based PRNG xor'd with some other good PRNG.   (Fortuna,&lt;br&gt;
         maybe. Is there a combine operation better than xor? See also SHA3&lt;br&gt;
         if the SHA3 winner is one that specifies a PRNG mode of&lt;br&gt;
         operation.)&lt;br&gt;
      * We should consider splicing this combined-stream PRNG into OpenSSL&lt;br&gt;
         as the RNG it uses for SSL and key generation.&lt;br&gt;
      * We should re-seed the RNG before and after very sensitive&lt;br&gt;
         operations, like private key generation.&lt;br&gt;
&lt;br&gt;
1.1. ECC notes&lt;br&gt;
&lt;br&gt;
   ECC is the brave new[*] crypto of the future!   It's faster[**] than&lt;br&gt;
   doing crypto in Z_n (as we do for RSA and DH now) for equivalent&lt;br&gt;
   levels of security, and the resulting outputs are much shorter.&lt;br&gt;
&lt;br&gt;
   As near as I can tell as a layman, Certicom is muddying the waters as&lt;br&gt;
   much as possible wrt claiming that it's nigh-impractical to deploy ECC&lt;br&gt;
   without licensing their patents.   This is rather like the silliness&lt;br&gt;
   that PKP used to pull back in the day, where they claimed that their&lt;br&gt;
   patents covered not only the existing public key cryptography&lt;br&gt;
   algorithms, but also the very idea of public key cryptography itself.&lt;br&gt;
&lt;br&gt;
   DJB claims that for every patent he's aware of, either that patent&lt;br&gt;
   doesn't cover his code, or that patent is invalid because of prior&lt;br&gt;
   art.   I'm not going to try to evaluate these claims, since I'm not&lt;br&gt;
   supposed to be reading patents for typical "let's avoid the \
appearance&lt;br&gt;  of knowing infringement" reasons.   But before we dive into the \
world&lt;br&gt;  of ECC, we should see if we can ask any friendly patent attorneys and&lt;br&gt;
   ECC experts for a second or third opinion here.&lt;br&gt;
&lt;br&gt;
   I note in passing that nearly all of the patents that DJB mentions in&lt;br&gt;
   his list would appear to expire over the next 12 months or so.&lt;br&gt;
&lt;br&gt;
   Additionally, there are ECC groups out there less fast than DJB's, but&lt;br&gt;
   more widely available and analyzed.   We should consider some of those&lt;br&gt;
   too.&lt;br&gt;
&lt;br&gt;
   One final issue to investigate is whether using these algorithms will&lt;br&gt;
   make any major free software distribution decide not to include us.   I&lt;br&gt;
   seem to recall seeing that one or two of the big ones had at one point&lt;br&gt;
   decided to ship OpenSSL only with ECC disabled, either because of real&lt;br&gt;
   patent concerns, or because of an opinion that the Certicom license&lt;br&gt;
   for ECC use in TLS was problematic for free software, or something&lt;br&gt;
   like that.   We should check that out.&lt;br&gt;
&lt;br&gt;
   [*] Actually, it's older than onion routing, and older than some&lt;br&gt;
   members of the Tor Project.&lt;br&gt;
&lt;br&gt;
   [**] Actually, because of the common practice of choosing a small-ish&lt;br&gt;
   prime value (65537) for e in RSA, RSA public key operations can be a&lt;br&gt;
   little faster than equivalent-security ECDH or ECDSA operations.   The&lt;br&gt;
   private key operations in RSA are still much much slower.&lt;br&gt;
&lt;br&gt;
2. New identities&lt;br&gt;
&lt;br&gt;
   Identity keys and their fingerprints are used:&lt;br&gt;
      - To sign router descriptors.&lt;br&gt;
      - To identify nodes in consensus directories.&lt;br&gt;
      - To make sure we're talking to the right node in the link handshake.&lt;br&gt;
      - To make sure that the extending node is talking to the right next&lt;br&gt;
         node when sending an extend cell.&lt;br&gt;
      - To identify particular nodes in the hidden service subsystem.&lt;br&gt;
      - To identify nodes in the UI in various places.&lt;br&gt;
      - Internally, to identify a node uniquely in the codebase.&lt;br&gt;
      - To determine which part of the circuit ID space to use on a Tor&lt;br&gt;
         instance's links.&lt;br&gt;
&lt;br&gt;
2.1. New identities, option 1: "RSA&gt;1024, slow migration"&lt;br&gt;
&lt;br&gt;
   In this option, we use RSA for identity keys indefinitely.   Nearly all&lt;br&gt;
   operations done with an identity key are signature checking; signing&lt;br&gt;
   happens only a few times an hour per node even with pathological&lt;br&gt;
   cases.   Since signature checking is really cheap with RSA, there's no&lt;br&gt;
   speed advantage for ECC here.   (There is a space advantage, since the&lt;br&gt;
   keys are much smaller.)&lt;br&gt;
&lt;br&gt;
   The easiest way to migrate to longer identity keys is to tell all Tors&lt;br&gt;
   to begin accepting longer identity keys now, and to tweak all our&lt;br&gt;
   protocols so that longer RSA identity keys are understood.   We should&lt;br&gt;
   then have a pair of parameters in the consensus that determines the&lt;br&gt;
   largest and smallest acceptable identity key size in the network.&lt;br&gt;
   Clients and servers should reject any keys longer or shorter than&lt;br&gt;
   specified.   Once all versions of Tor can accept long identity keys, we&lt;br&gt;
   raise the maximum size from 1024 to somewhere in the 2048-4096 range.&lt;br&gt;
&lt;br&gt;
2.2. New identities option 2: "RSA&gt;1024, faster migration"&lt;br&gt;
&lt;br&gt;
   In this option, we use RSA for identity keys indefinitely as above.&lt;br&gt;
   But we allow nodes to begin having longer identities now, even though&lt;br&gt;
   older Tors won't understand them.   This implies, of course, that every&lt;br&gt;
   such node needs to have at least 2 identities: one RSA1024 identity&lt;br&gt;
   for backward compatibility, one RSA&gt;1024 identity for more secure&lt;br&gt;
   identification.&lt;br&gt;
&lt;br&gt;
   We would have these identities cross-certify as follows: All keys&lt;br&gt;
   would be listed in the router descriptor.   RSA&gt;1024 keys would be&lt;br&gt;
   called something other than identity-key, so as not to confuse older&lt;br&gt;
   clients.   A signature with the RSA&gt;1024 key would appear right before&lt;br&gt;
   the current RSA1024 signature.   This way, signed material would&lt;br&gt;
   include both keys, and would be signed by both keys.&lt;br&gt;
&lt;br&gt;
       [In other words, descriptors would look something like:&lt;br&gt;
&lt;br&gt;
         router foo...&lt;br&gt;
         ...&lt;br&gt;
         identity-key&lt;br&gt;
         -----BEGIN RSA KEY-----&lt;br&gt;
         1024-bit RSA key here&lt;br&gt;
         -----END RSA KEY-----&lt;br&gt;
         ext-identity-key&lt;br&gt;
         -----BEGIN RSA KEY-----&lt;br&gt;
         3072-bit RSA key here&lt;br&gt;
         -----END RSA KEY-----&lt;br&gt;
         ...&lt;br&gt;
         ext-signature&lt;br&gt;
         -----BEGIN SIGNATURE-----&lt;br&gt;
         signature of everything through "ext-signature\n",&lt;br&gt;
         using the long key&lt;br&gt;
         -----END SIGNATURE-----&lt;br&gt;
         router-signature&lt;br&gt;
         -----BEGIN SIGNATURE-----&lt;br&gt;
         signature of everything through "router-signature\n",&lt;br&gt;
         using the short key&lt;br&gt;
         -----END SIGNATURE-----&lt;br&gt;
&lt;br&gt;
       ]&lt;br&gt;
&lt;br&gt;
   See "UI notes" in the "new fingerprints" section below for \
some of the&lt;br&gt;  implications of letting nodes have multiple identity keys.&lt;br&gt;
&lt;br&gt;
   We'll need to advertise these new identities in consensus directories&lt;br&gt;
   too; see 4.2 below for more info there.&lt;br&gt;
&lt;br&gt;
2.3. New identities option 3: "RSA&gt;1024 and/or Ed25519, faster \
migration"&lt;br&gt; &lt;br&gt;
   As in option 2 above, but new keys can also be Ed25519.   If we expect&lt;br&gt;
   that not all installations will allow Ed25519 (see "ECC Notes",&lt;br&gt;
   section 1.1), we'll need to say that every server with an Ed25519 key&lt;br&gt;
   must also have an RSA&gt;1024 key.&lt;br&gt;
&lt;br&gt;
2.4. Implications for current use of identity keys&lt;br&gt;
&lt;br&gt;
   Let's review our use of identity keys again and make sure that we can&lt;br&gt;
   handle all of them with the ideas above.&lt;br&gt;
&lt;br&gt;
      - To sign router descriptors.&lt;br&gt;
&lt;br&gt;
   We discussed this in 2.2.&lt;br&gt;
&lt;br&gt;
      - To make sure we're talking to the right node in the link handshake.&lt;br&gt;
&lt;br&gt;
   The current v3 link handshake can handle presenting multiple identity&lt;br&gt;
   certificates in the CERT cell.   We should consider ourselves to be&lt;br&gt;
   connected to a node with identity X if _any_ of the identity&lt;br&gt;
   certificates that it presents in its authenticated CERT cell has&lt;br&gt;
   identity X.   To handle EXTEND cells correctly, we should verify every&lt;br&gt;
   identity we can.&lt;br&gt;
&lt;br&gt;
      - To make sure that the extending node is talking to the right next node&lt;br&gt;
         when sending an extend cell.&lt;br&gt;
&lt;br&gt;
   The new extend cell format needs to allow the client to tell the&lt;br&gt;
   extending node about some identity for the destination node that the&lt;br&gt;
   extending node will be able to understand.   This is a capability of&lt;br&gt;
   the extending node that the client needs to be able to check. (Also,&lt;br&gt;
   the extend cell needs to hash that identity in a form the extending&lt;br&gt;
   node can understand, but that's a fingerprint issue.)&lt;br&gt;
&lt;br&gt;
      - To determine which part of the circuit ID space to use on a Tor&lt;br&gt;
         instance's links.&lt;br&gt;
&lt;br&gt;
   We can continue to use RSA1024 identity key comparison here by&lt;br&gt;
   default.   We can also use some other parameter of the v3 handshake, or&lt;br&gt;
   introduce a new link protocol where if the initiator authenticates,&lt;br&gt;
   the initiator always gets the low circIDs and the responder always&lt;br&gt;
   gets the high ones.&lt;br&gt;
&lt;br&gt;
      - To identify nodes in consensus directories.&lt;br&gt;
      - To identify nodes in the UI in various places.&lt;br&gt;
      - Internally, to identify a node uniquely in the codebase.&lt;br&gt;
&lt;br&gt;
   See sections 3 and 4 below.&lt;br&gt;
&lt;br&gt;
      - To identify particular nodes in the hidden service subsystem.&lt;br&gt;
&lt;br&gt;
   Out of scope.&lt;br&gt;
&lt;br&gt;
2.5. Migrating away from short ID keys entirely&lt;br&gt;
&lt;br&gt;
   Eventually, no version of Tor that requires 1024-bit identity keys will&lt;br&gt;
   remain.   When that happens, we should stop using them entirely.   That&lt;br&gt;
   means that if we take any path other than the "slow migration" path \
of&lt;br&gt;  2.1, we'll need to make everything that looks at a node's \
identity&lt;br&gt;  also accept nodes with _only_ a RSA&gt;1024/Ed25519 identity.&lt;br&gt;
&lt;br&gt;
   At the directory service level, we should have an option to allow&lt;br&gt;
   nodes without RSA1024 identity keys (off until all clients and nodes&lt;br&gt;
   accept new identity keys).&lt;br&gt;
&lt;br&gt;
2.6. Selective correctness attacks&lt;br&gt;
&lt;br&gt;
   For any scheme based on having multiple signature types on a router&lt;br&gt;
   descriptor or other document, an attacker could mount a partitioning&lt;br&gt;
   attack by making a document which older clients will accept but newer&lt;br&gt;
   clients will reject.&lt;br&gt;
&lt;br&gt;
   It's easy to prevent this at the consensus step: directory authorities&lt;br&gt;
   MUST NOT accept any descriptor unless all clients will be able to&lt;br&gt;
   verify it.&lt;br&gt;
&lt;br&gt;
   For bridge descriptors, we need to investigate more carefully.&lt;br&gt;
&lt;br&gt;
3. New fingerprints&lt;br&gt;
&lt;br&gt;
   Right now we compute fingerprints by taking the SHA1 hash of an ASN1&lt;br&gt;
   encoding of the RSA1024 identity key.   We encode this in hex almost&lt;br&gt;
   everywhere, and sometimes prefix it with a $.&lt;br&gt;
&lt;br&gt;
   I propose that fingerprints of the future be determined by taking a&lt;br&gt;
   digest using SHA256 or SHA3 of:&lt;br&gt;
&lt;br&gt;
         "Hash Algorithm Name", "Key Type Name", encoded key&lt;br&gt;
&lt;br&gt;
   When representing these internally, we should include the hash&lt;br&gt;
   algorithm that was used.   When representing them in the UI, we should&lt;br&gt;
   use the notation %b64, where b64 is a base-64 encoding, omitting the&lt;br&gt;
   trailing =s.&lt;br&gt;
&lt;br&gt;
   (Other plausible characters to use are @, ?, +, ~, =, etc.   I like %,&lt;br&gt;
   but can be persuaded.   Bikeshed bikeshed bikeshed.)&lt;br&gt;
&lt;br&gt;
   Since 43 base-64 characters is enough to represent a 256-bit digest,&lt;br&gt;
   with 2 bits left over, I propose that the b64 value encode&lt;br&gt;
&lt;br&gt;
         hh | D(hash algorithm name, key type, encoded key)&lt;br&gt;
&lt;br&gt;
   where hh is a 2-bit value, with one of the following values:&lt;br&gt;
&lt;br&gt;
         00 -- sha256&lt;br&gt;
         01 -- sha3&lt;br&gt;
         10 -- to be determined&lt;br&gt;
         11 -- reserved.&lt;br&gt;
&lt;br&gt;
   We should investigate in the interface whether it's plausible to allow&lt;br&gt;
   a prefix of a node ID where the full ID would otherwise be required.&lt;br&gt;
   That seems risky for short prefixes, though.&lt;br&gt;
&lt;br&gt;
3.1. How many fingerprints is that anyway?!&lt;br&gt;
&lt;br&gt;
   Suppose that we allow sha256 and sha3 as hash algorithms, and we allow&lt;br&gt;
   each node to have 3 identity keys: one RSA1024, one RSA&gt;1024, and one&lt;br&gt;
   ECC.   Then we would have 7 fingerprints (6 plus the legacy&lt;br&gt;
   SHA1(RSA1024) fingerprint), for a total of 20+6*32==212 bytes per&lt;br&gt;
   node.&lt;br&gt;
&lt;br&gt;
   It's not a horrible problem to accept them all in the UI, but the UI&lt;br&gt;
   isn't the only place that needs to know fingerprints.   Instead, let's&lt;br&gt;
   say that RSA1024 identities are only identified with SHA1 hashes.&lt;br&gt;
   This limits our fingerprint load to a more manageable 20+32*2 == 84&lt;br&gt;
   bytes per node.   Still not great, though.&lt;br&gt;
&lt;br&gt;
3.2. What does this imply for the UI?&lt;br&gt;
&lt;br&gt;
   In the UI we'll lose the property that no node has more than one&lt;br&gt;
   fingerprint: I do not believe that this actually hurts us.&lt;br&gt;
&lt;br&gt;
3.3. Implications for directory information&lt;br&gt;
&lt;br&gt;
   Clients must know a hash for each node's identity key, or else they&lt;br&gt;
   can't make an authenticated connection to the node or tell ORs how to&lt;br&gt;
   extend to the node.&lt;br&gt;
&lt;br&gt;
   This means that if client Alice wants to connect to node Bob, Alice&lt;br&gt;
   must have a fingerprint of Bob's ID key such that she understands the&lt;br&gt;
   ID key type and the fingerprint algorithm.   If Alice wants to extend&lt;br&gt;
   from Bob to Carol, she must have a fingerprint of Carol's ID key such&lt;br&gt;
   that Bob understands the ID key type and the fingerprint algorithm.&lt;br&gt;
&lt;br&gt;
   So for every node, Alice must not only know a fingerprint that *she*&lt;br&gt;
   can use for that node, but also a set of fingerprints such that every&lt;br&gt;
   node can understand at least one fingerprint in the set.&lt;br&gt;
&lt;br&gt;
   This implies a proliferation of fingerprints!   We should tread&lt;br&gt;
   carefully here.   To prevent proliferation, the easiest solution is not&lt;br&gt;
   to add too many new types and to have a good plan for retiring older&lt;br&gt;
   types.&lt;br&gt;
&lt;br&gt;
3.4. Implications for EXTEND cells&lt;br&gt;
&lt;br&gt;
   As mentioned in 3.3, when a client Alice tells node Bob to extend&lt;br&gt;
   to node Carol, she needs to give Bob a fingerprint for Carol that Bob&lt;br&gt;
   will understand: one where Bob understands the digest algorithm, and&lt;br&gt;
   understands the identity key type.&lt;br&gt;
&lt;br&gt;
   There are two ways we can do this:&lt;br&gt;
&lt;br&gt;
      1) Alice's EXTEND cell contains every fingerprint for Carol that&lt;br&gt;
          Alice knows about.   Bob treats the cell as valid if every one he&lt;br&gt;
          can verify is correct.&lt;br&gt;
&lt;br&gt;
      2) Alice knows which fingerprint types Bob understands (either via&lt;br&gt;
          his version, or something else in his directory info).   She&lt;br&gt;
          selects a fingerprint for Carol using the best one of these&lt;br&gt;
          types.&lt;br&gt;
&lt;br&gt;
   The first seems more robust to me, if we have space for enough bytes.&lt;br&gt;
   If we proliferate too many types, though, we'll need to do the second.&lt;br&gt;
&lt;br&gt;
4. Directory changes&lt;br&gt;
&lt;br&gt;
4.1. Better cross-referencing&lt;br&gt;
&lt;br&gt;
   In some places, directory objects cross-reference one another by SHA1&lt;br&gt;
   hash.   They should use a better hash algorithm instead.&lt;br&gt;
&lt;br&gt;
   This does make problems in a few cases.&lt;br&gt;
&lt;br&gt;
   Router descriptors and extrainfo descriptors:&lt;br&gt;
&lt;br&gt;
       One problematic case is in determining node families.   If node A&lt;br&gt;
       and node B want to list each other as being in the same family,&lt;br&gt;
       they need to do so in a way that clients can interpret.   That could&lt;br&gt;
       mean listing SHA1-RSA1024 fingerprints so old clients understand,&lt;br&gt;
       AND new fingerprints for security. (But *that* could create&lt;br&gt;
       interesting partitioning attacks wherein your family looks&lt;br&gt;
       different depending on who's looking.)&lt;br&gt;
&lt;br&gt;
          Solution: we need to move the responsibility for combining node&lt;br&gt;
          families into the consensus voting process, so clients don't&lt;br&gt;
          need to understand the cross-reference types themselves.&lt;br&gt;
&lt;br&gt;
       Another case is in certifying extrainfo documents from descriptors.&lt;br&gt;
       For that, we can list multiple extrainfo digests, either on the&lt;br&gt;
       extrainfo line, or on additional lines.&lt;br&gt;
&lt;br&gt;
   Voting and consensus documents:&lt;br&gt;
&lt;br&gt;
       Adding more fingerprints in votes isn't a problem; votes are a tiny&lt;br&gt;
       fraction of authority bw usage.   Adding more hashes is easy.&lt;br&gt;
&lt;br&gt;
       For consensus documents, we ought to have flavors that you can&lt;br&gt;
       download depending on what set of fingerprint types you&lt;br&gt;
       understand.&lt;br&gt;
&lt;br&gt;
       For integrity purposes, consensuses can refer to microdescriptors&lt;br&gt;
       or descriptors by any digest type that the client understands.   But&lt;br&gt;
       for downloading purposes, the digest type must be one that&lt;br&gt;
       directory caches also support: see 4.4.&lt;br&gt;
&lt;br&gt;
4.2. More fingerprints&lt;br&gt;
&lt;br&gt;
   Because extending from node A to node B requires that we have node B's&lt;br&gt;
   fingerprint in a way that node A will understand, it is not enough to&lt;br&gt;
   get a set of identity fingerprints for each node in the format that&lt;br&gt;
   the client likes best -- see 3.3 and 3.4 above.   So every flavor of&lt;br&gt;
   consensus we serve needs to include a node identity in a format the&lt;br&gt;
   client understands, and node identities in formats such that every&lt;br&gt;
   node will understand at least one.&lt;br&gt;
&lt;br&gt;
4.3. An option: compound signatures on directory objects&lt;br&gt;
&lt;br&gt;
    In Tor 0.2.2.x and later, when we check a signature on a directory&lt;br&gt;
    object (not including hidden service descriptors), we only look at&lt;br&gt;
    the first DIGEST_LEN bytes of the RSA-signed data.   Once 0.2.1.x is&lt;br&gt;
    obsolete, or on any types of signatures not checked in 0.2.1.x, we&lt;br&gt;
    can use the rest of the space.   (We're using PKCS1 padding on our&lt;br&gt;
    signatures, which has an overhead of 11 bytes.   Signing a SHA1 hash&lt;br&gt;
    with a 1024-bit key therefore leaves 128-11-20==97 more bytes we&lt;br&gt;
    could use for a SHA2 or a SHA3 hash.)&lt;br&gt;
&lt;br&gt;
4.4. Downloading by digest&lt;br&gt;
&lt;br&gt;
    We should have directory caches support downloading objects by more&lt;br&gt;
    hash types.   Right now, descriptors are downloaded by their SHA1&lt;br&gt;
    hashes and microdescriptors by their SHA256 hashes.   This is okay for&lt;br&gt;
    now, but once SHA3 is out, we should support downloading all of these&lt;br&gt;
    by SHA3 digest.&lt;br&gt;
&lt;br&gt;
5. Link crypto changes&lt;br&gt;
&lt;br&gt;
   Currently we use TLS.   That's fine.&lt;br&gt;
&lt;br&gt;
   We should however look to longer link keys, bigger DH groups, etc.&lt;br&gt;
&lt;br&gt;
   Once TLS versions 1.1/1.2 are available in OpenSSL, we should move to&lt;br&gt;
   use them, I think.   We should also look into how quickly we can&lt;br&gt;
   deprecate TLS 1.0 and SSL &lt;= 3 usage.&lt;br&gt;
&lt;br&gt;
6. Relay crypto changes&lt;br&gt;
&lt;br&gt;
   There are a few things we might want out of improved relay crypto.&lt;br&gt;
   They include:&lt;br&gt;
    - Resistance to end-to-end bitwise tagging attacks.&lt;br&gt;
    - Better resistance to malleability.&lt;br&gt;
    - If using counter mode, no block-cipher operations on any value&lt;br&gt;
       known to the attacker.&lt;br&gt;
&lt;br&gt;
   I'll try to provide these in increasing order of difficulty.   None of&lt;br&gt;
   these is necessarily correct; I should look for a security proof or a&lt;br&gt;
   better construction for any that we seem likely to use.&lt;br&gt;
&lt;br&gt;
   Rationales: Our existing malleability resistance is a kludge.   Doing&lt;br&gt;
   no block-cipher ops on attacker-known values increases our security&lt;br&gt;
   margins a little.   Our arguments about tagging attacks hold that an&lt;br&gt;
   attacker who controls both ends has plenty of ways to win even if&lt;br&gt;
   tagging attacks are foiled; nonetheless, most of these ways are&lt;br&gt;
   technically slightly more difficult than xor-based tagging, and it&lt;br&gt;
   could be useful to boost our defense-in-depth a little bit, just in&lt;br&gt;
   case other active end-to-end attacks turn out to be harder than we'd&lt;br&gt;
   thought.&lt;br&gt;
&lt;br&gt;
6.1. Option 1: Use AES-CTR in a less scary mode&lt;br&gt;
&lt;br&gt;
    When doing key expansion, in addition to establishing Kf, Kb, Df, and&lt;br&gt;
    Db, also establish IVf and IVb.   Use the current relay crypto, except&lt;br&gt;
    instead of starting the counters at 0, start them at IVf and IVb.&lt;br&gt;
    This way, an attacker doesn't have any known plaintexts to work with,&lt;br&gt;
    which makes AES a little more robust.&lt;br&gt;
&lt;br&gt;
6.2. Option 2: As 1, but tagging attacks garble the circuit after one block.&lt;br&gt;
&lt;br&gt;
    Keep an HMAC of all previously received encrypted cells on a circuit.&lt;br&gt;
    When decrypting a cell, use this HMAC value to determine the first 64&lt;br&gt;
    bits of the counter; increment the low 64 bits of the counter as&lt;br&gt;
    usual.&lt;br&gt;
&lt;br&gt;
    This way, if an adversary flips any bits before passing the stream&lt;br&gt;
    through an honest node, no _subsequent_ block will be recoverable.&lt;br&gt;
&lt;br&gt;
    To prevent any part of the stream from being re-used, close any&lt;br&gt;
    circuit if the low 64 bits of the counter would ever wrap (that is,&lt;br&gt;
    around 295 million terabytes).&lt;br&gt;
&lt;br&gt;
    (If we're using a stream cipher with fast re-key, then we can just&lt;br&gt;
    have the key used for each block be an HMAC of all previously&lt;br&gt;
    received ciphertext.)&lt;br&gt;
&lt;br&gt;
6.3. Option 3: As 1, but tagging attacks garble the circuit in the same block.&lt;br&gt;
&lt;br&gt;
    Use a large-block cipher mode, such as BEAR or LIONESS (depending on&lt;br&gt;
    whether we need a PRP or SPRP).   Base the key material for each block&lt;br&gt;
    on an HMAC of all previous blocks' ciphertexts.&lt;br&gt;
&lt;br&gt;
    This way, if an adversary makes any alteration in a block, that block&lt;br&gt;
    and all subsequent blocks will be garbled.   It's more expensive than&lt;br&gt;
    2, though, especially if we need to use a LIONESS construction.&lt;br&gt;
&lt;br&gt;
    {I considered IGE here, with a trick where odd-numbered nodes on a&lt;br&gt;
    circuit start from the front of the block and even-numbered nodes&lt;br&gt;
    start from the end, but it didn't seem much better.   We should&lt;br&gt;
    investigate relative performance, though.}&lt;br&gt;
&lt;br&gt;
6.4. Option 4: Shall we have middle nodes be able to fast-stop bad data?&lt;br&gt;
&lt;br&gt;
    In all the above options, if a cell is altered, the middle node can&lt;br&gt;
    at best turn that cell and the rest of the cells on the circuit into&lt;br&gt;
    garbage, which the last node won't deliver (if honest) or can't&lt;br&gt;
    deliver (if dishonest).&lt;br&gt;
&lt;br&gt;
    Might we prefer to do as in mixnets, and have nodes kill circuits&lt;br&gt;
    upon receiving altered cells?&lt;br&gt;
&lt;br&gt;
    It's not such an obvious improvement.   Including more MACs is more&lt;br&gt;
    expensive in per-cell overhead.   The attacks that we would foil this&lt;br&gt;
    way but not with Option 3 are not so much better than the the passive or&lt;br&gt;
    timing-based-active end-to-end attacks that would still remain.&lt;br&gt;
&lt;br&gt;
    Consider that if option 3 is in place, an end-to-end attacker who&lt;br&gt;
    wants to do a tagging attack at one node can garble the rest of the&lt;br&gt;
    circuit and see if the output is garbled at the exit node.   But such&lt;br&gt;
    an attacker could just as easily close the circuit at one of those&lt;br&gt;
    nodes and watch for a corresponding close event, or even better --&lt;br&gt;
    simply pause traffic on that circuit for a while and watch for a&lt;br&gt;
    corresponding gap at the exit.   The only advantage of the garbling&lt;br&gt;
    attack would be that garbled cells are presumably rarer than circuit&lt;br&gt;
    closes or traffic pauses, and thus easier to use to distinguish&lt;br&gt;
    target circuits.   But that's still questionable: the other attacks&lt;br&gt;
    win fine, and the pause attack doesn't risk detection as much.&lt;br&gt;
&lt;br&gt;
    So why might we want to do this?   First, the overhead doesn't need to&lt;br&gt;
    be as bad as you might first expect (see below).   Second, it would be&lt;br&gt;
    nice to increase the security margin as much as possible: "attacks&lt;br&gt;
    only get better".&lt;br&gt;
&lt;br&gt;
    So let's figure out how it would look.&lt;br&gt;
&lt;br&gt;
    To do this one, we'd want to have outgoing and incoming circuits&lt;br&gt;
    treated differently.   Incoming cells would get decrypted as in 1&lt;br&gt;
    above, except that we'd have a MAC on them.   For outgoing cells,&lt;br&gt;
    each node would check that the first N bytes of the cell&lt;br&gt;
    match a MAC of all data seen so far, *including the rest of the&lt;br&gt;
    cell*.   They'd then remove the first N bytes, re-pad the cell&lt;br&gt;
    with bytes from a PRNG, and decrypt the resulting re-padded cell.&lt;br&gt;
    (This is basically how mixmaster works, and how mixminion works in&lt;br&gt;
    the common case.)&lt;br&gt;
&lt;br&gt;
    The space overhead here is kind of large: N bits per cell per node.&lt;br&gt;
    In the most paranoid case, if we used 256-bit HMACs on 3-node paths,&lt;br&gt;
    that's 96 bytes per cell, which is more than 20% of the total length.&lt;br&gt;
    But we can probably do better if we let the CREATE operation also&lt;br&gt;
    tell the node some N to check.   For example, the first node doesn't&lt;br&gt;
    need to check any bits.   The second and third nodes could check 64&lt;br&gt;
    bits apiece; that only has 16 bytes overhead total, and high&lt;br&gt;
    probability of catching any changes. (Birthday attacks don't matter&lt;br&gt;
    here, and an attacker who mounts this attack for long enough to&lt;br&gt;
    accidentally find a 64-bit MAC will break so many circuits in the&lt;br&gt;
    process as to become totally unreliable.)&lt;br&gt;
&lt;br&gt;
    All of this leaks the path lengths and position on the path to&lt;br&gt;
    various nodes.   We might open ourselves up to partitioning attacks if&lt;br&gt;
    different clients choose different numbers of bits.   What's more, we&lt;br&gt;
    might leak the length of the path to the last node by how much junk&lt;br&gt;
    there is at the end of the cell.   So we'd need to be careful!&lt;br&gt;
&lt;br&gt;
    Here's a simple construction for this format, to be concrete:&lt;br&gt;
&lt;br&gt;
       The CREATE operation's KDF produces the following outputs:&lt;br&gt;
                Kf, IVf   (stream cipher key and IV for forward direction)&lt;br&gt;
                Kb, IVb   (stream cipher key and IV for reverse direction)&lt;br&gt;
                Mf          (MAC key for forward direction)&lt;br&gt;
                Mb          (MAC key for reverse direction)&lt;br&gt;
                SEEDf      (PRNG key for forward direction)&lt;br&gt;
       And it also sets the following user-selected parameter:&lt;br&gt;
                MACBYTESf (an integer between 0 and 32 inclusive)&lt;br&gt;
                MACBYTESb (an integer between 0 and 32 inclusive)&lt;br&gt;
                CANEXIT    (boolean: can we exit from this hop?)&lt;br&gt;
&lt;br&gt;
       Let Kf[i], Mf[i], etc denote the parameter Kf, Mf, etc as shared&lt;br&gt;
       between the client and the i'th node in its circuit.&lt;br&gt;
&lt;br&gt;
       Relay cells sent towards the client have the following plaintext&lt;br&gt;
       format:&lt;br&gt;
             Body:&lt;br&gt;
                Content:&lt;br&gt;
                   Relay Command [1 byte]&lt;br&gt;
                   StreamID         [2 bytes]&lt;br&gt;
                   Length            [2 bytes]&lt;br&gt;
                   Data               [Up to CELL_DATA_LEN-5-MACBYTESb bytes]&lt;br&gt;
                   Padding          [randomly generated as needed to fill the&lt;br&gt;
                                          cell]&lt;br&gt;
                MAC(All previous encrypted content + encrypted content,&lt;br&gt;
                                                   Mb)[:MACBYTESb]    [MACBYTESb \
bytes]&lt;br&gt; &lt;br&gt;
       The originator of the client-bound cell encrypts the content with&lt;br&gt;
       the next part of its Kb,IVb stream, then appends the MAC.&lt;br&gt;
&lt;br&gt;
       Non-clients receiving a client-bound relay cell encrypt the entire&lt;br&gt;
       cell body, MAC included, with the next part of the stream cipher&lt;br&gt;
       that was keyed with Kb,IVb.&lt;br&gt;
&lt;br&gt;
       When the client receives a relay cell body, it iteratively does:&lt;br&gt;
&lt;br&gt;
          For node i in circuit from 1..N:&lt;br&gt;
                Let cells_i = all previous cells which we previously decided&lt;br&gt;
                     were from node i, or relayed by node i,&lt;br&gt;
                and let cellbody = the body of the cell, except for the last&lt;br&gt;
                     MACBYTESb[i] bytes,&lt;br&gt;
                and let cellmac = the last MACBYTESb[i] bytes of this cell.&lt;br&gt;
&lt;br&gt;
                If cellmac is nonempty, check wither cellmac = mac_received,&lt;br&gt;
                where mac_received is the first MACBYTESb[i] bytes of&lt;br&gt;
                MAC(cells_i | cellbody, Mb[i]). If so, this cell is from node&lt;br&gt;
                i.&lt;br&gt;
&lt;br&gt;
                If this cell is from node i, add cellbody to cells_i, then&lt;br&gt;
                decrypt cellbody using the stream keyed with Kb[i],IVb[i].&lt;br&gt;
                Act on it as a relay cell.&lt;br&gt;
&lt;br&gt;
                Otherwise add the entire cell to cells_i, and decrypt it, MAC&lt;br&gt;
                included, with the stream keyed with Kb[i], IVb[i].&lt;br&gt;
&lt;br&gt;
          If no node sent this cell: it's junk and somebody is probably&lt;br&gt;
          messing with us!   Destroy the circuit.&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
       When the client *sends* a cell outbound to node N:&lt;br&gt;
&lt;br&gt;
             Let cells[i] start at "" for all i in 1...N initially, and \
get&lt;br&gt;  updated as below.&lt;br&gt;
&lt;br&gt;
             Let MACLEN = SUM(MACBYTESf[1...N])&lt;br&gt;
&lt;br&gt;
             Let Body =&lt;br&gt;
                   Relay Command [1 byte]&lt;br&gt;
                   StreamID         [2 bytes]&lt;br&gt;
                   Length            [2 bytes]&lt;br&gt;
                   Data               [Up to CELL_DATA_LEN-5-MACLEN bytes]&lt;br&gt;
                   Padding          [randomly generated,&lt;br&gt;
                                          CELL_DATA_LEN-5-MACLEN-len(Data) bytes]&lt;br&gt;
&lt;br&gt;
             Let PAD[i] = the next MACBYTESf[i] bytes from the PRNG keyed&lt;br&gt;
             with SEEDf[i], for i in 1...N&lt;br&gt;
&lt;br&gt;
             Let STREAM[i] = the next CELL_DATA_LEN bytes of&lt;br&gt;
                the stream keyed by Kf[i],IV[i], for i in 1...N&lt;br&gt;
&lt;br&gt;
             Let PADSEEN[1] == ""&lt;br&gt;
&lt;br&gt;
             For i in 2...N:&lt;br&gt;
                   Let L = len(PADSEEN[i-1]) + len(PAD[i-1])&lt;br&gt;
                   Let PADSEEN[i] = (PADSEEN[i-1] | PAD[i-1]) xor&lt;br&gt;
                                             STREAM[i-1][CELL_DATA_LEN-L:]&lt;br&gt;
&lt;br&gt;
             For i in N down to 1:&lt;br&gt;
&lt;br&gt;
                  Let Encbody = Body xor STREAM[i][:len(Body)]&lt;br&gt;
                  Let extra = "RECOGNIZED" if i == N, "OK" \
otherwise&lt;br&gt;  Let cells[i] = cells[i] | Body | PADSEEN[i]&lt;br&gt;
                  Let M = MAC(cells[i] | extra , Mf[i])&lt;br&gt;
&lt;br&gt;
                  Let Body = M[:MACBYTESf[i]] | EncBody&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
       To receive an outbound cell:&lt;br&gt;
&lt;br&gt;
             Let M be the first MACBYTESf bytes of the cell, let REST be the&lt;br&gt;
             rest of the cell, and let "cells" be all previous cells on \
                this&lt;br&gt;
             circuit.   If CANEXIT, and M = \
                MAC(cells|rest|"RECOGNIZED",&lt;br&gt;
             Mb)[:MACBYTESf], and MACBYTESf &gt; 0, this cell is for us.   If M&lt;br&gt;
             = MAC(cells|rest|"OK", Mb)[:MACBYTESf], this cell is not \
for&lt;br&gt;  us, but is valid.   Otherwise, destroy the circuit.&lt;br&gt;
&lt;br&gt;
             Let PAD = the next MACBYTESf[i] bytes of the PRNG keyed with&lt;br&gt;
             SEEDf, and decrypt REST | PAD using the stream cipher keyed&lt;br&gt;
             with Kf,IVf.   If this cell is for us, act on it as a relay&lt;br&gt;
             cell.   Otherwise, relay it.&lt;br&gt;
&lt;br&gt;
       ANOTHER VARIANT:&lt;br&gt;
&lt;br&gt;
             If we restrict MACBYTESf values to range 0..HL/2, where HL is the&lt;br&gt;
             length of the MAC output, we can replace&lt;br&gt;
                MAC(x | "RECOGNIZED")[:MACBYTESf] and MAC(x | \
"OK")[:MACBYTESf]&lt;br&gt;  with&lt;br&gt;
                MAC(x)[:MACBYTESf] and MAC(x)[HL-MACBYTESf:]&lt;br&gt;
&lt;br&gt;
       PICKING MACBYTESf,MACBYTESb.&lt;br&gt;
&lt;br&gt;
             We don't need to worry about birthday attacks:&lt;br&gt;
&lt;br&gt;
                  Because we're using a MAC, only the parties who are making&lt;br&gt;
                  the MACs could try to do a brute-force search for a&lt;br&gt;
                  collision, but they have no reason to do so.&lt;br&gt;
&lt;br&gt;
                  If a collision occurs accidentally, an adversary can't&lt;br&gt;
                  substitute an earlier-seen cell for a later one with the&lt;br&gt;
                  same MAC, since the MAC covers not only the cell, but all&lt;br&gt;
                  previous cells on the circuit.&lt;br&gt;
&lt;br&gt;
             So 16 bytes is about the most we should ever do, given our&lt;br&gt;
             usual security parameters.   Let me moot the number 8 for&lt;br&gt;
             MACBYTESb.&lt;br&gt;
&lt;br&gt;
             For outbound cells, for any hop we can exit from, choosing&lt;br&gt;
             MACBYTESf=6 gets us the current security level.   For the first&lt;br&gt;
             hop, assuming we don't exit from it, choosing MACBYTESf=0 is&lt;br&gt;
             totally safe, since the link crypto guarantees that nothing was&lt;br&gt;
             corrupted on the way.&lt;br&gt;
&lt;br&gt;
             In general, to prevent an end-to-end tagging attack, it seems&lt;br&gt;
             sufficient to do something like setting MACBYTES=8 for the last&lt;br&gt;
             hop, and MACBYTES=8 for one hop in the middle.&lt;br&gt;
&lt;br&gt;
       OTHER VARIANTS:&lt;br&gt;
&lt;br&gt;
             Can we combine this approach with one of the approaches in 2 or&lt;br&gt;
             3 above to ensure that if corrupt data passes (because of our&lt;br&gt;
             use of truncated HMACs) it still corrupts the stream?&lt;br&gt;
&lt;br&gt;
             Can/should we use GCM or something here instead of separate&lt;br&gt;
             encrypt/hmac operations?   It doesn't seem that GCM per se would&lt;br&gt;
             apply without some tweaking, which we probably do not have the&lt;br&gt;
             expertise to do.&lt;br&gt;
&lt;br&gt;
      OVERHEAD NOTES:&lt;br&gt;
&lt;br&gt;
             When computing additional overhead with this method, note that&lt;br&gt;
             it lets us replace the old 4 byte "digest" field and the 2 \
byte&lt;br&gt;  "recognized" field.&lt;br&gt;
&lt;br&gt;
             I note in passing that we need at most 9 bits for the length&lt;br&gt;
             field, and at most 6 bits for the command field, yet we're using \
                a&lt;br&gt;
             total of 3 bytes for those 15 bits.   That's an opportunity to&lt;br&gt;
             save another byte.&lt;br&gt;
&lt;br&gt;
ACKS&lt;br&gt;
&lt;br&gt;
    Lots of the good ideas and concerns here are due to Robert Ransom.&lt;br&gt;
&lt;br&gt;
    Michael Stone helped some with "relay option 4" above.&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br clear="all"&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;-- &lt;br&gt;"Those who would \
give up Essential Liberty to purchase a little Temporary Safety deserve neither   \
Liberty nor Safety."&lt;br&gt;-- Benjamin Franklin &lt;br&gt; &lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111101053345</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2011-11-01 05:33:45-0400</timestampReceived><subject>Re: [tor-dev] Draft sketch document with ideas for future crypto	ops</subject><body>

On Mon, Oct 31, 2011 at 09:25:58PM -0400, Nick Mathewson wrote:
&gt;   The point of this document is to discuss what crypto we ought to be using.

Thanks Nick!

&gt;     - To make sure that the extending node is talking to the right next node
&gt;       when sending an extend cell.
&gt; 
&gt;   The new extend cell format needs to allow the client to tell the
&gt;   extending node about some identity for the destination node that the
&gt;   extending node will be able to understand.  This is a capability of
&gt;   the extending node that the client needs to be able to check. (Also,
&gt;   the extend cell needs to hash that identity in a form the extending
&gt;   node can understand, but that's a fingerprint issue.)

Right now microdescriptors don't have any identity key in them. It would
seem that Alice never needs to remember the identity key for the relays
she uses at all. (She learns the fingerprint of the identity key from
the microdescriptor-flavored consensus, and if she does a handshake with
the relay she can learn its identity key while making sure it hashes to
the right thing, but otherwise she doesn't use or remember it.)

This is fine until we get to your sentence about Alice needing to know
how to hash the identity in some other form.

&gt;   a  When representing them in the UI, we should
&gt;   use the notation %b64, where b64 is a base-64 encoding, omitting the
&gt;   trailing =s.

Another use for identity keys that we left out of the list is the dot-exit
notation. I don't think base64 domain names will work.

It may well be fine to say that the feature dies in the migration,
but we should actively decide it rather than overlooking it.

&gt; 3.4. Implications for EXTEND cells
&gt; 
&gt;   As mentioned in 3.3, when a client Alice tells node Bob to extend
&gt;   to node Carol, she needs to give Bob a fingerprint for Carol that Bob
&gt;   will understand: one where Bob understands the digest algorithm, and
&gt;   understands the identity key type.
&gt; 
&gt;   There are two ways we can do this:
&gt; 
&gt;     1) Alice's EXTEND cell contains every fingerprint for Carol that
&gt;        Alice knows about.  Bob treats the cell as valid if every one he
&gt;        can verify is correct.
&gt; 
&gt;     2) Alice knows which fingerprint types Bob understands (either via
&gt;        his version, or something else in his directory info).  She
&gt;        selects a fingerprint for Carol using the best one of these
&gt;        types.
&gt; 
&gt;   The first seems more robust to me, if we have space for enough bytes.
&gt;   If we proliferate too many types, though, we'll need to do the second.

The first seems more prone to partitioning worries to me. If different
clients know how to handle different fingerprints, and the anonymous
client tells us which fingerprints it knows how to handle, that could
be bad news. Unless we're planning to just have Alice stick in all the
blobs that she thinks are fingerprints, whether her Tor version knows
how to read them or not? That could work.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102170116</emailId><senderName>Robert Ransom</senderName><senderEmail>rransom.8774@gmail.com</senderEmail><timestampReceived>2011-11-02 17:01:16-0400</timestampReceived><subject>Re: [tor-dev] Draft sketch document with ideas for future crypto ops</subject><body>

On 2011-11-01, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; On Mon, Oct 31, 2011 at 09:25:58PM -0400, Nick Mathewson wrote:
&gt;&gt;   The point of this document is to discuss what crypto we ought to be
&gt;&gt; using.
&gt;
&gt; Thanks Nick!
&gt;
&gt;&gt;     - To make sure that the extending node is talking to the right next
&gt;&gt; node
&gt;&gt;       when sending an extend cell.
&gt;&gt;
&gt;&gt;   The new extend cell format needs to allow the client to tell the
&gt;&gt;   extending node about some identity for the destination node that the
&gt;&gt;   extending node will be able to understand.  This is a capability of
&gt;&gt;   the extending node that the client needs to be able to check. (Also,
&gt;&gt;   the extend cell needs to hash that identity in a form the extending
&gt;&gt;   node can understand, but that's a fingerprint issue.)
&gt;
&gt; Right now microdescriptors don't have any identity key in them. It would
&gt; seem that Alice never needs to remember the identity key for the relays
&gt; she uses at all. (She learns the fingerprint of the identity key from
&gt; the microdescriptor-flavored consensus, and if she does a handshake with
&gt; the relay she can learn its identity key while making sure it hashes to
&gt; the right thing, but otherwise she doesn't use or remember it.)
&gt;
&gt; This is fine until we get to your sentence about Alice needing to know
&gt; how to hash the identity in some other form.

I suggest gluing the fingerprint-extraction function to the
identity-key signature cryptosystem in our protocols.  So, instead of
hashing 2048-bit RSA keys in multiple ways, we would have
rsa2048-sha256 for 2048-bit RSA keys used to sign SHA-256 hashes *and*
hashed into fingerprints using SHA-256, and we might also have
rsa2048-tiger for 2048-bit RSA keys used to sign Tiger hashes and
hashed into fingerprints using Tiger.

Curve25519 public keys do not need to be hashed to form fingerprints
-- the keys themselves are shorter than the output of any hash
function we would consider using.  (Yes, I know Tiger has a 192-bit
output.  We wouldn't consider using it.)

&gt;&gt;   a  When representing them in the UI, we should
&gt;&gt;   use the notation %b64, where b64 is a base-64 encoding, omitting the
&gt;&gt;   trailing =s.
&gt;
&gt; Another use for identity keys that we left out of the list is the dot-exit
&gt; notation. I don't think base64 domain names will work.

They won't work.  I suggest base32-encoded 255-bit (sc) hashes or
public keys (51 characters long).

&gt; It may well be fine to say that the feature dies in the migration,
&gt; but we should actively decide it rather than overlooking it.

We need to support some way to extend circuits to a specified exit
node without requiring a controller that reimplements Tor's full path
selection algorithm.

&gt;&gt; 3.4. Implications for EXTEND cells
&gt;&gt;
&gt;&gt;   As mentioned in 3.3, when a client Alice tells node Bob to extend
&gt;&gt;   to node Carol, she needs to give Bob a fingerprint for Carol that Bob
&gt;&gt;   will understand: one where Bob understands the digest algorithm, and
&gt;&gt;   understands the identity key type.

No.  We will only use fingerprints of identity keys for TLS-based link
protocols.

Link specifiers for our UDP-based link protocol will contain a
link-authentication public encryption key, and the CREATE cell that
causes a relay to open a UDP-based link will be sent encrypted to that
public key in the packet which opens the link.  (Yes, I know we can't
get forward secrecy for anything we send in that first packet
encrypted to a non-short-term public key.  We don't need forward
secrecy for a CREATE cell.)

&gt;&gt;   There are two ways we can do this:
&gt;&gt;
&gt;&gt;     1) Alice's EXTEND cell contains every fingerprint for Carol that
&gt;&gt;        Alice knows about.  Bob treats the cell as valid if every one he
&gt;&gt;        can verify is correct.
&gt;&gt;
&gt;&gt;     2) Alice knows which fingerprint types Bob understands (either via
&gt;&gt;        his version, or something else in his directory info).  She
&gt;&gt;        selects a fingerprint for Carol using the best one of these
&gt;&gt;        types.
&gt;&gt;
&gt;&gt;   The first seems more robust to me, if we have space for enough bytes.
&gt;&gt;   If we proliferate too many types, though, we'll need to do the second.
&gt;
&gt; The first seems more prone to partitioning worries to me. If different
&gt; clients know how to handle different fingerprints, and the anonymous
&gt; client tells us which fingerprints it knows how to handle, that could
&gt; be bad news. Unless we're planning to just have Alice stick in all the
&gt; blobs that she thinks are fingerprints, whether her Tor version knows
&gt; how to read them or not? That could work.

We discussed how to handle multiple crypto protocols earlier this
year.  Each relay publishes an ordered list of the protocols it likes
for each protocol slot; the consensus contains a set of currently
approved protocols for each protocol slot; each client uses the first
protocol in the relay's list which (a) the client supports and (b) is
listed in the consensus as approved', unless the user specifically
configures the client to use a custom set of protocols.  The
approved-protocol set in the consensus can both protect the anonymity
of clients which support new protocols and disable old protocols if
they break.


Robert Ransom
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111101193752</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-01 19:37:52-0400</timestampReceived><subject>[tor-dev] future-proofing by combining ciphers (was: Draft sketch</subject><body>

in reference to
https://lists.torproject.org/pipermail/tor-dev/2011-November/002999.html

We're doing a development effort and/or thought experiment in the
Tahoe-LAFS project. This development effort and/or thought experiment
is called "One Hundred Year Cryptography" [1].

The main result of the experiment so far is that you don't need to
worry very much future-proofing your digital signatures,
collision-resistant hashes, or MACs, but you *should* worry about
future-proofing your Diffie-Hellmans and ciphers!

Once you deploy a future version of Tor which no longer accepts
old-style signatures, then it will no longer matter to your users if
someone subsequently figures out how to forge old-style signatures
(for example by using quantum computers). On the other hand, once you
deploy a future version of Tor that uses a newer cipher, your users
remain vulnerable to an attacker who later breaks the older cipher and
reads their older plaintexts.

Combining two ciphers as you suggested by XORing their output (and
keying them independentlyperhaps by deriving two subkeys from a
master key using a strong KDF) seems to be a safe and efficient way to
protect against this sort of threat and doesn't seem to impose too
high of a burden of complexity. That's what we intend to do in
Tahoe-LAFS. A Google Summer of Code student, Yu Xue, contributed some
code to generate subkeys and XOR the streams, but we haven't yet
integrated it into Tahoe-LAFS itself. (I intend to do that in the
release cycle that just opened up, so within the next 4 or so months.)

I haven't thought very much about future-proofing Diffie-Hellman
operations. That sounds like it might be more complex. I *have*
thought about how to combine two different digital signatures or
public key encryption algorithms. Those don't seem too dauntingly
complex, but like I said not so urgent.

I'm leaning toward combining AES-256 with XSalsa20. Other interesting
options include ChaCha (used in SHA-3 finalist Blake, and very similar
to Salsa20) and Threefish (used in SHA-3 finalist Skein).

Regards,

Zooko

[1] https://tahoe-lafs.org/trac/tahoe-lafs/wiki/OneHundredYearCryptography
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111102014507</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-02 01:45:07-0400</timestampReceived><subject>Re: [tor-dev] is ECC patented? (was: Draft sketch document with</subject><body>

So I did some digging and Certicom claims nothing against RFC 6090.
They do claim 2 patents against the draft,
but I doubt either of them check out. One is on point validation by
substitution into a curve, the other on ECDSA for smart cards. If its
a big worry Tor should get a lawyer to check this out, but I'm not
that worried: Patents filled
in the 2000s seem a bit late to the party anyway.
Sincerely,
Watson Ladd

On Tue, Nov 1, 2011 at 2:05 PM, Zooko O'Whielacronx &lt;zooko@zooko.com&gt; wrote:
&gt; A few pointers. On the happy "yay we can use it freely" side, we have:
&gt;
&gt; * RFC 6090
&gt;
&gt; Pure gold! A catalog of ECC techniques which were published so long
&gt; ago that they cannot still be under patent. It includes digital
&gt; signatures and Diffie-Hellman.
&gt;
&gt; * DJB's page stating that certain patents don't apply to Curve25519
&gt; (which you mentioned): http://cr.yp.to/ecdh/patents.html
&gt;
&gt; * Jack Lloyd's statement that he avoided techniques newer than about
&gt; 1990 in Botan: https://bugzilla.redhat.com/show_bug.cgi?id=615372#c19
&gt;
&gt; On the sad "no we can't use it" side, we have:
&gt;
&gt; * Fedora's insistence on removing all elliptic curve cryptography from
&gt; their Linux distribution and refusing to answer questions about why:
&gt; https://bugzilla.redhat.com/show_bug.cgi?id=615372
&gt;
&gt; Regards,
&gt;
&gt; Zooko
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;



-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither   Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111102174638</emailId><senderName>unknown</senderName><senderEmail>unknown@pgpru.com</senderEmail><timestampReceived>2011-11-02 17:46:38-0400</timestampReceived><subject>Re: [tor-dev] Draft sketch document with ideas for future crypto ops</subject><body>

On Mon, 31 Oct 2011 23:59:55 -0500
Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:

&gt; What about this for modification resistance?
&gt; We keep a count of all cells passing and use AES in CTR mode with a 2 part
&gt; counter: the first part the cell counter, the second one a block counter.
&gt; Then to authenticate the cell we can use a 16 byte tag and a Wegman-Carter
&gt; MAC. This gives a total overhead of 48 bytes for a three hop link, which is
&gt; half the cited one, and which
&gt; is provably as secure as AES.
&gt; 
&gt; ChaCha is a component part of one of the SHA-3 finalists, namely JH. If JH
&gt; is selected as the SHA3 candidate, this may (read may) entail something
&gt; about the security of ChaCha. The HAIFA construction JH uses doesn't say
&gt; much about proofs of security, unlike the sponge papers.
&gt; 
&gt;
&gt; 2012 is coming soon: The schedule says between March and June of this year
&gt; SHA3 will be announced. Everything after that involves bureaucracy. Why
&gt; switch to SHA256 and then to SHA3 when we won't be done before March anyway?

I'm very enthusiastic about one of five SHA-3 finalist -- Keccak. 
I contact with the Keccak team about some ideas and they responded readily.
IMHO Keccak is more perspespective than Skein or ChaCha as a universal cryptoprimitive to make
most of symmetryc algos obsolete.

Keccak is not only a hash with any possible length of output but PBKDF, KDF, MAC, old-style HMAC, 
Stream cipher, random acces Stream Cipher, stronge authenticated Stream Cipher, 
per block or per complete message authenticated Stream Cipher and possible many more, 
proved to be secure in random oracle model and easy to use to make most of protocols
simple. 

The Keccak team pointed me to a method for executing stream cipher encryption and
authenticated encryption based on sponge.

The first presentation of the so called duplexing mode, using a sponge
for MACing and encryption was at the SHA-3 conference in Santa Barbara
in 2010.
You can download the paper from here
http://csrc.nist.gov/groups/ST/hash/sha-3/Round2/Aug2010/documents/papers/SHA3_Aug2010_Papers.zip
And recently presented at SAC2011, here you can have a look at the
presentation http://sac2011.ryerson.ca/SAC2011/BDPVA.pdf

If NIST make the Keccak a SHA-3 finalist then be prepare to integrate it as a good flexible choice.
Not only as a hash but virtually as everything symmetric algos.
Unfortunately, most of the Keccak properties may be standartizated so slow. 

And most of that non-hash properties seems non-conservative, experimental, innovatory and ambitious but
very amazingly perspective and good designed with respectful research works 
and good reputations of authors.

See www.keccak.noekeon.org for details.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102175348</emailId><senderName>unknown</senderName><senderEmail>unknown@pgpru.com</senderEmail><timestampReceived>2011-11-02 17:53:48-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me (was: Draft sketch</subject><body>

On Tue, 1 Nov 2011 14:51:00 -0700
coderman &lt;coderman@gmail.com&gt; wrote:

&gt; On Tue, Nov 1, 2011 at 1:20 PM, Zooko O'Whielacronx &lt;zooko@zooko.com&gt; wrote:
&gt; &gt; ...
&gt; &gt; Therefore, in the context of whether we can expect SHA-3 and/or
&gt; &gt; SHA-256 circuits to come built into our chips in the future, the fact
&gt; &gt; that SHA-256 can be implemented in a smaller circuit means it would be
&gt; &gt; cheaper for a chip maker to include it.
&gt; 
&gt; my strong preference for SHA-2-256 is precisely for this reason. i use
&gt; multiple systems with hardware accelerated SHA-2-256. these systems
&gt; will never have accelerated SHA-3.
&gt; 
&gt; adoption of SHA-3 into hardware designs may change this in the future;
&gt; i am skeptical :)
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

I'm very enthusiastic about one of five SHA-3 finalist -- Keccak. 
I contact with the Keccak team about some ideas and they responded readily.
IMHO Keccak is more perspespective than Skein or ChaCha as a universal cryptoprimitive to make
most of symmetryc algos obsolete.

Keccak is not only a hash with any possible length of output but PBKDF, KDF, MAC, old-style HMAC, 
Stream cipher, random acces Stream Cipher, stronge authenticated Stream Cipher, 
per block or per complete message authenticated Stream Cipher and possible many more, 
proved to be secure in random oracle model and easy to use to make most of protocols
simple. 

The Keccak team pointed me to a method for executing stream cipher encryption and
authenticated encryption based on sponge.

The first presentation of the so called duplexing mode, using a sponge
for MACing and encryption was at the SHA-3 conference in Santa Barbara
in 2010.
You can download the paper from here
http://csrc.nist.gov/groups/ST/hash/sha-3/Round2/Aug2010/documents/papers/SHA3_Aug2010_Papers.zip
And recently presented at SAC2011, here you can have a look at the
presentation http://sac2011.ryerson.ca/SAC2011/BDPVA.pdf

If NIST make the Keccak a SHA-3 finalist then be prepare to integrate it as a good flexible choice.
Not only as a hash but virtually as everything symmetric algos.
Unfortunately, most of the Keccak properties may be standartizated so slow. 

And most of that non-hash properties seems non-conservative, experimental, innovatory and ambitious but
very amazingly perspective and good designed with respectful research works 
and good reputations of authors.

See www.keccak.noekeon.org for details.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111102185032</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-02 18:50:32-0400</timestampReceived><subject>Re: [tor-dev] A concrete proposal for crypto (at least part of it)</subject><body>

On Wed, Nov 2, 2011 at 2:19 PM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; On Wed, Nov 2, 2011 at 11:45 AM, Robert Ransom &lt;rransom.8774@gmail.com&gt; w=
rote:
&gt;&gt; On 2011-11-02, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt;&gt;&gt; Dear All,
&gt;&gt;[...omitted..]
&gt;&gt;
&gt;&gt;&gt; Right now Tor encrypts the streams of data from a client to a OR with
&gt;&gt;&gt; AES-CTR and no integrity checks.
&gt;&gt;
&gt;&gt; Bullshit. =A0We have a 32-bit-per-cell integrity check at the ends of a =
circuit.
&gt; So let's say that I am a malicious 1st hop and a malicious 3rd hop,
&gt; and I want to find out. If I have known plaintext I can modify it, say
&gt; the packet type headers. =A0Then the third router will see nonsense and
&gt; know that it this circuit is compromised. The second router can detect
&gt; this with my proposal, it
&gt; cannot right now.

See https://blog.torproject.org/blog/one-cell-enough ; see also the
part in the original Tor design paper where we discuss integrity
checking and tagging attacks.  See also the three paragraphs near the
beginning of section 6.4 in the document under discussion, which say:

"""
   It's not such an obvious improvement.  Including more MACs is more
   expensive in per-cell overhead.  The attacks that we would foil this
   way but not with Option 3 are not so much better than the the passive or
   timing-based-active end-to-end attacks that would still remain.

   Consider that if option 3 is in place, an end-to-end attacker who
   wants to do a tagging attack at one node can garble the rest of the
   circuit and see if the output is garbled at the exit node.  But such
   an attacker could just as easily close the circuit at one of those
   nodes and watch for a corresponding close event, or even better --
   simply pause traffic on that circuit for a while and watch for a
   corresponding gap at the exit.  The only advantage of the garbling
   attack would be that garbled cells are presumably rarer than circuit
   closes or traffic pauses, and thus easier to use to distinguish
   target circuits.  But that's still questionable: the other attacks
   win fine, and the pause attack doesn't risk detection as much.

   So why might we want to do this?  First, the overhead doesn't need to
   be as bad as you might first expect (see below).  Second, it would be
   nice to increase the security margin as much as possible: "attacks
   only get better".
"""

In summary:

 - If you control first and last hops in any currently known
deployable low-latency anonymity design, you win already through
active and passive timing attacks.  (As Paul notes in his mail.)
 - Xor tagging attacks are strictly easier to detect than timing
attacks, since the attacker risks breaking the circuits that they
don't in fact control.
 - Therefore it isn't completely obvious that any attacker actually
gets weaker if Tor does hop-by-hop integrity-checking.  (Before
anybody says "but..." here, please actually go read that blog post :)
)
 - Moreover, doing whole-cell crypto (as in option 3) lowers the
number of bits that you can get out of a tagging attack.  So the
incremental advantage of option 4 (hop-by-hop integrity checking) over
option 3 may be even less than its advantage over current Tor.

 - But maybe we should do hop-by-hop integrity checking anyway, since:
   - Less sophisticated attackers probably would have an easier time
implementing tagging attacks than they would implementing timing
correlation attacks.
   - "Attacks get better, not worse."  Right now, I can't think of a
way to make cell tagging better than active or passive timing attacks.
 But who knows, maybe we'll be glad later that we added it for some
reason if somebody finds a novel attack on some other part of our
protocol stack or something.
  - It's doesn't have to be all that expensive in space to help a lot,
and it doesn't seem to be any more expensive in time than the
whole-cell-crypto designs of option 3.  (It might in fact be cheaper
in time, depending.)

This is one of the parts of the document that I wish people would
discuss, btw.  The conclusions here are not obvious to me, and
although I prefer hop-by-hop checking based on the reasons above, I
don't think that they're absolutely compelling.

&gt; Ends of circuit alone are not enough.

That's certainly worth discussing, but it's not what Robert was
disagreeing with.  What you said was "Tor encrypts the data ... with
no integrity checks."  I think that's what he was reacting to.

cheers,
--
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111103021227</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-03 02:12:27-0400</timestampReceived><subject>Re: [tor-dev] Rewriting tor-spec to be crypto agnostic</subject><body>

On Wed, Nov 2, 2011 at 9:25 PM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; Dear all,
&gt; I'm busy rewriting tor-spec (well, mangling it) to be crypto agnostic
&gt; (read: shoving hard choices to later). In the process I am trying to
&gt; make it a bit clearer.

Hi, Watson!  Some initial thoughts to observe or ignore as you see fit:

It's best to do stuff like this in multiple small steps if you want it
merged upstream.  That way, if we like 80% of what you're doing, we
can merge the 8/10 pieces we like right away and keep talking about
the remaining 2/10.  (For instance, stuff that improves clarity should
definitely go in.)

It's also a good idea to remember that the tor-spec.txt isn't just a
design for a possible anonymity net: it's a writeup for how Tor
actually works.  So anything that changes its semantic meaning is
un-mergeable unless Tor itself gets changed.  The process for doing
that is the proposal system documented in the tor-spec repository,
proposal 001.  So it's probably best to make sure you keep any
semantic changes separate.

&gt; The spec seems to hold open the possibility that nodes not on the two
&gt; ends of a circuit can send recognized RELAY cells (the role of OPs in
&gt; processing
&gt; RELAY cells is also unclear). Is this the case, or is this not
&gt; supported given that there are no points at which the spec explicitly
&gt; calls for them to be sent?

This is the "leaky pipe topology" as documented in the tor-design
paper, which you should probably read.  It is indeed intentional.

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111103215457</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-03 21:54:57-0400</timestampReceived><subject>[tor-dev] Leap Seconds</subject><body>

Dear All,
What precisely is the timestamp? Right now it says "number of seconds
since the Unix epoch" which leaves open TAI, UTC, or UT1. We probably
are using UTC so I should say that, but I just want to make sure.
Sincerely,
Watson Ladd
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111103232259</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-03 23:22:59-0400</timestampReceived><subject>Re: [tor-dev] patch to torspec that seperates out the crypto.</subject><body>

On Thu, Nov 3, 2011 at 6:30 PM, Watson Ladd &lt;watsonbladd@gmail.com&gt; wrote:
&gt; Dear all,
&gt; Here is a patch that removes crypto cruft from torspec.txt. It does
&gt; make torspec unusable because we haven't written crypto.txt yet.
&gt; In the process I noticed a few things I cleaned up, and also noticed
&gt; that RELAY_EXTEND cells have to be understood by both ORs, which
&gt; could be an impediment to migration.
&gt; Sincerely,
&gt; Watson Ladd

It's an interesting exercise but I don't think I can apply this any
time in the near future.

Trivial stuff that would be easy to fix:

a) It's an old-style diff. We're on unified diffs.  (So are most
open-source projects I know if.)

b) The clarity stuff is mixed in with the extract-crypto stuff. Like I
said previously, "It's best to do stuff like this in multiple small
steps if you want it merged upstream.  That way, if we like 80% of
what you're doing, we can merge the 8/10 pieces we like right away and
keep talking about the remaining 2/10."

c) It removes info without adding it elsewhere.  This would turn the
tor spec into "tor spec plus references to stuff that doesn't exist."
(I know you say "we haven't written it yet" -- but what's this "we"?
We already wrote a specification for Tor's crypto: it's tor-spec.txt.)

Fundamental stuff:

d) It feels like premature generalization.  The time to split off
"here is how the crypto fits in", it seems to me, is after we have
multiple crypto implementations.  Otherwise we're likely to draw the
boundaries wrong.

e) It adds confusing stuff in the name of clarity.  It's odd to say
that StreamIDs MUST NOT be zero and then go on to explain when they
may.

If you're having a good time and learning about Tor here I don't want
you to stop, but I don't think this is the right way to improve the
clarity and organization of our specifications.

apologies,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104011424</emailId><senderName>Watson Ladd</senderName><senderEmail>watsonbladd@gmail.com</senderEmail><timestampReceived>2011-11-04 01:14:24-0400</timestampReceived><subject>[tor-dev] [idle speculation] Combining bridge partioning and</subject><body>

Dear all,
I read arma's blog entry calling for someone to see if limiting
zig-zag attacks would harm anonymity. Well, I don't have an answer,
but I did notice that we could increase the number of bridge
authorities by having each bridge authority take a distinct subset of
bridges to hand out, and then implementing a honest forwarder that
forwards an email asking for bridges to a bridge authority based on
some hash function of the requesting gmail address. Compromising an
authority results in those bridges being cut off, but only a subset of
users are affected. This also prevents zig-zag attacks: there are no
clients who see bridges in two distinct authorities mandate.
Unfortunately this only works if bridges are careful not to be listed
by multiple authorities.
Sincerely,
Watson Ladd



-- 
"Those who would give up Essential Liberty to purchase a little
Temporary Safety deserve neither   Liberty nor Safety."
-- Benjamin Franklin
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20111104154600</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-11-04 15:46:00-0400</timestampReceived><subject>Re: [tor-dev] The consequences of key compromise (or the reasons</subject><body>

On 11/04/2011 01:39 AM, Jon Callas wrote:
&gt;
&gt; It's certainly laudable to worry about TLAs with ASICs. They probably
&gt; can't break 80-bit crypto yet, but that's why you need to get off of
&gt; it now.
&gt;
&gt; On the other hand, no TLA worth their salt is buying ASICs to crack
&gt; crypto. They are buying zero-day kernel 'sploits. That's how the
&gt; Germans are beating Skype. Keep that in perspective. The half life of
&gt; an ASIC is 18 months. Zero-days are much more effective and much
&gt; cheaper.

I think this does not follow. Just because they are buying 0-days 
doesn't mean that they are not also buying ASICs (or at least FPGAs). My 
guess is that there are some adversaries with more money for 
cybershenanigans than they know what to do with right now.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111104195306</emailId><senderName>Jon Callas</senderName><senderEmail>joncallas@me.com</senderEmail><timestampReceived>2011-11-04 19:53:06-0400</timestampReceived><subject>Re: [tor-dev] Subject: Re: The consequences of key compromise (or</subject><body>


On Nov 4, 2011, at 12:14 AM, Markku-Juhani O. Saarinen wrote:

&gt; 
&gt; From: Jon Callas &lt;joncallas@me.com&gt;
&gt; 
&gt; &gt; People should get off of 80-bit crypto as soon as is reasonably possible. This \
&gt; &gt; means RSA 1024, SHA-1, etc. NIST recommended doing this by the end of 2010, but \
&gt; &gt; are now holding their nose and saying that 2013 is the real new date.
&gt; 
&gt; Absolutely agree. The 80-bit figure was apparently adopted by U.S.
&gt; Government some 25+ years ago (skipjack etc).

Yeah, Skipjack is one of the others in the suite, but we civilians don't use it. \
We're pretty good at 128-bit crypto on the symmetric side. However, the other major \
thing to remember is that a block size of 64 bits also is an issue. There are \
birthday-bounds problems for objects of size around the size of a Blu-Ray disk.

&gt; 
&gt; &gt; This seems basically reasonable to me. No one has yet factored a 768-bit number, \
&gt; &gt; let alone a 1K one. 
&gt; 
&gt; 768-bit RSA was factored in 2009 and the authors of that paper
&gt; conjecture that 1024 bits would be factored "within a decade" and
&gt; recommend that 1024-bit RSA should be phased out within a couple of
&gt; years. http://eprint.iacr.org/2010/006.pdf
&gt; 
&gt; I am certainly doing that with the stuff that I am maintaining.

It was a special-form number, though. It wasn't a general-case one. I didn't go into \
details because we should all be getting off 1024. In many cases, jumping to 2K-bit \
keys works fine. In others, it doesn't.

&gt; 
&gt; &gt; SHA-1 actually looks safer today than it did in 2005. But still. Moving away is a \
&gt; &gt; Good Thing, so long as it doesn't make you do something stupid.
&gt; 
&gt; Well, after the 2005 Wang-Yin-Yu paper which had a 2^69 attack, there
&gt; was a claimed 2^52 attack in 2009 which turned out to have a flawed cost
&gt; evaluation. There has also been talk of a 2^63 attack, but that
&gt; difference can be put down to attack implementation skill and detail.

I'll repeat what I said after the 2^52 paper: 2^52 *whats*? It matters. 2^52 seconds \
is still a large number, and smaller than  (but near to) 2^80 clock cycles. I've \
never gotten a good answer to that.

But -- I was recommending "walk, do not run to the exit" in 2005. NIST wanted people \
off of it by 2010. My comment is at best a left-handed compliment.


&gt; 
&gt; I was always doubtful whether or not those techniques could be expanded
&gt; to work against the SHA-2 algorithms. 

Me too, but there were people who were sure of it in 2004-2005.

&gt; 
&gt; It is also funny that many people talk about SHA-2 as if was a single
&gt; algorithm; there are actually two quite distinct algorithms, one for
&gt; (now fading) 32-bit architectures (SHA-224,SHA-256) and one for 64-bit
&gt; algorithms (SHA-384,SHA-512,SHA-512/224,SHA-512/256). The variants of
&gt; these two algorithms only differ in the number of output bits and the IV
&gt; values and hence have a constant speed regardless of their digest size.
&gt; You can run "openssl speed sha" to see a real-world performance
&gt; comparison on a particular box.


You are, of course, correct.

I try to call out SHA-256 and SHA-512, but sometimes it's simpler to call them SHA-2, \
especially since NIST does.

	Jon

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111104234943</emailId><senderName>"Zooko O'Whielacronx"</senderName><senderEmail>zooko@zooko.com</senderEmail><timestampReceived>2011-11-04 23:49:43-0400</timestampReceived><subject>Re: [tor-dev] SHA-3 isn't looking so hot to me</subject><body>

Here is the letter I wrote to the SHA-3 mailing list, followed by
replies from Jon Callas and John Kelsey.

-------
From: Zooko O'Whielacronx
	
Folks:

You might be interested in this discussion on the tor-dev mailing list
about a new crypto protocol for Tor:

https://lists.torproject.org/pipermail/tor-dev/2011-November/date.html

One of the issues brought up by Tor developer Nick Mathewson was
whether to switch from SHA-1 to SHA-2 or instead wait for SHA-3. I
argued that SHA-2 is better than SHA-3 (at least for a few years).

I feel slightly traitorous saying it, because I've enjoyed reading
this mailing list for years, and many of the SHA-3 candidates are
beautiful constructions, and I want them to be widely studied and
used, but there you have it: I can't think of good arguments for the
Tor developers to jump to SHA-3. Perhaps you can!

Regards,

Zooko
-------

-------
From: Jon Callas

Why do you feel traitorous saying it? In my opinion it's the right
decision (and frankly, having read the notes, some of the others are
sub-optimal), and I'm a co-author of a finalist.

Engineering is the art of applying science within constraints. Those
constraints include but are not limited to the laws of physics,
budgets, schedules, performance, and so on. The worst decision is no
decision.

If you are unhappy with SHA-1 for security reasons, then your first
choice should be using SHA-256. Your second choice should be SHA-512,
possibly in one of the narrow-width constructions that NIST recently
published. Those are the best-understood secure hash functions we
have.

SHA-3 candidates, no matter which ones they are are each and all
slightly less well-understood than SHA-2, for all the obvious reasons.

If you are unhappy with the above assessment for *performance*
reasons, well, that's a different kettle of fish entirely. Further
discussion is needed, but it's easier to find a performance metric and
select along it than there is to find a security metric. It can be
done, obviously, but the debate is a lot more entertaining.

The hardest thing of all, of course, is to try to minimax the two
considerations, security and performance. That debate would be really
entertaining.

All of this, however, presupposes that Tor can't reserve an algorithm
identifier for SHA-3 and design things so SHA-256 is used now and
SHA-3 when it's finally available. And yes, that's easier said than
done, but heck, that's what engineering is, too.

       Jon
-------

-------
From: John Kelsey

For whatever it's worth, if someone asked me the same question, I'd
give the same advice--go ahead and switch to SHA256 or SHA512, but
make sure you build algorithm identifiers and versioning into your
protocol, so that it's possible to change hash functions (and
everything else) when you need to.

SHA1 has a claimed collision attack (which looks like it should be
right, but has never been verified experimentally), and also has a
certain collision attack at 2^{80} work, so if you are worried about
collisions in your application, you should definitely switch, and I
think SHA2 is pretty much the only good choice right now.  Similarly,
if you're in a position to change hash functions now, but it will be a
big pain to do it in two or three years, switching to SHA2 makes good
sense.  On the other hand, if you're only using SHA1 with HMAC to do
MACing and key derivation and random number generation, there doesn't
appear to be any great urgency in switching over, as there are no
results I'm aware of that come anywhere close to really threatening
those applications.  There's no reason to keep SHA1 around in those
applications if you don't need to, but there is also no enormous
urgency switching over to SHA2 or SHA3 for HMAC.

Finally, if you're only worried about preimage and second preimage
resistance, SHA1 still seems okay.  But be careful assuming that you
don't care about collisions--there are a lot of weird and surprising
things you can do to hash functions if you can find intermediate
collisions.  For example, if a single colliding message is no big
deal, but a billion messages with the same hash is a disaster for your
application, it turns out you care very much about the difficulty of
finding one collision at a time in your Merkle-Damgaard hash function.
 It's much safer to just use hash functions whose cryptographic
strength and width makes collisions impractical to ever find--that is,
hash functions like SHA2 instead of SHA1.

--John
-------
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111106005855</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-06 00:58:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal 189: AUTHORIZE and AUTHORIZED cells</subject><body>

Julian Yon &lt;julian@yon.org.uk&gt; writes:

&gt; On 05/11/11 03:21, George Kadianakis wrote:
&gt;&gt; There are some things in these HTTP solutions that make me nervous.
&gt;&gt; 
&gt;&gt; In the "GET /?q=correct+horse+battery+staple\r\n\r\n" client-side case
&gt;&gt; we will have to build HTTP header spoofing into the tor client, which
&gt;&gt; is not fun since modern browsers send loads of HTTP headers in their
&gt;&gt; first GET.
&gt;
&gt; A valid concern. Also applies to the ETag proposal.
&gt;
&gt;&gt; In the Etags/Cookies/whatever server-side case we will probably have
&gt;&gt; to build some sort of 'valid document'/'innocuous webpage' generator
&gt;&gt; into the Tor bridge, which is also not fun. Fortunately, we might be
&gt;&gt; able to reuse such a construction when Bridge Passwords fail:
&gt;&gt; https://lists.torproject.org/pipermail/tor-dev/2011-October/002996.html
&gt;
&gt; My thought was that it's not too hard to proxy to a real webserver for
&gt; content and inject/modify headers as required.
&gt;
&gt;&gt; Still, I would very much enjoy if we could find a way to authenticate
&gt;&gt; the bridge using the shared secret without relying on HTTP covert
&gt;&gt; channel wizardry. 
&gt;
&gt; We're really talking about steganography here rather than a true covert
&gt; channel. I believe the purpose is to avoid bridge enumeration due to the
&gt; initial connection having a fingerprint? So you need an invisible method
&gt; of authentication. It may be that distributing more information to
&gt; bridge users out-of-band is actually the best approach. But to me the
&gt; advantage of a technical solution is increased resistance to social
&gt; engineering.
&gt;
&gt;&gt; I've been thinking of having bridges that use Bridge Passwords, "tag"
&gt;&gt; their SSL certificate, say the Serial Number, with their password, and
&gt;&gt; have clients validate them before proceeding with AUTHORIZE cells.
&gt;
&gt; That's certainly subtle. You're left with the problem of what the client
&gt; should do if it can't authenticate the bridge. It still needs to send
&gt; something down the pipe that it opened, and the server still needs to
&gt; respond to that, otherwise the unused connection will look suspicious.
&gt;
&gt;
&gt; J

Thanks for the ideas and the interest guys! 

I think it's time to reroute this thread towards comments on proposal
189 and scanning resistance; that is resistance against adversaries
who scan hosts to find bridges.

We will surely need a different thread and a different proposal for
resistance against censors using MITM attacks to detect bridges.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111107021243</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-07 02:12:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal 190: Password-based Bridge Client</subject><body>

Let's try again this proposal with a more Keep It Simple, Stupid!
approach.

After deciding that MITM is not in our threat model at the moment,
this new proposal 190 doesn't even try to protect against an MITM
adversary! It's slicker, faster and maybe even better.
Inlining:

Filename: 190-shared-secret-bridge-authorization.txt
Title: Bridge Client Authorization Based on a Shared Secret
Author: George Kadianakis
Created: 04 Nov 2011
Status: Open

1. Overview

   Proposals 187 and 189 introduced AUTHORIZE and AUTHORIZED cells.
   Their purpose is to make bridge relays scanning resistant against
   censoring adversaries capable of probing hosts to observe whether
   they speak the Tor protocol.

   This proposal specifies a bridge client authorization scheme based
   on a shared secret between the bridge user and bridge operator.

2. Motivation

   A bridge client authorization scheme should only allow clients who
   show knowledge of a shared secret to talk Tor to the bridge.

3. Shared-secret-based authorization

3.1. Where do shared secrets come from?

   A shared secret is a piece of data known only to the bridge
   operator and the bridge client.

   It's meant to be automatically generated by the bridge
   implementation to avoid issues with insecure and weak passwords.

   Bridge implementations SHOULD create shared secrets by generating
   random data using a strong RNG or PRNG.

3.2. AUTHORIZE cell format

   In shared-secret-based authorization, the MethodFields field of the
   AUTHORIZE cell becomes:

       'shared_secret'               [10 octets]

   where:

   'shared_secret', is the shared secret between the bridge operator
                    and the bridge client.

3.3. Cell parsing

   Bridge implementations MUST reject any AUTHORIZE cells whose
   'shared_secret' field does not match the shared secret negotiated
   between the bridge operator and authorized bridge clients.

4. Tor implementation

4.1. Bridge side

   Tor bridge implementations MUST create the bridge shared secret by
   generating 10 octets of random data using a strong RNG or PRNG.

   Tor bridge implementations MUST store the shared secret in
   'DataDirectory/keys/bridge_auth_ss_key' in hexademical encoding.

   Tor bridge implementations MUST support the boolean
   'BridgeRequireClientSharedSecretAuthorization' configuration file
   option which enables bridge client authorization based on a shared
   secret.

   If 'BridgeRequireClientSharedSecretAuthorization' is set, bridge
   implementations MUST generate a new shared secret, if
   'DataDirectory/keys/bridge_auth_ss_key' does not already exist.

4.2. Client side

   Tor client implementations must extend their Bridge line format to
   support bridge shared secrets. The new format is:
     Bridge &lt;method&gt; &lt;address:port&gt; [["keyid="]&lt;id-fingerprint&gt;] ["shared_secret="&lt;shared_secret&gt;]

   where &lt;shared_secret&gt; is the bridge shared secret in hexademical
   encoding.

   Tor clients who use bridges with shared-secret-based client
   authorization must specify the bridge's shared secret as in:
     Bridge 12.34.56.78 shared_secret=934caff420aa7852b855

5. Discussion

5.1. What should actually happen when a bridge rejects an AUTHORIZE
     cell?

   When a bridge detects a badly formed or malicious AUTHORIZE cell,
   it should assume that the other side is an adversary scanning for
   bridges. The bridge should then act accordingly to avoid detection.

   This proposal does not try to specify how a bridge can avoid
   detection by an adversary.

6. Acknowledgements

   Thanks to Nick Mathewson and Robert Ransom for the help and
   suggestions while writing this proposal.


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108090850</emailId><senderName>"warms0x"</senderName><senderEmail>warms0x@riseup.net</senderEmail><timestampReceived>2011-11-08 09:08:50-0400</timestampReceived><subject>Re: [tor-dev] Implement JSONP interface for check.torproject.org</subject><body>

&gt; (Off-list reply to avoid unnecessary archive bits :))

Well damn. Since I already screwed up, I might as well apologize with
another unnecessary email to the list.

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108180706</emailId><senderName>Marsh Ray</senderName><senderEmail>marsh@extendedsubset.com</senderEmail><timestampReceived>2011-11-08 18:07:06-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance</subject><body>

On 11/08/2011 09:36 AM, George Kadianakis wrote:
&gt;
&gt; Some arguments to consider against the tagging idea are:
&gt; c) We most probably won't be able to tag CA-signed certificates.

TLS 1.0 over TCP port 443 with a server cert rooting to a well-known CA 
is probably the biggest stream of opaque traffic on the Internet.

Seems like it would be a big loss to not be able to blend in with that.

- Marsh
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111108232155</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@gmail.com</senderEmail><timestampReceived>2011-11-08 23:21:55-0400</timestampReceived><subject>Re: [tor-dev] Proposal: Bridge Detection Resistance against</subject><body>

Alright, posting an updated version of this proposal. It features
shortened fingerprints and discussion on the certificate tagging.

I hope 39 Base32 characters feel OK. If not, state your arguments and
preferred solutions and I will update the proposal locally; I will try
to not spam the list even more for fingerprint size changes.

Inlining:

Filename: XXX-mitm-bridge-detection-resistance.txt
Title: Bridge Detection Resistance against MITM-capable Adversaries
Author: George Kadianakis
Created: 07 Nov 2011
Status: Open

1. Overview

   Proposals 187, 189 and 190 make the first steps toward scanning
   resistant bridges. They attempt to block attacks from censoring
   adversaries who provoke bridges into speaking the Tor protocol.

   An attack vector that hasn't been explored in those previous
   proposals is that of an adversary capable of performing Man In The
   Middle attacks to Tor clients. At the moment, Tor clients using the
   v3 link protocol have no way to detect such an MITM attack, and
   will gladly send an VERSIONS or an AUTHORIZE cell to the MITMed
   connection, thereby revealing the Tor protocol and thus the bridge.

   This proposal introduces a way for clients to detect an MITMed SSL
   connection, allowing them to protect against the above attack.

2. Motivation

   When the v3 link handshake protocol is performed, Tor's SSL
   handshake is performed with the server sending a self-signed
   certificate and the client blindly accepting it. This allows the
   adversary to perform an MITM attack.

   A Tor client must detect the MITM attack before he initializes the
   Tor protocol by sending a VERSIONS or an AUTHORIZE cell. A good
   moment to detect such an MITM attack is during the SSL handshake.

   To achieve that, bridge operators provide their bridge users with a
   hash digest of the public-key certificate their bridge is using for
   SSL. Bridge clients store that hash digest locally and associate it
   with that specific bridge. Bridge clients who have "pinned" a
   bridge to a certificate "fingerprint" can thereafter validate that
   their SSL connection peer is the intended bridge.

   Of course, the hash digest must be provided to users out-of-band
   and before the actual SSL handshake. Usually, the bridge operator
   gives the hash digest to her bridge users along with the rest of
   the bridge credentials, like the bridge's address and port.

3. Security implications

   Bridge clients who have pinned a bridge to a certificate
   fingerprint will be able to detect an MITMing adversary in timely
   fashion. If after detection they act as an innocuous Internet
   client, they can successfully remove suspicion from the SSL
   connection and subvert bridge detection.

   Pinning a certificate fingerprint and detecting an MITMing attacker
   does not automatically aleviate suspicions from the bridge or the
   client. Clients must have a behavior to follow after detecting the
   MITM attack so that they look like innocent Netizens. This proposal
   does not try to specify such a behavior.

   Implementation and use of this scheme does not render bridges and
   clients immune to scanning or DPI attacks. This scheme should be
   used along with bridge client authorization schemes like the ones
   detailed in proposal 190.

4. Tor Implementation

4.1. Certificate fingerprint creation

   The certificate fingerprints used on this scheme MUST be computed
   by applying the SHA256 cryptographic hash function upon the ASN.1
   DER encoding of a public-key certificate, then truncating the hash
   output to 12 bytes, encoding it to RFC4648 Base32 and omitting any
   trailing padding '='.

4.2. Bridge side implementation

   Tor bridge implementations SHOULD provide a command line option
   that exports a fully equipped Bridge line containing the bridge
   address and port, the link certificate fingerprint and any other
   enabled Bridge options, so that bridge operators can easily send it
   to their users.

   In the case of expiring SSL certificates, Tor bridge
   implementations SHOULD warn the bridge operator a sensible amount
   of time before the expiration, so that she can warn her clients and
   potentially rotate the certificate herself.

4.3. Client side implementation

   Tor client implementations MUST extend their Bridge line format to
   support bridge SSL certificate fingerprints. The new format is:
     Bridge &lt;method&gt; &lt;address:port&gt; [["keyid="]&lt;id-fingerprint&gt;] \
       ["shared_secret="&lt;shared_secret&gt;] ["link_cert_fpr="&lt;fingerprint&gt;]

   where &lt;fingerprint&gt; is the bridge's SSL certificate fingerprint in
   hexademical encoding.

   Tor clients who use bridges and want to pin their SSL certificates
   must specify the bridge's SSL certificate fingerprint as in:
     Bridge 12.34.56.78 shared_secret=934caff420aa7852b855 \
         link_cert_fpr=GM4GEMBXGEZGKOJQMJSWINZSHFSGMOBRMYZGCMQ

4.4. Implementation prerequisites

   Tor bridges currently rotate their SSL certificates every 2
   hours. This not only acts as a fingerprint for the bridges, but it
   also acts as a blocker for this proposal.

   Tor trac ticket #4390 and proposal YYY were created to resolve this
   issue.

5. Other ideas

5.1. Certificate tagging using a shared secret

   Another idea worth considering is having the bridge use the shared
   secret from proposal 190 to embed a "secret message" on her
   certificate, which could only be understood by a client who knows
   that shared secret, essentially authenticating the bridge.

   Specifically, the bridge would "tag" the Serial Number (or any
   other covert field) of her certificate with the (potentially
   truncated) HMAC of her link public key, using the shared secret of
   proposal 190 as the key: HMAC(shared_secret, link_public_key).

   A client knowing the shared secret would be able to verify the
   'link_public_key' and authenticate the bridge, and since the Serial
   Number field is usually composed of random bytes a probing attacker
   would not notice the "tagging" of the certificate.

   Arguments for this scheme are that it:
   a) doesn't need extra bridge credentials apart from the shared secret
      of prop190.
   b) doesn't need any maintenance in case of certificate expiration.

   Arguments against this scheme are:
   a) In the case of self-signed certificates, OpenSSL creates an
      8-bytes random Serial number, and we would probably need
      something more than 8-bytes to tag. There are not many other
      covert fields in SSL certificates mutable by vanilla OpenSSL.
   b) It complicates the scheme, and if not implemented and researched
      wisely it might also make it fingerprintable.
   c) We most probably won't be able to tag CA-signed certificates.

6. Discussion

6.1. In section 4.1, why do you truncate the SHA256 output to 12 bytes?!

   Bridge credentials are frequently propagated by word of mouth or
   are physically written down, which renders the occult Base64
   encoding unsatisfactory. The 104 characters Base32 encoding or the
   64 characters hex representation of the SHA256 output would also be
   too much bloat.

   By truncating the SHA256 output to 12 bytes and encoding it with
   Base32, we get 39 characters of readable and easy to transcribe
   output, and sufficient security. Finally, dividing '39' by the
   golden ratio gives us about 24.10!

6. Acknowledgements

   Thanks to Robert Ransom for his great help and suggestions on
   devising this scheme and writing this proposal!

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111109073726</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-11-09 07:37:26-0400</timestampReceived><subject>Re: [tor-dev] [Patch] or/eventdns.c</subject><body>

"Nick Mathewson" &lt;nickm@alum.mit.edu&gt; wrote:

&gt; I can't merge this one because we're trying to minimize drift between
&gt; Libevent's evdns.c and Tor's eventdns.c.  Once we (eventually) require
&gt; libevent 2.0, we can just throw out our own eventdns.c . 

I cannot see that my use of set_socket_nonblocking() and network_init()
has anything to do with libevent. 

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111112044846</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-12 04:48:46-0400</timestampReceived><subject>Re: [tor-dev] [Patch] test_util.c</subject><body>

On Fri, Nov 11, 2011 at 11:46 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
&gt; Those '{}' constructs are not well liked by MSVC (cl v.16.xx).
&gt; An easy fix:

Applied; thanks!

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111112224012</emailId><senderName>Julian Yon</senderName><senderEmail>julian@yon.org.uk</senderEmail><timestampReceived>2011-11-12 22:40:12-0400</timestampReceived><subject>Re: [tor-dev] What Should Tor Bridges and Clients Do When They Get</subject><body>

[Attachment #2 (multipart/signed)]


On 09/11/11 16:12, George Kadianakis wrote:
&gt; The easy choice is an "HTTPS" server with the default Apache "It
&gt; Works!", or a closed basic access authentication, but really
&gt; implementing a spoofed HTTPS server in tor will be a PITA, because
&gt; censors can easily test us by provoking one of [0] (there is a reason
&gt; that HTTP servers usually require lots of LoCs to work).
&gt; 
&gt; Maybe we should ship a configured Apache server with the long-term
&gt; future "Anti-censorship Tor Bundle"?

Sounds good. But is this also vulnerable to fingerprinting? There's
nothing gained if Tor-Apache sticks out like an inflamed digit.

&gt; Also, what happens to Tor on Linux when it can't listen on port 443?
&gt; Or when port 443 is already taken? HTTPS servers on 9001 sure look
&gt; sketchy.
&gt; 
&gt; Any ideas are welcome.
&gt; 
&gt; Any services widely used, frequently seen with SSL support, that
&gt; handle traffic that kinda looks like Tor's and are easily
&gt; implementable, are also welcome.

People use SMTP, POP, IMAP, XMPP over SSL (off the top of my head). Not
sure any of them look convincingly like web traffic though.


Julian

-- 
3072D/D2DE707D Julian Yon (2011 General Use) &lt;pgp.2011@jry.me&gt;


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111117004742</emailId><senderName>Qiang Wang</senderName><senderEmail>wangq1979@gmail.com</senderEmail><timestampReceived>2011-11-17 00:47:42-0400</timestampReceived><subject>Re: [tor-dev] About JTor project</subject><body>

[Attachment #2 (multipart/alternative)]


HI Damian,

Thank you for your prompt reply, and your advice. I will take a close look
at them to see if I can provide any help.

Cheers!

Qiang

On 17 November 2011 00:26, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; &gt; I am very interested in Tor project, and I want to contribute something
&gt; to
&gt; &gt; it. In particular, I'd like to work on JTor. Could anyone tell me whom I
&gt; can
&gt; &gt; contact with for further information regarding getting involved in?
&gt;
&gt; Hi Qiang. Glad you want to help! JTor has been without a maintainer
&gt; for quite a while so the project's author, Bruce (cc-ed), will be your
&gt; best bet if you have questions or need a mentor. If you're interested
&gt; in java projects in general then Orbot and Metrics are both java
&gt; codebases as well.
&gt;
&gt; Cheers! -Damian
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

HI Damian,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thank you for your prompt reply, and your advice. I \
will take a close look at them to see if I can provide any \
help.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cheers!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Qiang&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt; On 17 November 2011 00:26, Damian Johnson &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; &lt;div class="im"&gt;&gt; I am very interested in Tor \
project, and I want to contribute something to&lt;br&gt; &gt; it. In particular, I'd \
like to work on JTor. Could anyone tell me whom I can&lt;br&gt; &gt; contact with for \
further information regarding getting involved in?&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Hi Qiang. Glad you want to help! JTor has been without a maintainer&lt;br&gt;
for quite a while so the project's author, Bruce (cc-ed), will be your&lt;br&gt;
best bet if you have questions or need a mentor. If you're interested&lt;br&gt;
in java projects in general then Orbot and Metrics are both java&lt;br&gt;
codebases as well.&lt;br&gt;
&lt;br&gt;
Cheers! -Damian&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt;
&lt;a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt; &lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111117065140</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2011-11-17 06:51:40-0400</timestampReceived><subject>Re: [tor-dev] Regarding Metrics project</subject><body>

Hi Qiang,

I'm cc'ing tor-dev, because I think your original request to work on
Java codebases went there.

On 11/17/11 2:13 AM, Qiang Wang wrote:
&gt; This is Qiang, and I am very interested in Tor project, and want to
&gt; contribute something. I was wondering if I can provide any help about
&gt; metrics project?
&gt; 
&gt; Could you please let me know your recommendations?

Sure thing.  Three ideas come to mind:

- Improve the consensus-health script: We have a Java program that
downloads the network statuses from all eight directory authorities and
compares them to each other to detect problems.  One of the outputs is a
web page [0], another output is a status email [1], and a third is a
message sent to an IRC bot [2].  The code [3] needs some love.

- Answer the question what fraction of exit relays exit from a different
IP than is in their descriptor.  This is a typical question that can be
answered using the metrics data [4] we have.  We'd want to publish the
analysis code in the metrics-tasks repository [5], so that others can
reproduce the results or refine the analysis.  There's already a lot of
Java code in that repository, because that's what I use when analyzing
metrics data.  We have plenty of other analysis questions similar to
this one, so if you don't like this one, take a look at the Analysis
component in our bug tracker [6].

- Implement an efficient relay-search database.  We have a web site for
searching relays by IP, nickname, or fingerprint [7], but it's really
slow.  The main problem is that the database originally was designed for
aggregating statistics about relays, not for searching relays.  I have
two ideas here: The first is to design a separate PostgreSQL database
[8] and go crazy with indexes, the second is to try out CouchDB for this
[9].  This task isn't really that Java-specific, except for the fact
that I'm using Java to import data and send queries.

If anything sounds interesting to you, please let me know.  I have more
information about these tasks and can help you get started.  Also look
at the research section of the metrics website [10] to learn more.

Best,
Karsten


[0] https://metrics.torproject.org/consensus-health.html

[1]
https://lists.torproject.org/pipermail/tor-consensus-health/2011-November/000026.html

[2] See the IRC bot nsa in #tor-bots on OFTC, e.g., "&lt; nsa&gt; or:
[consensus-health] The following directory authorities set conflicting
or invalid consensus parameters: ides bwauthbestratio=1 bwauthcircs=0
bwauthdescbw=1 bwauthkp=10000 bwauthpid=1 bwauthtd=0 bwauthti=0
bwauthtidecay=5000 cbtnummodes=3 refuseunknownexits=1"

[3]
https://gitweb.torproject.org/metrics-web.git/tree/HEAD:/src/org/torproject/chc

[4] https://metrics.torproject.org/data.html

[5] https://gitweb.torproject.org/metrics-tasks.git

[6]
https://trac.torproject.org/projects/tor/query?status=!closed&amp;component=Analysis&amp;order=priority

[7] https://metrics.torproject.org/relay-search.html

[8] https://trac.torproject.org/projects/tor/ticket/2922

[9] https://trac.torproject.org/projects/tor/ticket/4440

[10] https://metrics.torproject.org/research.html
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111123075757</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-11-23 07:57:57-0400</timestampReceived><subject>[tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

Hi all,

i got a WDTV Live
(http://support.wdc.com/product/install.asp?groupid=1003=en) that's
part of bigger family of consumer mediaplayer from Western Digital
(http://support.wdc.com/product/install.asp?level1=10=en).

It seems it can run Tor without any major issue.
There is a very nice hacked firmware community around WDTV users, that's
a very cheap hardware (retail price 70-80EUR).

What's about making a "promotional" campaign like for the Tor Cloud to
have people running Tor Relay "right on their TV" ?

I mean, the "hacked firmware" installation process of WDTV works that way:
- Plug an USB Key formatted FAT32 with 3 files (boot, kernel, image) on WDTV
- Poweron

So it may be possible to make a campaign where users are invited to "run
their tor relay" on their TV in 3 simple steps:
- Get a USB Key
- Load that files on it
- Plug to your WDTV
- Poweron your WDTV
You are now helping poor sirian, iranian and chinese censored people.

That way even the average fat guy sitting on his couch drinking beer and
eating wing chicken can support freedom of speech.

That kind of user can just "poweron" the WDTV and with his "remote
control" after seeing his favorite telefilm on paytv, can just "zap" to
see how his Tor Router is working: On TV!

This could be defined as the "very lazy Tor user" who doesn't even want
to use a computer, but just do TV zapping :P

So, the idea could be to do a custom hacked firmware of WDTV and a WDTV
Apps that you can "click" via remote control, seeing the statistics of
your Tor Relay.

# uname -a
Linux WDTVLIVE 2.6.22.19-19-4 #28 PREEMPT Mon Mar 22 20:08:14 CST 2010
mips GNU/Linux

# tor --version
Jan 01 15:41:37.533 [notice] Tor v0.2.2.32 (git-877e17749725ab88). This
is experimental software. Do not rely on it for strong anonymity.
(Running on Linux mips)
Tor version 0.2.2.32 (git-877e17749725ab88).

# free
              total         used         free       shared      buffers
  Mem:       199056       193664         5392            0        10832
 Swap:            0            0            0
Total:       199056       193664         5392

# cat /proc/cpuinfo
system type             : Sigma Designs TangoX
processor               : 0
cpu model               : MIPS 24K V7.12  FPU V0.0
Initial BogoMIPS        : 332.59
wait instruction        : yes
microsecond timers      : yes
tlb_entries             : 32
extra interrupt vector  : yes
hardware watchpoint     : yes
ASEs implemented        : mips16
shadow register sets    : 1
VCED exceptions         : not available
VCEI exceptions         : not available

System bus frequency    : 333000000 Hz
CPU frequency           : 499500000 Hz
DSP frequency           : 333000000 Hz


-naif
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111130091643</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-11-30 09:16:43-0400</timestampReceived><subject>[tor-dev] Periodic alert to outdated Tor operators?</subject><body>

Hi all,

should we send a periodic email reminder to all operators running
outdated Tor routers?

From a brief look at cached-descriptors:

grep 'Tor 0\.2\.0' /var/lib/tor/cached-descriptors | wc -l
111

grep 'Tor 0\.2\.1' /var/lib/tor/cached-descriptors | wc -l
5631

grep 'Tor 0\.2\.2' /var/lib/tor/cached-descriptors | wc -l
11572

grep 'Tor 0\.2\.3' /var/lib/tor/cached-descriptors | wc -l
1182

It would be nice to have an automatic system that spam periodically all
Tor operators that run outdated Tor routers.

-naif
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111130092007</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2011-11-30 09:20:07-0400</timestampReceived><subject>Re: [tor-dev] Periodic alert to outdated Tor operators?</subject><body>

----- Original Message -----
&gt; should we send a periodic email reminder to all operators running
&gt; outdated Tor routers?
AFAIK it should be already in place, isn't it?

-- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111123160208</emailId><senderName>Gisle Vanem</senderName><senderEmail>gvanem@broadpark.no</senderEmail><timestampReceived>2011-11-23 16:02:08-0400</timestampReceived><subject>[tor-dev] Failed test in UNICODE</subject><body>

I just built Tor and the test suite with UNICODE enabled (MS Visual-C v16
on Win-XP SP3). With some patching, the test-programs compiled and ran 
mostly fine. Except test_util_spawn_background_ok() failed for a reason I 
did't understand initially:

&gt; test --warn

util/spawn_background_ok: Nov 23 14:35:55.531 [warn] Failed to create child process 
test-child.exe: Systemet finner ikke angitt fil.

  FAIL test_util.c:1405: assert(process_handle.status == expected_status): -1 vs 1
  [spawn_background_ok FAILED]

util/spawn_background_partial_read: Nov 23 14:35:55.546 [warn] Failed to create child process 
test-child.exe: Systemet finner ikke angitt fil.

  FAIL test_util.c:1521: assert(process_handle.status == expected_status): -1 vs 1
  [spawn_background_partial_read FAILED]


("Systemet finner ikke angitt fil" -&gt; "System doesn't find specified file").

I think the reason is that CreateProcessW() is used in common/util.c.
The function is passed a 'const char *const filename'. Either we should 
always use CreateProcessA() or convert 'filename' using mbstowcs().
What do you think?

--gv
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111128052317</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-11-28 05:23:17-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

On 11/23/2011 02:57 AM, Fabio Pietrosanti (naif) wrote:
&gt; What's about making a "promotional" campaign like for the Tor Cloud to
&gt; have people running Tor Relay "right on their TV" ?

Great hacking on the WDTV!

I have been looking at getting Orbot (Tor on Android) running on Google
TV flavor of Android, and it seems pretty straightforward. I will
probably wait until the next gen of these come out, as right now, I know
no one who actually owns one of these devices.

+n
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111128100659</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2011-11-28 10:06:59-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

On 11/27/2011 09:23 PM, Nathan Freitas wrote:
&gt; On 11/23/2011 02:57 AM, Fabio Pietrosanti (naif) wrote:
&gt;&gt; What's about making a "promotional" campaign like for the Tor Cloud to
&gt;&gt; have people running Tor Relay "right on their TV" ?
&gt; 
&gt; Great hacking on the WDTV!
&gt; 
&gt; I have been looking at getting Orbot (Tor on Android) running on Google
&gt; TV flavor of Android, and it seems pretty straightforward. I will
&gt; probably wait until the next gen of these come out, as right now, I know
&gt; no one who actually owns one of these devices.
&gt; 

I have one.

All the best,
Jake
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111128123703</emailId><senderName>"Fabio Pietrosanti (naif)"</senderName><senderEmail>lists@infosecurity.ch</senderEmail><timestampReceived>2011-11-28 12:37:03-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

On 11/28/11 6:23 AM, Nathan Freitas wrote:
&gt; I have been looking at getting Orbot (Tor on Android) running on Google
&gt; TV flavor of Android, and it seems pretty straightforward. I will
&gt; probably wait until the next gen of these come out, as right now, I know
&gt; no one who actually owns one of these devices.

It would be also interesting to play around the Wii Linux system, to see
if Tor can run over Co-Linux on a Wii :-)

http://wiibrew.org/wiki/Wii-Linux
http://www.gc-linux.org/wiki/Wii:Hardware_Support

Think how cool it would be if all "Homebrew" wii users would be able to
plug an SD with a ready-made Linux/Tor image and click on it, loading
when Wii is not used (most of the time).

-naif
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111128124640</emailId><senderName>Marco Bonetti</senderName><senderEmail>sid77@slackware.it</senderEmail><timestampReceived>2011-11-28 12:46:40-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

----- Original Message -----
&gt; Think how cool it would be if all "Homebrew" wii users would be able
&gt; to plug an SD with a ready-made Linux/Tor image and click on it, loading
&gt; when Wii is not used (most of the time).
I thought about that two year a go or so, when collecting information for my talk on \
strange Tor ports. The main problem I see, here, is that the wii does not have a \
backgrounding system: the main application is loaded "in foreground" replacing the \
System Menu and that's all you can have running. Yes, sure, you can have some nice \
Vidalia-style infographics on it but that's all. Or you can run Linux on it but from \
booting the open source kernel onward it's not different then running an ordinary PPC \
Linux distribution.

One interesting hack, don't know if possible though, would be that of running \
something *behind* the System Menu.

-- 
Marco Bonetti
Tor research and other stuff: http://sid77.slackware.it/
Slackintosh Linux Project Developer: http://workaround.ch/
Linux-live for powerpc: http://workaround.ch/pub/rsync/mb/linux-live/

My GnuPG key id: 0x0B60BC5F
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111123120731</emailId><senderName>Shondoit</senderName><senderEmail>shondoit@gmail.com</senderEmail><timestampReceived>2011-11-23 12:07:31-0400</timestampReceived><subject>Re: [tor-dev] Tor glossary</subject><body>

[Attachment #2 (multipart/alternative)]


During translating last week it occurred to me that we do not have a
consistent translation for some common phrases.

I've set up a first draft of all common words that are used throughout the
various Tor projects.

Why I'm sending this to tor-dev is the following:
- You as developers know which phrases are important for a clear
communication of Tor's (and others) workings. I would very much like if you
can add to the lists the words that are essential to be consistently
translated. (as of writing this, I know I forgot to add 'Introduction
Point')
 - Sometimes different phrases are used throughout the applications.
Sometimes it's called an 'exit node' other times it's an 'exit relay'. It
would benefit consistency when devs use the glossary for common terms.
 - Translators sometimes don't know the definition of words, or the context
changes. A directory in the Tor context is different from a directory in an
OS context. I'm not sure what the best way is to go about doing this, but
we need definitions.

The last version of the list can be found in my github:
https://github.com/Shondoit/torglossary

If you have additions to the list, definitions, suggestions, you can either
email or clone/fork the repo and add it yourself.

Thanks in advance

[Attachment #5 (text/html)]

During translating last week it occurred to me that we do not have a consistent \
translation for some common phrases.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I've set up a first draft \
of all common words that are used throughout the various Tor projects.&lt;/div&gt;

&lt;div&gt;

&lt;br&gt;&lt;/div&gt;&lt;div&gt;Why I'm sending this to tor-dev is the following:&lt;/div&gt;&lt;div&gt;- You \
as developers know which phrases are important for a clear communication of Tor's \
(and others) workings. I would very much like if you can add to the lists the words \
that are essential to be consistently translated. (as of writing this, I know I \
forgot to add 'Introduction Point')&lt;/div&gt;

&lt;div&gt;

- Sometimes different phrases are used throughout the applications. Sometimes \
it's called an 'exit node' other times it's an 'exit relay'. \
It would benefit consistency when devs use the glossary for common terms.&lt;/div&gt;

&lt;div&gt;

- Translators sometimes don't know the definition of words, or the context \
changes. A directory in the Tor context is different from a directory in an OS \
context. I'm not sure what the best way is to go about doing this, but we need \
definitions.&lt;/div&gt;

&lt;div&gt;

&lt;br&gt;&lt;/div&gt;&lt;div&gt;The last version of the list can be found in my github:&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://github.com/Shondoit/torglossary" \
target="_blank"&gt;https://github.com/Shondoit/torglossary&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If \
you have additions to the list, definitions, suggestions, you can either email or \
clone/fork the repo and add it yourself.&lt;/div&gt;

&lt;div&gt;

&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks in advance&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20111124053630</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2011-11-24 05:36:30-0400</timestampReceived><subject>[tor-dev] Bug triage status</subject><body>

Hi, Roger!

As discussed, I did some Tor bug triage tonight.  Here's what I did:

 * I made a new "Tor: very long term" (formerly "Tor: distant future")
milestone for stuff too long-term to be in "Tor: unspecified."  Now we
will no longer have "unspecified" mean "maybe never" to some of us and
"I honestly don't know" to others.
 * I made a new "tor: 0.2.4.x" milestone
 * I went through every ticket in "post 0.2.3.x" (there were like 3 or
4) and reassigned them someplace better.
 * I went through every ticket without a component.
 * I went through every ticket in Tor: unspecified to see if it
belonged there.  Surprisingly, very few of them belonged in "Tor: very
long term".
 * I went through every ticket without a milestone that was assigned
to one of the core Tor components (that is, Tor Bridge, Tor Hidden
Service, Tor Directory Authority, Tor Client, Tor Relay).  Now they
all have milestones; some few of them also have comments, or are
closed.

Still to do, possibly by me, possibly not:

  * Triage all 233 open 0.2.3.x tickets.  The ones that are
feature-like, big, and not planned to get done by nov 30 should get
punted to "unspecified" or 0.2.4.x or "very long term."  The ones that
are feature-like and small should get ordinary triage. The ones that
are bugs should get priorities assigned, or marked as deferrable, or
such.
  * Triage all 23 open 0.2.2.x-final tickets.  Some of these are bugs
that we believe *should* have their fixes applied on 0.2.2; some are
merely bugs that *exist* in 0.2.2, but which might not be important
enough to alter a stable release.
  * Triage all core-Tor bugs in a milestone other than 0.2.2.x-final,
0.2.3.x-final, 0.2.4.x-final, unspecified, or very long term.

Next steps for Roger here:

  * Go over the "Unspecified" stuff I've triaged to see if you agree.
It should be cleaner than it was before,

happy Thanksgiving,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111128144233</emailId><senderName>Nathan Freitas</senderName><senderEmail>nathan@freitas.net</senderEmail><timestampReceived>2011-11-28 14:42:33-0400</timestampReceived><subject>Re: [tor-dev] Tor on TV (hemm, on WDTV!)</subject><body>

On 11/28/2011 05:06 AM, Jacob Appelbaum wrote:
&gt; I have one

I meant civilians. Good to know though... if someone can get one donated
to Guardian Project, we'll be happy to do the port! :)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111130095548</emailId><senderName>"Runa A. Sandvik"</senderName><senderEmail>runa.sandvik@gmail.com</senderEmail><timestampReceived>2011-11-30 09:55:48-0400</timestampReceived><subject>Re: [tor-dev] Periodic alert to outdated Tor operators?</subject><body>

On Wed, Nov 30, 2011 at 9:20 AM, Marco Bonetti &lt;sid77@slackware.it&gt; wrote:
&gt; ----- Original Message -----
&gt;&gt; should we send a periodic email reminder to all operators running
&gt;&gt; outdated Tor routers?
&gt; AFAIK it should be already in place, isn't it?

I think that's only if you've signed up for https://weather.torproject.org/.

-- 
Runa A. Sandvik
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111130182257</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@alum.mit.edu</senderEmail><timestampReceived>2011-11-30 18:22:57-0400</timestampReceived><subject>Re: [tor-dev] Failed test in UNICODE</subject><body>

On Wed, Nov 23, 2011 at 11:02 AM, Gisle Vanem &lt;gvanem@broadpark.no&gt; wrote:
[...]
&gt; ("Systemet finner ikke angitt fil" -&gt; "System doesn't find specified file").
&gt;
&gt; I think the reason is that CreateProcessW() is used in common/util.c.
&gt; The function is passed a 'const char *const filename'. Either we should
&gt; always use CreateProcessA() or convert 'filename' using mbstowcs().
&gt; What do you think?

So, in the rest of util.c it looks like we do a conditional mbstowcs()
before calling a Windows function that expects a TCHAR.   So we should
either do that, or have a wrapper function that does a conditional
mbstowcs or strlcpy depending on whether UNICODE is defined.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20111130223117</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2011-11-30 22:31:17-0400</timestampReceived><subject>[tor-dev] Automatically retrieve and store information about bridges</subject><body>

Filename: xxx-store-bridge-information.txt
Title: Automatically retrieve and store information about bridges
Author: Sebastian Hahn
Created: 16-Nov-2011
Status: Open
Target: 0.2.[45].x

Overview:
Currently, tor already stores some information about the bridges it is
configured to use locally, but doesn't make great use of the stored
data. This data is the Tor configuration information about the bridge
(IP address, port, and optionally fingerprint) and the bridge descriptor
which gets stored along with the other descriptors a Tor client fetches,
as well as an "EntryGuard" line in the state file. That line includes
the Tor version we used to add the bridge, and a slightly randomized
timestamp (up to a month in the past of the real date). The descriptor
data also includes some more accurate timestamps about when the
descriptor was fetched.

The information we give out about bridges via bridgedb currently only
includes the IP address and port, because giving out the fingerprint as
well might mean that Tor clients make direct connections to the bridge
authority, since we didn't design Tor's UpdateBridgesFromAuthority
behaviour correctly.

Motivation:

The only way to let Tor know about a change affecting the bridge (IP
address or port change) is to either ask the bridge authority directly,
or reconfigure Tor. The former requires making a non-anonymized direct
connection to the bridge authority Tonga and asking it for the current
descriptor of the bridge with a given fingerprint - this is unsafe and
also requires prior knowledge of the fingerprint. The latter requires
user intervention, first to learn that there was an update and second to
actually teach Tor about the change.

This is way too complicated for most users, and should be unnecessary
while the user has at least one bridge that remains working: Tonga can
give out bridge descriptors when asked for the descriptor for a certain
fingerprint, and Tor clients learn the fingerprint either from their
torrc file or from the first connection they make to a bridge.

For some users, however, this option is not what they want: They might
use private bridges or have special security concerns, which would make
them want to connect to the IP addresses specified in their
configuration only, and not tell Tonga about the set of bridges they
know about, even through a Tor circuit. Also see
https://blog.torproject.org/blog/different-ways-use-bridge for more
information about the different types of bridge users.

Design:

Tor should provide a new configuration option that allows bridge users
to indicate that they wish to contact Tonga anonymously and learn about
updates for the bridges that they know about, but can't currently reach.
Once those updates have been received, the clients would then hold on to
the new information in their state file, and use it across restarts for
connection attempts.

The option UpdateBridgesFromAuthority should be removed or recycled for
this purpose, as it is currently dangerous to set (it makes direct
connections to the bridge authority, thus leaking that a user is about
to use bridges). Recycling the option is probably the better choice,
because current users of the option get a surprising and never useful
behaviour. On the other hand, users who downgrade their Tors might get
the old behaviour by accident.

If configured with this option, tor would make an anonymized connection
to Tonga to ask for the descriptors of bridges that it cannot currently
connect to, once every few hours. Making more frequent requests would
likely not help, as bridge information doesn't typically change that
frequently, and may overload Tonga.

This information needs to be stored in the state file:

- An exact copy of the Bridge stanza in the torrc file, so that tor can
  detect when the bridge is unconfigured/the configuration is changed

- The IP address, port, and fingerprint we last used when making a
  successful connection to the bridge, if this differs from/supplements
  the configured data.

- The IP address, port, and fingerprint we learned from the bridge
  authority, if this differs from both the configured data and the data
  we used for the last successful connection.

We don't store more data in the state file to avoid leaking too much if
the state file falls into the hands of an adversary.

Security implications:

Storing sensitive data on disk is risky when the computer one uses gets
into the wrong hands, and state file entries can be used to identify
times the user was online. This is already a problem for the Bridge
lines in a user's configuration file, but by storing more information
about bridges some timings can be deduced.

Another risk is that this allows long-term tracking of users when the
set of bridges a user knows about is known to the attacker, and the set
is unique.  This is not very hard to achieve for bridgedb, as users
typically make requests to it non-anomymized and bridgedb can
selectively pick bridges to report. By combining the data about
descriptor fetches on Tonga and this fingerprint, a usage pattern can be
established. Also, bridgedb could give out a made-up fingerprint to a
user that requested bridges, thus easily creating a unique set.

Users of private bridges should not set this option, as it will leak the
fingerprints of their bridges to Tonga. This is not a huge concern, as
Tonga doesn't know about those descriptors, but private bridge users
will likely want to avoid leaking the existence of their bridge. We
might want to figure out a way to indicate that a bridge is private on
the Bridge line in the configuration, so fetching the descriptor from
Tonga is disabled for those automatically. This warrants more discussion
to find a solution that doesn't require bridge users to understand the
trade-offs of setting a configuration option.

One idea is to indicate that a bridge is private by a special flag in
its bridge descriptor, so clients can avoid leaking those to the bridge
authority automatically. Also, Bridge lines for private bridges
shouldn't include the fingerprint so that users don't accidentally leak
the fingerprint to the bridge authority before they have talked to the
bridge.

Specification:

No change/addition to the current specification is necessary, as the
data that gets stored at clients is not covered by the specification.
This document is supposed to serve as a basis for discussion and to
provide hints for implementors.

Compatibility:

Tonga is already set up to send out descriptors requested by clients, so
the bridge authority side doesn't need any changes. The new
configuration options governing the behaviour of Tor would be
incompatible with previous versions, so the torrc needs to be adapted.
The state file changes should not affect older versions.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email></emails>