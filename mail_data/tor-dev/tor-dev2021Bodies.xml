<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20211221130431</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-12-21 13:04:31-0400</timestampReceived><subject>Re: [tor-dev] the consequences of deprecating debian alpha repos with every new major branch</subject><body>

looks like someone decided to solve this.

apparently there are alpha release repos available now that do not contain branch names

https://deb.torproject.org/torproject.org/dists/:
&gt; [DIR] tor-experimental-bookworm/    2021-12-20 22:21    -   
&gt; [DIR] tor-experimental-bullseye/    2021-12-20 22:21    -   
&gt; [DIR] tor-experimental-buster/      2021-12-20 22:21    -   
&gt; [DIR] tor-experimental-focal/       2021-12-20 22:21    -   
&gt; [...]

   

thank you!
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211212192143</emailId><senderName>"Ali Clark"</senderName><senderEmail>ali@aliclark.net</senderEmail><timestampReceived>2021-12-12 19:21:43-0400</timestampReceived><subject>Re: [tor-dev] The case for Tor-over-QUIC</subject><body>

[Attachment #2 (multipart/alternative)]


Sections 3 and 6 of the Quux paper have some relevant discussion [1]

&gt; Unfortunately, it appears that the Quux QUIC paper studied QUIC at the
&gt; wrong position - between relays, and the QuTor implementation is
&gt; unclear. This means that it may still be an open question as to if
&gt; QUIC's congestion control algorithms will behave optimally in a
&gt; Tor-like network under heavy load.

  As Reardon and Goldberg noted in concluding remarks, approaches other
  than hop-by-hop will incur an extra cost for retransmissions, since
  these must be rerouted through a larger part of the network [RG09].
 
  As Tschorsch and Scheuermann discuss [TS12], due to the longer RTT of
  TCP connections, end-to-end approaches will also take longer to "ramp
  up" through slow start and up to a steady state.
 
  Both of these factors (not to mention increased security risk of
  information leakage [DM09]) suggest that hop-by-hop designs are likely
  to yield beer results. In fact, the hop-by-hop approach may be viewed as
  an instance of the Split TCP Performance-Enhancing Proxy design, whereby
  arbitrary TCP connections are split in two to negate the issues noted
  above.

&gt; Unfortunately, the Quux implementation appears to use QUIC at a
&gt; suboptimal position -- they replace Tor's TLS connections with QUIC,
&gt; and use QUIC streams in place of Tor's circuit ID -- but only between
&gt; relays. This means that it does not benefit from QUIC's end-to-end
&gt; congestion control for the entire path of the circuit. Such a design
&gt; will not solve the queuing and associated OOM problems at Tor relays,
&gt; since relays would be unable to drop cells to signal backpressure to
&gt; endpoints. Drops will instead block every circuit on a connection
&gt; between relays, and even then, due to end-to-end reliability, relays
&gt; will still need to queue without bound, subject to Tor's current (and
&gt; inadequate) flow control.

  A fully QUIC relay path (with slight modication to fix a limit on
  internal buffer sizes) would allow end-to-end backpressure to be used
  from the client application TCP stream up to the exit TCP stream.
  Leaving aside Tor's inbound rate limit mechanism but retaining the
  global outbound limit, this design would allow max-min fairness to be
  achieved in the network, as outlined by Tschorsch and Scheuermann
  [TS11].

  ...

  Once implemented however, backpressure would allow Tor to adopt a
  signicantly improved internal design. In such a design, a Tor relay
  could read a single cell from one QUIC stream's read buffer, onion crypt
  it, and immediately place it onto the write buffer of the next stream in
  the circuit. This process would be able to operate at the granularity of
  a single cell because the read and write operations for QUIC are very
  cheap user-space function calls and not syscalls as for host TCP.

  The schedule of this action would be governed by the existing EWMA
  scheduler for circuits that have both a readable stream and a writeable
  stream (and as allowed by a global outgoing token bucket), allowing
  optimal quality of service for circuits.

  It's expected that backpressure implemented in this way will yield
  signicant performance and fairness gains on top of the performance
  improvement found in this thesis.

One issue for Quux was that it used the Chromium demo QUIC server code as the
basis for its implementation, which was fine for performance research but not
such a good choice for Tor's networking stack.

Several Rust implementations have been released with server-side (not just
client-side) usage, so I expect that to be much less of an issue today.

io_uring is also a significant development since Quux was developed, as
it can reduce the performance hit for host-TCP syscalls, or for using
recvmsg instead of recvmmsg with QUIC if the implementation makes
it difficult to use recvmmsg on the listener side.

[1] https://www.benthamsgaze.org/wp-content/uploads/2016/09/393617_Alastair_Clark_aclark_2360661_860598830.pdf


The following paper has in-depth discussion, but I don't have a copy to
hand unfortunately:

Ali Clark. Tor network performance — transport and flow control.  Technical report, \
University College London, April 2016


[Attachment #5 (text/html)]

&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;style \
type="text/css"&gt;p.MsoNormal,p.MsoNoSpacing{margin:0}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;Sections \
3 and 6 of the Quux paper have some relevant discussion \
[1]&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; Unfortunately, it appears that the Quux QUIC \
paper studied QUIC at the&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; wrong position - between relays, and the \
QuTor implementation is&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; unclear. This means that it may still be \
an open question as to if&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; QUIC's congestion control algorithms \
will behave optimally in a&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; Tor-like network under heavy \
load.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  As Reardon and Goldberg noted in concluding \
remarks, approaches other&lt;br&gt;&lt;/div&gt;&lt;div&gt;  than hop-by-hop will incur an extra \
cost for retransmissions, since&lt;br&gt;&lt;/div&gt;&lt;div&gt;  these must be rerouted through a \
larger part of the network [RG09].&lt;br&gt;&lt;/div&gt;&lt;div&gt; &lt;br&gt;&lt;/div&gt;&lt;div&gt;  As \
Tschorsch and Scheuermann discuss [TS12], due to the longer RTT \
of&lt;br&gt;&lt;/div&gt;&lt;div&gt;  TCP connections, end-to-end approaches will also take longer \
to "ramp&lt;br&gt;&lt;/div&gt;&lt;div&gt;  up" through slow start and up to a steady \
state.&lt;br&gt;&lt;/div&gt;&lt;div&gt; &lt;br&gt;&lt;/div&gt;&lt;div&gt;  Both of these factors (not to \
mention increased security risk of&lt;br&gt;&lt;/div&gt;&lt;div&gt;  information leakage [DM09]) \
suggest that hop-by-hop designs are likely&lt;br&gt;&lt;/div&gt;&lt;div&gt;  to yield beer \
results. In fact, the hop-by-hop approach may be viewed as&lt;br&gt;&lt;/div&gt;&lt;div&gt;  an \
instance of the Split TCP Performance-Enhancing Proxy design, \
whereby&lt;br&gt;&lt;/div&gt;&lt;div&gt;  arbitrary TCP connections are split in two to negate the \
issues noted&lt;br&gt;&lt;/div&gt;&lt;div&gt;  above.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; \
Unfortunately, the Quux implementation appears to use QUIC at a&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; \
suboptimal position -- they replace Tor's TLS connections with \
QUIC,&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; and use QUIC streams in place of Tor's circuit ID -- but \
only between&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; relays. This means that it does not benefit from \
QUIC's end-to-end&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; congestion control for the entire path of the \
circuit. Such a design&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; will not solve the queuing and associated \
OOM problems at Tor relays,&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; since relays would be unable to drop \
cells to signal backpressure to&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; endpoints. Drops will instead \
block every circuit on a connection&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; between relays, and even then, \
due to end-to-end reliability, relays&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; will still need to queue \
without bound, subject to Tor's current (and&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt; inadequate) flow \
control.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  A fully QUIC relay path (with slight \
modication to fix a limit on&lt;br&gt;&lt;/div&gt;&lt;div&gt;  internal buffer sizes) would allow \
end-to-end backpressure to be used&lt;br&gt;&lt;/div&gt;&lt;div&gt;  from the client application \
TCP stream up to the exit TCP stream.&lt;br&gt;&lt;/div&gt;&lt;div&gt;  Leaving aside Tor's \
inbound rate limit mechanism but retaining the&lt;br&gt;&lt;/div&gt;&lt;div&gt;  global outbound \
limit, this design would allow max-min fairness to be&lt;br&gt;&lt;/div&gt;&lt;div&gt;  achieved \
in the network, as outlined by Tschorsch and Scheuermann&lt;br&gt;&lt;/div&gt;&lt;div&gt;  \
[TS11].&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  ...&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  \
Once implemented however, backpressure would allow Tor to adopt \
a&lt;br&gt;&lt;/div&gt;&lt;div&gt;  signicantly improved internal design. In such a design, a Tor \
relay&lt;br&gt;&lt;/div&gt;&lt;div&gt;  could read a single cell from one QUIC stream's read \
buffer, onion crypt&lt;br&gt;&lt;/div&gt;&lt;div&gt;  it, and immediately place it onto the write \
buffer of the next stream in&lt;br&gt;&lt;/div&gt;&lt;div&gt;  the circuit. This process would be \
able to operate at the granularity of&lt;br&gt;&lt;/div&gt;&lt;div&gt;  a single cell because the \
read and write operations for QUIC are very&lt;br&gt;&lt;/div&gt;&lt;div&gt;  cheap user-space \
function calls and not syscalls as for host TCP.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  \
The schedule of this action would be governed by the existing \
EWMA&lt;br&gt;&lt;/div&gt;&lt;div&gt;  scheduler for circuits that have both a readable stream and \
a writeable&lt;br&gt;&lt;/div&gt;&lt;div&gt;  stream (and as allowed by a global outgoing token \
bucket), allowing&lt;br&gt;&lt;/div&gt;&lt;div&gt;  optimal quality of service for \
circuits.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  It's expected that backpressure \
implemented in this way will yield&lt;br&gt;&lt;/div&gt;&lt;div&gt;  signicant performance and \
fairness gains on top of the performance&lt;br&gt;&lt;/div&gt;&lt;div&gt;  improvement found in \
this thesis.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;One issue for Quux was that it used the \
Chromium demo QUIC server code as the&lt;br&gt;&lt;/div&gt;&lt;div&gt;basis for its implementation, \
which was fine for performance research but not&lt;br&gt;&lt;/div&gt;&lt;div&gt;such a good choice for \
Tor's networking stack.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Several Rust implementations \
have been released with server-side (not just&lt;br&gt;&lt;/div&gt;&lt;div&gt;client-side) usage, so I \
expect that to be much less of an issue today.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;io_uring \
is also a significant development since Quux was developed, as&lt;br&gt;&lt;/div&gt;&lt;div&gt;it can \
reduce the performance hit for host-TCP syscalls, or for using&lt;br&gt;&lt;/div&gt;&lt;div&gt;recvmsg \
instead of recvmmsg with QUIC if the implementation makes&lt;br&gt;&lt;/div&gt;&lt;div&gt;it difficult \
to use recvmmsg on the listener side.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;[1] &lt;a \
href="https://www.benthamsgaze.org/wp-content/uploads/2016/09/393617_Alastair_Clark_ac \
lark_2360661_860598830.pdf"&gt;https://www.benthamsgaze.org/wp-content/uploads/2016/09/39 \
3617_Alastair_Clark_aclark_2360661_860598830.pdf&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The \
following paper has in-depth discussion, but I don't have a copy \
to&lt;br&gt;&lt;/div&gt;&lt;div&gt;hand unfortunately:&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Ali Clark. Tor \
network performance — transport and flow control.  Technical report, \
University College London, April 2016&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210328174446</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2021-03-28 17:44:46-0400</timestampReceived><subject>Re: [tor-dev] A new idea for email encryption on tor</subject><body>

[Attachment #2 (multipart/alternative)]


Well, you do. It is stored on your local machine only.
--Keifer


On Wed, Dec 2, 2020 at 1:10 PM Wisdom With Rahul &lt;rahulbhatia172@gmail.com&gt;
wrote:

&gt; This idea is interesting but who owns all the keys?
&gt;
&gt; Thanks and regards!
&gt;
&gt;
&gt;
&gt;
&gt; On Fri 13 Nov, 2020, 6:49 AM Keifer Bly, &lt;keifer.bly@gmail.com&gt; wrote:
&gt;
&gt;&gt; Well, the mechanism is that it overwrites the key ever time, so each
&gt;&gt; message has its own unique key, also the receiver needs to verify the key
&gt;&gt; file with the built in tool to be able to use it. So an attacker does not
&gt;&gt; know this the only way to get this information is from the person that
&gt;&gt; created the message as the need when the OS originally generated the
&gt;&gt; message, not when it was uploaded as an attachment somewhere. That's what I
&gt;&gt; was thinking. I will look into the communities suggested, thanks very much.
&gt;&gt; --Keifer
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Nov 12, 2020 at 1:27 PM Santiago Torres-Arias &lt;
&gt;&gt; santiago@archlinux.org&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer Bly wrote:
&gt;&gt;&gt; &gt; Hi there,
&gt;&gt;&gt;
&gt;&gt;&gt; Hello,
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; So I have a new email encryption system which requires that the user
&gt;&gt;&gt; has
&gt;&gt;&gt; &gt; the specific key file generated for a message rather than the password,
&gt;&gt;&gt; &gt; specifically this software generates a unique key file for a specific
&gt;&gt;&gt; &gt; message every time a message is created. The user then enters the date
&gt;&gt;&gt; and
&gt;&gt;&gt; &gt; time the message was created. Without the original key file the message
&gt;&gt;&gt; &gt; can't be opened;
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; https://www.youtube.com/watch?v=R0W7OVdNrOA
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; Here is a video showing the software. I've built it for Windows and
&gt;&gt;&gt; Mac OS.
&gt;&gt;&gt; &gt; I was wondering if this could be implemented in tor. I think it would
&gt;&gt;&gt; be an
&gt;&gt;&gt; &gt; interesting idea for a tor based email system to make the messages
&gt;&gt;&gt; &gt; unrecoverable after use.
&gt;&gt;&gt;
&gt;&gt;&gt; I'm not a tor-dev, so I can't comment on the interest, but it appears to
&gt;&gt;&gt; me that the value added of this idea (basically, using time to seed a
&gt;&gt;&gt; PRF/KDF) is very little. All in all, using time to seed keys is not the
&gt;&gt;&gt; best idea. It also seems to be on top of PGP, so I'm pretty convinced
&gt;&gt;&gt; this doesn't provide perfect forward-secrecy unless you're layering any
&gt;&gt;&gt; sort of session key ratcheting mechanism yourself.
&gt;&gt;&gt;
&gt;&gt;&gt; I think the goal is laudable, but I suggest getting a little bit more
&gt;&gt;&gt; involved in cryptography engineering communities to see learn, develop
&gt;&gt;&gt; and eventually help change the status quo.
&gt;&gt;&gt;
&gt;&gt;&gt; Cheers!
&gt;&gt;&gt; -S
&gt;&gt;&gt; _______________________________________________
&gt;&gt;&gt; tor-dev mailing list
&gt;&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;&gt;
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Well, you  do. It is stored on your local machine only.&lt;br \
clear="all"&gt;&lt;div&gt;&lt;div dir="ltr" class="gmail_signature" \
data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Wed, Dec 2, 2020 at 1:10 PM Wisdom With Rahul &lt;&lt;a \
href="mailto:rahulbhatia172@gmail.com"&gt;rahulbhatia172@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="auto"&gt;This \
idea is interesting but who owns all the keys?&lt;br&gt;&lt;br&gt;&lt;div&gt;Thanks and \
regards!&lt;br&gt;&lt;br&gt;&lt;br&gt;       &lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Fri 13 Nov, 2020, 6:49 AM Keifer Bly, &lt;&lt;a \
href="mailto:keifer.bly@gmail.com" target="_blank"&gt;keifer.bly@gmail.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div dir="ltr"&gt;Well, \
the mechanism  is that it  overwrites the key ever time, so each message has its own \
unique key, also the receiver  needs to verify the key file with the built in tool to \
be able to use it. So an attacker does not know this the only way to get this \
information is from the person that created the message as the need when the OS \
originally generated the message, not when it was uploaded as an attachment \
somewhere. That's what I was thinking. I will look into the communities \
suggested, thanks very much. --Keifer  &lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Thu, Nov 12, 2020 at 1:27 PM \
Santiago Torres-Arias &lt;&lt;a href="mailto:santiago@archlinux.org" rel="noreferrer" \
target="_blank"&gt;santiago@archlinux.org&lt;/a&gt;&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;On Thu, Nov 12, 2020 at 11:19:44AM -0800, Keifer \
Bly wrote:&lt;br&gt; &gt; Hi there,&lt;br&gt;
&lt;br&gt;
Hello,&lt;br&gt;
&lt;br&gt;
&gt; So I have a new email encryption system which requires that the user has&lt;br&gt;
&gt; the specific key file generated for a message rather than the password,&lt;br&gt;
&gt; specifically this software generates a unique key file for a specific&lt;br&gt;
&gt; message every time a message is created. The user then enters the date and&lt;br&gt;
&gt; time the message was created. Without the original key file the message&lt;br&gt;
&gt; can't be opened;&lt;br&gt;
&gt;&lt;br&gt;
&gt; &lt;a href="https://www.youtube.com/watch?v=R0W7OVdNrOA" rel="noreferrer \
noreferrer" target="_blank"&gt;https://www.youtube.com/watch?v=R0W7OVdNrOA&lt;/a&gt;&lt;br&gt; \
&gt;&lt;br&gt; &gt; Here is a video showing the software. I've built it for Windows and \
Mac OS.&lt;br&gt; &gt; I was wondering if this could be implemented in tor. I think it \
would be an&lt;br&gt; &gt; interesting idea for a tor based email system to make the \
messages&lt;br&gt; &gt; unrecoverable after use.&lt;br&gt;
&lt;br&gt;
I'm not a tor-dev, so I can't comment on the interest, but it appears to&lt;br&gt;
me that the value added of this idea (basically, using time to seed a&lt;br&gt;
PRF/KDF) is very little. All in all, using time to seed keys is not the&lt;br&gt;
best idea. It also seems to be on top of PGP, so I'm pretty convinced&lt;br&gt;
this doesn't provide perfect forward-secrecy unless you're layering any&lt;br&gt;
sort of session key ratcheting mechanism yourself.&lt;br&gt;
&lt;br&gt;
I think the goal is laudable, but I suggest getting a little bit more&lt;br&gt;
involved in cryptography engineering communities to see learn, develop&lt;br&gt;
and eventually help change the status quo.&lt;br&gt;
&lt;br&gt;
Cheers!&lt;br&gt;
-S&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" rel="noreferrer" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" rel="noreferrer" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211010211229</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 21:12:29-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt; On Tue, Aug 4, 2020 at 6:41 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;&gt;
&gt;&gt; nusenu:
&gt;&gt;&gt; I'll wait until you (Tor developers) decided on the final naming and format
&gt;&gt;
&gt;&gt; Is there any interest to move this topic forward to come to some decision
&gt;&gt; in the near future? (before the end of the month)
&gt; 
&gt; I don't think that'd be too hard.
&gt; 
&gt;&gt; Here is a short summary of what opinions I observed for this topic (naming and format
&gt;&gt; for Ed25519 identities) so far:
&gt;&gt;
&gt;&gt; Naming proposals for relay Ed25519 identities:
&gt;&gt; ------------------------------------
&gt;&gt;
&gt;&gt; 'v2 fingerprints' (Damian)
&gt;&gt;
&gt;&gt; "ed25519 identity" or even just "identity" (nickm)
&gt;&gt;
&gt;&gt;
&gt;&gt; Output format the Ed25519 relay IDs:
&gt;&gt; ------------------------------------
&gt;&gt;
&gt;&gt; base64 - 43 characters long (nickm)
&gt;&gt;    this is problematic due to the "/" sign (Damian)
&gt;&gt; hex - 64 characters long (Damian)
&gt;&gt;    "/" is problematic for DirPort urls, GETINFO commands, etc (Damian)
&gt;&gt;      isn't there urlencoding for URLs? (nusenu)
&gt;&gt; base64urlsafe - 43 characters long (nusenu)
&gt;&gt;
&gt;&gt; I hope we can agree to use the same format in all places.
&gt;&gt;
&gt;&gt; How does the decision process looks like in general in the Tor Project?
&gt; 
&gt; I think right now Tor uses unpadded base64 in most internal formats,
&gt; but it doesn't actually use those in the user interface anywhere, so
&gt; we could just use base64urlsafe (per rfc4648 section 5) for the user
&gt; interface.
&gt; 
&gt; I would be fine with standardizing that for our API, but I'd want to
&gt; write a proposal for it first.  It wouldn't have to be long.  We'd
&gt; want to describe other places where we currently use regular base64
&gt; for 256-bit keys, and say whether we should/shouldn't accept and emit
&gt; url-safe identifiers there instead.
&gt; 
&gt; We should specify that there are no spaces, that the padding "="
&gt; characters are removed, and that even though the format as given can
&gt; handle 43*6==258 bits, the last two bits must be set to 0, since these
&gt; are only 256-bit identifiers.
&gt; 
&gt; We should also _probably_ specify some canonical encoding for a pair of keys.
&gt; 

I've come to the conclusion that since people are used so much to the fact
that relay ID's (RSA) never were case sensitive, ed25519 should not
be case sensitive either.

So I'd propose to use base32 without padding.
That would make it 52 chars long.

Any opinions?

kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211010212627</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2021-10-10 21:26:27-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

On Sun, Oct 10, 2021 at 5:13 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; &gt; On Tue, Aug 4, 2020 at 6:41 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; nusenu:
&gt; &gt;&gt;&gt; I'll wait until you (Tor developers) decided on the final naming and format
&gt; &gt;&gt;
&gt; &gt;&gt; Is there any interest to move this topic forward to come to some decision
&gt; &gt;&gt; in the near future? (before the end of the month)
&gt; &gt;
&gt; &gt; I don't think that'd be too hard.
&gt; &gt;
&gt; &gt;&gt; Here is a short summary of what opinions I observed for this topic (naming and format
&gt; &gt;&gt; for Ed25519 identities) so far:
&gt; &gt;&gt;
&gt; &gt;&gt; Naming proposals for relay Ed25519 identities:
&gt; &gt;&gt; ------------------------------------
&gt; &gt;&gt;
&gt; &gt;&gt; 'v2 fingerprints' (Damian)
&gt; &gt;&gt;
&gt; &gt;&gt; "ed25519 identity" or even just "identity" (nickm)
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; Output format the Ed25519 relay IDs:
&gt; &gt;&gt; ------------------------------------
&gt; &gt;&gt;
&gt; &gt;&gt; base64 - 43 characters long (nickm)
&gt; &gt;&gt;    this is problematic due to the "/" sign (Damian)
&gt; &gt;&gt; hex - 64 characters long (Damian)
&gt; &gt;&gt;    "/" is problematic for DirPort urls, GETINFO commands, etc (Damian)
&gt; &gt;&gt;      isn't there urlencoding for URLs? (nusenu)
&gt; &gt;&gt; base64urlsafe - 43 characters long (nusenu)
&gt; &gt;&gt;
&gt; &gt;&gt; I hope we can agree to use the same format in all places.
&gt; &gt;&gt;
&gt; &gt;&gt; How does the decision process looks like in general in the Tor Project?
&gt; &gt;
&gt; &gt; I think right now Tor uses unpadded base64 in most internal formats,
&gt; &gt; but it doesn't actually use those in the user interface anywhere, so
&gt; &gt; we could just use base64urlsafe (per rfc4648 section 5) for the user
&gt; &gt; interface.
&gt; &gt;
&gt; &gt; I would be fine with standardizing that for our API, but I'd want to
&gt; &gt; write a proposal for it first.  It wouldn't have to be long.  We'd
&gt; &gt; want to describe other places where we currently use regular base64
&gt; &gt; for 256-bit keys, and say whether we should/shouldn't accept and emit
&gt; &gt; url-safe identifiers there instead.
&gt; &gt;
&gt; &gt; We should specify that there are no spaces, that the padding "="
&gt; &gt; characters are removed, and that even though the format as given can
&gt; &gt; handle 43*6==258 bits, the last two bits must be set to 0, since these
&gt; &gt; are only 256-bit identifiers.
&gt; &gt;
&gt; &gt; We should also _probably_ specify some canonical encoding for a pair of keys.
&gt; &gt;
&gt;
&gt; I've come to the conclusion that since people are used so much to the fact
&gt; that relay ID's (RSA) never were case sensitive, ed25519 should not
&gt; be case sensitive either.
&gt;
&gt; So I'd propose to use base32 without padding.
&gt; That would make it 52 chars long.
&gt;
&gt; Any opinions?
&gt;

Hm.  Every time we've displayed Ed25519 fingerprints so far, we've
used base64.  I'm not sure that changing it will actually save more
confusion than it causes.

yrs,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211010213244</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 21:32:44-0400</timestampReceived><subject>Re: [tor-dev] How do Ed25519 relay IDs look like?</subject><body>

&gt;&gt; Any opinions?
&gt;&gt;
&gt; 
&gt; Hm.  Every time we've displayed Ed25519 fingerprints so far, we've
&gt; used base64.  I'm not sure that changing it will actually save more
&gt; confusion than it causes.

thanks for the prompt reply.

Hm, ok I guess then we have already reached the point of no return
where it is too late to come to a common format that can be used everywhere
even in places where "/" is not supported.

kind regards,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210802104201</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-08-02 10:42:01-0400</timestampReceived><subject>Re: [tor-dev] A proposal to phase out CAPTCHAs for BridgeDB</subject><body>

On Thu, Jul 29, 2021 at 04:46:37PM -0400, Cecylia Bocovich wrote:
&gt; I would like to propose that we remove the CAPTCHAs from BridgeDB
&gt; entirely, but I'd like to know whether there is research out there
&gt; *specifically that fits with the anti-censorship context* showing that
&gt; these CAPTCHAs are actually doing useful work to prevent Bridge
&gt; enumeration. But, even if the CAPTCHAs are preventing a small number of
&gt; censors from enumerating more bridges, is the usability impact worth
&gt; what marginal benefit we get from it?

Right. As another data point, the original bridge distribution design
did not intend for the https bridge bucket to use captchas:
https://svn-archive.torproject.org/svn/projects/design-paper/blocking.html#tth_sEc7.4
The original plan around captchas was to rely on Gmail's captcha, or
whatever Gmail uses as an account creation rate limiter, for the email
distribution bucket. That way *they* keep up with captcha research rather
than forcing us to become (and stay) captcha experts.

Thought #1: While of course we don't necessarily need to stick to
the vision from 15 years ago, I think there's a lot of merit to the
let-a-thousand-flowers-bloom approach to distribution strategies, where
we don't need to glue captchas on to every one of them. I support your
goal of dropping Captchas from the https distributor, on the theory that
they are implicitly included (and done better!) for the email distributor.

Thought #2: Are there adversaries who would happily scrape the https
distributor if it were trivial to do, and just the barrier of solving
the captchas dissuades them? I'm thinking of the Belarus A1 censorship
event for example:
https://gitlab.torproject.org/tpo/anti-censorship/censorship-analysis/-/blob/main/reports/2020/belarus/2020-belarus-report.md
 where our analysis indicates that they scraped the gmail distributor but
not the https distributor. Maybe they already had the gmail accounts in
place from some other attack, so it was cheap to use them for scraping.

Thought #3: We added captchas for the https distributor, but then when
we added the Moat distributor we put captchas on it too. And the Moat
distributor doesn't have any *other* rate-limiting or defense (compare to
the isolation-by-address-block for answers from the https distributor). So
Moat seems extra vulnerable to cheap full enumeration.

Thought #4: We would be in a much better position to experiment here if
we had a better measurement and feedback infrastructure in place. Like,
if we removed the captchas today, how would we know what the impacts are
in terms of higher risk of blocking?

So, I too am tempted to get rid of the captchas, but especially since
we use them in the Moat distributor too, it is unclear how much losing
them would impact usability and security, and it is unclear how we would
learn the answer to that in practice.

My suggestion would be to focus on getting that measurement and
feedback infrastructure in place first, before considering improving
the captchas. We know we need it to know how things are going now, and
we're going to need it to understand the impact of any changes we make.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210109003422</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-01-09 00:34:22-0400</timestampReceived><subject>[tor-dev] Has Core Tor Development Slowed? Or Are We Moving To Rust/arti?</subject><body>

[Attachment #2 (multipart/signed)]


Hi tor-dev@,

I hope you all had a great holiday season.

I noticed that Core Tor development, especially with the tor daemon, has 
slowed down significantly since the COVID crisis.

Sorry if I have been less active in the Tor community as opposed to the 
past. I've been more focused on FreeBSD Ports as of now, but I still 
want to post at least the occasional Tor patch here and there.

Core Tor/Tor hasn't seen an update since December 21, even when we are 
already a week into 2021.

Is this related to the layoffs which happened last year? Or is Tor 
moving to Rust (via arti) and all the development is happening there? 
I'm guessing both.

If it's the latter, I guess I have to start learning Rust sooner rather 
than later. Well, who am I kidding, I had to learn C# and PowerShell for 
my job (Disclaimer: I work at Microsoft, not on security or 
Windows/Azure however).

Is there any other reason?

Best,

Neel Chauhan

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210109165439</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2021-01-09 16:54:39-0400</timestampReceived><subject>Re: [tor-dev] Has Core Tor Development Slowed? Or Are We Moving To Rust/arti?</subject><body>

On Fri, Jan 8, 2021 at 7:43 PM Neel Chauhan &lt;neel@neelc.org&gt; wrote:
&gt;
&gt; Hi tor-dev@,
&gt;
&gt; I hope you all had a great holiday season.
&gt;
&gt; I noticed that Core Tor development, especially with the tor daemon, has
&gt; slowed down significantly since the COVID crisis.
&gt;
&gt; Sorry if I have been less active in the Tor community as opposed to the
&gt; past. I've been more focused on FreeBSD Ports as of now, but I still
&gt; want to post at least the occasional Tor patch here and there.
&gt;
&gt; Core Tor/Tor hasn't seen an update since December 21, even when we are
&gt; already a week into 2021.

Briefly:

We've been on vacation for a while.  We're still developing Tor.

-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210211233627</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-02-11 23:36:27-0400</timestampReceived><subject>[tor-dev] [RFC] Proposal: "Res tokens: Anonymous Credentials for Onion Service DoS Resilience"</subject><body>

Hello all,

after lots of investigation on anonymous credentials, we are glad to
present you with a draft of the onion services anti-DoS proposal using
tokens.

While the basic idea of the proposal should remain reasonably solid,
there are various XXX sprinkled around the proposal and some of them
definitely need to be addressed before the proposal becomes truly
usable.

We are particularly looking forward to feedback about:
- Token issuance services
- The anonymous credential scheme chosen
- The XXXs and design decisions of the proposal

Hope you have a pleasant read!

---

```
Filename: 331-res-tokens-for-anti-dos.md
Title: Res tokens: Anonymous Credentials for Onion Service DoS Resilience
Author: George Kadianakis, Mike Perry
Created: 11-02-2021
Status: Draft
```

                  +--------------+           +------------------+
                  | Token Issuer |           | Onion Service    |
                  +--------------+           +------------------+
                         ^                            ^
                         |        +----------+        |
                Issuance |  1.    |          |   2.   | Redemption
                         +-------&gt;|  Alice   |&lt;-------+
                                  |          |
                                  +----------+


# 0. Introduction

  This proposal specifies a simple anonymous credential scheme based on Blind
  RSA signatures designed to fight DoS abuse against onion services. We call
  the scheme "Res tokens".

  Res tokens are issued by third-party issuance services, and are verified by
  onion services during the introduction protocol (through the INTRODUCE1
  cell).

  While Res tokens are used for denial of service protection in this proposal,
  we demonstrate how they can have application in other Tor areas as well, like
  improving the IP reputation of Tor exit nodes.

# 1. Motivation

  Denial of service attacks against onion services have been explored in the past
  and various defenses have been proposed:
  - Tor proposal #305 specifies network-level rate-limiting mechanisms.
  - Onionbalance allows operators to scale their onions horizontally.
  - Tor proposal #327 increases the attacker's computational requirements (not \
implemented yet).

  While the above proposals in tandem should provide reasonable protection
  against many DoS attackers, they fundamentally work by reducing the assymetry
  between the onion service and the attacker. This won't work if the attacker
  is extremely powerful because the assymetry is already huge and cutting it
  down does not help.

  we believe that a proposal based on cryptographic guarantees -- like Res
  tokens -- can offer protection against even extremely strong attackers.

# 2. Overview

  In this proposal we introduce an anonymous credential scheme -- Res tokens --
  that is well fitted for protecting onion services against DoS attacks. We
  also introduce a system where clients can acquire such anonymous credentials
  from various types of Token Issuers and then redeem them at the onion service
  to gain access even when under DoS conditions.

  In section [TOKEN_DESIGN], we list our requirements from an anonymous
  credential scheme and provide a high-level overview of how the Res token
  scheme works.

  In section [PROTOCOL_SPEC], we specify the token issuance and redemption protocols,
  as well as the mathematical operations that need to be conducted for these to work.

  In section [TOKEN_ISSUERS], we provide a few examples and guidelines for
  various token issuer services that could exist.

  In section [DISCUSSION], we provide more use cases for Res tokens as well as
  future improvements we can conduct to the scheme.

# 3. Design [TOKEN_DESIGN]

  In this section we will go over the high-level design of the system, and on
  the next section we will delve into the lower-level details of the protocol.

## 3.1. Anonymous credentials

  Anonymous credentials or tokens are cryptographic identifiers that allow
  their bearer to maintain an identity while also preserving anonymity.

  Clients can acquire a token in a variety of ways (e.g. registering on a
  third-party service, solving a CAPTCHA, completing a PoW puzzle) and then
  redeem it at the onion service proving this way that work was done, but
  without linking the act of token acquisition with the act of token
  redemption.

## 3.2. Anonymous credential properties

  The anonymous credential literature is vast and there are dozens of
  credential schemes with different properties [REF_TOKEN_ZOO], in this section
  we detail the properties we care about for this use case:

  - Public Verifiability: Because of the distributed trust properties of the
      Tor network, we need anonymous credentials that can be issued by one
      party (the token issuer) and verified by a different party (in this case
      the onion service).

  - Perfect unlinkability: Unlinkability between token issuance and token
      redemption is vital in private settings like Tor. For this reason we want
      our scheme to preserve its unlinkability even if its fundamental security
      assumption is broken. We want unlinkability to be protected by
      information theoretic security or random oracle, and not just
      computational security.

  - Small token size: The tokens will be transfered to the service through the
      INTRODUCE1 cell which is not flexible and has only a limited amount of
      space (about 200 bytes) [REF_INTRO_SPACE]. We need tokens to be small.

  - Quick Verification: Onions are already experiencing resource starvation
      because of the DoS attacks so it's important that the process of
      verifying a token should be as quick as possible. In section [TOKEN_PERF]
      we will go deeper into this requirement.

  After careful consideration of the above requirements, we have leaned towards
  using Blind RSA as the primitive for our tokens, since it's the fastest
  scheme by far that also allows public verifiability. See also Appendix B
  [BLIND_RSA_PROOF] for a security proof sketch of Blind RSA perfect unlinkability.

## 3.3. Other security considerations

  Apart from the above properties we also want:

  - Double spending protection: We don't want Malory to be able to double spend
      her tokens in various onion services thereby amplifying her attack. For
      this reason our tokens are not global, and can only be redeemed at a
      specific destination onion service.

  - Metadata: We want to encode metadata/attributes in the tokens. In
      particular, we want to encode the destination onion service and an
      expiration date. For more information see section [DEST_DIGEST]. For
      blind RSA tokens this is usually done using "partially blind signatures"
      but to keep it simple we instead encode the destination directly in the
      message to be blind-signed and the expiration date using a set of
      rotating signing keys.

  - One-show: There are anonymous credential schemes with multi-show support
      where one token can be used multiple times in an unlinkable
      fashion. However, that might allow an adversary to use a single token to
      launch a DoS attack, since revocation solutions are complex and
      inefficient in anonymous credentials. For this reason, in this work we
      use one-show tokens that can only be redeemed once. That takes care of
      the revocation problem but it means that a client will have to get more
      tokens periodically.

## 3.4. Res tokens overview

  Throughout this proposal we will be using our own token scheme, named "Res",
  which is based on blind RSA signatures. In this modern cryptographic world,
  not only we have the audacity of using Chaum's oldest blind signature scheme
  of all times, but we are also using RSA with a modulus of 1024 bits...

  The reason that Res uses only 1024-bits RSA is because we care most about
  small token size and quick verification rather than the unforgeability of the
  token. This means that if the attacker breaks the issuer's RSA signing key
  and issues tokens for herself, this will enable the adversary to launch DoS
  attacks against onion services, but it won't allow her to link users (because
  of the "perfect unlinkability" property).

  Furthermore, Res tokens get a short implicit expiration date by having the
  issuer rapidly rotate issuance keys every few hours. This means that even if
  an adversary breaks an issuance key, she will be able to forge tokens for
  just a few hours before that key expires.

  For more ideas on future schemes and improvements see section [FUTURE_RES].

## 3.5. Token performance requirements [TOKEN_PERF]

  As discussed above, verification performance is extremely important in the
  anti-DoS use case. In this section we provide some concrete numbers on what
  we are looking for.

  In proposal #327 [REF_POW_PERF] we measured that the total time spent by the
  onion service on processing a single INTRODUCE2 cell ranges from 5 msec to 15
  msecs with a mean time around 5.29 msec. This time also includes the launch
  of a rendezvous circuit, but does not include the additional blocking and
  time it takes to process future cells from the rendezvous point.

  We also measured that the parsing and validation of INTRODUCE2 cell ("top
  half") takes around 0.26 msec; that's the lightweight part before the onion
  service decides to open a rendezvous circuit and do all the path selection
  and networking.

  This means that any defenses introduced by this proposal should add minimal
  overhead to the above "top half" procedure, so as to apply access control in
  the lightest way possible.

  For this reason we implemented a basic version of the Res token scheme in
  Rust and benchmarked the verification and issuance procedure [REF_RES_BENCH].

  We measured that the verification procedure from section [RES_VERIFY] takes
  about 0.104 ms, which we believe is a reasonable verification overhead for
  the purposes of this proposal.

  We also measured that the issuance procedure from [RES_ISSUANCE] takes about
  0.614 ms.

# 4. Specification [PROTOCOL_SPEC]

                  +--------------+           +------------------+
                  | Token Issuer |           | Onion Service    |
                  +--------------+           +------------------+
                         ^                            ^
                         |        +----------+        |
                Issuance |  1.    |          |   2.   | Redemption
                         +-------&gt;|  Alice   |&lt;-------+
                                  |          |
                                  +----------+

## 4.0. Notation

  Let `a || b` be the concatenation of a with b.

  Let `a^b` denote the exponentiation of a to the bth power.

  Let `a == b` denote a check for equality between a and b.

  Let FDH_N(msg) be a Full Domain Hash (FDH) of 'msg' using SHA256 and
  stretching the digest to be equal to the size of an RSA modulus N.

## 4.1. Token issuer setup

  The Issuer creates a set of ephemeral RSA-1024 "issuance keys" that will be
  used during the issuance protocol. Issuers will be rotating these ephemeral
  keys every 6 hours.

  The Issuer exposes the set of active issuance public keys through a REST HTTP
  API that can be accessed by visiting /issuers.keys.

  Tor directory authorities periodically fetch the issuer's public keys and
  vote for those keys in the consensus so that they are readily available by
  clients. The keys in the current consensus are considered active, whereas the
  ones that have fallen off have expired.

  XXX how many issuance public keys are active each time? how does overlapping
      keys work? clients and onions need to know precise expiration date for
      each key. this needs to be specified and tested for robustness.

  XXX every how often does the fetch work? how does the voting work? which
      issuers are considered official? specify consensus method.

  XXX An alternative approach: Issuer has a long-term ed25519 certification key
      that creates expiring certificates for the ephemeral issuance keys. Alice
      shows the certificate to the service to prove that the token comes from
      an issuer. The consensus includes the long-term certification key of the
      issuers to establish ground truth.
      This way we avoid the synchronization between dirauths and issuers, and
      the multiple overlapping active issuance keys. However, certificates
      might not fit in the INTRODUCE1 cell (prop220 certs take 104 bytes on
      their own).  Also certificate metadata might create a vector for
      linkability attacks between the issuer and the verifier.

## 4.2. Onion service signals ongoing DoS attack

  When an onion service is under DoS attack it adds the following line in the
  "encrypted" (inner) part of the v3 descriptor as a way to signal to its
  clients that tokens are required for gaining access:

    "token-required" SP token-type SP issuer-list NL

    [At most once]

    token-type: Is the type of token supported ("res" for this proposal)
    issuer: A comma separated list of issuers which are supported by this onion \
service

## 4.3. Token issuance

  When Alice visits an onion service with an active "token-required" line in
  its descriptor it checks whether there are any tokens available for this
  onion service in its token store. If not, it needs to acquire some and hence
  the token issuance protocol commences.

### 4.3.1. Client preparation [DEST_DIGEST]

  Alice first chooses an issuer supported by the onion service depending on her
  preferences by looking at the consensus and her Tor configuration file for
  the current list of active issuers.

  After picking a supported issuer, she performs the following preparation
  before contacting the issuer:

  1) Alice extracts the issuer's public key (N,e) from the consensus

  2) Alice computes a destination digest as follows:

           dest_digest = FDH_N(destination || salt)

              where:
              - 'destination' is the 32-byte ed25519 public identity key of the \
                destination onion
              - 'salt' is a random 32-byte value,

  3) Alice samples a blinding factor 'r' uniformly at random from [1, N)

  4) Alice computes:
           blinded_message = dest_digest * r^e (mod N)

  After this phase is completed, Alice has a blinded message that is tailored
  specifically for the destination onion service. Alice will send the blinded
  message to the Token Issuer, but because of the blinding the Issuer does not
  get to learn the dest_digest value.

  XXX Is the salt needed? Reevaluate.

### 4.3.3. Token Issuance [RES_ISSUANCE]

  Alice now initiates contact with the Token Issuer and spends the resources
  required to get issued a token (e.g. solve a CAPTCHA or a PoW, create an
  account, etc.). After that step is complete, Alice sends the blinded_message
  to the issuer through a JSON-RPC API.

  After the Issuer receives the blinded_message it signs it as follows:

        blinded_signature = blinded_message ^ d (mod N)

          where:
          - 'd' is the private RSA exponent.

  and returns the blinded_signature to Alice.

  XXX specify API (JSON-RPC? Needs SSL + pubkey pinning.)

### 4.3.4. Unblinding step

  Alice verifies the received blinded signature, and unblinds it to get the
  final token as follows:

        token = blinded_signature * r^{-1} (mod N)
              = blinded_message ^ d * r^{-1] (mod N)
              = (dest_digest * r^e) ^d * r^{-1} (mod N)
              = dest_digest ^ d * r * r^{-1} (mod N)
              = dest_digest ^ d (mod N)

          where:
          - r^{-1} is the multiplicative inverse of the blinding factor 'r'

  Alice will now use the 'token' to get access to the onion service.

  By verifying the received signature using the issuer keys in the consensus,
  Alice ensures that a legitimate token was received and that it has not
  expired (since the issuer keys are still in the consensus).

## 4.4. Token redemption

### 4.4.1. Alice sends token to onion service

  Now that Alice has a valid 'token' it can request access to the onion
  service. It does so by embedding the token into the INTRODUCE1 cell to the
  onion service.

  To do so, Alice adds an extension to the encrypted portion of the INTRODUCE1
  cell by using the EXTENSIONS field (see [PROCESS_INTRO2] section in
  rend-spec-v3.txt). The encrypted portion of the INTRODUCE1 cell only gets
  read by the onion service and is ignored by the introduction point.

  We propose a new EXT_FIELD_TYPE value:

    [02] -- ANON_TOKEN

  The EXT_FIELD content format is:

       TOKEN_VERSION    [1 byte]
       ISSUER_KEY       [4 bytes]
       DEST_DIGEST      [32 bytes]
       TOKEN            [128 bytes]
       SALT             [32 bytes]

  where:
   - TOKEN_VERSION is the version of the token ([0x01] for Res tokens)
   - ISSUER_KEY is the public key of the chosen issuer (truncated to 4 bytes)
   - DEST_DIGEST is the 'dest_digest' from above
   - TOKEN is the 'token' from above
   - SALT is the 32-byte 'salt' added during blinding

  This will increase the INTRODUCE1 payload size by 199 bytes since the data
  above is 197 bytes, the extension type and length is 2 extra bytes, and the
  N_EXTENSIONS field is always present. According to ticket #33650, INTRODUCE1
  cells currently have more than 200 bytes available so we should be able to
  fit the above fields in the cell.

  XXX maybe we don't need to pass DEST_DIGEST and we can just derive it

  XXX maybe with a bit of tweaking we can even use a 1536-bit RSA signature here...

### 4.4.2. Onion service verifies token  [RES_VERIFY]

  Upon receiving an INTRODUCE1 cell with the above extension the service
  verifies the token. It does so as follows:

  1) The service checks its double spend protection cache for an element that
     matches DEST_DIGEST. If one is found, verification fails.
  2) The service checks: DEST_DIGEST == FDH_N(service_pubkey || SALT), where
     'service_pubkey' is its own long-term identity pubkey.
  3) The service finds the corresponding issuer pubkey 'e' based on ISSUER_KEY
     from the consensus or its configuration file
  4) The service checks: TOKEN ^ e == DEST_DIGEST

  Finally the onion service adds the DEST_DIGEST to its double spend protection
  cache to avoid the same token getting redeemed twice.  Onion services keep a
  double spend protection cache by maintaining a sorted array of truncated
  DEST_DIGEST elements.

  If any of the above steps fail, the verification process aborts and the
  introduction request gets discarded.

  If all the above verification steps have been completed successfully, the
  service knows that this a valid token issued by the token issuer, and that
  the token has been created for this onion service specifically. The service
  considers the token valid and the rest of the onion service protocol carries
  out as normal.

# 5. Token issuers [TOKEN_ISSUERS]

  In this section we go over some example token issuers. While we can have
  official token issuers that are supported by the Tor directory authorities,
  it is also possible to have unofficial token issuers between communities that
  can be embedded directly into the configuration file of the onion service and
  the client.

  In general, we consider the design of token issuers to be independent from
  this proposal so we will touch the topic but not go too deep into it.

## 5.1. CAPTCHA token issuer

  A use case resembling the setup of Cloudflare's PrivacyPass would be to have
  a CAPTCHA service that issues tokens after a successful CAPTCHA solution.

  Tor Project, Inc runs https://ctokens.torproject.org which serves hCaptcha
  CAPTCHAs. When the user solves a CAPTCHA the server gives back a list of
  tokens. The amount of tokens rewarded for each solution can be tuned based on
  abuse level.

  Clients reach this service via a regular Tor Exit connection, possibly via a
  dedicated exit enclave-like relay that can only connect to \
https://ctokens.torproject.org.

  Upon receiving tokens, Tor Browser delivers them to the Tor client via the
  control port, which then stores the tokens into a token cache to be used when
  connecting to onion services.

  In terms of UX, most of the above procedure can be hidden from the user by
  having Tor Browser do most of the things under the scenes and only present
  the CAPTCHA to the user if/when needed (if the user doesn't have tokens
  available for that destination).

  XXX specify control port API between browser and tor

## 5.2. PoW token issuer

  An idea that mixes the CAPTCHA issuer with proposal#327, would be to have a
  token issuer that accepts PoW solutions and provides tokens as a reward.

  This solution tends to be less optimal than applying proposal#327 directly
  because it doesn't allow us to fine-tune the PoW difficulty based on the
  attack severity; which is something we are able to do with proposal#327.

  However, we can use the fact that token issuance happens over HTTP to
  introduce more advanced PoW-based concepts. For example, we can design token
  issuers that accept blockchain shares as a reward for tokens. For example, a
  system like Monero's Primo could be used to provide DoS protection and also
  incentivize the token issuer by being able to use those shares for pool
  mining [REF_PRIMO].

## 5.3. Onion service self-issuing

  The onion service itself can also issue tokens to its users and then use
  itself as an issuer for verification. This way it can reward trusted users by
  giving it tokens for the future. The tokens can be rewarded from within the
  website of the onion service and passed to the Tor Client through the control
  port, or they can be provided in an out-of-bands way for future use
  (e.g. from a journalist to a future source using a QR code).

  Unfortunately, the anonymous credential scheme specified in this proposal is
  one-show, so the onion service cannot provide a single token that will work
  for multiple "logins". In the future we can design multi-show credential
  systems that also have revocation to further facilitate this use case (see
  [FUTURE_RES] for more info).

# 6. User Experience

  This proposal has user facing UX consequences.

  Ideally we want this process to be invisible to the user and things to "just
  work". This can be achieved with token issuers that don't require manual work
  by the user (e.g. the PoW issuer, or the onion service itself), since both the
  token issuance and the token redemption protocols don't require any manual work.

  In the cases where manual work is needed by the user (e.g. solving a CAPTCHA)
  it's ideal if the work is presented to the user right before visiting the
  destination and only if it's absolutely required. An explanation about the
  service being under attack should be given to the user when the CAPTCHA is
  provided.

# 7. Security

  In this section we analyze potential security threats of the above system:

  - An evil client can hoard tokens for hours and unleash them all at once to
    cause a denial of service attack. We might want to make the key rotation
    even more frequent if we think that's a possible threat.

  - A trusted token issuer can always DoS an onion service by forging tokens.

  - Overwhelming attacks like "top half attacks" and "hybrid attacks" from
    proposal#327 is valid for this proposal as well.

  - A bad RNG can completely wreck the linkability properties of this proposal.

  XXX Actually analyze the above if we think there is merit to listing them

# 8. Discussion [DISCUSSION]

## 8.1. Using Res tokens on Exit relays

  There are more scenarios within Tor that could benefit from Res tokens
  however we didn't expand on those use cases to keep the proposal short.  In
  the future, we might want to split this document into two proposals: one
  proposal that specifies the token scheme, and another that specifies how to
  use it in the context of onion servicves, so that we can then write more
  proposals that use the token scheme as a primitive.

  An extremely relevant use case would be to use Res tokens as a way to protect
  and improve the IP reputation of Exit relays. We can introduce an exit pool
  that requires tokens in exchange for circuit streams. The idea is that exits
  that require tokens will see less abuse, and will not have low scores in the
  various IP address reputation systems that now govern who gets access to
  websites and web services on the public Internet. We hope that this way we
  will see  less websites blocking Tor.

## 8.2. Future improvements to this proposal [FUTURE_RES]

  The Res token scheme is a pragmatic scheme that works for the space/time
  constraints of this use case but it's far from ideal for the greater future
  (RSA? RSA-1024?).

  After Tor proposal#319 gets implemented we will be able to pack more data in
  RELAY cells and that opens the door to token schemes with bigger token
  sizes. For example, we could design schemes based on BBS+ that can provide
  more advanced features like multi-show and complex attributes but currently
  have bigger token sizes (300+ bytes). That would greatly improve UX since the
  client won't have to solve multiple CAPTCHAs to gain access. Unfortunately,
  another problem here is that right now pairing-based schemes have
  significantly worse verification performance than RSA (e.g. in the order of
  4-5 ms compared to &lt;0.5 ms). We expect pairing-based cryptography performance
  to only improve in the future and we are looking forward to these advances.

  When we switch to a multi-show scheme, we will also need revocation support
  otherwise a single client can abuse the service with a single multi-show
  token. To achieve this we would need to use blacklisting schemes based on
  accumulators (or other primitives) that can provide more flexible revocation
  and blacklisting; however these come at the cost of additional verification
  time which is not something we can spare at this time. We warmly welcome
  research on revocation schemes that are lightweight on the verification side
  but can be heavy on the proving side.

## 8.3. Other uses for tokens in Tor

  There is more use cases for tokens in Tor but we think that other token
  schemes with different properties would be better suited for those.

  In particular we could use tokens as authentication mechanisms for logging
  into services (e.g. acquiring bridges, or logging into Wikipedia). However
  for those use cases we would ideally need multi-show tokens with revocation
  support. We can also introduce token schemes that help us build a secure name
  system for onion services.

  We hope that more research will be done on how to combine various token
  schemes together, and how we can maintain agility while using schemes with
  different primitives and properties.

# 9. Acknowledgements

  Thanks to Jeff Burdges for all the information about Blind RSA and anonymous
  credentials.

  Thanks to Michele Orrù for the help with the unlinkability proof and for the
  discussions about anonymous credentials.

  Thanks to Chelsea Komlo for pointing towards anonymous credentials in
  the context of DoS defenses for onion services.

---

# Appendix A: RSA Blinding Security Proof [BLIND_RSA_PROOF]

  This proof sketch was provided by Michele Orrù:

  ```
  RSA Blind Sigs: https://en.wikipedia.org/wiki/Blind_signature#Blind_RSA_signatures

  As you say, blind RSA should be perfectly blind.

  I tried to look at Boneh-Shoup, Katz-Lindell, and Bellare-Goldwasser for a proof, \
but didn't find any :(

  The basic idea is proving that:
  for any  message "m0" that is blinded with "r0^e" to obtain "b" (that is sent to \
the server), it is possible to freely choose another message "m1" that blinded with \
another opening "r1^e" to obtain the same "b".

  As long as r1, r0 are chosen uniformly at random, you have no way of telling if \
what message was picked and therefore it is *perfectly* blind.

  To do so:
  Assume the messages ("m0" and "m1") are invertible mod N=pq (this happens at most \
with overwhelming probability phi(N)/N if m is uniformly distributed as a result of a \
hash, or you can enforce it at signing time).

  Blinding happens by computing:
     b = m0 * (r0^e).

  However, I can also write:
     b = m0 * r0^e = (m1/m1) * m0 * r0^e = m1 * (m0/m1*r0^e).

  This means that r1 = (m0/m1)^d * r0 is another valid blinding factor for b, and \
it's distributed exactly as r0 in the group of invertibles (it's unif at random, \
because r0 is so).  ```

---

[REF_TOKEN_ZOO]: https://tokenzoo.github.io/
[REF_INTRO_SPACE]: https://gitlab.torproject.org/legacy/trac/-/issues/33650#note_2350910
 [REF_CHAUM]: https://eprint.iacr.org/2001/002.pdf
[REF_PRIMO]: https://repo.getmonero.org/selene/primo
             https://www.monerooutreach.org/stories/RPC-Pay.html
[REF_POW_PERF]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/proposals/327-pow-over-intro.txt#L1050
 [REF_RES_BENCH]: https://github.com/asn-d6/res_tokens_benchmark
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210402174101</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-04-02 17:41:01-0400</timestampReceived><subject>Re: [tor-dev] Question about hidden services shared by multiple hosts</subject><body>

[Attachment #2 (multipart/signed)]


On 26 Mar (08:55:54), Holmes Wilson wrote:
&gt; Hi everyone,

Greetings,

&gt; 
&gt; We're working on a peer-to-peer group chat app where peers connect over v3
&gt; onion addresses. 
&gt; 
&gt; One issue are groups where there are many users but only a few are online in
&gt; a given moment.  Onion addresses are forever, and existing peers might know
&gt; every peer in the network, but it will take a while to try connecting to all
&gt; of them to find one that is online. 
&gt; 
&gt; In this case, it seems helpful for one or more peers to share one or more
&gt; onion addresses that would serve as reliable  "trackers", e.g. 
&gt; 
&gt; 1. All members know the keypairs for these addresses.
&gt; 2. All online members ping these addresses at random intervals to say
&gt;    they're online.
&gt; 3. If they can't connect to an address, they start hosting it themselves.
&gt; 
&gt; We're going to start testing it, but we're wondering if folks here know the
&gt; likely outcome of trying to "share" hosting of an onion service in this
&gt; spontaneous-volunteer sort of way and if there are downsides.
&gt; 
&gt; I *think* the most important question is how long it takes for the network
&gt; to stop routing incoming traffic to an offline client when there's an online
&gt; one available. How long will the address likely be unreachable in one of
&gt; these transition moments, assuming some peer immediately detects that a
&gt; "tracker" onion address has gone offline and begins hosting it themselves?
&gt; (And does this question make sense?)

Interesting idea!

So sharing onion address key material between peers can be fine until they are
used at the same time. What will happen is that the two peers hosting the same
onion address (service) will start competing on the onion service directory
side where service's upload what we call a "descriptor" which is what client
fetch in order to initiate a connection to the service.

With v3, it gets even more complicated actually because of the "revision
counter" in the descriptor which v2 didn't have.

It is simply a number that keeps going up in the descriptor so the onion
service directory (relay) doesn't accept a previous descriptor (replay). And
so, your two peers sharing the onion keys will require to somehow sync that
revision counter for your idea to work (located on disk in the state file,
"HidServRevCounter").

Else, one will inevitably be higher than the other and thus will always
succeed where it will always fail for the other peer.

One approach here, and it is a hack of course, is for the second peer
detecting that the onion is down to download the descriptor (offline one)
still on the directory, get the revision counter out of it ("revision-counter"
field), do a +1 on it and set its state file with it. It is a hack but would
work... You will likely have to deal with "descriptor not found anymore on the
directories" and so you could bruteforce the revision counter from your last
one like adding +1000 to it and that might do the trick. But I would
definitely avoid as much as possible brute forcing it by small steps else your
service will add undesirable load to the network with a lot of upload
attempts.

Now lets say you are able to pull that off, if I understand your question
correctly, once an onion address goes offline, if the other peer would become
the service then few seconds later, all clients will be able to connect to it.
In other words, launching a new service takes few seconds before it can be
reached. The new descriptor will be used by the directories immediately upon
upload as long as the revision counter is higher than the previous one :).

Hope this help!
David

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210503063808</emailId><senderName>Miguel Jacq</senderName><senderEmail>mig@mig5.net</senderEmail><timestampReceived>2021-05-03 06:38:08-0400</timestampReceived><subject>[tor-dev] ClientAuthV3 for v3 onions via Tor controller is accepted by ADD_ONION but seems to get ig</subject><body>

[Attachment #2 (multipart/signed)]


Hi there,

I'm one of the OnionShare developers and I'm trying to implement the new support for \
ClientAuthV3 via the controller as per [1] (thanks for adding it!). Since OnionShare \
depends on Stem, I also began by adding support for passing the ClientAuthV3 argument \
and V3Auth flag into Stem (I intend on submitting that as a PR once I solve the \
problem below, but I think the problem isn't Stem specific)

I can send the ClientAuthV3 base32-encoded public key and the V3Auth flag to \
ADD_ONION, and get a 250 response back.

The problem is that when I then visit the onion address, it doesn't actually require \
the Client Auth that was set :) 

I am running the nightly Tor on Debian 10 (Buster):

```
Tor version 0.4.7.0-alpha-dev.
Tor is running on Linux with Libevent 2.1.8-stable, OpenSSL 1.1.1d, Zlib 1.2.11, \
Liblzma 5.2.4, Libzstd 1.3.8 and Glibc 2.28 as libc. Tor compiled with GCC version \
8.3.0 ```


Steps to reproduce:

1) Take these public and private base32-encoded strings (as generated by [2], if you \
want to generate different ones)

public:  FGTORMIDKR7T2PR632HSHLWA4G6HF5TCWSGMHDUU4LWBEFTAVYQQ
private: 5ZTNYVGHGMBCWT47YQT4ZFOFBWYU24C5PRQZ2CRCXZ5FKTVMJ7QA

2) Start a simple service on localhost:9735:

```
echo Hi | nc -l 127.0.0.1 9735
```

3) Connect to Tor's control port and add an onion with a private key that will derive \
the onion address rujvluxdgiibem3odopgkgiiajgtwfbdgkuqfyydhl5qupotpwyxjaid.onion (or \
put your own if you wish):

```
user@onionshare:~$ sudo telnet localhost 9051
Trying ::1...
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
authenticate ""
250 OK
ADD_ONION ED25519-V3:MNkxu0oI0CX6Oq1AEroRGSAiqXurEbzBdraDKJB1pkNkl9hNCr+bagdAg7gA4F3M/FrF7BHBdh5zdvkHB7oO4w== \
ClientAuthV3=FGTORMIDKR7T2PR632HSHLWA4G6HF5TCWSGMHDUU4LWBEFTAVYQQ Flags=V3Auth \
Port=80,9735 250-ServiceID=rujvluxdgiibem3odopgkgiiajgtwfbdgkuqfyydhl5qupotpwyxjaid
250-ClientAuthV3=AUEFTXH34ZVRXIIVOK5G7XLHTUXGVRLLXG7DG3NKJLRCVSEEHQDQ
250 OK
```

4) Visit http://rujvluxdgiibem3odopgkgiiajgtwfbdgkuqfyydhl5qupotpwyxjaid.onion and \
expect to get the Tor Browser pop-up dialog '[onion service] is requesting that you \
authenticate.. Enter your private key for this onion service'. etc

Instead: the service loads 'Hi' without any requirement for Client Auth occurring. I \
never added the private key to Tor Browser in any way.


Is it a bug, or am I doing it wrong somehow?

Thanks!

mig5

[1] https://gitlab.torproject.org/tpo/core/tor/-/issues/40084
[2] https://github.com/pastly/python-snippits/blob/master/src/tor/x25519-gen.py


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210613053752</emailId><senderName>Chad Retz</senderName><senderEmail>chad.retz@gmail.com</senderEmail><timestampReceived>2021-06-13 05:37:52-0400</timestampReceived><subject>[tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"
onion services) doesn't support setting an Onionbalance
frontend/master onion address (specifically
https://gitlab.torproject.org/tpo/core/tor/-/issues/32709 doesn't seem
to have a control-side analogue). Would a feature request for adding a
`*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or whatever)
to ADD_ONION be reasonable? If so, just add in Gitlab?

Also curious alternative scalability and load balancing options for
ephemeral v3 onion services. I have read
https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf
but unsure if anything more recent has been written. Beyond that and
Onionbalance, any other interesting approaches I could employ
(assuming I can dev anything from a control port pov, but am wanting
to work w/ an unmodified Tor binary)?

Thanks,
Chad
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210708162213</emailId><senderName>Richard Pospesel</senderName><senderEmail>richard@torproject.org</senderEmail><timestampReceived>2021-07-08 16:22:13-0400</timestampReceived><subject>[tor-dev] Mostly Automatic Censorship Circumvention in Tor Browser</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi Everyone,

As part of our Sponsor 30 work, we are looking to improve the new
about:torconnect experience by adding automatic tor settings
configuration for censorship circumvention.

This document outlines and discusses the *technical* challenges
associated with this work, and does not go into any great detail on the
right UX would be (in terms of easy of use, user trust, etc).

Anyway, if you see any pitfalls or problems with anything here, do let
us know.

------------------------------8&lt;--------------------------------------

# Mostly Automatic Bridge Configuration to Bypass Internet Censorship

Our goal for this work is to enable Tor Browser users to access tor
without having to navigate to about:preferences#tor to configure
bridges. Technically speaking, this is a trivial problem assuming you know:

- which bridge settings work at the user's location
- the location of the user

## Circumvention Settings Map

For now, it seems sufficient to maintain a map of countries to some
data-structure containing information about which censorship
circumvention techniques work and which ones do not. A proposed example
format can be found here:

-
https://gitlab.torproject.org/tpo/anti-censorship/state-of-censorship/-/blob/main/state-of-censorship.json


This map would at be distributed and updated through tor-browser releases.

### Problems

#### Censorship Changes Invalidate the Map

The obvious problem with distributing the censorship-circumvention
settings map with Tor Browser is that if the techniques used in a
location change such that old settings no longer work, you will be left
with a non-functional Tor Browser with no way to update it apart from
acquiring a fresh install with the updated settings or by manually
configuring Tor Browser's bridge settings (so what users have to do now)

A fix for this would be to provide a rules update mechanism whereby
updated rules could be fetched outside of tor (via the clearnet, or over
moat). Special care would need to be taken to ensure the rule updates
from this automatic mechanism actually came from the Tor Project (via
some sort of signature verification scheme, for example).

Another wrinkle here is that rules would also need to be distributed
somewhere that is difficult to censor. It seems likely that we may need
different locations and mechanisms for acquiring the rule-set based on
the user's location.

Whatever the mechanism, updates should happen at least before the user
attempts to auto-configure. Otherwise, perhaps we should periodically
auto-update the the settings at a reasonable cadence.

#### Time Investment to Update Map

Another problem with solely distributing the rules through Tor Browser,
is that censorship events would now require a Tor Browser release just
to push new rules out to people. Publishing new Tor Browser releases is
not a simple task, and enabling adversaries to force Tor Browser
releases by tweaking their censorship systems seems like a cute way to
DDOS the Applications team.

An alternate update channel is definitely necessary outside of periodic
Tor Browser releases.

#### Are Per-Country Entries Granular Enough?

One could imagine highly localized censorship events occurring which
require special settings that are not needed in the rest of the country.
For instance, if there is a clearnet blackout in Minneapolis, would we
want to pipe *all* of our US users through the same bridges? Seems like
a potential scalability problem for countries with large populations.

## Determining User Location

A user's location can be determined by accessing location services
through the clearnet. Mozilla offers a such a service (
https://location.services.mozilla.com/ ) with a very simple HTTP
interface. Prior to bootstrapping, Tor Browser can access the location
service by temporarily enabling network DNS:

- network.dns.disabled=false

and making an exception for the location service URL to bypass the proxy by:

- network.proxy.no_proxies_on="location.services.mozilla.com"

The location service would send back a country code in a JSON object
which we can use to look up appropriate bridge settings in our map
described above.

### Problems

So the functionality of this approach is pretty easy to implement: tweak
some prefs, make an XMLHttpRequest, change the prefs back.

One possible problem we may face is if censors start blocking Mozilla's
location services. Maybe we should have a pool of location service
providers to make this more difficult (though we would need to do the
research and figure out how feasible this is from a cost perspective).

It is also possible to add location service functionality to moat,
though this would also be a bit of an engineering endeavor.

If we move forward with Mozilla's location services, we will need to
acquire an API key, but I would not expect this to be an issue. We will
also need to make arrangements with them to surpass the current limit of
100,000 daily API requests ( see:
https://location.services.mozilla.com/terms )

The big challenge here is engineering the right UX which maintains our
users trust. I think we need to be very explicit with this convenience
feature, and definitely not just have it silently happen in the
background. Users should also be able to opt-out, and manually select
their country for the purposes of getting the right settings out of the
above mentioned map.

It should be very difficult to accidentally enable this automatic
lookup. This will likely require a fair bit of iteration on the
about:torconnect page design and flow.


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210907182230</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-07 18:22:30-0400</timestampReceived><subject>[tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi,

As asked in the torspec MR [1] (42) for ticket [2] (40448), I propose a 
MiddleOnly dirauth flag for relays.

The proposal, #334, is attached to this email, and is titled "A dirauth 
flag to mark Relays as Middle-only".

Please comment and review it.

Best,

Neel Chauhan

===

Links:

[1] - https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/42

[2] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448
["334-middle-only-flag.txt" (text/plain)]

Filename: 334-middle-only-flag.txt
Title: A dirauth flag to mark Relays as Middle-only
Author: Neel Chauhan
Created: 2021-09-07
Status: open

1. Introduction

  The Health Team often deals with a large number of relays with an incorrect
  configuration (e.g. not all relays in MyFamily), or needs validation that
  requires contacting the relay operator. It is desirable to put the said
  relays in a less powerful position, such as a middle and rendezvous only
  flag that prevents a relay from being say an entry guard or an exit. [1]

2. The MiddleOnly Flag

  We propose a consensus flag MiddleOnly.

  What this flag does is that a relay must only be in a a middle or
  rendezvous point should a relay have this flag. This is to prevent issues
  with a misconfigured relay as described in Section 1 (Introduction) while
  the Health  Team assesses the risk with the relay.

3. Implementation details

  The MiddleOnly flag can be assigned to relays whose IP addresses are
  configured at the directory authority level, similar to how the BadExit flag
  currently works. In short, if a relay's IP is designated as middle-only, it
  must assign the MiddleOnly flag, otherwise

  Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
  that aren't designated as middle-only in the dirauths must not get the
  MiddleOnly flag. This is to allow new entry guards and exit relays to enter
  the Tor network, while giving relay administrators flexibility to increase
  and reduce bandwidth, or switch between exit and non-exit relays.

  Clients should interpret the MiddleOnly flag while parsing relay descriptors
  to determine whether a relay is to be avoided as an entry guard or exit. If
  a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
  relays as entry guards or exit relays.

3. Citations

  [1] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211010124343</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 12:43:43-0400</timestampReceived><subject>[tor-dev] ed25519_master_id_public_key -&gt; ed25519 id</subject><body>

Hi,

given a relay's ed25519_master_id_public_key
file, is there a simple way to generate the
43 chars long ed25519 identity string (also found in fingerprint-ed25519)?

thanks,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211101150904</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-11-01 15:09:04-0400</timestampReceived><subject>Re: [tor-dev] proposal 328 status</subject><body>

[Attachment #2 (multipart/signed)]


On 29 Oct (22:48:53), nusenu wrote:
&gt; Hi,
&gt; 
&gt; I'm wondering if the current version of the text is the latest available version of it or
&gt; if there is somewhere a newer version that hasn't been pushed yet?
&gt; 
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; 
&gt; "Status: Draft" but it is already in released tor versions.

It should actually be set to "Closed" now and we need to merge it in
dir-spec.txt.

&gt; 
&gt; also in the context of this change:
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/40364
&gt; the proposal still mentions extra-info documents.

And change that as well.

I just opened: https://gitlab.torproject.org/tpo/core/torspec/-/issues/70

Cheers!
David

-- 
eCVYxw3Iqh/9/IgYu/jMmS7iZf2Wky+ZIob+SBM/7/o=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211207182654</emailId><senderName>Jeff Burdges</senderName><senderEmail>burdges@gnunet.org</senderEmail><timestampReceived>2021-12-07 18:26:54-0400</timestampReceived><subject>Re: [tor-dev] Interoperation with libp2p</subject><body>


I work on a project that selected libp2p, but only write cryptographic code, not \
networking code..  I'd caution against using libp2p for anything serious.

Protocol Labs always took a pretty sophomoric approach:  libp2p managed to be better \
than ethereum's but ignored almost everyone working in that space.  It devp2p.  IPFS \
might still be inferior to Tahoe LAFS in real terms, especially due to lacking \
erasure coding.

At some point Protocol Labs spun off libp2p, and by then its core devs recognized \
many of the underlying mistakes.  It also benefits from considerable interest but I \
think our stronger networking people remain unimpressed. 

It' always possible to learn from their mistakes of course, but I suspect tor people \
learned most of those lessons from I2P's efforts.  


Now libp2p doing their own scheme for sending their stuff over Tor's existing streams \
makes sense.  Maybe someone would even pay Tor folk a support contract for the \
assistance designing that?

We've a relatively low bar for grants up to 30k EUR, and more carefully evaluate ones \
up to 100k EUR, so if any Tor people want to submit a grant for improving the rust \
libp2p's Tor usage, then I'll ask for it to be supported:    \
https://github.com/w3f/General-Grants-Program/  https://github.com/libp2p/rust-libp2p

I advise against allowing any libp2p cruft into tor itself though.


&gt; On 10 Nov 2021, at 16:26, Mike Mestnik &lt;cheako+torproject_org@mikemestnik.net&gt; \
&gt; wrote: https://gitlab.torproject.org/tpo/core/torspec/-/issues/64

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211207183251</emailId><senderName>Jeff Burdges</senderName><senderEmail>burdges@gnunet.org</senderEmail><timestampReceived>2021-12-07 18:32:51-0400</timestampReceived><subject>Re: [tor-dev] Interoperation with libp2p</subject><body>



&gt; On 7 Dec 2021, at 19:26, Jeff Burdges &lt;burdges@gnunet.org&gt; wrote:
&gt; I advise against allowing any libp2p cruft into tor itself though.

Among the many reasons. I'd expect libp2p to be a nightmare of downgrade attacks, \
given the amount of badly rolled stuff they must still support, like their dangerous \
key exchange SECIO built on the legacy curve sep256k1, but it'll go deep than that.

Jeff
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211208014941</emailId><senderName>Ismail Khoffi</senderName><senderEmail>ismail.khoffi@gmail.com</senderEmail><timestampReceived>2021-12-08 01:49:41-0400</timestampReceived><subject>Re: [tor-dev] Interoperation with libp2p</subject><body>

[Attachment #2 (multipart/alternative)]


FWIW, I don't think libp2p supports SECIO anymore. In fact the (go)
repository has been archived: https://github.com/libp2p/go-libp2p-secio and
there is no trace of SECIO in the current (go) implementation of libp2p.

On Tue, 7 Dec 2021 at 19:33, Jeff Burdges &lt;burdges@gnunet.org&gt; wrote:

&gt;
&gt;
&gt; &gt; On 7 Dec 2021, at 19:26, Jeff Burdges &lt;burdges@gnunet.org&gt; wrote:
&gt; &gt; I advise against allowing any libp2p cruft into tor itself though.
&gt;
&gt; Among the many reasons. I'd expect libp2p to be a nightmare of downgrade
&gt; attacks, given the amount of badly rolled stuff they must still support,
&gt; like their dangerous key exchange SECIO built on the legacy curve sep256k1,
&gt; but it'll go deep than that.
&gt;
&gt; Jeff
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;FWIW, I don't think libp2p supports SECIO anymore. \
In fact the (go) repository has been archived:  &lt;a \
href="https://github.com/libp2p/go-libp2p-secio"&gt;https://github.com/libp2p/go-libp2p-secio&lt;/a&gt; \
and there is no trace of SECIO in the current (go) implementation of \
libp2p.&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Tue, 7 \
Dec 2021 at 19:33, Jeff Burdges &lt;&lt;a \
href="mailto:burdges@gnunet.org"&gt;burdges@gnunet.org&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;br&gt; &lt;br&gt;
&gt; On 7 Dec 2021, at 19:26, Jeff Burdges &lt;&lt;a href="mailto:burdges@gnunet.org" \
target="_blank"&gt;burdges@gnunet.org&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; I advise against allowing \
any libp2p cruft into tor itself though.&lt;br&gt; &lt;br&gt;
Among the many reasons. I'd expect libp2p to be a nightmare of downgrade attacks, \
given the amount of badly rolled stuff they must still support, like their dangerous \
key exchange SECIO built on the legacy curve sep256k1, but it'll go deep than \
that.&lt;br&gt; &lt;br&gt;
Jeff&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211101194605</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-01 19:46:05-0400</timestampReceived><subject>Re: [tor-dev] proposal 328 status</subject><body>



David Goulet:
&gt; On 29 Oct (22:48:53), nusenu wrote:
&gt; &gt; Hi,
&gt; &gt; 
&gt; &gt; I'm wondering if the current version of the text is the latest available version \
&gt; &gt; of it or if there is somewhere a newer version that hasn't been pushed yet?
&gt; &gt; 
&gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; &gt;  
&gt; &gt; "Status: Draft" but it is already in released tor versions.
&gt; 
&gt; It should actually be set to "Closed" now and we need to merge it in
&gt; dir-spec.txt.

"Implemented-In" would also be nice.

my understanding of the changelog
https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/361/diffs#821ec629171cb3d62b4ce801f8e81e2bbfe9b011_0_1


was that only the "overload-general" line got moved (not all lines from this spec)
from the extra-info descriptor to the server descriptor,
but this change implies that all lines are now located in the server descriptors?

https://gitlab.torproject.org/tpo/core/torspec/-/commit/3424a245774e2ee56115e36cc4f8790fa53067c0#2c338f8c98c902438a74b0f928609906424b356d_30_28
 https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md



Has the version field in the "overload-general" line been increase when the semantics \
for DNS timeouts changed? (the 1 to 1%/10min change)


related stem ticket:
https://github.com/torproject/stem/issues/91


kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211010152950</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-10 15:29:50-0400</timestampReceived><subject>Re: [tor-dev] ed25519_master_id_public_key -&gt; ed25519 id</subject><body>

On Sun, Oct 10, 2021 at 8:44 AM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; given a relay's ed25519_master_id_public_key
&gt; file, is there a simple way to generate the
&gt; 43 chars long ed25519 identity string (also found in fingerprint-ed25519)?
&gt;

Yes, there is!

First you verify that the file is really 64 bytes long, and that the
first 32 bytes of the file are really "== ed25519v1-public: type0
==\0\0\0".

Having done that, you base64-encode the second 32 bytes of the file,
with no "=" padding.

I've attached a lazy little python script.

cheers,
-- 
Nick

["ed-key-to-fp.py" (text/x-python)]

#!/usr/bin/python

import sys
import binascii

# requires python 3
assert sys.version_info &gt;= (3,0,0)

try:
    s = open(sys.argv[1], "rb").read()
except IndexError:
    print("Syntax: {} &lt;filename&gt;".format(sys.argv[0]))
    sys.exit(1)

header = b"== ed25519v1-public: type0 ==\0\0\0"

if len(s) != 64 and s[:32] != header:
    print("This wasn't an ed25519_master_id_public_key file.")
    sys.exit(1)
else:
    print(binascii.b2a_base64(s[32:]).decode("ascii").strip().replace("=",""))


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211010155925</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 15:59:25-0400</timestampReceived><subject>Re: [tor-dev] ed25519_master_id_public_key -&gt; ed25519 id</subject><body>

&gt; Yes, there is!
&gt; 
&gt; First you verify that the file is really 64 bytes long, and that the
&gt; first 32 bytes of the file are really "== ed25519v1-public: type0
&gt; ==\0\0\0".
&gt; 
&gt; Having done that, you base64-encode the second 32 bytes of the file,
&gt; with no "=" padding.

thank you for this description, so I can confirm that this:

cut -b 33- ed25519_master_id_public_key |base64

gives me the same string as in the file fingerprint-ed25519


kind regards,
nusenu
-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210907183344</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2021-09-07 18:33:44-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

On Tue, Sep 07, 2021 at 11:22:30AM -0700, Neel Chauhan wrote:
&gt; 3. Implementation details
&gt; 
&gt;   The MiddleOnly flag can be assigned to relays whose IP addresses are
&gt;   configured at the directory authority level, similar to how the BadExit flag
&gt;   currently works. In short, if a relay's IP is designated as middle-only, it
&gt;   must assign the MiddleOnly flag, otherwise

This sentence is cut off?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210907194701</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2021-09-07 19:47:01-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Neel Chauhan wrote:
&gt; Hi,
&gt; 
&gt; As asked in the torspec MR [1] (42) for ticket [2] (40448), I propose a 
&gt; MiddleOnly dirauth flag for relays.
&gt; 
&gt; The proposal, #334, is attached to this email, and is titled "A dirauth 
&gt; flag to mark Relays as Middle-only".
&gt; 
&gt; Please comment and review it.
&gt; 
&gt; Best,
&gt; 
&gt; Neel Chauhan
&gt; 
&gt; ===
&gt; 
&gt; Links:
&gt; 
&gt; [1] - https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/42
&gt; 
&gt; [2] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448
&gt; 

Hi Neel,

Please add a "MOTIVATION" section and explain in detail why is this 
needed for the network/heath team and how will it improve things? Also 
include in the "MOTIVATION" section the following:

- Why not play with the Exit/Guard to achieve the same goal, why not 
possible? what is the goal -- we need to know the goal to further 
discuss this.

- It's something at Directory Authority Level only? So the client / 
relay operator has no decision whatsoever for this flag? What are the 
tie breakers or based on what is this assigned?

- How will this work in a wonderful feature I am dreaming of where all 
the relays are Exits and maybe we make walking onions working?

P.S. Rendezvous point is NOT a less powerful position (at least from an 
onion service server/operator point of view), unless you are using 
vanguards plugin by Mike with rendguard component activated. Because 
it's always chosen by the client connecting to the onion service, and we 
should assume the client is always ~LE~ evil. Trust me on this :)


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210907203432</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-07 20:34:32-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi,

I have an updated proposal which addresses your concerns, along with 
David Goulet's comments on GitLab.

On 2021-09-07 12:47, s7r wrote:
&gt; Hi Neel,
&gt; 
&gt; Please add a "MOTIVATION" section and explain in detail why is this
&gt; needed for the network/heath team and how will it improve things? Also
&gt; include in the "MOTIVATION" section the following:
&gt; 
&gt; - Why not play with the Exit/Guard to achieve the same goal, why not
&gt; possible? what is the goal -- we need to know the goal to further
&gt; discuss this.

I have an updated proposal which addresses your concerns, along with 
David Goulet's comments on GitLab.

&gt; - It's something at Directory Authority Level only? So the client /
&gt; relay operator has no decision whatsoever for this flag? What are the
&gt; tie breakers or based on what is this assigned?

This is something assigned at the dirauth-level.

&gt; - How will this work in a wonderful feature I am dreaming of where all
&gt; the relays are Exits and maybe we make walking onions working?

I believe it shouldn't affect these scenarios, but have mentioned we 
should look out for them.

&gt; P.S. Rendezvous point is NOT a less powerful position (at least from
&gt; an onion service server/operator point of view), unless you are using
&gt; vanguards plugin by Mike with rendguard component activated. Because
&gt; it's always chosen by the client connecting to the onion service, and
&gt; we should assume the client is always ~LE~ evil. Trust me on this :)

I have also updated this to be a strictly Middle-only flag, and am not 
giving rendezvous capabilities to MiddleOnly relays.

Sorry about this, but I have taken more-or-less a so-called "break" from 
Tor development for a while. I am technically a volunteer, and my 
$DAYJOB is at "Big Tech" (don't judge, that's where I found work).

I also got FreeBSD "commit bit" (not every Tor developer uses Debian) 
which took time away from Tor volunteer efforts. I am only getting back 
to Tor development as of the past week or two, so I need to refresh my 
memory.

Going back, this update also completes the missing paragraph reported by 
Ian, that seemed to miss me in the original proposal.

-Neel Chauhan
["334-middle-only-flag.txt" (text/plain)]

Filename: 334-middle-only-flag.txt
Title: A dirauth flag to mark Relays as Middle-only
Author: Neel Chauhan
Created: 2021-09-07
Status: Open

1. Introduction

  The Health Team often deals with a large number of relays with an incorrect
  configuration (e.g. not all relays in MyFamily), or needs validation that
  requires contacting the relay operator. It is desirable to put the said
  relays in a less powerful position, such as a middle only flag that prevents
  a relay from being used in more powerful positions like an entry guard or an
  exit relay. [1]

1.1. Motivation

  The proposed middle-only flag is needed by the Health Team to prevent
  misconfigured relays from being used in positions capable of deanonymizing
  users while the team evaluates the relay's risk to the network. An example
  of this scenario is when a guard and exit relay run by the same operator
  has an incomplete MyFamily, and the same operator's guard and exit are used
  in a circuit.

  The reason why we won't play with the Guard and Exit flags or weights to
  achieve the same goal is because even if we were to reduce the guard and
  exit weights of a misconfigured relay, it could keep some users at risk of
  deanonymization. Even a small fraction of users at risk of deanonymization
  isn't something we should aim for.

  One case we could look out for is if all relays are exit relays (unlikely),
  or if walking onions are working on the current Tor network. This proposal
  should not affect those scenarios, but we should watch out for these cases.

2. The MiddleOnly Flag

  We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
  assigned this flag from the directory authorities.

  What this flag does is that a relay must not be used as an entry guard or
  exit relay. This is to prevent issues with a misconfigured relay as described
  in Section 1 (Introduction) while the Health Team assesses the risk with the
  relay.

3. Implementation details

  The MiddleOnly flag can be assigned to relays whose IP addresses are
  configured at the directory authority level, similar to how the BadExit flag
  currently works. In short, if a relay's IP is designated as middle-only, it
  must assign the MiddleOnly flag, otherwise we must not assign it.

  Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
  that aren't designated as middle-only in the dirauths must not get the
  MiddleOnly flag. This is to allow new entry guards and exit relays to enter
  the Tor network, while giving relay administrators flexibility to increase
  and reduce bandwidth, or change their exit policy.

3.1. Client Implementation

  Clients should interpret the MiddleOnly flag while parsing relay descriptors
  to determine whether a relay is to be avoided for non-middle purposes. If
  a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
  relays as entry guards or exit relays.

3.2. MiddleOnly Relay Purposes

  If a relay has the MiddleOnly flag, we do not allow it to be used for the
  following purposes:

   * Entry Guard

   * Exit

   * Onion Service Rendevous Point

   * Onion Service Intro Point

   * Onion Service HSDir

   * Fallback Directories

  The reason for this is to prevent a misconfigured relay from being used
  in places where they may know about the client directly. This is in case
  certain misconfigured relays are used to deanonymize clients.

4. Consensus Method

  We also propose a new consensus method 32, which is to only use this flag if
  and when all authorities understand the flag and agree on it. This is because
  the MiddleOnly flag impacts path selection for clients.

5. Citations

  [1] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210907205205</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2021-09-07 20:52:05-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Neel Chauhan wrote:
&gt; 
&gt; I believe it shouldn't affect these scenarios, but have mentioned we 
&gt; should look out for them.
&gt; 
&gt;&gt; P.S. Rendezvous point is NOT a less powerful position (at least from
&gt;&gt; an onion service server/operator point of view), unless you are using
&gt;&gt; vanguards plugin by Mike with rendguard component activated. Because
&gt;&gt; it's always chosen by the client connecting to the onion service, and
&gt;&gt; we should assume the client is always ~LE~ evil. Trust me on this :)
&gt; 
&gt; I have also updated this to be a strictly Middle-only flag, and am not 
&gt; giving rendezvous capabilities to MiddleOnly relays.
&gt; 
&gt; Sorry about this, but I have taken more-or-less a so-called "break" from 
&gt; Tor development for a while. I am technically a volunteer, and my 
&gt; $DAYJOB is at "Big Tech" (don't judge, that's where I found work).
&gt; 
&gt; I also got FreeBSD "commit bit" (not every Tor developer uses Debian) 
&gt; which took time away from Tor volunteer efforts. I am only getting back 
&gt; to Tor development as of the past week or two, so I need to refresh my 
&gt; memory.
&gt; 
&gt; Going back, this update also completes the missing paragraph reported by 
&gt; Ian, that seemed to miss me in the original proposal.
&gt; 

Don't worry -- it's glad to have you back always. Thanks. No judging 
anywhere around here by any means :)

The proposal looks much better with the motivation section, at least me 
know what's all about.

So the DirAuths will just vote about MiddleOnly like they vote about 
BadExit, based on internal communication. Sounds plausible for the 
desired goal.

I saw you mentioned on the list of position where we will NOT use 
MiddleOnly relays RendezVous Points. Please add a note to it that in 
order to enforce this particular requirement, we need to teach the onion 
service server that receives the INTRODUCE2 cell to a rend point with 
MiddleOnly flag to not proceed with the rend protocol and close that 
circuit. Otherwise the requirement enforcement won't work because 
anybody doing any attack would probably use modified clients that don't 
follow the rules to not select a MiddleOnly as rend point.

I don't see any major blockers for this proposal, because if it's voted 
at DirAuth level only, in case it makes troubles for us in a perfect 
future (walking onions / all exits) we can simply decide at DirAuth 
level to not vote on it any more and remove the code that parses it.

What will the consensus requirement be for this flag? 50%+1? IIRC the 
BadExit flag can be assigned with less than 50%+1 DirAuths.


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210910230556</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-09-10 23:05:56-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Thank you for working on this,
I was hoping for such a flag for a long time,
great to see that it is happening now.

The flag should minimize the ability of the relay to do harm.
This means such relays should _not_ be used by tor clients for _any_
other use-case than the second hop position (no HSDir, no fallbackdir, ...).

Also ensure this functionality is available to tor clients via a torrc option
like "ExcludeExitNodes" can be used by tor clients as well.

The torrc option for clients could be named "LimitToMiddleOnlyNodes" or similar
and takes a list of relay fingerprints and can appear multiple times in a torrc (like ExcludeExitNodes).

If there are conflicting configurations the exclusion should overrule
the inclusion of a relay fingerprint. Detected conflicts should cause
a log entry.
An example for a conflict:
MapAddress, EntryNodes, ExitNodes (or any other including option)
mentions a relay fingerprint that is also excluded.

kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210912191737</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-12 19:17:37-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi,

I have an updated proposal.

On 2021-09-07 13:52, s7r wrote:
&gt; Don't worry -- it's glad to have you back always. Thanks. No judging
&gt; anywhere around here by any means :)

No problem!

&gt; The proposal looks much better with the motivation section, at least
&gt; me know what's all about.

Thanks!

&gt; So the DirAuths will just vote about MiddleOnly like they vote about
&gt; BadExit, based on internal communication. Sounds plausible for the
&gt; desired goal.

Makes sense

&gt; I saw you mentioned on the list of position where we will NOT use
&gt; MiddleOnly relays RendezVous Points. Please add a note to it that in
&gt; order to enforce this particular requirement, we need to teach the
&gt; onion service server that receives the INTRODUCE2 cell to a rend point
&gt; with MiddleOnly flag to not proceed with the rend protocol and close
&gt; that circuit. Otherwise the requirement enforcement won't work because
&gt; anybody doing any attack would probably use modified clients that
&gt; don't follow the rules to not select a MiddleOnly as rend point.

I've added that section.

&gt; I don't see any major blockers for this proposal, because if it's
&gt; voted at DirAuth level only, in case it makes troubles for us in a
&gt; perfect future (walking onions / all exits) we can simply decide at
&gt; DirAuth level to not vote on it any more and remove the code that
&gt; parses it.

Makes sense.

Although being a realist here, all exits aren't likely, mainly for 
relays hosted on residential ISPs as well as hosts less supportive of 
exit relays. But hey, we never know, we should prepare for any scenario, 
good or bad.

Both are very common. The former IMHO is very good as it helps 
decentralize/diversify the network away from big datacenters, even if 
only for non-exits. It's harder to surveil every ISP in NA and EU than 
it it to surveil a few OVH, Scaleway, and Hetzner datacenters. However 
the latter still sucks period, all hosts should allow exits.

For me, I'd love to have an exit from home, but there are too many 
blockers in that. My home middle relay is off right now mainly because 
of severe ping spikes when it's on [1].

&gt; What will the consensus requirement be for this flag? 50%+1? IIRC the
&gt; BadExit flag can be assigned with less than 50%+1 DirAuths.

To stay safe from malicious relays, like BadExit, my updated proposal 
says that if one dirauth gives a relay the MiddleOnly flag, then it's 
set for that relay. This is to prevent harm while all (or the majority 
of) dirauths give the relay that flag.

-Neel

Tidbits if you're interested (feel free to ignore if you aren't):

[1] - The CenturyLink tech said they need to add capacity to the 
neighborhood's GPON splitter node. And no, I'm not signing up for 
Comcast since Tor+WFH would saturate the DOCSIS upstream assuming I 
won't go over the cap (which I will).
["334-middle-only-flag.txt" (text/plain)]

Filename: 334-middle-only-flag.txt
Title: A dirauth flag to mark Relays as Middle-only
Author: Neel Chauhan
Created: 2021-09-07
Status: Open

1. Introduction

  The Health Team often deals with a large number of relays with an incorrect
  configuration (e.g. not all relays in MyFamily), or needs validation that
  requires contacting the relay operator. It is desirable to put the said
  relays in a less powerful position, such as a middle only flag that prevents
  a relay from being used in more powerful positions like an entry guard or an
  exit relay. [1]

1.1. Motivation

  The proposed middle-only flag is needed by the Health Team to prevent
  misconfigured relays from being used in positions capable of deanonymizing
  users while the team evaluates the relay's risk to the network. An example
  of this scenario is when a guard and exit relay run by the same operator
  has an incomplete MyFamily, and the same operator's guard and exit are used
  in a circuit.

  The reason why we won't play with the Guard and Exit flags or weights to
  achieve the same goal is because even if we were to reduce the guard and
  exit weights of a misconfigured relay, it could keep some users at risk of
  deanonymization. Even a small fraction of users at risk of deanonymization
  isn't something we should aim for.

  One case we could look out for is if all relays are exit relays (unlikely),
  or if walking onions are working on the current Tor network. This proposal
  should not affect those scenarios, but we should watch out for these cases.

2. The MiddleOnly Flag

  We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
  assigned this flag from the directory authorities.

  What this flag does is that a relay must not be used as an entry guard or
  exit relay. This is to prevent issues with a misconfigured relay as described
  in Section 1 (Introduction) while the Health Team assesses the risk with the
  relay.

3. Implementation details

  The MiddleOnly flag can be assigned to relays whose IP addresses are
  configured at the directory authority level, similar to how the BadExit flag
  currently works. In short, if a relay's IP is designated as middle-only, it
  must assign the MiddleOnly flag, otherwise we must not assign it.

  Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
  that aren't designated as middle-only in the dirauths must not get the
  MiddleOnly flag. This is to allow new entry guards and exit relays to enter
  the Tor network, while giving relay administrators flexibility to increase
  and reduce bandwidth, or change their exit policy.

3.1. Client Implementation

  Clients should interpret the MiddleOnly flag while parsing relay descriptors
  to determine whether a relay is to be avoided for non-middle purposes. If
  a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
  relays as entry guards or exit relays.

3.2. MiddleOnly Relay Purposes

  If a relay has the MiddleOnly flag, we do not allow it to be used for the
  following purposes:

   * Entry Guard

   * Exit

   * Onion Service Rendevous Point

   * Onion Service Intro Point

   * Onion Service HSDir

   * Fallback Directories

  The reason for this is to prevent a misconfigured relay from being used
  in places where they may know about the client directly. This is in case
  certain misconfigured relays are used to deanonymize clients.

4. Onion Service Implementation

  As MiddleOnly relays are not used as rendezvous points, we will need special
  considerations on onion service hosts.

  On an onion service host, when a INTRODUCE2 cell is received, if the
  rendevous point has a MiddleOnly flag, the onion service host should close
  the circuit and therefore not proceed with the protocol.

5. Consensus Considerations

5.1. Consensus Methods

  We propose a new consensus method 32, which is to only use this flag if and
  when all authorities understand the flag and agree on it. This is because the
  MiddleOnly flag impacts path selection for clients.

5.2. Consensus Requirements

  On the directory authorities, similar to the BadExit flag, if one dirauth
  gives a relay the MiddleOnly flag, we should mark the MiddleOnly flag for
  the relay even if other dirauths didn't add the flag.

  This is to help prevent a malicious relay from harming the network while
  the majority of dirauths' administrators wait to give the said relay a
  MiddleOnly flag.

6. Citations

  [1] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210912192118</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-12 19:21:18-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi nusenu,

On 2021-09-10 16:05, nusenu wrote:
&gt; Thank you for working on this,
&gt; I was hoping for such a flag for a long time,
&gt; great to see that it is happening now.

No problem!

&gt; The flag should minimize the ability of the relay to do harm.
&gt; This means such relays should _not_ be used by tor clients for _any_
&gt; other use-case than the second hop position (no HSDir, no fallbackdir, 
&gt; ...).

My updated proposal (most recent s7r email) says a MiddleOnly relay is 
strictly a middle, and nothing else. The original did not say that, and 
I don't know if you got the original or the most recent.

&gt; Also ensure this functionality is available to tor clients via a torrc 
&gt; option
&gt; like "ExcludeExitNodes" can be used by tor clients as well.
&gt; 
&gt; The torrc option for clients could be named "LimitToMiddleOnlyNodes" or 
&gt; similar
&gt; and takes a list of relay fingerprints and can appear multiple times
&gt; in a torrc (like ExcludeExitNodes).
&gt; 

I don't know if torrc options are supposed to go in Proposal documents, 
so I excluded it from there. I will try to make sure an 
"ExcludeMiddleNodes" option (how I would name it) would be included, 
although I may do it in another ticket/MR.

&gt; If there are conflicting configurations the exclusion should overrule
&gt; the inclusion of a relay fingerprint. Detected conflicts should cause
&gt; a log entry.
&gt; An example for a conflict:
&gt; MapAddress, EntryNodes, ExitNodes (or any other including option)
&gt; mentions a relay fingerprint that is also excluded.

Makes sense.

&gt; 
&gt; kind regards,
&gt; nusenu

No problem!

-Neel
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210912193140</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-09-12 19:31:40-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Neel Chauhan:
&gt;&gt; Also ensure this functionality is available to tor clients via a
&gt;&gt; torrc option like "ExcludeExitNodes" can be used by tor clients as
&gt;&gt; well.
&gt;&gt; 
&gt;&gt; The torrc option for clients could be named
&gt;&gt; "LimitToMiddleOnlyNodes" or similar and takes a list of relay
&gt;&gt; fingerprints and can appear multiple times in a torrc (like
&gt;&gt; ExcludeExitNodes).
&gt;&gt; 
&gt; 
&gt; I don't know if torrc options are supposed to go in Proposal
&gt; documents

I agree that the naming of torrc options is not in scope of a proposal,
but the fact that the MiddleOnly path selection constraint feature can be used by clients without
requiring DirAuth actions probably is.

&gt; I will try to make sure an
&gt; "ExcludeMiddleNodes" option (how I would name it) would be included

A name "ExcludedMiddleNodes" would suggest the exact opposite of what MiddleOnly
actually is for, no? It suggests that the given relays are excluded from the middle position
but in fact they should be limited to the middle position.

kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210912212912</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-12 21:29:12-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi,

On 2021-09-12 12:31, nusenu wrote:
&gt; Neel Chauhan:
&gt;&gt;&gt; Also ensure this functionality is available to tor clients via a
&gt;&gt;&gt; torrc option like "ExcludeExitNodes" can be used by tor clients as
&gt;&gt;&gt; well.
&gt;&gt;&gt; 
&gt;&gt;&gt; The torrc option for clients could be named
&gt;&gt;&gt; "LimitToMiddleOnlyNodes" or similar and takes a list of relay
&gt;&gt;&gt; fingerprints and can appear multiple times in a torrc (like
&gt;&gt;&gt; ExcludeExitNodes).
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; I don't know if torrc options are supposed to go in Proposal
&gt;&gt; documents
&gt; 
&gt; I agree that the naming of torrc options is not in scope of a proposal,
&gt; but the fact that the MiddleOnly path selection constraint feature can
&gt; be used by clients without
&gt; requiring DirAuth actions probably is.

It makes sense about that. I will send an updated proposal.

&gt;&gt; I will try to make sure an
&gt;&gt; "ExcludeMiddleNodes" option (how I would name it) would be included
&gt; 
&gt; A name "ExcludedMiddleNodes" would suggest the exact opposite of what 
&gt; MiddleOnly
&gt; actually is for, no? It suggests that the given relays are excluded
&gt; from the middle position
&gt; but in fact they should be limited to the middle position.

Sorry, my bad.

The ExcludeMiddleNodes did give a good idea for a new feature I already 
have a MR for:

  * https://gitlab.torproject.org/tpo/core/tor/-/issues/40466

  * https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/436

It's unrelated to this PR, though, and I don't know if it will go in.

&gt; kind regards,
&gt; nusenu

Any time,

Neel Chauhan
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210912214714</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-09-12 21:47:14-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

&gt; Sorry, my bad.
&gt; 
&gt; The ExcludeMiddleNodes did give a good idea for a new feature I already have a MR for:
&gt; 
&gt;   * https://gitlab.torproject.org/tpo/core/tor/-/issues/40466
&gt; 
&gt;   * https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/436
&gt; 
&gt; It's unrelated to this PR, though, and I don't know if it will go in.

thanks for these pointers.

In case "ExcludeGuardNodes" option is accepted and merged, the documentation should explicitly point out
the differences between

LimitToMiddleOnlyNodes NodeX
vs.
ExcludeGuardNodes NodeX
+
ExcludeExitNodes NodeX

thanks,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210913002834</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-13 00:28:34-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi nusenu,

On 2021-09-12 14:47, nusenu wrote:
&gt; thanks for these pointers.
&gt; 
&gt; In case "ExcludeGuardNodes" option is accepted and merged, the
&gt; documentation should explicitly point out
&gt; the differences between
&gt; 
&gt; LimitToMiddleOnlyNodes NodeX
&gt; vs.
&gt; ExcludeGuardNodes NodeX
&gt; +
&gt; ExcludeExitNodes NodeX
&gt; 
&gt; thanks,
&gt; nusenu

Makes sense. I also got confused by "LimitToMiddleOnlyNodes" versus 
"ExcludeMiddleNodes".

-Neel
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210913034824</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-09-13 03:48:24-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

On Sun, Sep 12, 2021 at 12:17:37PM -0700, Neel Chauhan wrote:
&gt;  If a relay has the MiddleOnly flag, we do not allow it to be used for the
&gt;  following purposes:
&gt;
&gt;   * Entry Guard

While we're trying to be exhaustive here, "Directory Guard" might be a
good addition to this list. (But trying to be exhaustive is risky because
Tor's design will change over time and we'll forget to update this list.)

&gt;   On an onion service host, when a INTRODUCE2 cell is received, if the
&gt;   rendevous point has a MiddleOnly flag, the onion service host should close
&gt;   the circuit and therefore not proceed with the protocol.

Two thoughts on this part:

(A) If we're teaching Tors to actively avoid touching these MiddleOnly
relays even when other people specify them, the rendezvous point
isn't the only one to look for. The next one that comes to mind is
the introduction point, i.e. if a client gets an onion descriptor that
lists an introduction point that has the flag, they would want to avoid
it. And now that we've got two examples, I bet there's a third, and even
if there isn't a third now, it's the sort of thing where future design
changes will forget to consider this part.

(B) There's a bigger problem here, stemming from desynchronized network
knowledge. For example, if my Tor doesn't think a relay has the MiddleOnly
flag, but your Tor thinks it does (e.g. because I have the consensus from
this hour and you have the one from last hour), then you'll refuse to
interact with me.

First, this situation can leak to me which consensus you're using,
which could build into other attacks. See this classic paper on this risk:
https://www.freehaven.net/anonbib/#danezis-pet2008

And second, this situation introduces hard-to-debug robustness issues,
which wouldn't be just a theoretical concern, since they would happen
each time the flag transitions on a given relay.

My suggestion would be to drop this idea of having Tors refuse to use
MiddleOnly relays in risky roles when other people specify them. We
already make sure to build our own path using relays we wanted to use,
before reaching those risky roles. Let's trust the other side to do it
too and not worry about it if it doesn't.

In the case of the two examples we've identified so far, the
attacker could use any relay they like in the next hop after that relay,
and we wouldn't know whether they're doing it. And for the rendezvous
point case in particular, it doesn't even need to be a relay that's in
the consensus right now (in part because we didn't want to get into the
information desync situation there too), so putting only this constraint
on what is an acceptable rendezvous point would be weird.

That is, I think these extra restrictions (avoiding the relays) would be
a slight improvement to security in theory, but I see that as outweighed
by the loss of robustness and by the other security angle (avoiding
letting people probe our internal network knowledge).

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210913060207</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2021-09-13 06:02:07-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Roger Dingledine:

[snip]

&gt; That is, I think these extra restrictions (avoiding the relays) would b=
e
&gt; a slight improvement to security in theory, but I see that as outweighe=
d
&gt; by the loss of robustness and by the other security angle (avoiding
&gt; letting people probe our internal network knowledge).

+1

Georg


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210914180038</emailId><senderName></senderName><senderEmail>ezhigp</senderEmail><timestampReceived>2021-09-14 18:00:38-0400</timestampReceived><subject>[tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Neel Chauman wrote at Sun Sep 12 19:17:37 UTC 2021:
&gt; my updated proposal 
&gt; says that if one dirauth gives a relay the MiddleOnly flag, then it's 
&gt; set for that relay. This is to prevent harm while all (or the majority 
&gt; of) dirauths give the relay that flag.

Imagine one hostile dirauth that votes for this flag on every relay it cannot \
control. Guessing the result is left as an exercise to the reader :).



(Spoiler: IIUC, this will result in using only attacker-controlled relays as entries \
and exits, resulting in both-ends control of all external and hidserv circuits). \
_______________________________________________ tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210914183102</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-14 18:31:02-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi Roger,

On 2021-09-12 20:48, Roger Dingledine wrote:
&gt; On Sun, Sep 12, 2021 at 12:17:37PM -0700, Neel Chauhan wrote:
&gt;&gt;  If a relay has the MiddleOnly flag, we do not allow it to be used for 
&gt;&gt; the
&gt;&gt;  following purposes:
&gt;&gt; 
&gt;&gt;   * Entry Guard
&gt; 
&gt; While we're trying to be exhaustive here, "Directory Guard" might be a
&gt; good addition to this list. (But trying to be exhaustive is risky 
&gt; because
&gt; Tor's design will change over time and we'll forget to update this 
&gt; list.)
&gt; 
&gt;&gt;   On an onion service host, when a INTRODUCE2 cell is received, if the
&gt;&gt;   rendevous point has a MiddleOnly flag, the onion service host should 
&gt;&gt; close
&gt;&gt;   the circuit and therefore not proceed with the protocol.
&gt; 
&gt; Two thoughts on this part:
&gt; 
&gt; (A) If we're teaching Tors to actively avoid touching these MiddleOnly
&gt; relays even when other people specify them, the rendezvous point
&gt; isn't the only one to look for. The next one that comes to mind is
&gt; the introduction point, i.e. if a client gets an onion descriptor that
&gt; lists an introduction point that has the flag, they would want to avoid
&gt; it. And now that we've got two examples, I bet there's a third, and 
&gt; even
&gt; if there isn't a third now, it's the sort of thing where future design
&gt; changes will forget to consider this part.
&gt; 
&gt; (B) There's a bigger problem here, stemming from desynchronized network
&gt; knowledge. For example, if my Tor doesn't think a relay has the 
&gt; MiddleOnly
&gt; flag, but your Tor thinks it does (e.g. because I have the consensus 
&gt; from
&gt; this hour and you have the one from last hour), then you'll refuse to
&gt; interact with me.
&gt; 
&gt; First, this situation can leak to me which consensus you're using,
&gt; which could build into other attacks. See this classic paper on this 
&gt; risk:
&gt; https://www.freehaven.net/anonbib/#danezis-pet2008
&gt; 
&gt; And second, this situation introduces hard-to-debug robustness issues,
&gt; which wouldn't be just a theoretical concern, since they would happen
&gt; each time the flag transitions on a given relay.
&gt; 
&gt; My suggestion would be to drop this idea of having Tors refuse to use
&gt; MiddleOnly relays in risky roles when other people specify them. We
&gt; already make sure to build our own path using relays we wanted to use,
&gt; before reaching those risky roles. Let's trust the other side to do it
&gt; too and not worry about it if it doesn't.
&gt; 
&gt; In the case of the two examples we've identified so far, the
&gt; attacker could use any relay they like in the next hop after that 
&gt; relay,
&gt; and we wouldn't know whether they're doing it. And for the rendezvous
&gt; point case in particular, it doesn't even need to be a relay that's in
&gt; the consensus right now (in part because we didn't want to get into the
&gt; information desync situation there too), so putting only this 
&gt; constraint
&gt; on what is an acceptable rendezvous point would be weird.
&gt; 
&gt; That is, I think these extra restrictions (avoiding the relays) would 
&gt; be
&gt; a slight improvement to security in theory, but I see that as 
&gt; outweighed
&gt; by the loss of robustness and by the other security angle (avoiding
&gt; letting people probe our internal network knowledge).
&gt; 
&gt; --Roger

Roger and George, thank you so much for your feedback.

I was worried restricting MiddleOnly relays too far would become too 
ambitious and hard to implement a la Windows "Longhorn"/Vista 
(disclaimer: I work at Microsoft but not on Windows). I guess it's true.

I have an updated Prop334 attached.

-Neel
["334-middle-only-flag.txt" (text/plain)]

Filename: 334-middle-only-flag.txt
Title: A Directory Authority flag to mark Relays as Middle-only
Author: Neel Chauhan
Created: 2021-09-07
Status: Open

1. Introduction

  The Health Team often deals with a large number of relays with an incorrect
  configuration (e.g. not all relays in MyFamily), or needs validation that
  requires contacting the relay operator. It is desirable to put the said
  relays in a less powerful position, such as a middle only flag that prevents
  a relay from being used in more powerful positions like an entry guard or an
  exit relay. [1]

1.1. Motivation

  The proposed middle-only flag is needed by the Health Team to prevent
  misconfigured relays from being used in positions capable of deanonymizing
  users while the team evaluates the relay's risk to the network. An example
  of this scenario is when a guard and exit relay run by the same operator
  has an incomplete MyFamily, and the same operator's guard and exit are used
  in a circuit.

  The reason why we won't play with the Guard and Exit flags or weights to
  achieve the same goal is because even if we were to reduce the guard and
  exit weights of a misconfigured relay, it could keep some users at risk of
  deanonymization. Even a small fraction of users at risk of deanonymization
  isn't something we should aim for.

  One case we could look out for is if all relays are exit relays (unlikely),
  or if walking onions are working on the current Tor network. This proposal
  should not affect those scenarios, but we should watch out for these cases.

2. The MiddleOnly Flag

  We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
  assigned this flag from the directory authorities.

  What this flag does is that a relay must not be used as an entry guard or
  exit relay. This is to prevent issues with a misconfigured relay as described
  in Section 1 (Introduction) while the Health Team assesses the risk with the
  relay.

3. Implementation details

  The MiddleOnly flag can be assigned to relays whose IP addresses are
  configured at the directory authority level, similar to how the BadExit flag
  currently works. In short, if a relay's IP is designated as middle-only, it
  must assign the MiddleOnly flag, otherwise we must not assign it.

  Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
  that aren't designated as middle-only in the dirauths must not get the
  MiddleOnly flag. This is to allow new entry guards and exit relays to enter
  the Tor network, while giving relay administrators flexibility to increase
  and reduce bandwidth, or change their exit policy.

3.1. Client Implementation

  Clients should interpret the MiddleOnly flag while parsing relay descriptors
  to determine whether a relay is to be avoided for non-middle purposes. If
  a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
  relays as entry guards or exit relays.

3.2. MiddleOnly Relay Purposes

  If a relay has the MiddleOnly flag, we do not allow it to be used for the
  following purposes:

   * Entry Guard

   * Directory Guard

   * Exit Relay

  The reason for this is to prevent a misconfigured relay from being used
  in places where they may know about clients or destination traffic. This
  is in case certain misconfigured relays are used to deanonymize clients.

  We could also bar a MiddleOnly relay from other purposes such as rendezvous
  and fallback directory purposes. However, while more secure in theory, this
  adds unnecessary complexity to the Tor design and has the possibility of
  breaking clients that aren't MiddleOnly-aware [2].

4. Consensus Considerations

4.1. Consensus Methods

  We propose a new consensus method 32, which is to only use this flag if and
  when all authorities understand the flag and agree on it. This is because the
  MiddleOnly flag impacts path selection for clients.

4.2. Consensus Requirements

  On the directory authorities, similar to the BadExit flag, if one dirauth
  gives a relay the MiddleOnly flag, we should mark the MiddleOnly flag for
  the relay even if other dirauths didn't add the flag.

  This is to help prevent a malicious relay from harming the network while
  the majority of dirauths' administrators wait to give the said relay a
  MiddleOnly flag.

5. Acknowledgements

  Thank you so much to nusenu, s7r, and Roger Dingledine for your suggestions
  to Prop334. My proposal wouldn't be what it is without you.

6. Citations

  [1] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448

  [2] - https://lists.torproject.org/pipermail/tor-dev/2021-September/014627.html


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210914190007</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-09-14 19:00:07-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]


On 14 Sep (11:31:02), Neel Chauhan wrote:
&gt; Hi Roger,

Hi Neel!

Thanks for your proposal!!

&gt; 
&gt; On 2021-09-12 20:48, Roger Dingledine wrote:
&gt; &gt; On Sun, Sep 12, 2021 at 12:17:37PM -0700, Neel Chauhan wrote:
&gt; &gt; &gt;  If a relay has the MiddleOnly flag, we do not allow it to be used
&gt; &gt; &gt; for the
&gt; &gt; &gt;  following purposes:
&gt; &gt; &gt; 
&gt; &gt; &gt;   * Entry Guard
&gt; &gt; 
&gt; &gt; While we're trying to be exhaustive here, "Directory Guard" might be a
&gt; &gt; good addition to this list. (But trying to be exhaustive is risky
&gt; &gt; because
&gt; &gt; Tor's design will change over time and we'll forget to update this
&gt; &gt; list.)
&gt; &gt; 
&gt; &gt; &gt;   On an onion service host, when a INTRODUCE2 cell is received, if the
&gt; &gt; &gt;   rendevous point has a MiddleOnly flag, the onion service host
&gt; &gt; &gt; should close
&gt; &gt; &gt;   the circuit and therefore not proceed with the protocol.
&gt; &gt; 
&gt; &gt; Two thoughts on this part:
&gt; &gt; 
&gt; &gt; (A) If we're teaching Tors to actively avoid touching these MiddleOnly
&gt; &gt; relays even when other people specify them, the rendezvous point
&gt; &gt; isn't the only one to look for. The next one that comes to mind is
&gt; &gt; the introduction point, i.e. if a client gets an onion descriptor that
&gt; &gt; lists an introduction point that has the flag, they would want to avoid
&gt; &gt; it. And now that we've got two examples, I bet there's a third, and even
&gt; &gt; if there isn't a third now, it's the sort of thing where future design
&gt; &gt; changes will forget to consider this part.
&gt; &gt; 
&gt; &gt; (B) There's a bigger problem here, stemming from desynchronized network
&gt; &gt; knowledge. For example, if my Tor doesn't think a relay has the
&gt; &gt; MiddleOnly
&gt; &gt; flag, but your Tor thinks it does (e.g. because I have the consensus
&gt; &gt; from
&gt; &gt; this hour and you have the one from last hour), then you'll refuse to
&gt; &gt; interact with me.
&gt; &gt; 
&gt; &gt; First, this situation can leak to me which consensus you're using,
&gt; &gt; which could build into other attacks. See this classic paper on this
&gt; &gt; risk:
&gt; &gt; https://www.freehaven.net/anonbib/#danezis-pet2008
&gt; &gt; 
&gt; &gt; And second, this situation introduces hard-to-debug robustness issues,
&gt; &gt; which wouldn't be just a theoretical concern, since they would happen
&gt; &gt; each time the flag transitions on a given relay.
&gt; &gt; 
&gt; &gt; My suggestion would be to drop this idea of having Tors refuse to use
&gt; &gt; MiddleOnly relays in risky roles when other people specify them. We
&gt; &gt; already make sure to build our own path using relays we wanted to use,
&gt; &gt; before reaching those risky roles. Let's trust the other side to do it
&gt; &gt; too and not worry about it if it doesn't.
&gt; &gt; 
&gt; &gt; In the case of the two examples we've identified so far, the
&gt; &gt; attacker could use any relay they like in the next hop after that relay,
&gt; &gt; and we wouldn't know whether they're doing it. And for the rendezvous
&gt; &gt; point case in particular, it doesn't even need to be a relay that's in
&gt; &gt; the consensus right now (in part because we didn't want to get into the
&gt; &gt; information desync situation there too), so putting only this constraint
&gt; &gt; on what is an acceptable rendezvous point would be weird.
&gt; &gt; 
&gt; &gt; That is, I think these extra restrictions (avoiding the relays) would be
&gt; &gt; a slight improvement to security in theory, but I see that as outweighed
&gt; &gt; by the loss of robustness and by the other security angle (avoiding
&gt; &gt; letting people probe our internal network knowledge).
&gt; &gt; 
&gt; &gt; --Roger
&gt; 
&gt; Roger and George, thank you so much for your feedback.
&gt; 
&gt; I was worried restricting MiddleOnly relays too far would become too
&gt; ambitious and hard to implement a la Windows "Longhorn"/Vista (disclaimer: I
&gt; work at Microsoft but not on Windows). I guess it's true.
&gt; 
&gt; I have an updated Prop334 attached.
&gt; 
&gt; -Neel

&gt; Filename: 334-middle-only-flag.txt
&gt; Title: A Directory Authority flag to mark Relays as Middle-only
&gt; Author: Neel Chauhan
&gt; Created: 2021-09-07
&gt; Status: Open
&gt; 
&gt; 1. Introduction
&gt; 
&gt;   The Health Team often deals with a large number of relays with an incorrect
&gt;   configuration (e.g. not all relays in MyFamily), or needs validation that
&gt;   requires contacting the relay operator. It is desirable to put the said
&gt;   relays in a less powerful position, such as a middle only flag that prevents
&gt;   a relay from being used in more powerful positions like an entry guard or an
&gt;   exit relay. [1]
&gt; 
&gt; 1.1. Motivation
&gt; 
&gt;   The proposed middle-only flag is needed by the Health Team to prevent
&gt;   misconfigured relays from being used in positions capable of deanonymizing
&gt;   users while the team evaluates the relay's risk to the network. An example
&gt;   of this scenario is when a guard and exit relay run by the same operator
&gt;   has an incomplete MyFamily, and the same operator's guard and exit are used
&gt;   in a circuit.
&gt; 
&gt;   The reason why we won't play with the Guard and Exit flags or weights to
&gt;   achieve the same goal is because even if we were to reduce the guard and
&gt;   exit weights of a misconfigured relay, it could keep some users at risk of
&gt;   deanonymization. Even a small fraction of users at risk of deanonymization
&gt;   isn't something we should aim for.
&gt; 
&gt;   One case we could look out for is if all relays are exit relays (unlikely),
&gt;   or if walking onions are working on the current Tor network. This proposal
&gt;   should not affect those scenarios, but we should watch out for these cases.
&gt; 
&gt; 2. The MiddleOnly Flag
&gt; 
&gt;   We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
&gt;   assigned this flag from the directory authorities.
&gt; 
&gt;   What this flag does is that a relay must not be used as an entry guard or
&gt;   exit relay. This is to prevent issues with a misconfigured relay as described
&gt;   in Section 1 (Introduction) while the Health Team assesses the risk with the
&gt;   relay.
&gt; 
&gt; 3. Implementation details
&gt; 
&gt;   The MiddleOnly flag can be assigned to relays whose IP addresses are
&gt;   configured at the directory authority level, similar to how the BadExit flag
&gt;   currently works. In short, if a relay's IP is designated as middle-only, it
&gt;   must assign the MiddleOnly flag, otherwise we must not assign it.

Note: a unique identifier of relays is by relay identity key (its
fingerprint), not the IP address. However, it is true we do reject relays
based on fingerprint and address most of the times so I think it would be
better to also specify the fingerprint approach as well.

&gt; 
&gt;   Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
&gt;   that aren't designated as middle-only in the dirauths must not get the
&gt;   MiddleOnly flag. This is to allow new entry guards and exit relays to enter
&gt;   the Tor network, while giving relay administrators flexibility to increase
&gt;   and reduce bandwidth, or change their exit policy.
&gt; 
&gt; 3.1. Client Implementation
&gt; 
&gt;   Clients should interpret the MiddleOnly flag while parsing relay descriptors
&gt;   to determine whether a relay is to be avoided for non-middle purposes. If
&gt;   a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
&gt;   relays as entry guards or exit relays.
&gt; 
&gt; 3.2. MiddleOnly Relay Purposes
&gt; 
&gt;   If a relay has the MiddleOnly flag, we do not allow it to be used for the
&gt;   following purposes:
&gt; 
&gt;    * Entry Guard
&gt; 
&gt;    * Directory Guard
&gt; 
&gt;    * Exit Relay
&gt; 
&gt;   The reason for this is to prevent a misconfigured relay from being used
&gt;   in places where they may know about clients or destination traffic. This
&gt;   is in case certain misconfigured relays are used to deanonymize clients.
&gt; 
&gt;   We could also bar a MiddleOnly relay from other purposes such as rendezvous
&gt;   and fallback directory purposes. However, while more secure in theory, this
&gt;   adds unnecessary complexity to the Tor design and has the possibility of
&gt;   breaking clients that aren't MiddleOnly-aware [2].

Can we have a note on why HSDir, Intro and Rendezvous relays have not been put
in that list?

&gt; 
&gt; 4. Consensus Considerations
&gt; 
&gt; 4.1. Consensus Methods
&gt; 
&gt;   We propose a new consensus method 32, which is to only use this flag if and
&gt;   when all authorities understand the flag and agree on it. This is because the
&gt;   MiddleOnly flag impacts path selection for clients.
&gt; 
&gt; 4.2. Consensus Requirements
&gt; 
&gt;   On the directory authorities, similar to the BadExit flag, if one dirauth
&gt;   gives a relay the MiddleOnly flag, we should mark the MiddleOnly flag for
&gt;   the relay even if other dirauths didn't add the flag.

I'm a tiny bit skeptical about this here. This is a whole lot of power for one
dirauth.

The idea behind enforcing a consensus method is that a majority of authorities
would vote on MiddleOnly and not very few.

It is true that there is often a delay with a majority of authorities agreeing
on a flag from the time the health team flag a relay MiddleOnly.

However, I'm not sure we should always let 1 authority dictate that flag
regardless of what the others think.

It is _not_ common but it had happened in the past that TPO's health team
would recommend to reject a relay and few authorities agreed to do it but not
the majority as the rest didn't find the reasons good enough and so the relay
was never rejected in the end because lack of majority.

That is a bit the last last safe guard of the authority protocol here which is
that an actual trusted operators makes the ultimate decision to reject or not
based on the information provided by the health team. And this works if every
decision needs majority.

Adding that requirement would not allow this and so like rejecting a relay
from the consensus, I think we need to enforce majority here and not have one
single authority dictate it.

Thoughts?

Thanks!
David

-- 
K7aNcvjqUnm77UVeDN/oRSBek/3QsRHYncZM5w7KiRM=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210914212427</emailId><senderName>Tor Relays</senderName><senderEmail>torrelaysaregreat@gmail.com</senderEmail><timestampReceived>2021-09-14 21:24:27-0400</timestampReceived><subject>[tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/alternative)]


 David Goulet:

&gt; However, I'm not sure we should always let 1 authority dictate that flag
&gt; regardless of what the others think.
&gt;
&gt; I think we need to enforce majority here and not have one
&gt; single authority dictate it.
&gt;
&gt; Thoughts?
&gt;

+1

I can compromise one authority and can MiddleOnly the whole Tor network.

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;
David Goulet:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;However, I'm not \
sure we should always let 1 authority dictate that flag&lt;br&gt; regardless of what the \
others think.&lt;br&gt;&lt;br&gt;I think we need to enforce majority here and not have one&lt;br&gt; \
single authority dictate it.&lt;br&gt;&lt;br&gt; Thoughts?

&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;+1&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I can compromise one \
authority and can MiddleOnly the whole Tor network.&lt;/div&gt;

&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210915074830</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2021-09-15 07:48:30-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


David Goulet:
&gt; On 14 Sep (11:31:02), Neel Chauhan wrote:
&gt;&gt; Hi Roger,
&gt; 
&gt; Hi Neel!
&gt; 
&gt; Thanks for your proposal!!
&gt; 
&gt;&gt;
&gt;&gt; On 2021-09-12 20:48, Roger Dingledine wrote:
&gt;&gt;&gt; On Sun, Sep 12, 2021 at 12:17:37PM -0700, Neel Chauhan wrote:
&gt;&gt;&gt;&gt;  If a relay has the MiddleOnly flag, we do not allow it to be used
&gt;&gt;&gt;&gt; for the
&gt;&gt;&gt;&gt;  following purposes:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;   * Entry Guard
&gt;&gt;&gt;
&gt;&gt;&gt; While we're trying to be exhaustive here, "Directory Guard" might be a
&gt;&gt;&gt; good addition to this list. (But trying to be exhaustive is risky
&gt;&gt;&gt; because
&gt;&gt;&gt; Tor's design will change over time and we'll forget to update this
&gt;&gt;&gt; list.)
&gt;&gt;&gt;
&gt;&gt;&gt;&gt;   On an onion service host, when a INTRODUCE2 cell is received, if the
&gt;&gt;&gt;&gt;   rendevous point has a MiddleOnly flag, the onion service host
&gt;&gt;&gt;&gt; should close
&gt;&gt;&gt;&gt;   the circuit and therefore not proceed with the protocol.
&gt;&gt;&gt;
&gt;&gt;&gt; Two thoughts on this part:
&gt;&gt;&gt;
&gt;&gt;&gt; (A) If we're teaching Tors to actively avoid touching these MiddleOnly
&gt;&gt;&gt; relays even when other people specify them, the rendezvous point
&gt;&gt;&gt; isn't the only one to look for. The next one that comes to mind is
&gt;&gt;&gt; the introduction point, i.e. if a client gets an onion descriptor that
&gt;&gt;&gt; lists an introduction point that has the flag, they would want to avoid
&gt;&gt;&gt; it. And now that we've got two examples, I bet there's a third, and even
&gt;&gt;&gt; if there isn't a third now, it's the sort of thing where future design
&gt;&gt;&gt; changes will forget to consider this part.
&gt;&gt;&gt;
&gt;&gt;&gt; (B) There's a bigger problem here, stemming from desynchronized network
&gt;&gt;&gt; knowledge. For example, if my Tor doesn't think a relay has the
&gt;&gt;&gt; MiddleOnly
&gt;&gt;&gt; flag, but your Tor thinks it does (e.g. because I have the consensus
&gt;&gt;&gt; from
&gt;&gt;&gt; this hour and you have the one from last hour), then you'll refuse to
&gt;&gt;&gt; interact with me.
&gt;&gt;&gt;
&gt;&gt;&gt; First, this situation can leak to me which consensus you're using,
&gt;&gt;&gt; which could build into other attacks. See this classic paper on this
&gt;&gt;&gt; risk:
&gt;&gt;&gt; https://www.freehaven.net/anonbib/#danezis-pet2008
&gt;&gt;&gt;
&gt;&gt;&gt; And second, this situation introduces hard-to-debug robustness issues,
&gt;&gt;&gt; which wouldn't be just a theoretical concern, since they would happen
&gt;&gt;&gt; each time the flag transitions on a given relay.
&gt;&gt;&gt;
&gt;&gt;&gt; My suggestion would be to drop this idea of having Tors refuse to use
&gt;&gt;&gt; MiddleOnly relays in risky roles when other people specify them. We
&gt;&gt;&gt; already make sure to build our own path using relays we wanted to use,
&gt;&gt;&gt; before reaching those risky roles. Let's trust the other side to do it
&gt;&gt;&gt; too and not worry about it if it doesn't.
&gt;&gt;&gt;
&gt;&gt;&gt; In the case of the two examples we've identified so far, the
&gt;&gt;&gt; attacker could use any relay they like in the next hop after that relay,
&gt;&gt;&gt; and we wouldn't know whether they're doing it. And for the rendezvous
&gt;&gt;&gt; point case in particular, it doesn't even need to be a relay that's in
&gt;&gt;&gt; the consensus right now (in part because we didn't want to get into the
&gt;&gt;&gt; information desync situation there too), so putting only this constraint
&gt;&gt;&gt; on what is an acceptable rendezvous point would be weird.
&gt;&gt;&gt;
&gt;&gt;&gt; That is, I think these extra restrictions (avoiding the relays) would be
&gt;&gt;&gt; a slight improvement to security in theory, but I see that as outweighed
&gt;&gt;&gt; by the loss of robustness and by the other security angle (avoiding
&gt;&gt;&gt; letting people probe our internal network knowledge).
&gt;&gt;&gt;
&gt;&gt;&gt; --Roger
&gt;&gt;
&gt;&gt; Roger and George, thank you so much for your feedback.
&gt;&gt;
&gt;&gt; I was worried restricting MiddleOnly relays too far would become too
&gt;&gt; ambitious and hard to implement a la Windows "Longhorn"/Vista (disclaimer: I
&gt;&gt; work at Microsoft but not on Windows). I guess it's true.
&gt;&gt;
&gt;&gt; I have an updated Prop334 attached.
&gt;&gt;
&gt;&gt; -Neel
&gt; 
&gt;&gt; Filename: 334-middle-only-flag.txt
&gt;&gt; Title: A Directory Authority flag to mark Relays as Middle-only
&gt;&gt; Author: Neel Chauhan
&gt;&gt; Created: 2021-09-07
&gt;&gt; Status: Open
&gt;&gt;
&gt;&gt; 1. Introduction
&gt;&gt;
&gt;&gt;   The Health Team often deals with a large number of relays with an incorrect
&gt;&gt;   configuration (e.g. not all relays in MyFamily), or needs validation that
&gt;&gt;   requires contacting the relay operator. It is desirable to put the said
&gt;&gt;   relays in a less powerful position, such as a middle only flag that prevents
&gt;&gt;   a relay from being used in more powerful positions like an entry guard or an
&gt;&gt;   exit relay. [1]
&gt;&gt;
&gt;&gt; 1.1. Motivation
&gt;&gt;
&gt;&gt;   The proposed middle-only flag is needed by the Health Team to prevent
&gt;&gt;   misconfigured relays from being used in positions capable of deanonymizing
&gt;&gt;   users while the team evaluates the relay's risk to the network. An example
&gt;&gt;   of this scenario is when a guard and exit relay run by the same operator
&gt;&gt;   has an incomplete MyFamily, and the same operator's guard and exit are used
&gt;&gt;   in a circuit.
&gt;&gt;
&gt;&gt;   The reason why we won't play with the Guard and Exit flags or weights to
&gt;&gt;   achieve the same goal is because even if we were to reduce the guard and
&gt;&gt;   exit weights of a misconfigured relay, it could keep some users at risk of
&gt;&gt;   deanonymization. Even a small fraction of users at risk of deanonymization
&gt;&gt;   isn't something we should aim for.
&gt;&gt;
&gt;&gt;   One case we could look out for is if all relays are exit relays (unlikely),
&gt;&gt;   or if walking onions are working on the current Tor network. This proposal
&gt;&gt;   should not affect those scenarios, but we should watch out for these cases.
&gt;&gt;
&gt;&gt; 2. The MiddleOnly Flag
&gt;&gt;
&gt;&gt;   We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
&gt;&gt;   assigned this flag from the directory authorities.
&gt;&gt;
&gt;&gt;   What this flag does is that a relay must not be used as an entry guard or
&gt;&gt;   exit relay. This is to prevent issues with a misconfigured relay as described
&gt;&gt;   in Section 1 (Introduction) while the Health Team assesses the risk with the
&gt;&gt;   relay.
&gt;&gt;
&gt;&gt; 3. Implementation details
&gt;&gt;
&gt;&gt;   The MiddleOnly flag can be assigned to relays whose IP addresses are
&gt;&gt;   configured at the directory authority level, similar to how the BadExit flag
&gt;&gt;   currently works. In short, if a relay's IP is designated as middle-only, it
&gt;&gt;   must assign the MiddleOnly flag, otherwise we must not assign it.
&gt; 
&gt; Note: a unique identifier of relays is by relay identity key (its
&gt; fingerprint), not the IP address. However, it is true we do reject relays
&gt; based on fingerprint and address most of the times so I think it would be
&gt; better to also specify the fingerprint approach as well.
&gt; 
&gt;&gt;
&gt;&gt;   Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
&gt;&gt;   that aren't designated as middle-only in the dirauths must not get the
&gt;&gt;   MiddleOnly flag. This is to allow new entry guards and exit relays to enter
&gt;&gt;   the Tor network, while giving relay administrators flexibility to increase
&gt;&gt;   and reduce bandwidth, or change their exit policy.
&gt;&gt;
&gt;&gt; 3.1. Client Implementation
&gt;&gt;
&gt;&gt;   Clients should interpret the MiddleOnly flag while parsing relay descriptors
&gt;&gt;   to determine whether a relay is to be avoided for non-middle purposes. If
&gt;&gt;   a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
&gt;&gt;   relays as entry guards or exit relays.
&gt;&gt;
&gt;&gt; 3.2. MiddleOnly Relay Purposes
&gt;&gt;
&gt;&gt;   If a relay has the MiddleOnly flag, we do not allow it to be used for the
&gt;&gt;   following purposes:
&gt;&gt;
&gt;&gt;    * Entry Guard
&gt;&gt;
&gt;&gt;    * Directory Guard
&gt;&gt;
&gt;&gt;    * Exit Relay
&gt;&gt;
&gt;&gt;   The reason for this is to prevent a misconfigured relay from being used
&gt;&gt;   in places where they may know about clients or destination traffic. This
&gt;&gt;   is in case certain misconfigured relays are used to deanonymize clients.
&gt;&gt;
&gt;&gt;   We could also bar a MiddleOnly relay from other purposes such as rendezvous
&gt;&gt;   and fallback directory purposes. However, while more secure in theory, this
&gt;&gt;   adds unnecessary complexity to the Tor design and has the possibility of
&gt;&gt;   breaking clients that aren't MiddleOnly-aware [2].
&gt; 
&gt; Can we have a note on why HSDir, Intro and Rendezvous relays have not been put
&gt; in that list?
&gt; 
&gt;&gt;
&gt;&gt; 4. Consensus Considerations
&gt;&gt;
&gt;&gt; 4.1. Consensus Methods
&gt;&gt;
&gt;&gt;   We propose a new consensus method 32, which is to only use this flag if and
&gt;&gt;   when all authorities understand the flag and agree on it. This is because the
&gt;&gt;   MiddleOnly flag impacts path selection for clients.
&gt;&gt;
&gt;&gt; 4.2. Consensus Requirements
&gt;&gt;
&gt;&gt;   On the directory authorities, similar to the BadExit flag, if one dirauth
&gt;&gt;   gives a relay the MiddleOnly flag, we should mark the MiddleOnly flag for
&gt;&gt;   the relay even if other dirauths didn't add the flag.
&gt; 
&gt; I'm a tiny bit skeptical about this here. This is a whole lot of power for one
&gt; dirauth.
&gt; 
&gt; The idea behind enforcing a consensus method is that a majority of authorities
&gt; would vote on MiddleOnly and not very few.
&gt; 
&gt; It is true that there is often a delay with a majority of authorities agreeing
&gt; on a flag from the time the health team flag a relay MiddleOnly.
&gt; 
&gt; However, I'm not sure we should always let 1 authority dictate that flag
&gt; regardless of what the others think.
&gt; 
&gt; It is _not_ common but it had happened in the past that TPO's health team
&gt; would recommend to reject a relay and few authorities agreed to do it but not
&gt; the majority as the rest didn't find the reasons good enough and so the relay
&gt; was never rejected in the end because lack of majority.
&gt; 
&gt; That is a bit the last last safe guard of the authority protocol here which is
&gt; that an actual trusted operators makes the ultimate decision to reject or not
&gt; based on the information provided by the health team. And this works if every
&gt; decision needs majority.
&gt; 
&gt; Adding that requirement would not allow this and so like rejecting a relay
&gt; from the consensus, I think we need to enforce majority here and not have one
&gt; single authority dictate it.
&gt; 
&gt; Thoughts?

Yes, I agree with that reasoning. I don't think the delay in proposing
relay X is getting the MiddleOnly flag and a majority of directory
authorities saying so is an issue. It's not an issue either in the
outright reject cases where we find an actual attacker, which are
arguably worse. And even if it really were an issue, we could ping folks
to apply the flag in case we actually find its application urgent.

Additionally, and to pick up the second potential argument you mention,
those directory authorities that were in the past reluctant to reject a
bunch of relays (for good reasons) that got proposed by network health
folks might now be pretty happy with applying the MiddleOnly flag (for
the same reasons).

Georg

&gt; Thanks!
&gt; David
&gt; 
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 



["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210916125229</emailId><senderName>s7r</senderName><senderEmail>s7r@sky-ip.org</senderEmail><timestampReceived>2021-09-16 12:52:29-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Tor Relays wrote:
&gt; David Goulet:
&gt; 
&gt;     However, I'm not sure we should always let 1 authority dictate that flag
&gt;     regardless of what the others think.
&gt; 
&gt;     I think we need to enforce majority here and not have one
&gt;     single authority dictate it.
&gt; 
&gt;     Thoughts?
&gt; 
&gt; 
&gt; +1
&gt; 
&gt; I can compromise one authority and can MiddleOnly the whole Tor network.
&gt; 

+1

of course we should not allow just 1 Directory Authority to have this 
power. This would undermine the security model of the consensus we have 
in Tor -- that is why we have more Directory Authorities controlled by 
different people in different jurisdictions / parts of the world so it's 
hard for an attacker to compromise all at once. We know and agree it's 
simple and cheap (even free if it's a LEA with a subpoena) to compromise 
one directory authority but much harder to compromise 50% + 1.


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210917223520</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-17 22:35:20-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi David,

On 2021-09-14 12:00, David Goulet wrote:
&gt; On 14 Sep (11:31:02), Neel Chauhan wrote:
&gt;&gt; 3. Implementation details
&gt;&gt; 
&gt;&gt;   The MiddleOnly flag can be assigned to relays whose IP addresses are
&gt;&gt;   configured at the directory authority level, similar to how the 
&gt;&gt; BadExit flag
&gt;&gt;   currently works. In short, if a relay's IP is designated as 
&gt;&gt; middle-only, it
&gt;&gt;   must assign the MiddleOnly flag, otherwise we must not assign it.
&gt; 
&gt; Note: a unique identifier of relays is by relay identity key (its
&gt; fingerprint), not the IP address. However, it is true we do reject 
&gt; relays
&gt; based on fingerprint and address most of the times so I think it would 
&gt; be
&gt; better to also specify the fingerprint approach as well.

IMHO there are two sides to the coin.

If a malicious relay is MiddleOnly'd by its fignerprint, it could rekey 
and possibly become an guard/exit again.

However, a malicious relay operator could also change IPs (e.g. cloud) 
while keeping the fingerprint the same.

However, my updated proposal adds the fingerprint section.

&gt;&gt;   Relays which haven't gotten the Guard or Exit flags yet but have IP 
&gt;&gt; addresses
&gt;&gt;   that aren't designated as middle-only in the dirauths must not get 
&gt;&gt; the
&gt;&gt;   MiddleOnly flag. This is to allow new entry guards and exit relays 
&gt;&gt; to enter
&gt;&gt;   the Tor network, while giving relay administrators flexibility to 
&gt;&gt; increase
&gt;&gt;   and reduce bandwidth, or change their exit policy.
&gt;&gt; 
&gt;&gt; 3.1. Client Implementation
&gt;&gt; 
&gt;&gt;   Clients should interpret the MiddleOnly flag while parsing relay 
&gt;&gt; descriptors
&gt;&gt;   to determine whether a relay is to be avoided for non-middle 
&gt;&gt; purposes. If
&gt;&gt;   a client parses the MiddleOnly flag, it must not use 
&gt;&gt; MiddleOnly-designated
&gt;&gt;   relays as entry guards or exit relays.
&gt;&gt; 
&gt;&gt; 3.2. MiddleOnly Relay Purposes
&gt;&gt; 
&gt;&gt;   If a relay has the MiddleOnly flag, we do not allow it to be used 
&gt;&gt; for the
&gt;&gt;   following purposes:
&gt;&gt; 
&gt;&gt;    * Entry Guard
&gt;&gt; 
&gt;&gt;    * Directory Guard
&gt;&gt; 
&gt;&gt;    * Exit Relay
&gt;&gt; 
&gt;&gt;   The reason for this is to prevent a misconfigured relay from being 
&gt;&gt; used
&gt;&gt;   in places where they may know about clients or destination traffic. 
&gt;&gt; This
&gt;&gt;   is in case certain misconfigured relays are used to deanonymize 
&gt;&gt; clients.
&gt;&gt; 
&gt;&gt;   We could also bar a MiddleOnly relay from other purposes such as 
&gt;&gt; rendezvous
&gt;&gt;   and fallback directory purposes. However, while more secure in 
&gt;&gt; theory, this
&gt;&gt;   adds unnecessary complexity to the Tor design and has the 
&gt;&gt; possibility of
&gt;&gt;   breaking clients that aren't MiddleOnly-aware [2].
&gt; 
&gt; Can we have a note on why HSDir, Intro and Rendezvous relays have not 
&gt; been put
&gt; in that list?

I believe Roger sent me a writeup where it would add a lot of complexity 
to the tor code: 
https://lists.torproject.org/pipermail/tor-dev/2021-September/014627.html

I can agree with him, would we want another Windows "Longhorn"/Vista and 
get something so mired in complexity?

&gt;&gt; 
&gt;&gt; 4. Consensus Considerations
&gt;&gt; 
&gt;&gt; 4.1. Consensus Methods
&gt;&gt; 
&gt;&gt;   We propose a new consensus method 32, which is to only use this flag 
&gt;&gt; if and
&gt;&gt;   when all authorities understand the flag and agree on it. This is 
&gt;&gt; because the
&gt;&gt;   MiddleOnly flag impacts path selection for clients.
&gt;&gt; 
&gt;&gt; 4.2. Consensus Requirements
&gt;&gt; 
&gt;&gt;   On the directory authorities, similar to the BadExit flag, if one 
&gt;&gt; dirauth
&gt;&gt;   gives a relay the MiddleOnly flag, we should mark the MiddleOnly 
&gt;&gt; flag for
&gt;&gt;   the relay even if other dirauths didn't add the flag.
&gt; 
&gt; I'm a tiny bit skeptical about this here. This is a whole lot of power 
&gt; for one
&gt; dirauth.
&gt; 
&gt; The idea behind enforcing a consensus method is that a majority of 
&gt; authorities
&gt; would vote on MiddleOnly and not very few.
&gt; 
&gt; It is true that there is often a delay with a majority of authorities 
&gt; agreeing
&gt; on a flag from the time the health team flag a relay MiddleOnly.
&gt; 
&gt; However, I'm not sure we should always let 1 authority dictate that 
&gt; flag
&gt; regardless of what the others think.
&gt; 
&gt; It is _not_ common but it had happened in the past that TPO's health 
&gt; team
&gt; would recommend to reject a relay and few authorities agreed to do it 
&gt; but not
&gt; the majority as the rest didn't find the reasons good enough and so the 
&gt; relay
&gt; was never rejected in the end because lack of majority.
&gt; 
&gt; That is a bit the last last safe guard of the authority protocol here 
&gt; which is
&gt; that an actual trusted operators makes the ultimate decision to reject 
&gt; or not
&gt; based on the information provided by the health team. And this works if 
&gt; every
&gt; decision needs majority.
&gt; 
&gt; Adding that requirement would not allow this and so like rejecting a 
&gt; relay
&gt; from the consensus, I think we need to enforce majority here and not 
&gt; have one
&gt; single authority dictate it.
&gt; 
&gt; Thoughts?

The majority system does sound good to me.

&gt; Thanks!
&gt; David

I have an updated proposal with your suggestions, but will read

Sorry if I couldn't get back to you earlier. Yesterday, my team at 
$DAYJOB decided to go back to the office, and outside of work hours, I 
have been wrangling with a fiber ISP with massive latency spikes which 
prevents me from running a Tor relay at home.

No problem,

Neel
["334-middle-only-flag.txt" (text/plain)]

Filename: 334-middle-only-flag.txt
Title: A Directory Authority flag to mark Relays as Middle-only
Author: Neel Chauhan
Created: 2021-09-07
Status: Open

1. Introduction

  The Health Team often deals with a large number of relays with an incorrect
  configuration (e.g. not all relays in MyFamily), or needs validation that
  requires contacting the relay operator. It is desirable to put the said
  relays in a less powerful position, such as a middle only flag that prevents
  a relay from being used in more powerful positions like an entry guard or an
  exit relay. [1]

1.1. Motivation

  The proposed middle-only flag is needed by the Health Team to prevent
  misconfigured relays from being used in positions capable of deanonymizing
  users while the team evaluates the relay's risk to the network. An example
  of this scenario is when a guard and exit relay run by the same operator
  has an incomplete MyFamily, and the same operator's guard and exit are used
  in a circuit.

  The reason why we won't play with the Guard and Exit flags or weights to
  achieve the same goal is because even if we were to reduce the guard and
  exit weights of a misconfigured relay, it could keep some users at risk of
  deanonymization. Even a small fraction of users at risk of deanonymization
  isn't something we should aim for.

  One case we could look out for is if all relays are exit relays (unlikely),
  or if walking onions are working on the current Tor network. This proposal
  should not affect those scenarios, but we should watch out for these cases.

2. The MiddleOnly Flag

  We propose a consensus flag MiddleOnly. As mentioned earlier, relays will be
  assigned this flag from the directory authorities.

  What this flag does is that a relay must not be used as an entry guard or
  exit relay. This is to prevent issues with a misconfigured relay as described
  in Section 1 (Introduction) while the Health Team assesses the risk with the
  relay.

3. Implementation details

  The MiddleOnly flag can be assigned to relays whose IP addresses and/or
  fingerprints are configured at the directory authority level, similar to
  how the BadExit flag currently works. In short, if a relay's IP is
  designated as middle-only, it must assign the MiddleOnly flag, otherwise
  we must not assign it.

  Relays which haven't gotten the Guard or Exit flags yet but have IP addresses
  that aren't designated as middle-only in the dirauths must not get the
  MiddleOnly flag. This is to allow new entry guards and exit relays to enter
  the Tor network, while giving relay administrators flexibility to increase
  and reduce bandwidth, or change their exit policy.

3.1. Client Implementation

  Clients should interpret the MiddleOnly flag while parsing relay descriptors
  to determine whether a relay is to be avoided for non-middle purposes. If
  a client parses the MiddleOnly flag, it must not use MiddleOnly-designated
  relays as entry guards or exit relays.

3.2. MiddleOnly Relay Purposes

  If a relay has the MiddleOnly flag, we do not allow it to be used for the
  following purposes:

   * Entry Guard

   * Directory Guard

   * Exit Relay

  The reason for this is to prevent a misconfigured relay from being used
  in places where they may know about clients or destination traffic. This
  is in case certain misconfigured relays are used to deanonymize clients.

  We could also bar a MiddleOnly relay from other purposes such as rendezvous
  and fallback directory purposes. However, while more secure in theory, this
  adds unnecessary complexity to the Tor design and has the possibility of
  breaking clients that aren't MiddleOnly-aware [2].

4. Consensus Considerations

4.1. Consensus Methods

  We propose a new consensus method 32, which is to only use this flag if and
  when all authorities understand the flag and agree on it. This is because the
  MiddleOnly flag impacts path selection for clients.

4.2. Consensus Requirements

  The MiddleOnly flag would work like most other consensus flags where a
  majority of dirauths have to assign a relay the flag in order for a relay
  to have the MiddleOnly flag.

  Another approach is to make it that only one dirauth is needed to give
  relays this flag, however it would put too much power in the hands of a
  single directory authority servre [3].

5. Acknowledgements

  Thank you so much to nusenu, s7r, David Goulet, and Roger Dingledine for your
  suggestions to Prop334. My proposal wouldn't be what it is without you.

6. Citations

  [1] - https://gitlab.torproject.org/tpo/core/tor/-/issues/40448

  [2] - https://lists.torproject.org/pipermail/tor-dev/2021-September/014627.html

  [3] - https://lists.torproject.org/pipermail/tor-dev/2021-September/014630.html


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210917230230</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-09-17 23:02:30-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi Neel,

it would be great if you could open a MR for the proposal so we can always see the \
latest version and changes there.
(Over time it became unclear what comments have already been addressed in the text an \
which didn't.)

kind regards,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210917230943</emailId><senderName>Neel Chauhan</senderName><senderEmail>neel@neelc.org</senderEmail><timestampReceived>2021-09-17 23:09:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

Hi nusenu (and tor-dev@),

On 2021-09-17 16:02, nusenu wrote:
&gt; it would be great if you could open a MR for the proposal so we can
&gt; always see the latest version and changes
&gt; there.
&gt; (Over time it became unclear what comments have already been addressed
&gt; in the text an which didn't.)

Done: https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/46

&gt; kind regards,
&gt; nusenu

-Neel
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210614102456</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-06-14 10:24:56-0400</timestampReceived><subject>Re: [tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

Chad Retz &lt;chad.retz@gmail.com&gt; writes:

&gt; A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"
&gt; onion services) doesn't support setting an Onionbalance
&gt; frontend/master onion address (specifically
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/32709 doesn't seem
&gt; to have a control-side analogue). Would a feature request for adding a
&gt; `*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or whatever)
&gt; to ADD_ONION be reasonable? If so, just add in Gitlab?
&gt; 

Hell Ched,

that's indeed something that is missing and a reasonable feature
request. A spec/code patch would be particularly welcome ;)

&gt; Also curious alternative scalability and load balancing options for
&gt; ephemeral v3 onion services. I have read
&gt; https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf
&gt; but unsure if anything more recent has been written. Beyond that and
&gt; Onionbalance, any other interesting approaches I could employ
&gt; (assuming I can dev anything from a control port pov, but am wanting
&gt; to work w/ an unmodified Tor binary)?
&gt; 

Another complementary approach is to split the 'introduction' and
'rendezvous' functionalities to different hosts:
             https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt
 However it hasn't been implemented yet...

Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210616132835</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-06-16 13:28:35-0400</timestampReceived><subject>Re: [tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

[Attachment #2 (multipart/alternative)]


Would this return a list of currently-online onion addresses in possession
of the frontend address key?

Or would it just route traffic to one of those addresses invisibly?

For our application (a messaging app) it would be super useful to get the
full list of known online (or recently seen online) onion addresses in
possession of some frontend key. This would let us use onionbalance for
peer discovery instead of blindly trying the set of all known peers, which
won't work well for large groups / large numbers of peers.

I'd be interested in working with others on a spec for this!

On Mon, Jun 14, 2021 at 6:25 AM George Kadianakis &lt;desnacked@riseup.net&gt;
wrote:

&gt; Chad Retz &lt;chad.retz@gmail.com&gt; writes:
&gt;
&gt; &gt; A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"
&gt; &gt; onion services) doesn't support setting an Onionbalance
&gt; &gt; frontend/master onion address (specifically
&gt; &gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/32709 doesn't seem
&gt; &gt; to have a control-side analogue). Would a feature request for adding a
&gt; &gt; `*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or whatever)
&gt; &gt; to ADD_ONION be reasonable? If so, just add in Gitlab?
&gt; &gt;
&gt;
&gt; Hell Ched,
&gt;
&gt; that's indeed something that is missing and a reasonable feature
&gt; request. A spec/code patch would be particularly welcome ;)
&gt;
&gt; &gt; Also curious alternative scalability and load balancing options for
&gt; &gt; ephemeral v3 onion services. I have read
&gt; &gt;
&gt; https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf
&gt; &gt; but unsure if anything more recent has been written. Beyond that and
&gt; &gt; Onionbalance, any other interesting approaches I could employ
&gt; &gt; (assuming I can dev anything from a control port pov, but am wanting
&gt; &gt; to work w/ an unmodified Tor binary)?
&gt; &gt;
&gt;
&gt; Another complementary approach is to split the 'introduction' and
&gt; 'rendezvous' functionalities to different hosts:
&gt;
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt
&gt; However it hasn't been implemented yet...
&gt;
&gt; Cheers!
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="auto"&gt;Would this return a list of currently-online onion addresses in \
possession of the frontend address key?&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto"&gt;Or would it just route traffic to one of those addresses \
invisibly?&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;For our application (a \
messaging app) it would be super useful to get the full list of known online (or \
recently seen online) onion addresses in possession of some frontend key. This would \
let us use onionbalance for peer discovery instead of blindly trying the set of all \
known peers, which won't work well for large groups / large numbers of \
peers.&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;I'd be interested in \
working with others on a spec for this!&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Mon, Jun 14, 2021 at 6:25 AM George Kadianakis &lt;&lt;a \
href="mailto:desnacked@riseup.net"&gt;desnacked@riseup.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex"&gt;Chad Retz &lt;&lt;a \
href="mailto:chad.retz@gmail.com" target="_blank"&gt;chad.retz@gmail.com&lt;/a&gt;&gt; \
writes:&lt;br&gt; &lt;br&gt;
&gt; A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"&lt;br&gt;
&gt; onion services) doesn't support setting an Onionbalance&lt;br&gt;
&gt; frontend/master onion address (specifically&lt;br&gt;
&gt; &lt;a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/32709" \
rel="noreferrer" target="_blank"&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/32709&lt;/a&gt; \
doesn't seem&lt;br&gt; &gt; to have a control-side analogue). Would a feature request \
for adding a&lt;br&gt; &gt; `*(SP "OnionbalanceMasterKey=" OBKey)` (or \
"OBMasterKey" or whatever)&lt;br&gt; &gt; to ADD_ONION be reasonable? If so, just \
add in Gitlab?&lt;br&gt; &gt;&lt;br&gt;
&lt;br&gt;
Hell Ched,&lt;br&gt;
&lt;br&gt;
that's indeed something that is missing and a reasonable feature&lt;br&gt;
request. A spec/code patch would be particularly welcome ;)&lt;br&gt;
&lt;br&gt;
&gt; Also curious alternative scalability and load balancing options for&lt;br&gt;
&gt; ephemeral v3 onion services. I have read&lt;br&gt;
&gt; &lt;a href="https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf" \
rel="noreferrer" target="_blank"&gt;https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf&lt;/a&gt;&lt;br&gt;
 &gt; but unsure if anything more recent has been written. Beyond that and&lt;br&gt;
&gt; Onionbalance, any other interesting approaches I could employ&lt;br&gt;
&gt; (assuming I can dev anything from a control port pov, but am wanting&lt;br&gt;
&gt; to work w/ an unmodified Tor binary)?&lt;br&gt;
&gt;&lt;br&gt;
&lt;br&gt;
Another complementary approach is to split the 'introduction' and&lt;br&gt;
'rendezvous' functionalities to different hosts:&lt;br&gt;
                    &lt;a \
href="https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt" \
rel="noreferrer" target="_blank"&gt;https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt&lt;/a&gt;&lt;br&gt;
 However it hasn't been implemented yet...&lt;br&gt;
&lt;br&gt;
Cheers!&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210723210101</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-07-23 21:01:01-0400</timestampReceived><subject>Re: [tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

[Attachment #2 (multipart/alternative)]


Hi George,

Sorry for the slow reply here! Just getting back to this. 

&gt; &gt; For our application (a messaging app) it would be super useful to get the
&gt; &gt; full list of known online (or recently seen online) onion addresses in
&gt; &gt; possession of some frontend key. This would let us use onionbalance for
&gt; &gt; peer discovery instead of blindly trying the set of all known peers, which
&gt; &gt; won't work well for large groups / large numbers of peers.
&gt; &gt; 
&gt; 
&gt; Hmm, can you please give us some more details on what you are looking
&gt; for? What is peer discovery in the above context, and what do you mean
&gt; with "full list of ... onion addresses in possession of some frontend
&gt; key"? I'm asking because the frontend key of onionbalance is also the
&gt; onion address that users should access.

Our context is we are building a Discord-like team messaging app where peers are \
connected to each other over Tor, via onion addresses, rather than to a central \
server. So each user connects to a few peers, and messages travel across peers on a \
gossip network, and there's a mechanism for syncing messages you missed, say, if you \
went offline for a bit. 

One problem we have is, when a new peer comes online, how do they know which other \
peers are online? Right now, they can try all of the peers they know about, or \
perhaps try recently-seen peers. But if there are hundreds of peers and only a few \
are currently online, it will be necessary to try many unreachable peers before \
finding one who's online. So that's not ideal.

One solution to this would be for each online peer to host the same onion service, \
using a shared key, in addition to their normal peer onion address. And at this \
address they could return a list of peers they knew were online. So a user would just \
have to connect to one address, at which point the Tor network would connect them to \
some online peer, and then that peer could tell them about other online peers. The \
problem with this approach, as pointed out by folks on this list, was that all those \
peers would have to really trust each other, since any one of them could go rogue and \
host malicious information instead of the peer list, gumming up the works. I'm not \
sure this is a fatal problem, since it would still *help* in cases where there wasn't \
a malicious peer, and users could still fall back to the slower method of trying \
every peer. 

But what I'm wondering is whether there is any mechanism for a bunch of onion \
addresses that *don't* completely trust each other to share a "meta" onion address on \
the Tor network, such that when the user looks up that identifier instead of getting \
connected directly to whatever content one of those onion addresses is serving, they \
get a list of all onion addresses that hold the keys to the "meta" address. 

It'd be like asking Tor, "show me a list of all onion addresses that have registered \
this meta address." Sort of like asking, "show me a list of mirrors for this \
address…" at which point the user could try connecting to one or more of them, but \
would not have as serious problem if one of the sites went rogue and started serving \
useless content.

This is a bit of a long explanation, and my guess is that there isn't anything like \
this and that the above scenario isn't common enough to be worth targeting, but I was \
curious if anything like this had ever been discussed.

Thanks!
Holmes

&gt; 
&gt; Cheers!
&gt; 
&gt; 
&gt; &gt; I'd be interested in working with others on a spec for this!
&gt; &gt; 
&gt; &gt; On Mon, Jun 14, 2021 at 6:25 AM George Kadianakis &lt;desnacked@riseup.net&gt;
&gt; &gt; wrote:
&gt; &gt; 
&gt; &gt; &gt; Chad Retz &lt;chad.retz@gmail.com&gt; writes:
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"
&gt; &gt; &gt; &gt; onion services) doesn't support setting an Onionbalance
&gt; &gt; &gt; &gt; frontend/master onion address (specifically
&gt; &gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/32709 doesn't seem
&gt; &gt; &gt; &gt; to have a control-side analogue). Would a feature request for adding a
&gt; &gt; &gt; &gt; `*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or whatever)
&gt; &gt; &gt; &gt; to ADD_ONION be reasonable? If so, just add in Gitlab?
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; Hell Ched,
&gt; &gt; &gt; 
&gt; &gt; &gt; that's indeed something that is missing and a reasonable feature
&gt; &gt; &gt; request. A spec/code patch would be particularly welcome ;)
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Also curious alternative scalability and load balancing options for
&gt; &gt; &gt; &gt; ephemeral v3 onion services. I have read
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf
&gt; &gt; &gt; &gt; but unsure if anything more recent has been written. Beyond that and
&gt; &gt; &gt; &gt; Onionbalance, any other interesting approaches I could employ
&gt; &gt; &gt; &gt; (assuming I can dev anything from a control port pov, but am wanting
&gt; &gt; &gt; &gt; to work w/ an unmodified Tor binary)?
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; Another complementary approach is to split the 'introduction' and
&gt; &gt; &gt; 'rendezvous' functionalities to different hosts:
&gt; &gt; &gt; 
&gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt
&gt; &gt; &gt;  However it hasn't been implemented yet...
&gt; &gt; &gt; 
&gt; &gt; &gt; Cheers!
&gt; &gt; &gt; _______________________________________________
&gt; &gt; &gt; tor-dev mailing list
&gt; &gt; &gt; tor-dev@lists.torproject.org
&gt; &gt; &gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; &gt; &gt; 
&gt; &gt; _______________________________________________
&gt; &gt; tor-dev mailing list
&gt; &gt; tor-dev@lists.torproject.org &lt;mailto:tor-dev@lists.torproject.org&gt;
&gt; &gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev \
&gt; &gt; &lt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&gt;


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;Hi George,&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Sorry for the slow reply here! Just getting back to \
this. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;div&gt;&lt;blockquote \
type="cite" class=""&gt;&lt;div class=""&gt;&lt;blockquote type="cite" style="font-family: \
Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; \
font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; \
text-indent: 0px; text-transform: none; white-space: normal; widows: auto; \
word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; \
text-decoration: none;" class=""&gt;For our application (a messaging app) it would be \
super useful to get the&lt;br class=""&gt;full list of known online (or recently seen \
online) onion addresses in&lt;br class=""&gt;possession of some frontend key. This would \
let us use onionbalance for&lt;br class=""&gt;peer discovery instead of blindly trying the \
set of all known peers, which&lt;br class=""&gt;won't work well for large groups / large \
numbers of peers.&lt;br class=""&gt;&lt;br class=""&gt;&lt;/blockquote&gt;&lt;br style="caret-color: \
rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; font-style: normal; \
font-variant-caps: normal; font-weight: normal; letter-spacing: normal; text-align: \
start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: \
0px; -webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none; \
float: none; display: inline !important;" class=""&gt;Hmm, can you please give us some \
more details on what you are looking&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); \
font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none; \
float: none; display: inline !important;" class=""&gt;for? What is peer discovery in the \
above context, and what do you mean&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); \
font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none; \
float: none; display: inline !important;" class=""&gt;with "full list of ... onion \
addresses in possession of some frontend&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); \
font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none; \
float: none; display: inline !important;" class=""&gt;key"? I'm asking because the \
frontend key of onionbalance is also the&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); \
font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;span \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none; \
float: none; display: inline !important;" class=""&gt;onion address that users should \
access.&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); font-family: Helvetica; \
font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none;" class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;Our \
context is we are building a Discord-like team messaging app where peers are \
connected to each other over Tor, via onion addresses, rather than to a central \
server. So each user connects to a few peers, and messages travel across peers on a \
gossip network, and there's a mechanism for syncing messages you missed, say, if you \
went offline for a bit. &lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;One problem we have \
is, when a new peer comes online, how do they know which other peers are online? \
Right now, they can try all of the peers they know about, or perhaps try \
recently-seen peers. But if there are hundreds of peers and only a few are currently \
online, it will be necessary to try many unreachable peers before finding one who's \
online. So that's not ideal.&lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;One solution to this \
would be for each online peer to host the same onion service, using a shared key, in \
addition to their normal peer onion address. And at this address they could return a \
list of peers they knew were online. So a user would just have to connect to one \
address, at which point the Tor network would connect them to some online peer, and \
then that peer could tell them about other online peers. The problem with this \
approach, as pointed out by folks on this list, was that all those peers would have \
to really trust each other, since any one of them could go rogue and host malicious \
information instead of the peer list, gumming up the works. I'm not sure this is a \
fatal problem, since it would still *help* in cases where there wasn't a malicious \
peer, and users could still fall back to the slower method of trying every \
peer. &lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;But what I'm wondering is whether there \
is any mechanism for a bunch of onion addresses that *don't* completely trust each \
other to share a "meta" onion address on the Tor network, such that when the user \
looks up that identifier instead of getting connected directly to whatever content \
one of those onion addresses is serving, they get a list of all onion addresses that \
hold the keys to the "meta" address. &lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;It'd be \
like asking Tor, "show me a list of all onion addresses that have registered this \
meta address." Sort of like asking, "show me a list of mirrors for this address…" \
at which point the user could try connecting to one or more of them, but would not \
have as serious problem if one of the sites went rogue and started serving useless \
content.&lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;This is a bit of a long explanation, and \
my guess is that there isn't anything like this and that the above scenario isn't \
common enough to be worth targeting, but I was curious if anything like this had ever \
been discussed.&lt;/div&gt;&lt;div&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div&gt;Thanks!&lt;/div&gt;&lt;div&gt;Holmes&lt;/div&gt;&lt;div&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;blockquote type="cite" class=""&gt;&lt;div class=""&gt;&lt;br \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;span style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: \
12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none; float: none; display: inline !important;" \
class=""&gt;Cheers!&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, 0); font-family: Helvetica; \
font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none;" class=""&gt;&lt;br style="caret-color: rgb(0, 0, 0); font-family: \
Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; \
font-weight: normal; letter-spacing: normal; text-align: start; text-indent: 0px; \
text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;&lt;br \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;blockquote type="cite" style="font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;I'd be interested in \
working with others on a spec for this!&lt;br class=""&gt;&lt;br class=""&gt;On Mon, Jun 14, 2021 \
at 6:25 AM George Kadianakis &lt;&lt;a href="mailto:desnacked@riseup.net" \
class=""&gt;desnacked@riseup.net&lt;/a&gt;&gt;&lt;br class=""&gt;wrote:&lt;br class=""&gt;&lt;br \
class=""&gt;&lt;blockquote type="cite" class=""&gt;Chad Retz &lt;&lt;a \
href="mailto:chad.retz@gmail.com" class=""&gt;chad.retz@gmail.com&lt;/a&gt;&gt; writes:&lt;br \
class=""&gt;&lt;br class=""&gt;&lt;blockquote type="cite" class=""&gt;A quick glance at the code \
shows that ADD_ONION (i.e. "ephemeral"&lt;br class=""&gt;onion services) doesn't support \
setting an Onionbalance&lt;br class=""&gt;frontend/master onion address (specifically&lt;br \
class=""&gt;&lt;a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/32709" \
class=""&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/32709&lt;/a&gt; doesn't \
seem&lt;br class=""&gt;to have a control-side analogue). Would a feature request for adding \
a&lt;br class=""&gt;`*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or \
whatever)&lt;br class=""&gt;to ADD_ONION be reasonable? If so, just add in Gitlab?&lt;br \
class=""&gt;&lt;br class=""&gt;&lt;/blockquote&gt;&lt;br class=""&gt;Hell Ched,&lt;br class=""&gt;&lt;br \
class=""&gt;that's indeed something that is missing and a reasonable feature&lt;br \
class=""&gt;request. A spec/code patch would be particularly welcome ;)&lt;br class=""&gt;&lt;br \
class=""&gt;&lt;blockquote type="cite" class=""&gt;Also curious alternative scalability and \
load balancing options for&lt;br class=""&gt;ephemeral v3 onion services. I have read&lt;br \
class=""&gt;&lt;br class=""&gt;&lt;/blockquote&gt;&lt;a \
href="https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf" \
class=""&gt;https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf&lt;/a&gt;&lt;br \
class=""&gt;&lt;blockquote type="cite" class=""&gt;but unsure if anything more recent has been \
written. Beyond that and&lt;br class=""&gt;Onionbalance, any other interesting approaches I \
could employ&lt;br class=""&gt;(assuming I can dev anything from a control port pov, but am \
wanting&lt;br class=""&gt;to work w/ an unmodified Tor binary)?&lt;br class=""&gt;&lt;br \
class=""&gt;&lt;/blockquote&gt;&lt;br class=""&gt;Another complementary approach is to split the \
'introduction' and&lt;br class=""&gt;'rendezvous' functionalities to different hosts:&lt;br \
class=""&gt;&lt;br class=""&gt;https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt&lt;br \
class=""&gt;However it hasn't been implemented yet...&lt;br class=""&gt;&lt;br \
class=""&gt;Cheers!&lt;br class=""&gt;_______________________________________________&lt;br \
class=""&gt;tor-dev mailing list&lt;br class=""&gt;tor-dev@lists.torproject.org&lt;br \
class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;br \
class=""&gt;&lt;br class=""&gt;&lt;/blockquote&gt;_______________________________________________&lt;br \
class=""&gt;tor-dev mailing list&lt;br class=""&gt;&lt;a \
href="mailto:tor-dev@lists.torproject.org" \
class=""&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br class=""&gt;&lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" \
class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210503205939</emailId><senderName>Miguel Jacq</senderName><senderEmail>mig@mig5.net</senderEmail><timestampReceived>2021-05-03 20:59:39-0400</timestampReceived><subject>Re: [tor-dev] ClientAuthV3 for v3 onions via Tor controller is accepted by ADD_ONION but seems to ge</subject><body>

[Attachment #2 (multipart/signed)]


Hello again, just to add some clarification to what I realise is a confusing output \
below:

On Mon, May 03, 2021 at 04:38:07PM +1000, Miguel Jacq wrote:
&gt; ```
&gt; user@onionshare:~$ sudo telnet localhost 9051
&gt; Trying ::1...
&gt; Trying 127.0.0.1...
&gt; Connected to localhost.
&gt; Escape character is '^]'.
&gt; authenticate ""
&gt; 250 OK
&gt; ADD_ONION ED25519-V3:MNkxu0oI0CX6Oq1AEroRGSAiqXurEbzBdraDKJB1pkNkl9hNCr+bagdAg7gA4F3M/FrF7BHBdh5zdvkHB7oO4w== \
&gt; ClientAuthV3=FGTORMIDKR7T2PR632HSHLWA4G6HF5TCWSGMHDUU4LWBEFTAVYQQ Flags=V3Auth \
&gt; Port=80,9735 250-ServiceID=rujvluxdgiibem3odopgkgiiajgtwfbdgkuqfyydhl5qupotpwyxjaid
&gt; 250-ClientAuthV3=AUEFTXH34ZVRXIIVOK5G7XLHTUXGVRLLXG7DG3NKJLRCVSEEHQDQ
&gt; 250 OK
&gt; ```

The public key is different in the request and response here, that's my copy-paste \
fail.. I had 'lost' the original private key and wanted to provide a valid pair for \
someone to troubleshoot with. As a result I amended my output here to show the new \
public key being sent in the ADD_ONION, but forgot to update it in the returned \
response from my earlier attempt. Sorry if it added confusion.

The problem still stands that the ClientAuthV3 key is accepted by ADD_ONION in the \
nightly/alpha Tor, but it doesn't then seem to be enforced when viewing the onion \
service.. unless I'm doing something wrong.

Appreciate any help, cheers!

mig5


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210403002223</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-04-03 00:22:23-0400</timestampReceived><subject>Re: [tor-dev] Question about hidden services shared by multiple hosts</subject><body>

[Attachment #2 (multipart/alternative)]


Interesting!

So it seems important to not have two clients hosting the same onion
address at the same time, which is doable, and then we have to figure out
this revision counter.

What happens if the revision counter is not incremented correctly?

Is it that the now offline host could become the destination for incoming
traffic to the onion address?

Thanks so much for this feedback!
Holmes




On Fri, Apr 2, 2021 at 1:41 PM David Goulet &lt;dgoulet@torproject.org&gt; wrote:

&gt; On 26 Mar (08:55:54), Holmes Wilson wrote:
&gt; &gt; Hi everyone,
&gt;
&gt; Greetings,
&gt;
&gt; &gt;
&gt; &gt; We're working on a peer-to-peer group chat app where peers connect over
&gt; v3
&gt; &gt; onion addresses.
&gt; &gt;
&gt; &gt; One issue are groups where there are many users but only a few are
&gt; online in
&gt; &gt; a given moment.  Onion addresses are forever, and existing peers might
&gt; know
&gt; &gt; every peer in the network, but it will take a while to try connecting to
&gt; all
&gt; &gt; of them to find one that is online.
&gt; &gt;
&gt; &gt; In this case, it seems helpful for one or more peers to share one or more
&gt; &gt; onion addresses that would serve as reliable  "trackers", e.g.
&gt; &gt;
&gt; &gt; 1. All members know the keypairs for these addresses.
&gt; &gt; 2. All online members ping these addresses at random intervals to say
&gt; &gt;    they're online.
&gt; &gt; 3. If they can't connect to an address, they start hosting it themselves.
&gt; &gt;
&gt; &gt; We're going to start testing it, but we're wondering if folks here know
&gt; the
&gt; &gt; likely outcome of trying to "share" hosting of an onion service in this
&gt; &gt; spontaneous-volunteer sort of way and if there are downsides.
&gt; &gt;
&gt; &gt; I *think* the most important question is how long it takes for the
&gt; network
&gt; &gt; to stop routing incoming traffic to an offline client when there's an
&gt; online
&gt; &gt; one available. How long will the address likely be unreachable in one of
&gt; &gt; these transition moments, assuming some peer immediately detects that a
&gt; &gt; "tracker" onion address has gone offline and begins hosting it
&gt; themselves?
&gt; &gt; (And does this question make sense?)
&gt;
&gt; Interesting idea!
&gt;
&gt; So sharing onion address key material between peers can be fine until they
&gt; are
&gt; used at the same time. What will happen is that the two peers hosting the
&gt; same
&gt; onion address (service) will start competing on the onion service directory
&gt; side where service's upload what we call a "descriptor" which is what
&gt; client
&gt; fetch in order to initiate a connection to the service.
&gt;
&gt; With v3, it gets even more complicated actually because of the "revision
&gt; counter" in the descriptor which v2 didn't have.
&gt;
&gt; It is simply a number that keeps going up in the descriptor so the onion
&gt; service directory (relay) doesn't accept a previous descriptor (replay).
&gt; And
&gt; so, your two peers sharing the onion keys will require to somehow sync that
&gt; revision counter for your idea to work (located on disk in the state file,
&gt; "HidServRevCounter").
&gt;
&gt; Else, one will inevitably be higher than the other and thus will always
&gt; succeed where it will always fail for the other peer.
&gt;
&gt; One approach here, and it is a hack of course, is for the second peer
&gt; detecting that the onion is down to download the descriptor (offline one)
&gt; still on the directory, get the revision counter out of it
&gt; ("revision-counter"
&gt; field), do a +1 on it and set its state file with it. It is a hack but
&gt; would
&gt; work... You will likely have to deal with "descriptor not found anymore on
&gt; the
&gt; directories" and so you could bruteforce the revision counter from your
&gt; last
&gt; one like adding +1000 to it and that might do the trick. But I would
&gt; definitely avoid as much as possible brute forcing it by small steps else
&gt; your
&gt; service will add undesirable load to the network with a lot of upload
&gt; attempts.
&gt;
&gt; Now lets say you are able to pull that off, if I understand your question
&gt; correctly, once an onion address goes offline, if the other peer would
&gt; become
&gt; the service then few seconds later, all clients will be able to connect to
&gt; it.
&gt; In other words, launching a new service takes few seconds before it can be
&gt; reached. The new descriptor will be used by the directories immediately
&gt; upon
&gt; upload as long as the revision counter is higher than the previous one :).
&gt;
&gt; Hope this help!
&gt; David
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="auto"&gt;Interesting!  &lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;So it \
seems important to not have two clients hosting the same onion address at the same \
time, which is doable, and then we have to figure out this revision \
counter.&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;What happens if the revision \
counter is not incremented correctly?  &lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto"&gt;Is it that the now offline host could become the destination for incoming \
traffic to the onion address?&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;Thanks \
so much for this feedback!  &lt;/div&gt;&lt;div dir="auto"&gt;Holmes  &lt;/div&gt;&lt;div \
dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
dir="auto"&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Fri, Apr 2, 2021 at 1:41 PM David Goulet &lt;&lt;a \
href="mailto:dgoulet@torproject.org"&gt;dgoulet@torproject.org&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex"&gt;On 26 Mar (08:55:54), Holmes Wilson \
wrote:&lt;br&gt; &gt; Hi everyone,&lt;br&gt;
&lt;br&gt;
Greetings,&lt;br&gt;
&lt;br&gt;
&gt; &lt;br&gt;
&gt; We're working on a peer-to-peer group chat app where peers connect over v3&lt;br&gt;
&gt; onion addresses. &lt;br&gt;
&gt; &lt;br&gt;
&gt; One issue are groups where there are many users but only a few are online in&lt;br&gt;
&gt; a given moment.   Onion addresses are forever, and existing peers might know&lt;br&gt;
&gt; every peer in the network, but it will take a while to try connecting to all&lt;br&gt;
&gt; of them to find one that is online. &lt;br&gt;
&gt; &lt;br&gt;
&gt; In this case, it seems helpful for one or more peers to share one or more&lt;br&gt;
&gt; onion addresses that would serve as reliable   "trackers", e.g. &lt;br&gt;
&gt; &lt;br&gt;
&gt; 1. All members know the keypairs for these addresses.&lt;br&gt;
&gt; 2. All online members ping these addresses at random intervals to say&lt;br&gt;
&gt;      they're online.&lt;br&gt;
&gt; 3. If they can't connect to an address, they start hosting it themselves.&lt;br&gt;
&gt; &lt;br&gt;
&gt; We're going to start testing it, but we're wondering if folks here know the&lt;br&gt;
&gt; likely outcome of trying to "share" hosting of an onion service in this&lt;br&gt;
&gt; spontaneous-volunteer sort of way and if there are downsides.&lt;br&gt;
&gt; &lt;br&gt;
&gt; I *think* the most important question is how long it takes for the network&lt;br&gt;
&gt; to stop routing incoming traffic to an offline client when there's an online&lt;br&gt;
&gt; one available. How long will the address likely be unreachable in one of&lt;br&gt;
&gt; these transition moments, assuming some peer immediately detects that a&lt;br&gt;
&gt; "tracker" onion address has gone offline and begins hosting it themselves?&lt;br&gt;
&gt; (And does this question make sense?)&lt;br&gt;
&lt;br&gt;
Interesting idea!&lt;br&gt;
&lt;br&gt;
So sharing onion address key material between peers can be fine until they are&lt;br&gt;
used at the same time. What will happen is that the two peers hosting the same&lt;br&gt;
onion address (service) will start competing on the onion service directory&lt;br&gt;
side where service's upload what we call a "descriptor" which is what \
client&lt;br&gt; fetch in order to initiate a connection to the service.&lt;br&gt;
&lt;br&gt;
With v3, it gets even more complicated actually because of the "revision&lt;br&gt;
counter" in the descriptor which v2 didn't have.&lt;br&gt;
&lt;br&gt;
It is simply a number that keeps going up in the descriptor so the onion&lt;br&gt;
service directory (relay) doesn't accept a previous descriptor (replay). And&lt;br&gt;
so, your two peers sharing the onion keys will require to somehow sync that&lt;br&gt;
revision counter for your idea to work (located on disk in the state file,&lt;br&gt;
"HidServRevCounter").&lt;br&gt;
&lt;br&gt;
Else, one will inevitably be higher than the other and thus will always&lt;br&gt;
succeed where it will always fail for the other peer.&lt;br&gt;
&lt;br&gt;
One approach here, and it is a hack of course, is for the second peer&lt;br&gt;
detecting that the onion is down to download the descriptor (offline one)&lt;br&gt;
still on the directory, get the revision counter out of it \
("revision-counter"&lt;br&gt; field), do a +1 on it and set its state file with \
it. It is a hack but would&lt;br&gt; work... You will likely have to deal with \
"descriptor not found anymore on the&lt;br&gt; directories" and so you could \
bruteforce the revision counter from your last&lt;br&gt; one like adding +1000 to it and \
that might do the trick. But I would&lt;br&gt; definitely avoid as much as possible brute \
forcing it by small steps else your&lt;br&gt; service will add undesirable load to the \
network with a lot of upload&lt;br&gt; attempts.&lt;br&gt;
&lt;br&gt;
Now lets say you are able to pull that off, if I understand your question&lt;br&gt;
correctly, once an onion address goes offline, if the other peer would become&lt;br&gt;
the service then few seconds later, all clients will be able to connect to it.&lt;br&gt;
In other words, launching a new service takes few seconds before it can be&lt;br&gt;
reached. The new descriptor will be used by the directories immediately upon&lt;br&gt;
upload as long as the revision counter is higher than the previous one :).&lt;br&gt;
&lt;br&gt;
Hope this help!&lt;br&gt;
David&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210406103747</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-04-06 10:37:47-0400</timestampReceived><subject>Re: [tor-dev] Question about hidden services shared by multiple hosts</subject><body>

David Goulet &lt;dgoulet@torproject.org&gt; writes:

&gt; On 26 Mar (08:55:54), Holmes Wilson wrote:
&gt;&gt; Hi everyone,
&gt;
&gt; Greetings,
&gt;
&gt;&gt; 
&gt;&gt; We're working on a peer-to-peer group chat app where peers connect over v3
&gt;&gt; onion addresses. 
&gt;&gt; 
&gt;&gt; One issue are groups where there are many users but only a few are online in
&gt;&gt; a given moment.  Onion addresses are forever, and existing peers might know
&gt;&gt; every peer in the network, but it will take a while to try connecting to all
&gt;&gt; of them to find one that is online. 
&gt;&gt; 
&gt;&gt; In this case, it seems helpful for one or more peers to share one or more
&gt;&gt; onion addresses that would serve as reliable  "trackers", e.g. 
&gt;&gt; 
&gt;&gt; 1. All members know the keypairs for these addresses.
&gt;&gt; 2. All online members ping these addresses at random intervals to say
&gt;&gt;    they're online.
&gt;&gt; 3. If they can't connect to an address, they start hosting it themselves.
&gt;&gt; 
&gt;&gt; We're going to start testing it, but we're wondering if folks here know the
&gt;&gt; likely outcome of trying to "share" hosting of an onion service in this
&gt;&gt; spontaneous-volunteer sort of way and if there are downsides.
&gt;&gt; 
&gt;&gt; I *think* the most important question is how long it takes for the network
&gt;&gt; to stop routing incoming traffic to an offline client when there's an online
&gt;&gt; one available. How long will the address likely be unreachable in one of
&gt;&gt; these transition moments, assuming some peer immediately detects that a
&gt;&gt; "tracker" onion address has gone offline and begins hosting it themselves?
&gt;&gt; (And does this question make sense?)
&gt;
&gt; Interesting idea!
&gt;
&gt; So sharing onion address key material between peers can be fine until they are
&gt; used at the same time. What will happen is that the two peers hosting the same
&gt; onion address (service) will start competing on the onion service directory
&gt; side where service's upload what we call a "descriptor" which is what client
&gt; fetch in order to initiate a connection to the service.
&gt;
&gt; With v3, it gets even more complicated actually because of the "revision
&gt; counter" in the descriptor which v2 didn't have.
&gt;
&gt; It is simply a number that keeps going up in the descriptor so the onion
&gt; service directory (relay) doesn't accept a previous descriptor (replay). And
&gt; so, your two peers sharing the onion keys will require to somehow sync that
&gt; revision counter for your idea to work (located on disk in the state file,
&gt; "HidServRevCounter").
&gt;
&gt; Else, one will inevitably be higher than the other and thus will always
&gt; succeed where it will always fail for the other peer.
&gt;

Hello all,

this revision counter sync issue is not a problem anymore since we
introduced the Order-Preserving-Encryption revision counter logic:
    https://gitlab.torproject.org/tpo/core/tor/-/blob/master/src/feature/hs/hs_service.c#L2979
    https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/rend-spec-v3.txt#L2548
Feel free to try it and let us know if it doesn't work. The solution
assumes that all peers have reasonably synchronized clocks.

In other news, the above "all members know all keypairs" approach seems
super dangerous in terms of security, especially if not all those
members are 100% trusted by each other.

To answer the performance question, if a peer immediately notices the
onion service being offline and begins hosting it, it should be
pretty-much immediately reachable by new clients.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210302180146</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-03-02 18:01:46-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

David Goulet &lt;dgoulet@torproject.org&gt; writes:

&gt; Greetings,
&gt;
&gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt;
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt;

Hello all,

while working on this proposal I had to change it slightly to add a few
more metrics and also to simplify some engineering issues that we would
encounter. You can find the changes here:
           https://gitlab.torproject.org/asn/torspec/-/commit/b57743b9764bd8e6ef8de689d14483b7ec9c91ec

Mike, based on your comments in the #40222 ticket, I would appreciate
comments on the way the DNS issues will be reported. David argued that
they should not be part of the "overload-general" line because they are
not an overload and it's not the fault of the network in any way. This
is why we added them as separate lines. Furthermore, David suggested we
turn them into a threshold "only report if 25% of the total requests
have timed out" instead of "only report if at least one time out has
occured" since that would be more useful.

We also decided to simplify the 'overload-ratelimits' line to make it
easier to implement (learning whether it was a burst or rate overload in
Tor seems to be quite hard, so we decided to merge these two events).

Cheers!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210302205843</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-03-02 20:58:43-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>



On 3/2/21 6:01 PM, George Kadianakis wrote:
&gt; 
&gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt; 
&gt;&gt; Greetings,
&gt;&gt;
&gt;&gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt;&gt;
&gt;&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt;&gt;
&gt; 
&gt; Hello all,
&gt; 
&gt; while working on this proposal I had to change it slightly to add a few
&gt; more metrics and also to simplify some engineering issues that we would
&gt; encounter. You can find the changes here:
&gt;            https://gitlab.torproject.org/asn/torspec/-/commit/b57743b9764bd8e6ef8de689d14483b7ec9c91ec
&gt; 
&gt; Mike, based on your comments in the #40222 ticket, I would appreciate
&gt; comments on the way the DNS issues will be reported. David argued that
&gt; they should not be part of the "overload-general" line because they are
&gt; not an overload and it's not the fault of the network in any way. This
&gt; is why we added them as separate lines. Furthermore, David suggested we
&gt; turn them into a threshold "only report if 25% of the total requests
&gt; have timed out" instead of "only report if at least one time out has
&gt; occured" since that would be more useful.

I'm confused by this confusion. There's pretty clear precedent for
treating packet drops as a sign of network capacity overload. We've also
seen it experimentally specifically with respect to DNS, during Rob's
experiment. We discussed this on Monday.

However, I agree there's a chance that a single packet drop can be
spurious, and/or could be due to ephemeral overload as TCP congestion
causes. But 25% is waaaaaaaaaay too high. Even 1% is high IMO, but is
more reasonable. We should ask some exits what they see now. The fact
that our DNS scanners are not currently seeing this at all, and the
issue appeared only for the exact duration of Rob's experiment, suggests
that DNS packets drops are extremely rare in healthy network conditions.

Furthermore, revealing the specific type of overload condition
increases the ability for the adversary to use this information for
various attacks. I'd rather it be combined in all cases, so that the
specific cause is not visible. In all cases, the reaction of our systems
should be the same: direct less load to relays with this line. If we
need to dig, that's what MetricsPort is for.

In fact, this DNS packet drop signal may be particularly useful in
traffic analysis attacks. Its reporting, and likely all of this overload
reporting, should probably be delayed until something like the top of
the hour after it happens. We may even want this delay to be a consensus
parameter. Something like "Report only after N minutes", or "Report only
N minute windows", perhaps?

&gt; We also decided to simplify the 'overload-ratelimits' line to make it
&gt; easier to implement (learning whether it was a burst or rate overload in
&gt; Tor seems to be quite hard, so we decided to merge these two events).

Ok, this makes sense.

-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210303073926</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2021-03-03 07:39:26-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Mike Perry:
&gt; 
&gt; 
&gt; On 3/2/21 6:01 PM, George Kadianakis wrote:
&gt;&gt;
&gt;&gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt;&gt;
&gt;&gt;&gt; Greetings,
&gt;&gt;&gt;
&gt;&gt;&gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt;&gt;&gt;
&gt;&gt;&gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Hello all,
&gt;&gt;
&gt;&gt; while working on this proposal I had to change it slightly to add a few
&gt;&gt; more metrics and also to simplify some engineering issues that we would
&gt;&gt; encounter. You can find the changes here:
&gt;&gt;            https://gitlab.torproject.org/asn/torspec/-/commit/b57743b9764bd8e6ef8de689d14483b7ec9c91ec
&gt;&gt;
&gt;&gt; Mike, based on your comments in the #40222 ticket, I would appreciate
&gt;&gt; comments on the way the DNS issues will be reported. David argued that
&gt;&gt; they should not be part of the "overload-general" line because they are
&gt;&gt; not an overload and it's not the fault of the network in any way. This
&gt;&gt; is why we added them as separate lines. Furthermore, David suggested we
&gt;&gt; turn them into a threshold "only report if 25% of the total requests
&gt;&gt; have timed out" instead of "only report if at least one time out has
&gt;&gt; occured" since that would be more useful.
&gt; 
&gt; I'm confused by this confusion. There's pretty clear precedent for
&gt; treating packet drops as a sign of network capacity overload. We've also
&gt; seen it experimentally specifically with respect to DNS, during Rob's
&gt; experiment. We discussed this on Monday.
&gt; 
&gt; However, I agree there's a chance that a single packet drop can be
&gt; spurious, and/or could be due to ephemeral overload as TCP congestion
&gt; causes. But 25% is waaaaaaaaaay too high. Even 1% is high IMO, but is
&gt; more reasonable. We should ask some exits what they see now. The fact
&gt; that our DNS scanners are not currently seeing this at all, and the
&gt; issue appeared only for the exact duration of Rob's experiment, suggests
&gt; that DNS packets drops are extremely rare in healthy network conditions.
&gt; 
&gt; Furthermore, revealing the specific type of overload condition
&gt; increases the ability for the adversary to use this information for
&gt; various attacks. I'd rather it be combined in all cases, so that the
&gt; specific cause is not visible. In all cases, the reaction of our systems
&gt; should be the same: direct less load to relays with this line. If we
&gt; need to dig, that's what MetricsPort is for.

+1

&gt; In fact, this DNS packet drop signal may be particularly useful in
&gt; traffic analysis attacks. Its reporting, and likely all of this overload
&gt; reporting, should probably be delayed until something like the top of
&gt; the hour after it happens. We may even want this delay to be a consensus
&gt; parameter. Something like "Report only after N minutes", or "Report only
&gt; N minute windows", perhaps?

That's a good idea, thanks. I am not sure we really need a consensus
parameter for that but some delay, which makes sure the DNS packet drop
does not aid in traffic analysis, seems indeed to be a smart idea.

Georg

&gt;&gt; We also decided to simplify the 'overload-ratelimits' line to make it
&gt;&gt; easier to implement (learning whether it was a burst or rate overload in
&gt;&gt; Tor seems to be quite hard, so we decided to merge these two events).
&gt; 
&gt; Ok, this makes sense.
&gt; 



["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210303131408</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-03-03 13:14:08-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

[Attachment #2 (multipart/signed)]


On 02 Mar (20:58:43), Mike Perry wrote:
&gt; 
&gt; 
&gt; On 3/2/21 6:01 PM, George Kadianakis wrote:
&gt; &gt; 
&gt; &gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt; &gt; 
&gt; &gt; &gt; Greetings,
&gt; &gt; &gt; 
&gt; &gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt; &gt; 
&gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; Hello all,
&gt; &gt; 
&gt; &gt; while working on this proposal I had to change it slightly to add a few
&gt; &gt; more metrics and also to simplify some engineering issues that we would
&gt; &gt; encounter. You can find the changes here:
&gt; &gt; https://gitlab.torproject.org/asn/torspec/-/commit/b57743b9764bd8e6ef8de689d14483b7ec9c91ec
&gt; &gt;  
&gt; &gt; Mike, based on your comments in the #40222 ticket, I would appreciate
&gt; &gt; comments on the way the DNS issues will be reported. David argued that
&gt; &gt; they should not be part of the "overload-general" line because they are
&gt; &gt; not an overload and it's not the fault of the network in any way. This
&gt; &gt; is why we added them as separate lines. Furthermore, David suggested we
&gt; &gt; turn them into a threshold "only report if 25% of the total requests
&gt; &gt; have timed out" instead of "only report if at least one time out has
&gt; &gt; occured" since that would be more useful.
&gt; 
&gt; I'm confused by this confusion. There's pretty clear precedent for
&gt; treating packet drops as a sign of network capacity overload. We've also
&gt; seen it experimentally specifically with respect to DNS, during Rob's
&gt; experiment. We discussed this on Monday.
&gt; 
&gt; However, I agree there's a chance that a single packet drop can be
&gt; spurious, and/or could be due to ephemeral overload as TCP congestion
&gt; causes. But 25% is waaaaaaaaaay too high. Even 1% is high IMO, but is
&gt; more reasonable. We should ask some exits what they see now. The fact
&gt; that our DNS scanners are not currently seeing this at all, and the
&gt; issue appeared only for the exact duration of Rob's experiment, suggests
&gt; that DNS packets drops are extremely rare in healthy network conditions.

Ok, likely 25% is way too high indeed.

The idea behind this was simply that a network hiccup or a temporary faulty
DNS server would not move away traffic from the Exit for a 72h period
(reminder that the "overload-general" sticks for 72h in the extrainfo once
hit).

&gt; 
&gt; Furthermore, revealing the specific type of overload condition
&gt; increases the ability for the adversary to use this information for
&gt; various attacks. I'd rather it be combined in all cases, so that the
&gt; specific cause is not visible. In all cases, the reaction of our systems
&gt; should be the same: direct less load to relays with this line. If we
&gt; need to dig, that's what MetricsPort is for.
&gt; 
&gt; In fact, this DNS packet drop signal may be particularly useful in
&gt; traffic analysis attacks. Its reporting, and likely all of this overload
&gt; reporting, should probably be delayed until something like the top of
&gt; the hour after it happens. We may even want this delay to be a consensus
&gt; parameter. Something like "Report only after N minutes", or "Report only
&gt; N minute windows", perhaps?

Yes definitely and I would even add a random component in this so not all
relays will report an overload in a predictable timeframe and thus "if the
line appear, I know it was hit N hours ago" type of calculation.

Cheers!
David

-- 
QlSpNB+aSzOYvM3E0etjbW84Wyx4/7PrwKfWOtmEgE0=


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210212002426</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-02-12 00:24:26-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: "Res tokens: Anonymous Credentials for Onion Service DoS Resilience"</subject><body>

On 2/11/21 5:36 PM, George Kadianakis wrote:
&gt; We are particularly looking forward to feedback about:
&gt; - Token issuance services
&gt; - The anonymous credential scheme chosen
&gt; - The XXXs and design decisions of the proposal
&gt; 
&gt; Hope you have a pleasant read!

&gt; # 9. Acknowledgements
&gt; 
&gt; Thanks to Jeff Burdges for all the information about Blind RSA and anonymous
&gt; credentials.
&gt; 
&gt; Thanks to Michele Orrù for the help with the unlinkability proof and for the
&gt; discussions about anonymous credentials.
&gt; 
&gt; Thanks to Chelsea Komlo for pointing towards anonymous credentials in
&gt; the context of DoS defenses for onion services.

Yooo, duuude! We need to give a public shoutout to OG Chaum! Almost 40
years later, and still the best properties we could find for our use
case. Oldest *AND* best! Fine 1983 vintage crypto, well aged, and
post-quantum unlinkable!

If you know anything about the history of this token, you will know with
certainty that Murs wrote this song about Chaum, referring to when
someone once asked Chaum how to link his tokens to track users:
https://open.spotify.com/track/0RdiYSv0mUfqYXN5WwYXjl

(Ok, so the Murs part may be apocryphal, but the rest is true!)

The One True Anonymity OG was even in talks with credit card companies:
https://decrypt.co/resources/digicash-what-is-cryptocurrency-explainer
https://www.satoshiwatch.com/hall-of-fame/dr-david-chaum/in-depth/digicash-blew-everything-david-chaums/


&gt; ---
&gt; 
&gt; # Appendix A: RSA Blinding Security Proof [BLIND_RSA_PROOF]
&gt; 
&gt; This proof sketch was provided by Michele Orrù:
&gt; 
&gt; ```
&gt; RSA Blind Sigs: https://en.wikipedia.org/wiki/Blind_signature#Blind_RSA_signatures
&gt; 
&gt; As you say, blind RSA should be perfectly blind.
&gt; 
&gt; I tried to look at Boneh-Shoup, Katz-Lindell, and Bellare-Goldwasser for a proof, \
&gt; but didn't find any :( 
&gt; The basic idea is proving that:
&gt; for any  message "m0" that is blinded with "r0^e" to obtain "b" (that is sent to \
&gt; the server), it is possible to freely choose another message "m1" that blinded with \
&gt; another opening "r1^e" to obtain the same "b". 
&gt; As long as r1, r0 are chosen uniformly at random, you have no way of telling if \
&gt; what message was picked and therefore it is *perfectly* blind. 
&gt; To do so:
&gt; Assume the messages ("m0" and "m1") are invertible mod N=pq (this happens at most \
&gt; with overwhelming probability phi(N)/N if m is uniformly distributed as a result of \
&gt; a hash, or you can enforce it at signing time). 
&gt; Blinding happens by computing:
&gt; b = m0 * (r0^e).
&gt; 
&gt; However, I can also write:
&gt; b = m0 * r0^e = (m1/m1) * m0 * r0^e = m1 * (m0/m1*r0^e).
&gt; 
&gt; This means that r1 = (m0/m1)^d * r0 is another valid blinding factor for b, and \
&gt; it's distributed exactly as r0 in the group of invertibles (it's unif at random, \
&gt; because r0 is so). ```
&gt; 
&gt; ---
&gt; 
&gt; [REF_TOKEN_ZOO]: https://tokenzoo.github.io/
&gt; [REF_INTRO_SPACE]: \
&gt; https://gitlab.torproject.org/legacy/trac/-/issues/33650#note_2350910 [REF_CHAUM]: \
&gt; https://eprint.iacr.org/2001/002.pdf [REF_PRIMO]: \
&gt; https://repo.getmonero.org/selene/primo \
&gt; https://www.monerooutreach.org/stories/RPC-Pay.html [REF_POW_PERF]: \
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/proposals/327-pow-over-intro.txt#L1050
&gt;  [REF_RES_BENCH]: https://github.com/asn-d6/res_tokens_benchmark


-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210212014224</emailId><senderName>Nicholas Hopper</senderName><senderEmail>hopper@cs.umn.edu</senderEmail><timestampReceived>2021-02-12 01:42:24-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: "Res tokens: Anonymous Credentials for Onion Service DoS Resilience"</subject><body>

Hi George!

A couple of thoughts about this proposal:

On Thu, Feb 11, 2021 at 5:36 PM George Kadianakis
&lt;desnacked@riseup.net&gt; wrote:&gt; ## 4.1. Token issuer setup&gt;
&gt;   The Issuer creates a set of ephemeral RSA-1024 "issuance keys" that will be
&gt;   used during the issuance protocol. Issuers will be rotating these ephemeral
&gt;   keys every 6 hours.
&gt;
&gt;   The Issuer exposes the set of active issuance public keys through a REST HTTP
&gt;   API that can be accessed by visiting /issuers.keys.
&gt;
&gt;   Tor directory authorities periodically fetch the issuer's public keys and
&gt;   vote for those keys in the consensus so that they are readily available by
&gt;   clients. The keys in the current consensus are considered active, whereas the
&gt;   ones that have fallen off have expired.
&gt;
&gt;   XXX how many issuance public keys are active each time? how does overlapping
&gt;       keys work? clients and onions need to know precise expiration date for
&gt;       each key. this needs to be specified and tested for robustness.
&gt;
&gt;   XXX every how often does the fetch work? how does the voting work? which
&gt;       issuers are considered official? specify consensus method.
&gt;
&gt;   XXX An alternative approach: Issuer has a long-term ed25519 certification key
&gt;       that creates expiring certificates for the ephemeral issuance keys. Alice
&gt;       shows the certificate to the service to prove that the token comes from
&gt;       an issuer. The consensus includes the long-term certification key of the
&gt;       issuers to establish ground truth.
&gt;       This way we avoid the synchronization between dirauths and issuers, and
&gt;       the multiple overlapping active issuance keys. However, certificates
&gt;       might not fit in the INTRODUCE1 cell (prop220 certs take 104 bytes on
&gt;       their own).  Also certificate metadata might create a vector for
&gt;       linkability attacks between the issuer and the verifier.
&gt;
&gt; ## 4.2. Onion service signals ongoing DoS attack
&gt;
&gt;   When an onion service is under DoS attack it adds the following line in the
&gt;   "encrypted" (inner) part of the v3 descriptor as a way to signal to its
&gt;   clients that tokens are required for gaining access:
&gt;
&gt;     "token-required" SP token-type SP issuer-list NL
&gt;
&gt;     [At most once]
&gt;
&gt;     token-type: Is the type of token supported ("res" for this proposal)
&gt;     issuer: A comma separated list of issuers which are supported by this onion service
&gt;

How are issuers identified?  I ask because of a potential problem noted below...

&gt; ### 4.3.1. Client preparation [DEST_DIGEST]
&gt;
&gt;   Alice first chooses an issuer supported by the onion service depending on her
&gt;   preferences by looking at the consensus and her Tor configuration file for
&gt;   the current list of active issuers.
&gt;
&gt;   After picking a supported issuer, she performs the following preparation
&gt;   before contacting the issuer:
&gt;
&gt;   1) Alice extracts the issuer's public key (N,e) from the consensus
&gt;
&gt;   2) Alice computes a destination digest as follows:
&gt;
&gt;            dest_digest = FDH_N(destination || salt)
&gt;
&gt;               where:
&gt;               - 'destination' is the 32-byte ed25519 public identity key of the destination onion
&gt;               - 'salt' is a random 32-byte value,
&gt;
&gt;   3) Alice samples a blinding factor 'r' uniformly at random from [1, N)
&gt;
&gt;   4) Alice computes:
&gt;            blinded_message = dest_digest * r^e (mod N)
&gt;
&gt;   After this phase is completed, Alice has a blinded message that is tailored
&gt;   specifically for the destination onion service. Alice will send the blinded
&gt;   message to the Token Issuer, but because of the blinding the Issuer does not
&gt;   get to learn the dest_digest value.
&gt;
&gt;   XXX Is the salt needed? Reevaluate.

Yes, the salt is needed (or, *some* input besides the destination must
go into the FDH) otherwise, all (unblinded) tokens signed by a given
issuance key will be identical.  This would be great for unlinkability
but not so good for double-spend prevention. :)

&gt;   We propose a new EXT_FIELD_TYPE value:
&gt;
&gt;     [02] -- ANON_TOKEN
&gt;
&gt;   The EXT_FIELD content format is:
&gt;
&gt;        TOKEN_VERSION    [1 byte]
&gt;        ISSUER_KEY       [4 bytes]
&gt;        DEST_DIGEST      [32 bytes]
&gt;        TOKEN            [128 bytes]
&gt;        SALT             [32 bytes]
&gt;
&gt;   where:
&gt;    - TOKEN_VERSION is the version of the token ([0x01] for Res tokens)
&gt;    - ISSUER_KEY is the public key of the chosen issuer (truncated to 4 bytes)
&gt;    - DEST_DIGEST is the 'dest_digest' from above
&gt;    - TOKEN is the 'token' from above
&gt;    - SALT is the 32-byte 'salt' added during blinding

Is it a problem that it is trivial to produce an RSA key with a given
4-byte truncation?  (so an adversarial issuer could choose a key to
match another issuer's keys)  Because you can generate an RSA key with
a targeted most- or least-significant bytes value in roughly the same
amount of work that it takes to generate an RSA key at all.  (For
example, if we are talking about the 4 least-significant bytes: find a
prime p, then set the 4 least-significant bytes of a candidate q to
(t*p^{-1} mod 2^{32}) before choosing the rest of q at random)

-Nick

-- 
------------------------------------------------------------------------
Nicholas Hopper (he/him/his)
Professor, Computer Science &amp; Engineering
University of Minnesota
------------------------------------------------------------------------
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211204145139</emailId><senderName>Richard Pospesel</senderName><senderEmail>richard@blueprintforfreespeech.net</senderEmail><timestampReceived>2021-12-04 14:51:39-0400</timestampReceived><subject>[tor-dev] Gosling onion-to-onion specifications</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Hi tor-dev,

As part of my work with Blueprint for Free Speech, I recently gave a 
short presentation during the 2021 state-of-the-onion where we announced 
Gosling ( see https://youtu.be/mNhIjtXuVzk?t=8155 ).

If you missed the talk, the tldr; is that we're developing a 
specification and reference implementation library for building (onion 
service based) anonymous+private+secure peer-to-peer applications.

Essentially, we're taking what we've learned about onion-to-onion 
authentication from Ricochet-Refresh, extracting and improving the 
relevant pieces, and packaging it all in a library that developers can 
use to build their own anonymous+private+secure peer-to-peer 
applications. Our hope is that future developers will not need to be tor 
experts to build these types of applications.

Today ,I'm happy to announce that we just made the the gosling repo on 
Github public!

- https://github.com/blueprint-freespeech/gosling

Things are little bare-bones at the moment, but the most relevant piece 
right now is the protocol specification here:

- https://github.com/blueprint-freespeech/gosling/blob/main/docs/protocol.md

You'll also find some initial prototyping work under the source 
directory (the pace of development should pick up come 2022).

Please go take a look and feel free to respond here with any questions, 
concerns, criticisms, etc. Thanks!

best,
-Richard


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211207142507</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-12-07 14:25:07-0400</timestampReceived><subject>Re: [tor-dev] Accessing Shared Random Values as a Protocol on top of Tor</subject><body>

[Attachment #2 (multipart/signed)]


On 29 Oct (23:56:07), Sebastian Hoffmann wrote:
&gt; Hi,
&gt; 
&gt; I'm wondering if I can access the shared random value[1] while
&gt; developing a
&gt; protocol/application on top of Tor onion services. The application is
&gt; still in
&gt; early development, but it would be great if I could depend on the shared
&gt; random
&gt; value.
&gt; 
&gt; If this is not the correct mailing list for this question, I would be
&gt; glad if
&gt; you could point me to one.

You can through the ControlPort with:

  "GETINFO sr/current"
  "GETINFO sr/previous"

From control-spec.txt:

    "sr/current"                                                           
    "sr/previous"                                                        
      The current or previous shared random value, as received in the    
      consensus, base-64 encoded.  An empty value means that either   
      the consensus has no shared random value, or Tor has no consensus. 

Cheers!
David

-- 
PyBJTQkt8p8BjnK5Ab+oFbVk2ILMK5Ty/Hz4v9WU/+4=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211208015636</emailId><senderName>Jorropo</senderName><senderEmail>jorropo.pgm@gmail.com</senderEmail><timestampReceived>2021-12-08 01:56:36-0400</timestampReceived><subject>Re: [tor-dev] Interoperation with libp2p</subject><body>

[Attachment #2 (multipart/alternative)]


Hey, I work for protocol labs (however not in the libp2p team) and I am a
go-libp2p contributor.

&gt; Thinking out loud: NAT traversal can use a rendezvous node, hidden
services are an intriguing option

Yes there have been people who already thought that however, tor doesn't
need to do anything.

I've worked on https://github.com/berty/go-libp2p-tor-transport once (PoC
leaks IPs with DNS requests, no audit, TLDR don't use it).

&gt; This first is to be able to advertise libp2p network in the directory, a
16bit network ID would be sufficient(where about 16 networks could be
advertised).
&gt; The second is to be able to send tor frames that unwrap to libp2p frames
once they reach a node advertising being part of a libp2p network or
networks(by way of using masking bits). I feel the second could be
accomplished with hidden service, but it feels more natural to want an RPC.

If I understand correctly you want for tor clients to be able to dial
libp2p clients because something would advertise and relay libp2p endpoints
in tor's directory ?

That sounds overly complicated and pretty much useless. I mean that looks
cool but if libp2p wants to use tor it can just use tor like anyone else
does (see my transport above), each libp2p node that wants to use tor just
run a tor client, connect to the tor network and register itself in the
directory, then advertise the tor hash in libp2p's DHT, to me this is a way
better solution because that doesn't make libp2p special, everything works
as they are supposed to and keep development efforts to a healthy low.

&gt; IPFS might still be inferior to Tahoe LAFS in real terms, especially due
to lacking erasure coding.

IPFS isn't just a filesharing network, it's a content addressed network
(TL;DR no one owns files, it's a network where you query a hash and it
return you the content that has that hash).
IPFS is in philosophy way closer to bittorrent than Tahoe LAFS, Bittorent
is also a network where you query for hash and you get content that has
that hash and I don't belive anyone ever said that bittorent is bad because
you can't force people to remove your content (actually music and movie
lobby did but I don't think you would agree with them) and for me the same
apply to IPFS.

&gt; Now libp2p doing their own scheme for sending their stuff over Tor's
existing streams makes sense.

+1

&gt; I'd expect libp2p to be a nightmare of downgrade attacks, given the
amount of badly rolled stuff they must still support, like their dangerous
key exchange SECIO built on the legacy curve sep256k1, but it'll go deep
than that.

It's really not, we have a fast deprecation cycle, unless you manually
choose to add support for it in your build it's not available anymore, any
software using libp2p right now use tls1.3, noise
&lt;https://github.com/libp2p/specs/blob/master/noise/README.md&gt; or QUIC's
layer (so I believe dtls).

Le mar. 7 dÃ©c. 2021 Ã  19:33, Jeff Burdges &lt;burdges@gnunet.org&gt; a Ã©crit :

&gt;
&gt;
&gt; &gt; On 7 Dec 2021, at 19:26, Jeff Burdges &lt;burdges@gnunet.org&gt; wrote:
&gt; &gt; I advise against allowing any libp2p cruft into tor itself though.
&gt;
&gt; Among the many reasons. I'd expect libp2p to be a nightmare of downgrade
&gt; attacks, given the amount of badly rolled stuff they must still support,
&gt; like their dangerous key exchange SECIO built on the legacy curve sep256k1,
&gt; but it'll go deep than that.
&gt;
&gt; Jeff
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;&lt;div dir="ltr"&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;Hey, I work for protocol \
labs (however not in the libp2p team) and I am a go-libp2p \
contributor.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&gt;  Thinking out loud:
NAT traversal can use a rendezvous node, hidden services are an intriguing option

&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Yes there have been people who already thought that however, tor \
doesn't need to do anything.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I've worked on &lt;a \
href="https://github.com/berty/go-libp2p-tor-transport"&gt;https://github.com/berty/go-libp2p-tor-transport&lt;/a&gt; \
once (PoC leaks IPs with DNS requests, no audit, TLDR don't use \
it).&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&gt;   This first is to be able to advertise libp2p \
network in the directory, a 16bit network ID would be sufficient(where about 16 \
networks could be advertised).  

&lt;br&gt;&gt; 
 The second is to be able to send tor frames that unwrap to libp2p frames once they \
reach a node advertising being part of a libp2p network or networks(by way of using \
masking bits).  I feel the second could be accomplished with hidden service, but it \
feels more natural to want an RPC.&lt;br&gt;&lt;br&gt;&lt;/div&gt;If I understand correctly you want \
for tor clients to be able to dial libp2p clients because something would advertise \
and relay libp2p endpoints in tor's directory ?&lt;br&gt;&lt;br&gt;&lt;/div&gt;That sounds overly \
complicated and pretty much useless. I mean that looks cool but if libp2p wants to \
use tor it can just use tor like anyone else does (see my transport above), each \
libp2p node that wants to use tor just run a tor client, connect to the tor network \
and register itself in the directory, then advertise the tor hash in libp2p's \
DHT, to me this is a way better solution because that doesn't make libp2p \
special, everything works as they are supposed to and keep development efforts to a \
healthy low.&lt;br&gt;&lt;br&gt;&gt; IPFS might still be inferior to Tahoe LAFS in real terms, \
especially due to lacking erasure coding.&lt;br&gt;&lt;br&gt;&lt;/div&gt;IPFS isn't just a \
filesharing network, it's a content addressed network (TL;DR no one owns files, \
it's a network where you query a hash and it return you the content that has that \
hash).&lt;br&gt;&lt;/div&gt;IPFS is in philosophy way closer to bittorrent than Tahoe LAFS, \
Bittorent is also a network where you query for hash and you get content that has \
that hash and I don't belive anyone ever said that bittorent is bad because you \
can't force people to remove your content (actually music and movie lobby did but \
I don't think you would agree with them) and for me the same apply to \
IPFS.&lt;br&gt;&lt;/div&gt;&lt;br&gt;&gt;  Now libp2p doing their own scheme for sending their stuff \
over Tor's existing streams makes sense.&lt;br&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;+1&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&gt;  \
I'd expect libp2p to be a nightmare of downgrade attacks, given the  amount of badly \
rolled stuff they must still support, like their  dangerous key exchange SECIO built \
on the legacy curve sep256k1, but  it'll go deep than that.&lt;br&gt;&lt;br&gt;&lt;/div&gt;It's \
really not, we have a fast deprecation cycle, unless you manually choose to add \
support for it in your build it's not available anymore, any software using \
libp2p right now use tls1.3, &lt;a \
href="https://github.com/libp2p/specs/blob/master/noise/README.md"&gt;noise&lt;/a&gt; or \
QUIC's layer (so I believe dtls).&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;Le  mar. 7 dÃ©c. 2021 Ã   19:33, Jeff Burdges &lt;&lt;a \
href="mailto:burdges@gnunet.org"&gt;burdges@gnunet.org&lt;/a&gt;&gt; a Ã©crit  \
:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;br&gt; &lt;br&gt;
&gt; On 7 Dec 2021, at 19:26, Jeff Burdges &lt;&lt;a href="mailto:burdges@gnunet.org" \
target="_blank"&gt;burdges@gnunet.org&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; I advise against allowing \
any libp2p cruft into tor itself though.&lt;br&gt; &lt;br&gt;
Among the many reasons. I'd expect libp2p to be a nightmare of downgrade attacks, \
given the amount of badly rolled stuff they must still support, like their dangerous \
key exchange SECIO built on the legacy curve sep256k1, but it'll go deep than \
that.&lt;br&gt; &lt;br&gt;
Jeff&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211208094021</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-12-08 09:40:21-0400</timestampReceived><subject>Re: [tor-dev] HAROI: Human Readable Authenticated Relay Operator Identifier</subject><body>

Hi,

Georg Koppen:
&gt; I think I am confused a bit. So, how does that relate to the contact
&gt; information sharing specification you propagate? Is your new proposal
&gt; an additional thing relay operators should implement on top of the
&gt; that specification? Or should they choose between the two? What
&gt; shortcoming does your new proposal solve that is not addressed by the
&gt; other specification and vice versa?

On a technical level
CIISS proofs [1] and HAROI proofs are the same,
the main difference is the integration into tor and the verification
of proofs by directory authorities.

The proof field in CIISS would eventually become obsolete should HAROIs get implemented in tor,
but since the proof is the same, relay operators do not have
to setup some new kind of proofs when HAROI is implemented
(&gt;1400 relays, &gt;50% exit probability have properly setup their proof already and more will follow soon).
The CIISS proof will continue to serve its purpose until HAROI is deployed in tor releases
since it naturally takes a long time until all relays run a supported tor version that would support it.

The main benefit of HAROI is the central verification of proofs by directory authorities
instead of requiring everyone to verify the proofs themselves.
This is better for efficiency and will reduce the load on proof endpoints (DNS and webservers).

I hope that helps clarifying the relation between HAROI and CIISS proof field.

Should you have any more questions do not hesitate to ask.


kind regards,
nusenu

[1] https://nusenu.github.io/ContactInfo-Information-Sharing-Specification/#proof

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211212180003</emailId><senderName>lejeczek via tor-dev</senderName><senderEmail>tor-dev@lists.torproject.org</senderEmail><timestampReceived>2021-12-12 18:00:03-0400</timestampReceived><subject>[tor-dev] compiling torsocks</subject><body>

Hi guys

A complete non-dev/programmer here so please go easy on me.
I'm trying to compile torsocks with 'mock', while 'tor' 
compiles okey for 'torsock' I fail with:
...
configure.ac:20: comes from Automake 1.16.1.  You should 
recreate
configure.ac:20: aclocal.m4 with aclocal and run automake 
again.
WARNING: 'automake-1.16' is probably too old.
          You should only need it if you modified 
'Makefile.am' or
          'configure.ac' or m4 files included by 
'configure.ac'.
          The 'automake' program is part of the GNU Automake 
package:
          &lt;http://www.gnu.org/software/automake&gt;
          It also requires GNU Autoconf, GNU m4 and Perl in 
order to run:
          &lt;http://www.gnu.org/software/autoconf&gt;
          &lt;http://www.gnu.org/software/m4/&gt;
          &lt;http://www.perl.org/&gt;
make[1]: *** [Makefile:600: Makefile.in] Error 63
make: *** [Makefile:466: all-recursive] Error 1
...

My setup is Centos 9 and obviously I do it with an rpm/spec.
Would you guys be kind to guide me to troubleshoot this?
many thanks, L.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20211212190132</emailId><senderName>Shannon via tor-dev</senderName><senderEmail>tor-dev@lists.torproject.org</senderEmail><timestampReceived>2021-12-12 19:01:32-0400</timestampReceived><subject>Re: [tor-dev] Client identification for authenticated onions</subject><body>

unsubscribe

Regards,
Shannon

Sent with ProtonMail Secure Email.

------- Original Message -------

On Tuesday, December 7th, 2021 at 9:21 AM, &lt;yanmaani@cock.li&gt; wrote:

&gt; On 2021-08-23 20:56, cho8jeiv4aus at paperboats.net wrote:
&gt;
&gt; &gt; Hi there. I had an idea recently for an onion service to improve the UX
&gt; &gt;
&gt; &gt; of sites that require a login. The site would have two onions: one for
&gt; &gt;
&gt; &gt; those who want to use onion auth and another for those who don't or are
&gt; &gt;
&gt; &gt; still setting it up. A user would first sign in with a
&gt; &gt;
&gt; &gt; username+password
&gt; &gt;
&gt; &gt; on the unauthenticated onion and click a button to generate a
&gt; &gt;
&gt; &gt; certificate associated with their account. Then they would add the
&gt; &gt;
&gt; &gt; public key to their browser and visit the authenticated onion. The
&gt; &gt;
&gt; &gt; application server would then match the pubkey used to authenticate
&gt; &gt;
&gt; &gt; with
&gt; &gt;
&gt; &gt; an account in the database, and log them in automatically.
&gt;
&gt; As for your case, you could maybe try client-side TLS certificates.
&gt;
&gt; I've had a similar idea for DoS protection. You have two onions, call
&gt;
&gt; them "open" and "closed".
&gt;
&gt; In the good times, you go to the "open" onion and register. It gives you
&gt;
&gt; a client authentication password for "closed" and redirects you there.
&gt;
&gt; On subsequent logins, you just go straight to the "closed" onion. (In
&gt;
&gt; theory, it's enough to have the key get you to the login screen - it
&gt;
&gt; doesn't actually have to replace authentication)
&gt;
&gt; Then, when the attack comes, it will take down the "open" onion.
&gt;
&gt; However, the "closed" onion is protected by client auth, and can be
&gt;
&gt; rate-limited by key.
&gt;
&gt; The only thing that would be needed for this is a special version of
&gt;
&gt; client authorization that allows the server to see which key is
&gt;
&gt; connecting, as opposed to "some key but you don't know which for privacy
&gt;
&gt; reasons".
&gt;
&gt; &gt; As an operator, an alternative would be to generate one (authenticated)
&gt; &gt;
&gt; &gt; onion service per user and route them all to the same place with
&gt; &gt;
&gt; &gt; different Host headers, but that seems rather inefficient, and I don't
&gt; &gt;
&gt; &gt; know how well the tor daemon scales up to hundreds of onion services
&gt; &gt;
&gt; &gt; anyway.
&gt;
&gt; That's not great for the network.
&gt;
&gt; tor-dev mailing list
&gt;
&gt; tor-dev@lists.torproject.org
&gt;
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20211223224244</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-12-23 22:42:44-0400</timestampReceived><subject>Re: [tor-dev] HAROI -&gt; AROI</subject><body>

to avoid that long name:
Human Readable Authenticated Relay Operator Identifier (HAROI)

I'm replacing it with the slightly shorter:

Authenticated Relay Operator ID (AROI)


and use that wording across all OrNetStats pages now:

https://nusenu.github.io/OrNetStats/w/misc/families-by-bandwidth.html


kind regards,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211224143826</emailId><senderName>Raphaël_Fabre</senderName><senderEmail>contact@fabco.tech</senderEmail><timestampReceived>2021-12-24 14:38:26-0400</timestampReceived><subject>[tor-dev] [dappy] Willing to chat with tor devs, about name system issues/solutions</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Hello

I'm Raphaël (fr) I just joined the tor dev mailing list. I would like to chat with \
tor developers, particularly if they have worked, or are interested in the issues \
regarding a name system for tor.

I'm the lead developer of dappy https://dappy.tech , we'll launch in 2022 and I do \
think we have interesting properties, for the public web as well as for tor and \
privacy-focused web projects.

We are the only name system in the world that does co-resolution, that's the way we \
found to maintain a consistent name system, and also avoid censorship and phishing.

Our system has the following properties:
- blockchain-based name system: it simply means that mapping is globally consistent, \
name management is distributed in the sense that a blockchain handles it, the \
                resolver just connect to this blockchain.
- Systematic co-resolution (not rotation): lookup request are always addressed to a \
network of independant agents: there are many instead of a single one. And then there \
is consensus at browser level. This prevents 90% of attacks or attempt of \
                censorship/phishing.
- Anonymous registrations
- Load-balancing of names: you can attach 20 IP addresses to your name, dappy browser \
                will try each one of them until it gets a response.
- 100% encrypted/https

Censorship cannot happen, neither at the storage location (blockchain) or on-the-fly \
at resolution time (co-resolution)

We will launch in 2022 and would be thrilled to exchange with some developers or \
engineers.

This document has lead me to the path of the tor-dev mailing list \
https://gitlab.torproject.org/legacy/trac/-/wikis/doc/OnionServiceNamingSystems

Happy to chat
Merry Christmas

Raphaël Fabre
Building a ultra-secure blockchain-based name system and browser https://dappy.tech


[Attachment #5 (text/html)]

&lt;div style="font-family: arial; font-size: 14px;"&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;Hello &lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: \
14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;I'm Raphaël (fr) \
I just joined the tor dev mailing list. I would like to chat with tor developers, \
particularly if they have worked, or are interested in the issues regarding a name \
system for tor.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: \
14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;I'm the lead \
developer of dappy &lt;a href="https://dappy.tech"&gt;https://dappy.tech&lt;/a&gt; , we'll launch \
in 2022 and I do think we have interesting properties, for the public web as well as \
for tor and privacy-focused web projects.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;We are \
the only name system in the world that does co-resolution, that's the way we found to \
maintain a consistent name system, and also avoid censorship and \
phishing.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
style="font-family: arial; font-size: 14px;"&gt;Our system has the following \
properties:&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;- \
blockchain-based name system: it simply means that mapping is globally consistent, \
name management is distributed in the sense that a blockchain handles it, the \
resolver just connect to this blockchain.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;- Systematic co-resolution (not rotation): &lt;b&gt;lookup request are \
always addressed to a network of independant agents: there are many instead of a \
single one&lt;/b&gt;. And then there is consensus at browser level. This prevents 90% of \
attacks or attempt of censorship/phishing.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;- Anonymous registrations&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;- Load-balancing of names: you can attach 20 IP addresses to your \
name, dappy browser will try each one of them until it gets a response.&lt;br&gt;&lt;/div&gt;&lt;div \
style="font-family: arial; font-size: 14px;"&gt;- 100% encrypted/https&lt;br&gt;&lt;/div&gt;&lt;div \
style="font-family: arial; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: \
arial; font-size: 14px;"&gt;&lt;b&gt;Censorship cannot happen, neither at the storage location \
(blockchain) or on-the-fly at resolution time (co-resolution)&lt;/b&gt;&lt;/div&gt;&lt;div \
style="font-family: arial; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: \
arial; font-size: 14px;"&gt;We will launch in 2022 and would be thrilled to exchange \
with some developers or engineers.&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;This \
document has lead me to the path of the tor-dev mailing list &lt;a \
href="https://gitlab.torproject.org/legacy/trac/-/wikis/doc/OnionServiceNamingSystems" \
&gt;https://gitlab.torproject.org/legacy/trac/-/wikis/doc/OnionServiceNamingSystems&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
&gt; style="font-family: arial; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: \
&gt; arial; font-size: 14px;"&gt;Happy to chat&lt;/div&gt;&lt;div style="font-family: arial; \
&gt; font-size: 14px;"&gt;Merry Christmas&lt;br&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
&gt; font-size: 14px;"&gt;&lt;div style="font-family: arial; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
&gt; class="protonmail_signature_block" style="font-family: arial; font-size: \
&gt; 14px;"&gt;&lt;div class="protonmail_signature_block-user"&gt;&lt;div&gt;&lt;b&gt;&lt;span \
&gt; style="font-size:12px;" class="size"&gt;Raphaël Fabre&lt;/span&gt;&lt;/b&gt;&lt;span \
&gt; style="font-size:12px;" class="size"&gt;&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span \
&gt; style="font-size:12px;" class="size"&gt;Building a ultra-secure blockchain-based name \
&gt; system and browser &lt;/span&gt;&lt;a title="https://dappy.tech" \
&gt; href="https://dappy.tech" rel="noopener noreferrer" target="_blank"&gt;&lt;span \
&gt; style="font-size:12px;" \
&gt; class="size"&gt;https://dappy.tech&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div \
&gt; class="protonmail_signature_block-proton \
&gt; protonmail_signature_block-empty"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style="font-family: arial; \
&gt; font-size: 14px;"&gt;&lt;br&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211227185845</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-12-27 18:58:45-0400</timestampReceived><subject>Re: [tor-dev] AROI</subject><body>


related rC3 presentation:

title: Towards a more Trustworthy Tor Network

when: 2021-12-28, 17:00 CET
where: https://streaming.media.ccc.de/rc3/csh

kind regards,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211101093421</emailId><senderName></senderName><senderEmail>yanmaani</senderEmail><timestampReceived>2021-11-01 09:34:21-0400</timestampReceived><subject>Re: [tor-dev] Client identification for authenticated onions</subject><body>

On 2021-08-23 20:56, cho8jeiv4aus at paperboats.net wrote:
&gt; Hi there. I had an idea recently for an onion service to improve the UX
&gt; of sites that require a login. The site would have two onions: one for
&gt; those who want to use onion auth and another for those who don't or are
&gt; still setting it up. A user would first sign in with a 
&gt; username+password
&gt; on the unauthenticated onion and click a button to generate a
&gt; certificate associated with their account. Then they would add the
&gt; public key to their browser and visit the authenticated onion. The
&gt; application server would then match the pubkey used to authenticate 
&gt; with
&gt; an account in the database, and log them in automatically.

As for your case, you could maybe try client-side TLS certificates.

I've had a similar idea for DoS protection. You have two onions, call 
them "open" and "closed".

In the good times, you go to the "open" onion and register. It gives you 
a client authentication password for "closed" and redirects you there. 
On subsequent logins, you just go straight to the "closed" onion. (In 
theory, it's enough to have the key get you to the login screen - it 
doesn't actually have to replace authentication)

Then, when the attack comes, it will take down the "open" onion. 
However, the "closed" onion is protected by client auth, and can be 
rate-limited by key.

The only thing that would be needed for this is a special version of 
client authorization that allows the server to see *which* key is 
connecting, as opposed to "some key but you don't know which for privacy 
reasons".

&gt; As an operator, an alternative would be to generate one (authenticated)
&gt; onion service per user and route them all to the same place with
&gt; different Host headers, but that seems rather inefficient, and I don't
&gt; know how well the tor daemon scales up to hundreds of onion services 
&gt; anyway.

That's not great for the network.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211101195652</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-11-01 19:56:52-0400</timestampReceived><subject>Re: [tor-dev] proposal 328 status</subject><body>

[Attachment #2 (multipart/signed)]


On 01 Nov (20:46:05), nusenu wrote:
&gt; 
&gt; 
&gt; David Goulet:
&gt; &gt; On 29 Oct (22:48:53), nusenu wrote:
&gt; &gt; &gt; Hi,
&gt; &gt; &gt; 
&gt; &gt; &gt; I'm wondering if the current version of the text is the latest available \
&gt; &gt; &gt; version of it or if there is somewhere a newer version that hasn't been pushed \
&gt; &gt; &gt; yet? 
&gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; &gt; &gt;  
&gt; &gt; &gt; "Status: Draft" but it is already in released tor versions.
&gt; &gt; 
&gt; &gt; It should actually be set to "Closed" now and we need to merge it in
&gt; &gt; dir-spec.txt.
&gt; 
&gt; "Implemented-In" would also be nice.
&gt; 
&gt; my understanding of the changelog
&gt; https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/361/diffs#821ec629171cb3d62b4ce801f8e81e2bbfe9b011_0_1
&gt;  
&gt; was that only the "overload-general" line got moved (not all lines from this spec)
&gt; from the extra-info descriptor to the server descriptor,
&gt; but this change implies that all lines are now located in the server descriptors?
&gt; 
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/commit/3424a245774e2ee56115e36cc4f8790fa53067c0#2c338f8c98c902438a74b0f928609906424b356d_30_28
&gt;  https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; 

Ah ! my mistake. I'll fix that right away.

You are absolutely right, the other overload lines are in the extra-info only.
The general one is in the server descriptor. I confirmed with the
implementation and will fix the spec asap!

Good catch!

&gt; 
&gt; Has the version field in the "overload-general" line been increase when the
&gt; semantics for DNS timeouts changed?  (the 1 to 1%/10min change)

Yes, in theory but we didn't go for this considering that the version 1 here
is absolutely broken and at this early time, we wanted to be agile with this
feature and so we backported this as a "fix" to a feature.

Any new features to that very line will see a version bump and a proposal for
sure.

The overload-general line implementation had a mis-communication between the
proposal and the coding work and so we thought we had the X% over Y% but we
didn't in the end.

Cheers!
David

-- 
eCVYxw3Iqh/9/IgYu/jMmS7iZf2Wky+ZIob+SBM/7/o=


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211105205124</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-05 20:51:24-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

current version of the text:
https://nusenu.github.io/tor-relay-operator-ids-trust-information/

&gt; Some comments, in no particular order:
&gt; 
&gt; Why not just put the keys in directly, or even a magnet link to your
&gt; latest web of trust? That would remove the need to trust SSL CAs.

Since the spec does not mention keys, which keys do you mean?

Note that the level of indirection
trust information -&gt; operator ID -&gt; relay ID
is crucial. Anything that requires to assign trust to
individual relays does not really scale well
and we trust relays largely by trusting their operators (less on other factors).


&gt; What problems does this solve, specifically, and how? If I - me
&gt; personally, not the generic I - wanted to spin up a relay, how would
&gt; I do that?
&gt; 
&gt; Would I go on this mailing list and ask random people to sign my
&gt; relay? If so, it's not very useful.
&gt; 
&gt; Or would I just run it without any signatures at all? If so, it's not
&gt; very useful.
&gt; 
&gt; The basic problem, I think, is the same as for PGP: it's not really
&gt; clear what you're attesting to

I've tried to make it more clear now and I've added a second point:

a TA asserts that
(1) a given operator ID is running relays without malicious intent
(2) they have met at least once in a physical setting (not just online)

https://github.com/nusenu/tor-relay-operator-ids-trust-information/blob/main/README.md#trust-anchor-ta

&gt; If I sign a my mate's
&gt; relay, 

Note: there is no manual signing and no trust at the individual relay level in the spec.

&gt; and then that relay turns out to be dodgy, do I also lose my
&gt; relay operation privileges?

No, but you will likely loose people's trust to assert a third parties trust level.
So if you were a TA for someone before you probably loose that ability, but it is up to the consumer
of trust information to define their rules for which TA to trust and how to respond to TA "errors".

Thanks to your input I added support for negative trust configurations:
https://nusenu.github.io/tor-relay-operator-ids-trust-information/#negative-trust-configuration

&gt; If you're going to do it in a "machine-friendly" manner, then I
&gt; suppose you have to come up with some kind of formalized notion of
&gt; what trust represents, maybe have some numerical scale so you can
&gt; define (just as an example) 100 = "I've personally audited the
&gt; hardware", 70 = "This is an organization I trust", 10 = "I know who
&gt; this person is, it's not just a fresh hotmail".

currently, by publishing an operator-id (=domain) a TA
only claims that "this operator runs relays without malicious intent" and that they met at least once.
It does not say anything about the operational security practices of an operator.

Having a granularity of 100 steps to denote the trust level is too much in my opinion.
Let's keep it simple.

&gt; Anyway, if you're going to do that, it might also be reasonable to
&gt; hook into a pre-existing web of trust, like GPG or something. That
&gt; way, we can encode stuff like "I trust my mate Alice, she isn't a
&gt; relay operator, she trusts Bob, who is, therefore I transitively
&gt; trust Bob." 

I don't think there is much benefit in using existing GPG signatures because
signatures on GPG keys only make claims about identities, they do not make any claims about
non-malicious relay operator intentions. Malicious operators are willing to go
quite far as we see in practice. Finding a poor person who is willing to go to
the next GPG key signing event for money is trivial for them I guess.

kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211109172015</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-09 17:20:15-0400</timestampReceived><subject>Re: [tor-dev] onionoo overload_general_timestamp (prop 328)</subject><body>




&gt; Said this I will update both the timestamp and the protocol version for consistency.

thanks, appreciated.
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211109174433</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-09 17:44:33-0400</timestampReceived><subject>[tor-dev] prometheus relay label</subject><body>

Hi,

when adding MetricsPort support to ansible-relayor
I realized that many operators that run more than one tor instance per server
will run into an issue because tor's relay prometheus metrics has no identifying \
label like fingerprint=
or similar to tell tor instances appart. The instance=
default label can have the same value for all tor instances on a given server
so that can not be used.

To avoid using nickname (might not be set) the easiest option is probably to use
the relay's SHA1 fingerprint or alternatively the IP:ORPort combination
which is unique per server but not necessarily globally unique (RFC1918 IPs).

Another neat option for operators is to use node_exporter's textfile collector to
collect tor's MetricsPort content to avoid having to run an additional webserver
for TLS and authentication (because unlike tor's exporter node_exporter comes with \
TLS and authentication builtin). In that case the suggested solution would be even \
more needed because in that case relabling via prometheus' scrape config is no longer \
possible.

What do you think about this suggestion?

kind regards,
nusenu



-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211110152618</emailId><senderName>Mike Mestnik</senderName><senderEmail>cheako+torproject_org@mikemestnik.net</senderEmail><timestampReceived>2021-11-10 15:26:18-0400</timestampReceived><subject>[tor-dev] Interoperation with libp2p</subject><body>

https://gitlab.torproject.org/tpo/core/torspec/-/issues/64
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211207232922</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-12-07 23:29:22-0400</timestampReceived><subject>[tor-dev] HAROI: Human Readable Authenticated Relay Operator Identifier</subject><body>

Hi,

below is a partial proposal draft for human readable relay operator IDs that are \
authenticated by directory authorities. If there is any interest in implementing
something like this I'll complete the draft and submit
it via gitlab.

kind regards,
nusenu


# HAROI: Human Readable Authenticated Relay Operator Identifier


A HAROI is a DNS FQDN that can be chosen by a relay operator and
linked to one or more relays in a verifiable way.
The link is authenticated in the sense that it requires some control
over the relay and the FQDN (on the DNS or webroot level).
A relay can only be linked to a single HAROI.
Relays publish their HAROI via their descriptor.
Directory authorities verify the link and publish the verification result in their \
vote.

## Motivation

Many tools in the tor ecosystem display at least some relay (operator)
information (nickname, ContactInfo, ...), some examples are:
- Tor Browser
- Relay Search [1]
- Onioncircuits by tails [2]
- ExoneraTor [3]
- allium [4]

unfortunatelly there is no authenticated operator ID available, these tools could \
display, so they might display misleading information, something that has been \
exploited in the wild for impersonation attacks.

There is a value in giving relay operators the possibility to
declare an identifier that is globally unique, consistent and can not be easily \
spoofed by adversaries so they do not become easy victims of impersonation attacks.
The tor ecosystem would benefit from an operator ID that can not be spoofed.

This proposal is not replacing the relay ContactInfo.

## Design

* A HAROI is optional and not mandatory.
* A HAROI is verified by directory authorities in one of two ways, depending on the \
proof type. In the distant future where relays have no RSA1024 keys, Ed25519 proof \
                types are added.
* The used proof type can be selected by the relay operator.

Successfully verified proofs are cached by directory authorities for 30 days.
After 30 days proofs are verified again.

Relay operators that want to make use of HAROI can participate without
requiring a domain since many free services offer custom free subdomains
(example: GitLab or GitHub pages).


## Proof Types

Relay operators, that chose to set a HAROI,
can select their preferred a proof type.

### uri-rsa

This proof type can be verified by fetching
the list of relay RSA SHA1 fingerprints from
the FQDN via HTTPS using the well-known URI
as defined in proposal 326
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/326-tor-relay-well-known-uri-rfc8615.md#well-knowntor-relayrsa-fingerprinttxt


Example: if the FQDN is example.com, the url to fetch the list of fingerprints is:

https://example.com/.well-known/tor-relay/rsa-fingerprint.txt

The TLS certificate used on the webserver must be from a trusted CA and logged in a \
public certificate transparency log.

For N relays using the same FQDN only a single HTTPS GET request is needed.

### dns-rsa

This proof type can be verified by performing
DNS lookups. To make use of this proof type the DNS zone MUST be DNSSEC signed.

The DNS query is constructed by combining the relay's fingerprint and the FQDN:

relay-fingerprint.&lt;FQDN&gt;

example:

relay-fingerprint.example.com value: "we-run-this-tor-relay"

relay-fingerprint is the 40 character RSA SHA1 fingerprint of the tor relay.
Each relay has its own DNS record, a single TXT record MUST be returned per relay \
only.

content of the TXT record MUST match:

"we-run-this-tor-relay"

Each relay requires a single DNS lookup (less scalable than the uri-rsa option).


## Relay Configuration

Relay operators can specify their identifier via a torrc option.

OperatorIdentifier &lt;FQDN&gt; &lt;proof-type&gt;

example:

OperatorIdentifier example.com dns-rsa

## Length Limit

Although DNS FQDNs can be rather long, we limit HAROIs to 40 characters.
(As of December 2021 the longest observed HAROI is 28 characters long.)
Operators will not be able to specify a HAROI longer than 40 characters in their \
torrc. Directory authorities refuse to accept them as well.


## Relays Descriptor Changes


This proposal defines a new optional descriptor field that is
automatically verified and voted on by tor directory authorities.

operatorid &lt;FQDN&gt; &lt;proof-type&gt;


## Directory Authorities

Directory authorities refuse to accept domains on the public suffix list [5].

XXX TODO


## Security Considerations

Relay operators can trick directory authorities into performing DNS lookups
and HTTPS GETs on arbitrary domains.

Possible solutions:
Directory authorities could required PTR+A DNS records on the same domain as the \
given FQDN for the relays IP address.


[1] https://metrics.torproject.org/rs.html
[2] https://gitlab.tails.boum.org/tails/onioncircuits
[3] https://metrics.torproject.org/exonerator.html
[4] https://yui.cat/
[5] https://publicsuffix.org/list/public_suffix_list.dat



-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211208081812</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2021-12-08 08:18:12-0400</timestampReceived><subject>Re: [tor-dev] HAROI: Human Readable Authenticated Relay Operator Identifier</subject><body>

This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
[Attachment #2 (multipart/mixed)]

[Attachment #4 (text/plain)]

nusenu:
&gt; Hi,
&gt; 
&gt; below is a partial proposal draft for human readable relay operator IDs 
&gt; that are authenticated
&gt; by directory authorities. If there is any interest in implementing
&gt; something like this I'll complete the draft and submit
&gt; it via gitlab.

I think I am confused a bit. So, how does that relate to the contact 
information sharing specification you propagate? Is your new proposal an 
additional thing relay operators should implement on top of the that 
specification? Or should they choose between the two? What shortcoming 
does your new proposal solve that is not addressed by the other 
specification and vice versa?

Georg

&gt; kind regards,
&gt; nusenu
&gt; 
&gt; 
&gt; # HAROI: Human Readable Authenticated Relay Operator Identifier
&gt; 
&gt; 
&gt; A HAROI is a DNS FQDN that can be chosen by a relay operator and
&gt; linked to one or more relays in a verifiable way.
&gt; The link is authenticated in the sense that it requires some control
&gt; over the relay and the FQDN (on the DNS or webroot level).
&gt; A relay can only be linked to a single HAROI.
&gt; Relays publish their HAROI via their descriptor.
&gt; Directory authorities verify the link and publish the verification 
&gt; result in their vote.
&gt; 
&gt; ## Motivation
&gt; 
&gt; Many tools in the tor ecosystem display at least some relay (operator)
&gt; information (nickname, ContactInfo, ...), some examples are:
&gt; - Tor Browser
&gt; - Relay Search [1]
&gt; - Onioncircuits by tails [2]
&gt; - ExoneraTor [3]
&gt; - allium [4]
&gt; 
&gt; unfortunatelly there is no authenticated operator ID available, these 
&gt; tools could display,
&gt; so they might display misleading information, something that has been 
&gt; exploited in the wild for
&gt; impersonation attacks.
&gt; 
&gt; There is a value in giving relay operators the possibility to
&gt; declare an identifier that is globally unique, consistent and can not be 
&gt; easily spoofed by adversaries
&gt; so they do not become easy victims of impersonation attacks.
&gt; The tor ecosystem would benefit from an operator ID that can not be 
&gt; spoofed.
&gt; 
&gt; This proposal is not replacing the relay ContactInfo.
&gt; 
&gt; ## Design
&gt; 
&gt; * A HAROI is optional and not mandatory.
&gt; * A HAROI is verified by directory authorities in one of two ways, 
&gt; depending on the proof type.
&gt; In the distant future where relays have no RSA1024 keys, Ed25519 proof 
&gt; types are added.
&gt; * The used proof type can be selected by the relay operator.
&gt; 
&gt; Successfully verified proofs are cached by directory authorities for 30 
&gt; days.
&gt; After 30 days proofs are verified again.
&gt; 
&gt; Relay operators that want to make use of HAROI can participate without
&gt; requiring a domain since many free services offer custom free subdomains
&gt; (example: GitLab or GitHub pages).
&gt; 
&gt; 
&gt; ## Proof Types
&gt; 
&gt; Relay operators, that chose to set a HAROI,
&gt; can select their preferred a proof type.
&gt; 
&gt; ### uri-rsa
&gt; 
&gt; This proof type can be verified by fetching
&gt; the list of relay RSA SHA1 fingerprints from
&gt; the FQDN via HTTPS using the well-known URI
&gt; as defined in proposal 326
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/326-tor-relay-well-known-uri-rfc8615.md#well-knowntor-relayrsa-fingerprinttxt \
&gt;  
&gt; 
&gt; Example: if the FQDN is example.com, the url to fetch the list of 
&gt; fingerprints is:
&gt; 
&gt; https://example.com/.well-known/tor-relay/rsa-fingerprint.txt
&gt; 
&gt; The TLS certificate used on the webserver must be from a trusted CA and 
&gt; logged in a public certificate transparency log.
&gt; 
&gt; For N relays using the same FQDN only a single HTTPS GET request is needed.
&gt; 
&gt; ### dns-rsa
&gt; 
&gt; This proof type can be verified by performing
&gt; DNS lookups. To make use of this proof type the DNS zone MUST be DNSSEC 
&gt; signed.
&gt; 
&gt; The DNS query is constructed by combining the relay's fingerprint and 
&gt; the FQDN:
&gt; 
&gt; relay-fingerprint.&lt;FQDN&gt;
&gt; 
&gt; example:
&gt; 
&gt; relay-fingerprint.example.com value: "we-run-this-tor-relay"
&gt; 
&gt; relay-fingerprint is the 40 character RSA SHA1 fingerprint of the tor 
&gt; relay.
&gt; Each relay has its own DNS record, a single TXT record MUST be returned 
&gt; per relay only.
&gt; 
&gt; content of the TXT record MUST match:
&gt; 
&gt; "we-run-this-tor-relay"
&gt; 
&gt; Each relay requires a single DNS lookup (less scalable than the uri-rsa 
&gt; option).
&gt; 
&gt; 
&gt; ## Relay Configuration
&gt; 
&gt; Relay operators can specify their identifier via a torrc option.
&gt; 
&gt; OperatorIdentifier &lt;FQDN&gt; &lt;proof-type&gt;
&gt; 
&gt; example:
&gt; 
&gt; OperatorIdentifier example.com dns-rsa
&gt; 
&gt; ## Length Limit
&gt; 
&gt; Although DNS FQDNs can be rather long, we limit HAROIs to 40 characters.
&gt; (As of December 2021 the longest observed HAROI is 28 characters long.)
&gt; Operators will not be able to specify a HAROI longer than 40 characters 
&gt; in their torrc.
&gt; Directory authorities refuse to accept them as well.
&gt; 
&gt; 
&gt; ## Relays Descriptor Changes
&gt; 
&gt; 
&gt; This proposal defines a new optional descriptor field that is
&gt; automatically verified and voted on by tor directory authorities.
&gt; 
&gt; operatorid &lt;FQDN&gt; &lt;proof-type&gt;
&gt; 
&gt; 
&gt; ## Directory Authorities
&gt; 
&gt; Directory authorities refuse to accept domains on the public suffix list 
&gt; [5].
&gt; 
&gt; XXX TODO
&gt; 
&gt; 
&gt; ## Security Considerations
&gt; 
&gt; Relay operators can trick directory authorities into performing DNS lookups
&gt; and HTTPS GETs on arbitrary domains.
&gt; 
&gt; Possible solutions:
&gt; Directory authorities could required PTR+A DNS records on the same 
&gt; domain as the given FQDN for the relays IP address.
&gt; 
&gt; 
&gt; [1] https://metrics.torproject.org/rs.html
&gt; [2] https://gitlab.tails.boum.org/tails/onioncircuits
&gt; [3] https://metrics.torproject.org/exonerator.html
&gt; [4] https://yui.cat/
&gt; [5] https://publicsuffix.org/list/public_suffix_list.dat
&gt; 
&gt; 
&gt; 


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

--===============1339008912805917599==--

</body></email><email><emailId>20211121102706</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-21 10:27:06-0400</timestampReceived><subject>Re: [tor-dev] proposal 328: consensus parameters</subject><body>

Nick Mathewson:
&gt; Every network parameter has a default value; IIUC, unless at least three
&gt; authorities are voting for some value, everybody will use the default.
&gt; It's normal for the authorities not to vote for a different value if they
&gt; all think the default is reasonable.
&gt; 
&gt; The default for these parameters is in param-spec.txt at
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/param-spec.txt#L194

thank you Nick for explaining this,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211001131519</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-01 13:15:19-0400</timestampReceived><subject>[tor-dev] (Short) Arti Report 6: September 15 through September 30</subject><body>

# Arti Report 6: September 15 through September 30

## Activities since our last report

Hello!  Lots of code since last time, but not so much to say about it.  I'm
chugging ahead on the Guard nodes implementation, but it isn't done yet.
Most of the code is there, but I need to write tests, chase down a few spec
issues, fix a couple of things that "don't feel right", and integrate it all
with tor-circmgr.

You can track progress on the guard implementation at
&lt;https://gitlab.torproject.org/tpo/core/arti/-/issues/58&gt;.


## Thanks!

Thanks to Jani Monoses for refactoring, Daniel Eades for cleanup, and Trinity
Pointard for OSX reproducible builds and integration testing (!).
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211006153745</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-10-06 15:37:45-0400</timestampReceived><subject>Re: [tor-dev] Updated Proposal 324: RTT-based Congestion Control for Tor</subject><body>

We have done another round of updates to Proposal 324:
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/324-rtt-congestion-control.txt

Since the last update (summary provided below in the quoted reply), the
main changes are to include the drain rate of an edge connection in the
XON cell, for flow control. This reduces the XON/XOFF chatter and
average queue size in the event that edges are sending slower than their
Tor circuits.

Additionally, dropmark defenses were added in the form of controlling
the frequency of XON/XOFF, and in providing a time duration after which
we stop allowing data on half-closed connections. (As with all dropped
cell defenses in C-Tor, these are only enforced by the vanguards addon -
https://github.com/mikeperry-tor/vanguards/blob/master/README_TECHNICAL.md#the-bandguards-subsystem)

A C-Tor implementation of the flow control algorithm for edges has been
merged to tor.git's origin/main. It lives in
src/core/or/congestion_control_flow.[ch]. This implementation remains
off by default, pending implementation of protocol negotiation for
Congestion Control
(https://gitlab.torproject.org/tpo/core/tor/-/issues/40444).

This flow control implementation was evaluated and tuned by David Goulet
and myself over a custom onion service test bed, and we verified that it
is only active when edges are draining slower than their Tor circuit.

The specification has also been updated with additional details for what
remains to be tested and tuned in Shadow, as well as additional
consensus parameters external to congestion control that will require
re-tuning as well. These details can be found in Section 6 of Proposal
324. The consensus parameter list for tuning is in Section 6.5.

Here is the full Proposal 324 changelog since the last tor-dev post:
 - Export the monotime clock stall detection as a global property
 - Specify advertisement of edge drain rate in XON, to minimize chatter
 - Limit the frequency of XON/XOFF with consensus params
 - Describe oomkiller behavior wrt misbehaving endpoints
 - Describe dropmark defenses using XON/XOFF limits
 - Describe how half-closed edge connections are handled with flow
   control
 - Describe onion service advertisement and negotiation of congestion
   control
 - Describe flow control consensus parameters
 - Describe flow control shadow experiments and live comparison
 - Create and describe additional consensus parameters that will
   influence congestion control performance and memory usage
 - Clarify performance metrics involved in experiments
 - Describe more shortcomings of TOR_WESTWOOD/BOOTLEG_RTT_TOR
 - Remove some stale XXXs and TODOs

Review and comments are welcome!

On 7/30/21 6:22 PM, Mike Perry wrote:
&gt; As a heads up, I have updated Proposal 324: RTT-based Congestion Control
&gt; for Tor -
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/324-rtt-congestion-control.txt
&gt; 
&gt; The updated version has a new congestion control algorithm, detailed
&gt; specifics on how to accurately measure RTT and BDP, and descriptions of
&gt; algorithm parameter values and tuning experiments, among other improvements.
&gt; 
&gt; A C implementation of these algorithms has been merged to tor.git
&gt; orgin/main. They live in src/core/or/congestion_control_*.[ch]. These
&gt; algorithms are not enabled yet; we still need to implement flow control
&gt; and negotiation, as well as do shadow experimentation to determine good
&gt; candidate parameter values to further tune on live.
&gt; 
&gt; Here is a full changelog since the proposal was last published to tor-dev:
&gt;  - Correct algorithms to update once per congestion window
&gt;  - Add orconn blocking and edge connection checks as signals
&gt;  - Specify BDP estimators based on onion service testing and eval.
&gt;  - Specify a pure BDP tracking congestion control algorithm (TOR_NOLA)
&gt;  - Update consensus parameters with tuning notes
&gt;  - Document what we learned so far in live onion service experimentation
&gt;  - Mention that we need to test intermittent downloads in Shadow/live
&gt;  - Describe clock jump and stall detection during RTT measurement
&gt;  - Mention if we calculate package window, it can become negative
&gt;  - Break off the backwards ECN idea into a future idea draft:
&gt; 
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/ideas/xxx-backward-ecn.txt
&gt;  - Update old trac URLs
&gt;  - Add Acknowledgements
&gt; 
&gt; Review and comments are welcome!
&gt; 
&gt; --
&gt; Mike Perry
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 

-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211007012438</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2021-10-07 01:24:38-0400</timestampReceived><subject>[tor-dev] v2 Onions, IPv6 BiDir P2P Capability Regression... [re: Relays running</subject><body>

On that, and regardless of what TPO Inc says re...

tor is a bit decentralized, and freely licensed, as such...

DirAuths, HSDirs, Relays are all free to choose to continue signing
over and running older versions in order to support the community of
tor clients that are happily using useful features that the Tor Project on
its high horse demands with its blanket fiat fist and refusing to consider
and support users... to remove from such users, herein as noted before,
v2 onions and simple OnionCat IPv6 /48+80 UDP transport P2P E2E
BiDir addressing and thus all current IPv6 capable apps incl VOIP Bittorrent
comms status chat game coins etc and future apps that needing such
tech to operate across onionland. That's bad, and a big regression in
service, both active now, and preventing potential development on
interesting new uses and applications in the future.

These users, these features, apps, and their recognized tradeoffs, their
free choices made therein, are of merit and import. And Tor Project
is choosing to censor and ban v2 and them without regard.

Perhaps some v2 users will likewise email all the relays
seeking not their censorship, but instead their support.
But perhaps due to any needs they may have to remain
unknown they may not be able to voice out to lists etc,
as such the surfaceweb cannot make dis-use assumptions
and must indeed hold v2 in their stead for them.

Kudos to those distributed DirAuths, HSDirs, and Relays who
refuse to comply with Tor Project Inc demands to crush all
v2 onion users and their legitimate use cases.

The better path is for TPO to either recognize and continue, or to
modularize v2 onion support out to community stewardship such
that the features that it provides may continue until a future vN
or a seamless scalable externally attached solution for the same
features and uses is found. And to make v3 the default choice
"advertised" in docs and configs, with v2 a lesser noted option
yet for just providing above capabilities.

Tor Project still doesn't have a version feature matrix table, nor
an honest open balanced and free to all authors wiki education
page detailing use case and tradeoff notes for users about
the v2+OnionCat vs v3 tech capabilities, thereby allowing tor
users to freely make educated choices therein on their own.
Instead it has a bricked up and censored prop blog and lists.
Like TPO's censorship, that's unfair, unwarranted, questionable,
and needs to end.

ps: Yes, upgrade, if merely behind on versions sake, lots
of good fixes, improvements, performance, features, security,
etc come with those.

But when it comes to a big and permanent regression of
overall network capability issue such as this, that's different,
and needs consideration beyond the vague handwavy
universal whitewash "reason" being uttered by TPO such as
"v2 insecure"... which is false re educated tradeoffs and uses
that users are free to evaluate and choose on their own.
In fact, users are in better more intelligent aware position
having learned a bit of something and made that themselves.

Users are also free to eval by bring forward to today sense
of the NSA's 10+ year old slides that noted "Tor Stinks".
What conditions, designs, capabilities, etc have changed
since then.


Cheers all.



On 10/5/21, Georg Koppen &lt;gk@torproject.org&gt; wrote:
&gt; Relays running unsupported Tor versions is a problem we have never
&gt; really dealt with in a systematic way in the way. Some of you might
&gt; recall that we (with the help of volunteers) tried back in 2019/2020 to
&gt; get operators, running an unsupported Tor version, to upgrade[1] but
&gt; then we dropped the ball. Alas.
&gt;
&gt; We just started that process again by contacting every relay operator
&gt; running an outdated Tor version (any version not 0.3.5.x or 0.4.5.x or
&gt; 0.4.6.x or 0.4.7.x) by email where possible. Additionally, we created a
&gt; wiki page outlining the current process and things we still need to
&gt; figure out.[2] On that page we plan to make statistics related to the
&gt; EOL relay removal available as well, including the final list of relays
&gt; we'll reject. Thus, stay tuned. Feedback, as always, is very much welcome!
&gt;
&gt; We plan to keep this topic on our radar this time while refining the
&gt; process as we go. Meanwhile, if you are running a relay with an
&gt; unsupported Tor version, please upgrade for the sake of our users' safety.
&gt;
&gt; If you need help, join us on #tor-relays or #tor-relays:matrix.org if
&gt; you use Element.
&gt;
&gt; [1] https://blog.torproject.org/removing-end-life-relays-network
&gt; [2] https://gitlab.torproject.org/tpo/network-health/team/-/wikis/Relay-EOL-policy
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211010183701</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 18:37:01-0400</timestampReceived><subject>Re: [tor-dev] ed25519_master_id_public_key -&gt; ed25519 id</subject><body>



nusenu:
&gt; cut -b 33- ed25519_master_id_public_key |base64

hint: don't use this

Since cut is line based it will only read until the end of the line
but the input file is not a text file - so it will stop reading at random offsets.


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20211010200734</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 20:07:34-0400</timestampReceived><subject>[tor-dev] tor Prometheus Metrics Documentation</subject><body>

Hi,

since Neel is working on unix socket support [1] for MetricsPort
I'm preparing to add support for it to relayor.
I don't like to add additional attack surface to a relay but since
tor does not support TLS and basic auth on the MetricsPort I'll likely
install nginx that takes care of TLS and authentication.
If you have any opinion on that I'd also like to hear it.

It would be nice to have a documentation for all tor prometheus metrics
in the man page or on a website, some information can be found at [3] but not all.
Is there already a complete documentation for tor prometheus metrics data?

Here is an example of how other projects have documented their metrics [5].

I don't know if it is too late for that but it would be great to use the
well known IANA RCODE [4] naming for the DNS return codes
where possible instead of the custom naming.

examples (just guessing):
tor_relay_exit_dns_error_total{... reason="format"}    -&gt; FormErr?
tor_relay_exit_dns_error_total{... reason="notexist"}  -&gt; NXDomain?

kind regards,
nusenu


[1] https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/453
[3] https://support.torproject.org/relay-operators/relay-bridge-overloaded/
[4] https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-6
[5] https://doc.powerdns.com/recursor/metrics.html#metricnames
related feature request:
[2] https://gitlab.torproject.org/tpo/core/tor/-/issues/40194



-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211014122007</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-14 12:20:07-0400</timestampReceived><subject>[tor-dev] Arti report 7: September 30 through October 13</subject><body>

# Arti Report 7: September 30 through October 13

## Guards are working!

Finally, at long last, we've got Guard nodes working in Arti!

When we first made our roadmap, we set our first milestone as "Arti
has all the features necessary for basic anonymity."  Now that
Guards are implemented, all of those features are done!

Does this mean that Arti is now production-ready for anonymous use?
No, not yet.  Just because we no longer have _missing_ privacy
features doesn't mean that those privacy features are actually
implemented correctly.  We'll need a lot more testing, debugging,
and experimentation.  Also, it's very possible we've forgotten
something.  We'll need careful auditing to be sure.

### Interesting guard issues

There are more issues to fix and features to add to the guard
implementation down the road.  For a current list, have a look at
[this comment](https://gitlab.torproject.org/tpo/core/arti/-/issues/58#note_2754904),
which lists them.

## What's next

Over the next couple of weeks, we'll be working on smaller issues,
bugfixes, and miscellaneous cleanups for an upcoming "0.0.1"
release, targeting November 1.

You can see our latest progress
[here]((https://gitlab.torproject.org/tpo/core/arti/-/milestones/6).

## Thanks!

Thanks to Jani Monoses for progress towards a WASM port, and Trinity
Pointard for updates to dependencies.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211106141921</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-06 14:19:21-0400</timestampReceived><subject>[tor-dev] onionoo overload_general_timestamp (prop 328)</subject><body>

Hi,

in onionoo all timestamps used to be in the format
YYYY-MM-DD hh:mm:ss

Proposal 328 has timestamps in this same format
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md

The newly added prop328 fields in oninoo appear to break with that convention
https://metrics.torproject.org/onionoo.html#details_relay_overload_general_timestamp

Here is an example for an onionoo overload_general_timestamp which appears
to be at millisecond granularity (the source has a granularity of an hour):
1636038000000

Was there a particular motivation for this format change and granularity?
And what do you think about changing it to use the YYYY-MM-DD hh:mm:ss
format for consistency and having a direct human readable format here as well?

related:
Karsten used to maintain onionoo protocol documentation/changelog and versions:
https://metrics.torproject.org/onionoo.html#versions
Is that and the 'version' field in onionoo no longer maintained?
(since it didn't change with the new fields)


kind regards,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211108135840</emailId><senderName>Silvia/Hiro</senderName><senderEmail>hiro@torproject.org</senderEmail><timestampReceived>2021-11-08 13:58:40-0400</timestampReceived><subject>Re: [tor-dev] onionoo overload_general_timestamp (prop 328)</subject><body>

Hi,

On 6/11/21 15:19, nusenu wrote:
&gt; Hi,
&gt;
&gt; in onionoo all timestamps used to be in the format
&gt; YYYY-MM-DD hh:mm:ss
&gt;
&gt; Proposal 328 has timestamps in this same format
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md 
&gt;
&gt;
&gt; The newly added prop328 fields in oninoo appear to break with that 
&gt; convention
&gt; https://metrics.torproject.org/onionoo.html#details_relay_overload_general_timestamp 
&gt;
&gt;
&gt; Here is an example for an onionoo overload_general_timestamp which 
&gt; appears
&gt; to be at millisecond granularity (the source has a granularity of an 
&gt; hour):
&gt; 1636038000000

Thanks for reporting this. You are right this is probably a carry over 
for how the field was read in metrics-lib. I will be changing it to a 
human readable format as per specs.


&gt;
&gt; Was there a particular motivation for this format change and granularity?
&gt; And what do you think about changing it to use the YYYY-MM-DD hh:mm:ss
&gt; format for consistency and having a direct human readable format here 
&gt; as well?
&gt;
&gt; related:
&gt; Karsten used to maintain onionoo protocol documentation/changelog and 
&gt; versions:
&gt; https://metrics.torproject.org/onionoo.html#versions
&gt; Is that and the 'version' field in onionoo no longer maintained?
&gt; (since it didn't change with the new fields)

Sure, we intend to maintain the version field, and since new fields have 
been added the protocol version should have been updated.

The reason I haven't updated it yet was that I wasn't very pleased that 
we had to add the overload_ratelimits [1] and overload_fd_exhausted [2] 
fields in the bandwidth document. We needed to expose these fields, but 
we also knew these didn't belong to this document. So the idea was to 
plan a bigger release with a little restructure of the onionoo internals 
and update the protocol version then.

Said this I will update both the timestamp and the protocol version for 
consistency.

Thanks for bringing this up.


Cheers,

-hiro

[1] 
https://metrics.torproject.org/onionoo.html#bandwidth_relay_overload_ratelimits

[2] 
https://metrics.torproject.org/onionoo.html#bandwidth_bridge_overload_fd_exhausted

&gt; kind regards,
&gt; nusenu
&gt;
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211117213917</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-11-17 21:39:17-0400</timestampReceived><subject>[tor-dev] proposal 328: consensus parameters</subject><body>

Hi,

https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; For DNS timeouts, the X and Y are consensus parameters
&gt; (overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)
&gt; defined in param-spec.txt.

should one be able to find these parameters
(overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)
on
https://consensus-health.torproject.org/#consensusparams
or in
https://collector.torproject.org/recent/relay-descriptors/consensuses/

or is this not yet deployed?
What are the values of these parameters currently?

thanks,
nusenu


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211118005902</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-11-18 00:59:02-0400</timestampReceived><subject>Re: [tor-dev] proposal 328: consensus parameters</subject><body>

[Attachment #2 (multipart/alternative)]


On Wed, Nov 17, 2021 at 4:39 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:

&gt; Hi,
&gt;
&gt;
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md
&gt; &gt; For DNS timeouts, the X and Y are consensus parameters
&gt; &gt; (overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)
&gt; &gt; defined in param-spec.txt.
&gt;
&gt; should one be able to find these parameters
&gt; (overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)
&gt; on
&gt; https://consensus-health.torproject.org/#consensusparams
&gt; or in
&gt; https://collector.torproject.org/recent/relay-descriptors/consensuses/
&gt;
&gt; or is this not yet deployed?
&gt; What are the values of these parameters currently?
&gt;
&gt;
Every network parameter has a default value; IIUC, unless at least three
authorities are voting for some value, everybody will use the default.
It's normal for the authorities not to vote for a different value if they
all think the default is reasonable.

The default for these parameters is in param-spec.txt at
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/param-spec.txt#L194

cheers,
-- 
Nick

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div dir="ltr"&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Wed, Nov 17, 2021 at 4:39 PM nusenu &lt;&lt;a \
href="mailto:nusenu-lists@riseup.net"&gt;nusenu-lists@riseup.net&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px 0px 0px \
0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;Hi,&lt;br&gt; &lt;br&gt;
&lt;a href="https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md" \
rel="noreferrer" target="_blank"&gt;https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md&lt;/a&gt;&lt;br&gt;
 &gt; For DNS timeouts, the X and Y are consensus parameters&lt;br&gt;
&gt; (overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)&lt;br&gt;
&gt; defined in param-spec.txt.&lt;br&gt;
&lt;br&gt;
should one be able to find these parameters&lt;br&gt;
(overload_dns_timeout_scale_percent and overload_dns_timeout_period_secs)&lt;br&gt;
on&lt;br&gt;
&lt;a href="https://consensus-health.torproject.org/#consensusparams" rel="noreferrer" \
target="_blank"&gt;https://consensus-health.torproject.org/#consensusparams&lt;/a&gt;&lt;br&gt; or \
in&lt;br&gt; &lt;a href="https://collector.torproject.org/recent/relay-descriptors/consensuses/" \
rel="noreferrer" target="_blank"&gt;https://collector.torproject.org/recent/relay-descriptors/consensuses/&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;
or is this not yet deployed?&lt;br&gt;
What are the values of these parameters currently?&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Every network parameter has a default value; \
IIUC, unless at least three   authorities are voting for some value, everybody will \
use the default.   It's normal for the authorities not to vote for a different \
value if they all think the default is reasonable.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The \
default for these parameters is in param-spec.txt at &lt;a \
href="https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/param-spec.txt#L194"&gt; \
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/param-spec.txt#L194&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;cheers,&lt;/div&gt;&lt;div&gt;-- \
&lt;br&gt;&lt;/div&gt;&lt;div&gt;Nick&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211017181905</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2021-10-17 18:19:05-0400</timestampReceived><subject>Re: [tor-dev] Proposal 335: An authority-only design for MiddleOnly</subject><body>

On Sun, Oct 10, 2021 at 12:39 PM nusenu &lt;nusenu-lists@riseup.net&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; has this proposal any implications wrt to making the MiddleOnly
&gt; feature available to clients (without requiring DA actions)?
&gt;
&gt; With ExcludeExitNodes/ExitNodes + ExcludeGuardNodes [1]
&gt; tor clients basically can get the "MiddleOnly" feature without DA actions,
&gt; but ExcludeGuardNodes [1] is not there yet. This is why I'm asking.
&gt;
&gt; [1] https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/436

I don't think it would especially help or prevent a
MiddleOnly/ExcludeGuard feature for clients.

&gt; &gt; ## Generating votes
&gt; &gt;
&gt; &gt; When voting for a relay with the `MiddleOnly` flag, an authority
&gt; &gt; should set all flags indicating that a relay is unusable for a
&gt; &gt; particular purpose, and against all flags indicating that the relay
&gt; &gt; is usable for a particular position.
&gt;
&gt; This part was not clear to me, but if I ignore it, the rest makes sense.
&gt; It is not clear because it says an authority should set _all_ flags to indicate
&gt; that a relay is unusable for a particular purpose.

Ooops, that should say that the authority should vote for all "this
relay is unusable" flags, and against all "this relay is usable for a
non-middle purpose" flags.  I'll edit.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211022230231</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-10-22 23:02:31-0400</timestampReceived><subject>Re: [tor-dev] Proposal 336: Randomized schedule for guard retries</subject><body>

On Fri, Oct 22, 2021 at 05:36:48PM -0400, Nick Mathewson wrote:
&gt; Title: Randomized schedule for guard retries
&gt; Author: Nick Mathewson
&gt; Created: 2021-10-22
&gt; Status: Open

Looks great. It's an obvious improvement, and I don't see any downsides.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211022231219</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-10-22 23:12:19-0400</timestampReceived><subject>Re: [tor-dev] Proposal 337: A simpler way to decide, "Is this guard usable?"</subject><body>

On Fri, Oct 22, 2021 at 05:38:27PM -0400, Nick Mathewson wrote:
&gt; In this circumstance, we _could_ say that we only build circuits to G1,
&gt; wait for them to succeed or fail, and only try G2 if we see that the
&gt; circuits to G1 have failed completely.  But that delays in the case that
&gt; G1 is down.
&gt; 
&gt; Instead, the first time we get a circuit request, we try to build one
&gt; circuit to G1.  On the next circuit request, if the circuit to G1 isn't
&gt; done yet, we launch a circuit to G2 instead.  The next request (if the
&gt; G1 and G2 circuits are still pending) goes to G3, and so on.  But
&gt; (here's the critical part!) we don't actually _use_ the circuit to G2
&gt; unless the circuit to G1 fails, and we don't actually _use_ the circuit
&gt; to G3 unless the circuits to G1 and G2 both fail.
&gt; 
&gt; This approach causes Tor clients to check the status of multiple
&gt; possible guards in parallel, while not actually _using_ any guard until
&gt; we're sure that all the guards we'd rather use are down.

On reflection, this design (both our current behavior, and also that
same behavior in your proposed new design) is kind of bizarre.

I've written my thoughts as a gitlab ticket for torspec:
https://gitlab.torproject.org/tpo/core/torspec/-/issues/68
but I'll paste them here too.

There are two suboptimal things about this approach:

(1) We're potentially touching a whole lot more guards than we need to.
For example, imagine we've gone offline and managed to mark our primary
guards down, but then we come back online and we're running ricochet,
and we have 100 contacts. We then launch 100 new circuits, which causes
us to start connections to the next 100 guards in our list. That's a
lot of surface area, impacting both security (many new guards that learn
that I'm a Tor user) and network load.

(2) Why should the number of new guards that we try in parallel be a
function of the number of circuits we're hoping to build? If it's a good
idea to try several in parallel in case the first one is slow to fail,
then shouldn't we do that even if there's only one circuit waiting? And
from the other side, if we have ten circuits waiting, why should that
map to testing ten new guards, when it is super unlikely that we're
going to end up using that tenth guard?

Here is a concrete alternative design: if our primary guards are down,
and we don't yet have a guard that we know we want to use, and there is
at least one circuit pending hoping to have a guard, then try to always
have three new guard attempts in-flight. This way we are getting the
parallel attempt feature, and we get it even if we don't have multiple
circuits waiting; and also we are limiting our surface area, and focusing
our guard attempts on the ones most likely to actually be used.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211027174826</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-27 17:48:26-0400</timestampReceived><subject>[tor-dev] Arti report 8: October 14 through October 27</subject><body>

# Arti Report 7: October 14 through October 27

# Towards Arti 0.0.1

On Monday November 1, we're planning to put out Arti version 0.0.1.  Our goal
is to include all the features that are needed for reasonable security, and a
top-level API that isn't _so_ far from completely wrong.  Right now, it looks
like we're in good shape for that timeline.

Since the last update, we've fixed a lot of smaller issues, including:
* running out of files on OSX
* making it harder to accidentally leak DNS requests
* lots of API refactoring
* restored the ability for multiple Arti instances to share a single set of
local directories
* easier setup
* easier API for stream isolatoin
* more reliable tests for asynchronous timeout-based logic
* and more!

We're now working on documentation and usability.  There's now an example
program in
[`crates/arti-client/examples`](https://gitlab.torproject.org/tpo/core/arti/-/blob/main/crates/arti-client/examples/hyper.rs)
 that uses [`hyper`](https://hyper.rs/) to download an HTTP document, and
we're adding examples elsewhere in our top-level API documentation.

# Followup from our guard implementation

Our work on guards (completed in the last round) has kicked off a new batch
of guard research.  As with other parts of the Tor protocols,
implementing our specification in Rust has exposed some weaknesses or
confusing points in our design.  In response to issues that we found,
we've opened a few issues and written a couple of proposals to improve
our code.

For example, see:
* [Proposal 336](https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/336-randomize-guard-retries.md),
  to randomize guard retry timing.
* [Proposal 337](https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/337-simpler-guard-usability.md),
  to describe a simpler formulation of our guard behavior.
* [torspec#67](https://gitlab.torproject.org/tpo/core/torspec/-/issues/67),
  to treat guards as usable more eagerly.
* [torspec#68](https://gitlab.torproject.org/tpo/core/torspec/-/issues/68),
  to improve our behavior when our primary guards are down.


# What's next

Once the next release is out, we'll turn our attention to Arti 0.1.0.
For that release, our priority target is beta testing and experimental
embedding.  We'll be working to improve performance and to stabilize a
set of stable APIs to provide a wider set of functionality for
applications that want to embed Arti in different scenarios.

We'll need your help, though: we will need feedback from everybody who's
interested in using our code, in order to make sure that we're providing
solid, usable interfaces that do what you need.  Please try it out, and
let us know what's bad or missing!

We're hoping to get Arti 0.1.0 released some time in March of 2022, with
multiple smaller update releases between now and then.  At our bi-weekly
meeting next Wednesday, we'll be prioritizing tasks for the next set of
releases, and refining our roadmap for the coming months.  Why not join
us?  Information is on the
[meeting pad](https://pad.riseup.net/p/arti-meeting-pad-keep).


# Thanks!

Thanks to Jani Monoses and Dimitris Apostolou for their patches in this
release!

And special thanks and welcome to eta, our new team member!  She's
started with Tor last Tuesday, and has hit the ground running, already
fixing substantial bugs and refactoring a bunch of tricky code.  It's
great to watch the pace and quality of our development improve as more
people join the team!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211028185304</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2021-10-28 18:53:04-0400</timestampReceived><subject>Re: [tor-dev] [tor-relays] Relays running an unsupported (EOL) Tor version</subject><body>

&gt; mpan:
&gt;&gt; Is there any data available that sheds light on
&gt;&gt; why operators run outdated versions

Besides latent OS packages, or being busy, or simply not
updating things, those are natures of computing world anyway...
or having no network operations crypto-monetization model as
some nextgen p2p overlay-exit networks are now working with...
there can be other reasons people may run different versions...

tor the software is different from from Tor Project Inc.
The software is opensource and BSD licensed. Thus anyone
may copy, run, share, redistribute, fork, modify, support it,
create and vote in any consensus, run relays, run more
networks than just tor on their nodes, run services, etc,
completely without involvement from, and indeed in full
disregard of whatever Tor Project Inc and its people may say.
The tor protocol, code, and operational network are not
the property of Tor Project Inc, nor are its operators
and users under its command and control.
tor's users may run whichever of the many tor client implementations
they wish to run, and may run whatever protocols, applications, and
uses over the tor network that they wish.
tor's relay operators and dirauths are free to run and support
the running of older, different, forked, or project protocol addition
enhancement or migration versions, in part in order to support features
that some of the entire global userbase of tor are using, and have
no good replacement for, or may wish to develop apps to, and run
them upon or over, such features and capabilities in the future.

Such as the censored topic of v2 onions with OnionCat,
OnionVPN, etc in order to continue or design, deploy, and
run new p2p apps comms, etc over those, ie...

https://www.onioncat.org/

So a large number of relays may be freely and rightly choosing,
as is their right if they wish, to continue running a v2 onion version
for that.

And overlay nets have some great uses, some examples
of which Tor Project advertises, such that those users or
even operators may prefer not to post, so you may want to
consider some of those good uses for them in their stead,
even ones that are dependent on such versions.

And another topical fact re versions, which will be censored, is
that attackers do falsify their version strings, and a lot more, in
order to run whatever custom exploits they want against the network.
And that Traffic Analysis and Sybil attacks nodes are real and in use.
And that there is no longer sufficient warning and ongoing visibly
posted education on these and other matters, in particular
at point of download, install, splashpage, and frontpage...
even some warnings were removed... versioned away.
These are the sort of lack of info that can put users at severe risk.
Tor Project Inc is censoring embarassing or simple facts / info.
And is now attempting to silence and kill useful and in use features
and future application possibilities based on them, whitewashing
them with handwavy vague absolutist claims such as "old" or
"insecure", instead of creating detailed comparisons for users.
tor's users and operators are the ones who get to choose their own
versions, and use appropriate features / freedom / security tradeoffs,
not by the sole dictate of Tor Project Inc.
Which by the way is funded to $Millions per year so that is not
an argument to killing otherwise modularizable features either,
but may be why there are insufficient disclaimers, and censors.

On 10/28/21, Georg Koppen &lt;gk@torproject.org&gt; wrote:
&gt; I don't think we have [...] feedback

Well when Tor's hypocrites, liars, and frauds are censoring feedback
etc off all their "bricked up" fora, full stop. Thus their users and operators
are missing information and topical discussions may hardly flourish
can they in an environment of censor, chilled, and steered speech.
The censorship of conversation on tor by Tor Project Inc and its people...
while publicizing claims to cherish and uphold Free Speech ideals...
is blatantly hypocritical, and it must end.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211029192552</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-29 19:25:52-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

Hi,

thanks for your input.

There will be a new iteration of the draft and I will reply to your email
again once that is done, as it should cover some of the areas you mentioned.

kind regards,
nusenu

yanmaani@cock.li:
&gt; (sorry for replying directly before)
&gt; On 2021-10-03 16:16, nusenu-lists at riseup.net wrote:
&gt; &gt; Hi,
&gt; &gt; 
&gt; &gt; I wrote down a spec for a simple web of trust
&gt; &gt; for relay operator IDs:
&gt; 
&gt; Some comments, in no particular order:
&gt; 
&gt; Why not just put the keys in directly, or even a magnet link to your latest web of \
&gt; trust? That would remove the need to trust SSL CAs. 
&gt; What problems does this solve, specifically, and how? If I - me personally, not the \
&gt; generic I - wanted to spin up a relay, how would I do that? 
&gt; Would I go on this mailing list and ask random people to sign my relay? If so, it's \
&gt; not very useful. 
&gt; Or would I just run it without any signatures at all? If so, it's not very useful.
&gt; 
&gt; The basic problem, I think, is the same as for PGP: it's not really clear what \
&gt; you're attesting to when you sign. If I sign a my mate's relay, and then that relay \
&gt; turns out to be dodgy, do I also lose my relay operation privileges? 
&gt; I think that WoT systems have a definite value for preventing Sybil attacks, they \
&gt; are very powerful, and I don't think these issues are insurmountable, but they have \
&gt; to be addressed. 
&gt; If you're going to do it in a "machine-friendly" manner, then I suppose you have to \
&gt; come up with some kind of formalized notion of what trust represents, maybe have \
&gt; some numerical scale so you can define (just as an example) 100 = "I've personally \
&gt; audited the hardware", 70 = "This is an organization I trust", 10 = "I know who \
&gt; this person is, it's not just a fresh hotmail". 
&gt; Or, you can do it in a "human-friendly" manner, where you just write text notes \
&gt; with each trust relationship. That would make it quite useless to parse, but could \
&gt; be useful to give us some information about relays. 
&gt; Now, here's my gut feeling:
&gt; 
&gt; Instinctively, it seems silly to have the trust relationships denote "this person \
&gt; is a good relay operator" (how would you even quantify that?), and maybe more \
&gt; reasonable to have it denote "I know this guy, he didn't just pop into existence \
&gt; last Thursday". And if you're doing that, it seems like the second approach makes \
&gt; more sense. This clearly suggests some limitations to it, but possibly still \
&gt; useful. 
&gt; Anyway, if you're going to do that, it might also be reasonable to hook into a \
&gt; pre-existing web of trust, like GPG or something. That way, we can encode stuff \
&gt; like "I trust my mate Alice, she isn't a relay operator, she trusts Bob, who is, \
&gt; therefore I transitively trust Bob." This doesn't work great if Alice has to \
&gt; register in the separate Tor Web of Trust thing. (On the other hand, we introduce \
&gt; the problem of someone doing a Sybil by being introduced to random people who will \
&gt; sign literally anything, not being aware of Tor, and then showing up with \
&gt; plausible-looking trust pairs. But maybe that's not such a big problem, because \
&gt; that arguably looks even shadier?) 
&gt; I think this is a very good initiative, anyway.

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211029204853</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-29 20:48:53-0400</timestampReceived><subject>[tor-dev] proposal 328 status</subject><body>

Hi,

I'm wondering if the current version of the text is the latest available version of it or
if there is somewhere a newer version that hasn't been pushed yet?


https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/328-relay-overload-report.md

"Status: Draft" but it is already in released tor versions.

also in the context of this change:
https://gitlab.torproject.org/tpo/core/tor/-/issues/40364
the proposal still mentions extra-info documents.

thanks,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211008142342</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-08 14:23:42-0400</timestampReceived><subject>[tor-dev] Proposal 335: An authority-only design for MiddleOnly</subject><body>

```
Filename: 335-middle-only-redux.md
Title: An authority-only design for MiddleOnly
Author: Nick Mathewson
Created: 2021-10-08
Status: Open
```

# Introduction

This proposal describes an alternative design for a `MiddleOnly`
flag.  Instead of making changes at the client level, it adds a
little increased complexity at the directory authority's voting
process.  In return for that complexity, this design will work
without additional changes required from Tor clients.

For additional motivation and discussion see proposal 334 by Neel
Chauhan, and the related discussions on tor-dev.

# Protocol changes

## Generating votes

When voting for a relay with the `MiddleOnly` flag, an authority
should set all flags indicating that a relay is unusable for a
particular purpose, and against all flags indicating that the relay
is usable for a particular position.

These flags SHOULD be set in a vote whenever `MiddleOnly` is
present, and only when the authority is configured to vote on the
`BadExit` flag.

  * `BadExit`

These flags SHOULD be cleared in a vote whenever `MiddleOnly` is
present.

  * `Exit`
  * `Guard`
  * `HSDir`
  * `V2Dir`

## Computing a consensus

This proposal will introduce a new consensus method (probably 32).
Whenever computing a consensus using that consensus method or later,
authorities post-process the set of flags that appear in the
consensus after flag voting takes place, by applying the same rule
as above.

That is, with this consensus method, the authorities first compute
the presence or absence of each flag on each relay as usual.  Then,
if the `MiddleOnly` flag is present, the authorities set `BadExit`,
and clear `Exit`, `Guard`, `HSDir`, and `V2Dir`.

# Configuring authorities

We'll need a means for configuring which relays will receive this
flag.  For now, we'll just reuse the same mechanism as
`AuthDirReject` and `AuthDirBadExit`: a set of torrc configuration
lines listing relays by address.  We'll call this
`AuthDirMiddleOnly`.

We'll also add an `AuthDirListsMiddleOnly` option to turn on or off
voting on this option at all.

# Notes on safety and migration

Under this design, the MiddleOnly option becomes useful immediately,
since authorities that use it will stop voting for certain
additional options for MiddleOnly relays without waiting for the
other authorities.

We don't need to worry about a single authority setting MiddleOnly
unilaterally for all relays, since the MiddleOnly flag will have no
special effect until most authorities have upgraded to the new
consensus method.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211008173726</emailId><senderName></senderName><senderEmail>ezhigp</senderEmail><timestampReceived>2021-10-08 17:37:26-0400</timestampReceived><subject>Re: [tor-dev] Proposal 335: An authority-only design for MiddleOnly</subject><body>

&gt; ```
&gt; Filename: 335-middle-only-redux.md
&gt; Title: An authority-only design for MiddleOnly
&gt; Author: Nick Mathewson
&gt; Created: 2021-10-08
&gt; Status: Open
&gt; ...
&gt; 
&gt; These flags SHOULD be set in a vote whenever `MiddleOnly` is
&gt; present, and only when the authority is configured to vote on the
&gt; `BadExit` flag.
&gt; 
&gt; * `BadExit`
&gt; 
&gt; These flags SHOULD be cleared in a vote whenever `MiddleOnly` is
&gt; present.
&gt; 
&gt; * `Exit`
I believe that BadExit is supposed to be given together with Exit, to mark that \
technically it's possible to exit from this relay, but it is not recommended unless \
you know what you do.
&gt; * `Guard`
&gt; * `HSDir`
&gt; * `V2Dir`
It looks like we don't fear such a relay at Intro?
Or it is a sign that this proposal is only a set of quick actions before #334?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211010163900</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-10 16:39:00-0400</timestampReceived><subject>Re: [tor-dev] Proposal 335: An authority-only design for MiddleOnly</subject><body>

Hi,

has this proposal any implications wrt to making the MiddleOnly
feature available to clients (without requiring DA actions)?

With ExcludeExitNodes/ExitNodes + ExcludeGuardNodes [1]
tor clients basically can get the "MiddleOnly" feature without DA actions,
but ExcludeGuardNodes [1] is not there yet. This is why I'm asking.

[1] https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/436


&gt; ## Generating votes
&gt; 
&gt; When voting for a relay with the `MiddleOnly` flag, an authority
&gt; should set all flags indicating that a relay is unusable for a
&gt; particular purpose, and against all flags indicating that the relay
&gt; is usable for a particular position.

This part was not clear to me, but if I ignore it, the rest makes sense.
It is not clear because it says an authority should set _all_ flags to indicate
that a relay is unusable for a particular purpose.


kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211030065607</emailId><senderName>Sebastian Hoffmann</senderName><senderEmail>oreophilum@riseup.net</senderEmail><timestampReceived>2021-10-30 06:56:07-0400</timestampReceived><subject>[tor-dev] Accessing Shared Random Values as a Protocol on top of Tor</subject><body>

Hi,

I'm wondering if I can access the shared random value[1] while
developing a
protocol/application on top of Tor onion services. The application is
still in
early development, but it would be great if I could depend on the shared
random
value.

If this is not the correct mailing list for this question, I would be
glad if
you could point me to one.

--Sebastian

[1]: PUB-SHAREDRANDOM in
https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210901134024</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-09-01 13:40:24-0400</timestampReceived><subject>[tor-dev] No arti report this week.</subject><body>

Hi!

Usually I do Arti reports every other Wednesday, but this week I'm on
vacation.  I'll send the next report on September 15, so that the
reports can be offset from the Arti meetings.

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211022213648</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-22 21:36:48-0400</timestampReceived><subject>[tor-dev] Proposal 336: Randomized schedule for guard retries</subject><body>

```
Filename: 336-randomize-guard-retries.md
Title: Randomized schedule for guard retries
Author: Nick Mathewson
Created: 2021-10-22
Status: Open
```

# Introduction

When we notice that a guard isn't working, we don't mark it as retriable
until a certain interval has passed.  Currently, these intervals are
fixed, as described in the documentation for `GUARDS_RETRY_SCHED` in
`guard-spec` appendix A.1.  Here we propose using a randomized retry
interval instead, based on the same decorrelated-jitter algorithm we use
for directory retries.

The upside of this approach is that it makes our behavior in
the presence of an unreliable network a bit harder for an attacker to
predict. It also means that if a guard goes down for a while, its
clients will notice that it is up at staggered times, rather than
probing it in lock-step.

The downside of this approach is that we can, if we get unlucky
enough, completely fail to notice that a preferred guard is online when
we would otherwise have noticed sooner.

Note that when a guard is marked retriable, it isn't necessarily retried
immediately.  Instead, its status is changed from "Unreachable" to
"Unknown", which will cause it to get retried.

For reference, our previous schedule was:

```
   {param:PRIMARY_GUARDS_RETRY_SCHED}
      -- every 10 minutes for the first six hours,
      -- every 90 minutes for the next 90 hours,
      -- every 4 hours for the next 3 days,
      -- every 9 hours thereafter.

   {param:GUARDS_RETRY_SCHED} --
      -- every hour for the first six hours,
      -- every 4 hours for the next 90 hours,
      -- every 18 hours for the next 3 days,
      -- every 36 hours thereafter.
```

# The new algorithm

We re-use the decorrelated-jitter algorithm from `dir-spec` section 5.5.
The specific formula used to compute the 'i+1'th delay is:

```
Delay_{i+1} = MIN(cap, random_between(lower_bound, upper_bound))
where upper_bound = MAX(lower_bound+1, Delay_i * 3)
      lower_bound = MAX(1, base_delay).
```

For primary guards, we set base_delay to 30 seconds and cap to 6 hours.

For non-primary guards, we set base_delay to 10 minutes and cap to 36
hours.

(These parameters were selected by simulating the results of using them
until they looked "a bit more aggressive" than the current algorithm, but
not too much.)

The average behavior for the new primary schedule is:

```
First 1.0 hours: 10.14283 attempts. (Avg delay 4m 47.41s)
First 6.0 hours: 19.02377 attempts. (Avg delay 15m 36.95s)
First 96.0 hours: 56.11173 attempts. (Avg delay 1h 40m 3.13s)
First 168.0 hours: 83.67091 attempts. (Avg delay 1h 58m 43.16s)
Steady state: 2h 36m 44.63s between attempts.
```

The average behavior for the new non-primary schedule is:

```
First 1.0 hours: 3.08069 attempts. (Avg delay 14m 26.08s)
First 6.0 hours: 8.1473 attempts. (Avg delay 35m 25.27s)
First 96.0 hours: 22.57442 attempts. (Avg delay 3h 49m 32.16s)
First 168.0 hours: 29.02873 attempts. (Avg delay 5h 27m 2.36s)
Steady state: 11h 15m 28.47s between attempts.
```
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210915232140</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-09-15 23:21:40-0400</timestampReceived><subject>[tor-dev] Arti report 5: August 18 through September 15</subject><body>

# Arti Report 5: August 4 through September 15

## Activities since our last report

I'm back, with updates from the last month!  We've spent a lot of time over
the last on cleaning up technical debt issues in our code that had
accumulated as I wrote it.  There are more tests and warnings enabled than
before, and we've changed some new internal APIs to make them unable to
panic.  We're also using the [`derive_builder`][derive_builder] tool to throw
out a bunch of boilerplate code.

When I wrote last month, I'd just finished up the implementation for circuit
build timeout inference.  As followup work to that, I worked with Mike Perry
to collect all of the missing specification issues that I'd found while
cloning that feature, and [roll them back][torspec-mr-40] into our
`path-spec.txt` document.  Mike'sw found a couple of mistakes in my
implementation that I was able to resolve—fortunately, by removing code from
the Arti timeout inference code.



## Getting a head start on API design

API design will be the focus of our 0.1.0 release, but we still want to get
it "as right as we can" in the upcoming 0.0.1 version.

With that in mind, we've started enumerating the various kinds of programs
and environments that we need to support down the road, and [working on a list
of example programs][ticket-164] that we might be able to ship with Arti.
(My own experience so far is that writing example code is just about the best
way to find API deficiencies.)


## Uplifting new features from C Tor

For our work on congestion control, we're getting a new
[circuit extension handshake][prop332].  Going forward, as we add features to
C Tor, we're going to try to add them to Arti at around the same time.  With
that in mind, we have the new handshake implemented (but not enabled): we
used its implementation to validate our specifications double-check
our test vectors.

## Towards guard support

Our largest remaining priority for Arti 0.0.1 is full support for
[guard nodes][guard-spec].  (In Tor, a "guard node" is a relay that a client
decides to use as the first hop for all of its circuits for a long time.
Using guard nodes improves resistance against many kinds of attacks based on
hostile relays.)

We've started laying the groundwork here: we now have support for all of the
guard-related consensus parameters, and we've reworked our relay selection
code to allow picking multiple weighted random items without replacement.
We've also added some previously unneeded lookup-by-ID features to network
directory code.

(Fun fact: the Tor implementation of mapping IDs to relays has been
historically ugly, since we don't really know a relay's ed25519 identity
until we have a microdescriptor for it.  In C, this has led to a reasonably
messy pile of dangling pointer bugs…which Rust won't even let us write!
Also, we've made better design choices in Arti about our directory objects,
so we don't have do support all of the strange mutability that our C code had
to try to handle.)

We're now in the midst of coding up a guard implementation.  The tricky part
here is that our guard logic affects circuit building selection (since
circuit paths must begin with a guard), but circuit construction affects
guard selection.  We're experimenting with different designs to try to keep
the complexity here under control.



# Thanks to awesome volunteers!

Thanks to Jani Monoses for migrating Arti to the tracing crate and adding
journald support; to Robin Leander Schröder for cleaning up some of our
`unwrap_or()` code; to S0AndS0 for work enabling the `unwrap_used` Clippy
lint; to Daniel Eades for work cleaning up Clippy lints in our test modules,
and to Trinity Pointard for work on stream isolation and reproducible builds!


[ticket-164]: https://gitlab.torproject.org/tpo/core/arti/-/issues/164
[prop-332]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/332-ntor-v3-with-extra-data.md
 [derive_builder]: https://crates.io/crates/derive_builder
[torspec-mr-40]:
https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/40
[guard-spec]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/guard-spec.txt
 _______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210918201430</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2021-09-18 20:14:30-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Fri, Jul 16, 2021 at 8:31 AM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
 [...]
&gt; But this post from Trevor also made me realize a bigger issue with the
&gt; protocol Nick proposed:
&gt;
&gt; If you want the protocol to work with Walking Onions, it needs to be
&gt; *post-specified peer*.  That is, contrary to:
&gt;
&gt; &gt; The client knows:
&gt; &gt;   * B: a public "onion key" for S
&gt;
&gt; The client will in fact _not_ know B in advance in a Walking Onions
&gt; setting, but rather will learn it at the end of the handshake.  The
&gt; protocol Nick specified does in fact use B in the first message, unlike
&gt; the current ntor handshake, which just sends KEYID(B) in the first flow,
&gt; but it's not part of the math, or indeed as far as I can see, used for
&gt; anything at all in Section 5.1.4 of tor-spec.txt, and so can be easily
&gt; removed (and replaced with B being sent by the server) for Walking
&gt; Onions.

Well, in the current deployment, the client only knows one B for each
server at a time, and if the server responds with a B that the client
_doesn't_ recognize, the client won't have any idea whether or not B
is really authentic. (Priving that B is authentic is a big part of
what Walking Onions has to solve.)

Walking Onions is a big enough set of protocol changes that I'm
comfortable requiring a subsequent handshake bump when we get there.
Who knows, we may want another one between now and then if we decide
to go hybrid-PQ or use Noise or something :)

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211022213827</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-10-22 21:38:27-0400</timestampReceived><subject>[tor-dev] Proposal 337: A simpler way to decide, "Is this guard usable?"</subject><body>

```
Filename: 337-simpler-guard-usability.md
Title: A simpler way to decide, "Is this guard usable?"
Author: Nick Mathewson
Created: 2021-10-22
Status: Open
```

# Introduction

The current `guard-spec` describes a mechanism for how to behave when
our primary guards are unreachable, and we don't know which other guards
are reachable.  This proposal describes a simpler method, currently
implemented in [Arti](https://gitlab.torproject.org/tpo/core/arti/).

(Note that this method might not actually give different results: its
only advantage is that it is much simpler to implement.)

## The task at hand

For illustration, we'll assume that our primary guards are P1, P2, and
P3, and our subsequent guards (in preference order) are G1, G2, G3, and
so on.  The status of each guard is Reachable (we think we can connect
to it), Unreachable (we think it's down), or Unknown (we haven't tried
it recently).

The question becomes, "What should we do when P1, P2, and P3 are
Unreachable, and G1, G2, ... are all Unknown"?

In this circumstance, we _could_ say that we only build circuits to G1,
wait for them to succeed or fail, and only try G2 if we see that the
circuits to G1 have failed completely.  But that delays in the case that
G1 is down.

Instead, the first time we get a circuit request, we try to build one
circuit to G1.  On the next circuit request, if the circuit to G1 isn't
done yet, we launch a circuit to G2 instead.  The next request (if the
G1 and G2 circuits are still pending) goes to G3, and so on.  But
(here's the critical part!) we don't actually _use_ the circuit to G2
unless the circuit to G1 fails, and we don't actually _use_ the circuit
to G3 unless the circuits to G1 and G2 both fail.

This approach causes Tor clients to check the status of multiple
possible guards in parallel, while not actually _using_ any guard until
we're sure that all the guards we'd rather use are down.

## The current algorithm and its drawbacks

For the current algorithm, see `guard-spec` section 4.9: circuits are
exploratory if they are not using a primary guard.  If such an
exploratory circuit is `waiting_for_better_guard`, then we advance it
(or not) depending on the status of all other _circuits_ using guards that
we'd rather be using.

In other words, the current algorithm is described in terms of actions
to take with given circuits.

For Arti (and for other modular Tor implementations), however, this
algorithm is a bit of a pain: it introduces dependencies between the
guard code and the circuit handling code, requiring each one to mess
with the other.

# Proposal

I suggest that we describe an alternative algorithm for handing circuits
to non-primary guards, to be used in preference to the current
algorithm.  Unlike the existing approach, it isolates the guard logic a
bit better from the circuit logic.

## Handling exploratory circuits

When all primary guards are Unreachable, we need to try non-primary
guards.  We select the first such guard (in preference order) that is
neither Unreachable nor Pending.  Whenever we give out such a guard, if
the guard's status is Unknown, then we call that guard "Pending" until
the attempt to use it succeeds or fails.  We remember when the guard
became Pending.

&gt; Aside: None of the above is a change from our existing specification.

After completing a circuit, the implementation must check whether
its guard is usable.  A guard is usable according to these rules:

Primary guards are always usable.

Non-primary guards are usable for a given circuit if every guard earlier
in the preference list is either unsuitable for that circuit
(e.g. because of family restrictions), or marked as Unreachable, or has
been pending for at least `{NONPRIMARY_GUARD_CONNECT_TIMEOUT}`.

Non-primary guards are unusable for a given circuit if some guard earlier
in the preference list is suitable for the circuit _and_ Reachable.

Non-primary guards are unusable if they have not become usable after
`{NONPRIMARY_GUARD_IDLE_TIMEOUT}` seconds.

If a circuit's guard is neither usable nor unusable immediately, the
circuit is not discarded; instead, it is kept (but not used) until it
becomes usable or unusable.

&gt; I am not 100% sure whether this description produces the same behavior
&gt; as the current guard-spec, but it is simpler to describe, and has
&gt; proven to be simpler to implement.

## Implications for program design.

(This entire section is implementation detail to explain why this is a
simplification from the previous algorithm. It is for explanatory
purposes only and is not part of the spec.)

With this algorithm, we cut down the interaction between the guard code
and the circuit code considerably, but we do not remove it entirely.
Instead, there remains (in Arti terms) a pair of communication channels
between the circuit manager and the guard manager:

 * Whenever a guard is given to the circuit manager, the circuit manager
   receives the write end of a single-use channel to
   report whether the guard has succeeded or failed.

 * Whenever a non-primary guard is given to the circuit manager, the
   circuit receives the read end of a single-use channel that will tell
   it whether the guard is usable or unusable.  This channel doesn't
   report anything until the guard has one status or the other.

With this design, the circuit manager never needs to look at the list of
guards, and the guard manager never needs to look at the list of
circuits.

## Subtleties concerning "guard success"

Note that the above definitions of a Reachable guard depend on reporting
when the _guard_ is successful or failed. This is not necessarily the
same as reporting whether the _circuit_ is successful or failed.  For
example, a circuit that fails after the first hop does not necessarily
indicate that there's anything wrong with the guard.  Similarly, we can
reasonably conclude that the guard is working (at least somewhat) as
long as we have an open channel to it.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211003161605</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-03 16:16:05-0400</timestampReceived><subject>[tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

Hi,

I wrote down a spec for a simple web of trust
for relay operator IDs:

https://gitlab.torproject.org/nusenu/torspec/-/blob/simple-wot-for-relay-operator-ids/ \
proposals/ideas/xxx-simple-relay-operator-wot.md#a-simple-web-of-trust-for-tor-relay-operator-ids


This is related to:
https://gitlab.torproject.org/tpo/network-health/metrics/relay-search/-/issues/40001
https://lists.torproject.org/pipermail/tor-relays/2020-July/018656.html

kind regards,
nusenu
-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211004114919</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-10-04 11:49:19-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

[Attachment #2 (multipart/signed)]


On 03 Oct (18:16:05), nusenu wrote:
&gt; Hi,
&gt; 
&gt; I wrote down a spec for a simple web of trust
&gt; for relay operator IDs:
&gt; 
&gt; https://gitlab.torproject.org/nusenu/torspec/-/blob/simple-wot-for-relay-operator-id \
&gt; s/proposals/ideas/xxx-simple-relay-operator-wot.md#a-simple-web-of-trust-for-tor-relay-operator-ids
&gt; 

Hi nusenu!

Maybe you would like to open a merge request or post it on tor-dev in its
entirety so we can comment? Whatever you prefer.

Thanks!
David

-- 
beACX6/yfvyT3YZaLcsyGOAcmV/wX/HH3vFXWRSiLeo=


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211004135643</emailId><senderName>Zaphoid via tor-dev</senderName><senderEmail>tor-dev@lists.torproject.org</senderEmail><timestampReceived>2021-10-04 13:56:43-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

While I understand the rationale for proposals such as these and agree there is a \
problem with malicious relays on the network, I feel that proposals such as these:

- Raise the barrier for entry. People that would like to contribute to the network by \
running a relay or several relays would have this extra administrative burden now

- These extra verification steps and collected details nibble-away ones ability to \
contribute to the network anonymously.

- Despite individuals' best intent, systems and processes for collection and \
aggregation of personal details often have vulnerabilities. These vulnerabilities, \
when exported could be used to harm the very people the project is designed to \
protect.

Z

Sent with ProtonMail Secure Email.

------- Original Message -------

On Sunday, October 3rd, 2021 at 12:16 PM, nusenu &lt;nusenu-lists@riseup.net&gt; wrote:

&gt; Hi,
&gt; 
&gt; I wrote down a spec for a simple web of trust
&gt; 
&gt; for relay operator IDs:
&gt; 
&gt; https://gitlab.torproject.org/nusenu/torspec/-/blob/simple-wot-for-relay-operator-id \
&gt; s/proposals/ideas/xxx-simple-relay-operator-wot.md#a-simple-web-of-trust-for-tor-relay-operator-ids
&gt;  
&gt; This is related to:
&gt; 
&gt; https://gitlab.torproject.org/tpo/network-health/metrics/relay-search/-/issues/40001
&gt;  
&gt; https://lists.torproject.org/pipermail/tor-relays/2020-July/018656.html
&gt; 
&gt; kind regards,
&gt; 
&gt; nusenu
&gt; ------------------------------------------------------------------------------------ \
&gt; ------------------------------------------------------------------------------------ \
&gt; ------------------------------------------------------------------------------------ \
&gt; ------------------------------------------------------------------------------------ \
&gt; -------------------------------------------------------------------------------------------------------------------------------
&gt;  
&gt; https://nusenu.github.io
&gt; 
&gt; tor-dev mailing list
&gt; 
&gt; tor-dev@lists.torproject.org
&gt; 
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20211004170248</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-10-04 17:02:48-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

&gt; Maybe you would like to open a merge request or post it on tor-dev in its
&gt; entirety so we can comment? Whatever you prefer.

https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/49


-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20211024053723</emailId><senderName></senderName><senderEmail>yanmaani</senderEmail><timestampReceived>2021-10-24 05:37:23-0400</timestampReceived><subject>Re: [tor-dev] A Simple Web of Trust for Tor Relay Operator IDs</subject><body>

(sorry for replying directly before)
On 2021-10-03 16:16, nusenu-lists at riseup.net wrote:
&gt; Hi,
&gt; 
&gt; I wrote down a spec for a simple web of trust
&gt; for relay operator IDs:

Some comments, in no particular order:

Why not just put the keys in directly, or even a magnet link to your 
latest web of trust? That would remove the need to trust SSL CAs.

What problems does this solve, specifically, and how? If I - me 
personally, not the generic I - wanted to spin up a relay, how would I 
do that?

Would I go on this mailing list and ask random people to sign my relay? 
If so, it's not very useful.

Or would I just run it without any signatures at all? If so, it's not 
very useful.

The basic problem, I think, is the same as for PGP: it's not really 
clear what you're attesting to when you sign. If I sign a my mate's 
relay, and then that relay turns out to be dodgy, do I also lose my 
relay operation privileges?

I think that WoT systems have a definite value for preventing Sybil 
attacks, they are very powerful, and I don't think these issues are 
insurmountable, but they have to be addressed.

If you're going to do it in a "machine-friendly" manner, then I suppose 
you have to come up with some kind of formalized notion of what trust 
represents, maybe have some numerical scale so you can define (just as 
an example) 100 = "I've personally audited the hardware", 70 = "This is 
an organization I trust", 10 = "I know who this person is, it's not just 
a fresh hotmail".

Or, you can do it in a "human-friendly" manner, where you just write 
text notes with each trust relationship. That would make it quite 
useless to parse, but could be useful to give us some information about 
relays.

Now, here's my gut feeling:

Instinctively, it seems silly to have the trust relationships denote 
"this person is a good relay operator" (how would you even quantify 
that?), and maybe more reasonable to have it denote "I know this guy, he 
didn't just pop into existence last Thursday". And if you're doing that, 
it seems like the second approach makes more sense. This clearly 
suggests some limitations to it, but possibly still useful.

Anyway, if you're going to do that, it might also be reasonable to hook 
into a pre-existing web of trust, like GPG or something. That way, we 
can encode stuff like "I trust my mate Alice, she isn't a relay 
operator, she trusts Bob, who is, therefore I transitively trust Bob." 
This doesn't work great if Alice has to register in the separate Tor Web 
of Trust thing. (On the other hand, we introduce the problem of someone 
doing a Sybil by being introduced to random people who will sign 
literally anything, not being aware of Tor, and then showing up with 
plausible-looking trust pairs. But maybe that's not such a big problem, 
because that arguably looks even shadier?)

I think this is a very good initiative, anyway.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210918202745</emailId><senderName></senderName><senderEmail>ezhigp</senderEmail><timestampReceived>2021-09-18 20:27:45-0400</timestampReceived><subject>Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only</subject><body>

-------- Original Message --------
From: Neel Chauhan &lt;neel@neelc.org&gt;
Apparently from: tor-dev-bounces@lists.torproject.org
To: tor-dev@lists.torproject.org
Subject: Re: [tor-dev] Proposal 334: A flag to mark Relays as middle-only
Date: Fri, 17 Sep 2021 16:09:43 -0700

&gt; Hi nusenu (and tor-dev@),
&gt; 
&gt; On 2021-09-17 16:02, nusenu wrote:
&gt; &gt; it would be great if you could open a MR for the proposal so we can
&gt; &gt; always see the latest version and changes
&gt; &gt; there.
&gt; &gt; (Over time it became unclear what comments have already been addressed
&gt; &gt; in the text an which didn't.)
&gt; 
&gt; Done: https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/46
Line 102&gt; single directory authority servre [3].
Typo here.
&gt; 
&gt; &gt; kind regards,
&gt; &gt; nusenu
&gt; 
&gt; -Neel
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210805172119</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-08-05 17:21:19-0400</timestampReceived><subject>[tor-dev] Arti Report 3: July 21 through August 4</subject><body>

Still quiet here for the last couple of weeks.  I've been moving ahead on
circuit timeout inference, and reviewing _lots_ of volunteer-submitted code
(and job applications).

The quiet part is coming to an end: Two of the engineers who have been on
vacation or leave are back, and we're all trying to ramp up.  We're also
hoping to be scheduling interviews with prospective co-workers soon, so
that's taking up some of our time.. but once it's done, it should accelerate
our pace a bit.

## Circuit timeout inference logic

I had hoped to be done with this by now, but it turns out that this code
touches on several key architectural issues that we'll want to make sure we
get right in the future.  I'll touch on them a bit here.

### Persistent state

The Tor protocol requires clients to keep persistent state across
invocations in order to achieve good performance and privacy.  Two
notable cases of this are in the circuit management code: client need to
remember circuit timeout data, and need to remember guard selection
data.

The C Tor client records these items in the same ad-hoc format used by
Tor's configuration code.  But for Rust, using serde seems like a better
fit.

I want to maintain the feature that Arti has now where you can run
multiple processes with the same state directory.  That could get
tricky in the long run, but I think it's a design feature we need if
we're going to keep Arti flexible enough for general use.

My first implementation here is going to be bare-bones, but I'm trying
to design it to grow and get replaced down the line.

### Inter-module event notification

Frequently one module needs to notify another when some event occurs.
In the circuit-timeout case, we need to notify the circuit manager
whenever the network parameters have changed.

We don't want to have the circuit manager probing the directory manager,
since that's a higher-level module.  And we don't want it probing the
`NetDir` object it gets whenever it's time to build a circuit, since
that would be a weird side-effect.

The best I've been able to come up with for now is to allow the
directory manager to expose a `Stream` of events for directory changes,
and to have the `TorClient` object use events from that stream to alert
the circuit manager to possibly changed network parameters.  I think
this should scale to other kinds of inter-module events in the future,
though I do have a slight concern that it makes `TorClient` harder to
reproduce with lower-level crates than it would be otherwise.  (There's
probably no avoiding that at this stage, though.)

### Non-user-initiated background tasks

The circuit timeout code sometimes needs to build testing circuits in
order to gather data, and the guard code does too.  If we code this in a
sloppy way, we'll wind up with three separate systems that all build circuits
for different reasons at different times.  With any luck, we can summarize
the triggers from all of these circuit types into a single system.

## Coming up

We've been working on refinements to the API in `arti-tor-client` to try to
simplify the API as much as possible while still exposing the full back-end
functionality.  Everybody should expect a lot of unstability here.

I am still hoping very much that the next time I write one of these reports,
we'll be done with circuit timeout inference, and I can talk about API work
and early progress on guards! :)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210809165412</emailId><senderName>Apratim Ranjan Chakrabarty</senderName><senderEmail>abishekhmjee@gmail.com</senderEmail><timestampReceived>2021-08-09 16:54:12-0400</timestampReceived><subject>[tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring #Update</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

Since my previous updates I've come up with a near working system that
fetches data from different browsers via a control node and exit relays,
and analyzes the different results, and further renders and plots the data
into the localhost of the system.

Areas where work is pending:

+ The Captcha Monitor is working and producing data-points, provided
"captchamonitor-tor-container" works correctly. As of now I do have data
but not much. Can check here:[0].The fault in container is that it turns
unhealthy and therby the application doesn't work, as it depends upon the
"captchamonitor-tor-container". Tickets regarding this are: [1],[2]. So
this will be one of my tasks to complete as more the data, more will the
cases to look for and access the working.

+ Create more graphs which would provide more insights and data to the
users[3].

+ Reviews from the Community: For the dashboard [0], I'll add the search
bar which as of now is disabled. Further on clicking the individual Relay
it redirects to the detailed page based on relay. As of now there are a lot
of directions where it could be improved, one possible example could be the
UI of the website. This is a field I would require some help from the
community for ideas on improving it.

That being said, I'm maintaining more on to-dos and resources here: [4].
Again,feel free to add more resources and discussions here as to what you
feel could be added or removed and help a better working for the system.

Thanks,
Apratim

References:
[0]: http://20.85.221.64:5000/dashboard.html
[1]: https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/95
[2]: https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/99
[3]: https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/88
[4]: https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/96

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi,&lt;br&gt;&lt;br&gt;Since my previous updates I've come up with a near \
working system that fetches data from different browsers via a control node and exit \
relays, and analyzes the different results, and further renders and plots the data \
into the localhost of the system.&lt;br&gt;&lt;br&gt;Areas where work is pending:&lt;br&gt;&lt;br&gt;+ The \
Captcha Monitor is working and producing data-points, provided \
"captchamonitor-tor-container" works correctly. As of now I do have data \
but not much. Can check here:[0].The fault in container is that it turns unhealthy \
and therby the application doesn't work, as it depends upon the \
"captchamonitor-tor-container". Tickets regarding this are: [1],[2]. So \
this will be one of my tasks to complete as more the data, more will the cases to \
look for and access the working. &lt;br&gt;&lt;br&gt;+ Create more graphs which would provide \
more insights and data to the users[3].&lt;br&gt;&lt;br&gt;+ Reviews from the Community: For the \
dashboard [0], I'll add the search bar which as of now is disabled. Further on \
clicking the individual Relay it redirects to the detailed page based on relay. As of \
now there are a lot of directions where it could be improved, one possible example \
could be the UI of the website. This is a field I would require some help from the \
community for ideas on improving it.&lt;br&gt;&lt;br&gt;That being said, I'm maintaining more \
on to-dos and resources here: [4]. Again,feel free to add more resources and \
discussions here as to what you feel could be added or removed and help a better \
working for the system.&lt;br&gt;&lt;br&gt;Thanks,&lt;br&gt;Apratim&lt;br&gt;&lt;br&gt;References:&lt;br&gt;[0]: &lt;a \
href="http://20.85.221.64:5000/dashboard.html"&gt;http://20.85.221.64:5000/dashboard.html&lt;/a&gt;&lt;br&gt;[1]: \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/95"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/95&lt;/a&gt;&lt;br&gt;[2]: \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/99"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/99&lt;/a&gt;&lt;br&gt;[3]: \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/88"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/88&lt;/a&gt;&lt;br&gt;[4]: \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/96"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/issues/96&lt;/a&gt;&lt;/div&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210816192305</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-08-16 19:23:05-0400</timestampReceived><subject>[tor-dev] This week's arti meeting rescheduled: 18 August, 1600 UTC</subject><body>

Hi!

Because of a scheduling conflict, our biweekly Arti meeting is
rescheduled (for this Wednesday only).  The time this week will be at
18 August, 1600 UTC, at https://tor.meet.coop/gab-sis-ldw-xad .

This week we'll be brainstorming API ideas, use cases, and user
stories.  Don't worry if you can't make it: we record our meetings and
put them online on Tor's youtube channel.  (And this won't be your
last chance to influence the API; it's just an initial brainstorming
session.)

cheers,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210816212131</emailId><senderName>meejah</senderName><senderEmail>meejah@meejah.ca</senderEmail><timestampReceived>2021-08-16 21:21:31-0400</timestampReceived><subject>[tor-dev] txtorcon 21.1.0</subject><body>

[Attachment #2 (multipart/alternative)]


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

I'm pleased to announce txtorcon 21.1.0. This fixes some incorrectly-skipped tests in \
21.0.0

* Fix some incorrect unit-test skipping logic (thanks Jean-Paul Calderone)
   https://github.com/meejah/txtorcon/issues/354 and \
                https://github.com/meejah/txtorcon/issues/352
* Fix broken tests revealed by previous fixes (thanks Jean-Paul Calderone)
   https://github.com/meejah/txtorcon/issues/356

You can download the release from PyPI or GitHub (or of
course "pip install txtorcon"):

  https://pypi.python.org/pypi/txtorcon/21.1.0
  https://github.com/meejah/txtorcon/releases/tag/v21.1.0

Releases are also available from the hidden service:

  http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-21.1.0.tar.gz
  http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-21.1.0.tar.gz.asc


You can verify the sha256sum of both by running the following 4 lines
in a shell wherever you have the files downloaded:

cat &lt;&lt;EOF | sha256sum --check
aebf0b9ec6c69a029f6b61fd534e785692e28fdcd2fd003ce3cc132b9393b7d6  \
dist/txtorcon-21.1.0.tar.gz \
bcc54299e5119d6a9ace889bbefc1ff93108a204824b738e9c77bdb71f61661f  \
dist/txtorcon-21.1.0-py2.py3-none-any.whl EOF

thanks,
meejah
-----BEGIN PGP SIGNATURE-----

iQFFBAEBCgAvFiEEnVor1WiOy4id680/wmAoAxKAaacFAmEa1UoRHG1lZWphaEBt
ZWVqYWguY2EACgkQwmAoAxKAaad3/gf/S0mneFfvY0CdqR3DyIOgjX29lIotkDzf
1SeTnLdSU2SYXj89d8TnCUONkQiFZvruGcQufASA+mbIFKC+2KwZ7BVJLlYJ9MGu
Cyjt+1jr2xXGmAEVqLcDwCZM7v4BknD/W2jxZqLx3CjDuU3U1abjcJUBlt2Pq/uA
B5wWK6PAxIE1rksGtk+ftMf+jMIRwTb5hNj9HynDuGzW3MFbmanyQh2eBfQPlrve
1FqmQUEaOKMM6S34mvExRIjB5/q1SNs8+zX9oAR5wrLh3NVCsiVyXtVOvU949sLy
HKVm9nHzgemRrj/nsKetLahM5MYpRYFMhZVYTK+nyotK+I5tRfrXGQ==
=e+mc
-----END PGP SIGNATURE-----


[Attachment #5 (text/html)]

&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;style \
type="text/css"&gt;p.MsoNormal,p.MsoNoSpacing{margin:0}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;-----BEGIN \
PGP SIGNED MESSAGE-----&lt;br&gt;&lt;/div&gt;&lt;div&gt;Hash: SHA512&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'm \
pleased to announce txtorcon 21.1.0. This fixes some incorrectly-skipped tests in \
21.0.0&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;* Fix some incorrect unit-test skipping logic \
(thanks Jean-Paul Calderone)&lt;br&gt;&lt;/div&gt;&lt;div&gt;   &lt;a \
href="https://github.com/meejah/txtorcon/issues/354"&gt;https://github.com/meejah/txtorcon/issues/354&lt;/a&gt; \
and &lt;a href="https://github.com/meejah/txtorcon/issues/352"&gt;https://github.com/meejah/txtorcon/issues/352&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;* \
Fix broken tests revealed by previous fixes (thanks Jean-Paul \
Calderone)&lt;br&gt;&lt;/div&gt;&lt;div&gt;   &lt;a \
href="https://github.com/meejah/txtorcon/issues/356"&gt;https://github.com/meejah/txtorcon/issues/356&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You \
can download the release from PyPI or GitHub (or of&lt;br&gt;&lt;/div&gt;&lt;div&gt;course "pip install \
txtorcon"):&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  &lt;a \
href="https://pypi.python.org/pypi/txtorcon/21.1.0"&gt;https://pypi.python.org/pypi/txtorcon/21.1.0&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  \
&lt;a href="https://github.com/meejah/txtorcon/releases/tag/v21.1.0"&gt;https://github.com/meejah/txtorcon/releases/tag/v21.1.0&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Releases \
are also available from the hidden service:&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  &lt;a \
href="http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-2 \
1.1.0.tar.gz"&gt;http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-21.1.0.tar.gz&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;  \
&lt;a href="http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorco \
n-21.1.0.tar.gz.asc"&gt;http://fjblvrw2jrxnhtg67qpbzi45r7ofojaoo3orzykesly2j3c2m3htapid.onion/txtorcon-21.1.0.tar.gz.asc&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You \
can verify the sha256sum of both by running the following 4 lines&lt;br&gt;&lt;/div&gt;&lt;div&gt;in a \
shell wherever you have the files downloaded:&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;cat \
&lt;&lt;EOF | sha256sum \
--check&lt;br&gt;&lt;/div&gt;&lt;div&gt;aebf0b9ec6c69a029f6b61fd534e785692e28fdcd2fd003ce3cc132b9393b7d6  \
dist/txtorcon-21.1.0.tar.gz&lt;br&gt;&lt;/div&gt;&lt;div&gt;bcc54299e5119d6a9ace889bbefc1ff93108a204824b738e9c77bdb71f61661f  \
dist/txtorcon-21.1.0-py2.py3-none-any.whl&lt;br&gt;&lt;/div&gt;&lt;div&gt;EOF&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;thanks,&lt;br&gt;&lt;/div&gt;&lt;div&gt;meejah&lt;br&gt;&lt;/div&gt;&lt;div&gt;-----BEGIN \
PGP SIGNATURE-----&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;iQFFBAEBCgAvFiEEnVor1WiOy4id680/wmAoAx \
KAaacFAmEa1UoRHG1lZWphaEBt&lt;br&gt;&lt;/div&gt;&lt;div&gt;ZWVqYWguY2EACgkQwmAoAxKAaad3/gf/S0mneFfvY0Cdq \
R3DyIOgjX29lIotkDzf&lt;br&gt;&lt;/div&gt;&lt;div&gt;1SeTnLdSU2SYXj89d8TnCUONkQiFZvruGcQufASA+mbIFKC+2KwZ \
7BVJLlYJ9MGu&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cyjt+1jr2xXGmAEVqLcDwCZM7v4BknD/W2jxZqLx3CjDuU3U1abjcJUBlt2 \
Pq/uA&lt;br&gt;&lt;/div&gt;&lt;div&gt;B5wWK6PAxIE1rksGtk+ftMf+jMIRwTb5hNj9HynDuGzW3MFbmanyQh2eBfQPlrve&lt;b \
r&gt;&lt;/div&gt;&lt;div&gt;1FqmQUEaOKMM6S34mvExRIjB5/q1SNs8+zX9oAR5wrLh3NVCsiVyXtVOvU949sLy&lt;br&gt;&lt;/div \
&gt;&lt;div&gt;HKVm9nHzgemRrj/nsKetLahM5MYpRYFMhZVYTK+nyotK+I5tRfrXGQ==&lt;br&gt;&lt;/div&gt;&lt;div&gt;=e+mc&lt;br&gt;&lt;/div&gt;&lt;div&gt;-----END \
&gt; PGP SIGNATURE-----&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210818172238</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-08-18 17:22:38-0400</timestampReceived><subject>[tor-dev] Arti report 4: August 4 through August 18</subject><body>

# Arti Report 3: August 4 through August 18


At last we're done with circuit timeout inference!  See the last weeks
update for an overview of what this was, and why it was hard. As of last
Friday, we've finally got an Arti implementation that builds testing
circuits as appropriate, infers reasonable timeouts, and remembers those
timeouts across runs.

As a side-benefit to this work, we've found a number of points where we
need to clarify the Tor specification to be more precise about correct
behavior for a Tor client.  (For example, how to break ties when
deciding on the most populous histogram bins.) I'm taking some time to
circle back and fix those in the Tor specs.

Here is the first recorded persistent state from an Arti implementation,
lightly reformatted:

    version = 1
    histogram = [[415, 1], [495, 2], [515, 1], [535, 1], [545, 1],
        [555, 1], [625, 1], [655, 1], [665, 1], [785, 1], [835, 1],
        [865, 2], [885, 3], [955, 1], [965, 1], [975, 2], [985, 1],
        [1005, 2], [1025, 1], [1035, 2], [1055, 3], [1065, 1],
        [1075, 1], [1085, 2], [1095, 1], [1115, 2], [1135, 2],
        [1145, 2], [1175, 1], [1185, 1], [1195, 2], [1205, 3],
        [1215, 1], [1235, 2], [1245, 6], [1255, 1], [1265, 2],
        [1285, 2], [1295, 3], [1305, 1], [1315, 1], [1355, 2],
        [1375, 2], [1385, 2], [1405, 2], [1435, 1], [1455, 1],
        [1465, 1], [1495, 1], [1505, 1], [1525, 1], [1535, 1],
        [1555, 1], [1565, 1], [1605, 1], [1625, 1], [1665, 1],
        [1765, 1], [1785, 1], [1825, 1], [1965, 1], [2165, 1],
        [2495, 1], [3025, 1], [3855, 1], [4265, 1], [4795, 1],
        [4935, 1], [5435, 1], [6825, 1]]
    current_timeout = 1592
    abandoned_circs = 0
    successful_circs = 20

## Other work

We've continued to review and merge volunteer patches. Thanks,
everybody! In response to a patch documenting a number of possible
panics, I've taken a pass through the code to reduce the number of
functions that could panic.

I've also been spending some time improving test coverage: while doing
so, I found an incorrect behavior when checking whether two IPv6
addresses were on the same network.  (Tests are great and need to be
everywhere, apparently.)

## Coming up

Our current priorities are:

   * Starting API design work.  So far we've been feeling our way
     forward, and it's time to get more systematic.

   * Improving our APIs and internal functionality for stream isolation,
     to support a variety of usecases more like what can be done with
     current Tor.

   * Kicking off the work on a Guard implementation.  This is the last
     key feature we need for a basic level of privacy.

   * Lots more interviewing job candidates.

Let's see how far we get in the next two weeks!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210823205635</emailId><senderName></senderName><senderEmail>cho8jeiv4aus</senderEmail><timestampReceived>2021-08-23 20:56:35-0400</timestampReceived><subject>[tor-dev] Client identification for authenticated onions</subject><body>

Hi there. I had an idea recently for an onion service to improve the UX 
of sites that require a login. The site would have two onions: one for 
those who want to use onion auth and another for those who don't or are 
still setting it up. A user would first sign in with a username+password 
on the unauthenticated onion and click a button to generate a 
certificate associated with their account. Then they would add the 
public key to their browser and visit the authenticated onion. The 
application server would then match the pubkey used to authenticate with 
an account in the database, and log them in automatically.

I've looked in the mailing list archives and `man 1 tor` but didn't find 
anything that would facilitate this. The closest, it seems, is 
HiddenServiceExportCircuitID, but that is for *circuit* IDs, not 
*client* IDs. Is this possible to implement, either as an operator or as 
a Tor developer?

As an operator, an alternative would be to generate one (authenticated) 
onion service per user and route them all to the same place with 
different Host headers, but that seems rather inefficient, and I don't 
know how well the tor daemon scales up to hundreds of onion services anyway.

P.S. I didn't find an easy way to do full text search on the mailing 
list archives, so I wrote a little script to download them all. I've 
attached it in case it ends up useful. It requires python3.8+ and you'll 
need to `pip install aiohttp anyio BeautifulSoup4` first. After that you 
can run `./pipermail_fetch.py 
https://lists.torproject.org/pipermail/tor-dev/` and then something like 
`rg --context 3 --search-zip '^[^&gt;].*search term here'` will do the trick.


["pipermail_fetch.py" (text/x-python)]

#!/usr/bin/env python3
# SPDX-License-Identifier: BlueOak-1.0.0

import io
import sys
import anyio
import aiohttp
import platform
import contextlib
from yarl import URL
import importlib.util
from bs4 import BeautifulSoup
from dataclasses import dataclass
from typing import Iterable, Union

HAVE_LXML = bool(importlib.util.find_spec('lxml'))

USER_AGENT = '; '.join((
	sys.argv[0],
	'aiohttp/' + aiohttp.__version__,
	f'{platform.python_implementation()}/{platform.python_version()}',
))

@dataclass
class MailingList:
	"""usually the same as the local part of the list's email address"""
	name: str
	"""links to all the full text archives of the list"""
	text_urls: Iterable[Union[URL, str]]

async def amain():
	archive_page_url = sys.argv[1]
	async with \
		aiohttp.ClientSession(headers={'User-Agent': USER_AGENT}) as http, \
		anyio.create_task_group() as tg \
	:
		async with http.get(archive_page_url) as resp:
			soup = BeautifulSoup(await resp.text(), 'lxml' if HAVE_LXML else 'html.parser')

		list = parse_mailing_list(resp.url, soup)
		output_dir = anyio.Path(resp.url.host) / list.name
		await output_dir.mkdir(exist_ok=True)
		for url in list.text_urls:
			tg.start_soon(fetch, http, output_dir, url)

	print(file=sys.stderr)

def parse_mailing_list(url, soup):
	title = soup.find('title').text
	# format: The &lt;name&gt; Archives
	title = title.removeprefix('The ').removesuffix(' Archives')
	# use .join instead of / in case the href is absolute 🙄
	# weird that pathlib supports `absolute / absolute` but yarl doesn't
	return MailingList(title, text_urls=(url.join(URL(a.attrs['href'])) for a in \
soup.select('td:last-child a')))

async def fetch(http, output_dir, link):
	async with \
		await (out_path := output_dir / link.name).open('ab') as outf, \
		http.get(link) as resp \
	:
		with contextlib.suppress(KeyError):
			if int(resp.headers['Content-Length']) == (await out_path.stat()).st_size:
				# we already have the whole file
				return

		await outf.seek(0)
		await outf.truncate()  # download resumption is not supported yet
		await acopyfile(resp.content, outf)

	print('.', end='', file=sys.stderr, flush=True)

async def acopyfile(inf, outf, buf_size=io.DEFAULT_BUFFER_SIZE):
	while (chunk := await inf.read(buf_size)):
		await outf.write(chunk)

def main(): anyio.run(amain)

if __name__ == '__main__':
	main()



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210826150649</emailId><senderName>Gaba</senderName><senderEmail>gaba@torproject.org</senderEmail><timestampReceived>2021-08-26 15:06:49-0400</timestampReceived><subject>[tor-dev] Next public Arti meeting happening on September 8th at 1500 UTC</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hi!

We are canceling the meeting on September 1st. Our next meeting will be
on September 8th (and then every 2 weeks).

Meeting's room:  https://tor.meet.coop/gab-sis-ldw-xad
Meeting notes in:
http://kfahv6wfkbezjyg4r6mlhpmieydbebr5vkok5r34ya464gqz6c44bnyd.onion/p/arti-meeting-pad-keep
Recording of previous meetings:
https://www.youtube.com/playlist?list=PLwyU2dZ3LJErozq7cTtImuWkSn_34pEpq

Agenda

- status of Arti development and planning
- user stories for Arti API https://pad.riseup.net/p/MUjnic0eRT0WrDW7M-us

cheers
gaba

-- 
pronouns she/her/they
GPG Fingerprint EE3F DF5C AD91 643C 21BE  8370 180D B06C 59CA BD19

["OpenPGP_0x180DB06C59CABD19.asc" (application/pgp-keys)]
["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210708160827</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-07-08 16:08:27-0400</timestampReceived><subject>[tor-dev] Arti development report: 23 June through July 7</subject><body>

# Arti Report 1: 23 June through July 7

We started with a project kickoff meeting.  We're planning to continue
meeting every 2 weeks, making our meetings increasingly public, and
posting them on youtube.

We wrote up an announcement to explain what Arti is and why we're doing
it.  The [announcement](https://blog.torproject.org/announcing-arti)
goes live on July 8; it's a good place to start if you're not already
familiar with the project, or if you're looking for more helpful links.

To get ready for future development, and check the state of our packages
we put out an [0.0.0 release](https://crates.io/crates/arti) and
uploaded it to crates.io.  We found a couple of issues while doing so
([#129][ticket-129], [#130][ticket-130]).

We want to switch as much new-feature development to Arti as we can.
With that in mind, we're developing a set of guidelines for discouraging
features in C -- especially features with the potential to destabilize
our code. (See [#128][ticket-128].)  We're trying a bottom-up approach
here, starting by identifying what kinds of features we've done recently
that maybe we should skip in the future.

We had an excellent meeting with developers on various Zcash projects,
to gather requirements, set expectations, and open lines of
communication.  Based on their suggestions, we opened a set of new
tickets to work on.  ([#132][ticket-132] [#133][ticket-133]
[#134][ticket-134] [#135][ticket-135] [#136][ticket-136]
[#137][ticket-137] [#138][ticket-138] [#139][ticket-139]
[#140][ticket-140])

In terms of new code written, things have been a bit slow: we're still
ramping up, and a lot of folks take vacations in the summer.  We
[revised our asynchronous runtime backend][ticket-129] based on issues
we found while uploading our packages.  More recently, I've started
working on an [implementation][ticket-57] of Tor's
[circuit timeout inference][cti] code, which is necessary for good
performance and security.

## Next steps

In our next couple of weeks, I hope we get a first cut at our circuit
timeout code finished and working, and figure out a reasonable initial
solution for our [persistence needs][ticket-59].  We'll also be ramping
up on implementations for [guard nodes][ticket-58] and
[stream isolation][ticket-73], both of which are necessary for security.


[ticket-57]: https://gitlab.torproject.org/tpo/core/arti/-/issues/57
[ticket-58]: https://gitlab.torproject.org/tpo/core/arti/-/issues/58
[ticket-59]: https://gitlab.torproject.org/tpo/core/arti/-/issues/59
[ticket-73]: https://gitlab.torproject.org/tpo/core/arti/-/issues/73
[ticket-128]: https://gitlab.torproject.org/tpo/core/arti/-/issues/128
[ticket-129]: https://gitlab.torproject.org/tpo/core/arti/-/issues/129
[ticket-130]: https://gitlab.torproject.org/tpo/core/arti/-/issues/130
[ticket-132]: https://gitlab.torproject.org/tpo/core/arti/-/issues/132
[ticket-133]: https://gitlab.torproject.org/tpo/core/arti/-/issues/133
[ticket-134]: https://gitlab.torproject.org/tpo/core/arti/-/issues/134
[ticket-135]: https://gitlab.torproject.org/tpo/core/arti/-/issues/135
[ticket-136]: https://gitlab.torproject.org/tpo/core/arti/-/issues/136
[ticket-137]: https://gitlab.torproject.org/tpo/core/arti/-/issues/137
[ticket-138]: https://gitlab.torproject.org/tpo/core/arti/-/issues/138
[ticket-139]: https://gitlab.torproject.org/tpo/core/arti/-/issues/139
[ticket-140]: https://gitlab.torproject.org/tpo/core/arti/-/issues/140
[cti]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/path-spec.txt#L364
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210708183232</emailId><senderName>Tom Ritter</senderName><senderEmail>tom@ritter.vg</senderEmail><timestampReceived>2021-07-08 18:32:32-0400</timestampReceived><subject>Re: [tor-dev] Mostly Automatic Censorship Circumvention in Tor Browser</subject><body>

&gt; ## Circumvention Settings Map

Do we ever see FallbackDirs censored but relays not? Not sure if that's useful.

It seems like this entire data structure could be condensed into a
very small format (2 bytes per country; maybe even 1 byte if you
dropped a few things). 2 bytes per country-name; 4 countries and right
now it's 16 bytes. That's small enough to fit in a standard 256-bit
random nonce or counter, smuggled inside a cryptographic protocol like
TLS. Or put into a DNS TXT record.

&gt; #### Time Investment to Update Map

Updating such a file is the exact purpose of the Remote Settings
feature of Firefox:
https://firefox-source-docs.mozilla.org/services/settings/index.html

I'm sure Tor is loath to run additional infrastructure on top of the
update server but... this exists.  I think one Remote Settings bucket
is enabled by Tor Browser? Maybe OneCRL?  (Or maybe I'm thinking of
Addon-Blocklist which I don't think is Remote Settings....)

Mozilla might be able to host this _for_ Tor (and Tor devs have the
admin control on the bucket) but obviously that would allow some level
of control of Tor Browser by Mozilla.

&gt; #### Are Per-Country Entries Granular Enough?

It seems like today this problem is not worth trying to address. Seems
difficult, and has it ever actually been needed?

&gt; ## Determining User Location

Doesn't tor ship with a geoip database that can do this given the
user's internet-facing IP with some but not perfect accuracy?

-tom

On Thu, 8 Jul 2021 at 12:22, Richard Pospesel &lt;richard@torproject.org&gt; wrote:
&gt; 
&gt; Hi Everyone,
&gt; 
&gt; As part of our Sponsor 30 work, we are looking to improve the new
&gt; about:torconnect experience by adding automatic tor settings
&gt; configuration for censorship circumvention.
&gt; 
&gt; This document outlines and discusses the *technical* challenges
&gt; associated with this work, and does not go into any great detail on the
&gt; right UX would be (in terms of easy of use, user trust, etc).
&gt; 
&gt; Anyway, if you see any pitfalls or problems with anything here, do let
&gt; us know.
&gt; 
&gt; ------------------------------8&lt;--------------------------------------
&gt; 
&gt; # Mostly Automatic Bridge Configuration to Bypass Internet Censorship
&gt; 
&gt; Our goal for this work is to enable Tor Browser users to access tor
&gt; without having to navigate to about:preferences#tor to configure
&gt; bridges. Technically speaking, this is a trivial problem assuming you know:
&gt; 
&gt; - which bridge settings work at the user's location
&gt; - the location of the user
&gt; 
&gt; ## Circumvention Settings Map
&gt; 
&gt; For now, it seems sufficient to maintain a map of countries to some
&gt; data-structure containing information about which censorship
&gt; circumvention techniques work and which ones do not. A proposed example
&gt; format can be found here:
&gt; 
&gt; -
&gt; https://gitlab.torproject.org/tpo/anti-censorship/state-of-censorship/-/blob/main/state-of-censorship.json
&gt;  
&gt; This map would at be distributed and updated through tor-browser releases.
&gt; 
&gt; ### Problems
&gt; 
&gt; #### Censorship Changes Invalidate the Map
&gt; 
&gt; The obvious problem with distributing the censorship-circumvention
&gt; settings map with Tor Browser is that if the techniques used in a
&gt; location change such that old settings no longer work, you will be left
&gt; with a non-functional Tor Browser with no way to update it apart from
&gt; acquiring a fresh install with the updated settings or by manually
&gt; configuring Tor Browser's bridge settings (so what users have to do now)
&gt; 
&gt; A fix for this would be to provide a rules update mechanism whereby
&gt; updated rules could be fetched outside of tor (via the clearnet, or over
&gt; moat). Special care would need to be taken to ensure the rule updates
&gt; from this automatic mechanism actually came from the Tor Project (via
&gt; some sort of signature verification scheme, for example).
&gt; 
&gt; Another wrinkle here is that rules would also need to be distributed
&gt; somewhere that is difficult to censor. It seems likely that we may need
&gt; different locations and mechanisms for acquiring the rule-set based on
&gt; the user's location.
&gt; 
&gt; Whatever the mechanism, updates should happen at least before the user
&gt; attempts to auto-configure. Otherwise, perhaps we should periodically
&gt; auto-update the the settings at a reasonable cadence.
&gt; 
&gt; #### Time Investment to Update Map
&gt; 
&gt; Another problem with solely distributing the rules through Tor Browser,
&gt; is that censorship events would now require a Tor Browser release just
&gt; to push new rules out to people. Publishing new Tor Browser releases is
&gt; not a simple task, and enabling adversaries to force Tor Browser
&gt; releases by tweaking their censorship systems seems like a cute way to
&gt; DDOS the Applications team.
&gt; 
&gt; An alternate update channel is definitely necessary outside of periodic
&gt; Tor Browser releases.
&gt; 
&gt; #### Are Per-Country Entries Granular Enough?
&gt; 
&gt; One could imagine highly localized censorship events occurring which
&gt; require special settings that are not needed in the rest of the country.
&gt; For instance, if there is a clearnet blackout in Minneapolis, would we
&gt; want to pipe *all* of our US users through the same bridges? Seems like
&gt; a potential scalability problem for countries with large populations.
&gt; 
&gt; ## Determining User Location
&gt; 
&gt; A user's location can be determined by accessing location services
&gt; through the clearnet. Mozilla offers a such a service (
&gt; https://location.services.mozilla.com/ ) with a very simple HTTP
&gt; interface. Prior to bootstrapping, Tor Browser can access the location
&gt; service by temporarily enabling network DNS:
&gt; 
&gt; - network.dns.disabled=false
&gt; 
&gt; and making an exception for the location service URL to bypass the proxy by:
&gt; 
&gt; - network.proxy.no_proxies_on="location.services.mozilla.com"
&gt; 
&gt; The location service would send back a country code in a JSON object
&gt; which we can use to look up appropriate bridge settings in our map
&gt; described above.
&gt; 
&gt; ### Problems
&gt; 
&gt; So the functionality of this approach is pretty easy to implement: tweak
&gt; some prefs, make an XMLHttpRequest, change the prefs back.
&gt; 
&gt; One possible problem we may face is if censors start blocking Mozilla's
&gt; location services. Maybe we should have a pool of location service
&gt; providers to make this more difficult (though we would need to do the
&gt; research and figure out how feasible this is from a cost perspective).
&gt; 
&gt; It is also possible to add location service functionality to moat,
&gt; though this would also be a bit of an engineering endeavor.
&gt; 
&gt; If we move forward with Mozilla's location services, we will need to
&gt; acquire an API key, but I would not expect this to be an issue. We will
&gt; also need to make arrangements with them to surpass the current limit of
&gt; 100,000 daily API requests ( see:
&gt; https://location.services.mozilla.com/terms )
&gt; 
&gt; The big challenge here is engineering the right UX which maintains our
&gt; users trust. I think we need to be very explicit with this convenience
&gt; feature, and definitely not just have it silently happen in the
&gt; background. Users should also be able to opt-out, and manually select
&gt; their country for the purposes of getting the right settings out of the
&gt; above mentioned map.
&gt; 
&gt; It should be very difficult to accidentally enable this automatic
&gt; lookup. This will likely require a fair bit of iteration on the
&gt; about:torconnect page design and flow.
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210716193426</emailId><senderName>Trevor Perrin</senderName><senderEmail>trevp@trevp.net</senderEmail><timestampReceived>2021-07-16 19:34:26-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Fri, Jul 16, 2021 at 5:31 AM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt;
&gt; On Tue, Jul 13, 2021 at 11:34:47AM -0700, Trevor Perrin wrote:
&gt; &gt; You also wanted to add an (optional) pre-shared key, which Noise supports:
&gt; &gt;
&gt; &gt; NKpsk0:
&gt; &gt;   &lt;- s
&gt; &gt;   ...
&gt; &gt;   -&gt; psk, e, es
&gt; &gt;   &lt;- e, ee
&gt;
&gt; Out of curiosity, Trevor, what properties does this Noise protocol
&gt; provide for low-entropy psk?

The Noise PSK is intended for 256-bit secrets, however:

 * A low-entropy (even malicious) PSK can't reduce the security of the
rest of the handshake.  I.e. NKpsk0 with a bad PSK has all the
security properties of NK.

 * The handshake will only complete successfully if both parties use
the same PSK.

This is *NOT* a PAKE: the legitimate recipient of the first NKpsk0
handshake message will be able to try offline guesses for the PSK.

Noise doesn't have a PAKE feature.  You could generically combine a
Noise handshake with an Oblivious PRF to produce a PAKE (like Hugo's
OPAQUE).  Integrating a "balanced" PAKE, like in OTR, would be more
complicated.


&gt; If you want the protocol to work with Walking Onions, it needs to be
&gt; *post-specified peer*.  That is, contrary to:
&gt;
&gt; &gt; The client knows:
&gt; &gt;   * B: a public "onion key" for S
&gt;
&gt; The client will in fact _not_ know B in advance in a Walking Onions
&gt; setting, but rather will learn it at the end of the handshake.

I don't know the requirements here, but fwiw here's what pre-specified
peer (NK or NK1) vs post-specified peer (NX) looks like for a Noise
handshake:

NK:
  &lt;- s
  ...
  -&gt; e, es
  &lt;- e, ee

NX:
  -&gt; e
  &lt;- e, ee, s, es

Trevor
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210720161150</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2021-07-20 16:11:50-0400</timestampReceived><subject>Re: [tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring #Update</subject><body>

On Mon, Jul 12, 2021 at 05:01:35PM +0530, Apratim Ranjan Chakrabarty wrote:
&gt; ** Looking forward for suggestions and comments as to how to improve on it.
&gt; Also materials like research paper in this domain would be helpful **

Section IV-C of the ICLab paper has discussion of block page detection.
The first pass is regex for known block pages, but there is also
clustering by similar HTML structure and text.
https://censorbib.nymity.ch/#Niaki2020a
https://github.com/net4people/bbs/issues/52

The 2016 "Do You See What I See?" study seems to be in line with your
project. "The second-class treatment of anonymous users ranges from
outright rejection to ... imposing hurdles such as CAPTCHA-solving....
Our study draws upon ... scans of the home pages of top-1,000 Alexa
websites through every Tor exit..." Section V-A has to do with scans of
top-ranked sites.
https://www.ndss-symposium.org/wp-content/uploads/2017/09/do-you-see-what-i-see-differential-treatment-anonymous-users.pdf
 https://archive.org/details/ndss16doyousee
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210720191620</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-07-20 19:16:20-0400</timestampReceived><subject>Re: [tor-dev] Weaving a Faster Tor: paper/video of possible interest</subject><body>

[Attachment #2 (multipart/signed)]


On 20 Jul (01:29:54), Steven Engler wrote:
&gt; On 2021-07-19 3:24 p.m., David Goulet wrote:
&gt; &gt; On 06 Jul (13:52:50), Ian Goldberg wrote:
&gt; &gt; &gt; Hello tor-dev,
&gt; &gt; &gt; 
&gt; &gt; &gt; Steve Engler (currently part of the Shadow team) and I have a paper of
&gt; &gt; &gt; possible interest to appear at ARES 2021 next month.
&gt; &gt; &gt; 
&gt; &gt; &gt; It's a design of a multi-threaded relay architecture, of possible
&gt; &gt; &gt; particular interest when considering relay support in arti, for example
&gt; &gt; &gt; (though the proof-of-concept implementation is based on the usual C
&gt; &gt; &gt; codebase).
&gt; &gt; &gt; 
&gt; &gt; &gt; If you're interested, here are previews of:
&gt; &gt; &gt; 
&gt; &gt; &gt; Paper: https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf
&gt; &gt; &gt; Video: https://www.youtube.com/watch?v=41a6nLUJye8
&gt; &gt; &gt; Code: https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn
&gt; &gt; &gt;        https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing
&gt; &gt; 
&gt; &gt; Interesting!!!
&gt; &gt; 
&gt; &gt; One part caught my eye in section 4.3:
&gt; &gt; 
&gt; &gt;    "The large amount of locking would harm the relay's performance, and mes-
&gt; &gt;    sage passing would break some of the assumptions of Tor's primary scheduler,
&gt; &gt;    the KIST scheduler. Rather than using a global scheduler, each local
&gt; &gt;    connection manager uses its own local scheduler which processes only the
&gt; &gt;    connections it owns."
&gt; &gt; 
&gt; &gt; So KIST was also put in place in order to be able to consider _all_ channels
&gt; &gt; within one scheduling loop so to properly applied EWMA scheduling that is
&gt; &gt; basically loud circuits (lots of traffic) are less prioritize from quiet ones.
&gt; &gt; 
&gt; &gt; Moving to a scheduler per thread (as in only handling its set of connections),
&gt; &gt; we loose that property no? And so loud circuits end up crushing quiet
&gt; &gt; circuits on the physical link?
&gt; 
&gt; (Sending this from an address that is a tor-dev list member.)
&gt; 
&gt; If the scheduler's prioritization needs to be exact across all circuits in
&gt; the relay, then yes that isn't possible with a scheduler per thread.
&gt; 
&gt; Our argument is that we don't believe the relay needs prioritization to be
&gt; perfect across all circuits in the relay. For relays that currently aren't
&gt; able to saturate their physical link due to CPU performance limitations, the
&gt; greater total throughput from multi-threading might be worth partially
&gt; relaxing the scheduling prioritization. Performing per-thread circuit EWMA
&gt; scheduling should still be enough to prevent loud circuits from crushing
&gt; quiet circuits, as long as connections are load-balanced across threads in a
&gt; way that each thread has a mix of loud and quiet circuits.

Interesting.

We would need the load balancing to be very active then, and rebalancing
connections across the thread pool basically. But, yeah, I think I can see
that the current property of needing to look at all connections for
prioritization could be relaxed if we pull off proper load-balancing between
threads but again, my guts tells me it would need to be active rebalancing.

In my experience, active rebalancing like that can be a complex beast both in
terms of concurrency but not impossible. Likely easier in more modern language
also :P.

&gt; 
&gt; &gt; Another thing. Looking at figure (c), it appears only "relay/edge connections"
&gt; &gt; can queue cells on a circuit half *directly* that is not using a channel. I
&gt; &gt; assume that concurrency there between a relay connection writing a cell on a
&gt; &gt; circuit half and a cell received through a channel (from another circuit half)
&gt; &gt; has been thought of? :)
&gt; 
&gt; Since the connection object holds the only reference to the circuit half, it
&gt; can access the circuit half directly without locking or message passing.
&gt; This is good for performance and for limiting buffer bloat. Cells arriving
&gt; at a circuit half on a channel should be queued in that channel and
&gt; shouldn't directly trigger any access on the circuit half (the channel
&gt; shouldn't hold a reference to that circuit half). Since the connection
&gt; object is in charge of both writing a cell on a circuit half and having that
&gt; circuit half process cells that are queued on its channel, there shouldn't
&gt; be any concurrency issues here.

Ok. Let me try to summarize: A connection reads its inbound cells, queue them
onto the correct circuit half (which I assume sticks to that connection and
thus no concurrent access) which then process them and sends them on its
channel (where a channel is always 1:1 circuit half relationship) and that
receiving circuit half (at that point on another thread) then enqueue them in
the scheduler list (if need be) so it can end up sending them on the right
connection.

&gt; 
&gt; &gt; I'm asking also because within Tor, there are numerous places where a cell is
&gt; &gt; enqueued on a circuit (even an OR circuit like TRUNCATE for instance) and so
&gt; &gt; those place would need to use a channel or use the way relay connections write
&gt; &gt; them (which appears to be without a channel)?
&gt; 
&gt; We were only able to discuss this briefly in the paper, but there's a bit
&gt; more about that in section 5.3.4 here:
&gt; https://uwspace.uwaterloo.ca/bitstream/handle/10012/16108/Engler_Steven.pdf
&gt; 
&gt; Generally, we want cells to only be enqueued by the circuit half's
&gt; connection object rather than having many places in tor try to communicate
&gt; directly with circuit objects. When other parts of tor want to enqueue a
&gt; cell on a circuit half, they should use the relay controller to send a
&gt; message to the other thread's connection manager along one of the async
&gt; channels shown in figure 4.a. The connection manager can then have the
&gt; corresponding relay connection enqueue a cell directly on the circuit half.

Ok!

Thanks for the answers!
David

-- 
ZpHhHUq0V09YaQpr2fmlzErQIDjsDcy67bcQlORvsSw=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210721195637</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-07-21 19:56:37-0400</timestampReceived><subject>[tor-dev] Arti development report: July 7 through July 21</subject><body>

# Arti Report 2: July 7 through July 21

It's been a quiet couple of weeks.  Most of the team has been on
vacation or leave for the last two weeks, so the Arti hacking has
been down to me (nick) for this period.

Our last report went out on the same day that our [announcement]
went public, and since then we've had an influx of attention and
volunteers interest.  Thanks to everybody who's been trying out the
code!  Special thanks to `trinity-1686a` for a
[stream-isolation] implementation, `lyuyuan` for
work on [RESOLVE and RESOLVE_PTR][resolve], and everybody else who's
been submitting patches!

## Circuit timeout inference

My own work for this period has focused on [circuit timeout
inference][cti].  (I decided to start with this because it's part of the
Tor protocol that I've worked with the least in the past.)

The approach is kind of complicated: in order to adjust our timeout, we
need to observe how long circuits actually take to
complete... including the circuits that we don't use because they
take longer than our current timeout timeout. So we have to keep
building circuits for a while even after they time out, so that we
can observe how long it takes them to finish.  Then we use an
estimator based on a Pareto distribution, and use that to determine
our actual cutoffs.

The core logic is now [implemented in Arti][pareto-code], and we
just have a few more pieces ([persistence][ticket-143],
[directory notification][ticket-144], and
[testing circuits][ticket-145]) to cover before we can call it done.

## Open problems

Our timeout tests rely on using a simulated view of time.  (Nobody
wants to wait 10 seconds for a simulated 10-second timeout!)  For
that, we have [testing code][rt-mock-time] to override the
asynchronous runtime's view of the passage of time.

But we have a bug somewhere that makes these tests unreliable.  The
[WaitFor] future, which is supposed to run a another future to
completion while advancing the current (simulated) time, doesn't
seem to be reliable.  As implemented, it advances the current time
even when the future it's testing _isn't_ blocked on time, and
sometimes advances time much too far while the tested future makes
no progress.  I've kludged it up by making it yield a lot and
advance time in tiny increments, but that's just a workaround.

Does anybody like [debugging Futures code][ticket-149]?

## Next steps

In the next two weeks I hope we can wrap up the outstanding issues above
in circuit timeouts, including the ones that require some
architectural decisions.

I'm also hoping that we can make progress on [guards]: that's the
last remaining really big security feature we have to do for
our 0.0.1 milestone.  Once that's done, we can move on to polishing
and infrastructure issues for the rest of the time we have for this
milestone.

Finally, we're going to be expanding our team!  Please have a look
at our [job-opening], and share it with anybody you know who is
interested in Rust and Tor, and who might be interested in a job.

Next update in two weeks!

[announcement]: https://blog.torproject.org/announcing-arti
[cti]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/path-spec.txt#L364
[cti]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/guard-spec.txt
[job-opening]: https://www.torproject.org/about/jobs/rust-dev/
[pareto-code]: https://gitlab.torproject.org/tpo/core/arti/-/blob/main/tor-circmgr/src/timeouts/pareto.rs
[resolve]: https://gitlab.torproject.org/tpo/core/arti/-/merge_requests/39
[rt-mock-time]:
https://gitlab.torproject.org/tpo/core/arti/-/blob/main/tor-rtmock/src/time.rs
[stream-isolation]:
https://gitlab.torproject.org/tpo/core/arti/-/merge_requests/38
[ticket-143]: https://gitlab.torproject.org/tpo/core/arti/-/issues/143
[ticket-144]: https://gitlab.torproject.org/tpo/core/arti/-/issues/144
[ticket-145]: https://gitlab.torproject.org/tpo/core/arti/-/issues/145
[ticket-149]: https://gitlab.torproject.org/tpo/core/arti/-/issues/149
[WaitFor]: https://gitlab.torproject.org/tpo/core/arti/-/blob/main/tor-rtmock/src/sleep_runtime.rs#L123
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210722161216</emailId><senderName>Gaba</senderName><senderEmail>gaba@torproject.org</senderEmail><timestampReceived>2021-07-22 16:12:16-0400</timestampReceived><subject>[tor-dev] The Tor Project hiring software engineers</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hi!


We have a few positions open right now. Please apply or share it in your
networks!


Rust developers for the network team (to work on Arti):

http://torproject.org/about/jobs/rust-dev/index.html

Anti-censorship engineer to work mostly in Go and with focus on China:

http://torproject.org/about/jobs/software-developer-anticensorship-2/index.html


C++ and Javascript developer to work with our applications team (the one
maintaining Tor Browser):

http://torproject.org/about/jobs/software-engineer-applications-team/



Thanks!

-- 
pronouns she/her/they
GPG Fingerprint EE3F DF5C AD91 643C 21BE  8370 180D B06C 59CA BD19

["OpenPGP_0x180DB06C59CABD19.asc" (application/pgp-keys)]
["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210726101107</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-07-26 10:11:07-0400</timestampReceived><subject>Re: [tor-dev] A series of questions about Tor (m1 support, forward secrecy, v3 auth)</subject><body>

Holmes Wilson &lt;h@zbay.llc&gt; writes:

&gt; Hi everyone,
&gt; 

Hello Holmes,

here are some attempts to answer your questions.

&gt; 2. FORWARD SECRECY
&gt; 
&gt; Is there a good source for documentation on how forward secrecy works in Tor, and \
&gt; on what security guarantees it provides? Googling finds things like this reddit \
&gt; post (https://www.reddit.com/r/TOR/comments/cryrjx/does_tor_use_pfs/) but I can't \
&gt; find any detailed information about it, what threat models it fits, etc.  
&gt; One specific question is, if two users are communicating by sending messages over a \
&gt; connection to an onion service (like ricochet) and an attacker surveils their \
&gt; internet traffic and compromises their devices at a later date, will the attacker \
&gt; be able to recover the clear text of their conversation? When are keys for a given \
&gt; connection destroyed? Does it happen continuously throughout the course of a Tor \
&gt; connection? Or on the creation of a new circuit? Or what? 

tl;dr Onion service sessions are protected with forward secrecy.

In particular, v3 onion services use a variant of the ntor key exchange
(see [NTOR-WITH-EXTRA-DATA] in rend-spec-v3.txt) when doing their
rendezvous. The ntor key exchange provides forward secrecy which means
that if the long-term public key is compromised (e.g. by pwning their
device), the session remains secure as long as the short-term ephemeral
session secrets don't get compromised.

The forward secrecy "happens" at the creation of the rendezvous circuit
and not continuously through the course of a Tor connection (i.e. no
ratcheting happens). This means that if an attacker has the transcript
of the entire circuit, and manages to compromise the session in its
midpoint, it should be possible for her to decrypt back to the start of
the session.

Here is the original ntor paper:  http://www.cypherpunks.ca/~iang/pubs/ntor.pdf

&gt; 3. V3 AUTH AND DOS ATTACKS
&gt; 
&gt; Does v3 onion authentication protect against DOS attacks? That is, can someone who \
&gt; is not authorized to connect to an onion address with authentication enabled still \
&gt; cause problems for that onion address? Can they connect to it at all, in the sense \
&gt; of being able to send data to the tor client at that onion address? Or does the Tor \
&gt; network itself prevent this connection from even happening?  
&gt; A related question is, if we're looking to deny connections to an onion address to \
&gt; any unauthorized users, and we're considering turning off onion authentication and \
&gt; implementing some standard authentication scheme that seems fairly well-supported \
&gt; at the web server layer, is there any security-related reason why we would be \
&gt; better off using Tor's own authentication instead? Using our own authentication \
&gt; scheme will be a bit easier to control, rather than having to send commands to Tor \
&gt; (and possibly restart it for removing users?) but I'm wondering if there are \
&gt; security properties we lose by doing that.  

Like hackerncoder said, v3 onion authentication protects against DoS
attacks because the access control happens very early in the connection
process.

An attacker with no access to the auth keys cannot decrypt the onion
descriptor, which means that they cannot do introduction or rendezvous
with the onion service. It so happens that all onion DoS attack vectors
are during intro or rendezvous, and hence v3 onion auth protects against
them.

WRT your second question, if you swap the client authentication with
your own application-layer authentication scheme, you are losing the
above properties, since it means that an attacker will be able to reach
the web server before they get denied access. This means that the
attacker will be able to abuse DoS vectors during the intro and
rendezvous steps of the connection.

There is something to be said about the UX issues of having this custom
authentication mechanism and it not being in the application-layer, and
this is something we should be improving in the future.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210726102035</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-07-26 10:20:35-0400</timestampReceived><subject>Re: [tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

Holmes Wilson &lt;h@zbay.llc&gt; writes:

&gt; Hi George,
&gt; 
&gt; Sorry for the slow reply here! Just getting back to this. 
&gt; 
&gt; &gt; &gt; For our application (a messaging app) it would be super useful to get the
&gt; &gt; &gt; full list of known online (or recently seen online) onion addresses in
&gt; &gt; &gt; possession of some frontend key. This would let us use onionbalance for
&gt; &gt; &gt; peer discovery instead of blindly trying the set of all known peers, which
&gt; &gt; &gt; won't work well for large groups / large numbers of peers.
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; Hmm, can you please give us some more details on what you are looking
&gt; &gt; for? What is peer discovery in the above context, and what do you mean
&gt; &gt; with "full list of ... onion addresses in possession of some frontend
&gt; &gt; key"? I'm asking because the frontend key of onionbalance is also the
&gt; &gt; onion address that users should access.
&gt; 
&gt; Our context is we are building a Discord-like team messaging app where peers are \
&gt; connected to each other over Tor, via onion addresses, rather than to a central \
&gt; server. So each user connects to a few peers, and messages travel across peers on a \
&gt; gossip network, and there's a mechanism for syncing messages you missed, say, if \
&gt; you went offline for a bit.  
&gt; One problem we have is, when a new peer comes online, how do they know which other \
&gt; peers are online? Right now, they can try all of the peers they know about, or \
&gt; perhaps try recently-seen peers. But if there are hundreds of peers and only a few \
&gt; are currently online, it will be necessary to try many unreachable peers before \
&gt; finding one who's online. So that's not ideal. 
&gt; One solution to this would be for each online peer to host the same onion service, \
&gt; using a shared key, in addition to their normal peer onion address. And at this \
&gt; address they could return a list of peers they knew were online. So a user would \
&gt; just have to connect to one address, at which point the Tor network would connect \
&gt; them to some online peer, and then that peer could tell them about other online \
&gt; peers. The problem with this approach, as pointed out by folks on this list, was \
&gt; that all those peers would have to really trust each other, since any one of them \
&gt; could go rogue and host malicious information instead of the peer list, gumming up \
&gt; the works. I'm not sure this is a fatal problem, since it would still *help* in \
&gt; cases where there wasn't a malicious peer, and users could still fall back to the \
&gt; slower method of trying every peer.  
&gt; But what I'm wondering is whether there is any mechanism for a bunch of onion \
&gt; addresses that *don't* completely trust each other to share a "meta" onion address \
&gt; on the Tor network, such that when the user looks up that identifier instead of \
&gt; getting connected directly to whatever content one of those onion addresses is \
&gt; serving, they get a list of all onion addresses that hold the keys to the "meta" \
&gt; address.  
&gt; It'd be like asking Tor, "show me a list of all onion addresses that have \
&gt; registered this meta address." Sort of like asking, "show me a list of mirrors for \
&gt; this address…" at which point the user could try connecting to one or more of \
&gt; them, but would not have as serious problem if one of the sites went rogue and \
&gt; started serving useless content. 
&gt; This is a bit of a long explanation, and my guess is that there isn't anything like \
&gt; this and that the above scenario isn't common enough to be worth targeting, but I \
&gt; was curious if anything like this had ever been discussed. 

Hello Holmes,

I don't know much about these kind of P2P protocols, but my intuition is
that this "get list of online peers" should be handled on the gossip
protocol layer, and not on the Tor layer. As a naive strawman example,
each peer can keep its own list of online peers and return it when asked.

I feel like the idea of "connect to meta address to get list of online
peers" is kinda the same as "ask any peer you can find for the list of
online peers". That's because with the meta address idea you don't have
a way to know whether the meta address result is a trusted peer; in the
same way that you don't know whether the peers you get through gossip
are trusted peers. This means that in either case you will have to
handle malicious nodes somehow.

In any case, the "meta" address idea is not handled natively by Tor
right now. You could in theory do it by having multiple peers share the
same private key, but I don't know if the results would be ideal. For
example, a single such peer can DoS the system by continously sending a
corrupt onion descriptor for the meta address.

Good luck with designing your P2P protocol!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210730164603</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2021-07-30 16:46:03-0400</timestampReceived><subject>Re: [tor-dev] A proposal to phase out CAPTCHAs for BridgeDB</subject><body>

On Thu, Jul 29, 2021 at 04:46:37PM -0400, Cecylia Bocovich wrote:
&gt; Hi everyone,
&gt; 
&gt; We've been working on improving the usability of BridgeDB lately, and
&gt; our CAPTCHAs have been a constant thorny problem. They are not
&gt; accessible for blind users [0]. We've gotten many complaints over the
&gt; years that they are hard to use [1], I'm sure Gus and the community team
&gt; members can vent about the impact they've had on users.

Yeah :/

&gt; 
&gt; We even have some evidence that bots have been able to enumerate our
&gt; CAPTCHAs just fine [2].

Many moons ago, BridgeDB proxied CAPTCHA challenges from ReCAPTCHA [7],
instead of creating and serving its own. Eventually, Isis implemented
the current custom (GIMP) CAPTCHA system themselves because ReCAPTCHA
served impossible challenges [8].

&gt; There are other anti-enumeration defences on
&gt; BridgeDB that are perhaps more useful including:

[snip]

&gt; I would like to propose that we remove the CAPTCHAs from BridgeDB
&gt; entirely, but I'd like to know whether there is research out there
&gt; *specifically that fits with the anti-censorship context* showing that
&gt; these CAPTCHAs are actually doing useful work to prevent Bridge
&gt; enumeration. But, even if the CAPTCHAs are preventing a small number of
&gt; censors from enumerating more bridges, is the usability impact worth
&gt; what marginal benefit we get from it?
&gt; 
&gt; Options for how to move forward:
&gt; 
&gt; Option 1: Just remove the CAPTCHAs already!
&gt; 
&gt; We're tired of waiting and just want our bridges.

For mostly obvious reasons, this option worries me.

&gt; 
&gt; Option 2: Do some science?
&gt; 
&gt; We could make a new distribution bucket in BridgeDB that distributes
&gt; bridges through Moat without a CAPTCHA and have new versions of Tor
&gt; Browser pull from this bucket. We can watch and perform measurements in
&gt; places we know enumeration attempts have occurred in the past and see
&gt; whether these bridges are enumerated more quickly and more completely
&gt; than the old-school Moat bucket.

I like this idea.

&gt; 
&gt; Option 3: Keep doing what we're doing but try to make the CAPTCHAs more
&gt; usable.
&gt; 
&gt; This is the work we've had planned, but will only get us so far.
&gt; 

I'd be interested in this one, too, with a bit of (2) and some science.
We could conduct an(other) experiment where the current CAPTCHA system
is the control, and BridgeDB serves challenges from e.g., hCAPTCHA, 50%
of the time, and that new experimental CAPTCHA system protects a new,
independent, bridge bucket (like in 2).

There could be three outcomes:

  1. Success/Failure rates of challenges per connection (summarized by
     quartiles?)
  2. How many new bridges are blocked from within the countries
     identified in (2) after some time period?
  3. How quickly new bridges are blocked from within the countries
     identified in (2)?

At the end of the day, my primary concern is whether *people* have
access to the resources they need. I appreciate the the difficulty of
this situation and running a service like this (and I don't envy you :)).

&gt; 
&gt; Endpoint enumeration is a tricky topic and we do have some other
&gt; alternatives in the pipeline. Conjure is more of a "blocking resistance
&gt; through collateral damage" approach that's somewhat similar to domain
&gt; fronting [5]. We've been looking at and hope to do more work in the
&gt; future on reputation-based bridge distribution [6]. I see these as more
&gt; promising than CAPTCHAs in the long run, and CAPTCHA-less BridgeDB
&gt; bridges seem to still fill a need that built-in bridges and private
&gt; bridges don't fill.

I agree, and this sounds good to me.

Thanks!

&gt; 
&gt; I'd appreciate any thoughts, comments, or experiences others have!
&gt; 
&gt; Cecylia
&gt; 
&gt; [0]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/10831
&gt; [1]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/24607
&gt; [2]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/32117
&gt; [3]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/pluggable-transports/obfs4/-/issues/31701
&gt;  [4]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/censorship-analysis/-/blob/main/reports/2020/belarus/2020-belarus-report.md
&gt;  [5] https://gitlab.torproject.org/tpo/anti-censorship/team/-/issues/9
&gt; [6]
&gt; https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/31873

[7]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/5481
[9]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/10809

&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210730182234</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-07-30 18:22:34-0400</timestampReceived><subject>[tor-dev] Updated Proposal 324: RTT-based Congestion Control for Tor</subject><body>

As a heads up, I have updated Proposal 324: RTT-based Congestion Control
for Tor -
https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/324-rtt-congestion-control.txt

The updated version has a new congestion control algorithm, detailed
specifics on how to accurately measure RTT and BDP, and descriptions of
algorithm parameter values and tuning experiments, among other improvements.

A C implementation of these algorithms has been merged to tor.git
orgin/main. They live in src/core/or/congestion_control_*.[ch]. These
algorithms are not enabled yet; we still need to implement flow control
and negotiation, as well as do shadow experimentation to determine good
candidate parameter values to further tune on live.

Here is a full changelog since the proposal was last published to tor-dev:
 - Correct algorithms to update once per congestion window
 - Add orconn blocking and edge connection checks as signals
 - Specify BDP estimators based on onion service testing and eval.
 - Specify a pure BDP tracking congestion control algorithm (TOR_NOLA)
 - Update consensus parameters with tuning notes
 - Document what we learned so far in live onion service experimentation
 - Mention that we need to test intermittent downloads in Shadow/live
 - Describe clock jump and stall detection during RTT measurement
 - Mention if we calculate package window, it can become negative
 - Break off the backwards ECN idea into a future idea draft:

https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/ideas/xxx-backward-ecn.txt
 - Update old trac URLs
 - Add Acknowledgements

Review and comments are welcome!

-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210601101133</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-06-01 10:11:33-0400</timestampReceived><subject>[tor-dev] [RFC] Proposal 332: Vanguards lite</subject><body>

Hello list,

I present you with a simplified version of prop292 which protects
against guard discovery attacks.

The proposal can also be found in:
   https://gitlab.torproject.org/asn/torspec/-/commits/vg-lite

---

```
Filename: 332-vanguards-lite.md
Title: Vanguards lite
Author: George Kadianakis, Mike Perry
Created: 2021-05-20
Status: Draft
```

# 0. Introduction &amp; Motivation

  This proposal specifies a simplified version of Proposal 292 "Mesh-based
  vanguards" for the purposes of implementing it directly into the C Tor
  codebase.

  For more details on guard discovery attacks and how vanguards defend against
  it, we refer to Proposal 292 [PROP292_REF].

# 1. Overview

  We propose an identical system to the Mesh-based Vanguards from proposal 292,
  but with the following differences:

  - No third layer of guards is used.
  - The Layer2 lifetime uses the max(x,x) distribution with a minimum of one
    day and maximum of 12 days. This makes the average lifetime approximately a
    week. We let NUM_LAYER2_GUARDS=4.
  - We don't write guards on disk. This means that the guard topology resets
    when tor restarts.

  By avoiding a third-layer of guards we reduce the linkability issues
  of Proposal 292, which means that we don't have to add an extra hop on top of
  our paths. This simplifies engineering.

# 2. Rotation Period Analysis

  From the table in Section 3.1 of Proposal 292, with NUM_LAYER2_GUARDS=4 it
  can be seen that this means that the Sybil attack on Layer2 will complete
  with 50% chance in 18*7 days (126 days) for the 1% adversary, 4*7 days (one
  month) for the 5% adversary, and 2*7 days (two weeks) for the 10% adversary.

# 3. Tradeoffs from Proposal 292

  This proposal has several advantages over Proposal 292:

  By avoiding a third-layer of guards we reduce the linkability issues of
  Proposal 292, which means that we don't have to add an extra hop on top of
  our paths. This simplifies engineering and makes paths shorter by default:
  this means less latency and quicker page load times.

  This proposal also comes with disadvantages:

  The lack of third-layer guards makes it easier to launch guard discovery
  attacks against clients and onion services. Long-lived services are not well
  protected, and this proposal might provide those services with a false sense
  of security. Such services should still use the vanguards addon [VANGUARDS_REF].

# 4. References

  [PROP292_REF]: https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/292-mesh-vanguards.txt
  [VANGUARDS_REF]: https://github.com/mikeperry-tor/vanguards
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210712160147</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-07-12 16:01:47-0400</timestampReceived><subject>[tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

```
Filename: 332-ntor-v3-with-extra-data.md
Title: Ntor protocol with extra data, version 3.
Author: Nick Mathewson
Created: 12 July 2021
Status: Open
```

# Overview

The ntor handshake is our current protocol for circuit
establishment.

So far we have two variants of the ntor handshake in use: the "ntor
v1" that we use for everyday circuit extension (see `tor-spec.txt`)
and the "hs-ntor" that we use for v3 onion service handshake (see
`rend-spec-v3.txt`).  This document defines a third version of ntor,
adapting the improvements from hs-ntor for use in regular circuit
establishment.

These improvements include:

 * Support for sending additional encrypted and authenticated
   protocol-setup handshake data as part of the ntor handshake.  (The
   information sent from the client to the relay does not receive
   forward secrecy.)

 * Support for using an external shared secret that both parties must
   know in order to complete the handshake.  (In the HS handshake, this
   is the subcredential.  We don't use it for circuit extension, but in
   theory we could.)

 * Providing a single specification that can, in the future, be used
   both for circuit extension _and_ HS introduction.

# The improved protocol: an abstract view

Given a client "C" that wants to construct a circuit to a
relay "S":

The client knows:
  * B: a public "onion key" for S
  * ID: an identity for S, represented as a fixed-length
    byte string.
  * CM: a message that it wants to send to S as part of the
    handshake.
  * An optional "verification" string.

The relay knows:
  * A set of [(b,B)...] "onion key" keypairs.  One of them is
    "current", the others are outdated, but still valid.
  * ID: Its own identity.
  * A function for computing a server message SM, based on a given
    client message.
  * An optional "verification" string. This must match the "verification"
    string from the client.

Both parties have a strong source of randomness.

Given this information, the client computes a "client handshake"
and sends it to the relay.

The relay then uses its information plus the client handshake to see
if the incoming message is valid; if it is, then it computes a
"server handshake" to send in reply.

The client processes the server handshake, and either succeeds or fails.

At this point, the client and the relay both have access to:
  * CM (the message the client sent)
  * SM (the message the relay sent)
  * KS (a shared byte stream of arbitrary length, used to compute
    keys to be used elsewhere in the protocol).

Additionally, the client knows that CM was sent _only_ to the relay
whose public onion key is B, and that KS is shared _only_ with that
relay.

The relay does not know which client participated in the handshake,
but it does know that CM came from the same client that generated
the key X, and that SM and KS were shared _only_ with that client.

Both parties know that CM, SM, and KS were shared correctly, or not
at all.

Both parties know that they used the same verification string; if
they did not, they do not learn what the verification string was.
(This feature is required for HS handshakes.)

# The handshake in detail

## Notation

We use the following notation:

  * `|` -- concatenation
  * `"..."` -- a byte string, with no terminating NUL.
  * `ENCAP(s)` -- an encapsulation function.  We define this
     as `htonll(len(s)) | s`.  (Note that `len(ENCAP(s)) = len(s) + 8`).
  * `PARTITION(s, n1, n2, n3, ...)` -- a function that partitions a
     bytestring `s` into chunks of length `n1`, `n2`, `n3`, and so
     on. Extra data is put into a final chunk.  If `s` is not long
     enough, the function fails.

We require the following crypto operations:

  * `KDF(s,t)` -- a tweakable key derivation function, returning a
     keystream of arbitrary length.
  * `H(s,t)` -- a tweakable hash function of output length
     `DIGEST_LEN`.
  * `MAC(k, msg, t)` -- a tweakable message-authentication-code function,
     of output length `MAC_LEN`.
  * `EXP(pk,sk)` -- our Diffie Hellman group operation, taking a
     public key of length `PUB_KEY_LEN`.
  * `KEYGEN()` -- our Diffie-Hellman keypair generation algorithm,
    returning a (secret-key,public-key) pair.
  * `ENC(k, m)` -- a stream cipher with key of length `ENC_KEY_LEN`.
    `DEC(k, m)` is its inverse.

Parameters:

  * `PROTOID` -- a short protocol identifier
  * `t_*` -- a set of "tweak" strings, used to derive distinct
    hashes from a single hash function.
  * `ID_LEN` -- the length of an identity key that uniquely identifies
    a relay.

Given our cryptographic operations and a set of tweak strings, we
define:

```
H_foo(s) = H(s, t_foo)
MAC_foo(k, msg) = MAC(k, msg, t_foo)
KDF_foo(s) = KDF(s, t_foo)
```

See Appendix A.1 below for a set of instantiations for these operations
and constants.

## Client operation, phase 1

The client knows:
    B, ID -- the onion key and ID of the relay it wants to use.
    CM -- the message that it wants to send as part of its
           handshake.
    VER -- a verification string.

First, the client generates a single-use keypair:

    x,X = KEYGEN()

and computes:

    Bx = EXP(B,x)
    secret_input_phase1 = Bx | ID | X | B | PROTOID | ENCAP(VER)
    phase1_keys = KDF_msgkdf(secret_input_phase1)
    (ENC_K1, MAC_K1) = PARTITION(phase1_keys, ENC_KEY_LEN, MAC_KEY_LEN)

    encrypted_msg = ENC(ENC_K1, CM)
    msg_mac = MAC_msgmac(MAC_K1, ID | B | X | encrypted_msg)

and sends:

    NODEID      ID               [ID_LEN bytes]
    KEYID       B                [PUB_KEY_LEN bytes]
    CLIENT_PK   X                [PUB_KEY_LEN bytes]
    MSG         encrypted_msg    [len(CM) bytes]
    MAC         msg_mac          [last MAC_LEN bytes of message]

The client remembers x, X, B, ID, Bx, and msg_mac.

## Server operation

The relay checks whether NODEID is as expected, and looks up
the (b,B) keypair corresponding to KEYID.  If the keypair is
missing or the NODEID is wrong, the handshake fails.

Now the relay uses `X=CLIENT_PK` to compute:

    Xb = EXP(X,b)
    secret_input_phase1 = Xb | ID | X | B | PROTOID | ENCAP(VER)
    phase1_keys = KDF_msgkdf(secret_input_phase1)
    (ENC_K1, MAC_K1) = PARTITION(phase1_keys, ENC_KEY_LEN, MAC_KEY_LEN)

    expected_mac = MAC_msgmac(MAC_K1, ID | B | X | MSG)

If `expected_mac` is not `MAC`, the handshake fails.  Otherwise
the relay computes `CM` as:

    CM = DEC(MSG, ENC_K1)

The relay then checks whether `CM` is well-formed, and in response
composes `SM`, the reply that it wants to send as part of the
handshake. It then generates a new ephemeral keypair:

    y,Y = KEYGEN()

and computes the rest of the handshake:

    Xy = EXP(X,y)
    secret_input = Xy | Xb | ID | B | X | Y | PROTOID | ENCAP(VER)
    ntor_key_seed = H_key_seed(secret_input)
    verify = H_verify(secret_input)

    RAW_KEYSTREAM = KDF_final(ntor_key_seed)
    (ENC_KEY, KEYSTREAM) = PARTITION(RAW_KEYSTREAM, ENC_KEY_LKEN, ...)

    encrypted_msg = ENC(ENC_KEY, SM)

    auth_input = verify | ID | B | Y | X | MAC | ENCAP(encrypted_msg) |
        PROTOID | "Server"
    AUTH = H_auth(auth_input)

The relay then sends:

    Y          Y              [PUB_KEY_LEN bytes]
    AUTH       AUTH           [DIGEST_LEN bytes]
    MSG        encrypted_msg  [len(SM) bytes, up to end of the message]

The relay uses KEYSTREAM to generate the shared secrets for the
newly created circuit.

## Client operation, phase 2

The client computes:

    Yx = EXP(Y, x)
    secret_input = Yx | Bx | ID | B | X | Y | PROTOID | ENCAP(VER)
    ntor_key_seed = H_key_seed(secret_input)
    verify = H_verify(secret_input)

    auth_input = verify | ID | B | Y | X | MAC | ENCAP(MSG) |
        PROTOID | "Server"
    AUTH_expected = H_auth(auth_input)

If AUTH_expected is equal to AUTH, then the handshake has
succeeded.  The client can then calculate:

    RAW_KEYSTREAM = KDF_final(ntor_key_seed)
    (ENC_KEY, KEYSTREAM) = PARTITION(RAW_KEYSTREAM, ENC_KEY_LKEN, ...)

    SM = DEC(ENC_KEY, MSG)

SM is the message from the relay, and the client uses KEYSTREAM to
generate the shared secrets for the newly created circuit.

# Security notes

Whenever comparing bytestrings, implementations SHOULD use
constant-time comparison function to avoid side-channel attacks.

To avoid small-subgroup attacks against the Diffie-Hellman function,
implementations SHOULD either:

   * Make sure that all incoming group members are in fact in the DH
     group.
   * Validate all outputs from the EXP function to make sure that
     they are not degenerate.


# Notes on usage

We don't specify what should actually be done with the resulting
keystreams; that depends on the usage for which this handshake is
employed.  Typically, they'll be divided up into a series of tags
and symmetric keys.

The keystreams generated here are (conceptually) unlimited.  In
practice, the usage will determine the amount of key material
actually needed: that's the amount that clients and relays will
actually generate.

The PROTOID parameter should be changed not only if the
cryptographic operations change here, but also if the usage changes
at all, or if the meaning of any parameters changes.  (For example,
if the encoding of CM and SM changed, or if ID were a different
length or represented a different type of key, then we should start
using a new PROTOID.)


# A.1 Instantiation

Here are a set of functions based on SHA3, SHAKE128, Curve25519, and
AES256:

```
H(s, t) = SHA3_256(ENCAP(t) | s)
MAC(k, msg, t) = SHA3_256(ENCAP(t) | ENCAP(k) | s)
KDF(s, t) = SHAKE_128(ENCAP(t) | s)
ENC(k, m) = AES_256_CTR(k, m)

EXP(pk,sk), KEYGEN: defined as in curve25519

DIGEST_LEN = MAC_LEN = ENC_KEY_LEN = PUB_KEY_LEN = 32

ID_LEN = 32  (representing an ed25519 identity key)
```

Notes on selected operations: SHA3 can be pretty slow, and AES256 is
likely overkill.  I'm choosing them anyway because they are what we
use in hs-ntor, and in my preliminary experiments they don't account
for even 1% of the time spent on this handshake.

```
t_msgkdf = PROTOID | ":kdf_phase1"
t_msgmac = PROTOID | ":msg_mac"
t_key_seed = PROTOID | ":key_seed"
t_verify = PROTOID | ":verify"
t_final = PROTOID | ":kdf_final"
t_auth = PROTOID | ":auth_final"
```

# A.2 Encoding for use with Tor circuit extension

Here we give a concrete instantiation of ntor-v3 for use with
circuit extension in Tor, and the parameters in A.1 above.

If in use, this is a new CREATE2 type.  Clients should not use it
unless the relay advertises support by including an appropriate
version of the `Relay=X` subprotocol in its protocols list.

When the encoding and methods of this section, along with the
instantiations from the previous section, are in use, we specify:

    PROTOID = "ntor3-curve25519-sha3_256-1"

The key material is extracted as follows, unless modified by the
handshake (see below).  See tor-spec.txt for more info on the
specific values:

    Df    Digest authentication, forwards  [20 bytes]
    Db    Digest authentication, backwards [20 bytes]
    Kf    Encryption key, forwards         [16 bytes]
    Kb    Encryption key, backwards        [16 bytes]
    KH    Onion service nonce              [20 bytes]

We use the following meta-encoding for the contents of client and
server messages.

    [Any number of times]:
       TYPE     [one byte]
       LEN      [one byte]
       BODY     [LEN bytes]

We do not specify specific TYPE semantics here; we leave those for
other proposals.

All parties MUST reject messages that are not well-formed per the
rules above.

To avoid partitioning, clients MUST reject messages with TYPEs that
they do not recognize.  (Therefore, whenever we specify a new server
message TYPE, we must say that it can only be included if the client
signals that it understands it.)

# A.3 How much space is available?

We start with a 498-byte payload in each relay cell.

The header of the EXTEND2 cell, including link specifiers and other
headers, comes to 89 bytes.

The client handshake requires 128 bytes (excluding CM).

That leaves 281 bytes, "which should be plenty".

# X.1 Negotiating proposal-324 circuit windows

(We should move this section into prop324 when this proposal is
finished.)

We define a type value, CIRCWINDOW_INC.

We define a triplet of consensus parameters: `circwindow_inc_min`,
`cincwindow_inc_max`, and `circwindow_inc_dflt`.  These all have
range (1,65535).

When the authority operators want to experiment with different
values for `circwindow_inc_dflt`, they set `circwindow_inc_min` and
`circwindow_inc_max` to the range in which they want to experiment,
making sure that the existing `circwindow_inc_dflt` is within that
range.

vWhen a client sees that a relay supports the ntor3 handshake type
(subprotocol `Relay=X`), and also supports the flow control
algorithms of proposal 324 (subprotocol `FlowCtrl=X`), then the
client sends a message, with type `CIRCWINDOW_INC`, containing a
two-byte integer equal to `circwindow_inc_dflt`.

The relay rejects the message if the value given is outside of the
[`circwindow_inc_min`, `circwindow_inc_max`] range.  Otherwise, it
accepts it, and replies with the same message that the client sent.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210521092659</emailId><senderName>Apratim Ranjan Chakrabarty</senderName><senderEmail>abishekhmjee@gmail.com</senderEmail><timestampReceived>2021-05-21 09:26:59-0400</timestampReceived><subject>[tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring</subject><body>

[Attachment #2 (multipart/alternative)]


Hello everyone,

I'm Apratim (irc: _ranchak_), and I'm from Haldia Institute of Technology,
India, studying Computer Science Engineering. I'll be working this summer
on the GSoC project: "Alexa Top Sites Captcha and Tor Block Monitoring"
with my mentors Barkin, Pili, Gerog and Roger guiding me through the irc.
I'm very excited to be a part of Tor and am interested in working on this
project!

Briefing about the project: As of now "The Captcha Monitoring" project
tracks how often CDN (for ex. Cloudflare, Akamai, Amazon Cloudfront, etc.)
fronted webpages return CAPTCHAs to Tor clients. My project will be
focussed on tracking the The Alexa Top 500 Websites, to give a detailed
perspective of websites mentioned in the Topsites, blocking or returning
Captchas to Tor clients. The project aims to do so by fetching webpages
over a period of time from both Tor clients/browsers and the non-tor
browsers thereby comparing the results. The results will be then collected
and provide answers to the different metrics, and also form an
understanding of how websites are blocking Tor and affect Internet freedom.
Also one could visit:
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021 for
detailed info.

As planned and discussed by my mentor, I'll be creating more issues, which
could be seen from the sidebar along the wiki page, to record my progress.
As of now one could reach out with suggestions and advises in the irc
(#tor-dev) as well as here: tpo/community/support/#40013. I also plan to
update my wiki page frequently and have all the information required.

Hope to have a great learning ahead and enjoy this summer!

Regards,
Apratim

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hello everyone,&lt;br&gt;&lt;br&gt;I'm Apratim (irc: _ranchak_), and I'm \
from Haldia Institute of Technology, India, studying Computer Science Engineering. \
I'll be working this summer on the GSoC project: "Alexa Top Sites Captcha \
and Tor Block Monitoring" with my mentors Barkin, Pili, Gerog and Roger guiding \
me through the irc. I'm very excited to be a part of Tor and am interested in \
working on this project!&lt;br&gt;&lt;br&gt;&lt;div&gt;Briefing about the project: As of now "The \
Captcha Monitoring" project tracks how often CDN (for ex. Cloudflare, Akamai, \
Amazon Cloudfront, etc.) fronted webpages return CAPTCHAs to Tor clients. My project \
will be focussed on tracking the The Alexa Top 500 Websites, to give a detailed \
perspective of websites mentioned in the Topsites, blocking or returning Captchas to \
Tor clients. The project aims to do so by fetching webpages over a period of time \
from both Tor clients/browsers and the non-tor browsers thereby comparing the \
results. The results will be then collected and provide answers to the different \
metrics, and also form an understanding of how websites are blocking Tor and affect \
Internet freedom. Also one could visit: &lt;a \
href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021&lt;/a&gt; \
for detailed info.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;As planned and discussed by my \
mentor, I'll be creating more issues, which could be seen from the sidebar along \
the wiki page, to record my progress. As of now one could reach out with suggestions \
and advises in the irc (#tor-dev) as well as here: tpo/community/support/#40013. I \
also plan to update my wiki page frequently and have all the information \
required.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Hope to have a great learning ahead and enjoy this \
summer! &lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Regards,&lt;/div&gt;&lt;div&gt;Apratim&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210706175250</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2021-07-06 17:52:50-0400</timestampReceived><subject>[tor-dev] Weaving a Faster Tor: paper/video of possible interest</subject><body>

Hello tor-dev,

Steve Engler (currently part of the Shadow team) and I have a paper of
possible interest to appear at ARES 2021 next month.

It's a design of a multi-threaded relay architecture, of possible
particular interest when considering relay support in arti, for example
(though the proof-of-concept implementation is based on the usual C
codebase).

If you're interested, here are previews of:

Paper: https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf
Video: https://www.youtube.com/watch?v=41a6nLUJye8
Code: https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn
      https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing

-- 
Ian Goldberg
Canada Research Chair in Privacy Enhancing Technologies
Professor, Cheriton School of Computer Science
University of Waterloo
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210719192443</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-07-19 19:24:43-0400</timestampReceived><subject>Re: [tor-dev] Weaving a Faster Tor: paper/video of possible interest</subject><body>

[Attachment #2 (multipart/signed)]


On 06 Jul (13:52:50), Ian Goldberg wrote:
&gt; Hello tor-dev,
&gt; 
&gt; Steve Engler (currently part of the Shadow team) and I have a paper of
&gt; possible interest to appear at ARES 2021 next month.
&gt; 
&gt; It's a design of a multi-threaded relay architecture, of possible
&gt; particular interest when considering relay support in arti, for example
&gt; (though the proof-of-concept implementation is based on the usual C
&gt; codebase).
&gt; 
&gt; If you're interested, here are previews of:
&gt; 
&gt; Paper: https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf
&gt; Video: https://www.youtube.com/watch?v=41a6nLUJye8
&gt; Code: https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn
&gt;       https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing

Interesting!!!

One part caught my eye in section 4.3:

  "The large amount of locking would harm the relay's performance, and mes-
  sage passing would break some of the assumptions of Tor's primary scheduler,
  the KIST scheduler. Rather than using a global scheduler, each local
  connection manager uses its own local scheduler which processes only the
  connections it owns."

So KIST was also put in place in order to be able to consider _all_ channels
within one scheduling loop so to properly applied EWMA scheduling that is
basically loud circuits (lots of traffic) are less prioritize from quiet ones.

Moving to a scheduler per thread (as in only handling its set of connections),
we loose that property no? And so loud circuits end up crushing quiet
circuits on the physical link?

Another thing. Looking at figure (c), it appears only "relay/edge connections"
can queue cells on a circuit half *directly* that is not using a channel. I
assume that concurrency there between a relay connection writing a cell on a
circuit half and a cell received through a channel (from another circuit half)
has been thought of? :)

I'm asking also because within Tor, there are numerous places where a cell is
enqueued on a circuit (even an OR circuit like TRUNCATE for instance) and so
those place would need to use a channel or use the way relay connections write
them (which appears to be without a channel)?

Anyhow, good read, thanks for this paper!

Cheers!
David

-- 
6wN+FRCe3M9NFjAhiEkBEUpGWtZEa3ayD2xpq4CyMkE=

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210723214647</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-07-23 21:46:47-0400</timestampReceived><subject>[tor-dev] A series of questions about Tor (m1 support, forward secrecy, v3 auth)</subject><body>

Hi everyone,

A few disjointed questions that have come up recently in our work with Tor:

1. PERFORMANCE ON M1 / ARM64

We just got a report from a user that the tor binary for Mac was using much more CPU \
on Apple Silicon / M1 than it used on Intel. Has anyone scene anything like this? Is \
there an arm64 build of tor binary for Mac, existing or in the works? 

(Related: do Tor developers have a few M1 Macs to test on? We could probably donate \
one if not!) 

2. FORWARD SECRECY

Is there a good source for documentation on how forward secrecy works in Tor, and on \
what security guarantees it provides? Googling finds things like this reddit post \
(https://www.reddit.com/r/TOR/comments/cryrjx/does_tor_use_pfs/) but I can't find any \
detailed information about it, what threat models it fits, etc. 

One specific question is, if two users are communicating by sending messages over a \
connection to an onion service (like ricochet) and an attacker surveils their \
internet traffic and compromises their devices at a later date, will the attacker be \
able to recover the clear text of their conversation? When are keys for a given \
connection destroyed? Does it happen continuously throughout the course of a Tor \
connection? Or on the creation of a new circuit? Or what?

3. V3 AUTH AND DOS ATTACKS

Does v3 onion authentication protect against DOS attacks? That is, can someone who is \
not authorized to connect to an onion address with authentication enabled still cause \
problems for that onion address? Can they connect to it at all, in the sense of being \
able to send data to the tor client at that onion address? Or does the Tor network \
itself prevent this connection from even happening? 

A related question is, if we're looking to deny connections to an onion address to \
any unauthorized users, and we're considering turning off onion authentication and \
implementing some standard authentication scheme that seems fairly well-supported at \
the web server layer, is there any security-related reason why we would be better off \
using Tor's own authentication instead? Using our own authentication scheme will be a \
bit easier to control, rather than having to send commands to Tor (and possibly \
restart it for removing users?) but I'm wondering if there are security properties we \
lose by doing that. 

Thanks!

Also, apologies if any of these questions aren't clear or well-formed! 

Holmes
 
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210723222849</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2021-07-23 22:28:49-0400</timestampReceived><subject>Re: [tor-dev] A series of questions about Tor (m1 support, forward secrecy, v3 auth)</subject><body>

Hi Holmes,

On Fri, Jul 23, 2021 at 05:46:47PM -0400, Holmes Wilson wrote:
&gt; Hi everyone,
&gt; 
&gt; A few disjointed questions that have come up recently in our work with Tor:
&gt; 
&gt; 1. PERFORMANCE ON M1 / ARM64
&gt; 
&gt; We just got a report from a user that the tor binary for Mac was using much more \
&gt; CPU on Apple Silicon / M1 than it used on Intel. Has anyone scene anything like \
&gt; this? Is there an arm64 build of tor binary for Mac, existing or in the works? 

Can you provide more detail about where this tor binary came from? Was
it compiled from source or did it come from Tor Browser?

&gt; 
&gt; (Related: do Tor developers have a few M1 Macs to test on? We could probably donate \
&gt; one if not!)  

We do not, but we'd be happy to discuss this with you!

(I'll leave your other two questions to another tor person)

&gt; 2. FORWARD SECRECY
&gt; 
&gt; Is there a good source for documentation on how forward secrecy works in Tor, and \
&gt; on what security guarantees it provides? Googling finds things like this reddit \
&gt; post (https://www.reddit.com/r/TOR/comments/cryrjx/does_tor_use_pfs/) but I can't \
&gt; find any detailed information about it, what threat models it fits, etc.  
&gt; One specific question is, if two users are communicating by sending messages over a \
&gt; connection to an onion service (like ricochet) and an attacker surveils their \
&gt; internet traffic and compromises their devices at a later date, will the attacker \
&gt; be able to recover the clear text of their conversation? When are keys for a given \
&gt; connection destroyed? Does it happen continuously throughout the course of a Tor \
&gt; connection? Or on the creation of a new circuit? Or what? 
&gt; 3. V3 AUTH AND DOS ATTACKS
&gt; 
&gt; Does v3 onion authentication protect against DOS attacks? That is, can someone who \
&gt; is not authorized to connect to an onion address with authentication enabled still \
&gt; cause problems for that onion address? Can they connect to it at all, in the sense \
&gt; of being able to send data to the tor client at that onion address? Or does the Tor \
&gt; network itself prevent this connection from even happening?  
&gt; A related question is, if we're looking to deny connections to an onion address to \
&gt; any unauthorized users, and we're considering turning off onion authentication and \
&gt; implementing some standard authentication scheme that seems fairly well-supported \
&gt; at the web server layer, is there any security-related reason why we would be \
&gt; better off using Tor's own authentication instead? Using our own authentication \
&gt; scheme will be a bit easier to control, rather than having to send commands to Tor \
&gt; (and possibly restart it for removing users?) but I'm wondering if there are \
&gt; security properties we lose by doing that.  
&gt; Thanks!
&gt; 
&gt; Also, apologies if any of these questions aren't clear or well-formed! 
&gt; 
&gt; Holmes
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210723234621</emailId><senderName>hackerncoder</senderName><senderEmail>hackerncoder@encryptionin.space</senderEmail><timestampReceived>2021-07-23 23:46:21-0400</timestampReceived><subject>Re: [tor-dev] A series of questions about Tor (m1 support, forward secrecy, v3 auth)</subject><body>

Disclaimer: I do not know that much about Tor, but I can read (and have
read parts of) the specifications

And sorry to Holmes for sending this twice. I'm not used to mailing 
lists, "reply" is right next to (and before, so when running on 
auto-pilot that's the first thing I see) "reply list".

 &gt; Hi everyone,
 &gt;
 &gt; A few disjointed questions that have come up recently in our work 
with Tor:
 &gt;
 &gt; 1. PERFORMANCE ON M1 / ARM64
 &gt;
 &gt; We just got a report from a user that the tor binary for Mac was 
using much more CPU on Apple Silicon / M1 than it used on Intel. Has 
anyone scene anything like this? Is there an arm64 build of tor binary 
for Mac, existing or in the works?
 &gt;
 &gt; (Related: do Tor developers have a few M1 Macs to test on? We could 
probably donate one if not!)
 &gt;
 &gt; 2. FORWARD SECRECY
 &gt;
 &gt; Is there a good source for documentation

In general I would point at https://spec.torproject.org, they are
technical and long when you just want info on one specific thing, but is
still good nonetheless. In particular you may find rend-spec-v3
(onion/hidden services, v3) and tor-spec good.

 &gt; on how forward secrecy works in Tor, and on what security guarantees 
it provides? Googling finds things like this reddit post 
(https://www.reddit.com/r/TOR/comments/cryrjx/does_tor_use_pfs/) but I 
canâ€™t find any detailed information about it, what threat models it 
fits, etc.

In tor-spec there point "2" for connections[1], they are made with TLS,
so if supported by both client and relay it may be it is possible that
FS happens here.

 &gt; One specific question is, if two users are communicating by sending 
messages over a connection to an onion service (like ricochet) and an 
attacker surveils their internet traffic and compromises their devices 
at a later date, will the attacker be able to recover the clear text of 
their conversation? When are keys for a given connection destroyed? Does 
it happen continuously throughout the course of a Tor connection? Or on 
the creation of a new circuit? Or what?
 &gt;
 &gt; 3. V3 AUTH AND DOS ATTACKS
 &gt;
 &gt; Does v3 onion authentication protect against DOS attacks? That is, 
can someone who is not authorized to connect to an onion address with 
authentication enabled still cause problems for that onion address? Can 
they connect to it at all, in the sense of being able to send data to 
the tor client at that onion address? Or does the Tor network itself 
prevent this connection from even happening?

No. The rendevouz specifications (v3) [2] make it so only authorized
clients (if enabled) are able to figure out (e.g.) the introduction
points of the onion service, thereby being unable to contact it.

"The second layer of descriptor encryption is designed to protect
descriptor confidentiality against unauthorized clients. If client
authorization is enabled, it's encrypted using the descriptor_cookie,
and contains needed information for connecting to the hidden service,
like the list of its introduction points."

 &gt; A related question is, if weâ€™re looking to deny connections to an 
onion address to any unauthorized users, and weâ€™re considering turning 
off onion authentication and implementing some standard authentication 
scheme that seems fairly well-supported at the web server layer, is 
there any security-related reason why we would be better off using 
Torâ€™s own authentication instead? Using our own authentication scheme 
will be a bit easier to control, rather than having to send commands to 
Tor (and possibly restart it for removing users?) but Iâ€™m wondering if 
there are security properties we lose by doing that &gt;
 &gt; Thanks!
 &gt;
 &gt; Also, apologies if any of these questions arenâ€™t clear or well-formed!
 &gt;
 &gt; Holmes
 &gt;

[1] https://gitweb.torproject.org/torspec.git/tree/tor-spec.txt#n196
[2] https://gitweb.torproject.org/torspec.git/tree/rend-spec-v3.txt#n1287
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210724194001</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-07-24 19:40:01-0400</timestampReceived><subject>Re: [tor-dev] A series of questions about Tor (m1 support, forward secrecy, v3 auth)</subject><body>

[Attachment #2 (multipart/alternative)]


&gt; &gt; We just got a report from a user that the tor binary for Mac was using much more \
&gt; &gt; CPU on Apple Silicon / M1 than it used on Intel. Has anyone scene anything like \
&gt; &gt; this? Is there an arm64 build of tor binary for Mac, existing or in the works? 
&gt; 
&gt; Can you provide more detail about where this tor binary came from? Was
&gt; it compiled from source or did it come from Tor Browser?

It came from Tor Browser. So it was definitely an intel build. Is compiling for \
M1/arm64 as simple as compiling Tor on M1? 

&gt; &gt; (Related: do Tor developers have a few M1 Macs to test on? We could probably \
&gt; &gt; donate one if not!)  
&gt; 
&gt; We do not, but we'd be happy to discuss this with you!

Sure thing! I'll email you directly.

Holmes


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;&lt;br class=""&gt;&lt;div&gt;&lt;blockquote type="cite" \
class=""&gt;&lt;div class=""&gt;&lt;blockquote type="cite" style="font-family: Helvetica; \
font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; \
text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; \
-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; text-decoration: \
none;" class=""&gt;We just got a report from a user that the tor binary for Mac was \
using much more CPU on Apple Silicon / M1 than it used on Intel. Has anyone scene \
anything like this? Is there an arm64 build of tor binary for Mac, existing or in the \
works?&lt;span class="Apple-converted-space"&gt; &lt;/span&gt;&lt;br class=""&gt;&lt;/blockquote&gt;&lt;br \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;span style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: \
12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none; float: none; display: inline !important;" class=""&gt;Can you \
provide more detail about where this tor binary came from? Was&lt;/span&gt;&lt;br \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;span style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: \
12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none; float: none; display: inline !important;" class=""&gt;it compiled \
from source or did it come from Tor Browser?&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, \
0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;It came from Tor Browser. So \
it was definitely an intel build. Is compiling for M1/arm64 as simple as compiling \
Tor on M1? &lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;blockquote type="cite" class=""&gt;&lt;div \
class=""&gt;&lt;blockquote type="cite" style="font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; \
-webkit-text-stroke-width: 0px; text-decoration: none;" class=""&gt;(Related: do Tor \
developers have a few M1 Macs to test on? We could probably donate one if not!)&lt;span \
class="Apple-converted-space"&gt; &lt;/span&gt;&lt;br class=""&gt;&lt;br class=""&gt;&lt;/blockquote&gt;&lt;br \
style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: 12px; \
font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: \
normal; text-align: start; text-indent: 0px; text-transform: none; white-space: \
normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;span style="caret-color: rgb(0, 0, 0); font-family: Helvetica; font-size: \
12px; font-style: normal; font-variant-caps: normal; font-weight: normal; \
letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; \
white-space: normal; word-spacing: 0px; -webkit-text-stroke-width: 0px; \
text-decoration: none; float: none; display: inline !important;" class=""&gt;We do not, \
but we'd be happy to discuss this with you!&lt;/span&gt;&lt;br style="caret-color: rgb(0, 0, \
0); font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: \
normal; font-weight: normal; letter-spacing: normal; text-align: start; text-indent: \
0px; text-transform: none; white-space: normal; word-spacing: 0px; \
-webkit-text-stroke-width: 0px; text-decoration: none;" \
class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;Sure thing! I'll email you \
directly.&lt;/div&gt;&lt;div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div&gt;Holmes&lt;/div&gt;&lt;/div&gt;&lt;br \
class=""&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210719234339</emailId><senderName>Nafis Abir</senderName><senderEmail>nafisabir0@gmail.com</senderEmail><timestampReceived>2021-07-19 23:43:39-0400</timestampReceived><subject>Re: [tor-dev] Weaving a Faster Tor: paper/video of possible interest</subject><body>

[Attachment #2 (multipart/alternative)]


thanks a lot for this information


On Tue, Jul 6, 2021 at 11:53 PM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:

&gt; Hello tor-dev,
&gt;
&gt; Steve Engler (currently part of the Shadow team) and I have a paper of
&gt; possible interest to appear at ARES 2021 next month.
&gt;
&gt; It's a design of a multi-threaded relay architecture, of possible
&gt; particular interest when considering relay support in arti, for example
&gt; (though the proof-of-concept implementation is based on the usual C
&gt; codebase).
&gt;
&gt; If you're interested, here are previews of:
&gt;
&gt; Paper: https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf
&gt; Video: https://www.youtube.com/watch?v=41a6nLUJye8
&gt; Code: https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn
&gt;       https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing
&gt;
&gt; --
&gt; Ian Goldberg
&gt; Canada Research Chair in Privacy Enhancing Technologies
&gt; Professor, Cheriton School of Computer Science
&gt; University of Waterloo
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;div&gt;thanks a lot for this \
information&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" \
class="gmail_attr"&gt;On Tue, Jul 6, 2021 at 11:53 PM Ian Goldberg &lt;&lt;a \
href="mailto:iang@uwaterloo.ca"&gt;iang@uwaterloo.ca&lt;/a&gt;&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote \
class="gmail_quote" style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;Hello tor-dev,&lt;br&gt; &lt;br&gt;
Steve Engler (currently part of the Shadow team) and I have a paper of&lt;br&gt;
possible interest to appear at ARES 2021 next month.&lt;br&gt;
&lt;br&gt;
It's a design of a multi-threaded relay architecture, of possible&lt;br&gt;
particular interest when considering relay support in arti, for example&lt;br&gt;
(though the proof-of-concept implementation is based on the usual C&lt;br&gt;
codebase).&lt;br&gt;
&lt;br&gt;
If you're interested, here are previews of:&lt;br&gt;
&lt;br&gt;
Paper: &lt;a href="https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf" rel="noreferrer" \
                target="_blank"&gt;https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf&lt;/a&gt;&lt;br&gt;
                
Video: &lt;a href="https://www.youtube.com/watch?v=41a6nLUJye8" rel="noreferrer" \
                target="_blank"&gt;https://www.youtube.com/watch?v=41a6nLUJye8&lt;/a&gt;&lt;br&gt;
Code: &lt;a href="https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn" \
rel="noreferrer" target="_blank"&gt;https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn&lt;/a&gt;&lt;br&gt;
  &lt;a href="https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing" \
rel="noreferrer" target="_blank"&gt;https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing&lt;/a&gt;&lt;br&gt;
 &lt;br&gt;
-- &lt;br&gt;
Ian Goldberg&lt;br&gt;
Canada Research Chair in Privacy Enhancing Technologies&lt;br&gt;
Professor, Cheriton School of Computer Science&lt;br&gt;
University of Waterloo&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210720052954</emailId><senderName>Steven Engler</senderName><senderEmail>opara@torproject.org</senderEmail><timestampReceived>2021-07-20 05:29:54-0400</timestampReceived><subject>Re: [tor-dev] Weaving a Faster Tor: paper/video of possible interest</subject><body>

On 2021-07-19 3:24 p.m., David Goulet wrote:
&gt; On 06 Jul (13:52:50), Ian Goldberg wrote:
&gt;&gt; Hello tor-dev,
&gt;&gt;
&gt;&gt; Steve Engler (currently part of the Shadow team) and I have a paper of
&gt;&gt; possible interest to appear at ARES 2021 next month.
&gt;&gt;
&gt;&gt; It's a design of a multi-threaded relay architecture, of possible
&gt;&gt; particular interest when considering relay support in arti, for example
&gt;&gt; (though the proof-of-concept implementation is based on the usual C
&gt;&gt; codebase).
&gt;&gt;
&gt;&gt; If you're interested, here are previews of:
&gt;&gt;
&gt;&gt; Paper: https://cs.uwaterloo.ca/~iang/pubs/mttor-ares21.pdf
&gt;&gt; Video: https://www.youtube.com/watch?v=41a6nLUJye8
&gt;&gt; Code: https://git-crysp.uwaterloo.ca/sengler/tor-parallel-relay-conn
&gt;&gt;        https://git-crysp.uwaterloo.ca/sengler/relay-throughput-testing
&gt; 
&gt; Interesting!!!
&gt; 
&gt; One part caught my eye in section 4.3:
&gt; 
&gt;    "The large amount of locking would harm the relay’s performance, and mes-
&gt;    sage passing would break some of the assumptions of Tor’s primary scheduler,
&gt;    the KIST scheduler. Rather than using a global scheduler, each local
&gt;    connection manager uses its own local scheduler which processes only the
&gt;    connections it owns."
&gt; 
&gt; So KIST was also put in place in order to be able to consider _all_ channels
&gt; within one scheduling loop so to properly applied EWMA scheduling that is
&gt; basically loud circuits (lots of traffic) are less prioritize from quiet ones.
&gt; 
&gt; Moving to a scheduler per thread (as in only handling its set of connections),
&gt; we loose that property no? And so loud circuits end up crushing quiet
&gt; circuits on the physical link?

(Sending this from an address that is a tor-dev list member.)

If the scheduler's prioritization needs to be exact across all circuits 
in the relay, then yes that isn't possible with a scheduler per thread.

Our argument is that we don't believe the relay needs prioritization to 
be perfect across all circuits in the relay. For relays that currently 
aren't able to saturate their physical link due to CPU performance 
limitations, the greater total throughput from multi-threading might be 
worth partially relaxing the scheduling prioritization. Performing 
per-thread circuit EWMA scheduling should still be enough to prevent 
loud circuits from crushing quiet circuits, as long as connections are 
load-balanced across threads in a way that each thread has a mix of loud 
and quiet circuits.

&gt; Another thing. Looking at figure (c), it appears only "relay/edge connections"
&gt; can queue cells on a circuit half *directly* that is not using a channel. I
&gt; assume that concurrency there between a relay connection writing a cell on a
&gt; circuit half and a cell received through a channel (from another circuit half)
&gt; has been thought of? :)

Since the connection object holds the only reference to the circuit 
half, it can access the circuit half directly without locking or message 
passing. This is good for performance and for limiting buffer bloat. 
Cells arriving at a circuit half on a channel should be queued in that 
channel and shouldn't directly trigger any access on the circuit half 
(the channel shouldn't hold a reference to that circuit half). Since the 
connection object is in charge of both writing a cell on a circuit half 
and having that circuit half process cells that are queued on its 
channel, there shouldn't be any concurrency issues here.

&gt; I'm asking also because within Tor, there are numerous places where a cell is
&gt; enqueued on a circuit (even an OR circuit like TRUNCATE for instance) and so
&gt; those place would need to use a channel or use the way relay connections write
&gt; them (which appears to be without a channel)?

We were only able to discuss this briefly in the paper, but there's a 
bit more about that in section 5.3.4 here:
https://uwspace.uwaterloo.ca/bitstream/handle/10012/16108/Engler_Steven.pdf

Generally, we want cells to only be enqueued by the circuit half's 
connection object rather than having many places in tor try to 
communicate directly with circuit objects. When other parts of tor want 
to enqueue a cell on a circuit half, they should use the relay 
controller to send a message to the other thread's connection manager 
along one of the async channels shown in figure 4.a. The connection 
manager can then have the corresponding relay connection enqueue a cell 
directly on the circuit half.

&gt; Anyhow, good read, thanks for this paper!

Thanks for reading it! :)

- Steve
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210524230419</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2021-05-24 23:04:19-0400</timestampReceived><subject>Re: [tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring</subject><body>

&gt; https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021
&gt; tpo/community/support/#40013

https://trac.torproject.org/projects/tor/wiki/org/projects/DontBlockMe
https://trac.torproject.org/projects/tor/wiki/org/doc/ListOfServicesBlockingTor

The importance due to negative utility and freedom impact this big blocking
problem has been having on Tor users. The DBM project in the original wiki'd
links could/should have been first picked up and added adjunct to with the
publicly sphere engaged and reporting in the OONI style (itself started after
the decade of the DBM project started its outline). And the problem grew larger.

Cloudflare (TLS stripping spies), reCaptcha, etc... have only spread worse over
time now blocking even more percent of sites, by their default config and or by
negative biased wording in the blocking softwares config docs about tor users
that their customers then read and make bad misconcept about tor and its users
thus leading to more blocking being configured, meanwhile tor users have grown
in mass numbers, thus more negative impact total to bigger percent of people
using internet especially via tor and VPN.

At least some people formally looks at problem now, even if only first
GSOC, to proof and expose it to sunshine more, towards ending it.
Most of the project aspects for it are in searchable lists history around the
above links, including automating the scans, ranking, reporting, doing public
engagement against the blocks using the provided list of potential solutions
to get the problem solved, etc.

It is really very bad when Tor users are censored forbidden prevented from
right of just clicking and only *reading* information on the internet, let
alone Tor users needs to publish their own there, to reply interact
utilize with others in the fora and platforms and services, to use buy pay
support patronize and get delivery, to debate social meet discover help learn
politic etc, the right to *write* to the internet... under such discriminatory
predjudiced anti human right of participation, under these kneejerk
least-co$t-and-thought-given blocking regimes and mentalities.

The use of tor, VPN's, new overlay and proxy networks, to browse/use
the internet is only growing worldwide, for good ways and defensive protective
sensible reasons... but users still getting more "you are denied to use this
service via tor/VPN, your account has been locked and deleted, your datas
and balance has been confiscated, you are banned for life, you must submit
selfies phones IDs and all life data infos, etc" ... all just for using the
tor/VPN/proxy.

Such source based blocking methods even being applied to users
of IRC, and now to the cryptocurrency networks.

End these blocking regimes being deployed against freedoms
of millions of worlds users... "DontBlockMe"... indeed!
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210712114335</emailId><senderName>Apratim Ranjan Chakrabarty</senderName><senderEmail>abishekhmjee@gmail.com</senderEmail><timestampReceived>2021-07-12 11:43:35-0400</timestampReceived><subject>[tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring #Update</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone!

Been quite sometime since the last update but if one wants to see the
details in between one could go to the DIAL blogs for the project[1].
As of now, we do have a working project with the following details
implemented [2] and further the dotted[consensus module], idea taken from
Senser paper[3] haven't been implemented yet, but hopefully I'll implement
it within a week or two at most. I personally was tilted towards the
similarity of the structure but after some discussions with woswos and
Micah Sherr[4], I've thought of implementing the content based approach
too.

I'll briefly describe both the methods below:
+ Structure of the website: This was thought of because we don't really
know what various changes would be there for a website. More specifically
would be useful for dynamic websites, websites with language based on
geolocation (Geotargeting). But I have to use a filter list and statistical
method to approach the problem.

+ Content based Approach: Compares the content of the HTML data using tree
like structure and hashes to know how the structure is different or
similar. Usage of proxies of the same locations as vantage points to get
better results.

That said, the above mentioned methods are used for  the case where
websites partially block tor. One good example for this case would be
https://dan.me.uk/ which doesn't block tor exit relay nodes completely, but
gives an error page (partial block) and no error HTTP response code. The
checking of the HTTP response codes being a low-hanging-fruitish algorithm
is our first step which is seen performing good and might sometimes result
in false positives (Says a website like https://cloudflare.com to be
blocked completely, when it returns captcha or is partially blocked).

Further for the demo purpose, one can refer to the Experimental code[5] and
it's log[6] (Isn't much of a good code and is a bit old but wrote to serve
the purpose of backing up the first method (Structure of the website)).
Also one could look into the `Analyzer.py`[7,8] which would contain the
most recent and improved logic to the analysis. Hope to improve it with
every passing day. I also plan to create a FAQ[9] page which would have
excerpts of discussions or answers to as why a following approach was taken.


Thanks,
Apratim
(irc: _ranchak_)


** Looking forward for suggestions and comments as to how to improve on it.
Also materials like research paper in this domain would be helpful **

References:
[1]
https://hub.osc.dial.community/t/tor-project-alexa-top-sites-captcha-and-block-monitoring/2552
 [2]
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021#updated-logic
[3] http://people.cs.georgetown.edu/~wzhou/publication/senser-acsac13.pdf
[4] https://seclab.cs.georgetown.edu/msherr/
[5]
https://github.com/Hackhard/Fetcher/blob/b9f2fa8d09061862cf954537cbaad7921ddb3d89/status%20code/test_run4/tr.py
 [6]
https://raw.githubusercontent.com/Hackhard/Fetcher/main/status%20code/test_run4/tr_bash_output
 [7] Consensus_lite branch:
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/consensus_lite/src/captchamonitor/core/analyzer.py
 [8] Master branch:
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/master/src/captchamonitor/core/analyzer.py
 [9]
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021/Faqs


[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi everyone!&lt;br&gt;&lt;br&gt;Been quite sometime since the last update but if \
one wants to see the details in between one could go to the DIAL blogs for the \
project[1].&lt;br&gt;As of now, we do have a working project with the following details \
implemented [2] and further the dotted[consensus module], idea taken from Senser \
paper[3] haven't been implemented yet, but hopefully I'll implement it within \
a week or two at most. I personally was tilted towards the similarity of the \
structure but after some discussions with woswos and Micah Sherr[4], I've thought \
of implementing the content based approach too. &lt;br&gt;&lt;br&gt;&lt;div&gt;I'll briefly \
describe both the methods below:&lt;/div&gt;&lt;div&gt;+ Structure of the website: This was \
thought of because we don't really know what various changes would be there for a \
website. More specifically would be useful for dynamic websites, websites with \
language based on geolocation (Geotargeting). But I have to use a filter list and \
statistical method to approach the problem.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;+ Content based \
Approach: Compares the content of the HTML data using tree like structure and hashes \
to know how the structure is different or similar. Usage of proxies of the same \
locations as vantage points to get better results.&lt;br&gt;&lt;br&gt;&lt;div&gt;That said, the above \
mentioned methods are used for   the case where websites partially block tor. One \
good example for this case would be &lt;a \
href="https://dan.me.uk/"&gt;https://dan.me.uk/&lt;/a&gt; which doesn't block tor exit \
relay nodes completely, but gives an error page (partial block) and no error HTTP \
response code. The checking of the HTTP response codes being a \
&lt;span&gt;&lt;span&gt;low-hanging-fruitish algorithm&lt;/span&gt;&lt;/span&gt; is our first step which is \
seen performing good and might sometimes result in false positives (Says a website \
like &lt;a href="https://cloudflare.com"&gt;https://cloudflare.com&lt;/a&gt; to be blocked \
completely, when it returns captcha or is partially \
blocked).&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;Further for the demo purpose, one can refer to the \
Experimental code[5] and it's log[6] (Isn't much of a good code and is a bit \
old but wrote to serve the purpose of backing up the first method (Structure of the \
website)). Also one could look into the `Analyzer.py`[7,8] which would contain the \
most recent and improved logic to the analysis. Hope to improve it with every passing \
day. I also plan to create a FAQ[9] page which would have excerpts of discussions or \
answers to as why a following approach was taken.&lt;br&gt;&lt;br&gt;&lt;br&gt;Thanks, &lt;br&gt;Apratim \
&lt;br&gt;(irc: _ranchak_)&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;div&gt;** Looking forward for suggestions and comments \
as to how to improve on it. Also materials like research paper in this domain would \
be helpful **&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;References:&lt;br&gt;[1] &lt;a \
href="https://hub.osc.dial.community/t/tor-project-alexa-top-sites-captcha-and-block-m \
onitoring/2552"&gt;https://hub.osc.dial.community/t/tor-project-alexa-top-sites-captcha-and-block-monitoring/2552&lt;/a&gt;&lt;br&gt;[2] \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021#update \
d-logic"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021#updated-logic&lt;/a&gt;&lt;br&gt;[3] \
&lt;a href="http://people.cs.georgetown.edu/~wzhou/publication/senser-acsac13.pdf"&gt;http://people.cs.georgetown.edu/~wzhou/publication/senser-acsac13.pdf&lt;/a&gt;&lt;br&gt;&lt;div&gt;[4] \
&lt;a href="https://seclab.cs.georgetown.edu/msherr/"&gt;https://seclab.cs.georgetown.edu/msherr/&lt;/a&gt;&lt;/div&gt;&lt;div&gt;[5] \
&lt;a href="https://github.com/Hackhard/Fetcher/blob/b9f2fa8d09061862cf954537cbaad7921ddb \
3d89/status%20code/test_run4/tr.py"&gt;https://github.com/Hackhard/Fetcher/blob/b9f2fa8d09061862cf954537cbaad7921ddb3d89/status%20code/test_run4/tr.py&lt;/a&gt;&lt;/div&gt;&lt;div&gt;[6] \
&lt;a href="https://raw.githubusercontent.com/Hackhard/Fetcher/main/status%20code/test_ru \
n4/tr_bash_output"&gt;https://raw.githubusercontent.com/Hackhard/Fetcher/main/status%20code/test_run4/tr_bash_output&lt;/a&gt;&lt;/div&gt;&lt;div&gt;[7] \
Consensus_lite branch: &lt;a \
href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/consensus_lite/src/c \
aptchamonitor/core/analyzer.py"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/consensus_lite/src/captchamonitor/core/analyzer.py&lt;/a&gt;&lt;/div&gt;&lt;div&gt;[8] \
Master branch: &lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/ma \
ster/src/captchamonitor/core/analyzer.py"&gt;https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/blob/master/src/captchamonitor/core/analyzer.py&lt;/a&gt;&lt;/div&gt;&lt;div&gt;[9] \
&lt;a href="https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021/Faqs"&gt; \
https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021/Faqs&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;




_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210712190411</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2021-07-12 19:04:11-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Mon, Jul 12, 2021 at 12:01:47PM -0400, Nick Mathewson wrote:
&gt; Both parties know that they used the same verification string; if
&gt; they did not, they do not learn what the verification string was.
&gt; (This feature is required for HS handshakes.)

I'm not sure the protocol you specify has this feature as written.  For
example, if the verification string has low entropy, the server could
brute-force the client's verification string (using the MAC to check its
guess).  This is unlike, say, OTR's SMP or a PAKE, in which each online
execution of the protocol allows the server just one guess.

But perhaps you don't actually need the property in as strong a form as
you wrote it, since the HS handshake application has high-entropy
secrets?
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210712190902</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2021-07-12 19:09:02-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Mon, Jul 12, 2021 at 3:04 PM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt;
&gt; On Mon, Jul 12, 2021 at 12:01:47PM -0400, Nick Mathewson wrote:
&gt; &gt; Both parties know that they used the same verification string; if
&gt; &gt; they did not, they do not learn what the verification string was.
&gt; &gt; (This feature is required for HS handshakes.)
&gt;
&gt; I'm not sure the protocol you specify has this feature as written.  For
&gt; example, if the verification string has low entropy, the server could
&gt; brute-force the client's verification string (using the MAC to check its
&gt; guess).  This is unlike, say, OTR's SMP or a PAKE, in which each online
&gt; execution of the protocol allows the server just one guess.
&gt;
&gt; But perhaps you don't actually need the property in as strong a form as
&gt; you wrote it, since the HS handshake application has high-entropy
&gt; secrets?

Oh yes, you are right, of course.

Can you suggest a way to phrase this property that encompasses what
the protocol actually does provide?

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210729204637</emailId><senderName>Cecylia Bocovich</senderName><senderEmail>cohosh@torproject.org</senderEmail><timestampReceived>2021-07-29 20:46:37-0400</timestampReceived><subject>[tor-dev] A proposal to phase out CAPTCHAs for BridgeDB</subject><body>

Hi everyone,

We've been working on improving the usability of BridgeDB lately, and
our CAPTCHAs have been a constant thorny problem. They are not
accessible for blind users [0]. We've gotten many complaints over the
years that they are hard to use [1], I'm sure Gus and the community team
members can vent about the impact they've had on users.

We even have some evidence that bots have been able to enumerate our
CAPTCHAs just fine [2]. There are other anti-enumeration defences on
BridgeDB that are perhaps more useful including:
- partitioning bridges into buckets based on IP subnet: A user who
requests bridges from a single IP address or multiple IP addresses from
the same subnet won't be able to see every bridge.
- time-locking access to bridges: The set of bridges that BridgeDB
distributes to users during a single time period is locked to a small
number. Repeated requests for bridges during that time period will
return the same 3 bridges to the user.
We haven't done a lot of experimenting with tuning these parameters to
slow bridge enumeration attempts.

For the most part, on the country level, censors that are willing to put
the effort into blocking BridgeDB bridges seem to be pretty effective at
it regardless of CAPTCHAs. The GFW blocked all of the new bridges from
our 2019 bridge campaign in less than a month [3]. There was a recent
case of censorship in Belarus where state censors blocked all of
BridgeDB's email distributed bridges, but weren't able to enumerate
bridges distributed over Moat or HTTPS [4]. It's possible that that
CAPTCHAs were the reason behind this, but it's hard to know for sure.

I would like to propose that we remove the CAPTCHAs from BridgeDB
entirely, but I'd like to know whether there is research out there
*specifically that fits with the anti-censorship context* showing that
these CAPTCHAs are actually doing useful work to prevent Bridge
enumeration. But, even if the CAPTCHAs are preventing a small number of
censors from enumerating more bridges, is the usability impact worth
what marginal benefit we get from it?

Options for how to move forward:

Option 1: Just remove the CAPTCHAs already!

    We're tired of waiting and just want our bridges.

Option 2: Do some science?

    We could make a new distribution bucket in BridgeDB that distributes
bridges through Moat without a CAPTCHA and have new versions of Tor
Browser pull from this bucket. We can watch and perform measurements in
places we know enumeration attempts have occurred in the past and see
whether these bridges are enumerated more quickly and more completely
than the old-school Moat bucket.

Option 3: Keep doing what we're doing but try to make the CAPTCHAs more
usable.

    This is the work we've had planned, but will only get us so far.


Endpoint enumeration is a tricky topic and we do have some other
alternatives in the pipeline. Conjure is more of a "blocking resistance
through collateral damage" approach that's somewhat similar to domain
fronting [5]. We've been looking at and hope to do more work in the
future on reputation-based bridge distribution [6]. I see these as more
promising than CAPTCHAs in the long run, and CAPTCHA-less BridgeDB
bridges seem to still fill a need that built-in bridges and private
bridges don't fill.

I'd appreciate any thoughts, comments, or experiences others have!

Cecylia

[0]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/10831
[1]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/24607
[2]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/32117
[3]
https://gitlab.torproject.org/tpo/anti-censorship/pluggable-transports/obfs4/-/issues/31701
 [4]
https://gitlab.torproject.org/tpo/anti-censorship/censorship-analysis/-/blob/main/reports/2020/belarus/2020-belarus-report.md
 [5] https://gitlab.torproject.org/tpo/anti-censorship/team/-/issues/9
[6]
https://gitlab.torproject.org/tpo/anti-censorship/bridgedb/-/issues/31873
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210730160739</emailId><senderName>sajolida</senderName><senderEmail>sajolida@pimienta.org</senderEmail><timestampReceived>2021-07-30 16:07:39-0400</timestampReceived><subject>Re: [tor-dev] A proposal to phase out CAPTCHAs for BridgeDB</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


Cecylia Bocovich:
&gt; Option 1: Just remove the CAPTCHAs already!
&gt; 
&gt;     We're tired of waiting and just want our bridges.
&gt; 
&gt; Option 2: Do some science?
&gt; 
&gt;     We could make a new distribution bucket in BridgeDB that distributes
&gt; bridges through Moat without a CAPTCHA and have new versions of Tor
&gt; Browser pull from this bucket. We can watch and perform measurements in
&gt; places we know enumeration attempts have occurred in the past and see
&gt; whether these bridges are enumerated more quickly and more completely
&gt; than the old-school Moat bucket.

Hi Cecylia,

I understand that your Option 2 would remove all CAPTCHAs for all Tor
Browser users.

I don't know much about bridge distribution so my idea is most likely
flawed. But what about combining Option 1 and Option 2 by doing a bigger
experiment that would already remove the CAPTCHAs for a significant
amount of users:

Split the current CAPTCHA bridges 50/50 into 2 buckets:

- Bridges in the 1st bucket would be distributed without CAPTCHA.
- Bridges in the 2nd bucket would be distributed with a CAPTCHA.

New versions of Tor Browser could pick from either of the 2 buckets.
Maybe based on a silly metric like whether the 3rd part of the IP
address is odd or even to be consistent across a same local network,
or maybe something smarter.

You get the science while saving CAPTCHAs to 50% of users already and
not risking all your CAPTCHA bridges in the gamble. It might be easier
to measure how much CAPTCHAs really prevent enumeration by comparing
both buckets over the same period of time. All Tor Browsers remain the
same. The current UI could display or not display the CAPTCHAs when
requesting a bridge without a lot of change.

&gt; Option 3: Keep doing what we're doing but try to make the CAPTCHAs more
&gt; usable.
&gt; 
&gt;     This is the work we've had planned, but will only get us so far.

I'd keep Option 3 for if the experiment proves that CAPTCHAs are really
useful at preventing enumeration.

-- 
sajolida
Tails â€” https://tails.boum.org/
UX  · Fundraising  · Technical Writing


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210712203817</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2021-07-12 20:38:17-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Mon, Jul 12, 2021 at 03:09:02PM -0400, Nick Mathewson wrote:
&gt; On Mon, Jul 12, 2021 at 3:04 PM Ian Goldberg &lt;iang@uwaterloo.ca&gt; wrote:
&gt; &gt;
&gt; &gt; On Mon, Jul 12, 2021 at 12:01:47PM -0400, Nick Mathewson wrote:
&gt; &gt; &gt; Both parties know that they used the same verification string; if
&gt; &gt; &gt; they did not, they do not learn what the verification string was.
&gt; &gt; &gt; (This feature is required for HS handshakes.)
&gt; &gt;
&gt; &gt; I'm not sure the protocol you specify has this feature as written.  For
&gt; &gt; example, if the verification string has low entropy, the server could
&gt; &gt; brute-force the client's verification string (using the MAC to check its
&gt; &gt; guess).  This is unlike, say, OTR's SMP or a PAKE, in which each online
&gt; &gt; execution of the protocol allows the server just one guess.
&gt; &gt;
&gt; &gt; But perhaps you don't actually need the property in as strong a form as
&gt; &gt; you wrote it, since the HS handshake application has high-entropy
&gt; &gt; secrets?
&gt; 
&gt; Oh yes, you are right, of course.
&gt; 
&gt; Can you suggest a way to phrase this property that encompasses what
&gt; the protocol actually does provide?

Could I convince you to use a hash (domain-separated but not keyed) of
VER instead of ENCAP(VER)?  Then you could say that the protocol reveals
no more about VER than H_verstr(VER) does.  [Note: H_verstr is different
from H_verify.]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210713183447</emailId><senderName>Trevor Perrin</senderName><senderEmail>trevp@trevp.net</senderEmail><timestampReceived>2021-07-13 18:34:47-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

Hi Nick, you might look at the Noise framework:

http://noiseprotocol.org/noise.html

Noise has a naming scheme for "handshake patterns".  Ntor matches what
we call NK1.  Your new scheme I think matches NK (the 1 in NK1
indicates a "deferred" pattern where the DH operation that
authenticates the server is performed prior to the 2nd message rather
than the first).

NK1:
  &lt;- s
  ...
  -&gt; e
  &lt;- e, ee, es


(read as: initiator has pre-knowledge of server's static public key s;
initiator sends their ephemeral in first message; responder sends
their ephemeral in second message, then performs the two 2 DH
operations, hashing them together and using the result for encrypting
future data).

In NK, the ephemeral-static DH is performed earlier so that the first
message's handshake payload can be encrypted:

NK:
  &lt;- s
  ...
  -&gt; e, es
  &lt;- e, ee

You also wanted to add an (optional) pre-shared key, which Noise supports:

NKpsk0:
  &lt;- s
  ...
  -&gt; psk, e, es
  &lt;- e, ee


Some advantages of Noise are that you could reuse existing libraries
and Noise's growing body of security analysis.

Also, we're working on KEM extensions for post-quantum, signatures,
and other things, so Noise might make it easier to evolve the protocol
(eg NK1 vs NK vs NKpsk0).

Trevor

On Mon, Jul 12, 2021 at 9:02 AM Nick Mathewson &lt;nickm@torproject.org&gt; wrote:
&gt;
&gt; ```
&gt; Filename: 332-ntor-v3-with-extra-data.md
&gt; Title: Ntor protocol with extra data, version 3.
&gt; Author: Nick Mathewson
&gt; Created: 12 July 2021
&gt; Status: Open
&gt; ```
&gt;
&gt; # Overview
&gt;
&gt; The ntor handshake is our current protocol for circuit
&gt; establishment.
&gt;
&gt; So far we have two variants of the ntor handshake in use: the "ntor
&gt; v1" that we use for everyday circuit extension (see `tor-spec.txt`)
&gt; and the "hs-ntor" that we use for v3 onion service handshake (see
&gt; `rend-spec-v3.txt`).  This document defines a third version of ntor,
&gt; adapting the improvements from hs-ntor for use in regular circuit
&gt; establishment.
&gt;
&gt; These improvements include:
&gt;
&gt;  * Support for sending additional encrypted and authenticated
&gt;    protocol-setup handshake data as part of the ntor handshake.  (The
&gt;    information sent from the client to the relay does not receive
&gt;    forward secrecy.)
&gt;
&gt;  * Support for using an external shared secret that both parties must
&gt;    know in order to complete the handshake.  (In the HS handshake, this
&gt;    is the subcredential.  We don't use it for circuit extension, but in
&gt;    theory we could.)
&gt;
&gt;  * Providing a single specification that can, in the future, be used
&gt;    both for circuit extension _and_ HS introduction.
&gt;
&gt; # The improved protocol: an abstract view
&gt;
&gt; Given a client "C" that wants to construct a circuit to a
&gt; relay "S":
&gt;
&gt; The client knows:
&gt;   * B: a public "onion key" for S
&gt;   * ID: an identity for S, represented as a fixed-length
&gt;     byte string.
&gt;   * CM: a message that it wants to send to S as part of the
&gt;     handshake.
&gt;   * An optional "verification" string.
&gt;
&gt; The relay knows:
&gt;   * A set of [(b,B)...] "onion key" keypairs.  One of them is
&gt;     "current", the others are outdated, but still valid.
&gt;   * ID: Its own identity.
&gt;   * A function for computing a server message SM, based on a given
&gt;     client message.
&gt;   * An optional "verification" string. This must match the "verification"
&gt;     string from the client.
&gt;
&gt; Both parties have a strong source of randomness.
&gt;
&gt; Given this information, the client computes a "client handshake"
&gt; and sends it to the relay.
&gt;
&gt; The relay then uses its information plus the client handshake to see
&gt; if the incoming message is valid; if it is, then it computes a
&gt; "server handshake" to send in reply.
&gt;
&gt; The client processes the server handshake, and either succeeds or fails.
&gt;
&gt; At this point, the client and the relay both have access to:
&gt;   * CM (the message the client sent)
&gt;   * SM (the message the relay sent)
&gt;   * KS (a shared byte stream of arbitrary length, used to compute
&gt;     keys to be used elsewhere in the protocol).
&gt;
&gt; Additionally, the client knows that CM was sent _only_ to the relay
&gt; whose public onion key is B, and that KS is shared _only_ with that
&gt; relay.
&gt;
&gt; The relay does not know which client participated in the handshake,
&gt; but it does know that CM came from the same client that generated
&gt; the key X, and that SM and KS were shared _only_ with that client.
&gt;
&gt; Both parties know that CM, SM, and KS were shared correctly, or not
&gt; at all.
&gt;
&gt; Both parties know that they used the same verification string; if
&gt; they did not, they do not learn what the verification string was.
&gt; (This feature is required for HS handshakes.)
&gt;
&gt; # The handshake in detail
&gt;
&gt; ## Notation
&gt;
&gt; We use the following notation:
&gt;
&gt;   * `|` -- concatenation
&gt;   * `"..."` -- a byte string, with no terminating NUL.
&gt;   * `ENCAP(s)` -- an encapsulation function.  We define this
&gt;      as `htonll(len(s)) | s`.  (Note that `len(ENCAP(s)) = len(s) + 8`).
&gt;   * `PARTITION(s, n1, n2, n3, ...)` -- a function that partitions a
&gt;      bytestring `s` into chunks of length `n1`, `n2`, `n3`, and so
&gt;      on. Extra data is put into a final chunk.  If `s` is not long
&gt;      enough, the function fails.
&gt;
&gt; We require the following crypto operations:
&gt;
&gt;   * `KDF(s,t)` -- a tweakable key derivation function, returning a
&gt;      keystream of arbitrary length.
&gt;   * `H(s,t)` -- a tweakable hash function of output length
&gt;      `DIGEST_LEN`.
&gt;   * `MAC(k, msg, t)` -- a tweakable message-authentication-code function,
&gt;      of output length `MAC_LEN`.
&gt;   * `EXP(pk,sk)` -- our Diffie Hellman group operation, taking a
&gt;      public key of length `PUB_KEY_LEN`.
&gt;   * `KEYGEN()` -- our Diffie-Hellman keypair generation algorithm,
&gt;     returning a (secret-key,public-key) pair.
&gt;   * `ENC(k, m)` -- a stream cipher with key of length `ENC_KEY_LEN`.
&gt;     `DEC(k, m)` is its inverse.
&gt;
&gt; Parameters:
&gt;
&gt;   * `PROTOID` -- a short protocol identifier
&gt;   * `t_*` -- a set of "tweak" strings, used to derive distinct
&gt;     hashes from a single hash function.
&gt;   * `ID_LEN` -- the length of an identity key that uniquely identifies
&gt;     a relay.
&gt;
&gt; Given our cryptographic operations and a set of tweak strings, we
&gt; define:
&gt;
&gt; ```
&gt; H_foo(s) = H(s, t_foo)
&gt; MAC_foo(k, msg) = MAC(k, msg, t_foo)
&gt; KDF_foo(s) = KDF(s, t_foo)
&gt; ```
&gt;
&gt; See Appendix A.1 below for a set of instantiations for these operations
&gt; and constants.
&gt;
&gt; ## Client operation, phase 1
&gt;
&gt; The client knows:
&gt;     B, ID -- the onion key and ID of the relay it wants to use.
&gt;     CM -- the message that it wants to send as part of its
&gt;            handshake.
&gt;     VER -- a verification string.
&gt;
&gt; First, the client generates a single-use keypair:
&gt;
&gt;     x,X = KEYGEN()
&gt;
&gt; and computes:
&gt;
&gt;     Bx = EXP(B,x)
&gt;     secret_input_phase1 = Bx | ID | X | B | PROTOID | ENCAP(VER)
&gt;     phase1_keys = KDF_msgkdf(secret_input_phase1)
&gt;     (ENC_K1, MAC_K1) = PARTITION(phase1_keys, ENC_KEY_LEN, MAC_KEY_LEN)
&gt;
&gt;     encrypted_msg = ENC(ENC_K1, CM)
&gt;     msg_mac = MAC_msgmac(MAC_K1, ID | B | X | encrypted_msg)
&gt;
&gt; and sends:
&gt;
&gt;     NODEID      ID               [ID_LEN bytes]
&gt;     KEYID       B                [PUB_KEY_LEN bytes]
&gt;     CLIENT_PK   X                [PUB_KEY_LEN bytes]
&gt;     MSG         encrypted_msg    [len(CM) bytes]
&gt;     MAC         msg_mac          [last MAC_LEN bytes of message]
&gt;
&gt; The client remembers x, X, B, ID, Bx, and msg_mac.
&gt;
&gt; ## Server operation
&gt;
&gt; The relay checks whether NODEID is as expected, and looks up
&gt; the (b,B) keypair corresponding to KEYID.  If the keypair is
&gt; missing or the NODEID is wrong, the handshake fails.
&gt;
&gt; Now the relay uses `X=CLIENT_PK` to compute:
&gt;
&gt;     Xb = EXP(X,b)
&gt;     secret_input_phase1 = Xb | ID | X | B | PROTOID | ENCAP(VER)
&gt;     phase1_keys = KDF_msgkdf(secret_input_phase1)
&gt;     (ENC_K1, MAC_K1) = PARTITION(phase1_keys, ENC_KEY_LEN, MAC_KEY_LEN)
&gt;
&gt;     expected_mac = MAC_msgmac(MAC_K1, ID | B | X | MSG)
&gt;
&gt; If `expected_mac` is not `MAC`, the handshake fails.  Otherwise
&gt; the relay computes `CM` as:
&gt;
&gt;     CM = DEC(MSG, ENC_K1)
&gt;
&gt; The relay then checks whether `CM` is well-formed, and in response
&gt; composes `SM`, the reply that it wants to send as part of the
&gt; handshake. It then generates a new ephemeral keypair:
&gt;
&gt;     y,Y = KEYGEN()
&gt;
&gt; and computes the rest of the handshake:
&gt;
&gt;     Xy = EXP(X,y)
&gt;     secret_input = Xy | Xb | ID | B | X | Y | PROTOID | ENCAP(VER)
&gt;     ntor_key_seed = H_key_seed(secret_input)
&gt;     verify = H_verify(secret_input)
&gt;
&gt;     RAW_KEYSTREAM = KDF_final(ntor_key_seed)
&gt;     (ENC_KEY, KEYSTREAM) = PARTITION(RAW_KEYSTREAM, ENC_KEY_LKEN, ...)
&gt;
&gt;     encrypted_msg = ENC(ENC_KEY, SM)
&gt;
&gt;     auth_input = verify | ID | B | Y | X | MAC | ENCAP(encrypted_msg) |
&gt;         PROTOID | "Server"
&gt;     AUTH = H_auth(auth_input)
&gt;
&gt; The relay then sends:
&gt;
&gt;     Y          Y              [PUB_KEY_LEN bytes]
&gt;     AUTH       AUTH           [DIGEST_LEN bytes]
&gt;     MSG        encrypted_msg  [len(SM) bytes, up to end of the message]
&gt;
&gt; The relay uses KEYSTREAM to generate the shared secrets for the
&gt; newly created circuit.
&gt;
&gt; ## Client operation, phase 2
&gt;
&gt; The client computes:
&gt;
&gt;     Yx = EXP(Y, x)
&gt;     secret_input = Yx | Bx | ID | B | X | Y | PROTOID | ENCAP(VER)
&gt;     ntor_key_seed = H_key_seed(secret_input)
&gt;     verify = H_verify(secret_input)
&gt;
&gt;     auth_input = verify | ID | B | Y | X | MAC | ENCAP(MSG) |
&gt;         PROTOID | "Server"
&gt;     AUTH_expected = H_auth(auth_input)
&gt;
&gt; If AUTH_expected is equal to AUTH, then the handshake has
&gt; succeeded.  The client can then calculate:
&gt;
&gt;     RAW_KEYSTREAM = KDF_final(ntor_key_seed)
&gt;     (ENC_KEY, KEYSTREAM) = PARTITION(RAW_KEYSTREAM, ENC_KEY_LKEN, ...)
&gt;
&gt;     SM = DEC(ENC_KEY, MSG)
&gt;
&gt; SM is the message from the relay, and the client uses KEYSTREAM to
&gt; generate the shared secrets for the newly created circuit.
&gt;
&gt; # Security notes
&gt;
&gt; Whenever comparing bytestrings, implementations SHOULD use
&gt; constant-time comparison function to avoid side-channel attacks.
&gt;
&gt; To avoid small-subgroup attacks against the Diffie-Hellman function,
&gt; implementations SHOULD either:
&gt;
&gt;    * Make sure that all incoming group members are in fact in the DH
&gt;      group.
&gt;    * Validate all outputs from the EXP function to make sure that
&gt;      they are not degenerate.
&gt;
&gt;
&gt; # Notes on usage
&gt;
&gt; We don't specify what should actually be done with the resulting
&gt; keystreams; that depends on the usage for which this handshake is
&gt; employed.  Typically, they'll be divided up into a series of tags
&gt; and symmetric keys.
&gt;
&gt; The keystreams generated here are (conceptually) unlimited.  In
&gt; practice, the usage will determine the amount of key material
&gt; actually needed: that's the amount that clients and relays will
&gt; actually generate.
&gt;
&gt; The PROTOID parameter should be changed not only if the
&gt; cryptographic operations change here, but also if the usage changes
&gt; at all, or if the meaning of any parameters changes.  (For example,
&gt; if the encoding of CM and SM changed, or if ID were a different
&gt; length or represented a different type of key, then we should start
&gt; using a new PROTOID.)
&gt;
&gt;
&gt; # A.1 Instantiation
&gt;
&gt; Here are a set of functions based on SHA3, SHAKE128, Curve25519, and
&gt; AES256:
&gt;
&gt; ```
&gt; H(s, t) = SHA3_256(ENCAP(t) | s)
&gt; MAC(k, msg, t) = SHA3_256(ENCAP(t) | ENCAP(k) | s)
&gt; KDF(s, t) = SHAKE_128(ENCAP(t) | s)
&gt; ENC(k, m) = AES_256_CTR(k, m)
&gt;
&gt; EXP(pk,sk), KEYGEN: defined as in curve25519
&gt;
&gt; DIGEST_LEN = MAC_LEN = ENC_KEY_LEN = PUB_KEY_LEN = 32
&gt;
&gt; ID_LEN = 32  (representing an ed25519 identity key)
&gt; ```
&gt;
&gt; Notes on selected operations: SHA3 can be pretty slow, and AES256 is
&gt; likely overkill.  I'm choosing them anyway because they are what we
&gt; use in hs-ntor, and in my preliminary experiments they don't account
&gt; for even 1% of the time spent on this handshake.
&gt;
&gt; ```
&gt; t_msgkdf = PROTOID | ":kdf_phase1"
&gt; t_msgmac = PROTOID | ":msg_mac"
&gt; t_key_seed = PROTOID | ":key_seed"
&gt; t_verify = PROTOID | ":verify"
&gt; t_final = PROTOID | ":kdf_final"
&gt; t_auth = PROTOID | ":auth_final"
&gt; ```
&gt;
&gt; # A.2 Encoding for use with Tor circuit extension
&gt;
&gt; Here we give a concrete instantiation of ntor-v3 for use with
&gt; circuit extension in Tor, and the parameters in A.1 above.
&gt;
&gt; If in use, this is a new CREATE2 type.  Clients should not use it
&gt; unless the relay advertises support by including an appropriate
&gt; version of the `Relay=X` subprotocol in its protocols list.
&gt;
&gt; When the encoding and methods of this section, along with the
&gt; instantiations from the previous section, are in use, we specify:
&gt;
&gt;     PROTOID = "ntor3-curve25519-sha3_256-1"
&gt;
&gt; The key material is extracted as follows, unless modified by the
&gt; handshake (see below).  See tor-spec.txt for more info on the
&gt; specific values:
&gt;
&gt;     Df    Digest authentication, forwards  [20 bytes]
&gt;     Db    Digest authentication, backwards [20 bytes]
&gt;     Kf    Encryption key, forwards         [16 bytes]
&gt;     Kb    Encryption key, backwards        [16 bytes]
&gt;     KH    Onion service nonce              [20 bytes]
&gt;
&gt; We use the following meta-encoding for the contents of client and
&gt; server messages.
&gt;
&gt;     [Any number of times]:
&gt;        TYPE     [one byte]
&gt;        LEN      [one byte]
&gt;        BODY     [LEN bytes]
&gt;
&gt; We do not specify specific TYPE semantics here; we leave those for
&gt; other proposals.
&gt;
&gt; All parties MUST reject messages that are not well-formed per the
&gt; rules above.
&gt;
&gt; To avoid partitioning, clients MUST reject messages with TYPEs that
&gt; they do not recognize.  (Therefore, whenever we specify a new server
&gt; message TYPE, we must say that it can only be included if the client
&gt; signals that it understands it.)
&gt;
&gt; # A.3 How much space is available?
&gt;
&gt; We start with a 498-byte payload in each relay cell.
&gt;
&gt; The header of the EXTEND2 cell, including link specifiers and other
&gt; headers, comes to 89 bytes.
&gt;
&gt; The client handshake requires 128 bytes (excluding CM).
&gt;
&gt; That leaves 281 bytes, "which should be plenty".
&gt;
&gt; # X.1 Negotiating proposal-324 circuit windows
&gt;
&gt; (We should move this section into prop324 when this proposal is
&gt; finished.)
&gt;
&gt; We define a type value, CIRCWINDOW_INC.
&gt;
&gt; We define a triplet of consensus parameters: `circwindow_inc_min`,
&gt; `cincwindow_inc_max`, and `circwindow_inc_dflt`.  These all have
&gt; range (1,65535).
&gt;
&gt; When the authority operators want to experiment with different
&gt; values for `circwindow_inc_dflt`, they set `circwindow_inc_min` and
&gt; `circwindow_inc_max` to the range in which they want to experiment,
&gt; making sure that the existing `circwindow_inc_dflt` is within that
&gt; range.
&gt;
&gt; vWhen a client sees that a relay supports the ntor3 handshake type
&gt; (subprotocol `Relay=X`), and also supports the flow control
&gt; algorithms of proposal 324 (subprotocol `FlowCtrl=X`), then the
&gt; client sends a message, with type `CIRCWINDOW_INC`, containing a
&gt; two-byte integer equal to `circwindow_inc_dflt`.
&gt;
&gt; The relay rejects the message if the value given is outside of the
&gt; [`circwindow_inc_min`, `circwindow_inc_max`] range.  Otherwise, it
&gt; accepts it, and replies with the same message that the client sent.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210716123141</emailId><senderName>Ian Goldberg</senderName><senderEmail>iang@uwaterloo.ca</senderEmail><timestampReceived>2021-07-16 12:31:41-0400</timestampReceived><subject>Re: [tor-dev] Proposal 332: Ntor protocol with extra data, version 3.</subject><body>

On Tue, Jul 13, 2021 at 11:34:47AM -0700, Trevor Perrin wrote:
&gt; You also wanted to add an (optional) pre-shared key, which Noise supports:
&gt; 
&gt; NKpsk0:
&gt;   &lt;- s
&gt;   ...
&gt;   -&gt; psk, e, es
&gt;   &lt;- e, ee

Out of curiosity, Trevor, what properties does this Noise protocol
provide for low-entropy psk?

Nick, what are the settings in Tor (if any) in which low-entropy psk
will come up?


But this post from Trevor also made me realize a bigger issue with the
protocol Nick proposed:

If you want the protocol to work with Walking Onions, it needs to be
*post-specified peer*.  That is, contrary to:

&gt; The client knows:
&gt;   * B: a public "onion key" for S

The client will in fact _not_ know B in advance in a Walking Onions
setting, but rather will learn it at the end of the handshake.  The
protocol Nick specified does in fact use B in the first message, unlike
the current ntor handshake, which just sends KEYID(B) in the first flow,
but it's not part of the math, or indeed as far as I can see, used for
anything at all in Section 5.1.4 of tor-spec.txt, and so can be easily
removed (and replaced with B being sent by the server) for Walking
Onions.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210613120050</emailId><senderName>Georg Koppen</senderName><senderEmail>gk@torproject.org</senderEmail><timestampReceived>2021-06-13 12:00:50-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: "Res tokens: Anonymous Credentials for Onion Service DoS Resilience"</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


George Kadianakis:
&gt; Hello all,
&gt; 
&gt; after lots of investigation on anonymous credentials, we are glad to
&gt; present you with a draft of the onion services anti-DoS proposal using
&gt; tokens.

Thanks! I finally managed to read through and think about the proposal
(but note: I've not read proposal 327 yet, so I hope my remarks are not
too silly were that proposal comes into play). I have some comments
inline but did not tackle any XXX parts yet (and I'll provide a torspec
branch later for fixing the typos I found).

&gt; While the basic idea of the proposal should remain reasonably solid,
&gt; there are various XXX sprinkled around the proposal and some of them
&gt; definitely need to be addressed before the proposal becomes truly
&gt; usable.
&gt; 
&gt; We are particularly looking forward to feedback about:
&gt; - Token issuance services
&gt; - The anonymous credential scheme chosen
&gt; - The XXXs and design decisions of the proposal
&gt; 
&gt; Hope you have a pleasant read!
&gt; 
&gt; ---
&gt; 
&gt; ```

[snip]

&gt; ## 3.3. Other security considerations
&gt; 
&gt;   Apart from the above properties we also want:
&gt; 
&gt;   - Double spending protection: We don't want Malory to be able to double spend
&gt;       her tokens in various onion services thereby amplifying her attack. For
&gt;       this reason our tokens are not global, and can only be redeemed at a
&gt;       specific destination onion service.
&gt; 
&gt;   - Metadata: We want to encode metadata/attributes in the tokens. In
&gt;       particular, we want to encode the destination onion service and an
&gt;       expiration date. For more information see section [DEST_DIGEST]. For
&gt;       blind RSA tokens this is usually done using "partially blind signatures"
&gt;       but to keep it simple we instead encode the destination directly in the
&gt;       message to be blind-signed and the expiration date using a set of
&gt;       rotating signing keys.
&gt; 
&gt;   - One-show: There are anonymous credential schemes with multi-show support
&gt;       where one token can be used multiple times in an unlinkable
&gt;       fashion. However, that might allow an adversary to use a single token to
&gt;       launch a DoS attack, since revocation solutions are complex and
&gt;       inefficient in anonymous credentials. For this reason, in this work we
&gt;       use one-show tokens that can only be redeemed once. That takes care of
&gt;       the revocation problem but it means that a client will have to get more
&gt;       tokens periodically.

While reading I had the feeling we have the one-show property because we
want to (easily) prevent double-spending. Thus, can't we just fold that
part into the "Double spending protection" one? As it stands I found it
confusing/redundant.

[snip]
&gt; ## 4.2. Onion service signals ongoing DoS attack

Let me look at that from a slightly different angle. What about
something like

## 4.2. Onion service signals DoS attack protection

? That is, would we be okay if onion services used the mechanism in this
proposal for *preventing* DoS attacks(, too,) in the first place? Worst
case would be every onion service has the anti-DoS security feature on
24/7 but there are other scenarios conceivable that point in a similar
direction (e.g. anti-DoS protection only on on weekends or just at
particular times).

Looking at the proposal for answering my question I am not sure. It
seems you indicate in section 6 that this would be strongly undesired at
least in cases where manual work needs to be done:

"""
In the cases where manual work is needed by the user (e.g. solving a
CAPTCHA) it's ideal if the work is presented to the user right before
visiting the destination and *only* if it's *absolutely* required.
[emphasis mine, GeKo]
"""

But there are other token issuers with different constraints conceivable
(as you mention in the proposal itself).

The reason why I bring this up is two-fold:

1. We had been thinking about that issue back then when we were
evaluating Prviacy Pass for an inclusion into Tor Browser and as a
solution to/against Cloudflare's CAPTCHAs. One of the biggest arguments
against doing that was that we were afraid of enabling a mechanism that
would boil down in the longer run to requiring a kind of "driver's
license" (you need to solve a CAPTCHA first) to just reading news on the
Internet anywhere. Even though that may come anyway at some point in the
future we thought the Tor Project should not be at the forefront on that
trend essentially pushing it with our "seal of acceptance".

While I think that both contexts (the Privacy Pass - website and the Res
token - onion service one) are sufficiently different that our concerns
from back then do not apply 1:1, I do wonder how the story in the onion
services one looks like...

2. Why would onion service providers even do such a thing as using the
tokens outside of an ongoing DoS attack? Well, nobody wants to get hit
by an attack in the first place if they can easily *prevent* it. Tokens
would offer that (likely even for more attacks than just the intended
DoS). In particular, the situation of an onion service provider is the
classical one where they alone doing X is not too problematic but if all
of them were doing X it could be. I can likely see a future where onion
service guides start with "And if you are under DoS attack require
tokens" but soon turn, subtly, into "And if you want to prevent DoS
attacks require tokens" and finally "And for your onion service security
require tokens". Who as an onion service provider does not want all of
those things? (In particular if you imagine an adversary who wants to
stifle onion service adoption by trying to bully onion services into
enabling token usage 24/7 thus rendering the UX for users abysmal.)

So, again: are we okay with tokens used differently than we expect? If
not, how do we prevent that?

&gt;   When an onion service is under DoS attack it adds the following line in the
&gt;   "encrypted" (inner) part of the v3 descriptor as a way to signal to its
&gt;   clients that tokens are required for gaining access:
&gt; 
&gt;     "token-required" SP token-type SP issuer-list NL
&gt; 
&gt;     [At most once]
&gt; 
&gt;     token-type: Is the type of token supported ("res" for this proposal)
&gt;     issuer: A comma separated list of issuers which are supported by this onion service
&gt; 
&gt; ## 4.3. Token issuance
&gt; 
&gt;   When Alice visits an onion service with an active "token-required" line in
&gt;   its descriptor it checks whether there are any tokens available for this

Maybe better: "any not-yet expired tokens"? If I understood the proposal
correctly then the expiry check should be possible at that point and it
would potentially save Alice some token generation. Or maybe the token
store is taking care of that part where it keeps track of the expiration
and only keeps the unexpired ones?

&gt;   onion service in its token store. If not, it needs to acquire some and hence
&gt;   the token issuance protocol commences.

[snip]

&gt; ## 5.1. CAPTCHA token issuer
&gt; 
&gt;   A use case resembling the setup of Cloudflare's PrivacyPass would be to have
&gt;   a CAPTCHA service that issues tokens after a successful CAPTCHA solution.
&gt; 
&gt;   Tor Project, Inc runs https://ctokens.torproject.org which serves hCaptcha
&gt;   CAPTCHAs. When the user solves a CAPTCHA the server gives back a list of
&gt;   tokens. The amount of tokens rewarded for each solution can be tuned based on
&gt;   abuse level.

How does the abuse level come in? Is that just something based on users
over and over again requesting tokens? Or is that a reaction to tokens
involved in (DoS) attacks? Or...?

[snip]

&gt; ## 8.1. Using Res tokens on Exit relays
&gt; 
&gt;   There are more scenarios within Tor that could benefit from Res tokens
&gt;   however we didn't expand on those use cases to keep the proposal short.  In
&gt;   the future, we might want to split this document into two proposals: one
&gt;   proposal that specifies the token scheme, and another that specifies how to
&gt;   use it in the context of onion servicves, so that we can then write more
&gt;   proposals that use the token scheme as a primitive.

I think splitting the proposals up would be really useful. One challenge
might be, though, to write the token scheme one in a way that it is
easily compatible with tokens for, say, onion services and exit nodes,
given that the latter usage might have quite different requirements (you
mention some points here in 8.2). I think it's worth a try anyway.

&gt;   An extremely relevant use case would be to use Res tokens as a way to protect
&gt;   and improve the IP reputation of Exit relays. We can introduce an exit pool
&gt;   that requires tokens in exchange for circuit streams. The idea is that exits
&gt;   that require tokens will see less abuse, and will not have low scores in the
&gt;   various IP address reputation systems that now govern who gets access to
&gt;   websites and web services on the public Internet. We hope that this way we
&gt;   will see  less websites blocking Tor.

There is much to say about using tokens in that context, but I guess
this should be done in a different proposal/mail, so I'll omit a bunch
of points for now. :) One thing I found interesting, though, while
thinking about incentives for relay operators was that tokens at exit
relays might actually alone be an incentive for more operators running
exit relays. Given the hassle for relay operators involved in dealing
with abuse and how that affects willingness to run exit nodes I suspect
tokens at exits could help with that problem, too.

[snip]

Georg


["OpenPGP_signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210627210157</emailId><senderName>David Willis</senderName><senderEmail>davidwills76@protonmail.com</senderEmail><timestampReceived>2021-06-27 21:01:57-0400</timestampReceived><subject>[tor-dev] Build HS Circuit</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Hi

I'm doing a research project into onions and I'm trying to add a control port command \
to build a HS circuit. I see EXTENDCIRC can create normal circs, but how would I \
modify it a to build a HS circuit? Assuming I've already HSFETCHed it.

I don't wait to initiate a socks request, just build the circuit and wait.

It isn't quite clear to me where in the code base onion circuits are built or how, \
and how to initiate one. Would be grateful even for high-level instructions.

Thanks
David
University of Singapore

Sent with [ProtonMail](https://protonmail.com/) Secure Email.


[Attachment #5 (text/html)]

&lt;div&gt;Hi&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;I'm doing a research project into onions and I'm trying to \
add a control port command to build a HS circuit.  I see EXTENDCIRC can create \
normal circs, but how would I modify it a to build a HS circuit?  Assuming I've \
already HSFETCHed it.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I don't wait to initiate a socks \
request, just build the circuit and wait.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It isn't quite \
clear to me where in the code base onion circuits are built or how, and how to \
initiate one.  Would be grateful even for high-level \
instructions.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks&lt;br&gt;&lt;/div&gt;&lt;div&gt;David&lt;br&gt;&lt;/div&gt;&lt;div&gt;University \
of Singapore&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div class="protonmail_signature_block"&gt;&lt;div \
class="protonmail_signature_block-user protonmail_signature_block-empty"&gt;&lt;/div&gt;&lt;div \
class="protonmail_signature_block-proton"&gt;Sent with &lt;a href="https://protonmail.com/" \
target="_blank"&gt;ProtonMail&lt;/a&gt; Secure Email.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210628112535</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-06-28 11:25:35-0400</timestampReceived><subject>Re: [tor-dev] Scalability or Onionbalance for v3 ephemeral/ADD_ONION services</subject><body>

Holmes Wilson &lt;h@zbay.llc&gt; writes:

&gt; Would this return a list of currently-online onion addresses in possession
&gt; of the frontend address key?
&gt;
&gt; Or would it just route traffic to one of those addresses invisibly?
&gt;

Hello Holmes,

I think the feature that Chad was asking for would just allow them to
enable OnionBalance through the control port (since setting
OnionbalanceMasterKey is a necessary step of configuring onionbalance
backends).

&gt; For our application (a messaging app) it would be super useful to get the
&gt; full list of known online (or recently seen online) onion addresses in
&gt; possession of some frontend key. This would let us use onionbalance for
&gt; peer discovery instead of blindly trying the set of all known peers, which
&gt; won't work well for large groups / large numbers of peers.
&gt;

Hmm, can you please give us some more details on what you are looking
for? What is peer discovery in the above context, and what do you mean
with "full list of ... onion addresses in possession of some frontend
key"? I'm asking because the frontend key of onionbalance is also the
onion address that users should access.

Cheers!


&gt; I'd be interested in working with others on a spec for this!
&gt;
&gt; On Mon, Jun 14, 2021 at 6:25 AM George Kadianakis &lt;desnacked@riseup.net&gt;
&gt; wrote:
&gt;
&gt;&gt; Chad Retz &lt;chad.retz@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; A quick glance at the code shows that ADD_ONION (i.e. "ephemeral"
&gt;&gt; &gt; onion services) doesn't support setting an Onionbalance
&gt;&gt; &gt; frontend/master onion address (specifically
&gt;&gt; &gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/32709 doesn't seem
&gt;&gt; &gt; to have a control-side analogue). Would a feature request for adding a
&gt;&gt; &gt; `*(SP "OnionbalanceMasterKey=" OBKey)` (or "OBMasterKey" or whatever)
&gt;&gt; &gt; to ADD_ONION be reasonable? If so, just add in Gitlab?
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt; Hell Ched,
&gt;&gt;
&gt;&gt; that's indeed something that is missing and a reasonable feature
&gt;&gt; request. A spec/code patch would be particularly welcome ;)
&gt;&gt;
&gt;&gt; &gt; Also curious alternative scalability and load balancing options for
&gt;&gt; &gt; ephemeral v3 onion services. I have read
&gt;&gt; &gt;
&gt;&gt; https://www.benthamsgaze.org/wp-content/uploads/2015/11/sucu-torscaling.pdf
&gt;&gt; &gt; but unsure if anything more recent has been written. Beyond that and
&gt;&gt; &gt; Onionbalance, any other interesting approaches I could employ
&gt;&gt; &gt; (assuming I can dev anything from a control port pov, but am wanting
&gt;&gt; &gt; to work w/ an unmodified Tor binary)?
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt; Another complementary approach is to split the 'introduction' and
&gt;&gt; 'rendezvous' functionalities to different hosts:
&gt;&gt;
&gt;&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/main/proposals/255-hs-load-balancing.txt
&gt;&gt; However it hasn't been implemented yet...
&gt;&gt;
&gt;&gt; Cheers!
&gt;&gt; _______________________________________________
&gt;&gt; tor-dev mailing list
&gt;&gt; tor-dev@lists.torproject.org
&gt;&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210504123049</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-05-04 12:30:49-0400</timestampReceived><subject>Re: [tor-dev] ClientAuthV3 for v3 onions via Tor controller is accepted by ADD_ONION but seems to ge</subject><body>

[Attachment #2 (multipart/signed)]


On 04 May (06:59:39), Miguel Jacq wrote:
&gt; Hello again, just to add some clarification to what I realise is a confusing output \
&gt; below: 
&gt; On Mon, May 03, 2021 at 04:38:07PM +1000, Miguel Jacq wrote:
&gt; &gt; ```
&gt; &gt; user@onionshare:~$ sudo telnet localhost 9051
&gt; &gt; Trying ::1...
&gt; &gt; Trying 127.0.0.1...
&gt; &gt; Connected to localhost.
&gt; &gt; Escape character is '^]'.
&gt; &gt; authenticate ""
&gt; &gt; 250 OK
&gt; &gt; ADD_ONION ED25519-V3:MNkxu0oI0CX6Oq1AEroRGSAiqXurEbzBdraDKJB1pkNkl9hNCr+bagdAg7gA4F3M/FrF7BHBdh5zdvkHB7oO4w== \
&gt; &gt; ClientAuthV3=FGTORMIDKR7T2PR632HSHLWA4G6HF5TCWSGMHDUU4LWBEFTAVYQQ Flags=V3Auth \
&gt; &gt; Port=80,9735 250-ServiceID=rujvluxdgiibem3odopgkgiiajgtwfbdgkuqfyydhl5qupotpwyxjaid
&gt; &gt;  250-ClientAuthV3=AUEFTXH34ZVRXIIVOK5G7XLHTUXGVRLLXG7DG3NKJLRCVSEEHQDQ
&gt; &gt; 250 OK
&gt; &gt; ```
&gt; 
&gt; The public key is different in the request and response here, that's my copy-paste \
&gt; fail.. I had 'lost' the original private key and wanted to provide a valid pair for \
&gt; someone to troubleshoot with. As a result I amended my output here to show the new \
&gt; public key being sent in the ADD_ONION, but forgot to update it in the returned \
&gt; response from my earlier attempt. Sorry if it added confusion. 
&gt; The problem still stands that the ClientAuthV3 key is accepted by ADD_ONION in the \
&gt; nightly/alpha Tor, but it doesn't then seem to be enforced when viewing the onion \
&gt; service.. unless I'm doing something wrong. 
&gt; Appreciate any help, cheers!

Hi!

I've created https://gitlab.torproject.org/tpo/core/tor/-/issues/40378 to
track this down.

Thanks a lot for the detailed report!
David

-- 
NQlJcF99RlKvTqgt52eFZXmY4kBQuGdSZNERmVsg/3E=


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210506061912</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-05-06 06:19:12-0400</timestampReceived><subject>Re: [tor-dev] What's the best way to learn about critical updates to Tor?</subject><body>

On Wed, May 05, 2021 at 06:39:11PM -0400, Holmes Wilson wrote:
&gt; For the messaging app we???re building on Tor (not Tor browser) what???s the best \
&gt; way for us to be alerted when there are critical updates to Tor, so that we can \
&gt; prepare a new release as quickly as possible?

Signing up to the tor-packagers@ list is a pretty good choice:
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-packagers

Sometimes there are security fixes that come out suddenly, or that
we keep the details of quiet until the release:
https://gitlab.torproject.org/tpo/core/team/-/wikis/NetworkTeam/SecurityPolicy
https://gitlab.torproject.org/tpo/core/team/-/wikis/home

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210506161558</emailId><senderName>David Fifield</senderName><senderEmail>david@bamsoftware.com</senderEmail><timestampReceived>2021-05-06 16:15:58-0400</timestampReceived><subject>Re: [tor-dev] Uptime stats for "Tor user can access an otherwise-functional hidden service"?</subject><body>

On Wed, May 05, 2021 at 03:27:23PM -0400, Holmes Wilson wrote:
&gt; 3. Is there some incident log somewhere of problems that affected
&gt; onion services network wide that includes how long these problems
&gt; persisted for? (I don't see any onion service outage notes in this
&gt; document, though I seem to remember there was an issue a few months
&gt; back? https://metrics.torproject.org/news.html)

There's a small number of onion-related events at
https://gitlab.torproject.org/tpo/metrics/timeline
(search for "onion".)

Metrics news.html takes its input from the above timeline, but news.html
is currently out of sync, since before the January incident:
https://gitlab.torproject.org/tpo/metrics/timeline/-/issues/4
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210516031107</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-05-16 03:11:07-0400</timestampReceived><subject>Re: [tor-dev] descriptor sync finished event after disabling UseMicrodescriptors (stem)</subject><body>

On Sat, May 15, 2021 at 10:04:28AM +0200, nusenu wrote:
&gt; thanks for your reply and confirming that there is no event for this,
&gt; so the best option is to make a simple loop and test every few seconds if the \
&gt; download is completed I guess.

What are you actually trying to do?

I ask because Tor will function just fine even when you don't have every
single descriptor, and that's good because there are plenty of situations
where you miss a few (e.g. because your dir cache doesn't have them)
and it takes a while to get them.

So this notion of "the download is completed" is more ambiguous than
you might hope.

That said, if you want to know about progress of fetching descriptors once
you've turned off UseMicrodescriptors, that's exactly what the NEWDESC
event is for. On the other hand, if you are wanting to track progress
of new microdescriptor fetches once you've turned UseMicrodescriptors
back on, I think your best bet might be to track STREAM events, since
each dir fetch is a stream internally -- but either way you're going to
need to keep a bunch of state on your side, about which descriptors you
don't have yet, which ones have a current fetch going, etc. Which comes
back to "what are you actually trying to do." :)

&gt; &gt; &gt; I also noticed that fetching takes significantly longer when microdescriptors \
&gt; &gt; &gt; are disabled temporarily when compared to  adding 
&gt; &gt; &gt; UseMicrodescriptors 0 
&gt; &gt; &gt; to the torrc file persistently and restarting the tor client.
&gt; &gt; 
&gt; &gt; Maybe simply because server descriptors are much larger than microdesc?
&gt; 
&gt; In both cases we fetch the same kind of descriptors.
&gt; 
&gt; 1) torrc: UseMicrodescriptors 0 -&gt; start tor -&gt; fast to complete descriptor \
&gt; fetching 
&gt; 2) no torrc change -&gt; start tor -&gt;  controller.set_conf('UseMicrodescriptors', '0') \
&gt; -&gt; slow  
&gt; Maybe (2) is slower because tor does not start the download directly after \
&gt; set_conf('UseMicrodescriptors', '0') is received.

When you turn off UseMicrodescriptors, that means Tor needs to fetch a
vanilla-flavored (non-microdescriptor-flavored) networkstatus consensus
document, before it can know which descriptors it ought to ask for next.

Tor has various internal events that check to see if it has all the
directory info it wants, and that launch fetches of anything that's
missing. Probably the delay you're seeing is waiting until the next one
of those events triggers. You could send Tor a hup signal (or on the
control port, "signal hup") to encourage it to reevaluate all the dir
info it's missing.

For my various network health scanners, I tend to set
"fetchuselessdescriptors 1" so I maintain both flavors of consensuses
and descriptors by default.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210516213628</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-05-16 21:36:28-0400</timestampReceived><subject>Re: [tor-dev] Consensus network status fetch</subject><body>

On Sun, May 16, 2021 at 06:05:59PM +0000, sysmanager7 wrote:
&gt; crotab -l root returns 0
&gt; crontab -l user returns 0

Modern cron jobs don't just live in the crontab. See also your /etc/cron*
directories, which is where various packages might put cron things.

For example, in my case I have an /etc/cron.daily/logrotate file (placed
by my logrotate package) and also I have an /etc/logrotate.d/tor file
(placed by my tor package).

&gt;    00:00:05 [NOTICE] Read configuration file "/etc/tor/torrc".
&gt;  x 00:00:05 [NOTICE] Read configuration file "/usr/share/tor/tor-service-defaults-torrc".
&gt;  x 00:00:05 [NOTICE] Received reload signal (hup). Reloading config and resetting internal state.
&gt; 
&gt;  What happens after the signal hup is my band settings are changed from 2/4 MBs to 112/120MBs. This
&gt;  usually happens at 1/2 am so the relay operates at those settings for a solid eight hours. I am paying
&gt;  for this, when the above happens, it gets expensive! Which is why this has to stop.

Switching to other config values after a HUP makes me think you are
configuring your Tor in some way other than editing /etc/tor/torrc.

Maybe you're doing your config changes via nyx, or some other transient
way, rather than by editing the torrc file?

Since this is about running a relay, you also might get better help
if you switch to the tor-relays@ list:
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-relays

Hope this helps,
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210524234531</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2021-05-24 23:45:31-0400</timestampReceived><subject>Re: [tor-dev] GSoC 2021 - Alexa Top Sites Captcha and Tor Block Monitoring</subject><body>

&gt;&gt; https://gitlab.torproject.org/woswos/CAPTCHA-Monitor/-/wikis/GSoC-2021
&gt;&gt; tpo/community/support/#40013
&gt;
&gt; https://trac.torproject.org/projects/tor/wiki/org/projects/DontBlockMe
&gt; https://trac.torproject.org/projects/tor/wiki/org/doc/ListOfServicesBlockingTor

Beyond talk (and dev) there was tor-access, though it
seemed more on tokenizing/tracking out permissive rights
granting structures only upon tor/vpn users, rather than the
services side investing into some DBM suggested methods
whereby both clearnet and tor/vpn users would have and
enjoy same class of equal rights and usage models, or on
developing/promulgating a rights based concept to the world.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210525132131</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2021-05-25 13:21:31-0400</timestampReceived><subject>[tor-dev] Renaming the primary branch of tor.git</subject><body>

Hello!

As of today, the primary development branch of tor.git (the Git
repository containing the source code of Tor) is now named 'main'. If
you use tor.git in your tools, where you refer to the branch names, you
probably want to change that to 'main' right away, otherwise your tools
may break.

All existing Gitlab MR's should have been updated to target the new
primary branch name, but contributors should make sure their local
checkouts are tracking main now for updates.

Tor.git maintainers should re-run the usual scripts and make sure their
work tree setup uses 'main'.

All the best,
Alex.

-- 
Alexander Færøy
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210408134236</emailId><senderName>axel simon</senderName><senderEmail>axel+tor@axelsimon.net</senderEmail><timestampReceived>2021-04-08 13:42:36-0400</timestampReceived><subject>[tor-dev] sigstore for improving verification of downloads?</subject><body>

Hello all,

I've been a Tor user for a long time, have helped a bit with translation at=
 times, and been working on issues related to freedom and the Internet for =
a while (as part of La Quadrature du Net), but i'm writing today with my wo=
rk hat on, as a member of the security team at Red Hat's office of the CTO.

We recently announced a new project called sigstore [1], which could be sum=
marised as "Let's Encrypt, but for software provenance and code signing".

If you want to read other people explain it better than me, i found these t=
wo articles did a good job:
- https://www.darkreading.com/application-security/linux-foundation-debuts-=
sigstore-project-for-software-signing/d/d-id/1340360
- https://www.zdnet.com/article/linux-foundation-announces-new-open-source-=
software-signing-service/

In any case, the idea is to provide a public good service, heavily inspired=
 by Let's Encrypt, that lets developpers sign packages, containers, code ar=
tifacts in general, and lets user verify them in a simple way.

It's still early days, but the aim is to make it a lot easier to verify the=
 integrity of software, and to do better and easier than "here's a binary, =
here's an .asc detached PGP signature, here's a page that says that 0xBLA i=
s our public key", which as we know is a procedure most users simply don't =
follow.

To avoid the pains of key management (and the nasty targets keys quickly be=
come), sigstore uses ephemeral signing keys (which don't ever touch the dis=
k), publishes the signature in a first transparency log, and discards the k=
ey after signature.

The other part of the system, which connects a signing key to an entity, is=
 based on issuing a certificate to the signer which contains their email ad=
dress and their pubkey, if they can prove control of the email address usin=
g OpenID Connect. This certificate is then stored in a second transpararenc=
y log, which provides a second root of trust, directly inspired by the Cert=
ificate Transparency project [2].

Using both transparency logs (signatures and certificates), one can then ve=
rify that a binary download is the expected one, and that is was signed by =
someone who controls an email address. Tools are being built to do this aut=
omatically, and in a repeatable way.

The idea is also to make it easy for developers to monitor the certificate =
transparency log for their email, which could alert them to untowards actio=
ns, if a new certificate pops up for something they never signed.
The OpenID Connect part is designed to allow for both large ID=A0providers =
(like Github or Google) and bring-your-own.

As i was saying, it's still early days, but it's coming along nicely and in=
 my mind, Tor (and TAILS) are projects that would very much benefit from si=
gstore, hence this email.
Work is currently under way with the Ruby and WebAssembly communities to he=
lp them use sigstore to sign their stuff, and more generally the project ha=
s been well received so far.

The whole system is, of course, free and open source and i might add, welco=
mes new contributors. [3]
We also have a chat, if anyone is into that kind of thing. [4]

Interested in your thoughts, critiques etc. =


Thanks and hope this is helpful!

axel

1. Jointly with Google and Purdue University, https://sigstore.dev
2. https://certificate.transparency.dev/
3. https://github.com/sigstore
4. https://join.slack.com/t/sigstore/shared_invite/zt-mhs55zh0-XmY3bcfWn4XE=
yMqUUutbUQ

-- =

axel simon
axel@redhat.com // axel+tor@axelsimon.net
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210410145707</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-04-10 14:57:07-0400</timestampReceived><subject>Re: [tor-dev] Question about hidden services shared by multiple hosts</subject><body>



&gt; On Apr 6, 2021, at 6:37 AM, George Kadianakis &lt;desnacked@riseup.net&gt; wrote:
&gt; 
&gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt; 
&gt; &gt; On 26 Mar (08:55:54), Holmes Wilson wrote:
&gt; &gt; &gt; Hi everyone,
&gt; &gt; 
&gt; &gt; Greetings,
&gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; We're working on a peer-to-peer group chat app where peers connect over v3
&gt; &gt; &gt; onion addresses. 
&gt; &gt; &gt; 
&gt; &gt; &gt; One issue are groups where there are many users but only a few are online in
&gt; &gt; &gt; a given moment.  Onion addresses are forever, and existing peers might know
&gt; &gt; &gt; every peer in the network, but it will take a while to try connecting to all
&gt; &gt; &gt; of them to find one that is online. 
&gt; &gt; &gt; 
&gt; &gt; &gt; In this case, it seems helpful for one or more peers to share one or more
&gt; &gt; &gt; onion addresses that would serve as reliable  "trackers", e.g. 
&gt; &gt; &gt; 
&gt; &gt; &gt; 1. All members know the keypairs for these addresses.
&gt; &gt; &gt; 2. All online members ping these addresses at random intervals to say
&gt; &gt; &gt; they're online.
&gt; &gt; &gt; 3. If they can't connect to an address, they start hosting it themselves.
&gt; &gt; &gt; 
&gt; &gt; &gt; We're going to start testing it, but we're wondering if folks here know the
&gt; &gt; &gt; likely outcome of trying to "share" hosting of an onion service in this
&gt; &gt; &gt; spontaneous-volunteer sort of way and if there are downsides.
&gt; &gt; &gt; 
&gt; &gt; &gt; I *think* the most important question is how long it takes for the network
&gt; &gt; &gt; to stop routing incoming traffic to an offline client when there's an online
&gt; &gt; &gt; one available. How long will the address likely be unreachable in one of
&gt; &gt; &gt; these transition moments, assuming some peer immediately detects that a
&gt; &gt; &gt; "tracker" onion address has gone offline and begins hosting it themselves?
&gt; &gt; &gt; (And does this question make sense?)
&gt; &gt; 
&gt; &gt; Interesting idea!
&gt; &gt; 
&gt; &gt; So sharing onion address key material between peers can be fine until they are
&gt; &gt; used at the same time. What will happen is that the two peers hosting the same
&gt; &gt; onion address (service) will start competing on the onion service directory
&gt; &gt; side where service's upload what we call a "descriptor" which is what client
&gt; &gt; fetch in order to initiate a connection to the service.
&gt; &gt; 
&gt; &gt; With v3, it gets even more complicated actually because of the "revision
&gt; &gt; counter" in the descriptor which v2 didn't have.
&gt; &gt; 
&gt; &gt; It is simply a number that keeps going up in the descriptor so the onion
&gt; &gt; service directory (relay) doesn't accept a previous descriptor (replay). And
&gt; &gt; so, your two peers sharing the onion keys will require to somehow sync that
&gt; &gt; revision counter for your idea to work (located on disk in the state file,
&gt; &gt; "HidServRevCounter").
&gt; &gt; 
&gt; &gt; Else, one will inevitably be higher than the other and thus will always
&gt; &gt; succeed where it will always fail for the other peer.
&gt; &gt; 
&gt; 
&gt; Hello all,
&gt; 
&gt; this revision counter sync issue is not a problem anymore since we
&gt; introduced the Order-Preserving-Encryption revision counter logic:
&gt; https://gitlab.torproject.org/tpo/core/tor/-/blob/master/src/feature/hs/hs_service.c#L2979
&gt;  https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/rend-spec-v3.txt#L2548
&gt;  Feel free to try it and let us know if it doesn't work. The solution
&gt; assumes that all peers have reasonably synchronized clocks.

Nice, that's convenient! We'll try it! What happens if peers don't have reasonably \
synchronized clocks, just out of curiosity? 

&gt; In other news, the above "all members know all keypairs" approach seems
&gt; super dangerous in terms of security, especially if not all those
&gt; members are 100% trusted by each other.

Thank you for flagging this. Are there threats beyond denial of service that we \
should be worried about? It would be extremely helpful to hear about them, if so.

If you're mostly worried about the fact that any member can now wreak havoc with this \
shared peer discovery service, I *think* that's okay for this mechanism. Though I'd \
hugely appreciate being corrected on this!

Here's why I *think* it may be okay, though again I welcome being corrected:

First, each peer will already know the full list of member addresses, and the signing \
key of an admin, so we can build things such that whoever runs this service does not \
have the power to pollute a user's list of peers—just the power to offer users \
useless offline peers, or offer them nothing.

Second, because this "shared" service is only for learning more quickly which ones \
are online, even if a malicious member uses their knowledge of the keys to disable \
the service for all users forever, peers would still have other (albeit slower) ways \
to connect to each other. (Worst case: try all peers. Or we could have 3 or more \
shared addresses where each is known to subgroup of users, so that an attacker would \
need to control multiple accounts to break the mechanism.)

I assume there are big things I'm missing and I'm extremely grateful for any \
feedback! 

The alternatives we've considered for discovering which peers are online either \
require a peer that is always online (which is ideal but not practical for all \
groups) or some global network that metadata would probably leak to, and that an even \
larger set of malicious peers could probably wreak havoc with.

It would be amazing if the Tor network offered some kind of "meta-onion" address that \
would return a list of all online onion addresses with the keys for this address. \
(Since then we wouldn't have to worry about one malicious peer with the keys taking \
down the whole discovery mechanism for everyone.) Is there anything like this? It \
seems like it might be useful in other cases as well, such as load balancing. 

Again thanks everyone for the responses and feedback!!!

H

&gt; 
&gt; To answer the performance question, if a peer immediately notices the
&gt; onion service being offline and begins hosting it, it should be
&gt; pretty-much immediately reachable by new clients.
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210414142846</emailId><senderName>Matthew Finkel</senderName><senderEmail>sysrqb@torproject.org</senderEmail><timestampReceived>2021-04-14 14:28:46-0400</timestampReceived><subject>[tor-dev] Hackathon UDP Support</subject><body>

Hello!

During the Hackweek, I spent a little time hacking support of
UDP-over-Tor. The goal of the project was supporting UDP onion services,
and leaving Exit support for another time.

I didn't have a working implementation by the end of the week, but life
moves one.

This is an initial mail about the general idea, and I'll follow up with
a concrete proposal in the not-too-distant future.

I have a (currently broken) branch `feature_udp_data` in my gitlab repo
[0]. I started simplifying/refactoring the hack job, but it's still a
work in progress.

I'll briefly describe how the working version [1] is designed. Overall,
this mostly just-works. While UDP is not a reliable routed protocol,
datagrams are not dropped within the network. We delegate drops to the
edges' recv/send queues (and any intermediate network equipment).


Client Side:

The patch continued our dependence on SOCKS5 [2] and (maybe correctly)
implemented the UDP ASSOCIATE command. The client sends a normal SOCKS5
handshake, except the new command is 0x03. The tor client then:
  - Establishes a rendezvous circuit with the specified onion service
    hostname in the handshake
  - On completing that connection, creates and binds a datagram socket
  - Sends the application a Success response and includes the datagram
    socket's bound address and port in that message.

The client then sends all datagrams to the provided (bound)
address:port, and the TCP socket used in the SOCKS5 handshake is only
kept open as a way of tracking the UDP socket's lifetime. Tor knows that
any datagram payload should be transported as a datagram instead of a
stream.


Tor Internal:

The patch introduces two relay cell commands: DATAGRAM and
DATAGRAM_FRAG. These relay cell types are stateless. Simply, when a tor
client (or general edge, in the future) receives a DATAGRAM_FRAG relay
cell, it knows that the payload is only a fragment of an entire
datagram. As a result, tor queues the data and does not send it to the
application. When a DATAGRAM cell is received, then tor knows the
contained payload is either:
  1) a complete datagram that fit into a single relay cell
  2) the final payload of a fragmented datagram

In either case, tor appends the payload to the (possibly empty) queue
and then sends it to the application. Tor doesn't need to care which one
is the current case. Also, Tor doesn't take into account a MTU mismatch
between the client-side and server-side - future work.

As an aside, I considered introducing only a single DATAGRAM relay cell,
and reserving the first byte for metadata (and using a bit indicating if
the payload is a fragment). However, I couldn't convince myself that
losing one byte of payload capacity was worth the advantages. I'll leave
this as a valuable discussion during the proposal process.


Onion Service Side:

The onion service is configured normally, except now there is a
HiddenServiceType configuration option. When it isn't provided, the
default value is "stream", otherwise it should be "dgram". This
configuration tells tor that a "stream" opened to this onion service (on
the specified port) is actually connectionless, and any payload data
should be sent and received as datagrams. Following from the previous
section, when a DATAGRAM relay cell is received, the queued payload is
packaged as a datagram and sent to the configured onion service
address:port.


Future design considerations:
  - Better client-side interface than SOCKS5 UDP Associate?
  - Relay cell design improvements
  - Cleaner onion service configuration?
  - MTU difference on the client/server-sides
  - What's missing before we can support this on Exits?


[0] https://gitlab.torproject.org/sysrqb/tor/
[1] commit ebfb4a97713d49a5e7f61709658b9d55ac21ec95
[2] https://tools.ietf.org/html/rfc1928
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210422202740</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-04-22 20:27:40-0400</timestampReceived><subject>[tor-dev] Free and Open Communications on the Internet (FOCI) submission deadline May 13</subject><body>

Hi folks! The FOCI workshop is happening again this year, organized by
our friends Eric Wustrow (Tapdance, Conjure) and Dave Levin (Geneva).

The deadline for submissions is May 13.

Cecylia, Arturo, me, Alberto from IODA, Tariq, Rob, phw, etc are all on
the program committee:
https://conferences.sigcomm.org/sigcomm/2021/workshop-foci.html

So: if you have something you want to share with the FOCI audience,
consider writing it down and submitting. :)

Thanks!
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210303180649</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-03-03 18:06:49-0400</timestampReceived><subject>Re: [tor-dev] Proposal 328: Make Relays Report When They Are Overloaded</subject><body>

On 3/3/21 1:14 PM, David Goulet wrote:
&gt; 
&gt; On 02 Mar (20:58:43), Mike Perry wrote:
&gt; &gt; 
&gt; &gt; 
&gt; &gt; On 3/2/21 6:01 PM, George Kadianakis wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; David Goulet &lt;dgoulet@torproject.org&gt; writes:
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Greetings,
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Attached is a proposal from Mike Perry and I. Merge requsest is here:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/22
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; Hello all,
&gt; &gt; &gt; 
&gt; &gt; &gt; while working on this proposal I had to change it slightly to add a few
&gt; &gt; &gt; more metrics and also to simplify some engineering issues that we would
&gt; &gt; &gt; encounter. You can find the changes here:
&gt; &gt; &gt; https://gitlab.torproject.org/asn/torspec/-/commit/b57743b9764bd8e6ef8de689d14483b7ec9c91ec
&gt; &gt; &gt;  
&gt; &gt; &gt; Mike, based on your comments in the #40222 ticket, I would appreciate
&gt; &gt; &gt; comments on the way the DNS issues will be reported. David argued that
&gt; &gt; &gt; they should not be part of the "overload-general" line because they are
&gt; &gt; &gt; not an overload and it's not the fault of the network in any way. This
&gt; &gt; &gt; is why we added them as separate lines. Furthermore, David suggested we
&gt; &gt; &gt; turn them into a threshold "only report if 25% of the total requests
&gt; &gt; &gt; have timed out" instead of "only report if at least one time out has
&gt; &gt; &gt; occured" since that would be more useful.
&gt; &gt; 
&gt; &gt; I'm confused by this confusion. There's pretty clear precedent for
&gt; &gt; treating packet drops as a sign of network capacity overload. We've also
&gt; &gt; seen it experimentally specifically with respect to DNS, during Rob's
&gt; &gt; experiment. We discussed this on Monday.
&gt; &gt; 
&gt; &gt; However, I agree there's a chance that a single packet drop can be
&gt; &gt; spurious, and/or could be due to ephemeral overload as TCP congestion
&gt; &gt; causes. But 25% is waaaaaaaaaay too high. Even 1% is high IMO, but is
&gt; &gt; more reasonable. We should ask some exits what they see now. The fact
&gt; &gt; that our DNS scanners are not currently seeing this at all, and the
&gt; &gt; issue appeared only for the exact duration of Rob's experiment, suggests
&gt; &gt; that DNS packets drops are extremely rare in healthy network conditions.
&gt; 
&gt; Ok, likely 25% is way too high indeed.
&gt; 
&gt; The idea behind this was simply that a network hiccup or a temporary faulty
&gt; DNS server would not move away traffic from the Exit for a 72h period
&gt; (reminder that the "overload-general" sticks for 72h in the extrainfo once
&gt; hit).

Yes, it sticks for 72 hours because sbws does not store descriptors.
However, the timestamp should *not* update unless the overload condition
occurs again. In this way, we can defer the logic to if the overload
signal is "fresh" vs "stale" to sbws, rather than have it on relays.

This also suggests we want to put some kind of counter in there, like
"number of times this has been listed in the past 72 hours" as well.
That way we can also defer the heuristics to respond to temporary hiccup
vs persistent overload to sbws, too, without needing to bake too of this
logic into relays (which are a PITA to upgrade and may end up running
different versions of this).

George also said you guys felt pressure to rush for the 0.4.6 merge
deadline on this. I would suggest that we not try to bang this out in a
week, but instead try to address these issues with a bit more thought.
If we miss 0.4.6, it's not the end of the world.

Plus this week is shaping up to be pure madness anyway, in other areas.

&gt; &gt; Furthermore, revealing the specific type of overload condition
&gt; &gt; increases the ability for the adversary to use this information for
&gt; &gt; various attacks. I'd rather it be combined in all cases, so that the
&gt; &gt; specific cause is not visible. In all cases, the reaction of our systems
&gt; &gt; should be the same: direct less load to relays with this line. If we
&gt; &gt; need to dig, that's what MetricsPort is for.
&gt; &gt; 
&gt; &gt; In fact, this DNS packet drop signal may be particularly useful in
&gt; &gt; traffic analysis attacks. Its reporting, and likely all of this overload
&gt; &gt; reporting, should probably be delayed until something like the top of
&gt; &gt; the hour after it happens. We may even want this delay to be a consensus
&gt; &gt; parameter. Something like "Report only after N minutes", or "Report only
&gt; &gt; N minute windows", perhaps?
&gt; 
&gt; Yes definitely and I would even add a random component in this so not all
&gt; relays will report an overload in a predictable timeframe and thus "if the
&gt; line appear, I know it was hit N hours ago" type of calculation.

Nice.

Wrt what Georg said, the reason for consensus parameter(s) is also for
agility in the face of uncertainty of potential attacks and how much
they may be helped by a particular response time/fuzz factor. Who can
say if Ian's excitement was performance research, or new attack papers
(kidding Ian, but you know how it goes :).



-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210315195813</emailId><senderName>William Kane</senderName><senderEmail>ttallink@googlemail.com</senderEmail><timestampReceived>2021-03-15 19:58:13-0400</timestampReceived><subject>Re: [tor-dev] [tor-relays] Did 'Sandbox 1' break Tor for anyone else on 0.4.5.6?</subject><body>

Hi Peter,

&gt;Would be great if you could get details about the failing call.

I already thought of gathering said details by tracing the process,
but did not want to risk my uptime statistics, which would inevitably
happen if I had to restart the server and service over and over (I
disabled tracing globally through the Yama LSM as a security measure,
i.e. kernel.yama.ptrace_scope == 3) - recently I lost the guard flag
multiple times, caused by some sort of attack that I already reported
on this list (tor-relays) - someone kept creating a fuckton of
circuits through my relay (averaging 90k per minute), thus causing tor
to run out of memory / get oom-killed by the kernel before it could
even step in and close the circuits - if it was even trying to, it
would make sense for the DoS mitigation code to be active only for the
first link in the circuit aka the guard, and my node simply being a
middle-only relay, it got completely stomped by said attack.

After somewhat mitigating this attack by tweaking MaxMemInQueues,
creating a bigger swap file and tuning vm.swappiness, I regained the
guard flag, but then the hypervisor my KVM box is running under
experienced some issues and had to be rebooted - once again, I
received no notice of that until the relay was already offline for a
few days, causing me to lose the guard flag again.

Seems like luck is just not on my side these days, or well, it's been weeks now.

&gt; You should simply see a Permission Denied if the capability is the problem.

Here's a copy from stdout, only happening if Sandbox is set to 1.:

Mar 15 20:15:20.000 [notice] Configured to measure statistics. Look
for the *-stats files that will first be written to the data directory
in 24 hours from now.
Mar 15 20:15:21.000 [warn] fstat() on directory /var/lib/tor_debug failed.
Mar 15 20:15:21.000 [err] Can't create/check datadirectory /var/lib/tor_debug
Mar 15 20:15:21.000 [err] Error initializing keys; exiting

Running it as a privileged user does not change thing, so no permissions issue:

Mar 15 20:17:24.000 [notice] Configured to measure statistics. Look
for the *-stats files that will first be written to the data directory
in 24 hours from now.
Mar 15 20:17:24.000 [warn] You are running Tor as root. You don't need
to, and you probably shouldn't.
Mar 15 20:17:25.000 [warn] fstat() on directory /var/lib/tor_debug failed.
Mar 15 20:17:25.000 [err] Can't create/check datadirectory /var/lib/tor_debug
Mar 15 20:17:25.000 [err] Error initializing keys; exiting

I've traced down the origin of the fstat() call to this piece of code:

https://github.com/torproject/tor/blob/master/src/lib/fs/dir.c#L158

However, looking at the code that establishes and populates seccomp
rules, it seems like fstat and it's 64 bit counterpart are not subject
to (parameter) filtering, i.e. seccomp_rule_add_0 is invoked with the
parameter SCMP_ACT_ALLOW, reading the manpage for seccomp_rule_add(3)
reveals: "The seccomp filter will have no effect on the thread calling
the syscall if it matches the filter rule."

References:

https://github.com/torproject/tor/blob/master/src/lib/sandbox/sandbox.c#L148
https://github.com/torproject/tor/blob/master/src/lib/sandbox/sandbox.c#L1595
https://man7.org/linux/man-pages/man3/seccomp_rule_add.3.html

So, even though technically, seccomp should allow these syscalls to be
invoked, no matter which parameters are passed, somehow enabling the
whole sandbox subsystem still breaks fstat.

We are getting into tor-dev@ territory here, so maybe someone who is
more experienced with the code base could figure out why this is
happening, I'm pretty good at C/C++ on Linux / Windows and all the
shenanigans that come with it, but lack time to debug this further.

I've added tor-dev@lists.torproject.org as a CC just in case.

- William

2021-03-15 17:10 GMT, Peter Gerber &lt;tor@arbitrary.ch&gt;:
&gt; Hi William
&gt;
&gt; William Kane:
&gt;&gt; Hi everyone,
&gt;&gt;
&gt;&gt; Ever since I upgraded to tor version 0.4.5.6, enabling tor's built-in
&gt;&gt; seccomp sandbox completely breaks tor, i.e. it gets killed by the
&gt;&gt; kernel on start for a seccomp violation (fstat(..)) - sandboxing
&gt;&gt; worked fine on 0.4.4.6, my system configuration did not change between
&gt;&gt; the updates.
&gt;
&gt; Tor itself usually fails with a Permission Denied error when a syscall
&gt; fails due to seccomp. So, this is rather odd.
&gt;
&gt;&gt; I figured this was happening because I do not grant the
&gt;&gt; CAP_DAC_READ_SEARCH capability, but I'm not so sure anymore if that's
&gt;&gt; the reason.
&gt;
&gt; You should simply see a Permission Denied if the capability is the problem.
&gt;
&gt; Would be great if you could get details about the failing call. If
&gt; seccomp is involved, you should be able to get details like this:
&gt;
&gt; • install package auditd
&gt; • make sure auditd is running
&gt; • crash Tor
&gt; • find the syscall with `ausearch -ts recent -i`
&gt;
&gt; Peter
&gt;
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210320124407</emailId><senderName>Aashim Garg</senderName><senderEmail>aashim1garg@gmail.com</senderEmail><timestampReceived>2021-03-20 12:44:07-0400</timestampReceived><subject>[tor-dev] Regarding GSoC'21</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

I hope you are all doing great!


I am Aashim Garg, a third-year undergrad student studying Computer Science
in India.In the past I have made projects using react , next and
typescript. I want to work on the OONI: Integration and unit testing of
OONI probe Desktop apps .
Can you please guide me on how I can start working on it and I would love
to be a part of this community!

Regards

Aashim Garg

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;&lt;p style="color:rgb(14,16,26);background:transparent none repeat \
scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;&lt;span style="background:transparent \
none repeat scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;Hi everyone,  \
&lt;/span&gt;&lt;/p&gt;&lt;p style="color:rgb(14,16,26);background:transparent none repeat scroll 0% \
0%;margin-top:0pt;margin-bottom:0pt"&gt;&lt;span style="background:transparent none repeat \
scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;I hope you are all doing \
great!&lt;/span&gt;&lt;/p&gt;&lt;p style="color:rgb(14,16,26);background:transparent none repeat \
scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;&lt;br&gt;&lt;/p&gt;&lt;p \
style="color:rgb(14,16,26);background:transparent none repeat scroll 0% \
0%;margin-top:0pt;margin-bottom:0pt"&gt;&lt;span style="background:transparent none repeat \
scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;I  am Aashim Garg, a third-year \
undergrad student studying Computer  Science in India.&lt;/span&gt;In the past I have made \
projects using react , next and typescript. I want to work on the OONI: Integration \
and unit testing of OONI probe Desktop apps . &lt;br&gt;Can you please  guide me on how I \
can start working on it and I would  love to be a part of this \
community!&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="color:rgb(14,16,26);background:transparent none \
repeat scroll 0% 0%;margin-top:0pt;margin-bottom:0pt"&gt;Regards &lt;br&gt;&lt;/p&gt;&lt;p \
style="color:rgb(14,16,26);background:transparent none repeat scroll 0% \
0%;margin-top:0pt;margin-bottom:0pt"&gt;Aashim Garg&lt;br&gt;&lt;/p&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210322195443</emailId><senderName>William Kane</senderName><senderEmail>ttallink@googlemail.com</senderEmail><timestampReceived>2021-03-22 19:54:43-0400</timestampReceived><subject>[tor-dev] Circuit Creation Madness: Anyone else still experiencing (extremely) excessive clients / (</subject><body>

@tor-relays:

Sorry for being quite noisy recently but I really need to know how
many people are suffering from the same madness I am encountering
right now.

Quick excerpt from the log:

...
Mar 22 09:48:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:48:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [12420 similar message(s) suppressed in last 120 seconds]
Mar 22 09:49:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:49:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [31764 similar message(s) suppressed in last 60 seconds]
Mar 22 09:50:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:50:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [104748 similar message(s) suppressed in last 60 seconds]
Mar 22 09:51:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:51:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [364165 similar message(s) suppressed in last 60 seconds]
Mar 22 09:52:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:52:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [509474 similar message(s) suppressed in last 60 seconds]
Mar 22 09:53:10 &lt;hostname_redacted&gt; tor[pid_redacted]: Mar 22
09:53:10.000 [warn] Your computer is too slow to handle this many
circuit creation requests! Please consider using the
MaxAdvertisedBandwidth config option or choosing a more restricted
exit policy. [241332 similar message(s) suppressed in last 60 seconds]
...

This then goes on for a while, stopping at a few million suppressed
messages / circuit creation attempts.

Sorry, but 1 million circuit creation requests in just 5 minutes,
there is no way that this is legitimate behavior we are seeing - this
is also what was previously used to get my relay oom-killed but that I
have fixed so the legitimate clients hopefully don't suffer too much
anymore.

If any other relay operators are encountering the same log entries or
behavior, please don't hesitate to reply.

Added tor-dev@lists.torproject.org as a CC as they might want to know
about this.

@tor-dev:

I suspect some kind of denial-of-service attack against onion services
or a more targeted attack against singular relays for guard discovery
/ traffic confirmation attacks.

Might be smart to add some code which, if this scenario is triggered,
lists offenders by hashes of their signing keys (if relay), or IP
addresses (if client).

There doesn't seem to be a defense against this, and the new connect()
rate-limit added through ticket 40253 also won't handle this as the
connection is already ACK'd and established, and a malicious relay
with custom source code could do whatever it was programmed to do
anyway.

- William
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210323190019</emailId><senderName>maketorgreatagain</senderName><senderEmail>maketorgreatagain@protonmail.com</senderEmail><timestampReceived>2021-03-23 19:00:19-0400</timestampReceived><subject>[tor-dev] Please reconsider Issue #2667 (tor over tor is much needed)</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Good day,

We am making this request to our bellowed Tor Project developers and relay operators \
to reconsider issue https://gitlab.torproject.org/tpo/core/tor/-/issues/2667. Tor \
over tor scenario is not recommended by Tor project but We are forced to use such \
setup to hide our operations from the powerful adversary which would in case we use \
bridge between our two tor path most likely possible de-anonymize us and put our life \
in dangerous.

Tor is making our work possible and helping collaborate without restrictions, please \
let's reconsider this issue one more time. We are running number of relay and we \
considered not applying latest update to help us at least work with our own relay but \
adversary observes big part of network and will most likely identify us when 70% of \
network start dropping tor over tor connections.

Tor over tor scenario does not amplify attack power within tor network, the strength \
of any request is losing it's power right after first hop, but for many people it \
provides necessary and much required privacy.

We do highly sensitive work in research journalism across the globe and only way we \
found so far not be de-anonymized was tor over tor scenario, probably for reason that \
two circuits are dynamic and it's very hard for adversary to track that down properly \
due to nature of tor network. Understandable that you most of time support regular \
Tor Browser usage and 3 hop circuits but believe us there are situations where our \
scenario is really necessary.

We have collected donations of around 21000 USD in XMR so far(we know it's not much), \
which we can either donate to Tor project to help fix this issue or otherwise fund \
relay operators to run not-up-to-date relays just to help us operate under this \
powerful adversary. The second is worse solution as it would make network more \
vulnerable, or at least allow relay operators to enable or disable that option and \
don't make it mandatory.

Privacy for the win!

Much love for Tor project and you relay operators
Best regards


[Attachment #5 (text/html)]

&lt;div&gt;Good day,&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;  We am making this request to \
our bellowed Tor Project developers and relay operators to reconsider issue &lt;a \
href="https://gitlab.torproject.org/tpo/core/tor/-/issues/2667" target="_blank" \
rel="noreferrer nofollow \
noopener"&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/2667&lt;/a&gt;.  Tor over tor \
scenario is not recommended by Tor project but We are forced to use such setup to \
hide our operations from the powerful adversary which would in case we use bridge \
between our two tor path most likely possible de-anonymize us and put our life in \
dangerous. &lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Tor  is making our work possible and helping \
collaborate without restrictions, please let's reconsider this issue one more time. \
We are running number of relay and we considered not applying latest update to
help us at least work with our own relay but adversary observes big part
 of network and will most likely identify us when 70% of network start
dropping tor over tor connections.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Tor over tor scenario \
does not  amplify attack power within tor network, the strength of any request is
 losing it's power right after first hop, but for many people it
provides necessary and much required privacy.&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We
 do highly sensitive work in research journalism across the globe and
only way we found so far not be de-anonymized was tor over tor scenario,
 probably for reason that two circuits are dynamic and it's very hard
for adversary to track that down properly due to nature of tor network.
Understandable that you most of time support regular Tor Browser usage
and 3 hop circuits but believe us there are situations where our
scenario is really necessary.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We have
collected donations of around 21000 USD in XMR so far(we know it's not
much), which we can either donate to Tor project to help fix this issue
or otherwise fund relay operators to run not-up-to-date relays just to
help us operate under this powerful adversary. The second is worse
solution as it would make network more vulnerable, or at least allow
relay operators to enable or disable that option and don't make it
mandatory.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Privacy for the \
win!&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Much love for Tor project and you relay \
operators&lt;br&gt;&lt;/div&gt;&lt;div&gt;Best regards&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210325095310</emailId><senderName>Jeff Burdges</senderName><senderEmail>burdges@gnunet.org</senderEmail><timestampReceived>2021-03-25 09:53:10-0400</timestampReceived><subject>[tor-dev] staking donations</subject><body>


I realize this would be the wrong part of the Tor project to which to suggest this, \
but I know the people on this list and I do not know the people elsewhere in Tor, and \
there is some small technical content here, so..

There are now a bunch of proof-of-stake cybercoins aka crypto-currencies, like \
polkadot by my employer, cosmos, cardano, etc.  As a rule, these have the property \
that people who own the currency for one reason or another can lock their currency to \
help deSybil some special nodes, usually called validators.  This earns them some \
rewards because doing so usually makes them liable for misbehavior of the validator.

This is very different from bitcoin where five guys in China and one guy in Island \
take all the rewards, and those six guys spend a lot of real money doing so.  Now \
quite a lot of people are claiming these reward, and the real work they are doing is \
running one server, or even merely saying "I know that dude and he seems okay". 

This means a lot of people suddenly have an income stream on which they need to pay \
taxes, but for which the taxes are complex.  At least a few of these people do not \
yet stake because they do not yet know how to handle the taxes, like maybe they need \
time to set up a company or whatever. 

At least a few of these should've a somewhat flexible key infrastructure like I had \
us do in polkadot, and in particular users can simply point their rewards at another \
address besides the one from which they stake.

If you're a non-profit that can avoid the tax complexities, then it'd be a good time \
to accept donations in these new crypto currencies, because aside from regular \
donation some people might just skip thinking about their own taxes for a while by \
point their rewards at someone like Tor who'd spend the money usefully.. at least \
temporarily. 

I realize there might be other complexities of course, but if this were interesting \
then I could likely convince someone around here to implement some partial rewards \
division thing, which might enable people to contribute longer term.

Best,
Jeff


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210505223911</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-05-05 22:39:11-0400</timestampReceived><subject>[tor-dev] What's the best way to learn about critical updates to Tor?</subject><body>

Hi all,

For the messaging app we're building on Tor (not Tor browser) what's the best way for \
us to be alerted when there are critical updates to Tor, so that we can prepare a new \
release as quickly as possible?

(Apologies for the flurry of questions today!)

Holmes
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210505192723</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-05-05 19:27:23-0400</timestampReceived><subject>[tor-dev] Uptime stats for "Tor user can access an otherwise-functional hidden service"?</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

I'm building a messaging app based on Tor v3 onion services and I'm wondering what \
kind of uptime expectations we should set with users and other stakeholders. 

Is there data over time on uptime for onion service functionality? That is, not for a \
particular onion service, but for something like, given that the user's access to Tor \
is not being limited by their ISP, and given that the onion service is fully \
operational, whether a Tor user can reach the onion service?

Some more concrete versions of this question are: 

1. For what percentage of time over a given time period (say the past 3 years) are \
there no known network-wide problems affecting onion services? 2. What percentage of \
attempts by a user attempting to connect to a onion service are successful, assuming \
no successful censorship of the user's network? 3. Is there some incident log \
somewhere of problems that affected onion services network wide that includes how \
long these problems persisted for? (I don't see any onion service outage notes in \
this document, though I seem to remember there was an issue a few months back? \
https://metrics.torproject.org/news.html &lt;https://metrics.torproject.org/news.html&gt;)  \


I see there's uptime data for various relays, but I'm not sure how to translate this \
into a meaningful answer to the two above questions. Are there any good answers to \
these questions out there in the wild? Even approximate answers or lower bounds for \
uptime are fine and super helpful!  

Thanks!!!
Holmes


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;Hi everyone,&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I'm building a messaging app based on Tor v3 onion \
services and I'm wondering what kind of uptime expectations we should set with users \
and other stakeholders. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Is \
there data over time on uptime for onion service functionality? That is, not for a \
particular onion service, but for something like, given that the user's access to Tor \
is not being limited by their ISP, and given that the onion service is fully \
operational, whether a Tor user can reach the onion service?&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Some more concrete versions of this question \
are: &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;1. For what percentage \
of time over a given time period (say the past 3 years) are there no known \
network-wide problems affecting onion services?&lt;/div&gt;&lt;div class=""&gt;2. What \
percentage of attempts by a user attempting to connect to a onion service \
are successful, assuming no successful censorship of the user's network?&lt;/div&gt;&lt;div \
class=""&gt;3. Is there some incident log somewhere of problems that affected onion \
services network wide that includes how long these problems persisted for? (I don't \
see any onion service outage notes in this document, though I seem to remember there \
was an issue a few months back? &lt;a href="https://metrics.torproject.org/news.html" \
class=""&gt;https://metrics.torproject.org/news.html&lt;/a&gt;)  &lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I see there's uptime data for various relays, but I'm \
not sure how to translate this into a meaningful answer to the two above questions. \
Are there any good answers to these questions out there in the wild? Even approximate \
answers or lower bounds for uptime are fine and super helpful!  &lt;/div&gt;&lt;div \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thanks!!!&lt;/div&gt;&lt;div \
class=""&gt;Holmes&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210507121114</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-05-07 12:11:14-0400</timestampReceived><subject>[tor-dev] descriptor sync finished event after disabling UseMicrodescritors</subject><body>

Hi,

what is the best way to find out when descriptor fetching is completed 
after temporarily disabling microdescriptors on a running tor client daemon?
The temporary disabling of microdescriptors is done using this line in a python \
script using stem:

controller.set_conf('UseMicrodescriptors', '0')

Is there a better way than to try and re-try after 10 seconds in a loop via \
controller.get_server_descriptors() ?

I also noticed that fetching takes significantly longer when microdescriptors are \
disabled temporarily when compared to  adding 
UseMicrodescriptors 0 
to the torrc file persistently and restarting the tor client.

Can I tell tor to "fetch now" directly after
controller.set_conf('UseMicrodescriptors', '0')
via an additional control command?

kind regards,
nusenu

-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210514180250</emailId><senderName>sysmanager7</senderName><senderEmail>sysmanager7@protonmail.com</senderEmail><timestampReceived>2021-05-14 18:02:50-0400</timestampReceived><subject>[tor-dev] Consensus network status fetch</subject><body>

[Attachment #2 (multipart/alternative)]

[Attachment #4 (text/plain)]

Why does a network status fetch cause a signal hup and my system to reset?

00:30:35 [NOTICE] While not bootstrapping, fetched this many bytes: 17796869 (server descriptor
x fetch); 8622 (server descriptor upload); 2216044 (consensus network-status fetch); 148431
x (microdescriptor fetch)
x 00:00:07 [NOTICE] Read configuration file "/etc/tor/torrc".
x 00:00:07 [NOTICE] Read configuration file "/usr/share/tor/tor-service-defaults-torrc".
x 00:00:07 [NOTICE] Received reload signal (hup). Reloading config and resetting internal state.
xlq May 13, 2021 qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk

Sent with [ProtonMail](https://protonmail.com) Secure Email.
[Attachment #5 (text/html)]

&lt;div&gt;Why does a network status fetch cause a signal hup and my system to \
reset?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;00:30:35 [NOTICE] While not bootstrapping, fetched \
this many bytes: 17796869 (server descriptor&lt;br&gt;&lt;/div&gt;&lt;div&gt;x   fetch); 8622 \
(server descriptor upload); 2216044 (consensus network-status fetch); \
148431&lt;br&gt;&lt;/div&gt;&lt;div&gt;x   (microdescriptor fetch)&lt;br&gt;&lt;/div&gt;&lt;div&gt;x 00:00:07 \
[NOTICE] Read configuration file "/etc/tor/torrc".&lt;br&gt;&lt;/div&gt;&lt;div&gt;x 00:00:07 [NOTICE] \
Read configuration file "/usr/share/tor/tor-service-defaults-torrc".&lt;br&gt;&lt;/div&gt;&lt;div&gt;x \
00:00:07 [NOTICE] Received reload signal (hup). Reloading config and resetting \
internal state.&lt;br&gt;&lt;/div&gt;&lt;div&gt;xlq May 13, 2021 \
qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
class="protonmail_signature_block"&gt;&lt;div class="protonmail_signature_block-user \
protonmail_signature_block-empty"&gt;&lt;br&gt;&lt;/div&gt;&lt;div \
class="protonmail_signature_block-proton"&gt;Sent with &lt;a href="https://protonmail.com" \
target="_blank"&gt;ProtonMail&lt;/a&gt; Secure Email.&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210514214713</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-05-14 21:47:13-0400</timestampReceived><subject>Re: [tor-dev] Consensus network status fetch</subject><body>

On Fri, May 14, 2021 at 06:02:50PM +0000, sysmanager7 wrote:
&gt; Why does a network status fetch cause a signal hup and my system to reset?
&gt; 
&gt; x 00:00:07 [NOTICE] Received reload signal (hup). Reloading config and resetting internal state.

It probably isn't the networkstatus fetch that did it. It's much more
likely that something else on your system sent the HUP signal -- I would
guess it's something that is part of your Tor package.

For example, if your Tor package enables logrotation, it probably hups
Tor after that so Tor will close the old log file and reopen a new one.

So, it depends which Tor package you have. Take a look at what cron jobs
it added and what they do.

--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210516180559</emailId><senderName>sysmanager7</senderName><senderEmail>sysmanager7@protonmail.com</senderEmail><timestampReceived>2021-05-16 18:05:59-0400</timestampReceived><subject>Re: [tor-dev] Consensus network status fetch</subject><body>

crotab -l root returns 0
crontab -l user returns 0

I am running a tor relay on Ubuntu 20.4 on a digital Ocean Droplet.

NTX is used to monitor

   00:00:05 [NOTICE] Read configuration file "/etc/tor/torrc".
 x 00:00:05 [NOTICE] Read configuration file "/usr/share/tor/tor-service-defaults-torrc".
 x 00:00:05 [NOTICE] Received reload signal (hup). Reloading config and resetting internal state.

 What happens after the signal hup is my band settings are changed from 2/4 MBs to 112/120MBs. This
 usually happens at 1/2 am so the relay operates at those settings for a solid eight hours. I am paying
 for this, when the above happens, it gets expensive! Which is why this has to stop.

Sent with ProtonMail Secure Email.

------- Original Message -------
On Friday, May 14, 2021 4:47 PM, Roger Dingledine &lt;arma@torproject.org&gt; wrote:

&gt; On Fri, May 14, 2021 at 06:02:50PM +0000, sysmanager7 wrote:
&gt;
&gt; &gt; Why does a network status fetch cause a signal hup and my system to reset?
&gt; &gt; x 00:00:07 [NOTICE] Received reload signal (hup). Reloading config and resetting internal state.
&gt;
&gt; It probably isn't the networkstatus fetch that did it. It's much more
&gt; likely that something else on your system sent the HUP signal -- I would
&gt; guess it's something that is part of your Tor package.
&gt;
&gt; For example, if your Tor package enables logrotation, it probably hups
&gt; Tor after that so Tor will close the old log file and reopen a new one.
&gt;
&gt; So, it depends which Tor package you have. Take a look at what cron jobs
&gt; it added and what they do.
&gt;
&gt; --Roger
&gt;
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

</body></email><email><emailId>20210510132750</emailId><senderName>David Goulet</senderName><senderEmail>dgoulet@torproject.org</senderEmail><timestampReceived>2021-05-10 13:27:50-0400</timestampReceived><subject>Re: [tor-dev] descriptor sync finished event after disabling UseMicrodescritors</subject><body>

[Attachment #2 (multipart/signed)]


On 07 May (14:11:14), nusenu wrote:
&gt; Hi,
&gt; 
&gt; what is the best way to find out when descriptor fetching is completed 

I wasn't entirely sure of this so I looked at the code and turns out that when
you get new microdescriptors, we only emit a BOOTSTRAP event but if the
bootstrap is already 100%, nothing is emitted.

I had hopes in "NEWDESC" until I read this sentence from the spec:

  This event is generated when new router descriptors (not microdescs or
  extrainfos or anything else) are received.

So I think the short answer is, tor doesn't inform you of this.

But, you could do the experiment of listening to _all_ events on the control
port and see if there could be something I missed or some combination of
events that could indicate to you this... hacky I know but one possible
avenue.

&gt; after temporarily disabling microdescriptors on a running tor client daemon?
&gt; The temporary disabling of microdescriptors is done using this line in a
&gt; python script using stem:
&gt; 
&gt; controller.set_conf('UseMicrodescriptors', '0')
&gt; 
&gt; Is there a better way than to try and re-try after 10 seconds in a loop via
&gt; controller.get_server_descriptors() ?

I'm not sure there is with tor itself :S.

&gt; 
&gt; I also noticed that fetching takes significantly longer when microdescriptors are \
&gt; disabled temporarily when compared to  adding 
&gt; UseMicrodescriptors 0 
&gt; to the torrc file persistently and restarting the tor client.

Maybe simply because server descriptors are much larger than microdesc?

&gt; 
&gt; Can I tell tor to "fetch now" directly after
&gt; controller.set_conf('UseMicrodescriptors', '0')
&gt; via an additional control command?

I don't think this is possible as far as my memory goes for control-spec.txt.

Cheers!
David

-- 
cEzKnCIRITTGQ0bcIesPTXZ4YIe0B0feRIrRBkFZXvo=


["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210515080428</emailId><senderName>nusenu</senderName><senderEmail>nusenu-lists@riseup.net</senderEmail><timestampReceived>2021-05-15 08:04:28-0400</timestampReceived><subject>Re: [tor-dev] descriptor sync finished event after disabling UseMicrodescriptors (stem)</subject><body>

Hi David,

thanks for your reply and confirming that there is no event for this,
so the best option is to make a simple loop and test every few seconds if the \
download is completed I guess.

&gt; &gt; I also noticed that fetching takes significantly longer when microdescriptors are \
&gt; &gt; disabled temporarily when compared to  adding 
&gt; &gt; UseMicrodescriptors 0 
&gt; &gt; to the torrc file persistently and restarting the tor client.
&gt; 
&gt; Maybe simply because server descriptors are much larger than microdesc?

In both cases we fetch the same kind of descriptors.

1) torrc: UseMicrodescriptors 0 -&gt; start tor -&gt; fast to complete descriptor fetching

2) no torrc change -&gt; start tor -&gt;  controller.set_conf('UseMicrodescriptors', '0') \
-&gt; slow 

Maybe (2) is slower because tor does not start the download directly after \
set_conf('UseMicrodescriptors', '0') is received.


kind regards,
nusenu
 
-- 
https://nusenu.github.io
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210505223535</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-05-05 22:35:35-0400</timestampReceived><subject>Re: [tor-dev] Uptime stats for "Tor user can access an otherwise-functional hidden service"?</subject><body>

[Attachment #2 (multipart/alternative)]


And I just saw today's blog post about the new status page. Congrats on launching \
this! Someone is reading my mind :) 

But is there any good source for historical data on incidents or re: the questions \
below? 

Also, is there currently some monitoring in place such that someone on the Tor team \
gets a phonecall or SMS alert if onion services seem to be globally down? Several \
projects I've been a part of over the years have benefitted immensely from this, \
using tools like PagerDuty, so I'm curious if Tor has something like this for onion \
services. 

Great work and I'm curious to learn more!!

—Holmes 


&gt; On May 5, 2021, at 3:27 PM, Holmes Wilson &lt;h@zbay.llc&gt; wrote:
&gt; 
&gt; Hi everyone,
&gt; 
&gt; I'm building a messaging app based on Tor v3 onion services and I'm wondering what \
&gt; kind of uptime expectations we should set with users and other stakeholders.  
&gt; Is there data over time on uptime for onion service functionality? That is, not for \
&gt; a particular onion service, but for something like, given that the user's access to \
&gt; Tor is not being limited by their ISP, and given that the onion service is fully \
&gt; operational, whether a Tor user can reach the onion service? 
&gt; Some more concrete versions of this question are: 
&gt; 
&gt; 1. For what percentage of time over a given time period (say the past 3 years) are \
&gt; there no known network-wide problems affecting onion services? 2. What percentage \
&gt; of attempts by a user attempting to connect to a onion service are successful, \
&gt; assuming no successful censorship of the user's network? 3. Is there some incident \
&gt; log somewhere of problems that affected onion services network wide that includes \
&gt; how long these problems persisted for? (I don't see any onion service outage notes \
&gt; in this document, though I seem to remember there was an issue a few months back? \
&gt; https://metrics.torproject.org/news.html \
&gt; &lt;https://metrics.torproject.org/news.html&gt;)   
&gt; I see there's uptime data for various relays, but I'm not sure how to translate \
&gt; this into a meaningful answer to the two above questions. Are there any good \
&gt; answers to these questions out there in the wild? Even approximate answers or lower \
&gt; bounds for uptime are fine and super helpful!   
&gt; Thanks!!!
&gt; Holmes


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;And I just saw today's blog post about the \
new status page. Congrats on launching this! Someone is reading my mind :) &lt;div \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;But is there any good source for historical \
data on incidents or re: the questions below? &lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Also, is there currently some monitoring in place such \
that someone on the Tor team gets a phonecall or SMS alert if onion services seem to \
be globally down? Several projects I've been a part of over the years have benefitted \
immensely from this, using tools like PagerDuty, so I'm curious if Tor has something \
like this for onion services. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Great work and I'm curious to learn more!!&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;—Holmes &lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;div&gt;&lt;br class=""&gt;&lt;blockquote type="cite" class=""&gt;&lt;div \
class=""&gt;On May 5, 2021, at 3:27 PM, Holmes Wilson &lt;&lt;a href="mailto:h@zbay.llc" \
class=""&gt;h@zbay.llc&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br class="Apple-interchange-newline"&gt;&lt;div \
class=""&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" \
class=""&gt;&lt;div style="word-wrap: break-word; -webkit-nbsp-mode: space; line-break: \
after-white-space;" class=""&gt;Hi everyone,&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;I'm building a messaging app based on Tor v3 onion services and I'm \
wondering what kind of uptime expectations we should set with users and other \
stakeholders. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Is there data \
over time on uptime for onion service functionality? That is, not for a particular \
onion service, but for something like, given that the user's access to Tor is not \
being limited by their ISP, and given that the onion service is fully operational, \
whether a Tor user can reach the onion service?&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Some more concrete versions of this question \
are: &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;1. For what percentage \
of time over a given time period (say the past 3 years) are there no known \
network-wide problems affecting onion services?&lt;/div&gt;&lt;div class=""&gt;2. What \
percentage of attempts by a user attempting to connect to a onion service \
are successful, assuming no successful censorship of the user's network?&lt;/div&gt;&lt;div \
class=""&gt;3. Is there some incident log somewhere of problems that affected onion \
services network wide that includes how long these problems persisted for? (I don't \
see any onion service outage notes in this document, though I seem to remember there \
was an issue a few months back? &lt;a href="https://metrics.torproject.org/news.html" \
class=""&gt;https://metrics.torproject.org/news.html&lt;/a&gt;)  &lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I see there's uptime data for various relays, but I'm \
not sure how to translate this into a meaningful answer to the two above questions. \
Are there any good answers to these questions out there in the wild? Even approximate \
answers or lower bounds for uptime are fine and super helpful!  &lt;/div&gt;&lt;div \
class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Thanks!!!&lt;/div&gt;&lt;div \
class=""&gt;Holmes&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210506144450</emailId><senderName>George Kadianakis</senderName><senderEmail>desnacked@riseup.net</senderEmail><timestampReceived>2021-05-06 14:44:50-0400</timestampReceived><subject>Re: [tor-dev] Uptime stats for "Tor user can access an otherwise-functional hidden service"?</subject><body>

Holmes Wilson &lt;h@zbay.llc&gt; writes:

&gt; And I just saw today's blog post about the new status page. Congrats on launching \
&gt; this! Someone is reading my mind :)  

Hello Holmes,

glad you like the status page! It's indeed great!

&gt; But is there any good source for historical data on incidents or re: the questions \
&gt; below?  

I don't think we have historical data about v3 downtimes unfortunately,
apart from the January event mentioned on status.torproject.org . 

We *have* developed tools to monitor the health of v3 onion services in
an attempt to weed down reachability issues [0] but we mainly used the
tool to find specific bugs, and not as a downtime scanner. That is, we
never performed truly long-term experiments with it, or hooked it to
some global dashboard.

&gt; Also, is there currently some monitoring in place such that someone on the Tor team \
&gt; gets a phonecall or SMS alert if onion services seem to be globally down? Several \
&gt; projects I've been a part of over the years have benefitted immensely from this, \
&gt; using tools like PagerDuty, so I'm curious if Tor has something like this for onion \
&gt; services.  

We are currently not aware of any unresolved reachability issues with v3
onion services.

Fortunately, the onion community is pretty active so we usually become
aware of such issues pretty quickly if they appear on a widespread
scale. That said, I don't think getting alerted more quickly (via an
SMS) would be a bad idea.

Regarding your question: 

&gt; 2. What percentage of attempts by a user attempting to connect to a
&gt; onion service are successful, assuming no successful censorship of the
&gt; user's network?

I would say 100% of attempts modulo unknown reachability bugs. Even if
the client picks a bad path, and a circuit gets broken, the Tor client
should be smart enough to rebuild the circuit and retry the onion
connection.

As always, if you have encountered reachability issues, please do get in
touch with us (and also please provide some logs) so that we can look
this more deeply.

[0]: https://gitlab.torproject.org/tpo/core/tor/-/issues/28841

&gt; 
&gt; &gt; On May 5, 2021, at 3:27 PM, Holmes Wilson &lt;h@zbay.llc&gt; wrote:
&gt; &gt; 
&gt; &gt; Hi everyone,
&gt; &gt; 
&gt; &gt; I'm building a messaging app based on Tor v3 onion services and I'm wondering \
&gt; &gt; what kind of uptime expectations we should set with users and other stakeholders. \
&gt; &gt;  
&gt; &gt; Is there data over time on uptime for onion service functionality? That is, not \
&gt; &gt; for a particular onion service, but for something like, given that the user's \
&gt; &gt; access to Tor is not being limited by their ISP, and given that the onion service \
&gt; &gt; is fully operational, whether a Tor user can reach the onion service? 
&gt; &gt; Some more concrete versions of this question are: 
&gt; &gt; 
&gt; &gt; 1. For what percentage of time over a given time period (say the past 3 years) \
&gt; &gt; are there no known network-wide problems affecting onion services? 2. What \
&gt; &gt; percentage of attempts by a user attempting to connect to a onion service are \
&gt; &gt; successful, assuming no successful censorship of the user's network? 3. Is there \
&gt; &gt; some incident log somewhere of problems that affected onion services network wide \
&gt; &gt; that includes how long these problems persisted for? (I don't see any onion \
&gt; &gt; service outage notes in this document, though I seem to remember there was an \
&gt; &gt; issue a few months back? https://metrics.torproject.org/news.html \
&gt; &gt; &lt;https://metrics.torproject.org/news.html&gt;)   
&gt; &gt; I see there's uptime data for various relays, but I'm not sure how to translate \
&gt; &gt; this into a meaningful answer to the two above questions. Are there any good \
&gt; &gt; answers to these questions out there in the wild? Even approximate answers or \
&gt; &gt; lower bounds for uptime are fine and super helpful!   
&gt; &gt; Thanks!!!
&gt; &gt; Holmes
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210326125554</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-03-26 12:55:54-0400</timestampReceived><subject>[tor-dev] Question about hidden services shared by multiple hosts</subject><body>

Hi everyone,

We're working on a peer-to-peer group chat app where peers connect over v3 onion \
addresses. 

One issue are groups where there are many users but only a few are online in a given \
moment.  Onion addresses are forever, and existing peers might know every peer in the \
network, but it will take a while to try connecting to all of them to find one that \
is online. 

In this case, it seems helpful for one or more peers to share one or more onion \
addresses that would serve as reliable  "trackers", e.g. 

1. All members know the keypairs for these addresses.
2. All online members ping these addresses at random intervals to say they're online.
3. If they can't connect to an address, they start hosting it themselves.

We're going to start testing it, but we're wondering if folks here know the likely \
outcome of trying to "share" hosting of an onion service in this \
spontaneous-volunteer sort of way and if there are downsides.

I *think* the most important question is how long it takes for the network to stop \
routing incoming traffic to an offline client when there's an online one available. \
How long will the address likely be unreachable in one of these transition moments, \
assuming some peer immediately detects that a "tracker" onion address has gone \
offline and begins hosting it themselves? (And does this question make sense?)

Thanks!

Holmes
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210326151513</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-03-26 15:15:13-0400</timestampReceived><subject>[tor-dev] Proposal 329: Traffic Splitting (Conflux)</subject><body>

I'm pleased to present for your enjoyment, excitement, and
enlightenment: Tor Proposal 329: Traffic Splitting!

I've included it inline below. The canonical version for merge exists in
a gitlab MR:
https://gitlab.torproject.org/tpo/core/torspec/-/merge_requests/34

Please merge that one, as it also has a commit to add a much-deserved
Acknowledgement section to Proposal 324, too.

Feel free to respond on-thread, though!

==================================================================
Filename: 329-traffic-splitting.txt
Title: Overcoming Tor's Bottlenecks with Traffic Splitting
Author: David Goulet, Mike Perry
Created: 2020-11-25
Status: Draft

0. Status

This proposal describes the Conflux [CONFLUX] system developed by
Mashael AlSabah, Kevin Bauer, Tariq Elahi, and Ian Goldberg. It aims at
improving Tor client network performance by dynamically splitting
traffic between two circuits.


1. Overview

1.1. Multipath TCP Design Space

In order to understand our improvements to Conflux, it is important to
properly conceptualize what is involved in the design of multipath
algorithms in general.

The design space is broken into two orthogonal parts: congestion control
algorithms that apply to each path, and traffic scheduling algorithms
that decide when to send packets to send on each path.

MPTCP specifies 'coupled' congestion control (see [COUPLED]). Coupled
congestion control updates single-path congestion control algorithms to
account for shared bottlenecks between the paths, so that the combined
congestion control algorithms do not overwhelm any bottlenecks that
happen to be shared between the multiple paths. Various ways of
accomplishing this have been proposed and implemented in the Linux
kernel.

Because Tor's congestion control only concerns itself with bottnecks in
Tor relay queues, and not with any other bottlenecks (such as
intermediate Internet routers), we can avoid this complexity merely by
specifying that any paths that are constructed should not share any
relays. In this way, we can proceed to use the exact same congestion
control as specified in Proposal 324, for each path.

For this reason, this proposal will focus on the traffic scheduling
algorithms, rather than coupling. We propose three candidate algorithms
that have been studied in the literature, and will compare their
performance using simulation and consensus parameters.

1.2. Divergence from the initial Conflux design

The initial [CONFLUX] paper doesn't provide any indications on how to
handle the size of out-of-order cell queue, which we consider a
potential dangerous memory DoS vector (see [MEMORY_DOS]). It also used
RTT as the sole heuristic for selecting which circuit to send on, which
may vary depending on the geographical locations of the participant
relays, without considering their actual available circuit capacity
(which will be available to us via Proposal 324). Additionally, since
the publication of [CONFLUX], more modern packet scheduling algorithms
have been developed, which aim to reduce out-of-order queue size.

We propose mitigations for these issues using modern scheduling
algorithms, as well as implementations options for avoiding the
out-of-order queue at Exit relays. Additionally, we consider resumption,
side channel, and traffic analysis risks and benefits in [RESUMPTION],
[SIDE_CHANNELS] and [TRAFFIC_ANALYSIS].


2. Design

The following section describes the Conflux design. Each sub-section is
a building block to the multipath design that Conflux proposes.

The circuit construction is as follow:

       Primary Circuit (lower RTT)
          +-------+      +--------+
          |Guard 1|-----&gt;|Middle 1|----------+
          +---^---+      +--------+          |
 +-----+      |                           +--v---+
 | OP  +------+                           | Exit |--&gt; ...
 +-----+      |                           +--^---+
          +---v---+      +--------+          |
          |Guard 2|-----&gt;|Middle 2|----------+
          +-------+      +--------+
       Secondary Circuit (higher RTT)

Both circuits are built using current Tor path selection, however they
SHOULD NOT share the same Guard relay, or middle relay. By avoiding
using the same relays in these positions in the path, we ensure
additional path capacity, and eliminate the need to use more complicated
'coupled' congestion control algorithms from the MPTCP
literature[COUPLED].  This both simplifies design, and improves
performance.

Then, the OP needs to link the two circuits together, as described in
[LINKING_CIRCUITS], [LINKING_EXIT], and [LINKING_SERVICE].

For ease of explanation, the primary circuit is the circuit with lower
RTT, and the secondary circuit is the circuit with higher RTT. Initial
RTT is measured during circuit linking, as described in
[LINKING_CIRCUITS].  RTT is continually measured using SENDME timing, as
in Proposal 324.  This means that during use, the primary circuit and
secondary circuit may switch roles, depending on unrelated network
congestion caused by other Tor clients.

We also support linking onion service circuits together. In this case,
only two rendezvous circuits are linked. Each of these RP circuits will
be constructed separately, and then linked. However, the same path
constraints apply to each half of the circuits (no shared relays between
the legs).  Should, by chance, the service and the client sides end up
sharing some relays, this is not catastrophic. Multipath TCP researchers
we have consulted believe Tor's congestion control from Proposal 324 to
be sufficient in this rare case.

Only two circuits SHOULD be linked together. However, implementations
SHOULD make it easy for researchers to *test* more than two paths, as
this has been shown to assist in traffic analysis resistance[WTF_SPLIT].
At minimum, this means not hardcoding only two circuits in the
implementation.

If the number of circuits exceeds the current number of guard relays,
guard relays MAY be re-used, but implementations SHOULD use the same
number of Guards as paths.

Linked circuits MUST NOT be extended further once linked (ie:
'cannibalization' is not supported).

2.1. Advertising support for conflux

We propose a new protocol version in order to advertise support for
circuit linking on the relay side:

   "Relay=4" -- Relay supports an 2 byte sequence number in a RELAY cell
                header used for multipath circuit which are linked with the
                new RELAY_CIRCUIT_LINK relay cell command.

XXX: Advertise this in onion service descriptor.
XXX: Onion service descriptor can advertise more than two circuits?

The next section describes how the circuits are linked together.

2.2. Linking circuits [LINKING_CIRCUITS]

To link circuits, we propose new relay commands that are sent on both
circuits, as well as a response to confirm the join, and an ack of this
response. These commands create a 3way handshake, which allows each
endpoint to measure the initial RTT of each leg upon link, without
needing to wait for any data.

All three stages of this handshake are sent on *each* circuit leg to be
linked.

To save round trips, these cells SHOULD be combined with the initial
RELAY_BEGIN cell on the faster circuit leg, using Proposal 325. See
[LINKING_EXIT] and [LINKING_SERVICE] for more details on setup in each
case.

There are other ways to do this linking that we have considered, but
they seem not to be significantly better than this method, especially
since we can use Proposal 325 to eliminate the RTT cost of this setup
before sending data. For those other ideas, see [ALTERNATIVE_LINKING]
and [ALTERNATIVE_RTT], in the appendix.

The first two parts of the handshake establish the link, and enable
resumption:

   16 -- RELAY_CIRCUIT_LINK

         Sent from the OP to the exit/service in order to link
         circuits together at the end point.

   17 -- RELAY_CIRCUIT_LINKED

         Sent from the exit/service to the OP, to confirm the circuits
         were linked.

These cells have the following contents:

  VERSION   [1 byte]
  PAYLOAD   [variable, up to end of relay payload]

The VERSION tells us which circuit linking mechanism to use. At this
point in time, only 0x01 is recognized and is the one described by the
Conflux design.

For version 0x01, the PAYLOAD contains:

   NONCE              [32 bytes]
   LAST_SEQNO_SENT    [8 bytes]
   LAST_SEQNO_RECV    [8 bytes]

XXX: Should we let endpoints specify their preferred [SCHEDULING] alg
here, to override consensus params? This has benefits: eg low-memory
mobile clients can ask for an alg that is better for their reorder
queues. But it also has complexity risk, if the other endpoint does not
want to support it, because of its own memory issues.

The NONCE contains a random 256-bit secret, used to associate the two
circuits together. The nonce must not be shared outside of the circuit
transmission, or data may be injected into TCP streams. This means it
MUST NOT be logged to disk.

The two sequence number fields are 0 upon initial link, but non-zero in
the case of a resumption attempt (See [RESUMPTION]).

If either circuit does not receive a RELAY_CIRCUIT_LINKED response, both
circuits MUST be closed.

The third stage of the handshake exists to help the exit/service measure
initial RTT, for use in [SCHEDULING]:

   18 -- RELAY_CIRCUIT_LINKED_RTT_ACK

         Sent from the OP to the exit/service, to provide initial RTT
         measurement for the exit/service.

For timeout of the handshake, clients should use the normal SOCKS/stream
timeout already in use for RELAY_BEGIN.

These three relay commands (RELAY_CIRCUIT_LINK, RELAY_CIRCUIT_LINKED,
and RELAY_CIRCUIT_LINKED_ACK) are send on *each* leg, to allow each
endpoint to measure the initial RTT of each leg.

2.2. Linking Circuits from OP to Exit [LINKING_EXIT]

To link exit circuits, two circuits to the same exit are built. The
client records the circuit build time of each.

If the circuits are being built on-demand, for immediate use, the
circuit with the lower build time SHOULD use Proposal 325 to append its
first RELAY cell to the RELAY_COMMAND_LINK, on the circuit with the
lower circuit build time. The exit MUST respond on this same leg.  After
that, actual RTT measurements MUST be used to determine future
transmissions, as specified in [SCHEDULING].

The RTT times between RELAY_COMMAND_LINK and RELAY_COMMAND_LINKED are
measured by the client, to determine each circuit RTT to determine
primary vs secondary circuit use, and for packet scheduling.  Similarly,
the exit measures the RTT times between RELAY_COMMAND_LINKED and
RELAY_COMMAND_LINKED_ACK, for the same purpose.

2.3. Linking circuits to an onion service [LINKING_SERVICE]

For onion services, we will only concern ourselves with linking
rendezvous circuits.

To join rendezvous circuits, clients make two introduce requests to a
service's intropoint, causing it to create two rendezvous circuits, to
meet the client at two separate rendezvous points. These introduce
requests MUST be sent to the same intropoint (due to potential use of
onionbalance), and SHOULD be sent back-to-back on the same intro
circuit. They MAY be combined with Proposal 325.

The first rendezvous circuit to get joined SHOULD use Proposal 325 to
append the RELAY_BEGIN command, and the service MUST answer on this
circuit, until RTT can be measured.

Once both circuits are linked and RTT is measured, packet scheduling
should be used, as per [SCHEDULING].

2.4. Congestion Control Application [CONGESTION_CONTROL]

The SENDMEs for congestion control are performed per-leg. As data
arrives, regardless of its ordering, it is counted towards SENDME
delivery. In this way, 'cwnd - package_window' of each leg always
reflects the available data to send on each leg. This is important for
[SCHEDULING].

The Congestion control Stream XON/XOFF can be sent on either leg, and
applies to the stream's transmission on both legs.

2.5. Sequencing [SEQUENCING]

With multiple paths for data, the problem of data re-ordering appears.
In other words, cells can arrive out of order from the two circuits
where cell N + 1 arrives before the cell N.

Handling this reordering operates after congestion control for each
circuit leg, but before relay cell command processing or stream data
delivery.

For the receiver to be able to reorder the receiving cells, a sequencing
scheme needs to be implemented. However, because Tor does not drop or
reorder packets inside of a circuit, this sequence number can be very
small. It only has to signal that a cell comes after those arriving on
another circuit.

To achieve this, we add a small sequence number to the common relay
header for all relay cells on linked circuits. This sequence number is
meant to signal the number of cells sent on the *other* leg, so that
each endpoint knows how many cells are still in-flight on another leg.
It is different from the absolute sequence number used in
[LINKING_CIRCUITS] and [RESUMPTION], but can be derived from that
number, using relative arithmetic.

  Relay command   [1 byte]
  Recognized      [2 bytes]
  StreamID        [2 bytes]
  Digest          [4 bytes]
  Length          [2 bytes]
&gt; LongSeq         [1 bit]  # If this bit is set, use 31 bits for Seq
&gt; Sequencing      [7 or 31 bits]
  Data            [Remainder]

The sequence number is only set for the first cell after the endpoint
switches legs. In this case, LongSeq is set to 1, and the Sequencing
field is 31 more bits. Otherwise it is a 1 byte 0 value.

These fields MUST be present on ALL end-to-end relay cells on each leg
that come from the endpoint, following a RELAY_CIRCUIT_LINK command.

They are absent on 'leaky pipe' RELAY_COMMAND_DROP and
RELAY_COMMAND_PADDING_NEGOTIATED cells that come from middle relays, as
opposed to the endpoint, to support padding.

When an endpoint switches legs, on the first cell in a new leg, LongSeq
is set to 1, and the following 31 bits represent the *total* number of
cells sent on the *other* leg, before the switch. The receiver must wait
for that number of cells to arrive from the previous leg before
delivering that cell.

XXX: In the rare event that we send more than 2^31 cells (~1TB) on a
single leg, do we force a switch of legs, or expand the field further?

An alternative method of sequencing, that assumes that the endpoint
knows when it is going to switch, the cell before it switches, is
specified in [ALTERNATIVE_SEQUENCING]. Note that that method requires
only 1 byte for sequence number and switch signaling, but requires that
the sender know that it is planning to switch, the cell before it
switches.  (This is possible with [BLEST_TOR], but [LOWRTT_TOR] can
switch based on RTT change, so it may be one cell late in that case).

2.6. Resumption [RESUMPTION]

In the event that a circuit leg is destroyed, they MAY be resumed.

Resumption is achieved by re-using the NONCE and method to the same
endpoint (either [LINKING_EXIT] or [LINKING_SERVICE]). The resumed path
need not use the same middle and guard relays, but should not share any
relays with any existing legs(s).

To provide resumption, endpoints store an absolute 64bit cell counter of
the last cell they have sent on a conflux pair (their LAST_SEQNO_SENT),
as well the last sequence number they have delivered in-order to edge
connections corresponding to a conflux pair (their LAST_SEQNO_RECV).
Additionally, endpoints MAY store the entire contents of unacked
inflight cells (ie the 'package_window' from proposal 324), for each
leg, along with information corresponding to those cells' absolute
sequence numbers.

These 64 bit absolute counters can wrap without issue, as congestion
windows will never grow to 2^64 cells until well past the Singularity.
However, it is possible that extremely long, bulk circuits could exceed
2^64 total sent or received cells, so endpoints SHOULD handle wrapped
sequence numbers for purposes of computing retransmit information. (But
even this case is unlikely to happen within the next decade or so).

Upon resumption, the LAST_SEQNO_SENT and LAST_SEQNO_RECV fields are used
to convey the sequence numbers of the last cell the relay sent and
received on that leg. The other endpoint can use these sequence numbers
to determine if it received the in-flight data or not, or sent more data
since that point, up to and including this absolute sequence number. If
LAST_SEQNO_SENT has not been received, the endpoint MAY transmit the
missing data, if it still has it buffered.

Because both endpoints get information about the other side's absolute
SENT sequence number, they will know exactly how many re-transmitted
packets to expect, should the circuit stay open. Re-transmitters should
not re-increment their absolute sent fields while re-transmitting.

If it does not have this missing data due to memory pressure, that
endpoint should destroy *both* legs, as this represents unrecoverable
data loss.

Otherwise, the new circuit can be re-joined, and its RTT can be compared
to the remaining circuit to determine if the new leg is primary or
secondary.

It is even possible to resume conflux circuits where both legs have been
collapsed using this scheme, if endpoints continue to buffer their
unacked package_window data for some time after this close. However, see
[TRAFFIC_ANALYSIS] for more details on the full scope of this issue.

If endpoints are buffering package_window data, such data should be
given priority to be freed in any oomkiller invocation. See [MEMORY_DOS]
for more oomkiller information.


3. Traffic Scheduling [SCHEDULING]

In order to load balance the traffic between the two circuits, the
original conflux paper used only RTT. However, with Proposal 324, we
will have accurate information on the instantaneous available bandwidth
of each circuit leg, as 'cwnd - package_window' (see Section 3 of
Proposal 324).

Some additional RTT optimizations are also useful, to improve
responsiveness and minimize out-of-order queue sizes.

We specify two traffic schedulers from the multipath literature and
adapt them to Tor: [LOWRTT_TOR] and [BLEST_TOR]. [LOWRTT_TOR] also has
three variants, with different trade offs.

However, see the [TRAFFIC_ANALYSIS] sections of this proposal for
important details on how this selection can be changed, to reduce
website traffic fingerprinting.

3.1. LowRTT Scheduling [LOWRTT_TOR]

This scheduling algorithm is based on the original [CONFLUX] paper, with
ideas from [MPTCP]'s minRTT/LowRTT scheduler.

In this algorithm, endpoints send cells on the circuit with lower RTT
(primary circuit). This continues while the congestion window on the
circuit has available room: ie whenever cwnd - package_window &gt; 0.

Whenever the primary circuit's congestion window becomes full, the
secondary circuit is used. We stop reading on the send window source
(edge connection) when both congestion windows become full.

In this way, unlike original conflux, we switch to the secondary circuit
without causing congestion on the primary circuit. This improves both
load times, and overall throughput.

This behavior matches minRTT from [MPTCP], sometimes called LowRTT.

It may be better to stop reading on the edge connection when the primary
congestion window becomes full, rather than switch to the secondary
circuit as soon as the primary congestion window becomes full. (Ie: only
switch if the RTTs themselves change which circuit is primary). This is
what was done in the original Conflux paper. This behavior effectively
causes us to optimize for responsiveness and congestion avoidance,
rather than throughput. For evaluation, we should control this switching
behavior with a consensus parameter (see [CONSENSUS_PARAMETERS]).

Because of potential side channel risk (see [SIDE_CHANNELS]), a third
variant of this algorithm, where the primary circuit is chosen during
the [LINKING_CIRCUITS] handshake and never changed, should also be
possible to control via consensus parameter.

3.2. BLEST Scheduling [BLEST_TOR]

[BLEST] attempts to predict the availability of the primary circuit, and
use this information to reorder transmitted data, to minimize
head-of-line blocking in the recipient (and thus minimize out-of-order
queues there).

BLEST_TOR uses the primary circuit until the congestion window is full.
Then, it uses the relative RTT times of the two circuits to calculate
how much data can be sent on the secondary circuit faster than if we
just waited for the primary circuit to become available.

This is achieved by computing two variables at the sender:

  rtts = secondary.currRTT / primary.currRTT
  primary_limit = primary.cwnd + (rtts-1)/2)*rtts

Note: This (rtts-1)/2 factor represents anticipated congestion window
growth over this period.. it may be different for Tor, depending on CC
alg.

If primary_limit &lt; secondary.cwnd - (secondary.package_window + 1), then
there is enough space on the secondary circuit to send data faster than
we could than waiting for the primary circuit.

XXX: Note that BLEST uses total_send_window where we use secondary.cwnd
in this check. total_send_window is min(recv_win, CWND). But since Tor
does not use receive windows and intead uses stream XON/XOFF, we only
use CWND. There is some concern this may alter BLEST's buffer
minimization properties, but since receive window should only matter if
the application is slower than Tor, and XON/XOFF should cover that case,
hopefully this is fine.

Otherwise, if the primary_limit condition is not hit, cease reading on
source edge connections until SENDME acks come back.

Here is the pseudocode for this:

  while source.has_data_to_send():
    if primary.cwnd &gt; primary.package_window:
      primary.send(source.get_packet())
      continue

    rtts = secondary.currRTT / primary.currRTT
    primary_limit = (primary.cwnd + (rtts-1)/2)*rtts

    if primary_limit &lt; secondary.cwnd - (secondary.package_window+1):
      secondary.send(source.get_packet())
    else:
      break # done for now, wait for SENDME to free up CWND and restart

Note that BLEST also has a parameter lambda that is updated whenever HoL
blocking occurs. Because it is expensive and takes significant time to
signal this over Tor, we omit this.

XXX: See [REORDER_SIGNALING] section if we want this lambda feedback.

3.3. Reorder queue signaling [REORDER_SIGNALING]

Reordering should be fairly simple task. By following using the sequence
number field in [SEQUENCING], endpoints can know how many cells are
still in flight on the other leg.

To reorder them properly, a buffer of out of order cells needs to be
kept.  On the Exit side, this can quickly become overwhelming
considering ten of thousands of possible circuits can be held open
leading to gigabytes of memory being used. There is a clear potential
memory DoS vector which means that a tor implementation should be able
to limit the size of those queues.

Luckily, [BLEST_TOR] and the form of [LOWRTT_TOR] that only uses the
primary circuit will minimize or eliminate this out-of-order buffer.

XXX: The remainder of this section may be over-complicating things... We
only need these concepts if we want to use BLEST's lambda feedback.

The default for this queue size is governed by the 'cflx_reorder_client'
and 'cflx_reorder_srv' consensus parameters (see [CONSENSUS_PARAMS]).
'cflx_reorder_srv' applies to Exits and onion services. Both parameters
can be overridden by Torrc, to larger or smaller than the consensus
parameter. (Low memory clients may want to lower it; SecureDrop onion
services or other high-upload services may want to raise it).

When the reorder queue hits this size, a RELAY_CONFLUX_XOFF is sent down
the circuit leg that has data waiting in the queue and use of that leg
must cease, until it drains to half of this value, at which point an
RELAY_CONFLUX_XON is sent. Note that this is different than the stream
XON/XOFF from Proposal 324.

XXX: [BLEST] actually does not cease use of a path in this case, but
instead uses this signal to adjust the lambda parameter, which biases
traffic away from that leg.


4. Security Considerations

4.1. Memory Denial of Service [MEMORY_DOS]

Both reorder queues and retransmit buffers inherently represent a memory
denial of service condition.

For [RESUMPTION] retransmit buffers, endpoints that support this feature
SHOULD free retransmit information as soon as they get close to memory
pressure. This prevents resumption while data is in flight, but will not
otherwise harm operation.

For reorder buffers, adversaries can potentially impact this at any
point, but most obviously and most severely from the client position.

In particular, clients can lie about sequence numbers, sending cells
with sequence numbers such that the next expected sequence number is
never sent. They can do this repeatedly on many circuits, to exhaust
memory at exits.

One option is to only allow actual traffic splitting in the downstream
direction, towards clients, and always use the primary circuit for
everything in the upstream direction. However, the ability to support
conflux from the client to the exit shows promise against traffic
analysis (see [WTF_SPLIT]).

The other option is to use [BLEST_TOR] from clients to exits, as it has
predictable interleaved cell scheduling, and minimizes reorder queues at
exits. If the ratios prescribed by that algorithm are not followed
within some bounds, the other endpoint can close both circuits, and free
the queue memory.

This still leaves the possibility that intermediate relays may block a
leg, allowing cells to traverse only one leg, thus still accumulating at
the reorder queue. Clients can also spoof sequence numbers similarly, to
make it appear that they are following [BLEST_TOR], without actually
sending any data on one of the legs.

To handle either of these cases, when a relay is under memory pressure,
the circuit OOM killer SHOULD free and close circuits with the oldest
reorder queue data, first. This heuristic was shown to be best during
the [SNIPER] attack OOM killer iteration cycle.

4.2. Side Channels [SIDE_CHANNELS]

Two potential side channels may be introduced by the use of Conflux:
   1. RTT leg-use bias by altering SENDME latency
   2. Location info leaks through the use of both leg's latencies

For RTT and leg-use bias, Guard relays could delay legs to introduce a
pattern into the delivery of cells at the exit relay, by varying the
latency of SENDME cells (every 100th cell) to change the distribution of
traffic to send information. This attack could be performed in either
direction of traffic, to bias traffic load off of a particular Guard.
If an adversary controls both Guards, it could in theory send a binary
signal more easily, by alternating delays on each.

However, this risk weighs against the potential benefits against traffic
fingerprinting, as per [WTF_SPLIT]. Additionally, even ignoring
cryptographic tagging attacks, this side channel provides significantly
lower information over time than inter-packet-delay based side channels
that are already available to Guards and routers along the path to the
Guard.

Tor currently provides no defenses against already existing
single-circuit delay-based side channels, though both circuit padding
and [BACKLIT] are potential options it could conceivably deploy. The
[BACKLIT] paper also has an excellent review of the various methods that
have been studied for such single circuit side channels, and the
[BACKLIT] style RTT monitoring could be used to protect against these
conflux side channels as well. Circuit padding can also help to obscure
which cells are SENDMEs, since circuit padding is not counted towards
SENDME totals.

The second class of side channel is where the Exit relay may be able to
use the two legs to further infer more information about client
location. See [LATENCY_LEAK] for more details. It is unclear at this
time how much more severe this is for two paths than just one.

We should preserve the ability to disable conflux to and from Exit
relays, should these side channels prove more severe, or should it prove
possible to mitigate single-circuit side channels, but not conflux side
channels.

In all cases, all of these side channels appear less severe for onion
service traffic, due to the higher path variability due to relay
selection, as well as the end-to-end nature of conflux in that case.
This indicates that our ability to enable/disable conflux for services
should be separate from Exits.

4.3. Traffic analysis [TRAFFIC_ANALYSIS]

Even though conflux shows benefits against traffic analysis in
[WTF_SPLIT], these gains may be moot if the adversary is able to perform
packet counting and timing analysis at guards to guess which specific
circuits are linked.  In particular, the 3 way handshake in
[LINKING_CIRCUITS] may be quite noticeable.

As one countermeasure, it may be possible to eliminate the third leg
(RELAY_CIRCUIT_LINKED_ACK) by computing the exit/service RTT via
measuring the time between CREATED/REND_JOINED and RELAY_CIRCUIT_LINK,
but this will introduce cross-component complexity into Tor's protocol
that could quickly become unwieldy and fragile.

Additionally, the conflux handshake may make onion services stand out
more, regardless of the number of stages in the handshake. For this
reason, it may be more wise to simply address these issues with circuit
padding machines during circuit setup (see padding-spec.txt).

Additional traffic analysis considerations arise when combining conflux
with padding, for purposes of mitigating traffic fingerprinting. For
this, it seems wise to treat the packet schedulers as another piece of a
combined optimization problem in tandem with optimizing padding
machines, perhaps introducing randomness or fudge factors their
scheduling, as a parameterized distribution. For details, see
https://github.com/torproject/tor/blob/master/doc/HACKING/CircuitPaddingDevelopment.md


Finally, conflux may exacerbate forms of confirmation-based traffic
analysis that close circuits to determine concretely if they were in
use, since closing either leg might cause resumption to fail. TCP RST
injection can perform this attack on the side, without surveillance
capability. [RESUMPTION] with buffering of the inflight unacked
package_window data, for retransmit, is a partial mitigation, if
endpoints buffer this data for retransmission for a brief time even if
both legs close. This seems more feasible for onion services, which are
more vulnerable to this attack. However, if the adversary controls the
client, they will notice the resumption re-link, and still obtain
confirmation that way.

It seems the only way to fully mitigate these kinds of attacks is with
the Snowflake pluggable transport, which provides its own resumption and
retransmit behavior. Additionally, Snowflake's use of UDP DTLS also
protects against TCP RST injection, which we suspect to be the main
vector for such attacks.

In the future, a DTLS or QUIC transport for Tor such as masque could
provide similar RST injection resistance, and resumption at Guard/Bridge
nodes, as well.


5. System Interactions

  - congestion control
  - EWMA and KIST
  - CBT and number of guards
  - Onion service circ obfuscation
  - Future UDP (may increase need for UDP to buffer before dropping)
  - Padding (no sequence numbers on padding cells, as per [SEQUENCING])
    - Also, any padding machines may need re-tuning
  - No 'cannibalization' of linked circuits


6. Consensus and Torrc Parameters [CONSENSUS]

  - conflux_circs
    - Number of conflux circuits

  - conflux_sched_exits, conflux_sched_clients, conflux_sched_service
    - Three forms of LOWRTT_TOR, and BLEST_TOR

  - ConfluxOnionService
  - ConfluxOnionCircs


7. Tuning Experiments [EXPERIMENTS]

  - conflux_sched &amp; conflux_exits
    - Exit reorder queue size
    - Responsiveness vs throughput tradeoff?
  - Congestion control
  - EWMA and KIST
  - num guards &amp; conflux_circs


Appended A [ALTERNATIVES]

A.1 BEGIN/END sequencing [ALTERNATIVE_SEQUENCING]

In this method of signaling, we increment the sequence number by 1 only
when we switch legs, and use BEGIN/END "bookends" to know that all data
on a leg has been received.

To achieve this, we add a small sequence number to the common relay
header for all relay cells on linked circuits, as well as a field to
signal the beginning of a sequence, intermediate data, and the end of a
sequence.

  Relay command   [1 byte]
  Recognized      [2 bytes]
  StreamID        [2 bytes]
  Digest          [4 bytes]
  Length          [2 bytes]
&gt; Switching       [2 bits]    # 01 = BEGIN, 00 = CONTINUE, 10 = END
&gt; Sequencing      [6 bits]
  Data            [PAYLOAD_LEN - 12 - Length bytes]

These fields MUST be present on ALL end-to-end relay cells on each leg
that come from the endpoint, following a RELAY_CIRCUIT_LINK command.

They are absent on 'leaky pipe' RELAY_COMMAND_DROP and
RELAY_COMMAND_PADDING_NEGOTIATED cells that come from middle relays, as
opposed to the endpoint, to support padding.

Sequence numbers are incremented by one when an endpoint switches legs
to transmit a cell. This number will wrap; implementations should treat
0 as the next sequence after 2^6-1. Because we do not expect to support
significantly more than 2 legs, and much fewer than 63, this is not an
issue.

The first cell on a new circuit MUST use the BEGIN code for switching.
Cells are delivered from that circuit until an END switching signal is
received, even if cells arrive first on another circuit with the next
sequence number before and END switching field. Recipients MUST only
deliver cells with a BEGIN, if their Sequencing number is one more than
the last END.

A.2 Alternative Link Handshake [ALTERNATIVE_LINKING]

The circuit linking in [LINKING_CIRCUITS] could be done as encrypted
ntor onionskin extension fields, similar to those used by v3 onions.

This approach has at least four problems:
  i). For onion services, since onionskins traverse the intro circuit
      and return on the rend circuit, this handshake cannot measure
      RTT there.
 ii). Since these onionskins are larger, and have no PFS, an adversary
      at the middle relay knows that the onionskin is for linking, and
      can potentially try to obtain the onionskin key for attacks on
      the link.
iii). It makes linking circuits more fragile, since they could timeout
      due to CBT, or other issues during construction.
 iv). The overhead in processing this onionskin in onionskin queues
      adds additional time for linking, even in the Exit case, making
      that RTT potentially noisy.

Additionally, it is not clear that this approach actually saves us
anything in terms of setup time, because we can optimize away the
linking phase using Proposal 325, to combine initial RELAY_BEGIN cells
with RELAY_CIRCUIT_LINK.

A.3. Alternative RTT measurement [ALTERNATIVE_RTT]

Instead of measuring RTTs during [LINKING_CIRCUITS], we could create
PING/PONG cells, whose sole purpose is to allow endpoints to measure
RTT.

This was rejected for several reasons. First, during circuit use, we
already have SENDMEs to measure RTT. Every 100 cells (or
'circwindow_inc' from Proposal 324), we are able to re-measure RTT based
on the time between that Nth cell and the SENDME ack. So we only need
PING/PONG to measure initial circuit RTT.

If we were able to use onionskins, as per [ALTERNATIVE_LINKING] above,
we might be able to specify a PING/PONG/PING handshake solely for
measuring initial RTT, especially for onion service circuits.

The reason for not making a dedicated PING/PONG for this purpose is that
it is context-free. Even if we were able to use onionskins for linking
and resumption, to avoid additional data in handshake that just measures
RTT, we would have to enforce that this PING/PONG/PING only follows the
exact form needed by this proposal, at the expected time, and at no
other points.

If we do not enforce this specific use of PING/PONG/PING, it becomes
another potential side channel, for use in attacks such as [DROPMARK].

In general, Tor is planning to remove current forms of context-free and
semantic-free cells from its protocol:
https://gitlab.torproject.org/tpo/core/torspec/-/issues/39

We should not add more.


Appendix B: Acknowledgments

Thanks to Per Hurtig for helping us with the framing of the MPTCP
problem space.

Thanks to Simone Ferlin for clarifications on the [BLEST] paper, and for
pointing us at the Linux kernel implementation.

Extreme thanks goes again to Toke Høiland-Jørgensen, who helped
immensely towards our understanding of how the BLEST condition relates
to edge connection pushback, and for clearing up many other
misconceptions we had.

Finally, thanks to Mashael AlSabah, Kevin Bauer, Tariq Elahi, and Ian
Goldberg, for the original [CONFLUX] paper!


References:

[CONFLUX]
   https://freehaven.net/anonbib/papers/pets2013/paper_65.pdf

[BLEST]

https://olivier.mehani.name/publications/2016ferlin_blest_blocking_estimation_mptcp_scheduler.pdf
  https://opus.lib.uts.edu.au/bitstream/10453/140571/2/08636963.pdf

https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.95/net/mptcp/mptcp_blest.c

[WTF_SPLIT]

https://www.comsys.rwth-aachen.de/fileadmin/papers/2020/2020-delacadena-trafficsliver.pdf


[COUPLED]
   https://datatracker.ietf.org/doc/html/rfc6356

https://www.researchgate.net/profile/Xiaoming_Fu2/publication/230888515_Delay-based_Co \
ngestion_Control_for_Multipath_TCP/links/54abb13f0cf2ce2df668ee4e.pdf?disableCoverPage=true
  http://staff.ustc.edu.cn/~kpxue/paper/ToN-wwj-2020.04.pdf
   https://www.thinkmind.org/articles/icn_2019_2_10_30024.pdf
   https://arxiv.org/pdf/1308.3119.pdf

[BACKLIT]
   https://www.freehaven.net/anonbib/cache/acsac11-backlit.pdf

[LATENCY_LEAK]
   https://www.freehaven.net/anonbib/cache/ccs07-latency-leak.pdf
   https://www.robgjansen.com/publications/howlow-pets2013.pdf

[SNIPER]
   https://www.freehaven.net/anonbib/cache/sniper14.pdf

[DROPMARK]
   https://www.freehaven.net/anonbib/cache/sniper14.pdf


-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210328175634</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2021-03-28 17:56:34-0400</timestampReceived><subject>[tor-dev] My tool I made which makes running relays on Windows very simple.</subject><body>

[Attachment #2 (multipart/alternative)]


Hi all,

So this is a tool I developed for tor which makes running relays on Windows
very simple.

https://www.youtube.com/watch?v=Vpk6yvUWQqU

Features:

Example torrc file which can be configured as wanted.

Automatically checks if tor is running the newest version on startup, if
not updates to newest version.

One button configuration to configure relay to start when Windows starts.

Generates a tor log file which can tell tor messages.

Drawbacks:

Only supports vanilla bridges.

Configures Windows Defender Firewall automatically to allow tor traffic,
but other firewalls will need to be manually configured.

Cheers.


--Keifer

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi all,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;So this is a tool I developed for tor which \
makes running relays on Windows very simple.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://www.youtube.com/watch?v=Vpk6yvUWQqU"&gt;https://www.youtube.com/watch?v=Vpk6yvUWQqU&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Features:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Example \
torrc file which can be configured  as wanted.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Automatically \
checks if tor is running the newest version on startup, if not updates to newest \
version.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;One button configuration  to configure relay to \
start when Windows starts.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Generates a tor log file which \
can tell tor messages.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Drawbacks:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Only \
supports vanilla bridges.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Configures Windows Defender \
Firewall automatically to allow tor traffic, but other firewalls will need to be \
manually configured.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cheers.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br \
clear="all"&gt;&lt;div&gt;&lt;div dir="ltr" class="gmail_signature" \
data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210202124616</emailId><senderName>Jithin S</senderName><senderEmail>jithins@iiitd.ac.in</senderEmail><timestampReceived>2021-02-02 12:46:16-0400</timestampReceived><subject>[tor-dev] (no subject)</subject><body>

[Attachment #2 (multipart/alternative)]


Hi,

I have recently started running a TOR node with the nickname *CostlyOnion2.
*At the time of writing of this email, the details of the node are as
follows:

*Uptime*: 14 days 3 hours 18 minutes and 0 second
*Advertised Bandwidth*: 3.35 MiB/s
*Flags*:  *Fast  Running  Stable  V2Dir  Valid*
*First Seen*: 2021-01-18 17:00:00 (14 days 19 hours 13 minutes and 32
seconds)
*Last Restarted*: 2021-01-19 08:55:32

For current details, click here
&lt;https://metrics.torproject.org/rs.html#details/19EDB4798A4C170D603F86D8862BC22D55EEAA6D&gt;
.

My concern is how soon we will get a Guard status for our relay. I have
read this &lt;https://blog.torproject.org/lifecycle-new-relay&gt; blog post
regarding the life cycle of a relay. As it says, for a relay aged 8-68 days
to get "Guard" status, we need to keep an eye on three factors *viz.
*bandwidth,
weighted fractional uptime, and time known.  Suppose we keep running the
relay all the time with the above-mentioned bandwidth(3.35 MiB/s), I
would like to know about following


   - How long it will take to get the guard status?
   - My link bandwidth is quite high (close to 50MBytes/s), still the
   advertised is around 3.35MiB/s. What could be the possible factors for this?
   - As I am doing some analysis studies, we would also like to know what
   all factors we should take into account for the users to make use of our
   relay?

I also request you to share any relevant resources for getting more
information regarding the above questions, especially on the calculation of
consensus weight.

Thanks and regards,
Jithin S

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Hi,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I have recently started  running a TOR node \
with the nickname &lt;i&gt;CostlyOnion2. &lt;/i&gt;At the time of writing of this email, the \
details of the node are as follows:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Uptime&lt;/b&gt;:  14 days \
3 hours 18 minutes and 0 second&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Advertised Bandwidth&lt;/b&gt;:  3.35 \
MiB/s&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Flags&lt;/b&gt;:    &lt;i&gt;Fast   Running   Stable   V2Dir   \
Valid&lt;/i&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;First Seen&lt;/b&gt;:  2021-01-18 17:00:00 (14 days 19 hours 13 \
minutes and 32 seconds)&lt;br&gt;&lt;b&gt;Last Restarted&lt;/b&gt;:  2021-01-19 \
08:55:32&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;For current details, click &lt;a \
href="https://metrics.torproject.org/rs.html#details/19EDB4798A4C170D603F86D8862BC22D55EEAA6D"&gt;here&lt;/a&gt;.&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My \
concern is how soon we will get a Guard status for our relay. I have read &lt;a \
href="https://blog.torproject.org/lifecycle-new-relay"&gt;this&lt;/a&gt;  blog post regarding \
the life cycle of a relay. As it says, for a relay aged 8-68 days to get \
"Guard" status, we need to keep an eye on three factors &lt;i&gt;viz. \
&lt;/i&gt;bandwidth, weighted fractional uptime, and time known.    Suppose we keep running \
the relay all the time with the above-mentioned bandwidth(3.35 MiB/s), I would  like \
to know about following  &lt;/div&gt;&lt;blockquote style="margin:0 0 0 \
40px;border:none;padding:0px"&gt;&lt;ul&gt;&lt;li&gt;How long it will take to get the guard status?  \
&lt;/li&gt;&lt;li&gt;My link bandwidth is quite high (close to 50MBytes/s), still the advertised \
is around 3.35MiB/s. What could be the possible factors for this?&lt;/li&gt;&lt;li&gt;As I am \
doing some analysis studies, we would also like to know what all factors we should \
take into account for the users to make use of our \
relay?&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;div&gt;I also request you to share any relevant resources \
for getting more information regarding the above questions, especially on the \
calculation of consensus weight.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks and \
regards,&lt;/div&gt;&lt;div&gt;Jithin S&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210204151045</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-02-04 15:10:45-0400</timestampReceived><subject>[tor-dev] Proposed changes to Tor long-term-support (LTS) policy</subject><body>

Hi, all!

I've been working on a proposed change to Tor's LTS policies. I've run
it by a few people already, and now I'm posting it here for wider
comment.

(summary: If we decide to do this, we will still be able to do LTS
releases, but we will backport fewer things to them, and we will make
fewer promises about how well they will work on the network.)


=====================
# Background and summary:

I'm proposing a change to Tor's long-term support (LTS) policies.

For reference, our current policy is described at
https://gitlab.torproject.org/tpo/core/team/-/wikis/NetworkTeam/CoreTorReleases

We've been struggling with our LTS policies for a while.  In brief: we
backport too many fixes, and we promise too much support for LTS
releases.

The developers don't like it, because the amount of things that we keep
trying to fix in our LTS releases keeps us working on old crufty code
for a long time.

Many packagers don't like it, because they have a policy of auditing
security backports, and we backport too much to our LTS releases for
them to audit carefully.

And our network maintenance group doesn't like it, because our
commitment to supporting very old protocol versions keeps us from
implementing performance and security improvements on a rapid schedule,
unless we backport those changes to the LTS releases.

Therefore, we're going to propose these changes:
   - That once a release becomes LTS-only, its code no longer gets
     anything but security patches (narrowly defined), and minimal
     patches to keep it working on the network.

   - We will no longer guarantee that an LTS-only release will work (or
     work well) on the mainline Tor network for its entire LTS
     lifetime.  We'll try to deliver this if we can, but it won't
     be a definite guarantee.

# In more detail

We propose the following release statuses:

   - Development.  (Every series starts out in this state as an alpha.)

   - Stable.  (Once a series is officially 'ready', we call it stable.)

   - Old-stable.  (Every supported stable release, except the most
     recent one, is in this state.)

   - Long-term support only. (Any LTS release, once a newer release
     has become old-stable.  Only certain releases will get LTS support.)

Every series starts out in "development".  Once it's officially
ready, we call it "stable".  All stable releases besides the most
recent one are "old-stable".

Allowed in all releases:
   - Updates to authorities list
   - Updates to fallbackdirs list
   - Updates to geoip database

LTS-only (any LTS release, once an newer release is oldstable):
   - Only two kinds of changes are allowed:
       - Security fixes, narrowly defined. (See below for a definition.)
       - _Simple_ patches that keep the release functional on the
         network.
   - Relays are not guaranteed to be supported on the network,
     although we'll try not to remove them gratuitously.
   - Clients and onion services are not guaranteed to work on the
     network, although we'll try not to break them gratuitously.

In other words, with an LTS release there will be no guarantee that the
software works on the network.  The promise is that we will keep it
working on the network when we can do so with simple low-risk patches,
and that _if_ it works, we will fix security problems in it.

Oldstable (All stable releases besides the most recent stable release):
  - Stability fixes are also allowed.
  - Relays will be supported on the network.
  - Clients and onion services will be supported on the network.
  - Dirauths may be supported.

Stable (The single most recent stable release):
  - All fixes are allowed.
  - Relays will be supported on the network.
  - Clients and onion services will be supported on the network.
  - Dirauths will be supported.

Development:
  - All fixes are allowed.
  - Relays will be supported on the network.
  - Clients and onion services will be supported on the network.
  - Dirauths will be supported.

==============================

What is a security fix?
  - It is a _bugfix_ that resolves a vulnerability.  _Features_ that
    make Tor more private, anonymous, or more secure won't count.

==============================

The LTS policy above will apply to 0.3.5 _starting with 0.3.5.14_, since
we've already made backports that will appear in 0.3.5.13.

We have already committed to making 0.3.5 an LTS release until Feb 1,
2022.

We also now commit to making 0.4.5 an LTS release until _at least_ Feb
15, 2023. Whether we continue to do this LTS for longer will depend on
our experiences with this new policy.

==============================

So, any proposed amendments to this?

best wishes,
-- 
Nick
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210210180848</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2021-02-10 18:08:48-0400</timestampReceived><subject>[tor-dev] Proposal 330: Modernizing authority contact entries</subject><body>

(I'm using 330 for this proposal, since 329 is reserved for conflux.)

```
Filename: 330-authority-contact.md
Title: Modernizing authority contact entries
Author: Nick Mathewson
Created: ---
Status: Draft
```

This proposal suggests changes to interfaces used to describe a
directory authority, to better support load balancing and
denial-of-service resistance.

(In an appendix, it also suggests an improvement to the description of
authority identity keys, to avoid a deprecated cryptographic algorithm.)

# Background

There are, broadly, three good reasons to make a directory request to a Tor
directory authority:

   - As a relay, to publish a new descriptor.
   - As another authority, to perform part of the voting and consensus
     protocol.
   - As a relay, to fetch a consensus or a set of (micro)descriptors.

There are some more reasons that are OK-ish:
   - as a bandwidth authority or similar related tool running under the
     auspices of an authority.
   - as a metrics tool, to fetch directory information.
   - As a liveness checking tool, to make sure the authorities are running.

There are also a number of bad reasons to make a directory request to a
Tor directory authority.

   - As a client, to download directory information.  (_Clients should
     instead use a directory guard, or a fallback directory if
     they don't know any directory information at all._)
   - As a tor-related application, to download directory information.
     (_Such applications should instead run a tor client, which can
     maintain an up-to-date directory much more efficiently._)


Currently, Tor provides two mechanisms for downloading and uploading directory
information: the DirPort, and the BeginDir command.  A DirPort is an
HTTP port on which directory information is served.  The BeginDir
command is a relay command that is used to send an HTTP stream directly
over a Tor circuit.

Historically, we used DirPort for all directory requests.  Later, when
we needed encrypted or anonymous directory requests, we moved to a
"Begin-over-tor" approach, and then to BeginDir.  We still use the
DirPort directly, however, when relays are connecting to authorities to
publish descriptors or download fresh directories.  We also use it for
voting.

This proposal suggests that instead of having only a single DirPort,
authorities should be able to expose a separate contact point for each
supported interaction above.  By separating these contact points, we can
impose separate access controls and rate limits on each, to improve the
robustness of the consensus voting process.

Eventually, separate contact points will allow us do even more: we'll be
able to have separate implementations for the upload and download
components of the authorities, and keep the voting component mostly
offline.

# Adding contact points to authorities

Currently, for each directory authority, we ship an authority entry.
For example, the entry describing tor26 is:

    "tor26 orport=443 "
      "v3ident=14C131DFC5C6F93646BE72FA1401C02A8DF2E8B4 "
      "ipv6=[2001:858:2:2:aabb:0:563b:1526]:443 "
      "86.59.21.38:80 847B 1F85 0344 D787 6491 A548 92F9 0493 4E4E B85D",

We extend these lines with optional contact point elements as follows:

   - `upload=http://IP:port/`  A location to publish router descriptors.
   - `download=http://IP:port/`  A location to use for caches when fetching
     router descriptors.
   - `vote=http://IP:port/` A location to use for authorities when voting.

Each of these contact point elements can appear more than once.  If it does,
then it describes multiple valid contact points for a given purpose;
implementations MAY use any of the contact point elements that they recognize
for a given authority.

Implementations SHOULD ignore url schemas that they do not recognize, and
SHOULD ignore hostnames addresses that appear in the place of the IP elements
above. (This will make it easier for us to extend these lists in the future.)

If there is no contact point element for a given type, then implementations
should fall back to using the main IPv4 addr:port, and/or the IPv6 addr:port
if available.

As an extra rule: If more than one authority lists the same upload
point, then uploading a descriptor to that upload point counts as having
uploaded it to all of those authorities.  (This rule will allow multiple
authorities to share an upload point in the future, if they decide to do
so.  We do not need a corresponding rules for voting or downloading,
since every authority participates in voting directly, and since there
is no notion of "downloading from each authority.")

# Authority-side configuration

We add a few flags to DirPort configuration, indicating what kind of requests
are acceptable.

   - `no-voting`
   - `no-download`
   - `no-upload`

These flags remove a given set of possible operations from a given
DirPort.  So for example, an authority might say:

     DirPort 9030 no-download no-upload
     DirPort 9040 no-voting no-upload
     DirPort 9050 no-voting no-download

We can also allow "upload-only" as an alias for "no-voting
no-download", and so on.

Note that authorities would need to keep a legacy dirport around until
all relays have upgraded.

# Bridge authorities

This proposal does not yet apply to bridge authorities, since neither
clients nor bridges connect to bridge authorities over HTTP.  A later
proposal may add a schema that can be used to describe contacting to a
bridge authority via BEGINDIR.

# Example uses

## Example setup: Simple access control and balancing.

Right now the essential functionality of authorities is sometimes
blocked by getting too much load from directory downloads by
non-relays.  To address this we can proceed as follows.  We can have
each relay authority open four separate dirports: One for publishing,
one for voting, one for downloading, and one legacy port.
These can be rate-limited separately, and requests sent to the wrong port
can be rejected.  We could additionally prioritize voting, then uploads,
then downloads.  This could be done either within Tor, or with other IP
shaping tools.

## Example setup: Full authority refactoring

In the future, this system lets us get fancier with our authorities and
how they are factored.  For example, as in proposal 257, an authority could
run upload services, voting, and download services all at
separate locations.

The authorities themselves would be the only ones that needed to use
their voting protocol.  The upload services (run on the behalf of
authorities or groups of authorities) could receive descriptors and do
initial testing on them before passing them on to the authorities.  The
authorities could then vote with one another, and push the resulting
consensus and descriptors to the download services.  This would make the
download services primarily responsible for serving directory
information, and have them take all the load.


# Appendix: Cryptographic extensions to authority configuration

The 'v3ident' element, and the relay identity fingerprint in authority
configuration, are currently both given as SHA1 digests of RSA keys.  SHA1 is
currently deprecated: even though we're only relying on second-preimage
resistance, we should migrate away.

With that in mind, we're adding two more fields to the authority entries:

   - `ed25519-id=BASE64` The ed25519 identity of a the authority when it
      acts as a relay.
   - `v3ident-sha3-256=HEX` The SHA3-256 digest of the authority's v3 signing
      key.

(We use base64 here for the ed25519 key since that's what we use
elsewhere.)
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210213003740</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@torproject.org</senderEmail><timestampReceived>2021-02-13 00:37:40-0400</timestampReceived><subject>Re: [tor-dev] [RFC] Proposal: "Res tokens: Anonymous Credentials for Onion Service DoS Resilience"</subject><body>

On 2/11/21 7:42 PM, Nicholas Hopper wrote:
&gt; 
&gt; Hi George!

Suuuup, fellow Chaum fan! I liked bnymble! It was the least scary of all
of the revocation schemes I've read. At least I could understand the
linkability properties.

Were you at the party when Chaum's patents expired? I forget. I suppose
there probably was more than one of those, too.

&gt; A couple of thoughts about this proposal:
&gt; 
&gt; On Thu, Feb 11, 2021 at 5:36 PM George Kadianakis
&gt; &lt;desnacked@riseup.net&gt; wrote:&gt; ## 4.1. Token issuer setup&gt;
&gt;&gt;   The Issuer creates a set of ephemeral RSA-1024 "issuance keys" that will be
&gt;&gt;   used during the issuance protocol. Issuers will be rotating these ephemeral
&gt;&gt;   keys every 6 hours.
&gt;&gt;
&gt;&gt;   The Issuer exposes the set of active issuance public keys through a REST HTTP
&gt;&gt;   API that can be accessed by visiting /issuers.keys.
&gt;&gt;
&gt;&gt;   Tor directory authorities periodically fetch the issuer's public keys and
&gt;&gt;   vote for those keys in the consensus so that they are readily available by
&gt;&gt;   clients. The keys in the current consensus are considered active, whereas the
&gt;&gt;   ones that have fallen off have expired.
&gt;&gt;
&gt;&gt;   XXX how many issuance public keys are active each time? how does overlapping
&gt;&gt;       keys work? clients and onions need to know precise expiration date for
&gt;&gt;       each key. this needs to be specified and tested for robustness.
&gt;&gt;
&gt;&gt;   XXX every how often does the fetch work? how does the voting work? which
&gt;&gt;       issuers are considered official? specify consensus method.
&gt;&gt;
&gt;&gt;   XXX An alternative approach: Issuer has a long-term ed25519 certification key
&gt;&gt;       that creates expiring certificates for the ephemeral issuance keys. Alice
&gt;&gt;       shows the certificate to the service to prove that the token comes from
&gt;&gt;       an issuer. The consensus includes the long-term certification key of the
&gt;&gt;       issuers to establish ground truth.
&gt;&gt;       This way we avoid the synchronization between dirauths and issuers, and
&gt;&gt;       the multiple overlapping active issuance keys. However, certificates
&gt;&gt;       might not fit in the INTRODUCE1 cell (prop220 certs take 104 bytes on
&gt;&gt;       their own).  Also certificate metadata might create a vector for
&gt;&gt;       linkability attacks between the issuer and the verifier.
&gt;&gt;
&gt;&gt; ## 4.2. Onion service signals ongoing DoS attack
&gt;&gt;
&gt;&gt;   When an onion service is under DoS attack it adds the following line in the
&gt;&gt;   "encrypted" (inner) part of the v3 descriptor as a way to signal to its
&gt;&gt;   clients that tokens are required for gaining access:
&gt;&gt;
&gt;&gt;     "token-required" SP token-type SP issuer-list NL
&gt;&gt;
&gt;&gt;     [At most once]
&gt;&gt;
&gt;&gt;     token-type: Is the type of token supported ("res" for this proposal)
&gt;&gt;     issuer: A comma separated list of issuers which are supported by this onion service
&gt;&gt;
&gt; 
&gt; How are issuers identified?  I ask because of a potential problem noted below...

We debated this and ultimately decided on a REST service that listed
issuer keys, that the dirauths fetch (See Section 4.1 above). We can pin
the TLS key(s) used to auth the request.

&gt;&gt; ### 4.3.1. Client preparation [DEST_DIGEST]
&gt;&gt;
&gt;&gt;   Alice first chooses an issuer supported by the onion service depending on her
&gt;&gt;   preferences by looking at the consensus and her Tor configuration file for
&gt;&gt;   the current list of active issuers.
&gt;&gt;
&gt;&gt;   After picking a supported issuer, she performs the following preparation
&gt;&gt;   before contacting the issuer:
&gt;&gt;
&gt;&gt;   1) Alice extracts the issuer's public key (N,e) from the consensus
&gt;&gt;
&gt;&gt;   2) Alice computes a destination digest as follows:
&gt;&gt;
&gt;&gt;            dest_digest = FDH_N(destination || salt)
&gt;&gt;
&gt;&gt;               where:
&gt;&gt;               - 'destination' is the 32-byte ed25519 public identity key of the destination onion
&gt;&gt;               - 'salt' is a random 32-byte value,
&gt;&gt;
&gt;&gt;   3) Alice samples a blinding factor 'r' uniformly at random from [1, N)
&gt;&gt;
&gt;&gt;   4) Alice computes:
&gt;&gt;            blinded_message = dest_digest * r^e (mod N)
&gt;&gt;
&gt;&gt;   After this phase is completed, Alice has a blinded message that is tailored
&gt;&gt;   specifically for the destination onion service. Alice will send the blinded
&gt;&gt;   message to the Token Issuer, but because of the blinding the Issuer does not
&gt;&gt;   get to learn the dest_digest value.
&gt;&gt;
&gt;&gt;   XXX Is the salt needed? Reevaluate.
&gt; 
&gt; Yes, the salt is needed (or, *some* input besides the destination must
&gt; go into the FDH) otherwise, all (unblinded) tokens signed by a given
&gt; issuance key will be identical.  This would be great for unlinkability
&gt; but not so good for double-spend prevention. :)

Aha! George and I knew we needed to salt our Chaum burgers, but neither
of us could remember why. Such ancient lore. Much teriyaki.

See, this is why we need real cryptographers looking at this stuff!

&gt;&gt;   We propose a new EXT_FIELD_TYPE value:
&gt;&gt;
&gt;&gt;     [02] -- ANON_TOKEN
&gt;&gt;
&gt;&gt;   The EXT_FIELD content format is:
&gt;&gt;
&gt;&gt;        TOKEN_VERSION    [1 byte]
&gt;&gt;        ISSUER_KEY       [4 bytes]
&gt;&gt;        DEST_DIGEST      [32 bytes]
&gt;&gt;        TOKEN            [128 bytes]
&gt;&gt;        SALT             [32 bytes]
&gt;&gt;
&gt;&gt;   where:
&gt;&gt;    - TOKEN_VERSION is the version of the token ([0x01] for Res tokens)
&gt;&gt;    - ISSUER_KEY is the public key of the chosen issuer (truncated to 4 bytes)
&gt;&gt;    - DEST_DIGEST is the 'dest_digest' from above
&gt;&gt;    - TOKEN is the 'token' from above
&gt;&gt;    - SALT is the 32-byte 'salt' added during blinding
&gt; 
&gt; Is it a problem that it is trivial to produce an RSA key with a given
&gt; 4-byte truncation?  (so an adversarial issuer could choose a key to
&gt; match another issuer's keys)  Because you can generate an RSA key with
&gt; a targeted most- or least-significant bytes value in roughly the same
&gt; amount of work that it takes to generate an RSA key at all.  (For
&gt; example, if we are talking about the 4 least-significant bytes: find a
&gt; prime p, then set the 4 least-significant bytes of a candidate q to
&gt; (t*p^{-1} mod 2^{32}) before choosing the rest of q at random)

Well, again, the dirauths will list the full-length issuer fingerprints
in the consensus to determine the actual key, so all we need here is a
key-id hint which key to verify the signature with. Since we don't
expect a lot of issuers, the likelihood of 32bit collision is low. I
suppose we should probably specify that the REST service must reject any
keys that collide key-ids.


-- 
Mike Perry
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210222004543</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-02-22 00:45:43-0400</timestampReceived><subject>Re: [tor-dev] Best way to reload config on Windows?</subject><body>

[Attachment #2 (multipart/alternative)]


thanks!

&gt; On Feb 18, 2021, at 5:30 PM, Keifer Bly &lt;keifer.bly@gmail.com&gt; wrote:
&gt; 
&gt; Well, perhaps this tool will be of use to you:
&gt; 
&gt; https://www.youtube.com/watch?v=Vpk6yvUWQqU \
&gt; &lt;https://www.youtube.com/watch?v=Vpk6yvUWQqU&gt; 
&gt; Something I made to help tor operators on Windows. 
&gt; 
&gt; You can reconfigure tor (by the torrc file) with ease. Cheers.
&gt; --Keifer
&gt; 
&gt; 
&gt; On Thu, Feb 18, 2021 at 9:59 AM Holmes Wilson &lt;h@zbay.llc&gt; wrote:
&gt; Hi everyone,
&gt; 
&gt; We're building a Ricochet-inspired chat app, and there are situations where we want \
&gt; to create a new hidden service URL. On macOS and Linux we can send a SIGHUP to make \
&gt; Tor reload its config. What's the best way to do this on Windows?  
&gt; I found an old issue for this \
&gt; (https://gitlab.torproject.org/tpo/core/tor/-/issues/10052 \
&gt; &lt;https://gitlab.torproject.org/tpo/core/tor/-/issues/10052&gt;) but it looks like it \
&gt; never got addressed.  
&gt; Thoughts?
&gt; 
&gt; Holmes
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org &lt;mailto:tor-dev@lists.torproject.org&gt;
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev \
&gt; &lt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&gt; \
&gt; _______________________________________________ tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;thanks!&lt;br class=""&gt;&lt;div&gt;&lt;br \
class=""&gt;&lt;blockquote type="cite" class=""&gt;&lt;div class=""&gt;On Feb 18, 2021, at 5:30 PM, \
Keifer Bly &lt;&lt;a href="mailto:keifer.bly@gmail.com" \
class=""&gt;keifer.bly@gmail.com&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br \
class="Apple-interchange-newline"&gt;&lt;div class=""&gt;&lt;div dir="ltr" class=""&gt;Well, perhaps \
this tool will be of use to you:&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;a \
href="https://www.youtube.com/watch?v=Vpk6yvUWQqU" \
class=""&gt;https://www.youtube.com/watch?v=Vpk6yvUWQqU&lt;/a&gt;&lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;Something I made to help tor operators on \
Windows. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;You can \
reconfigure tor (by the torrc file) with ease. Cheers.&lt;br clear="all" class=""&gt;&lt;div \
class=""&gt;&lt;div dir="ltr" class="gmail_signature" data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr" class=""&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;br \
class=""&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Thu, Feb 18, \
2021 at 9:59 AM Holmes Wilson &lt;&lt;a href="mailto:h@zbay.llc" \
class=""&gt;h@zbay.llc&lt;/a&gt;&gt; wrote:&lt;br class=""&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" \
style="margin:0px 0px 0px 0.8ex;border-left:1px solid \
rgb(204,204,204);padding-left:1ex"&gt;&lt;div style="overflow-wrap: break-word;" \
class=""&gt;Hi everyone,&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;We're building a \
Ricochet-inspired chat app, and there are situations where we want to create a new \
hidden service URL. On macOS and Linux we can send a SIGHUP to make Tor reload its \
config. What's the best way to do this on Windows? &lt;/div&gt;&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I found an old issue for this (&lt;a \
href="https://gitlab.torproject.org/tpo/core/tor/-/issues/10052" target="_blank" \
class=""&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/10052&lt;/a&gt;) but it looks \
like it never got addressed. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Thoughts?&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Holmes&lt;/div&gt;&lt;/div&gt;_______________________________________________&lt;br \
class=""&gt; tor-dev mailing list&lt;br class=""&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" target="_blank" \
class=""&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br class=""&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank" class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br \
class=""&gt; &lt;/blockquote&gt;&lt;/div&gt;
_______________________________________________&lt;br class=""&gt;tor-dev mailing list&lt;br \
class=""&gt;&lt;a href="mailto:tor-dev@lists.torproject.org" \
class=""&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br \
class=""&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;br \
class=""&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br class=""&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210223215810</emailId><senderName>"Christopher Wood"</senderName><senderEmail>caw@heapingbits.net</senderEmail><timestampReceived>2021-02-23 21:58:10-0400</timestampReceived><subject>Re: [tor-dev]  =?utf-8?q?=5BRFC=5D_Proposal=3A_=22Res_tokens=3A_Anony?=</subject><body>

Nice work, George! In case folks are interested, I wrote up a very similar proposal \
independently:

   https://chris-wood.github.io/draft-wood-cfrg-blind-signatures/draft-wood-cfrg-rsa-blind-signatures.html


Perhaps we should converge? :-)

Best,
Chris

On Thu, Feb 11, 2021, at 3:36 PM, George Kadianakis wrote:
&gt; Hello all,
&gt; 
&gt; after lots of investigation on anonymous credentials, we are glad to
&gt; present you with a draft of the onion services anti-DoS proposal using
&gt; tokens.
&gt; 
&gt; While the basic idea of the proposal should remain reasonably solid,
&gt; there are various XXX sprinkled around the proposal and some of them
&gt; definitely need to be addressed before the proposal becomes truly
&gt; usable.
&gt; 
&gt; We are particularly looking forward to feedback about:
&gt; - Token issuance services
&gt; - The anonymous credential scheme chosen
&gt; - The XXXs and design decisions of the proposal
&gt; 
&gt; Hope you have a pleasant read!
&gt; 
&gt; ---
&gt; 
&gt; ```
&gt; Filename: 331-res-tokens-for-anti-dos.md
&gt; Title: Res tokens: Anonymous Credentials for Onion Service DoS Resilience
&gt; Author: George Kadianakis, Mike Perry
&gt; Created: 11-02-2021
&gt; Status: Draft
&gt; ```
&gt; 
&gt; +--------------+           +------------------+
&gt; &gt; Token Issuer |           | Onion Service    |
&gt; +--------------+           +------------------+
&gt; ^                            ^
&gt; &gt; +----------+        |
&gt; Issuance |  1.    |          |   2.   | Redemption
&gt; +-------&gt;|  Alice   |&lt;-------+
&gt; &gt; &gt; 
&gt; +----------+
&gt; 
&gt; 
&gt; # 0. Introduction
&gt; 
&gt; This proposal specifies a simple anonymous credential scheme based on Blind
&gt; RSA signatures designed to fight DoS abuse against onion services. We call
&gt; the scheme "Res tokens".
&gt; 
&gt; Res tokens are issued by third-party issuance services, and are verified by
&gt; onion services during the introduction protocol (through the INTRODUCE1
&gt; cell).
&gt; 
&gt; While Res tokens are used for denial of service protection in this proposal,
&gt; we demonstrate how they can have application in other Tor areas as well, like
&gt; improving the IP reputation of Tor exit nodes.
&gt; 
&gt; # 1. Motivation
&gt; 
&gt; Denial of service attacks against onion services have been explored 
&gt; in the past
&gt; and various defenses have been proposed:
&gt; - Tor proposal #305 specifies network-level rate-limiting mechanisms.
&gt; - Onionbalance allows operators to scale their onions horizontally.
&gt; - Tor proposal #327 increases the attacker's computational 
&gt; requirements (not implemented yet).
&gt; 
&gt; While the above proposals in tandem should provide reasonable protection
&gt; against many DoS attackers, they fundamentally work by reducing the assymetry
&gt; between the onion service and the attacker. This won't work if the attacker
&gt; is extremely powerful because the assymetry is already huge and cutting it
&gt; down does not help.
&gt; 
&gt; we believe that a proposal based on cryptographic guarantees -- like Res
&gt; tokens -- can offer protection against even extremely strong attackers.
&gt; 
&gt; # 2. Overview
&gt; 
&gt; In this proposal we introduce an anonymous credential scheme -- Res tokens --
&gt; that is well fitted for protecting onion services against DoS attacks. We
&gt; also introduce a system where clients can acquire such anonymous credentials
&gt; from various types of Token Issuers and then redeem them at the onion service
&gt; to gain access even when under DoS conditions.
&gt; 
&gt; In section [TOKEN_DESIGN], we list our requirements from an anonymous
&gt; credential scheme and provide a high-level overview of how the Res token
&gt; scheme works.
&gt; 
&gt; In section [PROTOCOL_SPEC], we specify the token issuance and 
&gt; redemption protocols,
&gt; as well as the mathematical operations that need to be conducted for 
&gt; these to work.
&gt; 
&gt; In section [TOKEN_ISSUERS], we provide a few examples and guidelines for
&gt; various token issuer services that could exist.
&gt; 
&gt; In section [DISCUSSION], we provide more use cases for Res tokens as well as
&gt; future improvements we can conduct to the scheme.
&gt; 
&gt; # 3. Design [TOKEN_DESIGN]
&gt; 
&gt; In this section we will go over the high-level design of the system, and on
&gt; the next section we will delve into the lower-level details of the protocol.
&gt; 
&gt; ## 3.1. Anonymous credentials
&gt; 
&gt; Anonymous credentials or tokens are cryptographic identifiers that allow
&gt; their bearer to maintain an identity while also preserving anonymity.
&gt; 
&gt; Clients can acquire a token in a variety of ways (e.g. registering on a
&gt; third-party service, solving a CAPTCHA, completing a PoW puzzle) and then
&gt; redeem it at the onion service proving this way that work was done, but
&gt; without linking the act of token acquisition with the act of token
&gt; redemption.
&gt; 
&gt; ## 3.2. Anonymous credential properties
&gt; 
&gt; The anonymous credential literature is vast and there are dozens of
&gt; credential schemes with different properties [REF_TOKEN_ZOO], in this section
&gt; we detail the properties we care about for this use case:
&gt; 
&gt; - Public Verifiability: Because of the distributed trust properties of the
&gt; Tor network, we need anonymous credentials that can be issued by one
&gt; party (the token issuer) and verified by a different party (in this case
&gt; the onion service).
&gt; 
&gt; - Perfect unlinkability: Unlinkability between token issuance and token
&gt; redemption is vital in private settings like Tor. For this reason we want
&gt; our scheme to preserve its unlinkability even if its fundamental security
&gt; assumption is broken. We want unlinkability to be protected by
&gt; information theoretic security or random oracle, and not just
&gt; computational security.
&gt; 
&gt; - Small token size: The tokens will be transfered to the service through the
&gt; INTRODUCE1 cell which is not flexible and has only a limited amount of
&gt; space (about 200 bytes) [REF_INTRO_SPACE]. We need tokens to be small.
&gt; 
&gt; - Quick Verification: Onions are already experiencing resource starvation
&gt; because of the DoS attacks so it's important that the process of
&gt; verifying a token should be as quick as possible. In section [TOKEN_PERF]
&gt; we will go deeper into this requirement.
&gt; 
&gt; After careful consideration of the above requirements, we have leaned 
&gt; towards
&gt; using Blind RSA as the primitive for our tokens, since it's the 
&gt; fastest
&gt; scheme by far that also allows public verifiability. See also 
&gt; Appendix B
&gt; [BLIND_RSA_PROOF] for a security proof sketch of Blind RSA perfect 
&gt; unlinkability.
&gt; 
&gt; ## 3.3. Other security considerations
&gt; 
&gt; Apart from the above properties we also want:
&gt; 
&gt; - Double spending protection: We don't want Malory to be able to double spend
&gt; her tokens in various onion services thereby amplifying her attack. For
&gt; this reason our tokens are not global, and can only be redeemed at a
&gt; specific destination onion service.
&gt; 
&gt; - Metadata: We want to encode metadata/attributes in the tokens. In
&gt; particular, we want to encode the destination onion service and an
&gt; expiration date. For more information see section [DEST_DIGEST]. For
&gt; blind RSA tokens this is usually done using "partially blind signatures"
&gt; but to keep it simple we instead encode the destination directly in the
&gt; message to be blind-signed and the expiration date using a set of
&gt; rotating signing keys.
&gt; 
&gt; - One-show: There are anonymous credential schemes with multi-show support
&gt; where one token can be used multiple times in an unlinkable
&gt; fashion. However, that might allow an adversary to use a single token to
&gt; launch a DoS attack, since revocation solutions are complex and
&gt; inefficient in anonymous credentials. For this reason, in this work we
&gt; use one-show tokens that can only be redeemed once. That takes care of
&gt; the revocation problem but it means that a client will have to get more
&gt; tokens periodically.
&gt; 
&gt; ## 3.4. Res tokens overview
&gt; 
&gt; Throughout this proposal we will be using our own token scheme, named "Res",
&gt; which is based on blind RSA signatures. In this modern cryptographic world,
&gt; not only we have the audacity of using Chaum's oldest blind signature scheme
&gt; of all times, but we are also using RSA with a modulus of 1024 bits...
&gt; 
&gt; The reason that Res uses only 1024-bits RSA is because we care most about
&gt; small token size and quick verification rather than the unforgeability of the
&gt; token. This means that if the attacker breaks the issuer's RSA signing key
&gt; and issues tokens for herself, this will enable the adversary to launch DoS
&gt; attacks against onion services, but it won't allow her to link users (because
&gt; of the "perfect unlinkability" property).
&gt; 
&gt; Furthermore, Res tokens get a short implicit expiration date by having the
&gt; issuer rapidly rotate issuance keys every few hours. This means that even if
&gt; an adversary breaks an issuance key, she will be able to forge tokens for
&gt; just a few hours before that key expires.
&gt; 
&gt; For more ideas on future schemes and improvements see section [FUTURE_RES].
&gt; 
&gt; ## 3.5. Token performance requirements [TOKEN_PERF]
&gt; 
&gt; As discussed above, verification performance is extremely important in the
&gt; anti-DoS use case. In this section we provide some concrete numbers on what
&gt; we are looking for.
&gt; 
&gt; In proposal #327 [REF_POW_PERF] we measured that the total time spent by the
&gt; onion service on processing a single INTRODUCE2 cell ranges from 5 msec to 15
&gt; msecs with a mean time around 5.29 msec. This time also includes the launch
&gt; of a rendezvous circuit, but does not include the additional blocking and
&gt; time it takes to process future cells from the rendezvous point.
&gt; 
&gt; We also measured that the parsing and validation of INTRODUCE2 cell ("top
&gt; half") takes around 0.26 msec; that's the lightweight part before the onion
&gt; service decides to open a rendezvous circuit and do all the path selection
&gt; and networking.
&gt; 
&gt; This means that any defenses introduced by this proposal should add minimal
&gt; overhead to the above "top half" procedure, so as to apply access control in
&gt; the lightest way possible.
&gt; 
&gt; For this reason we implemented a basic version of the Res token scheme in
&gt; Rust and benchmarked the verification and issuance procedure [REF_RES_BENCH].
&gt; 
&gt; We measured that the verification procedure from section [RES_VERIFY] takes
&gt; about 0.104 ms, which we believe is a reasonable verification overhead for
&gt; the purposes of this proposal.
&gt; 
&gt; We also measured that the issuance procedure from [RES_ISSUANCE] takes about
&gt; 0.614 ms.
&gt; 
&gt; # 4. Specification [PROTOCOL_SPEC]
&gt; 
&gt; +--------------+           +------------------+
&gt; &gt; Token Issuer |           | Onion Service    |
&gt; +--------------+           +------------------+
&gt; ^                            ^
&gt; &gt; +----------+        |
&gt; Issuance |  1.    |          |   2.   | Redemption
&gt; +-------&gt;|  Alice   |&lt;-------+
&gt; &gt; &gt; 
&gt; +----------+
&gt; 
&gt; ## 4.0. Notation
&gt; 
&gt; Let `a || b` be the concatenation of a with b.
&gt; 
&gt; Let `a^b` denote the exponentiation of a to the bth power.
&gt; 
&gt; Let `a == b` denote a check for equality between a and b.
&gt; 
&gt; Let FDH_N(msg) be a Full Domain Hash (FDH) of 'msg' using SHA256 and
&gt; stretching the digest to be equal to the size of an RSA modulus N.
&gt; 
&gt; ## 4.1. Token issuer setup
&gt; 
&gt; The Issuer creates a set of ephemeral RSA-1024 "issuance keys" that will be
&gt; used during the issuance protocol. Issuers will be rotating these ephemeral
&gt; keys every 6 hours.
&gt; 
&gt; The Issuer exposes the set of active issuance public keys through a REST HTTP
&gt; API that can be accessed by visiting /issuers.keys.
&gt; 
&gt; Tor directory authorities periodically fetch the issuer's public keys and
&gt; vote for those keys in the consensus so that they are readily available by
&gt; clients. The keys in the current consensus are considered active, whereas the
&gt; ones that have fallen off have expired.
&gt; 
&gt; XXX how many issuance public keys are active each time? how does overlapping
&gt; keys work? clients and onions need to know precise expiration date for
&gt; each key. this needs to be specified and tested for robustness.
&gt; 
&gt; XXX every how often does the fetch work? how does the voting work? which
&gt; issuers are considered official? specify consensus method.
&gt; 
&gt; XXX An alternative approach: Issuer has a long-term ed25519 certification key
&gt; that creates expiring certificates for the ephemeral issuance keys. Alice
&gt; shows the certificate to the service to prove that the token comes from
&gt; an issuer. The consensus includes the long-term certification key of the
&gt; issuers to establish ground truth.
&gt; This way we avoid the synchronization between dirauths and issuers, and
&gt; the multiple overlapping active issuance keys. However, certificates
&gt; might not fit in the INTRODUCE1 cell (prop220 certs take 104 bytes on
&gt; their own).  Also certificate metadata might create a vector for
&gt; linkability attacks between the issuer and the verifier.
&gt; 
&gt; ## 4.2. Onion service signals ongoing DoS attack
&gt; 
&gt; When an onion service is under DoS attack it adds the following line in the
&gt; "encrypted" (inner) part of the v3 descriptor as a way to signal to its
&gt; clients that tokens are required for gaining access:
&gt; 
&gt; "token-required" SP token-type SP issuer-list NL
&gt; 
&gt; [At most once]
&gt; 
&gt; token-type: Is the type of token supported ("res" for this proposal)
&gt; issuer: A comma separated list of issuers which are supported by 
&gt; this onion service
&gt; 
&gt; ## 4.3. Token issuance
&gt; 
&gt; When Alice visits an onion service with an active "token-required" line in
&gt; its descriptor it checks whether there are any tokens available for this
&gt; onion service in its token store. If not, it needs to acquire some and hence
&gt; the token issuance protocol commences.
&gt; 
&gt; ### 4.3.1. Client preparation [DEST_DIGEST]
&gt; 
&gt; Alice first chooses an issuer supported by the onion service depending on her
&gt; preferences by looking at the consensus and her Tor configuration file for
&gt; the current list of active issuers.
&gt; 
&gt; After picking a supported issuer, she performs the following preparation
&gt; before contacting the issuer:
&gt; 
&gt; 1) Alice extracts the issuer's public key (N,e) from the consensus
&gt; 
&gt; 2) Alice computes a destination digest as follows:
&gt; 
&gt; dest_digest = FDH_N(destination || salt)
&gt; 
&gt; where:
&gt; - 'destination' is the 32-byte ed25519 public identity 
&gt; key of the destination onion
&gt; - 'salt' is a random 32-byte value,
&gt; 
&gt; 3) Alice samples a blinding factor 'r' uniformly at random from [1, N)
&gt; 
&gt; 4) Alice computes:
&gt; blinded_message = dest_digest * r^e (mod N)
&gt; 
&gt; After this phase is completed, Alice has a blinded message that is tailored
&gt; specifically for the destination onion service. Alice will send the blinded
&gt; message to the Token Issuer, but because of the blinding the Issuer does not
&gt; get to learn the dest_digest value.
&gt; 
&gt; XXX Is the salt needed? Reevaluate.
&gt; 
&gt; ### 4.3.3. Token Issuance [RES_ISSUANCE]
&gt; 
&gt; Alice now initiates contact with the Token Issuer and spends the resources
&gt; required to get issued a token (e.g. solve a CAPTCHA or a PoW, create an
&gt; account, etc.). After that step is complete, Alice sends the blinded_message
&gt; to the issuer through a JSON-RPC API.
&gt; 
&gt; After the Issuer receives the blinded_message it signs it as follows:
&gt; 
&gt; blinded_signature = blinded_message ^ d (mod N)
&gt; 
&gt; where:
&gt; - 'd' is the private RSA exponent.
&gt; 
&gt; and returns the blinded_signature to Alice.
&gt; 
&gt; XXX specify API (JSON-RPC? Needs SSL + pubkey pinning.)
&gt; 
&gt; ### 4.3.4. Unblinding step
&gt; 
&gt; Alice verifies the received blinded signature, and unblinds it to get the
&gt; final token as follows:
&gt; 
&gt; token = blinded_signature * r^{-1} (mod N)
&gt; = blinded_message ^ d * r^{-1] (mod N)
&gt; = (dest_digest * r^e) ^d * r^{-1} (mod N)
&gt; = dest_digest ^ d * r * r^{-1} (mod N)
&gt; = dest_digest ^ d (mod N)
&gt; 
&gt; where:
&gt; - r^{-1} is the multiplicative inverse of the blinding factor 'r'
&gt; 
&gt; Alice will now use the 'token' to get access to the onion service.
&gt; 
&gt; By verifying the received signature using the issuer keys in the consensus,
&gt; Alice ensures that a legitimate token was received and that it has not
&gt; expired (since the issuer keys are still in the consensus).
&gt; 
&gt; ## 4.4. Token redemption
&gt; 
&gt; ### 4.4.1. Alice sends token to onion service
&gt; 
&gt; Now that Alice has a valid 'token' it can request access to the onion
&gt; service. It does so by embedding the token into the INTRODUCE1 cell to the
&gt; onion service.
&gt; 
&gt; To do so, Alice adds an extension to the encrypted portion of the INTRODUCE1
&gt; cell by using the EXTENSIONS field (see [PROCESS_INTRO2] section in
&gt; rend-spec-v3.txt). The encrypted portion of the INTRODUCE1 cell only gets
&gt; read by the onion service and is ignored by the introduction point.
&gt; 
&gt; We propose a new EXT_FIELD_TYPE value:
&gt; 
&gt; [02] -- ANON_TOKEN
&gt; 
&gt; The EXT_FIELD content format is:
&gt; 
&gt; TOKEN_VERSION    [1 byte]
&gt; ISSUER_KEY       [4 bytes]
&gt; DEST_DIGEST      [32 bytes]
&gt; TOKEN            [128 bytes]
&gt; SALT             [32 bytes]
&gt; 
&gt; where:
&gt; - TOKEN_VERSION is the version of the token ([0x01] for Res tokens)
&gt; - ISSUER_KEY is the public key of the chosen issuer (truncated to 4 bytes)
&gt; - DEST_DIGEST is the 'dest_digest' from above
&gt; - TOKEN is the 'token' from above
&gt; - SALT is the 32-byte 'salt' added during blinding
&gt; 
&gt; This will increase the INTRODUCE1 payload size by 199 bytes since the data
&gt; above is 197 bytes, the extension type and length is 2 extra bytes, and the
&gt; N_EXTENSIONS field is always present. According to ticket #33650, INTRODUCE1
&gt; cells currently have more than 200 bytes available so we should be able to
&gt; fit the above fields in the cell.
&gt; 
&gt; XXX maybe we don't need to pass DEST_DIGEST and we can just derive it
&gt; 
&gt; XXX maybe with a bit of tweaking we can even use a 1536-bit RSA 
&gt; signature here...
&gt; 
&gt; ### 4.4.2. Onion service verifies token  [RES_VERIFY]
&gt; 
&gt; Upon receiving an INTRODUCE1 cell with the above extension the service
&gt; verifies the token. It does so as follows:
&gt; 
&gt; 1) The service checks its double spend protection cache for an element that
&gt; matches DEST_DIGEST. If one is found, verification fails.
&gt; 2) The service checks: DEST_DIGEST == FDH_N(service_pubkey || SALT), where
&gt; 'service_pubkey' is its own long-term identity pubkey.
&gt; 3) The service finds the corresponding issuer pubkey 'e' based on ISSUER_KEY
&gt; from the consensus or its configuration file
&gt; 4) The service checks: TOKEN ^ e == DEST_DIGEST
&gt; 
&gt; Finally the onion service adds the DEST_DIGEST to its double spend protection
&gt; cache to avoid the same token getting redeemed twice.  Onion services keep a
&gt; double spend protection cache by maintaining a sorted array of truncated
&gt; DEST_DIGEST elements.
&gt; 
&gt; If any of the above steps fail, the verification process aborts and the
&gt; introduction request gets discarded.
&gt; 
&gt; If all the above verification steps have been completed successfully, the
&gt; service knows that this a valid token issued by the token issuer, and that
&gt; the token has been created for this onion service specifically. The service
&gt; considers the token valid and the rest of the onion service protocol carries
&gt; out as normal.
&gt; 
&gt; # 5. Token issuers [TOKEN_ISSUERS]
&gt; 
&gt; In this section we go over some example token issuers. While we can have
&gt; official token issuers that are supported by the Tor directory authorities,
&gt; it is also possible to have unofficial token issuers between communities that
&gt; can be embedded directly into the configuration file of the onion service and
&gt; the client.
&gt; 
&gt; In general, we consider the design of token issuers to be independent from
&gt; this proposal so we will touch the topic but not go too deep into it.
&gt; 
&gt; ## 5.1. CAPTCHA token issuer
&gt; 
&gt; A use case resembling the setup of Cloudflare's PrivacyPass would be to have
&gt; a CAPTCHA service that issues tokens after a successful CAPTCHA solution.
&gt; 
&gt; Tor Project, Inc runs https://ctokens.torproject.org which serves hCaptcha
&gt; CAPTCHAs. When the user solves a CAPTCHA the server gives back a list of
&gt; tokens. The amount of tokens rewarded for each solution can be tuned based on
&gt; abuse level.
&gt; 
&gt; Clients reach this service via a regular Tor Exit connection, 
&gt; possibly via a
&gt; dedicated exit enclave-like relay that can only connect to 
&gt; https://ctokens.torproject.org.
&gt; 
&gt; Upon receiving tokens, Tor Browser delivers them to the Tor client via the
&gt; control port, which then stores the tokens into a token cache to be used when
&gt; connecting to onion services.
&gt; 
&gt; In terms of UX, most of the above procedure can be hidden from the user by
&gt; having Tor Browser do most of the things under the scenes and only present
&gt; the CAPTCHA to the user if/when needed (if the user doesn't have tokens
&gt; available for that destination).
&gt; 
&gt; XXX specify control port API between browser and tor
&gt; 
&gt; ## 5.2. PoW token issuer
&gt; 
&gt; An idea that mixes the CAPTCHA issuer with proposal#327, would be to have a
&gt; token issuer that accepts PoW solutions and provides tokens as a reward.
&gt; 
&gt; This solution tends to be less optimal than applying proposal#327 directly
&gt; because it doesn't allow us to fine-tune the PoW difficulty based on the
&gt; attack severity; which is something we are able to do with proposal#327.
&gt; 
&gt; However, we can use the fact that token issuance happens over HTTP to
&gt; introduce more advanced PoW-based concepts. For example, we can design token
&gt; issuers that accept blockchain shares as a reward for tokens. For example, a
&gt; system like Monero's Primo could be used to provide DoS protection and also
&gt; incentivize the token issuer by being able to use those shares for pool
&gt; mining [REF_PRIMO].
&gt; 
&gt; ## 5.3. Onion service self-issuing
&gt; 
&gt; The onion service itself can also issue tokens to its users and then use
&gt; itself as an issuer for verification. This way it can reward trusted users by
&gt; giving it tokens for the future. The tokens can be rewarded from within the
&gt; website of the onion service and passed to the Tor Client through the control
&gt; port, or they can be provided in an out-of-bands way for future use
&gt; (e.g. from a journalist to a future source using a QR code).
&gt; 
&gt; Unfortunately, the anonymous credential scheme specified in this proposal is
&gt; one-show, so the onion service cannot provide a single token that will work
&gt; for multiple "logins". In the future we can design multi-show credential
&gt; systems that also have revocation to further facilitate this use case (see
&gt; [FUTURE_RES] for more info).
&gt; 
&gt; # 6. User Experience
&gt; 
&gt; This proposal has user facing UX consequences.
&gt; 
&gt; Ideally we want this process to be invisible to the user and things 
&gt; to "just
&gt; work". This can be achieved with token issuers that don't require 
&gt; manual work
&gt; by the user (e.g. the PoW issuer, or the onion service itself), since 
&gt; both the
&gt; token issuance and the token redemption protocols don't require any 
&gt; manual work.
&gt; 
&gt; In the cases where manual work is needed by the user (e.g. solving a CAPTCHA)
&gt; it's ideal if the work is presented to the user right before visiting the
&gt; destination and only if it's absolutely required. An explanation about the
&gt; service being under attack should be given to the user when the CAPTCHA is
&gt; provided.
&gt; 
&gt; # 7. Security
&gt; 
&gt; In this section we analyze potential security threats of the above system:
&gt; 
&gt; - An evil client can hoard tokens for hours and unleash them all at once to
&gt; cause a denial of service attack. We might want to make the key rotation
&gt; even more frequent if we think that's a possible threat.
&gt; 
&gt; - A trusted token issuer can always DoS an onion service by forging tokens.
&gt; 
&gt; - Overwhelming attacks like "top half attacks" and "hybrid attacks" from
&gt; proposal#327 is valid for this proposal as well.
&gt; 
&gt; - A bad RNG can completely wreck the linkability properties of this proposal.
&gt; 
&gt; XXX Actually analyze the above if we think there is merit to listing them
&gt; 
&gt; # 8. Discussion [DISCUSSION]
&gt; 
&gt; ## 8.1. Using Res tokens on Exit relays
&gt; 
&gt; There are more scenarios within Tor that could benefit from Res tokens
&gt; however we didn't expand on those use cases to keep the proposal short.  In
&gt; the future, we might want to split this document into two proposals: one
&gt; proposal that specifies the token scheme, and another that specifies how to
&gt; use it in the context of onion servicves, so that we can then write more
&gt; proposals that use the token scheme as a primitive.
&gt; 
&gt; An extremely relevant use case would be to use Res tokens as a way to protect
&gt; and improve the IP reputation of Exit relays. We can introduce an exit pool
&gt; that requires tokens in exchange for circuit streams. The idea is that exits
&gt; that require tokens will see less abuse, and will not have low scores in the
&gt; various IP address reputation systems that now govern who gets access to
&gt; websites and web services on the public Internet. We hope that this way we
&gt; will see  less websites blocking Tor.
&gt; 
&gt; ## 8.2. Future improvements to this proposal [FUTURE_RES]
&gt; 
&gt; The Res token scheme is a pragmatic scheme that works for the space/time
&gt; constraints of this use case but it's far from ideal for the greater future
&gt; (RSA? RSA-1024?).
&gt; 
&gt; After Tor proposal#319 gets implemented we will be able to pack more data in
&gt; RELAY cells and that opens the door to token schemes with bigger token
&gt; sizes. For example, we could design schemes based on BBS+ that can provide
&gt; more advanced features like multi-show and complex attributes but currently
&gt; have bigger token sizes (300+ bytes). That would greatly improve UX since the
&gt; client won't have to solve multiple CAPTCHAs to gain access. Unfortunately,
&gt; another problem here is that right now pairing-based schemes have
&gt; significantly worse verification performance than RSA (e.g. in the order of
&gt; 4-5 ms compared to &lt;0.5 ms). We expect pairing-based cryptography performance
&gt; to only improve in the future and we are looking forward to these advances.
&gt; 
&gt; When we switch to a multi-show scheme, we will also need revocation support
&gt; otherwise a single client can abuse the service with a single multi-show
&gt; token. To achieve this we would need to use blacklisting schemes based on
&gt; accumulators (or other primitives) that can provide more flexible revocation
&gt; and blacklisting; however these come at the cost of additional verification
&gt; time which is not something we can spare at this time. We warmly welcome
&gt; research on revocation schemes that are lightweight on the verification side
&gt; but can be heavy on the proving side.
&gt; 
&gt; ## 8.3. Other uses for tokens in Tor
&gt; 
&gt; There is more use cases for tokens in Tor but we think that other token
&gt; schemes with different properties would be better suited for those.
&gt; 
&gt; In particular we could use tokens as authentication mechanisms for logging
&gt; into services (e.g. acquiring bridges, or logging into Wikipedia). However
&gt; for those use cases we would ideally need multi-show tokens with revocation
&gt; support. We can also introduce token schemes that help us build a secure name
&gt; system for onion services.
&gt; 
&gt; We hope that more research will be done on how to combine various token
&gt; schemes together, and how we can maintain agility while using schemes with
&gt; different primitives and properties.
&gt; 
&gt; # 9. Acknowledgements
&gt; 
&gt; Thanks to Jeff Burdges for all the information about Blind RSA and anonymous
&gt; credentials.
&gt; 
&gt; Thanks to Michele Orrù for the help with the unlinkability proof and for the
&gt; discussions about anonymous credentials.
&gt; 
&gt; Thanks to Chelsea Komlo for pointing towards anonymous credentials in
&gt; the context of DoS defenses for onion services.
&gt; 
&gt; ---
&gt; 
&gt; # Appendix A: RSA Blinding Security Proof [BLIND_RSA_PROOF]
&gt; 
&gt; This proof sketch was provided by Michele Orrù:
&gt; 
&gt; ```
&gt; RSA Blind Sigs: 
&gt; https://en.wikipedia.org/wiki/Blind_signature#Blind_RSA_signatures
&gt; 
&gt; As you say, blind RSA should be perfectly blind.
&gt; 
&gt; I tried to look at Boneh-Shoup, Katz-Lindell, and Bellare-Goldwasser 
&gt; for a proof, but didn't find any :(
&gt; 
&gt; The basic idea is proving that:
&gt; for any  message "m0" that is blinded with "r0^e" to obtain "b" (that 
&gt; is sent to the server), it is possible to freely choose another message 
&gt; "m1" that blinded with another opening "r1^e" to obtain the same "b".
&gt; 
&gt; As long as r1, r0 are chosen uniformly at random, you have no way of 
&gt; telling if what message was picked and therefore it is *perfectly* 
&gt; blind.
&gt; 
&gt; To do so:
&gt; Assume the messages ("m0" and "m1") are invertible mod N=pq (this 
&gt; happens at most with overwhelming probability phi(N)/N if m is 
&gt; uniformly distributed as a result of a hash, or you can enforce it at 
&gt; signing time).
&gt; 
&gt; Blinding happens by computing:
&gt; b = m0 * (r0^e).
&gt; 
&gt; However, I can also write:
&gt; b = m0 * r0^e = (m1/m1) * m0 * r0^e = m1 * (m0/m1*r0^e).
&gt; 
&gt; This means that r1 = (m0/m1)^d * r0 is another valid blinding factor 
&gt; for b, and it's distributed exactly as r0 in the group of invertibles 
&gt; (it's unif at random, because r0 is so).
&gt; ```
&gt; 
&gt; ---
&gt; 
&gt; [REF_TOKEN_ZOO]: https://tokenzoo.github.io/
&gt; [REF_INTRO_SPACE]: 
&gt; https://gitlab.torproject.org/legacy/trac/-/issues/33650#note_2350910
&gt; [REF_CHAUM]: https://eprint.iacr.org/2001/002.pdf
&gt; [REF_PRIMO]: https://repo.getmonero.org/selene/primo
&gt; https://www.monerooutreach.org/stories/RPC-Pay.html
&gt; [REF_POW_PERF]: 
&gt; https://gitlab.torproject.org/tpo/core/torspec/-/blob/master/proposals/327-pow-over-intro.txt#L1050
&gt;  [REF_RES_BENCH]: https://github.com/asn-d6/res_tokens_benchmark
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt; 
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210109185618</emailId><senderName>Alexander =?utf-8?B?RsOmcsO4eQ==?=</senderName><senderEmail>ahf@torproject.org</senderEmail><timestampReceived>2021-01-09 18:56:18-0400</timestampReceived><subject>Re: [tor-dev] Has Core Tor Development Slowed? Or Are We Moving To Rust/arti?</subject><body>

Hello Neel,

On 2021/01/08 16:34, Neel Chauhan wrote:
&gt; I hope you all had a great holiday season.

Likewise!

&gt; Sorry if I have been less active in the Tor community as opposed to the
&gt; past. I've been more focused on FreeBSD Ports as of now, but I still want=
 to
&gt; post at least the occasional Tor patch here and there.

Absolutely no need to apologize, Neel, you're one of our more persistent
contributors over the years :-) Hope you enjoy hacking on the FreeBSD
ports tree as well.

&gt; Core Tor/Tor hasn't seen an update since December 21, even when we are
&gt; already a week into 2021.

TPI ("The Company behind Tor") gave everybody some additional amount of
vacation days for this holiday because last year was quite intense for
us all. Some people returned on the 7th and the rest will return on
Monday the 11th. That might explain why nothing have happened yet here
in 2021 :-) Expect operations to normalize next week, hopefully with
recharged batteries ready for 2021 :-)

&gt; Is this related to the layoffs which happened last year? Or is Tor moving=
 to
&gt; Rust (via arti) and all the development is happening there? I'm guessing
&gt; both.

The amount of work done is definitely related to the layoffs that
happened in April, but also related to our deliverables for 2020 for the
teams and thus the people left after the layoffs.

When the layoffs happened, most of April and quite a bit of May was used
for re-structuring the organisation and figuring out what to do next. We
decided to move some people around to do tasks for different teams than
their usual ones, and we created some new tasks we wanted to resolve
here and now that didn't have to do with any specific codebases or
teams, such as looking at our infrastructure for doing software
development.

If we look back at the second half of 2020, for Tor's Network Team, then
a lot of the tasks we have had has been longer term deliverables. We
started up the new project on network performance work where a lot of
cross-team interaction have happened together with the network team, the
metrics team, and our new network health team where the teams works
together on analysis/experiments or in codebases that are not
necessarily tor.git. Efforts such as looking into the next generation
bandwidth scanners (both sbws and flashflow) have taken some time as
well.

When Nick had shown the prototype of Arti at some point in 2020, we
tried to figure out a way where Nick could focus a bit more intensely on
this project, because it was looking *very* promising. This of course
have an impact too, but we think it's worth it because Arti will be
solving some of the architectural issues that will take a very long time
to resolve in the current codebase.

Additionally, some time have been spend helping our friends from the
guardian project on some profiling and Tor integration work for their
mobile applications.

It should be said though, that we don't hope that you have been impacted
by this as a volunteer over the year. We have tried to ensure that all
the normal tasks we have over the weeks regarding Tor maintenance have
remained the same (tasks such as doing code reviews, rolling releases,
backporting, etc.)

&gt; If it's the latter, I guess I have to start learning Rust sooner rather t=
han
&gt; later. Well, who am I kidding, I had to learn C# and PowerShell for my job
&gt; (Disclaimer: I work at Microsoft, not on security or Windows/Azure howeve=
r).

I think exploring Rust now might be a good idea. The Arti project that
Nick started does seem to solve some very specific issues that we have
been trying to deal with for years, and everybody in the Network Team in
Tor have been very impressed with how quickly things are able to move
forward in the Arti project.

If you take a look at the TODO file[1] in the root of the Arti
repository, and take a look at its history, you can get a feeling on how
quickly Nick have been able to move this project forward. It's very
exciting, and people are starting to submit patches to it as well :-)

A lot of us inside of Tor's network team still need to become better
Rust programmers, but hopefully we can speed that up by working
together.

All the best,
Alex.

[1]: https://gitlab.torproject.org/tpo/core/arti/-/blob/main/TODO

-- =

Alexander F=E6r=F8y
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210115130059</emailId><senderName>Matt Traudt</senderName><senderEmail>pastly@torproject.org</senderEmail><timestampReceived>2021-01-15 13:00:59-0400</timestampReceived><subject>Re: [tor-dev] torify/nmap results in SIGABRT</subject><body>

If this nmap command tries to generate non-TCP traffic, then that's your
problem. Tor only supports TCP traffic.

Also, I hope you have a good reason for portscanning over Tor. People
irresponsibly doing this contribute to Tor's bad reputation and ruin it
for everyone. People rely on Tor for free access to uncensored
information, and doing big port scanning the Internet or irresponsibly
scraping webpages causes exit operators trouble.

Rent a cheap VPS or something. Bonus: it will be way faster, support all
transport protocols, AND you don't have to deal with proxying over Tor.

Matt

On 1/14/21 22:19, Peng Yu wrote:
&gt; Hi,
&gt; 
&gt; I see the following error. Is it a bug in torify/torsocks? Thanks.
&gt; 
&gt; $ torify nmap -p7 google.com
&gt; ...
&gt; NSOCK ERROR [88.9380s] nsock_make_socket(): Socket trouble: Operation
&gt; not permitted
&gt; Assertion failed: (nse-&gt;iod-&gt;sd &gt;= 0), function nsock_pool_add_event,
&gt; file nsock_core.c, line 1273.
&gt; Abort trap: 6
&gt; 
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210120124805</emailId><senderName>Anthony Korte</senderName><senderEmail>makk12161985@gmail.com</senderEmail><timestampReceived>2021-01-20 12:48:05-0400</timestampReceived><subject>Re: [tor-dev] DirAuth usage and 503 try again later</subject><body>

[Attachment #2 (multipart/alternative)]


I have an unrelated question... where could I go with similar minds so that
I may ask or would it be appropriate and acceptable to do that here ,
thanks .

On Mon, Jan 11, 2021, 6:21 PM James &lt;jbrown299@yandex.com&gt; wrote:

&gt; Good day.
&gt;
&gt; Is there any chance that torpy (https://github.com/torpyorg/torpy) was
&gt; triggered this issue
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/33018 ?
&gt;
&gt; Some wary facts:
&gt; - Torpy using old fashion consensus (not mircodesc)
&gt; - When consensus not present in cache (first time usage) it downloads
&gt; consensus from random directory authorities only.
&gt; - Before August 2020 it was using plain HTTP requests to DirAuths. Now
&gt; it creates "CREATE_FAST" circuits to DirAuths (is that right way by the
&gt; way?)
&gt;
&gt;  From other side:
&gt; - Torpy store consensus on disk (so whenever client restart it must not
&gt; download full consensus again)
&gt; - It will try download consensus after time which sets by valid_time
&gt; field from consensus which more than 1 hour (so it's not so often)
&gt; - Torpy try get consensus by "diff" feature (so it's minimize traffic)
&gt;
&gt; Still may be some of this features not working well in some conditions.
&gt; Which could cause a lot of consensus downloads in Jan 2020... Or may be
&gt; you know more info about this situation?
&gt;
&gt;
&gt;
&gt; Do you have some recommendations for tor client implementation?
&gt; Can you explain in several paragraphs what behavior of original tor
&gt; client is? As far as I understand when first time original tor starts it
&gt; tries download consensus from fallback dirs not from DA? Is this key point?
&gt;
&gt; There is one more issue
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/40239
&gt; which I'm not understand correctly. Let's imagine it's first run of tor
&gt; client and that time coincidentally coincided with DA voting. That means
&gt; client will not be able to download consensus? That is strange decision.
&gt; Or do you mean clients must download consensus from fallback dirs which
&gt; never in "voting" process?
&gt;
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="auto"&gt;I have an unrelated question... where could I go with similar minds \
so that I may ask or would it be appropriate and acceptable to do that here , thanks \
.&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div dir="ltr" class="gmail_attr"&gt;On Mon, Jan 11, \
2021, 6:21 PM James &lt;&lt;a \
href="mailto:jbrown299@yandex.com"&gt;jbrown299@yandex.com&lt;/a&gt;&gt; \
wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex"&gt;Good day.&lt;br&gt; &lt;br&gt;
Is there any chance that torpy (&lt;a href="https://github.com/torpyorg/torpy" \
rel="noreferrer noreferrer" target="_blank"&gt;https://github.com/torpyorg/torpy&lt;/a&gt;) \
was &lt;br&gt; triggered this issue &lt;br&gt;
&lt;a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/33018" rel="noreferrer \
noreferrer" target="_blank"&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/33018&lt;/a&gt; \
?&lt;br&gt; &lt;br&gt;
Some wary facts:&lt;br&gt;
- Torpy using old fashion consensus (not mircodesc)&lt;br&gt;
- When consensus not present in cache (first time usage) it downloads &lt;br&gt;
consensus from random directory authorities only.&lt;br&gt;
- Before August 2020 it was using plain HTTP requests to DirAuths. Now &lt;br&gt;
it creates "CREATE_FAST" circuits to DirAuths (is that right way by the \
&lt;br&gt; way?)&lt;br&gt;
&lt;br&gt;
  From other side:&lt;br&gt;
- Torpy store consensus on disk (so whenever client restart it must not &lt;br&gt;
download full consensus again)&lt;br&gt;
- It will try download consensus after time which sets by valid_time &lt;br&gt;
field from consensus which more than 1 hour (so it's not so often)&lt;br&gt;
- Torpy try get consensus by "diff" feature (so it's minimize \
traffic)&lt;br&gt; &lt;br&gt;
Still may be some of this features not working well in some conditions. &lt;br&gt;
Which could cause a lot of consensus downloads in Jan 2020... Or may be &lt;br&gt;
you know more info about this situation?&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
Do you have some recommendations for tor client implementation?&lt;br&gt;
Can you explain in several paragraphs what behavior of original tor &lt;br&gt;
client is? As far as I understand when first time original tor starts it &lt;br&gt;
tries download consensus from fallback dirs not from DA? Is this key point?&lt;br&gt;
&lt;br&gt;
There is one more issue &lt;br&gt;
&lt;a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/40239" rel="noreferrer \
noreferrer" target="_blank"&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/40239&lt;/a&gt;&lt;br&gt;
 which I'm not understand correctly. Let's imagine it's first run of tor \
&lt;br&gt; client and that time coincidentally coincided with DA voting. That means &lt;br&gt;
client will not be able to download consensus? That is strange decision. &lt;br&gt;
Or do you mean clients must download consensus from fallback dirs which &lt;br&gt;
never in "voting" process?&lt;br&gt;
&lt;br&gt;
_______________________________________________&lt;br&gt;
tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" target="_blank" \
rel="noreferrer"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer \
noreferrer" target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt;
 &lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210124055721</emailId><senderName>Andreas Kempe</senderName><senderEmail>kempe@lysator.liu.se</senderEmail><timestampReceived>2021-01-24 05:57:21-0400</timestampReceived><subject>[tor-dev] Relay stalling when creating circuits</subject><body>

[Attachment #2 (multipart/signed)]


Hello everyone!

For a while now, I've noted that when running a non-exit relay under
fairly heavy load that is allowed to be utilised as a client, it has a
tendency to stall when trying to create new circuits.

If the relay has not been used as a client for a while and has a need
to create new circuits, CPU load shoots up to 100 % and the stalls for
some amount of time. I've seen stalls of over 1 minute.

I've taken two profiling traces of the relay, one during normal
operations and during the stalling behaviour. This was done on version
0.4.4.6 and each profile is approximately a 10 second recording.

Normal case:
&gt;- 84,34% event_base_loop
&gt;      - 80,19% event_process_active_single_queue
&gt;         - 42,87% scheduler_evt_callback
&gt;            - 42,86% kist_scheduler_run
&gt;               + 20,23% connection_handle_write
&gt;               + 9,47% update_socket_info_impl
&gt;               + 5,07% channel_flush_some_cells
&gt;               + 2,49% smartlist_pqueue_pop
&gt;               + 2,19% outbuf_table_add
&gt;               + 1,06% smartlist_pqueue_add
&gt;         + 28,38% conn_read_callback
&gt;         - 5,27% periodic_event_dispatch
&gt;            - 3,32% second_elapsed_callback
&gt;               + 1,69% run_connection_housekeeping
&gt;               + 0,98% circuit_build_needed_circs
&gt;            + 1,73% save_state_callback
&gt;         + 1,50% conn_write_callback
&gt;         + 1,02% connection_ap_attach_pending
&gt;      + 4,02% epoll_dispatch

Stalling case:
&gt;- 86,27% event_base_loop
&gt;   - 85,52% event_process_active_single_queue
&gt;      - 31,78% periodic_event_dispatch
&gt;         - 30,00% second_elapsed_callback
&gt;            - 28,84% circuit_build_needed_circs
&gt;               - 15,35% connection_ap_attach_pending
&gt;                  - 15,34% connection_ap_handshake_attach_circuit
&gt;                     - 15,34% circuit_get_open_circ_or_launch
&gt;                          10,14% circuit_get_best
&gt;                        - 4,99% circuit_launch_by_extend_info
&gt;                           - 4,88% circuit_establish_circuit
&gt;                              + 2,11% router_choose_random_node
&gt;                              + 2,05% nodelist_add_node_and_family
&gt;                                0,69% count_acceptable_nodes.isra.0
&gt;               + 13,39% circuit_launch_by_extend_info
&gt;            + 0,80% run_connection_housekeeping
&gt;         + 1,74% save_state_callback
&gt;      - 30,76% connection_ap_attach_pending
&gt;         - connection_ap_handshake_attach_circuit
&gt;            - 30,74% circuit_get_open_circ_or_launch
&gt;               - 30,63% circuit_get_best
&gt;                    1,18% circuit_get_global_list
&gt;      + 11,50% conn_read_callback
&gt;      + 10,47% scheduler_evt_callback
&gt;         - 10,47% scheduler_evt_callback
&gt;            - kist_scheduler_run
&gt;               + 6,27% connection_handle_write
&gt;               + 1,54% channel_flush_some_cells
&gt;               + 0,98% update_socket_info_impl
&gt;               + 0,91% smartlist_pqueue_pop
&gt;     0,75% epoll_dispatch

(The traces above are meant to be indented for legibility, but some
mail clients think they know better.)

Has anyone seen similar behaviour or have an inkling as to what's
going on? I thought it best to ask before diving into the code.

Cordially,
Andreas Kempe

["signature.asc" (application/pgp-signature)]

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210218155934</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-02-18 15:59:34-0400</timestampReceived><subject>[tor-dev] Best way to reload config on Windows?</subject><body>

[Attachment #2 (multipart/alternative)]


Hi everyone,

We're building a Ricochet-inspired chat app, and there are situations where we want \
to create a new hidden service URL. On macOS and Linux we can send a SIGHUP to make \
Tor reload its config. What's the best way to do this on Windows? 

I found an old issue for this \
(https://gitlab.torproject.org/tpo/core/tor/-/issues/10052 \
&lt;https://gitlab.torproject.org/tpo/core/tor/-/issues/10052&gt;) but it looks like it \
never got addressed. 

Thoughts?

Holmes


[Attachment #5 (unknown)]

&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; \
charset=utf-8"&gt;&lt;/head&gt;&lt;body style="word-wrap: break-word; -webkit-nbsp-mode: space; \
line-break: after-white-space;" class=""&gt;Hi everyone,&lt;div class=""&gt;&lt;br \
class=""&gt;&lt;/div&gt;&lt;div class=""&gt;We're building a Ricochet-inspired chat app, and there \
are situations where we want to create a new hidden service URL. On macOS and Linux \
we can send a SIGHUP to make Tor reload its config. What's the best way to do this on \
Windows? &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div class=""&gt;I found an old \
issue for this (&lt;a href="https://gitlab.torproject.org/tpo/core/tor/-/issues/10052" \
class=""&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/10052&lt;/a&gt;) but it looks \
like it never got addressed. &lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Thoughts?&lt;/div&gt;&lt;div class=""&gt;&lt;br class=""&gt;&lt;/div&gt;&lt;div \
class=""&gt;Holmes&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210218180440</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-02-18 18:04:40-0400</timestampReceived><subject>Re: [tor-dev] Best way to reload config on Windows?</subject><body>

On Thu, Feb 18, 2021 at 10:59:34AM -0500, Holmes Wilson wrote:
&gt; We???re building a Ricochet-inspired chat app, and there are situations where we \
&gt; want to create a new hidden service URL. On macOS and Linux we can send a SIGHUP to \
&gt; make Tor reload its config. What???s the best way to do this on Windows? 

Your best bet is to connect over the controlport and issue a 'signal
reload' command.

My guess is that you will already be wanting a controller connection,
for example to learn about Tor's bootstrap state or other warnings that
Tor wants to give you, so hopefully this is an easy answer. :)

That said, how did you get into the situation where you want Tor to reload
its config file? To me that sounds like you've made some weird UX choices
like asking the user to go edit their torrc file, and maybe there are
better choices -- for example, you could use setconf and saveconf over
the control port to configure the onion service.

https://spec.torproject.org/control-spec

Hope that helps,
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210218183550</emailId><senderName>Holmes Wilson</senderName><senderEmail>h@zbay.llc</senderEmail><timestampReceived>2021-02-18 18:35:50-0400</timestampReceived><subject>Re: [tor-dev] Best way to reload config on Windows?</subject><body>

Thanks, this is helpful!

We were changing the .torrc file programmatically to add and remove hidden services \
and then sending a SIGHUP to get Tor to recognize the changes. We'll try using the \
control port instead. 

Thanks again,

-H

&gt; On Feb 18, 2021, at 1:04 PM, Roger Dingledine &lt;arma@torproject.org&gt; wrote:
&gt; 
&gt; On Thu, Feb 18, 2021 at 10:59:34AM -0500, Holmes Wilson wrote:
&gt; &gt; We???re building a Ricochet-inspired chat app, and there are situations where we \
&gt; &gt; want to create a new hidden service URL. On macOS and Linux we can send a SIGHUP \
&gt; &gt; to make Tor reload its config. What???s the best way to do this on Windows? 
&gt; 
&gt; Your best bet is to connect over the controlport and issue a 'signal
&gt; reload' command.
&gt; 
&gt; My guess is that you will already be wanting a controller connection,
&gt; for example to learn about Tor's bootstrap state or other warnings that
&gt; Tor wants to give you, so hopefully this is an easy answer. :)
&gt; 
&gt; That said, how did you get into the situation where you want Tor to reload
&gt; its config file? To me that sounds like you've made some weird UX choices
&gt; like asking the user to go edit their torrc file, and maybe there are
&gt; better choices -- for example, you could use setconf and saveconf over
&gt; the control port to configure the onion service.
&gt; 
&gt; https://spec.torproject.org/control-spec
&gt; 
&gt; Hope that helps,
&gt; --Roger
&gt; 
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210218223022</emailId><senderName>Keifer Bly</senderName><senderEmail>keifer.bly@gmail.com</senderEmail><timestampReceived>2021-02-18 22:30:22-0400</timestampReceived><subject>Re: [tor-dev] Best way to reload config on Windows?</subject><body>

[Attachment #2 (multipart/alternative)]


Well, perhaps this tool will be of use to you:

https://www.youtube.com/watch?v=Vpk6yvUWQqU

Something I made to help tor operators on Windows.

You can reconfigure tor (by the torrc file) with ease. Cheers.
--Keifer


On Thu, Feb 18, 2021 at 9:59 AM Holmes Wilson &lt;h@zbay.llc&gt; wrote:

&gt; Hi everyone,
&gt;
&gt; We're building a Ricochet-inspired chat app, and there are situations
&gt; where we want to create a new hidden service URL. On macOS and Linux we can
&gt; send a SIGHUP to make Tor reload its config. What's the best way to do this
&gt; on Windows?
&gt;
&gt; I found an old issue for this (
&gt; https://gitlab.torproject.org/tpo/core/tor/-/issues/10052) but it looks
&gt; like it never got addressed.
&gt;
&gt; Thoughts?
&gt;
&gt; Holmes
&gt; _______________________________________________
&gt; tor-dev mailing list
&gt; tor-dev@lists.torproject.org
&gt; https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
&gt;

[Attachment #5 (text/html)]

&lt;div dir="ltr"&gt;Well, perhaps this tool will be of use to you:&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;a \
href="https://www.youtube.com/watch?v=Vpk6yvUWQqU"&gt;https://www.youtube.com/watch?v=Vpk6yvUWQqU&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Something \
I made to help tor operators on Windows.  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You can \
reconfigure tor (by the torrc file) with ease. Cheers.&lt;br clear="all"&gt;&lt;div&gt;&lt;div \
dir="ltr" class="gmail_signature" data-smartmail="gmail_signature"&gt;&lt;div \
dir="ltr"&gt;--Keifer&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;&lt;div \
dir="ltr" class="gmail_attr"&gt;On Thu, Feb 18, 2021 at 9:59 AM Holmes Wilson \
&lt;h@zbay.llc&gt; wrote:&lt;br&gt;&lt;/div&gt;&lt;blockquote class="gmail_quote" style="margin:0px \
0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"&gt;&lt;div \
style="overflow-wrap: break-word;"&gt;Hi everyone,&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We're building a \
Ricochet-inspired chat app, and there are situations where we want to create a new \
hidden service URL. On macOS and Linux we can send a SIGHUP to make Tor reload its \
config. What's the best way to do this on Windows?  &lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I found \
an old issue for this (&lt;a \
href="https://gitlab.torproject.org/tpo/core/tor/-/issues/10052" \
target="_blank"&gt;https://gitlab.torproject.org/tpo/core/tor/-/issues/10052&lt;/a&gt;) but it \
looks like it never got addressed.  \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thoughts?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Holmes&lt;/div&gt;&lt;/div&gt;_______________________________________________&lt;br&gt;
 tor-dev mailing list&lt;br&gt;
&lt;a href="mailto:tor-dev@lists.torproject.org" \
target="_blank"&gt;tor-dev@lists.torproject.org&lt;/a&gt;&lt;br&gt; &lt;a \
href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev" rel="noreferrer" \
target="_blank"&gt;https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev&lt;/a&gt;&lt;br&gt; \
&lt;/blockquote&gt;&lt;/div&gt;



_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210115031913</emailId><senderName>Peng Yu</senderName><senderEmail>pengyu.ut@gmail.com</senderEmail><timestampReceived>2021-01-15 03:19:13-0400</timestampReceived><subject>[tor-dev] torify/nmap results in SIGABRT</subject><body>

Hi,

I see the following error. Is it a bug in torify/torsocks? Thanks.

$ torify nmap -p7 google.com
...
NSOCK ERROR [88.9380s] nsock_make_socket(): Socket trouble: Operation
not permitted
Assertion failed: (nse-&gt;iod-&gt;sd &gt;= 0), function nsock_pool_add_event,
file nsock_core.c, line 1273.
Abort trap: 6

-- 
Regards,
Peng
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210111222029</emailId><senderName>James</senderName><senderEmail>jbrown299@yandex.com</senderEmail><timestampReceived>2021-01-11 22:20:29-0400</timestampReceived><subject>[tor-dev] DirAuth usage and 503 try again later</subject><body>

Good day.

Is there any chance that torpy (https://github.com/torpyorg/torpy) was 
triggered this issue 
https://gitlab.torproject.org/tpo/core/tor/-/issues/33018 ?

Some wary facts:
- Torpy using old fashion consensus (not mircodesc)
- When consensus not present in cache (first time usage) it downloads 
consensus from random directory authorities only.
- Before August 2020 it was using plain HTTP requests to DirAuths. Now 
it creates "CREATE_FAST" circuits to DirAuths (is that right way by the 
way?)

 From other side:
- Torpy store consensus on disk (so whenever client restart it must not 
download full consensus again)
- It will try download consensus after time which sets by valid_time 
field from consensus which more than 1 hour (so it's not so often)
- Torpy try get consensus by "diff" feature (so it's minimize traffic)

Still may be some of this features not working well in some conditions. 
Which could cause a lot of consensus downloads in Jan 2020... Or may be 
you know more info about this situation?



Do you have some recommendations for tor client implementation?
Can you explain in several paragraphs what behavior of original tor 
client is? As far as I understand when first time original tor starts it 
tries download consensus from fallback dirs not from DA? Is this key point?

There is one more issue 
https://gitlab.torproject.org/tpo/core/tor/-/issues/40239
which I'm not understand correctly. Let's imagine it's first run of tor 
client and that time coincidentally coincided with DA voting. That means 
client will not be able to download consensus? That is strange decision. 
Or do you mean clients must download consensus from fallback dirs which 
never in "voting" process?

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210112005332</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2021-01-12 00:53:32-0400</timestampReceived><subject>Re: [tor-dev] DirAuth usage and 503 try again later</subject><body>



&gt; On 11. Jan 2021, at 23:20, James &lt;jbrown299@yandex.com&gt; wrote:
&gt; 
&gt; Good day.
&gt; 
&gt; Is there any chance that torpy (https://github.com/torpyorg/torpy) was triggered \
&gt; this issue https://gitlab.torproject.org/tpo/core/tor/-/issues/33018 ? 
&gt; Some wary facts:
&gt; - Torpy using old fashion consensus (not mircodesc)
&gt; - When consensus not present in cache (first time usage) it downloads consensus \
&gt;                 from random directory authorities only.
&gt; - Before August 2020 it was using plain HTTP requests to DirAuths. Now it creates \
&gt; "CREATE_FAST" circuits to DirAuths (is that right way by the way?) 
&gt; From other side:
&gt; - Torpy store consensus on disk (so whenever client restart it must not download \
&gt;                 full consensus again)
&gt; - It will try download consensus after time which sets by valid_time field from \
&gt;                 consensus which more than 1 hour (so it's not so often)
&gt; - Torpy try get consensus by "diff" feature (so it's minimize traffic)
&gt; 
&gt; Still may be some of this features not working well in some conditions. Which could \
&gt; cause a lot of consensus downloads in Jan 2020... Or may be you know more info \
&gt; about this situation?

Hi there,

thanks for the message. I think it is very likely that torpy is
responsible for a at least a part of the increased load we're seeing on
dirauths. I have taken a (very!) quick look at the source, and it appears
that there are some problems. Please excuse any inaccuracies, I am not
that strong in Python nor have I done too much Tor development recently:

First, I found this string in the code: "Hardcoded into each Tor client
is the information about 10 beefy Tor nodes run by trusted volunteers".
The word beefy is definitely wrong here. The nodes are not particularly
powerful, which is why we have the fallback dir design for
bootstrapping.

The code counts Serge as a directory authority which signs the
consensus, and checks that over half of the dirauths signed it. But
Serge is only the bridge authority and never signs the consensus, so
torpy will reject some consensuses that are indeed valid. Once this
happens, torpy goes into a deathly loop of "consensus invalid,
trying again". There are no timeouts, backoffs, or failures noted.

The code frequently throws exceptions, but when an exception occurs
it just continues doing what it was doing before. It has absolutely
no regards to constrain its resources when using the Tor network.

The logic that if a network_status document was already downloaded that
is used rather than trying to download a new one does not work. I have
a network_status document, but the dirauths are contacted anyway.
Perhaps descriptors are not cached to disk and downloaded on every new
start of the application?

New consensuses never seem to be downloaded from guards, only from
dirauths.

If my analsis above is at least mostly correct, if only some few people
are running a scraper using torpy and call the binary in a loop, they
will quickly overload the dirauths, causing exactly the trouble we're
seeing. The effects compound, because torpy is relentless in trying
again. Especially a scraper that might call torpy in a loop would just
think that a single file failed to download and go to the next, once
again creating load on all the dirauths.

There are probably more things suboptimal that I missed here.
Generally, I think torpy needs to implement the following quickly if it
wants to stop hurting the network. This is in order of priority, but I
think _ALL_ (maybe more) are needed before torpy stops being an abuser
of the network:

- Stop automatically retrying on failure, without backoff
- Cache failures to disk to ensure a newly started torpy_cli does not
  request the same resources again that the previous instance failed to
  get.
- Fix consensus validation logic to work the same way as tor cli (maybe
  as easy as removing Serge)
- use microdescs/consensus, cache descriptors

I wonder if we can actively defend against network abuse like this in
a sensible way. Perhaps you have some ideas, too? I think torpy has the
ability to also quickly overwhelm fallback dirs in its current
implementation, so simply switching to them from dirauths is not a
solution here. Defenses are probably necessary to implement even if
torpy can be fixed very quickly, because the older versions of torpy are
out there and I assume will continue to be used. Hopefully that point
is wrong?

Thanks
Sebastian

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210115225602</emailId><senderName>James</senderName><senderEmail>jbrown299@yandex.com</senderEmail><timestampReceived>2021-01-15 22:56:02-0400</timestampReceived><subject>[tor-dev] DirAuth usage and 503 try again later</subject><body>

Sebastian,
Thank you for comments.

First of all, sorry if torpy hurt in some way Tor Network. It was 
unintentionally.

In any case, it seems to me that if there was some high-level 
description of logic for official tor client, it would be very useful.

 &gt;First, I found this string in the code: "Hardcoded into each Tor client
 &gt;is the information about 10 beefy Tor nodes run by trusted volunteers".
 &gt;The word beefy is definitely wrong here. The nodes are not particularly
 &gt;powerful, which is why we have the fallback dir design for
 &gt;bootstrapping.
At first glance, it seemed that the AuthDirs were the most trusted and 
reliable place for obtaining consensus. Now I'm understand more.


 &gt;The code counts Serge as a directory authority which signs the
 &gt;consensus, and checks that over half of the dirauths signed it. But
 &gt;Serge is only the bridge authority and never signs the consensus, so
 &gt;torpy will reject some consensuses that are indeed valid.
Yep, here you right. Thanks for pointing out.

 &gt;Once this
 &gt;happens, torpy goes into a deathly loop of "consensus invalid,
 &gt;trying again". There are no timeouts, backoffs, or failures noted.
Not really, because torpy has only 3 retries for getting consensus. But 
probably you are right because user code probably can do retry calling 
torpy in a loop. So that will always try download network_status... If 
you have some sort of statistic about increasing traffic we can compare 
that with time when was consensus signed by 4 signers which enough for 
tor but not enough for torpy.


 &gt;The code frequently throws exceptions, but when an exception occurs
 &gt;it just continues doing what it was doing before. It has absolutely
 &gt;no regards to constrain its resources when using the Tor network.
What kind of constraints can you advise?

 &gt;The logic that if a network_status document was already downloaded that
 &gt;is used rather than trying to download a new one does not work.
It works. But probably not in optimal way. It caches network_status only.


 &gt;I have
 &gt;a network_status document, but the dirauths are contacted anyway.
 &gt;Perhaps descriptors are not cached to disk and downloaded on every new
 &gt;start of the application?

Exactly. Descriptors and network_status diff every hour was asking 
always from AuthDirs.


 &gt;New consensuses never seem to be downloaded from guards, only from
 &gt;dirauths.
Thanks for pointing out. I looked more deeply into tor client sources. 
So basically if we have network_status we can use guard nodes to ask 
network_status and descriptors from them. Otherwise using fallback dirs 
to download network_status. I've implemented such logic in last commit.


 &gt;There are probably more things suboptimal that I missed here.
If you find more please let me know. It really helpful.

 &gt;Generally, I think torpy needs to implement the following quickly if it
 &gt;wants to stop hurting the network. This is in order of priority, but I
 &gt;think _ALL_ (maybe more) are needed before torpy stops being an abuser
 &gt;of the network:
 &gt;

 &gt;- Stop automatically retrying on failure, without backoff
I've added delays and backoff between retries.

 &gt;- Cache failures to disk to ensure a newly started torpy_cli does not
 &gt;  request the same resources again that the previous instance failed to
 &gt;  get.
That will be on the list. But probably even if there is a loop level 
above and without this feature but with backoff it will be delays like: 
3 sec, 5, 7, 9; 3, 5, 7, 9. Seems ok?

 &gt;- Fix consensus validation logic to work the same way as tor cli (maybe
 &gt;  as easy as removing Serge)
Done. Only auth dirs with V3_DIRINFO flag will be counted. It wasn't 
obvious =(

 &gt;- use microdescs/consensus, cache descriptors
On the list.

Moreover, I've switched to using fallback dirs instead of auth dirs and 
to guards if torpy has "reasonable" live consensus.

 &gt; Defenses are probably necessary to implement even if
 &gt;torpy can be fixed very quickly, because the older versions of torpy 
 &gt;are out there and I assume will continue to be used. Hopefully that
 &gt;point is wrong?
I believe that old versions doesn't work any more because them could not 
connect to auth dirs. Users getting 503 many times, so they will update 
client. I hope.


Thank you very much. And sorry again.
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210116010642</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2021-01-16 01:06:42-0400</timestampReceived><subject>Re: [tor-dev] DirAuth usage and 503 try again later</subject><body>

Hi James,

thanks for already working on patches for these issues! I will reply
inline some more.

&gt; On 15. Jan 2021, at 23:56, James &lt;jbrown299@yandex.com&gt; wrote:
&gt; 
&gt; First of all, sorry if torpy hurt in some way Tor Network. It was unintentionally.

I believe you :)

&gt; In any case, it seems to me that if there was some high-level description of logic \
&gt; for official tor client, it would be very useful.

Indeed. The more people work on alternative clients etc, the more we can
learn here. Perhaps you can help point out places where documentation
could help or something was not easy to understand.

&gt; &gt; First, I found this string in the code: "Hardcoded into each Tor client
&gt; &gt; is the information about 10 beefy Tor nodes run by trusted volunteers".
&gt; &gt; The word beefy is definitely wrong here. The nodes are not particularly
&gt; &gt; powerful, which is why we have the fallback dir design for
&gt; &gt; bootstrapping.
&gt; At first glance, it seemed that the AuthDirs were the most trusted and reliable \
&gt; place for obtaining consensus. Now I'm understand more.

The consensus is signed, so all the places to get it from are equally
trusted. That's the beauty of the consensus system :) The dirauths
are just trusted to create it, it doesn't matter who spreads it.

&gt; &gt; Once this
&gt; &gt; happens, torpy goes into a deathly loop of "consensus invalid,
&gt; &gt; trying again". There are no timeouts, backoffs, or failures noted.
&gt; Not really, because torpy has only 3 retries for getting consensus. But probably \
&gt; you are right because user code probably can do retry calling torpy in a loop. So \
&gt; that will always try download network_status... If you have some sort of statistic \
&gt; about increasing traffic we can compare that with time when was consensus signed by \
&gt; 4 signers which enough for tor but not enough for torpy.

Interesting, I ran torpy and on the console it seemed to try more
often. Perhaps it made some progress and then failed on a different
thing, which it then tried again.

To your second point, something like this can probably be done using
https://metrics.torproject.org. But I am not doing the analysis here
at the moment for personal reasons, sorry. Maybe someone else wants
to look at it.

&gt; &gt; The code frequently throws exceptions, but when an exception occurs
&gt; &gt; it just continues doing what it was doing before. It has absolutely
&gt; &gt; no regards to constrain its resources when using the Tor network.
&gt; What kind of constraints can you advise?

I think instead of throwing an exception and continuing, you should
give clear error messages and consider whether you need to stop
execution. For example, if you downloaded a consensus and it is
invalid, you're likely not going to get a valid one by trying again
immediately. Instead, it would be better to declare who gave you the
invalid one and log a sensible error.

In addition, properly using already downloaded directory information
would be a much more considerate use of resources.

&gt; &gt; The logic that if a network_status document was already downloaded that
&gt; &gt; is used rather than trying to download a new one does not work.
&gt; It works. But probably not in optimal way. It caches network_status only.

I may have confused it with asking for the diff. But that should not
be necessary at all if you already have the latest one, so don't ask
for a diff in this case.

&gt; &gt; I have
&gt; &gt; a network_status document, but the dirauths are contacted anyway.
&gt; &gt; Perhaps descriptors are not cached to disk and downloaded on every new
&gt; &gt; start of the application?
&gt; 
&gt; Exactly. Descriptors and network_status diff every hour was asking always from \
&gt; AuthDirs.

Please cache descriptors.

&gt; &gt; New consensuses never seem to be downloaded from guards, only from
&gt; &gt; dirauths.
&gt; Thanks for pointing out. I looked more deeply into tor client sources. So basically \
&gt; if we have network_status we can use guard nodes to ask network_status and \
&gt; descriptors from them. Otherwise using fallback dirs to download network_status. \
&gt; I've implemented such logic in last commit.

Cool!

&gt; &gt; - Stop automatically retrying on failure, without backoff
&gt; I've added delays and backoff between retries.
&gt; 
&gt; &gt; - Cache failures to disk to ensure a newly started torpy_cli does not
&gt; &gt; request the same resources again that the previous instance failed to
&gt; &gt; get.
&gt; That will be on the list. But probably even if there is a loop level above and \
&gt; without this feature but with backoff it will be delays like: 3 sec, 5, 7, 9; 3, 5, \
&gt; 7, 9. Seems ok?

Well, the problem is if I run torpy_cli in parallel 100 times, we will
still send many requests per second. From dirauth access patterns, we
can see that some people indeed have such access patterns. So I think
the backoff is a great start (tor client uses exponential backoff I
think) but it definitely is not enough. If you couldn't get something
this hour and you tried a few times, you need to stop trying again for
this hour.

&gt; &gt; Defenses are probably necessary to implement even if
&gt; &gt; torpy can be fixed very quickly, because the older versions of torpy &gt;are out \
&gt; &gt; there and I assume will continue to be used. Hopefully that point is wrong?
&gt; I believe that old versions doesn't work any more because them could not connect to \
&gt; auth dirs. Users getting 503 many times, so they will update client. I hope.


Would be nice. We'll see!

Thanks
Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev


</body></email><email><emailId>20210118170021</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@torproject.org</senderEmail><timestampReceived>2021-01-18 17:00:21-0400</timestampReceived><subject>Re: [tor-dev] DirAuth usage and 503 try again later</subject><body>

On Sat, Jan 16, 2021 at 01:56:02AM +0300, James wrote:
&gt; In any case, it seems to me that if there was some high-level description of
&gt; logic for official tor client, it would be very useful.

Hi James! Thanks for starting this discussion.

While I was looking at moria1's directory activity during the overload,
I did say to myself "wow that's a lot of microdescriptor downloads".

So hearing that torpy isn't caching mirodescriptors yet makes me think
that it's a good bet for explaining our overload last weekend.

I agree that we should have clearer docs for "how to be nice to the Tor
network." We actually have an open ticket for that goal but nobody has
worked on it in a while:
https://gitlab.torproject.org/tpo/core/tor/-/issues/7106

Quoting from that ticket:

"""Second, it's easy to make client-side decisions that harm the Tor
network. For examples, you can hold your TLS connections open too long,
or do too many TLS connections, or make circuits too often, or ask the
directory authorities for everything. We need to write up a spec to
clarify how well-behaving Tor clients should do things. Maybe that means
we write up some principles along the way, or maybe we just identify
every design point that matters and say what to do for each of them."""

And in fact, since Nick has been working a lot on Arti lately:
https://gitlab.torproject.org/tpo/core/arti/
it might be a perfect time for him to help document the current Tor
behavior and the current Arti behavior, and we can think about where
there is room for improvement.

&gt;  If you have
&gt; some sort of statistic about increasing traffic we can compare that

Here's the most interesting graph so far:
https://metrics.torproject.org/dirbytes.html

So from that graph, the number of bytes handled by the directory
authorities doesn't go up a lot, because they were already rate limited
(instead, they just failed more often).

But the number of bytes handled by directory mirrors (including
fallbackdirs) shot up a huge amount. For context, if we imagine that
the normal Tor network handles between 2M and 8M daily users, then that
added dir mirror load would imply an extra 4M to 16M daily users if they
follow Tor's directory update habits. I'm guessing that the torpy users
weren't following Tor's directory update habits, and so a much smaller
set of users accounted for a much larger fraction of the load.

&gt; &gt;The logic that if a network_status document was already downloaded that
&gt; &gt;is used rather than trying to download a new one does not work.
&gt; It works. But probably not in optimal way. It caches network_status only.

Here's my first start at three principles we should all follow when
writing Tor clients:

(1) Reduce redundant interactions. For examples:

- Cache as much as possible of the directory information you fetch
(consensus documents, microdescriptors, certs)

- If a directory fetch failed, don't just relaunch a duplicate request
right after (because it will probably fail too).

- If your setup involves running multiple Tors locally, consider using a
shared directory cache, so only one of them needs to fetch new directory
info and then all of them can use it.

(2) Reduce impact of interactions. For examples:

- Always use the "If-Modified-Since" header on consensus updates, so
they don't send you a consensus that you already have.

- Try to use the consensus diff system, so if you have an existing
consensus you aren't fetching an entire new consensus.

- Ask for compression, to save overall bandwidth in the network.

- Move load off of directory authorities, and then off of fallback
directories, as soon as possible. That is, if you have a list of
fallbackdirs, ask them instead of directory authorities. And once
you have a consensus and you've chosen your directory guards, ask
them instead of the fallbackdirs.

(3) Plan ahead for what your current code will do in a few years when
the world is different.

- To start here, check out the "slow zombies and fast zombies" discussion
in Proposal 266:
https://gitweb.torproject.org/torspec.git/tree/proposals/266-removing-current-obsolete-clients.txt

- Specifically, think about how your code handles failures, and design
your interactions with the Tor network so that if many people are running
your code in the future, and it's failing for example because it is
asking directory questions in an old format or because the directory
servers have started rate limiting differently, it will back off rather
than become more aggressive.

- When possible, look for ways to recognize when your code is asking old
questions, so it can warn the user and stop interacting with the network.

...What else should be on the list?

Thanks!
--Roger

_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email><email><emailId>20210120110407</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2021-01-20 11:04:07-0400</timestampReceived><subject>Re: [tor-dev] DirAuth usage and 503 try again later</subject><body>



&gt; On 18. Jan 2021, at 18:00, Roger Dingledine &lt;arma@torproject.org&gt; wrote:
&gt; While I was looking at moria1's directory activity during the overload,
&gt; I did say to myself "wow that's a lot of microdescriptor downloads".
&gt;
&gt; So hearing that torpy isn't caching mirodescriptors yet makes me think
&gt; that it's a good bet for explaining our overload last weekend.

The fact that torpy doesn't use microdescriptors makes me think there's
at least some other party involved here. Hopefully they can also improve
their software, but it makes me wonder what that software is :/

Cheers
Sebastian
_______________________________________________
tor-dev mailing list
tor-dev@lists.torproject.org
https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-dev
</body></email></emails>