<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20090105123039</emailId><senderName>Boris Gimelbrand</senderName><senderEmail>borisg@yoggie.com</senderEmail><timestampReceived>2009-01-05 12:30:39-0400</timestampReceived><subject>Fwd: Country patch for Tor</subject><body>


----- Forwarded Message -----
From: "Boris Gimelbrand" &lt;borisg@yoggie.com&gt;
To: or-dev@seul.org
Sent: Monday, January 5, 2009 2:30:04 PM (GMT+0200) Auto-Detected
Subject: Country patch for Tor

Hi,

I added a patch that enables choosing exit node country from configuration file.
It uses already existing functions that access GeoIP database.
I also added an option to load one country only from the GeoIP database,
for limited resources systems.
The new parameters are:
ExitCountry, e.g. "ExitCountry gb" for Britain.
GeoIPExitCountryOnly - if true, load only the country chosen in ExitCountry from GeoIP database.


Sample configuration:

GeoIPFile /etc/yoggie/torIpToCountry.csv
GeoIPExitCountryOnly 1
ExitCountry gb

Thanks
Sincerely
Boris Gimelbrand

["country.patch" (application/octet-stream)]

</body></email><email><emailId>20090703130352</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2009-07-03 13:03:52-0400</timestampReceived><subject>Re: [or-cvs] r19895: {website} updated vidalia 0.1.14 available</subject><body>


phobos@seul.org wrote:

&gt; Author: phobos
&gt; Date: 2009-07-01 20:48:56 -0400 (Wed, 01 Jul 2009)
&gt; New Revision: 19895
&gt; 
&gt; Modified:
&gt;    website/trunk/vidalia/en/index.wml
&gt; Log:
&gt; updated vidalia 0.1.14 available
&gt; 
&gt; 
&gt; Modified: website/trunk/vidalia/en/index.wml
&gt; ===================================================================
&gt; --- website/trunk/vidalia/en/index.wml	2009-07-01 21:34:36 UTC (rev 19894)
&gt; +++ website/trunk/vidalia/en/index.wml	2009-07-02 00:48:56 UTC (rev 19895)
&gt; @@ -38,18 +38,18 @@

&gt; -&lt;!--
&gt;    &lt;li&gt;
&gt; -     &lt;a href="dist/vidalia-0.1.12-ppc.dmg"&gt;Mac OS X PPC-only&lt;/a&gt;
&gt; -    (&lt;a href="dist/vidalia-0.1.12-ppc.dmg.asc"&gt;sig&lt;/a&gt;)
&gt; +     &lt;a href="dist/vidalia-0.1.13-ppc.dmg"&gt;Mac OS X PPC-only&lt;/a&gt;
&gt; +    (&lt;a href="dist/vidalia-0.1.13-ppc.dmg.asc"&gt;sig&lt;/a&gt;)
&gt;    &lt;/li&gt;
&gt; +&lt;--

The '!' got lost.

Fabian

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090105123004</emailId><senderName>Boris Gimelbrand</senderName><senderEmail>borisg@yoggie.com</senderEmail><timestampReceived>2009-01-05 12:30:04-0400</timestampReceived><subject>Country patch for Tor</subject><body>

Hi,

I added a patch that enables choosing exit node country from configuration file.
It uses already existing functions that access GeoIP database.
I also added an option to load one country only from the GeoIP database,
for limited resources systems.
The new parameters are:
ExitCountry, e.g. "ExitCountry gb" for Britain.
GeoIPExitCountryOnly - if true, load only the country chosen in ExitCountry from GeoIP database.


Sample configuration:

GeoIPFile /etc/yoggie/torIpToCountry.csv
GeoIPExitCountryOnly 1
ExitCountry gb

Thanks
Sincerely
Boris Gimelbrand
</body></email><email><emailId>20090106173123</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2009-01-06 17:31:23-0400</timestampReceived><subject>Re: [or-cvs] r17930: {projects} Fix German translation.</subject><body>


ioerror@seul.org wrote:

&gt; Author: ioerror
&gt; Date: 2009-01-05 18:02:46 -0500 (Mon, 05 Jan 2009)
&gt; New Revision: 17930
&gt; 
&gt; Modified:
&gt;    projects/gettor/i18n/de/gettor_de.po
&gt; Log:
&gt; Fix German translation.
&gt; 
&gt; 
&gt; Modified: projects/gettor/i18n/de/gettor_de.po
&gt; ===================================================================
&gt; --- projects/gettor/i18n/de/gettor_de.po	2009-01-05 22:43:54 UTC
&gt; (rev 17929) +++ projects/gettor/i18n/de/gettor_de.po	2009-01-05
&gt; 23:02:46 UTC (rev 17930) @@ -154,7 +154,7 @@
&gt;  "    Here's your requested software as a zip file. Please unzip the \n"
&gt;  "    package and verify the signature.\n"
&gt;  "        "
&gt; -"\n"
&gt; +msgstr "\n"
&gt;  "Hier ist die von Ihnen angeforderte Software als Zip-datei. Bitte\n"

The correct capitalisation is "Zip-Datei".

Fabian

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090115225635</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-01-15 22:56:35-0400</timestampReceived><subject>PATCH: support local application data paths by default via configure option --enable-local-appdata</subject><body>

This patch changes the default location where config and data files
are stored when the --enable-local-appdata option is configured.  This
changes the Windows path from %APPDATA% to a host local
%USERPROFILE%\Local Settings\Application Data\ path (aka,
LOCAL_APPDATA).

["tor-localappdata.patch" (text/x-patch)]

diff -Naur orig-tor/configure.in mod-tor/configure.in
--- orig-tor/configure.in	2009-01-07 21:05:02.433428000 +0000
+++ mod-tor/configure.in	2009-01-15 22:32:40.208956064 +0000
@@ -96,6 +96,13 @@
 AC_ARG_ENABLE(gcc-warnings,
      AS_HELP_STRING(--enable-gcc-warnings, enable verbose warnings))
 
+AC_ARG_ENABLE(local-appdata,
+   AS_HELP_STRING(--enable-local-appdata, default to host local application data paths on Windows))
+if test "$enable_local_appdata" = "yes"; then
+  AC_DEFINE(ENABLE_LOCAL_APPDATA, 1,
+            [Defined if we default to host local appdata paths on Windows])
+fi
+
 AC_PROG_CC
 AC_PROG_CPP
 AC_PROG_MAKE_SET
diff -Naur orig-tor/src/or/config.c mod-tor/src/or/config.c
--- orig-tor/src/or/config.c	2009-01-07 21:13:02.443406000 +0000
+++ mod-tor/src/or/config.c	2009-01-15 22:35:36.250193728 +0000
@@ -3735,8 +3735,11 @@
   /* Find X:\documents and settings\username\application data\ .
    * We would use SHGetSpecialFolder path, but that wasn't added until IE4.
    */
-  if (!SUCCEEDED(SHGetSpecialFolderLocation(NULL, CSIDL_APPDATA,
-                                            &amp;idl))) {
+#ifdef ENABLE_LOCAL_APPDATA
+  if (!SUCCEEDED(SHGetSpecialFolderLocation(NULL, CSIDL_LOCAL_APPDATA, &amp;idl))) {
+#else
+  if (!SUCCEEDED(SHGetSpecialFolderLocation(NULL, CSIDL_APPDATA, &amp;idl))) {
+#endif
     GetCurrentDirectory(MAX_PATH, path);
     is_set = 1;
     log_warn(LD_CONFIG,


</body></email><email><emailId>20090121065605</emailId><senderName>Marcus Wolschon</senderName><senderEmail>marcus@wolschon.biz</senderEmail><timestampReceived>2009-01-21 06:56:05-0400</timestampReceived><subject>Ipv6</subject><body>

On Wed, 21 Jan 2009 01:14:08 -0500, Nick Mathewson &lt;nickm@freehaven.net&gt;
wrote:
&gt; Right now, though, the Tor development branch is in feature-freeze to
&gt; get ready for a stable 0.2.1.x release.  Could I ask you to remind me
&gt; to look at this patch again once 0.2.1.x is on a stable branch and
&gt; 0.2.2.x development is underway?

Hello everyone.

I had submitted a patch to allow hidden services to reside on
IPv6-addresses in the last feature-freeze and was told that
it would be shelved for 0.2.1.
I have not heard anything about it since. Is it included
in 0.2.1 and if not, what open issues exist with it?

Marcus
</body></email><email><emailId>20090116211027</emailId><senderName>Christopher Davis</senderName><senderEmail>loafier@gmail.com</senderEmail><timestampReceived>2009-01-16 21:10:27-0400</timestampReceived><subject>Patch to enable socks4/5 support for OR connections</subject><body>

Hello,

I mentioned this work breifly in a post to or-talk just recently.
Hopefully, this can be useful to others.

Directory connections could be made to use SOCKS proxies, as well,
using the same framework. Although, as Roger explained in his reply 
to my post to or-talk, supporting OR connections seems to be enough
to get things working.

The SOCKS 5 client supports rfc 1929 user/pass auth if the 
configuration directives are set. The SOCKS 4 user id is always 
left empty.

Functions to connect through the proxy server are in connection.c.
I moved in the functions for HTTP CONNECT proxy support from
connection_or.c, so that there is a consistent framework. Hopefully
the comments are enough to explain how it works, but if not, I 
can expand them a bit. 

Thanks,
-- 
Christopher Davis

["tor_or_connection_socks.patch" (text/plain)]

Index: src/or/connection_or.c
===================================================================
--- src/or/connection_or.c	(revision 18118)
+++ src/or/connection_or.c	(working copy)
@@ -187,66 +187,6 @@
   return 0;
 }
 
-/** Read conn's inbuf. If the http response from the proxy is all
- * here, make sure it's good news, and begin the tls handshake. If
- * it's bad news, close the connection and return -1. Else return 0
- * and hope for better luck next time.
- */
-static int
-connection_or_read_proxy_response(or_connection_t *or_conn)
-{
-  char *headers;
-  char *reason=NULL;
-  int status_code;
-  time_t date_header;
-  connection_t *conn = TO_CONN(or_conn);
-
-  switch (fetch_from_buf_http(conn-&gt;inbuf,
-                              &amp;headers, MAX_HEADERS_SIZE,
-                              NULL, NULL, 10000, 0)) {
-    case -1: /* overflow */
-      log_warn(LD_PROTOCOL,
-               "Your https proxy sent back an oversized response. Closing.");
-      return -1;
-    case 0:
-      log_info(LD_OR,"https proxy response not all here yet. Waiting.");
-      return 0;
-    /* case 1, fall through */
-  }
-
-  if (parse_http_response(headers, &amp;status_code, &amp;date_header,
-                          NULL, &amp;reason) &lt; 0) {
-    log_warn(LD_OR,
-             "Unparseable headers from proxy (connecting to '%s'). Closing.",
-             conn-&gt;address);
-    tor_free(headers);
-    return -1;
-  }
-  if (!reason) reason = tor_strdup("[no reason given]");
-
-  if (status_code == 200) {
-    log_info(LD_OR,
-             "HTTPS connect to '%s' successful! (200 %s) Starting TLS.",
-             conn-&gt;address, escaped(reason));
-    tor_free(reason);
-    if (connection_tls_start_handshake(or_conn, 0) &lt; 0) {
-      /* TLS handshaking error of some kind. */
-      connection_mark_for_close(conn);
-
-      return -1;
-    }
-    return 0;
-  }
-  /* else, bad news on the status code */
-  log_warn(LD_OR,
-           "The https proxy sent back an unexpected status code %d (%s). "
-           "Closing.",
-           status_code, escaped(reason));
-  tor_free(reason);
-  connection_mark_for_close(conn);
-  return -1;
-}
-
 /** Handle any new bytes that have come in on connection &lt;b&gt;conn&lt;/b&gt;.
  * If conn is in 'open' state, hand it to
  * connection_or_process_cells_from_inbuf()
@@ -255,11 +195,24 @@
 int
 connection_or_process_inbuf(or_connection_t *conn)
 {
+  int ret;
   tor_assert(conn);
 
   switch (conn-&gt;_base.state) {
-    case OR_CONN_STATE_PROXY_READING:
-      return connection_or_read_proxy_response(conn);
+    case OR_CONN_STATE_PROXY_HANDSHAKING:
+      ret = connection_read_proxy_handshake(TO_CONN(conn));
+
+      /* start TLS after handshake completion, or deal with error */
+      if (ret == 1) {
+        tor_assert(TO_CONN(conn)-&gt;proxy_state == PROXY_CONNECTED);
+        if (connection_tls_start_handshake(conn, 0) &lt; 0)
+          ret = -1;
+      }
+      if (ret &lt; 0) {
+        connection_mark_for_close(TO_CONN(conn));
+      }
+
+      return ret;
     case OR_CONN_STATE_OPEN:
     case OR_CONN_STATE_OR_HANDSHAKING:
       return connection_or_process_cells_from_inbuf(conn);
@@ -312,11 +265,7 @@
   assert_connection_ok(TO_CONN(conn),0);
 
   switch (conn-&gt;_base.state) {
-    case OR_CONN_STATE_PROXY_FLUSHING:
-      log_debug(LD_OR,"finished sending CONNECT to proxy.");
-      conn-&gt;_base.state = OR_CONN_STATE_PROXY_READING;
-      connection_stop_writing(TO_CONN(conn));
-      break;
+    case OR_CONN_STATE_PROXY_HANDSHAKING:
     case OR_CONN_STATE_OPEN:
     case OR_CONN_STATE_OR_HANDSHAKING:
       connection_stop_writing(TO_CONN(conn));
@@ -334,6 +283,7 @@
 int
 connection_or_finished_connecting(or_connection_t *or_conn)
 {
+  int proxy_type;
   connection_t *conn;
   tor_assert(or_conn);
   conn = TO_CONN(or_conn);
@@ -343,28 +293,24 @@
             conn-&gt;address,conn-&gt;port);
   control_event_bootstrap(BOOTSTRAP_STATUS_HANDSHAKE, 0);
 
-  if (get_options()-&gt;HttpsProxy) {
-    char buf[1024];
-    char *base64_authenticator=NULL;
-    const char *authenticator = get_options()-&gt;HttpsProxyAuthenticator;
+  proxy_type = PROXY_NONE;
 
-    if (authenticator) {
-      base64_authenticator = alloc_http_authenticator(authenticator);
-      if (!base64_authenticator)
-        log_warn(LD_OR, "Encoding https authenticator failed");
+  if (get_options()-&gt;HttpsProxy)
+    proxy_type = PROXY_CONNECT;
+  else if (get_options()-&gt;Socks4Proxy)
+    proxy_type = PROXY_SOCKS4;
+  else if (get_options()-&gt;Socks5Proxy)
+    proxy_type = PROXY_SOCKS5;
+
+  if (proxy_type != PROXY_NONE) {
+    /* start proxy handshake */
+    if (connection_proxy_connect(conn, proxy_type) &lt; 0) {
+      connection_mark_for_close(conn);
+      return -1;
     }
-    if (base64_authenticator) {
-      tor_snprintf(buf, sizeof(buf), "CONNECT %s:%d HTTP/1.1\r\n"
-                   "Proxy-Authorization: Basic %s\r\n\r\n",
-                   fmt_addr(&amp;conn-&gt;addr),
-                   conn-&gt;port, base64_authenticator);
-      tor_free(base64_authenticator);
-    } else {
-      tor_snprintf(buf, sizeof(buf), "CONNECT %s:%d HTTP/1.0\r\n\r\n",
-                   fmt_addr(&amp;conn-&gt;addr), conn-&gt;port);
-    }
-    connection_write_to_buf(buf, strlen(buf), conn);
-    conn-&gt;state = OR_CONN_STATE_PROXY_FLUSHING;
+
+    connection_start_reading(conn);
+    conn-&gt;state = OR_CONN_STATE_PROXY_HANDSHAKING;
     return 0;
   }
 
@@ -730,6 +676,7 @@
   or_connection_t *conn;
   or_options_t *options = get_options();
   int socket_error = 0;
+  int using_proxy = 0;
   tor_addr_t addr;
 
   tor_assert(_addr);
@@ -748,19 +695,28 @@
   conn-&gt;_base.state = OR_CONN_STATE_CONNECTING;
   control_event_or_conn_status(conn, OR_CONN_EVENT_LAUNCHED, 0);
 
+  /* use a proxy server if available */
   if (options-&gt;HttpsProxy) {
-    /* we shouldn't connect directly. use the https proxy instead. */
+    using_proxy = 1;
     tor_addr_from_ipv4h(&amp;addr, options-&gt;HttpsProxyAddr);
     port = options-&gt;HttpsProxyPort;
+  } else if (options-&gt;Socks4Proxy) {
+    using_proxy = 1;
+    tor_addr_from_ipv4h(&amp;addr, options-&gt;Socks4ProxyAddr);
+    port = options-&gt;Socks4ProxyPort;
+  } else if (options-&gt;Socks5Proxy) {
+    using_proxy = 1;
+    tor_addr_from_ipv4h(&amp;addr, options-&gt;Socks5ProxyAddr);
+    port = options-&gt;Socks5ProxyPort;
   }
 
   switch (connection_connect(TO_CONN(conn), conn-&gt;_base.address,
                              &amp;addr, port, &amp;socket_error)) {
     case -1:
       /* If the connection failed immediately, and we're using
-       * an https proxy, our https proxy is down. Don't blame the
-       * Tor server. */
-      if (!options-&gt;HttpsProxy) {
+       * a proxy, our proxy is down. Don't blame the Tor server.
+       */
+      if (!using_proxy) {
         entry_guard_register_connect_status(conn-&gt;identity_digest, 0,
                                             time(NULL));
         router_set_status(conn-&gt;identity_digest, 0);
Index: src/or/config.c
===================================================================
--- src/or/config.c	(revision 18118)
+++ src/or/config.c	(working copy)
@@ -238,6 +238,10 @@
   V(HttpProxyAuthenticator,      STRING,   NULL),
   V(HttpsProxy,                  STRING,   NULL),
   V(HttpsProxyAuthenticator,     STRING,   NULL),
+  V(Socks4Proxy,                 STRING,   NULL),
+  V(Socks5Proxy,                 STRING,   NULL),
+  V(Socks5ProxyUsername,         STRING,   NULL),
+  V(Socks5ProxyPassword,         STRING,   NULL),
   OBSOLETE("IgnoreVersion"),
   V(KeepalivePeriod,             INTERVAL, "5 minutes"),
   VAR("Log",                     LINELIST, Logs,             NULL),
@@ -3360,6 +3364,42 @@
       REJECT("HttpsProxyAuthenticator is too long (&gt;= 48 chars).");
   }
 
+  if (options-&gt;Socks4Proxy) { /* parse it now */
+    if (parse_addr_port(LOG_WARN, options-&gt;Socks4Proxy, NULL,
+                        &amp;options-&gt;Socks4ProxyAddr,
+                        &amp;options-&gt;Socks4ProxyPort) &lt;0)
+      REJECT("Socks4Proxy failed to parse or resolve. Please fix.");
+    if (options-&gt;Socks4ProxyPort == 0) { /* give it a default */
+      options-&gt;Socks4ProxyPort = 1080;
+    }
+  }
+
+  if (options-&gt;Socks5Proxy) { /* parse it now */
+    if (parse_addr_port(LOG_WARN, options-&gt;Socks5Proxy, NULL,
+                        &amp;options-&gt;Socks5ProxyAddr,
+                        &amp;options-&gt;Socks5ProxyPort) &lt;0)
+      REJECT("Socks5Proxy failed to parse or resolve. Please fix.");
+    if (options-&gt;Socks5ProxyPort == 0) { /* give it a default */
+      options-&gt;Socks5ProxyPort = 1080;
+    }
+  }
+
+  if (options-&gt;Socks5ProxyUsername) {
+    size_t len;
+
+    len = strlen(options-&gt;Socks5ProxyUsername);
+    if (len &lt; 1 || len &gt; 255)
+      REJECT("Socks5ProxyUsername must be between 1 and 255 characters.");
+
+    if (!options-&gt;Socks5ProxyPassword)
+      REJECT("Socks5ProxyPassword must be included with Socks5ProxyUsername.");
+
+    len = strlen(options-&gt;Socks5ProxyPassword);
+    if (len &lt; 1 || len &gt; 255)
+      REJECT("Socks5ProxyPassword must be between 1 and 255 characters.");
+  } else if (options-&gt;Socks5ProxyPassword)
+    REJECT("Socks5ProxyPassword must be included with Socks5ProxyUsername.");
+
   if (options-&gt;HashedControlPassword) {
     smartlist_t *sl = decode_hashed_passwords(options-&gt;HashedControlPassword);
     if (!sl) {
Index: src/or/or.h
===================================================================
--- src/or/or.h	(revision 18118)
+++ src/or/or.h	(working copy)
@@ -221,6 +221,21 @@
 /* !!!! If _CONN_TYPE_MAX is ever over 15, we must grow the type field in
  * connection_t. */
 
+/* Proxy client types */
+#define PROXY_NONE 0
+#define PROXY_CONNECT 1
+#define PROXY_SOCKS4 2
+#define PROXY_SOCKS5 3
+
+/* Proxy client handshake states */
+#define PROXY_HTTPS_WANT_CONNECT_OK 1
+#define PROXY_SOCKS4_WANT_CONNECT_OK 2
+#define PROXY_SOCKS5_WANT_AUTH_METHOD_NONE 3
+#define PROXY_SOCKS5_WANT_AUTH_METHOD_RFC1929 4
+#define PROXY_SOCKS5_WANT_AUTH_RFC1929_OK 5
+#define PROXY_SOCKS5_WANT_CONNECT_OK 6
+#define PROXY_CONNECTED 7
+
 /** True iff &lt;b&gt;x&lt;/b&gt; is an edge connection. */
 #define CONN_IS_EDGE(x) \
   ((x)-&gt;type == CONN_TYPE_EXIT || (x)-&gt;type == CONN_TYPE_AP)
@@ -241,26 +256,24 @@
 #define _OR_CONN_STATE_MIN 1
 /** State for a connection to an OR: waiting for connect() to finish. */
 #define OR_CONN_STATE_CONNECTING 1
-/** State for a connection to an OR: waiting for proxy command to flush. */
-#define OR_CONN_STATE_PROXY_FLUSHING 2
-/** State for a connection to an OR: waiting for proxy response. */
-#define OR_CONN_STATE_PROXY_READING 3
+/** State for a connection to an OR: waiting for proxy handshake to complete */
+#define OR_CONN_STATE_PROXY_HANDSHAKING 2
 /** State for a connection to an OR or client: SSL is handshaking, not done
  * yet. */
-#define OR_CONN_STATE_TLS_HANDSHAKING 4
+#define OR_CONN_STATE_TLS_HANDSHAKING 3
 /** State for a connection to an OR: We're doing a second SSL handshake for
  * renegotiation purposes. */
-#define OR_CONN_STATE_TLS_CLIENT_RENEGOTIATING 5
+#define OR_CONN_STATE_TLS_CLIENT_RENEGOTIATING 4
 /** State for a connection at an OR: We're waiting for the client to
  * renegotiate. */
-#define OR_CONN_STATE_TLS_SERVER_RENEGOTIATING 6
+#define OR_CONN_STATE_TLS_SERVER_RENEGOTIATING 5
 /** State for a connection to an OR: We're done with our SSL handshake, but we
  * haven't yet negotiated link protocol versions and sent a netinfo cell.
  */
-#define OR_CONN_STATE_OR_HANDSHAKING 7
+#define OR_CONN_STATE_OR_HANDSHAKING 6
 /** State for a connection to an OR: Ready to send/receive cells. */
-#define OR_CONN_STATE_OPEN 8
-#define _OR_CONN_STATE_MAX 8
+#define OR_CONN_STATE_OPEN 7
+#define _OR_CONN_STATE_MAX 7
 
 #define _EXIT_CONN_STATE_MIN 1
 /** State for an exit connection: waiting for response from dns farm. */
@@ -971,6 +984,9 @@
    * to the evdns_server_port is uses to listen to and answer connections. */
   struct evdns_server_port *dns_server_port;
 
+  /** CONNECT/SOCKS proxy client handshake state (for outgoing connections). */
+  unsigned int proxy_state:4;
+
 } connection_t;
 
 /** Stores flags and information related to the portion of a v2 Tor OR
@@ -2355,6 +2371,16 @@
   uint16_t HttpsProxyPort; /**&lt; Parsed port for https proxy, if any. */
   char *HttpsProxyAuthenticator; /**&lt; username:password string, if any. */
 
+  char *Socks4Proxy;
+  uint32_t Socks4ProxyAddr;
+  uint16_t Socks4ProxyPort;
+
+  char *Socks5Proxy;
+  uint32_t Socks5ProxyAddr;
+  uint16_t Socks5ProxyPort;
+  char *Socks5ProxyUsername;
+  char *Socks5ProxyPassword;
+
   /** List of configuration lines for replacement directory authorities.
    * If you just want to replace one class of authority at a time,
    * use the "Alternate*Authority" options below instead. */
@@ -2690,6 +2716,7 @@
                         int force_complete);
 int fetch_from_buf_socks(buf_t *buf, socks_request_t *req,
                          int log_sockstype, int safe_socks);
+int fetch_from_buf_socks_client(buf_t *buf, int state, char **reason);
 int fetch_from_buf_line(buf_t *buf, char *data_out, size_t *data_len);
 
 int peek_buf_has_control0_command(buf_t *buf);
@@ -2949,6 +2976,10 @@
 int connection_connect(connection_t *conn, const char *address,
                        const tor_addr_t *addr,
                        uint16_t port, int *socket_error);
+
+int connection_proxy_connect(connection_t *conn, int type);
+int connection_read_proxy_handshake(connection_t *conn);
+
 int retry_all_listeners(smartlist_t *replaced_conns,
                         smartlist_t *new_conns);
 
Index: src/or/buffers.c
===================================================================
--- src/or/buffers.c	(revision 18118)
+++ src/or/buffers.c	(working copy)
@@ -1600,6 +1600,177 @@
   }
 }
 
+/** Inspect a reply from SOCKS server stored in &lt;b&gt;buf&lt;/b&gt; according
+ * to &lt;b&gt;state&lt;/b&gt;, removing the protocol data upon success. Return 0 on
+ * incomplete response, 1 on success and -1 on error, in which case
+ * &lt;b&gt;reason&lt;/b&gt; is set to a descriptive message (free() when finished
+ * with it).
+ *
+ * As a special case, 2 is returned when user/pass is required
+ * during SOCKS5 handshake and user/pass is configured.
+ */
+int
+fetch_from_buf_socks_client(buf_t *buf, int state, char **reason)
+{
+  unsigned char *data;
+  size_t addrlen;
+
+  if (buf-&gt;datalen &lt; 2)
+    return 0;
+
+  buf_pullup(buf, 128, 0);
+  tor_assert(buf-&gt;head &amp;&amp; buf-&gt;head-&gt;datalen &gt;= 2);
+
+  data = (unsigned char *) buf-&gt;head-&gt;data;
+
+  switch (state) {
+    case PROXY_SOCKS4_WANT_CONNECT_OK:
+      /* Wait for the complete response */
+      if (buf-&gt;head-&gt;datalen &lt; 8)
+        return 0;
+
+      if (data[1] != 0x5a) {
+        switch (data[1]) {
+          case 0x5b:
+            *reason = tor_strdup("server rejected connection");
+            break;
+          case 0x5c:
+            *reason = tor_strdup("server cannot connect to identd "
+                                 "on this client");
+            break;
+          case 0x5d:
+            *reason = tor_strdup("user id does not match identd");
+            break;
+          default:
+            *reason = tor_strdup("invalid SOCKS 4 response code");
+            break;
+        }
+
+        return -1;
+      }
+
+      /* Success */
+      buf_remove_from_front(buf, 8);
+      return 1;
+
+    case PROXY_SOCKS5_WANT_AUTH_METHOD_NONE:
+      /* we don't have any credentials */
+      if (data[1] != 0x00) {
+        *reason = tor_strdup("server doesn't support any of our "
+                             "available authentication methods");
+        return -1;
+      }
+
+      log_info(LD_NET, "SOCKS 5 client: continuing without authentication");
+      buf_clear(buf);
+      return 1;
+
+    case PROXY_SOCKS5_WANT_AUTH_METHOD_RFC1929:
+      /* we have a username and password. return 1 if we can proceed without
+       * providing authentication, or 2 otherwise. */
+      switch (data[1]) {
+        case 0x00:
+          log_info(LD_NET, "SOCKS 5 client: we have auth details but server "
+                            "doesn't require authentication.");
+          buf_clear(buf);
+          return 1;
+        case 0x02:
+          log_info(LD_NET, "SOCKS 5 client: need authentication.");
+          buf_clear(buf);
+          return 2;
+        /* fall through */
+      }
+
+      *reason = tor_strdup("server doesn't support any of our available "
+                           "authentication methods");
+      return -1;
+
+    case PROXY_SOCKS5_WANT_AUTH_RFC1929_OK:
+      /* handle server reply to rfc1929 authentication */
+      if (data[1] != 0x00) {
+        *reason = tor_strdup("authentication failed");
+        return -1;
+      }
+
+      log_info(LD_NET, "SOCKS 5 client: authentication successful.");
+      buf_clear(buf);
+      return 1;
+
+    case PROXY_SOCKS5_WANT_CONNECT_OK:
+      /* response is variable length. BND.ADDR, etc, isn't needed
+       * (don't bother with buf_pullup()), but make sure to eat all
+       * the data used */
+
+      /* wait for address type field to arrive */
+      if (buf-&gt;datalen &lt; 4)
+        return 0;
+
+      switch (data[3]) {
+        case 0x01: /* ip4 */
+          addrlen = 4;
+          break;
+        case 0x04: /* ip6 */
+          addrlen = 16;
+          break;
+        case 0x03: /* fqdn (can this happen here?) */
+          if (buf-&gt;datalen &lt; 5)
+            return 0;
+          addrlen = 1 + data[4];
+          break;
+        default:
+          *reason = tor_strdup("invalid response to connect request");
+          return -1;
+      }
+
+      /* wait for address and port */
+      if (buf-&gt;datalen &lt; 6 + addrlen)
+        return 0;
+
+      if (data[1] != 0x00) {
+
+        switch (data[1]) {
+          case 0x01:
+            *reason = tor_strdup("general SOCKS server failure");
+            break;
+          case 0x02:
+            *reason = tor_strdup("connection not allowed by ruleset");
+            break;
+          case 0x03:
+            *reason = tor_strdup("Network unreachable");
+            break;
+          case 0x04:
+            *reason = tor_strdup("Host unreachable");
+            break;
+          case 0x05:
+            *reason = tor_strdup("Connection refused");
+            break;
+          case 0x06:
+            *reason = tor_strdup("TTL expired");
+            break;
+          case 0x07:
+            *reason = tor_strdup("Command not supported");
+            break;
+          case 0x08:
+            *reason = tor_strdup("Address type not supported");
+            break;
+          default:
+            *reason = tor_strdup("unknown reason");
+            break;
+        }
+
+        return -1;
+      }
+
+      buf_remove_from_front(buf, 6 + addrlen);
+      return 1;
+  }
+
+  /* shouldn't get here... */
+  tor_assert(0);
+
+  return -1;
+}
+
 /** Return 1 iff buf looks more like it has an (obsolete) v0 controller
  * command on it than any valid v1 controller command. */
 int
Index: src/or/connection.c
===================================================================
--- src/or/connection.c	(revision 18118)
+++ src/or/connection.c	(working copy)
@@ -32,6 +32,10 @@
 static void client_check_address_changed(int sock);
 static void set_constrained_socket_buffers(int sock, int size);
 
+static const char *connection_proxy_state_to_string(int state);
+static int connection_read_https_proxy_response(connection_t *conn);
+static void connection_send_socks5_connect(connection_t *conn);
+
 /** The last IPv4 address that our network interface seemed to have been
  * binding to, in host order.  We use this to detect when our IP changes. */
 static uint32_t last_interface_ip = 0;
@@ -92,8 +96,7 @@
     case CONN_TYPE_OR:
       switch (state) {
         case OR_CONN_STATE_CONNECTING: return "connect()ing";
-        case OR_CONN_STATE_PROXY_FLUSHING: return "proxy flushing";
-        case OR_CONN_STATE_PROXY_READING: return "proxy reading";
+        case OR_CONN_STATE_PROXY_HANDSHAKING: return "handshaking (proxy)";
         case OR_CONN_STATE_TLS_HANDSHAKING: return "handshaking (TLS)";
         case OR_CONN_STATE_TLS_CLIENT_RENEGOTIATING:
           return "renegotiating (TLS)";
@@ -1315,6 +1318,353 @@
   return inprogress ? 0 : 1;
 }
 
+/** Convert state number to string representation for logging purposes.
+ */
+static const char *
+connection_proxy_state_to_string(int state)
+{
+  static const char *unknown = "???";
+  static const char *states[] = {
+    "PROXY_NONE",
+    "PROXY_HTTPS_WANT_CONNECT_OK",
+    "PROXY_SOCKS4_WANT_CONNECT_OK",
+    "PROXY_SOCKS5_WANT_AUTH_METHOD_NONE",
+    "PROXY_SOCKS5_WANT_AUTH_METHOD_RFC1929",
+    "PROXY_SOCKS5_WANT_AUTH_RFC1929_OK",
+    "PROXY_SOCKS5_WANT_CONNECT_OK",
+    "PROXY_CONNECTED",
+  };
+
+  if (state &lt; PROXY_NONE || state &gt; PROXY_CONNECTED)
+    return unknown;
+
+  return states[state];
+}
+
+/** Write a proxy request of &lt;b&gt;type&lt;/b&gt; (socks4, socks5, https) to conn
+ * for conn-&gt;addr:conn-&gt;port, authenticating with the auth details given
+ * in the configuration (if available). SOCKS 5 and HTTP CONNECT proxies
+ * support authentication.
+ *
+ * Returns -1 if conn-&gt;addr is incompatible with the proxy protocol, and
+ * 0 otherwise.
+ *
+ * Use connection_read_proxy_handshake() to complete the handshake.
+ */
+int
+connection_proxy_connect(connection_t *conn, int type)
+{
+  or_options_t *options;
+
+  tor_assert(conn);
+
+  options = get_options();
+
+  switch (type) {
+    case PROXY_CONNECT: {
+      char buf[1024];
+      char *base64_authenticator=NULL;
+      const char *authenticator = options-&gt;HttpsProxyAuthenticator;
+
+      /* Send HTTP CONNECT and authentication (if available) in
+       * one request */
+
+      if (authenticator) {
+        base64_authenticator = alloc_http_authenticator(authenticator);
+        if (!base64_authenticator)
+          log_warn(LD_OR, "Encoding https authenticator failed");
+      }
+
+      if (base64_authenticator) {
+        tor_snprintf(buf, sizeof(buf), "CONNECT %s:%d HTTP/1.1\r\n"
+                     "Proxy-Authorization: Basic %s\r\n\r\n",
+                     fmt_addr(&amp;conn-&gt;addr),
+                     conn-&gt;port, base64_authenticator);
+        tor_free(base64_authenticator);
+      } else {
+        tor_snprintf(buf, sizeof(buf), "CONNECT %s:%d HTTP/1.0\r\n\r\n",
+                     fmt_addr(&amp;conn-&gt;addr), conn-&gt;port);
+      }
+
+      connection_write_to_buf(buf, strlen(buf), conn);
+      conn-&gt;proxy_state = PROXY_HTTPS_WANT_CONNECT_OK;
+      break;
+    }
+
+    case PROXY_SOCKS4: {
+      unsigned char buf[9];
+      uint16_t portn;
+      uint32_t ip4addr;
+
+      /* Send a SOCKS4 connect request with empty user id */
+
+      if (tor_addr_family(&amp;conn-&gt;addr) != AF_INET) {
+        log_warn(LD_NET, "SOCKS4 client is incompatible with with IPv6");
+        return -1;
+      }
+
+      ip4addr = tor_addr_to_ipv4n(&amp;conn-&gt;addr);
+      portn = htons(conn-&gt;port);
+
+      buf[0] = 4; /* version */
+      buf[1] = SOCKS_COMMAND_CONNECT; /* command */
+      memcpy(buf + 2, &amp;portn, 2); /* port */
+      memcpy(buf + 4, &amp;ip4addr, 4); /* addr */
+      buf[8] = 0; /* userid (empty) */
+
+      connection_write_to_buf((char *)buf, sizeof buf, conn);
+      conn-&gt;proxy_state = PROXY_SOCKS4_WANT_CONNECT_OK;
+      break;
+    }
+
+    case PROXY_SOCKS5: {
+      unsigned char buf[4]; /* fields: vers, num methods, method list */
+
+      /* Send a SOCKS5 greeting (connect request must wait) */
+
+      buf[0] = 5; /* version */
+
+      /* number of auth methods */
+      if (options-&gt;Socks5ProxyUsername) {
+        buf[1] = 2;
+        buf[2] = 0x00; /* no authentication */
+        buf[3] = 0x02; /* rfc1929 Username/Passwd auth */
+        conn-&gt;proxy_state = PROXY_SOCKS5_WANT_AUTH_METHOD_RFC1929;
+      } else {
+        buf[1] = 1;
+        buf[2] = 0x00; /* no authentication */
+        conn-&gt;proxy_state = PROXY_SOCKS5_WANT_AUTH_METHOD_NONE;
+      }
+
+      connection_write_to_buf((char *)buf, 2 + buf[1], conn);
+      break;
+    }
+
+    default:
+      log_err(LD_BUG, "Invalid proxy protocol, %d", type);
+      tor_fragile_assert();
+      return -1;
+  }
+
+  log_debug(LD_NET, "set state %s",
+            connection_proxy_state_to_string(conn-&gt;proxy_state));
+
+  return 0;
+}
+
+/** Read conn's inbuf. If the http response from the proxy is all
+ * here, make sure it's good news, then return 1. If it's bad news,
+ * return -1. Else return 0 and hope for better luck next time.
+ */
+static int
+connection_read_https_proxy_response(connection_t *conn)
+{
+  char *headers;
+  char *reason=NULL;
+  int status_code;
+  time_t date_header;
+
+  switch (fetch_from_buf_http(conn-&gt;inbuf,
+                              &amp;headers, MAX_HEADERS_SIZE,
+                              NULL, NULL, 10000, 0)) {
+    case -1: /* overflow */
+      log_warn(LD_PROTOCOL,
+               "Your https proxy sent back an oversized response. Closing.");
+      return -1;
+    case 0:
+      log_info(LD_NET,"https proxy response not all here yet. Waiting.");
+      return 0;
+    /* case 1, fall through */
+  }
+
+  if (parse_http_response(headers, &amp;status_code, &amp;date_header,
+                          NULL, &amp;reason) &lt; 0) {
+    log_warn(LD_NET,
+             "Unparseable headers from proxy (connecting to '%s'). Closing.",
+             conn-&gt;address);
+    tor_free(headers);
+    return -1;
+  }
+  if (!reason) reason = tor_strdup("[no reason given]");
+
+  if (status_code == 200) {
+    log_info(LD_NET,
+             "HTTPS connect to '%s' successful! (200 %s) Starting TLS.",
+             conn-&gt;address, escaped(reason));
+    tor_free(reason);
+    return 1;
+  }
+  /* else, bad news on the status code */
+  log_warn(LD_NET,
+           "The https proxy sent back an unexpected status code %d (%s). "
+           "Closing.",
+           status_code, escaped(reason));
+  tor_free(reason);
+  return -1;
+}
+
+/** Send SOCKS5 CONNECT command to &lt;b&gt;conn&lt;/b&gt;, copying &lt;b&gt;conn-&gt;addr&lt;/b&gt;
+ * and &lt;b&gt;conn-&gt;port&lt;/b&gt; into the request.
+ */
+static void
+connection_send_socks5_connect(connection_t *conn)
+{
+  unsigned char buf[1024];
+  size_t reqsize = 6;
+  uint16_t port = htons(conn-&gt;port);
+
+  buf[0] = 5; /* version */
+  buf[1] = SOCKS_COMMAND_CONNECT; /* command */
+  buf[2] = 0; /* reserved */
+
+  if (tor_addr_family(&amp;conn-&gt;addr) == AF_INET) {
+    uint32_t addr = tor_addr_to_ipv4n(&amp;conn-&gt;addr);
+
+    buf[3] = 1;
+    reqsize += 4;
+    memcpy(buf + 4, &amp;addr, 4);
+    memcpy(buf + 8, &amp;port, 2);
+  } else { /* AF_INET6 */
+    buf[3] = 4;
+    reqsize += 16;
+    memcpy(buf + 4, tor_addr_to_in6(&amp;conn-&gt;addr), 16);
+    memcpy(buf + 20, &amp;port, 2);
+  }
+
+  connection_write_to_buf((char *)buf, reqsize, conn);
+
+  conn-&gt;proxy_state = PROXY_SOCKS5_WANT_CONNECT_OK;
+}
+
+/** Call this from connection_*_process_inbuf() to advance the proxy
+ * handshake.
+ *
+ * No matter what proxy protocol is used, if this function returns 1, the
+ * handshake is complete, and the data remaining on inbuf may contain the
+ * start of the communication with the requested server.
+ *
+ * Returns 0 if the current buffer contains an incomplete response, and -1
+ * on error.
+ */
+int
+connection_read_proxy_handshake(connection_t *conn)
+{
+  int ret = 0;
+  char *reason = NULL;
+
+  log_debug(LD_NET, "enter state %s",
+            connection_proxy_state_to_string(conn-&gt;proxy_state));
+
+  switch (conn-&gt;proxy_state) {
+    case PROXY_HTTPS_WANT_CONNECT_OK:
+      ret = connection_read_https_proxy_response(conn);
+      if (ret == 1)
+        conn-&gt;proxy_state = PROXY_CONNECTED;
+      break;
+
+    case PROXY_SOCKS4_WANT_CONNECT_OK:
+      ret = fetch_from_buf_socks_client(conn-&gt;inbuf,
+                                        conn-&gt;proxy_state,
+                                        &amp;reason);
+      if (ret == 1)
+        conn-&gt;proxy_state = PROXY_CONNECTED;
+      break;
+
+    case PROXY_SOCKS5_WANT_AUTH_METHOD_NONE:
+      ret = fetch_from_buf_socks_client(conn-&gt;inbuf,
+                                        conn-&gt;proxy_state,
+                                        &amp;reason);
+      /* no auth needed, do connect */
+      if (ret == 1) {
+        connection_send_socks5_connect(conn);
+        ret = 0;
+      }
+      break;
+
+    case PROXY_SOCKS5_WANT_AUTH_METHOD_RFC1929:
+      ret = fetch_from_buf_socks_client(conn-&gt;inbuf,
+                                        conn-&gt;proxy_state,
+                                        &amp;reason);
+
+      /* send auth if needed, otherwise do connect */
+      if (ret == 1) {
+        connection_send_socks5_connect(conn);
+        ret = 0;
+      } else if (ret == 2) {
+        unsigned char buf[1024];
+        size_t reqsize, usize, psize;
+        const char *user, *pass;
+
+        user = get_options()-&gt;Socks5ProxyUsername;
+        pass = get_options()-&gt;Socks5ProxyPassword;
+        tor_assert(user &amp;&amp; pass);
+
+        /* XXX len of user and pass must be &lt;= 255 !!! */
+        usize = strlen(user);
+        psize = strlen(pass);
+        tor_assert(usize &lt;= 255 &amp;&amp; psize &lt;= 255);
+        reqsize = 3 + usize + psize;
+
+        buf[0] = 1; /* negotiation version */
+        buf[1] = usize;
+        memcpy(buf + 2, user, usize);
+        buf[2 + usize] = psize;
+        memcpy(buf + 3 + usize, pass, psize);
+
+        connection_write_to_buf((char *)buf, reqsize, conn);
+
+        conn-&gt;proxy_state = PROXY_SOCKS5_WANT_AUTH_RFC1929_OK;
+        ret = 0;
+      }
+      break;
+
+    case PROXY_SOCKS5_WANT_AUTH_RFC1929_OK:
+      ret = fetch_from_buf_socks_client(conn-&gt;inbuf,
+                                        conn-&gt;proxy_state,
+                                        &amp;reason);
+      /* send the connect request */
+      if (ret == 1) {
+        connection_send_socks5_connect(conn);
+        ret = 0;
+      }
+      break;
+
+    case PROXY_SOCKS5_WANT_CONNECT_OK:
+      ret = fetch_from_buf_socks_client(conn-&gt;inbuf,
+                                        conn-&gt;proxy_state,
+                                        &amp;reason);
+      if (ret == 1)
+        conn-&gt;proxy_state = PROXY_CONNECTED;
+      break;
+
+    default:
+      log_err(LD_BUG, "Invalid proxy_state for reading, %d",
+              conn-&gt;proxy_state);
+      tor_fragile_assert();
+      ret = -1;
+      break;
+  }
+
+  log_debug(LD_NET, "leaving state %s",
+            connection_proxy_state_to_string(conn-&gt;proxy_state));
+
+  if (ret &lt; 0) {
+    if (reason) {
+      log_warn(LD_NET, "Proxy Client: unable to connect to %s:%d (%s)",
+                conn-&gt;address, conn-&gt;port, escaped(reason));
+      tor_free(reason);
+    } else {
+      log_warn(LD_NET, "Proxy Client: unable to connect to %s:%d",
+                conn-&gt;address, conn-&gt;port);
+    }
+  } else if (ret == 1) {
+    log_info(LD_NET, "Proxy Client: connection to %s:%d successful",
+              conn-&gt;address, conn-&gt;port);
+  }
+
+  return ret;
+}
+
 /**
  * Launch any configured listener connections of type &lt;b&gt;type&lt;/b&gt;.  (A
  * listener is configured if &lt;b&gt;port_option&lt;/b&gt; is non-zero.  If any
@@ -2075,7 +2425,7 @@
   }
 
   if (connection_speaks_cells(conn) &amp;&amp;
-      conn-&gt;state &gt; OR_CONN_STATE_PROXY_READING) {
+      conn-&gt;state &gt; OR_CONN_STATE_PROXY_HANDSHAKING) {
     int pending;
     or_connection_t *or_conn = TO_OR_CONN(conn);
     size_t initial_size;
@@ -2303,7 +2653,7 @@
     : connection_bucket_write_limit(conn, now);
 
   if (connection_speaks_cells(conn) &amp;&amp;
-      conn-&gt;state &gt; OR_CONN_STATE_PROXY_READING) {
+      conn-&gt;state &gt; OR_CONN_STATE_PROXY_HANDSHAKING) {
     or_connection_t *or_conn = TO_OR_CONN(conn);
     if (conn-&gt;state == OR_CONN_STATE_TLS_HANDSHAKING ||
         conn-&gt;state == OR_CONN_STATE_TLS_CLIENT_RENEGOTIATING) {
@@ -3033,7 +3383,7 @@
     }
 //    tor_assert(conn-&gt;addr &amp;&amp; conn-&gt;port);
     tor_assert(conn-&gt;address);
-    if (conn-&gt;state &gt; OR_CONN_STATE_PROXY_READING)
+    if (conn-&gt;state &gt; OR_CONN_STATE_PROXY_HANDSHAKING)
       tor_assert(or_conn-&gt;tls);
   }
 
Index: doc/tor.1.in
===================================================================
--- doc/tor.1.in	(revision 18118)
+++ doc/tor.1.in	(working copy)
@@ -292,6 +292,25 @@
 patch if you want it to support others.
 .LP
 .TP
+\fBSocks4Proxy\fR \fIhost\fR[:\fIport\fR]\fP
+Tor will make all OR connections through the SOCKS 4 proxy at host:port
+(or host:1080 if port is not specified).
+.LP
+.TP
+\fBSocks5Proxy\fR \fIhost\fR[:\fIport\fR]\fP
+Tor will make all OR connections through the SOCKS 5 proxy at host:port
+(or host:1080 if port is not specified).
+.LP
+.TP
+\fBSocks5ProxyUsername\fR \fIusername\fP
+.LP
+.TP
+\fBSocks5ProxyPassword\fR \fIpassword\fP
+If defined, authenticate to the SOCKS 5 server using username and password
+in accordance to RFC 1929. Both username and password must be between 1 and 255
+characters.
+.LP
+.TP
 \fBKeepalivePeriod \fR\fINUM\fP
 To keep firewalls from expiring connections, send a padding keepalive
 cell every NUM seconds on open connections that are in use. If the


</body></email><email><emailId>20090118192252</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-01-18 19:22:52-0400</timestampReceived><subject>Proposal 158: Clients download consensus + microdescriptors</subject><body>

Filename: 158-microdescriptors.txt
Title: Clients download consensus + microdescriptors
Version: $Revision: 18172 $
Last-Modified: $Date: 2009-01-18 13:57:20 -0500 (Sun, 18 Jan 2009) $
Author: Roger Dingledine
Created: 17-Jan-2009
Status: Open

1. Overview

  This proposal replaces section 3.2 of proposal 141, which was
  called "Fetching descriptors on demand". Rather than modifying the
  circuit-building protocol to fetch a server descriptor inline at each
  circuit extend, we instead put all of the information that clients need
  either into the consensus itself, or into a new set of data about each
  relay called a microdescriptor. The microdescriptor is a direct
  transform from the relay descriptor, so relays don't even need to know
  this is happening.

  Descriptor elements that are small and frequently changing should go
  in the consensus itself, and descriptor elements that are small and
  relatively static should go in the microdescriptor. If we ever end up
  with descriptor elements that aren't small yet clients need to know
  them, we'll need to resume considering some design like the one in
  proposal 141.

2. Motivation

  See
  http://archives.seul.org/or/dev/Nov-2008/msg00000.html and
  http://archives.seul.org/or/dev/Nov-2008/msg00001.html and especially
  http://archives.seul.org/or/dev/Nov-2008/msg00007.html
  for a discussion of the options and why this is currently the best
  approach.

3. Design

  There are three pieces to the proposal. First, authorities will list in
  their votes (and thus in the consensus) what relay descriptor elements
  are included in the microdescriptor, and also list the expected hash
  of microdescriptor for each relay. Second, directory mirrors will serve
  microdescriptors. Third, clients will ask for them and cache them.

3.1. Consensus changes

  V3 votes should include a new line:
    microdescriptor-elements bar baz foo
  listing each descriptor element (sorted alphabetically) that authority
  included when it calculated its expected microdescriptor hashes.

  We also need to include the hash of each expected microdescriptor in
  the routerstatus section. I suggest a new "m" line for each stanza,
  with the base64 of the hash of the elements that the authority voted
  for above.

  The consensus microdescriptor-elements and "m" lines are then computed
  as described in Section 3.1.2 below.

  I believe that means we need a new consensus-method "6" that knows
  how to compute the microdescriptor-elements and add "m" lines.

3.1.1. Descriptor elements to include for now

  To start, the element list that authorities suggest should be
    family onion-key

  (Note that the or-dev posts above only mention onion-key, but if
  we don't also include family then clients will never learn it. It
  seemed like it should be relatively static, so putting it in the
  microdescriptor is smarter than trying to fit it into the consensus.)

  We could imagine a config option "family,onion-key" so authorities
  could change their voted preferences without needing to upgrade.

3.1.2. Computing consensus for microdescriptor-elements and "m" lines

  One approach is for the consensus microdescriptor-elements line to
  include every element listed by a majority of authorities, sorted. The
  problem here is that it will no longer be deterministic what the correct
  hash for the "m" line should be. We could imagine telling the authority
  to go look in its descriptor and produce the right hash itself, but
  we don't want consensus calculation to be based on external data like
  that. (Plus, the authority may not have the descriptor that everybody
  else voted to use.)

  The better approach is to take the exact set that has the most votes
  (breaking ties by the set that has the most elements, and breaking
  ties after that by whichever is alphabetically first). That will
  increase the odds that we actually get a microdescriptor hash that
  is both a) for the descriptor we're putting in the consensus, and b)
  over the elements that we're declaring it should be for.

  Then the "m" line for a given relay is the one that gets the most votes
  from authorities that both a) voted for the microdescriptor-elements
  line we're using, and b) voted for the descriptor we're using.

  (If there's a tie, use the smaller hash. But really, if there are
  multiple such votes and they differ about a microdescriptor, we caught
  one of them lying or being buggy. We should log it to track down why.)

  If there are no such votes, then we leave out the "m" line for that
  relay. That means clients should avoid it for this time period. (As
  an extension it could instead mean that clients should fetch the
  descriptor and figure out its microdescriptor themselves. But let's
  not get ahead of ourselves.)

  It would be nice to have a more foolproof way to agree on what
  microdescriptor hash each authority should vote for, so we can avoid
  missing "m" lines. Just switching to a new consensus-method each time
  we change the set of microdescriptor-elements won't help though, since
  each authority will still have to decide what hash to vote for before
  knowing what consensus-method will be used.

  Here's one way we could do it. Each vote / consensus includes
  the microdescriptor-elements that were used to compute the hashes,
  and also a preferred-microdescriptor-elements set. If an authority
  has a consensus from the previous period, then it should use the
  consensus preferred-microdescriptor-elements when computing its votes
  for microdescriptor-elements and the appropriate hashes in the upcoming
  period. (If it has no previous consensus, then it just writes its
  own preferences in both lines.)

3.2. Directory mirrors serve microdescriptors

  Directory mirrors should then read the microdescriptor-elements line
  from the consensus, and learn how to answer requests. (Directory mirrors
  continue to serve normal relay descriptors too, a) to serve old clients
  and b) to be able to construct microdescriptors on the fly.)

  The microdescriptors with hashes &lt;D1&gt;,&lt;D2&gt;,&lt;D3&gt; should be available at:
    http://&lt;hostname&gt;/tor/micro/d/&lt;D1&gt;+&lt;D2&gt;+&lt;D3&gt;.z

  All the microdescriptors from the current consensus should also be
  available at:
    http://&lt;hostname&gt;/tor/micro/all.z
  so a client that's bootstrapping doesn't need to send a 70KB URL just
  to name every microdescriptor it's looking for.

  The format of a microdescriptor is the header line
  "microdescriptor-header"
  followed by each element (keyword and body), alphabetically. There's
  no need to mention what hash it's for, since it's self-identifying:
  you can hash the elements to learn this.

  (Do we need a footer line to show that it's over, or is the next
  microdescriptor line or EOF enough of a hint? A footer line wouldn't
  hurt much. Also, no fair voting for the microdescriptor-element
  "microdescriptor-header".)

  The hash of the microdescriptor is simply the hash of the concatenated
  elements -- not counting the header line or hypothetical footer line.
  Unless you prefer that?

  Is there a reasonable way to version these things? We could say that
  the microdescriptor-header line can contain arguments which clients
  must ignore if they don't understand them. Any better ways?

  Directory mirrors should check to make sure that the microdescriptors
  they're about to serve match the right hashes (either the hashes from
  the fetch URL or the hashes from the consensus, respectively).

  We will probably want to consider some sort of smart data structure to
  be able to quickly convert microdescriptor hashes into the appropriate
  microdescriptor. Clients will want this anyway when they load their
  microdescriptor cache and want to match it up with the consensus to
  see what's missing.

3.3. Clients fetch them and cache them

  When a client gets a new consensus, it looks to see if there are any
  microdescriptors it needs to learn. If it needs to learn more than
  some threshold of the microdescriptors (half?), it requests 'all',
  else it requests only the missing ones.

  Clients maintain a cache of microdescriptors along with metadata like
  when it was last referenced by a consensus. They keep a microdescriptor
  until it hasn't been mentioned in any consensus for a week. Future
  clients might cache them for longer or shorter times.

3.3.1. Information leaks from clients

  If a client asks you for a set of microdescs, then you know she didn't
  have them cached before. How much does that leak? What about when
  we're all using our entry guards as directory guards, and we've seen
  that user make a bunch of circuits already?

  Fetching "all" when you need at least half is a good first order fix,
  but might not be all there is to it.

  Another future option would be to fetch some of the microdescriptors
  anonymously (via a Tor circuit).

4. Transition and deployment

  Phase one, the directory authorities should start voting on
  microdescriptors and microdescriptor elements, and putting them in the
  consensus. This should happen during the 0.2.1.x series, and should
  be relatively easy to do.

  Phase two, directory mirrors should learn how to serve them, and learn
  how to read the consensus to find out what they should be serving. This
  phase could be done either in 0.2.1.x or early in 0.2.2.x, depending
  on how messy it turns out to be and how quickly we get around to it.

  Phase three, clients should start fetching and caching them instead
  of normal descriptors. This should happen post 0.2.1.x.

</body></email><email><emailId>20090204092531</emailId><senderName>Csaba Kiraly</senderName><senderEmail>kiraly@disi.unitn.it</senderEmail><timestampReceived>2009-02-04 09:25:31-0400</timestampReceived><subject>Effect of Tor window size on performance</subject><body>

Dear All,

I'm new to the or-dev list so please excuse me if I mention something 
that was already discussed.
We've did a study of Tor's flow-control mechanism, and what came out is 
that reducing the flow-control window size (CIRCWINDOW) would be 
beneficial not just for the individual client, but for the whole Tor 
network.
You can find a tech report describing our results (still work in 
progress) at

http://disi.unitn.it/locigno/preprints/TR-DISI-08-041.pdf

It is also about other topics (namely measures with datagram based 
solutions, in our case using IPsec, and a theoretical evaluation of TCP 
based solutions), but I think what is most interesting for immediate use 
in development is how much the flow-control window size can influence 
application-level delay in an overload situation. In my understanding, 
overload is the natural state of the Tor network, so it is important to 
make the system behave well in these conditions.

I've started to discuss this topic with Roger and he suggested me to 
extend the discussion to the or-dev list. See our conversation below and 
my original mail at the very end of this long mail.
Any feedback/discussion of the ideas is welcome,
Csaba


Roger Dingledine wrote:
&gt; On Sat, Nov 01, 2008 at 07:03:36PM +0100, Csaba Kiraly wrote:
&gt;   
&gt;&gt; One things that could be of immediate use for Tor is the study of Tor's
&gt;&gt; flow-control mechanism, and its behavior with different window sizes. In
&gt;&gt; short, by reducing the window size from the current 1000 to e.g. 200 in
&gt;&gt; the Tor network, there would be a huge decrease in application level
&gt;&gt; round trip times. It would also mean much smaller buffers in OR nodes,
&gt;&gt; reducing their memory consumption significantly. At the same time,
&gt;&gt; throughput would remain the same. Figure 6 of the tech report shows
&gt;&gt; delay and throughput with some window sizes.
&gt;&gt;     
&gt;
&gt; ...
&gt;
&gt; I think these are great ideas. You're right that the initial choice of
&gt; window size was just a random number that I picked that seemed large
&gt; enough to provide good throughput. And on thinking about it more,
&gt; I think you're right that a larger number actually just congests the
&gt; network more.
&gt;
&gt; I've had an item on the 'volunteer' page related to window size for a
&gt; few years now: Item #8 on https://www.torproject.org/volunteer#Research
&gt;
&gt; It seems that variable window sizes would be even more flexible than what
&gt; you propose, since then it could adapt to different levels of congestion.
&gt;   
&gt; In particular, I worry about:
&gt;
&gt;   
&gt;&gt; Your throughput is limited to cell_size * CIRCWINDOW / D (without
&gt;&gt; considering the size of CIRCWINDOW_INCREMENT and delay of the SENDME
&gt;&gt; cell on the return path)
&gt;&gt; With typical data: cell size=0.5 kbytes ; CWND_SIZE=1000, D=1 sec
&gt;&gt; The throughput is limited to 500 kbytes/sec
&gt;&gt;     
&gt;
&gt; What if D=5 because there's still congestion? If we then cut the circuit
&gt; window size by another factor of 5, we end up with an expected throughput
&gt; of 20KB, which is a bit on the 'uncomfortably low' end. (What if D=10?)
&gt;   
As a first attempt we are trying fixed reduced window size. If it gets 
variable, what we introduce instead of the current end-to-end 
flow-control is some kind of congestion control with an end-to-end 
feedback loop. To avoid strange interactions between various levels of 
congestion-control, I think this variability should be kept really slow 
(obviously it should be done per circuit).

&gt;   
&gt;&gt; Lets concentrate now on 5-7.
&gt;&gt; 5, This is studied in Fig. 2, confronting TCP-in-TCP with normal TCP on
&gt;&gt; the same path (TCP-in-IP). With one stream, delays are almost the same.
&gt;&gt; TCP is good in adapting to the congestion and keeping its delay low.
&gt;&gt;     
&gt;
&gt; This introduces the recent discussion about using UDP for transport. See
&gt; e.g. http://archives.seul.org/or/talk/Oct-2008/msg00095.html
&gt;
&gt; One of the big reasons they concluded why Tor is slow is because it puts
&gt; both loud and quiet streams together into one TCP connection. When TCP's
&gt; back-off kicks in, all the streams get punished, not just the loud ones.
&gt;
&gt; Ultimately we'd like to resolve this whole TCP flow control thing by
&gt; switching to UDP transport between each relay, and then either have a
&gt; user-space TCP stack sitting at each relay to reconstruct the packets,
&gt; or have one sitting at each end of the circuit to reconstruct them.
&gt; Alas, there are still a big pile of open development problems there
&gt; -- as a first example, there appears to be no free-software stable
&gt; platform-independent secure user-space TCP stack out there.
&gt;
&gt;   
On the long run, I'm also more of a fan of a datagram based solution 
with only end-to-end congestion control. What we've been using in the 
tech report is
IPsec tunnels, and at that point kernel level TCP stack comes for free. 
With this solution, performance is almost equivalent to native IP 
tunneling on the same path.
Obviously IPsec and kernel TCP has all of its well known drawbacks, but 
that's off-topic here.
We had our reasons to use IPsec, but what's important from Tor's 
perspective, is that a UDP based transport would produce almost the same 
performance, if OR nodes are strong enough and delay factors 5-7 are 
handled well. (see delay factors at the end in my original mail)

Another thing that comes to my mind is that a better separation of 
signaling (directory lookup, circuit setup, etc.) and data path would be 
beneficial. This would ease things such as experimenting with DTLS or 
other transport methods on the overlay tunnel, and experimenting with 
different solutions end-to-end.
&gt;&gt; 6, I've noticed this limit (MIN_TLS_FLUSHLEN) in the code. Its size is
&gt;&gt; about 32 cells, doesn't seems to be an important delay component.
&gt;&gt;     
&gt;
&gt; Right. I added that in because in some cases we were reading in hundreds
&gt; of kilobytes without initiating any writes until all the reads were
&gt; done. I have absolutely no idea whether that was a good idea. It would
&gt; be great to be able to have some data about these things.
&gt;
&gt; Speaking of which, Tor's round-robin when we run low on our bandwidth
&gt; buckets has to matter here. We try to round-robin 16KB at a time, but
&gt; have smaller allocations when our token bucket is getting low. Again,
&gt; I just made up some numbers, and it would be great to get real data there.
&gt;
&gt;   
&gt;&gt; 7, The huge part of the delay is here: hundreds if not thousands of
&gt;&gt; cells waiting in a FIFO queue (the OR's output buffer towards another
&gt;&gt; OR) before getting to the TLS tunnel.
&gt;&gt;     
&gt;
&gt; So the next question is an implementation one. Right now the window sizes
&gt; are hard-coded at both ends. I've been meaning to extend the protocol
&gt; so sendme cells have a number in them, and so the initial window sizes
&gt; are specified in the 'create' and 'created' cells for circuits and the
&gt; 'begin' and 'connected' cells for streams. But we haven't really fleshed
&gt; out the details of those designs, or how they could be phased in and still
&gt; handle clients and relays that don't use (or know about) the numbers.
&gt;
&gt; So the big deployment question is: is it worth it to work on a design
&gt; for the above, and then either shrink the default window sizes or do
&gt; something smarter like variable window sizes, or should we just be
&gt; patient until a UDP-based solution is more within reach?
&gt;
&gt; One answer is that if you were interested in working on a design proposal
&gt; and patch, it would be much more likely to get implemented. :)
&gt;   
We are doing verifications on this. Our lab experiments (the ones in the 
tech report) show that there is a huge gain on the user side in delays, 
while throughput is untouched. Throughput is capped with a static window 
size, but I think the cap can be chosen better than what it is now. 
There should also be a big gain in the memory consumption of ORs, 
although we didn't measure it yet. Since the Tor network is kind of 
overloaded all the time, memory usage should decrease almost linearly 
with the window size.

Currently we are verifying one-side modification of the circuit, i.e. 
whether one side of the connection can reduce the widow size on its own, 
without explicitly notifying the other side.  From the  code it seems to 
me that this will work, and if so, phasing in a smaller window size in a 
new release should not be a problem.

&gt;   
&gt;&gt; One negative effect which could be considered, is the following: having
&gt;&gt; less cells in buffers, the "mixing" effect is less. I know that there is
&gt;&gt; no real mixing in Tor, what I mean is that even if cells are not
&gt;&gt; re-ordered, due to the introduced delays, finding correspondence between
&gt;&gt; an entering cell and its correspondent cell leaving later on is quite
&gt;&gt; hard. I don't think reducing this delay is a problem, but it should be
&gt;&gt; mentioned at least.
&gt;&gt;     
&gt;
&gt; This doesn't bother me either. I think we're quite vulnerable already
&gt; to an adversary trying to match up flows.
&gt;
&gt;   
&gt;&gt; In the report, we also analyze the effect of external TCP tunnels when
&gt;&gt; several streams are multiplexed over them. In this case, an TCP tunnel
&gt;&gt; becomes a real bottleneck.
&gt;&gt;     
&gt;
&gt; Indeed. Is this the same statement that I made above, from Joel's
&gt; thesis?
&gt;   
Well,  we've had different ways of analysing it but some the conclusions 
are similar, even if not the same :)
We did not try analysing the effect of mixing different (loud and quiet) 
kinds of traffic. What we say is that all streams suffer even if they 
are from the same kind.

&gt;   
&gt;&gt; Finally, we also discuss how the combination of 1) datagram based
&gt;&gt; operation, 2) allowing for cell/packet drops in overlay nodes, and 3)
&gt;&gt; relying on only one end-to-end congestion control loop increase
&gt;&gt; performance. We do this through an example of an IPsec based
&gt;&gt; architecture, but results partially apply to DTLS as well.
&gt;&gt;     
&gt;
&gt; Sounds great.
&gt;
&gt; Are you able to send this to the or-dev list too? I think it would be
&gt; more useful to have other people see the thread too.
&gt;
&gt; Thanks!
&gt; --Roger
&gt;   

Csaba Kiraly wrote:  
&gt;&gt; Dear Roger,
&gt;&gt;
&gt;&gt; As Giuseppe said, the tech report is work in progress, however I think
&gt;&gt; there are already some parts that might be interesting for you and for
&gt;&gt; others involved in Tor development.
&gt;&gt;
&gt;&gt; One things that could be of immediate use for Tor is the study of Tor's
&gt;&gt; flow-control mechanism, and its behavior with different window sizes. In
&gt;&gt; short, by reducing the window size from the current 1000 to e.g. 200 in
&gt;&gt; the Tor network, there would be a huge decrease in application level
&gt;&gt; round trip times. It would also mean much smaller buffers in OR nodes,
&gt;&gt; reducing their memory consumption significantly. At the same time,
&gt;&gt; throughput would remain the same. Figure 6 of the tech report shows
&gt;&gt; delay and throughput with some window sizes.
&gt;&gt;
&gt;&gt; I hope you don't mind if I give a more detailed Tor-specific explanation
&gt;&gt; of this aspect here below, since it was not (yet) discussed in the tech
&gt;&gt; report in enough detail.
&gt;&gt;
&gt;&gt; As you know, Tor breaks up the end-to-end TCP loop, and replaces it with
&gt;&gt; its own reliable delivery service. It implements reliable delivery by
&gt;&gt; using TCP on the overlay links, and by not dropping cells in OR nodes
&gt;&gt; (it can't drop cells in ORs, because there is no other end-to-end
&gt;&gt; reliability mechanism that would resend a cell).
&gt;&gt;
&gt;&gt; If you consider also that bottlenecks are typically inside the Tor
&gt;&gt; network (and not after the exit node) you get to the following 
&gt;&gt; phenomenon:
&gt;&gt; The source sends cells as fast as it can until its CIRCWINDOW  (or
&gt;&gt; STREAMWINDOW)permits. These cells all get buffered at the OR before the
&gt;&gt; bottleneck overlay link. When some (CIRCWINDOW_INCREMENT) data gets
&gt;&gt; through the bottleneck and arrives to the exit node, a SENDME cell is
&gt;&gt; sent back. The source pushes again, and as a result, the buffer before
&gt;&gt; the bottleneck link is always almost full. This introduces two problems:
&gt;&gt; large delays for end nodes and huge memory consumption for ORs.
&gt;&gt;
&gt;&gt; Large delay :
&gt;&gt; The delay introduced by the FIFO buffer in the OR before the bottleneck
&gt;&gt; can be estimated as:
&gt;&gt; cell_size * CIRCWINDOW / bottleneck_bandwidth
&gt;&gt;
&gt;&gt; With typical data: cell size=0.5 Kbytes; CIRCWINDOW=1000;
&gt;&gt; bottleneck_bandwidth= 50 Kbytes/sec;
&gt;&gt; you get a potential delay of 10 seconds. Fortunately, applications are
&gt;&gt; typically not that eager to push all that information inside, still, the
&gt;&gt; accumulated delay is huge.
&gt;&gt;
&gt;&gt; Large memory consumption at OR nodes:
&gt;&gt; an OR node should potentially buffer cell_size * CIRCWINDOW, i.e. 500
&gt;&gt; Kbytes for each circuit.
&gt;&gt;
&gt;&gt; With a smaller window, both the delay and memory consumption would be
&gt;&gt; smaller. Thus the important question is: why not reduce the window? One
&gt;&gt; would say throughput, but the important thing to note is that a smaller
&gt;&gt; (but not too small) window would not reduce throughput. This can be seen
&gt;&gt; on the right side of fig.4: all the Tor curves are the same, independent
&gt;&gt; of the window size (and the number of streams).
&gt;&gt;
&gt;&gt; The reason is simple: if there is a bottleneck on the path taken by the
&gt;&gt; circuit, the throughput depends on how the bandwidth of the TCP
&gt;&gt; connection of the bottlenecked OR link is shared among circuits.
&gt;&gt; Buffering more cells before this TCP connection does not make it more
&gt;&gt; effective.
&gt;&gt;
&gt;&gt; Delay and throughput can be analyzed in more detail.
&gt;&gt;
&gt;&gt; In Tor, delay comes from the following factors (I hope I've managed to
&gt;&gt; list them all):
&gt;&gt; 0, circuit setup delay
&gt;&gt; 1, delay outside the Tor network: TCP from application to SOCKS proxy
&gt;&gt; 2, delay outside the Tor network: TCP from exit node to destination node
&gt;&gt; 3, cell forming delay at the edge of the circuit (either at the OP or at
&gt;&gt; the exit OR)
&gt;&gt; 4, IP level delay on each overlay link (due to physical distance, IP
&gt;&gt; hops, etc.)
&gt;&gt; 5, delay introduced by TCP on each overlay link
&gt;&gt; 6, delay introduced by TLS record forming on each overlay link
&gt;&gt; 7, delay of FIFO cell buffers in ORs for each overlay link
&gt;&gt;
&gt;&gt; With CIRCWINDOW=1000, it seems that point 7. is responsible for large
&gt;&gt; part of the overall delay:
&gt;&gt; 0, is important at the beginning, but not during transmission
&gt;&gt; 1, is almost negligible
&gt;&gt; 2, is in the range of normal unprotected operation. There is not too
&gt;&gt; much to do to reduce it, except for selecting the exit node near the
&gt;&gt; destination, but this could compromise privacy.
&gt;&gt; 3, you already have a mechanism (based on port numbers) to mitigate this
&gt;&gt; 4, there is not too much to do with this, except changing the OR
&gt;&gt; selection strategy, and thus compromising privacy. There are numerous
&gt;&gt; proposals on that, as far as I remember.
&gt;&gt;
&gt;&gt; These factors add up for some hundreds of milliseconds, depending on the
&gt;&gt; choice of the OR nodes, and how they are connected to the Internet.
&gt;&gt;
&gt;&gt; Lets concentrate now on 5-7.
&gt;&gt; 5, This is studied in Fig. 2, confronting TCP-in-TCP with normal TCP on
&gt;&gt; the same path (TCP-in-IP). With one stream, delays are almost the same.
&gt;&gt; TCP is good in adapting to the congestion and keeping its delay low.
&gt;&gt;
&gt;&gt; 6, I've noticed this limit (MIN_TLS_FLUSHLEN) in the code. Its size is
&gt;&gt; about 32 cells, doesn't seems to be an important delay component.
&gt;&gt;
&gt;&gt; 7, The huge part of the delay is here: hundreds if not thousands of
&gt;&gt; cells waiting in a FIFO queue (the OR's output buffer towards another
&gt;&gt; OR) before getting to the TLS tunnel.
&gt;&gt;
&gt;&gt; This would suggest to reduce CIRCWINDOW as much as possible. To
&gt;&gt; understand what possible means, throughput should be analyzed:
&gt;&gt; Suppose for a minute that the Tor network is not overloaded, and there
&gt;&gt; is no overlay link bottleneck that would limit your throughput. In this
&gt;&gt; case 7) becomes negligible, while CIRCWINDOW limits your cells in
&gt;&gt; flight, and thus your throughput. Let D be the delays due to delay
&gt;&gt; factors 1..6
&gt;&gt;
&gt;&gt; Your throughput is limited to cell_size * CIRCWINDOW / D (without
&gt;&gt; considering the size of CIRCWINDOW_INCREMENT and delay of the SENDME
&gt;&gt; cell on the return path)
&gt;&gt; With typical data: cell size=0.5 kbytes ; CWND_SIZE=1000, D=1 sec
&gt;&gt; The throughput is limited to 500 kbytes/sec
&gt;&gt;
&gt;&gt; Reducing CIRCWINDOW to 200, this goes down to 100 kbytes/sec (if D=1
&gt;&gt; sec), which is still much above what is needed. Moreover, the Tor
&gt;&gt; network IS more congested than that (at least this was my impression),
&gt;&gt; so reducing CIRCWINDOW would have absolutely no negative effect on the
&gt;&gt; throughput.
&gt;&gt;
&gt;&gt; One negative effect which could be considered, is the following: having
&gt;&gt; less cells in buffers, the "mixing" effect is less. I know that there is
&gt;&gt; no real mixing in Tor, what I mean is that even if cells are not
&gt;&gt; re-ordered, due to the introduced delays, finding correspondence between
&gt;&gt; an entering cell and its correspondent cell leaving later on is quite
&gt;&gt; hard. I don't think reducing this delay is a problem, but it should be
&gt;&gt; mentioned at least.
&gt;&gt;
&gt;&gt; In the report, we also analyze the effect of external TCP tunnels when
&gt;&gt; several streams are multiplexed over them. In this case, an TCP tunnel
&gt;&gt; becomes a real bottleneck.
&gt;&gt;
&gt;&gt; Finally, we also discuss how the combination of 1) datagram based
&gt;&gt; operation, 2) allowing for cell/packet drops in overlay nodes, and 3)
&gt;&gt; relying on only one end-to-end congestion control loop increase
&gt;&gt; performance. We do this through an example of an IPsec based
&gt;&gt; architecture, but results partially apply to DTLS as well.
&gt;&gt;
&gt;&gt; I hope you don't mind for this long mail!
&gt;&gt; Best regards,
&gt;&gt; Csaba 

</body></email><email><emailId>20090301103709</emailId><senderName>Michael Gold</senderName><senderEmail>torlists@rilmarder.org</senderEmail><timestampReceived>2009-03-01 10:37:09-0400</timestampReceived><subject>Patch to authenticate by uid/gid on ControlSocket</subject><body>

[Attachment #2 (multipart/mixed)]


Hi all,

The attached patch allows tor (0.2.0.34) to automatically authenticate
the client of a Unix-domain control socket, by asking the kernel for the
uid and gid of the remote user.  There are still some unresolved issues,
but feedback would be appreciated.

Unauthenticated connections on Unix-domain sockets are now disabled,
even if no authentication is configured; however, tor will always accept
control connections if the client has the same uid and gid as the server
(regardless of authentication settings).  The new config file parameters
"ControlAllowUsers" and "ControlAllowGroups" can be used to allow other
users.  Each takes a comma-separated list of user/group names; for
groups, any member of a group (as determined by /etc/group) is accepted.
This is similar to the AllowUsers/AllowGroups settings in openssh.

The problem I've run into is that the listener socket permissions are
affected by the umask, and Linux won't let users without write
permission connect (apparently other systems ignore the permissions).
The obvious solution of fchmod(fd, 0777) has no effect; other possible
solutions are:
 - Use chmod; this would be vulnerable to a race condition if another
   user could delete and replace the socket before the chmod, but it
   should be okay if there's a warning in the documentation.
 - Change the umask temporarily; this would affect all threads, so it's
   only an option if filesystem operations are restricted to one thread.

Any suggestions?

So far this patch has only been tested on Linux, but it seems to work
fine after manually fixing the socket permissions.  Testing on other
Unix-like systems would be helpful, if anyone's interested (run
autoreconf before building it).

-- Michael

["tor-ctlsock-auth.diff" (text/x-diff)]

diff --git a/configure.in b/configure.in
index e733ad9..d7c0a25 100644
--- a/configure.in
+++ b/configure.in
@@ -18,7 +18,7 @@ fi
 
 # Not a no-op; we want to make sure that CPPFLAGS is set before we use
 # the += operator on it in src/or/Makefile.am
-CPPFLAGS="$CPPFLAGS -I../common"
+CPPFLAGS="$CPPFLAGS -I\${top_srcdir}/src/common"
 
 AC_ARG_ENABLE(debug,
  AS_HELP_STRING(--enable-debug, compile with debugging info),
@@ -183,7 +183,7 @@ dnl \
-------------------------------------------------------------------  dnl Check for \
functions before libevent, since libevent-1.2 apparently  dnl exports strlcpy without \
defining it in a header.  
-AC_CHECK_FUNCS(gettimeofday ftime socketpair uname inet_aton strptime getrlimit \
strlcat strlcpy strtoull ftello getaddrinfo localtime_r gmtime_r memmem strtok_r \
inet_pton inet_ntop) +AC_CHECK_FUNCS(gettimeofday ftime socketpair uname inet_aton \
strptime getrlimit strlcat strlcpy strtoull ftello getaddrinfo localtime_r gmtime_r \
memmem strtok_r inet_pton inet_ntop getpeereid)  
 using_custom_malloc=no
 if test x$enable_openbsd_malloc = xyes ; then
diff --git a/src/common/compat.c b/src/common/compat.c
index 681d43b..beaafb6 100644
--- a/src/common/compat.c
+++ b/src/common/compat.c
@@ -1141,6 +1141,22 @@ switch_id(const char *user)
 #endif
 }
 
+#ifdef NEED_GETPEEREID
+int
+tor_getpeereid(int sockfd, uid_t *euid, gid_t *egid)
+{
+  struct ucred cred;
+  socklen_t credlen = sizeof(cred);
+  if (getsockopt(sockfd, SOL_SOCKET, SO_PEERCRED, &amp;cred, &amp;credlen) &lt; 0)
+    return -1;
+
+  tor_assert(credlen == sizeof(cred));
+  *euid = cred.uid;
+  *egid = cred.gid;
+  return 0;
+}
+#endif
+
 #ifdef HAVE_PWD_H
 /** Allocate and return a string containing the home directory for the
  * user &lt;b&gt;username&lt;/b&gt;. Only works on posix-like systems. */
diff --git a/src/common/compat.h b/src/common/compat.h
index 2a8cba3..fac4773 100644
--- a/src/common/compat.h
+++ b/src/common/compat.h
@@ -420,6 +420,19 @@ int network_init(void);
 
 int tor_addr_lookup(const char *name, uint16_t family, tor_addr_t *addr_out);
 
+#ifdef HAVE_GETPEEREID
+#define HAVE_COMPAT_GETPEEREID
+#define tor_getpeereid getpeereid
+#elif defined(SO_PEERCRED)
+#define HAVE_COMPAT_GETPEEREID
+#define NEED_GETPEEREID
+int tor_getpeereid(int s, uid_t *euid, gid_t *egid);
+#endif
+
+#if defined(HAVE_COMPAT_GETPEEREID) &amp;&amp; defined(HAVE_PWD_H)
+#define AF_UNIX_UID_AUTH
+#endif
+
 /* For stupid historical reasons, windows sockets have an independent
  * set of errnos, and an independent way to get them.  Also, you can't
  * always believe WSAEWOULDBLOCK.  Use the macros below to compare
diff --git a/src/or/config.c b/src/or/config.c
index 4267cb1..a7a5159 100644
--- a/src/or/config.c
+++ b/src/or/config.c
@@ -168,6 +168,8 @@ static config_var_t _option_vars[] = {
   V(ControlListenAddress,        LINELIST, NULL),
   V(ControlPort,                 UINT,     "0"),
   V(ControlSocket,               LINELIST, NULL),
+  V(ControlAllowUsers,           CSV, NULL),
+  V(ControlAllowGroups,          CSV, NULL),
   V(CookieAuthentication,        BOOL,     "0"),
   V(CookieAuthFileGroupReadable, BOOL,     "0"),
   V(CookieAuthFile,              STRING,   NULL),
@@ -382,6 +384,16 @@ static config_var_description_t options_description[] = {
     "(localhost only) on this port, and allow those connections to control "
     "the Tor process using the Tor Control Protocol (described in"
     "control-spec.txt).", },
+  { "ControlSocket", "If set, Tor will accept connections on a Unix domain "
+    "socket with the given path, and allow those connections to control "
+    "the Tor process using the Tor Control Protocol (described in"
+    "control-spec.txt).  Unix only.", },
+  { "ControlAllowUsers", "If set, Tor will treat control socket connections "
+    "from any of the specified users as authenticated.  "
+    "This works on sockets defined with ControlSocket (not ControlPort).", },
+  { "ControlAllowGroups", "If set, Tor will treat control socket connections "
+    "from a user in any of the specified groups as authenticated.  "
+    "This works on sockets defined with ControlSocket (not ControlPort).", },
   { "CookieAuthentication", "If this option is set to 1, don't allow any "
     "connections to the control port except when the connecting process "
     "can read a file that Tor creates in its data directory." },
diff --git a/src/or/connection.c b/src/or/connection.c
index 697cbcf..90aa39c 100644
--- a/src/or/connection.c
+++ b/src/or/connection.c
@@ -835,6 +835,7 @@ connection_create_listener(struct sockaddr *listensockaddr, int \
type,  strerror(errno));
       goto err;
     }
+
     s = tor_open_socket(AF_UNIX, SOCK_STREAM, 0);
     if (s &lt; 0) {
       log_warn(LD_NET,"Socket creation failed: %s.", strerror(errno));
@@ -853,6 +854,14 @@ connection_create_listener(struct sockaddr *listensockaddr, int \
type,  tor_close_socket(s);
       goto err;
     }
+#ifdef AF_UNIX_UID_AUTH
+    /*FIXME: this has no effect on Linux */
+    if (fchmod(s, 0777) &lt; 0) {
+      log_warn(LD_NET,"Could not set permissions on %s: %s.", address,
+               tor_socket_strerror(tor_socket_errno(s)));
+      goto err;
+    }
+#endif
 #endif /* HAVE_SYS_UN_H */
   } else {
       log_err(LD_BUG,"Got unexpected address family %d.",
@@ -1085,8 +1094,7 @@ connection_init_accepted_conn(connection_t *conn, uint8_t \
listener_type)  conn-&gt;state = DIR_CONN_STATE_SERVER_COMMAND_WAIT;
       break;
     case CONN_TYPE_CONTROL:
-      conn-&gt;state = CONTROL_CONN_STATE_NEEDAUTH;
-      break;
+      return connection_control_init_accepted_conn(TO_CONTROL_CONN(conn));
   }
   return 0;
 }
diff --git a/src/or/control.c b/src/or/control.c
index 8aa5c6c..1ecebc8 100644
--- a/src/or/control.c
+++ b/src/or/control.c
@@ -13,6 +13,7 @@ const char control_c_id[] =
 
 #define CONTROL_PRIVATE
 
+#define _BSD_SOURCE  /* for getgrouplist, getpwnam_r, etc. */
 #include "or.h"
 
 /** Yield true iff &lt;b&gt;s&lt;/b&gt; is the state of a control_connection_t that has
@@ -1004,6 +1005,12 @@ handle_control_authenticate(control_connection_t *conn, \
uint32_t len,  int bad_cookie=0, bad_password=0;
   smartlist_t *sl = NULL;
 
+  if (conn-&gt;_base.state == CONTROL_CONN_STATE_OPEN) {
+    /* the connection is already authenticated, so don't check again */
+    send_control_done(conn);
+    return 0;
+  }
+
   if (TOR_ISXDIGIT(body[0])) {
     cp = body;
     while (TOR_ISXDIGIT(*cp))
@@ -1034,13 +1041,6 @@ handle_control_authenticate(control_connection_t *conn, \
uint32_t len,  used_quoted_string = 1;
   }
 
-  if (!options-&gt;CookieAuthentication &amp;&amp; !options-&gt;HashedControlPassword &amp;&amp;
-      !options-&gt;HashedControlSessionPassword) {
-    /* if Tor doesn't demand any stronger authentication, then
-     * the controller can get in with anything. */
-    goto ok;
-  }
-
   if (options-&gt;CookieAuthentication) {
     int also_password = options-&gt;HashedControlPassword != NULL ||
       options-&gt;HashedControlSessionPassword != NULL;
@@ -2642,6 +2642,179 @@ connection_control_reached_eof(control_connection_t *conn)
   return 0;
 }
 
+/** Called to initialise a new control socket. */
+int
+connection_control_init_accepted_conn(control_connection_t *conn)
+{
+  int auth = 0;
+  or_options_t *options = get_options();
+  conn-&gt;_base.state = CONTROL_CONN_STATE_NEEDAUTH;
+
+  if (!options-&gt;CookieAuthentication &amp;&amp;
+      !options-&gt;HashedControlPassword &amp;&amp;
+      !options-&gt;HashedControlSessionPassword &amp;&amp;
+#ifdef AF_UNIX_UID_AUTH
+      conn-&gt;_base.socket_family != AF_UNIX &amp;&amp;
+#endif
+      !options-&gt;ControlAllowUsers &amp;&amp;
+      !options-&gt;ControlAllowGroups) {
+    /* if Tor doesn't demand any stronger authentication, then
+     * the controller can get in with anything. */
+    auth = 1;
+  }
+
+#ifdef AF_UNIX_UID_AUTH
+  if (!auth &amp;&amp; conn-&gt;_base.socket_family == AF_UNIX) {
+    int sock = conn-&gt;_base.s;
+    uid_t sockuid;
+    gid_t sockgid;
+    struct passwd _pwd;
+    char *pwdbuf;
+    size_t pwdbufsize;
+
+    if (tor_getpeereid(sock, &amp;sockuid, &amp;sockgid) &lt; 0) {
+      log_warn(LD_CONTROL, "Couldn't authenticate Unix-domain control "
+                           "socket: %s", strerror(errno));
+      goto skip_unixauth;
+    }
+
+    if (sockuid == getuid()) {
+      /* Always let a user access their own server. */
+      log_info(LD_CONTROL, "Authenticated control connection (%d) "
+                           "via own UID (%d)",
+               sock, sockuid);
+      auth = 1;
+      goto skip_unixauth;
+    }
+
+    pwdbufsize = sysconf(_SC_GETPW_R_SIZE_MAX);
+    if (pwdbufsize == -1)
+      pwdbufsize = 16384;
+    pwdbuf = tor_malloc(pwdbufsize);
+
+    if (options-&gt;ControlAllowUsers) {
+      SMARTLIST_FOREACH(options-&gt;ControlAllowUsers, const char *, name,
+      {
+        struct passwd *pwd;
+        errno = getpwnam_r(name, &amp;_pwd, pwdbuf, pwdbufsize, &amp;pwd);
+        if (!pwd) {
+          if (errno)
+            log_warn(LD_CONTROL, "Couldn't get info for username \"%s\" "
+                                 "in ControlAllowUsers: %s",
+                     name, strerror(errno));
+          else
+            log_warn(LD_CONTROL, "Invalid username \"%s\" in "
+                                 "ControlAllowUsers", name);
+        } else {
+          if (sockuid == pwd-&gt;pw_uid) {
+            log_info(LD_CONTROL, "Authenticated control connection (%d) via "
+                                 "ControlAllowUsers (username \"%s\")",
+                     sock, name);
+            auth = 1;
+            break;
+          }
+        }
+      });
+    }
+
+    if (!auth &amp;&amp; options-&gt;ControlAllowGroups) {
+      struct passwd *sockpwd;
+      gid_t *sockgroups = NULL;
+      const int maxgroups = 32;
+      int ngroups = 0;
+
+      struct group _grp;
+      char *grpbuf;
+      size_t grpbufsize;
+
+      /* Find the user's groups. */
+
+      sockgroups = tor_malloc(sizeof(gid_t) * maxgroups);
+
+      errno = getpwuid_r(sockuid, &amp;_pwd, pwdbuf, pwdbufsize, &amp;sockpwd);
+      if (sockpwd) {
+        int rv, oldn = ngroups;
+
+        ngroups = maxgroups;
+        rv = getgrouplist(sockpwd-&gt;pw_name, sockpwd-&gt;pw_gid,
+                          sockgroups, &amp;ngroups);
+        if (rv &lt; 0 &amp;&amp; ngroups &gt; oldn) {
+          /* retry with a bigger buffer */
+          sockgroups = tor_realloc(sockgroups, sizeof(gid_t) * ngroups);
+          rv = getgrouplist(sockpwd-&gt;pw_name, sockpwd-&gt;pw_gid,
+                            sockgroups, &amp;ngroups);
+        }
+
+        if (rv &lt; 0) {
+          /* the getgrouplist man page doesn't say whether it sets errno */
+          log_warn(LD_CONTROL, "Couldn't get group list for connecting user "
+                               "\"%s\" to check ControlAllowGroups",
+                   sockpwd-&gt;pw_name);
+          ngroups = 0;
+        }
+      } else {  /* getpwuid failed */
+        if (errno)
+          log_warn(LD_CONTROL, "Couldn't get user info for connecting UID %d "
+                               "to check ControlAllowGroups: %s",
+                   sockuid, strerror(errno));
+        /* else, it's a UID with no username */
+
+        /* we can still check the gid returned by getpeereid */
+        ngroups = 0;
+      }
+
+      /* Check whether the user is in an acceptable group. */
+
+      grpbufsize = sysconf(_SC_GETGR_R_SIZE_MAX);
+      if (grpbufsize == -1)
+        grpbufsize = 16384;
+      grpbuf = tor_malloc(grpbufsize);
+
+      SMARTLIST_FOREACH(options-&gt;ControlAllowGroups, const char *, name,
+      {
+        struct group *grp;
+        errno = getgrnam_r(name, &amp;_grp, grpbuf, grpbufsize, &amp;grp);
+        if (!grp) {
+          if (errno)
+            log_warn(LD_CONTROL, "Couldn't get info for group \"%s\" in "
+                                 "ControlAllowGroups: %s",
+                     name, strerror(errno));
+          else
+            log_warn(LD_CONTROL, "Invalid group name \"%s\" in "
+                                 "ControlAllowGroups", name);
+        } else {
+          int i;
+          auth = (sockgid == grp-&gt;gr_gid ||
+                  (sockpwd &amp;&amp; sockpwd-&gt;pw_gid == grp-&gt;gr_gid));
+          for (i = 0; i &lt; ngroups &amp;&amp; !auth; ++i) {
+            if (sockgroups[i] == grp-&gt;gr_gid) auth = 1;
+          }
+
+          if (auth) {
+            /* log the numeric UID since pwd may be null */
+            log_info(LD_CONTROL, "Authenticated control connection (%d) via "
+                                 "ControlAllowGroups (group \"%s\", UID %d)",
+                     sock, grp-&gt;gr_name, sockuid);
+            break;
+          }
+        }
+      });
+
+      tor_free(sockgroups);
+      tor_free(grpbuf);
+    }
+
+    tor_free(pwdbuf);
+skip_unixauth: ;
+  }
+#endif
+
+  if (auth)
+    conn-&gt;_base.state = CONTROL_CONN_STATE_OPEN;
+
+  return 0;
+}
+
 /** Return true iff &lt;b&gt;cmd&lt;/b&gt; is allowable (or at least forgivable) at this
  * stage of the protocol. */
 static int
diff --git a/src/or/or.h b/src/or/or.h
index 9e926b4..1188fb1 100644
--- a/src/or/or.h
+++ b/src/or/or.h
@@ -64,6 +64,12 @@
 #ifdef HAVE_TIME_H
 #include &lt;time.h&gt;
 #endif
+#ifdef HAVE_PWD_H
+#include &lt;pwd.h&gt;
+#endif
+#ifdef HAVE_GRP_H
+#include &lt;grp.h&gt;
+#endif
 
 #ifdef MS_WINDOWS
 #include &lt;io.h&gt;
@@ -2060,6 +2066,10 @@ typedef struct {
   int ControlPort; /**&lt; Port to listen on for control connections. */
   config_line_t *ControlSocket; /**&lt; List of Unix Domain Sockets to listen on
                                  * for control connections. */
+  smartlist_t *ControlAllowUsers; /**&lt; List of usernames that should have
+                                   * access to the control socket. */
+  smartlist_t *ControlAllowGroups; /**&lt; List of group names that should have
+                                    * access to the control socket. */
   int DirPort; /**&lt; Port to listen on for directory connections. */
   int DNSPort; /**&lt; Port to listen on for DNS requests. */
   int AssumeReachable; /**&lt; Whether to publish our descriptor regardless. */
@@ -2956,6 +2966,7 @@ void control_adjust_event_log_severity(void);
 
 int connection_control_finished_flushing(control_connection_t *conn);
 int connection_control_reached_eof(control_connection_t *conn);
+int connection_control_init_accepted_conn(control_connection_t *conn);
 int connection_control_process_inbuf(control_connection_t *conn);
 
 #define EVENT_AUTHDIR_NEWDESCS 0x000D


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090401104217</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-04-01 10:42:17-0400</timestampReceived><subject>Another data set worth graphing: v3 status votes</subject><body>

Hi Karsten,

I've been thinking about
https://bugs.torproject.org/flyspray/index.php?do=details&amp;id=696

The way we noticed it was by realizing that some authorities were voting
for Stable very differently than the other authorities.

While you're working on metrics, it might be useful to take the
v3-status-votes file from gabelmoo's datadir (which contains all
the v3 networkstatus votes for the last consensus), and make a
graph for each status flag of which authority voted how for each
relay. I'm imagining relays on the x axis (the votes already sort
them by identity key I think), and booleans on the y axis, and six
colors for the six authorities. The votes ought to mostly overlap --
any significant differences might indicate further bugs. For example,
if some authorities have stopped voting correctly for Stable, that will
influence their Guard flag assignment too.

Doing the parsing and graphing in a mostly automated way will let us
easily rerun the test down the road to make sure that anomalies haven't
appeared.

A more interesting graph might be the average of votes from the authority
for that relay over some time period. Do we save votes currently, or
just consensuses?

Not super high priority, unless it turns out to uncover a big bug, in
which case we'll want to go back in time and mark it high priority. ;)

Thanks,
--Roger

</body></email><email><emailId>20090503125328</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-05-03 12:53:28-0400</timestampReceived><subject>Dropping version 0 hidden service descriptors</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Nick,

(Is or-dev the right place to ask you to pull from my branch? Or is that
going to create too much noise?)


I worked on dropping the version 0 hidden service descriptor format.
This is my branch that does the following two things:

- - Hidden services stop publishing version 0 descriptors.
- - Clients stop requesting version 0 descriptors.

The result is that both services and clients produce fewer traffic when
advertising/connecting to services.

The support for storing version 0 descriptors on the authorities is
still in. Otherwise, 0.1.x hidden services and clients would stop
working as soon as moria1+2 and tor26 have upgraded. We can still change
this in 0.2.3.x. Or let me know if you want to drop it now. But in
contrast to the changes above, leaving this in doesn't hurt traffic-wise.

I also updated rend-spec.txt a bit. I found that I'll have to work on
the spec some more to reflect the proposal 121 changes. That's on my list.

Please find the branch dropv0hidserv in

git://git.torproject.org/~karsten/git/tor/

Best,
- --Karsten

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkn9k8QACgkQ0M+WPffBEmWL1QCgqaAtgdb4nqsozPzph6pFfxgw
JpMAn3+F1fNay7DohXbbk1Xhlms82Ca2
=fc3v
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090609050341</emailId><senderName>Marcus Griep</senderName><senderEmail>tormaster@xpdm.us</senderEmail><timestampReceived>2009-06-09 05:03:41-0400</timestampReceived><subject>[PATCH] Add port support to TorBulkExitList.py</subject><body>

[Attachment #2 (multipart/mixed)]


Currently, the Tor Bulk Exit List python CGI script only supports
creation of exit lists for port 80. For some services, such as IRC,
port 80 may not be sufficient. Thus, I've done the light lifting and
extended the prior handiwork of ioerror to support creating Bulk
Exit Lists for ports other than port 80. The patch submitted doesn't
expose this functionality outright, but adding a "port" query string
parameter will give access to this feature.

In doing so, I noticed two possible bugs whose fixes are included in
this patch and described below:

@@ -52,7 +53,7 @@
In this section of code, we've determined that the cashed file for
the (IP,port) tuple has not expired, so we intend to return the
cached file. Instead, the `parsedExitList` is being read, which
includes every node that has any exit port open. This means that the
first result would be correct, but, until the cache expires,
subsequent requests will return the full list of exit nodes.

@@ -170,10 +171,10 @@
In this section, we are figuring out what the DNSEL result means. If
an exit is allowed for the given (exit,port,IP) tuple, then
127.0.0.2 is returned as an address result. For the question of "is
this an allowed exit?" the deleted logic returns "no" if any DNS
answer entry does not match 127.0.0.2. However, the predicate here
should be "exists" rather than "all". The substitute logic returns
yes if any DNS answer entry matches 127.0.0.2.

Patch attached, comments welcome.

-- 
Marcus Griep
GPG Key ID: 0x070E3F2D
������
https://torproj.xpdm.us
������������ ����.���� �, 3 �

["TorBulkExitList.py.patch" (text/plain)]

Index: TorBulkExitList.py
===================================================================
--- TorBulkExitList.py  (revision 19666)
+++ TorBulkExitList.py  (working copy)
@@ -8,9 +8,10 @@
 from mod_python import util

 DNS.ParseResolvConf()
-def bulkCheck(RemoteServerIP):
+def bulkCheck(RemoteServerIP, RemotePort):
     parsedExitList = "/tmp/TorBulkCheck/parsed-exit-list"
-    cacheFile = parsedExitList + "-" + RemoteServerIP + ".cache"
+    cacheFile = parsedExitList + "-" + RemoteServerIP +\
+        "_" + RemotePort + ".cache"
     confirmedExits = []

     # Do we have a fresh exit cache?
@@ -34,7 +35,7 @@
         # the list
         for possibleExit in possibleExits:
             try:
-                if (isUsingTor(possibleExit, RemoteServerIP) == 0 ):
+                if (isUsingTor(possibleExit, RemoteServerIP, RemotePort) == 0 ):
                     confirmedExits.append(possibleExit)
             except:
                 return None
@@ -52,7 +53,7 @@

     else:
         # Lets return the cache
-        cachedExits = open(parsedExitList, 'r')
+        cachedExits = open(cacheFile, 'r')
         cachedExitList = cachedExits.readlines()
         return cachedExitList

@@ -170,10 +171,10 @@
             # We're getting unexpected data - fail closed
             return 2
         for a in answer.answers:
-            if a['data'] != "127.0.0.2":
-                return 2
+            if a['data'] == "127.0.0.2":
+                return 0
         # If we're here, we've had a positive exit answer
-        return 0
+        return 2

 def parseAddress(req):
     # Get the ip from apache
@@ -199,16 +200,21 @@
     req.content_type = 'text/plain; charset=utf-8'

     RemoteServerIP = parseAddress(req)
-    RemotePort = "80"
+    RemotePort = util.FieldStorage(req).getfirst("port", "80")

     if RemoteServerIP is not None:

         updateCache()
-        TestedExits = bulkCheck(RemoteServerIP)
+        TestedExits = bulkCheck(RemoteServerIP, RemotePort)
         req.write("# This is a list of all Tor exit nodes that can contact " + RemoteServerIP +
         " on Port " + RemotePort + " #\n")
+
+        querystring = "ip=%s" % RemoteServerIP
+       if RemotePort != "80":
+               querystring += "&amp;port=%s" % RemotePort
+
         req.write("# You can update this list by visiting " + \
-        "https://check.torproject.org/cgi-bin/TorBulkExitList.py?ip=%s #\n" % RemoteServerIP)
+        "https://check.torproject.org/cgi-bin/TorBulkExitList.py?%s #\n" % querystring)

         dateOfAccess = time.asctime(time.gmtime())
         req.write("# This file was generated on %s UTC #\n" % dateOfAccess)

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090503184941</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-03 18:49:41-0400</timestampReceived><subject>Re: Dropping version 0 hidden service descriptors</subject><body>

On Sun, May 03, 2009 at 02:53:28PM +0200, Karsten Loesing wrote:
&gt; -----BEGIN PGP SIGNED MESSAGE-----
&gt; Hash: SHA1
&gt; 
&gt; Hi Nick,
&gt; 
&gt; (Is or-dev the right place to ask you to pull from my branch? Or is that
&gt; going to create too much noise?)

Let's give it a try and see how it works out. 
 
&gt; I worked on dropping the version 0 hidden service descriptor format.
&gt; This is my branch that does the following two things:
&gt; 
&gt; - - Hidden services stop publishing version 0 descriptors.
&gt; - - Clients stop requesting version 0 descriptors.
&gt; 
&gt; The result is that both services and clients produce fewer traffic when
&gt; advertising/connecting to services.
&gt; 
&gt; The support for storing version 0 descriptors on the authorities is
&gt; still in. Otherwise, 0.1.x hidden services and clients would stop
&gt; working as soon as moria1+2 and tor26 have upgraded. We can still change
&gt; this in 0.2.3.x. Or let me know if you want to drop it now. But in
&gt; contrast to the changes above, leaving this in doesn't hurt traffic-wise.

Seems plausible.  So, the effect is that 0.1.2 clients won't be able
to use hidden services from 0.2.2 hidden servers, and vice versa?  It
doesn't sound disastrous.  Nobody should be using 0.1.2 anyway.

Two questions: 
  1) Do we have some idea of what fraction of hidden services are
     still v0 only?

  2) Did you test that this works with 0.2.0 clients and hidden servers?

yrs,
-- 
Nick
</body></email><email><emailId>20090301174703</emailId><senderName>John Brooks</senderName><senderEmail>special@dereferenced.net</senderEmail><timestampReceived>2009-03-01 17:47:03-0400</timestampReceived><subject>Re: Patch to authenticate by uid/gid on ControlSocket</subject><body>

Great idea! This should simplify things quite a lot when using control
connections.

I'm surprised fchmod doesn't work, but I don't think using chmod() would be
a problem here. Another user very likely wouldn't have the permissions to
replace the socket file, and if they did, the chmod() call would then fail
as the tor user would not own the new file. If they were already running as
the tor user, they could do all sorts of other things and make it really a
moot point anyway. I don't see a way that another user could bother tor
using that race condition.

 - John Brooks

On Sun, Mar 1, 2009 at 3:37 AM, Michael Gold &lt;torlists@rilmarder.org&gt; wrote:

&gt; Hi all,
&gt;
&gt; The attached patch allows tor (0.2.0.34) to automatically authenticate
&gt; the client of a Unix-domain control socket, by asking the kernel for the
&gt; uid and gid of the remote user.  There are still some unresolved issues,
&gt; but feedback would be appreciated.
&gt;
&gt; Unauthenticated connections on Unix-domain sockets are now disabled,
&gt; even if no authentication is configured; however, tor will always accept
&gt; control connections if the client has the same uid and gid as the server
&gt; (regardless of authentication settings).  The new config file parameters
&gt; "ControlAllowUsers" and "ControlAllowGroups" can be used to allow other
&gt; users.  Each takes a comma-separated list of user/group names; for
&gt; groups, any member of a group (as determined by /etc/group) is accepted.
&gt; This is similar to the AllowUsers/AllowGroups settings in openssh.
&gt;
&gt; The problem I've run into is that the listener socket permissions are
&gt; affected by the umask, and Linux won't let users without write
&gt; permission connect (apparently other systems ignore the permissions).
&gt; The obvious solution of fchmod(fd, 0777) has no effect; other possible
&gt; solutions are:
&gt;  - Use chmod; this would be vulnerable to a race condition if another
&gt;   user could delete and replace the socket before the chmod, but it
&gt;   should be okay if there's a warning in the documentation.
&gt;  - Change the umask temporarily; this would affect all threads, so it's
&gt;   only an option if filesystem operations are restricted to one thread.
&gt;
&gt; Any suggestions?
&gt;
&gt; So far this patch has only been tested on Linux, but it seems to work
&gt; fine after manually fixing the socket permissions.  Testing on other
&gt; Unix-like systems would be helpful, if anyone's interested (run
&gt; autoreconf before building it).
&gt;
&gt; -- Michael
&gt;
&gt; -----BEGIN PGP SIGNATURE-----
&gt; Version: GnuPG v2.0.9 (GNU/Linux)
&gt;
&gt; iEYEARECAAYFAkmqZVQACgkQ+RZl+46r4TdNzgCfdu6TvbQyrNfMWeijKJRpUXjn
&gt; 1bsAnjPj89471DOj3ho1XF2Fui8YZXP1
&gt; =0EF0
&gt; -----END PGP SIGNATURE-----
&gt;
&gt;

[Attachment #3 (text/html)]

&lt;div&gt;Great idea! This should simplify things quite a lot when using control \
connections.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'm surprised fchmod doesn't work, but \
I don't think using chmod() would be a problem here. Another user very likely \
wouldn't have the permissions to replace the socket file, and if they did, the \
chmod() call would then fail as the tor user would not own the new file. If they were \
already running as the tor user, they could do all sorts of other things and make it \
really a moot point anyway. I don't see a way that another user could bother tor \
using that race condition.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;  - John Brooks&lt;br&gt;
&lt;br&gt;&lt;div class="gmail_quote"&gt;On Sun, Mar 1, 2009 at 3:37 AM, Michael Gold &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:torlists@rilmarder.org"&gt;torlists@rilmarder.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; Hi all,&lt;br&gt;
&lt;br&gt;
The attached patch allows tor (0.2.0.34) to automatically authenticate&lt;br&gt;
the client of a Unix-domain control socket, by asking the kernel for the&lt;br&gt;
uid and gid of the remote user.  There are still some unresolved issues,&lt;br&gt;
but feedback would be appreciated.&lt;br&gt;
&lt;br&gt;
Unauthenticated connections on Unix-domain sockets are now disabled,&lt;br&gt;
even if no authentication is configured; however, tor will always accept&lt;br&gt;
control connections if the client has the same uid and gid as the server&lt;br&gt;
(regardless of authentication settings).  The new config file parameters&lt;br&gt;
"ControlAllowUsers" and "ControlAllowGroups" can be used to allow \
other&lt;br&gt; users.  Each takes a comma-separated list of user/group names; for&lt;br&gt;
groups, any member of a group (as determined by /etc/group) is accepted.&lt;br&gt;
This is similar to the AllowUsers/AllowGroups settings in openssh.&lt;br&gt;
&lt;br&gt;
The problem I've run into is that the listener socket permissions are&lt;br&gt;
affected by the umask, and Linux won't let users without write&lt;br&gt;
permission connect (apparently other systems ignore the permissions).&lt;br&gt;
The obvious solution of fchmod(fd, 0777) has no effect; other possible&lt;br&gt;
solutions are:&lt;br&gt;
 - Use chmod; this would be vulnerable to a race condition if another&lt;br&gt;
   user could delete and replace the socket before the chmod, but it&lt;br&gt;
   should be okay if there's a warning in the documentation.&lt;br&gt;
 - Change the umask temporarily; this would affect all threads, so it's&lt;br&gt;
   only an option if filesystem operations are restricted to one thread.&lt;br&gt;
&lt;br&gt;
Any suggestions?&lt;br&gt;
&lt;br&gt;
So far this patch has only been tested on Linux, but it seems to work&lt;br&gt;
fine after manually fixing the socket permissions.  Testing on other&lt;br&gt;
Unix-like systems would be helpful, if anyone's interested (run&lt;br&gt;
autoreconf before building it).&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;
-- Michael&lt;br&gt;
&lt;/font&gt;&lt;br&gt;-----BEGIN PGP SIGNATURE-----&lt;br&gt;
Version: GnuPG v2.0.9 (GNU/Linux)&lt;br&gt;
&lt;br&gt;
iEYEARECAAYFAkmqZVQACgkQ+RZl+46r4TdNzgCfdu6TvbQyrNfMWeijKJRpUXjn&lt;br&gt;
1bsAnjPj89471DOj3ho1XF2Fui8YZXP1&lt;br&gt;
=0EF0&lt;br&gt;
-----END PGP SIGNATURE-----&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20090811183350</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2009-08-11 18:33:50-0400</timestampReceived><subject>Re: [or-cvs] [tor/master] Disable .exit notation unless</subject><body>


nickm@seul.org (Nick Mathewson) wrote:

&gt; Author: Roger Dingledine &lt;arma@torproject.org&gt;
&gt; Date: Fri, 7 Aug 2009 19:26:41 -0400
&gt; Subject: Disable .exit notation unless AllowDotExit is 1.
&gt; Commit: 3e4379c2e73bf458cf60c63df44a8d0ec761568c
&gt; 
&gt; ---
&gt;  doc/tor.1.in             |    7 +++++++
&gt;  src/or/config.c          |    1 +
&gt;  src/or/connection_edge.c |   18 ++++++++++++------
&gt;  src/or/or.h              |    9 ++++++++-
&gt;  src/or/test.c            |    8 ++++----
&gt;  5 files changed, 32 insertions(+), 11 deletions(-)
&gt; 
&gt; diff --git a/doc/tor.1.in b/doc/tor.1.in
&gt; index b6e2231..fa383cc 100644
&gt; --- a/doc/tor.1.in
&gt; +++ b/doc/tor.1.in
&gt; @@ -690,6 +690,13 @@ resolved.  This helps trap accidental attempts to resolve URLs and so on.
&gt;  (Default: 0)
&gt;  .LP
&gt;  .TP
&gt; +\fBAllowDotOnion \fR\fB0\fR|\fB1\fR\fP
&gt; +If enabled, we convert "www.google.com.foo.exit" addresses on the
&gt; +SocksPort/TransPort/NatdPort into "www.google.com" addresses that exit
&gt; +from the node "foo". Disabled by default since attacking websites and
&gt; +exit relays can use it to manipulate your path selection. (Default: 0)

Passing the exit notation through the TransPort or the NatdPort will
be challenging given that Tor only gets the destination IP address.

Fabian

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090812034649</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-08-12 03:46:49-0400</timestampReceived><subject>Re: [or-cvs] [tor/master] Disable .exit notation unless AllowDotExit</subject><body>

On Tue, Aug 11, 2009 at 11:33 AM, Fabian
Keil&lt;freebsd-listen@fabiankeil.de&gt; wrote:
&gt; ...
&gt; Passing the exit notation through the TransPort or the NatdPort will
&gt; be challenging given that Tor only gets the destination IP address.

the TransPort is intended to be used with DNSPort, thus .exit notation
will auto map to a private address like .onions do and facilitate the
same path manipulation.

setting AutomapHostsSuffixes config option with .onion only can avoid
this for transparent Tor users with older versions. (but SOCKS still
an issue).

best regards,
</body></email><email><emailId>200903011747030</emailId><senderName>John Brooks</senderName><senderEmail>special@dereferenced.net</senderEmail><timestampReceived>2009-03-01 17:47:03-0400</timestampReceived><subject>Re: Patch to authenticate by uid/gid on ControlSocket</subject><body>

Great idea! This should simplify things quite a lot when using control
connections.

I'm surprised fchmod doesn't work, but I don't think using chmod() would be
a problem here. Another user very likely wouldn't have the permissions to
replace the socket file, and if they did, the chmod() call would then fail
as the tor user would not own the new file. If they were already running as
the tor user, they could do all sorts of other things and make it really a
moot point anyway. I don't see a way that another user could bother tor
using that race condition.

 - John Brooks

On Sun, Mar 1, 2009 at 3:37 AM, Michael Gold &lt;torlists@rilmarder.org&gt; wrote:

&gt; Hi all,
&gt;
&gt; The attached patch allows tor (0.2.0.34) to automatically authenticate
&gt; the client of a Unix-domain control socket, by asking the kernel for the
&gt; uid and gid of the remote user.  There are still some unresolved issues,
&gt; but feedback would be appreciated.
&gt;
&gt; Unauthenticated connections on Unix-domain sockets are now disabled,
&gt; even if no authentication is configured; however, tor will always accept
&gt; control connections if the client has the same uid and gid as the server
&gt; (regardless of authentication settings).  The new config file parameters
&gt; "ControlAllowUsers" and "ControlAllowGroups" can be used to allow other
&gt; users.  Each takes a comma-separated list of user/group names; for
&gt; groups, any member of a group (as determined by /etc/group) is accepted.
&gt; This is similar to the AllowUsers/AllowGroups settings in openssh.
&gt;
&gt; The problem I've run into is that the listener socket permissions are
&gt; affected by the umask, and Linux won't let users without write
&gt; permission connect (apparently other systems ignore the permissions).
&gt; The obvious solution of fchmod(fd, 0777) has no effect; other possible
&gt; solutions are:
&gt;  - Use chmod; this would be vulnerable to a race condition if another
&gt;   user could delete and replace the socket before the chmod, but it
&gt;   should be okay if there's a warning in the documentation.
&gt;  - Change the umask temporarily; this would affect all threads, so it's
&gt;   only an option if filesystem operations are restricted to one thread.
&gt;
&gt; Any suggestions?
&gt;
&gt; So far this patch has only been tested on Linux, but it seems to work
&gt; fine after manually fixing the socket permissions.  Testing on other
&gt; Unix-like systems would be helpful, if anyone's interested (run
&gt; autoreconf before building it).
&gt;
&gt; -- Michael
&gt;
&gt; -----BEGIN PGP SIGNATURE-----
&gt; Version: GnuPG v2.0.9 (GNU/Linux)
&gt;
&gt; iEYEARECAAYFAkmqZVQACgkQ+RZl+46r4TdNzgCfdu6TvbQyrNfMWeijKJRpUXjn
&gt; 1bsAnjPj89471DOj3ho1XF2Fui8YZXP1
&gt; =0EF0
&gt; -----END PGP SIGNATURE-----
&gt;
&gt;

[Attachment #3 (text/html)]

&lt;div&gt;Great idea! This should simplify things quite a lot when using control \
connections.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I'm surprised fchmod doesn't work, but \
I don't think using chmod() would be a problem here. Another user very likely \
wouldn't have the permissions to replace the socket file, and if they did, the \
chmod() call would then fail as the tor user would not own the new file. If they were \
already running as the tor user, they could do all sorts of other things and make it \
really a moot point anyway. I don't see a way that another user could bother tor \
using that race condition.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;  - John Brooks&lt;br&gt;
&lt;br&gt;&lt;div class="gmail_quote"&gt;On Sun, Mar 1, 2009 at 3:37 AM, Michael Gold &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:torlists@rilmarder.org"&gt;torlists@rilmarder.org&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 .8ex;border-left:1px \
#ccc solid;padding-left:1ex;"&gt; Hi all,&lt;br&gt;
&lt;br&gt;
The attached patch allows tor (0.2.0.34) to automatically authenticate&lt;br&gt;
the client of a Unix-domain control socket, by asking the kernel for the&lt;br&gt;
uid and gid of the remote user.  There are still some unresolved issues,&lt;br&gt;
but feedback would be appreciated.&lt;br&gt;
&lt;br&gt;
Unauthenticated connections on Unix-domain sockets are now disabled,&lt;br&gt;
even if no authentication is configured; however, tor will always accept&lt;br&gt;
control connections if the client has the same uid and gid as the server&lt;br&gt;
(regardless of authentication settings).  The new config file parameters&lt;br&gt;
"ControlAllowUsers" and "ControlAllowGroups" can be used to allow \
other&lt;br&gt; users.  Each takes a comma-separated list of user/group names; for&lt;br&gt;
groups, any member of a group (as determined by /etc/group) is accepted.&lt;br&gt;
This is similar to the AllowUsers/AllowGroups settings in openssh.&lt;br&gt;
&lt;br&gt;
The problem I've run into is that the listener socket permissions are&lt;br&gt;
affected by the umask, and Linux won't let users without write&lt;br&gt;
permission connect (apparently other systems ignore the permissions).&lt;br&gt;
The obvious solution of fchmod(fd, 0777) has no effect; other possible&lt;br&gt;
solutions are:&lt;br&gt;
 - Use chmod; this would be vulnerable to a race condition if another&lt;br&gt;
   user could delete and replace the socket before the chmod, but it&lt;br&gt;
   should be okay if there's a warning in the documentation.&lt;br&gt;
 - Change the umask temporarily; this would affect all threads, so it's&lt;br&gt;
   only an option if filesystem operations are restricted to one thread.&lt;br&gt;
&lt;br&gt;
Any suggestions?&lt;br&gt;
&lt;br&gt;
So far this patch has only been tested on Linux, but it seems to work&lt;br&gt;
fine after manually fixing the socket permissions.  Testing on other&lt;br&gt;
Unix-like systems would be helpful, if anyone's interested (run&lt;br&gt;
autoreconf before building it).&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;
-- Michael&lt;br&gt;
&lt;/font&gt;&lt;br&gt;-----BEGIN PGP SIGNATURE-----&lt;br&gt;
Version: GnuPG v2.0.9 (GNU/Linux)&lt;br&gt;
&lt;br&gt;
iEYEARECAAYFAkmqZVQACgkQ+RZl+46r4TdNzgCfdu6TvbQyrNfMWeijKJRpUXjn&lt;br&gt;
1bsAnjPj89471DOj3ho1XF2Fui8YZXP1&lt;br&gt;
=0EF0&lt;br&gt;
-----END PGP SIGNATURE-----&lt;br&gt;
&lt;br&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20090301185602</emailId><senderName>Michael Gold</senderName><senderEmail>torlists@rilmarder.org</senderEmail><timestampReceived>2009-03-01 18:56:02-0400</timestampReceived><subject>Re: Patch to authenticate by uid/gid on ControlSocket</subject><body>


On Sun, Mar 01, 2009 at 10:47:03 -0700, John Brooks wrote:
&gt; Great idea! This should simplify things quite a lot when using control
&gt; connections.
&gt; 
&gt; I'm surprised fchmod doesn't work, but I don't think using chmod() would be
&gt; a problem here. Another user very likely wouldn't have the permissions to
&gt; replace the socket file, and if they did, the chmod() call would then fail
&gt; as the tor user would not own the new file. If they were already running as
&gt; the tor user, they could do all sorts of other things and make it really a
&gt; moot point anyway. I don't see a way that another user could bother tor
&gt; using that race condition.

The problem of fchmod not working is Linux-specific and seems to be
brought up on LKML every few years, though there's never a response and
nobody's sent a patch.

The race condition could be exploited by hardlinking a file owned by the
Tor user, which would then become world-writable.  But this would only
work if the attacker had write permission to the directory and the
sticky bit was clear.

-- Michael

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090302185821</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-03-02 18:58:21-0400</timestampReceived><subject>Re: Patch to authenticate by uid/gid on ControlSocket</subject><body>

On Sun, Mar 01, 2009 at 05:37:09AM -0500, Michael Gold wrote:
&gt; Hi all,
&gt; 
&gt; The attached patch allows tor (0.2.0.34) to automatically authenticate
&gt; the client of a Unix-domain control socket, by asking the kernel for the
&gt; uid and gid of the remote user.  There are still some unresolved issues,
&gt; but feedback would be appreciated.

Hi, Michael!

A few issues here: first off, we try not to add new features in the
stable series.  Since the development series is in feature freeze too
(we're trying to stabilize it), we'd have to hold off on applying this
until 0.2.2.x-alpha forks off.

Secondly, UID/GID-based authentication is potentially problematic in
the general case, and I think we should think hard about whether it's
safe in the particular case here.  For TCP sockets, it would be a
totally bad idea: it's way to easy for a user's web browser (which
runs as their own UID/GID, after all) to get tricked into making a
connection to a local socket, saying "AUTHENTICATE\r\n", and then
running whatever anonymity-breaking control commands the attacker
wants.  (That's why we recommend passwords on all control sockets.)
Now, I don't _think_ the same attack works for unix sockets, but we
should try to figure out if there is a similar attack here.  I'd guess
offhand that this is probably safe, but I'd like to have more than a
guess to go on here.
 
I'm also worried about the change that seems (if I understand
correctly) to make the initial AUTHENTICATE command optional when
you're using UID/GID authentication.  Some of the earliest attacks on
the control port protocol worked by embedding the payload inside
another protocol, confident that any amount of garbage would get
ignored if it ended with \r\n.  That's why the current protocol closes
the connection immediately if the first command is anything but
AUTHENTICATE or PROTOCOLINFO.  Accepting anything besides
AUTHENTICATE, PROTOCOLINFO, or QUIT as a first command is
nonconformant to control-spec.txt, and probably shouldn't be allowed.

On the permissions issue: In Tor today, I believe only the main thread
creates any files, so it ought to be safe to change the umask
temporarily.


&gt; diff --git a/configure.in b/configure.in
&gt; index e733ad9..d7c0a25 100644

[Nice to see somebody besides me using git. ;) ] 

&gt; --- a/configure.in
&gt; +++ b/configure.in
&gt; @@ -18,7 +18,7 @@ fi
&gt;  
&gt;  # Not a no-op; we want to make sure that CPPFLAGS is set before we use
&gt;  # the += operator on it in src/or/Makefile.am
&gt; -CPPFLAGS="$CPPFLAGS -I../common"
&gt; +CPPFLAGS="$CPPFLAGS -I\${top_srcdir}/src/common"

This seems like an unrelated change for cross-compiling, yeah?  If so,
maybe it should go into its own patch.  


&gt;    if (options-&gt;CookieAuthentication) {
&gt;      int also_password = options-&gt;HashedControlPassword != NULL ||
&gt;        options-&gt;HashedControlSessionPassword != NULL;
&gt; @@ -2642,6 +2642,179 @@ connection_control_reached_eof(control_connection_t *conn)
&gt;    return 0;
&gt;  }
&gt;  
&gt; +/** Called to initialise a new control socket. */
&gt; +int
&gt; +connection_control_init_accepted_conn(control_connection_t *conn)
&gt; +{

Wow, there's a lot of code here.  Any way to break this into
functions?  It seems like it might be easier to parse the user/group
lists when the option is set, rather than when the connection happens,
too.

yrs,
-- 
Nick
</body></email><email><emailId>20090213222341</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-02-13 22:23:41-0400</timestampReceived><subject>Re: Effect of Tor window size on performance</subject><body>

On Wed, Feb 04, 2009 at 10:25:31AM +0100, Csaba Kiraly wrote:
&gt; http://disi.unitn.it/locigno/preprints/TR-DISI-08-041.pdf
[snip]
&gt; Another thing that comes to my mind is that a better separation of 
&gt; signaling (directory lookup, circuit setup, etc.) and data path would be 
&gt; beneficial. This would ease things such as experimenting with DTLS or 
&gt; other transport methods on the overlay tunnel, and experimenting with 
&gt; different solutions end-to-end.

True. But on the other hand, if we separate them on the wire then we
are giving up some potential anonymity protections that we might get by
blending them together.

I've heard from a few people studying the "website fingerprinting"
attack (see #1 on https://www.torproject.org/volunteer#Research) that
Tor's directory fetches confuse their statistics. Whether it's something
that could be easily distinguished and removed from their statistics is
an open question. My guess is that it's not confusing the attack very
much, so we shouldn't be too stubborn about keeping everything blended
together. But "more research remains", as they say.

&gt; &gt;So the next question is an implementation one. Right now the window sizes
&gt; &gt;are hard-coded at both ends. I've been meaning to extend the protocol
&gt; &gt;so sendme cells have a number in them, and so the initial window sizes
&gt; &gt;are specified in the 'create' and 'created' cells for circuits and the
&gt; &gt;'begin' and 'connected' cells for streams. But we haven't really fleshed
&gt; &gt;out the details of those designs, or how they could be phased in and still
&gt; &gt;handle clients and relays that don't use (or know about) the numbers.
&gt; &gt;
&gt; &gt;So the big deployment question is: is it worth it to work on a design
&gt; &gt;for the above, and then either shrink the default window sizes or do
&gt; &gt;something smarter like variable window sizes, or should we just be
&gt; &gt;patient until a UDP-based solution is more within reach?
&gt; &gt;
&gt; &gt;One answer is that if you were interested in working on a design proposal
&gt; &gt;and patch, it would be much more likely to get implemented. :)
&gt; &gt;  
&gt; We are doing verifications on this. Our lab experiments (the ones in the 
&gt; tech report) show that there is a huge gain on the user side in delays, 
&gt; while throughput is untouched. Throughput is capped with a static window 
&gt; size, but I think the cap can be chosen better than what it is now. 
&gt; There should also be a big gain in the memory consumption of ORs, 
&gt; although we didn't measure it yet. Since the Tor network is kind of 
&gt; overloaded all the time, memory usage should decrease almost linearly 
&gt; with the window size.
&gt; 
&gt; Currently we are verifying one-side modification of the circuit, i.e. 
&gt; whether one side of the connection can reduce the widow size on its own, 
&gt; without explicitly notifying the other side.  From the  code it seems to 
&gt; me that this will work, and if so, phasing in a smaller window size in a 
&gt; new release should not be a problem.

Hey, that's a really good point. We don't have to change much code at
all if we want to use a *smaller* package window than we are allowed. We
simply pretend that the package window started out smaller, and either
side can do that independently!

Do you have a patch in mind for this? It would seem that if we
change init_circuit_base() so it sets circ-&gt;package_window to some
lower number x, and change connection_exit_begin_conn() so it sets
nstream-&gt;package_window to some even lower number y, that should be it.
The client side will send sendme's like normal, and the only difference
is that no more than y cells will ever be 'in flight' for a given stream.

So here are the questions we need to consider:

1) What values of x and y are best? Presumably as we reduce them from
1000 and 500, the performance gets better, but at some point they become
so low that performance gets worse (because each round-trip through the
network takes extra time). As sample numbers, if we start x at 100 and
y at 50, then we need another round-trip for any stream that delivers
more than 24900 bytes, and/or for every 49800 bytes on the circuit.
Should our choices be influenced by the 'typical' Tor stream that the
network is seeing right now? (Not that we have those numbers, but maybe
we should get them.) What other factors are there?

2) What are the effects of this patch in a hybrid Tor network? If some
exit relays use package windows of 1000, and newer ones use package
windows of 100, will the newer ones get 'clobbered' by the old ones?
That is, should we expect to see even more slow-down in the network
while the relays transition? Is there anything we can do about that,
since it will take a year or more for everybody to transition?

3) Should we reduce the package_windows on the client side too? It would
be easy to do. How do we decide whether it's worth it?

Anything I missed?

Thanks!
--Roger

</body></email><email><emailId>20090215201536</emailId><senderName>"Steven J. Murdoch"</senderName><senderEmail>tor+steven.murdoch@cl.cam.ac.uk</senderEmail><timestampReceived>2009-02-15 20:15:36-0400</timestampReceived><subject>Re: Effect of Tor window size on performance</subject><body>

On Fri, Feb 13, 2009 at 05:23:41PM -0500, Roger Dingledine wrote:
&gt; I've heard from a few people studying the "website fingerprinting"
&gt; attack (see #1 on https://www.torproject.org/volunteer#Research) that
&gt; Tor's directory fetches confuse their statistics. Whether it's something
&gt; that could be easily distinguished and removed from their statistics is
&gt; an open question.

Currently, directory fetches are trivial to remove from traffic dumps,
with high probability.

Firstly, directory fetches don't use guards. So if you watch for a
little while, the guards become obvious and the remainder can be
eliminated. 

Secondly, the directory fetches use very large TLS application
records. I assume this is because the mirror can serve the document
straight out of memory, rather than having to wait for cells to
trickle in.

Both these issues could be fixed, but then some more subtle traffic
analysis techniques could be used (e.g. using latency of round-trips
to see circuit extension and count hops). Making them hard to
distinguish would be a difficult problem.

Steven.

-- 
w: http://www.cl.cam.ac.uk/users/sjm217/
</body></email><email><emailId>20090121054604</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-01-21 05:46:04-0400</timestampReceived><subject>Re: Proposal 158: Clients download consensus + microdescriptors</subject><body>

On Sun, Jan 18, 2009 at 02:22:52PM -0500, Roger Dingledine wrote:
&gt; Filename: 158-microdescriptors.txt
&gt; Title: Clients download consensus + microdescriptors
&gt; Version: $Revision: 18172 $
&gt; Last-Modified: $Date: 2009-01-18 13:57:20 -0500 (Sun, 18 Jan 2009) $
&gt; Author: Roger Dingledine
&gt; Created: 17-Jan-2009
&gt; Status: Open

Hi, Roger!  This needs even more discussion, but I think it's going on
the right direction.

&gt; 
&gt; 1. Overview
&gt; 
&gt;   This proposal replaces section 3.2 of proposal 141, which was
&gt;   called "Fetching descriptors on demand". Rather than modifying the
&gt;   circuit-building protocol to fetch a server descriptor inline at each
&gt;   circuit extend, we instead put all of the information that clients need
&gt;   either into the consensus itself, or into a new set of data about each
&gt;   relay called a microdescriptor. The microdescriptor is a direct
&gt;   transform from the relay descriptor, so relays don't even need to know
&gt;   this is happening.
&gt; 
&gt;   Descriptor elements that are small and frequently changing should go
&gt;   in the consensus itself, and descriptor elements that are small and
&gt;   relatively static should go in the microdescriptor. If we ever end up
&gt;   with descriptor elements that aren't small yet clients need to know
&gt;   them, we'll need to resume considering some design like the one in
&gt;   proposal 141.

This is a good breakdown, and clarifies our motivation decently well.

Does this mean that the ports should (assuming it's possible) get
moved into the microdescriptor?  I think exit policies are relatively
stable.

 [...] 
&gt; 3. Design
&gt; 
&gt;   There are three pieces to the proposal. First, authorities will list in
&gt;   their votes (and thus in the consensus) what relay descriptor elements
&gt;   are included in the microdescriptor, and also list the expected hash
&gt;   of microdescriptor for each relay. Second, directory mirrors will serve
&gt;   microdescriptors. Third, clients will ask for them and cache them.
&gt; 
&gt; 3.1. Consensus changes
&gt; 
&gt;   V3 votes should include a new line:
&gt;     microdescriptor-elements bar baz foo
&gt;   listing each descriptor element (sorted alphabetically) that authority
&gt;   included when it calculated its expected microdescriptor hashes.
&gt; 
&gt;   We also need to include the hash of each expected microdescriptor in
&gt;   the routerstatus section. I suggest a new "m" line for each stanza,
&gt;   with the base64 of the hash of the elements that the authority voted
&gt;   for above.
&gt; 
&gt;   The consensus microdescriptor-elements and "m" lines are then computed
&gt;   as described in Section 3.1.2 below.
&gt; 
&gt;   I believe that means we need a new consensus-method "6" that knows
&gt;   how to compute the microdescriptor-elements and add "m" lines.

Right.  We'll allocate the actual number when we implement; 6 seems
likeliest.

 [...]
&gt; 3.1.2. Computing consensus for microdescriptor-elements and "m" lines
 [...]
&gt;   It would be nice to have a more foolproof way to agree on what
&gt;   microdescriptor hash each authority should vote for, so we can avoid
&gt;   missing "m" lines. Just switching to a new consensus-method each time
&gt;   we change the set of microdescriptor-elements won't help though, since
&gt;   each authority will still have to decide what hash to vote for before
&gt;   knowing what consensus-method will be used.
&gt; 
&gt;   Here's one way we could do it. Each vote / consensus includes
&gt;   the microdescriptor-elements that were used to compute the hashes,
&gt;   and also a preferred-microdescriptor-elements set. If an authority
&gt;   has a consensus from the previous period, then it should use the
&gt;   consensus preferred-microdescriptor-elements when computing its votes
&gt;   for microdescriptor-elements and the appropriate hashes in the upcoming
&gt;   period. (If it has no previous consensus, then it just writes its
&gt;   own preferences in both lines.)

Here's a way that recovers a little more gracefully from
desynchronization.  The vote could include two sets at most: the one
you would like to use, and the one that was used in the most recent
consensus you have.  You include m-lines for both.  If either set
wins, your m-lines influence the consensus.

(If your favorite set is the one that the last consensus lists, you
wouldn't include duplicate m-lines.)

&gt; 3.2. Directory mirrors serve microdescriptors
&gt; 
&gt;   Directory mirrors should then read the microdescriptor-elements line
&gt;   from the consensus, and learn how to answer requests. (Directory mirrors
&gt;   continue to serve normal relay descriptors too, a) to serve old clients
&gt;   and b) to be able to construct microdescriptors on the fly.)
&gt; 

So let's talk a little bit about why we're doing it this way.

The reason for doing this particular design (call it "caches build
microdescriptors") is mainly b above, so that if more info needs to
get added to microdescriptors, the caches can just serve it, and they
don't need to be upgraded.

The alternative would be to have the authorities generate and serve
the microdescriptors themselves.  (Call this "authorities build
microdescriptor".)  This would give us greater freedom in what we put
in them and how we format them, but would require more stuff to get
downloaded and cached from the authorities by the mirrors.

Even though I initially advocated it, I am not sure that the approach
this proposal takes actually helps forward compatibility.  After all,
the only reason to add a new field to microdescriptors is because
clients are going to start using it.  So, clients are upgrading
anyway.  Authorities would in both cases need to be reconfigured, at
least, to vote for the new microdescriptor constructions.

So how are these approaches different in their outcomes?

Advantages for "Caches build microdescriptors"

   + Caches download less from the authorities. 
   + It is trivial to determine that the authorities have computed the
     microdescriptor for a descriptor correctly if you have both.
     (With "Authorities build microdescriptors", you need to know the
     algorithm that the authorities used, so it's easy, but not
     quite so trivial.)
   +??? We can change what goes into microdescriptors just by
     upgrading the authority configuration.  This is not so great as
     it might first seem.  Revisions to microdescriptor contents
     shouldn't happen lightly, after all, since making them bigger
     will defeat their purpose, and taking things out will make old
     clients stop working.  Since changing their contents would
     require a proposal and a client behavior shift anyway, is having
     the authorities upgrade to a new consensus-version such a big deal?

Advantages for "Authorities build microdescriptors":
   + We have more flexibility about what the microdescriptors can
     contain.  For instance, they can't include the equivalent of the
     "p" lines in the current consensus format, even though those need
     to be calculated from exit policies, and are not simple copies.
     This is especially important if our goal is to shift stable info
     into the microdescriptors in order to keep consensuses small
     while making clients download descriptors less.

That's 3 advantages for "Caches build", and only 1 for "Authorities
build", but I think that the advantage of "authorities build" is much
bigger.  It lets us consider things like the exit-ports line, binary
packing of onion keys [not actually a win, but the next thing could
be], and so on.  What do you think?

(I think it was originally I who argued for a list of items to include
in the first place.  I may have been wrong and reaching for premature
generality.)

&gt;   The microdescriptors with hashes &lt;D1&gt;,&lt;D2&gt;,&lt;D3&gt; should be available at:
&gt;     http://&lt;hostname&gt;/tor/micro/d/&lt;D1&gt;+&lt;D2&gt;+&lt;D3&gt;.z

This implies that unless the mirror knows the microdescriptors for
every router in the last two or three consensuses, the client is out of
luck.  Thus, the mirror must have kept track of the fields listed for
microdescriptors in all the live consensuses.  So be it.

&gt;   All the microdescriptors from the current consensus should also be
&gt;   available at:
&gt;     http://&lt;hostname&gt;/tor/micro/all.z
&gt;   so a client that's bootstrapping doesn't need to send a 70KB URL just
&gt;   to name every microdescriptor it's looking for.

Good idea.

&gt;   The format of a microdescriptor is the header line
&gt;   "microdescriptor-header"
&gt;   followed by each element (keyword and body), alphabetically. There's
&gt;   no need to mention what hash it's for, since it's self-identifying:
&gt;   you can hash the elements to learn this.

We should mention that the header line is semantically important.  If
you see:
  microdescriptor-header foo bar
  foo X
then you know that the base descriptor has no bar element, whereas if
you see:
  microdescriptor-header foo
  foo X
then you know nothing about the bar element.

What are clients supposed to do, btw, if they find that the
microdescriptors that the authority lists do not contain some field
they regard as essential?  I assume the answer is, "This must never
happen.  Once a client version uses a field in microdescriptors, that
field must be present in microdescriptors until all client versions
requiring it are obsolete."  Yes?  Otherwise clients that want that
field need to fall back to descriptors.

&gt;   (Do we need a footer line to show that it's over, or is the next
&gt;   microdescriptor line or EOF enough of a hint? A footer line wouldn't
&gt;   hurt much. Also, no fair voting for the microdescriptor-element
&gt;   "microdescriptor-header".)

I don't see that a footer line is necessary.

&gt;   The hash of the microdescriptor is simply the hash of the concatenated
&gt;   elements -- not counting the header line or hypothetical footer line.
&gt;   Unless you prefer that?

Just the elements is fine.

&gt;   Is there a reasonable way to version these things? We could say that
&gt;   the microdescriptor-header line can contain arguments which clients
&gt;   must ignore if they don't understand them. Any better ways?

If we go with the authorities-build-microdescriptors idea, let's have
them numbered like the consensus version.

&gt;   Directory mirrors should check to make sure that the microdescriptors
&gt;   they're about to serve match the right hashes (either the hashes from
&gt;   the fetch URL or the hashes from the consensus, respectively).
&gt; 
&gt;   We will probably want to consider some sort of smart data structure to
&gt;   be able to quickly convert microdescriptor hashes into the appropriate
&gt;   microdescriptor. Clients will want this anyway when they load their
&gt;   microdescriptor cache and want to match it up with the consensus to
&gt;   see what's missing.
&gt;
&gt; 3.3. Clients fetch them and cache them
&gt; 
&gt;   When a client gets a new consensus, it looks to see if there are any
&gt;   microdescriptors it needs to learn. If it needs to learn more than
&gt;   some threshold of the microdescriptors (half?), it requests 'all',
&gt;   else it requests only the missing ones.

The client should estimate the typical compressed microdescriptor size
(CM).  Requesting another microdescriptor costs 41 bytes in the HTTP
request.   If the client wants N microdescriptors, and 41*N &gt; CM, it
should request all.

&gt;   Clients maintain a cache of microdescriptors along with metadata like
&gt;   when it was last referenced by a consensus. They keep a microdescriptor
&gt;   until it hasn't been mentioned in any consensus for a week. Future
&gt;   clients might cache them for longer or shorter times.
&gt; 
&gt; 3.3.1. Information leaks from clients
&gt; 
&gt;   If a client asks you for a set of microdescs, then you know she didn't
&gt;   have them cached before. How much does that leak? What about when
&gt;   we're all using our entry guards as directory guards, and we've seen
&gt;   that user make a bunch of circuits already?
&gt; 
&gt;   Fetching "all" when you need at least half is a good first order fix,
&gt;   but might not be all there is to it.
&gt; 
&gt;   Another future option would be to fetch some of the microdescriptors
&gt;   anonymously (via a Tor circuit).

Are these leaks worse than leaks from descriptor downloading?  If so,
how?

&gt; 4. Transition and deployment
&gt; 
&gt;   Phase one, the directory authorities should start voting on
&gt;   microdescriptors and microdescriptor elements, and putting them in the
&gt;   consensus. This should happen during the 0.2.1.x series, and should
&gt;   be relatively easy to do.

As we discussed on IRC, I believe this should wait till 0.2.2.x.
Getting the authorities onto newer versions is comparatively easy, and
0.2.1.x is in feature freeze now.  If it's important to prototype it
earlier, I can try to do that in a non-merged branch.

&gt;   Phase two, directory mirrors should learn how to serve them, and learn
&gt;   how to read the consensus to find out what they should be serving. This
&gt;   phase could be done either in 0.2.1.x or early in 0.2.2.x, depending
&gt;   on how messy it turns out to be and how quickly we get around to it.
&gt; 
&gt;   Phase three, clients should start fetching and caching them instead
&gt;   of normal descriptors. This should happen post 0.2.1.x.

yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20090121135820</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2009-01-21 13:58:20-0400</timestampReceived><subject>Re: Proposal 158: Clients download consensus + microdescriptors</subject><body>



On Wed, Jan 21, 2009 at 12:46:04AM -0500, Nick Mathewson wrote:
&gt; On Sun, Jan 18, 2009 at 02:22:52PM -0500, Roger Dingledine wrote:

&gt; The reason for doing this particular design (call it "caches build
&gt; microdescriptors") is mainly b above, so that if more info needs to
&gt; get added to microdescriptors, the caches can just serve it, and they
&gt; don't need to be upgraded.
&gt; 
&gt; The alternative would be to have the authorities generate and serve
&gt; the microdescriptors themselves.  (Call this "authorities build
&gt; microdescriptor".)  This would give us greater freedom in what we put
&gt; in them and how we format them, but would require more stuff to get
&gt; downloaded and cached from the authorities by the mirrors.
&gt; 
&gt; Even though I initially advocated it, I am not sure that the approach
&gt; this proposal takes actually helps forward compatibility.  After all,
&gt; the only reason to add a new field to microdescriptors is because
&gt; clients are going to start using it.  So, clients are upgrading
&gt; anyway.  Authorities would in both cases need to be reconfigured, at
&gt; least, to vote for the new microdescriptor constructions.
&gt; 
&gt; So how are these approaches different in their outcomes?
&gt; 
&gt; Advantages for "Caches build microdescriptors"
&gt; 
&gt;    + Caches download less from the authorities. 
&gt;    + It is trivial to determine that the authorities have computed the
&gt;      microdescriptor for a descriptor correctly if you have both.
&gt;      (With "Authorities build microdescriptors", you need to know the
&gt;      algorithm that the authorities used, so it's easy, but not
&gt;      quite so trivial.)
&gt;    +??? We can change what goes into microdescriptors just by
&gt;      upgrading the authority configuration.  This is not so great as
&gt;      it might first seem.  Revisions to microdescriptor contents
&gt;      shouldn't happen lightly, after all, since making them bigger
&gt;      will defeat their purpose, and taking things out will make old
&gt;      clients stop working.  Since changing their contents would
&gt;      require a proposal and a client behavior shift anyway, is having
&gt;      the authorities upgrade to a new consensus-version such a big deal?
&gt; 
&gt; Advantages for "Authorities build microdescriptors":
&gt;    + We have more flexibility about what the microdescriptors can
&gt;      contain.  For instance, they can't include the equivalent of the
&gt;      "p" lines in the current consensus format, even though those need
&gt;      to be calculated from exit policies, and are not simple copies.
&gt;      This is especially important if our goal is to shift stable info
&gt;      into the microdescriptors in order to keep consensuses small
&gt;      while making clients download descriptors less.
&gt; 
&gt; That's 3 advantages for "Caches build", and only 1 for "Authorities
&gt; build", but I think that the advantage of "authorities build" is much
&gt; bigger.  It lets us consider things like the exit-ports line, binary
&gt; packing of onion keys [not actually a win, but the next thing could
&gt; be], and so on.  What do you think?
&gt; 

Just a high-level support for Nick's point. The entire purpose here is
to cleverly eek out some much-needed/desired optimization of
distributing (micro)descriptor information, and as Roger (Needham)
always used to quote to us from Strachey, it's impossible to foresee
the consequences of being clever. In this case that means that until
this has had a chance to work through both in the spec and in
deployment experience for a while you probably want to be maximally
flexible so that an unforeseen change to microdescriptors that
ultimately emerges as necessary or at least clearly desirable is not
locked out or at least is not as painful or requiring of compatibility
tradeoff frustrations in decisions.

Another caveat about the pain of possibly not getting it perfectly
right the first time is potential attacks that somehow sneak in
between the job of the authorities and the job of the descriptors. No,
I don't have anything specific in mind, but its just an observation
that there is probably more protocol-level recovery flexibility (less
need to get it right the first time) in the authorities-build
approach. That shouldn't stop exploration, but the risk tradeoff
should be in mind at all times going forward.

aloha,
Paul
</body></email><email><emailId>20090130043956</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-01-30 04:39:56-0400</timestampReceived><subject>Re: Proposal 158: Clients download consensus + microdescriptors</subject><body>

On Wed, Jan 21, 2009 at 12:46:04AM -0500, Nick Mathewson wrote:
&gt; &gt;   Descriptor elements that are small and frequently changing should go
&gt; &gt;   in the consensus itself, and descriptor elements that are small and
&gt; &gt;   relatively static should go in the microdescriptor. If we ever end up
&gt; &gt;   with descriptor elements that aren't small yet clients need to know
&gt; &gt;   them, we'll need to resume considering some design like the one in
&gt; &gt;   proposal 141.
&gt; 
&gt; This is a good breakdown, and clarifies our motivation decently well.
&gt; 
&gt; Does this mean that the ports should (assuming it's possible) get
&gt; moved into the microdescriptor?  I think exit policies are relatively
&gt; stable.

Yes, we could move ports, exit policies, and the version line into the
microdescriptor.

We could also dump the descriptor digest and timestamp-of-descriptor
as well.

Both of these steps involve breaking the consensus for current clients,
though (you can't do them until all clients are using microdescriptors),
so I didn't discuss them in this proposal.

We might want to think at some point about teaching clients to handle
consensus status lines that are missing these entries. I think that
can be done in a separate (related) proposal. But we should still do
it reasonably soon, or that will be the reason why we can't dump these
elements from the consensus.

&gt;  [...]
&gt; &gt; 3.1.2. Computing consensus for microdescriptor-elements and "m" lines
&gt;  [...]
&gt; &gt;   It would be nice to have a more foolproof way to agree on what
&gt; &gt;   microdescriptor hash each authority should vote for, so we can avoid
&gt; &gt;   missing "m" lines. Just switching to a new consensus-method each time
&gt; &gt;   we change the set of microdescriptor-elements won't help though, since
&gt; &gt;   each authority will still have to decide what hash to vote for before
&gt; &gt;   knowing what consensus-method will be used.
&gt; &gt; 
&gt; &gt;   Here's one way we could do it. Each vote / consensus includes
&gt; &gt;   the microdescriptor-elements that were used to compute the hashes,
&gt; &gt;   and also a preferred-microdescriptor-elements set. If an authority
&gt; &gt;   has a consensus from the previous period, then it should use the
&gt; &gt;   consensus preferred-microdescriptor-elements when computing its votes
&gt; &gt;   for microdescriptor-elements and the appropriate hashes in the upcoming
&gt; &gt;   period. (If it has no previous consensus, then it just writes its
&gt; &gt;   own preferences in both lines.)
&gt; 
&gt; Here's a way that recovers a little more gracefully from
&gt; desynchronization.  The vote could include two sets at most: the one
&gt; you would like to use, and the one that was used in the most recent
&gt; consensus you have.  You include m-lines for both.  If either set
&gt; wins, your m-lines influence the consensus.
&gt; 
&gt; (If your favorite set is the one that the last consensus lists, you
&gt; wouldn't include duplicate m-lines.)

Fine with me. I think desync will be rare, so either of the approaches
should be fine. Whatever is easiest to code and maintain.

&gt; &gt; 3.2. Directory mirrors serve microdescriptors
&gt; &gt; 
&gt; &gt;   Directory mirrors should then read the microdescriptor-elements line
&gt; &gt;   from the consensus, and learn how to answer requests. (Directory mirrors
&gt; &gt;   continue to serve normal relay descriptors too, a) to serve old clients
&gt; &gt;   and b) to be able to construct microdescriptors on the fly.)
&gt; 
&gt; Advantages for "Authorities build microdescriptors":
&gt;    + We have more flexibility about what the microdescriptors can
&gt;      contain.  For instance, they can't include the equivalent of the
&gt;      "p" lines in the current consensus format, even though those need
&gt;      to be calculated from exit policies, and are not simple copies.
&gt;      This is especially important if our goal is to shift stable info
&gt;      into the microdescriptors in order to keep consensuses small
&gt;      while making clients download descriptors less.
&gt; 
&gt; That's 3 advantages for "Caches build", and only 1 for "Authorities
&gt; build", but I think that the advantage of "authorities build" is much
&gt; bigger.  It lets us consider things like the exit-ports line, binary
&gt; packing of onion keys [not actually a win, but the next thing could
&gt; be], and so on.  What do you think?

Agreed, I think that is better.

Can we just have authorities make microdescriptors available with the
same interface that mirrors make them available? I think so.

&gt; &gt;   The microdescriptors with hashes &lt;D1&gt;,&lt;D2&gt;,&lt;D3&gt; should be available at:
&gt; &gt;     http://&lt;hostname&gt;/tor/micro/d/&lt;D1&gt;+&lt;D2&gt;+&lt;D3&gt;.z
&gt; 
&gt; This implies that unless the mirror knows the microdescriptors for
&gt; every router in the last two or three consensuses, the client is out of
&gt; luck.  Thus, the mirror must have kept track of the fields listed for
&gt; microdescriptors in all the live consensuses.  So be it.

Yep. Mirrors will probably cache microdescriptors exactly as clients do.
If they don't change much, this will not be much of a burden.

Though the client isn't totally out of luck: we should do some 'retry'
schedule just like we do already for the case where the mirror doesn't
have the descriptor we want.

&gt; &gt;   The format of a microdescriptor is the header line
&gt; &gt;   "microdescriptor-header"
&gt; &gt;   followed by each element (keyword and body), alphabetically. There's
&gt; &gt;   no need to mention what hash it's for, since it's self-identifying:
&gt; &gt;   you can hash the elements to learn this.
&gt; 
&gt; We should mention that the header line is semantically important.  If
&gt; you see:
&gt;   microdescriptor-header foo bar
&gt;   foo X
&gt; then you know that the base descriptor has no bar element, whereas if
&gt; you see:
&gt;   microdescriptor-header foo
&gt;   foo X
&gt; then you know nothing about the bar element.

I don't understand this part. It seems like you're trying to add a new
feature or something. What will clients care whether foo and bar are
both listed? Do authorities specify that the microdescriptor should list
"foo bar"? If so, it would seem that this header needs to be included
in what is hashed.

Also, you talk of elements in the "base descriptor". How does this play
with putting "p" lines (exit policies) into the microdescriptor, where
that isn't an element in the base descriptor?

Or is the suggestion just that when serving the microdescriptor, the
mirror will put the first keyword of each line of the microdescriptor
into the microdescriptor-header line? What does that buy us?

&gt; What are clients supposed to do, btw, if they find that the
&gt; microdescriptors that the authority lists do not contain some field
&gt; they regard as essential?  I assume the answer is, "This must never
&gt; happen.  Once a client version uses a field in microdescriptors, that
&gt; field must be present in microdescriptors until all client versions
&gt; requiring it are obsolete."  Yes?

Sure.

&gt;  Otherwise clients that want that field need to fall back to descriptors.

Clients or relays falling back to needing a real descriptor is never an
option we want to accept. Otherwise we just lengthen the period of time
where every mirror must cache every descriptor.

&gt; &gt;   The hash of the microdescriptor is simply the hash of the concatenated
&gt; &gt;   elements -- not counting the header line or hypothetical footer line.
&gt; &gt;   Unless you prefer that?
&gt; 
&gt; Just the elements is fine.

See above.

&gt; &gt;   Is there a reasonable way to version these things? We could say that
&gt; &gt;   the microdescriptor-header line can contain arguments which clients
&gt; &gt;   must ignore if they don't understand them. Any better ways?
&gt; 
&gt; If we go with the authorities-build-microdescriptors idea, let's have
&gt; them numbered like the consensus version.

"Numbered like" meaning we start with version 6?

&gt; &gt;   When a client gets a new consensus, it looks to see if there are any
&gt; &gt;   microdescriptors it needs to learn. If it needs to learn more than
&gt; &gt;   some threshold of the microdescriptors (half?), it requests 'all',
&gt; &gt;   else it requests only the missing ones.
&gt; 
&gt; The client should estimate the typical compressed microdescriptor size
&gt; (CM).  Requesting another microdescriptor costs 41 bytes in the HTTP
&gt; request.   If the client wants N microdescriptors, and 41*N &gt; CM, it
&gt; should request all.

Most clients have higher download than upload, so the math isn't quite
this simple. But sure, that's a fine start. We can tweak it later if we
come up with a better way, without affecting anything else.

&gt; &gt; 3.3.1. Information leaks from clients
&gt; &gt; 
&gt; &gt;   If a client asks you for a set of microdescs, then you know she didn't
&gt; &gt;   have them cached before. How much does that leak? What about when
&gt; &gt;   we're all using our entry guards as directory guards, and we've seen
&gt; &gt;   that user make a bunch of circuits already?
&gt; &gt; 
&gt; &gt;   Fetching "all" when you need at least half is a good first order fix,
&gt; &gt;   but might not be all there is to it.
&gt; &gt; 
&gt; &gt;   Another future option would be to fetch some of the microdescriptors
&gt; &gt;   anonymously (via a Tor circuit).
&gt; 
&gt; Are these leaks worse than leaks from descriptor downloading?  If so,
&gt; how?

Well, they are different. In the descriptor case, having cached info from
two days ago means you have no valid descriptors. In the microdescriptor
case, cached info from two days ago probably gives you a lot of the
microdescriptors already.

I'm not sure if one is worse. It feels like the partitioning opportunities
will be greater when the lifetimes of the blobs we cache are much higher
(and have more variance).

&gt; &gt; 4. Transition and deployment
&gt; &gt; 
&gt; &gt;   Phase one, the directory authorities should start voting on
&gt; &gt;   microdescriptors and microdescriptor elements, and putting them in the
&gt; &gt;   consensus. This should happen during the 0.2.1.x series, and should
&gt; &gt;   be relatively easy to do.
&gt; 
&gt; As we discussed on IRC, I believe this should wait till 0.2.2.x.
&gt; Getting the authorities onto newer versions is comparatively easy, and
&gt; 0.2.1.x is in feature freeze now.

Sounds good.

--Roger

</body></email><email><emailId>20090121061408</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-01-21 06:14:08-0400</timestampReceived><subject>Re: Patch to enable socks4/5 support for OR connections</subject><body>

On Fri, Jan 16, 2009 at 01:10:27PM -0800, Christopher Davis wrote:
&gt; Hello,
&gt; 
&gt; I mentioned this work breifly in a post to or-talk just recently.
&gt; Hopefully, this can be useful to others.
&gt; 
&gt; Directory connections could be made to use SOCKS proxies, as well,
&gt; using the same framework. Although, as Roger explained in his reply 
&gt; to my post to or-talk, supporting OR connections seems to be enough
&gt; to get things working.
&gt; 
&gt; The SOCKS 5 client supports rfc 1929 user/pass auth if the 
&gt; configuration directives are set. The SOCKS 4 user id is always 
&gt; left empty.
&gt; 
&gt; Functions to connect through the proxy server are in connection.c.
&gt; I moved in the functions for HTTP CONNECT proxy support from
&gt; connection_or.c, so that there is a consistent framework. Hopefully
&gt; the comments are enough to explain how it works, but if not, I 
&gt; can expand them a bit. 

Hi, Christopher!  This looks like good code to me; it is one of the
best-written feature patches I've seen in a long time.

Right now, though, the Tor development branch is in feature-freeze to
get ready for a stable 0.2.1.x release.  Could I ask you to remind me
to look at this patch again once 0.2.1.x is on a stable branch and
0.2.2.x development is underway?

(If people who want to use Tor from behind their SOCKS proxies would
try this patch out and let me know whether it works for them too, that
would be great.)

thanks again,
-- 
Nick
</body></email><email><emailId>20090105193209</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-01-05 19:32:09-0400</timestampReceived><subject>Re: Country patch for Tor</subject><body>

On Mon, Jan 05, 2009 at 02:30:04PM +0200, Boris Gimelbrand wrote:
&gt; Hi,
&gt; 
&gt; I added a patch that enables choosing exit node country from configuration file.
&gt; It uses already existing functions that access GeoIP database.
&gt; I also added an option to load one country only from the GeoIP database,
&gt; for limited resources systems.

Have you seen the new node list syntax in the development series, in
0.2.1.6-alpha and later?  Now you can do similar things with:
    
    # Use exit nodes in GB.
    ExitNodes {gb}

    # Use exit nodes in countries that have won the World Cup
    # recently. Also use any exit node at MIT.
    ExitNodes {it}, {br}, {fr}, 18.0.0.0/8

    # Don't use an exit node in any country that is sinking under
    # water.
    ExcludeExitNodes {mv}

{This is one of the reasons it's usually better to write feature
patches against the development series (where we add features) than
against stable versions.}
 
yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20090803191148</emailId><senderName>Prithula Dhungel</senderName><senderEmail>prithula.dhungel@gmail.com</senderEmail><timestampReceived>2009-08-03 19:11:48-0400</timestampReceived><subject>overloaded routers in Tor</subject><body>

Hi all,
  It has been mentioned in papers and documents that imbalance in router
load distribution is one of the factors contributing to delay in receiving
responses in Tor and that the reason for this imbalance is due to the router
selection algorithm that is biased towards nodes that advertise high
bandwidth availability. Does anyone know if there has been a detailed study
of measuring what fraction of routers are overloaded in Tor and why they are
overloaded?

Any pointers would be highly appreciated.

Thanks,

-- 
Prithula Dhungel

[Attachment #3 (text/html)]

Hi all,&lt;br&gt;  It has been mentioned in papers and documents that imbalance in router \
load distribution is one of the factors contributing to delay in receiving responses \
in Tor and that the reason for this imbalance is due to the router selection \
algorithm that is biased towards nodes that advertise high bandwidth availability. \
Does anyone know if there has been a detailed study of measuring what fraction of \
routers are overloaded in Tor and why they are overloaded?&lt;br&gt; &lt;br&gt;Any pointers would \
be highly appreciated.&lt;br&gt;&lt;br&gt;Thanks,&lt;br clear="all"&gt;&lt;br&gt;-- &lt;br&gt;Prithula Dhungel&lt;br&gt;



</body></email><email><emailId>20090817222144</emailId><senderName>Robert Hogan</senderName><senderEmail>robert@roberthogan.net</senderEmail><timestampReceived>2009-08-17 22:21:44-0400</timestampReceived><subject>Re: [or-cvs] [tor/master] LetsKillNoConnect removes support for .noconnect This is a patch to remove</subject><body>

On Monday 10 August 2009 03:14:53 Nick Mathewson wrote:
&gt; Author: Jacob Appelbaum &lt;jacob@appelbaum.net&gt;
&gt; Date: Sat, 8 Aug 2009 19:15:22 -0700
&gt; Subject: LetsKillNoConnect removes support for .noconnect
&gt; Commit: 33762b529694f58d7640ebcbef1bc0f940419c89
&gt;

Um, why? Gregory's talk introduces it as a more reliable way of 
establishing if a browser is using Tor. Isn't that what the DNSEL already 
does? If it's more reliable than DNSEL alone, why not offer his javascript 
to sites as a method of corroborating DNSEL results? 

I agree the discovery of an unintended effect is a good reason for removing 
a feature temporarily, just in case, but would it not be useful to 
reinstate it as '.isusingtor' and allow remote sites to make use of it?


</body></email><email><emailId>20090818183648</emailId><senderName>Fabian Keil</senderName><senderEmail>freebsd-listen@fabiankeil.de</senderEmail><timestampReceived>2009-08-18 18:36:48-0400</timestampReceived><subject>Re: [or-cvs] [tor/master] Disable .exit notation unless</subject><body>


coderman &lt;coderman@gmail.com&gt; wrote:

&gt; On Tue, Aug 11, 2009 at 11:33 AM, Fabian
&gt; Keil&lt;freebsd-listen@fabiankeil.de&gt; wrote:
&gt; &gt; ...
&gt; &gt; Passing the exit notation through the TransPort or the NatdPort will
&gt; &gt; be challenging given that Tor only gets the destination IP address.
&gt; 
&gt; the TransPort is intended to be used with DNSPort, thus .exit notation
&gt; will auto map to a private address like .onions do and facilitate the
&gt; same path manipulation.

I stand corrected. Thanks.
 
Fabian

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090825043408</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-08-25 04:34:08-0400</timestampReceived><subject>Proposal 168: Reduce default circuit window</subject><body>

Filename: 168-reduce-circwindow.txt
Title: Reduce default circuit window
Author: Roger Dingledine
Created: 12-Aug-2009
Status: Open
Target: 0.2.2

0. History


1. Overview

  We should reduce the starting circuit "package window" from 1000 to
  101. The lower package window will mean that clients will only be able
  to receive 101 cells (~50KB) on a circuit before they need to send a
  'sendme' acknowledgement cell to request 100 more.

  Starting with a lower package window on exit relays should save on
  buffer sizes (and thus memory requirements for the exit relay), and
  should save on queue sizes (and thus latency for users).

  Lowering the package window will induce an extra round-trip for every
  additional 50298 bytes of the circuit. This extra step is clearly a
  slow-down for large streams, but ultimately we hope that a) clients
  fetching smaller streams will see better response, and b) slowing
  down the large streams in this way will produce lower e2e latencies,
  so the round-trips won't be so bad.

2. Motivation

  Karsten's torperf graphs show that the median download time for a 50KB
  file over Tor in mid 2009 is 7.7 seconds, whereas the median download
  time for 1MB and 5MB are around 50s and 150s respectively. The 7.7
  second figure is way too high, whereas the 50s and 150s figures are
  surprisingly low.

  The median round-trip latency appears to be around 2s, with 25% of
  the data points taking more than 5s. That's a lot of variance.

  We designed Tor originally with the original goal of maximizing
  throughput. We figured that would also optimize other network properties
  like round-trip latency. Looks like we were wrong.

3. Design

  Wherever we initialize the circuit package window, initialize it to
  101 rather than 1000. Reducing it should be safe even when interacting
  with old Tors: the old Tors will receive the 101 cells and send back
  a sendme ack cell. They'll still have much higher deliver windows,
  but the rest of their deliver window will go unused.

  You can find the patch at arma/circwindow. It seems to work.

3.1. Why not 100?

  Tor 0.0.0 through 0.2.1.19 have a bug where they only send the sendme
  ack cell after 101 cells rather than the intended 100 cells.

  Once 0.2.1.19 is obsolete we can change it back to 100 if we like. But
  hopefully we'll have moved to some datagram protocol long before
  0.2.1.19 becomes obsolete.

3.2. What about stream packaging windows?

  Right now the stream packaging windows start at 500. The goal was to
  set the stream window to half the circuit window, to provide a crude
  load balancing between streams on the same circuit. Once we lower
  the circuit packaging window, the stream packaging window basically
  becomes redundant.

  We could leave it in -- it isn't hurting much in either case. Or we
  could take it out -- people building other Tor clients would thank us
  for that step. Alas, people building other Tor clients are going to
  have to be compatible with current Tor clients, so in practice there's
  no point taking out the stream packaging windows.

3.3. What about variable circuit windows?

  Once upon a time we imagined adapting the circuit package window to
  the network conditions. That is, we would start the window small,
  and raise it based on the latency and throughput we see.

  In theory that crude imitation of TCP's windowing system would allow
  us to adapt to fill the network better. In practice, I think we want
  to stick with the small window and never raise it. The low cap reduces
  the total throughput you can get from Tor for a given circuit. But
  that's a feature, not a bug.

4. Evaluation

  How do we know this change is actually smart? It seems intuitive that
  it's helpful, and some smart systems people have agreed that it's
  a good idea (or said another way, they were shocked at how big the
  default package window was before).

  To get a more concrete sense of the benefit, though, Karsten has been
  running torperf side-by-side on exit relays with the old package window
  vs the new one. The results are mixed currently -- it is slightly faster
  for fetching 40KB files, and slightly slower for fetching 50KB files.

  I think it's going to be tough to get a clear conclusion that this is
  a good design just by comparing one exit relay running the patch. The
  trouble is that the other hops in the circuits are still getting bogged
  down by other clients introducing too much traffic into the network.

  Ultimately, we'll want to put the circwindow parameter into the
  consensus so we can test a broader range of values once enough relays
  have upgraded.

5. Transition and deployment

  We should put the circwindow in the consensus (see proposal 167),
  with an initial value of 101. Then as more exit relays upgrade,
  clients should seamlessly get the better behavior.

  Note that upgrading the exit relay will only affect the "download"
  package window. An old client that's uploading lots of bytes will
  continue to use the old package window at the client side, and we
  can't throttle that window at the exit side without breaking protocol.

  The real question then is what we should backport to 0.2.1. Assuming
  this could be a big performance win, we can't afford to wait until
  0.2.2.x comes out before starting to see the changes here. So we have
  two options as I see them:
  a) once clients in 0.2.2.x know how to read the value out of the
  consensus, and it's been tested for a bit, backport that part to
  0.2.1.x.
  b) if it's too complex to backport, just pick a number, like 101, and
  backport that number.

  Clearly choice (a) is the better one if the consensus parsing part
  isn't very complex. Let's shoot for that, and fall back to (b) if the
  patch turns out to be so big that we reconsider.

</body></email><email><emailId>20090825093709</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-08-25 09:37:09-0400</timestampReceived><subject>Re: Proposal 167: Vote on network parameters in consensus</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 08/25/2009 06:32 AM, Roger Dingledine wrote:
&gt;   Consensus documents that are generated with a sufficiently new consensus
&gt;   method (7?) then include a params line that includes every key listed
&gt;   in any vote, and the median value for that key (in case of ties,
&gt;   we use the median closer to zero).
&gt;
&gt; [...]
&gt; 
&gt; 2.2. What about non-integers?
&gt; 
&gt;   I'm not sure how we would do median on non-integer values. Further,
&gt;   I don't have any non-integer values in mind yet. So I say we cross
&gt;   that bridge when we get to it.

Why are medians on non-integer values a problem? If there's an odd
number of non-integer values, we pick the middle one. Otherwise, we
could calculate the mean of the two middle values. (This could also
apply to integer values, instead of deciding in favor of the lower of
the two middle values.)


Also, we might want to add a requirement that every Tor using these
values should adapt to changes gently. Taking the maximum number of
cells in circuit queues as an example: If we change that number from
1000 to 101 on half of the directories, and one directory has uptime
problems, the consensus value might fluctuate between 101 and 1000 (or
550 if we used the mean of the two middle values). In that case, we
probably don't want relays to change their parameters every hour. Maybe
relays should change their parameters only once in, say, 12 hours, and
ignore further updates during that time.

- --Karsten
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkqTsMAACgkQ0M+WPffBEmUqsgCeO2kifV9rLLETbdiCif6lCU5+
TesAn3gxjCzV2opQA/K+gpokm9YgvZn8
=jB8C
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090831185458</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-08-31 18:54:58-0400</timestampReceived><subject>Re: Building tor on Solaris10-Sparc and SunStudio CC</subject><body>

On Wed, Aug 26, 2009 at 09:05:55PM +0200, Thomas.Hluchnik@netcologne.de wrote:

 [...]
&gt; 
&gt; source='compat.c' object='compat.o' libtool=no \
&gt; 	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
&gt; 	cc -DHAVE_CONFIG_H -I. -I../.. -I../../src/common  -I/usr/local/ssl/include -g -g \
&gt; -O -c compat.c "compat.c", line 373: warning: initializer does not fit or is out of \
&gt; range: 128 "compat.c", line 373: warning: initializer does not fit or is out of \
&gt; range: 129

Oh.  It looks like your 'char' is signed.  These should be harmless,
but somebody should write a patch for this.  Probably, making the
array into an array of 'unsigned char', and adding a cast to the
functions that use it, would suffice.

&gt; "compat.c", line 373: warning: initializer does not fit or is out of range: 130
&gt; ...
&gt; ... # lots of lines here !
&gt; ...
&gt; "compat.c", line 398: warning: initializer does not fit or is out of range: 255
&gt; "compat.c", line 1162: warning: statement not reached

Weird; I wonder why we don't see this one on more platforms.

&gt; "compat.c", line 2177: warning: initializer does not fit or is out of range: -1

This could use an explicit cast.  We want an identifier that's not
going to be a thread ID.


&gt; 
&gt; 
&gt; source='circuituse.c' object='circuituse.o' libtool=no \
&gt; 	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
&gt; 	cc -DHAVE_CONFIG_H -I. -I../.. -DSHARE_DATADIR="\"/usr/share\"" \
&gt; -DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
&gt; -I/usr/local/ssl/include   -g -g -O -c circuituse.c "circuitlist.c", line 679: \
&gt; warning: loop not entered at top

Loop not entered at all, apparently.  This code should be in an #if
0/#endif block.

&gt; 
&gt; 
&gt; 
&gt; source='buffers.c' object='buffers.o' libtool=no \
&gt; 	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
&gt; 	cc -DHAVE_CONFIG_H -I. -I../.. -DSHARE_DATADIR="\"/usr/share\"" \
&gt; -DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
&gt; -I/usr/local/ssl/include   -g -g -O -c buffers.c "buffers.c", line 1456: warning: \
&gt; statement not reached 

This should probably be tor_fragile_assert(); break;

&gt; 
&gt; 
&gt; source='geoip.c' object='geoip.o' libtool=no \
&gt; 	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
&gt; 	cc -DHAVE_CONFIG_H -I. -I../..  -DSHARE_DATADIR="\"/usr/share\"" \
&gt; -DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
&gt; -I/usr/local/ssl/include   -g -g -O -c geoip.c "geoip.c", line 296: warning: syntax \
&gt; error:  empty declaration "geoip.c", line 298: warning: syntax error:  empty \
&gt; declaration 

That's inside a huge macro expansion; I can't do much to debug it.


It would be neat if somebody who can program C and who uses this
version of sun CC would clean up these warnings and send in a patch.
It's nice to build warning-free on as many platforms as possible.

yrs,
-- 
Nick


</body></email><email><emailId>20090706022530</emailId><senderName>Prithula Dhungel</senderName><senderEmail>prithula.dhungel@gmail.com</senderEmail><timestampReceived>2009-07-06 02:25:30-0400</timestampReceived><subject>OR interaction with directory server</subject><body>

Hi all,
  Could anyone guide me as to how long does it take for the information
about a new OR (say R1) to be received by an OP (say x), if the OP x wants
to use the OR R1 specifically to make a circuit? I observe a certain amount
of delay in that. Is it because the directory servers need to reach a
consensus for the new OR?

Also, if R1's onion key changes, how long before it will be known to x
(given that x knows about R1 already).

Thanks for the help,
--
Prithula Dhungel

[Attachment #3 (text/html)]

Hi all,&lt;br&gt;=A0 Could anyone guide me as to how long does it take for the in=
formation about a new OR (say R1) to be received by an OP (say x), if the O=
P x wants to use the OR R1 specifically to make a circuit? I observe a cert=
ain amount of delay in that. Is it because the directory servers need to re=
ach a consensus for the new OR?&lt;br&gt;
&lt;br&gt;Also, if R1's onion key changes, how long before it will be known t=
o x (given that x knows about R1 already).&lt;br&gt;&lt;br&gt;Thanks for the help,&lt;br&gt;-=
-&lt;br&gt;Prithula Dhungel&lt;br&gt;


</body></email><email><emailId>20090720235803</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-07-20 23:58:03-0400</timestampReceived><subject>Please help with measuring network statistics on your relay</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hello everyone,

two months ago, I wrote a blog post describing plans to extend network
measurements:

https://blog.torproject.org/blog/performance-measurements-and-blockingresistance-analysis-tor-network


In brief, this plan includes that: entry guards count the number of
clients per country per day; relays determine statistics on the number
of cells waiting in their local queues; exit nodes count the number of
bytes and streams per exit port per day. All these statistics are
aggregated, so that none of the network data can be used to de-anonymize
users. These aggregations include counting users by country, counting
events per day, and rounding up to a multiple of 4 or 8. We need these
network data to make Tor faster and/or more useful for circumvention.

As of today, the necessary code changes to gather these statistics are
ready, including improved statistics for directory requests that have
been in the code before. For now, statistics are only written to local
files and not to extra-info documents. But before changing the
extra-info document format, I want to be sure that the gathered network
data are useful.

The only missing piece is a dozen or more people who configure their
nodes to gather these statistics for two weeks or longer. During and at
the end of this time I'll need the new files ending in -stats that
contain the gathered statistics. Stable and fast nodes are preferred.
For the exit port statistics we'll need some exit nodes permitting
exiting to _all_ ports. It doesn't matter for the statistics if a node
does not permit exiting or doesn't have the Guard flag. If there are no
results to report, the affected -stats file is omitted.

If you want to help out with gathering these statistics on your node (or
just want to know how statistics are measured), please do the following:

- - Run "git clone git://git.torproject.org/git/tor/".
- - Check that you have commit b71bbdc69a56 or later in your branch.
- - Run "./autogen.sh &amp;&amp; ./configure --enable-dirreq-stats
- --enable-entry-stats --enable-buffer-stats --enable-exit-stats &amp;&amp; make".
- - Possibly run "make install", or use the executable in src/or/tor.
- - Add four config options to your torrc: "DirReqStatistics 1",
"EntryStatistics 1", "CellStatistics 1", "ExitPortStatistics 1"; if you
only want to gather some of the statistics, only set those config
options to 1.
- - Add another config option to your torrc, saying where Tor can find
your GeoIP database; if you cloned the tor repository to ~/tor/, the
config option would be: "GeoIPFile ~/tor/src/config/geoip".
- - Start your node and look out for notice-level logs saying that your
node is gathering statistics.
- - Wait for 24 hours for the directory to write files called
dirreq-stats, entry-stats, cell-stats, and exit-stats to its data
directory; these files are extended every 24 hours.
- - Make the content of these -stats files available to me once after 24
hours, after 1 week, and after 2 weeks; I plan to make all files public
together with their analysis by mid-August.
- - Let me know about some basic bandwidth information of your node:
fingerprint, configured BandwidthRate, BandwidthBurst, and
MaxAdvertisedBandwidth if used; also let me know if you are okay with
being mentioned with your real name in PDFs based on these data.

Be aware that this code might contain bugs that break your node! You
should be comfortable running bleeding-edge software versions.

Here is a brief description what kind of data the four -stats files will
contain (examples show fewer data and shorter measurement intervals):

1. Directory request statistics
(dirreq-stats file, --enable-dirreq-stats, DirReqStatistics 1)

written 2009-07-19 18:12:08
started-at 2009-07-19 17:41:54
ns-ips ca=8,de=8,hk=8,ir=8,my=8,ro=8,us=8
ns-v2-ips au=8,ca=8,cn=8,de=8,es=8,gb=8,il=8,it=8,kw=8,ru=8,se=8,us=8
requests-start 2009-07-19 17:41:54
n-ns-reqs ca=8,de=8,hk=8,ir=8,my=8,ro=8,us=8
n-v2-ns-reqs au=8,ca=8,cn=8,de=8,es=8,gb=8,il=8,it=8,kw=8,ru=8,se=8,us=8
n-ns-resp
ok=16,not-enough-sigs=0,unavailable=0,not-found=0,not-modified=0,busy=0
n-v2-ns-resp ok=32,unavailable=0,not-found=8,not-modified=0,busy=0
v2-ns-share 0.05%
v3-ns-share 0.05%
ns-direct-dl complete=0,timeout=0,running=0
ns-v2-direct-dl
complete=28,timeout=0,running=0,min=5744,d1=15039,d2=60333,q1=76680,d3=79327,d4=101335,md=120688,d6=137291,d7=180365,q3=198729,d8=209279,d9=272368,max=3198322541
 ns-tunneled-dl complete=12,timeout=0,running=0
ns-v2-tunneled-dl complete=0,timeout=0,running=0

The dirreq-stats file counts the number of directory requests coming
from clients asking for network statuses. The ns-ips and ns-v2-ips lines
list the number of unique IPs per country for v3 and v2 statuses,
n-ns-reqs and n-v2-ns-reqs the number of requests per country. n-ns-resp
and n-v2-ns-resp list the number of response codes, or rather reasons
for sending them. v2-ns-share and v3-ns-share are estimates of the share
of requests that a directory should see. ns-direct-dl and
ns-v2-direct-dl list the number of complete downloads, timeouts, and
still running downloads for direct requests. ns-tunneled-dl and
ns-v2-tunneled-dl show the same numbers for tunneled requests. When
there are more than 16 complete downloads in the latter four lines,
statistics are given about the client bandwidths in B/s, including
minimum/maximum, deciles, quartiles, and median.

2. Cell statistics
(buffer-stats file, --enable-buffer-stats, CellStatistics 1)

written 2009-07-19 18:11:55 (1800 s)
processed-cells 350,133,131,130,128,123,110,61,12,2
queued-cells 1.61,0.15,0.11,0.31,0.06,0.38,0.12,0.00,0.00,0.00
time-in-queue 3392,585,638,1562,348,1294,145,24,6,117
number-of-circuits-per-share 45

The buffer-stats file contains some statistics about the time that cells
spend in circuit queues. processed-cells are the mean number of total
processed cells per circuit, with circuits divided by 10 classes from
loudest to quietest circuits. queued-cells describe the mean number of
queued cells over time per circuit class. time-in-queue is the mean time
in milliseconds that a cell spends in a queue.
number-of-circuits-per-share is the number of circuits per circuit class.

3. Entry statistics
(entry-stats file, --enable-entry-stats, EntryStatistics 1)

written 2009-07-19 18:12:08
started-at 2009-07-19 17:41:54
ips
de=72,us=72,fr=24,gb=24,it=24,ru=24,cn=16,ir=16,pl=16,??=8,ae=8,ar=8,at=8,az=8,be=8,bg \
=8,br=8,ca=8,ch=8,co=8,cz=8,es=8,fi=8,gr=8,hk=8,hu=8,id=8,ie=8,il=8,in=8,jp=8,kr=8,kw=8,mx=8,my=8,nl=8,ph=8,qa=8,ro=8,sa=8,se=8,sk=8,tr=8,ua=8,vn=8,ye=8


The entry-stats file contains the number of connecting clients to an
entry node per country and 24 hours. These numbers are contained in the
ips line.

4. Exit port statistics
(exit-stats file, --enable-exit-stats, ExitPortStatistics 1)

written 2009-07-06 12:32:03 (86400 s)
kibibytes-written
80=784877,443=184575,27619=528,38230=1079,46060=520055,53456=632231,63032=996797,other=13048442
 kibibytes-read
80=19296747,443=394341,27619=505020,38230=1029286,46060=67253,53456=112665,63032=64583,other=11429424
 streams-opened
80=792612,443=43324,27619=4,38230=4,46060=4,53456=4,63032=4,other=244212

The exit-stats file contains the number of KiB and opened streams per
exit port per 24 hours. The lines show tuples of the exit port number
and the number of KiB or opened streams.


If you have any questions regarding these measurements, or find a bug in
the measurement code, please let me know, here or off-list!

Thanks!
- --Karsten
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkplBIkACgkQ0M+WPffBEmXvOwCfQnH3F2cZpoPgXrMHS9cVFo3t
rH8AoKrU3CYaLCugJ3Sk8DV9LnKSGzZ7
=obKt
-----END PGP SIGNATURE-----


</body></email><email><emailId>20090721213013</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-07-21 21:30:13-0400</timestampReceived><subject>Proposal: Including Network Statistics in Extra-Info Documents</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Filename: XXX-statistics-extra-info-docs.txt
Title: Including Network Statistics in Extra-Info Documents
Author: Karsten Loesing
Created: 21-Jul-2009
Target: 0.2.2
Status: Open

Change history:

  21-Jul-2009  Initial proposal for or-dev


Overview:

  The Tor network has grown to almost two thousand relays and millions
  of casual users over the past few years. With growth has come
  increasing performance problems and attempts by some countries to
  block access to the Tor network. In order to address these problems,
  we need to learn more about the Tor network. This proposal suggests to
  measure additional statistics and include them in extra-info documents
  to help us understand the Tor network better.


Introduction:

  As of May 2009, relays, bridges, and directories gather the following
  data for statistical purposes:

  - Relays and bridges count the number of bytes that they have pushed
    in 15-minute intervals over the past 24 hours. Relays and bridges
    include these data in extra-info documents that they send to the
    directory authorities whenever they publish their server descriptor.

  - Bridges further include a rough number of clients per country that
    they have seen in the past 48 hours in their extra-info documents.

  - Directories can be configured to count the number of clients they
    see per country in the past 24 hours and to write them to a local
    file.

  Since then we extended the network statistics in Tor. These statistics
  include:

  - Directories now gather more precise statistics about connecting
    clients. Fixes include measuring in intervals of exactly 24 hours,
    counting unsuccessful requests, measuring download times, etc. The
    directories append their statistics to a local file every 24 hours.

  - Entry guards count the number of clients per country per day like
    bridges do and write them to a local file every 24 hours.

  - Relays measure statistics of the number of cells in their circuit
    queues and how much time these cells spend waiting there. Relays
    write these statistics to a local file every 24 hours.

  - Exit nodes count the number of read and written bytes on exit
    connections per port as well as the number of opened exit streams
    per port in 24-hour intervals. Exit nodes write their statistics to
    a local file.

  The following four sections contain descriptions for adding these
  statistics to the relays' extra-info documents.


Directory request statistics:

  The first type of statistics aims at measuring directory requests sent
  by clients to a directory mirror or directory authority. More
  precisely, these statistics aim at requests for v2 and v3 network
  statuses only. These directory requests are sent non-anonymously,
  either via HTTP-like requests to a directory's Dir port or tunneled
  over a 1-hop circuit.

  Measuring directory request statistics is useful for several reasons:
  First, the number of locally seen directory requests can be used to
  estimate the total number of clients in the Tor network. Second, the
  country-wise classification of requests using a GeoIP database can
  help counting the relative and absolute number of users per country.
  Third, the download times can give hints on the available bandwidth
  capacity at clients.

  Directory requests do not give any hints on the contents that clients
  send or receive over the Tor network. Every client requests network
  statuses from the directories, so that there are no anonymity-related
  concerns to gather these statistics. It might be, though, that clients
  wish to hide the fact that they are connecting to the Tor network.
  Therefore, IP addresses are resolved to country codes in memory,
  events are accumulated over 24 hours, and numbers are rounded up to
  multiples of 4 or 8.

   "dirreq-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
      [At most once.]

      YYYY-MM-DD HH:MM:SS defines the end of the included measurement
      interval of length NSEC seconds (86400 seconds by default).

      A "dirreq-stats-end" line, as well as any other "dirreq-*" line,
      is only added when the relay has opened its Dir port and after 24
      hours of measuring directory requests.

   "dirreq-v2-ips" CC=N,CC=N,... NL
      [At most once.]
   "dirreq-v3-ips" CC=N,CC=N,... NL
      [At most once.]

      List of mappings from two-letter country codes to the number of
      unique IP addresses that have connected from that country to
      request a v2/v3 network status, rounded up to the nearest multiple
      of 8. Only those IP addresses are counted that the directory can
      answer with a 200 OK status code.

   "dirreq-v2-reqs" CC=N,CC=N,... NL
      [At most once.]
   "dirreq-v3-reqs" CC=N,CC=N,... NL
      [At most once.]

      List of mappings from two-letter country codes to the number of
      requests for v2/v3 network statuses from that country, rounded up
      to the nearest multiple of 8. Only those requests are counted that
      the directory can answer with a 200 OK status code.

   "dirreq-v2-share" num% NL
      [At most once.]
   "dirreq-v3-share" num% NL
      [At most once.]

      The share of v2/v3 network status requests that the directory
      expects to receive from clients based on its advertised bandwidth
      compared to the overall network bandwidth capacity. Shares are
      formatted in percent with two decimal places. Shares are
      calculated as means over the whole 24-hour interval.

   "dirreq-v2-resp" status=num,... NL
      [At most once.]
   "dirreq-v3-resp" status=nul,... NL
      [At most once.]

      List of mappings from response statuses to the number of requests
      for v2/v3 network statuses that were answered with that response
      status, rounded up to the nearest multiple of 4. Only response
      statuses with at least 1 response are reported. New response
      statuses can be added at any time. The current list of response
      statuses is as follows:

      "ok": a network status request is answered; this number
         corresponds to the sum of all requests as reported in
         "dirreq-v2-reqs" or "dirreq-v3-reqs", respectively, before
         rounding up.
      "not-enough-sigs: a version 3 network status is not signed by a
         sufficient number of requested authorities.
      "unavailable": a requested network status object is unavailable.
      "not-found": a requested network status is not found.
      "not-modified": a network status has not been modified since the
         If-Modified-Since time that is included in the request.
      "busy": the directory is busy.

   "dirreq-v2-direct-dl" key=val,... NL
      [At most once.]
   "dirreq-v3-direct-dl" key=val,... NL
      [At most once.]
   "dirreq-v2-tunneled-dl" key=val,... NL
      [At most once.]
   "dirreq-v3-tunneled-dl" key=val,... NL
      [At most once.]

      List of statistics about possible failures in the download process
      of v2/v3 network statuses. Requests are either "direct"
      HTTP-encoded requests over the relay's directory port, or
      "tunneled" requests using a BEGIN_DIR cell over the relay's OR
      port. The list of possible statistics can change, and statistics
      can be left out from reporting. The current list of statistics is
      as follows:

      Successful downloads and failures:

      "complete": a client has finished the download successfully.
      "timeout": a download did not finish within 10 minutes after
         starting to send the response.
      "running": a download is still running at the end of the
         measurement period for less than 10 minutes after starting to
         send the response.

      Download times:

      "min", "max": smallest and largest measured bandwidth in B/s.
      "d[1-4,6-9]": 1st to 4th and 6th to 9th decile of measured
         bandwidth in B/s. For a given decile i, i/10 of all downloads
         had a smaller bandwidth than di, and (10-i)/10 of all downloads
         had a larger bandwidth than di.
      "q[1,3]": 1st and 3rd quartile of measured bandwidth in B/s. One
         fourth of all downloads had a smaller bandwidth than q1, one
         fourth of all downloads had a larger bandwidth than q3, and the
         remaining half of all downloads had a bandwidth between q1 and
         q3.
      "md": median of measured bandwidth in B/s. Half of the downloads
         had a smaller bandwidth than md, the other half had a larger
         bandwidth than md.


Entry guard statistics:

  Entry guard statistics include the number of clients per country and
  per day that are connecting directly to an entry guard.

  Entry guard statistics are important to learn more about the
  distribution of clients to countries. In the future, this knowledge
  can be useful to detect if there are or start to be any restrictions
  for clients connecting from specific countries.

  The information which client connects to a given entry guard is very
  sensitive. This information must not be combined with the information
  what contents are leaving the network at the exit nodes. Therefore,
  entry guard statistics need to be aggregated to prevent them from
  becoming useful for de-anonymization. Aggregation includes resolving
  IP addresses to country codes, counting events over 24-hour intervals,
  and rounding up numbers to the next multiple of 8.

   "entry-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
      [At most once.]

      YYYY-MM-DD HH:MM:SS defines the end of the included measurement
      interval of length NSEC seconds (86400 seconds by default).

      An "entry-stats-end" line, as well as any other "entry-*"
      line, is first added after the relay has been running for at least
      24 hours.

   "entry-ips" CC=N,CC=N,... NL
      [At most once.]

      List of mappings from two-letter country codes to the number of
      unique IP addresses that have connected from that country to the
      relay and which are no known other relays, rounded up to the
      nearest multiple of 8.


Cell statistics:

  The third type of statistics have to do with the time that cells spend
  in circuit queues. In order to gather these statistics, the relay
  memorizes when it puts a given cell in a circuit queue and when this
  cell is flushed. The relay further notes the life time of the circuit.
  These data are sufficient to determine the mean number of cells in a
  queue over time and the mean time that cells spend in a queue.

  Cell statistics are necessary to learn more about possible reasons for
  the poor network performance of the Tor network, especially high
  latencies. The same statistics are also useful to determine the
  effects of design changes by comparing today's data with future data.

  There are basically no privacy concerns from measuring cell
  statistics, regardless of a node being an entry, middle, or exit node.

   "cell-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
      [At most once.]

      YYYY-MM-DD HH:MM:SS defines the end of the included measurement
      interval of length NSEC seconds (86400 seconds by default).

      A "cell-stats-end" line, as well as any other "cell-*" line,
      is first added after the relay has been running for at least 24
      hours.

   "cell-processed-cells" num,...,num NL
      [At most once.]

      Mean number of processed cells per circuit, subdivided into
      deciles of circuits by the number of cells they have processed in
      descending order from loudest to quietest circuits.

   "cell-queued-cells" num,...,num NL
      [At most once.]

      Mean number of cells contained in queues by circuit decile. These
      means are calculated by 1) determining the mean number of cells in
      a single circuit between its creation and its termination and 2)
      calculating the mean for all circuits in a given decile as
      determined in "cell-processed-cells". Numbers have a precision of
      two decimal places.

   "cell-time-in-queue" num,...,num NL
      [At most once.]

      Mean time cells spend in circuit queues in milliseconds. Times are
      calculated by 1) determining the mean time cells spend in the
      queue of a single circuit and 2) calculating the mean for all
      circuits in a given decile as determined in
      "cell-processed-cells".

   "cell-circuits-per-decile" num NL
      [At most once.]

      Mean number of circuits that are included in any of the deciles,
      rounded up to the next integer.


Exit statistics:

  The last type of statistics affects exit nodes counting the number of
  bytes written and read and the number of streams opened per port and
  per 24 hours. Exit port statistics can be measured from looking of
  headers of BEGIN and DATA cells. A BEGIN cell contains the exit port
  that is required for the exit node to open a new exit stream.
  Subsequent DATA cells coming from the client or being sent back to the
  client contain a length field stating how many bytes of application
  data are contained in the cell.

  Exit port statistics are important to measure in order to identify
  possible load-balancing problems with respect to exit policies. Exit
  nodes that permit more ports than others are very likely overloaded
  with traffic for those ports plus traffic for other ports. Improving
  load balancing in the Tor network improves the overall utilization of
  bandwidth capacity.

  Exit traffic is one of the most sensitive parts of network data in the
  Tor network. Even though these statistics do not require looking at
  traffic contents, statistics are aggregated so that they are not
  useful for de-anonymizing users. Only those ports are reported that
  have seen at least 0.1% of exiting or incoming bytes, numbers of bytes
  are rounded up to full kibibytes (KiB), and stream numbers are rounded
  up to the next multiple of 4.

   "exit-stats-end" YYYY-MM-DD HH:MM:SS (NSEC s) NL
      [At most once.]

      YYYY-MM-DD HH:MM:SS defines the end of the included measurement
      interval of length NSEC seconds (86400 seconds by default).

      An "exit-stats-end" line, as well as any other "exit-*" line, is
      first added after the relay has been running for at least 24 hours
      and only if the relay permits exiting (where exiting to a single
      port and IP address is sufficient).

   "exit-kibibytes-written" port=N,port=N,... NL
      [At most once.]
   "exit-kibibytes-read" port=N,port=N,... NL
      [At most once.]

      List of mappings from ports to the number of kibibytes that the
      relay has written to or read from exit connections to that port,
      rounded up to the next full kibibyte.

   "exit-streams-opened" port=N,port=N,... NL
      [At most once.]

      List of mappings from ports to the number of opened exit streams
      to that port, rounded up to the nearest multiple of 4.


Implementation notes:

  Right now, relays that are configured accordingly write similar
  statistics to those described in this proposal to disk every 24 hours.
  With this proposal being implemented, relays include the contents of
  these files in extra-info documents.

  The following steps are necessary to implement this proposal:

  1. The current format of [dirreq|entry|buffer|exit]-stats files needs
     to be adapted to the description in this proposal. This step
     basically means renaming keywords.

  2. The timing of writing the four *-stats files should be unified, so
     that they are written exactly after 24 hours after starting the
     relay. Right now, the measurement intervals for dirreq, entry, and
     exit stats starts with the first observed request, and files are
     written when observing the first request that occurs more than 24
     hours after the beginning of the measurement interval. With this
     proposal, the measurement intervals should all start at the same
     time, and files should be written exactly 24 hours later.

  3. It is advantageous to cache statistics in local files in the data
     directory until they are included in extra-info documents. The
     reason is that the 24-hour measurement interval can be very
     different from the 18-hour publication interval of extra-info
     documents. When a relay crashed after finishing a measurement
     interval, but before publishing the next extra-info document,
     statistics would get lost. Therefore, statistics are written to
     disk when finishing a measurement interval and read from disk when
     generating an extra-info document. As a result, the *-stats files
     need to be overwritten after 24 hours, rather than appending new
     statistics to them. Further, the contents of the *-stats files need
     to be checked in the process of generating extra-info documents.

  4. With the statistics patches being tested, the ./configure options
     should be removed and the statistics code be compiled by default.
     It is still required for relay operators to add configuration
     options (DirReqStatistics, ExitPortStatistics, etc.) to enable
     gathering statistics. However, in the near future, statistics shall
     be enabled gathered by all relays by default, where requiring a
     ./configure option would be a barrier for many relay operators.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkpmM2EACgkQ0M+WPffBEmVxvwCePIPo/oWaHqspvidENbuxWXzB
PJkAn2oaYfyy67CK3ui/AmMYt/lUl1JP
=oWQx
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090603133553</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-06-03 13:35:53-0400</timestampReceived><subject>Re: Writing geoip stats to disk on directories</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/26/2009 06:55 AM, Roger Dingledine wrote:
&gt; [...] this approach sounds like what we should be doing both for the
&gt; geoip aggregate stats you write to the file and analyze, and also for
&gt; the aggregate stats that bridges collect.

The changes for directories writing stats about their usage to disk are
now in master (commit dfebc88). Right now we have 11 nodes measuring
these stats which should give us some good first insights. I'm going to
analyze these data in about 2 weeks from now.

If people here want to help out with getting some stats on their nodes
(or just want to know how stats are measured), please do the following:

- - git clone git://git.torproject.org/git/tor
- - ./autogen.sh &amp;&amp; ./configure --enable-geoip-stats &amp;&amp; make
- - possibly make install, or use the executable in src/or/tor
- - configure the node as directory mirror
- - (there are no further configurations necessary to measure geoip stats)
- - wait for 24 hours for the directory to write a file called geoip-stats
to its data directory; this file is extended every 24 hours
- - make the content of the geoip-stats file available to me/this list by
no later than June 13 (but not much earlier to include at least 1 week
of requests, better 10 days)
- - let me/this list know about some basic bandwidth information of your
node: BandwidthRate, BandwidthBurst, and MaxAdvertisedBandwidth if used

The geoip-stats file will contain entries like this:

written 2009-06-02 18:53:02
started-at 2009-06-01 18:53:00
ns-ips us=1088,de=728,fr=392,cn=248,kr=240,it=208,gb=192,se=176,...
ns-v2-ips us=352,de=208,cn=192,kr=104,gb=80,ca=56,fr=56,ru=56,au=40,...
requests-start 2009-06-01 18:53:00
n-ns-reqs us=1184,de=744,fr=408,kr=336,cn=280,it=216,gb=192,se=176,...
n-v2-ns-reqs us=376,de=208,cn=192,kr=144,gb=88,ru=64,ca=56,fr=56,...
v2-ns-share 0.27%
v3-ns-share 0.27%

This node has a configured bandwidth rate of 200 KB/s and burst of 500 KB/s.

Very brief explanation: The ns-[v2-]ips lines show the number of IP
addresses per country seen in the past 24 hours requesting either a v2
or v3 directory. The n-[v2-]ns-reqs show numbers of v2 or v3 directory
requests per country in the past 24 hours which are slightly higher as
the same IP address can request the directory more than once a day. The
v[23]-ns-share lines show the fraction of such requests by already
bootstrapped clients that we should see. written, started-at, and
requests-start should be self-explanatory.

&gt;&gt; The next step would be to add the geoip-stats lines (or a subset of
&gt;&gt; them) to extra-info documents. I think a proposal for that would be in
&gt;&gt; place, but first I think it's fine to start with measuring on a few
&gt;&gt; nodes and working with files.
&gt; 
&gt; You mean for bridges, or for normal relays? I don't think we're at the
&gt; point yet where we want normal relays to turn on the ENABLE_GEOIP_STATS
&gt; compile-time flag. I want to be much more sure that we've got all the
&gt; details right first. (Like, have run it for several months at a test
&gt; relay and have a good handle on exactly what it's getting.)

Yup. The plan is to analyze the geoip-stats files first and see if we
are happy with the kind of results. The next step would be to write a
proposal for having normal relays report aggregate stats, too.

Speaking of, I didn't change the behavior of bridges writing stats to
their extra-info documents. I don't want to mess with that without
knowing for sure what else will be changed in extra-info documents. All
this will go into a proposal to be discussed here.

Best,
- --Karsten

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkomfDgACgkQ0M+WPffBEmXTrACfa3QGe+enSGPjXkk0YNVj8uEW
RR0An1O9dk7UQ49Iru/K+v5CYK6ozXz0
=2JV9
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090606000913</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2009-06-06 00:09:13-0400</timestampReceived><subject>Re: Older proposals in need of discussion: 149 ("Using data from NETINFO cells")</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On May 22, 2009, at 9:47 PM, Nick Mathewson wrote:

&gt; Last August I sent out proposal 149, but it never got much discussion
&gt; on this list.  (Looking at the archives, I can't find any.)  Here's
&gt; the paragraph that hasn't much been implemented:

I've read through the proposal as it exists today, and it appears to  
be missing something to actually do, imo. Maybe something like the  
next paragraph could help make things clearer?

Adjusting our time and IP address

    When we believe that our clock is skewed, we should log who told us
    so and adjust our clock accordingly. We should remember that we
    (recently) adjusted our clock, and learn whether adjusting the clock
    helped at all. If it didn't help for a few times, we should warn  
that
    our clock is erratic and we cannot work correctly. For our IP  
address,
    we want to build two test circuits before we change our IP, to make
    sure we're really available at the new address and not available at
    the old address anymore. If we're not available at the new  
address, we
    should warn about this problem.

I'm still not totally happy, I still wonder if there is something  
missing that better describes what we want to do

Sebastian
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAkops6kACgkQCADWu989zuY2HACeKX3yck7WGvUGlu32WIcXCt/F
MG0An00gQ4qly+4zUCiN7MtLOX4WiipT
=/LWg
-----END PGP SIGNATURE-----

</body></email><email><emailId>20090606004000</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2009-06-06 00:40:00-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This time, it really is the right feedback for 165. I almost promise.

On May 28, 2009, at 6:51 PM, Nick Mathewson wrote:
&gt; Filename: 165-simple-robust-voting.txt

I thought about issues when we add/remove more than one authority  
before all operators had a chance to upgrade or upgrade again (in case  
of removal), but couldn't come up with an actually bad situation. But  
this led to the realization that the work flow described just talks  
about one authority getting added/removed at a time, I think the  
situation with more than one change can quickly get complex (and it's  
easy to imagine that with 15 authorities, some operators will be on  
vacation for a month, for example). The proposal could maybe be  
clearer on how those cases should be handled by the operators.


Sebastian

-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAkopuuAACgkQCADWu989zubVMgCgzxFa/rdmmyRcOEpUPb36NsNS
24wAoLOKxbQ1xN6ScEAswcB2SRXEhdUr
=hvZP
-----END PGP SIGNATURE-----

</body></email><email><emailId>20090609164458</emailId><senderName>Marcus Griep</senderName><senderEmail>tormaster@xpdm.us</senderEmail><timestampReceived>2009-06-09 16:44:58-0400</timestampReceived><subject>Re: [PATCH] Add port support to TorBulkExitList.py</subject><body>

[Attachment #2 (multipart/mixed)]


Marcus Griep wrote:
&gt; Patch attached, comments welcome.

I noticed one comment left unchanged in my patch that could leave
the next editor of this code a bit confused (comment no longer
matches the comment). This patch includes that minor comment fix
(block @@ -170,10 +171,10 @@) incorporated with my prior patch.

-- 
Marcus Griep
GPG Key ID: 0x070E3F2D
������
https://torproj.xpdm.us
������������ ����.���� �, 3 �

["TorBulkExitList.py.patch" (text/plain)]

Index: TorBulkExitList.py
===================================================================
--- TorBulkExitList.py  (revision 19666)
+++ TorBulkExitList.py  (working copy)
@@ -8,9 +8,10 @@
 from mod_python import util

 DNS.ParseResolvConf()
-def bulkCheck(RemoteServerIP):
+def bulkCheck(RemoteServerIP, RemotePort):
     parsedExitList = "/tmp/TorBulkCheck/parsed-exit-list"
-    cacheFile = parsedExitList + "-" + RemoteServerIP + ".cache"
+    cacheFile = parsedExitList + "-" + RemoteServerIP +\
+        "_" + RemotePort + ".cache"
     confirmedExits = []

     # Do we have a fresh exit cache?
@@ -34,7 +35,7 @@
         # the list
         for possibleExit in possibleExits:
             try:
-                if (isUsingTor(possibleExit, RemoteServerIP) == 0 ):
+                if (isUsingTor(possibleExit, RemoteServerIP, RemotePort) == 0 ):
                     confirmedExits.append(possibleExit)
             except:
                 return None
@@ -52,7 +53,7 @@

     else:
         # Lets return the cache
-        cachedExits = open(parsedExitList, 'r')
+        cachedExits = open(cacheFile, 'r')
         cachedExitList = cachedExits.readlines()
         return cachedExitList

@@ -170,10 +171,10 @@
             # We're getting unexpected data - fail closed
             return 2
         for a in answer.answers:
-            if a['data'] != "127.0.0.2":
-                return 2
+            if a['data'] == "127.0.0.2":
+                return 0
-        # If we're here, we've had a positive exit answer
+        # If we're here, we have not received a positive exit answer
-        return 0
+        return 2

 def parseAddress(req):
     # Get the ip from apache
@@ -199,16 +200,21 @@
     req.content_type = 'text/plain; charset=utf-8'

     RemoteServerIP = parseAddress(req)
-    RemotePort = "80"
+    RemotePort = util.FieldStorage(req).getfirst("port", "80")

     if RemoteServerIP is not None:

         updateCache()
-        TestedExits = bulkCheck(RemoteServerIP)
+        TestedExits = bulkCheck(RemoteServerIP, RemotePort)
         req.write("# This is a list of all Tor exit nodes that can contact " + RemoteServerIP +
         " on Port " + RemotePort + " #\n")
+
+        querystring = "ip=%s" % RemoteServerIP
+       if RemotePort != "80":
+               querystring += "&amp;port=%s" % RemotePort
+
         req.write("# You can update this list by visiting " + \
-        "https://check.torproject.org/cgi-bin/TorBulkExitList.py?ip=%s #\n" % RemoteServerIP)
+        "https://check.torproject.org/cgi-bin/TorBulkExitList.py?%s #\n" % querystring)

         dateOfAccess = time.asctime(time.gmtime())
         req.write("# This file was generated on %s UTC #\n" % dateOfAccess)

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090611034635</emailId><senderName></senderName><senderEmail>tormaster</senderEmail><timestampReceived>2009-06-11 03:46:35-0400</timestampReceived><subject>[PATCH] Fix stale descriptor refetch dropping connection</subject><body>

From: Marcus Griep &lt;marcus@griep.us&gt;

When a refetch is requested for a v2 hidden service descriptor,
but we already have one cached, proceed with the connection
rather than dropping it into limbo.

Signed-off-by: Marcus Griep &lt;marcus@griep.us&gt;
---

 When making a connection, "rewrite_and_attach" considers a hidden
 service descriptor to be stale after 15 minutes. When this occurs,
 it asks the rendclient to refetch the descriptor. The rendclient
 notices that it already has a v2 hidden service descriptor cached
 and drops the request. This results in the connection falling
 through the cracks as no function attempts to further the
 connection attempt.

 This fix adds a single line which, instead of dropping the
 refetch request, passes the query on to be attempted with the
 cached descriptor.

 src/or/rendclient.c |    1 +
 1 files changed, 1 insertions(+), 0 deletions(-)

diff --git a/src/or/rendclient.c b/src/or/rendclient.c
index 6fe3a69..a161c5c 100644
--- a/src/or/rendclient.c
+++ b/src/or/rendclient.c
@@ -495,6 +495,7 @@ rend_client_refetch_v2_renddesc(const rend_data_t *rend_query)
   if (rend_cache_lookup_entry(rend_query-&gt;onion_address, -1, &amp;e) &gt; 0) {
     log_info(LD_REND, "We would fetch a v2 rendezvous descriptor, but we "
                       "already have that descriptor here. Not fetching.");
+    rend_client_desc_trynow(rend_query-&gt;onion_address);
     return;
   }
   log_debug(LD_REND, "Fetching v2 rendezvous descriptor for service %s",
-- 
1.6.0.4

</body></email><email><emailId>20090614090024</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-14 09:00:24-0400</timestampReceived><subject>Re: Proposal 161: Computing Bandwidth Adjustments</subject><body>

On Wed, May 13, 2009 at 01:30:06AM -0400, Nick Mathewson wrote:
&gt; &gt; Each slice takes around 3-6 hours. The entire network can take as long
&gt; &gt; as a week.. Hence the desire to parallelize..
&gt; 
&gt; My intuition says that unless we scan the whole network every two days
&gt; (or ideally less), our data will likely be useless.
&gt; 
&gt; What if, instead of running in a batch mode, we were constantly
&gt; scanning and iteratively refining our guesses for ratios, discounting
&gt; old data as newer data arrived?  We'd still want to parallelize some,
&gt; but we wouldn't run into the problem of having some nodes' estimated
&gt; values be far more accurate than others.

I think this is a key idea that we should try to do. Doing a run for
several hours before getting numbers means that our numbers will always
be several hours out of date. If our plan is to do continuous runs
anyway, then we should be able to have a "most recent estimate" after
each measurement, that combines that result with the previous results
in some smart way.

But that said, I'm fine with phase one being "do it the way Mike already
has in mind", in the interest of getting something up and working. I
think the formats we've defined so far won't have to change if we switch
to a better estimation method for attempt #2.

&gt; &gt; I'm not sure what to do with this second problem as it is
&gt; &gt; non-deterministic. Using the alpha smoothing factor from your reply to
&gt; &gt; 160 seems like it should help. I do actually track bandwidth changes
&gt; &gt; during the scan, I and I can write some code to abstain from
&gt; &gt; publishing updates to nodes whose bandwidths change drastically during
&gt; &gt; the scan. But what is "drastically", and is this edge case worth the
&gt; &gt; complexity, or is the alpha smoothing good enough?
&gt; 
&gt; I don't know, alas.  Is there a way we can measure how this is working
&gt; in practice?  I think that if we refresh our bandwidth estimates only
&gt; (say) every day or so, we will really hammer nodes that want to change
&gt; their bandwidth downward, which seems poor.  Lagging on nodes that
&gt; raise their bandwidth isn't quite as bad.
&gt; 
&gt; Roger -- any intuition on this one?  It is too hard for 01:30 EDT Nick.

It remains to be seen how much oscillation we'll actually have. I would
think it's better to oscillate more than to never quite get where we
should actually be. And the more up-to-date our measurement can be,
the less oscillation we should see.

I think if we figure that most relays have about the same actual capacity
from one hour to the next, then we ought to be able to make it work. The
actual parameters for damping will have to be determined experimentally.
But if we keep track of votes we can look afterwards to see how often we
overshoot. It will be a fun exercise to add to Karsten's (already full)
plate. :) Really, even if we do it horribly, I think we're still going
to be doing better than the current load balancing approach.

&gt; &gt; &gt; Slightly less crazy idea 2: if the values change too fast, we could do
&gt; &gt; &gt; a standard time-weighted average, where we compute the new declared
&gt; &gt; &gt; bandwidth BW' as a weighted average of the old declared bandwidth
&gt; &gt; &gt; and
&gt; &gt; &gt; the new measured bandwidth.)
&gt; &gt;
&gt; &gt; Yeah, I like idea 2, basically what you mentioned in 160. This would
&gt; &gt; be done Tor-end, not scanner end, right?
&gt; 
&gt; I don't have a strong feeling about that.  To me, it seems easier to
&gt; do it at the scanner end, or as a processing step between the scanner
&gt; end and the authorities... but that's just because I'm thinking of the
&gt; scanner stuff as easier to change if we think of a better algorithm.

Seems smartest to do it in the set of steps before Tor reads in the
file. Whether that's "in" the scanner, or in some intermediate phase,
doesn't much matter to Tor. But I think Tor's job should be to take the
number from the file and put it in its next vote (and then know how to
turn votes into a consensus bandwidth, including clipping to some cap,
modifying by some deterministic rounding-off process, etc).

--Roger

</body></email><email><emailId>20090825043206</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-08-25 04:32:06-0400</timestampReceived><subject>Proposal 167: Vote on network parameters in consensus</subject><body>

Filename: 167-params-in-consensus.txt
Title: Vote on network parameters in consensus
Author: Roger Dingledine
Created: 18-Aug-2009
Status: Open
Target: 0.2.2

0. History


1. Overview

  Several of our new performance plans involve guessing how to tune
  clients and relays, yet we won't be able to learn whether we guessed
  the right tuning parameters until many people have upgraded. Instead,
  we should have directory authorities vote on the parameters, and teach
  Tors to read the currently recommended values out of the consensus.

2. Design

  V3 votes should include a new "params" line after the known-flags
  line. It contains key=value pairs, where value is an integer.

  Consensus documents that are generated with a sufficiently new consensus
  method (7?) then include a params line that includes every key listed
  in any vote, and the median value for that key (in case of ties,
  we use the median closer to zero).

2.1. Planned keys.

  The first planned parameter is "circwindow=101", which is the initial
  circuit packaging window that clients and relays should use. Putting
  it in the consensus will let us perform experiments with different
  values once enough Tors have upgraded -- see proposal 168.

  Later parameters might include a weighting for how much to favor quiet
  circuits over loud circuits in our round-robin algorithm; a weighting
  for how much to prioritize relays over clients if we use an incentive
  scheme like the gold-star design; and what fraction of circuits we
  should throw out from proposal 151.

2.2. What about non-integers?

  I'm not sure how we would do median on non-integer values. Further,
  I don't have any non-integer values in mind yet. So I say we cross
  that bridge when we get to it.

</body></email><email><emailId>20090826190555</emailId><senderName></senderName><senderEmail>thomas.hluchnik</senderEmail><timestampReceived>2009-08-26 19:05:55-0400</timestampReceived><subject>Building tor on Solaris10-Sparc and SunStudio CC</subject><body>


Hello,

may I shortly introduce myself here: I am a german Sysadmin who is member of the \
German Privacy Foundation. I am running two tor nodes with Linux (baphomet, info4all) \
privately. Now I take my time to play around running tor on Sparc/Solaris10 with \
Sun's Compiler Suite. For this purpose I have another node (herecomesthesun) running \
at home via DSL. Perhaps I can manage to setup a high volume tor node on Sparc \
hardware in the near future.


My test machine:
Sun Enterprise E450, 4x248 Mhz, 2GB RAM

root@e450# uname -a
SunOS e450 5.10 Generic_127127-11 sun4u sparc SUNW,Ultra-4

root@e450# pkginfo -l SPROcc
   PKGINST:  SPROcc
      NAME:  Sun Studio 12 C Compiler
  CATEGORY:  application
      ARCH:  sparc
   VERSION:  12.0,REV=2007.05.03

You must know that I am NO programmer. I dont understand any C code.


When building the tor executables I noticed some courious messages I would like to \
tell here, maybe this helps the developers improving the code.

First, I changed the configure script fast &amp; dirty to enable threads with Solaris:

if test x$enable_threads = x; then
   case $host in
    *-*-solaris* )
     # Don't try multithreading on solaris -- cpuworkers seem to lock.
     { echo "$as_me:$LINENO: You are running Solaris; Sometimes threading makes
cpu workers lock up here. Use it at your risk." &gt;&amp;5
echo "$as_me: You are running Solaris; Sometimes threading makes
cpu workers lock up here. Use it at your risk." &gt;}
     enable_threads="yes";;
    *)
     enable_threads="yes";;
   esac
fi

This seems to work, because configure notices:

checking pthread.h usability... yes
checking pthread.h presence... yes
checking for pthread.h... yes
checking for pthread_create... yes


Another message that always occurs with or without threads is this:
checking for net/pfvar.h... no
checking for linux/netfilter_ipv4.h... no
configure: Transparent proxy support enabled, but missing headers.
checking for struct timeval.tv_sec... yes

OK. configure succeeds.




Then doing make, I get some warning messages here:

source='compat.c' object='compat.o' libtool=no \
	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
	cc -DHAVE_CONFIG_H -I. -I../.. -I../../src/common  -I/usr/local/ssl/include -g -g -O \
-c compat.c "compat.c", line 373: warning: initializer does not fit or is out of \
range: 128 "compat.c", line 373: warning: initializer does not fit or is out of \
range: 129 "compat.c", line 373: warning: initializer does not fit or is out of \
                range: 130
...
... # lots of lines here !
...
"compat.c", line 398: warning: initializer does not fit or is out of range: 255
"compat.c", line 1162: warning: statement not reached
"compat.c", line 2177: warning: initializer does not fit or is out of range: -1


source='circuituse.c' object='circuituse.o' libtool=no \
	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
	cc -DHAVE_CONFIG_H -I. -I../.. -DSHARE_DATADIR="\"/usr/share\"" \
-DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
-I/usr/local/ssl/include   -g -g -O -c circuituse.c "circuitlist.c", line 679: \
warning: loop not entered at top



source='buffers.c' object='buffers.o' libtool=no \
	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
	cc -DHAVE_CONFIG_H -I. -I../.. -DSHARE_DATADIR="\"/usr/share\"" \
-DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
-I/usr/local/ssl/include   -g -g -O -c buffers.c "buffers.c", line 1456: warning: \
statement not reached



source='geoip.c' object='geoip.o' libtool=no \
	DEPDIR=.deps depmode=none /bin/bash ../../depcomp \
	cc -DHAVE_CONFIG_H -I. -I../..  -DSHARE_DATADIR="\"/usr/share\"" \
-DLOCALSTATEDIR="\"/usr/var\"" -DBINDIR="\"/usr/bin\"" -I../../src/common  \
-I/usr/local/ssl/include   -g -g -O -c geoip.c "geoip.c", line 296: warning: syntax \
error:  empty declaration "geoip.c", line 298: warning: syntax error:  empty \
declaration



make finishes successful (exit 0) an I got a binary:

root@e450# file src/or/tor
src/or/tor:     ELF 32-bit MSB executable SPARC32PLUS Version 1, V8+ Required, \
dynamically linked, not stripped

root@e450# ldd src/or/tor
        libz.so.1 =&gt;     	 /usr/lib/libz.so.1
        libevent-1.4.so.2 =&gt;     /usr/lib/libevent-1.4.so.2
        libssl.so.0.9.8 =&gt;       /usr/local/ssl/lib/libssl.so.0.9.8
        libcrypto.so.0.9.8 =&gt;    /usr/local/ssl/lib/libcrypto.so.0.9.8
        libnsl.so.1 =&gt;  	 /lib/libnsl.so.1
        libsocket.so.1 =&gt;        /lib/libsocket.so.1
        libc.so.1 =&gt;    	 /lib/libc.so.1
        librt.so.1 =&gt;    	 /lib/librt.so.1
        libresolv.so.2 =&gt;        /lib/libresolv.so.2
        libdl.so.1 =&gt;   	 /lib/libdl.so.1
        libgcc_s.so.1 =&gt;         /usr/local/lib/libgcc_s.so.1
        libmp.so.2 =&gt;   	 /lib/libmp.so.2
        libmd.so.1 =&gt;   	 /lib/libmd.so.1
        libscf.so.1 =&gt;  	 /lib/libscf.so.1
        libaio.so.1 =&gt;  	 /lib/libaio.so.1
        libdoor.so.1 =&gt; 	 /lib/libdoor.so.1
        libuutil.so.1 =&gt;         /lib/libuutil.so.1
        libgen.so.1 =&gt;  	 /lib/libgen.so.1
        libm.so.2 =&gt;    	 /lib/libm.so.2
        /platform/SUNW,Ultra-4/lib/libc_psr.so.1
        /platform/SUNW,Ultra-4/lib/libmd_psr.so.1

Please notice libgcc_s.so.1 Is this OK? I use Sun's CC, so is this wrong or right to \
have linked the binary against a gcc library? The executable works all day long, I \
got no errors.


Kind Regards

Thomas


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090902063527</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-09-02 06:35:27-0400</timestampReceived><subject>Re: Proposal 167: Vote on network parameters in consensus</subject><body>

On Tue, Aug 25, 2009 at 11:37:09AM +0200, Karsten Loesing wrote:
&gt; &gt; 2.2. What about non-integers?
&gt; &gt; 
&gt; &gt;   I'm not sure how we would do median on non-integer values. Further,
&gt; &gt;   I don't have any non-integer values in mind yet. So I say we cross
&gt; &gt;   that bridge when we get to it.
&gt; 
&gt; Why are medians on non-integer values a problem? If there's an odd
&gt; number of non-integer values, we pick the middle one. Otherwise, we
&gt; could calculate the mean of the two middle values. (This could also
&gt; apply to integer values, instead of deciding in favor of the lower of
&gt; the two middle values.)

Ah. By non-integer I had meant "arbitrary string". After all, I didn't
want to predict all the comparator functions we would want on our
arbitrary strings.

But you're right that we could allow floats. That's fine by me.

&gt; Also, we might want to add a requirement that every Tor using these
&gt; values should adapt to changes gently. Taking the maximum number of
&gt; cells in circuit queues as an example: If we change that number from
&gt; 1000 to 101 on half of the directories, and one directory has uptime
&gt; problems, the consensus value might fluctuate between 101 and 1000 (or
&gt; 550 if we used the mean of the two middle values). In that case, we
&gt; probably don't want relays to change their parameters every hour. Maybe
&gt; relays should change their parameters only once in, say, 12 hours, and
&gt; ignore further updates during that time.

Maybe. I think that's quite a bit of work to get right, and will still
be bothering us with edge cases for quite a while. I'd rather take the
simpler approach on the coding side, and focus on ensuring that the
authorities don't get into a situation like that.

--Roger

</body></email><email><emailId>20090914194505</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-09-14 19:45:05-0400</timestampReceived><subject>Re: Proposal 167: Vote on network parameters in consensus</subject><body>

On Tue, Aug 25, 2009 at 12:32:06AM -0400, Roger Dingledine wrote:
&gt; Filename: 167-params-in-consensus.txt
&gt; Title: Vote on network parameters in consensus
&gt; Author: Roger Dingledine
&gt; Created: 18-Aug-2009
&gt; Status: Open
&gt; Target: 0.2.2
&gt; 
&gt; 0. History
&gt; 
&gt; 
&gt; 1. Overview
&gt; 
&gt;   Several of our new performance plans involve guessing how to tune
&gt;   clients and relays, yet we won't be able to learn whether we guessed
&gt;   the right tuning parameters until many people have upgraded. Instead,
&gt;   we should have directory authorities vote on the parameters, and teach
&gt;   Tors to read the currently recommended values out of the consensus.
&gt; 
&gt; 2. Design
&gt; 
&gt;   V3 votes should include a new "params" line after the known-flags
&gt;   line. It contains key=value pairs, where value is an integer.

Let's say that all the keys need to match the Keyword pattern in
dir-spec.txt.
 
&gt;   Consensus documents that are generated with a sufficiently new consensus
&gt;   method (7?) then include a params line that includes every key listed
&gt;   in any vote,

We need to specify what order the parameters appear in the consensus,
and what position in the consensus the parameters line appears.  Let's
say that the keys are sorted lexically in the output, and that the
line appears directly after "known-flags".

&gt; and the median value for that key (in case of ties,
&gt;   we use the median closer to zero).

Is +1 or -1 closer to zero? ;)

For the sake of our sanity, why not have it be "the lower median"?
That's easiest to implement.

Note that the design here allows any authority to introduce an
arbitrary number of parameters.

yrs,
-- 
Nick
</body></email><email><emailId>20090914201538</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-09-14 20:15:38-0400</timestampReceived><subject>Re: Proposal 167: Vote on network parameters in consensus</subject><body>

On Mon, Sep 14, 2009 at 03:45:05PM -0400, Nick Mathewson wrote:
&gt; &gt;   V3 votes should include a new "params" line after the known-flags
&gt; &gt;   line. It contains key=value pairs, where value is an integer.
&gt; 
&gt; Let's say that all the keys need to match the Keyword pattern in
&gt; dir-spec.txt.

Ok.

&gt; &gt;   Consensus documents that are generated with a sufficiently new consensus
&gt; &gt;   method (7?) then include a params line that includes every key listed
&gt; &gt;   in any vote,
&gt; 
&gt; We need to specify what order the parameters appear in the consensus,
&gt; and what position in the consensus the parameters line appears.  Let's
&gt; say that the keys are sorted lexically in the output,

Ok.

&gt; and that the
&gt; line appears directly after "known-flags".

Yep, that agrees with my original choice (above).

&gt; &gt; and the median value for that key (in case of ties,
&gt; &gt;   we use the median closer to zero).
&gt; 
&gt; Is +1 or -1 closer to zero? ;)
&gt; 
&gt; For the sake of our sanity, why not have it be "the lower median"?
&gt; That's easiest to implement.

Ok.

&gt; Note that the design here allows any authority to introduce an
&gt; arbitrary number of parameters.

We could do what we did with "Measured=" on the w line, which is "it
doesn't count unless at least three authorities vote about it".

--Roger

</body></email><email><emailId>20090615072757</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-15 07:27:57-0400</timestampReceived><subject>Re: Proposal 163: Detecting whether a connection comes from a client</subject><body>

On Fri, May 22, 2009 at 02:59:53AM -0400, Nick Mathewson wrote:
&gt;    There are at least two reasons for which Tor servers want to tell
&gt;    which connections come from clients and which come from other
&gt;    servers:
&gt; 
&gt;      1) Some exits, proposal 152 notwithstanding, want to disallow
&gt;         their use as single-hop proxies.
&gt;      2) Some performance-related proposals involve prioritizing
&gt;         traffic from relays, or limiting traffic per client (but not
&gt;         per relay).

We should think about these two approaches separately.

In particular, I think #2 is a distraction. In performance.pdf I proposed
that one option to improve Tor's speed is to rate limit clients (say,
10KB bandwidthrate and 500KB bandwidthburst). Nick wants to do this
rate limiting on relays, because it would be too easy for a client to
cheat and remove the self-limiting. But can't a bittorrent user cheat
the relay limiting by saying "numentryguards 100"? What we'd really want
(if we decide it's a good idea in the first place) is to limit the total
traffic the client can induce.

So I think if we want to do this proposal, it should be because of
reason #1 above. That also helps us clarify our threat model and security
requirements.

&gt;    When a node or circuit tries to use server privileges, if it is
&gt;    "definitely a client" as per above, we can refuse it immediately.
&gt; 
&gt;    If it's "probably a server" as per above, we can accept it.

So far so good.

&gt;    Otherwise, we have either a client, or a server that is neither
&gt;    listed in any consensus or used by any other clients -- in other
&gt;    words, a new or private server.
&gt; 
&gt;    For these servers, we should attempt to build one or more test
&gt;    circuits through them.  If enough of the circuits succeed, the
&gt;    node is a real relay.  If not, it is probably a client.
&gt; 
&gt;    While we are waiting for the test circuits to succeed, we should
&gt;    allow a short grace period in which server privileges are
&gt;    permitted.  When a test is done, we should remember its outcome
&gt;    for a while, so we don't need to do it again.

I think Sebastian had an important point here: we're not doing very
well at the arms race if the attacker just needs to pass the test once
or twice per time period. In fact, if our goal is
   To make grabbing relay privileges at least as difficult as just
   running a relay.
then what is the hard part of running a relay? One answer is "setting
up port forwarding". Another answer is "transiting lots of bandwidth
and potentially getting your ISP upset at you". I would argue that the
arms race you propose focuses on the former, and to stay ahead of the
game it ought to focus on the latter.

&gt; [... a variety of complex and fragile steps in the arms race ...]

Here's a counterproposal: if it's listed in the consensus, then it's
a relay, and if it's not, then it isn't.

This could have some false negatives. In particular:

1) Won't we refuse to exit for relays that just joined the consensus? I
think these are fine actually: assuming exit relays fetch the consensus
at the accelerated "directory mirror" rate, then they should always hear
about new relays before ordinary clients do.

2) What about relays that are dropped from the most recent consensus
(say because they failed recent reachability tests), yet they're still
up and clients are still using them? I guess that argues for remembering
(summaries of) the last few consensuses so you can guess better. Yuck.

3) What about exit relays that just started up, and don't magically know
the past few consensuses? First, it will be a few cycles before clients
learn about the exit relay, so they'll rarely be totally without history.
Second, perhaps those are acceptable degradations -- as long as the begin
cell is refused with one of the reasons in edge_reason_is_retriable(),
then the client will try somewhere else. If the reason is EXITPOLICY,
the client will avoid that exit until it gets a new descriptor; I'm not
sure if that means we should make use of that or not.

4) What about the glorious future when Tor has scaled and it's harder
for every exit to know all consensuses? One answer is that we can tackle
this problem then. Another answer is that the alternative arms races
start to suck then too, because too many people are in the "we have to
do active checking" edge case.

While I'm at it, here's another design: the authorities sign a little
token that a relay can use when connecting to another relay to prove
its relayness. No fresh token, you're not a relay. A problem with this
design though is that the incentives aren't lined up right: why does
the middle hop care whether he gets a token? He never sees any harm to
himself by not having one. I guess we could just make it part of the
protocol, and he'll never even need to know it's happening. Is this a
direction worth exploring?

I guess another option is to stop trying to complexify things and accept
the attack. My main reasoning against letting people do path selection
in a non-standard way was because our load balancing algorithm couldn't
handle it. It looks like mikeperry's proposal 161 will do much better
in this regard. Maybe that's good enough?

--Roger

</body></email><email><emailId>20090615181851</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-06-15 18:18:51-0400</timestampReceived><subject>Re: Proposal 158 revised: Microdescriptors again</subject><body>

[I've snipped the points where I agree with you and am just merging
your changes into the proposal.]

On Sat, Jun 13, 2009 at 03:23:41AM -0400, Roger Dingledine wrote:
&gt; On Sat, May 16, 2009 at 12:46:40AM -0400, Nick Mathewson wrote:
 [...]
&gt; &gt; 3.1.2. Computing consensus for microdescriptor-elements and "m" lines
&gt; &gt; 
&gt; &gt;   When we generating a consensus, we use whichever m line
&gt; &gt;   unambiguously corresponds to the descriptor digest that will be
&gt; &gt;   included in the consensus.  (If there are multiple m lines for that
&gt; &gt;   descriptor digest, we use whichever is most common.  If they are
&gt; &gt;   equally common, we break ties in the favor of the lexically
&gt; &gt;   earliest.  Either way, we should log a warning: That's likely a
&gt; &gt;   bug.)
&gt; 
&gt; I don't understand the above. The microdescriptor is a straight
&gt; function of a) the consensus method, and b) whichever relay descriptor
&gt; is a winner for this vote. So that means the "m" line we pick for the
&gt; consensus has to be the microdescriptor digest from whichever votes a)
&gt; voted for the winner, and b) offered the consensus method that we chose
&gt; to use for constructing this consensus. If any such votes differ, we'll
&gt; have other problems, like disagreeing authorities serving disagreeing
&gt; microdescriptors. I guess that's what you're getting at above?

Right.  If two authorities cannot agree on which microdescriptor is
produces by transforming a descriptor with digest X with consensus
method Y, then (at least) one of them is broken.  But we need to keep
going in this case, since we don't want a single broken authority to
be able to prevent us from forming a consensus.  So we specify that
ties are broken by going with the most common digest, followed by the
lexically earliest.

 [...]
&gt; &gt;   All the microdescriptors from the current consensus should also be
&gt; &gt;   available at:
&gt; &gt;     http://&lt;hostname&gt;/tor/micro/all.z
&gt; 
&gt; How will these two URLs interact with future flavors? If a later flavor
&gt; uses a different hash function, do we still offer everything under
&gt; /tor/micro/d/&lt;D&gt;, even though different clients are verifying results
&gt; with different hash functions?

According to proposal 162, flavors are supposed to apply to
consensuses.  There is no current design for multiple parallel flavors
of microdescriptors.  So I guess we need to figure this out.

Thinking aloud.... Let's consider two cases:

    A) A new flavor supports a new hash algorithm, and refers to
       microdescriptors by this hash.  Clients want to download
       microdescriptors by this hash, but they are the same as the
       other microdescriptors.

    B) A new flavor has its own notion of microdescriptors, and these
       microdescriptors are not the same as those generated with some
       other flavor of consensus.

I think that A and B want different solutions.  For A, caches should
download microdescriptors by whichever hash algorithm they like best,
and serve them by all the hash algorithms they know.  Because caches
can only use flavors they understand, I think that we can safely defer
specifying how they handle this case until there _are_ two such
flavors out there.

Right now, we have no notion or design for B at all.  My intuition
says that we should try to avoid B, and if it happens, we have created
something that isn't a microdescriptor.

Or we could try to do a bit like you suggest, so that there is
     /tor/micro/MF/d-sha256/&lt;D1&gt;
where MF is a "microdescriptor flavor" such that multiple flavors of
consensus can share a single microdescriptor flavor.

 [...]
&gt; If we do change our hash function, caches that don't recognize the flavor
&gt; won't be able to verify that the microdescriptor hashes are correct. And
&gt; since they won't know whether we've changed the hash function in a
&gt; flavor they don't recognize, does that mean that caches should never
&gt; check hashes on flavors they don't recognize?

IMO if you have no way to check a hash, you should not be serving
documents indexed only by that hash.  So if a cache doesn't support
AHS, it shouldn't ever serve /tor/micro/MF/d-ahs/&lt;D1&gt; .  Anything else
seems crazy to me.

Another issue with microdescriptors: unlike router descriptors, there
isn't a trivial way to determine microdescriptor boundaries when you
get a lot of them concatenated.  I suppose we could introduce an
element that always comes first, or say that they're separated by
blank lines, or something like that.

yrs,
-- 
Nick
</body></email><email><emailId>20090615205433</emailId><senderName>Marcus Griep</senderName><senderEmail>tormaster@xpdm.us</senderEmail><timestampReceived>2009-06-15 20:54:33-0400</timestampReceived><subject>Re: Proposal 162: Publish the consensus in multiple flavors</subject><body>


On Mon, 2009-06-15 at 14:19 -0400, Nick Mathewson wrote:
&gt; On Fri, Jun 12, 2009 at 11:10:09PM -0400, Roger Dingledine wrote:
&gt; &gt; On Fri, May 15, 2009 at 01:05:41PM -0400, Nick Mathewson wrote:
&gt; &gt; &gt;    Our past approach to cases like this has been to shovel all of
&gt; &gt; &gt;    the data into the consensus document.  But this is rather poor
&gt; &gt; &gt;    for bandwidth.  Adding a single SHA256 hash to a consensus for
&gt; &gt; &gt;    each router increases the compressed consensus size by 47%.  In
&gt; &gt; &gt;    comparison, replacing a single SHA1 hash with a SHA256 hash for
&gt; &gt; &gt;    each listed router increases the consensus size by only 18%.
&gt; &gt; 
&gt; &gt; SHA256's are still huge. It's a real shame there aren't accepted hash
&gt; &gt; functions that use only 20 bytes.
&gt; 
&gt; I think we're going to have to live with this, unless we want to be
&gt; crypto-weirdos and say that our hash function is the first 20 bytes of
&gt; SHA256 or something else horribly under-analyzed like that.

One option is to use SHA224, SHA256's shorter cousin. It would lower the
size from 32 bytes to 28 bytes and is a part of the FIPS standard.
-- 
Marcus Griep
GPG Key ID: 0x070E3F2D
������
https://torproj.xpdm.us
������������ ����.���� �, 3 �

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090616052341</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2009-06-16 05:23:41-0400</timestampReceived><subject>Re: Proposal: MapAddress wilcards [*]</subject><body>

&gt; If somebody submitted a clean short patch for this, we'd probably
&gt; put it in.

For simplicity, I'd definitely go with making the '*' match any and
all levels to the left of its placement, inclusive. *.google.com
would match a.google.com, b.a.google.com, z.&lt;...&gt;.google.com. Noted
because combining my #2 and #3 would be easier. #1 of course would
match the google.com 'host' and need to remain that way anyways.

And because your 'tor controller' paragraph indicates an extant API
for the more exotic... I need to look at those functions you mention :)

Though I doubt users would need more than the catchall patch above.

The '**' was only there if counting levels, as in #2, was thought
to be useful. Probably not.

One last thing I thought of for the future was point to multipoint
mappings:
 *.google.com=*.google.com.&lt;exit1&gt;.exit
 *.google.com=*.google.com.&lt;exit2&gt;.exit
 ...

Would provide a set of exits to try to use for whatever matches the
left side. And it quite possibly would not 'do the right thing'
from a user point of view. Perhaps the first exit that is up gets
the traffic, but if it goes down, don't switch because that would
look like 'traveling' which would be bad. Unless the user could be
notified and switch it with their logins. So I left it out earlier.

Sort of more specific than 'only use &lt;country&gt; exits for my surfing',
'use these exits for this site'.



&gt; TrackHostExits &lt;host/dom list&gt;

Man page indicates that this does: for each item in the list, track
that item independently to whatever exit Tor picked. Ok, so, new...

TrackHostExits &lt;host/dom list&gt; [rulenum]
TrackHostExitsTogether &lt;0|1&gt; [rulenum]
0 - each list item tracks its exit independantly, the current default
1 - all list items follow the same, autochosen, exit

The [rulenum] allows multiple statements to be configured. For when
the Together option = 1, and you want independant threads tracking
each list, to possibly different autochosen exits. Oops, more
simply...

TrackHostsExitTogether &lt;host/dom list 1&gt;
TrackHostsExitTogether &lt;host/dom list 2&gt;

And ok, so, new...

TrackHostsExit &lt;exit&gt; &lt;host/dom list&gt;

Track and tie the entire list to an exit. Probably not as dynamic
[control interface] or capable as the general MapAddress
proposal/interface, but serves the same purpose as it. Perhaps as
a simpler rc config interface.



&gt; I don't imagine that ordinary users would ever touch this sort of
&gt; feature, because it requires them to:

&gt; a) know about the .exit notation

It took me a fair bit of time to find and figure out MapAddress.
Now that I know it, it is invaluable. I was asleep and left out
some important use cases, likely much more common than blocking...

Sites that pick language and featuresets depending on their idea
of your geolocation. Sites that refuse to create accounts, or delete
preexisting valid accounts, if the user 'travels'. Ebay is one such
site that dislikes travelers.

Placing these gotcha cases in the torfaq, etc, would help users be
aware of them and introduce the .exit workaround... as in my #1,
and hopefully in this new feature.

I put this to the or-talk for the users there in case they run into
this.

&gt; b) know how to find a suitable exit relay.

Users could pick a relay by country from perhaps one of the torstatus
pages and then say:

MapAddress *.google.com=*.google.com.&lt;exit&gt;.exit

I think there was discussion around letting operators denote their
country in their descriptors. So vidalia and the like may one day
filter and display those, with or without regard to the geoip db.
Had something to do with selecting countries, dunno.
</body></email><email><emailId>20090606002456</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2009-06-06 00:24:56-0400</timestampReceived><subject>Re: Proposal 163: Detecting whether a connection comes from a client</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Next part of the proposal feedback message flood:

On May 22, 2009, at 8:59 AM, Nick Mathewson wrote:
&gt;   For these servers, we should attempt to build one or more test
&gt;   circuits through them.  If enough of the circuits succeed, the
&gt;   node is a real relay.  If not, it is probably a client.
&gt;
&gt;   While we are waiting for the test circuits to succeed, we should
&gt;   allow a short grace period in which server privileges are
&gt;   permitted.  When a test is done, we should remember its outcome
&gt;   for a while, so we don't need to do it again.
&gt;
&gt; [snip]

&gt;   If we can build circuits starting at a suspect node, but we don't
&gt;   have enough information to try extending circuits elsewhere
&gt;   through the node, should we conclude that the node is
&gt;   "server-like" or not?

imo, that's not a server.

Also:
I think we should wait for servers to appear in the consensus during  
the first part of the 48 hours "we accept you as a relay" period  
(after we could extend circuits to the node). If they don't appear in  
that period, treat them as clients for the rest of the grace period.  
Drawback: Bridges won't be listed in the consensus, yet their  
bandwidth consumption might be legitimate since they can be serving  
many clients. Not sure where to draw the line here.
If we don't do something like that, someone can be act like a relay  
for 10 minutes and then stop being one, after two days, start the game  
again, etc.


Sebastian
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAkopt1gACgkQCADWu989zuYoZgCglk2XZqF22eT15b7jCmOEPFNO
lpEAn32/OG4KLUiNeiyZa6TKFb7BfKnM
=bKf4
-----END PGP SIGNATURE-----

</body></email><email><emailId>20090606003309</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2009-06-06 00:33:09-0400</timestampReceived><subject>Re: Proposal 158 revised: Microdescriptors again</subject><body>


On May 16, 2009, at 6:46 AM, Nick Mathewson wrote:

&gt; As long promised, I've revised Roger's January proposal on
&gt; microdescriptors.  Here's the latest version.  It incorporates (I
&gt; hope) our discussions on the topic, plus suggestions based on proposal
&gt; 162.
&gt; [snip]

&gt;  (We use base64 for size and for consistency with the consensus
&gt;  format. We use -s instead of +s to separate these items, since

this sentence's end is not
what is it trying to

I thought about issues when we add/remove more than one authority  
before all operators had a chance to upgrade or upgrade again (in case  
of removal), but couldn't come up with an actually bad situation. But  
this led to the realization that the work flow described just talks  
about one authority getting added/removed at a time, I think the  
situation with more than one change can quickly get complex (and it's  
easy to imagine that with 15 authorities, some operators will be on  
vacation for a month, for example). The proposal could maybe be  
clearer on how those cases should be handled by the operators.


Sebastian

</body></email><email><emailId>20090606001703</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2009-06-06 00:17:03-0400</timestampReceived><subject>Re: Proposal 162: Publish the consensus in multiple flavors</subject><body>

I like the proposal, it's a big step towards getting new features into  
the users' hands faster. I have just one question that popped up:

On May 15, 2009, at 7:05 PM, Nick Mathewson wrote:

&gt;    Each Document line describes the length of the signed portion of
&gt;    a consensus (the signatures themselves are not included), along
&gt;    with one or more digests of that signed portion.  Digests are
&gt;    given in hex.  The algorithm "sha256" MUST be included; others
&gt;    are allowed.
&gt;
&gt;    The algname part of a signature describes what algorithm was
&gt;    used to hash the identity and signing keys, and to compute the
&gt;    signature.  The algorithm "sha256" MUST be recognized;
&gt;    signatures with unrecognized algorithms MUST be ignored.
&gt;    (See below).
&gt;
&gt; [snip]

&gt;    4.1. The "sha256" signature format.
&gt;
&gt;    The 'SHA256' signature format for directory objects is defined as
&gt;    the RSA signature of the OAEP+-padded SHA256 digest of the SHA256
&gt;    digest of the the item to be signed.  When checking signatures,
&gt;    the signature MUST be treated as valid if the signed material
&gt;    begins with SHA256(SHA256(document)); this allows us to add other
&gt;    data later.

Somehow, this sections seems to create a dependency on sha256, as I  
don't see how we could quickly migrate away from that, if we needed  
to. Maybe I'm understanding this wrong, but I have the impression that  
clients could assume that if the sha256 signature is correct, they  
don't need to verify any other signatures that they recognize. Imo,  
they should verify those, as well, and only treat the document as  
valid if all signatures match?


Sebastian
</body></email><email><emailId>20090612193627</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2009-06-12 19:36:27-0400</timestampReceived><subject>Proposal: MapAddress wilcards [*]</subject><body>

Probably should have gone to or-dev, not or-talk...

Many sites these days have multiple hosts in their domains. These
sites may have various administrative, logging or restrictive
policies. The same goes for the path to them if the user is unfortunate
enough to reside in strange lands.

As pure example, note myspace. They have myspace.com, full of
subdomains and hosts. There is also myspacecdn.com and a couple
others. They all work together to deliver the full content, images,
etc. This is common for load balancing, service segmentation and
so on.

Problem:
(A) Tor makes the use of MapAddress with sites that use multiple
hosts like these difficult and insufficient because:

1 - Each host requires another MapAddress statement.
2 - It is impossible to know all the hosts the site uses beforehand.
3 - The sites commonly change hosts on a whim.

And missing the mapping due to this could affect either the user
or the site in unintended ways. Mapping should be a bit smarter and
able to do the right thing. Users commonly desire to 'send all my
traffic for site x via exit y and make it just work'.

Solution:
(B) So the following feature is proposed. Allow wildcards in the
MapAddress function such that:

1 - MapAddress google.com=google.com.&lt;exit&gt;.exit
 Is now, and should remain, single host specific as usual.

2 - MapAddress *.google.com=*.google.com.&lt;exit&gt;.exit
 Matches any third level domain such as www.google.com, but obviously
 not google.com itself, as that is handled by (1) above. The name
 must have three levels to match.

3 - MapAddress **.google.com=**.google.com.&lt;exit&gt;.exit
 Matches any third or deeper level domain such as a.b.c.d.google.com.
 This is a sensible hack. It is meant to allow future expansion of
 MapAddress to use some form of regex. Since '**' isn't really used
 in regexes, it is a useful glob for this purpose of allowing
 everything to match... which the user would _really_ want to have
 happen easily, without resorting to the obvious further nonsense
 in (4), which would be subject to the same problems in (A) above.

4 - MapAddress *.*.google.com=*.*.google.com.&lt;exit&gt;.exit
 Matches any third and fourth domain. Only four level names would
 match. This is a NON-proposal.

5 - *google.com
 This is also a NON-proposal. It is too far down the path of some
 form of regex for the quick fix this proposal is meant to be. And
 it would obviously match all sorts of undesirables. The dots are
 important in DNS.

Note that having globs on the right side of the '=' doesn't make
sense from a routing point of view, but it's not supposed to. It
is done so that scripts can continue to keep track and do things
like:

/bin/sh
 # add map
 dst=$src.$exit.exit
 printf "authenticate \"foo\"\r\nmapaddress $src=$dst\r\nquit\r\n" |
 # remove map
 dst=$src
 printf "authenticate \"foo\"\r\nmapaddress $src=$dst\r\nquit\r\n" |

And of course the below command should list the mappings as usual.
Both the static mapping that was entered, and the dynamic ones that
result from it...

getinfo address-mappings/all

google.com google.com.&lt;exit&gt;.exit NEVER
**.google.com **.google.com.&lt;exit&gt;.exit NEVER
google.com.&lt;exit&gt;.exit &lt;ip.ad.dr.ess&gt;.&lt;exit&gt;.exit "2009-06-05 18:01:20"
mail.google.com.&lt;exit&gt;.exit &lt;ip.ad.dr.ess&gt;.&lt;exit&gt;.exit "2009-06-05 18:01:22"
a.b.google.com.&lt;exit&gt;.exit &lt;ip.ad.dr.ess&gt;.&lt;exit&gt;.exit "2009-06-05 18:01:24"

At this time, it is unimportant which rule the dynamic entry resulted
from as that is not denoted in the current versions of Tor. A simple
numeric tag in the first column of every rule would suffice for
that in the future.
</body></email><email><emailId>20090606002645</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2009-06-06 00:26:45-0400</timestampReceived><subject>Re: Proposal 164: Reporting the status of server votes</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On May 22, 2009, at 9:00 AM, Nick Mathewson wrote:

&gt; Filename: 164-reporting-server-status.txt

I like the proposal. I've often needed that info to help someone, and  
since I don't operate an authority, I was stuck waiting for someone  
who does.

Thanks!
Sebastian
-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAkopt8UACgkQCADWu989zub3ZQCfQGFv5R+kjj7Iaa/+I4VSLpz8
E04AoOQwqmPRydlCyKjiXamd4JZ7AcZs
=yuEe
-----END PGP SIGNATURE-----

</body></email><email><emailId>20090614064005</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-14 06:40:05-0400</timestampReceived><subject>Re: Proposal 164: Reporting the status of server votes</subject><body>

On Fri, May 22, 2009 at 03:00:42AM -0400, Nick Mathewson wrote:
&gt;        - Look through your log for reports of what the authority said
&gt;          when you tried to upload.
&gt; 
&gt;        - Look at the consensus; see if you're listed.
&gt; 
&gt;        - Wait a while, see if things get better.
&gt; 
&gt;        - Download the votes from all the authorities, and see how they
&gt;          voted.  Try to figure out why.

Mere mortals can't do this step either. It involves fetching a secret
only-mentioned-in-the-spec URL ("/tor/status-vote/current/authority")
from a set of secret only-mentioned-in-the-code IP addresses.

&gt;        - If you think they'll listen to you, ask some authority
&gt;          operators to look you up in their mtbf files and logs to see
&gt;          why they voted as they did.

In practice, it's sufficient to ask an authority operator to go look
through the "v3-status-votes" file in their datadir that gets written
every voting period, and see what the recent votes have said about
your relay.

&gt;    This is far too hard.
&gt; 
&gt; Solution:
&gt; 
&gt;    We should add a new vote-like information-only document that
&gt;    authorities serve on request.  Call it a "vote info".  It is
&gt;    generated at the same time as a vote, but used only for
&gt;    determining why a server voted as it did.  It is served from
&gt;    /tor/status-vote-info/current/authority[.z]
&gt; 
&gt;    It differs from a vote in that:
&gt; 
&gt;    * Its vote-status field is 'vote-info'.
&gt; 
&gt;    * It includes routers that the authority would not include
&gt;      in its vote.
&gt; 
&gt;      For these, it includes an "omitted" line with an English
&gt;      message explaining why they were omitted.
&gt; 
&gt;    * For each router, it includes a line describing its WFU and
&gt;      MTBF.  The format is:
&gt; 
&gt;        "stability &lt;mtbf&gt; up-since='date'"
&gt;        "uptime &lt;wfu&gt; down-since='date'"
&gt; 
&gt;    * It describes the WFU and MTBF thresholds it requires to
&gt;      vote for a given router in various roles in the header.
&gt;      The format is:
&gt; 
&gt;        "flag-requirement &lt;flag-name&gt; &lt;field&gt; &lt;op&gt; &lt;value&gt;"
&gt; 
&gt;      e.g.
&gt; 
&gt;        "flag-requirement Guard uptime &gt; 80"
&gt; 
&gt;    * It includes info on routers all of whose descriptors that
&gt;      were uploaded but rejected over the past few hours.  The
&gt;      "r" lines for these are the same as for regular routers.
&gt;      The other lines are omitted for these routers, and are
&gt;      replaced with a single "rejected" line, explaining (in
&gt;      English) why the router was rejected.

How does the 'omitted' line differ from the 'rejected' line?

Also, this reminds me of a wishlist item that Robert Hogan had a while
back. He wants to know how many Tors are configured to be relays, but
fail their self-reachability checks, so don't even try to publish. If
it's hundreds or thousands, that means we should work harder to help
users learn that they're not helping out in the way they think they are.

&gt;    A status site (like Torweather or Torstatus or another
&gt;    tool) can poll these files when they are generated, collate
&gt;    the data, and make it available to server operators.

Sounds like a fine plan. I agree that this would be a helpful feature
to have. But it's also not upgrade-path-critical in the way that a lot
of the other pending proposals are -- we could do it in 0.2.2 or 0.2.3
or later and nothing else would have to change to accommodate.

Also, it can be done pretty well by a) teaching users to read their logs,
which they're already not so bad at if they're the sort of users who know
how to realize that this vote-info stuff exists, and b) teaching sites
like torstatus to fetch the secret URLs from the secret IP addresses and
crunch the vote data that's already available. This proposal only really
adds help for folks who can't find their logs, and folks who want to
know why they're not marked Stable (answer: "you're not stable enough;
oh, and bug 969").

So: if you are itching to do it (or somebody else is), by all means go
for it. But if it seems like a big pile of hassle (and some of the ideas
above are pretty invasive and tricky to do efficiently), feel free to
put it off indefinitely.

Here's an alternative proposal: I set up a cron job on moria to copy
moria1's v3-status-votes file to someplace web-accessible, and then we
tell the torstatus folks that they can fetch it and parse it if they
want to?

(It's my understanding that torstatus isn't seeing much development these
days, which might be bad for all of these plans which end with "and then
those nice people will fetch it and make it user-understandable".)

--Roger

</body></email><email><emailId>20090615211423</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-15 21:14:23-0400</timestampReceived><subject>Re: Proposal: MapAddress wilcards [*]</subject><body>

On Fri, Jun 12, 2009 at 03:36:27PM -0400, grarpamp wrote:
&gt; (B) So the following feature is proposed. Allow wildcards in the
&gt; MapAddress function such that:
&gt; 
&gt; 1 - MapAddress google.com=google.com.&lt;exit&gt;.exit
&gt;  Is now, and should remain, single host specific as usual.
&gt; 
&gt; 2 - MapAddress *.google.com=*.google.com.&lt;exit&gt;.exit
&gt;  Matches any third level domain such as www.google.com, but obviously
&gt;  not google.com itself, as that is handled by (1) above. The name
&gt;  must have three levels to match.

If somebody submitted a clean short patch for this, we'd probably put
it in.

&gt; 3 - MapAddress **.google.com=**.google.com.&lt;exit&gt;.exit
&gt; 4 - MapAddress *.*.google.com=*.*.google.com.&lt;exit&gt;.exit
&gt; 5 - *google.com

It seems that what you really want is a Tor controller. It could
setconf __LeaveStreamsUnattached, listen for new stream events,
redirectstream them however it likes, and then attachstream them to
circuitid 0, meaning Tor will take care of it. Then you can do full-scale
regexps in your python or perl or whatever. If you want to go nuts, you
could even consider making it a plugin for the nascent Vidalia plugin
architecture. :)

I don't imagine that ordinary users would ever touch this sort of feature,
because it requires them to a) know about the .exit notation and b)
know how to find a suitable exit relay. What they might touch, though,
is some sort of hack on TrackHostExits that lets you say "whichever exit
you picked for .google.com, please use that same exit for .gmaps.com."

I'm not sure how to make that user-friendly or user-accessible though.

--Roger


</body></email><email><emailId>20090504231210</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-05-04 23:12:10-0400</timestampReceived><subject>Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

Filename: 160-bandwidth-offset.txt
Title: Authorities vote for bandwidth offsets in consensus
Version: $Revision$
Last-Modified: $Date$
Author: Roger Dingledine
Created: 4-May-2009
Status: Open
Target: 0.2.2.x

1. Motivation

  As part of proposal 141, we moved the bandwidth value for each relay
  into the consensus. Now clients can know how they should load balance
  even before they've fetched the corresponding relay descriptors.

  Putting the bandwidth in the consensus also lets the directory
  authorities choose more accurate numbers to advertise, if we come up
  with a better algorithm for deciding weightings.

  Our original plan was to teach directory authorities how to measure
  bandwidth themselves; then every authority would vote for the bandwidth
  it prefers, and we'd take the median of votes as usual.

  The problem comes when we have 7 authorities, and only a few of them
  have smarter bandwidth allocation algorithms. So long as the majority
  of them are voting for the number in the relay descriptor, the minority
  that have better numbers will be ignored.

2. Options

  One fix would be to demand that every authority also run the
  new bandwidth measurement algorithms: in that case, part of the
  responsibility of being an authority operator is that you need to run
  this code too. But in practice we can't really require all current
  authority operators to do that; and if we want to expand the set of
  authority operators even further, it will become even more impractical.
  Also, bandwidth testing adds load to the network, so we don't really
  want to require that the number of concurrent bandwidth tests match
  the number of authorities we have.

  The better fix is to allow certain authorities to specify that they are
  voting on bandwidth "offsets": how much they think the weight should
  be changed for the relay in question. We should put the offset vote in
  the stanza for the relay in question, so a given authority can choose
  which relays to express preferences for and which not.

3. Security implications

  If only some authorities choose to vote on an offset, then a majority of
  those voting authorities can arbitrarily change the bandwidth weighting
  for the relay. At the extreme, if there's only one offset-voting
  authority, then that authority can dictate which relays clients will
  find attractive.

  This problem isn't entirely new: we already have the worry wrt
  the subset of authorities that vote for BadExit.

  To make it not so bad, we should deploy at least three offset-voting
  authorities.

  Also, authorities that know how to vote for offsets should vote for
  an offset of zero for new nodes, rather than choosing not to vote on
  any offset in those cases.

4. Design

  First, we need a new consensus method to support this new calculation.

  Now v3 votes can have a new weight on the "w" line:
    "Bandwidth_Offset=" INT.
  Once we're using the new consensus method, the new way to compute the
  Bandwidth weight is by taking the old vote (explained in proposal 141:
  median, then choose the lower number in the case of ties), and adding
  or subtracting the median offset (using the offset closer to 0 in the
  case of ties, and with a sum of 0 if the sum is negative).

  Then the actual consensus looks just the same as it did before,
  so clients never have to know that this additional calculation is
  happening.

</body></email><email><emailId>20090626152707</emailId><senderName>Prithula Dhungel</senderName><senderEmail>prithula.dhungel@gmail.com</senderEmail><timestampReceived>2009-06-26 15:27:07-0400</timestampReceived><subject>Single hop connections?</subject><body>

Hi all,
   I have just started looking at the Tor code. I wanted to know if it will
be at all possible to have a single hop path and communicate over it (apart
from the single hop path that can be made for directory server interaction).
For the non-directory server intended circuits, I see that the Tor code
specifically checks that the circuit is not single hop.

Would it be at all possible to make a one - hop circuit (which I guess is
possible by specifying the nickname, digest of the router) and then use it
for a normal purpose?

Any guidance will be highly appreciated.

Prithu

[Attachment #3 (text/html)]

Hi all,&lt;br&gt;=A0=A0 I have just started looking at the Tor code. I wanted to =
know if it will be at all possible to have a single hop path and communicat=
e over it (apart from the single hop path that can be made for directory se=
rver interaction). For the non-directory server intended circuits, I see th=
at the Tor code specifically checks that the circuit is not single hop. &lt;br=
&gt;
&lt;br&gt;Would it be at all possible to make a one - hop circuit (which I guess =
is possible by specifying the nickname, digest of the router) and then use =
it for a normal purpose?&lt;br&gt;&lt;br&gt;Any guidance will be highly appreciated.&lt;br=
&gt;
&lt;br&gt;Prithu&lt;br&gt;


</body></email><email><emailId>20090626155320</emailId><senderName>"Alberto M. Scattolo"</senderName><senderEmail>thedarkfreesoul@gmail.com</senderEmail><timestampReceived>2009-06-26 15:53:20-0400</timestampReceived><subject>Re: Single hop connections?</subject><body>

Hi Prithula,

I'm very new to Tor but I think this is not possible, unless you
change Tor source code and force it to do it. With one-hop-circuit you
would lose all anonymity. As far as I know Tor needs at least 2 hops
but 3 is much better.
Why do you want a single-hop circuit?
-- 

Alberto Maria Scattolo
Google profile: http://www.google.com/profiles/thedarkfreesoul

</body></email><email><emailId>20090626163545</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2009-06-26 16:35:45-0400</timestampReceived><subject>Re: Single hop connections?</subject><body>

Tor caters to several different audiences. For individuals that want Tor for
counter-censorship rather than privacy (ex. Chinese users) single-hop
circuits make a lot of sense, IMHO. It would be faster for them and place
less load on the Tor network (assuming exit nodes aren't the bottleneck).
Chinese users use open proxies all the time simply to get around the great
firewall, and this would allow them to use the Tor network like a big proxy
grab-bag. If they don't need privacy then making them go through extra hops
seems a lose-lose for both them and us.

However, it's not all roses and sunshine. One gotcha dr|z3d brought up on
irc was: "The point about single hops is that it exposing the node operator
to inordinate risk of legal pressure." Another issue might be making the
network appear more desirable to p2p traffic (allowing for more speed
probably means more abuse in that regard). Cheers! -Damian

On Fri, Jun 26, 2009 at 8:53 AM, Alberto M. Scattolo &lt;
thedarkfreesoul@gmail.com&gt; wrote:

&gt; Hi Prithula,
&gt;
&gt; I'm very new to Tor but I think this is not possible, unless you
&gt; change Tor source code and force it to do it. With one-hop-circuit you
&gt; would lose all anonymity. As far as I know Tor needs at least 2 hops
&gt; but 3 is much better.
&gt; Why do you want a single-hop circuit?
&gt; --
&gt;
&gt; Alberto Maria Scattolo
&gt; Google profile: http://www.google.com/profiles/thedarkfreesoul
&gt;

[Attachment #3 (text/html)]

Tor caters to several different audiences. For individuals that want Tor for \
counter-censorship rather than privacy (ex. Chinese users) single-hop circuits make a \
lot of sense, IMHO. It would be faster for them and place less load on the Tor \
network (assuming exit nodes aren't the bottleneck). Chinese users use open \
proxies all the time simply to get around the great firewall, and this would allow \
them to use the Tor network like a big proxy grab-bag. If they don't need privacy \
then making them go through extra hops seems a lose-lose for both them and \
us.&lt;br&gt;&lt;br&gt;However, it's not all roses and sunshine. One gotcha dr|z3d brought up \
on irc was: "The point about single hops is that it exposing the node operator \
to inordinate risk of legal pressure." Another issue might be making the network \
appear more desirable to p2p traffic (allowing for more speed probably means more \
abuse in that regard). Cheers! -Damian&lt;br&gt; &lt;br&gt;&lt;div class="gmail_quote"&gt;On Fri, Jun \
26, 2009 at 8:53 AM, Alberto M. Scattolo &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:thedarkfreesoul@gmail.com"&gt;thedarkfreesoul@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, \
204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt; Hi Prithula,&lt;br&gt;
&lt;br&gt;
I'm very new to Tor but I think this is not possible, unless you&lt;br&gt;
change Tor source code and force it to do it. With one-hop-circuit you&lt;br&gt;
would lose all anonymity. As far as I know Tor needs at least 2 hops&lt;br&gt;
but 3 is much better.&lt;br&gt;
Why do you want a single-hop circuit?&lt;br&gt;
&lt;font color="#888888"&gt;--&lt;br&gt;
&lt;br&gt;
Alberto Maria Scattolo&lt;br&gt;
Google profile: &lt;a href="http://www.google.com/profiles/thedarkfreesoul" \
target="_blank"&gt;http://www.google.com/profiles/thedarkfreesoul&lt;/a&gt;&lt;br&gt; \
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20090626182112</emailId><senderName>Carsten_Krüger</senderName><senderEmail>c.krueger@gmx.org</senderEmail><timestampReceived>2009-06-26 18:21:12-0400</timestampReceived><subject>Re: Single hop connections?</subject><body>

Hello Damian,

&gt; Tor caters to several different audiences. For individuals that want Tor for
&gt; counter-censorship rather than privacy (ex. Chinese users) single-hop
&gt; circuits make a lot of sense, IMHO.

No

1. some exit nodes could be operated by chinese government, if it's
single hop the node knows origin and destination and the chinese user
goes to jail.
2. It's easy to blacklist all exit nodes, because of this entry guard
nodes are introduced to tor

greetings
Carsten


</body></email><email><emailId>20090626183908</emailId><senderName>Prithula Dhungel</senderName><senderEmail>prithula.dhungel@gmail.com</senderEmail><timestampReceived>2009-06-26 18:39:08-0400</timestampReceived><subject>Re: Single hop connections?</subject><body>

Hi all,
  Thanks for the quick response. I am starting to do a project related to
Tor that would require me to build 1-hop circuits and communicate from my OP
to a webserver via the one single OR.
I was going though the Tor code and came across this function:

int
connection_exit_begin_conn(cell_t *cell, circuit_t *circ();

in the file src/or/connection_edge.c

Particularly, in line number: 2252

if (or_circ &amp;&amp; or_circ-&gt;is_first_hop) {
      /* Don't let clients use us as a single-hop proxy; it attracts
attackers
       * and users who'd be better off with, well, single-hop proxies.
       */
      log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,
             "Attempt to open a stream on first hop of circuit. Closing.");
      end_payload[0] = END_STREAM_REASON_TORPROTOCOL;
      relay_send_command_from_edge(rh.stream_id, circ, RELAY_COMMAND_END,
                                   end_payload, 1, NULL);
      tor_free(address);
      return 0;
    }

I'm afraid this means that no OR will allow an OP to use it as a single-hop
router (except for the director server connections?)

I tried making a one - hop circuit. It worked. However, when I try to attach
a stream to the one-hop circuit, I get a RELAY_CELL_END immediately after I
send a RELAY_SEND_BEGIN on that circuit.

Any suggestions? Maybe I'm getting the code all wrong?

Prithula


On Fri, Jun 26, 2009 at 12:35 PM, Damian Johnson &lt;atagar1@gmail.com&gt; wrote:

&gt; Tor caters to several different audiences. For individuals that want Tor
&gt; for counter-censorship rather than privacy (ex. Chinese users) single-hop
&gt; circuits make a lot of sense, IMHO. It would be faster for them and place
&gt; less load on the Tor network (assuming exit nodes aren't the bottleneck).
&gt; Chinese users use open proxies all the time simply to get around the great
&gt; firewall, and this would allow them to use the Tor network like a big proxy
&gt; grab-bag. If they don't need privacy then making them go through extra hops
&gt; seems a lose-lose for both them and us.
&gt;
&gt; However, it's not all roses and sunshine. One gotcha dr|z3d brought up on
&gt; irc was: "The point about single hops is that it exposing the node operator
&gt; to inordinate risk of legal pressure." Another issue might be making the
&gt; network appear more desirable to p2p traffic (allowing for more speed
&gt; probably means more abuse in that regard). Cheers! -Damian
&gt;
&gt;
&gt; On Fri, Jun 26, 2009 at 8:53 AM, Alberto M. Scattolo &lt;
&gt; thedarkfreesoul@gmail.com&gt; wrote:
&gt;
&gt;&gt; Hi Prithula,
&gt;&gt;
&gt;&gt; I'm very new to Tor but I think this is not possible, unless you
&gt;&gt; change Tor source code and force it to do it. With one-hop-circuit you
&gt;&gt; would lose all anonymity. As far as I know Tor needs at least 2 hops
&gt;&gt; but 3 is much better.
&gt;&gt; Why do you want a single-hop circuit?
&gt;&gt; --
&gt;&gt;
&gt;&gt; Alberto Maria Scattolo
&gt;&gt; Google profile: http://www.google.com/profiles/thedarkfreesoul
&gt;&gt;
&gt;
&gt;


-- 
Prithula Dhungel

[Attachment #3 (text/html)]

Hi all,&lt;br&gt;  Thanks for the quick response. I am starting to do a project related to \
Tor that would require me to build 1-hop circuits and communicate from my OP to a \
webserver via the one single OR.&lt;br&gt;I was going though the Tor code and came across \
this function:&lt;br&gt; &lt;br&gt;int&lt;br&gt;connection_exit_begin_conn(cell_t *cell, circuit_t \
*circ();&lt;br&gt;&lt;br&gt;in the file src/or/connection_edge.c&lt;br&gt;&lt;br&gt;Particularly, in line \
number: 2252&lt;br&gt;&lt;br&gt;if (or_circ &amp;&amp; or_circ-&gt;is_first_hop) {&lt;br&gt;      /* \
                Don't let clients use us as a single-hop proxy; it attracts \
                attackers&lt;br&gt;
       * and users who'd be better off with, well, single-hop proxies.&lt;br&gt;       \
*/&lt;br&gt;      log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,&lt;br&gt;             "Attempt to \
open a stream on first hop of circuit. Closing.");&lt;br&gt;  end_payload[0] = \
END_STREAM_REASON_TORPROTOCOL;&lt;br&gt;      relay_send_command_from_edge(rh.stream_id, \
circ, RELAY_COMMAND_END,&lt;br&gt;                                   end_payload, 1, \
NULL);&lt;br&gt;      tor_free(address);&lt;br&gt;  return 0;&lt;br&gt;    }&lt;br&gt;&lt;br&gt;I'm afraid this \
means that no OR will allow an OP to use it as a single-hop router (except for the \
director server connections?)&lt;br&gt;&lt;br&gt;I tried making a one - hop circuit. It worked. \
However, when I try to attach a stream to the one-hop circuit, I get a RELAY_CELL_END \
immediately after I send a RELAY_SEND_BEGIN on that circuit.&lt;br&gt; &lt;br&gt;Any suggestions? \
Maybe I'm getting the code all wrong?&lt;br&gt;&lt;br&gt;Prithula&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;div \
class="gmail_quote"&gt;On Fri, Jun 26, 2009 at 12:35 PM, Damian Johnson &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:atagar1@gmail.com"&gt;atagar1@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt; &lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, \
204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;Tor caters to several \
different audiences. For individuals that want Tor for counter-censorship rather than \
privacy (ex. Chinese users) single-hop circuits make a lot of sense, IMHO. It would \
be faster for them and place less load on the Tor network (assuming exit nodes \
aren't the bottleneck). Chinese users use open proxies all the time simply to get \
around the great firewall, and this would allow them to use the Tor network like a
big proxy grab-bag. If they don't need privacy then making them go through extra \
hops seems a lose-lose for both them and us.&lt;br&gt;&lt;br&gt;However, it's not all roses \
and sunshine. One gotcha dr|z3d brought up on irc was: "The point about single \
hops is that it exposing the node operator to inordinate risk of legal \
pressure." Another issue might be making the network appear more desirable to \
p2p traffic (allowing for more speed probably means more abuse in that regard). \
Cheers! -Damian&lt;div&gt; &lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;
&lt;br&gt;&lt;div class="gmail_quote"&gt;On Fri, Jun 26, 2009 at 8:53 AM, Alberto M. Scattolo \
&lt;span dir="ltr"&gt;&lt;&lt;a href="mailto:thedarkfreesoul@gmail.com" \
target="_blank"&gt;thedarkfreesoul@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote \
class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt \
0pt 0.8ex; padding-left: 1ex;"&gt;

Hi Prithula,&lt;br&gt;
&lt;br&gt;
I'm very new to Tor but I think this is not possible, unless you&lt;br&gt;
change Tor source code and force it to do it. With one-hop-circuit you&lt;br&gt;
would lose all anonymity. As far as I know Tor needs at least 2 hops&lt;br&gt;
but 3 is much better.&lt;br&gt;
Why do you want a single-hop circuit?&lt;br&gt;
&lt;font color="#888888"&gt;--&lt;br&gt;
&lt;br&gt;
Alberto Maria Scattolo&lt;br&gt;
Google profile: &lt;a href="http://www.google.com/profiles/thedarkfreesoul" \
target="_blank"&gt;http://www.google.com/profiles/thedarkfreesoul&lt;/a&gt;&lt;br&gt; \
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt; &lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br \
clear="all"&gt;&lt;br&gt;-- &lt;br&gt;Prithula Dhungel&lt;br&gt;



</body></email><email><emailId>20090512140511</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-12 14:05:11-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Mon, May 04, 2009 at 07:12:10PM -0400, Roger Dingledine wrote:
&gt; Filename: 160-bandwidth-offset.txt
&gt; Title: Authorities vote for bandwidth offsets in consensus
&gt; Version: $Revision$
&gt; Last-Modified: $Date$
&gt; Author: Roger Dingledine
&gt; Created: 4-May-2009
&gt; Status: Open
&gt; Target: 0.2.2.x
&gt; 
&gt; 1. Motivation
&gt; 
&gt;   As part of proposal 141, we moved the bandwidth value for each relay
&gt;   into the consensus. Now clients can know how they should load balance
&gt;   even before they've fetched the corresponding relay descriptors.
&gt; 
&gt;   Putting the bandwidth in the consensus also lets the directory
&gt;   authorities choose more accurate numbers to advertise, if we come up
&gt;   with a better algorithm for deciding weightings.
&gt; 
&gt;   Our original plan was to teach directory authorities how to measure
&gt;   bandwidth themselves; then every authority would vote for the bandwidth
&gt;   it prefers, and we'd take the median of votes as usual.
&gt; 
&gt;   The problem comes when we have 7 authorities, and only a few of them
&gt;   have smarter bandwidth allocation algorithms. So long as the majority
&gt;   of them are voting for the number in the relay descriptor, the minority
&gt;   that have better numbers will be ignored.
&gt; 
&gt; 2. Options
&gt; 
&gt;   One fix would be to demand that every authority also run the
&gt;   new bandwidth measurement algorithms: in that case, part of the
&gt;   responsibility of being an authority operator is that you need to run
&gt;   this code too. But in practice we can't really require all current
&gt;   authority operators to do that; and if we want to expand the set of
&gt;   authority operators even further, it will become even more impractical.
&gt;   Also, bandwidth testing adds load to the network, so we don't really
&gt;   want to require that the number of concurrent bandwidth tests match
&gt;   the number of authorities we have.
&gt; 
&gt;   The better fix is to allow certain authorities to specify that they are
&gt;   voting on bandwidth "offsets": how much they think the weight should
&gt;   be changed for the relay in question. We should put the offset vote in
&gt;   the stanza for the relay in question, so a given authority can choose
&gt;   which relays to express preferences for and which not.

As Roger and I discussed on Friday, this seems needlessly complex.
The semantics you're suggesting seem to be that an authority can say:
   w Bandwidth=X
if they're not too sure, and 
   w Bandwidth=Y Offset=Z
if they're pretty sure that the real value of the bandwidth is Y+Z.

This is a big buggy, as noted.  Suppose that there are 3 authorities,
and they say about a single router:
       Bw=1000 Offset=0      (Total=1000)
       Bw=1500 Offset=0      (Total=1500)
       Bw=1000 Offset=500    (Total=1500)
Note that the algorithm described below will give a median Bw if 1000
and a median offset of 0, producing a declared bandwidth of 1000.  But
if instead we had taken the median of the actual observed totals, we
would have gotten a value of 1500.

It makes more sense just to let bandwidth mean bandwidth.  If we want
to have measured bandwidth count for more than reported bandwidth,
let's have an optional flag on the vote line that looks like:

   w Bandwidth=X Measured=1

This way the median actually -is- the median.  See below for my
suggested voting algorithm.

&gt; 3. Security implications
&gt; 
&gt;   If only some authorities choose to vote on an offset, then a majority of
&gt;   those voting authorities can arbitrarily change the bandwidth weighting
&gt;   for the relay. At the extreme, if there's only one offset-voting
&gt;   authority, then that authority can dictate which relays clients will
&gt;   find attractive.
&gt; 
&gt;   This problem isn't entirely new: we already have the worry wrt
&gt;   the subset of authorities that vote for BadExit.
&gt; 
&gt;   To make it not so bad, we should deploy at least three offset-voting
&gt;   authorities.
&gt; 
&gt;   Also, authorities that know how to vote for offsets should vote for
&gt;   an offset of zero for new nodes, rather than choosing not to vote on
&gt;   any offset in those cases.

Suggested revision: If there are at least MIN_MEASURING (say, 3)
voters that say "measured" about a given banwidth observation, then we
take the median of their observations as the bandwidth of the router.
Otherwise, we proceed as in the current dir-spec.txt for that router.

&gt; 4. Design
&gt; 
&gt;   First, we need a new consensus method to support this new calculation.
&gt; 
&gt;   Now v3 votes can have a new weight on the "w" line:
&gt;     "Bandwidth_Offset=" INT.
&gt;   Once we're using the new consensus method, the new way to compute the
&gt;   Bandwidth weight is by taking the old vote (explained in proposal 141:
&gt;   median, then choose the lower number in the case of ties), and adding
&gt;   or subtracting the median offset (using the offset closer to 0 in the
&gt;   case of ties, and with a sum of 0 if the sum is negative).
&gt; 
&gt;   Then the actual consensus looks just the same as it did before,
&gt;   so clients never have to know that this additional calculation is
&gt;   happening.

Here are some additional suggestions that came up as we were talking.

* We'd like to avoid having little changes in measured bandwidth
  result in changes to the consensus, since we'd like to be able to
  transfer consensus diffs.  Thus, let's round our votes to the
  first N significant bits.
  
  In other words, if we've observed a bandwidth of 28789 bytes for a
  node, that's  111 0000 0111 0101.   We round that down to 111 0000
  0000 0000, and declare 26872.

  This is better than rounding to the nearest 1k, since a 1k change is
  very significant for low values, and relatively frequent for high
  values.

* We want to have our declared values for node bandwidth lag our
  observations by a little.  If we observe that a node has a very high
  bandwidth, we don't want to declare that high bandwidth immediately,
  since a node with apparent high available bandwidth could have
  either a very high capacity, or a very unused capacity.  Instead, we
  want to adjust the bandwidth upwards more slowly, so that we don't
  oscillate between "notice that performance is good and declare the
  node as high-capacity, and get it hammered by requests; notice that
  performance is bad and declare the node as low-capacity and have
  users stop using it".

  (Mike came up with the idea for this one; I don't know if it's made
  it to or-dev yet.)

  My typical way for doing this would be for voters who are measuring
  bandwidth to declare the bandwidth of a node as a weighted average
  of the observation and the last declared bandwidth:

         Bw_new = (Bw_old * Alpha + Observation)/(Alpha + 1)

  Roger noted that with an approach like this, Alpha could be voted on
  like any other value, letting us adjust the lag parameters.

* It's really important that measurers try to normalize declared
  bandwidth values to the same scale.  Conceptually, a bandwidth as we
  use it in the consensus is just a weight on an arbitrary scale.  But
  if different authorities are voting for bandwidths using different
  scales -- for example, if one systematically underestimates by 10%
  -- then the one with the middle _scale_ will pretty much
  unilaterally set the weights for the routers.

  I don't have a great solution for this one, other than to try to
  make sure the bandwidth measurement algorithms don't have any
  systemic bias depending on which authority is running them from
  where on the Internet.  We _could_ normalize everything to a
  fraction, but that doesn't seem like it would give stable values,
  and combining these values would seem hard.


-- 
Nick
</body></email><email><emailId>20090512164650</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-12 16:46:50-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Tue, May 12, 2009 at 10:05:11AM -0400, Nick Mathewson wrote:
 [...]
&gt; Here are some additional suggestions that came up as we were
&gt; talking.


Oh!  Here's one more we may want to think about:

Right now, clients don't believe any bandwidth value over a certain
amount, so that routers can't say "I have a 1 Terabyte capacity!" and
get all the traffic.  But if bandwidths are measured by the
authorities, it could become safe to believe big bandwidths.  Thus,
the consensus should indicate whether its bandwidth values are to be
clipped or not.

-- 
Nick
</body></email><email><emailId>20090512224436</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2009-05-12 22:44:36-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>


Thus spake Nick Mathewson (nickm@torproject.org):

&gt; &gt;   The better fix is to allow certain authorities to specify that they are
&gt; &gt;   voting on bandwidth "offsets": how much they think the weight should
&gt; &gt;   be changed for the relay in question. We should put the offset vote in
&gt; &gt;   the stanza for the relay in question, so a given authority can choose
&gt; &gt;   which relays to express preferences for and which not.
&gt; 
&gt; As Roger and I discussed on Friday, this seems needlessly complex.
&gt; The semantics you're suggesting seem to be that an authority can say:
&gt;    w Bandwidth=X
&gt; if they're not too sure, and 
&gt;    w Bandwidth=Y Offset=Z
&gt; if they're pretty sure that the real value of the bandwidth is Y+Z.
&gt; 
&gt; This is a big buggy, as noted.  Suppose that there are 3 authorities,
&gt; and they say about a single router:
&gt;        Bw=1000 Offset=0      (Total=1000)
&gt;        Bw=1500 Offset=0      (Total=1500)
&gt;        Bw=1000 Offset=500    (Total=1500)
&gt; Note that the algorithm described below will give a median Bw if 1000
&gt; and a median offset of 0, producing a declared bandwidth of 1000.  But
&gt; if instead we had taken the median of the actual observed totals, we
&gt; would have gotten a value of 1500.
&gt; 
&gt; It makes more sense just to let bandwidth mean bandwidth.  If we want
&gt; to have measured bandwidth count for more than reported bandwidth,
&gt; let's have an optional flag on the vote line that looks like:
&gt; 
&gt;    w Bandwidth=X Measured=1
&gt; 
&gt; This way the median actually -is- the median.  See below for my
&gt; suggested voting algorithm.

Ok, just FYI, the bandwidth measurements are actually computed as the
ratio of the average stream bandwidth through a node to the average
stream bandwidth observed for nodes of similar reported capacity (or
the average of the network as a whole). 

I'll be detailing the exact nature of this computation in Proposal 161
today, but the end result of the measurement is actually just a
floating point value that is computed independent of the reported
bandwidth. It only becomes a bandwidth value once we multiply it
against a reported bandwidth for a node. I'm guessing the value we
would use for this multiplication would be the reported value we saw
during the scan.

&gt; &gt; 4. Design
&gt; &gt; 
&gt; &gt;   First, we need a new consensus method to support this new calculation.
&gt; &gt; 
&gt; &gt;   Now v3 votes can have a new weight on the "w" line:
&gt; &gt;     "Bandwidth_Offset=" INT.
&gt; &gt;   Once we're using the new consensus method, the new way to compute the
&gt; &gt;   Bandwidth weight is by taking the old vote (explained in proposal 141:
&gt; &gt;   median, then choose the lower number in the case of ties), and adding
&gt; &gt;   or subtracting the median offset (using the offset closer to 0 in the
&gt; &gt;   case of ties, and with a sum of 0 if the sum is negative).
&gt; &gt; 
&gt; &gt;   Then the actual consensus looks just the same as it did before,
&gt; &gt;   so clients never have to know that this additional calculation is
&gt; &gt;   happening.
&gt; 
&gt; Here are some additional suggestions that came up as we were talking.
&gt; 
&gt; * We'd like to avoid having little changes in measured bandwidth
&gt;   result in changes to the consensus, since we'd like to be able to
&gt;   transfer consensus diffs.  Thus, let's round our votes to the
&gt;   first N significant bits.
&gt;   
&gt;   In other words, if we've observed a bandwidth of 28789 bytes for a
&gt;   node, that's  111 0000 0111 0101.   We round that down to 111 0000
&gt;   0000 0000, and declare 26872.
&gt; 
&gt;   This is better than rounding to the nearest 1k, since a 1k change is
&gt;   very significant for low values, and relatively frequent for high
&gt;   values.

Ok. If we are voting on bandwidths, should we do this in the python or
in Tor?

&gt; * It's really important that measurers try to normalize declared
&gt;   bandwidth values to the same scale.  Conceptually, a bandwidth as we
&gt;   use it in the consensus is just a weight on an arbitrary scale.  But
&gt;   if different authorities are voting for bandwidths using different
&gt;   scales -- for example, if one systematically underestimates by 10%
&gt;   -- then the one with the middle _scale_ will pretty much
&gt;   unilaterally set the weights for the routers.
&gt; 
&gt;   I don't have a great solution for this one, other than to try to
&gt;   make sure the bandwidth measurement algorithms don't have any
&gt;   systemic bias depending on which authority is running them from
&gt;   where on the Internet.  We _could_ normalize everything to a
&gt;   fraction, but that doesn't seem like it would give stable values,
&gt;   and combining these values would seem hard.

I'm thinking for now we just distribute the scanners on different
geographical locations: one west coast US, one east coast US, and one
Europe to start. My intuition is that the median authority will vary
from node to node, depending upon the geographical location of that
node. If this turns out not to be the case and the measurements end up
being biased for some reason, we can try to figure that out at that
point. But even so, the freedom of the middle value should at least be
bounded by the other two measurements' bias.


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20090614050518</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-14 05:05:18-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Tue, May 12, 2009 at 10:05:11AM -0400, Nick Mathewson wrote:
&gt; It makes more sense just to let bandwidth mean bandwidth.  If we want
&gt; to have measured bandwidth count for more than reported bandwidth,
&gt; let's have an optional flag on the vote line that looks like:
&gt; 
&gt;    w Bandwidth=X Measured=1
&gt; 
&gt; This way the median actually -is- the median.

Sounds like a fine plan.

&gt; Suggested revision: If there are at least MIN_MEASURING (say, 3)
&gt; voters that say "measured" about a given banwidth observation, then we
&gt; take the median of their observations as the bandwidth of the router.
&gt; Otherwise, we proceed as in the current dir-spec.txt for that router.

Ok.

&gt; * We'd like to avoid having little changes in measured bandwidth
&gt;   result in changes to the consensus, since we'd like to be able to
&gt;   transfer consensus diffs.  Thus, let's round our votes to the
&gt;   first N significant bits.
&gt;   
&gt;   In other words, if we've observed a bandwidth of 28789 bytes for a
&gt;   node, that's  111 0000 0111 0101.   We round that down to 111 0000
&gt;   0000 0000, and declare 26872.
&gt; 
&gt;   This is better than rounding to the nearest 1k, since a 1k change is
&gt;   very significant for low values, and relatively frequent for high
&gt;   values.

Ok, but another constraint here is that users want to look at the numbers
in the consensus and find them intuitive. Can we take the resulting
number (26872) and round it off to 26? That will take care of an unending
stream of users wondering why the heck it says 26872. As a side effect,
the status stanzas get smaller too.

--Roger

</body></email><email><emailId>20090614050752</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-14 05:07:52-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Tue, May 12, 2009 at 12:46:50PM -0400, Nick Mathewson wrote:
&gt; Oh!  Here's one more we may want to think about:
&gt; 
&gt; Right now, clients don't believe any bandwidth value over a certain
&gt; amount, so that routers can't say "I have a 1 Terabyte capacity!" and
&gt; get all the traffic.  But if bandwidths are measured by the
&gt; authorities, it could become safe to believe big bandwidths.  Thus,
&gt; the consensus should indicate whether its bandwidth values are to be
&gt; clipped or not.

I think we should just declare that they're never to be clipped. Why
leave it to old clients to decide what's safe for them, and splinter
the anonymity sets? In fact, proposal 141 already says this:

  Authorities will cap the bandwidth number at some arbitrary value,
  currently 10MB/sec.  If a router claims a larger bandwidth an
  authority's vote will still only show Bandwidth=10240.
  [...]
  Clients should believe the bandwidth as presented in the consensus,
  not capping it again.

--Roger

</body></email><email><emailId>20090613031009</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-13 03:10:09-0400</timestampReceived><subject>Re: Proposal 162: Publish the consensus in multiple flavors</subject><body>

On Fri, May 15, 2009 at 01:05:41PM -0400, Nick Mathewson wrote:
&gt; Filename: 162-consensus-flavors.txt
&gt; Title: Publish the consensus in multiple flavors

Looks good. We should do it.

&gt;    Our past approach to cases like this has been to shovel all of
&gt;    the data into the consensus document.  But this is rather poor
&gt;    for bandwidth.  Adding a single SHA256 hash to a consensus for
&gt;    each router increases the compressed consensus size by 47%.  In
&gt;    comparison, replacing a single SHA1 hash with a SHA256 hash for
&gt;    each listed router increases the consensus size by only 18%.

SHA256's are still huge. It's a real shame there aren't accepted hash
functions that use only 20 bytes.

&gt;    In addition to the consensus currently served at
&gt;    /tor/status-vote/(current|next)/consensus.z ,

Are we expecting to make this url deprecated at some point? I guess not
until 0.2.1.x is obsolete, which is a long time from now.

In the mean time, do we really want to force caches to mirror the
old-school consensus URL, and also the "ns" consensus flavor URL, even
though they'll always be the same document? Seems to me that we could
start out with only one consensus flavor, the "microdesc" one.

&gt;     The algname part of a signature describes what algorithm was
&gt;     used to hash the identity and signing keys, and to compute the
&gt;     signature.  The algorithm "sha256" MUST be recognized;
&gt;     signatures with unrecognized algorithms MUST be ignored.
&gt;     (See below).

I'm still curious about Sebastian's question here. I guess the
plan is to use sha256 sigs for now, and if we decide we don't like
that hash function, we a) make up a new consensus flavor that hashes
microdescriptors with whirlpool++, b) get all the authorities to upgrade
to a consensus method that agrees to build that flavor and list the
new flavor in the consensus-index file, hashed by whirlpool++ as well
as sha256, and c) teach clients to fetch the new flavor and make sure
the ... make sure the what? Is there anything in the consensus itself
that shows what digest the authority used when signing? It seems like we
want to make sure the "Signature*" lines from the consensus-index get
used in the appropriate consensus flavor too.

More generally, at some point we should specify our upgrade path plan,
so we're less likely to learn later that it has holes.

Also, in that case, caches that haven't upgraded can still be tricked
by an authority into fetching a colliding consensus flavor document,
since they'd only be checking the sha256. That's not so bad since clients
should be able to check the hashes themselves. In theory it's a DoS worry,
since an attacker could make it hard to find a copy with the right valid
hashes and signatures; but in practice I don't see an authority actually
being able to pull off that attack without somebody noticing and fixing
it out of band. And we're only vulnerable to an authority doing it,
right (assuming honest but not-upgraded relays, and nobody mitm'ing the
connection from relay to authority)?

&gt;     The consensus index is made available at
&gt;        /tor/status-vote/(current|next)/consensus-index.z.

You should be aware that due to a bug in the current code, that url is
valid already:
128.31.0.34:9031/tor/status-vote/current/consensus-index

Not a huge problem though, I think.

&gt;     Caches should fetch this document so they can check the
&gt;     correctness of the different consensus documents they fetch.
&gt;     They do not need to check anything about an unrecognized
&gt;     consensus document beyond its digest.

and length.

This proposal should definitely be targeted for 0.2.2, so caches can
start caching flavors.

Thanks!
--Roger

</body></email><email><emailId>20090615181925</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-06-15 18:19:25-0400</timestampReceived><subject>Re: Proposal 162: Publish the consensus in multiple flavors</subject><body>

On Fri, Jun 12, 2009 at 11:10:09PM -0400, Roger Dingledine wrote:
&gt; On Fri, May 15, 2009 at 01:05:41PM -0400, Nick Mathewson wrote:
&gt; &gt; Filename: 162-consensus-flavors.txt
&gt; &gt; Title: Publish the consensus in multiple flavors
&gt; 
&gt; Looks good. We should do it.
&gt; 
&gt; &gt;    Our past approach to cases like this has been to shovel all of
&gt; &gt;    the data into the consensus document.  But this is rather poor
&gt; &gt;    for bandwidth.  Adding a single SHA256 hash to a consensus for
&gt; &gt;    each router increases the compressed consensus size by 47%.  In
&gt; &gt;    comparison, replacing a single SHA1 hash with a SHA256 hash for
&gt; &gt;    each listed router increases the consensus size by only 18%.
&gt; 
&gt; SHA256's are still huge. It's a real shame there aren't accepted hash
&gt; functions that use only 20 bytes.

I think we're going to have to live with this, unless we want to be
crypto-weirdos and say that our hash function is the first 20 bytes of
SHA256 or something else horribly under-analyzed like that.

&gt; &gt;    In addition to the consensus currently served at
&gt; &gt;    /tor/status-vote/(current|next)/consensus.z ,
&gt; 
&gt; Are we expecting to make this url deprecated at some point? I guess not
&gt; until 0.2.1.x is obsolete, which is a long time from now.
&gt; 
&gt; In the mean time, do we really want to force caches to mirror the
&gt; old-school consensus URL, and also the "ns" consensus flavor URL, even
&gt; though they'll always be the same document? Seems to me that we could
&gt; start out with only one consensus flavor, the "microdesc" one.

My plan was to have the "ns" URL be synonymous with the old URL, so
that once the authorities are serving at the ns URL, caches can start
fetching it.  They don't need to download the document more than
once.  The old URL will only need to be an alias for the "ns" URL.

&gt; &gt;     The algname part of a signature describes what algorithm was
&gt; &gt;     used to hash the identity and signing keys, and to compute the
&gt; &gt;     signature.  The algorithm "sha256" MUST be recognized;
&gt; &gt;     signatures with unrecognized algorithms MUST be ignored.
&gt; &gt;     (See below).
&gt; 
&gt; I'm still curious about Sebastian's question here. I guess the
&gt; plan is to use sha256 sigs for now, and if

"when" ;)

&gt;                                             we decide we don't like
&gt; that hash function, we a) make up a new consensus flavor that hashes
&gt; microdescriptors with whirlpool++, b) get all the authorities to upgrade
&gt; to a consensus method that agrees to build that flavor and list the
&gt; new flavor in the consensus-index file, hashed by whirlpool++ as well
&gt; as sha256, and c) teach clients to fetch the new flavor and make sure
&gt; the ... make sure the what? Is there anything in the consensus itself
&gt; that shows what digest the authority used when signing? It seems like we
&gt; want to make sure the "Signature*" lines from the consensus-index get
&gt; used in the appropriate consensus flavor too.

You mean, we should have new consensus document types include
extensible signature lines of the format currently specified for the
consensus-index?  I think that's a good idea.  We can't trivially do
it for the existing networkstatus format without a bit of intense
hacking, though, since existing clients will freak out if they fetch a
consensus with directory signatures they can't verify.

The right place to specify this is probably when introducing a new
consensus flavor: I'll amend 158 to say that we use this format.

&gt; More generally, at some point we should specify our upgrade path plan,
&gt; so we're less likely to learn later that it has holes.

Indeed we should.  That's what I'm hoping the current
xxx-what-uses-sha1.txt document turns into.

&gt; Also, in that case, caches that haven't upgraded can still be tricked
&gt; by an authority into fetching a colliding consensus flavor document,
&gt; since they'd only be checking the sha256. That's not so bad since clients
&gt; should be able to check the hashes themselves. In theory it's a DoS worry,
&gt; since an attacker could make it hard to find a copy with the right valid
&gt; hashes and signatures; but in practice I don't see an authority actually
&gt; being able to pull off that attack without somebody noticing and fixing
&gt; it out of band. And we're only vulnerable to an authority doing it,
&gt; right (assuming honest but not-upgraded relays, and nobody mitm'ing the
&gt; connection from relay to authority)?

So the attack would run like this:
  - Mallory (the hostile authority) guesses what a future consensus
    will be.  This is hard unless there is way less information in
    everyone else's vote than we might have thought.  Note that the
    each consensus includes a vote-digest line from every voter, so
    that unless Mallory can guess all other authorities' votes
    exactly, he's going to have trouble here.

    (Mallory can make more than one guess, but unless he guesses
    the actual consensus, he loses.  He can influence the consensus by
    voting on it, but his influence is not unlimited.)

  - Mallory figures out an alternate consensus that he wants the
    authorities to publish instead.

  - Mallory generates a hash collision between the future consensus
    and the desired target consensus.  He can modify the future
    consensus most easily through introducing stuff in the contact
    line of his vote, and through 

    (Note that this step is going to be computationally expensive, and
    it's got to happen on a tight schedule: the longer Mallory spends
    generating a collision, the likelier it is that no vote he can
    make will make the consensus confirm to his expectations.)

  - The authorities vote.  Mallory now has a signed document
    purporting to be a consensus that shares the SHA256 of the actual
    consensus.  Any caches and clients that look only at the SHA256 of
    the document will believe it to be properly signed.

I think this attack probably wouldn't work so well in practice because
of the difficulty of guessing a consensus in time, but please check my
reasoning.

The part of this that worries me is that Mallory could set the
fresh-until time indefinitely far in the future, so that if the attack
ever _did_ work, the affected clients would stay compromised
indefinitely, or until they upgraded.

We could mitigate that part of this attack by imposing a maximum on
the freshness of any descriptor, I guess.

Alternatively, if we are really worried here, we could have each
authority include a random nonce in its vote so that there is no way
to predict what the vote-digest fields of a consensus will be in
advance.  This is a cheap fix, and it would cut the attack window
down to the voting delay time, so Mallory would need to find a hash
collision in about 5 minutes.

&gt; &gt;     The consensus index is made available at
&gt; &gt;        /tor/status-vote/(current|next)/consensus-index.z.
&gt; 
&gt; You should be aware that due to a bug in the current code, that url is
&gt; valid already:
&gt; 128.31.0.34:9031/tor/status-vote/current/consensus-index
&gt; 
&gt; Not a huge problem though, I think.

Not a huge problem, so long as we don't have caches try to fetch it
until all the authorities are upgraded.

yrs,
-- 
Nick
</body></email><email><emailId>20090606003722</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2009-06-06 00:37:22-0400</timestampReceived><subject>Re: Proposal 158 revised: Microdescriptors again</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


On Jun 6, 2009, at 2:33 AM, Sebastian Hahn wrote:

&gt;
&gt; On May 16, 2009, at 6:46 AM, Nick Mathewson wrote:
&gt;
&gt;&gt; As long promised, I've revised Roger's January proposal on
&gt;&gt; microdescriptors.  Here's the latest version.  It incorporates (I
&gt;&gt; hope) our discussions on the topic, plus suggestions based on  
&gt;&gt; proposal
&gt;&gt; 162.
&gt;&gt; [snip]
&gt;
&gt;&gt; (We use base64 for size and for consistency with the consensus
&gt;&gt; format. We use -s instead of +s to separate these items, since
&gt;
&gt; this sentence's end is not
&gt; what is it trying to
&gt;
&gt; I thought about issues when we add/remove more than one authority  
&gt; before all operators had a chance to upgrade or upgrade again (in  
&gt; case of removal), but couldn't come up with an actually bad  
&gt; situation. But this led to the realization that the work flow  
&gt; described just talks about one authority getting added/removed at a  
&gt; time, I think the situation with more than one change can quickly  
&gt; get complex (and it's easy to imagine that with 15 authorities, some  
&gt; operators will be on vacation for a month, for example). The  
&gt; proposal could maybe be clearer on how those cases should be handled  
&gt; by the operators.
&gt;
&gt;
&gt; Sebastian
&gt;

erm. this is when you write feedback in one document and then copy it  
into e-mails. Sorry... that last paragraph was for 165. I probably  
wanted to hide the fact that I didn't have any other things.

Sebastian


-----BEGIN PGP SIGNATURE-----

iEYEARECAAYFAkopukMACgkQCADWu989zubNvwCcCOriUevb2hDt/vdPmzNtmnEo
YCgAoNN3+lYQGMedyg/xJjyJKLqUKUzM
=E5l0
-----END PGP SIGNATURE-----

</body></email><email><emailId>20090613072341</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-13 07:23:41-0400</timestampReceived><subject>Re: Proposal 158 revised: Microdescriptors again</subject><body>

On Sat, May 16, 2009 at 12:46:40AM -0400, Nick Mathewson wrote:
&gt; Filename: 158-microdescriptors.txt
&gt; Title: Clients download consensus + microdescriptors

We should do this one too, also in the 0.2.2.x timeframe. The microdesc
flavor can be the test case for consensus flavors.

&gt; 1. Overview
&gt; 
&gt;   This proposal replaces section 3.2 of proposal 141, which was
&gt;   called "Fetching descriptors on demand". Rather than modifying the
&gt;   circuit-building protocol to fetch a server descriptor inline at each
&gt;   circuit extend, we instead put all of the information that clients need
&gt;   either into the consensus itself, or into a new set of data about each
&gt;   relay called a microdescriptor. The microdescriptor is a direct
&gt;   transform from the relay descriptor, so relays don't even need to know
&gt;   this is happening.

This last sentence is false, now that authorities serve microdescs and
relays cache and serve them. A replacement sentence might be "".

&gt; 3. Design
&gt; 
&gt;   There are three pieces to the proposal. First, authorities will list in
&gt;   their votes (and thus in the consensus)  the expected hash
&gt;   of microdescriptor for each relay. Second, directory mirrors will serve
&gt;   microdescriptors. Third, clients will ask for them and cache them.

  There are three pieces to the proposal. First, authorities will list
  in their votes (and thus in the consensus) the expected hash
  of microdescriptor for each relay. Second, authorities will serve
  microdescriptors, and directory mirrors will cache and serve them.
  Third, clients will ask for them and cache them.

&gt; 3.1. Consensus changes
&gt; 
&gt;   If the authorities choose a consensus method of a given version or
&gt;   later, a microdescriptor format is implicit in that version.
&gt;   A microdescriptor should in every case be a pure function of the
&gt;   router descriptor and the conensus method.

s/conensus/consensus/

&gt;   In votes, need to include the hash of each expected microdescriptor in
&gt;   the routerstatus section. I suggest a new "m" line for each stanza,
&gt;   with the base64 of the SHA256 hash of the router's microdescriptor.
&gt; 
&gt;   For every consensus method that an authority supports, it includes a
&gt;   separate "m" line in each router section of its vote, containing:
&gt;     "m" SP methods SP digest NL
&gt;   where methods is a comma-separated list of the consensus methods
&gt;   that the authority believes will produce "digest".

Learning from our lessons in proposal 162, shouldn't the m line in the
vote be
  "m" SP methods 1*(SP AlgorithmName "=" Digest) NL
?

On the one hand, it isn't critical to plan this part ahead of time,
since only the authorities would need to update in order to understand
a new voting format. But on the other hand, when the time does come,
a) we'd need a flag hour for authorities to recognize the new format,
and those suck, and b) do we really want to be designing and deploying
this part on the day we finally realize we need to switch hashes? :)

(I think it's fine for the consensus itself to not specify any
algorithmnames; that's what flavors are for. But since we don't have vote
flavors, the votes need to say which algorithms produce which digests,
so the authorities can make all the consensus flavors.)

&gt; 3.1.1. Descriptor elements to include for now
&gt; 
&gt;   In the first version, the microdescriptor should contain the
&gt;   onion-key element and the family element from the router descriptor.

Should we put the exit policy summary here too, and take it out of the
main consensus? I don't think anybody actually uses it from the main
consensus yet.

&gt; 3.1.2. Computing consensus for microdescriptor-elements and "m" lines
&gt; 
&gt;   When we generating a consensus, we use whichever m line
&gt;   unambiguously corresponds to the descriptor digest that will be
&gt;   included in the consensus.  (If there are multiple m lines for that
&gt;   descriptor digest, we use whichever is most common.  If they are
&gt;   equally common, we break ties in the favor of the lexically
&gt;   earliest.  Either way, we should log a warning: That's likely a
&gt;   bug.)

I don't understand the above. The microdescriptor is a straight
function of a) the consensus method, and b) whichever relay descriptor
is a winner for this vote. So that means the "m" line we pick for the
consensus has to be the microdescriptor digest from whichever votes a)
voted for the winner, and b) offered the consensus method that we chose
to use for constructing this consensus. If any such votes differ, we'll
have other problems, like disagreeing authorities serving disagreeing
microdescriptors. I guess that's what you're getting at above?

&gt;   We still need to descide whether to move ports into microdescriptors
&gt;   or not.  In either case, they can be removed from the current "ns"
&gt;   flavor of consensus, since no current clients use them, and they
&gt;   take up about 5% of the compressed consensus.

Ah, here it is. Yes, I think we should put them in.

&gt; 3.2. Directory mirrors serve microdescriptors
&gt; 
&gt;   Directory mirrors should then read the microdescriptor-elements line
&gt;   from the consensus, and learn how to answer requests. (Directory mirrors
&gt;   continue to serve normal relay descriptors too, a) to serve old clients
&gt;   and b) to be able to construct microdescriptors on the fly.)

  That's wrong now. New text:

  Directory mirrors should then fetch, cache, and serve each
  microdescriptor from the authorities. (They need to continue to serve
  normal relay descriptors too, to handle old clients.)

&gt;   The microdescriptors with base64 hashes &lt;D1&gt;,&lt;D2&gt;,&lt;D3&gt; should be available at:
&gt;     http://&lt;hostname&gt;/tor/micro/d/&lt;D1&gt;-&lt;D2&gt;-&lt;D3&gt;.z
&gt;   (We use base64 for size and for consistency with the consensus
&gt;   format. We use -s instead of +s to separate these items, since
&gt;   the + character use used in base64 encoding.)

s/use used/is used/

&gt;   All the microdescriptors from the current consensus should also be
&gt;   available at:
&gt;     http://&lt;hostname&gt;/tor/micro/all.z

How will these two URLs interact with future flavors? If a later flavor
uses a different hash function, do we still offer everything under
/tor/micro/d/&lt;D&gt;, even though different clients are verifying results
with different hash functions?

And which microdescriptors get put in /tor/micro/all if there are two
active flavors?

One answer is to make it /tor/micro/F/d/&lt;D1&gt; and /tor/micro/F/all.
So long as we don't change our hash function, that should do it.

(In practice, implementations can realize that /F1/d/D1 and /F2/d/D1
are the same and don't need to be stored in duplicate.)

If we do change our hash function, caches that don't recognize the flavor
won't be able to verify that the microdescriptor hashes are correct. And
since they won't know whether we've changed the hash function in a
flavor they don't recognize, does that mean that caches should never
check hashes on flavors they don't recognize?

&gt;   so a client that's bootstrapping doesn't need to send a 70KB URL just
&gt;   to name every microdescriptor it's looking for.

That's a 110KB URL if we use SHA256. :)

&gt; 3.3.1. Information leaks from clients
&gt; 
&gt;   If a client asks you for a set of microdescs, then you know she didn't
&gt;   have them cached before. How much does that leak? What about when
&gt;   we're all using our entry guards as directory guards, and we've seen
&gt;   that user make a bunch of circuits already?
&gt; 
&gt;   Fetching "all" when you need at least half is a good first order fix,
&gt;   but might not be all there is to it.
&gt; 
&gt;   Another future option would be to fetch some of the microdescriptors
&gt;   anonymously (via a Tor circuit).

Other crazy options include doing decoy fetches, so somebody seeing a
fetch can't conclude much from it.

&gt; 4. Transition and deployment
&gt; 
&gt;   Phase one, the directory authorities should start voting on
&gt;   microdescriptors and microdescriptor elements, and putting them in the

s/ and microdescriptor elements//

&gt;   consensus.

Thanks!
--Roger

</body></email><email><emailId>20090618192618</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-06-18 19:26:18-0400</timestampReceived><subject>Re: Proposal 164: Reporting the status of server votes</subject><body>

On Sun, Jun 14, 2009 at 02:40:05AM -0400, Roger Dingledine wrote:
&gt; On Fri, May 22, 2009 at 03:00:42AM -0400, Nick Mathewson wrote:
&gt; &gt;        - Look through your log for reports of what the authority said
&gt; &gt;          when you tried to upload.
&gt; &gt; 
&gt; &gt;        - Look at the consensus; see if you're listed.
&gt; &gt; 
&gt; &gt;        - Wait a while, see if things get better.
&gt; &gt; 
&gt; &gt;        - Download the votes from all the authorities, and see how they
&gt; &gt;          voted.  Try to figure out why.
&gt; 
&gt; Mere mortals can't do this step either. It involves fetching a secret
&gt; only-mentioned-in-the-spec URL ("/tor/status-vote/current/authority")
&gt; from a set of secret only-mentioned-in-the-code IP addresses.
&gt; 
&gt; &gt;        - If you think they'll listen to you, ask some authority
&gt; &gt;          operators to look you up in their mtbf files and logs to see
&gt; &gt;          why they voted as they did.
&gt; 
&gt; In practice, it's sufficient to ask an authority operator to go look
&gt; through the "v3-status-votes" file in their datadir that gets written
&gt; every voting period, and see what the recent votes have said about
&gt; your relay.
&gt; 
&gt; &gt;    This is far too hard.
&gt; &gt; 
&gt; &gt; Solution:
&gt; &gt; 
&gt; &gt;    We should add a new vote-like information-only document that
&gt; &gt;    authorities serve on request.  Call it a "vote info".  It is
&gt; &gt;    generated at the same time as a vote, but used only for
&gt; &gt;    determining why a server voted as it did.  It is served from
&gt; &gt;    /tor/status-vote-info/current/authority[.z]
&gt; &gt; 
&gt; &gt;    It differs from a vote in that:
&gt; &gt; 
&gt; &gt;    * Its vote-status field is 'vote-info'.
&gt; &gt; 
&gt; &gt;    * It includes routers that the authority would not include
&gt; &gt;      in its vote.
&gt; &gt; 
&gt; &gt;      For these, it includes an "omitted" line with an English
&gt; &gt;      message explaining why they were omitted.
 [...]
&gt; &gt;    * It includes info on routers all of whose descriptors that
&gt; &gt;      were uploaded but rejected over the past few hours.  The
&gt; &gt;      "r" lines for these are the same as for regular routers.
&gt; &gt;      The other lines are omitted for these routers, and are
&gt; &gt;      replaced with a single "rejected" line, explaining (in
&gt; &gt;      English) why the router was rejected.
&gt; 
&gt; How does the 'omitted' line differ from the 'rejected' line?

An omitted router is one that we know a descriptor for but don't want
to include in our vote (usually because it isn't running).  A rejected
descriptor is one that we refused to even store when it was uploaded
to us.

&gt; Also, this reminds me of a wishlist item that Robert Hogan had a while
&gt; back. He wants to know how many Tors are configured to be relays, but
&gt; fail their self-reachability checks, so don't even try to publish. If
&gt; it's hundreds or thousands, that means we should work harder to help
&gt; users learn that they're not helping out in the way they think they are.

Sounds like something that could use a proposal, yeah.

&gt; &gt;    A status site (like Torweather or Torstatus or another
&gt; &gt;    tool) can poll these files when they are generated, collate
&gt; &gt;    the data, and make it available to server operators.
&gt; 
&gt; Sounds like a fine plan. I agree that this would be a helpful feature
&gt; to have. But it's also not upgrade-path-critical in the way that a lot
&gt; of the other pending proposals are -- we could do it in 0.2.2 or 0.2.3
&gt; or later and nothing else would have to change to accommodate.

Agreed.

&gt; Also, it can be done pretty well by a) teaching users to read their logs,
&gt; which they're already not so bad at if they're the sort of users who know
&gt; how to realize that this vote-info stuff exists, and b) teaching sites
&gt; like torstatus to fetch the secret URLs from the secret IP addresses and
&gt; crunch the vote data that's already available. This proposal only really
&gt; adds help for folks who can't find their logs, and folks who want to
&gt; know why they're not marked Stable (answer: "you're not stable enough;
&gt; oh, and bug 969").

We can maybe also add some controller features to substitute for (a)
with people who use guis.

&gt; So: if you are itching to do it (or somebody else is), by all means go
&gt; for it. But if it seems like a big pile of hassle (and some of the ideas
&gt; above are pretty invasive and tricky to do efficiently), feel free to
&gt; put it off indefinitely.
&gt;
&gt; Here's an alternative proposal: I set up a cron job on moria to copy
&gt; moria1's v3-status-votes file to someplace web-accessible, and then we
&gt; tell the torstatus folks that they can fetch it and parse it if they
&gt; want to?

Sounds like a good start.  It would be even better to keep a
(rolling?) backlog of status votes, so that we can look into questions
like "why is this server only listed in 1/3 consensuses?"

I think I'll decide that I agree with you on the relative non-urgency
of this, and put it off until somebody feels like doing it.

yrs,
-- 
Nick
</body></email><email><emailId>20090621140509</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-21 14:05:09-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Sun, Jun 14, 2009 at 01:05:18AM -0400, Roger Dingledine wrote:
&gt; &gt; * We'd like to avoid having little changes in measured bandwidth
&gt; &gt;   result in changes to the consensus, since we'd like to be able to
&gt; &gt;   transfer consensus diffs.  Thus, let's round our votes to the
&gt; &gt;   first N significant bits.
&gt; &gt;   
&gt; &gt;   In other words, if we've observed a bandwidth of 28789 bytes for a
&gt; &gt;   node, that's  111 0000 0111 0101.   We round that down to 111 0000
&gt; &gt;   0000 0000, and declare 26872.
&gt; &gt; 
&gt; &gt;   This is better than rounding to the nearest 1k, since a 1k change is
&gt; &gt;   very significant for low values, and relatively frequent for high
&gt; &gt;   values.
&gt; 
&gt; Ok, but another constraint here is that users want to look at the numbers
&gt; in the consensus and find them intuitive. Can we take the resulting
&gt; number (26872) and round it off to 26? That will take care of an unending
&gt; stream of users wondering why the heck it says 26872. As a side effect,
&gt; the status stanzas get smaller too.

Mike and I decided that for now the algorithm can be: take the first
two or three significant digits, and zero out (rounding up or down)
the rest of the digits.

In the future the voters should consider the current value in the
consensus and only vote a change if it has changed "enough" -- either
a significant fraction of the vote, or a significant fraction of the
total network capacity. More spec'ing needs to be done there.

What really needs to get solidified is the client side, since
that's harder to change. Right now the consensus uses bandwidths in
kilobytes. That is, they drop the last 3 digits (technically they divide
by 1024, but I'm going to pretend that's the same). Mike on the other
hand would rather have the bandwidth in the consensus be bytes -- it
doesn't hurt to have "000" in each status (since we use compression),
and it might give us some flexibility later.

In the interest of getting 0.2.1.x out the door, I say we leave it as
KB for now. I've pushed a patch to my "consensus-bandwidths" branch on
moria that makes clients start using it. Nick, please merge to master
and maint-0.2.1 whenever you like.

Then we can migrate to a different format later -- for example bundled
with the switch to the microdesc consensus flavor.

--Roger

</body></email><email><emailId>20090626235251</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-06-26 23:52:51-0400</timestampReceived><subject>Re: Single hop connections?</subject><body>

On Fri, Jun 26, 2009 at 02:39:08PM -0400, Prithula Dhungel wrote:
&gt;   Thanks for the quick response. I am starting to do a project related to
&gt; Tor that would require me to build 1-hop circuits and communicate from my OP
&gt; to a webserver via the one single OR.

Tor relays by default shouldn't let you exit from them after only one hop.
See the third paragraph of:
https://wiki.torproject.org/noreply/TheOnionRouter/TorFAQ#VariablePathLength

If you want to set up a relay that allows one-hop exits, have it set
AllowSingleHopExits in its torrc. Then its server descriptor will
indicate to the client that it's willing to allow them.

(Alas, the checks in the code to prevent single-hop exits are not as
thorough as they should be -- see e.g. proposal 163:
http://archives.seul.org/or/dev/May-2009/msg00019.html
http://archives.seul.org/or/dev/Jun-2009/msg00018.html
)

--Roger


</body></email><email><emailId>20090503210345</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-05-03 21:03:45-0400</timestampReceived><subject>Re: Dropping version 0 hidden service descriptors</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/03/2009 08:49 PM, Nick Mathewson wrote:
&gt; Seems plausible.  So, the effect is that 0.1.2 clients won't be able
&gt; to use hidden services from 0.2.2 hidden servers, and vice versa?  It
&gt; doesn't sound disastrous.  Nobody should be using 0.1.2 anyway.

Yes.

&gt; Two questions: 
&gt;   1) Do we have some idea of what fraction of hidden services are
&gt;      still v0 only?

Not really. I'd guess that the fraction of v0 only hidden services is
similar to the fraction of 0.1.x client versions in the network (unless
many people running 0.2.x use the HiddenServiceVersion config option to
make their service v0 only, which I doubt). As an approximation, we
might assume that the fraction of 0.1.x clients is similar to the
fraction of 0.1.x relays in the network which is 15% (long shot, I
know). So, 15% of the current clients will not be able to access newly
setup hidden services on 0.2.2.x, and new clients on 0.2.2.x cannot
access 15% of the current hidden services. Acceptable or too early to
change? Your call.

&gt;   2) Did you test that this works with 0.2.0 clients and hidden servers?

Yes. I think I tried all possible combinations. No guarantee that I
didn't overlook something, though.

Best,
- --Karsten

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkn+Bq0ACgkQ0M+WPffBEmVPWQCfZqGx03HZCBr1olZ5Ux+UYP7B
N8oAoMFJqapUa/Fhw2qvTO7Pxj4v3zoN
=4v6H
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090508162157</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-05-08 16:21:57-0400</timestampReceived><subject>Attn controller developers: Removing old event formats in 0.2.2.</subject><body>

Hi, all!  If you're writing a controller, I've probably been bugging
you to make sure you are using the EXTENDED_EVENTS and LONG_NAMES
features.  As of 0.2.2.x, I'm planning to make both of them always on
so we no longer need to support the old controller event formats.

To refresh, the LONG_NAMES format is necessary to keep a good idea of
which nodes are which when their named-ness could be in flux, and the
EXTENDED_EVENTS format allows us to add new KEY=VALUE elements to
controller events without breaking existing controllers.

You can try this out in the branch "remove-old-event-fmts" from
my public repository at git://git.torproject.org/~nickm/git/tor.
Please let me know if it turns out to be problematic; I'll merge it
into the master repository if nobody has objected in the next while.

peace,
-- 
Nick
</body></email><email><emailId>20090512201036</emailId><senderName></senderName><senderEmail>bigstaar</senderEmail><timestampReceived>2009-05-12 20:10:36-0400</timestampReceived><subject>unsubscribe</subject><body>


-- 
Neu: GMX FreeDSL Komplettanschluss mit DSL 6.000 Flatrate + Telefonanschluss für nur \
17,95 Euro/mtl.!* http://dslspecial.gmx.de/freedsl-surfflat/?ac=OM.AD.PD003K11308T4569a



</body></email><email><emailId>20090513020308</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-13 02:03:08-0400</timestampReceived><subject>Re: Proposal 160: Authorities vote for bandwidth offsets in consensus</subject><body>

On Tue, May 12, 2009 at 03:44:36PM -0700, Mike Perry wrote:
 [...]
&gt; &gt; It makes more sense just to let bandwidth mean bandwidth.  If we want
&gt; &gt; to have measured bandwidth count for more than reported bandwidth,
&gt; &gt; let's have an optional flag on the vote line that looks like:
&gt; &gt; 
&gt; &gt;    w Bandwidth=X Measured=1
&gt; &gt; 
&gt; &gt; This way the median actually -is- the median.  See below for my
&gt; &gt; suggested voting algorithm.
&gt; 
&gt; Ok, just FYI, the bandwidth measurements are actually computed as the
&gt; ratio of the average stream bandwidth through a node to the average
&gt; stream bandwidth observed for nodes of similar reported capacity (or
&gt; the average of the network as a whole). 
&gt; 
&gt; I'll be detailing the exact nature of this computation in Proposal 161
&gt; today, but the end result of the measurement is actually just a
&gt; floating point value that is computed independent of the reported
&gt; bandwidth. It only becomes a bandwidth value once we multiply it
&gt; against a reported bandwidth for a node. I'm guessing the value we
&gt; would use for this multiplication would be the reported value we saw
&gt; during the scan.

Hm.  Let's come back to this issue when your proposal is out.  I've
got some questions about your approach (it isn't what I thought you
were doing), but it seems stupid for me to bring them up before I've
actually seen what the approach is.

[As it is, I don't see the bandwidth values in the consensus as
bandwidths _per se_ so much as I see them as recommended weights for
node selection, that happen to be scaled the same as bandwidths.  But
that's more a matter of how to think about it than a matter of how it
actually works.]

 [...]
&gt; &gt;   This is better than rounding to the nearest 1k, since a 1k change is
&gt; &gt;   very significant for low values, and relatively frequent for high
&gt; &gt;   values.
&gt; 
&gt; Ok. If we are voting on bandwidths, should we do this in the python or
&gt; in Tor?

It doesn't matter much to me.  Might as well do it in Tor for
consistency, since it feels more like part of "How to publish and vote
on bandwidths" than it feels like "How to estimate bandwidths."  I'd
think that the bandwidth estimator should give Tor the most accurate
estimate it can, and the authority can figure out what to do with it
from there.

yrs,
-- 
Nick
</body></email><email><emailId>20090513024828</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2009-05-13 02:48:28-0400</timestampReceived><subject>Proposal: Computing Bandwidth Adjustments</subject><body>


Title: Computing Bandwidth Adjustments
Author: Mike Perry
Created: 12-May-2009
Target: 0.2.2.x


1. Motivation

  There is high variance in the performance of the Tor network. Despite 
  our efforts to balance load evenly across the Tor nodes, some nodes are
  significantly slower and more overloaded than others.

  Proposal 160 describes how we can augment the directory authorities to 
  vote on measured bandwidths for routers. This proposal describes what
  goes into the measuring process.


2. Measurement Selection

  The general idea is to determine a load factor representing the ratio
  of the capacity of measured nodes to the rest of the network. This load 
  factor could be computed from three potentially relevant statistics: 
  circuit failure rates, circuit extend times, or stream capacity.

  Circuit failure rates and circuit extend times appear to be
  non-linearly proportional to node load. We've observed that the same
  nodes when scanned at US nighttime hours (when load is presumably
  lower) exhibit almost no circuit failure, and significantly faster
  extend times than when scanned during the day. 

  Stream capacity, however, is much more uniform, even during US
  nighttime hours. Moreover, it is a more intuitive representation of 
  node capacity, and also less dependent upon distance and latency 
  if amortized over large stream fetches.
 

2. Average Stream Bandwidth Calculation
 
  The average stream bandwidths are obtained by dividing the network
  into 3% slices according to advertised node bandwidth, yielding 
  about 45 nodes per slice in the current network.

  Two hop circuits are built using nodes from the same slice, and a large
  file is downloaded via these circuits. This process is repeated
  several hundred times, and average stream capacities are assigned to
  each node from these results.


3. Ratio Calculation Options

  There are two options for deriving the ratios themselves. They can
  be obtained by dividing each nodes' average stream capacity by
  either the average for the slice, or the average for the network as a
  whole.

  Dividing by the network-wide average has the advantage that it will
  account for issues related to unbalancing between higher vs lower 
  capacity, such as Steven Murdoch's queuing theory weighting result.

  Dividing by the slice average has the advantage that many scans can
  be run in parallel from a single authority, and that results are
  typically available sooner after a given scan takes place.


3. Ratio Filtering

  After the base ratios are calculated, a second pass is performed
  to remove any streams with nodes of ratios less than X=0.5 from
  the results of other nodes. In addition, all outlying streams
  with capacity of one standard deviation below a node's average
  are also removed.

  The final ratio result will be calculated as the maximum of 
  these two resulting ratios if both are less than 1.0, the minimum
  if both are greater than 1.0, and the mean if one is greater
  and one is less than 1.0.


4. Security implications

  The ratio filtering will deal with cases of sabotage by dropping
  both very slow outliers in stream average calculations, as well
  as dropping streams that used very slow nodes from the calculation
  of other nodes.

  This scheme will not address nodes that try to game the system by
  providing better service to scanners. The scanners can be detected
  at the entry by IP address, and at the exit by the destination fetch.

  Measures can be taken to obfuscate and separate the scanners' source
  IP address from the directory authority IP address. For instance,
  scans can happen offsite and the results can be rsynced into the
  authorities.  The destination fetch can also be obscured by using SSL
  and periodically changing the large document that is fetched. 

  Neither of these methods are foolproof, but such nodes can already
  lie about their bandwidth to attract more traffic, so this solution
  does not set us back any in that regard.


4. Integration with Proposal 160

  The final results will be produced for the voting mechanism
  described in Proposal 160 by multiplying the derived ratio by 
  the average observed advertised bandwidth during the course of the
  scan. This will produce a new bandwidth value that will be 
  output into a file consisting of lines of the form:

  &lt;node-idhex&gt; SP new_bandwidth NL

  This file can be either copied or rsynced into a directory readable
  by the directory authority.




-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20090513104038</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2009-05-13 10:40:38-0400</timestampReceived><subject>Re: Proposal 161: Computing Bandwidth Adjustments</subject><body>


Thus spake Nick Mathewson (nickm@torproject.org):

&gt; On Tue, May 12, 2009 at 09:46:05PM -0700, Mike Perry uttered:
&gt; &gt; Thus spake Nick Mathewson (nickm@torproject.org):
&gt;  [...]
&gt; &gt; &gt; There are some magic numbers here: Why 3%?  How large are these files
&gt; &gt; &gt; and how often are they downloaded?  Why "several hundred"?  Is the
&gt; &gt; &gt; "several hundred" a function of the "45" above?
&gt; &gt; 
&gt; &gt; Currently no. I've been meaning to do some statistics on how long it
&gt; &gt; takes to converge. Eyeballing seems to indicate the filtered values
&gt; &gt; converge after about 100 fetches or so, or about 3-4 per node. I've
&gt; &gt; been doing runs of 250 just for good measure.
&gt; 
&gt; As discussed on IRC, we should see if we can get away with fetching
&gt; smaller files to test the weaker slices. If we can, hooray for us!  If
&gt; it doesn't work, too bad. :/
&gt; 
&gt; As for the slice size, it seems that maybe a quasi-constant slice size
&gt; would work better than having it be fixed at 3% of the network.  That
&gt; way, we always send the same amount of traffic per node, rather than
&gt; getting sparser and sparser as the slices get bigger but our traffic
&gt; stays the same.

Ok, it should be fairly easy to set this at slices of 50 nodes each.
It gets a bit more complicated if I would need to grow the slices
to include at least N exit nodes, but we seem to have at least 10 exit
nodes in every 50 node slice anyway.

Also, with respect to the 250 fetches, it should be possible to write
a new node generator type that attempts to keep the circuit chosen
count equal for each node, and it should also be fairly
straight-forward to stop the scan once every node has been chosen for
at least 7 circuits.

&gt; &gt; &gt; I want to see a calculation for what fraction of the network capacity
&gt; &gt; &gt; we expect to use for this testing.  I wouldn't expect it to be over a
&gt; &gt; &gt; percent, but I'd like to see the math to prove it.
&gt; &gt; 
&gt; &gt; This is a function of how much we parallelize and how many scanners we
&gt; &gt; have. Right now, there is 0 parallelization built in, which means that
&gt; &gt; each scanner takes up approximately 20-50Kbytes/sec of two nodes at a
&gt; &gt; time. This is compared to the 120Mbytes/sec of exit capacity Tor
&gt; &gt; currently has.
&gt; &gt;  
&gt; &gt; &gt; Also, how long does it take to run these tests over the network?  If
&gt; &gt; &gt; it takes much longer than a consensus interval, we should think about
&gt; &gt; &gt; what happens if a node's advertised capacity changes greatly, and
&gt; &gt; &gt; whether we want to treat newer measurements as more accurate.
&gt; &gt; 
&gt; &gt; Each slice takes around 3-6 hours. The entire network can take as long
&gt; &gt; as a week.. Hence the desire to parallelize..
&gt; 
&gt; My intuition says that unless we scan the whole network every two days
&gt; (or ideally less), our data will likely be useless.
&gt; 
&gt; What if, instead of running in a batch mode, we were constantly
&gt; scanning and iteratively refining our guesses for ratios, discounting
&gt; old data as newer data arrived?  We'd still want to parallelize some,
&gt; but we wouldn't run into the problem of having some nodes' estimated
&gt; values be far more accurate than others.

Hrmm.. So the continually-updating idea is not that hard, thanks to
our SQL-based stat store.

We can then fully parallelize and output a first pass with filtered
averages for each node. A second script can then compute a
network-wide average of filtered stream averages, and then use that to
produce ratios and then bandwidths. 

This would then solve both our desire for quick scans and for
network-wide ratios.

But note this won't be cheap memory-wise. We'd need a new tor
client instance, a new speedracer instance, and a new metatroller
instance for each slice. That's at least 12m + 5m + 50m for each
slice. That quickly adds up to around 2GB for doing the entire network 
in parallel. I can see about reducing the metatroller overhead, but
with all the statistics we need to load in and out of the SQL tables,
its probably not going to be easy. 

It will also require about 600Kbytes/sec, or almost 5Mbit up+down per
authority (based on an average stream capacity of 20Kbytes/sec and 30
slices).

We can try to reach some middle-ground where each parallel scanner
scans like 15% of the network or so, as opposed to 3%, but the way the
restrictions get set up, we can only scan a particular 3% slice at a
time. By the time we wrap through the 15%, we probably would just want
to discard all the prior scan results and start fresh.

&gt; &gt; &gt; (Crazy idea 1: If the values change too fast or slow, we could
&gt; &gt; &gt; exponentiate the ratios out of the algorithm before using them.
&gt; &gt; &gt; Slightly less crazy idea 2: if the values change too fast, we could do
&gt; &gt; &gt; a standard time-weighted average, where we compute the new declared
&gt; &gt; &gt; bandwidth BW' as a weighted average of the old declared bandwidth and
&gt; &gt; &gt; the new measured bandwidth.)
&gt; &gt; 
&gt; &gt; Yeah, I like idea 2, basically what you mentioned in 160. This would
&gt; &gt; be done Tor-end, not scanner end, right?
&gt; 
&gt; I don't have a strong feeling about that.  To me, it seems easier to
&gt; do it at the scanner end, or as a processing step between the scanner
&gt; end and the authorities... but that's just because I'm thinking of the
&gt; scanner stuff as easier to change if we think of a better algorithm.

Ok.

-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20090515170541</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-15 17:05:41-0400</timestampReceived><subject>Proposal 162: Publish the consensus in multiple flavors</subject><body>

Filename: 162-consensus-flavors.txt
Title: Publish the consensus in multiple flavors
Author: Nick Mathewson
Created: 14-May-2009
Target: 0.2.2
Status: Open


Overview:

   This proposal describes a way to publish each consensus in
   multiple simultaneous formats, or "flavors".  This will reduce the
   amount of time needed to deploy new consensus-like documents, and
   reduce the size of consensus documents in the long term.

Motivation:

   In the future, we will almost surely want different fields and
   data in the network-status document.  Examples include:
      - Publishing hashes of microdescriptors instead of hashes of
        full descriptors (Proposal 158).
      - Including different digests of descriptors, instead of the
        perhaps-soon-to-be-totally-broken SHA1.

   Note that in both cases, from the client's point of view, this
   information _replaces_ older information.  If we're using a
   SHA256 hash, we don't need to see the SHA1.  If clients only want
   microdescriptors, they don't (necessarily) need to see hashes of
   other things.

   Our past approach to cases like this has been to shovel all of
   the data into the consensus document.  But this is rather poor
   for bandwidth.  Adding a single SHA256 hash to a consensus for
   each router increases the compressed consensus size by 47%.  In
   comparison, replacing a single SHA1 hash with a SHA256 hash for
   each listed router increases the consensus size by only 18%.

Design in brief:

   Let the voting process will remain as it is, until a consensus is
   generated.  With future versions of the voting algorithm, instead
   of just a single consensus being generated, multiple consensus
   "flavors" are produced.

   Consensuses (all of them) include a list of which flavors are
   being generated.  Caches fetch and serve all flavors of consensus
   that are listed, regardless of whether they can parse or validate
   them, and serve them to clients.  Thus, once this design is in
   place, we won't need to deploy more cache changes in order to get
   new flavors of consensus to be cached.

   Clients download only the consensus flavor they want.

A note on hashes:

   Everything in this document is specified to use SHA256, and to be
   upgradeable to use better hashes in the future.

Spec modifications:

   1. URLs and changes to the current consensus format.

   Every consensus flavor has a name consisting of a sequence of one
   or more alphanumeric characters and dashes.  For compatibility
   current descriptor flavor is called "ns".

   The supported consensus flavors are defined as part of the
   authorities' consensus method.

   For each supported flavors, every authority calculates another
   consensus document of as-yet-unspecified format, and exchange
   detached signatures for these documents as in the current consensus
   design.

   In addition to the consensus currently served at
   /tor/status-vote/(current|next)/consensus.z , authorities serve
   another consensus of each flavor "F" from the location
   /tor/status-vote/(current|next)/F/consensus.z.

   When caches serve these documents, they do so from the same
   locations.

   2. Document format: generic consensus.

   The format of a flavored consensus is as-yet-unspecified, except
   that the first line is:
      "network-status-version" SP version SP flavor NL

   where version is 3 or higher, and the flavor is a string
   consisting of alphanumeric characters and dashes, matching the
   corresponding flavor listed in the unflavored consensus.

   3. Document format: detached signatures.

   In addition to the current detached signature format, we allow
   the first line to take the form,
      "consensus-digest" SP flavor SP 1*(Algname "=" Digest) NL

   The consensus-signatures URL should contain the signatures
   for _all_ flavors of consensus.

   4. The consensus index:

   Authorities additionally generate and serve a consensus-index
   document.  Its format is:

       Header ValidAfter ValidUntil Documents Signatures

       Header = "consensus-index" SP version NL
       ValidAfter = as in a consensus
       ValidUntil = as in a consensus
       Documents = Document*
       Document = "document" SP flavor SP SignedLength
                                    1*(SP AlgorithmName "=" Digest) NL
       Signatures = Signature *
       Signature = "directory-signature" SP algname SP identity
                           SP signing-key-digest NL signature

    There must be one Document line for each generated consensus flavor
    Each Document line describes the length of the signed portion of
    a consensus (the signatures themselves are not included), along
    with one or more digests of that signed portion.  Digests are
    given in hex.  The algorithm "sha256" MUST be included; others
    are allowed.

    The algname part of a signature describes what algorithm was
    used to hash the identity and signing keys, and to compute the
    signature.  The algorithm "sha256" MUST be recognized;
    signatures with unrecognized algorithms MUST be ignored.
    (See below).

    The consensus index is made available at
       /tor/status-vote/(current|next)/consensus-index.z.

    Caches should fetch this document so they can check the
    correctness of the different consensus documents they fetch.
    They do not need to check anything about an unrecognized
    consensus document beyond its digest.

    4.1. The "sha256" signature format.

    The 'SHA256' signature format for directory objects is defined as
    the RSA signature of the OAEP+-padded SHA256 digest of the SHA256
    digest of the the item to be signed.  When checking signatures,
    the signature MUST be treated as valid if the signed material
    begins with SHA256(SHA256(document)); this allows us to add other
    data later.

Considerations:

    - We should not create a new flavor of consensus when adding a
      field wouldn't be too onerous.

    - We should not proliferate flavors lightly: clients will be
      distinguishable based on which flavor they download.

Migration:

    - Stage one: authorities begin generating and serving
      consensus-index files.

    - Stage two: Caches begin downloading consenusus-index files,
      validating them, and using them to decide what flavors of
      consensus documents to cache.  They download all listed
      documents, and compare them to the digests given in the
      consensus.

    - Stage three: Once we want to make a significant change to the
      consensus format, we deploy another flavor of consensus at the
      authorities.  This will immediately start getting cached by the
      caches, and clients can start fetching the new flavor without
      waiting a version or two for enough caches to begin supporting
      it.


</body></email><email><emailId>20090515173921</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-15 17:39:21-0400</timestampReceived><subject>Re: revised Proposal 161: Computing bandwidth adjustments</subject><body>

I've pushed Mike's revisions to proposal 161 based on discussion
here.  I have a few questions on the revised version:

&gt;   Two hop circuits are built using nodes from the same slice, and a large
&gt;   file is downloaded via these circuits. For nodes in the first 15% of the
&gt;   network, a 500K file will be used. For nodes in the next 15%, a 250K file
&gt;   will be used. For nodes in next 15%, a 100K file will be used. The 
&gt;   remainder of the nodes will fetch a 75K file.[1]

The "first" 15%?   Do you mean the "fastest"?  And what does the [1]
refer to?

&gt;   This process is repeated 250 times, and average stream capacities are 
&gt;   assigned to each node from these results. 
&gt;   
&gt;   In the future, a node generator type can be created to ensure that
&gt;   each node is chosen to participate in an equal number of circuits,
&gt;   and the selection will continue until every live node is chosen
&gt;   to participate in at least 7 circuits.

By the way, what does the algorithm do with non-running nodes now?
Does it retry them as it goes?  Does a circuit that failed to build
mean anything for the node's capacity?  Does it count to the number of
circuits built?

Also, we'll want to think more about this "until every live node is chosen
to participate in at least 7 circuits" thing before we do it; if 7
random circuits per live node are necessary and sufficient to measure
the nodes' capacities, then we can get away with less (or will have to
handle more) circuits than we're currently planning.  [For example, if
all 50 nodes are live, we'll need about 354 circuits on average.  If
only 30 are live, we'll expect to be done after 201 circuits.]

 [...]
&gt;   This will produce a new bandwidth value that will be output into a 
&gt;   file consisting of lines of the form:
&gt; 
&gt;   node_id=&lt;idhex&gt; SP bw=&lt;Bw_new&gt; NL
&gt;   
&gt;   This file can be either copied or rsynced into a directory readable
&gt;   by the directory authority.

When documenting and building this format, remember to note that
programs parsing it MUST ignore unrecognized line formats and
unrecognized fields on the lines they do recognize.

Otherwise, this looks fine to me.

-- 
Nick 
</body></email><email><emailId>20090522065953</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-22 06:59:53-0400</timestampReceived><subject>Proposal 163: Detecting whether a connection comes from a client</subject><body>

Filename: 163-detecting-clients.txt
Title: Detecting whether a connection comes from a client
Author: Nick Mathewson
Created: 22-May-2009
Target: 0.2.2
Status: Open


Overview:

   Some aspects of Tor's design require relays to distinguish
   connections from clients from connections that come from relays.
   The existing means for doing this is easy to spoof.  We propose
   a better approach.

Motivation:

   There are at least two reasons for which Tor servers want to tell
   which connections come from clients and which come from other
   servers:

     1) Some exits, proposal 152 notwithstanding, want to disallow
        their use as single-hop proxies.
     2) Some performance-related proposals involve prioritizing
        traffic from relays, or limiting traffic per client (but not
        per relay).

   Right now, we detect client vs server status based on how the
   client opens circuits.  (Check out the code that implements the
   AllowSingleHopExits option if you want all the details.)  This
   method is depressingly easy to fake, though.  This document
   proposes better means.

Goals:

   To make grabbing relay privileges at least as difficult as just
   running a relay.

   In the analysis below, "using server privileges" means taking any
   action that only servers are supposed to do, like delivering a
   BEGIN cell to an exit node that doesn't allow single hop exits,
   or claiming server-like amounts of bandwidth.

Passive detection:

   A connection is definitely a client connection if it takes one of
   the TLS methods during setup that does not establish an identity
   key.

   A circuit is definitely a client circuit if it is initiated with
   a CREATE_FAST cell, though the node could be a client or a server.

   A node that's listed in a recent consensus is probably a server.

   A node to which we have successfully extended circuits from
   multiple origins is probably a server.

Active detection:

   If a node doesn't try to use server privileges at all, we never
   need to care whether it's a server.

   When a node or circuit tries to use server privileges, if it is
   "definitely a client" as per above, we can refuse it immediately.

   If it's "probably a server" as per above, we can accept it.

   Otherwise, we have either a client, or a server that is neither
   listed in any consensus or used by any other clients -- in other
   words, a new or private server.

   For these servers, we should attempt to build one or more test
   circuits through them.  If enough of the circuits succeed, the
   node is a real relay.  If not, it is probably a client.

   While we are waiting for the test circuits to succeed, we should
   allow a short grace period in which server privileges are
   permitted.  When a test is done, we should remember its outcome
   for a while, so we don't need to do it again.

Why it's hard to do good testing:

   Doing a test circuit starting with an unlisted router requires
   only that we have an open connection for it.  Doing a test
   circuit starting elsewhere _through_ an unlisted router--though
   more reliable-- would require that we have a known address, port,
   identity key, and onion key for the router.  Only the address and
   identity key are easily available via the current Tor protocol in
   all cases.

   We could fix this part by requiring that all servers support
   BEGIN_DIR and support downloading at least a current descriptor
   for themselves.

Open questions:

   What are the thresholds for the needed numbers of circuits
   for us to decide that a node is a relay?

      [Suggested answer: two circuits from two distinct hosts.]

   How do we pick grace periods?  How long do we remember the
   outcome of a test?

      [Suggested answer: 10 minute grace period; 48 hour memory of
      test outcomes.]

   If we can build circuits starting at a suspect node, but we don't
   have enough information to try extending circuits elsewhere
   through the node, should we conclude that the node is
   "server-like" or not?

      [Suggested answer: for now, just try making circuits through
      the node.  Extend this to extending circuits as needed.]

</body></email><email><emailId>20090522070042</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-22 07:00:42-0400</timestampReceived><subject>Proposal 164: Reporting the status of server votes</subject><body>

Filename: 164-reporting-server-status.txt
Title: Reporting the status of server votes
Author: Nick Mathewson
Created: 22-May-2009
Target: 0.2.2
Status: Open


Overview:

   When a given node isn't listed in the directory, it isn't always easy
   to tell why.  This proposal suggest a quick-and-dirty way for
   authorities to export not only how they voted, but why, and a way to
   collate the information.

Motivation:

   Right now, if you want to know the reason why your server was listed
   a certain way in the Tor directory, the following steps are
   recommended:

       - Look through your log for reports of what the authority said
         when you tried to upload.

       - Look at the consensus; see if you're listed.

       - Wait a while, see if things get better.

       - Download the votes from all the authorities, and see how they
         voted.  Try to figure out why.

       - If you think they'll listen to you, ask some authority
         operators to look you up in their mtbf files and logs to see
         why they voted as they did.

   This is far too hard.

Solution:

   We should add a new vote-like information-only document that
   authorities serve on request.  Call it a "vote info".  It is
   generated at the same time as a vote, but used only for
   determining why a server voted as it did.  It is served from
   /tor/status-vote-info/current/authority[.z]

   It differs from a vote in that:

   * Its vote-status field is 'vote-info'.

   * It includes routers that the authority would not include
     in its vote.

     For these, it includes an "omitted" line with an English
     message explaining why they were omitted.

   * For each router, it includes a line describing its WFU and
     MTBF.  The format is:

       "stability &lt;mtbf&gt; up-since='date'"
       "uptime &lt;wfu&gt; down-since='date'"

   * It describes the WFU and MTBF thresholds it requires to
     vote for a given router in various roles in the header.
     The format is:

       "flag-requirement &lt;flag-name&gt; &lt;field&gt; &lt;op&gt; &lt;value&gt;"

     e.g.

       "flag-requirement Guard uptime &gt; 80"

   * It includes info on routers all of whose descriptors that
     were uploaded but rejected over the past few hours.  The
     "r" lines for these are the same as for regular routers.
     The other lines are omitted for these routers, and are
     replaced with a single "rejected" line, explaining (in
     English) why the router was rejected.


   A status site (like Torweather or Torstatus or another
   tool) can poll these files when they are generated, collate
   the data, and make it available to server operators.

Risks:

   This document makes no provisions for caching these "vote
   info" documents.  If many people wind up fetching them
   aggressively from the authorities, that would be bad.
</body></email><email><emailId>20090522194747</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-22 19:47:47-0400</timestampReceived><subject>Older proposals in need of discussion: 149 ("Using data from NETINFO cells")</subject><body>

Last August I sent out proposal 149, but it never got much discussion
on this list.  (Looking at the archives, I can't find any.)  Here's
the paragraph that hasn't much been implemented:

   We need to think about attackers here.  Just because a router tells
   us that we have a given IP or a given clock skew doesn't mean that
   it's true.  We believe this information only if we've heard it from
   a majority of the routers we've connected to recently, including at
   least 3 routers chosen at random.  Routers only believe this
   information if the majority includes at least one authority.

This isn't so good:

   - It's less secure than we would like for clients.  If I can block
     your network connection selectively,  I can make you only connect
     to routers I control, who can lie to you about your IP and the
     time.

   - It's sometimes useless for clients.  If a client's timestamp is
     in the distant past or future, it may not believe in the quality
     of _any_ router info, and so not actually try to connect to
     anybody and learn the time via a NETINFO cell.  Or it might fail
     because the other side's x509 certs will look invalid.  Or it
     might fail because its own x509 certs will be invalid.

   - It's less functional than we want for servers.  Most servers
     don't go out of their way to talk to the authorities, and so they
     don't often get time/ip info this way.

So I propose that we amend 149 as follows:

   1) Clients and servers alike should believe the time from a netinfo
     if all of the following hold:
      - They have heard similar times from a majority of the servers
        they have connected to.
      - The majority contains at least 3 servers not in the same
        family.
      - A majority of the connections that the node has attempted were
        successful.       

   2) Clients don't care about their own IP.  Servers should consider
      testing an IP given from a netinfo cell if it meets the criteria
      for time differences in 1) above, and they don't already have a
      working IP.

   3) We should stop rejecting connections entirely because of expired
      or no-longer-valid x509 certificates.  Instead, we should allow
      the connection to continue, but not believe the identity of the
      other side.

   4) We should check the code to see what clients do with seemingly
      expired or future consensus documents.  Clients should always
      provisionally accept a consensus if it is newer than any
      consensus they have.  They should then contact nodes until they
      know what time it is.

Thoughts?
-- 
Nick


   
</body></email><email><emailId>20090526045557</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-05-26 04:55:57-0400</timestampReceived><subject>Re: Writing geoip stats to disk on directories</subject><body>

On Mon, May 25, 2009 at 11:45:51PM +0200, Karsten Loesing wrote:
&gt; My first idea is to synchronize request history periods with writing
&gt; down stats. This basically means writing down stats only when periods
&gt; end. The main reason is that we should ensure that only requests are
&gt; written to disk that have been measured over exactly 24 hours. Writing
&gt; down stats earlier might be problematic from an anonymity point of view.
&gt; And after a restart we don't pick up these values anyway. Longer times
&gt; (or in general different times than 24 hours) would complicate the
&gt; analysis to a certain extent. In terms of code that means dropping
&gt; DUMP_GEOIP_STATS_INTERVAL in main.c and dumping stats whenever we change
&gt; the request period.

That sounds like a great idea. More generally, we have three main
constraints here:

A) We want to not output any numbers until we have a sufficient number
of hours of data. Otherwise we risk providing an aggregate over too
small a time window.

B) We want to avoid the same problem on the other end. That is, if we
print the rolling 24 hour aggregate every 5 minutes, then people could
learn too much about what happened exactly 24 hours earlier.

C) We want to know the size of the interval that our statistics are over
(as opposed to "between 24 and 48 hours and I won't tell you which").

C') Optionally, we might also want the interval to be over exactly 24
hours, so we don't have to deal with time zone questions. (We'll never
totally get away from this issue, since we'll still wonder about weekends,
holidays, summers, etc.)

So it sounds like the new plan is "output nothing until you have 24
hours of data. Then output the 24 hours of data. Then 8 hours later,
add in the new 8 hours, drop the old 8 hours, and output the new last
24 hours of data. Repeat."

That solves (a) because we wait til we have enough data before outputting
anything; solves (b) because we drop data only in blocks of 8 hours,
which we hope is large enough; and solves (c) because every number we
get is for a 24-hour window.

Did I get it right?

If so, this approach sounds like what we should be doing both for the
geoip aggregate stats you write to the file and analyze, and also for
the aggregate stats that bridges collect.

&gt; Also, stats should be appended to the geoip-stats
&gt; file rather than replacing that file.

Also sounds good.

&gt; My next thought is whether or not we want to make the period length
&gt; configurable. From earlier measurements I found that the period length
&gt; of 8 hours (as defined in REQUEST_HIST_PERIOD) works fine. Also,
&gt; configurable period lengths might complicate analysis, too. If we want
&gt; to make the period length configurable, we should define a lower limit
&gt; of, say, 2 hours. Otherwise, people could compare subsequent
&gt; observations to learn more details about requests. Possible values for
&gt; period lengths would then be 2, 3, 4, 6, 8, 12, or 24 hours. But again,
&gt; do we need to make this configurable? And if so, should we use the
&gt; config option DirRecordUsageSaveInterval instead of REQUEST_HIST_PERIOD?

Don't make it configurable until you actually need it to be. It sounds
like you don't need it to be.

&gt; The next step would be to add the geoip-stats lines (or a subset of
&gt; them) to extra-info documents. I think a proposal for that would be in
&gt; place, but first I think it's fine to start with measuring on a few
&gt; nodes and working with files.

You mean for bridges, or for normal relays? I don't think we're at the
point yet where we want normal relays to turn on the ENABLE_GEOIP_STATS
compile-time flag. I want to be much more sure that we've got all the
details right first. (Like, have run it for several months at a test
relay and have a good handle on exactly what it's getting.)

Thanks!
--Roger

</body></email><email><emailId>20090527183426</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-27 18:34:26-0400</timestampReceived><subject>Rejecting proposal 134</subject><body>

I'm rejecting proposal 134 after a conversation with Peter.  The
max-clique idea is fundamentally flawed from a security POV.

Suppose that we have a clique of size N, and M hostile members in the
clique.  If these hostile members stop declaring trust for up to M-1
good members of the clique, the clique with the hostile members will
in it will be larger than the one without them. 

The M hostile members will constitute a majority of this new clique
when M &gt; (N-(M-1)) / 2, or when M &gt; (N + 1) / 3.  This breaks our
requirement that an adversary must compromise a majority of authorities
in order to control the consensus.

We talked about a simpler approach that I'll try to write up as a
proposal in the next day or two.

-- 
Nick
</body></email><email><emailId>20090529022154</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2009-05-29 02:21:54-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

On Thu, May 28, 2009 at 06:00:15PM -0400, Nick Mathewson wrote:
&gt; On Thu, May 28, 2009 at 05:02:09PM -0400, Paul Syverson wrote:
&gt; &gt; On Thu, May 28, 2009 at 04:23:57PM -0400, Nick Mathewson wrote:
&gt; &gt; &gt; On Thu, May 28, 2009 at 03:58:42PM -0400, Paul Syverson wrote:
&gt; &gt; &gt; &gt; Hi Nick et al.,
&gt; &gt; &gt; &gt; &gt; 
&gt; [...]
&gt; &gt; &gt; Here you're missing the line that says
&gt; &gt; &gt; 
&gt; &gt; &gt;    Once enough authorities list the new set as acceptable, we start
&gt; &gt; &gt;    having authorities stop listing the old set.  Once there are more
&gt; &gt; &gt;    listing the new set than the old set, the new set will win.
&gt; &gt; &gt; 
&gt; &gt; &gt; In other words, once the operators notice that enough authorities are
&gt; &gt; &gt; listing the set-minus-Bob, they manually stop listing
&gt; &gt; &gt; sets-including-Bob.  Assuming that there are N authorities (including
&gt; &gt; &gt; Bob), once N-1 authorities list the set without Bob, we need just 2
&gt; &gt; &gt; authorities to drop the set including Bob and we'll be fine.
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; I didn't miss the line. My point is that you won't ever get
&gt; &gt; any honest authorities to drop the set including Bob, so you will
&gt; &gt; never make it to 2 without changing something in the protocol.
&gt; &gt; if either of those two authorities drop the list that includes Bob,
&gt; &gt; they will not be honest (following the proposed protocol), because
&gt; &gt; they are supposed to prefer the voting set for which the number of
&gt; &gt; authorities that list themselves in it is higher not just the
&gt; &gt; one that is moving in the direction they would like to go.
&gt; &gt; It's the criterion for delisting a set that does not work.
&gt; 
&gt; Oh!  Okay, no, I've explained the protocol wrong.
&gt; 
&gt; When I say that authorities prefer the more-approved set, that _only
&gt; applies to choosing who the voters are in a given round of voting_.
&gt; It doesn't apply to deciding which sets to list in a vote.
&gt; 
&gt; Deciding which sets to list is a manual decision made by the authority
&gt; operators.  My intent was that the operator of an honest is absolutely
&gt; allowed to de-list an obsolete but larger set.  Authority operators
&gt; need to coordinate their actions here out-of-band.
&gt; 
&gt; Did that clear it up?
&gt; 

Yes and no. That's fine, but if they can coordinate on who is
an authority out-of-band, why is this protocol needed?

If by "coordinate their actions here out-of-band" you just meant
that they would agree the plan is to, e.g., drop Bob or, e.g., add
Charlie to the existing set once sufficient agreement has percolated
through, then we are in complete agreement except that I think
this should be explicitly included in the protocol to avoid confusion.

&gt; peace,

et cum spiritu tuo

(Won't you eat my sleazy pancakes just for Saintly Alphonzo)

-Paul
</body></email><email><emailId>20090531173827</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-31 17:38:27-0400</timestampReceived><subject>Re: Fix for #937 - support dynamic crypto acceleration engines</subject><body>

On Sat, May 30, 2009 at 03:29:17PM -0700, coderman wrote:

Hi!  This looks pretty good.  Just one thing:

   +  if ((old-&gt;HardwareAccel != new_val-&gt;HardwareAccel)
   +      || (old-&gt;AccelName != new_val-&gt;AccelName)
   +      || (old-&gt;AccelDir != new_val-&gt;AccelDir)) {

In C you can't compare strings with == and !=; you need to use
strcmp().

I've added a patch to fix this up, added a changelog entry, and merged
the patch.

-- 
Nick

</body></email><email><emailId>20090402015043</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-04-02 01:50:43-0400</timestampReceived><subject>Re: Another data set worth graphing: v3 status votes</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Roger,

On 04/01/2009 12:42 PM, Roger Dingledine wrote:
&gt; While you're working on metrics, it might be useful to take the
&gt; v3-status-votes file from gabelmoo's datadir (which contains all
&gt; the v3 networkstatus votes for the last consensus), and make a
&gt; graph for each status flag of which authority voted how for each
&gt; relay. I'm imagining relays on the x axis (the votes already sort
&gt; them by identity key I think), and booleans on the y axis, and six
&gt; colors for the six authorities. The votes ought to mostly overlap --
&gt; any significant differences might indicate further bugs. For example,
&gt; if some authorities have stopped voting correctly for Stable, that will
&gt; influence their Guard flag assignment too.

Sure, I made a first attempt to visualize the voting process for some of
the flags. Having all relays on the x axis made the graphs pretty hard
to read, if not impossible. Instead, I arranged the booleans in several
rows, so that all relays having a specific flag fit on one page. This
does not permit comparisons between flags, but maybe that will be step 2
after finding out why single flags behave as they do. Here's the PDF
(2.2 MB):

http://freehaven.net/~karsten/metrics/relayflags-2009-04-01.pdf

&gt; Doing the parsing and graphing in a mostly automated way will let us
&gt; easily rerun the test down the road to make sure that anomalies haven't
&gt; appeared.

The process is fully automated. It's the usual Java-R-LaTeX winning team
that takes only a few seconds to run. (I can upload the sources when we
are happy with the resulting graphs.)

&gt; A more interesting graph might be the average of votes from the authority
&gt; for that relay over some time period. Do we save votes currently, or
&gt; just consensuses?

We save both votes and consensuses. I can have a closer look at the
trends if there is something interesting we hope to find.

&gt; Not super high priority, unless it turns out to uncover a big bug, in
&gt; which case we'll want to go back in time and mark it high priority. ;)

The patterns I found are probably no big bugs, but they do look unusual.
Or they are features that I'm not aware of.

- --Karsten

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFJ1Bny0M+WPffBEmURAtApAJ4yHVVxtikJdAOwJoe9kkLK33nPIwCdEJEA
A0IBwNtNhCXTs/9XfX/45MI=
=4IvE
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090409204212</emailId><senderName>Christopher Davis</senderName><senderEmail>chrisd@mangrin.org</senderEmail><timestampReceived>2009-04-09 20:42:12-0400</timestampReceived><subject>Limiting Unused Connections</subject><body>

Hello,

I've been looking at bug 469, where servers are screwed after being
deprived of file descriptors in simple DoS attacks:

https://bugs.torproject.org/flyspray/index.php?id=469&amp;do=details

I've also had a chance to work on a small patch to limit unused
connections, which is copied below. It tries to work as Roger
suggested in his flyspray posting (which is a few years old now,
but still valid in concept, I think), and it also extends to cover
direct connections to the DirPort.

Basically, new connections to ORPort and DirPort are marked "unused"
until either something happens on the connection or the connection
is closed/freed. If there are too many unused conns from a single IP,
future connections are dropped quickly after accept().
The patch is currently unfinished. It's missing the configuration
directive, and the log levels/messages need to be reconsidered.

Is this work moving in the right direction, or should I consider
writing a proposal instead?

-- 
Christopher Davis
Mangrin Remailer Admin
PGP: 0x0F8DA163

Index: src/or/connection_or.c
===================================================================
--- src/or/connection_or.c	(revision 19229)
+++ src/or/connection_or.c	(working copy)
@@ -1160,6 +1160,8 @@
     or_handshake_state_free(conn-&gt;handshake_state);
     conn-&gt;handshake_state = NULL;
   }
+  if (tor_tls_is_server(conn-&gt;tls) &amp;&amp; TO_CONN(conn)-&gt;should_mark_used)
+    connection_mark_used(TO_CONN(conn));
   connection_start_reading(TO_CONN(conn));
   circuit_n_conn_done(conn, 1); /* send the pending creates, if any. */
 
Index: src/or/or.h
===================================================================
--- src/or/or.h	(revision 19229)
+++ src/or/or.h	(working copy)
@@ -927,6 +927,11 @@
   /** True iff we've called connection_close_immediate() on this linked
    * connection. */
   unsigned int linked_conn_is_closed:1;
+  /** True if this connection is currently considered unused and should be
+   * marked as used at some point. */
+  unsigned int should_mark_used:1;
+  /** True if this connection was marked used by connection_mark_used() */
+  unsigned int marked_used:1;
 
   int s; /**&lt; Our socket; -1 if this connection is closed, or has no
           * socket. */
@@ -3006,6 +3011,8 @@
 void connection_dump_buffer_mem_stats(int severity);
 void remove_file_if_very_old(const char *fname, time_t now);
 
+void connection_mark_used(connection_t *conn);
+
 /********************************* connection_edge.c *************************/
 
 #define connection_mark_unattached_ap(conn, endreason) \
Index: src/or/connection.c
===================================================================
--- src/or/connection.c	(revision 19229)
+++ src/or/connection.c	(working copy)
@@ -11,6 +11,7 @@
  **/
 
 #include "or.h"
+#include "ht.h"
 
 static connection_t *connection_create_listener(
                                struct sockaddr *listensockaddr,
@@ -39,9 +40,124 @@
  * Used to detect IP address changes. */
 static smartlist_t *outgoing_addrs = NULL;
 
+/** Map remote addreses to count of unused connections. */
+typedef struct unused_conns {
+  HT_ENTRY(unused_conns) node;
+  tor_addr_t addr;
+  uint16_t count;
+} unused_conns_t;
+
+static INLINE int
+unused_conns_eq(const unused_conns_t *uca, const unused_conns_t *ucb)
+{
+  return tor_addr_eq(&amp;uca-&gt;addr, &amp;ucb-&gt;addr);
+}
+
+static INLINE unsigned int
+unused_conns_hash(const unused_conns_t *uc)
+{
+  return tor_addr_hash(&amp;uc-&gt;addr);
+}
+
+static HT_HEAD(unused_conns_map, unused_conns)
+              unused_conns_map_root = HT_INITIALIZER();
+
+HT_PROTOTYPE(unused_conns_map, unused_conns, node, unused_conns_hash,
+              unused_conns_eq)
+HT_GENERATE(unused_conns_map, unused_conns, node, unused_conns_hash,
+              unused_conns_eq, 0.6, malloc, realloc, free)
+
 /**************************************************************/
 
 /**
+ * Find &lt;b&gt;addr&lt;/b&gt; in the unused conns hash table.
+ */
+static unused_conns_t *
+unused_conns_find(const tor_addr_t *addr)
+{
+  unused_conns_t search, *uc;
+
+  memset(&amp;search, 0, sizeof search);
+  tor_addr_copy(&amp;search.addr, addr);
+  uc = HT_FIND(unused_conns_map, &amp;unused_conns_map_root, &amp;search);
+
+  return uc;
+}
+
+/**
+ * Check that the count of unused conns from &lt;b&gt;addr&lt;/b&gt; is within limits,
+ * and then increment the count. If no entry for addr exists within the
+ * hash table, add it now.
+ */
+static int
+unused_conns_check_and_increment(const tor_addr_t *addr)
+{
+//XXX make this a configuration directive?
+#define MAX_UNUSED_CONNECTIONS 10
+
+  unused_conns_t *uc;
+
+  uc = unused_conns_find(addr);
+
+  if (uc) {
+    if (uc-&gt;count &gt;= MAX_UNUSED_CONNECTIONS)
+      return 0;
+    uc-&gt;count++;
+  } else {
+    uc = tor_malloc_zero(sizeof *uc);
+    tor_addr_copy(&amp;uc-&gt;addr, addr);
+    uc-&gt;count = 1;
+    HT_INSERT(unused_conns_map, &amp;unused_conns_map_root, uc);
+  }
+
+  log_warn(LD_NET, "increment unused conns %s, %u", fmt_addr(&amp;uc-&gt;addr),
+            (unsigned)uc-&gt;count);
+
+  return 1;
+}
+
+/**
+ * Decrement the count of unused conns for &lt;b&gt;addr&lt;/b&gt;. If there're no
+ * more conns left, remove it from the hash table.
+ */
+static void
+unused_conns_decrement(const tor_addr_t *addr)
+{
+  unused_conns_t *uc;
+
+  uc = unused_conns_find(addr);
+
+  if (uc) {
+    tor_assert(uc-&gt;count &gt; 0);
+    log_warn(LD_NET, "decrement unused conns %s, %u", fmt_addr(&amp;uc-&gt;addr),
+              (unsigned)uc-&gt;count-1);
+    if (--uc-&gt;count == 0) {
+      HT_REMOVE(unused_conns_map, &amp;unused_conns_map_root, uc);
+      tor_free(uc);
+    }
+  } else {
+    log_err(LD_BUG, "Can't find address in map to decrement unused conns.");
+    tor_fragile_assert();
+  }
+}
+
+/**
+ * Mark &lt;b&gt;conn&lt;/b&gt; used, updating the entry in the hash table.
+ */
+void
+connection_mark_used(connection_t *conn)
+{
+  if (conn-&gt;should_mark_used &amp;&amp; !conn-&gt;marked_used) {
+    unused_conns_decrement(&amp;conn-&gt;addr);
+    conn-&gt;marked_used = 1;
+    conn-&gt;should_mark_used = 0;
+  } else {
+    log_err(LD_BUG, "Connection marked used already!");
+    tor_fragile_assert();
+  }
+}
+
+/**
  * Return the human-readable name for the connection type &lt;b&gt;type&lt;/b&gt;
  */
 const char *
@@ -433,6 +549,9 @@
     conn-&gt;s = -1;
   }
 
+  if (conn-&gt;should_mark_used &amp;&amp; !conn-&gt;marked_used)
+    connection_mark_used(conn);
+
   if (conn-&gt;type == CONN_TYPE_OR &amp;&amp;
       !tor_digest_is_zero(TO_OR_CONN(conn)-&gt;identity_digest)) {
     log_warn(LD_BUG, "called on OR conn with non-zeroed identity_digest");
@@ -1094,6 +1213,8 @@
   if (conn-&gt;socket_family == AF_INET || conn-&gt;socket_family == AF_INET6) {
     tor_addr_t addr;
     uint16_t port;
+    int should_mark_used = 0;
+
     if (check_sockaddr(remote, remotelen, LOG_INFO)&lt;0) {
       log_info(LD_NET,
                "accept() returned a strange address; trying getsockname().");
@@ -1130,8 +1251,7 @@
         tor_close_socket(news);
         return 0;
       }
-    }
-    if (new_type == CONN_TYPE_DIR) {
+    } else if (new_type == CONN_TYPE_DIR) {
       /* check dirpolicy to see if we should accept it */
       if (dir_policy_permits_address(&amp;addr) == 0) {
         log_notice(LD_DIRSERV,"Denying dir connection from address %s.",
@@ -1141,8 +1261,21 @@
       }
     }
 
+    /* check that there aren't too many unused connections */
+    if (new_type == CONN_TYPE_OR || new_type == CONN_TYPE_DIR) {
+      if (unused_conns_check_and_increment(&amp;addr) == 0) {
+        //XXX this message would spam the log file during DoS attack
+        log_warn(LD_NET, "too many unused connections from %s.",
+                  fmt_addr(&amp;addr));
+        tor_close_socket(news);
+        return 0;
+      }
+      should_mark_used = 1;
+    }
+
     newconn = connection_new(new_type, conn-&gt;socket_family);
     newconn-&gt;s = news;
+    newconn-&gt;should_mark_used = should_mark_used;
 
     /* remember the remote address */
     tor_addr_copy(&amp;newconn-&gt;addr, &amp;addr);
Index: src/or/directory.c
===================================================================
--- src/or/directory.c	(revision 19229)
+++ src/or/directory.c	(working copy)
@@ -3205,6 +3205,11 @@
     r = -1;
   }
 
+  /* make sure to only mark direct dir conns used; tunneled conns are marked
+   * in connection_or.c after handshaking */
+  if (TO_CONN(conn)-&gt;should_mark_used)
+    connection_mark_used(TO_CONN(conn));
+
   tor_free(headers); tor_free(body);
   return r;
 }
</body></email><email><emailId>20090424130612</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-04-24 13:06:12-0400</timestampReceived><subject>[Announcement] We're switching version control systems</subject><body>

Hello, everyone!  Sometime in the next week or two, I am planning to
move the repository for Tor software from Subversion to Git.  This will
only affect the Tor program itself -- other software in the Tor
Project's Subversion repository will stay where it is for now.

WHAT DOES THAT MEAN?

When we develop software, we use a tool called a version control system
to keep track of all of the changes we have made to it.  Right now, we
use Subversion, which is a pretty conservative centralized version
control design: it manages everything in a big repository on our
Subversion server.  We're switching to Git, which is a decentralized
version control system (DVCS): it allows for many repositories existing
in parallel on different computers.

For more info on Git and its advantages, see http://git-scm.com/ .
We're mainly switching for:

- Better support for branch merging.
- Better support for distributed collaboration.
- Better support for offline development.
- Better support for security fix development.
- Cryptographic confirmation of repository integrity.

NOTES:

- Yes, we'll back up before we start.
- No, I don't know which day the switch will happen on yet.
- No, the website is not moving out of svn.
- Yes, this might be a good time to think about the story of the bike shed.
  [http://www.bikeshed.com/]

HOW DOES THIS AFFECT YOU?

== If you download Tor as a package

  It doesn't affect you at all, except inasmuch as it helps us develop
  Tor more effectively and get you better work faster.

== If you have been tracking Tor from subversion, but not changing it

  Instead of checking out the repository using "svn checkout", you'll
  clone it out with "git clone".  Instead of saying "svn update" to
  see the latest version, you'll say "git pull".

== If you have been writing patches for Tor against subversion, and
   mailing them in.

  As above, you'll need to use git to get the latest development
  version, not subversion.  If you do your work on a local git branch,
  though, you have a better ability to make sure that your patches
  form a logical sequence, and that they apply cleanly against the
  latest Tor before you send them in.

  Of course, you can still just do your patches against a working copy,
  use "git diff" to generate a patch, and email it in.  Just because
  you have support for local branches and versioning doesn't mean you
  need to use it.

  We'll be glad to work with people on the mailing lists and the IRC
  channels to help folks transition along with us.  I'll be sending out
  links to more detailed instructions as the transition occurs.

For more reading on Git, see:

The Git Tutorial
  http://www.kernel.org/pub/software/scm/git/docs/gittutorial.html
  http://www.kernel.org/pub/software/scm/git/docs/gittutorial-2.html

Git for Computer scientists
  http://eagain.net/articles/git-for-computer-scientists/

The "Everyday Git" quick-reference:
  http://www.kernel.org/pub/software/scm/git/docs/everyday.html

Git for SVN users:
  http://www.gnome.org/~newren/eg/git-for-svn-users.html

Two very opinionated Google Tech Talks talks about Git:
  Randal Schwartz:
     http://video.google.com/videoplay?docid=-3999952944619245780
  Linus Torvalds
     http://www.youtube.com/watch?v=4XpnKHJAok8

Our handy repository of (supposedly) useful Git tools.
  git://git.torproject.org/git/githax
See in particular the documentation on using Git with our Thandy
project; the instructions for Tor should be similar.
  http://git.torproject.org/checkout/githax/master/doc/Howto-thandy.txt

And of course, the delightful Git Manual:
  http://www.kernel.org/pub/software/scm/git/docs/user-manual.html

yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20090430051703</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-04-30 05:17:03-0400</timestampReceived><subject>Re: The Git conversion is done.</subject><body>

On Thu, Apr 30, 2009 at 01:02:22AM -0400, Nick Mathewson wrote:
&gt; [Also posted to or-talk.  This will be the next-to-last email for a
&gt;  while that I send to both lists.  The last one will be a "How The Tor
&gt;  Development Process Works, And How You Can Work With It" thing in a
&gt;  week or four.]

I knew when I was typing that paragraph that making a promise like
this is perilous, because...

&gt; Tor is now in Git.  The repository is at
&gt;    git://git.freehaven.net/git/tor.git
&gt; 
&gt; There is also a historical-interest repository at
&gt;    git://git.freehaven.net/git/tor-history.git

...these URLs should of course be 

     Tor is now in Git.  The repository is at
         git://git.torproject.org/git/tor.git
 
     There is also a historical-interest repository at
         git://git.torproject/git/tor-history.git


sleepy and liable to break something,
-- 
Nick
</body></email><email><emailId>20090430063815</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-04-30 06:38:15-0400</timestampReceived><subject>Re: [or-cvs] r19162: {projects} start making a 2009 todo list out of the performance ideas.  (projec</subject><body>

On Sat, Apr 11, 2009 at 01:54:33AM +0200, Karsten Loesing wrote:
&gt; &gt;   - 1.2, new circuit window sizes
&gt; &gt;     - Conclude whether the transition period will hurt as much as it
&gt; &gt;       seems like it will.
&gt; &gt;     * Pick a lower number, and switch to it.
&gt; &gt; Metrics: gather queue sizes from relays so we have a better sense of
&gt; &gt; what's actually going on.
&gt; 
&gt; Can you tell more details? Are there queues for circuits (1000 cells
&gt; max) and for streams (500 cells max)? Is relay.c a good place to start
&gt; looking for that code? Are we interested in average numbers of cells by
&gt; streams, by circuits, by both, or only in the sum of all cells waiting?
&gt; Should we write the number of cells waiting in those queues to disk
&gt; every 1 or 10 seconds and use those data for evaluation?

There are two phases here. The first is to instrument the heck out
of a few relays that we run, so we can get more details and better
intuition about what we should be trying to learn. To that end, for
every OR connection, what is its current outbuffer size? How many active
circuits are there on that conn? ('active' means they have a cell queued
for writing onto the outbuffer.) For the active circuits, how many cells
are queued at each?

The outbuffer lengths can be found via various places that call
buf_datalen() in buffers.c. See also dumpstats() in main.c. For the
circuit queues, check out conn-&gt;active_circuits in various places of
relay.c. For the interaction between active circuits and outbuffers,
see connection_or_flushed_some() in connection_or.c.

It's probably also worth instrumenting some of the things you suggest
above, in terms of how many cells are traversing each circuit. Do most
circuits stay inactive, but a few become active, send their cells, become
inactive, get new cells and become active, and keep oscillating? Or
are there active circuits that just stay active for seconds at a time
because they can't clear their queue?

So we should collect these numbers first, and look at them, and figure
out if it changes our opinions about what else we want to know.

Then we should summarize the info in a way that we can collect and
log 60-second snapshots to watch for trends: median queue size, 90%,
10%; mean outbuf size, 90%, 10%. Mean number of active circuits,
90%, 10%. Whatever else looks interesting. And based on our "why does
everything happen at the beginning of each minute" questions, we should
probably try a period of something different than 60 seconds too, so we
can see whether we get way different answers. :)

While I'm at it, for relays that rate limit, I want to know what fraction
of each second they spend with empty write buckets. My guess is that
for most relays that rate limit, they have a full second's worth of
data queued up already, and at the top of each second, they pull off
one second's worth of bytes, send them, and then go dormant again until
the next second. That behavior sucks, and we have some ideas of how to
fix it (step one: lower the circuit window sizes, so there's less data
in flight on the network; step two, reduce the granularity of the token
bucket refills, so it sends bytes more regularly throughout the second),
but step zero is to confirm that this behavior actually happens.

What's the average time that a given cell spends waiting at our
relay? If we add a struct timeval to the packed_cell_t, we can learn
how long it takes until that cell gets flushed to the outbuf. Once we
know max/min/mean/median for that, we can decide if there's something we
can improve. Those numbers are also metrics that we should automate and
track over time, to give us a sense of intra-relay slowdown and whether
we're fixing it.

Also in there: do some relays refuse to read from us for multiple seconds
at a time? That is, above I speculated that stuff is waiting for the
next second before it goes out. But if there are several seconds of
stuff buffered, then the wait will be even longer. So even if the relay
that we instrument is fast enough and behaving well, this should give
us a sense of how loaded the other relays are.

The main reason to lower the circuit window is to reduce the clutter of
bytes in the middle of the network. By reducing the queues, we should
be able to decrease latency. So another item we need to measure is the
actual latency that Tor clients should be seeing. We should run a Tor
client somewhere that makes "typical" Tor circuits (i.e. just let Tor
choose its own paths, but set UseEntryGuards to 0, and only make requests
to port 80 so it builds circuits which exit there), and send pings every
so often, and track how long they take. One easy way to ping is to make
a request to an IP address that we know is refused by the last hop's
exit policy. Say, 127.0.0.1:80. Then measure the time between sending
the connect cell, and receiving the end cell. We expect this latency
to go down over time, a) because we lower the circuit window, and b)
because Tor has on-average-better circuits based on Mike Perry's plans.

Once we've done this instrumenting for circuits on ORConns, we should
think about whether we need to do the same things for instrumenting edge
streams and how they add cells to their circuits, and how they flush
them on the socks side. But I hope that we get most of what we need
out of looking at how relays behave inside the network.

So that was phase one. Phase two is to roll out a few of these changes
to every relay, and then have them record summary stats and publish them
in their extra-info documents. That way we'll get a better cross-section
of the network rather than just seeing the relays that we set up. This
phase can come later once we know more about what we want.

[High priority, since I really want to get the baseline measurements
in place so we can start rolling out our changes.]

&gt; &gt;   - 2.5, Default exit policies
&gt; &gt;     * Change Vidalia's default exit policy to not click "other protocols".
&gt; &gt;     D let exit relays specify some destination networks/ports that get
&gt; &gt;       rate limited further.
&gt; &gt; Metrics: At what fraction of exit relays allowing a given port out
&gt; &gt; do connections to that port start to suffer? That is, if even 5%
&gt; &gt; of the relays (by bandwidth) allowing a port to exit are enough for
&gt; &gt; most connections to that port to work fine, then we're going to have
&gt; &gt; a tough time pushing unwanted traffic off the network just by changing
&gt; &gt; some exit policies. (Alas, this question is messy because it pretends
&gt; &gt; that the amount of traffic generated for port x is independent of x.
&gt; &gt; How to phrase it so it's more useful?)
&gt; 
&gt; Okay, I'm not sure if I understand that question. What exactly do you
&gt; want to have measured here?

Let's say port 6881 is the default bittorrent port. It's refused in the
default exit policy, but there are a few relays out there who allow
it anyway. If I'm doing a connection to port 6881, that means I have
to exit from one of those few that allow it. We theorize that the few
relays who allow it are massively overloaded (e.g. have higher latencies
and give lower throughput) compared to other relays that advertise the
same bandwidth, because they're attracting all the default bittorrent
streams. So the first question is: is this really true? We could look at
Mike's torflow stats and look at the exit policies and see if open exit
policies are correlated to some of the slower relays. The next question
is: if you try to fetch a large file from port 6881 vs from port 6880,
how big a performance difference do you see?

Then there are other ports, like 119 or 25, that might not attract as
much traffic. Are the relays that allow those as overloaded as the ones
that allow 6881? This question may be hard to answer, since I imagine
there aren't many relays in either of these categories, and the few that
do exist probably overlap.

The ultimate goal is to answer the question: If we reject more ports in
the default exit policy, a) would we reduce the performance for some
classes of users (theoretically the answer is "of course yes", but
the question is "how much in practice?"), and b) would we thus improve
performance for the folks who use the remaining ports? I'm thinking in
particular of the folks who use port 80.

I'm not sure how to measure this though, because the "reduce performance
for some classes" step is designed to make them stop trying to use Tor,
and we'd have to have some model for how successful we'll be, and it
gets messy very quickly. Hm. Suggestions? :)

In any case, we can still try to answer the preliminary question, which
is "does restricting a port in the default exit policy actually have a
big impact on the performance you get if you want to use that port?"

[Medium priority, because I don't expect it'll be a huge change, so
the relay-buffer and circuit-window stuff should come first]

&gt; &gt;   - 3.6, incentives to relay
&gt; &gt;     - Sort out how to do circuit priority in practice. I think the only
&gt; &gt;       answer here is to make different TLS connections for different
&gt; &gt;       priorities. (Otherwise other people can free-ride on your
&gt; &gt;       high-priority conns.)
&gt; &gt; Metrics: what period of time should the gold star status last? That is,
&gt; &gt; What period of time, taken as a rolling snapshot of which relays are
&gt; &gt; present in the network, guarantees a sufficiently large anonymity set
&gt; &gt; for high-priority relays?
&gt; 
&gt; This goes in the direction of the churn measurements for my thesis. But
&gt; I'm unsure what exactly the question is. You want to know how many of
&gt; the relays at time X are still running at time Y? Or, maybe only a
&gt; subset of relays (which criteria)?

If I know that my target was a relay within the past X hours, what is the
expected size of his anonymity set for various values of X? Plotting the
"number of relays that could have been my target" vs X will give us a
sense of the churn of the network.

But let's say my target has linkable behavior. He logs into wikileaks
with a distribution centered around every L hours, and each time he
does that, I know he was a relay within the past X hours. Now we can
do an intersection attack. For various values of L (a day, a few days,
a week, a month), what do the above entropy-vs-X graphs look like?

I would guess that a small X is going to shrink the entropy quickly. But
if we use an X of a week or two, does it still shrink quickly, or is
there a large stable core of the network that still provides pretty good
cover? And if there is, is the stable core stable enough that the value
of X doesn't much matter?

[Low priority, since there's a good chance the conclusion will be "don't
do that"]

&gt; &gt;   - 4.2, getting better bandwidth estimates
&gt; &gt; Metrics: how accurate are the ten-second-bandwidth-burst advertised
&gt; &gt; numbers anyway, in terms of guessing capacity? Steven says we're at 50%
&gt; &gt; load, but is that just because our advertised bandwidth is a function
&gt; &gt; of our recent load?
&gt; 
&gt; How would accuracy be measured? How do I learn how much 100% of the
&gt; capacity of a relay are?
&gt; 
&gt; &gt;     - What is "true" capacity anyway?
&gt; &gt; Metrics: What other algorithms can we use to produce a more accurate
&gt; &gt; advertised bandwidth?
&gt; 
&gt; Is this a question that can be answered by metrics? Can you give more hints?

Hell if I know. I guess that means this one should wait. ;)

Mike Perry has a plan to use torflow to measure the capacity he actually
receives from each relay, and compare it to the capacity he receives
from its peers (that is, relays that advertise similar bandwidths). Then
we will modify the bandwidth values in the networkstatus consensus based
on the measurements, with the hopes of making peers more equal. At that
point there will be a feedback loop, where advertising a higher number
attracts more users, thus slowing it down; and advertising a lower
number sheds users, thus speeding it up. So if we can get the tuning
right, the advertised bandwidth numbers will more accurately reflect
reality.

Then the new set of metrics questions will come in: how come some numbers
are so different from what the relays themselves are claiming? Are there
ways we can help the relays come up with a number that's closer to what
torflow decided they should use, so torflow doesn't have to correct it
as much?

Another metrics question is to reproduce the Snader-Borisov results, by
running an instrumented relay that records how fast it thinks the other
relays are, and see how closely the measurements match a) the bandwidth
that the relay advertises, and b) the bandwidth in the consensus (well,
the load balancing ratio in the consensus, really). Then get a bunch of
people to run the instrumented version, and see if the median or mean of
their opinions is more useful. I bet Robin would be happy to help with
this -- I almost rolled out a version of their patch in 2008, but then
I had second thoughts because I was unsure how much anonymity could be
broken by an adversary who sees votes by every relay on the bandwidth
they've seen from every other relay, and also has some network traces
of his own. There's another research question for somebody to tackle. :)

[Low priority, since Mike should do his part first]

&gt; &gt;   - 4.5, Older entry guards are overloaded
&gt; &gt; Metrics: compare "how fast each relay should be based on its advertised
&gt; &gt; capacity" with "how long the relay has had the guard flag", to see how
&gt; &gt; big an issue this is really.
&gt; 
&gt; Okay, that means finding a possible correlation between advertised
&gt; capacity and time since getting the Guard flag for the first time.
&gt; Should be possible, but I need to think harder about doing this
&gt; efficiently with the current database.

Yep. It actually isn't "time since getting the Guard flag for the first
time" -- it's "time spent in the network with the Guard flag", since
the users you accumulate as a guard are, well, cumulative.

[High priority, since I changed the code in 0.2.1.14-rc, so our period
of being able to measure the old situation is disappearing as people
upgrade.]

&gt; &gt; Metrics: How many relays does a client touch over time x, given that they
&gt; &gt; drop old guards y seconds after choosing them? Even if y is infinite,
&gt; &gt; we have some number based on guards going away. How does x grow as we
&gt; &gt; reduce y?
&gt; 
&gt; Hey, x has two meanings here. ;) The question should be "How many relays
&gt; z does a client touch over time x, given that they drop old guards y
&gt; seconds after choosing them?" Maybe we want to fix the time x to, say, 1
&gt; month?

Sounds good. I actually picked 4-8 weeks for y in 0.2.1.14-rc, so I'd be
curious to know the answer for several values of x: 1 month, 2 months,
6 months, 12 months, etc.

Basically, my hope is that a value of 1 month for y is approximately
the same as a value of infinity for y, even for large values of x.

On the other hand, if y=1mo and y=\inf actually are the same, then
shouldn't the network be rebalancing over time, and the old Guards
shouldn't be so overloaded? I don't actually know what to expect here. I
look forward to some actual data. :)

[Medium priority, since we should learn a good value for y and use it,
rather than continually picking new bad values and splintering the
anonymity set too much.]

&gt; &gt;     * Pick a conservative y like six months, and implement.
&gt; &gt;     D Reduce y based on the results of the metrics. (don't partition
&gt; &gt;       clients too far by tor version though.)
&gt; &gt; Metrics: if we were more flexible in our Guard stability criteria, how
&gt; &gt; many more relays would get the Guard flag? How would that influence the
&gt; &gt; above numbers? I'd like to become very flexible so more than half of
&gt; &gt; the relays get to be guards. Are there cutoffs that are reasonable and
&gt; &gt; fit naturally into the data from the past few years?
&gt; 
&gt; I have started playing with the selection criteria to see how many
&gt; Fast/Stable/Guard nodes we'd have ended up with in the past. If the
&gt; stupid database finishes anytime soon, we'll have results tonight or
&gt; tomorrow. The question how that would have influenced the above numbers
&gt; would be next.

Great. Let me know how that goes. :)

[Medium priority, since right now there are far too few guards.]

We'll still want to tackle the edge-case where a user picks three
low-bandwidth guards and keeps them for a month. Having a high variance
of outcomes from guard selection means that some users will find Tor fast
and some will find it slow, and that leads to hack recommendations like
"if Tor is slow then delete your state file and restart".

I'm not sure how to resolve this. The fragile kludge is to have some
smart heuristics, e.g. Alice tries again if she chooses three guards whose
bandwidths sum to less than 100KB. The overkill way is to make RealGuard
and AdequateGuard flags, and make sure Alice picks at least one RealGuard.

&gt; &gt; Metrics: if we're more flexible in our Guard speed criteria, how does
&gt; &gt; that impact the speed that clients should expect? Originally we avoided
&gt; &gt; 20KB/s relays as guards, because "then clients can't ever get more than
&gt; &gt; 20KB/s". But they can't get that now anyway.
&gt; 
&gt; What metric would answer this question? The distribution of advertised
&gt; bandwidth for different Guard selection criteria?

I'm not sure. I was going to suggest to make paths through the first
set and then through the second set, and compare the performance you
see. But the situation is so broken right now wrt guard load that an
experiment like that wouldn't really be useful.

Another option would be to do all our changes, let everything settle down,
and then do the two sets of measurements and compare. I'd be tempted to
include "be more flexible about who can be a guard" in those changes,
and then ask the question in reverse: if we were more strict, how much
faster would Tor get for the client?

&gt; &gt;   - 5.2, better timeouts for giving up on circuits/streams
&gt; &gt;     * clients gather data about circuit timeouts, and then abandon
&gt; &gt;       circuits that take more than a std dev above that.
&gt; &gt; Metrics: Right now we abandon the circuit after 10 seconds for the first
&gt; &gt; try. What are the download stats if we don't abandon it? What "try a
&gt; &gt; new one" timeouts will minimize the number of circuits we go through,
&gt; &gt; while also minimizing the time-until-user-gets-website?
&gt; 
&gt; Hmm. We might completely remove the 10-seconds timeout and see how long
&gt; it takes until the stream is attached (or if it fails). From these data
&gt; we could derive a better timeout. Is that what you have conceived?

Yes, that sounds like a great start. Once we know how long they take in
practice, then we can see what we think the 10s timeout is doing to the
situation (whether it's helping or hurting).

[Medium priority, since I think we can get a big win here]

Thanks!
--Roger

</body></email><email><emailId>20090308065121</emailId><senderName>Michael Gold</senderName><senderEmail>torlists@rilmarder.org</senderEmail><timestampReceived>2009-03-08 06:51:21-0400</timestampReceived><subject>Re: Patch to authenticate by uid/gid on ControlSocket</subject><body>


On Mon, Mar 02, 2009 at 13:58:21 -0500, Nick Mathewson wrote:
&gt; Hi, Michael!
&gt; 
&gt; A few issues here: first off, we try not to add new features in the
&gt; stable series.  Since the development series is in feature freeze too
&gt; (we're trying to stabilize it), we'd have to hold off on applying this
&gt; until 0.2.2.x-alpha forks off.

It doesn't look like the relevant code has changed much between the two
series, so this shouldn't be a problem.

&gt; Secondly, UID/GID-based authentication is potentially problematic in
&gt; the general case, and I think we should think hard about whether it's
&gt; safe in the particular case here.  For TCP sockets, it would be a
&gt; totally bad idea: it's way to easy for a user's web browser (which
&gt; runs as their own UID/GID, after all) to get tricked into making a
&gt; connection to a local socket, saying "AUTHENTICATE\r\n", and then
&gt; running whatever anonymity-breaking control commands the attacker
&gt; wants.  (That's why we recommend passwords on all control sockets.)
&gt; Now, I don't _think_ the same attack works for unix sockets, but we
&gt; should try to figure out if there is a similar attack here.  I'd guess
&gt; offhand that this is probably safe, but I'd like to have more than a
&gt; guess to go on here.

I grepped the Debian iceweasel-3.0.6 source package for AF_UNIX,
AF_LOCAL, and AF_FILE.  It looks like Unix sockets are only used for IPC
(using a fixed path), asynchronous DNS lookups, and some socketpair
calls.  I've never heard of any browser allowing users to connect to
Unix domain sockets, or any web server that listens on them -- so a
similar attack seems unlikely.

Also, on my system there are already some important programs listening
on Unix sockets, such as X11, dbus, ssh-agent, and cups; dbus and
ssh-agent both use getpeereid/SO_PEERCRED for authentication (with no
additional credentials required, AFAICT).

&gt; I'm also worried about the change that seems (if I understand
&gt; correctly) to make the initial AUTHENTICATE command optional when
&gt; you're using UID/GID authentication.  Some of the earliest attacks on
&gt; the control port protocol worked by embedding the payload inside
&gt; another protocol, confident that any amount of garbage would get
&gt; ignored if it ended with \r\n.  That's why the current protocol closes
&gt; the connection immediately if the first command is anything but
&gt; AUTHENTICATE or PROTOCOLINFO.  Accepting anything besides
&gt; AUTHENTICATE, PROTOCOLINFO, or QUIT as a first command is
&gt; nonconformant to control-spec.txt, and probably shouldn't be allowed.

Is it enough to require an AUTHENTICATE command, or should we also try
to verify that there's two-way communication? (e.g., by including some
random string in PROTOCOLINFO and having the client echo it back.)

I guess I should add a new AuthMethod to PROTOCOLINFO too; probably
something like "UID".

&gt; On the permissions issue: In Tor today, I believe only the main thread
&gt; creates any files, so it ought to be safe to change the umask
&gt; temporarily.

Good, that makes things simple.

&gt; &gt; +/** Called to initialise a new control socket. */
&gt; &gt; +int
&gt; &gt; +connection_control_init_accepted_conn(control_connection_t *conn)
&gt; &gt; +{
&gt; 
&gt; Wow, there's a lot of code here.  Any way to break this into
&gt; functions?

Sure, both the ControlAllowUsers and ControlAllowGroups sections (at
least) could be easily broken out.

&gt; It seems like it might be easier to parse the user/group
&gt; lists when the option is set, rather than when the connection happens,
&gt; too.

Maybe, and it would reveal configuration errors earlier too -- but users
and groups can be dynamically changed, and reading it each time ensures
we have the latest info.  For example, someone authenticating via a
group membership should have their access revoked immediately when they
are removed from the group.

Thanks for your comments,
-- Michael

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090513034602</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-13 03:46:02-0400</timestampReceived><subject>Re: Proposal 161: Computing Bandwidth Adjustments</subject><body>

On Tue, May 12, 2009 at 07:48:28PM -0700, Mike Perry wrote:
&gt; Title: Computing Bandwidth Adjustments
&gt; Author: Mike Perry
&gt; Created: 12-May-2009
&gt; Target: 0.2.2.x

(Checked in to the main repo as Proposal 161.  I added a "filename"
and a "status" field here.)

The proposal looks good for a start, but I'd like to see more
discussion of some points.  I have some question below.

 [...]
&gt; 2. Average Stream Bandwidth Calculation
&gt;  
&gt;   The average stream bandwidths are obtained by dividing the network
&gt;   into 3% slices according to advertised node bandwidth, yielding 
&gt;   about 45 nodes per slice in the current network.
&gt; 
&gt;   Two hop circuits are built using nodes from the same slice, and a large
&gt;   file is downloaded via these circuits. This process is repeated
&gt;   several hundred times, and average stream capacities are assigned to
&gt;   each node from these results.

There are some magic numbers here: Why 3%?  How large are these files
and how often are they downloaded?  Why "several hundred"?  Is the
"several hundred" a function of the "45" above?

I want to see a calculation for what fraction of the network capacity
we expect to use for this testing.  I wouldn't expect it to be over a
percent, but I'd like to see the math to prove it.

Also, how long does it take to run these tests over the network?  If
it takes much longer than a consensus interval, we should think about
what happens if a node's advertised capacity changes greatly, and
whether we want to treat newer measurements as more accurate.

Another possibility I want to consider: what if, instead of putting
nodes into slices based on their declared bandwidths, we put them into
slices based on the most recent bandwidth for them in the consensus?
That way, if a node advertises 100x as much bandwidth as it really
has, we will soon start measuring it along with the really other slow
nodes, rather than measuring it along with the high-capacity nodes
forever.

[Ah.  I see on IRC that the above paragraph is what you already have
in mind.]

 [...]
&gt; 3. Ratio Filtering
&gt; 
&gt;   After the base ratios are calculated, a second pass is performed
&gt;   to remove any streams with nodes of ratios less than X=0.5 from
&gt;   the results of other nodes.   In addition, all outlying streams
&gt;   with capacity of one standard deviation below a node's average
&gt;   are also removed.
&gt; 
&gt;   The final ratio result will be calculated as the maximum of 
&gt;   these two resulting ratios if both are less than 1.0, the minimum
&gt;   if both are greater than 1.0, and the mean if one is greater
&gt;   and one is less than 1.0.

I am little confused about what happens here.  Can you clarify this
with some pseudocode for the whole algorithm?  Based on what you've
written, I _think_ it would go something like:

     1. Partition nodes into equal-sized sets of approximately 45
        nodes, dividing slices by declared bandwidth.
     2. For each slice, build about 100 two-hop circuits, and check
        the bandwidth on each.
     3. For each node N, let BW_measured(N) = MEAN(b | b is the bandwidth
        of a stream that went through N).
     4. For each slice S, let BW_avg(S) = MEAN(b | b is the bandwidth
        of a stream built through S).  Let BW_stddev(S) = The standard
	deviation of all such streams.  Let Normal_Streams(S) = { all
	streams in S such that their bandwidth b is at least 0.5 *
        BW_avg(S), and such that |b-BW_avg(S)|&lt;= BW_stddev(S) }

     5. For each node N, let BW_measured2(N) = MEAN(b | b is the bandwidth
        of a stream that went through N, for all streams in
        Normal_Streams(S)).

     6. For each node N, if BW_measured and BW_measured2 are on the
        same side of 1.0, let BW_final(N) be whichever of BW_measured
        and BW_measured2 is closer to 1.0.  Otherwise let BW_final(N)
        be the mean of BW_measured and BW_measured2.

Am I close?  Let's get the right pseudocode into the proposal; this is
a complicated enough algorithm that it could use a mathy exposition.

Also, I'm not sure what the motivation is.  Have you tried it without
this step, and found that it didn't work so well?

&gt; 4. Security implications
&gt; 
&gt;   The ratio filtering will deal with cases of sabotage by dropping
&gt;   both very slow outliers in stream average calculations, as well
&gt;   as dropping streams that used very slow nodes from the calculation
&gt;   of other nodes.
&gt; 
&gt;   This scheme will not address nodes that try to game the system by
&gt;   providing better service to scanners. The scanners can be detected
&gt;   at the entry by IP address, and at the exit by the destination fetch.
&gt; 
&gt;   Measures can be taken to obfuscate and separate the scanners' source
&gt;   IP address from the directory authority IP address. For instance,
&gt;   scans can happen offsite and the results can be rsynced into the
&gt;   authorities.  The destination fetch can also be obscured by using SSL
&gt;   and periodically changing the large document that is fetched. 
&gt; 
&gt;   Neither of these methods are foolproof, but such nodes can already
&gt;   lie about their bandwidth to attract more traffic, so this solution
&gt;   does not set us back any in that regard.

Yeah.  I suppose we can carry on an arms-race here if somebody really
wants to start one.

&gt; 4. Integration with Proposal 160
&gt; 
&gt;   The final results will be produced for the voting mechanism
&gt;   described in Proposal 160 by multiplying the derived ratio by 
&gt;   the average observed advertised bandwidth during the course of the
&gt;   scan. This will produce a new bandwidth value that will be 
&gt;   output into a file consisting of lines of the form:
&gt; 
&gt;   &lt;node-idhex&gt; SP new_bandwidth NL
&gt; 
&gt;   This file can be either copied or rsynced into a directory readable
&gt;   by the directory authority.

Let's make this a little more extensible, so we can add new fields in
the future without breaking things.  Let's say that the format is

    "node id=&lt;idhex&gt; SP bw=&lt;new_bandwidth&gt; NL"

and specify that implementations must ignore any lines starting with
any keywords they don't recognize, or any key=value values inside a
line if they don't recognize the keyword.

That way, if we want to tell Tor more in the future, we can.


* *

So, something that didn't come up: I think that it's important to have
values for weights change a bit slowly based on node speed or
slowness.  Otherwise, we can wind up with a situation where we notice
a node is slow, so everybody leaves, so we notice it is fast, so
everybody hammers it.  I _think_ that the above algorithm has this
property--does it?

(Crazy idea 1: If the values change too fast or slow, we could
exponentiate the ratios out of the algorithm before using them.
Slightly less crazy idea 2: if the values change too fast, we could do
a standard time-weighted average, where we compute the new declared
bandwidth BW' as a weighted average of the old declared bandwidth and
the new measured bandwidth.)


yrs,
-- 
Nick
</body></email><email><emailId>20090525214551</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-05-25 21:45:51-0400</timestampReceived><subject>Writing geoip stats to disk on directories</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Nick, Roger,

I'm thinking about changing the timing of how directories write geoip
stats to disk. Right now, directories measure requests over at most 3
periods of 8 hours each (see REQUEST_HIST_LEN and REQUEST_HIST_PERIOD in
geoip.c). That means, whenever they have measured 24 hours of requests
they forget about the oldest 8 hours of requests. The directories write
these geoip stats to disk once an hour (see DUMP_GEOIP_STATS_INTERVAL in
main.c), regardless of when request periods start or end. More
precisely, directories overwrite the local geoip-stats file every hour.
I also found a config option DirRecordUsageSaveInterval which should say
how often geoip data is flushed to disk and which defaults to 6 hours,
but which is not used in the code. I think we should improve the timing
of writing geoip stats to disk.

My first idea is to synchronize request history periods with writing
down stats. This basically means writing down stats only when periods
end. The main reason is that we should ensure that only requests are
written to disk that have been measured over exactly 24 hours. Writing
down stats earlier might be problematic from an anonymity point of view.
And after a restart we don't pick up these values anyway. Longer times
(or in general different times than 24 hours) would complicate the
analysis to a certain extent. In terms of code that means dropping
DUMP_GEOIP_STATS_INTERVAL in main.c and dumping stats whenever we change
the request period. Also, stats should be appended to the geoip-stats
file rather than replacing that file.

My next thought is whether or not we want to make the period length
configurable. From earlier measurements I found that the period length
of 8 hours (as defined in REQUEST_HIST_PERIOD) works fine. Also,
configurable period lengths might complicate analysis, too. If we want
to make the period length configurable, we should define a lower limit
of, say, 2 hours. Otherwise, people could compare subsequent
observations to learn more details about requests. Possible values for
period lengths would then be 2, 3, 4, 6, 8, 12, or 24 hours. But again,
do we need to make this configurable? And if so, should we use the
config option DirRecordUsageSaveInterval instead of REQUEST_HIST_PERIOD?

Does this all make sense to you? If so, I'd prepare a patch to make the
described changes. Or did I just misunderstand your intentions when
adding this functionality.

The next step would be to add the geoip-stats lines (or a subset of
them) to extra-info documents. I think a proposal for that would be in
place, but first I think it's fine to start with measuring on a few
nodes and working with files.

Thanks!
- --Karsten
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkobEYUACgkQ0M+WPffBEmXzhQCgxWIVrMQqBpSEkAYGXr4TkYSJ
4csAn0O8tlg5TKgZua7HOS8Sy0ptcsCE
=0DXG
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090528165113</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-28 16:51:13-0400</timestampReceived><subject>Proposal 165: Easy migration for voting authority sets</subject><body>


Filename: 165-simple-robust-voting.txt
Title: Easy migration for voting authority sets
Author: Nick Mathewson
Created: 2009-05-28
Status: Open

Overview:

  This proposal describes any easy-to-implement, easy-to-verify way to
  change the set of authorities without creating a "flag day" situation.

Motivation:

  From proposal 134 ("More robust consensus voting with diverse
  authority sets") by Peter Palfrader:

      Right now there are about five authoritative directory servers
      in the Tor network, tho this number is expected to rise to about
      15 eventually.

      Adding a new authority requires synchronized action from all
      operators of directory authorities so that at any time during the
      update at least half of all authorities are running and agree on
      who is an authority.  The latter requirement is there so that the
      authorities can arrive at a common consensus: Each authority
      builds the consensus based on the votes from all authorities it
      recognizes, and so a different set of recognized authorities will
      lead to a different consensus document.

  In response to this problem, proposal 134 suggested that every
  candidate authority list in its vote whom it believes to be an
  authority.  These A-says-B-is-an-authority relationships form a
  directed graph.  Each authority then iteratively finds the largest
  clique in the graph and remove it, until they find one containing
  them.  They vote with this clique.

  Proposal 134 had some problems:

    - It had a security problem in that M hostile authorities in a
      clique could effectively kick out M-1 honest authorities.  This
      could enable a minority of the original authorities to take over.

    - It was too complex in its implications to analyze well: it took us
      over a year to realize that it was insecure.

    - It tried to solve a bigger problem: general fragmentation of
      authority trust.  Really, all we wanted to have was the ability to
      add and remove authorities without forcing a flag day.

Proposed protocol design:

   A "Voting Set" is a set of authorities.  Each authority has a list of
   the voting sets it considers acceptable.  These sets must always
   contain the authority itself.  Each authority lists all of these
   voting sets in its votes.

   Authorities exchange votes with every other authority in any of their
   voting sets.

   When it comes time to calculate a consensus, an authority votes with
   whichever voting set it lists that is listed by the most members of
   that set.

   For example, suppose authority A recognizes two sets, "A B C D" and
   "A E F G H".  Suppose that the first set is recognized by all of A,
   B, C, and D, whereas the second set is recognized only by A, E, and
   F.  Because the first set is recognize by more of the authorities in
   it than the other one, A will vote with the first set.

   Ties are broken in favor of some arbitrary function of the identity
   keys of the authorities in the set.

How to migrate authority sets:

   In steady state, each authority should list only the current actual
   voting set as accepted.

   When we want to add an authority, we list two voting sets: one
   containing all the old authorities, and one containing the old
   authorities and the new authority too.  Once all authorities are
   listing the new set of authorities, they will start preferring that
   set because of its size.

   When we want to remove an authority, we list two voting sets: one
   containing all the authorities, and one omitting the authority we
   want to remove.  Once enough authorities list the new set as
   acceptable, we start having authorities stop listing the old set.
   Once there are more listing the new set than the old set, the new set
   will win.

Data format changes:

   Add a new 'voting-set' line to the vote document format.  Allow it to
   occur any number of times.  Its format is:

      voting-set SP 'fingerprint' SP 'fingerprint' ... NL

   where each fingerprint is the hex fingerprint of an identity key of
   an authority.  Sort fingerprints in ascending order.

   When the consensus method is at least 'X' (decide this when we
   implement the proposal), add this line to the consensus format as
   well, before the first dir-source line.  [This information is not
   redundant with the dir-source sections in the consensus: If an
   authority is recognized didn't vote, that authority will appear in
   the voting-set line but not in the dir-source sections.]

   We don't need to list other information about authorities in our
   vote.

Migration issues:

   We should keep track somewhere of which Tor client versions
   recognized which authorities.

Acknowledgments:

   The design came out of an IRC conversation with Peter Palfrader.  He
   had the basic idea first.

</body></email><email><emailId>20090530222917</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-05-30 22:29:17-0400</timestampReceived><subject>Fix for #937 - support dynamic crypto acceleration engines</subject><body>

Branch hardware_accel_improvements at
git://git.torproject.org/~coderman/git/tor.git contains a fix for
dynamic crypto acceleration engines in OpenSSL and includes
documentation for two new options:

HardwareAccel 0|1
If non-zero, try to use built-in (static) crypto hardware acceleration
when available. (Default: 0)

AccelName NAME
When using OpenSSL hardware crypto acceleration attempt to load the
dynamic engine of this name. This must be used for any dynamic
hardware engine. Names can be verified with the openssl engine
command.

AccelDir DIR
Specify this option if using dynamic hardware acceleration and the
engine implementation library resides somewhere other than the OpenSSL
default.

This has been tested on openssl 0.9.7d through 0.9.8k and under load
by router 'badbits' for the past week or so.

For example, a padlock accelerated Tor would set the following in torrc:
HardwareAccel 1
AccelName padlock

And notices.log should show:
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for SHA1
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for AES
(info log level provides additional detail)

Additional testing with other dynamic engines and performance
improvement profiles would be useful.

Best regards,

</body></email><email><emailId>20090530223319</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-05-30 22:33:19-0400</timestampReceived><subject>Re: Fix for #937 - support dynamic crypto acceleration engines</subject><body>

i should mention that this is intended for 0.2.2 and a merge into master.

On Sat, May 30, 2009 at 3:29 PM, coderman&lt;coderman@gmail.com&gt; wrote:
&gt; Branch hardware_accel_improvements at
&gt; git://git.torproject.org/~coderman/git/tor.git contains a fix for
&gt; dynamic crypto acceleration engines in OpenSSL...

</body></email><email><emailId>20090528195842</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2009-05-28 19:58:42-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

Hi Nick et al.,

Two things:

1. I think you mean that an authority votes with whatever the largest
set is that it lists that is listed by the most members of that set. 
(I added "largest" to your criterion.)

I guess there is an ambiguity of 'most' but if you have a set and a
proper subset, both of which are listed by all the members of each,
then the ones in the smaller set have no basis to prefer the larger
one and will never drop the smaller one. If by 'most' you implicitly
mean biggest rather than largest fraction, it is confusing since
it is no longer relative to the givne voting set but relative to
others.


2. More significantly, there is something I don't get about the
proposal. I think I understand the problem with proposal 134. It seems
like a standard byzantine failure when there are not at least 3n+1
honest and correct voters, where n is the number of dishonest, but I
didn't look at it closely to see if there are some differences.

The new proposal is not that bad, but it still allows a single
hostile authority to prevent the addition of a new authority.

If Alice does not want to add authority Bob, then she
refuses to make a voting set containing him. Other honest-correct
authorities will not prefer the new voting set until some of them drop
the old one that did not have Bob in it. But none of them should
ever do that because the voting set without Bob in it is preferred by
a larger majority of its members.

If 'most' is interpreted as discussed in 1. above, the same problem
applies, but you need two hostile authorities to make sure Bob can never
get in no matter what the rest of the authorities do.

Similarly, if the honest authorities want to drop Bob, as long as two
existing authorities (possibly but not necessarily one being Bob) want
to maintain him, then none should ever delist the larger set because
it will always be preferred over the smaller one. So he won't
get dropped.

What am I missing?

aloha,
Paul


</body></email><email><emailId>20090528202357</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-28 20:23:57-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

On Thu, May 28, 2009 at 03:58:42PM -0400, Paul Syverson wrote:
&gt; Hi Nick et al.,
&gt; 
&gt; Two things:
&gt; 
&gt; 1. I think you mean that an authority votes with whatever the largest
&gt; set is that it lists that is listed by the most members of that set. 
&gt; (I added "largest" to your criterion.)
&gt; 
&gt; I guess there is an ambiguity of 'most' but if you have a set and a
&gt; proper subset, both of which are listed by all the members of each,
&gt; then the ones in the smaller set have no basis to prefer the larger
&gt; one and will never drop the smaller one. If by 'most' you implicitly
&gt; mean biggest rather than largest fraction, it is confusing since
&gt; it is no longer relative to the givne voting set but relative to
&gt; others.

Okay, I'll try again.  What I meant is that, given two sets S1 and S2 that an
authority lists, that authority will prefer S1 over S2 whenever the
number of other authorities in S1 that themselves list S1 is higher
than the number of other authorities in S2 that themselves list S2.

&gt; 2. More significantly, there is something I don't get about the
&gt; proposal. I think I understand the problem with proposal 134. It seems
&gt; like a standard byzantine failure when there are not at least 3n+1
&gt; honest and correct voters, where n is the number of dishonest, but I
&gt; didn't look at it closely to see if there are some differences.
&gt; 
&gt; The new proposal is not that bad, but it still allows a single
&gt; hostile authority to prevent the addition of a new authority.
&gt; 
&gt; If Alice does not want to add authority Bob, then she
&gt; refuses to make a voting set containing him. Other honest-correct
&gt; authorities will not prefer the new voting set until some of them drop
&gt; the old one that did not have Bob in it. But none of them should
&gt; ever do that because the voting set without Bob in it is preferred by
&gt; a larger majority of its members.

Right.

Please take the entire section "How to migrate authority sets" as
normative rather than a complete description of how to upgrade: if one
of the authority operators doesn't participate, then the other
operators need to manually intervene and either stop listing sets that
include that operator's authority, or convince that operator to
upgrade.

&gt; If 'most' is interpreted as discussed in 1. above, the same problem
&gt; applies, but you need two hostile authorities to make sure Bob can never
&gt; get in no matter what the rest of the authorities do.

Well, that's only unless 3 other authorities stop listing the sets
that _don't_ include Bob.

&gt; Similarly, if the honest authorities want to drop Bob, as long as two
&gt; existing authorities (possibly but not necessarily one being Bob) want
&gt; to maintain him, then none should ever delist the larger set because
&gt; it will always be preferred over the smaller one. So he won't
&gt; get dropped.

Here you're missing the line that says

   Once enough authorities list the new set as acceptable, we start
   having authorities stop listing the old set.  Once there are more
   listing the new set than the old set, the new set will win.

In other words, once the operators notice that enough authorities are
listing the set-minus-Bob, they manually stop listing
sets-including-Bob.  Assuming that there are N authorities (including
Bob), once N-1 authorities list the set without Bob, we need just 2
authorities to drop the set including Bob and we'll be fine.


The important insight about the difference between this proposal and
proposal 134 is that proposal 165 fails conservatively, and only fails
during migration: Given a functional authority set endorsed by all
honest authorities, I think there is nothing a hostile minority can do
on their to make the honest authorities stop generating a correct
consensus with that authority set.

yrs,
-- 
Nick

</body></email><email><emailId>20090528210209</emailId><senderName>Paul Syverson</senderName><senderEmail>syverson@itd.nrl.navy.mil</senderEmail><timestampReceived>2009-05-28 21:02:09-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

On Thu, May 28, 2009 at 04:23:57PM -0400, Nick Mathewson wrote:
&gt; On Thu, May 28, 2009 at 03:58:42PM -0400, Paul Syverson wrote:
&gt; &gt; Hi Nick et al.,
&gt; &gt; 
&gt; &gt; Two things:
&gt; &gt; 
&gt; &gt; 1. I think you mean that an authority votes with whatever the largest
&gt; &gt; set is that it lists that is listed by the most members of that set. 
&gt; &gt; (I added "largest" to your criterion.)
&gt; &gt; 
&gt; &gt; I guess there is an ambiguity of 'most' but if you have a set and a
&gt; &gt; proper subset, both of which are listed by all the members of each,
&gt; &gt; then the ones in the smaller set have no basis to prefer the larger
&gt; &gt; one and will never drop the smaller one. If by 'most' you implicitly
&gt; &gt; mean biggest rather than largest fraction, it is confusing since
&gt; &gt; it is no longer relative to the givne voting set but relative to
&gt; &gt; others.
&gt; 
&gt; Okay, I'll try again.  What I meant is that, given two sets S1 and S2 that an
&gt; authority lists, that authority will prefer S1 over S2 whenever the
&gt; number of other authorities in S1 that themselves list S1 is higher
&gt; than the number of other authorities in S2 that themselves list S2.
&gt; 

Much clearer, at least to me.


&gt; &gt; 2. More significantly, there is something I don't get about the
&gt; &gt; proposal. I think I understand the problem with proposal 134. It seems
&gt; &gt; like a standard byzantine failure when there are not at least 3n+1
&gt; &gt; honest and correct voters, where n is the number of dishonest, but I
&gt; &gt; didn't look at it closely to see if there are some differences.
&gt; &gt; 
&gt; &gt; The new proposal is not that bad, but it still allows a single
&gt; &gt; hostile authority to prevent the addition of a new authority.
&gt; &gt; 
&gt; &gt; If Alice does not want to add authority Bob, then she
&gt; &gt; refuses to make a voting set containing him. Other honest-correct
&gt; &gt; authorities will not prefer the new voting set until some of them drop
&gt; &gt; the old one that did not have Bob in it. But none of them should
&gt; &gt; ever do that because the voting set without Bob in it is preferred by
&gt; &gt; a larger majority of its members.
&gt; 
&gt; Right.
&gt; 
&gt; Please take the entire section "How to migrate authority sets" as
&gt; normative rather than a complete description of how to upgrade: if one
&gt; of the authority operators doesn't participate, then the other
&gt; operators need to manually intervene and either stop listing sets that
&gt; include that operator's authority, or convince that operator to
&gt; upgrade.

Yes. I was going to suggest something like that, but I wanted to make
sure I understood first. Also, I wasn't confident exactly what else
could happen once that were allowed. I'm still not sure, but maybe
it's fine. I need to think about it more or to be convinced.
Anyway, might be moot. See below.

&gt; 
&gt; &gt; If 'most' is interpreted as discussed in 1. above, the same problem
&gt; &gt; applies, but you need two hostile authorities to make sure Bob can never
&gt; &gt; get in no matter what the rest of the authorities do.
&gt; 
&gt; Well, that's only unless 3 other authorities stop listing the sets
&gt; that _don't_ include Bob.
&gt; 

Right, but they shouldn't if they are honest. See below.

&gt; &gt; Similarly, if the honest authorities want to drop Bob, as long as two
&gt; &gt; existing authorities (possibly but not necessarily one being Bob) want
&gt; &gt; to maintain him, then none should ever delist the larger set because
&gt; &gt; it will always be preferred over the smaller one. So he won't
&gt; &gt; get dropped.
&gt; 
&gt; Here you're missing the line that says
&gt; 
&gt;    Once enough authorities list the new set as acceptable, we start
&gt;    having authorities stop listing the old set.  Once there are more
&gt;    listing the new set than the old set, the new set will win.
&gt; 
&gt; In other words, once the operators notice that enough authorities are
&gt; listing the set-minus-Bob, they manually stop listing
&gt; sets-including-Bob.  Assuming that there are N authorities (including
&gt; Bob), once N-1 authorities list the set without Bob, we need just 2
&gt; authorities to drop the set including Bob and we'll be fine.
&gt; 

I didn't miss the line. My point is that you won't ever get
any honest authorities to drop the set including Bob, so you will
never make it to 2 without changing something in the protocol.
if either of those two authorities drop the list that includes Bob,
they will not be honest (following the proposed protocol), because
they are supposed to prefer the voting set for which the number of
authorities that list themselves in it is higher not just the
one that is moving in the direction they would like to go.
It's the criterion for delisting a set that does not work.



You don't want to force simultaneous action: that was the whole point.
And you don't want to let a minority remove Bob on their own.  I think
you need to add something like an explicit suggested voting set change
to the protocol rather than it just being implicit in the voting sets
everyone has. If there is an explicit suggestion to replace one voting
set with another, then once a majority have started listing the new
set any one of them can correctly delist the old one. Maybe you
had something like that implicitly in mind, but I didn't see it in
the proposal. (Or maybe I'm still wrong and still dont see it?)


&gt; 
&gt; The important insight about the difference between this proposal and
&gt; proposal 134 is that proposal 165 fails conservatively, and only fails
&gt; during migration: Given a functional authority set endorsed by all
&gt; honest authorities, I think there is nothing a hostile minority can do
&gt; on their to make the honest authorities stop generating a correct
&gt; consensus with that authority set.
&gt; 

I kind of agree. My intuition is that what they can do, however,
is prevent the set of authorities from ever changing, and "they"
can be even smaller than just a minority: two authorities suffice.
See if you think the above fixes it.

aloha,
Paul
</body></email><email><emailId>20090528211126</emailId><senderName>Marcus Griep</senderName><senderEmail>tormaster@xpdm.us</senderEmail><timestampReceived>2009-05-28 21:11:26-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>


I'm probably jumping into the middle of a debate I know nothing
about, but I think I have a clarification of note:

Paul Syverson wrote:
&gt; I didn't miss the line. My point is that you won't ever get
&gt; any honest authorities to drop the set including Bob, so you will
&gt; never make it to 2 without changing something in the protocol.
&gt; if either of those two authorities drop the list that includes Bob,
&gt; they will not be honest (following the proposed protocol), because
&gt; they are supposed to prefer the voting set for which the number of
&gt; authorities that list themselves in it is higher not just the
&gt; one that is moving in the direction they would like to go.
&gt; It's the criterion for delisting a set that does not work.

Each authority would have multiple voting sets. When we want to
"drop Bob", we don't just drop Bob from the voting set. We create a
new voting set that doesn't contain Bob (VS-B) and publish that
along with the old voting set with Bob (VS+B). This doesn't need to
happen all at once; VS+B remains the consensus vote. However, once a
(super)majority (the level 'X') is reached, the authorities take
action again and begin removing VS+B. Once the numebr of authorities
in VS-B listing VS-B as one of their voting sets is greater than the
number of authorities in VS+B listing VS-B as on of their voting
sets, VS-B becomes the consensus vote.

-- 
Marcus Griep
GPG Key ID: 0x070E3F2D
������
https://torproj.xpdm.us
������������ ����.���� �, 3 �


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090528212956</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-28 21:29:56-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

On Thu, May 28, 2009 at 05:11:26PM -0400, Marcus Griep wrote:
&gt; I'm probably jumping into the middle of a debate I know nothing
&gt; about, but I think I have a clarification of note:
&gt; 
&gt; Paul Syverson wrote:
&gt; &gt; I didn't miss the line. My point is that you won't ever get
&gt; &gt; any honest authorities to drop the set including Bob, so you will
&gt; &gt; never make it to 2 without changing something in the protocol.
&gt; &gt; if either of those two authorities drop the list that includes Bob,
&gt; &gt; they will not be honest (following the proposed protocol), because
&gt; &gt; they are supposed to prefer the voting set for which the number of
&gt; &gt; authorities that list themselves in it is higher not just the
&gt; &gt; one that is moving in the direction they would like to go.
&gt; &gt; It's the criterion for delisting a set that does not work.
&gt; 
&gt; Each authority would have multiple voting sets. When we want to
&gt; "drop Bob", we don't just drop Bob from the voting set. We create a
&gt; new voting set that doesn't contain Bob (VS-B) and publish that
&gt; along with the old voting set with Bob (VS+B). This doesn't need to
&gt; happen all at once; VS+B remains the consensus vote. However, once a
&gt; (super)majority (the level 'X') is reached, the authorities take
&gt; action again and begin removing VS+B. Once the numebr of authorities
&gt; in VS-B listing VS-B as one of their voting sets is greater than the
&gt; number of authorities in VS+B listing VS-B as on of their voting
&gt; sets, VS-B becomes the consensus vote.

I think that one problem we've got in the discussion here is that we
aren't distinguishing well between the authority directory servers and
the operators of those servers.  My plan here has been that changes in
listed authority sets should only happens on the initiative of the
operators.  The servers on their own never decide it's time to start
or stop listing a given set.  Human intervention is explicitly
required.


-- 
Nick
</body></email><email><emailId>20090528220015</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-28 22:00:15-0400</timestampReceived><subject>Re: Proposal 165: Easy migration for voting authority sets</subject><body>

On Thu, May 28, 2009 at 05:02:09PM -0400, Paul Syverson wrote:
&gt; On Thu, May 28, 2009 at 04:23:57PM -0400, Nick Mathewson wrote:
&gt; &gt; On Thu, May 28, 2009 at 03:58:42PM -0400, Paul Syverson wrote:
&gt; &gt; &gt; Hi Nick et al.,
&gt; &gt; &gt; 
&gt; &gt; &gt; Two things:
&gt; &gt; &gt; 
&gt; &gt; &gt; 1. I think you mean that an authority votes with whatever the largest
&gt; &gt; &gt; set is that it lists that is listed by the most members of that set. 
&gt; &gt; &gt; (I added "largest" to your criterion.)
&gt; &gt; &gt; 
&gt; &gt; &gt; I guess there is an ambiguity of 'most' but if you have a set and a
&gt; &gt; &gt; proper subset, both of which are listed by all the members of each,
&gt; &gt; &gt; then the ones in the smaller set have no basis to prefer the larger
&gt; &gt; &gt; one and will never drop the smaller one. If by 'most' you implicitly
&gt; &gt; &gt; mean biggest rather than largest fraction, it is confusing since
&gt; &gt; &gt; it is no longer relative to the givne voting set but relative to
&gt; &gt; &gt; others.
&gt; &gt; 
&gt; &gt; Okay, I'll try again.  What I meant is that, given two sets S1 and S2 that an
&gt; &gt; authority lists, that authority will prefer S1 over S2 whenever the
&gt; &gt; number of other authorities in S1 that themselves list S1 is higher
&gt; &gt; than the number of other authorities in S2 that themselves list S2.
&gt; &gt; 
&gt; 
&gt; Much clearer, at least to me.

Okay.  Next time I revise this proposal, I'll put it in.

[...]
&gt; &gt; Here you're missing the line that says
&gt; &gt; 
&gt; &gt;    Once enough authorities list the new set as acceptable, we start
&gt; &gt;    having authorities stop listing the old set.  Once there are more
&gt; &gt;    listing the new set than the old set, the new set will win.
&gt; &gt; 
&gt; &gt; In other words, once the operators notice that enough authorities are
&gt; &gt; listing the set-minus-Bob, they manually stop listing
&gt; &gt; sets-including-Bob.  Assuming that there are N authorities (including
&gt; &gt; Bob), once N-1 authorities list the set without Bob, we need just 2
&gt; &gt; authorities to drop the set including Bob and we'll be fine.
&gt; &gt; 
&gt; 
&gt; I didn't miss the line. My point is that you won't ever get
&gt; any honest authorities to drop the set including Bob, so you will
&gt; never make it to 2 without changing something in the protocol.
&gt; if either of those two authorities drop the list that includes Bob,
&gt; they will not be honest (following the proposed protocol), because
&gt; they are supposed to prefer the voting set for which the number of
&gt; authorities that list themselves in it is higher not just the
&gt; one that is moving in the direction they would like to go.
&gt; It's the criterion for delisting a set that does not work.

Oh!  Okay, no, I've explained the protocol wrong.

When I say that authorities prefer the more-approved set, that _only
applies to choosing who the voters are in a given round of voting_.
It doesn't apply to deciding which sets to list in a vote.

Deciding which sets to list is a manual decision made by the authority
operators.  My intent was that the operator of an honest is absolutely
allowed to de-list an obsolete but larger set.  Authority operators
need to coordinate their actions here out-of-band.

Did that clear it up?

peace,
-- 
Nick
</body></email><email><emailId>20090513044605</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2009-05-13 04:46:05-0400</timestampReceived><subject>Re: Proposal 161: Computing Bandwidth Adjustments</subject><body>


Thus spake Nick Mathewson (nickm@torproject.org):

&gt; &gt; 2. Average Stream Bandwidth Calculation
&gt; &gt;  
&gt; &gt;   The average stream bandwidths are obtained by dividing the network
&gt; &gt;   into 3% slices according to advertised node bandwidth, yielding 
&gt; &gt;   about 45 nodes per slice in the current network.
&gt; &gt; 
&gt; &gt;   Two hop circuits are built using nodes from the same slice, and a large
&gt; &gt;   file is downloaded via these circuits. This process is repeated
&gt; &gt;   several hundred times, and average stream capacities are assigned to
&gt; &gt;   each node from these results.
&gt; 
&gt; There are some magic numbers here: Why 3%?  How large are these files
&gt; and how often are they downloaded?  Why "several hundred"?  Is the
&gt; "several hundred" a function of the "45" above?

Currently no. I've been meaning to do some statistics on how long it
takes to converge. Eyeballing seems to indicate the filtered values
converge after about 100 fetches or so, or about 3-4 per node. I've
been doing runs of 250 just for good measure.

&gt; I want to see a calculation for what fraction of the network capacity
&gt; we expect to use for this testing.  I wouldn't expect it to be over a
&gt; percent, but I'd like to see the math to prove it.

This is a function of how much we parallelize and how many scanners we
have. Right now, there is 0 parallelization built in, which means that
each scanner takes up approximately 20-50Kbytes/sec of two nodes at a
time. This is compared to the 120Mbytes/sec of exit capacity Tor
currently has.
 
&gt; Also, how long does it take to run these tests over the network?  If
&gt; it takes much longer than a consensus interval, we should think about
&gt; what happens if a node's advertised capacity changes greatly, and
&gt; whether we want to treat newer measurements as more accurate.

Each slice takes around 3-6 hours. The entire network can take as long
as a week.. Hence the desire to parallelize..

For the capacity change case, let's consider what happens in stages:

 0. The node gets more capacity from its ISP or by boosting rate
    limiting (these may not actually be equivalent cases, but lets
    assume they are for now).
 1. It is able to transmit more bytes in a 10 second interval. If it 
    has enough clients trying to use it through other high capacity 
    nodes, it will eventually fill its capacity during this interval.
 2. Between now and the next time the consensus is published, the
    streams through it will exhibit higher average capacity.
 3. At the next consensus interval, the authorities will publish the
    higher advertised bandwidth that the node has observed.
 4. As the published value makes its way to clients, they will 
    choose the node more often for their streams.
 5. The average stream capacity of the node should now begin to drop.

Steps 1-3 may actually occur over several consensus intervals. I've
noticed that changing the capacity on my nodes drastically actually
takes several consensus publishings to really boost their observed
values to the maximum, probably because of the limiting factor of the
spare capacity of other nodes in the circuits that run through my
node.

So we can see that we may actually notice higher capacities of nodes
before the values are published in the consensus (ie steps 0-2). This
should not be a big problem, as our reported bandwidth updates will be
based on multiples of the old consensus values, and should approximate
the new capacity of the node.

The other issue is between steps 3 and 5: The node's new capacity is
published, but it is not yet attracting enough client traffic to bring
its average stream capacity down. In this case, we may publish a value
that is too high. 

I'm not sure what to do with this second problem as it is
non-deterministic. Using the alpha smoothing factor from your reply to
160 seems like it should help. I do actually track bandwidth changes
during the scan, I and I can write some code to abstain from
publishing updates to nodes whose bandwidths change drastically during
the scan. But what is "drastically", and is this edge case worth the
complexity, or is the alpha smoothing good enough?

&gt; Another possibility I want to consider: what if, instead of putting
&gt; nodes into slices based on their declared bandwidths, we put them into
&gt; slices based on the most recent bandwidth for them in the consensus?
&gt; That way, if a node advertises 100x as much bandwidth as it really
&gt; has, we will soon start measuring it along with the really other slow
&gt; nodes, rather than measuring it along with the high-capacity nodes
&gt; forever.
&gt; 
&gt; [Ah.  I see on IRC that the above paragraph is what you already have
&gt; in mind.]

Yes. We can also use the ratio of the consensus values to the
published values to evaluate experimental reweighting mechanisms (such
as Steven Murdoch's queuing theory-based weighting or adjusting
directory mirror weighting) without affecting the network balancing.
If the ratios get closer to 1, the new algorithm is an improvement. If
they get farther from 1, the new algorithm is worse.


&gt;  [...]
&gt; &gt; 3. Ratio Filtering
&gt; &gt; 
&gt; &gt;   After the base ratios are calculated, a second pass is performed
&gt; &gt;   to remove any streams with nodes of ratios less than X=0.5 from
&gt; &gt;   the results of other nodes.   In addition, all outlying streams
&gt; &gt;   with capacity of one standard deviation below a node's average
&gt; &gt;   are also removed.
&gt; &gt; 
&gt; &gt;   The final ratio result will be calculated as the maximum of 
&gt; &gt;   these two resulting ratios if both are less than 1.0, the minimum
&gt; &gt;   if both are greater than 1.0, and the mean if one is greater
&gt; &gt;   and one is less than 1.0.
&gt; 
&gt; I am little confused about what happens here.  Can you clarify this
&gt; with some pseudocode for the whole algorithm?  Based on what you've
&gt; written, I _think_ it would go something like:

This is roughly right except for step 4 and 6:
 
&gt;      1. Partition nodes into equal-sized sets of approximately 45
&gt;         nodes, dividing slices by declared bandwidth.
&gt;      2. For each slice, build about 100 two-hop circuits, and check
&gt;         the bandwidth on each.
&gt;      3. For each node N, let BW_measured(N) = MEAN(b | b is the bandwidth
&gt;         of a stream that went through N).
&gt;      4. For each slice S, let BW_avg(S) = MEAN(b | b is the bandwidth
&gt;         of a stream built through S).  Let BW_stddev(S) = The standard
&gt; 	deviation of all such streams.  Let Normal_Streams(S) = { all
&gt; 	streams in S such that their bandwidth b is at least 0.5 *
&gt;         BW_avg(S), and such that |b-BW_avg(S)|&lt;= BW_stddev(S) }


Let Bw_stddev(N) = Standard deviation of stream bw through node N

Let Normal_Routers(S) = 
   {all routers with Bw_measured(N)/Bw_avg(s) &gt; 0.5 }

Let Normal_Streams(N) = 
   {all streams containing N such that they do not contain any node in
    Normal_Routers(S) other than N and such that their capacity is 
    greater than BW_measured(N)-Bw_stddev(N) }

Let BW_avg2(S) = MEAN(b | b in Normal_Streams(N) for all N)

Note the high part of the stddev is not removed from Normal_Streams(N).


&gt;      5. For each node N, let BW_measured2(N) = MEAN(b | b is the bandwidth
&gt;         of a stream that went through N, for all streams in
&gt;         Normal_Streams(N))

Let Bw_Ratio(N) = Bw_measured(N)/Bw_avg(S)

Let Bw_Ratio2(N) = Bw_measured2(N)/Bw_avg2(S)

      6. For each node N, if BW_ratio and BW_ratio2 are on the
         same side of 1.0, let BW_final(N) be whichever of BW_ratio
         and BW_ratio2 is closer to 1.0.  Otherwise let BW_final(N)
         be the mean of BW_ratio and BW_ratio2.
&gt; 
&gt; Am I close?  Let's get the right pseudocode into the proposal; this is
&gt; a complicated enough algorithm that it could use a mathy exposition.

Ok. Will update it with some pseudocode based on the above.
 
&gt; Also, I'm not sure what the motivation is.  Have you tried it without
&gt; this step, and found that it didn't work so well?

Well, I was bothered by the fact that fast nodes were being penalized
by slow nodes when we happened to use both in the same circuit. I was
also bothered by the possibility of nodes being able to sabotage
faster nodes by acting really slow whenever they observed them as one
of their neighbors.

I actually notice better convergence if I employ filtering as well.

&gt; &gt; 4. Integration with Proposal 160
&gt; &gt; 
&gt; &gt;   The final results will be produced for the voting mechanism
&gt; &gt;   described in Proposal 160 by multiplying the derived ratio by 
&gt; &gt;   the average observed advertised bandwidth during the course of the
&gt; &gt;   scan. This will produce a new bandwidth value that will be 
&gt; &gt;   output into a file consisting of lines of the form:
&gt; &gt; 
&gt; &gt;   &lt;node-idhex&gt; SP new_bandwidth NL
&gt; &gt; 
&gt; &gt;   This file can be either copied or rsynced into a directory readable
&gt; &gt;   by the directory authority.
&gt; 
&gt; Let's make this a little more extensible, so we can add new fields in
&gt; the future without breaking things.  Let's say that the format is
&gt; 
&gt;     "node id=&lt;idhex&gt; SP bw=&lt;new_bandwidth&gt; NL"
&gt; 
&gt; and specify that implementations must ignore any lines starting with
&gt; any keywords they don't recognize, or any key=value values inside a
&gt; line if they don't recognize the keyword.
&gt; 
&gt; That way, if we want to tell Tor more in the future, we can.
&gt; 
&gt; 
&gt; * *
&gt; 
&gt; So, something that didn't come up: I think that it's important to have
&gt; values for weights change a bit slowly based on node speed or
&gt; slowness.  Otherwise, we can wind up with a situation where we notice
&gt; a node is slow, so everybody leaves, so we notice it is fast, so
&gt; everybody hammers it.  I _think_ that the above algorithm has this
&gt; property--does it?
&gt; 
&gt; (Crazy idea 1: If the values change too fast or slow, we could
&gt; exponentiate the ratios out of the algorithm before using them.
&gt; Slightly less crazy idea 2: if the values change too fast, we could do
&gt; a standard time-weighted average, where we compute the new declared
&gt; bandwidth BW' as a weighted average of the old declared bandwidth and
&gt; the new measured bandwidth.)

Yeah, I like idea 2, basically what you mentioned in 160. This would
be done Tor-end, not scanner end, right?


-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20090513053006</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-05-13 05:30:06-0400</timestampReceived><subject>Re: Proposal 161: Computing Bandwidth Adjustments</subject><body>

On Tue, May 12, 2009 at 09:46:05PM -0700, Mike Perry uttered:
&gt; Thus spake Nick Mathewson (nickm@torproject.org):
 [...]
&gt; &gt; There are some magic numbers here: Why 3%?  How large are these files
&gt; &gt; and how often are they downloaded?  Why "several hundred"?  Is the
&gt; &gt; "several hundred" a function of the "45" above?
&gt; 
&gt; Currently no. I've been meaning to do some statistics on how long it
&gt; takes to converge. Eyeballing seems to indicate the filtered values
&gt; converge after about 100 fetches or so, or about 3-4 per node. I've
&gt; been doing runs of 250 just for good measure.

As discussed on IRC, we should see if we can get away with fetching
smaller files to test the weaker slices. If we can, hooray for us!  If
it doesn't work, too bad. :/

As for the slice size, it seems that maybe a quasi-constant slice size
would work better than having it be fixed at 3% of the network.  That
way, we always send the same amount of traffic per node, rather than
getting sparser and sparser as the slices get bigger but our traffic
stays the same.

&gt; &gt; I want to see a calculation for what fraction of the network capacity
&gt; &gt; we expect to use for this testing.  I wouldn't expect it to be over a
&gt; &gt; percent, but I'd like to see the math to prove it.
&gt; 
&gt; This is a function of how much we parallelize and how many scanners we
&gt; have. Right now, there is 0 parallelization built in, which means that
&gt; each scanner takes up approximately 20-50Kbytes/sec of two nodes at a
&gt; time. This is compared to the 120Mbytes/sec of exit capacity Tor
&gt; currently has.
&gt;  
&gt; &gt; Also, how long does it take to run these tests over the network?  If
&gt; &gt; it takes much longer than a consensus interval, we should think about
&gt; &gt; what happens if a node's advertised capacity changes greatly, and
&gt; &gt; whether we want to treat newer measurements as more accurate.
&gt; 
&gt; Each slice takes around 3-6 hours. The entire network can take as long
&gt; as a week.. Hence the desire to parallelize..

My intuition says that unless we scan the whole network every two days
(or ideally less), our data will likely be useless.

What if, instead of running in a batch mode, we were constantly
scanning and iteratively refining our guesses for ratios, discounting
old data as newer data arrived?  We'd still want to parallelize some,
but we wouldn't run into the problem of having some nodes' estimated
values be far more accurate than others.

&gt; For the capacity change case, let's consider what happens in stages:
&gt; 
&gt;  0. The node gets more capacity from its ISP or by boosting rate
&gt;     limiting (these may not actually be equivalent cases, but lets
&gt;     assume they are for now).
&gt;  1. It is able to transmit more bytes in a 10 second interval. If it 
&gt;     has enough clients trying to use it through other high capacity 
&gt;     nodes, it will eventually fill its capacity during this interval.
&gt;  2. Between now and the next time the consensus is published, the
&gt;     streams through it will exhibit higher average capacity.
&gt;  3. At the next consensus interval, the authorities will publish the
&gt;     higher advertised bandwidth that the node has observed.
&gt;  4. As the published value makes its way to clients, they will 
&gt;     choose the node more often for their streams.
&gt;  5. The average stream capacity of the node should now begin to drop.
&gt; 
&gt; Steps 1-3 may actually occur over several consensus intervals. I've
&gt; noticed that changing the capacity on my nodes drastically actually
&gt; takes several consensus publishings to really boost their observed
&gt; values to the maximum, probably because of the limiting factor of the
&gt; spare capacity of other nodes in the circuits that run through my
&gt; node.
&gt; 
&gt; So we can see that we may actually notice higher capacities of nodes
&gt; before the values are published in the consensus (ie steps 0-2). This
&gt; should not be a big problem, as our reported bandwidth updates will be
&gt; based on multiples of the old consensus values, and should approximate
&gt; the new capacity of the node.
&gt;
&gt; The other issue is between steps 3 and 5: The node's new capacity is
&gt; published, but it is not yet attracting enough client traffic to bring
&gt; its average stream capacity down. In this case, we may publish a value
&gt; that is too high. 
&gt; 
&gt; I'm not sure what to do with this second problem as it is
&gt; non-deterministic. Using the alpha smoothing factor from your reply to
&gt; 160 seems like it should help. I do actually track bandwidth changes
&gt; during the scan, I and I can write some code to abstain from
&gt; publishing updates to nodes whose bandwidths change drastically during
&gt; the scan. But what is "drastically", and is this edge case worth the
&gt; complexity, or is the alpha smoothing good enough?

I don't know, alas.  Is there a way we can measure how this is working
in practice?  I think that if we refresh our bandwidth estimates only
(say) every day or so, we will really hammer nodes that want to change
their bandwidth downward, which seems poor.  Lagging on nodes that
raise their bandwidth isn't quite as bad.

Roger -- any intuition on this one?  It is too hard for 01:30 EDT Nick.

 [...]
&gt; &gt; (Crazy idea 1: If the values change too fast or slow, we could
&gt; &gt; exponentiate the ratios out of the algorithm before using them.
&gt; &gt; Slightly less crazy idea 2: if the values change too fast, we could do
&gt; &gt; a standard time-weighted average, where we compute the new declared
&gt; &gt; bandwidth BW' as a weighted average of the old declared bandwidth and
&gt; &gt; the new measured bandwidth.)
&gt; 
&gt; Yeah, I like idea 2, basically what you mentioned in 160. This would
&gt; be done Tor-end, not scanner end, right?

I don't have a strong feeling about that.  To me, it seems easier to
do it at the scanner end, or as a processing step between the scanner
end and the authorities... but that's just because I'm thinking of the
scanner stuff as easier to change if we think of a better algorithm.

yrs,
-- 
Nick
</body></email><email><emailId>20090308232037</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-03-08 23:20:37-0400</timestampReceived><subject>Re: [PATCH] Fix VPATH builds</subject><body>

On Sun, Mar 08, 2009 at 12:44:43AM -0500, Michael Gold wrote:
&gt; While writing my previous patch I fixed a bug that was causing VPATH
&gt; builds to fail.  As Nick suggested, I've separated the fix into it's own
&gt; patch, which is attached.  It's against 0.2.0.34 but also applies to
&gt; 0.2.1.12-alpha (I haven't tested it on that version, but I don't see
&gt; anything that would cause problems).  I suggest applying it to both
&gt; versions.

Thanks; applied to 0.2.1.x and marked for backport to 0.2.0.x branch.

yrs,
-- 
Nick
</body></email><email><emailId>20090313092854</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-03-13 09:28:54-0400</timestampReceived><subject>Re: Effect of Tor window size on performance</subject><body>

On Mon, Feb 16, 2009 at 12:26:32PM +0100, Csaba Kiraly wrote:
&gt; &gt;Hey, that's a really good point. We don't have to change much code at
&gt; &gt;all if we want to use a *smaller* package window than we are allowed. We
&gt; &gt;simply pretend that the package window started out smaller, and either
&gt; &gt;side can do that independently!
&gt; &gt;
&gt; &gt;Do you have a patch in mind for this? It would seem that if we
&gt; &gt;change init_circuit_base() so it sets circ-&gt;package_window to some
&gt; &gt;lower number x, and change connection_exit_begin_conn() so it sets
&gt; &gt;nstream-&gt;package_window to some even lower number y, that should be it.
&gt; &gt;The client side will send sendme's like normal, and the only difference
&gt; &gt;is that no more than y cells will ever be 'in flight' for a given stream.
&gt; &gt;  
&gt; Its not even that "complicated", you already have the defines in or.h :-)
&gt; #define CIRCWINDOW_START 1000
&gt; #define CIRCWINDOW_INCREMENT 100
&gt; #define STREAMWINDOW_START 500
&gt; #define STREAMWINDOW_INCREMENT 50
&gt; 
&gt; In our test code we've also changed some other things to have a better 
&gt; control of the test environment, but the modification needed is only to 
&gt; change these.

I think just changing those defines won't work. The problem is that we
set both the package_window and the deliver_window to be that number.

And if we set the deliver_window to be 100, and the other side hasn't
applied the patch (so they set their package_window to be 1000), we will
start hanging up on their circuits because they're breaking the protocol.

Your patch should work in a Tor network consisting only of patched Tors.
But it shouldn't work in a hybrid network.

Unless I'm wrong. :)

&gt; &gt;1) What values of x and y are best? Presumably as we reduce them from
&gt; &gt;1000 and 500, the performance gets better, but at some point they become
&gt; &gt;so low that performance gets worse (because each round-trip through the
&gt; &gt;network takes extra time). As sample numbers, if we start x at 100 and
&gt; &gt;y at 50, then we need another round-trip for any stream that delivers
&gt; &gt;more than 24900 bytes, and/or for every 49800 bytes on the circuit.
&gt; &gt;Should our choices be influenced by the 'typical' Tor stream that the
&gt; &gt;network is seeing right now? (Not that we have those numbers, but maybe
&gt; &gt;we should get them.) What other factors are there?
&gt; &gt;  
&gt; Note that changing y would also change our overhead. Currently with 100 
&gt; it is 1% (1 send_me sent back for every 100 cells received).

I should clarify that if we don't want to change existing clients much,
we are limited in changes we can make.

Specifically, we can't choose a circuit package window over 1000 or
under 100, and the circuit sendme value must remain 100.

Similarly, we can't choose a stream package window over 500 or under 50,
and the stream sendme value must remain 50.

&gt; Another thing to consider is the x/y ratio. Currently it is 10. Lets see 

No, currently the ratio is 1000/500 = 2. I think we're confusing our
variables below. :)

&gt; some considerations:
&gt; - 2 seems a bit low: Say A and B are the two ends of the circuit and 
&gt; traffic flows mainly from A to B. Assuming that one-way delays are equal 
&gt; in both directions (this is reasonable since we have asymmetry only in 
&gt; the A-B traffic, but overlay links of the same path are used by other 
&gt; circuits in the reverse direction as well), the send_me cell is sent 
&gt; from B when half of the cells arrives. The send_me arrives back to A 
&gt; when all the cells have arrived to B. At this point A can start pumping 
&gt; in new cells, which might be a bit late.
&gt; - 10 might be a bit large, I don't think we have such asymmetries in the 
&gt; network, between OR nodes that justify such a high factor.

My current understanding of what happens is that most of the cells
in the window arrive at about the same time. That is, the exit relay
packages all 500 cells that are allowed in the stream window, and pushes
them down the circuit, and then goes silent. They arrive to the client
at about the same time, so the client sends 10 sendme cells back. The
sendme cells arrive at the exit relay at about the same time, so it
packages another 500 cells. Repeat.

My original goal with "fine-grained" sendmes was that the data cells
coming from the exit relay would be spread throughout the circuit, and
if we could get a sendme cell back to the exit relay before the last
data cells arrive, the flow would never have to slow down. I didn't
anticipate how much end-to-end latency there would be, though. Now that
cells get buffered for entire seconds at intermediate relays, my original
idea looks kind of stupid. (If they were to get split up in the network,
such that some were arriving when others were still stuck in the circuit,
it would look more like a good idea again. I wonder how to learn whether
that happens.)

So overall, we should be thinking of our total window size as a block
of cells that will go through the network all at once. The bigger the
size is, the more congestion it will produce with other blocks-of-cells.
Whereas the smaller the size is, the lower the maximum data rate can be.

And the fact that it takes more than one sendme cell to refill the window
is basically now a bug.

&gt; I think 500 is a safe bet for x to start with, but from our measurements 
&gt; it seems that even 200 would do fine with nice performance improvements. 
&gt; Of course we are working on more measurements to be on the safe side.

If our goal is to reduce the amount of clutter inside the network, I'm
inclined to go for the smallest numbers we can: circuit window of 100
and stream window of 50 (which can be refilled by one sendme cell).

After all, trying to optimize bandwidth hasn't worked very well, because
there are people out there who want to use way more bandwidth than Tor
can provide. Maybe we should give optimizing latency a shot next.

So to think this through: at 50 cells per stream window, we're saying
that any file less than 25KB can be gotten in one 'go', and after that
we require one extra network round-trip per 25KB we want. We'd better be
cutting down latency a lot by this change, or the additional round-trips
will put any latency savings back in.

Can we come up with a number for average webpage size we want to optimize
for (and deviation around that average)? If we find that many people
want 30KB files, then choosing a window of 25KB isn't smart.

&gt; &gt;2) What are the effects of this patch in a hybrid Tor network? If some
&gt; &gt;exit relays use package windows of 1000, and newer ones use package
&gt; &gt;windows of 100, will the newer ones get 'clobbered' by the old ones?
&gt; &gt;That is, should we expect to see even more slow-down in the network
&gt; &gt;while the relays transition? Is there anything we can do about that,
&gt; &gt;since it will take a year or more for everybody to transition?
&gt; &gt;  
&gt; We've already done measurements on what we call the asymmetric scenario, 
&gt; i.e. where the client is the old one and the exit node is the new one. 
&gt; It seems that performance improvements are there. We are currently 
&gt; thinking of some "fairness" tests; we have some ideas, but it is not yet 
&gt; exactly clear how to perform them. Anyway, from current numbers it seems 
&gt; that the 'clobbered' ones would be the old ones, so at least we have one 
&gt; more incentive for people to change version :-)

Ah, I think you misunderstand. I meant a network where some exit relays
use the new package window and some use the old one.

Imagine a network where one exit relay uses the new package window
(25KB/50KB), and all the other exit relays use the old package window
(250KB/500KB). Assume a set of clients, some of which are trying to fetch
huge files via Tor.

Anybody who picks the normal (old-style) exit relays will get 250KB of
data per round-trip. But anybody who picks the new exit relay gets only
25KB of data per round-trip.

If most exit relays are still sending back 250KB blocks, then anybody
who picks the new exit relay is going to get the worst of both worlds:
a) a Tor network with really high latency, and b) only 25KB at a time.

But I guess it's not as bad as it could be. It could be that the user
gets worse performance when she upgrades to a smaller circuit window, so
she would choose to never upgrade. (This situation will actually happen
with respect to uploading lots of data, since the client's package window
comes into play there. But I think that's rarer.)

--Roger

</body></email><email><emailId>20090216112632</emailId><senderName>Csaba Kiraly</senderName><senderEmail>kiraly@disi.unitn.it</senderEmail><timestampReceived>2009-02-16 11:26:32-0400</timestampReceived><subject>Re: Effect of Tor window size on performance</subject><body>

Roger Dingledine wrote:
&gt; On Wed, Feb 04, 2009 at 10:25:31AM +0100, Csaba Kiraly wrote:
&gt;   
&gt;&gt; http://disi.unitn.it/locigno/preprints/TR-DISI-08-041.pdf
&gt;&gt;     
&gt; [snip]
&gt;   
[snip]
&gt;&gt;&gt; So the next question is an implementation one. Right now the window sizes
&gt;&gt;&gt; are hard-coded at both ends. I've been meaning to extend the protocol
&gt;&gt;&gt; so sendme cells have a number in them, and so the initial window sizes
&gt;&gt;&gt; are specified in the 'create' and 'created' cells for circuits and the
&gt;&gt;&gt; 'begin' and 'connected' cells for streams. But we haven't really fleshed
&gt;&gt;&gt; out the details of those designs, or how they could be phased in and still
&gt;&gt;&gt; handle clients and relays that don't use (or know about) the numbers.
&gt;&gt;&gt;
&gt;&gt;&gt; So the big deployment question is: is it worth it to work on a design
&gt;&gt;&gt; for the above, and then either shrink the default window sizes or do
&gt;&gt;&gt; something smarter like variable window sizes, or should we just be
&gt;&gt;&gt; patient until a UDP-based solution is more within reach?
&gt;&gt;&gt;
&gt;&gt;&gt; One answer is that if you were interested in working on a design proposal
&gt;&gt;&gt; and patch, it would be much more likely to get implemented. :)
&gt;&gt;&gt;  
&gt;&gt;&gt;       
&gt;&gt; We are doing verifications on this. Our lab experiments (the ones in the 
&gt;&gt; tech report) show that there is a huge gain on the user side in delays, 
&gt;&gt; while throughput is untouched. Throughput is capped with a static window 
&gt;&gt; size, but I think the cap can be chosen better than what it is now. 
&gt;&gt; There should also be a big gain in the memory consumption of ORs, 
&gt;&gt; although we didn't measure it yet. Since the Tor network is kind of 
&gt;&gt; overloaded all the time, memory usage should decrease almost linearly 
&gt;&gt; with the window size.
&gt;&gt;
&gt;&gt; Currently we are verifying one-side modification of the circuit, i.e. 
&gt;&gt; whether one side of the connection can reduce the widow size on its own, 
&gt;&gt; without explicitly notifying the other side.  From the  code it seems to 
&gt;&gt; me that this will work, and if so, phasing in a smaller window size in a 
&gt;&gt; new release should not be a problem.
&gt;&gt;     
&gt;
&gt; Hey, that's a really good point. We don't have to change much code at
&gt; all if we want to use a *smaller* package window than we are allowed. We
&gt; simply pretend that the package window started out smaller, and either
&gt; side can do that independently!
&gt;
&gt; Do you have a patch in mind for this? It would seem that if we
&gt; change init_circuit_base() so it sets circ-&gt;package_window to some
&gt; lower number x, and change connection_exit_begin_conn() so it sets
&gt; nstream-&gt;package_window to some even lower number y, that should be it.
&gt; The client side will send sendme's like normal, and the only difference
&gt; is that no more than y cells will ever be 'in flight' for a given stream.
&gt;   
Its not even that "complicated", you already have the defines in or.h :-)
#define CIRCWINDOW_START 1000
#define CIRCWINDOW_INCREMENT 100
#define STREAMWINDOW_START 500
#define STREAMWINDOW_INCREMENT 50

In our test code we've also changed some other things to have a better 
control of the test environment, but the modification needed is only to 
change these.

&gt; So here are the questions we need to consider:
&gt;
&gt; 1) What values of x and y are best? Presumably as we reduce them from
&gt; 1000 and 500, the performance gets better, but at some point they become
&gt; so low that performance gets worse (because each round-trip through the
&gt; network takes extra time). As sample numbers, if we start x at 100 and
&gt; y at 50, then we need another round-trip for any stream that delivers
&gt; more than 24900 bytes, and/or for every 49800 bytes on the circuit.
&gt; Should our choices be influenced by the 'typical' Tor stream that the
&gt; network is seeing right now? (Not that we have those numbers, but maybe
&gt; we should get them.) What other factors are there?
&gt;   
Note that changing y would also change our overhead. Currently with 100 
it is 1% (1 send_me sent back for every 100 cells received). This extra 
traffic is on the "backward" path, so in the typical download scenario, 
the overhead would be on the ADSL uplink. Increasing it too much would 
be bad, but I think 5% is still fine.
What points in the direction of reducing y is that with a lower y we 
have less burstiness in the traffic pumped in the circuit by the exit 
node, which typically improves performance.

Another thing to consider is the x/y ratio. Currently it is 10. Lets see 
some considerations:
- 2 seems a bit low: Say A and B are the two ends of the circuit and 
traffic flows mainly from A to B. Assuming that one-way delays are equal 
in both directions (this is reasonable since we have asymmetry only in 
the A-B traffic, but overlay links of the same path are used by other 
circuits in the reverse direction as well), the send_me cell is sent 
from B when half of the cells arrives. The send_me arrives back to A 
when all the cells have arrived to B. At this point A can start pumping 
in new cells, which might be a bit late.
- 10 might be a bit large, I don't think we have such asymmetries in the 
network, between OR nodes that justify such a high factor.

I think 500 is a safe bet for x to start with, but from our measurements 
it seems that even 200 would do fine with nice performance improvements. 
Of course we are working on more measurements to be on the safe side.

&gt; 2) What are the effects of this patch in a hybrid Tor network? If some
&gt; exit relays use package windows of 1000, and newer ones use package
&gt; windows of 100, will the newer ones get 'clobbered' by the old ones?
&gt; That is, should we expect to see even more slow-down in the network
&gt; while the relays transition? Is there anything we can do about that,
&gt; since it will take a year or more for everybody to transition?
&gt;   
We've already done measurements on what we call the asymmetric scenario, 
i.e. where the client is the old one and the exit node is the new one. 
It seems that performance improvements are there. We are currently 
thinking of some "fairness" tests; we have some ideas, but it is not yet 
exactly clear how to perform them. Anyway, from current numbers it seems 
that the 'clobbered' ones would be the old ones, so at least we have one 
more incentive for people to change version :-)

Note that in this scenario y is practically 100 (client side matters), 
while have done tests with x (server side) from 10000 down to 200. We 
will add 100, just to see how things go bad with that.
&gt; 3) Should we reduce the package_windows on the client side too? It would
&gt; be easy to do. How do we decide whether it's worth it?
&gt;   
I think it would be better to do it symmetrically, not differentiating 
between the two sides. On one hand, with the typical client use, i.e. 
web browsing, upload traffic is small so the value does not really 
matter. Browsers do some pipelining of HTTP requests in 1.1,  but that 
should still be small amount of data. On the other hand, if a "client" 
starts to do some nasty things, or just uploads a file, a lower window 
value should be beneficial,  just like in the exit node's case. I don't 
think there are any asymmetries in the circuits. As said before, they 
are bottlenecked because of the OR-OR connections traversed, and theses 
are bottlenecked both ways because of the many circuits passing through 
them.
&gt; Anything I missed?
&gt;
&gt; Thanks!
&gt; --Roger
&gt;   
I think thats all. We are doing some more measurements, and coming up 
with the results soon. As I said, the code modification is at the level 
of changing defines and simple recompile, but we should better verify 
more scenarios before making the change.
Thanks for the questions and ideas!
Csaba

</body></email><email><emailId>20090217235050</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2009-02-17 23:50:50-0400</timestampReceived><subject>Re: Proposal: Exit Scanning</subject><body>

&gt;
&gt;
&gt; &gt; Scanning methodology:
&gt; &gt;
&gt; &gt; The first scans to be implemented are HTTP, HTML, Javascript, and
&gt; &gt; SSL scans.
&gt; &gt;
&gt; &gt; The HTTP scan scrapes Google for common filetype urls such as exe, msi,
&gt; &gt; doc, dmg, etc. It then fetches these urls through Non-Tor and Tor, and
&gt; &gt; compares the SHA1 hases of the resulting content.
&gt;                       ^^hashes
&gt; &gt; The SSL scan downloads certificates for all IPs a domain will locally
&gt; &gt; resolve to and compares these certificates to those seen over Tor. The
&gt; &gt; scanner notes if a domain had rotated certificates locally in the
&gt; &gt; results for each scan.
&gt; &gt;
&gt; &gt; The HTML scan checks HTML, Javascript, and plugin content for
&gt; &gt; modifications. Because of the dynamic nature of most of the web, the
&gt; &gt; scanner has a number of mechanisms built in to filter out false
&gt; &gt; positives that are used when a change is noticed between Tor and
&gt; &gt; Non-Tor.
&gt;
&gt; As an eventual feature, for the above tests, it probably makes sense
&gt; to be able to imitate a few different popular browsers as the scanner
&gt; does its checks.  If an adversary can recognize the scanner, it can
&gt; MITM everything _but_ the scanner.
&gt;

You're right.  It would be best to imitate different browsers.

I got one thing to add to this.  Simply using a "User-Agent:" header isn't
good enough.  You will need to look at the order in which the headers are
sent.  As an example (which may or may not be accurate) FF may send
"User-Agent:" before a "Accept-Encoding:" where IE may do the opposite.  It
would be feasible for an attacker to analyze the order of the HTTP headers
to determine which browser is being used, or in this case, that a scanner is
being used.

I looked at this some time back and was able to guess, very accurately at
that, which browser was being used.  Specifically, I was looking for FF
agents pretending to be a different browser.

Just my $0.02...

- Kyle

[Attachment #3 (text/html)]

&lt;div class="gmail_quote"&gt;&lt;blockquote class="gmail_quote" style="margin:0 0 0 \
.8ex;border-left:1px #ccc solid;padding-left:1ex;"&gt;&lt;div class="Ih2E3d"&gt;&lt;br&gt; &gt; \
Scanning methodology:&lt;br&gt; &gt;&lt;br&gt;
&gt; The first scans to be implemented are HTTP, HTML, Javascript, and&lt;br&gt;
&gt; SSL scans.&lt;br&gt;
&gt;&lt;br&gt;
&gt; The HTTP scan scrapes Google for common filetype urls such as exe, msi,&lt;br&gt;
&gt; doc, dmg, etc. It then fetches these urls through Non-Tor and Tor, and&lt;br&gt;
&gt; compares the SHA1 hases of the resulting content.&lt;br&gt;
&lt;/div&gt;                     \
 ^^hashes&lt;br&gt; &lt;div class="Ih2E3d"&gt;&gt; The SSL scan downloads certificates for \
all IPs a domain will locally&lt;br&gt; &gt; resolve to and compares these certificates to \
those seen over Tor. The&lt;br&gt; &gt; scanner notes if a domain had rotated certificates \
locally in the&lt;br&gt; &gt; results for each scan.&lt;br&gt;
&gt;&lt;br&gt;
&gt; The HTML scan checks HTML, Javascript, and plugin content for&lt;br&gt;
&gt; modifications. Because of the dynamic nature of most of the web, the&lt;br&gt;
&gt; scanner has a number of mechanisms built in to filter out false&lt;br&gt;
&gt; positives that are used when a change is noticed between Tor and&lt;br&gt;
&gt; Non-Tor.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;As an eventual feature, for the above tests, it probably makes sense&lt;br&gt;
to be able to imitate a few different popular browsers as the scanner&lt;br&gt;
does its checks.  If an adversary can recognize the scanner, it can&lt;br&gt;
MITM everything _but_ the scanner.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;You're \
right.  It would be best to imitate different \
browsers.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I got one thing to add to this.  Simply using \
a "User-Agent:" header isn't good enough.  You will need to look \
at the order in which the headers are sent.  As an example (which may or may not \
be accurate) FF may send "User-Agent:" before a \
"Accept-Encoding:" where IE may do the opposite.  It would be feasible \
for an attacker to analyze the order of the HTTP headers to determine which browser \
is being used, or in this case, that a scanner is being used.&lt;br&gt; \
&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I looked at this some time back and was able to guess, very \
accurately at that, which browser was being used.  Specifically, I was looking \
for FF agents pretending to be a different browser.&lt;/div&gt; &lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Just my \
$0.02...&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;- Kyle&lt;/div&gt;&lt;/div&gt;



</body></email><email><emailId>20090430050222</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@torproject.org</senderEmail><timestampReceived>2009-04-30 05:02:22-0400</timestampReceived><subject>The Git conversion is done.</subject><body>

[Also posted to or-talk.  This will be the next-to-last email for a
 while that I send to both lists.  The last one will be a "How The Tor
 Development Process Works, And How You Can Work With It" thing in a
 week or four.]

Tor is now in Git.  The repository is at
   git://git.freehaven.net/git/tor.git

There is also a historical-interest repository at
   git://git.freehaven.net/git/tor-history.git
It has all the obsolete branches that we would never have put into svn
in the first place if we had been working with a DVCS.

I've revised our internal Git Howto document a bit, with help from
Marcus Griep.  It might be a good starting point if you're new to Git:

   http://git.torproject.org/checkout/githax/master/doc/Howto.txt

Happy hacking,
-- 
Nick
</body></email><email><emailId>20090410235433</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-04-10 23:54:33-0400</timestampReceived><subject>Re: [or-cvs] r19162: {projects} start making a 2009 todo list out</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Roger,

your performance metrics TODOs raise a couple of questions. Maybe you
can help resolve some of them?

&gt;   - 1.2, new circuit window sizes
&gt;     - Conclude whether the transition period will hurt as much as it
&gt;       seems like it will.
&gt;     * Pick a lower number, and switch to it.
&gt; Metrics: gather queue sizes from relays so we have a better sense of
&gt; what's actually going on.

Can you tell more details? Are there queues for circuits (1000 cells
max) and for streams (500 cells max)? Is relay.c a good place to start
looking for that code? Are we interested in average numbers of cells by
streams, by circuits, by both, or only in the sum of all cells waiting?
Should we write the number of cells waiting in those queues to disk
every 1 or 10 seconds and use those data for evaluation?

&gt;   - 2.5, Default exit policies
&gt;     * Change Vidalia's default exit policy to not click "other protocols".
&gt;     D let exit relays specify some destination networks/ports that get
&gt;       rate limited further.
&gt; Metrics: At what fraction of exit relays allowing a given port out
&gt; do connections to that port start to suffer? That is, if even 5%
&gt; of the relays (by bandwidth) allowing a port to exit are enough for
&gt; most connections to that port to work fine, then we're going to have
&gt; a tough time pushing unwanted traffic off the network just by changing
&gt; some exit policies. (Alas, this question is messy because it pretends
&gt; that the amount of traffic generated for port x is independent of x.
&gt; How to phrase it so it's more useful?)

Okay, I'm not sure if I understand that question. What exactly do you
want to have measured here?

&gt;   - 3.6, incentives to relay
&gt;     - Sort out how to do circuit priority in practice. I think the only
&gt;       answer here is to make different TLS connections for different
&gt;       priorities. (Otherwise other people can free-ride on your
&gt;       high-priority conns.)
&gt; Metrics: what period of time should the gold star status last? That is,
&gt; What period of time, taken as a rolling snapshot of which relays are
&gt; present in the network, guarantees a sufficiently large anonymity set
&gt; for high-priority relays?

This goes in the direction of the churn measurements for my thesis. But
I'm unsure what exactly the question is. You want to know how many of
the relays at time X are still running at time Y? Or, maybe only a
subset of relays (which criteria)?

&gt;   - 4.2, getting better bandwidth estimates
&gt; Metrics: how accurate are the ten-second-bandwidth-burst advertised
&gt; numbers anyway, in terms of guessing capacity? Steven says we're at 50%
&gt; load, but is that just because our advertised bandwidth is a function
&gt; of our recent load?

How would accuracy be measured? How do I learn how much 100% of the
capacity of a relay are?

&gt;     - What is "true" capacity anyway?
&gt; Metrics: What other algorithms can we use to produce a more accurate
&gt; advertised bandwidth?

Is this a question that can be answered by metrics? Can you give more hints?

&gt;   - 4.5, Older entry guards are overloaded
&gt; Metrics: compare "how fast each relay should be based on its advertised
&gt; capacity" with "how long the relay has had the guard flag", to see how
&gt; big an issue this is really.

Okay, that means finding a possible correlation between advertised
capacity and time since getting the Guard flag for the first time.
Should be possible, but I need to think harder about doing this
efficiently with the current database.

&gt; Metrics: How many relays does a client touch over time x, given that they
&gt; drop old guards y seconds after choosing them? Even if y is infinite,
&gt; we have some number based on guards going away. How does x grow as we
&gt; reduce y?

Hey, x has two meanings here. ;) The question should be "How many relays
z does a client touch over time x, given that they drop old guards y
seconds after choosing them?" Maybe we want to fix the time x to, say, 1
month?

&gt;     * Pick a conservative y like six months, and implement.
&gt;     D Reduce y based on the results of the metrics. (don't partition
&gt;       clients too far by tor version though.)
&gt; Metrics: if we were more flexible in our Guard stability criteria, how
&gt; many more relays would get the Guard flag? How would that influence the
&gt; above numbers? I'd like to become very flexible so more than half of
&gt; the relays get to be guards. Are there cutoffs that are reasonable and
&gt; fit naturally into the data from the past few years?

I have started playing with the selection criteria to see how many
Fast/Stable/Guard nodes we'd have ended up with in the past. If the
stupid database finishes anytime soon, we'll have results tonight or
tomorrow. The question how that would have influenced the above numbers
would be next.

&gt; Metrics: if we're more flexible in our Guard speed criteria, how does
&gt; that impact the speed that clients should expect? Originally we avoided
&gt; 20KB/s relays as guards, because "then clients can't ever get more than
&gt; 20KB/s". But they can't get that now anyway.

What metric would answer this question? The distribution of advertised
bandwidth for different Guard selection criteria?

&gt;   - 5.2, better timeouts for giving up on circuits/streams
&gt;     * clients gather data about circuit timeouts, and then abandon
&gt;       circuits that take more than a std dev above that.
&gt; Metrics: Right now we abandon the circuit after 10 seconds for the first
&gt; try. What are the download stats if we don't abandon it? What "try a
&gt; new one" timeouts will minimize the number of circuits we go through,
&gt; while also minimizing the time-until-user-gets-website?

Hmm. We might completely remove the 10-seconds timeout and see how long
it takes until the stream is attached (or if it fails). From these data
we could derive a better timeout. Is that what you have conceived?

Thanks!
- --Karsten
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFJ39w50M+WPffBEmURAsuIAJ9sYzNlh/l9vFmwsWQUcTGhkS2P6gCggoQg
zFpC5BQe1ObQnK9QqiUFOWE=
=hb7K
-----END PGP SIGNATURE-----
</body></email><email><emailId>20090308054443</emailId><senderName>Michael Gold</senderName><senderEmail>torlists@rilmarder.org</senderEmail><timestampReceived>2009-03-08 05:44:43-0400</timestampReceived><subject>[PATCH] Fix VPATH builds</subject><body>

[Attachment #2 (multipart/mixed)]


While writing my previous patch I fixed a bug that was causing VPATH
builds to fail.  As Nick suggested, I've separated the fix into it's own
patch, which is attached.  It's against 0.2.0.34 but also applies to
0.2.1.12-alpha (I haven't tested it on that version, but I don't see
anything that would cause problems).  I suggest applying it to both
versions.

-- Michael

["tor-fix-vpath-builds.diff" (text/x-diff)]

diff --git a/configure.in b/configure.in
index e733ad9..d7c0a25 100644
--- a/configure.in
+++ b/configure.in
@@ -18,7 +18,7 @@ fi
 
 # Not a no-op; we want to make sure that CPPFLAGS is set before we use
 # the += operator on it in src/or/Makefile.am
-CPPFLAGS="$CPPFLAGS -I../common"
+CPPFLAGS="$CPPFLAGS -I\${top_srcdir}/src/common"
 
 AC_ARG_ENABLE(debug,
  AS_HELP_STRING(--enable-debug, compile with debugging info),

["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090217235325</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-02-17 23:53:25-0400</timestampReceived><subject>Moving from test win32 MSI packages to production ready</subject><body>

Moving from test win32 MSI packages to production ready

This is important for updater assisted bundle and network
installer packages. [0]

The new MSI packages in testing need a few changes before
any public distribution of them is reasonable. The other
changes mentioned below can wait until after an initial
MSI based bundle is announced and distributed.

There are also some significant differences between these
packages and the existing NSIS based installers:
a) Windows 2K SP2 is the minimum supported OS version due to
   the Microsoft Installer switch.
b) Only local per user installs are currently supported. [1]

Work in progress in progress for minimal first distribution:
 [code drop ETA end-of-week. public www pkgs next month?]
1) Add all of the various LICENSE files and disclaimers into
   each package, every time, for all necessary languages
   OR
   Include new license file package so that we don't need to
   track and maintain redundant license data in the packages
   or bundles individually. [2]
2) Add edmanm's Vidalia bundle NSI installer logic for Tor
   button installation into the bundle installer exe.
3) Provide the quick and thorough uninstall utility with
   bundled packages. [3]

Near term changes of high priority likely to prevent some
users from installing or being able to use the new packages:
0) At some point the keys used for the Thandy repo and sent
   with the client exe need to be updated. That point may or
   may not be before the first release, but probably should?
1) Finish support for native mingw32 python to eliminate
   dependency on Microsoft Visual C++ Runtime in Thandy and
   other apps. [4]
2) Implement changes to bundle package WiX specs for feature
   selection configuration via command line and registry.
3) Integrate localization support into WiX specs if needed
   for that feature and integrate multiple localization
   bundling into the installers. [5]
4) Support install as service and for-all-users based
   deployments of the MSI packages and bundles. [6]
5) Add optional support for Marble Vidalia widget; bonus
   points if it can detect 3D render frame rate and adjust
   on the fly.

Additional features that may or may not be needed:
a) Implement Thandy updater support for service installs
   and all bundle component packages.
b) Include Tor with the network installer for initial
   downloads routed through Tor instead of direct only.
c) Support for native 64bit applications and packages.
d) Support for SteadyState deployments. [7]
e) Including current cached directory consensus info and
   descriptors with frequently updated bundle installers
f) Provide hooks for users to use bridge descriptors and
   stay within strict firewall constraints for both the
   network based installation and the first time bundle
   installation.

[ref]:

0. Alpha packages with untrustworthy Thandy signatures:
https://data.peertech.org/files/demo/updater/index.html
Feedback welcomed!

1. Practical impacts of new Microsoft Installer packages:
the primary concern aside from higher minimal supported
operating system version is the path under which Tor
and bundle components reside. For the assisted updater
to be able to run from Vidalia and with least privileges
the program files as well as application data must all
reside under CSIDL_LOCAL_APPDATA, aka:
%USERPROFILE%\Local Settings\Application Data\, aka:
C:\Documents and Settings\&lt;user&gt;\Local Settings\Application Data\

2. License package or just hack existing .wxs files for each?
There are two reasons I am leaning toward a license
package. An infrequently updated license package makes
the bandwidth savings for Thandy updates even more useful
given the large amount of license data in a single kernel
image associated with all of the packages used in the Tor
VM file system image. This would also prevent needless
duplication of license data in the bundle and network
installers.

3. The problem with un-installing or repairing a bundle:
Since we're now shipping the guts of Tor and all its
bundle related dependencies in MSI packages we need
something more than the default MSI package remove via
control panel option for the bundle and network installer.
The MSI package utility also requires that .msi packages be
available on the file system for repair.
The MSI package utility also requires that package removal
without a local copy of the .msi package use the Product ID
instead of .msi package file.
The work-in-progress bundle package utility is a small
stand-alone native exe that interacts with msiexec, the
registry, and can assist with securely updating and
repairing all of the MSI packages distributed.

4. What is the "Microsoft Revenue Generation Feature/Tax":
It would be ideal if anyone that wanted to build an entire
set of bundle packages and installers from source and
redistribute everything they need without anything more
onerous than "open source" [see 2] derivative work
constraints and require no licensed software to build it.
Microsoft conspires to guarantee that you'll be using a
licensed copy of at least the most recent Visual Studio C++
for building your distributable executables. Note that any
package that ships with the Visual C++ runtime libraries as
a side by side assembly built with licensed VC++ cannot be
built by anyone without their own licensed copy of VC++.

5. Localized MSI packages with WiX:
This boils to mapping as much as we can in terms of text
presented to the user from the default WixLocalization
element specification. Whatever can not be deferred to by
default in the standard WiX UI would then need to be added
from sources when building the packages.

6. Installation and upgrades for all-user or service setup:
The default local install per user mode of deployment is
preferred because it does not require administrator rights
nor will multiple copies of the same product series on the
same host conflict with each other. The ability to install
as a service that launches at boot and/or make parts of the
packages available to all users requires at least:
  a) Installing into a local, persistent location and not
     under any User owned Application Data folders.
  b) Prompting for escalation during initial bundle install
     and indicating admin requirements in MSI package.
  c) Moving the Tor update process out of Vidalia and doing
     it from service or manually after user notification.

7. Microsoft Windows SteadyState (part of Shared Access
   Computing)
  http://www.microsoft.com/windows/products/winfamily/sharedaccess/whatis/default.mspx
</body></email><email><emailId>20090228200253</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2009-02-28 20:02:53-0400</timestampReceived><subject>GetTor locale parsing</subject><body>

Hi,

I'm working on a spec (currently a really rough draft) of how GetTor
will handle locale selection for end users.

If anyone has any interest in the subject, here's the draft:
https://tor-svn.freehaven.net/svn/projects/gettor/README.locale-spec-draft

Best,
Jacob

</body></email><email><emailId>20090106061314</emailId><senderName>Boris Gimelbrand</senderName><senderEmail>borisg@yoggie.com</senderEmail><timestampReceived>2009-01-06 06:13:14-0400</timestampReceived><subject>Re: Country patch for Tor</subject><body>

No, I haven't. I saw that it's still on the "to do" list, and it didn't cross my mind to check 
the development version.

----- Original Message -----
From: "Nick Mathewson" &lt;nickm@freehaven.net&gt;
To: or-dev@freehaven.net
Sent: Monday, January 5, 2009 9:32:09 PM (GMT+0200) Auto-Detected
Subject: Re: Country patch for Tor

On Mon, Jan 05, 2009 at 02:30:04PM +0200, Boris Gimelbrand wrote:
&gt; Hi,
&gt; 
&gt; I added a patch that enables choosing exit node country from configuration file.
&gt; It uses already existing functions that access GeoIP database.
&gt; I also added an option to load one country only from the GeoIP database,
&gt; for limited resources systems.

Have you seen the new node list syntax in the development series, in
0.2.1.6-alpha and later?  Now you can do similar things with:
    
    # Use exit nodes in GB.
    ExitNodes {gb}

    # Use exit nodes in countries that have won the World Cup
    # recently. Also use any exit node at MIT.
    ExitNodes {it}, {br}, {fr}, 18.0.0.0/8

    # Don't use an exit node in any country that is sinking under
    # water.
    ExcludeExitNodes {mv}

{This is one of the reasons it's usually better to write feature
patches against the development series (where we add features) than
against stable versions.}
 
yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20090106181555</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2009-01-06 18:15:55-0400</timestampReceived><subject>Re: [or-cvs] r17930: {projects} Fix German translation.</subject><body>

On 06.01. 18:31, Fabian Keil wrote:

&gt; &gt; +msgstr "\n"
&gt; &gt;  "Hier ist die von Ihnen angeforderte Software als Zip-datei. Bitte\n"
&gt; 
&gt; The correct capitalisation is "Zip-Datei".

Thank you. Fixed as of revision 17967.

Best,
    Christian
</body></email><email><emailId>20090115230753</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-01-15 23:07:53-0400</timestampReceived><subject>Re: PATCH: support local application data paths by default via configure option --enable-local-appda</subject><body>

On Thu, Jan 15, 2009 at 02:56:35PM -0800, coderman wrote:
&gt; This patch changes the default location where config and data files
&gt; are stored when the --enable-local-appdata option is configured.  This
&gt; changes the Windows path from %APPDATA% to a host local
&gt; %USERPROFILE%\Local Settings\Application Data\ path (aka,
&gt; LOCAL_APPDATA).

Applied in spite of feature freeze, since Thandy apparently needs it.
</body></email><email><emailId>20090117234825</emailId><senderName>Sambuddho Chakravarty</senderName><senderEmail>sc2516@columbia.edu</senderEmail><timestampReceived>2009-01-17 23:48:25-0400</timestampReceived><subject>Problem running tor-0.2.0.32 on Ubuntu 8.04</subject><body>

Hello All
 I tried compiling tor-0.2.0.32 on Ubuntu 8.04 (off the shelf version - 
running kernel 2.6.24-23-generic , glibc - 2.7 , gcc 4.2.4) . 
Compilation went fine but when trying to run , I get the following error

*** glibc detected *** /bin/tor: malloc(): memory corruption: 0x08101de8 ***
======= Backtrace: =========
/lib/tls/i686/cmov/libc.so.6[0xb7ceb356]
/lib/tls/i686/cmov/libc.so.6(__libc_malloc+0x8d)[0xb7ceccad]
/bin/tor[0x80b9961]
/bin/tor[0x80be13f]
/bin/tor[0x806c463]
/bin/tor[0x806cc22]
/bin/tor[0x8064194]
/bin/tor[0x80650df]
/bin/tor[0x8092957]
/bin/tor[0x80b6ac2]
/lib/tls/i686/cmov/libc.so.6(__libc_start_main+0xe0)[0xb7c95450]
/bin/tor[0x804ce31]
======= Memory map: ========
08048000-080ee000 r-xp 00000000 08:06 971319     /bin/tor
080ee000-080f1000 rw-p 000a5000 08:06 971319     /bin/tor
080f1000-08121000 rw-p 080f1000 00:00 0          [heap]
b7b00000-b7b21000 rw-p b7b00000 00:00 0
b7b21000-b7c00000 ---p b7b21000 00:00 0
b7c31000-b7c3b000 r-xp 00000000 08:06 897621     /lib/libgcc_s.so.1
b7c3b000-b7c3c000 rw-p 0000a000 08:06 897621     /lib/libgcc_s.so.1
b7c48000-b7c4a000 rw-p b7c48000 00:00 0
b7c4a000-b7c59000 r-xp 00000000 08:06 914930     
/lib/tls/i686/cmov/libresolv-2.7.so
b7c59000-b7c5b000 rw-p 0000f000 08:06 914930     
/lib/tls/i686/cmov/libresolv-2.7.so
b7c5b000-b7c5d000 rw-p b7c5b000 00:00 0
b7c5d000-b7c64000 r-xp 00000000 08:06 914931     
/lib/tls/i686/cmov/librt-2.7.so
b7c64000-b7c66000 rw-p 00006000 08:06 914931     
/lib/tls/i686/cmov/librt-2.7.so
b7c66000-b7c7a000 r-xp 00000000 08:06 914921     
/lib/tls/i686/cmov/libnsl-2.7.so
b7c7a000-b7c7c000 rw-p 00013000 08:06 914921     
/lib/tls/i686/cmov/libnsl-2.7.so
b7c7c000-b7c7f000 rw-p b7c7c000 00:00 0
b7c7f000-b7dc8000 r-xp 00000000 08:06 914915     
/lib/tls/i686/cmov/libc-2.7.so
b7dc8000-b7dc9000 r--p 00149000 08:06 914915     
/lib/tls/i686/cmov/libc-2.7.so
b7dc9000-b7dcb000 rw-p 0014a000 08:06 914915     
/lib/tls/i686/cmov/libc-2.7.so
b7dcb000-b7dce000 rw-p b7dcb000 00:00 0
b7dce000-b7de1000 r-xp 00000000 08:06 1158756    
/usr/lib/libevent-1.3e.so.1.0.3
b7de1000-b7de2000 rw-p 00013000 08:06 1158756    
/usr/lib/libevent-1.3e.so.1.0.3
b7de2000-b7de3000 rw-p b7de2000 00:00 0
b7de3000-b7de5000 r-xp 00000000 08:06 914918     
/lib/tls/i686/cmov/libdl-2.7.so
b7de5000-b7de7000 rw-p 00001000 08:06 914918     
/lib/tls/i686/cmov/libdl-2.7.so
b7de7000-b7dfb000 r-xp 00000000 08:06 914929     
/lib/tls/i686/cmov/libpthread-2.7.so
b7dfb000-b7dfd000 rw-p 00013000 08:06 914929     
/lib/tls/i686/cmov/libpthread-2.7.so
b7dfd000-b7dff000 rw-p b7dfd000 00:00 0
b7dff000-b7f29000 r-xp 00000000 08:06 1436739    
/usr/lib/i686/cmov/libcrypto.so.0.9.8
b7f29000-b7f3e000 rw-p 00129000 08:06 1436739    
/usr/lib/i686/cmov/libcrypto.so.0.9.8
b7f3e000-b7f42000 rw-p b7f3e000 00:00 0
b7f42000-b7f80000 r-xp 00000000 08:06 1436741    
/usr/lib/i686/cmov/libssl.so.0.9.8
b7f80000-b7f84000 rw-p 0003d000 08:06 1436741    
/usr/lib/i686/cmov/libssl.so.0.9.8
b7f84000-b7f98000 r-xp 00000000 08:06 1413862    /usr/lib/libz.so.1.2.3.3
b7f98000-b7f99000 rw-p 00013000 08:06 1413862    /usr/lib/libz.so.1.2.3.3
b7fa4000-b7fa7000 rw-p b7fa4000 00:00 0
b7fa7000-b7fa8000 r-xp b7fa7000 00:00 0          [vdso]
b7fa8000-b7fc2000 r-xp 00000000 08:06 897612     /lib/ld-2.7.so
b7fc2000-b7fc4000 rw-p 00019000 08:06 897612     /lib/ld-2.7.so
bfeea000-bfeff000 rw-p bffeb000 00:00 0          [stack]


Any reason why I am getting this ? How can this be fixed ?

Thanks
Sambuddho
</body></email><email><emailId>20090121072544</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-01-21 07:25:44-0400</timestampReceived><subject>Re: Ipv6</subject><body>

On Wed, Jan 21, 2009 at 07:56:05AM +0100, Marcus Wolschon wrote:
&gt; On Wed, 21 Jan 2009 01:14:08 -0500, Nick Mathewson &lt;nickm@freehaven.net&gt;
&gt; wrote:
&gt; &gt; Right now, though, the Tor development branch is in feature-freeze to
&gt; &gt; get ready for a stable 0.2.1.x release.  Could I ask you to remind me
&gt; &gt; to look at this patch again once 0.2.1.x is on a stable branch and
&gt; &gt; 0.2.2.x development is underway?
&gt; 
&gt; Hello everyone.
&gt; 
&gt; I had submitted a patch to allow hidden services to reside on
&gt; IPv6-addresses in the last feature-freeze and was told that
&gt; it would be shelved for 0.2.1.
&gt; I have not heard anything about it since. Is it included
&gt; in 0.2.1 and if not, what open issues exist with it?

Thanks for reminding me!  I just tried the functionality, and found a
bug in the code.  It should be fixed in svn trunk now.

Full IPv6 exit support isn't there yet, of course, but hidden services
on IPv6 addresses should work.  With trunk (or 0.2.1.12 or later),
you'd use a syntax like
   HiddenServicePort 80 [::1]:8080
to have a hidden service at ::1.

BTW, looking at the archives, I see that I told you that I would "be
sure to merge this patch once 0.2.1.x is branched".  I think I have
learned that I am forgetful, and so from now on, I should not say
"This patch will be merged later".  Instead, I should say "Please
remind me later if this patch has not been merged."  This way, there
will be two people trying to remember everything instead of just one.

yrs,
-- 
Nick Mathewson

</body></email><email><emailId>20090121185211</emailId><senderName>Christopher Davis</senderName><senderEmail>loafier@gmail.com</senderEmail><timestampReceived>2009-01-21 18:52:11-0400</timestampReceived><subject>Re: Patch to enable socks4/5 support for OR connections</subject><body>

On Wed, Jan 21, 2009 at 01:14:08AM -0500, Nick Mathewson wrote:
&gt; On Fri, Jan 16, 2009 at 01:10:27PM -0800, Christopher Davis wrote:
&gt; &gt; Hello,
&gt; &gt; 
&gt; &gt; I mentioned this work breifly in a post to or-talk just recently.
&gt; &gt; Hopefully, this can be useful to others.
&gt; &gt; 
&gt; &gt; Directory connections could be made to use SOCKS proxies, as well,
&gt; &gt; using the same framework. Although, as Roger explained in his reply 
&gt; &gt; to my post to or-talk, supporting OR connections seems to be enough
&gt; &gt; to get things working.
&gt; &gt; 
&gt; &gt; The SOCKS 5 client supports rfc 1929 user/pass auth if the 
&gt; &gt; configuration directives are set. The SOCKS 4 user id is always 
&gt; &gt; left empty.
&gt; &gt; 
&gt; &gt; Functions to connect through the proxy server are in connection.c.
&gt; &gt; I moved in the functions for HTTP CONNECT proxy support from
&gt; &gt; connection_or.c, so that there is a consistent framework. Hopefully
&gt; &gt; the comments are enough to explain how it works, but if not, I 
&gt; &gt; can expand them a bit. 
&gt; 
&gt; Hi, Christopher!  This looks like good code to me; it is one of the
&gt; best-written feature patches I've seen in a long time.
&gt; 
&gt; Right now, though, the Tor development branch is in feature-freeze to
&gt; get ready for a stable 0.2.1.x release.  Could I ask you to remind me
&gt; to look at this patch again once 0.2.1.x is on a stable branch and
&gt; 0.2.2.x development is underway?
&gt; 

Sure, no problem.

&gt; (If people who want to use Tor from behind their SOCKS proxies would
&gt; try this patch out and let me know whether it works for them too, that
&gt; would be great.)
&gt; 

One way to test this quickly is to use ssh dynamic port forwarding,
eg: ssh -D 1080 localhost. This works for socks4 and 5, although
user/pass auth requires a more complete socks server.

&gt; thanks again,
&gt; -- 
&gt; Nick


-- 
Christopher Davis
</body></email><email><emailId>20090130050508</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-01-30 05:05:08-0400</timestampReceived><subject>Re: Proposal 158: Clients download consensus + microdescriptors</subject><body>

On Thu, Jan 29, 2009 at 11:39:56PM -0500, Roger Dingledine wrote:
&gt; &gt; Does this mean that the ports should (assuming it's possible) get
&gt; &gt; moved into the microdescriptor?  I think exit policies are relatively
&gt; &gt; stable.
&gt; 
&gt; Yes, we could move ports, exit policies, and the version line into the
&gt; microdescriptor.
&gt; 
&gt; We could also dump the descriptor digest and timestamp-of-descriptor
&gt; as well.
&gt; 
&gt; Both of these steps involve breaking the consensus for current clients,
&gt; though (you can't do them until all clients are using microdescriptors),

Nick pointed out that the "p" lines (exit policies) are not yet used. We
could move them now, and take them out of the main consensus. We should
do that.

I am also wrong above that we could move the 'version' line. Even though
it is probably mostly static, clients need it to make decisions about
which mirrors they're allowed to ask for microdescriptors. So that means
I left out a constraint in my original heuristics for which elements go
where: if clients need it in order to properly fetch microdescriptors,
it must go in the consensus proper.

--Roger

</body></email><email><emailId>20090217102349</emailId><senderName>Mike Perry</senderName><senderEmail>mikeperry@fscked.org</senderEmail><timestampReceived>2009-02-17 10:23:49-0400</timestampReceived><subject>Proposal: Exit Scanning</subject><body>


Title: Exit Scanning
Version: $Revision$
Last-Modified: $Date$
Author: Mike Perry
Created: 13-Feb-2009

Overview:

This proposal describes the implementation and integration of an
automated exit node scanner for scanning the Tor network for malicious,
misconfigured, firewalled or filtered nodes.

Motivation:

Tor exit nodes can be run by anyone with an Internet connection. Often,
these users aren't fully aware of limitations of their networking
setup.  Content filters, antivirus software, advertisements injected by
their service providers, malicious upstream providers, and the resource
limitations of their computer or networking equipment have all been
observed on the current Tor network.

It is also possible that some nodes exist purely for malicious
purposes.  In the past, there have been intermittent instances of
nodes spoofing SSH keys, as well as nodes being used for purposes of
plaintext surveillance. 

While it is not realistic to expect to catch extremely targeted or
completely passive malicious adversaries, the goal is to prevent
malicious adversaries from deploying dragnet attacks against large
segments of the Tor userbase.


Scanning methodology:

The first scans to be implemented are HTTP, HTML, Javascript, and
SSL scans.

The HTTP scan scrapes Google for common filetype urls such as exe, msi,
doc, dmg, etc. It then fetches these urls through Non-Tor and Tor, and
compares the SHA1 hases of the resulting content. 

The SSL scan downloads certificates for all IPs a domain will locally
resolve to and compares these certificates to those seen over Tor. The
scanner notes if a domain had rotated certificates locally in the
results for each scan.

The HTML scan checks HTML, Javascript, and plugin content for
modifications. Because of the dynamic nature of most of the web, the
scanner has a number of mechanisms built in to filter out false
positives that are used when a change is noticed between Tor and
Non-Tor. 

All tests also share a URL-based false positive filter that
automatically removes results retroactively if the number of failures
exceeds a certain percentage of nodes tested with the URL.


Deployment Stages:

To avoid instances where bugs cause us to mark exit nodes as BadExit
improperly, it is proposed that we begin use of the scanner in stages.

1. Manual Review:

  In the first stage, basic scans will be run by a small number of
  people while we stabilize the scanner. The scanner has the ability
  to resume crashed scans, and to rescan nodes that fail various
  tests.

2. Human Review:

  In the second stage, results will be automatically mailed to 
  an email list of interested parties for review. We will also begin 
  classifying failure types into three to four different severity 
  levels, based on both the reliability of the test and the nature of 
  the failure.

3. Automatic BadExit Marking:

  In the final stage, the scanner will begin marking exits depending
  on the failure severity level in one of three different ways: by
  node idhex, by node IP, or by node IP mask. A potential fourth, less
  severe category of results may still be delivered via email only for
  review.
 
  BadExit markings will be delivered in batches upon completion
  of whole-network scans, so that the final false positive
  filter has an opportunity to filter out URLs that exhibit
  dynamic content beyond what we can filter.


Specification of Exit Marking:

Technically, BadExit could be marked via SETCONF AuthDirBadExit over
the control port, but this would allow full access to the directory
authority configuration and operation.

The approved-routers file could also be used, but currently it only
supports fingerprints, and it also contains other data unrelated to
exit scanning that would be difficult to coordinate.

Instead, we propose that a new badexit-routers file that has three
keywords:

  BadExitNet 1*[exitpattern from 2.3 in dir-spec.txt]
  BadExitFP 1*[hexdigest from 2.3 in dir-spec.txt]

BadExitNet lines would follow the codepaths used by AuthDirBadExit to
set authdir_badexit_policy, and BadExitFP would follow the codepaths
from approved-router's !badexit lines.

The scanner would have exclusive ability to write, append, rewrite,
and modify this file. Prior to building a new consensus vote, a
participating Tor authority would read in a fresh copy.
 

Security Implications:

Aside from evading the scanner's detection, there are two additional
high-level security considerations:

1. Ensure nodes cannot be marked BadExit by an adversary at will

It is possible individual website owners will be able to target certain
Tor nodes, but once they begin to attempt to fail more than the URL
filter percentage of the exits, their sites will be automatically
discarded. 

Failing specific nodes is possible, but scanned results are fully
reproducible, and BadExits should be rare enough that humans are never
fully removed from the loop.

State (cookies, cache, etc) does not otherwise persist in the scanner
between exit nodes to enable one exit node to bias the results of a
later one.

2. Ensure that scanner compromise does not yield authority compromise

Having a separate file that is under the exclusive control of the
scanner allows us to heavily isolate the scanner from the Tor
authority, potentially even running them on separate machines.




-- 
Mike Perry
Mad Computer Scientist
fscked.org evil labs

[Attachment #3 (application/pgp-signature)]

</body></email><email><emailId>20090217223113</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-02-17 22:31:13-0400</timestampReceived><subject>Re: Proposal: Exit Scanning</subject><body>

On Tue, Feb 17, 2009 at 02:23:49AM -0800, Mike Perry wrote:

Good proposal.

 [...]
&gt; While it is not realistic to expect to catch extremely targeted or
&gt; completely passive malicious adversaries, the goal is to prevent
&gt; malicious adversaries from deploying dragnet attacks against large
&gt; segments of the Tor userbase.

Another goal is to discourage in would-be attackers the idea that
it's totally safe to 

&gt; Scanning methodology:
&gt; 
&gt; The first scans to be implemented are HTTP, HTML, Javascript, and
&gt; SSL scans.
&gt; 
&gt; The HTTP scan scrapes Google for common filetype urls such as exe, msi,
&gt; doc, dmg, etc. It then fetches these urls through Non-Tor and Tor, and
&gt; compares the SHA1 hases of the resulting content. 
                      ^^hashes
&gt; The SSL scan downloads certificates for all IPs a domain will locally
&gt; resolve to and compares these certificates to those seen over Tor. The
&gt; scanner notes if a domain had rotated certificates locally in the
&gt; results for each scan.
&gt; 
&gt; The HTML scan checks HTML, Javascript, and plugin content for
&gt; modifications. Because of the dynamic nature of most of the web, the
&gt; scanner has a number of mechanisms built in to filter out false
&gt; positives that are used when a change is noticed between Tor and
&gt; Non-Tor. 

As an eventual feature, for the above tests, it probably makes sense
to be able to imitate a few different popular browsers as the scanner
does its checks.  If an adversary can recognize the scanner, it can
MITM everything _but_ the scanner.

 [...] 
&gt; 3. Automatic BadExit Marking:
&gt; 
&gt;   In the final stage, the scanner will begin marking exits depending
&gt;   on the failure severity level in one of three different ways: by
&gt;   node idhex, by node IP, or by node IP mask. A potential fourth, less
&gt;   severe category of results may still be delivered via email only for
&gt;   review.
&gt;  
&gt;   BadExit markings will be delivered in batches upon completion
&gt;   of whole-network scans, so that the final false positive
&gt;   filter has an opportunity to filter out URLs that exhibit
&gt;   dynamic content beyond what we can filter.

These batches should include descriptions of what the node seems to
have done and when.

&gt; Specification of Exit Marking:
&gt; 
&gt; Technically, BadExit could be marked via SETCONF AuthDirBadExit over
&gt; the control port, but this would allow full access to the directory
&gt; authority configuration and operation.

Agreed.

&gt; The approved-routers file could also be used, but currently it only
&gt; supports fingerprints, and it also contains other data unrelated to
&gt; exit scanning that would be difficult to coordinate.
&gt; 
&gt; Instead, we propose that a new badexit-routers file that has three
&gt; keywords:
&gt; 
&gt;   BadExitNet 1*[exitpattern from 2.3 in dir-spec.txt]
&gt;   BadExitFP 1*[hexdigest from 2.3 in dir-spec.txt]
&gt; 
&gt; BadExitNet lines would follow the codepaths used by AuthDirBadExit to
&gt; set authdir_badexit_policy, and BadExitFP would follow the codepaths
&gt; from approved-router's !badexit lines.

(What's the third keyword?)

If possible, I'd like the approved-routers format to expand to also
include IPs, networks, and fingerprints.  Then I'd like a config
option to allow an authority to have more than one
approved-routers-ish file.  This way, we wouldn't need to add new
special handling for every flag we decide to set automatically via an
external tool.

Also, it would be neat to migrate the syntax something that doesn't
!have !so !many !bangs.  Maybe we should just deprecate the
approved-routers syntax, and have the syntax for the new files be
sane.

Everything in the last two paragraphs should be dead easy to hack in
during the 0.2.2.x series.

-- 
Nick





</body></email><email><emailId>20090217225325</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-02-17 22:53:25-0400</timestampReceived><subject>Re: Proposal: Exit Scanning</subject><body>

On Tue, Feb 17, 2009 at 02:23:49AM -0800, Mike Perry wrote:
&gt; Title: Exit Scanning
&gt; Version: $Revision$
&gt; Last-Modified: $Date$
&gt; Author: Mike Perry
&gt; Created: 13-Feb-2009

I have just added this to the proposal directory as 'proposal 159'.

&gt; Specification of Exit Marking:
&gt; 
&gt; Technically, BadExit could be marked via SETCONF AuthDirBadExit over
&gt; the control port, but this would allow full access to the directory
&gt; authority configuration and operation.

Right. That seems like a very bad move.

&gt; The approved-routers file could also be used, but currently it only
&gt; supports fingerprints, and it also contains other data unrelated to
&gt; exit scanning that would be difficult to coordinate.
&gt; 
&gt; Instead, we propose that a new badexit-routers file that has three
&gt; keywords:
&gt; 
&gt;   BadExitNet 1*[exitpattern from 2.3 in dir-spec.txt]
&gt;   BadExitFP 1*[hexdigest from 2.3 in dir-spec.txt]
&gt; 
&gt; BadExitNet lines would follow the codepaths used by AuthDirBadExit to
&gt; set authdir_badexit_policy, and BadExitFP would follow the codepaths
&gt; from approved-router's !badexit lines.
&gt; 
&gt; The scanner would have exclusive ability to write, append, rewrite,
&gt; and modify this file. Prior to building a new consensus vote, a
&gt; participating Tor authority would read in a fresh copy.

This would involve quite a bit of new code -- reading, parsing, checking,
etc. I suggest we use the approved-routers file, with !badexit that's
already supported and teach it how to handle a new !badexitnet line.

It shouldn't be any more hassle on the SoaT side. For the two
Naming authorities (moria1 and tor26), we already manage multiple
approved-routers files, which are combined automatically.
https://svn.torproject.org/svn/tor/trunk/contrib/auto-naming/

The rule in my Makefile is:

approved-routers: approved-routers-auto approved-routers-manual tor-bad-fingerpr
ints/bad-routers
        cat $^ &gt; "$@"

This 'approved-routers-auto' file is created by
https://svn.torproject.org/svn/tor/trunk/contrib/auto-naming/build-approved-routers

So SoaT could just generate and maintain an 'approved-routers-badexit'
file and we could add it to the Makefile line.

(One last note would be that we should run the file through another tiny
script to strip lines that don't start with !badexit or !badexitnet,
so we don't have to worry about somebody breaking into the soat and
generating !reject lines or Naming lines.)

--Roger

</body></email><email><emailId>20091021012808</emailId><senderName>Shane Pope</senderName><senderEmail>shane.m.pope@gmail.com</senderEmail><timestampReceived>2009-10-21 01:28:08-0400</timestampReceived><subject>Re: Tor Port-Scanning Resistance Specification</subject><body>

For archival sake, here's the spec in textual format. -Shane

Tor Port-Scanning Resistance

Shane Pope

0. Preliminaries

0.1 Definitions, Notation and encoding

    OR Port -- The port running the OR protocol on the server.

    Tor bridge -- A relay running Tor
    Bug-compatible -- Any inputs into an altered system will respond with the
      exact same response the unaltered system would respond with.
    Bridge-specific password -- A password set by the bridge operator. This

      password will be sent as a query string from a Tor client to the
webserver.
      Example: GET /tor/?passwordGoesHere

1. System Overview

   An adversary who wants to identify a machine running Tor can try
connecting to

   ports on the machine and following Tor protocol. If any of the ports respond
   following Tor protocol, we know they are running Tor. This system
aims to prevent
   port-scanning tools from detecting Tor servers. To do this we attempt to hide

   the server behind an HTTPS webserver(Apache). Another goal is
making the system
   usable enough that it will be easy to widely deploy.


2.  Protocol

    Tor runs on a local port, which cannot be connected to from the
outside. Apache

    runs on the standard https port (and http, as an average webserver would).
    Anyone connecting to the webserver will receive a bug-compatible response,
    typically a 404 or the page at the url passed, unless they know a

    bridge-specific password. If the bridge-specific password is sent, the
    connection begins proxying all data to and from the local Tor server.

2.1 Bridge-Specific Password

    - Stub. Generated?

2.2 Required Changes to Tor Client

    - Client needs a flag when given a bridge to know to treat the
bridge as normal
      or scanning resistant (Easy)
    - Client must use a web browser-identical TLS handshake.

    - After creating the TLS connection the client must send the bridge-specific
      password.
    - Client must then be changed to send all data under this SSL connection
      instead of the normal Tor SSL protocol.

2.3 Required features of the Apache module

    - Authenticate the user if the correct password is sent, otherwise
let Apache
      handle the request. (DONE)
    - Create a socket to local Tor bridge (DONE - Socket per connection)

    - Pass all bits from authenticated client connection to Tor
    - Pass all bits from local Tor back to authenticated client

2.4 Required Changes to Tor Server

    - Add directives to know if the server is a scanning resistant
bridge or not. (Easy)

    - Rewrite connection code to accept unencrypted OR connections (Eek)
    - More?

2.5 Benefits

    - Completely hides initial Tor handshake
    - No window of time to be scanned at all.














3.  Another Protocol (Much easier to implement, not working on due to
problems with it)

    Tor runs it's OR port on a high numbered port. Tor stops accepting
connections.

    Apache accepts a bridge-specific password over https. Apache then sends a
    command to Tor to begin accepting connections for a few minutes or until the
    user has connected. Any user attempting to port scan Tor would
only be able to

    scan between the window that the port accepts connections.

3.1 Required Changes to Tor Client

    - Client needs a flag when given a bridge to know to treat the
bridge as normal
      or scanning resistant (Easy)

    - Client must follow the same TLS protocol that Apache runs, and send the
      bridge-specific password after connecting.

3.2 Required features of the Apache module

    - Authenticate the user if the correct password is sent, otherwise
let Apache

      handle the request. (DONE)
    - Connect to Tor's controller port and sending "open port" command to Tor.

3.3 Required Changes to Tor Server

    - Add directives to know if the server is a scanning resistant
bridge or not.

    - Add code to disable accepting connections on the OR Port unless
some flag is
      true, and time out that flag to false.
    - Add code to turn the flag above to false if the set of users who
      authenticated through the webserver has connected.

    - Set the above flag using the controller port.

3.4 Benefits

    - Possibly easier to port to other webservers.
    - Much easier to implement
    - Small window of time in which Tor can be detected.

3.5 Problems with design

    - Does not hide inital Tor handshake
    - Tor can still be detected, via port scan, in a small timeframe

On Tue, Oct 20, 2009 at 8:11 PM, Shane Pope &lt;Shane.M.Pope@gmail.com&gt; wrote:

&gt; I've written up a specification for the project I'm working on. Any
&gt; feedback would be much appreciated.
&gt;
&gt; http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt
&gt;
&gt; -Shane
&gt;

[Attachment #3 (text/html)]

For archival sake, here's the spec in textual format. -Shane&lt;br&gt;&lt;br&gt;&lt;pre&gt;Tor \
Port-Scanning Resistance&lt;br&gt;&lt;br&gt;Shane Pope&lt;br&gt;&lt;br&gt;0. Preliminaries&lt;br&gt;&lt;br&gt;0.1 \
Definitions, Notation and encoding&lt;br&gt;&lt;br&gt;    OR Port -- The port running the OR \
protocol on the server.&lt;br&gt;

    Tor bridge -- A relay running Tor&lt;br&gt;    Bug-compatible -- Any inputs into an \
altered system will respond with the&lt;br&gt;      exact same response the unaltered \
system would respond with.&lt;br&gt;    Bridge-specific password -- A password set by the \
bridge operator. This&lt;br&gt;

      password will be sent as a query string from a Tor client to the webserver.&lt;br&gt; \
Example: GET /tor/?passwordGoesHere&lt;br&gt;&lt;br&gt;1. System Overview&lt;br&gt;&lt;br&gt;   An adversary \
who wants to identify a machine running Tor can try connecting to&lt;br&gt;

   ports on the machine and following Tor protocol. If any of the ports respond&lt;br&gt;   \
following Tor protocol, we know they are running Tor. This system aims to prevent&lt;br&gt; \
port-scanning tools from detecting Tor servers. To do this we attempt to hide&lt;br&gt;

   the server behind an HTTPS webserver(Apache). Another goal is making the \
system&lt;br&gt;   usable enough that it will be easy to widely deploy.&lt;br&gt;&lt;br&gt;&lt;br&gt;2.  \
Protocol&lt;br&gt;&lt;br&gt;    Tor runs on a local port, which cannot be connected to from the \
outside. Apache&lt;br&gt;

    runs on the standard https port (and http, as an average webserver would).&lt;br&gt;    \
Anyone connecting to the webserver will receive a bug-compatible response,&lt;br&gt;    \
typically a 404 or the page at the url passed, unless they know a &lt;br&gt;

    bridge-specific password. If the bridge-specific password is sent, the&lt;br&gt;    \
connection begins proxying all data to and from the local Tor server.&lt;br&gt;&lt;br&gt;2.1 \
Bridge-Specific Password&lt;br&gt;&lt;br&gt;    - Stub. Generated?&lt;br&gt;

&lt;br&gt;2.2 Required Changes to Tor Client&lt;br&gt;&lt;br&gt;    - Client needs a flag when given a \
bridge to know to treat the bridge as normal&lt;br&gt;      or scanning resistant \
(Easy)&lt;br&gt;    - Client must use a web browser-identical TLS handshake.&lt;br&gt;

    - After creating the TLS connection the client must send the bridge-specific&lt;br&gt;  \
password.&lt;br&gt;    - Client must then be changed to send all data under this SSL \
connection&lt;br&gt;      instead of the normal Tor SSL protocol.&lt;br&gt;

&lt;br&gt;2.3 Required features of the Apache module&lt;br&gt;&lt;br&gt;    - Authenticate the user if \
the correct password is sent, otherwise let Apache&lt;br&gt;      handle the request. \
(DONE)&lt;br&gt;    - Create a socket to local Tor bridge (DONE - Socket per \
connection)&lt;br&gt;

    - Pass all bits from authenticated client connection to Tor&lt;br&gt;    - Pass all \
bits from local Tor back to authenticated client&lt;br&gt;&lt;br&gt;2.4 Required Changes to Tor \
Server&lt;br&gt;&lt;br&gt;    - Add directives to know if the server is a scanning resistant \
bridge or not. (Easy)&lt;br&gt;

    - Rewrite connection code to accept unencrypted OR connections (Eek)&lt;br&gt;    - \
More?&lt;br&gt;&lt;br&gt;2.5 Benefits&lt;br&gt;&lt;br&gt;    - Completely hides initial Tor handshake&lt;br&gt;    \
- No window of time to be scanned at all.&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;br&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;3.  Another Protocol (Much easier to \
implement, not working on due to problems with it)&lt;br&gt;&lt;br&gt;    Tor runs it's OR \
port on a high numbered port. Tor stops accepting connections.&lt;br&gt;

    Apache accepts a bridge-specific password over https. Apache then sends a&lt;br&gt;    \
command to Tor to begin accepting connections for a few minutes or until the&lt;br&gt;    \
user has connected. Any user attempting to port scan Tor would only be able to&lt;br&gt;

    scan between the window that the port accepts connections.&lt;br&gt;&lt;br&gt;3.1 Required \
Changes to Tor Client&lt;br&gt;&lt;br&gt;    - Client needs a flag when given a bridge to know to \
treat the bridge as normal&lt;br&gt;      or scanning resistant (Easy)&lt;br&gt;

    - Client must follow the same TLS protocol that Apache runs, and send the&lt;br&gt;     \
bridge-specific password after connecting.&lt;br&gt;&lt;br&gt;3.2 Required features of the Apache \
module&lt;br&gt;&lt;br&gt;    - Authenticate the user if the correct password is sent, otherwise \
let Apache&lt;br&gt;

      handle the request. (DONE)&lt;br&gt;    - Connect to Tor's controller port and \
sending "open port" command to Tor.&lt;br&gt;&lt;br&gt;3.3 Required Changes to Tor \
Server&lt;br&gt;&lt;br&gt;    - Add directives to know if the server is a scanning resistant \
bridge or not.&lt;br&gt;

    - Add code to disable accepting connections on the OR Port unless some flag \
is&lt;br&gt;      true, and time out that flag to false.&lt;br&gt;    - Add code to turn the flag \
above to false if the set of users who&lt;br&gt;      authenticated through the webserver \
has connected.&lt;br&gt;

    - Set the above flag using the controller port.&lt;br&gt;&lt;br&gt;3.4 Benefits&lt;br&gt;&lt;br&gt;    - \
Possibly easier to port to other webservers.&lt;br&gt;    - Much easier to implement&lt;br&gt;    \
- Small window of time in which Tor can be detected.&lt;br&gt;

&lt;br&gt;3.5 Problems with design&lt;br&gt;&lt;br&gt;    - Does not hide inital Tor handshake&lt;br&gt;    - \
Tor can still be detected, via port scan, in a small timeframe&lt;br&gt;&lt;/pre&gt;&lt;div \
class="gmail_quote"&gt;On Tue, Oct 20, 2009 at 8:11 PM, Shane Pope &lt;span \
dir="ltr"&gt;&lt;&lt;a href="mailto:Shane.M.Pope@gmail.com"&gt;Shane.M.Pope@gmail.com&lt;/a&gt;&gt;&lt;/span&gt; \
wrote:&lt;br&gt;

&lt;blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;"&gt;I've written up a specification \
for the project I'm working on. Any feedback would be much appreciated.&lt;br&gt;

&lt;br clear="all"&gt;&lt;a href="http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt" \
target="_blank"&gt;http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt&lt;/a&gt;&lt;br&gt;&lt;font \
color="#888888"&gt; &lt;br&gt;-Shane&lt;br&gt;
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20091025072248</emailId><senderName>Jacob Appelbaum</senderName><senderEmail>jacob@appelbaum.net</senderEmail><timestampReceived>2009-10-25 07:22:48-0400</timestampReceived><subject>Tor on Android - Progress! (Orbot)</subject><body>


Hello *,

Nathan and I have been working on making a viable, secure and usable
port of Tor to the Android platform. There have been a few attempts at
getting Tor or Tor like software (onion coffee, etc) to run on Android.
The most notable was probably Adam Langley's initial attempts. For quite
sometime, Nathan and I tried a few different approaches. Finally, we
stumbled upon a method for calling arbitrary binaries that are stored as
assets in a package. Nathan wrote a little about this method here:

	http://openideals.com/2009/10/22/orbot-proxy/

We spent most of today working on an Orbot build document:

	https://tor-svn.freehaven.net/svn/projects/android/trunk/Orbot/BUILD

The BUILD document starts a user off without any Android tools on their
system. By the end of the tutorial, you'll have a working, signed Orbot
package. We will endevor to keep this document up to date.

Orbot provides a simple way to run the C reference implementation of
Tor. This means that we can have hidden services and all of the rest of
the Tor client/server/bridge functionality on Android. I expect that
hidden services will become popular if someone ports TorChat to Android.

Tor itself exposes the usual SOCKS proxy and Orbot extends this by also
offering an HTTP proxy. Part of the code that powers the HTTP proxy is a
powered by a fork of jsocks. We've named it asocks (Android SOCKS) and
put it in subversion:

	https://tor-svn.freehaven.net/svn/projects/android/trunk/asocks/

The UI for Orbot really needs a lot of work. It will require a lot of
polish. Currently, it does do very basic controlling of Tor; it's mostly
by brute force and doesn't use anything fancy with the control port.

The next step will be to create a second application that actually uses
Tor. It will likely be a web browser that specifically utilizes Tor for
everything. This will be similar in scope to what Conell did for
TorProxy with his Shadow browser:

	http://www.cl.cam.ac.uk/research/dtg/android/tor/

It is likely that we'll replace TorProxy in the market after we're
pretty sure that we're on the right path.

If you'd like to try a build of Orbot, I've put up an early alpha build:

	http://freehaven.net/~ioerror/Orbot-signed-alpha-24-10-2009.apk

If you have an android phone, you can scan this QR code to download and
install the package:

	http://freehaven.net/~ioerror/orbot.png

This is our first alpha release and we'd love some feedback...

Best,
Jacob


["signature.asc" (application/pgp-signature)]

</body></email><email><emailId>20090901115045</emailId><senderName>Björn_Scheuermann</senderName><senderEmail>scheuermann@cs.uni-duesseldorf.de</senderEmail><timestampReceived>2009-09-01 11:50:45-0400</timestampReceived><subject>Re: Proposal 168: Reduce default circuit window</subject><body>

Hi all,

this sounds like an interesting proposal! However, I'd like to point you to 
some implications and side effects. Over the past months, one of my students 
(Daniel Marks, on CC) has worked on congestion control in Tor. One of his 
results is an implementation of Tor circuits in a network simulation framework 
(ns-2). We use this implementation to simulate Tor networks of different size 
and with different traffic patterns, play with various parameters and measure 
throughput, cell latencies, etc. Currently, our aim is to gain a better 
understanding of congestion effects in Tor and their implications and 
interrelations.

Over the weekend, Daniel has run some simulations with the proposed reduction 
of the window size. They are certainly still a bit preliminary, but 
nevertheless some trends are clear.

&gt; 1. Overview
&gt;
&gt;   We should reduce the starting circuit "package window" from 1000 to
&gt;   101. The lower package window will mean that clients will only be able
&gt;   to receive 101 cells (~50KB) on a circuit before they need to send a
&gt;   'sendme' acknowledgement cell to request 100 more.
&gt;
&gt;   Starting with a lower package window on exit relays should save on
&gt;   buffer sizes (and thus memory requirements for the exit relay), and
&gt;   should save on queue sizes (and thus latency for users).

A central problem currently is the huge queues that build up in the onion 
routers. A reduction of the window size will certainly result in shorter 
queues. Whether these translate into lower latencies depends on the definition 
of "latency", however. If "latency" is the time that a given cell spends 
within the Tor overlay, certainly yes. If "latency", however, is the time that 
it takes to download, e.g., a certain web page, this does not necessarily hold 
true (see below).

&gt;   Lowering the package window will induce an extra round-trip for every
&gt;   additional 50298 bytes of the circuit. This extra step is clearly a
&gt;   slow-down for large streams, but ultimately we hope that a) clients
&gt;   fetching smaller streams will see better response, and b) slowing
&gt;   down the large streams in this way will produce lower e2e latencies,
&gt;   so the round-trips won't be so bad.

As far as we see, the current Tor design largely decouples the queues of 
individual circuits (which is good!). If some given circuit's queue in an 
onion router is short, then cells from this circuit will experience 
low queueing delays, even if the queues of other circuits in the same router 
are long - the round robin scheduler will pick cells from the short queue for 
transmission not long after they arrived. (The outgoing TCP buffer also has a 
certain impact here, but the by far largest fraction of the queueing delay is 
apparently within Tor itself.) This also implies: slowing down the other 
streams does not necessarily and automatically help to achieve shorter 
download times!

&gt; 2. Motivation
&gt;
&gt;   Karsten's torperf graphs show that the median download time for a 50KB
&gt;   file over Tor in mid 2009 is 7.7 seconds, whereas the median download
&gt;   time for 1MB and 5MB are around 50s and 150s respectively. The 7.7
&gt;   second figure is way too high, whereas the 50s and 150s figures are
&gt;   surprisingly low.

Your statement implies that you are looking at something like the 
"transmission latency per KB" (which is, by the way, identical to the inverse 
throughput). This metric can be treacherous. To illustrate my point, imagine a 
(very) long communication link, e.g., going from the earth to the moon 
(ok...). Assume it has enormously large available bandwidth, but also a very 
high link latency (say, 7.7 seconds ;-) ). If you send a file of 50 KB over 
that link, it this will never arrive after less than 7.7 seconds. If you send 
a 5 MB file (without waiting for ACKs), it will likewise arrive after 7.7 
seconds - so you get a much lower "transmission latency per KB of data" (= 
bandwidth!). Artificially limiting the 5 MB transmissions' bandwidth will not 
help the 50 KB transmissions to deliver their data any faster.

This may be a bit (ok, not just a bit) simplistic, but it underlines that 
throughput and latency are not independent and can only to a certain extent be 
optimized individually or traded off against each other. And if there are 
multiple interfering circuits, things become really interesting and often 
behave differently than one would initially expect.

The key question here is what the 7.7 seconds are spent for; they are a 
symptom, not the cause. Our current impression is that the key problem in Tor 
is not as much the maximum window size as the fact that the window is opened 
in huge chunks. This makes the traffic extremely bursty and results in 
unnecessarily long queues. If you just reduce the maximum window size to 101 
but still release 100 cells at once into the overlay, this burstiness will 
remain (or it will become even worse).

&gt;   The median round-trip latency appears to be around 2s, with 25% of
&gt;   the data points taking more than 5s. That's a lot of variance.

That's also what we see in the simulations. However, it appears that the 
variance gets worse if you reduce the window size. The reason is that a "stop-
and-go" traffic pattern emerges: after 101 cells, the source must wait for the 
sendme; during that time, the circuit becomes completely empty. Potentially 
free bandwidth at the routers is not used, while readily prepared cells must 
wait for a long time in the circuit's source. After the sendme arrives, the 
first cells make it through the overlay very quickly. The differences between 
individual cells' latencies are therefore huge.

&gt;   We designed Tor originally with the original goal of maximizing
&gt;   throughput. We figured that would also optimize other network properties
&gt;   like round-trip latency. Looks like we were wrong.

Well - cutting down the bandwidth (at the risk of underutilizing resources in 
the Tor overlay) does not automatically improve other performance aspects. I 
have a feeling this could turn out to be a case of "out of the frying pan into 
the fire".

&gt; (...)
&gt;
&gt; 3.3. What about variable circuit windows?
&gt;
&gt;  Once upon a time we imagined adapting the circuit package window to
&gt;  the network conditions. That is, we would start the window small,
&gt;  and raise it based on the latency and throughput we see.
&gt;
&gt;  In theory that crude imitation of TCP's windowing system would allow
&gt;  us to adapt to fill the network better. In practice, I think we want
&gt;  to stick with the small window and never raise it. The low cap reduces
&gt;  the total throughput you can get from Tor for a given circuit. But
&gt;  that's a feature, not a bug.

Note that a hard window size limit does not put a cap on the throughput, but 
on the bandwidth-delay product. Then, circuits with longer RTTs would 
experience a dramatic breakdown in throughput, because they can only send ~50 
KB and must then wait for the sendme to arrive. Circuits with low RTT are much 
less affected. Applications will also suffer from extremely bursty traffic ("stop-
and-go"), probably worse than in the current Tor overlay. This is exactly what 
we observe in our simulations.

(BTW: Could this have implications on security? From the maximum throughput of 
a circuit, or from the burst pattern, it might be possible to infer 
information on the circuit's length/delay, or on an onion router's position 
within the circuit.)

&gt; 4. Evaluation
&gt;
&gt;   How do we know this change is actually smart? It seems intuitive that
&gt;   it's helpful, and some smart systems people have agreed that it's
&gt;   a good idea (or said another way, they were shocked at how big the
&gt;   default package window was before).
&gt;
&gt;   To get a more concrete sense of the benefit, though, Karsten has been
&gt;   running torperf side-by-side on exit relays with the old package window
&gt;   vs the new one. The results are mixed currently -- it is slightly faster
&gt;   for fetching 40KB files, and slightly slower for fetching 50KB files.

Note that file sizes of 40 or 50 KB cannot tell you much about such a 
modification. As you state above, 100 cells is equivalent to ~50 KB of payload. 
I.e., you do the whole transmission within the initial transfer window. So, 
the data transfer will be over before the circuit's window mechanisms have had 
a chance to become active at all! Consequently, modifications to the window 
mechanism will not impact transfers that are below that threshold directly.

&gt;   I think it's going to be tough to get a clear conclusion that this is
&gt;   a good design just by comparing one exit relay running the patch. The
&gt;   trouble is that the other hops in the circuits are still getting bogged
&gt;   down by other clients introducing too much traffic into the network.

Maybe I'm getting something royally wrong - but what exactly are the 
mechanisms within an onion router that would result in one circuit 
experiencing much longer cell queuing delays just because *another* circuit 
has a long queue in that router? In terms of fair resource sharing between 
circuits (and the opportunity to forward cells quickly), our impression is 
that the round-robin scheduler does its job pretty well. It will be hard to 
improve on that just by introducing intentional resource underutilization.
But you guys know the Tor sources much better than we do - are we missing 
something important here?


Cheers

Björn


-- 
Jun.-Prof. Dr. Björn Scheuermann
Mobile and Decentralized Networks Group
Heinrich Heine University
Universitätsstr. 1, D-40225 Düsseldorf, Germany

Building 25.12, Room 02.42
Tel: +49 211 81 11692
Fax: +49 211 81 11638 
scheuermann@cs.uni-duesseldorf.de
http://www.cn.uni-duesseldorf.de


</body></email><email><emailId>20091021011129</emailId><senderName>Shane Pope</senderName><senderEmail>shane.m.pope@gmail.com</senderEmail><timestampReceived>2009-10-21 01:11:29-0400</timestampReceived><subject>Tor Port-Scanning Resistance Specification</subject><body>

I've written up a specification for the project I'm working on. Any feedback
would be much appreciated.

http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt

-Shane

[Attachment #3 (text/html)]

I've written up a specification for the project I'm working on. Any feedback \
would be much appreciated.&lt;br&gt;&lt;br clear="all"&gt;&lt;a \
href="http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt"&gt;http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt&lt;/a&gt;&lt;br&gt;


&lt;br&gt;-Shane&lt;br&gt;



</body></email><email><emailId>20091113125000</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2009-11-13 12:50:00-0400</timestampReceived><subject>Thoughts on changing our package names</subject><body>

I've been meeting more and more tor users over the past few months who
are confused by our package naming.  They want to download a "tor
bundle" but instead get a "vidalia bundle".  They don't understand what
the difference between vidalia, tor, polipo, and the other stuff in our
bundles.  It's all Tor to them.

The version numbers also confuse them.  They aren't sure what all the
numbers mean, nor why they should care.  From the perspective of a new
user, they don't care about the different components of a package and
what version each component is; they just need to know if they have the
latest or not.

Until we have the secure updater deployed and going, our various bundles
are how users get Tor.  As Tor attracts a less technical user concerned
about their online privacy and anonymity, the bundle naming schemes
become increasingly confusing.

I'd like to simply get rid of the installation bundles in favor of Tor
Browser Bundles for Windows, OS X, and Linuxes.  However, that fantasy
world is a ways off.  We need help fine tuning the browser bundles for
OS X and Linux.

My next best thought is to simply name the installation bundles as such:

Tor-Installation-Bundle-for-(Windows|OS X)-(bundle version number).

The bundle versions can start off at 1.0 and work their way up with each
new release.  There would be package change logs to explain what's
different in each new installation bundle version.  Users will be able
to simply tell if they have the latest or not by comparing the bundle
version number.

Only -stable versions of Tor get a bundle version number as described
above.  -alpha packages are still built the with the version numbers of
tor and vidalia as a distinction.  Alternatively, we could switch to
some nomenclature such as odd numbered major versions as -alpha, even
numbered major releases as -stable.  However, given how fast we switch
from -alpha to -stable, we'll be at Tor Installation Bundle for Windows
14.1 soon enough.

Thoughts?

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20091208011220</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-12-08 01:12:20-0400</timestampReceived><subject>More thoughts on bridge distribution strategies</subject><body>

Hi folks,

A few weeks back I spent 3 days at Kaist, talking to teams of freshmen
who are brainstorming distribution strategies for Tor bridges. For a
refresher on what I'm talking about, see the original blog post:
https://blog.torproject.org/blog/bridge-distribution-strategies

While the problem started out as theoretical at the beginning of the term,
it became much more concrete in September when China blocked the public
Tor relays:
https://blog.torproject.org/blog/picturing-tor-censorship-in-china

Here are some newer ideas on how we should handle the problem, sparked
by talking to the students and also by spending several days focused on
it myself.

The first point is to recognize better where we are in the arms race.
Specifically, we've had exactly one blocking event. Most countries have
never blocked any bridges, and China did one push on Sept 25.

(For this discussion I'm ignoring cases where they block by protocol
fingerprint rather than IP address. That's an important issue that we
have to prepare for also, and in some countries it may actually be a
more urgent issue, but it's a separate topic.)

Practically speaking, what we expect to see for the next months is
people mostly ignoring us with perhaps one or two days where they put
in a lot of effort. They're not (yet) rolling out automated enumeration
programs that run 24/7 and try to block bridges in real-time.

---Part one----------------------------------------------------------

Conclusion #1 is that we need to hold more of our bridges in reserve.
Right now we have perhaps 300-400 bridges running at any given time. The
configuration parameters I picked for the bridgedb server involve holding
1/11 of the bridges in reserve (5/11 are given out via https, and 5/11
are given out via gmail). On Sept 25, they enumerated and blocked the
https portion. That's about half the bridges gone. If they'd decided
to make a bunch of gmail accounts, they would have found over 90% of
the bridges -- leaving us with only 30-40 bridges for whatever disaster
recovery backup plan we produce.

So the next time somebody tries to learn all the bridges, we need to
make sure they get a much smaller fraction. The only reason to make
that fraction not too tiny is that we need to handle all the load that
users want to put on the bridges. Karsten's latest estimates show 30k+
daily users of bridges. They won't all fit on just 5 bridges.

Soon Karsten will be publishing anonymized archives of bridge descriptors,
and it will be clearer that the distribution of users to bridges is far
from even. There actually are a handful of bridges that are handling
much of the traffic from China. Presumably these are the ones that
spread through out-of-band social channels and not our automated (and
more evenly distributed) distribution mechanisms. So I'm tempted to be
conservative and say that a share of 20% for https, 10% for gmail, and
70% in reserve is a fine new plan. (I suggest a higher share for https
since it's easier to use so it will end up with a higher load.)

In fact, if we expect the next blocking event to come all at once, then
one additional goal we should want is that some people who already have
a bridge don't get blocked. One way to go about this is to vary which
bridges are available at all. Up until recently it turns out we were
almost doing this: we reshuffled which bridges were available to which IP
addresses every few days. But our problem was that all the bridges were
still available to *some* IP address. Instead, we need to keep some of
the bridges within the https share in reserve, and make only a fraction
of them available at any given point. For example, we could pick 1/5
of the https share and hand those out; every week we would change to
a different 1/5. Thus anybody who tries to block all the https bridges
today will learn only 1/5 of them, and people who learned their bridges
last week will be unaffected.

There are some drawbacks here. Two big ones are 1) a patient attacker can
still learn the whole set in that share over time, and 2) if a bunch of
users all decide in the same week that they need bridges, then the load
will be uneven. I'm not too worried about #1 yet (we'll deal with that
when it happens), and I think #2 is an acceptable tradeoff too.

Another problem with the more general approach of keeping 70% of the
bridges unpublished is that people may not get the immediate gratification
of seeing users, and so they'll turn off their bridge. This is a social
problem that can be tackled at a different level than the other technical
problems here. But we should be sure to address it.

---Part two----------------------------------------------------------

Conclusion #2 is that we need to prepare better for the next blocking
event. Actually, we still haven't reacted well to the first one. Our
bridgedb code doesn't know how to leave out bridges that we know are
blocked. We're still giving out blocked bridges to China via the https
mechanism. :(

The immediate need is for bridgedb to take in a blacklist of IP addresses
that shouldn't be offered. It can then just leave those out of any
answers it provides.

(I had originally been thinking "leave them blocked -- if we cull the
blocked ones, we're just making it easier for them to find the remaining
unblocked ones and block those." But since nobody's tried to do any more
blocking, we're just harming the current users for no gain.)

The more advanced approach is to give out different answers
depending on what country you're asking about. For example, you
could visit https://bridges.torproject.org/zh, or you could mail
bridges+zh@torproject.org. As a bonus, we could provide instructions
localized in that language. Kaner is currently adding this type of
feature to our gettor email auto-responder, so it's the same idea here.

Now, the downside here is that giving different answers to different
countries means there are more overall addresses being offered out.
After all, we can't tell what country the asker *really* is in. So if you
wanted to enumerate bridges, you would ask about each country separately,
and pool your answers.

We could imagine a solution where we have a totally separate set of
bridges for each country, and figure that a given country will do the
minimum possible work and block only the ones assigned to its country. My
preference would be to move directly to the later step in the arms race,
and just make the answers as uniform between countries as possible:
tag each bridge internally with which countries it's blocked in, and
skip over blocked bridges when choosing which answers to give out.

Finally, there's the related problem of figuring out which bridges are
actually blocked. Eventually we'd like to automate this, while at the same
time not introducing new ways for attackers to learn all the addresses
we're testing. But assuming the blocking events are obvious and rare,
the simple answer for now is to do it manually soon after the fact. I
still have the list from doing the manual test shortly after Sept 25.

---Part three--------------------------------------------------------

Conclusion #3 is that we're doing our gmail answers wrong. Our current
approach is that we do a one-off answer in response to an email request.
Instead we need to focus on building a relationship with that email
address. Specifically, gmail requests should be more like subscriptions
rather than responses.

A while ago, our gmail autoresponder behavior was to pick a set of three
answers the first time a given address mails us. Then on subsequent
mails, we provide exactly the same answer, except we leave out bridges
that we know are down. So if you mail us a week later from the same
gmail account, and all three of your original bridges had disappeared,
then we'd send you a list of zero bridges. Not so good.

In early October we fixed that to send the first three running bridges in
the hash ring, starting from the point in the hash ring that the gmail
account maps to. So you get three bridges, and if you ask again later,
and those three are down, you get new ones. And if the originals come
back, you get whichever three are first (closest) in line.

We also changed it so you don't have to say 'get bridges' in the body
of the mail: too many users were getting that wrong. But that trick
introduced a new concern: we could get into email loops where we bombard
a gmail user who has set up a vacation program to auto-answer. The fix for
now is to answer a given address no more than once every couple of hours.

But what if you get three bridges, and they go down in an hour? Bridgedb
will ignore your followup request.

My incremental fix is to check if the answer has changed since last
time, and if it has, be willing to answer even if the 'couple of hours'
hasn't elapsed. That way people can get answers if there are new answers,
and we still protect against email loops.

But I have a better fix. Why not automatically mail out an update if
the answer changes? There could be a new command 'subscribe bridges',
and then it will remember which ones you've heard already, and if the
best three answers include any you haven't heard before, it'll send you
an email. Or we can batch them, or only mail if none of the ones you've
heard are still up, or some other permutation. 'get bridges' could be a
synonym for a one-week subscription.

This approach means storing data about which gmail addresses are our users
(boo), though hopefully they're using throwaway gmail addresses if that
matters to them. But better, it brings in a host of new possibilities down
the road when the arms race has moved to its next phase. Specifically,
we can allocate persistent bridges to the gmail accounts that have been
around a while, or the ones whose bridges didn't get blocked, etc. See
"the sixth strategy" in the original blocking-resistance design doc for
my original plans there:
https://git.torproject.org/checkout/tor/master/doc/design-paper/blocking.html#tth_sEc7.4

It's kind of a shame that we can't demand proof-of-ongoing-work though.
I fear the scenario where we just accrue more and more gmail accounts
that we're mailing updates to but they've long since forgotten about
Tor. Should we make them re-subscribe periodically? Alas, our proof of
work on the gmail side is in creating a new account, not in receiving
further emails. So maybe we need to start relying more on the social
networking side as the arms race progresses here.

---Part four--------------------------------------------------------

Conclusion #4 is that we need to automate some other distribution
approaches. When the https approach got blocked, and we worried the gmail
approach would get blocked soon after, we got a friend in China to set
up a password-protected twitter account and sign up his 1000 closest
friends. Then I manually fed him the list of "reserve" bridges for a
few weeks, and he twittered a few bridges per day.

We need somebody to automate the posting of them on the twitter side
(anybody want to help write the scripts there?). And we need to automate
the bridgedb side also, for example so it writes out an up-to-date new
list of bridge addresses to various files that we can then export. As
a simple example, I'd like to mail a daily list to this fellow in China
with
a) which bridges from the previous mails are still around today, and
b) all the newly available bridges.

Next would be having bridgedb, or some associated scripts, track lists
and write them out to different files by share (not just every reserved
bridge at once). Then we can identify a few social hubs in each affected
country and make sure they always have a good handle on some new (and
otherwise unknown) bridges.

Having alternatives to the gmail distribution strategy is particularly
important these days in places like Iran, where they've shown little
hesitation in blocking gmail when things get rough. Right now your
best bet if you can't reach bridges.tp.o or gmail is to show up to IRC
and hope that I'm around and can give you one of the reserve bridge
addresses. That doesn't scale.

---Part five--------------------------------------------------------

Where are we going to go in the future?

It's hard to say how the arms race will progress on the attacker side, so
it's hard to predict how we'll need to adapt. But here are two directions
to keep in mind.

First, as the arms race picks up we're going to want to think harder about
ways to isolate good users on long-term bridges. One of the promising
directions from the Kaist groups was the idea of splitting users into
two groups each epoch: a large group and a small group. Each group
gets its own bridge. If the bridge for the small group ends up blocked,
break the small group in half and repeat. If it doesn't end up blocked,
all of those users are known good -- leave them with their bridge, and
they'll all be fine. Now, this approach has some remaining challenges
(for example, what if it takes a while before the bridge gets blocked),
but the basic idea of "separate users onto bridges such that you can
cluster good users by themselves on the long-term bridges" is a good goal.

Second, bridge distribution strategies where you can vary the hardness
of the challenge could be useful. The harder the challenge, the less
likely an attacker is to go for it. Thus the strategy adapts well to
unknown and/or changing levels of effort on the part of the adversary. For
example, say you have an online game with 50 levels, each harder than the
last, and you give out a few bridge addresses for successfully passing a
level. At the beginning when the attacker is ignoring it, passing just
the first level is enough to get a working bridge. But as the attacker
starts putting more effort in, then only the users who care a great deal
(the ones who play many levels) will be the ones with usable bridges.

All of that said, another constraint to remember is an economic one:
we should avoid challenges where experience with the challenge favors
the attacker. For example, if you have to solve a minesweeper game
to get bridges, and you get different bridges depending on how large
the board is, then the attacker will get really good at minesweeper,
whereas the users won't. So the "hard" levels will be harder for the
users than the attacker, and suddenly the disparity in effort will be
less than it used to be.

--Roger

</body></email><email><emailId>20091217022430</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2009-12-17 02:24:30-0400</timestampReceived><subject>Control Spec Addition First Draft</subject><body>

Hi Roger. Here's the first draft of the proposed additions to address the
arm
wishlist. To start with:
- What more would be useful? I don't do core tor development nor analysis
like
 Karsten so I'm not sure what you'd like from a monitor for debugging or
 network examination. One thought might be a GETINFO option for getting log
 entries related to a given connection (would be especially interesting in
 case investigating circuit extension failures and such). Probably not
 possible since it would require tor to remember log data...

- Comments like "Wtf? That's utterly useless/wrong!" appreciated! I've
naively
 included included some things that might not be helpful (like the 'e/E'
flag
 to indicate if connections are encrypted), not to mention mistakes thanks
to
 a not-quite-so-perfect understanding of networking, tor, and writing specs.

- Anything dangerous? Doubt it, but the bandwidth measurements should
probably
 either be rounded or provided occasionally (say, every second) to address
 correlation attacks. I'm sure Sebastian will enthusiastically sink some
 paranoia into this later. ;)

- Should we document how frequently the connection data is updated or have
some
 'last updated time' parameter?

- When hosting hidden services I'd imagine some connections are dedicated to
 them. If so, lets add a flag to indicate them.

Cheers! -Damian

-------------------------------------------------------------------------------

The following is a proposal for additions to the control-spec's GETINFO
parameters to reveal additional information related to tor connections and
circuits. The intention is to provide a viable alternative to netstat and
lsof
for discovering these stats with the following benefits:

- Performance
Frequently querying this information via external tools has a significant
overhead (especially for busy relays). Tor already has this information
cached
so being able to fetch it via the control port would introduce significant
performance benefits for monitoring tools like arm.

- Authoritative
How does tor view the world? An external perspective of how tor is utilizing
network resources is interesting, but from an auditing perspective it's even
more interesting if this can be used to validate tor's internal accounting.

- Additional Information
While we can infer some information like the connection type and
corresponding
relay from raw connection data, it would be a lot nicer (and more accurate)
to
not need to guess. Providing additional information (like per-connection
bandwidth or buffer usage) might also be interesting, assuming we can do so
safely.

Most of this information is already available to relays (both benign and
malicious), but if you spot some troubling privacy implication then please
speak up! Nothing here should end the world, but we certainly don't want to
make things easier for not-so-well-meaning people.

-------------------------------------------------------------------------------

   "conn/&lt;Connection identity&gt;" -- Provides entry for the associated
     connection, formatted as:
       CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF

     none of the parameters contain whitespace, and additional results must
be
     ignored to allow for future expansion. Parameters are defined as
follows:
       CONN_ID - Unique identifier associated with this connection.
       CIRC_ID - Unique identifier for the circuit this belongs to (0 if
this
         doesn't belong to any circuit). At most their may be two
connections
         (one inbound, one outbound) with any given CIRC_ID.
       OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
       IP/PORT - IP address and port used by the associated connection.
       TYPE_FLAGS - Single character flags indicating directionality and
type
         of the connection (consists of one from each category, may become
         longer for future expansion).
           I: inbound, i: listening (unestablished inbound),
             O: outbound, o: unestablished outbound
           C: client related, R: relay related, X: control, D: directory
           T: inter-tor connection, t: outside the tor network
           E: encrypted traffic, e: unencrypted traffic
         For instance, "IRtE" would indicate that this was an established
         1st-hop (or bridged) relay connection.
       READ/WRITE - Total bytes read/written over the life of this
connection.
       UPTIME - Time the connection's been established in seconds.
       BUFF - Bytes of data buffered for this relay connection.

   "conn/all" -- Newline separated listing of all current connections.

   "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
     RelayBandwidthRate if set, otherwise BandwidthRate).

   "info/relay/burst-limit" -- Effective relayed burst limit.

   "info/relay/read-total" -- Total bytes relayed (download).

   "info/relay/write-total" -- Total bytes relayed (upload).

   "info/relay/buffer-cap" -- Maximum buffer size for relay connections.

   "info/uptime-process" -- Total uptime of the tor process (in seconds).

   "info/uptime-reset" -- Time since last reset (startup or sighup signal,
in
     seconds).

   "info/descriptor-used" -- Count of file descriptors used.

   "info/descriptor-limit" -- File descriptor limit (getrlimit results).

   "ns/authority" -- Router status info (v2 directory style) for all
     recognized directory authorities, joined by newlines.

[Attachment #3 (text/html)]

&lt;div class="gmail_quote"&gt;Hi Roger. Here's the first draft of the proposed \
additions to address the arm&lt;br&gt; wishlist. To start with:&lt;br&gt;
- What more would be useful? I don't do core tor development nor analysis \
like&lt;br&gt;  Karsten so I'm not sure what you'd like from a monitor for \
debugging or&lt;br&gt;  network examination. One thought might be a GETINFO option for \
getting log&lt;br&gt;  entries related to a given connection (would be especially \
interesting in&lt;br&gt;  case investigating circuit extension failures and such). Probably \
not&lt;br&gt;  possible since it would require tor to remember log data...&lt;br&gt;
&lt;br&gt;
- Comments like "Wtf? That's utterly useless/wrong!" appreciated! \
I've naively&lt;br&gt;  included included some things that might not be helpful (like \
the 'e/E' flag&lt;br&gt;  to indicate if connections are encrypted), not to mention \
mistakes thanks to&lt;br&gt;  a not-quite-so-perfect understanding of networking, tor, and \
writing specs.&lt;br&gt; &lt;br&gt;
- Anything dangerous? Doubt it, but the bandwidth measurements should probably&lt;br&gt;
  either be rounded or provided occasionally (say, every second) to address&lt;br&gt;
  correlation attacks. I'm sure Sebastian will enthusiastically sink some&lt;br&gt;
  paranoia into this later. ;)&lt;br&gt;
&lt;br&gt;
- Should we document how frequently the connection data is updated or have some&lt;br&gt;
  'last updated time' parameter?&lt;br&gt;
&lt;br&gt;
- When hosting hidden services I'd imagine some connections are dedicated to&lt;br&gt;
  them. If so, lets add a flag to indicate them.&lt;br&gt;
&lt;br&gt;
Cheers! -Damian&lt;br&gt;
&lt;br&gt;
-------------------------------------------------------------------------------&lt;br&gt;
&lt;br&gt;
The following is a proposal for additions to the control-spec's GETINFO&lt;br&gt;
parameters to reveal additional information related to tor connections and&lt;br&gt;
circuits. The intention is to provide a viable alternative to netstat and lsof&lt;br&gt;
for discovering these stats with the following benefits:&lt;br&gt;
&lt;br&gt;
- Performance&lt;br&gt;
Frequently querying this information via external tools has a significant&lt;br&gt;
overhead (especially for busy relays). Tor already has this information cached&lt;br&gt;
so being able to fetch it via the control port would introduce significant&lt;br&gt;
performance benefits for monitoring tools like arm.&lt;br&gt;
&lt;br&gt;
- Authoritative&lt;br&gt;
How does tor view the world? An external perspective of how tor is utilizing&lt;br&gt;
network resources is interesting, but from an auditing perspective it's even&lt;br&gt;
more interesting if this can be used to validate tor's internal accounting.&lt;br&gt;
&lt;br&gt;
- Additional Information&lt;br&gt;
While we can infer some information like the connection type and corresponding&lt;br&gt;
relay from raw connection data, it would be a lot nicer (and more accurate) to&lt;br&gt;
not need to guess. Providing additional information (like per-connection&lt;br&gt;
bandwidth or buffer usage) might also be interesting, assuming we can do so&lt;br&gt;
safely.&lt;br&gt;
&lt;br&gt;
Most of this information is already available to relays (both benign and&lt;br&gt;
malicious), but if you spot some troubling privacy implication then please&lt;br&gt;
speak up! Nothing here should end the world, but we certainly don't want to&lt;br&gt;
make things easier for not-so-well-meaning people.&lt;br&gt;
&lt;br&gt;
-------------------------------------------------------------------------------&lt;br&gt;
&lt;br&gt;
    "conn/&lt;Connection identity&gt;" -- Provides entry for the \
associated&lt;br&gt;  connection, formatted as:&lt;br&gt;
        CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF&lt;br&gt;
&lt;br&gt;
      none of the parameters contain whitespace, and additional results must be&lt;br&gt;
      ignored to allow for future expansion. Parameters are defined as follows:&lt;br&gt;
        CONN_ID - Unique identifier associated with this connection.&lt;br&gt;
        CIRC_ID - Unique identifier for the circuit this belongs to (0 if this&lt;br&gt;
          doesn't belong to any circuit). At most their may be two \
connections&lt;br&gt;  (one inbound, one outbound) with any given CIRC_ID.&lt;br&gt;
        OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.&lt;br&gt;
        IP/PORT - IP address and port used by the associated connection.&lt;br&gt;
        TYPE_FLAGS - Single character flags indicating directionality and type&lt;br&gt;
          of the connection (consists of one from each category, may become&lt;br&gt;
          longer for future expansion).&lt;br&gt;
            I: inbound, i: listening (unestablished inbound),&lt;br&gt;
              O: outbound, o: unestablished outbound&lt;br&gt;
            C: client related, R: relay related, X: control, D: directory&lt;br&gt;
            T: inter-tor connection, t: outside the tor network&lt;br&gt;
            E: encrypted traffic, e: unencrypted traffic&lt;br&gt;
          For instance, "IRtE" would indicate that this was an \
established&lt;br&gt;  1st-hop (or bridged) relay connection.&lt;br&gt;
        READ/WRITE - Total bytes read/written over the life of this connection.&lt;br&gt;
        UPTIME - Time the connection's been established in seconds.&lt;br&gt;
        BUFF - Bytes of data buffered for this relay connection.&lt;br&gt;
&lt;br&gt;
    "conn/all" -- Newline separated listing of all current connections.&lt;br&gt;
&lt;br&gt;
    "info/relay/bw-limit" -- Effective relayed bandwidth limit \
(currently&lt;br&gt;  RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt;
&lt;br&gt;
    "info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt;
&lt;br&gt;
    "info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;
&lt;br&gt;
    "info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt;
&lt;br&gt;
    "info/relay/buffer-cap" -- Maximum buffer size for relay \
connections.&lt;br&gt; &lt;br&gt;
    "info/uptime-process" -- Total uptime of the tor process (in \
seconds).&lt;br&gt; &lt;br&gt;
    "info/uptime-reset" -- Time since last reset (startup or sighup signal, \
in&lt;br&gt;  seconds).&lt;br&gt;
&lt;br&gt;
    "info/descriptor-used" -- Count of file descriptors used.&lt;br&gt;
&lt;br&gt;
    "info/descriptor-limit" -- File descriptor limit (getrlimit \
results).&lt;br&gt; &lt;br&gt;
    "ns/authority" -- Router status info (v2 directory style) for all&lt;br&gt;
      recognized directory authorities, joined by newlines.&lt;br&gt;
&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20091220074311</emailId><senderName>Sebastian Hahn</senderName><senderEmail>hahn.seb@web.de</senderEmail><timestampReceived>2009-12-20 07:43:11-0400</timestampReceived><subject>Re: Control Spec Addition First Draft</subject><body>

Hi Damian,

please find my comments inline below.

On Dec 17, 2009, at 3:24 AM, Damian Johnson wrote:

[snip]
&gt; - Anything dangerous? Doubt it, but the bandwidth measurements should probably
&gt; either be rounded or provided occasionally (say, every second) to address
&gt; correlation attacks. I'm sure Sebastian will enthusiastically sink some
&gt; paranoia into this later. ;)

As always, I'm very uncomfortable with giving away users'/destinations' ip addresses \
or ports. I do realize that the same information can be obtained from netstat and \
friends, but I still think we should actively discourage the use and acquisition of \
this data. I realize that this is against the intentions of this proposal, but I hope \
that it is still useful even without client/destination identifying information.

&gt; - When hosting hidden services I'd imagine some connections are dedicated to
&gt; them. If so, lets add a flag to indicate them.

This is, I think, a misunderstanding of what a connection is. More below.

[snip]
&gt; "conn/&lt;Connection identity&gt;" -- Provides entry for the associated
&gt; connection, formatted as:
&gt; CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF
&gt; 
&gt; none of the parameters contain whitespace, and additional results must be
&gt; ignored to allow for future expansion. Parameters are defined as follows:
&gt; CONN_ID - Unique identifier associated with this connection.
&gt; CIRC_ID - Unique identifier for the circuit this belongs to (0 if this
&gt; doesn't belong to any circuit). At most their may be two connections
&gt; (one inbound, one outbound) with any given CIRC_ID.

Here, the connection identity needs to either include the CIRC_ID, or this is \
ambigious. Tor mutliplexes many circuits over the same connection, so there is no way \
to infer the circuit id from a connection id. Also, for exit connections, there may \
be more than two connections with the same circuit id. What this means: We either \
want a seperate query to learn about circuits, or we want the conn_id to list all the \
circuits that it has attached, or we want to only allow queries of this kind when \
circ id and conn id are both known to the controller

&gt; OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
&gt; IP/PORT - IP address and port used by the associated connection.
&gt; TYPE_FLAGS - Single character flags indicating directionality and type
&gt; of the connection (consists of one from each category, may become
&gt; longer for future expansion).
&gt; I: inbound, i: listening (unestablished inbound),
&gt; O: outbound, o: unestablished outbound
&gt; C: client related, R: relay related, X: control, D: directory
&gt; T: inter-tor connection, t: outside the tor network
&gt; E: encrypted traffic, e: unencrypted traffic
&gt; For instance, "IRtE" would indicate that this was an established
&gt; 1st-hop (or bridged) relay connection.

These flags seem to be mostly redundant. Again, they don't necessarily work because a \
connection can be used for many things. As for the Ee flag, I don't really see the \
purpose, we certainly shouldn't look at exit traffic going through the connection to \
decide if it is encrypted or not.

&gt; READ/WRITE - Total bytes read/written over the life of this connection.
&gt; UPTIME - Time the connection's been established in seconds.
&gt; BUFF - Bytes of data buffered for this relay connection.
&gt; 
&gt; "conn/all" -- Newline separated listing of all current connections.
&gt; 
&gt; "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt; RelayBandwidthRate if set, otherwise BandwidthRate).
&gt; 
&gt; "info/relay/burst-limit" -- Effective relayed burst limit.
&gt; 
&gt; "info/relay/read-total" -- Total bytes relayed (download).
&gt; 
&gt; "info/relay/write-total" -- Total bytes relayed (upload).
&gt; 
&gt; "info/relay/buffer-cap" -- Maximum buffer size for relay connections.
&gt; 
&gt; "info/uptime-process" -- Total uptime of the tor process (in seconds).
&gt; 
&gt; "info/uptime-reset" -- Time since last reset (startup or sighup signal, in
&gt; seconds).
&gt; 
&gt; "info/descriptor-used" -- Count of file descriptors used.
&gt; 
&gt; "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt; 
&gt; "ns/authority" -- Router status info (v2 directory style) for all
&gt; recognized directory authorities, joined by newlines.
&gt; 

These all sound sane.


Sebastian


</body></email><email><emailId>20091208112654</emailId><senderName>Christian Fromme</senderName><senderEmail>kaner@strace.org</senderEmail><timestampReceived>2009-12-08 11:26:54-0400</timestampReceived><subject>Re: More thoughts on bridge distribution strategies</subject><body>

Hi Roger,

On Tue, Dec 8, 2009 at 2:12 AM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:

&gt; ---Part three--------------------------------------------------------
&gt; But I have a better fix. Why not automatically mail out an update if
&gt; the answer changes? There could be a new command 'subscribe bridges',
&gt; and then it will remember which ones you've heard already, and if the
&gt; best three answers include any you haven't heard before, it'll send you
&gt; an email. Or we can batch them, or only mail if none of the ones you've
&gt; heard are still up, or some other permutation. 'get bridges' could be a
&gt; synonym for a one-week subscription.
&gt;
&gt; This approach means storing data about which gmail addresses are our users
&gt; (boo), though hopefully they're using throwaway gmail addresses if that
&gt; matters to them. But better, it brings in a host of new possibilities down
&gt; the road when the arms race has moved to its next phase. Specifically,
&gt; we can allocate persistent bridges to the gmail accounts that have been
&gt; around a while, or the ones whose bridges didn't get blocked, etc. See
&gt; "the sixth strategy" in the original blocking-resistance design doc for
&gt; my original plans there:
&gt; https://git.torproject.org/checkout/tor/master/doc/design-paper/blocking.html#tth_sEc7.4

I think the benefits outweighs the risk of keeping email addresses.

&gt; It's kind of a shame that we can't demand proof-of-ongoing-work though.
&gt; I fear the scenario where we just accrue more and more gmail accounts
&gt; that we're mailing updates to but they've long since forgotten about
&gt; Tor. Should we make them re-subscribe periodically? Alas, our proof of
&gt; work on the gmail side is in creating a new account, not in receiving
&gt; further emails. So maybe we need to start relying more on the social
&gt; networking side as the arms race progresses here.

Why not mail the user periodically with a mail 'do you want more
bridges'? If he answers to that, he has effectively extended his
subscription, where otherwise (say, grace period of one week) we purge
his address from our database.

&gt; ---Part four--------------------------------------------------------
&gt;
&gt; Conclusion #4 is that we need to automate some other distribution
&gt; approaches. When the https approach got blocked, and we worried the gmail
&gt; approach would get blocked soon after, we got a friend in China to set
&gt; up a password-protected twitter account and sign up his 1000 closest
&gt; friends. Then I manually fed him the list of "reserve" bridges for a
&gt; few weeks, and he twittered a few bridges per day.
&gt;
&gt; We need somebody to automate the posting of them on the twitter side
&gt; (anybody want to help write the scripts there?). And we need to automate
&gt; the bridgedb side also, for example so it writes out an up-to-date new
&gt; list of bridge addresses to various files that we can then export. As
&gt; a simple example, I'd like to mail a daily list to this fellow in China
&gt; with
&gt; a) which bridges from the previous mails are still around today, and
&gt; b) all the newly available bridges.

I don't know whether you already meant this, but we surely should
encrypt those mails.

&gt; Next would be having bridgedb, or some associated scripts, track lists
&gt; and write them out to different files by share (not just every reserved
&gt; bridge at once). Then we can identify a few social hubs in each affected
&gt; country and make sure they always have a good handle on some new (and
&gt; otherwise unknown) bridges.
&gt;
&gt; Having alternatives to the gmail distribution strategy is particularly
&gt; important these days in places like Iran, where they've shown little
&gt; hesitation in blocking gmail when things get rough. Right now your
&gt; best bet if you can't reach bridges.tp.o or gmail is to show up to IRC
&gt; and hope that I'm around and can give you one of the reserve bridge
&gt; addresses. That doesn't scale.

What about an IRC bot? With the same subscription parameters as an
email subscription? In theory, we could place that in every IRC net.
The only problem I see is usability. People hardly are able to follow
directions for email subscriptions, how harder would it be for them to
punch in IRC commands in a query?

Another thought: Couldn't bridges themselves offer a https server on
port XYZ and hand out bridges that way? On each request, they could
query bridgedb and get some addresses under the same restrictions as
usual? I'm sure someone came up with that already and there's a good
reason why we don't want that.

&gt; ---Part five--------------------------------------------------------
&gt;
&gt; Where are we going to go in the future?
&gt;
&gt; It's hard to say how the arms race will progress on the attacker side, so
&gt; it's hard to predict how we'll need to adapt. But here are two directions
&gt; to keep in mind.
&gt;
&gt; First, as the arms race picks up we're going to want to think harder about
&gt; ways to isolate good users on long-term bridges. One of the promising
&gt; directions from the Kaist groups was the idea of splitting users into
&gt; two groups each epoch: a large group and a small group. Each group
&gt; gets its own bridge. If the bridge for the small group ends up blocked,
&gt; break the small group in half and repeat. If it doesn't end up blocked,
&gt; all of those users are known good -- leave them with their bridge, and
&gt; they'll all be fine. Now, this approach has some remaining challenges
&gt; (for example, what if it takes a while before the bridge gets blocked),
&gt; but the basic idea of "separate users onto bridges such that you can
&gt; cluster good users by themselves on the long-term bridges" is a good goal.

Good idea. In addition, if we have that database of users you spoke
about above, we can also tag users with something like "trusted user"
and "not so trusted user", depending on user-parameters like 'duration
of subscription', 'percentage of bridges blocked after handing them
out to the user' etc.

Best,
Christian
</body></email><email><emailId>20091114024734</emailId><senderName>Sebastian Hahn</senderName><senderEmail>mail@sebastianhahn.net</senderEmail><timestampReceived>2009-11-14 02:47:34-0400</timestampReceived><subject>Re: Thoughts on changing our package names</subject><body>


On Nov 13, 2009, at 1:50 PM, Andrew Lewman wrote:

&gt; I've been meeting more and more tor users over the past few months who
&gt; are confused by our package naming.  They want to download a "tor
&gt; bundle" but instead get a "vidalia bundle".  They don't understand  
&gt; what
&gt; the difference between vidalia, tor, polipo, and the other stuff in  
&gt; our
&gt; bundles.  It's all Tor to them.

I have the same experience. Heck, when I was a novice Tor user I  
needed to go back to my browser and look at the filename that was  
downloaded to figure out where in my Downoads directory that Tor thing  
was.
&gt; I'd like to simply get rid of the installation bundles in favor of Tor
&gt; Browser Bundles for Windows, OS X, and Linuxes.  However, that fantasy
&gt; world is a ways off.  We need help fine tuning the browser bundles for
&gt; OS X and Linux.

I'm not sure this path is that great an idea. We currently have quite  
a few windows users run relays, and my intuition is that most of them  
are running the installation bundle, so Tor starts automatically when  
they boot their computer. Losing this option seems bad.

&gt; My next best thought is to simply name the installation bundles as  
&gt; such:
&gt;
&gt; Tor-Installation-Bundle-for-(Windows|OS X)-(bundle version number).
&gt;
&gt; The bundle versions can start off at 1.0 and work their way up with  
&gt; each
&gt; new release.  There would be package change logs to explain what's
&gt; different in each new installation bundle version.  Users will be able
&gt; to simply tell if they have the latest or not by comparing the bundle
&gt; version number.

I think this scheme is a good idea. We could still have some  
flexibility, and call our current bundle 1.0 for a start, and then  
move our way up to 1.1, etc; and when we feel an important enough  
feature gets implemented, we increment. But worrying about this  
version scheme seems to be not really necessary, as the versions only  
need to be monotonically increasing to not confuse the user.

&gt; Only -stable versions of Tor get a bundle version number as described
&gt; above.  -alpha packages are still built the with the version numbers  
&gt; of
&gt; tor and vidalia as a distinction.  Alternatively, we could switch to
&gt; some nomenclature such as odd numbered major versions as -alpha, even
&gt; numbered major releases as -stable.  However, given how fast we switch
&gt; from -alpha to -stable, we'll be at Tor Installation Bundle for  
&gt; Windows
&gt; 14.1 soon enough.

Why not keep our current way of naming stuff for alphas (calling the  
bundle Vidalia bundle, etc; and making it a little harder to find on  
the website so less unsuspecting users stumble across it the first  
time they try out Tor)? It seems that our testers should be able to  
cope.

&gt; Thoughts?

What does Matt think about rebranding Vidalia?


Sebastian
</body></email><email><emailId>20091114044315</emailId><senderName>Andrew Lewman</senderName><senderEmail>andrew@torproject.org</senderEmail><timestampReceived>2009-11-14 04:43:15-0400</timestampReceived><subject>Re: Thoughts on changing our package names</subject><body>

On 11/13/2009 09:47 PM, Sebastian Hahn wrote:
&gt;&gt; Tor-Installation-Bundle-for-(Windows|OS X)-(bundle version number).
&gt;&gt; Only -stable versions of Tor get a bundle version number as described
&gt;&gt; above.  -alpha packages are still built the with the version numbers of
&gt;&gt; tor and vidalia as a distinction.  Alternatively, we could switch to
&gt;&gt; some nomenclature such as odd numbered major versions as -alpha, even
&gt;&gt; numbered major releases as -stable.  However, given how fast we switch
&gt;&gt; from -alpha to -stable, we'll be at Tor Installation Bundle for Windows
&gt;&gt; 14.1 soon enough.
&gt; 
&gt; Why not keep our current way of naming stuff for alphas (calling the
&gt; bundle Vidalia bundle, etc; and making it a little harder to find on the
&gt; website so less unsuspecting users stumble across it the first time they
&gt; try out Tor)? It seems that our testers should be able to cope.

I'm fine with leaving the -alpha bundles alone.

&gt; What does Matt think about rebranding Vidalia?

I don't think we need to rebrand vidalia.  I'm literally just thinking
about the package names, the file names, and how we reference them.
Having Vidalia as the control interface, branded vidalia, still works
for most people, as the name matches the whole onion thing we have going on.

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20091117003109</emailId><senderName>coderman</senderName><senderEmail>coderman@gmail.com</senderEmail><timestampReceived>2009-11-17 00:31:09-0400</timestampReceived><subject>Re: Thoughts on changing our package names</subject><body>

On Fri, Nov 13, 2009 at 4:50 AM, Andrew Lewman &lt;andrew@torproject.org&gt; wrote:
&gt; I've been meeting more and more tor users over the past few months who
&gt; are confused by our package naming.  They want to download a "tor
&gt; bundle" but instead get a "vidalia bundle".  They don't understand what
&gt; the difference between vidalia, tor, polipo, and the other stuff in our
&gt; bundles.  It's all Tor to them.
&gt;
&gt; The version numbers also confuse them.  They aren't sure what all the
&gt; numbers mean, nor why they should care.  From the perspective of a new
&gt; user, they don't care about the different components of a package and
&gt; what version each component is; they just need to know if they have the
&gt; latest or not.

Agreed. Regardless of individual component versions I would also like
to see a single consistent version number associated with a singular
"Tor Bundle" installer.
The fact that this bundle is comprised of a number of different parts
like Polipo, Vidalia, etc. should be internal to the package and not
confusing the user.


&gt; My next best thought is to simply name the installation bundles as such:
&gt;
&gt; Tor-Installation-Bundle-for-(Windows|OS X)-(bundle version number).

I would omit the -Installation- and -for- part for brevity and replace
Windows with Win32 as one day we may care about 64bit native builds.
That is, Tor-Bundle-Win32-1.0
Is the Installation part to distinguish from the no-install portable
Tor browser bundle? That is the extent of my bike shed commentary :)


&gt; Only -stable versions of Tor get a bundle version number as described
&gt; above.  -alpha packages are still built the with the version numbers of
&gt; tor and vidalia as a distinction.  Alternatively, we could switch to
&gt; some nomenclature such as odd numbered major versions as -alpha, even
&gt; numbered major releases as -stable.  However, given how fast we switch
&gt; from -alpha to -stable, we'll be at Tor Installation Bundle for Windows
&gt; 14.1 soon enough.
&gt;
&gt; Thoughts?

Sounds good!

</body></email><email><emailId>20091021011717</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2009-10-21 01:17:17-0400</timestampReceived><subject>Re: Tor Port-Scanning Resistance Specification</subject><body>

Shane Pope wrote:
&gt; I've written up a specification for the project I'm working on. Any
&gt; feedback would be much appreciated.
&gt;
&gt; http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt
&gt;
&gt; -Shane
I like the idea of section 2.x. 
That's my two cents.

- Kyle
</body></email><email><emailId>200910210117170</emailId><senderName>Kyle Williams</senderName><senderEmail>kyle.kwilliams@gmail.com</senderEmail><timestampReceived>2009-10-21 01:17:17-0400</timestampReceived><subject>Re: Tor Port-Scanning Resistance Specification</subject><body>

Shane Pope wrote:
&gt; I've written up a specification for the project I'm working on. Any
&gt; feedback would be much appreciated.
&gt;
&gt; http://scanresisttor.googlecode.com/svn/mod_tor/tor_sr_spec.txt
&gt;
&gt; -Shane
I like the idea of section 2.x. 
That's my two cents.

- Kyle
</body></email><email><emailId>20090909100130</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-09-09 10:01:30-0400</timestampReceived><subject>Re: Proposal 168: Reduce default circuit window</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Björn,

I'm commenting on just a few points here:

On 09/01/2009 01:50 PM, Björn Scheuermann wrote:
&gt; this sounds like an interesting proposal! However, I'd like to point you to 
&gt; some implications and side effects. Over the past months, one of my students 
&gt; (Daniel Marks, on CC) has worked on congestion control in Tor. One of his 
&gt; results is an implementation of Tor circuits in a network simulation framework 
&gt; (ns-2). We use this implementation to simulate Tor networks of different size 
&gt; and with different traffic patterns, play with various parameters and measure 
&gt; throughput, cell latencies, etc. Currently, our aim is to gain a better 
&gt; understanding of congestion effects in Tor and their implications and 
&gt; interrelations.

Sounds great. Are you planning to release your simulation sources? I'd
lie when saying that I want to look at the sources now, but I certainly
would like to play with your simulation at a later point. As may others.

&gt;&gt; 2. Motivation
&gt;&gt;
&gt;&gt;   Karsten's torperf graphs show that the median download time for a 50KB
&gt;&gt;   file over Tor in mid 2009 is 7.7 seconds, whereas the median download
&gt;&gt;   time for 1MB and 5MB are around 50s and 150s respectively. The 7.7
&gt;&gt;   second figure is way too high, whereas the 50s and 150s figures are
&gt;&gt;   surprisingly low.
&gt; 
&gt; Your statement implies that you are looking at something like the 
&gt; "transmission latency per KB" (which is, by the way, identical to the inverse 
&gt; throughput).

True, most of the torperf graphs are for measuring bandwidth rather than
latency. See the PDF reports for more information:

https://git.torproject.org/checkout/metrics/master/report/performance/torperf-2009-08-24.pdf

https://git.torproject.org/checkout/metrics/master/report/circwindow/circwindow-2009-08-19.pdf

The early results of cells in circuit queues might help, too. Note that
more work remains to make real use of these data. Want to help? :)

https://git.torproject.org/checkout/metrics/master/report/buffer/bufferstats-2009-08-25.pdf

&gt;&gt;   To get a more concrete sense of the benefit, though, Karsten has been
&gt;&gt;   running torperf side-by-side on exit relays with the old package window
&gt;&gt;   vs the new one. The results are mixed currently -- it is slightly faster
&gt;&gt;   for fetching 40KB files, and slightly slower for fetching 50KB files.
&gt; 
&gt; Note that file sizes of 40 or 50 KB cannot tell you much about such a 
&gt; modification. As you state above, 100 cells is equivalent to ~50 KB of payload. 
&gt; I.e., you do the whole transmission within the initial transfer window. So, 
&gt; the data transfer will be over before the circuit's window mechanisms have had 
&gt; a chance to become active at all! Consequently, modifications to the window 
&gt; mechanism will not impact transfers that are below that threshold directly.

The 50 KiB (kibibytes, not kilobytes) download should not fit into one
circuit window of 101 cells. That circuit window can hold up to 101 x
498 = 50298 bytes whereas the file size is 51200 bytes. Due to the
torperf output, the client receives even 51466 bytes. So, we need a
second circuit window to transfer the 50 KiB file.

But I admit that 50 KiB is still pretty low. Right now, we have more
measurements running with 1 MiB files. They just take somewhat longer to
complete, because we cannot start new downloads in 5-minute intervals,
but only in 30-minute intervals. At the moment we have 347 data points;
not enough to make a useful statement. It's going to take another two
weeks to have enough data.

&gt;&gt;   I think it's going to be tough to get a clear conclusion that this is
&gt;&gt;   a good design just by comparing one exit relay running the patch. The
&gt;&gt;   trouble is that the other hops in the circuits are still getting bogged
&gt;&gt;   down by other clients introducing too much traffic into the network.
&gt; 
&gt; Maybe I'm getting something royally wrong - but what exactly are the 
&gt; mechanisms within an onion router that would result in one circuit 
&gt; experiencing much longer cell queuing delays just because *another* circuit 
&gt; has a long queue in that router? In terms of fair resource sharing between 
&gt; circuits (and the opportunity to forward cells quickly), our impression is 
&gt; that the round-robin scheduler does its job pretty well. It will be hard to 
&gt; improve on that just by introducing intentional resource underutilization.
&gt; But you guys know the Tor sources much better than we do - are we missing 
&gt; something important here?

The problem of loud circuits slowing down other circuits emerges when
these circuits are sharing the same TCP connection.

Did you have a look at Joel's and Ian's USENIX paper?

"All traffic between any pair of routers, even if they represent
circuits for different clients, are multiplexed over a single TCP
connection. This results in interference across circuits during
congestion control, packet dropping and packet reordering. This
interference greatly contributes to Tor's notorious latency problems."

See http://crysp.uwaterloo.ca/publications/ for the publication list or
http://www.cypherpunks.ca/~iang/pubs/TorTP.pdf for the PDF.

Best,
- --Karsten

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkqnfPgACgkQ0M+WPffBEmVF0ACgzroWeSx5CMtNJ9kHJDx7yXpI
/DwAoLrR4HJN606+zBZbheBFUzfUvuuA
=Ss05
-----END PGP SIGNATURE-----
</body></email><email><emailId>20091214012314</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-12-14 01:23:14-0400</timestampReceived><subject>Squeezing non-relays at the entry node</subject><body>

Hi folks (Nick in particular),

I've been pondering other performance improvements. One of them is to
rate-limit client connections as they enter the network. Rate limiting
in the Tor client itself would work better, but it's not a very stable
equilibrium -- it encourages people to switch to security disasters
like tortunnel.

So I'm looking at rate-limiting non-relay OR connections. Here's the
patch:

diff --git a/src/or/connection_or.c b/src/or/connection_or.c
index aa26bf8..3f984bf 100644
--- a/src/or/connection_or.c
+++ b/src/or/connection_or.c
@@ -333,10 +333,24 @@ connection_or_init_conn_from_address(or_connection_t *conn
,
 { 
   or_options_t *options = get_options();
   routerinfo_t *r = router_get_by_digest(id_digest);
-  conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
-  conn-&gt;read_bucket = conn-&gt;bandwidthburst = (int)options-&gt;BandwidthBurst;
   connection_or_set_identity_digest(conn, id_digest);

+  if (r || router_get_consensus_status_by_id(id_digest)) {
+    /* It's in the consensus, or we have a descriptor for it meaning it
+     * was probably in a recent consensus. It's a recognized relay:
+     * give it full bandwidth. */
+    conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
+    conn-&gt;read_bucket = conn-&gt;bandwidthburst = (int)options-&gt;BandwidthBurst;
+  } else { /* Not a recognized relay. Squeeze it down based on the
+            * suggested bandwidth parameters in the consensus. */
+    conn-&gt;bandwidthrate =
+      (int)networkstatus_get_param(NULL, "bwconnrate",
+                                   (int)options-&gt;BandwidthRate);
+    conn-&gt;read_bucket = conn-&gt;bandwidthburst =
+      (int)networkstatus_get_param(NULL, "bwconnburst",
+                                   (int)options-&gt;BandwidthBurst);
+  }
+
   conn-&gt;_base.port = port;
   tor_addr_copy(&amp;conn-&gt;_base.addr, addr);
   tor_addr_copy(&amp;conn-&gt;real_addr, addr);

As you can see, I'm making it configurable inside the consensus, so we
can experiment with it rather than rolling it out and then changing our
minds later. I don't have a good sense of whether it will be a good move,
but the only way I can imagine to find out is to try it.

I'm imagining trying it out with a rate of 20KB and a burst of 500KB.

As a nice side effect, we'll also be rolling out the infrastructure for
one defense against Sambuddho's "approximating a global passive adversary"
congestion attack, if the attack ever gets precise enough that we can
try out our defense and compare.

In the distant future, where we've deployed a design where not all relays
get to see the unified networkstatus consensus, we'll have to stop voting
for a modified bwconnrate and bwconnburst, since the relays won't be
able to know (at least this way) if it's a genuine relay. Maybe part
of that design will be to present a signed credential proving you're a
public relay. In any case, we have a way to disable this feature when
that distant future arrives.

We're also squeezing down bridge relays by this feature, since the public
relays can't tell the difference between a bridge and a client. At some
point we should make sure that bridges send their client traffic over
different TCP connections than their own traffic. That's a separate
discussion though.

It shouldn't impact bandwidth bootstrapping tests, since those aim to
spread 500KB of traffic across 4 circuits.

It would impact Mike's bwauthority tests. We'd want to make an exception
for those Tors. I think we'd leave the torperf deployments alone, since
after all their goal is to measure "realistic" client performance.

It could also impact initial directory info bootstrapping -- if you try
to fetch 1MB from a particular dir mirror, it would slow down the second
half of that download. We'd want to keep an eye on how much that changes.

A more thorough solution would be to rate-limit all the OR conns coming
from a particular non-relay into the same bucket, to prevent people
getting around the limits by opening multiple TCP connections. But it's
actually not so easy to open multiple conns to the same destination in
Tor; plus I'm aiming to solve this for the general case where people
are overloading relays and don't even know it's a bad thing.

My main concern here is that I wonder if we are being thorough enough at
detecting "is a relay". It checks the consensus and the descriptor cache
currently. So if the authorities think you're not Running, they won't put
you in the consensus, and no relays will hear about you. If you go up and
down, relays that serve dirport info will have your descriptor cached,
so they'll recognize you so long as you were around in the past day or so.

Relays that don't serve dirport info will stop fetching descriptors,
but they'll continue to fetch the consensus. So they'll still mostly work.

Are there any other cases that are going to be a problem? Are there better
(simple, easy to deploy soon) ways to decide if the peer is a relay?

--Roger

</body></email><email><emailId>20091217022353</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2009-12-17 02:23:53-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

I'm sure you've thought of this, but adversaries can replicate any
properties we're looking for to rate limit. In this case simply making
yourself a slow relay and routing client traffic through yourself
(being your own first hop) seems to get around the limitation. -Damian

On Sun, Dec 13, 2009 at 5:23 PM, Roger Dingledine &lt;arma@mit.edu&gt; wrote:
&gt; Hi folks (Nick in particular),
&gt;
&gt; I've been pondering other performance improvements. One of them is to
&gt; rate-limit client connections as they enter the network. Rate limiting
&gt; in the Tor client itself would work better, but it's not a very stable
&gt; equilibrium -- it encourages people to switch to security disasters
&gt; like tortunnel.
&gt;
&gt; So I'm looking at rate-limiting non-relay OR connections. Here's the
&gt; patch:
&gt;
&gt; diff --git a/src/or/connection_or.c b/src/or/connection_or.c
&gt; index aa26bf8..3f984bf 100644
&gt; --- a/src/or/connection_or.c
&gt; +++ b/src/or/connection_or.c
&gt; @@ -333,10 +333,24 @@ connection_or_init_conn_from_address(or_connection_t
*conn
&gt; ,
&gt;  {
&gt;   or_options_t *options = get_options();
&gt;   routerinfo_t *r = router_get_by_digest(id_digest);
&gt; -  conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
&gt; -  conn-&gt;read_bucket = conn-&gt;bandwidthburst =
(int)options-&gt;BandwidthBurst;
&gt;   connection_or_set_identity_digest(conn, id_digest);
&gt;
&gt; +  if (r || router_get_consensus_status_by_id(id_digest)) {
&gt; +    /* It's in the consensus, or we have a descriptor for it meaning it
&gt; +     * was probably in a recent consensus. It's a recognized relay:
&gt; +     * give it full bandwidth. */
&gt; +    conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;
&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst =
(int)options-&gt;BandwidthBurst;
&gt; +  } else { /* Not a recognized relay. Squeeze it down based on the
&gt; +            * suggested bandwidth parameters in the consensus. */
&gt; +    conn-&gt;bandwidthrate =
&gt; +      (int)networkstatus_get_param(NULL, "bwconnrate",
&gt; +                                   (int)options-&gt;BandwidthRate);
&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst =
&gt; +      (int)networkstatus_get_param(NULL, "bwconnburst",
&gt; +                                   (int)options-&gt;BandwidthBurst);
&gt; +  }
&gt; +
&gt;   conn-&gt;_base.port = port;
&gt;   tor_addr_copy(&amp;conn-&gt;_base.addr, addr);
&gt;   tor_addr_copy(&amp;conn-&gt;real_addr, addr);
&gt;
&gt; As you can see, I'm making it configurable inside the consensus, so we
&gt; can experiment with it rather than rolling it out and then changing our
&gt; minds later. I don't have a good sense of whether it will be a good move,
&gt; but the only way I can imagine to find out is to try it.
&gt;
&gt; I'm imagining trying it out with a rate of 20KB and a burst of 500KB.
&gt;
&gt; As a nice side effect, we'll also be rolling out the infrastructure for
&gt; one defense against Sambuddho's "approximating a global passive adversary"
&gt; congestion attack, if the attack ever gets precise enough that we can
&gt; try out our defense and compare.
&gt;
&gt; In the distant future, where we've deployed a design where not all relays
&gt; get to see the unified networkstatus consensus, we'll have to stop voting
&gt; for a modified bwconnrate and bwconnburst, since the relays won't be
&gt; able to know (at least this way) if it's a genuine relay. Maybe part
&gt; of that design will be to present a signed credential proving you're a
&gt; public relay. In any case, we have a way to disable this feature when
&gt; that distant future arrives.
&gt;
&gt; We're also squeezing down bridge relays by this feature, since the public
&gt; relays can't tell the difference between a bridge and a client. At some
&gt; point we should make sure that bridges send their client traffic over
&gt; different TCP connections than their own traffic. That's a separate
&gt; discussion though.
&gt;
&gt; It shouldn't impact bandwidth bootstrapping tests, since those aim to
&gt; spread 500KB of traffic across 4 circuits.
&gt;
&gt; It would impact Mike's bwauthority tests. We'd want to make an exception
&gt; for those Tors. I think we'd leave the torperf deployments alone, since
&gt; after all their goal is to measure "realistic" client performance.
&gt;
&gt; It could also impact initial directory info bootstrapping -- if you try
&gt; to fetch 1MB from a particular dir mirror, it would slow down the second
&gt; half of that download. We'd want to keep an eye on how much that changes.
&gt;
&gt; A more thorough solution would be to rate-limit all the OR conns coming
&gt; from a particular non-relay into the same bucket, to prevent people
&gt; getting around the limits by opening multiple TCP connections. But it's
&gt; actually not so easy to open multiple conns to the same destination in
&gt; Tor; plus I'm aiming to solve this for the general case where people
&gt; are overloading relays and don't even know it's a bad thing.
&gt;
&gt; My main concern here is that I wonder if we are being thorough enough at
&gt; detecting "is a relay". It checks the consensus and the descriptor cache
&gt; currently. So if the authorities think you're not Running, they won't put
&gt; you in the consensus, and no relays will hear about you. If you go up and
&gt; down, relays that serve dirport info will have your descriptor cached,
&gt; so they'll recognize you so long as you were around in the past day or so.
&gt;
&gt; Relays that don't serve dirport info will stop fetching descriptors,
&gt; but they'll continue to fetch the consensus. So they'll still mostly work.
&gt;
&gt; Are there any other cases that are going to be a problem? Are there better
&gt; (simple, easy to deploy soon) ways to decide if the peer is a relay?
&gt;
&gt; --Roger
&gt;
&gt;

[Attachment #3 (text/html)]

&lt;div class="gmail_quote"&gt;I'm sure you've thought of this, but adversaries can \
replicate any&lt;br&gt; properties we're looking for to rate limit. In this case simply \
making&lt;br&gt; yourself a slow relay and routing client traffic through yourself&lt;br&gt;
(being your own first hop) seems to get around the limitation. -Damian&lt;br&gt;
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div class="h5"&gt;&lt;br&gt;
On Sun, Dec 13, 2009 at 5:23 PM, Roger Dingledine &lt;&lt;a \
href="mailto:arma@mit.edu"&gt;arma@mit.edu&lt;/a&gt;&gt; wrote:&lt;br&gt; &gt; Hi folks (Nick in \
particular),&lt;br&gt; &gt;&lt;br&gt;
&gt; I've been pondering other performance improvements. One of them is to&lt;br&gt;
&gt; rate-limit client connections as they enter the network. Rate limiting&lt;br&gt;
&gt; in the Tor client itself would work better, but it's not a very stable&lt;br&gt;
&gt; equilibrium -- it encourages people to switch to security disasters&lt;br&gt;
&gt; like tortunnel.&lt;br&gt;
&gt;&lt;br&gt;
&gt; So I'm looking at rate-limiting non-relay OR connections. Here's the&lt;br&gt;
&gt; patch:&lt;br&gt;
&gt;&lt;br&gt;
&gt; diff --git a/src/or/connection_or.c b/src/or/connection_or.c&lt;br&gt;
&gt; index aa26bf8..3f984bf 100644&lt;br&gt;
&gt; --- a/src/or/connection_or.c&lt;br&gt;
&gt; +++ b/src/or/connection_or.c&lt;br&gt;
&gt; @@ -333,10 +333,24 @@ connection_or_init_conn_from_address(or_connection_t \
*conn&lt;br&gt; &gt; ,&lt;br&gt;
&gt;  {&lt;br&gt;
&gt;   or_options_t *options = get_options();&lt;br&gt;
&gt;   routerinfo_t *r = router_get_by_digest(id_digest);&lt;br&gt;
&gt; -  conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;&lt;br&gt;
&gt; -  conn-&gt;read_bucket = conn-&gt;bandwidthburst = \
(int)options-&gt;BandwidthBurst;&lt;br&gt; &gt;   connection_or_set_identity_digest(conn, \
id_digest);&lt;br&gt; &gt;&lt;br&gt;
&gt; +  if (r || router_get_consensus_status_by_id(id_digest)) {&lt;br&gt;
&gt; +    /* It's in the consensus, or we have a descriptor for it meaning it&lt;br&gt;
&gt; +     * was probably in a recent consensus. It's a recognized relay:&lt;br&gt;
&gt; +     * give it full bandwidth. */&lt;br&gt;
&gt; +    conn-&gt;bandwidthrate = (int)options-&gt;BandwidthRate;&lt;br&gt;
&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst = \
(int)options-&gt;BandwidthBurst;&lt;br&gt; &gt; +  } else { /* Not a recognized relay. \
Squeeze it down based on the&lt;br&gt; &gt; +            * suggested bandwidth parameters \
in the consensus. */&lt;br&gt; &gt; +    conn-&gt;bandwidthrate =&lt;br&gt;
&gt; +      (int)networkstatus_get_param(NULL, "bwconnrate",&lt;br&gt;
&gt; +                                   (int)options-&gt;BandwidthRate);&lt;br&gt;
&gt; +    conn-&gt;read_bucket = conn-&gt;bandwidthburst =&lt;br&gt;
&gt; +      (int)networkstatus_get_param(NULL, "bwconnburst",&lt;br&gt;
&gt; +                                   (int)options-&gt;BandwidthBurst);&lt;br&gt;
&gt; +  }&lt;br&gt;
&gt; +&lt;br&gt;
&gt;   conn-&gt;_base.port = port;&lt;br&gt;
&gt;   tor_addr_copy(&amp;conn-&gt;_base.addr, addr);&lt;br&gt;
&gt;   tor_addr_copy(&amp;conn-&gt;real_addr, addr);&lt;br&gt;
&gt;&lt;br&gt;
&gt; As you can see, I'm making it configurable inside the consensus, so we&lt;br&gt;
&gt; can experiment with it rather than rolling it out and then changing our&lt;br&gt;
&gt; minds later. I don't have a good sense of whether it will be a good \
move,&lt;br&gt; &gt; but the only way I can imagine to find out is to try it.&lt;br&gt;
&gt;&lt;br&gt;
&gt; I'm imagining trying it out with a rate of 20KB and a burst of 500KB.&lt;br&gt;
&gt;&lt;br&gt;
&gt; As a nice side effect, we'll also be rolling out the infrastructure for&lt;br&gt;
&gt; one defense against Sambuddho's "approximating a global passive \
adversary"&lt;br&gt; &gt; congestion attack, if the attack ever gets precise enough \
that we can&lt;br&gt; &gt; try out our defense and compare.&lt;br&gt;
&gt;&lt;br&gt;
&gt; In the distant future, where we've deployed a design where not all \
relays&lt;br&gt; &gt; get to see the unified networkstatus consensus, we'll have to \
stop voting&lt;br&gt; &gt; for a modified bwconnrate and bwconnburst, since the relays \
won't be&lt;br&gt; &gt; able to know (at least this way) if it's a genuine relay. \
Maybe part&lt;br&gt; &gt; of that design will be to present a signed credential proving \
you're a&lt;br&gt; &gt; public relay. In any case, we have a way to disable this \
feature when&lt;br&gt; &gt; that distant future arrives.&lt;br&gt;
&gt;&lt;br&gt;
&gt; We're also squeezing down bridge relays by this feature, since the \
public&lt;br&gt; &gt; relays can't tell the difference between a bridge and a client. \
At some&lt;br&gt; &gt; point we should make sure that bridges send their client traffic \
over&lt;br&gt; &gt; different TCP connections than their own traffic. That's a \
separate&lt;br&gt; &gt; discussion though.&lt;br&gt;
&gt;&lt;br&gt;
&gt; It shouldn't impact bandwidth bootstrapping tests, since those aim to&lt;br&gt;
&gt; spread 500KB of traffic across 4 circuits.&lt;br&gt;
&gt;&lt;br&gt;
&gt; It would impact Mike's bwauthority tests. We'd want to make an \
exception&lt;br&gt; &gt; for those Tors. I think we'd leave the torperf deployments \
alone, since&lt;br&gt; &gt; after all their goal is to measure "realistic" client \
performance.&lt;br&gt; &gt;&lt;br&gt;
&gt; It could also impact initial directory info bootstrapping -- if you try&lt;br&gt;
&gt; to fetch 1MB from a particular dir mirror, it would slow down the second&lt;br&gt;
&gt; half of that download. We'd want to keep an eye on how much that \
changes.&lt;br&gt; &gt;&lt;br&gt;
&gt; A more thorough solution would be to rate-limit all the OR conns coming&lt;br&gt;
&gt; from a particular non-relay into the same bucket, to prevent people&lt;br&gt;
&gt; getting around the limits by opening multiple TCP connections. But it's&lt;br&gt;
&gt; actually not so easy to open multiple conns to the same destination in&lt;br&gt;
&gt; Tor; plus I'm aiming to solve this for the general case where people&lt;br&gt;
&gt; are overloading relays and don't even know it's a bad thing.&lt;br&gt;
&gt;&lt;br&gt;
&gt; My main concern here is that I wonder if we are being thorough enough at&lt;br&gt;
&gt; detecting "is a relay". It checks the consensus and the descriptor \
cache&lt;br&gt; &gt; currently. So if the authorities think you're not Running, they \
won't put&lt;br&gt; &gt; you in the consensus, and no relays will hear about you. If \
you go up and&lt;br&gt; &gt; down, relays that serve dirport info will have your descriptor \
cached,&lt;br&gt; &gt; so they'll recognize you so long as you were around in the past \
day or so.&lt;br&gt; &gt;&lt;br&gt;
&gt; Relays that don't serve dirport info will stop fetching descriptors,&lt;br&gt;
&gt; but they'll continue to fetch the consensus. So they'll still mostly \
work.&lt;br&gt; &gt;&lt;br&gt;
&gt; Are there any other cases that are going to be a problem? Are there better&lt;br&gt;
&gt; (simple, easy to deploy soon) ways to decide if the peer is a relay?&lt;br&gt;
&gt;&lt;br&gt;
&gt; --Roger&lt;br&gt;
&gt;&lt;br&gt;
&gt;&lt;br&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20091217024320</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-12-17 02:43:20-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

On Wed, Dec 16, 2009 at 06:23:53PM -0800, Damian Johnson wrote:
&gt; I'm sure you've thought of this, but adversaries can replicate any
&gt; properties we're looking for to rate limit. In this case simply making
&gt; yourself a slow relay and routing client traffic through yourself
&gt; (being your own first hop) seems to get around the limitation. -Damian

Yep. But quoting my Tor-incentives paper:
(not quite the same situation, but related enough)

\subsection{The audit arms race}

Some attacks outlined above involve relays that provide some level of
service but not quite as much as we might prefer. The response in each
case is a smarter or more intensive measurement algorithm so the directory
authorities can more precisely distinguish uncooperative behavior.

To see why this won't be an arms race between increasingly subtle
cheating and increasingly sophisticated audits, we need to examine the
incentives for ordinary users. Based on informal discussions with Tor
relay operators, the most challenging part of setting up a Tor relay
is configuring the software, enabling port forwarding in the firewall,
etc. Compared to this initial barrier, the incremental cost of providing
a bit more bandwidth is low for most users. As long as our audit
mechanism correctly judges whether the user relays any traffic at all,
we're verifying that the user has performed the most personally costly
step in setting up a relay. We expect that the diminishing returns a
strategic relay gets in saving bandwidth as we progress down the arms
race will limit the complexity required for the auditing mechanism.

--Roger

</body></email><email><emailId>20091217144031</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-12-17 14:40:31-0400</timestampReceived><subject>Metrics website (was: Re: Publishing sanitized bridge descriptors)</subject><body>

Hello everyone,

the sanitized bridge descriptors as discussed in my earlier mail are now available \
here (on the Data page):

  http://metrics.torproject.org/

That website also contains most of the other metrics data we have as well as some \
early graphs and reports. Some files, especially signatures, are still missing, and I \
need to add a documentation page with instructions for parsing the files. That is \
going to happen in January.

As usual, feedback is welcome -- and likely to influence the order of adding more \
information to the website.

Thanks,
--Karsten


On Nov 10, 2009, at 6:06 PM, Karsten Loesing wrote:

&gt; Hi everyone,
&gt; 
&gt; I'm planning to publish a sanitized version of the bridge descriptors that our \
&gt; bridge authority Tonga gathers. The general idea behind this is to make all data \
&gt; public that we gather for statistical purposes. There are several reasons for doing \
&gt; so: transparency towards our community, restricting ourselves to gathering only \
&gt; those statistics that we think are safe to make public, allowing others to do the \
&gt; same research as we do, etc. 
&gt; The bridge descriptors contain IP addresses and other contact information of \
&gt; bridges that we don't want to give away. Doing so would defeat the purpose of \
&gt; bridges, after all. 
&gt; Here are the steps that we're taking to remove all potentially sensitive \
&gt; information from bridge descriptors before publication: 
&gt; 1. Replace the bridge identity with its SHA1 value
&gt; 
&gt; Clients can request a bridge's current descriptor by sending its identity string to \
&gt; the bridge authority. This is a feature to make bridges on dynamic IP addresses \
&gt; useful. Therefore, the original identities (and anything that could be used to \
&gt; derive them) need to be removed from the descriptors. The bridge identity is \
&gt; replaced with its SHA1 hash value. The idea is to have a consistent replacement \
&gt; that remains stable over months or even years (without keeping a secret for a keyed \
&gt; hash function). 
&gt; 2. Remove all cryptographic keys and signatures
&gt; 
&gt; It would be straightforward to learn about the bridge identity from the bridge's \
&gt; public key. Replacing keys by newly generated ones seemed to be unnecessary (and \
&gt; would involve keeping a state over months/years), so that all cryptographic objects \
&gt; have simply been removed. 
&gt; 3. Replace IP address with 127.0.0.1
&gt; 
&gt; Of course, the IP address needs to be removed, too. However, the IP address is \
&gt; resolved to a country code first and the result written to the contact line as \
&gt; "somebody at example dot de" for Germany, etc. The ports are kept unchanged though. \
&gt;  4. Replace contact information
&gt; 
&gt; If there is contact information in a descriptor, the contact line is changed to \
&gt; "somebody at ...". If there is none, a contact line is added saying "nobody at ..." \
&gt; in order to put in the country code. 
&gt; 5. Replace nickname with Unnamed
&gt; 
&gt; The bridge nicknames might give hints on the location of the bridge if chosen \
&gt; without care; e.g. a bridge nickname might be very similar to the operators' relay \
&gt; nicknames which might be located on adjacent IP addresses. All bridge nicknames are \
&gt; therefore replaced with the string Unnamed. 
&gt; Note that these processing steps only prevent people from learning about new bridge \
&gt; locations. People who already know a bridge identity or location can easily learn \
&gt; more about this bridge from the sanitized descriptors. This is useful for \
&gt; statistical analysis, e.g. to filter out bridges that have been running as relays \
&gt; before. 
&gt; The Java application that does all the parsing, replacing, and rewriting can be \
&gt; found here: 
&gt; https://tor-svn.freehaven.net/svn/projects/archives/trunk/bridge-desc-sanitizer/
&gt; 
&gt; Here is a sample of the bridge descriptors of October 2008 (not 2009, in case there \
&gt; turn out to be sensitive parts in there): 
&gt; http://freehaven.net/~karsten/volatile/bridges-2008-10.tar.bz2    (4.6 MB)
&gt; 
&gt; Are there any sensitive parts in that tarball that we don't want to publish?
&gt; 
&gt; Thanks,
&gt; --Karsten


</body></email><email><emailId>20091217222114</emailId><senderName>Nick Mathewson</senderName><senderEmail>nickm@freehaven.net</senderEmail><timestampReceived>2009-12-17 22:21:14-0400</timestampReceived><subject>Re: More thoughts on bridge distribution strategies</subject><body>

On Mon, Dec 07, 2009 at 08:12:20PM -0500, Roger Dingledine wrote:
 [...]
&gt; Practically speaking, what we expect to see for the next months is
&gt; people mostly ignoring us with perhaps one or two days where they put
&gt; in a lot of effort. They're not (yet) rolling out automated enumeration
&gt; programs that run 24/7 and try to block bridges in real-time.

Right.  I would expect this trend to continue for about as long as it
seems to continue to work okay for them.  After all, the typical
censors already have extensive experience in and ample
hardware/software support for the "use manpower to find all the IPs
for X and block them all" model of censorship.  So long as that model
works well enough to seriously inconvenience most users, they've not
got much incentive to work harder at it.

 [...]
&gt; Conclusion #4 is that we need to automate some other distribution
&gt; approaches.

I think something else we really need to do here is stop trying to do
all the bridge distribution R&amp;D ourselves.  This is a case where a
diversity of good approaches will help, not hurt, privacy... and we'll
get more approaches if we work better with people who want to develop
them.

In my ideal world, we'd assign bridges to one or more distributors,
some of which would be our existing email/twitter/web schemes, some of
which would be informal social networks, some of which would be crazy
captcha-based systems developed by third parties, and so on.  We'd try
to track, for each bridge, whether it was used and whether it was
blocked by various censors.  We'd then try to infer which distributors
were good at getting bridges used where, and which were bad at keeping
bridges from getting blocked by whom.

Instead of leaving many bridges completely unused, we'd either assign
them to distributors with low (but nonzero) usage and very low
blocking, or assign them to distributors with a fairly local
audience.

Roger will doubtlessly be recalling the papers he worked on ages ago
about the limits of resisting insider attacks against in reputation
systems of this kind, but I think something like this could be a
positive step in the arms race.

Of course, right now it's all handwaving on my part.  Somebody needs
to sit down and work out the math.  I've gotten a little progress made
here; once I'm farther along I'll ask some of the usual suspects whether
they're interested in coauthoring a paper.

yrs,
-- 
Nick Mathewson
</body></email><email><emailId>20091219133016</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2009-12-19 13:30:16-0400</timestampReceived><subject>Re: Please help with measuring network statistics on your relay</subject><body>

On Thu, Dec 17, 2009 at 04:12:20PM +0100, karsten.loesing@gmx.net wrote 8.9K bytes in 191 lines about:
: - enable CellStatistics, DirReqStatistics, EntryStatistics, and/or
: ExitStatistics (depending on the statistics to gather), and

In case you haven't tried this, s/ExitStatistics/ExitPortStatistics/ in
the email and your config will work.

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20091220222431</emailId><senderName>Damian Johnson</senderName><senderEmail>atagar1@gmail.com</senderEmail><timestampReceived>2009-12-20 22:24:31-0400</timestampReceived><subject>Re: Control Spec Addition First Draft</subject><body>

Hi Sebastian, thanks for the feedback!

As always, I'm very uncomfortable with giving away users'/destinations' ip
&gt; addresses or ports. I do realize that the same information can be obtained
&gt; from netstat and friends, but I still think we should actively discourage
&gt; the use and acquisition of this data. I realize that this is against the
&gt; intentions of this proposal, but I hope that it is still useful even without
&gt; client/destination identifying information.
&gt;

Disagree for the following reasons:
- As mentioned on IRC: all Internet facing applications (browsers, email
clients, tor) are attack vectors for my system. Tor's developers are good,
but I'm not so sure that they're infallible (sorry Nick) and hence the
process can't be blindly trusted - that's why I think transparency is the
best way to go. With hundreds of connections to relatively unknown
destinations tor is already the bane of network based IDS so it would be
nice if we could provide some accounting to system administrators that tor
is behaving as it should. For instance say the tor process claims a big
outbound connection taking 90% of your bandwidth that can't be accounted for
as belonging to a circuit. If you aren't using it as a client that would
be... bad.

- I agree that for correlation attacks this data is of concern in the event
that numerous relays store or share this information. However, for an
individual relay operator having this data shouldn't pose *any* threat to
tor users (if it does... we have an issue). From what I can tell this
proposal doesn't do anything that makes correlation attacks more dangerous
since netstat running in a cron job is all they need (assuming they own a
big chunk of the relays).

- Tor was designed with a certain level of distrust of relays. Beyond that
the best we can do is discourage them from risky behaviour (ie, running
outdated versions, looking at exit traffic, sharing connection data, etc).
By including connection types controllers will have the opportunity to tell
relay operators "Oi! Please don't look at these exit connections unless you
have a damn good reason.". As it stands I don't have a way of telling them
apart, and hence can't even hide them by default.

- As you mentioned we can't (and imho shouldn't) prevent relay operators
from seeing the connections made to/from their own system. This proposal
doesn't seem to exasperate any privacy issues while providing some nice
benefits (performance and some handy bits of extra data that'll make
security anomalies far easier to detect).

This is, I think, a misunderstanding of what a connection is. More below.
&gt;

No, the hidden service question isn't. I'm assuming that when hosting hidden
services there's some connections dedicated to providing that service. If
so, a TYPE_FLAG should probably be included since they don't really belong
to any of the other groups. Changed proposal to include one till someone
tells me this is wrong.

Here, the connection identity needs to either include the CIRC_ID, or this
&gt; is ambigious...
&gt;

Thanks for the catch! Made the following three corrections:

- Changed signature to "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" to
avoid ambiguity. I'm assuming that in general people will use the "conn/all"
to discover the circuit/connection ids (actually, can't think of a use for
getting a single connection - just including it to conform with other
control-spec GETINFO options).

- Noted that more than two connections could have the same circuit ID in the
case of exit connections.

- Including a L_PORT (local port) parameter - wasn't mentioned but
definitely an oversight.

These flags seem to be mostly redundant. Again, they don't necessarily work
&gt; because a connection can be used for many things. As for the Ee flag, I
&gt; don't really see the purpose, we certainly shouldn't look at exit traffic
&gt; going through the connection to decide if it is encrypted or not.


Yea, I wasn't sure if they should be like argument flags (given a default if
excluded) or always explicitly stated. Opted for the later since in general
explicit is better than implicit, and this way implementers (like TorCtl)
won't need to hard code any defaults. Both minor points and glad to discuss
more if people disagree.

Yes, if this was only associated with a connection it wouldn't work, but
circuit/connection combinations should be unique so issue fixed there.

As for the Ee flag I'm suspecting that it would have use for client
connections since any unencrypted traffic there is sniffable. This isn't
important to the use cases I care about so we can drop it if others think
it's a bad idea.

Here's the revised proposal:

-------------------------------------------------------------------------------

  "conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides entry for the
    associated connection, formatted as:
      CONN_ID CIRC_ID OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME BUFF

    none of the parameters contain whitespace, and additional results must
be
    ignored to allow for future expansion. Parameters are defined as
follows:
      CONN_ID - Unique identifier associated with this connection.
      CIRC_ID - Unique identifier for the circuit this belongs to (0 if this
        doesn't belong to any circuit). At most their may be two connections
        (one inbound, one outbound) with any given CIRC_ID except in the
case
        of exit connections.
      OR_ID - Relay fingerprint, 0 if connection doesn't belong to a relay.
      IP/PORT - IP address and port used by the associated connection.
      L_PORT - Local port used by the connection.
      TYPE_FLAGS - Single character flags indicating directionality and type
        of the connection (consists of one from each category, may become
        longer for future expansion).
          I: inbound, i: listening (unestablished inbound),
            O: outbound, o: unestablished outbound
          C: client related, R: relay related, X: control, H: hidden
service,
            D: directory
          T: inter-tor connection, t: outside the tor network
          E: encrypted traffic, e: unencrypted traffic
        For instance, "IRtE" would indicate that this was an established
        1st-hop (or bridged) relay connection.
      READ/WRITE - Total bytes read/written over the life of this
connection.
      UPTIME - Time the connection's been established in seconds.
      BUFF - Bytes of data buffered for this relay connection.

  "conn/all" -- Newline separated listing of all current connections.

  "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
    RelayBandwidthRate if set, otherwise BandwidthRate).

  "info/relay/burst-limit" -- Effective relayed burst limit.

  "info/relay/read-total" -- Total bytes relayed (download).

  "info/relay/write-total" -- Total bytes relayed (upload).

  "info/relay/buffer-cap" -- Maximum buffer size for relay connections.

  "info/uptime-process" -- Total uptime of the tor process (in seconds).

  "info/uptime-reset" -- Time since last reset (startup or sighup signal, in
    seconds).

  "info/descriptor-used" -- Count of file descriptors used.

  "info/descriptor-limit" -- File descriptor limit (getrlimit results).

  "ns/authority" -- Router status info (v2 directory style) for all
    recognized directory authorities, joined by newlines.

-------------------------------------------------------------------------------

Cheers! -Damian

On Sat, Dec 19, 2009 at 11:43 PM, Sebastian Hahn &lt;hahn.seb@web.de&gt; wrote:

&gt; Hi Damian,
&gt;
&gt; please find my comments inline below.
&gt;
&gt; On Dec 17, 2009, at 3:24 AM, Damian Johnson wrote:
&gt;
&gt; [snip]
&gt; &gt;  - Anything dangerous? Doubt it, but the bandwidth measurements should
&gt; probably
&gt; &gt;  either be rounded or provided occasionally (say, every second) to
&gt; address
&gt; &gt;  correlation attacks. I'm sure Sebastian will enthusiastically sink some
&gt; &gt;  paranoia into this later. ;)
&gt;
&gt; As always, I'm very uncomfortable with giving away users'/destinations' ip
&gt; addresses or ports. I do realize that the same information can be obtained
&gt; from netstat and friends, but I still think we should actively discourage
&gt; the use and acquisition of this data. I realize that this is against the
&gt; intentions of this proposal, but I hope that it is still useful even without
&gt; client/destination identifying information.
&gt;
&gt; &gt; - When hosting hidden services I'd imagine some connections are dedicated
&gt; to
&gt; &gt;  them. If so, lets add a flag to indicate them.
&gt;
&gt; This is, I think, a misunderstanding of what a connection is. More below.
&gt;
&gt; [snip]
&gt; &gt;    "conn/&lt;Connection identity&gt;" -- Provides entry for the associated
&gt; &gt;      connection, formatted as:
&gt; &gt;        CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF
&gt; &gt;
&gt; &gt;      none of the parameters contain whitespace, and additional results
&gt; must be
&gt; &gt;      ignored to allow for future expansion. Parameters are defined as
&gt; follows:
&gt; &gt;        CONN_ID - Unique identifier associated with this connection.
&gt; &gt;        CIRC_ID - Unique identifier for the circuit this belongs to (0 if
&gt; this
&gt; &gt;          doesn't belong to any circuit). At most their may be two
&gt; connections
&gt; &gt;          (one inbound, one outbound) with any given CIRC_ID.
&gt;
&gt; Here, the connection identity needs to either include the CIRC_ID, or this
&gt; is ambigious. Tor mutliplexes many circuits over the same connection, so
&gt; there is no way to infer the circuit id from a connection id. Also, for exit
&gt; connections, there may be more than two connections with the same circuit
&gt; id. What this means: We either want a seperate query to learn about
&gt; circuits, or we want the conn_id to list all the circuits that it has
&gt; attached, or we want to only allow queries of this kind when circ id and
&gt; conn id are both known to the controller
&gt;
&gt; &gt;        OR_ID - Relay fingerprint, 0 if connection doesn't belong to a
&gt; relay.
&gt; &gt;        IP/PORT - IP address and port used by the associated connection.
&gt; &gt;        TYPE_FLAGS - Single character flags indicating directionality and
&gt; type
&gt; &gt;          of the connection (consists of one from each category, may
&gt; become
&gt; &gt;          longer for future expansion).
&gt; &gt;            I: inbound, i: listening (unestablished inbound),
&gt; &gt;              O: outbound, o: unestablished outbound
&gt; &gt;            C: client related, R: relay related, X: control, D: directory
&gt; &gt;            T: inter-tor connection, t: outside the tor network
&gt; &gt;            E: encrypted traffic, e: unencrypted traffic
&gt; &gt;          For instance, "IRtE" would indicate that this was an established
&gt; &gt;          1st-hop (or bridged) relay connection.
&gt;
&gt; These flags seem to be mostly redundant. Again, they don't necessarily work
&gt; because a connection can be used for many things. As for the Ee flag, I
&gt; don't really see the purpose, we certainly shouldn't look at exit traffic
&gt; going through the connection to decide if it is encrypted or not.
&gt;
&gt; &gt;        READ/WRITE - Total bytes read/written over the life of this
&gt; connection.
&gt; &gt;        UPTIME - Time the connection's been established in seconds.
&gt; &gt;        BUFF - Bytes of data buffered for this relay connection.
&gt; &gt;
&gt; &gt;    "conn/all" -- Newline separated listing of all current connections.
&gt; &gt;
&gt; &gt;    "info/relay/bw-limit" -- Effective relayed bandwidth limit (currently
&gt; &gt;      RelayBandwidthRate if set, otherwise BandwidthRate).
&gt; &gt;
&gt; &gt;    "info/relay/burst-limit" -- Effective relayed burst limit.
&gt; &gt;
&gt; &gt;    "info/relay/read-total" -- Total bytes relayed (download).
&gt; &gt;
&gt; &gt;    "info/relay/write-total" -- Total bytes relayed (upload).
&gt; &gt;
&gt; &gt;    "info/relay/buffer-cap" -- Maximum buffer size for relay connections.
&gt; &gt;
&gt; &gt;    "info/uptime-process" -- Total uptime of the tor process (in seconds).
&gt; &gt;
&gt; &gt;    "info/uptime-reset" -- Time since last reset (startup or sighup
&gt; signal, in
&gt; &gt;      seconds).
&gt; &gt;
&gt; &gt;    "info/descriptor-used" -- Count of file descriptors used.
&gt; &gt;
&gt; &gt;    "info/descriptor-limit" -- File descriptor limit (getrlimit results).
&gt; &gt;
&gt; &gt;    "ns/authority" -- Router status info (v2 directory style) for all
&gt; &gt;      recognized directory authorities, joined by newlines.
&gt; &gt;
&gt;
&gt; These all sound sane.
&gt;
&gt;
&gt; Sebastian

[Attachment #3 (text/html)]

Hi Sebastian, thanks for the feedback!&lt;br&gt;&lt;br&gt;&lt;blockquote style="border-left: 1px \
solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" \
class="gmail_quote"&gt;As always, I'm very uncomfortable with giving away \
users'/destinations' ip addresses or ports. I do realize that the same \
information can be obtained from netstat and friends, but I still think we should \
actively discourage the use and acquisition of this data. I realize that this is
against the intentions of this proposal, but I hope that it is still
useful even without client/destination identifying \
information.&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;Disagree for the following reasons:&lt;br&gt;- As \
mentioned on IRC: all Internet facing applications (browsers, email clients, tor) are \
attack vectors for my system. Tor's developers are good, but I'm not so sure \
that they're infallible (sorry Nick) and hence the process can't be blindly \
trusted - that's why I think transparency is the best way to go. With hundreds of \
connections to relatively unknown destinations tor is already the bane of network \
based IDS so it would be nice if we could provide some accounting to system \
administrators that tor is behaving as it should. For instance say the tor process \
claims a big outbound connection taking 90% of your bandwidth that can't be \
accounted for as belonging to a circuit. If you aren't using it as a client that \
would be... bad.&lt;br&gt; &lt;br&gt;- I agree that for correlation attacks this data is of \
concern in the event that numerous relays store or share this information. However, \
for an individual relay operator having this data shouldn't pose *any* threat to \
tor users (if it does... we have an issue). From what I can tell this proposal \
doesn't do anything that makes correlation attacks more dangerous since netstat \
running in a cron job is all they need (assuming they own a big chunk of the \
relays).&lt;br&gt; &lt;br&gt;- Tor was designed with a certain level of distrust of relays. \
Beyond that the best we can do is discourage them from risky behaviour (ie, running \
outdated versions, looking at exit traffic, sharing connection data, etc). By \
including connection types controllers will have the opportunity to tell relay \
operators "Oi! Please don't look at these exit connections unless you have a \
damn good reason.". As it stands I don't have a way of telling them apart, \
and hence can't even hide them by default.&lt;br&gt; &lt;br&gt;- As you mentioned we \
can't (and imho shouldn't) prevent relay operators from seeing the \
connections made to/from their own system. This proposal doesn't seem to \
exasperate any privacy issues while providing some nice benefits (performance and \
some handy bits of extra data that'll make security anomalies far easier to \
detect).&lt;br&gt; &lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); \
margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;This is, I think, \
a misunderstanding of what a connection is. More below.&lt;br&gt;&lt;/blockquote&gt; &lt;br&gt;No, the \
hidden service question isn't. I'm assuming that when hosting hidden services \
there's some connections dedicated to providing that service. If so, a TYPE_FLAG \
should probably be included since they don't really belong to any of the other \
groups. Changed proposal to include one till someone tells me this is wrong.&lt;br&gt; \
&lt;br&gt;&lt;blockquote style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt \
0.8ex; padding-left: 1ex;" class="gmail_quote"&gt;Here, the connection identity needs to \
either include the CIRC_ID, or this is ambigious...&lt;br&gt; &lt;/blockquote&gt;&lt;br&gt;Thanks for \
the catch! Made the following three corrections:&lt;br&gt;&lt;br&gt;- Changed signature to \
"conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" to avoid \
ambiguity. I'm assuming that in general people will use the "conn/all" \
to discover the circuit/connection ids (actually, can't think of a use for \
getting a single connection - just including it to conform with other control-spec \
GETINFO options).&lt;br&gt; &lt;br&gt;- Noted that more than two connections could have the same \
circuit ID in the case of exit connections.&lt;br&gt;&lt;br&gt;- Including a L_PORT (local port) \
parameter - wasn't mentioned but definitely an oversight.&lt;br&gt;&lt;br&gt;&lt;blockquote \
style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; \
padding-left: 1ex;" class="gmail_quote"&gt; These flags seem to be mostly redundant. \
Again, they don't necessarily work because a connection can be used for many \
things. As for the Ee flag, I don't really see the purpose, we certainly \
shouldn't look at exit traffic going through the connection to decide if it is \
encrypted or not.&lt;/blockquote&gt;&lt;br&gt;Yea, I wasn't sure if they should be like \
argument flags (given a default if excluded) or always explicitly stated. Opted for \
the later since in general explicit is better than implicit, and this way \
implementers (like TorCtl) won't need to hard code any defaults. Both minor \
points and glad to discuss more if people disagree.&lt;br&gt; &lt;br&gt;Yes, if this was only \
associated with a connection it wouldn't work, but circuit/connection \
combinations should be unique so issue fixed there.&lt;br&gt;&lt;br&gt;As for the Ee flag I'm \
suspecting that it would have use for client connections since any unencrypted \
traffic there is sniffable. This isn't important to the use cases I care about so \
we can drop it if others think it's a bad idea.&lt;br&gt; &lt;br&gt;Here's the revised \
proposal:&lt;br&gt;&lt;br&gt;-------------------------------------------------------------------------------&lt;br&gt;&lt;br&gt; \
"conn/&lt;Circuit identity&gt;/&lt;Connection identity&gt;" -- Provides \
entry for the&lt;br&gt;  associated connection, formatted as:&lt;br&gt;      CONN_ID CIRC_ID \
OR_ID IP PORT L_PORT TYPE_FLAGS READ WRITE UPTIME BUFF&lt;br&gt;&lt;br&gt;    none of the \
parameters contain whitespace, and additional results must be&lt;br&gt;    ignored to allow \
for future expansion. Parameters are defined as follows:&lt;br&gt;  CONN_ID - Unique \
identifier associated with this connection.&lt;br&gt;      CIRC_ID - Unique identifier for \
the circuit this belongs to (0 if this&lt;br&gt;        doesn't belong to any circuit). \
At most their may be two connections&lt;br&gt;  (one inbound, one outbound) with any given \
CIRC_ID except in the case&lt;br&gt;        of exit connections.&lt;br&gt;      OR_ID - Relay \
fingerprint, 0 if connection doesn't belong to a relay.&lt;br&gt;      IP/PORT - IP \
address and port used by the associated connection.&lt;br&gt;  L_PORT - Local port used by \
the connection.&lt;br&gt;      TYPE_FLAGS - Single character flags indicating \
directionality and type&lt;br&gt;        of the connection (consists of one from each \
category, may become&lt;br&gt;        longer for future expansion).&lt;br&gt;  I: inbound, i: \
listening (unestablished inbound),&lt;br&gt;            O: outbound, o: unestablished \
outbound&lt;br&gt;          C: client related, R: relay related, X: control, H: hidden \
service,&lt;br&gt;            D: directory&lt;br&gt;  T: inter-tor connection, t: outside the tor \
network&lt;br&gt;          E: encrypted traffic, e: unencrypted traffic&lt;br&gt;        For \
instance, "IRtE" would indicate that this was an established&lt;br&gt;        \
1st-hop (or bridged) relay connection.&lt;br&gt;  READ/WRITE - Total bytes read/written \
over the life of this connection.&lt;br&gt;      UPTIME - Time the connection's been \
established in seconds.&lt;br&gt;      BUFF - Bytes of data buffered for this relay \
connection.&lt;br&gt;&lt;br&gt;  "conn/all" -- Newline separated listing of all current \
connections.&lt;br&gt;&lt;br&gt;  "info/relay/bw-limit" -- Effective relayed bandwidth \
limit (currently&lt;br&gt;    RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt; &lt;br&gt; \
"info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt;&lt;br&gt;  \
"info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;&lt;br&gt;  \
"info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt; &lt;br&gt;  \
"info/relay/buffer-cap" -- Maximum buffer size for relay \
connections.&lt;br&gt;&lt;br&gt;  "info/uptime-process" -- Total uptime of the tor \
process (in seconds).&lt;br&gt;&lt;br&gt;  "info/uptime-reset" -- Time since last reset \
(startup or sighup signal, in&lt;br&gt;  seconds).&lt;br&gt;&lt;br&gt;  \
"info/descriptor-used" -- Count of file descriptors used.&lt;br&gt;&lt;br&gt;  \
"info/descriptor-limit" -- File descriptor limit (getrlimit \
results).&lt;br&gt;&lt;br&gt;  "ns/authority" -- Router status info (v2 directory \
style) for all&lt;br&gt;  recognized directory authorities, joined by \
newlines.&lt;br&gt;&lt;br&gt;-------------------------------------------------------------------------------&lt;br&gt;&lt;br&gt;Cheers! \
-Damian&lt;br&gt;&lt;br&gt;&lt;div class="gmail_quote"&gt;On Sat, Dec 19, 2009 at 11:43 PM, Sebastian \
Hahn &lt;span dir="ltr"&gt;&lt;&lt;a \
href="mailto:hahn.seb@web.de"&gt;hahn.seb@web.de&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt; &lt;blockquote \
class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt \
0pt 0.8ex; padding-left: 1ex;"&gt;Hi Damian,&lt;br&gt; &lt;br&gt;
please find my comments inline below.&lt;br&gt;
&lt;br&gt;
On Dec 17, 2009, at 3:24 AM, Damian Johnson wrote:&lt;br&gt;
&lt;br&gt;
[snip]&lt;br&gt;
&lt;div class="im"&gt;&gt;  - Anything dangerous? Doubt it, but the bandwidth measurements \
should probably&lt;br&gt; &gt;  either be rounded or provided occasionally (say, every \
second) to address&lt;br&gt; &gt;  correlation attacks. I'm sure Sebastian will \
enthusiastically sink some&lt;br&gt; &gt;  paranoia into this later. ;)&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;As always, I'm very uncomfortable with giving away \
users'/destinations' ip addresses or ports. I do realize that the same \
information can be obtained from netstat and friends, but I still think we should \
actively discourage the use and acquisition of this data. I realize that this is \
against the intentions of this proposal, but I hope that it is still useful even \
without client/destination identifying information.&lt;br&gt;

&lt;div class="im"&gt;&lt;br&gt;
&gt; - When hosting hidden services I'd imagine some connections are dedicated \
to&lt;br&gt; &gt;  them. If so, lets add a flag to indicate them.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;This is, I think, a misunderstanding of what a connection is. More below.&lt;br&gt;
&lt;br&gt;
[snip]&lt;br&gt;
&lt;div class="im"&gt;&gt;    "conn/&lt;Connection identity&gt;" -- Provides \
entry for the associated&lt;br&gt; &gt;      connection, formatted as:&lt;br&gt;
&gt;        CONN_ID CIRC_ID OR_ID IP PORT TYPE_FLAGS READ WRITE UPTIME BUFF&lt;br&gt;
&gt;&lt;br&gt;
&gt;      none of the parameters contain whitespace, and additional results must \
be&lt;br&gt; &gt;      ignored to allow for future expansion. Parameters are defined as \
follows:&lt;br&gt; &gt;        CONN_ID - Unique identifier associated with this \
connection.&lt;br&gt; &gt;        CIRC_ID - Unique identifier for the circuit this belongs \
to (0 if this&lt;br&gt; &gt;          doesn't belong to any circuit). At most their may \
be two connections&lt;br&gt; &gt;          (one inbound, one outbound) with any given \
CIRC_ID.&lt;br&gt; &lt;br&gt;
&lt;/div&gt;Here, the connection identity needs to either include the CIRC_ID, or this is \
ambigious. Tor mutliplexes many circuits over the same connection, so there is no way \
to infer the circuit id from a connection id. Also, for exit connections, there may \
be more than two connections with the same circuit id. What this means: We either \
want a seperate query to learn about circuits, or we want the conn_id to list all the \
circuits that it has attached, or we want to only allow queries of this kind when \
circ id and conn id are both known to the controller&lt;br&gt;

&lt;div class="im"&gt;&lt;br&gt;
&gt;        OR_ID - Relay fingerprint, 0 if connection doesn't belong to a \
relay.&lt;br&gt; &gt;        IP/PORT - IP address and port used by the associated \
connection.&lt;br&gt; &gt;        TYPE_FLAGS - Single character flags indicating \
directionality and type&lt;br&gt; &gt;          of the connection (consists of one from \
each category, may become&lt;br&gt; &gt;          longer for future expansion).&lt;br&gt;
&gt;            I: inbound, i: listening (unestablished inbound),&lt;br&gt;
&gt;              O: outbound, o: unestablished outbound&lt;br&gt;
&gt;            C: client related, R: relay related, X: control, D: directory&lt;br&gt;
&gt;            T: inter-tor connection, t: outside the tor network&lt;br&gt;
&gt;            E: encrypted traffic, e: unencrypted traffic&lt;br&gt;
&gt;          For instance, "IRtE" would indicate that this was an \
established&lt;br&gt; &gt;          1st-hop (or bridged) relay connection.&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;These flags seem to be mostly redundant. Again, they don't necessarily work \
because a connection can be used for many things. As for the Ee flag, I don't \
really see the purpose, we certainly shouldn't look at exit traffic going through \
the connection to decide if it is encrypted or not.&lt;br&gt;

&lt;div class="im"&gt;&lt;br&gt;
&gt;        READ/WRITE - Total bytes read/written over the life of this \
connection.&lt;br&gt; &gt;        UPTIME - Time the connection's been established in \
seconds.&lt;br&gt; &gt;        BUFF - Bytes of data buffered for this relay connection.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "conn/all" -- Newline separated listing of all current \
connections.&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/relay/bw-limit" -- Effective relayed bandwidth limit \
(currently&lt;br&gt; &gt;      RelayBandwidthRate if set, otherwise BandwidthRate).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/burst-limit" -- Effective relayed burst limit.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/read-total" -- Total bytes relayed (download).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/write-total" -- Total bytes relayed (upload).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/relay/buffer-cap" -- Maximum buffer size for relay \
connections.&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/uptime-process" -- Total uptime of the tor process (in \
seconds).&lt;br&gt; &gt;&lt;br&gt;
&gt;    "info/uptime-reset" -- Time since last reset (startup or sighup \
signal, in&lt;br&gt; &gt;      seconds).&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/descriptor-used" -- Count of file descriptors used.&lt;br&gt;
&gt;&lt;br&gt;
&gt;    "info/descriptor-limit" -- File descriptor limit (getrlimit \
results).&lt;br&gt; &gt;&lt;br&gt;
&gt;    "ns/authority" -- Router status info (v2 directory style) for \
all&lt;br&gt; &gt;      recognized directory authorities, joined by newlines.&lt;br&gt;
&gt;&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;These all sound sane.&lt;br&gt;
&lt;font color="#888888"&gt;&lt;br&gt;
&lt;br&gt;
Sebastian&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;



</body></email><email><emailId>20091223101118</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-12-23 10:11:18-0400</timestampReceived><subject>Re: Squeezing non-relays at the entry node</subject><body>

On Sun, Dec 13, 2009 at 08:23:14PM -0500, Roger Dingledine wrote:
&gt; I've been pondering other performance improvements. One of them is to
&gt; rate-limit client connections as they enter the network. Rate limiting
&gt; in the Tor client itself would work better, but it's not a very stable
&gt; equilibrium -- it encourages people to switch to security disasters
&gt; like tortunnel.

I talked to Nick about this idea, and he:
1) Reminded me about proposal 163. Go read that thread. The main
difference is that I proposed a "or has a descriptor in its cache"
check too.
2) Demanded that I break out the "is a client" to its own function. Ok.
3) Thought it was a fine experiment to do.

Here's the newer patch:

http://archives.seul.org/or/cvs/Dec-2009/msg00390.html

&gt; My main concern here is that I wonder if we are being thorough enough at
&gt; detecting "is a relay". It checks the consensus and the descriptor cache
&gt; currently. So if the authorities think you're not Running, they won't put
&gt; you in the consensus, and no relays will hear about you. If you go up and
&gt; down, relays that serve dirport info will have your descriptor cached,
&gt; so they'll recognize you so long as you were around in the past day or so.
&gt; 
&gt; Relays that don't serve dirport info will stop fetching descriptors,
&gt; but they'll continue to fetch the consensus. So they'll still mostly work.

Soon I would like to make all relays above e.g. 50KB/s cache and serve
directory info. Having a separate open DirPort is becoming an obsolete
notion these days anyway now that most Tors use begindir requests over
the ORPort. Once we do that, these relays will be better at identifying
who else is a relay. I'd also like to make all relays regardless of their
dirport status answer begindir requests for their own descriptor. That bug
is currently preventing people (for example, me while testing censorship
stuff in Hong Kong) from using relays with no dirport set as bridges.

But that, as they say, is a proposal for another time.

--Roger

</body></email><email><emailId>20091110170626</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-11-10 17:06:26-0400</timestampReceived><subject>Publishing sanitized bridge descriptors</subject><body>

Hi everyone,

I'm planning to publish a sanitized version of the bridge descriptors  
that our bridge authority Tonga gathers. The general idea behind this  
is to make all data public that we gather for statistical purposes.  
There are several reasons for doing so: transparency towards our  
community, restricting ourselves to gathering only those statistics  
that we think are safe to make public, allowing others to do the same  
research as we do, etc.

The bridge descriptors contain IP addresses and other contact  
information of bridges that we don't want to give away. Doing so would  
defeat the purpose of bridges, after all.

Here are the steps that we're taking to remove all potentially  
sensitive information from bridge descriptors before publication:

1. Replace the bridge identity with its SHA1 value

Clients can request a bridge's current descriptor by sending its  
identity string to the bridge authority. This is a feature to make  
bridges on dynamic IP addresses useful. Therefore, the original  
identities (and anything that could be used to derive them) need to be  
removed from the descriptors. The bridge identity is replaced with its  
SHA1 hash value. The idea is to have a consistent replacement that  
remains stable over months or even years (without keeping a secret for  
a keyed hash function).

2. Remove all cryptographic keys and signatures

It would be straightforward to learn about the bridge identity from  
the bridge's public key. Replacing keys by newly generated ones seemed  
to be unnecessary (and would involve keeping a state over months/ 
years), so that all cryptographic objects have simply been removed.

3. Replace IP address with 127.0.0.1

Of course, the IP address needs to be removed, too. However, the IP  
address is resolved to a country code first and the result written to  
the contact line as "somebody at example dot de" for Germany, etc. The  
ports are kept unchanged though.

4. Replace contact information

If there is contact information in a descriptor, the contact line is  
changed to "somebody at ...". If there is none, a contact line is  
added saying "nobody at ..." in order to put in the country code.

5. Replace nickname with Unnamed

The bridge nicknames might give hints on the location of the bridge if  
chosen without care; e.g. a bridge nickname might be very similar to  
the operators' relay nicknames which might be located on adjacent IP  
addresses. All bridge nicknames are therefore replaced with the string  
Unnamed.

Note that these processing steps only prevent people from learning  
about new bridge locations. People who already know a bridge identity  
or location can easily learn more about this bridge from the sanitized  
descriptors. This is useful for statistical analysis, e.g. to filter  
out bridges that have been running as relays before.

The Java application that does all the parsing, replacing, and  
rewriting can be found here:

https://tor-svn.freehaven.net/svn/projects/archives/trunk/bridge-desc-sanitizer/

Here is a sample of the bridge descriptors of October 2008 (not 2009,  
in case there turn out to be sensitive parts in there):

http://freehaven.net/~karsten/volatile/bridges-2008-10.tar.bz2    (4.6  
MB)

Are there any sensitive parts in that tarball that we don't want to  
publish?

Thanks,
--Karsten

</body></email><email><emailId>20091118021011</emailId><senderName></senderName><senderEmail>andrew</senderEmail><timestampReceived>2009-11-18 02:10:11-0400</timestampReceived><subject>Re: Thoughts on changing our package names</subject><body>

On Mon, Nov 16, 2009 at 04:31:09PM -0800, coderman@gmail.com wrote 1.9K bytes in 44 lines about:
: 
: I would omit the -Installation- and -for- part for brevity and replace
: Windows with Win32 as one day we may care about 64bit native builds.
: That is, Tor-Bundle-Win32-1.0
: Is the Installation part to distinguish from the no-install portable
: Tor browser bundle? That is the extent of my bike shed commentary :)

Yes.  The installation is there to distinguish from the TBB.

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject
</body></email><email><emailId>20091030064040</emailId><senderName>grarpamp</senderName><senderEmail>grarpamp@gmail.com</senderEmail><timestampReceived>2009-10-30 06:40:40-0400</timestampReceived><subject>Proposal: MapAddress wilcards [*]</subject><body>

This proposal regarding domain name mapping is still alive and
maybe made it into a developer queue somewhere :)

However I forgot to add the IP address version of it. This is very
rough... wanted to get it out there for comment as time is short
to do much with it atm.

It is known that both fqdn's and ip's are commonly published,
embedded and otherwise used for various purposes on the internet
at large. Therefore:

Mapaddress should also be able to map any destination IPv4 or IPv6
address in CIDR notation through any particular exit. The CIDR
notation is what's new and provides the wildcard function. Example:

# catch just one address, route it through this exit
MAPADDRESS 1.2.3.4/32 1.2.3.4/32.&lt;fingerprint&gt;.exit
# map a range of addresses
MAPADDRESS 10.0.0.0/22 10.0.0.0/22.&lt;fingerprint&gt;.exit
# map all traffic
MAPADDRESS 0.0.0.0/0 0.0.0.0/0.&lt;fingerprint&gt;.exit

Other interesting variations may be possible or useful:

# one to one by name, name could be wildcarded
MAPADDRESS foo.com 1.2.3.4/32.&lt;fingerprint&gt;.exit

# many to one name/ip
MAPADDRESS 10.0.0.0/22 foo.com.&lt;fingerprint&gt;.exit
MAPADDRESS 10.0.0.0/22 1.2.3.4/32.&lt;fingerprint&gt;.exit

# address translation
MAPADDRESS 2.3.4.5/20 7.8.9.0/20.&lt;fingerprint&gt;.exit


There should be a control flag somewhere that says socks requests
for fqdn's that are resolved to ip addresses should then be final
checked against the CIDR maps. Default = 1.

# MapFqdnCidr = 0
foo.com -&gt; socks -&gt; tor_resolve [ip1] -&gt; exit -&gt; internet [ip1]
# MapFqdnCidr = 1
foo.com -&gt; socks -&gt; tor_resolve [ip1] -&gt; tor_map [ip2] -&gt; exit -&gt; internet [ip2]


There could also be something where tor will auto-create a matching
one to one host map like 1.2.3.4/32 1.2.3.4/32.&lt;fingerprint&gt;.exit.
foo.com maps to an ip, so might as well also map whatever that
resolves to to the same exit. I think it already does this to some
extent but would catch the cases where say, a webserver admin coded
both the fqdn and ip in html page. Could get funky if multiple A
records come back. And could be covered by 0/0 ip and *. fqdn maps,
so a non priority.

Just thinking... thanks!
</body></email><email><emailId>20091031034532</emailId><senderName>Darren Thurston</senderName><senderEmail>darren.t.thurston@gmail.com</senderEmail><timestampReceived>2009-10-31 03:45:32-0400</timestampReceived><subject>osx installer problems on several machines</subject><body>

Hi,

How do I file a bug report? I ran into this FAIL on two seperate Apple  
machines last night at Tor Night at the VanHackSpace. Tried on a fresh  
install here with same results. I still have not narrowed down what is  
causing the problem, it looks like the browser is not connecting to  
the polipo from what I can tell.

any ideas?

Cheers,
Darren




------

# Installed new system 10.6 base no updates on MacBook

# Installed Firefox 3.5.4

# Installed vidalia package: vidalia-bundle-0.2.1.20-0.2.5-i386.dmg

#ran the "Install Torbutton for Firefox" script

#Started Vidalia tor start fine and connects to a circuit fine, log  
below:

Oct 30 19:58:23.209 [Notice] Tor v0.2.1.20. This is experimental  
software. Do not rely on it for strong anonymity. (Running on Darwin  
i386)
Oct 30 19:58:23.224 [Notice] Initialized libevent version 1.4.12- 
stable using method kqueue. Good.
Oct 30 19:58:23.224 [Notice] Opening Socks listener on 127.0.0.1:9050
Oct 30 19:58:23.224 [Notice] Opening Control listener on 127.0.0.1:9051
Oct 30 19:58:23.568 [Notice] This version of Tor (0.2.1.20) is newer  
than any recommended version in its series, according to the directory  
authorities. Recommended versions are:  
0.2.0.34,0.2.0.35,0.2.1.19,0.2.2.1-alpha,0.2.2.2-alpha,0.2.2.3-alpha, 
0.2.2.4-alpha,0.2.2.5-alpha
Oct 30 19:58:24.216 [Notice] We now have enough directory information  
to build circuits.
Oct 30 19:58:24.217 [Notice] Bootstrapped 80%: Connecting to the Tor  
network.
Oct 30 19:58:24.394 [Notice] Bootstrapped 85%: Finishing handshake  
with first hop.
Oct 30 19:58:27.874 [Notice] Bootstrapped 90%: Establishing a Tor  
circuit.
Oct 30 19:58:32.793 [Notice] Tor has successfully opened a circuit.  
Looks like client functionality is working.
Oct 30 19:58:32.795 [Notice] Bootstrapped 100%: Done.


#Started Firefox and it gives me the alert:

The proxy server is refusing connections
Firefox is configured to use a proxy server that is refusing  
connections.

     *   Check the proxy settings to make sure that they are correct.

     *   Contact your network administrator to make sure the proxy  
server is
           working.


#top tells me their all the correct things are running:


202- polipo       0.0       00:00.00 1    0    14   28   120K   240K    
492K
201- tor          0.0       00:01.27 1    0    18   43   5344K  1128K   
9304K
197- Vidalia      0.0       00:08.25 6    1    107  188  14M    31M     
36M


 From what I can tell the proxy settings in FF are set correctly:

HTTP Proxy 127.0.0.1:8118
SSL Proxy 127.0.0.1:8118
SOCKS 5 127.0.0.1:9050


and it looks like all the settings are correct in Vidalia

----

cat torrc

# This file was generated by Tor; if you edit it, comments will not be  
preserved
# The old torrc file was renamed to torrc.orig.1 or similar, and Tor  
will ignore it

# If set, Tor will accept connections from the same machine (localhost  
only)
# on this port, and allow those connections to control the Tor process  
using
# the Tor Control Protocol (described in control-spec.txt).
ControlPort 9051
# Store working data, state, keys, and caches here.
DataDirectory /Users/sand/.tor/
HashedControlPassword  
16:E8C7050BABCE652860183B560A0ABBC869B5E85B54562EC092FE637AD1
# Where to send logging messages.  Format is minSeverity[-maxSeverity]
# (stderr|stdout|syslog|file FILENAME).
Log notice stdout

---

cat vidalia.conf

[General]
ProxyExecutable=/Applications/Vidalia.app/Contents/MacOS/polipo
RunProxyAtStart=true
InterfaceStyle=Macintosh (aqua)
ShowMainWindowAtStart=false

[Tor]
TorExecutable=/Applications/Vidalia.app/Contents/MacOS/tor
DataDirectory=/Users/sand/.tor/

[MessageLog]
Geometry=@ByteArray(\x1\xd9\xd0\xcb 
\0\x1\0\0\0\0\x1\xc2\0\0\0\xe9\0\0\x5\x37\0\0\x2\xba 
\0\0\x1\xc2\0\0\0\xff\0\0\x5\x37\0\0\x2\xba\0\0\0\0\0\0)

[MainWindow]
Geometry=@ByteArray(\x1\xd9\xd0\xcb\0\x1\0\0\0\0\x3\x32\0\0\0w 
\0\0\x4\xcc\0\0\x2\x37\0\0\x3\x32\0\0\0\x8d\0\0\x4\xcc 
\0\0\x2\x37\0\0\0\0\0\0)

[BandwidthGraph]
Geometry=@ByteArray(\x1\xd9\xd0\xcb\0\x1\0\0\0\0\x1h 
\0\0\0\xf8\0\0\x2\x82\0\0\x1&lt;\0\0\x1h\0\0\x1\xe\0\0\x2\x82\0\0\x1&lt; 
\0\0\0\0\0\0)

[NetViewer]
Geometry=@ByteArray(\x1\xd9\xd0\xcb\0\x1\0\0\0\0\x1h 
\0\0\0\xf8\0\0\x4\xb3\0\0\x3\x61\0\0\x1h\0\0\x1\xe 
\0\0\x4\xb3\0\0\x3\x61\0\0\0\0\0\0)

[ConfigDialog]
Geometry=@ByteArray(\x1\xd9\xd0\xcb\0\x1\0\0\0\0\0\xb9\0\0\0\xcd\0\0\x3 
(\0\0\x3\x16\0\0\0\xb9\0\0\0\xe3\0\0\x3(\0\0\x3\x16\0\0\0\0\0\0)

[HelpBrowser]
Geometry="@ByteArray(\x1\xd9\xd0\xcb\0\x1\0\0\0\0\0,\0\0\0Y\0\0\x2Z 
\0\0\x2(\0\0\0,\0\0\0o\0\0\x2Z\0\0\x2(\0\0\0\0\0\0)"

[Network]
ProxyType=none

[Server]
ExitPolicy=

[Service]
Services=@Invalid()

---












</body></email><email><emailId>20091031045853</emailId><senderName>Darren Thurston</senderName><senderEmail>darren.t.thurston@gmail.com</senderEmail><timestampReceived>2009-10-31 04:58:53-0400</timestampReceived><subject>osx installer ( 0.2.2.5-alpha ) same problems</subject><body>

Just thought I'd try 0.2.2.5-alpha and see if it might work. No luck  
at all either, same problems.

Darren

---
sudo rm -rf /Applications/Vidalia.app/
sudo rm -rf /Library/Torbutton/
sudo rm -rf ~/Library/Vidalia
sudo rm -rf ~/.tor


also removed FireFox


# Installed Firefox 3.5.4

# Installed vidalia package: vidalia-bundle-0.2.2.5-alpha-0.2.5-i386.dmg

#ran the "Install Torbutton for Firefox" script

#Started Vidalia tor start fine and connects to a circuit fine, log  
below:

Oct 30 21:34:21.236 [Notice] Tor v0.2.2.5-alpha  
(git-255245a2891cfa56). This is experimental software. Do not rely on  
it for strong anonymity. (Running on Darwin i386)
Oct 30 21:34:21.238 [Notice] Initialized libevent version 1.4.12- 
stable using method kqueue. Good.
Oct 30 21:34:21.238 [Notice] Opening Socks listener on 127.0.0.1:9050
Oct 30 21:34:21.239 [Notice] Opening Control listener on 127.0.0.1:9051
Oct 30 21:34:22.171 [Notice] We now have enough directory information  
to build circuits.
Oct 30 21:34:22.171 [Notice] Bootstrapped 80%: Connecting to the Tor  
network.
Oct 30 21:34:22.458 [Notice] Bootstrapped 85%: Finishing handshake  
with first hop.
Oct 30 21:34:25.575 [Notice] Bootstrapped 90%: Establishing a Tor  
circuit.
Oct 30 21:34:30.853 [Notice] Tor has successfully opened a circuit.  
Looks like client functionality is working.
Oct 30 21:34:30.855 [Notice] Bootstrapped 100%: Done.

#same as last email no connection same errors in FireFox
---

</body></email><email><emailId>20091031050648</emailId><senderName>Roger Dingledine</senderName><senderEmail>arma@mit.edu</senderEmail><timestampReceived>2009-10-31 05:06:48-0400</timestampReceived><subject>(FWD) Re: osx installer problems on several machines</subject><body>

[Forwarding because Andrew isn't subscribed to the list at the address
he tried to post from. More generally, this thread belongs on or-talk,
not or-dev. -RD]

----- Forwarded message from owner-or-dev@freehaven.net -----

From andrew@torproject.org  Fri Oct 30 23:57:23 2009
Date: Fri, 30 Oct 2009 23:57:23 -0400
From: Andrew Lewman &lt;andrew@torproject.org&gt;
To: or-dev@freehaven.net
Subject: Re: osx installer problems on several machines

On 10/30/2009 11:45 PM, Darren Thurston wrote:
&gt; How do I file a bug report? I ran into this FAIL on two seperate Apple
&gt; machines last night at Tor Night at the VanHackSpace. Tried on a fresh
&gt; install here with same results. I still have not narrowed down what is
&gt; causing the problem, it looks like the browser is not connecting to the
&gt; polipo from what I can tell.

bugs.torproject.org in the future, but the issue appears to be a missing
proxy config option in Vidalia Settings should read

"-c /Applications/Vidalia.app/Contents/Resources/polipo.conf"

In the vidalia.conf file, it's:

ProxyExecutableArguments=-c \
/Applications/Vidalia.app/Contents/Resources/polipo.conf

-- 
Andrew Lewman
The Tor Project
pgp 0x31B0974B

Website: https://torproject.org/
Blog: https://blog.torproject.org/
Identi.ca: torproject

----- End forwarded message -----

</body></email><email><emailId>20091031051144</emailId><senderName>Darren Thurston</senderName><senderEmail>darren.t.thurston@gmail.com</senderEmail><timestampReceived>2009-10-31 05:11:44-0400</timestampReceived><subject>bug tracker</subject><body>

list,

No problem RD. Found the tor and vidalia bug trackers, looks like the  
OSX installer has been broken since at least 9.01.09 ticket #512

d

</body></email><email><emailId>20090911175030</emailId><senderName>Camilo Viecco</senderName><senderEmail>cviecco@anml.iu.edu</senderEmail><timestampReceived>2009-09-11 17:50:30-0400</timestampReceived><subject>Re: Proposal 168: Reduce default circuit window</subject><body>

Hello Karsten

I have to agree with Björn, reducing the circuit window parameter is a
bad idea (we are using a flow control mechanism to try to solve
congestion control).  I believe that Björn's student simulations would
be true. Since most websites nowadays are larger than 50KB the user
experience at the end of the day would be even worse (slower and
burstier experience) but also the network would be internaly bw limited
to about 400 kbps (assuming 125ms between routers and the client and
only taking into account TCP dequeing,) even with infinite bandwidth
between nodes. Assuming some large values for throgput and very small
queues the througput for each circuit is limited to 190-129 kbps
depending on assumptions.

I think that would really reduce the ability to use the Tor network as
default in a daily basis.

Camilo

Assumptions for the values above:
avg RTT between nodes=125ms
avg ckt per node =10
Average throughout of the slowest node in a circuit = 500 KB/s
Window size =50KB
Average Tor queue size= 100KB

Simple table for the Througput limits.
               Latency(s)    Throughput (KB/s)    Througput (kbps)
Just natural     0.375        133.33                1066.67        
*infinite throughput
+TCP queues      1.000        50                     400           
*infinite throughput
+ trasmission    1.100        45.45                  363.64        
-&gt;slowest link is 500KB and only dedicates to the connections!
+ Tor queueing   2.100        23.81                  190.48         -&gt;
as above with queing 100KB on average for the nodes.







Karsten Loesing wrote:
&gt; Hi Björn,
&gt;
&gt; I'm commenting on just a few points here:
&gt;
&gt; On 09/01/2009 01:50 PM, Björn Scheuermann wrote:
&gt; &gt; this sounds like an interesting proposal! However, I'd like to point
&gt; you to
&gt; &gt; some implications and side effects. Over the past months, one of my
&gt; students
&gt; &gt; (Daniel Marks, on CC) has worked on congestion control in Tor. One
&gt; of his
&gt; &gt; results is an implementation of Tor circuits in a network simulation
&gt; framework
&gt; &gt; (ns-2). We use this implementation to simulate Tor networks of
&gt; different size
&gt; &gt; and with different traffic patterns, play with various parameters
&gt; and measure
&gt; &gt; throughput, cell latencies, etc. Currently, our aim is to gain a better
&gt; &gt; understanding of congestion effects in Tor and their implications and
&gt; &gt; interrelations.
&gt;
&gt; Sounds great. Are you planning to release your simulation sources? I'd
&gt; lie when saying that I want to look at the sources now, but I certainly
&gt; would like to play with your simulation at a later point. As may others.
&gt;
&gt; &gt;&gt; 2. Motivation
&gt; &gt;&gt;
&gt; &gt;&gt;   Karsten's torperf graphs show that the median download time for a
&gt; 50KB
&gt; &gt;&gt;   file over Tor in mid 2009 is 7.7 seconds, whereas the median download
&gt; &gt;&gt;   time for 1MB and 5MB are around 50s and 150s respectively. The 7.7
&gt; &gt;&gt;   second figure is way too high, whereas the 50s and 150s figures are
&gt; &gt;&gt;   surprisingly low.
&gt; &gt; Your statement implies that you are looking at something like the
&gt; &gt; "transmission latency per KB" (which is, by the way, identical to
&gt; the inverse
&gt; &gt; throughput).
&gt;
&gt; True, most of the torperf graphs are for measuring bandwidth rather than
&gt; latency. See the PDF reports for more information:
&gt;
&gt; https://git.torproject.org/checkout/metrics/master/report/performance/torperf-2009-08-24.pdf
&gt;
&gt; https://git.torproject.org/checkout/metrics/master/report/circwindow/circwindow-2009-08-19.pdf
&gt;
&gt; The early results of cells in circuit queues might help, too. Note that
&gt; more work remains to make real use of these data. Want to help? :)
&gt;
&gt; https://git.torproject.org/checkout/metrics/master/report/buffer/bufferstats-2009-08-25.pdf
&gt;
&gt; &gt;&gt;   To get a more concrete sense of the benefit, though, Karsten has been
&gt; &gt;&gt;   running torperf side-by-side on exit relays with the old package
&gt; window
&gt; &gt;&gt;   vs the new one. The results are mixed currently -- it is slightly
&gt; faster
&gt; &gt;&gt;   for fetching 40KB files, and slightly slower for fetching 50KB files.
&gt; &gt; Note that file sizes of 40 or 50 KB cannot tell you much about such a
&gt; &gt; modification. As you state above, 100 cells is equivalent to ~50 KB
&gt; of payload.
&gt; &gt; I.e., you do the whole transmission within the initial transfer
&gt; window. So,
&gt; &gt; the data transfer will be over before the circuit's window
&gt; mechanisms have had
&gt; &gt; a chance to become active at all! Consequently, modifications to the
&gt; window
&gt; &gt; mechanism will not impact transfers that are below that threshold
&gt; directly.
&gt;
&gt; The 50 KiB (kibibytes, not kilobytes) download should not fit into one
&gt; circuit window of 101 cells. That circuit window can hold up to 101 x
&gt; 498 = 50298 bytes whereas the file size is 51200 bytes. Due to the
&gt; torperf output, the client receives even 51466 bytes. So, we need a
&gt; second circuit window to transfer the 50 KiB file.
&gt;
&gt; But I admit that 50 KiB is still pretty low. Right now, we have more
&gt; measurements running with 1 MiB files. They just take somewhat longer to
&gt; complete, because we cannot start new downloads in 5-minute intervals,
&gt; but only in 30-minute intervals. At the moment we have 347 data points;
&gt; not enough to make a useful statement. It's going to take another two
&gt; weeks to have enough data.
&gt;
&gt; &gt;&gt;   I think it's going to be tough to get a clear conclusion that this is
&gt; &gt;&gt;   a good design just by comparing one exit relay running the patch. The
&gt; &gt;&gt;   trouble is that the other hops in the circuits are still getting
&gt; bogged
&gt; &gt;&gt;   down by other clients introducing too much traffic into the network.
&gt; &gt; Maybe I'm getting something royally wrong - but what exactly are the
&gt; &gt; mechanisms within an onion router that would result in one circuit
&gt; &gt; experiencing much longer cell queuing delays just because *another*
&gt; circuit
&gt; &gt; has a long queue in that router? In terms of fair resource sharing
&gt; between
&gt; &gt; circuits (and the opportunity to forward cells quickly), our
&gt; impression is
&gt; &gt; that the round-robin scheduler does its job pretty well. It will be
&gt; hard to
&gt; &gt; improve on that just by introducing intentional resource
&gt; underutilization.
&gt; &gt; But you guys know the Tor sources much better than we do - are we
&gt; missing
&gt; &gt; something important here?
&gt;
&gt; The problem of loud circuits slowing down other circuits emerges when
&gt; these circuits are sharing the same TCP connection.
&gt;
&gt; Did you have a look at Joel's and Ian's USENIX paper?
&gt;
&gt; "All traffic between any pair of routers, even if they represent
&gt; circuits for different clients, are multiplexed over a single TCP
&gt; connection. This results in interference across circuits during
&gt; congestion control, packet dropping and packet reordering. This
&gt; interference greatly contributes to Tors notorious latency problems."
&gt;
&gt; See http://crysp.uwaterloo.ca/publications/ for the publication list or
&gt; http://www.cypherpunks.ca/~iang/pubs/TorTP.pdf for the PDF.
&gt;
&gt; Best,
&gt; --Karsten
&gt;

</body></email><email><emailId>20090911223252</emailId><senderName>Pat Duff</senderName><senderEmail>arbortender@gmail.com</senderEmail><timestampReceived>2009-09-11 22:32:52-0400</timestampReceived><subject>unsubscribe</subject><body>

&lt;HTML&gt;&lt;HEAD&gt;&lt;META HTTP-EQUIV='Content-Type' CONTENT='text/html; charset=iso-8859-1'&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;SPAN style='FONT-SIZE: 10pt; FONT-FAMILY: Arial; FONT-WEIGHT:Normal;'&gt;&lt;/SPAN&gt;&lt;/BODY&gt;&lt;/HTML&gt;
</body></email><email><emailId>20091217151220</emailId><senderName>Karsten Loesing</senderName><senderEmail>karsten.loesing@gmx.net</senderEmail><timestampReceived>2009-12-17 15:12:20-0400</timestampReceived><subject>Re: Please help with measuring network statistics on your relay</subject><body>

Hi everyone,

&lt;netiquette-discussion&gt;First off, sorry for top-quoting my own message.
I find it easier for others to have the original context available if
required, though I'm not referring to any specific part of my earlier
message.&lt;/netiquette-discussion&gt;


I'm looking for help by relay operators who are running fast and stable
relays (not only in the sense of the network status flags) and who want
to participate in gathering statistics about the Tor network.

To give you an idea what your statistics are used for, see the graphs here:

  http://metrics.torproject.org/graphs.html

If people want to help gathering statistics on their relays, they'll
need to:

- run Tor 0.2.2.4-alpha or higher,

- enable CellStatistics, DirReqStatistics, EntryStatistics, and/or
ExitStatistics (depending on the statistics to gather), and

- enable ExtraInfoStatistics to include statistics in the extra-info
descriptors that relays upload to the directory authorities (important).

Any further steps, like sending me the contents of files from Tor's data
directory, are NOT required anymore. I'm extracting the relevant lines
from the extra-info descriptor archives (as can everybody else).

For further information see my earlier mail below. The data format has
slightly changed, and the configuration has become much easier.

Thanks,
--Karsten



On 07/21/2009 01:58 AM, Karsten Loesing wrote:
&gt; Hello everyone,
&gt; 
&gt; two months ago, I wrote a blog post describing plans to extend network
&gt; measurements:
&gt; 
&gt; https://blog.torproject.org/blog/performance-measurements-and-blockingresistance-analysis-tor-network
&gt;  
&gt; In brief, this plan includes that: entry guards count the number of
&gt; clients per country per day; relays determine statistics on the number
&gt; of cells waiting in their local queues; exit nodes count the number of
&gt; bytes and streams per exit port per day. All these statistics are
&gt; aggregated, so that none of the network data can be used to de-anonymize
&gt; users. These aggregations include counting users by country, counting
&gt; events per day, and rounding up to a multiple of 4 or 8. We need these
&gt; network data to make Tor faster and/or more useful for circumvention.
&gt; 
&gt; As of today, the necessary code changes to gather these statistics are
&gt; ready, including improved statistics for directory requests that have
&gt; been in the code before. For now, statistics are only written to local
&gt; files and not to extra-info documents. But before changing the
&gt; extra-info document format, I want to be sure that the gathered network
&gt; data are useful.
&gt; 
&gt; The only missing piece is a dozen or more people who configure their
&gt; nodes to gather these statistics for two weeks or longer. During and at
&gt; the end of this time I'll need the new files ending in -stats that
&gt; contain the gathered statistics. Stable and fast nodes are preferred.
&gt; For the exit port statistics we'll need some exit nodes permitting
&gt; exiting to _all_ ports. It doesn't matter for the statistics if a node
&gt; does not permit exiting or doesn't have the Guard flag. If there are no
&gt; results to report, the affected -stats file is omitted.
&gt; 
&gt; If you want to help out with gathering these statistics on your node (or
&gt; just want to know how statistics are measured), please do the following:
&gt; 
&gt; - Run "git clone git://git.torproject.org/git/tor/".
&gt; - Check that you have commit b71bbdc69a56 or later in your branch.
&gt; - Run "./autogen.sh &amp;&amp; ./configure --enable-dirreq-stats
&gt; --enable-entry-stats --enable-buffer-stats --enable-exit-stats &amp;&amp; make".
&gt; - Possibly run "make install", or use the executable in src/or/tor.
&gt; - Add four config options to your torrc: "DirReqStatistics 1",
&gt; "EntryStatistics 1", "CellStatistics 1", "ExitPortStatistics 1"; if you
&gt; only want to gather some of the statistics, only set those config
&gt; options to 1.
&gt; - Add another config option to your torrc, saying where Tor can find
&gt; your GeoIP database; if you cloned the tor repository to ~/tor/, the
&gt; config option would be: "GeoIPFile ~/tor/src/config/geoip".
&gt; - Start your node and look out for notice-level logs saying that your
&gt; node is gathering statistics.
&gt; - Wait for 24 hours for the directory to write files called
&gt; dirreq-stats, entry-stats, cell-stats, and exit-stats to its data
&gt; directory; these files are extended every 24 hours.
&gt; - Make the content of these -stats files available to me once after 24
&gt; hours, after 1 week, and after 2 weeks; I plan to make all files public
&gt; together with their analysis by mid-August.
&gt; - Let me know about some basic bandwidth information of your node:
&gt; fingerprint, configured BandwidthRate, BandwidthBurst, and
&gt; MaxAdvertisedBandwidth if used; also let me know if you are okay with
&gt; being mentioned with your real name in PDFs based on these data.
&gt; 
&gt; Be aware that this code might contain bugs that break your node! You
&gt; should be comfortable running bleeding-edge software versions.
&gt; 
&gt; Here is a brief description what kind of data the four -stats files will
&gt; contain (examples show fewer data and shorter measurement intervals):
&gt; 
&gt; 1. Directory request statistics
&gt; (dirreq-stats file, --enable-dirreq-stats, DirReqStatistics 1)
&gt; 
&gt; written 2009-07-19 18:12:08
&gt; started-at 2009-07-19 17:41:54
&gt; ns-ips ca=8,de=8,hk=8,ir=8,my=8,ro=8,us=8
&gt; ns-v2-ips au=8,ca=8,cn=8,de=8,es=8,gb=8,il=8,it=8,kw=8,ru=8,se=8,us=8
&gt; requests-start 2009-07-19 17:41:54
&gt; n-ns-reqs ca=8,de=8,hk=8,ir=8,my=8,ro=8,us=8
&gt; n-v2-ns-reqs au=8,ca=8,cn=8,de=8,es=8,gb=8,il=8,it=8,kw=8,ru=8,se=8,us=8
&gt; n-ns-resp
&gt; ok=16,not-enough-sigs=0,unavailable=0,not-found=0,not-modified=0,busy=0
&gt; n-v2-ns-resp ok=32,unavailable=0,not-found=8,not-modified=0,busy=0
&gt; v2-ns-share 0.05%
&gt; v3-ns-share 0.05%
&gt; ns-direct-dl complete=0,timeout=0,running=0
&gt; ns-v2-direct-dl
&gt; complete=28,timeout=0,running=0,min=5744,d1=15039,d2=60333,q1=76680,d3=79327,d4=101335,md=120688,d6=137291,d7=180365,q3=198729,d8=209279,d9=272368,max=3198322541
&gt;  ns-tunneled-dl complete=12,timeout=0,running=0
&gt; ns-v2-tunneled-dl complete=0,timeout=0,running=0
&gt; 
&gt; The dirreq-stats file counts the number of directory requests coming
&gt; from clients asking for network statuses. The ns-ips and ns-v2-ips lines
&gt; list the number of unique IPs per country for v3 and v2 statuses,
&gt; n-ns-reqs and n-v2-ns-reqs the number of requests per country. n-ns-resp
&gt; and n-v2-ns-resp list the number of response codes, or rather reasons
&gt; for sending them. v2-ns-share and v3-ns-share are estimates of the share
&gt; of requests that a directory should see. ns-direct-dl and
&gt; ns-v2-direct-dl list the number of complete downloads, timeouts, and
&gt; still running downloads for direct requests. ns-tunneled-dl and
&gt; ns-v2-tunneled-dl show the same numbers for tunneled requests. When
&gt; there are more than 16 complete downloads in the latter four lines,
&gt; statistics are given about the client bandwidths in B/s, including
&gt; minimum/maximum, deciles, quartiles, and median.
&gt; 
&gt; 2. Cell statistics
&gt; (buffer-stats file, --enable-buffer-stats, CellStatistics 1)
&gt; 
&gt; written 2009-07-19 18:11:55 (1800 s)
&gt; processed-cells 350,133,131,130,128,123,110,61,12,2
&gt; queued-cells 1.61,0.15,0.11,0.31,0.06,0.38,0.12,0.00,0.00,0.00
&gt; time-in-queue 3392,585,638,1562,348,1294,145,24,6,117
&gt; number-of-circuits-per-share 45
&gt; 
&gt; The buffer-stats file contains some statistics about the time that cells
&gt; spend in circuit queues. processed-cells are the mean number of total
&gt; processed cells per circuit, with circuits divided by 10 classes from
&gt; loudest to quietest circuits. queued-cells describe the mean number of
&gt; queued cells over time per circuit class. time-in-queue is the mean time
&gt; in milliseconds that a cell spends in a queue.
&gt; number-of-circuits-per-share is the number of circuits per circuit class.
&gt; 
&gt; 3. Entry statistics
&gt; (entry-stats file, --enable-entry-stats, EntryStatistics 1)
&gt; 
&gt; written 2009-07-19 18:12:08
&gt; started-at 2009-07-19 17:41:54
&gt; ips
&gt; de=72,us=72,fr=24,gb=24,it=24,ru=24,cn=16,ir=16,pl=16,??=8,ae=8,ar=8,at=8,az=8,be=8, \
&gt; bg=8,br=8,ca=8,ch=8,co=8,cz=8,es=8,fi=8,gr=8,hk=8,hu=8,id=8,ie=8,il=8,in=8,jp=8,kr=8,kw=8,mx=8,my=8,nl=8,ph=8,qa=8,ro=8,sa=8,se=8,sk=8,tr=8,ua=8,vn=8,ye=8
&gt;  
&gt; The entry-stats file contains the number of connecting clients to an
&gt; entry node per country and 24 hours. These numbers are contained in the
&gt; ips line.
&gt; 
&gt; 4. Exit port statistics
&gt; (exit-stats file, --enable-exit-stats, ExitPortStatistics 1)
&gt; 
&gt; written 2009-07-06 12:32:03 (86400 s)
&gt; kibibytes-written
&gt; 80=784877,443=184575,27619=528,38230=1079,46060=520055,53456=632231,63032=996797,other=13048442
&gt;  kibibytes-read
&gt; 80=19296747,443=394341,27619=505020,38230=1029286,46060=67253,53456=112665,63032=64583,other=11429424
&gt;  streams-opened
&gt; 80=792612,443=43324,27619=4,38230=4,46060=4,53456=4,63032=4,other=244212
&gt; 
&gt; The exit-stats file contains the number of KiB and opened streams per
&gt; exit port per 24 hours. The lines show tuples of the exit port number
&gt; and the number of KiB or opened streams.
&gt; 
&gt; 
&gt; If you have any questions regarding these measurements, or find a bug in
&gt; the measurement code, please let me know, here or off-list!
&gt; 
&gt; Thanks!
&gt; --Karsten


</body></email></emails>