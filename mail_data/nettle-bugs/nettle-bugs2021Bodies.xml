<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20211110193109</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-11-10 19:31:09-0400</timestampReceived><subject>Re: [PATCH] Curve point decompression</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Wim Lewis &lt;wiml@hhhh.org&gt; writes:
&gt;
&gt;&gt; Now that 3.5.1 is out, is there a chance this could be looked at?
&gt; Not sure in which order to do things. Maybe it will be best to first add
&gt; the square root routines, with tests, and then add functions for
&gt; converting between points and octet strings (and related utilities, if
&gt; needed).

I have added sqrt functions on the branch ecc-sqrt (sorry for a forced
update since previous attempt). So this is now on top of the changes to
the inversion improvements from last year. All the secpxxxr1 curves are
supported, but not the gost curves.

Tests pass (I have additional changes to enable randomized tests that
I'd like to commit in a few days), except that sqrt(0) fails for the
secp224 curve, where the implementation uses the full Tonelli-Shanks
algorithm. I'm looking at the algorithm description in Cohen's book (A
course in computational algebraic number theory), and it seems to not
work for this case.

If we need sqrt(0), it must be handled as a special case. Also, unlike
the other square root functions, it seems tricky to make the secp224r1
square root function side-channel silent. But I expect the main use case
of point decompression is for public input (secrets in elliptic curve
crypto tend to be scalars, not points), right?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210104190005</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-01-04 19:00:05-0400</timestampReceived><subject>Compile issue on Solaris 11.3</subject><body>

Hi Everyone,

I bumped to Nettle 3.7. The build is resulting in:

gcc -I. -I/export/home/jwalton/tmp/ok2delete/include -DNDEBUG
-DHAVE_CONFIG_H -g2 -O2 -m64 -march=native -fPIC -pthread -ggdb3 -Wall
-W -Wno-sign-compare   -Wmissing-prototypes -Wmissing-declarations
-Wstrict-prototypes   -Wpointer-arith -Wbad-function-cast
-Wnested-externs -fPIC -MT sha256-compress-2.o -MD -MP -MF
sha256-compress-2.o.d -c sha256-compress-2.s
gcc -I. -I/export/home/jwalton/tmp/ok2delete/include -DNDEBUG
-DHAVE_CONFIG_H -g2 -O2 -m64 -march=native -fPIC -pthread -ggdb3 -Wall
-W -Wno-sign-compare   -Wmissing-prototypes -Wmissing-declarations
-Wstrict-prototypes   -Wpointer-arith -Wbad-function-cast
-Wnested-externs -fPIC -MT sexp.o -MD -MP -MF sexp.o.d -c sexp.c \
&amp;&amp; true
sha256-compress-2.ssha1-compress-2.s: Assembler messages:
sha1-compress-2.s:73: Error: : no such instruction: `sha1rnds4
$0,%xmm5,%xmm4'Assembler messages:
sha256-compress-2.s:87
: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha1-compress-2.s:78sha256-compress-2.s: Error: no such instruction:
`sha1nexte %xmm1,%xmm6':89
: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'sha1-compress-2.s:80
: Error: no such instruction: `sha1rnds4 $0,%xmm6,%xmm4'
sha256-compress-2.ssha1-compress-2.s:96:81: Error: : Error: no such
instruction: `sha1msg1 %xmm1,%xmm0'no such instruction: `sha256rnds2
%xmm5,%xmm6'

sha1-compress-2.s:86sha256-compress-2.s: Error: :98no such
instruction: `sha1nexte %xmm2,%xmm5'
: Error: sha1-compress-2.s:88: no such instruction: `sha256rnds2
%xmm6,%xmm5'Error:
sha256-compress-2.sno such instruction: `sha1rnds4 $0,%xmm5,%xmm4':99
: Error: sha1-compress-2.sno such instruction: `sha256msg1 %xmm2,%xmm1'
:89: Error: no such instruction: `sha1msg1 %xmm2,%xmm1'
sha256-compress-2.s:106: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha1-compress-2.s:96sha256-compress-2.s: Error: no such instruction:
`sha1nexte %xmm3,%xmm6'
:108sha1-compress-2.s:98: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5':
Error: no such instruction: `sha1msg2 %xmm3,%xmm0'
sha256-compress-2.ssha1-compress-2.s:109:99: : Error: Error: no such
instruction: `sha1rnds4 $0,%xmm6,%xmm4'no such instruction:
`sha256msg1 %xmm3,%xmm2'

sha256-compress-2.s:117: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:119: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:123: Error: no such instruction: `sha256msg2 %xmm4,%xmm1'
sha256-compress-2.s:124: sha1-compress-2.sError: no such instruction:
`sha256msg1 %xmm4,%xmm3'
:100: Error: sha256-compress-2.sno such instruction: `sha1msg1 %xmm3,%xmm2'
:129: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha1-compress-2.s:104: Error: no such instruction: `sha1nexte
%xmm0,%xmm5'sha256-compress-2.s:131: Error:
no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha1-compress-2.s:106sha256-compress-2.s: :135: Error: Error: no such
instruction: `sha1msg2 %xmm0,%xmm1'no such instruction: `sha256msg2
%xmm1,%xmm2'

sha256-compress-2.ssha1-compress-2.s:107:136: : Error: no such
instruction: `sha256msg1 %xmm1,%xmm4'
Error: no such instruction: `sha1rnds4 $0,%xmm5,%xmm4'sha256-compress-2.s
:141: sha1-compress-2.sError: no such instruction: `sha256rnds2 %xmm5,%xmm6'
:108: sha256-compress-2.sError: no such instruction: `sha1msg1 %xmm0,%xmm3':143:
Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha1-compress-2.s:113: Error: sha256-compress-2.s:147: Error: no such
instruction: `sha1nexte %xmm1,%xmm6'no such instruction: `sha256msg2
%xmm2,%xmm3'

sha256-compress-2.ssha1-compress-2.s:148:115: Error: : no such
instruction: `sha256msg1 %xmm2,%xmm1'
Error: sha256-compress-2.sno such instruction: `sha1msg2 %xmm1,%xmm2':153:
Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.ssha1-compress-2.s:155: Error: :116: no such
instruction: `sha256rnds2 %xmm6,%xmm5'
Error: no such instruction: `sha1rnds4 $1,%xmm6,%xmm4'
sha1-compress-2.s:117: Error: sha256-compress-2.sno such instruction:
`sha1msg1 %xmm1,%xmm0':159: Error:
no such instruction: `sha256msg2 %xmm3,%xmm4'
sha256-compress-2.s:160sha1-compress-2.s: Error: no such instruction:
`sha256msg1 %xmm3,%xmm2'
:121: Error: no such instruction: `sha1nexte %xmm2,%xmm5'sha256-compress-2.s
:165: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha1-compress-2.ssha256-compress-2.s:123: Error: no such instruction:
`sha1msg2 %xmm2,%xmm3'
sha1-compress-2.s:167: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5':124
: Error: no such instruction: `sha1rnds4 $1,%xmm5,%xmm4'
sha256-compress-2.ssha1-compress-2.s:125:171: : Error: no such
instruction: `sha256msg2 %xmm4,%xmm1'Error: no such instruction:
`sha1msg1 %xmm2,%xmm1'

sha256-compress-2.s:172: Error: sha1-compress-2.s:129no such
instruction: `sha256msg1 %xmm4,%xmm3'
: Error: no such instruction: `sha1nexte %xmm3,%xmm6'sha256-compress-2.s
:177: sha1-compress-2.sError: no such instruction: `sha256rnds2 %xmm5,%xmm6'
:131: Error: sha256-compress-2.sno such instruction: `sha1msg2 %xmm3,%xmm0':179
: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'sha1-compress-2.s
:132: Error: no such instruction: `sha1rnds4 $1,%xmm6,%xmm4'
sha256-compress-2.s:183: Error: sha1-compress-2.s:133no such
instruction: `sha256msg2 %xmm1,%xmm2'
: sha256-compress-2.sError: :184no such instruction: `sha1msg1 %xmm3,%xmm2'
: Error: no such instruction: `sha256msg1 %xmm1,%xmm4'
sha1-compress-2.s:137: Error: no such instruction: `sha1nexte %xmm0,%xmm5'
sha1-compress-2.s:139: sha256-compress-2.sError: no such instruction:
`sha1msg2 %xmm0,%xmm1':189:
Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha1-compress-2.s:140sha256-compress-2.s:191: : Error: no such
instruction: `sha256rnds2 %xmm6,%xmm5'Error: no such instruction:
`sha1rnds4 $1,%xmm5,%xmm4'

sha1-compress-2.ssha256-compress-2.s:141: :195: Error: Error: no such
instruction: `sha1msg1 %xmm0,%xmm3'no such instruction: `sha256msg2
%xmm2,%xmm3'

sha256-compress-2.s:196sha1-compress-2.s:145: : Error: no such
instruction: `sha256msg1 %xmm2,%xmm1'
Error: no such instruction: `sha1nexte %xmm1,%xmm6'
sha256-compress-2.s:201: Error: no such instruction: `sha256rnds2
%xmm5,%xmm6'sha1-compress-2.s:147
: Error: sha256-compress-2.s:203: Error: no such instruction:
`sha1msg2 %xmm1,%xmm2'no such instruction: `sha256rnds2 %xmm6,%xmm5'

sha256-compress-2.ssha1-compress-2.s:148:207: : Error: Error: no such
instruction: `sha256msg2 %xmm3,%xmm4'
sha256-compress-2.s:208: Error: no such instruction: `sha256msg1 %xmm3,%xmm2'
sha256-compress-2.s:213: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:215: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:219: Error: no such instruction: `sha256msg2 %xmm4,%xmm1'
sha256-compress-2.s:220: Error: no such instruction: `sha256msg1 %xmm4,%xmm3'
sha256-compress-2.s:225: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:227: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:231: Error: no such instruction: `sha256msg2 %xmm1,%xmm2'
sha256-compress-2.s:232: Error: no such instruction: `sha256msg1 %xmm1,%xmm4'
sha256-compress-2.s:237: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:239: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:243: Error: no such instruction: `sha256msg2 %xmm2,%xmm3'
sha256-compress-2.s:247: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:249: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:253: Error: no such instruction: `sha256msg2 %xmm3,%xmm4'
sha256-compress-2.s:257: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:259: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
no such instruction: `sha1rnds4 $1,%xmm6,%xmm4'
sha1-compress-2.s:149: Error: no such instruction: `sha1msg1 %xmm1,%xmm0'
sha1-compress-2.s:154: Error: no such instruction: `sha1nexte %xmm2,%xmm5'
sha1-compress-2.s:156: Error: no such instruction: `sha1msg2 %xmm2,%xmm3'
sha1-compress-2.s:157: Error: no such instruction: `sha1rnds4 $2,%xmm5,%xmm4'
sha1-compress-2.s:158: Error: no such instruction: `sha1msg1 %xmm2,%xmm1'
sha1-compress-2.s:162: Error: no such instruction: `sha1nexte %xmm3,%xmm6'
sha1-compress-2.s:164: Error: no such instruction: `sha1msg2 %xmm3,%xmm0'
sha1-compress-2.s:165: Error: no such instruction: `sha1rnds4 $2,%xmm6,%xmm4'
sha1-compress-2.s:166: Error: no such instruction: `sha1msg1 %xmm3,%xmm2'
sha1-compress-2.s:170: Error: no such instruction: `sha1nexte %xmm0,%xmm5'
sha1-compress-2.s:172: Error: no such instruction: `sha1msg2 %xmm0,%xmm1'
sha1-compress-2.s:173: Error: no such instruction: `sha1rnds4 $2,%xmm5,%xmm4'
sha1-compress-2.s:174: Error: no such instruction: `sha1msg1 %xmm0,%xmm3'
sha1-compress-2.s:178: Error: no such instruction: `sha1nexte %xmm1,%xmm6'
sha1-compress-2.s:180: Error: no such instruction: `sha1msg2 %xmm1,%xmm2'
sha1-compress-2.s:181: Error: no such instruction: `sha1rnds4 $2,%xmm6,%xmm4'
sha1-compress-2.s:182: Error: no such instruction: `sha1msg1 %xmm1,%xmm0'
sha1-compress-2.s:186: Error: no such instruction: `sha1nexte %xmm2,%xmm5'
sha1-compress-2.s:188: Error: no such instruction: `sha1msg2 %xmm2,%xmm3'
sha1-compress-2.s:189: Error: no such instruction: `sha1rnds4 $2,%xmm5,%xmm4'
sha1-compress-2.s:190: Error: no such instruction: `sha1msg1 %xmm2,%xmm1'
sha1-compress-2.s:195: Error: no such instruction: `sha1nexte %xmm3,%xmm6'
sha1-compress-2.s:197: Error: no such instruction: `sha1msg2 %xmm3,%xmm0'
sha1-compress-2.s:198: Error: no such instruction: `sha1rnds4 $3,%xmm6,%xmm4'
sha1-compress-2.s:199: Error: no such instruction: `sha1msg1 %xmm3,%xmm2'
sha1-compress-2.s:203: Error: no such instruction: `sha1nexte %xmm0,%xmm5'
sha1-compress-2.s:205: Error: no such instruction: `sha1msg2 %xmm0,%xmm1'
sha1-compress-2.s:206: Error: no such instruction: `sha1rnds4 $3,%xmm5,%xmm4'
sha1-compress-2.s:207: Error: no such instruction: `sha1msg1 %xmm0,%xmm3'
sha1-compress-2.s:211: Error: no such instruction: `sha1nexte %xmm1,%xmm6'
sha1-compress-2.s:213: Error: no such instruction: `sha1msg2 %xmm1,%xmm2'
sha1-compress-2.s:214: Error: no such instruction: `sha1rnds4 $3,%xmm6,%xmm4'
sha1-compress-2.s:217: Error: no such instruction: `sha1nexte %xmm2,%xmm5'
sha1-compress-2.s:219: Error: no such instruction: `sha1msg2 %xmm2,%xmm3'
sha1-compress-2.s:220: Error: no such instruction: `sha1rnds4 $3,%xmm5,%xmm4'
sha1-compress-2.s:222: Error: no such instruction: `sha1nexte %xmm3,%xmm6'
sha1-compress-2.s:224: Error: no such instruction: `sha1rnds4 $3,%xmm6,%xmm4'
sha1-compress-2.s:226: Error: no such instruction: `sha1nexte %xmm8,%xmm5'
gmake[1]: *** [sha1-compress-2.o] Error 1
gmake[1]: *** Waiting for unfinished jobs....

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210201014338</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-01 01:43:38-0400</timestampReceived><subject>Add pbkdf2_hmac_sha384 and pbkdf2_hmac_sha512 to Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I just opened a merge request [1] to add pbkdf2_hmac_sha384 and 
pbkdf2_hmac_sha512 to the Nettle library.

These pbkdf2 functions are required to implement pbes2-* key management 
algorithms defined in the JSON Web Encryption (JWE) and JSON Web 
Algorithms (JWA) specifications [2], [3].

I added the new pbkdf2 functions, one test case per function, based on 
the same key derivation as the pbkdf2_hmac_sha256 test case. I also 
updated the documentation.

Is it possible to get a code review for this patch?

Thanks in advance

/Nicolas

[1] https://git.lysator.liu.se/nettle/nettle/-/merge_requests/18
[2] https://tools.ietf.org/html/rfc7516
[3] https://tools.ietf.org/html/rfc7518

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210225081435</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-25 08:14:35-0400</timestampReceived><subject>Status update</subject><body>

I've haven't had much hacking time since the 3.7.1 bug fix rel1ease. I'm
aware of the following recent issues that need review/work:

1. New Arm64 code (don't recall current status off the top of my head).

2. s390x testing. I'd prefer to not run a git checkout on the s390x test
   machine, but have the ci job make a tarball, ssh it over to the test
   machine, unpack in a fresh directory for build and test. This needs
   to be in place before adding s390x specific code. When done, could
   likely be reused for remote testing on any other platforms of
   interest, which aren't directly available in the ci system.

3. AES-keywrap merge request,
   https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19

4. RSA-OAEP merge request. I intend to attend to (3) first, and will not
   pay much attention to this one at the moment. If anyone else would
   like to help out with review, maybe have alook at this one?
   https://git.lysator.liu.se/nettle/nettle/-/merge_requests/20 

Anything else? There are other projects that's been on hold for a while,
e.g., support for compact representation (aka "point compression") on
the NIST curves, that I don't give high priority at the moment.

I often get some hacking time on Wednesdays and weekends, but not every
week.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061511</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:11-0400</timestampReceived><subject>[RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

Hi!

This series introduces a mechanism to support arch specific, combined AES+GCM
{en,de}cryption functions. These functions are stubbed by default and will
fall-back to the separate hash and crypt functions if no arch override exists.
The arch override can be provided either at build time via appropriate config
options or using the FAT runtime mechanism.

An implementation combining AES+GCM _can potentially_ yield significant
performance boosts by allowing for increased instruction parallelism, avoiding
C-function call overhead, more flexibility in assembly fine-tuning, etc. This
series provides such an implementation based on the existing optimized Nettle
routines for POWER9 and later processors. Benchmark results on a POWER9
Blackbird running at 3.5GHz are given at the end of this mail. Both builds were
configured statically ie. not FAT. FAT performance is slightly lower for both
but shows similar gains with this series. The OpenSSL build is based on latest
OpenSSL master with all PowerPC optimizations enabled.

Note that the gains on an early POWER10 system are even more impressive but
unfortunately I cannot share those results publically yet :(

AES+GCM combined (this series)
------------------------------
         Algorithm         mode Mbyte/s

        gcm_aes128      encrypt 2567.62
        gcm_aes128      decrypt 2582.32
        gcm_aes128       update 7724.15

        gcm_aes192      encrypt 2279.39
        gcm_aes192      decrypt 2293.20
        gcm_aes192       update 7724.41

        gcm_aes256      encrypt 2054.09
        gcm_aes256      decrypt 2061.25
        gcm_aes256       update 7724.04

openssl gcm_aes128      encrypt 2336.93
openssl gcm_aes128      decrypt 2337.95
openssl gcm_aes128       update 6248.22

openssl gcm_aes192      encrypt 2113.93
openssl gcm_aes192      decrypt 2114.93
openssl gcm_aes192       update 6210.65

openssl gcm_aes256      encrypt 1936.95
openssl gcm_aes256      decrypt 1935.88
openssl gcm_aes256       update 6208.72

AES,GCM separate (nettle master)
--------------------------------
         Algorithm         mode Mbyte/s

        gcm_aes128      encrypt 1418.66
        gcm_aes128      decrypt 1418.97
        gcm_aes128       update 7766.31

        gcm_aes192      encrypt 1314.03
        gcm_aes192      decrypt 1313.17
        gcm_aes192       update 7760.23

        gcm_aes256      encrypt 1218.75
        gcm_aes256      decrypt 1218.64
        gcm_aes256       update 7760.52

openssl gcm_aes128      encrypt 2324.70
openssl gcm_aes128      decrypt 2317.19
openssl gcm_aes128       update 6152.77

openssl gcm_aes192      encrypt 2102.99
openssl gcm_aes192      decrypt 2098.98
openssl gcm_aes192       update 6175.62

openssl gcm_aes256      encrypt 1925.85
openssl gcm_aes256      decrypt 1922.49
openssl gcm_aes256       update 6204.55

Christopher M. Riedl (6):
  gcm: Introduce gcm_aes_{de,en}crypt()
  ppc: Fix variable name for --enable-power-altivec
  ppc: Add FAT feature and config option for ISA 3.0
  ppc: Add gcm_aes_encrypt() asm for ISA 3.0 (P9)
  ppc: Add gcm_aes_decrypt() asm for ISA 3.0 (P9)
  ppc: Enable gcm_aes_{de,en}crypt() FAT

 configure.ac                      |  19 +-
 fat-ppc.c                         |  45 ++
 fat-setup.h                       |   6 +
 gcm-internal.h                    |  14 +
 gcm.c                             | 151 ++++++-
 powerpc64/fat/gcm-aes-decrypt.asm |  37 ++
 powerpc64/fat/gcm-aes-encrypt.asm |  37 ++
 powerpc64/p9/gcm-aes-decrypt.asm  | 663 +++++++++++++++++++++++++++++
 powerpc64/p9/gcm-aes-encrypt.asm  | 666 ++++++++++++++++++++++++++++++
 9 files changed, 1630 insertions(+), 8 deletions(-)
 create mode 100644 powerpc64/fat/gcm-aes-decrypt.asm
 create mode 100644 powerpc64/fat/gcm-aes-encrypt.asm
 create mode 100644 powerpc64/p9/gcm-aes-decrypt.asm
 create mode 100644 powerpc64/p9/gcm-aes-encrypt.asm

-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210509081950</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-09 08:19:50-0400</timestampReceived><subject>S390x other modes and memxor (was: Re: [S390x] Optimize AES modes)</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Sat, May 1, 2021 at 6:11 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Is https://git.lysator.liu.se/nettle/nettle/-/merge_requests/23 still
&gt;&gt; the current code?
&gt;&gt;
&gt;
&gt; I've added the basic AES-192 and AES-256 too since there is no problem to
&gt; test them all together.

Merged to the s390x branch now. Thanks for your patience.

For further improvement, it would be nice to have aesN_set_encrypt_key
and aesN_set_decrypt_key be two entrypoints to the same function. But
will make the file replacement logic a bit more complex.

And maybe the public aes*_invert_key functions should be marked
as deprecated (and deleted, next time we have an abi break)? No other
ciphers in Nettle have this feature, and it's not that useful for
applications. From codesearch.debian.net, it looks like they are exposed
by the haskell and rust bindings, though.

&gt; For the other the modes, 

Before doing the other modes, do you think you could investigate if
memxor and memxor3 can be sped up? That should benefit many ciphers
and modes, and give more relevant speedup numbers for specialized
functions like aes cbc and aes ctr.

The best strategy depends on whether or not unaligned memory access is
possible and efficient. All current implementations do aligned writes to
the destination area (and smaller writes if needed at the edges). For the
C implementation and several of the asm implementations, they also do
aligned reads, and use shifting to get inputs xored together at the right
places. 

While the x86_64 implementation uses unaligned reads, since that seems
as efficient, and reduces complexity quite a lot.

On all platforms I'm familiar with, assembly implementations can assume
that it is safe to read a few bytes outside the edge of the input
buffer, as long as those reads don't cross a word boundary
(corresponding to valgrind option --partial-loads-ok=yes).

Ideally, memxor performance should be limited by memory/cache bandwidth
(with data in L1 cache probably being the most important case. It looks
like nettle-benchmark calls it with a size of 10 KB).

Note that memxor3 must process data in descending address order, to
support the call from cbc_decrypt, with overlapping operands.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210514054533</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-14 05:45:33-0400</timestampReceived><subject>[Aarch64] Optimize SHA1 Compress</subject><body>

This patch optimizes SHA1 compress function for arm64 architecture by
taking advantage of SHA-1 instructions of Armv8 crypto extension.
The SHA-1 instructions:
SHA1C: SHA1 hash update (choose)
SHA1H: SHA1 fixed rotate
SHA1M: SHA1 hash update (majority)
SHA1P: SHA1 hash update (parity)
SHA1SU0: SHA1 schedule update 0
SHA1SU1: SHA1 schedule update 1

The patch is based on sha1-arm.c - ARMv8 SHA extensions using C intrinsics
of repository https://github.com/noloader/SHA-Intrinsics by Jeffrey Walton.

The patch passes the testsuite of nettle library and the benchmark numbers
are considerably improved but the performance of the overall sha1 hash
function doesn't surpass the corresponding openssl numbers.

Benchmark on gcc117 instance of CFarm before applying the patch:
         Algorithm         mode        Mbyte/s
         sha1               update       214.16
         openssl sha1  update       849.44
         hmac-sha1     64 bytes     61.69
         hmac-sha1     256 bytes   131.50
         hmac-sha1    1024 bytes  185.20
         hmac-sha1    4096 bytes  204.55
         hmac-sha1    single msg  210.97

Benchmark on gcc117 instance of CFarm after applying the patch:
         Algorithm         mode        Mbyte/s
         sha1                update       795.57
         openssl sha1   update       849.25
         hmac-sha1      64 bytes    167.65
         hmac-sha1      256 bytes   408.24
         hmac-sha1     1024 bytes  636.68
         hmac-sha1     4096 bytes  739.42
         hmac-sha1     single msg  775.89

---
 arm64/crypto/sha1-compress.asm | 245
+++++++++++++++++++++++++++++++++++++++++
 arm64/machine.m4               |   7 ++
 2 files changed, 252 insertions(+)
 create mode 100644 arm64/crypto/sha1-compress.asm

diff --git a/arm64/crypto/sha1-compress.asm b/arm64/crypto/sha1-compress.asm
new file mode 100644
index 00000000..bb3f1d35
--- /dev/null
+++ b/arm64/crypto/sha1-compress.asm
@@ -0,0 +1,245 @@
+C arm64/crypto/sha1-compress.asm
+
+ifelse(`
+   Copyright (C) 2021 Mamone Tarsha
+
+   Based on sha1-arm.c - ARMv8 SHA extensions using C intrinsics of
+   repository https://github.com/noloader/SHA-Intrinsics
+   sha1-arm.c is written and placed in public domain by Jeffrey Walton,
+   based on code from ARM, and by Johannes Schneiders, Skip
+   Hovsmith and Barry O'Rourke for the mbedTLS project.
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+.file "sha1-compress.asm"
+.arch armv8-a+crypto
+
+.text
+
+C Register usage:
+
+define(`STATE', `x0')
+define(`INPUT', `x1')
+
+define(`CONST0', `v0')
+define(`CONST1', `v1')
+define(`CONST2', `v2')
+define(`CONST3', `v3')
+define(`MSG0', `v4')
+define(`MSG1', `v5')
+define(`MSG2', `v6')
+define(`MSG3', `v7')
+define(`ABCD', `v16')
+define(`ABCD_SAVED', `v17')
+define(`E0', `v18')
+define(`E0_SAVED', `v19')
+define(`E1', `v20')
+define(`TMP0', `v21')
+define(`TMP1', `v22')
+
+C void nettle_sha1_compress(uint32_t *state, const uint8_t *input)
+
+PROLOGUE(nettle_sha1_compress)
+    C Initialize constants
+    mov            w2,#0x7999
+    movk           w2,#0x5A82,lsl #16
+    dup            CONST0.4s,w2
+    mov            w2,#0xEBA1
+    movk           w2,#0x6ED9,lsl #16
+    dup            CONST1.4s,w2
+    mov            w2,#0xBCDC
+    movk           w2,#0x8F1B,lsl #16
+    dup            CONST2.4s,w2
+    mov            w2,#0xC1D6
+    movk           w2,#0xCA62,lsl #16
+    dup            CONST3.4s,w2
+
+    C Load state
+    add            x2,STATE,#16
+    movi           E0.4s,#0
+    ld1            {ABCD.4s},[STATE]
+    ld1            {E0.s}[0],[x2]
+
+    C Save state
+    mov            ABCD_SAVED.16b,ABCD.16b
+    mov            E0_SAVED.16b,E0.16b
+
+    C Load message
+    ld1            {MSG0.16b,MSG1.16b,MSG2.16b,MSG3.16b},[INPUT]
+
+    C Reverse for little endian
+    rev32          MSG0.16b,MSG0.16b
+    rev32          MSG1.16b,MSG1.16b
+    rev32          MSG2.16b,MSG2.16b
+    rev32          MSG3.16b,MSG3.16b
+
+    add            TMP0.4s,MSG0.4s,CONST0.4s
+    add            TMP1.4s,MSG1.4s,CONST0.4s
+
+    C Rounds 0-3
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG2.4s,CONST0.4s
+    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
+
+    C Rounds 4-7
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG3.4s,CONST0.4s
+    sha1su1        MSG0.4s,MSG3.4s
+    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
+
+    C Rounds 8-11
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG0.4s,CONST0.4s
+    sha1su1        MSG1.4s,MSG0.4s
+    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
+
+    C Rounds 12-15
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG1.4s,CONST1.4s
+    sha1su1        MSG2.4s,MSG1.4s
+    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
+
+    C Rounds 16-19
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG2.4s,CONST1.4s
+    sha1su1        MSG3.4s,MSG2.4s
+    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
+
+    C Rounds 20-23
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG3.4s,CONST1.4s
+    sha1su1        MSG0.4s,MSG3.4s
+    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
+
+    C Rounds 24-27
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG0.4s,CONST1.4s
+    sha1su1        MSG1.4s,MSG0.4s
+    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
+
+    C Rounds 28-31
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG1.4s,CONST1.4s
+    sha1su1        MSG2.4s,MSG1.4s
+    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
+
+    C Rounds 32-35
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG2.4s,CONST2.4s
+    sha1su1        MSG3.4s,MSG2.4s
+    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
+
+    C Rounds 36-39
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG3.4s,CONST2.4s
+    sha1su1        MSG0.4s,MSG3.4s
+    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
+
+    C Rounds 40-43
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG0.4s,CONST2.4s
+    sha1su1        MSG1.4s,MSG0.4s
+    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
+
+    C Rounds 44-47
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG1.4s,CONST2.4s
+    sha1su1        MSG2.4s,MSG1.4s
+    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
+
+    C Rounds 48-51
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG2.4s,CONST2.4s
+    sha1su1        MSG3.4s,MSG2.4s
+    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
+
+    C Rounds 52-55
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG3.4s,CONST3.4s
+    sha1su1        MSG0.4s,MSG3.4s
+    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
+
+    C Rounds 56-59
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG0.4s,CONST3.4s
+    sha1su1        MSG1.4s,MSG0.4s
+    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
+
+    C Rounds 60-63
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG1.4s,CONST3.4s
+    sha1su1        MSG2.4s,MSG1.4s
+    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
+
+    C Rounds 64-67
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
+    add            TMP0.4s,MSG2.4s,CONST3.4s
+    sha1su1        MSG3.4s,MSG2.4s
+    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
+
+    C Rounds 68-71
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    add            TMP1.4s,MSG3.4s,CONST3.4s
+    sha1su1        MSG0.4s,MSG3.4s
+
+    C Rounds 72-75
+    sha1h          SFP(E1),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
+
+    C Rounds 76-79
+    sha1h          SFP(E0),SFP(ABCD)
+    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+
+    C Combine state
+    add            E0.4s,E0.4s,E0_SAVED.4s
+    add            ABCD.4s,ABCD.4s,ABCD_SAVED.4s
+
+    C Store state
+    st1            {ABCD.4s},[STATE]
+    st1            {E0.s}[0],[x2]
+
+    ret
+EPILOGUE(nettle_sha1_compress)
diff --git a/arm64/machine.m4 b/arm64/machine.m4
index e69de29b..7df62bcc 100644
--- a/arm64/machine.m4
+++ b/arm64/machine.m4
@@ -0,0 +1,7 @@
+C Get 32-bit floating-point register from vector register
+C SFP(VR)
+define(`SFP',``s'substr($1,1,len($1))')
+
+C Get 128-bit floating-point register from vector register
+C QFP(VR)
+define(`QFP',``q'substr($1,1,len($1))')

-- 
2.25.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210701134151</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-01 13:41:51-0400</timestampReceived><subject>[AArch64] Optimize SHA-256 compress</subject><body>

I made a merge request !28
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/28&gt; to the
'arm64-sha1' branch that optimizes SHA-256 compress function, I've added a
brief description of the patch in addition to benchmark numbers in the MR
description. A patch for fat build support will be followed in another
merge request.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210810141300</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-08-10 14:13:00-0400</timestampReceived><subject>Is there an equivalent to curve25519_mul for ECC keys?</subject><body>

Hello,

I'm wondering if there is a function of a combination of functions to perform a DH \
computation using ECC keys and their parameters "struct ecc_point *pub1, struct \
ecc_scalar *key2"?

/Nicolas
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210902174750</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-02 17:47:50-0400</timestampReceived><subject>Reorganization of x86_64 aesni code</subject><body>

I've merged a reorganization of the x86_64 aesni code to the
master-updates branch for testing. This replaces the
x86_64/aesni/aes-*crypt-internal.asm files with separate files for the
different key sizes, as has been discussed earlier.

And I've implemented 2-way interleaving, i.e., doing 2 blocks at a time,
which gave a nice speedup on the order of 15% in my tests. I may be
worthwhile to go to 3-way or 4-way, but I don't plan to try that soon.

Regards,
/Niels
-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211021095031</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-10-21 09:50:31-0400</timestampReceived><subject>[S390x] Optimize SHA3 permute using vector facility</subject><body>

I've added a new patch that optimizes SHA3 permute function for S390x
architecture https://git.lysator.liu.se/nettle/nettle/-/merge_requests/36
More about the patch in merge request description.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211124074058</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-24 07:40:58-0400</timestampReceived><subject>[PATCH 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Add OSCCA SM3 secure hash generic hash algorithm, described
in OSCCA GM/T 0004-2012 SM3. 

Tianjia Zhang (4):
  Add OSCCA SM3 hash algorithm
  testsuite: add test for SM3 hash function
  hmac: add support for SM3 hash function
  nettle-benchmark: bench SM3 hashes

 Makefile.in                 |   7 +-
 examples/nettle-benchmark.c |   2 +-
 hmac-sm3-meta.c             |  47 +++++++
 hmac-sm3.c                  |  59 +++++++++
 hmac.h                      |  19 +++
 nettle-meta-hashes.c        |   1 +
 nettle-meta-macs.c          |   1 +
 nettle-meta.h               |   2 +
 sm3-meta.c                  |  41 ++++++
 sm3.c                       | 250 ++++++++++++++++++++++++++++++++++++
 sm3.h                       |  81 ++++++++++++
 testsuite/.gitignore        |   1 +
 testsuite/Makefile.in       |   2 +-
 testsuite/hmac-test.c       |   6 +
 testsuite/meta-hash-test.c  |   3 +-
 testsuite/meta-mac-test.c   |   1 +
 testsuite/sm3-test.c        |  20 +++
 17 files changed, 537 insertions(+), 6 deletions(-)
 create mode 100644 hmac-sm3-meta.c
 create mode 100644 hmac-sm3.c
 create mode 100644 sm3-meta.c
 create mode 100644 sm3.c
 create mode 100644 sm3.h
 create mode 100644 testsuite/sm3-test.c

-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125160415</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-11-25 16:04:15-0400</timestampReceived><subject>Re: [PATCH 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:

&gt; Add OSCCA SM3 secure hash generic hash algorithm, described
&gt; in OSCCA GM/T 0004-2012 SM3. 

Thanks, I've had a first quick look, and it looks nice. I don't know
much about this hash function, though. A few questions:

* Is there some reasonably authoritative English reference for the
  algorithm? I checked wikipedia, and it only links to an old internet
  draft, https://tools.ietf.org/id/draft-oscca-cfrg-sm3-02.html

* The name "sm3" is a bit short, would it make sense to add some
  family-prefix, maybe "oscca_sm3"? 
 
* Do you have some examples of protocols or applications that specify
  the use of sm3?

* The implementation, it's written from scratch, or is it based on some
  reference implementation?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211201194017</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-01 19:40:17-0400</timestampReceived><subject>Re: [PATCH v2 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:

&gt; Add OSCCA SM3 secure hash (OSCCA GM/T 0004-2012 SM3) generic
&gt; hash transformation.

Thanks, merged the patch series onto a branch "sm3" for testing, with
only minor changes.

&gt; --- /dev/null
&gt; +++ b/sm3.h
[...]
&gt; +#define SM3_DIGEST_SIZE 32
&gt; +#define SM3_BLOCK_SIZE 64
&gt; +/* For backwards compatibility */
&gt; +#define SM3_DATA_SIZE SM3_BLOCK_SIZE

I dropped the definition of SM3_DATA_SIZE, since this is a new feature
in Nettle, there's no old version to be compatible with.

Would you mind writing a short description of the algorithm for the
manual? I think it should go under "Miscellaneous hash functions". Would
be nice with some brief background on this hash function (origin,
intended applications, when and where it's useful) plus reference docs
for the defined constants and functions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211202092314</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-02 09:23:14-0400</timestampReceived><subject>Re: [PATCH v2 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Hi Niels,

On 12/2/21 3:40 AM, Niels Möller wrote:
&gt; Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:
&gt; 
&gt;&gt; Add OSCCA SM3 secure hash (OSCCA GM/T 0004-2012 SM3) generic
&gt;&gt; hash transformation.
&gt; 
&gt; Thanks, merged the patch series onto a branch "sm3" for testing, with
&gt; only minor changes.
&gt; 
&gt;&gt; --- /dev/null
&gt;&gt; +++ b/sm3.h
&gt; [...]
&gt;&gt; +#define SM3_DIGEST_SIZE 32
&gt;&gt; +#define SM3_BLOCK_SIZE 64
&gt;&gt; +/* For backwards compatibility */
&gt;&gt; +#define SM3_DATA_SIZE SM3_BLOCK_SIZE
&gt; 
&gt; I dropped the definition of SM3_DATA_SIZE, since this is a new feature
&gt; in Nettle, there's no old version to be compatible with.

Thanks for pointing it out.

&gt; 
&gt; Would you mind writing a short description of the algorithm for the
&gt; manual? I think it should go under "Miscellaneous hash functions". Would
&gt; be nice with some brief background on this hash function (origin,
&gt; intended applications, when and where it's useful) plus reference docs
&gt; for the defined constants and functions.
&gt; 

SM3 is a cryptographic hash function standard adopted by the government 
of the People's Republic of China, which was issued by the Cryptography 
Standardization Technical Committee of China on December 17, 2010. The 
corresponding standard is "GM/T 0004-2012 "SM3 Cryptographic Hash 
Algorithm"".

SM3 algorithm is a hash algorithm in ShangMi cryptosystems. SM3 is 
mainly used for digital signature and verification, message 
authentication code generation and verification, random number 
generation, etc. Its algorithm is public. Combined with the public key 
algorithm SM2 and the symmetric encryption algorithm SM4, it can be used 
in various data security and network security scenarios such as the TLS 
1.3 protocol, disk encryption, standard digital certificates, and 
digital signatures. According to the State Cryptography Administration 
of China, its security and efficiency are equivalent to SHA-256.

Reference specification:
1. http://gmbz.org.cn/main/viewfile/20180108023812835219.html
2. http://www.gmbz.org.cn/upload/2018-07-24/1532401392982079739.pdf
3. https://datatracker.ietf.org/doc/html/draft-oscca-cfrg-sm3-02
4. https://datatracker.ietf.org/doc/html/rfc8998


Thanks for your reminder, the above is the information I provided. Do I 
need to submit it to the document through PATCH?

Best regards,
Tianjia
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211201215835</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-01 21:58:35-0400</timestampReceived><subject>Re: [PATCH 3/7] ecc: Add powerpc64 assembly for ecc_256_redc</subject><body>

Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:

&gt; --- /dev/null
&gt; +++ b/powerpc64/ecc-secp256r1-redc.asm
&gt; @@ -0,0 +1,144 @@
&gt; +C powerpc64/ecc-secp256r1-redc.asm
&gt; +ifelse(`
&gt; +   Copyright (C) 2021 Amitay Isaacs &amp; Martin Schwenke, IBM Corporation
&gt; +
&gt; +   Based on x86_64/ecc-secp256r1-redc.asm

Looks good, and it seems method follows the x86_64 version closely. I
just checked in a correction and a clarification to the comments to the
x86_64 version.

A few comments below.

&gt; +C Register usage:
&gt; +
&gt; +define(`SP', `r1')
&gt; +
&gt; +define(`RP', `r4')
&gt; +define(`XP', `r5')
&gt; +
&gt; +define(`F0', `r3')
&gt; +define(`F1', `r6')
&gt; +define(`F2', `r7')
&gt; +define(`F3', `r8')
&gt; +
&gt; +define(`U0', `r9')
&gt; +define(`U1', `r10')
&gt; +define(`U2', `r11')
&gt; +define(`U3', `r12')
&gt; +define(`U4', `r14')
&gt; +define(`U5', `r15')
&gt; +define(`U6', `r16')
&gt; +define(`U7', `r17')

One could save one register by letting U7 and XP overlap, since XP isn't
used after loading U7.

&gt; +	.file "ecc-secp256r1-redc.asm"
&gt; +
&gt; +C FOLD(x), sets (F3,F2,F1,F0)  &lt;-- [(x &lt;&lt; 224) - (x &lt;&lt; 192) - (x &lt;&lt; 96)] &gt;&gt; 64
&gt; +define(`FOLD', `
&gt; +	sldi	F2, $1, 32
&gt; +	srdi	F3, $1, 32
&gt; +	li	F0, 0
&gt; +	li	F1, 0
&gt; +	subfc	F0, F2, F0
&gt; +	subfe	F1, F3, F1

I think the 

	li	F0, 0
	li	F1, 0
	subfc	F0, F2, F0
	subfe	F1, F3, F1

could be replaced with 

	subfic	F0, F2, 0    C "negate with borrow"
	subfze	F1, F3 

If that is measurably faster, I can't say. 

Another option: Since powerpc, like arm, seems to use the proper two's
complement convention that "borrow" is not carry, maybe we don't need to
negate to F0 and F1 at all, and instead change the later subtraction, replacing

	subfc	U1, F0, U1
	subfe	U2, F1, U2
	subfe	U3, F2, U3
	subfe	U0, F3, U0

with

	addc	U1, F0, U1
	adde	U2, F1, U2
	subfe	U3, F2, U3
	subfe	U0, F3, U0

I haven't thought that through, but it does make some sense to me. I
think the arm code propagates carry through a mix of add and sub
instructions in a some places. Maybe F2 needs to be incremented
somewhere for this to work, but probably still cheaper. If this works,
FOLD would turn into something like

	sldi	F0, $1, 32
	srdi	F1, $1, 32
	subfc	F2, $1, F0
	addme	F3, F1

(If you want to investigate this later on, that's fine too, I could merge
the code with the current folding logic).

&gt; +	C If carry, we need to add in
&gt; +	C 2^256 - p = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
&gt; +	li	F0, 0
&gt; +	addze	F0, F0
&gt; +	neg	F2, F0
&gt; +	sldi	F1, F2, 32
&gt; +	srdi	F3, F2, 32
&gt; +	li	U7, -2
&gt; +	and	F3, F3, U7

I think the three instructions to set F3 could be replaced with

	srdi	F3, F2, 31
	sldi	F3, F3, 1

Or maybe the and operation is faster than shift?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211203210955</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-03 21:09:55-0400</timestampReceived><subject>Re: [PATCH 3/7] ecc: Add powerpc64 assembly for ecc_256_redc</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; If this works,
&gt; FOLD would turn into something like
&gt;
&gt; 	sldi	F0, $1, 32
&gt; 	srdi	F1, $1, 32
&gt; 	subfc	F2, $1, F0
&gt; 	addme	F3, F1

I'm looking at a different approach (experimenting on ARM64, which is
quite similar to powerpc, but I don't yet have working code). To
understand what the redc code is doing we need to keep in mind that what
one folding step does is to compute

   &lt;U4,U3,U2,U1,U0&gt; + U0*p 

which cancels the low limb, since p = -1 (mod 2^64). So since the low
limb always cancel, what we need is

   &lt;U4,U3,U2,U1&gt; + U0*((p+1)/2^64) 
 
The x86_64 code does this by splitting U0*p into 2^{256} U0 - (2^{256} -
p) * U0, subtracting in the folding step, and adding in the high part
later. But one doesn't have to do it that way. One could instead use a
FOLD macro that computes

  (2^{192} - 2^{160} + 2^{128} + 2^{32}) U0

I also wonder of there's some way to use carry out from one fold step
and apply it at the right place while preparing the F0,F1,F2,F3 for the next step.

Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211202200959</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-02 20:09:59-0400</timestampReceived><subject>Re: [PATCH v2 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:

&gt; Hi Niels,
&gt;
&gt;&gt; Would you mind writing a short description of the algorithm for the
&gt;&gt; manual? I think it should go under "Miscellaneous hash functions". Would
&gt;&gt; be nice with some brief background on this hash function (origin,
&gt;&gt; intended applications, when and where it's useful) plus reference docs
&gt;&gt; for the defined constants and functions.
&gt;&gt;
&gt;
&gt; SM3 is a cryptographic hash function standard adopted by the
&gt; government of the People's Republic of China, which was issued by the
&gt; Cryptography Standardization Technical Committee of China on December
&gt; 17, 2010. The corresponding standard is "GM/T 0004-2012 "SM3
&gt; Cryptographic Hash Algorithm"".
&gt;
&gt; SM3 algorithm is a hash algorithm in ShangMi cryptosystems. SM3 is
&gt; mainly used for digital signature and verification, message
&gt; authentication code generation and verification, random number
&gt; generation, etc.

Thanks for the backround.

&gt;                  Its algorithm is public. Combined with the public key
&gt; algorithm SM2 and the symmetric encryption algorithm SM4, it can be
&gt; used in various data security and network security scenarios such as
&gt; the TLS 1.3 protocol, disk encryption, standard digital certificates,
&gt; and digital signatures. 

I think the above two sentences could be removed or shortened. I think
the mention of TLS, with reference to RFC 8998, is the part most
relevant for the Nettle manual. Besides that I think your text provides
right level of detail.

&gt;                         According to the State Cryptography
&gt; Administration of China, its security and efficiency are equivalent to
&gt; SHA-256.

This is relevant too.

&gt; Thanks for your reminder, the above is the information I provided. Do
&gt; I need to submit it to the document through PATCH?

If you can prepare a patch for nettle.texinfo, that would be ideal.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211126045849</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-26 04:58:49-0400</timestampReceived><subject>Re: [PATCH 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Hi Niels,


SM2/3/4 is a series of algorithms, which are all standards formulated by 
the China Cryptography Administration. They are widely used in China. At 
present, they are all ISO international standards. We will also consider 
supporting SM2 and SM4 algorithms in the future.

On 11/26/21 12:04 AM, Niels Möller wrote:
&gt; Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:
&gt; 
&gt;&gt; Add OSCCA SM3 secure hash generic hash algorithm, described
&gt;&gt; in OSCCA GM/T 0004-2012 SM3.
&gt; 
&gt; Thanks, I've had a first quick look, and it looks nice. I don't know
&gt; much about this hash function, though. A few questions &gt;
&gt; * Is there some reasonably authoritative English reference for the
&gt;    algorithm? I checked wikipedia, and it only links to an old internet
&gt;    draft, https://tools.ietf.org/id/draft-oscca-cfrg-sm3-02.html
&gt; 


You can refer to the ISO specification here:
https://www.iso.org/standard/67116.html
Or PDF version:
https://github.com/alipay/tls13-sm-spec/blob/master/sm-en-pdfs/sm3/GBT.32905-2016.SM3-en.pdf

&gt; * The name "sm3" is a bit short, would it make sense to add some
&gt;    family-prefix, maybe "oscca_sm3"?
&gt;   

I do not recommend adding algorithm family prefixes. The algorithm names 
are already standardized, and the current mainstream implementations 
also use SM3 names, such as libgcrypt, openssl, linux kernel, coreutils, 
etc.

&gt; * Do you have some examples of protocols or applications that specify
&gt;    the use of sm3?
&gt; 

The SM2/3/4 algorithm can now be used in TLS 1.3 and other scenarios. It 
is also mandatory to use this type of algorithm in some areas in China. 
You can refer to:
https://datatracker.ietf.org/doc/html/rfc8998
https://datatracker.ietf.org/doc/draft-chen-sm2-sm3-algorithms/

&gt; * The implementation, it's written from scratch, or is it based on some
&gt;    reference implementation?
&gt; 

The specification does not define the reference implementation of the 
algorithm. This series of patches mainly refers to the SM3 
implementation in libgcrypt and gnulib.

&gt; Regards,
&gt; /Niels
&gt; 

I hope your question has been answered, thanks again.

Best regards,
Tianjia
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211128100353</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-11-28 10:03:53-0400</timestampReceived><subject>Re: [PATCH 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:

&gt; You can refer to the ISO specification here:
&gt; https://www.iso.org/standard/67116.html
&gt; Or PDF version:
&gt; https://github.com/alipay/tls13-sm-spec/blob/master/sm-en-pdfs/sm3/GBT.32905-2016.SM3-en.pdf

I see that RFC 8998 refers to
http://www.gmbz.org.cn/upload/2018-07-24/1532401392982079739.pdf, which
looks like the same pdf file. I find it a bit odd that the document
carries no information on author or organization.

&gt; The specification does not define the reference implementation of the
&gt; algorithm. This series of patches mainly refers to the SM3
&gt; implementation in libgcrypt and gnulib.

It looks like the gcrypt implementation is licensed under LGPLv2.1 or
later (see https://github.com/gpg/libgcrypt/blob/master/cipher/sm3.c),
so should be fine to copy into nettle (in contrast to gnulib code, which
appears to be GPLv3, and would need explicit permission from copyright
holder before relicensing). But if it is a derived work of libgcrypt, in
the sense of copyright law, the copyright header needs to acknowledge
that, ie,

   Copyright (C) 2017 Jia Zhang
   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;

Or did you write both versions, with Jia being an alternate form of
your name?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211022084501</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-10-22 08:45:01-0400</timestampReceived><subject>Re: [S390x] Optimize SHA3 permute using vector facility</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I've added a new patch that optimizes SHA3 permute function for S390x
&gt; architecture https://git.lysator.liu.se/nettle/nettle/-/merge_requests/36
&gt; More about the patch in merge request description.

Really nice speedup, and interesting that it's significantly faster than
your previous version using the special sha3 instructions.

I'm sorry the existing implementations are quite hard to follow, with
irregular data movements and rather unstructured comments. It must have
been a bit challenging to decipher the x86_64 version. Do you have any
ideas on how to improve documentation and comments?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211022131859</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-10-22 13:18:59-0400</timestampReceived><subject>Re: [S390x] Optimize SHA3 permute using vector facility</subject><body>

On Fri, Oct 22, 2021 at 10:45 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I've added a new patch that optimizes SHA3 permute function for S390x
&gt; &gt; architecture
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/36
&gt; &gt; More about the patch in merge request description.
&gt;
&gt; Really nice speedup, and interesting that it's significantly faster than
&gt; your previous version using the special sha3 instructions.
&gt;
&gt; I'm sorry the existing implementations are quite hard to follow, with
&gt; irregular data movements and rather unstructured comments. It must have
&gt; been a bit challenging to decipher the x86_64 version. Do you have any
&gt; ideas on how to improve documentation and comments?
&gt;

Actually, I need to invest more time on improving the documentation and
comments as I wasn't give enough attention for them during implementing the
s390x version. I'll see what I can do in this matter.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211024185148</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-10-24 18:51:48-0400</timestampReceived><subject>Re: [S390x] Optimize SHA3 permute using vector facility</subject><body>

On Fri, Oct 22, 2021 at 10:45 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I've added a new patch that optimizes SHA3 permute function for S390x
&gt; &gt; architecture
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/36
&gt; &gt; More about the patch in merge request description.
&gt;
&gt; Really nice speedup, and interesting that it's significantly faster than
&gt; your previous version using the special sha3 instructions.
&gt;

Yes, special sha3 instruction of s390x arch doesn't fit well in the SHA3
permute function of nettle, it executes unneeded procedures that are
handled by other functions in nettle that slow down the performance
compared to regular vectorized optimization.


&gt; I'm sorry the existing implementations are quite hard to follow, with
&gt; irregular data movements and rather unstructured comments. It must have
&gt; been a bit challenging to decipher the x86_64 version. Do you have any
&gt; ideas on how to improve documentation and comments?
&gt;

I made some documentation and comment improvements on the implementation,
the new doc illustrates the structure of main permute elements in more
detail. The update has also some improvements on the usage of instruction
set that yield a faster performance.
Let me know if there is any improvement potential there!

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211206085700</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-06 08:57:00-0400</timestampReceived><subject>[PATCH] doc: documentation fot SM3 hash</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 nettle.texinfo | 74 ++++++++++++++++++++++++++++++++++++++++++++++++--
 1 file changed, 72 insertions(+), 2 deletions(-)

diff --git a/nettle.texinfo b/nettle.texinfo
index 39d01159..76934637 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -950,6 +950,52 @@ This function also resets the context in the same way as
 @code{streebog256_init}.
 @end deftypefun
 
+@subsubsection @acronym{SM3}
+
+SM3 is a cryptographic hash function standard adopted by the government of the
+People's Republic of China, which was issued by the Cryptography Standardization
+Technical Committee of China on December 17, 2010. The corresponding standard
+is GM/T 0004-2012 "SM3 Cryptographic Hash Algorithm".
+
+SM3 algorithm is a hash algorithm in ShangMi cryptosystems. SM3 is mainly used
+for digital signature and verification, message authentication code generation
+and verification, random number generation, and the RFC 8998 specification
+defines the usage of ShangMi algorithm suite in TLS 1.3, etc. According to the
+State Cryptography Administration of China, its security and efficiency are
+equivalent to SHA-256.
+
+Nettle defines SM3 in @file{&lt;nettle/sm3.h&gt;}.
+
+@deftp {Context struct} {struct sm3_ctx}
+@end deftp
+
+@defvr Constant SM3_DIGEST_SIZE
+The size of a SM3 digest, i.e. 32.
+@end defvr
+
+@defvr Constant SM3_BLOCK_SIZE
+The internal block size of SM3. Useful for some special constructions,
+in particular HMAC-SM3.
+@end defvr
+
+@deftypefun void sm3_init (struct sm3_ctx *@var{ctx})
+Initialize the SM3 state.
+@end deftypefun
+
+@deftypefun void sm3_update (struct sm3_ctx *@var{ctx}, size_t @var{length}, const \
uint8_t *@var{data}) +Hash some more data.
+@end deftypefun
+
+@deftypefun void sm3_digest (struct sm3_ctx *@var{ctx}, size_t @var{length}, uint8_t \
*@var{digest}) +Performs final processing and extracts the message digest, writing it
+to @var{digest}. @var{length} may be smaller than
+@code{SM3_DIGEST_SIZE}, in which case only the first @var{length}
+octets of the digest are written.
+
+This function also resets the context in the same way as
+@code{sm3_init}.
+@end deftypefun
+
 
 @node Legacy hash functions
 @subsection Legacy hash functions
@@ -1256,6 +1302,7 @@ The last three attributes are function pointers, of types
 @deftypevrx {Constant Struct} {struct nettle_hash} nettle_sha3_256
 @deftypevrx {Constant Struct} {struct nettle_hash} nettle_gosthash94
 @deftypevrx {Constant Struct} {struct nettle_hash} nettle_gosthash94cp
+@deftypevrx {Constant Struct} {struct nettle_hash} nettle_sm3
 These are all the hash functions that Nettle implements.
 @end deftypevr
 
@@ -3775,8 +3822,8 @@ There are abstract functions that use a pointer to a \
@code{struct  nettle_hash} to represent the underlying hash function and @code{void \
*}  pointers that point to three different context structs for that hash
 function. There are also concrete functions for @acronym{HMAC-MD5},
-@acronym{HMAC-RIPEMD160} @acronym{HMAC-SHA1}, @acronym{HMAC-SHA256}, and
-@acronym{HMAC-SHA512}. First, the abstract functions:
+@acronym{HMAC-RIPEMD160} @acronym{HMAC-SHA1}, @acronym{HMAC-SHA256},
+@acronym{HMAC-SHA512}, and @acronym{HMAC-SM3}. First, the abstract functions:
 
 @deftypefun void hmac_set_key (void *@var{outer}, void *@var{inner}, void \
*@var{state}, const struct nettle_hash *@var{H}, size_t @var{length}, const uint8_t \
*@var{key})  Initializes the three context structs from the key. The @var{outer} and
@@ -3963,6 +4010,29 @@ This function also resets the context for processing new \
messages, with  the same key.
 @end deftypefun
 
+
+@subsubsection @acronym{HMAC-SM3}
+
+@deftp {Context struct} {struct hmac_sm3_ctx}
+@end deftp
+
+@deftypefun void hmac_sm3_set_key (struct hmac_sm3_ctx *@var{ctx}, size_t \
@var{key_length}, const uint8_t *@var{key}) +Initializes the context with the key.
+@end deftypefun
+
+@deftypefun void hmac_sm3_update (struct hmac_sm3_ctx *@var{ctx}, size_t \
@var{length}, const uint8_t *@var{data}) +Process some more data.
+@end deftypefun
+
+@deftypefun void hmac_sm3_digest (struct hmac_sm3_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{digest}) +Extracts the @acronym{MAC}, writing it to \
@var{digest}. @var{length} may be smaller than +@code{SM3_DIGEST_SIZE}, in which case \
only the first @var{length} +octets of the @acronym{MAC} are written.
+
+This function also resets the context for processing new messages, with
+the same key.
+@end deftypefun
+
 @node UMAC
 @subsection @acronym{UMAC}
 @cindex UMAC
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210810203239</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-10 20:32:39-0400</timestampReceived><subject>Re: Is there an equivalent to curve25519_mul for ECC keys?</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I'm wondering if there is a function of a combination of functions to
&gt; perform a DH computation using ECC keys and their parameters "struct
&gt; ecc_point *pub1, struct ecc_scalar *key2"?

ecc_point_mul (declared in ecc.h) is intended to do that. There's also
a variant ecc_point_mul_g.

But it seems they're not properly documented in the manual.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210514124237</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2021-05-14 12:42:37-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

Hi Maamoun,
you added the standard GNU License to these files, but the repository
you mention has no license at all (red flag), and looking at the code
it points to on which these files are "based" the current license if
ASL 2.0

How much are your patches "based" on the SHA-Intrinsic source?

The perf improvement is great btw.

Simo.


On Fri, 2021-05-14 at 08:45 +0300, Maamoun TK wrote:
&gt; This patch optimizes SHA1 compress function for arm64 architecture by
&gt; taking advantage of SHA-1 instructions of Armv8 crypto extension.
&gt; The SHA-1 instructions:
&gt; SHA1C: SHA1 hash update (choose)
&gt; SHA1H: SHA1 fixed rotate
&gt; SHA1M: SHA1 hash update (majority)
&gt; SHA1P: SHA1 hash update (parity)
&gt; SHA1SU0: SHA1 schedule update 0
&gt; SHA1SU1: SHA1 schedule update 1
&gt; 
&gt; The patch is based on sha1-arm.c - ARMv8 SHA extensions using C intrinsics
&gt; of repository https://github.com/noloader/SHA-Intrinsics by Jeffrey Walton.
&gt; 
&gt; The patch passes the testsuite of nettle library and the benchmark numbers
&gt; are considerably improved but the performance of the overall sha1 hash
&gt; function doesn't surpass the corresponding openssl numbers.
&gt; 
&gt; Benchmark on gcc117 instance of CFarm before applying the patch:
&gt;          Algorithm         mode        Mbyte/s
&gt;          sha1               update       214.16
&gt;          openssl sha1  update       849.44
&gt;          hmac-sha1     64 bytes     61.69
&gt;          hmac-sha1     256 bytes   131.50
&gt;          hmac-sha1    1024 bytes  185.20
&gt;          hmac-sha1    4096 bytes  204.55
&gt;          hmac-sha1    single msg  210.97
&gt; 
&gt; Benchmark on gcc117 instance of CFarm after applying the patch:
&gt;          Algorithm         mode        Mbyte/s
&gt;          sha1                update       795.57
&gt;          openssl sha1   update       849.25
&gt;          hmac-sha1      64 bytes    167.65
&gt;          hmac-sha1      256 bytes   408.24
&gt;          hmac-sha1     1024 bytes  636.68
&gt;          hmac-sha1     4096 bytes  739.42
&gt;          hmac-sha1     single msg  775.89
&gt; 
&gt; ---
&gt;  arm64/crypto/sha1-compress.asm | 245
&gt; +++++++++++++++++++++++++++++++++++++++++
&gt;  arm64/machine.m4               |   7 ++
&gt;  2 files changed, 252 insertions(+)
&gt;  create mode 100644 arm64/crypto/sha1-compress.asm
&gt; 
&gt; diff --git a/arm64/crypto/sha1-compress.asm b/arm64/crypto/sha1-compress.asm
&gt; new file mode 100644
&gt; index 00000000..bb3f1d35
&gt; --- /dev/null
&gt; +++ b/arm64/crypto/sha1-compress.asm
&gt; @@ -0,0 +1,245 @@
&gt; +C arm64/crypto/sha1-compress.asm
&gt; +
&gt; +ifelse(`
&gt; +   Copyright (C) 2021 Mamone Tarsha
&gt; +
&gt; +   Based on sha1-arm.c - ARMv8 SHA extensions using C intrinsics of
&gt; +   repository https://github.com/noloader/SHA-Intrinsics
&gt; +   sha1-arm.c is written and placed in public domain by Jeffrey Walton,
&gt; +   based on code from ARM, and by Johannes Schneiders, Skip
&gt; +   Hovsmith and Barry O'Rourke for the mbedTLS project.
&gt; +
&gt; +   This file is part of GNU Nettle.
&gt; +
&gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; +   modify it under the terms of either:
&gt; +
&gt; +     * the GNU Lesser General Public License as published by the Free
&gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or
&gt; +
&gt; +     * the GNU General Public License as published by the Free
&gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or both in parallel, as here.
&gt; +
&gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; +   General Public License for more details.
&gt; +
&gt; +   You should have received copies of the GNU General Public License and
&gt; +   the GNU Lesser General Public License along with this program.  If
&gt; +   not, see http://www.gnu.org/licenses/.
&gt; +')
&gt; +
&gt; +.file "sha1-compress.asm"
&gt; +.arch armv8-a+crypto
&gt; +
&gt; +.text
&gt; +
&gt; +C Register usage:
&gt; +
&gt; +define(`STATE', `x0')
&gt; +define(`INPUT', `x1')
&gt; +
&gt; +define(`CONST0', `v0')
&gt; +define(`CONST1', `v1')
&gt; +define(`CONST2', `v2')
&gt; +define(`CONST3', `v3')
&gt; +define(`MSG0', `v4')
&gt; +define(`MSG1', `v5')
&gt; +define(`MSG2', `v6')
&gt; +define(`MSG3', `v7')
&gt; +define(`ABCD', `v16')
&gt; +define(`ABCD_SAVED', `v17')
&gt; +define(`E0', `v18')
&gt; +define(`E0_SAVED', `v19')
&gt; +define(`E1', `v20')
&gt; +define(`TMP0', `v21')
&gt; +define(`TMP1', `v22')
&gt; +
&gt; +C void nettle_sha1_compress(uint32_t *state, const uint8_t *input)
&gt; +
&gt; +PROLOGUE(nettle_sha1_compress)
&gt; +    C Initialize constants
&gt; +    mov            w2,#0x7999
&gt; +    movk           w2,#0x5A82,lsl #16
&gt; +    dup            CONST0.4s,w2
&gt; +    mov            w2,#0xEBA1
&gt; +    movk           w2,#0x6ED9,lsl #16
&gt; +    dup            CONST1.4s,w2
&gt; +    mov            w2,#0xBCDC
&gt; +    movk           w2,#0x8F1B,lsl #16
&gt; +    dup            CONST2.4s,w2
&gt; +    mov            w2,#0xC1D6
&gt; +    movk           w2,#0xCA62,lsl #16
&gt; +    dup            CONST3.4s,w2
&gt; +
&gt; +    C Load state
&gt; +    add            x2,STATE,#16
&gt; +    movi           E0.4s,#0
&gt; +    ld1            {ABCD.4s},[STATE]
&gt; +    ld1            {E0.s}[0],[x2]
&gt; +
&gt; +    C Save state
&gt; +    mov            ABCD_SAVED.16b,ABCD.16b
&gt; +    mov            E0_SAVED.16b,E0.16b
&gt; +
&gt; +    C Load message
&gt; +    ld1            {MSG0.16b,MSG1.16b,MSG2.16b,MSG3.16b},[INPUT]
&gt; +
&gt; +    C Reverse for little endian
&gt; +    rev32          MSG0.16b,MSG0.16b
&gt; +    rev32          MSG1.16b,MSG1.16b
&gt; +    rev32          MSG2.16b,MSG2.16b
&gt; +    rev32          MSG3.16b,MSG3.16b
&gt; +
&gt; +    add            TMP0.4s,MSG0.4s,CONST0.4s
&gt; +    add            TMP1.4s,MSG1.4s,CONST0.4s
&gt; +
&gt; +    C Rounds 0-3
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG2.4s,CONST0.4s
&gt; +    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
&gt; +
&gt; +    C Rounds 4-7
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG3.4s,CONST0.4s
&gt; +    sha1su1        MSG0.4s,MSG3.4s
&gt; +    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
&gt; +
&gt; +    C Rounds 8-11
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG0.4s,CONST0.4s
&gt; +    sha1su1        MSG1.4s,MSG0.4s
&gt; +    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
&gt; +
&gt; +    C Rounds 12-15
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG1.4s,CONST1.4s
&gt; +    sha1su1        MSG2.4s,MSG1.4s
&gt; +    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
&gt; +
&gt; +    C Rounds 16-19
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG2.4s,CONST1.4s
&gt; +    sha1su1        MSG3.4s,MSG2.4s
&gt; +    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
&gt; +
&gt; +    C Rounds 20-23
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG3.4s,CONST1.4s
&gt; +    sha1su1        MSG0.4s,MSG3.4s
&gt; +    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
&gt; +
&gt; +    C Rounds 24-27
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG0.4s,CONST1.4s
&gt; +    sha1su1        MSG1.4s,MSG0.4s
&gt; +    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
&gt; +
&gt; +    C Rounds 28-31
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG1.4s,CONST1.4s
&gt; +    sha1su1        MSG2.4s,MSG1.4s
&gt; +    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
&gt; +
&gt; +    C Rounds 32-35
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG2.4s,CONST2.4s
&gt; +    sha1su1        MSG3.4s,MSG2.4s
&gt; +    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
&gt; +
&gt; +    C Rounds 36-39
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG3.4s,CONST2.4s
&gt; +    sha1su1        MSG0.4s,MSG3.4s
&gt; +    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
&gt; +
&gt; +    C Rounds 40-43
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG0.4s,CONST2.4s
&gt; +    sha1su1        MSG1.4s,MSG0.4s
&gt; +    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
&gt; +
&gt; +    C Rounds 44-47
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG1.4s,CONST2.4s
&gt; +    sha1su1        MSG2.4s,MSG1.4s
&gt; +    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
&gt; +
&gt; +    C Rounds 48-51
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG2.4s,CONST2.4s
&gt; +    sha1su1        MSG3.4s,MSG2.4s
&gt; +    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
&gt; +
&gt; +    C Rounds 52-55
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG3.4s,CONST3.4s
&gt; +    sha1su1        MSG0.4s,MSG3.4s
&gt; +    sha1su0        MSG1.4s,MSG2.4s,MSG3.4s
&gt; +
&gt; +    C Rounds 56-59
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG0.4s,CONST3.4s
&gt; +    sha1su1        MSG1.4s,MSG0.4s
&gt; +    sha1su0        MSG2.4s,MSG3.4s,MSG0.4s
&gt; +
&gt; +    C Rounds 60-63
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG1.4s,CONST3.4s
&gt; +    sha1su1        MSG2.4s,MSG1.4s
&gt; +    sha1su0        MSG3.4s,MSG0.4s,MSG1.4s
&gt; +
&gt; +    C Rounds 64-67
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +    add            TMP0.4s,MSG2.4s,CONST3.4s
&gt; +    sha1su1        MSG3.4s,MSG2.4s
&gt; +    sha1su0        MSG0.4s,MSG1.4s,MSG2.4s
&gt; +
&gt; +    C Rounds 68-71
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +    add            TMP1.4s,MSG3.4s,CONST3.4s
&gt; +    sha1su1        MSG0.4s,MSG3.4s
&gt; +
&gt; +    C Rounds 72-75
&gt; +    sha1h          SFP(E1),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
&gt; +
&gt; +    C Rounds 76-79
&gt; +    sha1h          SFP(E0),SFP(ABCD)
&gt; +    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
&gt; +
&gt; +    C Combine state
&gt; +    add            E0.4s,E0.4s,E0_SAVED.4s
&gt; +    add            ABCD.4s,ABCD.4s,ABCD_SAVED.4s
&gt; +
&gt; +    C Store state
&gt; +    st1            {ABCD.4s},[STATE]
&gt; +    st1            {E0.s}[0],[x2]
&gt; +
&gt; +    ret
&gt; +EPILOGUE(nettle_sha1_compress)
&gt; diff --git a/arm64/machine.m4 b/arm64/machine.m4
&gt; index e69de29b..7df62bcc 100644
&gt; --- a/arm64/machine.m4
&gt; +++ b/arm64/machine.m4
&gt; @@ -0,0 +1,7 @@
&gt; +C Get 32-bit floating-point register from vector register
&gt; +C SFP(VR)
&gt; +define(`SFP',``s'substr($1,1,len($1))')
&gt; +
&gt; +C Get 128-bit floating-point register from vector register
&gt; +C QFP(VR)
&gt; +define(`QFP',``q'substr($1,1,len($1))')
&gt; 

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210514145333</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-14 14:53:33-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

On Fri, May 14, 2021 at 3:42 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:

&gt; you added the standard GNU License to these files, but the repository
&gt; you mention has no license at all (red flag), and looking at the code
&gt; it points to on which these files are "based" the current license if
&gt; ASL 2.0
&gt;
&gt; How much are your patches "based" on the SHA-Intrinsic source?
&gt;

I've written the patch from scratch while keeping in mind how to use the
SHA-1 instructions of Arm64 crypto extension from sha1-arm.c in Jeffrey's
repository.
I've Cced Jeffrey in the main message to get his input on this patch.

regards,
Maamoun
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210520181618</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-20 18:16:18-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I've written the patch from scratch while keeping in mind how to use the
&gt; SHA-1 instructions of Arm64 crypto extension from sha1-arm.c in Jeffrey's
&gt; repository.

If that is the case, avoid phrases like "based on" which are easily
misread as implying it's a derived work in the copyright sense.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210520184409</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-20 18:44:09-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

On Thu, May 20, 2021 at 9:16 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I've written the patch from scratch while keeping in mind how to use the
&gt; &gt; SHA-1 instructions of Arm64 crypto extension from sha1-arm.c in Jeffrey's
&gt; &gt; repository.
&gt;
&gt; If that is the case, avoid phrases like "based on" which are easily
&gt; misread as implying it's a derived work in the copyright sense.
&gt;

I'll just mention it in the README file then.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210520191850</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-20 19:18:50-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

I've mentioned it in the README file.

---
 arm64/README                   | 7 +++++++
 arm64/crypto/sha1-compress.asm | 6 ------
 2 files changed, 7 insertions(+), 6 deletions(-)

diff --git a/arm64/README b/arm64/README
index d2745d57..206bb773 100644
--- a/arm64/README
+++ b/arm64/README
@@ -83,5 +83,12 @@ particular care must be taken if the loaded data is then
to be regarded as
 elements of e.g. a doubleword vector. Indicies may appear reversed on
 big-endian systems (because they are).

+Hardware-accelerated SHA Instructions
+
+The SHA optimized cores are implemented using SHA hashing instructions
added
+to AArch64 in crypto extensions. The repository [3] illustrates using those
+instructions for optimizing SHA hashing functions.
+
 [1]
https://github.com/ARM-software/abi-aa/releases/download/2020Q4/aapcs64.pdf
 [2] https://llvm.org/docs/BigEndianNEON.html
+[3] https://github.com/noloader/SHA-Intrinsics
diff --git a/arm64/crypto/sha1-compress.asm b/arm64/crypto/sha1-compress.asm
index bb3f1d35..f261c93d 100644
--- a/arm64/crypto/sha1-compress.asm
+++ b/arm64/crypto/sha1-compress.asm
@@ -3,12 +3,6 @@ C arm64/crypto/sha1-compress.asm
 ifelse(`
    Copyright (C) 2021 Mamone Tarsha

-   Based on sha1-arm.c - ARMv8 SHA extensions using C intrinsics of
-   repository https://github.com/noloader/SHA-Intrinsics
-   sha1-arm.c is written and placed in public domain by Jeffrey Walton,
-   based on code from ARM, and by Johannes Schneiders, Skip
-   Hovsmith and Barry O'Rourke for the mbedTLS project.
-
    This file is part of GNU Nettle.

    GNU Nettle is free software: you can redistribute it and/or

-- 
2.25.1

On Thu, May 20, 2021 at 9:44 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Thu, May 20, 2021 at 9:16 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; I've written the patch from scratch while keeping in mind how to use the
&gt;&gt; &gt; SHA-1 instructions of Arm64 crypto extension from sha1-arm.c in
&gt;&gt; Jeffrey's
&gt;&gt; &gt; repository.
&gt;&gt;
&gt;&gt; If that is the case, avoid phrases like "based on" which are easily
&gt;&gt; misread as implying it's a derived work in the copyright sense.
&gt;&gt;
&gt;
&gt; I'll just mention it in the README file then.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210523075204</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-23 07:52:04-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

Looks pretty good. A few comments and questions below.

&gt; This patch optimizes SHA1 compress function for arm64 architecture by
&gt; taking advantage of SHA-1 instructions of Armv8 crypto extension.
&gt; The SHA-1 instructions:
&gt; SHA1C: SHA1 hash update (choose)
&gt; SHA1H: SHA1 fixed rotate
&gt; SHA1M: SHA1 hash update (majority)
&gt; SHA1P: SHA1 hash update (parity)
&gt; SHA1SU0: SHA1 schedule update 0
&gt; SHA1SU1: SHA1 schedule update 1

Can you add this brief summary of instructions as a comment in the asm
file?

&gt; Benchmark on gcc117 instance of CFarm before applying the patch:
&gt;          Algorithm         mode        Mbyte/s
&gt;          sha1               update       214.16
&gt;          openssl sha1  update       849.44

&gt; Benchmark on gcc117 instance of CFarm after applying the patch:
&gt;          Algorithm         mode        Mbyte/s
&gt;          sha1                update       795.57
&gt;          openssl sha1   update       849.25

Great speedup! Any idea why openssl is still slightly faster?

&gt; +define(`TMP0', `v21')
&gt; +define(`TMP1', `v22')

Not sure I understand how these are used, but it looks like the TMP
variables are used in some way for the message expansion state? E.g.,
TMP0 assigned in the code for rounds 0-3, and this value used in the
code for rounds 8-11. Other implementations don't need extra state for
this, but just modifies the 16 message words in-place. 

It would be nice to either make the TMP registers more temporary (i.e.,
no round depends on the value in these registers from previous rounds)
and keep needed state only on the MSG variables. Or rename them to give
a better hint on how they're used.

&gt; +C void nettle_sha1_compress(uint32_t *state, const uint8_t *input)
&gt; +
&gt; +PROLOGUE(nettle_sha1_compress)
&gt; +    C Initialize constants
&gt; +    mov            w2,#0x7999
&gt; +    movk           w2,#0x5A82,lsl #16
&gt; +    dup            CONST0.4s,w2
&gt; +    mov            w2,#0xEBA1
&gt; +    movk           w2,#0x6ED9,lsl #16
&gt; +    dup            CONST1.4s,w2
&gt; +    mov            w2,#0xBCDC
&gt; +    movk           w2,#0x8F1B,lsl #16
&gt; +    dup            CONST2.4s,w2
&gt; +    mov            w2,#0xC1D6
&gt; +    movk           w2,#0xCA62,lsl #16
&gt; +    dup            CONST3.4s,w2

Maybe would be clearer or more efficient to load these from memory? Not
sure if there's an nice and consice way to load the four 32-bit values
into a 128-bit, and then copy/duplicate them into the four const
registers.

&gt; +    C Load message
&gt; +    ld1            {MSG0.16b,MSG1.16b,MSG2.16b,MSG3.16b},[INPUT]
&gt; +
&gt; +    C Reverse for little endian
&gt; +    rev32          MSG0.16b,MSG0.16b
&gt; +    rev32          MSG1.16b,MSG1.16b
&gt; +    rev32          MSG2.16b,MSG2.16b
&gt; +    rev32          MSG3.16b,MSG3.16b

How does this work on big-endian? The ld1 with .16b is endian-neutral
(according to the README), that means we always get the wrong order, and
then we do unconditional byteswapping? Maybe add a comment. Not sure if
it's worth the effort to make it work differently (ld1 .4w on
big-endian)? It's going to be a pretty small fraction of the per-block
processing.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210601170242</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-06-01 17:02:42-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; Great speedup! Any idea why openssl is still slightly faster?
&gt;&gt;
&gt;
&gt; Sure, OpenSSL implementation uses a loop inside SH1 update function which
&gt; eliminates the constant initialization and state loading/sotring for each
&gt; block while nettle does that for every block iteration.

I see, that can make a difference if the actual compressing is fast
enough.

&gt; Modifying the message words in-place will change the value used by
&gt; 'sha1su0' and 'sha1su1' instructions. According to ARM ® A64 Instruction Set
&gt; Architecture:
&gt; SHA1SU0 &lt;Vd&gt;.4S, &lt;Vn&gt;.4S, &lt;Vm&gt;.4S
&gt; &lt;Vd&gt; Is the name of the SIMD&amp;FP source and destination register
&gt; .
&gt; .
&gt;
&gt; SHA1SU1 &lt;Vd&gt;.4S, &lt;Vn&gt;.4S
&gt; &lt;Vd&gt; Is the name of the SIMD&amp;FP source and destination register
&gt; .
&gt; .
&gt;
&gt; So using TMP variable is necessary here. I can't think of any replacement,
&gt; let me know how the other implementations handle this case.

I'm afraid I have no concrete suggestion, I would need to read up on the
aarch64 instructions. Implementations that do only a single round at a
time (e.g., the C implementation) uses a 16-word circular buffer for the
message expansion state, and updates one of the words per round. If I
read the latest patch correctly, you also don't keep any state besides
the MSGx registers?

&gt; It would be nice to either make the TMP registers more temporary (i.e.,
&gt;&gt; no round depends on the value in these registers from previous rounds)
&gt;&gt; and keep needed state only on the MSG variables. Or rename them to give
&gt;&gt; a better hint on how they're used.
&gt;&gt;
&gt;
&gt; Done! Yield a slight performance increase btw.

Nice.

&gt; We can load all the constants (including duplicate values) from memory with
&gt; one instruction. The issue is how to get the data address properly for
&gt; every supported abi!

&gt; the easiest solution is to define
&gt; the data in the .text section to make sure the address is near enough to be
&gt; loaded with certain instruction. Do you want to do that?

Using .text would probably work, even if it's in some sense more correct to put
the constants in rodata segment. But let's leave as is for now.

&gt;  We have an intensive discussion about that in the GCM patch. The short
&gt; story, this patch should work well for both endianness modes.

Sounds good.

I've pushed the combined patches to a branch arm64-sha1. Would you like
to update the fat build setup, before merging to master?

Regards,
/Niels

-- 
Niels MÃ¶ller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405073957</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-04-05 07:39:57-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

"Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:

&gt; An implementation combining AES+GCM _can potentially_ yield significant
&gt; performance boosts by allowing for increased instruction parallelism, avoiding
&gt; C-function call overhead, more flexibility in assembly fine-tuning, etc. This
&gt; series provides such an implementation based on the existing optimized Nettle
&gt; routines for POWER9 and later processors. Benchmark results on a POWER9
&gt; Blackbird running at 3.5GHz are given at the end of this mail.

Benchmark results are impressive. If I get the numbers right, cycles per
block (16 bytes) is reduced from 40 to 22.5. You can run
nettle-benchmark with the flag -f 3.5e9 (for 3.5GHz clock frequency) to
get cycle numbers in the output.

I'm a bit conservative about about adding assembly code for combined
operations, since it can lead to an explosion in the amount of code to
maintain. So I'd like to understand a bit better where the 17.5 saved
cycles were spent. For the code on master, gcm_encrypt (with aes) is built from
these building blocks:

  * gcm_fill

    C code, essentially 2 64-bit stores per block. On little endian, it
    also needs some byte swapping.

  * aes_encrypt

    Using power assembly. Performance measured as the "aes128  ECB
    encrypt" line in nettle-benchmark output.

  * memxor3

    This is C code on power (and rather hairy C code). Performance can
    be measured with nettle-benchmark, and it's going to be a bit
    alignment dependent.

  * gcm_hash

    This uses power assembly. Performance is measured as the "gcm
    update" line in nettle-benchmark output. From your numbers, this
    seems to be 7.3 cycles per block.

So before going all the way with a combined aes_gcm function, I think
it's good to try to optimize the building blocks. Please benchmark
memxor3, to see if it could benefit from assembly implementation. If so,
that should give a nice speedup to several modes, not just gcm. (If you
implement memxor3, beware that it needs to support some overlap, to not
break in-place CBC decrypt).

Another potential overhead is that data is stored to memory when passed
between these functions. It seems we store a block 3 times, and loads a
block 4 times (the additional accesses should be cache friendly, but
wills till cost some execution resources). Optimizing that seems to need
some kind of combined function. But maybe it is sufficient to optimize
something a bit more general than aes gcm, e.g., aes ctr?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210520190627</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-20 19:06:27-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

"Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:

&gt; So in total, if we assume an ideal (but impossible) zero-cost version
&gt; for memxor, memxor3, and gcm_fill and avoid permutes via ISA 3.0 vector
&gt; load/stores we can only account for 11.82 cycles/block; leaving 4.97
&gt; cycles/block as an additional benefit of the combined implementation.

One hypothesis for that gain is that we can avoid storing the aes input
in memory at all; instead, generated the counter values on the fly in
the appropriate registers.

&gt;&gt; Another potential overhead is that data is stored to memory when passed
&gt;&gt; between these functions. It seems we store a block 3 times, and loads a
&gt;&gt; block 4 times (the additional accesses should be cache friendly, but
&gt;&gt; wills till cost some execution resources). Optimizing that seems to need
&gt;&gt; some kind of combined function. But maybe it is sufficient to optimize
&gt;&gt; something a bit more general than aes gcm, e.g., aes ctr?
&gt;
&gt; This would basically have to replace the nettle_crypt16 function call
&gt; with arch-specific assembly, right? I can code this up and try it out in
&gt; the context of AES-GCM.

Yes, something like that. If we leave the _nettle_gcm_hash unchanged
(with its own independent assembly implementation), and look at
gcm_encrypt, what we have is

      const void *cipher, nettle_cipher_func *f,

  _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);

It would be nice if we could replace that with a call to aes_ctr_crypt,
and then optimizing that would benefit both gcm and plain ctr. But it's
not quite that easy, because gcm unfortunately uses it's own variant of
ctr mode, which is why we need to pass the gcm_fill function in the
first place.

So if we need separate assembly for aes_plain_ctr and aes_gcm_ctr (they
*might* still share some code, but they would be distinct entry points).
Say we call the gcm-specific ctr function from some variant of
gcm_encrypt via a different function pointer. Then that gcm_encrypt
variant is getting a bit pointless. Maybe it's better to do

  void aes128_gcm_encrypt(...)
  {
    _nettle_aes128_gcm_ctr(...);
    _nettle_gcm_hash(...);
  }

At least, we avoid duplicating the _gcm_hash for aes128, aes192, aes256
(and any other algorithms we might want to optimize in a similar way).
And each of the aes assembly routines should be fairly small and easy to
maintain. 

I wonder if there are any reasonable alternatives with similar
performance? One idea that occurs to me is to replace the role of
gcm_fill function (and the nettle_fill16_fOBunc type) with an
arch-specific assembly only hook-interface that gets inputs in specified
registers, and is expected to produce the next cipher input in
registers.

We could then have a aes128_any_encrypt that takes the same args as
aes128_encrypt + a pointer to such a magic assembly function.

The aes128_any_encrypt assembly would then put required input in the
right registers (address of clear text, current counter block, previous
ciphertext block, etc) and have a loop where each iteration calls the
hook, and encrypts a block from registers.

But I'm afraid it's not going to be so easy, given that where possible
(i.e., all modes but cbc encrypt) would like to have the option to do
multiple blocks in parallell. Perhaps better to have an assembly
interface to functions doing ECB on one block, two blocks, three blocks
(if there are sufficient number of registers), etc, in registers, and
call that from the other assembly functions. A bit like the recent
chacha_Ncore functions, but with input and output output in registers
rather than stored in memory.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210601202131</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-06-01 20:21:31-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

On Thu May 20, 2021 at 3:59 PM EDT, Maamoun TK wrote:
&gt; On Thu, May 20, 2021 at 10:06 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt;
&gt; &gt; "Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; So in total, if we assume an ideal (but impossible) zero-cost version
&gt; &gt; &gt; for memxor, memxor3, and gcm_fill and avoid permutes via ISA 3.0 vector
&gt; &gt; &gt; load/stores we can only account for 11.82 cycles/block; leaving 4.97
&gt; &gt; &gt; cycles/block as an additional benefit of the combined implementation.
&gt; &gt;
&gt; &gt; One hypothesis for that gain is that we can avoid storing the aes input
&gt; &gt; in memory at all; instead, generated the counter values on the fly in
&gt; &gt; the appropriate registers.
&gt; &gt;
&gt; &gt; &gt;&gt; Another potential overhead is that data is stored to memory when passed
&gt; &gt; &gt;&gt; between these functions. It seems we store a block 3 times, and loads a
&gt; &gt; &gt;&gt; block 4 times (the additional accesses should be cache friendly, but
&gt; &gt; &gt;&gt; wills till cost some execution resources). Optimizing that seems to need
&gt; &gt; &gt;&gt; some kind of combined function. But maybe it is sufficient to optimize
&gt; &gt; &gt;&gt; something a bit more general than aes gcm, e.g., aes ctr?
&gt; &gt; &gt;
&gt; &gt; &gt; This would basically have to replace the nettle_crypt16 function call
&gt; &gt; &gt; with arch-specific assembly, right? I can code this up and try it out in
&gt; &gt; &gt; the context of AES-GCM.
&gt; &gt;
&gt; &gt; Yes, something like that. If we leave the _nettle_gcm_hash unchanged
&gt; &gt; (with its own independent assembly implementation), and look at
&gt; &gt; gcm_encrypt, what we have is
&gt; &gt;
&gt; &gt;       const void *cipher, nettle_cipher_func *f,
&gt; &gt;
&gt; &gt;   _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
&gt; &gt;
&gt; &gt; It would be nice if we could replace that with a call to aes_ctr_crypt,
&gt; &gt; and then optimizing that would benefit both gcm and plain ctr. But it's
&gt; &gt; not quite that easy, because gcm unfortunately uses it's own variant of
&gt; &gt; ctr mode, which is why we need to pass the gcm_fill function in the
&gt; &gt; first place.
&gt; &gt;
&gt; &gt; So if we need separate assembly for aes_plain_ctr and aes_gcm_ctr (they
&gt; &gt; *might* still share some code, but they would be distinct entry points).
&gt; &gt; Say we call the gcm-specific ctr function from some variant of
&gt; &gt; gcm_encrypt via a different function pointer. Then that gcm_encrypt
&gt; &gt; variant is getting a bit pointless. Maybe it's better to do
&gt; &gt;
&gt; &gt;   void aes128_gcm_encrypt(...)
&gt; &gt;   {
&gt; &gt;     _nettle_aes128_gcm_ctr(...);
&gt; &gt;     _nettle_gcm_hash(...);
&gt; &gt;   }
&gt; &gt;
&gt; &gt; At least, we avoid duplicating the _gcm_hash for aes128, aes192, aes256
&gt; &gt; (and any other algorithms we might want to optimize in a similar way).
&gt; &gt; And each of the aes assembly routines should be fairly small and easy to
&gt; &gt; maintain.
&gt; &gt;
&gt;
&gt; While writing the white paper "Optimize AES-GCM for PowerPC architecture
&gt; processors", I concluded that is the best approach to implement for
&gt; PowerPC
&gt; architecture, easy to maintain, avoid duplication, and perform well.
&gt; I've separated aes_gcm encrypt/decrypt to two functions, aes_ctr and
&gt; ghash.
&gt; Both implemented using Power ISA v3.00 assisted with vector-scalar
&gt; registers.
&gt; I got 1.18 cycles/byte for gcm-aes-128 encrypt/decrypt, 1.31 cycles/byte
&gt; for gcm-aes-192 encrypt/decrypt, and 1.44 cycles/byte for gcm-aes-256
&gt; encrypt/decrypt.

Neat, did you base that on the aes-gcm combined series I posted here or
completely different/new code?

&gt;
&gt; Still if there are additional vector registers, I would give the
&gt; combined
&gt; function a shot as it eliminates loading the input message twice.
&gt;
&gt; regards,
&gt; Mamone

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210225100432</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2021-02-25 10:04:32-0400</timestampReceived><subject>Re: Status update</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; 4. RSA-OAEP merge request. I intend to attend to (3) first, and will not
&gt;    pay much attention to this one at the moment. If anyone else would
&gt;    like to help out with review, maybe have alook at this one?
&gt;    https://git.lysator.liu.se/nettle/nettle/-/merge_requests/20 

I had a brief look at this and it's already in a pretty good shape.
I'll try to do a thorough review if that helps.

Given the use of PKCS #1 v1.5 padding seems to be becoming
problematic[1], I guess this is a much wanted feature.

Regards,

Footnotes:
[1]  https://github.com/openssl/openssl/issues/13421

-- 
Daiki Ueno
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210302023251</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-02 02:32:51-0400</timestampReceived><subject>Re: Status update</subject><body>

On Thu, Feb 25, 2021 at 10:14 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; 1. New Arm64 code (don't recall current status off the top of my head).


I almost forget about fat build, do you want fat support before merging the
code to the master branch or it's ok to be made afterward?

2. s390x testing. I'd prefer to not run a git checkout on the s390x test
&gt;    machine, but have the ci job make a tarball, ssh it over to the test
&gt;    machine, unpack in a fresh directory for build and test. This needs
&gt;    to be in place before adding s390x specific code. When done, could
&gt;    likely be reused for remote testing on any other platforms of
&gt;    interest, which aren't directly available in the ci system.
&gt;

Done!

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210304084834</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-04 08:48:34-0400</timestampReceived><subject>Re: Status update</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; 1. New Arm64 code (don't recall current status off the top of my head).
&gt;
&gt; I almost forget about fat build, do you want fat support before merging the
&gt; code to the master branch or it's ok to be made afterward?

I've merged the arm64 branch now, thanks! Fat build would be nice. And
I'd like to change to m4 macros.

Do you plan to work on arm64 implementations of more algorithms? If I've
got it right, there are extensions with AES and SHA instructions?
Chacha/salsa20 could benefit from general SIMD instructions.

&gt; 2. s390x testing. I'd prefer to not run a git checkout on the s390x test
&gt;&gt;    machine, but have the ci job make a tarball, ssh it over to the test
&gt;&gt;    machine, unpack in a fresh directory for build and test. This needs
&gt;&gt;    to be in place before adding s390x specific code. When done, could
&gt;&gt;    likely be reused for remote testing on any other platforms of
&gt;&gt;    interest, which aren't directly available in the ci system.

&gt; Done!

Thanks! Sorry I'm a bit slow, but I hope to be able to setup an account
and try this out reasonably soon.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210304175630</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-04 17:56:30-0400</timestampReceived><subject>Re: Status update</subject><body>

On Thu, Mar 4, 2021 at 10:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; And I'd like to change to m4 macros.
&gt;

I considered to use m4 macros but it "mangles" parameter names, it becomes
hard for reader to keep track on the macro body. However, I'm still up to
change it to m4 macros if you like.


&gt; Do you plan to work on arm64 implementations of more algorithms? If I've
&gt; got it right, there are extensions with AES and SHA instructions?
&gt;

Sure, I'll try to keep S390x and arm64 optimizations on the same track.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328013413</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-28 01:34:13-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

On Mon, Jan 4, 2021 at 4:00 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; Hi Everyone,
&gt; &gt;
&gt; &gt; I bumped to Nettle 3.7. The build is resulting in:
&gt;
&gt; Clearly, the assembler doesn't know of the sha-related instructions
&gt; (introduced in 2013, according to
&gt; https://en.wikipedia.org/wiki/Intel_SHA_extensions). Which assembler
&gt; (and version) are you using? If it's difficult to upgrade the assembler,
&gt; it could be worked around by replacing the instructions with equivalent
&gt; .byte sequences.

This makes no sense...

I added --disable-x86-sha-ni and it still produces the error. How is
the ASM being used if it is disabled???

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328022017</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-28 02:20:17-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

On Sat, Mar 27, 2021 at 9:34 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; This makes no sense...
&gt;
&gt; I added --disable-x86-sha-ni and it still produces the error. How is
&gt; the ASM being used if it is disabled???

Here's a demonstration of the configuration problem.

["test-nettle.sh.txt" (text/plain)]

#!/usr/bin/env bash

NETTLE=nettle-3.7.2

rm -rf ${NETTLE}

if ! wget -O nettle-3.7.2.tar.gz https://ftp.gnu.org/gnu/nettle/${NETTLE}.tar.gz ;
then
	echo "Failed to download Nettle"
	exit 1
fi

if ! gzip -d &lt; ${NETTLE}.tar.gz | tar xf - ;
then
	echo "Failed to unpack Nettle"
	exit 1
fi

cd nettle-3.7.2 || exit 1

if ! ./configure --enable-fat --disable-sha-ni ;
then
	echo "Failed to configure Nettle"
	exit 1
fi

dd if=/dev/urandom of=sha1-compress.asm count=1024
dd if=/dev/urandom of=sha256-compress.asm count=1024

if ! make -j 4 ;
then
	echo "Failed to build Nettle"
	exit 1
fi

if ! make check ;
then
	echo "Failed to test Nettle"
	exit 1
fi

exit 0
[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210328081803</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-28 08:18:03-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt;&gt; I added --disable-x86-sha-ni and it still produces the error. How is
&gt;&gt; the ASM being used if it is disabled???

You need to choose *either* --enable-fat (now the default), *or* use the
explicit config options for particular instructions. Mixing is not
supported. Don't do that.

And I think this is at least the third time I point this out to you,
most recently just a few days ago. If, e.g., you deeply dislike the way
Nettle's configure works and would like it to change, your current
behavior is not a productive way of improving anything. It is annoying
me and wasting my time.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328082148</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-28 08:21:48-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

On Sun, Mar 28, 2021 at 4:18 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt;&gt; I added --disable-x86-sha-ni and it still produces the error. How is
&gt; &gt;&gt; the ASM being used if it is disabled???
&gt;
&gt; You need to choose *either* --enable-fat (now the default), *or* use the
&gt; explicit config options for particular instructions. Mixing is not
&gt; supported. Don't do that.
&gt;
&gt; And I think this is at least the third time I point this out to you,
&gt; most recently just a few days ago. If, e.g., you deeply dislike the way
&gt; Nettle's configure works and would like it to change, your current
&gt; behavior is not a productive way of improving anything. It is annoying
&gt; me and wasting my time.

--enable-fat turns on cpu identification and runtime switching. I need
that. I need AES. I don't need SHA. It is impossible to get into a
good configuration.

Nettle wastes a fair amount our time trying to work through these problems.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211205202027</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-05 20:20:27-0400</timestampReceived><subject>ARM64 ecc_256_redc (was: Re: [PATCH 3/7] ecc: Add powerpc64 assembly for ecc_256_redc)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I'm looking at a different approach (experimenting on ARM64, which is
&gt; quite similar to powerpc, but I don't yet have working code). To
&gt; understand what the redc code is doing we need to keep in mind that what
&gt; one folding step does is to compute
&gt;
&gt;    &lt;U4,U3,U2,U1,U0&gt; + U0*p 
&gt;
&gt; which cancels the low limb, since p = -1 (mod 2^64). So since the low
&gt; limb always cancel, what we need is
&gt;
&gt;    &lt;U4,U3,U2,U1&gt; + U0*((p+1)/2^64) 
&gt;  
&gt; The x86_64 code does this by splitting U0*p into 2^{256} U0 - (2^{256} -
&gt; p) * U0, subtracting in the folding step, and adding in the high part
&gt; later. But one doesn't have to do it that way. One could instead use a
&gt; FOLD macro that computes
&gt;
&gt;   (2^{192} - 2^{160} + 2^{128} + 2^{32}) U0
&gt;
&gt; I also wonder of there's some way to use carry out from one fold step
&gt; and apply it at the right place while preparing the F0,F1,F2,F3 for the next step.

I've got this working now, attaching the version with early carry
folding. Also checked in on the branch arm64-ecc. The preceding commit
(5ee0839bb28c092044fce09534651b78640518c4) collects carries and adds
them in as a separate pass over the data.

I've tested it only with Tested only with qemu-aarch64, help with
benchmarking on real arm64 hardware appreciated (just add the file in
the arm64/ directory and run ./config.status --recheck &amp;&amp;
./config.status have the build pick it up).

I think the approach should apply to other 64-bit archs (should probably
work also on x86_64, where it's sometimes tricky to avoid x86_64
instructions clobbering the carry flag when it should be preserved, but
probably not so difficult in this case).


["ecc-secp256r1-redc.asm" (text/plain)]

C arm64/ecc-secp256r1-redc.asm

ifelse(`
   Copyright (C) 2013, 2021 Niels Möller

   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

	.file "ecc-secp256r1-redc.asm"

define(`RP', `x1')
define(`XP', `x2')

define(`U0', `x0') C Overlaps unused modulo input
define(`U1', `x3')
define(`U2', `x4')
define(`U3', `x5')
define(`U4', `x6')
define(`U5', `x7')
define(`U6', `x8')
define(`U7', `x9')
define(`F0', `x10')
define(`F1', `x11')
define(`F2', `x12')
define(`F3', `x13')
define(`ZERO', `x14')

C FOLD(x), sets (F3, F2,F1,F0 )  &lt;--  (x &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt; 32)
define(`FOLD', `
	lsl	F0, $1, #32
	lsr	F1, $1, #32
	subs	F2, $1, F0
	sbc	F3, $1, F1
')

C FOLDC(x), sets (F3, F2,F1,F0)  &lt;--  ((x+c) &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt; 32)
define(`FOLDC', `
	lsl	F0, $1, #32
	lsr	F1, $1, #32
	adc	F3, $1, ZERO	C May overflow, but final result will not.
	subs	F2, $1, F0
	sbc	F3, F3, F1
')

PROLOGUE(_nettle_ecc_secp256r1_redc)
	ldr	U0, [XP]
	ldr	U1, [XP, #8]
	ldr	U2, [XP, #16]
	ldr	U3, [XP, #24]
	ldr	U4, [XP, #32]
	ldr	U5, [XP, #40]
	ldr	U6, [XP, #48]
	ldr	U7, [XP, #56]
	mov	ZERO, #0

	FOLD(U0)
	adds	U1, U1, F0
	adcs	U2, U2, F1
	adcs	U3, U3, F2
	adcs	U4, U4, F3

	FOLDC(U1)
	adds	U2, U2, F0
	adcs	U3, U3, F1
	adcs	U4, U4, F2
	adcs	U5, U5, F3

	FOLDC(U2)
	adds	U3, U3, F0
	adcs	U4, U4, F1
	adcs	U5, U5, F2
	adcs	U6, U6, F3

	FOLDC(U3)
	adds	U4, U4, F0
	adcs	U5, U5, F1
	adcs	U6, U6, F2
	adcs	U7, U7, F3

	C Sum, including carry, is &lt; 2^{256} + p.
	C If carry, we need to add in 2^{256} mod p = 2^{256} - p
	C     = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
	C and this addition can not overflow.
	adc	F0, ZERO, ZERO
	neg	F2, F0
	lsl	F1, F2, #32
	lsr	F3, F2, #32
	and	F3, F3, #-2

	adds	U0, F0, U4
	adcs	U1, F1, U5
	adcs	U2, F2, U6
	adc	U3, F3, U7

	str	U0, [RP]
	str	U1, [RP, #8]
	str	U2, [RP, #16]
	str	U3, [RP, #24]

	ret
EPILOGUE(_nettle_ecc_secp256r1_redc)


Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20211206080115</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-06 08:01:15-0400</timestampReceived><subject>Re: ANNOUNCE: Serious bug in Nettle's ecdsa_verify - Critical Confirmation</subject><body>

"Jayakumar, Jaikanth" &lt;jaikanth.jayakumar1@optum.com&gt; writes:

&gt; There is a small confusion, I believe the bug reported here
&gt; (https://lists.lysator.liu.se/pipermail/nettle-bugs/2021/009457.html)
&gt; is related to CVE-2021-20305, right ? and this (CVE-2021-20305) is
&gt; fixed in version 3.7.2.

Which *two* problems are you asking about? The problem referred to as 
https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-20305
was fixed in nettle-3.7.2. 

Then there was a different problem, in RSA decryption,
https://cve.mitre.org/cgi-bin/cvename.cgi?name=2021-3580, fixed in
nettle-3.7.3.

&gt; In the case it is the same, it would help big time if the CVE was
&gt; mentioned somewhere in the bug announcement thread.

I'll try to remember to mention relevant CVE ids in future release
announcements. Would help to also document in the NEWS file?

Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211206084931</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-06 08:49:31-0400</timestampReceived><subject>Re: [PATCH v2 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Hi Niels,

On 12/3/21 4:09 AM, Niels Möller wrote:
&gt; Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:
&gt; 
&gt;&gt; Hi Niels,
&gt;&gt;
&gt;&gt;&gt; Would you mind writing a short description of the algorithm for the
&gt;&gt;&gt; manual? I think it should go under "Miscellaneous hash functions". Would
&gt;&gt;&gt; be nice with some brief background on this hash function (origin,
&gt;&gt;&gt; intended applications, when and where it's useful) plus reference docs
&gt;&gt;&gt; for the defined constants and functions.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; SM3 is a cryptographic hash function standard adopted by the
&gt;&gt; government of the People's Republic of China, which was issued by the
&gt;&gt; Cryptography Standardization Technical Committee of China on December
&gt;&gt; 17, 2010. The corresponding standard is "GM/T 0004-2012 "SM3
&gt;&gt; Cryptographic Hash Algorithm"".
&gt;&gt;
&gt;&gt; SM3 algorithm is a hash algorithm in ShangMi cryptosystems. SM3 is
&gt;&gt; mainly used for digital signature and verification, message
&gt;&gt; authentication code generation and verification, random number
&gt;&gt; generation, etc.
&gt; 
&gt; Thanks for the backround.
&gt; 
&gt;&gt;                   Its algorithm is public. Combined with the public key
&gt;&gt; algorithm SM2 and the symmetric encryption algorithm SM4, it can be
&gt;&gt; used in various data security and network security scenarios such as
&gt;&gt; the TLS 1.3 protocol, disk encryption, standard digital certificates,
&gt;&gt; and digital signatures.
&gt; 
&gt; I think the above two sentences could be removed or shortened. I think
&gt; the mention of TLS, with reference to RFC 8998, is the part most
&gt; relevant for the Nettle manual. Besides that I think your text provides
&gt; right level of detail.
&gt; 

Will update in next patch.

&gt;&gt;                          According to the State Cryptography
&gt;&gt; Administration of China, its security and efficiency are equivalent to
&gt;&gt; SHA-256.
&gt; 
&gt; This is relevant too.
&gt; 
&gt;&gt; Thanks for your reminder, the above is the information I provided. Do
&gt;&gt; I need to submit it to the document through PATCH?
&gt; 
&gt; If you can prepare a patch for nettle.texinfo, that would be ideal.
&gt; 
&gt; Regards,
&gt; /Niels
&gt; 

Thanks for your suggestion, I will send another patch to update 
nettle.texinfo.

Best regards,
Tianjia
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211206212925</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-06 21:29:25-0400</timestampReceived><subject>x86_64 ecc_256_redc (was: Re: ARM64 ecc_256_redc)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I think the approach should apply to other 64-bit archs (should probably
&gt; work also on x86_64, where it's sometimes tricky to avoid x86_64
&gt; instructions clobbering the carry flag when it should be preserved, but
&gt; probably not so difficult in this case).

x86_64 version below. I could also trimmed register usage, so it no
longer needs to save and restore any registers. On my machine, this
gives a speedup of 17% for ecc_secp256r1_redc in isolation, 3% speedup
for ecdsa sign and 7% speedup of ecdsa verify.

Regards,
/Niels

C x86_64/ecc-secp256r1-redc.asm

ifelse(`
   Copyright (C) 2013, 2021 Niels Möller

   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

	.file "ecc-secp256r1-redc.asm"

define(`RP', `%rsi')
define(`XP', `%rdx')

define(`U0', `%rdi') C Overlaps unused modulo input
define(`U1', `%rcx')
define(`U2', `%rax')
define(`U3', `%r8')
define(`F0', `%r9')
define(`F1', `%r10')
define(`F2', `%r11')
define(`F3', `%rdx') C Overlap XP, used only in final carry folding

C FOLD(x), sets (x,F2,F1,F0 )  &lt;--  (x &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt; 32)
define(`FOLD', `
	mov	$1, F0
	mov	$1, F1
	mov	$1, F2
	shl	`$'32, F0
	shr	`$'32, F1
	sub	F0, F2
	sbb	F1, $1
')
C FOLDC(x), sets (x,F2,F1,F0)  &lt;--  ((x+c) &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt; 32)
define(`FOLDC', `
	mov	$1, F0
	mov	$1, F1
	mov	$1, F2
	adc	`$'0, $1
	shl	`$'32, F0
	shr	`$'32, F1
	sub	F0, F2
	sbb	F1, $1
')
PROLOGUE(_nettle_ecc_secp256r1_redc)
	W64_ENTRY(3, 0)

	mov	(XP), U0
	FOLD(U0)
	mov	8(XP), U1
	mov	16(XP), U2
	mov	24(XP), U3
	add	F0, U1
	adc	F1, U2
	adc	F2, U3
	adc	32(XP), U0

	FOLDC(U1)
	add	F0, U2
	adc	F1, U3
	adc	F2, U0
	adc	40(XP), U1

	FOLDC(U2)
	add	F0, U3
	adc	F1, U0
	adc	F2, U1
	adc	48(XP), U2

	FOLDC(U3)
	add	F0, U0
	adc	F1, U1
	adc	F2, U2
	adc	56(XP), U3

	C Sum, including carry, is &lt; 2^{256} + p.
	C If carry, we need to add in 2^{256} mod p = 2^{256} - p
	C     = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
	C and this addition can not overflow.
	sbb	F2, F2
	mov	F2, F0
	mov	F2, F1
	mov	XREG(F2), XREG(F3)
	neg	F0
	shl	$32, F1
	and	$-2, XREG(F3)

	add	F0, U0
	mov	U0, (RP)
	adc	F1, U1
	mov	U1, 8(RP)
	adc	F2, U2
	mov	U2, 16(RP)
	adc	F3, U3

	mov	U3, 24(RP)

	W64_EXIT(3, 0)
	ret
EPILOGUE(_nettle_ecc_secp256r1_redc)

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211207074439</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-12-07 07:44:39-0400</timestampReceived><subject>Re: [PATCH 3/7] ecc: Add powerpc64 assembly for ecc_256_redc</subject><body>

On Wed, 2021-12-01 at 22:58 +0100, Niels Möller wrote:
&gt; Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:
&gt; 
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/powerpc64/ecc-secp256r1-redc.asm
&gt; &gt; @@ -0,0 +1,144 @@
&gt; &gt; +C powerpc64/ecc-secp256r1-redc.asm
&gt; &gt; +ifelse(`
&gt; &gt; +   Copyright (C) 2021 Amitay Isaacs &amp; Martin Schwenke, IBM
&gt; &gt; Corporation
&gt; &gt; +
&gt; &gt; +   Based on x86_64/ecc-secp256r1-redc.asm
&gt; 
&gt; Looks good, and it seems method follows the x86_64 version closely. I
&gt; just checked in a correction and a clarification to the comments to
&gt; the
&gt; x86_64 version.
&gt; 
&gt; A few comments below.
&gt; 
&gt; &gt; +C Register usage:
&gt; &gt; +
&gt; &gt; +define(`SP', `r1')
&gt; &gt; +
&gt; &gt; +define(`RP', `r4')
&gt; &gt; +define(`XP', `r5')
&gt; &gt; +
&gt; &gt; +define(`F0', `r3')
&gt; &gt; +define(`F1', `r6')
&gt; &gt; +define(`F2', `r7')
&gt; &gt; +define(`F3', `r8')
&gt; &gt; +
&gt; &gt; +define(`U0', `r9')
&gt; &gt; +define(`U1', `r10')
&gt; &gt; +define(`U2', `r11')
&gt; &gt; +define(`U3', `r12')
&gt; &gt; +define(`U4', `r14')
&gt; &gt; +define(`U5', `r15')
&gt; &gt; +define(`U6', `r16')
&gt; &gt; +define(`U7', `r17')
&gt; 
&gt; One could save one register by letting U7 and XP overlap, since XP
&gt; isn't
&gt; used after loading U7.
&gt; 
&gt; &gt; +       .file "ecc-secp256r1-redc.asm"
&gt; &gt; +
&gt; &gt; +C FOLD(x), sets (F3,F2,F1,F0)  &lt;-- [(x &lt;&lt; 224) - (x &lt;&lt; 192) - (x
&gt; &gt; &lt;&lt; 96)] &gt;&gt; 64
&gt; &gt; +define(`FOLD', `
&gt; &gt; +       sldi    F2, $1, 32
&gt; &gt; +       srdi    F3, $1, 32
&gt; &gt; +       li      F0, 0
&gt; &gt; +       li      F1, 0
&gt; &gt; +       subfc   F0, F2, F0
&gt; &gt; +       subfe   F1, F3, F1
&gt; 
&gt; I think the 
&gt; 
&gt;         li      F0, 0
&gt;         li      F1, 0
&gt;         subfc   F0, F2, F0
&gt;         subfe   F1, F3, F1
&gt; 
&gt; could be replaced with 
&gt; 
&gt;         subfic  F0, F2, 0    C "negate with borrow"
&gt;         subfze  F1, F3 
&gt; 
&gt; If that is measurably faster, I can't say. 

You are quick to find the exactly fitting instruction.  Yes, it
definitely does the same job with two less instructions and gives about
1% speedup for only reduction code.

&gt; 
&gt; Another option: Since powerpc, like arm, seems to use the proper
&gt; two's
&gt; complement convention that "borrow" is not carry, maybe we don't need
&gt; to
&gt; negate to F0 and F1 at all, and instead change the later subtraction,
&gt; replacing
&gt; 
&gt;         subfc   U1, F0, U1
&gt;         subfe   U2, F1, U2
&gt;         subfe   U3, F2, U3
&gt;         subfe   U0, F3, U0
&gt; 
&gt; with
&gt; 
&gt;         addc    U1, F0, U1
&gt;         adde    U2, F1, U2
&gt;         subfe   U3, F2, U3
&gt;         subfe   U0, F3, U0
&gt; 
&gt; I haven't thought that through, but it does make some sense to me. I
&gt; think the arm code propagates carry through a mix of add and sub
&gt; instructions in a some places. Maybe F2 needs to be incremented
&gt; somewhere for this to work, but probably still cheaper. If this
&gt; works,
&gt; FOLD would turn into something like
&gt; 
&gt;         sldi    F0, $1, 32
&gt;         srdi    F1, $1, 32
&gt;         subfc   F2, $1, F0
&gt;         addme   F3, F1
&gt; 
&gt; (If you want to investigate this later on, that's fine too, I could
&gt; merge
&gt; the code with the current folding logic).
&gt; 
&gt; &gt; +       C If carry, we need to add in
&gt; &gt; +       C 2^256 - p = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
&gt; &gt; +       li      F0, 0
&gt; &gt; +       addze   F0, F0
&gt; &gt; +       neg     F2, F0
&gt; &gt; +       sldi    F1, F2, 32
&gt; &gt; +       srdi    F3, F2, 32
&gt; &gt; +       li      U7, -2
&gt; &gt; +       and     F3, F3, U7
&gt; 
&gt; I think the three instructions to set F3 could be replaced with
&gt; 
&gt;         srdi    F3, F2, 31
&gt;         sldi    F3, F3, 1
&gt; 
&gt; Or maybe the and operation is faster than shift?
&gt; 
&gt; Regards,
&gt; /Niels

I will continue to investigate the suggestions you have made.

Amitay.
-- 

There are two times in a man's life when he should not speculate: when
he
can't afford it, and when he can. - Mark Twain
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211207203805</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-07 20:38:05-0400</timestampReceived><subject>Re: [PATCH] doc: documentation fot SM3 hash</subject><body>

Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:

&gt; Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
&gt; ---
&gt;  nettle.texinfo | 74 ++++++++++++++++++++++++++++++++++++++++++++++++--
&gt;  1 file changed, 72 insertions(+), 2 deletions(-)

Thanks! Merged now.

Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211209211612</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-09 21:16:12-0400</timestampReceived><subject>Re: powerpc ecc 256 redc (was Re: x86_64 ecc_256_redc)</subject><body>

nisse@lysator.liu.se (Niels M=C3=B6ller) writes:

&gt; Thanks! Merged to master-updates for ci testing.

And now merged to the master branch.

&gt; I think it should be possible to reduce number of needed registers, and
&gt; completely avoid using callee-save registers (load the values now in
&gt; U4-U7 one at a time a bit closer to the place where they are needed in),
&gt; and replace F3 with $1 in the FOLD and FOLDC macros.

Attaching a variant to do this. Passes tests with qemu, but I haven't
benchmarked it on any real hardware.



C powerpc64/ecc-secp256r1-redc.asm

ifelse(`
   Copyright (C) 2021 Amitay Isaacs &amp; Martin Schwenke, IBM Corporation

   Based on x86_64/ecc-secp256r1-redc.asm

   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C Register usage:

define(`RP', `r4')
define(`XP', `r5')

define(`F0', `r3')
define(`F1', `r6')
define(`F2', `r7')
define(`T', `r8')

define(`U0', `r9')
define(`U1', `r10')
define(`U2', `r11')
define(`U3', `r12')

	.file "ecc-secp256r1-redc.asm"

C FOLD(x), sets (x,F2,F1,F0)  &lt;-- [(x &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt;32)]
define(`FOLD', `
	sldi	F0, $1, 32
	srdi	F1, $1, 32
	subfc	F2, F0, $1
	subfe	$1, F1, $1
')

C FOLDC(x), sets (x,F2,F1,F0)  &lt;-- [((x+c) &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt;32)]
define(`FOLDC', `
	sldi	F0, $1, 32
	srdi	F1, $1, 32
	addze	T, $1
	subfc	F2, F0, $1
	subfe	$1, F1, T
')

	C void ecc_secp256r1_redc (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
	.text
define(`FUNC_ALIGN', `5')
PROLOGUE(_nettle_ecc_secp256r1_redc)

	ld	U0, 0(XP)
	ld	U1, 8(XP)
	ld	U2, 16(XP)
	ld	U3, 24(XP)

	FOLD(U0)
	ld	T, 32(XP)
	addc	U1, F0, U1
	adde	U2, F1, U2
	adde	U3, F2, U3
	adde	U0, U0, T

	FOLDC(U1)
	ld	T, 40(XP)
	addc	U2, F0, U2
	adde	U3, F1, U3
	adde	U0, F2, U0
	adde	U1, U1, T

	FOLDC(U2)
	ld	T, 48(XP)
	addc	U3, F0, U3
	adde	U0, F1, U0
	adde	U1, F2, U1
	adde	U2, U2, T

	FOLDC(U3)
	ld	T, 56(XP)
	addc	U0, F0, U0
	adde	U1, F1, U1
	adde	U2, F2, U2
	adde	U3, U3, T

	C If carry, we need to add in
	C 2^256 - p = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
	li	F0, 0
	addze	F0, F0
	neg	F2, F0
	sldi	F1, F2, 32
	srdi	T, F2, 32
	li	XP, -2
	and	T, T, XP

	addc	U0, F0, U0
	adde	U1, F1, U1
	adde	U2, F2, U2
	adde	U3, T, U3

	std	U0, 0(RP)
	std	U1, 8(RP)
	std	U2, 16(RP)
	std	U3, 24(RP)

	blr
EPILOGUE(_nettle_ecc_secp256r1_redc)


&gt; Regards,
&gt; /Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20211213081939</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:39-0400</timestampReceived><subject>[PATCH 0/7] Introduce SM4 symmetric cipher algorithm</subject><body>

SM4 is a block cipher standard published by the government of the People's
Republic of China, and it was issued by the State Cryptography Administration
on March 21, 2012. The standard is GM/T 0002-2012 "SM4 block cipher algorithm".

SM4 algorithm is a symmetric cipher algorithm in ShangMi cryptosystems. The
block length and key length are both 128 bits. Both the encryption algorithm
and the key derivation algorithm use 32 rounds of non-linear iterative
structure, and the S box is a fixed 8 bits. The RFC 8998 specification
defines the usage of ShangMi algorithm suite in TLS 1.3, etc. According to
the State Cryptography Administration of China, its security and efficiency
are equivalent to AES-128.

Reference specification:
1. http://www.gmbz.org.cn/upload/2018-04-04/1522788048733065051.pdf
2. http://gmbz.org.cn/main/viewfile/20180108015408199368.html
3. https://tools.ietf.org/id/draft-ribose-cfrg-sm4-10.html
4. https://datatracker.ietf.org/doc/html/rfc8998

Tianjia Zhang (7):
  doc: Add Copyright of SM3 hash algorithm
  Introduce SM4 symmetric cipher algorithm
  testsuite: add test for SM4 symmetric algorithm
  nettle-benchmark: bench SM4 symmetric algorithm
  doc: documentation for SM4 cipher algorithm
  gcm: Add SM4 as the GCM underlying cipher
  doc: documentation for GCM using SM4 cipher

 Makefile.in                  |   2 +
 examples/nettle-benchmark.c  |   2 +
 gcm-sm4-meta.c               |  60 ++++++++++
 gcm-sm4.c                    |  81 +++++++++++++
 gcm.h                        |  25 +++-
 nettle-meta-aeads.c          |   1 +
 nettle-meta-ciphers.c        |   1 +
 nettle-meta.h                |   3 +
 nettle.texinfo               |  81 +++++++++++++
 sm4-meta.c                   |  49 ++++++++
 sm4.c                        | 225 +++++++++++++++++++++++++++++++++++
 sm4.h                        |  71 +++++++++++
 testsuite/.gitignore         |   1 +
 testsuite/Makefile.in        |   2 +-
 testsuite/gcm-test.c         |  18 +++
 testsuite/meta-aead-test.c   |   1 +
 testsuite/meta-cipher-test.c |   3 +-
 testsuite/sm4-test.c         |  19 +++
 18 files changed, 642 insertions(+), 3 deletions(-)
 create mode 100644 gcm-sm4-meta.c
 create mode 100644 gcm-sm4.c
 create mode 100644 sm4-meta.c
 create mode 100644 sm4.c
 create mode 100644 sm4.h
 create mode 100644 testsuite/sm4-test.c

-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081940</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:40-0400</timestampReceived><subject>[PATCH 1/7] doc: Add Copyright of SM3 hash algorithm</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 nettle.texinfo | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/nettle.texinfo b/nettle.texinfo
index 76934637..45b06720 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -293,6 +293,10 @@ Written by @value{AUTHOR}, using Peter Gutmann's SHA1 code as a model.
 @item SHA3
 Written by @value{AUTHOR}.
 
+@item SM3
+The C implementation of the SM3 message digest is written by Tianjia
+Zhang, and the code is based on the implementation by Jia Zhang.
+
 @item TWOFISH
 The implementation of the TWOFISH cipher is written by Ruud de Rooij.
 
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081941</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:41-0400</timestampReceived><subject>[PATCH 2/7] Introduce SM4 symmetric cipher algorithm</subject><body>

Introduce the SM4 cipher algorithms (OSCCA GB/T 32907-2016).

SM4 (GBT.32907-2016) is a cryptographic standard issued by the
Organization of State Commercial Administration of China (OSCCA)
as an authorized cryptographic algorithms for the use within China.

SMS4 was originally created for use in protecting wireless
networks, and is mandated in the Chinese National Standard for
Wireless LAN WAPI (Wired Authentication and Privacy Infrastructure)
(GB.15629.11-2003).

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in                  |   1 +
 nettle-meta-ciphers.c        |   1 +
 nettle-meta.h                |   2 +
 sm4-meta.c                   |  49 ++++++++
 sm4.c                        | 225 +++++++++++++++++++++++++++++++++++
 sm4.h                        |  71 +++++++++++
 testsuite/meta-cipher-test.c |   3 +-
 7 files changed, 351 insertions(+), 1 deletion(-)
 create mode 100644 sm4-meta.c
 create mode 100644 sm4.c
 create mode 100644 sm4.h

diff --git a/Makefile.in b/Makefile.in
index 0590c370..62511df4 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -150,6 +150,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 serpent-meta.c \
 		 streebog.c streebog-meta.c \
 		 twofish.c twofish-meta.c \
+		 sm4.c sm4-meta.c \
 		 umac-nh.c umac-nh-n.c umac-l2.c umac-l3.c \
 		 umac-poly64.c umac-poly128.c umac-set-key.c \
 		 umac32.c umac64.c umac96.c umac128.c \
diff --git a/nettle-meta-ciphers.c b/nettle-meta-ciphers.c
index 49cb47a7..f8d691cf 100644
--- a/nettle-meta-ciphers.c
+++ b/nettle-meta-ciphers.c
@@ -54,6 +54,7 @@ const struct nettle_cipher * const _nettle_ciphers[] = {
   &amp;nettle_arctwo64,
   &amp;nettle_arctwo128,
   &amp;nettle_arctwo_gutmann128,
+  &amp;nettle_sm4,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index d684947e..3d0440e8 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -89,6 +89,8 @@ extern const struct nettle_cipher nettle_arctwo64;
 extern const struct nettle_cipher nettle_arctwo128;
 extern const struct nettle_cipher nettle_arctwo_gutmann128;
 
+extern const struct nettle_cipher nettle_sm4;
+
 struct nettle_hash
 {
   const char *name;
diff --git a/sm4-meta.c b/sm4-meta.c
new file mode 100644
index 00000000..ef462299
--- /dev/null
+++ b/sm4-meta.c
@@ -0,0 +1,49 @@
+/* sm4-meta.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "sm4.h"
+
+const struct nettle_cipher nettle_sm4 = {
+  "sm4",
+  sizeof(struct sm4_ctx),
+  SM4_BLOCK_SIZE,
+  SM4_KEY_SIZE,
+  (nettle_set_key_func *) sm4_set_key,
+  (nettle_set_key_func *) sm4_set_key,
+  (nettle_cipher_func *) sm4_encrypt,
+  (nettle_cipher_func *) sm4_decrypt
+};
diff --git a/sm4.c b/sm4.c
new file mode 100644
index 00000000..662e83df
--- /dev/null
+++ b/sm4.c
@@ -0,0 +1,225 @@
+/* sm4.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+
+#include "sm4.h"
+
+#include "macros.h"
+
+
+static const uint32_t fk[4] =
+{
+  0xa3b1bac6, 0x56aa3350, 0x677d9197, 0xb27022dc
+};
+
+static const uint32_t ck[32] =
+{
+  0x00070e15, 0x1c232a31, 0x383f464d, 0x545b6269,
+  0x70777e85, 0x8c939aa1, 0xa8afb6bd, 0xc4cbd2d9,
+  0xe0e7eef5, 0xfc030a11, 0x181f262d, 0x343b4249,
+  0x50575e65, 0x6c737a81, 0x888f969d, 0xa4abb2b9,
+  0xc0c7ced5, 0xdce3eaf1, 0xf8ff060d, 0x141b2229,
+  0x30373e45, 0x4c535a61, 0x686f767d, 0x848b9299,
+  0xa0a7aeb5, 0xbcc3cad1, 0xd8dfe6ed, 0xf4fb0209,
+  0x10171e25, 0x2c333a41, 0x484f565d, 0x646b7279
+};
+
+static const uint8_t sbox[256] =
+{
+  0xd6, 0x90, 0xe9, 0xfe, 0xcc, 0xe1, 0x3d, 0xb7,
+  0x16, 0xb6, 0x14, 0xc2, 0x28, 0xfb, 0x2c, 0x05,
+  0x2b, 0x67, 0x9a, 0x76, 0x2a, 0xbe, 0x04, 0xc3,
+  0xaa, 0x44, 0x13, 0x26, 0x49, 0x86, 0x06, 0x99,
+  0x9c, 0x42, 0x50, 0xf4, 0x91, 0xef, 0x98, 0x7a,
+  0x33, 0x54, 0x0b, 0x43, 0xed, 0xcf, 0xac, 0x62,
+  0xe4, 0xb3, 0x1c, 0xa9, 0xc9, 0x08, 0xe8, 0x95,
+  0x80, 0xdf, 0x94, 0xfa, 0x75, 0x8f, 0x3f, 0xa6,
+  0x47, 0x07, 0xa7, 0xfc, 0xf3, 0x73, 0x17, 0xba,
+  0x83, 0x59, 0x3c, 0x19, 0xe6, 0x85, 0x4f, 0xa8,
+  0x68, 0x6b, 0x81, 0xb2, 0x71, 0x64, 0xda, 0x8b,
+  0xf8, 0xeb, 0x0f, 0x4b, 0x70, 0x56, 0x9d, 0x35,
+  0x1e, 0x24, 0x0e, 0x5e, 0x63, 0x58, 0xd1, 0xa2,
+  0x25, 0x22, 0x7c, 0x3b, 0x01, 0x21, 0x78, 0x87,
+  0xd4, 0x00, 0x46, 0x57, 0x9f, 0xd3, 0x27, 0x52,
+  0x4c, 0x36, 0x02, 0xe7, 0xa0, 0xc4, 0xc8, 0x9e,
+  0xea, 0xbf, 0x8a, 0xd2, 0x40, 0xc7, 0x38, 0xb5,
+  0xa3, 0xf7, 0xf2, 0xce, 0xf9, 0x61, 0x15, 0xa1,
+  0xe0, 0xae, 0x5d, 0xa4, 0x9b, 0x34, 0x1a, 0x55,
+  0xad, 0x93, 0x32, 0x30, 0xf5, 0x8c, 0xb1, 0xe3,
+  0x1d, 0xf6, 0xe2, 0x2e, 0x82, 0x66, 0xca, 0x60,
+  0xc0, 0x29, 0x23, 0xab, 0x0d, 0x53, 0x4e, 0x6f,
+  0xd5, 0xdb, 0x37, 0x45, 0xde, 0xfd, 0x8e, 0x2f,
+  0x03, 0xff, 0x6a, 0x72, 0x6d, 0x6c, 0x5b, 0x51,
+  0x8d, 0x1b, 0xaf, 0x92, 0xbb, 0xdd, 0xbc, 0x7f,
+  0x11, 0xd9, 0x5c, 0x41, 0x1f, 0x10, 0x5a, 0xd8,
+  0x0a, 0xc1, 0x31, 0x88, 0xa5, 0xcd, 0x7b, 0xbd,
+  0x2d, 0x74, 0xd0, 0x12, 0xb8, 0xe5, 0xb4, 0xb0,
+  0x89, 0x69, 0x97, 0x4a, 0x0c, 0x96, 0x77, 0x7e,
+  0x65, 0xb9, 0xf1, 0x09, 0xc5, 0x6e, 0xc6, 0x84,
+  0x18, 0xf0, 0x7d, 0xec, 0x3a, 0xdc, 0x4d, 0x20,
+  0x79, 0xee, 0x5f, 0x3e, 0xd7, 0xcb, 0x39, 0x48
+};
+
+static uint32_t
+sm4_t_non_lin_sub(uint32_t x)
+{
+  uint32_t out;
+
+  out  = (uint32_t)sbox[x &amp; 0xff];
+  out |= (uint32_t)sbox[(x &gt;&gt; 8) &amp; 0xff] &lt;&lt; 8;
+  out |= (uint32_t)sbox[(x &gt;&gt; 16) &amp; 0xff] &lt;&lt; 16;
+  out |= (uint32_t)sbox[(x &gt;&gt; 24) &amp; 0xff] &lt;&lt; 24;
+
+  return out;
+}
+
+static uint32_t
+sm4_key_lin_sub(uint32_t x)
+{
+  return x ^ ROTL32(13, x) ^ ROTL32(23, x);
+}
+
+static uint32_t
+sm4_enc_lin_sub(uint32_t x)
+{
+  return x ^ ROTL32(2, x) ^ ROTL32(10, x) ^ ROTL32(18, x) ^ ROTL32(24, x);
+}
+
+static uint32_t
+sm4_key_sub(uint32_t x)
+{
+  return sm4_key_lin_sub(sm4_t_non_lin_sub(x));
+}
+
+static uint32_t
+sm4_enc_sub(uint32_t x)
+{
+  return sm4_enc_lin_sub(sm4_t_non_lin_sub(x));
+}
+
+static uint32_t
+sm4_round(uint32_t x0, uint32_t x1, uint32_t x2, uint32_t x3, uint32_t rk)
+{
+  return x0 ^ sm4_enc_sub(x1 ^ x2 ^ x3 ^ rk);
+}
+
+void
+sm4_set_key(struct sm4_ctx *ctx, const uint8_t *key)
+{
+  uint32_t rk[4];
+  int i;
+
+  rk[0] = READ_UINT32(key +  0) ^ fk[0];
+  rk[1] = READ_UINT32(key +  4) ^ fk[1];
+  rk[2] = READ_UINT32(key +  8) ^ fk[2];
+  rk[3] = READ_UINT32(key + 12) ^ fk[3];
+
+  for (i = 0; i &lt; 32; i += 4)
+    {
+      rk[0] ^= sm4_key_sub(rk[1] ^ rk[2] ^ rk[3] ^ ck[i + 0]);
+      rk[1] ^= sm4_key_sub(rk[2] ^ rk[3] ^ rk[0] ^ ck[i + 1]);
+      rk[2] ^= sm4_key_sub(rk[3] ^ rk[0] ^ rk[1] ^ ck[i + 2]);
+      rk[3] ^= sm4_key_sub(rk[0] ^ rk[1] ^ rk[2] ^ ck[i + 3]);
+
+      ctx-&gt;rkey_enc[i + 0] = rk[0];
+      ctx-&gt;rkey_enc[i + 1] = rk[1];
+      ctx-&gt;rkey_enc[i + 2] = rk[2];
+      ctx-&gt;rkey_enc[i + 3] = rk[3];
+      ctx-&gt;rkey_dec[31 - 0 - i] = rk[0];
+      ctx-&gt;rkey_dec[31 - 1 - i] = rk[1];
+      ctx-&gt;rkey_dec[31 - 2 - i] = rk[2];
+      ctx-&gt;rkey_dec[31 - 3 - i] = rk[3];
+    }
+}
+
+static void
+sm4_crypt_block(const uint32_t *rk, uint8_t *dst, const uint8_t *src)
+{
+  uint32_t x[4], i;
+
+  x[0] = READ_UINT32(src + 0 * 4);
+  x[1] = READ_UINT32(src + 1 * 4);
+  x[2] = READ_UINT32(src + 2 * 4);
+  x[3] = READ_UINT32(src + 3 * 4);
+
+  for (i = 0; i &lt; 32; i += 4)
+    {
+      x[0] = sm4_round(x[0], x[1], x[2], x[3], rk[i + 0]);
+      x[1] = sm4_round(x[1], x[2], x[3], x[0], rk[i + 1]);
+      x[2] = sm4_round(x[2], x[3], x[0], x[1], rk[i + 2]);
+      x[3] = sm4_round(x[3], x[0], x[1], x[2], rk[i + 3]);
+    }
+
+  WRITE_UINT32(dst + 0 * 4, x[3 - 0]);
+  WRITE_UINT32(dst + 1 * 4, x[3 - 1]);
+  WRITE_UINT32(dst + 2 * 4, x[3 - 2]);
+  WRITE_UINT32(dst + 3 * 4, x[3 - 3]);
+}
+
+void
+sm4_encrypt(const struct sm4_ctx *context,
+	    size_t length,
+	    uint8_t *dst,
+	    const uint8_t *src)
+{
+  const uint32_t *keys = context-&gt;rkey_enc;
+
+  assert( !(length % SM4_BLOCK_SIZE) );
+  for ( ; length; length -= SM4_BLOCK_SIZE)
+    {
+      sm4_crypt_block(keys, dst, src);
+      src += SM4_BLOCK_SIZE;
+      dst += SM4_BLOCK_SIZE;
+    }
+}
+
+void
+sm4_decrypt(const struct sm4_ctx *context,
+	    size_t length,
+	    uint8_t *dst,
+	    const uint8_t *src)
+{
+  const uint32_t *keys = context-&gt;rkey_dec;
+
+  assert( !(length % SM4_BLOCK_SIZE) );
+  for ( ; length; length -= SM4_BLOCK_SIZE)
+    {
+      sm4_crypt_block(keys, dst, src);
+      src += SM4_BLOCK_SIZE;
+      dst += SM4_BLOCK_SIZE;
+    }
+}
diff --git a/sm4.h b/sm4.h
new file mode 100644
index 00000000..a55d99c7
--- /dev/null
+++ b/sm4.h
@@ -0,0 +1,71 @@
+/* sm4.h
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#ifndef NETTLE_SM4_H_INCLUDED
+#define NETTLE_SM4_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define sm4_set_key nettle_sm4_set_key
+#define sm4_encrypt nettle_sm4_encrypt
+#define sm4_decrypt nettle_sm4_decrypt
+
+#define SM4_BLOCK_SIZE 16
+#define SM4_KEY_SIZE 16
+
+struct sm4_ctx
+{
+  uint32_t rkey_enc[32];
+  uint32_t rkey_dec[32];
+};
+
+void
+sm4_set_key(struct sm4_ctx *ctx, const uint8_t *key);
+
+void
+sm4_encrypt(const struct sm4_ctx *ctx,
+	    size_t length, uint8_t *dst,
+	    const uint8_t *src);
+void
+sm4_decrypt(const struct sm4_ctx *ctx,
+	    size_t length, uint8_t *dst,
+	    const uint8_t *src);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_SM4_H_INCLUDED */
diff --git a/testsuite/meta-cipher-test.c b/testsuite/meta-cipher-test.c
index f949fd76..62488b7f 100644
--- a/testsuite/meta-cipher-test.c
+++ b/testsuite/meta-cipher-test.c
@@ -18,7 +18,8 @@ const char* ciphers[] = {
   "serpent256",
   "twofish128",
   "twofish192",
-  "twofish256"
+  "twofish256",
+  "sm4"
 };
 
 void
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081942</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:42-0400</timestampReceived><subject>[PATCH 3/7] testsuite: add test for SM4 symmetric algorithm</subject><body>

Add a testuite for SM4 symmetric algorithm. Test vectors are based
on: https://tools.ietf.org/id/draft-ribose-cfrg-sm4-10.html

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 testsuite/.gitignore  |  1 +
 testsuite/Makefile.in |  2 +-
 testsuite/sm4-test.c  | 19 +++++++++++++++++++
 3 files changed, 21 insertions(+), 1 deletion(-)
 create mode 100644 testsuite/sm4-test.c

diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index ca41472e..07127d2b 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -98,6 +98,7 @@
 /sha512-256-test
 /sha512-test
 /sm3-test
+/sm4-test
 /streebog-test
 /twofish-test
 /umac-test
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 6734d3e6..c2662826 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -24,7 +24,7 @@ TS_NETTLE_SOURCES = aes-test.c aes-keywrap-test.c arcfour-test.c arctwo-test.c \
 		    sha384-test.c sha512-test.c sha512-224-test.c sha512-256-test.c \
 		    sha3-permute-test.c sha3-224-test.c sha3-256-test.c \
 		    sha3-384-test.c sha3-512-test.c \
-		    shake256-test.c streebog-test.c sm3-test.c \
+		    shake256-test.c streebog-test.c sm3-test.c sm4-test.c \
 		    serpent-test.c twofish-test.c version-test.c \
 		    knuth-lfib-test.c \
 		    cbc-test.c cfb-test.c ctr-test.c gcm-test.c eax-test.c ccm-test.c \
diff --git a/testsuite/sm4-test.c b/testsuite/sm4-test.c
new file mode 100644
index 00000000..97d9d58a
--- /dev/null
+++ b/testsuite/sm4-test.c
@@ -0,0 +1,19 @@
+#include "testutils.h"
+#include "sm4.h"
+
+void
+test_main(void)
+{
+  /* test vectors from:
+   * https://tools.ietf.org/id/draft-ribose-cfrg-sm4-10.html
+   */
+  test_cipher(&amp;nettle_sm4,
+	      SHEX("0123456789ABCDEF FEDCBA9876543210"),
+	      SHEX("0123456789ABCDEF FEDCBA9876543210"),
+	      SHEX("681EDF34D206965E 86B3E94F536E4246"));
+
+  test_cipher(&amp;nettle_sm4,
+	      SHEX("FEDCBA9876543210 0123456789ABCDEF"),
+	      SHEX("0001020304050607 08090A0B0C0D0E0F"),
+	      SHEX("F766678F13F01ADE AC1B3EA955ADB594"));
+}
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081943</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:43-0400</timestampReceived><subject>[PATCH 4/7] nettle-benchmark: bench SM4 symmetric algorithm</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 examples/nettle-benchmark.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index ba5dd284..802a7234 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -63,6 +63,7 @@
 #include "sha1.h"
 #include "sha2.h"
 #include "sha3.h"
+#include "sm4.h"
 #include "twofish.h"
 #include "umac.h"
 #include "cmac.h"
@@ -926,6 +927,7 @@ main(int argc, char **argv)
       &amp;nettle_des3,
       &amp;nettle_serpent256,
       &amp;nettle_twofish128, &amp;nettle_twofish192, &amp;nettle_twofish256,
+      &amp;nettle_sm4,
       NULL
     };
 
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081944</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:44-0400</timestampReceived><subject>[PATCH 5/7] doc: documentation for SM4 cipher algorithm</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 nettle.texinfo | 39 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 39 insertions(+)

diff --git a/nettle.texinfo b/nettle.texinfo
index 45b06720..a291dc7e 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -297,6 +297,9 @@ Written by @value{AUTHOR}.
 The C implementation of the SM3 message digest is written by Tianjia
 Zhang, and the code is based on the implementation by Jia Zhang.
 
+@item SM4
+The implementation of the SM4 cipher is written by Tianjia Zhang.
+
 @item TWOFISH
 The implementation of the TWOFISH cipher is written by Ruud de Rooij.
 
@@ -2277,6 +2280,42 @@ in any other way.
 Analogous to @code{twofish_encrypt}
 @end deftypefun
 
+@node SM4
+@subsection SM4
+@cindex SM4
+
+SM4 is a block cipher standard adopted by the government of the People's
+Republic of China, and it was issued by the State Cryptography Administration
+on March 21, 2012. The standard is GM/T 0002-2012 "SM4 block cipher algorithm".
+Nettle defines it in @file{&lt;nettle/sm4.h&gt;}.
+
+@deftp {Context struct} {struct sm4_ctx}
+@end deftp
+
+@defvr Constant SM4_BLOCK_SIZE
+The SM4 block-size, 16.
+@end defvr
+
+@defvr Constant SM4_KEY_SIZE
+Default SM4 key size, 16.
+@end defvr
+
+@deftypefun void sm4_set_key (struct sm4_ctx *@var{ctx}, size_t @var{length}, const \
uint8_t *@var{key}) +Initialize the cipher. The same function is used for both \
encryption and +decryption.
+@end deftypefun
+
+@deftypefun void sm4_encrypt (struct sm4_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{dst}, const uint8_t *@var{src}) +Encryption function. @var{length} must \
be an integral multiple of the +block size. If it is more than one block, the data is \
processed in ECB +mode. @code{src} and @code{dst} may be equal, but they must not \
overlap +in any other way.
+@end deftypefun
+
+@deftypefun void sm4_decrypt (struct sm4_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{dst}, const uint8_t *@var{src}) +Analogous to @code{sm4_encrypt}
+@end deftypefun
+
 @node nettle_cipher abstraction
 @subsection The @code{struct nettle_cipher} abstraction
 @cindex nettle_cipher
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20211213081945</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:45-0400</timestampReceived><subject>[PATCH 6/7] gcm: Add SM4 as the GCM underlying cipher</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in                |  1 +
 gcm-sm4-meta.c             | 60 ++++++++++++++++++++++++++++
 gcm-sm4.c                  | 81 ++++++++++++++++++++++++++++++++++++++
 gcm.h                      | 25 +++++++++++-
 nettle-meta-aeads.c        |  1 +
 nettle-meta.h              |  1 +
 testsuite/gcm-test.c       | 18 +++++++++
 testsuite/meta-aead-test.c |  1 +
 8 files changed, 187 insertions(+), 1 deletion(-)
 create mode 100644 gcm-sm4-meta.c
 create mode 100644 gcm-sm4.c

diff --git a/Makefile.in b/Makefile.in
index 62511df4..a4c45201 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -112,6 +112,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 gcm-aes256.c gcm-aes256-meta.c \
 		 gcm-camellia128.c gcm-camellia128-meta.c \
 		 gcm-camellia256.c gcm-camellia256-meta.c \
+		 gcm-sm4.c gcm-sm4-meta.c \
 		 cmac.c cmac64.c cmac-aes128.c cmac-aes256.c cmac-des3.c \
 		 cmac-aes128-meta.c cmac-aes256-meta.c cmac-des3-meta.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
diff --git a/gcm-sm4-meta.c b/gcm-sm4-meta.c
new file mode 100644
index 00000000..dc7bd1ae
--- /dev/null
+++ b/gcm-sm4-meta.c
@@ -0,0 +1,60 @@
+/* gcm-sm4-meta.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "nettle-meta.h"
+
+#include "gcm.h"
+
+static nettle_set_key_func gcm_sm4_set_nonce_wrapper;
+static void
+gcm_sm4_set_nonce_wrapper (void *ctx, const uint8_t *nonce)
+{
+  gcm_sm4_set_iv (ctx, GCM_IV_SIZE, nonce);
+}
+
+const struct nettle_aead nettle_gcm_sm4 =
+  { "gcm_sm4", sizeof(struct gcm_sm4_ctx),
+    GCM_BLOCK_SIZE, SM4_KEY_SIZE,
+    GCM_IV_SIZE, GCM_DIGEST_SIZE,
+    (nettle_set_key_func *) gcm_sm4_set_key,
+    (nettle_set_key_func *) gcm_sm4_set_key,
+    gcm_sm4_set_nonce_wrapper,
+    (nettle_hash_update_func *) gcm_sm4_update,
+    (nettle_crypt_func *) gcm_sm4_encrypt,
+    (nettle_crypt_func *) gcm_sm4_decrypt,
+    (nettle_hash_digest_func *) gcm_sm4_digest,
+  };
diff --git a/gcm-sm4.c b/gcm-sm4.c
new file mode 100644
index 00000000..70c1c6cf
--- /dev/null
+++ b/gcm-sm4.c
@@ -0,0 +1,81 @@
+/* gcm-sm4.c
+
+   Galois counter mode using SM4 as the underlying cipher.
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "gcm.h"
+
+void
+gcm_sm4_set_key(struct gcm_sm4_ctx *ctx, const uint8_t *key)
+{
+  GCM_SET_KEY(ctx, sm4_set_key, sm4_encrypt, key);
+}
+
+void
+gcm_sm4_set_iv (struct gcm_sm4_ctx *ctx,
+		size_t length, const uint8_t *iv)
+{
+  GCM_SET_IV (ctx, length, iv);
+}
+
+void
+gcm_sm4_update (struct gcm_sm4_ctx *ctx,
+		size_t length, const uint8_t *data)
+{
+  GCM_UPDATE (ctx, length, data);
+}
+
+void
+gcm_sm4_encrypt(struct gcm_sm4_ctx *ctx,
+		size_t length, uint8_t *dst, const uint8_t *src)
+{
+  GCM_ENCRYPT(ctx, sm4_encrypt, length, dst, src);
+}
+
+void
+gcm_sm4_decrypt(struct gcm_sm4_ctx *ctx,
+		size_t length, uint8_t *dst, const uint8_t *src)
+{
+  GCM_DECRYPT(ctx, sm4_encrypt, length, dst, src);
+}
+
+void
+gcm_sm4_digest(struct gcm_sm4_ctx *ctx,
+	       size_t length, uint8_t *digest)
+{
+  GCM_DIGEST(ctx, sm4_encrypt, length, digest);
+}
diff --git a/gcm.h b/gcm.h
index 96578530..2a35de3c 100644
--- a/gcm.h
+++ b/gcm.h
@@ -40,6 +40,7 @@
 
 #include "aes.h"
 #include "camellia.h"
+#include "sm4.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -95,6 +96,13 @@ extern "C" {
 #define gcm_camellia256_decrypt nettle_gcm_camellia256_decrypt
 #define gcm_camellia256_digest nettle_gcm_camellia256_digest
 
+#define gcm_sm4_set_key nettle_gcm_sm4_set_key
+#define gcm_sm4_set_iv nettle_gcm_sm4_set_iv
+#define gcm_sm4_update nettle_gcm_sm4_update
+#define gcm_sm4_encrypt nettle_gcm_sm4_encrypt
+#define gcm_sm4_decrypt nettle_gcm_sm4_decrypt
+#define gcm_sm4_digest nettle_gcm_sm4_digest
+
 #define GCM_BLOCK_SIZE 16
 #define GCM_IV_SIZE (GCM_BLOCK_SIZE - 4)
 #define GCM_DIGEST_SIZE 16
@@ -322,7 +330,22 @@ void gcm_camellia256_decrypt(struct gcm_camellia256_ctx *ctx,
 void gcm_camellia256_digest(struct gcm_camellia256_ctx *ctx,
 			    size_t length, uint8_t *digest);
 
-  
+
+struct gcm_sm4_ctx GCM_CTX(struct sm4_ctx);
+
+void gcm_sm4_set_key(struct gcm_sm4_ctx *ctx, const uint8_t *key);
+void gcm_sm4_set_iv (struct gcm_sm4_ctx *ctx,
+		     size_t length, const uint8_t *iv);
+void gcm_sm4_update (struct gcm_sm4_ctx *ctx,
+		     size_t length, const uint8_t *data);
+void gcm_sm4_encrypt(struct gcm_sm4_ctx *ctx,
+		     size_t length, uint8_t *dst, const uint8_t *src);
+void gcm_sm4_decrypt(struct gcm_sm4_ctx *ctx,
+		     size_t length, uint8_t *dst, const uint8_t *src);
+void gcm_sm4_digest(struct gcm_sm4_ctx *ctx,
+		    size_t length, uint8_t *digest);
+
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle-meta-aeads.c b/nettle-meta-aeads.c
index c99cc465..78f38a3c 100644
--- a/nettle-meta-aeads.c
+++ b/nettle-meta-aeads.c
@@ -43,6 +43,7 @@ const struct nettle_aead * const _nettle_aeads[] = {
   &amp;nettle_gcm_aes256,
   &amp;nettle_gcm_camellia128,
   &amp;nettle_gcm_camellia256,
+  &amp;nettle_gcm_sm4,
   &amp;nettle_eax_aes128,
   &amp;nettle_chacha_poly1305,
   NULL
diff --git a/nettle-meta.h b/nettle-meta.h
index 3d0440e8..19dc96c5 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -200,6 +200,7 @@ extern const struct nettle_aead nettle_gcm_aes192;
 extern const struct nettle_aead nettle_gcm_aes256;
 extern const struct nettle_aead nettle_gcm_camellia128;
 extern const struct nettle_aead nettle_gcm_camellia256;
+extern const struct nettle_aead nettle_gcm_sm4;
 extern const struct nettle_aead nettle_eax_aes128;
 extern const struct nettle_aead nettle_chacha_poly1305;
 
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index df1fc94a..d9af0e0a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -540,6 +540,24 @@ test_main(void)
 		 "16aedbf5a0de6a57 a637b39b"),	/* iv */
 	    SHEX("5791883f822013f8bd136fc36fb9946b"));	/* tag */
 
+  /*
+   * GCM-SM4 Test Vectors from
+   * https://datatracker.ietf.org/doc/html/rfc8998
+   */
+  test_aead(&amp;nettle_gcm_sm4, NULL,
+	    SHEX("0123456789ABCDEFFEDCBA9876543210"),
+	    SHEX("FEEDFACEDEADBEEFFEEDFACEDEADBEEFABADDAD2"),
+	    SHEX("AAAAAAAAAAAAAAAABBBBBBBBBBBBBBBB"
+	         "CCCCCCCCCCCCCCCCDDDDDDDDDDDDDDDD"
+	         "EEEEEEEEEEEEEEEEFFFFFFFFFFFFFFFF"
+	         "EEEEEEEEEEEEEEEEAAAAAAAAAAAAAAAA"),
+	    SHEX("17F399F08C67D5EE19D0DC9969C4BB7D"
+	         "5FD46FD3756489069157B282BB200735"
+	         "D82710CA5C22F0CCFA7CBF93D496AC15"
+	         "A56834CBCF98C397B4024A2691233B8D"),
+	    SHEX("00001234567800000000ABCD"),
+	    SHEX("83DE3541E4C2B58177E065A9BF7B62EC"));
+
   /* Test gcm_hash, with varying message size, keys and iv all zero.
      Not compared to any other implementation. */
   test_gcm_hash (SDATA("a"),
diff --git a/testsuite/meta-aead-test.c b/testsuite/meta-aead-test.c
index 1fcede40..ceeca227 100644
--- a/testsuite/meta-aead-test.c
+++ b/testsuite/meta-aead-test.c
@@ -8,6 +8,7 @@ const char* aeads[] = {
   "gcm_aes256",
   "gcm_camellia128",
   "gcm_camellia256",
+  "gcm_sm4",
   "eax_aes128",
   "chacha_poly1305",
 };
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211213081946</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-12-13 08:19:46-0400</timestampReceived><subject>[PATCH 7/7] doc: documentation for GCM using SM4 cipher</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 nettle.texinfo | 38 ++++++++++++++++++++++++++++++++++++++
 1 file changed, 38 insertions(+)

diff --git a/nettle.texinfo b/nettle.texinfo
index a291dc7e..823d3f41 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -3360,6 +3360,44 @@ that @var{length} is @code{GCM_DIGEST_SIZE}, but if you \
provide a smaller  value, only the first @var{length} octets of the digest are \
written.  @end deftypefun
 
+@subsubsection @acronym{GCM}-SM4 interface
+
+The following functions implement the case of @acronym{GCM} using
+SM4 as the underlying cipher.
+
+@deftp {Context struct} {struct gcm_sm4_ctx}
+Context structs, defined using @code{GCM_CTX}.
+@end deftp
+
+@deftypefun void gcm_sm4_set_key (struct gcm_sm4_ctx *@var{ctx}, const uint8_t \
*@var{key}) +Initializes @var{ctx} using the given key.
+@end deftypefun
+
+@deftypefun void gcm_sm4_set_iv (struct gcm_sm4_ctx *@var{ctx}, size_t @var{length}, \
const uint8_t *@var{iv}) +Initializes the per-message state, using the given \
@acronym{IV}. +@end deftypefun
+
+@deftypefun void gcm_sm4_update (struct gcm_sm4_ctx *@var{ctx}, size_t @var{length}, \
const uint8_t *@var{data}) +Provides associated data to be authenticated. If used, \
must be called +before @code{gcm_sm4_encrypt} or @code{gcm_sm4_decrypt}. All but the
+last call for each message @emph{must} use a length that is a multiple
+of the block size.
+@end deftypefun
+
+@deftypefun void gcm_sm4_encrypt (struct gcm_sm4_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{dst}, const uint8_t *@var{src}) +@deftypefunx void \
gcm_sm4_decrypt (struct gcm_sm4_ctx *@var{ctx}, size_t @var{length}, uint8_t \
*@var{dst}, const uint8_t *@var{src}) +Encrypts or decrypts the data of a message. \
All but the last call for +each message @emph{must} use a length that is a multiple \
of the block +size.
+@end deftypefun
+
+@deftypefun void gcm_sm4_digest (struct gcm_sm4_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{digest}) +Extracts the message digest (also known ``authentication \
tag''). This is +the final operation when processing a message. It's strongly \
recommended +that @var{length} is @code{GCM_DIGEST_SIZE}, but if you provide a \
smaller +value, only the first @var{length} octets of the digest are written.
+@end deftypefun
+
 @node CCM
 @subsection Counter with CBC-MAC mode
 
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20211217121143</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-17 12:11:43-0400</timestampReceived><subject>Status update</subject><body>

Hi, just a heads up that I'll likely not be very responsive next few
weeks. I may or may not get some hacking time during Christmas holidays.

What I'd like to do when I get time: Review recent patches for powerpc
ecc and sm4. Complete support for ANSI x9.62 (I'm not really up-to-date
on the details, but needed square root code is already in, and there's
code to do the rest was posted by Wim Lewis long ago). Prepare a new
release. Maybe write salsa20 and chacha assembly for more platforms.

But not necessarily in that order. Feel free to reply with suggested
priorities, and remind me if there's something important that I've
missed.

Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211124074059</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-24 07:40:59-0400</timestampReceived><subject>[PATCH 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Add OSCCA SM3 secure hash (OSCCA GM/T 0004-2012 SM3) generic
hash transformation.

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in                |   3 +-
 nettle-meta-hashes.c       |   1 +
 nettle-meta.h              |   1 +
 sm3-meta.c                 |  41 ++++++
 sm3.c                      | 250 +++++++++++++++++++++++++++++++++++++
 sm3.h                      |  81 ++++++++++++
 testsuite/meta-hash-test.c |   3 +-
 7 files changed, 378 insertions(+), 2 deletions(-)
 create mode 100644 sm3-meta.c
 create mode 100644 sm3.c
 create mode 100644 sm3.h

diff --git a/Makefile.in b/Makefile.in
index e6fc25b8..77f474c3 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -145,6 +145,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 sha3-224.c sha3-224-meta.c sha3-256.c sha3-256-meta.c \
 		 sha3-384.c sha3-384-meta.c sha3-512.c sha3-512-meta.c \
 		 shake256.c \
+		 sm3.c sm3-meta.c \
 		 serpent-set-key.c serpent-encrypt.c serpent-decrypt.c \
 		 serpent-meta.c \
 		 streebog.c streebog-meta.c \
@@ -233,7 +234,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pbkdf2.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
-	  serpent.h sha.h sha1.h sha2.h sha3.h streebog.h twofish.h \
+	  serpent.h sha.h sha1.h sha2.h sha3.h sm3.h streebog.h twofish.h \
 	  umac.h yarrow.h xts.h poly1305.h nist-keywrap.h
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 8e96dd41..4d421182 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -55,6 +55,7 @@ const struct nettle_hash * const _nettle_hashes[] = {
   &amp;nettle_sha3_512,
   &amp;nettle_streebog256,
   &amp;nettle_streebog512,
+  &amp;nettle_sm3,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 6a62b653..664321d8 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -145,6 +145,7 @@ extern const struct nettle_hash nettle_sha3_384;
 extern const struct nettle_hash nettle_sha3_512;
 extern const struct nettle_hash nettle_streebog256;
 extern const struct nettle_hash nettle_streebog512;
+extern const struct nettle_hash nettle_sm3;
 
 struct nettle_mac
 {
diff --git a/sm3-meta.c b/sm3-meta.c
new file mode 100644
index 00000000..7aae7ce4
--- /dev/null
+++ b/sm3-meta.c
@@ -0,0 +1,41 @@
+/* sm3-meta.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "sm3.h"
+
+const struct nettle_hash nettle_sm3
+= _NETTLE_HASH(sm3, SM3);
diff --git a/sm3.c b/sm3.c
new file mode 100644
index 00000000..955939fa
--- /dev/null
+++ b/sm3.c
@@ -0,0 +1,250 @@
+/* sm3.c
+
+   The SM3 hash function.
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+
+#include "sm3.h"
+
+#include "macros.h"
+#include "nettle-write.h"
+
+static const uint32_t K[64] =
+{
+  0x79cc4519UL, 0xf3988a32UL, 0xe7311465UL, 0xce6228cbUL,
+  0x9cc45197UL, 0x3988a32fUL, 0x7311465eUL, 0xe6228cbcUL,
+  0xcc451979UL, 0x988a32f3UL, 0x311465e7UL, 0x6228cbceUL,
+  0xc451979cUL, 0x88a32f39UL, 0x11465e73UL, 0x228cbce6UL,
+  0x9d8a7a87UL, 0x3b14f50fUL, 0x7629ea1eUL, 0xec53d43cUL,
+  0xd8a7a879UL, 0xb14f50f3UL, 0x629ea1e7UL, 0xc53d43ceUL,
+  0x8a7a879dUL, 0x14f50f3bUL, 0x29ea1e76UL, 0x53d43cecUL,
+  0xa7a879d8UL, 0x4f50f3b1UL, 0x9ea1e762UL, 0x3d43cec5UL,
+  0x7a879d8aUL, 0xf50f3b14UL, 0xea1e7629UL, 0xd43cec53UL,
+  0xa879d8a7UL, 0x50f3b14fUL, 0xa1e7629eUL, 0x43cec53dUL,
+  0x879d8a7aUL, 0x0f3b14f5UL, 0x1e7629eaUL, 0x3cec53d4UL,
+  0x79d8a7a8UL, 0xf3b14f50UL, 0xe7629ea1UL, 0xcec53d43UL,
+  0x9d8a7a87UL, 0x3b14f50fUL, 0x7629ea1eUL, 0xec53d43cUL,
+  0xd8a7a879UL, 0xb14f50f3UL, 0x629ea1e7UL, 0xc53d43ceUL,
+  0x8a7a879dUL, 0x14f50f3bUL, 0x29ea1e76UL, 0x53d43cecUL,
+  0xa7a879d8UL, 0x4f50f3b1UL, 0x9ea1e762UL, 0x3d43cec5UL
+};
+
+/*
+  Transform the message X which consists of 16 32-bit-words. See
+  GM/T 004-2012 for details. */
+#define R(i, a, b, c, d, e, f, g, h, t, w1, w2)     \
+  do {                                              \
+    ss1 = ROTL32(7, (ROTL32(12, (a)) + (e) + (t))); \
+    ss2 = ss1 ^ ROTL32(12, (a));                    \
+    d += FF ## i(a, b, c) + ss2 + ((w1) ^ (w2));    \
+    h += GG ## i(e, f, g) + ss1 + (w1);             \
+    b = ROTL32(9, (b));                             \
+    f = ROTL32(19, (f));                            \
+    h = P0((h));                                    \
+  } while (0)
+
+#define R1(a,b,c,d,e,f,g,h,t,w1,w2) R(1,a,b,c,d,e,f,g,h,t,w1,w2)
+#define R2(a,b,c,d,e,f,g,h,t,w1,w2) R(2,a,b,c,d,e,f,g,h,t,w1,w2)
+
+#define FF1(x, y, z)  (x ^ y ^ z)
+#define FF2(x, y, z)  ((x &amp; y) | (x &amp; z) | (y &amp; z))
+
+#define GG1(x, y, z)  (x ^ y ^ z)
+#define GG2(x, y, z)  ((x &amp; y) | ( ~x &amp; z))
+
+/* Message expansion */
+#define P0(x) ((x) ^ ROTL32(9, (x)) ^ ROTL32(17, (x)))
+#define P1(x) ((x) ^ ROTL32(15, (x)) ^ ROTL32(23, (x)))
+#define I(i)  (w[i] = READ_UINT32(input + i * 4))
+#define W1(i) (w[i &amp; 0x0f])
+#define W2(i) (w[i &amp; 0x0f] =                                            \
+        P1(w[i &amp; 0x0f] ^ w[(i-9) &amp; 0x0f] ^ ROTL32(15, w[(i-3) &amp; 0x0f])) \
+        ^ ROTL32(7, w[(i-13) &amp; 0x0f])                                   \
+        ^ w[(i-6) &amp; 0x0f])
+
+
+static void
+sm3_compress(uint32_t *state, const uint8_t *input)
+{
+  uint32_t a, b, c, d, e, f, g, h, ss1, ss2;
+  uint32_t w[16];
+
+  a = state[0];
+  b = state[1];
+  c = state[2];
+  d = state[3];
+  e = state[4];
+  f = state[5];
+  g = state[6];
+  h = state[7];
+
+  R1(a, b, c, d, e, f, g, h, K[0], I(0), I(4));
+  R1(d, a, b, c, h, e, f, g, K[1], I(1), I(5));
+  R1(c, d, a, b, g, h, e, f, K[2], I(2), I(6));
+  R1(b, c, d, a, f, g, h, e, K[3], I(3), I(7));
+  R1(a, b, c, d, e, f, g, h, K[4], W1(4), I(8));
+  R1(d, a, b, c, h, e, f, g, K[5], W1(5), I(9));
+  R1(c, d, a, b, g, h, e, f, K[6], W1(6), I(10));
+  R1(b, c, d, a, f, g, h, e, K[7], W1(7), I(11));
+  R1(a, b, c, d, e, f, g, h, K[8], W1(8), I(12));
+  R1(d, a, b, c, h, e, f, g, K[9], W1(9), I(13));
+  R1(c, d, a, b, g, h, e, f, K[10], W1(10), I(14));
+  R1(b, c, d, a, f, g, h, e, K[11], W1(11), I(15));
+  R1(a, b, c, d, e, f, g, h, K[12], W1(12), W2(16));
+  R1(d, a, b, c, h, e, f, g, K[13], W1(13), W2(17));
+  R1(c, d, a, b, g, h, e, f, K[14], W1(14), W2(18));
+  R1(b, c, d, a, f, g, h, e, K[15], W1(15), W2(19));
+
+  R2(a, b, c, d, e, f, g, h, K[16], W1(16), W2(20));
+  R2(d, a, b, c, h, e, f, g, K[17], W1(17), W2(21));
+  R2(c, d, a, b, g, h, e, f, K[18], W1(18), W2(22));
+  R2(b, c, d, a, f, g, h, e, K[19], W1(19), W2(23));
+  R2(a, b, c, d, e, f, g, h, K[20], W1(20), W2(24));
+  R2(d, a, b, c, h, e, f, g, K[21], W1(21), W2(25));
+  R2(c, d, a, b, g, h, e, f, K[22], W1(22), W2(26));
+  R2(b, c, d, a, f, g, h, e, K[23], W1(23), W2(27));
+  R2(a, b, c, d, e, f, g, h, K[24], W1(24), W2(28));
+  R2(d, a, b, c, h, e, f, g, K[25], W1(25), W2(29));
+  R2(c, d, a, b, g, h, e, f, K[26], W1(26), W2(30));
+  R2(b, c, d, a, f, g, h, e, K[27], W1(27), W2(31));
+  R2(a, b, c, d, e, f, g, h, K[28], W1(28), W2(32));
+  R2(d, a, b, c, h, e, f, g, K[29], W1(29), W2(33));
+  R2(c, d, a, b, g, h, e, f, K[30], W1(30), W2(34));
+  R2(b, c, d, a, f, g, h, e, K[31], W1(31), W2(35));
+
+  R2(a, b, c, d, e, f, g, h, K[32], W1(32), W2(36));
+  R2(d, a, b, c, h, e, f, g, K[33], W1(33), W2(37));
+  R2(c, d, a, b, g, h, e, f, K[34], W1(34), W2(38));
+  R2(b, c, d, a, f, g, h, e, K[35], W1(35), W2(39));
+  R2(a, b, c, d, e, f, g, h, K[36], W1(36), W2(40));
+  R2(d, a, b, c, h, e, f, g, K[37], W1(37), W2(41));
+  R2(c, d, a, b, g, h, e, f, K[38], W1(38), W2(42));
+  R2(b, c, d, a, f, g, h, e, K[39], W1(39), W2(43));
+  R2(a, b, c, d, e, f, g, h, K[40], W1(40), W2(44));
+  R2(d, a, b, c, h, e, f, g, K[41], W1(41), W2(45));
+  R2(c, d, a, b, g, h, e, f, K[42], W1(42), W2(46));
+  R2(b, c, d, a, f, g, h, e, K[43], W1(43), W2(47));
+  R2(a, b, c, d, e, f, g, h, K[44], W1(44), W2(48));
+  R2(d, a, b, c, h, e, f, g, K[45], W1(45), W2(49));
+  R2(c, d, a, b, g, h, e, f, K[46], W1(46), W2(50));
+  R2(b, c, d, a, f, g, h, e, K[47], W1(47), W2(51));
+
+  R2(a, b, c, d, e, f, g, h, K[48], W1(48), W2(52));
+  R2(d, a, b, c, h, e, f, g, K[49], W1(49), W2(53));
+  R2(c, d, a, b, g, h, e, f, K[50], W1(50), W2(54));
+  R2(b, c, d, a, f, g, h, e, K[51], W1(51), W2(55));
+  R2(a, b, c, d, e, f, g, h, K[52], W1(52), W2(56));
+  R2(d, a, b, c, h, e, f, g, K[53], W1(53), W2(57));
+  R2(c, d, a, b, g, h, e, f, K[54], W1(54), W2(58));
+  R2(b, c, d, a, f, g, h, e, K[55], W1(55), W2(59));
+  R2(a, b, c, d, e, f, g, h, K[56], W1(56), W2(60));
+  R2(d, a, b, c, h, e, f, g, K[57], W1(57), W2(61));
+  R2(c, d, a, b, g, h, e, f, K[58], W1(58), W2(62));
+  R2(b, c, d, a, f, g, h, e, K[59], W1(59), W2(63));
+  R2(a, b, c, d, e, f, g, h, K[60], W1(60), W2(64));
+  R2(d, a, b, c, h, e, f, g, K[61], W1(61), W2(65));
+  R2(c, d, a, b, g, h, e, f, K[62], W1(62), W2(66));
+  R2(b, c, d, a, f, g, h, e, K[63], W1(63), W2(67));
+
+  state[0] ^= a;
+  state[1] ^= b;
+  state[2] ^= c;
+  state[3] ^= d;
+  state[4] ^= e;
+  state[5] ^= f;
+  state[6] ^= g;
+  state[7] ^= h;
+}
+
+void
+sm3_init(struct sm3_ctx *ctx)
+{
+  static const uint32_t H0[_SM3_DIGEST_LENGTH] =
+  {
+    0x7380166fUL, 0x4914b2b9UL, 0x172442d7UL, 0xda8a0600UL,
+    0xa96f30bcUL, 0x163138aaUL, 0xe38dee4dUL, 0xb0fb0e4eUL
+  };
+
+  memcpy(ctx-&gt;state, H0, sizeof(H0));
+
+  /* Initialize bit count */
+  ctx-&gt;count = 0;
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+#define COMPRESS(ctx, data) (sm3_compress((ctx)-&gt;state, (data)))
+
+void
+sm3_update(struct sm3_ctx *ctx,
+	   size_t length, const uint8_t *data)
+{
+  MD_UPDATE(ctx, length, data, COMPRESS, ctx-&gt;count++);
+}
+
+static void
+sm3_write_digest(struct sm3_ctx *ctx,
+		 size_t length,
+		 uint8_t *digest)
+{
+  uint64_t bit_count;
+
+  assert(length &lt;= SM3_DIGEST_SIZE);
+
+  MD_PAD(ctx, 8, COMPRESS);
+
+  /* There are 512 = 2^9 bits in one block */
+  bit_count = (ctx-&gt;count &lt;&lt; 9) | (ctx-&gt;index &lt;&lt; 3);
+
+  /* This is slightly inefficient, as the numbers are converted to
+     big-endian format, and will be converted back by the compression
+     function. It's probably not worth the effort to fix this. */
+  WRITE_UINT64(ctx-&gt;block + (SM3_BLOCK_SIZE - 8), bit_count);
+  COMPRESS(ctx, ctx-&gt;block);
+
+  _nettle_write_be32(length, digest, ctx-&gt;state);
+}
+
+void
+sm3_digest(struct sm3_ctx *ctx,
+	   size_t length,
+	   uint8_t *digest)
+{
+  sm3_write_digest(ctx, length, digest);
+  sm3_init(ctx);
+}
diff --git a/sm3.h b/sm3.h
new file mode 100644
index 00000000..f825b9fc
--- /dev/null
+++ b/sm3.h
@@ -0,0 +1,81 @@
+/* sm3.h
+
+   The SM3 hash function.
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+ 
+#ifndef NETTLE_SM3_H_INCLUDED
+#define NETTLE_SM3_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define sm3_init nettle_sm3_init
+#define sm3_update nettle_sm3_update
+#define sm3_digest nettle_sm3_digest
+
+#define SM3_DIGEST_SIZE 32
+#define SM3_BLOCK_SIZE 64
+/* For backwards compatibility */
+#define SM3_DATA_SIZE SM3_BLOCK_SIZE
+
+/* Digest is kept internally as 8 32-bit words. */
+#define _SM3_DIGEST_LENGTH 8
+
+struct sm3_ctx
+{
+  uint32_t state[_SM3_DIGEST_LENGTH];
+  uint64_t count;               /* Block count */
+  unsigned index;               /* Into buffer */
+  uint8_t block[SM3_BLOCK_SIZE]; /* Block buffer */
+};
+
+void
+sm3_init(struct sm3_ctx *ctx);
+
+void
+sm3_update(struct sm3_ctx *ctx,
+	   size_t length,
+	   const uint8_t *data);
+
+void
+sm3_digest(struct sm3_ctx *ctx,
+	   size_t length,
+	   uint8_t *digest);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_SM3_H_INCLUDED */
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index eb9f3698..3aed43fc 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -21,7 +21,8 @@ const char* hashes[] = {
   "sha3_384",
   "sha3_512",
   "streebog256",
-  "streebog512"
+  "streebog512",
+  "sm3",
 };
 
 void
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211124074100</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-24 07:41:00-0400</timestampReceived><subject>[PATCH 2/4] testsuite: add test for SM3 hash function</subject><body>

Add a testuite for SM3 hash function. Test vectors are based on:
https://datatracker.ietf.org/doc/html/draft-shen-sm3-hash-01

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 testsuite/.gitignore  |  1 +
 testsuite/Makefile.in |  2 +-
 testsuite/sm3-test.c  | 20 ++++++++++++++++++++
 3 files changed, 22 insertions(+), 1 deletion(-)
 create mode 100644 testsuite/sm3-test.c

diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 9d8a7681..ca41472e 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -97,6 +97,7 @@
 /sha512-224-test
 /sha512-256-test
 /sha512-test
+/sm3-test
 /streebog-test
 /twofish-test
 /umac-test
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 2b554261..6734d3e6 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -24,7 +24,7 @@ TS_NETTLE_SOURCES = aes-test.c aes-keywrap-test.c arcfour-test.c arctwo-test.c \
 		    sha384-test.c sha512-test.c sha512-224-test.c sha512-256-test.c \
 		    sha3-permute-test.c sha3-224-test.c sha3-256-test.c \
 		    sha3-384-test.c sha3-512-test.c \
-		    shake256-test.c streebog-test.c \
+		    shake256-test.c streebog-test.c sm3-test.c \
 		    serpent-test.c twofish-test.c version-test.c \
 		    knuth-lfib-test.c \
 		    cbc-test.c cfb-test.c ctr-test.c gcm-test.c eax-test.c ccm-test.c \
diff --git a/testsuite/sm3-test.c b/testsuite/sm3-test.c
new file mode 100644
index 00000000..d3684afd
--- /dev/null
+++ b/testsuite/sm3-test.c
@@ -0,0 +1,20 @@
+#include "testutils.h"
+#include "sm3.h"
+
+void
+test_main(void)
+{
+    /* test vectors from:
+     * https://datatracker.ietf.org/doc/html/draft-shen-sm3-hash-01
+     */
+  test_hash(&amp;nettle_sm3,
+            SDATA("abc"),
+            SHEX("66c7f0f462eeedd9 d1f2d46bdc10e4e2"
+                 "4167c4875cf2f7a2 297da02b8f4ba8e0"));
+
+  test_hash(&amp;nettle_sm3,
+            SDATA("abcdabcdabcdabcdabcdabcdabcdabcd"
+                  "abcdabcdabcdabcdabcdabcdabcdabcd"),
+            SHEX("debe9ff92275b8a1 38604889c18e5a4d"
+                 "6fdb70e5387e5765 293dcba39c0c5732"));
+}
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211124074101</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-24 07:41:01-0400</timestampReceived><subject>[PATCH 3/4] hmac: add support for SM3 hash function</subject><body>

Add support for calculating HMAC using SM3 hash functions.

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in               |  4 +--
 hmac-sm3-meta.c           | 47 +++++++++++++++++++++++++++++++
 hmac-sm3.c                | 59 +++++++++++++++++++++++++++++++++++++++
 hmac.h                    | 19 +++++++++++++
 nettle-meta-macs.c        |  1 +
 nettle-meta.h             |  1 +
 testsuite/hmac-test.c     |  6 ++++
 testsuite/meta-mac-test.c |  1 +
 8 files changed, 136 insertions(+), 2 deletions(-)
 create mode 100644 hmac-sm3-meta.c
 create mode 100644 hmac-sm3.c

diff --git a/Makefile.in b/Makefile.in
index 77f474c3..0590c370 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -117,10 +117,10 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
-		 hmac-sha512.c hmac-streebog.c \
+		 hmac-sha512.c hmac-streebog.c hmac-sm3.c \
 		 hmac-md5-meta.c hmac-ripemd160-meta.c hmac-sha1-meta.c \
 		 hmac-sha224-meta.c hmac-sha256-meta.c hmac-sha384-meta.c \
-		 hmac-sha512-meta.c hmac-streebog-meta.c \
+		 hmac-sha512-meta.c hmac-streebog-meta.c hmac-sm3-meta.c \
 		 knuth-lfib.c hkdf.c \
 		 md2.c md2-meta.c md4.c md4-meta.c \
 		 md5.c md5-compress.c md5-compat.c md5-meta.c \
diff --git a/hmac-sm3-meta.c b/hmac-sm3-meta.c
new file mode 100644
index 00000000..d3d7f3d2
--- /dev/null
+++ b/hmac-sm3-meta.c
@@ -0,0 +1,47 @@
+/* hmac-sm3-meta.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "hmac.h"
+
+static void
+hmac_sm3_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_sm3_set_key (ctx, SM3_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_sm3
+= _NETTLE_HMAC(hmac_sm3, SM3);
diff --git a/hmac-sm3.c b/hmac-sm3.c
new file mode 100644
index 00000000..decb4a2d
--- /dev/null
+++ b/hmac-sm3.c
@@ -0,0 +1,59 @@
+/* hmac-sm3.c
+
+   HMAC-SM3 message authentication code.
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "hmac.h"
+
+void
+hmac_sm3_set_key(struct hmac_sm3_ctx *ctx,
+		 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_sm3, key_length, key);
+}
+
+void
+hmac_sm3_update(struct hmac_sm3_ctx *ctx,
+		size_t length, const uint8_t *data)
+{
+  sm3_update(&amp;ctx-&gt;state, length, data);
+}
+
+void
+hmac_sm3_digest(struct hmac_sm3_ctx *ctx,
+		size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_sm3, length, digest);
+}
diff --git a/hmac.h b/hmac.h
index 72c8fd57..453a67af 100644
--- a/hmac.h
+++ b/hmac.h
@@ -42,6 +42,7 @@
 #include "sha1.h"
 #include "sha2.h"
 #include "streebog.h"
+#include "sm3.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -81,6 +82,9 @@ extern "C" {
 #define hmac_streebog512_set_key nettle_hmac_streebog512_set_key
 #define hmac_streebog512_update nettle_hmac_streebog512_update
 #define hmac_streebog512_digest nettle_hmac_streebog512_digest
+#define hmac_sm3_set_key nettle_hmac_sm3_set_key
+#define hmac_sm3_update nettle_hmac_sm3_update
+#define hmac_sm3_digest nettle_hmac_sm3_digest
 
 void
 hmac_set_key(void *outer, void *inner, void *state,
@@ -273,6 +277,21 @@ void
 hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
 		   size_t length, uint8_t *digest);
 
+/* hmac-sm3 */
+struct hmac_sm3_ctx HMAC_CTX(struct sm3_ctx);
+
+void
+hmac_sm3_set_key(struct hmac_sm3_ctx *ctx,
+		 size_t key_length, const uint8_t *key);
+
+void
+hmac_sm3_update(struct hmac_sm3_ctx *ctx,
+		size_t length, const uint8_t *data);
+
+void
+hmac_sm3_digest(struct hmac_sm3_ctx *ctx,
+		size_t length, uint8_t *digest);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle-meta-macs.c b/nettle-meta-macs.c
index 5e8f8713..40aa6dcd 100644
--- a/nettle-meta-macs.c
+++ b/nettle-meta-macs.c
@@ -50,6 +50,7 @@ const struct nettle_mac * const _nettle_macs[] = {
   &amp;nettle_hmac_sha512,
   &amp;nettle_hmac_streebog256,
   &amp;nettle_hmac_streebog512,
+  &amp;nettle_hmac_sm3,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 664321d8..d684947e 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -291,6 +291,7 @@ extern const struct nettle_mac nettle_hmac_sha384;
 extern const struct nettle_mac nettle_hmac_sha512;
 extern const struct nettle_mac nettle_hmac_streebog256;
 extern const struct nettle_mac nettle_hmac_streebog512;
+extern const struct nettle_mac nettle_hmac_sm3;
 
 #ifdef __cplusplus
 }
diff --git a/testsuite/hmac-test.c b/testsuite/hmac-test.c
index 348f7920..0d1fb44c 100644
--- a/testsuite/hmac-test.c
+++ b/testsuite/hmac-test.c
@@ -883,4 +883,10 @@ test_main(void)
 	    SHEX("0126bdb87800af214341456563780100"),
 	    SHEX("a1aa5f7de402d7b3d323f2991c8d4534"
 	         "013137010a83754fd0af6d7cd4922ed9"));
+
+  HMAC_TEST(sm3,
+	    SDATA("monkey monkey monkey monkey"),
+	    SDATA("abc"),
+            SHEX("7a9388e2ca5343b5d76e7c2c3d84f239"
+                 "f306c0b60d5e0dc4d2771e42860a6a2b"));
 }
diff --git a/testsuite/meta-mac-test.c b/testsuite/meta-mac-test.c
index adbd4326..0ff82810 100644
--- a/testsuite/meta-mac-test.c
+++ b/testsuite/meta-mac-test.c
@@ -14,6 +14,7 @@ const char* macs[] = {
   "hmac_sha512",
   "hmac_streebog256",
   "hmac_streebog512",
+  "hmac_sm3",
 };
 
 void
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211124074102</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-24 07:41:02-0400</timestampReceived><subject>[PATCH 4/4] nettle-benchmark: bench SM3 hashes</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 examples/nettle-benchmark.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 50a5815a..ba5dd284 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -909,7 +909,7 @@ main(int argc, char **argv)
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
       &amp;nettle_ripemd160, &amp;nettle_gosthash94,
       &amp;nettle_gosthash94cp, &amp;nettle_streebog256,
-      &amp;nettle_streebog512,
+      &amp;nettle_streebog512, &amp;nettle_sm3,
       NULL
     };
 
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084736</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:36-0400</timestampReceived><subject>[PATCH 2/7] ecc: Add powerpc64 assembly for ecc_224_modp</subject><body>

Signed-off-by: Amitay Isaacs &lt;amitay@ozlabs.org&gt;
---
 powerpc64/ecc-secp224r1-modp.asm | 123 +++++++++++++++++++++++++++++++
 1 file changed, 123 insertions(+)
 create mode 100644 powerpc64/ecc-secp224r1-modp.asm

diff --git a/powerpc64/ecc-secp224r1-modp.asm b/powerpc64/ecc-secp224r1-modp.asm
new file mode 100644
index 00000000..e993376f
--- /dev/null
+++ b/powerpc64/ecc-secp224r1-modp.asm
@@ -0,0 +1,123 @@
+C powerpc64/ecc-secp224r1-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Amitay Isaacs, IBM Corporation
+
+   Based on x86_64/ecc-secp224r1-modp.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-secp224r1-modp.asm"
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`T0', `r6')
+define(`T1', `r7')
+define(`H0', `r8')
+define(`H1', `r9')
+define(`H2', `r10')
+define(`F0', `r11')
+define(`F1', `r12')
+define(`F2', `r14')
+define(`T2', `r3')
+
+	C void ecc_secp224r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_secp224r1_modp)
+	std	F2, -8(SP)
+
+	ld	H0, 48(XP)
+	ld	H1, 56(XP)
+	C set (F2, F1, F0) &lt;-- (H1, H0) &lt;&lt; 32
+	sldi	F0, H0, 32
+	srdi	F1, H0, 32
+	sldi	T0, H1, 32
+	srdi	F2, H1, 32
+	or	F1, T0, F1
+
+	li	H2, 0
+	ld	T0, 16(XP)
+	ld	T1, 24(XP)
+	subfc	T0, F0, T0
+	subfe	T1, F1, T1
+	subfe	H0, F2, H0
+	addme	H1, H1
+
+	ld	T2, 32(XP)
+	addc	H0, T2, H0
+	ld	T2, 40(XP)
+	adde	H1, T2, H1
+	addze	H2, H2
+
+	C Set (F2, F1, F0) &lt;-- (H2, H1, H0) &lt;&lt; 32
+	sldi	F0, H0, 32
+	srdi	F1, H0, 32
+	addc	H0, T0, H0
+	sldi	T0, H1, 32
+	srdi	F2, H1, 32
+	adde	H1, T1, H1
+	sldi	T1, H2, 32
+	addze	H2, H2
+	or	F1, T0, F1
+	or	F2, T1, F2
+
+	ld	T0, 0(XP)
+	ld	T1, 8(XP)
+	subfc	T0, F0, T0
+	subfe	T1, F1, T1
+	subfe	H0, F2, H0
+	addme	H1, H1
+	addme	H2, H2
+
+	srdi	F0, H1, 32
+	sldi	F1, H2, 32
+	or	F0, F1, F0
+	clrrdi	F1, H1, 32
+	mr	F2, H2
+	clrldi	H1, H1, 32
+
+	subfc	T0, F0, T0
+	addme	F1, F1
+	addme	F2, F2
+	addc	T1, F1, T1
+	adde	H0, F2, H0
+	addze	H1, H1
+
+	std	T0, 0(RP)
+	std	T1, 8(RP)
+	std	H0, 16(RP)
+	std	H1, 24(RP)
+
+	ld	F2, -8(SP)
+
+	blr
+EPILOGUE(_nettle_ecc_secp224r1_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211207073731</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-12-07 07:37:31-0400</timestampReceived><subject>Re: powerpc ecc 256 redc (was Re: x86_64 ecc_256_redc)</subject><body>

Hi Niels,

On Mon, 2021-12-06 at 22:29 +0100, Niels Möller wrote:
&gt; nisse@lysator.liu.se  (Niels Möller) writes:
&gt; 
&gt; &gt; I think the approach should apply to other 64-bit archs (should
&gt; &gt; probably
&gt; &gt; work also on x86_64, where it's sometimes tricky to avoid x86_64
&gt; &gt; instructions clobbering the carry flag when it should be preserved,
&gt; &gt; but
&gt; &gt; probably not so difficult in this case).
&gt; 
&gt; x86_64 version below. I could also trimmed register usage, so it no
&gt; longer needs to save and restore any registers. On my machine, this
&gt; gives a speedup of 17% for ecc_secp256r1_redc in isolation, 3%
&gt; speedup
&gt; for ecdsa sign and 7% speedup of ecdsa verify.

On POWER9, the new code gives ~20% speedup for ecc_secp256r1_redc in
isolation, and ~1% speedup for ecdsa sign and verify over the earlier
assembly version.


Amitay.
-- 

Do it ! Move it ! Make it happen ! No one ever sat their way to
success.

["ecc-secp256r1-redc.asm" (ecc-secp256r1-redc.asm)]

C powerpc64/ecc-secp256r1-redc.asm

ifelse(`
   Copyright (C) 2021 Amitay Isaacs &amp; Martin Schwenke, IBM Corporation

   Based on x86_64/ecc-secp256r1-redc.asm

   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C Register usage:

define(`SP', `r1')

define(`RP', `r4')
define(`XP', `r5')

define(`F0', `r3')
define(`F1', `r6')
define(`F2', `r7')
define(`F3', `r8')

define(`U0', `r9')
define(`U1', `r10')
define(`U2', `r11')
define(`U3', `r12')
define(`U4', `r14')
define(`U5', `r15')
define(`U6', `r16')
define(`U7', `r17')

	.file "ecc-secp256r1-redc.asm"

C FOLD(x), sets (F3,F2,F1,F0)  &lt;-- [(x &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt;32)]
define(`FOLD', `
	sldi	F0, $1, 32
	srdi	F1, $1, 32
	subfc	F2, F0, $1
	subfe	F3, F1, $1
')

C FOLDC(x), sets (F3,F2,F1,F0)  &lt;-- [((x+c) &lt;&lt; 192) - (x &lt;&lt; 160) + (x &lt;&lt; 128) + (x &lt;&lt;32)]
define(`FOLDC', `
	sldi	F0, $1, 32
	srdi	F1, $1, 32
	addze	F3, $1
	subfc	F2, F0, $1
	subfe	F3, F1, F3
')

	C void ecc_secp256r1_redc (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
	.text
define(`FUNC_ALIGN', `5')
PROLOGUE(_nettle_ecc_secp256r1_redc)

	std	U4,-32(SP)
	std	U5,-24(SP)
	std	U6,-16(SP)
	std	U7,-8(SP)

	ld	U0, 0(XP)
	ld	U1, 8(XP)
	ld	U2, 16(XP)
	ld	U3, 24(XP)
	ld	U4, 32(XP)
	ld	U5, 40(XP)
	ld	U6, 48(XP)
	ld	U7, 56(XP)

	FOLD(U0)
	addc	U1, F0, U1
	adde	U2, F1, U2
	adde	U3, F2, U3
	adde	U4, F3, U4

	FOLDC(U1)
	addc	U2, F0, U2
	adde	U3, F1, U3
	adde	U4, F2, U4
	adde	U5, F3, U5

	FOLDC(U2)
	addc	U3, F0, U3
	adde	U4, F1, U4
	adde	U5, F2, U5
	adde	U6, F3, U6

	FOLDC(U3)
	addc	U4, F0, U4
	adde	U5, F1, U5
	adde	U6, F2, U6
	adde	U7, F3, U7

	C If carry, we need to add in
	C 2^256 - p = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
	li	F0, 0
	addze	F0, F0
	neg	F2, F0
	sldi	F1, F2, 32
	srdi	F3, F2, 32
	li	XP, -2
	and	F3, F3, XP

	addc	U0, F0, U4
	adde	U1, F1, U5
	adde	U2, F2, U6
	adde	U3, F3, U7

	std	U0, 0(RP)
	std	U1, 8(RP)
	std	U2, 16(RP)
	std	U3, 24(RP)

	ld	U4,-32(SP)
	ld	U5,-24(SP)
	ld	U6,-16(SP)
	ld	U7,-8(SP)

	blr
EPILOGUE(_nettle_ecc_secp256r1_redc)

[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20211207202552</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-12-07 20:25:52-0400</timestampReceived><subject>Re: powerpc ecc 256 redc (was Re: x86_64 ecc_256_redc)</subject><body>

Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:

&gt; On POWER9, the new code gives ~20% speedup for ecc_secp256r1_redc in
&gt; isolation, and ~1% speedup for ecdsa sign and verify over the earlier
&gt; assembly version.

Thanks! Merged to master-updates for ci testing.

I think it should be possible to reduce number of needed registers, and
completely avoid using callee-save registers (load the values now in
U4-U7 one at a time a bit closer to the place where they are needed in),
and replace F3 with $1 in the FOLD and FOLDC macros.

Regards,
/Niels

-- 
Niels Möller. PGP key CB4962D070D77D7FCB8BA36271D8F1FF368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084737</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:37-0400</timestampReceived><subject>[PATCH 3/7] ecc: Add powerpc64 assembly for ecc_256_redc</subject><body>

Signed-off-by: Amitay Isaacs &lt;amitay@ozlabs.org&gt;
Signed-off-by: Martin Schwenke &lt;martin@meltin.net&gt;
---
 powerpc64/ecc-secp256r1-redc.asm | 144 +++++++++++++++++++++++++++++++
 1 file changed, 144 insertions(+)
 create mode 100644 powerpc64/ecc-secp256r1-redc.asm

diff --git a/powerpc64/ecc-secp256r1-redc.asm b/powerpc64/ecc-secp256r1-redc.asm
new file mode 100644
index 00000000..59447567
--- /dev/null
+++ b/powerpc64/ecc-secp256r1-redc.asm
@@ -0,0 +1,144 @@
+C powerpc64/ecc-secp256r1-redc.asm
+
+ifelse(`
+   Copyright (C) 2021 Amitay Isaacs &amp; Martin Schwenke, IBM Corporation
+
+   Based on x86_64/ecc-secp256r1-redc.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Register usage:
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`F0', `r3')
+define(`F1', `r6')
+define(`F2', `r7')
+define(`F3', `r8')
+
+define(`U0', `r9')
+define(`U1', `r10')
+define(`U2', `r11')
+define(`U3', `r12')
+define(`U4', `r14')
+define(`U5', `r15')
+define(`U6', `r16')
+define(`U7', `r17')
+
+	.file "ecc-secp256r1-redc.asm"
+
+C FOLD(x), sets (F3,F2,F1,F0)  &lt;-- [(x &lt;&lt; 224) - (x &lt;&lt; 192) - (x &lt;&lt; 96)] &gt;&gt; 64
+define(`FOLD', `
+	sldi	F2, $1, 32
+	srdi	F3, $1, 32
+	li	F0, 0
+	li	F1, 0
+	subfc	F0, F2, F0
+	subfe	F1, F3, F1
+	subfe	F2, $1, F2
+	addme	F3, F3
+')
+
+	C void ecc_secp256r1_redc (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_secp256r1_redc)
+
+	std	U4,-32(SP)
+	std	U5,-24(SP)
+	std	U6,-16(SP)
+	std	U7,-8(SP)
+
+	ld	U0, 0(XP)
+	ld	U1, 8(XP)
+	ld	U2, 16(XP)
+	ld	U3, 24(XP)
+	ld	U4, 32(XP)
+	ld	U5, 40(XP)
+	ld	U6, 48(XP)
+	ld	U7, 56(XP)
+
+	FOLD(U0)
+	subfc	U1, F0, U1
+	subfe	U2, F1, U2
+	subfe	U3, F2, U3
+	subfe	U0, F3, U0
+
+	FOLD(U1)
+	subfc	U2, F0, U2
+	subfe	U3, F1, U3
+	subfe	U4, F2, U4
+	subfe	U1, F3, U1
+
+	FOLD(U2)
+	subfc	U3, F0, U3
+	subfe	U4, F1, U4
+	subfe	U5, F2, U5
+	subfe	U2, F3, U2
+
+	FOLD(U3)
+	subfc	U4, F0, U4
+	subfe	U5, F1, U5
+	subfe	U6, F2, U6
+	subfe	U3, F3, U3
+
+	addc	U0, U4, U0
+	adde	U1, U5, U1
+	adde	U2, U6, U2
+	adde	U3, U7, U3
+
+	C If carry, we need to add in
+	C 2^256 - p = &lt;0xfffffffe, 0xff..ff, 0xffffffff00000000, 1&gt;
+	li	F0, 0
+	addze	F0, F0
+	neg	F2, F0
+	sldi	F1, F2, 32
+	srdi	F3, F2, 32
+	li	U7, -2
+	and	F3, F3, U7
+
+	addc	U0, F0, U0
+	adde	U1, F1, U1
+	adde	U2, F2, U2
+	adde	U3, F3, U3
+
+	std	U0, 0(RP)
+	std	U1, 8(RP)
+	std	U2, 16(RP)
+	std	U3, 24(RP)
+
+	ld	U4,-32(SP)
+	ld	U5,-24(SP)
+	ld	U6,-16(SP)
+	ld	U7,-8(SP)
+
+	blr
+EPILOGUE(_nettle_ecc_secp256r1_redc)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084738</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:38-0400</timestampReceived><subject>[PATCH 4/7] ecc: Add powerpc64 assembly for ecc_384_modp</subject><body>

From: Martin Schwenke &lt;martin@meltin.net&gt;

Signed-off-by: Martin Schwenke &lt;martin@meltin.net&gt;
Signed-off-by: Amitay Isaacs &lt;amitay@ozlabs.org&gt;
Signed-off-by: Alastair D'Silva &lt;alastair@d-silva.org&gt;
---
 powerpc64/ecc-secp384r1-modp.asm | 227 +++++++++++++++++++++++++++++++
 1 file changed, 227 insertions(+)
 create mode 100644 powerpc64/ecc-secp384r1-modp.asm

diff --git a/powerpc64/ecc-secp384r1-modp.asm b/powerpc64/ecc-secp384r1-modp.asm
new file mode 100644
index 00000000..67791f09
--- /dev/null
+++ b/powerpc64/ecc-secp384r1-modp.asm
@@ -0,0 +1,227 @@
+C powerpc64/ecc-secp384r1-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Martin Schwenke, Amitay Isaacs &amp; Alastair D ´Silva, IBM Corporation
+
+   Based on x86_64/ecc-secp256r1-redc.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-secp384r1-modp.asm"
+
+C Register usage:
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`D5', `r6')
+define(`T0', `r7')
+define(`T1', `r8')
+define(`T2', `r9')
+define(`T3', `r10')
+define(`T4', `r11')
+define(`T5', `r12')
+define(`H0', `r14')
+define(`H1', `r15')
+define(`H2', `r16')
+define(`H3', `r17')
+define(`H4', `r18')
+define(`H5', `r19')
+define(`C2', `r3')
+define(`C0', H5)	C Overlap
+define(`TMP', XP)	C Overlap
+
+
+	C void ecc_secp384r1_modp (const struct ecc_modulo *m, mp_limb_t *rp, mp_limb_t *xp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_secp384r1_modp)
+
+	std	H0, -48(SP)
+	std	H1, -40(SP)
+	std	H2, -32(SP)
+	std	H3, -24(SP)
+	std	H4, -16(SP)
+	std	H5, -8(SP)
+
+	C First get top 2 limbs, which need folding twice.
+	C B^10 = B^6 + B^4 + 2^32 (B-1)B^4.
+	C We handle the terms as follow:
+	C
+	C B^6: Folded immediatly.
+	C
+	C B^4: Delayed, added in in the next folding.
+	C
+	C 2^32(B-1) B^4: Low half limb delayed until the next
+	C folding. Top 1.5 limbs subtracted and shifter now, resulting
+	C in 2.5 limbs. The low limb saved in D5, high 1.5 limbs added
+	C in.
+
+	ld	H4, 80(XP)
+	ld	H5, 88(XP)
+	C Shift right 32 bits, into H1, H0
+	srdi	H1, H5, 32
+	sldi	D5, H5, 32
+	srdi	H0, H4, 32
+	or	H0, H0, D5
+
+	C	H1 H0
+	C       -  H1 H0
+	C       --------
+	C       H1 H0 D5
+	subfic	D5, H0, 0
+	subfe	H0, H1, H0
+	addme	H1, H1
+
+	li	C2, 0
+	addc	H0, H4, H0
+	adde	H1, H5, H1
+	addze	C2, C2
+
+	C Add in to high part
+	ld	T1, 48(XP)
+	ld	T2, 56(XP)
+	addc	H0, T1, H0
+	adde	H1, T2, H1
+	addze	C2, C2		C Do C2 later
+
+	C +1 term
+	ld	T0, 0(XP)
+	ld	T1, 8(XP)
+	ld	T2, 16(XP)
+	ld	T3, 24(XP)
+	ld	T4, 32(XP)
+	ld	T5, 40(XP)
+	ld	H2, 64(XP)
+	ld	H3, 72(XP)
+	addc	T0, H0, T0
+	adde	T1, H1, T1
+	adde	T2, H2, T2
+	adde	T3, H3, T3
+	adde	T4, H4, T4
+	adde	T5, H5, T5
+	li	C0, 0
+	addze	C0, C0
+
+	C +B^2 term
+	addc	T2, H0, T2
+	adde	T3, H1, T3
+	adde	T4, H2, T4
+	adde	T5, H3, T5
+	addze	C0, C0
+
+	C Shift left, including low half of H4
+	sldi	H4, H4, 32
+	srdi	TMP, H3, 32
+	or	H4, TMP, H4
+
+	sldi	H3, H3, 32
+	srdi	TMP, H2, 32
+	or	H3, TMP, H3
+
+	sldi	H2, H2, 32
+	srdi	TMP, H1, 32
+	or	H2, TMP, H2
+
+	sldi	H1, H1, 32
+	srdi	TMP, H0, 32
+	or	H1, TMP, H1
+
+	sldi	H0, H0, 32
+
+	C   H4 H3 H2 H1 H0  0
+	C  -   H4 H3 H2 H1 H0
+	C  ---------------
+	C   H4 H3 H2 H1 H0 TMP
+
+	subfic	TMP, H0, 0
+	subfe	H0, H1, H0
+	subfe	H1, H2, H1
+	subfe	H2, H3, H2
+	subfe	H3, H4, H3
+	addme	H4, H4
+
+	addc	T0, TMP, T0
+	adde	T1, H0, T1
+	adde	T2, H1, T2
+	adde	T3, H2, T3
+	adde	T4, H3, T4
+	adde	T5, H4, T5
+	addze	C0, C0
+
+	C Remains to add in C2 and C0
+	C Set H1, H0 = (2^96 - 2^32 + 1) C0
+	sldi	H1, C0, 32
+	subfc	H0, H1, C0
+	addme	H1, H1
+
+	C Set H3, H2 = (2^96 - 2^32 + 1) C2
+	sldi	H3, C2, 32
+	subfc	H2, H3, C2
+	addme	H3, H3
+	addc	H2, C0, H2
+
+	li	C0, 0
+	addc	T0, H0, T0
+	adde	T1, H1, T1
+	adde	T2, H2, T2
+	adde	T3, H3, T3
+	adde	T4, C2, T4
+	adde	T5, D5, T5		C Value delayed from initial folding
+	addze	C0, C0
+
+	C Final unlikely carry
+	sldi	H1, C0, 32
+	subfc	H0, H1, C0
+	addme	H1, H1
+
+	addc	T0, H0, T0
+	adde	T1, H1, T1
+	adde	T2, C0, T2
+	addze	T3, T3
+	addze	T4, T4
+	addze	T5, T5
+
+	std	T0, 0(RP)
+	std	T1, 8(RP)
+	std	T2, 16(RP)
+	std	T3, 24(RP)
+	std	T4, 32(RP)
+	std	T5, 40(RP)
+
+	ld	H0, -48(SP)
+	ld	H1, -40(SP)
+	ld	H2, -32(SP)
+	ld	H3, -24(SP)
+	ld	H4, -16(SP)
+	ld	H5, -8(SP)
+
+	blr
+EPILOGUE(_nettle_ecc_secp384r1_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084739</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:39-0400</timestampReceived><subject>[PATCH 5/7] ecc: Add powerpc64 assembly for ecc_521_modp</subject><body>

From: Martin Schwenke &lt;martin@meltin.net&gt;

Signed-off-by: Martin Schwenke &lt;martin@meltin.net&gt;
Signed-off-by: Alastair D'Silva &lt;alastair@d-silva.org&gt;
---
 powerpc64/ecc-secp521r1-modp.asm | 166 +++++++++++++++++++++++++++++++
 1 file changed, 166 insertions(+)
 create mode 100644 powerpc64/ecc-secp521r1-modp.asm

diff --git a/powerpc64/ecc-secp521r1-modp.asm b/powerpc64/ecc-secp521r1-modp.asm
new file mode 100644
index 00000000..a9d197c9
--- /dev/null
+++ b/powerpc64/ecc-secp521r1-modp.asm
@@ -0,0 +1,166 @@
+C powerpc64/ecc-secp521r1-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Martin Schwenke &amp; Alastair D ´Silva, IBM Corporation
+
+   Based on x86_64/ecc-secp521r1-modp.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-secp521r1-modp.asm"
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`U0', `r6')
+define(`U1', `r7')
+define(`U2', `r8')
+define(`U3', `r9')
+define(`U4', `r10')
+define(`U5', `r11')
+define(`U6', `r12')
+define(`U7', `r14')
+define(`U8', `r15')
+define(`U9', `r16')
+
+define(`T0', `r3')
+define(`T1', `r17')
+
+
+	C void ecc_secp521r1_modp (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_secp521r1_modp)
+
+	std	U7, -32(SP)
+	std	U8, -24(SP)
+	std	U9, -16(SP)
+	std	T1, -8(SP)
+
+	C Read top 17 limbs, shift left 55 bits
+	ld	U1, 72(XP)
+	sldi	U0, U1, 55
+	srdi	U1, U1, 9
+
+	ld	T0, 80(XP)
+	srdi	U2, T0, 9
+	sldi	T0, T0, 55
+	or	U1, T0, U1
+
+	ld	T0, 88(XP)
+	srdi	U3, T0, 9
+	sldi	T0, T0, 55
+	or	U2, T0, U2
+
+	ld	T0, 96(XP)
+	srdi	U4, T0, 9
+	sldi	T0, T0, 55
+	or	U3, T0, U3
+
+	ld	T0, 104(XP)
+	srdi	U5, T0, 9
+	sldi	T0, T0, 55
+	or	U4, T0, U4
+
+	ld	T0, 112(XP)
+	srdi	U6, T0, 9
+	sldi	T0, T0, 55
+	or	U5, T0, U5
+
+	ld	T0, 120(XP)
+	srdi	U7, T0, 9
+	sldi	T0, T0, 55
+	or	U6, T0, U6
+
+	ld	T0, 128(XP)
+	srdi	U8, T0, 9
+	sldi	T0, T0, 55
+	or	U7, T0, U7
+
+	ld	T0, 136(XP)
+	srdi	U9, T0, 9
+	sldi	T0, T0, 55
+	or	U8, T0, U8
+
+	ld	T0, 0(XP)
+	ld	T1, 8(XP)
+	addc	U0, T0, U0
+	adde	U1, T1, U1
+	ld	T0, 16(XP)
+	ld	T1, 24(XP)
+	adde	U2, T0, U2
+	adde	U3, T1, U3
+	ld	T0, 32(XP)
+	ld	T1, 40(XP)
+	adde	U4, T0, U4
+	adde	U5, T1, U5
+	ld	T0, 48(XP)
+	ld	T1, 56(XP)
+	adde	U6, T0, U6
+	adde	U7, T1, U7
+	ld	T0, 64(XP)
+	adde	U8, T0, U8
+	addze	U9, U9
+
+	C Top limbs are &lt;U9, U8&gt;. Keep low 9 bits of 8, and fold the
+	C top bits (at most 65 bits).
+	srdi	T0, U8, 9
+	andi.	U8, U8, 0x1ff
+	srdi	T1, U9, 9
+	sldi	U9, U9, 55
+	or	T0, U9, T0
+
+	addc	U0, T0, U0
+	adde	U1, T1, U1
+	addze	U2, U2
+	addze	U3, U3
+	addze	U4, U4
+	addze	U5, U5
+	addze	U6, U6
+	addze	U7, U7
+	addze	U8, U8
+
+	std	U0, 0(RP)
+	std	U1, 8(RP)
+	std	U2, 16(RP)
+	std	U3, 24(RP)
+	std	U4, 32(RP)
+	std	U5, 40(RP)
+	std	U6, 48(RP)
+	std	U7, 56(RP)
+	std	U8, 64(RP)
+
+	ld	U7, -32(SP)
+	ld	U8, -24(SP)
+	ld	U9, -16(SP)
+	ld	T1, -8(SP)
+
+	blr
+EPILOGUE(_nettle_ecc_secp521r1_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084740</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:40-0400</timestampReceived><subject>[PATCH 6/7] ecc: Add powerpc64 assembly for ecc_25519_modp</subject><body>

From: Martin Schwenke &lt;martin@meltin.net&gt;

Signed-off-by: Martin Schwenke &lt;martin@meltin.net&gt;
Signed-off-by: Alastair D'Silva &lt;alastair@d-silva.org&gt;
---
 powerpc64/ecc-curve25519-modp.asm | 103 ++++++++++++++++++++++++++++++
 1 file changed, 103 insertions(+)
 create mode 100644 powerpc64/ecc-curve25519-modp.asm

diff --git a/powerpc64/ecc-curve25519-modp.asm b/powerpc64/ecc-curve25519-modp.asm
new file mode 100644
index 00000000..4f9f8f73
--- /dev/null
+++ b/powerpc64/ecc-curve25519-modp.asm
@@ -0,0 +1,103 @@
+C powerpc64/ecc-25519-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Martin Schwenke &amp; Alastair D ´Silva, IBM Corporation
+
+   Based on x86_64/ecc-25519-modp.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-25519-modp.asm"
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`U0', `r6')	C Overlaps unused modulo input
+define(`U1', `r7')
+define(`U2', `r8')
+define(`U3', `r9')
+define(`T0', `r10')
+define(`T1', `r11')
+define(`M', `r12')
+
+define(`UN', r3)
+
+	C void ecc_curve25519_modp (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_curve25519_modp)
+
+	C First fold the limbs affecting bit 255
+	ld	UN, 56(XP)
+	li	M, 38
+	mulhdu	T1, M, UN
+	mulld	UN, M, UN
+	ld	U3, 24(XP)
+	li	T0, 0
+	addc	U3, UN, U3
+	adde	T0, T1, T0
+
+	ld	UN, 40(XP)
+	mulhdu	U2, M, UN
+	mulld	UN, M, UN
+
+	addc	U3, U3, U3
+	adde	T0, T0, T0
+	srdi	U3, U3, 1	C Undo shift, clear high bit
+
+	C Fold the high limb again, together with RP[5]
+	li	T1, 19
+	mulld	T0, T1, T0
+	ld	U0, 0(XP)
+	ld	U1, 8(XP)
+	ld	T1, 16(XP)
+	addc	U0, T0, U0
+	adde	U1, UN, U1
+	ld	T0, 32(XP)
+	adde	U2, U2, T1
+	addze	U3, U3
+
+	mulhdu	T1, M, T0
+	mulld	T0, M, T0
+	addc	U0, T0, U0
+	adde	U1, T1, U1
+	std	U0, 0(RP)
+	std	U1, 8(RP)
+
+	ld	T0, 48(XP)
+	mulhdu	T1, M, T0
+	mulld	UN, M, T0
+	adde	U2, UN, U2
+	adde	U3, T1, U3
+	std	U2, 16(RP)
+	std	U3, 24(RP)
+
+	blr
+EPILOGUE(_nettle_ecc_curve25519_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084741</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:41-0400</timestampReceived><subject>[PATCH 7/7] ecc: Add powerpc64 assembly for ecc_448_modp</subject><body>

From: Martin Schwenke &lt;martin@meltin.net&gt;

Signed-off-by: Martin Schwenke &lt;martin@meltin.net&gt;
Signed-off-by: Amitay Isaacs &lt;amitay@gmail.com&gt;
---
 powerpc64/ecc-curve448-modp.asm | 174 ++++++++++++++++++++++++++++++++
 1 file changed, 174 insertions(+)
 create mode 100644 powerpc64/ecc-curve448-modp.asm

diff --git a/powerpc64/ecc-curve448-modp.asm b/powerpc64/ecc-curve448-modp.asm
new file mode 100644
index 00000000..411c8df7
--- /dev/null
+++ b/powerpc64/ecc-curve448-modp.asm
@@ -0,0 +1,174 @@
+C powerpc/ecc-curve448-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Martin Schwenke &amp; Amitay Isaacs, IBM Corporation
+
+   Based on x86_64/ecc-curve448-modp.asm
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-curve448-modp.asm"
+
+define(`SP', `r1')
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`X0', `r3')
+define(`X1', `r9')
+define(`X2', `r10')
+define(`X3', `r11')
+define(`X4', `r12')
+define(`X5', `r14')
+define(`X6', `r15')
+define(`X7', `r16')
+define(`T0', `r6')
+define(`T1', `r7')
+define(`T2', `r8')
+define(`TT', `r17')
+
+define(`LO', `TT')	C Overlap
+
+	C void ecc_curve448_modp (const struct ecc_modulo *p, mp_limb_t *rp, mp_limb_t *xp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_curve448_modp)
+
+	std	X5, -32(SP)
+	std	X6, -24(SP)
+	std	X7, -16(SP)
+	std	TT, -8(SP)
+
+	C First load the values to be shifted by 32.
+	ld	T0, 88(XP)	C use for X0, X1
+	ld	T1, 96(XP)	C use for X2
+	ld	T2, 104(XP)	C use for X3
+	ld	X4, 56(XP)
+	ld	X5, 64(XP)
+	ld	X6, 72(XP)
+	ld	X7, 80(XP)
+
+	C Multiply by 2^32
+	sldi	X0, T0, 32
+	srdi	LO, T0, 32
+	sldi	X1, T1, 32
+	or	X1, X1, LO
+	srdi	LO, T1, 32
+	sldi	X2, T2, 32
+	or	X2, X2, LO
+	srdi	LO, T2, 32
+	sldi	X3, X4, 32
+	or	X3, X3, LO
+	srdi	LO, X4, 32
+	sldi	X4, X5, 32
+	or	X4, X4, LO
+	srdi	LO, X5, 32
+	sldi	X5, X6, 32
+	or	X5, X5, LO
+	srdi	LO, X6, 32
+	sldi	X6, X7, 32
+	or	X6, X6, LO
+
+	srdi	X7, X7, 32
+
+	C Multiply by 2
+	addc	T0, T0, T0
+	adde	T1, T1, T1
+	adde	T2, T2, T2
+	addze	X7, X7
+
+	C Main additions
+	ld	TT, 56(XP)
+	addc	X0, TT, X0
+	ld	TT, 64(XP)
+	adde	X1, TT, X1
+	ld	TT, 72(XP)
+	adde	X2, TT, X2
+	ld	TT, 80(XP)
+	adde	X3, TT, X3
+	adde	X4, T0, X4
+	adde	X5, T1, X5
+	adde	X6, T2, X6
+	addze	X7, X7
+
+	ld	T0, 0(XP)
+	addc	X0, T0, X0
+	ld	T1, 8(XP)
+	adde	X1, T1, X1
+	ld	T2, 16(XP)
+	adde	X2, T2, X2
+	ld	TT, 24(XP)
+	adde	X3, TT, X3
+	ld	T0, 32(XP)
+	adde	X4, T0, X4
+	ld	T1, 40(XP)
+	adde	X5, T1, X5
+	ld	T2, 48(XP)
+	adde	X6, T2, X6
+	addze	X7, X7
+
+	C X7 wraparound
+	sldi	T0, X7, 32
+	srdi	T1, X7, 32
+	li	T2, 0
+	addc	X0, X7, X0
+	addze	X1, X1
+	addze	X2, X2
+	adde	X3, T0, X3
+	adde	X4, T1, X4
+	addze	X5, X5
+	addze	X6, X6
+	addze	T2, T2
+
+	C Final carry wraparound. Carry T2 &gt; 0 only if
+	C X6 is zero, so carry is absorbed.
+	sldi	T0, T2, 32
+
+	addc	X0, T2, X0
+	addze	X1, X1
+	addze	X2, X2
+	adde	X3, T0, X3
+	addze	X4, X4
+	addze	X5, X5
+	addze	X6, X6
+
+	std	X0, 0(RP)
+	std	X1, 8(RP)
+	std	X2, 16(RP)
+	std	X3, 24(RP)
+	std	X4, 32(RP)
+	std	X5, 40(RP)
+	std	X6, 48(RP)
+
+	ld	X5, -32(SP)
+	ld	X6, -24(SP)
+	ld	X7, -16(SP)
+	ld	TT, -8(SP)
+
+	blr
+EPILOGUE(_nettle_ecc_curve448_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129121837</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:18:37-0400</timestampReceived><subject>Re: [PATCH 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Hi Niels,

On 11/28/21 6:03 PM, Niels Möller wrote:
&gt; Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt; writes:
&gt; 
&gt;&gt; You can refer to the ISO specification here:
&gt;&gt; https://www.iso.org/standard/67116.html
&gt;&gt; Or PDF version:
&gt;&gt; https://github.com/alipay/tls13-sm-spec/blob/master/sm-en-pdfs/sm3/GBT.32905-2016.SM3-en.pdf
&gt; 
&gt; I see that RFC 8998 refers to
&gt; http://www.gmbz.org.cn/upload/2018-07-24/1532401392982079739.pdf, which
&gt; looks like the same pdf file. I find it a bit odd that the document
&gt; carries no information on author or organization.
&gt; 

There is no author in the document, but the website www.gmbz.org.cn that 
publishes this standard is China's Cryptography Standardization 
Technical Committee.

Thank you very much for your reminder, Jia Zhang is not himself, but 
another colleague of our team, I will add copyright information in the 
next version

&gt;&gt; The specification does not define the reference implementation of the
&gt;&gt; algorithm. This series of patches mainly refers to the SM3
&gt;&gt; implementation in libgcrypt and gnulib.
&gt; 
&gt; It looks like the gcrypt implementation is licensed under LGPLv2.1 or
&gt; later (see https://github.com/gpg/libgcrypt/blob/master/cipher/sm3.c),
&gt; so should be fine to copy into nettle (in contrast to gnulib code, which
&gt; appears to be GPLv3, and would need explicit permission from copyright
&gt; holder before relicensing). But if it is a derived work of libgcrypt, in
&gt; the sense of copyright law, the copyright header needs to acknowledge
&gt; that, ie,
&gt; 
&gt;     Copyright (C) 2017 Jia Zhang
&gt;     Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
&gt; 
&gt; Or did you write both versions, with Jia being an alternate form of
&gt; your name?
&gt; 

Thanks for pointing it out, Jia Zhang is another colleague of our team, 
I will add copyright information in the next version.

Best regards,
Tianjia
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129123232</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:32:32-0400</timestampReceived><subject>[PATCH v2 0/4] Introduce OSCCA SM3 hash algorithm</subject><body>

Add OSCCA SM3 secure hash generic hash algorithm, described
in OSCCA GM/T 0004-2012 SM3, the corresponding English specification:
http://www.gmbz.org.cn/upload/2018-07-24/1532401392982079739.pdf

Tianjia Zhang (4):
  Add OSCCA SM3 hash algorithm
  testsuite: add test for SM3 hash function
  hmac: add support for SM3 hash function
  nettle-benchmark: bench SM3 hashes

 Makefile.in                 |   7 +-
 examples/nettle-benchmark.c |   2 +-
 hmac-sm3-meta.c             |  47 +++++++
 hmac-sm3.c                  |  59 +++++++++
 hmac.h                      |  19 +++
 nettle-meta-hashes.c        |   1 +
 nettle-meta-macs.c          |   1 +
 nettle-meta.h               |   2 +
 sm3-meta.c                  |  42 ++++++
 sm3.c                       | 251 ++++++++++++++++++++++++++++++++++++
 sm3.h                       |  82 ++++++++++++
 testsuite/.gitignore        |   1 +
 testsuite/Makefile.in       |   2 +-
 testsuite/hmac-test.c       |   6 +
 testsuite/meta-hash-test.c  |   3 +-
 testsuite/meta-mac-test.c   |   1 +
 testsuite/sm3-test.c        |  20 +++
 17 files changed, 540 insertions(+), 6 deletions(-)
 create mode 100644 hmac-sm3-meta.c
 create mode 100644 hmac-sm3.c
 create mode 100644 sm3-meta.c
 create mode 100644 sm3.c
 create mode 100644 sm3.h
 create mode 100644 testsuite/sm3-test.c

-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129123233</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:32:33-0400</timestampReceived><subject>[PATCH v2 1/4] Add OSCCA SM3 hash algorithm</subject><body>

Add OSCCA SM3 secure hash (OSCCA GM/T 0004-2012 SM3) generic
hash transformation.

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in                |   3 +-
 nettle-meta-hashes.c       |   1 +
 nettle-meta.h              |   1 +
 sm3-meta.c                 |  42 +++++++
 sm3.c                      | 251 +++++++++++++++++++++++++++++++++++++
 sm3.h                      |  82 ++++++++++++
 testsuite/meta-hash-test.c |   3 +-
 7 files changed, 381 insertions(+), 2 deletions(-)
 create mode 100644 sm3-meta.c
 create mode 100644 sm3.c
 create mode 100644 sm3.h

diff --git a/Makefile.in b/Makefile.in
index e6fc25b8..77f474c3 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -145,6 +145,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 sha3-224.c sha3-224-meta.c sha3-256.c sha3-256-meta.c \
 		 sha3-384.c sha3-384-meta.c sha3-512.c sha3-512-meta.c \
 		 shake256.c \
+		 sm3.c sm3-meta.c \
 		 serpent-set-key.c serpent-encrypt.c serpent-decrypt.c \
 		 serpent-meta.c \
 		 streebog.c streebog-meta.c \
@@ -233,7 +234,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pbkdf2.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
-	  serpent.h sha.h sha1.h sha2.h sha3.h streebog.h twofish.h \
+	  serpent.h sha.h sha1.h sha2.h sha3.h sm3.h streebog.h twofish.h \
 	  umac.h yarrow.h xts.h poly1305.h nist-keywrap.h
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 8e96dd41..4d421182 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -55,6 +55,7 @@ const struct nettle_hash * const _nettle_hashes[] = {
   &amp;nettle_sha3_512,
   &amp;nettle_streebog256,
   &amp;nettle_streebog512,
+  &amp;nettle_sm3,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 6a62b653..664321d8 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -145,6 +145,7 @@ extern const struct nettle_hash nettle_sha3_384;
 extern const struct nettle_hash nettle_sha3_512;
 extern const struct nettle_hash nettle_streebog256;
 extern const struct nettle_hash nettle_streebog512;
+extern const struct nettle_hash nettle_sm3;
 
 struct nettle_mac
 {
diff --git a/sm3-meta.c b/sm3-meta.c
new file mode 100644
index 00000000..036e9e95
--- /dev/null
+++ b/sm3-meta.c
@@ -0,0 +1,42 @@
+/* sm3-meta.c
+
+   Copyright (C) 2017 Jia Zhang
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "sm3.h"
+
+const struct nettle_hash nettle_sm3
+= _NETTLE_HASH(sm3, SM3);
diff --git a/sm3.c b/sm3.c
new file mode 100644
index 00000000..ac58cb38
--- /dev/null
+++ b/sm3.c
@@ -0,0 +1,251 @@
+/* sm3.c
+
+   The SM3 hash function.
+
+   Copyright (C) 2017 Jia Zhang
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+
+#include "sm3.h"
+
+#include "macros.h"
+#include "nettle-write.h"
+
+static const uint32_t K[64] =
+{
+  0x79cc4519UL, 0xf3988a32UL, 0xe7311465UL, 0xce6228cbUL,
+  0x9cc45197UL, 0x3988a32fUL, 0x7311465eUL, 0xe6228cbcUL,
+  0xcc451979UL, 0x988a32f3UL, 0x311465e7UL, 0x6228cbceUL,
+  0xc451979cUL, 0x88a32f39UL, 0x11465e73UL, 0x228cbce6UL,
+  0x9d8a7a87UL, 0x3b14f50fUL, 0x7629ea1eUL, 0xec53d43cUL,
+  0xd8a7a879UL, 0xb14f50f3UL, 0x629ea1e7UL, 0xc53d43ceUL,
+  0x8a7a879dUL, 0x14f50f3bUL, 0x29ea1e76UL, 0x53d43cecUL,
+  0xa7a879d8UL, 0x4f50f3b1UL, 0x9ea1e762UL, 0x3d43cec5UL,
+  0x7a879d8aUL, 0xf50f3b14UL, 0xea1e7629UL, 0xd43cec53UL,
+  0xa879d8a7UL, 0x50f3b14fUL, 0xa1e7629eUL, 0x43cec53dUL,
+  0x879d8a7aUL, 0x0f3b14f5UL, 0x1e7629eaUL, 0x3cec53d4UL,
+  0x79d8a7a8UL, 0xf3b14f50UL, 0xe7629ea1UL, 0xcec53d43UL,
+  0x9d8a7a87UL, 0x3b14f50fUL, 0x7629ea1eUL, 0xec53d43cUL,
+  0xd8a7a879UL, 0xb14f50f3UL, 0x629ea1e7UL, 0xc53d43ceUL,
+  0x8a7a879dUL, 0x14f50f3bUL, 0x29ea1e76UL, 0x53d43cecUL,
+  0xa7a879d8UL, 0x4f50f3b1UL, 0x9ea1e762UL, 0x3d43cec5UL
+};
+
+/*
+  Transform the message X which consists of 16 32-bit-words. See
+  GM/T 004-2012 for details. */
+#define R(i, a, b, c, d, e, f, g, h, t, w1, w2)     \
+  do {                                              \
+    ss1 = ROTL32(7, (ROTL32(12, (a)) + (e) + (t))); \
+    ss2 = ss1 ^ ROTL32(12, (a));                    \
+    d += FF ## i(a, b, c) + ss2 + ((w1) ^ (w2));    \
+    h += GG ## i(e, f, g) + ss1 + (w1);             \
+    b = ROTL32(9, (b));                             \
+    f = ROTL32(19, (f));                            \
+    h = P0((h));                                    \
+  } while (0)
+
+#define R1(a,b,c,d,e,f,g,h,t,w1,w2) R(1,a,b,c,d,e,f,g,h,t,w1,w2)
+#define R2(a,b,c,d,e,f,g,h,t,w1,w2) R(2,a,b,c,d,e,f,g,h,t,w1,w2)
+
+#define FF1(x, y, z)  (x ^ y ^ z)
+#define FF2(x, y, z)  ((x &amp; y) | (x &amp; z) | (y &amp; z))
+
+#define GG1(x, y, z)  (x ^ y ^ z)
+#define GG2(x, y, z)  ((x &amp; y) | ( ~x &amp; z))
+
+/* Message expansion */
+#define P0(x) ((x) ^ ROTL32(9, (x)) ^ ROTL32(17, (x)))
+#define P1(x) ((x) ^ ROTL32(15, (x)) ^ ROTL32(23, (x)))
+#define I(i)  (w[i] = READ_UINT32(input + i * 4))
+#define W1(i) (w[i &amp; 0x0f])
+#define W2(i) (w[i &amp; 0x0f] =                                            \
+        P1(w[i &amp; 0x0f] ^ w[(i-9) &amp; 0x0f] ^ ROTL32(15, w[(i-3) &amp; 0x0f])) \
+        ^ ROTL32(7, w[(i-13) &amp; 0x0f])                                   \
+        ^ w[(i-6) &amp; 0x0f])
+
+
+static void
+sm3_compress(uint32_t *state, const uint8_t *input)
+{
+  uint32_t a, b, c, d, e, f, g, h, ss1, ss2;
+  uint32_t w[16];
+
+  a = state[0];
+  b = state[1];
+  c = state[2];
+  d = state[3];
+  e = state[4];
+  f = state[5];
+  g = state[6];
+  h = state[7];
+
+  R1(a, b, c, d, e, f, g, h, K[0], I(0), I(4));
+  R1(d, a, b, c, h, e, f, g, K[1], I(1), I(5));
+  R1(c, d, a, b, g, h, e, f, K[2], I(2), I(6));
+  R1(b, c, d, a, f, g, h, e, K[3], I(3), I(7));
+  R1(a, b, c, d, e, f, g, h, K[4], W1(4), I(8));
+  R1(d, a, b, c, h, e, f, g, K[5], W1(5), I(9));
+  R1(c, d, a, b, g, h, e, f, K[6], W1(6), I(10));
+  R1(b, c, d, a, f, g, h, e, K[7], W1(7), I(11));
+  R1(a, b, c, d, e, f, g, h, K[8], W1(8), I(12));
+  R1(d, a, b, c, h, e, f, g, K[9], W1(9), I(13));
+  R1(c, d, a, b, g, h, e, f, K[10], W1(10), I(14));
+  R1(b, c, d, a, f, g, h, e, K[11], W1(11), I(15));
+  R1(a, b, c, d, e, f, g, h, K[12], W1(12), W2(16));
+  R1(d, a, b, c, h, e, f, g, K[13], W1(13), W2(17));
+  R1(c, d, a, b, g, h, e, f, K[14], W1(14), W2(18));
+  R1(b, c, d, a, f, g, h, e, K[15], W1(15), W2(19));
+
+  R2(a, b, c, d, e, f, g, h, K[16], W1(16), W2(20));
+  R2(d, a, b, c, h, e, f, g, K[17], W1(17), W2(21));
+  R2(c, d, a, b, g, h, e, f, K[18], W1(18), W2(22));
+  R2(b, c, d, a, f, g, h, e, K[19], W1(19), W2(23));
+  R2(a, b, c, d, e, f, g, h, K[20], W1(20), W2(24));
+  R2(d, a, b, c, h, e, f, g, K[21], W1(21), W2(25));
+  R2(c, d, a, b, g, h, e, f, K[22], W1(22), W2(26));
+  R2(b, c, d, a, f, g, h, e, K[23], W1(23), W2(27));
+  R2(a, b, c, d, e, f, g, h, K[24], W1(24), W2(28));
+  R2(d, a, b, c, h, e, f, g, K[25], W1(25), W2(29));
+  R2(c, d, a, b, g, h, e, f, K[26], W1(26), W2(30));
+  R2(b, c, d, a, f, g, h, e, K[27], W1(27), W2(31));
+  R2(a, b, c, d, e, f, g, h, K[28], W1(28), W2(32));
+  R2(d, a, b, c, h, e, f, g, K[29], W1(29), W2(33));
+  R2(c, d, a, b, g, h, e, f, K[30], W1(30), W2(34));
+  R2(b, c, d, a, f, g, h, e, K[31], W1(31), W2(35));
+
+  R2(a, b, c, d, e, f, g, h, K[32], W1(32), W2(36));
+  R2(d, a, b, c, h, e, f, g, K[33], W1(33), W2(37));
+  R2(c, d, a, b, g, h, e, f, K[34], W1(34), W2(38));
+  R2(b, c, d, a, f, g, h, e, K[35], W1(35), W2(39));
+  R2(a, b, c, d, e, f, g, h, K[36], W1(36), W2(40));
+  R2(d, a, b, c, h, e, f, g, K[37], W1(37), W2(41));
+  R2(c, d, a, b, g, h, e, f, K[38], W1(38), W2(42));
+  R2(b, c, d, a, f, g, h, e, K[39], W1(39), W2(43));
+  R2(a, b, c, d, e, f, g, h, K[40], W1(40), W2(44));
+  R2(d, a, b, c, h, e, f, g, K[41], W1(41), W2(45));
+  R2(c, d, a, b, g, h, e, f, K[42], W1(42), W2(46));
+  R2(b, c, d, a, f, g, h, e, K[43], W1(43), W2(47));
+  R2(a, b, c, d, e, f, g, h, K[44], W1(44), W2(48));
+  R2(d, a, b, c, h, e, f, g, K[45], W1(45), W2(49));
+  R2(c, d, a, b, g, h, e, f, K[46], W1(46), W2(50));
+  R2(b, c, d, a, f, g, h, e, K[47], W1(47), W2(51));
+
+  R2(a, b, c, d, e, f, g, h, K[48], W1(48), W2(52));
+  R2(d, a, b, c, h, e, f, g, K[49], W1(49), W2(53));
+  R2(c, d, a, b, g, h, e, f, K[50], W1(50), W2(54));
+  R2(b, c, d, a, f, g, h, e, K[51], W1(51), W2(55));
+  R2(a, b, c, d, e, f, g, h, K[52], W1(52), W2(56));
+  R2(d, a, b, c, h, e, f, g, K[53], W1(53), W2(57));
+  R2(c, d, a, b, g, h, e, f, K[54], W1(54), W2(58));
+  R2(b, c, d, a, f, g, h, e, K[55], W1(55), W2(59));
+  R2(a, b, c, d, e, f, g, h, K[56], W1(56), W2(60));
+  R2(d, a, b, c, h, e, f, g, K[57], W1(57), W2(61));
+  R2(c, d, a, b, g, h, e, f, K[58], W1(58), W2(62));
+  R2(b, c, d, a, f, g, h, e, K[59], W1(59), W2(63));
+  R2(a, b, c, d, e, f, g, h, K[60], W1(60), W2(64));
+  R2(d, a, b, c, h, e, f, g, K[61], W1(61), W2(65));
+  R2(c, d, a, b, g, h, e, f, K[62], W1(62), W2(66));
+  R2(b, c, d, a, f, g, h, e, K[63], W1(63), W2(67));
+
+  state[0] ^= a;
+  state[1] ^= b;
+  state[2] ^= c;
+  state[3] ^= d;
+  state[4] ^= e;
+  state[5] ^= f;
+  state[6] ^= g;
+  state[7] ^= h;
+}
+
+void
+sm3_init(struct sm3_ctx *ctx)
+{
+  static const uint32_t H0[_SM3_DIGEST_LENGTH] =
+  {
+    0x7380166fUL, 0x4914b2b9UL, 0x172442d7UL, 0xda8a0600UL,
+    0xa96f30bcUL, 0x163138aaUL, 0xe38dee4dUL, 0xb0fb0e4eUL
+  };
+
+  memcpy(ctx-&gt;state, H0, sizeof(H0));
+
+  /* Initialize bit count */
+  ctx-&gt;count = 0;
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+#define COMPRESS(ctx, data) (sm3_compress((ctx)-&gt;state, (data)))
+
+void
+sm3_update(struct sm3_ctx *ctx,
+	   size_t length, const uint8_t *data)
+{
+  MD_UPDATE(ctx, length, data, COMPRESS, ctx-&gt;count++);
+}
+
+static void
+sm3_write_digest(struct sm3_ctx *ctx,
+		 size_t length,
+		 uint8_t *digest)
+{
+  uint64_t bit_count;
+
+  assert(length &lt;= SM3_DIGEST_SIZE);
+
+  MD_PAD(ctx, 8, COMPRESS);
+
+  /* There are 512 = 2^9 bits in one block */
+  bit_count = (ctx-&gt;count &lt;&lt; 9) | (ctx-&gt;index &lt;&lt; 3);
+
+  /* This is slightly inefficient, as the numbers are converted to
+     big-endian format, and will be converted back by the compression
+     function. It's probably not worth the effort to fix this. */
+  WRITE_UINT64(ctx-&gt;block + (SM3_BLOCK_SIZE - 8), bit_count);
+  COMPRESS(ctx, ctx-&gt;block);
+
+  _nettle_write_be32(length, digest, ctx-&gt;state);
+}
+
+void
+sm3_digest(struct sm3_ctx *ctx,
+	   size_t length,
+	   uint8_t *digest)
+{
+  sm3_write_digest(ctx, length, digest);
+  sm3_init(ctx);
+}
diff --git a/sm3.h b/sm3.h
new file mode 100644
index 00000000..8017a543
--- /dev/null
+++ b/sm3.h
@@ -0,0 +1,82 @@
+/* sm3.h
+
+   The SM3 hash function.
+
+   Copyright (C) 2017 Jia Zhang
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+ 
+#ifndef NETTLE_SM3_H_INCLUDED
+#define NETTLE_SM3_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define sm3_init nettle_sm3_init
+#define sm3_update nettle_sm3_update
+#define sm3_digest nettle_sm3_digest
+
+#define SM3_DIGEST_SIZE 32
+#define SM3_BLOCK_SIZE 64
+/* For backwards compatibility */
+#define SM3_DATA_SIZE SM3_BLOCK_SIZE
+
+/* Digest is kept internally as 8 32-bit words. */
+#define _SM3_DIGEST_LENGTH 8
+
+struct sm3_ctx
+{
+  uint32_t state[_SM3_DIGEST_LENGTH];
+  uint64_t count;               /* Block count */
+  unsigned index;               /* Into buffer */
+  uint8_t block[SM3_BLOCK_SIZE]; /* Block buffer */
+};
+
+void
+sm3_init(struct sm3_ctx *ctx);
+
+void
+sm3_update(struct sm3_ctx *ctx,
+	   size_t length,
+	   const uint8_t *data);
+
+void
+sm3_digest(struct sm3_ctx *ctx,
+	   size_t length,
+	   uint8_t *digest);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_SM3_H_INCLUDED */
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index eb9f3698..3aed43fc 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -21,7 +21,8 @@ const char* hashes[] = {
   "sha3_384",
   "sha3_512",
   "streebog256",
-  "streebog512"
+  "streebog512",
+  "sm3",
 };
 
 void
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129123234</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:32:34-0400</timestampReceived><subject>[PATCH v2 2/4] testsuite: add test for SM3 hash function</subject><body>

Add a testuite for SM3 hash function. Test vectors are based on:
https://datatracker.ietf.org/doc/html/draft-shen-sm3-hash-01

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 testsuite/.gitignore  |  1 +
 testsuite/Makefile.in |  2 +-
 testsuite/sm3-test.c  | 20 ++++++++++++++++++++
 3 files changed, 22 insertions(+), 1 deletion(-)
 create mode 100644 testsuite/sm3-test.c

diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 9d8a7681..ca41472e 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -97,6 +97,7 @@
 /sha512-224-test
 /sha512-256-test
 /sha512-test
+/sm3-test
 /streebog-test
 /twofish-test
 /umac-test
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 2b554261..6734d3e6 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -24,7 +24,7 @@ TS_NETTLE_SOURCES = aes-test.c aes-keywrap-test.c arcfour-test.c arctwo-test.c \
 		    sha384-test.c sha512-test.c sha512-224-test.c sha512-256-test.c \
 		    sha3-permute-test.c sha3-224-test.c sha3-256-test.c \
 		    sha3-384-test.c sha3-512-test.c \
-		    shake256-test.c streebog-test.c \
+		    shake256-test.c streebog-test.c sm3-test.c \
 		    serpent-test.c twofish-test.c version-test.c \
 		    knuth-lfib-test.c \
 		    cbc-test.c cfb-test.c ctr-test.c gcm-test.c eax-test.c ccm-test.c \
diff --git a/testsuite/sm3-test.c b/testsuite/sm3-test.c
new file mode 100644
index 00000000..d3684afd
--- /dev/null
+++ b/testsuite/sm3-test.c
@@ -0,0 +1,20 @@
+#include "testutils.h"
+#include "sm3.h"
+
+void
+test_main(void)
+{
+    /* test vectors from:
+     * https://datatracker.ietf.org/doc/html/draft-shen-sm3-hash-01
+     */
+  test_hash(&amp;nettle_sm3,
+            SDATA("abc"),
+            SHEX("66c7f0f462eeedd9 d1f2d46bdc10e4e2"
+                 "4167c4875cf2f7a2 297da02b8f4ba8e0"));
+
+  test_hash(&amp;nettle_sm3,
+            SDATA("abcdabcdabcdabcdabcdabcdabcdabcd"
+                  "abcdabcdabcdabcdabcdabcdabcdabcd"),
+            SHEX("debe9ff92275b8a1 38604889c18e5a4d"
+                 "6fdb70e5387e5765 293dcba39c0c5732"));
+}
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129123235</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:32:35-0400</timestampReceived><subject>[PATCH v2 3/4] hmac: add support for SM3 hash function</subject><body>

Add support for calculating HMAC using SM3 hash functions.

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 Makefile.in               |  4 +--
 hmac-sm3-meta.c           | 47 +++++++++++++++++++++++++++++++
 hmac-sm3.c                | 59 +++++++++++++++++++++++++++++++++++++++
 hmac.h                    | 19 +++++++++++++
 nettle-meta-macs.c        |  1 +
 nettle-meta.h             |  1 +
 testsuite/hmac-test.c     |  6 ++++
 testsuite/meta-mac-test.c |  1 +
 8 files changed, 136 insertions(+), 2 deletions(-)
 create mode 100644 hmac-sm3-meta.c
 create mode 100644 hmac-sm3.c

diff --git a/Makefile.in b/Makefile.in
index 77f474c3..0590c370 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -117,10 +117,10 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
-		 hmac-sha512.c hmac-streebog.c \
+		 hmac-sha512.c hmac-streebog.c hmac-sm3.c \
 		 hmac-md5-meta.c hmac-ripemd160-meta.c hmac-sha1-meta.c \
 		 hmac-sha224-meta.c hmac-sha256-meta.c hmac-sha384-meta.c \
-		 hmac-sha512-meta.c hmac-streebog-meta.c \
+		 hmac-sha512-meta.c hmac-streebog-meta.c hmac-sm3-meta.c \
 		 knuth-lfib.c hkdf.c \
 		 md2.c md2-meta.c md4.c md4-meta.c \
 		 md5.c md5-compress.c md5-compat.c md5-meta.c \
diff --git a/hmac-sm3-meta.c b/hmac-sm3-meta.c
new file mode 100644
index 00000000..d3d7f3d2
--- /dev/null
+++ b/hmac-sm3-meta.c
@@ -0,0 +1,47 @@
+/* hmac-sm3-meta.c
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "hmac.h"
+
+static void
+hmac_sm3_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_sm3_set_key (ctx, SM3_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_sm3
+= _NETTLE_HMAC(hmac_sm3, SM3);
diff --git a/hmac-sm3.c b/hmac-sm3.c
new file mode 100644
index 00000000..decb4a2d
--- /dev/null
+++ b/hmac-sm3.c
@@ -0,0 +1,59 @@
+/* hmac-sm3.c
+
+   HMAC-SM3 message authentication code.
+
+   Copyright (C) 2021 Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "hmac.h"
+
+void
+hmac_sm3_set_key(struct hmac_sm3_ctx *ctx,
+		 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_sm3, key_length, key);
+}
+
+void
+hmac_sm3_update(struct hmac_sm3_ctx *ctx,
+		size_t length, const uint8_t *data)
+{
+  sm3_update(&amp;ctx-&gt;state, length, data);
+}
+
+void
+hmac_sm3_digest(struct hmac_sm3_ctx *ctx,
+		size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_sm3, length, digest);
+}
diff --git a/hmac.h b/hmac.h
index 72c8fd57..453a67af 100644
--- a/hmac.h
+++ b/hmac.h
@@ -42,6 +42,7 @@
 #include "sha1.h"
 #include "sha2.h"
 #include "streebog.h"
+#include "sm3.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -81,6 +82,9 @@ extern "C" {
 #define hmac_streebog512_set_key nettle_hmac_streebog512_set_key
 #define hmac_streebog512_update nettle_hmac_streebog512_update
 #define hmac_streebog512_digest nettle_hmac_streebog512_digest
+#define hmac_sm3_set_key nettle_hmac_sm3_set_key
+#define hmac_sm3_update nettle_hmac_sm3_update
+#define hmac_sm3_digest nettle_hmac_sm3_digest
 
 void
 hmac_set_key(void *outer, void *inner, void *state,
@@ -273,6 +277,21 @@ void
 hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
 		   size_t length, uint8_t *digest);
 
+/* hmac-sm3 */
+struct hmac_sm3_ctx HMAC_CTX(struct sm3_ctx);
+
+void
+hmac_sm3_set_key(struct hmac_sm3_ctx *ctx,
+		 size_t key_length, const uint8_t *key);
+
+void
+hmac_sm3_update(struct hmac_sm3_ctx *ctx,
+		size_t length, const uint8_t *data);
+
+void
+hmac_sm3_digest(struct hmac_sm3_ctx *ctx,
+		size_t length, uint8_t *digest);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle-meta-macs.c b/nettle-meta-macs.c
index 5e8f8713..40aa6dcd 100644
--- a/nettle-meta-macs.c
+++ b/nettle-meta-macs.c
@@ -50,6 +50,7 @@ const struct nettle_mac * const _nettle_macs[] = {
   &amp;nettle_hmac_sha512,
   &amp;nettle_hmac_streebog256,
   &amp;nettle_hmac_streebog512,
+  &amp;nettle_hmac_sm3,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 664321d8..d684947e 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -291,6 +291,7 @@ extern const struct nettle_mac nettle_hmac_sha384;
 extern const struct nettle_mac nettle_hmac_sha512;
 extern const struct nettle_mac nettle_hmac_streebog256;
 extern const struct nettle_mac nettle_hmac_streebog512;
+extern const struct nettle_mac nettle_hmac_sm3;
 
 #ifdef __cplusplus
 }
diff --git a/testsuite/hmac-test.c b/testsuite/hmac-test.c
index 348f7920..0d1fb44c 100644
--- a/testsuite/hmac-test.c
+++ b/testsuite/hmac-test.c
@@ -883,4 +883,10 @@ test_main(void)
 	    SHEX("0126bdb87800af214341456563780100"),
 	    SHEX("a1aa5f7de402d7b3d323f2991c8d4534"
 	         "013137010a83754fd0af6d7cd4922ed9"));
+
+  HMAC_TEST(sm3,
+	    SDATA("monkey monkey monkey monkey"),
+	    SDATA("abc"),
+            SHEX("7a9388e2ca5343b5d76e7c2c3d84f239"
+                 "f306c0b60d5e0dc4d2771e42860a6a2b"));
 }
diff --git a/testsuite/meta-mac-test.c b/testsuite/meta-mac-test.c
index adbd4326..0ff82810 100644
--- a/testsuite/meta-mac-test.c
+++ b/testsuite/meta-mac-test.c
@@ -14,6 +14,7 @@ const char* macs[] = {
   "hmac_sha512",
   "hmac_streebog256",
   "hmac_streebog512",
+  "hmac_sm3",
 };
 
 void
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084734</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:34-0400</timestampReceived><subject>[PATCH 0/7] Add powerpc64 assembly for elliptic curves</subject><body>

Hi,

This series of patches add the powerpc64 assembly for modp/redc functions
for elliptic curves P192, P224, P256, P384, P521, X25519 and X448. It results
in 15-30% performance improvements as measured on POWER9 system using
hogweed-benchmark.

master
------
            name size   sign/ms verify/ms

           ecdsa  192   13.5465    3.8313
           ecdsa  224    8.4079    2.5289
           ecdsa  256    8.5772    2.4691
           ecdsa  384    3.4361    0.9765
           ecdsa  521    2.2918    0.6785

           eddsa  255   15.0672    4.1138
           eddsa  448    4.7115    1.3067
           curve  255   15.5206    6.4745
           curve  448    4.7906    2.0458

this series
-----------
            name size   sign/ms verify/ms

           ecdsa  192   17.5450    5.6564
           ecdsa  224   10.8847    3.7482
           ecdsa  256   11.0208    3.5215
           ecdsa  384    5.1133    1.6133
           ecdsa  521    2.8815    0.9348

           eddsa  255   17.4936    4.9027
           eddsa  448    6.0401    1.7075
           curve  255   18.1034    7.6884
           curve  448    6.1756    2.7095

Amitay Isaacs (3):
  ecc: Add powerpc64 assembly for ecc_192_modp
  ecc: Add powerpc64 assembly for ecc_224_modp
  ecc: Add powerpc64 assembly for ecc_256_redc

Martin Schwenke (4):
  ecc: Add powerpc64 assembly for ecc_384_modp
  ecc: Add powerpc64 assembly for ecc_521_modp
  ecc: Add powerpc64 assembly for ecc_25519_modp
  ecc: Add powerpc64 assembly for ecc_448_modp

 powerpc64/ecc-curve25519-modp.asm | 103 ++++++++++++++
 powerpc64/ecc-curve448-modp.asm   | 174 +++++++++++++++++++++++
 powerpc64/ecc-secp192r1-modp.asm  |  93 ++++++++++++
 powerpc64/ecc-secp224r1-modp.asm  | 123 ++++++++++++++++
 powerpc64/ecc-secp256r1-redc.asm  | 144 +++++++++++++++++++
 powerpc64/ecc-secp384r1-modp.asm  | 227 ++++++++++++++++++++++++++++++
 powerpc64/ecc-secp521r1-modp.asm  | 166 ++++++++++++++++++++++
 7 files changed, 1030 insertions(+)
 create mode 100644 powerpc64/ecc-curve25519-modp.asm
 create mode 100644 powerpc64/ecc-curve448-modp.asm
 create mode 100644 powerpc64/ecc-secp192r1-modp.asm
 create mode 100644 powerpc64/ecc-secp224r1-modp.asm
 create mode 100644 powerpc64/ecc-secp256r1-redc.asm
 create mode 100644 powerpc64/ecc-secp384r1-modp.asm
 create mode 100644 powerpc64/ecc-secp521r1-modp.asm

-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211125084735</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-25 08:47:35-0400</timestampReceived><subject>[PATCH 1/7] ecc: Add powerpc64 assembly for ecc_192_modp</subject><body>

Signed-off-by: Amitay Isaacs &lt;amitay@ozlabs.org&gt;
---
 powerpc64/ecc-secp192r1-modp.asm | 93 ++++++++++++++++++++++++++++++++
 1 file changed, 93 insertions(+)
 create mode 100644 powerpc64/ecc-secp192r1-modp.asm

diff --git a/powerpc64/ecc-secp192r1-modp.asm b/powerpc64/ecc-secp192r1-modp.asm
new file mode 100644
index 00000000..97c71a83
--- /dev/null
+++ b/powerpc64/ecc-secp192r1-modp.asm
@@ -0,0 +1,93 @@
+C powerpc64/ecc-secp192r1-modp.asm
+
+ifelse(`
+   Copyright (C) 2021 Amitay Isaacs, IBM Corporation
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+	.file "ecc-secp192r1-modp.asm"
+
+define(`RP', `r4')
+define(`XP', `r5')
+
+define(`T0', `r6')
+define(`T1', `r7')
+define(`T2', `r8')
+define(`T3', `r9')
+define(`C1', `r10')
+define(`C2', `r11')
+
+	C void ecc_secp192r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	.text
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_ecc_secp192r1_modp)
+	ld	T0, 0(XP)
+	ld	T1, 8(XP)
+	ld	T2, 16(XP)
+
+	li	C1, 0
+	li	C2, 0
+
+	ld	T3, 24(XP)
+	addc	T0, T3, T0
+	adde	T1, T3, T1
+	addze	T2, T2
+	addze	C1, C1
+
+	ld	T3, 32(XP)
+	addc	T1, T3, T1
+	adde	T2, T3, T2
+	addze	C1, C1
+
+	ld	T3, 40(XP)
+	addc	T0, T3, T0
+	adde	T1, T3, T1
+	adde	T2, T3, T2
+	addze	C1, C1
+
+	addc	T0, C1, T0
+	adde	T1, C1, T1
+	addze	T2, T2
+	addze	C2, C2
+
+	li	C1, 0
+	addc	T0, C2, T0
+	adde	T1, C2, T1
+	addze	T2, T2
+	addze	C1, C1
+
+	addc	T0, C1, T0
+	adde	T1, C1, T1
+	addze	T2, T2
+
+	std	T0, 0(RP)
+	std	T1, 8(RP)
+	std	T2, 16(RP)
+
+	blr
+EPILOGUE(_nettle_ecc_secp192r1_modp)
-- 
2.33.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211130191733</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-11-30 19:17:33-0400</timestampReceived><subject>Re: [PATCH 1/7] ecc: Add powerpc64 assembly for ecc_192_modp</subject><body>

Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:

&gt; +	.file "ecc-secp192r1-modp.asm"

Thanks, I'm looking at this file first (being the simplest, even though
the security level of this curve is a bit low for current usage, so
performance not of so great importance).

I'm quite new to powerpc, so I'm refering to the instruction reference,
and trying to learn as we go along. It seems addc is addition with carry
output (but no carry input), adde is addition with carry input and
output, and addze is addition of zero with carry input and output.

&gt; +define(`RP', `r4')
&gt; +define(`XP', `r5')
&gt; +
&gt; +define(`T0', `r6')
&gt; +define(`T1', `r7')
&gt; +define(`T2', `r8')
&gt; +define(`T3', `r9')
&gt; +define(`C1', `r10')
&gt; +define(`C2', `r11')

As I understand it, we could also use register r3 (unused input
argument), but we don't need to, since we have enough free scratch
registers.

&gt; +	C void ecc_secp192r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
&gt; +	.text
&gt; +define(`FUNC_ALIGN', `5')
&gt; +PROLOGUE(_nettle_ecc_secp192r1_modp)
&gt; +	ld	T0, 0(XP)
&gt; +	ld	T1, 8(XP)
&gt; +	ld	T2, 16(XP)
&gt; +
&gt; +	li	C1, 0
&gt; +	li	C2, 0
&gt; +
&gt; +	ld	T3, 24(XP)
&gt; +	addc	T0, T3, T0
&gt; +	adde	T1, T3, T1
&gt; +	addze	T2, T2
&gt; +	addze	C1, C1
&gt; +
&gt; +	ld	T3, 32(XP)
&gt; +	addc	T1, T3, T1
&gt; +	adde	T2, T3, T2
&gt; +	addze	C1, C1
&gt; +
&gt; +	ld	T3, 40(XP)
&gt; +	addc	T0, T3, T0
&gt; +	adde	T1, T3, T1
&gt; +	adde	T2, T3, T2
&gt; +	addze	C1, C1

To analyze what we are doing, I'm using the Nettle and GMP convention
that B = 2^64 (bignum base), then p = B^3 - B - 1, or B^3 = B + 1 (mod
p). Denote the six input words as

  &lt;a_5,a_4,a_3,a_2,a_1,a_0&gt;

representing the number 

  B^5 a_5 + B^4 a_4 + B^3 a_3 + B^2 a_2 + B a_1 + a_0

The accumulation above, as I understand it, computes

  &lt;c_1,t_2,t_1,t_0&gt; = &lt;a_2,a_1,a_0&gt; + a_3 (B+1) + a_4 (B^2 + B) 
                    + a_5 (B^2 + B + 1&gt;

or more graphically,

      a_2 a_2 a_1
          a_3 a_3
      a_4 a_4
    + a_5 a_5 a_5
  ---------------
  c_1 t_2 t_1 t_0

This number is &lt; 3 B^3, which means that c_1 is 0, 1 or 2 (each of the
addze instructions can increment it).

This looks nice, and I think it is pretty efficient too. It looks a bit
different from what the x86_64 code is doing; maybe the latter could be
improved.

&gt; +	addc	T0, C1, T0
&gt; +	adde	T1, C1, T1
&gt; +	addze	T2, T2
&gt; +	addze	C2, C2

Above, c_1 is folded in at the right places, 

  &lt;c_2,t_2,t_1,t_0&gt;  &lt;--  &lt;t_2, t_1, t_0&gt; + c_1 (B + 1)

This number is &lt; B^3 + 3 (B+1). This implies that in the (quite
unlikely) case we get carry out, i.e., c_2 = 1, then the value of the
low three words is &lt; 3 (B+1). That means that there can be no new carry
out when folding c_2.

&gt; +	li	C1, 0
&gt; +	addc	T0, C2, T0
&gt; +	adde	T1, C2, T1
&gt; +	addze	T2, T2
&gt; +	addze	C1, C1
&gt; +
&gt; +	addc	T0, C1, T0
&gt; +	adde	T1, C1, T1
&gt; +	addze	T2, T2

So I think this final folding could be reduced to just

	addc	T0, C2, T0
	adde	T1, C2, T1
	addze	T2, T2

There's no carry out, from this, because either C2 was zero, or T2 was
small, &lt;= 3. Does that make sense?

&gt; +	std	T0, 0(RP)
&gt; +	std	T1, 8(RP)
&gt; +	std	T2, 16(RP)
&gt; +
&gt; +	blr
&gt; +EPILOGUE(_nettle_ecc_secp192r1_modp)

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211128101759</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-11-28 10:17:59-0400</timestampReceived><subject>Re: [PATCH 0/7] Add powerpc64 assembly for elliptic curves</subject><body>

Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:

&gt; This series of patches add the powerpc64 assembly for modp/redc functions
&gt; for elliptic curves P192, P224, P256, P384, P521, X25519 and X448. It results
&gt; in 15-30% performance improvements as measured on POWER9 system using
&gt; hogweed-benchmark.

Nice. For testing these functions, I recommend running

  while NETTLE_TEST_SEED=0 ./testsuite/ecc-mod-test ; do : ; done

and

  while NETTLE_TEST_SEED=0 ./testsuite/ecc-redc-test ; do : ; done

for a few hours.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211129123236</emailId><senderName>Tianjia Zhang</senderName><senderEmail>tianjia.zhang@linux.alibaba.com</senderEmail><timestampReceived>2021-11-29 12:32:36-0400</timestampReceived><subject>[PATCH v2 4/4] nettle-benchmark: bench SM3 hashes</subject><body>

Signed-off-by: Tianjia Zhang &lt;tianjia.zhang@linux.alibaba.com&gt;
---
 examples/nettle-benchmark.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 50a5815a..ba5dd284 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -909,7 +909,7 @@ main(int argc, char **argv)
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
       &amp;nettle_ripemd160, &amp;nettle_gosthash94,
       &amp;nettle_gosthash94cp, &amp;nettle_streebog256,
-      &amp;nettle_streebog512,
+      &amp;nettle_streebog512, &amp;nettle_sm3,
       NULL
     };
 
-- 
2.32.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211130022626</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-30 02:26:26-0400</timestampReceived><subject>Re: [PATCH 0/7] Add powerpc64 assembly for elliptic curves</subject><body>

On Sun, 2021-11-28 at 11:17 +0100, Niels Möller wrote:
&gt; Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:
&gt; 
&gt; &gt; This series of patches add the powerpc64 assembly for modp/redc
&gt; &gt; functions
&gt; &gt; for elliptic curves P192, P224, P256, P384, P521, X25519 and X448.
&gt; &gt; It results
&gt; &gt; in 15-30% performance improvements as measured on POWER9 system
&gt; &gt; using
&gt; &gt; hogweed-benchmark.
&gt; 
&gt; Nice. For testing these functions, I recommend running
&gt; 
&gt;   while NETTLE_TEST_SEED=0 ./testsuite/ecc-mod-test ; do : ; done
&gt; 
&gt; and
&gt; 
&gt;   while NETTLE_TEST_SEED=0 ./testsuite/ecc-redc-test ; do : ; done
&gt; 
&gt; for a few hours.
&gt; 
&gt; Regards,
&gt; /Niels

I have both tests running for more than 24 hours without failure.

Is there anything else I need to do?

Thanks.

Amitay.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211130235151</emailId><senderName>Amitay Isaacs</senderName><senderEmail>amitay@ozlabs.org</senderEmail><timestampReceived>2021-11-30 23:51:51-0400</timestampReceived><subject>Re: [PATCH 1/7] ecc: Add powerpc64 assembly for ecc_192_modp</subject><body>

On Tue, 2021-11-30 at 20:17 +0100, Niels Möller wrote:
&gt; Amitay Isaacs &lt;amitay@ozlabs.org&gt; writes:
&gt; 
&gt; &gt; +       .file "ecc-secp192r1-modp.asm"
&gt; 
&gt; Thanks, I'm looking at this file first (being the simplest, even
&gt; though
&gt; the security level of this curve is a bit low for current usage, so
&gt; performance not of so great importance).

Yes. The main focus was on curves p256 and higher.  For completeness
sake I added the assembly for p192 and p224 curves.

&gt; 
&gt; I'm quite new to powerpc, so I'm refering to the instruction
&gt; reference,
&gt; and trying to learn as we go along. It seems addc is addition with
&gt; carry
&gt; output (but no carry input), adde is addition with carry input and
&gt; output, and addze is addition of zero with carry input and output.
&gt; 
&gt; &gt; +define(`RP', `r4')
&gt; &gt; +define(`XP', `r5')
&gt; &gt; +
&gt; &gt; +define(`T0', `r6')
&gt; &gt; +define(`T1', `r7')
&gt; &gt; +define(`T2', `r8')
&gt; &gt; +define(`T3', `r9')
&gt; &gt; +define(`C1', `r10')
&gt; &gt; +define(`C2', `r11')
&gt; 
&gt; As I understand it, we could also use register r3 (unused input
&gt; argument), but we don't need to, since we have enough free scratch
&gt; registers.

Generally I avoided using r3 as it is the first input argument, but
also serves as the return value of the function.  So unless we are
running short of registers r3 is left untouched.  (Even though there
are 32 registers, only some of them can be used without saving them
first.)  For example, r3 is used in p224 modp implementation.

&gt; 
&gt; &gt; +       C void ecc_secp192r1_modp (const struct ecc_modulo *m,
&gt; &gt; mp_limb_t *rp)
&gt; &gt; +       .text
&gt; &gt; +define(`FUNC_ALIGN', `5')
&gt; &gt; +PROLOGUE(_nettle_ecc_secp192r1_modp)
&gt; &gt; +       ld      T0, 0(XP)
&gt; &gt; +       ld      T1, 8(XP)
&gt; &gt; +       ld      T2, 16(XP)
&gt; &gt; +
&gt; &gt; +       li      C1, 0
&gt; &gt; +       li      C2, 0
&gt; &gt; +
&gt; &gt; +       ld      T3, 24(XP)
&gt; &gt; +       addc    T0, T3, T0
&gt; &gt; +       adde    T1, T3, T1
&gt; &gt; +       addze   T2, T2
&gt; &gt; +       addze   C1, C1
&gt; &gt; +
&gt; &gt; +       ld      T3, 32(XP)
&gt; &gt; +       addc    T1, T3, T1
&gt; &gt; +       adde    T2, T3, T2
&gt; &gt; +       addze   C1, C1
&gt; &gt; +
&gt; &gt; +       ld      T3, 40(XP)
&gt; &gt; +       addc    T0, T3, T0
&gt; &gt; +       adde    T1, T3, T1
&gt; &gt; +       adde    T2, T3, T2
&gt; &gt; +       addze   C1, C1
&gt; 
&gt; To analyze what we are doing, I'm using the Nettle and GMP convention
&gt; that B = 2^64 (bignum base), then p = B^3 - B - 1, or B^3 = B + 1
&gt; (mod
&gt; p). Denote the six input words as
&gt; 
&gt;   &lt;a_5,a_4,a_3,a_2,a_1,a_0&gt;
&gt; 
&gt; representing the number 
&gt; 
&gt;   B^5 a_5 + B^4 a_4 + B^3 a_3 + B^2 a_2 + B a_1 + a_0
&gt; 
&gt; The accumulation above, as I understand it, computes
&gt; 
&gt;   &lt;c_1,t_2,t_1,t_0&gt; = &lt;a_2,a_1,a_0&gt; + a_3 (B+1) + a_4 (B^2 + B) 
&gt;                     + a_5 (B^2 + B + 1&gt;
&gt; 
&gt; or more graphically,
&gt; 
&gt;       a_2 a_2 a_1
&gt;           a_3 a_3
&gt;       a_4 a_4
&gt;     + a_5 a_5 a_5
&gt;   ---------------
&gt;   c_1 t_2 t_1 t_0
&gt; 
&gt; This number is &lt; 3 B^3, which means that c_1 is 0, 1 or 2 (each of
&gt; the
&gt; addze instructions can increment it).
&gt; 
&gt; This looks nice, and I think it is pretty efficient too. It looks a
&gt; bit
&gt; different from what the x86_64 code is doing; maybe the latter could
&gt; be
&gt; improved.
&gt; 
&gt; &gt; +       addc    T0, C1, T0
&gt; &gt; +       adde    T1, C1, T1
&gt; &gt; +       addze   T2, T2
&gt; &gt; +       addze   C2, C2
&gt; 
&gt; Above, c_1 is folded in at the right places, 
&gt; 
&gt;   &lt;c_2,t_2,t_1,t_0&gt;  &lt;--  &lt;t_2, t_1, t_0&gt; + c_1 (B + 1)
&gt; 
&gt; This number is &lt; B^3 + 3 (B+1). This implies that in the (quite
&gt; unlikely) case we get carry out, i.e., c_2 = 1, then the value of the
&gt; low three words is &lt; 3 (B+1). That means that there can be no new
&gt; carry
&gt; out when folding c_2.
&gt; 
&gt; &gt; +       li      C1, 0
&gt; &gt; +       addc    T0, C2, T0
&gt; &gt; +       adde    T1, C2, T1
&gt; &gt; +       addze   T2, T2
&gt; &gt; +       addze   C1, C1
&gt; &gt; +
&gt; &gt; +       addc    T0, C1, T0
&gt; &gt; +       adde    T1, C1, T1
&gt; &gt; +       addze   T2, T2
&gt; 
&gt; So I think this final folding could be reduced to just
&gt; 
&gt;         addc    T0, C2, T0
&gt;         adde    T1, C2, T1
&gt;         addze   T2, T2
&gt; 
&gt; There's no carry out, from this, because either C2 was zero, or T2
&gt; was
&gt; small, &lt;= 3. Does that make sense?

This was the first code I wrote using the exact calculation you have
outlined above.  However, I was not sure about the sizes of the carry
(C1 and C2).  I did notice the x86 code short-cutting the C2 folding,
but the reasoning was not apparent.

Thank you for explaining the bounds calculation.  That does help me
understand why C2 folding can be simplified as you have suggested.

&gt; 
&gt; &gt; +       std     T0, 0(RP)
&gt; &gt; +       std     T1, 8(RP)
&gt; &gt; +       std     T2, 16(RP)
&gt; &gt; +
&gt; &gt; +       blr
&gt; &gt; +EPILOGUE(_nettle_ecc_secp192r1_modp)
&gt; 
&gt; Regards,
&gt; /Niels
&gt; 

Amitay.
-- 

Good literature is about Love and War.
Junk Fiction is about Sex and Violence.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211022135450</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-10-22 13:54:50-0400</timestampReceived><subject>secp256r1 mod functions</subject><body>

Hi,

a while ago I was asked to explain the 64-bit C versions of
ecc_secp256r1_modp and ecc_secp256r1_modq (in ecc-secp256r1.c), and I
found that a bit difficult.

I've rewritten them, on branch
https://git.lysator.liu.se/nettle/nettle/-/blob/secp256r1-mod/ecc-secp256r1.c.
Main difference is handling of the case that next quotient is close to
2^{64}: Old code allowed the quotient to overflow 64 bits, using an
additional carry variable q2. New code ensures that next quotient is
always at most 2^{64} - 1.

For the new implementation, the modp function is a special case of the
2/1 division in https://gmplib.org/~tege/division-paper.pdf (would
usually need 3/2 division to get sufficient accuracy, but reduces to 2/1
since the next most significant word of p is 0), and the modq function
is a special case of divappr2, described in
https://www.lysator.liu.se/~nisse/misc/schoolbook-divappr.pdf.

I've not been able to measure any significant difference in speed (I get
somewhat noisy measurements from the examples/ecc-benchmark tool),
although I would expect the new code to be very slightly faster. These
functions are not that performance critical, since the bulk of the
reductions for this curve is done using redc, not mod.

Any additional testing, benchmarking, or code staring, is appreciated. I
will likely merge the new code to the master branch in a few days.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20211031073714</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-10-31 07:37:14-0400</timestampReceived><subject>Re: [S390x] Optimize SHA3 permute using vector facility</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made some documentation and comment improvements on the implementation,
&gt; the new doc illustrates the structure of main permute elements in more
&gt; detail. The update has also some improvements on the usage of instruction
&gt; set that yield a faster performance.

Thanks! Merged now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210902175440</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-02 17:54:40-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I've tried a different approach on branch
&gt; https://git.lysator.liu.se/nettle/nettle/-/tree/ppc64-efv2-check. Patch
&gt; below. (It makes sense to me to have the new check together with the ABI
&gt; check, but on second thought, probably a mistake to overload the ABI
&gt; variable. It would be better to have a separate configure variable, more
&gt; similar to the W64_ABI).

Another iteration, on that branch (sorry for the typo in the branch
name), or see patch below.

Stijn, can you try it out and see if it works for you?

Regards,
/Niels

diff --git a/config.m4.in b/config.m4.in
index d89325b8..b98a5817 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -5,6 +5,7 @@ define(`COFF_STYLE', `@ASM_COFF_STYLE@')dnl
 define(`TYPE_FUNCTION', `@ASM_TYPE_FUNCTION@')dnl
 define(`TYPE_PROGBITS', `@ASM_TYPE_PROGBITS@')dnl
 define(`ALIGN_LOG', `@ASM_ALIGN_LOG@')dnl
+define(`ELFV2_ABI', `@ELFV2_ABI@')dnl
 define(`W64_ABI', `@W64_ABI@')dnl
 define(`RODATA', `@ASM_RODATA@')dnl
 define(`WORDS_BIGENDIAN', `@ASM_WORDS_BIGENDIAN@')dnl
diff --git a/configure.ac b/configure.ac
index ebec8759..2ed4ab4e 100644
--- a/configure.ac
+++ b/configure.ac
@@ -311,6 +311,9 @@ AC_SUBST([GMP_NUMB_BITS])
 # Figure out ABI. Currently, configurable only by setting CFLAGS.
 ABI=standard
 
+ELFV2_ABI=no # For powerpc64
+W64_ABI=no   # For x86_64 windows
+
 case "$host_cpu" in
   [x86_64 | amd64])
     AC_TRY_COMPILE([
@@ -355,6 +358,15 @@ case "$host_cpu" in
     ], [
       ABI=64
     ])
+    if test "$ABI" = 64 ; then
+      AC_TRY_COMPILE([
+#if _CALL_ELF == 2
+#error ELFv2 ABI
+#endif
+      ], [], [], [
+	ELFV2_ABI=yes
+      ])
+    fi
     ;;
   aarch64*)
     AC_TRY_COMPILE([
@@ -750,7 +762,6 @@ IF_DLL='#'
 LIBNETTLE_FILE_SRC='$(LIBNETTLE_FORLINK)'
 LIBHOGWEED_FILE_SRC='$(LIBHOGWEED_FORLINK)'
 EMULATOR=''
-W64_ABI=no
 
 case "$host_os" in
   mingw32*|cygwin*)
@@ -1031,6 +1042,7 @@ AC_SUBST(ASM_TYPE_FUNCTION)
 AC_SUBST(ASM_TYPE_PROGBITS)
 AC_SUBST(ASM_MARK_NOEXEC_STACK)
 AC_SUBST(ASM_ALIGN_LOG)
+AC_SUBST(ELFV2_ABI)
 AC_SUBST(W64_ABI)
 AC_SUBST(ASM_WORDS_BIGENDIAN)
 AC_SUBST(EMULATOR)
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index 187a49b8..b59f0863 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -1,7 +1,7 @@
 define(`PROLOGUE',
 `.globl C_NAME($1)
 DECLARE_FUNC(C_NAME($1))
-ifelse(WORDS_BIGENDIAN,no,
+ifelse(ELFV2_ABI,yes,
 `ifdef(`FUNC_ALIGN',`.align FUNC_ALIGN')
 C_NAME($1):
 addis 2,12,(.TOC.-C_NAME($1))@ha
@@ -17,7 +17,7 @@ ifdef(`FUNC_ALIGN',`.align FUNC_ALIGN')
 undefine(`FUNC_ALIGN')')
 
 define(`EPILOGUE',
-`ifelse(WORDS_BIGENDIAN,no,
+`ifelse(ELFV2_ABI,yes,
 `.size C_NAME($1), . - C_NAME($1)',
 `.size .C_NAME($1), . - .C_NAME($1)
 .size C_NAME($1), . - .C_NAME($1)')')

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210904150948</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-09-04 15:09:48-0400</timestampReceived><subject>Re: Reorganization of x86_64 aesni code</subject><body>

On Thu, Sep 2, 2021 at 7:48 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I've merged a reorganization of the x86_64 aesni code to the
&gt; master-updates branch for testing. This replaces the
&gt; x86_64/aesni/aes-*crypt-internal.asm files with separate files for the
&gt; different key sizes, as has been discussed earlier.
&gt;
&gt; And I've implemented 2-way interleaving, i.e., doing 2 blocks at a time,
&gt; which gave a nice speedup on the order of 15% in my tests. I may be
&gt; worthwhile to go to 3-way or 4-way, but I don't plan to try that soon.
&gt;

Great speedup! I tweaked the implementation to do 4-way interleaving but it
seems has no performance benefits over the 2-way interleaving by running
the benchmark on my machine with Intel Comet Lake architecture.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210918083535</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-18 08:35:35-0400</timestampReceived><subject>Re: Feature request: OCB mode</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; If someone wants to work on it, please post to the list. I might look
&gt; into it myself, but as you have noticed, I have rather limited hacking
&gt; time.

I've given it a try, see branch ocb-mode. Based on RFC 7253. Passes
tests, but not particularly optimized. Some comments and questions:

1. Most of the operations use only the enrypt function of the underlying
   block cipher. Except ocb decrypt, which needs *both* the decrypt
   function and the encrypt function. For ciphers that use different key
   setup for encrypt and decrypt, e.g., AES, that means that to decrypt
   OCB one needs to initialize two separate aes128_ctx. To call the
   somewhat unwieldy

      void
      ocb_decrypt (struct ocb_ctx *ctx, const struct ocb_key *key,
                   const void *encrypt_ctx, nettle_cipher_func *encrypt,
                   const void *decrypt_ctx, nettle_cipher_func *decrypt,
                   size_t length, uint8_t *dst, const uint8_t *src);

2. It's not obvious how to best manage the different L_i values. Can be
   computed upfront, on demand, or cached in some way. Current code
   computes only L_*, L_$ and L_0 up front (part of ocb_set_key), and
   the others recomputed each time they're needed.

3. The processing of the authenticated data doesn't depend on the nonce
   in any way. That means that if one processes several messages with
   the same key and associated data, the associated data can be
   processed once, with the same sum reused for all messages.

   Is that something that is useful in practice, and which nettle
   interfaces should support?

4. The way the nonce is used seems designed to allow cheap incrementing
   of the nonce. The nonce is used to determine

     Offset_0 = Stretch[1+bottom..128+bottom]

   where "bottom" is the least significant 6 bits of the nonce, acting as
   a shift, and "Stretch" is independent of those nonce bits, so
   unchanged on all but one out of 64 nonce increments.

   Should nettle support some kind of auto-incrementing nonce that takes
   advantage of this? Nettle does something similar for UMAC (not sure
   if there are others).

As I said, current code is not particularly optimized, but OCB has
potential to be quite fast. The per-block processing for authentication
of the message (not associated data) is just an XOR. And
encryption/decryption can be done several blocks in parallel, like CTR
mode. If we do, e.g., 4 or 8 blocks at a time, there will be a fairly
regular structure of the needed Offset_i values, possibly making them
cheaper to setup, but I haven't yet looked into those details.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210919085628</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-09-19 08:56:28-0400</timestampReceived><subject>Re: CBC-AES (was: Re: [S390x] Optimize AES modes)</subject><body>

On Mon, Sep 13, 2021 at 5:08 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; I've also added a cbc-aes128-encrypt.asm.
&gt; &gt; That gives more significant speedup, almost 60%. I think main reason for
&gt; &gt; the speedup is that we avoid reloading subkeys between blocks.
&gt;
&gt; I've continued this path, see branch aes-cbc. The aes128 variant is at
&gt;
&gt;
&gt; https://git.lysator.liu.se/nettle/nettle/-/blob/aes-cbc/x86_64/aesni/cbc-aes128-encrypt.asm
&gt;
&gt; Benchmark results are positive but a bit puzzling. On my laptop (AMD
&gt; Ryzen 5) I get
&gt;
&gt;             aes128  ECB encrypt 5450.18
&gt;
&gt; This is the latest version, doing two blocks per iteration.
&gt;
&gt;             aes128  CBC encrypt  547.34
&gt;
&gt; The general CBC mode written in C, with one call to aes128_encrypt per
&gt; block. 10(!) times slower than ECB.
&gt;
&gt;         cbc_aes128      encrypt  865.11
&gt;
&gt; The new assembly function. Almost 60% speedup over the old code, which
&gt; is nice, and large enough that it seems motivated to have the new
&gt; functin. But still 6 times slower than ECB. I'm not sure why. Let's look
&gt; a bit closer at cycle numbers.
&gt;
&gt; Not sure I get accurate cycle numbers (it's a bit tricky with variable
&gt; features and turbo modes and whatnot), but it looks like ECB mode is 6
&gt; cycles per block, which would be consistent with issue of two aesenc
&gt; instructions per block. While the CBC mode is 37 cycles per block,
&gt; almost 4 cycles per aesenc.
&gt;
&gt; This could be explained if (i) latency of aesenc is 3-4 cycles, and (ii)
&gt; the processor's out-of-order machinery results in as many as 7-8 blocks
&gt; processed in parallel when executing the ECB loop, i.e., instruction
&gt; issue for 3-4 iterations through the loop before the results of the
&gt; first iteration is ready.
&gt;

I did the tests on Intel Comet Lake architecture and I can't think of
another explanation, it seems x86_64 arch issues multiple blocks
simultaneously without hand-written unrolling of the block loop. Also,
Intel processors or at least Intel Comet Lake arch implements this
machinery in a more ideal way than your testing processor (AMD Ryzen 5) so
you don't even need to have 2-way interleaving of AES-ECB implementation
nor a separate AES-CBC implementation. I got the same benchmark speed of
ECB and CBC modes for all cases with CBC mode being always 6 times slower
than ECB mode.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210920143247</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-20 14:32:47-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I got almost 12% speedup of optimizing the sha3_permute() function using
&gt; the SHA hardware accelerator of s390x, is it worth adding that assembly
&gt; implementation?

For such a small assembly function, I think it's worth the effort (more
questionable if it was worth adding the special instructions for it...).

If you have the time, you could also try out doing it with vector
registers, like on x86_64 and arm/neon. Some difficulties in the x86_64
implementation were (i) xmm register shortage, (ii) moving 64-bit pieces
between the 128-bit xmm registers, and (iii) rotating the 64-bit pieces
of an xmm register by different shift counts.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210922155747</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-22 15:57:47-0400</timestampReceived><subject>Structural fixes to the manual</subject><body>

I've spent some time to improve structure (mostly non-text changes) of
the manual.

1. Deleted all explicit node pointers in nettle.texinfo, instead letting
   makeinfo infer the node structure. This is the recommended way these
   days, according to texinfo documentation.

2. Changed the make rules producing nettle.pdf to use texi2pdf, instead
   of the chain texi2dvi + dvips + pstopdf. Most obvious result is that
   hyperlinks work better, and output file is slightly smaller. It's
   done in whatever way is default in texi2pdf, I haven't tried to check
   the details (e.g., what kind of fonts are used, and if they're all
   embedded in the file).

3. Split the huge Cipher functions node into one node per cipher.

4. Fixed a few places where urls or example code was too wide for the
   page.

According to the docs
(https://www.gnu.org/software/texinfo/manual/texinfo/html_node/URL-Line-Breaking.html),
line breaks should be automatically added in urls when needed (and
that's true also according to the docs for texinfo-6.7, which is what I
have installed), but that didn't work at all when I tried it, so I've
added a few explicit hints on how to break long urls. Also the
@urefbreakstyle command wasn't recognized at all. Anyone here more
familiar with texinfo that can explain?

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210813121608</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-13 12:16:08-0400</timestampReceived><subject>[S390x] Optimize SHA256 and SHA512 compress functions</subject><body>

I made a merge request in the main repository that optimizes SHA256 and
SHA512 compress functions for s390x architecture with fat build support !35
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/35&gt;.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210816164919</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-08-16 16:49:19-0400</timestampReceived><subject>Re: Is there an equivalent to curve25519_mul for ECC keys?</subject><body>

Thanks a lot for the response!

As I could see, with ecc_point_mul, only the point x of the scalar r is 
useful for the ecdh-es computation.

The implementation was quick and easy with that :)

/Nicolas

Le 2021-08-10 Ã  17 h 32, Niels MÃ¶ller a Ã©crit  :
&gt; Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:
&gt; 
&gt;&gt; I'm wondering if there is a function of a combination of functions to
&gt;&gt; perform a DH computation using ECC keys and their parameters "struct
&gt;&gt; ecc_point *pub1, struct ecc_scalar *key2"?
&gt; 
&gt; ecc_point_mul (declared in ecc.h) is intended to do that. There's also
&gt; a variant ecc_point_mul_g.
&gt; 
&gt; But it seems they're not properly documented in the manual.
&gt; 
&gt; Regards,
&gt; /Niels
&gt; 
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210822180359</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-22 18:03:59-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; That's right, in little-endian systems I got "#define _CALL_ELF 2" while in
&gt; big-endian ones that value is 1 except when using musl.

That's good.

&gt; I've updated the
&gt; patch in the branch
&gt; https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix to exploit
&gt; this distinction.

I've tried a different approach on branch
https://git.lysator.liu.se/nettle/nettle/-/tree/ppc64-efv2-check. Patch
below. (It makes sense to me to have the new check together with the ABI
check, but on second thought, probably a mistake to overload the ABI
variable. It would be better to have a separate configure variable, more
similar to the W64_ABI).

Unfortunaly, the CI cross builds aren't working at the moment (the
buildenv images are based on Debian Buster ("stable" at the time images
were built), and nettle's ci scripts do apt-get update and apt-get
install, which now attempts to get Bullseye packages (new "stable" since
a week ago)).

Regards,
/Niels

diff --git a/config.m4.in b/config.m4.in
index d89325b8..2ac19a84 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -5,6 +5,7 @@ define(`COFF_STYLE', `@ASM_COFF_STYLE@')dnl
 define(`TYPE_FUNCTION', `@ASM_TYPE_FUNCTION@')dnl
 define(`TYPE_PROGBITS', `@ASM_TYPE_PROGBITS@')dnl
 define(`ALIGN_LOG', `@ASM_ALIGN_LOG@')dnl
+define(`ABI', `@ABI@')dnl
 define(`W64_ABI', `@W64_ABI@')dnl
 define(`RODATA', `@ASM_RODATA@')dnl
 define(`WORDS_BIGENDIAN', `@ASM_WORDS_BIGENDIAN@')dnl
diff --git a/configure.ac b/configure.ac
index ebec8759..0efa5795 100644
--- a/configure.ac
+++ b/configure.ac
@@ -353,8 +353,15 @@ case "$host_cpu" in
     ], [], [
       ABI=32
     ], [
-      ABI=64
-    ])
+      AC_TRY_COMPILE([
+#if _CALL_ELF == 2
+#error ELFv2 ABI
+#endif
+      ], [], [
+	ABI=64v1
+      ], [
+	ABI=64v2
+      ])])
     ;;
   aarch64*)
     AC_TRY_COMPILE([
@@ -514,7 +521,7 @@ if test "x$enable_assembler" = xyes ; then
       fi
       ;;
     *powerpc64*)
-      if test "$ABI" = 64 ; then
+      if test "$ABI" != 32 ; then
 	GMP_ASM_POWERPC_R_REGISTERS
 	asm_path="powerpc64"
 	if test "x$enable_fat" = xyes ; then
@@ -1032,6 +1039,7 @@ AC_SUBST(ASM_TYPE_PROGBITS)
 AC_SUBST(ASM_MARK_NOEXEC_STACK)
 AC_SUBST(ASM_ALIGN_LOG)
 AC_SUBST(W64_ABI)
+AC_SUBST(ABI)
 AC_SUBST(ASM_WORDS_BIGENDIAN)
 AC_SUBST(EMULATOR)
 AC_SUBST(ASM_X86_ENDBR)
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index 187a49b8..60c7465d 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -1,7 +1,7 @@
 define(`PROLOGUE',
 `.globl C_NAME($1)
 DECLARE_FUNC(C_NAME($1))
-ifelse(WORDS_BIGENDIAN,no,
+ifelse(ABI,64v2,
 `ifdef(`FUNC_ALIGN',`.align FUNC_ALIGN')
 C_NAME($1):
 addis 2,12,(.TOC.-C_NAME($1))@ha
@@ -17,7 +17,7 @@ ifdef(`FUNC_ALIGN',`.align FUNC_ALIGN')
 undefine(`FUNC_ALIGN')')
 
 define(`EPILOGUE',
-`ifelse(WORDS_BIGENDIAN,no,
+`ifelse(ABI,64v2,
 `.size C_NAME($1), . - C_NAME($1)',
 `.size .C_NAME($1), . - .C_NAME($1)
 .size C_NAME($1), . - .C_NAME($1)')')


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210829153708</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-29 15:37:08-0400</timestampReceived><subject>Re: Big endian tests (no mips) (was: Re: Build problem on ppc64be + musl)</subject><body>

On Mon, Aug 23, 2021 at 8:59 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; Unfortunaly, the CI cross builds aren't working at the moment (the
&gt; &gt; buildenv images are based on Debian Buster ("stable" at the time images
&gt; &gt; were built), and nettle's ci scripts do apt-get update and apt-get
&gt; &gt; install, which now attempts to get Bullseye packages (new "stable" since
&gt; &gt; a week ago)).
&gt;
&gt; Images now updated to debian stable (thanks, Daiki!). But we'll have to
&gt; drop mips tests for now, since current setup assumes archs under tests
&gt; are available in debian, and mips has been discontinued as a debian
&gt; release architecture. Other cross builds now work (change to drop mips
&gt; is on the master-updates branch). If you have ideas on how to revive mips
&gt; tests, that's welcome, but for now we'll have to do without.
&gt;
&gt; I would like to keep testing on big-endian. s390x is big-endian, right?
&gt; And so is powerpc64 (non -el). So it would be nice to configure cross
&gt; tests on one of those platforms configured with --disable-assembler, to
&gt; test portability of the C code. Are s390x cross tools and qemu-user in
&gt; good enough shape (it's an official debian release arch), or is
&gt; powerpc64 a better option?
&gt;

Yes, s390x is big-endian and it's good for such purposes. Along being
officially supported in debian releases, it runs natively on remote
instance in gitlab CI.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210829155254</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-29 15:52:54-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

Applying hardware-accelerated SHA3 instruction to optimize sha3_permute
function for s390x arch has an insignificant impact on the performance, I'm
wondering what we can do to take full advantage of those instructions.
Optimizing sha3_absorb seems a good way to go since the s390x-specific
accelerator implies permuting of state bytes and XOR operations but the
downside of implementing this function is handling the block size variants
for each mode, S390x arch supports the standard block sizes so we can
branch for each standard size in the supported modes but should we consider
unexpected block size during the implementation?

regards,
Mamone

On Sun, Aug 29, 2021 at 5:39 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I added support for the sha1_compress_n function on arm architecture in
&gt; the same branch
&gt; https://git.lysator.liu.se/mamonet/nettle/-/tree/sha1-compress-n
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt; On Sat, Aug 21, 2021 at 5:22 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; On Thu, Aug 19, 2021 at 8:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; What is x86/sha1-compress.nlms? How can I implement nettle_copmress_n
&gt;&gt;&gt; &gt; function for that particular type?
&gt;&gt;&gt;
&gt;&gt;&gt; That's an input file for an obscure "loop mixer" tool, IIRC, it was
&gt;&gt;&gt; written mainly by David Harvey for use with GMP loops. This tool tries
&gt;&gt;&gt; permuting the instructions of an assembly loop, taking dependencies into
&gt;&gt;&gt; account, benchmarks each variant, and tries to find the fastest
&gt;&gt;&gt; instruction sequence. It seems I tried this toool on x86 sha1_compress
&gt;&gt;&gt; back in 2009, on an AMD K7, and it gave a 17% speedup at the time,
&gt;&gt;&gt; according to commit message for 1e757582ac7f8465b213d9761e17c33bd21ca686.
&gt;&gt;&gt;
&gt;&gt;&gt; So you can just ignore this file. And you may want to look at the more
&gt;&gt;&gt; readable version of x86/sha1_compress.asm, just before that commit.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Thanks, I left the nlms files as are and modified x86/sha1_compress.asm
&gt;&gt; to work with the sha1_compress_n function. I've kept the function
&gt;&gt; parameters in the stack since the instructions are able to execute on
&gt;&gt; memory operands and x86 calling convention passes the parameters through
&gt;&gt; the stack, I'm not sure if those parameters are read-only or can be
&gt;&gt; adjustable, TBH I haven't run into x86 32-bit code for 8 years. What I did
&gt;&gt; is reserving fields in the stack for two parameters and adjusting both
&gt;&gt; values in the new locations to keep the original values unmodified.
&gt;&gt;
&gt;&gt; regards,
&gt;&gt; Mamone
&gt;&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210830195134</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-30 19:51:34-0400</timestampReceived><subject>Re: Big endian tests (no mips)</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Mon, Aug 23, 2021 at 8:59 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; I would like to keep testing on big-endian. s390x is big-endian, right?
&gt;&gt; And so is powerpc64 (non -el). So it would be nice to configure cross
&gt;&gt; tests on one of those platforms configured with --disable-assembler, to
&gt;&gt; test portability of the C code. Are s390x cross tools and qemu-user in
&gt;&gt; good enough shape (it's an official debian release arch), or is
&gt;&gt; powerpc64 a better option?
&gt;&gt;
&gt;
&gt; Yes, s390x is big-endian and it's good for such purposes. Along being
&gt; officially supported in debian releases, it runs natively on remote
&gt; instance in gitlab CI.

I've just added an s390x cross-build to the gitlab ci, with
--disable-assembler to exercise all #if WORDS_BIGENDIAN. 

I noticed that for some of the archs (powerpc64, powerpc64el, s390x,
i.e., the ones not used in gnutls tests) we don't have any cross
libgmp-dev packages preinstalled in the image, and since we don't
explicitly install them either, there's no test coverage of public key
functions in these builds. I'll see if I can fix that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210901101220</emailId><senderName>Justus Winter</senderName><senderEmail>justus@sequoia-pgp.org</senderEmail><timestampReceived>2021-09-01 10:12:20-0400</timestampReceived><subject>Feature request: OCB mode</subject><body>

[Attachment #2 (multipart/signed)]


Hello,

we (Sequoia PGP) would love to see OCB being implemented in Nettle.  The
OpenPGP working group is working on a revision of RFC4880, which will
mostly be a cryptographic refresh, and will bring AEAD to OpenPGP.

The previous -now abandoned- draft called for EAX being mandatory, and
OCB being optional [0].  This was motivated by OCB being encumbered by
patents.  However, said patents were waived by the holder [1].

0: https://datatracker.ietf.org/doc/html/draft-ietf-openpgp-rfc4880bis-10#section-9.6
1: https://mailarchive.ietf.org/arch/msg/cfrg/qLTveWOdTJcLn4HP3ev-vrj05Vg/

With OCB being no longer patent-encumbered, it seems preferable over the
two-pass EAX construction.  Therefore, it seems plausible that the WG
makes OCB mandatory to implement.  To support that in Sequoia, we'd need
support for that in Nettle (Nettle is our main cryptographic backend).

Unfortunately, we don't have the expertise in our team to contribute a
patch, and we currently aren't in a position to offer funding for the
implementation.

Thanks,
Justus

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210913150850</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-13 15:08:50-0400</timestampReceived><subject>CBC-AES (was: Re: [S390x] Optimize AES modes)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I've also added a cbc-aes128-encrypt.asm.
&gt; That gives more significant speedup, almost 60%. I think main reason for
&gt; the speedup is that we avoid reloading subkeys between blocks.

I've continued this path, see branch aes-cbc. The aes128 variant is at 

https://git.lysator.liu.se/nettle/nettle/-/blob/aes-cbc/x86_64/aesni/cbc-aes128-encrypt.asm

Benchmark results are positive but a bit puzzling. On my laptop (AMD
Ryzen 5) I get

            aes128  ECB encrypt 5450.18

This is the latest version, doing two blocks per iteration.

            aes128  CBC encrypt  547.34

The general CBC mode written in C, with one call to aes128_encrypt per
block. 10(!) times slower than ECB.

        cbc_aes128      encrypt  865.11

The new assembly function. Almost 60% speedup over the old code, which
is nice, and large enough that it seems motivated to have the new
functin. But still 6 times slower than ECB. I'm not sure why. Let's look
a bit closer at cycle numbers.

Not sure I get accurate cycle numbers (it's a bit tricky with variable
features and turbo modes and whatnot), but it looks like ECB mode is 6
cycles per block, which would be consistent with issue of two aesenc
instructions per block. While the CBC mode is 37 cycles per block,
almost 4 cycles per aesenc. 

This could be explained if (i) latency of aesenc is 3-4 cycles, and (ii)
the processor's out-of-order machinery results in as many as 7-8 blocks
processed in parallel when executing the ECB loop, i.e., instruction
issue for 3-4 iterations through the loop before the results of the
first iteration is ready.

The interface for the new function is 

  struct cbc_aes128_ctx CBC_CTX(struct aes128_ctx, AES_BLOCK_SIZE);
  void
  cbc_aes128_encrypt(struct cbc_aes128_ctx *ctx, size_t length, 
                     uint8_t *dst, const uint8_t *src);

I'm not that fond of the struct cbc_aes128_ctx though, which includes
both (constant) subkeys and iv. So I'm considering changing that to

  void
  cbc_aes128_encrypt(const struct aes128_ctx *ctx, uint8_t *iv,
                     size_t length, uint8_t *dst, const uint8_t *src);

I.e., similar to cbc_encrypt, but without the arguments
nettle_cipher_func *f, size_t block_size.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210810205513</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-10 20:55:13-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request in the main repository that optimizes SHA1 for s390x
&gt; architecture with fat build support !33
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33&gt;.

Regarding the discussion on
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33#note_10005:
It seems the sha1 instructions on s390x are fast enough that the
overhead of loading constants, and loading and storing the state, all
per block, is a significant cost.

I think it makes sense to change the internal convention for
_sha1_compress so that it can do multiple blocks. There are currently 5
assembly implementations that would need updating: arm/v6, arm64/crypto, x86,
x86_64 and x86_64/sha_ni. And the C implementation, of course.

If it turns out to be too large a change to do them all at once, one
could introduce some new _sha1_compress_n function or the like, and use
when available. Actually, we probably need to do that anyway, since for
historical reasons, _nettle_sha1_compress is a public function, and needs
to be kept (as just a simple C wrapper) for backwards compatibility.
Changing it incrementally should be doable but a bit hairy.

There are some other similar compression functions with
assembly implementation, for md5, sha256 and sha512. But there's no need
to change them all at the same time, or at all.

Regarding the MD_UPDATE macro, that one is defined in the public header
file macros.h (which in retrospect was a mistake). So it's probably best
to leave it unchanged. New macros for the new convention should be put
into some internal header, e.g., md-internal.h.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210812132633</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-12 13:26:33-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

On Tue, Aug 10, 2021 at 11:55 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I made a merge request in the main repository that optimizes SHA1 for
&gt; s390x
&gt; &gt; architecture with fat build support !33
&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33&gt;.
&gt;
&gt; Regarding the discussion on
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33#note_10005:
&gt; It seems the sha1 instructions on s390x are fast enough that the
&gt; overhead of loading constants, and loading and storing the state, all
&gt; per block, is a significant cost.
&gt;
&gt; I think it makes sense to change the internal convention for
&gt; _sha1_compress so that it can do multiple blocks. There are currently 5
&gt; assembly implementations that would need updating: arm/v6, arm64/crypto,
&gt; x86,
&gt; x86_64 and x86_64/sha_ni. And the C implementation, of course.
&gt;
&gt; If it turns out to be too large a change to do them all at once, one
&gt; could introduce some new _sha1_compress_n function or the like, and use
&gt; when available. Actually, we probably need to do that anyway, since for
&gt; historical reasons, _nettle_sha1_compress is a public function, and needs
&gt; to be kept (as just a simple C wrapper) for backwards compatibility.
&gt; Changing it incrementally should be doable but a bit hairy.
&gt;
&gt; There are some other similar compression functions with
&gt; assembly implementation, for md5, sha256 and sha512. But there's no need
&gt; to change them all at the same time, or at all.
&gt;
&gt; Regarding the MD_UPDATE macro, that one is defined in the public header
&gt; file macros.h (which in retrospect was a mistake). So it's probably best
&gt; to leave it unchanged. New macros for the new convention should be put
&gt; into some internal header, e.g., md-internal.h.
&gt;

I've initialized a support of sha1_compress_n function in this branch
https://git.lysator.liu.se/mamonet/nettle/-/tree/sha1-compress-n
The function works and performs as exprected, I also adapted sha1_compress
of s390x and arm64 with the new compress function.
Predictably, SHA1 update is now equally performing with the OpenSSL
function on arm64 architecture. Benchmark of executing
examples/nettle-benchmark on arm64:
         Algorithm         mode        Mbyte/s
         sha1               update       849.82
         openssl sha1  update       849.73
Benchmark of executing examples/nettle-benchmark on s390x:
        Algorithm         mode        Mbyte/s
         sha1               update       1791.25
The s390x performance of the new compress function now doubles the speed of
the single block optimized function using built-in SHA1 accelerator.
Yet, there are implementations of x86, x86_64, and arm architectures to
adapt with the new compress function, and the patch may have potential for
further improvements in terms of naming convention and documentation.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210814231056</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-14 23:10:56-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

On Thu, Aug 12, 2021 at 4:26 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Tue, Aug 10, 2021 at 11:55 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt;
&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; I made a merge request in the main repository that optimizes SHA1 for
&gt;&gt; s390x
&gt;&gt; &gt; architecture with fat build support !33
&gt;&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33&gt;.
&gt;&gt;
&gt;&gt; Regarding the discussion on
&gt;&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33#note_10005:
&gt;&gt; It seems the sha1 instructions on s390x are fast enough that the
&gt;&gt; overhead of loading constants, and loading and storing the state, all
&gt;&gt; per block, is a significant cost.
&gt;&gt;
&gt;&gt; I think it makes sense to change the internal convention for
&gt;&gt; _sha1_compress so that it can do multiple blocks. There are currently 5
&gt;&gt; assembly implementations that would need updating: arm/v6, arm64/crypto,
&gt;&gt; x86,
&gt;&gt; x86_64 and x86_64/sha_ni. And the C implementation, of course.
&gt;&gt;
&gt;&gt; If it turns out to be too large a change to do them all at once, one
&gt;&gt; could introduce some new _sha1_compress_n function or the like, and use
&gt;&gt; when available. Actually, we probably need to do that anyway, since for
&gt;&gt; historical reasons, _nettle_sha1_compress is a public function, and needs
&gt;&gt; to be kept (as just a simple C wrapper) for backwards compatibility.
&gt;&gt; Changing it incrementally should be doable but a bit hairy.
&gt;&gt;
&gt;&gt; There are some other similar compression functions with
&gt;&gt; assembly implementation, for md5, sha256 and sha512. But there's no need
&gt;&gt; to change them all at the same time, or at all.
&gt;&gt;
&gt;&gt; Regarding the MD_UPDATE macro, that one is defined in the public header
&gt;&gt; file macros.h (which in retrospect was a mistake). So it's probably best
&gt;&gt; to leave it unchanged. New macros for the new convention should be put
&gt;&gt; into some internal header, e.g., md-internal.h.
&gt;&gt;
&gt;
&gt; Yet, there are implementations of x86, x86_64, and arm architectures to
&gt; adapt with the new compress function
&gt;

Modified basic x86_64 implementation to sha1_compress_n function in the
same branch. Unfortunately, my x86_64 CPU doesn't support SHA extension so
I'm trying to figure out a simple way to test the hardware-accelerated
implementation.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210818202943</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-18 20:29:43-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

What is x86/sha1-compress.nlms? How can I implement nettle_copmress_n
function for that particular type?

regards,
Mamone

On Sun, Aug 15, 2021 at 2:10 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Thu, Aug 12, 2021 at 4:26 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; On Tue, Aug 10, 2021 at 11:55 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; I made a merge request in the main repository that optimizes SHA1 for
&gt;&gt;&gt; s390x
&gt;&gt;&gt; &gt; architecture with fat build support !33
&gt;&gt;&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33&gt;.
&gt;&gt;&gt;
&gt;&gt;&gt; Regarding the discussion on
&gt;&gt;&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33#note_10005:
&gt;&gt;&gt; It seems the sha1 instructions on s390x are fast enough that the
&gt;&gt;&gt; overhead of loading constants, and loading and storing the state, all
&gt;&gt;&gt; per block, is a significant cost.
&gt;&gt;&gt;
&gt;&gt;&gt; I think it makes sense to change the internal convention for
&gt;&gt;&gt; _sha1_compress so that it can do multiple blocks. There are currently 5
&gt;&gt;&gt; assembly implementations that would need updating: arm/v6, arm64/crypto,
&gt;&gt;&gt; x86,
&gt;&gt;&gt; x86_64 and x86_64/sha_ni. And the C implementation, of course.
&gt;&gt;&gt;
&gt;&gt;&gt; If it turns out to be too large a change to do them all at once, one
&gt;&gt;&gt; could introduce some new _sha1_compress_n function or the like, and use
&gt;&gt;&gt; when available. Actually, we probably need to do that anyway, since for
&gt;&gt;&gt; historical reasons, _nettle_sha1_compress is a public function, and needs
&gt;&gt;&gt; to be kept (as just a simple C wrapper) for backwards compatibility.
&gt;&gt;&gt; Changing it incrementally should be doable but a bit hairy.
&gt;&gt;&gt;
&gt;&gt;&gt; There are some other similar compression functions with
&gt;&gt;&gt; assembly implementation, for md5, sha256 and sha512. But there's no need
&gt;&gt;&gt; to change them all at the same time, or at all.
&gt;&gt;&gt;
&gt;&gt;&gt; Regarding the MD_UPDATE macro, that one is defined in the public header
&gt;&gt;&gt; file macros.h (which in retrospect was a mistake). So it's probably best
&gt;&gt;&gt; to leave it unchanged. New macros for the new convention should be put
&gt;&gt;&gt; into some internal header, e.g., md-internal.h.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Yet, there are implementations of x86, x86_64, and arm architectures to
&gt;&gt; adapt with the new compress function
&gt;&gt;
&gt;
&gt; Modified basic x86_64 implementation to sha1_compress_n function in the
&gt; same branch. Unfortunately, my x86_64 CPU doesn't support SHA extension so
&gt; I'm trying to figure out a simple way to test the hardware-accelerated
&gt; implementation.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210819054801</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-19 05:48:01-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; What is x86/sha1-compress.nlms? How can I implement nettle_copmress_n
&gt; function for that particular type?

That's an input file for an obscure "loop mixer" tool, IIRC, it was
written mainly by David Harvey for use with GMP loops. This tool tries
permuting the instructions of an assembly loop, taking dependencies into
account, benchmarks each variant, and tries to find the fastest
instruction sequence. It seems I tried this toool on x86 sha1_compress
back in 2009, on an AMD K7, and it gave a 17% speedup at the time,
according to commit message for 1e757582ac7f8465b213d9761e17c33bd21ca686.

So you can just ignore this file. And you may want to look at the more
readable version of x86/sha1_compress.asm, just before that commit.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210821032233</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-21 03:22:33-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

On Thu, Aug 19, 2021 at 8:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; What is x86/sha1-compress.nlms? How can I implement nettle_copmress_n
&gt; &gt; function for that particular type?
&gt;
&gt; That's an input file for an obscure "loop mixer" tool, IIRC, it was
&gt; written mainly by David Harvey for use with GMP loops. This tool tries
&gt; permuting the instructions of an assembly loop, taking dependencies into
&gt; account, benchmarks each variant, and tries to find the fastest
&gt; instruction sequence. It seems I tried this toool on x86 sha1_compress
&gt; back in 2009, on an AMD K7, and it gave a 17% speedup at the time,
&gt; according to commit message for 1e757582ac7f8465b213d9761e17c33bd21ca686.
&gt;
&gt; So you can just ignore this file. And you may want to look at the more
&gt; readable version of x86/sha1_compress.asm, just before that commit.
&gt;

Thanks, I left the nlms files as are and modified x86/sha1_compress.asm to
work with the sha1_compress_n function. I've kept the function parameters
in the stack since the instructions are able to execute on memory operands
and x86 calling convention passes the parameters through the stack, I'm not
sure if those parameters are read-only or can be adjustable, TBH I haven't
run into x86 32-bit code for 8 years. What I did is reserving fields in the
stack for two parameters and adjusting both values in the new locations to
keep the original values unmodified.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210829153920</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-29 15:39:20-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

I added support for the sha1_compress_n function on arm architecture in the
same branch https://git.lysator.liu.se/mamonet/nettle/-/tree/sha1-compress-n

regards,
Mamone

On Sat, Aug 21, 2021 at 5:22 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Thu, Aug 19, 2021 at 8:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; What is x86/sha1-compress.nlms? How can I implement nettle_copmress_n
&gt;&gt; &gt; function for that particular type?
&gt;&gt;
&gt;&gt; That's an input file for an obscure "loop mixer" tool, IIRC, it was
&gt;&gt; written mainly by David Harvey for use with GMP loops. This tool tries
&gt;&gt; permuting the instructions of an assembly loop, taking dependencies into
&gt;&gt; account, benchmarks each variant, and tries to find the fastest
&gt;&gt; instruction sequence. It seems I tried this toool on x86 sha1_compress
&gt;&gt; back in 2009, on an AMD K7, and it gave a 17% speedup at the time,
&gt;&gt; according to commit message for 1e757582ac7f8465b213d9761e17c33bd21ca686.
&gt;&gt;
&gt;&gt; So you can just ignore this file. And you may want to look at the more
&gt;&gt; readable version of x86/sha1_compress.asm, just before that commit.
&gt;&gt;
&gt;
&gt; Thanks, I left the nlms files as are and modified x86/sha1_compress.asm to
&gt; work with the sha1_compress_n function. I've kept the function parameters
&gt; in the stack since the instructions are able to execute on memory operands
&gt; and x86 calling convention passes the parameters through the stack, I'm not
&gt; sure if those parameters are read-only or can be adjustable, TBH I haven't
&gt; run into x86 32-bit code for 8 years. What I did is reserving fields in the
&gt; stack for two parameters and adjusting both values in the new locations to
&gt; keep the original values unmodified.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210816201441</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-16 20:14:41-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

Forcing ELFv2 abi doesn't work for big-endian mode as this mode has no
support for ELFv2. ppc64 linux big-endian is deprecated, it' not unexpected
to get such issues. Dropping big-endian support for powerpc could be an
option to solve this issue but that will be a drawback for AIX (BE) systems.

regards,
Maamoun

On Mon, Aug 16, 2021 at 10:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Stijn Tintel &lt;stijn@linux-ipv6.be&gt; writes:
&gt;
&gt; &gt; I suspect this is because musl doesn't support the ELFv1 ABI on ppc64 at
&gt; &gt; all, regardless of endianness. I've tried adding -mabi=elfv2 to CFLAGS,
&gt; &gt; to force using the ELFv2 ABI, but the problem persists. Suggestions
&gt; welcome.
&gt;
&gt; I don't know that much about ppc64 abi issues myself. From your
&gt; description, it seems clear that it's a linker error, and that object
&gt; files corresponding to C source files somehow carry different "abi
&gt; version attributes" than object files corresponding to nettle's assembly
&gt; source files.
&gt;
&gt; As you've found, configuring with --disable-assembler works around the
&gt; problem, but to solve it properly, we'd need to understand why that is.
&gt; The assembler should not be invoked directly, but via the same $(CC) and
&gt; $(CFLAGS) as the C compiler.
&gt;
&gt; You'd need to compare those object files and how they're generated.
&gt; Compare the compiler command lines. You could perhaps use gcc -v to see
&gt; how gcc invokes the assembler in both cases. You can use gcc -save-temps
&gt; to look at the assembly files generated by gcc, and check if they use
&gt; some special pseudoops to specify the abi. You can use tools like
&gt; objdump or readelf to compare attributes in the object files.
&gt;
&gt; If you can figure out how to produce object files that are compatible
&gt; according to the linker, that may not be sufficient, though. You also
&gt; need to tweak the assembly files and related macros and configure checks
&gt; to use the right api. See powerpc64/README and powerpc64/machine.m4. As
&gt; I understand it, abi is currently selected depending on the endianness,
&gt; using v1 for big endian and v2 for little endian.
&gt;
&gt; It may need a configure test independent of endianness. Maybe there's
&gt; some predefined symbol we can check, similar to 32-bit/64-bit ABI checks
&gt; on other platforms? You could run something like
&gt;
&gt; powerpc64-openwrt-linux-musl-gcc -E -dM - &lt;/dev/null | sort
&gt;
&gt; With the powerpc64le-linux-gnu-gcc cross compiler I have, the closest
&gt; suspect I see is
&gt;
&gt; #define _CALL_ELF 2
&gt;
&gt; Maybe that's the right thing to check? I don't have a big-endian system
&gt; or crosscompiler close at hand, but at least there's a bigendian
&gt; powerpc64-linux-gnu cross compile setup in the ci system hosted at gitlab.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210817064001</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-17 06:40:01-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Forcing ELFv2 abi doesn't work for big-endian mode as this mode has no
&gt; support for ELFv2. ppc64 linux big-endian is deprecated, it' not unexpected
&gt; to get such issues. Dropping big-endian support for powerpc could be an
&gt; option to solve this issue but that will be a drawback for AIX (BE) systems.

The configuration where it didn't work was
powerpc64-openwrt-linux-musl. I'd like Nettle to work on embedded
systems whenever practical. But support depends on assistance from users
of those systems.

As I understood it, this system needs to use the v2 ABI. I would hope
it's easy to detect the abi used by the configured C compiler, and then
select the same prologue sequence as is currently used for
little-endian. I.e., one more configure test, and changing the
"ifelse(WORDS_BIGENDIAN,no," condition in powerpc64/machine.m4 to check
a different configure variable.

I don't know how the linker detected abi incompatibility (ld error message
like "gcm-hash.o: ABI version 1 is not compatible with ABI version 2
output"), if that's based just on the presence of the special ".opd"
section, or if there are other attributes in the ELF file, and if so,
how the assembler decides which attributes to attach.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210823185953</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-23 18:59:53-0400</timestampReceived><subject>Big endian tests (no mips) (was: Re: Build problem on ppc64be + musl)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Unfortunaly, the CI cross builds aren't working at the moment (the
&gt; buildenv images are based on Debian Buster ("stable" at the time images
&gt; were built), and nettle's ci scripts do apt-get update and apt-get
&gt; install, which now attempts to get Bullseye packages (new "stable" since
&gt; a week ago)).

Images now updated to debian stable (thanks, Daiki!). But we'll have to
drop mips tests for now, since current setup assumes archs under tests
are available in debian, and mips has been discontinued as a debian
release architecture. Other cross builds now work (change to drop mips
is on the master-updates branch). If you have ideas on how to revive mips
tests, that's welcome, but for now we'll have to do without.

I would like to keep testing on big-endian. s390x is big-endian, right?
And so is powerpc64 (non -el). So it would be nice to configure cross
tests on one of those platforms configured with --disable-assembler, to
test portability of the C code. Are s390x cross tools and qemu-user in
good enough shape (it's an official debian release arch), or is
powerpc64 a better option?
 
Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210817132903</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-08-17 13:29:03-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Tue, Aug 17, 2021 at 2:40 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Forcing ELFv2 abi doesn't work for big-endian mode as this mode has no
&gt; &gt; support for ELFv2. ppc64 linux big-endian is deprecated, it' not unexpected
&gt; &gt; to get such issues. Dropping big-endian support for powerpc could be an
&gt; &gt; option to solve this issue but that will be a drawback for AIX (BE) systems.
&gt;
&gt; The configuration where it didn't work was
&gt; powerpc64-openwrt-linux-musl. I'd like Nettle to work on embedded
&gt; systems whenever practical. But support depends on assistance from users
&gt; of those systems.

Musl Libc does not support ELFv1, so I don't understand how this
configuration is possible.

&gt;
&gt; As I understood it, this system needs to use the v2 ABI. I would hope
&gt; it's easy to detect the abi used by the configured C compiler, and then
&gt; select the same prologue sequence as is currently used for
&gt; little-endian. I.e., one more configure test, and changing the
&gt; "ifelse(WORDS_BIGENDIAN,no," condition in powerpc64/machine.m4 to check
&gt; a different configure variable.
&gt;
&gt; I don't know how the linker detected abi incompatibility (ld error message
&gt; like "gcm-hash.o: ABI version 1 is not compatible with ABI version 2
&gt; output"), if that's based just on the presence of the special ".opd"
&gt; section, or if there are other attributes in the ELF file, and if so,
&gt; how the assembler decides which attributes to attach.

The linker looks for the special ELF attribute.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210817172718</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-17 17:27:18-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; Musl Libc does not support ELFv1, so I don't understand how this
&gt; configuration is possible.

If I understood the original report, musl always uses ELFv2 abi, for
both little and big endian configurations. Which for big endian is
incompatible with the way powerpc64 assembly is configured in nettle.

Nettle assembly files currently use ELFv2 on little endian, but always
uses ELFv1 on big endian.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210817182308</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-08-17 18:23:08-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

I believe that some OS (FreeBSD? NetBSD?) is trying to use ELFv2 with
PPC64 BE.  That is a separate issue and I do not believe that Musl
Libc plans to support that configuration.

AIX continues to use its ABI, which essentially is closely related to
ELFv1 and uses the XCOFF file format and syntax.

Thanks, David

On Tue, Aug 17, 2021 at 1:27 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; Musl Libc does not support ELFv1, so I don't understand how this
&gt; &gt; configuration is possible.
&gt;
&gt; If I understood the original report, musl always uses ELFv2 abi, for
&gt; both little and big endian configurations. Which for big endian is
&gt; incompatible with the way powerpc64 assembly is configured in nettle.
&gt;
&gt; Nettle assembly files currently use ELFv2 on little endian, but always
&gt; uses ELFv1 on big endian.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210818192924</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-18 19:29:24-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Tue, Aug 17, 2021 at 9:40 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; The configuration where it didn't work was
&gt; powerpc64-openwrt-linux-musl. I'd like Nettle to work on embedded
&gt; systems whenever practical. But support depends on assistance from users
&gt; of those systems.
&gt;
&gt; As I understood it, this system needs to use the v2 ABI. I would hope
&gt; it's easy to detect the abi used by the configured C compiler, and then
&gt; select the same prologue sequence as is currently used for
&gt; little-endian. I.e., one more configure test, and changing the
&gt; "ifelse(WORDS_BIGENDIAN,no," condition in powerpc64/machine.m4 to check
&gt; a different configure variable.
&gt;

I skipped processing the assembly files with a different approach, I made
the configuration check for musl and endianness variant to trigger assembly
processing. You can check the fix in this branch
https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix
Apparently, the bug reporter uses a cross-compiler for powerpc arch. It
would be great to run this fix at the same bug environment since I tested
the patch in different circumstances.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210818214019</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-18 21:40:19-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Wed, Aug 18, 2021 at 11:38 PM Stijn Tintel &lt;stijn@linux-ipv6.be&gt; wrote:

&gt; On 18/08/2021 22:29, Maamoun TK wrote:
&gt; &gt; On Tue, Aug 17, 2021 at 9:40 AM Niels Möller &lt;nisse@lysator.liu.se
&gt; &gt; &lt;mailto:nisse@lysator.liu.se&gt;&gt; wrote:
&gt; &gt;
&gt; &gt;     The configuration where it didn't work was
&gt; &gt;     powerpc64-openwrt-linux-musl. I'd like Nettle to work on embedded
&gt; &gt;     systems whenever practical. But support depends on assistance from
&gt; &gt;     users
&gt; &gt;     of those systems.
&gt; &gt;
&gt; &gt;     As I understood it, this system needs to use the v2 ABI. I would hope
&gt; &gt;     it's easy to detect the abi used by the configured C compiler, and
&gt; &gt;     then
&gt; &gt;     select the same prologue sequence as is currently used for
&gt; &gt;     little-endian. I.e., one more configure test, and changing the
&gt; &gt;     "ifelse(WORDS_BIGENDIAN,no," condition in powerpc64/machine.m4 to
&gt; &gt;     check
&gt; &gt;     a different configure variable.
&gt; &gt;
&gt; &gt;
&gt; &gt; I skipped processing the assembly files with a different approach, I
&gt; &gt; made the configuration check for musl and endianness variant to
&gt; &gt; trigger assembly processing. You can check the fix in this branch
&gt; &gt; https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix
&gt; &gt; &lt;https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix&gt;
&gt; &gt; Apparently, the bug reporter uses a cross-compiler for powerpc arch.
&gt; &gt; It would be great to run this fix at the same bug environment since I
&gt; &gt; tested the patch in different circumstances.
&gt;
&gt; Your patch has no effect in my environment (OpenWrt build system), as
&gt; host_os is linux-gnu, according to config.log, so it doesn't match
&gt; *musl. See [1] for config.log and [2] for full compile log.
&gt;
&gt; The output of powerpc64-openwrt-linux-musl-gcc -E -dM - &lt;/dev/null |
&gt; sort, which was requested earlier in this thread can be seen at [3].
&gt;
&gt; Thanks,
&gt; Stijn
&gt;
&gt; [1] https://gist.github.com/9e0ecb025033dda1d0d58094da84c308
&gt; [2] https://gist.github.com/stintel/0e7046df511cf4d1ca20edb56df50b1b
&gt; [3] https://gist.github.com/stintel/b3651a7db87edea9e8bd0aef242bcdae


config.guess detects the C standard library based on a result from the
compiler defined in "CC_FOR_BUILD" variable, for some reason OpenWrt build
system failed to set that variable properly, from your config.log I can see
CC_FOR_BUILD='gcc -O -g' but when I use bare musl tools I get
CC_FOR_BUILD='musl-gcc'

There is nothing specific in the output of powerpc64-openwrt-linux-musl-gcc
-E -dM log as I can see. In musl libc FAQ, they stated that there is no
__MUSL__ in the preprocessor macros https://wiki.musl-libc.org/faq.html

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210818215904</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-18 21:59:04-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Thu, Aug 19, 2021 at 12:40 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Wed, Aug 18, 2021 at 11:38 PM Stijn Tintel &lt;stijn@linux-ipv6.be&gt; wrote:
&gt;
&gt;&gt; On 18/08/2021 22:29, Maamoun TK wrote:
&gt;&gt; &gt; On Tue, Aug 17, 2021 at 9:40 AM Niels Möller &lt;nisse@lysator.liu.se
&gt;&gt; &gt; &lt;mailto:nisse@lysator.liu.se&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt;     The configuration where it didn't work was
&gt;&gt; &gt;     powerpc64-openwrt-linux-musl. I'd like Nettle to work on embedded
&gt;&gt; &gt;     systems whenever practical. But support depends on assistance from
&gt;&gt; &gt;     users
&gt;&gt; &gt;     of those systems.
&gt;&gt; &gt;
&gt;&gt; &gt;     As I understood it, this system needs to use the v2 ABI. I would
&gt;&gt; hope
&gt;&gt; &gt;     it's easy to detect the abi used by the configured C compiler, and
&gt;&gt; &gt;     then
&gt;&gt; &gt;     select the same prologue sequence as is currently used for
&gt;&gt; &gt;     little-endian. I.e., one more configure test, and changing the
&gt;&gt; &gt;     "ifelse(WORDS_BIGENDIAN,no," condition in powerpc64/machine.m4 to
&gt;&gt; &gt;     check
&gt;&gt; &gt;     a different configure variable.
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; I skipped processing the assembly files with a different approach, I
&gt;&gt; &gt; made the configuration check for musl and endianness variant to
&gt;&gt; &gt; trigger assembly processing. You can check the fix in this branch
&gt;&gt; &gt; https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix
&gt;&gt; &gt; &lt;https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix&gt;
&gt;&gt; &gt; Apparently, the bug reporter uses a cross-compiler for powerpc arch.
&gt;&gt; &gt; It would be great to run this fix at the same bug environment since I
&gt;&gt; &gt; tested the patch in different circumstances.
&gt;&gt;
&gt;&gt; Your patch has no effect in my environment (OpenWrt build system), as
&gt;&gt; host_os is linux-gnu, according to config.log, so it doesn't match
&gt;&gt; *musl. See [1] for config.log and [2] for full compile log.
&gt;&gt;
&gt;&gt; The output of powerpc64-openwrt-linux-musl-gcc -E -dM - &lt;/dev/null |
&gt;&gt; sort, which was requested earlier in this thread can be seen at [3].
&gt;&gt;
&gt;&gt; Thanks,
&gt;&gt; Stijn
&gt;&gt;
&gt;&gt; [1] https://gist.github.com/9e0ecb025033dda1d0d58094da84c308
&gt;&gt; [2] https://gist.github.com/stintel/0e7046df511cf4d1ca20edb56df50b1b
&gt;&gt; [3] https://gist.github.com/stintel/b3651a7db87edea9e8bd0aef242bcdae
&gt;
&gt;
&gt; config.guess detects the C standard library based on a result from the
&gt; compiler defined in "CC_FOR_BUILD" variable, for some reason OpenWrt build
&gt; system failed to set that variable properly, from your config.log I can see
&gt; CC_FOR_BUILD='gcc -O -g' but when I use bare musl tools I get
&gt; CC_FOR_BUILD='musl-gcc'
&gt;

The macro GMP_PROG_CC_FOR_BUILD in aclocal.m4 sets "CC_FOR_BUIL=gcc -O -g"
rather than the actual compiler by checking if the library is configured
with cross-compiling, I wonder if there is a workaround for that.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210819060445</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-19 06:04:45-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; config.guess detects the C standard library based on a result from the
&gt; compiler defined in "CC_FOR_BUILD" variable, for some reason OpenWrt build
&gt; system failed to set that variable properly, from your config.log I can see
&gt; CC_FOR_BUILD='gcc -O -g' but when I use bare musl tools I get
&gt; CC_FOR_BUILD='musl-gcc'

In Nettle's Makefiles, CC_FOR_BUILD is intended to be a compiler
targetting the *build* system, used to compile things like eccdata.c
that are run on the build system as part of the build. It's intended to
be different from CC when cross compiling.

Not entirely sure how CC_FOR_BUILD is used in config.guess, but I think
it is used to detect the system type of the build system.

&gt; There is nothing specific in the output of powerpc64-openwrt-linux-musl-gcc
&gt; -E -dM log as I can see. In musl libc FAQ, they stated that there is no
&gt; __MUSL__ in the preprocessor macros https://wiki.musl-libc.org/faq.html

The interesting thing I see is 

#define _CALL_ELF 2

I hope this can be used to distinguish from other big-endian systems,
that use ELFv1 abi?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210819202234</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-08-19 20:22:34-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; AIX continues to use its ABI, which essentially is closely related to
&gt; ELFv1 and uses the XCOFF file format and syntax.

When you say "closely related" is it close enough that the same assembly
can be used as for ELFv1? I don't remember if Maamoun or someone else
tested Nettle's powerpc64 assembly on AIX?

Is there some established common name for this calling convention, for
both ELFv1 and XCOFF? Otherwise, I'd refer to it as ELFv1, even though
it works on non-ELF AIX too.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210819203425</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-08-19 20:34:25-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Thu, Aug 19, 2021 at 4:22 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; AIX continues to use its ABI, which essentially is closely related to
&gt; &gt; ELFv1 and uses the XCOFF file format and syntax.
&gt;
&gt; When you say "closely related" is it close enough that the same assembly
&gt; can be used as for ELFv1? I don't remember if Maamoun or someone else
&gt; tested Nettle's powerpc64 assembly on AIX?
&gt;
&gt; Is there some established common name for this calling convention, for
&gt; both ELFv1 and XCOFF? Otherwise, I'd refer to it as ELFv1, even though
&gt; it works on non-ELF AIX too.

The AIX ABI and the ELFv1 ABI are not identical.  AIX uses XCOFF file
format and syntax.  PPC64 BE Linux uses ELF file format and syntax.

The ELFv1 ABI was derived from the AIX ABI and both use function
descriptors (ELFv1 calls OPD or Official Procedure Descriptors).
Function pointers are pointers to the descriptors, not to code.  ELFv1
uses ELF section names and decorations.

AIX uses the TOC for global data managed by the compiler.  ELFv1 can
use a TOC or a more standard GOT managed by the linker.

The assembly language for the instructions is the same (AIX prefers
registers as only numbers, while ELF allows letters to distinguish the
different register sets (GPRs, FPRs, VSRs).

One can translate between AIX and ELFv1 fairly easily, and possibly
use a single assembly file with some m4 macros to hide the
differences, but one cannot use identical assembly language files for
both.

Thanks David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210703180139</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-03 18:01:39-0400</timestampReceived><subject>[AArch64] Fat build support for SHA-256 compress</subject><body>

I made a merge request that adds fat build support for SHA-256 compress
function !29 &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/29&gt;

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210627155032</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-06-27 15:50:32-0400</timestampReceived><subject>[S390x] Optimize GHASH</subject><body>

I made a merge request !26
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
optimizes the GHASH algorithm for S390x architecture. I've attached a
benchmark in the description of merge request that describes the
improvement of using GHASH accelerator over C implementation. I've also
made two patches for fat build support of AES and GHASH for S390x
architecture in addition to optimize memxor function using 'xc (xor
storage-to-storage) instruction'
Files  · s390x-fat  · Maamoun TK / nettle  · GitLab (liu.se)
&lt;https://git.lysator.liu.se/mamonet/nettle/-/tree/s390x-fat&gt;
Files  · s390x-memxor  · Maamoun TK / nettle  · GitLab (liu.se)
&lt;https://git.lysator.liu.se/mamonet/nettle/-/tree/s390x-memxor&gt;
I'll make merge requests for both patches after the current one being
merged since they need to rebase on top of that patch.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210714182520</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-14 18:25:20-0400</timestampReceived><subject>Re: [Aarch64] Optimize AES</subject><body>

I made this patch operate AES ciphering with fixed key sizes of 128-bit,
192-bit, and 256-bit, in this case I eliminated the loading process of key
expansion for every round. Since this technique produces performance
benefits, I'm planning to keep the implementation as is and in case
handling uncommon key size is mandatory, I can append additional branch to
process message blocks with any key size. What do you think?

regards,
Mamone

On Sat, May 1, 2021 at 5:39 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; This patch optimizes nettle_aes_encrypt() and nettle_aes_decrypt()
&gt; functions for arm64 architecture, it takes advantage of 'aese' and 'aesmc'
&gt; instructions to optimize the encryption function and 'aesd' and 'aesimc' to
&gt; optimize the decryption function.
&gt;
&gt; The patch passes the testsuite of nettle. I also run the benchmark on
&gt; gcc117 instance of CFarm by configuring the library with "--disable-fat
&gt; --enable-arm64-crypto" options then executing examples/nettle-benchmark:
&gt;
&gt; aes128  ECB encrypt 2522.67
&gt; aes128  ECB decrypt 2522.53
&gt; aes192  ECB encrypt 2165.06
&gt; aes192  ECB decrypt 2165.04
&gt; aes256  ECB encrypt 1866.80
&gt; aes256  ECB decrypt 1866.38
&gt;
&gt; openssl aes128  ECB encrypt 1043.52
&gt; openssl aes128  ECB decrypt 1043.05
&gt; openssl aes192  ECB encrypt  904.08
&gt; openssl aes192  ECB decrypt  903.85
&gt; openssl aes256  ECB encrypt  787.43
&gt; openssl aes256  ECB decrypt  787.20
&gt;
&gt; gcm_aes128      encrypt  955.10
&gt; gcm_aes128      decrypt  955.06
&gt; gcm_aes128       update 3269.18
&gt; gcm_aes192      encrypt  896.26
&gt; gcm_aes192      decrypt  896.46
&gt; gcm_aes192       update 3270.24
&gt; gcm_aes256      encrypt  840.17
&gt; gcm_aes256      decrypt  843.53
&gt; gcm_aes256       update 3270.08
&gt;
&gt; openssl gcm_aes128      encrypt  894.51
&gt; openssl gcm_aes128      decrypt  899.05
&gt; openssl gcm_aes128       update 1636.61
&gt; openssl gcm_aes192      encrypt  834.94
&gt; openssl gcm_aes192      decrypt  841.99
&gt; openssl gcm_aes192       update 1631.40
&gt; openssl gcm_aes256      encrypt  788.48
&gt; openssl gcm_aes256      decrypt  791.31
&gt; openssl gcm_aes256       update 1635.18
&gt;
&gt; I'm a little suspicious about the benchmark numbers because as I remember
&gt; the performance of gcm update doesn't double the openssl number, I repeat
&gt; running the process but kept giving the same performance margin.
&gt;
&gt; ---
&gt;  arm64/crypto/aes-decrypt-internal.asm | 223
&gt; ++++++++++++++++++++++++++++++++++
&gt;  arm64/crypto/aes-encrypt-internal.asm | 223
&gt; ++++++++++++++++++++++++++++++++++
&gt;  2 files changed, 446 insertions(+)
&gt;  create mode 100644 arm64/crypto/aes-decrypt-internal.asm
&gt;  create mode 100644 arm64/crypto/aes-encrypt-internal.asm
&gt;
&gt; diff --git a/arm64/crypto/aes-decrypt-internal.asm
&gt; b/arm64/crypto/aes-decrypt-internal.asm
&gt; new file mode 100644
&gt; index 00000000..4bfdb314
&gt; --- /dev/null
&gt; +++ b/arm64/crypto/aes-decrypt-internal.asm
&gt; @@ -0,0 +1,223 @@
&gt; +C arm64/crypto/aes-decrypt-internal.asm
&gt; +
&gt; +ifelse(`
&gt; +   Copyright (C) 2021 Mamone Tarsha
&gt; +   This file is part of GNU Nettle.
&gt; +
&gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; +   modify it under the terms of either:
&gt; +
&gt; +     * the GNU Lesser General Public License as published by the Free
&gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or
&gt; +
&gt; +     * the GNU General Public License as published by the Free
&gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or both in parallel, as here.
&gt; +
&gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; +   General Public License for more details.
&gt; +
&gt; +   You should have received copies of the GNU General Public License and
&gt; +   the GNU Lesser General Public License along with this program.  If
&gt; +   not, see http://www.gnu.org/licenses/.
&gt; +')
&gt; +
&gt; +.file "aes-decrypt-internal.asm"
&gt; +.arch armv8-a+crypto
&gt; +
&gt; +.text
&gt; +
&gt; +C Register usage:
&gt; +
&gt; +define(`ROUNDS', `x0')
&gt; +define(`KEYS', `x1')
&gt; +define(`LENGTH', `x3')
&gt; +define(`DST', `x4')
&gt; +define(`SRC', `x5')
&gt; +
&gt; +define(`S0', `v0')
&gt; +define(`S1', `v1')
&gt; +define(`S2', `v2')
&gt; +define(`S3', `v3')
&gt; +define(`K0', `v16')
&gt; +define(`K1', `v17')
&gt; +define(`K2', `v18')
&gt; +define(`K3', `v19')
&gt; +define(`K4', `v20')
&gt; +define(`K5', `v21')
&gt; +define(`K6', `v22')
&gt; +define(`K7', `v23')
&gt; +define(`K8', `v24')
&gt; +define(`K9', `v25')
&gt; +define(`K10', `v26')
&gt; +define(`K11', `v27')
&gt; +define(`K12', `v28')
&gt; +define(`K13', `v29')
&gt; +define(`K14', `v30')
&gt; +
&gt; +C AES_ROUND_4B(KEY)
&gt; +define(`AES_ROUND_4B', m4_assert_numargs(1)`
&gt; +    aesd           S0.16b,$1.16b
&gt; +    aesimc         S0.16b,S0.16b
&gt; +    aesd           S1.16b,$1.16b
&gt; +    aesimc         S1.16b,S1.16b
&gt; +    aesd           S2.16b,$1.16b
&gt; +    aesimc         S2.16b,S2.16b
&gt; +    aesd           S3.16b,$1.16b
&gt; +    aesimc         S3.16b,S3.16b
&gt; +')
&gt; +
&gt; +C AES_LAST_ROUND_4B(KEY)
&gt; +define(`AES_LAST_ROUND_4B', m4_assert_numargs(1)`
&gt; +    aesd           S0.16b,$1.16b
&gt; +    eor            S0.16b,S0.16b,K14.16b
&gt; +    aesd           S1.16b,$1.16b
&gt; +    eor            S1.16b,S1.16b,K14.16b
&gt; +    aesd           S2.16b,$1.16b
&gt; +    eor            S2.16b,S2.16b,K14.16b
&gt; +    aesd           S3.16b,$1.16b
&gt; +    eor            S3.16b,S3.16b,K14.16b
&gt; +')
&gt; +
&gt; +C AES_ROUND_1B(KEY)
&gt; +define(`AES_ROUND_1B', m4_assert_numargs(1)`
&gt; +    aesd           S0.16b,$1.16b
&gt; +    aesimc         S0.16b,S0.16b
&gt; +')
&gt; +
&gt; +C AES_LAST_ROUND_1B(KEY)
&gt; +define(`AES_LAST_ROUND_1B', m4_assert_numargs(1)`
&gt; +    aesd           S0.16b,$1.16b
&gt; +    eor            S0.16b,S0.16b,K14.16b
&gt; +')
&gt; +
&gt; +C _aes_decrypt(unsigned rounds, const uint32_t *keys,
&gt; +C       const struct aes_table *T,
&gt; +C       size_t length, uint8_t *dst,
&gt; +C       const uint8_t *src)
&gt; +
&gt; +PROLOGUE(_nettle_aes_decrypt)
&gt; +    ands           x6,LENGTH,#-64
&gt; +    b.eq           L1B
&gt; +
&gt; +    mov            x7,KEYS
&gt; +    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x7],#64
&gt; +    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x7],#64
&gt; +    ld1            {K8.4s,K9.4s},[x7],#32
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L4B_last_key
&gt; +    ld1            {K10.4s,K11.4s},[x7],#32
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L4B_last_key
&gt; +    ld1            {K12.4s,K13.4s},[x7],#32
&gt; +
&gt; +L4B_last_key:
&gt; +    ld1            {K14.4s},[x7]
&gt; +
&gt; +L4B_loop:
&gt; +    ld1            {S0.16b,S1.16b,S2.16b,S3.16b},[SRC],#64
&gt; +
&gt; +    AES_ROUND_4B(K0)
&gt; +    AES_ROUND_4B(K1)
&gt; +    AES_ROUND_4B(K2)
&gt; +    AES_ROUND_4B(K3)
&gt; +    AES_ROUND_4B(K4)
&gt; +    AES_ROUND_4B(K5)
&gt; +    AES_ROUND_4B(K6)
&gt; +    AES_ROUND_4B(K7)
&gt; +    AES_ROUND_4B(K8)
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L4B_10_round
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L4B_12_round
&gt; +    b              L4B_14_round
&gt; +
&gt; +L4B_10_round:
&gt; +    AES_LAST_ROUND_4B(K9)
&gt; +    b              L4B_done
&gt; +L4B_12_round:
&gt; +    AES_ROUND_4B(K9)
&gt; +    AES_ROUND_4B(K10)
&gt; +    AES_LAST_ROUND_4B(K11)
&gt; +    b              L4B_done
&gt; +L4B_14_round:
&gt; +    AES_ROUND_4B(K9)
&gt; +    AES_ROUND_4B(K10)
&gt; +    AES_ROUND_4B(K11)
&gt; +    AES_ROUND_4B(K12)
&gt; +    AES_LAST_ROUND_4B(K13)
&gt; +
&gt; +L4B_done:
&gt; +    st1            {S0.16b,S1.16b,S2.16b,S3.16b},[DST],#64
&gt; +
&gt; +    subs           x6,x6,#64
&gt; +    b.ne           L4B_loop
&gt; +
&gt; +    and            LENGTH,LENGTH,#63
&gt; +
&gt; +L1B:
&gt; +    cbz            LENGTH,Ldone
&gt; +
&gt; +    mov            x6,KEYS
&gt; +    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x6],#64
&gt; +    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x6],#64
&gt; +    ld1            {K8.4s,K9.4s},[x6],#32
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L1B_last_key
&gt; +    ld1            {K10.4s,K11.4s},[x6],#32
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L1B_last_key
&gt; +    ld1            {K12.4s,K13.4s},[x6],#32
&gt; +
&gt; +L1B_last_key:
&gt; +    ld1            {K14.4s},[x6]
&gt; +
&gt; +L1B_loop:
&gt; +    ld1            {S0.16b},[SRC],#16
&gt; +
&gt; +    AES_ROUND_1B(K0)
&gt; +    AES_ROUND_1B(K1)
&gt; +    AES_ROUND_1B(K2)
&gt; +    AES_ROUND_1B(K3)
&gt; +    AES_ROUND_1B(K4)
&gt; +    AES_ROUND_1B(K5)
&gt; +    AES_ROUND_1B(K6)
&gt; +    AES_ROUND_1B(K7)
&gt; +    AES_ROUND_1B(K8)
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L1B_10_round
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L1B_12_round
&gt; +    b              L1B_14_round
&gt; +
&gt; +L1B_10_round:
&gt; +    AES_LAST_ROUND_1B(K9)
&gt; +    b              L1B_done
&gt; +L1B_12_round:
&gt; +    AES_ROUND_1B(K9)
&gt; +    AES_ROUND_1B(K10)
&gt; +    AES_LAST_ROUND_1B(K11)
&gt; +    b              L1B_done
&gt; +L1B_14_round:
&gt; +    AES_ROUND_1B(K9)
&gt; +    AES_ROUND_1B(K10)
&gt; +    AES_ROUND_1B(K11)
&gt; +    AES_ROUND_1B(K12)
&gt; +    AES_LAST_ROUND_1B(K13)
&gt; +
&gt; +L1B_done:
&gt; +    st1            {S0.16b},[DST],#16
&gt; +
&gt; +    subs           LENGTH,LENGTH,#16
&gt; +    b.ne           L1B_loop
&gt; +
&gt; +Ldone:
&gt; +    ret
&gt; +EPILOGUE(_nettle_aes_decrypt)
&gt; diff --git a/arm64/crypto/aes-encrypt-internal.asm
&gt; b/arm64/crypto/aes-encrypt-internal.asm
&gt; new file mode 100644
&gt; index 00000000..314f9333
&gt; --- /dev/null
&gt; +++ b/arm64/crypto/aes-encrypt-internal.asm
&gt; @@ -0,0 +1,223 @@
&gt; +C arm64/crypto/aes-encrypt-internal.asm
&gt; +
&gt; +ifelse(`
&gt; +   Copyright (C) 2021 Mamone Tarsha
&gt; +   This file is part of GNU Nettle.
&gt; +
&gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; +   modify it under the terms of either:
&gt; +
&gt; +     * the GNU Lesser General Public License as published by the Free
&gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or
&gt; +
&gt; +     * the GNU General Public License as published by the Free
&gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or both in parallel, as here.
&gt; +
&gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; +   General Public License for more details.
&gt; +
&gt; +   You should have received copies of the GNU General Public License and
&gt; +   the GNU Lesser General Public License along with this program.  If
&gt; +   not, see http://www.gnu.org/licenses/.
&gt; +')
&gt; +
&gt; +.file "aes-encrypt-internal.asm"
&gt; +.arch armv8-a+crypto
&gt; +
&gt; +.text
&gt; +
&gt; +C Register usage:
&gt; +
&gt; +define(`ROUNDS', `x0')
&gt; +define(`KEYS', `x1')
&gt; +define(`LENGTH', `x3')
&gt; +define(`DST', `x4')
&gt; +define(`SRC', `x5')
&gt; +
&gt; +define(`S0', `v0')
&gt; +define(`S1', `v1')
&gt; +define(`S2', `v2')
&gt; +define(`S3', `v3')
&gt; +define(`K0', `v16')
&gt; +define(`K1', `v17')
&gt; +define(`K2', `v18')
&gt; +define(`K3', `v19')
&gt; +define(`K4', `v20')
&gt; +define(`K5', `v21')
&gt; +define(`K6', `v22')
&gt; +define(`K7', `v23')
&gt; +define(`K8', `v24')
&gt; +define(`K9', `v25')
&gt; +define(`K10', `v26')
&gt; +define(`K11', `v27')
&gt; +define(`K12', `v28')
&gt; +define(`K13', `v29')
&gt; +define(`K14', `v30')
&gt; +
&gt; +C AES_ROUND_4B(KEY)
&gt; +define(`AES_ROUND_4B', m4_assert_numargs(1)`
&gt; +    aese           S0.16b,$1.16b
&gt; +    aesmc          S0.16b,S0.16b
&gt; +    aese           S1.16b,$1.16b
&gt; +    aesmc          S1.16b,S1.16b
&gt; +    aese           S2.16b,$1.16b
&gt; +    aesmc          S2.16b,S2.16b
&gt; +    aese           S3.16b,$1.16b
&gt; +    aesmc          S3.16b,S3.16b
&gt; +')
&gt; +
&gt; +C AES_LAST_ROUND_4B(KEY)
&gt; +define(`AES_LAST_ROUND_4B', m4_assert_numargs(1)`
&gt; +    aese           S0.16b,$1.16b
&gt; +    eor            S0.16b,S0.16b,K14.16b
&gt; +    aese           S1.16b,$1.16b
&gt; +    eor            S1.16b,S1.16b,K14.16b
&gt; +    aese           S2.16b,$1.16b
&gt; +    eor            S2.16b,S2.16b,K14.16b
&gt; +    aese           S3.16b,$1.16b
&gt; +    eor            S3.16b,S3.16b,K14.16b
&gt; +')
&gt; +
&gt; +C AES_ROUND_1B(KEY)
&gt; +define(`AES_ROUND_1B', m4_assert_numargs(1)`
&gt; +    aese           S0.16b,$1.16b
&gt; +    aesmc          S0.16b,S0.16b
&gt; +')
&gt; +
&gt; +C AES_LAST_ROUND_1B(KEY)
&gt; +define(`AES_LAST_ROUND_1B', m4_assert_numargs(1)`
&gt; +    aese           S0.16b,$1.16b
&gt; +    eor            S0.16b,S0.16b,K14.16b
&gt; +')
&gt; +
&gt; +C _aes_encrypt(unsigned rounds, const uint32_t *keys,
&gt; +C       const struct aes_table *T,
&gt; +C       size_t length, uint8_t *dst,
&gt; +C       uint8_t *src)
&gt; +
&gt; +PROLOGUE(_nettle_aes_encrypt)
&gt; +    ands           x6,LENGTH,#-64
&gt; +    b.eq           L1B
&gt; +
&gt; +    mov            x7,KEYS
&gt; +    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x7],#64
&gt; +    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x7],#64
&gt; +    ld1            {K8.4s,K9.4s},[x7],#32
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L4B_last_key
&gt; +    ld1            {K10.4s,K11.4s},[x7],#32
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L4B_last_key
&gt; +    ld1            {K12.4s,K13.4s},[x7],#32
&gt; +
&gt; +L4B_last_key:
&gt; +    ld1            {K14.4s},[x7]
&gt; +
&gt; +L4B_loop:
&gt; +    ld1            {S0.16b,S1.16b,S2.16b,S3.16b},[SRC],#64
&gt; +
&gt; +    AES_ROUND_4B(K0)
&gt; +    AES_ROUND_4B(K1)
&gt; +    AES_ROUND_4B(K2)
&gt; +    AES_ROUND_4B(K3)
&gt; +    AES_ROUND_4B(K4)
&gt; +    AES_ROUND_4B(K5)
&gt; +    AES_ROUND_4B(K6)
&gt; +    AES_ROUND_4B(K7)
&gt; +    AES_ROUND_4B(K8)
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L4B_10_round
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L4B_12_round
&gt; +    b              L4B_14_round
&gt; +
&gt; +L4B_10_round:
&gt; +    AES_LAST_ROUND_4B(K9)
&gt; +    b              L4B_done
&gt; +L4B_12_round:
&gt; +    AES_ROUND_4B(K9)
&gt; +    AES_ROUND_4B(K10)
&gt; +    AES_LAST_ROUND_4B(K11)
&gt; +    b              L4B_done
&gt; +L4B_14_round:
&gt; +    AES_ROUND_4B(K9)
&gt; +    AES_ROUND_4B(K10)
&gt; +    AES_ROUND_4B(K11)
&gt; +    AES_ROUND_4B(K12)
&gt; +    AES_LAST_ROUND_4B(K13)
&gt; +
&gt; +L4B_done:
&gt; +    st1            {S0.16b,S1.16b,S2.16b,S3.16b},[DST],#64
&gt; +
&gt; +    subs           x6,x6,#64
&gt; +    b.ne           L4B_loop
&gt; +
&gt; +    and            LENGTH,LENGTH,#63
&gt; +
&gt; +L1B:
&gt; +    cbz            LENGTH,Ldone
&gt; +
&gt; +    mov            x6,KEYS
&gt; +    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x6],#64
&gt; +    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x6],#64
&gt; +    ld1            {K8.4s,K9.4s},[x6],#32
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L1B_last_key
&gt; +    ld1            {K10.4s,K11.4s},[x6],#32
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L1B_last_key
&gt; +    ld1            {K12.4s,K13.4s},[x6],#32
&gt; +
&gt; +L1B_last_key:
&gt; +    ld1            {K14.4s},[x6]
&gt; +
&gt; +L1B_loop:
&gt; +    ld1            {S0.16b},[SRC],#16
&gt; +
&gt; +    AES_ROUND_1B(K0)
&gt; +    AES_ROUND_1B(K1)
&gt; +    AES_ROUND_1B(K2)
&gt; +    AES_ROUND_1B(K3)
&gt; +    AES_ROUND_1B(K4)
&gt; +    AES_ROUND_1B(K5)
&gt; +    AES_ROUND_1B(K6)
&gt; +    AES_ROUND_1B(K7)
&gt; +    AES_ROUND_1B(K8)
&gt; +    cmp            ROUNDS,#10
&gt; +    b.eq           L1B_10_round
&gt; +    cmp            ROUNDS,#12
&gt; +    b.eq           L1B_12_round
&gt; +    b              L1B_14_round
&gt; +
&gt; +L1B_10_round:
&gt; +    AES_LAST_ROUND_1B(K9)
&gt; +    b              L1B_done
&gt; +L1B_12_round:
&gt; +    AES_ROUND_1B(K9)
&gt; +    AES_ROUND_1B(K10)
&gt; +    AES_LAST_ROUND_1B(K11)
&gt; +    b              L1B_done
&gt; +L1B_14_round:
&gt; +    AES_ROUND_1B(K9)
&gt; +    AES_ROUND_1B(K10)
&gt; +    AES_ROUND_1B(K11)
&gt; +    AES_ROUND_1B(K12)
&gt; +    AES_LAST_ROUND_1B(K13)
&gt; +
&gt; +L1B_done:
&gt; +    st1            {S0.16b},[DST],#16
&gt; +
&gt; +    subs           LENGTH,LENGTH,#16
&gt; +    b.ne           L1B_loop
&gt; +
&gt; +Ldone:
&gt; +    ret
&gt; +EPILOGUE(_nettle_aes_encrypt)
&gt;
&gt; --
&gt; 2.25.1
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710182740</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-10 18:27:40-0400</timestampReceived><subject>[S390x] Optimize memxor</subject><body>

I made a merge request !30
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/30&gt; that
optimizes memxor function for S390x architecture. I've attached a benchmark
on a Z15 processor in the MR description.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210717093347</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-17 09:33:47-0400</timestampReceived><subject>Re: [Aarch64] Optimize AES</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made this patch operate AES ciphering with fixed key sizes of 128-bit,
&gt; 192-bit, and 256-bit, in this case I eliminated the loading process of key
&gt; expansion for every round. Since this technique produces performance
&gt; benefits, I'm planning to keep the implementation as is and in case
&gt; handling uncommon key size is mandatory, I can append additional branch to
&gt; process message blocks with any key size. What do you think?

There's no need to support non-standard key sizes. _nettle_aes_encrypt
should only ever be called with one of the constants _AES128_ROUNDS,
_AES192_ROUNDS, _AES256_ROUNDS as the first argument.

I think it's becoming clearer that we should make assembly for
_nettle_aes_encypt optional, in favor of separate entry points for
aes{128,192,256}_{en,de}crypt. I think you or I had an experimental
branch to do that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210701134359</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-01 13:43:59-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

I've replied to your comments in the MR.

Thank you,
Mamone

On Wed, Jun 30, 2021 at 10:10 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I made a merge request !26
&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
&gt; &gt; optimizes the GHASH algorithm for S390x architecture.
&gt;
&gt; Nice! I've added a few comments in the mr.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210702205922</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-02 20:59:22-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

I've added a new comment that wipes hash subkey from stack once GHASH
operation completed as it's a good practice to do so, I also added a
disassembly snippet in the comment section that proves the need of
reserving 160 bytes before committing a dynamic stack allocation.

regards,
Mamone

On Thu, Jul 1, 2021 at 4:43 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; I've replied to your comments in the MR.
&gt;
&gt; Thank you,
&gt; Mamone
&gt;
&gt; On Wed, Jun 30, 2021 at 10:10 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt;
&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; I made a merge request !26
&gt;&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
&gt;&gt; &gt; optimizes the GHASH algorithm for S390x architecture.
&gt;&gt;
&gt;&gt; Nice! I've added a few comments in the mr.
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt; /Niels
&gt;&gt;
&gt;&gt; --
&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210702234823</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-02 23:48:23-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Fri, Jul 2, 2021 at 11:59 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I've added a new comment that wipes hash subkey from stack once GHASH
&gt; operation completed as it's a good practice to do so
&gt;

*commit

I'm thinking it's also worth it to wipe the authentication tag and the
leftover bytes of input data from the stack. Leaving out the output
authentication tag in the stack is never a good idea and in case of
processing AAD the input data is left in the clear so leaving leftover
bytes in the stack may reveal potential secret data. I've pushed another
commit to wipe the whole parameter block content (authentication tag and
hash subkey) and the leftover bytes of input data.

regards,
Mamone


&gt; On Thu, Jul 1, 2021 at 4:43 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; I've replied to your comments in the MR.
&gt;&gt;
&gt;&gt; Thank you,
&gt;&gt; Mamone
&gt;&gt;
&gt;&gt; On Wed, Jun 30, 2021 at 10:10 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; I made a merge request !26
&gt;&gt;&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
&gt;&gt;&gt; &gt; optimizes the GHASH algorithm for S390x architecture.
&gt;&gt;&gt;
&gt;&gt;&gt; Nice! I've added a few comments in the mr.
&gt;&gt;&gt;
&gt;&gt;&gt; Regards,
&gt;&gt;&gt; /Niels
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;&gt;
&gt;&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210708170114</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-08 17:01:14-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

Hi Niels,

Any update on this patch? I think we have reached the merging stage of this
patch if there are no further queries.

regards,
Mamone

On Sat, Jul 3, 2021 at 2:48 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; On Fri, Jul 2, 2021 at 11:59 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; I've added a new comment that wipes hash subkey from stack once GHASH
&gt;&gt; operation completed as it's a good practice to do so
&gt;&gt;
&gt;
&gt; *commit
&gt;
&gt; I'm thinking it's also worth it to wipe the authentication tag and the
&gt; leftover bytes of input data from the stack. Leaving out the output
&gt; authentication tag in the stack is never a good idea and in case of
&gt; processing AAD the input data is left in the clear so leaving leftover
&gt; bytes in the stack may reveal potential secret data. I've pushed another
&gt; commit to wipe the whole parameter block content (authentication tag and
&gt; hash subkey) and the leftover bytes of input data.
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt;
&gt;&gt; On Thu, Jul 1, 2021 at 4:43 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; I've replied to your comments in the MR.
&gt;&gt;&gt;
&gt;&gt;&gt; Thank you,
&gt;&gt;&gt; Mamone
&gt;&gt;&gt;
&gt;&gt;&gt; On Wed, Jun 30, 2021 at 10:10 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; &gt; I made a merge request !26
&gt;&gt;&gt;&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
&gt;&gt;&gt;&gt; &gt; optimizes the GHASH algorithm for S390x architecture.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Nice! I've added a few comments in the mr.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Regards,
&gt;&gt;&gt;&gt; /Niels
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; --
&gt;&gt;&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt;&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210708204346</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-08 20:43:46-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Any update on this patch? I think we have reached the merging stage of this
&gt; patch if there are no further queries.

Merged, thanks!

&gt;&gt; I'm thinking it's also worth it to wipe the authentication tag and the
&gt;&gt; leftover bytes of input data from the stack. Leaving out the output
&gt;&gt; authentication tag in the stack is never a good idea and in case of
&gt;&gt; processing AAD the input data is left in the clear so leaving leftover
&gt;&gt; bytes in the stack may reveal potential secret data. I've pushed another
&gt;&gt; commit to wipe the whole parameter block content (authentication tag and
&gt;&gt; hash subkey) and the leftover bytes of input data.

Other nettle functions don't do that, it's generally assumed that the
running program is trustworthy, and that the operating system protects
the data from non-trustworthy processes. I think using encrypted swap
(using an ephemeral key destroyed on shutdown) is a good idea.

To me, it makes some sense for nettle to wipe the copy of the key (since
the application might wipe the context struct and expect no copies to
remain), but probably overkill for the other data. But it shouldn't hurt
either.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210708205653</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-08 20:56:53-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Thu, Jul 8, 2021 at 11:43 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;&gt; I'm thinking it's also worth it to wipe the authentication tag and the
&gt; &gt;&gt; leftover bytes of input data from the stack. Leaving out the output
&gt; &gt;&gt; authentication tag in the stack is never a good idea and in case of
&gt; &gt;&gt; processing AAD the input data is left in the clear so leaving leftover
&gt; &gt;&gt; bytes in the stack may reveal potential secret data. I've pushed another
&gt; &gt;&gt; commit to wipe the whole parameter block content (authentication tag and
&gt; &gt;&gt; hash subkey) and the leftover bytes of input data.
&gt;
&gt; Other nettle functions don't do that, it's generally assumed that the
&gt; running program is trustworthy, and that the operating system protects
&gt; the data from non-trustworthy processes. I think using encrypted swap
&gt; (using an ephemeral key destroyed on shutdown) is a good idea.
&gt;
&gt; To me, it makes some sense for nettle to wipe the copy of the key (since
&gt; the application might wipe the context struct and expect no copies to
&gt; remain), but probably overkill for the other data. But it shouldn't hurt
&gt; either.
&gt;

S390x's GHASH implementation needs to copy the key and input tail data to
the stack, I just instructed the function to wipe that data from the stack
once the cipher operation is completed, I don't do any kind of data wiping
from the input buffer or cipher context. My concern is if the program
terminates then the operation system will deallocate the program's stack
without clearing its content so that leftover data will remain somewhere at
the RAM which could be a subject for a memory allocation or dumbing by
other programs.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210709070835</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-09 07:08:35-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; My concern is if the program
&gt; terminates then the operation system will deallocate the program's stack
&gt; without clearing its content so that leftover data will remain somewhere at
&gt; the RAM which could be a subject for a memory allocation or dumbing by
&gt; other programs.

I think the kernel is responsible for clearing that memory before
handing it out to a new process. If it didn't, that would be a huge
security problem. I'm fairly sure operating systems do this correctly.
(And I would be a bit curious to know of any exceptions, maybe some
embedded or ancient systems don't do it?)

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710184448</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-10 18:44:48-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Fri, Jul 9, 2021 at 10:08 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; My concern is if the program
&gt; &gt; terminates then the operation system will deallocate the program's stack
&gt; &gt; without clearing its content so that leftover data will remain somewhere
&gt; at
&gt; &gt; the RAM which could be a subject for a memory allocation or dumbing by
&gt; &gt; other programs.
&gt;
&gt; I think the kernel is responsible for clearing that memory before
&gt; handing it out to a new process. If it didn't, that would be a huge
&gt; security problem. I'm fairly sure operating systems do this correctly.
&gt; (And I would be a bit curious to know of any exceptions, maybe some
&gt; embedded or ancient systems don't do it?)
&gt;

You are right, modern operating systems are supposed to have this
functionality but accessing some program's memory is pretty easy nowadays,
I think it's a good practice to clean behind the cipher functions for what
it makes sense and whenever possible.

In another topic, I've optimized the SHA-512 algorithm for arm64
architecture but it turned out all CFarm variants don't support SHA-512
crypto extension so I can't do any performance or correctness testing for
now. Do you know any CFarm alternative that supports SHA-512 and SHA3
extensions for arm64 architectures?

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710185522</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-07-10 18:55:22-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Sat, Jul 10, 2021 at 2:45 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; On Fri, Jul 9, 2021 at 10:08 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; My concern is if the program
&gt; &gt; &gt; terminates then the operation system will deallocate the program's stack
&gt; &gt; &gt; without clearing its content so that leftover data will remain somewhere
&gt; &gt; at
&gt; &gt; &gt; the RAM which could be a subject for a memory allocation or dumbing by
&gt; &gt; &gt; other programs.
&gt; &gt;
&gt; &gt; I think the kernel is responsible for clearing that memory before
&gt; &gt; handing it out to a new process. If it didn't, that would be a huge
&gt; &gt; security problem. I'm fairly sure operating systems do this correctly.
&gt; &gt; (And I would be a bit curious to know of any exceptions, maybe some
&gt; &gt; embedded or ancient systems don't do it?)
&gt; &gt;
&gt;
&gt; You are right, modern operating systems are supposed to have this
&gt; functionality but accessing some program's memory is pretty easy nowadays,
&gt; I think it's a good practice to clean behind the cipher functions for what
&gt; it makes sense and whenever possible.
&gt;
&gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt; crypto extension so I can't do any performance or correctness testing for
&gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt; extensions for arm64 architectures?

There is a new AArch64 system in the GCC Compile Farm that has not
been installed yet.  That system might provide the SHA-512 support.
It will have an Ampere eMAG processor supporting ARMv8.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710190651</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-10 19:06:51-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Sat, Jul 10, 2021 at 9:55 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:

&gt; On Sat, Jul 10, 2021 at 2:45 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; On Fri, Jul 9, 2021 at 10:08 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; My concern is if the program
&gt; &gt; &gt; &gt; terminates then the operation system will deallocate the program's
&gt; stack
&gt; &gt; &gt; &gt; without clearing its content so that leftover data will remain
&gt; somewhere
&gt; &gt; &gt; at
&gt; &gt; &gt; &gt; the RAM which could be a subject for a memory allocation or dumbing
&gt; by
&gt; &gt; &gt; &gt; other programs.
&gt; &gt; &gt;
&gt; &gt; &gt; I think the kernel is responsible for clearing that memory before
&gt; &gt; &gt; handing it out to a new process. If it didn't, that would be a huge
&gt; &gt; &gt; security problem. I'm fairly sure operating systems do this correctly.
&gt; &gt; &gt; (And I would be a bit curious to know of any exceptions, maybe some
&gt; &gt; &gt; embedded or ancient systems don't do it?)
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; You are right, modern operating systems are supposed to have this
&gt; &gt; functionality but accessing some program's memory is pretty easy
&gt; nowadays,
&gt; &gt; I think it's a good practice to clean behind the cipher functions for
&gt; what
&gt; &gt; it makes sense and whenever possible.
&gt; &gt;
&gt; &gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt; &gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt; &gt; crypto extension so I can't do any performance or correctness testing for
&gt; &gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt; &gt; extensions for arm64 architectures?
&gt;
&gt; There is a new AArch64 system in the GCC Compile Farm that has not
&gt; been installed yet.  That system might provide the SHA-512 support.
&gt; It will have an Ampere eMAG processor supporting ARMv8.
&gt;
&gt; Thanks, David
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710190808</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-10 19:08:08-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Sat, Jul 10, 2021 at 9:55 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:

&gt; On Sat, Jul 10, 2021 at 2:45 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; On Fri, Jul 9, 2021 at 10:08 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; My concern is if the program
&gt; &gt; &gt; &gt; terminates then the operation system will deallocate the program's
&gt; stack
&gt; &gt; &gt; &gt; without clearing its content so that leftover data will remain
&gt; somewhere
&gt; &gt; &gt; at
&gt; &gt; &gt; &gt; the RAM which could be a subject for a memory allocation or dumbing
&gt; by
&gt; &gt; &gt; &gt; other programs.
&gt; &gt; &gt;
&gt; &gt; &gt; I think the kernel is responsible for clearing that memory before
&gt; &gt; &gt; handing it out to a new process. If it didn't, that would be a huge
&gt; &gt; &gt; security problem. I'm fairly sure operating systems do this correctly.
&gt; &gt; &gt; (And I would be a bit curious to know of any exceptions, maybe some
&gt; &gt; &gt; embedded or ancient systems don't do it?)
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; You are right, modern operating systems are supposed to have this
&gt; &gt; functionality but accessing some program's memory is pretty easy
&gt; nowadays,
&gt; &gt; I think it's a good practice to clean behind the cipher functions for
&gt; what
&gt; &gt; it makes sense and whenever possible.
&gt; &gt;
&gt; &gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt; &gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt; &gt; crypto extension so I can't do any performance or correctness testing for
&gt; &gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt; &gt; extensions for arm64 architectures?
&gt;
&gt; There is a new AArch64 system in the GCC Compile Farm that has not
&gt; been installed yet.  That system might provide the SHA-512 support.
&gt; It will have an Ampere eMAG processor supporting ARMv8.
&gt;

Thanks for the info, I think we have to wait until the new system is set up.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210714181534</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-14 18:15:34-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

On Sat, Jul 10, 2021 at 10:08 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Sat, Jul 10, 2021 at 9:55 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt;
&gt;&gt; On Sat, Jul 10, 2021 at 2:45 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; On Fri, Jul 9, 2021 at 10:08 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; My concern is if the program
&gt;&gt; &gt; &gt; &gt; terminates then the operation system will deallocate the program's
&gt;&gt; stack
&gt;&gt; &gt; &gt; &gt; without clearing its content so that leftover data will remain
&gt;&gt; somewhere
&gt;&gt; &gt; &gt; at
&gt;&gt; &gt; &gt; &gt; the RAM which could be a subject for a memory allocation or dumbing
&gt;&gt; by
&gt;&gt; &gt; &gt; &gt; other programs.
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; I think the kernel is responsible for clearing that memory before
&gt;&gt; &gt; &gt; handing it out to a new process. If it didn't, that would be a huge
&gt;&gt; &gt; &gt; security problem. I'm fairly sure operating systems do this correctly.
&gt;&gt; &gt; &gt; (And I would be a bit curious to know of any exceptions, maybe some
&gt;&gt; &gt; &gt; embedded or ancient systems don't do it?)
&gt;&gt; &gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; You are right, modern operating systems are supposed to have this
&gt;&gt; &gt; functionality but accessing some program's memory is pretty easy
&gt;&gt; nowadays,
&gt;&gt; &gt; I think it's a good practice to clean behind the cipher functions for
&gt;&gt; what
&gt;&gt; &gt; it makes sense and whenever possible.
&gt;&gt; &gt;
&gt;&gt; &gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt;&gt; &gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt;&gt; &gt; crypto extension so I can't do any performance or correctness testing
&gt;&gt; for
&gt;&gt; &gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt;&gt; &gt; extensions for arm64 architectures?
&gt;&gt;
&gt;&gt; There is a new AArch64 system in the GCC Compile Farm that has not
&gt;&gt; been installed yet.  That system might provide the SHA-512 support.
&gt;&gt; It will have an Ampere eMAG processor supporting ARMv8.
&gt;&gt;
&gt;
&gt; Thanks for the info, I think we have to wait until the new system is set
&gt; up.
&gt;

To clarify, the new Aarch64 machine in GCC Compile Farm doesn't support
SHA-512 and SHA3 extensions.

Until we figure a way to test the optimized cores of SHA-512 and SHA, we
can proceed with the optimized implementation of AES for Arm64 then I'll
implement optimizations for Chacha20 and Poly1305 which is planned to be
released with corresponding optimizations for S390x architecture by using
the supported vector facility.

There are also two patches of fat build support and memxor optimization for
s390x, it would be great to process them so I can start pushing patches of
SHA optimizations for s390x architecture.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210820213640</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-20 21:36:40-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Thu, Aug 19, 2021 at 9:04 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; config.guess detects the C standard library based on a result from the
&gt; &gt; compiler defined in "CC_FOR_BUILD" variable, for some reason OpenWrt
&gt; build
&gt; &gt; system failed to set that variable properly, from your config.log I can
&gt; see
&gt; &gt; CC_FOR_BUILD='gcc -O -g' but when I use bare musl tools I get
&gt; &gt; CC_FOR_BUILD='musl-gcc'
&gt;
&gt; In Nettle's Makefiles, CC_FOR_BUILD is intended to be a compiler
&gt; targetting the *build* system, used to compile things like eccdata.c
&gt; that are run on the build system as part of the build. It's intended to
&gt; be different from CC when cross compiling.
&gt;
&gt; Not entirely sure how CC_FOR_BUILD is used in config.guess, but I think
&gt; it is used to detect the system type of the build system.
&gt;
&gt; &gt; There is nothing specific in the output of
&gt; powerpc64-openwrt-linux-musl-gcc
&gt; &gt; -E -dM log as I can see. In musl libc FAQ, they stated that there is no
&gt; &gt; __MUSL__ in the preprocessor macros https://wiki.musl-libc.org/faq.html
&gt;
&gt; The interesting thing I see is
&gt;
&gt; #define _CALL_ELF 2
&gt;
&gt; I hope this can be used to distinguish from other big-endian systems,
&gt; that use ELFv1 abi?
&gt;

That's right, in little-endian systems I got "#define _CALL_ELF 2" while in
big-endian ones that value is 1 except when using musl. I've updated the
patch in the branch
https://git.lysator.liu.se/mamonet/nettle/-/tree/ppc64_musl_fix to exploit
this distinction. Testing the fix again by the bug reporter will be
appreciated since I don't have OpenWrt build system in my power system.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210821033932</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-08-21 03:39:32-0400</timestampReceived><subject>Re: Build problem on ppc64be + musl</subject><body>

On Thu, Aug 19, 2021 at 11:22 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; AIX continues to use its ABI, which essentially is closely related to
&gt; &gt; ELFv1 and uses the XCOFF file format and syntax.
&gt;
&gt; I don't remember if Maamoun or someone else
&gt; tested Nettle's powerpc64 assembly on AIX?
&gt;

I tried testing powerpc64 assembly on AIX but as far as I remember I didn't
get the library configured in the first place, there is some issue that
obstructs the configuration process on AIX. I'll get into this issue once
we're done with the current tasks so I don't get confused.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210919234358</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-09-19 23:43:58-0400</timestampReceived><subject>Re: [S390x] Optimize SHA1 with fat build support</subject><body>

On Sun, Aug 29, 2021 at 5:52 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; Applying hardware-accelerated SHA3 instruction to optimize sha3_permute
&gt; function for s390x arch has an insignificant impact on the performance, I'm
&gt; wondering what we can do to take full advantage of those instructions.
&gt; Optimizing sha3_absorb seems a good way to go since the s390x-specific
&gt; accelerator implies permuting of state bytes and XOR operations but the
&gt; downside of implementing this function is handling the block size variants
&gt; for each mode, S390x arch supports the standard block sizes so we can
&gt; branch for each standard size in the supported modes but should we consider
&gt; unexpected block size during the implementation?
&gt;

I got almost 12% speedup of optimizing the sha3_permute() function using
the SHA hardware accelerator of s390x, is it worth adding that assembly
implementation? I'll attach the patch at the end of this email.

In another topic, are you aware of any CFarm alternative that have arm64
machine with SHA-256 and SHA3 support to continue optimizing those
functions for aarch64 architecture in addition to x86_64 machine with shani
support to complete the patch of sha1_comoress_n() function and maximize
the performance of SHA1 compress function on hardware-supported
architectures.

C s390x/msa_x6/sha3-permute.asm

ifelse(`
   Copyright (C) 2021 Mamone Tarsha
   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C KIMD (COMPUTE INTERMEDIATE MESSAGE DIGEST) is specefied in
C "z/Architecture Principles of Operation SA22-7832-12" as follows:
C A function specified by the function code in general register 0 is
performed.
C General register 1 contains the logical address of the leftmost byte of
the parameter block in storage.
C the second operand is processed as specified by the function code using
an initial chaining value in
C the parameter block, and the result replaces the chaining value.

C This implementation uses KIMD-SHA3-512 function.
C The parameter block used for the KIMD-SHA3-512 function has the following
format:
C *----------------------------------------------*
C |               ICV (200 bytes)                |
C *----------------------------------------------*

C SHA function code
define(`SHA3_512_FUNCTION_CODE', `35')
C Size of block
define(`SHA3_512_BLOCK_SIZE', `72')
C Size of state
define(`SHA3_STATE_SIZE', `200')

.file "sha3-permute.asm"

.text

C void
C sha3_permute(struct sha3_ctx *ctx)

PROLOGUE(nettle_sha3_permute)
    lghi           %r0,SHA3_512_FUNCTION_CODE    C FUNCTION_CODE
    ALLOC_STACK(%r1,SHA3_STATE_SIZE+SHA3_512_BLOCK_SIZE)
.irp idx, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
19, 20, 21, 22, 23, 24
    mvcin          \idx*8(8,%r1),\idx*8+7(%r2)
.endr
    la             %r4,SHA3_STATE_SIZE (%r1)
    xc             0(SHA3_512_BLOCK_SIZE,%r4),0(%r4)
    lghi           %r5,SHA3_512_BLOCK_SIZE
1:  .long   0xb93e0004                           C kimd %r0,%r4. perform
KIMD-SHA operation on data
    brc            1,1b
.irp idx, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
19, 20, 21, 22, 23, 24
    mvcin          \idx*8(8,%r2),\idx*8+7(%r1)
.endr
    FREE_STACK(SHA3_STATE_SIZE+SHA3_512_BLOCK_SIZE)
    br             RA
EPILOGUE(nettle_sha3_permute)

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210901190937</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-09-01 19:09:37-0400</timestampReceived><subject>Re: Feature request: OCB mode</subject><body>

Justus Winter &lt;justus@sequoia-pgp.org&gt; writes:

&gt; we (Sequoia PGP) would love to see OCB being implemented in Nettle.  The
&gt; OpenPGP working group is working on a revision of RFC4880, which will
&gt; mostly be a cryptographic refresh, and will bring AEAD to OpenPGP.
&gt;
&gt; The previous -now abandoned- draft called for EAX being mandatory, and
&gt; OCB being optional [0].  This was motivated by OCB being encumbered by
&gt; patents.  However, said patents were waived by the holder [1].
&gt;
&gt; 0: https://datatracker.ietf.org/doc/html/draft-ietf-openpgp-rfc4880bis-10#section-9.6
&gt; 1: https://mailarchive.ietf.org/arch/msg/cfrg/qLTveWOdTJcLn4HP3ev-vrj05Vg/

That's good news, I hadn't seen that. Then OCB gets a lot more
interesting. And https://datatracker.ietf.org/doc/html/rfc7253 is a
proper reference (there seems to be a couple of different versions of
OCB)?

&gt; Unfortunately, we don't have the expertise in our team to contribute a
&gt; patch, and we currently aren't in a position to offer funding for the
&gt; implementation.

If someone wants to work on it, please post to the list. I might look
into it myself, but as you have noticed, I have rather limited hacking
time.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210701194554</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-01 19:45:54-0400</timestampReceived><subject>Re: [AArch64] Optimize SHA-256 compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request !28
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/28&gt; to the
&gt; 'arm64-sha1' branch that optimizes SHA-256 compress function, I've added a
&gt; brief description of the patch in addition to benchmark numbers in the MR
&gt; description. A patch for fat build support will be followed in another
&gt; merge request.

Thanks, merged now!

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210705191922</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-05 19:19:22-0400</timestampReceived><subject>Re: [AArch64] Fat build support for SHA-256 compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request that adds fat build support for SHA-256 compress
&gt; function !29 &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/29&gt;

Thanks, merged!

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210714105808</emailId><senderName>Norbert Pocs</senderName><senderEmail>npocs@redhat.com</senderEmail><timestampReceived>2021-07-14 10:58:08-0400</timestampReceived><subject>Re: HPKE implementation</subject><body>

Hi nettle,

The implementation was proposed as a PR [0] with all modes and all
combinations of primitives described in [1].

OpenSSL has an open issue for HPKE support [2].

0 - https://git.lysator.liu.se/nettle/nettle/-/merge_requests/27
1 - https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-hpke-10
2 - https://github.com/openssl/openssl/issues/14748

Regards
Norbert Pócs


On Tue, Mar 2, 2021 at 12:58 PM Norbert Pocs &lt;npocs@redhat.com&gt; wrote:

&gt; Which combinations of public key mechanism, key derivation/expansion,
&gt;&gt; and aead are of main interest?
&gt;
&gt;
&gt; The required combinations for the encrypted client hello [0] in TLS will
&gt; be the main focus,
&gt; then continuous implementation of the others.
&gt;
&gt; Do you expect the specification to be finalized soon?
&gt;&gt;
&gt;
&gt; I do not know when the specification will be finalized, however
&gt; implementations of HPKE already exist [1]. The analysis can
&gt; be found here [2].
&gt;
&gt; [0] https://tools.ietf.org/html/draft-ietf-tls-esni-09#section-9
&gt; [1] https://github.com/cfrg/draft-irtf-cfrg-hpke/
&gt; [2] https://eprint.iacr.org/2020/1499
&gt;
&gt; Regards
&gt; Norbert Pócs
&gt;
&gt;
&gt; On Thu, Feb 25, 2021 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Norbert Pocs &lt;npocs@redhat.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; My current project is the implementation of HPKE draft [0]. The first
&gt;&gt; goal
&gt;&gt; &gt; is to implement mode_base.
&gt;&gt;
&gt;&gt; Hi, I was not aware of this work. It could make sense to support in
&gt;&gt; Nettle, in particular if GnuTLS wants to use it.
&gt;&gt;
&gt;&gt; Which combinations of public key mechanism, key derivation/expansion,
&gt;&gt; and aead are of main interest?
&gt;&gt;
&gt;&gt; Do you expect the specification to be finalized soon?
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt; /Niels
&gt;&gt;
&gt;&gt; --
&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;
&gt;&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210717103750</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-17 10:37:50-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; You are right, modern operating systems are supposed to have this
&gt; functionality but accessing some program's memory is pretty easy nowadays,
&gt; I think it's a good practice to clean behind the cipher functions for what
&gt; it makes sense and whenever possible.

I think it's futile to try to do that thoroughly, e.g., code generated
by the compiler will not clear each stack frame on return (and I'm not
even ware of any compiler option to generate code like that). We have to
trust the operating system (where as usual, "trust" can also be read as
"depend on").

For the specific case of key material, it might make sense to go to a
little extra effort to not leave copies in memory, but other neetle code
doesn't do that.

&gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt; crypto extension so I can't do any performance or correctness testing for
&gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt; extensions for arm64 architectures?

Can you do correctness tests on qemu? (I've been using a crosscompiler
and qemu-user to test other ARM code, and that's also what the ci tests
do).

I have access to the systems listed on
https://gmplib.org/devel/testsystems, is any of those applicable? The
arm64 machines available includes one Cortex-A73 and one Apple M1.

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210717105020</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-17 10:50:20-0400</timestampReceived><subject>Re: [Aarch64] Optimize AES</subject><body>

On Sat, Jul 17, 2021 at 1:46 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; It fits better to have one implementation per key size, I'll modify this
&gt; &gt; patch to apply this approach. However, we need to merge the s390x branch
&gt; at
&gt; &gt; first since it has a separate  implementation for each key size.
&gt;
&gt; Right. With fat support in, is there anything else that is essential
&gt; before merging?
&gt;

No, AES and GHASH have the full functionalities for S390x architecture in
this way.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210717110050</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-17 11:00:50-0400</timestampReceived><subject>Fwd: [S390x] Optimize GHASH</subject><body>

---------- Forwarded message ---------
From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
Date: Sat, Jul 17, 2021 at 2:00 PM
Subject: Re: [S390x] Optimize GHASH
To: Niels Möller &lt;nisse@lysator.liu.se&gt;


On Sat, Jul 17, 2021 at 1:37 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt; In another topic, I've optimized the SHA-512 algorithm for arm64
&gt; &gt; architecture but it turned out all CFarm variants don't support SHA-512
&gt; &gt; crypto extension so I can't do any performance or correctness testing for
&gt; &gt; now. Do you know any CFarm alternative that supports SHA-512 and SHA3
&gt; &gt; extensions for arm64 architectures?
&gt;
&gt; Can you do correctness tests on qemu? (I've been using a crosscompiler
&gt; and qemu-user to test other ARM code, and that's also what the ci tests
&gt; do).
&gt;

Sure, but I'm also concerned about the performance testing. I was always
trying to get the best performance out of hardware-accelerated cores.


&gt; I have access to the systems listed on
&gt; https://gmplib.org/devel/testsystems, is any of those applicable? The
&gt; arm64 machines available includes one Cortex-A73 and one Apple M1.
&gt;

Cortex-A73 doesn't support SHA-512 and SHA3 List of ARM microarchitectures
- Wikipedia &lt;https://en.wikipedia.org/wiki/List_of_ARM_microarchitectures&gt;
Cortex-A75 is the minimum architecture that has a full implementation of
ARMv8.2-A which is the arch that introduced SHA-512 and SHA3 AArch64
Options (Using the GNU Compiler Collection (GCC))
&lt;https://gcc.gnu.org/onlinedocs/gcc/AArch64-Options.html&gt;
Cortex-A55 should support those extensions according to the list.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210722103333</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-22 10:33:33-0400</timestampReceived><subject>Re: [S390x] Optimize memxor</subject><body>

Optimized memxor3 function using vector facility has been added to merge
request along with fat build support and a new s390x option in configure.ac

regards,
Mamone

On Sat, Jul 10, 2021 at 9:27 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I made a merge request !30
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/30&gt; that
&gt; optimizes memxor function for S390x architecture. I've attached a benchmark
&gt; on a Z15 processor in the MR description.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210724130101</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-24 13:01:01-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

On Sat, Jul 24, 2021 at 3:51 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I've applied for your change requests. I think we're ready to merge the
&gt; &gt; s390x branch at this point, let me know if there are conflicts with the
&gt; &gt; master branch tho.
&gt;
&gt; Merged to master branch now! Had to commit some minor fixes to make
&gt; "make dist" and the s390x ci build work, and added a brief ChangeLog
&gt; entry for latest additions.
&gt;
&gt; For the memxor merge requests, it would be good to retarget to the
&gt; master branch (but I'm not sure how to do that in gitlab).
&gt;

I've edited the MR to target the master branch.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210730122515</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-30 12:25:15-0400</timestampReceived><subject>[S390x] Optimize SHA1 with fat build support</subject><body>

I made a merge request in the main repository that optimizes SHA1 for s390x
architecture with fat build support !33
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/33&gt;.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210730122621</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-30 12:26:21-0400</timestampReceived><subject>[AArch64] Optimize AES with fat build support</subject><body>

 I made a merge request in the main repository that optimizes AES for arm64
architecture with fat build support !34
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/34&gt;.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210601194414</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-06-01 19:44:14-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

On Tue, Jun 1, 2021 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; If I
&gt; read the latest patch correctly, you also don't keep any state besides
&gt; the MSGx registers?
&gt;

Right, everything is done in the same context of each round in the latest
patch, nothing kept beyond or after.


&gt; &gt; the easiest solution is to define
&gt; &gt; the data in the .text section to make sure the address is near enough to
&gt; be
&gt; &gt; loaded with certain instruction. Do you want to do that?
&gt;
&gt; Using .text would probably work, even if it's in some sense more correct
&gt; to put
&gt; the constants in rodata segment. But let's leave as is for now.
&gt;

I agree, it's acceptable to keep it as is for this case. I'm a little
concerned about handling the constant initialization of more complicated
cases, we're gonna discuss it at the time.


&gt; I've pushed the combined patches to a branch arm64-sha1. Would you like
&gt; to update the fat build setup, before merging to master?
&gt;

Sure, I just need some time as I have some stuff to sort out before doing
the fat build for this patch.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210601210143</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-06-01 21:01:43-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

On Tue, Jun 1, 2021 at 11:21 PM Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
wrote:

&gt; On Thu May 20, 2021 at 3:59 PM EDT, Maamoun TK wrote:
&gt; &gt; On Thu, May 20, 2021 at 10:06 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; &gt; wrote:
&gt; &gt;
&gt; &gt; &gt; "Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; So in total, if we assume an ideal (but impossible) zero-cost version
&gt; &gt; &gt; &gt; for memxor, memxor3, and gcm_fill and avoid permutes via ISA 3.0
&gt; vector
&gt; &gt; &gt; &gt; load/stores we can only account for 11.82 cycles/block; leaving 4.97
&gt; &gt; &gt; &gt; cycles/block as an additional benefit of the combined implementation.
&gt; &gt; &gt;
&gt; &gt; &gt; One hypothesis for that gain is that we can avoid storing the aes input
&gt; &gt; &gt; in memory at all; instead, generated the counter values on the fly in
&gt; &gt; &gt; the appropriate registers.
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;&gt; Another potential overhead is that data is stored to memory when
&gt; passed
&gt; &gt; &gt; &gt;&gt; between these functions. It seems we store a block 3 times, and
&gt; loads a
&gt; &gt; &gt; &gt;&gt; block 4 times (the additional accesses should be cache friendly, but
&gt; &gt; &gt; &gt;&gt; wills till cost some execution resources). Optimizing that seems to
&gt; need
&gt; &gt; &gt; &gt;&gt; some kind of combined function. But maybe it is sufficient to
&gt; optimize
&gt; &gt; &gt; &gt;&gt; something a bit more general than aes gcm, e.g., aes ctr?
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; This would basically have to replace the nettle_crypt16 function call
&gt; &gt; &gt; &gt; with arch-specific assembly, right? I can code this up and try it
&gt; out in
&gt; &gt; &gt; &gt; the context of AES-GCM.
&gt; &gt; &gt;
&gt; &gt; &gt; Yes, something like that. If we leave the _nettle_gcm_hash unchanged
&gt; &gt; &gt; (with its own independent assembly implementation), and look at
&gt; &gt; &gt; gcm_encrypt, what we have is
&gt; &gt; &gt;
&gt; &gt; &gt;       const void *cipher, nettle_cipher_func *f,
&gt; &gt; &gt;
&gt; &gt; &gt;   _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst,
&gt; src);
&gt; &gt; &gt;
&gt; &gt; &gt; It would be nice if we could replace that with a call to aes_ctr_crypt,
&gt; &gt; &gt; and then optimizing that would benefit both gcm and plain ctr. But it's
&gt; &gt; &gt; not quite that easy, because gcm unfortunately uses it's own variant of
&gt; &gt; &gt; ctr mode, which is why we need to pass the gcm_fill function in the
&gt; &gt; &gt; first place.
&gt; &gt; &gt;
&gt; &gt; &gt; So if we need separate assembly for aes_plain_ctr and aes_gcm_ctr (they
&gt; &gt; &gt; *might* still share some code, but they would be distinct entry
&gt; points).
&gt; &gt; &gt; Say we call the gcm-specific ctr function from some variant of
&gt; &gt; &gt; gcm_encrypt via a different function pointer. Then that gcm_encrypt
&gt; &gt; &gt; variant is getting a bit pointless. Maybe it's better to do
&gt; &gt; &gt;
&gt; &gt; &gt;   void aes128_gcm_encrypt(...)
&gt; &gt; &gt;   {
&gt; &gt; &gt;     _nettle_aes128_gcm_ctr(...);
&gt; &gt; &gt;     _nettle_gcm_hash(...);
&gt; &gt; &gt;   }
&gt; &gt; &gt;
&gt; &gt; &gt; At least, we avoid duplicating the _gcm_hash for aes128, aes192, aes256
&gt; &gt; &gt; (and any other algorithms we might want to optimize in a similar way).
&gt; &gt; &gt; And each of the aes assembly routines should be fairly small and easy
&gt; to
&gt; &gt; &gt; maintain.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; While writing the white paper "Optimize AES-GCM for PowerPC architecture
&gt; &gt; processors", I concluded that is the best approach to implement for
&gt; &gt; PowerPC
&gt; &gt; architecture, easy to maintain, avoid duplication, and perform well.
&gt; &gt; I've separated aes_gcm encrypt/decrypt to two functions, aes_ctr and
&gt; &gt; ghash.
&gt; &gt; Both implemented using Power ISA v3.00 assisted with vector-scalar
&gt; &gt; registers.
&gt; &gt; I got 1.18 cycles/byte for gcm-aes-128 encrypt/decrypt, 1.31 cycles/byte
&gt; &gt; for gcm-aes-192 encrypt/decrypt, and 1.44 cycles/byte for gcm-aes-256
&gt; &gt; encrypt/decrypt.
&gt;
&gt; Neat, did you base that on the aes-gcm combined series I posted here or
&gt; completely different/new code?
&gt;

It's based on new code written to fit the paper context.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210608191334</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-06-08 19:13:34-0400</timestampReceived><subject>Re: ANNOUNCE: Nettle-3.7.3</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I've prepared a new bug-fix release of Nettle, a low-level
&gt; cryptographics library, to fix bugs in the RSA decryption functions. The
&gt; bugs cause crashes on certain invalid inputs, which could be used
&gt; for denial of service attacks on applications using these functions.

I forgot to reference the CVE id allocated for this problem:
CVE-2021-3580 (at the moment still in the "reserved" state). Thanks to
Simo Sorce and Redhat for that registration.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210630083338</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-06-30 08:33:38-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Hi Niels,

Did you get a chance to look at the recently posted patches?

Thank you,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210630184723</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-06-30 18:47:23-0400</timestampReceived><subject>Re: [Aarch64] Fat build support for SHA1 compress</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This patch added fat build support SHA1 compress function using the regular
&gt; HWCAP features.

Thanks, merged to the arm64-sha1 branch for testing. 

The patch in the email didn't apply cleanly, there were some breakage
with added newline characters etc. Maybe try as an attachment next time
(or create a merge request).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210630191006</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-06-30 19:10:06-0400</timestampReceived><subject>Re: [S390x] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request !26
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/26&gt; that
&gt; optimizes the GHASH algorithm for S390x architecture.

Nice! I've added a few comments in the mr.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210501143916</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-01 14:39:16-0400</timestampReceived><subject>[Aarch64] Optimize AES</subject><body>

This patch optimizes nettle_aes_encrypt() and nettle_aes_decrypt()
functions for arm64 architecture, it takes advantage of 'aese' and 'aesmc'
instructions to optimize the encryption function and 'aesd' and 'aesimc' to
optimize the decryption function.

The patch passes the testsuite of nettle. I also run the benchmark on
gcc117 instance of CFarm by configuring the library with "--disable-fat
--enable-arm64-crypto" options then executing examples/nettle-benchmark:

aes128  ECB encrypt 2522.67
aes128  ECB decrypt 2522.53
aes192  ECB encrypt 2165.06
aes192  ECB decrypt 2165.04
aes256  ECB encrypt 1866.80
aes256  ECB decrypt 1866.38

openssl aes128  ECB encrypt 1043.52
openssl aes128  ECB decrypt 1043.05
openssl aes192  ECB encrypt  904.08
openssl aes192  ECB decrypt  903.85
openssl aes256  ECB encrypt  787.43
openssl aes256  ECB decrypt  787.20

gcm_aes128      encrypt  955.10
gcm_aes128      decrypt  955.06
gcm_aes128       update 3269.18
gcm_aes192      encrypt  896.26
gcm_aes192      decrypt  896.46
gcm_aes192       update 3270.24
gcm_aes256      encrypt  840.17
gcm_aes256      decrypt  843.53
gcm_aes256       update 3270.08

openssl gcm_aes128      encrypt  894.51
openssl gcm_aes128      decrypt  899.05
openssl gcm_aes128       update 1636.61
openssl gcm_aes192      encrypt  834.94
openssl gcm_aes192      decrypt  841.99
openssl gcm_aes192       update 1631.40
openssl gcm_aes256      encrypt  788.48
openssl gcm_aes256      decrypt  791.31
openssl gcm_aes256       update 1635.18

I'm a little suspicious about the benchmark numbers because as I remember
the performance of gcm update doesn't double the openssl number, I repeat
running the process but kept giving the same performance margin.

---
 arm64/crypto/aes-decrypt-internal.asm | 223
++++++++++++++++++++++++++++++++++
 arm64/crypto/aes-encrypt-internal.asm | 223
++++++++++++++++++++++++++++++++++
 2 files changed, 446 insertions(+)
 create mode 100644 arm64/crypto/aes-decrypt-internal.asm
 create mode 100644 arm64/crypto/aes-encrypt-internal.asm

diff --git a/arm64/crypto/aes-decrypt-internal.asm
b/arm64/crypto/aes-decrypt-internal.asm
new file mode 100644
index 00000000..4bfdb314
--- /dev/null
+++ b/arm64/crypto/aes-decrypt-internal.asm
@@ -0,0 +1,223 @@
+C arm64/crypto/aes-decrypt-internal.asm
+
+ifelse(`
+   Copyright (C) 2021 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+.file "aes-decrypt-internal.asm"
+.arch armv8-a+crypto
+
+.text
+
+C Register usage:
+
+define(`ROUNDS', `x0')
+define(`KEYS', `x1')
+define(`LENGTH', `x3')
+define(`DST', `x4')
+define(`SRC', `x5')
+
+define(`S0', `v0')
+define(`S1', `v1')
+define(`S2', `v2')
+define(`S3', `v3')
+define(`K0', `v16')
+define(`K1', `v17')
+define(`K2', `v18')
+define(`K3', `v19')
+define(`K4', `v20')
+define(`K5', `v21')
+define(`K6', `v22')
+define(`K7', `v23')
+define(`K8', `v24')
+define(`K9', `v25')
+define(`K10', `v26')
+define(`K11', `v27')
+define(`K12', `v28')
+define(`K13', `v29')
+define(`K14', `v30')
+
+C AES_ROUND_4B(KEY)
+define(`AES_ROUND_4B', m4_assert_numargs(1)`
+    aesd           S0.16b,$1.16b
+    aesimc         S0.16b,S0.16b
+    aesd           S1.16b,$1.16b
+    aesimc         S1.16b,S1.16b
+    aesd           S2.16b,$1.16b
+    aesimc         S2.16b,S2.16b
+    aesd           S3.16b,$1.16b
+    aesimc         S3.16b,S3.16b
+')
+
+C AES_LAST_ROUND_4B(KEY)
+define(`AES_LAST_ROUND_4B', m4_assert_numargs(1)`
+    aesd           S0.16b,$1.16b
+    eor            S0.16b,S0.16b,K14.16b
+    aesd           S1.16b,$1.16b
+    eor            S1.16b,S1.16b,K14.16b
+    aesd           S2.16b,$1.16b
+    eor            S2.16b,S2.16b,K14.16b
+    aesd           S3.16b,$1.16b
+    eor            S3.16b,S3.16b,K14.16b
+')
+
+C AES_ROUND_1B(KEY)
+define(`AES_ROUND_1B', m4_assert_numargs(1)`
+    aesd           S0.16b,$1.16b
+    aesimc         S0.16b,S0.16b
+')
+
+C AES_LAST_ROUND_1B(KEY)
+define(`AES_LAST_ROUND_1B', m4_assert_numargs(1)`
+    aesd           S0.16b,$1.16b
+    eor            S0.16b,S0.16b,K14.16b
+')
+
+C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+C       const struct aes_table *T,
+C       size_t length, uint8_t *dst,
+C       const uint8_t *src)
+
+PROLOGUE(_nettle_aes_decrypt)
+    ands           x6,LENGTH,#-64
+    b.eq           L1B
+
+    mov            x7,KEYS
+    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x7],#64
+    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x7],#64
+    ld1            {K8.4s,K9.4s},[x7],#32
+    cmp            ROUNDS,#10
+    b.eq           L4B_last_key
+    ld1            {K10.4s,K11.4s},[x7],#32
+    cmp            ROUNDS,#12
+    b.eq           L4B_last_key
+    ld1            {K12.4s,K13.4s},[x7],#32
+
+L4B_last_key:
+    ld1            {K14.4s},[x7]
+
+L4B_loop:
+    ld1            {S0.16b,S1.16b,S2.16b,S3.16b},[SRC],#64
+
+    AES_ROUND_4B(K0)
+    AES_ROUND_4B(K1)
+    AES_ROUND_4B(K2)
+    AES_ROUND_4B(K3)
+    AES_ROUND_4B(K4)
+    AES_ROUND_4B(K5)
+    AES_ROUND_4B(K6)
+    AES_ROUND_4B(K7)
+    AES_ROUND_4B(K8)
+    cmp            ROUNDS,#10
+    b.eq           L4B_10_round
+    cmp            ROUNDS,#12
+    b.eq           L4B_12_round
+    b              L4B_14_round
+
+L4B_10_round:
+    AES_LAST_ROUND_4B(K9)
+    b              L4B_done
+L4B_12_round:
+    AES_ROUND_4B(K9)
+    AES_ROUND_4B(K10)
+    AES_LAST_ROUND_4B(K11)
+    b              L4B_done
+L4B_14_round:
+    AES_ROUND_4B(K9)
+    AES_ROUND_4B(K10)
+    AES_ROUND_4B(K11)
+    AES_ROUND_4B(K12)
+    AES_LAST_ROUND_4B(K13)
+
+L4B_done:
+    st1            {S0.16b,S1.16b,S2.16b,S3.16b},[DST],#64
+
+    subs           x6,x6,#64
+    b.ne           L4B_loop
+
+    and            LENGTH,LENGTH,#63
+
+L1B:
+    cbz            LENGTH,Ldone
+
+    mov            x6,KEYS
+    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x6],#64
+    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x6],#64
+    ld1            {K8.4s,K9.4s},[x6],#32
+    cmp            ROUNDS,#10
+    b.eq           L1B_last_key
+    ld1            {K10.4s,K11.4s},[x6],#32
+    cmp            ROUNDS,#12
+    b.eq           L1B_last_key
+    ld1            {K12.4s,K13.4s},[x6],#32
+
+L1B_last_key:
+    ld1            {K14.4s},[x6]
+
+L1B_loop:
+    ld1            {S0.16b},[SRC],#16
+
+    AES_ROUND_1B(K0)
+    AES_ROUND_1B(K1)
+    AES_ROUND_1B(K2)
+    AES_ROUND_1B(K3)
+    AES_ROUND_1B(K4)
+    AES_ROUND_1B(K5)
+    AES_ROUND_1B(K6)
+    AES_ROUND_1B(K7)
+    AES_ROUND_1B(K8)
+    cmp            ROUNDS,#10
+    b.eq           L1B_10_round
+    cmp            ROUNDS,#12
+    b.eq           L1B_12_round
+    b              L1B_14_round
+
+L1B_10_round:
+    AES_LAST_ROUND_1B(K9)
+    b              L1B_done
+L1B_12_round:
+    AES_ROUND_1B(K9)
+    AES_ROUND_1B(K10)
+    AES_LAST_ROUND_1B(K11)
+    b              L1B_done
+L1B_14_round:
+    AES_ROUND_1B(K9)
+    AES_ROUND_1B(K10)
+    AES_ROUND_1B(K11)
+    AES_ROUND_1B(K12)
+    AES_LAST_ROUND_1B(K13)
+
+L1B_done:
+    st1            {S0.16b},[DST],#16
+
+    subs           LENGTH,LENGTH,#16
+    b.ne           L1B_loop
+
+Ldone:
+    ret
+EPILOGUE(_nettle_aes_decrypt)
diff --git a/arm64/crypto/aes-encrypt-internal.asm
b/arm64/crypto/aes-encrypt-internal.asm
new file mode 100644
index 00000000..314f9333
--- /dev/null
+++ b/arm64/crypto/aes-encrypt-internal.asm
@@ -0,0 +1,223 @@
+C arm64/crypto/aes-encrypt-internal.asm
+
+ifelse(`
+   Copyright (C) 2021 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+.file "aes-encrypt-internal.asm"
+.arch armv8-a+crypto
+
+.text
+
+C Register usage:
+
+define(`ROUNDS', `x0')
+define(`KEYS', `x1')
+define(`LENGTH', `x3')
+define(`DST', `x4')
+define(`SRC', `x5')
+
+define(`S0', `v0')
+define(`S1', `v1')
+define(`S2', `v2')
+define(`S3', `v3')
+define(`K0', `v16')
+define(`K1', `v17')
+define(`K2', `v18')
+define(`K3', `v19')
+define(`K4', `v20')
+define(`K5', `v21')
+define(`K6', `v22')
+define(`K7', `v23')
+define(`K8', `v24')
+define(`K9', `v25')
+define(`K10', `v26')
+define(`K11', `v27')
+define(`K12', `v28')
+define(`K13', `v29')
+define(`K14', `v30')
+
+C AES_ROUND_4B(KEY)
+define(`AES_ROUND_4B', m4_assert_numargs(1)`
+    aese           S0.16b,$1.16b
+    aesmc          S0.16b,S0.16b
+    aese           S1.16b,$1.16b
+    aesmc          S1.16b,S1.16b
+    aese           S2.16b,$1.16b
+    aesmc          S2.16b,S2.16b
+    aese           S3.16b,$1.16b
+    aesmc          S3.16b,S3.16b
+')
+
+C AES_LAST_ROUND_4B(KEY)
+define(`AES_LAST_ROUND_4B', m4_assert_numargs(1)`
+    aese           S0.16b,$1.16b
+    eor            S0.16b,S0.16b,K14.16b
+    aese           S1.16b,$1.16b
+    eor            S1.16b,S1.16b,K14.16b
+    aese           S2.16b,$1.16b
+    eor            S2.16b,S2.16b,K14.16b
+    aese           S3.16b,$1.16b
+    eor            S3.16b,S3.16b,K14.16b
+')
+
+C AES_ROUND_1B(KEY)
+define(`AES_ROUND_1B', m4_assert_numargs(1)`
+    aese           S0.16b,$1.16b
+    aesmc          S0.16b,S0.16b
+')
+
+C AES_LAST_ROUND_1B(KEY)
+define(`AES_LAST_ROUND_1B', m4_assert_numargs(1)`
+    aese           S0.16b,$1.16b
+    eor            S0.16b,S0.16b,K14.16b
+')
+
+C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+C       const struct aes_table *T,
+C       size_t length, uint8_t *dst,
+C       uint8_t *src)
+
+PROLOGUE(_nettle_aes_encrypt)
+    ands           x6,LENGTH,#-64
+    b.eq           L1B
+
+    mov            x7,KEYS
+    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x7],#64
+    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x7],#64
+    ld1            {K8.4s,K9.4s},[x7],#32
+    cmp            ROUNDS,#10
+    b.eq           L4B_last_key
+    ld1            {K10.4s,K11.4s},[x7],#32
+    cmp            ROUNDS,#12
+    b.eq           L4B_last_key
+    ld1            {K12.4s,K13.4s},[x7],#32
+
+L4B_last_key:
+    ld1            {K14.4s},[x7]
+
+L4B_loop:
+    ld1            {S0.16b,S1.16b,S2.16b,S3.16b},[SRC],#64
+
+    AES_ROUND_4B(K0)
+    AES_ROUND_4B(K1)
+    AES_ROUND_4B(K2)
+    AES_ROUND_4B(K3)
+    AES_ROUND_4B(K4)
+    AES_ROUND_4B(K5)
+    AES_ROUND_4B(K6)
+    AES_ROUND_4B(K7)
+    AES_ROUND_4B(K8)
+    cmp            ROUNDS,#10
+    b.eq           L4B_10_round
+    cmp            ROUNDS,#12
+    b.eq           L4B_12_round
+    b              L4B_14_round
+
+L4B_10_round:
+    AES_LAST_ROUND_4B(K9)
+    b              L4B_done
+L4B_12_round:
+    AES_ROUND_4B(K9)
+    AES_ROUND_4B(K10)
+    AES_LAST_ROUND_4B(K11)
+    b              L4B_done
+L4B_14_round:
+    AES_ROUND_4B(K9)
+    AES_ROUND_4B(K10)
+    AES_ROUND_4B(K11)
+    AES_ROUND_4B(K12)
+    AES_LAST_ROUND_4B(K13)
+
+L4B_done:
+    st1            {S0.16b,S1.16b,S2.16b,S3.16b},[DST],#64
+
+    subs           x6,x6,#64
+    b.ne           L4B_loop
+
+    and            LENGTH,LENGTH,#63
+
+L1B:
+    cbz            LENGTH,Ldone
+
+    mov            x6,KEYS
+    ld1            {K0.4s,K1.4s,K2.4s,K3.4s},[x6],#64
+    ld1            {K4.4s,K5.4s,K6.4s,K7.4s},[x6],#64
+    ld1            {K8.4s,K9.4s},[x6],#32
+    cmp            ROUNDS,#10
+    b.eq           L1B_last_key
+    ld1            {K10.4s,K11.4s},[x6],#32
+    cmp            ROUNDS,#12
+    b.eq           L1B_last_key
+    ld1            {K12.4s,K13.4s},[x6],#32
+
+L1B_last_key:
+    ld1            {K14.4s},[x6]
+
+L1B_loop:
+    ld1            {S0.16b},[SRC],#16
+
+    AES_ROUND_1B(K0)
+    AES_ROUND_1B(K1)
+    AES_ROUND_1B(K2)
+    AES_ROUND_1B(K3)
+    AES_ROUND_1B(K4)
+    AES_ROUND_1B(K5)
+    AES_ROUND_1B(K6)
+    AES_ROUND_1B(K7)
+    AES_ROUND_1B(K8)
+    cmp            ROUNDS,#10
+    b.eq           L1B_10_round
+    cmp            ROUNDS,#12
+    b.eq           L1B_12_round
+    b              L1B_14_round
+
+L1B_10_round:
+    AES_LAST_ROUND_1B(K9)
+    b              L1B_done
+L1B_12_round:
+    AES_ROUND_1B(K9)
+    AES_ROUND_1B(K10)
+    AES_LAST_ROUND_1B(K11)
+    b              L1B_done
+L1B_14_round:
+    AES_ROUND_1B(K9)
+    AES_ROUND_1B(K10)
+    AES_ROUND_1B(K11)
+    AES_ROUND_1B(K12)
+    AES_LAST_ROUND_1B(K13)
+
+L1B_done:
+    st1            {S0.16b},[DST],#16
+
+    subs           LENGTH,LENGTH,#16
+    b.ne           L1B_loop
+
+Ldone:
+    ret
+EPILOGUE(_nettle_aes_encrypt)

-- 
2.25.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210509175646</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-09 17:56:46-0400</timestampReceived><subject>Re: S390x other modes and memxor (was: Re: [S390x] Optimize AES modes)</subject><body>

On Sun, May 9, 2021 at 11:19 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Before doing the other modes, do you think you could investigate if
&gt; memxor and memxor3 can be sped up? That should benefit many ciphers
&gt; and modes, and give more relevant speedup numbers for specialized
&gt; functions like aes cbc and aes ctr.
&gt;
&gt; The best strategy depends on whether or not unaligned memory access is
&gt; possible and efficient. All current implementations do aligned writes to
&gt; the destination area (and smaller writes if needed at the edges). For the
&gt; C implementation and several of the asm implementations, they also do
&gt; aligned reads, and use shifting to get inputs xored together at the right
&gt; places.
&gt;
&gt; While the x86_64 implementation uses unaligned reads, since that seems
&gt; as efficient, and reduces complexity quite a lot.
&gt;
&gt; On all platforms I'm familiar with, assembly implementations can assume
&gt; that it is safe to read a few bytes outside the edge of the input
&gt; buffer, as long as those reads don't cross a word boundary
&gt; (corresponding to valgrind option --partial-loads-ok=yes).
&gt;
&gt; Ideally, memxor performance should be limited by memory/cache bandwidth
&gt; (with data in L1 cache probably being the most important case. It looks
&gt; like nettle-benchmark calls it with a size of 10 KB).
&gt;
&gt; Note that memxor3 must process data in descending address order, to
&gt; support the call from cbc_decrypt, with overlapping operands.
&gt;


This is great information that I can keep in my memory for next
implementations. s390x arch offers 'xc' instruction "Storage-to-storage
XOR" at maximum length of 256 bytes but we can do as many iterations as we
need. I optimized memxor using that instruction as it achieves the optimal
performance for such case, I'll attach the patch at the end of message.
Unfortunately, I couldn't manage to optimize memxor3 using 'xc' instruction
because while it supports the overlapped operands it processes them from
left to right, one byte at a time.
However, I think optimizing just memxor could make a good sense of how much
it would increase the performance of AES modes. CBC mode could come in
handy here since it uses memxor in encrypt and decrypt operations in case
the operands of decrypt operation don't overlap. Here is the benchmark
result of CBC mode:

*---------------------------------------------------------------------------------------------------*
|                                              AES-128 Encrypt | AES-128
Decrypt |
|------------------------------------------------------------------------|----------------------------|
| CBC-Accelerator                             1.18 cbp     |     0.75 cbp
        |
| Basic AES-Accelerator                    13.50 cbp   |     3.34 cbp
      |
| Basic AES-Accelerator with memxor 15.50         |     1.57
  |
*-----------------------------------------------------------------------------------------------------*

I can interpret the decrease in performance using optimized memxor by the
overhead caused by 'ex' instruction since "xor_len" macro patches the
length of 'xc' instruction then it fetches that instruction in memory in
order to execute it, that happens for every single block so it makes sense
to get more cycles per byte.
The decrypt operation is improved using optimized memxor but still with
CBC-accelerator it's almost twice the speed. The speed of encrypt operation
doesn't improve and TBH 15 cycles per byte are a lot of cycles for CBC mode
so we really need to consider the accelerators since it offers an optimal
performance for the architecture.

regards,
Mamone

---
 s390x/machine.m4 | 13 +++++++++++++
 s390x/memxor.asm | 54
++++++++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 67 insertions(+)
 create mode 100644 s390x/memxor.asm

diff --git a/s390x/machine.m4 b/s390x/machine.m4
index acd5e26c..b94c408a 100644
--- a/s390x/machine.m4
+++ b/s390x/machine.m4
@@ -1,2 +1,15 @@
 C Register usage:
 define(`RA', `%r14')
+
+C XOR contents of two areas in storage with specific length
+C len cannot be assigned to general register 0
+C len &lt;= 256
+C xor_len(dst, src, len, tmp_addr)
+define(`xor_len',
+`larl           $4,18f
+    aghi           $3,-1
+    jm             19f
+    ex             $3,0($4)
+    j              19f
+18: xc             0(1,$1),0($2)
+19:')
diff --git a/s390x/memxor.asm b/s390x/memxor.asm
new file mode 100644
index 00000000..178e68e9
--- /dev/null
+++ b/s390x/memxor.asm
@@ -0,0 +1,54 @@
+C s390/memxor.asm
+
+ifelse(`
+   Copyright (C) 2021 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+.file "memxor.asm"
+
+.text
+
+C void * memxor(void *dst, const void *src, size_t n)
+
+PROLOGUE(nettle_memxor)
+    lgr            %r0,%r2
+    srlg           %r5,%r4,8
+    clgije         %r5,0,Llen
+L256_loop:
+    xc             0(256,%r2),0(%r3)
+    aghi           %r2,256
+    aghi           %r3,256
+    brctg          %r5,L256_loop
+Llen:
+    risbg          %r5,%r4,56,191,0
+    jz             Ldone
+    xor_len(%r2,%r3,%r5,%r1)
+Ldone:
+    lgr            %r2,%r0
+    br             RA
+EPILOGUE(nettle_memxor)

-- 
2.25.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210710182955</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-10 18:29:55-0400</timestampReceived><subject>[S390x] Fat build support for AES and GHASH</subject><body>

I created a MR !31
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/31&gt; that adds
fat build support of AES and GHASH for S390x architecture. The MR's
description has a brief overview of the modifications done to add the fat
build support.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210717101346</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-17 10:13:46-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I created a MR !31
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/31&gt; that adds
&gt; fat build support of AES and GHASH for S390x architecture. The MR's
&gt; description has a brief overview of the modifications done to add the fat
&gt; build support.

Merged, thanks! I wrote some comments asking for two followup changes
(avoid inline asm, and setting of FAT_TEST_LIST).

Do you think we're getting ready to merge the s390x branch to master?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210721072812</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-21 07:28:12-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

On Sat, Jul 17, 2021 at 1:13 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I created a MR !31
&gt; &gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/31&gt; that adds
&gt; &gt; fat build support of AES and GHASH for S390x architecture. The MR's
&gt; &gt; description has a brief overview of the modifications done to add the fat
&gt; &gt; build support.
&gt;
&gt; Merged, thanks! I wrote some comments asking for two followup changes
&gt; (avoid inline asm, and setting of FAT_TEST_LIST).
&gt;
&gt; Do you think we're getting ready to merge the s390x branch to master?
&gt;

I've applied for your change requests. I think we're ready to merge the
s390x branch at this point, let me know if there are conflicts with the
master branch tho.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210721151154</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-21 15:11:54-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I've applied for your change requests. I think we're ready to merge the
&gt; s390x branch at this point, let me know if there are conflicts with the
&gt; master branch tho.

Fixes merged, thanks!. I'll try out merging the s390x branch into
master(-updates), to see if there are any difficulties.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210721153726</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-07-21 15:37:26-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

On Wed, Jul 21, 2021 at 6:11 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; I've applied for your change requests. I think we're ready to merge the
&gt; &gt; s390x branch at this point, let me know if there are conflicts with the
&gt; &gt; master branch tho.
&gt;
&gt; Fixes merged, thanks!. I'll try out merging the s390x branch into
&gt; master(-updates), to see if there are any difficulties.
&gt;

Great! I intend to push SHA and CBC optimizations of s390x architecture to
the s390x branch after being merged, it will be good to keep it in the
repository. We also need a new branch after the s390x branch is merged to
push AES optimizations of aarch64 into.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210607065928</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-06-07 06:59:28-0400</timestampReceived><subject>ANNOUNCE: Nettle-3.7.3</subject><body>

[Attachment #2 (multipart/signed)]


I've prepared a new bug-fix release of Nettle, a low-level
cryptographics library, to fix bugs in the RSA decryption functions. The
bugs cause crashes on certain invalid inputs, which could be used
for denial of service attacks on applications using these functions.
More details in NEWS file below.

Upgrading is strongly recommended.

The Nettle home page can be found at
https://www.lysator.liu.se/~nisse/nettle/, and the manual at
https://www.lysator.liu.se/~nisse/nettle/nettle.html.

The release can be downloaded from

  https://ftp.gnu.org/gnu/nettle/nettle-3.7.3.tar.gz
  ftp://ftp.gnu.org/gnu/nettle/nettle-3.7.3.tar.gz
  https://www.lysator.liu.se/~nisse/archive/nettle-3.7.3.tar.gz

Regards,
/Niels

NEWS for the Nettle 3.7.3 release

	This is bugfix release, fixing bugs that could make the RSA
	decryption functions crash on invalid inputs.

	Upgrading to the new version is strongly recommended. For
	applications that want to support older versions of Nettle,
	the bug can be worked around by adding a check that the RSA
	ciphertext is in the range 0 &lt; ciphertext &lt; n, before
	attempting to decrypt it.

	Thanks to Paul Schaub and Justus Winter for reporting these
	problems.

	The new version is intended to be fully source and binary
	compatible with Nettle-3.6. The shared library names are
	libnettle.so.8.4 and libhogweed.so.6.4, with sonames
	libnettle.so.8 and libhogweed.so.6.

	Bug fixes:

	* Fix crash for zero input to rsa_sec_decrypt and
	  rsa_decrypt_tr. Potential denial of service vector.

	* Ensure that all of rsa_decrypt_tr and rsa_sec_decrypt return
	  failure for out of range inputs, instead of either crashing,
	  or silently reducing input modulo n. Potential denial of
	  service vector.

	* Ensure that rsa_decrypt returns failure for out of range
	  inputs, instead of silently reducing input modulo n.

	* Ensure that rsa_sec_decrypt returns failure if the message
	  size is too large for the given key. Unlike the other bugs,
	  this would typically be triggered by invalid local
	  configuration, rather than by processing untrusted remote
	  data.

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.


["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210629140209</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-06-29 14:02:09-0400</timestampReceived><subject>[Aarch64] Fat build support for SHA1 compress</subject><body>

This patch added fat build support SHA1 compress function using the regular
HWCAP features.

---
 arm64/fat/sha1-compress-2.asm | 37 +++++++++++++++++++++++++++++++++++++
 fat-arm64.c                   | 32 ++++++++++++++++++++++++++++++--
 2 files changed, 67 insertions(+), 2 deletions(-)
 create mode 100644 arm64/fat/sha1-compress-2.asm

diff --git a/arm64/fat/sha1-compress-2.asm b/arm64/fat/sha1-compress-2.asm
new file mode 100644
index 00000000..b53cb63e
--- /dev/null
+++ b/arm64/fat/sha1-compress-2.asm
@@ -0,0 +1,37 @@
+C arm64/fat/sha1-compress-2.asm
+
+
+ifelse(`
+   Copyright (C) 2021 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+dnl PROLOGUE(nettle_sha1_compress) picked up by configure
+
+define(`fat_transform', `_$1_arm64')
+include_src(`arm64/crypto/sha1-compress.asm')
diff --git a/fat-arm64.c b/fat-arm64.c
index 9f81951f..c696e9bb 100644
--- a/fat-arm64.c
+++ b/fat-arm64.c
@@ -61,10 +61,14 @@
 #ifndef HWCAP_PMULL
 #define HWCAP_PMULL (1 &lt;&lt; 4)
 #endif
+#ifndef HWCAP_SHA1
+#define HWCAP_SHA1 (1 &lt;&lt; 5)
+#endif

 struct arm64_features
 {
   int have_pmull;
+  int have_sha1;
 };

 #define MATCH(s, slen, literal, llen) \
@@ -75,6 +79,7 @@ get_arm64_features (struct arm64_features *features)
 {
   const char *s;
   features-&gt;have_pmull = 0;
+  features-&gt;have_sha1 = 0;

   s = secure_getenv (ENV_OVERRIDE);
   if (s)
@@ -85,6 +90,8 @@ get_arm64_features (struct arm64_features *features)

  if (MATCH (s, length, "pmull", 5))
   features-&gt;have_pmull = 1;
+  else if (MATCH (s, length, "sha1", 4))
+  features-&gt;have_sha1 = 1;
  if (!sep)
   break;
  s = sep + 1;
@@ -95,6 +102,8 @@ get_arm64_features (struct arm64_features *features)
       unsigned long hwcap = getauxval(AT_HWCAP);
       features-&gt;have_pmull
  = ((hwcap &amp; (HWCAP_ASIMD | HWCAP_PMULL)) == (HWCAP_ASIMD | HWCAP_PMULL));
+      features-&gt;have_sha1
+ = ((hwcap &amp; (HWCAP_ASIMD | HWCAP_SHA1)) == (HWCAP_ASIMD | HWCAP_SHA1));
 #endif
     }
 }
@@ -109,6 +118,10 @@ DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, c)
 DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, arm64)
 #endif /* GCM_TABLE_BITS == 8 */

+DECLARE_FAT_FUNC(nettle_sha1_compress, sha1_compress_func)
+DECLARE_FAT_FUNC_VAR(sha1_compress, sha1_compress_func, c)
+DECLARE_FAT_FUNC_VAR(sha1_compress, sha1_compress_func, arm64)
+
 static void CONSTRUCTOR
 fat_init (void)
 {
@@ -119,8 +132,9 @@ fat_init (void)

   verbose = getenv (ENV_VERBOSE) != NULL;
   if (verbose)
-    fprintf (stderr, "libnettle: cpu features: %s\n",
-     features.have_pmull ? "polynomial multiply long instructions
(PMULL/PMULL2)" : "");
+    fprintf (stderr, "libnettle: cpu features:%s%s\n",
+     features.have_pmull ? " polynomial multiply long instructions
(PMULL/PMULL2)" : "",
+       features.have_sha1 ? " sha1 instructions" : "");

   if (features.have_pmull)
     {
@@ -142,6 +156,16 @@ fat_init (void)
       _nettle_gcm_hash_vec = _nettle_gcm_hash_c;
 #endif /* GCM_TABLE_BITS == 8 */
     }
+  if (features.have_sha1)
+    {
+      if (verbose)
+ fprintf (stderr, "libnettle: enabling hardware-accelerated sha1 compress
code.\n");
+      nettle_sha1_compress_vec = _nettle_sha1_compress_arm64;
+    }
+  else
+    {
+      nettle_sha1_compress_vec = _nettle_sha1_compress_c;
+    }
 }

 #if GCM_TABLE_BITS == 8
@@ -154,3 +178,7 @@ DEFINE_FAT_FUNC(_nettle_gcm_hash, void,
  size_t length, const uint8_t *data),
  (key, x, length, data))
 #endif /* GCM_TABLE_BITS == 8 */
+
+DEFINE_FAT_FUNC(nettle_sha1_compress, void,
+ (uint32_t *state, const uint8_t *input),
+ (state, input))

-- 
2.25.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210724125109</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-07-24 12:51:09-0400</timestampReceived><subject>Re: [S390x] Fat build support for AES and GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I've applied for your change requests. I think we're ready to merge the
&gt; s390x branch at this point, let me know if there are conflicts with the
&gt; master branch tho.

Merged to master branch now! Had to commit some minor fixes to make
"make dist" and the s390x ci build work, and added a brief ChangeLog
entry for latest additions.

For the memxor merge requests, it would be good to retarget to the
master branch (but I'm not sure how to do that in gitlab).

Regards,
/Niels

&gt; regards,
&gt; Mamone

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210509210545</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-09 21:05:45-0400</timestampReceived><subject>Re: S390x other modes and memxor</subject><body>

On Sun, May 9, 2021 at 9:49 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; This seems to confirm that cbc encrypt is the operation that gains the
&gt; most from assembly for the combined operation. That aes decrypt can also
&gt; gain a factor two in performance, does that mean that both aes-cbc and
&gt; memxor run at speed limited by memory bandwidth? And then the gain is
&gt; from one less pass loading and storing data from memory?
&gt;

I can't think of another reason.


&gt; What unit is "cbp"?
&gt;

Yes, Cycles per byte. I spelled it wrong in the last message.

If it's cycles per byte, 0.77 cycles/byte for memxor
&gt; (the cost of "Basic AES-Accelerator with memxor" minus cost of
&gt; CBC-Accellerator) sounds unexpectedly slow, compared to, e.g, x86_64,
&gt; where I get 0.08 cycles per byte (regardless of alignment), or 0.64
&gt; cycles per 64-bit word.
&gt;

I'm calculating cycles per byte as follows:
Frequency/(Buf_size/Elapsed_time); Units are Hz, Byte, Second respectively.
I measured the cycles per byte for memxor on z15 I got:
2.8 cpb for C implementation
0.9 cpb for optimized memxor
If my calculation is correct, then accessing memory in z/architecture
processors in a quit expensive comparing to other architectures.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210520195911</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-20 19:59:11-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

On Thu, May 20, 2021 at 10:06 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; "Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:
&gt;
&gt; &gt; So in total, if we assume an ideal (but impossible) zero-cost version
&gt; &gt; for memxor, memxor3, and gcm_fill and avoid permutes via ISA 3.0 vector
&gt; &gt; load/stores we can only account for 11.82 cycles/block; leaving 4.97
&gt; &gt; cycles/block as an additional benefit of the combined implementation.
&gt;
&gt; One hypothesis for that gain is that we can avoid storing the aes input
&gt; in memory at all; instead, generated the counter values on the fly in
&gt; the appropriate registers.
&gt;
&gt; &gt;&gt; Another potential overhead is that data is stored to memory when passed
&gt; &gt;&gt; between these functions. It seems we store a block 3 times, and loads a
&gt; &gt;&gt; block 4 times (the additional accesses should be cache friendly, but
&gt; &gt;&gt; wills till cost some execution resources). Optimizing that seems to need
&gt; &gt;&gt; some kind of combined function. But maybe it is sufficient to optimize
&gt; &gt;&gt; something a bit more general than aes gcm, e.g., aes ctr?
&gt; &gt;
&gt; &gt; This would basically have to replace the nettle_crypt16 function call
&gt; &gt; with arch-specific assembly, right? I can code this up and try it out in
&gt; &gt; the context of AES-GCM.
&gt;
&gt; Yes, something like that. If we leave the _nettle_gcm_hash unchanged
&gt; (with its own independent assembly implementation), and look at
&gt; gcm_encrypt, what we have is
&gt;
&gt;       const void *cipher, nettle_cipher_func *f,
&gt;
&gt;   _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
&gt;
&gt; It would be nice if we could replace that with a call to aes_ctr_crypt,
&gt; and then optimizing that would benefit both gcm and plain ctr. But it's
&gt; not quite that easy, because gcm unfortunately uses it's own variant of
&gt; ctr mode, which is why we need to pass the gcm_fill function in the
&gt; first place.
&gt;
&gt; So if we need separate assembly for aes_plain_ctr and aes_gcm_ctr (they
&gt; *might* still share some code, but they would be distinct entry points).
&gt; Say we call the gcm-specific ctr function from some variant of
&gt; gcm_encrypt via a different function pointer. Then that gcm_encrypt
&gt; variant is getting a bit pointless. Maybe it's better to do
&gt;
&gt;   void aes128_gcm_encrypt(...)
&gt;   {
&gt;     _nettle_aes128_gcm_ctr(...);
&gt;     _nettle_gcm_hash(...);
&gt;   }
&gt;
&gt; At least, we avoid duplicating the _gcm_hash for aes128, aes192, aes256
&gt; (and any other algorithms we might want to optimize in a similar way).
&gt; And each of the aes assembly routines should be fairly small and easy to
&gt; maintain.
&gt;

While writing the white paper "Optimize AES-GCM for PowerPC architecture
processors", I concluded that is the best approach to implement for PowerPC
architecture, easy to maintain, avoid duplication, and perform well.
I've separated aes_gcm encrypt/decrypt to two functions, aes_ctr and ghash.
Both implemented using Power ISA v3.00 assisted with vector-scalar
registers.
I got 1.18 cycles/byte for gcm-aes-128 encrypt/decrypt, 1.31 cycles/byte
for gcm-aes-192 encrypt/decrypt, and 1.44 cycles/byte for gcm-aes-256
encrypt/decrypt.

Still if there are additional vector registers, I would give the combined
function a shot as it eliminates loading the input message twice.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210522075810</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-22 07:58:10-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; We could either switch it on by default in configure.ac, or add a
&gt; configure flag in .gitlab-ci.

Just pushed a change to .gitlab-ci to pass --enable-s390x-msa, and it
seems to work, see

https://gitlab.com/gnutls/nettle/-/jobs/1284895250#L580

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210523093811</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-23 09:38:11-0400</timestampReceived><subject>Re: [Aarch64] Optimize SHA1 Compress</subject><body>

On Sun, May 23, 2021 at 10:52 AM Niels MÃ¶ller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; This patch optimizes SHA1 compress function for arm64 architecture by
&gt; &gt; taking advantage of SHA-1 instructions of Armv8 crypto extension.
&gt; &gt; The SHA-1 instructions:
&gt; &gt; SHA1C: SHA1 hash update (choose)
&gt; &gt; SHA1H: SHA1 fixed rotate
&gt; &gt; SHA1M: SHA1 hash update (majority)
&gt; &gt; SHA1P: SHA1 hash update (parity)
&gt; &gt; SHA1SU0: SHA1 schedule update 0
&gt; &gt; SHA1SU1: SHA1 schedule update 1
&gt;
&gt; Can you add this brief summary of instructions as a comment in the asm
&gt; file?
&gt;

Done! I'll attach a patch at the end of the message that performs slightly
better as well.

         Algorithm         mode Mbyte/s
              sha1       update  800.80
      openssl sha1       update  849.17
         hmac-sha1     64 bytes  166.10
         hmac-sha1    256 bytes  409.24
         hmac-sha1   1024 bytes  636.98
         hmac-sha1   4096 bytes  739.20
         hmac-sha1   single msg  775.67

&gt; Benchmark on gcc117 instance of CFarm before applying the patch:
&gt; &gt;          Algorithm         mode        Mbyte/s
&gt; &gt;          sha1               update       214.16
&gt; &gt;          openssl sha1  update       849.44
&gt;
&gt; &gt; Benchmark on gcc117 instance of CFarm after applying the patch:
&gt; &gt;          Algorithm         mode        Mbyte/s
&gt; &gt;          sha1                update       795.57
&gt; &gt;          openssl sha1   update       849.25
&gt;
&gt; Great speedup! Any idea why openssl is still slightly faster?
&gt;

Sure, OpenSSL implementation uses a loop inside SH1 update function which
eliminates the constant initialization and state loading/sotring for each
block while nettle does that for every block iteration.


&gt; &gt; +define(`TMP0', `v21')
&gt; &gt; +define(`TMP1', `v22')
&gt;
&gt; Not sure I understand how these are used, but it looks like the TMP
&gt; variables are used in some way for the message expansion state? E.g.,
&gt; TMP0 assigned in the code for rounds 0-3, and this value used in the
&gt; code for rounds 8-11. Other implementations don't need extra state for
&gt; this, but just modifies the 16 message words in-place.
&gt;

Modifying the message words in-place will change the value used by
'sha1su0' and 'sha1su1' instructions. According to ARM ® A64 Instruction Set
Architecture:
SHA1SU0 &lt;Vd&gt;.4S, &lt;Vn&gt;.4S, &lt;Vm&gt;.4S
&lt;Vd&gt; Is the name of the SIMD&amp;FP source and destination register
.
.

SHA1SU1 &lt;Vd&gt;.4S, &lt;Vn&gt;.4S
&lt;Vd&gt; Is the name of the SIMD&amp;FP source and destination register
.
.

So using TMP variable is necessary here. I can't think of any replacement,
let me know how the other implementations handle this case.

It would be nice to either make the TMP registers more temporary (i.e.,
&gt; no round depends on the value in these registers from previous rounds)
&gt; and keep needed state only on the MSG variables. Or rename them to give
&gt; a better hint on how they're used.
&gt;

Done! Yield a slight performance increase btw.


&gt; &gt; +C void nettle_sha1_compress(uint32_t *state, const uint8_t *input)
&gt; &gt; +
&gt; &gt; +PROLOGUE(nettle_sha1_compress)
&gt; &gt; +    C Initialize constants
&gt; &gt; +    mov            w2,#0x7999
&gt; &gt; +    movk           w2,#0x5A82,lsl #16
&gt; &gt; +    dup            CONST0.4s,w2
&gt; &gt; +    mov            w2,#0xEBA1
&gt; &gt; +    movk           w2,#0x6ED9,lsl #16
&gt; &gt; +    dup            CONST1.4s,w2
&gt; &gt; +    mov            w2,#0xBCDC
&gt; &gt; +    movk           w2,#0x8F1B,lsl #16
&gt; &gt; +    dup            CONST2.4s,w2
&gt; &gt; +    mov            w2,#0xC1D6
&gt; &gt; +    movk           w2,#0xCA62,lsl #16
&gt; &gt; +    dup            CONST3.4s,w2
&gt;
&gt; Maybe would be clearer or more efficient to load these from memory? Not
&gt; sure if there's an nice and consice way to load the four 32-bit values
&gt; into a 128-bit, and then copy/duplicate them into the four const
&gt; registers.
&gt;

We can load all the constants (including duplicate values) from memory with
one instruction. The issue is how to get the data address properly for
every supported abi! By far I saw solutions with multiple paths for
different abi which I don't really like, the easiest solution is to define
the data in the .text section to make sure the address is near enough to be
loaded with certain instruction. Do you want to do that?


&gt; &gt; +    C Load message
&gt; &gt; +    ld1            {MSG0.16b,MSG1.16b,MSG2.16b,MSG3.16b},[INPUT]
&gt; &gt; +
&gt; &gt; +    C Reverse for little endian
&gt; &gt; +    rev32          MSG0.16b,MSG0.16b
&gt; &gt; +    rev32          MSG1.16b,MSG1.16b
&gt; &gt; +    rev32          MSG2.16b,MSG2.16b
&gt; &gt; +    rev32          MSG3.16b,MSG3.16b
&gt;
&gt; How does this work on big-endian? The ld1 with .16b is endian-neutral
&gt; (according to the README), that means we always get the wrong order, and
&gt; then we do unconditional byteswapping? Maybe add a comment. Not sure if
&gt; it's worth the effort to make it work differently (ld1 .4w on
&gt; big-endian)? It's going to be a pretty small fraction of the per-block
&gt; processing.
&gt;

 We have an intensive discussion about that in the GCM patch. The short
story, this patch should work well for both endianness modes. However, it's
not the same way we use in GCM patch to handle the endianness variation, to
follow GCM patch way we can do:

    C Load message
    ld1            {MSG0.4s,MSG1.4s,MSG2.4s,MSG3.4s},[INPUT]

    C Reverse for little endian
IF_LE(`
    rev32          MSG0.16b,MSG0.16b
    rev32          MSG1.16b,MSG1.16b
    rev32          MSG2.16b,MSG2.16b
    rev32          MSG3.16b,MSG3.16b
')

regards,
Mamone

---
 arm64/crypto/sha1-compress.asm | 93
+++++++++++++++++++++++-------------------
 1 file changed, 50 insertions(+), 43 deletions(-)

diff --git a/arm64/crypto/sha1-compress.asm b/arm64/crypto/sha1-compress.asm
index f261c93d..9f7d9f37 100644
--- a/arm64/crypto/sha1-compress.asm
+++ b/arm64/crypto/sha1-compress.asm
@@ -30,6 +30,15 @@ ifelse(`
    not, see http://www.gnu.org/licenses/.
 ')

+C This implementation uses the SHA-1 instructions of Armv8 crypto
+C extension.
+C SHA1C: SHA1 hash update (choose)
+C SHA1H: SHA1 fixed rotate
+C SHA1M: SHA1 hash update (majority)
+C SHA1P: SHA1 hash update (parity)
+C SHA1SU0: SHA1 schedule update 0
+C SHA1SU1: SHA1 schedule update 1
+
 .file "sha1-compress.asm"
 .arch armv8-a+crypto

@@ -53,8 +62,7 @@ define(`ABCD_SAVED', `v17')
 define(`E0', `v18')
 define(`E0_SAVED', `v19')
 define(`E1', `v20')
-define(`TMP0', `v21')
-define(`TMP1', `v22')
+define(`TMP', `v21')

 C void nettle_sha1_compress(uint32_t *state, const uint8_t *input)

@@ -92,140 +100,139 @@ PROLOGUE(nettle_sha1_compress)
     rev32          MSG2.16b,MSG2.16b
     rev32          MSG3.16b,MSG3.16b

-    add            TMP0.4s,MSG0.4s,CONST0.4s
-    add            TMP1.4s,MSG1.4s,CONST0.4s
-
     C Rounds 0-3
+    add            TMP.4s,MSG0.4s,CONST0.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG2.4s,CONST0.4s
+    sha1c          QFP(ABCD),SFP(E0),TMP.4s
     sha1su0        MSG0.4s,MSG1.4s,MSG2.4s

     C Rounds 4-7
+    add            TMP.4s,MSG1.4s,CONST0.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG3.4s,CONST0.4s
+    sha1c          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG0.4s,MSG3.4s
     sha1su0        MSG1.4s,MSG2.4s,MSG3.4s

     C Rounds 8-11
+    add            TMP.4s,MSG2.4s,CONST0.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG0.4s,CONST0.4s
+    sha1c          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG1.4s,MSG0.4s
     sha1su0        MSG2.4s,MSG3.4s,MSG0.4s

     C Rounds 12-15
+    add            TMP.4s,MSG3.4s,CONST0.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1c          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG1.4s,CONST1.4s
+    sha1c          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG2.4s,MSG1.4s
     sha1su0        MSG3.4s,MSG0.4s,MSG1.4s

     C Rounds 16-19
+    add            TMP.4s,MSG0.4s,CONST0.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1c          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG2.4s,CONST1.4s
+    sha1c          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG3.4s,MSG2.4s
     sha1su0        MSG0.4s,MSG1.4s,MSG2.4s

     C Rounds 20-23
+    add            TMP.4s,MSG1.4s,CONST1.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG3.4s,CONST1.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG0.4s,MSG3.4s
     sha1su0        MSG1.4s,MSG2.4s,MSG3.4s

     C Rounds 24-27
+    add            TMP.4s,MSG2.4s,CONST1.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG0.4s,CONST1.4s
+    sha1p          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG1.4s,MSG0.4s
     sha1su0        MSG2.4s,MSG3.4s,MSG0.4s

     C Rounds 28-31
+    add            TMP.4s,MSG3.4s,CONST1.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG1.4s,CONST1.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG2.4s,MSG1.4s
     sha1su0        MSG3.4s,MSG0.4s,MSG1.4s

     C Rounds 32-35
+    add            TMP.4s,MSG0.4s,CONST1.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG2.4s,CONST2.4s
+    sha1p          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG3.4s,MSG2.4s
     sha1su0        MSG0.4s,MSG1.4s,MSG2.4s

     C Rounds 36-39
+    add            TMP.4s,MSG1.4s,CONST1.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG3.4s,CONST2.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG0.4s,MSG3.4s
     sha1su0        MSG1.4s,MSG2.4s,MSG3.4s

     C Rounds 40-43
+    add            TMP.4s,MSG2.4s,CONST2.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG0.4s,CONST2.4s
+    sha1m          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG1.4s,MSG0.4s
     sha1su0        MSG2.4s,MSG3.4s,MSG0.4s

     C Rounds 44-47
+    add            TMP.4s,MSG3.4s,CONST2.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG1.4s,CONST2.4s
+    sha1m          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG2.4s,MSG1.4s
     sha1su0        MSG3.4s,MSG0.4s,MSG1.4s

     C Rounds 48-51
+    add            TMP.4s,MSG0.4s,CONST2.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG2.4s,CONST2.4s
+    sha1m          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG3.4s,MSG2.4s
     sha1su0        MSG0.4s,MSG1.4s,MSG2.4s

     C Rounds 52-55
+    add            TMP.4s,MSG1.4s,CONST2.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1m          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG3.4s,CONST3.4s
+    sha1m          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG0.4s,MSG3.4s
     sha1su0        MSG1.4s,MSG2.4s,MSG3.4s

     C Rounds 56-59
+    add            TMP.4s,MSG2.4s,CONST2.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1m          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG0.4s,CONST3.4s
+    sha1m          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG1.4s,MSG0.4s
     sha1su0        MSG2.4s,MSG3.4s,MSG0.4s

     C Rounds 60-63
+    add            TMP.4s,MSG3.4s,CONST3.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG1.4s,CONST3.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG2.4s,MSG1.4s
     sha1su0        MSG3.4s,MSG0.4s,MSG1.4s

     C Rounds 64-67
+    add            TMP.4s,MSG0.4s,CONST3.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
-    add            TMP0.4s,MSG2.4s,CONST3.4s
+    sha1p          QFP(ABCD),SFP(E0),TMP.4s
     sha1su1        MSG3.4s,MSG2.4s
     sha1su0        MSG0.4s,MSG1.4s,MSG2.4s

     C Rounds 68-71
+    add            TMP.4s,MSG1.4s,CONST3.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
-    add            TMP1.4s,MSG3.4s,CONST3.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s
     sha1su1        MSG0.4s,MSG3.4s

     C Rounds 72-75
+    add            TMP.4s,MSG2.4s,CONST3.4s
     sha1h          SFP(E1),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E0),TMP0.4s
+    sha1p          QFP(ABCD),SFP(E0),TMP.4s

     C Rounds 76-79
+    add            TMP.4s,MSG3.4s,CONST3.4s
     sha1h          SFP(E0),SFP(ABCD)
-    sha1p          QFP(ABCD),SFP(E1),TMP1.4s
+    sha1p          QFP(ABCD),SFP(E1),TMP.4s

     C Combine state
     add            E0.4s,E0.4s,E0_SAVED.4s

-- 
2.25.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210523194036</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-23 19:40:36-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I've added test cases to verify that unwrap fail if the input values
&gt; are incorrect [1]. I reuse all the unwrap test cases, changed one
&gt; ciphertext byte and expect the unwrap function to return 0.

I've merged the latest version of
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19 to the
master-updates branch, with some minor changes (moved function typedefs
out of nettle-types.h, and indentation fixes to nist-keywrap.h.

Thanks for your contribution and patience.

&gt;&gt; Or possibly under "7.3 Cipher modes", if it's too different from the
&gt;&gt; AEAD constructions.
&gt;&gt;
&gt; Until we come to a solution on where to put the documentation, I've
&gt; started a first draft for the documentation. Can you give me feedback
&gt; on it?

I think putting it under cipher modes probably makes the most sense.

The function reference looks good, it doesn't have to be a lot of text.
Please spell "cipher" consistently, not "cypher".

In the introduction, you write "Its intention is to provide an algorithm
to wrap and unwrap cryptographic keys.". Is it possible to give a bit
more details, some guidance on when it is a good idea to use this key
wrapping rather than a more general AEAD algorithm? If there's some
interesting background, or examples of protocols that use aes keywrap,
that could also go here.

I think it would also be nice to clarify that the spec defines the key
wrapping as an aes-specific mode, but Nettle's implementation supports
any block cipher with a block size of 16 bytes.

&gt; Also, I've never used LaTex. What tool do you recommend to write LaTex
&gt; documentation? I've tried gummi but it says there are errors in the
&gt; nettle.texinfo file...

Texinfo is not quite the same as LaTeX, even if it uses the same TeX
machinery for the typeset pdf version.

Manual is here:
https://www.gnu.org/software/texinfo/manual/texinfo/texinfo.html, but I
think you can mostly go by the examples elsewhere in the Nettle manual,
and check the docs only for the markup you need. You probably need to
grasp the @node thing, though. See
https://www.gnu.org/software/texinfo/manual/texinfo/texinfo.html#Writing-a-Node
(the nettle manual uses the old-fashined way with explicit node links).

I edit it in emacs, like any other file.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061512</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:12-0400</timestampReceived><subject>[RFC PATCH 1/6] gcm: Introduce gcm_aes_{de,en}crypt()</subject><body>

Currently the AES-GCM crypt and hash parts are performed in two separate
functions. Each can be replaced with an arch-specific optimized assembly
routine. This makes it difficult to introduce an arch-specific routine
implementing the combination of both parts in a single function.

Rework the existing gcm_{en,de}crypt() functions to instead call a new
gcm_aes_{en,de}crypt_wrap() function which calls out to a (for now) stub
gcm_aes_{en,de}crypt(). This stub can be then overriden either via FAT
or statically during build.

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 configure.ac |   8 ++-
 gcm.c        | 147 +++++++++++++++++++++++++++++++++++++++++++++++++--
 2 files changed, 149 insertions(+), 6 deletions(-)

diff --git a/configure.ac b/configure.ac
index 026ae99d..ba85a313 100644
--- a/configure.ac
+++ b/configure.ac
@@ -538,7 +538,7 @@ asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   salsa20-2core.asm salsa20-core-internal-2.asm \
   sha1-compress-2.asm sha256-compress-2.asm \
   sha3-permute-2.asm sha512-compress-2.asm \
-  umac-nh-n-2.asm umac-nh-2.asm"
+  umac-nh-n-2.asm umac-nh-2.asm gcm-aes-encrypt.asm gcm-aes-decrypt.asm"
 
 asm_hogweed_optional_list=""
 if test "x$enable_public_key" = "xyes" ; then
@@ -674,7 +674,11 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_sha512_compress
 #undef HAVE_NATIVE_sha3_permute
 #undef HAVE_NATIVE_umac_nh
-#undef HAVE_NATIVE_umac_nh_n])
+#undef HAVE_NATIVE_umac_nh_n
+#undef HAVE_NATIVE_gcm_aes_decrypt
+#undef HAVE_NATIVE_gcm_aes_encrypt
+#undef HAVE_NATIVE_fat_gcm_aes_decrypt
+#undef HAVE_NATIVE_fat_gcm_aes_encrypt])
 
 if test "x$enable_pic" = xyes; then
     LSH_CCPIC
diff --git a/gcm.c b/gcm.c
index d1f21d3a..6fe25a01 100644
--- a/gcm.c
+++ b/gcm.c
@@ -423,28 +423,167 @@ gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
 }
 #endif
 
+enum gcm_aes_rounds {
+    NOT_AES = 0,
+    AES_128 = _AES128_ROUNDS,
+    AES_192 = _AES192_ROUNDS,
+    AES_256 = _AES256_ROUNDS
+};
+
+static enum gcm_aes_rounds
+_nettle_gcm_get_aes_rounds(nettle_cipher_func *f)
+{
+  if (f == (nettle_cipher_func *)nettle_aes128_encrypt ||
+      f == (nettle_cipher_func *)nettle_aes128_decrypt)
+    {
+      return AES_128;
+    }
+  else if (f == (nettle_cipher_func *)nettle_aes192_encrypt ||
+	   f == (nettle_cipher_func *)nettle_aes192_decrypt)
+    {
+      return AES_192;
+    }
+  else if (f == (nettle_cipher_func *)nettle_aes256_encrypt ||
+	   f == (nettle_cipher_func *)nettle_aes256_decrypt)
+    {
+      return AES_256;
+    }
+  else
+    {
+      return NOT_AES;
+    }
+}
+
+#if !HAVE_NATIVE_gcm_aes_encrypt
+# if !HAVE_NATIVE_fat_gcm_aes_encrypt
+#   define _nettle_gcm_aes_encrypt _nettle_gcm_aes_encrypt_c
+static
+#endif /* !HAVE_NATIVE_fat_gcm_aes_encrypt */
+int
+_nettle_gcm_aes_encrypt_c (const struct gcm_key *key, union nettle_block16 *x,
+			   size_t length, const uint8_t *src, unsigned rounds,
+			   const uint32_t *keys, uint8_t *dst, uint8_t* ctr)
+{
+  (void)key;
+  (void)x;
+  (void)length;
+  (void)src;
+  (void)rounds;
+  (void)keys;
+  (void)dst;
+  (void)ctr;
+
+  return -1; /* Not implemented */
+}
+#endif /* !HAVE_NATIVE_gcm_aes_encrypt */
+
+static int
+_nettle_gcm_aes_encrypt_wrap (struct gcm_ctx *ctx, const struct gcm_key *key,
+			      const void *cipher, size_t length, uint8_t *dst,
+			      const uint8_t *src, enum gcm_aes_rounds rounds)
+{
+  switch (rounds) {
+    default:
+      abort();
+    case AES_128:
+      return _nettle_gcm_aes_encrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes128_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+    case AES_192:
+      return _nettle_gcm_aes_encrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes192_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+    case AES_256:
+      return _nettle_gcm_aes_encrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes256_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+  }
+}
+
 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
 	     const void *cipher, nettle_cipher_func *f,
 	     size_t length, uint8_t *dst, const uint8_t *src)
 {
+  enum gcm_aes_rounds rounds;
   assert(ctx-&gt;data_size % GCM_BLOCK_SIZE == 0);
 
-  _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
-  _nettle_gcm_hash(key, &amp;ctx-&gt;x, length, dst);
+  rounds = _nettle_gcm_get_aes_rounds(f);
+
+  if (rounds == NOT_AES ||
+      _nettle_gcm_aes_encrypt_wrap(ctx, key, cipher, length,
+				   dst, src, rounds) == -1)
+    {
+      _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
+      _nettle_gcm_hash(key, &amp;ctx-&gt;x, length, dst);
+    }
 
   ctx-&gt;data_size += length;
 }
 
+#if !HAVE_NATIVE_gcm_aes_decrypt
+# if !HAVE_NATIVE_fat_gcm_aes_decrypt
+#   define _nettle_gcm_aes_decrypt _nettle_gcm_aes_decrypt_c
+static
+#endif /* !HAVE_NATIVE_fat_gcm_aes_decrypt */
+int
+_nettle_gcm_aes_decrypt_c (const struct gcm_key *key, union nettle_block16 *x,
+			   size_t length, const uint8_t *src, unsigned rounds,
+			   const uint32_t *keys, uint8_t *dst, uint8_t *ctr)
+{
+  (void)key;
+  (void)x;
+  (void)length;
+  (void)src;
+  (void)rounds;
+  (void)keys;
+  (void)dst;
+  (void)ctr;
+
+  return -1; /* Not implemented */
+}
+#endif /* !HAVE_NATIVE_gcm_aes_decrypt */
+
+static int
+_nettle_gcm_aes_decrypt_wrap (struct gcm_ctx *ctx, const struct gcm_key *key,
+			      const void *cipher, size_t length, uint8_t *dst,
+			      const uint8_t *src, enum gcm_aes_rounds rounds)
+{
+  switch (rounds) {
+    default:
+      abort();
+    case AES_128:
+      return _nettle_gcm_aes_decrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes128_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+    case AES_192:
+      return _nettle_gcm_aes_decrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes192_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+    case AES_256:
+      return _nettle_gcm_aes_decrypt(key, &amp;ctx-&gt;x, length, src, rounds,
+				     ((struct aes256_ctx*)cipher)-&gt;keys, dst,
+				     ctx-&gt;ctr.b);
+  }
+}
+
 void
 gcm_decrypt(struct gcm_ctx *ctx, const struct gcm_key *key,
 	    const void *cipher, nettle_cipher_func *f,
 	    size_t length, uint8_t *dst, const uint8_t *src)
 {
+  enum gcm_aes_rounds rounds;
   assert(ctx-&gt;data_size % GCM_BLOCK_SIZE == 0);
 
-  _nettle_gcm_hash(key, &amp;ctx-&gt;x, length, src);
-  _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
+  rounds = _nettle_gcm_get_aes_rounds(f);
+
+  if (rounds == NOT_AES ||
+      _nettle_gcm_aes_decrypt_wrap(ctx, key, cipher, length,
+				   dst, src, rounds) == -1)
+    {
+      _nettle_gcm_hash(key, &amp;ctx-&gt;x, length, src);
+      _nettle_ctr_crypt16(cipher, f, gcm_fill, ctx-&gt;ctr.b, length, dst, src);
+    }
 
   ctx-&gt;data_size += length;
 }
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061513</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:13-0400</timestampReceived><subject>[RFC PATCH 2/6] ppc: Fix variable name for --enable-power-altivec</subject><body>

The AC_ARG_ENABLE(...) macro for --enable-power-altivec is called with
enable_altivec=no as the default when the commandline option is not
given to configure. However, the variable $enable_power_altivec is
actually checked - not $enable_altivec. This doesn't matter in practice
since $enable_power_altivec remains unset and the check works as
expected when the commandline option is absent. Fix it anyways for
consistency with the other arguments.

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 configure.ac | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/configure.ac b/configure.ac
index ba85a313..253735a7 100644
--- a/configure.ac
+++ b/configure.ac
@@ -99,7 +99,7 @@ AC_ARG_ENABLE(power-crypto-ext,
 
 AC_ARG_ENABLE(power-altivec,
   AC_HELP_STRING([--enable-power-altivec], [Enable POWER altivec and vsx extensions. (default=no)]),,
-  [enable_altivec=no])
+  [enable_power_altivec=no])
 
 AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of libgmp.]),,
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210509184935</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-09 18:49:35-0400</timestampReceived><subject>Re: S390x other modes and memxor</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This is great information that I can keep in my memory for next
&gt; implementations. s390x arch offers 'xc' instruction "Storage-to-storage
&gt; XOR" at maximum length of 256 bytes but we can do as many iterations as we
&gt; need. I optimized memxor using that instruction as it achieves the optimal
&gt; performance for such case, I'll attach the patch at the end of
&gt; message.

Nice! I'd like to merge this as soon as the s390x ci is up and running
again.

&gt; Unfortunately, I couldn't manage to optimize memxor3 using 'xc' instruction
&gt; because while it supports the overlapped operands it processes them from
&gt; left to right, one byte at a time.

Hmm, I wonder if there's some way to work around that.

&gt; However, I think optimizing just memxor could make a good sense of how much
&gt; it would increase the performance of AES modes. CBC mode could come in
&gt; handy here since it uses memxor in encrypt and decrypt operations in case
&gt; the operands of decrypt operation don't overlap. Here is the benchmark
&gt; result of CBC mode:
&gt;
&gt; *---------------------------------------------------------------------------------------------------*
&gt; |                                              AES-128 Encrypt | AES-128
&gt; Decrypt |
&gt; |------------------------------------------------------------------------|----------------------------|
&gt; | CBC-Accelerator                             1.18 cbp     |     0.75 cbp
&gt;         |
&gt; | Basic AES-Accelerator                    13.50 cbp   |     3.34 cbp
&gt;       |
&gt; | Basic AES-Accelerator with memxor 15.50         |     1.57
&gt;   |
&gt; *-----------------------------------------------------------------------------------------------------*

This seems to confirm that cbc encrypt is the operation that gains the
most from assembly for the combined operation. That aes decrypt can also
gain a factor two in performance, does that mean that both aes-cbc and
memxor run at speed limited by memory bandwidth? And then the gain is
from one less pass loading and storing data from memory?

What unit is "cbp"? If it's cycles per byte, 0.77 cycles/byte for memxor
(the cost of "Basic AES-Accelerator with memxor" minus cost of
CBC-Accellerator) sounds unexpectedly slow, compared to, e.g, x86_64,
where I get 0.08 cycles per byte (regardless of alignment), or 0.64
cycles per 64-bit word.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203185934</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-02-03 18:59:34-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, Feb 3, 2021 at 11:13 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; Thanks for setting this up.  The default accounts have a limited time
&gt; &gt; (90 days?).  For long-term CI access, I can help request a long-term
&gt; &gt; account for Nettle.
&gt;
&gt; That would be helpful.
&gt;
&gt; I've had look at the terms and conditions,
&gt; http://security.marist.edu/LinuxOne/TC.PDF. Most of it looks very
&gt; reasonable, but there are a few items that I find a bit unclear:
&gt;
&gt; 9. [...] You agree to obey all relevant New York State and US laws,
&gt;    including all export controls laws.
&gt;
&gt; My understanding is that US export control laws don't apply to FOSS
&gt; software (and that's why, e.g., Debian no longer have special non-us
&gt; mirrors for distributing cryptographic software). But I don't know the
&gt; details, and if there really isn't a problem, why is it mentioned
&gt; explicitly in the terms and conditions?

I am not a lawyer and cannot give legal advice about any of this.  I
also cannot speak officially for IBM or Marist about the terms and
conditions of agreements.

This hasn't been a problem for other Open Source projects, including
Open Source cryptographic libraries.

You're not hosting development of the library in the U.S. nor
distributing the library from the U.S., so you would seem to be
obeying New York State and US laws.  The U.S. does not restrict
importation of cryptographic software.  Downloading the library or
repo into the system at Marist to run testing or CI is considered
importing.


&gt;
&gt; 10 [...] d. To protect your LinuxOne Account, keep your Secure Shell
&gt;    (SSH) keys confidential. You are responsible for the activity that
&gt;    happens on or through your LinuxOne Account.
&gt;
&gt; Is it acceptable under these terms if I upload a private key to a CI
&gt; config that is part of the gnutls project hosted on gitlab.com?
&gt; Maamoun's suggested method was to add it as a "Variable" in the CI/CD
&gt; web config, I'm assuming that will not make it publicly visible (but I'd
&gt; need to double check).

The item is not specifying how you handle the security and
confidentiality of your keys, only that you are responsible for
activity on your LinuxONE s390x instance.  The intention is that you
not email spam or hack other systems or run Bitcoin miners from your
account, and make a reasonable effort that malicious parties cannot
break into your LinuxONE instance to do similar bad things.

&gt;
&gt; I don't know precisely which individuals will get access to use the key
&gt; (and hence my account) if I do that, even though I expect it to be small
&gt; number of good people (admins of the gnutls project, and the key will
&gt; also be technically accessible by gitlab staff).
&gt;
&gt;    [...] Do not reuse your LinuxOne Account keys on third-party
&gt;    applications.
&gt;
&gt; I also don't understand what "third-party applications" means in this
&gt; context, but I'd guess gitlab could be one?

Again, I interpret this as basic key security: don't reuse keys or
passwords on multiple accounts where a compromise of one account would
allow an attacker to compromise other accounts, including the LinuxONE
system.  It didn't say that you couldn't use it, it said don't REuse
it, such as, don't use the same key for LinuxONE and AWS and wherever
else you run CI.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210302022757</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-02 02:27:57-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

I managed to get the tarball approach working in gitlab ci with the
following steps:

- In gitlab go to settings -&gt; CI / CD. Expand Variables and add the
following variables:

   - S390X_SSH_IP_ADDRESS: username@instance_ip
   - S390X_SSH_PRIVATE_KEY: private key of ssh connection
   - S390X_SSH_CI_DIRECTORY: name of directory in remote server where the
   tarball is extracted and tested

- Update gitlab-ci.yml as follows:

   - Add this line to variables category at the top of file:

  DEBIAN_BUILD: buildenv-debian

   - Add these lines to the end of file

Debian.remote.s390x:
  image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$DEBIAN_BUILD
  before_script:
  - apt-get update -qq
  - apt-get install -qq git
  - 'which ssh-agent || ( apt-get install -qq openssh-client )'
  - eval $(ssh-agent -s)
  - ssh-add &lt;(echo "$S390X_SSH_PRIVATE_KEY")
  - mkdir -p ~/.ssh
  - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" &gt; ~/.ssh/config
  - ssh $S390X_SSH_IP_ADDRESS "mkdir -p
$S390X_SSH_CI_DIRECTORY/$CI_PIPELINE_IID"
  script:
  - tar --exclude=.git --exclude=gitlab-ci.yml -cf - . | ssh
$S390X_SSH_IP_ADDRESS "cd $S390X_SSH_CI_DIRECTORY/$CI_PIPELINE_IID &amp;&amp; tar
-xf - &amp;&amp;
    ./.bootstrap &amp;&amp; ./configure --disable-documentation &amp;&amp; make &amp;&amp; make
check"
  after_script:
  - eval $(ssh-agent -s)
  - ssh-add &lt;(echo "$S390X_SSH_PRIVATE_KEY")
  - ssh $S390X_SSH_IP_ADDRESS "rm -rf
$S390X_SSH_CI_DIRECTORY/$CI_PIPELINE_IID/ &amp;&amp; exit"
  only:
    variables:
    - $S390X_SSH_IP_ADDRESS
    - $S390X_SSH_PRIVATE_KEY
    - $S390X_SSH_CI_DIRECTORY
  tags:
  - shared
  - linux
  except:
  - tags

This approach archives the repo files and extracts the tar in remote server
in order to be built and tested. It creates a directory with a unique name
in the remote server for every pipeline, also if one of the required
variables is not present (defined) the job is not created, with that said
fresh forks wouldn't have s390x job unless they define the s390x specific
variables.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210324185238</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-24 18:52:38-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I managed to get the tarball approach working in gitlab ci with the
&gt; following steps:

Thanks for the research. I've added a test job based on these ideas. See
https://git.lysator.liu.se/nettle/nettle/-/commit/c25774e230985a625fa5112f3f19e03302e49e7f.
An almost identical setup was run successfully as
https://gitlab.com/gnutls/nettle/-/jobs/1125145345.

&gt; - In gitlab go to settings -&gt; CI / CD. Expand Variables and add the
&gt; following variables:
&gt;
&gt;    - S390X_SSH_IP_ADDRESS: username@instance_ip
&gt;    - S390X_SSH_PRIVATE_KEY: private key of ssh connection
&gt;    - S390X_SSH_CI_DIRECTORY: name of directory in remote server where the
&gt;    tarball is extracted and tested

I made only the private key a variable (and of type "file", which means
it's stored in a temporary file, with file name in $SSH_PRIVATE_KEY).
The others are defined in the .gitlab-ci.yml file.

&gt; - Update gitlab-ci.yml as follows:
&gt;
&gt;    - Add this line to variables category at the top of file:
&gt;
&gt;   DEBIAN_BUILD: buildenv-debian

I used the same fedora image as for the simpler build jobs.

&gt;   script:
&gt;   - tar --exclude=.git --exclude=gitlab-ci.yml -cf - . | ssh
&gt; $S390X_SSH_IP_ADDRESS "cd $S390X_SSH_CI_DIRECTORY/$CI_PIPELINE_IID &amp;&amp; tar
&gt; -xf - &amp;&amp;

I'm using ./configure &amp;&amp; make dist instead, then we get a bit testing of
that too. On the remote side, directory name is based on
$CI_PIPELINE_IID, that seems to be a good way to get one directory per job.

&gt;   only:
&gt;     variables:
&gt;     - $S390X_SSH_IP_ADDRESS
&gt;     - $S390X_SSH_PRIVATE_KEY
&gt;     - $S390X_SSH_CI_DIRECTORY

What does this mean? Ah, it excludes the job if these variables aren't
set?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325183819</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-25 18:38:19-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, Mar 24, 2021 at 8:52 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;    - S390X_SSH_IP_ADDRESS: username@instance_ip
&gt; &gt;    - S390X_SSH_PRIVATE_KEY: private key of ssh connection
&gt; &gt;    - S390X_SSH_CI_DIRECTORY: name of directory in remote server where the
&gt; &gt;    tarball is extracted and tested
&gt;
&gt; I made only the private key a variable (and of type "file", which means
&gt; it's stored in a temporary file, with file name in $SSH_PRIVATE_KEY).
&gt; The others are defined in the .gitlab-ci.yml file.
&gt;

Isn't it better to define S390X_SSH_IP_ADDRESS variable rather than
hard-code the remote server address in .gitlab-ci.yml? fresh forks now need
to update .gitlab-ci.yml to get a S390x job which is a bit unwieldy in my
opinion.


&gt; &gt; - Update gitlab-ci.yml as follows:
&gt; &gt;
&gt; &gt;    - Add this line to variables category at the top of file:
&gt; &gt;
&gt; &gt;   DEBIAN_BUILD: buildenv-debian
&gt;
&gt; I used the same fedora image as for the simpler build jobs.
&gt;

Good.


&gt; &gt;   only:
&gt; &gt;     variables:
&gt; &gt;     - $S390X_SSH_IP_ADDRESS
&gt; &gt;     - $S390X_SSH_PRIVATE_KEY
&gt; &gt;     - $S390X_SSH_CI_DIRECTORY
&gt;
&gt; What does this mean? Ah, it excludes the job if these variables aren't
&gt; set?
&gt;

Yes, this is what it does according to gitlab ci docs
&lt;https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic&gt;. otherwise, fresh
forks will have always-unsuccessful job.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210327070710</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-27 07:07:10-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Isn't it better to define S390X_SSH_IP_ADDRESS variable rather than
&gt; hard-code the remote server address in .gitlab-ci.yml? fresh forks now need
&gt; to update .gitlab-ci.yml to get a S390x job which is a bit unwieldy in my
&gt; opinion.

Makes sense. I've added it as a variable, and renamed to S390X_ACCOUNT.
Value is of the form username@ip-address.

&gt; Yes, this is what it does according to gitlab ci docs
&gt; &lt;https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic&gt;. otherwise, fresh
&gt; forks will have always-unsuccessful job.

Ok, added a section

  only:
    variables:
    - $SSH_PRIVATE_KEY
    - $S390X_ACCOUNT

Still on the master-updates branch, will merge as soon as the run looks
green.

Regards,
/Nies

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210327073756</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-27 07:37:56-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; &gt;   only:
&gt;&gt; &gt;     variables:
&gt;&gt; &gt;     - $S390X_SSH_IP_ADDRESS
&gt;&gt; &gt;     - $S390X_SSH_PRIVATE_KEY
&gt;&gt; &gt;     - $S390X_SSH_CI_DIRECTORY
&gt;&gt;
&gt;&gt; What does this mean? Ah, it excludes the job if these variables aren't
&gt;&gt; set?
&gt;&gt;
&gt;
&gt; Yes, this is what it does according to gitlab ci docs
&gt; &lt;https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic&gt;. otherwise, fresh
&gt; forks will have always-unsuccessful job.

Hmm, docs aren't quite clear, but it doesn't seem to work as is. I
accidentally set the new S390X_ACCOUNT varable to "protected", and then
the job was started but with $S390X_ACCOUNT expanding to the empty
string, and failing.. Perhaps
it needs to be written as

  - $FOO != ""

instead?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210327093531</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-27 09:35:31-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sat, Mar 27, 2021 at 9:37 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt;&gt; &gt;   only:
&gt; &gt;&gt; &gt;     variables:
&gt; &gt;&gt; &gt;     - $S390X_SSH_IP_ADDRESS
&gt; &gt;&gt; &gt;     - $S390X_SSH_PRIVATE_KEY
&gt; &gt;&gt; &gt;     - $S390X_SSH_CI_DIRECTORY
&gt; &gt;&gt;
&gt; &gt;&gt; What does this mean? Ah, it excludes the job if these variables aren't
&gt; &gt;&gt; set?
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Yes, this is what it does according to gitlab ci docs
&gt; &gt; &lt;https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic&gt;. otherwise, fresh
&gt; &gt; forks will have always-unsuccessful job.
&gt;
&gt; Hmm, docs aren't quite clear, but it doesn't seem to work as is. I
&gt; accidentally set the new S390X_ACCOUNT varable to "protected", and then
&gt; the job was started but with $S390X_ACCOUNT expanding to the empty
&gt; string, and failing.. Perhaps
&gt; it needs to be written as
&gt;
&gt;   - $FOO != ""
&gt;
&gt; instead?
&gt;


This doc
&lt;https://docs.gitlab.com/ee/ci/variables/#syntax-of-cicd-variable-expressions&gt;
looks more clear, according to this doc we check variable presence
correctly, it checks if the variable is defined and non-empty. I think it's
some sort of bug.
However, you can try $S390X_ACCOUNT != null which just checks if the
variable is defined.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328190422</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-28 19:04:22-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Now that testing is up, we can return to the code.

I'd prefer to do things incrementally. I've created a branch "s390x",
with basic configure setup and the README file from your merge request.

Next, I think it makes sense to start with adding the basic aes
functions. From a quick look at the MR, it seems the aes instructions
don't want any explicit key schedule with expanded subkeys, but wants
the raw key? Same for encrypt and decrypt?

It would make sense to me with one file each under s390x/msa_x1 for
the functions being replaced, but then the current aes-encrypt.c would
also need to be split accordingly.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328202830</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-28 20:28:30-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sun, Mar 28, 2021 at 9:04 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Next, I think it makes sense to start with adding the basic aes
&gt; functions.


I'll prepare a MR for the basic aes functions to the s390x branch.


&gt; From a quick look at the MR, it seems the aes instructions
&gt; don't want any explicit key schedule with expanded subkeys, but wants
&gt; the raw key? Same for encrypt and decrypt?
&gt;

Correct, both encrypt and decrypt operations just need the raw key, the key
schedule is executed internally.


&gt; It would make sense to me with one file each under s390x/msa_x1 for
&gt; the functions being replaced, but then the current aes-encrypt.c would
&gt; also need to be split accordingly.
&gt;

Splitting key functions and ciphering functions for the basic AES
implementation is reasonable but splitting encrypting and decrypting
functions are a lot of files considering how many functions are implemented
for S390x arch. I don't get why aes-encrypt.c need to be split accordingly
tho, I think it would work just fine.

Regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210330181928</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-30 18:19:28-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sun, Mar 28, 2021 at 10:28 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I'll prepare a MR for the basic aes functions to the s390x branch.
&gt;

 I made a MR that implements the AES-128 set key functions and the basic
AES-128 functions for S390x architecture (one file for each).

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210331191844</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-31 19:18:44-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Splitting key functions and ciphering functions for the basic AES
&gt; implementation is reasonable but splitting encrypting and decrypting
&gt; functions are a lot of files considering how many functions are implemented
&gt; for S390x arch. I don't get why aes-encrypt.c need to be split accordingly
&gt; tho, I think it would work just fine.

Also discussed on the MR. The reason it makes sense to me to split
aes-encrypt.c, is that:

  (i) It's more consistent with the other aes-related functions. 

 (ii) The current aes-encrypt.c contains both the encryption functions
      aes128_encrypt, aes192_encrypt, aes256_encrypt, which we'd want to
      override with assembly implementations, and the legacy wrapper
      function aes_encrypt, which shouldn't be overridden. So we can't
      use plain file-level override, but need #ifdefs too.

(iii) I've considered doing it earlier, to make it easier to implement
      aes without a round loop (like for all current versions of
      aes-encrypt-internal.*). E.g., on x86_64, for aes128 we could load
      all subkeys into registers and still have registers left to do two
      or more blocks in parallel, but then we'd need to override
      aes128_encrypt separately from the other aes*_encrypt.

I've tried out a split, see below patch. It's a rather large change,
moving pieces to new places, but nothing difficult. I'm considering
committing this to the s390x branch, what do you think?

Regarding the large number of functions for s390x, I'm not yet convinced
we should have all of them, we'll have to consider the tradeoff between
speedup and complexity case by case. In particular, cbc encrypt (but not
decrypt!) is notoriously slow, since it's inherently serial. So I'm
curious about potential speedup there. Before getting too far, it may
also be worthwhile to try out an assembly memxor.

diff --git a/Makefile.in b/Makefile.in
index 868afdd7..8d474d1e 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -74,8 +74,10 @@ dvi installcheck uninstallcheck:
 
 all-here: $(TARGETS) $(DOCTARGETS)
 
-nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
+nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
+		 aes128-decrypt.c aes192-decrypt.c aes256-decrypt.c \
 		 aes-encrypt-internal.c aes-encrypt.c aes-encrypt-table.c \
+		 aes128-encrypt.c aes192-encrypt.c aes256-encrypt.c \
 		 aes-invert-internal.c aes-set-key-internal.c \
 		 aes-set-encrypt-key.c aes-set-decrypt-key.c \
 		 aes128-set-encrypt-key.c aes128-set-decrypt-key.c \
diff --git a/aes-decrypt-table.c b/aes-decrypt-table.c
new file mode 100644
index 00000000..301020ee
--- /dev/null
+++ b/aes-decrypt-table.c
@@ -0,0 +1,345 @@
+/* aes-decrypt-table.c
+
+   Decryption function for aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;stdlib.h&gt;
+
+#include "aes-internal.h"
+
+const struct aes_table
+_nettle_aes_decrypt_table =
+  { /* isbox */
+    {
+      0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38,
+      0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb,
+      0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87,
+      0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb,
+      0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d,
+      0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e,
+      0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2,
+      0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25,
+      0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16,
+      0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92,
+      0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda,
+      0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84,
+      0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a,
+      0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06,
+      0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02,
+      0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b,
+      0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea,
+      0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73,
+      0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85,
+      0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e,
+      0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89,
+      0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b,
+      0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20,
+      0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4,
+      0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31,
+      0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f,
+      0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d,
+      0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef,
+      0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0,
+      0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61,
+      0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26,
+      0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d,
+    },
+    { /* itable */
+      {
+	0x50a7f451,0x5365417e,0xc3a4171a,0x965e273a,
+	0xcb6bab3b,0xf1459d1f,0xab58faac,0x9303e34b,
+	0x55fa3020,0xf66d76ad,0x9176cc88,0x254c02f5,
+	0xfcd7e54f,0xd7cb2ac5,0x80443526,0x8fa362b5,
+	0x495ab1de,0x671bba25,0x980eea45,0xe1c0fe5d,
+	0x02752fc3,0x12f04c81,0xa397468d,0xc6f9d36b,
+	0xe75f8f03,0x959c9215,0xeb7a6dbf,0xda595295,
+	0x2d83bed4,0xd3217458,0x2969e049,0x44c8c98e,
+	0x6a89c275,0x78798ef4,0x6b3e5899,0xdd71b927,
+	0xb64fe1be,0x17ad88f0,0x66ac20c9,0xb43ace7d,
+	0x184adf63,0x82311ae5,0x60335197,0x457f5362,
+	0xe07764b1,0x84ae6bbb,0x1ca081fe,0x942b08f9,
+	0x58684870,0x19fd458f,0x876cde94,0xb7f87b52,
+	0x23d373ab,0xe2024b72,0x578f1fe3,0x2aab5566,
+	0x0728ebb2,0x03c2b52f,0x9a7bc586,0xa50837d3,
+	0xf2872830,0xb2a5bf23,0xba6a0302,0x5c8216ed,
+	0x2b1ccf8a,0x92b479a7,0xf0f207f3,0xa1e2694e,
+	0xcdf4da65,0xd5be0506,0x1f6234d1,0x8afea6c4,
+	0x9d532e34,0xa055f3a2,0x32e18a05,0x75ebf6a4,
+	0x39ec830b,0xaaef6040,0x069f715e,0x51106ebd,
+	0xf98a213e,0x3d06dd96,0xae053edd,0x46bde64d,
+	0xb58d5491,0x055dc471,0x6fd40604,0xff155060,
+	0x24fb9819,0x97e9bdd6,0xcc434089,0x779ed967,
+	0xbd42e8b0,0x888b8907,0x385b19e7,0xdbeec879,
+	0x470a7ca1,0xe90f427c,0xc91e84f8,0x00000000,
+	0x83868009,0x48ed2b32,0xac70111e,0x4e725a6c,
+	0xfbff0efd,0x5638850f,0x1ed5ae3d,0x27392d36,
+	0x64d90f0a,0x21a65c68,0xd1545b9b,0x3a2e3624,
+	0xb1670a0c,0x0fe75793,0xd296eeb4,0x9e919b1b,
+	0x4fc5c080,0xa220dc61,0x694b775a,0x161a121c,
+	0x0aba93e2,0xe52aa0c0,0x43e0223c,0x1d171b12,
+	0x0b0d090e,0xadc78bf2,0xb9a8b62d,0xc8a91e14,
+	0x8519f157,0x4c0775af,0xbbdd99ee,0xfd607fa3,
+	0x9f2601f7,0xbcf5725c,0xc53b6644,0x347efb5b,
+	0x7629438b,0xdcc623cb,0x68fcedb6,0x63f1e4b8,
+	0xcadc31d7,0x10856342,0x40229713,0x2011c684,
+	0x7d244a85,0xf83dbbd2,0x1132f9ae,0x6da129c7,
+	0x4b2f9e1d,0xf330b2dc,0xec52860d,0xd0e3c177,
+	0x6c16b32b,0x99b970a9,0xfa489411,0x2264e947,
+	0xc48cfca8,0x1a3ff0a0,0xd82c7d56,0xef903322,
+	0xc74e4987,0xc1d138d9,0xfea2ca8c,0x360bd498,
+	0xcf81f5a6,0x28de7aa5,0x268eb7da,0xa4bfad3f,
+	0xe49d3a2c,0x0d927850,0x9bcc5f6a,0x62467e54,
+	0xc2138df6,0xe8b8d890,0x5ef7392e,0xf5afc382,
+	0xbe805d9f,0x7c93d069,0xa92dd56f,0xb31225cf,
+	0x3b99acc8,0xa77d1810,0x6e639ce8,0x7bbb3bdb,
+	0x097826cd,0xf418596e,0x01b79aec,0xa89a4f83,
+	0x656e95e6,0x7ee6ffaa,0x08cfbc21,0xe6e815ef,
+	0xd99be7ba,0xce366f4a,0xd4099fea,0xd67cb029,
+	0xafb2a431,0x31233f2a,0x3094a5c6,0xc066a235,
+	0x37bc4e74,0xa6ca82fc,0xb0d090e0,0x15d8a733,
+	0x4a9804f1,0xf7daec41,0x0e50cd7f,0x2ff69117,
+	0x8dd64d76,0x4db0ef43,0x544daacc,0xdf0496e4,
+	0xe3b5d19e,0x1b886a4c,0xb81f2cc1,0x7f516546,
+	0x04ea5e9d,0x5d358c01,0x737487fa,0x2e410bfb,
+	0x5a1d67b3,0x52d2db92,0x335610e9,0x1347d66d,
+	0x8c61d79a,0x7a0ca137,0x8e14f859,0x893c13eb,
+	0xee27a9ce,0x35c961b7,0xede51ce1,0x3cb1477a,
+	0x59dfd29c,0x3f73f255,0x79ce1418,0xbf37c773,
+	0xeacdf753,0x5baafd5f,0x146f3ddf,0x86db4478,
+	0x81f3afca,0x3ec468b9,0x2c342438,0x5f40a3c2,
+	0x72c31d16,0x0c25e2bc,0x8b493c28,0x41950dff,
+	0x7101a839,0xdeb30c08,0x9ce4b4d8,0x90c15664,
+	0x6184cb7b,0x70b632d5,0x745c6c48,0x4257b8d0,
+      },
+#if !AES_SMALL
+      { /* Before: itable[1] */
+	0xa7f45150,0x65417e53,0xa4171ac3,0x5e273a96,
+	0x6bab3bcb,0x459d1ff1,0x58faacab,0x03e34b93,
+	0xfa302055,0x6d76adf6,0x76cc8891,0x4c02f525,
+	0xd7e54ffc,0xcb2ac5d7,0x44352680,0xa362b58f,
+	0x5ab1de49,0x1bba2567,0x0eea4598,0xc0fe5de1,
+	0x752fc302,0xf04c8112,0x97468da3,0xf9d36bc6,
+	0x5f8f03e7,0x9c921595,0x7a6dbfeb,0x595295da,
+	0x83bed42d,0x217458d3,0x69e04929,0xc8c98e44,
+	0x89c2756a,0x798ef478,0x3e58996b,0x71b927dd,
+	0x4fe1beb6,0xad88f017,0xac20c966,0x3ace7db4,
+	0x4adf6318,0x311ae582,0x33519760,0x7f536245,
+	0x7764b1e0,0xae6bbb84,0xa081fe1c,0x2b08f994,
+	0x68487058,0xfd458f19,0x6cde9487,0xf87b52b7,
+	0xd373ab23,0x024b72e2,0x8f1fe357,0xab55662a,
+	0x28ebb207,0xc2b52f03,0x7bc5869a,0x0837d3a5,
+	0x872830f2,0xa5bf23b2,0x6a0302ba,0x8216ed5c,
+	0x1ccf8a2b,0xb479a792,0xf207f3f0,0xe2694ea1,
+	0xf4da65cd,0xbe0506d5,0x6234d11f,0xfea6c48a,
+	0x532e349d,0x55f3a2a0,0xe18a0532,0xebf6a475,
+	0xec830b39,0xef6040aa,0x9f715e06,0x106ebd51,
+	0x8a213ef9,0x06dd963d,0x053eddae,0xbde64d46,
+	0x8d5491b5,0x5dc47105,0xd406046f,0x155060ff,
+	0xfb981924,0xe9bdd697,0x434089cc,0x9ed96777,
+	0x42e8b0bd,0x8b890788,0x5b19e738,0xeec879db,
+	0x0a7ca147,0x0f427ce9,0x1e84f8c9,0x00000000,
+	0x86800983,0xed2b3248,0x70111eac,0x725a6c4e,
+	0xff0efdfb,0x38850f56,0xd5ae3d1e,0x392d3627,
+	0xd90f0a64,0xa65c6821,0x545b9bd1,0x2e36243a,
+	0x670a0cb1,0xe757930f,0x96eeb4d2,0x919b1b9e,
+	0xc5c0804f,0x20dc61a2,0x4b775a69,0x1a121c16,
+	0xba93e20a,0x2aa0c0e5,0xe0223c43,0x171b121d,
+	0x0d090e0b,0xc78bf2ad,0xa8b62db9,0xa91e14c8,
+	0x19f15785,0x0775af4c,0xdd99eebb,0x607fa3fd,
+	0x2601f79f,0xf5725cbc,0x3b6644c5,0x7efb5b34,
+	0x29438b76,0xc623cbdc,0xfcedb668,0xf1e4b863,
+	0xdc31d7ca,0x85634210,0x22971340,0x11c68420,
+	0x244a857d,0x3dbbd2f8,0x32f9ae11,0xa129c76d,
+	0x2f9e1d4b,0x30b2dcf3,0x52860dec,0xe3c177d0,
+	0x16b32b6c,0xb970a999,0x489411fa,0x64e94722,
+	0x8cfca8c4,0x3ff0a01a,0x2c7d56d8,0x903322ef,
+	0x4e4987c7,0xd138d9c1,0xa2ca8cfe,0x0bd49836,
+	0x81f5a6cf,0xde7aa528,0x8eb7da26,0xbfad3fa4,
+	0x9d3a2ce4,0x9278500d,0xcc5f6a9b,0x467e5462,
+	0x138df6c2,0xb8d890e8,0xf7392e5e,0xafc382f5,
+	0x805d9fbe,0x93d0697c,0x2dd56fa9,0x1225cfb3,
+	0x99acc83b,0x7d1810a7,0x639ce86e,0xbb3bdb7b,
+	0x7826cd09,0x18596ef4,0xb79aec01,0x9a4f83a8,
+	0x6e95e665,0xe6ffaa7e,0xcfbc2108,0xe815efe6,
+	0x9be7bad9,0x366f4ace,0x099fead4,0x7cb029d6,
+	0xb2a431af,0x233f2a31,0x94a5c630,0x66a235c0,
+	0xbc4e7437,0xca82fca6,0xd090e0b0,0xd8a73315,
+	0x9804f14a,0xdaec41f7,0x50cd7f0e,0xf691172f,
+	0xd64d768d,0xb0ef434d,0x4daacc54,0x0496e4df,
+	0xb5d19ee3,0x886a4c1b,0x1f2cc1b8,0x5165467f,
+	0xea5e9d04,0x358c015d,0x7487fa73,0x410bfb2e,
+	0x1d67b35a,0xd2db9252,0x5610e933,0x47d66d13,
+	0x61d79a8c,0x0ca1377a,0x14f8598e,0x3c13eb89,
+	0x27a9ceee,0xc961b735,0xe51ce1ed,0xb1477a3c,
+	0xdfd29c59,0x73f2553f,0xce141879,0x37c773bf,
+	0xcdf753ea,0xaafd5f5b,0x6f3ddf14,0xdb447886,
+	0xf3afca81,0xc468b93e,0x3424382c,0x40a3c25f,
+	0xc31d1672,0x25e2bc0c,0x493c288b,0x950dff41,
+	0x01a83971,0xb30c08de,0xe4b4d89c,0xc1566490,
+	0x84cb7b61,0xb632d570,0x5c6c4874,0x57b8d042,
+      },{ /* Before: itable[2] */
+	0xf45150a7,0x417e5365,0x171ac3a4,0x273a965e,
+	0xab3bcb6b,0x9d1ff145,0xfaacab58,0xe34b9303,
+	0x302055fa,0x76adf66d,0xcc889176,0x02f5254c,
+	0xe54ffcd7,0x2ac5d7cb,0x35268044,0x62b58fa3,
+	0xb1de495a,0xba25671b,0xea45980e,0xfe5de1c0,
+	0x2fc30275,0x4c8112f0,0x468da397,0xd36bc6f9,
+	0x8f03e75f,0x9215959c,0x6dbfeb7a,0x5295da59,
+	0xbed42d83,0x7458d321,0xe0492969,0xc98e44c8,
+	0xc2756a89,0x8ef47879,0x58996b3e,0xb927dd71,
+	0xe1beb64f,0x88f017ad,0x20c966ac,0xce7db43a,
+	0xdf63184a,0x1ae58231,0x51976033,0x5362457f,
+	0x64b1e077,0x6bbb84ae,0x81fe1ca0,0x08f9942b,
+	0x48705868,0x458f19fd,0xde94876c,0x7b52b7f8,
+	0x73ab23d3,0x4b72e202,0x1fe3578f,0x55662aab,
+	0xebb20728,0xb52f03c2,0xc5869a7b,0x37d3a508,
+	0x2830f287,0xbf23b2a5,0x0302ba6a,0x16ed5c82,
+	0xcf8a2b1c,0x79a792b4,0x07f3f0f2,0x694ea1e2,
+	0xda65cdf4,0x0506d5be,0x34d11f62,0xa6c48afe,
+	0x2e349d53,0xf3a2a055,0x8a0532e1,0xf6a475eb,
+	0x830b39ec,0x6040aaef,0x715e069f,0x6ebd5110,
+	0x213ef98a,0xdd963d06,0x3eddae05,0xe64d46bd,
+	0x5491b58d,0xc471055d,0x06046fd4,0x5060ff15,
+	0x981924fb,0xbdd697e9,0x4089cc43,0xd967779e,
+	0xe8b0bd42,0x8907888b,0x19e7385b,0xc879dbee,
+	0x7ca1470a,0x427ce90f,0x84f8c91e,0x00000000,
+	0x80098386,0x2b3248ed,0x111eac70,0x5a6c4e72,
+	0x0efdfbff,0x850f5638,0xae3d1ed5,0x2d362739,
+	0x0f0a64d9,0x5c6821a6,0x5b9bd154,0x36243a2e,
+	0x0a0cb167,0x57930fe7,0xeeb4d296,0x9b1b9e91,
+	0xc0804fc5,0xdc61a220,0x775a694b,0x121c161a,
+	0x93e20aba,0xa0c0e52a,0x223c43e0,0x1b121d17,
+	0x090e0b0d,0x8bf2adc7,0xb62db9a8,0x1e14c8a9,
+	0xf1578519,0x75af4c07,0x99eebbdd,0x7fa3fd60,
+	0x01f79f26,0x725cbcf5,0x6644c53b,0xfb5b347e,
+	0x438b7629,0x23cbdcc6,0xedb668fc,0xe4b863f1,
+	0x31d7cadc,0x63421085,0x97134022,0xc6842011,
+	0x4a857d24,0xbbd2f83d,0xf9ae1132,0x29c76da1,
+	0x9e1d4b2f,0xb2dcf330,0x860dec52,0xc177d0e3,
+	0xb32b6c16,0x70a999b9,0x9411fa48,0xe9472264,
+	0xfca8c48c,0xf0a01a3f,0x7d56d82c,0x3322ef90,
+	0x4987c74e,0x38d9c1d1,0xca8cfea2,0xd498360b,
+	0xf5a6cf81,0x7aa528de,0xb7da268e,0xad3fa4bf,
+	0x3a2ce49d,0x78500d92,0x5f6a9bcc,0x7e546246,
+	0x8df6c213,0xd890e8b8,0x392e5ef7,0xc382f5af,
+	0x5d9fbe80,0xd0697c93,0xd56fa92d,0x25cfb312,
+	0xacc83b99,0x1810a77d,0x9ce86e63,0x3bdb7bbb,
+	0x26cd0978,0x596ef418,0x9aec01b7,0x4f83a89a,
+	0x95e6656e,0xffaa7ee6,0xbc2108cf,0x15efe6e8,
+	0xe7bad99b,0x6f4ace36,0x9fead409,0xb029d67c,
+	0xa431afb2,0x3f2a3123,0xa5c63094,0xa235c066,
+	0x4e7437bc,0x82fca6ca,0x90e0b0d0,0xa73315d8,
+	0x04f14a98,0xec41f7da,0xcd7f0e50,0x91172ff6,
+	0x4d768dd6,0xef434db0,0xaacc544d,0x96e4df04,
+	0xd19ee3b5,0x6a4c1b88,0x2cc1b81f,0x65467f51,
+	0x5e9d04ea,0x8c015d35,0x87fa7374,0x0bfb2e41,
+	0x67b35a1d,0xdb9252d2,0x10e93356,0xd66d1347,
+	0xd79a8c61,0xa1377a0c,0xf8598e14,0x13eb893c,
+	0xa9ceee27,0x61b735c9,0x1ce1ede5,0x477a3cb1,
+	0xd29c59df,0xf2553f73,0x141879ce,0xc773bf37,
+	0xf753eacd,0xfd5f5baa,0x3ddf146f,0x447886db,
+	0xafca81f3,0x68b93ec4,0x24382c34,0xa3c25f40,
+	0x1d1672c3,0xe2bc0c25,0x3c288b49,0x0dff4195,
+	0xa8397101,0x0c08deb3,0xb4d89ce4,0x566490c1,
+	0xcb7b6184,0x32d570b6,0x6c48745c,0xb8d04257,
+      },{ /* Before: itable[3] */
+	0x5150a7f4,0x7e536541,0x1ac3a417,0x3a965e27,
+	0x3bcb6bab,0x1ff1459d,0xacab58fa,0x4b9303e3,
+	0x2055fa30,0xadf66d76,0x889176cc,0xf5254c02,
+	0x4ffcd7e5,0xc5d7cb2a,0x26804435,0xb58fa362,
+	0xde495ab1,0x25671bba,0x45980eea,0x5de1c0fe,
+	0xc302752f,0x8112f04c,0x8da39746,0x6bc6f9d3,
+	0x03e75f8f,0x15959c92,0xbfeb7a6d,0x95da5952,
+	0xd42d83be,0x58d32174,0x492969e0,0x8e44c8c9,
+	0x756a89c2,0xf478798e,0x996b3e58,0x27dd71b9,
+	0xbeb64fe1,0xf017ad88,0xc966ac20,0x7db43ace,
+	0x63184adf,0xe582311a,0x97603351,0x62457f53,
+	0xb1e07764,0xbb84ae6b,0xfe1ca081,0xf9942b08,
+	0x70586848,0x8f19fd45,0x94876cde,0x52b7f87b,
+	0xab23d373,0x72e2024b,0xe3578f1f,0x662aab55,
+	0xb20728eb,0x2f03c2b5,0x869a7bc5,0xd3a50837,
+	0x30f28728,0x23b2a5bf,0x02ba6a03,0xed5c8216,
+	0x8a2b1ccf,0xa792b479,0xf3f0f207,0x4ea1e269,
+	0x65cdf4da,0x06d5be05,0xd11f6234,0xc48afea6,
+	0x349d532e,0xa2a055f3,0x0532e18a,0xa475ebf6,
+	0x0b39ec83,0x40aaef60,0x5e069f71,0xbd51106e,
+	0x3ef98a21,0x963d06dd,0xddae053e,0x4d46bde6,
+	0x91b58d54,0x71055dc4,0x046fd406,0x60ff1550,
+	0x1924fb98,0xd697e9bd,0x89cc4340,0x67779ed9,
+	0xb0bd42e8,0x07888b89,0xe7385b19,0x79dbeec8,
+	0xa1470a7c,0x7ce90f42,0xf8c91e84,0x00000000,
+	0x09838680,0x3248ed2b,0x1eac7011,0x6c4e725a,
+	0xfdfbff0e,0x0f563885,0x3d1ed5ae,0x3627392d,
+	0x0a64d90f,0x6821a65c,0x9bd1545b,0x243a2e36,
+	0x0cb1670a,0x930fe757,0xb4d296ee,0x1b9e919b,
+	0x804fc5c0,0x61a220dc,0x5a694b77,0x1c161a12,
+	0xe20aba93,0xc0e52aa0,0x3c43e022,0x121d171b,
+	0x0e0b0d09,0xf2adc78b,0x2db9a8b6,0x14c8a91e,
+	0x578519f1,0xaf4c0775,0xeebbdd99,0xa3fd607f,
+	0xf79f2601,0x5cbcf572,0x44c53b66,0x5b347efb,
+	0x8b762943,0xcbdcc623,0xb668fced,0xb863f1e4,
+	0xd7cadc31,0x42108563,0x13402297,0x842011c6,
+	0x857d244a,0xd2f83dbb,0xae1132f9,0xc76da129,
+	0x1d4b2f9e,0xdcf330b2,0x0dec5286,0x77d0e3c1,
+	0x2b6c16b3,0xa999b970,0x11fa4894,0x472264e9,
+	0xa8c48cfc,0xa01a3ff0,0x56d82c7d,0x22ef9033,
+	0x87c74e49,0xd9c1d138,0x8cfea2ca,0x98360bd4,
+	0xa6cf81f5,0xa528de7a,0xda268eb7,0x3fa4bfad,
+	0x2ce49d3a,0x500d9278,0x6a9bcc5f,0x5462467e,
+	0xf6c2138d,0x90e8b8d8,0x2e5ef739,0x82f5afc3,
+	0x9fbe805d,0x697c93d0,0x6fa92dd5,0xcfb31225,
+	0xc83b99ac,0x10a77d18,0xe86e639c,0xdb7bbb3b,
+	0xcd097826,0x6ef41859,0xec01b79a,0x83a89a4f,
+	0xe6656e95,0xaa7ee6ff,0x2108cfbc,0xefe6e815,
+	0xbad99be7,0x4ace366f,0xead4099f,0x29d67cb0,
+	0x31afb2a4,0x2a31233f,0xc63094a5,0x35c066a2,
+	0x7437bc4e,0xfca6ca82,0xe0b0d090,0x3315d8a7,
+	0xf14a9804,0x41f7daec,0x7f0e50cd,0x172ff691,
+	0x768dd64d,0x434db0ef,0xcc544daa,0xe4df0496,
+	0x9ee3b5d1,0x4c1b886a,0xc1b81f2c,0x467f5165,
+	0x9d04ea5e,0x015d358c,0xfa737487,0xfb2e410b,
+	0xb35a1d67,0x9252d2db,0xe9335610,0x6d1347d6,
+	0x9a8c61d7,0x377a0ca1,0x598e14f8,0xeb893c13,
+	0xceee27a9,0xb735c961,0xe1ede51c,0x7a3cb147,
+	0x9c59dfd2,0x553f73f2,0x1879ce14,0x73bf37c7,
+	0x53eacdf7,0x5f5baafd,0xdf146f3d,0x7886db44,
+	0xca81f3af,0xb93ec468,0x382c3424,0xc25f40a3,
+	0x1672c31d,0xbc0c25e2,0x288b493c,0xff41950d,
+	0x397101a8,0x08deb30c,0xd89ce4b4,0x6490c156,
+	0x7b6184cb,0xd570b632,0x48745c6c,0xd04257b8,
+      },
+#endif /* !AES_SMALL */
+    }
+  };
diff --git a/aes-decrypt.c b/aes-decrypt.c
index 1c22bfbb..6b007121 100644
--- a/aes-decrypt.c
+++ b/aes-decrypt.c
@@ -35,316 +35,10 @@
 # include "config.h"
 #endif
 
-#include &lt;assert.h&gt;
 #include &lt;stdlib.h&gt;
 
 #include "aes-internal.h"
 
-static const struct aes_table
-_aes_decrypt_table =
-  { /* isbox */
-    {
-      0x52,0x09,0x6a,0xd5,0x30,0x36,0xa5,0x38,
-      0xbf,0x40,0xa3,0x9e,0x81,0xf3,0xd7,0xfb,
-      0x7c,0xe3,0x39,0x82,0x9b,0x2f,0xff,0x87,
-      0x34,0x8e,0x43,0x44,0xc4,0xde,0xe9,0xcb,
-      0x54,0x7b,0x94,0x32,0xa6,0xc2,0x23,0x3d,
-      0xee,0x4c,0x95,0x0b,0x42,0xfa,0xc3,0x4e,
-      0x08,0x2e,0xa1,0x66,0x28,0xd9,0x24,0xb2,
-      0x76,0x5b,0xa2,0x49,0x6d,0x8b,0xd1,0x25,
-      0x72,0xf8,0xf6,0x64,0x86,0x68,0x98,0x16,
-      0xd4,0xa4,0x5c,0xcc,0x5d,0x65,0xb6,0x92,
-      0x6c,0x70,0x48,0x50,0xfd,0xed,0xb9,0xda,
-      0x5e,0x15,0x46,0x57,0xa7,0x8d,0x9d,0x84,
-      0x90,0xd8,0xab,0x00,0x8c,0xbc,0xd3,0x0a,
-      0xf7,0xe4,0x58,0x05,0xb8,0xb3,0x45,0x06,
-      0xd0,0x2c,0x1e,0x8f,0xca,0x3f,0x0f,0x02,
-      0xc1,0xaf,0xbd,0x03,0x01,0x13,0x8a,0x6b,
-      0x3a,0x91,0x11,0x41,0x4f,0x67,0xdc,0xea,
-      0x97,0xf2,0xcf,0xce,0xf0,0xb4,0xe6,0x73,
-      0x96,0xac,0x74,0x22,0xe7,0xad,0x35,0x85,
-      0xe2,0xf9,0x37,0xe8,0x1c,0x75,0xdf,0x6e,
-      0x47,0xf1,0x1a,0x71,0x1d,0x29,0xc5,0x89,
-      0x6f,0xb7,0x62,0x0e,0xaa,0x18,0xbe,0x1b,
-      0xfc,0x56,0x3e,0x4b,0xc6,0xd2,0x79,0x20,
-      0x9a,0xdb,0xc0,0xfe,0x78,0xcd,0x5a,0xf4,
-      0x1f,0xdd,0xa8,0x33,0x88,0x07,0xc7,0x31,
-      0xb1,0x12,0x10,0x59,0x27,0x80,0xec,0x5f,
-      0x60,0x51,0x7f,0xa9,0x19,0xb5,0x4a,0x0d,
-      0x2d,0xe5,0x7a,0x9f,0x93,0xc9,0x9c,0xef,
-      0xa0,0xe0,0x3b,0x4d,0xae,0x2a,0xf5,0xb0,
-      0xc8,0xeb,0xbb,0x3c,0x83,0x53,0x99,0x61,
-      0x17,0x2b,0x04,0x7e,0xba,0x77,0xd6,0x26,
-      0xe1,0x69,0x14,0x63,0x55,0x21,0x0c,0x7d,
-    },
-    { /* itable */
-      { 
-	0x50a7f451,0x5365417e,0xc3a4171a,0x965e273a,
-	0xcb6bab3b,0xf1459d1f,0xab58faac,0x9303e34b,
-	0x55fa3020,0xf66d76ad,0x9176cc88,0x254c02f5,
-	0xfcd7e54f,0xd7cb2ac5,0x80443526,0x8fa362b5,
-	0x495ab1de,0x671bba25,0x980eea45,0xe1c0fe5d,
-	0x02752fc3,0x12f04c81,0xa397468d,0xc6f9d36b,
-	0xe75f8f03,0x959c9215,0xeb7a6dbf,0xda595295,
-	0x2d83bed4,0xd3217458,0x2969e049,0x44c8c98e,
-	0x6a89c275,0x78798ef4,0x6b3e5899,0xdd71b927,
-	0xb64fe1be,0x17ad88f0,0x66ac20c9,0xb43ace7d,
-	0x184adf63,0x82311ae5,0x60335197,0x457f5362,
-	0xe07764b1,0x84ae6bbb,0x1ca081fe,0x942b08f9,
-	0x58684870,0x19fd458f,0x876cde94,0xb7f87b52,
-	0x23d373ab,0xe2024b72,0x578f1fe3,0x2aab5566,
-	0x0728ebb2,0x03c2b52f,0x9a7bc586,0xa50837d3,
-	0xf2872830,0xb2a5bf23,0xba6a0302,0x5c8216ed,
-	0x2b1ccf8a,0x92b479a7,0xf0f207f3,0xa1e2694e,
-	0xcdf4da65,0xd5be0506,0x1f6234d1,0x8afea6c4,
-	0x9d532e34,0xa055f3a2,0x32e18a05,0x75ebf6a4,
-	0x39ec830b,0xaaef6040,0x069f715e,0x51106ebd,
-	0xf98a213e,0x3d06dd96,0xae053edd,0x46bde64d,
-	0xb58d5491,0x055dc471,0x6fd40604,0xff155060,
-	0x24fb9819,0x97e9bdd6,0xcc434089,0x779ed967,
-	0xbd42e8b0,0x888b8907,0x385b19e7,0xdbeec879,
-	0x470a7ca1,0xe90f427c,0xc91e84f8,0x00000000,
-	0x83868009,0x48ed2b32,0xac70111e,0x4e725a6c,
-	0xfbff0efd,0x5638850f,0x1ed5ae3d,0x27392d36,
-	0x64d90f0a,0x21a65c68,0xd1545b9b,0x3a2e3624,
-	0xb1670a0c,0x0fe75793,0xd296eeb4,0x9e919b1b,
-	0x4fc5c080,0xa220dc61,0x694b775a,0x161a121c,
-	0x0aba93e2,0xe52aa0c0,0x43e0223c,0x1d171b12,
-	0x0b0d090e,0xadc78bf2,0xb9a8b62d,0xc8a91e14,
-	0x8519f157,0x4c0775af,0xbbdd99ee,0xfd607fa3,
-	0x9f2601f7,0xbcf5725c,0xc53b6644,0x347efb5b,
-	0x7629438b,0xdcc623cb,0x68fcedb6,0x63f1e4b8,
-	0xcadc31d7,0x10856342,0x40229713,0x2011c684,
-	0x7d244a85,0xf83dbbd2,0x1132f9ae,0x6da129c7,
-	0x4b2f9e1d,0xf330b2dc,0xec52860d,0xd0e3c177,
-	0x6c16b32b,0x99b970a9,0xfa489411,0x2264e947,
-	0xc48cfca8,0x1a3ff0a0,0xd82c7d56,0xef903322,
-	0xc74e4987,0xc1d138d9,0xfea2ca8c,0x360bd498,
-	0xcf81f5a6,0x28de7aa5,0x268eb7da,0xa4bfad3f,
-	0xe49d3a2c,0x0d927850,0x9bcc5f6a,0x62467e54,
-	0xc2138df6,0xe8b8d890,0x5ef7392e,0xf5afc382,
-	0xbe805d9f,0x7c93d069,0xa92dd56f,0xb31225cf,
-	0x3b99acc8,0xa77d1810,0x6e639ce8,0x7bbb3bdb,
-	0x097826cd,0xf418596e,0x01b79aec,0xa89a4f83,
-	0x656e95e6,0x7ee6ffaa,0x08cfbc21,0xe6e815ef,
-	0xd99be7ba,0xce366f4a,0xd4099fea,0xd67cb029,
-	0xafb2a431,0x31233f2a,0x3094a5c6,0xc066a235,
-	0x37bc4e74,0xa6ca82fc,0xb0d090e0,0x15d8a733,
-	0x4a9804f1,0xf7daec41,0x0e50cd7f,0x2ff69117,
-	0x8dd64d76,0x4db0ef43,0x544daacc,0xdf0496e4,
-	0xe3b5d19e,0x1b886a4c,0xb81f2cc1,0x7f516546,
-	0x04ea5e9d,0x5d358c01,0x737487fa,0x2e410bfb,
-	0x5a1d67b3,0x52d2db92,0x335610e9,0x1347d66d,
-	0x8c61d79a,0x7a0ca137,0x8e14f859,0x893c13eb,
-	0xee27a9ce,0x35c961b7,0xede51ce1,0x3cb1477a,
-	0x59dfd29c,0x3f73f255,0x79ce1418,0xbf37c773,
-	0xeacdf753,0x5baafd5f,0x146f3ddf,0x86db4478,
-	0x81f3afca,0x3ec468b9,0x2c342438,0x5f40a3c2,
-	0x72c31d16,0x0c25e2bc,0x8b493c28,0x41950dff,
-	0x7101a839,0xdeb30c08,0x9ce4b4d8,0x90c15664,
-	0x6184cb7b,0x70b632d5,0x745c6c48,0x4257b8d0,
-      },
-#if !AES_SMALL
-      { /* Before: itable[1] */
-	0xa7f45150,0x65417e53,0xa4171ac3,0x5e273a96,
-	0x6bab3bcb,0x459d1ff1,0x58faacab,0x03e34b93,
-	0xfa302055,0x6d76adf6,0x76cc8891,0x4c02f525,
-	0xd7e54ffc,0xcb2ac5d7,0x44352680,0xa362b58f,
-	0x5ab1de49,0x1bba2567,0x0eea4598,0xc0fe5de1,
-	0x752fc302,0xf04c8112,0x97468da3,0xf9d36bc6,
-	0x5f8f03e7,0x9c921595,0x7a6dbfeb,0x595295da,
-	0x83bed42d,0x217458d3,0x69e04929,0xc8c98e44,
-	0x89c2756a,0x798ef478,0x3e58996b,0x71b927dd,
-	0x4fe1beb6,0xad88f017,0xac20c966,0x3ace7db4,
-	0x4adf6318,0x311ae582,0x33519760,0x7f536245,
-	0x7764b1e0,0xae6bbb84,0xa081fe1c,0x2b08f994,
-	0x68487058,0xfd458f19,0x6cde9487,0xf87b52b7,
-	0xd373ab23,0x024b72e2,0x8f1fe357,0xab55662a,
-	0x28ebb207,0xc2b52f03,0x7bc5869a,0x0837d3a5,
-	0x872830f2,0xa5bf23b2,0x6a0302ba,0x8216ed5c,
-	0x1ccf8a2b,0xb479a792,0xf207f3f0,0xe2694ea1,
-	0xf4da65cd,0xbe0506d5,0x6234d11f,0xfea6c48a,
-	0x532e349d,0x55f3a2a0,0xe18a0532,0xebf6a475,
-	0xec830b39,0xef6040aa,0x9f715e06,0x106ebd51,
-	0x8a213ef9,0x06dd963d,0x053eddae,0xbde64d46,
-	0x8d5491b5,0x5dc47105,0xd406046f,0x155060ff,
-	0xfb981924,0xe9bdd697,0x434089cc,0x9ed96777,
-	0x42e8b0bd,0x8b890788,0x5b19e738,0xeec879db,
-	0x0a7ca147,0x0f427ce9,0x1e84f8c9,0x00000000,
-	0x86800983,0xed2b3248,0x70111eac,0x725a6c4e,
-	0xff0efdfb,0x38850f56,0xd5ae3d1e,0x392d3627,
-	0xd90f0a64,0xa65c6821,0x545b9bd1,0x2e36243a,
-	0x670a0cb1,0xe757930f,0x96eeb4d2,0x919b1b9e,
-	0xc5c0804f,0x20dc61a2,0x4b775a69,0x1a121c16,
-	0xba93e20a,0x2aa0c0e5,0xe0223c43,0x171b121d,
-	0x0d090e0b,0xc78bf2ad,0xa8b62db9,0xa91e14c8,
-	0x19f15785,0x0775af4c,0xdd99eebb,0x607fa3fd,
-	0x2601f79f,0xf5725cbc,0x3b6644c5,0x7efb5b34,
-	0x29438b76,0xc623cbdc,0xfcedb668,0xf1e4b863,
-	0xdc31d7ca,0x85634210,0x22971340,0x11c68420,
-	0x244a857d,0x3dbbd2f8,0x32f9ae11,0xa129c76d,
-	0x2f9e1d4b,0x30b2dcf3,0x52860dec,0xe3c177d0,
-	0x16b32b6c,0xb970a999,0x489411fa,0x64e94722,
-	0x8cfca8c4,0x3ff0a01a,0x2c7d56d8,0x903322ef,
-	0x4e4987c7,0xd138d9c1,0xa2ca8cfe,0x0bd49836,
-	0x81f5a6cf,0xde7aa528,0x8eb7da26,0xbfad3fa4,
-	0x9d3a2ce4,0x9278500d,0xcc5f6a9b,0x467e5462,
-	0x138df6c2,0xb8d890e8,0xf7392e5e,0xafc382f5,
-	0x805d9fbe,0x93d0697c,0x2dd56fa9,0x1225cfb3,
-	0x99acc83b,0x7d1810a7,0x639ce86e,0xbb3bdb7b,
-	0x7826cd09,0x18596ef4,0xb79aec01,0x9a4f83a8,
-	0x6e95e665,0xe6ffaa7e,0xcfbc2108,0xe815efe6,
-	0x9be7bad9,0x366f4ace,0x099fead4,0x7cb029d6,
-	0xb2a431af,0x233f2a31,0x94a5c630,0x66a235c0,
-	0xbc4e7437,0xca82fca6,0xd090e0b0,0xd8a73315,
-	0x9804f14a,0xdaec41f7,0x50cd7f0e,0xf691172f,
-	0xd64d768d,0xb0ef434d,0x4daacc54,0x0496e4df,
-	0xb5d19ee3,0x886a4c1b,0x1f2cc1b8,0x5165467f,
-	0xea5e9d04,0x358c015d,0x7487fa73,0x410bfb2e,
-	0x1d67b35a,0xd2db9252,0x5610e933,0x47d66d13,
-	0x61d79a8c,0x0ca1377a,0x14f8598e,0x3c13eb89,
-	0x27a9ceee,0xc961b735,0xe51ce1ed,0xb1477a3c,
-	0xdfd29c59,0x73f2553f,0xce141879,0x37c773bf,
-	0xcdf753ea,0xaafd5f5b,0x6f3ddf14,0xdb447886,
-	0xf3afca81,0xc468b93e,0x3424382c,0x40a3c25f,
-	0xc31d1672,0x25e2bc0c,0x493c288b,0x950dff41,
-	0x01a83971,0xb30c08de,0xe4b4d89c,0xc1566490,
-	0x84cb7b61,0xb632d570,0x5c6c4874,0x57b8d042,
-      },{ /* Before: itable[2] */
-	0xf45150a7,0x417e5365,0x171ac3a4,0x273a965e,
-	0xab3bcb6b,0x9d1ff145,0xfaacab58,0xe34b9303,
-	0x302055fa,0x76adf66d,0xcc889176,0x02f5254c,
-	0xe54ffcd7,0x2ac5d7cb,0x35268044,0x62b58fa3,
-	0xb1de495a,0xba25671b,0xea45980e,0xfe5de1c0,
-	0x2fc30275,0x4c8112f0,0x468da397,0xd36bc6f9,
-	0x8f03e75f,0x9215959c,0x6dbfeb7a,0x5295da59,
-	0xbed42d83,0x7458d321,0xe0492969,0xc98e44c8,
-	0xc2756a89,0x8ef47879,0x58996b3e,0xb927dd71,
-	0xe1beb64f,0x88f017ad,0x20c966ac,0xce7db43a,
-	0xdf63184a,0x1ae58231,0x51976033,0x5362457f,
-	0x64b1e077,0x6bbb84ae,0x81fe1ca0,0x08f9942b,
-	0x48705868,0x458f19fd,0xde94876c,0x7b52b7f8,
-	0x73ab23d3,0x4b72e202,0x1fe3578f,0x55662aab,
-	0xebb20728,0xb52f03c2,0xc5869a7b,0x37d3a508,
-	0x2830f287,0xbf23b2a5,0x0302ba6a,0x16ed5c82,
-	0xcf8a2b1c,0x79a792b4,0x07f3f0f2,0x694ea1e2,
-	0xda65cdf4,0x0506d5be,0x34d11f62,0xa6c48afe,
-	0x2e349d53,0xf3a2a055,0x8a0532e1,0xf6a475eb,
-	0x830b39ec,0x6040aaef,0x715e069f,0x6ebd5110,
-	0x213ef98a,0xdd963d06,0x3eddae05,0xe64d46bd,
-	0x5491b58d,0xc471055d,0x06046fd4,0x5060ff15,
-	0x981924fb,0xbdd697e9,0x4089cc43,0xd967779e,
-	0xe8b0bd42,0x8907888b,0x19e7385b,0xc879dbee,
-	0x7ca1470a,0x427ce90f,0x84f8c91e,0x00000000,
-	0x80098386,0x2b3248ed,0x111eac70,0x5a6c4e72,
-	0x0efdfbff,0x850f5638,0xae3d1ed5,0x2d362739,
-	0x0f0a64d9,0x5c6821a6,0x5b9bd154,0x36243a2e,
-	0x0a0cb167,0x57930fe7,0xeeb4d296,0x9b1b9e91,
-	0xc0804fc5,0xdc61a220,0x775a694b,0x121c161a,
-	0x93e20aba,0xa0c0e52a,0x223c43e0,0x1b121d17,
-	0x090e0b0d,0x8bf2adc7,0xb62db9a8,0x1e14c8a9,
-	0xf1578519,0x75af4c07,0x99eebbdd,0x7fa3fd60,
-	0x01f79f26,0x725cbcf5,0x6644c53b,0xfb5b347e,
-	0x438b7629,0x23cbdcc6,0xedb668fc,0xe4b863f1,
-	0x31d7cadc,0x63421085,0x97134022,0xc6842011,
-	0x4a857d24,0xbbd2f83d,0xf9ae1132,0x29c76da1,
-	0x9e1d4b2f,0xb2dcf330,0x860dec52,0xc177d0e3,
-	0xb32b6c16,0x70a999b9,0x9411fa48,0xe9472264,
-	0xfca8c48c,0xf0a01a3f,0x7d56d82c,0x3322ef90,
-	0x4987c74e,0x38d9c1d1,0xca8cfea2,0xd498360b,
-	0xf5a6cf81,0x7aa528de,0xb7da268e,0xad3fa4bf,
-	0x3a2ce49d,0x78500d92,0x5f6a9bcc,0x7e546246,
-	0x8df6c213,0xd890e8b8,0x392e5ef7,0xc382f5af,
-	0x5d9fbe80,0xd0697c93,0xd56fa92d,0x25cfb312,
-	0xacc83b99,0x1810a77d,0x9ce86e63,0x3bdb7bbb,
-	0x26cd0978,0x596ef418,0x9aec01b7,0x4f83a89a,
-	0x95e6656e,0xffaa7ee6,0xbc2108cf,0x15efe6e8,
-	0xe7bad99b,0x6f4ace36,0x9fead409,0xb029d67c,
-	0xa431afb2,0x3f2a3123,0xa5c63094,0xa235c066,
-	0x4e7437bc,0x82fca6ca,0x90e0b0d0,0xa73315d8,
-	0x04f14a98,0xec41f7da,0xcd7f0e50,0x91172ff6,
-	0x4d768dd6,0xef434db0,0xaacc544d,0x96e4df04,
-	0xd19ee3b5,0x6a4c1b88,0x2cc1b81f,0x65467f51,
-	0x5e9d04ea,0x8c015d35,0x87fa7374,0x0bfb2e41,
-	0x67b35a1d,0xdb9252d2,0x10e93356,0xd66d1347,
-	0xd79a8c61,0xa1377a0c,0xf8598e14,0x13eb893c,
-	0xa9ceee27,0x61b735c9,0x1ce1ede5,0x477a3cb1,
-	0xd29c59df,0xf2553f73,0x141879ce,0xc773bf37,
-	0xf753eacd,0xfd5f5baa,0x3ddf146f,0x447886db,
-	0xafca81f3,0x68b93ec4,0x24382c34,0xa3c25f40,
-	0x1d1672c3,0xe2bc0c25,0x3c288b49,0x0dff4195,
-	0xa8397101,0x0c08deb3,0xb4d89ce4,0x566490c1,
-	0xcb7b6184,0x32d570b6,0x6c48745c,0xb8d04257,
-      },{ /* Before: itable[3] */
-	0x5150a7f4,0x7e536541,0x1ac3a417,0x3a965e27,
-	0x3bcb6bab,0x1ff1459d,0xacab58fa,0x4b9303e3,
-	0x2055fa30,0xadf66d76,0x889176cc,0xf5254c02,
-	0x4ffcd7e5,0xc5d7cb2a,0x26804435,0xb58fa362,
-	0xde495ab1,0x25671bba,0x45980eea,0x5de1c0fe,
-	0xc302752f,0x8112f04c,0x8da39746,0x6bc6f9d3,
-	0x03e75f8f,0x15959c92,0xbfeb7a6d,0x95da5952,
-	0xd42d83be,0x58d32174,0x492969e0,0x8e44c8c9,
-	0x756a89c2,0xf478798e,0x996b3e58,0x27dd71b9,
-	0xbeb64fe1,0xf017ad88,0xc966ac20,0x7db43ace,
-	0x63184adf,0xe582311a,0x97603351,0x62457f53,
-	0xb1e07764,0xbb84ae6b,0xfe1ca081,0xf9942b08,
-	0x70586848,0x8f19fd45,0x94876cde,0x52b7f87b,
-	0xab23d373,0x72e2024b,0xe3578f1f,0x662aab55,
-	0xb20728eb,0x2f03c2b5,0x869a7bc5,0xd3a50837,
-	0x30f28728,0x23b2a5bf,0x02ba6a03,0xed5c8216,
-	0x8a2b1ccf,0xa792b479,0xf3f0f207,0x4ea1e269,
-	0x65cdf4da,0x06d5be05,0xd11f6234,0xc48afea6,
-	0x349d532e,0xa2a055f3,0x0532e18a,0xa475ebf6,
-	0x0b39ec83,0x40aaef60,0x5e069f71,0xbd51106e,
-	0x3ef98a21,0x963d06dd,0xddae053e,0x4d46bde6,
-	0x91b58d54,0x71055dc4,0x046fd406,0x60ff1550,
-	0x1924fb98,0xd697e9bd,0x89cc4340,0x67779ed9,
-	0xb0bd42e8,0x07888b89,0xe7385b19,0x79dbeec8,
-	0xa1470a7c,0x7ce90f42,0xf8c91e84,0x00000000,
-	0x09838680,0x3248ed2b,0x1eac7011,0x6c4e725a,
-	0xfdfbff0e,0x0f563885,0x3d1ed5ae,0x3627392d,
-	0x0a64d90f,0x6821a65c,0x9bd1545b,0x243a2e36,
-	0x0cb1670a,0x930fe757,0xb4d296ee,0x1b9e919b,
-	0x804fc5c0,0x61a220dc,0x5a694b77,0x1c161a12,
-	0xe20aba93,0xc0e52aa0,0x3c43e022,0x121d171b,
-	0x0e0b0d09,0xf2adc78b,0x2db9a8b6,0x14c8a91e,
-	0x578519f1,0xaf4c0775,0xeebbdd99,0xa3fd607f,
-	0xf79f2601,0x5cbcf572,0x44c53b66,0x5b347efb,
-	0x8b762943,0xcbdcc623,0xb668fced,0xb863f1e4,
-	0xd7cadc31,0x42108563,0x13402297,0x842011c6,
-	0x857d244a,0xd2f83dbb,0xae1132f9,0xc76da129,
-	0x1d4b2f9e,0xdcf330b2,0x0dec5286,0x77d0e3c1,
-	0x2b6c16b3,0xa999b970,0x11fa4894,0x472264e9,
-	0xa8c48cfc,0xa01a3ff0,0x56d82c7d,0x22ef9033,
-	0x87c74e49,0xd9c1d138,0x8cfea2ca,0x98360bd4,
-	0xa6cf81f5,0xa528de7a,0xda268eb7,0x3fa4bfad,
-	0x2ce49d3a,0x500d9278,0x6a9bcc5f,0x5462467e,
-	0xf6c2138d,0x90e8b8d8,0x2e5ef739,0x82f5afc3,
-	0x9fbe805d,0x697c93d0,0x6fa92dd5,0xcfb31225,
-	0xc83b99ac,0x10a77d18,0xe86e639c,0xdb7bbb3b,
-	0xcd097826,0x6ef41859,0xec01b79a,0x83a89a4f,
-	0xe6656e95,0xaa7ee6ff,0x2108cfbc,0xefe6e815,
-	0xbad99be7,0x4ace366f,0xead4099f,0x29d67cb0,
-	0x31afb2a4,0x2a31233f,0xc63094a5,0x35c066a2,
-	0x7437bc4e,0xfca6ca82,0xe0b0d090,0x3315d8a7,
-	0xf14a9804,0x41f7daec,0x7f0e50cd,0x172ff691,
-	0x768dd64d,0x434db0ef,0xcc544daa,0xe4df0496,
-	0x9ee3b5d1,0x4c1b886a,0xc1b81f2c,0x467f5165,
-	0x9d04ea5e,0x015d358c,0xfa737487,0xfb2e410b,
-	0xb35a1d67,0x9252d2db,0xe9335610,0x6d1347d6,
-	0x9a8c61d7,0x377a0ca1,0x598e14f8,0xeb893c13,
-	0xceee27a9,0xb735c961,0xe1ede51c,0x7a3cb147,
-	0x9c59dfd2,0x553f73f2,0x1879ce14,0x73bf37c7,
-	0x53eacdf7,0x5f5baafd,0xdf146f3d,0x7886db44,
-	0xca81f3af,0xb93ec468,0x382c3424,0xc25f40a3,
-	0x1672c31d,0xbc0c25e2,0x288b493c,0xff41950d,
-	0x397101a8,0x08deb30c,0xd89ce4b4,0x6490c156,
-	0x7b6184cb,0xd570b632,0x48745c6c,0xd04257b8,
-      },
-#endif /* !AES_SMALL */  
-    }
-  };
-
 void
 aes_decrypt(const struct aes_ctx *ctx,
 	    size_t length, uint8_t *dst,
@@ -364,33 +58,3 @@ aes_decrypt(const struct aes_ctx *ctx,
       break;
     }
 }
-
-void
-aes128_decrypt(const struct aes128_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_decrypt(_AES128_ROUNDS, ctx-&gt;keys, &amp;_aes_decrypt_table,
-		      length, dst, src);
-}
-
-void
-aes192_decrypt(const struct aes192_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_decrypt(_AES192_ROUNDS, ctx-&gt;keys, &amp;_aes_decrypt_table,
-		      length, dst, src);
-}
-
-void
-aes256_decrypt(const struct aes256_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_decrypt(_AES256_ROUNDS, ctx-&gt;keys, &amp;_aes_decrypt_table,
-		      length, dst, src);
-}
diff --git a/aes-encrypt.c b/aes-encrypt.c
index 257fa402..56efd92c 100644
--- a/aes-encrypt.c
+++ b/aes-encrypt.c
@@ -35,7 +35,6 @@
 # include "config.h"
 #endif
 
-#include &lt;assert.h&gt;
 #include &lt;stdlib.h&gt;
 
 #include "aes-internal.h"
@@ -62,33 +61,3 @@ aes_encrypt(const struct aes_ctx *ctx,
       break;
     }
 }
-
-void
-aes128_encrypt(const struct aes128_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_encrypt(_AES128_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
-		      length, dst, src);
-}
-
-void
-aes192_encrypt(const struct aes192_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_encrypt(_AES192_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
-		      length, dst, src);
-}
-
-void
-aes256_encrypt(const struct aes256_ctx *ctx,
-	       size_t length, uint8_t *dst,
-	       const uint8_t *src)
-{
-  assert(!(length % AES_BLOCK_SIZE) );
-  _nettle_aes_encrypt(_AES256_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
-		      length, dst, src);
-}
diff --git a/aes-internal.h b/aes-internal.h
index 04f61c8c..64cf7be5 100644
--- a/aes-internal.h
+++ b/aes-internal.h
@@ -96,9 +96,8 @@ _nettle_aes_decrypt(unsigned rounds, const uint32_t *keys,
   | ((uint32_t) T-&gt;sbox[ B2(w2) ] &lt;&lt; 16)		\
   | ((uint32_t) T-&gt;sbox[ B3(w3) ] &lt;&lt; 24)) ^ (k))
      
-/* Globally visible so that the same sbox table can be used by aes_set_encrypt_key */
-
 extern const struct aes_table _nettle_aes_encrypt_table;
 #define aes_sbox (_nettle_aes_encrypt_table.sbox)
+extern const struct aes_table _nettle_aes_decrypt_table;
 
 #endif /* NETTLE_AES_INTERNAL_H_INCLUDED */
diff --git a/aes128-decrypt.c b/aes128-decrypt.c
new file mode 100644
index 00000000..168d8158
--- /dev/null
+++ b/aes128-decrypt.c
@@ -0,0 +1,50 @@
+/* aes128-decrypt.c
+
+   Decryption function for aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes128_decrypt(const struct aes128_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_decrypt(_AES128_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_decrypt_table,
+		      length, dst, src);
+}
diff --git a/aes128-encrypt.c b/aes128-encrypt.c
new file mode 100644
index 00000000..35d15b36
--- /dev/null
+++ b/aes128-encrypt.c
@@ -0,0 +1,50 @@
+/* aes128-encrypt.c
+
+   Encryption function for the aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes128_encrypt(const struct aes128_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_encrypt(_AES128_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
+		      length, dst, src);
+}
diff --git a/aes192-decrypt.c b/aes192-decrypt.c
new file mode 100644
index 00000000..f97e2f6b
--- /dev/null
+++ b/aes192-decrypt.c
@@ -0,0 +1,50 @@
+/* aes192-decrypt.c
+
+   Decryption function for aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes192_decrypt(const struct aes192_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_decrypt(_AES192_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_decrypt_table,
+		      length, dst, src);
+}
diff --git a/aes192-encrypt.c b/aes192-encrypt.c
new file mode 100644
index 00000000..efa40e45
--- /dev/null
+++ b/aes192-encrypt.c
@@ -0,0 +1,50 @@
+/* aes192-encrypt.c
+
+   Encryption function for the aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes192_encrypt(const struct aes192_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_encrypt(_AES192_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
+		      length, dst, src);
+}
diff --git a/aes256-decrypt.c b/aes256-decrypt.c
new file mode 100644
index 00000000..42042cf6
--- /dev/null
+++ b/aes256-decrypt.c
@@ -0,0 +1,50 @@
+/* aes256-decrypt.c
+
+   Decryption function for aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes256_decrypt(const struct aes256_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_decrypt(_AES256_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_decrypt_table,
+		      length, dst, src);
+}
diff --git a/aes256-encrypt.c b/aes256-encrypt.c
new file mode 100644
index 00000000..98474bb5
--- /dev/null
+++ b/aes256-encrypt.c
@@ -0,0 +1,50 @@
+/* aes256-encrypt.c
+
+   Encryption function for the aes/rijndael block cipher.
+
+   Copyright (C) 2002, 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "aes-internal.h"
+
+void
+aes256_encrypt(const struct aes256_ctx *ctx,
+	       size_t length, uint8_t *dst,
+	       const uint8_t *src)
+{
+  assert(!(length % AES_BLOCK_SIZE) );
+  _nettle_aes_encrypt(_AES256_ROUNDS, ctx-&gt;keys, &amp;_nettle_aes_encrypt_table,
+		      length, dst, src);
+}

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210401055715</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-04-01 05:57:15-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; &gt; I've tried out a split, see below patch. It's a rather large change,
&gt; &gt; moving pieces to new places, but nothing difficult. I'm considering
&gt; &gt; committing this to the s390x branch, what do you think?
&gt; &gt; 
&gt; 
&gt; I agree, I'll modify the patch of basic AES-128 optimized functions to be
&gt; built on top of the splitted aes functions.

Ok, pushed to the s390x branch now.

&gt; memxor performs the same in C and assembly since s390 architecture offers
&gt; memory xor instruction "xc" see xor_len macro in machine.m4 of the original
&gt; patch for an implementation example.

But the C implmementation is somewhat complicated, splitting into
several cases depending on alignment, and shifting data around to be able
to do word operations. If it can be done simpler with the nc
instruction, that would at least cut some overhead. (Note that memxor3
must support the overlap case needed by cbc decrypt).

&gt; However, s390x AES accelerators offer considerable speedup against C
&gt; implementation with optimized internal AES. The following table
&gt; demonstrates the idea more clearly:
&gt; 
&gt; Function               S390x accelerator   C implementation with optimized
&gt; internal AES (Only enable aes128.asm, aes192.asm, aes256.asm)
&gt; -------------------------------------------------------------------------------------------------------------------------------
&gt; 
[...]
&gt; CBC AES128 Decrypt  0.647008 cpb  3.131405 cpb
[...]
&gt; CTR AES128 Crypt    0.710237 cpb  4.767290 cpb

For these two, the speed difference should essentially be the time for
the C implementation of memxor. "cpb" mean cycles per byte, right? 2-4
cycles per byte for memxor is quite slow. On my x86_64 laptop (ok,
comparing apples to oranges), memxor, for the aligned case, is 0.08 cpb,
and memxor twice as much. And even the C implementation is not that much
slower.

&gt; GCM AES128 Encrypt  0.630504 cpb  15.473187 cpb

For GCM, are there instructions that combine AES-CTR and GCM HASH? Or
are those done separately? It would be nice to have GCM HASH being fast
by itself, for performance with other ciphers than aes.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210401152153</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-04-01 15:21:53-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; (iii) I've considered doing it earlier, to make it easier to implement
&gt;       aes without a round loop (like for all current versions of
&gt;       aes-encrypt-internal.*). E.g., on x86_64, for aes128 we could load
&gt;       all subkeys into registers and still have registers left to do two
&gt;       or more blocks in parallel, but then we'd need to override
&gt;       aes128_encrypt separately from the other aes*_encrypt.

I've given this a try, see experimental patch below. It adds a
x86_64/aesni/aes128-encrypt.asm, with a 2-way loop. It gives a very
modest speedup, 5%, when I benchmark on my laptop (which is now a pretty
fast machine, AMD Ryzen 5). I've also added a cbc-aes128-encrypt.asm.
That gives more significant speedup, almost 60%. I think main reason for
the speedup is that we avoid reloading subkeys between blocks.

If we want to go this way, I wonder how to do it without an explosion of
files and functions. For s390x, it seems each function will be very
small, but not so for most other archs. There are at least three modes
that are similar to cbc encrypt in that they have to process blocks
sequentially, with no parallelism: CBC encrypt, CMAC, and XTS (there may
be more). It's not so nice if we need (modes × ciphers) number of assembly
files, with lots of duplication.

Regards,
/Niels

diff --git a/ChangeLog b/ChangeLog
index 3d19b1dd..68b8f632 100644
--- a/ChangeLog
+++ b/ChangeLog
@@ -1,5 +1,13 @@
 2021-04-01  Niels Möller  &lt;nisse@lysator.liu.se&gt;
 
+	* cbc-aes128-encrypt.c (nettle_cbc_aes128_encrypt): New file and function.
+	* x86_64/aesni/cbc-aes128-encrypt.asm: New file.
+
+	* configure.ac (asm_replace_list): Add aes128-encrypt.asm
+	aes128-decrypt.asm.
+	* x86_64/aesni/aes128-encrypt.asm: New file, with 2-way loop.
+	* x86_64/aesni/aes128-decrypt.asm: Likewise.
+
 	Move aes128_encrypt and similar functions to their own files. To
 	make it easier for assembly implementations to override specific
 	AES variants.
diff --git a/Makefile.in b/Makefile.in
index 8d474d1e..b6b983fd 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -101,7 +101,8 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c aes-decrypt-table.c \
 		 camellia256-set-encrypt-key.c camellia256-crypt.c \
 		 camellia256-set-decrypt-key.c \
 		 camellia256-meta.c \
-		 cast128.c cast128-meta.c cbc.c \
+		 cast128.c cast128-meta.c \
+		 cbc.c cbc-aes128-encrypt.c \
 		 ccm.c ccm-aes128.c ccm-aes192.c ccm-aes256.c cfb.c \
 		 siv-cmac.c siv-cmac-aes128.c siv-cmac-aes256.c \
 		 cnd-memcpy.c \
diff --git a/cbc-aes128-encrypt.c b/cbc-aes128-encrypt.c
new file mode 100644
index 00000000..5f7d1c8c
--- /dev/null
+++ b/cbc-aes128-encrypt.c
@@ -0,0 +1,42 @@
+/* cbc-aes128-encrypt.c
+
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "cbc.h"
+
+void
+nettle_cbc_aes128_encrypt(struct cbc_aes128_ctx *ctx, size_t length, uint8_t *dst, const uint8_t *src)
+{
+  CBC_ENCRYPT(ctx, aes128_encrypt, length, dst, src);
+}
diff --git a/cbc.h b/cbc.h
index 93b2e739..beece610 100644
--- a/cbc.h
+++ b/cbc.h
@@ -35,6 +35,7 @@
 #define NETTLE_CBC_H_INCLUDED
 
 #include "nettle-types.h"
+#include "aes.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -79,6 +80,10 @@ memcpy((ctx)-&gt;iv, (data), sizeof((ctx)-&gt;iv))
 		 sizeof((self)-&gt;iv), (self)-&gt;iv,	\
 		 (length), (dst), (src)))
 
+struct cbc_aes128_ctx CBC_CTX(struct aes128_ctx, AES_BLOCK_SIZE);
+void
+nettle_cbc_aes128_encrypt(struct cbc_aes128_ctx *ctx, size_t length, uint8_t *dst, const uint8_t *src);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/configure.ac b/configure.ac
index be2916c1..26e41d89 100644
--- a/configure.ac
+++ b/configure.ac
@@ -544,6 +544,7 @@ fi
 # Files which replace a C source file (or otherwise don't correspond
 # to a new object file).
 asm_replace_list="aes-encrypt-internal.asm aes-decrypt-internal.asm \
+		aes128-encrypt.asm aes128-decrypt.asm cbc-aes128-encrypt.asm \
 		arcfour-crypt.asm camellia-crypt-internal.asm \
 		md5-compress.asm memxor.asm memxor3.asm \
 		poly1305-internal.asm \
diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 9ce3a733..686cf3b9 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -240,6 +240,21 @@ bench_ctr(void *arg)
 	    BENCH_BLOCK, info-&gt;dst, info-&gt;src);
 }
 
+struct bench_cbc_aes128_info
+{
+  struct cbc_aes128_ctx ctx;
+
+  const uint8_t *src;
+  uint8_t *dst;
+};
+
+static void
+bench_cbc_aes128(void *arg)
+{
+  struct bench_cbc_aes128_info *info = arg;
+  nettle_cbc_aes128_encrypt(&amp;info-&gt;ctx, BENCH_BLOCK, info-&gt;dst, info-&gt;src);
+}
+
 struct bench_aead_info
 {
   void *ctx;
@@ -740,6 +755,29 @@ time_cipher(const struct nettle_cipher *cipher)
   free(key);
 }
 
+static void
+time_cbc_aes128(void)
+{
+  struct bench_cbc_aes128_info info;
+  uint8_t key[AES128_KEY_SIZE];
+  uint8_t iv[AES_BLOCK_SIZE];
+
+  static uint8_t src_data[BENCH_BLOCK];
+  static uint8_t data[BENCH_BLOCK];
+
+  init_key(sizeof(key), key);
+  init_key(sizeof(iv), iv);
+  init_data(data);
+  init_data(src_data);
+
+  aes128_set_encrypt_key(&amp;info.ctx.ctx, key);
+  CBC_SET_IV(&amp;info.ctx, iv);
+  info.src = src_data;
+  info.dst = data;
+  display("aes128", "new cbc", AES_BLOCK_SIZE,
+	  time_function(bench_cbc_aes128, &amp;info));
+}
+
 static void
 time_aead(const struct nettle_aead *aead)
 {
@@ -1027,6 +1065,9 @@ main(int argc, char **argv)
       if (!alg || strstr ("hmac-sha512", alg))
 	time_hmac_sha512();
 
+      if (!alg || strstr ("cbc-aes128", alg))
+	time_cbc_aes128();
+
       optind++;
     } while (alg &amp;&amp; argv[optind]);
 
diff --git a/testsuite/cbc-test.c b/testsuite/cbc-test.c
index 9394f1cb..ff0c4cbe 100644
--- a/testsuite/cbc-test.c
+++ b/testsuite/cbc-test.c
@@ -3,6 +3,43 @@
 #include "cbc.h"
 #include "knuth-lfib.h"
 
+static void
+test_cbc_aes128(const struct tstring *key,
+		const struct tstring *cleartext,
+		const struct tstring *ciphertext,
+		const struct tstring *iiv)
+{
+  struct cbc_aes128_ctx ctx;
+  uint8_t *data;
+  size_t length;
+
+  ASSERT (cleartext-&gt;length == ciphertext-&gt;length);
+  length = cleartext-&gt;length;
+
+  ASSERT (key-&gt;length == AES128_KEY_SIZE);
+  ASSERT (iiv-&gt;length == AES_BLOCK_SIZE);
+
+  data = xalloc(length);
+  aes128_set_encrypt_key(&amp;ctx.ctx, key-&gt;data);
+  CBC_SET_IV(&amp;ctx, iiv-&gt;data);
+
+  nettle_cbc_aes128_encrypt(&amp;ctx,
+			    length, data, cleartext-&gt;data);
+
+  if (!MEMEQ(length, data, ciphertext-&gt;data))
+    {
+      fprintf(stderr, "CBC encrypt failed:\nInput:");
+      tstring_print_hex(cleartext);
+      fprintf(stderr, "\nOutput: ");
+      print_hex(length, data);
+      fprintf(stderr, "\nExpected:");
+      tstring_print_hex(ciphertext);
+      fprintf(stderr, "\n");
+      FAIL();
+    }
+  free(data);
+}
+
 /* Test with more data and inplace decryption, to check that the
  * cbc_decrypt buffering works. */
 #define CBC_BULK_DATA 0x2710 /* 10000 */
@@ -161,6 +198,17 @@ test_main(void)
 		       "b2eb05e2c39be9fcda6c19078c6a9d1b"),
 		  SHEX("000102030405060708090a0b0c0d0e0f"));
 
+  test_cbc_aes128(SHEX("2b7e151628aed2a6abf7158809cf4f3c"),
+		  SHEX("6bc1bee22e409f96e93d7e117393172a"
+		       "ae2d8a571e03ac9c9eb76fac45af8e51"
+		       "30c81c46a35ce411e5fbc1191a0a52ef"
+		       "f69f2445df4f9b17ad2b417be66c3710"),
+		  SHEX("7649abac8119b246cee98e9b12e9197d"
+		       "5086cb9b507219ee95db113a917678b2"
+		       "73bed6b8e3c1743b7116e69e22229516"
+		       "3ff1caa1681fac09120eca307586e1a7"),
+		  SHEX("000102030405060708090a0b0c0d0e0f"));
+
   test_cbc_bulk();
 }
 
diff --git a/x86_64/aesni/aes128-decrypt.asm b/x86_64/aesni/aes128-decrypt.asm
new file mode 100644
index 00000000..79111e47
--- /dev/null
+++ b/x86_64/aesni/aes128-decrypt.asm
@@ -0,0 +1,136 @@
+C x86_64/aesni/aes128-decrypt.asm
+
+ifelse(`
+   Copyright (C) 2015, 2018, 2021 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Input argument
+define(`CTX',	`%rdi')
+define(`LENGTH',`%rsi')
+define(`DST',	`%rdx')
+define(`SRC',	`%rcx')
+
+define(`KEY0', `%xmm0')
+define(`KEY1', `%xmm1')
+define(`KEY2', `%xmm2')
+define(`KEY3', `%xmm3')
+define(`KEY4', `%xmm4')
+define(`KEY5', `%xmm5')
+define(`KEY6', `%xmm6')
+define(`KEY7', `%xmm7')
+define(`KEY8', `%xmm8')
+define(`KEY9', `%xmm9')
+define(`KEY10', `%xmm10')
+define(`X', `%xmm11')
+define(`Y', `%xmm12')
+
+	.file "aes128-decrypt.asm"
+
+	C nettle_aes128_decrypt(const struct aes128_ctx *ctx,
+	C                       size_t length, uint8_t *dst,
+	C                       const uint8_t *src);
+
+	.text
+	ALIGN(16)
+PROLOGUE(nettle_aes128_decrypt)
+	W64_ENTRY(4, 13)
+	shr	$4, LENGTH
+	test	LENGTH, LENGTH
+	jz	.Lend
+
+	movups	(CTX), KEY0
+	movups	16(CTX), KEY1
+	movups	32(CTX), KEY2
+	movups	48(CTX), KEY3
+	movups	64(CTX), KEY4
+	movups	80(CTX), KEY5
+	movups	96(CTX), KEY6
+	movups	112(CTX), KEY7
+	movups	128(CTX), KEY8
+	movups	144(CTX), KEY9
+	movups	160(CTX), KEY10
+	shr	LENGTH
+	jnc	.Lblock_loop
+
+	movups	(SRC), X
+	pxor	KEY0, X
+	aesdec	KEY1, X
+	aesdec	KEY2, X
+	aesdec	KEY3, X
+	aesdec	KEY4, X
+	aesdec	KEY5, X
+	aesdec	KEY6, X
+	aesdec	KEY7, X
+	aesdec	KEY8, X
+	aesdec	KEY9, X
+	aesdeclast KEY10, X
+
+	movups	X, (DST)
+	add	$16, SRC
+	add	$16, DST
+	test	LENGTH, LENGTH
+	jz	.Lend
+
+.Lblock_loop:
+	movups	(SRC), X
+	movups	16(SRC), Y
+	pxor	KEY0, X
+	pxor	KEY0, Y
+	aesdec	KEY1, X
+	aesdec	KEY1, Y
+	aesdec	KEY2, X
+	aesdec	KEY2, Y
+	aesdec	KEY3, X
+	aesdec	KEY3, Y
+	aesdec	KEY4, X
+	aesdec	KEY4, Y
+	aesdec	KEY5, X
+	aesdec	KEY5, Y
+	aesdec	KEY6, X
+	aesdec	KEY6, Y
+	aesdec	KEY7, X
+	aesdec	KEY7, Y
+	aesdec	KEY8, X
+	aesdec	KEY8, Y
+	aesdec	KEY9, X
+	aesdec	KEY9, Y
+	aesdeclast KEY10, X
+	aesdeclast KEY10, Y
+
+	movups	X, (DST)
+	movups	Y, 16(DST)
+	add	$32, SRC
+	add	$32, DST
+	dec	LENGTH
+	jnz	.Lblock_loop
+
+.Lend:
+	W64_EXIT(4, 13)
+	ret
+EPILOGUE(nettle_aes128_decrypt)
diff --git a/x86_64/aesni/aes128-encrypt.asm b/x86_64/aesni/aes128-encrypt.asm
new file mode 100644
index 00000000..8e7ebe78
--- /dev/null
+++ b/x86_64/aesni/aes128-encrypt.asm
@@ -0,0 +1,136 @@
+C x86_64/aesni/aes128-encrypt.asm
+
+ifelse(`
+   Copyright (C) 2015, 2018, 2021 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Input argument
+define(`CTX',	`%rdi')
+define(`LENGTH',`%rsi')
+define(`DST',	`%rdx')
+define(`SRC',	`%rcx')
+
+define(`KEY0', `%xmm0')
+define(`KEY1', `%xmm1')
+define(`KEY2', `%xmm2')
+define(`KEY3', `%xmm3')
+define(`KEY4', `%xmm4')
+define(`KEY5', `%xmm5')
+define(`KEY6', `%xmm6')
+define(`KEY7', `%xmm7')
+define(`KEY8', `%xmm8')
+define(`KEY9', `%xmm9')
+define(`KEY10', `%xmm10')
+define(`X', `%xmm11')
+define(`Y', `%xmm12')
+
+	.file "aes128-encrypt.asm"
+
+	C nettle_aes128_encrypt(const struct aes128_ctx *ctx,
+	C                       size_t length, uint8_t *dst,
+	C                       const uint8_t *src);
+
+	.text
+	ALIGN(16)
+PROLOGUE(nettle_aes128_encrypt)
+	W64_ENTRY(4, 13)
+	shr	$4, LENGTH
+	test	LENGTH, LENGTH
+	jz	.Lend
+
+	movups	(CTX), KEY0
+	movups	16(CTX), KEY1
+	movups	32(CTX), KEY2
+	movups	48(CTX), KEY3
+	movups	64(CTX), KEY4
+	movups	80(CTX), KEY5
+	movups	96(CTX), KEY6
+	movups	112(CTX), KEY7
+	movups	128(CTX), KEY8
+	movups	144(CTX), KEY9
+	movups	160(CTX), KEY10
+	shr	LENGTH
+	jnc	.Lblock_loop
+
+	movups	(SRC), X
+	pxor	KEY0, X
+	aesenc	KEY1, X
+	aesenc	KEY2, X
+	aesenc	KEY3, X
+	aesenc	KEY4, X
+	aesenc	KEY5, X
+	aesenc	KEY6, X
+	aesenc	KEY7, X
+	aesenc	KEY8, X
+	aesenc	KEY9, X
+	aesenclast KEY10, X
+
+	movups	X, (DST)
+	add	$16, SRC
+	add	$16, DST
+	test	LENGTH, LENGTH
+	jz	.Lend
+
+.Lblock_loop:
+	movups	(SRC), X
+	movups	16(SRC), Y
+	pxor	KEY0, X
+	pxor	KEY0, Y
+	aesenc	KEY1, X
+	aesenc	KEY1, Y
+	aesenc	KEY2, X
+	aesenc	KEY2, Y
+	aesenc	KEY3, X
+	aesenc	KEY3, Y
+	aesenc	KEY4, X
+	aesenc	KEY4, Y
+	aesenc	KEY5, X
+	aesenc	KEY5, Y
+	aesenc	KEY6, X
+	aesenc	KEY6, Y
+	aesenc	KEY7, X
+	aesenc	KEY7, Y
+	aesenc	KEY8, X
+	aesenc	KEY8, Y
+	aesenc	KEY9, X
+	aesenc	KEY9, Y
+	aesenclast KEY10, X
+	aesenclast KEY10, Y
+
+	movups	X, (DST)
+	movups	Y, 16(DST)
+	add	$32, SRC
+	add	$32, DST
+	dec	LENGTH
+	jnz	.Lblock_loop
+
+.Lend:
+	W64_EXIT(4, 13)
+	ret
+EPILOGUE(nettle_aes128_encrypt)
diff --git a/x86_64/aesni/cbc-aes128-encrypt.asm b/x86_64/aesni/cbc-aes128-encrypt.asm
new file mode 100644
index 00000000..04c6c6b0
--- /dev/null
+++ b/x86_64/aesni/cbc-aes128-encrypt.asm
@@ -0,0 +1,108 @@
+C x86_64/aesni/cbc-aes128-encrypt.asm
+
+ifelse(`
+   Copyright (C) 2015, 2018, 2021 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Input argument
+define(`CTX',	`%rdi')
+define(`LENGTH',`%rsi')
+define(`DST',	`%rdx')
+define(`SRC',	`%rcx')
+
+define(`KEY0', `%xmm0')
+define(`KEY1', `%xmm1')
+define(`KEY2', `%xmm2')
+define(`KEY3', `%xmm3')
+define(`KEY4', `%xmm4')
+define(`KEY5', `%xmm5')
+define(`KEY6', `%xmm6')
+define(`KEY7', `%xmm7')
+define(`KEY8', `%xmm8')
+define(`KEY9', `%xmm9')
+define(`KEY10', `%xmm10')
+define(`X', `%xmm11')
+define(`BLOCK', `%xmm12')
+
+	.file "cbc-aes128-encrypt.asm"
+
+	C nettle_cbc_aes128_encrypt(struct cbc_aes128_ctx *ctx,
+	C                       size_t length, uint8_t *dst,
+	C                       const uint8_t *src);
+
+	.text
+	ALIGN(16)
+PROLOGUE(nettle_cbc_aes128_encrypt)
+	W64_ENTRY(4, 13)
+	shr	$4, LENGTH
+	test	LENGTH, LENGTH
+	jz	.Lend
+
+	movups	(CTX), KEY0
+	movups	16(CTX), KEY1
+	movups	32(CTX), KEY2
+	movups	48(CTX), KEY3
+	movups	64(CTX), KEY4
+	movups	80(CTX), KEY5
+	movups	96(CTX), KEY6
+	movups	112(CTX), KEY7
+	movups	128(CTX), KEY8
+	movups	144(CTX), KEY9
+	movups	160(CTX), KEY10
+	movups	176(CTX), X	C Load IV
+
+.Lblock_loop:
+	movups	(SRC), BLOCK	C Cleartext block
+	pxor	BLOCK, X
+	pxor	KEY0, X
+	aesenc	KEY1, X
+	aesenc	KEY2, X
+	aesenc	KEY3, X
+	aesenc	KEY4, X
+	aesenc	KEY5, X
+	aesenc	KEY6, X
+	aesenc	KEY7, X
+	aesenc	KEY8, X
+	aesenc	KEY9, X
+	aesenclast KEY10, X
+
+	movups	X, (DST)
+	add	$16, SRC
+	add	$16, DST
+
+	dec	LENGTH
+	jnz	.Lblock_loop
+
+	C Save IV
+	movups	X, 176(CTX)
+
+.Lend:
+	W64_EXIT(4, 13)
+	ret
+EPILOGUE(nettle_cbc_aes128_encrypt)

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210401173350</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-04-01 17:33:50-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Thu, Apr 1, 2021 at 7:57 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; For GCM, are there instructions that combine AES-CTR and GCM HASH? Or
&gt; are those done separately? It would be nice to have GCM HASH being fast
&gt; by itself, for performance with other ciphers than aes.
&gt;

MSA_X4 has a GHASH implementation using KIMD-GHASH built-in function which
optimizes the performance of GHASH authentication for aes and non-aes
ciphers. MSA_X6 implements KMA-GCM-AES-128, KMA-GCM-AES-192,
and KMA-GCM-AES-256 functions that maximize the performance of AES-GCM.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210401174329</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-04-01 17:43:29-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Thu, Apr 1, 2021 at 5:21 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; (iii) I've considered doing it earlier, to make it easier to implement
&gt; &gt;       aes without a round loop (like for all current versions of
&gt; &gt;       aes-encrypt-internal.*). E.g., on x86_64, for aes128 we could load
&gt; &gt;       all subkeys into registers and still have registers left to do two
&gt; &gt;       or more blocks in parallel, but then we'd need to override
&gt; &gt;       aes128_encrypt separately from the other aes*_encrypt.
&gt;
&gt; I've given this a try, see experimental patch below. It adds a
&gt; x86_64/aesni/aes128-encrypt.asm, with a 2-way loop. It gives a very
&gt; modest speedup, 5%, when I benchmark on my laptop (which is now a pretty
&gt; fast machine, AMD Ryzen 5). I've also added a cbc-aes128-encrypt.asm.
&gt; That gives more significant speedup, almost 60%. I think main reason for
&gt; the speedup is that we avoid reloading subkeys between blocks.
&gt;
&gt; If we want to go this way, I wonder how to do it without an explosion of
&gt; files and functions. For s390x, it seems each function will be very
&gt; small, but not so for most other archs. There are at least three modes
&gt; that are similar to cbc encrypt in that they have to process blocks
&gt; sequentially, with no parallelism: CBC encrypt, CMAC, and XTS (there may
&gt; be more). It's not so nice if we need (modes × ciphers) number of assembly
&gt; files, with lots of duplication.
&gt;

I can think of a core function for AES-CBC mode cbc_aes_encrypt that
supplies cbc_aes128_encrypt, cbc_aes192_encrypt, and cbc_aes256_encrypt
function, now we can optimize cbc_aes_encrypt in assembly while taking care
of rounds parameter during implementing. I still prefer duplicating files
and functions for AES modes with different rounds rather than going with
this approach as I can't think of any other solution.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210104231219</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-04 23:12:19-0400</timestampReceived><subject>[S390x] Optimize AES modes</subject><body>

I made a merge request for optimizing AES modes on s390x architecture, the
patch implements the optimized cores using cipher instructions that have
been added to s390x arch in message security assist extensions. The patch
uses the following functions:
KM-AES-128 (ECB-AES128)
KM-AES-192 (ECB-AES192)
KM-AES-256 (ECB-AES256)
KMC-AES-128 (CBC-AES128)
KMC-AES-192 (CBC-AES192)
KMC-AES-256 (CBC-AES256)
KMAC-AES-128 (CCM-AES128, CMAC-AES128)
KMAC-AES-192 (CCM-AES192)
KMAC-AES-256 (CCM-AES256, CMAC-AES256)
KMF-AES-128 (CFB-AES128, CFB8-AES128)
KMF-AES-192 (CFB-AES192, CFB8-AES192)
KMF-AES-256 (CFB-AES256, CFB8-AES256)
KM-XTS-AES-128 (XTS-AES128)
KM-XTS-AES-256 (XTS-AES256)
KIMD-GHASH (GHASH)
KMCTR-AES-128, KMA-GCM-AES-128 (CTR-AES128)
KMCTR-AES-192, KMA-GCM-AES-192 (CTR-AES192)
KMCTR-AES-256, KMA-GCM-AES-256 (CTR-AES256)
KMA-GCM-AES-128 (GCM-AES128)
KMA-GCM-AES-192 (GCM-AES192)
KMA-GCM-AES-256 (GCM-AES256)

The merge request has also a benchmark that measures the speed of optimized
cores on s390x arch.

I can't set up gitlab CI for automatic testing on s390x arch because qemu
hasn't implemented cipher functions for this arch. However, there is an
easy way to test the patch manually by requesting a free account on the
LinuxONE Community
Cloud, both short-term and long-term access are available.
https://linuxone.cloud.marist.edu/#/register?flag=VM

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210120204136</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-20 20:41:36-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Hello Neils,

Any update on this? Is there anything missed in my side?

regards,
Mamone

On Tue, Jan 5, 2021 at 1:12 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; I made a merge request for optimizing AES modes on s390x architecture, the
&gt; patch implements the optimized cores using cipher instructions that have
&gt; been added to s390x arch in message security assist extensions. The patch
&gt; uses the following functions:
&gt; KM-AES-128 (ECB-AES128)
&gt; KM-AES-192 (ECB-AES192)
&gt; KM-AES-256 (ECB-AES256)
&gt; KMC-AES-128 (CBC-AES128)
&gt; KMC-AES-192 (CBC-AES192)
&gt; KMC-AES-256 (CBC-AES256)
&gt; KMAC-AES-128 (CCM-AES128, CMAC-AES128)
&gt; KMAC-AES-192 (CCM-AES192)
&gt; KMAC-AES-256 (CCM-AES256, CMAC-AES256)
&gt; KMF-AES-128 (CFB-AES128, CFB8-AES128)
&gt; KMF-AES-192 (CFB-AES192, CFB8-AES192)
&gt; KMF-AES-256 (CFB-AES256, CFB8-AES256)
&gt; KM-XTS-AES-128 (XTS-AES128)
&gt; KM-XTS-AES-256 (XTS-AES256)
&gt; KIMD-GHASH (GHASH)
&gt; KMCTR-AES-128, KMA-GCM-AES-128 (CTR-AES128)
&gt; KMCTR-AES-192, KMA-GCM-AES-192 (CTR-AES192)
&gt; KMCTR-AES-256, KMA-GCM-AES-256 (CTR-AES256)
&gt; KMA-GCM-AES-128 (GCM-AES128)
&gt; KMA-GCM-AES-192 (GCM-AES192)
&gt; KMA-GCM-AES-256 (GCM-AES256)
&gt;
&gt; The merge request has also a benchmark that measures the speed of
&gt; optimized cores on s390x arch.
&gt;
&gt; I can't set up gitlab CI for automatic testing on s390x arch because qemu
&gt; hasn't implemented cipher functions for this arch. However, there is an
&gt; easy way to test the patch manually by requesting a free account on the
&gt; LinuxONE Community
&gt; Cloud, both short-term and long-term access are available.
&gt; https://linuxone.cloud.marist.edu/#/register?flag=VM
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202224417</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-02 22:44:17-0400</timestampReceived><subject>Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I've added a merge request to implement AES key wrap and unwrap in 
Nettle [1].

The MR is not complete, because the tests haven't been pushed yet and 
the documentation is missing, but if the new functionality is welcome to 
Nettle, I'd rather have some feedback on the code first, to make sure it 
respects the project guidelines.

I can add tests based on the tests vectors in the RFC [2], but I'm not 
sure how the test suites are build, should I need to create test_wrap 
functions like in aes-test.c or something else?

Thanks in advance for your help!

/Nicolas

[1] https://tools.ietf.org/html/rfc3394
[2] https://tools.ietf.org/html/rfc3394#section-4

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210202224543</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-02 22:45:43-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Le 2021-02-02 Ã  17 h 44, Nicolas Mora a Ã©crit  :
&gt; Hello,
&gt; 
&gt; I've added a merge request to implement AES key wrap and unwrap in 
&gt; Nettle [1].
&gt; 

Of course I forgot the link to the MR...

https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210203084709</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-03 08:47:09-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I've added a merge request to implement AES key wrap and unwrap in
&gt; Nettle [1].

Thanks. Can you give a bit more details on the usecase? I've understood
that it's part of web-related specs, but do you know any examples of
protocols or applicatinos using it, and how?

I've only had a quick look at the spec, and it looks like it works a bit
like an AEAD algorithm (authenticated encryption with associated data),
but with no associated data, no nonce (that's often an advantage, I
guess), and message length contrained to be a multiple of 8 bytes. So
not obvious to me when it's useful to use this key wrap method over any
general AEAD construction.

Should it really be AES only? It could be generalized to arbitrary block
ciphers (as long as block size is an even number of bytes), or more
easily to any 16-byte block cipher. I think the spec
https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-38F.pdf
mentioned a variant for "TDEA" (I guess that's triple-DES?), which
doesn't seem that relevant.

Some comments on the code:

* Nettle usually doesn't return any status codes based on validation of
  inputs. The key wrap function should not have a return value. It can
  assume passed in pointers are valid, and use assert to check that
  lengths are valid. The unwrap function should obviously have a return
  value, but it doesn't need to check conditions that are trivial to
  check for the caller (not an obvious call if invalid ciphertext length
  for unwrap should trigger an assert or give a zero return value;
  whatever choice is made it needs to be clearly documented).

* Try to avoid conditions on algorithm type. The common style in nettle
  is to have a general function taking an opaque context and needed
  function pointers as input, and then small convenience wrappers for
  algorithms of interest. So for the key wrap function, the cipher could
  be represented as a const void * for a cipher context already
  initialized with the "kek" key, and a nettle_cipher_func for invoking
  the cipher. If we want to support arbitrary block size (which is a bit
  questionable), it would also need a block size parametert.

* If we restrict the implementation to 16-byte block size, it would be
  good to use wider types than uint8_t for the internal data shuffling.
  I think most or all internal state could be represented as union
  nettle_block16 or uint64_t. Movement (and xor) is independent of
  endianness. Easiest way to test for big-endian is likely to target
  mips, using cross compiler and qemu (like the mips builds in the
  gitlab ci). The

        I[7] ^= (n*j)+(i+1);

  line would differ depending on endianness, if we want to do on a
  64-bit state variable. (Staying with bytes and memcpy may be fine if
  you think it makes the code simpler and there's no significant
  performance difference).

* For the final memcmp in the unwrap function, you could use memeql_sec,
  to make the comparison side-channel silent (i.e., not leak information
  about the first differing byte).

* Since relation bewteen input and output size is very simple, we don't
  need both arguments. Just document the relation and provide
  appropriate #defined constants. The convention for similar functions
  is that the single length argument specifies the size of the *output*
  buffer.

So to be concrete on the interface comments, I'd suggest something like

void
nist_keywrap16(const void *ctx, nettle_cipher_func *encrypt, 
               const uint8_t *iv, size_t ciphertext_length, 
               uint8_t *ciphertext, cosnt uint8_t *cleartext);

int
nist_keyunwrap16(const void *ctx, nettle_cipher_func *decrypt,
                 const uint8_t *iv, size_t cleartext_length, 
                 uint8_t *cleartext, const uint8_t *ciphertext);

Not clear if default iv should be handled at this level. What are the
usecases for specifying a different iv?

&gt; I can add tests based on the tests vectors in the RFC [2], but I'm not
&gt; sure how the test suites are build, should I need to create test_wrap
&gt; functions like in aes-test.c or something else?

I think it would make sense to put tests in a new file. test_main should
contain one fucntion call per test case, calling whatever helper
functions are needed. It's probably sufficient to test
algorithm-specific convenience functions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203135853</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-03 13:58:53-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; So to be concrete on the interface comments, I'd suggest something like
&gt;
&gt; void
&gt; nist_keywrap16(const void *ctx, nettle_cipher_func *encrypt, 
&gt;                const uint8_t *iv, size_t ciphertext_length, 
&gt;                uint8_t *ciphertext, cosnt uint8_t *cleartext);
&gt;
&gt; int
&gt; nist_keyunwrap16(const void *ctx, nettle_cipher_func *decrypt,
&gt;                  const uint8_t *iv, size_t cleartext_length, 
&gt;                  uint8_t *cleartext, const uint8_t *ciphertext);

And it's desirable if in-place operation works efficiently, while for
non-inplace operation, the input shouldn't be clobbered.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203195935</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-03 19:59:35-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello Niels,

Thanks for your feedback!

Le 2021-02-03 Ã  03 h 47, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt; Thanks. Can you give a bit more details on the usecase? I've understood
&gt; that it's part of web-related specs, but do you know any examples of
&gt; protocols or applicatinos using it, and how?
&gt; 
The AES Key Wrap is an encryption scheme designed to encrypt/decrypt a 
cryptographic key, the RFC introduction says:

    This key wrap algorithm needs to provide ample security to protect
    keys in the context of prudently designed key management
    architecture.

The AES key wrap is used in the JOSE standard to protect the encryption 
key used in some JWE (JSON Web Encryption) key management algorithms [1].

Basically, a JWE is an encrypted token. The payload encryption uses AES 
CBC|GCM with 128/192/256 bits key length. The AES key used to encrypt 
the payload is included encrypted in the token.

Concerning the algorithms used to encrypt the AES key, AES Key Wrap is 
required in 9 out of 17 possible algorithms.

I'm the author of the SSO Server Glewlwyd [2], Glewlwyd implements 
OpenID Connect, which uses JWT (JSON Web Tokens) via one of my library 
called Rhonabwy [3].
A JWT is a token signed (JWS) and/or encrypted (JWE). The encrypted 
tokens can be used for requests or response in lots of cases, to 
increase the security level of the application when it's required.

Currently Glewlwyd supports all signing algorithms specified, but not 
all encryption algorithm are supported yet. I intend to support as much 
possible encryption algorithm. And AES key Wrap is required in 9/17 
specified encryption algorithms [4]

&gt; 
&gt; Should it really be AES only? It could be generalized to arbitrary block
&gt; ciphers (as long as block size is an even number of bytes), or more
&gt; easily to any 16-byte block cipher. I think the spec
&gt; https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-38F.pdf
&gt; mentioned a variant for "TDEA" (I guess that's triple-DES?), which
&gt; doesn't seem that relevant.
&gt; 
It was designed to wrap key data, but not necessarily AES only. The kek 
must be an AES key though. The key data to wrap can be any data, as long 
as it's a set of 64 bits blocks.

&gt; Some comments on the code:
&gt; 
&gt; * Nettle usually doesn't return any status codes based on validation of
&gt;    inputs. The key wrap function should not have a return value. It can
&gt;    assume passed in pointers are valid, and use assert to check that
&gt;    lengths are valid. The unwrap function should obviously have a return
&gt;    value, but it doesn't need to check conditions that are trivial to
&gt;    check for the caller (not an obvious call if invalid ciphertext length
&gt;    for unwrap should trigger an assert or give a zero return value;
&gt;    whatever choice is made it needs to be clearly documented).
&gt; 
Noted, I'll remove the return statement for the key_wrap function, I'll 
also remove the input validation

&gt; * Try to avoid conditions on algorithm type. The common style in nettle
&gt;    is to have a general function taking an opaque context and needed
&gt;    function pointers as input, and then small convenience wrappers for
&gt;    algorithms of interest. So for the key wrap function, the cipher could
&gt;    be represented as a const void * for a cipher context already
&gt;    initialized with the "kek" key, and a nettle_cipher_func for invoking
&gt;    the cipher. If we want to support arbitrary block size (which is a bit
&gt;    questionable), it would also need a block size parametert.
&gt; 
Good point, instead of passing the kek in the input params, it's better 
to pass a struct aes_ctx which is supposed to be already initialized.

&gt; * If we restrict the implementation to 16-byte block size, it would be
&gt;    good to use wider types than uint8_t for the internal data shuffling.
&gt;    I think most or all internal state could be represented as union
&gt;    nettle_block16 or uint64_t. Movement (and xor) is independent of
&gt;    endianness. Easiest way to test for big-endian is likely to target
&gt;    mips, using cross compiler and qemu (like the mips builds in the
&gt;    gitlab ci). The
&gt; 
&gt;          I[7] ^= (n*j)+(i+1);
  &gt;
&gt;    line would differ depending on endianness, if we want to do on a
&gt;    64-bit state variable. (Staying with bytes and memcpy may be fine if
&gt;    you think it makes the code simpler and there's no significant
&gt;    performance difference).
&gt; 
Good point too. Endianess is my kryptonite so my code would not be valid 
on all architectures...

&gt; * For the final memcmp in the unwrap function, you could use memeql_sec,
&gt;    to make the comparison side-channel silent (i.e., not leak information
&gt;    about the first differing byte).
&gt; 
noted too

&gt; * Since relation bewteen input and output size is very simple, we don't
&gt;    need both arguments. Just document the relation and provide
&gt;    appropriate #defined constants. The convention for similar functions
&gt;    is that the single length argument specifies the size of the *output*
&gt;    buffer.
&gt; 
&gt; So to be concrete on the interface comments, I'd suggest something like
&gt; 
&gt; void
&gt; nist_keywrap16(const void *ctx, nettle_cipher_func *encrypt,
&gt;                 const uint8_t *iv, size_t ciphertext_length,
&gt;                 uint8_t *ciphertext, cosnt uint8_t *cleartext);
&gt; 
&gt; int
&gt; nist_keyunwrap16(const void *ctx, nettle_cipher_func *decrypt,
&gt;                   const uint8_t *iv, size_t cleartext_length,
&gt;                   uint8_t *cleartext, const uint8_t *ciphertext);
&gt; 
We can also replace the uint8_t with uint64_t as well in the input values?

&gt; Not clear if default iv should be handled at this level. What are the
&gt; usecases for specifying a different iv?
&gt; 
It's up to the calling algorithm.
The IV is used for key data integrity [5].
Concerning using different IVs, the paragraph 2.2.3.2 mentions that 
alternative IVs can be used as part of larger key management protocols 
if the key data is not just an AES key, it may not always be a multiple 
of 64 bits.

Also, setting the default IV as a 'const uint8_t default_iv' in the 
function code isn't the best move, I totally agree.

Perhaps if instead of using uint8_t[8] I use uint64_t, then the default 
IV can be a classic #define DEFAULT_IV A6A6A6A6A6A6A6A6

&gt;&gt; I can add tests based on the tests vectors in the RFC [2], but I'm not
&gt;&gt; sure how the test suites are build, should I need to create test_wrap
&gt;&gt; functions like in aes-test.c or something else?
&gt; 
&gt; I think it would make sense to put tests in a new file. test_main should
&gt; contain one fucntion call per test case, calling whatever helper
&gt; functions are needed. It's probably sufficient to test
&gt; algorithm-specific convenience functions.
&gt; 
I'll get back to the tests when the function code will be completed then.

Thanks for all the feedback and the help!

/Nicolas

[1] https://tools.ietf.org/html/rfc7518#section-4
[2] https://github.com/babelouest/glewlwyd
[3] https://github.com/babelouest/rhonabwy
[4] https://tools.ietf.org/html/rfc7518#section-4.1
[5] https://tools.ietf.org/html/rfc3394#section-2.2.3

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210204064832</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-04 06:48:32-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; It was designed to wrap key data, but not necessarily AES only. The
&gt; kek must be an AES key though. The key data to wrap can be any data,
&gt; as long as it's a set of 64 bits blocks.

If it doesn't add a lot of complexity, I think it would be nice to be
able to substitute at least other 16-byte block ciphers (e.g., any other
AES finalist, serpent and twofish being the once currently implemented in
Nettle).

&gt; Good point, instead of passing the kek in the input params, it's
&gt; better to pass a struct aes_ctx which is supposed to be already
&gt; initialized.

I think it's better to represent the context as a const void* (in the
main function), and let the caller allocate and pass in appropriate
context, aes128_ctx or aes256_ctx etc). struct aes_ctx is deprecated,
with the current api model being that the AES variants with different
key sizes are separete algorithms, similarities just being
implementation details.

We could still have convenience wrappers taking the key as a byte
string, if that'ss the common usecase.

&gt; Good point too. Endianess is my kryptonite so my code would not be
&gt; valid on all architectures...

If one goes this way, one needs some extra care and testing. It's worth
it if there's a measurable performance improvement. Not sure about this
case, but AES itself is pretty fast on some platforms.

(Also, for the best AES performance, one should call aes_encrypt with
more than one block at a time. But as far as I understand, AES key wrap
is inherently serial, so that's not possible here).

&gt; We can also replace the uint8_t with uint64_t as well in the input values?

It would be nice if we could have that alignment on input and output,
but I think it's not a good idea to have uint64_t in this interface.
We'd force alignment requirement on callers (who may be forced to make
an extra copy to be able to call the function), and we'd also need to
document endianness of the input. In short, since the specification
defines the mechanism as operating on byte strings, the Nettle api
should too.

I suspect that using byte strings in the interface and uint64_t
internally makes it a bit difficult to allocate storage for internal
state, since one can't just reuse the output buffer for working storage.
Is the size needed for internal state same as the message size, or is if
fixed size? I think it's doable but tricky to make it work without
separate allocation for working storage.

&gt; It's up to the calling algorithm. The IV is used for key data
&gt; integrity [5]. Concerning using different IVs, the paragraph 2.2.3.2
&gt; mentions that alternative IVs can be used as part of larger key
&gt; management protocols if the key data is not just an AES key, it may
&gt; not always be a multiple of 64 bits.

I was pointed to RFC 5649 (AES Key Wrap with Padding), is that relevant?

&gt; Perhaps if instead of using uint8_t[8] I use uint64_t, then the
&gt; default IV can be a classic #define DEFAULT_IV A6A6A6A6A6A6A6A6

That would work for this particular value, since it is invariant under
byte swapping. But in general an uint64_t iv would be endian dpendent. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210304091443</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-04 09:14:43-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I've updated the MR with the new functions definitions and added test
&gt; cases based on the test vectors from the RFC.
&gt;
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19

I've added a couple of comments on the mr.

One question: Do you intentionally limit message size to 64 bytes? Is
that according to spec?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210304222118</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-04 22:21:18-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

Le 2021-03-04 Ã  04 h 14, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt; I've added a couple of comments on the mr.
&gt; 
Thanks a lot!

I still have one uresolved comment about byte swapping but the rest are 
resolved.

&gt; One question: Do you intentionally limit message size to 64 bytes? Is
&gt; that according to spec?
&gt; 
Not at all. At first I thought AES key wrap had an input limit because 
it's about wrapping cypher keys, so to me the limit was 64 bytes.
But even if it's the intention, I don't see any specific limitation on 
input message in the specs.

The only limitation is to have cyphertext 8 bytes longer than cleartext, 
and cleartext to be at least 16 bytes to be a set of 8-bytes blocks.

Therefore I removed 'uint8_t R[64]' to use TMP_GMP_DECL(R, uint8_t); 
instead.

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210306094507</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-06 09:45:07-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I still have one uresolved comment about byte swapping but the rest
&gt; are resolved.

Thanks. I'll do this round of comments on email, since it might be of
interest to other contributors.

* About the byteswapping comment, the code

     // A = MSB(64, B) ^ t where t = (n*j)+i
     A64 = READ_UINT64(B.b);
     A64 ^= (n*j)+(i+1);
     WRITE_UINT64(A.b, A64);

could be replaced by something like

#if WORDS_BIGENDIAN
     A.u64 = B.u64 ^ (n*j)+(i+1);
#elif HAVE_BUILTIN_BSWAP64
     A.u64 = B.u64 ^ __builtin_bswap64((n*j)+(i+1));
#else
     ... READ_UINT64 / WRITE_UINT64 or some other workaround ...
#endif

Preferably encapsulated into a single macro, so it doesn't have to be
duplicated in both the wrap and the unwrap function. There's another
example of using __builtin_bswap64 in ctr.c.


* Intialization: If you don't intend to use the initial values, omit
initialization in declarations like

  union nettle_block16 I = {0}, B = {0};
  union nettle_block8 A = {0};

That helps tools like valgrind detect accidental use of uninitialized
data. (And then I'm not even sure exactly how initializers are
interpreted for a union type).

* Some or all memcpys in the main loop can be replaced by uint64_t
operations, e.g.,

  I.u64 = A.u64;

instead of 

  memcpy(I.b, A.b, 8);

(memcpy is needed when either left or right hand side is an unaligned
byte buffer). If it turns out that you never use .b on some variable,
you can drop the use of the union type for that variable and use
uint64_t directly.

&gt; Therefore I removed 'uint8_t R[64]' to use TMP_GMP_DECL(R, uint8_t);
&gt; instead.

Unfortunately, that doesn't work: This code should go into libnettle
(not libhogweed), and then it can't depend on GMP. You could do plain
malloc + free, but according to the README file, Nettle doesn't do
memory allocation, so that's not ideal.

I think it should be doable to reuse the output buffer as temporary
storage (R = ciphertext for wrap, R = cleartext for unwrap). In-place
operation (ciphertext == cleartext) should be supported (but no partial
overlap), so it's important to test that case.

Using the output area directly has the drawback that it isn't aligned,
so you'll need to keep some memcpys in the main loop. One could consider
using an aligned pointer into output buffer and separate handling of
first and/or last block, but if that's a lot of extra complexty, I
wouldn't do it unless either (i) it gives a significant performance
improvement, or (ii) it turns out to actually be reasonably nice and clean.

* And one more nit: Indentation. It's fine to use TAB characters, but
they must be assumed to be traditional TAB to 8 positions: changing the
appearance of TAB to anything else in one's editor is wrong, because it
makes the code look weird for everyone else (e.g., in gitlab's ui). And
the visual appearance should follow GNU standards, braces on their own
lines, indent steps of two spaces, which means usually SPC characters,
with TAB only for large indentation.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210306154416</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-06 15:44:16-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I haven't made all the changes you requested but here's my situation.

Le 2021-03-06 Ã  04 h 45, Niels MÃ¶ller a Ã©crit  :
&gt; Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:
&gt; 
&gt; 
&gt; * About the byteswapping comment, the code
&gt; 
&gt;       // A = MSB(64, B) ^ t where t = (n*j)+i
&gt;       A64 = READ_UINT64(B.b);
&gt;       A64 ^= (n*j)+(i+1);
&gt;       WRITE_UINT64(A.b, A64);
&gt; 
&gt; could be replaced by something like
&gt; 
&gt; #if WORDS_BIGENDIAN
&gt;       A.u64 = B.u64 ^ (n*j)+(i+1);
&gt; #elif HAVE_BUILTIN_BSWAP64
&gt;       A.u64 = B.u64 ^ __builtin_bswap64((n*j)+(i+1));
&gt; #else
&gt;       ... READ_UINT64 / WRITE_UINT64 or some other workaround ...
&gt; #endif
&gt; 
The problem I have with this is the type of A and B: nettle_block8 and 
nettle_block16, and in nettle_block16, u64 is declared as 'uint64_t u64[2];'

So do I need to choose B.u64[0] or B.u64[1] depending on the architecture?

&gt; Preferably encapsulated into a single macro, so it doesn't have to be
&gt; duplicated in both the wrap and the unwrap function. There's another
&gt; example of using __builtin_bswap64 in ctr.c.
&gt; 
I've started something like that:

#if WORDS_BIGENDIAN
   #define MSB_XOR_T_WRAP(A, B, xor) A.u64 = B.u64 ^ (xor);
#elif HAVE_BUILTIN_BSWAP64
   #define MSB_XOR_T_WRAP(A, B, xor) A.u64 = B.u64 ^ 
__builtin_bswap64((xor));
#else
   #define MSB_XOR_T_WRAP(A, B, xor) \
   uint64_t A64_##A##; \
   A64_##A## = READ_UINT64 (B.b); \
   A64_##A## ^= (xor); \
   WRITE_UINT64 (A.b, A64_##A##); \
#endif

First I need to fix my B.u64 issue

&gt; 
&gt; * Intialization: If you don't intend to use the initial values, omit
&gt; initialization in declarations like
&gt; 
&gt;    union nettle_block16 I = {0}, B = {0};
&gt;    union nettle_block8 A = {0};
&gt; 
Fixed

&gt; * Some or all memcpys in the main loop can be replaced by uint64_t
&gt; operations, e.g.,
&gt; 
&gt;    I.u64 = A.u64;
&gt; 
&gt; instead of
&gt; 
&gt;    memcpy(I.b, A.b, 8);
&gt; 
I have the same problem with B.u64 being an array
&gt; 
&gt;&gt; Therefore I removed 'uint8_t R[64]' to use TMP_GMP_DECL(R, uint8_t);
&gt;&gt; instead.
&gt; 
&gt; Unfortunately, that doesn't work: This code should go into libnettle
&gt; (not libhogweed), and then it can't depend on GMP. You could do plain
&gt; malloc + free, but according to the README file, Nettle doesn't do
&gt; memory allocation, so that's not ideal.
&gt; 
&gt; I think it should be doable to reuse the output buffer as temporary
&gt; storage (R = ciphertext for wrap, R = cleartext for unwrap). In-place
&gt; operation (ciphertext == cleartext) should be supported (but no partial
&gt; overlap), so it's important to test that case.
&gt; 
I've updated the MR to reuse ciphertext or cleartext as R. The original 
test cases still pass, I'll have to complete the tests.

&gt; Using the output area directly has the drawback that it isn't aligned,
&gt; so you'll need to keep some memcpys in the main loop. One could consider
&gt; using an aligned pointer into output buffer and separate handling of
&gt; first and/or last block, but if that's a lot of extra complexty, I
&gt; wouldn't do it unless either (i) it gives a significant performance
&gt; improvement, or (ii) it turns out to actually be reasonably nice and clean.
&gt; 
I'll rely on your wisdom about that if you don't mind

&gt; * And one more nit: Indentation. It's fine to use TAB characters, but
&gt; they must be assumed to be traditional TAB to 8 positions: changing the
&gt; appearance of TAB to anything else in one's editor is wrong, because it
&gt; makes the code look weird for everyone else (e.g., in gitlab's ui). And
&gt; the visual appearance should follow GNU standards, braces on their own
&gt; lines, indent steps of two spaces, which means usually SPC characters,
&gt; with TAB only for large indentation.
&gt; 
I agree, I've updated the indentation using gnu indent with gnu style

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210306162700</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-06 16:27:00-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I haven't made all the changes you requested but here's my situation.
&gt;
&gt; Le 2021-03-06 Ã  04 h 45, Niels MÃ¶ller a Ã©crit  :
&gt;&gt; Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:
&gt;&gt;
&gt;&gt;
&gt;&gt; * About the byteswapping comment, the code
&gt;&gt;
&gt;&gt;       // A = MSB(64, B) ^ t where t = (n*j)+i
&gt;&gt;       A64 = READ_UINT64(B.b);
&gt;&gt;       A64 ^= (n*j)+(i+1);
&gt;&gt;       WRITE_UINT64(A.b, A64);
&gt;&gt;
&gt;&gt; could be replaced by something like
&gt;&gt;
&gt;&gt; #if WORDS_BIGENDIAN
&gt;&gt;       A.u64 = B.u64 ^ (n*j)+(i+1);
&gt;&gt; #elif HAVE_BUILTIN_BSWAP64
&gt;&gt;       A.u64 = B.u64 ^ __builtin_bswap64((n*j)+(i+1));
&gt;&gt; #else
&gt;&gt;       ... READ_UINT64 / WRITE_UINT64 or some other workaround ...
&gt;&gt; #endif
&gt;&gt;
&gt; The problem I have with this is the type of A and B: nettle_block8 and
&gt; nettle_block16, and in nettle_block16, u64 is declared as 'uint64_t
&gt; u64[2];'
&gt;
&gt; So do I need to choose B.u64[0] or B.u64[1] depending on the architecture?

As far as I understand, B.u64[0] would be right in all cases. That
represents the first 8 bytes of B.b, interpreted as a 64-bit number in
platform-dependant endianness. Which is the same data accessed (using
big-endian, regardless of platform) by the READ_UINT64 version.

&gt;&gt; * Some or all memcpys in the main loop can be replaced by uint64_t
&gt;&gt; operations, e.g.,
&gt;&gt;
&gt;&gt;    I.u64 = A.u64;
&gt;&gt;
&gt;&gt; instead of
&gt;&gt;
&gt;&gt;    memcpy(I.b, A.b, 8);
&gt;&gt;
&gt; I have the same problem with B.u64 being an array

.u64[0] for bytes 0--7, .u64[1] for bytes 8--15.

&gt; I've updated the MR to reuse ciphertext or cleartext as R. The
&gt; original test cases still pass, I'll have to complete the tests.

Hmm. I think you should leave the input buffer untouched, with type
const uint8_t*, and only use the *output* area for temporary storage.

In the in-place case, those will be the same and the code needs to
handle that case, but if caller passes separate input and output
buffers, the input should not be modified.

&gt;&gt; Using the output area directly has the drawback that it isn't aligned,
&gt;&gt; so you'll need to keep some memcpys in the main loop. One could consider
&gt;&gt; using an aligned pointer into output buffer and separate handling of
&gt;&gt; first and/or last block, but if that's a lot of extra complexty, I
&gt;&gt; wouldn't do it unless either (i) it gives a significant performance
&gt;&gt; improvement, or (ii) it turns out to actually be reasonably nice and clean.
&gt;&gt;
&gt; I'll rely on your wisdom about that if you don't mind

That's fine for now. We might try out the more complex way later.

&gt; I agree, I've updated the indentation using gnu indent with gnu style

Thanks. One peculiarity with the gnu style is the space between function
name and open parenthesis (which you have after reindent). Nettle isn't
quite consistent, but new code mostly follows this convention.

Regards,
/Niels

-- 
Niels MÃ¶ller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210306204855</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-06 20:48:55-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

On Tue, Feb 2, 2021 at 5:44 PM Nicolas Mora &lt;nicolas@babelouest.org&gt; wrote:
&gt;
&gt; Hello,
&gt;
&gt; I've added a merge request to implement AES key wrap and unwrap in
&gt; Nettle [1].
&gt;
&gt; The MR is not complete, because the tests haven't been pushed yet and
&gt; the documentation is missing, but if the new functionality is welcome to
&gt; Nettle, I'd rather have some feedback on the code first, to make sure it
&gt; respects the project guidelines.
&gt;
&gt; I can add tests based on the tests vectors in the RFC [2], but I'm not
&gt; sure how the test suites are build, should I need to create test_wrap
&gt; functions like in aes-test.c or something else?

One small comment... It may be useful to provide RFC 5469 Key Wrap.
RFC 5469 provides a little more flexibility in the size of the secret
being wrapped.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210306221907</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-06 22:19:07-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello

Current status update

Le 2021-03-06 Ã  11 h 27, Niels MÃ¶ller a Ã©crit  :

&gt;&gt;&gt;        // A = MSB(64, B) ^ t where t = (n*j)+i
&gt;&gt;&gt;        A64 = READ_UINT64(B.b);
&gt;&gt;&gt;        A64 ^= (n*j)+(i+1);
&gt;&gt;&gt;        WRITE_UINT64(A.b, A64);
&gt;&gt;&gt;
I've added 2 macros definitions: MSB_XOR_T_WRAP and MSB_XOR_T_UNWRAP, I 
couldn't find how to make just one macro for both cases because of the 
direction of the xor.

&gt;&gt; I have the same problem with B.u64 being an array
&gt; 
&gt; .u64[0] for bytes 0--7, .u64[1] for bytes 8--15.
&gt; 
OK, I can set all .u64[0], but when it comes to .u64[1], I have a 
different behavior, example:

memcpy (I.b + 8, R + (i * 8), 8); // This one works
I.u64[1] = *(R + (i * 8)); // This one doesn't work

Is there something I'm missing?

&gt;&gt; I agree, I've updated the indentation using gnu indent with gnu style
&gt; 
&gt; Thanks. One peculiarity with the gnu style is the space between function
&gt; name and open parenthesis (which you have after reindent). Nettle isn't
&gt; quite consistent, but new code mostly follows this convention.
&gt; 
No problem, keeping the code style consistent is very important for 
maintenance.

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210307000822</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-07 00:08:22-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello again,

Le 2021-03-06 Ã  11 h 27, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt;&gt; I've updated the MR to reuse ciphertext or cleartext as R. The
&gt;&gt; original test cases still pass, I'll have to complete the tests.
&gt; 
&gt; Hmm. I think you should leave the input buffer untouched, with type
&gt; const uint8_t*, and only use the *output* area for temporary storage.
&gt; 
&gt; In the in-place case, those will be the same and the code needs to
&gt; handle that case, but if caller passes separate input and output
&gt; buffers, the input should not be modified.
&gt; 
I feel ashamed for that one :p

I've reverted the changes to use the output buffer as the intermediate 
value instead.

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210307151156</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-07 15:11:56-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; memcpy (I.b + 8, R + (i * 8), 8); // This one works
&gt; I.u64[1] = *(R + (i * 8)); // This one doesn't work
&gt;
&gt; Is there something I'm missing?

The reason it doesn't work is the type of R. R is now an unaligned
uint8_t *. *(R + (i * 8)) (the same as R[i*8]) is an uint8_t, not an
uint64_t.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210307152617</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-07 15:26:17-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I've added 2 macros definitions: MSB_XOR_T_WRAP and MSB_XOR_T_UNWRAP,
&gt; I couldn't find how to make just one macro for both cases because of
&gt; the direction of the xor.

Hmm. Maybe better to define an optional swap operation. Like

#if WORDS_BIGENDIAN
#define bswap_if_le(x) (x)
#elif HAVE_BUILTIN_BSWAP64
#define bswap_if_le(x) (__builtin_bswap64 (x))
#else
static uint64_t
bswap_if_le(uint64_t x) 
{
  x = ((x &gt;&gt; 32) &amp; UINT64_C(0xffffffff)) 
           | ((x &amp; UINT64_C(0xffffffff)) &lt;&lt; 32);
  x = ((x &gt;&gt; 16) &amp; UINT64_C(0xffff0000ffff)) 
           | ((x &amp; UINT64_C(0xffff0000ffff)) &lt;&lt; 16);
  x = ((x &gt;&gt; 8)  &amp; UINT64_C(0xff00ff00ff00ff)) 
           | ((x &amp; UINT64_C(0xff00ff00ff00ff)) &lt;&lt; 8);
  return x;
}
#endif

and then use as 

  B.u64[0] = A.u64 ^ bswap_if_le((n * j) + (i + 1));

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210307212216</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-07 21:22:16-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

Le 2021-03-07 Ã  10 h 26, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt; Hmm. Maybe better to define an optional swap operation. Like
&gt; 
Thanks a lot for that, I wouldn't be able to come up with it by myself...

 &gt; The reason it doesn't work is the type of R. R is now an unaligned
 &gt; uint8_t *. *(R + (i * 8)) (the same as R[i*8]) is an uint8_t, not an
 &gt; uint64_t.

I forgot to check the types, thanks for the explanation!

I've updated the code with the new bswap_if_le and removed the commented 
code.

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210328151045</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-28 15:10:45-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I've updated the code with the new bswap_if_le and removed the
&gt; commented code.

Hi, I haven't been paying attention to this for a few weeks, but I've
had a nother look now. I've left a few comments on the MR.

For testing, it's important to test both in-place operation (that should
be supported, right? Following the conventions documented at
https://www.lysator.liu.se/~nisse/nettle/nettle.html#Conventions), and
separate input and output area.

For the tests of unwrap, it is important to test the error case, i.e.,
try changing some bit in the input, and verify that unwrap returns an
error.

The new feature also needs documentation, will you look into that once
code, and in particular the interfaces, are solid?

Regards,
/Niels



-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328204720</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-03-28 20:47:20-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

Le 2021-03-28 Ã  11 h 10, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt; Hi, I haven't been paying attention to this for a few weeks, but I've
&gt; had a nother look now. I've left a few comments on the MR.
&gt; 
Thanks, I've made the requested changes in the MR.

&gt; For testing, it's important to test both in-place operation (that should
&gt; be supported, right? Following the conventions documented at
&gt; https://www.lysator.liu.se/~nisse/nettle/nettle.html#Conventions), and
&gt; separate input and output area.
&gt; 
&gt; For the tests of unwrap, it is important to test the error case, i.e.,
&gt; try changing some bit in the input, and verify that unwrap returns an
&gt; error.
&gt; 
No problem, I'll add more test cases with expected errors on unwrap. 
I'll also make changes to fit the convention if needed. (I used 
aes-test.c as starting point to write the aes-keywrap-test.c)

&gt; The new feature also needs documentation, will you look into that once
&gt; code, and in particular the interfaces, are solid?
&gt; 
Definitely!
What do you think the documentation should look like? Should it be near 
paragraph 7.2.1? Like

7.2.1.1 AES Key Wrap

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210329173203</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-29 17:32:03-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt;&gt; The new feature also needs documentation, will you look into that once
&gt;&gt; code, and in particular the interfaces, are solid?
&gt;&gt;
&gt; Definitely!
&gt; What do you think the documentation should look like? Should it be
&gt; near paragraph 7.2.1? Like
&gt;
&gt; 7.2.1.1 AES Key Wrap

That's one possibility, but I think it would also be natural to put it
somewhere under or close to "7.4. Authenticated encryption and
associated data", even though there's no associated data. That section
could perhaps be retitled to "Authenticated encryption" to generalize
it?

Or possibly under "7.3 Cipher modes", if it's too different from the
AEAD constructions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405131656</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-04-05 13:16:56-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I've added test cases to verify that unwrap fail if the input values are 
incorrect [1]. I reuse all the unwrap test cases, changed one ciphertext 
byte and expect the unwrap function to return 0.

Le 2021-03-29 Ã  13 h 32, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt; That's one possibility, but I think it would also be natural to put it
&gt; somewhere under or close to "7.4. Authenticated encryption and
&gt; associated data", even though there's no associated data. That section
&gt; could perhaps be retitled to "Authenticated encryption" to generalize
&gt; it?
&gt; 
&gt; Or possibly under "7.3 Cipher modes", if it's too different from the
&gt; AEAD constructions.
&gt; 
Until we come to a solution on where to put the documentation, I've 
started a first draft for the documentation. Can you give me feedback on it?
I'm used to write documentation but for my projects and with my style, 
but I don't know if the text is too much or too few.

Also, I've never used LaTex. What tool do you recommend to write LaTex 
documentation? I've tried gummi but it says there are errors in the 
nettle.texinfo file...

/Nicolas

[1] 
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19/diffs#2c39052896159220aa30be267faae43df72f2fb8_0_223



["aes-keywrap-doc.txt" (text/plain)]

X.X.X NIST AES Keywrap

AES keywrap is a key management algorithm defined in RFC 3394. Its intention is to \
provide an algorithm to wrap and unwrap cryptographic keys. It requires an AES key \
(128, 192 or 256-bits), an 8-bytes IV, the data to encrypt is n blocks of 8-bytes. \
The wrap output is n+1 blocks of 8-bytes.

The default IV specified by the standard is A6A6A6A6A6A6A6A6.

X.X.X.1 General NIST AES Keywrap interface

Function: void nist_keywrap16 (const void *ctx, nettle_cipher_func *encrypt, const \
uint8_t *iv, size_t ciphertext_length, uint8_t *ciphertext, const uint8_t \
*cleartext);

Wraps *cleartext. The AES context *ctx struct aes128_ctx, struct aes192_ctx or struct \
aes256_ctx must be initialized with the cypher key. The *encrypt function is the \
aes{128,192,256}_encrypt function corresponding to the AES context size. *iv is the \
initialization vector, a 8-bytes value. *cleartext length must be at least \
ciphertext_length+8.

Function: int nist_keyunwrap16 (const void *ctx, nettle_cipher_func *decrypt, const \
uint8_t *iv, size_t cleartext_length, uint8_t *cleartext, const uint8_t *ciphertext);

Unwraps *ciphertext. The AES context *ctx struct aes128_ctx, struct aes192_ctx or \
struct aes256_ctx must be initialized with the decypher key. The *decrypt function is \
the aes{128,192,256}_decrypt function corresponding to the AES context size. *iv is \
the initialization vector, a 8-bytes value. *ciphertext length must be \
cleartext_length-8. Returns 1 on unwrap success, 0 on unwrap error.

X.X.X.2 Specific context NIST AES Keywrap interface

Function: void aes128_keywrap (struct aes128_ctx *ctx, const uint8_t *iv, size_t \
                ciphertext_length, uint8_t *ciphertext, const uint8_t *cleartext);
Function: void aes192_keywrap (struct aes192_ctx *ctx, const uint8_t *iv, size_t \
                ciphertext_length, uint8_t *ciphertext, const uint8_t *cleartext);
Function: void aes256_keywrap (struct aes256_ctx *ctx, const uint8_t *iv, size_t \
ciphertext_length, uint8_t *ciphertext, const uint8_t *cleartext);

The AES context *ctx must be initialized with the cypher key. *iv is the \
initialization vector, a 8-bytes value. *cleartext length must be at least \
ciphertext_length+8.

Function: int aes128_keyunwrap (struct aes128_ctx *ctx, const uint8_t *iv, size_t \
                cleartext_length, uint8_t *cleartext, const uint8_t *ciphertext);
Function: int aes192_keyunwrap (struct aes192_ctx *ctx, const uint8_t *iv, size_t \
                cleartext_length, uint8_t *cleartext, const uint8_t *ciphertext);
Function: int aes256_keyunwrap (struct aes256_ctx *ctx, const uint8_t *iv, size_t \
cleartext_length, uint8_t *cleartext, const uint8_t *ciphertext);

The AES context *ctx must be initialized with the decypher key. *iv is the \
initialization vector, a 8-bytes value. *ciphertext length must be \
cleartext_length-8. Returns 1 on unwrap success, 0 on unwrap error.


["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #11 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210407120923</emailId><senderName>Aapo Talvensaari</senderName><senderEmail>aapo.talvensaari@gmail.com</senderEmail><timestampReceived>2021-04-07 12:09:23-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

On Mon, Apr 5, 2021 at 4:17 PM Nicolas Mora &lt;nicolas@babelouest.org&gt; wrote:

&gt; Until we come to a solution on where to put the documentation, I've
&gt; started a first draft for the documentation. Can you give me feedback on
&gt; it?
&gt;

It says: "*ciphertext length must be cleartext_length-8" but shouldn't that
be:
"*ciphertext length must be cleartext_length+8"?
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210121075322</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-21 07:53:22-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Any update on this? Is there anything missed in my side?

I'm a bit concerned about testing, and missing qemu support. I guess
we'll have to do with manual tests, but I won't be able to do that
regularly myself. Sorry for the delay.

Du you think it would be useful to setup a ci build, even if it has to
disable the asm code at compile time or runtime? That would at least
give some coverage to configure and fat logic.

I would also prefer to get the basic AES functions in (aes128.asm,
aes192.asm, aes256.asm), before considering combined aes-mode functions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210121135630</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-01-21 13:56:30-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Thu, Jan 21, 2021 at 2:53 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Any update on this? Is there anything missed in my side?
&gt;
&gt; I'm a bit concerned about testing, and missing qemu support. I guess
&gt; we'll have to do with manual tests, but I won't be able to do that
&gt; regularly myself. Sorry for the delay.

The Nettle project can access the LinuxONE Community Cloud at Marist
for the long-term to run manual or automated CI testing.  Jenkins and
Travis CI are available, in addition to anything that you want to
configure in your instance.

QEMU or emulators on non-IBM hardware are not an option for these features.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210121150502</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-21 15:05:02-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Thanks for the info, I'll see how I can integrate LinuxONE Community Cloud
to nettle CI for automated testing.

regards,
Mamone

On Thu, Jan 21, 2021 at 3:56 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:

&gt; On Thu, Jan 21, 2021 at 2:53 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; Any update on this? Is there anything missed in my side?
&gt; &gt;
&gt; &gt; I'm a bit concerned about testing, and missing qemu support. I guess
&gt; &gt; we'll have to do with manual tests, but I won't be able to do that
&gt; &gt; regularly myself. Sorry for the delay.
&gt;
&gt; The Nettle project can access the LinuxONE Community Cloud at Marist
&gt; for the long-term to run manual or automated CI testing.  Jenkins and
&gt; Travis CI are available, in addition to anything that you want to
&gt; configure in your instance.
&gt;
&gt; QEMU or emulators on non-IBM hardware are not an option for these features.
&gt;
&gt; Thanks, David
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210121220452</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-21 22:04:52-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

I managed to integrate an instance of LinuxONE Community Cloud to nettle
CI, I can't make a merge request for it because it has manual steps so I'll
write a guide for it. The integration process is pretty straightforward and
it can be done by following these steps:
- Create a free account here
https://linuxone.cloud.marist.edu/#/register?flag=VM and make an instance
(All instances are z15 so it supports all the current implemented features).
- run the following commands in the instance:

   - mkdir nettle &amp;&amp; cd nettle
   - git init
   - git remote add origin https://gitlab.com/nettle/nettle.git

- In gitlab go to settings -&gt; CI / CD. Expand Variables and add variable,
Key: SSH_PRIVATE_KEY, Value: (Set the private key here)
- Update gitlab-ci.yml as follows (assisted by this recip
https://medium.com/@hfally/a-gitlab-ci-config-to-deploy-to-your-server-via-ssh-43bf3cf93775
):

   - Add this line to variables category:

  DEBIAN_BUILD: buildenv-debian

   - Add these lines to the end of file

Debian.remote.s390x:
  image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$DEBIAN_BUILD
  before_script:
  - apt-get update -qq
  - apt-get install -qq git
  - 'which ssh-agent || ( apt-get install -qq openssh-client )'
  - eval $(ssh-agent -s)
  - ssh-add &lt;(echo "$SSH_PRIVATE_KEY")
  - mkdir -p ~/.ssh
  - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" &gt; ~/.ssh/config
  script:
  - ssh linux1@IP_ADDRESS "cd nettle &amp;&amp; git pull origin s390x --rebase &amp;&amp;
./.bootstrap &amp;&amp; ./configure --enable-fat &amp;&amp; make &amp;&amp; make check &amp;&amp; exit"
  tags:
  - shared
  - linux
  except:
  - tags

Note: Replace IP_ADDRESS with ip address of instance.

On Thu, Jan 21, 2021 at 5:05 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; Thanks for the info, I'll see how I can integrate LinuxONE Community Cloud
&gt; to nettle CI for automated testing.
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt; On Thu, Jan 21, 2021 at 3:56 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt;
&gt;&gt; On Thu, Jan 21, 2021 at 2:53 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt; &gt;
&gt;&gt; &gt; &gt; Any update on this? Is there anything missed in my side?
&gt;&gt; &gt;
&gt;&gt; &gt; I'm a bit concerned about testing, and missing qemu support. I guess
&gt;&gt; &gt; we'll have to do with manual tests, but I won't be able to do that
&gt;&gt; &gt; regularly myself. Sorry for the delay.
&gt;&gt;
&gt;&gt; The Nettle project can access the LinuxONE Community Cloud at Marist
&gt;&gt; for the long-term to run manual or automated CI testing.  Jenkins and
&gt;&gt; Travis CI are available, in addition to anything that you want to
&gt;&gt; configure in your instance.
&gt;&gt;
&gt;&gt; QEMU or emulators on non-IBM hardware are not an option for these
&gt;&gt; features.
&gt;&gt;
&gt;&gt; Thanks, David
&gt;&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203154659</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-03 15:46:59-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Debian.remote.s390x:
&gt;   image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$DEBIAN_BUILD
&gt;   before_script:
&gt;   - apt-get update -qq
&gt;   - apt-get install -qq git
&gt;   - 'which ssh-agent || ( apt-get install -qq openssh-client )'
&gt;   - eval $(ssh-agent -s)
&gt;   - ssh-add &lt;(echo "$SSH_PRIVATE_KEY")
&gt;   - mkdir -p ~/.ssh
&gt;   - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" &gt; ~/.ssh/config
&gt;   script:
&gt;   - ssh linux1@IP_ADDRESS "cd nettle &amp;&amp; git pull origin s390x --rebase &amp;&amp;
&gt; ./.bootstrap &amp;&amp; ./configure --enable-fat &amp;&amp; make &amp;&amp; make check &amp;&amp; exit"
&gt;   tags:
&gt;   - shared
&gt;   - linux
&gt;   except:
&gt;   - tags

It looks like this hardcodes the branch to test ("s390x"), while the ci
jobs usually runs on all branches. It also doesn't clean up the remote
state between builds.

I wonder if it would be more reliable to run make dist
PACKAGE_VERSION=snapshot on the ci build machine, and copy the resulting
tarball to the remote machine for build and test. The commands run on the
remote machine should unpack the snapshot in a fresh directory, run
configure, make, make check.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203161300</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-03 16:13:00-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; Thanks for setting this up.  The default accounts have a limited time
&gt; (90 days?).  For long-term CI access, I can help request a long-term
&gt; account for Nettle.

That would be helpful. 

I've had look at the terms and conditions,
http://security.marist.edu/LinuxOne/TC.PDF. Most of it looks very
reasonable, but there are a few items that I find a bit unclear:

9. [...] You agree to obey all relevant New York State and US laws,
   including all export controls laws.

My understanding is that US export control laws don't apply to FOSS
software (and that's why, e.g., Debian no longer have special non-us
mirrors for distributing cryptographic software). But I don't know the
details, and if there really isn't a problem, why is it mentioned
explicitly in the terms and conditions?

10 [...] d. To protect your LinuxOne Account, keep your Secure Shell
   (SSH) keys confidential. You are responsible for the activity that
   happens on or through your LinuxOne Account. 

Is it acceptable under these terms if I upload a private key to a CI
config that is part of the gnutls project hosted on gitlab.com?
Maamoun's suggested method was to add it as a "Variable" in the CI/CD
web config, I'm assuming that will not make it publicly visible (but I'd
need to double check).

I don't know precisely which individuals will get access to use the key
(and hence my account) if I do that, even though I expect it to be small
number of good people (admins of the gnutls project, and the key will
also be technically accessible by gitlab staff). 

   [...] Do not reuse your LinuxOne Account keys on third-party
   applications.

I also don't understand what "third-party applications" means in this
context, but I'd guess gitlab could be one?

Regards, 
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210203165112</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-02-03 16:51:12-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, Feb 3, 2021 at 11:13 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;  ...
&gt; I've had look at the terms and conditions,
&gt; http://security.marist.edu/LinuxOne/TC.PDF. Most of it looks very
&gt; reasonable, but there are a few items that I find a bit unclear:
&gt;
&gt; 9. [...] You agree to obey all relevant New York State and US laws,
&gt;    including all export controls laws.
&gt;
&gt; My understanding is that US export control laws don't apply to FOSS
&gt; software (and that's why, e.g., Debian no longer have special non-us
&gt; mirrors for distributing cryptographic software). But I don't know the
&gt; details, and if there really isn't a problem, why is it mentioned
&gt; explicitly in the terms and conditions?

IBM is a US company. It has to comply with the export laws.

For an open source project you have to email the encryption
coordinator (the NSA) with a link to the project's website and source
files. Also see
https://www.eff.org/deeplinks/2019/08/us-export-controls-and-published-encryption-source-code-explained.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405204957</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-04-05 20:49:57-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Thu, Apr 1, 2021 at 12:01 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I'll modify the patch of basic AES-128 optimized functions to be built on
&gt; top of the splitted aes functions.
&gt;

Done!
It works as a file-override basis. The patch also passes the testsuite and
yields expected benchmark numbers.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210501151122</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-01 15:11:22-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Hi Niels, hope you are doing well now
&gt; Any update on this patch?

Thanks, I'm feeling a lot better, although still a bit tired.

Is https://git.lysator.liu.se/nettle/nettle/-/merge_requests/23 still
the current code?

I hope to be back to reviewing pending patches soon, but I also got a
fairly serious bug report a few days ago that I need to attend to first.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210501153909</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-01 15:39:09-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sat, May 1, 2021 at 6:11 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Hi Niels, hope you are doing well now
&gt; &gt; Any update on this patch?
&gt;
&gt; Thanks, I'm feeling a lot better, although still a bit tired.


Good, I hope your recovery is going well.


&gt;
&gt; Is https://git.lysator.liu.se/nettle/nettle/-/merge_requests/23 still
&gt; the current code?
&gt;

Yes, it's still up to date.


&gt; I hope to be back to reviewing pending patches soon, but I also got a
&gt; fairly serious bug report a few days ago that I need to attend to first.
&gt;

No problem, take your time and take care.
I also want to say that the white paper "Optimize AES-GCM for PowerPC
architecture processor" is almost done and it looks great, I'm just doing
some polishing now. Hope we can get the pending patches done soon so we can
have time to review the research and the upcoming patches.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210508000258</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-08 00:02:58-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sat, May 1, 2021 at 6:11 PM Niels MÃ¶ller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Is https://git.lysator.liu.se/nettle/nettle/-/merge_requests/23 still
&gt; the current code?
&gt;

I've added the basic AES-192 and AES-256 too since there is no problem to
test them all together.

For the other the modes, I don't think we can continue with the
file-override basis to handle the optimized cores, if we take ccm-aes128.c
as example you will see it has 8 functions, separating them in one file
each is overkill so my approach to handle such case is to redefine the
function name of C file to not conflict with the name of optimized core in
case the optimized core is exit, this tricks is also used to support fat
build for functions because we need to keep the two functions (C and
optimized core) around to be picked at run-time.
So redefining the function name will avoid the conflict with the optimized
core and it's the first step to support fat build for that function, take a
look how I implemented this approach in ccm-aes128.c file
&lt;https://git.lysator.liu.se/mamonet/nettle/-/blob/s390x-aes/ccm-aes128.c#L52&gt;ccm-aes128.c
 · s390x-aes  · Maamoun TK / nettle  · GitLab (liu.se)
&lt;https://git.lysator.liu.se/mamonet/nettle/-/blob/s390x-aes/ccm-aes128.c#L48-53&gt;

&lt;https://git.lysator.liu.se/mamonet/nettle/-/blob/s390x-aes/ccm-aes128.c#L52&gt;
regards,
Mamone
&lt;https://git.lysator.liu.se/mamonet/nettle/-/blob/s390x-aes/ccm-aes128.c#L52&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210508182409</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-08 18:24:09-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; Thanks for setting this up.  The default accounts have a limited time
&gt; (90 days?).  For long-term CI access, I can help request a long-term
&gt; account for Nettle.

Hi, I set up the s390x vm for Nettle ci tests late March. What
information do you need to arrange an extension to long-term access, so
it doesn't expire?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210508204043</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-05-08 20:40:43-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Sat, May 8, 2021 at 2:24 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; Thanks for setting this up.  The default accounts have a limited time
&gt; &gt; (90 days?).  For long-term CI access, I can help request a long-term
&gt; &gt; account for Nettle.
&gt;
&gt; Hi, I set up the s390x vm for Nettle ci tests late March. What
&gt; information do you need to arrange an extension to long-term access, so
&gt; it doesn't expire?

With what email address is the account associated?  With the same one
as this email message? nisse (at) lysator?

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210510085341</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-10 08:53:41-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

I made a new merge request to s390x branch Add AES API for CBC mode (!24)  ·
Merge requests  · Nettle / nettle  · GitLab (liu.se)
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/24&gt;
This api is required to handle the optimized CBC cores which will be added
later.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210519074909</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-19 07:49:09-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Hi, Niels

Did you get the credentials of the new VM? I'm thinking after adding the
address and ssh key of new VM, we can't get the optimized cores of AES
tested since enable-msa isn't triggered. We need to push some sort of
hard-coded option in configure.ac to get it tested in the VM during ci job.

regards,
Mamone

On Mon, May 10, 2021 at 6:13 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; They are going to create a new VM on a separate Open Source Software
&gt; &gt; Cloud for long-term projects.  They will contact you directly with the
&gt; &gt; credentials.
&gt;
&gt; Sounds good. Thanks for the update.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210519162016</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-05-19 16:20:16-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Did you get the credentials of the new VM? 

Yes! I set it up and updated the gitlab config last evening, and I've
seen a successfull ci run.

&gt; I'm thinking after adding the
&gt; address and ssh key of new VM, we can't get the optimized cores of AES
&gt; tested since enable-msa isn't triggered. We need to push some sort of
&gt; hard-coded option in configure.ac to get it tested in the VM during ci job.

We could either switch it on by default in configure.ac, or add a
configure flag in .gitlab-ci.

Once fat build support is added, we will no longer to enable it
explicitly, right?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210519193109</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-05-19 19:31:09-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, May 19, 2021 at 7:20 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt; I'm thinking after adding the
&gt; &gt; address and ssh key of new VM, we can't get the optimized cores of AES
&gt; &gt; tested since enable-msa isn't triggered. We need to push some sort of
&gt; &gt; hard-coded option in configure.ac to get it tested in the VM during ci
&gt; job.
&gt;
&gt; We could either switch it on by default in configure.ac, or add a
&gt; configure flag in .gitlab-ci.
&gt;
&gt; Once fat build support is added, we will no longer to enable it
&gt; explicitly, right?
&gt;

Right, I prefer to get done with AES accelerators then add fat build
support for the added modes at once because of dependency relationships for
these modes that add more complexity to s390x-fat.c.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061514</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:14-0400</timestampReceived><subject>[RFC PATCH 3/6] ppc: Add FAT feature and config option for ISA 3.0</subject><body>

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 configure.ac |  9 ++++++++-
 fat-ppc.c    | 12 ++++++++++++
 2 files changed, 20 insertions(+), 1 deletion(-)

diff --git a/configure.ac b/configure.ac
index 253735a7..a0df0cc8 100644
--- a/configure.ac
+++ b/configure.ac
@@ -101,6 +101,10 @@ AC_ARG_ENABLE(power-altivec,
   AC_HELP_STRING([--enable-power-altivec], [Enable POWER altivec and vsx extensions. (default=no)]),,
   [enable_power_altivec=no])
 
+AC_ARG_ENABLE(power-isa-30,
+  AC_HELP_STRING([--enable-power-isa-30], [Enable POWER ISA 3.0 (POWER9) features. (default=no)]),,
+  [enable_power_isa_30=no])
+
 AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of libgmp.]),,
   [enable_mini_gmp=no])
@@ -501,8 +505,11 @@ if test "x$enable_assembler" = xyes ; then
 	if test "x$enable_fat" = xyes ; then
 	  asm_path="powerpc64/fat $asm_path"
 	  OPT_NETTLE_SOURCES="fat-ppc.c $OPT_NETTLE_SOURCES"
-	  FAT_TEST_LIST="none crypto_ext altivec"
+	  FAT_TEST_LIST="none crypto_ext altivec isa_30"
 	else
+	  if test "$enable_power_isa_30" = yes ; then
+	    asm_path="powerpc64/p9 $asm_path"
+	  fi
 	  if test "$enable_power_crypto_ext" = yes ; then
             asm_path="powerpc64/p8 $asm_path"
 	  fi
diff --git a/fat-ppc.c b/fat-ppc.c
index 3adbb88c..67ef46ab 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -78,11 +78,15 @@
 #ifndef PPC_FEATURE2_VEC_CRYPTO
 #define PPC_FEATURE2_VEC_CRYPTO 0x02000000
 #endif
+#ifndef PPC_FEATURE2_ARCH_3_00
+#define PPC_FEATURE2_ARCH_3_00 0x00800000
+#endif
 
 struct ppc_features
 {
   int have_crypto_ext;
   int have_altivec;
+  int have_isa_30;
 };
 
 #define MATCH(s, slen, literal, llen) \
@@ -94,6 +98,7 @@ get_ppc_features (struct ppc_features *features)
   const char *s;
   features-&gt;have_crypto_ext = 0;
   features-&gt;have_altivec = 0;
+  features-&gt;have_isa_30 = 0;
 
   s = secure_getenv (ENV_OVERRIDE);
   if (s)
@@ -106,6 +111,8 @@ get_ppc_features (struct ppc_features *features)
 	  features-&gt;have_crypto_ext = 1;
 	else if (MATCH(s, length, "altivec", 7))
 	  features-&gt;have_altivec = 1;
+	else if (MATCH(s, length, "isa_30", 6))
+	  features-&gt;have_isa_30 = 1;
 	if (!sep)
 	  break;
 	s = sep + 1;
@@ -116,6 +123,8 @@ get_ppc_features (struct ppc_features *features)
       features-&gt;have_crypto_ext
 	= _system_configuration.implementation &gt;= 0x10000u;
       features-&gt;have_altivec = _system_configuration.vmx_version &gt; 1;
+      /* TODO: AIX magic bits to decode ISA 3.0 / POWER9 support */
+      features-&gt;have_isa_30 = 0;
 #else
       unsigned long hwcap = 0;
       unsigned long hwcap2 = 0;
@@ -141,6 +150,9 @@ get_ppc_features (struct ppc_features *features)
       features-&gt;have_altivec
 	= ((hwcap &amp; (PPC_FEATURE_HAS_ALTIVEC | PPC_FEATURE_HAS_VSX))
 	   == (PPC_FEATURE_HAS_ALTIVEC | PPC_FEATURE_HAS_VSX));
+
+      features-&gt;have_isa_30
+        = ((hwcap2 &amp; PPC_FEATURE2_ARCH_3_00) == PPC_FEATURE2_ARCH_3_00);
 #endif
     }
 }
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061515</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:15-0400</timestampReceived><subject>[RFC PATCH 4/6] ppc: Add gcm_aes_encrypt() asm for ISA 3.0 (P9)</subject><body>

This implementation is based on the existing, per-algorithm optimized
powerpc64/p8/aes-encrypt-internal.asm and powerpc64/p8/gcm-hash.asm
implementations by Niels Möller and Mamone Tarsha.

Significant changes:

  - Combine AES + GCM into a single function call which does up-to 8x
    unrolled AES followed by 2x 4x unrolled GCM back-to-back.
  - Handle the IV|CTR increment in assembly and avoid the somewhat
    costly gcm_fill() call to precalculate the counter values.
  - Use ISA 3.0 (P9) lxvb16x/stxvb16x to load/store unaligned VSX
    registers to avoid permutes on LE machines.
  - Use ISA 3.0 (P9) lxvll/stxvll to load/store left-aligned,
    zero-padded partial (&lt;16B) blocks.
  - Use ISA 3.0 (P9) lxv/stxv to load/store the non-volatile vector
    registers from/to the stack redzone to avoid using a GPR register as
    an index.

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 gcm.c                            |   4 +
 powerpc64/p9/gcm-aes-encrypt.asm | 666 +++++++++++++++++++++++++++++++
 2 files changed, 670 insertions(+)
 create mode 100644 powerpc64/p9/gcm-aes-encrypt.asm

diff --git a/gcm.c b/gcm.c
index 6fe25a01..39e7a7c7 100644
--- a/gcm.c
+++ b/gcm.c
@@ -61,8 +61,12 @@
    GCM_TABLE_BITS == 8 layout */
 #undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_aes_decrypt
+#undef HAVE_NATIVE_gcm_aes_encrypt
 #undef HAVE_NATIVE_fat_gcm_hash
 #undef HAVE_NATIVE_fat_gcm_init_key
+#undef HAVE_NATIVE_fat_gcm_aes_decrypt
+#undef HAVE_NATIVE_fat_gcm_aes_encrypt
 #endif
 
 #if !HAVE_NATIVE_gcm_hash
diff --git a/powerpc64/p9/gcm-aes-encrypt.asm b/powerpc64/p9/gcm-aes-encrypt.asm
new file mode 100644
index 00000000..43f577fa
--- /dev/null
+++ b/powerpc64/p9/gcm-aes-encrypt.asm
@@ -0,0 +1,666 @@
+C powerpc64/p9/gcm-aes-encrypt.asm
+
+ifelse(`
+   Copyright (C) 2020 Niels Möller and Mamone Tarsha
+   Copyright (C) 2021 Christopher M. Riedl
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+
+.file "gcm-aes-encrypt.asm"
+
+.text
+
+C void gcm_aes_encrypt(const struct gcm_key *key, union gcm_block *x,
+C                      size_t length, const uint8_t *src,
+C                      unsigned rounds, const uint32_t *keys,
+C                      uint8_t *dst, uint32_t *ctr)
+
+C Register usage:
+define(`SP',	`r1')
+define(`TOCP',	`r2')
+
+C Parameters:
+define(`TABLE',	`r3')
+define(`X',	`r4')	C Output GCM/Ghash tag
+define(`LENGTH',`r5')
+define(`SRC',	`r6')	C Plaintext input
+define(`ROUNDS',`r7')
+define(`KEYS',	`r8')
+define(`DST',	`r9')
+define(`PCTR',	`r10')	C Pointer to 12B IV and starting 4B ctr
+
+C GCM/Ghash:
+define(`POLY_L',`v0')
+define(`D',	`v1')
+define(`H1M',	`v6')
+define(`H1L',	`v7')
+define(`H2M',	`v8')
+define(`H2L',	`v9')
+define(`H3M',	`v10')
+define(`H3L',	`v11')
+define(`H4M',	`v12')
+define(`H4L',	`v13')
+define(`R',	`v14')
+define(`F',	`v15')
+define(`R2',	`v16')
+define(`F2',	`v17')
+define(`T',	`v18')
+define(`R3',	`v20')
+define(`F3',	`v21')
+define(`R4',	`v22')
+define(`F4',	`v23')
+
+C AES:
+define(`K',	`v25')
+define(`S0',	`v2')
+define(`S1',	`v3')
+define(`S2',	`v4')
+define(`S3',	`v5')
+define(`S4',	`v26')
+define(`S5',	`v27')
+define(`S6',	`v28')
+define(`S7',	`v29')
+define(`CTR',	`v30')
+define(`INC',	`v31')
+define(`C0',	`v14')
+define(`C1',	`v15')
+define(`C2',	`v16')
+define(`C3',	`v17')
+define(`C4',	`v20')
+define(`C5',	`v21')
+define(`C6',	`v22')
+define(`C7',	`v23')
+
+define(`LCNT',	`r14')
+define(`ZERO',	`v16')
+define(`POLY',	`v24')
+C misc: r15,r16,r17
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_aes_encrypt)
+
+	vxor		ZERO,ZERO,ZERO
+	subi		ROUNDS,ROUNDS,1		C Last AES round uses vcipherlast
+
+	C Store non-volatiles on the 288B stack redzone
+	std		r14,-8*1(SP)
+	std		r15,-8*2(SP)
+	std		r16,-8*3(SP)
+	std		r17,-8*4(SP)
+	stxv		VSR(v20),-16*3(SP)
+	stxv		VSR(v21),-16*4(SP)
+	stxv		VSR(v22),-16*5(SP)
+	stxv		VSR(v23),-16*6(SP)
+	stxv		VSR(v24),-16*7(SP)
+	stxv		VSR(v25),-16*8(SP)
+	stxv		VSR(v26),-16*9(SP)
+	stxv		VSR(v27),-16*10(SP)
+	stxv		VSR(v28),-16*11(SP)
+	stxv		VSR(v29),-16*12(SP)
+	stxv		VSR(v30),-16*13(SP)
+	stxv		VSR(v31),-16*14(SP)
+
+	DATA_LOAD_VEC(POLY,.polynomial,r14)
+	DATA_LOAD_VEC(INC,.increment,r14)
+
+	lxvb16x		VSR(CTR),0,PCTR		C Load 'ctr' pointer
+	xxmrghd		VSR(POLY_L),VSR(ZERO),VSR(POLY)
+	lxvb16x		VSR(D),0,X		C load 'X' pointer
+
+L8x:
+	C --- process 8 blocks '128-bit each' per one loop ---
+	srdi.		LCNT,LENGTH,7		C 8-blocks loop count 'LENGTH / (8 * 16)'
+	beq		L4x
+
+	C load table elements
+	li		r15,4*16
+	li		r16,5*16
+	li		r17,6*16
+	lxvd2x		VSR(H3M),r15,TABLE
+	lxvd2x		VSR(H3L),r16,TABLE
+	lxvd2x		VSR(H4M),r17,TABLE
+	li		r16,7*16
+	lxvd2x		VSR(H4L),r16,TABLE
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L8x_loop:
+L8x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		S0,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S0,S0,K
+	vmr		S1,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S1,S1,K
+	vmr		S2,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S2,S2,K
+	vmr		S3,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S3,S3,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+	vmr		S4,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S4,S4,K
+	vmr		S5,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S5,S5,K
+	vmr		S6,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S6,S6,K
+	vmr		S7,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		S7,S7,K
+
+.align 5
+L8x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	addi		r15,r15,1*16
+	vcipher		S0,S0,K
+	vcipher		S1,S1,K
+	vcipher		S2,S2,K
+	vcipher		S3,S3,K
+	vcipher		S4,S4,K
+	vcipher		S5,S5,K
+	vcipher		S6,S6,K
+	vcipher		S7,S7,K
+	bdnz		L8x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	S0,S0,K
+	vcipherlast	S1,S1,K
+	vcipherlast	S2,S2,K
+	vcipherlast	S3,S3,K
+	vcipherlast	S4,S4,K
+	vcipherlast	S5,S5,K
+	vcipherlast	S6,S6,K
+	vcipherlast	S7,S7,K
+
+	C AES(counter) XOR plaintext = ciphertext
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvb16x		VSR(C0),0,SRC
+	lxvb16x		VSR(C1),r15,SRC
+	lxvb16x		VSR(C2),r16,SRC
+	lxvb16x		VSR(C3),r17,SRC
+	vxor		S0,C0,S0
+	vxor		S1,C1,S1
+	vxor		S2,C2,S2
+	vxor		S3,C3,S3
+
+	addi		SRC,SRC,4*16
+	lxvb16x		VSR(C4),0,SRC
+	lxvb16x		VSR(C5),r15,SRC
+	lxvb16x		VSR(C6),r16,SRC
+	lxvb16x		VSR(C7),r17,SRC
+	vxor		S4,C4,S4
+	vxor		S5,C5,S5
+	vxor		S6,C6,S6
+	vxor		S7,C7,S7
+
+	C Store ciphertext 
+	stxvb16x	VSR(S0),0,DST
+	stxvb16x	VSR(S1),r15,DST
+	stxvb16x	VSR(S2),r16,DST
+	stxvb16x	VSR(S3),r17,DST
+	addi		DST,DST,4*16
+	stxvb16x	VSR(S4),0,DST
+	stxvb16x	VSR(S5),r15,DST
+	stxvb16x	VSR(S6),r16,DST
+	stxvb16x	VSR(S7),r17,DST
+
+	addi		SRC,SRC,4*16
+	addi		DST,DST,4*16
+
+L8x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S1
+	vpmsumd		R2,H3M,S1
+	vpmsumd		F3,H2L,S2
+	vpmsumd		R3,H2M,S2
+	vpmsumd		F4,H1L,S3
+	vpmsumd		R4,H1M,S3
+	vpmsumd		F,H4L,S0
+	vpmsumd		R,H4M,S0
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	C previous digest combining
+	vxor		S4,S4,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S5
+	vpmsumd		R2,H3M,S5
+	vpmsumd		F3,H2L,S6
+	vpmsumd		R3,H2M,S6
+	vpmsumd		F4,H1L,S7
+	vpmsumd		R4,H1M,S7
+	vpmsumd		F,H4L,S4
+	vpmsumd		R,H4M,S4
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	C Decrement 8x block count and check if done
+	subi		LCNT,LCNT,1
+	cmpldi		LCNT,0
+	bne		L8x_loop
+	clrldi		LENGTH,LENGTH,57	C 'set the high-order 57 bits to zeros'
+
+L4x:
+	C --- process 4 blocks --- 
+	srdi.		LCNT,LENGTH,6		C 4-blocks loop count 'LENGTH / (4 * 16)'
+	beq		L2x
+
+	C load table elements
+	li		r15,4*16
+	li		r16,5*16
+	li		r17,6*16
+	lxvd2x		VSR(H3M),r15,TABLE
+	lxvd2x		VSR(H3L),r16,TABLE
+	lxvd2x		VSR(H4M),r17,TABLE
+	li		r16,7*16
+	lxvd2x		VSR(H4L),r16,TABLE
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L4x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		S0,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		S1,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		S2,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		S3,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		S0,S0,K
+	vxor		S1,S1,K
+	vxor		S2,S2,K
+	vxor		S3,S3,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L4x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		S0,S0,K
+	vcipher		S1,S1,K
+	vcipher		S2,S2,K
+	vcipher		S3,S3,K
+	addi		r15,r15,1*16
+	bdnz		L4x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	S0,S0,K
+	vcipherlast	S1,S1,K
+	vcipherlast	S2,S2,K
+	vcipherlast	S3,S3,K
+
+	C AES(counter) XOR plaintext = ciphertext
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvb16x		VSR(C0),0,SRC
+	lxvb16x		VSR(C1),r15,SRC
+	lxvb16x		VSR(C2),r16,SRC
+	lxvb16x		VSR(C3),r17,SRC
+	vxor		S0,C0,S0
+	vxor		S1,C1,S1
+	vxor		S2,C2,S2
+	vxor		S3,C3,S3
+
+	C Store ciphertext in DST
+	stxvb16x	VSR(S0),0,DST
+	stxvb16x	VSR(S1),r15,DST
+	stxvb16x	VSR(S2),r16,DST
+	stxvb16x	VSR(S3),r17,DST
+
+L4x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S1
+	vpmsumd		R2,H3M,S1
+	vpmsumd		F3,H2L,S2
+	vpmsumd		R3,H2M,S2
+	vpmsumd		F4,H1L,S3
+	vpmsumd		R4,H1M,S3
+	vpmsumd		F,H4L,S0
+	vpmsumd		R,H4M,S0
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,4*16
+	addi		SRC,SRC,4*16
+	clrldi		LENGTH,LENGTH,58	C 'set the high-order 58 bits to zeros'
+
+L2x:
+	C --- process 2 blocks ---
+	srdi.		r14,LENGTH,5		C 'LENGTH / (2 * 16)'
+	beq		L1x
+
+	C load table elements
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L2x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		S0,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		S1,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		S0,S0,K
+	vxor		S1,S1,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L2x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		S0,S0,K
+	vcipher		S1,S1,K
+	addi		r15,r15,1*16
+	bdnz		L2x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	S0,S0,K
+	vcipherlast	S1,S1,K
+
+	C AES(counter) XOR plaintext = ciphertext
+	li		r15,1*16
+	lxvb16x		VSR(C0),0,SRC
+	lxvb16x		VSR(C1),r15,SRC
+	vxor		S0,C0,S0
+	vxor		S1,C1,S1
+
+	C Store ciphertext in DST
+	stxvb16x	VSR(S0),0,DST
+	stxvb16x	VSR(S1),r15,DST
+
+L2x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H1L,S1
+	vpmsumd		R2,H1M,S1
+	vpmsumd		F,H2L,S0
+	vpmsumd		R,H2M,S0
+
+	C deferred recombination of partial products
+	vxor		F,F,F2
+	vxor		R,R,R2
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,2*16
+	addi		SRC,SRC,2*16
+	clrldi		LENGTH,LENGTH,59	C 'set the high-order 59 bits to zeros'
+
+L1x:
+	C --- process 1 block ---
+	srdi.		r14,LENGTH,4		C 'LENGTH / (1 * 16)'
+	beq		Lpartial
+
+	C load table elements
+	li		r15,1*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+
+L1x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		S0,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		S0,S0,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L1x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		S0,S0,K
+	addi		r15,r15,1*16
+	bdnz		L1x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	S0,S0,K
+
+	C AES(counter) XOR plaintext = ciphertext
+	lxvb16x		VSR(C0),0,SRC
+	vxor		S0,C0,S0
+
+	C Store ciphertext in DST
+	stxvb16x	VSR(S0),0,DST
+
+L1x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F,H1L,S0
+	vpmsumd		R,H1M,S0
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,1*16
+	addi		SRC,SRC,1*16
+	clrldi		LENGTH,LENGTH,60	C 'set the high-order 60 bits to zeros'
+
+Lpartial:
+	C --- process partial block ---
+	cmpldi		LENGTH,0
+	beq		Ldone
+
+	C load table elements
+	li		r15,1*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+
+Lpartial_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		S0,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		S0,S0,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+Lpartial_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		S0,S0,K
+	addi		r15,r15,1*16
+	bdnz		Lpartial_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	S0,S0,K
+
+	C Load the partial block left-aligned and zero-padded
+	sldi		LENGTH,LENGTH,56
+	lxvll		VSR(C0),SRC,LENGTH
+
+	C AES(counter) XOR plaintext = ciphertext
+	vxor		S0,C0,S0
+
+	C Store ciphertext in DST
+	stxvll		VSR(S0),DST,LENGTH
+
+	C TODO: Lazy, reload the value to zero-out the padding bits again
+	lxvll		VSR(S0),DST,LENGTH
+
+Lpartial_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F,H1L,S0
+	vpmsumd		R,H1M,S0
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+Ldone:
+	stxvb16x	VSR(D),0,X		C store digest 'D'
+	stxvb16x	VSR(CTR),0,PCTR		C store updated 'ctr'
+
+	C Restore non-volatiles from the 288B stack redzone
+	ld		r14,-8*1(SP)
+	ld		r15,-8*2(SP)
+	ld		r16,-8*3(SP)
+	ld		r17,-8*4(SP)
+	lxv		VSR(v20),-16*3(SP)
+	lxv		VSR(v21),-16*4(SP)
+	lxv		VSR(v22),-16*5(SP)
+	lxv		VSR(v23),-16*6(SP)
+	lxv		VSR(v24),-16*7(SP)
+	lxv		VSR(v25),-16*8(SP)
+	lxv		VSR(v26),-16*9(SP)
+	lxv		VSR(v27),-16*10(SP)
+	lxv		VSR(v28),-16*11(SP)
+	lxv		VSR(v29),-16*12(SP)
+	lxv		VSR(v30),-16*13(SP)
+	lxv		VSR(v31),-16*14(SP)
+
+	li		r3,0			C return 0 for success
+	blr
+
+EPILOGUE(_nettle_gcm_aes_encrypt)
+
+.data
+.align 4
+C 0xC2000000000000000000000000000001
+.polynomial:
+IF_BE(`
+	.byte 0xC2
+	.rept 14
+	.byte 0x00
+	.endr
+	.byte 0x01
+',`
+	.byte 0x01
+	.rept 14
+	.byte 0x00
+	.endr
+	.byte 0xC2
+')
+.align 4
+.increment:
+IF_LE(`
+	.byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
+')
+IF_BE(`
+	.byte 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+')
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061516</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:16-0400</timestampReceived><subject>[RFC PATCH 5/6] ppc: Add gcm_aes_decrypt() asm for ISA 3.0 (P9)</subject><body>

This implementation is based on the existing, per-algorithm optimized
powerpc64/p8/aes-encrypt-internal.asm and powerpc64/p8/gcm-hash.asm
implementations by Niels Möller and Mamone Tarsha. See the previous
gcm_aes_encrypt() commit for details about major changes.

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 powerpc64/p9/gcm-aes-decrypt.asm | 663 +++++++++++++++++++++++++++++++
 1 file changed, 663 insertions(+)
 create mode 100644 powerpc64/p9/gcm-aes-decrypt.asm

diff --git a/powerpc64/p9/gcm-aes-decrypt.asm b/powerpc64/p9/gcm-aes-decrypt.asm
new file mode 100644
index 00000000..4316a487
--- /dev/null
+++ b/powerpc64/p9/gcm-aes-decrypt.asm
@@ -0,0 +1,663 @@
+C powerpc64/p9/gcm-aes-decrypt.asm
+
+ifelse(`
+   Copyright (C) 2020 Niels Möller and Mamone Tarsha
+   Copyright (C) 2021 Christopher M. Riedl
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+
+.file "gcm-aes-decrypt.asm"
+
+.text
+
+C void gcm_aes_decrypt(const struct gcm_key *key, union gcm_block *x,
+C                      size_t length, const uint8_t *src,
+C                      unsigned rounds, const uint32_t *keys,
+C                      uint8_t *dst, uint32_t *ctr)
+
+C Register usage:
+define(`SP',	`r1')
+define(`TOCP',	`r2')
+
+C Parameters:
+define(`TABLE',	`r3')
+define(`X',	`r4')	C Output GCM/Ghash tag
+define(`LENGTH',`r5')
+define(`SRC',	`r6')	C Ciphertext input
+define(`ROUNDS',`r7')
+define(`KEYS',	`r8')
+define(`DST',	`r9')
+define(`PCTR',	`r10')	C Pointer to 12B IV and starting 4B ctr
+
+C GCM/Ghash:
+define(`POLY_L',`v0')
+define(`D',	`v1')
+define(`H1M',	`v6')
+define(`H1L',	`v7')
+define(`H2M',	`v8')
+define(`H2L',	`v9')
+define(`H3M',	`v10')
+define(`H3L',	`v11')
+define(`H4M',	`v12')
+define(`H4L',	`v13')
+define(`R',	`v14')
+define(`F',	`v15')
+define(`R2',	`v16')
+define(`F2',	`v17')
+define(`T',	`v18')
+define(`R3',	`v20')
+define(`F3',	`v21')
+define(`R4',	`v22')
+define(`F4',	`v23')
+
+C AES:
+define(`K',	`v25')
+define(`S0',	`v2')
+define(`S1',	`v3')
+define(`S2',	`v4')
+define(`S3',	`v5')
+define(`S4',	`v26')
+define(`S5',	`v27')
+define(`S6',	`v28')
+define(`S7',	`v29')
+define(`CTR',	`v30')
+define(`INC',	`v31')
+define(`C0',	`v14')
+define(`C1',	`v15')
+define(`C2',	`v16')
+define(`C3',	`v17')
+define(`C4',	`v20')
+define(`C5',	`v21')
+define(`C6',	`v22')
+define(`C7',	`v23')
+
+define(`LCNT',	`r14')
+define(`ZERO',	`v16')
+define(`POLY',	`v24')
+C misc: r15,r16,r17
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_aes_decrypt)
+
+	vxor		ZERO,ZERO,ZERO
+	subi		ROUNDS,ROUNDS,1		C Last AES round uses vcipherlast
+
+	C Store non-volatiles on the 288B stack redzone
+	std		r14,-8*1(SP)
+	std		r15,-8*2(SP)
+	std		r16,-8*3(SP)
+	std		r17,-8*4(SP)
+	stxv		VSR(v20),-16*3(SP)
+	stxv		VSR(v21),-16*4(SP)
+	stxv		VSR(v22),-16*5(SP)
+	stxv		VSR(v23),-16*6(SP)
+	stxv		VSR(v24),-16*7(SP)
+	stxv		VSR(v25),-16*8(SP)
+	stxv		VSR(v26),-16*9(SP)
+	stxv		VSR(v27),-16*10(SP)
+	stxv		VSR(v28),-16*11(SP)
+	stxv		VSR(v29),-16*12(SP)
+	stxv		VSR(v30),-16*13(SP)
+	stxv		VSR(v31),-16*14(SP)
+
+	DATA_LOAD_VEC(POLY,.polynomial,r14)
+	DATA_LOAD_VEC(INC,.increment,r14)
+
+	lxvb16x		VSR(CTR),0,PCTR		C Load 'ctr' pointer
+	xxmrghd		VSR(POLY_L),VSR(ZERO),VSR(POLY)
+	lxvb16x		VSR(D),0,X		C load 'X' pointer
+
+L8x:
+	C --- process 8 blocks '128-bit each' per one loop ---
+	srdi.		LCNT,LENGTH,7		C 8-blocks loop count 'LENGTH / (8 * 16)'
+	beq		L4x
+
+	C load table elements
+	li		r15,4*16
+	li		r16,5*16
+	li		r17,6*16
+	lxvd2x		VSR(H3M),r15,TABLE
+	lxvd2x		VSR(H3L),r16,TABLE
+	lxvd2x		VSR(H4M),r17,TABLE
+	li		r16,7*16
+	lxvd2x		VSR(H4L),r16,TABLE
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L8x_loop:
+L8x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		C0,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C0,C0,K
+	vmr		C1,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C1,C1,K
+	vmr		C2,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C2,C2,K
+	vmr		C3,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C3,C3,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+	vmr		C4,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C4,C4,K
+	vmr		C5,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C5,C5,K
+	vmr		C6,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C6,C6,K
+	vmr		C7,CTR
+	vadduwm		CTR,CTR,INC
+	vxor		C7,C7,K
+
+.align 5
+L8x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	addi		r15,r15,1*16
+	vcipher		C0,C0,K
+	vcipher		C1,C1,K
+	vcipher		C2,C2,K
+	vcipher		C3,C3,K
+	vcipher		C4,C4,K
+	vcipher		C5,C5,K
+	vcipher		C6,C6,K
+	vcipher		C7,C7,K
+	bdnz		L8x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	C0,C0,K
+	vcipherlast	C1,C1,K
+	vcipherlast	C2,C2,K
+	vcipherlast	C3,C3,K
+	vcipherlast	C4,C4,K
+	vcipherlast	C5,C5,K
+	vcipherlast	C6,C6,K
+	vcipherlast	C7,C7,K
+
+	C AES(counter) XOR ciphertext = plaintext
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvb16x		VSR(S0),0,SRC
+	lxvb16x		VSR(S1),r15,SRC
+	lxvb16x		VSR(S2),r16,SRC
+	lxvb16x		VSR(S3),r17,SRC
+	vxor		C0,C0,S0
+	vxor		C1,C1,S1
+	vxor		C2,C2,S2
+	vxor		C3,C3,S3
+
+	addi		SRC,SRC,4*16
+	lxvb16x		VSR(S4),0,SRC
+	lxvb16x		VSR(S5),r15,SRC
+	lxvb16x		VSR(S6),r16,SRC
+	lxvb16x		VSR(S7),r17,SRC
+	vxor		C4,C4,S4
+	vxor		C5,C5,S5
+	vxor		C6,C6,S6
+	vxor		C7,C7,S7
+
+	C Store plaintext 
+	stxvb16x	VSR(C0),0,DST
+	stxvb16x	VSR(C1),r15,DST
+	stxvb16x	VSR(C2),r16,DST
+	stxvb16x	VSR(C3),r17,DST
+	addi		DST,DST,4*16
+	stxvb16x	VSR(C4),0,DST
+	stxvb16x	VSR(C5),r15,DST
+	stxvb16x	VSR(C6),r16,DST
+	stxvb16x	VSR(C7),r17,DST
+
+	addi		SRC,SRC,4*16
+	addi		DST,DST,4*16
+
+L8x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S1
+	vpmsumd		R2,H3M,S1
+	vpmsumd		F3,H2L,S2
+	vpmsumd		R3,H2M,S2
+	vpmsumd		F4,H1L,S3
+	vpmsumd		R4,H1M,S3
+	vpmsumd		F,H4L,S0
+	vpmsumd		R,H4M,S0
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	C previous digest combining
+	vxor		S4,S4,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S5
+	vpmsumd		R2,H3M,S5
+	vpmsumd		F3,H2L,S6
+	vpmsumd		R3,H2M,S6
+	vpmsumd		F4,H1L,S7
+	vpmsumd		R4,H1M,S7
+	vpmsumd		F,H4L,S4
+	vpmsumd		R,H4M,S4
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	C Decrement 8x block count and check if done
+	subi		LCNT,LCNT,1
+	cmpldi		LCNT,0
+	bne		L8x_loop
+	clrldi		LENGTH,LENGTH,57	C 'set the high-order 57 bits to zeros'
+
+L4x:
+	C --- process 4 blocks --- 
+	srdi.		LCNT,LENGTH,6		C 4-blocks loop count 'LENGTH / (4 * 16)'
+	beq		L2x
+
+	C load table elements
+	li		r15,4*16
+	li		r16,5*16
+	li		r17,6*16
+	lxvd2x		VSR(H3M),r15,TABLE
+	lxvd2x		VSR(H3L),r16,TABLE
+	lxvd2x		VSR(H4M),r17,TABLE
+	li		r16,7*16
+	lxvd2x		VSR(H4L),r16,TABLE
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L4x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		C0,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		C1,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		C2,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		C3,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		C0,C0,K
+	vxor		C1,C1,K
+	vxor		C2,C2,K
+	vxor		C3,C3,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L4x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		C0,C0,K
+	vcipher		C1,C1,K
+	vcipher		C2,C2,K
+	vcipher		C3,C3,K
+	addi		r15,r15,1*16
+	bdnz		L4x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	C0,C0,K
+	vcipherlast	C1,C1,K
+	vcipherlast	C2,C2,K
+	vcipherlast	C3,C3,K
+
+	C AES(counter) XOR ciphertext = plaintext
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvb16x		VSR(S0),0,SRC
+	lxvb16x		VSR(S1),r15,SRC
+	lxvb16x		VSR(S2),r16,SRC
+	lxvb16x		VSR(S3),r17,SRC
+	vxor		C0,C0,S0
+	vxor		C1,C1,S1
+	vxor		C2,C2,S2
+	vxor		C3,C3,S3
+
+	C Store plaintext in DST
+	stxvb16x	VSR(C0),0,DST
+	stxvb16x	VSR(C1),r15,DST
+	stxvb16x	VSR(C2),r16,DST
+	stxvb16x	VSR(C3),r17,DST
+
+L4x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H3L,S1
+	vpmsumd		R2,H3M,S1
+	vpmsumd		F3,H2L,S2
+	vpmsumd		R3,H2M,S2
+	vpmsumd		F4,H1L,S3
+	vpmsumd		R4,H1M,S3
+	vpmsumd		F,H4L,S0
+	vpmsumd		R,H4M,S0
+
+	C deferred recombination of partial products
+	vxor		F3,F3,F4
+	vxor		R3,R3,R4
+	vxor		F,F,F2
+	vxor		R,R,R2
+	vxor		F,F,F3
+	vxor		R,R,R3
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,4*16
+	addi		SRC,SRC,4*16
+	clrldi		LENGTH,LENGTH,58	C 'set the high-order 58 bits to zeros'
+
+L2x:
+	C --- process 2 blocks ---
+	srdi.		r14,LENGTH,5		C 'LENGTH / (2 * 16)'
+	beq		L1x
+
+	C load table elements
+	li		r15,1*16
+	li		r16,2*16
+	li		r17,3*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+	lxvd2x		VSR(H2M),r16,TABLE
+	lxvd2x		VSR(H2L),r17,TABLE
+
+L2x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		C0,CTR
+	vadduwm		CTR,CTR,INC
+	vmr		C1,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		C0,C0,K
+	vxor		C1,C1,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L2x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		C0,C0,K
+	vcipher		C1,C1,K
+	addi		r15,r15,1*16
+	bdnz		L2x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	C0,C0,K
+	vcipherlast	C1,C1,K
+
+	C AES(counter) XOR ciphertext = plaintext
+	li		r15,1*16
+	lxvb16x		VSR(S0),0,SRC
+	lxvb16x		VSR(S1),r15,SRC
+	vxor		C0,C0,S0
+	vxor		C1,C1,S1
+
+	C Store plaintext in DST
+	stxvb16x	VSR(C0),0,DST
+	stxvb16x	VSR(C1),r15,DST
+
+L2x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F2,H1L,S1
+	vpmsumd		R2,H1M,S1
+	vpmsumd		F,H2L,S0
+	vpmsumd		R,H2M,S0
+
+	C deferred recombination of partial products
+	vxor		F,F,F2
+	vxor		R,R,R2
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,2*16
+	addi		SRC,SRC,2*16
+	clrldi		LENGTH,LENGTH,59	C 'set the high-order 59 bits to zeros'
+
+L1x:
+	C --- process 1 block ---
+	srdi.		r14,LENGTH,4		C 'LENGTH / (1 * 16)'
+	beq		Lpartial
+
+	C load table elements
+	li		r15,1*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+
+L1x_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		C0,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		C0,C0,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+L1x_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		C0,C0,K
+	addi		r15,r15,1*16
+	bdnz		L1x_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	C0,C0,K
+
+	C AES(counter) XOR ciphertext = plaintext
+	lxvb16x		VSR(S0),0,SRC
+	vxor		C0,C0,S0
+
+	C Store plaintext in DST
+	stxvb16x	VSR(C0),0,DST
+
+L1x_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F,H1L,S0
+	vpmsumd		R,H1M,S0
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+	addi		DST,DST,1*16
+	addi		SRC,SRC,1*16
+	clrldi		LENGTH,LENGTH,60	C 'set the high-order 60 bits to zeros'
+
+Lpartial:
+	C --- process partial block ---
+	cmpldi		LENGTH,0
+	beq		Ldone
+
+	C load table elements
+	li		r15,1*16
+	lxvd2x		VSR(H1M),0,TABLE
+	lxvd2x		VSR(H1L),r15,TABLE
+
+Lpartial_aes:
+	lxvb16x		VSR(K),0,KEYS
+
+	C Increment ctr
+	vmr		C0,CTR
+	vadduwm		CTR,CTR,INC
+
+	vxor		C0,C0,K
+
+	mtctr		ROUNDS
+	li		r15,1*16
+
+.align 5
+Lpartial_aes_rnd_loop:
+	lxvb16x		VSR(K),r15,KEYS
+	vcipher		C0,C0,K
+	addi		r15,r15,1*16
+	bdnz		Lpartial_aes_rnd_loop
+
+	lxvb16x		VSR(K),r15,KEYS
+	vcipherlast	C0,C0,K
+
+	C Load the partial block left-aligned and zero-padded
+	sldi		LENGTH,LENGTH,56
+	lxvll		VSR(S0),SRC,LENGTH
+
+	C AES(counter) XOR ciphertext = plaintext
+	vxor		C0,C0,S0
+
+	C Store plaintext in DST
+	stxvll		VSR(C0),DST,LENGTH
+
+Lpartial_gcm:
+	C previous digest combining
+	vxor		S0,S0,D
+
+	C polynomial multiplication
+	vpmsumd		F,H1L,S0
+	vpmsumd		R,H1M,S0
+
+	C reduction
+	vpmsumd		T,F,POLY_L
+	xxswapd		VSR(D),VSR(F)
+	vxor		R,R,T
+	vxor		D,R,D
+
+Ldone:
+	stxvb16x	VSR(D),0,X		C store digest 'D'
+	stxvb16x	VSR(CTR),0,PCTR		C store updated 'ctr'
+
+	C Restore non-volatiles from the 288B stack redzone
+	ld		r14,-8*1(SP)
+	ld		r15,-8*2(SP)
+	ld		r16,-8*3(SP)
+	ld		r17,-8*4(SP)
+	lxv		VSR(v20),-16*3(SP)
+	lxv		VSR(v21),-16*4(SP)
+	lxv		VSR(v22),-16*5(SP)
+	lxv		VSR(v23),-16*6(SP)
+	lxv		VSR(v24),-16*7(SP)
+	lxv		VSR(v25),-16*8(SP)
+	lxv		VSR(v26),-16*9(SP)
+	lxv		VSR(v27),-16*10(SP)
+	lxv		VSR(v28),-16*11(SP)
+	lxv		VSR(v29),-16*12(SP)
+	lxv		VSR(v30),-16*13(SP)
+	lxv		VSR(v31),-16*14(SP)
+
+	li		r3,0			C return 0 for success
+	blr
+
+EPILOGUE(_nettle_gcm_aes_decrypt)
+
+.data
+.align 4
+C 0xC2000000000000000000000000000001
+.polynomial:
+IF_BE(`
+	.byte 0xC2
+	.rept 14
+	.byte 0x00
+	.endr
+	.byte 0x01
+',`
+	.byte 0x01
+	.rept 14
+	.byte 0x00
+	.endr
+	.byte 0xC2
+')
+.align 4
+.increment:
+IF_LE(`
+	.byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
+')
+IF_BE(`
+	.byte 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+')
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405061517</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 06:15:17-0400</timestampReceived><subject>[RFC PATCH 6/6] ppc: Enable gcm_aes_{de,en}crypt() FAT</subject><body>

Enable runtime override via FAT for gcm_aes_{de,en}crypt() on ppc
ISA 3.0 (P9 and beyond) platforms.

Signed-off-by: Christopher M. Riedl &lt;cmr@linux.ibm.com&gt;
---
 fat-ppc.c                         | 33 +++++++++++++++++++++++++++
 fat-setup.h                       |  6 +++++
 gcm-internal.h                    | 14 ++++++++++++
 powerpc64/fat/gcm-aes-decrypt.asm | 37 +++++++++++++++++++++++++++++++
 powerpc64/fat/gcm-aes-encrypt.asm | 37 +++++++++++++++++++++++++++++++
 5 files changed, 127 insertions(+)
 create mode 100644 powerpc64/fat/gcm-aes-decrypt.asm
 create mode 100644 powerpc64/fat/gcm-aes-encrypt.asm

diff --git a/fat-ppc.c b/fat-ppc.c
index 67ef46ab..9cc9d526 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -173,6 +173,14 @@ DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, ppc64)
 DECLARE_FAT_FUNC(_nettle_gcm_hash, gcm_hash_func)
 DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, c)
 DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_gcm_aes_encrypt, gcm_aes_crypt_func)
+DECLARE_FAT_FUNC_VAR(gcm_aes_encrypt, gcm_aes_crypt_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_aes_encrypt, gcm_aes_crypt_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_gcm_aes_decrypt, gcm_aes_crypt_func)
+DECLARE_FAT_FUNC_VAR(gcm_aes_decrypt, gcm_aes_crypt_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_aes_decrypt, gcm_aes_crypt_func, ppc64)
 #endif /* GCM_TABLE_BITS == 8 */
 
 DECLARE_FAT_FUNC(_nettle_chacha_core, chacha_core_func)
@@ -238,6 +246,20 @@ fat_init (void)
       nettle_chacha_crypt_vec = _nettle_chacha_crypt_1core;
       nettle_chacha_crypt32_vec = _nettle_chacha_crypt32_1core;
     }
+  if (features.have_isa_30)
+    {
+      if (verbose)
+	fprintf (stderr, "libnettle: enabling arch 3.0 code.\n");
+#if GCM_TABLE_BITS == 8
+      _nettle_gcm_aes_encrypt_vec = _nettle_gcm_aes_encrypt_ppc64;
+      _nettle_gcm_aes_decrypt_vec = _nettle_gcm_aes_decrypt_ppc64;
+#endif /* GCM_TABLE_BITS == 8 */
+    }
+  else
+    {
+      _nettle_gcm_aes_encrypt_vec = _nettle_gcm_aes_encrypt_c;
+      _nettle_gcm_aes_decrypt_vec = _nettle_gcm_aes_decrypt_c;
+    }
 }
 
 DEFINE_FAT_FUNC(_nettle_aes_encrypt, void,
@@ -263,6 +285,17 @@ DEFINE_FAT_FUNC(_nettle_gcm_hash, void,
 		(const struct gcm_key *key, union nettle_block16 *x,
 		 size_t length, const uint8_t *data),
 		(key, x, length, data))
+
+DEFINE_FAT_FUNC(_nettle_gcm_aes_encrypt, int,
+		(const struct gcm_key *key, union nettle_block16 *x,
+		 size_t length, const uint8_t *src, unsigned rounds,
+		 const uint32_t *keys, uint8_t *dst, uint8_t* ctr),
+		(key, x, length, src, rounds, keys, dst, ctr))
+DEFINE_FAT_FUNC(_nettle_gcm_aes_decrypt, int,
+		(const struct gcm_key *key, union nettle_block16 *x,
+		 size_t length, const uint8_t *src, unsigned rounds,
+		 const uint32_t *keys, uint8_t *dst, uint8_t* ctr),
+		(key, x, length, src, rounds, keys, dst, ctr))
 #endif /* GCM_TABLE_BITS == 8 */
 
 DEFINE_FAT_FUNC(_nettle_chacha_core, void,
diff --git a/fat-setup.h b/fat-setup.h
index 4e528d6b..70c271e5 100644
--- a/fat-setup.h
+++ b/fat-setup.h
@@ -194,3 +194,9 @@ typedef void chacha_crypt_func(struct chacha_ctx *ctx,
 			       size_t length,
 			       uint8_t *dst,
 			       const uint8_t *src);
+
+typedef int gcm_aes_crypt_func(const struct gcm_key *key,
+			       union nettle_block16 *x, size_t length,
+			       const uint8_t *src, unsigned rounds,
+			       const uint32_t *keys, uint8_t *dst,
+			       uint8_t* ctr);
diff --git a/gcm-internal.h b/gcm-internal.h
index 2e28be2d..63373d95 100644
--- a/gcm-internal.h
+++ b/gcm-internal.h
@@ -51,4 +51,18 @@ _nettle_gcm_hash_c (const struct gcm_key *key, union nettle_block16 *x,
 		    size_t length, const uint8_t *data);
 #endif
 
+#if HAVE_NATIVE_fat_gcm_aes_encrypt
+int
+_nettle_gcm_aes_encrypt_c (const struct gcm_key *key, union nettle_block16 *x,
+			   size_t length, const uint8_t *src, unsigned rounds,
+			   const uint32_t *keys, uint8_t *dst, uint8_t* ctr);
+#endif
+
+#if HAVE_NATIVE_fat_gcm_aes_decrypt
+int
+_nettle_gcm_aes_decrypt_c (const struct gcm_key *key, union nettle_block16 *x,
+			   size_t length, const uint8_t *src, unsigned rounds,
+			   const uint32_t *keys, uint8_t *dst, uint8_t* ctr);
+#endif
+
 #endif /* NETTLE_GCM_INTERNAL_H_INCLUDED */
diff --git a/powerpc64/fat/gcm-aes-decrypt.asm b/powerpc64/fat/gcm-aes-decrypt.asm
new file mode 100644
index 00000000..a6bd2e36
--- /dev/null
+++ b/powerpc64/fat/gcm-aes-decrypt.asm
@@ -0,0 +1,37 @@
+C powerpc64/fat/gcm-aes-decrypt.asm
+
+ifelse(`
+   Copyright (C) 2021 Christopher M. Riedl 
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+dnl picked up by configure
+dnl PROLOGUE(_nettle_fat_gcm_aes_decrypt)
+
+define(`fat_transform', `$1_ppc64')
+include_src(`powerpc64/p9/gcm-aes-decrypt.asm')
diff --git a/powerpc64/fat/gcm-aes-encrypt.asm b/powerpc64/fat/gcm-aes-encrypt.asm
new file mode 100644
index 00000000..1cffce9d
--- /dev/null
+++ b/powerpc64/fat/gcm-aes-encrypt.asm
@@ -0,0 +1,37 @@
+C powerpc64/fat/gcm-aes-encrypt.asm
+
+ifelse(`
+   Copyright (C) 2021 Christopher M. Riedl 
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+dnl picked up by configure
+dnl PROLOGUE(_nettle_fat_gcm_aes_encrypt)
+
+define(`fat_transform', `$1_ppc64')
+include_src(`powerpc64/p9/gcm-aes-encrypt.asm')
-- 
2.26.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210405235300</emailId><senderName>"Christopher M. Riedl"</senderName><senderEmail>cmr@linux.ibm.com</senderEmail><timestampReceived>2021-04-05 23:53:00-0400</timestampReceived><subject>Re: [RFC PATCH 0/6] Introduce combined AES-GCM assembly for POWER9+</subject><body>

On Mon Apr 5, 2021 at 2:39 AM CDT, Niels Möller wrote:
&gt; "Christopher M. Riedl" &lt;cmr@linux.ibm.com&gt; writes:
&gt;
&gt; &gt; An implementation combining AES+GCM _can potentially_ yield significant
&gt; &gt; performance boosts by allowing for increased instruction parallelism, avoiding
&gt; &gt; C-function call overhead, more flexibility in assembly fine-tuning, etc. This
&gt; &gt; series provides such an implementation based on the existing optimized Nettle
&gt; &gt; routines for POWER9 and later processors. Benchmark results on a POWER9
&gt; &gt; Blackbird running at 3.5GHz are given at the end of this mail.
&gt;
&gt; Benchmark results are impressive. If I get the numbers right, cycles per
&gt; block (16 bytes) is reduced from 40 to 22.5. You can run
&gt; nettle-benchmark with the flag -f 3.5e9 (for 3.5GHz clock frequency) to
&gt; get cycle numbers in the output.

Hi Niels,

Your math is very close - here are benchmark results for encrypt (since
decrypt is essentially the same):

AES+GCM combined (this series)
------------------------------
         Algorithm         mode Mbyte/s cycles/byte cycles/block
        gcm_aes128      encrypt 2564.32        1.30        20.83
        gcm_aes192      encrypt 2276.86        1.47        23.46
        gcm_aes256      encrypt 2051.87        1.63        26.03

AES,GCM separate (nettle master)
--------------------------------
         Algorithm         mode Mbyte/s cycles/byte cycles/block
        gcm_aes128      encrypt 1419.17        2.35        37.63
        gcm_aes192      encrypt 1313.69        2.54        40.65
        gcm_aes256      encrypt 1218.79        2.74        43.82

So for aes128: 37.63 - 20.83 = 16.80 cycles/block improvement.

&gt;
&gt; I'm a bit conservative about about adding assembly code for combined
&gt; operations, since it can lead to an explosion in the amount of code to
&gt; maintain. So I'd like to understand a bit better where the 17.5 saved
&gt; cycles were spent. For the code on master, gcm_encrypt (with aes) is
&gt; built from
&gt; these building blocks:

Makes perfect sense to me!

&gt;
&gt; * gcm_fill
&gt;
&gt; C code, essentially 2 64-bit stores per block. On little endian, it
&gt; also needs some byte swapping.
&gt;
&gt; * aes_encrypt
&gt;
&gt; Using power assembly. Performance measured as the "aes128 ECB
&gt; encrypt" line in nettle-benchmark output.
&gt;
&gt; * memxor3
&gt;
&gt; This is C code on power (and rather hairy C code). Performance can
&gt; be measured with nettle-benchmark, and it's going to be a bit
&gt; alignment dependent.
&gt;
&gt; * gcm_hash
&gt;
&gt; This uses power assembly. Performance is measured as the "gcm
&gt; update" line in nettle-benchmark output. From your numbers, this
&gt; seems to be 7.3 cycles per block.
&gt;
&gt; So before going all the way with a combined aes_gcm function, I think
&gt; it's good to try to optimize the building blocks. Please benchmark
&gt; memxor3, to see if it could benefit from assembly implementation. If so,
&gt; that should give a nice speedup to several modes, not just gcm. (If you
&gt; implement memxor3, beware that it needs to support some overlap, to not
&gt; break in-place CBC decrypt).

The benchmark results don't convince me memxor3 and memxor are actually
a huge bottleneck by themselves. It does appear to show that my combined
implementation is dominated by the cost of AES (which matches when I run
a simple test encrypt program with the 'perf' utility):

         Algorithm         mode Mbyte/s cycles/byte cycles/block
            memxor      aligned 16634.14        0.20         1.61
            memxor    unaligned 11089.33        0.30         2.41
           memxor3      aligned 17261.19        0.19         1.55
           memxor3  unaligned01 11549.04        0.29         2.31
           memxor3  unaligned11 11181.62        0.30         2.39
           memxor3  unaligned12  8485.88        0.39         3.15
            aes128  ECB encrypt  2762.38        1.21        19.33
            aes128  ECB decrypt  2203.65        1.51        24.24

I tried a few other experiments:

 1. Replace memxor/3 with a no-op function (ie. just 'return'):
     Algorithm         mode Mbyte/s cycles/byte cycles/block
    gcm_aes128      encrypt 1553.08        2.15        34.39
    gcm_aes192      encrypt 1428.57        2.34        37.38
    gcm_aes256      encrypt 1318.05        2.53        40.52
   
    aes128: 37.63 - 34.39 = 3.24 cycles/block

 2. Replace memxor/3,gcm_fill w/ a no-op function:
     Algorithm         mode Mbyte/s cycles/byte cycles/block
    gcm_aes128      encrypt 1793.37        1.86        29.78
    gcm_aes192      encrypt 1625.74        2.05        32.85
    gcm_aes256      encrypt 1483.81        2.25        35.99

    aes128: 34.39 - 29.78 = 4.61 cycles/block

 3. Replace memxor/3, and gcm_fill w/ no-op functions and use POWER9
    instructions lxvb16x/stxvb16x to load/store unaligned vectors and
    avoid the permutes on LE:
     Algorithm         mode Mbyte/s cycles/byte cycles/block
    gcm_aes128      encrypt 2069.67        1.61        25.80
    gcm_aes192      encrypt 1875.97        1.78        28.47
    gcm_aes256      encrypt 1717.33        1.94        31.10

    aes128: 29.78 - 25.80 = 3.98 cycles/block

So in total, if we assume an ideal (but impossible) zero-cost version
for memxor, memxor3, and gcm_fill and avoid permutes via ISA 3.0 vector
load/stores we can only account for 11.82 cycles/block; leaving 4.97
cycles/block as an additional benefit of the combined implementation.
But all this assumes zero-cost implementations of these building blocks
so the improvement of the combined implementation is &gt;5 cycles/block.
   
&gt;
&gt; Another potential overhead is that data is stored to memory when passed
&gt; between these functions. It seems we store a block 3 times, and loads a
&gt; block 4 times (the additional accesses should be cache friendly, but
&gt; wills till cost some execution resources). Optimizing that seems to need
&gt; some kind of combined function. But maybe it is sufficient to optimize
&gt; something a bit more general than aes gcm, e.g., aes ctr?

This would basically have to replace the nettle_crypt16 function call
with arch-specific assembly, right? I can code this up and try it out in
the context of AES-GCM.

Thanks!
Chris R.

&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210407130609</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-04-07 13:06:09-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

Hello,

Le 2021-04-07 Ã  08 h 09, Aapo Talvensaari a Ã©crit  :
&gt; 
&gt; It says: "*ciphertext length must be cleartext_length-8" but shouldn't that
&gt; be:
&gt; "*ciphertext length must be cleartext_length+8"?

Indeed, the typo is similar in the other paragraph.

For void aesXXX_keywrap, it should say:
"*cleartext length must be ciphertext_length-8."

For int aesXXX_keyunwrap, it should say:
"*ciphertext length must be cleartext_length+8."

/Nicolas
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210421202449</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-04-21 20:24:49-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Hi Niels, hope you are doing well now
Any update on this patch?

regards,
Mamone


On Mon, Apr 5, 2021 at 11:49 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Thu, Apr 1, 2021 at 12:01 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; I'll modify the patch of basic AES-128 optimized functions to be built on
&gt;&gt; top of the splitted aes functions.
&gt;&gt;
&gt;
&gt; Done!
&gt; It works as a file-override basis. The patch also passes the testsuite and
&gt; yields expected benchmark numbers.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210302115818</emailId><senderName>Norbert Pocs</senderName><senderEmail>npocs@redhat.com</senderEmail><timestampReceived>2021-03-02 11:58:18-0400</timestampReceived><subject>Re: HPKE implementation</subject><body>

&gt;
&gt; Which combinations of public key mechanism, key derivation/expansion,
&gt; and aead are of main interest?


The required combinations for the encrypted client hello [0] in TLS will be
the main focus,
then continuous implementation of the others.

Do you expect the specification to be finalized soon?
&gt;

I do not know when the specification will be finalized, however
implementations of HPKE already exist [1]. The analysis can
be found here [2].

[0] https://tools.ietf.org/html/draft-ietf-tls-esni-09#section-9
[1] https://github.com/cfrg/draft-irtf-cfrg-hpke/
[2] https://eprint.iacr.org/2020/1499

Regards
Norbert Pócs


On Thu, Feb 25, 2021 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Norbert Pocs &lt;npocs@redhat.com&gt; writes:
&gt;
&gt; &gt; My current project is the implementation of HPKE draft [0]. The first
&gt; goal
&gt; &gt; is to implement mode_base.
&gt;
&gt; Hi, I was not aware of this work. It could make sense to support in
&gt; Nettle, in particular if GnuTLS wants to use it.
&gt;
&gt; Which combinations of public key mechanism, key derivation/expansion,
&gt; and aead are of main interest?
&gt;
&gt; Do you expect the specification to be finalized soon?
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210307182435</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-07 18:24:35-0400</timestampReceived><subject>Re: Status update</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I considered to use m4 macros but it "mangles" parameter names, it becomes
&gt; hard for reader to keep track on the macro body. However, I'm still up to
&gt; change it to m4 macros if you like.

The below patch seems to work. It's a drawback that m4 doesn't have
named parameters, only $1, $2, ..., but I think it's good with
consistency, and I don't think names "param1" and "param2" are that
helpful compared to $2, $3.

But it would be nice with a bit more documentation of the macros. And of
the registers, at least, group them to make it clear which registers are
the input data (C0 -- C3?) or other state (e.g., accumulators), which
registers are used for the precomputed key-dependent parameters, and
which registers are short-lived temporaries.

In other news, I've applied for an account at
https://linuxone.cloud.marist.edu, but it seems there's some manual
review involved so not completed yet,

Regards,
/Niels

diff --git a/arm64/crypto/gcm-hash.asm b/arm64/crypto/gcm-hash.asm
index b77b08d6..f86fb504 100644
--- a/arm64/crypto/gcm-hash.asm
+++ b/arm64/crypto/gcm-hash.asm
@@ -47,21 +47,22 @@ define(`R', `v18')
 define(`R1', `v19')
 
 C common macros:
-.macro PMUL in, param1, param2
-    pmull          F.1q,\param2\().1d,\in\().1d
-    pmull2         F1.1q,\param2\().2d,\in\().2d
-    pmull          R.1q,\param1\().1d,\in\().1d
-    pmull2         R1.1q,\param1\().2d,\in\().2d
+C PMUL(in, param1, param2)
+define(`PMUL', m4_assert_numargs(3)`
+    pmull          F.1q,$3.1d,$1.1d
+    pmull2         F1.1q,$3.2d,$1.2d
+    pmull          R.1q,$2.1d,$1.1d
+    pmull2         R1.1q,$2.2d,$1.2d
     eor            F.16b,F.16b,F1.16b
     eor            R.16b,R.16b,R1.16b
-.endm
-
-.macro REDUCTION out
+')
+C REDUCTION(out)
+define(`REDUCTION', m4_assert_numargs(1)`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
-    eor            \out\().16b,F.16b,R.16b
-.endm
+    eor            $1.16b,F.16b,R.16b
+')
 
     C void gcm_init_key (union gcm_block *table)
 
@@ -101,13 +102,14 @@ define(`H3L', `v28')
 define(`H4M', `v29')
 define(`H4L', `v30')
 
-.macro PMUL_PARAM in, param1, param2
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    eor            Hm.16b,\in\().16b,Hp.16b
-    ext            \param1\().16b,Hm.16b,\in\().16b,#8
-    ext            \param2\().16b,\in\().16b,Hm.16b,#8
-    ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-.endm
+C PMUL_PARAM(in, param1, param2)
+define(`PMUL_PARAM', m4_assert_numargs(3)`
+    pmull2         Hp.1q,$1.2d,POLY.2d
+    eor            Hm.16b,$1.16b,Hp.16b
+    ext            $2.16b,Hm.16b,$1.16b,#8
+    ext            $3.16b,$1.16b,Hm.16b,#8
+    ext            $2.16b,$2.16b,$2.16b,#8
+')
 
 PROLOGUE(_nettle_gcm_init_key)
     add            x1,TABLE,#16*H_Idx
@@ -138,13 +140,13 @@ IF_LE(`
 
     C --- calculate H^2 = H*H ---
 
-    PMUL_PARAM H,H1M,H1L
+    PMUL_PARAM(H,H1M,H1L)
 
-    PMUL H,H1M,H1L
+    PMUL(H,H1M,H1L)
 
-    REDUCTION H2
+    REDUCTION(H2)
 
-    PMUL_PARAM H2,H2M,H2L
+    PMUL_PARAM(H2,H2M,H2L)
 
     C we store to the table as doubleword-vectors in current memory endianness
     C because it's our own strictly internal data structure and what gcm_hash
@@ -153,19 +155,19 @@ IF_LE(`
 
     C --- calculate H^3 = H^1*H^2 ---
 
-    PMUL H2,H1M,H1L
+    PMUL(H2,H1M,H1L)
 
-    REDUCTION H3
+    REDUCTION(H3)
 
-    PMUL_PARAM H3,H3M,H3L
+    PMUL_PARAM(H3,H3M,H3L)
 
     C --- calculate H^4 = H^2*H^2 ---
 
-    PMUL H2,H2M,H2L
+    PMUL(H2,H2M,H2L)
 
-    REDUCTION H4
+    REDUCTION(H4)
 
-    PMUL_PARAM H4,H4M,H4L
+    PMUL_PARAM(H4,H4M,H4L)
 
     st1            {H3M.2d,H3L.2d,H4M.2d,H4L.2d},[TABLE]
 
@@ -197,16 +199,17 @@ define(`H3L', `v29')
 define(`H4M', `v30')
 define(`H4L', `v31')
 
-.macro PMUL_SUM in, param1, param2
-    pmull          F2.1q,\param2\().1d,\in\().1d
-    pmull2         F3.1q,\param2\().2d,\in\().2d
-    pmull          R2.1q,\param1\().1d,\in\().1d
-    pmull2         R3.1q,\param1\().2d,\in\().2d
+C PMUL_SUM(in, param1, param2)
+define(`PMUL_SUM', m4_assert_numargs(3)`
+    pmull          F2.1q,$3.1d,$1.1d
+    pmull2         F3.1q,$3.2d,$1.2d
+    pmull          R2.1q,$2.1d,$1.1d
+    pmull2         R3.1q,$2.2d,$1.2d
     eor            F2.16b,F2.16b,F3.16b
     eor            R2.16b,R2.16b,R3.16b
     eor            F.16b,F.16b,F2.16b
     eor            R.16b,R.16b,R2.16b
-.endm
+')
 
     C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
     C                size_t length, const uint8_t *data)
@@ -238,12 +241,12 @@ IF_LE(`
 
     eor            C0.16b,C0.16b,D.16b
 
-    PMUL C1,H3M,H3L
-    PMUL_SUM C2,H2M,H2L
-    PMUL_SUM C3,H1M,H1L
-    PMUL_SUM C0,H4M,H4L
+    PMUL(C1,H3M,H3L)
+    PMUL_SUM(C2,H2M,H2L)
+    PMUL_SUM(C3,H1M,H1L)
+    PMUL_SUM(C0,H4M,H4L)
 
-    REDUCTION D
+    REDUCTION(D)
 
     subs           x4,x4,#64
     b.ne           L4x_loop
@@ -264,10 +267,10 @@ IF_LE(`
 
     eor            C0.16b,C0.16b,D.16b
 
-    PMUL C1,H1M,H1L
-    PMUL_SUM C0,H2M,H2L
+    PMUL(C1,H1M,H1L)
+    PMUL_SUM(C0,H2M,H2L)
 
-    REDUCTION D
+    REDUCTION(D)
 
     and            LENGTH,LENGTH,#31
 
@@ -284,9 +287,9 @@ IF_LE(`
 
     eor            C0.16b,C0.16b,D.16b
 
-    PMUL C0,H1M,H1L
+    PMUL(C0,H1M,H1L)
 
-    REDUCTION D
+    REDUCTION(D)
 
 Lmod:
     tst            LENGTH,#15
@@ -325,9 +328,9 @@ Lmod_8_load:
 Lmod_8_done:
     eor            C0.16b,C0.16b,D.16b
 
-    PMUL C0,H1M,H1L
+    PMUL(C0,H1M,H1L)
 
-    REDUCTION D
+    REDUCTION(D)
 
 Ldone:
 IF_LE(`

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210316080756</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-16 08:07:56-0400</timestampReceived><subject>ANNOUNCE: Serious bug in Nettle's ecdsa_verify</subject><body>

I've been made aware of a bug in Nettle's code to verify ECDSA
signatures. Certain signatures result in the ecc point multiply function
being called with out-of-range scalars, which may give incorrect
results, or crash in an assertion failure. It's an old bug, probably
since Nettle's initial implementation of ECDSA.

I've just pushed fixes for ecdsa_verify, as well as a few other cases of
potentially out-of-range scalars, to the master-updates branch. I haven't
fully analysed the implications, but I'll describe my current
understanding.

I think an assertion failure, useful for a denial-of-service attack, is
easy on the curves where the bitsize of q, the group order, is not an
integral number of words. That's secp224r1, on 64-bit platforms, and
secp521r1.

Even when it's not possible to trigger an assertion failure, it's easy
to produce valid-looking input "signatures" that hit out-of range
intermediate scalar values where point multiplication may misbehave.
This applies to all the NIST secp* curves as well as the GOST curves.

To me, it looks very difficult to make it misbehave in such a way that
ecdsa_verify will think an invalid signature is valid, but it might be
possible; further analysis is needed. I will not be able to analyze it
properly now, if anyone else would like to look into it, I can provide a
bit more background.

ed25519 and ed448 may be affected too, but it appears a bit harder to
find inputs that hit out of range values. And since point operations are
inherently more robust on these curves, I think they will produce
correct results as long as they don't hit the assert.

Advise on how to deal best with this? My current plan is to prepare a
3.7.2 bugfix release (from a new bugfix-only branch, without the new
arm64 code). Maybe as soon as tomorrow (Wednesday, european time), or in
the weekend.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210321092411</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-21 09:24:11-0400</timestampReceived><subject>ANNOUNCE: Nettle-3.7.2</subject><body>

[Attachment #2 (multipart/signed)]


I've prepared a new bug-fix release of Nettle, a low-level
cryptographics library, to fix a serious bug in the function to verify
ECDSA signatures. Implications include an assertion failure, which could
be used for denial-of-service, when verifying signatures on the
secp_224r1 and secp521_r1 curves. More details in NEWS file below.

Upgrading is strongly recomended.

The Nettle home page can be found at
https://www.lysator.liu.se/~nisse/nettle/, and the manual at
https://www.lysator.liu.se/~nisse/nettle/nettle.html.

The release can be downloaded from

  https://ftp.gnu.org/gnu/nettle/nettle-3.7.2.tar.gz
  ftp://ftp.gnu.org/gnu/nettle/nettle-3.7.2.tar.gz
  https://www.lysator.liu.se/~nisse/archive/nettle-3.7.2.tar.gz

Regards,
/Niels

NEWS for the Nettle 3.7.2 release

	This is a bugfix release, fixing a bug in ECDSA signature
	verification that could lead to a denial of service attack
	(via an assertion failure) or possibly incorrect results. It
	also fixes a few related problems where scalars are required
	to be canonically reduced modulo the ECC group order, but in
	fact may be slightly larger.

	Upgrading to the new version is strongly recommended.

	Even when no assert is triggered in ecdsa_verify, ECC point
	multiplication may get invalid intermediate values as input,
	and produce incorrect results. It's trivial to construct
	alleged signatures that result in invalid intermediate values.
	It appears difficult to construct an alleged signature that
	makes the function misbehave in such a way that an invalid
	signature is accepted as valid, but such attacks can't be
	ruled out without further analysis.

	Thanks to Guido Vranken for setting up the fuzzer tests that
	uncovered this problem.

	The new version is intended to be fully source and binary
	compatible with Nettle-3.6. The shared library names are
	libnettle.so.8.3 and libhogweed.so.6.3, with sonames
	libnettle.so.8 and libhogweed.so.6.

	Bug fixes:

	* Fixed bug in ecdsa_verify, and added a corresponding test
          case.

	* Similar fixes to ecc_gostdsa_verify and gostdsa_vko.

	* Similar fixes to eddsa signatures. The problem is less severe
          for these curves, because (i) the potentially out or range
          value is derived from output of a hash function, making it
          harder for the attacker to to hit the narrow range of
          problematic values, and (ii) the ecc operations are
          inherently more robust, and my current understanding is that
          unless the corresponding assert is hit, the verify
          operation should complete with a correct result.

	* Fix to ecdsa_sign, which with a very low probability could
          return out of range signature values, which would be
          rejected immediately by a verifier.

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.


["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210321204507</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-21 20:45:07-0400</timestampReceived><subject>[S390x] Optimize SHA functions</subject><body>

I made a patch that optimizes SHA functions on S390x architecture. the
patch implements the optimized cores using cipher instructions that have
been added to s390x arch in message security assist extensions. The patch
uses the following functions:

KIMD-SHA-1, KLMD-SHA-1 (SHA1)
KIMD-SHA-256, KLMD-SHA-256 (SHA256)
KIMD-SHA-512, KLMD-SHA-512 (SHA512)
KIMD-SHA3-224, KLMD-SHA3-224 (SHA3-224)
KIMD-SHA3-256, KLMD-SHA3-224 (SHA3-256)
KIMD-SHA3-384, KLMD-SHA3-224 (SHA3-384)
KIMD-SHA3-512, KLMD-SHA3-224 (SHA3-512)
KLMD-SHAKE-256 (SHA3-256-SHAKE)

The patch built on top of AES patch of s390x so I can't make a merge
request until the previous patch got merged. However, the code can be found
in my fork s390x-sha
&lt;https://git.lysator.liu.se/mamonet/nettle/-/tree/s390x-sha&gt;.
The optimized core can be enabled by either fat build or enabling the
corresponding configuration options (MSA, MSA-X1, MSA-X2, MSA-X6).

Benchmark of this patch using nettle-benchmark (Tested on z15 5.2GHZ):

*---------------------------------------------------------------------------*
|   Algorithm        |      C             |   Hardware-accelerated  |
|   sha1               |      360.69     |   1735.34
|
|  sha224            |      244.63     |   2179.60                        |
|  sha256            |      244.63     |   2179.74                        |
|  sha384            |      372.57     |   3464.84                        |
|  sha512            |      370.82     |   3463.66                        |
|  sha512-224     |      364.93     |   3382.58                        |
|  sha512-256     |      373.19     |   3463.23                        |
|  sha3-224         |      236.50     |   6859.54                        |
|  sha3-256         |      224.76     |   6656.05                        |
|  sha3-384         |      173.21     |   5818.89                        |
|  sha3-512         |      119.79     |   4693.53                        |
*---------------------------------------------------------------------------*

I have a couple of questions for this patch:

Is packing the configuration MSA options in single option is more
convenient than spamming the options with MSA extensions?

The optimized functions of sha3_update store the state buffer in big-endian
order, while C implementation store each 64-bit of state buffer in
little-endian order, I see the state buffer is used internally and since
both sha3_update and sha3_digest are optimized so both have the
same convention I think it's okay to keep it up like that, any opinions
here?

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210322065821</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-22 06:58:21-0400</timestampReceived><subject>Re: Nettle 3.7.2 and OS X 10.5</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I enabled Altivec builds with
&gt; --enable-power-altivec and --enable-fat.

Don't do that. As I've tried to explain before, that combination makes
no sense. --enable-power-altivec means "unconditionally use the altivec
code". --enable-fat (now the default) means "let the fat setup code
determine at runtime if altivec (and other) features should be used".

That said, I haven't done any tests of the altivec code on Mac. I'd have
to rely on help from Mac users to fix any problems.

&gt; Auditing the dylib it appears Altivec was not engaged:
&gt;
&gt; $ otool -tV /usr/local/lib/libnettle.dylib | grep perm
&gt; 0001f124        b       _nettle_sha3_permute
&gt; _nettle_sha3_permute:
&gt; 000204ec        bl      _nettle_sha3_permute
&gt;
&gt; I think there's something a bit sideways here.

You're a bit too terse, I have no idea what problem this is intended to
illustrate.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210322075513</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-22 07:55:13-0400</timestampReceived><subject>Re: Nettle 3.7.2 and OS X 10.12.6</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; And it looks like examples are not quite working either:
&gt;
&gt; $ make check
&gt; ...
&gt; ====================
&gt; All 110 tests passed
&gt; ====================
&gt; Making check in examples
&gt; TEST_SHLIB_DIR="/Users/jwalton/Build-Scripts/nettle-3.7.2/.lib" \
&gt;           srcdir="." EMULATOR="" EXEEXT="" \
&gt;           ".."/run-tests rsa-sign-test rsa-verify-test rsa-encrypt-test
&gt; Opening `testkey' failed: No such file or directory
&gt; Invalid key
&gt; FAIL: rsa-sign
&gt; Opening `testkey' failed: No such file or directory
&gt; Invalid key
&gt; FAIL: rsa-verify
&gt; Opening `testkey.pub' failed: No such file or directory
&gt; Invalid key
&gt; FAIL: rsa-encrypt
&gt; ===================
&gt; 3 of 3 tests failed
&gt; ===================
&gt; make[1]: *** [check] Error 1
&gt; make: *** [check] Error 2
&gt;
&gt; $ find . -name testkey.pub
&gt; $ find . -name testkey

My best guess is that your operating system fails to regard the scripts
examples/setup-env and teardown-env as executable (similarly to the
main run-tests script). The setup-env script is supposed to create those
files.

The executability-bit that is set on certain files in the tarball must
be honored for the build to work correctly. Please to whatever it takes
to convince your build environment to do that.

&gt; Examples have been breaking the build for years. Why are examples even
&gt; built during 'make check'?

The tests that are failing for you act as a kind of integration-level
test for the library. I think that has some value.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210322181919</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-22 18:19:19-0400</timestampReceived><subject>Re: [AArch64] Fat build support for GCM optimization and syntax improvements</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request #21
&gt; &lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/21&gt; that adds
&gt; fat build support for GCM implementation on arm64, the patch also updates
&gt; the README file to stay on par with the other architectures and use m4
&gt; macros in gcm-hash.asm (patch provided by Niels Möller), in addition to add
&gt; documentation comments.

Thanks! Merged to master-updates, for testing.

Regard,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325162140</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-25 16:21:40-0400</timestampReceived><subject>Re: bug#47222: Serious bug in Nettle's ecdsa_verify</subject><body>

Ludovic Courtès &lt;ludo@gnu.org&gt; writes:

&gt; Are there plans to make a new 3.5 release including these fixes?

No, I don't plan any 3.5.x release.

&gt; Alternatively, could you provide guidance as to which commits should be
&gt; cherry-picked in 3.5 for downstream distros?

Look at the branch release-3.7-fixes
(https://git.lysator.liu.se/nettle/nettle/-/commits/release-3.7-fixes/).
The commits since 3.7.1 are the ones you need.

Changes to gostdsa and ed448 will not apply, since those curves didn't
exist in nettle-3.5. Changes to ed25519 might not apply cleanly, due to
refactoring when adding ed448.

&gt; I'm asking because in Guix, the easiest way for us to deploy the fixes
&gt; on the ‘master' branch would be by "grafting" a new Nettle variant
&gt; ABI-compatible with 3.5.1, which is the one packages currently depend on.

I still recommend upgrading to the latest version. There were an abi
break in 3.6 (so you'd need to recompile lots of guix packages), but no
incompatible changes to the (source level) api.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325180241</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 18:02:41-0400</timestampReceived><subject>=?UTF-8?Q?xts=2Ec=3A59=3A_warning=3A_integer_constant_is_too_large_for?= =?UTF-8?Q?_=E2=80=98long=E2</subject><body>

This is building Nettle 3.7.2 on a PowerMac with OS X 10.5:

/usr/bin/cc -I. -I/usr/local/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2
-mlong-double-64 -fno-common -maltivec -fPIC -pthread -ggdb3
-Wno-pointer-sign -Wall -W   -Wmissing-prototypes
-Wmissing-declarations -Wstrict-prototypes   -Wpointer-arith
-Wbad-function-cast -Wnested-externs -fPIC -MT xts-aes128.o -MD -MP
-MF xts-aes128.o.d -c xts-aes128.c \
        &amp;&amp; true
xts.c: In function ‘xts_shift':
xts.c:59: warning: integer constant is too large for ‘long' type
xts.c:59: warning: integer constant is too large for ‘long' type
xts.c:60: warning: integer constant is too large for ‘long' type
xts.c:60: warning: integer constant is too large for ‘long' type
xts.c:60: warning: integer constant is too large for ‘long' type

On OS X 10.5, you have to use unsigned long long and the ull suffix.

Maybe you should add a configure test to see whether you need the ull suffix.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325182126</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 18:21:26-0400</timestampReceived><subject>Re: libhgwwed has gone missing...</subject><body>

On Thu, Mar 25, 2021 at 1:20 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Thu, Mar 25, 2021 at 3:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; It looks like Nettle is no longer building or installing hogweed on
&gt; &gt; &gt; some Apple platforms.
&gt; &gt; &gt;
&gt; &gt; &gt; This is from a PowerMac G5 running OS X 10.5:
&gt; &gt;
&gt; &gt; Most likely the configure check for libgmp failed. Check config.log for
&gt; &gt; details. I think the most recent change to the gmp dependency was in
&gt; &gt; nettle-3.6, which requires gmp-6.1 or later.
&gt;
&gt; Here is what the GMP install looks like:
&gt;
&gt; $ ls -al /usr/local/lib/*gmp*
&gt; -rwxr-xr-x  1 root  wheel   543216 Mar 24 21:39 /usr/local/lib/libgmp.10.dylib
&gt; -rw-r--r--  1 root  wheel  3078944 Mar 24 21:39 /usr/local/lib/libgmp.a
&gt; lrwxr-xr-x  1 root  wheel       15 Mar 24 21:39
&gt; /usr/local/lib/libgmp.dylib -&gt; libgmp.10.dylib
&gt; -rwxr-xr-x  1 root  wheel      947 Mar 24 21:39 /usr/local/lib/libgmp.la
&gt;
&gt; And:
&gt;
&gt; $ cat /usr/local/lib/pkgconfig/gmp.pc
&gt; prefix=/usr/local
&gt; exec_prefix=${prefix}
&gt; includedir=${prefix}/include
&gt; libdir=${prefix}/lib
&gt;
&gt; Name: GNU MP
&gt; Description: GNU Multiple Precision Arithmetic Library
&gt; URL: https://gmplib.org
&gt; Version: 6.2.1
&gt; Cflags: -I${includedir}
&gt; Libs: -L${libdir} -lgmp
&gt;
&gt; Attached is config.log.

OK, so I can work around this with:

    ./configure \
        ac_cv_lib_gmp___gmpn_zero_p=yes

But the test is shady. It does not include the proper header and then
looks for a mangled symbol name. If you would have used the proper
header then gmpn_zero_p would have been available to you.

| /* Override any GCC internal prototype to avoid an error.
|    Use char because int might match the return type of a GCC
|    builtin and then its argument prototype would still apply.  */
| #ifdef __cplusplus
| extern "C"
| #endif
| char __gmpn_zero_p ();
| int
| main ()
| {
| return __gmpn_zero_p ();
|   ;
|   return 0;
| }

GMP needs a fair amount of patching on OS X 10.5 due to the extern
inline problems. Here's what my patches look like:
https://github.com/noloader/Build-Scripts/blob/master/patch/gmp-darwin.patch.
It includes a patch for mpn_zero_p.

The GMP folks have been aware of the problem for about 15 years but
have not fixed it. Also see
https://gmplib.org/list-archives/gmp-bugs/2009-May/001423.html. I also
wrote to one of the maintainers and offered the patch. "Patches
welcome" is utter bullshit in the free software world. I laugh when I
see someone use the phrase.

I think you should reconsider how you do things. The recommended way
to check for a version of the library is with pkg-config. I.e.:

    pkg-config --libs "gmp &gt;= 6.1.0"

I also think you should pay more attention to the dominant use case of
nettle+hogweed. It is dominant because distros and users expect/need
nettle+hogweed. GnuTLS requires nettle+hogweed. (Can you name anyone
who just wants nettle?).

The current behavior of silent failure is not appropriate. You should
fail configure _if_ GMP is not satisfactory in the absence of
--disable-hogweed. Folks who do not want hogweed are _not_ the
majority. They should have to do something special like
--disable-hogweed. That's good security engineering.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325184549</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-25 18:45:49-0400</timestampReceived><subject>Re: xts.c:59: warning: integer constant is too large for =?utf-8?B?4oCYbG9uZ+KAmQ==?= type</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; This is building Nettle 3.7.2 on a PowerMac with OS X 10.5:
&gt;
&gt; /usr/bin/cc -I. -I/usr/local/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2
&gt; -mlong-double-64 -fno-common -maltivec -fPIC -pthread -ggdb3
&gt; -Wno-pointer-sign -Wall -W   -Wmissing-prototypes
&gt; -Wmissing-declarations -Wstrict-prototypes   -Wpointer-arith
&gt; -Wbad-function-cast -Wnested-externs -fPIC -MT xts-aes128.o -MD -MP
&gt; -MF xts-aes128.o.d -c xts-aes128.c \
&gt;         &amp;&amp; true
&gt; xts.c: In function ‘xts_shift':
&gt; xts.c:59: warning: integer constant is too large for ‘long' type
&gt; xts.c:59: warning: integer constant is too large for ‘long' type
&gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt;
&gt; On OS X 10.5, you have to use unsigned long long and the ull suffix.

This is confusing. The xts_shift function is not in nettle-3.7.2, as far
as I can tell, it was deleted long ago in
https://git.lysator.liu.se/nettle/nettle/-/commit/685cc919a37b60d3f81dd569bf6e93ad7be0f89b.

&gt; Maybe you should add a configure test to see whether you need the ull suffix.

The current related code uses UINT64_C for the 64-bit constants. No
configure test needed.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325184713</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 18:47:13-0400</timestampReceived><subject>=?UTF-8?Q?Re=3A_xts=2Ec=3A59=3A_warning=3A_integer_constant_is_too_large?= =?UTF-8?Q?_for_=E2=80=98l</subject><body>

On Thu, Mar 25, 2021 at 2:45 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; This is building Nettle 3.7.2 on a PowerMac with OS X 10.5:
&gt; &gt;
&gt; &gt; /usr/bin/cc -I. -I/usr/local/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2
&gt; &gt; -mlong-double-64 -fno-common -maltivec -fPIC -pthread -ggdb3
&gt; &gt; -Wno-pointer-sign -Wall -W   -Wmissing-prototypes
&gt; &gt; -Wmissing-declarations -Wstrict-prototypes   -Wpointer-arith
&gt; &gt; -Wbad-function-cast -Wnested-externs -fPIC -MT xts-aes128.o -MD -MP
&gt; &gt; -MF xts-aes128.o.d -c xts-aes128.c \
&gt; &gt;         &amp;&amp; true
&gt; &gt; xts.c: In function ‘xts_shift':
&gt; &gt; xts.c:59: warning: integer constant is too large for ‘long' type
&gt; &gt; xts.c:59: warning: integer constant is too large for ‘long' type
&gt; &gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt; &gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt; &gt; xts.c:60: warning: integer constant is too large for ‘long' type
&gt; &gt;
&gt; &gt; On OS X 10.5, you have to use unsigned long long and the ull suffix.
&gt;
&gt; This is confusing. The xts_shift function is not in nettle-3.7.2, as far
&gt; as I can tell, it was deleted long ago in
&gt; https://git.lysator.liu.se/nettle/nettle/-/commit/685cc919a37b60d3f81dd569bf6e93ad7be0f89b.
&gt;
&gt; &gt; Maybe you should add a configure test to see whether you need the ull suffix.
&gt;
&gt; The current related code uses UINT64_C for the 64-bit constants. No
&gt; configure test needed.

My bad, that came from 3.5.

Sorry about that.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325193816</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 19:38:16-0400</timestampReceived><subject></subject><body>

Hi Everyone,

Here's the result of building Nettle 3.7.2 on Solaris 11.3, i86pc:

/bin/gcc -I. -I/opt/ssh/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2 -m64
-march=native -fPIC -pthread -ggdb3 -Wall -W -Wno-sign-compare
-Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -fPIC -MT
sexp-format.o -MD -MP -MF sexp-format.o.d -c sexp-format.c \
&amp;&amp; true
sha256-compress-2.s: Assembler messages:
sha256-compress-2.s:87: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:89: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'
sha256-compress-2.s:96: Error: no such instruction: `sha256rnds2 %xmm5,%xmm6'
sha256-compress-2.s:98: Error: no such instruction: `sha256rnds2 %xmm6,%xmm5'

--enable-aes, --enable-sha, --enable-fat were _not_ provided to configure.

Attached is config.log.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210328095009</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-28 09:50:09-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; --enable-fat turns on cpu identification and runtime switching. I need
&gt; that. I need AES. I don't need SHA. It is impossible to get into a
&gt; good configuration.

I don't think it's worthwhile to add complexity to configure and the fat
machinery, and testing thereof, to make it flexible enough for that
usecase. In your case, you need it to be able to use an assembler
missing support for instructions added to the architecture 7.5 years
ago. Are there other usecases where more flexibility would be
beneficial?

I might consider it, if someone else wants to do the work, and it turns
out it doesn't get too messy.

To get it to work in your setting, I would suggest one of:

(i) Stick to --disable-assembler, to get something that works but is
    slow (and unfortunately a performance regression since nettle-3.6).

(ii) Upgrade your assembler to a version that recognizes the sha
     instructions (not sure which assembler you're using, I did ask,
     when you reported the problem back in January, but I haven't seen
     an answer). I would be a bit surprised if support for these
     instructions is still missing in recent releases of Oracle's
     development tools, if that's what you're using.

&gt; Nettle wastes a fair amount our time trying to work through these problems.

To be honest, high performance on the proprietary and somewhat obscure
Solaris operating system is not going to be a high priority to me, in
particular version 11.3 which is soon officially end of support (January
2024, according to wikipedia, curiously the same date as for the much
older Solaris 10). Correctness, which you'd get with
--disable-assembler, is considerably more important. I'm willing to help
getting Nettle to work on obscure and obsolete systems, as long as the
cost in added complexity is small.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210329205414</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2021-03-29 20:54:14-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

On Mon, 2021-03-29 at 19:32 +0200, Niels Möller wrote:
&gt; Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:
&gt; 
&gt; &gt; &gt; The new feature also needs documentation, will you look into that once
&gt; &gt; &gt; code, and in particular the interfaces, are solid?
&gt; &gt; &gt; 
&gt; &gt; Definitely!
&gt; &gt; What do you think the documentation should look like? Should it be
&gt; &gt; near paragraph 7.2.1? Like
&gt; &gt; 
&gt; &gt; 7.2.1.1 AES Key Wrap
&gt; 
&gt; That's one possibility, but I think it would also be natural to put it
&gt; somewhere under or close to "7.4. Authenticated encryption and
&gt; associated data", even though there's no associated data. That section
&gt; could perhaps be retitled to "Authenticated encryption" to generalize
&gt; it?
&gt; 
&gt; Or possibly under "7.3 Cipher modes", if it's too different from the
&gt; AEAD constructions.

FWIW NIST considers this a category on it's own under key management.

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210331210125</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-31 21:01:25-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, Mar 31, 2021 at 9:18 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; The reason it makes sense to me to split
&gt; aes-encrypt.c, is that:
&gt; 
&gt; (i) It's more consistent with the other aes-related functions.
&gt; 
&gt; (ii) The current aes-encrypt.c contains both the encryption functions
&gt; aes128_encrypt, aes192_encrypt, aes256_encrypt, which we'd want to
&gt; override with assembly implementations, and the legacy wrapper
&gt; function aes_encrypt, which shouldn't be overridden. So we can't
&gt; use plain file-level override, but need #ifdefs too.
&gt; 
&gt; (iii) I've considered doing it earlier, to make it easier to implement
&gt; aes without a round loop (like for all current versions of
&gt; aes-encrypt-internal.*). E.g., on x86_64, for aes128 we could load
&gt; all subkeys into registers and still have registers left to do two
&gt; or more blocks in parallel, but then we'd need to override
&gt; aes128_encrypt separately from the other aes*_encrypt.
&gt; 
&gt; I've tried out a split, see below patch. It's a rather large change,
&gt; moving pieces to new places, but nothing difficult. I'm considering
&gt; committing this to the s390x branch, what do you think?
&gt; 

I agree, I'll modify the patch of basic AES-128 optimized functions to be
built on top of the splitted aes functions.

Regarding the large number of functions for s390x, I'm not yet convinced
&gt; we should have all of them, we'll have to consider the tradeoff between
&gt; speedup and complexity case by case. In particular, cbc encrypt (but not
&gt; decrypt!) is notoriously slow, since it's inherently serial. So I'm
&gt; curious about potential speedup there.

Before getting too far, it may also be worthwhile to try out an assembly
&gt; memxor.
&gt; 

memxor performs the same in C and assembly since s390 architecture offers
memory xor instruction "xc" see xor_len macro in machine.m4 of the original
patch for an implementation example.
However, s390x AES accelerators offer considerable speedup against C
implementation with optimized internal AES. The following table
demonstrates the idea more clearly:

Function               S390x accelerator   C implementation with optimized
internal AES (Only enable aes128.asm, aes192.asm, aes256.asm)
-------------------------------------------------------------------------------------------------------------------------------
 CBC AES128 Encrypt  1.073569 cpb  13.674891 cpb
CBC AES128 Decrypt  0.647008 cpb  3.131405 cpb
CBC AES192 Encrypt  1.266316 cpb  13.183552 cpb
CBC AES192 Decrypt  0.622058 cpb  3.074917 cpb
CBC AES256 Encrypt  1.450422 cpb  14.380789 cpb
CBC AES256 Decrypt  0.648403 cpb  3.040746 cpb
CFB AES128 Encrypt  1.199716 cpb  15.116906 cpb
CFB AES128 Decrypt  1.205567 cpb  3.144538 cpb
CFB AES192 Encrypt  1.393276 cpb  15.340453 cpb
CFB AES192 Decrypt  1.415399 cpb  3.064844 cpb
CFB AES256 Encrypt  1.687762 cpb  15.876734 cpb
CFB AES256 Decrypt  1.677147 cpb  3.065851 cpb
CFB8 AES128 Encrypt 17.278379 cpb 178.117195 cpb
CFB8 AES128 Decrypt 17.327002 cpb 183.136198 cpb
CFB8 AES192 Encrypt 20.408311 cpb 184.028411 cpb
CFB8 AES192 Decrypt 20.397928 cpb 187.534654 cpb
CFB8 AES256 Encrypt 23.549944 cpb 184.800598 cpb
CFB8 AES256 Decrypt 23.367348 cpb 190.355030 cpb
CMAC AES128 Update  1.026380 cpb  12.108085 cpb
CMAC AES256 Update  1.399747 cpb  11.497727 cpb
CCM AES128 Encrypt  1.828593 cpb  15.332434 cpb
CCM AES128 Decrypt  1.691520 cpb  14.115167 cpb
CCM AES128 Update   1.027736 cpb  10.918015 cpb
CCM AES192 Encrypt  1.883996 cpb  15.840703 cpb
CCM AES192 Decrypt  1.950362 cpb  14.478925 cpb
CCM AES192 Update   1.213858 cpb  11.239195 cpb
CCM AES256 Encrypt  2.206957 cpb  15.861586 cpb
CCM AES256 Decrypt  2.311447 cpb  15.051353 cpb
CCM AES256 Update   1.404938 cpb  11.441472 cpb
CTR AES128 Crypt    0.710237 cpb  4.767290 cpb
CTR AES192 Crypt    0.635386 cpb  3.489661 cpb
CTR AES256 Crypt    0.628296 cpb  3.138727 cpb
XTS AES128 Encrypt  0.655454 cpb  15.757406 cpb
XTS AES128 Decrypt  0.656113 cpb  15.920863 cpb
XTS AES256 Encrypt  0.663048 cpb  16.689253 cpb
XTS AES256 Decrypt  0.676298 cpb  16.670889 cpb
GCM AES128 Encrypt  0.630504 cpb  15.473187 cpb
GCM AES128 Decrypt  0.627714 cpb  15.529209 cpb
GCM AES128 Update   0.514662 cpb  11.608726 cpb
GCM AES192 Encrypt  0.642785 cpb  15.245804 cpb
GCM AES192 Decrypt  0.631627 cpb  15.511039 cpb
GCM AES192 Update   0.499630 cpb  11.745876 cpb
GCM AES256 Encrypt  0.631046 cpb  15.400776 cpb
GCM AES256 Decrypt  0.622329 cpb  15.419954 cpb
GCM AES256 Update   0.499630 cpb  11.569789 cpb

Also, the optimized AES cores for s390x could serve as a good reference for
other crypto libraries since they have clean and well-documented assembly
implementation.
The only drawback I can see is spamming preprocessor conditions in C files
of AES modes to support fat build for those accelerators which is worth it
IMO considering the speed gain we get.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210322014511</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-22 01:45:11-0400</timestampReceived><subject>Nettle 3.7.2 and OS X 10.5</subject><body>

Hi Everyone,

I'm testing Nettle 3.7.2  on a PowerMac with OS X 10.5 . I added
-maltivec to CFLAGS and CXXFLAGS. I enabled Altivec builds with
--enable-power-altivec and --enable-fat.

Auditing the dylib it appears Altivec was not engaged:

$ otool -tV /usr/local/lib/libnettle.dylib | grep perm
0001f124        b       _nettle_sha3_permute
_nettle_sha3_permute:
000204ec        bl      _nettle_sha3_permute

I think there's something a bit sideways here.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210321221849</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-21 22:18:49-0400</timestampReceived><subject>Nettle 3.7.2 and OS X 10.12.6</subject><body>

$ make check
...
          ../run-tests aes-test arcfour-test arctwo-test blowfish-test
bcrypt-test cast128-test base16-test base64-test camellia-test
chacha-test cnd-memcpy-test des-test des3-test md2-test md4-test
md5-test md5-compat-test memeql-test memxor-test gosthash94-test
ripemd160-test hkdf-test salsa20-test sha1-test sha224-test
sha256-test sha384-test sha512-test sha512-224-test sha512-256-test
sha3-permute-test sha3-224-test sha3-256-test sha3-384-test
sha3-512-test shake256-test streebog-test serpent-test twofish-test
version-test knuth-lfib-test cbc-test cfb-test ctr-test gcm-test
eax-test ccm-test cmac-test siv-test poly1305-test
chacha-poly1305-test hmac-test umac-test meta-hash-test
meta-cipher-test meta-aead-test meta-armor-test meta-mac-test
buffer-test yarrow-test xts-test pbkdf2-test x86-ibt-test  sexp-test
sexp-format-test rsa2sexp-test sexp2rsa-test bignum-test
random-prime-test pkcs1-test pkcs1-sec-decrypt-test pss-test
rsa-sign-tr-test pss-mgf1-test rsa-pss-sign-tr-test rsa-test
rsa-encrypt-test rsa-keygen-test rsa-sec-decrypt-test
rsa-compute-root-test dsa-test dsa-keygen-test curve25519-dh-test
curve448-dh-test ecc-mod-test ecc-modinv-test ecc-redc-test
ecc-sqrt-test ecc-dup-test ecc-add-test ecc-mul-g-test ecc-mul-a-test
ecdsa-sign-test ecdsa-verify-test ecdsa-keygen-test ecdh-test
eddsa-compress-test eddsa-sign-test eddsa-verify-test ed25519-test
ed448-test gostdsa-sign-test gostdsa-verify-test gostdsa-keygen-test
gostdsa-vko-test cxx-test sexp-conv-test pkcs1-conv-test
nettle-pbkdf2-test symbols-test  dlopen-test
/bin/sh: ../run-tests: Permission denied
make[1]: *** [check] Error 126
make: *** [check] Error 2

$ cd testsuite/

$ ../run-tests aes-test
-bash: ../run-tests: Permission denied

$ ls -Al ../run-tests
-rw-r--r--  1 jwalton  staff  2777 Mar 21 04:32 ../run-tests
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210321222323</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-21 22:23:23-0400</timestampReceived><subject>Re: Nettle 3.7.2 and OS X 10.12.6</subject><body>

On Sun, Mar 21, 2021 at 6:18 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; $ make check
&gt; ...
&gt;           ../run-tests aes-test arcfour-test arctwo-test blowfish-test
&gt; bcrypt-test cast128-test base16-test base64-test camellia-test
&gt; chacha-test cnd-memcpy-test des-test des3-test md2-test md4-test
&gt; md5-test md5-compat-test memeql-test memxor-test gosthash94-test
&gt; ripemd160-test hkdf-test salsa20-test sha1-test sha224-test
&gt; sha256-test sha384-test sha512-test sha512-224-test sha512-256-test
&gt; sha3-permute-test sha3-224-test sha3-256-test sha3-384-test
&gt; sha3-512-test shake256-test streebog-test serpent-test twofish-test
&gt; version-test knuth-lfib-test cbc-test cfb-test ctr-test gcm-test
&gt; eax-test ccm-test cmac-test siv-test poly1305-test
&gt; chacha-poly1305-test hmac-test umac-test meta-hash-test
&gt; meta-cipher-test meta-aead-test meta-armor-test meta-mac-test
&gt; buffer-test yarrow-test xts-test pbkdf2-test x86-ibt-test  sexp-test
&gt; sexp-format-test rsa2sexp-test sexp2rsa-test bignum-test
&gt; random-prime-test pkcs1-test pkcs1-sec-decrypt-test pss-test
&gt; rsa-sign-tr-test pss-mgf1-test rsa-pss-sign-tr-test rsa-test
&gt; rsa-encrypt-test rsa-keygen-test rsa-sec-decrypt-test
&gt; rsa-compute-root-test dsa-test dsa-keygen-test curve25519-dh-test
&gt; curve448-dh-test ecc-mod-test ecc-modinv-test ecc-redc-test
&gt; ecc-sqrt-test ecc-dup-test ecc-add-test ecc-mul-g-test ecc-mul-a-test
&gt; ecdsa-sign-test ecdsa-verify-test ecdsa-keygen-test ecdh-test
&gt; eddsa-compress-test eddsa-sign-test eddsa-verify-test ed25519-test
&gt; ed448-test gostdsa-sign-test gostdsa-verify-test gostdsa-keygen-test
&gt; gostdsa-vko-test cxx-test sexp-conv-test pkcs1-conv-test
&gt; nettle-pbkdf2-test symbols-test  dlopen-test
&gt; /bin/sh: ../run-tests: Permission denied
&gt; make[1]: *** [check] Error 126
&gt; make: *** [check] Error 2
&gt;
&gt; $ cd testsuite/
&gt;
&gt; $ ../run-tests aes-test
&gt; -bash: ../run-tests: Permission denied
&gt;
&gt; $ ls -Al ../run-tests
&gt; -rw-r--r--  1 jwalton  staff  2777 Mar 21 04:32 ../run-tests

This fixed the run-tests problem.

find . -name 'run-tests' -exec chmod +x {} \;
if [[ -n "$(command -v xattr 2&gt;/dev/null)" ]]; then
    find . -name 'run-tests' -exec xattr -r -d com.apple.quarantine {} \;
fi

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210321201954</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-03-21 20:19:54-0400</timestampReceived><subject>[AArch64] Fat build support for GCM optimization and syntax improvements</subject><body>

I made a merge request #21
&lt;https://git.lysator.liu.se/nettle/nettle/-/merge_requests/21&gt; that adds
fat build support for GCM implementation on arm64, the patch also updates
the README file to stay on par with the other architectures and use m4
macros in gcm-hash.asm (patch provided by Niels Möller), in addition to add
documentation comments.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325014758</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 01:47:58-0400</timestampReceived><subject>libhgwwed has gone missing...</subject><body>

It looks like Nettle is no longer building or installing hogweed on
some Apple platforms.

This is from a PowerMac G5 running OS X 10.5:

$ ls /usr/local/lib | grep -E 'gmp|nettle|hogweed'
libgmp.10.dylib
libgmp.a
libgmp.dylib
libgmp.la
libnettle.8.2.dylib
libnettle.8.3.dylib
libnettle.8.dylib
libnettle.a
libnettle.dylib
libpari-gmp.dylib

It is causing a failure in GnuTLS:

checking for NETTLE... yes
checking for HOGWEED... no
configure: error:
  ***
  *** Libhogweed (nettle's companion library) 3.4.1 was not found.
Note that you must compile nettle with gmp support.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325022018</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 02:20:18-0400</timestampReceived><subject>Re: libhgwwed has gone missing...</subject><body>

The last version of Nettle to build and install Hogweed on PowerMac was 3.5.

I think this flew under the radar because prefix=/usr/local. Through
subsequent upgrades, GnuTLS was picking up the old version of Hogwwed.

Jeff

On Wed, Mar 24, 2021 at 9:47 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; It looks like Nettle is no longer building or installing hogweed on
&gt; some Apple platforms.
&gt;
&gt; This is from a PowerMac G5 running OS X 10.5:
&gt;
&gt; $ ls /usr/local/lib | grep -E 'gmp|nettle|hogweed'
&gt; libgmp.10.dylib
&gt; libgmp.a
&gt; libgmp.dylib
&gt; libgmp.la
&gt; libnettle.8.2.dylib
&gt; libnettle.8.3.dylib
&gt; libnettle.8.dylib
&gt; libnettle.a
&gt; libnettle.dylib
&gt; libpari-gmp.dylib
&gt;
&gt; It is causing a failure in GnuTLS:
&gt;
&gt; checking for NETTLE... yes
&gt; checking for HOGWEED... no
&gt; configure: error:
&gt;   ***
&gt;   *** Libhogweed (nettle's companion library) 3.4.1 was not found.
&gt; Note that you must compile nettle with gmp support.
&gt;
&gt; Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325074838</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-03-25 07:48:38-0400</timestampReceived><subject>Re: libhgwwed has gone missing...</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; It looks like Nettle is no longer building or installing hogweed on
&gt; some Apple platforms.
&gt;
&gt; This is from a PowerMac G5 running OS X 10.5:

Most likely the configure check for libgmp failed. Check config.log for
details. I think the most recent change to the gmp dependency was in
nettle-3.6, which requires gmp-6.1 or later.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210325172007</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-25 17:20:07-0400</timestampReceived><subject>Re: libhgwwed has gone missing...</subject><body>

On Thu, Mar 25, 2021 at 3:48 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; It looks like Nettle is no longer building or installing hogweed on
&gt; &gt; some Apple platforms.
&gt; &gt;
&gt; &gt; This is from a PowerMac G5 running OS X 10.5:
&gt;
&gt; Most likely the configure check for libgmp failed. Check config.log for
&gt; details. I think the most recent change to the gmp dependency was in
&gt; nettle-3.6, which requires gmp-6.1 or later.

Here is what the GMP install looks like:

$ ls -al /usr/local/lib/*gmp*
-rwxr-xr-x  1 root  wheel   543216 Mar 24 21:39 /usr/local/lib/libgmp.10.dylib
-rw-r--r--  1 root  wheel  3078944 Mar 24 21:39 /usr/local/lib/libgmp.a
lrwxr-xr-x  1 root  wheel       15 Mar 24 21:39
/usr/local/lib/libgmp.dylib -&gt; libgmp.10.dylib
-rwxr-xr-x  1 root  wheel      947 Mar 24 21:39 /usr/local/lib/libgmp.la

And:

$ cat /usr/local/lib/pkgconfig/gmp.pc
prefix=/usr/local
exec_prefix=${prefix}
includedir=${prefix}/include
libdir=${prefix}/lib

Name: GNU MP
Description: GNU Multiple Precision Arithmetic Library
URL: https://gmplib.org
Version: 6.2.1
Cflags: -I${includedir}
Libs: -L${libdir} -lgmp

Attached is config.log.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210321223841</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-03-21 22:38:41-0400</timestampReceived><subject>Nettle 3.7.2 and OS X 10.12.6</subject><body>

And it looks like examples are not quite working either:

$ make check
...
====================
All 110 tests passed
====================
Making check in examples
TEST_SHLIB_DIR="/Users/jwalton/Build-Scripts/nettle-3.7.2/.lib" \
          srcdir="." EMULATOR="" EXEEXT="" \
          ".."/run-tests rsa-sign-test rsa-verify-test rsa-encrypt-test
Opening `testkey' failed: No such file or directory
Invalid key
FAIL: rsa-sign
Opening `testkey' failed: No such file or directory
Invalid key
FAIL: rsa-verify
Opening `testkey.pub' failed: No such file or directory
Invalid key
FAIL: rsa-encrypt
===================
3 of 3 tests failed
===================
make[1]: *** [check] Error 1
make: *** [check] Error 2

$ find . -name testkey.pub
$ find . -name testkey
$

Examples have been breaking the build for years. Why are examples even
built during 'make check'? Can they be moved to their own recipe so
users can get on with their work?

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210201192257</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-01 19:22:57-0400</timestampReceived><subject>Re: Add pbkdf2_hmac_sha384 and pbkdf2_hmac_sha512 to Nettle</subject><body>

Nicolas Mora &lt;nicolas@babelouest.org&gt; writes:

&gt; I just opened a merge request [1] to add pbkdf2_hmac_sha384 and
&gt; pbkdf2_hmac_sha512 to the Nettle library.

Looks good, merged to the master-updates branch with minor comment
edits.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210205171415</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-05 17:14:15-0400</timestampReceived><subject>Re: Add AES Key Wrap (RFC 3394) in Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I've updated the MR with the new functions definitions and added test 
cases based on the test vectors from the RFC.

https://git.lysator.liu.se/nettle/nettle/-/merge_requests/19

Le 2021-02-04 Ã  01 h 48, Niels MÃ¶ller a Ã©crit  :
&gt; 
&gt;&gt; It was designed to wrap key data, but not necessarily AES only. The
&gt;&gt; kek must be an AES key though. The key data to wrap can be any data,
&gt;&gt; as long as it's a set of 64 bits blocks.
&gt; 
&gt; If it doesn't add a lot of complexity, I think it would be nice to be
&gt; able to substitute at least other 16-byte block ciphers (e.g., any other
&gt; AES finalist, serpent and twofish being the once currently implemented in
&gt; Nettle).
&gt; 
No problem, as long as cleartext is an array of 64bits, the function 
will wrap it, not matter what is is.

&gt; 
&gt;&gt; We can also replace the uint8_t with uint64_t as well in the input values?
&gt; 
&gt; It would be nice if we could have that alignment on input and output,
&gt; but I think it's not a good idea to have uint64_t in this interface.
&gt; We'd force alignment requirement on callers (who may be forced to make
&gt; an extra copy to be able to call the function), and we'd also need to
&gt; document endianness of the input. In short, since the specification
&gt; defines the mechanism as operating on byte strings, the Nettle api
&gt; should too.
&gt; 
&gt; I suspect that using byte strings in the interface and uint64_t
&gt; internally makes it a bit difficult to allocate storage for internal
&gt; state, since one can't just reuse the output buffer for working storage.
&gt; Is the size needed for internal state same as the message size, or is if
&gt; fixed size? I think it's doable but tricky to make it work without
&gt; separate allocation for working storage.
&gt; 
After testing with uint64_t arrays for ciphertext and cleartext, I'd 
prefer getting back to uint8_t arrays instead. there are no iunt64_t 
data blocks used elsewhere in the library so one would have to convert 
all uint8_t to uint64_t and vice-versa, I think this change could be 
avoided.

Do you agree?

&gt; 
&gt; I was pointed to RFC 5649 (AES Key Wrap with Padding), is that relevant?
&gt; 
I'm not sure, the JOSE specification don't mention it so I wasn't aware 
of its existence before.
I'll have a look but since it's an addon to RFC 3394, it may be 
implemented as an additional function.

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210205190007</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-02-05 19:00:07-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

On Wed, Feb 3, 2021 at 5:47 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; It looks like this hardcodes the branch to test ("s390x"), while the ci
&gt; jobs usually runs on all branches. It also doesn't clean up the remote
&gt; state between builds.
&gt;
&gt; I wonder if it would be more reliable to run make dist
&gt; PACKAGE_VERSION=snapshot on the ci build machine, and copy the resulting
&gt; tarball to the remote machine for build and test. The commands run on the
&gt; remote machine should unpack the snapshot in a fresh directory, run
&gt; configure, make, make check.
&gt;


I figured an approach that test the branch in which the changes are
committed:

Debian.remote.s390x:
  image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$DEBIAN_BUILD
  before_script:
  - apt-get update -qq
  - apt-get install -qq git
  - 'which ssh-agent || ( apt-get install -qq openssh-client )'
  - eval $(ssh-agent -s)
  - ssh-add &lt;(echo "$SSH_PRIVATE_KEY")
  - mkdir -p ~/.ssh
  - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" &gt; ~/.ssh/config
  - ssh linux1@IP_ADDRESS "mkdir -p nettle_ci/$CI_PIPELINE_IID"
  script:
  - ssh linux1@IP_ADDRESS "cd nettle_ci/$CI_PIPELINE_IID &amp;&amp; git clone
--depth=1 --branch $CI_COMMIT_REF_NAME https://gitlab.com/gnutls/nettle.git
. &amp;&amp;
    ./.bootstrap &amp;&amp; ./configure --disable-documentation &amp;&amp; make &amp;&amp; make
check"
  after_script:
  - eval $(ssh-agent -s)
  - ssh-add &lt;(echo "$SSH_PRIVATE_KEY")
  - ssh linux1@IP_ADDRESS "rm -rf nettle_ci/$CI_PIPELINE_IID/ &amp;&amp; exit"
  tags:
  - shared
  - linux
  except:
  - tags

It used CI_PIPELINE_IID to make a new directory with a unique name to
safely handle job race conditions in case pushing many commits quickly.
According to
https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
CI_PIPELINE_IID
is unique for the current project so it's ok to use it in this context.
After the job is completed, the directory with a unique name is removed for
cleaning up.
However, this approach has a downside, if more than one commit is pushed
quickly, all the created pipelines may check the latest commit, not the
corresponding ones. We can solve this issue by
using CI_COMMIT_SHA predefined environment variable and commands like git
reset --hard $CI_COMMIT_SHA or git checkout $CI_COMMIT_SHA. However, I
haven't tested any and am not sure if it's worth it.

Maamoun's suggested method was to add it as a "Variable" in the CI/CD
&gt; web config, I'm assuming that will not make it publicly visible (but I'd
&gt; need to double check).
&gt;

It looks like it doesn't expose the key publicly, it shows $SSH_PRIVATE_KEY
name in the console windows without revealing any value, not sure if there
other places where such things could be exploited or something.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210206160752</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-06 16:07:52-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; The arm64 branch builds and passes the testsuite on aarch64 and
&gt; aarch64_be with gcc 10.2 and clang 11.0.1 with and without the optimized
&gt; assembly routines on my pine64 boards. This is with the .arch directive
&gt; instead of modifying CFLAGS and the new configure option name
&gt; --enable-arm64-crypto.

Thanks for testing! (My own testing was done with cross-compiler and
user-level qemu).

&gt; Out of curiosity I've also collected some benchmark numbers for
&gt; gcm_aes256. (Is that a correct and sensible algorithm for that purpose?)

I think that's appropriate for benchmarking gcm_hash, but the "update"
numbers are the ones that reflect gcm_hash performance.

&gt; The speedup from using pmull seems to be around 35% for encrypt/decrypt.
&gt;
&gt; Interestingly, LE is about a cycle per block faster than BE even though
&gt; it should have quite a few more rev64s to execute than BE. Could this be
&gt; masked by memory accesses, pipelining or scheduling?

For the encrypt/decrypt operations, you also run AES (in CTR mode),
which works with little-endian data.

&gt; How is the massive speedup in update to be interpreted and that BE here
&gt; is indeed quite a bit faster than LE? Do I understand correctly that on
&gt; update only GCM is run on unencrypted data for authentication purposes
&gt; so that this number really indicates the pure GCM pmull speedup?

That's right, the "update" numbers runs only the authentication part of
gcm, i.e., gcm_hash. Which is useful for benchmarking gcm_hash, but
probably not so relevant for real world applications, since I'd expect
it's rare to pass large amounts of "associated data" to gcm.

&gt; What's also curious is that the system's openssl 1.1.1i is consistenly
&gt; reported an order of magnitude faster than nettle. I guess the major
&gt; factor is that there's no optimized AES for aarch64 yet in nettle which
&gt; openssl seems to have.

That would be my guess too. And if we look at the update numbers only,
the new code appears a bit faster than openssl.

&gt; Just out of curiosity: I assume there's no aesni-pmull-like GCM
&gt; implementation for x86_64?

That's right. There's some assembly code, but using the same algorithm
as the C implementation, based on table lookups.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210206190631</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-02-06 19:06:31-0400</timestampReceived><subject>Re: Old ARM Neon code for salsa20 and chacha</subject><body>

Hello Niels,

On Thu, Jan 28, 2021 at 07:26:46PM +0100, Niels Möller wrote:

&gt; &gt; With the new 2-way or 3-way functions, performance of the single-block
&gt; &gt; functions isn't that critical, so deletion may be ok even if it causes
&gt; &gt; some small regression on some processors (e.g., single-block chacha
&gt; &gt; getting 13% slower on the old Cortex-A9)
&gt; I've made a branch with deletion of this code, "delete-1-way-neon". Any
&gt; comments before I merge to master?

Removing them also lowers the amount of code to maintain. I've done a few
quick builds of the branch with and without assembly and NEON in
particular enabled. All combinations build, run the testsuite and
benchmark results look consistent to me.
-- 
Thanks, Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210210132420</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-10 13:24:20-0400</timestampReceived><subject>Bug fix release Nettle-3.7.1 ?</subject><body>

Hi, I think the chacha bug is a severe enough regression to warrant a
bugfix release pretty soon. I'll aim to get it out in a week from now.

I think it should be fine to do a 3.7.1 release from the master branch,
rather than cherry-picking selected bugfixes. I've looked through git
history and ChangeLog since the release one and a half month ago, and I
think this is a accurate summary for the NEWS file:

	Bug fixes:

	* Fix bug in chacha counter update logic. The problem affected
	  ppc64 and ppc64el, with the new altivec assembly code
	  enabled. Reported by Andreas Metzler, after breakage in
	  GnuTLS tests on ppc64.

	* Support for big-endian ARM platforms has been restored.
	  Fixes contributed by Michael Weiser.

	* Fix build problem on OpenBSD/powerpc64, reported by Jasper
	  Lievisse Adriaanse.

	* Fix corner case bug in ECDSA verify, it would produce
	  incorrect result in the unlikely case of an all-zero
	  message hash. Reported by Guido Vranken.

	New features:

	* Support for pbkdf2_hmac_sha384 and pbkdf2_hmac_sha512,
	  contributed by Nicolas Mora.

	Miscellaneous:

	* Poorly performing ARM Neon code for doing single-block
	  Salsa20 and Chacha has been deleted. The code to do two or
	  three blocks in parallel, introduced in Nettle-3.7, is
	  unchanged.

Sonames will be unchanged. libnettle.so should get an incremented minor
number, for the addition of the new pbkdf2 function. I don't think
libhogweed.so strictly needs an incremented minor number, but maybe it's
less confusing to increment it anyway.

Anything I'm missing? Any easy in-progress changes that should also get
into the release?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210210172552</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2021-02-10 17:25:52-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

On 2021-02-10 Daiki Ueno &lt;ueno@gnu.org&gt; wrote:
&gt; nisse@lysator.liu.se (Niels Möller) writes:
[...]
&gt; &gt; Tentative patch below, but I need to extend the tests to get proper test
&gt; &gt; coverage of this case.

&gt; Thank you so much!  The patch fixes the issue (tested on gcc cfarm).

Hello,

Just for completeness sake I can confirm that nettle Git master
64837b2e433e2b99b893683949bad3a99acab38f lets gnutls testsuite succeed
on Debian's ppc64el porter machine.

Thank you very much for fixing this so quickly.

cu Andreas
-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210212224126</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-12 22:41:26-0400</timestampReceived><subject>Re: Add RSA-OAEP encryption/decryption to Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello again,

After rethinking it, I refactored the new functions to be consistent 
with how Nettle functions are designed, now there's one encrypt/decrypt 
function per hash.

https://git.lysator.liu.se/nettle/nettle/-/merge_requests/20

The new functions are the following:

Encryption:
int
rsa_oaep_sha1_encrypt(const struct rsa_public_key *key,
	    void *random_ctx, nettle_random_func *random,
	    size_t label_length, const uint8_t *label,
	    size_t length, const uint8_t *message,
	    mpz_t gibberish);

int
rsa_oaep_sha256_encrypt(const struct rsa_public_key *key,
	    void *random_ctx, nettle_random_func *random,
	    size_t label_length, const uint8_t *label,
	    size_t length, const uint8_t *message,
	    mpz_t gibberish);

int
rsa_oaep_sha384_encrypt(const struct rsa_public_key *key,
	    void *random_ctx, nettle_random_func *random,
	    size_t label_length, const uint8_t *label,
	    size_t length, const uint8_t *message,
	    mpz_t gibberish);

int
rsa_oaep_sha512_encrypt(const struct rsa_public_key *key,
	    void *random_ctx, nettle_random_func *random,
	    size_t label_length, const uint8_t *label,
	    size_t length, const uint8_t *message,
	    mpz_t gibberish);

Decryption:
int
rsa_oaep_sha1_decrypt(const struct rsa_private_key *key,
	    size_t label_length, const uint8_t *label,
	    size_t *length, uint8_t *message,
	    const mpz_t gibberish);

int
rsa_oaep_sha256_decrypt(const struct rsa_private_key *key,
	    size_t label_length, const uint8_t *label,
	    size_t *length, uint8_t *message,
	    const mpz_t gibberish);

int
rsa_oaep_sha384_decrypt(const struct rsa_private_key *key,
	    size_t label_length, const uint8_t *label,
	    size_t *length, uint8_t *message,
	    const mpz_t gibberish);

int
rsa_oaep_sha512_decrypt(const struct rsa_private_key *key,
	    size_t label_length, const uint8_t *label,
	    size_t *length, uint8_t *message,
	    const mpz_t gibberish);

The tests are updated too

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210214104535</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-02-14 10:45:35-0400</timestampReceived><subject>Re: Arcfour status</subject><body>

On Sun, Feb 14, 2021 at 5:36 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; I've had a report (from Matthew Kempe) about another problem with the
&gt; openssl benchmarking code. It fails on FreeBSD, because there (and
&gt; possible in other environments too) openssl has been configured without
&gt; RC4 (aka arcfour) support. I'm considering just deleting code to
&gt; benchmark openssl arcfour; I don't plan any improvements of Nettle's
&gt; arcfour performance, and I would be surprised if the openssl people do.

If you want to retain the support when OpenSSL makes it available...

I think you can pick up RC4 availability via opensslconf.h. If RC4 is
disabled, then OpenSSL will define OPENSSL_NO_RC4. For example, here's
the define from OpenSSL sources:

openssl$ grep -IR NO_RC4 ./*
./apps/rsa.c:#ifndef OPENSSL_NO_RC4
./apps/rsa.c:#ifndef OPENSSL_NO_RC4
./apps/speed.c:#ifndef OPENSSL_NO_RC4
...

And here's what an opensslconf.h looks like:

$ grep OPENSSL_NO /usr/include/openssl/opensslconf.h | head -n 4
#ifndef OPENSSL_NO_COMP
# define OPENSSL_NO_COMP
#ifndef OPENSSL_NO_MD2
# define OPENSSL_NO_MD2

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210217204611</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-17 20:46:11-0400</timestampReceived><subject>ANNOUNCE: Nettle-3.7.1</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

I'd like to announce a new release of GNU Nettle, a low-level
cryptographics library. This release fixes a few problem in Nettle-3.7,
in particular, a bug affecting GnuTLS on powerpc64 platforms. See NEWS
entries below.

The Nettle home page can be found at
https://www.lysator.liu.se/~nisse/nettle/, and the manual at
https://www.lysator.liu.se/~nisse/nettle/nettle.html.

The release can be downloaded from

  https://ftp.gnu.org/gnu/nettle/nettle-3.7.1.tar.gz
  ftp://ftp.gnu.org/gnu/nettle/nettle-3.7.1.tar.gz
  https://www.lysator.liu.se/~nisse/archive/nettle-3.7.1.tar.gz

Happy hacking,
/Niels Möller

NEWS for the Nettle 3.7.1 release

	This is primarily a bug fix release, fixing a couple of
	problems found in Nettle-3.7.

	The new version is intended to be fully source and binary
	compatible with Nettle-3.6. The shared library names are
	libnettle.so.8.2 and libhogweed.so.6.2, with sonames
	libnettle.so.8 and libhogweed.so.6.

	Bug fixes:

	* Fix bug in chacha counter update logic. The problem affected
	  ppc64 and ppc64el, with the new altivec assembly code
	  enabled. Reported by Andreas Metzler, after breakage in
	  GnuTLS tests on ppc64.

	* Support for big-endian ARM platforms has been restored.
	  Fixes contributed by Michael Weiser.

	* Fix build problem on OpenBSD/powerpc64, reported by Jasper
	  Lievisse Adriaanse.

	* Fix corner case bug in ECDSA verify, it would produce
	  incorrect result in the unlikely case of an all-zero
	  message hash. Reported by Guido Vranken.

	New features:

	* Support for pbkdf2_hmac_sha384 and pbkdf2_hmac_sha512,
	  contributed by Nicolas Mora.

	Miscellaneous:

	* Poorly performing ARM Neon code for doing single-block
	  Salsa20 and Chacha has been deleted. The code to do two or
	  three blocks in parallel, introduced in Nettle-3.7, is
	  unchanged.


- -- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

-----BEGIN PGP SIGNATURE-----

iQEzBAEBCgAdFiEEy0li0HDXfX/Li6Nicdjx/zaMZncFAmAtgJMACgkQcdjx/zaM
ZnfTEQf+KdzEoCkSHZfOFQ9qreKfY4ZVzxO3Nbh8wBiQYbueUw2X9kNxh+ErL4M7
FL2ovRbE3vLsWft5Y+rWg7wmDPUCwOdVsovURwENB6l+kbynksG+DWhIfg6hcjQ4
qqlhSArW/2UtIlswMj1hfh/g//aUDl0gigZX0C1LmCIlr4IzZvmMk5+9ZsR+9cXT
+R/gdh2Hxw/DzMT8yB/J5wP5/5IzA5xkV2LhBKqS538bFEVsE7t+DInEjoUYhmtv
st5VuyUxstKxqtp6RB+RfVcWDwpyyMi6/wn8fKfv5UkdVVgOHsXwY2Ls2YG6oKvs
XswtEhTV17sYMTlVNtLKm8vOLnLYPA==
=E0qp
-----END PGP SIGNATURE-----
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210225185713</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-25 18:57:13-0400</timestampReceived><subject>Re: HPKE implementation</subject><body>

Norbert Pocs &lt;npocs@redhat.com&gt; writes:

&gt; My current project is the implementation of HPKE draft [0]. The first goal
&gt; is to implement mode_base.

Hi, I was not aware of this work. It could make sense to support in
Nettle, in particular if GnuTLS wants to use it.

Which combinations of public key mechanism, key derivation/expansion,
and aead are of main interest?

Do you expect the specification to be finalized soon?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210226164034</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-02-26 16:40:34-0400</timestampReceived><subject>Re: Status update</subject><body>

Hi Niels,

On Thu, Feb 25, 2021 at 10:14 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; 1. New Arm64 code (don't recall current status off the top of my head).
&gt;

It has no issue I'm aware of, as long the arm64 code is reviewed, passes
the testsuite, and hits the expected performance it's ok to move forward
and merge the branch to master IMO.


&gt; 2. s390x testing. I'd prefer to not run a git checkout on the s390x test
&gt;    machine, but have the ci job make a tarball, ssh it over to the test
&gt;    machine, unpack in a fresh directory for build and test. This needs
&gt;    to be in place before adding s390x specific code. When done, could
&gt;    likely be reused for remote testing on any other platforms of
&gt;    interest, which aren't directly available in the ci system.
&gt;

Ok, I'll see what I can do here.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210123185230</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-23 18:52:30-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Michael,

On Sat, Jan 23, 2021 at 2:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; I've just retested and reread some ARM documents. Here's a patch that
&gt; uses ld1.16b and thus eliminates almost all special BE treatment but
&gt; subsequently has to leave in all the rev64s as well. This has the
&gt; testsuite passing on BE and (still) LE. My take at an explanation below.
&gt;
&gt; diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
&gt; index 1c14db54..8c8a370e 100644
&gt; --- a/arm64/v8/gcm-hash.asm
&gt; +++ b/arm64/v8/gcm-hash.asm
&gt; @@ -55,17 +55,10 @@ C common macros:
&gt;  .endm
&gt;
&gt;  .macro REDUCTION out
&gt; -IF_BE(`
&gt; -    pmull          T.1q,F.1d,POLY.1d
&gt; -    ext            \out\().16b,F.16b,F.16b,#8
&gt; -    eor            R.16b,R.16b,T.16b
&gt; -    eor            \out\().16b,\out\().16b,R.16b
&gt; -',`
&gt;      pmull          T.1q,F.1d,POLY.1d
&gt;      eor            R.16b,R.16b,T.16b
&gt;      ext            R.16b,R.16b,R.16b,#8
&gt;      eor            \out\().16b,F.16b,R.16b
&gt; -')
&gt;  .endm
&gt;
&gt;      C void gcm_init_key (union gcm_block *table)
&gt; @@ -108,27 +101,20 @@ define(`H4M', `v29')
&gt;  define(`H4L', `v30')
&gt;
&gt;  .macro PMUL_PARAM in, param1, param2
&gt; -IF_BE(`
&gt; -    pmull2         Hp.1q,\in\().2d,POLY.2d
&gt; -    ext            Hm.16b,\in\().16b,\in\().16b,#8
&gt; -    eor            Hm.16b,Hm.16b,Hp.16b
&gt; -    zip            \param1\().2d,\in\().2d,Hm.2d
&gt; -    zip2           \param2\().2d,\in\().2d,Hm.2d
&gt; -',`
&gt;      pmull2         Hp.1q,\in\().2d,POLY.2d
&gt;      eor            Hm.16b,\in\().16b,Hp.16b
&gt;      ext            \param1\().16b,Hm.16b,\in\().16b,#8
&gt;      ext            \param2\().16b,\in\().16b,Hm.16b,#8
&gt;      ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
&gt; -')
&gt;  .endm
&gt;
&gt;  PROLOGUE(_nettle_gcm_init_key)
&gt; -    ldr            HQ,[TABLE,#16*H_Idx]
&gt; +    C LSB vector load: x1+0 into H.b[0] and x1+15 into H.b[15]
&gt; +    add            x1,TABLE,#16*H_Idx
&gt; +    ld1            {H.16b},[x1]
&gt;      dup            EMSB.16b,H.b[0]
&gt; -IF_LE(`
&gt; +    C treat H as two MSB doublewords
&gt;      rev64          H.16b,H.16b
&gt; -')
&gt;      mov            x1,#0xC200000000000000
&gt;      mov            x2,#1
&gt;      mov            POLY.d[0],x1
&gt; @@ -221,9 +207,7 @@ PROLOGUE(_nettle_gcm_hash)
&gt;      mov            POLY.d[0],x4
&gt;
&gt;      ld1            {D.16b},[X]
&gt; -IF_LE(`
&gt;      rev64          D.16b,D.16b
&gt; -')
&gt;
&gt;      ands           x4,LENGTH,#-64
&gt;      b.eq           L2x
&gt; @@ -234,12 +218,10 @@ IF_LE(`
&gt;
&gt;  L4x_loop:
&gt;      ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
&gt; -IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt;      rev64          C1.16b,C1.16b
&gt;      rev64          C2.16b,C2.16b
&gt;      rev64          C3.16b,C3.16b
&gt; -')
&gt;
&gt;      eor            C0.16b,C0.16b,D.16b
&gt;
&gt; @@ -262,10 +244,8 @@ L2x:
&gt;      ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
&gt;
&gt;      ld1            {C0.16b,C1.16b},[DATA],#32
&gt; -IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt;      rev64          C1.16b,C1.16b
&gt; -')
&gt;
&gt;      eor            C0.16b,C0.16b,D.16b
&gt;
&gt; @@ -283,9 +263,7 @@ L1x:
&gt;      ld1            {H1M.16b,H1L.16b},[TABLE]
&gt;
&gt;      ld1            {C0.16b},[DATA],#16
&gt; -IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt; -')
&gt;
&gt;      eor            C0.16b,C0.16b,D.16b
&gt;
&gt; @@ -335,9 +313,7 @@ Lmod_8_done:
&gt;      REDUCTION D
&gt;
&gt;  Ldone:
&gt; -IF_LE(`
&gt;      rev64          D.16b,D.16b
&gt; -')
&gt;      st1            {D.16b},[X]
&gt;      ret
&gt;  EPILOGUE(_nettle_gcm_hash)


I have one question here, do operations on doublewords transpose both
doubleword parts in BE mode? for example pmull instruction transpose
doublewords on LE mode when operated, in BE I don't expect the same
behavior hence we can't get this patch working on BE mode. The core of
pmull instruction is shift and xor operations so we can't perform pmull
instruction on byte-reversed doublewords as it's gonna produce wrong
results.


&gt;
My understanding is that ld1 and st1 are "single-element structure"
&gt; operations. (Identical to vld1 in arm32 NEON we discussed recently for
&gt; chacha and salsa2 asm.) That means they load a number of elements of a
&gt; given type from consecutive memory locations into the corresponding
&gt; vector register indices.
&gt;
&gt; ld1 {v0.4s},[x0] would load four 32bit words from consecutive memory
&gt; locations and put them into v0.s[0] through v0.s[3]. So x0+0..3 (bytes)
&gt; would go into v0.s[0], x0+4..7 would to into v0.s[1] and so on.
&gt; Endianness would apply to the internal byte order of the elements, so
&gt; each word would be loaded MSB-first in BE-mode and LSB-first in LE-mode.
&gt;
&gt; So, given memory content such as:
&gt;
&gt; x0 + 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt; byte 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt;
&gt; We should get on BE:
&gt;
&gt;          MSB     LSB
&gt; v0.s[0]:     0 1 2 3
&gt; v0.s[1]:     4 5 6 7
&gt; v0.s[2]:   8 9 10 11
&gt; v0.s[3]: 12 13 14 15
&gt;
&gt; Or looked at as byte-vectors:
&gt;
&gt;         |v0.s[0]|v0.s[1]| v0.s[2] | v0.s[3]  |
&gt;       v0.b[0]                             v0.b[15]
&gt; v0.16b:  3 2 1 0 7 6 5 4 11 10 9 8 15 14 13 12
&gt;
&gt; On LE we should get:
&gt;
&gt;          MSB     LSB
&gt; v0.d[0]:     3 2 1 0
&gt; v0.d[1]:     7 6 5 4
&gt; v0.d[2]:   11 10 9 8
&gt; v0.d[3]: 15 14 13 12
&gt;
&gt;       v0.b[0]                             v0.b[15]
&gt; v0.16b: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt;
&gt; This was just meant as intro. I've not actually tested this. I hope I
&gt; got it right and not just added to everyone's confusion (mine included).
&gt; :/
&gt;
&gt; Back to ld1.16b: This now loads a vector of 16 bytes consecutively.
&gt; Since bytes have no endianness there will be no changes in order on
&gt; either LE and BE modes. The register content will look the same on both:
&gt;
&gt; x0 +    0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt; byte:   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt;     v0.b[0]                             v0.b[15]
&gt; v0.16b: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt;
&gt; So larger datatypes loaded that way should be stored little-endian in
&gt; memory to make sense as e.g. .d[0] after such a load. Or we need to
&gt; rev64 them.
&gt;
&gt; &gt; load the H value by using ld1 "ld1 {H.16b},[x1]" in this way we can still
&gt; &gt; have to deal with LE as transposed doublewords and with BE in normal way
&gt; &gt; (not transposed doublewords or transposed quadword).
&gt;
&gt; After sending my last email I realised that the doublewords aren't
&gt; actually transposed with BE as such. They're just transposed compared to
&gt; the original LE routine because the ldr instruction loads in completely
&gt; reversed order in each mode and the LE routine does convert the internal
&gt; byte order of the doublewords to BE but not the overall order of the
&gt; 128bit quadword because it doesn't need to and regards them as a
&gt; vector of two doublewords anyway.
&gt;
&gt; ld1.16b doesn't change that at all. It just behaves the same on LE and
&gt; BE. So we'll always load vectors of bytes. And it'll always be an LSB
&gt; load. And if we want to treat them as big-endian doublewords we have to
&gt; adjust them accordingly. That's why we now also need all the rev64s on
&gt; BE above.
&gt;
&gt; That opens another topic: As you may have noticed I haven't got the
&gt; slightest idea of what the code is actually doing. Assembly also isn't
&gt; my first language either. I'm only mechanically trying to get BE mode to
&gt; produce the same results as LE.
&gt;
&gt; This made me realise that I haven't the faintest idea what we're getting
&gt; as input and producing as output either. :/ So are we working on blocks
&gt; of bytes and producing blocks of bytes and just treating them as
&gt; big-endian 64bit doublewords internally to exploit availability of
&gt; instructions that can work on these types or could we actually declare
&gt; the elements of TABLE to be quadwords in host endianness? Then we could
&gt; actually throw ld1.2d at them and eliminate all the rev64s.
&gt;
&gt; Duh, I think we can regardless, at least for BE:
&gt;
&gt; diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
&gt; index 1c14db54..642e3840 100644
&gt; --- a/arm64/v8/gcm-hash.asm
&gt; +++ b/arm64/v8/gcm-hash.asm
&gt; @@ -55,17 +55,10 @@ C common macros:
&gt;  .endm
&gt;
&gt;  .macro REDUCTION out
&gt; -IF_BE(`
&gt; -    pmull          T.1q,F.1d,POLY.1d
&gt; -    ext            \out\().16b,F.16b,F.16b,#8
&gt; -    eor            R.16b,R.16b,T.16b
&gt; -    eor            \out\().16b,\out\().16b,R.16b
&gt; -',`
&gt;      pmull          T.1q,F.1d,POLY.1d
&gt;      eor            R.16b,R.16b,T.16b
&gt;      ext            R.16b,R.16b,R.16b,#8
&gt;      eor            \out\().16b,F.16b,R.16b
&gt; -')
&gt;  .endm
&gt;
&gt;      C void gcm_init_key (union gcm_block *table)
&gt; @@ -108,27 +101,20 @@ define(`H4M', `v29')
&gt;  define(`H4L', `v30')
&gt;
&gt;  .macro PMUL_PARAM in, param1, param2
&gt; -IF_BE(`
&gt; -    pmull2         Hp.1q,\in\().2d,POLY.2d
&gt; -    ext            Hm.16b,\in\().16b,\in\().16b,#8
&gt; -    eor            Hm.16b,Hm.16b,Hp.16b
&gt; -    zip            \param1\().2d,\in\().2d,Hm.2d
&gt; -    zip2           \param2\().2d,\in\().2d,Hm.2d
&gt; -',`
&gt;      pmull2         Hp.1q,\in\().2d,POLY.2d
&gt;      eor            Hm.16b,\in\().16b,Hp.16b
&gt;      ext            \param1\().16b,Hm.16b,\in\().16b,#8
&gt;      ext            \param2\().16b,\in\().16b,Hm.16b,#8
&gt;      ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
&gt; -')
&gt;  .endm
&gt;
&gt;  PROLOGUE(_nettle_gcm_init_key)
&gt; -    ldr            HQ,[TABLE,#16*H_Idx]
&gt; -    dup            EMSB.16b,H.b[0]
&gt; +    add            x1,TABLE,#16*H_Idx
&gt; +    ld1            {H.2d},[x1]
&gt;  IF_LE(`
&gt;      rev64          H.16b,H.16b
&gt;  ')
&gt; +    dup            EMSB.16b,H.b[7]
&gt;      mov            x1,#0xC200000000000000
&gt;      mov            x2,#1
&gt;      mov            POLY.d[0],x1
&gt; @@ -220,7 +206,7 @@ PROLOGUE(_nettle_gcm_hash)
&gt;      mov            x4,#0xC200000000000000
&gt;      mov            POLY.d[0],x4
&gt;
&gt; -    ld1            {D.16b},[X]
&gt; +    ld1            {D.2d},[X]
&gt;  IF_LE(`
&gt;      rev64          D.16b,D.16b
&gt;  ')
&gt; @@ -233,7 +219,7 @@ IF_LE(`
&gt;      ld1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[x5]
&gt;
&gt;  L4x_loop:
&gt; -    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
&gt; +    ld1            {C0.2d,C1.2d,C2.2d,C3.2d},[DATA],#64
&gt;  IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt;      rev64          C1.16b,C1.16b
&gt; @@ -261,7 +247,7 @@ L2x:
&gt;
&gt;      ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
&gt;
&gt; -    ld1            {C0.16b,C1.16b},[DATA],#32
&gt; +    ld1            {C0.2d,C1.2d},[DATA],#32
&gt;  IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt;      rev64          C1.16b,C1.16b
&gt; @@ -282,7 +268,7 @@ L1x:
&gt;
&gt;      ld1            {H1M.16b,H1L.16b},[TABLE]
&gt;
&gt; -    ld1            {C0.16b},[DATA],#16
&gt; +    ld1            {C0.2d},[DATA],#16
&gt;  IF_LE(`
&gt;      rev64          C0.16b,C0.16b
&gt;  ')
&gt; @@ -335,9 +321,7 @@ Lmod_8_done:
&gt;      REDUCTION D
&gt;
&gt;  Ldone:
&gt; -IF_LE(`
&gt;      rev64          D.16b,D.16b
&gt; -')
&gt;      st1            {D.16b},[X]
&gt;      ret
&gt;  EPILOGUE(_nettle_gcm_hash)
&gt;

I like your ideas so far as you're shrinking the gap between both
endianness code but if my previous concern is right we still can't get this
patch works too.


&gt; Please excuse my laboured and longwinded thinking. ;) I really have to
&gt; start thinking in vectors also.
&gt;

Actually, I'm impressed how you get and handle all these ideas in your mind
and turn around quickly once you get a new one. Dealing with vector
registers in aarch64 is really challenging, both x86_64 and PowerPC don't
drag the endianness issues to vector registers, it's only applied to memory
and once the data loaded from memory into vector register all
endianness concerns are ended. Although PowerPC supports both endianness
modes, AltiVec instructions operate the same on vector registers on both
modes. It's a weird decision made by the Arm side.


&gt; And as always after all this guesswork I have found a likely very
&gt; relevant comment in gcm.c:
&gt;
&gt;   /* Shift uses big-endian representation. */
&gt; #if WORDS_BIGENDIAN
&gt;   reduce = shift_table[x-&gt;u64[1] &amp; 0xff];
&gt;
&gt; Is that it? Or is TABLE just internal to the routine and we can store
&gt; there however we please? (Apart from H at TABLE[128] initialised for us
&gt; by gcm_set_key and stored BE?)
&gt;

The assembly implementation of GHASH has a whole different scheme from C
table-lookup implementation, you don't have to worry about any of that.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210124131403</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-24 13:14:03-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Sat, Jan 23, 2021 at 08:52:30PM +0200, Maamoun TK wrote:

&gt; &gt; @@ -280,9 +266,9 @@ L1x:
&gt; &gt;      tst            LENGTH,#-16
&gt; &gt;      b.eq           Lmod
&gt; &gt;  
&gt; &gt; -    ld1            {H1M.16b,H1L.16b},[TABLE]
&gt; &gt; +    ld1            {H1M.2d,H1L.2d},[TABLE]
&gt; &gt;  
&gt; &gt; -    ld1            {C0.16b},[DATA],#16
&gt; &gt; +    ld1            {C0.2d},[DATA],#16
&gt; &gt;  IF_LE(`
&gt; &gt;      rev64          C0.16b,C0.16b
&gt; &gt;  ')
&gt; behavior hence we can't get this patch working on BE mode. The core of

First off: All three patches from my previous mail had the test gcm-hash
passing on LE and BE. I just reconfirmed the last patch with the whole
testsuite on LE and BE. So they should be working and cause no
regression.

&gt; I have one question here, do operations on doublewords transpose both
&gt; doubleword parts in BE mode? for example pmull instruction transpose
&gt; doublewords on LE mode when operated, in BE I don't expect the same
&gt; behavior hence we can't get this patch working on BE mode. The core of
&gt; pmull instruction is shift and xor operations so we can't perform pmull
&gt; instruction on byte-reversed doublewords as it's gonna produce wrong
&gt; results.

I think this directly corresponds to your next question:

&gt; Dealing with vector
&gt; registers in aarch64 is really challenging, both x86_64 and PowerPC don't
&gt; drag the endianness issues to vector registers, it's only applied to memory
&gt; and once the data loaded from memory into vector register all
&gt; endianness concerns are ended. Although PowerPC supports both endianness
&gt; modes, AltiVec instructions operate the same on vector registers on both
&gt; modes. It's a weird decision made by the Arm side.

I think there might be a misunderstanding here (possibly caused by
my attemps at explaining what ldr does, sorry):

On arm(32) and aarch64, endianness is also exclusively handled on
load and store operations. Register layout and operation behaviour is
identical in both modes. I think ARM also speaks of "memory endianness"
for just that reason. There is no adjustable "CPU endianness". It's
always "CPU-native".

So pmull will behave exactly the same in BE and LE mode. We just have
to make sure our load operations put the operands in the correct (i.e.
CPU-native) representation into the correct vector register indices upon
load.

So as an example:

pmull2 v0.1q,v1.2d,v2.2d

will always work on d[2] of v1 and v2 and put the result into all of v0.
And it expects its operands there in exactly one format, i.e. the least
significant bit at one end and the most-significant bit at the other
(and it's the same ends/bits in both memory-endianness modes :). And it will
also store to v0 in exactly the same representation in LE and BE mode.
Nothing changes with an endianness mode switch.

That's where load and store come in:

ld1 {v1.2d,v2.2d},[x0]

will load v1 and v2 with one-dimensional vectors from memory. So v1.d[0]
will be read from x0+0, v1.d[1] from x0+8 (bytes) and v2.d[0] from x0+16
and v2.d[1] from x0+24. That'll also be the same in LE and BE mode
because that's the structure of the vector prescribed by the load
operation we choose. Endianness will be applied to the individual
doublewords but the order in which they're loaded from memory and in
which they're put into d[0] and d[1] won't change, because they're
vectors.

So if you've actually stored a vector from CPU registers using
st1 {v1.2d, v2.2d},[x0]
and then load them back using
ld1 {v1.2d, v2.2d},[x0]
there's nothing else that needs to be done. The individual bytes of the
doublewords will be stored LE in memory in LE mode and BE in BE mode but
you won't notice. And the order of the doublewords in memory will be the
same in both modes.

If you're loading something that isn't stored LE or has no endianness at
all, e.g. just a sequence of data bytes (as in DATA in our code) or
something that was explicitly stored BE even on an LE CPU (as in
TABLE[128] in our code, I gather) but want to treat it as a larger
datatype, then you have to define endianness and need to apply
correction. That's why we need to rev64 in one mode (e.g. LE) to get the
same register-content in both endianness modes if what's loaded isn't
actually stored in that endianness in memory. 

Another way is to explicitly load a vector of bytes using ld1 {v1.16b,
v2.16b},[x0]. Then you can be sure what you get as register content, no
matter what memory endianness the CPU is using. If it's really just a
sequence of data bytes stored in their correct and necessary order in
memory and we only want to apply shifts and logical operations to each
of them, we'd be all set.

Here we can also exploit but need to be careful to understand the
different views on the register, so the fact that b[0] through b[7] is
mapped to d[0] and that b[0] will be the least significant byte in d[0]
and b[7] will be MSB. This layout is cpu-native, i.e. also the same in
both endianness modes. It's just that an ld1 {v1.16b} will always load a
vector of bytes with eight elements as consecutive bytes from memory
into b[0] through b[7], so it'll always be an LSB-first load when
interpreted as a larger data type. If we then look at that data trough
d[0] it will appear reversed if it isn't really a doubleword that was
stored little-endian.

That's why an ld1 {v1.b16,v2.b16},[x0] will produce incorrect results
with a pmull2 v0.1q,v1.2d,v2.2d in at least one endianness because we're
telling one operation that it's dealing with a byte-vector and the other
expects us to provide a vector of doublewords. If what we're loading is
actually something that was stored as doublewords in current memory
endianness, then ld1 {v1.2d,v2.2d} is the correct load operation. If
it's data bytes we want to *treat* as a big-endian doubleword, we can
use either ld1 {v1.16b,v2.16b} or {v1.2d,v2.2d} but in both cases need
to rev64 the register content if memory endianness is LE.

Now what *ldr* does is load a single 128bit quadword. And this will
indeed transpose the doublewords in BE mode when looked at through d[0]
and d[1]. Because as a big-endian load it will of course load the byte
at x0 into the most significant byte of e.g. v2, i.e. v2.d[1], i.e.
v2.b[15] and not v2.d[0], i.e. v2.b[7] (as with ld1.2d) or v2.b[0] (as
with ld1.16b). Similarly, x0+15 will go into v2.b[0] in BE and v2.b[15]
in LE mode. So this will only make sense if what we're loading was
actually stored using str as a 128bit quadword in current memory
endianness. If it's a sequence of bytes (st1.16b) we want to treat as a
vector of doublewords, not only will the bytes appear inverted when
looked at through d[0] and d[1] but also what's in d[0] will be in d[1]
in the other endianness mode and vice-versa. If it's a vector of
doublewords in memory endianness (st1.2d), byte order in the register
will be correct in both modes (because it's different in memory) but
d[0] and d[1] will still be transposed.

That's where all my rambling about doubleword transposition came from.
Does that make sense?

I just found this document from the LLVM guys with pictures! :)
https://llvm.org/docs/BigEndianNEON.html

BTW: ARM even goes as far as always storing *instructions* themselves,
so the actual opcodes the CPU decodes and executes, little-endian, even
in BE binaries. So the instruction fetch and decode stage always
operates little-endian. When the instruction is executed it's then just
an additional flag that tells load and store instructions how to behave
when executed and accessing memory. (I'm actually extrapolation from
what I know to be true for classic arm32 but it makes sense for that to
be true for aarch64 as well.)

&gt; &gt; Please excuse my laboured and longwinded thinking. ;) I really have to
&gt; &gt; start thinking in vectors also.
&gt; Actually, I'm impressed how you get and handle all these ideas in your mind
&gt; and turn around quickly once you get a new one.

Uh, thanks, FWIW. :)

I think to gather you (same as me) prefer to think in big-endian
representation. As for arm and aarch64, little-endian is the default, do
you think, the routine could be changed to move the special endianness
treatment using rev64 to BE mode, i.e. avoid them in the standard LE
case? It's certainly beyond me but it might give some additional
speedup.

Or would it be irrelevant compared to the speedup already given by using
pmull in the first place?

&gt; &gt; @@ -335,9 +321,7 @@ Lmod_8_done:
&gt; &gt;      REDUCTION D
&gt; &gt;
&gt; &gt;  Ldone:
&gt; &gt; -IF_LE(`
&gt; &gt;      rev64          D.16b,D.16b
&gt; &gt; -')
&gt; &gt;      st1            {D.16b},[X]
&gt; &gt;      ret
&gt; &gt;  EPILOGUE(_nettle_gcm_hash)
&gt; &gt;
&gt; I like your ideas so far as you're shrinking the gap between both
&gt; endianness code but if my previous concern is right we still can't get this
&gt; patch works too.

As said, the testsuite is passing with all three diffs from my previous
mail.

[...]
PASS: symbols
PASS: dlopen
====================
All 110 tests passed
====================
make[1]: Leaving directory '/home/michael/build-aarch64_be/testsuite'
Making check in examples
make[1]: Entering directory '/home/michael/build-aarch64_be/examples'
TEST_SHLIB_DIR="/home/michael/build-aarch64_be/.lib" \
  srcdir="../../nettle/examples" EMULATOR="" EXEEXT="" \
          "../../nettle"/run-tests rsa-sign-test rsa-verify-test
rsa-encrypt-test
xxxxxx
xxxxxx
PASS: rsa-sign
PASS: rsa-verify
PASS: rsa-encrypt
==================
All 3 tests passed
==================
make[1]: Leaving directory
'/home/michael/build-aarch64_be/examples'
[michael@aarch64-be:~/build-aarch64_be]

[...]
PASS: symbols
PASS: dlopen
====================
All 110 tests passed
====================
make[1]: Leaving directory '/home/michael/build-aarch64/testsuite'
Making check in examples
make[1]: Entering directory '/home/michael/build-aarch64/examples'
TEST_SHLIB_DIR="/home/michael/build-aarch64/.lib" \
  srcdir="../../nettle/examples" EMULATOR="" EXEEXT="" \
          "../../nettle"/run-tests rsa-sign-test rsa-verify-test
rsa-encrypt-test
xxxxxx
xxxxxx
ee
PASS: rsa-sign
PASS: rsa-verify
PASS: rsa-encrypt
==================
All 3 tests passed
==================
make[1]: Leaving directory '/home/michael/build-aarch64/examples'
[michael@aarch64:~/build-aarch64]

&gt; &gt; And as always after all this guesswork I have found a likely very
&gt; &gt; relevant comment in gcm.c:
&gt; &gt;
&gt; &gt;   /* Shift uses big-endian representation. */
&gt; &gt; #if WORDS_BIGENDIAN
&gt; &gt;   reduce = shift_table[x-&gt;u64[1] &amp; 0xff];
&gt; &gt;
&gt; &gt; Is that it? Or is TABLE just internal to the routine and we can store
&gt; &gt; there however we please? (Apart from H at TABLE[128] initialised for us
&gt; &gt; by gcm_set_key and stored BE?)
&gt; &gt;
&gt; The assembly implementation of GHASH has a whole different scheme from C
&gt; table-lookup implementation, you don't have to worry about any of that.

Perfect. So whether we use ld1/st1.16b or ld1/st1.2d for TABLE doesn't
matter. I wouldn't expect it but we could benchmark whether one is faster
than the other though!?

For clarification: How is H, i.e. TABLE[128] defined an interface to
gcm_set_key? I see that gcm_set_key calls a cipher function to fill it.
So I guess it provides the routine with a sequence of bytes  (similar to
DATA), i.e. the key, which will be the same on LE and BE and we *treat*
it as a big-endian doubleword for the sake of using pmull on it.
Correct?
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209073040</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2021-02-09 07:30:40-0400</timestampReceived><subject>GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Hello,

Upgrading nettle from 3.6 to 3.7 triggers a GnuTLS 3.7.0 testsuite
error on both ppc64 and ppc64el:

(sid_ppc64el-dchroot)ametzler@plummer:~/GNUTLS/gnutls28-3.7.0/b4deb/tests$ ./min
i-record-2
testing aes-cbc
testing aes-cbc-sha256
testing aes-gcm
testing aes-ccm
testing aes-ccm-8
testing null-sha1
testing arcfour-sha1
testing arcfour-md5
testing chacha20-poly1305
testing tls13-chacha20-poly1305
server:330: client: Error: An unexpected TLS packet was received.

Running the same binary dynamically (with LD_LIBRARY_PATH setting) linked
against nettle 3.6 succeeds.

--verbose logs are huge (5-7 MB xz-compressed), I have uploaded them to
https://people.debian.org/~ametzler/tmp/

cu Andreas

-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209123706</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2021-02-09 12:37:06-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

On 2021-02-09 Andreas Metzler &lt;ametzler@bebt.de&gt; wrote:
&gt; Hello,

&gt; Upgrading nettle from 3.6 to 3.7 triggers a GnuTLS 3.7.0 testsuite
&gt; error on both ppc64 and ppc64el:

&gt; (sid_ppc64el-dchroot)ametzler@plummer:~/GNUTLS/gnutls28-3.7.0/b4deb/tests$ ./min
[...]
&gt; testing chacha20-poly1305
&gt; testing tls13-chacha20-poly1305
&gt; server:330: client: Error: An unexpected TLS packet was received.

&gt; Running the same binary dynamically (with LD_LIBRARY_PATH setting) linked
&gt; against nettle 3.6 succeeds.

&gt; --verbose logs are huge (5-7 MB xz-compressed), I have uploaded them to
&gt; https://people.debian.org/~ametzler/tmp/

Hello,

I have bisected this[1] in nettle git and found

58a0301437e9beb23130423ff1063a67b6f2b43b
ppc: New assembly for chacha_core4, doing four blocks in parallel.

as first bad commit, the previous one
(58c55046beda976b10ac3ce930696d172e5e5038 Fix a ChangeLog typo.) works.

cu Andreas

[1] twice :-( First try found d56503602134442832e73bc40a657954d3f8db8f
- "Enable fat build by default." so I did a second run with
--enable-fat.
-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210212191738</emailId><senderName>Nicolas Mora</senderName><senderEmail>nicolas@babelouest.org</senderEmail><timestampReceived>2021-02-12 19:17:38-0400</timestampReceived><subject>Add RSA-OAEP encryption/decryption to Nettle</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]

[Attachment #6 (multipart/mixed)]


Hello,

I've made a new Merge Request in the nettle gitlab repo to provide 
RSA-OAEP encryption and decryption:
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/20

It adds 2 new functions:

int
pkcs1_oaep_encrypt (size_t key_size,
	       void *random_ctx, nettle_random_func *random,
	       size_t hlen,
	       size_t label_length, const uint8_t *label,
	       size_t message_length, const uint8_t *message,
	       mpz_t m);

int
pkcs1_oaep_decrypt (size_t key_size,
	       const mpz_t m,
	       size_t hlen,
	       size_t label_length, const uint8_t *label,
	       size_t *length, uint8_t *message);

The parameter hlen is the output length of the SHA function used for 
masking data:
- SHA1_DIGEST_SIZE
- SHA256_DIGEST_SIZE
- SHA384_DIGEST_SIZE
- SHA512_DIGEST_SIZE

Is it possible to get feedback for this MR and eventually push it to the 
master branch?

Thanks in advance

/Nicolas

["OpenPGP_signature.asc" (application/pgp-signature)]
[Attachment #10 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210214103603</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-14 10:36:03-0400</timestampReceived><subject>Arcfour status</subject><body>

I've had a report (from Matthew Kempe) about another problem with the
openssl benchmarking code. It fails on FreeBSD, because there (and
possible in other environments too) openssl has been configured without
RC4 (aka arcfour) support. I'm considering just deleting code to
benchmark openssl arcfour; I don't plan any improvements of Nettle's
arcfour performance, and I would be surprised if the openssl people do.

I do intend to keep arcfour support in Nettle for the foreseeable
future, to support old protocols and applications. But I'm thinking that
maybe the arcfour assembly code could be deleted?

Nettle currently includes arcfour assembly implementations for x86
(32-bit) and sparc (both 32-bit and 64-bit), which as far as I remember
gave a modest speedup when added. But the code hasn't been tuned or
benchmarked recently. And we have nothing for more relevant platforms.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209161521</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-09 16:15:21-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; I have bisected this[1] in nettle git and found
&gt;
&gt; 58a0301437e9beb23130423ff1063a67b6f2b43b
&gt; ppc: New assembly for chacha_core4, doing four blocks in parallel.

This is indeed new code in nettle-3.7, and particularly suspect since
the test fails only on ppc. Do you know what the code path is? Is GnuTLS
using Nettle's chacha_poly1305_* functions, or is it calling chacha and
poly1305 functions separately?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210225103728</emailId><senderName>Norbert Pocs</senderName><senderEmail>npocs@redhat.com</senderEmail><timestampReceived>2021-02-25 10:37:28-0400</timestampReceived><subject>HPKE implementation</subject><body>

Hello mailing list,

I am a student at Brno University of Technology at Faculty of Information
Technology and intern at Red Hat Crypto team.

My current project is the implementation of HPKE draft [0]. The first goal
is to implement mode_base.

Example usage for the project is the encrypted hello message in TLS [1].

Do you have interest in merging the code after completion?

[0] https://tools.ietf.org/html/draft-irtf-cfrg-hpke-07

[1] https://gitlab.com/gnutls/gnutls/-/issues/595

Regards
Norbert Pócs
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209171229</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2021-02-09 17:12:29-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

On 2021-02-09 Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; &gt; I have bisected this[1] in nettle git and found
&gt; &gt;
&gt; &gt; 58a0301437e9beb23130423ff1063a67b6f2b43b
&gt; &gt; ppc: New assembly for chacha_core4, doing four blocks in parallel.

&gt; This is indeed new code in nettle-3.7, and particularly suspect since
&gt; the test fails only on ppc. Do you know what the code path is? Is GnuTLS
&gt; using Nettle's chacha_poly1305_* functions, or is it calling chacha and
&gt; poly1305 functions separately?

Hello,

Afaict from
https://gitlab.com/gnutls/gnutls/-/blob/master/lib/nettle/cipher.c#L815
it does use chacha_poly1305_encrypt/decrypt/update/digest/set_key/set_nonce.

I am not 100% sure. -  I thought I could brute-force this with ltrace, but I
only got it to show direct library calls to gnutls_* but not the
indirect ones (gnutls calling nettle).

cu Andreas
-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209184655</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-09 18:46:55-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; Afaict from
&gt; https://gitlab.com/gnutls/gnutls/-/blob/master/lib/nettle/cipher.c#L815
&gt; it does use chacha_poly1305_encrypt/decrypt/update/digest/set_key/set_nonce.

I see. (But closer to line 857). I wonder what the precise message size
was. Log says

server|&lt;5&gt;| REC[0x100372bc820]: Received Packet Application Data(23) with length: 209
server|&lt;10&gt;| READ: Got 209 bytes from 0x3
server|&lt;10&gt;| READ: read 209 bytes from 0x3
server|&lt;10&gt;| RB: Have 5 bytes into buffer. Adding 209 bytes.
server|&lt;10&gt;| RB: Requested 214 bytes
server|&lt;5&gt;| REC[0x100372bc820]: Decrypted Packet[191] Unknown Packet(196) with \
length: 192 server|&lt;5&gt;| REC[0x100372bc820]: Received unexpected packet 196 (Unknown \
Packet) expecting 23 (Application Data)

I would guess that means that we got 209 bytes, including the 16-byte
poly1305 authentication tag. Message size is then 209 - 16 = 193 bytes.
If the first byte is a TLS packet type, the "length: 192" in the next to
last line makes sense if the packet type byte is excluded. Right?

And preceding packets, which are smaller (packet size increasing one
byte per packet), appear to be decrypted correctly. I'll investigate.

What is the source of the incoming packets? GnuTLS of the same version,
also using Nettle-3.7, or the previous version, or some prerecorded
data? It's not obvious to me if the error is on the sender or the
receiver side.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210209200710</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-09 20:07:10-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I would guess that means that we got 209 bytes, including the 16-byte
&gt; poly1305 authentication tag. Message size is then 209 - 16 = 193 bytes.
&gt; If the first byte is a TLS packet type, the "length: 192" in the next to
&gt; last line makes sense if the packet type byte is excluded. Right?

I've found one problem, although I don't see that it would cause
precisely the reported problem. It would result in incorrect
encrypt/decrypt of the data immediately after a call to chacha_crypt or
chacha_crypt32 with 129 &lt;= (length % 256) &lt;= 192. In code used only on
ppc64 with the new altivec chacha code enabled.

Tentative patch below, but I need to extend the tests to get proper test
coverage of this case.

Regards,
/Niels

diff --git a/chacha-crypt.c b/chacha-crypt.c
index 081ebcf4..9db13183 100644
--- a/chacha-crypt.c
+++ b/chacha-crypt.c
@@ -80,13 +80,16 @@ _nettle_chacha_crypt_4core(struct chacha_ctx *ctx,
   while (length &gt; 2*CHACHA_BLOCK_SIZE)
     {
       _nettle_chacha_4core (x, ctx-&gt;state, CHACHA_ROUNDS);
-      ctx-&gt;state[12] += 4;
-      ctx-&gt;state[13] += (ctx-&gt;state[12] &lt; 4);
       if (length &lt;= 4*CHACHA_BLOCK_SIZE)
 	{
+	  uint32_t blocks = 3 + (length &gt; 3*CHACHA_BLOCK_SIZE);
+	  ctx-&gt;state[12] += blocks;
+	  ctx-&gt;state[13] += (ctx-&gt;state[12] &lt; blocks);
 	  memxor3 (dst, src, x, length);
 	  return;
 	}
+      ctx-&gt;state[12] += 4;
+      ctx-&gt;state[13] += (ctx-&gt;state[12] &lt; 4);
       memxor3 (dst, src, x, 4*CHACHA_BLOCK_SIZE);
 
       length -= 4*CHACHA_BLOCK_SIZE;
@@ -200,12 +203,13 @@ _nettle_chacha_crypt32_4core(struct chacha_ctx *ctx,
   while (length &gt; 2*CHACHA_BLOCK_SIZE)
     {
       _nettle_chacha_4core32 (x, ctx-&gt;state, CHACHA_ROUNDS);
-      ctx-&gt;state[12] += 4;
       if (length &lt;= 4*CHACHA_BLOCK_SIZE)
 	{
+	  ctx-&gt;state[12] += 3 + (length &gt; 3*CHACHA_BLOCK_SIZE);
 	  memxor3 (dst, src, x, length);
 	  return;
 	}
+      ctx-&gt;state[12] += 4;
       memxor3 (dst, src, x, 4*CHACHA_BLOCK_SIZE);
 
       length -= 4*CHACHA_BLOCK_SIZE;

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210209213606</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-02-09 21:36:06-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

On Tue, Feb 9, 2021 at 3:07 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; I would guess that means that we got 209 bytes, including the 16-byte
&gt; &gt; poly1305 authentication tag. Message size is then 209 - 16 = 193 bytes.
&gt; &gt; If the first byte is a TLS packet type, the "length: 192" in the next to
&gt; &gt; last line makes sense if the packet type byte is excluded. Right?
&gt;
&gt; I've found one problem, although I don't see that it would cause
&gt; precisely the reported problem. It would result in incorrect
&gt; encrypt/decrypt of the data immediately after a call to chacha_crypt or
&gt; chacha_crypt32 with 129 &lt;= (length % 256) &lt;= 192. In code used only on
&gt; ppc64 with the new altivec chacha code enabled.
&gt;
&gt; Tentative patch below, but I need to extend the tests to get proper test
&gt; coverage of this case.

If needed, you can find Bernstein's reference implementation at
https://cr.yp.to/chacha.html. Modify it for IETF's ChaCha and use it
to generate test vectors. A set of 12x blocks would probably be a good
choice.

Or you can use the test vectors from Wei Dai's Crypto++. The project
already generated test vectors for 1x, 4x and 12x blocks. The test
vectors include Bernstein's ChaCha and the IETF version. Also see
https://github.com/weidai11/cryptopp/blob/master/TestVectors/chacha.txt
.

You might also consider changing the project's governance to require a
complete set of test vectors for each algorithm. If you are doing 4x
blocks, then you need test vectors covering them. You should also use
an independent program to generate them, like Bernstein's reference
implementation. (I don't believe the IETF provides a reference
implementation).

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210210101131</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-10 10:11:31-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Or you can use the test vectors from Wei Dai's Crypto++. The project
&gt; already generated test vectors for 1x, 4x and 12x blocks. The test
&gt; vectors include Bernstein's ChaCha and the IETF version. Also see
&gt; https://github.com/weidai11/cryptopp/blob/master/TestVectors/chacha.txt

Thanks, I've copied one of the 1024 byte test vectors from there.

&gt; You might also consider changing the project's governance to require a
&gt; complete set of test vectors for each algorithm. If you are doing 4x
&gt; blocks, then you need test vectors covering them. You should also use
&gt; an independent program to generate them, like Bernstein's reference
&gt; implementation. (I don't believe the IETF provides a reference
&gt; implementation).

In this case, the coverage problem wasn't mainly lack of authoritative
test vectors, but missing coverage for sequences of calls to
chacha_crypt/chacha_crypt32. The bug was in the counter update at the
very end of the processing, for certain data sizes, and would not cause
obviously incorrect results until the next call.

For tests that vary things like alignment, message size, how to split a
message into multiple calls, etc, I think it's usually good enough to
check that the result always is identical to the simplest way to do it
(say, using a single call for the complete message, friendly alignment,
and without involving any assembly code). I think of that kind of tests
as mostly orthogonal to tests using authoritative test vectors.

I've pushed test updates to the branch fix-chacha-counter, and ci builds
now fail on ppc64. The fix posted to the list appears to work, I'll push
that to the branch in a moment.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210210113846</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2021-02-10 11:38:46-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Hello,

nisse@lysator.liu.se (Niels Möller) writes:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt;&gt; I would guess that means that we got 209 bytes, including the 16-byte
&gt;&gt; poly1305 authentication tag. Message size is then 209 - 16 = 193 bytes.
&gt;&gt; If the first byte is a TLS packet type, the "length: 192" in the next to
&gt;&gt; last line makes sense if the packet type byte is excluded. Right?

That's exactly the case (under TLS 1.3).  As the protocol uses separate
keys for handshake and application traffic (and the error happens in
sending application data and no post-handshake messages are exchanged),
I guess you can also assume that the same data (all bytes are 0x2) with
different lengths is fed into chacha_crypt* in the failing test case
(mini-record-2).

&gt; I've found one problem, although I don't see that it would cause
&gt; precisely the reported problem. It would result in incorrect
&gt; encrypt/decrypt of the data immediately after a call to chacha_crypt or
&gt; chacha_crypt32 with 129 &lt;= (length % 256) &lt;= 192. In code used only on
&gt; ppc64 with the new altivec chacha code enabled.
&gt;
&gt; Tentative patch below, but I need to extend the tests to get proper test
&gt; coverage of this case.

Thank you so much!  The patch fixes the issue (tested on gcc cfarm).

In the gdb trace, I see nettle_chacha_poly1305_encrypt() is called with
the following length pattern: 128, 63, 128, 64, 192, 1, 192, 2.  I can
try to create a test case if necessary.

Also: thank you Andreas for looking into it.

Regards,
-- 
Daiki Ueno
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210210130117</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-10 13:01:17-0400</timestampReceived><subject>Re: GnuTLS testsuite error on ppc64 after nettle upgrade</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; Thank you so much!  The patch fixes the issue (tested on gcc cfarm).

Thanks for testing. Pushed to master branch now. BTW, I could test
ppc64el locally on my laptop fairly easily, I used:

# apt-get install -t testing gcc-powerpc64le-linux-gnu
# dpkg --add-architecture ppc64el
# apt-get update
# apt-get install libc6:ppc64el

(I already had qemu-user and binfmt magic installed)

$ ~/hack/nettle/configure --host=powerpc64le-linux-gnu --enable-mini-gmp CXX=/bin/false
$ make -j10 &amp;&amp; make -j10 check
 
&gt; In the gdb trace, I see nettle_chacha_poly1305_encrypt() is called with
&gt; the following length pattern: 128, 63, 128, 64, 192, 1, 192, 2.  I can
&gt; try to create a test case if necessary.

I see. And then it's the first call with length 192 that updates the
counter value incorrectly (incrementing it by 4 instead of 3), with
incorrect encryption on the next call. No calls with length 129, which
would be the smallest one to trigger the bug.

You can have a look at the updated test and see if you think an
additional test would be worthwhile. The loop testing various lengths
start at
https://git.lysator.liu.se/nettle/nettle/-/blob/master/testsuite/chacha-test.c#L193,
and the code from line 219 and on is new.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210101162919</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-01 16:29:19-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Happy new year, Niels and all around,

On Wed, Dec 30, 2020 at 09:12:24PM +0100, Niels Möller wrote:

&gt; &gt; It comes out at around seven cycles per block slowdown for chacha-3core
&gt; &gt; and five for salsa20-2core. I trace this to vst1.8. It's just slower
&gt; Thanks for investigating. Maybe keep some IF_BE / IF_LE just for the
&gt; store instructions, to stay with vstm on little-endian?

Sounds good. I'll try to finalise a patch and reconfirm that there's no
speed regression from it.

&gt; &gt; Does this seem reasonable or does it point to some flaw in my
&gt; &gt; benchmarking or system software/hardware? 
&gt; That's unexpected. In principle I guess it's possible for the C compiler
&gt; to generate great vectorized code, but that seems a bit unlikely. Do you
&gt; get the same results if you build Nettle-3.6? 

With the help of Jeff I've gone on a bit of a benchmark binge using a:

- Raspberry Pi 1B (Broadcom BCM2835, arm11),
- Cubieboard2 (Allwinner A20, Cortex-A7),
- Wandboard (Freescale i.MX6 DualLite, Cortex-A9),
- Tinkerboard (Rockchip RK3288, Cortex-A17) and
- Raspberry Pi 4 (Broadcom BCM2711, Cortex-A72).

The rpi1b doesn't do NEON, so there's no numbers for that. I booted the
rpi4 with Ubuntu 20.04 armhf with arm32 kernel and userland to avoid any
influence of switches from/to 64bit mode. Some other metrics of the
systems (such as compiler) and the build commands used are in the
attached result notes. The Debian and Ubuntu systems had cpufreq
activated. Since I didn't want to mess with that, I ran the benchmark
multiple times in a loop to get cpufreq to scale up.

I've put together a small script that parses the manual notes for
plotting using gnuplot. That produced the attached charts, which are
quite interesting.

t=$(mktemp) ; cat nettle-arm-bench.txt | python3 nettle-arm-bench.py &gt;$t ; gnuplot -e \
"set term pngcairo font 'sans,9' size 960, 540; set style data histograms; set ylabel \
'cycles/block'; set xtics rotate out; set style fill solid border; set style \
histogram clustered; plot f or [COL=2:5] '$t' using COL:xticlabels(1) title \
columnheader;" &gt;nettle-arm-bench-chart.png ; rm -f "$t"

&gt; &gt; From ChangeLog comments, it seems I got 45% speedup for Salsa20,
&gt; compared to the C implementation, when I wrote the original neon
&gt; assembly code. At the time, benchmarked on a pandaboard (cortex a9), if
&gt; I remember correctly.

I've disassembled an example of what the C compiler produces (I think
chacha-core-internal.o) and there were no NEON instructions in there. At
first glance it looked very similar to the armv6 assembler code.

BTW: The compilers default to their respective architecture, so would
produce armv5 code on the rpi1b and armv7 on tinkerboard/wandboard/
cubieboard2/rpi4.

If these numbers are correct, it would seem that gcc got a *lot* better
in optimising for ARM in recent versions. And ARM seems to have
continuously improved native ARM instruction performance but NEON has
been stagnant.

What confuses me is that the arm, armv6 and neon routines all give
approximately the same speed. I'd have expected some visible difference
there. Maybe I'm still just doing something wrong here?

At least the numbers rule out some peculiarity of the Cubieboards or my
Gentoo installation, IMO.

&gt; Is it for a fat build? If so, it's possibly that the fat setup logic
&gt; selects the C implementation is this hacked setup (but on the other
&gt; hand, I'd guess a fat build may just failed at link time if these files
&gt; are removed).

I did not enable fat for nettle 3.6 and explicitly disabled it for
master. I forced selection of specific routines using configure options.
-- 
Thanks,
Michael


["nettle-arm-bench.txt" (text/plain)]

rpi 1b:
root@rpi0-20200831:~# lsb_release -a
No LSB modules are available.
Distributor ID: Debian
Description:    Debian GNU/Linux 10 (buster)
Release:        10
Codename:       buster
michael@rpi0-20200831:~$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabi/8/lto-wrapper
Target: arm-linux-gnueabi
Configured with: ../src/configure -v --with-pkgversion='Debian 8.3.0-6' \
--with-bugurl=file:///usr/share/doc/gcc-8/README.Bugs \
--enable-languages=c,ada,c++,go,d,fortran,objc,obj-c++ --prefix=/usr \
--with-gcc-major-version-only --program-suffix=-8 --program-prefix=arm-linux-gnueabi- \
--enable-shared --enable-linker-build-id --libexecdir=/usr/lib \
--without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls \
--enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes \
--with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-libitm \
--disable-libquadmath --disable-libquadmath-support --enable-plugin \
--enable-default-pie --with-system-zlib --with-target-system-zlib \
--enable-objc-gc=auto --enable-multiarch --disable-sjlj-exceptions \
--with-arch=armv5te --with-float=soft --disable-werror --enable-checking=release \
--build=arm-linux-gnueabi --host=arm-linux-gnueabi --target=arm-linux-gnueabi Thread \
model: posix gcc version 8.3.0 (Debian 8.3.0-6)

wandboard:
mweiser@wandboard:~$ lsb_release -a
No LSB modules are available.
Distributor ID: Debian
Description:    Debian GNU/Linux 10 (buster)
Release:        10
Codename:       buster
mweiser@wandboard:~$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabihf/8/lto-wrapper
Target: arm-linux-gnueabihf
Configured with: ../src/configure -v --with-pkgversion='Debian 8.3.0-6' \
--with-bugurl=file:///usr/share/doc/gcc-8/README.Bugs \
--enable-languages=c,ada,c++,go,d,fortran,objc,obj-c++ --prefix=/usr \
--with-gcc-major-version-only --program-suffix=-8 \
--program-prefix=arm-linux-gnueabihf- --enable-shared --enable-linker-build-id \
--libexecdir=/usr/lib --without-included-gettext --enable-threads=posix \
--libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu \
--enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new \
--enable-gnu-unique-object --disable-libitm --disable-libquadmath \
--disable-libquadmath-support --enable-plugin --enable-default-pie --with-system-zlib \
--with-target-system-zlib --enable-objc-gc=auto --enable-multiarch \
--disable-sjlj-exceptions --with-arch=armv7-a --with-fpu=vfpv3-d16 --with-float=hard \
--with-mode=thumb --disable-werror --enable-checking=release \
--build=arm-linux-gnueabihf --host=arm-linux-gnueabihf --target=arm-linux-gnueabihf \
Thread model: posix gcc version 8.3.0 (Debian 8.3.0-6)
mweiser@wandboard:~$ sudo cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq
996000
mweiser@wandboard:~$ sudo cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq
396000
mweiser@wandboard:~$ sudo cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq
396000
mweiser@wandboard:~$ sudo cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_max_freq
996000

tinkerboard:
mweiser@tinkerboard:~$ lsb_release -a
No LSB modules are available.
Distributor ID: Debian
Description:    Debian GNU/Linux 9.13 (stretch)
Release:        9.13
Codename:       stretch
mweiser@tinkerboard:~$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabihf/6/lto-wrapper
Target: arm-linux-gnueabihf
Configured with: ../src/configure -v --with-pkgversion='Debian 6.3.0-18+deb9u1' \
--with-bugurl=file:///usr/share/doc/gcc-6/README.Bugs \
--enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr \
--program-suffix=-6 --program-prefix=arm-linux-gnueabihf- --enable-shared \
--enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext \
--enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ \
--enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes \
--with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-libitm \
--disable-libquadmath --enable-plugin --enable-default-pie --with-system-zlib \
--disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo \
--with-java-home=/usr/lib/jvm/java-1.5.0-gcj-6-armhf/jre --enable-java-home \
--with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-6-armhf \
--with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-6-armhf \
--with-arch-directory=arm --with-ecj-jar=/usr/share/java/eclipse-ecj.jar \
--with-target-system-zlib --enable-objc-gc=auto --enable-multiarch \
--disable-sjlj-exceptions --with-arch=armv7-a --with-fpu=vfpv3-d16 --with-float=hard \
--with-mode=thumb --enable-checking=release --build=arm-linux-gnueabihf \
--host=arm-linux-gnueabihf --target=arm-linux-gnueabihf Thread model: posix
gcc version 6.3.0 20170516 (Debian 6.3.0-18+deb9u1)
mweiser@tinkerboard:~/nettle/3.6/noasm/examples$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_max_freq 1512000
mweiser@tinkerboard:~/nettle/3.6/noasm/examples$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq 600000
mweiser@tinkerboard:~/nettle/3.6/noasm/examples$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq ; LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20 ; sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq 600000
[...]
1512000

cubieboard2:
[michael@c2-le:~/nettle/3.6/noasm/examples] gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/armv7ve-unknown-linux-gnueabihf/10.2.0/lto-wrapper
                
Target: armv7ve-unknown-linux-gnueabihf
Configured with: /var/tmp/portage/sys-devel/gcc-10.2.0-r5/work/gcc-10.2.0/configure \
--host=armv7ve-unknown-linux-gnueabihf --build=armv7ve-unknown-linux-gnueabihf \
--prefix=/usr --bindir=/usr/armv7ve-unknown-linux-gnueabihf/gcc-bin/10.2.0 \
--includedir=/usr/lib/gcc/armv7ve-unknown-linux-gnueabihf/10.2.0/include \
--datadir=/usr/share/gcc-data/armv7ve-unknown-linux-gnueabihf/10.2.0 \
--mandir=/usr/share/gcc-data/armv7ve-unknown-linux-gnueabihf/10.2.0/man \
--infodir=/usr/share/gcc-data/armv7ve-unknown-linux-gnueabihf/10.2.0/info \
--with-gxx-include-dir=/usr/lib/gcc/armv7ve-unknown-linux-gnueabihf/10.2.0/include/g++-v10 \
--with-python-dir=/share/gcc-data/armv7ve-unknown-linux-gnueabihf/10.2.0/python \
--enable-languages=c,c++ --enable-obsolete --enable-secureplt --disable-werror \
--with-system-zlib --disable-nls --enable-checking=release \
--with-bugurl=https://bugs.gentoo.org/ --with-pkgversion='Gentoo Hardened 10.2.0-r5 \
p6' --enable-esp --enable-libstdcxx-time --enable-shared --enable-threads=posix \
--enable-__cxa_atexit --enable-clocale=gnu --disable-multilib --disable-fixed-point \
--with-float=hard --with-arch=armv7ve --with-float=hard --with-fpu=vfpv3-d16 \
--enable-libgomp --disable-libssp --disable-libada --disable-systemtap \
--enable-vtable-verify --without-zstd --enable-lto --without-isl --enable-default-pie \
--enable-default-ssp Thread model: posix
Supported LTO compression algorithms: zlib
gcc version 10.2.0 (Gentoo Hardened 10.2.0-r5 p6)

-&gt; git am ../../0001-Delete-benchmark-code-attempting-to-measure-function.patch

rpi4:
ubuntu@ubuntu:~/3.6/noasm$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 20.04.1 LTS
Release:        20.04
Codename:       focal
ubuntu@ubuntu:~/3.6/noasm$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabihf/9/lto-wrapper
Target: arm-linux-gnueabihf
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 9.3.0-17ubuntu1~20.04' \
--with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs \
--enable-languages=c,ada,c++,go,d,fortran,objc,obj-c++,gm2 --prefix=/usr \
--with-gcc-major-version-only --program-suffix=-9 \
--program-prefix=arm-linux-gnueabihf- --enable-shared --enable-linker-build-id \
--libexecdir=/usr/lib --without-included-gettext --enable-threads=posix \
--libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug \
--enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new \
--enable-gnu-unique-object --disable-libitm --disable-libquadmath \
--disable-libquadmath-support --enable-plugin --enable-default-pie --with-system-zlib \
--with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch \
--enable-multilib --disable-sjlj-exceptions --with-arch=armv7-a --with-fpu=vfpv3-d16 \
--with-float=hard --with-mode=thumb --disable-werror --enable-multilib \
--enable-checking=release --build=arm-linux-gnueabihf --host=arm-linux-gnueabihf \
--target=arm-linux-gnueabihf Thread model: posix
gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)
ubuntu@ubuntu:~/3.6/noasm$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq 1000000
ubuntu@ubuntu:~/3.6/noasm$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_max_freq 1500000
ubuntu@ubuntu:~/3.6/noasm$ sudo cat \
/sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq 1500000

3.6:

noasm:
git checkout -f nettle_3.6_release_20200429 &amp;&amp; ./.bootstrap &amp;&amp; ./configure \
--disable-documentation --disable-assembler &amp;&amp; make &amp;&amp; make check for gcc10: git \
checkout -f nettle_3.6_release_20200429 &amp;&amp; git am \
../../0001-Delete-benchmark-code-attempting-to-measure-function.patch &amp;&amp; ./.bootstrap \
&amp;&amp; ./configure --disable-documentation --disable-assembler &amp;&amp; make &amp;&amp; make check

rpi1b:
  Version:           nettle 3.6
  Host type:         armv6l-unknown-linux-gnueabi
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

michael@rpi0-20200831:~/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

benchmark call overhead: 0.022739 us  15.92 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   18.74       35.63      2280.28
            chacha      decrypt   18.68       35.73      2286.80

   chacha_poly1305      encrypt   12.15       54.94      3516.11
   chacha_poly1305      decrypt   12.07       55.32      3540.54
   chacha_poly1305       update   34.57       19.31      1235.86

           salsa20      encrypt   22.27       29.97      1918.36
           salsa20      decrypt   22.27       29.98      1918.48

        salsa20r12      encrypt   31.06       21.49      1375.55
        salsa20r12      decrypt   31.17       21.42      1370.91
michael@rpi0-20200831:~/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

benchmark call overhead: 0.022700 us  15.89 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   18.70       35.70      2284.81
            chacha      decrypt   18.63       35.84      2293.54

   chacha_poly1305      encrypt   12.08       55.25      3535.99
   chacha_poly1305      decrypt   12.08       55.28      3537.66
   chacha_poly1305       update   34.66       19.26      1232.80

           salsa20      encrypt   22.15       30.14      1928.93
           salsa20      decrypt   22.23       30.03      1922.19

        salsa20r12      encrypt   30.88       21.62      1383.57
        salsa20r12      decrypt   31.08       21.48      1374.68

wandboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009048 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   54.20       17.59      1126.01
            chacha      decrypt   54.14       17.61      1127.31

   chacha_poly1305      encrypt   36.20       26.35      1686.08
   chacha_poly1305      decrypt   36.14       26.39      1688.68
   chacha_poly1305       update  107.56        8.87       567.47

           salsa20      encrypt   57.08       16.71      1069.22
           salsa20      decrypt   56.91       16.76      1072.42

        salsa20r12      encrypt   80.93       11.78       754.22
        salsa20r12      decrypt   80.87       11.79       754.76
mweiser@wandboard:~/nettle/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009048 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   54.05       17.64      1129.27
            chacha      decrypt   54.02       17.65      1129.81

   chacha_poly1305      encrypt   36.08       26.43      1691.67
   chacha_poly1305      decrypt   36.08       26.44      1691.85
   chacha_poly1305       update  107.54        8.87       567.53

           salsa20      encrypt   57.06       16.71      1069.75
           salsa20      decrypt   57.14       16.69      1068.22

        salsa20r12      encrypt   80.48       11.85       758.42
        salsa20r12      decrypt   81.29       11.73       750.80

tinkerboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.001987 us   2.98 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   91.72       15.60       998.23
            chacha      decrypt   91.48       15.64      1000.77

   chacha_poly1305      encrypt   62.02       23.07      1476.25
   chacha_poly1305      decrypt   62.86       22.76      1456.44
   chacha_poly1305       update  199.94        7.15       457.91

           salsa20      encrypt  106.83       13.39       856.99
           salsa20      decrypt  108.61       13.17       842.94

        salsa20r12      encrypt  155.98        9.17       586.94
        salsa20r12      decrypt  153.02        9.35       598.32
mweiser@tinkerboard:~/nettle/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.001990 us   2.99 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   91.94       15.56       995.81
            chacha      decrypt   91.69       15.60       998.48

   chacha_poly1305      encrypt   62.74       22.80      1459.33
   chacha_poly1305      decrypt   62.98       22.71      1453.65
   chacha_poly1305       update  199.52        7.17       458.87

           salsa20      encrypt  106.98       13.37       855.77
           salsa20      decrypt  107.02       13.37       855.48

        salsa20r12      encrypt  155.61        9.19       588.33
        salsa20r12      decrypt  155.83        9.18       587.51

cubieboard2:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/3.6/noasm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.010974 us  10.97 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.41       31.36      2006.95
            chacha      decrypt   30.40       31.37      2007.48

   chacha_poly1305      encrypt   23.58       40.45      2588.67
   chacha_poly1305      decrypt   23.58       40.45      2588.66
   chacha_poly1305       update  104.44        9.13       584.41

           salsa20      encrypt   35.16       27.12      1735.73
           salsa20      decrypt   35.15       27.13      1736.64

        salsa20r12      encrypt   50.04       19.06      1219.82
        salsa20r12      decrypt   50.04       19.06      1219.75
[michael@c2-le:~/nettle/3.6/noasm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.010982 us  10.98 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.40       31.37      2007.74
            chacha      decrypt   30.40       31.37      2007.75

   chacha_poly1305      encrypt   23.58       40.44      2588.24
   chacha_poly1305      decrypt   23.56       40.47      2590.28
   chacha_poly1305       update  104.44        9.13       584.39

           salsa20      encrypt   35.09       27.18      1739.55
           salsa20      decrypt   35.16       27.12      1735.86

        salsa20r12      encrypt   49.98       19.08      1221.16
        salsa20r12      decrypt   49.97       19.09      1221.44

rpi4:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

benchmark call overhead: 0.004013 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  117.96       12.13       776.13
            chacha      decrypt  117.99       12.12       775.95

   chacha_poly1305      encrypt   80.29       17.82      1140.22
   chacha_poly1305      decrypt   80.21       17.83      1141.40
   chacha_poly1305       update  252.80        5.66       362.16

           salsa20      encrypt  151.63        9.43       603.80
           salsa20      decrypt  151.63        9.43       603.77

        salsa20r12      encrypt  212.37        6.74       431.10
        salsa20r12      decrypt  212.35        6.74       431.14
ubuntu@ubuntu:~/3.6/noasm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  118.05       12.12       775.55
            chacha      decrypt  118.06       12.12       775.48

   chacha_poly1305      encrypt   80.77       17.71      1133.52
   chacha_poly1305      decrypt   80.63       17.74      1135.44
   chacha_poly1305       update  254.92        5.61       359.15

           salsa20      encrypt  151.81        9.42       603.08
           salsa20      decrypt  151.81        9.42       603.06

        salsa20r12      encrypt  212.71        6.73       430.41
        salsa20r12      decrypt  212.71        6.73       430.42

arm:
git checkout -f nettle_3.6_release_20200429 &amp;&amp; sed -ie 's,m_path="arm/v6 \
arm",m_path="arm",' configure.ac &amp;&amp; ./.bootstrap &amp;&amp; ./configure \
--disable-documentation --disable-arm-neon &amp;&amp; make &amp;&amp; make check

rpi1b:
  Version:           nettle 3.6
  Host type:         armv6l-unknown-linux-gnueabi
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

michael@rpi0-20200831:~/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f .7e9 chacha salsa20

benchmark call overhead: 0.022722 us  15.91 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.54       34.17      2186.97
            chacha      decrypt   19.62       34.02      2177.15

   chacha_poly1305      encrypt   12.43       53.70      3436.81
   chacha_poly1305      decrypt   12.46       53.60      3430.12
   chacha_poly1305       update   34.71       19.23      1230.80

           salsa20      encrypt   23.44       28.49      1823.06
           salsa20      decrypt   23.27       28.68      1835.66

        salsa20r12      encrypt   33.38       20.00      1280.09
        salsa20r12      decrypt   33.40       19.99      1279.37
michael@rpi0-20200831:~/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f .7e9 chacha salsa20

benchmark call overhead: 0.022771 us  15.94 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.48       34.28      2193.70
            chacha      decrypt   19.51       34.22      2190.04

   chacha_poly1305      encrypt   12.37       53.97      3453.88
   chacha_poly1305      decrypt   12.41       53.77      3441.38
   chacha_poly1305       update   34.77       19.20      1228.91

           salsa20      encrypt   23.29       28.66      1834.47
           salsa20      decrypt   23.20       28.77      1841.37

        salsa20r12      encrypt   33.15       20.14      1288.66
        salsa20r12      decrypt   33.25       20.08      1284.84

wandboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009049 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.57       16.86      1078.93
            chacha      decrypt   56.51       16.88      1080.14

   chacha_poly1305      encrypt   37.20       25.64      1640.79
   chacha_poly1305      decrypt   37.19       25.64      1641.25
   chacha_poly1305       update  107.49        8.87       567.81

           salsa20      encrypt   59.00       16.16      1034.48
           salsa20      decrypt   59.03       16.15      1033.91

        salsa20r12      encrypt   88.02       10.84       693.44
        salsa20r12      decrypt   87.98       10.84       693.77
mweiser@wandboard:~/nettle/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009048 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.90       16.76      1072.75
            chacha      decrypt   57.14       16.69      1068.22

   chacha_poly1305      encrypt   37.22       25.62      1639.64
   chacha_poly1305      decrypt   37.26       25.59      1638.07
   chacha_poly1305       update  107.53        8.87       567.60

           salsa20      encrypt   59.06       16.15      1033.43
           salsa20      decrypt   59.08       16.14      1033.08

        salsa20r12      encrypt   88.09       10.83       692.89
        salsa20r12      decrypt   87.96       10.84       693.91

tinkerboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.001987 us   2.98 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   94.07       15.21       973.21
            chacha      decrypt   94.17       15.19       972.21

   chacha_poly1305      encrypt   64.13       22.31      1427.52
   chacha_poly1305      decrypt   64.18       22.29      1426.45
   chacha_poly1305       update  200.26        7.14       457.16

           salsa20      encrypt  109.93       13.01       832.83
           salsa20      decrypt  108.70       13.16       842.27

        salsa20r12      encrypt  159.49        8.97       574.02
        salsa20r12      decrypt  158.45        9.03       577.82
mweiser@tinkerboard:~/nettle/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.001989 us   2.98 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   93.84       15.24       975.58
            chacha      decrypt   92.21       15.51       992.87

   chacha_poly1305      encrypt   63.78       22.43      1435.45
   chacha_poly1305      decrypt   64.03       22.34      1429.80
   chacha_poly1305       update  199.96        7.15       457.85

           salsa20      encrypt  103.07       13.88       888.27
           salsa20      decrypt  110.40       12.96       829.27

        salsa20r12      encrypt  158.59        9.02       577.29
        salsa20r12      decrypt  158.68        9.02       576.97

cubieboard2:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/3.6/arm/examples] LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.02       30.75      1967.78
            chacha      decrypt   30.60       31.17      1994.87

   chacha_poly1305      encrypt   23.66       40.30      2579.42
   chacha_poly1305      decrypt   24.10       39.57      2532.74
   chacha_poly1305       update  100.31        9.51       608.44

           salsa20      encrypt   29.92       31.87      2039.69
           salsa20      decrypt   30.33       31.45      2012.68

        salsa20r12      encrypt   46.42       20.54      1314.74
        salsa20r12      decrypt   46.01       20.73      1326.43
[michael@c2-le:~/nettle/3.6/arm/examples] LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.25       30.52      1953.32
            chacha      decrypt   31.37       30.40      1945.63

   chacha_poly1305      encrypt   23.55       40.50      2592.05
   chacha_poly1305      decrypt   23.58       40.45      2588.88
   chacha_poly1305       update  103.94        9.18       587.22

           salsa20      encrypt   30.32       31.46      2013.14
           salsa20      decrypt   29.95       31.84      2037.67

        salsa20r12      encrypt   46.87       20.35      1302.11
        salsa20r12      decrypt   46.67       20.43      1307.71

rpi4:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f 1.5e9 \
chacha salsa20

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.38       11.98       766.90
            chacha      decrypt  119.38       11.98       766.91

   chacha_poly1305      encrypt   80.82       17.70      1132.76
   chacha_poly1305      decrypt   80.83       17.70      1132.67
   chacha_poly1305       update  250.63        5.71       365.28

           salsa20      encrypt  153.76        9.30       595.44
           salsa20      decrypt  153.74        9.30       595.49

        salsa20r12      encrypt  216.54        6.61       422.79
        salsa20r12      decrypt  216.52        6.61       422.84
ubuntu@ubuntu:~/3.6/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f 1.5e9 \
chacha salsa20

benchmark call overhead: 0.004011 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.46       11.97       766.40
            chacha      decrypt  119.43       11.98       766.57

   chacha_poly1305      encrypt   81.11       17.64      1128.80
   chacha_poly1305      decrypt   81.05       17.65      1129.57
   chacha_poly1305       update  252.34        5.67       362.81

           salsa20      encrypt  153.84        9.30       595.11
           salsa20      decrypt  153.81        9.30       595.23

        salsa20r12      encrypt  216.73        6.60       422.44
        salsa20r12      decrypt  216.71        6.60       422.47

armv6:
git checkout -f nettle_3.6_release_20200429 &amp;&amp; ./.bootstrap &amp;&amp; ./configure \
--disable-documentation --disable-arm-neon &amp;&amp; make &amp;&amp; make check

rpi1b:
michael@rpi0-20200831:~/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

benchmark call overhead: 0.022703 us  15.89 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.60       34.06      2179.89
            chacha      decrypt   19.64       33.99      2175.12

   chacha_poly1305      encrypt   12.42       53.77      3441.25
   chacha_poly1305      decrypt   12.40       53.83      3445.21
   chacha_poly1305       update   34.75       19.21      1229.61

           salsa20      encrypt   23.17       28.81      1843.94
           salsa20      decrypt   23.39       28.53      1826.23

        salsa20r12      encrypt   33.36       20.01      1280.58
        salsa20r12      decrypt   33.27       20.07      1284.24
michael@rpi0-20200831:~/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

benchmark call overhead: 0.022738 us  15.92 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.55       34.14      2184.93
            chacha      decrypt   19.50       34.23      2190.97

   chacha_poly1305      encrypt   12.47       53.53      3425.61
   chacha_poly1305      decrypt   12.39       53.87      3447.77
   chacha_poly1305       update   34.75       19.21      1229.59

           salsa20      encrypt   23.32       28.62      1831.96
           salsa20      decrypt   23.35       28.59      1829.62

        salsa20r12      encrypt   33.03       20.21      1293.48
        salsa20r12      decrypt   33.28       20.06      1283.98

wandboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009048 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.30       16.94      1084.06
            chacha      decrypt   56.40       16.91      1082.13

   chacha_poly1305      encrypt   37.00       25.77      1649.45
   chacha_poly1305      decrypt   37.06       25.73      1646.77
   chacha_poly1305       update  107.51        8.87       567.73

           salsa20      encrypt   58.72       16.24      1039.49
           salsa20      decrypt   58.57       16.28      1042.18

        salsa20r12      encrypt   87.43       10.91       698.07
        salsa20r12      decrypt   87.45       10.91       697.96
mweiser@wandboard:~/nettle/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009062 us   9.06 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.59       16.85      1078.57
            chacha      decrypt   56.65       16.83      1077.33

   chacha_poly1305      encrypt   37.11       25.70      1644.58
   chacha_poly1305      decrypt   37.23       25.62      1639.49
   chacha_poly1305       update  107.37        8.88       568.47

           salsa20      encrypt   58.89       16.19      1036.40
           salsa20      decrypt   58.65       16.26      1040.73

        salsa20r12      encrypt   87.29       10.93       699.25
        salsa20r12      decrypt   87.46       10.90       697.89

tinkerboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.002536 us   3.80 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   93.04       15.37       983.99
            chacha      decrypt   93.95       15.23       974.43

   chacha_poly1305      encrypt   63.19       22.64      1448.84
   chacha_poly1305      decrypt   63.37       22.57      1444.76
   chacha_poly1305       update  200.24        7.14       457.21

           salsa20      encrypt  110.31       12.97       829.97
           salsa20      decrypt  108.41       13.19       844.47

        salsa20r12      encrypt  162.24        8.82       564.31
        salsa20r12      decrypt  162.28        8.82       564.16
mweiser@tinkerboard:~/nettle/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.002032 us   3.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   94.17       15.19       972.16
            chacha      decrypt   94.18       15.19       972.14

   chacha_poly1305      encrypt   64.10       22.32      1428.34
   chacha_poly1305      decrypt   64.03       22.34      1429.80
   chacha_poly1305       update  200.31        7.14       457.06

           salsa20      encrypt  110.01       13.00       832.23
           salsa20      decrypt  111.61       12.82       820.30

        salsa20r12      encrypt  162.30        8.81       564.11
        salsa20r12      decrypt  162.29        8.81       564.12

cubieboard2:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/3.6/armv6/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.14       30.62      1959.85
            chacha      decrypt   31.36       30.41      1946.13

   chacha_poly1305      encrypt   23.57       40.46      2589.55
   chacha_poly1305      decrypt   23.92       39.87      2551.55
   chacha_poly1305       update  100.01        9.54       610.28

           salsa20      encrypt   36.39       26.20      1677.04
           salsa20      decrypt   36.55       26.09      1669.77

        salsa20r12      encrypt   51.78       18.42      1178.74
        salsa20r12      decrypt   52.53       18.15      1161.87
[michael@c2-le:~/nettle/3.6/armv6/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.45       30.33      1940.80
            chacha      decrypt   31.29       30.47      1950.37

   chacha_poly1305      encrypt   22.97       41.51      2656.82
   chacha_poly1305      decrypt   23.83       40.01      2560.88
   chacha_poly1305       update  101.99        9.35       598.41

           salsa20      encrypt   36.81       25.91      1658.00
           salsa20      decrypt   36.62       26.04      1666.72

        salsa20r12      encrypt   53.28       17.90      1145.65
        salsa20r12      decrypt   52.74       18.08      1157.25

rpi4:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.38       11.98       766.91
            chacha      decrypt  119.38       11.98       766.92

   chacha_poly1305      encrypt   81.12       17.63      1128.56
   chacha_poly1305      decrypt   81.03       17.65      1129.90
   chacha_poly1305       update  249.53        5.73       366.90

           salsa20      encrypt  153.78        9.30       595.34
           salsa20      decrypt  153.84        9.30       595.13

        salsa20r12      encrypt  216.34        6.61       423.20
        salsa20r12      decrypt  216.62        6.60       422.64
ubuntu@ubuntu:~/3.6/armv6/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.45       11.98       766.48
            chacha      decrypt  119.44       11.98       766.49

   chacha_poly1305      encrypt   81.15       17.63      1128.16
   chacha_poly1305      decrypt   81.50       17.55      1123.33
   chacha_poly1305       update  250.90        5.70       364.89

           salsa20      encrypt  153.90        9.30       594.89
           salsa20      decrypt  153.91        9.29       594.84

        salsa20r12      encrypt  216.66        6.60       422.56
        salsa20r12      decrypt  216.66        6.60       422.55


neon:
git checkout -f nettle_3.6_release_20200429 &amp;&amp; ./.bootstrap &amp;&amp; ./configure \
--disable-documentation &amp;&amp; make &amp;&amp; make check

rpi1b: fail

wandboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

benchmark call overhead: 0.009049 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   57.50       16.59      1061.50
            chacha      decrypt   57.33       16.63      1064.64

   chacha_poly1305      encrypt   37.60       25.36      1623.14
   chacha_poly1305      decrypt   37.77       25.25      1616.15
   chacha_poly1305       update  107.52        8.87       567.65

           salsa20      encrypt   57.04       16.72      1070.07
           salsa20      decrypt   57.04       16.72      1070.09

        salsa20r12      encrypt   86.20       11.06       708.09
        salsa20r12      decrypt   86.21       11.06       707.99
mweiser@wandboard:~/nettle/3.6/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

benchmark call overhead: 0.009050 us   9.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   57.73       16.52      1057.26
            chacha      decrypt   57.71       16.53      1057.68

   chacha_poly1305      encrypt   37.76       25.26      1616.57
   chacha_poly1305      decrypt   37.77       25.25      1615.97
   chacha_poly1305       update  107.50        8.87       567.78

           salsa20      encrypt   57.01       16.73      1070.60
           salsa20      decrypt   57.03       16.72      1070.15

        salsa20r12      encrypt   86.18       11.07       708.20
        salsa20r12      decrypt   86.19       11.06       708.16

tinkerboard:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/3.6/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.001985 us   2.98 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   77.66       18.42      1178.82
            chacha      decrypt   77.68       18.41      1178.54

   chacha_poly1305      encrypt   56.01       25.54      1634.60
   chacha_poly1305      decrypt   56.01       25.54      1634.64
   chacha_poly1305       update  200.06        7.15       457.62

           salsa20      encrypt   79.04       18.10      1158.29
           salsa20      decrypt   79.24       18.05      1155.44

        salsa20r12      encrypt  124.63       11.48       734.61
        salsa20r12      decrypt  124.63       11.48       734.57
mweiser@tinkerboard:~/nettle/3.6/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

benchmark call overhead: 0.002032 us   3.05 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   77.65       18.42      1179.06
            chacha      decrypt   77.71       18.41      1178.07

   chacha_poly1305      encrypt   56.03       25.53      1633.92
   chacha_poly1305      decrypt   56.01       25.54      1634.44
   chacha_poly1305       update  200.26        7.14       457.17

           salsa20      encrypt   78.91       18.13      1160.20
           salsa20      decrypt   78.97       18.12      1159.40

        salsa20r12      encrypt  124.63       11.48       734.57
        salsa20r12      decrypt  124.64       11.48       734.52

cubieboard2:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/3.6/neon/examples] LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.77       30.99      1983.49
            chacha      decrypt   30.74       31.02      1985.27

   chacha_poly1305      encrypt   23.61       40.39      2585.19
   chacha_poly1305      decrypt   23.65       40.32      2580.75
   chacha_poly1305       update  102.87        9.27       593.32

           salsa20      encrypt   30.43       31.34      2005.60
           salsa20      decrypt   30.47       31.30      2003.32

        salsa20r12      encrypt   47.18       20.21      1293.58
        salsa20r12      decrypt   47.22       20.20      1292.60
[michael@c2-le:~/nettle/3.6/neon/examples] LD_LIBRARY_PATH=../.lib ./nettle-benchmark \
-f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.40       30.37      1943.97
            chacha      decrypt   31.42       30.35      1942.37

   chacha_poly1305      encrypt   24.17       39.46      2525.24
   chacha_poly1305      decrypt   23.94       39.83      2549.35
   chacha_poly1305       update  103.84        9.18       587.79

           salsa20      encrypt   30.40       31.37      2007.64
           salsa20      decrypt   30.41       31.36      2007.13

        salsa20r12      encrypt   47.13       20.24      1295.10
        salsa20r12      decrypt   47.10       20.25      1295.91

rpi4:
  Version:           nettle 3.6
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/3.6/neon/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   78.33       18.26      1168.87
            chacha      decrypt   78.35       18.26      1168.57

   chacha_poly1305      encrypt   59.99       23.85      1526.12
   chacha_poly1305      decrypt   60.01       23.84      1525.51
   chacha_poly1305       update  249.94        5.72       366.30

           salsa20      encrypt   80.20       17.84      1141.62
           salsa20      decrypt   80.19       17.84      1141.70

        salsa20r12      encrypt  127.46       11.22       718.31
        salsa20r12      decrypt  127.44       11.23       718.42
ubuntu@ubuntu:~/3.6/neon/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

benchmark call overhead: 0.004010 us   6.02 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   78.32       18.27      1169.01
            chacha      decrypt   78.31       18.27      1169.11

   chacha_poly1305      encrypt   60.05       23.82      1524.69
   chacha_poly1305      decrypt   60.02       23.83      1525.42
   chacha_poly1305       update  253.66        5.64       360.92

           salsa20      encrypt   80.19       17.84      1141.66
           salsa20      decrypt   80.19       17.84      1141.67

        salsa20r12      encrypt  127.32       11.24       719.06

d41841fa1682:

noasm:
git checkout -f d41841fa1682cdee38446556e2e83fd606a8d8c4 &amp;&amp; ./.bootstrap &amp;&amp; \
./configure --disable-documentation --disable-assembler &amp;&amp; make &amp;&amp; make check

rpi1b:
  Version:           nettle 3.7
  Host type:         armv6l-unknown-linux-gnueabi
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

michael@rpi0-20200831:~/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   18.65       35.79      2290.86
            chacha      decrypt   18.93       35.26      2256.65

   chacha_poly1305      encrypt   12.02       55.54      3554.49
   chacha_poly1305      decrypt   12.15       54.93      3515.53
   chacha_poly1305       update   34.74       19.22      1229.80

           salsa20      encrypt   22.11       30.20      1932.70
           salsa20      decrypt   22.03       30.31      1939.55

        salsa20r12      encrypt   30.68       21.76      1392.38
        salsa20r12      decrypt   30.86       21.63      1384.42
michael@rpi0-20200831:~/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.01       35.11      2247.11
            chacha      decrypt   18.94       35.25      2255.95

   chacha_poly1305      encrypt   12.22       54.61      3495.08
   chacha_poly1305      decrypt   12.23       54.57      3492.45
   chacha_poly1305       update   34.95       19.10      1222.52

           salsa20      encrypt   22.17       30.11      1926.97
           salsa20      decrypt   22.14       30.15      1929.59

        salsa20r12      encrypt   30.81       21.67      1386.79
        salsa20r12      decrypt   31.03       21.51      1376.87

wandboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   54.15       17.61      1127.13
            chacha      decrypt   54.08       17.63      1128.61

   chacha_poly1305      encrypt   36.06       26.45      1692.79
   chacha_poly1305      decrypt   36.20       26.34      1686.06
   chacha_poly1305       update  107.45        8.88       568.02

           salsa20      encrypt   57.22       16.67      1066.64
           salsa20      decrypt   57.17       16.68      1067.59

        salsa20r12      encrypt   81.26       11.74       751.08
        salsa20r12      decrypt   81.34       11.72       750.38
mweiser@wandboard:~/nettle/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   54.28       17.57      1124.43
            chacha      decrypt   54.21       17.59      1125.91

   chacha_poly1305      encrypt   36.06       26.45      1692.63
   chacha_poly1305      decrypt   36.08       26.43      1691.50
   chacha_poly1305       update  107.49        8.87       567.81

           salsa20      encrypt   57.18       16.68      1067.38
           salsa20      decrypt   57.11       16.70      1068.65

        salsa20r12      encrypt   81.26       11.74       751.15
        salsa20r12      decrypt   81.32       11.73       750.59

tinkerboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   91.82       15.58       997.07
            chacha      decrypt   91.92       15.56       996.05

   chacha_poly1305      encrypt   62.95       22.72      1454.32
   chacha_poly1305      decrypt   62.96       22.72      1454.14
   chacha_poly1305       update  198.58        7.20       461.04

           salsa20      encrypt  107.74       13.28       849.79
           salsa20      decrypt  108.31       13.21       845.26

        salsa20r12      encrypt  155.41        9.20       589.09
        salsa20r12      decrypt  155.42        9.20       589.06
mweiser@tinkerboard:~/nettle/master/noasm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   90.72       15.77      1009.16
            chacha      decrypt   90.90       15.74      1007.21

   chacha_poly1305      encrypt   62.94       22.73      1454.62
   chacha_poly1305      decrypt   62.88       22.75      1455.94
   chacha_poly1305       update  198.46        7.21       461.31

           salsa20      encrypt  108.01       13.24       847.60
           salsa20      decrypt  107.64       13.29       850.58

        salsa20r12      encrypt  155.36        9.21       589.29
        salsa20r12      decrypt  155.39        9.21       589.19

cubieboard2:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/master/noasm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.37       31.40      2009.80
            chacha      decrypt   30.31       31.46      2013.42

   chacha_poly1305      encrypt   23.49       40.60      2598.36
   chacha_poly1305      decrypt   23.48       40.61      2599.14
   chacha_poly1305       update  103.64        9.20       588.92

           salsa20      encrypt   34.93       27.31      1747.60
           salsa20      decrypt   35.01       27.24      1743.55

        salsa20r12      encrypt   49.75       19.17      1226.76
        salsa20r12      decrypt   49.95       19.09      1221.85
[michael@c2-le:~/nettle/master/noasm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.31       31.46      2013.43
            chacha      decrypt   30.32       31.45      2013.11

   chacha_poly1305      encrypt   23.39       40.77      2609.20
   chacha_poly1305      decrypt   23.49       40.59      2597.85
   chacha_poly1305       update  104.24        9.15       585.55

           salsa20      encrypt   35.12       27.15      1737.79
           salsa20      decrypt   35.20       27.09      1733.74

        salsa20r12      encrypt   50.04       19.06      1219.69
        salsa20r12      decrypt   50.05       19.06      1219.55

rpi4:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    none
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/master/noasm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  117.89       12.13       776.62
            chacha      decrypt  117.90       12.13       776.50

   chacha_poly1305      encrypt   80.79       17.71      1133.24
   chacha_poly1305      decrypt   80.65       17.74      1135.23
   chacha_poly1305       update  254.61        5.62       359.58

           salsa20      encrypt  151.34        9.45       604.96
           salsa20      decrypt  151.34        9.45       604.95

        salsa20r12      encrypt  211.53        6.76       432.81
        salsa20r12      decrypt  211.53        6.76       432.81
ubuntu@ubuntu:~/master/noasm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  117.81       12.14       777.11
            chacha      decrypt  117.80       12.14       777.19

   chacha_poly1305      encrypt   80.65       17.74      1135.18
   chacha_poly1305      decrypt   79.98       17.89      1144.74
   chacha_poly1305       update  250.54        5.71       365.42

           salsa20      encrypt  151.28        9.46       605.20
           salsa20      decrypt  151.29        9.46       605.15

        salsa20r12      encrypt  211.51        6.76       432.86
        salsa20r12      decrypt  211.49        6.76       432.88

arm:
git checkout -f d41841fa1682cdee38446556e2e83fd606a8d8c4 &amp;&amp; sed -ie 's,m_path="arm/v6 \
arm",m_path="arm",' configure.ac &amp;&amp; ./.bootstrap &amp;&amp; ./configure \
--disable-documentation --disable-arm-neon --disable-fat &amp;&amp; make &amp;&amp; make check

rpi1b:
  Version:           nettle 3.7
  Host type:         armv6l-unknown-linux-gnueabi
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

michael@rpi0-20200831:~/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.61       34.04      2178.86
            chacha      decrypt   19.52       34.19      2188.27

   chacha_poly1305      encrypt   12.48       53.48      3422.54
   chacha_poly1305      decrypt   12.50       53.43      3419.22
   chacha_poly1305       update   34.64       19.27      1233.47

           salsa20      encrypt   22.37       29.84      1909.64
           salsa20      decrypt   22.38       29.83      1908.87

        salsa20r12      encrypt   31.38       21.27      1361.42
        salsa20r12      decrypt   31.45       21.22      1358.33
michael@rpi0-20200831:~/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.53       34.19      2187.87
            chacha      decrypt   19.45       34.33      2197.06

   chacha_poly1305      encrypt   12.44       53.67      3434.72
   chacha_poly1305      decrypt   12.35       54.04      3458.48
   chacha_poly1305       update   34.83       19.17      1226.66

           salsa20      encrypt   22.27       29.98      1918.60
           salsa20      decrypt   22.36       29.86      1910.80

        salsa20r12      encrypt   31.31       21.32      1364.64
        salsa20r12      decrypt   31.03       21.51      1376.78

wandboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.54       16.87      1079.58
            chacha      decrypt   56.48       16.89      1080.66

   chacha_poly1305      encrypt   37.20       25.64      1640.84
   chacha_poly1305      decrypt   37.22       25.62      1639.88
   chacha_poly1305       update  107.44        8.88       568.08

           salsa20      encrypt   59.92       15.92      1018.57
           salsa20      decrypt   59.62       16.00      1023.74

        salsa20r12      encrypt   86.48       11.03       705.76
        salsa20r12      decrypt   87.03       10.96       701.29
mweiser@wandboard:~/nettle/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.94       16.75      1071.87
            chacha      decrypt   56.94       16.75      1071.95

   chacha_poly1305      encrypt   37.24       25.61      1638.92
   chacha_poly1305      decrypt   37.28       25.58      1637.40
   chacha_poly1305       update  107.49        8.87       567.83

           salsa20      encrypt   59.76       15.96      1021.32
           salsa20      decrypt   59.92       15.91      1018.56

        salsa20r12      encrypt   86.62       11.01       704.59
        salsa20r12      decrypt   86.71       11.00       703.86

tinkerboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   93.70       15.27       977.09
            chacha      decrypt   93.60       15.28       978.08

   chacha_poly1305      encrypt   63.96       22.37      1431.47
   chacha_poly1305      decrypt   63.37       22.57      1444.79
   chacha_poly1305       update  198.56        7.20       461.07

           salsa20      encrypt  110.65       12.93       827.38
           salsa20      decrypt  110.61       12.93       827.69

        salsa20r12      encrypt  159.62        8.96       573.58
        salsa20r12      decrypt  160.54        8.91       570.30
mweiser@tinkerboard:~/nettle/master/arm/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   94.16       15.19       972.26
            chacha      decrypt   94.17       15.19       972.16

   chacha_poly1305      encrypt   62.62       22.84      1462.01
   chacha_poly1305      decrypt   63.97       22.36      1431.21
   chacha_poly1305       update  198.56        7.20       461.08

           salsa20      encrypt  111.03       12.88       824.56
           salsa20      decrypt  110.54       12.94       828.27

        salsa20r12      encrypt  160.73        8.90       569.59
        salsa20r12      decrypt  161.79        8.84       565.87

cubieboard2:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/master/arm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.59       30.18      1931.80
            chacha      decrypt   31.60       30.17      1931.19

   chacha_poly1305      encrypt   24.17       39.45      2524.74
   chacha_poly1305      decrypt   24.26       39.32      2516.37
   chacha_poly1305       update  104.04        9.17       586.63

           salsa20      encrypt   36.79       25.92      1659.00
           salsa20      decrypt   36.78       25.93      1659.42

        salsa20r12      encrypt   53.58       17.80      1139.08
        salsa20r12      decrypt   53.42       17.85      1142.50
[michael@c2-le:~/nettle/master/arm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.60       30.18      1931.68
            chacha      decrypt   31.46       30.31      1940.02

   chacha_poly1305      encrypt   24.26       39.32      2516.30
   chacha_poly1305      decrypt   24.25       39.33      2517.09
   chacha_poly1305       update  104.27        9.15       585.33

           salsa20      encrypt   36.74       25.96      1661.45
           salsa20      decrypt   36.79       25.92      1659.15

        salsa20r12      encrypt   53.46       17.84      1141.63
        salsa20r12      decrypt   53.38       17.86      1143.32

rpi4:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/master/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20  Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.44       11.98       766.54
            chacha      decrypt  119.44       11.98       766.49

   chacha_poly1305      encrypt   81.23       17.61      1127.05
   chacha_poly1305      decrypt   81.12       17.63      1128.58
   chacha_poly1305       update  251.32        5.69       364.29

           salsa20      encrypt  154.09        9.28       594.15
           salsa20      decrypt  154.10        9.28       594.10

        salsa20r12      encrypt  217.24        6.58       421.43
        salsa20r12      decrypt  217.25        6.58       421.41
ubuntu@ubuntu:~/master/arm/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.24       12.00       767.79
            chacha      decrypt  119.26       11.99       767.66

   chacha_poly1305      encrypt   80.62       17.74      1135.63
   chacha_poly1305      decrypt   80.48       17.77      1137.57
   chacha_poly1305       update  250.09        5.72       366.07

           salsa20      encrypt  153.94        9.29       594.72
           salsa20      decrypt  153.96        9.29       594.65

        salsa20r12      encrypt  216.82        6.60       422.25
        salsa20r12      decrypt  216.86        6.60       422.18

armv6:
git checkout -f d41841fa1682cdee38446556e2e83fd606a8d8c4 &amp;&amp; ./.bootstrap &amp;&amp; \
./configure --disable-documentation --disable-arm-neon --disable-fat &amp;&amp; make &amp;&amp; make \
check

rpi1b:
  Version:           nettle 3.7
  Host type:         armv6l-unknown-linux-gnueabi
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

michael@rpi0-20200831:~/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.30       34.60      2214.25
            chacha      decrypt   19.42       34.37      2199.99

   chacha_poly1305      encrypt   12.45       53.61      3431.36
   chacha_poly1305      decrypt   12.40       53.82      3444.53
   chacha_poly1305       update   34.81       19.18      1227.52

           salsa20      encrypt   23.26       28.69      1836.47
           salsa20      decrypt   23.25       28.71      1837.65

        salsa20r12      encrypt   33.37       20.01      1280.44
        salsa20r12      decrypt   33.01       20.22      1294.37
michael@rpi0-20200831:~/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f .7e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   19.61       34.04      2178.64
            chacha      decrypt   19.41       34.40      2201.54

   chacha_poly1305      encrypt   12.48       53.50      3424.18
   chacha_poly1305      decrypt   12.46       53.57      3428.23
   chacha_poly1305       update   34.60       19.29      1234.88

           salsa20      encrypt   23.36       28.58      1829.02
           salsa20      decrypt   23.40       28.53      1825.68

        salsa20r12      encrypt   33.27       20.06      1284.02
        salsa20r12      decrypt   33.52       19.92      1274.66

wandboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.48       16.88      1080.57
            chacha      decrypt   56.54       16.87      1079.50

   chacha_poly1305      encrypt   37.27       25.59      1637.81
   chacha_poly1305      decrypt   37.20       25.63      1640.52
   chacha_poly1305       update  107.54        8.87       567.58

           salsa20      encrypt   59.54       16.02      1025.08
           salsa20      decrypt   59.65       15.99      1023.21

        salsa20r12      encrypt   86.86       10.98       702.65
        salsa20r12      decrypt   86.61       11.01       704.73
mweiser@wandboard:~/nettle/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   56.60       16.85      1078.43
            chacha      decrypt   56.59       16.85      1078.51

   chacha_poly1305      encrypt   37.25       25.60      1638.60
   chacha_poly1305      decrypt   37.15       25.67      1642.87
   chacha_poly1305       update  107.46        8.87       567.97

           salsa20      encrypt   59.73       15.97      1021.90
           salsa20      decrypt   59.93       15.91      1018.45

        salsa20r12      encrypt   86.78       10.99       703.37
        salsa20r12      decrypt   86.79       10.99       703.21

tinkerboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   93.01       15.38       984.38
            chacha      decrypt   88.85       16.10      1030.41

   chacha_poly1305      encrypt   63.70       22.46      1437.32
   chacha_poly1305      decrypt   63.66       22.47      1438.08
   chacha_poly1305       update  198.54        7.21       461.13

           salsa20      encrypt  111.44       12.84       821.53
           salsa20      decrypt  111.45       12.84       821.50

        salsa20r12      encrypt  161.90        8.84       565.49
        salsa20r12      decrypt  161.97        8.83       565.24
mweiser@tinkerboard:~/nettle/master/armv6/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   92.98       15.39       984.69
            chacha      decrypt   93.05       15.37       983.90

   chacha_poly1305      encrypt   63.69       22.46      1437.51
   chacha_poly1305      decrypt   63.63       22.48      1438.84
   chacha_poly1305       update  198.57        7.20       461.06

           salsa20      encrypt  111.45       12.84       821.45
           salsa20      decrypt  111.45       12.84       821.50

        salsa20r12      encrypt  161.93        8.83       565.37
        salsa20r12      decrypt  161.94        8.83       565.34

cubieboard2:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/master/armv6/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.59       30.18      1931.83
            chacha      decrypt   31.53       30.25      1936.05

   chacha_poly1305      encrypt   24.13       39.53      2529.94
   chacha_poly1305      decrypt   24.23       39.36      2518.77
   chacha_poly1305       update  104.15        9.16       586.03

           salsa20      encrypt   36.81       25.91      1658.20
           salsa20      decrypt   36.72       25.97      1662.13

        salsa20r12      encrypt   53.64       17.78      1137.81
        salsa20r12      decrypt   53.59       17.80      1138.88
[michael@c2-le:~/nettle/master/armv6/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.63       30.16      1929.96
            chacha      decrypt   31.60       30.18      1931.77

   chacha_poly1305      encrypt   24.22       39.37      2519.89
   chacha_poly1305      decrypt   24.21       39.39      2520.67
   chacha_poly1305       update  104.01        9.17       586.79

           salsa20      encrypt   36.84       25.89      1656.72
           salsa20      decrypt   36.82       25.90      1657.60

        salsa20r12      encrypt   53.63       17.78      1138.17
        salsa20r12      decrypt   53.67       17.77      1137.25

rpi4:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/master/armv6/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20  Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.16       12.00       768.32
            chacha      decrypt  119.16       12.00       768.31

   chacha_poly1305      encrypt   81.30       17.59      1126.07
   chacha_poly1305      decrypt   81.46       17.56      1123.84
   chacha_poly1305       update  252.55        5.66       362.51

           salsa20      encrypt  154.14        9.28       593.94
           salsa20      decrypt  154.18        9.28       593.81

        salsa20r12      encrypt  217.15        6.59       421.61
        salsa20r12      decrypt  217.15        6.59       421.62
ubuntu@ubuntu:~/master/armv6/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  119.15       12.01       768.40
            chacha      decrypt  119.16       12.00       768.32

   chacha_poly1305      encrypt   81.21       17.62      1127.41
   chacha_poly1305      decrypt   81.40       17.57      1124.71
   chacha_poly1305       update  252.57        5.66       362.48

           salsa20      encrypt  154.09        9.28       594.14
           salsa20      decrypt  154.11        9.28       594.09

        salsa20r12      encrypt  217.23        6.59       421.46
        salsa20r12      decrypt  217.23        6.59       421.45

neon:
git checkout -f d41841fa1682cdee38446556e2e83fd606a8d8c4 &amp;&amp; ./.bootstrap &amp;&amp; \
./configure --disable-documentation --disable-fat &amp;&amp; make &amp;&amp; make check

rpi1b: fail

wandboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: no
  Using mini-gmp:    no
  Documentation:     no

mweiser@wandboard:~/nettle/master/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  100.53        9.49       607.14
            chacha      decrypt  100.56        9.48       606.95

   chacha_poly1305      encrypt   52.31       18.23      1166.88
   chacha_poly1305      decrypt   52.30       18.23      1166.97
   chacha_poly1305       update  107.54        8.87       567.55

           salsa20      encrypt   88.63       10.76       688.63
           salsa20      decrypt   88.62       10.76       688.75

        salsa20r12      encrypt  135.81        7.02       449.43
        salsa20r12      decrypt  135.77        7.02       449.55
mweiser@wandboard:~/nettle/master/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  100.51        9.49       607.23
            chacha      decrypt  100.52        9.49       607.17

   chacha_poly1305      encrypt   52.30       18.23      1166.97
   chacha_poly1305      decrypt   52.30       18.23      1166.96
   chacha_poly1305       update  107.51        8.87       567.70

           salsa20      encrypt   88.64       10.76       688.56
           salsa20      decrypt   88.61       10.76       688.82

        salsa20r12      encrypt  135.79        7.02       449.48
        salsa20r12      decrypt  135.78        7.02       449.53

tinkerboard:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

mweiser@tinkerboard:~/nettle/master/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  144.91        9.87       631.78
            chacha      decrypt  199.86        7.16       458.08

   chacha_poly1305      encrypt   99.70       14.35       918.29
   chacha_poly1305      decrypt   99.69       14.35       918.35
   chacha_poly1305       update  200.28        7.14       457.12

           salsa20      encrypt  150.32        9.52       609.03
           salsa20      decrypt  150.82        9.48       607.03

        salsa20r12      encrypt  232.63        6.15       393.56
        salsa20r12      decrypt  191.28        7.48       478.64
mweiser@tinkerboard:~/nettle/master/neon/examples$ LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  138.29       10.34       662.03
            chacha      decrypt  198.69        7.20       460.78

   chacha_poly1305      encrypt   99.69       14.35       918.37
   chacha_poly1305      decrypt   99.72       14.35       918.13
   chacha_poly1305       update  200.29        7.14       457.09

           salsa20      encrypt  150.44        9.51       608.56
           salsa20      decrypt  150.50        9.50       608.31

        salsa20r12      encrypt  233.31        6.13       392.41
        salsa20r12      decrypt  233.36        6.13       392.33

cubieboard2:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

[michael@c2-le:~/nettle/master/neon/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   63.06       15.12       967.84
            chacha      decrypt   63.05       15.12       967.99

   chacha_poly1305      encrypt   39.18       24.34      1557.94
   chacha_poly1305      decrypt   39.15       24.36      1558.90
   chacha_poly1305       update  104.42        9.13       584.51

           salsa20      encrypt   62.13       15.35       982.39
           salsa20      decrypt   62.16       15.34       981.84

        salsa20r12      encrypt   92.68       10.29       658.53
        salsa20r12      decrypt   92.65       10.29       658.74
[michael@c2-le:~/nettle/master/neon/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   63.07       15.12       967.69
            chacha      decrypt   62.98       15.14       969.05

   chacha_poly1305      encrypt   39.18       24.34      1557.89
   chacha_poly1305      decrypt   39.17       24.34      1558.04
   chacha_poly1305       update  104.37        9.14       584.80

           salsa20      encrypt   62.16       15.34       981.92
           salsa20      decrypt   62.11       15.35       982.68

        salsa20r12      encrypt   92.71       10.29       658.37
        salsa20r12      decrypt   92.70       10.29       658.42

rpi4:
  Version:           nettle 3.7
  Host type:         armv7l-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/neon arm/v6 arm
  Install prefix:    /usr/local
  Library directory: ${exec_prefix}/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

ubuntu@ubuntu:~/master/neon/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20  Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  206.67        6.92       442.99
            chacha      decrypt  206.62        6.92       443.09

   chacha_poly1305      encrypt  112.33       12.74       815.06
   chacha_poly1305      decrypt  112.34       12.73       814.95
   chacha_poly1305       update  250.27        5.72       365.82

           salsa20      encrypt  153.44        9.32       596.65
           salsa20      decrypt  153.38        9.33       596.90

        salsa20r12      encrypt  238.43        6.00       383.97
        salsa20r12      decrypt  238.40        6.00       384.03
ubuntu@ubuntu:~/master/neon/examples$ LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f \
1.5e9 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt  206.64        6.92       443.06
            chacha      decrypt  206.63        6.92       443.08

   chacha_poly1305      encrypt  113.02       12.66       810.09
   chacha_poly1305      decrypt  113.01       12.66       810.15
   chacha_poly1305       update  250.17        5.72       365.96

           salsa20      encrypt  153.36        9.33       596.97
           salsa20      decrypt  153.40        9.33       596.81

        salsa20r12      encrypt  238.48        6.00       383.90
        salsa20r12      decrypt  238.52        6.00       383.84


["nettle-arm-bench.py" (text/x-python)]

#!/usr/bin/python3

import re
import sys

vers = ["3.6", "d41841fa1682"]
variants = ["noasm", "arm", "armv6", "neon"]
boards = ["rpi1b", "cubieboard2", "wandboard", "tinkerboard", "rpi4"]
algos = ["chacha", "salsa20"]
#algos = ["chacha", "chacha_poly1305", "salsa20", "salsa20r12"]

val = {}

for ve in vers:
    val[ve] = {}
    for va in variants:
        val[ve][va] = {}
        for bo in boards:
            val[ve][va][bo] = {}
            for al in algos:
                val[ve][va][bo][al] = .0

ve = vers[0]
va = variants[0]
bo = boards[0]
for l in sys.stdin:
    l = l.lstrip().rstrip()
    if l.endswith(":"):
        tok = l.split(":")[0]
        if tok in vers:
            ve = tok
        if tok in variants:
            va = tok
        if tok in boards:
            bo = tok

    dat = re.split(" +", l)
    if len(dat) == 5 and dat[0] in algos and dat[1] == "encrypt":
        val[ve][va][bo][dat[0]] = float(dat[4])

print("board\t%s" % "\t".join(variants))
for bo in boards:
    for al in algos:
        for ve in vers:
            als = ""
            for va in variants:
                als += '\t%.2f' % val[ve][va][bo][al]

            print('"%s"%s' % (" ".join([bo, ve, al]), als))

    print('"" 0 0 0 0')

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210101170714</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-01 17:07:14-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; Happy new year, Niels and all around,
&gt;
&gt; On Wed, Dec 30, 2020 at 09:12:24PM +0100, Niels Möller wrote:
&gt;
&gt;&gt; &gt; It comes out at around seven cycles per block slowdown for chacha-3core
&gt;&gt; &gt; and five for salsa20-2core. I trace this to vst1.8. It's just slower
&gt;&gt; Thanks for investigating. Maybe keep some IF_BE / IF_LE just for the
&gt;&gt; store instructions, to stay with vstm on little-endian?
&gt;
&gt; Sounds good. I'll try to finalise a patch and reconfirm that there's no
&gt; speed regression from it.

Sounds good!

&gt; With the help of Jeff I've gone on a bit of a benchmark binge using a:
&gt;
&gt; - Raspberry Pi 1B (Broadcom BCM2835, arm11),
&gt; - Cubieboard2 (Allwinner A20, Cortex-A7),
&gt; - Wandboard (Freescale i.MX6 DualLite, Cortex-A9),
&gt; - Tinkerboard (Rockchip RK3288, Cortex-A17) and
&gt; - Raspberry Pi 4 (Broadcom BCM2711, Cortex-A72).
&gt;
&gt; The rpi1b doesn't do NEON, so there's no numbers for that. I booted the
&gt; rpi4 with Ubuntu 20.04 armhf with arm32 kernel and userland to avoid any
&gt; influence of switches from/to 64bit mode. Some other metrics of the
&gt; systems (such as compiler) and the build commands used are in the
&gt; attached result notes. The Debian and Ubuntu systems had cpufreq
&gt; activated. Since I didn't want to mess with that, I ran the benchmark
&gt; multiple times in a loop to get cpufreq to scale up.
&gt;
&gt; I've put together a small script that parses the manual notes for
&gt; plotting using gnuplot. That produced the attached charts, which are
&gt; quite interesting.

Thanks for investigating. So from these charts, it looks like the
single-block Neon code is of no benefit on any of the test systems. And
even significantly slower on the tinkerboard and rpi4.

If that's right, the code should probably just be deleted. But I'll have
to do a little benchmarking on my own before doing that.

&gt; If these numbers are correct, it would seem that gcc got a *lot* better
&gt; in optimising for ARM in recent versions. And ARM seems to have
&gt; continuously improved native ARM instruction performance but NEON has
&gt; been stagnant.

Interesting.

&gt; What confuses me is that the arm, armv6 and neon routines all give
&gt; approximately the same speed. I'd have expected some visible difference
&gt; there. Maybe I'm still just doing something wrong here?

If you look specifically at salsa20 and chacha performance, there's no
arm or armv6 assembly, so arm, armv6 and noasm should all use the C
implementation. While neon will run different code (unless something is
highly messed up in the config).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210101185054</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-01 18:50:54-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Thanks for investigating. So from these charts, it looks like the
&gt; single-block Neon code is of no benefit on any of the test systems. And
&gt; even significantly slower on the tinkerboard and rpi4.
&gt;
&gt; If that's right, the code should probably just be deleted. But I'll have
&gt; to do a little benchmarking on my own before doing that.

I've done a benchmark run of nettle-3.6 on the GMP "nanot2" system, with
a Cortex-A9 processor. The installed compiler is gcc-5.4 (a few years
old). This is what I get:

nisse@nanot2:~/build$ nettle-nanot2-noasm/config.status --version
nettle config.status 3.6
configured by /home/nisse/hack/nettle-3.6/configure, generated by GNU Autoconf 2.69,
  with options "'--disable-shared' '--disable-assembler'"

nisse@nanot2:~/build$ nettle-nanot2-noasm/examples/nettle-benchmark -f
1.4e9 salsa20

benchmark call overhead: 0.006500 us   9.10 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

           salsa20      encrypt   78.52       17.00      1088.22
           salsa20      decrypt   78.52       17.00      1088.22

        salsa20r12      encrypt  111.62       11.96       765.57
        salsa20r12      decrypt  111.62       11.96       765.57

nisse@nanot2:~/build$ nettle-nanot2-noasm/examples/nettle-benchmark -f 1.4e9 chacha

benchmark call overhead: 0.006500 us   9.10 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   66.21       20.17      1290.57
            chacha      decrypt   66.21       20.17      1290.57

-------------

nisse@nanot2:~/build$ nettle-nanot2-neon/config.status --version
nettle config.status 3.6
configured by /home/nisse/hack/nettle-3.6/configure, generated by GNU Autoconf 2.69,
  with options "'--disable-shared' '--enable-arm-neon'"

nisse@nanot2:~/build$ nettle-nanot2-neon/examples/nettle-benchmark -f 1.4e9 salsa20

benchmark call overhead: 0.006450 us   9.03 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

           salsa20      encrypt   74.41       17.94      1148.38
           salsa20      decrypt   74.41       17.94      1148.38

        salsa20r12      encrypt  113.56       11.76       752.44
        salsa20r12      decrypt  113.56       11.76       752.44

nisse@nanot2:~/build$ nettle-nanot2-neon/examples/nettle-benchmark -f 1.4e9 chacha

benchmark call overhead: 0.006438 us   9.01 cycles

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   75.12       17.77      1137.44
            chacha      decrypt   75.12       17.77      1137.44


So no big differences, but the neon code improves performance slightly
for chacha and sal20r12, and degrades performance sligtly for salsa20.

I had a quick look at the disassembly of the C implementations, and it
uses a fair amount of loads and stores to the stack in the loop (since
it has too few general purpose registers for the state to fit). But
maybe it's well enough scheduled to do many instructions can be executed
in parallel. To compare to the neon code, which does more work per
instruction, but with dependencies forcing sequential execution of the
instructions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210102210648</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-02 21:06:48-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

I've made a release candidate tarball, see
http://www.lysator.liu.se/~nisse/archive/nettle-3.7rc1.tar.gz

Intend to release in a day or two. I mostly trust the ci system, so I
will do only a few tests on the tarball to try to catch any packaging
mistakes. As usual, any additional testing highly appreciated.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210103231456</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-03 23:14:56-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hello Niels,

On Fri, Jan 01, 2021 at 06:07:14PM +0100, Niels Möller wrote:

&gt; &gt; With the help of Jeff I've gone on a bit of a benchmark binge using a:
&gt; &gt; 
&gt; &gt; - Raspberry Pi 1B (Broadcom BCM2835, arm11),
&gt; &gt; - Cubieboard2 (Allwinner A20, Cortex-A7),
&gt; &gt; - Wandboard (Freescale i.MX6 DualLite, Cortex-A9),
&gt; &gt; - Tinkerboard (Rockchip RK3288, Cortex-A17) and
&gt; &gt; - Raspberry Pi 4 (Broadcom BCM2711, Cortex-A72).
&gt; Thanks for investigating. So from these charts, it looks like the
&gt; single-block Neon code is of no benefit on any of the test systems. And
&gt; even significantly slower on the tinkerboard and rpi4.

Attached is the new patch that unconditionally switches from vldm to vld1.32 but
keeps vstm in favour of vst1.8 on little-endian for stores.

I've done some additional benchmarks to verify impact on performance.
I've used the wandboard, tinkerboard and rpi as before and cubieboard2s
in little- and big-endian modes. This time I switched the cpufreq
governor of the first three to "performance" to get more stable numbers
(which helped noticeably, @Jeff: and switched back to ondemand on your
boxes after). Also I did ten consecutive runs of benchmark and naively
averaged the numbers (see attached raw data document). With another
python script (attached) I created another chart using gnuplot[1].

This time I've normalised the numbers to percentages with unmodified
master as reference to give a clearer indication for very small changes.
So the first and fourth bar of each group (master and master-no23core)
represent 100 percent for the following two bars respectively. The
second bar (-unified) shows the values for the attached patch. The third
bar (-unified-full) shows the values for the previous patch which
unconditionally used vst1. -no23core again shows performance with
chacha-2core and salsa-3core disabled.

The graph shows the expected slowdown when using vst1 for cubieboard and
wandboard. The slowdown for the big-endian cubieboard (second cluster)
can be ignored because the faster routines on unmodified master are
broken. So the second and third bar just show the performance that needs
to be sacrificed to get them working compared to LE.

On cubieboard, wandboard and tinkerboard there's still a small overhead
from the switch to vld1.32 which was not reliably visible in my
earlier benchmarks.

What's interesting is that on both tinkerboard and rpi4 there's also
speedups from the switch to vld1.32 and even vst1.8 (the latter also on
the wandboard but only for the likely irrelevant single core routines).
So it seems, the performance penalty isn't set in stone and might differ
between generations and implementations.

From that point of view, the slight performance hit for vld1.32 but
keeping of vstm on LE seems the best compromise, at least for the
benchmarked set of machines.

Do you have any ideas how it might be that the wandboard, tinkerboard
and rpi4 show speedups with vst1.8 for one algorithm but slowdowns for
the other and even contradict each other in that? Does it make sense to
dig into that some more or should we leave it be for now?

[1] t=$(mktemp) ; cat nettle-arm-bench-2.txt | python3 nettle-arm-bench-2.py &gt;$t ; \
gnuplot -e "set term pngcairo font 'sans,9' size 960, 540; set style data histograms; \
set ylabel 'cycles/block'; set yrange [98:]; set xtics rotate out; set style fill \
solid border; set style histogram clustered; plot for [COL=2:7] '$t' using \
COL:xticlabels(1) title columnheader;" &gt;nettle-arm-bench-chart-2.png ; rm -f "$t"

&gt; &gt; What confuses me is that the arm, armv6 and neon routines all give
&gt; &gt; approximately the same speed. I'd have expected some visible difference
&gt; If you look specifically at salsa20 and chacha performance, there's no
&gt; arm or armv6 assembly, so arm, armv6 and noasm should all use the C
&gt; implementation. While neon will run different code (unless something is

Duh. So the slight differences were most likely due to the arm native
assembly memxor routines.
-- 
Thanks,
Michael


["nettle-arm-bench-2.txt" (text/plain)]

num=10 ; \
for a in chacha salsa20 ; do \
	for o in encrypt decrypt ; do \
		for b in master arm-be-unified arm-be-unified-full \
				master-no23core arm-be-unified-no23core arm-be-unified-full-no23core ; do \
			echo -n "$b $a $o " ; \
			for i in `seq 1 $num` ; do \
				LD_LIBRARY_PATH=build-$b/.lib \
					build-$b/examples/nettle-benchmark -f 1e9 "$a" | \
					grep " $a .* $o " ; \
			done | \
			awk "{ sum+=\$5 } END { print sum / $num }" ; \
		done ; \
	done ; \
done

cb2be:
master chacha encrypt 967.941
arm-be-unified chacha encrypt 975.227
arm-be-unified-full chacha encrypt 975.256
master-no23core chacha encrypt 1949.98
arm-be-unified-no23core chacha encrypt 1949.54
arm-be-unified-full-no23core chacha encrypt 1949.36
master chacha decrypt 967.818
arm-be-unified chacha decrypt 975.263
arm-be-unified-full chacha decrypt 975.117
master-no23core chacha decrypt 1949.91
arm-be-unified-no23core chacha decrypt 1948.77
arm-be-unified-full-no23core chacha decrypt 1948.73
master salsa20 encrypt 982.222
arm-be-unified salsa20 encrypt 987.145
arm-be-unified-full salsa20 encrypt 987.078
master-no23core salsa20 encrypt 2009.6
arm-be-unified-no23core salsa20 encrypt 2009.17
arm-be-unified-full-no23core salsa20 encrypt 2009.27
master salsa20 decrypt 982.108
arm-be-unified salsa20 decrypt 986.952
arm-be-unified-full salsa20 decrypt 986.955
master-no23core salsa20 decrypt 2009.54
arm-be-unified-no23core salsa20 decrypt 2009.27
arm-be-unified-full-no23core salsa20 decrypt 2009.12

cb2le:
master chacha encrypt 968.091
arm-be-unified chacha encrypt 970.03
arm-be-unified-full chacha encrypt 975.301
master-no23core chacha encrypt 1941.42
arm-be-unified-no23core chacha encrypt 1943.76
arm-be-unified-full-no23core chacha encrypt 1949.14
master chacha decrypt 967.843
arm-be-unified chacha decrypt 969.938
arm-be-unified-full chacha decrypt 975.149
master-no23core chacha decrypt 1941.12
arm-be-unified-no23core chacha decrypt 1943.75
arm-be-unified-full-no23core chacha decrypt 1948.79
master salsa20 encrypt 982.202
arm-be-unified salsa20 encrypt 983.302
arm-be-unified-full salsa20 encrypt 987.114
master-no23core salsa20 encrypt 2000.6
arm-be-unified-no23core salsa20 encrypt 2004.07
arm-be-unified-full-no23core salsa20 encrypt 2009.56
master salsa20 decrypt 982.029
arm-be-unified salsa20 decrypt 983.11
arm-be-unified-full salsa20 decrypt 987.037
master-no23core salsa20 decrypt 2000.44
arm-be-unified-no23core salsa20 decrypt 2003.84
arm-be-unified-full-no23core salsa20 decrypt 2009.24

wandboard:
master chacha encrypt 607.1
arm-be-unified chacha encrypt 608.137
arm-be-unified-full chacha encrypt 611.156
master-no23core chacha encrypt 1057.32
arm-be-unified-no23core chacha encrypt 1059.04
arm-be-unified-full-no23core chacha encrypt 1054.13
master chacha decrypt 607.076
arm-be-unified chacha decrypt 608.517
arm-be-unified-full chacha decrypt 612.231
master-no23core chacha decrypt 1057.04
arm-be-unified-no23core chacha decrypt 1058.98
arm-be-unified-full-no23core chacha decrypt 1053.96
master salsa20 encrypt 689.26
arm-be-unified salsa20 encrypt 691.27
arm-be-unified-full salsa20 encrypt 692.505
master-no23core salsa20 encrypt 1064.92
arm-be-unified-no23core salsa20 encrypt 1066.47
arm-be-unified-full-no23core salsa20 encrypt 1073.06
master salsa20 decrypt 688.966
arm-be-unified salsa20 decrypt 691.242
arm-be-unified-full salsa20 decrypt 692.618
master-no23core salsa20 decrypt 1064.66
arm-be-unified-no23core salsa20 decrypt 1066.36
arm-be-unified-full-no23core salsa20 decrypt 1072.83

tinkerboard:
master chacha encrypt 457.99
arm-be-unified chacha encrypt 458.329
arm-be-unified-full chacha encrypt 460.074
master-no23core chacha encrypt 1181.35
arm-be-unified-no23core chacha encrypt 1177.36
arm-be-unified-full-no23core chacha encrypt 1179.59
master chacha decrypt 459.424
arm-be-unified chacha decrypt 459.78
arm-be-unified-full chacha decrypt 461.57
master-no23core chacha decrypt 1181.38
arm-be-unified-no23core chacha decrypt 1176.76
arm-be-unified-full-no23core chacha decrypt 1179.05
master salsa20 encrypt 606.965
arm-be-unified salsa20 encrypt 601.151
arm-be-unified-full salsa20 encrypt 600.653
master-no23core salsa20 encrypt 1159.21
arm-be-unified-no23core salsa20 encrypt 1145.75
arm-be-unified-full-no23core salsa20 encrypt 1150.34
master salsa20 decrypt 607.889
arm-be-unified salsa20 decrypt 600.75
arm-be-unified-full salsa20 decrypt 598.105
master-no23core salsa20 decrypt 1158.48
arm-be-unified-no23core salsa20 decrypt 1145.5
arm-be-unified-full-no23core salsa20 decrypt 1151.3

rpi4:
master chacha encrypt 442.928
arm-be-unified chacha encrypt 442.479
arm-be-unified-full chacha encrypt 439.679
master-no23core chacha encrypt 1167.44
arm-be-unified-no23core chacha encrypt 1162.7
arm-be-unified-full-no23core chacha encrypt 1169.14
master chacha decrypt 443.26
arm-be-unified chacha decrypt 442.209
arm-be-unified-full chacha decrypt 439.808
master-no23core chacha decrypt 1167.54
arm-be-unified-no23core chacha decrypt 1162.67
arm-be-unified-full-no23core chacha decrypt 1169.03
master salsa20 encrypt 595.877
arm-be-unified salsa20 encrypt 595.913
arm-be-unified-full salsa20 encrypt 604.69
master-no23core salsa20 encrypt 1141.49
arm-be-unified-no23core salsa20 encrypt 1144.18
arm-be-unified-full-no23core salsa20 encrypt 1142.33
master salsa20 decrypt 596.213
arm-be-unified salsa20 decrypt 595.961
arm-be-unified-full salsa20 decrypt 604.602
master-no23core salsa20 decrypt 1141.25
arm-be-unified-no23core salsa20 decrypt 1143.96
arm-be-unified-full-no23core salsa20 decrypt 1142.28

["nettle-arm-bench-2.py" (text/x-python)]

#!/usr/bin/python3

import sys

variants = ["master", "arm-be-unified", "arm-be-unified-full",
        "master-no23core", "arm-be-unified-no23core", "arm-be-unified-full-no23core"]
boards = ["cb2le", "cb2be", "wandboard", "tinkerboard", "rpi4"]
algos = ["chacha", "salsa20"]
ops = ["encrypt", "decrypt"]

val = {}
for va in variants:
    val[va] = {}
    for bo in boards:
        val[va][bo] = {}
        for al in algos:
            val[va][bo][al] = {}
            for op in ops:
                val[va][bo][al][op] = .0

bo = boards[0]
for l in sys.stdin:
    tok = l.lstrip().rstrip().split()
    if not tok:
        continue
    if tok[0].endswith(":") and tok[0][:-1] in boards:
        bo = tok[0][:-1]
        continue
    if len(tok) == 4 and tok[0] in variants:
        val[tok[0]][bo][tok[1]][tok[2]] = float(tok[3])

print("board\t%s" % "\t".join(variants))
for bo in boards:
    for al in algos:
        for op in ops:
            vas = ""
            for va in variants:
                refva = "master"
                if "no23core" in va:
                    refva = "master-no23core"
                ref = val[refva][bo][al][op]
                abs_ = val[va][bo][al][op]
                rel = abs_ * 100 / ref
                vas += '\t%.2f' % rel

            print('"%s"%s' % (" ".join([bo, al, op]), vas))

    print('"" 0 0 0 0')

["0001-arm-Unify-neon-asm-for-big-and-little-endian-modes.patch" (text/x-diff)]

From d487ab6b942407671b5d5b02f0d61ef493af214c Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Fri, 25 Dec 2020 17:13:52 +0100
Subject: [PATCH] arm: Unify neon asm for big- and little-endian modes

Switch arm neon assembler routines to endianness-agnostic loads and
stores where possible to avoid modifications to the rest of the code.
This involves switching to vld1.32 for loading consecutive 32-bit words
in host endianness as well as vst1.8 for storing back to memory in
little-endian order as required by the caller. Where necessary, r3 is
used to store the precalculated offset into the source vector for the
secondary load operations. vstm is kept for little-endian platforms
because it is faster than vst1 on most ARM implementations.

vst1.x (at least on the Allwinner A20 Cortex-A7 implementation) seems to
interfer with itself on subsequent calls, slowing it down further. So we
reschedule some instructions to do stores as soon as results become
available to have some other calculations or loads before the next
vst1.x. This reliably saves two additional cycles per block on salsa20
and chacha which would otherwise be incurred.

vld1.x does not seem to suffer from this or at least not to a level
where two consecutive vld1.x run slower than an equivalent vldm.
Rescheduling them similarly did not improve performance beyond that of
vldm.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/README                         | 14 ++++++-
 arm/neon/chacha-3core.asm          | 36 ++++++++++++++----
 arm/neon/chacha-core-internal.asm  | 47 +++++++-----------------
 arm/neon/salsa20-2core.asm         | 28 ++++++++++----
 arm/neon/salsa20-core-internal.asm | 59 ++++++++++--------------------
 5 files changed, 95 insertions(+), 89 deletions(-)

diff --git a/arm/README b/arm/README
index 1ba54e0d..03149002 100644
--- a/arm/README
+++ b/arm/README
@@ -70,12 +70,24 @@ If data is to be processed with bit operations only, endianness can be ignored
 because byte-swapping on load and store will cancel each other out. Shifts
 however have to be inverted. See arm/memxor.asm for an example.
 
-3. vld1.8
+3. v{ld,st}1.{8,32}
 
 NEON's vld instruction can be used to produce endianness-neutral code. vld1.8
 will load a byte sequence into a register regardless of memory endianness. This
 can be used to process byte sequences. See arm/neon/umac-nh.asm for example.
 
+In the same fashion, vst1.8 can be used do a little-endian store. See
+arm/neon/salsa and chacha routines for examples.
+
+NOTE: vst1.x (at least on the Allwinner A20 Cortex-A7 implementation) seems to
+interfer with itself on subsequent calls, slowing it down. This can be avoided
+by putting calculcations or loads inbetween two vld1.x stores.
+
+Similarly, vld1.32 is used in chacha and salsa routines where 32-bit operands
+are stored in host-endianness in RAM but need to be loaded sequentially without
+the distortion introduced by vldm/vstm. Consecutive vld1.x instructions do not
+seem to suffer from slowdown similar to vst1.x.
+
 4. vldm/vstm
 
 Care has to be taken when using vldm/vstm because they have two non-obvious
diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..c29c62a5 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 C State, X, Y and Z representing consecutive blocks
 define(`X0', `q0')
@@ -64,10 +65,13 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
@@ -213,33 +217,49 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
+
+	C vst1.8 because caller expects results little-endian
+	C interleave loads, calculations and stores to save cycles on stores
+	C use vstm when little-endian for some additional speedup
+IF_BE(`	vst1.8	{X0,X1}, [DST]!')
+
+	vld1.32	{T2,T3}, [SRCp32]
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
-	vstmia	DST!, {X0,X1,X2,X3}
+IF_BE(`	vst1.8	{X2,X3}, [DST]!')
+IF_LE(`	vstmia	DST!, {X0,X1,X2,X3}')
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
+IF_BE(`	vst1.8	{Y0,Y1}, [DST]!')
+
 	vadd.i32	Y2, Y2, T2
-	vstmia	DST!, {Y0,Y1,Y2,Y3}
+IF_BE(`	vst1.8	{Y2,Y3}, [DST]!')
+IF_LE(`	vstmia	DST!, {Y0,Y1,Y2,Y3}')
 
 	vadd.i32	Z0, Z0, T0
 	vadd.i32	Z1, Z1, T1
+IF_BE(`	vst1.8	{Z0,Z1}, [DST]!')
+
 	vadd.i32	Z2, Z2, T2
 
 	vpop	{q4,q5,q6,q7}
 
-	vstm	DST, {Z0,Z1,Z2,Z3}
+IF_BE(`	vst1.8	{Z2,Z3}, [DST]')
+IF_LE(`	vstm	DST, {Z0,Z1,Z2,Z3}')
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	vldm	SRC, {X0,X1,X2,X3}
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i32	Y3, X3, Z3	C Increment 32-bit counter
 	vadd.i32	Z3, Y3, Z3
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index b0a775bd..5095be6a 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,7 +83,9 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	vld1.32	{X0,X1}, [SRC]!		C SRC changed!
+	vld1.32	{X2,X3}, [SRC]
 
 	vmov	S0, X0
 	vmov	S1, X1
@@ -96,15 +98,6 @@ PROLOGUE(_nettle_chacha_core)
 	C	 8  9 10 11	X2
 	C	12 13 14 15	X3
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-
 .Loop:
 	QROUND(X0, X1, X2, X3)
 
@@ -113,44 +106,32 @@ PROLOGUE(_nettle_chacha_core)
 	C	 5  6  7  4  &gt;&gt;&gt; 3
 	C	10 11  8  9  &gt;&gt;&gt; 2
 	C	15 12 13 14  &gt;&gt;&gt; 1
-
-	C In big-endian rotate rows, to get
-	C	 1  0  3  2
-	C	 6  5  4  7  &gt;&gt;&gt; 1
-	C	11 10  9  8  &gt;&gt;&gt; 2
-	C	12 15 14 13  &gt;&gt;&gt; 3
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	QROUND(X0, X1, X2, X3)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	bhi	.Loop
 
 	vadd.u32	X0, X0, S0
 	vadd.u32	X1, X1, S1
+
+	C vst1.8 because caller expects results little-endian
+	C use vstm when little-endian for some additional speedup
+IF_BE(`	vst1.8	{X0,X1}, [DST]!')
+
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+IF_BE(`	vst1.8	{X2,X3}, [DST]')
+IF_LE(`	vstm  DST, {X0,X1,X2,X3}')
 	bx	lr
 EPILOGUE(_nettle_chacha_core)
 
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index b3fe7e94..4d9da79b 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 C State, even elements in X, odd elements in Y
 define(`X0', `q0')
@@ -58,11 +59,14 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
-	vld1.64 {Y1}, [r12]
+	vld1.32 {Y1}, [r12]
 	vmov	Y0, X1
 	vadd.i64 Y1, Y1, X2	C Increment counter
 	vmov	Y2, X3
@@ -180,7 +184,8 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]
+	vld1.32	{T2,T3}, [SRCp32]
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
@@ -190,17 +195,26 @@ C Inverse swaps and transpositions
 C Add in the original context
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
+
+C vst1.8 because caller expects results little-endian
+C interleave loads, calculations and stores to save cycles on stores
+C use vstm when little-endian for some additional speedup
+IF_BE(`	vst1.8	{X0,X1}, [DST]!')
+
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
+IF_BE(`	vst1.8	{X2,X3}, [DST]!')
+IF_LE(`	vstmia	DST!, {X0,X1,X2,X3}')
 
-	vstmia	DST!, {X0,X1,X2,X3}
-	vld1.64 {X0}, [r12]
+	vld1.32 {X0}, [r12]
 	vadd.i32	T0, T0, Y3
 	vadd.i64	T2, T2, X0
 	vadd.i32	T1, T1, Y0
+IF_BE(`	vst1.8	{T0,T1}, [DST]!')
+
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2
-
-	vstm	DST, {T0,T1,T2,T3}
+IF_BE(`	vst1.8	{T2,T3}, [DST]')
+IF_LE(`	vstm	DST, {T0,T1,T2,T3}')
 	bx	lr
 EPILOGUE(_nettle_salsa20_2core)
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index d59d7b80..c5785da4 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 define(`X0', `q0')
 define(`X1', `q1')
@@ -86,7 +87,10 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
@@ -99,23 +103,10 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 8 13  2  7
 	C	12  1  6 11
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-	C Permuted to:
-	C	 5  0 15 10
-	C	 9  4  3 14
-	C	13  8  7  2
-	C	 1 12 11  6
-
 	C FIXME: Construct in some other way?
 	adr	r12, .Lmasks
-	vldm	r12, {M0101, M0110, M0011}
+	vld1.32	{M0101, M0110}, [r12]!
+	vld1.32	{M0011}, [r12]
 
 	vmov	S1, X1
 	vmov	S2, X2
@@ -160,29 +151,17 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 3  4  9 14  &gt;&gt;&gt; 1
 	C	 2  7  8 13  &gt;&gt;&gt; 2
 	C	 1  6 11 12  &gt;&gt;&gt; 3
-
-	C In big-endian rotate rows, to get
-	C	 5  0 15 10
-	C	 4  3 14  9  &gt;&gt;&gt; 3
-	C	 7  2 13  8  &gt;&gt;&gt; 2
-	C	 6  1 12 11  &gt;&gt;&gt; 1
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	QROUND(X0, X3, X2, X1)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	bhi	.Loop
 
@@ -202,19 +181,19 @@ IF_BE(`	vext.32	X3, X3, X3, #1')
 	vbit	X2, X3, M0101
 	vbit	X3, T1, M0101
 
-	vld1.64	{T0}, [SRC]
+	vld1.32	{T0}, [SRC]
 	vadd.u32	X0, X0, T0
 	vadd.u32	X1, X1, S1
+
+	C vst1.8 because caller expects results little-endian
+	C use vstm when little-endian for some additional speedup
+IF_BE(`	vst1.8	{X0,X1}, [DST]!')
+
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+IF_BE(`	vst1.8	{X2,X3}, [DST]')
+IF_LE(`	vstm	DST, {X0,X1,X2,X3}')
 	bx	lr
 EPILOGUE(_nettle_salsa20_core)
 
-- 
2.30.0


[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210113124338</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-13 12:43:38-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; Attached is the new patch that unconditionally switches from vldm to vld1.32 but
&gt; keeps vstm in favour of vst1.8 on little-endian for stores.

Thanks! Applied now.

&gt; From that point of view, the slight performance hit for vld1.32 but
&gt; keeping of vstm on LE seems the best compromise, at least for the
&gt; benchmarked set of machines.

I agree. One could consider having several variants and do code selection
depending on processor flavor. But I don't think that's worth the effort
if difference is just a percent or so.

&gt; Do you have any ideas how it might be that the wandboard, tinkerboard
&gt; and rpi4 show speedups with vst1.8 for one algorithm but slowdowns for
&gt; the other and even contradict each other in that? Does it make sense to
&gt; dig into that some more or should we leave it be for now?

I'd guess the algorithms differ in the details in how vst1.8 is
scheduled, and that's why vst1.8 is more or less efficient.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210105132309</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-05 13:23:09-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt; I made a merge request in the main repo that enables optimized GHASH on
&gt;&gt; AArch64 architecture.
&gt;
&gt; Nice! I've had a quick first look. For the organization, I think aarch64
&gt; assembly should go in it's own directory, arm64/, like it's done for x86
&gt; and sparc.

I've made a new branch "arm64" with the configure changes. If you think
that looks ok, can you add your new ghash code on top of that?

(I'd like to make a similar branch for S390x. It would be good to also
get S390x into the ci system, before adding s390x-specific assembly. I
hope that should be easy to do with the same cross setup as for arm,
arm64, mips, etc).

&gt; I wonder which assembly files we should use if target host is aarch64,
&gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt; we also use arm/neon/ code unconditionally?

The reference manual says

Armv8 can support the following levels of support for Advanced SIMD and
floating-point instructions:

*    Full SIMD and floating-point support without exception trapping.

*    Full SIMD and floating-point support with exception trapping.

*    No floating-point or SIMD support. This option is licensed only for
     implementations targeting specialized markets.

As far as I understand, that means Neon should be always available, in
both 32-bit and 64-bit mode.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210105133206</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-01-05 13:32:06-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Jan 5, 2021 at 8:23 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; ...
&gt; The reference manual says
&gt;
&gt; Armv8 can support the following levels of support for Advanced SIMD and
&gt; floating-point instructions:
&gt;
&gt; *    Full SIMD and floating-point support without exception trapping.
&gt;
&gt; *    Full SIMD and floating-point support with exception trapping.
&gt;
&gt; *    No floating-point or SIMD support. This option is licensed only for
&gt;      implementations targeting specialized markets.
&gt;
&gt; As far as I understand, that means Neon should be always available, in
&gt; both 32-bit and 64-bit mode.

NEON is called ASIMD under ARMv8. It is part of the base machine, like
SSE2 is part of x86_64.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210105155235</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-05 15:52:35-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Jan 5, 2021 at 3:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I've made a new branch "arm64" with the configure changes. If you think
&gt; that looks ok, can you add your new ghash code on top of that?
&gt;

Great. I'll add the ghash code to the branch once I finish the big-endian
support.


&gt; (It would be good to also
&gt; get S390x into the ci system, before adding s390x-specific assembly. I
&gt; hope that should be easy to do with the same cross setup as for arm,
&gt; arm64, mips, etc).
&gt;

This is not possible since qemu doesn't support cipher functions, it
implements subcode 0 (query) without actual encipher/decipher operations,
take a look here
https://git.qemu.org/?p=qemu.git;a=commit;h=be2b567018d987591647935a7c9648e9c45e05e8


I had a talk with David Edelsohn for this issue, I concluded that there is
no support for cipher functions on qemu and it's unlikely to happen anytime
soon. However, I updated the testutils to cover the s390x-specific assembly
so the patch can easily be tested manually by executing 'make check'. I
also have tested every aspect of this patch to make sure everything will go
well once it's merged.

&gt; I wonder which assembly files we should use if target host is aarch64,
&gt; &gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt; &gt; we also use arm/neon/ code unconditionally?
&gt;
&gt; The reference manual says
&gt;
&gt; Armv8 can support the following levels of support for Advanced SIMD and
&gt; floating-point instructions:
&gt;
&gt; *    Full SIMD and floating-point support without exception trapping.
&gt;
&gt; *    Full SIMD and floating-point support with exception trapping.
&gt;
&gt; *    No floating-point or SIMD support. This option is licensed only for
&gt;      implementations targeting specialized markets.
&gt;
&gt; As far as I understand, that means Neon should be always available, in
&gt; both 32-bit and 64-bit mode.
&gt;

I'll investigate how we can build the existing NEON implementations on
64-bit systems.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210105174606</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-05 17:46:06-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Maamoun,

On Tue, Jan 05, 2021 at 05:52:35PM +0200, Maamoun TK wrote:

&gt; &gt; I've made a new branch "arm64" with the configure changes. If you think
&gt; &gt; that looks ok, can you add your new ghash code on top of that?
&gt; Great. I'll add the ghash code to the branch once I finish the big-endian
&gt; support.

I've dusted off the pine64s I mentioned before. Both are running Gentoo,
one little-endian, the other big-endian. I'd be happy to give anything
you throw my way a whirl on real hardware.

# uname -a
Linux v 4.16.0-rc5-00012-g7cfbc0d114ca #1 SMP Tue Mar 13 18:55:14 CET 2018 aarch64_be \
GNU/Linux (A newer kernel is coming.)
# file /usr/lib64/libnettle.so.8.0
/usr/lib64/libnettle.so.8.0: ELF 64-bit MSB shared object, ARM aarch64, version 1 \
(SYSV), dynamically linked, stripped

Regarding CI: I've recently updated my buildroot-based armv[567]b container
images.[1] Something similar should be doable for aarch64_be.

[1] https://hub.docker.com/r/michaelweisernettleci/buildroot
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210105190459</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-05 19:04:59-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Thank you, I will keep you updated about progress of big-endian support for
GHASH on arm64 arch so we can test the patch on real device before sending
it to Niels.

regards,
Mamone

On Tue, Jan 5, 2021 at 8:00 PM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:

&gt; Hello Maamoun,
&gt;
&gt; On Tue, Jan 05, 2021 at 05:52:35PM +0200, Maamoun TK wrote:
&gt;
&gt; &gt; &gt; I've made a new branch "arm64" with the configure changes. If you think
&gt; &gt; &gt; that looks ok, can you add your new ghash code on top of that?
&gt; &gt; Great. I'll add the ghash code to the branch once I finish the big-endian
&gt; &gt; support.
&gt;
&gt; I've dusted off the pine64s I mentioned before. Both are running Gentoo,
&gt; one little-endian, the other big-endian. I'd be happy to give anything
&gt; you throw my way a whirl on real hardware.
&gt;
&gt; # uname -a
&gt; Linux v 4.16.0-rc5-00012-g7cfbc0d114ca #1 SMP Tue Mar 13 18:55:14 CET 2018
&gt; aarch64_be GNU/Linux
&gt; (A newer kernel is coming.)
&gt; # file /usr/lib64/libnettle.so.8.0
&gt; /usr/lib64/libnettle.so.8.0: ELF 64-bit MSB shared object, ARM aarch64,
&gt; version 1 (SYSV), dynamically linked, stripped
&gt;
&gt; Regarding CI: I've recently updated my buildroot-based armv[567]b container
&gt; images.[1] Something similar should be doable for aarch64_be.
&gt;
&gt; [1] https://hub.docker.com/r/michaelweisernettleci/buildroot
&gt; --
&gt; Thanks,
&gt; Michael
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210110203330</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-10 20:33:30-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Maamoun,

On Tue, Jan 05, 2021 at 09:04:59PM +0200, Maamoun TK wrote:

&gt; Thank you, I will keep you updated about progress of big-endian support for
&gt; GHASH on arm64 arch so we can test the patch on real device before sending
&gt; it to Niels.

I've added aarch64_be buildroot toolchain container images to
https://hub.docker.com/r/michaelweisernettleci/buildroot. Tags are
michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc and
michaelweisernettleci/buildroot:2020.11.1-aarch64_be-uclibc.

I've also updated the arm CI branch[1] with with an aarch64_be build[2]
that runs the testsuite through qemu-user.

[1] https://gitlab.com/michaelweiser/nettle/-/tree/arm-ci-fat
[2] https://gitlab.com/michaelweiser/nettle/-/blob/arm-ci-fat/.gitlab-ci.yml#L179

The BE pine64 board is also all updated now and standing by.
-- 
HTH,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210111213943</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-11 21:39:43-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

I have tuned the ghash patch to support big-endian mode but I'm really
having difficulties testing it out through emulating, I'll attach the patch
here so you can test it but I'm not sure how I can fix the bugs on
big-endian system if any, you can feel free to send debugging info or setup
a remote ssh connection so we can get it work properly.

The patch is built on top of the master branch.

regards,
Mamone

On Sun, Jan 10, 2021 at 10:45 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Hello Maamoun,
&gt;
&gt; On Tue, Jan 05, 2021 at 09:04:59PM +0200, Maamoun TK wrote:
&gt;
&gt; &gt; Thank you, I will keep you updated about progress of big-endian support
&gt; for
&gt; &gt; GHASH on arm64 arch so we can test the patch on real device before
&gt; sending
&gt; &gt; it to Niels.
&gt;
&gt; I've added aarch64_be buildroot toolchain container images to
&gt; https://hub.docker.com/r/michaelweisernettleci/buildroot. Tags are
&gt; michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc and
&gt; michaelweisernettleci/buildroot:2020.11.1-aarch64_be-uclibc.
&gt;
&gt; I've also updated the arm CI branch[1] with with an aarch64_be build[2]
&gt; that runs the testsuite through qemu-user.
&gt;
&gt; [1] https://gitlab.com/michaelweiser/nettle/-/tree/arm-ci-fat
&gt; [2]
&gt; https://gitlab.com/michaelweiser/nettle/-/blob/arm-ci-fat/.gitlab-ci.yml#L179
&gt;
&gt; The BE pine64 board is also all updated now and standing by.
&gt; --
&gt; HTH,
&gt; Michael
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210113175959</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-13 17:59:59-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Mon, Jan 11, 2021 at 11:39:43PM +0200, Maamoun TK wrote:

&gt; I have tuned the ghash patch to support big-endian mode but I'm really
&gt; having difficulties testing it out through emulating, I'll attach the patch
&gt; here so you can test it but I'm not sure how I can fix the bugs on
&gt; big-endian system if any, you can feel free to send debugging info or setup
&gt; a remote ssh connection so we can get it work properly.

Out of curiosity as I can't seem to find the beginning of the
discussion: Is there anyone but me with an actual use-case for
big-endian arm64 here? If not, I'd hate to cause a lot of effort for you
and would certainly put in the effort to get this going myself.

&gt; The patch is built on top of the master branch.

First it failed to compile gcm-hash.o with error "No rule to make
target" which turned out to be caused by a missing arm64/machine.m4.
After I added an empty file there it compiled fine on aarch64 and the
testsuite succeeded on the actual hardware as well as under qemu-aarch64
user mode emulation (both LE).

On aarch64_be it fails to compile with the following error message:

gcm-hash.s:113: Error: unknown mnemonic `zip' -- `zip v23.2d,v2.2d,v22.2d'
gcm-hash.s:119: Error: unknown mnemonic `zip' -- `zip v25.2d,v3.2d,v22.2d'
gcm-hash.s:129: Error: unknown mnemonic `zip' -- `zip v27.2d,v4.2d,v22.2d'
gcm-hash.s:137: Error: unknown mnemonic `zip' -- `zip v29.2d,v5.2d,v22.2d'

This happens with gcc 10.2.0 on my hardware board as well as cross gcc
9.3.0 of Buildroot 2020.11.1 in a container.

I did a search of the aarch64 instruction set and saw that there's zip1
and zip2 instructions. So as a first test I just changed zip to zip1
which made it compile. As was to be expected, the testsuite failed
though.

Before you try and get me up to speed on what the routine is supposed to
be doing there's also an option for you to get a cross toolchain and
emulator for your own tests without too much effort. Here's how I
cross-compile nettle and run the testsuite using rootless podman (docker
should do just as well) on my x86_64 box:

cd ~/Downloads
mkdir nettle
cd nettle
git clone https://git.lysator.liu.se/nettle/nettle
cd nettle
git apply ~/arm64_ghash.patch
./.bootstrap
podman run -it -v ~/Downloads/nettle:/nettle \
michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc-gdb cd /nettle/
mkdir build-aarch64_be
cd build-aarch64_be/
../nettle/configure --host=$(cat /buildroot/triple) --enable-armv8-a-crypto
make -j4
make -j4 check EMULATOR=/buildroot/qemu

Unfortunately, because in this case qemu-aarch64_be is running the
testsuite binaries under emulation and doesn't support the ptrace
syscall (and containers usually don't either), you can't just run it
under an aarch64_be native gdb to see what it's executing.

One option would be to boot a full BE system image with kernel in
qemu-system-aarch64 including a native gdb. But that's a bit of a hassle
(building a rootfs and kernel e.g. using buildroot, getting it to boot
in qemu, accessing it via console or network, ...)

qemu-user can however serve as a gdb server similar to qemu-system[1].
[1] https://qemu.readthedocs.io/en/latest/system/gdb.html

As luck would have it, above container image contains an x86_64-native
gdb targeting aarch64_be. So you can start the testsuite test under qemu
with the -g option and a port to listen on for the gdb remote debugging
connection and then fire up gdb and connect there. After that you can
debug as usual, single-step and look at register values:

root@6c85515d3939:/nettle/build-aarch64_be/testsuite# /buildroot/qemu -E \
LD_LIBRARY_PATH=../.lib -g 9000 ./gcm-test &amp; [1] 4205
root@6c85515d3939:/nettle/build-aarch64_be/testsuite# \
aarch64_be-buildroot-linux-gnu-gdb ./gcm-test GNU gdb (GDB) 8.3.1
[...]
Reading symbols from ./gcm-test...
(gdb) break main
Breakpoint 1 at 0x4037b0: file ../../nettle/testsuite/testutils.c, line 123.
(gdb) target remote localhost:9000
Remote debugging using localhost:9000
warning: remote target does not support file transfer, attempting to
access files from local filesystem.
warning: Unable to find dynamic linker breakpoint function.
GDB will be unable to debug shared library initializers
and track explicitly loaded dynamic code.
0x0000004000802040 in ?? ()
(gdb) c
Continuing.
warning: Could not load shared library symbols for 3 libraries, e.g.
/usr/lib64/libgmp.so.10.
Use the "info sharedlibrary" command to see the complete listing.
Do you need "set solib-search-path" or "set sysroot"?

Breakpoint 1, main (argc=1, argv=0x4000800d58) at \
../../nettle/testsuite/testutils.c:123 123       if (argc &gt; 1)
(gdb) b _nettle_gcm_init_key
Breakpoint 2 at 0x40008b69f4: file gcm-hash.s, line 93.
(gdb) c
Continuing.

Breakpoint 2, _nettle_gcm_init_key () at gcm-hash.s:93
93          ldr            q2,[x0,#16*128]
(gdb) s
94          dup            v0.16b,v2.b[0]
(gdb)
96          mov            x1,#0xC200000000000000
(gdb)
97          mov            x2,#1
(gdb)
98          mov            v6.d[0],x1
(gdb)
99          mov            v6.d[1],x2
(gdb)
100         sshr           v0.16b,v0.16b,#7
(gdb)
101         and            v0.16b,v0.16b,v6.16b
(gdb)
102         ushr           v1.2d,v2.2d,#63
(gdb)
103         and            v1.16b,v1.16b,v6.16b
(gdb)
104         ext            v1.16b,v1.16b,v1.16b,#8
(gdb)
105         shl            v2.2d,v2.2d,#1
(gdb)
106         orr            v2.16b,v2.16b,v1.16b
(gdb)
107         eor            v2.16b,v2.16b,v0.16b
(gdb)
109         dup            v6.2d,v6.d[0]
(gdb)
113         PMUL_PARAM v2,v23,v24
            ^--- doesn't seem to expand the macro here
(gdb)
115         PMUL v2,v23,v24
(gdb)
117         REDUCTION v3
(gdb) i r
x0             0x423390            4338576
x1             0xc200000000000000  -4467570830351532032
[...]
x30            0x406c44            4222020
sp             0x4000800ad0        0x4000800ad0
pc             0x40008b6a5c        0x40008b6a5c
&lt;_nettle_gcm_init_key+104&gt;
cpsr           0x80000000          -2147483648
fpsr           0x0                 0
fpcr           0x0                 0

The trick to see and single-step the individual instructions of the
macro seems to be disp/i $pc combined with stepi:

(gdb) disp/i $pc
1: x/i $pc
=&gt; 0x40008b6a30 &lt;_nettle_gcm_init_key+60&gt;:      pmull2  v20.1q, v2.2d,
v6.2d
(gdb) stepi
0x00000040008b6a34      113         PMUL_PARAM v2,v23,v24
1: x/i $pc
=&gt; 0x40008b6a34 &lt;_nettle_gcm_init_key+64&gt;:      ext     v22.16b, v2.16b,
v2.16b, #8
(gdb)
0x00000040008b6a38      113         PMUL_PARAM v2,v23,v24
1: x/i $pc
=&gt; 0x40008b6a38 &lt;_nettle_gcm_init_key+68&gt;:      eor     v22.16b,
v22.16b, v20.16b
(gdb)
0x00000040008b6a3c      113         PMUL_PARAM v2,v23,v24
1: x/i $pc
=&gt; 0x40008b6a3c &lt;_nettle_gcm_init_key+72&gt;:      zip1    v23.2d, v2.2d,
v22.2d

From here I would now continue to compare register contents after each
instruction on LE and BE to see where it's going wrong.

How would you like to proceed? Shall I dig into it or do you want to? :)

BTW: In case you want to build the image yourself, the diff to the
Dockerfile.aarch64[3] is this:

diff --git a/Dockerfile.aarch64 b/Dockerfile.aarch64
index 36af2c5..5b51c17 100644
--- a/Dockerfile.aarch64
+++ b/Dockerfile.aarch64
@@ -41,6 +41,7 @@ RUN br_libc="${BR_LIBC}" ; \
                echo "BR2_TOOLCHAIN_BUILDROOT_${libcopt}=y" ; \
                echo 'BR2_KERNEL_HEADERS_4_19=y' ; \
                echo 'BR2_PACKAGE_GMP=y' ; \
+               echo 'BR2_PACKAGE_HOST_GDB=y' ; \
                echo 'BR2_PER_PACKAGE_DIRECTORIES=y' ; \
        ) &gt; .config &amp;&amp; \
        make olddefconfig &amp;&amp; \
@@ -75,7 +76,7 @@ MAINTAINER Michael Weiser &lt;michael.weiser@gmx.de&gt;
 RUN apt-get update -qq -y &amp;&amp; \
        apt-get dist-upgrade -y &amp;&amp; \
        apt-get autoremove -y &amp;&amp; \
-       apt-get install -y autoconf dash g++ make qemu-user &amp;&amp; \
+       apt-get install -y autoconf dash g++ libncurses6 libexpat1 make
qemu-user &amp;&amp; \
        apt-get clean all &amp;&amp; \
        rm -rf /var/lib/apt/lists/*

[3] https://github.com/michaelweiser-nettle-ci/docker-buildroot/blob/master/Dockerfile.aarch64


The command to build the image is:

podman build -f Dockerfile.aarch64 --build-arg BR_LIBC=glibc -t \
                buildroot:2020.11.1-aarch64_be-glibc-gdb .
-- 
Thanks, Micha
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210118162740</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-18 16:27:40-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hi Michael,

On Wed, Jan 13, 2021 at 8:00 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Out of curiosity as I can't seem to find the beginning of the
&gt; discussion: Is there anyone but me with an actual use-case for
&gt; big-endian arm64 here? If not, I'd hate to cause a lot of effort for you
&gt; and would certainly put in the effort to get this going myself.
&gt;

It would be nice to get the implementation of the enhanced algorithm
working for both endian modes as it yields a good performance boost. Also,
there is no much effort here, the only thing I'm struggling with is to get
the binary built for Aarch64_be, I'm using Ubuntu on x86_64 as host and it
seems there is no official package to cross compile for Aarch64_be.


&gt; &gt; The patch is built on top of the master branch.
&gt;
&gt; First it failed to compile gcm-hash.o with error "No rule to make
&gt; target" which turned out to be caused by a missing arm64/machine.m4.
&gt; After I added an empty file there it compiled fine on aarch64 and the
&gt; testsuite succeeded on the actual hardware as well as under qemu-aarch64
&gt; user mode emulation (both LE).
&gt;
&gt; On aarch64_be it fails to compile with the following error message:
&gt;
&gt; gcm-hash.s:113: Error: unknown mnemonic `zip' -- `zip v23.2d,v2.2d,v22.2d'
&gt; gcm-hash.s:119: Error: unknown mnemonic `zip' -- `zip v25.2d,v3.2d,v22.2d'
&gt; gcm-hash.s:129: Error: unknown mnemonic `zip' -- `zip v27.2d,v4.2d,v22.2d'
&gt; gcm-hash.s:137: Error: unknown mnemonic `zip' -- `zip v29.2d,v5.2d,v22.2d'
&gt;
&gt; This happens with gcc 10.2.0 on my hardware board as well as cross gcc
&gt; 9.3.0 of Buildroot 2020.11.1 in a container.
&gt;
&gt; I did a search of the aarch64 instruction set and saw that there's zip1
&gt; and zip2 instructions. So as a first test I just changed zip to zip1
&gt; which made it compile. As was to be expected, the testsuite failed
&gt; though.
&gt;

You are on the right track so far.


&gt; Before you try and get me up to speed on what the routine is supposed to
&gt; be doing there's also an option for you to get a cross toolchain and
&gt; emulator for your own tests without too much effort. Here's how I
&gt; cross-compile nettle and run the testsuite using rootless podman (docker
&gt; should do just as well) on my x86_64 box:
&gt;
&gt; cd ~/Downloads
&gt; mkdir nettle
&gt; cd nettle
&gt; git clone https://git.lysator.liu.se/nettle/nettle
&gt; cd nettle
&gt; git apply ~/arm64_ghash.patch
&gt; ./.bootstrap
&gt; podman run -it -v ~/Downloads/nettle:/nettle
&gt; michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc-gdb
&gt; cd /nettle/
&gt; mkdir build-aarch64_be
&gt; cd build-aarch64_be/
&gt; ../nettle/configure --host=$(cat /buildroot/triple) --enable-armv8-a-crypto
&gt; make -j4
&gt; make -j4 check EMULATOR=/buildroot/qemu
&gt;

I tried that but I'm having difficulty getting it work, it seems there is a
problem in my system configuration that prevents podman establishing a
socket for connection, I spend some time looking for alternative solutions
with no chance. Do you have any other solutions? all what I can think of is
either setup ssh connection or work together to get it work if you are into
it!

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210119214307</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-19 21:43:07-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Mon, Jan 18, 2021 at 06:27:40PM +0200, Maamoun TK wrote:

&gt; It would be nice to get the implementation of the enhanced algorithm
&gt; working for both endian modes as it yields a good performance boost. Also,
&gt; there is no much effort here, the only thing I'm struggling with is to get
&gt; the binary built for Aarch64_be, I'm using Ubuntu on x86_64 as host and it
&gt; seems there is no official package to cross compile for Aarch64_be.

Yes, there are no packages for aarch64_be in any mainstream distribution
I'm aware of. Buildroot and Gentoo are the ones I know that can target
it, Yocto likely as well. All are compile-yourself-distributions and not
for the faint of heart. Also, I've just learned that Buildroot has made
a concious decision not to produce native toolchains for the target. So
you can only ever cross-compile nettle to it, run it on an actual board
or under qemu and then go back to the cross-compiler on the host.

&gt; &gt; I did a search of the aarch64 instruction set and saw that there's zip1
&gt; &gt; and zip2 instructions. So as a first test I just changed zip to zip1
&gt; &gt; which made it compile. As was to be expected, the testsuite failed
&gt; &gt; though.
&gt; &gt; 
&gt; You are on the right track so far.

I've poked at the code a bit more and seemingly made the key init
function work by eliminiating all the BE specific macros and instead
adjusting the load from memory to produce the same register content. At
least register values and the final output to memory look the same in
an x/64xb $x0-64 and x64/xb $x0 for the first test cases in gcm-test
(which they did not before).

137         PMUL_PARAM v5,v29,v30
(gdb)
139         st1            {v27.16b,v28.16b,v29.16b,v30.16b},[x0]
(gdb)
141         ret
(gdb) x/64xb $x0-64
0xaaaaaaac5390: 0x77    0x58    0x14    0xdf    0xa9    0x97    0xd2    0xcd
[.. all the same on BE and LE ...]
0xaaaaaaac53c8: 0x0d    0x12    0x63    0x69    0x37    0x20    0xd3    0xfe
(gdb) x/64xb $x0
0xaaaaaaac53d0: 0xf9    0xfa    0x22    0xc3    0x02    0xe7    0x95    0x86
[.. all the same on BE and LE ...]
0xaaaaaaac5408: 0x45    0x91    0xbd    0x48    0x73    0xd9    0x8b    0x5c
(gdb)

The problem here once more seems to be that after a 128bit LE load which
is later used as two 64bit operands, not only the bytes of the operands
are reversed (which you already counter by rev64'ing them, I gather) but
the operands (doublewords) also end up transposed in the register. This
is something the rest of the routine expects but is only true on LE. So
I adjusted for it on BE in a very pedestrian way:

diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
index 1c14db54..74cd656a 100644
--- a/arm64/v8/gcm-hash.asm
+++ b/arm64/v8/gcm-hash.asm
@@ -55,17 +55,10 @@ C common macros:
 .endm

 .macro REDUCTION out
-IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
-    ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
-',`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
-')
 .endm

     C void gcm_init_key (union gcm_block *table)
@@ -108,19 +101,11 @@ define(`H4M', `v29')
 define(`H4L', `v30')

 .macro PMUL_PARAM in, param1, param2
-IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    ext            Hm.16b,\in\().16b,\in\().16b,#8
-    eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
-',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b
     ext            \param1\().16b,Hm.16b,\in\().16b,#8
     ext            \param2\().16b,\in\().16b,Hm.16b,#8
     ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-')
 .endm

 PROLOGUE(_nettle_gcm_init_key)
@@ -128,6 +113,10 @@ PROLOGUE(_nettle_gcm_init_key)
     dup            EMSB.16b,H.b[0]
 IF_LE(`
     rev64          H.16b,H.16b
+',`
+    mov            x1,H.d[0]
+    mov            H.d[0],H.d[1]
+    mov            H.d[1],x1
 ')
     mov            x1,#0xC200000000000000
     mov            x2,#1

If my understanding is correct, we could avoid the doubleword swap for
both LE and BE if we were to load using ld1 to {H.b16} instead (with a
precalculation of the offset because ld1 won't take an immediate offset
that high, correct?). But then the rest of the routine would need to
change its expectation what H.d[0] and H.d[1] contain, respectively,
because they will no longer be transposed by neither the load on LE nor
an explicit swap on BE.

Somehow I have a feeling, I'm terribly missing the actual point here,
though. Are the zip instructions likely to give even further speedup
beyond the LE version? Could this be exploited for LE as well by
adjusting the loading scheme even more?

Also, it's not fully working yet. Before digging deeper I wanted to give
a bit of an update and get guidance as to how to proceed.

&gt; &gt; podman run -it -v ~/Downloads/nettle:/nettle
&gt; I tried that but I'm having difficulty getting it work, it seems there is a
&gt; problem in my system configuration that prevents podman establishing a
&gt; socket for connection, I spend some time looking for alternative solutions
&gt; with no chance. Do you have any other solutions? all what I can think of is
&gt; either setup ssh connection or work together to get it work if you are into
&gt; it!

I mulled this over from all directions. Access to the actual board is
somewhat complicated by the limits of my available Internet connections
(CGNAT being one, missing DMZ functionality on the routers another). It
can certainly be done, I just would need some time to set it up.

But I have made the cross-compiling and -debugging setup of the
container available on a vserver on the Net. Send me a mail directly
with an SSH ID public key if you'd like to try this out and I'll send
you instructions for login and use. We could meet up there in a
tmux/screen session and work on it together as well.

I have also tried to extract the buildroot toolchain from the image and
run it on my Gentoo box as well as Debian. It even seems relocatable, so
you can just put it anywhere and add it to PATH and it'll work. If you
want, I can put a tarball with the toolchain and qemu wrappers up on a
web server somewhere for you to grab. (I just thought, a container image
would be the easier delivery method nowadays. :)

Otherwise, what's your error message from podman? It's got no deamon, so
it shouldn't need a socket to connect to it like docker does. Out to the
Internet for image download it's also a standard client and respects
environment variables for proxies as usual.

rootless podman (running as your standard user instead of root) can take a
bit of tweaking before it stops throwing error messages but once that's
done it works nicely. I've never actually run podman as root by luck of
late birth with regards to containers.

Here's my command sequence on a Ubuntu 20.04 VM that's never seen
rootless podman before as per
https://www.vultr.com/docs/how-to-install-and-use-podman-on-ubuntu-20-04
(literally the first hit on search, can't vouch for the packages from
opensuse though):

michael@demo:~$ podman

Command 'podman' not found, did you mean:

  command 'pod2man' from deb perl (5.30.0-9ubuntu0.2)

Try: sudo apt install &lt;deb name&gt;

michael@demo:~$ source /etc/os-release
michael@demo:~$ sudo sh -c "echo 'deb \
http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/ \
/' &gt; /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list" michael@demo:~$ \
wget -nv https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/xUbuntu_${VERSION_ID}/Release.key \
-O- | sudo apt-key add - 2021-01-19 21:13:19
URL:https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_20.04/Release.key
 [1093/1093] -&gt; "-" [1]
OK
michael@demo:~$ sudo apt-get update -qq
michael@demo:~$ sudo apt-get -qq --yes install podman fuse-overlayfs slirp4netns
[...]
michael@demo:~$ podman run -it \
michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc-gdb Completed short name \
"michaelweisernettleci/buildroot" with unqualified-search registries (origin: \
/etc/containers/registries.conf) Trying to pull
docker.io/michaelweisernettleci/buildroot:2020.11.1-aarch64_be-glibc-gdb...
Getting image source signatures
Copying blob 6c33745f49b4 done
Copying blob ff35d554f2d5 done
Copying blob 3927b287d6b9 done
Copying blob 6bbc022f227c done
Copying config 21663e44fe done
Writing manifest to image destination
Storing signatures
root@06e70f1e12e4:/# aarch64_be-buildroot-linux-gnu-gcc -v
Using built-in specs.
COLLECT_GCC=/buildroot/output/host/bin/aarch64_be-buildroot-linux-gnu-gcc.br_real
COLLECT_LTO_WRAPPER=/buildroot/output/host/bin/../libexec/gcc/aarch64_be-buildroot-linux-gnu/9.3.0/lto-wrapper
                
Target: aarch64_be-buildroot-linux-gnu
Configured with: ./configure
--prefix=/buildroot/output/per-package/host-gcc-final/host
[...]
--enable-shared --disable-libgomp --silent
Thread model: posix
gcc version 9.3.0 (Buildroot 2020.11.1)
root@06e70f1e12e4:/# git clone https://git.lysator.liu.se/nettle/nettle
bash: git: command not found
root@06e70f1e12e4:/# apt-get update
Get:1 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]
Get:2 http://deb.debian.org/debian buster InRelease [121 kB]
[...]
root@06e70f1e12e4:/# apt-get install git
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following additional packages will be installed:
  ca-certificates git-man krb5-locales less libbsd0 libcurl3-gnutls
[...]
root@06e70f1e12e4:/# git clone https://git.lysator.liu.se/nettle/nettle
Cloning into 'nettle'...
warning: redirecting to https://git.lysator.liu.se/nettle/nettle.git/
remote: Enumerating objects: 721, done.
remote: Counting objects: 100% (721/721), done.
remote: Compressing objects: 100% (349/349), done.
remote: Total 21095 (delta 479), reused 593 (delta 372), pack-reused 20374
Receiving objects: 100% (21095/21095), 5.90 MiB | 3.47 MiB/s, done.
Resolving deltas: 100% (15748/15748), done.
root@06e70f1e12e4:/#

That was a lot easier than even I expected. Necessary stuff like entries
in /etc/subuid are automatically added by useradd as standard nowadays
without podman even being installed:

michael@demo:~$ cat /etc/subuid
michael:100000:65536

Hope that helps.

If all else fails and it's not too trying for your patience I'm up for
making it work iteratively by trial, error and discussion as above. ;)
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210120202519</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-20 20:25:19-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Michael,

On Tue, Jan 19, 2021 at 11:45 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Yes, there are no packages for aarch64_be in any mainstream distribution
&gt; I'm aware of. Buildroot and Gentoo are the ones I know that can target
&gt; it, Yocto likely as well. All are compile-yourself-distributions and not
&gt; for the faint of heart. Also, I've just learned that Buildroot has made
&gt; a concious decision not to produce native toolchains for the target. So
&gt; you can only ever cross-compile nettle to it, run it on an actual board
&gt; or under qemu and then go back to the cross-compiler on the host.
&gt; 

I'm trying to install Gentoo on VMware by walking through this receip
https://medium.com/@steensply/vmware-installation-of-gentoo-linux-from-scratch-on-an-encrypted-partition-9e4665f638e2
 I'm in the middle of receip now but there a lot of instruction there so I'm
gonna get the os working in the end.


&gt; 
&gt; &gt; &gt; I did a search of the aarch64 instruction set and saw that there's zip1
&gt; &gt; &gt; and zip2 instructions. So as a first test I just changed zip to zip1
&gt; &gt; &gt; which made it compile. As was to be expected, the testsuite failed
&gt; &gt; &gt; though.
&gt; &gt; &gt; 
&gt; &gt; You are on the right track so far.
&gt; 
&gt; I've poked at the code a bit more and seemingly made the key init
&gt; function work by eliminiating all the BE specific macros and instead
&gt; adjusting the load from memory to produce the same register content. At
&gt; least register values and the final output to memory look the same in
&gt; an x/64xb $x0-64 and x64/xb $x0 for the first test cases in gcm-test
&gt; (which they did not before).
&gt; 
&gt; 137         PMUL_PARAM v5,v29,v30
&gt; (gdb)
&gt; 139         st1            {v27.16b,v28.16b,v29.16b,v30.16b},[x0]
&gt; (gdb)
&gt; 141         ret
&gt; (gdb) x/64xb $x0-64
&gt; 0xaaaaaaac5390: 0x77    0x58    0x14    0xdf    0xa9    0x97    0xd2
&gt; 0xcd
&gt; [.. all the same on BE and LE ...]
&gt; 0xaaaaaaac53c8: 0x0d    0x12    0x63    0x69    0x37    0x20    0xd3
&gt; 0xfe
&gt; (gdb) x/64xb $x0
&gt; 0xaaaaaaac53d0: 0xf9    0xfa    0x22    0xc3    0x02    0xe7    0x95
&gt; 0x86
&gt; [.. all the same on BE and LE ...]
&gt; 0xaaaaaaac5408: 0x45    0x91    0xbd    0x48    0x73    0xd9    0x8b
&gt; 0x5c
&gt; (gdb)
&gt; 

Here how I get the vector instruction operate on registers in LE mode, i'll
take this instruction as example: pmull  v0.1q,v1.1d,v2.1d
Input represented as indexes
v1: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
v2: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
the instruction byte-reverse each of 64-bit parts of register so the
instruction consider the register as follow
v1: 7 6 5 4 3 2 1 0 15 14 13 12 11 10 9 8
v2: 7 6 5 4 3 2 1 0 15 14 13 12 11 10 9 8
so what I did in LE mode is reverse the 64-bit parts before execute the
doublework operation using rev64 instruction, according to that the pmull
output will be 128-bit byte-reversed
Output represented as indexes
v0: 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0

What I'm assuming in BE mode is operations are performed in normal way in
registers side so no need to reverse the inputs in addition to get normal
output hence the macros "REDUCTION" and "PMUL_PARAM" have differences in
their structure, it's not matter of zip instruction perform better but how
to handle the weird situation in LE mode.


&gt; The problem here once more seems to be that after a 128bit LE load which
&gt; is later used as two 64bit operands, not only the bytes of the operands
&gt; are reversed (which you already counter by rev64'ing them, I gather) but
&gt; the operands (doublewords) also end up transposed in the register. This
&gt; is something the rest of the routine expects but is only true on LE. So
&gt; I adjusted for it on BE in a very pedestrian way:
&gt; 
&gt; diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
&gt; index 1c14db54..74cd656a 100644
&gt; --- a/arm64/v8/gcm-hash.asm
&gt; +++ b/arm64/v8/gcm-hash.asm
&gt; @@ -55,17 +55,10 @@ C common macros:
&gt; .endm
&gt; 
&gt; .macro REDUCTION out
&gt; -IF_BE(`
&gt; -    pmull          T.1q,F.1d,POLY.1d
&gt; -    ext            \out\().16b,F.16b,F.16b,#8
&gt; -    eor            R.16b,R.16b,T.16b
&gt; -    eor            \out\().16b,\out\().16b,R.16b
&gt; -',`
&gt; pmull          T.1q,F.1d,POLY.1d
&gt; eor            R.16b,R.16b,T.16b
&gt; ext            R.16b,R.16b,R.16b,#8
&gt; eor            \out\().16b,F.16b,R.16b
&gt; -')
&gt; .endm
&gt; 
&gt; C void gcm_init_key (union gcm_block *table)
&gt; @@ -108,19 +101,11 @@ define(`H4M', `v29')
&gt; define(`H4L', `v30')
&gt; 
&gt; .macro PMUL_PARAM in, param1, param2
&gt; -IF_BE(`
&gt; -    pmull2         Hp.1q,\in\().2d,POLY.2d
&gt; -    ext            Hm.16b,\in\().16b,\in\().16b,#8
&gt; -    eor            Hm.16b,Hm.16b,Hp.16b
&gt; -    zip            \param1\().2d,\in\().2d,Hm.2d
&gt; -    zip2           \param2\().2d,\in\().2d,Hm.2d
&gt; -',`
&gt; pmull2         Hp.1q,\in\().2d,POLY.2d
&gt; eor            Hm.16b,\in\().16b,Hp.16b
&gt; ext            \param1\().16b,Hm.16b,\in\().16b,#8
&gt; ext            \param2\().16b,\in\().16b,Hm.16b,#8
&gt; ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
&gt; -')
&gt; .endm
&gt; 
&gt; PROLOGUE(_nettle_gcm_init_key)
&gt; @@ -128,6 +113,10 @@ PROLOGUE(_nettle_gcm_init_key)
&gt; dup            EMSB.16b,H.b[0]
&gt; IF_LE(`
&gt; rev64          H.16b,H.16b
&gt; +',`
&gt; +    mov            x1,H.d[0]
&gt; +    mov            H.d[0],H.d[1]
&gt; +    mov            H.d[1],x1
&gt; ')
&gt; mov            x1,#0xC200000000000000
&gt; mov            x2,#1
&gt; 
&gt; If my understanding is correct, we could avoid the doubleword swap for
&gt; both LE and BE if we were to load using ld1 to {H.b16} instead (with a
&gt; precalculation of the offset because ld1 won't take an immediate offset
&gt; that high, correct?). But then the rest of the routine would need to
&gt; change its expectation what H.d[0] and H.d[1] contain, respectively,
&gt; because they will no longer be transposed by neither the load on LE nor
&gt; an explicit swap on BE.
&gt; 
&gt; Somehow I have a feeling, I'm terribly missing the actual point here,
&gt; though. Are the zip instructions likely to give even further speedup
&gt; beyond the LE version? Could this be exploited for LE as well by
&gt; adjusting the loading scheme even more?
&gt; 

If my assumption about how instruction operates in BE mode is right so yes
this is not the actual point.


&gt; But I have made the cross-compiling and -debugging setup of the
&gt; container available on a vserver on the Net. Send me a mail directly
&gt; with an SSH ID public key if you'd like to try this out and I'll send
&gt; you instructions for login and use. We could meet up there in a
&gt; tmux/screen session and work on it together as well.
&gt; 

Let's try the second solution before we get to this.


&gt; I have also tried to extract the buildroot toolchain from the image and
&gt; run it on my Gentoo box as well as Debian. It even seems relocatable, so
&gt; you can just put it anywhere and add it to PATH and it'll work. If you
&gt; want, I can put a tarball with the toolchain and qemu wrappers up on a
&gt; web server somewhere for you to grab. (I just thought, a container image
&gt; would be the easier delivery method nowadays. :)
&gt; 

I would like to try this method in case my gentoo installation failed or
just been easier to extract your uploaded packages and add it to PATH.
Update: while I'm writing this message I got: no space left of device. It
seems I set low numbers while partitioning the device. Let's try the above
method before I start over to install gentoo.


&gt; Otherwise, what's your error message from podman? It's got no deamon, so
&gt; it shouldn't need a socket to connect to it like docker does. Out to the
&gt; Internet for image download it's also a standard client and respects
&gt; environment variables for proxies as usual.
&gt; 
&gt; 
I got Error: error creating network namespace for container. I think I can
fix it by tracing the problem but let's try the other methods first as I
think it's gonna be simpler for me..

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210121152457</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-21 15:24:57-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Jan 5, 2021 at 5:52 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; On Tue, Jan 5, 2021 at 3:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; &gt; I wonder which assembly files we should use if target host is aarch64,
&gt;&gt; &gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt;&gt; &gt; we also use arm/neon/ code unconditionally?
&gt;&gt;
&gt;&gt; The reference manual says
&gt;&gt;
&gt;&gt; Armv8 can support the following levels of support for Advanced SIMD and
&gt;&gt; floating-point instructions:
&gt;&gt;
&gt;&gt; *    Full SIMD and floating-point support without exception trapping.
&gt;&gt;
&gt;&gt; *    Full SIMD and floating-point support with exception trapping.
&gt;&gt;
&gt;&gt; *    No floating-point or SIMD support. This option is licensed only for
&gt;&gt;      implementations targeting specialized markets.
&gt;&gt;
&gt;&gt; As far as I understand, that means Neon should be always available, in
&gt;&gt; both 32-bit and 64-bit mode.
&gt;&gt;
&gt;
&gt; I'll investigate how we can build the existing NEON implementations on
&gt; 64-bit systems.
&gt;

I spent some time investigating and testing, it looks like aarch64 gcc can
not handle 32-bit assembly code currently. In order to build 32-bit arm
binaries on 64-bit systems, one has to use 'gcc-arm-linux-gnueabi' or
'gcc-arm-linux-gnueabihf' toolchains, I went through the options available
in aarch64 gcc https://gcc.gnu.org/onlinedocs/gcc/AArch64-Options.html but
none of which allow us to use 32-bit assembly code even '-mabi=ilp32'
doesn't do that as I get the same errors with or without it. I'm afraid
that we need to re-write the 32-bit assembly code in 64-bit format in order
to get those optimizations enabled in 64-bit arm binaries.

regards,
Mamone

On Tue, Jan 5, 2021 at 5:52 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:

&gt; On Tue, Jan 5, 2021 at 3:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; I've made a new branch "arm64" with the configure changes. If you think
&gt;&gt; that looks ok, can you add your new ghash code on top of that?
&gt;&gt;
&gt;
&gt; Great. I'll add the ghash code to the branch once I finish the big-endian
&gt; support.
&gt;
&gt;
&gt;&gt; (It would be good to also
&gt;&gt; get S390x into the ci system, before adding s390x-specific assembly. I
&gt;&gt; hope that should be easy to do with the same cross setup as for arm,
&gt;&gt; arm64, mips, etc).
&gt;&gt;
&gt;
&gt; This is not possible since qemu doesn't support cipher functions, it
&gt; implements subcode 0 (query) without actual encipher/decipher operations,
&gt; take a look here
&gt;
&gt; https://git.qemu.org/?p=qemu.git;a=commit;h=be2b567018d987591647935a7c9648e9c45e05e8
&gt;
&gt;
&gt; I had a talk with David Edelsohn for this issue, I concluded that there is
&gt; no support for cipher functions on qemu and it's unlikely to happen anytime
&gt; soon. However, I updated the testutils to cover the s390x-specific assembly
&gt; so the patch can easily be tested manually by executing 'make check'. I
&gt; also have tested every aspect of this patch to make sure everything will go
&gt; well once it's merged.
&gt;
&gt; &gt; I wonder which assembly files we should use if target host is aarch64,
&gt;&gt; &gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt;&gt; &gt; we also use arm/neon/ code unconditionally?
&gt;&gt;
&gt;&gt; The reference manual says
&gt;&gt;
&gt;&gt; Armv8 can support the following levels of support for Advanced SIMD and
&gt;&gt; floating-point instructions:
&gt;&gt;
&gt;&gt; *    Full SIMD and floating-point support without exception trapping.
&gt;&gt;
&gt;&gt; *    Full SIMD and floating-point support with exception trapping.
&gt;&gt;
&gt;&gt; *    No floating-point or SIMD support. This option is licensed only for
&gt;&gt;      implementations targeting specialized markets.
&gt;&gt;
&gt;&gt; As far as I understand, that means Neon should be always available, in
&gt;&gt; both 32-bit and 64-bit mode.
&gt;&gt;
&gt;
&gt; I'll investigate how we can build the existing NEON implementations on
&gt; 64-bit systems.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210121233259</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-21 23:32:59-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Wed, Jan 20, 2021 at 10:25:19PM +0200, Maamoun TK wrote:

&gt; I'm trying to install Gentoo on VMware by walking through this receip
&gt; https://medium.com/@steensply/vmware-installation-of-gentoo-linux-from-scratch-on-an-encrypted-partition-9e4665f638e2
&gt;  I'm in the middle of receip now but there a lot of instruction there so I'm
&gt; gonna get the os working in the end.

As far as I can tell that recipe only encompasses basic installation.
You'd additionally need to run crossdev to create a cross-toolchain and
then install qemu as well. Gentoo has a very steep learning curve. There's
no benefit compared to buildroot for our use-case here, IMO.

&gt; Here how I get the vector instruction operate on registers in LE mode, i'll
&gt; take this instruction as example: pmull  v0.1q,v1.1d,v2.1d
&gt; Input represented as indexes
&gt; v1: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt; v2: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
&gt; the instruction byte-reverse each of 64-bit parts of register so the
&gt; instruction consider the register as follow
&gt; v1: 7 6 5 4 3 2 1 0 15 14 13 12 11 10 9 8
&gt; v2: 7 6 5 4 3 2 1 0 15 14 13 12 11 10 9 8
&gt; so what I did in LE mode is reverse the 64-bit parts before execute the
&gt; doublework operation using rev64 instruction, according to that the pmull
&gt; output will be 128-bit byte-reversed
&gt; Output represented as indexes
&gt; v0: 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0

&gt; What I'm assuming in BE mode is operations are performed in normal way in
&gt; registers side so no need to reverse the inputs in addition to get normal
&gt; output hence the macros "REDUCTION" and "PMUL_PARAM" have differences in
&gt; their structure, it's not matter of zip instruction perform better but how
&gt; to handle the weird situation in LE mode.

I've tried for a number of hours to make this work today. Always when I
added correct handling of the transposed doublewords to one macro,
another broke down. To me the problem comes down to this: ldr
HQ,[TABLE...] and st1.16b are fighting each other and can't be brought
together without a lot of additional instructions (at least not by me).

Longer story: ldr does a 128bit load. This loads bytes in exactly
reverse order into the register on LE and BE. As you describe above, the
macros for LE expect a state which is neither of those: The bytes
transposed as if BE but the doublewords as loaded on LE. For BE this
poses the oppositve problem: It natively loads bytes in the order LE has
to reproduce using rev64 but then needs to reproduce the doubleword
order of LE for the LE routines to work or basically have native BE
routines.

That's what my last pedestrian change did. After today I'd perhaps write
it like this (untested):

@@ -125,10 +135,12 @@ IF_BE(`

 PROLOGUE(_nettle_gcm_init_key)
     ldr            HQ,[TABLE,#16*H_Idx]
-    dup            EMSB.16b,H.b[0]
 IF_LE(`
     rev64          H.16b,H.16b
+',`
+    ext            H.16b,H.16b,H.16b,#8
 ')
+    dup            EMSB.16b,H.b[7]
     mov            x1,#0xC200000000000000
     mov            x2,#1
     mov            POLY.d[0],x1

When trying to cater to the current layout on LE, all the other vectors
which are later used in conjunction with H to be reversed as well. That
leads to this diff to your initial patch:

@@ -125,14 +135,21 @@ IF_BE(`

 PROLOGUE(_nettle_gcm_init_key)
     ldr            HQ,[TABLE,#16*H_Idx]
-    dup            EMSB.16b,H.b[0]
 IF_LE(`
+    dup            EMSB.16b,H.b[0]
     rev64          H.16b,H.16b
+',`
+    dup            EMSB.16b,H.b[15]
 ')
     mov            x1,#0xC200000000000000
     mov            x2,#1
+IF_LE(`
     mov            POLY.d[0],x1
     mov            POLY.d[1],x2
+',`
+    mov            POLY.d[1],x1
+    mov            POLY.d[0],x2
+')
     sshr           EMSB.16b,EMSB.16b,#7
     and            EMSB.16b,EMSB.16b,POLY.16b
     ushr           B.2d,H.2d,#63
@@ -142,7 +159,11 @@ IF_LE(`
     orr            H.16b,H.16b,B.16b
     eor            H.16b,H.16b,EMSB.16b

+IF_LE(`
     dup            POLY.2d,POLY.d[0]
+',`
+    dup            POLY.2d,POLY.d[1]
+')

     C --- calculate H^2 = H*H ---

The difference in index in dup EMSB nicely shows the doubleword
transposition compared to LE. If on LE the dup was done after the rev64,
it'd be H.b[7] vs. H.b[15].

With this layout PMUL_PARAM can work on H and POLY but then needs to use
pmull instead of pmull2 because the relevant data is in the other
doublewords compared to LE. On the other hand, since the output of
PMUL_PARAM is to be stored using st1.16b it must not have the
doublewords transposed ("load-inverted" I termed it in the comments ;).
That leads to the following adjustment and makes the first 16bytes of
TABLE identical to LE:

@@ -109,11 +118,12 @@ define(`H4L', `v30')

 .macro PMUL_PARAM in, param1, param2
 IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
+    pmull          Hp.1q,\in\().1d,POLY.1d
     ext            Hm.16b,\in\().16b,\in\().16b,#8
     eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
+    C output must be in native register order (not load-inverted) for st1.16b to \
work +    zip2           \param1\().2d,\in\().2d,Hm.2d
+    zip1           \param2\().2d,\in\().2d,Hm.2d
 ',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b

In PMUL is where it breaks down, at least for my brain: Its first call
is handed H (which has doublewords "transposed" from the initial ldr) and
H1M and H1L (which must not have doublewords transposed so st1.16b
writes them to memory in correct order). It wants to pmull/pmull2 them
which requires corresponding doublewords at the same index. So we'd
need to temporarily transpose \in for that:

@@ -46,25 +46,34 @@ define(`R1', `v19')

 C common macros:
 .macro PMUL in, param1, param2
-    pmull          F.1q,\param2\().1d,\in\().1d
-    pmull2         F1.1q,\param2\().2d,\in\().2d
-    pmull          R.1q,\param1\().1d,\in\().1d
-    pmull2         R1.1q,\param1\().2d,\in\().2d
+    C PMUL_PARAM left us with \param1 and \param2 in native register order but
+    C \in is load-inverted from initial load of H using ldr, something must give
+IF_BE(`
+    ext            T.16b,\in\().16b,\in\().16b,#8
+',`
+    mov            T.16b,\in\().16b
+')
+    pmull          F.1q,\param2\().1d,T.1d
+    pmull2         F1.1q,\param2\().2d,T.2d
+    pmull          R.1q,\param1\().1d,T.1d
+    pmull2         R1.1q,\param1\().2d,T.2d
     eor            F.16b,F.16b,F1.16b
     eor            R.16b,R.16b,R1.16b
 .endm

If we finally artificially restore the doubleword transposition in
REDUCE for H2 and H3 we're all set for the next calls:

 .macro REDUCTION out
 IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
     ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
+    pmull2         T.1q,\out\().2d,POLY.2d
 ',`
     pmull          T.1q,F.1d,POLY.1d
+')
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
+C artificially restore load inversion for PMUL_PARAM :-(
+IF_BE(`
+    ext            \out\().16b,\out\().16b,\out\().16b,#8
 ')
 .endm

So all we're doing is catering to the quirk of the very first ldr
operation. The easiest solution seems to me to align all types of load
and store operations with each other or counteract their quirks right
after or before executing them. That way we end up with identical
register contents on LE and BE and don't have to maintain separate
implementations.

That'd be in line with what we ended up with on arm32 NEON as well.
memxor3.asm does do the dance of working with different register content
but there it's only bitwise operations and the load and store operations
have identical behaviour.

The advantage of the current implementation with transposed doublewords
and only the LE routines seems to me that overhead on LE and BE would
be about the same.

Do you think it makes sense to try and adjust the code to work with the
BE layout natively and have a full 128bit reverse after ldr-like loads
on LE instead (considering that 99,999% of aarch64 users will run LE)?

&gt; &gt; Otherwise, what's your error message from podman? It's got no deamon, so
&gt; &gt; it shouldn't need a socket to connect to it like docker does. Out to the
&gt; &gt; Internet for image download it's also a standard client and respects
&gt; &gt; environment variables for proxies as usual.
&gt; &gt; 
&gt; &gt; 
&gt; I got Error: error creating network namespace for container. I think I can
&gt; fix it by tracing the problem but let's try the other methods first as I
&gt; think it's gonna be simpler for me..

I found this error on the Net in conjunction with a Debian/Ubuntu
security-related custom kernel knob for disabling unprivileged user
namespaces that was enabled by default once. I tested that with Ubuntu
18.04, 20.04 and 20.10 yesterday and it's disabled (i.e. namespaces for
unprivileged users enabled) on all of them. You can still have a look at
your setting in /proc/sys/kernel/unprivileged_userns_clone or with
sysctl kernel.unprivileged_userns_clone. It needs to be set to 1 for
rootless podman to work.

You're not by any chance running the Windows Subsystem for Linux (WSL)?
https://github.com/containers/podman/issues/3288#issuecomment-501356136 :)

Or inside another container at a hosting service?
https://github.com/containers/podman/issues/4056

Otherwise I have no idea what could be causing that and have never seen
that error.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210122201436</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-22 20:14:36-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Fri, Jan 22, 2021 at 1:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Longer story: ldr does a 128bit load. This loads bytes in exactly
&gt; reverse order into the register on LE and BE. As you describe above, the
&gt; macros for LE expect a state which is neither of those: The bytes
&gt; transposed as if BE but the doublewords as loaded on LE. For BE this
&gt; poses the oppositve problem: It natively loads bytes in the order LE has
&gt; to reproduce using rev64 but then needs to reproduce the doubleword
&gt; order of LE for the LE routines to work or basically have native BE
&gt; routines.
&gt;
&gt; That's what my last pedestrian change did. After today I'd perhaps write
&gt; it like this (untested):
&gt;
&gt; @@ -125,10 +135,12 @@ IF_BE(`
&gt;
&gt;  PROLOGUE(_nettle_gcm_init_key)
&gt;      ldr            HQ,[TABLE,#16*H_Idx]
&gt; -    dup            EMSB.16b,H.b[0]
&gt;  IF_LE(`
&gt;      rev64          H.16b,H.16b
&gt; +',`
&gt; +    ext            H.16b,H.16b,H.16b,#8
&gt;  ')
&gt; +    dup            EMSB.16b,H.b[7]
&gt;      mov            x1,#0xC200000000000000
&gt;      mov            x2,#1
&gt;      mov            POLY.d[0],x1
&gt;
&gt; When trying to cater to the current layout on LE, all the other vectors
&gt; which are later used in conjunction with H to be reversed as well. That
&gt; leads to this diff to your initial patch:
&gt;
&gt; @@ -125,14 +135,21 @@ IF_BE(`
&gt;
&gt;  PROLOGUE(_nettle_gcm_init_key)
&gt;      ldr            HQ,[TABLE,#16*H_Idx]
&gt; -    dup            EMSB.16b,H.b[0]
&gt;  IF_LE(`
&gt; +    dup            EMSB.16b,H.b[0]
&gt;      rev64          H.16b,H.16b
&gt; +',`
&gt; +    dup            EMSB.16b,H.b[15]
&gt;  ')
&gt;      mov            x1,#0xC200000000000000
&gt;      mov            x2,#1
&gt; +IF_LE(`
&gt;      mov            POLY.d[0],x1
&gt;      mov            POLY.d[1],x2
&gt; +',`
&gt; +    mov            POLY.d[1],x1
&gt; +    mov            POLY.d[0],x2
&gt; +')
&gt;      sshr           EMSB.16b,EMSB.16b,#7
&gt;      and            EMSB.16b,EMSB.16b,POLY.16b
&gt;      ushr           B.2d,H.2d,#63
&gt; @@ -142,7 +159,11 @@ IF_LE(`
&gt;      orr            H.16b,H.16b,B.16b
&gt;      eor            H.16b,H.16b,EMSB.16b
&gt;
&gt; +IF_LE(`
&gt;      dup            POLY.2d,POLY.d[0]
&gt; +',`
&gt; +    dup            POLY.2d,POLY.d[1]
&gt; +')
&gt;
&gt;      C --- calculate H^2 = H*H ---
&gt;
&gt; The difference in index in dup EMSB nicely shows the doubleword
&gt; transposition compared to LE. If on LE the dup was done after the rev64,
&gt; it'd be H.b[7] vs. H.b[15].
&gt;

I see what you did here, but I'm confused about ld1 and st1 instructions so
let me clarify one thing before going on, how do ld1 and st1 load and store
from/into memory in BE mode? If they perform in a normal way then there is
no point of using ldr at all, I just used it because it handles imm offset.
so to replace this line "ldr HQ,[TABLE,#16*H_Idx]" we can just add the
offset to the register that hold the address "add x1,TABLE,#16*H_Idx" then
load the H value by using ld1 "ld1 {H.16b},[x1]" in this way we can still
have to deal with LE as transposed doublewords and with BE in normal way
(not transposed doublewords or transposed quadword).

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210122224839</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-22 22:48:39-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Fri, Jan 22, 2021 at 1:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Do you think it makes sense to try and adjust the code to work with the
&gt; BE layout natively and have a full 128bit reverse after ldr-like loads
&gt; on LE instead (considering that 99,999% of aarch64 users will run LE)?
&gt;

If you don't have a use-case we can suspend big-endian support of GCM
optimization on aarch64 until we get a request, use case or maybe
aarch64_be get more support in the future by main distributions.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210123000746</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-01-23 00:07:46-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Fri, Jan 22, 2021 at 5:48 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; On Fri, Jan 22, 2021 at 1:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt; wrote:
&gt;
&gt; &gt; Do you think it makes sense to try and adjust the code to work with the
&gt; &gt; BE layout natively and have a full 128bit reverse after ldr-like loads
&gt; &gt; on LE instead (considering that 99,999% of aarch64 users will run LE)?
&gt; &gt;
&gt;
&gt; If you don't have a use-case we can suspend big-endian support of GCM
&gt; optimization on aarch64 until we get a request, use case or maybe
&gt; aarch64_be get more support in the future by main distributions.

+1. At minimum, someone needs to produce an image to load on a
commodity board. If there are no images for a common board then
there's no demand in the market. There's no reason to jump through
hoops, like qemu, to solve a problem that does not exist.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210123003641</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-23 00:36:41-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Fri, Jan 22, 2021 at 10:14:36PM +0200, Maamoun TK wrote:

&gt; &gt; The difference in index in dup EMSB nicely shows the doubleword
&gt; &gt; transposition compared to LE. If on LE the dup was done after the rev64,
&gt; &gt; it'd be H.b[7] vs. H.b[15].
&gt; I see what you did here, but I'm confused about ld1 and st1 instructions so
&gt; let me clarify one thing before going on, how do ld1 and st1 load and store
&gt; from/into memory in BE mode? If they perform in a normal way then there is
&gt; no point of using ldr at all, I just used it because it handles imm offset.
&gt; so to replace this line "ldr HQ,[TABLE,#16*H_Idx]" we can just add the
&gt; offset to the register that hold the address "add x1,TABLE,#16*H_Idx" then

I've just retested and reread some ARM documents. Here's a patch that
uses ld1.16b and thus eliminates almost all special BE treatment but
subsequently has to leave in all the rev64s as well. This has the
testsuite passing on BE and (still) LE. My take at an explanation below.

diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
index 1c14db54..8c8a370e 100644
--- a/arm64/v8/gcm-hash.asm
+++ b/arm64/v8/gcm-hash.asm
@@ -55,17 +55,10 @@ C common macros:
 .endm
 
 .macro REDUCTION out
-IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
-    ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
-',`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
-')
 .endm
 
     C void gcm_init_key (union gcm_block *table)
@@ -108,27 +101,20 @@ define(`H4M', `v29')
 define(`H4L', `v30')
 
 .macro PMUL_PARAM in, param1, param2
-IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    ext            Hm.16b,\in\().16b,\in\().16b,#8
-    eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
-',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b
     ext            \param1\().16b,Hm.16b,\in\().16b,#8
     ext            \param2\().16b,\in\().16b,Hm.16b,#8
     ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-')
 .endm
 
 PROLOGUE(_nettle_gcm_init_key)
-    ldr            HQ,[TABLE,#16*H_Idx]
+    C LSB vector load: x1+0 into H.b[0] and x1+15 into H.b[15]
+    add            x1,TABLE,#16*H_Idx
+    ld1            {H.16b},[x1]
     dup            EMSB.16b,H.b[0]
-IF_LE(`
+    C treat H as two MSB doublewords
     rev64          H.16b,H.16b
-')
     mov            x1,#0xC200000000000000
     mov            x2,#1
     mov            POLY.d[0],x1
@@ -221,9 +207,7 @@ PROLOGUE(_nettle_gcm_hash)
     mov            POLY.d[0],x4
 
     ld1            {D.16b},[X]
-IF_LE(`
     rev64          D.16b,D.16b
-')
 
     ands           x4,LENGTH,#-64
     b.eq           L2x
@@ -234,12 +218,10 @@ IF_LE(`
 
 L4x_loop:
     ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
-IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
     rev64          C2.16b,C2.16b
     rev64          C3.16b,C3.16b
-')
 
     eor            C0.16b,C0.16b,D.16b
 
@@ -262,10 +244,8 @@ L2x:
     ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
 
     ld1            {C0.16b,C1.16b},[DATA],#32
-IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
-')
 
     eor            C0.16b,C0.16b,D.16b
 
@@ -283,9 +263,7 @@ L1x:
     ld1            {H1M.16b,H1L.16b},[TABLE]
 
     ld1            {C0.16b},[DATA],#16
-IF_LE(`
     rev64          C0.16b,C0.16b
-')
 
     eor            C0.16b,C0.16b,D.16b
 
@@ -335,9 +313,7 @@ Lmod_8_done:
     REDUCTION D
 
 Ldone:
-IF_LE(`
     rev64          D.16b,D.16b
-')
     st1            {D.16b},[X]
     ret
 EPILOGUE(_nettle_gcm_hash)

My understanding is that ld1 and st1 are "single-element structure"
operations. (Identical to vld1 in arm32 NEON we discussed recently for
chacha and salsa2 asm.) That means they load a number of elements of a
given type from consecutive memory locations into the corresponding
vector register indices.

ld1 {v0.4s},[x0] would load four 32bit words from consecutive memory
locations and put them into v0.s[0] through v0.s[3]. So x0+0..3 (bytes)
would go into v0.s[0], x0+4..7 would to into v0.s[1] and so on.
Endianness would apply to the internal byte order of the elements, so
each word would be loaded MSB-first in BE-mode and LSB-first in LE-mode.

So, given memory content such as:

x0 + 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
byte 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

We should get on BE:

         MSB     LSB
v0.s[0]:     0 1 2 3
v0.s[1]:     4 5 6 7
v0.s[2]:   8 9 10 11
v0.s[3]: 12 13 14 15

Or looked at as byte-vectors:

        |v0.s[0]|v0.s[1]| v0.s[2] | v0.s[3]  |
      v0.b[0]                             v0.b[15]
v0.16b:  3 2 1 0 7 6 5 4 11 10 9 8 15 14 13 12

On LE we should get:

         MSB     LSB
v0.d[0]:     3 2 1 0
v0.d[1]:     7 6 5 4
v0.d[2]:   11 10 9 8
v0.d[3]: 15 14 13 12

      v0.b[0]                             v0.b[15]
v0.16b: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

This was just meant as intro. I've not actually tested this. I hope I
got it right and not just added to everyone's confusion (mine included).
:/

Back to ld1.16b: This now loads a vector of 16 bytes consecutively.
Since bytes have no endianness there will be no changes in order on
either LE and BE modes. The register content will look the same on both:

x0 +    0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
byte:   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
    v0.b[0]                             v0.b[15]
v0.16b: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

So larger datatypes loaded that way should be stored little-endian in
memory to make sense as e.g. .d[0] after such a load. Or we need to
rev64 them.

&gt; load the H value by using ld1 "ld1 {H.16b},[x1]" in this way we can still
&gt; have to deal with LE as transposed doublewords and with BE in normal way
&gt; (not transposed doublewords or transposed quadword).

After sending my last email I realised that the doublewords aren't
actually transposed with BE as such. They're just transposed compared to
the original LE routine because the ldr instruction loads in completely
reversed order in each mode and the LE routine does convert the internal
byte order of the doublewords to BE but not the overall order of the
128bit quadword because it doesn't need to and regards them as a
vector of two doublewords anyway.

ld1.16b doesn't change that at all. It just behaves the same on LE and
BE. So we'll always load vectors of bytes. And it'll always be an LSB
load. And if we want to treat them as big-endian doublewords we have to
adjust them accordingly. That's why we now also need all the rev64s on
BE above.

That opens another topic: As you may have noticed I haven't got the
slightest idea of what the code is actually doing. Assembly also isn't
my first language either. I'm only mechanically trying to get BE mode to
produce the same results as LE.

This made me realise that I haven't the faintest idea what we're getting
as input and producing as output either. :/ So are we working on blocks
of bytes and producing blocks of bytes and just treating them as
big-endian 64bit doublewords internally to exploit availability of
instructions that can work on these types or could we actually declare
the elements of TABLE to be quadwords in host endianness? Then we could
actually throw ld1.2d at them and eliminate all the rev64s.

Duh, I think we can regardless, at least for BE:

diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
index 1c14db54..642e3840 100644
--- a/arm64/v8/gcm-hash.asm
+++ b/arm64/v8/gcm-hash.asm
@@ -55,17 +55,10 @@ C common macros:
 .endm
 
 .macro REDUCTION out
-IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
-    ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
-',`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
-')
 .endm
 
     C void gcm_init_key (union gcm_block *table)
@@ -108,27 +101,20 @@ define(`H4M', `v29')
 define(`H4L', `v30')
 
 .macro PMUL_PARAM in, param1, param2
-IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    ext            Hm.16b,\in\().16b,\in\().16b,#8
-    eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
-',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b
     ext            \param1\().16b,Hm.16b,\in\().16b,#8
     ext            \param2\().16b,\in\().16b,Hm.16b,#8
     ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-')
 .endm
 
 PROLOGUE(_nettle_gcm_init_key)
-    ldr            HQ,[TABLE,#16*H_Idx]
-    dup            EMSB.16b,H.b[0]
+    add            x1,TABLE,#16*H_Idx
+    ld1            {H.2d},[x1]
 IF_LE(`
     rev64          H.16b,H.16b
 ')
+    dup            EMSB.16b,H.b[7]
     mov            x1,#0xC200000000000000
     mov            x2,#1
     mov            POLY.d[0],x1
@@ -220,7 +206,7 @@ PROLOGUE(_nettle_gcm_hash)
     mov            x4,#0xC200000000000000
     mov            POLY.d[0],x4
 
-    ld1            {D.16b},[X]
+    ld1            {D.2d},[X]
 IF_LE(`
     rev64          D.16b,D.16b
 ')
@@ -233,7 +219,7 @@ IF_LE(`
     ld1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[x5]
 
 L4x_loop:
-    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
+    ld1            {C0.2d,C1.2d,C2.2d,C3.2d},[DATA],#64
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -261,7 +247,7 @@ L2x:
 
     ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
 
-    ld1            {C0.16b,C1.16b},[DATA],#32
+    ld1            {C0.2d,C1.2d},[DATA],#32
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -282,7 +268,7 @@ L1x:
 
     ld1            {H1M.16b,H1L.16b},[TABLE]
 
-    ld1            {C0.16b},[DATA],#16
+    ld1            {C0.2d},[DATA],#16
 IF_LE(`
     rev64          C0.16b,C0.16b
 ')
@@ -335,9 +321,7 @@ Lmod_8_done:
     REDUCTION D
 
 Ldone:
-IF_LE(`
     rev64          D.16b,D.16b
-')
     st1            {D.16b},[X]
     ret
 EPILOGUE(_nettle_gcm_hash)

Please excuse my laboured and longwinded thinking. ;) I really have to
start thinking in vectors also.

This also works for the whole TABLE and gives host-endianness storage
there (where ld1.16b should have caused it to be little-endian before,
if that's at all relevant):

diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
index 1c14db54..bd6820b3 100644
--- a/arm64/v8/gcm-hash.asm
+++ b/arm64/v8/gcm-hash.asm
@@ -55,17 +55,10 @@ C common macros:
 .endm
 
 .macro REDUCTION out
-IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
-    ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
-',`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
-')
 .endm
 
     C void gcm_init_key (union gcm_block *table)
@@ -108,27 +101,20 @@ define(`H4M', `v29')
 define(`H4L', `v30')
 
 .macro PMUL_PARAM in, param1, param2
-IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    ext            Hm.16b,\in\().16b,\in\().16b,#8
-    eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
-',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b
     ext            \param1\().16b,Hm.16b,\in\().16b,#8
     ext            \param2\().16b,\in\().16b,Hm.16b,#8
     ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-')
 .endm
 
 PROLOGUE(_nettle_gcm_init_key)
-    ldr            HQ,[TABLE,#16*H_Idx]
-    dup            EMSB.16b,H.b[0]
+    add            x1,TABLE,#16*H_Idx
+    ld1            {H.2d},[x1]
 IF_LE(`
     rev64          H.16b,H.16b
 ')
+    dup            EMSB.16b,H.b[7]
     mov            x1,#0xC200000000000000
     mov            x2,#1
     mov            POLY.d[0],x1
@@ -154,7 +140,7 @@ IF_LE(`
 
     PMUL_PARAM H2,H2M,H2L
 
-    st1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE],#64
+    st1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE],#64
 
     C --- calculate H^3 = H^1*H^2 ---
     
@@ -172,7 +158,7 @@ IF_LE(`
 
     PMUL_PARAM H4,H4M,H4L
 
-    st1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[TABLE]
+    st1            {H3M.2d,H3L.2d,H4M.2d,H4L.2d},[TABLE]
 
     ret
 EPILOGUE(_nettle_gcm_init_key)
@@ -220,7 +206,7 @@ PROLOGUE(_nettle_gcm_hash)
     mov            x4,#0xC200000000000000
     mov            POLY.d[0],x4
 
-    ld1            {D.16b},[X]
+    ld1            {D.2d},[X]
 IF_LE(`
     rev64          D.16b,D.16b
 ')
@@ -229,11 +215,11 @@ IF_LE(`
     b.eq           L2x
 
     add            x5,TABLE,#64
-    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
-    ld1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[x5]
+    ld1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE]
+    ld1            {H3M.2d,H3L.2d,H4M.2d,H4L.2d},[x5]
 
 L4x_loop:
-    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
+    ld1            {C0.2d,C1.2d,C2.2d,C3.2d},[DATA],#64
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -259,9 +245,9 @@ L2x:
     tst            LENGTH,#-32
     b.eq           L1x
 
-    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE]
 
-    ld1            {C0.16b,C1.16b},[DATA],#32
+    ld1            {C0.2d,C1.2d},[DATA],#32
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -280,9 +266,9 @@ L1x:
     tst            LENGTH,#-16
     b.eq           Lmod
 
-    ld1            {H1M.16b,H1L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d},[TABLE]
 
-    ld1            {C0.16b},[DATA],#16
+    ld1            {C0.2d},[DATA],#16
 IF_LE(`
     rev64          C0.16b,C0.16b
 ')
@@ -297,7 +283,7 @@ Lmod:
     tst            LENGTH,#15
     b.eq           Ldone
 
-    ld1            {H1M.16b,H1L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d},[TABLE]
 
     tbz            LENGTH,3,Lmod_8
     ldr            C0D,[DATA],#8
@@ -338,6 +324,6 @@ Ldone:
 IF_LE(`
     rev64          D.16b,D.16b
 ')
-    st1            {D.16b},[X]
+    st1            {D.2d},[X]
     ret
 EPILOGUE(_nettle_gcm_hash)

And as always after all this guesswork I have found a likely very
relevant comment in gcm.c:

  /* Shift uses big-endian representation. */
#if WORDS_BIGENDIAN
  reduce = shift_table[x-&gt;u64[1] &amp; 0xff];

Is that it? Or is TABLE just internal to the routine and we can store
there however we please? (Apart from H at TABLE[128] initialised for us
by gcm_set_key and stored BE?)
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210123115350</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-23 11:53:50-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hi Mamone, Jeff,

sorry for the duplication, used the wrong sender address for the list
again.

On Fri, Jan 22, 2021 at 07:07:46PM -0500, Jeffrey Walton wrote:

&gt; &gt; &gt; Do you think it makes sense to try and adjust the code to work with the
&gt; &gt; &gt; BE layout natively and have a full 128bit reverse after ldr-like loads
&gt; &gt; &gt; on LE instead (considering that 99,999% of aarch64 users will run LE)?
&gt; &gt; If you don't have a use-case we can suspend big-endian support of GCM
&gt; &gt; optimization on aarch64 until we get a request, use case or maybe
&gt; &gt; aarch64_be get more support in the future by main distributions.

I was actually referring to the performance hit for the overwhelming
number of users of a possible "mostly natively BE with quite some
overhead for converting back and forth on LE" approach compared to
"mostly-LE with slight adjustments for BE" as it (seemingly) started
out.

But today's session really cleared up for me that it isn't so much LE
vs. BE but just vector element order. What endianness remains is just
the given interface to the rest of the nettle code being defined as BE.
With the last patch from my previous email all this seemed to fall into
place nicely.

&gt; +1. At minimum, someone needs to produce an image to load on a
&gt; commodity board. If there are no images for a common board then
&gt; there's no demand in the market. There's no reason to jump through
&gt; hoops, like qemu, to solve a problem that does not exist.

My use-case has always been "because I can" and I really appreciate
everone's indulgence so far. So yes, by all means, focus on producing LE
asm for arm/aarch64 and I either dig into that for BE support or just
disable asm routines on my BE boards.

I also sometimes wonder who is actually producing all this nicely
working armeb and aarch64_be support in Qemu and Linux kernel when
there's apparently no users. I can understand that it's 90 or 95% very
good programming where endianness handling for PowerPC or MIPS just also
happens to work for BE arm. But the other 5% must come from somewhere.
So there must be some demand by someone but it's certainly very obscure.
;)
-- 
Bye, Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210124164433</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-24 16:44:33-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Michael,

On Sun, Jan 24, 2021 at 3:15 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; I think there might be a misunderstanding here (possibly caused by
&gt; my attemps at explaining what ldr does, sorry):
&gt;
&gt; On arm(32) and aarch64, endianness is also exclusively handled on
&gt; load and store operations. Register layout and operation behaviour is
&gt; identical in both modes. I think ARM also speaks of "memory endianness"
&gt; for just that reason. There is no adjustable "CPU endianness". It's
&gt; always "CPU-native".
&gt;
&gt; So pmull will behave exactly the same in BE and LE mode. We just have
&gt; to make sure our load operations put the operands in the correct (i.e.
&gt; CPU-native) representation into the correct vector register indices upon
&gt; load.
&gt;
&gt; So as an example:
&gt;
&gt; pmull2 v0.1q,v1.2d,v2.2d
&gt;
&gt; will always work on d[2] of v1 and v2 and put the result into all of v0.
&gt; And it expects its operands there in exactly one format, i.e. the least
&gt; significant bit at one end and the most-significant bit at the other
&gt; (and it's the same ends/bits in both memory-endianness modes :). And it
&gt; will
&gt; also store to v0 in exactly the same representation in LE and BE mode.
&gt; Nothing changes with an endianness mode switch.
&gt;
&gt; That's where load and store come in:
&gt;
&gt; ld1 {v1.2d,v2.2d},[x0]
&gt;
&gt; will load v1 and v2 with one-dimensional vectors from memory. So v1.d[0]
&gt; will be read from x0+0, v1.d[1] from x0+8 (bytes) and v2.d[0] from x0+16
&gt; and v2.d[1] from x0+24. That'll also be the same in LE and BE mode
&gt; because that's the structure of the vector prescribed by the load
&gt; operation we choose. Endianness will be applied to the individual
&gt; doublewords but the order in which they're loaded from memory and in
&gt; which they're put into d[0] and d[1] won't change, because they're
&gt; vectors.
&gt;
&gt; So if you've actually stored a vector from CPU registers using
&gt; st1 {v1.2d, v2.2d},[x0]
&gt; and then load them back using
&gt; ld1 {v1.2d, v2.2d},[x0]
&gt; there's nothing else that needs to be done. The individual bytes of the
&gt; doublewords will be stored LE in memory in LE mode and BE in BE mode but
&gt; you won't notice. And the order of the doublewords in memory will be the
&gt; same in both modes.
&gt;
&gt; If you're loading something that isn't stored LE or has no endianness at
&gt; all, e.g. just a sequence of data bytes (as in DATA in our code) or
&gt; something that was explicitly stored BE even on an LE CPU (as in
&gt; TABLE[128] in our code, I gather) but want to treat it as a larger
&gt; datatype, then you have to define endianness and need to apply
&gt; correction. That's why we need to rev64 in one mode (e.g. LE) to get the
&gt; same register-content in both endianness modes if what's loaded isn't
&gt; actually stored in that endianness in memory.
&gt;
&gt; Another way is to explicitly load a vector of bytes using ld1 {v1.16b,
&gt; v2.16b},[x0]. Then you can be sure what you get as register content, no
&gt; matter what memory endianness the CPU is using. If it's really just a
&gt; sequence of data bytes stored in their correct and necessary order in
&gt; memory and we only want to apply shifts and logical operations to each
&gt; of them, we'd be all set.
&gt;
&gt; Here we can also exploit but need to be careful to understand the
&gt; different views on the register, so the fact that b[0] through b[7] is
&gt; mapped to d[0] and that b[0] will be the least significant byte in d[0]
&gt; and b[7] will be MSB. This layout is cpu-native, i.e. also the same in
&gt; both endianness modes. It's just that an ld1 {v1.16b} will always load a
&gt; vector of bytes with eight elements as consecutive bytes from memory
&gt; into b[0] through b[7], so it'll always be an LSB-first load when
&gt; interpreted as a larger data type. If we then look at that data trough
&gt; d[0] it will appear reversed if it isn't really a doubleword that was
&gt; stored little-endian.
&gt;
&gt; That's why an ld1 {v1.b16,v2.b16},[x0] will produce incorrect results
&gt; with a pmull2 v0.1q,v1.2d,v2.2d in at least one endianness because we're
&gt; telling one operation that it's dealing with a byte-vector and the other
&gt; expects us to provide a vector of doublewords. If what we're loading is
&gt; actually something that was stored as doublewords in current memory
&gt; endianness, then ld1 {v1.2d,v2.2d} is the correct load operation. If
&gt; it's data bytes we want to *treat* as a big-endian doubleword, we can
&gt; use either ld1 {v1.16b,v2.16b} or {v1.2d,v2.2d} but in both cases need
&gt; to rev64 the register content if memory endianness is LE.
&gt;
&gt; Now what *ldr* does is load a single 128bit quadword. And this will
&gt; indeed transpose the doublewords in BE mode when looked at through d[0]
&gt; and d[1]. Because as a big-endian load it will of course load the byte
&gt; at x0 into the most significant byte of e.g. v2, i.e. v2.d[1], i.e.
&gt; v2.b[15] and not v2.d[0], i.e. v2.b[7] (as with ld1.2d) or v2.b[0] (as
&gt; with ld1.16b). Similarly, x0+15 will go into v2.b[0] in BE and v2.b[15]
&gt; in LE mode. So this will only make sense if what we're loading was
&gt; actually stored using str as a 128bit quadword in current memory
&gt; endianness. If it's a sequence of bytes (st1.16b) we want to treat as a
&gt; vector of doublewords, not only will the bytes appear inverted when
&gt; looked at through d[0] and d[1] but also what's in d[0] will be in d[1]
&gt; in the other endianness mode and vice-versa. If it's a vector of
&gt; doublewords in memory endianness (st1.2d), byte order in the register
&gt; will be correct in both modes (because it's different in memory) but
&gt; d[0] and d[1] will still be transposed.
&gt;
&gt; That's where all my rambling about doubleword transposition came from.
&gt; Does that make sense?
&gt;
&gt; I just found this document from the LLVM guys with pictures! :)
&gt; https://llvm.org/docs/BigEndianNEON.html
&gt;
&gt; BTW: ARM even goes as far as always storing *instructions* themselves,
&gt; so the actual opcodes the CPU decodes and executes, little-endian, even
&gt; in BE binaries. So the instruction fetch and decode stage always
&gt; operates little-endian. When the instruction is executed it's then just
&gt; an additional flag that tells load and store instructions how to behave
&gt; when executed and accessing memory. (I'm actually extrapolation from
&gt; what I know to be true for classic arm32 but it makes sense for that to
&gt; be true for aarch64 as well.)
&gt;

That explains everything, it also explains why ld1 instruction reverse the
byte order according to loading type on BE and always maintain the same
order on LE. The non memory related instructions maintain the same behavior
as it should no matter what the endianness mode they run on. Thanks for the
detailed explanation.
This scheme has a couple of advantages:
- Taking advantage of performance benefit of LE data layout on both memory
and registers side.
- Eliminating the overhead caused by transposing data order for every
potential load/store operation on LE since it's a more popular mode.

I think to gather you (same as me) prefer to think in big-endian
&gt; representation. As for arm and aarch64, little-endian is the default, do
&gt; you think, the routine could be changed to move the special endianness
&gt; treatment using rev64 to BE mode, i.e. avoid them in the standard LE
&gt; case? It's certainly beyond me but it might give some additional
&gt; speedup.
&gt;
&gt; Or would it be irrelevant compared to the speedup already given by using
&gt; pmull in the first place?


I don't know how it gonna affect the performance but it's irrelevant margin
indeed, TBH I liked the patch with the special endianness treatment but
it's up to you to decide!


&gt; &gt; &gt; And as always after all this guesswork I have found a likely very
&gt; &gt; &gt; relevant comment in gcm.c:
&gt; &gt; &gt;
&gt; &gt; &gt;   /* Shift uses big-endian representation. */
&gt; &gt; &gt; #if WORDS_BIGENDIAN
&gt; &gt; &gt;   reduce = shift_table[x-&gt;u64[1] &amp; 0xff];
&gt; &gt; &gt;
&gt; &gt; &gt; Is that it? Or is TABLE just internal to the routine and we can store
&gt; &gt; &gt; there however we please? (Apart from H at TABLE[128] initialised for us
&gt; &gt; &gt; by gcm_set_key and stored BE?)
&gt; &gt; &gt;
&gt; &gt; The assembly implementation of GHASH has a whole different scheme from C
&gt; &gt; table-lookup implementation, you don't have to worry about any of that.
&gt;
&gt; Perfect. So whether we use ld1/st1.16b or ld1/st1.2d for TABLE doesn't
&gt; matter. I wouldn't expect it but we could benchmark whether one is faster
&gt; than the other though!?
&gt;

Yeah, it doesn't matter since gcm_init_key() and gcm_hash() are the only
functions that use the table. keeping it ld1/st1.16b is fine, either way
there is a table layout at header of the file that gives a sense about the
table structure for the assembly implementation scheme.


&gt; For clarification: How is H, i.e. TABLE[128] defined an interface to
&gt; gcm_set_key? I see that gcm_set_key calls a cipher function to fill it.
&gt; So I guess it provides the routine with a sequence of bytes  (similar to
&gt; DATA), i.e. the key, which will be the same on LE and BE and we *treat*
&gt; it as a big-endian doubleword for the sake of using pmull on it.
&gt; Correct?
&gt;

subkey 'H' value is calculated by enciphering (usually using AES) a
sequence of ZERO data, then gcm_set_key() assign the calculated value
(subkey 'H') at the middle of TABLE array, that is TABLE[80], the remaining
fields of array are meant to be filled by C gcm_init_key() routine to
server as assistance subkeys for C table-look implementation. Since the
assembly implementation uses a different scheme, we don't need those
assistance subkeys so we grab the main subkey (H) value from the middle of
the table and hook our needed assistance values on this table in order to
be used by gcm_hash(). Hope it makes sense for you, let me know if you want
to hear further explanation.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210124183941</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-24 18:39:41-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; subkey 'H' value is calculated by enciphering (usually using AES) a
&gt; sequence of ZERO data, then gcm_set_key() assign the calculated value
&gt; (subkey 'H') at the middle of TABLE array, that is TABLE[80],

And the reason for it being stored in the *middle* is the "unnatural"
gcm bitorder. The C implementation uses the table for the gcm
multiplication, using 8 bits at a time from one of the inputs as the
table index. Conceptually, the H value belongs at index 1 in the table,
0000 0001 in binary, but in gcm's opposite bitorder world, that
corresponds to 1000 0000. If I remember correctly, the implementation
using 8 bit indexing, including the table layout, closely follows the
original gcm papers.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210125183015</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-25 18:30:15-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Sun, Jan 24, 2021 at 06:44:33PM +0200, Maamoun TK wrote:

&gt; &gt; representation. As for arm and aarch64, little-endian is the default, do
&gt; &gt; you think, the routine could be changed to move the special endianness
&gt; &gt; treatment using rev64 to BE mode, i.e. avoid them in the standard LE
&gt; &gt; case? It's certainly beyond me but it might give some additional
&gt; &gt; speedup.
&gt; &gt;
&gt; &gt; Or would it be irrelevant compared to the speedup already given by using
&gt; &gt; pmull in the first place?
&gt; I don't know how it gonna affect the performance but it's irrelevant margin
&gt; indeed, TBH I liked the patch with the special endianness treatment but
&gt; it's up to you to decide!

As you might expect, I like the one where doubleword vectors are used
throughout and stored in host endianness in TABLE because to me it's
most intuitive. For DATA my rationale is that if we want to *treat* it
as big-endian doublewords we should load it as doublewords to make it
clearer why and what we need to adjust afterwards. It also avoids the
rev64s with BE. I've added some comments with rationale. I've added a
README with an excerpt of last email as well. Attached are the current
patches, the first being your original. What do you think?

As said, I'm up for looking into endianness-specific versions of the
macros again. But what was supposed to be the LE versions of PMUL and
friends has now become the BE-native versions and we'd need to come up
with variants of them that make the rev64s unneccessary. Any ideas?
-- 
Thanks!
Michael

["0001-Mamone-s-unmodified-patch.patch" (text/x-diff)]

From 344e2061cc29ed065aeb687ab92a1ab7cdd1ea6e Mon Sep 17 00:00:00 2001
From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
Date: Mon, 25 Jan 2021 18:36:54 +0100
Subject: [PATCH 1/4] Mamone's unmodified patch

---
 Makefile.in           |   1 +
 arm64/v8/gcm-hash.asm | 343 ++++++++++++++++++++++++++++++++++++++++++
 configure.ac          |  23 +++
 3 files changed, 367 insertions(+)
 create mode 100644 arm64/v8/gcm-hash.asm

diff --git a/Makefile.in b/Makefile.in
index cfbc45bb..2697ad6d 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -616,6 +616,7 @@ distdir: $(DISTFILES)
 	set -e; for d in sparc32 sparc64 x86 \
 		x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
 		arm arm/neon arm/v6 arm/fat \
+		arm64 arm64/v8 \
 		powerpc64 powerpc64/p7 powerpc64/p8 powerpc64/fat ; do \
 	  mkdir "$(distdir)/$$d" ; \
 	  find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' -o -name \
                README ')' \
diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
new file mode 100644
index 00000000..1c14db54
--- /dev/null
+++ b/arm64/v8/gcm-hash.asm
@@ -0,0 +1,343 @@
+C arm/v8/gcm-hash.asm
+
+ifelse(`
+   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C gcm_set_key() assigns H value in the middle element of the table
+define(`H_Idx', `128')
+
+.file "gcm-hash.asm"
+
+.text
+
+C common register usage:
+define(`POLY', `v6')
+define(`T', `v7')
+define(`F', `v16')
+define(`F1', `v17')
+define(`R', `v18')
+define(`R1', `v19')
+
+C common macros:
+.macro PMUL in, param1, param2
+    pmull          F.1q,\param2\().1d,\in\().1d
+    pmull2         F1.1q,\param2\().2d,\in\().2d
+    pmull          R.1q,\param1\().1d,\in\().1d
+    pmull2         R1.1q,\param1\().2d,\in\().2d
+    eor            F.16b,F.16b,F1.16b
+    eor            R.16b,R.16b,R1.16b
+.endm
+
+.macro REDUCTION out
+IF_BE(`
+    pmull          T.1q,F.1d,POLY.1d
+    ext            \out\().16b,F.16b,F.16b,#8
+    eor            R.16b,R.16b,T.16b
+    eor            \out\().16b,\out\().16b,R.16b
+',`
+    pmull          T.1q,F.1d,POLY.1d
+    eor            R.16b,R.16b,T.16b
+    ext            R.16b,R.16b,R.16b,#8
+    eor            \out\().16b,F.16b,R.16b
+')
+.endm
+
+    C void gcm_init_key (union gcm_block *table)
+
+C This function populates the gcm table as the following layout
+C *******************************************************************************
+C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) \
div x������              | +C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� \
�+x��� �+x������)) mod x������) + (H1 div x������) | +C |                             \
| +C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) \
div x������              | +C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� \
�+x��� �+x������)) mod x������) + (H2 div x������) | +C |                             \
| +C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) \
div x������              | +C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� \
�+x��� �+x������)) mod x������) + (H3 div x������) | +C |                             \
| +C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) \
div x������              | +C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� \
�+x��� �+x������)) mod x������) + (H4 div x������) | +C \
******************************************************************************* +
+C gcm_init_key register usage:
+define(`TABLE', `x0')
+
+define(`EMSB', `v0')
+define(`B', `v1')
+define(`H', `v2')
+define(`HQ', `q2')
+define(`H2', `v3')
+define(`H3', `v4')
+define(`H4', `v5')
+define(`Hp', `v20')
+define(`Hl', `v21')
+define(`Hm', `v22')
+define(`H1M', `v23')
+define(`H1L', `v24')
+define(`H2M', `v25')
+define(`H2L', `v26')
+define(`H3M', `v27')
+define(`H3L', `v28')
+define(`H4M', `v29')
+define(`H4L', `v30')
+
+.macro PMUL_PARAM in, param1, param2
+IF_BE(`
+    pmull2         Hp.1q,\in\().2d,POLY.2d
+    ext            Hm.16b,\in\().16b,\in\().16b,#8
+    eor            Hm.16b,Hm.16b,Hp.16b
+    zip            \param1\().2d,\in\().2d,Hm.2d
+    zip2           \param2\().2d,\in\().2d,Hm.2d
+',`
+    pmull2         Hp.1q,\in\().2d,POLY.2d
+    eor            Hm.16b,\in\().16b,Hp.16b
+    ext            \param1\().16b,Hm.16b,\in\().16b,#8
+    ext            \param2\().16b,\in\().16b,Hm.16b,#8
+    ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
+')
+.endm
+
+PROLOGUE(_nettle_gcm_init_key)
+    ldr            HQ,[TABLE,#16*H_Idx]
+    dup            EMSB.16b,H.b[0]
+IF_LE(`
+    rev64          H.16b,H.16b
+')
+    mov            x1,#0xC200000000000000
+    mov            x2,#1
+    mov            POLY.d[0],x1
+    mov            POLY.d[1],x2
+    sshr           EMSB.16b,EMSB.16b,#7
+    and            EMSB.16b,EMSB.16b,POLY.16b
+    ushr           B.2d,H.2d,#63
+    and            B.16b,B.16b,POLY.16b
+    ext            B.16b,B.16b,B.16b,#8
+    shl            H.2d,H.2d,#1
+    orr            H.16b,H.16b,B.16b
+    eor            H.16b,H.16b,EMSB.16b
+
+    dup            POLY.2d,POLY.d[0]
+
+    C --- calculate H^2 = H*H ---
+
+    PMUL_PARAM H,H1M,H1L
+
+    PMUL H,H1M,H1L
+
+    REDUCTION H2
+
+    PMUL_PARAM H2,H2M,H2L
+
+    st1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE],#64
+
+    C --- calculate H^3 = H^1*H^2 ---
+    
+    PMUL H2,H1M,H1L
+
+    REDUCTION H3
+
+    PMUL_PARAM H3,H3M,H3L
+
+    C --- calculate H^4 = H^2*H^2 ---
+
+    PMUL H2,H2M,H2L
+
+    REDUCTION H4
+
+    PMUL_PARAM H4,H4M,H4L
+
+    st1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[TABLE]
+
+    ret
+EPILOGUE(_nettle_gcm_init_key)
+
+C gcm_hash register usage:
+define(`TABLE', `x0')
+define(`X', `x1')
+define(`LENGTH', `x2')
+define(`DATA', `x3')
+
+define(`D', `v0')
+define(`C0', `v1')
+define(`C0D', `d1')
+define(`C1', `v2')
+define(`C2', `v3')
+define(`C3', `v4')
+define(`R2', `v20')
+define(`F2', `v21')
+define(`R3', `v22')
+define(`F3', `v23')
+define(`H1M', `v24')
+define(`H1L', `v25')
+define(`H2M', `v26')
+define(`H2L', `v27')
+define(`H3M', `v28')
+define(`H3L', `v29')
+define(`H4M', `v30')
+define(`H4L', `v31')
+
+.macro PMUL_SUM in, param1, param2
+    pmull          F2.1q,\param2\().1d,\in\().1d
+    pmull2         F3.1q,\param2\().2d,\in\().2d
+    pmull          R2.1q,\param1\().1d,\in\().1d
+    pmull2         R3.1q,\param1\().2d,\in\().2d
+    eor            F2.16b,F2.16b,F3.16b
+    eor            R2.16b,R2.16b,R3.16b
+    eor            F.16b,F.16b,F2.16b
+    eor            R.16b,R.16b,R2.16b
+.endm
+
+    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+    C                size_t length, const uint8_t *data)
+
+PROLOGUE(_nettle_gcm_hash)
+    mov            x4,#0xC200000000000000
+    mov            POLY.d[0],x4
+
+    ld1            {D.16b},[X]
+IF_LE(`
+    rev64          D.16b,D.16b
+')
+
+    ands           x4,LENGTH,#-64
+    b.eq           L2x
+
+    add            x5,TABLE,#64
+    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
+    ld1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[x5]
+
+L4x_loop:
+    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
+IF_LE(`
+    rev64          C0.16b,C0.16b
+    rev64          C1.16b,C1.16b
+    rev64          C2.16b,C2.16b
+    rev64          C3.16b,C3.16b
+')
+
+    eor            C0.16b,C0.16b,D.16b
+
+    PMUL C1,H3M,H3L
+    PMUL_SUM C2,H2M,H2L
+    PMUL_SUM C3,H1M,H1L
+    PMUL_SUM C0,H4M,H4L
+
+    REDUCTION D
+
+    subs           x4,x4,#64
+    b.ne           L4x_loop
+
+    and            LENGTH,LENGTH,#63
+
+L2x:
+    tst            LENGTH,#-32
+    b.eq           L1x
+
+    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
+
+    ld1            {C0.16b,C1.16b},[DATA],#32
+IF_LE(`
+    rev64          C0.16b,C0.16b
+    rev64          C1.16b,C1.16b
+')
+
+    eor            C0.16b,C0.16b,D.16b
+
+    PMUL C1,H1M,H1L
+    PMUL_SUM C0,H2M,H2L
+
+    REDUCTION D
+
+    and            LENGTH,LENGTH,#31
+
+L1x:
+    tst            LENGTH,#-16
+    b.eq           Lmod
+
+    ld1            {H1M.16b,H1L.16b},[TABLE]
+
+    ld1            {C0.16b},[DATA],#16
+IF_LE(`
+    rev64          C0.16b,C0.16b
+')
+
+    eor            C0.16b,C0.16b,D.16b
+
+    PMUL C0,H1M,H1L
+
+    REDUCTION D
+
+Lmod:
+    tst            LENGTH,#15
+    b.eq           Ldone
+
+    ld1            {H1M.16b,H1L.16b},[TABLE]
+
+    tbz            LENGTH,3,Lmod_8
+    ldr            C0D,[DATA],#8
+IF_LE(`
+    rev64          C0.16b,C0.16b
+')
+    mov            x7,#0
+    mov            C0.d[1],x7
+Lmod_8:
+    tst            LENGTH,#7
+    b.eq           Lmod_8_done
+    mov            x6,#0
+    mov            x5,#64
+    and            x4,LENGTH,#7
+Lmod_8_loop:
+    mov            x7,#0
+    ldrb           w7,[DATA],#1
+    sub            x5,x5,#8
+    lsl            x7,x7,x5
+    orr            x6,x6,x7
+    subs           x4,x4,#1
+    b.ne           Lmod_8_loop
+    tbz            LENGTH,3,Lmod_8_load
+    mov            C0.d[1],x6
+    b              Lmod_8_done
+Lmod_8_load:
+    mov            x7,#0
+    mov            C0.d[0],x6
+    mov            C0.d[1],x7
+Lmod_8_done:
+    eor            C0.16b,C0.16b,D.16b
+
+    PMUL C0,H1M,H1L
+
+    REDUCTION D
+
+Ldone:
+IF_LE(`
+    rev64          D.16b,D.16b
+')
+    st1            {D.16b},[X]
+    ret
+EPILOGUE(_nettle_gcm_hash)
diff --git a/configure.ac b/configure.ac
index 763df3b5..debeb1a2 100644
--- a/configure.ac
+++ b/configure.ac
@@ -81,6 +81,10 @@ AC_ARG_ENABLE(arm-neon,
   AC_HELP_STRING([--enable-arm-neon], [Enable ARM Neon assembly. (default=auto)]),,
   [enable_arm_neon=auto])
 
+AC_ARG_ENABLE(armv8-a-crypto,
+  AC_HELP_STRING([--enable-armv8-a-crypto], [Enable Armv8-A Crypto extension. \
(default=no)]),, +  [enable_armv8_a_crypto=no])
+
 AC_ARG_ENABLE(x86-aesni,
   AC_HELP_STRING([--enable-x86-aesni], [Enable x86_64 aes instructions. \
(default=no)]),,  [enable_x86_aesni=no])
@@ -337,6 +341,17 @@ case "$host_cpu" in
     AC_TRY_COMPILE([
 #if defined(__PPC64__)
 #error 64-bit powerpc
+#endif
+    ], [], [
+      ABI=32
+    ], [
+      ABI=64
+    ])
+    ;;
+  aarch64*)
+    AC_TRY_COMPILE([
+#if defined(__aarch64__)
+#error 64-bit arm
 #endif
     ], [], [
       ABI=32
@@ -459,6 +474,14 @@ if test "x$enable_assembler" = xyes ; then
 	fi
       fi
       ;;
+    aarch64*)
+	    if test "$enable_armv8_a_crypto" = yes ; then
+        if test "$ABI" = 64 ; then
+          CFLAGS="$CFLAGS -Wa,-march=armv8-a+crypto"
+          asm_path="arm64 arm64/v8"
+        fi
+      fi
+    ;;
     *powerpc64*)
       if test "$ABI" = 64 ; then
 	GMP_ASM_POWERPC_R_REGISTERS
-- 
2.30.0


["0002-Add-an-empty-machine.m64-to-make-configure-happy.patch" (text/x-diff)]

From 3c219dfcc213f518dc2533eb86e8acdc3bdb8a62 Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Mon, 25 Jan 2021 18:38:20 +0100
Subject: [PATCH 2/4] Add an empty machine.m64 to make configure happy

---
 arm64/machine.m4 | 0
 1 file changed, 0 insertions(+), 0 deletions(-)
 create mode 100644 arm64/machine.m4

diff --git a/arm64/machine.m4 b/arm64/machine.m4
new file mode 100644
index 00000000..e69de29b
-- 
2.30.0


["0003-aarch64-Adjust-gcm-hash-assembly-for-big-endian-syst.patch" (text/x-diff)]

From 6ce9e36aeb7a076907604334277892b6919e4236 Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Mon, 25 Jan 2021 18:37:06 +0100
Subject: [PATCH 3/4] aarch64: Adjust gcm-hash assembly for big-endian systems

---
 arm64/v8/gcm-hash.asm | 52 +++++++++++++++++++------------------------
 1 file changed, 23 insertions(+), 29 deletions(-)

diff --git a/arm64/v8/gcm-hash.asm b/arm64/v8/gcm-hash.asm
index 1c14db54..10956622 100644
--- a/arm64/v8/gcm-hash.asm
+++ b/arm64/v8/gcm-hash.asm
@@ -55,17 +55,10 @@ C common macros:
 .endm
 
 .macro REDUCTION out
-IF_BE(`
-    pmull          T.1q,F.1d,POLY.1d
-    ext            \out\().16b,F.16b,F.16b,#8
-    eor            R.16b,R.16b,T.16b
-    eor            \out\().16b,\out\().16b,R.16b
-',`
     pmull          T.1q,F.1d,POLY.1d
     eor            R.16b,R.16b,T.16b
     ext            R.16b,R.16b,R.16b,#8
     eor            \out\().16b,F.16b,R.16b
-')
 .endm
 
     C void gcm_init_key (union gcm_block *table)
@@ -108,27 +101,25 @@ define(`H4M', `v29')
 define(`H4L', `v30')
 
 .macro PMUL_PARAM in, param1, param2
-IF_BE(`
-    pmull2         Hp.1q,\in\().2d,POLY.2d
-    ext            Hm.16b,\in\().16b,\in\().16b,#8
-    eor            Hm.16b,Hm.16b,Hp.16b
-    zip            \param1\().2d,\in\().2d,Hm.2d
-    zip2           \param2\().2d,\in\().2d,Hm.2d
-',`
     pmull2         Hp.1q,\in\().2d,POLY.2d
     eor            Hm.16b,\in\().16b,Hp.16b
     ext            \param1\().16b,Hm.16b,\in\().16b,#8
     ext            \param2\().16b,\in\().16b,Hm.16b,#8
     ext            \param1\().16b,\param1\().16b,\param1\().16b,#8
-')
 .endm
 
 PROLOGUE(_nettle_gcm_init_key)
-    ldr            HQ,[TABLE,#16*H_Idx]
-    dup            EMSB.16b,H.b[0]
+    add            x1,TABLE,#16*H_Idx
+    ld1            {H.2d},[x1]
+
+    C we treat data as big-endian doublewords for processing. Since there is no
+    C endianness-neutral MSB-first load operation we need to restore our desired
+    C byte order on little-endian systems. The same holds true for DATA below
+    C but not our own internal precalculated TABLE (see below).
 IF_LE(`
     rev64          H.16b,H.16b
 ')
+    dup            EMSB.16b,H.b[7]
     mov            x1,#0xC200000000000000
     mov            x2,#1
     mov            POLY.d[0],x1
@@ -154,7 +145,10 @@ IF_LE(`
 
     PMUL_PARAM H2,H2M,H2L
 
-    st1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE],#64
+    C we store to the table as doubleword-vectors in current memory endianness
+    C because it's our own strictly internal data structure and what gsm_hash
+    C can most naturally use
+    st1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE],#64
 
     C --- calculate H^3 = H^1*H^2 ---
     
@@ -172,7 +166,7 @@ IF_LE(`
 
     PMUL_PARAM H4,H4M,H4L
 
-    st1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[TABLE]
+    st1            {H3M.2d,H3L.2d,H4M.2d,H4L.2d},[TABLE]
 
     ret
 EPILOGUE(_nettle_gcm_init_key)
@@ -220,7 +214,7 @@ PROLOGUE(_nettle_gcm_hash)
     mov            x4,#0xC200000000000000
     mov            POLY.d[0],x4
 
-    ld1            {D.16b},[X]
+    ld1            {D.2d},[X]
 IF_LE(`
     rev64          D.16b,D.16b
 ')
@@ -229,11 +223,11 @@ IF_LE(`
     b.eq           L2x
 
     add            x5,TABLE,#64
-    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
-    ld1            {H3M.16b,H3L.16b,H4M.16b,H4L.16b},[x5]
+    ld1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE]
+    ld1            {H3M.2d,H3L.2d,H4M.2d,H4L.2d},[x5]
 
 L4x_loop:
-    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
+    ld1            {C0.2d,C1.2d,C2.2d,C3.2d},[DATA],#64
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -259,9 +253,9 @@ L2x:
     tst            LENGTH,#-32
     b.eq           L1x
 
-    ld1            {H1M.16b,H1L.16b,H2M.16b,H2L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d,H2M.2d,H2L.2d},[TABLE]
 
-    ld1            {C0.16b,C1.16b},[DATA],#32
+    ld1            {C0.2d,C1.2d},[DATA],#32
 IF_LE(`
     rev64          C0.16b,C0.16b
     rev64          C1.16b,C1.16b
@@ -280,9 +274,9 @@ L1x:
     tst            LENGTH,#-16
     b.eq           Lmod
 
-    ld1            {H1M.16b,H1L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d},[TABLE]
 
-    ld1            {C0.16b},[DATA],#16
+    ld1            {C0.2d},[DATA],#16
 IF_LE(`
     rev64          C0.16b,C0.16b
 ')
@@ -297,7 +291,7 @@ Lmod:
     tst            LENGTH,#15
     b.eq           Ldone
 
-    ld1            {H1M.16b,H1L.16b},[TABLE]
+    ld1            {H1M.2d,H1L.2d},[TABLE]
 
     tbz            LENGTH,3,Lmod_8
     ldr            C0D,[DATA],#8
@@ -338,6 +332,6 @@ Ldone:
 IF_LE(`
     rev64          D.16b,D.16b
 ')
-    st1            {D.16b},[X]
+    st1            {D.2d},[X]
     ret
 EPILOGUE(_nettle_gcm_hash)
-- 
2.30.0


["0004-aarch64-Add-README.patch" (text/x-diff)]

From 2804b9c062eddf82f56b5f5a30eea459fc790bc8 Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Mon, 25 Jan 2021 19:05:47 +0100
Subject: [PATCH 4/4] aarch64: Add README

---
 arm64/README | 45 +++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 45 insertions(+)
 create mode 100644 arm64/README

diff --git a/arm64/README b/arm64/README
new file mode 100644
index 00000000..139a3cc1
--- /dev/null
+++ b/arm64/README
@@ -0,0 +1,45 @@
+Endianness
+
+Similar to arm, aarch64 can run with little-endian or big-endian memory
+accesses. Endianness is handled exclusively on load and store operations.
+Register layout and operation behaviour is identical in both modes.
+
+When writing SIMD code, endianness interaction with vector loads and stores may
+exhibit seemingly unintuitive behaviour, particularly when mixing normal and
+vector load/store operations.
+
+See https://llvm.org/docs/BigEndianNEON.html for a good overview, particularly
+into the pitfalls of using ldr/str vs. ld1/st1.
+
+For example, ld1 {v1.2d,v2.2d},[x0] will load v1 and v2 with elements of a
+one-dimensional vector from consecutive memory locations. So v1.d[0] will be
+read from x0+0, v1.d[1] from x0+8 (bytes) and v2.d[0] from x0+16 and v2.d[1]
+from x0+24. That'll be the same in LE and BE mode because it is the structure
+of the vector prescribed by the load operation. Endianness will be applied to
+the individual doublewords but the order in which they're loaded from memory
+and in which they're put into d[0] and d[1] won't change.
+
+Another way is to explicitly load a vector of bytes using ld1 {v1.16b,
+v2.16b},[x0]. This will load x0+0 into v1.b[0], x0+1 (byte) into v1.b[1] and so
+forth. This load (or store) is endianness-neutral and behaves identical in LE
+and BE mode.
+
+Care must however be taken when switching views onto the registers: d[0] is
+mapped onto b[0] through b[7] and b[0] will be the least significant byte in
+d[0] and b[7] will be MSB. This layout is also the same in both memory
+endianness modes. ld1 {v1.16b}, however, will always load a vector of bytes
+with eight elements as consecutive bytes from memory into b[0] through b[7].
+When accessed trough d[0] this will only appear as the expected
+doubleword-sized number if it was indeed stored little-endian in memory.
+Something similar happens when loading a vector of doublewords (ld1
+{v1.2d},[x0]) and then accessing individual bytes of it. Bytes will only be at
+the expected indices if the doublewords are indeed stored in current memory
+endianness in memory. Therefore it is most intuitive to use the appropriate
+vector element width for the data being loaded or stored to apply the necessary
+endianness correction.
+
+Finally, ldr/str are not vector operations. When used to load a 128bit
+quadword, they will apply endianness to the whole quadword. Therefore
+particular care must be taken if the loaded data is then to be regarded as
+elements of e.g. a doubleword vector. Indicies may appear reversed on
+big-endian systems (because they are).
-- 
2.30.0


[Attachment #7 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210126171522</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-26 17:15:22-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Michael,

On Mon, Jan 25, 2021 at 8:45 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Attached are the current
&gt; patches, the first being your original. What do you think?
&gt;

I liked how the patch ended up so far, just give me one or two days to give
the patch additional review before letting it up to Neils.


&gt; As said, I'm up for looking into endianness-specific versions of the
&gt; macros again. But what was supposed to be the LE versions of PMUL and
&gt; friends has now become the BE-native versions and we'd need to come up
&gt; with variants of them that make the rev64s unneccessary. Any ideas?
&gt;

Are you looking for removing rev64s on LE? If so, I don't think we can
figure a variant that allows us continue working on an unsorted register
value on LE as pmull requires the input to be sorted properly, that is
transposed doublewords.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210126223244</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-26 22:32:44-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Mamone,

On Tue, Jan 26, 2021 at 07:15:22PM +0200, Maamoun TK wrote:

&gt; &gt; Attached are the current
&gt; &gt; patches, the first being your original. What do you think?
&gt; I liked how the patch ended up so far, just give me one or two days to give
&gt; the patch additional review before letting it up to Neils.

Perfect.

&gt; &gt; As said, I'm up for looking into endianness-specific versions of the
&gt; &gt; macros again. But what was supposed to be the LE versions of PMUL and
&gt; &gt; friends has now become the BE-native versions and we'd need to come up
&gt; &gt; with variants of them that make the rev64s unneccessary. Any ideas?

&gt; Are you looking for removing rev64s on LE? If so, I don't think we can
&gt; figure a variant that allows us continue working on an unsorted register
&gt; value on LE as pmull requires the input to be sorted properly, that is
&gt; transposed doublewords.

Let's leave it as it is then. I've caused enough effort with my little
hobby of running an ARM BE system for now. :)
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210127063943</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-27 06:39:43-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Are you looking for removing rev64s on LE? If so, I don't think we can
&gt; figure a variant that allows us continue working on an unsorted register
&gt; value on LE as pmull requires the input to be sorted properly, that is
&gt; transposed doublewords.

I haven't been following along closely, but it would be if gcm_hash
could work with a minimum of data shuffling, and let gsm_init_key move
the precomputed data around for best layout.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210130120923</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-30 12:09:23-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Mon, Jan 25, 2021 at 8:45 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; Attached are the current
&gt; patches.
&gt;

Everything looks fine to me, I made an additional review and the code seems
good for both endianness modes.
The patches pass the testsuite on little-endian and big-endian (Thanks
to Michael Weiser for providing a ready to go environment to test the patch
on big-endian mode)
I made one more patch that adds proper copyright and removes unused define.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210130121714</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-30 12:17:14-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Wed, Jan 27, 2021 at 12:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; I've caused enough effort with my little
&gt; hobby of running an ARM BE system for now. :)
&gt;

Thank you for the great work, we're now able to run the optimized gcm core
on big-endian arm64 systems.
I enjoyed working with you in order to get this done as I also learned many
stuff about arm endianness stuff.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210130160754</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-30 16:07:54-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Everything looks fine to me, I made an additional review and the code seems
&gt; good for both endianness modes.
&gt; The patches pass the testsuite on little-endian and big-endian (Thanks
&gt; to Michael Weiser for providing a ready to go environment to test the patch
&gt; on big-endian mode)
&gt; I made one more patch that adds proper copyright and removes unused define.

Nice!

I've merged the easy parts, machine.m4 and README, onto the arm64
branch. Not crystal clear how the more interesting parts relate, though.

Is 0001-Mamone-s-unmodified-patch.patch the same as
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/13? Do you
want to update the merge request with recent changes (on top of the
current arm64 branch), or should I merge mr13 as is, and then add the
other two patches (Michaels's BE support and this "adds proper copyright
and removes unused define") on top?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210130231736</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-30 23:17:36-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sat, Jan 30, 2021 at 6:07 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Is 0001-Mamone-s-unmodified-patch.patch the same as
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/13? Do you
&gt; want to update the merge request with recent changes (on top of the
&gt; current arm64 branch), or should I merge mr13 as is, and then add the
&gt; other two patches (Michaels's BE support and this "adds proper copyright
&gt; and removes unused define") on top?
&gt;

The merge request is out of date and should be closed. You just need to
merge 0001-Mamone-s-unmodified-patch.patch
then 0003-aarch64-Adjust-gcm-hash-assembly-for-big-endian-syst.patch on top
of the former.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210131034706</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-01-31 03:47:06-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

This is a new patch to fix the clang build if "armv8-a-crypto" is enabled
and should be applied on top of the previous patches.

regards,
Mamone

On Sun, Jan 31, 2021 at 1:17 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; On Sat, Jan 30, 2021 at 6:07 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Is 0001-Mamone-s-unmodified-patch.patch the same as
&gt;&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/13? Do you
&gt;&gt; want to update the merge request with recent changes (on top of the
&gt;&gt; current arm64 branch), or should I merge mr13 as is, and then add the
&gt;&gt; other two patches (Michaels's BE support and this "adds proper copyright
&gt;&gt; and removes unused define") on top?
&gt;&gt;
&gt;
&gt; The merge request is out of date and should be closed. You just need to
&gt; merge 0001-Mamone-s-unmodified-patch.patch
&gt; then 0003-aarch64-Adjust-gcm-hash-assembly-for-big-endian-syst.patch on top
&gt; of the former.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210131082104</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-31 08:21:04-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This is a new patch to fix the clang build if "armv8-a-crypto" is enabled
&gt; and should be applied on top of the previous patches.

Thanks, merged all the changes to the arm64 branch. Let me know if
there's anything I missed. I have a few comments on the main patch,
I'll write that in a separate mail.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210131083514</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-31 08:35:14-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; Subject: [PATCH 1/4] Mamone's unmodified patch

Hi, I've merged this, but I have a couple of comments and questions.

&gt; --- a/Makefile.in
&gt; +++ b/Makefile.in
&gt; @@ -616,6 +616,7 @@ distdir: $(DISTFILES)
&gt;  	set -e; for d in sparc32 sparc64 x86 \
&gt;  		x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
&gt;  		arm arm/neon arm/v6 arm/fat \
&gt; +		arm64 arm64/v8 \

Why the name "v8" for the directory, aren't arm64 and v8 more or less
synonyms? I think it would make more sense with a name connected to the
extension needed for the pmull instructions.

&gt; --- /dev/null
&gt; +++ b/arm64/v8/gcm-hash.asm
&gt; @@ -0,0 +1,343 @@

&gt; +C common macros:
&gt; +.macro PMUL in, param1, param2
&gt; +    pmull          F.1q,\param2\().1d,\in\().1d
&gt; +    pmull2         F1.1q,\param2\().2d,\in\().2d
&gt; +    pmull          R.1q,\param1\().1d,\in\().1d
&gt; +    pmull2         R1.1q,\param1\().2d,\in\().2d
&gt; +    eor            F.16b,F.16b,F1.16b
&gt; +    eor            R.16b,R.16b,R1.16b
&gt; +.endm

For consistency, I'd prefer defining all needed macros using m4.

&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -81,6 +81,10 @@ AC_ARG_ENABLE(arm-neon,
&gt;    AC_HELP_STRING([--enable-arm-neon], [Enable ARM Neon assembly. (default=auto)]),,
&gt;    [enable_arm_neon=auto])
&gt;  
&gt; +AC_ARG_ENABLE(armv8-a-crypto,
&gt; +  AC_HELP_STRING([--enable-armv8-a-crypto], [Enable Armv8-A Crypto extension. (default=no)]),,
&gt; +  [enable_armv8_a_crypto=no])

I think this would be more user-friendle without the "a",
--enable-armv8-crypto, or --enable-arm64-crypto. Or do you foresee any
collision with an incompatible ARMv8-M crypto extension or the like?

&gt; +    aarch64*)
&gt; +	    if test "$enable_armv8_a_crypto" = yes ; then
&gt; +        if test "$ABI" = 64 ; then
&gt; +          CFLAGS="$CFLAGS -Wa,-march=armv8-a+crypto"

(This looks slightly different after merging all the changes). 

I think it's unfortunate to have to modify CFLAGS, and in particular
using compiler-specific options. Is there any way to use a pseudoop in
the .asm file instead, similar to the .fpu neon used in the arm/neon/
files?

One could also consider introducing a separate ASMFLAGS make
variable (suggested earlier by Jeffrey Walton, for other reasons).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202043741</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-02-02 04:37:41-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sun, Jan 31, 2021 at 10:00 PM Michael Weiser &lt;michael.weiser@gmx.de&gt;
wrote:

&gt; It might as well be that llvm-as just knows the
&gt; pmull instruction and assembles it fine but can't check if the target
&gt; CPU will be able to run it.
&gt;

llvm-as wouldn't recognize pmull instruction without
adding -march=armv8-a+crypto flag at least with the version I use "3.8.1"
I tried both .arch armv8-a+crypto and .arch_extension crypto and they
worked only for gas while llvm-as produces errors for pmull using.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202064044</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-02 06:40:44-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; llvm-as wouldn't recognize pmull instruction without
&gt; adding -march=armv8-a+crypto flag at least with the version I use "3.8.1"
&gt; I tried both .arch armv8-a+crypto and .arch_extension crypto and they
&gt; worked only for gas while llvm-as produces errors for pmull using.

Is there any documentation for llvm-as? Best I could find is the minimal
man page https://www.llvm.org/docs/CommandGuide/llvm-as.html, with no
info whatsoever on, e.g., supported pseudoops.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202125931</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-02-02 12:59:31-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Niels,

On Tue, Feb 02, 2021 at 07:40:44AM +0100, Niels Möller wrote:

&gt; &gt; llvm-as wouldn't recognize pmull instruction without
&gt; &gt; adding -march=armv8-a+crypto flag at least with the version I use "3.8.1"

3.8.1 was released in 2017. It might not support recent
aarch64 additions regarding .arch directive and friends.

&gt; &gt; I tried both .arch armv8-a+crypto and .arch_extension crypto and they
&gt; &gt; worked only for gas while llvm-as produces errors for pmull using.
&gt; Is there any documentation for llvm-as? Best I could find is the minimal
&gt; man page https://www.llvm.org/docs/CommandGuide/llvm-as.html, with no
&gt; info whatsoever on, e.g., supported pseudoops.

I think my mentioning of llvm-as was a red herring. Looking at the
output of clang -v, llvm-as isn't involved at all. This is supported by
the man page stating that llvm-as accepts LLVM assembly and emits LLVM
bytecode. It appears, clang implements the assembler internally and we'd
need documentation on that. The clang man page even says so):

# man clang | grep assembler
              Clang  also  supports the use of an integrated assembler,
in which the code generator produces object files directly. This avoids
              the overhead of generating the ".s" file and of calling
the target assembler.

With that info I find [1] which lists the .arch directive including
+crypto syntax. armclang seems to be the official ARM toolchain.[2]

[1] https://www.keil.com/support/man/docs/armclang_ref/armclang_ref_hhk1510674590407.htm
[2] https://developer.arm.com/tools-and-software/embedded/arm-compiler/downloads/version-6

It is unclear to me if it's available upstream as well or an ARM
addition to the assembler. I'll try to get clang/llvm installed on my
pine64 boards for tests. That might take a few days though. :) I'll see
if I can try a prebuilt toolchain in the meantime.

Calling clang on assembly source with extension .s it calls itself with
(undocumented) option -cc1as, so likely again the integrated assembler:

# clang -v -c -o t.o t.s
clang version 11.0.1
Target: x86_64-pc-linux-gnu
Thread model: posix
InstalledDir: /usr/lib/llvm/11/bin
Selected GCC installation: /usr/lib/gcc/x86_64-pc-linux-gnu/10.2.0
Candidate multilib: .;@m64
Candidate multilib: 32;@m32
Selected multilib: .;@m64
 "/usr/lib/llvm/11/bin/clang-11" -cc1as -triple x86_64-pc-linux-gnu
-filetype obj -main-file-name t.s -target-cpu x86-64
-fdebug-compilation-dir /home/m -dwarf-debug-producer "clang version
11.0.1" -dwarf-version=4 -mrelocation-model static -o t.o t.s
-- 
Sorry,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202131908</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-02-02 13:19:08-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Feb 2, 2021 at 8:00 AM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt;
&gt; &gt; &gt; llvm-as wouldn't recognize pmull instruction without
&gt; &gt; &gt; adding -march=armv8-a+crypto flag at least with the version I use "3.8.1"
&gt;
&gt; 3.8.1 was released in 2017. It might not support recent
&gt; aarch64 additions regarding .arch directive and friends.
&gt;
&gt; &gt; &gt; I tried both .arch armv8-a+crypto and .arch_extension crypto and they
&gt; &gt; &gt; worked only for gas while llvm-as produces errors for pmull using.
&gt; &gt; Is there any documentation for llvm-as? Best I could find is the minimal
&gt; &gt; man page https://www.llvm.org/docs/CommandGuide/llvm-as.html, with no
&gt; &gt; info whatsoever on, e.g., supported pseudoops.
&gt;
&gt; I think my mentioning of llvm-as was a red herring. Looking at the
&gt; output of clang -v, llvm-as isn't involved at all. This is supported by
&gt; the man page stating that llvm-as accepts LLVM assembly and emits LLVM
&gt; bytecode. It appears, clang implements the assembler internally and we'd
&gt; need documentation on that. The clang man page even says so):

Clang always uses its integrated assembler unless you pass
-fno-integrated-as. If you use -fno-integrated-as, then be sure you
have an assembler that supports the ISA you are targeting. On OS X,
GNU's AS may not support the ISA.

Clang's assembler is crippled on OS X. Apple's Clang still does not
support pmull or crc instructions.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202132339</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2021-02-02 13:23:39-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Feb 2, 2021 at 8:19 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Tue, Feb 2, 2021 at 8:00 AM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; &gt; llvm-as wouldn't recognize pmull instruction without
&gt; &gt; &gt; &gt; adding -march=armv8-a+crypto flag at least with the version I use "3.8.1"
&gt; &gt;
&gt; &gt; 3.8.1 was released in 2017. It might not support recent
&gt; &gt; aarch64 additions regarding .arch directive and friends.
&gt; &gt;
&gt; &gt; &gt; &gt; I tried both .arch armv8-a+crypto and .arch_extension crypto and they
&gt; &gt; &gt; &gt; worked only for gas while llvm-as produces errors for pmull using.
&gt; &gt; &gt; Is there any documentation for llvm-as? Best I could find is the minimal
&gt; &gt; &gt; man page https://www.llvm.org/docs/CommandGuide/llvm-as.html, with no
&gt; &gt; &gt; info whatsoever on, e.g., supported pseudoops.
&gt; &gt;
&gt; &gt; I think my mentioning of llvm-as was a red herring. Looking at the
&gt; &gt; output of clang -v, llvm-as isn't involved at all. This is supported by
&gt; &gt; the man page stating that llvm-as accepts LLVM assembly and emits LLVM
&gt; &gt; bytecode. It appears, clang implements the assembler internally and we'd
&gt; &gt; need documentation on that. The clang man page even says so):
&gt;
&gt; Clang always uses its integrated assembler unless you pass
&gt; -fno-integrated-as. If you use -fno-integrated-as, then be sure you
&gt; have an assembler that supports the ISA you are targeting. On OS X,
&gt; GNU's AS may not support the ISA.
&gt;
&gt; Clang's assembler is crippled on OS X. Apple's Clang still does not
&gt; support pmull or crc instructions.

And I forgot to mention... On OS X, when using a port like MacPorts
with GCC... You want to pass -Wa,-q to GCC so GCC uses Clang's
integrated assembler. Without -Wa,-q, GCC will try to use GNU's AS.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202161241</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-02-02 16:12:41-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hi all,

On Tue, Feb 02, 2021 at 08:23:39AM -0500, Jeffrey Walton wrote:

&gt; &gt; &gt; I think my mentioning of llvm-as was a red herring. Looking at the
&gt; &gt; &gt; output of clang -v, llvm-as isn't involved at all. This is supported by
&gt; &gt; &gt; the man page stating that llvm-as accepts LLVM assembly and emits LLVM
&gt; &gt; &gt; bytecode. It appears, clang implements the assembler internally and we'd
&gt; &gt; &gt; need documentation on that. The clang man page even says so):
&gt; &gt;
&gt; &gt; Clang always uses its integrated assembler unless you pass
&gt; &gt; -fno-integrated-as. If you use -fno-integrated-as, then be sure you
I've downloaded binary builds of clang for aarch64 from
https://releases.llvm.org/download.html. 3.9.1 was the oldest prebuilt
toolchain I could find there and 11.0.0 the most recent.

As expected, a one-liner with just a pmull throws errors with gas and
the two clangs:

$ cat t.s
pmull v2.1q, v2.1d, v1.1d
$ aarch64-unknown-linux-gnu-as -v -o t.o t.s
GNU assembler version 2.35.1 (aarch64-unknown-linux-gnu) using BFD version (Gentoo 2.35.1 p2) 2.35.1
t.s: Assembler messages:
t.s:1: Error: selected processor does not support `pmull v2.1q,v2.1d,v1.1d'
$ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
t.s:1:1: error: instruction requires: crypto
pmull v2.1q, v2.1d, v1.1d
^
$ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s
t.s:1:1: error: instruction requires: aes
pmull v2.1q, v2.1d, v1.1d
^

This can be solved for all three with the -march option:

$ aarch64-unknown-linux-gnu-as -o t.o t.s -march=armv8-a+crypto
$ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s -march=armv8-a+crypto
$ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s -march=armv8-a+crypto
$

They also all support the .arch directive:

$ cat t.s
.arch armv8-a+crypto
pmull v2.1q, v2.1d, v1.1d
$ aarch64-unknown-linux-gnu-as -o t.o t.s
$ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
$ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s
$

clang does not, however, support the .arch_extension directive. 3.9.1 complains
about the directive, 11.0.0 seems to silently ignore it:

$ cat t.s
.arch_extension crypto
pmull v2.1q, v2.1d, v1.1d
$ aarch64-unknown-linux-gnu-as -o t.o t.s
$ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
t.s:1:1: error: unknown directive
.arch_extension crypto
^
t.s:2:1: error: instruction requires: crypto
pmull v2.1q, v2.1d, v1.1d
^
$ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s
t.s:2:1: error: instruction requires: aes
pmull v2.1q, v2.1d, v1.1d
^
-- 
HTH,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202170942</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-02 17:09:42-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; I've downloaded binary builds of clang for aarch64 from
&gt; https://releases.llvm.org/download.html. 3.9.1 was the oldest prebuilt
&gt; toolchain I could find there and 11.0.0 the most recent.

[...]

&gt; They also all support the .arch directive:
&gt;
&gt; $ cat t.s
&gt; .arch armv8-a+crypto
&gt; pmull v2.1q, v2.1d, v1.1d
&gt; $ aarch64-unknown-linux-gnu-as -o t.o t.s
&gt; $ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
&gt; $ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s

Thanks for investigating. The .arch pseudoop it is, then.

I've pushed a change to use that, instead of modifying CFLAGS.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202172249</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-02 17:22:49-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; FWIW, I like --enable-arm64-crypto because it would nicely match with a
&gt; directory arm64/crypto for the source and the idea of enabling the
&gt; crypto extension for the arm64 target of nettle and be in line with
&gt; --enable-arm-neon and arm/neon as well.

I'll rename both the directory and the configure option then.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202173304</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-02-02 17:33:04-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, Feb 2, 2021 at 7:22 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:
&gt;
&gt; &gt; FWIW, I like --enable-arm64-crypto because it would nicely match with a
&gt; &gt; directory arm64/crypto for the source and the idea of enabling the
&gt; &gt; crypto extension for the arm64 target of nettle and be in line with
&gt; &gt; --enable-arm-neon and arm/neon as well.
&gt;
&gt; I'll rename both the directory and the configure option then.
&gt;

I agree with the configure option, I also see directories in x86_64 named
with corresponding features so "crypto" name makes sense here too.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202174114</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2021-02-02 17:41:14-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sun, Jan 31, 2021 at 10:35 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; &gt; --- /dev/null
&gt; &gt; +++ b/arm64/v8/gcm-hash.asm
&gt; &gt; @@ -0,0 +1,343 @@
&gt;
&gt; &gt; +C common macros:
&gt; &gt; +.macro PMUL in, param1, param2
&gt; &gt; +    pmull          F.1q,\param2\().1d,\in\().1d
&gt; &gt; +    pmull2         F1.1q,\param2\().2d,\in\().2d
&gt; &gt; +    pmull          R.1q,\param1\().1d,\in\().1d
&gt; &gt; +    pmull2         R1.1q,\param1\().2d,\in\().2d
&gt; &gt; +    eor            F.16b,F.16b,F1.16b
&gt; &gt; +    eor            R.16b,R.16b,R1.16b
&gt; &gt; +.endm
&gt;
&gt; For consistency, I'd prefer defining all needed macros using m4.
&gt;

The macros in gcm-hash.asm file are dependent on defines in the same file
(shared for macros and function implementation) as they are relevant with
the implementation context, also moving those macros to another file makes
confusion for reader IMO.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202200829</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-02-02 20:08:29-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Sun, Jan 31, 2021 at 10:35 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; For consistency, I'd prefer defining all needed macros using m4.
&gt;
&gt; The macros in gcm-hash.asm file are dependent on defines in the same file
&gt; (shared for macros and function implementation) as they are relevant with
&gt; the implementation context, also moving those macros to another file makes
&gt; confusion for reader IMO.

I'm not suggesting moving them to a different file, just changing the
definition to use m4 define, something like (untested):

C PMUL(in,  param1, param2) 
define(`PMUL', `
	pmull          F.1q, $3.1d, $1.1d
	pmull2         F1.1q, $3.2d, $1.2d
	pmull          R.1q, $2.1d, $1.1d
	pmull2         R1.1q, $2.2d, $1.2d
	eor            F.16b, F.16b, F1.16b
	eor            R.16b, R.16b, R1.16b
')

With the recently added m4-utils.m4, one could also add some checking
with m4_assert_numargs(3) at the start of the macro definition, but
that's completely optional (other similar macros currently don't do
that).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210202201804</emailId><senderName>Martin_Storsjö</senderName><senderEmail>martin@martin.st</senderEmail><timestampReceived>2021-02-02 20:18:04-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Tue, 2 Feb 2021, Michael Weiser wrote:

&gt; clang does not, however, support the .arch_extension directive. 3.9.1 complains
&gt; about the directive, 11.0.0 seems to silently ignore it:
&gt; 
&gt; $ cat t.s
&gt; .arch_extension crypto
&gt; pmull v2.1q, v2.1d, v1.1d
&gt; $ aarch64-unknown-linux-gnu-as -o t.o t.s
&gt; $ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
&gt; t.s:1:1: error: unknown directive
&gt; .arch_extension crypto
&gt; ^
&gt; t.s:2:1: error: instruction requires: crypto
&gt; pmull v2.1q, v2.1d, v1.1d
&gt; ^
&gt; $ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s
&gt; t.s:2:1: error: instruction requires: aes
&gt; pmull v2.1q, v2.1d, v1.1d
&gt; ^

Clang does actually support .arch_extension for aarch64 in general since 
Clang 8 - but the "crypto" extension seems to be a bit of a special case, 
as it expands to a number of other features, including aes and sha2, 
depending on the base architecture level:

https://github.com/llvm/llvm-project/blob/main/llvm/lib/Target/AArch64/AsmParser/AArch64AsmParser.cpp#L5361-L5388


This routine is called when enabling extensions in .arch, but not in 
.arch_extension - which is a bug.

So ".arch_extension aes" would work, but setting the extension via the 
.arch directive is indeed more compatible.

// Martin


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210206142249</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-02-06 14:22:49-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Niels,

On Tue, Feb 02, 2021 at 06:09:42PM +0100, Niels Möller wrote:

&gt; &gt; I've downloaded binary builds of clang for aarch64 from
&gt; &gt; https://releases.llvm.org/download.html. 3.9.1 was the oldest prebuilt
&gt; &gt; toolchain I could find there and 11.0.0 the most recent.
&gt; [...]

&gt; &gt; They also all support the .arch directive:
&gt; &gt;
&gt; &gt; $ cat t.s
&gt; &gt; .arch armv8-a+crypto
&gt; &gt; pmull v2.1q, v2.1d, v1.1d
&gt; &gt; $ aarch64-unknown-linux-gnu-as -o t.o t.s
&gt; &gt; $ clang+llvm-3.9.1-aarch64-linux-gnu/bin/clang -c -o t.o t.s
&gt; &gt; $ clang+llvm-11.0.0-aarch64-linux-gnu/bin/clang -c -o t.o t.s
&gt; Thanks for investigating. The .arch pseudoop it is, then.

&gt; I've pushed a change to use that, instead of modifying CFLAGS.

The arm64 branch builds and passes the testsuite on aarch64 and
aarch64_be with gcc 10.2 and clang 11.0.1 with and without the optimized
assembly routines on my pine64 boards. This is with the .arch directive
instead of modifying CFLAGS and the new configure option name
--enable-arm64-crypto.

Out of curiosity I've also collected some benchmark numbers for
gcm_aes256. (Is that a correct and sensible algorithm for that purpose?)

The speedup from using pmull seems to be around 35% for encrypt/decrypt.

Interestingly, LE is about a cycle per block faster than BE even though
it should have quite a few more rev64s to execute than BE. Could this be
masked by memory accesses, pipelining or scheduling?

How is the massive speedup in update to be interpreted and that BE here
is indeed quite a bit faster than LE? Do I understand correctly that on
update only GCM is run on unencrypted data for authentication purposes
so that this number really indicates the pure GCM pmull speedup? If so,
it would indicate 19-fold speedup and an 8.6% advantage to BE.

What's also curious is that the system's openssl 1.1.1i is consistenly
reported an order of magnitude faster than nettle. I guess the major
factor is that there's no optimized AES for aarch64 yet in nettle which
openssl seems to have. So I built an openssl 1.1.1i without assembly
which produced the last benchmark which would support that.

cat /sys/devices/system/cpu/cpufreq/policy0/scaling_governor
performance
cat /sys/devices/system/cpu/cpufreq/policy0/cpuinfo_max_freq
1152000
LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f 1.152e9 gcm_aes256

         Algorithm         mode Mbyte/s cycles/byte cycles/block

aarch64-le gcc 10.2 with arm64-cypto:
        gcm_aes256      encrypt   29.42       37.34       597.41
        gcm_aes256      decrypt   29.43       37.34       597.36
        gcm_aes256       update 1417.32        0.78        12.40

openssl gcm_aes256      encrypt  391.93        2.80        44.85
openssl gcm_aes256      decrypt  392.35        2.80        44.80
openssl gcm_aes256       update 1246.04        0.88        14.11

aarch64-be gcc 10.2 with arm64-cypto:
        gcm_aes256      encrypt   29.35       37.43       598.82
        gcm_aes256      decrypt   29.36       37.42       598.77
        gcm_aes256       update 1540.34        0.71        11.41

openssl gcm_aes256      encrypt  398.96        2.75        44.06
openssl gcm_aes256      decrypt  397.66        2.76        44.20
openssl gcm_aes256       update 1306.05        0.84        13.46

aarch64-le clang 11.0.1 with arm64-cypto:
        gcm_aes256      encrypt   28.76       38.20       611.15
        gcm_aes256      decrypt   28.76       38.19       611.10
        gcm_aes256       update 1416.17        0.78        12.41

openssl gcm_aes256      encrypt  392.32        2.80        44.81
openssl gcm_aes256      decrypt  392.35        2.80        44.80
openssl gcm_aes256       update 1247.72        0.88        14.09

aarch64-be clang 11.0.1 with arm64-cypto:
        gcm_aes256      encrypt   28.70       38.28       612.53
        gcm_aes256      decrypt   28.69       38.29       612.59
        gcm_aes256       update 1543.87        0.71        11.39

openssl gcm_aes256      encrypt  399.46        2.75        44.00
openssl gcm_aes256      decrypt  398.90        2.75        44.07
openssl gcm_aes256       update 1317.87        0.83        13.34

aarch64-le gcc 10.2 without arm64-cypto:
        gcm_aes256      encrypt   21.43       51.27       820.28
        gcm_aes256      decrypt   21.43       51.27       820.30
        gcm_aes256       update   74.39       14.77       236.30

openssl gcm_aes256      encrypt  391.93        2.80        44.85
openssl gcm_aes256      decrypt  392.17        2.80        44.82
openssl gcm_aes256       update 1245.13        0.88        14.12

aarch64-be gcc 10.2 without arm64-cypto:
        gcm_aes256      encrypt   21.71       50.60       809.58
        gcm_aes256      decrypt   21.72       50.59       809.43
        gcm_aes256       update   79.01       13.90       222.47

openssl gcm_aes256      encrypt  398.43        2.76        44.12
openssl gcm_aes256      decrypt  398.67        2.76        44.09
openssl gcm_aes256       update 1309.52        0.84        13.42

aarch64-le clang 11.0.1 without arm64-cypto:
        gcm_aes256      encrypt   18.98       57.89       926.29
        gcm_aes256      decrypt   18.98       57.89       926.22
        gcm_aes256       update   53.67       20.47       327.53

openssl gcm_aes256      encrypt  392.16        2.80        44.82
openssl gcm_aes256      decrypt  392.17        2.80        44.82
openssl gcm_aes256       update 1248.30        0.88        14.08

aarch64-be clang 11.0.1 without arm64-cypto:
        gcm_aes256      encrypt   18.89       58.16       930.49
        gcm_aes256      decrypt   18.85       58.28       932.54
        gcm_aes256       update   53.67       20.47       327.53

openssl gcm_aes256      encrypt  399.36        2.75        44.02
openssl gcm_aes256      decrypt  398.87        2.75        44.07
openssl gcm_aes256       update 1318.44        0.83        13.33

aarch64-be gcc 10.2 without arm64-crypto and with no-asm openssl:
LD_LIBRARY_PATH=../../openssl-1.1.1i:../.lib ./nettle-benchmark -f 1.152e9 gcm_aes256

         Algorithm         mode Mbyte/s cycles/byte cycles/block

        gcm_aes256      encrypt   21.72       50.59       809.43
        gcm_aes256      decrypt   21.72       50.59       809.45
        gcm_aes256       update   79.02       13.90       222.45

openssl gcm_aes256      encrypt   21.06       52.17       834.70
openssl gcm_aes256      decrypt   21.34       51.49       823.82
openssl gcm_aes256       update   56.18       19.55       312.87

x86_64 Intel Skylake laptop gcc 10.2 fat as sanity check:
NETTLE_FAT_VERBOSE=1 LD_LIBRARY_PATH=../.lib ./nettle-benchmark -f 4.6e9
aes256
libnettle: fat library initialization.
libnettle: cpu features: vendor:intel,aesni
libnettle: using aes instructions.
libnettle: not using sha_ni instructions.
libnettle: intel SSE2 will be used for memxor.
sha1_compress: 209.50 cycles
salsa20_core: 205.70 cycles
sha3_permute: 918.50 cycles (38.27 / round)

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            aes256  ECB encrypt 4856.60        0.90        14.45
            aes256  ECB decrypt 4800.03        0.91        14.62
            aes256  CBC encrypt  889.91        4.93        78.87
            aes256  CBC decrypt 4331.24        1.01        16.21
            aes256   (in-place) 3516.29        1.25        19.96
            aes256          CTR 3131.58        1.40        22.41
            aes256   (in-place) 2826.07        1.55        24.84

    openssl aes256  ECB encrypt 4840.40        0.91        14.50
    openssl aes256  ECB decrypt 4835.88        0.91        14.51

        gcm_aes256      encrypt  585.60        7.49       119.86
        gcm_aes256      decrypt  585.29        7.50       119.92
        gcm_aes256       update  697.69        6.29       100.60

openssl gcm_aes256      encrypt 4499.49        0.97        15.60
openssl gcm_aes256      decrypt 4498.84        0.98        15.60
openssl gcm_aes256       update 11383.81        0.39         6.17

Just out of curiosity: I assume there's no aesni-pmull-like GCM
implementation for x86_64?
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210104181549</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-04 18:15:49-0400</timestampReceived><subject>ANNOUNCE: Nettle-3.7</subject><body>

[Attachment #2 (multipart/signed)]


I'm happy to announce a new release of GNU Nettle, a low-level
cryptographics library. This includes one new feature, and several
optimizations, see NEWS entries below.

The Nettle home page can be found at
https://www.lysator.liu.se/~nisse/nettle/, and the manual at
https://www.lysator.liu.se/~nisse/nettle/nettle.html.

The release can be downloaded from

  https://ftp.gnu.org/gnu/nettle/nettle-3.7.tar.gz
  ftp://ftp.gnu.org/gnu/nettle/nettle-3.7.tar.gz
  https://www.lysator.liu.se/~nisse/archive/nettle-3.7.tar.gz

Happy hacking,
/Niels Möller

NEWS for the Nettle 3.7 release

	This release adds one new feature, the bcrypt password hashing
	function, and lots of optimizations. There's also one
	important change to how Nettle is configured: Fat builds are
	now on by default.

	The release adds PowerPC64 assembly for a few algorithms,
	resulting in great speedups. Benchmarked on a Power9 machine,
	speedup was 13 times for AES256-CTR and AES256-GCM, and 3.5
	times for Chacha. For fat builds (now the default), the new
	code is used automatically, on processors supporting the needed
	instruction set extensions.

	The new version is intended to be fully source and binary
	compatible with Nettle-3.6. The shared library names are
	libnettle.so.8.1 and libhogweed.so.6.1, with sonames
	libnettle.so.8 and libhogweed.so.6.

	New features:

	* Support for bcrypt, contributed by Stephen R. van den Berg.

	Optimizations:

	* Much faster AES and GCM on PowerPC64 processors supporting
	  the corresponding crypto extensions. Contributed by Mamone
	  Tarsha.

	* Speed of Chacha improved on PowerPC64, x86_64 and ARM Neon.

	* Speed of Salsa20 improved on x86_64 and ARM Neon.

	* Overhaul of some elliptic curve primitives, improving ECDSA
	  signature speed.

	Configure:

	* Fat builds are enabled by default on the architectures where
	  it is supported (x86_64, arm and powerpc64). To disable
	  runtime selection, and instead specify the processor flavor
	  at configure time, you need to pass --disable-fat to the
	  configure script.

	Known issues:

	* The ARM assembly code in this release doesn't work correctly
	  on big-endian ARM systems. This will hopefully be fixed in a
	  later release.

	Miscellaneous:

	* Use a few more gmp-6.1 functions: mpn_cnd_add_n,
	  mpn_cnd_sub_n, mpn_cnd_swap. Delete corresponding internal
	  Nettle functions.

	* Convert all assembly files to use the default m4 quote
	  characters.

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.


["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210104210034</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-04 21:00:34-0400</timestampReceived><subject>Re: Compile issue on Solaris 11.3</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Hi Everyone,
&gt;
&gt; I bumped to Nettle 3.7. The build is resulting in:

Clearly, the assembler doesn't know of the sha-related instructions
(introduced in 2013, according to
https://en.wikipedia.org/wiki/Intel_SHA_extensions). Which assembler
(and version) are you using? If it's difficult to upgrade the assembler,
it could be worked around by replacing the instructions with equivalent
.byte sequences.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210113152020</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-13 15:20:20-0400</timestampReceived><subject>Old ARM Neon code for salsa20 and chacha (was: Re: Release of Nettle-3.7?)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I've done a benchmark run of nettle-3.6 on the GMP "nanot2" system, with
&gt; a Cortex-A9 processor. The installed compiler is gcc-5.4 (a few years
&gt; old).

I choose Cortex-A9 for this test in attempt to reproduce my old numbers.
Even if it's probably not that relevant today.

&gt; So no big differences, but the neon code improves performance slightly
&gt; for chacha and sal20r12, and degrades performance sligtly for salsa20.

(The improvement for chacha actually seem significant, 13% speedup for
the Neon code).

This is all about the old single-block functions. The Neon code for both
salsa20 and chacha uses instructions operating on four 32-bit entries at
a time. But most instructions depend on the result of the previous
instruction, and latency of Neon instructions is pretty high. According
to measurements by Torbjörn Granlund, we typically have a latency of at
*least* two cycles (the only observed case of single-cycle latency was
for veor on A53 and A55).

In addition, two shift operations, even if they are independent
typically can't be issued in the same cycle, because they compete for a
single shift unit. So if we look at a single round (i.e., a quarter of a
qround) and annotate with latency numbers, i.e., the earliest cycle the
instruction can be started, and for simplicity assume that all
instructions but veor has a latency of 2 cycles, we get (this is for
salsa20):

  vadd.i32 q8, q0, q3        0  t = x0 + x1
  vshl.i32 q9, q8, #7	     2  t &lt;&lt;&lt;= 7
  vshr.u32 q8, q8, #25       3
  veor  q1, q1, q8           4  x1 ^= t
  veor  q1, q1, q9           5
 
  vadd.i32 q8, q0, q1        6  (next QROUND)

So that's 6 cycles, for the same work as 12 scalar (32-bit) operations
(rotation is a single operation if done on scalar registers). So at
best, we can expect to get two 32-bit operations done per cycle. For
SIMD, that's not great at all.

For processors that can issue two instructions per cycle, and with
shorter latency, scalar code (i.e., code using only the general purpose
32-bit registers) could get more or less the same throughput. The scalar
code also gets the advantage that there's a handy rotate instruction
(instead of the shift right + shift left + combine used in the Neon
code), but it has the disadvantage of register shortage, and will need a
bunch of load and store instructions to access the state.

That doesn't quite explain why I saw a 45% speedup with Neon in 2013,
which has now disappeared. But maybe current gcc has good enough
instruction scheduling to produce code that can issue 2 instructions per
cycle on Cortex-A9 (which has quite limited out-of-order capabilities),
and gcc back then couldn't do that?

So what's next? Should the old code just be deleted? 

With the new 2-way or 3-way functions, performance of the single-block
functions isn't that critical, so deletion may be ok even if it causes
some small regression on some processors (e.g., single-block chacha
getting 13% slower on the old Cortex-A9)

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210113183552</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-13 18:35:52-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hello Niels,

On Wed, Jan 13, 2021 at 01:43:38PM +0100, Niels Möller wrote:

&gt; &gt; Attached is the new patch that unconditionally switches from vldm to vld1.32 but
&gt; &gt; keeps vstm in favour of vst1.8 on little-endian for stores.
&gt; Thanks! Applied now.

Perfect! Incidentally: The other day I was migrating my big-endian
cubieboard from LibreSSL to OpenSSL. Afterwards I was wondering why
their assembly routines didn't fail as I remembered and had disabled for
LibreSSL. From a quick glance at the OpenSSL code, it seems they're
doing exactly the same thing using v{ld,st}1[1,2].

[1] https://github.com/openssl/openssl/blob/8bc5b0a570c8a2c9886a3cae9dea2016d510578d/crypto/chacha/asm/chacha-armv4.pl#L686
 [2] https://github.com/openssl/openssl/blob/8bc5b0a570c8a2c9886a3cae9dea2016d510578d/crypto/chacha/asm/chacha-armv4.pl#L817
                
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210121220909</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2021-01-21 22:09:09-0400</timestampReceived><subject>Re: [S390x] Optimize AES modes</subject><body>

Hi, Maamoun

Thanks for setting this up.  The default accounts have a limited time
(90 days?).  For long-term CI access, I can help request a long-term
account for Nettle.

Thanks, David

On Thu, Jan 21, 2021 at 5:05 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; 
&gt; I managed to integrate an instance of LinuxONE Community Cloud to nettle CI, I \
&gt; can't make a merge request for it because it has manual steps so I'll write a guide \
&gt; for it. The integration process is pretty straightforward and it can be done by \
&gt;                 following these steps:
&gt; - Create a free account here https://linuxone.cloud.marist.edu/#/register?flag=VM \
&gt; and make an instance (All instances are z15 so it supports all the current \
&gt;                 implemented features).
&gt; - run the following commands in the instance:
&gt; 
&gt; mkdir nettle &amp;&amp; cd nettle
&gt; git init
&gt; git remote add origin https://gitlab.com/nettle/nettle.git
&gt; 
&gt; - In gitlab go to settings -&gt; CI / CD. Expand Variables and add variable, Key: \
&gt;                 SSH_PRIVATE_KEY, Value: (Set the private key here)
&gt; - Update gitlab-ci.yml as follows (assisted by this recip \
&gt; https://medium.com/@hfally/a-gitlab-ci-config-to-deploy-to-your-server-via-ssh-43bf3cf93775):
&gt;  
&gt; Add this line to variables category:
&gt; 
&gt; DEBIAN_BUILD: buildenv-debian
&gt; 
&gt; Add these lines to the end of file
&gt; 
&gt; Debian.remote.s390x:
&gt; image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$DEBIAN_BUILD
&gt; before_script:
&gt; - apt-get update -qq
&gt; - apt-get install -qq git
&gt; - 'which ssh-agent || ( apt-get install -qq openssh-client )'
&gt; - eval $(ssh-agent -s)
&gt; - ssh-add &lt;(echo "$SSH_PRIVATE_KEY")
&gt; - mkdir -p ~/.ssh
&gt; - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" &gt; ~/.ssh/config
&gt; script:
&gt; - ssh linux1@IP_ADDRESS "cd nettle &amp;&amp; git pull origin s390x --rebase &amp;&amp; \
&gt; ./.bootstrap &amp;&amp; ./configure --enable-fat &amp;&amp; make &amp;&amp; make check &amp;&amp; exit" tags:
&gt; - shared
&gt; - linux
&gt; except:
&gt; - tags
&gt; 
&gt; Note: Replace IP_ADDRESS with ip address of instance.
&gt; 
&gt; On Thu, Jan 21, 2021 at 5:05 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; &gt; 
&gt; &gt; Thanks for the info, I'll see how I can integrate LinuxONE Community Cloud to \
&gt; &gt; nettle CI for automated testing. 
&gt; &gt; regards,
&gt; &gt; Mamone
&gt; &gt; 
&gt; &gt; On Thu, Jan 21, 2021 at 3:56 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; On Thu, Jan 21, 2021 at 2:53 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Any update on this? Is there anything missed in my side?
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; I'm a bit concerned about testing, and missing qemu support. I guess
&gt; &gt; &gt; &gt; we'll have to do with manual tests, but I won't be able to do that
&gt; &gt; &gt; &gt; regularly myself. Sorry for the delay.
&gt; &gt; &gt; 
&gt; &gt; &gt; The Nettle project can access the LinuxONE Community Cloud at Marist
&gt; &gt; &gt; for the long-term to run manual or automated CI testing.  Jenkins and
&gt; &gt; &gt; Travis CI are available, in addition to anything that you want to
&gt; &gt; &gt; configure in your instance.
&gt; &gt; &gt; 
&gt; &gt; &gt; QEMU or emulators on non-IBM hardware are not an option for these features.
&gt; &gt; &gt; 
&gt; &gt; &gt; Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20210128182646</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2021-01-28 18:26:46-0400</timestampReceived><subject>Re: Old ARM Neon code for salsa20 and chacha</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; For processors that can issue two instructions per cycle, and with
&gt; shorter latency, scalar code (i.e., code using only the general purpose
&gt; 32-bit registers) could get more or less the same throughput. The scalar
&gt; code also gets the advantage that there's a handy rotate instruction
&gt; (instead of the shift right + shift left + combine used in the Neon
&gt; code), but it has the disadvantage of register shortage, and will need a
&gt; bunch of load and store instructions to access the state.
&gt;
&gt; That doesn't quite explain why I saw a 45% speedup with Neon in 2013,
&gt; which has now disappeared. But maybe current gcc has good enough
&gt; instruction scheduling to produce code that can issue 2 instructions per
&gt; cycle on Cortex-A9 (which has quite limited out-of-order capabilities),
&gt; and gcc back then couldn't do that?
&gt;
&gt; So what's next? Should the old code just be deleted? 
&gt;
&gt; With the new 2-way or 3-way functions, performance of the single-block
&gt; functions isn't that critical, so deletion may be ok even if it causes
&gt; some small regression on some processors (e.g., single-block chacha
&gt; getting 13% slower on the old Cortex-A9)

I've made a branch with deletion of this code, "delete-1-way-neon". Any
comments before I merge to master?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20210131195800</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2021-01-31 19:58:00-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Hello Niels,

&gt; I think this would be more user-friendle without the "a",
&gt; --enable-armv8-crypto, or --enable-arm64-crypto. Or do you foresee any
&gt; collision with an incompatible ARMv8-M crypto extension or the like?

FWIW, I like --enable-arm64-crypto because it would nicely match with a
directory arm64/crypto for the source and the idea of enabling the
crypto extension for the arm64 target of nettle and be in line with
--enable-arm-neon and arm/neon as well.

&gt; &gt; +    aarch64*)
&gt; &gt; +	    if test "$enable_armv8_a_crypto" = yes ; then
&gt; &gt; +        if test "$ABI" = 64 ; then
&gt; &gt; +          CFLAGS="$CFLAGS -Wa,-march=armv8-a+crypto"
&gt; (This looks slightly different after merging all the changes). 

&gt; I think it's unfortunate to have to modify CFLAGS, and in particular
&gt; using compiler-specific options. Is there any way to use a pseudoop in
&gt; the .asm file instead, similar to the .fpu neon used in the arm/neon/
&gt; files?

With binutils gas, both .arch and .arch_extension seem to do what you
describe. Based on when they appeared in the manual, both are supported
in gas since 2.26[4]. I've done a quick test with 2.35.1. I have
successfully tried both

.arch armv8-a+crypto
(the -a is required here, otherwise errors are still thrown for uses of
pmull with just armv8 or armv8-r)

and

.arch_extension crypto

The testsuite still runs with both on LE and BE cross-compiled and run
under qemu-user.

binutils 2.26 also know the crypto extension name and were released
January 2016. aarch64 support seems to have been introduced in 2.23
(October 2012) and with 2.25 (July 2015) the crypto flag to the -march
command line option was added. (All based on when it appeared in the
documentation.) So we'd likely have a dependency on 2.25 by using the
-march option already and 2.26 wouldn't be a big step.

[4] https://sourceware.org/binutils/docs-2.26/as/AArch64-Directives.html

All this is gas-specific though, I would assume. Some discussion of
compatible extensions to llvm-as seems to have happened in 2018 but I
have not researched what came out of it[5]. The recent date and that
it's the first search hit and no others link to documentation or such
doesn't bode well IMO. It might as well be that llvm-as just knows the
pmull instruction and assembles it fine but can't check if the target
CPU will be able to run it.

[5] https://lists.llvm.org/pipermail/llvm-dev/2018-September/126346.html

What other assemblers for aarch64 do you have in mind?
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email></emails>